{"id": "1301.3860", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "16-Jan-2013", "title": "Maximum Entropy and the Glasses You Are Looking Through", "abstract": "We give an interpretation of the Maximum Entropy (MaxEnt) Principle in game-theoretic terms. Based on this interpretation, we make a formal distinction between different ways of {em applying/} Maximum Entropy distributions. MaxEnt has frequently been criticized on the grounds that it leads to highly representation dependent results. In addition, it is possible to derive a model for this. For example, we do not have a model for the Maximum Entropy distribution using a finite-sample distribution, which allows us to have a model of the maximum entropy in the game, rather than the distribution based on a finite-sample distribution. In this model, it is possible to generate a model that uses an infinite-sample distribution which yields a max-entropy distribution. In general, if we can generate an infinite-sample distribution, then we can derive an infinite-sample distribution using the infinite-sample distribution. In contrast, we do not have a model for a finite-sample distribution, which allows us to derive an infinite-sample distribution, such as a finite-sample distribution, without allowing for infinite-sample distributions. In this view, we should not depend on the max-entropy distribution. In the future, we should consider the MaxEntropy distribution using a finite-sample distribution. A model for max-entropy distribution would be defined in the following manner: MaxEntropy(maxEntropy(maxEntropy(maxEntropy(maxEntropy(maxEntropy(maxEntropy(maxEntropy(maxEntropy(maxEntropy(maxEntropy(maxEntropy(maxEntropy(maxEntropy(maxEntropy(maxEntropy(maxEntropy(maxEntropy(maxEntropy(maxEntropy(maxEntropy(maxEntropy(maxEntropy(maxEntropy(maxEntropy(maxEntropy(maxEntropy(maxEntropy(maxEntropy(maxEntropy(maxEntropy(maxEntropy(maxEntropy(maxEntropy(maxEntropy(maxEntropy(maxEntropy(maxEntropy(maxEntropy(maxEntropy(maxEntropy(maxEntropy(maxEntropy(maxEntropy(maxEntropy(maxEntropy(maxEntropy(maxEntropy(maxEntropy(maxEntropy(maxEntropy(maxEntropy(maxEntropy(maxEntropy(maxEntropy(maxEntropy(maxEntropy(maxEntropy(maxEntropy(", "histories": [["v1", "Wed, 16 Jan 2013 15:50:30 GMT  (356kb)", "http://arxiv.org/abs/1301.3860v1", "Appears in Proceedings of the Sixteenth Conference on Uncertainty in Artificial Intelligence (UAI2000)"]], "COMMENTS": "Appears in Proceedings of the Sixteenth Conference on Uncertainty in Artificial Intelligence (UAI2000)", "reviews": [], "SUBJECTS": "cs.AI", "authors": ["peter d grunwald"], "accepted": false, "id": "1301.3860"}, "pdf": {"name": "1301.3860.pdf", "metadata": {"source": "CRF", "title": "Maximum Entropy and the Glasses You are Looking Through", "authors": ["Peter Grunwald"], "emails": [], "sections": [{"heading": null, "text": "We give an interpretation of the Maxi mum Entropy (MaxEnt) Principle in game theoretic terms. Based on this interpretation, we make a formal distinction between differ ent ways of applying Maximum Entropy dis tributions. MaxEnt has frequently been crit icized on the grounds that it leads to highly representation dependent results. Our dis tinction allows us to avoid this problem in many cases.\n1 INTRODUCTION\nThe Maximum Entropy Principle (Jaynes, 1989) is an often successful yet controversial method for in ductive inference. It has been justified and criticized in many different ways (Jaynes, 1989; Grove et al., 1994; Halpern & Koller, 199 5). Here we give a novel game-theoretic justification that is fundamentally dif ferent from previous ones: we show that the Max Ent distribution for a given constraint is the distribu tion that minimizes the worst-case expected loss when used for prediction in a certain game. We give sev eral interpretations of this game. We argue that the game-theoretic interpretation is more natural than the usual one, and that it sheds new light on the circum stances in which MaxEnt can be fruitfully applied. Specifically, there are applications of MaxEnt where the same inference problem may be associated with\nAlso: CWI, Kruislaan 413, 1098 SJ Amsterdam, The Netherlands. URL: http:/ /robotics.stanford.edu;-grunwald. Most of the work reported here was done while the author was a postdoctoral fellow at the Robotics Lab, Computer Sci ence Dept., Stanford University, Stanford CA 94305. At the time the author was supported by a TALENT-grant awarded by the Netherlands Organization for Scientific Research (NWO). A very preliminary version of some of the work reported here appeared in (Grunwald, 1998).\nseveral different games with different worst-case opti mal strategies. We use this insight to formally distin guish between qualitatively different ways of applying a MaxEnt distribution, ranging from 'completely safe' to 'completely untrustworthy' applications. This also leads to a partial solution of Bertrand's paradox, i.e. the representation dependency of MaxEnt inferences. Sections 2-4 introduce notation and review MaxEnt and the representation dependency problem. Section 5 gives our game-theoretic reinterpretation. Sections 6-8 show how the reinterpretation can be used to distin guish between different ways of applying MaxEnt and to (sometimes) avoid Bertrand's paradox.\n2 PRELIMINARIES\nConsider a finite sample space n. We reserve the use of random variable X to denote outcomes inn. All other random variables can be vector valued, i.e. they are by definition functions from n to R k for some k > 0. For random variable Y : n -t R k, we define the range of Y, denoted by !!y, as\nBy this notation !!x = n. We let Pv stand for the family of all probability distributions over !!y. For a Py E Pv and Av \ufffd !!y, Pv(Av) denotes the probability mass of Av under Py. For distri butions Px E Px, the notation Px(Y = y) is short for Px({x E nx I Y(x) = y}). Let Py E Py and Pz E Pz be distributions over !!y and nz respec tively. We say that Py and Pz are compatible (with underlying space nx) if there exists a Px E Px such that for ally E !!v,Px(Y = y) = Pv({y}) and for all z E !!z, Px(Z = z) = Pz({z}). Intuitively, Py and Pz are compatible if they can be thought of as marginal distributions of a single distribution Px de fined over the more fine-grained space !!x. We fre quently use random variables that are indicator func tions. The indicator function for event A \ufffd Ox is denoted by lxEA and defined by lxEA = 1 if X E A\nUNCERTAINTY IN ARTIFICIAL INTELLIGENCE PROCEEDINGS 2000 239\nand 0 otherwise. A measure for Dy is a function My : Dy --+ (0, oo) . It is extended to arbitrary events Ay \ufffd Dy by M(Ay) := L:yEAv My(y). 'Compatibil ity' of measures My and Mz is defined analogously to compatibility of probability distributions Py and Pz. The entropy of a distribution P over Dx relative to measure M over Dx is defined as\nP(X) M(x) 1-lM(P) := Ep(-ln M(X)] = L P(x) In P(x) . xEOx\nNotational Convention If a distribution, (or mea sure, or set of distributions) is denoted with a subscript Y for some random variable Y, we mean a distribution (measure, set of distributions) over Dy (examples are Py, My, Cy ). If a distribution (measure, set of dis tributions) is denoted without subscript, it is always a distribution (measure, set of distributions) over the basic sample space nx = n.\n3 REVIEW OF MAXENT\nLet \u00a2h, ... , \u00a2k be functions from Dx to R. In the usual MaxEnt setting, we are given a set of constraints regarding the expected values of the functions \u00a2i under some unknown distribution P*:\nwhere the ti are values in R. By taking the \u00a2i to be indicator functions we can express constraints of the form P* (Y = y) = t for arbitrary random variables Y.\nWe now ask the following question: if the only knowl edge we have about P* are the constraints given by (1), what is then our 'best' guess for P*? (for in terpretations of 'best' see Section 6). According to the adherents of maximum entropy we should adopt the distribution P that, among all the distributions satisfying the constraints (1), maximizes the entropy 1-lM(P). To formalize this idea we first abbreviate the constraints ( 1) to\nEp\u00b7 [\u00a2(X)] = t. (2)\nHere \u00a2(X) = (\u00a21 (X), ... , \u00a2k (X))T is a function from Dx to Rk and t is a k-dimensional vector (t1, . . . , tk) T. Each constraint of form (2) determines a set of proba bility distributions satisfying the constraint. This set is denoted by C:\nC := { P E Px I Ep[cp(X)] = t}. (3)\nIn all our theorems and propositions, we will assume the following\nRegularity conditions (A) Dx is finite; (B) the set C mentioned in the theorems is defined as in (3) and is non-empty (this means that every conceivable \u00a2 and t are allowed as long as C is non-empty).\nWe can now define maximum entropy inference for mally: given a tuple (D, M, \u00a2,C), where M is a mea sure over n and \u00a2 and C are as in (3), MaxEnt tells us to adopt the distribution PJ:? given by\nP(X) PJ:? := arg max 1iM(P) = arg max Ep(-ln M(X)]. PEC PEC\n(4)\nOur regularity conditions are sufficient to ensure that a unique PJ:;e always exists.\n4 MAXENT, MEASURE AND"}, {"heading": "RE PRESENTATION DEPENDENCY", "text": "Several versions of MaxEnt and of the related mini mum relative entropy principles exist in the literature. By making the entropy 1iM dependent on an underly ing measure M, we can account for all of these with our Equation 4. We distinguish between two main forms:\nCase A: M NOT available (U-MaxEnt) This is the 'classical' form of MaxEnt for discrete sample spaces (Jaynes, 1989). It does not mention any un derlying measure and tells us to pick the distribution P E C maximizing Ep[-ln P(X)]. It can be imple mented in (4) by taking M to be the uniform measure over the sample space Dx, defined by M(x) := 1. We will refer to this form of MaxEnt as U-MaxEnt.\nCase B: M available We will refer to this case simply as 'MaxEnt'. It has two sub-cases: first, the case where a unique measure ('natural way of counting outcomes') is available a priori. Sometimes, through knowledge of the physics of the domain that is being modeled, one can decide on a unique underlying mea sure M that is appropriate for the domain at hand (for ways to determine such a measure, see (Jaynes, 1989)). ( 4) can be directly applied here. Second, the Minimum Relative Entropy Principle. This is the case where a prior probability Q over nx is known, and the goal is to 'update' this prior probability based on the con straint (2). The minimum relative entropy principle tells us to pick the P minimizing Ep[ln(P(X)/Q(X))]. By picking M = Q, this can be represented as maxi mizing entropy relative to M.\nIf a priori knowledge about the domain other than the given constraint (2) is completely lacking, then U-MaxEnt (case A) is the only form we can apply. Unfortunately, case A is also the most problematic by far. In contrast to case B, case A typically gives results\n240 UNCERTAINTY IN ARTIFICIAL INTELLIGENCE PROCEEDINGS 2000\nthat are highly representation dependent: if the same domain is represented in a different language, Max Ent may lead to different results. Since the choice of representation seems arbitrary, the results one obtains using U-MaxEnt seem arbitrary as well. This fact is at least in the case of continuous data - often referred to as Bertrand's Paradox.\nExample 1 (a simple Bertrand's Paradox) Let nx = { 1, 2, 3} and let there be no further constraints (in our formulation, this can be expressed by picking \u00a2(x) = 0 and constraint Ep\u00b7 [\u00a2(X)] = 0). Consider an agent (call him Mr. X) who wants to infer a distri bution over Dx and who uses U-MaxEnt. Hence he picks PrJ; as given by ( 4) with U x the uniform mea sure over Dx . As is well known, the resulting PrJ; is the uniform distribution over Dx . Now consider an other agent (Mrs. Y) who looks at the same domain at a coarser level. Specifically, she can only distin guish between the case where X = 1 on the one hand and X E { 2, 3} on the other hand. Mrs. Y's sample space is therefore !1y = { { 1 }, {2, 3}}. If Mrs. Y uses U-MaxEnt she will adopt a uniform measure Uy over !1y. She will then infer a distribution PrJ: uniform over !1y. Then PrJ;( {1}) = 1/2, P{}';( {1}) = 1/3: the distributions inferred by Mr. X and Mrs. Y are incom patible, even though they are based on the same do main. For more subtle examples of this phenomenon, see for example (Halpern & Koller, 1995). In our for mulation (with underlying measure), Bertrand's para dox can be equivalently expressed as the dependency of PJ:r on the choice of underlying measure M. In our example, if Mrs. Y uses the measure M{r defined by M{r( {2, 3}) := 2 and My({1}) := 1 then she will infer P't:fi' ( { 1}) = 1 /3 after all: this change of measure over\ny !1y has the same effect on the probability assignments to elements of !1y as the representation change from !1y (with measure Uy) to the more fine-grained Dx (with measure U x) . This observation will be made precise in Theorem 2, Section 7.\nImportant In many cases, physical background knowl edge provides a 'natural' space for representing the domain at hand. For example, if we are to investigate the probabilities of the faces of a (possibly loaded) die, then by symmetry considerations, we should not distinguish a priori between the six faces. It is then only natural to take as basic sample space the space with exactly one outcome for each face, and to take a uniform measure over this space. The representation dependency should be considered problematic only if there is no preferred 'natural' sample space or (equiv alently, by Theorem 2), no natural underlying mea sure/prior.\nSome people do not see the above example as problem atic: the two agents are facing different 'experimental\nsituations', so it is not so strange that they obtain different results. But then the question is: what ex actly constitutes an 'experimental situation'? It is this question we will partially answer through our game theoretic reinterpretation of MaxEnt, which we pro ceed to discuss.\n5 MAXENT AS A GAME\nThe information inequality (Cover & Thomas, 1991) tells us that for all distributions p and Q over nx '\nEp[-ln P(X)] :S Ep[-ln Q(X)], (5)\nwith equality iff P = Q. This implies infQEPx Ep[-ln(Q(X)/M(X))] Ep[-ln(P(X)/M(X))] and hence entropy can be characterized as: 1iM(P) = infQEPx Ep[-ln(Q(X)/M(X))]. The maximum at tainable entropy for distributions in a set C is therefore given by\nsup 1iM(P) =sup inf Ep[-ln M Q( ( X X ) )]. (6) PEC PECQEPx\nReaders familiar with game theory (see e.g. (Berger, 198 5)) will recognize (6) as the maximin gain of a two player zero-sum game. If they are acquainted with Von Neumann's minimax theorem, they may further suspect that the following equality holds:\ninf sup Ep[-ln M Q( ( X X ) )] = QEPx PEC\nsup inf Ep[-ln M Q( ( X X ) )] = 1iM(PJ:;e). (7) PECQEPx\nThis equality indeed holds under very mild conditions, although this does not follow directly from Von Neu mann or Nash's theorems (which cannot handle arbi trary convex sets of mixed strategies such as C):\nTheorem 1 Under the regularity conditions of Section 3, Equation 7 holds. Moreover, (a) SUPPEC infQEPx Ep[-ln(Q(X)jM(X))] is reached for (and only for) P = PJ:r; {b) infQEPx supPEC Ep[-ln(Q(X)/M(X))] is reached for (and only for) Q = PJ:r. Hence (c) we have\nme . E [ I P(X) ] PM = arg mm sup p\u2022 - n M(X) , PEPx P*EC (8)\n{d) PJ:je is an 'equalizer strategy', i.e. for all P* E C,\nPJ:[e(X) _ PJ:[e(X) Ep\u00b7 [-ln M(X) ) - Ep;;e [-ln M(X) ) (9)\nA similar theorem with much less conditions on Dx and C will be provided in (Grunwald & Dawid, 2000).\nUNCERTAINTY IN ARTIFICIAL INTELLIGENCE PROCEEDINGS 2000 241\nBasic Interpretation Consider the decision theoretic setting where an Agent has to make deci sions about the outcomes in some space Ox. Agent's decisions come from a decision space V and the loss is measured by some function LOSS : Ox xV --+ RU{oo}. After making a decision 8 E V, the actual outcome x E Ox is revealed and Agent incurs a loss Loss(x, 8). Sometimes the decisions 8 are best interpreted as predictions of the values of x, sometimes they are best interpreted as game playing strategies.\nThe logarithmic loss function is a loss function that occurs in several games with several interpretations (Berger, 198 5; Cover & Thomas, 1991). The set V of available decisions for these games consists of all functions P : Ox --+ [0, 1) such that LxEflx P(x) = 1. Hence V is formally equivalent to Px. However, as we will see, the elements of V sometimes have interpreta tions very different from probability distributions. The logarithmic loss function (relative to measure M) is de fined by LOSS(x, P) = -ln(P(x)/M(x)) for each x E Ox and P E V. Consider now a game where Nature chooses a 'true' distribution P* and Agent wants to minimize his expected logarithmic loss. If Agent knew P*, he would choose arg minPEPx Ep\u00b7 [Loss(X, P)]. By the information inequality (5) we see that this is given by P = P*. But now consider the case where Agent only knows that P* E C for some set C. He may now want to minimize his worst-case (maximal) ex pected logarithmic loss over all choices of Nature. This is exactly what is expressed by (8): the maximum en tropy distribution is the worst-case optimal distribution for predicting outcomes of Ox when loss is measured by the logarithmic loss function.\nWhy would Agent at all be interested in minimizing logarithmic loss? This game has several important in terpretations. Below we discuss one that is of specific interest in the remainder of this paper; others are sum marized in Section 5.2."}, {"heading": "5.1 KELLY GAMBLING INTERPRETATION", "text": "Imagine a lottery where there are tickets for sale for betting on outcomes in Ox = {1, ... , m }. Ticket j (for 1 \ufffd j \ufffd m) pays b units if outcome j actually occurs; otherwise, it pays nothing. All tickets cost 1 unit, so all outcomes share the same odds. Agent has some capital K which he wants to invest in lottery tickets. Suppose that Agent thinks that the actual outcomes are distributed according to some distribu tion P*. Agent's gambling strategy can be described by a vector P = (P(1), . . . , P(m)) where P(j) is the fraction of capital K that Agent invests in outcome j. That is, he buys P(j) \u00b7 K tickets for outcome j; for convenience we allow buying a non-integer amount of tickets. If Agent plays the game only once, then\nhis expected gain Ep\u00b7 [bK P(X)] is maximized by the strategy with P(j) = 1 for the j with maximum prob ability P* (j). But now suppose Agent plays the same game several times. After each round, he reinvests his remaining capital by buying tickets for the next round. So after round 1, his capital is KI = P(xi)bK where XI is the actual outcome at round 1. After round 2, his capital is K2 = P(x 2 )bKI etc. If the number of rounds n is not too small or if it is not known in advance how many rounds there will be, it becomes better for Agent to adopt a fundamentally different strategy, sometimes called proportional gambling or the Kelly gambling scheme (Cover & Thomas, 1991, Chapter 7). This is defined as the gambling strategy P maximizing Ep\u00b7 [In P(X)). This quantity may be interpreted as the expected growth rate of the invested capital. To see why this is a sensible strategy, let P and Q be two distributions such that Ep. [In P(X)) > Ep\u00b7 [In Q(X)]. Suppose the game is played n times, and outcomes XI, ... , Xn are all independently dis tributed ,...., P*. Then, by the strong law of large numbers, (1/n)L.::\ufffd=Iln P(X;)--+ Ep.[ln P(X)] and (1/n) L.:\ufffd=Iln Q(X;) --+ Ep\u00b7 [In Q(X)) with probabil ity 1. It follows that there exists an \u20ac > 0 such that with probability 1, for all large n, I:\ufffd= I In P(X;) > L.:\ufffd=I In Q(X;) + m. This implies\nn n (10)\ni=I i=I\nwith ?*-probability 1, for all n larger than some n0. If Agent uses strategy P at each round i, his capi tal after n rounds is given by K bn TI\ufffd=I P(x;) . To gether with (10) this implies that for any two strate gies P and Q, with P* probability 1, Agent's end cap ital is exponentially larger for the strategy with larger expected growth rate. So (at least if n is large or unknown) a rational Agent should adopt the strat egy P maximizing Ep\u00b7 [In P(X)]. If the only thing Agent knows about P* is that P* E C, it is a good idea for the Agent to maximize his worst-case expected growth rate, i.e. to pick the strategy P that maximizes minp\u2022EC Ep\u00b7 [In P(X)], which is identical to the distri bution minimizing maxp\u2022EC Ep\u00b7 [-ln P(X)). The lat ter distribution is the MaxEnt distribution with uni form measure M: PJ:r is the worst-case optimal distri bution in the Kelly gambling game, maximizing, with probability 1, the worst-case end-capital for all large n. A uniform underlying measure M corresponds to the game with equal odds for all outcomes; non-uniform measures correspond to games with non-uniform odds.\n5.2 MDL & OTHER INTERPRETATIONS\nThe minimax game (8) has several other interpreta tions. We mention two. First, there is a statistical in-\n242 UNCERTAINTY IN ARTIFICIAL INTELLIGENCE PROCEEDINGS 2000\nterpretation: many statistical inference procedures can be interpreted as trying to infer, for a given set of data, the probability model within some class of models M that is 'as close as possible' to the unknown, 'true' data generating distribution P*. In Maximum Likeli hood and some Bayesian inference procedures, 'close ness' is measured by means of the Kullback-Leibler KL distance, which, for fixed P* and M, only differs from the expected logarithmic loss Ep\u00b7 [-ln(P(X)/M(X))] by a constant. Second, there is an interpretation in terms of the Minimum Description Length (MDL) Principle (Grunwald, 1998), a method for inductive in ference that is based on data compression. MDL can be seen as a mathematical formalization of Occam's Razor. It turns out that based on the minimax for mulation (8), MaxEnt can be interpreted as a form of MDL; this is shown in (Grunwald, 1998). Finally, we note that even if we do not assume the existence of a unique true distribution P* (to which for example the Bayesians may object) a form of our analysis can still be performed. All this will be treated in detail in the journal version of this paper.\n6 THE GLASSES YOU ARE LOOKING THROUGH\nLet us now stand back and ask why Agent would like to infer a probability distribution over a domain in the first place. Usually, this is because he would like to make good or at least reasonable predictions or deci sions concerning some random variable Y referring to the domain (more general prediction tasks will be con sidered in later sections). If Y is a random variable in the domain and V is a set of available decisions, then the quality of such decisions is usually measured by some loss function LOSS : S1y x V -t RU { oo}. If Agent knew the 'true' distribution P* governing domain f!x, then he could use this knowledge to make optimal pre dictions for any given loss function by predicting us ing the action J = arg minoE'D Ep\u00b7 [Loss (Y, 8)] (Berger, 198 5).\nBut the interpretation of PJ.:le from the minimax point of view (8) suggests that PJ.:le should first and fore most be interpreted as the strategy to adopt in the game described in Section 5 and not as the distribu tion P* according to which data are distributed. This leads to a key insight: perhaps we should not regard PJ.:le as a guess of the 'true' P* to be used by Agent in every prediction task that can be defined over the domain. It may be better to think of PJ.:le as being wrong yet useful in that it may be a reasonable guess of P* for use in some possible prediction tasks (i.e. for some random variables and loss functions) but a quite unreasonable guess for use in other combinations of\nrandom variables and loss functions1. To make this idea concrete, suppose Agent has no access to P* but approximates it using PJ.:}\". For given loss function LOSS , Agent can use PJ.:le to arrive at a prediction by picking\nJ = argmin Epm\u2022 [ LOSS (Y, 8)]. (11) oE'D M\nIn general, this will lead to reasonable results if V8 E V: EpM\u2022 [LOss (Y, 8)] \ufffd Ep\u00b7 [LOss(Y, 8)]. For each 8 E V, the function 'ljJ defined by '1/J (x) := LOSS(Y(x), 8) is a random variable. Hence, in order to be able to decide for arbitrary loss function LOSS whether PJ.:le as used in ( 11) will lead to reasonable predictions, it suffices if for arbitrary random variables 'ljJ : f!x -t R k, we can decide whether EpM\u2022 ['1/J (X)] is a reasonable guess for Ep\u00b7 ['1/J (X)]. Let us analyze this question further. In order to predict the likely value of Ep\u00b7 ['1/J (X)], Agent must assign probabilities to the values in f!w that random variable 'ljJ takes. This involves 'looking at the domain' in terms of the function '1/J; in other words, 'ljJ determines the 'glasses' through which Agent looks at data X from sample space S1x. But when in ferring PJ.:le, Agent observes averages of values of the function \u00a2. Hence Agent looks at the world in terms of f!.p. As discussed in Section 5.1, PJ.:le maximizes the worst-case gain when used for Kelly Gambling on the outcomes in f!x against odds determined by M. We may now ask ourselves why Agent should be in terested in a distribution that maximizes gain when betting on outcomes in nx if both the observables (\u00a2(X)) and the 'predictables' ('1/J (X)) are outcomes in spaces different from S1x. If no a priori measure M is available, U-MaxEnt advocates a uniform M. But should Agent adopt a uniform M over f!x, f!.p or f!w? Indeed \u00a2, 'ljJ and X may be related in such a way that the optimal gambling strategies against uniform odds for outcomes in nx, f!.p and n\"' are mutually incom patible. This immediately suggests that postulating a uniform measure over f!x may not be the right thing to do; and that it is not so strange that it leads to representation dependence. Analyzing this fact with the game-theoretic interpretation in mind, we find (in Section 8.3) that if \u00a2 and 'ljJ are related in a certain way, we can do something about this. Namely, as long as f!w is at least as 'coarse' as f!.p ('looking at an out come x through the 'glasses' \u00a2 allows a view on f!x\n1Related ideas are quite common in statistics and Ma chine Learning. As an example, 'Naive Bayes' models are joint probability distributions defined over discrete random variables X 1, .. . , Xk, Y of a certain parametric form. They usually perform exceedingly well when used to predict val ues of y conditional on xl, ... xk (Friedman et al., 1997) under the 0/1 {classification} loss function. Yet they make all kinds of unwarranted independence assumptions that might lead to disastrous results if they were used to pre dict, say, the value of x2 conditional on the value of xl.\nUNCERTAINTY IN ARTIFICIAL INTELLIGENCE PROCEEDINGS 2000 243\nthat is at least as fine-grained as the view through the glasses 'lj; '), it is still possible to postulate an a priori measure M (not necessarily uniform over Ox) such that the Kelly gambling games on outcomes in O.p and 01/1 and Ox against odds determined by M share the same worst-case optimal strategy PJ:;e. Moreover, as we shall see, postulating M in this way makes PJ.:? representation independent as long as it is only used for predictions concerning random variables 'lj; that are at least as 'coarse' as \u00a2. Similarly, under stronger con ditions on the relation between the functions \u00a2 and 'lj;, one can guarantee not only that PJ:? is representa tion independent but even that Ep;:;e ['1/J ] = Ep\u00b7 ['1/J ], i.e. that the MaxEnt guess of Ep\u00b7 ['1/J ] is correct. The moral of the story is that, depending on how the 'glasses' (ways of looking at the data) \u00a2 and 'lj; are re lated, applying MaxEnt may (a) be inherently repre sentation dependent (and should therefore not be used at all), or (b) be representation independent but not guaranteed to be 'optimal' or 'correct' (in this case it can be used as an inductive guess) or (c) be guaranteed to lead to correct or optimal predictions (in which case it should certainly be used). In Section 8 we formalize this distinction. We first need to establish the relation between representations and underlying measures.\n7 REPRESENTATION & MEASURE\nIn this section we will show that if we stick to a fixed measure, the results given by MaxEnt are invariant under all reasonable representation changes.\nFor two random variables Y and Z we say that Y de termines Z if there exists a function g : Oy -+ Oz such that for each x E 0, g(Y(x)) = Z(x) . In the language of measure theory, this can be simply expressed as 'Z is measurable in the u-algebra generated by Y'. More generally, we say that 'Y determines Z over A \ufffd Ox' if there exists g : Oy -+ Oz such that for each X E A, g(Y(x)) = Z(x) . A set Ov is an underlying space for space Oz if there exists a function h : Ov -+ Oz such that for all z E Oz, there exists v E Ov with h(v) = z. We can think of an underlying space Ov as a space that is at least as or more fine-grained than Oz. If V is a random variable Ox -+ Ov, then this simply means that V determines Z. The notion is more general in that we can take Z =X. In this case, Ov provides a new sample space such that all random variables that can be expressed as functions of Ox can also be ex pressed as functions of Ov. Let Ov be an underlying space for Ox. For any random variable Y : Ox -+ R, we write Yv to denote the random variable Ov -+ R that corresponds to Y in the underlying space: for all v E Ov, Yv(v) := Y(h(v)) with h : Ov -+ Ox de fined as above. With this convention, the function h\nitself can be written as h = Yv. More generally, let Wv and Tv be any two random variables Ov -+ R in the underlying space Ov, such that Wv determines Tv. Then Tw is defined as a function Ow -+ R with Vv E Ov : Tw(Wv(v)) := Tv(v) (in other words, Tw is a random variable in the intermediate space Ow that always takes on the same value as Tv). With this notation, \u00a2 can be equivalently written as \u00a2x. A MaxEnt problem with given underlying measure is characterized by a tuple (Ox, Mx, \u00a2x, Cx) (Sec tion 3). A valid representation shift of MaxEnt prob lem (Ox, Mx, \u00a2x, Cx) is a triple (Ov, Ow, Mw). Here Ov, Ow are sets and Mw is a measure over Ow satis fying\n1. Ov is an underlying space both for Ox and for Ow;\n2. the random variable Wv determines \u00a2v; 3. Mw and Mx are compatible (with underlying\nspace Ov; see Section 2).\nOx is called the original representation space and Ow is called the new representation space.\nIntuitively, a representation shift is 'valid' if the con straint Ep\u00b7 [\u00a2] = t can still be expressed in the new space. A valid representation shift (Ov, Ow, Mw) in duces a new MaxEnt problem (Ow, Mw, \u00a2w, Cw) de fined as follows:\nPme E [ l Pw(Ww) ] W;Mw := arg max Pw - n M (W ) , PwECw W W where Cw is the set of all distributions Pw over Pw that are compatible (with underlying space Ov) with some Px E C. By Theorem 1 we have that\nme . E [ l Pw(Ww) ] Pw;Mw = arg mm \ufffdup PW.- n M (W ) \u00b7 PwEPw PwECw W W\nThe following result is a simple extension of a well known theorem (see, for example (Shore & Johnson, 1980)). It shows that, if a measure Mx for the origi nal representation space is available, then a valid rep resentation shift leads to the same MaxEnt inferences for all random variables Y that can be expressed both in terms of the original and in terms of the new rep resentation space. In other words, as long as Mx is available, MaxEnt is representation independent.\nTheorem 2 Let (Ov, Ow, Mw) be a valid represen tation shift for MaxEnt problem (Ox, Mx, \u00a2x, Cx). Then for all Y : Ox -+ R such that X determines Y and Wv determines Yv, we have for all y E Oy:\nPw\ufffdMw (Yw = y) = Px/Mx (Yx = y)\n244 UNCERTAINTY IN ARTIFICIAL INTELLIGENCE PROCEEDINGS 2000\nThe present game-theoretic view provides a novel and simple interpretation of this result. Roughly speaking, a representation change amounts to a change in the set of tickets one can buy in the Kelly gambling game (out comes in nw rather than nx); by adopting a measure (odds) over Dw that is compatible with the measure (odds) Mx over Dx, one ensures that the prices of the different tickets will change along with the represen tation change so that the gambling game in the new space is essentially equivalent to the original game.\nThis implies that representation dependence of U MaxEnt stems only from the fact that, if we change representation from nx to nw' we adopt mutually in compatible measures (namely, the uniform measures in both spaces). In fact, we can view each measure Mx (as long as it is rational-valued) as an implicit re representation of the problem to a different underlying space Dv in which Mx (or, more precisely, the mea sure over Dv that is compatible with Mx) is uniform over Dv. We will use of this insight in the next sec tion, where we show how to apply MaxEnt in a careful manner.\n8 HOW TO APPLY MAXENT\nIn this section we return to our previous notation, i.e. PJ:;e is short for P)(';'k. Whenever in what follows we say 'we apply MaxEnt for guessing Ep\u00b7 [Y IZ] relative to measure M' this means that we use PJ:;e, defined for a set of constraints C as given by (3) as follows: we observe the value z taken on by Z. Then we infer (guess) that\nEp;:;\u2022 [YIZ = z] \ufffd Ep. [YIZ = z]. (12)\nwhere P* is the unknown 'true' distribution. We want to arrive at the general conditions on \u00a2, Y and Z under which inference (12) can be expected to be a reason able guess and we want to know what Agent should do if he does not know what M to pick. To treat this question in full generality, we will assume that Agent uses a set M of 'a priori possible underlying measures'. The case where an underlying measure or prior M is available can now be formulated by setting M := {M}. In the case where we have a definite rea son to pick nx as our basic representation space (e.g. the case of throwing dice, see Example 1), we can take M := { U x}, where U x is the uniform measure over Dx. If no underlying measure can be determined at all, we will set M to be the class of all measures over Dx. As we will see, this will make MaxEnt undefined in most cases. In order to make it well-defined, we must first guess a subset M' of M; that case will be treated in Section 8.3.\nWe are now ready to present our hierarchy of different forms of applying MaxEnt.\nDefinition 1 Application of MaxEnt for guessing Ep. [YIZ] relative to a set of measures M is called\n1. conditionally correct if Ep;:;\u00b7[YIZ = z] Ep\u00b7 [YIZ = z] for all M E M, all z E Dz, all P* E C.\n2. conditionally calibrated if there exists a ran dom variable V such that Z determines V, and Ep;:;\u00b7 [YIZ = z] = Ep;:;\u2022 [Y/Vz = Vz(z)] = Ep\u00b7(Y/Vz = Vz(z)] for all ME M, all z E Dz, all P* E C.\n3. well-defined if Epm\u2022[YIZ = z] = Epm\u2022[YIZ = Ml M2 z] for all M1, M2 EM, all z E Dz.\n4. ill-defined otherwise.\nWe note that 1. => 2. => 3. Category 2., while perhaps the most interesting, takes too long to discuss here. It will be explained in detail in the journal version of this paper. Category 4. concerns applications of Maximum Entropy that lead to arbitrary results and hence should be avoided (but see the next section!). By the discussion of the previous section, every (rational valued) measure M E M corresponds to an 'allowed' representation shift. Therefore, ill-defined applications of MaxEnt with respect to the set of all measures over Dx correspond to those applications of U -MaxEnt that are representation dependent. The other extreme is Category 1, which concerns applications of Max imum Entropy that are completely without risk. If MaxEnt is 'conditionally correct' for Ep\u00b7 [Y/Z == z], the guess Ep;:;\u2022[YIZ = z] = Ep\u00b7[YIZ = z] is guaran teed to be correct and involves no inductive inference. Theorem 3 below determines when this is the case.\n8.1 CONDITIONAL CORRECTNESS\nLet 'ljJ : Dx -+ R and \u00a2 : Dx -+ Rk be two functions and let A \ufffd nx. We say that 'ljJ is an affine function of \u00a2 over subdomain A if there exists (a:0, ... , ak) E Rk+1 such that for all x E A, 'l/J(x) = a:o + L\ufffd=l a:;\u00a2;(x) . We define the support SUPP of P'x \ufffd Px by\nSUPP(P'x) := {x E nx I P(x) > 0 for some p E P'x}.\nTheorem 3 If 'ljJ is an affine function of\u00a2 over subdo main SUPP(C), then for all Pt, P2* E C, Ept('l/J(X)] = Ep;('l/J(X)]. If 'ljJ is not an affine function of \u00a2 over subdomain SUPP(C) then there exist Pt, P2 E C such that Eptf'l/J(X)] ::j:. Ep;('l/J(X)].\nUNCERTAINTY IN ARTIFICIAL INTELLIGENCE PROCEEDINGS 2000 245\nLet Z be a 'trivial' random variable, i.e. 'Vx E Ox, Z(x) = 1. Theorem 1 implies that for any ME M and any C of form (3), PJ:;e E C. Theorem 3 now gives that for arbitrary sets of measures M, apply ing MaxEnt to guess Ep\u00b7 [YIZ] is conditionally cor rect iff Y is an affine function of \u00a2 over subdomain SUPP(C). To determine whether applying MaxEnt to guess Ep\u00b7 [YIZ] is conditionally correct for non-trivial Z (the case that Z(x) varies over SUPP(C)), we inter pret the conditioning event Z = z as the additional constraint Ep\u00b7 [1z=z] = 1. Clearly, this constraint is of the required form (2). Let, for z E Oz,\nc(z) = c n {P* E Px I Ep\u00b7[1z=zl = 1}. (13)\nThen, by the same reasoning as above, applying Max Ent to guess Ep\u00b7 [YIZ] is conditionally correct iff Y is an affine function of \u00a2 over subdomain SUPP(C(z)) for all z E Oz. This seems to imply that 'correct' applications of MaxEnt are trivial: if we know that Y is affine in \u00a2, i.e. Y(x) = ao + 2::7=1 a;\u00a2;(x), we can also directly infer that Ep\u00b7 [Y] = a0 + 2::7=1 a;Ep\u00b7[\u00a2;(X)] = a0 + 2::7=1 a;Ep;;\u2022[\u00a2;(X)] = Ep;;\u2022 [Y(X)] (the second equality follows because both P* and PJ:;e are members of C). However, there is at least one case where 'correct' applications are not entirely trivial. From Theorem 1 we see that for all P* E C, Ep;;\u00b7[-ln(P\u00a3;e(X)/M(X))] = Ep\u00b7 [-ln(PMe(X)/M(X))] (indeed, it turns out that -ln(PMe(\u00b7)/M(\u00b7)) is an affine function of \u00a2). This means that MaxEnt is 'correct' for inferring the ex pected logarithmic loss in the games described in Sec tion 5, e.g. in Kelly Gambling with odds determined by M. This can be interpreted as follows: imagine an Agent who adopts pMe and uses it for prediction of outcomes in Ox with respect to log-loss relative to measure M. For gambling strategy o E Px, he expects to incur loss Ep;;\u2022 [-In ;J{JJ) ]. Agent therefore decides to use the o which minimizes this, which by the infor mation inequality (Section 5) is given by o = pMe. Us ing this choice of o, Agent expects to make an average loss of Ep;;\u00b7[-ln(PMe(X)/M(X))]. In reality, he will make an average loss of Ep.[-ln(PMe(X)/M(X))]. Since these two are equal, Agent will have the right idea of how well he will be able to predict on average even if pMe is wrong.\n8.2 REPRESENTATION DEPENDENCE\nBy Definition 1, if M contains only a single element, MaxEnt is well-defined for guessing Ep. [YIZ] for all Y and Z. By Theorem 2, the guesses are also repre sentation independent. The other extreme is the case where no underlying measure is known at all and M contains all measures over Ox. It is straightforward to show\nProposition 1 Suppose M contains all measures over Ox. Then MaxEnt is ill-defined for guessing Ep. [YIZ] iff it is not conditionally correct for guessing Ep.[YIZJ.\nSince different measures correspond to different repre sentations, this corresponds to the fact that U-MaxEnt is highly representation dependent. The only way we can get to the interesting cases 2. and 3. of Defini tion 1 is by restricting the set of available measures M. It seems we have not gained anything so far, since we do not know how this should be done (we have already seen that choosing M = {Ux }, with Ux the uniform measure over Ox leads to representation dependence)! But it turns out that if the functions \u00a2, Y and Z are related in certain ways, then we can choose a subset of M in a different way that does preserve representation independence."}, {"heading": "8.3 REPRESENTATION INDEPENDENCE", "text": "We want to first select a subset M' of M and then apply MaxEnt to guess Ep\u00b7 [YIZ] in such a way that the whole (2-step) procedure becomes representation independent. Since we have no fixed measure or prior over Ox, the choice of flx as our basic sample space is essentially arbitrary. Therefore our procedure for se lecting measures should give the same result for every alternative choice of sample space in which both the constraint Ep\u00b7 [\u00a2] = t and the guess Ep\u00b7 [YIZ] can be expressed. Our previous analysis suggests a novel way of guessing M' which in many cases achieves this. It is based on the idea that the 'observables' in our problem are really the outcomes in Oq, and not the outcomes in Ox. This suggests postulating a uniform measure Uq, over Oq, rather than Ox. If we then restrict the func tions 'lj; about which we make guesses to those that are determined by \u00a2, the arbitrary choice of our basic rep resentation space Ox becomes irrelevant and we are guaranteed to make the same predictions independent of whatever Ox we choose. We now formalize this idea.\nWhen no underlying measure is given, a MaxEnt prob lem is determined by a triple (Ox, \u00a2x, Cx). Note that, compared to the treatment in Section 7, the measure Mx is missing. A valid representation shift of such a MaxEnt problem is a pair (Ov, Ow) such that (1) Ov is an underlying space both for Ox and for Ow; and (2), the random variable Wv determines \u00a2v (again, compare to the definition of valid representation shift in Section 7). The representation shift leads to a new MaxEnt problem (Ow, \u00a2w, Cw) where Cw is the set of distributions over Ow compatible to Cx (compatibility with respect to underlying space Ov).\nLet (Ov, Ow) be any valid representation shift of the\n246 UNCERTAINTY IN ARTIFICIAL INTELLIGENCE PROCEEDINGS 2000\nMaxEnt problem (Ox, \u00a2x, Cx ). Let U,p be the uniform measure over Oct>. Let M\ufffd be the class of all measures over Ox that are compatible with U,p, and let Mw be the class of all measures over Ow that are compati ble with U,p (compatibility with respect to underlying space Ov).\nProposition 2 (Bertrand's Paradox 'resolved') Let 'lj; : Ox ---+ R be a random variable in the original representation space. If 4> determines 'lj; on SUPP(C), then for all Mw E Mw and all Mx E M\ufffd, Ep\ufffd\u00b7 ['lj;w] = Ep\ufffd\u00b7 ['lj;x]; if 4> does not determine\nW;Mw X;Mx\n'lj; on SUPP(C), there exist Mx, M'x E M\ufffd such that Ep\ufffde ['lj;x] =f. Ep\ufffde ['lj;x].\nX;Mx X;M\ufffd\nThe proposition says that our two-step procedure gives representation independence iff MaxEnt is used to guess functions 'lj; that are determined by \u00a2. Defining cCz) as in (13) and reasoning exactly as below Theo rem 3, we obtain the following (informally stated)\nCorollary 1 The procedure of first setting Mx to be the set of measures over Ox that are compatible with Uct> and then applying MaxEnt to guess Ep. [YIZ] rel ative to set of measures Mx is a representation inde pendent procedure iff, for all z E Oz, \u00a2 determines Y over subdomain SUPP(C(zl). In particular this will be the case if 4> determines both Y and Z.\nSummarizing, if all measures M over Ox are a priori possible, then instead of using U-MaxEnt it may be better to adopt a uniform measure U,p over the space of observables O,p. In this way one obtains a proce dure which is representation independent for guessing a large class of random variables Y conditional on a large class of random variables Z. The measure U \u00a2 induces a set Mx of compatible measures over Ox. If Y and Z are such that even for this restricted set of measures, applying MaxEnt to guess Ep\u00b7 [YIZ] is ill-defined, then, in our view, any specific guess of Ep\u00b7 [YIZ] obtained by a further restriction of M\ufffd is basically arbitrary. We feel that in such cases, one should refrain from using MaxEnt altogether.\n9 FINAL REMARKS\nNon-convex constraints A major goal for future work is to analyze the behavior of PJ(e in minimax terms for constraints that go beyond form (2). For inequality constraints (E[\u00a2(X)] 2: t), adjusted ver sions of all our results still hold. For constraints such that C becomes non-convex, MaxEnt is known to lead to rather strange results. Interestingly, for such con straints, Theorem 1 does not apply and the minimax PJ:le is not equal any more to the traditional max imin PJ:le. We suspect that the minimax version gives\npreferable results in such cases. Consider for exam ple disjunctive constraints (Grove et al., 1994): let Ox = {0, 1}, M uniform, and let the constraint be [P*(X = 1) = 0.1] V [P*(X = 1) = 0.95]. Then traditional MaxEnt gives PJ.:;e(X = 1) = 0.1 which seems a dangerous guess - if it is wrong, it will lead to very bad predictions. In contrast, minimax PJ:}e gives PJ:}e(X = 1) = 0.5 (one can show that it co incides with the traditional MaxEnt distribution over the convex hull of C) which -to us -seems more rea sonable.\nRelated Work (Haussler, 1997) has given a related (but still essentially different) minimax result involv ing logarithmic regret rather than loss. (Halpern & Koller, 1995) note that MaxEnt can be made repre sentation independent for a restricted class of repre sentation shifts by restricting the class of priors M in a certain way, but they do not use this to distinguish between different uses (guesses of Ep\u00b7 ['lj;] for different 'lj;) of the same PJ:le.\nAcknowledgments The author is deeply indebted to Phil Dawid, who helped in many crucial ways.\nReferences\nBerger, J. ( 1985). Statistical decision theory and Bayesian analysis. Springer Series in Statistics. New York: Springer-Verlag. revised and expanded second edition.\nCover, T., & Thomas, J. (1991). Elements of information theory. New York: Wiley Interscience.\nFriedman, N., Geiger, D., & Goldszmidt, M. (1997). Bayesian network classifiers. Machine Learning, 2g, 131- 163.\nGrove, A., Halpern, J., & Koller, D. (1994). Random worlds and maximum entropy. Journal of AI Research, 2, 33-88.\nGrunwald, P. (1998). The Minimum Description Length Principle and reasoning under uncertainty. Doctoral dissertation, University of Amsterdam, The Nether lands. Available as ILLC Dissertation Series 1998-03; see http:/ /robotics.stanford.edu;-grunwald.\nGrunwald, P., & Dawid, A. P. (2000). Robust Bayes and maximum generalised entropy. In preparation.\nHalpern, J., & Koller, D. (1995). Representation depen dence in probabilistic inference. Proceedings of the Four teenth International Joint Conference on Artificial Intel ligence (IJCAI-95}.\nHaussler, D. (1997). A general minimax result for relative entropy. IEEE Transactions on Information Theory, 43, 1276-1280.\nJaynes, E. (1989). Papers on probability, statistics and statistical physics. Kluwer Academic Publishers. Second edition.\nShore, J., & Johnson, R. (1980). Axiomatic derivation of the principle of maximum entropy and the principle of\nminimum cross-entropy. IEEE Transactions on Infor\nmation Theory, IT-26, 26-37."}], "references": [], "referenceMentions": [], "year": 2011, "abstractText": "We give an interpretation of the Maxi\u00ad mum Entropy (MaxEnt) Principle in game\u00ad theoretic terms. Based on this interpretation, we make a formal distinction between differ\u00ad ent ways of applying Maximum Entropy dis\u00ad tributions. MaxEnt has frequently been crit\u00ad icized on the grounds that it leads to highly representation dependent results. Our dis\u00ad tinction allows us to avoid this problem in many cases.", "creator": "pdftk 1.41 - www.pdftk.com"}}}