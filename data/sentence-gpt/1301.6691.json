{"id": "1301.6691", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "23-Jan-2013", "title": "Hybrid Probabilistic Programs: Algorithms and Complexity", "abstract": "Hybrid Probabilistic Programs (HPPs) are logic programs that allow the programmer to explicitly encode his knowledge of the dependencies between events being described in the program. In this paper, we classify HPPs into three classes called HPP_1,HPP_2 and HPP_r,r&gt;= 3. For these classes, we provide three types of results for HPPs. First, we develop algorithms to compute the set of all ground consequences of an HPP. Then we provide algorithms and complexity results for the problems of entailment (\"Given an HPP P and a query Q as input, is Q a logical consequence of P?\") and consistency (\"Given an HPP P as input, is P consistent?\"). Our results provide a fine characterization of when polynomial algorithms exist for the above problems, and when these problems become intractable.\n\n\nThe HPP_1 and HPP_r classes are very similar to other types of programmable programs, and the differences are significant for both cases. HPP_1 and HPP_r are not constrained to provide specific, simple (and, as such, highly technical) applications. To date, HPP_r is well understood for software that is designed to support the types of problem and the various constraints it can solve. As such, a number of systems allow the programmer to freely specify an output in order to test the problems he is dealing with. HPP_r and HPP_r are also possible to define and control the types of problems a program can solve. In this paper, we present an alternative approach for building a programmable programmable programmable programmable in a simple, but not complicated, way. For example, an HPP_r has the following requirements:\n\nSuppose you have some type of task:\nSuppose you have some type of programmable programmable programmable programmable programmable programmable programmable programmable programmable programmable programmable programmable programmable programmable programmable programmable programmable programmable programmable programmable programmable programmable programmable programmable programmable programmable programmable programmable programmable programmable programmable programmable programmable programmable programmable programmable programmable programmable programmable programmable programmable programmable programmable programmable programmable programmable programmable programmable programmable programmable programmable programmable programmable programmable programmable programmable programmable programmable programmable programmable programmable programmable programmable programmable programmable", "histories": [["v1", "Wed, 23 Jan 2013 15:57:43 GMT  (569kb)", "http://arxiv.org/abs/1301.6691v1", "Appears in Proceedings of the Fifteenth Conference on Uncertainty in Artificial Intelligence (UAI1999)"]], "COMMENTS": "Appears in Proceedings of the Fifteenth Conference on Uncertainty in Artificial Intelligence (UAI1999)", "reviews": [], "SUBJECTS": "cs.AI", "authors": ["michael i dekhtyar", "alex dekhtyar", "v s subrahmanian"], "accepted": false, "id": "1301.6691"}, "pdf": {"name": "1301.6691.pdf", "metadata": {"source": "CRF", "title": "Hybrid Probabilistic Programs: Algorithms and Complexity", "authors": ["Michael I. Dekhtyar", "Alex Dekhtyar", "V.S. Subrahmanian"], "emails": ["Michael.Dekhtyar@tversu.ru", "dekhtyar@cs.umd.edu", "vs@cs.umd.edu"], "sections": [{"heading": null, "text": "Hybrid Probabilistic Programs (HPPs) are logic programs that allow the programmer to explicitly encode his knowledge of the de pendencies between events being described in the program. In this paper, we classify HPPs into three classes called H P P1, H P P2 and H P Pr, r 2: 3. For these classes, we pro vide three types of results for HPPs. First, we develop algorithms to compute the set of all ground consequences of an HPP. Then we provide algorithms and complexity results for the problems of entailment (\"Given an HPP P and a query Q as input, is Q a logical con sequence of P?\") and consistency (\"Given an HPP Pas input, is P consistent?\"). Our re sults provide a fine characterization of when polynomial algorithms exist for the above problems, and when these problems become intractable.\n1 Introduction\nComputing the probability of a complex .event from the probability of the primitive events constituting it depends upon the dependencies (if any) known to ex ist between the events being composed. For example, consider two events e1, e2. The probability, P( e1 II e2) of the occurrence of both is events is 0 if the events are mutually exclusive. However, if the events are independent, then P(e1 II e2) = P(et) x P(e2). If we are ignorant of the relationship between these two events, then, as stated by Boole(1], the best we can say about P( e1 II e2) is that it lies in the interval [max(O, P(et) + P(e2)- 1), min(P(et), Ph)]. In short, computing the probability of a complex event depends fundamentally upon our knowledge about the dependences between the events involved. In (2] we proposed a language called Hybrid Probabilistic (Logic)\nPrograms (or HPPs, for short), that extended logic programs to deal with diverse types of probabilistic dependencies, and we defined the semantics of such a language. HPPs build upon the idea of an annotated logic program introduced in (21], and studied exten sively by many researchers over the years (6, 9, 8] In this work, we make two classes of contributions.\nFirst, we study the complexity of a variety of prob lems related to the semantics of HPPs. In particular, we show that the complexity of the entailment prob lem (answers to queries to HPPs) is polynomial for HPPs with atomic heads of rules, and in many cases for HPPs with at most two atoms in the heads. However, when formulas of size three or more are allowed in the heads of the rules, the complexity of query processing becomes NP-complete. We establish some other com plexity results for related problems, such as checking the consistency of an HPP.\nSecond, we propose a proof system HGRp for HPPs that may be used for query processing. This is a Hilbert-style proof system and it is shown to be sound and complete. We show that proofs in HGRp are polynomially bounded in size (this is consistent with the preceding NP-completeness result because the search space may involve exponentially many deriva tions each of polynomially bounded length). This is an interesting and counterintuitive result - it says that (the answers to) all queries to HPPs have at least one polynomial explanation. It is well-known (see e.g. (20]) that for propositional classical logic, an existence of proof systems with polynomially bounded length of proofs is a difficult open question, as an affirmative an swer implies that N P = coN P. In fact, for many proof systems for classic propositional logic (e.g. resolution based) and for variety of nonmonotonic logics super polynomial lower bounds were established ( (23, 20]).\nSection 2 recapitulates the syntax and semantics of HPPs as described in (2] . In Section 3, we describe results on the computation complexity of HPPs. Sec tion 4 introduces the proof system HGRp, shows it is\nHybrid Probabilistic Programs: Algorithms and Complexity 161\nsound and complete, and then presents results showing the proofs in HGRp are polynomially bounded.\n2 Background\nThe aim of this section is to describe the syntax and semantics of HPPs - the content of this section is not new and overviews results in [2]. HPPs are based on an abstract class of functions called probabilistic strate gies. Associated with each such strategy s, we can in troduce a new \"conjunction like\" connective A, and a new \"disjunction like\" connective, V,, which may then be used to define a syntax for HPPs.\n2.1 Probabilistic Strategies (p-strategies)\nIt is well-known that the probability of a compound event may be an interval, rather than a point even if point probabilities are known for the primitive events involved. This was first shown by Boole[1] in 1854. Thus, p-strategies will be defined on intervals - points, in any case, are special cases of intervals.\nDefinition 1 A probabilistic strategy (p-strategy) zs a pair of functions: p = (c, md), such that: 1. c : C[O, 1] x C[O, 1) --+ C[O, 1) is called a probabilis tic composition function if it satisfies the following axzoms: (a) Commutativity: c([a1 , h], (a2, b2]) = c([a2, b2], [a1 , bi]) (b) Associativity : c( c([a1, b1], [ a2, b2]), [a,, b,]) = c([a\ufffd, b1], c([a2, b2],[aa, ba])) (c) Monotonicity : c([a1 , bl], [a2, b2]) \ufffd c([a3, b3], [a2, b2]) if [a1 , bi] \ufffd (a3,b3] (d) Separation: there exist two functions c1 and c2 such that c([a1 , bl], [a2, b2]) = ( c1 (a1, a2), c 2(b1 , b2)) 2. md : C[O, 1] - C[O, 1] is called a maximal interval function.\nIntuitively, a composition function determines, given the probability ranges of two events, the probability range of their (either and- or or-composition). A max interval function md returns the best estimate for the probability of simple event given the probability of a compound event. For the discussion on why we specify max-interval functions as above see [2].\nThe two combinations of events we plan on deal ing with are conjunctions of events and disjunction of events. Among all possible p-strategies, we iden tify conjunctive and disjunctive p-strategies, which will handle the computation of probabilities of these two combinations respectively.\nSince composition functions are both commutative and associative, all terms constructed by applications\nof composition function c to n 2:: 2 intervals /Jl = [a1, b1], ... , /Jn = [a,., bn] will have the same value which we will denote as c(1-11 , . . , !Jn) with it's lower bound c1(a1, ... ,an) and upper bound c\n2(bJ, ... , bn)\u00b7 For technical reasons it's convenient in the case n = 1 for any 1-1 = [a, b] to set c(!J) = !J, c1(a) = a and c2(b) =b. In the definition below [a, b] ::; [c, d] means that a ::; b and c ::; d.\nDefinition 2 Conjunctive and Disjunctive p-strategies A p-strategy < c, d >is called conjunctive (disjunctive) if it satisfies the following axioms:\nAxiom Conjunctive Strateg ies Bottomhne c([a1,b,J,[a,,b,]) < [min(a1,a,),min(h,b,)] ldentrty c([a, b , [1, 1])- [a, b] Annrhrlator c([a, b , [0, OJ) - [0, OJ Max. Interval md( a, bj) - [a, lj Axiom Disjunctive Strategies E!_ottomhne [max(a1,a2),max(b1,b2)] < c([a1,b1],[a2,b,]) ldentrty c([a, b , [0, OJ) - [a, bj Annrhrlator c([a, b , [1, 1])- [1, 1] Max. Interval md( a, bj) \ufffd [0, bj\nFor a more complete discussion of the axioms we refer the reader to [2].\nExample 1 Below are some examples of p-strategies. We provide definitions of composition functions only, as max-interval functions are defined uniquely by the type of p-strategy {2].\n\u2022 inc: p-strategies for independence assumption Conjunctive: Cinc([a, b], [c, d]) = [ac, bd]. Disjunctive: Cind([a, b], [c, d]) = [a+ c- ac, b + d- bd].\n\u2022 igc: p-strategies for ignorance assumption Conjunctive: Cigc( [a, b], [c, d]) = [max(O, a+ c- 1), min(b, d)]. Disjunctive: c;9d([a, b], [c, d]) =[max( a, c), min(1, b +d)].\n\u2022 pee: p-strategies for positive correlation assump tion Conjunctive: Cpcc([a, b], [c, d]) =[min( a, c), min(b, d)]. Disjunctive: Cpcd([a, b], [c, d]) =[max( a, c), max(b, d)].\n\u2022 p-strategy for negative correlation assumption Disjunctive: Cncd([a, b], [c, d]) =[min( a+ c, 1), min(b + d, 1)]\nExample 2 We illustrate why max-interval function as defined as above on the following example. Conider conjunctive p-strategy for independence inc. Suppose\n162 Dekhtyar, Dekhtyar, and Subrahmanian\nwe know that the probability of the conjunction of two events et and e2 under the assumption of independence lies in the interval [a, b]. Our goal is to find the interval in which the probability of each of the two simple events lies. We are looking at pairs of intervals [at, bt] and [a2, b2] such that ata2 = a and btb2 = b. Clearly we are interested in minimal possible values for at and a2 and maximal possible values of bt and b2 such that the above equalities hold. It is easy to notice that both at and a2 can go as low as a while both bt and b2 can reach 1 (not together). Just set [at, bt] = [a, b] and [a2, b2] = [1, 1] or vice versa. So, 1 is the maximum number bt and b2 can reach. Now we note that in order for a product of two numbers less than or equal to 1 to be equal to a number a, neither number can be less than a. This makes a the minimum at and a2 can reach. This suggests that the probability that each of the events et and e2 holds lies between a and 1. This interval is what will be returned by the mdine function.\nAs this paper investigates complexity of some algo rithmic problems related to HPPs, we assume that all intervals are bounded by rational numbers (which may be represented for example by finite binary numbers). To make our results independent of complexity of par ticular strategies we will assume below that the com putation of a composition function for each p-strategy is provided by a constant time oracle. This way, all bounds obtained in this paper should be multiplied by the complexity of computing the composition. How ever, for composition functions computable in poly nomial time such multiplication will not result in the change in the polynomiality (deterministic or nonde terministic) of the bounds.\n2.2 Syntax of hp-programs\nLet L be a language which has predicate, variable and constant symbols, but has no function symbols. Let BL be the set of all ground atoms of L.\nIn hybrid probabilistic programs, we assume the exis tence of an arbitrary, but fixed set of conjunctive and disjunctive p-strategies S denote CONJUVISJ. The programmer may augment this set with new strategies when s/he needs new ones for their application. Each conjunctive p-strategy p has an associated conjunction operator Ap and each disjunctive p-strategy p' has an associated disjunction operator V p'. Hybrid basic formulas, defined below, are either con junctions of atoms, or disjunctions of atoms (but not mixes of both) w.r.t. a single connective.\nDefinition 3 Let p be a conjunctive p-strategy, p' be a disjunctive p-strategy and At, . . . , Ak be distinct atoms. Then At Ap ... Ap Ak and At V p' A2 . . . V p' Ak are called hybrid basic formulas. Suppose b fp(BL) de-\nnotes the set of all ground hybrid basic formulas for the V P and Ap connectives. Let b fs (BL) = Upesb fp(BL).\nWe define a notion of annotations inductively as fol lows: (1) Any real number or variable over real num bers is an annotation term. (2) If f is an interpreted function over the reals of arity k and it, . . . , tk are annotation terms, then f (tt, . . . , tk ) is an annotation term. An annotation is pair [att, at2] where att, at2 are annotation terms. Thus, for instance, [0.5, 0.6], [0 .. 5, vfl] are both annotations.\nDefinition 4 A hybrid probabilistic annotated basic formula (hp-annotated basic formula) is an expres sion of the form B : J.l where B is a hybrid basic for mula and J.l is an annotation.\nDefinition 5 Let Bo, Bt, ... , Bk be hybrid basic for mulas. Let J.lo, J.lt , ... , J.lk he annotations. A hybrid probabilistic clause {hp-clause J is a construction of the form: Bo : J.lo <- Bt : J.lt A . . . A Bk : J.lk.\nInformally speaking, the above rule is read: \"If the probability of Bt falls in the interval J.lt and \u00b7 \u00b7 \u00b7 the probability of Bk falls within the interval J.lk, then the probability of Bo falls within the interval J.lo\u00b7 Note that it is entirely possible that B; uses a connective lip corresponding to a particular (conjunctive) p-strategy, while Bj may use a connective V P' corresponding to some other disjunctive p-strategy. HPPs allow mixing and matching of different kinds of p-strategies, both in the B; 's in the body of a rule, as well as in Bo - the head of a rule.\nDefinition 6 A hybrid probabilistic program {hp program ) over set S of p-strategies is a finite set of hp-clauses involving only connectives from S.\nAn hp-program is ground iff its every clause is ground, i.e. all its clauses do not contain neither variables nor variable annotations.\nFor example, consider an image processing application that contains a set of facts stating who was seen with whom. These facts may be extracted by an image pro cessing program which may identify persons in images with associated probabilities. A higher level program then classifies individuals as suspects based on differ ent criteria. Such an application may be encoded as an hp-program containing rules such as those shown below.\nseen(picl,idljohn) : [0.5,0.7] seen(picl,idl,ed): [0.2, 0.4] .... seen(picl,id2,ed): (0.5, 0.6] .... seen(picl,id2,dan): [0.2, 0.5] suspectl(Jr): [I, I] ....\nseen(Pic,ldl, )() : [0.5, 1] 1\\ seen(Pic,Jd2,ed) : [0.5, I] 1\\ ldi -j. ld2.\nHybrid Probabilistic Programs: Algorithms and Complexity 163\nsuspect2(X): [1, 1] - (seen(Pic,Id1,X) 1\\;g seen(Pic,Id2,ed)): [0.5, 1].\nsuspect3(X): [1, 1] - (seen(Pic,Id1,X) 1\\;n seen(Pic,Id2,ed)): [0.5, 1]. In the above example, we have two pictures, each of which contains two objects. Picture pic1 's object with id2 is identified as Ed with 50-60% probability and Dan with 20-50% probability. Three alternative defi nitions of suspect are given. The first says that if X occurs (with over 50% probability) in a picture where Ed also appears (with over 50% probability), then X is considered a suspect. By this rule, John is a suspect. The second rule says that if we know nothing about the occurrences of people in a picture and if the probabil ity that Ed and X are both in the picture is over 50% under this assumption, then X is considered a suspect. According to this rule, there are no suspects at all. A third possibility is that X be considered a suspect if we assume that people's appearances in pictures are independent of one another, and under this assump tion, Ed and X are both in the picture with over 50% probability. This rule yields no suspects either.\n2.3 Fixpoint and Model Theory for hp-programs\nIn this subsection, we briefly describe the model theory underlying HPPs. [2] contains a more comprehensive description. Before proceeding further we first intro duce some notation for \"splitting\" a complex formula into two parts.\nDefinition 7 Let F = F1 *P .. \u00b7 *p Fn, G = G1 *P .. \u00b7*p Gk (k > 0), H = H1 *P ... *P Hm (m > 0) where * E {/\\, V}. We will write G $p H = F (or G EB H if the p-strategy p is irrelevant) iff: {a) {G!, . .. , Gk}U{Hl, ... ,Hm} = {F1, . . . , Fn} and {b) {G1, . .. , Gk} n {H1, . .. , Hm} = 0.\nThe analog of an Herbrand interpretatio_n in classical logic programs is what we call a hybrid formula func tion.\nDefinition 8 A function h : bfs(BL) --+ C[O, 1], is called a hybrid formula function iff it satisfies the fol lowing three conditions: 1. Commutativity. If F = G1 El7p G2 then h(F) h(Gl *P G2)\u00b7 2. Composition. If F = G1 El7p G2 then h(F) C cp(h(Gl), h(G2)). 3. Decomposition. For any basic formula F , h(F) \ufffd mdp(h(F *P G)) for all pES and G E bfs(B\u00a3).\nFrom the first condition it follows that h( F) = h( F') for any F and F' which are permutations of one an other. Second condition states that the probability of a c0mplex formula is bounded by the probabilities of its\nsubformulas. Conversely, the third condition bounds the probability of a subformula by the probability of a formula it is a part of. We say that hybrid four mula function g is less than or equal to hybrid formula function h, denoted g::; h iff (VF E bfs(BL))(g(F) 2 h(F)).\nWe are now in a position to specify what it means for a hybrid basic formula function to satisfy a formula.\nDefinition 9 Satisfaction. Let h be a hybrid basic formula function, F E bfs(BL), J1. E C [O, 1]. We say that\n\u2022 h f= F: J1. iff h(F) \ufffd Jl.\u00b7\n\u2022 h f= F1 : Jl.l i\\ .. . i\\ Fn : Jl.n iff (V 1 ::; j ::; n )h F Fj: Jl.i\u00b7\n\u2022 h f= F : J1. <-- F1 : Jl.l i\\ . . . i\\ Fn : Jl.n iff either h f= F : J1. or h p!: F1 : Jl.l i\\ . . . i\\ Fn : Jl.n\u00b7\n\u2022 h f= (3x)(F : p.) iff h f= F(tfx) : J1. for some ground term t .\n\u2022 h f= (Vx)(F : p.) iff h f= F(tfx) : J1. for every ground term t.\nA formula function h is called a model of an hp program P (h f= P ) iff (h f= C) for all clauses C E P.\nAs usual, we say that F : J1. is a consequence of P iff for every model h of P, it is the case that h( F) \ufffd p.. It is possible for a hybrid formula function h to assign 0 to some formula. W hen h(F) = 0, h is \"saying\" that F's probability lies in the empty set. This corresponds to an inconsistency because, by definition, nothing is in the empty set.\nDefinition 10 Formula function h is called fully de fined iff'V(F E bfs(BL))(h(F) f. 0).\nNow we introduce the fixpoint semantics for the hp programs. Operator S p is a preliminary operator, re stricted only to the clauses which have the same head as the argument. It is then extended to full fixpoint operator Tp\nDefinition 11 Let P be a hybrid probabilistic program. Operator Sp : 'H.:F:F --+ 'H.:F:F is defined as follows (where F is a basic formula): Sp(h)(F) = nM where M = {1-l<TIF: 1-L<-- F1: Jl.l i\\ . . . i\\Fn: Jl.n is a ground instance of some clause in P ; <T is a ground substitution of annotation variables and (Vj ::; n)h(Fj) \ufffd Jl.j<T} if M = 0 Sp(h)(F) = [0, 1].\nWe use the definition of Sp to define the immediate consequence operator Tp.\n164 Dekhtyar, Dekhtyar, and Subrahmanian\nDefinition 12 Let P be a hybrid probabilistic program. We inductively define operator Tp : 'H.:F:F --+ 'H.:F:F as follows:\n1. Let F be an atomic formula. *if Sp(h)(F) = 0 then Tp(h)(F) = 0. *if Sp(h)(F) =f. 0, then let M = {(JLu,p)I(F Etlp G): JL ,__ F1 : JL! /\\ . . . /\\ Fn : JLn where lT is a ground substitution for the annotation varables and i E S and (Vj \ufffd n)h(Fj) \ufffd JLj<T}. We define Tp(h)(F) = (n {mdp(JLu)I(JLcr, i) EM}) n Sp(h)(F). 2. (F not atomic) Let F = F1 *P . \u2022 . *P Fn. Let M' = {(JLcr,p)IDl *P . . . *P Do : JL +-- E1 JL! /\\ . . . Em : JLm E ground(P); (Ill \ufffd j \ufffd m)h(Ei) \ufffd JLi; {Ft, ... ,F,.} c {D1, . . . Dk}, n < k} Then:\nTp(h)(F) = Sp(h)(F) n (n {cp(Tp(h)(G), Tp(h)(H))i\nGEBp H = F}) n (n {mdp(JLu)I(JLu,i) EM'})\nIn (2] it was shown that both Sp and Tp are monotonic if the annotations of the atoms in P are constant.\nDefinition 13 1. T$ = h1. where .l is the atomic function that assigns [0, 1] to all ground atoms A. 2. Tf5 = Tp (TJ;-1) where a is a successor ordinal whose predecessor is denoted by a - 1. 3. TJ, = U{Tftla < ;}, where; is limit ordinal.\nThe following results (2] ties together, the fixpoint the ory and the model theoretical characterizations of hp programs, regardless of which p-strategies occur in the hp-program being considered.\nTheorem 1 Let P be any hp-program. Then: 1. h is a model of P iff Tp(h) \ufffd h . 2. P has a model iff lfp(Tp) is fully defined. 3. If l f p(Tp) is fully defined, then it is the least model of P, and F : JL is a logical consequence of P iff l fp(Tp) \ufffd JL.\nIn what follows we will consider only ground hp programs. It is clear that for any such program P, the least fixpoint of its Tp operator, l f p(Tp) is achieved in a finite number of iterations, i.e., at least, l fp(Tp) = Tt. For brevity we will denote lfp(Tp) as hp.\n3 Algorithms and Complexity of ground HPPs\nIn this section, we will develop algorithms, and as sociated complexity results, for three kinds of HPP problems: logical consequences of an HPP P, entail ment problem (answer to query) , and consistency of P. Obviously, these three problems are closely related\nto one another. Due to space restrictions we are able to present only the algorithms and state the theorems here. All proofs and reductions can be found in (3].\n3.1 Complexity of model computation\nGiven a basic formula G, we define the width( G) to be the number of atoms in G. Given an hp-clause C = Bo : JLo - B1 : JL! /\\ ... /\\ Bk : J.lk, we say that the head-width of C is the width of Bo, and the body-width of C is max { width(B!), ... , width(B0)}.\nWe may now define a hierarchy of subclasses of HPPs in terms of the head/body widths of the clauses in volved.\nDefinition 14 Let H P Po,r denote the class of HPP programs P such that for all clauses C E P, the head width of C is less than or equal to k and the body width of C is less than or equal to r. Let H P P0 = Ur;::oHPPk,r\u00b7\nAlgorithm LFP below shows how we may compute the least fixpoint of Tp for class H P Pk,r\u00b7 Algorithm LFP. Input: P E H P Pk,ro N \ufffd max(k, r), m - number of clauses in P, F1 , ... F M - all formulas of width :::; N, lexicographically ordered. Output: table hm(Fk), 1 :5 k :5 M. BEGIN (algorithm)\n(I) FOR j = I TOM DO to(Fi) := [0, I]; (2) FOR i = 0 TO 2m- 1 DO\nBEGIN\n(3) FOR EACH C = G : p ,_ G, : PI II ... II Gn : /JI E P such that for all 1 ::5 j ::5 n to(GJ) \ufffd /Jj DO\nBEGIN\nto+ I (G):= to(G) n p; (4) (5) (6) delete C from P;\nG= H$p H1\n(7) END\nFOR EACH H included m G, DO\nto+ I ( H):= to(H) n mdp (p);\n(8) FOR j = 1 TO M DO (9) FOR k = j + 1 TO M DO (IO) IF Fk = Fj $p Ft (for some I< k)\n1.e.\n(11) THEN to+!(Fk) .- to+!(Fk) n c; ( t;+l ( Fj ), t;+l ( Fr) );\nEND\nEND.\nThe following theorem proves that algorithm LFP is a correct way of computing the least fixpoint of Tp for class H P Pk,r and establishes its complexity.\nTheorem 2 Let P be any program in H P Po,r with m clauses. Let a be the number of different atoms in P, s be the number of different strategies in P, and\nHybrid Probabilistic Programs: Algorithms and Complexity 165\nN \ufffd max{k, r}. Then Algorithm LFP computes hp on all the formulas of b fs(BL) of width :5 N in time 0(2m(2saN)2) = O(m(saN)2).\nThe proof of this result is long and complex, and uses the properties that (i) if a program P consists of m ground clauses, then Tj,m = l fp(Tp) and that (ii) for every i = 0, 1, .. . , 2m and for every k = 1, . .. M, the quantity t; ( Fk) in \u00b7algorithm LFP coincides with Tj,(Fk) and therefore t2m(Fk) = hp(Fk)\u00b7 It is important to note that this theorem tells us that computing the least fixpoint of an HPP is exponen tial in the width of the largest formula of interest. In other words, if we were to develop an implementation of HPPs, and we required that no basic formulas of length greater than 6 for some fixed 6 are allowed, then the above theorem yields a polynomial result. This is a reasonable assumption, as we do not expect that for mulas of width greater than some small constant (e.g., 4) would be of interest in any practical application. This is stated in the following corollary.\nCorollary 1 Let P be any hp-program, and suppose 6 is a fixed bound on the width of basic formulas oc curring in P. Then hp can be computed in polynomial time of size of P for all formulas of width \ufffd 6.\n3.2 Complexity of Entailment\nWhile it is important to know the complexity of com puting the entire model of an HPP, it is really the entailment problem which gets solved over and over when queries are asked to the program. In this section we will consider the complexity of entailment problem on HPPs: given a consistent program P and a query F : J.l, check whether P f= F : J.l\u00b7 As usual we fix some standard encoding which is used to represent programs and queries. If P is an HPP, IPI will denote the size of the representation of P in this encoding, and similarly, if F : J.l is an annotated basic formula, IF : J.LI will denote the size of its repre sentation. The complexity results in the sections that follow will be relative to IPI and IF: J.LI\u00b7\nIn order to carry out our analysis of the entailment problem, we will split the results into three parts based on the syntax of HPPs.\nAt first, we show that if we consider the class H P P1 containing only atoms in rule heads, then we can spe cialize algorithm LFP to a better algorithm, LFP1 for computing the least fixpoint of Tp.\nAlgorithm LFP1. Input: P E H P P1, m- number of clauses in P, F,, . . . ,FM - lexicographical enumeration of all formulas in P, F = A1 *p . . . *pAn, A; E BL,i E {1, ... ,n}. Output: p,' - a subinterval of {0, 1)\nBEGIN (1) FOR j = 1 TOM DO t(F;) := {0; 1]; (2) FOR i = 0 TO 2m- 1 DO\nBEGIN (3) FOR EVERY C = G: p, .__ G1 : p,,, ... ,G, /JI E P such that t(G1) <;; !Ji for alii :5 j :5 I DO\nBEGIN\n(4) t(G) := t(G) n p,; (5) delete C from P\nEND (6) FOR k = 1 TO M DO (7) IF Fk = B, *P ... *P Br, r > 0, B1 is an atom for all :Sj:Sr (8) THEN t(Fk) := Cp(t(B!), ... , t(Br)); END;\n(9) p,' := Cp(t(A!), ... , t(An)) END. (algorithm)\nThe following result specifies that the above algorithm may be directly used to check if an annotated basic formula F : J.l is entailed by an HPP P E H P Pt. Find the value J.l1 returned by Algorithm LFPt - if J.l1 \ufffd J.l, then P f= F : J.l, else it does not.\nTheorem 3 For any program P E H P P1 and an notated basic formula F : J.l the entailment problem \"P f= F : J.l\" is solvable in time O(IP I 2 +IF : J.Lil via Algorithm LFP1.\nOur next goal is to develop algorithms and provide complexity results for checking entailment when we consider hybrid probabilistic programs for H P Pr when r \ufffd 3. We start our analysis by first considering the class H P P0 of HPPs that only consist of facts, i.e. all rules in such HPPs have an empty body.\nThe following nondeterministic algorithm allows check entailment for hybrid probabilistic programs in this class.\nAlgorithm Ent-HPP0\nInput: program P E \u00b7 H P P0, consisting of m clauses C,, ... , Cm with empty bodies: C k = Hk : [ak, bk], k = 1, ... , m, formula F = B1 *P ... *P Bn, and an interval [a, b]. 1. Guess such k :5 width( F), sequence of bounds x,, ... ,Xk and partition F = F1 *P ... *P Fk which satisfy conditions: ( i) each F; is either some head Hk and x; ;::: bk, or it is a subformula of some head Hk = F; ffip H\ufffd and mdp({ak, bk]) <;; [0, x; ], and (ii) c\ufffd(X!, ... ,Xk) :5 b. 2. Guess such k :5 width( F), sequence of bounds x,, ... ,Xk and partition F = F1 *P ... *P Fk which satisfy conditions: (i) each F; is either some head Hk and x; :5 ak, or a sub formula of some head Hk = F; ffip H\ufffd and mdp({ak, bk]) <;; [x;, 1], and (ii) c\ufffd(x,, ... ,xk);::: a. 3. If both attempts are successful then output \"Yes\".\n166 Dekhtyar, Dekhtyar, and Subrahmanian\nThe following lemma establishes correctness of Algo rithm Ent-HPP0 and its complexity.\nLemma 1 {1) For any consistent hp-program P E H P P0 and any query F : (a, b] algorithm Ent-H P P0 output \"Yes\" iff P f= F: (a, b]. (2) Algorithm Ent-H P P0 works in nondeterministic polynomial time.\nLet us denote by F iredp(i) the set of those clauses of P whose bodies are satisfied by Tj, but are not satisfied . 1 by rp- . We are now ready to present a generic algorithm, Algo rithm Ent-HPP, that computes entailment by HPPs. Algorithm Ent-HPP Input: program P E HPP, consisting of m clauses C,, ... , C,. of the form C1 = H1 : J.li - Ff : \"' 1\\ ... /\\ F/.i' formula F = B, *P ... *P Bn, and an interval [a, b].\n(1) Po:= {Hi: J.lilbody of C1 is empty}; (2) FOR i = 1 TO 2m DO (3) guess Fired(i); (4) FOR EACH C1 E Firedp(i) DO (5) FOR I= 1 TO ri DO (6) Call Ent-H P p0(P;, Ff : vz); (7) END_DO (8) END.l)O (9) P; := p,_, u {H1: p1IC1 E Fired(i)} (10) END_DO (11) Call Ent-HPP0(P2,.,F: [a,b]) (12) Output \"Yes\" if all (nondeterministic) calls of Ent H P P0 were successful. The following result establishes that algorithm Ent HPP correctly computes entailment in nondetermin istic polynomial time.\nLemma 2 Algorithm Ent-HPP determines nonde terministically if P f= F : (a, b] in polynomial time.\nThis result provides an upper bound in the following claim.\nTheorem 4 The entailment problem is NP-complete for the classes H P P and H P Pk,r(k \ufffd 3).\nThe proof of NP-hardness can be obtained, by reduc ing a well-known NP-complete problem 3-Dimensional Matching to the entailment problem for the class HPP3,o\u00b7\nSo far we have have shown that entailment problem is polynomial for hp-programs in H P P, and is NP complete for hp-programs in H P Pk, k \ufffd 3. We now turn our attention to H P P2. Here, our results are most interesting - it will turn out that for many dif ferent types of p-strategies, the entailment problem is polynomially solvable, though this does not appear to be the case for all p-strategies.\nRecall that given a graph G = (V, E) , a matching[13] is a set E' \ufffd E such that no two edges in E' share a common vertex. A matching E' is maximal iff every edge in (E- E') shares a vertex with some edge in E'. If V = 2m, we say a matching E is complete iff every vertex v E V is the endpoint of some edge ev E E'. It will turn out that entailment is polynomial time equivalent to the following generalized matching problem on general graphs.\nGeneralized weighted matching problem\nGiven an edge-weighted, undirected graph G = (V, E, w) and a goal weight combination function c, find a complete matching for which the goal function on weights of selected edges is maximized {minimized).\nMore formally, we define two classes of \"yes-no\" matching problems: GWMma,(c) = {G = (V,E,w: E-+ (O,l]),B E (0, lJIIVI =2m} and there exists a complete matching {e1, ... , em} \ufffd E such that c(w(et), ... , w(em)) \ufffd B} and GWMmin(c) = {G = (V,E,w : E-+ (O,l]),B E (0, lJIIV I =2m} and there exists a complete matching {e1, ... , em} \ufffd E sucil that c(w(et), ... , w(em)) :S B}. The following result shows that entailment in HPPs is polynomial-time equivalent to the above generalized matching problems.\nTheorem 5 {1} Let P E H P P2 use probabilistic strategies with combination functions c = (c1, c2) where c1 E C1, c2 E C2 for some sets of functions C1 and C2. Then the entailment problem for P and annotated basic for mula F : J.l is polynomially reducible to the problems GW Mma\" ( c1) and GW Mmin ( c2) , where c1 E C1, c2 E c2. {2) Any generalized weighted matching problem for goal functions, satisfying axioms (a)-( d) of Definition 1 , is reducible in polynomial time to entailment prob lems for hp-programs of H P P2,0\u00b7\nIt is well-known (13] that weighted matching problem is solvable in polynomial time for the sum of edges weights. This allows to get effective algorithms for almost all of strategies considered in (2].\nCorollary 2 The entailment problem for the class of H P P2 programs over strategies S = {inc, igc, pee, igd, pcd, ned} is solvable in polynomial time.\nThe above result is interesting because it provides polynomial results for programs in H P P2 for all but one composition strategies studied in (2]. This leads to an interesting open question.\nOpen question. Is there polynomial time com putable composition function c = ( c1, c2) satisfying\nHybrid Probabilistic Programs: Algorithms and Complexity 167\naxioms (a)-(d) for which generalized matching prob lem GWMmin(c2) (GWMmax(c1)) is NP-complete?\n3.3 Complexity of the Consistency Problem\nIn this subsection, we establish the complexity of de termining if an HPP is consistent, i.e. is there a hybrid formula function h that satisfies all rules in P?\nIt is easy to see that even a simple H P P1 program containing two simple facts, viz. a : [0, 0], a : [1, 1], is inconsistent. The complicated interactions between logic and probabilities can engender more devious in consistencies in HPPs.\nThe following result tells us that to check if P is consis tent, if our language allows n ground atoms, we need to create only all ground basic formulas F containing all the n atoms and check if hp(F) =f. 0 for them. If so, P is guaranteed to be consistent.\nLemma 3 Let P E H PP over setS = {p1, ... , pm} of p-strategies and let A = {A1, . . . , An} be all the atoms found in P. Then P is consistent iff for all formulas F; of form F; = A1*p\u2022\u00b7. \u00b7*p, An, i = 1, ... , m, hp(F;) =f. 0.\nAs in the case of the Entailment Problem, we summa rize our results in three cases - where programs are from H P P1, from H P P2 and from H P Pa or larger.\nTheorem 6 {1) Given a program P E H P P1 its consistency can be established in polynomial time. {2} Inconsistency problem for H P P2 is polynomi ally reducible to GW Mrnin and GW Mmax\u00b7 So, for H P P2 programs over the set of p-strategies {inc, igc, pee, igd, pcd, ned} the consistency problem is solvable in polynomial time. {3) Consistency problem for HPP is co-J'!\"P-complete.\nWe present here only the nondeterministic algorithm lnCon which checks if an arbitrary HPP is inconsis tent.\nAlgorithm InCon. Input. An arbitrary HPP P. 1. Guess the shortest \"inconsistent\" formula F. 2. Guess two partitions ofF into G1 *P ... *pGm and H1 *P ... *P H\ufffdc two sets of numbers: x1, ... , Xm and YI, ... , Yk, 0 :5 x;,yi :S 1 such that c\ufffd(xJ, ... ,xm) > c!(Y!, \u00b7\u00b7\u00b7Yk) . 3. Using Algorithm Ent-HPP check that for all i E {1, ... m} PI= G;: [O,x;] and all j E {1, ... k} PI= H1: [y,' 1]. 4. If all calls to Algorithm Ent-HPP of previous step are successful then output \"Yes\".\n4 Proof Procedure\nIn this section, we present a sound and complete proof procedure for HPPs. The first proof procedure for probabilistic programs, introduced in [2] and [17] is based upon expanding the program P to a larger set of clauses (a closure of the program) and then re solving queries against that set. Since this procedure is computationally inefficient, other tabulation based proof procedures have also been developed. Here, we present a Hilbert-style proof system for ground hp programs which guarantees that all proofs are polyno mially bounded in length ! This is an interesting and counterintuitive result - it says that (the answers to) all queries to HPPs have at least one polynomial ex planation. Let us now define the axioms and inference rules of the proof system HGRp.\nDefinition 15 Let P be a ground hp-program over set S of p-strategies. We define the formal system HGRp as follows: 1. Axioms of HGRp are all expressions of the form: A:[0,1]' where A E B\u00a3. 2. Inference Rules. There are 7 types of inference rule schemas in HGRp. One type {Program) depends on the clauses of program P while other 6 types of inference rule schemas are independent of clauses in P but do depend on which p-strategies are in S. \u2022 Program: Let F : 1J - G1 : 1'1, ... , Gk : /Jk E P,\nG1 : /J! ... Gk : /Jk F: IJ\nNote: rules corresponding to clauses with empty body ( k = 0) are actually axioms. \u2022 A-Composition: Let A1,A2 E BL ,pES\nAI : /Jl A2 : /J2 (A! *pA2): Cp(/J!,/J2)\n\u2022 F-Composition:A1, ... Ak, B1 ... Bk E BL,P E S\n(AI *P ... *P Ak) : /Jl ( B! *p ... *P Bl): /J2 (A1 *P ... *P Ak *i> B1 *P ... *P B1): cp(/Jl, /J2)\n\u2022 Decomposition (cut): Let pES\n\u2022 Clarification: F :f.IF n F :fl2\n:J.Ll J.l2\n(FEBpG):J.L F:mdp(J.L)\n\u2022 Exchange: Let A1, ... ,Ak E BL, p E S, and let B1, ... , Bk be a permutation of A1, ... , Ak\n(A! *P ... *P Ak): IJ ( B! *P ... *P Bk): IJ\nal w. ak . F:fl f1Cf11 \u2022 Interv e enmg: F:J.L! 3. A finite sequence C1 ... C, of annotated formu las is called an HGRp-derivation iff each formula c1 = Fj : J.li can be deduced from zero {in the case of\n168 Dekhtyar, Dekhtyar, and Subrahmanian\naxiom), one, or more previous of C1 ... Cj -1 by apply ing one of the inference rules to them. We call formula Cr the result of the HGRp-derivation. 4. An annotated formula C = F : JJ is derivable in HGRp iff there exists such an HGRp-derivation cl, .. . Cr that Cr = c. We denote it by p 1-HGRp C, or just by P f- C in the absence of other inference systems.\nTheorem 7 (soundness of HGRp) Let P be an hp - program and let Q be a an hp-formula. If P f-sGRp Q, then PI= Q.\nIt is known that all \"natural\" proof systems for stan dard classical propositional logic have proofs of expo nential size (see e.g. [23]). But this is not the fact in our proof system HGRp. The following result states that HGRp is both a complete inference system and that the length of the proofs in HGRp is polynomially bounded.\nTheorem 8 For any P E H P P and annotated for mula F : JJ if P f- F : JJ then there exists such an HGRp-derivation C1, ... Cr that Cr = F : JJ and r :S O(IPI2 +IF : JJI) .\n5 Conclusions\nAs described in the introduction, there are numerous kinds of dependencies that might exist between un certain events. Probability theory mandates that the probability of a complex event be computed not only in terms of the probabilities of the primitive events in volved, but also it should take into account, dependen cies between the events involved. Hybrid Probabilistic Programs (HPPs) [2] represent one of the first frame works that allow a logic program to explicitly encode a variety of different probability assumptions explicitly into the program, for use in inferencing. Most exist ing frameworks for uncertainty in logic prqgramming [4, 5, 8, 9, 12, 14, 15, 17, 19, 21, 7] do not permit this. A few important initial attempts to incorporate different probabilistic strategies were made by Thone et al.[22], and Lakshmanan [12], which culminated in an extension of the relational algebra that accommo dated different probabilistic strategies [10]. In this paper. we have made three contributions. First, we have developed algorithms to efficiently perform a vari ety of computations for hybrid probabilistic programs. Each of these algorithms is \"tuned\" to fit the class within which an HPP falls (i.e. class H P P1, H P P2 or H P Pro r 2: 3). We have given algorithmic com plexity analyses of these problems. To date, with the exception of the work by Kiessling's group [7, 22] and by Lukasiewicz [15], almost no work on bottom up al gorithms for computing probabilistic logic programs\nexists. Our algorithms are the first to apply not only to HPPs, but to have finer complexity bounds for dif ferent classes of HPPs.\nSecond, we have studied the computational complexity of the Entailment and Consistency problems for the abovementioned classes of HPPs. The results may be neatly summarized via the following table.\nIn effect, this result says that from the point of view of complexity, it is possible to safely write HPPs over class H P P1 (with any set of composition strategies), or over class H P P2 (but with certain composition strate gies only), and be guaranteed a polynomial compu tation. To our knowledge, this paper is the first pa per to contain a detailed analysis of complexity results in probabilistic logic programs, though [10] contains some results for probabilistic relational algebra, and [12] contains some results for a different probabilistic framework.\nFinally, we have described a proof system for HPPs that guarantees that for every F : JJ that is a ground logical consequence of an HPP P, we have a polyno mially bounded proof of F : JJ, which in turn, means that an explanation for F : JJ is polynomially bounded. Though many proof systems have been developed for annotated logic programs they do not apply to prob abilistic logic programs. Our proof system HGRp is new (and is also different from the proof system in [2]), and to our knowledge none of the existing proof systems for annotated logic have been shown to have polynomially bounded proofs (and hence succinct ex planations).\nAcknowledgements.\nThe work of the first author had been partially supported by Russian Fundamental Studies Foun dation (Grants 97-01-00973). The other authors were supported by the Army Research Office un der Grants DAAH-04-95-10174, DAAH-04-96-10297, and DAAH04-96-1-0398, by the Army Research Lab oratory under contract number DAAL01-97-K0135 and under Cooperative Agreement DAALOl-96-2-0002 Federated Laboratory ATIRP Consortium, by an NSF Young Investigator award IRI-93-57756, and by a\n-;\nHybrid Probabilistic Programs: Algorithms and Complexity 169\nTASC/DARPA grant J09301S98061.\nReferences\n[1] G. Boole. (1854) The Laws of Thought, Macmil lan, London.\n[2] A. Dekhtyar and V.S. Subrahmanian. (1997) Hybrid Probabilistic Logic Programs, accepted to Journal of Logic Programming, Jan. 1998, preliminary version available as University of Maryland Tech Report CS-TR-3883, from http:/ jwww.cs.umd.edu/TRsjauthorsj Alex_Dekhtyar.html.\n[3] M. Dekhtyar, A. Dekhtyar and V.S. Subrahma nian. (1997) Hybrid Probabilistic Programs: Al gorithms and Complexity, submitted to Theoret ical Computer Science, Available as University of Maryland Tech Report CS-TR-3969.\n(4] D. Dubois and H. Prade. Certainty and Un certainty of Vague Knowledge and Generalized Dependencies in Fuzzy Databases. In Proceed ings International Fuzzy Engineering Sympo sium, pp. 239-249, Yokohama, Japan, 1988.\n[5] R. Fagin and J. Halpern. (1988) Uncertainty, Belief and Probability, in Proc. IJCAI-89, Mor gan Kaufman.\n[6] L.J. Henschen and J. Lu. (1992) The Complete ness of GP-resolution for Annotated Logics, In formation Processing Letters, 44, 1992, 135-140.\n(7] W. Kiessling, H. Thone and U. Guntzer. (1992) Database Support for Problematic Knowledge, Proc. EDBT-92, pps 421-436, Springer LNCS Vol. 580.\n[8] M. Kifer and A. Li. (1988) On the. Semantics of Rule-Based Expert Systems with Uncertainty, 2- nd Inti. Conf. on Database Theory, Springer Ver lag LNCS 326, (eds. M. Gyssens, J. Paredaens, D. Van Gucht), Bruges, Belgium, pp. 102-117.\n[9] M. Kifer and V. S. Subrahmanian. (1992) The ory of Generalized Annotated Logic Program ming and its Applications, JouRNAL OF Lome PROGRAMMING, 12, 4, pps 335-368, 1992.\n[10] V.S. Lakshmanan, N. Leone, R. Ross and V.S. Subrahmanian. ProbView: A Flexible Proba bilistic Database System. ACM TRANSACTIONS ON DATABASE SYSTEMS, Vol. 22, Nr. 3, pps 419- 469, Sep. 1997.\n(11] V.S. Lakshmanan and F. Sadri. (1994) Modeling Uncertainty in Deductive Databases, Proc. Int. Conf. on Database Expert Systems and Applica tions, (DEXA'94), September 7-9, 1994, Athens, Greece, Lecture Notes in Computer Science, Vol. 856, Springer (1994), pp. 724-733.\n[12] V.S. Lakshmanan and F. Sadri. (1994) Prob abilistic Deductive Databases, Proc. Int. Logic Programming Symp., (ILPS'94), November 1994, Ithaca, NY, MIT Press.\n[13] E. Lowler. Combinatorial Optimization: Net works and Matroids, Holt, Reinhart & Winston, New York, 1976.\n[14] T. Lukasiewicz. (1998) Probabilistic Logic Pro gramming, in Procs. 13th biennial European Conference on Artificial Intelligence, pps 388- 392, Brighton, UK, August 1998.\n(15] T. Lukasiewicz. (1998) Magic Inference Rules for Probabilistic Deduction under Taxonomic Knowledge, Proceedings of the 14th Conference on Uncertainty in Artificial Intelligence, pps 354- 361, Madison, Wisconsin, USA, July 1998.\n[16] J .W. Lloyd. (1987) Foundations of Logic Pro gramming, Springer.\n[17] R. Ng and V.S. Subrahmanian. (1993) Proba bilistic Logic Programming, INFORMATION AND CoMPUTATION, 101, 2, pps 150-201, 1993.\n(18] R. Ng and V.S. Subrahmanian. (1995) Stable Se mantics for Probabilistic Deductive Databases, INFORMATION AND COMPUTATION, 110, 1, pps 42-83.\n[19] N. Nilsson. (1986) Probabilistic Logic, Artificial Intelligence, 28, pp 71-87.\n(20] P. Pudlak. The lengths of proofs, Handbook of proof theory; Stud. Logic Found. Math.,127, North-Holland, Amsterdam, pps. 547-637, 1998.\n[21] V.S. Subrahmanian. (1987) On the Semantics of Quantitative Logic Programs, Proc. 4th IEEE Symp. on Logic Programming, pps 173-182, Computer Society Press. Sep. 1987.\n[22] H. Thone, W. Kiessling and U. Guntzer. (1995) On Cautious Probabilistic Inference and Default Detachment, Annals of Operations Research, 55, pps 195-224.\n[23] A. Urquhart. The Complexity of Propositional Proofs, The Bulletin of Symbolic Logic, 1(4):425- 467, December 1995."}], "references": [{"title": "Hybrid Probabilistic Logic Programs, accepted to Journal of Logic Programming, Jan. 1998, preliminary version available as University of Maryland Tech Report CS-TR-3883, from http:/  jwww.cs.umd.edu/TRsjauthorsj Alex_Dekhtyar.html", "author": ["A. Dekhtyar", "V.S. Subrahmanian"], "venue": null, "citeRegEx": "2", "shortCiteRegEx": "2", "year": 1997}], "referenceMentions": [{"referenceID": 0, "context": "The aim of this section is to describe the syntax and semantics of HPPs - the content of this section is not new and overviews results in [2].", "startOffset": 138, "endOffset": 141}, {"referenceID": 0, "context": "For the discussion on why we specify max-interval functions as above see [2].", "startOffset": 73, "endOffset": 76}, {"referenceID": 0, "context": "For a more complete discussion of the axioms we refer the reader to [2].", "startOffset": 68, "endOffset": 71}, {"referenceID": 0, "context": "[2] contains a more comprehensive description.", "startOffset": 0, "endOffset": 3}, {"referenceID": 0, "context": "The first proof procedure for probabilistic programs, introduced in [2] and [17] is based upon expanding the program P to a larger set of clauses (a closure of the program) and then re\u00ad solving queries against that set.", "startOffset": 68, "endOffset": 71}, {"referenceID": 0, "context": "Hybrid Probabilistic Programs (HPPs) [2] represent one of the first frame\u00ad works that allow a logic program to explicitly encode a variety of different probability assumptions explicitly into the program, for use in inferencing.", "startOffset": 37, "endOffset": 40}, {"referenceID": 0, "context": "Our proof system HGRp is new (and is also different from the proof system in [2]), and to our knowledge none of the existing proof systems for annotated logic have been shown to have polynomially bounded proofs (and hence succinct ex\u00ad planations).", "startOffset": 77, "endOffset": 80}], "year": 2011, "abstractText": "Hybrid Probabilistic Programs (HPPs) are logic programs that allow the programmer to explicitly encode his knowledge of the de\u00ad pendencies between events being described in the program. In this paper, we classify HPPs into three classes called H P P1, H P P2 and H P Pr, r 2: 3. For these classes, we pro\u00ad vide three types of results for HPPs. First, we develop algorithms to compute the set of all ground consequences of an HPP. Then we provide algorithms and complexity results for the problems of entailment (\"Given an HPP P and a query Q as input, is Q a logical con\u00ad sequence of P?\") and consistency (\"Given an HPP Pas input, is P consistent?\"). Our re\u00ad sults provide a fine characterization of when polynomial algorithms exist for the above problems, and when these problems become intractable.", "creator": "pdftk 1.41 - www.pdftk.com"}}}