{"id": "1301.6746", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "23-Jan-2013", "title": "Probabilistic Belief Change: Expansion, Conditioning and Constraining", "abstract": "The AGM theory of belief revision has become an important paradigm for investigating rational belief changes. Unfortunately, researchers working in this paradigm have restricted much of their attention to rather simple representations of belief states, namely logically closed sets of propositional sentences. In our opinion, this has resulted in a too abstract categorisation of belief change operations: expansion, revision, or contraction, or contraction.\n\n\n\nThe notion that belief change operations are not based on real beliefs, but rather based on a simplified process of categorisation, rather than a general set of ideas, is still the predominant form of belief change operations, and the majority of scientists have concluded that no change in real belief changes are based on real belief changes.\nThis is not the only argument that the AGM theory is a good approach to the problem of \"correcting\" beliefs and therefore is wrong. In the absence of actual research, it is often used to create more complex and difficult views.\nAccording to several leading members of the AGM, the AGM is a good way to test the hypothesis of the \"correcting\" hypothesis. For example, for example, in the first chapter of the original sentence of the original sentence of the original sentence of the original sentence of the original sentence of the original sentence of the original sentence of the original sentence of the original sentence of the original sentence of the original sentence of the original sentence of the original sentence of the original sentence of the original sentence of the original sentence of the original sentence of the original sentence of the original sentence of the original sentence of the original sentence of the original sentence of the original sentence of the original sentence of the original sentence of the original sentence of the original sentence of the original sentence of the original sentence of the original sentence of the original sentence of the original sentence of the original sentence of the original sentence of the original sentence of the original sentence of the original sentence of the original sentence of the original sentence of the original sentence of the original sentence of the original sentence of the original sentence of the original sentence of the original sentence of the original sentence of the original sentence of the original sentence of the original sentence of the original sentence of the original sentence of the original sentence of the original sentence of the original sentence of the original sentence of the original sentence of the original sentence of the original sentence of the original sentence of the original sentence of the original sentence of the original sentence of the original sentence of the original sentence of the original sentence of the original sentence of the original sentence of the original sentence of the original sentence of the original sentence", "histories": [["v1", "Wed, 23 Jan 2013 16:01:26 GMT  (271kb)", "http://arxiv.org/abs/1301.6746v1", "Appears in Proceedings of the Fifteenth Conference on Uncertainty in Artificial Intelligence (UAI1999)"]], "COMMENTS": "Appears in Proceedings of the Fifteenth Conference on Uncertainty in Artificial Intelligence (UAI1999)", "reviews": [], "SUBJECTS": "cs.AI", "authors": ["frans voorbraak"], "accepted": false, "id": "1301.6746"}, "pdf": {"name": "1301.6746.pdf", "metadata": {"source": "CRF", "title": "Probabilistic Belief Change: Expansion, Conditioning and Constraining", "authors": ["Frans Voorbraak"], "emails": [], "sections": [{"heading": null, "text": "The AGM theory of belief revision has be come an important paradigm for investigat ing rational belief changes. Unfortunately, researchers working in this paradigm have re stricted much of their attention to rather sim ple representations of belief states, namely logically closed sets of propositional sen tences. In our opinion, this has resulted in a too abstract categorisation of belief change operations: expansion, revision, or contrac tion. Occasionally, in the AGM paradigm, also probabilistic belief changes have been considered, and it is widely accepted that the probabilistic version of expansion is con ditioning. However, we argue that it may be more correct to view conditioning and expan sion as two essentially different kinds of belief change, and that what we call constraining is a better candidate for being considered prob abilistic expansion.\n1 Introduction The AGM theory of belief revision (Giirdenfors 1988, 1992) has become an important paradigm for inves tigating rational belief changes. In this theory, three main types of belief changes are distinguished, namely expansion, revision, and contraction. Expansion is the most simple type of belief change, partly because it is supposed to occur only when information is added which is consistent with the previously held beliefs, whereas the other types of belief changes (also) apply in case the new information is inconsistent with the old beliefs.\nIn fact, if logical theories are used to represent the belief states, then an explicit definition of expansion can be given: The result of expanding a theory K with a sentence \u00a2 is the set Cn(K U { \u00a2}) of logical\nconsequences of K U { \u00a2}. In general, no such explicit definition can be given for revision and contraction.\nWhen these types of belief changes are studied in the context of probabilistic belief states, at first sight, con ditioning seems to be the obvious probabilistic variant of expansion. We argue that closer inspection shows that conditioning and expansion are best viewed as two essentially different types of belief changes. This is most clear in the context of partial probability theory, where both types of belief changes can be compared.\nIn our view, conditioning is a type of belief change dif ferent from expansion, revision, and contraction. Con ditioning does not make sense in the context of belief states represented by logical theories, just as expan sion does not make sense in the context of belief states represented by probability functions. Expansion and conditioning both make sense in the context of belief states represented by partially determined probability functions, since they allow the representation of both ignorance and uncertainty.\nIn the remainder of this paper, we first review several models of belief states, including belief sets and (par tial) probabilistic models. Next, we discuss the notions of expansion and conditioning in the different contexts, and we provide several arguments for our opinion that these notions are essentially different, and that con straining is better suited than conditioning to be con sidered probabilistic expansion. In (Voorbraak, 1996), we briefly discuss the probabilistic variant of revision, but in this paper we restrict ourselves to expansion. We conclude with a discussion of the question how to determine whether either conditioning or constraining is appropriate.\n2 Belief State Models\nThroughout the paper, L denotes a propositional lan guage with the usual connectives -,, V, 1\\, --+, +->, and constants .l and T. For simplicity, we assume that L\n656 Voorbraak\nhas finitely many propositional letters Pl, P2, . . . , Pn. We write SL for the set of sentences of L and we use\n\u00a2, 1/J, . . . as sentential variables.\nWe further assume 1- to denote the standard proposi tional consequence relation on SL and Cn to denote the associated consequence operation. (If S \ufffd SL, then Cn(S) = {\u00a2 E SL : S 1- \u00a2}.) A setS\ufffd SL is called logically closed iff S = Cn( S).\nDefinition 1 (belief set) A belief set K for L zs a logically closed consistent subset of SL. A sentence \u00a2 of L is called accepted in K iff\u00a2 E K.\nFor technical convenience, the inconsistent belief state (containing all sentences of the language) is sometimes added to the considerations. However, in this paper, the rational belief states are assumed to be consistent.\nA sentence a E SL is called an atom of L iff a = 'lr1/\\'lr2/\\ . . . 1\\'lrn, where for each i E {1, . .. , n}, 'lr; = Pi or rr; = -,Pi. Notice that if n is the number of propo sitional letters of L, then the number N of atoms of L equals 2n. A belief set K for L can be represented equivalently by the set of all atoms of L which are consistent with K. Since atoms can be identified with possible worlds, this is called a possible worlds repre sentation of belief states.\nThe belief sets and the possible worlds models are es sentially equivalent, but there exist many other essen tially different models of belief states. For example, probabilistic models can be used to represent degrees of belief in propositions, as opposed to belief sets which only model whether a proposition is (fully) accepted or not.\nDefinition 2 (probabilistic model) A probabilis tic {belief) model P for L is a probability function on SL, that is, P is a function on SL satisfying the fol lowing three conditions.\n1. For all\u00a2 E SL, P(\u00a2) 2:: 0\n2. For all\u00a2 E SL, if I-\u00a2, then P(\u00a2) = 1\n3. For all \u00a2,1/J E SL, ifl- --.(\u00a2/\\ 1/;), then P(\u00a2V1j;) = P(\u00a2) + P(l/J).\nA sentence \u00a2 of L is called accepted in P iff P( \u00a2) = 1.\nWe write P ROB(SL) for the class of probability func tions on SL. With every probabilistic model P for L one can naturally associate the belief set t( P) for L given by t(P) = {\u00a2 E SL: P(\u00a2) = 1}. It is easy to see that t(P) is indeed a belief set and that in t(P) the same sentences are accepted as in P. The belief set t( P) is called the top of P. Of course, different proba bility functions may have the same top. The belief sets\nfor L correspond exactly to the equivalence classes of probabilistic models for L with the same top.\nIn other words, with every belief set K for L one can naturally associate a class of probability functions. Since also a probabilistic belief model P for L can be naturally associated with a class of probability func tions, namely { P}, it follows that using classes of prob ability functions as models of belief states naturally incorporates the previously defined models.\nDefinition 3 (partial probabilistic model) A partial probabilistic model II for L is a non-empty class of probability functions on SL. A sentence\u00a2 of L is called accepted in II iff for every P E II, P( \u00a2) = 1.\nLet i be the function embedding belief sets and prob ability models into partial probability models in the way mentioned above. That is, i assigns to a be lief set K for L, or probability function P on SL, the class of probability functions on SL compatible with K, or P. Thus, i(K) = {P E PROB(SL) : if\u00a2 E K, then P(\u00a2) = 1}, and i(P) = {P}.\nThe previously introduced function t for taking the top of a probability function can naturally be ex tended to partial probabilistic models as follows. If\nII is a class of probability functions on SL, then t(II) = {\u00a2 E SL: for every P E II, P(\u00a2) = 1}. Notice that t( i( P)) agrees with t( P) as previously defined, and that t( i(K)) = K.\nPartial probabilistic models are of technical interest, since they generalise both the belief sets and the prob abilistic models. In addition, it can be argued that in some situations, in particular when there is ig norance concerning the exact likelihood of events, a class of probability functions is more appropriate to model a belief state than a single probability function. Classes of probability functions are also mentioned in (Gardenfors, 1988) as possible belief state models.\nWe conclude this section by pointing out that a par tial probabilistic model can be viewed as some kind of possible worlds model for a probabilistic language. Let LPROB be a language for probabilistic reasoning with L as object language for the probability expressions. We use SLPROB to refer to the sentences of LPROB, and 1-PROB and GnP ROB denote a probabilistic conse quence relation and associated consequence operation on SLPROB. We assume that the sentences of L are not sentences of LPROB, but occur only in the scope of the probability operator of LpROB. For example, one can take LPROB to be (a suitable adaptation of) L( AX) or L( AXFo) of (Fagin et a!., 1988), and use AXMEAS or AXFo-MEAS of the same paper as the probabilistic logic.\nSentences of LPROB can be viewed as constraints on probability functions on S L, much as sentences of L can be viewed as constraints on possible worlds for L. Thus, any setS<::; SLPROB determines a partial prob abilistic model for L. Of course, S and CnPROB(S) determine the same model. Hence there is an ex act correspondence between (probabilistic) belief sets for LPROB and classes of probability functions deter mined by subsets of SLPROB. For any such class II, let (II) denote the belief set S for LPROB such that\nII= {P E PROB(SL): P satisfies S}. We will some times use P I= S as an abbreviation for 'P satisfies S'.\nAlthough, in general, a class of probability functions cannot be expected to correspond to a (probabilistic) belief set for LPROB, it seems likely that any natural occurring class is determined by a set of sentences of some probabilistic language. Therefore, a probabilistic belief set may be an interesting representation of a belief state.\n3 Conditioning and Constraining Let K be a belief set for L and let \u00a2 E S L be consistent with K, or, in other words, \ufffd\u00a2 not accepted in K. Then the belief in \u00a2 can be added to the belief state\nK without giving up any old beliefs. In the AGM theory, such a kind of change in belief state is called an expansion, and is modelled by the operation + given by K + \u00a2 = Cn(I< U {\u00a2}).\nIf we use a probability function P on S L as our rep resentation of belief state, then conditioning seems a natural candidate for the role played by the operation + on belief sets.\nDefinition 4 (conditioning) Let P be a probability function on SL. Define, for each \u00a2 E SL such that\nP(\u00a2) :f 0, the function P\u00a2 as follows.\nP(\u00a2 11 1/J) For every .p E SL, P\u00a2(.P) = P(!f;J\u00a2) = P(\u00a2) \u00b7\nIt is easy to check that the thus defined function P\u00a2 is a probability function on SL. The mapping from\nP to P\u00a2 is strongly related to expansion with \u00a2, since, just as the expansion operation, the mapping is defined whenever \ufffd\u00a2 is not accepted in the original belief state (P(\ufffd\u00a2) :f 1), and we have t(P)+\u00a2 = t(P\u00a2)\u00b7 It follows that the expansion operation + on belief sets can be viewed as an abstraction of Bayesian conditioning on probabilistic belief states.\nHowever, the expansion operation on belief sets can be viewed as an abstraction of many other operations on probabilistic belief models as well, including preserva tive imaging introduced in (Gardenfors, 1988). The\nProbabilistic Belief Change 657\nquestion arises whether compatibility with + is suffi cient for an operation on probabilistic belief models to qualify as a probabilistic expansion. This question is perhaps even more relevant in the context of partial probabilistic belief models, where even more opera tions are compatible with the expansion of belief sets. The following definitions describe two such operations.\nDefinition 5 (extended conditioning) Let II be a partial probabilistic model for L, and let\u00a2 E SL, such that for some P E II, P( \u00a2) > 0. Define the partial probabilistic model II\u00a2 for L as follows.\nII\u00a2= {P\u00a2: P E II, P(\u00a2) > 0}.\nDefinition 6 (constraining) Assume that II is a partial probabilistic model for L and that\u00a2 E SL, such that for some P E II, P( \u00a2) = 1. Define the partial probabilistic model II&\u00a2 for L as follows.\nII&\u00a2= {P E II: P(\u00a2) = 1}.\nThese, or similar operations have been studied before. See, for example, (Dubois and Prade, 1997). In (Grove and Halpern, 1998), both conditioning and constrain ing, and several other ways of updating sets of proba bility measures, are discussed from an axiomatic point of view.\nThe following proposition shows that constraining and extended conditioning are both compatible with + on embeddings of belief sets.\nProposition 1 Let II be a partial probabilistic belief model for L such that II = i( K), for some belief set\nK for L, and let \u00a2 E SL such that \ufffd<P fl. K. Then t(II&\u00a2) = t(II\u00a2) = t(II) + \u00a2.\nAlthough both operations are compatible with expan sions of belief sets, we consider constraining to be the proper probabilistic notion of expansion, whereas (ex tended) conditioning is in our opinion best viewed as a new kind of operation, different from both expan sion. (It is of course also different from the other AGM operations, revision and contraction, since these are intended for incorporating new information which is inconsistent with the previously held beliefs.) In the following section, we give several arguments support ing this view.\n4 Conditioning versus Expansion We argue that constraining and not conditioning should be considered to be probabilistic expansion, smce\n1. constraining, and not conditioning, can be viewed as expansion of probabilistic belief sets\n658 \\Toorbraak\n2. constraining can be said to (primarily) reduce ig norance, just like expansion, whereas condition ing is (primarily) connected with reducing uncer tainty.\nThis latter difference between conditioning and con straining will only be discussed briefly in general terms, but a concrete manifestation of this difference will be treated in more detail: like expansion, and in contrast to conditioning, constraining can be used to obtain any belief state from a state of ignorance while preserving intermediate results.\n4.1 Expansion of Probabilistic Belief Sets\nWe argue, that, in contrast to conditioning, constrain ing can be viewed as expansion of probabilistic belief sets. First notice that constraining can also be defined for sentences of LPROB instead of L.\nDefinition 7 (generalised constraining) Let II be a non-empty class of probability functions on SL. De fine, for each \u00a2> E SLpROB which is satisfied by some\nP E II,\nII&</>= {P E II: P \ufffd \u00a2>}.\nThis definition of constraining generalises definition 6, since II&</>, for \u00a2> E SL, can be viewed as an abbrevi ation of II&(P(</>)=l). Further on, we will also discuss an analogous generalisation of conditioning. The fol lowing proposition shows that the generalised version of constraining translates into the expansion of prob abilistic belief sets.\nProposition 2 Assume that S is a probabilistic belief set for LPROB\u00b7 Let II be the partial probabilistic belief mode/for L such that (II)= S, and let\u00a2> E SLPROB be consistent with S. Then (II&\u00a2) = CnPRoB(S U {\u00a2>)}).\nCorollary 3 Let II be a partial probabilistic belief model for L such that (IT) = S, and let \u00a2> E SL such that for some P E II, P(\u00a2>) = 1. Then (II&\u00a2} = CnPROB(S U {P(\u00a2>) = 1}).\nThe following example shows that the analogue of this corollary for conditioning does not hold, provided CnPROB is monotone, and LPROB is nontrivial, in the sense that it allows assigning (probability) values between 0 and 1.\nExample 1 Let p and q be the proposition letters of L, and let II be the partial probabilistic belief model for L such that (II} = CnPRoB( {P(pl\\q) = x, P(pl\\..,q) = 0} ), for some x between 0 and 1. Then (IT} contains\nP(p) = x, whereas (IT9) does not.\nConditioning is not just a matter of adding informa tion and possibly sharpening the bounds on probabil ity values. Conditioning may also involve the revision of previously held degrees of belief, even if one condi tions on events which are completely consistent with the old belief state. The possibility that conditioning is perhaps not a 'pure' expansion process since it has some aspects of a revision process has already been mentioned in (Dubois and Prade, 1992).\n4.2 Reducing Uncertainty or Ignorance\nWe claim that constraining can be said to (primar ily) reduce ignorance, whereas conditioning is (primar ily) connected with reducing uncertainty. To make this more precise, one needs measures of both un certainty and ignorance, preferably in the contexts of partially specified probability. Obtaining and justi fying such measures is not easy, although some work has been done in this area. See, for example, (Klir, 1994) for a discussion of such measures in the context of Dempster-Shafer theory.\nIn (Voorbraak, 1996) we propose provisional measures for uncertainty and ignorance in the partial proba bilistic case. The uncertainty measure is based on en tropy and the ignorance measure is based on the (av erage) difference between upper and lower probability of events.\nThese measures are provisional, and cannot be justi fied rigorously, but they suffice to show that condition ing is biased towards reducing uncertainty, whereas constraining is biased towards reducing ignorance. More precisely, if the uncertainty in a belief state is not minimal, then it can always be reduced by condition ing, but not always by constraining. If the ignorance in a belief state is not minimal, then it can always be reduced by both constraining and conditioning, but constraining always (weakly) reduces the ignorance, whereas after conditioning the ignorance might be in creased. See (Voorbraak, 1996) for details.\nSince the expansion operation + on belief sets is aimed at reducing ignorance rather than uncertainty, the above can be viewed as a second argument in favour of the position that constraining rather than condition ing is the probabilistic variant of expansion. Below, we will consider a more specific version of this argument.\n4.3 Expanding from Ignorance\nAny belief set K for L can be obtained from the ig norant belief state Cn(0) by a sequence of expansions. (In fact, since L has a finite number of proposition let ters, a single expansion suffices.) This is in accordance with the intuition that one can learn about a subject\nof which one is completely ignorant, without having to give up previously held beliefs.\nIntuitively, one should be able to learn about a sub ject in bits and pieces, possibly getting information from different sources and on different occasions. In deed, starting from the ignorant belief state Cn(0), iterated expansion leads to more and more extended belief states. This is a monotone process, since the fol lowing preservation property holds. Let K be a belief set for L, and let 1/;, \u00a2 E SL such that K, \u00a2, and 1/; are jointly consistent, then\n\u00a2 is accepted in (K + \u00a2) + 1/;. (1)\nSince for every probability function P on SL and \u00a2, 1/; E SL, such that P(\u00a2/\\1/;) > 0, we have (Prp)v,(\u00a2) = 1, the analogous property holds in the context of prob abilistic belief models. Here the most obvious candi date to represent the ignorant belief state is the uni form probability function Pun, defined by Pun(a) = tr\u2022 where N is the number of atoms of the language, and a is any one of these atoms. The following exam ple shows that it is not the case that any probability function P on SL can be obtained by conditioning the uniform probability function Pun on SL.\nExample 2 Let p be the only proposition letter of L, and let P be the probability function on SL given by P(p) = 0.1. Then P differs from (Pun)p, (Pun),p, and (Pun)pv,p(= Pun), which are the only probability functions that can be obtained by conditioning Pun\u00b7\nThis negative result can be circumvented if one gener alises the notion of (Bayesian) conditioning by allowing conditioning on events which are not certain. Jeffrey conditioning is such a generalisation of Bayesian con ditioning. Below we first define a simple version of Jeffrey conditioning, which we call binary Jeffrey con ditioning, for reasons that will become clear further on.\nDefinition 8 (binary Jeffrey conditioning) Let P be a probability function on SL, and let \u00a2 E SL such that 0 < P(\u00a2) < 1. Define, for any x E [0, 1], the function Prp,x as follows.\nPrp,x = xPrp + (1- x)P, rp\nNotice that the usual conditional probability function Prp = P</>,1. It is easy to see that the probability func tion of P example 2 can be obtained from Pun by bi nary Jeffrey conditioning: P = (Pun)p,0.1\u00b7 Binary Jef frey conditioning can be generalised in a natural way as follows.\nDefinition 9 (Jeffrey conditioning) Let P be a probability function on SL, and let { \u00a2; : i E I} be\nProbabilistic Belief Change 659\na set of mutually exclusive sentences of L, such that for every i E I, P( \u00a2;) > 0. Define, for any set {x; : i E I}, with x; E [0, 1] and Lief x; = 1, the function P{(rp,,x,):iEl} as follows.\nP{(rp,,x,):iEI} = L x;Prp,. iEI\nNotice that Prp,x = P{(rp,x),(,</>,1-x)}. Hence binary Jef frey conditioning is Jeffrey conditioning on two exclu sive events. Bayesian conditioning is Jeffrey condition ing on a single event and might be called unary Jeffrey conditioning. Jeffrey conditioning can be generalised even further to allow conditioning on constraints ex pressed by sentences of LPROB as follows.\nDefinition 10 (minimum cross entropy) Assume that a1, a\n2 , ... , aN are the atoms of L. Let P\nbe a probability function on SL, and let\u00a2 E SLPROB. We define Pif>, the minimum cross entropy update of P with \u00a2, to be that probability function P' on SL sat isfying \u00a2 where the function\n( 1 ) \ufffd '( ) P'(a;) I P , P = L..... P a; log ---p--( \u00b7) i=l Q'\ufffd\nis minimal.\nThe function (Pun) </> is the probability function satis fying \u00a2 with the maximum entropy. It follows that if\u00a2 uniquely determines a probability function P ( P' f= \u00a2 iff P' = P), then (Pun)</> = P.\nIt is also easy to show that every probability function P on SL can already be obtained from Pun by Jeffrey conditioning. In fact, the following proposition shows that one does not have to start from the 'ignorant' Pun, since (even binary) Jeffrey conditioning allows many probabilistic belief states to be changed into an arbitrary probabilistic belief state.\nProposition 4 Let P be a probability function on SL and let {a; : i E I} be the set of atoms of L such that P(a;) > 0. Assume that P' is a probability function on SL such that for every i E I, P'(a;) > 0. Then P can be obtained from P' by at most III applications of binary Jeffrey conditioning.\nExample 3 Let p and q be the proposition letters of L, and let P be the probability function on SL given by the table below. Let P' =Pun\u00b7 Then P1 = (Pun)pvq, P2 = P1A , , and P3 = PP2 0 9 = P. The different p q,T , . probability functions are described in the table below.\n660 Voorbraak\np/\\q p 0.4 P' = Pun 0.25 P' \ufffd p2 \ufffd p\ufffd 0.4 p /\\ --.q --.p /\\ q --.p /\\ --.q 0.5 0.1 0 0.25 0.25 0.25 \ufffd \ufffd 0 ,?;, ,?;, 0 0.5 0.1 0\nHowever, the above example illustrates that the men tioned generalised notions of conditioning do not sat isfy the generalisation of the preservation property (1). If\u00a2 and 1/; are allowed to range over SLPROB, then \u00a2 is no longer guaranteed to be accepted in ( P\u00a2)1/J\u00b7 Consider, for example, P = P1 from example 3, \u00a2 : P(p /\\ q) = \ufffd' and 1/; : P(p) = 0.9. We con clude that conditioning does not allow a preservative change of the ignorant belief state into an arbitrary belief state.\nIn the context of partial probabilistic belief mod els for L, the ignorant belief state is represented by PROB(SL). It is easy to see that any partial prob abilistic belief model determined by a subset S of SLPROB can be obtained from PROB(SL) by con straining with the sentences of S. In other words, any probabilistic belief set S for LPROB can be obtained by constraining the ignorant belief state CnpRoB(0). Moreover, constraining satisfies the appropriate gen eralisation of the preservation property ( 1):\nProposition 5 Let S = (II) be a (probabilistic) belief set for LPROB, and let '1/;, \u00a2 E SLPROB such that S, \u00a2>, and 1/; are jointly consistent. Then\n\u00a2 is accepted in (II&\u00a2 )&1/J.\nOf course, one cannot constrain ignorance to partial probabilistic belief models which are not determined by a subset S of SLPROB. Since a similar situation arises in the case of expanding belief sets and possi ble worlds models of a language with infinitely many proposition letters, we do not consider this to be an es sential difference between constraining and expansion.\nThe situation is much worse for conditioning, since very few partial probabilistic belief models can be ob tained from PROB(SL) by extended Bayesian condi tioning. Given our previous deliberations, it may be natural to consider set-extensions of the discussed gen eralisations of Bayesian conditioning. For example, for any\u00a2 E SLPROB, one can define II,p = { P,p: P E II}, where P,p is the minimum cross entropy update of P with \u00a2. The following example shows that this opera tion does not satisfy the preservation property.\nExample 4 Assume that p and q are the proposition letters of L, and let II= PROB( SL), \u00a2: P(p/\\ q) = 0.5, and 1/; : P(p) = 0.5. Then II, \u00a2, and 1/; are jointly\nconsistent, but it is not the case that \u00a2 is accepted in (II,p ) 1/l. The following table shows what happens to Pun during the updates.\np/\\q p /\\ --.q --.p /\\ q --.p /\\ --.q Pun 0.25 0.25 0.25 0.25\n( Pun)\u00a2 0.5 \ufffd \ufffd \ufffd ((Pun)\u00a2) 1/l 0.375 0.125 0.25 0.25\nSince Pun E PROB(SL), we have ((Pun)\u00a2)\u00a2 E (II,p) .p. Hence we cannot have (II,p).p(P /\\ q) = 0.5.\nNotice that the example shows that the preservation property is not even satisfied by the set-extension of bi nary Jeffrey conditioning. We conclude that (iterated) expansion has a certain property, namely the possibil ity of reaching every (definable) belief state from igno rance in a preservative manner, which is also possessed by constraining, but not by conditioning.\n5 Conditioning versus Constraining So far, we argued that conditioning or constraining are two different kinds of operations on belief states, where constraining is the proper probabilistic notion of expansion, since it is the expansion of probabilistic belief sets, and it can model preservative changes from the ignorant belief state to an arbitrary belief state. A decrease in ignorance is the main effect of constraining, whereas conditioning is primarily aimed at reducing uncertainty.\nWe have left open the question which of the two oper ations one should use when receiving information. We will discuss this matter using a well-known example deriving from (Smets, 1988). Example 5 (The three assassins) Mr. Jones has been murdered by one of the assassins Peter, Paul, and Mary under orders of Big Boss, who has chosen between these three possible killers as follows. He de cided between a male and a female killer by means of tossing a fair coin. A male killer was chosen in case the coin landed heads. Otherwise, a female killer was chosen. No information is available on how he decided between the two male assassins in case the coin landed heads.\nBased on the information above, it seems reasonable to say that the possibility of the killer being male and that of the killer being female are equally likely. Now suppose that you learn that at the time of the murder, Peter was at the police station, where he was ques tioned about some other crime. So you can rule out Peter as the killer. How should this new evidence be modelled? In particular, is it still equally likely for the killer to be male or female?\nTo formalise this example, let L be the language with the three propositional letters p, q, and r, where p : Peter is the killer, q : Paul is the killer, and r : Mary is the killer. Given that exactly one of the assassins mur dered Jones, only three atoms remain possible, namely, a = p 1\\ -.q 1\\ -.r, f3 = -.p 1\\ q 1\\ ..,r, and 1 = -.p 1\\ -.q 1\\ r. Adding the information that a fair coin toss decided the choice between a 'male and female killer leads to the partial probabilistic belief state II = { P E PROB(SL) : P(aV(3) = 0.5, P('Y) = 0.5}. This agrees with the interpretation in Dempster-Shafer the ory, where the information is encoded in the mass func tion m given by m (a V (3) = 0.5, m(1) = 0.5, which in duces a belief function Bel such that Bel is the lower envelope of II. Strict Bayesians will opt for the prob ability function P given by P ( a) = 0.25, P (f3) = 0.25, and P ('Y) = 0.5, which is the 'least informative' mem ber of II.\nHow to take account of the information -.p that Peter is not the killer? Strict Bayesians use Bayesian condi tioning and arrive at P\ufffdp given by P\ufffdp (f3) == !, and P\ufffdp('Y) = \ufffd. which implies that it is twice as likely for the killer to be female than to be male. However, as argued by (Smets, 1988) and (Halpern and Fagin, 1992), the 'least informative' prior P on which this answer is based makes some (unjustified) assumptions about how the choice between Peter and Paul is made.\nStarting from the partial probabilistic belief state II, one can use both constraining and (extended) condi tioning. Constraining II with -.p (or P (-.p) == 1) gives II&\ufffdp = { P E PROB(SL): P(f3) = 0.5, P ('Y) = 0.5}, which implies that the possibility of the killer being male and that of the killer being female are still equally likely. This answer completely agrees with the answer given be Dempster's rule of conditioning in Dempster Shafer theory, and is defended by Smets (Smets88).\nConditioning II with .,.,p gives II\ufffdp = { P E PROB(SL) : 0 :S P(f3) :S 0.5, 0.5 :S P ('Y) :S 1, P(f3 V 1) == 1}, which implies that the possibility of the killer being female is at least as likely as that of the killer being male. This answer, which is defended by (Halpern and Fagin, 1992), agrees with our intu ition that finding out that Peter has an alibi makes it less likely that the coin landed heads to a degree which equals one's degree of belief that Peter would have been chosen in case of heads. The ignorance concerning P(p\\p V q) makes it impossible to justify a specific answer.\nThe above is related to a distinction discussed in (Dubois and Prade, 1997) between specific informa tion, or factual evidence, which concerns a particu lar case at hand, and general information, or generic, background knowledge, which pertains to a class of sit-\nProbabilistic Belief Change 661\nuations. Constraining is applicable in case of (general) information referring to the prior probabilities, and (specific) information about the case at hand should be incorporated using (extended) conditioning.\nFor example, learning Peter's alibi provides specific information, whereas a report of an undercover agent saying that Big Boss decided to choose Paul in the event that a male killer had to be chosen constitutes general information. In both cases one learns ..,p, but if it is specific information one has to condition on this event, whereas one has to use constraining in case the information is general.\nThe distinction between specific and general informa tion is hard to make precise in general, but we find the following argument that Peter's alibi is specific, and not general, quite convincing.\nExample 6 Assume that in the context of example 5, you received a report of an undercover agent saying that Big Boss, in the event he has to choose a male killer, decides between Peter and Paul by means of a (second) fair coin toss. Further assume that this report is completely reliable, but that you read it after you learned about Peter's alibi.\nThe report of the undercover agent tells you that P(p)/( P(p) + P(q)) = 0.5. Simply adding this con straint to II\ufffdp (as previously defined) results in { P E PROB( SL) : P ('Y) = 1}, which is counterintuitive, and adding the constraint to II&\ufffdp is not possible at all, since it leads to an inconsistency. However, the constraint from the report is a constraint on the prior probabilities, not on the probabilities obtained after incorporating the evidence of Peter's alibi.\nAdding the constraint to II results in { P}, where P is the given by P (a) = 0.25, P(f3) = 0.25, and P('Y) = 0.5. Conditioning on the evidence of Peter's alibi gives { P\ufffdp}, which agrees with the answer given by strict Bayesians in the original example, since the probability function P is chosen by the strict Bayesians even without the information from the undercover agent. Notice, however, that it is not possible to use constraining to incorporate Peter's alibi in the belief state { P}. This supports our opinion that Peter's alibi is specific information which calls for conditioning and not for constraining.\nIt can be shown that the order among conditionings or among constrainings does not matter. More precisely, if for some P E II, P(\u00a2 1\\ 1/J) > 0, then (II,p).p = II,pA.p = (II.p),p, and if 1/>A 'if; is satisfied by some P E II, then (II&q, )&.p = II&( if> A 'I>) == (II&.p )&\u00a2.\nIn contrast, (IIq,)&.p = (II&.p)q, is not valid, as shown by the analysis of the example above. Constrain-\n662 Voorbraak\ning should always be performed before conditioning, which implies that after conditioning one should not forget about the original belief state, since general con straints should be added to this original belief state.\nUsually, one obtains additional information from ob servations of some aspects of the particular case at hand. This kind of information tends to be specific. But in some situations it might be reasonable to search for general information. For example, a chief of po lice, having the information described in the original example 5 of the three assassins, may conclude that he should assign at least as many detectives to investigate Mary as to investigate Paul. However, to determine an optimal division of the available detectives, he might try to reduce his ignorance by ordering an undercover agent to acquire information about the choice between Peter and Paul.\nWe conclude that the most common kind of probabilis tic evidence is specific evidence about the case at hand, and should be incorporated by means of (extended) conditioning. Some evidence may be of a general na ture and may reduce the ignorance concerning prior probabilities. Such evidence calls for constraining.\n6 Conclusion\nWe argued that conditioning can best be viewed as a type of belief change different from expansion, revision, and contraction. This difference becomes most clear in the context of belief states represented by partially determined probability functions, which allow the rep resentation of both ignorance and uncertainty. In this context, there are several operations agreeing with ex pansion on belief sets. Of these, constraining has more right to be called probabilistic expansion, than condi tioning has, although the latter is often chosen in the literature.\nThe principal result of constraining is a decrease in ignorance, whereas conditioning is aimed at reducing uncertainty. General evidence reducing ignorance con cerning the prior probabilities calls for constraining, but the most common probabilistic evidence concerns the particular case at hand, and should be modelled by means of conditioning. Constraining should always be applied before conditioning, since it represents evi dence concerning the prior probabilities.\nConditioning does not make sense in the context of be lief sets, which do not represent uncertainty, but only ignorance, just as expansion does not make sense in the context of belief states represented by probabil ity functions, which do not represent ignorance, but only uncertainty. Our distinction between expansion and conditioning calls into question the treatments of\nprobabilistic revision which start from the assumption that conditioning is the correct notion of probabilistic expansion.\nAcknowledgements\nThe investigations were carried out as part of the PIONIER-project Reasoning with Uncertainty, sub sidized by the Netherlands Organization of Scientific Research (NWO), under grant pgs-22-262.\nReferences\nD. Dubois and H. Prade, Belief change and possibility theory, in: P. Giirdenfors, ed., Belief Revision (Cam bridge U.P., Cambridge, 1992) 142-182.\nD. Dubois and H. Prade, Focusing vs belief revision: a fundamental distinction when dealing with generic knowledge, in D.M. Gabbay et al., eds., Qualitative and Quantitative Practical Reasoning. Proceedings ECSQARU-FAPR'97, LNCS 1244 (Springer, Berlin, 1997) 96-107.\nR. Fagin, J.Y. Halpern and N. Megiddo, A logic for reasoning about probabilities, in Proc. 3rd IEEE Symp. on Logic in Computer Science (1988) 277-191.\nP. Giirdenfors, Knowledge in Flux. Modeling the Dy namics of Epistemic States (MIT Press, Cambridge MA, 1988).\nP. Giirdenfors, Belief revision: An introduction, in: P. Gardenfors, ed., Belief Revision (Cambridge U.P., Cambridge, 1992) 1-28.\nA.J. Grove and J .Y. Halpern, Updating sets of prob abilities, Proceedings 14th Conference on Uncertainty in AI (1998) 173-182.\nJ .Y. Halpern and R. Fagin, Two views of belief: be lief as generalized probability and belief as evidence, Artificial Intelligence 54 (1992) 275-317.\nG.J. Klir, Measures of uncertainty in the Dempster Shafer theory of evidence, in: R.R. Yager, J. Kacprzyk, and M. Fedrizzi, eds., Advances in the Dempster Shaler Theory of Evidence (Wiley, New York, 1994) 35-49.\nP. Smets, Belief functions versus probability functions, in: B. Bouchon, L. Aitt, R.R. Yager, eds., Uncertainty and Intelligent Systems, LNCS 313 (Springer, Berlin, 1988) 17-24. F. Voorbraak, Probabilistic belief expansion and con ditioning, ILLC Research Report LP-96-07, (ILLC, University of Amsterdam, 1996). (Slightly revised ver sion submitted to Journal of Logic, Language and In formation)."}], "references": [{"title": "Belief change and possibility theory, in: P. Giirdenfors, ed., Belief Revision (Cam\u00ad bridge", "author": ["D. Dubois", "H. Prade"], "venue": "U.P., Cambridge,", "citeRegEx": "Dubois and Prade,? \\Q1992\\E", "shortCiteRegEx": "Dubois and Prade", "year": 1992}, {"title": "A logic for reasoning about probabilities, in Proc", "author": ["R. Fagin", "J.Y. Halpern", "N. Megiddo"], "venue": "IEEE Symp. on Logic in Computer Science", "citeRegEx": "Fagin et al\\.,? \\Q1988\\E", "shortCiteRegEx": "Fagin et al\\.", "year": 1988}, {"title": "Belief revision: An introduction, in: P. Gardenfors, ed., Belief Revision (Cambridge U.P", "author": ["P. Giirdenfors"], "venue": null, "citeRegEx": "Giirdenfors,? \\Q1992\\E", "shortCiteRegEx": "Giirdenfors", "year": 1992}, {"title": "Updating sets of prob\u00ad abilities", "author": ["A.J. Grove", "J .Y. Halpern"], "venue": "Proceedings 14th Conference on Uncertainty in AI", "citeRegEx": "Grove and Halpern,? \\Q1998\\E", "shortCiteRegEx": "Grove and Halpern", "year": 1998}, {"title": "Two views of belief: be\u00ad lief as generalized probability and belief as evidence", "author": ["Y. Halpern", "R. Fagin"], "venue": "Artificial Intelligence", "citeRegEx": "Halpern and Fagin,? \\Q1992\\E", "shortCiteRegEx": "Halpern and Fagin", "year": 1992}, {"title": "Measures of uncertainty in the Dempster\u00ad", "author": ["G.J. Klir"], "venue": "Shafer theory of evidence,", "citeRegEx": "Klir,? \\Q1994\\E", "shortCiteRegEx": "Klir", "year": 1994}, {"title": "Belief functions versus probability functions", "author": ["P. Smets"], "venue": "Uncertainty and Intelligent Systems,", "citeRegEx": "Smets,? \\Q1988\\E", "shortCiteRegEx": "Smets", "year": 1988}, {"title": "Probabilistic belief expansion and con\u00ad ditioning, ILLC Research Report LP-96-07", "author": ["F. Voorbraak"], "venue": "(ILLC, University of Amsterdam,", "citeRegEx": "Voorbraak,? \\Q1996\\E", "shortCiteRegEx": "Voorbraak", "year": 1996}], "referenceMentions": [{"referenceID": 7, "context": "In (Voorbraak, 1996), we briefly discuss the probabilistic variant of revision, but in this paper we restrict ourselves to expansion.", "startOffset": 3, "endOffset": 20}, {"referenceID": 3, "context": "In (Grove and Halpern, 1998), both conditioning and constrain\u00ad", "startOffset": 3, "endOffset": 28}, {"referenceID": 0, "context": "The possibility that conditioning is perhaps not a 'pure' expansion process since it has some aspects of a revision process has already been mentioned in (Dubois and Prade, 1992).", "startOffset": 154, "endOffset": 178}, {"referenceID": 5, "context": "See, for example, (Klir, 1994) for a discussion of such measures in the context of Dempster-Shafer theory.", "startOffset": 18, "endOffset": 30}, {"referenceID": 7, "context": "In (Voorbraak, 1996) we propose provisional measures for uncertainty and ignorance in the partial proba\u00ad", "startOffset": 3, "endOffset": 20}, {"referenceID": 7, "context": "See (Voorbraak, 1996) for details.", "startOffset": 4, "endOffset": 21}, {"referenceID": 6, "context": "We will discuss this matter using a well-known example deriving from (Smets, 1988).", "startOffset": 69, "endOffset": 82}, {"referenceID": 6, "context": "as argued by (Smets, 1988) and (Halpern and Fagin, 1992), the 'least informative' prior P on which this answer is based makes some (unjustified) assumptions about how the choice between Peter and Paul is made.", "startOffset": 13, "endOffset": 26}, {"referenceID": 4, "context": "as argued by (Smets, 1988) and (Halpern and Fagin, 1992), the 'least informative' prior P on which this answer is based makes some (unjustified) assumptions about how the choice between Peter and Paul is made.", "startOffset": 31, "endOffset": 56}, {"referenceID": 4, "context": "This answer, which is defended by (Halpern and Fagin, 1992), agrees with our intu\u00ad ition that finding out that Peter has an alibi makes it less likely that the coin landed heads to a degree which equals one's degree of belief that Peter would have been chosen in case of heads.", "startOffset": 34, "endOffset": 59}], "year": 2011, "abstractText": "The AGM theory of belief revision has be\u00ad come an important paradigm for investigat\u00ad ing rational belief changes. Unfortunately, researchers working in this paradigm have re\u00ad stricted much of their attention to rather sim\u00ad ple representations of belief states, namely logically closed sets of propositional sen\u00ad tences. In our opinion, this has resulted in a too abstract categorisation of belief change operations: expansion, revision, or contrac\u00ad tion. Occasionally, in the AGM paradigm, also probabilistic belief changes have been considered, and it is widely accepted that the probabilistic version of expansion is con\u00ad ditioning. However, we argue that it may be more correct to view conditioning and expan\u00ad sion as two essentially different kinds of belief change, and that what we call constraining is a better candidate for being considered prob\u00ad abilistic expansion.", "creator": "pdftk 1.41 - www.pdftk.com"}}}