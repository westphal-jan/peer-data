{"id": "1301.7369", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "30-Jan-2013", "title": "Dynamic Jointrees", "abstract": "It is well known that one can ignore parts of a belief network when computing answers to certain probabilistic queries. It is also well known that the ignorable parts (if any) depend on the specific query of interest and, therefore, may change as the query changes. Algorithms based on jointrees, however, do not seem to take computational advantage of these facts given that they typically construct jointrees for worst-case queries; that is, queries for which every part of the belief network is considered relevant do not have the power to modify the underlying properties.\n\nIn many cases, the results of this study are not surprising; if we look at the results of this study, we can see that this is the case of any algorithm, for which the original results are not relevant. Indeed, the results of the original studies were very similar to the results of other groups. As with the case of Algorithms based on jointrees, the results can be interpreted by all possible models of what a particular value of the model is, and we can even see why many of these results would be relevant to a particular query.\nHowever, this paper is a rather lengthy, lengthy and highly-paced article, because it will not focus on the specific case of Algorithms based on jointrees and on the specific problem. Nevertheless, it provides an excellent overview of what we can do to provide useful information to other algorithms. This is one of many reasons why we would want to use this paper and in any meaningful way. For one, the main problems are to find out which part of the belief network you need most in. One is the number of parts, which should help the algorithm and the others which may help you determine the appropriate part of the belief network, which are required to calculate the most optimal part of the belief network (i.e., if a given part of the belief network is a significant part of a given belief network, then the number of parts with which the most optimal part of the belief network has the most optimal part of the belief network is the most optimal part of the belief network). The biggest problems are to understand the fundamental and general properties of the belief network and how to calculate them. The main problems are to understand what is the fundamental and general properties of the belief network and how to calculate them.\nWhen we first come to the fundamental properties of the belief network and how to calculate them, this would be quite obvious to everyone. It is obvious that the basic elements in the belief network are very basic", "histories": [["v1", "Wed, 30 Jan 2013 15:03:15 GMT  (280kb)", "http://arxiv.org/abs/1301.7369v1", "Appears in Proceedings of the Fourteenth Conference on Uncertainty in Artificial Intelligence (UAI1998)"]], "COMMENTS": "Appears in Proceedings of the Fourteenth Conference on Uncertainty in Artificial Intelligence (UAI1998)", "reviews": [], "SUBJECTS": "cs.AI", "authors": ["adnan darwiche"], "accepted": false, "id": "1301.7369"}, "pdf": {"name": "1301.7369.pdf", "metadata": {"source": "CRF", "title": "Dynamic J ointrees", "authors": ["Adnan Darwiche"], "emails": ["darwiche@aub."], "sections": [{"heading": null, "text": "It is well known that one can ignore parts of a belief network when computing answers to certain probabilistic queries. It is also well known that the ignorable parts (if any) de pend on the specific query of interest and, therefore, may change as the query changes. Algorithms based on jointrees, however, do not seem to take computational advantage of these facts given that they typically con struct jointrees for worst-case queries; that is, queries for which every part of the belief net work is considered relevant. To address this limitation, we propose in this paper a method for reconfiguring jointrees dynamically as the query changes. The reconfiguration process aims at maintaining a jointree which corre sponds to the underlying belief network after it has been pruned given the current query. Our reconfiguration method is marked by three characteristics: (a) it is based on a non classical definition of jointrees; (b) it is rela tively efficient; and (c) it can reuse some of the computations performed before a jointree is reconfigured. We present preliminary ex perimental results which demonstrate signif icant savings over using static jointrees when query changes are considerable.\n1 Introduction\nThere is a number of algorithms for exact inference in belief networks, but the ones based on jointrees seem to be the most dominant [3, 4, 5]. According to these algorithms, the structure of a belief network is con verted into a jointree which is then used as the basis for computing posterior probabilities given evidence.\nOne of the main drawbacks of jointree algorithms, however, is that they prepare for worst-case queries.\nThat is, these algorithms typically build jointrees un der the assumption that every node in the belief net work can be observed or updated (its posterior proba bility computed). This means that the whole structure of the belief network is involved in computing a join tree which may, in certain situations, turn out to be an overkill. This happens when only part of the be lief network turns out to be relevant to a given query, therefore, permitting inference with respect to a much simpler jointree.\nConsider the belief network and its corresponding join tree shown in Figure 1(a) for an example. This jointree is built for the worst-case: any node can be observed and any node can be updated. Suppose, however, that in reality only Node B is observed and only Node C needs to be updated. In such a case, the pruned be lief network and its corresponding jointree shown in Figure 1(b) will suffice for handling the situation.\nAdopting the jointree in Figure 1 (b) will clearly involve less work, but the problem is that one may not know upfront that the query of interest is Pr(c I b). There fore, one is forced to build the jointree of Figure 1(a) in the first place to prepare for the worst case.\nOne suggestion, however, is to postpone the construc tion of the jointree until a specific query material-\n98 Darwiche\nizes. Once the query is known, the belief network can be pruned and a jointree can be constructed for the pruned belief network.\nThere are two main problems with such a proposal however. First, building a jointree is costly. There fore, building a jointree each time the query changes may not be cost effective. Second, even if building a jointree can be done efficiently, changing the jointree each time the query changes means that we are toss ing away the results of any computations performed thus far. But the reuse of such computations has been crucial for the performance of existing jointree algo rithms. Therefore, building a new jointree each time the query changes could undermine any savings that are expected from having a better jointree.\nIt appears, therefore, that any successful proposal for reconfiguring jointrees must satisfy at least two proper ties. First, it must provide a method for reconfiguring jointrees efficiently. Second, it must provide a mecha nism for reusing the results of computations performed before the jointree is reconfigured.\nIn this paper, we propose a method for dynamically reconfiguring jointrees in response to query changes. The method is shown to satisfy the above two prop erties and is inspired by a non-classical definition of jointrees, which is the subject of Section 2. Based on this non-classical definition, we propose a method for building jointrees in Section 3 and study its properties. In particular, we show how jointrees constructed using this method can be reconfigured in response to query changes. We then turn in Section 4 to a theorem which allows for the efficient reconfiguration of jointrees us ing our method. Section 5 is then dedicated to an other important theorem which explicates conditions under which computations performed before reconfig uring a jointree remain valid after reconfiguration. Ex perimental results are then given in Section 6 where we demonstrate significant savings using this new method when query changes are considerable. We finally close in Section 7 with some concluding remarks.\nProofs of all theorems can be found in [1].\n2 A Non-Classical Definition of\nJointrees\nWe review in this section the standard definition of a jointree and then propose an alternative definition which wilL underly our formal developments in this pa per. We start first with some preliminary definitions.\nA graph is a pair (V, A) where V is a finite set of nodes and A is a subset of V. x V known as edges. A labeled graph is a triple (V,A,L) where (V,A) is\na graph and L is a function that maps each node i in V to a label Li. Directed acyclic graphs (dags), undirected graphs, and trees are special cases of graphs obtained by imposing the usual conditions on the set of edges A. The family of a node in a dag 9 is the set containing the node and its parents in g.\nDefinition 1 A jointree for a directed acyclic graph g is a labeled tree I = (V, A, C) where\n1. Each label Ci is called a clique.\n2. Each family in g is contained in some clique Ci.\n3. If a node belongs to two cliques Ci and Ci, it must also belong to every clique ck where k is a node on the path connecting nodes i and j in /.\nThe separator of edge (i, j) in A is defined as def sij = ci ncj.\nThe jointree in Figure l(a) has two nodes with the associated cliques being {A, B, C} and {B, C, D}. It also has one separator {B, C}.\nWe now present an alternative definition of jointrees, which has inspired our proposal for reconfiguring join trees in response to a query change. Simply stated, a jointree for dag g is nothing but an aggregation of the families of g into groups which are connected in the form of a tree.\nDefinition 2 A basic jointree for a directed acyclic graph g is a labeled tree I = (V, A, 1-l) where\n1. Each label1li is called a hypernode.\n2. Each family in g is contained in some hypernode 1-li.\n3. Each hypernode 1-li is the union of some families in Q.\nFigure 2 (a) depicts a dag and Figure 2 (b) depicts a cor responding basic jointree with four hypernodes: 1\u00a31 = {A}, 1\u00a32 = {A,B}, 1\u00a33 = {A,C} and 1\u00a34 = {B,C,D}. Here, each hypernode contains a single family of the dag, which creates a one-to-one correspondence be tween the families of the dag and the hypernodes of its basic jointree.\nGiven a labeled tree T = (V,A,L) and an edge (i,j) in A, we will use Lij to denote the union of all labels Lk where k is a node on the i-side of the edge (i,j). For example, in Figure 2(b), 1i34 = 1\u00a31 U 1\u00a32 U 1\u00a33 = {A,B,C} and 1\u00a343 = 1\u00a34 = {B,C,D}.\nNote that Definition 2 of a basic jointree does not mention separators or cliques. These are derivative notions:\nDefinition 3 Let (V, A, 1\u00a3) be a basic jointree. The separator associated with edge (i,j) in A is defined as follows: def sii = 1lij n 1lji\u00b7 Moreover, the clique associated with node i in V is defined as follo;;;;s:-\nci d;j1li u U sij\u00b7 j\nThat is, the separator associated with an edge in a basic join tree contains nodes which are shared by fam ilies on opposite sides of the edge. In Figure 2(b), 1\u00a334 = {A,B,C} and 1\u00a343 = {B,C,D}. Therefore, S34 = {B, C} which are nothing but the nodes shared by families on opposite sides of the edge (3, 4).\nThe clique associated with a node in a basic jointree contains its hypernode and all adjacent separators. In Figure 2, 1\u00a33 = {A,C}, S13 = {A,B} and S43 = {B, C}. Therefore, C3 = 1\u00a33 U S13 U S43 ={A, B, C}.\nTheorem 1 Let T = (V, A, 1\u00a3) be a basic jointree for dag g and let Ci be the clique associated with node i in V. The labeled tree (V, A, C) is then a jointree for dag g. Moreover, for every edge (i,j) in A, we have ci n Cj = 1lij n 1lji\u00b7\nThis theorem asserts two important results. First, that we can covert any basic jointree into a classical join tree by simply converting each of its hypernodes into a clique as given by Definition 3. Second, that the separators of a basic jointree and those of its induced jointree are equal. Figure 2(c) depicts the jointree in duced by the basic jointree in Figure 2(b) .1\n1From the classical viewpoint, cliques C1 and C2 in Fig ure 2(c) are redundant and should be eliminated. However, we shall keep them because we would like to establish a\nDynamic Jointrees 99\nNote that in the standard definition of jointrees, cliques are primary objects and separator are sec ondary ones. Specifically, one defines a jointree by imposing a property on cliques and then defines sepa rator as a further detail needed by jointree algorithms. In our alternative definition of jointrees, however, both cliques and separators are derivative objects. The essence of a jointree according to our definition is an aggregation of families into a tree structure, leading to what we call a basic jointree. Once such an aggrega tion is committed to, separators and cliques follow as derivative objects that facilitate computations. Even then, however, separators are primary and cliques are secondary.\nTheorem 1, therefore, suggests a non-classical defini tion of join trees which promotes two key points. First, that the defining characteristic of a jointree is an ag gregation of families into groups and a connection of these groups into a tree. Second, that the separator associated with an edge is nothing but the intersection of families on opposite sides of the edge. We shall see in the following section how this viewpoint of jointrees can be exploited to reconfigure jointrees in response to a query change.\n3 A Non-Classical Method for Building Jointrees\nAccording to Theorem 1, one can construct a jointree T for dag g by simply constructing a basic jointree for g according to Definition 2 and then converting each of its hypernodes into a clique as given by Definition 3. The second step is deterministic, but the first step can be realized using a number of methods. We shall adopt a specific method in the rest of this paper for the sake of concreteness. Specifically, we will construct a basic jointree for a dag by simply connecting its families into a tree structure.\none-to-one correspondence between the nodes of a belief network and the cliques of its jointree. This will be dis cussed further in the following section.\n100 Darwiche\nDefinition 4 Let g = (V, A) be a dag. The family graph of g is a labeled dag (V, A, F) where Fi is the family of node i in g.\nEach spanning tree of this family graph is then a basic jointree.\nTheorem 2 Let \ufffd;t be the family graph of dag g and let T be a spanning tree of 9'. Then T is a basic jointree for g.\nFigure 3 depicts a belief network, its family graph and a basic jointree which corresponds to a spanning tree of the family graph. 2 According to our method then, constructing a basic jointree is just a matter of delet ing enough arcs from the family graph until the graph becomes singly connected.\nRealize that once a basic jointree is constructed, sepa rators and cliques are determined uniquely given Def inition 3. We shall therefore speak mostly about the basic jointree, leaving separators and cliques implicit.\nNow here's the basic observation underlying our pro posal for reconfiguring jointrees in response to a query change. Consider the belief network and its basic join tree shown in Figure 4(a). This basic jointree can be viewed as preparing for the worst-case: it can be used for computing the posterior probability of any node given evidence about any other node. Suppose now that we have evidence about Node B and we want to update Node C. We can, of course, use the ba sic jointree in Figure 4(a) to handle this query, but this amounts to performing inference with respect to the full belief network. As we have observed earlier, however, the simpler, pruned belief network in Fig ure 4(b) is sufficient for handling this query. Therefore,\n2It appears that our method for constructing jointrees can be justified using the transformation approach given in [2]. In particular, computing a spanning tree of the family graph can be viewed as successively applying the collapse transformation to the trivial cluster graph as defined in [2].\nwe will reconfigure the basic jointree in Figure 4(a) so it becomes a basic jointree for the pruned network in Figure 4(b).3 This can be achieved by simply remov ing the family of Node D, given that it was pruned, from its corresponding hypernode, leading to the basic jointree in Figure 4(b). This simpler, basic jointree is indeed a basic jointree for the pruned network in Fig ure 4(b) (according to Definition 2), and, therefore, can be used to answer the above query.\nThe simple method we used in the previous example is valid in general. That is, all we have to do is remove the family of each pruned node from its corresponding hypernode. We shall formalize this method now, but only after formalizing the notions of a query and that of pruning a belief network given a query.\nDefinition 5 Let E and Q be two sets of nodes in dag g and let e be an instantiation of nodes E.4 The pair ( e, Q) is called a query for dag g.\nThe intuition here is that e represents evidence about nodes E and Q represents nodes whose posterior prob abilities must be computed.\nGiven a belief network and a query (e, Q), not all nodes of the network may be relevant to the computa tion. In particular, any leaf node in the network which does not belong to either E or Q can be removed from the network. When this pruning operation is applied recursively, a large portion of the belief network may be pruned, which in turn may lead to a much sim pler jointree. Our goal, of course, is to reconfigure the originally constructed jointree so it corresponds to this pruned belief network. We put two constraints on ourselves, however: efficiency of reconfiguration, and reuse of previously performed computations. We will address these two constraints in the following two sec tions, but first we formalize the reconfiguration pro cess.\nDefinition 6 Let g be a dag and let q = ( e, Q) be a query for g. The pruning of g given q, denoted gq, is the dag which results from successively removing leaf nodes from g if they are not in E U Q.\nThis is a standard definition of pruning where removed leaf nodes are known as barren-nodes.\n3We have two choices when trying to perform inference with respect to the pruned belief network in Figure 4(b): We can directly compute a basic jointree for the network or we can reconfigure the basic jointree in Figure 4(a) for that purpose. We have opted for the second choice in order to generate a basic jointree which is as similar as possible to the original one. This is crucial for computation reuse as we shall discuss later.\n4 An instantiation of E contains one pair ( E, e) for each node E in E, where e is a value of node E.\nDefinition 7 Let g be a dag and T = (V, A, 1i) be a basic jointree for g {induced by a spanning tree of its family graph). Let q be a query for Q. The pruning of r given q, denoted rq' is a labeled tree (V, A, 1iq) where 1iq dg { 1ii, if i is a node in gq; i - 0, otherwise. That is, pruning a basic jointree is simply a matter of emptying the hypernode corresponding to each pruned node.\nTheorem 3 In Definition 7, the pruned tree Tq is guaranteed to be a basic jointree for the pruned dag gq.\nTherefore, Definition 7 can be viewed as a proposal for reconfiguring a basic jointree in response to a query change. The reconfiguration suggested by this defini tion leaves the structure of the basic jointree intact, but it may change the contents of its hypernodes, therefore, leading to a possible change in separators and cliques.\nWe will close this section by discussing how inference is performed in this framework of dynamic jointrees. The first thing to observe is that in the jointrees we have been generating, each clique ci has associated with it a single family; the family of node i. We will then associate the probability matrix of node i with clique Ci. Hence, initially, the local information associated with clique Ci is the matrix of node i multiplied by any likelihood vector representing evidence available about node i. If node i is pruned later, there will be no local information associated with its corresponding clique. For uniformity though, we assume that the local information is the unit potential 1 in such a case. From here on, we will use <Pi to represent the local information associated with clique ci under query q. Moreover, for each edge ( i, j), we will use <PiJ to denote nk \u00a2'\u00a3, where k is a node on the i-side of edge (i,j). We can now define the message from node i to node j under query q in the usual way:\nMij \ufffd L <Pi II M't,i. (1) Ci\\S'fi k=f.j\nNote, here, that messages, separators and cliques have superscripts q because they are now defined with re spect to a particular query q (and its pruned basic jointree Tq). To compute the probability distribution of a particular node i under query q, we can then use the standard formula:\nPrj = L <Pi II M't,i. Cf\\{i} k\n(2)\nPlease note that Equations 1 and 2 are nothing but the standard algorithm for jointrees as given in [4, 5]. The only difference, however, is that everything now is indexed by a query q.\n4 Reconfiguring a J ointree Efficiently\nReconfiguring a jointree in response to a query change involves two steps: (1) reconfiguring the underlying basic jointree; and (2) recomputing separators and cliques. To realize Step 1, all we have to do is de cide which nodes have been pruned from the underly ing dag given the current query and then update the hypernodes accordingly. Step 1 can be realized quite efficiently since pruning a belief network (according to Definition 6) can be done in time linear in the size of the network. Realizing Step 2, however, can be more involved since we must recompute 1iiJ n 1iji for each edge ( i, j) in the basic jointree (V, A, 1i). In the worst case, computing this intersection is quadratic in the number of nodes in the underlying dag.\nOne can do better than this, however, if one utilizes the following theorem.\nTheorem 4 Let (V, A, F) be a family graph and let (V, A', F) be one of its spanning trees. Let\nS d,;f {i: (i,j) E A and (i,j) (/A' for some j}.\nFor every edge (i,j) in A and A', Fii n FJi \\ {i} \ufffd S.\nFirst, note that S is the set of all nodes that have lost outgoing edges in the process of rendering the family graph singly connected. In Figure 5 for example, only one node, C, has lost an outgoing edge in this process. Therefore, S = { C} in this case.\nTheorem 4 is then saying that if a node k is shared by families on opposite sides of edge (i,j) (that is, k E FijnFJi), and if k =f i, then it must be a node that has lost an outgoing edge in the process of rendering the\n102 Darwiche\nfamily graph singly connected. The major implication of this theorem is:\nCorollary 1 Regarding the edge (i,j) in Theorem 4:\nConsider Figure 5 again where S = { C}. According to this corollary, the separator of any edge which extends from node i to node j can only contain node i and, possibly, Node C.\nTherefore, given Corollary 1, computing a separator is no longer quadratic in the number of nodes in the dag. It is only quadratic in the size of set S; that is, it is only quadratic in the number of nodes that have lost outgoing edges in the process of rendering the family graph singly connected.\nIn fact, Corollary 1 suggests a heuristic for construct ing jointrees from family graphs: minimize the number of nodes that will lose outgoing edges when rendering the family graph singly connected. Note that the size of any separator cannot exceed the size of set S plus 1; therefore, the previous heuristic will attempt to mini mize the size of separators.5\nWe have taken advantage of the above theorem in our implementation, which has led to an efficient compu tation of separators. This has made the time spent on reconfiguring jointrees insignificant compared to the achieved savings, as our experimental results will demonstrate later.\n5 Reusing Computations in Dynamic Jointrees\nWe now turn to the important issue of computation reuse. A key objective attempted by algorithms for be lief network inference is to reuse computations across different queries. That is, having computed the pos teriors of nodes Q given evidence e, algorithms save the results of their intermediate computations for the possibility of reusing them when trying to compute the posteriors of nodes Q' given evidence e'. In jointree algorithms, for example, if a message comes from a part of the jointree which did not involve a change in evidence, that message can be reused without having to recompute it again.\n5 An interesting implication of Corollary 4 is the follow ing result. Compute a loop-cutset of the family graph and generate a spanning tree by eliminating (from the graph) only edges that are outgoing from nodes in the loop-cutset. This is always possible by definition of a loop-cutset. Un der these conditions, we are guaranteed that no separator will have more than c + 1 nodes where c is the size of the loop-cutset.\nIn this section, we start by a theorem which states conditions under which a message computed with re spect to a basic jointree 'P1 will remain valid (can be reused) in the reconfigured basic jointree Tq2\u2022 Our re sults are with respect to a dag 9, its basic jointree T, and two corresponding queries q1 and q2.\nTheorem 5 For every edge ( i, j), if \u00a2 iJ S9? = S9\ufffd then M\ufffd\ufffd = M\ufffd\ufffd \u2022J \u2022J ' \u2022J \u2022J . = \"'\ufffd\ufffd and '\ufffd-'\u2022J\nThat is, if the local information associated with nodes on the i-side of edge (i,j) did not change when switch ing from query q1 to query q2, then the message from node i to node j can be reused. This is similar to message reuse in standard jointree algorithms except that standard algorithms do not check for the condi tion S'/J = S01; the condition always hold given that the jointree does not change.\nWe do have, however, an even stronger theorem which implies the one given above.\nTheorem 6 For every edge (i,j), if <Pi} S'fj \ufffd S'fJ , then\nMij = L Mij . S'/J \\S'[J\n= \"'\ufffd\ufffd and '\ufffd-'\u2022J\nThat is, even if the separator corresponding to a par ticular message does change as a result of changing the query, it may still be possible to reuse that message but only after marginalizing it.\nLet us consider an example illustrating the use of The orem 6. Figure 6(a) depicts a belief network and Fig ure 6(b) depicts its family graph. Suppose now that we have the query q1 = ( {}, { D}): we are interested in the prior distribution of Node D. The basic jointree in Figure 6(c) can be used to answer this query. Us ing Equations 1 and 2 to compute the distribution of\nNode D, we end up computing three messages: MAB, MBe and Men. Suppose now that the query changes to q2 = ( {}, { C}): we are now interested in the prior distribution of Node C. Node D becomes irrelevant and is pruned given this new query. Reconfiguring the basic jointree in Figure 6(c), we obtain the one in Figure 6(d). Note here the change in separators. In particular, the separator between Nodes B and C has changed from {A, B} to { B}. Since the local informa tion associated with Nodes A and B remain the same Theorem 6 tells us that '\nMQ2 - \"' Mql Be L....J Be\u00b7 {A}\nThat is, there is no need to recompute the message from Node B to Node C, we can simply reuse its pre vious value after we have marginalized it.\n6 Preliminary Experimental Results\nIf there are no query changes, our method will degen erate into the standard method for computing with jointrees, except possibly for the fact that we are con structing jointrees differently. However, if the query changes, then our method will reconfigure the jointree in response, reusing some - but not necessarily all - computations that have been performed with respect to the previous jointree.\nOur goal in this section is twofold. First, to substanti ate the claim that reconfiguring a jointree (as accom plished by our method) consumes insignificant time compared to the achieved savings. Second, to give an indication of the amount of saving possible as a result of reconfiguring a jointree.\nWe start by describing our experiments, that is, how we generated our belief networks and the correspond ing queries. Each belief network was generated given three parameters: the number of nodes, a probability distribution over sizes of families, and a graph-width parameter which controls the connectivity of gener ated networks. Each of the generated networks had, on average, 20% root nodes, 10% single-parent nodes, 2 5% two-parent nodes, 35% three-parent nodes and 10% four-parent nodes. The graph-width parameter was varied to generate networks with separators con taining up to 20 nodes.\nWe have conducted two sets of experiments. In the first, we attempted a standard computation: Compute the prior distribution of each leaf node in a belief net work (no evidence). However, we did this as follows. Given leaf nodes 1, 2, . .. , i, we have generated i queries ({},{1}), ({},{2}), . . . , ({},{i}). This has forced our algorithm to reconfigure the jointree before each query\nDynamic Jointrees 103\nis attempted. We have counted the number of addi tions and multiplications performed by our algorithm to compute these priors. We have also counted the same number of operations by running the algorithm but without reconfiguring the jointree.\nTable 1 depicts the results of this experiment. It shows ten sets of networks, each set containing 50 networks generated randomly using the same parameters. For each of the sets, the table shows the average and maxi mum saving factor: number of operations for the static jointree algorithm divided by the number of operations for the dynamic jointree algorithm. Note that for cer tain networks, the saving factor is as large as 282. 54! In fact, it appears that the more connected the network is, the higher the saving factor is. Table 1 supports this observation by showing the average size of the maximal separator for both dynamic and static jointrees. On average, it is clear that reconfiguring jointrees leads to reducing the size of the maximal separator.\nTable 1 also lists (in the last column) the ratio be tween the time spent reconfiguring jointrees and the time spent on standard inference - this is shown as a percentage. It should be clear from this table that this percentage is insignificant when viewed in light of the saving entailed by jointree reconfiguration. Again, no tice how this percentage gets smaller as the networks get more connected.\nThe second experiment involved changing evidence only. For this experiment, we picked up 10% of a net work's non-root nodes, instantiated them randomly, and then computed the posterior distribution for each root node in the network. We then considered each of the instantiated nodes in turn, changing the evidence on it randomly and recomputing the posterior distri bution of each root node. We repeated this process five times for each network.\nOur goal here was to generate a mixture of evidence changes, some leading to significant jointree reconfigu ration and others leading to no reconfiguration. Each of the five repetitions per network leads to a signifi cant jointree reconfiguration since evidence nodes are changing significantly. Within each repetition, how ever, no reconfiguration takes place since evidence nodes are the same - only their observed values change.\nTable 2 shows ten sets of networks, each set containing 50 networks generated randomly using the same pa rameters. The table shows the same indicators shown in Table 1. Note that Table 2 supports the same hy potheses supported by Table 1: The saving factor in creases as the networks become more connected; The time spent on reconfiguring jointrees is insignificant relative to the achieved savings; Dynamic reconfigura-\n104 Darwiche\ntion of jointrees does reduce the size of maximal sep arator on average; The savings due to reconfiguring jointrees can be quite significant, getting close to a factor of 300 in certain situations.\nThe reported experiments are by no means comprehen sive. However, they involve a total of 1000 networks with many queries attempted per network. Their in dications, therefore, are not to be underestimated.\n7 Conclusion\nThis paper is based on two contributions. First, a non classical definition of jointrees which stresses proper ties of jointrees that have not been given enough at tention in the literature. Second, an application of this non-classical definition to inference situations involv ing considerable query changes.\nFor these kind of situations, we have proposed to re configure the jointree as the query changes. We have also proposed a specific method for this reconfiguration and shown that it satisfies two important properties. First, it can be done efficiently. Second, it allows the reuse of some results computed before the reconfigu ration takes place.\nFinally, we provided a preliminary experimental anal ysis indicating that significant savings can be expected\nfrom reconfiguring jointrees in situations where query changes are considerable.\nReferences\n[1] Adnan Darwiche. Dynamic jointrees. Technical Report 98-03, Department of Mathematics, Amer ican University of Beirut, 1998.\n[2] Denise L. Draper. Clustering without (think ing about) triangulation. In Proceedings of the 11th Conference on Uncertainty in Artificial In telligence (UAI}, pages 125-133, 1995.\n[3] F. V. Jensen, S.L. Lauritzen, and K.G. Olesen. Bayesian updating in recursive graphical models by local computation. Computational Statistics Quar terly, 4:269-282, 1990.\n[4] R. Shachter, S.K. Andersen, and P. Szolovits. Global Conditioning for Probabilistic Inference in Belief Networks. In Proc. Tenth Conference on Un certainty in AI, pages 514-522, Seattle WA, 1994.\n[5] Prakash P. Shenoy and Glenn Shafer. Propagating belief functions with local computations. IEEE Ex pert, 1(3):43-52, 1986."}], "references": [{"title": "Dynamic jointrees", "author": ["Adnan Darwiche"], "venue": "Technical Report 98-03, Department of Mathematics, Amer\u00ad ican University of Beirut,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 1998}, {"title": "Clustering without (think\u00ad ing about) triangulation", "author": ["Denise L. Draper"], "venue": "In Proceedings of the 11th Conference on Uncertainty in Artificial In\u00ad telligence (UAI},", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 1995}, {"title": "Bayesian updating in recursive graphical models by local computation", "author": ["F.V. Jensen", "S.L. Lauritzen", "K.G. Olesen"], "venue": "Computational Statistics Quar\u00ad terly,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 1990}, {"title": "Global Conditioning for Probabilistic Inference in Belief Networks", "author": ["R. Shachter", "S.K. Andersen", "P. Szolovits"], "venue": "In Proc. Tenth Conference on Un\u00ad certainty in AI,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 1994}, {"title": "Propagating belief functions with local computations", "author": ["Prakash P. Shenoy", "Glenn Shafer"], "venue": "IEEE Ex\u00ad pert,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 1986}], "referenceMentions": [{"referenceID": 2, "context": "There is a number of algorithms for exact inference in belief networks, but the ones based on jointrees seem to be the most dominant [3, 4, 5].", "startOffset": 133, "endOffset": 142}, {"referenceID": 3, "context": "There is a number of algorithms for exact inference in belief networks, but the ones based on jointrees seem to be the most dominant [3, 4, 5].", "startOffset": 133, "endOffset": 142}, {"referenceID": 4, "context": "There is a number of algorithms for exact inference in belief networks, but the ones based on jointrees seem to be the most dominant [3, 4, 5].", "startOffset": 133, "endOffset": 142}, {"referenceID": 0, "context": "Proofs of all theorems can be found in [1].", "startOffset": 39, "endOffset": 42}, {"referenceID": 1, "context": "2It appears that our method for constructing jointrees can be justified using the transformation approach given in [2].", "startOffset": 115, "endOffset": 118}, {"referenceID": 1, "context": "In particular, computing a spanning tree of the family graph can be viewed as successively applying the collapse transformation to the trivial cluster graph as defined in [2].", "startOffset": 171, "endOffset": 174}, {"referenceID": 3, "context": "Please note that Equations 1 and 2 are nothing but the standard algorithm for jointrees as given in [4, 5].", "startOffset": 100, "endOffset": 106}, {"referenceID": 4, "context": "Please note that Equations 1 and 2 are nothing but the standard algorithm for jointrees as given in [4, 5].", "startOffset": 100, "endOffset": 106}], "year": 2011, "abstractText": "It is well known that one can ignore parts of a belief network when computing answers to certain probabilistic queries. It is also well known that the ignorable parts (if any) de\u00ad pend on the specific query of interest and, therefore, may change as the query changes. Algorithms based on jointrees, however, do not seem to take computational advantage of these facts given that they typically con\u00ad struct jointrees for worst-case queries; that is, queries for which every part of the belief net\u00ad work is considered relevant. To address this limitation, we propose in this paper a method for reconfiguring jointrees dynamically as the query changes. The reconfiguration process aims at maintaining a jointree which corre\u00ad sponds to the underlying belief network after it has been pruned given the current query. Our reconfiguration method is marked by three characteristics: (a) it is based on a non\u00ad classical definition of jointrees; (b) it is rela\u00ad tively efficient; and (c) it can reuse some of the computations performed before a jointree is reconfigured. We present preliminary ex\u00ad perimental results which demonstrate signif\u00ad icant savings over using static jointrees when query changes are considerable.", "creator": "pdftk 1.41 - www.pdftk.com"}}}