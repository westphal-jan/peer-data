{"id": "1301.7407", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "30-Jan-2013", "title": "Learning From What You Don't Observe", "abstract": "The process of diagnosis involves learning about the state of a system from various observations of symptoms or findings about the system. Sophisticated Bayesian (and other) algorithms have been developed to revise and maintain beliefs about the system as observations are made. Nonetheless, diagnostic models have tended to ignore some common sense reasoning exploited by human diagnosticians; In particular, one can learn from which observations have not been made, in the spirit of conversational implicature. There are two concepts that we describe to extract information from the observations not made. First, some symptoms, if present, are more likely to be reported before others. Second, most human diagnosticians and expert systems are economical in their data-gathering, searching first where they are more likely to find symptoms present. Thus, there is a desirable bias toward reporting symptoms that are present. We develop a simple model for these concepts that can significantly improve diagnostic inference.\n\n\n\nThe following two systems offer different ways to perform diagnosis. First, we are required to identify patterns of illness, such as the frequency and severity of the symptoms. Second, if symptoms are present, they are more likely to become reported before others. The second system, we are required to identify patterns of illness, such as the frequency and severity of the symptoms. Third, if symptoms are present, they are more likely to become reported before others. Third, if symptoms are present, they are more likely to become reported before others. Finally, if symptoms are present, they are more likely to become reported before others. Finally, if symptoms are present, they are more likely to become reported before others.\nWe develop a model for these concepts that can significantly improve diagnostic inference. First, we are required to identify patterns of illness, such as the frequency and severity of the symptoms. Third, if symptoms are present, they are more likely to become reported before others. We develop a model for these concepts that can significantly improve diagnostic inference. First, if symptoms are present, they are more likely to become reported before others. Finally, if symptoms are present, they are more likely to become reported before others. Finally, if symptoms are present, they are more likely to become reported before others. Finally, if symptoms are present, they are more likely to become reported before others. Finally, if symptoms are present, they are more likely to become reported before others. Finally, if symptoms are present, they are more likely to become reported before others. Finally, if symptoms are present, they are more likely to become reported", "histories": [["v1", "Wed, 30 Jan 2013 15:06:25 GMT  (411kb)", "http://arxiv.org/abs/1301.7407v1", "Appears in Proceedings of the Fourteenth Conference on Uncertainty in Artificial Intelligence (UAI1998)"]], "COMMENTS": "Appears in Proceedings of the Fourteenth Conference on Uncertainty in Artificial Intelligence (UAI1998)", "reviews": [], "SUBJECTS": "cs.AI", "authors": ["mark alan peot", "ross d shachter"], "accepted": false, "id": "1301.7407"}, "pdf": {"name": "1301.7407.pdf", "metadata": {"source": "CRF", "title": "Learning From What You Don't Observe", "authors": ["Mark A. Peot", "Arthur Conan Doyle"], "emails": [], "sections": [{"heading": null, "text": "In order to e\u00b7xtract information from the observations not made, we propose the following two concepts. First, some symptoms, if present, are more likely to be reported before others. Second, most human diagnosticians and expert systems are economical in their data-gathering, searching first where they are more likely to find symptoms present. Thus, there is a desirable bias toward reporting symptoms that are present. We develop a simple model for these concepts that can significantly improve diagnostic inference.\n1 INTRODUCTION\n''Is there any point to which you would wish to draw my attention?\"\n\"To the curious incident of the dog in the night time.\"\n\"The dog did nothing in the night-time.\"\n\"That was the curious incident,\" remarked Sherlock Holmes.\n- from Silver Blaze by Sir Arthur Conan Doyle This paper argues that the current practice for modeling missing observations in interactive Bayesian expert systems is incorrect. If there is no reported value for a chance node in a belief network, it is usually assumed that that chance node is unobserved and that this unobserved\nnode contributes no likelihood information to the rest of the belief network. If this chance node has no graphical successors, then it is barren [Shachter, 86]: the joint distribution of the other variables in the belief network is not a function of the distribution of the unobserved node.\nIn interactive diagnostic expert systems, however, there is a systematic bias introduced by people's preferences for reporting that can lead to systematic errors in diagnosis. In medicine, common sources of reporting biases might include:\na bias to report symptoms that are present instead of\nsymptoms that are absent, or\na bias to report symptoms that are more significant or\nurgent instead of symptoms that are less obviously urgent.\nFailure to model these biases can lead an expert system to produce erroneous recommendations early in the diagnostic process. If these biases are explicitly modeled, we demonstrate that early diagnostic differentials are more focussed, leading to more focussed question asking. Furthermore, the observations that the user of the expert system chooses to reveal inform on the likelihoods of unobserved variables.\nThe primary objective of this paper is to describe a simple mechanism for modeling biases in the responses to open probe questions in diagnostic expert systems. Open probe questions are unstructured questions that give the user freedom to choose the order that information is revealed. Section 2 describes open and closed probe questions and demonstrates that the responses to open probe questions do influence the probabilities of unobserved symptoms in diagnostic belief nets. Section 3 introduces the report node-a mechanism for modeling open probe questions in diagnostic domains comprised of unrelated symptoms of comparable severity. Section 4 shows how the simple report mechanism can be modified to allow the expert system to infer a particular user's biases from their responses to open probe questions. Section 5 introduce\ufffd a technique for handling symptoms that vary in perceived severity. Finally, Section 6 relates the report mechanism to concepts in linguistics, specifically conversational implicature and scalar implicature.\n440 Peot and Shachter\n2 OPEN AND CLOSED PROBES\nQuestions in a diagnosis domain can be grouped into two general categories, open and closed probes. Closed probes are requests for specific items of information. Examples of closed probes include: \"Is the patient male or female?\" Or \"Is the patient running a fever?\" Closed probes tend to discourage the user of the expert system from volunteering more than just the requested information. An open probe is a more general request for information that allows the user to select from a plethora of possible responses. Examples of open probes might include: \"What brings you to the doctor today?\" or \"What looks abnormal on the patient's CT scan?''\nOpen probe questions are more informative than closed probe questions even if the same observations are made. For example, suppose that a doctor starts a patient interview with the closed probe question: \"Do you have a rash?\" The response to this question (\"Yes\" or \"No\") will lead the doctor to adjust the probabilities of diseases that are conditionally relevant to the observation. The response will have no effect on the belief inferred for other diseases.\nSay instead that the doctor starts the interview with the open probe question: \"What is bothering you today?\" The patient responds, \"I have a rash.\" In this case, the doctor can conclude far more. In addition to the fact \"Rash = true\", the doctor might also reduce her belief that competing symptoms are present, especially if those symptoms are more severe. For example, the doctor might infer that it is unlikely that the patient is presenting with a severe headache or clenching chest pain; because if the patient were experiencing those symptoms, the patient would have mentioned them. This, in turn, decreases the probability that a non-rash-related disorder is present; focussing the doctor's subsequent question asking only on rash-related diseases.\nBayesian expert systems do not properly model the open probe phase of the patient interview process. In order to see why, we will consider the simple diagnostic belief network illustrated in Figure I. In this figure, there are 4 binary chance nodes representing two competing diseases, Poison Ivy (PI) and Migraine (M), with their associated symptoms, Rash (R) and Headache (H). Each of these nodes is binary with values absent and present. Poison ivy causes rash and migraine causes headache.\nwe set the value of \"Rash\" in the belief network to \"present.\" Based on this single observation, we conclude that the probability that poison ivy is present will change, while the probability that a migraine is present will be unchanged.\nFigure 2: A belief network modeling a patient's response to an open probe question.\nNow imagine that we ask the open probe question: \"What is your problem?\" If the patient responds that he has a rash and says nothing at all about the presence or absence of a headache, then we argue that the probability we should assign to headache (and migraine) should be reduced (or at least change).\nThe patient's response to the open probe question is a function of all of the symptoms si that he is experiencing at the time that the question is asked as well as the history of interaction between the patient and the diagnostician and other external factors. This situation is illustrated in Figure 2. Response is a chance node that represents the patient's response to the open probe question. Response is a function of the presence or absence of each of the symptoms as well as the possibly-observable external factors node. The values for the Response variable include all of the possible responses that the patient might make when answering the open probe. Possibilities in this instance might include \"I have a headache,\" or \"I have a headache and a rash,\" \"I hate it when you ask me all of these annoying questions,\" etc.\nBecause the patient's response to the open probe is a function of all of the symptoms that might influence the patient's chosen utterance, the response to the open probe should change our belief concerning every symptom that can influence the response. In this instance, we would argue that the patient would have a relatively high probability of reporting a severe headache if one were present. Since the patient did not choose to report any information about a headache, we can conclude that the patient probably does not have one.\n2.1 THE IMPACT OF OPEN PROBE QUESTIONS ON EXPERT SYSTEMS\nHow does this problem manifest in a diagnostic expert system?\nThe architecture of a typical diagnostic expert system is illustrated in Figure 3. This expert system is based on the\nhypothetico-deductive (H-D) cycle [Gorry+Barnett, 68; Miller, et al, 82; Horvitz, et al, 84]. In the H-D cycle, the user initiates diagnosis by presenting a (possibly empty) set of salient observations to the expert system. These observations are fed into the expert system based on the implicit open probe, \"What features describe your problem?\" Based on these salient observations, the expert system computes a probability distribution P(D;) (called a differential diagnosis) over the possible fault or disease hypotheses D;. After observing the initial differential diagnosis, the user can elect to act on this diagnosis or to refine the differential by answering further questions. In an expert system tool like Knowledge Industries' WIN-DX or Microsoft's MSBN system, some form of information value analysis [Howard 66; 67] is used to select the best observations to narrow the differential diagnosis. After the user answers one or more of these questions, the expert system formulates a new differential diagnosis and the cycle repeats.\nIn our example, the patient might enter the observation Rash = present in order to seed the diagnostic process. In the typical Bayesian expert system, a closed probe model (Fig. 1) is used to evaluate the response to the open probe question (Fig. 2). As a result, the expert system will over estimate the probability of symptoms the diseases that compete with poison ivy (e.g. migraine). This, in turn, causes the expert system to ask seemingly irrelevant questions in order to rule out competing diseases, even though no evidence has been presented that would lead the expert system to suspect that these diseases were present.\n3 BASIC REPORT NODES\nIf we were really clever (Turing Award clever), we could assess the outcomes and probability distribution for the Response variable in Figure 2. We (unfortunately) are significantly less clever, so we propose just to roughly model the likelihood and independence properties of the portions of the belief network surrounding Response.\nFigure 4 illustrates the likelihoods resulting from observing Response to be \"rash.\" The report node mechanism (to be defined) is based on the following two assumptions about these likelihoods:\nLearning From What You Don't Observe 441\n1. Veridicality: The user's response corresponds to the facts; that is, if the responder says that they have symptom S, then symptom S is present with probabil ity 1.0. This assumption allows us to assume that A.+ (See Fig 4) is the same whether node Rash is observed directly or not.\n2. Likelihood Independence: The likelihoods A.-(S) for symptoms that are not mentioned are mutually inde pendent.1\nFigure 4: Likelihood feedback from Response.\nGiven these assumptions, we can derive a simpler network model (Figure 5) that has the same independence and likelihood properties as the network of Figure 4. We replace the Response node with a series of binary report nodes, ReportQ(S;); one for each symptom S; that is a predecessor of the old Response variable.\nFigure 5: Approximating the response likelihood using Report.\nThe report node ReportQ(S;) represents the event: \"A value is reported for symptom S; in response to an open probe question Q.\" ReportQ(S;) is true if any value is observed for S; and is false otherwise.\nNote that if all of the symptom nodes were to be observed that the report nodes become independent from the remainder of the network. The report node mechanism is designed to capture the reporting biases for symptoms immediately after an open probe question is answered. Subsequent closed probe questioning on these unobserved symptoms will \"wash away\" the effect of the report nodes\n1 We will relax this assumption in the next section.\n442 Peot and Shachter\non those symptoms, D-separating [Geiger, et al; 90] the report nodes from the rest of the network.\n3.1 ASSESSMENT: REPORTABILITY AND REPORTING BIAS\nThe probability distribution for ReportQ(S;) can be assessed directly. We have found it useful, however, to factor the assessment. First we aggregate symptom values into two categories: present and absent. For each symptom, we assess P{ReportQ(Si) I Si =present}, the probability that the symptom will be reported given that it is abnormal. We will call this probability the reportability of the symptom, P Q(Si). Symptoms that are more evocative will tend to have a higher reportability. Subtle symptoms will tend to have a lower reportability.\nThe second parameter that we assess is the reporting bias for the symptom. This is the likelihood ratio\nP{ReportQ(S;} IS;= present} BQ(S;) P{ReportQ(S;} iS;- absent}\nThe reporting bias captures the fact that people are more likely to report the presence of a symptom rather than the absence of that symptom (recall the quotation at the start of the paper). If the reporting bias is greater than or equal to 1, the reportability and reporting bias together specify a single unique conditional probability distribution for the report node.\nIn order to minimize the number of parameters that have to be assessed for a model, we can assume that the reporting bias is constant for all symptoms in the knowledge base. With this assumption, we only need to assess one parameter, reportability, for each symptom in the knowledge base. We can reduce the burden of assessment still further by assessing reportability for groups of symptoms rather than the individual symptoms themselves.\nExample: Suppose that an expert system for dermatology proceeds sequentially through the following two phases of question-asking:\n1. Open probe (Initial complaint) phase: The user selects any number of symptoms from a menu of complaints, pressing OK when done.\n2. Closed probe phase: The diagnosis system uses infor mation value analysis to select subsequent questions for the user to answer.\nOur task is to assess a distribution for Report1nu(Rash). Rash can be either a bumpy blue rash, an itchy red rash, or absent. In this case, the two types of rash are considered to have roughly the same reportability. The knowledge engineer feels that it is highly likely that the patient will report either of these rashes and assigns them a reportability of 0.95. The knowledge engineer had previously assigned a reporting bias of 5 to the entire knowledge base, indicating that the patient is 5 times more likely to report a symptom when the symptom is present.\nThe conditional probability P{ReportiniiRash) I Rash} is\nRash = present Report1nu(Rash) PQ = 0.95\n-,Report/nil Rash) 1- PQ = 0.05\ndistribution\nRash= absent\nPQ \"]J; = 0.19\nQ\np 1- \"]J;Q = 0.81\nQ\n3.2 REPORT ABILITY, REPORTING BIAS AND INFERENCE\nfor\nAs mentioned earlier, observing symptom Si renders the report node ReportQ(Si) independent of the rest of the belief network. Thus, only the likelihood ratio"}, {"heading": "P{ -.ReportQ(S;) IS;= present} _ BQ( 1 - P Q)", "text": "P{\ufffdeportQ(S;) IS;- absent} - BQ- P Q\nhas an effect on inference, providing a default likelihood function for each unobserved symptom. We call this likelihood function, the relative likelihood of no report or A.\"Q( S;) . As the reportability, P Q\u2022 for Si approaches 1 (meaning that present symptoms are always reported),\nA.\"Q( S;) tends to 0, implying that if symptom Si is not reported, it is almost certain that Si is absent. As the\nreportability for the symptom approaches 0, A.\"Q approaches 1; indicating that if there is only a low probability that si will be reported if present, we should not assume that Si is absent if there is no report.\n3.3 CUBITAL 1UNNEL EXAMPLE\nWe tested the report node mechanism on the nerve compression disorder knowledge base (or CTS, after the most prominent disorder, carpal tunnel syndrome, in the KB). The CTS knowledge base was designed by a hand surgeon for evaluation of patients that were referred to his clinic with a preliminary diagnosis of a nerve compression injury affecting the hands or arms. Since the patients seen at this clinic have been referred by other doctors, the prior probabilities for many of the disorders are extremely large. For example, more than three-quarters of the patients in this clinic present with carpal tunnel syndrome.\nWe were interested in modeling the patient's response to an initial complaint question, such as \"What is bothering you?\" The response to this question can include any or all of the symptoms2 in the knowledge base.\nWe modeled the bias in the response to this question by adding a report node successor to each of the symptoms that might reported in response to this question. In order to simplify the assessment process, we assumed a single\n2 As seen in Figure 6, there are four classes of observations: signs (obser vations made by the doctor), symptoms (observations made by the patient), test results and predisposing factors.\nLearning From What You Don't Observe 443\nr nlc Alcohol Abuse Predisposing CNec\ufffdMRI\ufffd \ufffd Hypothyroid Diabetes \ufffd Factors ( Chest MRI) ---..._ 1-------- \ufffdhroni\ufffd Ren\u20ac><;[eavy Metal - Disease]:>\n\ufffdrvical Spine X-Rau, I CCervlcal Rib X-R\ufffd\n,._______ \ufffdripheral Neuropat\ufffd\n\ufffdrvical Radlculopa![: r:\u00a3ower Trunk EMG/NCS 1- \ufffdchlal Plexop\ufffd Jc::farpal T!!.(lnel EMG:::l. \ufffdonator TeresE\ufffd\n( Guyon's EMD.\n@bitaiTunne\ufffd @artenburg's \ufffd\nRadiology & EMG/NCS\nY Spurlinj!'s Test \ufffd I;!Eiateral Hands and Feew r-----.\nQ_hree minute;:::> KTinel'! base -\nhenarWeak Phalen's tesQ_ \ufffd ----- !!net's median wri!: J! (Tinel's ulnar\ufffdntrins\ufffd W I Qlnel's medl\ufffd ( Volar t:,orea':!: ::!lnel's Ulnar--.,_ \ufffdoulder and U f1i_nel's dlsta\nradial volar 3. ..JtJ.\nulnar 1.5 se\n(radial dorsa\nSigns\n. CJ\"eripheral NeuropathY \ufffdrvical Radicu lopatiii:\n<;:: Pancoast tumor:::>j' v rachial Plexopat\ufffd\n\ufffd:\u00a3\ufffd \ufffdarpal Tunnelr / )..\n\"Tl'ionator Te\ufffd \ufffd \ufffdGuyon's Syndro!Q_ \"-/ \ufffd rS\" ...__cubital Tunnell'// x venburg\u2022s: \ufffd\nDisorders\nNerve Compression Disorders of the Hand Created by Alex Dapm, M.D.\nI \ufffd!lateral !;!ands arie' I ne=..k p \ufffd cmer Trunk Con\nN\" \ufffd J <:]fadlation of e_aln +1- num\u00a7E .\u00a31-3.5 R?1-3.5 Radial Finge\ufffd - \"--._ '\\l (1-1.5Uin \\ l ...:- Hand weakness \ufffd .5- 2 Ulnar FiiiO'l. \ufffdight time numbn Radial Dorsal :2_ ::><::\":\" \ufffddiation of p'!!_n into Ulnar .<lli:> adia\ufffdon of pain into Radial \ufffd Ulnar r \ufffd C:: Radial Radi iation of pain \ufffdto Radial Dors@l:> '\\::EI\ufffd Pair!:2_\n_3.. C:::::Eibcm Part\u00b7 (Fore!!m P!)_ C Forearm F\nSymptoms\nr::>\nsF'\nadi\ntio\nlion\nR Bilateral Hands ,::::::;, \"' <::: Reportability :::> \ufffd R.Neck\ufffd c; R Radiation from Neck -:::? /7I-/,\ufffd .r- R 1-3.5 Radial Finger if_ Y'\"s;a0\n111!1 K R 1.5-2 Ulnar -c. R. Hand Weakn '){'\nC R Nighttime Numbness -:;> _u 'Y\u00b7y . C R. Dorsal Numbness\nlot ::2 M !Jf!/ / _ C R 1.5-2 Ulnar Radiation:::> 2 /lt1, C::: R 1-3.5 Radial Radiation A',\nC R. Radiation Dorsum ::::> -.::...__ R Elbcm Pain\n.1_ \ufffdrtit n R Forearm Pain\nReport Nodes & Reporting Parameters\nFigure 6: Nerve CompressiOn Dtsorders of the Hand\nglobal value for the reporting bias, Batobat and the reportability, P Global , for all of the report nodes.\nFigure 7 illustrates the effect of the reporting mechanism on the differential diagnosis as a function of Baiobai. In this example, the reportability, Paiobai, is set to 0.9. We entered three of the symptoms of cubital tunnel syndrome, a disorder caused by compression of the ulnar nerve where it passes through the cubital fossa (the \"funny bone\"). The symptoms:\n1. Numbness or pain on both the volar (palm) and dorsal surfaces of the ulnar fingers (pinky and ring finger),\n2. Radiation of pain into both the dorsal and volar surfaces of the ulnar fingers, and\n3. Elbow pain with radiation of pain toward the hand.\nFigure 7 was prepared by recording the probabilities for cubital tunnel syndrome and the next four leading disorders as a function of Baiobai\u00b7 If Baiobai is 1, the report nodes have no effect on the differential diagnosis. The probabilities for competing disorders are large because no symptoms have been observed that would rule these disorders out. In particular, note that carpal tunnel syndrome has nearly as high a probability as cubital tunnel syndrome, owing solely to its higher prior distribution.\nAs we increase the reporting bias, the probabilities for competing disorders drop by over an order of magnitude. The rate that the competing disorders drop in probability is different for each disease; probabilities for disorders with\nmany obvious, but unobserved, symptoms will tend to be decrease more than the probabilities of disorders with less obvious symptoms. If only a subset of the 'classic' symptoms of a disorder are entered, the primary diagnosis will also drop in probability, however the drop will tend to be less than that of disorders that have no positive findings.\nQ) U) :g U) 0 0.1 0 \ufffd :c \ufffd 0.01 e a..\n0.001 2 4 8 16 32\nBias -<>--Cubital Tunnel Syndrome -G- Carpal Tunnel Syndrome __._Peripheral Neuropathy -*-Guyon's Syndrome --)K- Thoracic Outlet Syndrome\nFigure 7: Differential diagnosis for the cubital tunnel syndrome case as a function of the global reporting bias Balobal\u00b7\nNote that increasing bias focuses the initial diagnosis on those disorders that are relevant to the reported symptoms. Increasing either the report bias or the reportability further focuses the differential diagnosis.\n444 Peot and Shachter\n4 LEARNING ABOUT REPORT ABILITY\nIn the next two sections, we will describe ways to relax the likelihood independence assumption. In Section 5, we will model the interaction between the report nodes for symptoms of differing severities. In this section, we relate the likelihoods for the report nodes through uncertain global reportability and reporting bias variables.\nThe reporting preferences for individuals can be very different. For example, one patient might be more forthcoming about his symptoms, reporting the absence or presence of a multitude of symptoms. Another patient might be more reticent, reporting just a few abnormal symptoms. Can the reporting mechanism be applied to patients with widely varying reporting preferences?\nAs long as the patient obeys the veridicality assumption (e.g. he doesn't lie or indulge in strategic (gaming) behavior) and the reportabilities and biases for symptoms change proportionally, the answer is yes. It is relatively straight forward to adapt the report node mechanism to permit learning of the bias and reportability parameters for a patient, either based on the results of a single interview or multiple interviews.\nThe technique that we use is to condition the individual report nodes on chance nodes, PGtobat and BGtobat, representing the global reportability and reporting bias for the knowledge base (see the far right side of Fig. 6). The reportability and bias for the individual report nodes can be any increasing function of these global reportability and reporting bias parameters. In the CTS knowledge base, we assume that the reportability and reporting bias for each of report nodes is the same as the global reportability.\nWhen report nodes are instantiated, they update the densities for these global parameters. If a symptom is reported to be present or absent, the distribution over P Global is multiplied by the likelihood function A.( P Global) = P Global \u2022 If a symptom is not reported, the likelihood function used for updating PGtobat can't be factored from the rest of the network, but resembles a function of the form A.( P Global) = C- P Global where C ;::: 1 is a constant that depends on the probability that the symptom is actually absent and the value of the global bias. The likelihood functions for reportability roughly resemble those found in the conjugate beta distribution, however the distribution over reportability is not a conjugate distribution.\nThe likelihood update for the bias parameter BGtobat is a strong function of whether the symptom is present or absent. If mostly present symptoms are observed, probability for higher biases will increase (as expected). If more absent symptoms are observed, the expectation of the reporting bias decreases.\nFigure 8 illustrates how the distribution over the global report bias and reportability changes with the number and type of observations in the CTS knowledge base. Since the\nreportability and bias variables cannot be represented using a conjugate distribution, we broke up the reportability and bias variables into a number of discrete values.3 We assigned an equal prior probability to each of these values in order to enhance the effect of the report node likelihood functions. Each column in the chart illustrates the posterior belief for reportability and reporting bias as a function of the number and type of observations. All of the report nodes are instantiated in each of the cases-the value for each report node is set to true if its associated symptom is observed and is false otherwise.\nThe far left column illustrates the belief in the reportability and report bias when no observations are entered in response to the initial complaint query. The expectation for the reportability is low (as expected). As more findings are observed, the expectation of reportability increases, regardless of whether the symptom reported is present or absent. Reportability, then, is primarily a function of the number of symptoms observed.\nThe reporting bias, on the other hand, is a strong function of whether the individual reports are present or absent. The middle columns of the figure illustrate how the expectation for the bias increases as more and more present symptoms are reported. The single report of absent (far right column) lowers the expectation of the bias.\n5 REPORTING AND SEVERITY\nIn this section, we will consider the interaction between reports for symptoms of differing severities. If one symptom is perceived to be more severe than another, we\n3 An alternative approach might be to use an optimization routine to iden tify the setting for P Global and Bctobal that maximizes the probability of evidence for the entire network.\nmight expect that the reportability for the first symptom is greater than that of the second. Furthermore, if a patient reports a number of mild symptoms at the start of an interview, we might conclude that it is extremely unlikely that a more severe symptom is present. In this section, we present a simple model that captures both of these kinds of inferences.\nThroughout this section, we will consider only two classes\nof symptoms: major symptoms {S\ufffd, ... , s:} and minor symptoms {Si, ... , s;;}. Two uncertain global parameters, P Major and P Minor , will be used to model the reportabilities for major and minor symptoms, respectively.\nOne possible belief network architecture that we might choose is to condition the reportability of the minor symptoms P Minor on a the presence of (possibly unreported) major symptoms. For example, we can reducing the minor symptom reportability whenever the\nboolean expression (S\ufffd =present) v ... v cs: =present) is true.\nWe propose an alternative technique (Figure 9). The reportability for the major symptoms, P Major , is a function h( P Minor) of the reportability for the minor symptoms. This function satisfies the following properties.\n1. Increasing reportability: h is strictly increasing on (0, 1). That is h(PMinor) > PMinor when PMinor E (0, 1).\n2. Probability: 't:f(PMinorE [0, 1]),h(PMinor)E [0, 1]\n3. Decreasing odds ratio: h(PMinor)l PMinor is decreasing.\nIt is easy to identify functions that satisfy these conditions. One such function is h(x) = 2x -x2\u2022\nIncreasing reponability ensures that the reportability of major symptoms is larger than the reportability of minor symptoms. Decreasing odds ratio guarantees the following: The change in expectation of reportability increases more when a minor symptom is reported to be present than if a major symptom is reported to be present. If this property is true, a report of a minor symptom will greatly increase the relative likelihood of no report for a major symptom, but the report of a major symptom will\nLearning From What You Don't Observe 445\nhave a smaller effect on A.Q . This means that if one or more minor symptoms is reported to be present and no major symptoms have been reported, then it is plausible to believe that no major symptoms are present. The converse is not true to the same degree.\nFor example, suppose that the prior probabilities for the disorders in Figure 9 are both 0.01. Rash and Chest Pain are both perfect observations-each symptom is present if and only if the corresponding disease is present. The prior distribution of PMinor is a uniform distribution and p Major = 2P Minor- p\ufffdinor. If we observe rash to be present and chest pain is unreported, the probability of heart attack drops from a prior value of 0.0 1 to 0.00 18. On the other hand, if we observe chest pain to be present and rash is unreported, the probability of rash drops from a prior of 0.0 1 to 0.004-a much smaller drop.\n6 RELATEDWORK\nOur research on reportability seems strongly related to linguistics research on conversational implicature. Conversational implicature is based on the observation [Grice, 1975] that the participants in a conversation generally and cooperatively adhere to a set of conventions for generating contributions to that conversation. This cooperative principle allows the listener to infer more from a conversation than is literally expressed. Say that a speaker remarks \"I have three children.\" This statement is literally true if the speaker has three, four, or twelve children. It is usually assumed, however, that if the speaker could have made a stronger claim (\"I have twelve children.\"), he would have.\nGrice's Maxims of Conversation [ 1967] represent an attempt (the most influential) to capture the conventions that govern the generation and interpretation of utterances in a conversation. Two of these maxims are relevant to the research reported in this paper, the Maxim of Quality and the Maxim of Quantity.\nThe Maxim of Quality says that a speaker should not say what he knows to be false and should not make any claims for which he lacks evidence. Veridicality (Section 3) is the assumption that the user of a diagnostic system will adhere to the Maxim of Quality.\nGrice's Maxim of Quantity states that the speaker should make the strongest statement supported by the evidence available to him and not make a statement that is stronger. One classic example of this is the statement \"Some of the apples are ripe.\" The Maxim of Quantity allows us to conclude from this statement that some of the apples are not ripe, because if all of the apples were ripe, the speaker would have said so. Our scheme for the interpretation of open probe questions relies on two quantity implicatures:\n1. the assumption that a patient will report symptoms that are present more readily than symptoms that are absent, and\n446 Peot and Shachter\n2. the assumpton that a speaker will tend to report more severe symptoms before those that are less severe.\nThis second implicature appears to be a kind of scalar implicature [Levinson, 83]. An implicational scale is a set of expressions of the same grammatical category that are linearly ordered in terms of their informativeness. For example, {all, many, some} constitute an implicational scale from the more informative \"all\" to the less informative \"some.\" Now consider the statements \"All of the apples are ripe,\" \"Many of the apples are ripe,\" and \"Some of the apples are ripe.\" Sentences using more informative terms from an implicational scale tend to imply that weaker statements are true. For example, \"Many of the apples are ripe\" implies that \"Some of the apples are ripe.\" Sentences using less informative statements tend to imply that stronger statements are false. For example, \"Many of the apples are ripe\" implies that the stronger statement \"All of the apples are ripe\" is false. In our work, symptoms of varying perceived severities appear to form a partial order similar to an implicational scale. A solitary report of a less severe symptom implies that a more severe symptom is absent. A solitary report of a severe symptom, on the other hand, does not seem to imply the absence of a lesser symptom quite as strongly.\n7 CONCLUSIONS\nWe have presented a simple technique for capturing two kinds of reporting preferences for answers to open probe questions: The first is a preference for reporting present symptoms over absent symptoms. The second is a preference for reporting more severe symptoms before those that are less severe. These two techniques allow us to use the answers to open probes to infer not only the values for reported symptoms, but also to infer likelihood functions for unobserved symptoms. The likelihoods resulting from these unobserved symptoms has the effect of focussing the differential diagnosis, resulting in more focussed question asking. The technique is easy to apply, seems effective, and corrects a potentially serious source of bias in probabilistic expert systems.\nIt seems plausible that we might improve our model of open probe questions by exploiting contemporary research in linguistics. There is a question, though, about whether this is worth it. The primary effect of changing the open probe model is to change the observation order in the sequence of closed probe question-asking following the initial open probe. The final diagnosis may not be a strong function of the observation order. None-the-less, this seems to be a fruitful area for further experimentation and analysis.\nAcknowledgments\nAlex Dagum (U. Toronto) developed the CTS knowledge base using Knowledge Industries' DXPress\u2122 expert system tool. Eugene Charniak (Brown) first pointed out the link between reportability and conversational implicature. R. Michael Young (Pittsburg) and Barbara\nGrosz (Harvard) introduced us to scalar implicature. Denise Draper (Rockwell) made many useful presentation suggestions. We benefited greatly from the Summer Institute of Linguistics web-based glossary (www.sil.org) and Jeanne Frommer's web-based summary of Pragmatics.\nReferences\n[Doyle, 1892] Doyle, Sir Arthur Conan. The Adventure of the Silver Blaze. Strand Magazine, December 1892.\n[Geiger, et al, 90] Geiger, D.; Verma, T.; and Pearl, J. Identifying independence m Bayesian networks. Networks 20, p. 507-34. [Gorry+Barnett, 68] Gorry, G. A. and Barnett, G. 0. Experience with a Model of Sequential Diagnosis, Computers and Biomedical Research. 1:490-507.\n[Grice, 75] Grice, H. P. \"Logic and conversation.\" In Cole and Morgan, Cole, P, and J. Morgan, eds. Syntax and Semantics, 3: Speech Acts. New York: Academic Press. [Hancher, 78] Hancher, M. Grice's \"Implicature\" and Literary Interpretation: Background and Preface. Presented at the Twentieth Annual Meeting of the Midwest Modern Language Association. Minneapolis, Minnesota, 2-4 November 1978.\n[Horvitz, et al., 84] Horvitz, E. J.; Heckerman, D. E.; Nathwani, B. N.; and Fagan, L. M. Diagnostic Strategies in the Hypothesis-Directed Pathfinder System. Proc. 1st Conference on AI Applications, Denver CO, IEEE Computer Society, p. 630-6.\n[Howard, 66] Howard, R. A. Information Value Theory, IEEE Trans. on Sys. Sci. & Cybernetics. Vol. SSC-2, No. 1, p. 22-6.\n[Howard, 67] Howard, R. A. Information Value Lotteries, IEEE Trans. on Sys. Sci. & Cybernetics. Vol. SSC-3, No. 1, p. 54-60.\n[Levinson 83] Levinson, S.C. Pragmatics: Cambridge, England: Cambridge University.\n[Miller, et al, 82] Miller, R.A.; Pople, E. P., and Myers, J.D. Internist-!. New England Journal of Medicine, 307:476- 86.\n[Shachter, 86] Shachter, R. D. Evaluating Influence Diagrams. Operations Research, 34:87 1-82."}], "references": [{"title": "The Adventure of the Silver Blaze", "author": ["Doyle", "1892] Doyle", "Sir Arthur Conan"], "venue": null, "citeRegEx": "Doyle et al\\.,? \\Q1892\\E", "shortCiteRegEx": "Doyle et al\\.", "year": 1892}, {"title": "Grice's \"Implicature\" and Literary Interpretation: Background and Preface. Presented at the Twentieth Annual Meeting of the Midwest Modern Language Association", "author": ["M. Hancher"], "venue": "[Hancher,", "citeRegEx": "Hancher,? \\Q1978\\E", "shortCiteRegEx": "Hancher", "year": 1978}], "referenceMentions": [], "year": 2011, "abstractText": "The process of diagnosis involves learning about the state of a system from various observations of symptoms or findings about the system. Sophisticated Bayesian (and other) algorithms have been developed to revise and maintain beliefs about the system as observations are made. Nonetheless, diagnostic models have tended to ignore some common sense reasoning exploited by human diagnosticians. In particular, one can learn from which observations have not been made, in the spirit of conversational implicature. In order to e\u00b7xtract information from the observations not made, we propose the following two concepts. First, some symptoms, if present, are more likely to be reported before others. Second, most human diagnosticians and expert systems are economical in their data-gathering, searching first where they are more likely to find symptoms present. Thus, there is a desirable bias toward reporting symptoms that are present. We develop a simple model for these concepts that can significantly improve diagnostic inference.", "creator": "pdftk 1.41 - www.pdftk.com"}}}