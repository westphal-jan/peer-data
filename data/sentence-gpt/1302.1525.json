{"id": "1302.1525", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "6-Feb-2013", "title": "Incremental Pruning: A Simple, Fast, Exact Method for Partially Observable Markov Decision Processes", "abstract": "Most exact algorithms for general partially observable Markov decision processes (POMDPs) use a form of dynamic programming in which a piecewise-linear and convex representation of one value function is transformed into another. We examine variations of the \"incremental pruning\" method for solving this problem and compare them to earlier algorithms from theoretical and empirical perspectives. We find that incremental pruning is presently the most efficient exact method for solving POMDPs. In particular, the approach of POMDPs involves increasing the POMDP number and increasing the value of the variable. As noted above, POMDPs generate a similar degree of error-prone algorithm because of the fact that this method is not explicitly linked to an empirical approach. This has also been confirmed by several empirical studies that perform POMDP analysis using different algorithms and in fact provide a better estimate of the likelihood that a given set of POMDP algorithms are successfully achieved. A previous paper published in the journal Nature, however, has used a similar approach to POMDP analysis using non-linear methods such as the H.G.S. algorithm.", "histories": [["v1", "Wed, 6 Feb 2013 15:54:07 GMT  (982kb)", "http://arxiv.org/abs/1302.1525v1", "Appears in Proceedings of the Thirteenth Conference on Uncertainty in Artificial Intelligence (UAI1997)"]], "COMMENTS": "Appears in Proceedings of the Thirteenth Conference on Uncertainty in Artificial Intelligence (UAI1997)", "reviews": [], "SUBJECTS": "cs.AI", "authors": ["anthony r cassandra", "michael l littman", "nevin lianwen zhang"], "accepted": false, "id": "1302.1525"}, "pdf": {"name": "1302.1525.pdf", "metadata": {"source": "CRF", "title": "Incremental Pruning: A Simple, Fast, Exact Method for Partially Observable Markov Decision Processes", "authors": ["Anthony Cassandra", "Nevin L. Zhang"], "emails": ["arc@cs.brown.edu", "lzhang@cs."], "sections": null, "references": [{"title": "Acting optimally in partially observ\u00ad", "author": ["A.R. Cassandra", "L.P. Kaelbling", "M.L. Littman"], "venue": null, "citeRegEx": "Cassandra et al\\.,? \\Q1994\\E", "shortCiteRegEx": "Cassandra et al\\.", "year": 1994}, {"title": "Algorithms for Partially Observ\u00ad", "author": ["Cheng", "H.-T"], "venue": null, "citeRegEx": "Cheng and H..T.,? \\Q1988\\E", "shortCiteRegEx": "Cheng and H..T.", "year": 1988}, {"title": "Reinforcement learning with", "author": ["L. Chrisman"], "venue": null, "citeRegEx": "Chrisman,? \\Q1992\\E", "shortCiteRegEx": "Chrisman", "year": 1992}, {"title": "Cost-effective sensing dur\u00ad", "author": ["E.A. Hansen"], "venue": null, "citeRegEx": "Hansen,? \\Q1994\\E", "shortCiteRegEx": "Hansen", "year": 1994}, {"title": "Efficient dynamic-programming updates", "author": ["M.L. Littman", "A.R. Cassandra", "L.P. Kaelbling"], "venue": null, "citeRegEx": "Littman et al\\.,? \\Q1996\\E", "shortCiteRegEx": "Littman et al\\.", "year": 1996}, {"title": "Overcoming incomplete per\u00ad", "author": ["R.A. McCallum"], "venue": null, "citeRegEx": "McCallum,? \\Q1993\\E", "shortCiteRegEx": "McCallum", "year": 1993}, {"title": "A survey of partially observ\u00ad able Markov decision processes: Theory, models, and algorithms", "author": ["G.E. Monahan"], "venue": "Management Science 28(1):1-16.", "citeRegEx": "Monahan,? 1982", "shortCiteRegEx": "Monahan", "year": 1982}, {"title": "Approximating op\u00ad timal policies for partially observable stochastic do\u00ad mains", "author": ["R. Parr", "S. Russell"], "venue": null, "citeRegEx": "Parr and Russell,? \\Q1995\\E", "shortCiteRegEx": "Parr and Russell", "year": 1995}, {"title": "A feasible computational ap\u00ad proach to infinite-horizon partially-observed Markov decision problems", "author": ["K."], "venue": "Technical report, Georgia Insti\u00ad tute of Technology, Atlanta, GA. Russell, S. J., and Norvig, P. 1994. Artificial Intel\u00ad", "citeRegEx": "K.,? 1981", "shortCiteRegEx": "K.", "year": 1981}, {"title": "Optimal control for partially observable Markov decision processes over an infinite horizon", "author": ["K. Prentice-Hall. Sawaki", "A. Ichikawa"], "venue": "ligence: A Modern Approach", "citeRegEx": "Sawaki and Ichikawa,? \\Q1978\\E", "shortCiteRegEx": "Sawaki and Ichikawa", "year": 1978}, {"title": "The opti\u00ad mal control of partially observable Markov processes over a finite horizon. Operations Research 21:10711088", "author": ["R.D. Smallwood", "E.J. Sondik"], "venue": null, "citeRegEx": "Smallwood and Sondik,? \\Q1973\\E", "shortCiteRegEx": "Smallwood and Sondik", "year": 1973}, {"title": "The Optimal Control of Partially Observable Markov Processes", "author": ["E. Sondik"], "venue": "Ph.D. Dissertation, Stanford University. Sondik, E. J. 1978. The optimal control of partially observable Markov processes over the infinite horizon:", "citeRegEx": "Sondik,? 1971", "shortCiteRegEx": "Sondik", "year": 1971}, {"title": "Solu\u00ad tion procedures for partially observed Markov deci\u00ad sion processes", "author": ["III White", "C.C.", "W.T. Scherer"], "venue": "Operations Research 37(5):791-797.", "citeRegEx": "White et al\\.,? 1989", "shortCiteRegEx": "White et al\\.", "year": 1989}, {"title": "Partially observed Markov decision processes: A survey", "author": ["III White", "C.C."], "venue": "Annals of Operations Research 32.", "citeRegEx": "White and C.,? 1991", "shortCiteRegEx": "White and C.", "year": 1991}, {"title": "Planning in stochas\u00ad tic domains: Problem characteristics and approxi\u00ad mation", "author": ["N.L. Zhang", "W. Liu"], "venue": "Technical Report HKUST-CS96-31, Depart\u00ad ment of Computer Science, Hong Kong University of Science and Technology.", "citeRegEx": "Zhang and Liu,? 1996", "shortCiteRegEx": "Zhang and Liu", "year": 1996}], "referenceMentions": [{"referenceID": 3, "context": "There are many ways to approach this prob\u00ad lem based on checking which information states can be reached (Washington 1996; Hansen 1994), search\u00ad ing for good controllers (Platzman 1981), and using dynamic programming (Smallwood & Sondik 1973; Cheng 1988; Monahan 1982; Littman, Cassandra, & Kaelbling 1996).", "startOffset": 105, "endOffset": 135}, {"referenceID": 6, "context": "There are many ways to approach this prob\u00ad lem based on checking which information states can be reached (Washington 1996; Hansen 1994), search\u00ad ing for good controllers (Platzman 1981), and using dynamic programming (Smallwood & Sondik 1973; Cheng 1988; Monahan 1982; Littman, Cassandra, & Kaelbling 1996).", "startOffset": 217, "endOffset": 306}, {"referenceID": 11, "context": "Several algorithms for dynamic-programming updates have been proposed, such as one pass (Sondik 1971), exhaustive (Monahan 1982), linear support (Cheng 1988), and witness (Littman, Cassandra, & Kaelbling 1996).", "startOffset": 88, "endOffset": 101}, {"referenceID": 6, "context": "Several algorithms for dynamic-programming updates have been proposed, such as one pass (Sondik 1971), exhaustive (Monahan 1982), linear support (Cheng 1988), and witness (Littman, Cassandra, & Kaelbling 1996).", "startOffset": 114, "endOffset": 128}, {"referenceID": 6, "context": "Several algorithms for dynamic-programming updates have been proposed, such as one pass (Sondik 1971), exhaustive (Monahan 1982), linear support (Cheng 1988), and witness (Littman, Cassandra, & Kaelbling 1996). Cheng (1988) gave experimental evidence that the linear support algorithm is more efficient than the", "startOffset": 115, "endOffset": 224}, {"referenceID": 8, "context": "Littman, Cassandra and Kael\u00ad bling (1996) compared the exhaustive algorithm, the linear support algorithm, and the witness algorithm and found that, except for tiny problems with approx\u00ad imately 2 observations or 2 states, which all three al\u00ad gorithms could solve quickly, witness was the fastest and had a number of superior theoretical properties.", "startOffset": 23, "endOffset": 42}, {"referenceID": 14, "context": "Recently, Zhang and Liu (1996) proposed a new method for dynamic-programming updates in POMDPS called incremental pruning.", "startOffset": 10, "endOffset": 31}, {"referenceID": 8, "context": "The algorithm is due to Lark (White 1991); Littman, Cassandra, & Kaelbling (1996) analyze the algorithm and describe the way that the argmax op\u00ad erators need to be implemented for the analysis to hold (ties must be broken lexicographically).", "startOffset": 27, "endOffset": 82}, {"referenceID": 6, "context": "sets from the s\ufffd sets was essentially proposed by Monahan (1982) (under the name of \"Sondik's one\u00ad pass algorithm\").", "startOffset": 50, "endOffset": 65}, {"referenceID": 6, "context": "Equation 13 is equiv\u00ad alent to using Monahan's (1982) filtering algorithm in lNCPRUNE, Equation 15 is equivalent to using Lark's filtering algorithm (W hite 1991) in lNCPRUNE (i.", "startOffset": 37, "endOffset": 54}, {"referenceID": 6, "context": "The first is numerical precision!Vtl Reference 4 436 Parr & Russell (1995) 4 Russell & Norvig (1994) 20 Cassandra, Kaelbling, & Littman (1994) 14 McCallum (1993) 9 Kushmerick, Hanks, & Weld (1995) 438 481 Chrisman (1992) 258", "startOffset": 115, "endOffset": 143}, {"referenceID": 4, "context": "The first is numerical precision!Vtl Reference 4 436 Parr & Russell (1995) 4 Russell & Norvig (1994) 20 Cassandra, Kaelbling, & Littman (1994) 14 McCallum (1993) 9 Kushmerick, Hanks, & Weld (1995) 438 481 Chrisman (1992) 258", "startOffset": 146, "endOffset": 162}, {"referenceID": 4, "context": "The first is numerical precision!Vtl Reference 4 436 Parr & Russell (1995) 4 Russell & Norvig (1994) 20 Cassandra, Kaelbling, & Littman (1994) 14 McCallum (1993) 9 Kushmerick, Hanks, & Weld (1995) 438 481 Chrisman (1992) 258", "startOffset": 146, "endOffset": 197}, {"referenceID": 2, "context": "The first is numerical precision!Vtl Reference 4 436 Parr & Russell (1995) 4 Russell & Norvig (1994) 20 Cassandra, Kaelbling, & Littman (1994) 14 McCallum (1993) 9 Kushmerick, Hanks, & Weld (1995) 438 481 Chrisman (1992) 258", "startOffset": 205, "endOffset": 221}], "year": 2011, "abstractText": "Most exact algorithms for general par\u00ad tially observable Markov decision processes (POMDPs) use a form of dynamic program\u00ad ming in which a piecewise-linear and con\u00ad vex representation of one value function is transformed into another. We examine vari\u00ad ations of the \"incremental pruning\" method for solving this problem and compare them to earlier algorithms from theoretical and em\u00ad pirical perspectives. We find that incremen\u00ad tal pruning is presently the most efficient ex\u00ad act method for solving POMDPs.", "creator": "pdftk 1.41 - www.pdftk.com"}}}