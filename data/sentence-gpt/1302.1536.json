{"id": "1302.1536", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "6-Feb-2013", "title": "Limitations of Skeptical Default Reasoning", "abstract": "Poole has shown that nonmonotonic logics do not handle the lottery paradox correctly. In this paper we will show that Pollock's theory of defeasible reasoning fails for the same reason: defeasible reasoning is incompatible with the skeptical notion of derivability.\n\n\n\nWe demonstrate that the problem of defeasible reasoning is a problem that is not consistent with the defeasible theory (I think we should probably try to show that, because of the nonmonotonic paradoxes, and because we've shown that there are some problems). The problem is that the only logical answer to the question is that it requires deductive reasoning to be considered as the nonmonotonic reason, and the most likely answer is that it is more likely that it is the nonmonotonic reason, than that it is the nonmonotonic reason. In this case, it's simply not enough to show that the nonmonotonic reason is not compatible with the nonmonotonic reason. It's more likely that the nonmonotonic reason is not compatible with the nonmonotonic reason, but the nonmonotonic reason is not compatible with the nonmonotonic reason. We will show that this is no good thing for a nonmonotonic reason. We need a good explanation to explain the problem.\nA good explanation for defeasible reasoning is that the explanation is that it is incoherent, and that it is not consistent with the nonmonotonic reason. This is what I propose here. The problem is that in any given case, we can expect that defeasible reasoning is incompatible with the nonmonotonic reason.\nWhat we see here is that there is not a good explanation for defeasible reasoning, but an explanation for the nonmonotonic reason that is incoherent. We need a good explanation for defeasible reasoning to explain the problem. If we consider the reason, the reason must also be of some level of epistemic relevance. We will show that the problem cannot be explained.\nThis is a case where we need a reasonable explanation to explain the problem. In fact, if we are not convinced that the reason is incoherent, and we can, we should try to explain it on a more logical level.\nThe problem is that in the above case, we can do some convincing on one hand. In fact, it can be argued that it is inconsistent with the nonmonotonic reason. For example, we cannot reason the reason on", "histories": [["v1", "Wed, 6 Feb 2013 15:55:09 GMT  (677kb)", "http://arxiv.org/abs/1302.1536v1", "Appears in Proceedings of the Thirteenth Conference on Uncertainty in Artificial Intelligence (UAI1997)"]], "COMMENTS": "Appears in Proceedings of the Thirteenth Conference on Uncertainty in Artificial Intelligence (UAI1997)", "reviews": [], "SUBJECTS": "cs.AI", "authors": ["jens doerpmund"], "accepted": false, "id": "1302.1536"}, "pdf": {"name": "1302.1536.pdf", "metadata": {"source": "CRF", "title": "Limitations of Skeptical Default Reasoning", "authors": ["J ens Doerpmund", "John Pollock"], "emails": ["jens@cs.man.ac.uk"], "sections": [{"heading": null, "text": "Poole has shown that nonmonotonic logics do not handle the lottery paradox correctly. In this paper we will show that Pollock's the ory of defeasible reasoning fails for the same reason: defeasible reasoning is incompatible with the skeptical notion of derivability.\n1 Introduction\nIn the preface to \"Cognitive Carpentry: A Blueprint for How to Build a Person\" John Pollock argues that \"work in artificial intelligence has made less progress than expected because it has been based upon inad equate foundations. AI systems are supposed to behave rationally, but their creators have not generally come to the problem equipped with an account of what it is to behave rationally.\" OSCAR, Pollock's framework for a reasoning engine, on the other hand, is \"capable of performing reasoning that philosophers would regard as epistemologically sophisticated [Pollock, 1995] .\"\nPollock claims that because many theories of uncer tain reasoning are semantical (i.e. proceeding in terms of models) rather than syntactical (i.e. proceeding in terms of arguments which may defeat one another), they are \"unable to adequately formulate principles of probabilistic reasoning [Pollock , 1990, Chapter 8].\" Unfortunately, the fact that Pollock's framework is not characterized semantically makes it very difficult to de termine which conclusions it sanctions. It may be for this reason that the mistake in Pollock's analysis re garding the important distinction between the paradox of the preface and the lottery paradox ([Pollock, 1990], [Pollock, 1994], [Pollock, 1995]) remained undetected. This is very unfortunate since other relevant problems of default reasoning (i.e. preference for more specific knowledge and contrapositive reasoning) pose no prob lem in Pollock's framework. Let us start with a review of the lottery paradox in default reasoning.\n2 Default Reasoning and the Lottery Paradox\nIn standard logic we are not able to draw conclusions if the available evidence is insufficient to guarantee their correctness. Default reasoning , on the other hand, al lows us to jump to conclusions even if the knowledge about the domain at hand is incomplete. Some of these conclusions may turn out to be incorrect and must be abandoned in order to avoid inconsistencies. To make this more precise, we provide a brief introduction to Reiter's default logic [Reiter, 1980].\n2.1 Default Logic\nReiter's default logic supports rules like 'if a(x) is prov able and if it is consistent to belief b(x), then derive c(x).' These rules are not expressed in the underlying object language, but can be seen as additional infer ence rules which augment those provided by first-order logic. Such a rule, which is called a default, has the fol lowing form:\na(x): b1(x), ... ,bn(x) c(x)\n(1)\nwhere a(x), b1(x), . .. , bn(x), and c(x) are first-order formulae whose free variables are among those of x = (x1, ... , xm ) . The meaning of a default is that c{x) is believed if a(x) is known to be true and b1(x), ... , bn(x) are consistent with what is known (i.e. -.b;(x) cannot be deduced). A default is called applicable if both of these conditions are satisfied; otherwise it is inapplic able. For example the statement \"Birds usually fly\" is expressed by the default\nbird(x): flies(x)\nflies(x) (2)\nA default theory A is a pair (D, W) of sets, where W contains ordinary first-order sentences representing knowledge about a particular domain, and D is a set of defaults, which are used to (partially) extend this knowledge by making plausible, but logically invalid inferences. Belief sets which are obtained by taking all\nformulae which can be deductively derived from both W and the consequents of all applicable defaults of D are called extensions of the theory 6..1\n2.2 Multiple Extensions\nA problem of default logic is that we often obtain mul tiple extensions. Consider the following classical ex ample:\nExample 1 (Nixon-Diamond) Quakers are typically pacifists. Republicans are typically not pacifists. Nixon is a Quaker and a Republican. Is Nixon a pacifist?\nThis can be encoded into the default theory 6 = (D, W), where D = { Quaker{x) : pacifist{x) Republican(x) : --.pacifist(x) } pacifist(x) ' --.pacifist{x)\nand W = { Quaker{x) A Republican{x)}.\nThe extensions of 6. are\nE1 Cn( {Quaker( Nixon), Republican{Nixon), pacifist(Nixon)}) and E2 Cn( { Quaker{Nixon), Republican(Nixon), -.pacifist(Nixon)} ),\nThe generation of multiple extensions is very com mon in logic-based frameworks for reasoning under uncertainty. What, then, can be inferred from the de fault theory of Example 1? According to Reiter, paci fist{Nixon) is provable, because each extension can be seen as an acceptable belief set and pacifist{Nixon) is contained in one of them. But by the same argument --.pacifist{Nixon) is provable. This \"credulous\" view which allows us to choose an extension does not seem to be a rational way of \"proving\" a sentence, since we can base our choice on what we actually want to infer. This problem is avoided in skeptical default reasoning, according to which a sentence is a theorem of a de fault theory if and only if the sentence is contained in (the intersection of) all extensions.2 In Example 1, we would therefore not be justified in believing either pa cifist{Nixon) or --.pacifist(Nixon). Although this seems to be the correct approach in this particular example, we will soon see that there are default theories which lead to rather peculiar results.\n2.3 The Lottery Paradox\nConsider the following example taken from [Poole, 1991, p. 290]:\n1See [Reiter, 1980] for a formal definition of an extension.\n2Note that the intersection of extensions is itself not an extension, since there are always applicable defaults which have not been applied.\nLimitations of Skeptical Default Reasoning 151\nExample 2 (Qualitative Lottery Paradox) Suppose we want to build a knowledge base about birds. Sup pose also that all we are told about Tweety is that Tweety is a bird. We first state knowledge about the different birds we are considering:\nVx.bird(x):::::: emu(x) Vpenguin(x) V hummingbird(x) Vsandpiper(x)Valbatross(x)V ... V canary(x). We now state defaults about birds (e.g., they fly, are within certain size ranges, nest in trees, etc.). For each sort of bird that is exceptional in some way we will be able to conclude that Tweety is not that sort of bird:\n\u2022 We conclude that Tweety is not an emu or a pen guin because they are exceptional in not flying.\n\u2022 We conclude that Tweety is not a hummingbird as hummingbirds are exceptional in their size {. . .}\nThe reason that we divide the class of birds into sub classes is because each subclass is exceptional in some way. Rather than being a pathological example, this would seem to be the general rule, typical of hierarch ies with exceptions.\nThis example is a qualitative version of the lottery paradox [Kyburg, Jr., 1961]. The original version is as follows:\nExample 3 (Lottery Paradox) Consider a fair lot tery consisting of one million tickets, only one of them is a winning ticket. Suppose you possess one ticket. Since the probability of winning the prize is 0.000001, it seems reasonable to infer that your ticket will not win. By the same argument it is reasonable to infer that each ticket will not win. This, however, is incon sistent since one ticket must be the winning ticket.\nIn both of the above\ufffdmentioned examples we end up having inconsistent beliefs. In default logic, however, we are only allowed to apply defaults if it is consistent to do so. Thus, in the lottery we would infer that the first 999,999 tickets will lose and- in order to maintain consistency- that ticket No. 1,000,000 will win. Since the order in which defaults are applied is irrelevant, we will get 999,999 other extensions. The intersection of all extensions does not contain any default inferences whatsoever. Thus, although it is very likely that, say, ticket No. 4 711 is a losing ticket, we are not able to infer this in default logic. In the qualitative example, we might infer in one extension that Tweety is an emu, in another extension that Tweety is a sand-piper. The number of extensions will be the same as the number of different kinds of birds. Since there are extensions in which Tweety is a non-flying bird, we are not able to infer that Tweety can fly if we opt for the skeptical view and decide to accept only beliefs contained in the intersection of all extensions.\nThe lottery paradox is indeed a serious problem in default reasoning. It arises whenever jointly incon sistent defaults are equally strong. Often, however,\n152 Doerpmund\none default should be preferred over another default. This is normally the case when one default is more specific than a competing one. Unfortunately, default reasoning systems, as described in [Poole, I984] or [Reiter, I980] are not capable of deciding which de faults are more specific and should therefore be pre ferred (i.e. applied first). Contraposition is yet another problem in default reasoning. For instance, knowing that birds normally fly, we may want to infer that an individual that can not fly is (normally) not a bird. But often contrapositive reasoning is not desired. We certainly don't want to infer that something that can fly is not an object, given that objects normally don't fly. Again, default reasoning systems are not capable of deciding under which circumstances the contraposition on defaults should be considered.\n3 Pollock's Theory of Defeasible Reasoning\nPollock's theory of defeasible reasoning constitutes a probabilistic framework that supports the detachment of beliefs by means of acceptance rules. Deductions are performed both on the level of probabilities and on the level of beliefs. The simplest acceptance rule, called (AI), is as follows [Pollock, I990].\nDefinition 1 (AI) If F is projectible3 with respect to G and r > 0.5 then G(c) 1\\ Pr(F I G) \ufffd r is a prima facie reason for F(c), the strength of the reason de pending upon the value of r.\nThe reasons for beliefs we obtain by applying (AI) are only prima facie reasons - that is, they can be defeated by so-called defeaters. Pollock distinguishes between undercutting de/eaters, which attack the con nection between a prima facie reason and its conclu sion, and rebutting de/eaters, which are reasons for denying a conclusion. A belief is warranted if and only if it has at least one prima facie reason which cannot be defeated.\nAn important undercutting defeater is the following.\nDefinition 2 (Dl) If F is projectible with respect to H, then H(c)l\\ Pr(F I GAH) \"I Pr(F I G) is an undercutting defeater for (Al).\n(DI) defeats prima facie reasons generated by (AI) whenever (AI) does not take all relevant information into account. Thus, the preference of reasons based on more specific information is dealt with correctly and does not need to be provided as in default logic.\nAn fundamental principle of Pollock's framework is the principle of collective defeat [Pollock, 1990, pp. 88].\n3The projectibility constraint is explained in [Pollock, 1990]. It is of no importance to our discussion.\nDefinition 3 (Collective Defeat) If we have equally good independent reasons for believing each member of a minimal set of jointly inconsistent propositions, and none of the reasons is contradictory in any other way, then none of the propositions in the set is justified.\nThe justification for the priciple of collective defeat is easily stated. Each \ufffd of a minimal set of inconsistent propositions {P1, ... , PN} is rebutted (and therefore not warranted), because its negation is deductively entailed by the conjunction P1 1\\ ... A Pi-1 A PHI 1\\ ... !\\ PN.\nNote that the principle of collective defeat is very sim ilar to the skeptical notion of derivability in default logic. In fact, in the lottery example Pollock's frame work sanctions the same conclusions as we would get in default logic. For instance, in Example 2 collective defeat forces us to remain agnostic about what kind of bird Tweety is. But this, it seems, does not affect the inference from the evidence stating that most birds fly to our believing that Tweety can fly.\nHowever, in \"The Collapse of Collective Defeat: Les sons from the Lottery Paradox,\" Kevin Korb con structs an argument against collective defeat that does not rely on the generation of multiple extensions. His criticism is based on the fact that \"one can 'lotter ize' just about any inductive inference problem, and so, if using Pollock's Rule [i.e. collective defeat], one will almost always be constrained to indecision, even concerning the most ordinary, dull, unobjectionable in ferences\" [Korb, I992]. Lotterization, of course, refers to the process of dividing the sample space of an ex periment into many partitions such that each member of the partition has an equally low probability of being selected. Korb's argument, then, is as follows. Let P be a proposition that has a high probability, and let Q be the negation of P. Normally, this would give us a reason for concluding P (and consequently \u2022Q). We now lotterize both P and Q such that all members of P and Q have roughly the same low probability. Thus, our knowledge base contains the following information:\np = -,Q, P := P1 V P2 V ... PM, Q:=Q1VQ2V ... QN, Pr(P ) =I- Pr(Q) ='high', Pr(-,Pi) \ufffd Pr(-,Qj ) ='high',\nfor all i E {I, . . ,M},j E {I, . .. ,N}.\nSince exactly one disjunct of\nis true, collective defeat applies and prevents us from believing the negations of any of the disjuncts. In par ticular, we are not warranted in believing any of the -,Qi. Our reasoning so far has had no influence on the high probability of P. Nevertheless, we cannot con clude P anymore. Suppose P were warranted - that is, we have no reason for believing ..,p that is as strong\nas the reason for believing P. Then we would be able to infer any of the -,Q; deductively. But, as we have seen, collective defeat prevents us from concluding any of the ...,Qi. Therefore, Korb argues, P cannot be war ranted.\nBut Korb's argument is wrong. Precisely because we can infer ...,Q; from P, the partition Korb has chosen is not minimal any more.4 The minimal partition would just contain the ...,pi\u00b7 In other words, we would not be justified in believing any of the -,pi (because of collective defeat), but we would be able to infer each of the -,Q;, because P is warranted. If, on the other hand, P is not warranted, then Korb's argument is correct but irrelevant, because we do not need further arguments against P.\n3.1 The Paradox of the Preface vs. the Lottery Paradox\nEven proponents of collective defeat acknowledge that there are situations in which the principle should not be applied. For instance, a person (vacuously) be lieves all of his beliefs, but he also believes that some of his beliefs are wrong (although he does not know which). Should he apply the principle of collective defeat and remain agnostic about everything he be lieves? Consider the following problem taken from [Makinson, 1965].\nSuppose that in the course of his book a writer makes a great many assertions, which we shall call s1, . .. , Sn\u00b7 Given each one of these, he believes that it is true. If he has already written other books, and received corrections from readers and reviewers, he may also believe that not everything he has written in his latest book is true. His ap proach is eminently rational; he has learnt from experience. The discovery of errors among statements which previously he be lieved to be true gives him a good ground for believing that there are undetected errors in his latest book [Makinson, 1965].\nThe structure of this paradox of the preface5 is very similar to the lottery paradox. As in the lottery case, we seem to be justified in believing each statement 81, .. . , 8n while at the same time we are justified in be lieving -,81 V ... V 'Sn. However, if we applied the principle of collective defeat to the paradox of the pre face, we would no longer be justified in believing any of the statements mentioned in the book! Examples like the paradox of the preface arise naturally in de fault reasoning. What distinguishes default reasoning\n4Cf. Definition 3 for a definition of collective defeat. 5The name of the paradox refers to the preface of a book in which it is common that authors acknowledge the support of various people, but take responsibility for any mistakes remaining in the book.\nLimitations of Skeptical Default Reasoning 153\nfrom deductive reasoning is that the inferences in de fault reasoning need not be valid, but merely plaus ible. Suppose, then, that the conclusions we derive from our evidence have a probability of 99.9% on av erage. Given that we have made more then 1000 infer ences, we should have a good reason for believing that at least one of the conclusions is wrong. If we were to apply collective defeat in this case, we would not be able to perform default reasoning at all.\nPollock therefore provides a reason for treating in stances of the lottery paradox and the paradox of the preface differently. The tickets in the lottery, Pollock argues, are negatively relevant. That is, inferring that a ticket loses makes it more likely that one of the remain ing tickets is the winning ticket. We therefore cannot possibly conclude that all tickets are winning tickets without obtaining an inconsistent belief set. Contrast this with the paradox of the preface. Here, the state ments made in the book are positively relevant. Con firming one statement decreases the probability that there exists a wrong statement, which in turn makes the other statements more likely (Pollock, 1995, p. 128]. We could, therefore, consistently believe each of the statements, and, as a consequence, discard the belief stating that (at least) one statement is wrong.\nThus, rather than seeing the above examples as ar guments supporting the view that uncertain reasoning frameworks be able to handle inconsistent information, Pollock prefers to ignore that the belief set is prob ably inconsistent. This view is not uncommon. In [Lehrer, 1990], for instance, it is argued that if we ac cept that at least one of our beliefs is wrong, then we forgo the chances of achieving the ideal of maxiveri ficity. A person is called maxiverific if he accepts all true statements and rejects all false statements by some rational methodology. Lehrer claims that it is not irra tional for a sensible person to \"adopt maxiverificity as an ideal and refuse to follow a policy that guarantees failure [Lehrer, 1990].\" Lehrer therefore comes to the same conclusion as Pollock: he suggests to ignore that some of the beliefs may be wrong. 6\nLet us restate Pollock's argument regarding positive and negative relevance in more detail. We know that most statements contained in a book are true, but we also know that it is very likely that at least one of them is false. We therefore have prima facie reasons for believing each of the statements Si as well as\n(3)\nThese beliefs are inconsistent, and it appears that they are subject to collective defeat. Although we would like to believe each of the si, we can construct ar guments for their negations. Suppose the statements s1, ... ,Sj-1,8j+l, ... ,SNare warranted. After all, each statement has a high probability of being true. From\n6However, Lehrer acknowledges that there are other strategies that may be equally rational.\n154 Doerpmund\nthis we can conclude\n81 1\\ \u00b7\u00b7\u00b7 /\\ 8j-1 /\\ 8j+ll\\ ... I\\ 8N\u00b7 {4)\n(3) and (4) together deductively imply ....,8j, and it seems that we are no longer justified in believing 8J. However, we can show that the argument for -.si is defeated. Since the statements in the book are not negatively relevant to each other, the confirmation of some statements does not make the remaining state\ufffd ments more likely. Instead , confirming a statement decreases the probability that the book contains false statements.\nClaim:\nThe following equation, which, according to (D1), provides an undercutting defeater for the inference leading to (3), holds.\n<\nProof:\nPr(-.s1 V ... V -.sN I 81 1\\ ... /\\ Bi-1 /\\ 8i+l /\\ ... /\\ SN)\nPr(-.sl V ... V -.sN) (5)\nIf { s1 , ... , s N} is a set of propositions that are positively relevant, then\nPr(8i I 81/\\ ... /\\ 8i-1 /\\ si+l /\\ ... I\\ SN) > Pr(si)\u00b7 (6)\nSince\nPr(si I s 1 /\\ ... /\\ Si-1 1\\ 8i+II\\ ... /\\ SN) 1- Pr(-.8i I 81/\\ ... /\\ Bi-11\\ 8i+11\\ ... /\\ 8N) 1- Pr(-.sl V ... V -.sN I\n>\n81 /\\ \u00b7\u00b7\u00b7 /\\ Si-1 1\\ Si+1 1\\ ... 1\\ SN) Pr( Si) = 1 - Pr( -.8i),\nit follows that\nPr( ...,81 V ... V -.5N I 81/\\ ... /\\ 8jl /\\ Bi+11\\ ... I\\ 8N) I\n< Pr(...,8i)\u00b7\n(7}\n(8)\nBecause the right hand side of (8) is less or equal than Pr{-.81 V ... V -.sN), (5) holds. D\nTherefore, (3) is not warranted, and we can conclude that all statements in the book are true.\nAccording to Pollock, collective defeat applies if and only if the members of a minimal set of jointly incon\ufffd sistent beliefs are negatively relevant [Pollock, 1994]. Clearly, if (3) were certain, then the statements would be negatively relevant. (3) states that (at least) one statement is false. Since all statements have the same probability of being true, the confirmation of one state ment makes the other statements less likely if we also know that there are false statements. However - and\nthis is where Pollock is mistaken, the converse is not true. Collective defeat can be defeated even if the pro\ufffd positions are negatively relevant.\nConsider a lottery which is not always fair: every lOOth draw does not contain a winning ticket. Since most draws are fair, we have a prima facie reason for be lieving t1 V ... V twooooo. Clearly, confirming that some tickets are losing tickets makes it more likely that the winning ticket is among the remaining tickets. Thus, the tickets are negatively relevant. However, the more tickets we confirm, the more probable it is that the cur rent draw contains only losing tickets. Thus, we have an undercutting defeater for concluding\nt1 V t2 V ... V twooooo (9)\ndespite the fact that the tickets are negatively relevant:\nPr(t1 V t2 V ... V twooooo I -.t1 1\\ ... /\\ -.ti-1 /\\ --,ti+I 1\\ ... /\\ --,tiOooooo )\n< Pr(t1 V t2 V ... V twooooo ) . (10)\nWithout (9) being warranted, we can infer that all tick ets are losing tickets.\nBecause our argument does not depend on the negative relevance of the propositions in the belief set, it has a devastating consequence. We can basically lotterize any proposition P having a high probability that is smaller than 1.\nClaim:\nLet P =PI V P2 V ... V PN be a 'lotterization' of P. If N is sufficiently large, we have a reason for believing each of the -.pi, even when the Pi are not positively relevant. This, however, means that P can never be warranted.\nProof:\nWe need to show that we are justified in believing that all Pi are false. In order to do this we show that the following equation, which provides a defeater for be lieving PI V ... V PN, holds.\n<\nPr(pl V ... V PN I -.pl 1\\ ... /\\ --,Pi-1 /\\-,Pi+ I /\\ ... 1\\ --,PN)\nPr(pl V ... V PN) . (11)\nFurthermore, we need to show that\nPr(pl V ... V PN I --,PI 1\\ ... 1\\ ...,Pi-1 1\\ 'Pi+1 1\\ ... 1\\ 'PN) (12)\nis less than 0.5 in order to make sure that the accept ance rule cannot be applied to create an undefeated reason for believing p1 V ... V PN.\nThe probability of P being false given that all but one of the Pi are false is\nPr(-.P I\u2022PI 1\\ . .. I\\ ....,PJ-1 1\\ ....,PJ+ll\\ ... I\\ 'PN)\n=\n=\nPr( -,p 1\\ \"\"\"'PI 1\\ ... /\\ \"\"\"'PJ\ufffdl 1\\ ....,Pi+l 1\\ \u00b7\u00b7\u00b7 1\\ \"\"\"'PN)\nPr( ...,PI 1\\ ... 1\\ ....,PJ\ufffdl 1\\ ....,PHI 1\\ \u00b7 \u00b7\u00b7 1\\ 'PN)\nPr(...,P) (13)\nPr(...,Pl 1\\ ... 1\\ ....,Pi-11\\ ....,PHil\\\u00b7\u00b7\u00b7 1\\ ....,PN)\nIf we know that all but one of the Pi are false, then either the remaining Pi is true, or P is false. Thus,\nPr(pj V -.P I -.p11\\ ... I\\ \"'Pj-11\\ ...,Pi+ll\\ \u00b7 \u00b7 \u00b7 1\\ 'PN)\n= 1. (14)\nIt follows that\nPr(--,pll\\ .. . I\\ \"\"\"'PJ\ufffdll\\ 'Pi+I 1\\ ... 1\\ ....,PN) Pr( --.P) + Pr(pj I P)\n1 Pr(...,P) +\nN ' (15)\nFrom {13), {14) and (15) we obtain\n=\n=\nPr(pi I \"\"\"'P1/\\ ... /\\ ....,PJ\ufffdl 1\\ ....,Pi+ll\\ . .. I\\ ....,PN) 1- Pr(-,Pi I 'Pl 1\\ ... 1\\ --,PJ\ufffdl 1\\ --,PJ+l 1\\ ... /\\ 'PN)\n1_ Pr(...,P)\nPr(-.pl 1\\ ... I\\ ....,PJ\ufffdl 1\\ ..,Pi+l 1\\ ... 1\\ 'PN)\n1- Pr(--,P)\n(16) Pr(\u2022P) + -k.\nThe right hand side of equation (16) decreases as N increases. Thus, we can make\nPr(pj 1--.pl/\\ ... I\\ 'PJ\ufffdll\\ ...,Pi+ll\\ ... I\\ --.pN) (17)\nas small as we want. D\nP is no longer warranted if the value of ( 16) is smaller then 0.5, or equivalently, if\nN> . r 1 l Pr(--.P) 4 Conclusions\n(18)\nWe have shown that any proposition P which has a probability of less than 1.0 is not accepted in Pollock's framework. The reason is not \ufffd as Kolb believes - because we could lotterize P and then show that the obtained disjuncts undergo collective defeat. Instead, the problem is that for each P = p1 V ... V PN, we can create a defeater\nPr(pl V ... V PN I\n'PI 1\\ ... I\\ --,PJ-1 1\\ 'Pi+ I 1\\ ... 1\\ -.pN) < Pr(p1V ... VpN). (19)\nBut does the left-hand side of the above equation really provide more information than the right-hand side?\nLimitations of Skeptical Default Reasoning 155\nClearly, each of the -.p; has a high probability and is therefore justified. However, given that one of the Pi must be true, and that we don't know which one it is,\nPr(....,PI 1\\ ... 1\\ ....,Pj-1 1\\ -.pi+l 1\\ ... 1\\ -.pN)\nis fairly low (namely 1/N). Thus, the conjunction\nshould not be accepted and should therefore not con tribute to provide a defeater for P. If Pollock's frame work could be changed to take this into account, likely propositions could be warranted after all. But then we would no longer be able to distinguish between the lottery paradox and the paradox of the preface (and therefore not be justified in believing any statement contained in a book). In either case, Pollock's claim that OS CAR is \"capable of performing reasoning that philosophers would regard as epistemologically soph isticated\" does not withstand scrutiny.\nAcknowledgements\nI would like to thank Ian Pratt for many valuable dis cussions which led to an earlier draft of this paper. Thanks also to the referees for their useful comments.\nReferences\n[Korb, 1992] Korb, K. B. ( 1992). The collapse of col lective defeat: Lessons from the lottery paradox. In Proceedings of the Biennal Meetings of the Philo sophy of Science Association, volume 1, pages 230- 236.\n[Kyburg, Jr., 1961] Kyburg, Jr., H. E. (1961) . Prob ability and the Logic of Rational Belief Wesleyan University Press, Middletown, CT.\n[Lehrer, 1990] Lehrer, K. (1990). Metamind, chapter 6: Reason and Consistency. Oxford University Press, New York.\n[Makinson, 1965] Makinson, D. C. (1965). The para dox of the preface. Analysis, 25:205-207.\n[Pollock, 1990] Pollock, J. L. (1990). Nomic Probabil ities and the Foundations of Induction. Oxford U ni versity Press, New York .\n[Pollock, 1994] Pollock, J. L. (1994). Justification and defeat. Artificial Intelligence, 67:377-407.\n[Pollock, 1995] Pollock, J. L. (1995). Cognitive Car pentry: A Blueprint for How to Build a Person. MIT Press, Cambridge, Massachusetts.\n[Poole, 1984] Poole, D. L. (1984). A logical system for default reasoning. In Proc. of the Non-Monotonic Reasoning Workshop, pages 373-384, New Paltz, NY.\n156 Doerpmund\n[Poole, 1991] Poole, D. L. (1991). The effect of know ledge on belief: conditioning, specificity and the lot tery paradox in default reasoning. Artificial Intelli gence, 49:281-307.\n[Reiter, 1980] Reiter, R. (1980). A logic for default reasoning. Artificial Intelligence, 13:81-132."}], "references": [], "referenceMentions": [], "year": 2011, "abstractText": "Poole has shown that nonmonotonic logics do not handle the lottery paradox correctly. In this paper we will show that Pollock's the\u00ad ory of defeasible reasoning fails for the same reason: defeasible reasoning is incompatible with the skeptical notion of derivability.", "creator": "pdftk 1.41 - www.pdftk.com"}}}