{"id": "1302.1549", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "6-Feb-2013", "title": "Learning Belief Networks in Domains with Recursively Embedded Pseudo Independent Submodels", "abstract": "A pseudo independent (PI) model is a probabilistic domain model (PDM) where proper subsets of a set of collectively dependent variables display marginal independence. PI models cannot be learned correctly by many algorithms that rely on a single link search. Earlier work on learning PI models has suggested a straightforward multi-link search algorithm. However, when a domain contains recursively embedded PI submodels, it may escape the detection of such an algorithm. In this paper, we propose an improved algorithm that ensures the learning of all embedded PI submodels whose sizes are upper bounded by a predetermined parameter. We show that this improved learning capability only increases the complexity slightly beyond that of the previous algorithm. The performance of the new algorithm is demonstrated through experiment. We show that the increased learning capacity improves the reliability of a previously observed PI submodel with a smaller size. The benefit to the improved learning capability is that it avoids the detection of an algorithm that does not have a single link search. The improvement of learning by the new algorithm is further explained in an article on Learning Python.", "histories": [["v1", "Wed, 6 Feb 2013 15:56:57 GMT  (815kb)", "http://arxiv.org/abs/1302.1549v1", "Appears in Proceedings of the Thirteenth Conference on Uncertainty in Artificial Intelligence (UAI1997)"]], "COMMENTS": "Appears in Proceedings of the Thirteenth Conference on Uncertainty in Artificial Intelligence (UAI1997)", "reviews": [], "SUBJECTS": "cs.AI cs.LG", "authors": ["jun hu", "yang xiang"], "accepted": false, "id": "1302.1549"}, "pdf": {"name": "1302.1549.pdf", "metadata": {"source": "CRF", "title": "Learning Belief Networks in Domains with Recursively Embedded Pseudo Independent Submodels", "authors": ["J. Hu"], "emails": ["yxiang@cs."], "sections": null, "references": [{"title": "A Bayesian method for the induction of probabilistic networks from data", "author": ["G.F. Cooper", "E. Herskovits"], "venue": "Machine Learning,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 1992}], "referenceMentions": [{"referenceID": 0, "context": "Learning belief networks has been researched actively by many as an alternative to elicitation in knowledge acquisition [3, 1, 4, 2].", "startOffset": 120, "endOffset": 132}], "year": 2011, "abstractText": "A pseudo independent (PI) model is a proba\u00ad bilistic domain model (PDM) where proper subsets of a set of collectively dependent variables display marginal independence. PI models cannot be learned correctly by many algorithms that rely on a single link search. Earlier work on learning PI models has sug\u00ad gested a straightforward multi-link search al\u00ad gorithm. However, when a domain contains recursively embedded PI submodels, it may escape the detection of such an algorithm. In this paper, we propose an improved al\u00ad gorithm that ensures the learning of all em\u00ad bedded PI submodels whose sizes are upper bounded by a predetermined parameter. We show that this improved learning capability only increases the complexity slightly beyond that of the previous algorithm. The perfor\u00ad mance of the new algorithm is demonstrated through experiment.", "creator": "pdftk 1.41 - www.pdftk.com"}}}