{"id": "1302.4813", "review": {"conference": "HLT-NAACL", "VERSION": "v1", "DATE_OF_SUBMISSION": "20-Feb-2013", "title": "Probabilistic Frame Induction", "abstract": "In natural-language discourse, related events tend to appear near each other to describe a larger scenario. Such structures can be formalized by the notion of a frame (a.k.a. the notion of the relationship between the two natural systems). This is in turn true of language, although there are a number of other possible expressions which can be formalized in both language and the world. For example, a language that resembles a language that mimics a language as a whole is called the Language of the World (CFI). In fact, there is an excellent literature in which we see the same thing happening in the world in the sense that the language itself is not merely the language of the world itself (CFI).\n\n\n\nAs the authors of this work, we also try to give a sense of the nature of language that is present in nature. This, of course, can only be applied to language that is part of our own life, and the world outside of our own life. This is not to say that language is not only a product of a particular type of language but also an artifact of that particular kind of language, as opposed to its specific features. For example, this is an extension of the language of the world, a type of language that is defined in that context by the notion of a particular language.\nThe first example of a language which resembles a language that resembles a language that resembles a language that resembles a language that resembles a language that resembles a language that resembles a language that resembles a language that resembles a language that resembles a language that resembles a language that resembles a language that resembles a language that resembles a language that resembles a language that resembles a language that resembles a language that resembles a language that resembles a language that resembles a language that resembles a language that resembles a language that resembles a language that resembles a language that resembles a language that resembles a language that resembles a language that resembles a language that resembles a language that resembles a language that resembles a language that resembles a language that resembles a language that resembles a language that resembles a language that resembles a language that resembles a language that resembles a language that resembles a language that resembles a language that resembles a language that resembles a language that resembles a language that resembles a language that resembles a language that resembles a language that resembles a language that resembles a language that resembles a language that resembles a language that resembles a language that resembles a language that resembles a language that resembles a language that resembles a language that resembles a language that resembles a language that resembles a language that resembles", "histories": [["v1", "Wed, 20 Feb 2013 05:47:32 GMT  (149kb,D)", "http://arxiv.org/abs/1302.4813v1", null]], "reviews": [], "SUBJECTS": "cs.CL", "authors": ["jackie chi kit cheung", "hoifung poon", "lucy vanderwende"], "accepted": true, "id": "1302.4813"}, "pdf": {"name": "1302.4813.pdf", "metadata": {"source": "CRF", "title": "Probabilistic Frame Induction\u2217", "authors": ["Jackie Chi Kit Cheung", "Hoifung Poon"], "emails": ["jcheung@cs.toronto.edu", "hoifung@microsoft.com", "lucyv@microsoft.com"], "sections": [{"heading": "1 Introduction", "text": "Events with causal or temporal relations tend to occur near each other in text. For example, a bombing scenario in an article on terrorism might begin with a DETONATION event, in which terrorists set\n\u2217This is a postprint version of a paper to appear in the Proceedings of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL/HLT 2013).\n\u2020This research was undertaken during the author\u2019s internship at Microsoft Research.\noff a bomb. Then, a DAMAGE event might ensue to describe the resulting destruction and any casualties, followed by an INVESTIGATION event covering subsequent police investigations. Afterwards, the bombing scenario may transition into a criminalprocessing scenario, which begins with police catching the terrorists, and proceeds to a trial, sentencing, etc. A common set of participants serves as the event arguments; e.g., the agent (or subject) of DETONATION is often the same as the theme (or object) of INVESTIGATION and corresponds to the PERPETRATOR.\nSuch structures can be formally captured by the notion of a frame (a.k.a. template), which consists of a set of events with prototypical transitions, as well as a set of slots representing the common participants. Identifying frames is an explicit or implicit prerequisite for many NLP tasks. Information extraction, for example, stipulates the types of events and slots that are extracted for a frame or template. Online applications such as dialogue systems and personal-assistant applications also model users\u2019 goals and subgoals using frame-like representations, and in natural-language generation, frames are often used to represent content to be expressed as well as to support surface realization.\nUntil recently, frames and related representations have been manually constructed, which has limited their applicability to a relatively small number of domains and a few slots within a domain. Furthermore, additional manual effort is needed after the frames are defined in order to extract frame components from text (e.g., in annotating examples and designing features to train a supervised learning model).\nar X\niv :1\n30 2.\n48 13\nv1 [\ncs .C\nL ]\n2 0\nFe b\nThis paradigm makes it hard to generalize across tasks and might suffer from annotator bias.\nRecently, there has been increasing interest in automatically inducing frames from text. A notable example is Chambers and Jurafsky (2011), which first clusters related verbs to form frames, and then clusters the verbs\u2019 syntactic arguments to identify slots. While Chambers and Jurafsky (2011) represents a major step forward in frame induction, it is also limited in several aspects. The clustering used ad hoc steps and customized similarity metrics, as well as an additional retrieval step from a large external text corpus for slot generation. This makes it hard to replicate their approach or adapt it to new domains. Lacking a coherent model, it is also difficult to incorporate additional linguistic insights and prior knowledge.\nIn this paper, we present ProFinder (PRObabilistic Frame INDucER), which is the first probabilistic approach for frame induction. ProFinder defines a joint distribution over the words in a document and their frame assignments by modeling frame and event transition, correlations among events and slots, and their surface realizations. Given a set of documents, ProFinder outputs a set of induced frames with learned parameters, as well as the most probable frame assignments that can be used for event and entity extraction. The numbers of events and slots are dynamically determined by a novel application of the split-merge approach from syntactic parsing (Petrov et al., 2006). In end-to-end evaluations from text to entity extraction using the standard MUC and TAC datasets, ProFinder achieved state-of-the-art results while significantly reducing engineering effort and requiring no external data."}, {"heading": "2 Related Work", "text": "In information extraction and other semantic processing tasks, the dominant paradigm requires two stages of manual effort. First, the target representation is defined manually by domain experts. Then, manual effort is required to construct an extractor or annotate examples to train a machine-learning system. Recently, there has been a burgeoning body of work in alleviating such manual effort. For example, a popular approach to reduce annotation effort is\nbootstrapping from seed examples (Patwardhan and Riloff, 2007; Huang and Riloff, 2012). However, this still requires prespecified frames or templates, and selecting seed words is often a challenging task due to semantic drift (Curran et al., 2007). Open IE (Banko and Etzioni, 2008) reduces the manual effort to designing a few domain-independent relation patterns, which can then be applied to extract relational triples from text. While extremely scalable, this approach can only extract atomic factoids within a sentence, and the resulting triples are noisy, non-cannonicalized text fragments.\nMore relevant to our approach is the recent work in unsupervised semantic induction, such as unsupervised semantic parsing (Poon and Domingos, 2009), unsupervised semantical role labeling (Swier and Stevenson, 2004) and induction (Lang and Lapata, 2011, e.g.), and slot induction from web search logs (Cheung and Li, 2012). As in ProFinder, they also model distributional contexts for slot or role induction. However, these approaches focus on semantics in independent sentences, and do not capture discourse-level dependencies.\nThe modeling component for frame and event transitions in ProFinder is similar to a sequential topic model (Gruber et al., 2007), and is inspired by the successful applications of such topic models in summarization (Barzilay and Lee, 2004; Daume\u0301 III and Marcu, 2006; Haghighi and Vanderwende, 2009, inter alia). There are, however, two main differences. First, ProFinder contains not a single sequential topic model, but two (for frames and events, respectively). In addition, it also models the interdependencies among events, slots, and surface text, which is analogous to the USP model (Poon and Domingos, 2009). ProFinder can thus be viewed as a novel combination of state-of-theart models in unsupervised semantics and discourse modeling.\nIn terms of aim and capability, ProFinder is most similar to Chambers and Jurafsky (2011), which culminated from a series of work for identifying correlated events and arguments in narrative (Chambers and Jurafsky, 2008; Chambers and Jurafsky, 2009). By adopting a probabilistic approach, ProFinder has a sound theoretical underpinning, and is easy to modify or extend. For example, in Section 3, we show how ProFinder can easily be\naugmented with additional linguistically-motivated features. Likewise, ProFinder can easily be used as a semi-supervised system if some slot designations and labeled examples are available.\nThe idea of representing and capturing stereotypical knowledge has a long history in artificial intelligence and psychology, and has assumed various names such as frames (Minsky, 1974), schemata (Rumelhart, 1975), and scripts (Schank and Abelson, 1977). In the linguistics and computational linguistics communities, frame semantics (Fillmore, 1982) uses frames as the central representation of word meaning, culminating in the development of FrameNet (Baker et al., 1998), which contains over 1000 manually annotated frames. A similarly rich lexical resource is the MindNet project (Richardson et al., 1998). Our notion of frame is related to these representations, but there are also subtle differences. For example, Minsky\u2019s frame emphasizes inheritance, which we do not model in this paper. (It should be a straightforward extension: using the split-and-merge approach, ProFinder already produces a hierarchy of events and slots in learning, although currently, it simply discards the intermediate levels.) As in semantic role labeling, FrameNet focuses on semantic roles and does not model event or frame transitions, so the scope of its frames is often no more than an event in our model. Perhaps the most similar to our frame is Roger Schank\u2019s scripts, which capture prototypical events and participants in a scenario such as restaurant dining. In their approach, however, scripts are manually defined, making it hard to generalize. In this regard, our work may be viewed as an attempt to revive a long tradition in AI and linguistics, by leveraging the recent advances in computational power, NLP, and machine learning."}, {"heading": "3 Probabilistic Frame Induction", "text": "In this section, we present ProFinder, a probabilistic model for frame induction. Let F be a set of frames, where each frame F = (EF , SF ) comprises a unique set of eventsEF and slots SF . Given a documentD and a word w inD, Zw = (f, e) represents an assignment of w to frame f \u2208 F and frame element e \u2208 Ef \u222a Sf . At the heart of ProFinder is a generative model P\u03b8(D,Z) that defines a joint\ndistribution over document D and the frame assignment to its words Z. Given a set of documents D, frame induction in ProFinder amounts to determining the number of frames, events and slots, as well as learning the parameters \u03b8 by summing out the latent assignmentsZ to maximize the likelihood of the document set \u220f\nD\u2208D P\u03b8(D).\nThe induced frames identify the key event structures in the document set. Additionally, ProFinder can also conduct event and entity extraction by computing the most probable frame assignment Z. In the remainder of the section, we first present the base model for ProFinder. We then introduce several linguistically motivated refinements, and efficient algorithms for learning and inference in ProFinder."}, {"heading": "3.1 Base Model", "text": "The probabilistic formulation of ProFinder makes it extremely flexible for incorporating linguistic intuition and prior knowledge. In this paper, we design our ProFinder model to capture three types of dependencies.\nFrame transitions between clauses A sentence contains one or more clauses, each of which is a minimal unit expressing a proposition. A clause is unlikely to straddle across different frames, so we stipulate that the words in a clause be assigned to the same frame. On the other hand, frame transitions can happen between clauses, and we adopt the common Markov assumption that the frame of a clause only depends on the clause immediately to its left. Here, sentences are ordered sequentially as they appear in the documents. Clauses are automatically extracted from the dependency parse and further decomposed into an event head and its syntactic arguments; see the experiment section for details.\nEvent transitions within a frame Events tend to transition into related events in the same frame, as determined by their causal or temporal relations. Each clause is assigned an event compatible with its frame assignment (i.e., the event is in the given frame). As for frame transitions, we assume that the event assignment of a clause depends only on the event of the previous clause.\nEmission of event heads and slot words Similar to topics in topic models, each event determines a multinomial from which the event head is generated. E.g., a detonation event might use verbs such as detonate, set off or nouns such as denotation, bombing as its event head. Additionally, as in USP (Poon and Domingos, 2009), an event also contains a multinomial of slots for each of its argument types1. E.g., the agent argument of a detonation event is generally the PERPETRATOR slot of the BOMBING frame. Finally, each slot has its own multinomials for generating the argument head and dependency label, regardless of the event.\nFormally, let D be a document and C1, \u00b7 \u00b7 \u00b7 , Cl be its clauses, the ProFinder model is defined by\nP\u03b8(D,Z) = PF\u2212INIT(F1)\u00d7 \u220f i PF\u2212TRAN(Fi+1|Fi)\n\u00d7 PE\u2212INIT(E1|F1) \u00d7 \u220f i PE\u2212TRAN(Ei+1|Ei, Fi+1, Fi)\n\u00d7 \u220f i PE\u2212HEAD(ei|Ei)\n\u00d7 \u220f i,j PSLOT(Si,j |Ei,j , Ai,j)\n\u00d7 \u220f i,j PA\u2212HEAD(ai,j |Si,j)\n\u00d7 \u220f i,j PA\u2212DEP(depi,j |Si,j)\nHere, Fi, Ei denote the frame and event assignment to clause Ci, respectively, and ei denotes the event head. For the j-th argument of clause i, Si,j denotes the slot assignment, Ai,j the argument type, ai,j the head word, and depi,j the dependency from the event head. PE\u2212TRAN(Ei+1|Ei, Fi+1, Fi) = PE\u2212INIT(Ei+1|Fi+1) if Fi+1 6= Fi.\nEssentially, ProFinder combines a frame HMM with an event HMM, where the first models frame transition and emits events, and the second models event transition within a frame and emits argument slots.\n1USP generates the argument types along with events from clustering. For simplicity, in ProFinder we simply classify a syntactic argument into subject, object, and prepositional object, according to its Stanford dependency to the event head."}, {"heading": "3.2 Model refinements", "text": "The base model captures the main dependencies in event narrative, but it can be easily extended to leverage additional linguistic intuition. ProFinder incorporates three such refinements.\nBackground frame Event narratives often contain interjections of general content common to all frames. For example, in newswire articles, ATTRIBUTION is commonplace to describe who said or reported a particular quote or fact. To avoid contaminating frames with generic content, we introduce a background frame with its own events, slots, and emission distributions, and a binary switch variable Bi \u2208 {BKG,CNT} that determines whether clause i is generated from the actual content frame Fi (CNT ) or background (BKG). We also stipulate that if background is chosen, the nominal frame stays the same as the previous clause.\nStickiness in frame and event transitions Prior work has demonstrated that promoting topic coherence in natural-language discourse helps discourse modeling (Barzilay and Lee, 2004). We extend ProFinder to leverage this intuition by incorporating a \u201cstickiness\u201d prior (Haghighi and Vanderwende, 2009) to encourage neighboring clauses to stay in the same frame. Specifically, along with introducing the background frame, the frame transition component now becomes\nPF\u2212TRAN(Fi+1|Fi, Bi+1) = (1) 1(Fi+1 = Fi), if Bi+1 = BKG \u03b21(Fi+1 = Fi)+\n(1\u2212 \u03b2)PF\u2212TRAN(Fi+1|Fi), if Bi+1 = CNT\nwhere \u03b2 is the stickiness parameter, and the event transition component correspondingly becomes\nPE\u2212TRAN(Ei+1|Ei, Fi+1, Fi, Bi+1) = (2) 1(Ei+1 = Ei), if Bi+1 = BKG PE\u2212TRAN(Ei+1|Ei), if Bi+1 = CNT,Fi = Fi+1 PE\u2212INIT(Ei+1), if Bi+1 = CNT,Fi 6= Fi+1\nArgument dependencies as caseframes As noticed in previous work such as Chambers and Jurafsky (2011), the combination of an event head\nand a dependency relation often gives a strong signal of the slot that is indicated. For example, bomb > nsubj often indicates a PERPETRATOR. Thus, rather than simply emitting the dependency from the event head to an event argument depi,j , our model instead emits the pair of event head and dependency relation, which we call a caseframe following Bean and Riloff (2004)."}, {"heading": "3.3 Full generative story", "text": "To summarize, the distributions that are learned by our model are the default distributions PBKG(B), PF\u2212INIT(F ), PE\u2212INIT(E), the transition distributions PF\u2212TRAN(Fi+1|Fi), PE\u2212TRAN(Ei+1|Ei), and the emission distributions PSLOT(S|E,A,B), PE\u2212HEAD(e|E,B), PA\u2212HEAD(a|S), PA\u2212DEP(dep|S). We used additive smoothing with uniform Dirichlet priors for all the multinomials. The overall generative story of our model is as follows:\n1. Draw a Bernoulli distribution for PBKG(B) 2. Draw the frame, event, and slot distributions 3. Draw an event head emission distribution PE\u2212HEAD(e|E,B) for each frame including the background frame 4. Draw event argument lemma and caseframe emission distributions for each slot in each frame including the background frame\n5. For each clause in each document, generate the clause-internal structure.\nThe clause-internal structure at clause i is generated by the following steps:\n1. Generate whether this clause is background (Bi \u2208 {CNT,BKG} \u223c PBKG(B)) 2. Generate the frame Fi and event Ei from PF\u2212INIT(F ), PE\u2212INIT(E), or according to equations 1 and 2 3. Generate the observed event head ei from PE\u2212HEAD(ei|Ei). 4. For each event argument: (a) Generate the slot Si,j from\nPSLOT(S|E,A,B). (b) Generate the dependency/caseframe emis-\nsion depi,j \u223c PA\u2212DEP(dep|S) and the lemma of the head word of the event argument ai,j \u223c PA\u2212HEAD(a|S)."}, {"heading": "3.4 Learning and Inference", "text": "Our generative model admits efficient inference by dynamic programming. In particular, after collapsing the latent assignment of frame, event, and background into a single hidden variable for each clause, the expectation and most probable assignment can be computed using standard forward-backward and Viterbi algorithms.\nParameter learning can be done using EM by alternating the computation of expected counts and the maximization of multinomial parameters. In particular, ProFinder used incremental EM, which has been shown to have better and faster convergence properties than standard EM (Liang and Klein, 2009).\nDetermining the optimal number of events and slots is challenging. One solution is to adopt nonparametric Bayesian methods by incorporating a hierarchical prior over the parameters (e.g., a Dirichlet process). However, this approach can impose unrealistic restrictions on the model choice and result in intractability which requires sampling or approximate inference to overcome. Additionally, EM learning can suffer from local optima due to its nonconvex learning objective, especially when dealing with a large number hidden states without a good initialization.\nTo address these issues, we adopt a novel application of the split-merge method previously used in\nsyntactic parsing for inferring refined latent syntactic categories (Petrov et al., 2006). Specifically, we initialize our model such that each frame is associated with one event and two slots. Then, after a number of iterations of EM, we split each event and slot in two along with their probability, and duplicate the associated emission distributions. We then add some perturbation to break symmetry. After splitting, we merge back a proportion of the newly split events and slots that result in the least improvement in the likelihood of the training data. For more details on split-merge, see (Petrov et al., 2006)\nBy adjusting the number of split-merge cycles and the merge parameters, our model learns the number of events and slots in a dynamical fashion that is tailored to the data. Moreover, our model starts with a small number of frame elements, which reduces the number of local optima and make initial learning easier. After each split, the subsequent learning starts with (a perturbed version of) the previously learned parameters, which makes a good initialization that is crucial for EM. Finally, it is also compatible with the hierarchical nature of events and slots. For example, slots can first be coarsely split into persons versus locations, and later refined into subcategories such as perpetrators and victims."}, {"heading": "4 MUC-4 Entity Extraction Experiments", "text": "We first evaluate our model on a standard entity extraction task, using the evaluation settings from Chambers and Jurafsky (2011) to enable a head-tohead comparison. Specifically, we use the MUC-4 data set (muc, 1992), which contains 1300 training and development documents on terrorism in South America, with 200 additional documents for testing. MUC-4 contains four templates: attack, kidnapping, bombing, and arson.2 All templates share the same set of predefined slots, with the evaluation focusing on the following four: perpetrator, physical target, human target, and instrument.\nFor each slot in a MUC template, the system first identified an induced slot that best maps to it by F1 on the development set. As in Chambers and Jurafsky (2011), template is ignored in final evaluation. So the system merged the induced slots across all\n2Two other templates have negligible counts and are ignored as in Chambers and Jurafsky (2011).\ntemplates to calculate the final scores. Correctness is determined by matching head words, and slots marked as optional in MUC are ignored when computing recall. All hyper-parameters are tuned on the development set3.\nDocument classification The MUC-4 dataset contains many documents that contain words related to MUC slots (e.g., plane and aviation), but are not about terrorism. To reduce precision errors, Chambers and Jurafsky\u2019s (2011) (henceforth, C&J) first filtered irrelevant documents based on the specificity of event heads to learned frames. To estimate the specificity, they used additional data retrieved from a large external corpus. In ProFinder, however, specificity can be easily estimated using the probability distributions learned during training. In particular, we define the probability of an event head in a frame j:\nPF (w) = \u2211 EF\u2208F PE\u2212HEAD(w|E)/|F |, (3)\nand the probability of a frame given an event head: P (F |w) = PF (w)/ \u2211 F \u2032\u2208F PF \u2032(w). (4)\nWe then follow the rest of Chambers and Jurafsky (2011) to score each learned frame with each MUC document, mapping a document to a frame if the average PF (w) in the document is above a threshold and the document contains at least one trigger word w\u2032 with P (F |w\u2032) > 0.2. The threshold and the induced frame were determined on the development set, which were then used to filter irrelevant documents in the test set.\nResults Compared to C&J, ProFinder is conceptually much simpler, involving a single probabilistic model, with standard learning and inference algorithms. In particular, it did not require multiple processing steps or customized similarity metrics; rather, it only used the data within MUC-4. In contrast, C&J required additional text to be retrieved from a large external corpus (Gigaword (Graff et al., 2005)) for each event cluster, yet ProFinder nevertheless was able to outperform C&J on entity extraction, as shown in Table 1. Our system achieved\n3We will make the parameter settings used in all experiments publicly available.\ngood recall but was hurt by the lower precision. We investigated the importance of document classification by only extracting from the gold-standard relevant documents (+doc. classification), which led to a substantial improvement in precision, suggesting possible further improvement by better document classification. Also unlike C&J, our system does not currently make use of coreference information.\nFigure 2 shows part of a frame that is learned by ProFinder, including some of the standard MUC slots and events. Our method also finds events not annotated in MUC, such as the discussion event. Other interesting events and slots that we noticed include an arrest event (call, arrest, express, meet, charge), a peace agreement slot (agreement, rights, law, proposal), and an authorities slot (police, gov-\nernment, force, command). The background frame was able to capture many verbs related to reporting, such as say, continue, add, believe, although it missed report."}, {"heading": "5 Evaluating Frame Induction Using Guided Summarization Templates", "text": "One issue with the MUC-4 evaluation is the limited variety of templates and entities that are available. Moreover, this data set was specifically developed for information extraction and questions remain whether our approach can generalize beyond it. We thus conducted a novel evaluation using the TAC guided summarization data set, which contains a wide variety of frames and topics. Our evaluation corresponds to a view of summarization as extracting structured information from the source text, and highlights the connection between summarization and information extraction (White et al., 2001).\nData preparation We use the TAC 2010 guided summarization data set for our experiments (Owczarzak and Dang, 2010). This data set provides templates as defined by the task organizers and contains 46 document clusters in five domains, with each cluster comprising 20 documents on a specific topic. Eight human-written model sum-\nmaries are provided for each document cluster. As part of the Pyramid evaluation method (Nenkova and Passonneau, 2004), these summaries have been manually segmented and labeled with slots from the corresponding template for each segment (Figure 3)4.\nWe first considered defining the task as extracting entities from the source text, but this annotation is not available in TAC, and pilot studies suggested that it required nontrivial effort to train average users to conduct high-quality annotation reliably. We thus defined our task as extracting entities from the model summaries instead. As mentioned earlier, TAC slot annotation is available for summaries. Furthermore, using the summary text has the advantage that slots that are considered important in the domain naturally appear more frequently, whereas unimportant text is filtered out.\nEach span that is labeled by a slot is called a contributor. We convert the contributors into a form that is more like the previous MUC evaluation, so that we can fairly compare against previous work like C&J that were designed to extract information into that form. Specifically, we extract the head lemma from all the maximal noun phrases found in the contributor. Like in MUC-4, we count a system-extracted noun phrase as a match if this head word matches and is extracted from the same document (i.e., summary). This process can lead to noise, as the meaning of some contributors depend on a larger phrasal unit than a noun phrase, but this heuristic normalizes the representations of the contributors so that they are amenable to our evaluation. We leave the denoising of this process to future work, and believe it should be feasible by crowdsourcing.\nMethod and experiments The induced entity clusters are mapped to the TAC slots in the TAC frames according to the best F1 achieved for each TAC slot. However, one issue is that many TAC slots are more general than the type of slots found in MUC. For example, slots like WHY and COUNTERMEASURES likely correspond to multiple slots at the granularity of MUC. Thus, we map theN -best induced slots to TAC slots rather than the 1-best, for\n4The full set of slots is available at http: //www.nist.gov/tac/2010/Summarization/ Guided-Summ.2010.guidelines.html\nN up to 5. We train ProFinder and a reimplementation of C&J on the 920 full source texts of TAC 2010, and test them on the 368 model summaries. We do not provide C&J\u2019s model with access to external data, in order to create fair comparison conditions to our model. We also eliminate a sentence relevance classification step from C&J, and the document relevance classification step from both models, because all sentences in the summary text are expected to be relevant. We tune C&J\u2019s clustering thresholds and the parameters to our model by twofold cross validation on the summaries, and assume gold summary classification into the five topic categories defined by TAC.\nResults The results on TAC are shown in Table 2. The overall results are poorer than for the MUC-4 task, but this task is harder given the greater diversity in frames and slots to be induced. Like in the previous evaluation, our system is able to outperform C&J in terms of recall and F1, but not precision. C&J\u2019s method produces many small clusters, which makes it easy to achieve high precision. The N -to-1 mapping procedure can also be seen to favor their method over ours, many small clusters with high precision can be selected to greatly improve recall, which is indeed the case. However, ProFinder with 1-to-1 mapping outperforms C&J even with 5- to-1 mapping."}, {"heading": "6 Conclusion", "text": "We have presented the first probabilistic approach to frame induction and shown that it achieves stateof-the-art results on end-to-end entity extraction in standard MUC and TAC data sets. Our model is inspired by recent advances in unsupervised semantic induction and in content modeling in summarization, and is easy to extend. We would like to further\ninvestigate frame induction evaluation, for example to evaluate event clustering in addition to the slots and entities."}, {"heading": "Acknowledgments", "text": "We would like to thank Nate Chambers for answering questions about his system. We would also like to thank Chris Quirk for help with preprocessing the MUC corpus, and the other members of the NLP group at Microsoft Research for useful discussions."}], "references": [{"title": "The Berkeley FrameNet project", "author": ["Charles J. Fillmore", "John B. Lowe"], "venue": "In Proceedings of the 17th International Conference on Computational linguistics", "citeRegEx": "Baker et al\\.,? \\Q1998\\E", "shortCiteRegEx": "Baker et al\\.", "year": 1998}, {"title": "The tradeoffs between open and traditional relation extraction", "author": ["Banko", "Etzioni2008] Michele Banko", "Oren Etzioni"], "venue": "Proceedings of ACL-08: HLT,", "citeRegEx": "Banko et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Banko et al\\.", "year": 2008}, {"title": "Catching the drift: Probabilistic content models, with applications to generation and summarization", "author": ["Barzilay", "Lee2004] Regina Barzilay", "Lillian Lee"], "venue": "In Proceedings of the Human Language Technology Conference of the North American Chapter", "citeRegEx": "Barzilay et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Barzilay et al\\.", "year": 2004}, {"title": "Unsupervised learning of contextual role knowledge for coreference resolution", "author": ["Bean", "Riloff2004] David Bean", "Ellen Riloff"], "venue": "In Proceedings of the Human Language Technology Conference of the North American Chapter of the Association", "citeRegEx": "Bean et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Bean et al\\.", "year": 2004}, {"title": "Unsupervised learning of narrative event chains", "author": ["Chambers", "Jurafsky2008] Nathanael Chambers", "Dan Jurafsky"], "venue": "In Proceedings of ACL-08: HLT,", "citeRegEx": "Chambers et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Chambers et al\\.", "year": 2008}, {"title": "Unsupervised learning of narrative schemas and their participants", "author": ["Chambers", "Jurafsky2009] Nathanael Chambers", "Dan Jurafsky"], "venue": "In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference", "citeRegEx": "Chambers et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Chambers et al\\.", "year": 2009}, {"title": "Template-based information extraction without the templates", "author": ["Chambers", "Jurafsky2011] Nathanael Chambers", "Dan Jurafsky"], "venue": "In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies,", "citeRegEx": "Chambers et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Chambers et al\\.", "year": 2011}, {"title": "Sequence clustering and labeling for unsupervised query intent discovery", "author": ["Cheung", "Li2012] Jackie C.K. Cheung", "Xiao Li"], "venue": "In Proceedings of the 5th ACM International Conference on Web Search and Data Mining,", "citeRegEx": "Cheung et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Cheung et al\\.", "year": 2012}, {"title": "Minimising semantic drift with mutual exclusion bootstrapping", "author": ["Tara Murphy", "Bernhard Scholz"], "venue": "In Proceedings of the 10th Conference of the Pacific Association for Computational Linguistics", "citeRegEx": "Curran et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Curran et al\\.", "year": 2007}, {"title": "Bayesian Query-Focused summarization", "author": ["III Daum\u00e9", "III Marcu2006] Hal Daum\u00e9", "Marcu. Daniel"], "venue": "In Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguis-", "citeRegEx": "Daum\u00e9 et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Daum\u00e9 et al\\.", "year": 2006}, {"title": "English gigaword second edition. Linguistic Data Consortium, Philadelphia", "author": ["Graff et al.2005] David Graff", "Junbo Kong", "Ke Chen", "Kazuaki Maeda"], "venue": null, "citeRegEx": "Graff et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Graff et al\\.", "year": 2005}, {"title": "Hidden topic markov models. Artificial Intelligence and Statistics (AISTATS)", "author": ["Gruber et al.2007] Amit Gruber", "Michael Rosen-Zvi", "Yair Weiss"], "venue": null, "citeRegEx": "Gruber et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Gruber et al\\.", "year": 2007}, {"title": "Exploring content models for multi-document summarization", "author": ["Haghighi", "Vanderwende2009] Aria Haghighi", "Lucy Vanderwende"], "venue": "In Proceedings of Human Language Technologies: The 2009 Annual Conference of the North American Chapter", "citeRegEx": "Haghighi et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Haghighi et al\\.", "year": 2009}, {"title": "Bootstrapped training of event extraction classifiers", "author": ["Huang", "Riloff2012] Ruihong Huang", "Ellen Riloff"], "venue": "In Proceedings of the 13th Conference of the European Chapter of the Association for Computational Linguistics,", "citeRegEx": "Huang et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Huang et al\\.", "year": 2012}, {"title": "Unsupervised semantic role induction via splitmerge clustering", "author": ["Lang", "Lapata2011] Joel Lang", "Mirella Lapata"], "venue": "In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies,", "citeRegEx": "Lang et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Lang et al\\.", "year": 2011}, {"title": "Online EM for unsupervised models", "author": ["Liang", "Klein2009] Percy Liang", "Dan Klein"], "venue": "In Proceedings of Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the Association for Computational Linguistics,", "citeRegEx": "Liang et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Liang et al\\.", "year": 2009}, {"title": "A framework for representing knowledge", "author": ["Marvin Minsky"], "venue": "Technical report,", "citeRegEx": "Minsky.,? \\Q1974\\E", "shortCiteRegEx": "Minsky.", "year": 1974}, {"title": "Evaluating content selection in summarization: The pyramid method", "author": ["Nenkova", "Passonneau2004] Ani Nenkova", "Rebecca Passonneau"], "venue": "In Proceedings of the Human Language Technology Conference of the North American Chapter of the Association", "citeRegEx": "Nenkova et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Nenkova et al\\.", "year": 2004}, {"title": "TAC 2010 guided summarization task guidelines", "author": ["Owczarzak", "Dang2010] Karolina Owczarzak", "Hoa T. Dang"], "venue": null, "citeRegEx": "Owczarzak et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Owczarzak et al\\.", "year": 2010}, {"title": "Effective information extraction with semantic affinity patterns and relevant regions", "author": ["Patwardhan", "Riloff2007] Siddharth Patwardhan", "Ellen Riloff"], "venue": "In Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Process-", "citeRegEx": "Patwardhan et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Patwardhan et al\\.", "year": 2007}, {"title": "Learning accurate, compact, and interpretable tree annotation", "author": ["Petrov et al.2006] Slav Petrov", "Leon Barrett", "Romain Thibaux", "Dan Klein"], "venue": "In Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting", "citeRegEx": "Petrov et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Petrov et al\\.", "year": 2006}, {"title": "Unsupervised semantic parsing", "author": ["Poon", "Domingos2009] Hoifung Poon", "Pedro Domingos"], "venue": "In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing,", "citeRegEx": "Poon et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Poon et al\\.", "year": 2009}, {"title": "MindNet: Acquiring and structuring semantic information from text", "author": ["William B. Dolan", "Lucy Vanderwende"], "venue": "In Proceedings of the 36th Annual Meeting of the Association", "citeRegEx": "Richardson et al\\.,? \\Q1998\\E", "shortCiteRegEx": "Richardson et al\\.", "year": 1998}, {"title": "Scripts, Plans, Goals, and Understanding: An Inquiry Into Human Knowledge Structures", "author": ["Schank", "Abelson1977] Roger C. Schank", "Robert P. Abelson"], "venue": null, "citeRegEx": "Schank et al\\.,? \\Q1977\\E", "shortCiteRegEx": "Schank et al\\.", "year": 1977}, {"title": "Unsupervised semantic role labelling", "author": ["Swier", "Stevenson2004] Robert S. Swier", "Suzanne Stevenson"], "venue": "Proceedings of EMNLP", "citeRegEx": "Swier et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Swier et al\\.", "year": 2004}, {"title": "Multidocument summarization via information extraction", "author": ["White et al.2001] Michael White", "Tanya Korelsky", "Claire Cardie", "Vincent Ng", "David Pierce", "Kiri Wagstaff"], "venue": "In Proceedings of the First International Conference on Human Language Technology", "citeRegEx": "White et al\\.,? \\Q2001\\E", "shortCiteRegEx": "White et al\\.", "year": 2001}], "referenceMentions": [{"referenceID": 20, "context": "The numbers of events and slots are dynamically determined by a novel application of the split-merge approach from syntactic parsing (Petrov et al., 2006).", "startOffset": 133, "endOffset": 154}, {"referenceID": 8, "context": "However, this still requires prespecified frames or templates, and selecting seed words is often a challenging task due to semantic drift (Curran et al., 2007).", "startOffset": 138, "endOffset": 159}, {"referenceID": 11, "context": "The modeling component for frame and event transitions in ProFinder is similar to a sequential topic model (Gruber et al., 2007), and is inspired by the successful applications of such topic models in summarization (Barzilay and Lee, 2004;", "startOffset": 107, "endOffset": 128}, {"referenceID": 16, "context": "The idea of representing and capturing stereotypical knowledge has a long history in artificial intelligence and psychology, and has assumed various names such as frames (Minsky, 1974), schemata (Rumelhart, 1975), and scripts (Schank and Abelson, 1977).", "startOffset": 170, "endOffset": 184}, {"referenceID": 0, "context": "In the linguistics and computational linguistics communities, frame semantics (Fillmore, 1982) uses frames as the central representation of word meaning, culminating in the development of FrameNet (Baker et al., 1998), which contains over", "startOffset": 197, "endOffset": 217}, {"referenceID": 22, "context": "A similarly rich lexical resource is the MindNet project (Richardson et al., 1998).", "startOffset": 57, "endOffset": 82}, {"referenceID": 20, "context": "syntactic parsing for inferring refined latent syntactic categories (Petrov et al., 2006).", "startOffset": 68, "endOffset": 89}, {"referenceID": 20, "context": "For more details on split-merge, see (Petrov et al., 2006)", "startOffset": 37, "endOffset": 58}, {"referenceID": 10, "context": "from a large external corpus (Gigaword (Graff et al., 2005)) for each event cluster, yet ProFinder nevertheless was able to outperform C&J on entity extraction, as shown in Table 1.", "startOffset": 39, "endOffset": 59}, {"referenceID": 25, "context": "tion and information extraction (White et al., 2001).", "startOffset": 32, "endOffset": 52}], "year": 2013, "abstractText": "In natural-language discourse, related events tend to appear near each other to describe a larger scenario. Such structures can be formalized by the notion of a frame (a.k.a. template), which comprises a set of related events and prototypical participants and event transitions. Identifying frames is a prerequisite for information extraction and natural language generation, and is usually done manually. Methods for inducing frames have been proposed recently, but they typically use ad hoc procedures and are difficult to diagnose or extend. In this paper, we propose the first probabilistic approach to frame induction, which incorporates frames, events, participants as latent topics and learns those frame and event transitions that best explain the text. The number of frames is inferred by a novel application of a split-merge method from syntactic parsing. In end-to-end evaluations from text to induced frames and extracted facts, our method produced state-of-the-art results while substantially reducing engineering effort.", "creator": "LaTeX with hyperref package"}}}