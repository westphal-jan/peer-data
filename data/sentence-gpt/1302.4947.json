{"id": "1302.4947", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "20-Feb-2013", "title": "Plausibility Measures: A User's Guide", "abstract": "We examine a new approach to modeling uncertainty based on plausibility measures, where a plausibility measure just associates with an event its plausibility, an element is some partially ordered set. This approach is easily seen to generalize other approaches to modeling uncertainty, such as probability measures, belief functions, and possibility measures. The lack of structure in a plausibility measure makes it easy for us to add structure on an \"as needed\" basis, letting us examine what is required to ensure that a plausibility measure has certain properties of interest. This gives us insight into the essential features of the properties in question, while allowing us to prove general results that apply to many approaches to reasoning about uncertainty. Plausibility measures have already proved useful in analyzing default reasoning. In this paper, we examine their \"algebraic properties,\" analogues to the use of + and * in probability theory. An understanding of such properties will be essential if plausibility measures are to be used in practice as a representation tool. To further examine the properties of a hypothetical action, we examine the relation between an action and a probability measure. For example, if we expect a probability measure to be a measure of probability to be a probability measure, then we assume that a probability measure to be a probability measure can be a model of probability. We find that a probability measure to be a probability measure can be a model of probability. In this case, we assume that our model of probability might be a model of probability, which would be the result of a probability measure having some properties, such as probability of probability of chance.\n\n\n\n\n\n\n\nThe above article provides a summary of what we expect to obtain from a predictive model:\nGiven our predictions of the likelihood of a probability measure, we can infer what is required to predict the likelihood of a probability measure with the form of a probability measure (e.g., if we choose the probability measure, we can infer what is required to predict the probability measure) that our predictions of the probability measure will be accurate or not.\nThe following table summarizes the probabilities of these probabilities (n = 6) when we calculate probabilities to have a probability measure.\nThe likelihood of a probability measure to be a probability measure (n = 6) is the expected probability of a probability measure of a probability measure (n = 6) if the probability measure is not (n = 6) then, we assume that the probability measure is a probability measure of probability. The probability measure is an element that is a probability measure for a probability", "histories": [["v1", "Wed, 20 Feb 2013 15:20:29 GMT  (428kb)", "http://arxiv.org/abs/1302.4947v1", "Appears in Proceedings of the Eleventh Conference on Uncertainty in Artificial Intelligence (UAI1995)"]], "COMMENTS": "Appears in Proceedings of the Eleventh Conference on Uncertainty in Artificial Intelligence (UAI1995)", "reviews": [], "SUBJECTS": "cs.AI", "authors": ["nir friedman", "joseph y halpern"], "accepted": false, "id": "1302.4947"}, "pdf": {"name": "1302.4947.pdf", "metadata": {"source": "CRF", "title": "Plausibility Measures: A User's Guide", "authors": ["Nir Friedman", "Joseph Y. Halpern"], "emails": ["nir@cs.stanford.edu", "halpem@almaden.ibm.com"], "sections": [{"heading": null, "text": "1 INTRODUCTION\nWe must reason and act in an uncertain world. There may be uncertainty about the state of the world, uncertainty about the effects of our actions, and uncertainty about other agents' actions. The standard approach to modeling uncer tainty is probability theory. In recent years, researchers, motivated by varying concerns including a dissatisfaction with some of the axioms of probability and a desire to represent information more qualitatively, have introduced a number of generalizations and alternatives to probability, such as Dempster-Shafer belief functions [Shafer 1976], possibility measures [Dubois and Prade 1990], and qualita tive probability [Fine 1973]. Our aim is to examine what is perhaps the most general approach possible to representing uncertainty, which we call a plausibility measure. A plausi bility measure associates with a set its plausibility, which is just an element in a partially ordered space. Every system-\natic approach for dealing with uncertainty that we are aware of can be viewed as a plausibility measure. Given how little structure we have required of a plausibility measure, this is perhaps not surprising.\nAs we shall show, this lack of structure turns out to be a significant advantage of plausibility measures. By adding structure on an \"as needed\" basis, we are able to understand what is required to ensure that a plausibility measure has certain properties of interest. This gives us insight into the essential features of the properties in question while allowing us to prove general results that apply to many approaches to reasoning about uncertainty. For example, in [Friedman and Halpern 1995a] we examine a necessary and sufficient condition for getting the KLM properties [Kraus et al. 1990] for defaults. Once we identify this condition, it is quite easy to show why many different approaches (such as preferential structures [Kraus et al. 1990], K rankings [Spohn 1987; Goldszmidt and Pearl 1992], and possibility measures [Benferhat et al. 1992]) all satisfy the KLM properties. Moreover, we also describe a weak necessary and sufficient condition for the KLM properties to be complete. This condition is easily seen to hold in all of these approaches. These results help us understand why the KLM properties characterize default reasoning in several different approaches.\nIn this paper, we move beyond the realm of qualitative and default reasoning, and take a more general look at plau sibility measures. If plausibility measures are to be used as a tool for representing uncertainty, then we shall need to be able to emulate some aspects of probabilistic reason ing, such as reasoning by cases and the ability to condition. For example, a standard approach to computing Pr( A) is to write it as Pr(A IBt ) Pr(Bt) + \u00b7 \u00b7 \u00b7 + Pr(AIBn) Pr(Bn) , where Bt, ... , Bn is a partition of the space. Other tech niques for representing uncertainty, such as \ufffdt-rankings and possibility measures, support similar reasoning. We exam ine what properties a plausibility measure must satisfy to allow us to carry out such reasoning. We provide construc tions that will be useful for any user of plausibility, show ing, for example, how we can start with an unconditional plausibility measure and construct a conditional plausibility measure with attractive properties. We also examine what properties of conditional plausibility are required to capture a plausibilistic analogue of Bayesian networks. Recently,\n176 Friedman and Halpern\nDarwiche and Ginsberg [Darwiche and Ginsberg 1992; Dar wiche 1992] and Weydert [ 1994] have proposed \"abstract\" formalisms with somewhat similar aims; we show how plausibility measures provide some advantages over both of these approaches.\nThe rest of this paper is organized as follows. In Section 2 we describe plausibility measures. We investigate their algebraic properties in Section 3, and apply these results in Section 4 to reasoning about independence and qualitative reasoning. We conclude with some discussion in Section 5.\n2 PLAUSIBILITY MEASURES\nA probability space is a tuple (W, :F, Pr), where W is a set of worlds, :F is an algebra of measurable subsets of W (that is, a set of subsets closed under finite union and complementation to which we assign probability), and Pr is a probability measure, that is, a function mapping each set in :F to a number in (0 , I] satisfying the well-known Kolmogorov axioms (Pr(0) = 0, Pr(W) = 1, and Pr(A U B) = Pr(A) + Pr(B) if A and B are disjoint).1\nA plausibility space is a direct generalization of a proba bility space. We simply replace the probability measure Pr by a plausibility measure PI, which, rather than mapping sets in :F to numbers in (0 , I], maps them to elements in some arbitrary partially ordered set. We read PI( A) as \"the plausibility of set A\". If PI( A) \ufffd PI( B), then B is at least as plausible as A. Formally, a plausibility space is a tuple S = (W, :F, D, PI), where W is a set of worlds, :F is an al gebra of subsets of W, D is a domain of plausibility values partially ordered by a relation \ufffdD (so that \ufffdD is reflexive, transitive, and anti-symmetric), and PI maps the sets in :F to D. We assume that D is pointed: that is, it contains two special elements T D and .ln such that .ln <n d <n T D for all d E D; we further assume that PI(W) = T D and PI(0) =.ln. As usual, we define the ordering <n by taking dt <n d2 if dt \ufffdD d2 and dt # d2. We omit the subscript D from \ufffdD. <n. T n. and .ln whenever it is clear from context.\nSome brief remarks on the definition: The algebra :F does not play a significant role in this paper. We have chosen to allow the generality of having an algebra of measurable sets to make it clear that plausibility spaces generalize probabil ity spaces. For ease of exposition, we omit the :F from here on in, always taking it to be 2 w, and just denote a plausibil ity space as (W, D, PI). In some applications we also do not care about the domain D. All that matters is the ordering induced by \ufffdD on the subsets in :F (see for example [Fried man and Halpern 1995a; Friedman et al. 1995]). However, in dealing with conditional plausibility the domain D plays a more significant role.\nSo far, the only assumption we have made about plausibility is that \ufffd is a partial order. We make one further assumption:\n1 Frequently it is also assumed that Pr satisfies countable addi tivity, i.e., if A,, i > 0, are pairwise disjoint, then Pr(U, A,) = L, Pr(A,). We defer a discussion of countable additivity to the full paper.\nAl. If A \ufffd B, then PI( A) \ufffd PI( B).\nThus, a set must be at least as plausible as any of its subsets. While this assumption holds for all the standard approaches to reasoning about uncertainty, we note that there are inter esting applications where this might not apply. For exam ple, if we take PI(A) to denote how \"happy\" an agent is if all he knows is that the true world is some world in A, then one could well imagine that A I might not hold. Knowing that the true world is w might be viewed as better than knowing that it is one of w and w'. For another example, suppose that we take PI(A) to denote the desirability of being in a situation where one needs to choose among elements of A. It is well known in the literature on choice theory that agents may occasionally view having more options as a worse situ ation, not a better one [Kreps 1988]. Despite these caveats, we shall assume A I for the remainder of the paper.\nClearly plausibility spaces generalize probability spaces. We now briefly discuss a few other notions of uncertainty that they generalize:\n\u2022 A belief function Bel on W is a function Bel : 2 w -t (0 , 1] satisfying certain axioms [Shafer 1976]. These axioms certainly imply property A1, so a belief func tion is a plausibility measure.\n\u2022 A fuzzy measure (or a Sugeno measure) f on W [Wang and Klir 1992] is a function f : 2w 1-+ (0 , 1], that satisfies A 1 and some continuity constraints. A possibility measure [Dubois and Prade 1990] Poss is a fuzzy measure with the additional property that Poss(A) = supwEA (Poss( { w} ).\n\u2022 An ordinal ranking (or K-ranking) on W (as defined by [Goldszmidt and Pearl 1992], based on ideas that go back to [Spohn 1987]) is a function\"' : 2 w --+ IN*, where IN* = IN U { oo }, such that \ufffdt(W) = 0, \ufffdt( 0) = oo, and K( A) = minaEA \ufffdt( {a}) if A # 0. Intuitively, an ordinal ranking assigns a degree of surprise to each subset of worlds in W, where 0 means unsurprising and higher numbers denote greater surprise. Again, it is easy to see that if \"' is a ranking on W, then (W, IN* , \"') is a plausibility space, where z \ufffdIN\u00b7 y if and only if y \ufffd z under the usual ordering on the ordinals.\n\u2022 A preference ordering on W is a partial order \ufffd over W. Intuitively, w -< w' holds if w is preferred to w'. Preference orders have been used to provide semantics for conditional (or default) statements. In [Friedman and Halpern 1995a] we show how to map preference orders on W to plausibility measures on W in a way that preserves the ordering of events of the form { w} as well as the truth values of defaults (see Section 4.2 for discussion).\n\u2022 A parametrized probability distribution (PPD) is a tu ple (W, {Pri : i 2: 0}) where each Pri is a probability measure over W. Such sequences of measures pro vide semantics for defaults in \u20ac-semantics [Pearl 1989; Goldszmidt et al. 1993]. In [Friedman and Halpern 1995a] we show how to map PPDs into plausibility measures in a way that preserves the truth-values of\ndefaults (again, see Section 4.2).\n\u2022 A qualitative probability space [Savage 1954; Fine 1973] is a pair (W, \ufffdP), where \ufffdP is a total pre-order over 2w that satisfies several additional properties. Intuitively, \ufffdP is a qualitative representation of some probability space Pr such that A \ufffdP B if and only if Pr(A) \ufffd Pr(B). A similar notion of qualitative possibility spaces is discussed in [Dubois 1986]. It easy to verify that both are instances of plausibility spaces.\nFor a plausibility measure PI with a domain D where sub traction makes sense, it is possible to define a dual notion Pld by taking Pld(A) = Pl(W) - Pl(A), where A is the complement of A. For example, the dual of a belief func tion is called a plausibility function [Shafer 1976] and the dual of a possibility measure is a necessity measure [Dubois and Prade 1990]; a probability distribution is its own dual. Note that these dual notions are also plausibility measures.2 In general, a plausibility measure PI on W does not have a dual, although it does induce a dual ordering \ufffdd on subsets of W, where A \ufffddB iff PI(A) \ufffd PI(B).\nGiven the simplicity and generality of plausibility mea sures, we were not surprised to discover that Weber [1991] recently defined a notion of uncertainty measures, which is a slight generalization of plausibility measure (in that domains more general than algebras of sets are allowed), and that Greco [1987] defined a notion of \u00a3-fuzzy measures which is somewhat more restricted than plausibility mea sures in that the range D is a complete lattice. We expect that others have used variants of this notion as well, although we have not found any further references in the literature. To the best of our knowledge, no systematic investigation of plausibility measures of the type we are initiating here has been carried out before.\n3 ALGEBRAIC PROPERTIES\nIn probability theory there is a functional connection captured by addition-between the probabilities of disjoint sets and the probability of their union. Similarly, there is a functional connection\ufffdaptured by multiplication between the conditional probability of A given B, the prob ability of B, and the probability of An B. These functional connections are frequently used in making probabilistic calculations. Not surprisingly perhaps, many approaches of handling uncertainty have analogues of addition and multiplication with similar roles. In particular, two recent \"abstract\" approaches to reasoning about uncertainty-that of Darwiche and Ginsberg [Darwiche and Ginsberg 1992; Darwiche 1992] and Weydert [1994]\ufffdonsider algebras of likelihood values that have some properties of probability,\n2 Although the word \"plausibility\" is used both in our notion of plausibility measure and in the Dempster-Shafer notion of a plausibility function, and plausibility functions are a special case of plausibility measures, there is no other connection between the two notions. There are simply not that many words that can be used to describe notions of uncertainty. We hope the overloading of \"plausibility\" will not cause confusion.\nPlausibility Measures: A User's Guide 177\nand allow operations analogous to addition and multiplica tion. As we now show, plausibility measures provide us with the tools to examine the assumptions on plausibility captured by assuming analogues to addition and multipli cation. Moreover, the appropriate application of these tools provides us with natural means of going from (uncondi tional) plausibility to conditional plausibility.\n3.1 DECOMPOSABLE MEASURES\nAs we said above, probability theory postulates a functional connection between the probability of disjoint events and the probability of their union. Such an assumption can be viewed as providing a systematic basis for dealing with the combination of evidence, as well as providing a certain modularity in the description of probabilities. For example, if W is finite, a description of the probability of each world in W determinesPr(A) for any A\ufffd W. It is easy to impose a similar requirement on plausibility measures. Consider the following property:\nDECOMP. If A and Band disjoint, A' and B' are disjoint, PI(A) \ufffd PI(A'), and PI(B) \ufffd PI(B'), then PI(A U B) \ufffd PI( A' U B').\nWe say that a plausibility measure PI is decomposable if it satisfies DECOMP.3 As we now show, decomposability is enough to force there to be a function EB on D such that PI(A U B) = PI(A) Ef)PI(B) for disjoint sets A and B; we say that EB determines decomposition for PI. In fact, the axiom DECOMP= which results from replacing all occur rences of \ufffd in DECOMP by = is already enough to force there to be a function EB that determines decomposition for PI. DECOMP forces Ef)to have a few additional properties that make it even more like addition.\nDefinition 3.1: Suppose D is a pointed ordered domain and o is a partial function mapping Dom( o) \ufffd D x D to D. If t, t' are two terms involving o, we write t =e t' if t = t' provided t and t' are both defined. (If one of t or t' is not defined, then t =e t' holds vacuously.) Similarly, we write t \ufffde t' if t \ufffd t' provided both t and t' are defined. We say that o is\n\u2022 commutative if dt o dz =e dz o dt,\n\u2022 associative if (dt o dz) o d3 =e dt o (d2 o d3)\n\u2022 monotonic if dt \ufffd d3 and d2 \ufffd d4 implies dt o d2 \ufffd. d3 0 d4,\n\u2022 additive if do l..=e d, and d o T =e T,\n\u2022 multiplicative if do l..=.l.. and d o T =e d,\n\u2022 invertible if (dt,d2), (dt,d3) E Dom(E\u00a3)), dt od2 \ufffd d3 o d4, and dz \ufffd d4 >l.. implies dt \ufffd d3.\n3DECOMP is a weak variant of a property of qualitative proba bilities called disjoint unions in [Fine 1973, p. 17]. A similar prop erty has been examined in the theory of fuzzy measures [Dubois 1986; Weber 199 1 ].\n178 Friedman and Halpern\nI\nTheorem 3.2: LetS = (W, D, PI) he a plausibility space. PI is decomposable if and only if there is a commuta tive, monotonic, additive function Ef;l on D with domain Dom(ij;)) = { (d, d') : 3 A , A' \ufffd W, An A' = 0, PI( A) = d, PI( A') = d'} that determines decomposition for PI such that:\n\u2022 Ef;l is associative on representations of disjoint sets, i.e., (d, Ef;ld2) ij;)d3 = d, Ef;l (d2 Ef;ld3) if there exist pairwise disjoint sets A,, A2; A3 such that Pl(Ai) =\ndi, i = 1' 2 , 3.\nNotice that the theorem does not say that Ef;l is associa tive. We show by example in the full paper that, in general, it is not.4 Interestingly, Fine [ 1973, p. 22] claimed that associativity of Ef;l in his framework follows from the as sociativity of U. This claim is not correct, although since there are differences between our assumptions and his, our counterexample does not apply to his framework. It is an open question whether associativity holds in his framework or not.5 We could, of course, define a (somewhat ugly) condition that would force $to be associative in general. We suspect that this will not be necessary in practice.\nProbability measures are decomposable, with decomposi tion determined by +. Similarly, possibility measures and x:-rankings are decomposable with decomposition deter mined by max and min, respectively. The embeddings of preferential structures and \u20ac-semantics into plausibility structures described in [Friedman and Halpern 1995a] also lead to decomposable plausibility measures. On the other hand, Dempster-Shafer belief functions are not in general decomposable. This follows from the following general observation:\nLemma 3.3: If (W, D, PI) is a decomposable plausibility space and A and B are disjoint subsets of W such that PI( A) =PI( B) = l_, then Pl(A U B) = l_.\nProof: SupposePI( A) = Pl(B) = l_. SinceP1(0) = _l,by DECOMP we have PI(A U B)= Pl(A u 0) = Pl(A) = l_. I\nSince it is easy to define a belief function Bel such that Bel( A) = Bel( B) = 0 for two disjoint sets A and B, while Bel( A U B) = 1, it follows that belief functions are not decomposable. A similar argument can be used to show that necessity measures, the duals of possibility measures, are not decomposable in general.\n4That is, we show that there are four pairs of disjoint sets (A, B), (C, D), (E, F), (G, H) such that PI(A) = d1, PI( B)= d2, PI(C) = d3, PI(D) = PI(A U B)= d1 ffi d2, PI(E) = d2, PI(F) = d3, PI( G)= d1, PI(H) = PI(E U F)= d ffi dJ, but PI( CUD) f. PI(GUH). Thus, (d1 ffid2)ffid3 f. d1 ffi(d2Ei:)d3), although all tenns are defined.\n5 A similar incorrect claim appears in [Darwiche and Gins berg 1992, p. 623]. However, in [Darwiche 1992], associativity is claimed to hold only for \"meaningful sums\". This seems to correspond to the same restriction as in Theorem 3.2.\nIn many cases, we may start with a plausibility defined just on the elements of W , not on all subsets of W . For exam ple, this may be the case if we try to elicit from the user an ordering on the worlds in W , but do not elicit a comparison between sets of worlds. As the next theorem shows, we can then extend this to a decomposable plausibility mea sure determined by a total function Ef;l that is commutative, associative, additive, and monotonic.\nDefinition 3.4: We say that the ordered domain D' extends the ordered domain D, denoted D !;;;; D', if D \ufffd D', l_D=l_D'\u2022 T D = T D'\u2022 and \ufffdDis \ufffdD' restricted to D x D. I\nTheorem 3.5: Suppose that D is an ordered domain and pl : W -+ D. Then there is a decomposable plausi bility structure S = (W, D', PI) such that Pl extends pl (i.e., D \ufffd D' andPl({w}) = pl(w) forw E W)and de composition for PI is determined by a total function ij;)that is commutative, associative, additive, and monotonic. More over, S is the minimal decomposable extension ofpl, in that ifS' = (W, D', PI') andPl' is a decomposable measure that extends pi, then Pl(A) \ufffd Pl(B) implies Pl'(A) \ufffd PI'(B) for all subsets A, B \ufffd W.\nThus, if we are given an arbitrary decomposable plausi bility space, then the function determining decomposition may not be associative (although it will still be associative in many cases of interest). However, if we are just given a plausibility on elements of W , we can construct a decom posable plausibility measure determined by a function that is associative. Moreover, the minimality of our construc tion ensures that it does not make unnecessary assumptions regarding the relative plausibility of sets of worlds.\n3.2 CONDITIONAL PLAUSIBILITY\nConditioning plays a central role in probabilistic reasoning. Not surprisingly, we are interested in studying conditioning in the context of plausibility as well. Of particular interest will be the connection between the conditional plausibil ity of A given B, and the plausibilities of B and An B. Before we can study this relationship, we need to consider conditioning in plausibility structures more generally.\nJust as a conditional probability measure associates with each pair of sets A and B a number, usually denoted Pr(AIB), a conditional plausibility measure associates with pairs of sets a conditional plausibility. Formally, a condi tional plausibility space is a family { (W, D A , PIA) : A \ufffd\nW } of plausibility spaces. We typically write Pl(BIA) rather than PIA(B) and Pl(A) rather than PI(AIW ). In keeping with standard practice in probability theory, we also sometimes write Pl(BIA, E) rather than Pl(BIA n E). Of course, we do not want the various PIA's to be arbitrary. Conditioning attempts to capture the intuition that when we learn A, the probability of sets disjoint from A becomes 0, while the relative probability of subsets of A does not change. The following coherence condition guarantees that conditional plausibility spaces have the same property:\nCl. Pl(BIA, E) \ufffd PI( CIA, E) if and only if PI( An\nBIE) \ufffdPI( A n CIE).\nIn probability theory, the unconditional probability de termines the conditional probability, via the relation Pr(AIB) = Pr(A n B)/Pr(B). This, of course, is not in general true in arbitrary plausibility measures. We can have two distinct conditional plausibility spaces {(W, D A, PIA) : A \ufffd W} and {(W, D\ufffd, PI\ufffd) : A \ufffd W} on the same space W that agree on the unconditional probability (i.e., Plw = PI\ufffd) and yet differ on their components. On the other hand, if all we care about is the ordering of plausibilities, these two conditional plausibility spaces must be essentially the same. To make this precise, we say that two plausibility spaces (W, D,PI) and (W, D',PI') are (order-)isomorphic if for any A, B \ufffd W , we have that Pl(A) \ufffdD PI(B) if and only ifPI'(A) \ufffdD' PI'(B).\nProposition 3.6: Let {(W, DA, PIA) : A \ufffd W} and {(W, D\ufffd, PI\ufffd) : A \ufffd W} he two conditional plausibil ity spaces on W . lfPiw and PI\ufffd are isomorphic, then PIA and PI\ufffd are isomorphic for all A \ufffd W.\nGiven an (unconditional) plausibility space S (W, D, PI), we can find a conditional plausibility space extending S and satisfying Cl in a straightforward way: Consider {(W, D A, PIA) : A \ufffd W}, where D A is a dis joint copy of {d E D : d \ufffdD PI(A)} and PIA(B) is the element in DA that corresponds to PI(A n B). It is easy to see that this conditional plausibility space satisfies Cl. Note that since DA and DB are disjoint when A=/= B, we cannot compare PI( CIA) to Pl(DIB). In fact, it is easy to verify that this plausibility space is the minimal one that extends Sand satisfies Cl.\nIn some applications, we want more than just Cl. We want there to be a function\u00ae such that Pl(A n BIC) = PI(AIB, C) @Pl(BIC), as there is for probability. Such a function @is said to determine conditioning/or PI. To study this functional connection (and, more generally, to allow us to compare Pl(BIA) to PI(B'IA') when A =/= A'), we consider standard conditional plausibility spaces, those for which there is some domain D such that for each A C W, either DA = {..lv} or DA \ufffdD. -\nTo force the existence of a function determining condition ing, we require:\nC2. If Pl(AIB, C) \ufffd PI(A'IB', C') and Pl(BIC) \ufffd Pl(B'IC'), then Pl(A n BIC) \ufffd PI(A' n B'IC').\nAgain, to get the functional dependency, we require only a weaker version of C2 denoted c2=, where all the \ufffd\u00b7s are replaced by =. Just as with DECOMP, the stronger C2 forces the function @ determining conditioning to be monotonic.\nAxiom C2 says that PI( A n B) is determined by PI( AlB) and Pl(B); it does not follow thatPI(AIB) is determined by PI(AnB) andPI(B). To force this, we need to force@to be \"invertible\". Roughly speaking, we want a division operator \ufffd such that PI( AlB) = Pl(A n B) \ufffdPI( B). Of course, we expect that by increasing the numerator or decreasing the denominator of a fraction like Pl(A n B) \ufffdPI( B), we\nPlausibility Measures: A User's Guide 179\nget an answer that's at least as large. This motivates the following axiom:\nC3. If PI( A n BIC) \ufffd PI( A' n B'IC') and Pl(BIC) ;::: Pl(B'IC') >..l, then PI{AIB, C)\ufffd Pl(A'IB', C').\nAgain, we get a weaker version of this axiom, denoted c3=, if we replace all the inequalities with =.\nTheorem 3.7: LetS = {(W, DA, PIA) : A \ufffd W} he a conditional plausibility space. PI satisfies Cl and C2 if and only if there exists a multiplicative, monotonic func tion @ with domain Dom( \u00ae) = {( d, d') : 3A, B, C \ufffd W, PI(AIB, C) = d, PI(BIC) = d'} that determines con ditioning for PI such that:\n\u2022 @satisfies limited associativity: if there exist sets A, B, C, D such that dt = PI(AIB, C, D), d2 = Pl(BIC, D), andd3 = Pl(CID), then (dt @d2)@d3 = dt @(d2 @d3).6\nPI additionally satisfies C3 if and only if@ is invertible.\nOf course, the standard definition of conditioning in prob ability satisfies C 1 -C3, and conditioning is determined by x. Similarly, the standard definition of conditioning in x:-rankings, which takes x:(AIB) = x:(A n B) - x:(B) [Spohn 1987], satisfies C 1-C3, with conditioning deter mined by addition. Finally, the standard notion of condi tioning in possibility measures [Dubois and Prade 1 990] which takes Poss(AIB) = 1 if Poss(A n B) = Poss(B) and Poss(AIB) = Poss(A n B) otherwise, satisfies Cl-C3, with conditioning determined by min. It may seem some what surprising here that min is invertible, as required by C3. After all, in general, min(dt, d3) = min(d2, d3) does not imply that d1 = d2. This implication does, however, hold in the domain of min in this case. We remark that we can take an alternate definition of conditioning in pos sibility theory, by defining Poss(AIB) = 0 ifPoss(B) = 0 and Poss(AIB) = Poss(A n B)/Poss(B) otherwise. This definition also satisfies C1-C3, with conditioning being determined by multiplication. We shall contrast the two definitions in the next section.\nNote that our theorem does not force@ to be commutative. It is easy to state conditions that force additional properties of@, such as commutativity (see [Fine 1973]).\nWhat happens when we add the requirement of decompos ability to conditional plausibility measures? There are actu ally two ways to do this. We say that a conditional plausibil ity measure is locally decomposable if every PIA is decom posable. This requirement ensures that for each A, there is a function EElA such thatPI(BUCIA) = PI(BIA)EEJAPI(CIA) whenever B and C are disjoint. This condition, however,\n61n the full paper we show by example that (8) is not associative in general. We remark that Fine [1973, p. 30] and Darwiche and Ginsberg [ 1992, p. 625] again incorrectly claimed that similar assumptions forced (8) to be associative on all of Dom( (8)), and not just on triples (dt, d2, d3) of this special form. Moreover, in this case, the example we provide is a counterexample to associativity also in Fine's framework.\n180 Friedman and Halpern\ndoes not relate EEl A to E98, i.e., the combination of disjoint events depends on the evidence. We say that conditional plausibility measure is globally decomposable (or just de composable) if it satisfies the following property:\nDECOMPc. If A and B and disjoint, A' and B' are disjoint, Pl(AIC) \ufffd Pl(A'IC'), and Pl(BIC) \ufffd Pl(B'IC'), then PI( AU BIG)\ufffd PI( A' U B'IC').\nIt is easy to state and prove an analogous result to Theo rem 3.2, i.e., that a conditional plausibility space is globally decomposable if and only if there is a commutative, mono tonic, and additive function E9 such that for disjoint sets A and B, we have PI( AU BIG)= Pl(AIC) ffiPl(BIC).\nIt is not immediately clear that we can find an invertible con ditional plausibility extending every (unconditional) plausi bility measure. As the next result shows, we can. Moreover, there is a unique minimal algebraic conditional plausibility measure, and it has some very nice properties.\nTheorem 3.8: LetS = (W, D, PI) be a plausibility space. Then there is a conditional plausibility space So = {(W, Do, PIA) : A \ufffd W} extending S (i.e., D !; Do and Plw = PI) in which conditioning is determined by a total function \u00aewhich is commutative, associative, mul tiplicative, invertible, and monotonic.1 Moreover, if S is decomposable, then so is So; in fact, there is a total func tion E9 that is commutative, additive, and monotonic that determines decomposition, and \u00aedistributes over EB. In addition, if there is an associative function that determines decomposition for PI, then E9 is associative as well.\nThe construction of Theorem 3.8 tells us that for any plau sibility measure PI we can find a \"nice\" (i.e., multiplica tive and invertible) conditional plausibility that extends it. Moreover, there is a conditional plausibility measure ex tending PI in which the functions determining conditioning and decomposition are total, and have desirable properties including commutativity and associativity of \u00ae. and dis tributivity of \u00ae over EB. As we show in the full paper, these properties are not necessarily implied by Cl-C3 and DECOMP c alone. When combined with our construction in Theorem 3.5, this gives us a way of starting with a plausibil ity measure on worlds in W, and extending to a conditional plausibility measure with these attractive properties.\nThe conditional plausibility measure constructed in The orem 3.8 is in a precise sense the minimal one with all the required properties. If we start with an unconditional probability measure, K ranking, or possibility measure, the standard approaches to conditioning do not in general give us the conditional measure defined by this construction. Thus, they makes some comparisons between conditional plausibilities that are not forced by our requirements. Inter estingly, if we consider the standard approach to condition ing in possibility measures defined earlier (with \u00aebeing min), it cannot be extended to a total commutative function.\n7Note that the fact that (8) satisfies these conditions guarantees that So satisfies C2 and C3.\nExample 3.9: Suppose we have a possibility measure Poss on a space W and sets A \ufffd B \ufffd C such that Poss(A) = 1/4, Poss(B) = 1/2, and Poss(C) = 3/4. (It is easy to find such a possibility measure.) Then, according to the definitions, we have Poss(AIB, C) = Poss(AIC) = 1/4, Poss(BIC) = 1/2. and Poss(BIA, C) = 1. Hence, min(Poss(BIA, C), Poss(AIC)) = min(Poss(AIB, C), Poss(BIC)) = 1/4. but Poss(AIB) =ft Poss(C). More abstractly, we have dt \u00aed2 = d2 (8)d3, but dt =ft d3. On the other hand, if \u00aecould be extended to a total, commutative, invertible function, we would have to have dt = d3. We return to this issue in the next section. I\n3.3 COMPARISON TO OTHER ALGEBRAIC APPROACHES\nWe now briefly compare our approach to others in the liter ature.\nDarwiche and Ginsberg's [1992] approach is somewhat similar to ours. They start with functions (which they call states of belief) that map formulas to an (unordered) set of plausibility values. To relate these to plausibility mea sures, we can take W to be the set of all truth assignments, and identify a formula with the set of worlds that satisfy it. Darwiche and Ginsberg then describe various assumptions that force the existence of what, in our terminology, are functions E9 and \u00aethat essentially determine decomposi tion and conditioning. They then define an ordering \ufffdEEl on plausibilities in terms of Elf. z \ufffdEEl y if there is a z such that :z: ffiz = y. Their assumptions do not force their analogues of E9 and \u00aeto be total (although they are total in all the examples provided).\nNotice that Darwiche and Ginsberg assume that originally we have a mapping from worlds to an unordered set of plausibility values. They then impose an ordering on this set. Their construction does not deal so well with the type of situation discussed before Theorem 3.5, where we start with a function pi that assigns to each world a plausibility in some ordered set; there is no way to take into account this initial ordering in their construction. For example, suppose W = {a, b} and pi( a) > pl(b). Their construction would make a and b incomparable according to \ufffdEEl\u00b7 since there is no c such that b E9 c = a. In particular, this means that the Darwiche-Ginsberg approach cannot deal with initial preferential orders, which arise in default reasoning (see Section 4.2).\nWeydert [ 1994] starts with total functions E9 and \u00aeon some set W , where E9 is commutative, associative, additive, and monotonic, while \u00ae is commutative, associative, multi plicative, invertible, and monotonic. (Indeed, he requires even more of E9 and \u00ae. although it is beyond the scope of the paper to explain these requirements.) Moreover, he also assumes a totally ordered domain D of plausibilities. He then define plausibility measures (quasi-measures in his terminology) as functions from W to D such that E9 determines decomposition and \u00aedetermines conditioning.\nOur discussion above shows that quasi-measures cannot\ncapture conditional possibility measures, since these can not be embedded in a total algebra. Similarly, they cannot capture belief functions, since these are not decomposable, nor preferential structures, since these are not totally or dered. Thus, Weydert's framework is not general enough to deal with many of the examples of interest to us.\n4 APPLICATIONS\nIn this section, we discuss two possible applications of plausibility: reasoning about independence and qualitative reasoning.\n4.1 INDEPENDENCE\nThe notion of independence plays a critical role in reason ing about uncertainty. Intuitively an event A is independent of B given C, if, once we know C, evidence regarding B does not provide us information about A. In probability theory, we say that A and B are independent given C if Pr(AIC) = Pr(AIB 1\\ C). It is easy to see that this is equiv alent to Pr(AABIC) = Pr(AIC) x Pr(BIC). Once we con sider formalisms other than probability theory, there are a number of alternative definitions of independence that have been considered in the literature; see, for example, [Fine 1973; Goldszmidt and Pearl 1992; Dubios et al. 1994]. We do not consider all the alternatives in our discussion of in dependence in the context of plausibility structures. Rather, we focus on one possible definition-perhaps the most ob vious generalization of the probabilistic definition-and a more qualitative variant of it.\nSuppose A, B, C \ufffd W. We say that PI makes A (plau sibilistically) independent of B given C denoted PI \ufffd Ind,(A, BIG), ifPI(BnC) =_l_ orPI(AIC) = Pi(AIB, C). Thus, A is independent from B given C either if B is implausible or if conditioning on B does not change the plausibility of A.\nTo what extent do properties of probabilistic independence carry over to this definition? That depends on what assump tions we make about the underlying plausibility measure. Once we consider multiplicative plausibility measures (so that it makes sense to use {8)), we can characterize plau sibilistic independence much as we did probabilistic inde pendence.\nProposition 4.1: (a) If PI satisfies c2= and PI f= Ind,(A, BIG), then PI( A n BIG) = Pl(AIC) \u00ae PI( BIG).\n(b) lfPi satisfies c2= and c3=' then Pl I= Jnd,(A, BIG) if and only if (Pi(A]C), Pl(BIC)) E Dom(Q9) and Pi(A n BIG) = PI(AIC) \u00aePl(BIC).\n(c) If Pi satisfies DECOMP'';. A1 n Az = 0, PI f= lnd, (A1 , BIG), and PI I= Ind,(Az, BjC), then PI \ufffd Ind,(AJ U Az, BIG).\nThus, if PI satisfies c2=, then when A and B are uncondi tionally independent (i.e., independent given W ), the plau sibility of A n B is determined by PI( A) and PI( B). This\nPlausibility Measures: A User's Guide 181\nseems to be a fundamental property of independence, and allows us to modularize the description of Pl. Decompos ability gives us another important property of independence: it guarantees that Ind, is closed under disjoint union.\nIn probability theory, independence is symmetric: if A is independent of B, then B is also independent of A. When is lnd, symmetric? Expanding the definition of Jnd,, we see that it is symmetric if whenever Pl(AIB, C) = Pl(AIC), then Pl(BIA, C) = PI( BIG). Now if PI satis fies c2=, then Pl(A n BIG) can be expanded in two ways: Pl(AIB, C) Q9Pl(BIC) and Pl(BIA, C) \u00aePl(AIC). Thus, we would expect Jnd, to be symmetric whenever \u00aeis in vertible. This may not follow if \u00ae is not total and com mutative. To see this, consider Example 3.9 again. The function min is invertible-C3 holds for conditional possi bility where conditioning is determined by min-yet, in that example, we have/nd, (A, BIG), but not lnd, (B, AI C). To get symmetry, we actually need the following variant of c3=:\nc4=. IfPI(A n BIG) = PI(A' n B'IC') and Pi(A!C) = PI(A'IB', C') >l_, then Pi(A!B, C)= Pi(A'IC').\nProposition 4.2: If PI satisfies c2= and C4=, then PI f= Ind,(A, BIG) if and only ifPi \ufffd Ind,(B, AIC).\nWe note that C4 = is satisfied by the conditional plausibility measure So constructed in Proposition 3.8, as well as by probability theory and \ufffd\ufffd:-ranking. As Example 3.9 shows, it is not satisfied by conditional possibility with conditioning determined by min, although it is satisfied by conditional possibility with conditioning determined by multiplication.\nWhat we are often interested in is not just the indepen dence of one event (set) from another, but independence among a family of events. Given a set A = {AI, ... , A\ufffd:} of events, define an atom over A to be an event of the form A\ufffd n ... n A\ufffd, where A\ufffd is either A\ufffd: or its com plement A\ufffd:. Given three sets of events A, B, and C, we say that PI makes A strongly independent of B given C, denoted PI f= IND, (A , BI C), if, for all atoms X over A, all atoms Y over B, and all atoms Z over C, we have PI f= Ind,(X, YjZ). We remark that although this defini tion focuses on atoms, by part (c) of Proposition 4.2, we can extend these independence assertions about atoms to independence assertions about arbitrary sets in decompos able structures. Notice that if A is the singleton {A}, B is the singleton {B}, and C is the singleton {C} and we are dealing with a plausibility measure that is in fact a proba bility function, then this definition amounts to saying that A is (probabilistically) independent of B given both C and c.s\nOnce we consider sets of events in this way, we can consider\n8This definition of independence is related to independence among random-variables [Pearl 1988]. Essentially, we are treat ing each event A as a two-valued random variable that has value 1 in all worlds w E A and value 0 in worlds w fl. A. The following discussion can be easily extended to deal with many-valued ran dom variables. Because of space constraints we defer that to the full version of the paper.\n182 Friedman and Halpern\nthe semi-graphoid properties [Pearl 1988]:\nGl. IND,( A , BIC) implies/ND,(B, A jC).\nG2. IND,( A , B U DjC) implies IND,( A , BjC).\nG3. IND,( A , B U DjC) implies IND,( A , BIC U D).\nG4. IND,( A , BjC) and IND,( A , DjC U B) implies IND,( A , B U D IC).\nThese properties are well-known to hold for probabilistic independence [Pearl 1988]. They also hold in the minimal decomposable conditional plausibility measures of Propo sition 3.8. In fact, we can prove a somewhat stronger result.\nTheorem 4.3: If PI is a conditional plausibility measure satisfying c2=. C4=, and DECOMP';, then IND, satisfies the semi-graphoid properties in Pl.\nThis result is somewhat similar to one of Wilson [ 1994], and shows that we need relatively little to get a non-probabilistic notion of independence that obeys all the semi-graphoid axioms.\nIt is known that any collection of independence statements that satisfy the semi-graphoid properties can be represented using a Bayesian network [Pearl 1988]. As we just saw, it takes fairly little to get a notion of plausibilistic inde pendence that obeys all the semi-graphoid properties. Dar wiche [ 1992] shows how to construct Bayesian networks in the framework of [Darwiche and Ginsberg 1992]. As we observed, this framework embodies additional assump tions beyond Cl, c2=, C4=, and DECOMP=. While this c extra structure, particularly properties like invertibility and commutativity, may not be necessary to define Bayesian networks, Darwiche's results suggest that they may be use ful in facilitating analogues of probabilistic algorithms for updating beliefs in Bayesian networks. Whether this struc ture really is necessary is an issue that deserves further exploration.\nWe now tum to a more qualitative notion of independence. If A is strongly independent of B given C, then discovering that some atom over B holds does not change the plausi bility of atoms over A. If all we care about is the relative plausibility of events, then we can consider a weaker notion, where discovering that some atom over B holds does not change the relative plausibility of atoms over A. Thus, we say PI makes A weakly independent of B given C, denoted PI F= Indw(A , BIG), if either Pl(B n C) =1.. or for all \ufffdtoms X and X' over A, we have Pl(XIC) \ufffd Pl(X'IC) tf and only if Pl(XIB n C) \ufffd PI(X'IB n C). We say PI makes A weakly independent of B given C, denoted PI F= INDw( A , BjC), if, for all atoms Y over Band all atoms Z over C, we have PI f= Indw(A , YIZ). It is easy to see that IND,(X, YjZ) implies INDw(X, YIZ), as the names suggest. There do not seem to be any straightforward conditions that force weak independence to obey the semi \ufffdraphoid properties. Nevertheless, as we shall see below, tt may be that weak independence has an important role to play in default reasoning.\n4.2 QUALITATIVE REASONING\nWe briefly review some of the results on default reasoning from [Friedman and Halpern 1995a; Friedman et al. 1995], in light of the results of the previous sections.\nA default is a formula of the form <p--+1/J, where <p and 1/J are propositional formulas. Such a default is read \"<p's are typically (or normally, or by default) 1/J's\". For the discus sion here, we identify a formula <p with the set consisting of the worlds where <p is true; this allows us to work with sets rather than formulas. We then say that a default A--+ B is satisfied by a a plausibility measure PI if either Pl(A) =..L or PI(A n B) > Pl(A n B), i.e., either A is implausible and we accept the default vacuously, orB is more plausible than its complement given A. This semantics for defaults is identical to that given for possibility measures [Benferhat et al. 1992] and for ordinal ranking structures [Goldszmidt and Pearl 1992]. As shown in [Friedman and Halpern 1995a], we can map other semantic structures used for giv ing semantics to defaults-including preferential structures [Kraus et al. 1990] and the parameterized probability dis tributions (PPDs) used in \ufffd:-semantics [Goldszmidt et al. 1993]-to plausibility structures in such a way as to pre serve the semantics of defaults.\nDefault reasoning in all these approaches is characterized by a collection of properties known as the KLM axioms [Kraus et al. 1990]. Our semantics for defaults does not guarantee that the KLM properties are satisfied. (In partic ular, they are not satisfied by probability measures.) What extra conditions do we have to place on plausibility mea sures to ensure that these properties are satisfied? In the presence of A l , the following axioms tum out to be all that we need\nA2. If A, B, and Care pairwise disjoint sets, PI(AU B) > PI(C), and PI(A U C) >PI( B), then PI( A) > PI(B U C).\nA3. If PI( A)= PI( B) =..L, then PI( AU B) =..L.\nIn [Friedman and Halpern 1995a] we prove that a plausibil ity measure satisfies all the KLM properties if and only if it satisfies A2 and A3. Thus, A2 and A3 capture the essence of the KLM properties.\nSince all the plausibility structures that arise from possibil ity measures, K:-rankings, preference structures, and PPDs, satisfy A2 and A3, this explains why the KLM properties hold in these approaches.9 Moreover, as we said in the intro duction, in [Friedman and Halpern 1995a] we also describe a weak necessary and sufficient condition for the KLM prop erties to be complete. This condition is easily seen to hold in all of these approaches. These results help us understand why the KLM properties characterize default reasoning in several different approaches. Plausibility structures also give us the tools to show how these approaches all differ once we allow first-order defaults [Friedman et al. 1995].\nWhile there is general agreement that the KLM proper-\n9We immediately get A3, using Lemma 3.3, as a consequence of the decomposability of these approaches.\nties are the \"core\" of default reasoning, there is also general agreement that they are too weak. For example suppose that a knowledge base contains only the defaultBird-+Fly. Us ing the KLM properties, we cannot derive Bird ARed -+Fly, since it is consistent with this knowledge base that red birds are exceptional. Yet, given that our knowledge base does not contain any information indicating that red birds are exceptional, we would like to infer that they are not. This problem has been dubbed the irrelevance problem, since we want our inference procedure to consider Red irrele vant to Bird-+Fly. A great deal of recent work on default reasoning (e.g., [Goldszmidt et al. 1 993; Goldszmidt and Pearl 1 992; Pearl 1 989]) has attempted to deal with the irrelevance problem. Roughly speaking, given a partic ular knowledge base, these approaches focus on a set of preferred structures that are determined by this particular knowledge base. Intuitively, these preferred structures sat isfy the knowledge base and some additional irrelevance properties that we want to view as true by default.\nThe results of the previous sections that plausibility may provide us with a general approach for dealing with irrel evance. How can we capture irrelevance? Perhaps the simplest definition is the following: B is irrelevant to the default C--+ A according to PI if C n B--+ A is satisfied by PI if and only if C-+A is satisfied by PI. It is easy to verify that PI F= lndw( {A}, BJC) if and only if B is irrel evant to C--+ A according to Pl. Thus, the weak notion of independence corresponds directly to irrelevance in default reasoning. Since all that matters in the semantics of a de fault such as C-+A is the relative plausibility of the sets C n A and C n A, it is clear that we do not need the full power of strong independence here.\nWe believe that by studying lndw in the context of default reasoning we can gain some insight into the irrelevance problem. For example, we can make precise approaches that make a maximal number of independence assumptions that are consistent with the knowledge base. We note that a similar suggestion is made by Dubois et. al. [ 1 994] using a slightly different notion of irrelevance. They say that B is irrelevant to C-+A if bothC-+A and CnB-+A hold. We believe that this condition is too strong, since it presupposes the acceptance of the default. We are currently exploring this issue further.\nQualitative measures also appear in the investigation of be lief change. The problem here is how an agent should change his beliefs after making a (possibly surprising) ob servation. It turns out that we can use conditioning in plausibility measures to handle belief change. Roughly, we say that an agent believes A given evidence E if Pl(AJE) > Pl(AJE). If we want the agent's beliefs to be closed under conjunction-if the agent believes A and B, then he also believes A n B-then we must limit our attention to qualitative plausibility measures.\nIndependence also proves to be important in belief change. In [Friedman and Halpern 1 995b], we describe belief change in a system by putting a plausibility measure on histories or runs that describe how the system changes over time. When doing probabilistic reasoning about such sys-\nPlausibility Measures: A User's Guide 183\nterns, in many cases it is reasonable to assume that a partic ular state transition is independent of when it occurs. This Markov assumption greatly simplifies reasoning about com plicated systems, and has been shown to be widely appli cable in practice. There is no difficulty stating the Markov assumption using plausibilistic notions of independence. Moreover, as shown in [Friedman and Halpern 1 995b], by combining the Markov assumption with qualitative plausi bility measures, we get a natural and powerful model of belief change. In this model, after making an observation, the agent may revise earlier beliefs, as is done by belief revi sion [Alchourr6n et al. 1 985], may consider it possible that his earlier beliefs were correct but the world has changed, as is done by belief update [Katsuno and Mendelzon 1 991 ], or take some combination of the two possibilities.\n5 DISCUSSION\nIn this paper, we have attempted to provide an introduction to plausibility measures, with a focus on their algebraic structure. Among other things, we showed how starting with a plausibility on worlds, we can extend to a condi tional plausibility measure defined on arbitrary sets, where the plausibilities have many of the properties satisfied by probability. In particular, decomposition is determined by a total function ffiwith many of the key properties of addition, and conditioning is determined by a total function \u00aewith many of the key properties of multiplication. Moreover, the independencies in this minimal conditional plausibil ity space satisfy the semi-graphoid conditions. Thus, we provide a construction that can generate a Bayesian net work from a preferential structure. We believe that this might have interesting implications in investigating the ir relevance problem in default reasoning.\nMore generally, as we hope our results show, plausibility measures give us a general framework in which to study fundamental issues of reasoning about uncertainty. They allow us to compare various approaches, and extract the key features needed to enable certain types of reasoning to be carried out. Plausibilities measures have already proved their usefulness in the analysis of qualitative default reason ing. We expect that many other applications will be found in the future.\nAcknowledgements\nThe authors are grateful to Adnan Darwiche, Moises Gold szmidt, and Daphne Koller for useful discussions relating to this work. The first author was supported in part by Rockwell Science Center in Palo Alto.\nReferences\nAlchourr6n, C. E., P. Giirdenfors, and D. Makinson ( 1 985). On the logic of theory change: partial meet functions for contraction and revision. Journal of Symbolic Logic 50, 5 1 0-530.\nBenferhat, S., D. Dubois, and H. Prade ( 1992). Representing default rules in possibilistic logic.\n184 Friedman and Halpern\nIn B. Nebel, C. Rich, and W. Swartout (Eds.), Proc . Third International Conference on Principles of Knowledge Representation and Reasoning ( KR '92), pp. 673-684. San Francisco: Morgan Kauf mann.\nDarwiche, A. ( 1 992). A Symbolic Generalization of Probability Theory. Ph. D. thesis, Stanford Univer sity.\n' Darwiche, A. and M. L. Ginsberg ( 1992). A symbolic\ngeneralization of probability theory. In Proc. Na tional Conference on Artificial Intelligence (AAAI '92), pp. 622-627. Menlo Park, Calif.: AAAI Press.\nDubios, D., L. Farinas del Cerro, A. Herzig, and H. Prade ( 1 994). An ordinal view of independence with ap plications to plausible reasoning. In R. L6pez de Mantara and D. Poole (Eds.), Proc. Tenth Confer ence on Uncertainty in Artificial Intelligence (UAI '94), pp. 1 95-203. San Francisco: Morgan Kauf mann.\nDubois, D. ( 1 986). Belief structures, possibility the ory and decomposable confidence measures on finite sets. Computers and Artificial Intelligence 5, 403- 4 1 6.\nDubois, D. and H. Prade ( 1 990). An introduction to pos sibilistic and fuzzy logics. In G. Shafer and J. Pearl (Eds.), Readings in Uncertain Reasoning. San Fran cisco: Morgan Kaufmann.\nFine, T. L. ( 1 973). Theories of Probability. New York: Academic Press.\nFriedman, N. and J. Y. Halpern (1 995a). Plausi bility measures and default reasoning. Techni cal Report 9959, IBM. Available by anonymous ftp from s tarry . stanford . edu/ pub/nir or via WWW at http : I / robotics . stanford . edu /users / nir.\nFriedman, N. and J. Y. Halpern ( 1 995b). A qualita tive Markov assumption and its implications for be lief change. Unpublished manuscript. Available by anonymous ftp from s tarry . stanford . edu/ pub / n i r or via WWW at http : I /robot ics . stanford . edu/ users /nir.\nFriedman, N., J. Y. Halpern, and D. Koller ( 1 995). Conditional first-order logic revisited. Un published manuscript. Available by anonymous ftp from s tarry . stanford . edu/pub/nir or via WWW at http : I / robot i c s . stanford . edu/ users /nir.\nGoldszmidt, M., P. Morris, and J. Pearl ( 1 993). A maxi mum entropy approach to nonmonotonic reasoning. IEEE Transactions of Pattern Analysis and Machine Intelligence 15(3), 220-232.\nGoldszmidt, M. and J. Pearl ( 1 992). Rank-based sys tems: A simple approach to belief revision, be lief update and reasoning about evidence and ac tions. In B. Nebel, C. Rich, and W. Swartout (Eds.), Proc. Third International Conference on Principles of Knowledge Representation and Reasoning (KR '92), pp. 66 1-672. San Francisco: Morgan Kauf mann.\nGreco, G. H. ( 1987). Fuzzy integrals and fuzzy mea sures with their values in complete lattices. Jour nal of Mathematical Analysis and Applications 126, 594-603.\nKatsuno, H. and A. Mendelzon ( 199 1 ). On the difference between updating a knowledge base and revising it. In J. A. Allen, R. Fikes, and E. Sandewall (Eds. ), Proc. Second International Conference on Principles of Knowledge Representation and Reasoning (KR '91 ), pp. 387-394. San Francisco: Morgan Kauf mann.\nKraus, S., D. J. Lehmann, and M. Magidor ( 1 990). Non monotonic reasoning, preferential models and cumu lative logics. Artificial lntelligence 44, 1 67-207.\nKreps, D. ( 1988). Notes on the Theory of Choice. Boul der, Colorado: Westview Press.\nPearl, J. ( 1988). Probabilistic Reasoning in Intelligent Systems. San Francisco, Calif.: Morgan Kaufmann.\nPearl, J. ( 1989). Probabilistic semantics for nonmono tonic reasoning: A survey. In R. J. Brachman, H. J. Levesque, and R. Reiter (Eds.), Proc. First Interna tional Conference on Principles of Knowledge Rep resentation and Reasoning ( KR '89 ), pp. 505-5 1 6. Reprinted in Readings in Uncertain Reasoning, G. Shafer and J. Pearl (eds.), Morgan Kaufmann, San Francisco, Calif., 1 990, pp. 699-7 1 0.\nSavage, L. J. ( 1 954). Foundations of Statistics. New York: John Wiley & Sons.\nShafer, G. ( 1 976). A Mathematical Theory of Evidence. Princeton, N.J.: Princeton University Press.\nSpohn, W. ( 1 987). Ordinal conditional functions: a dynamic theory of epistemic states. In W. Harper and B. Skyrms (Eds.), Causation in Decision, Be lie/ Change and Statistics, Volume 2, pp. 1 05-1 34. Dordrecht, Holland: Reidel.\nWang, Z. and G. J. Klir ( 1992). Fuzzy Measure Theory. New York: Plenum.\nWeber, S. ( 1 99 1 ). Uncertainty measures, decomposabil ity and admissibility. Fuzzy Sets and Systems 40, 395-405.\nWeydert, E. ( 1 994 ). General belief measures. In R. L6pez de Mantara and D. Poole (Eds.), Proc. Tenth Confer ence on Uncertainty in Artificial Intelligence (UAI '94), pp. 575-582. San Francisco: Morgan Kauf mann.\nWilson, N. ( 1 994). Generating graphoids from general ized conditional probability. In R. L6pez de Mantara and D. Poole (Eds.), Proc. Tenth Conference on Un certainty in Artificial Intelligence (UAI ' 94 ), pp. 583- 591 . San Francisco: Morgan Kaufmann."}], "references": [{"title": "Representing default rules in possibilistic logic", "author": ["S. Benferhat", "D. Dubois", "H. Prade"], "venue": null, "citeRegEx": "Benferhat et al\\.,? \\Q1992\\E", "shortCiteRegEx": "Benferhat et al\\.", "year": 1992}, {"title": "Fuzzy integrals and fuzzy mea\u00ad sures with their values in complete lattices", "author": ["G.H. Greco"], "venue": "Jour\u00ad nal of Mathematical Analysis and Applications", "citeRegEx": "Greco,? \\Q1987\\E", "shortCiteRegEx": "Greco", "year": 1987}, {"title": "Probabilistic Reasoning in Intelligent Systems", "author": ["J. Pearl"], "venue": null, "citeRegEx": "Pearl,? \\Q1988\\E", "shortCiteRegEx": "Pearl", "year": 1988}, {"title": "Probabilistic semantics for nonmono\u00ad tonic reasoning: A survey", "author": ["J. Pearl"], "venue": "Proc. First Interna\u00ad tional Conference on Principles of Knowledge Rep\u00ad resentation and Reasoning", "citeRegEx": "Pearl,? \\Q1989\\E", "shortCiteRegEx": "Pearl", "year": 1989}], "referenceMentions": [{"referenceID": 0, "context": "rankings [Spohn 1987; Goldszmidt and Pearl 1992], and possibility measures [Benferhat et al. 1992]) all satisfy the KLM properties.", "startOffset": 75, "endOffset": 98}, {"referenceID": 3, "context": "Such sequences of measures pro\u00ad vide semantics for defaults in \u20ac-semantics [Pearl 1989; Goldszmidt et al. 1993].", "startOffset": 75, "endOffset": 111}, {"referenceID": 1, "context": "Given the simplicity and generality of plausibility mea\u00ad sures, we were not surprised to discover that Weber [1991] recently defined a notion of uncertainty measures, which is a slight generalization of plausibility measure (in that domains more general than algebras of sets are allowed), and that Greco [1987] defined a notion of \u00a3-fuzzy measures which is somewhat more restricted than plausibility mea\u00ad sures in that the range D is a complete lattice.", "startOffset": 299, "endOffset": 312}, {"referenceID": 2, "context": "8This definition of independence is related to independence among random-variables [Pearl 1988].", "startOffset": 83, "endOffset": 95}, {"referenceID": 2, "context": "the semi-graphoid properties [Pearl 1988]:", "startOffset": 29, "endOffset": 41}, {"referenceID": 2, "context": "These properties are well-known to hold for probabilistic independence [Pearl 1988].", "startOffset": 71, "endOffset": 83}, {"referenceID": 2, "context": "It is known that any collection of independence statements that satisfy the semi-graphoid properties can be represented using a Bayesian network [Pearl 1988].", "startOffset": 145, "endOffset": 157}, {"referenceID": 0, "context": "This semantics for defaults is identical to that given for possibility measures [Benferhat et al. 1992] and for ordinal ranking structures [Goldszmidt and Pearl 1992].", "startOffset": 80, "endOffset": 103}], "year": 2011, "abstractText": "We examine a new approach to modeling uncer\u00ad tainty based on plausibility measures, where a plausibility measure just associates with an event its plausibility, an element is some partially or\u00ad dered set. This approach is easily seen to gener\u00ad alize other approaches to modeling uncertainty, such as probability measures, belief functions, and possibility measures. The lack of structure in a plausibility measure makes it easy for us to add structure on an \"as needed\" basis, letting us examine what is required to ensure that a plausi\u00ad bility measure has certain properties of interest. This gives us insight into the essential features of the properties in question, while allowing us to prove general results that apply to many ap\u00ad proaches to reasoning about uncertainty. Plau\u00ad sibility measures have already proved useful in analyzing default reasoning. In this paper, we examine their \"algebraic properties\", analogues to the use of+ and x in probability theory. An understanding of such properties will be essential if plausibility measures are to be used in practice as a representation tool.", "creator": "pdftk 1.41 - www.pdftk.com"}}}