{"id": "1302.4990", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "20-Feb-2013", "title": "A Method for Implementing a Probabilistic Model as a Relational Database", "abstract": "This paper discusses a method for implementing a probabilistic inference system based on an extended relational data model. This model provides a unified approach for a variety of applications such as dynamic programming, solving sparse linear equations, and constraint propagation. In this framework, the probability model is represented as a generalized relational database. Subsequent probabilistic requests can be processed as standard relational queries. Conventional database management systems can be easily adopted for implementing such an approximate reasoning system. The following example provides a straightforward proof of concept.\n\n\n\n\nSuppose we get a simple, compact database with four tables, which can be represented by two columns:\n1. We write an appropriate, complex, and reliable linear regression model, which compiles and then parses a simple, but complex, simple linear regression model. Then the model outputs a simple, and accurate, linear regression model. In addition, we can test for a subset of the data in a finite set of the models.\nThe algorithm is then evaluated to determine whether the data is consistent with the previous query (for example, our original query) with any other relevant data. Then, the model outputs a simple, and accurate, linear regression model. The model outputs a simple, and accurate, linear regression model. In addition, the model outputs a simple, and accurate, linear regression model. In addition, the model outputs a simple, and accurate, linear regression model. The model outputs a simple, and accurate, linear regression model. The model outputs a simple, and accurate, linear regression model. The model outputs a simple, and accurate, linear regression model.\nThe algorithm also tests whether the data are consistent with the previous query (for example, our original query) with any other relevant data. Then, the model outputs a simple, and accurate, linear regression model. The model outputs a simple, and accurate, linear regression model. In addition, the model outputs a simple, and accurate, linear regression model. The model outputs a simple, and accurate, linear regression model. In addition, the model outputs a simple, and accurate, linear regression model. The model outputs a simple, and accurate, linear regression model. The model outputs a simple, and accurate, linear regression model. In addition, the model outputs a simple, and accurate, linear regression model. In addition, the model outputs a simple, and accurate, linear regression model. In addition, the model outputs a simple, and accurate, linear regression model. In addition, the model outputs a simple, and accurate", "histories": [["v1", "Wed, 20 Feb 2013 15:24:15 GMT  (382kb)", "http://arxiv.org/abs/1302.4990v1", "Appears in Proceedings of the Eleventh Conference on Uncertainty in Artificial Intelligence (UAI1995)"]], "COMMENTS": "Appears in Proceedings of the Eleventh Conference on Uncertainty in Artificial Intelligence (UAI1995)", "reviews": [], "SUBJECTS": "cs.AI", "authors": ["michael s k m wong", "c j butz", "yang xiang"], "accepted": false, "id": "1302.4990"}, "pdf": {"name": "1302.4990.pdf", "metadata": {"source": "CRF", "title": "A Method for Implementing a Probabilistic Model as a Relational Database", "authors": [], "emails": ["wong@cs.uregina.ca>", "butz@cs.uregina.ca>", "yxiang@cs.uregina.ca>"], "sections": [{"heading": null, "text": "This paper discusses a method for im plementing a probabilistic inference system based on an extended relational data model. This model provides a unified approach for a variety of applications such as dynamic pro gramming, solving sparse linear equations, and constraint propagation. In this frame work, the probability model is represented as a generalized relational database. Subse quent probabilistic requests can be processed as standard relational queries. Conventional database management systems can be easily adopted for implementing such an approxi mate reasoning system.\n1 Introduction\nProbabilistic models [4, 9, 10] are used for making de cisions under uncertainty. The input to a probabilistic model is usually a Bayesian network [10]. It may also consist of a set of potentials which define a Markov network [4]. In this paper, we assume that the proba bilistic model is described by a Markov network. For this model, the propagation method [5, 6, 7, 12, 13] can be conveniently applied to convert the potentials into marginal distributions.\nThere is another important reason to characterize a probabilistic model by a Markov network, as it has been shown that such a network can be represented as a generalized relational database (14, 15, 16]. That is, the probabilistic model can be transformed into an equivalent (extended) relational data model. More specifically, the marginal corresponding to each po tential can be viewed as a relation in the relational database. Furthermore, the database scheme derived from a Markov network forms an acyclic join depen dency [15], which possesses many desirable properties [1, 8] in database applications.\nAs the probabilistic model is now represented by a re lational data model, a probability request expressed as a conditional probability can be equivalently trans formed into a standard query to be executed by the database management system. Naturally, all query optimization techniques can be directly applied to pro cessing this query including data structure modifica tion. Thus, these transformations allow us to take full advantage of the query optimizer and other per formance enhancement capabilities available in tradi tional relational databases.\nThis paper, a sequel of the presentation in the IPMU conference [15], reports on the technical details in volved in the design of a probabilistic inference system by transforming a Markov network into a relational database.\nOur paper is organized as follows. In Section 2, for completeness we review a unified relational data model for both probabilistic reasoning and database manage ment systems. In Section 3, we show that a factored probability distribution can be expressed as a general ized acyclic join dependency. The method for imple menting a probabilistic inference system is described in Section 4. First, we describe how a relational database is constructed for a given probabilistic model. We then show that processing a request for evidential reason ing is equivalent to processing a standard relational query. We conclude by pointing out that the extended relational database system can in fact model a number of apparently different but closely related applications [12].\n2 An Extended Relational Data Model for Probabilistic Inference\nBefore introducing our data model, we need to define some basic notions pertinent to our discussion such as: hypergraphs, factored distributions, and marginal ization. Then we show how under certain conditions a factored joint probability distribution can be expressed\nA Method for Implementing a Probabilistic Model as a Relational Database 557\nas a generalized acyclic join dependency m the ex tended relational model.\n2.1 Basic Notions\nHypergraphs and Hypertrees :\nLet C denote a lattice. We say that 1{ is a hyper graph, if 1{ is a finite subset of C. Consider, for ex ample, the power set 2x, where X= {xl, X2, ... , xn} is a set of variables. The power set 2x is a lattice of all subsets of X. Any subset of 2x is a hypergraph on 2x. We say that an element t in a hypergraph 1{ is a twig if there exists another element b in 1{, dis tinct from t , such that t n (U(1i- {t})) = t n b. We call any such b a branch for the twig t. A hypergraph 1{ is a hypertree (an acyclic hypergraph [1]) if its elements can be ordered, say h1, h2, ... , hn, so that h; is a twig in {h1, h2, . .. , h;}, fori = 2, ... , n. We call any such ordering a hypertree construction ordering for 1{. Given a hypertree construction ordering h1, h2, . . . , hn, we can choose, fori from 2 to n, an integer b(i) such that 1 :S b( i) :S i - 1 and hb(i) is a branch for h; in {h1, h2, ... , h;}. We call the function b(i) satisfying this condition a branching function for 1{ and h1, h2, ... , hn.\nFor example, let X = {x1, x2, ... , x6} and C = 2x. Consider a hypergraph, 1{ = {h1 = {x1, x2,x3},h2 = {x1, x2, x4} , h3 = {x2, x3, xs} , h4 = {xs, x6} }, de picted in Figure 1. This hypergraph is in fact a hy pertree; the ordering, for example, h1, h2, h3, h4, is a hypertree construction ordering and b(2) = 1, b(3) = 1, and b( 4) = 3 define its branching function.\nFigure 1: A graphical representation of the hypergraph 1{ = {hl, h2, h3, h4}\u00b7\nA hypertree K on C is called a hypertree cover for a given hypergraph 1{ on C if for every element h of 1{ , there exists an element k (h) of K such that h \ufffd k(h). In general, a hypergraph 1{ may have many hypertree covers. For example, the hypertree\ndepicted in Figure 1 is a hypertree cover of the hy pergraph, { {xb x2}, {x1, x3}, {x1, x2, x4}, {x2, xs} , {x3, xs} , {xs, x6} }.\nFactored Probability Distributions :\nLet X= {x1, x2, ... , xn} denote a set of variables. A factored probability distribution p(x1, x2, ... , Xn) can be written as:\nwhere each h; is a subset of X, i.e., h; E 2x, and \u00a2h, is a real-valued function on h;. Moreover, X= h1 U h2 U . .. U hn = U7=l h;. By definition, 1i = {h1, h2, ... , hn} is a hypergraph on the lattice 2x. Thus, a factored probability distribution can be viewed as a product on a hypergraph 1{, namely:\nLet Vx denote the discrete frame (state space) of the variable x E X. We call an element of Vx a configura tion of x. We define vh to be the Cartesian product of the frames of the variables in a hyperedge h E 2x:\nWe call vh the frame of h, and we call its elements configurations of h.\nLet h, k E 2x, and h \ufffd k. If c is a configuration of k, i.e., c E Vk, we write c.l.h for the configuration of h obtained by deleting the values of the variables in k and not in h. For example, let h = {x1, x2}, k = {x1, x2, x3, x4}, and c = (c1, c2, c3, c4), where c; E Vx;\u00b7 Then, c.l.h = ( c1, c2).\nIf h and k are disjoint subsets of X, ch is a configura tion of h, and Ck is a configuration of k, then we write (Chock) for the configuration of h U k obtained by con catenating ch and Ck. In other words, ( ch o Ck) is the unique configuration of hUk such that ( ch ock).l.h = ch and ( Ch o ck ).l.k = Ck. Using the above notation, a fac tored probability distribution \u00a2 on U1{ can be defined as follows:\n\u00a2(c) = (IT \u00a2h)( c) = IT \u00a2h( c.l.h), hE1i hE1i\nwhere c E vx is an arbitrary configuration and X = U?i.\nMarginalization :\n558 Wong, Butz, and Xiang\nConsider a function \u00a2k on a set k of variables. If h C k, \ufffd - then <Pk denotes the function on h defined as follows:\n<Pth(ch) = L tPk(ch o Ck-h), Ck-h\nwhere ch is a configuration of h, Ck-h is a configuration of k- h, and ch o Ck-h is a configuration of k. We call <Pth the marginal of tPk on h. A major task in probabilistic reasoning with belief net works is to compute marginals as new evidence be comes available.\n3 Representation of a Factored Probability Distribution as a Generalized Acyclic Join Dependency\nLet c be a configuration of X= {x1, x2, ... , Xn}\u00b7 Con sider a factored probability distribution \u00a2 on 1\u00a3:\n\u00a2(c)= II tPh(c.l.h). hE1i\nWe can conveniently express each function </Jh in the above product as a relation cl> h. Suppose h = {x1,x2, .. ,xt} . The function tPh can be expressed as a relation on the set { x1, x2, ... , Xt, f,!>h} of at tributes as shown in Figure 2. A configuration c; = (ci!,Ci2, ... ,c;t) in the above table denotes a row ex cluding the last element in the row, and s is the cardinality of Vh. .\nBy definition, the product \u00a2h \u00b7 \u00a2k of any two function c/>h and </Jk is given by:\nwhere c E Vhuk. We can therefore express the product c/>h \u00b7cf>k equivalently as a product join of the relations cl>h and cl>k, written cl>h 0 cl>k, which is defined as follows:\n(i) Compute the natural join, cl>h txJ cl>k, of the two relations of cl>h and cl>k.\n(ii) Add a new column with attribute !\u00a2h\u00b7\u00a2k to the relation cl>h txl cl>k on h U k. Each value of l\u00a2h\u00b7\u00a2k is given by tPh ( c.l.h) \u00b7 tPk ( c.l.k), where c E Vhuk.\n(iii) Obtain the resultant relation cl>h 0 cl>k by project ing the relation obtained in Step (ii) on the set of attributes h U k U U\u00a2h\u00b7\u00a2k }.\nFor example, let h = {x1, x2}, k = {x2, x3}, and vh = Vk = {0, 1}. The product join cl>h 0 cl>k is illustrated in Figure 3.\nSince the operator 0 is both commutative and associa tive, we can express a factored probability distribution as a join of relations:\n<P = II tPh = \u00ae cl>h = Q9{cl>hlh E 1\u00a3}. hE1i hE1i\nWe can also define marginalization as a relational op eration. Let c\ufffd>th denote the relation obtained by marginalizing the function \u00a2k on h \ufffd k. We can con struct the relation c\ufffd>th in two steps:\n(a) Project the relation cl>k on the set of attributes h U {/ \u00a2k}, without eliminating identical configu rations.\n(b) For every configuration ch E vh, replace the set of configurations of hU{!\u00a2k} in the relation obtained from Step (a) by the singleton configuration Ch o CLck-h </Jk(ch o Ck-h)).\nA Method for Implementing a Probabilistic Model as a Relational Database 559\nConsider, for example, the relation <I>k with k = {x1, x2, x3} as shown in Figure 4. Suppose we want to compute <I>t\nh for h = {x1, x2}. From Step (a), we obtain the relation in Figure 5 by projecting <I>k on h U {fq,k }. The final result is shown in Figure 6.\nTwo important properties are satisfied by the operator t of marginalization.\nLemma 1 [12, 15]\n(i) If <I>k is a relation on k, and h \ufffd g \ufffd k, then\n( <I>t g ).j. h = <I>t h .\n(ii) If <I>h and <I>k are relations on h and k, respec tively, then\nBefore discussing the computation of marginals of a factored distribution, let us first state the notion of computational feasibility introduced by Shafer (12]. We call a set of attributes feasible if it is feasible to\nrepresent relations on these attributes, join them, and marginalize on them. We assume that any subset of feasible attributes is also feasible. Furthermore, we as sume that the factored distribution is represented on a hypertree and every element in 1l is feasible.\nLemma 2 [12, 15] Let <I>= @{<I>hlh E 1l} be a fac tored probability distribution on a hypertree 1l. Let t be a twig in 1l and b be a branch for t . Then,\n(i) (@{<I>hlh E 1l }).l.uW'\n= (@{<I>hlh E 1\u00a3-t}) \u00ae<I>ftnb.\n(ii) If k \ufffd U1l-t, then (@{<I>h ih E 1l}).l.k = ( \u00ae{ <l>h\"t ih E 1\u00a3-t} ).l.k, where 1l-t denotes the set of hyperedges 1l - {t}, <I>i:t = <I>b \u00ae <t>f\ntnb, and <l>h\"t = <I>h for all other h in 1l-t.\nWe now describe a procedure for computing <J>.I.k for k E 1\u00a3, where <I> = @{ <I>h ih E 1l} and 1l is a hyper tree. Choose a hypertree construction ordering for 1l that begins with h1 = k as the root, say h1, h2, . . . , hn, and choose a branching b( i) function for this particular ordering. Fori= 1, 2, . . . , n, let\nThis is a sequence of sub-hypertrees, each larger than the last; 1\u00a31 = { h d and 1ln = 1l. The element h; is a twig in 1li. To compute <J>.I.k, we start with 1ln going backwards in this sequence. We use Lemma 2 each time to perform the reduction. At the step from 1l; to 1li-1, we go from <J>.I.U1i' to <J>.I.urc-\u2022. We omit h; in 1li and change the relation on hb(i) in 1li-1 from <I>i to hb(i)\nand the other relations in 1li-: are not changed. The collection of relations with which we begin, { <I>J: ih E 1ln}, is simply { <I>h ih E 1l}, and the collection with which we end, {<I>\ufffdIh E 1\u00a31}, consists of the single relation <I>\ufffd = <J>.I.h,.\nConsider a factored probability distribution <I> = @{<I>hlh E 1l} on a hypertree 1l = {h1, h2, . . . ,hn}. We say that <I> satisfies the acyclic join dependency (AJD), *[h1, h2, .. . , hn], if <I> decomposes losslessly onto a hypertree construction ordering h1, h2, . . . , hn, i.e., <I> can be expressed as:\nwhere \u00ae' is a generalized join operator defined by:\n560 Wong, Butz, and Xiang\nHence, The relation (<I>-1-h)-1 is defined as follows. First, let us define the inverse function (\u00a2-1-h)-1 of\u00a2. That is,\n<I>t \u00ae ( <I>f tnb) -1 = <f>-1-t \u00ae ( <f>-1-tnb) -1.\n( \u00a2+') -1 (c) = ( \ufffd \u00a2 ( c o c')) -1 , whe<e \ufffd \u00a2 ( c o c') > 0, Thnelation <I> can thO<efme be exp\u2022e,ed \"\" c is a configuration of h \ufffd U1l, and c' is a configuration of U1l - h. We call the function ( \u00a2-1-h) -1 the inverse marginal of\u00a2 on h. The inverse relation ( <f>.l.h )-1 is the relation constructed from the inverse function ( \u00a2-1-h) -1. Obviously, the product (\u00a2-1-h)-1 \u00b7 \u00a2-1-h is a unit function on h, and (<I>-1-h)-1 \u00ae <f>.l.h is an identity relation on h.\nTheorem 1 [15] Any factored probability distribu tion <I> = @{<I>hlh E 1l} on a hypertree, 1l = { h1 , h2 , ... , hn}, decomposes losslessly onto a hypertree construction ordering h1, h2, . .. , hn. That is, <I> satis fies the AJD, * [h1, h2 , ... , hn].\nProof\"\nSuppose t E 1l is a twig. By Lemma 2,\n((Q$){<I>hlh E 1l-t}) \u00ae<I>t)ww\u2022 (Q$){<I>hlh E 11-t}) \u00ae<I>ttn(u 1r')\n(Q$){<I>hlh E 1{-t}) \u00ae<I>ftnb.\nNote that (<I>ftnb)-1 \u00ae<I>ttnb \u00ae<l>t = <I>t, as (<I>t tnb)-1 \u00ae <t>ftnb is an identity relation on t n b. Thus, <f>W1l-1 \u00ae (<I>ftnb)-1 \u00ae <I>t (Q$){<I>hlh E 11-t}) \u00ae <I>ftnb \u00ae (<I>ftnb) -1 \u00ae <I>t\n(Q$){<I>hih E 1l-t}) \u00ae <I>t <I>.\nNow we want to show that:\n(<I>ftnb)-1 \u00ae <I>t = (<I>-1-tnb)-1 \u00ae <f>-1-t.\nNote that by property (ii) of Lemma 1, we obtain:\n<I>t \u00ae (Q$){ <I>h lh E 1{-t} ) .1-tn(u'W')\n(<I>t \u00ae (Q$){<I>hih E 1l-t}))-l-t <f>-1-t.\nOn the other hand, we have:\n(<I>ftnb)-1 \u00ae ((Q$){<I>hlh E 11-t})-1-tn(u?r'))-1\n(<I>Jt nb \u00ae (Q$){<I>hlh E 11-t})-1-tn(u'W'))-1 ((<I>t \u00ae (Q$){<I>hlh E 11-t).l.tn(u ?r')).l.tnb)-1 (((<I>t \u00ae (Q$){<I>hlh E 1{-t}))-1-t).l.tnb)1 ( ( <f>-1-t )-1-tnb) -1 ( <f>-1-tnb) -1.\n<I> <I>ww\u2022 \u00ae <f>-1-t \u00ae (<I>Hu'W')nt)-1\n<f>-1-UH -t (:9' <f>-1-t.\nMoreover,\nQ$){<I>hlh E 1{-t} \u00ae <I>t.l.tnb\nQ$){<I>h\"tih E 1l-t}.\nWe can immediately apply the same procedure to <I>-1-uH-' for further reduction. Thus, by applying this algorithm recursively, the desired result is obtained. D\n4 The method for implementing a Probabilistic Inference System\nIn order to convert a probabilistic model into a re lational model, first we need to be able to efficiently transform the input potentials into marginals. Since we assume that the hypergraph induced by the po tentials is a hypertree, we can apply the propagation method [6, 12] to compute all their marginals. This process involves first moving backward along the hy pertree construction ordering to find the marginal of the root, then moving forward from the root to the leaves for determining marginals of the other poten tials.\nThe next task is to transform a probability request into a standard relational query addressed to the database which is equivalent to the original probability model. The relational query can be formulated by scanning the probability request to determine the marginals in volved along the hypertree construction ordering, as well as the specific variables (attributes) within each respective marginal. Once the query is expressed in terms of the query language provided, it is then sub mitted to and processed by the standard database management system in the usual manner.\n4.1 Transformation of Potentials to Marginals (Relations)\nWe are given as input a set of potentials \u00a2h 's which define a factored joint probability distribution <I> = @{<I>hlh E 1l}, where 1l = {h1, h2, . . . , hn} is the cor responding hypergraph. The first step in this transfor mation is to check if the hypergraph 1l is a hypertree [1], but if so determine a branching function b( i) for it. If we do not have a hypertree, then some potentials\nA Method for Implementing a Probabilistic Model as a Relational Database 561\ncan be combined so that the resultant hypergraph is a hypertree [12].\nIn the following discussion, we henceforth assume that 1l = {h1, h2, . . . , hn} is a hypertree. Let the branch ing function b(i), i = 2, . . . , n define a hypertree con struction ordering. The procedure for computing the marginal of the root h1 by moving backward along the hypertree construction ordering has been described in Section 3.\nOnce we have determined the root marginal, q,.J.h1, we may move forward along the hypertree construction ordering to compute marginals of the other potentials. For this purpose, while we are moving backward we should save the relation ( <l>h ).J.h;nhb(i) at each stage 1li . Then we can determine ' the other marginals by the formula:\nTo see this, consider the situation where we have just computed the root marginal q,.J.h1, namely: q,.J.h1 = <I>h 19. (<!>2 ).J.h1nh, Note that <!>2 - (<I>').j.h, where 1 '61 h, . h, - , <I>'= @ {<I>h i h E 1l-h1 }. By Lemma 1, we obtain:\n( q, h1 0 ( <I>t ).j. h1 nh, ).j.h1 nh, q,.J.h1nh, 19. (1>2 ).j.h1nh2\u2022 h1 '61 h,\nFrom Lemmas 1 and 2, it follows:\n<I>t 0 ((<I>t).j.h1nh2)-1 0 (<I>.j.h1 ).j.h1nh2\nq,2 19. q,.J.h,nh, h, '61 h, (<I>t 0 <I>h,).j.h,\nq,.J.h, .\nHence, by continuing moving forward, we will arrive at the above general formula.\nConsider, for example, a factored joint probability dis tribution defined by six potentials [4] as shown in col umn 2 of Tables 1 to 6. We have modified the column names to reflect the notation used in this paper. The corresponding hypergraph, 1l = {h1 = {x1, x2}, h2 = {x2,x3 ,x4 ,x5},h3 {x2,x4,X5,x5},h4 {x2,x5,x7},h5 = {x2,x7,xs},h6 = {x7,xs,x9}}, is depicted in Figure 7. This hypergraph is in fact a hy pertree. The sequence h1 , h2 , h3, h4, h5, h6, is a hyper tree construction ordering which defines the branching function, b(2) = 1, b(3) = 2, b(4) = 3, b(5) = 4, b(6) = 5.\nTo compute the root marginal q,.J.h1 , we may move backward from the leaf hyperedge towards the root h1 along the hypertree construction ordering. Thus we first transform the hypergraph 1{6 ( = 1l) to 1{5. That\nconfiguration 4>(x1x2) c\ufffd>+h1 c\ufffd>+h1 -,,xl \"\"\"'1X2 0.502 0.391 0.391 ..,.,1 x, 0.261 0.058 0.058\nX1\u2022X2 0.498 0.387 0.387 X1 x, 0.739 0.164 0.164\nconfiguration \u00a2>(x2x3x<xo) <I>\ufffd\" 0 ((<I>\ufffd,)+h2nh1 ) -1 <I>+h2 \u2022X2\u2022Xa\u2022X4...,X5 0.475 0.569 0.443 ..,X2\u2022Xa\u2022X4 \"'\u2022 0.435 0.431 0.335 \u2022x2-,X3 X4-,X5 0.000 0.000 0.000 \u2022X:J\u2022X3 \"'\u2022 xs 0.000 0.000 0.000 ..,.,, X3-,,x4-,X5 0.000 0.000 0.000 ..,.,, X3...,X4 xs 0.000 0.000 0.000 ..,.,, x, X4-,X5 0.000 0.000 0.000 ..,.,, XJ \"'\u2022 \"'\u2022 0.000 0.000 0.000 X2\u2022Xa\u2022X4-,X5 0.000 0.000 0.000 X2\u2022Xa\u2022X4 \"'\u2022 0.000 0.000 0.000 X2-,X3 x4-,Xs 0.475 0.144 0.032 X2\u2022X3 \"'\u2022 xs 0.435 0.450 0.100 x, Xa\u2022X4-,X5 0.029 0.122 0.027\n\"'2 Xa\u2022X4 xo 0.061 0.212 0.047 \"'2 X3 X4-,X5 0.029 0.009 0.002 x, x, \"'\u2022 Xs 0.739 0.063 0.014\nis, we omit h6 in 1l6 and change the relation <l>h5 m 1{5 to <I>t defined by:\nq,5 hs =\nand the other relations in 1{5 are not changed. Simil iarly we have:\n<I> h. <I>t 0 ( <I>\ufffd . ).j.{x,,x7} ' <I>t <I>h, 0 ( <I>t ) .j.{x,,xs} >\n1> \ufffd2\nq, h 1 1\nAs <I>h, = q,.J. h1, we have thus determined the root marginal by moving backward. Now we start moving forward from the root. By applying the formula for computing other marginals, we immediately obtain:\nq,.J.h, <J>t 0 ((<J>\ufffd2 ).j.{x2})-1(q,.j. h1 ).j.{x2}, q,.J.h, <J>t 0 ((<J>t).j.{ x2,x4,xs})-1 (<I>.j. h2).j.{x2,x4,x5},\nq,.J.h\u2022 <J>t 0 ((<I>t).j.{x,,xs})-l(q,.j.h3).j.{x2,x6}, q,.J.h\u2022 <J>t 0 ((<I>t).j.{ x,,x7})-l(q,.j. h4).j.{x2,x7}, q,.J.hs <I>t 0 ((<I>t) .j.{x7,xs})-1(<J>.j. hs ).j.{x7,x8}.\nThe numerical results are shown in the last column of Tables 1 to 6. These relations q,.J.h; form an acyclic join dependency in our extended relational data model.\n562 Wong, Butz, and Xiang\nconfiguration \u00a2(x2x4x5xs) q,3 h \u00ae ((.P\ufffd,)J.h3nh2)-1 -..x2 -..x4 \"\"\"Xs -.xs 0.561 0.602 -..x2...,X4 -,,xiS xs 0.371 0.398 -.,x2-..x4 xs-.xs 0.519 0.676 -..x2-.x4 xs xs 0.250 0.324 \ufffdx, x4 -.xs -..xs 0.016 0.235 \ufffdx, X4\"\"'X5 xs 0.052 0.765 \ufffdx, X4 xs-.xs 0.058 0.251 \ufffdx, X4 xs xs 0.173 0.749\nX2 -.,x4 ...,X5 ...,X6 0.561 0.602 x2...,x4 ...,Xs xs 0.371 0.398 x2-.x4 xs-.xs 0.519 0.675 x2-..x4 xs xs 0.250 0.325 x, x4 -.xs...,xs 0.250 0.235 X2 X4'\"\"X5 xs 0.052 0.765 x, x. xs...,xs 0.058 0.251 x, x. xs xs 0.173 0.749\nq,J.h, 0.267 0.176 0.226 0.109 0.000 0.000 0.000 0.000 0.016 0.011 0.015 0.015 0.008 0.026 0.029 0.085\n4.2 Transformation of a Probability Request to a Query\nJust as we can transform a potential <I>h, to a marginal relation <J>.I.h;, we can transform a probability request of the form p(xa , . . . , xd iXe = f, . . . , Xg = 1) to a re lational query. This query can then be processed by the database management system. There are, how ever, two ways to construct the query depending on whether the product join ( 0) and generalized join ( 0') operators have been incorporated into the database management system. We will show how to transform the probability request to a relational query in either situation.\n(i) In the first case we assume that the database management system has been extended to include the product join and generalized join operators. Then with respect to a particular hypertree con struction ordering, we first determine the join path hr, . . . , hs such that the union hr U . . . U hs of these relation schemes (hyperedges) con\ufffd\ntains all the variables in the probability request p(xa , ... , xd lxe = f, . . . , Xg = 1). Then the re lation <I>\"' = <I>{xa, ... ,xd}' depicted in Figure 7, is being constructed by the query:\nSELECT Xa, . . . , Xd\nINTO <I>\"' FROM <J>.!.hr 0' ... 0' <J>.!.h, WHERE Xe = f, ... , Xg = f.\nAt this point, we have the information needed to answer the probability request all in a single rela tion <I>\"'. However, to compute the required condi tional probability, we need to marginalize <I>\"' onto {xa , ... , xd} by the following query:\nSELECT Xa, . . . , Xd, SU M(f<t>J INTO w\"' FROM <I>\"' GROUPBY Xa, . .. ,Xd\nSince the relation W\"' is not normalized, we have to define the normalization relation q,\"' which is a constant relation as shown in Figure 8, where\nA Method for Implementing a Probabilistic Model as a Relational Database 563\nX a Xd /J,, 4-.. = Cta Ctd ,f, .. (ct) = >.\nC2a C2d ,J, .. (c2) = >.\nCma Cmd ,J, .. (cm) = >.\nFinally, the answer to the probability request is given by the relation 1J!, \u00ae \ufffd;1. This demon strates that any probability request can be eas ily answered by submitting simple queries as de scribed to the relational database management system.\nThe above discussion indicates that we need not implement the marginalization operator .J_, as the standard relational query languages al ready provide the SUM and GROUP BY facil ities. These two functions are indeed equivalent to the marginalization operation.\n(ii) In the second case we simulate the product join and generalized join operators as we are interfac ing with a standard database management sys tem. We will first discuss the simulation of the product join (\u00ae) and generalized join (\u00ae') oper ators , before we construct the relation to answer the probability request.\nSuppose we want to compute the product join of two relations <l>h and <l>k, i.e. , <l>h \u00ae<l>k . According to the definition of \u00ae (see the example in Fig ure 3), we construct the relation <I> h tx1 <I> k by the query:\nSELECT h U k, f1>h, f1>k INTO <l>huk FROM <l>h,<l>k.\nNext we create a new column labelled by the at tribute f t/>h \u00b7t/>k, representing the product \u00a2Jh \u00b7 \u00a2Jk by the query:\nALTER TABLE <l>huk ADD f4>h \u00b7 4>k FLOAT.\nBy definition, the entries in this column are:\nwhere c E Vhuk. The following query:\nUPDATE <l>huk SET f4>h\u00b7t/>k = f1>h * f1>k,\naccomplishes this task. The last step in simulat ing the product join \u00ae is to project <l>huk onto the set of attributes h U k U {ft/>h\u00b7t/>k} using the query:\nSELECT h U k,J\u00a2h\u00b74>k INTO <l>h\u00aek FROM <l>huk\u00b7\nThus we have derived the relation <l>h0k = <l>h \u00ae <l>k . Since <l>h \u00ae' <l>k = <l>h \u00ae<l>k0<1>hnk -1, the simulation of the generalized join 0' is just a simple exten sion of the product join 0. That is we need only compute <l>hnk -1, the inverse relation of <l>hnk. We construct <l>hnk by the query:\nSELECT h n k, SU M(f\u00a2h) INTO <l>hnk FROM <l>h GROUPBY h n k.\nNote that we can use SU M(ft/>k) and <l>k in the above query, since <I>ihnk = <I>thnk. It is straight forward to construct the inverse relation <I> hnk -1 from <l>hnk. Now the relation <l>h\u00ae'k = <l>h 01 <l>k is obtained by performing the product join <l>h\u00aek \u00ae <l>hnk - 1 . Let hr, hr+1, . .. , hs-1, hs denote the join-path. We can compute the relation <I>e = ( ( . . . ( ( cf>.l-hr 0' cf>.l-hr+I) 0' ... ) 0' cf>.l-h,_, ) 0' cf>.l-h,) by repeatedly applying the generalized join operation. It is un derstood that the selection Xe = f, . . . , Xg = 1 has been performed on each of the relations in the join-path before <I>e is computed.\nThe relation <I>\"', depicted in Figure 7, is obtained by the query:\nSELECT X a, . . . , Xd INTO <1>, FROM <I>e.\nWe construct 1J!, and \ufffd,, depicted in Figure 8, as described in (i) of this subsection. The relation 1J! 0 \ufffd;1 is the answer to the given probability request.\n5 Conclusion\nOnce it is acknowledged that a probabilistic model can be viewed as an extended relational data model, it immediately follows that a probabilistic model can be implemented as an everyday database application. Thus, we are spared the arduous task of designing and\n564 Wong, Butz, and Xiang\nimplementing our own probabilistic inference system and the associated costs. Even if such a system was successfully implemented, the resulting performance may not be comparable to that of existing relational databases. Our approach enables us to take advantage of the various performance enhancement techniques including query processing, query optimization, and data structure storage and manipulation, available in traditional relational database management systems. Thus the time required for belief update and answer ing probability requests is shortened.\nThe proposed relational data model also provides a unified approach to design both database and proba bilistic reasoning systems.\nIn this paper, we have defined the product join oper ator Q9 based on ordinary multiplication primarily be cause we are dealing with probabilities. By defining Q9 differently (e.g. based on addition) , our relational data model can be easily extended to solve a number of ap parently different but closely related problems such as dynamic programming [2], solving sparse linear equa tions [11], and constraint propagation [3].\nReferences\n[1] C. Beeri, R. Fagin, D. Maier and M. Yannakakis, \"On the desirability of acyclic database schemes,\" Journal of the Association for Computing Ma chinery, vol. 30, 479-513, 1983.\n[2] U. Bertele and F. Brioschi, Nonserial Dynamic Programming. Academic Press, 1972.\n(3] R. Dechter, A. Dechter and J. Pearl, \"Optimiza tion in constraint networks,\" in Influence Dia grams, Belief Nets, and Decision Analysis, edited by R.M. Oliver and J.Q. Smith, Wiley, 1990.\n(4] P. Hajek, T. Havranek and R. Jirousek, Uncertain Information Processing in Expert Systems. CRC Press, 1992.\n[5) F.V. Jensen, \"Junction tree and decomposable hypergraphs,\" Technical report, JUDEX, Aal borg, Denmark, 1988.\n(6] F.V. Jensen, S.L. Lauritzen, and K.G. Olesen, \"Bayesian updating in causal probabilistic net works by local computations,\" Computational Statistics Quarterly, vol. 4, 269-282, 1990.\n[7) S.L. Lauritzen and D.J. Spiegelhalterr, \"Local computation with probabilities on graphical structures and their application to expert sys tems,\" Journal of the Royal Statistical Society, Series B, vol 50, 157-244, 1988.\n[8) D. Maier, The Theory of Relational Databases. Computer Science Press, 1983.\n(9] R.E. Neapolitan, Probabilistic Reasoning in Ex pert Systems. John Wiley and Sons, 1990.\n[10] J. Pearl, Probablistic Reasoning in Intelligent Sys tems: Networks of Plausible Inference. Morgan Kaufmann, 1988.\n[11) D .J. Rose, \"Triangulated graphs and the elimina tion process,\" Journal of Mathematical Analysis and Its Applications, 32, 597-609, 1970.\n(12] G. Shafer, \"An axiomatic study of computation in hypertrees,\" School of Business Working Paper Series, (No. 232), University of Kansas, Lawrence, 1991.\n(13] P. Shenoy, \"Valuation-based systems for discrete optimization,\" Proc. Sixth Conference on Uncer tainty in Artificial Intelligence, 334-335, 1990.\n[14) S.K.M. Wong, \"An extended relational data model for probablistic reasoning,\" submitted to publication, 1994.\n[15] S.K.M. Wong, Y. Xiang and X. Nie, \"Rep resentation of bayesian networks as relational databases,\" Proc. Fifth International Conference Information Processing and Management of Un certainty in Knowledge-based systems, 159-165, 1994.\n[16] S.K.M. Wong, Z.W. Wang, \"On axiomatization of probabilistic conditional independence,\" Proc. Tenth Conference on Uncertainty in Artificial In telligence, 591-597, 1994."}], "references": [{"title": "On the desirability of acyclic database schemes", "author": ["C. Beeri", "R. Fagin", "D. Maier", "M. Yannakakis"], "venue": "Journal of the Association for Computing Ma\u00ad chinery, vol. 30, 479-513, 1983.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 1983}, {"title": "On axiomatization of probabilistic conditional independence", "author": ["U. Bertele", "F. Brioschi", "Nonserial Dynamic Programming. Academic Press", "1972. (3] R. Dechter", "A. Dechter", "J. Pearl", "\"Optimiza\u00ad tion in constraint networks", "in Influence Dia\u00ad grams", "Belief Nets", "Decision Analysis", "edited by R.M. Oliver", "J.Q. Smith", "Wiley", "1990. (4] P. Hajek", "T. Havranek", "R. Jirousek", "Uncertain Information Processing in Expert Systems. CRC Press", "1992. [5) F.V. Jensen", "\"Junction tree", "decomposable hypergraphs", "Technical report", "JUDEX", "Aal\u00ad borg", "Denmark", "1988. (6] F.V. Jensen", "S.L. Lauritzen", "K.G. Olesen", "\"Bayesian updating in causal probabilistic net\u00ad works by local computations", "Computational Statistics Quarterly", "vol. 4", "269-282", "1990. [7) S.L. Lauritzen", "D.J. Spiegelhalterr", "\"Local computation with probabilities on graphical structures", "their application to expert sys\u00ad tems", "Journal of the Royal Statistical Society", "Series B", "vol 50", "157-244", "1988. [8) D. Maier", "The Theory of Relational Databases. Computer Science Press", "1983. (9] R.E. Neapolitan", "Probabilistic Reasoning in Ex\u00ad pert Systems. John Wiley", "Sons", "1990. [10] J. Pearl", "Probablistic Reasoning in Intelligent Sys\u00ad tems: Networks of Plausible Inference. Morgan Kaufmann", "1988. [11) D .J. Rose", "\"Triangulated graphs", "the elimina\u00ad tion process", "Journal of Mathematical Analysis", "Its Applications", "32", "597-609", "1970. (12] G. Shafer", "\"An axiomatic study of computation in hypertrees", "School of Business Working Paper Series", "(No. 232)", "University of Kansas", "Lawrence", "1991. (13] P. Shenoy", "\"Valuation-based systems for discrete optimization", "Proc. Sixth Conference on Uncer\u00ad tainty in Artificial Intelligence", "334-335", "1990. [14) S.K.M. Wong", "\"An extended relational data model for probablistic reasoning", "submitted to publication", "1994. [15] S.K.M. Wong", "Y. Xiang", "X. Nie", "\"Rep\u00ad resentation of bayesian networks as relational databases", "Proc. Fifth International Conference Information Processing", "Management of Un\u00ad certainty in Knowledge-based systems", "159-165", "1994. [16] S.K.M. Wong", "Z.W. Wang"], "venue": "Proc. Tenth Conference on Uncertainty in Artificial In\u00ad telligence, 591-597, 1994.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 1994}], "referenceMentions": [{"referenceID": 0, "context": "Furthermore, the database scheme derived from a Markov network forms an acyclic join depen\u00ad dency [15], which possesses many desirable properties [1, 8] in database applications.", "startOffset": 146, "endOffset": 152}, {"referenceID": 0, "context": "A hypergraph 1{ is a hypertree (an acyclic hypergraph [1]) if its elements can be ordered, say h1, h2, .", "startOffset": 54, "endOffset": 57}, {"referenceID": 0, "context": "The first step in this transfor\u00ad mation is to check if the hypergraph 1l is a hypertree [1], but if so determine a branching function b( i) for it.", "startOffset": 88, "endOffset": 91}, {"referenceID": 1, "context": "based on addition) , our relational data model can be easily extended to solve a number of ap\u00ad parently different but closely related problems such as dynamic programming [2], solving sparse linear equa\u00ad tions [11], and constraint propagation [3].", "startOffset": 171, "endOffset": 174}], "year": 2011, "abstractText": "This paper discusses a method for im\u00ad plementing a probabilistic inference system based on an extended relational data model. This model provides a unified approach for a variety of applications such as dynamic pro\u00ad gramming, solving sparse linear equations, and constraint propagation. In this frame\u00ad work, the probability model is represented as a generalized relational database. Subse\u00ad quent probabilistic requests can be processed as standard relational queries. Conventional database management systems can be easily adopted for implementing such an approxi\u00ad mate reasoning system.", "creator": "pdftk 1.41 - www.pdftk.com"}}}