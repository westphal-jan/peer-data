{"id": "1302.5681", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "21-Feb-2013", "title": "Weighted Sets of Probabilities and Minimax Weighted Expected Regret: New Approaches for Representing Uncertainty and Making Decisions", "abstract": "We consider a setting where an agent's uncertainty is represented by a set of probability measures, rather than a single measure. Measure-by-measure updating of such a set of measures upon acquiring new information is well-known to suffer from problems; agents are not always able to learn appropriately. To deal with these problems, we propose using weighted sets of probabilities: a representation where each measure is associated with a weight, which denotes its significance. We describe a natural approach to updating in such a situation and a natural approach to determining the weights. We then show how this representation can be used in decision-making, by modifying a standard approach to decision making -- minimizing expected regret -- to obtain minimax weighted expected regret (MWER). We provide an axiomatization that characterizes preferences induced by MWER both in the static and dynamic case.\n\n\n\n\n\n\nThe best approach is to combine an understanding of the natural or dynamic context of the value of a given asset or property to produce a standard approach that can account for the value of the asset or property to represent an objective value. This approach is based on the assumption that this assumption can be empirically verified and that it can be justified by the evidence.\nA standard approach of obtaining the optimal model of expectation for a given asset or property is a natural and dynamic approach to constructing an algorithm, if the model is used with respect to the underlying model. The standard approach should focus on the probability of the optimal model. For example, consider the probability of a given asset being valued for a given asset: a high probability of receiving a low probability of receiving a high probability of receiving a low probability of receiving a low probability of receiving a high probability of receiving a high probability of receiving a high probability of receiving a low probability of receiving a high probability of receiving a low probability of receiving a high probability of receiving a low probability of receiving a high probability of receiving a high probability of receiving a high probability of receiving a low probability of receiving a high probability of receiving a high probability of receiving a high probability of receiving a low probability of receiving a high probability of receiving a high probability of receiving a high probability of receiving a high probability of receiving a high probability of receiving a high probability of receiving a high probability of receiving a high probability of receiving a high probability of receiving a high probability of receiving a high probability of receiving a high probability of receiving a high probability of receiving a high probability of receiving a high probability of receiving a high probability of receiving a high probability of receiving a high probability of receiving", "histories": [["v1", "Thu, 21 Feb 2013 20:11:12 GMT  (189kb)", "http://arxiv.org/abs/1302.5681v1", "Full version of an article [arXiv:1210.4853] that appeared in UAI '12"]], "COMMENTS": "Full version of an article [arXiv:1210.4853] that appeared in UAI '12", "reviews": [], "SUBJECTS": "cs.GT cs.AI", "authors": ["joseph y halpern", "samantha leung"], "accepted": false, "id": "1302.5681"}, "pdf": {"name": "1302.5681.pdf", "metadata": {"source": "CRF", "title": "Weighted Sets of Probabilities and Minimax Weighted Expected Regret: New Approaches for Representing Uncertainty and Making Decisions", "authors": ["Samantha Leung"], "emails": ["halpern@cs.cornell.edu", "samlyy@cs.cornell.edu"], "sections": [{"heading": null, "text": "ar X\niv :1\n30 2.\n56 81\nv1 [\ncs .G"}, {"heading": "1 Introduction", "text": "Agents must constantly make decisions; these decisions are typically made in a setting with uncertainty. For decisions based on the outcome of the toss of a fair coin, the uncertainty can be well characterized by probability. However, what is the probability of you getting cancer if you eat fries at every meal? What if you have salads instead? Even experts would not agree on a single probability.\nRepresenting uncertainty by a single probability measure and making decisions by maximizing expected utility leads to further problems. Consider the following stylized problem, which serves as a running example in this paper.\n\u2217The authors thank Joerg Stoye for useful comments. Work supported in part by NSF grants IIS-0534064, IIS-0812045, and IIS-0911036, by AFOSR grants FA9550-08-1-0438 and FA9550-09-1-0266, and by ARO grant W911NF-09-1-0281.\nThe baker\u2019s delivery robot, T-800, is delivering 1, 000 cupcakes from the bakery to a banquet. Along the way, T-800 takes a tumble down a flight of stairs and breaks some of the cupcakes. The robot\u2019s map indicates that this flight of stairs must be either ten feet or fifteen feet high. For simplicity, assume that a fall of ten feet results in one broken cupcake, while a fall of fifteen feet results in ten broken cupcakes.\nT-800\u2019s choices and their consequences are summarized in Table 1. Decision theorists typically model decision problems with states, acts, and outcomes: the world is in one of many possible states, and the decision maker chooses an act, a function mapping states to outcomes. A natural state space in this problem is {good,broken}1000, where each state is a possible state of the cupcakes. However, all that matters about the state is the number of broken cakes, so we can further restrict to states with either one or ten broken cakes.\nT-800 can choose among three acts: cont : continue the delivery attempt; back : go back for new cupcakes; or check : open the container and count the number of broken cupcakes, and then decide to continue or go back, depending on the number of broken cakes. The client will tolerate one broken cupcake, but not ten broken cupcakes. Therefore, if T-800 chooses cont , it obtains a utility of 10, 000 if there is only one broken cake, but a utility of \u221210, 000 if there are ten broken cakes. If T-800 chooses to go back , then it gets a utility of 0. Finally, checking the cupcakes costs 4, 999 units of utility but is reliable, so if T-800 chooses check , it ends up with a utility of 5, 001 if there is one broken cake, and a utility of \u22124, 999 if there are ten broken cakes.\nIf we try to maximize expected utility, we must assume some probability over states. What measure should be used? There are two hypotheses that T800 entertains: (1) the stairs are ten feet high and (2) the stairs are fifteen feet high. Each of these places a different probability on states. If the stairs are ten feet high, we can take all of the 1, 000 states where there is exactly one broken cake to be equally probable, and take the remaining states to have probability 0; if the stairs are fifteen feet high, we can take all of the C(1000, 10) states where there are exactly ten broken cakes to be equally probable, and take the remaining states to have probability 0. One way to model T-800\u2019s uncertainty about the height of the stairs is to take each hypothesis to be equally likely. However, not having any idea about which hypothesis holds is very different from believing that all hypotheses are equally likely. It is easy to check that taking each hypothesis to be equally likely makes check the act that maximizes\nutility, but taking the probability that the stairs are fifteen feet high to be .51 makes back the act that maximizes expected utility, and taking the probability that the stairs are ten feet high to be .51 makes cont the act that maximizes expected utility. What makes any of these choices the \u201cright\u201d choice?\nIt is easy to construct many other examples where a single probability measure does not capture uncertainty, and does not result in what seem to be reasonable decisions, when combined with expected utility maximization. A natural alternative, which has often been considered in the literature, is to represent the agent\u2019s uncertainty by a set of probability measures. For example, in the delivery problem, the agent\u2019s beliefs could be represented by two probability measures, Pr1 and Pr10, one for each hypothesis. Thus, Pr1 assigns uniform probability to all states with exactly one broken cake, and Pr10 assigns uniform probability to all states with exactly ten broken cakes.\nBut this representation also has problems. Consider the delivery example again. Why should T-800 be sure that there is exactly either one broken cake or ten broken cakes? Of course, we can replace these two hypotheses by hypotheses that say that the probability of a cake being broken is either .001 or .01, but this doesn\u2019t solve the problem. Why should the agent be sure that the probability is either exactly .001 or exactly .01? Couldn\u2019t it also be .0999? Representing uncertainty by a set of measures still places a sharp boundary on what measures are considered possible and impossible.\nA second problem involves updating beliefs. How should beliefs be updated if they are represented by a set of probability measures? The standard approach for updating a single measure is by conditioning. The natural extension of conditioning to sets of measure is measure-by-measure updating: conditioning each measure on the information (and also removing measures that give the information probability 0).\nHowever, measure-by-measure updating can produce some rather counterintuitive outcomes. In the delivery example, suppose that a passer-by tells T-800 the information E: the first 100 cupcakes are good. Assuming that the passerby told the truth, intuition tells us that there is now more reason to believe that there is only one broken cupcake.\nHowever, Pr1 | E places uniform probability on all states where the first 100 cakes are good, and there is exactly one broken cake among the last 900. Similarly, Pr10 | E places uniform probability on all states where the first 100 cakes are good, and there are exactly ten broken cakes among the last 900. Pr1 | E still places probability 1 on there being one broken cake, just like Pr1, Pr10 | E still places probability 1 on there being ten broken cakes. There is no way to capture the fact that T-800 now views the hypothesis Pr10 as less likely, even if the passer-by had said instead that the first 990 cakes are all good!\nOf course, both of these problems would be alleviated if we placed a probability on hypotheses, but, as we have already observed, this leads to other problems. In this paper, we propose an intermediate approach: representing uncertainty using weighted sets of probabilities. That is, each probability measure is associated with a weight. These weights can be viewed as probabilities; indeed, if the set of probabilities is finite, we can normalize them so that they\nare effectively probabilities. Moreover, in one important setting, we update them in the same way that we would update probabilities, using likelihood (see below). On the other hand, these weights do not act like probabilities if the set of probabilities is infinite. For example, if we had a countable set of hypotheses, we could assign them all weight 1 (so that, intuitively, they are all viewed as equally likely), but there is no uniform measure on a countable set.\nMore importantly, when it comes to decision making, we use the weights quite differently from how we would use second-order probabilities on probabilities. Second-order probabilities would let us define a probability on events (by taking expectation) and maximize expected utility, in the usual way. Using the weights, we instead define a novel decision rule, minimax weighted expected regret (MWER), that has some rather nice properties, which we believe will make it widely applicable in practice. If all the weights are 1, then MWER is just the standard minimax expected regret (MER) rule (described below). If the set of probabilities is a singleton, then MWER agrees with (subjective) expected utility maximization (SEU). More interestingly perhaps, if the weighted set of measures converges to a single measure (which will happen in one important special case, discussed below), MWER converges to SEU. Thus, the weights give us a smooth, natural way of interpolating between MER and SEU.\nIn summary, weighted sets of probabilities allow us to represent ambiguity (uncertainty about the correct probability distribution). Real individuals are sensitive to this ambiguity when making decisions, and the MWER decision rule takes this into account. Updating the weighted sets of probabilities using likelihood allows the initial ambiguity to be resolved as more information about the true distribution is obtained.\nWe now briefly explain MWER, by first discussing MER. MER is a probabilistic variant of the minimax regret decision rule proposed by Niehans [13] and Savage [17]. Most likely, at some point, we\u2019ve second-guessed ourselves and thought \u201chad I known this, I would have done that instead\u201d. That is, in hindsight, we regret not choosing the act that turned out to be optimal for the realized state, called the ex post optimal act. The regret of an act a in a state s is the difference (in utility) between the ex post optimal act in s and a. Of course, typically one does not know the true state at the time of decision. Therefore the regret of an act is the worst-case regret, taken over all states. The minimax regret rule orders acts by their regret.\nThe definition of regret applies if there is no probability on states. If an agent\u2019s uncertainty is represented by a single probability measure, then we can compute the expected regret of an act a: just multiply the regret of an act a at a state s by the probability of s, and then sum. It is well known that the order on acts induced by minimizing expected regret is identical to that induced by maximizing expected utility (see [8] for a proof). If an agent\u2019s uncertainty is represented by a set P of probabilities, then we can compute the expected regret of an act a with respect to each probability measure Pr \u2208 P , and then take the worst-case expected regret. The MER (Minimax Expected Regret) rule orders acts according to their worst-case expected regret, preferring the act that minimizes the worst-case regret. If the set of measures is the set of all probability\nmeasures on states, then it is not hard to show that MER induces the same order on acts as (probability-free) minimax regret. Thus, MER generalizes both minimax regret (if P consists of all measures) and expected utility maximization (if P consists of a single measure).\nMWER further generalizes MER. If we start with a weighted set of measures, then we can compute the weighted expected regret for each one (just multiply the expected regret with respect to Pr by the weight of Pr) and compare acts by their worst-case weighted expected regret.\nSarver [16] also proves a representation theorem that involves putting a multiplicative weight on a regret quantity. However, his representation is fundamentally different from MWER. In his representation, regret is a factor only when comparing two sets of acts; the ranking of individual acts is given by expected utility maximization. By way of contrast, we do not compare sets of acts.\nIt is standard in decision theory to axiomatize a decision rule by means of a representation theorem. For example, Savage [18] showed that if an agent\u2019s preferences satisfied several axioms, such as completeness and transitivity, then the agent is behaving as if she is maximizing expected utility with respect to some utility function and probabilistic belief.\nIf uncertainty is represented by a set of probability measures, then we can generalize expected utility maximization to maxmin expected utility (MMEU). MMEU compares acts by their worst-case expected utility, taken over all measures. MMEU has been axiomatized by Gilboa and Schmeidler [7]. MER was axiomatized by Hayashi [8] and Stoye [20]. We provide an axiomatization of MWER. We make use of ideas introduced by Stoye [20] in his axiomatization of MER, but the extension seems quite nontrivial.\nWe also consider a dynamic setting, where beliefs are updated by new information. If observations are generated according to a probability measure that is stable over time, then, as we suggested above, there is a natural way of updating the weights given observations, using ideas of likelihood. The idea is straightforward. After receiving some information E, we update each probability Pr \u2208 P to Pr | E, and take its weight to be \u03b1Pr = Pr(E)/ supPr\u2032\u2208P Pr\n\u2032(E). If more than one Pr \u2208 P gets updated to the same Pr | E, the sup of all such weights is used. Thus, the weight of Pr after observing E is modified by taking into account the likelihood of observing E assuming that Pr is the true probability. We refer to this method of updating weights as likelihood updating.\nIf observations are generated by a stable measure (e.g., we observe the outcomes of repeated flips of a biased coin) then, as the agent makes more and more observations, the weighted set of probabilities of the agent will, almost surely, look more and more like a single measure. The weight of the measures in P closest to the measure generating the observations converges to 1, and the weight of all other measures converges to 0. This would not be the case if uncertainty were represented by a set of probability measures and we did measure-by-measure updating, as is standard. As we mentioned above, this means that MWER converges to SEU.\nWe provide an axiomatization for dynamic MWER with likelihood updat-\ning. We remark that a dynamic version of MMEU with measure-by-measure updating has been axiomatized by Jaffray [10], Pires [14], and Siniscalchi [19].\nLikelihood updating is somewhat similar in spirit to an updating method implicitly proposed by Epstein and Schneider [5]. They also represented uncertainty by using (unweighted) sets of probability measures. They choose a threshold \u03b1 with 0 < \u03b1 < 1, update by conditioning, and eliminate all measures whose relative likelihood does not exceed the threshold. This approach also has the property that, over time, all that is left in P are the measures closest to the measure generating the observations; all other measures are eliminated. However, it has the drawback that it introduces a new, somewhat arbitrary, parameter \u03b1.\nChateauneuf and Faro [2] also consider weighted sets of probabilities (they model the weights using what they call confidence functions), although they impose more constraints on the weights than we do. They then define and provide a representation of a generalization of MMEU using weighted sets of probabilities that parallels our generalization of MER. Chateauneuf and Faro do not discuss the dynamic situation; specifically, they do not consider how weights should be updated in the light of new information.\nThe rest of this paper is organized as follows. Section 2 introduces the weighted sets of probabilities representation, and Section 3 introduces the MWER decision rule. Axiomatic characterizations of static and dynamic MWER are provided in Sections 4 and 5, respectively. We conclude in Section 7."}, {"heading": "2 Weighted Sets of Probabilities", "text": "A set P+ of weighted probability measures on a set S consists of pairs (Pr, \u03b1Pr), where \u03b1Pr \u2208 [0, 1] and Pr is a probability measure on S.\n1 Let P = {Pr : \u2203\u03b1(Pr, \u03b1) \u2208 P+}. We assume that, for each Pr \u2208 P , there is exactly one \u03b1 such that (Pr, \u03b1) \u2208 P+. We denote this number by \u03b1Pr, and view it as the weight of Pr. We further assume for convenience that weights have been normalized so that there is at least one measure Pr \u2208 P such that \u03b1Pr = 1.\n2 We remark that, just as we do, Chateaunef and Faro [2] take weights to be in the interval [0, 1]. They impose additional requirements on the weights. For example, they require that the weight of a convex combination of two probability measures is at least as high as the weight of each one. This does not seem reasonable in our applications. For example, an agent may know that one of two measures is generating his observations, and give them both weight 1, while giving all other distributions weight 0.\n1In this paper, for ease of exposition, we take the state space S to be finite, and assume that all sets are measurable. We can easily generalize to arbitrary measure spaces.\n2While we could take weights to be probabilities, and normalize them so that they sum to 1, if P is finite, this runs into difficulties if we have an infinite number of measures in P. For example, if we are tossing a coin, and P includes all probabilities on heads from 1/3 to 2/3, using a uniform probability, we would be forced to assign each individual probability measure a weight of 0, which would not work well in the definition of MWER.\nAs we observed in the introduction, one way of updating weighted sets of probabilities is by using likelihood updating. We use P+ | E to denote the result of applying likelihood updating to P+. Define P + (E) = sup{\u03b1Pr Pr(E) : Pr \u2208 P}; if P + (E) > 0, set \u03b1Pr,E = sup{Pr\u2032\u2208P:Pr\u2032|E=Pr|E} \u03b1Pr\u2032 Pr \u2032(E)\nP + (E)\n. Note that\ngiven a measure Pr \u2208 P , there may be several distinct measures Pr\u2032 in P such that Pr\u2032 | E = Pr | E. Thus, we take the weight of Pr | E to be the sup of the possible candidate values of \u03b1Pr,E . By dividing by P + (E), we guarantee that \u03b1Pr,E \u2208 [0, 1], and that there is some measure Pr such that \u03b1Pr,E = 1, as long as there is some pair (\u03b1Pr,Pr) \u2208 P such that \u03b1Pr Pr(E) = P + (E). If P + (E) > 0, we take P+ | E to be {(Pr | E,\u03b1Pr,E) : Pr \u2208 P}.\nIf P + (E) = 0, then P+ | E is undefined.\nIn computing P+ | E, we update not just the probability measures in P , but also their weights. The new weight combines the old weight with the likelihood. Clearly, if all measures in P assign the same probability to the event E, then likelihood updating and measure-by-measure updating coincide. This is not surprising, since such an observation E does not give us information about the relative likelihood of measures. We stress that using likelihood updating is appropriate only if the measure generating the observations is assumed to be stable. For example, if observations of heads and tails are generated by coin tosses, and a coin of possibly different bias is tossed in each round, then likelihood updating would not be appropriate.\nIt is well known that, when conditioning on a single probability measure, the order that information is acquired is irrelevant; the same observation easily extends to sets of probability measures. As we now show, it can be further extended to weighted sets of probability measures.\nProposition 1. Likelihood updating is consistent in the sense that for all E1, E2 \u2286 S, (P+ | E1) | E2 = (P + | E2) | E1 = P + | (E1 \u2229 E2), provided that P+ | (E1 \u2229 E2) is defined.\nProof. By standard results, (Pr | E1) | E2 = (Pr | E2) | E1 = Pr | (E1 \u2229 E2). Since the weight of the measure Pr | E1 is proportional to \u03b1Pr Pr(E1), the weight of (Pr | E1) | E2 is proportional to \u03b1Pr Pr(E1) Pr(E2 | E1) = \u03b1Pr Pr(E1 \u2229 E2). Likewise, the weight of (Pr | E2) | E1 is proportional to \u03b1Pr Pr(E2) Pr(E1 | E2) = \u03b1Pr Pr(E1 \u2229 E2). Since, in all these cases, the sup of the weights is normalized to 1, the weights of corresonding measures in P+ | (E1 \u2229E2), (P\n+ | E1) | E2 and (P + | E2) | E1 must be equal."}, {"heading": "3 MWER", "text": "We now define MWER formally. Given a set S of states and a setX of outcomes, an act f (over S and X) is a function mapping S to X . For simplicity in this paper, we take S to be finite. Associated with each outcome x \u2208 X is a utility:\nu(x) is the utility of outcome x. We call a tuple (S,X, u) a (non-probabilistic) decision problem. To define regret, we need to assume that we are also given a set M \u2286 XS of feasible acts, called the menu. The reason for the menu is that, as is well known (and we will demonstrate by example shortly), regret can depend on the menu. Moreover, we assume that every menu M has utilities bounded from above. That is, we assume that for all menus M , supg\u2208M u(g(s)) is finite. This ensures that the regret of each act is well defined.3 For a menu M and act f \u2208 M , the regret of f with respect to M and decision problem (S,X, u) in state s is\nregM (f, s) =\n(\nsup g\u2208M u(g(s))\n)\n\u2212 u(f(s)).\nThat is, the regret of f in state s (relative to menu M) is the difference between u(f(s)) and the highest utility possible in state s (among all the acts in M). The regret of f with respect to M and decision problem (S,X, u) is the worst-case regret over all states:\nmax s\u2208S regM (f, s).\nWe denote this as reg (S,X,u) M (f), and usually omit the superscript (S,X, u) if it is clear from context. If there is a probability measure Pr over the states, then we can consider the probabilistic decision problem (S,X, u,Pr). The expected regret of f with respect to M is\nregM,Pr(f) = \u2211\ns\u2208S\nPr(s)regM (f, s).\nIf there is a set P of probability measures over the states, then we consider the P-decision problem (S,X, u,P). The maximum expected regret of f \u2208 M with respect to M and (S,X, u,P) is\nregM,P(f) = sup Pr\u2208P\n(\n\u2211\ns\u2208S\nPr(s)regM (f, s)\n)\n.\nFinally, if beliefs are modeled by weighted probabilities P+, then we consider the P+-decision problem (S,X, u,P+). The maximum weighted expected regret of f \u2208 M with respect to M and (S,X, u,P+) is\nregM,P+(f) = sup Pr\u2208P\n(\n\u03b1Pr \u2211\ns\u2208S\nPr(s)regM (f, s)\n)\n.\nThe MER decision rule is thus defined for all f, g \u2208 XS as\nf S,X,uM,P g iff reg (S,X,u) M,P (f) \u2264 reg (S,X,u) M,P (g).\n3 Stoye [21] assumes that, for each menu M , there is a finite set AM of acts such that M consists of all the convex combinations of the acts in AM . Our assumption is clearly much weaker than Stoye\u2019s.\nThat is, f is preferred to g if the maximum expected regret of f is less than that of g. We can similarly define M,reg , S,X,u M,Pr , and S,X,u M,P+ by replacing reg (S,X,u) M,P by reg (S,X,u) M , reg (S,X,u) M,Pr , and reg (S,X,u) M,P+ , respectively. Again, we usually omit the superscript (S,X, u) and subscript Pr or P+, and just write M , if it is clear from context.\nTo see how these definitions work, consider the delivery example from the introduction. There are 1, 000 states with one broken cake, and C(1000, 10) states with ten broken cakes. The regret of each action in a state depends only on the number of broken cakes, and is given in Table 2. It is easy to see that the action that minimizes regret is check , with cont and back having equal regret. If we represent uncertainty using the two probability measures Pr1 and Pr10, the expected regret of each of the acts with respect to Pr1 (resp., Pr10) is just its regret with respect to states with one (resp. ten) broken cakes. Thus, the action that minimizes maximum expected regret is again check .\nAs we said above, the ranking of acts based on MER or MWER can change if the menu of possible choices changes. For example, suppose that we introduce a new choice in the delivery problem, whose gains and losses are twice those of cont , resulting in the payoffs and regrets described in Table 3. In this new setting, cont has a lower maximum expected regret (10, 000) than check (14, 999), so MER prefers cont over check . Thus, the introduction of a new choice can affect the relative order of acts according to MER (and MWER), even though other acts are preferred to the new choice. By way of contrast, the decision rules MMEU and SEU are menu-independent ; the relative order of acts according to MMEU and SEU is not affected by the addition of new acts.\nWe next consider a dynamic situation, where the agent acquires information. Specifically, in the context of the delivery problem, suppose that T800 learns E\u2014the first 100 items are good. Initially, suppose that T-800\nhas no reason to believe that one hypothesis is more likely than the other, so assigns both hypotheses weight 1. Note that P1(E) = 0.9 and Pr10(E) = C(900, 10)/C(1000, 10)\u2248 0.35. Thus,\nP+ | E = {(Pr1 | E, 1), (Pr10 | E,C(900, 10)/(.9C(1000, 10))}.\nWe can also see from this example that MWER interpolates between MER and expected utility maximization. Suppose that a passer-by tells T-800 that the first N cupcakes are good. If N = 0, MWER with initial weights 1 is the same as MER. On the other hand, if N \u2265 991, then the likelihood of Pr10 is 0, and the only measure that has effect is Pr1, which means minimizing maximum weighted expected regret is just maximizing expected utility with respect to Pr1. If 0 < N < 991, then the likelihoods (hence weights) of Pr1 and Pr10 are 1 and C(1000\u2212N,10)C(1000,10) \u00d7 1000 1000\u2212N < ((999 \u2212 N)/999) 9. Thus, as N increases, the weight of Pr10 goes to 0, while the weight of Pr1 stays at 1."}, {"heading": "4 An axiomatic characterization of MWER", "text": "We now provide a representation theorem for MWER. That is, we provide a collection of properties (i.e., axioms) that hold of MWER such that a preference order on acts that satisfies these properties can be viewed as arising from MWER. To get such an axiomatic characterization, we restrict to what is known in the literature as the Anscombe-Aumann (AA) framework [1], where outcomes are restricted to lotteries. This framework is standard in the decision theory literature; axiomatic characterizations of SEU [1], MMEU [7], and MER [8, 20] have already been obtained in the AA framework. We draw on these results to obtain our axiomatization.\nGiven a set Y (which we view as consisting of prizes), a lottery over Y is just a probability with finite support on Y . Let \u2206(Y ) consist of all finite probabilities over Y . In the AA framework, the set of outcomes has the form \u2206(Y ). So now acts are functions from S to \u2206(Y ). (Such acts are sometimes called Anscombe-Aumann acts.) We can think of a lottery as modeling objective uncertainty, while a probability on states models subjective uncertainty; thus, in the AA framework we have both objective and subjective uncertainty. The technical advantage of considering such a set of outcomes is that we can consider convex combinations of acts. If f and g are acts, define the act \u03b1f + (1 \u2212 \u03b1)g to be the act that maps a state s to the lottery \u03b1f(s) + (1 \u2212 \u03b1)g(s).\nIn this setting, we assume that there is a utility function U on prizes in Y . The utility of a lottery l is just the expected utility of the prizes obtained, that is,\nu(l) = \u2211\n{y\u2208Y : l(y)>0}\nl(y)U(y).\nThis makes sense since l(y) is the probability of getting prize y if lottery l is played. The expected utility of an act f with respect to a probability Pr is then\njust u(f) = \u2211\ns\u2208S Pr(s)u(f(s)), as usual. We also assume that there are at least two prizes y1 and y2 in Y , with different utilities U(y1) and U(y2).\nGiven a set Y of prizes, a utility U on prizes, a state space S, and a set P+ of weighted probabilities on S, we can define a family S,\u2206(Y ),u M,P+ of preference orders on Anscombe-Aumann acts determined by weighted regret, one per menu M , as discussed above, where u is the utility function on lotteries determined by U . For ease of exposition, we usually write S,Y,UM,P+ rather than S,\u2206(Y ),u M,P+ .\nWe state the axioms in a way that lets us clearly distinguish the axioms for SEU, MMEU, MER, and MWER. The axioms are universally quantified over acts f , g, and h, menus M and M \u2032, and p \u2208 (0, 1). We assume that f, g \u2208 M when we write f M g.\n4 We use l\u2217 to denote a constant act that maps all states to l.\nAxiom 1. (Transitivity) f M g M h \u21d2 f M h.\nAxiom 2. (Completeness) f M g or g M f .\nAxiom 3. (Nontriviality) f \u227bM g for some acts f and g and menu M .\nAxiom 4. (Monotonicity) If (f(s))\u2217 {(f(s))\u2217,(g(s))\u2217} (g(s)) \u2217 for all s \u2208 S, then f M g.\nAxiom 5. (Mixture Continuity) If f \u227bM g \u227bM h, then there exist q, r \u2208 (0, 1) such that\nqf + (1\u2212 q)h \u227bM\u222a{qf+(1\u2212q)h} g \u227bM\u222a{rf+(1\u2212r)h} rf + (1\u2212 r)h.\nMenu-independent versions of Axioms 1\u20135 are standard. Clearly (menuindependent versions of) Axioms 1, 2, 4, and 5 hold for MMEU, MER, and SEU; Axiom 3 is assumed in all the standard axiomatizations, and is used to get a unique representation.\nAxiom 6. (Ambiguity Aversion)\nf \u223cM g \u21d2 pf + (1\u2212 p)g M\u222a{pf+(1\u2212p)g} g.\nAmbiguity Aversion says that the decision maker weakly prefers to hedge her bets. It also holds for MMEU, MER, and SEU, and is assumed in the axiomatizations for MMEU and MER. It is not assumed for the axiomatization of SEU, since it follows from the Independence axiom, discussed next. Independence also holds for MWER, provided that we are careful about the menus involved. Given a menu M and an act h, let pM +(1\u2212p)h be the menu {pf +(1\u2212p)h : p \u2208 M}.\n4Stoye [21] assumed that menus were convex, so that if f, g \u2208 M , then so is pf + (1\u2212 p)g. We do not make this assumption, although our results would still hold if we did (with the axioms slightly modified to ensure that menus are convex). While it may seem reasonable to think that, if f and g are feasible for an agent, then so is pf + (1 \u2212 p)g, this not always the case. For example, it may be difficult for the agent to randomize, or it may be infeasible for the agent to randomize with probability p for some choices of p (e.g., for p irrational).\nAxiom 7. (Independence)\nf M g iff pf + (1\u2212 p)h pM+(1\u2212p)h pg + (1\u2212 p)h.\nIndependence holds in a strong sense for SEU, since we can ignore the menus. The menu-independent version of Independence is easily seen to imply Ambiguity Aversion. Independence does not hold for MMEU.\nAlthough we have menu independence for SEU and MMEU, we do not have it for MER or MWER. The following two axioms are weakened versions of menu independence that do hold for MER and MWER.\nAxiom 8. (Menu independence for constant acts) If l\u2217 and (l\u2032)\u2217 are constant acts, then l\u2217 M (l \u2032)\u2217 iff l\u2217 M \u2032 (l \u2032)\u2217.\nIn light of this axiom, when comparing constant acts, we omit the menu. An act h is never strictly optimal relative to M if, for all states s \u2208 S, there is some f \u2208 M such that (f(s))\u2217 (h(s))\u2217.\nAxiom 9. (Independence of Never Strictly Optimal Alternatives (INA)) If every act in M \u2032 is never strictly optimal relative to M , then f M g iff f M\u222aM \u2032 g.\nAxiom 10. (Boundedness of menus) For every menu M , there exists a lottery l \u2208 \u2206(Y ) such that for all f \u2208 M and s \u2208 S, (f(s))\u2217 l \u2217 .\nThe boundedness axiom enforces the assumption that we made earlier that every menu has utilities that are bounded from above. Recall that this assumption is necessary for regret to be finite.\nWe now present our representation theorem for MWER. Roughly, the representation theorem states that a family of preferences satisfies Axioms 1\u201310 if and only if it has a MWER representation with respect to some utility function and weighted probabilities. In the representation theorem for SEU [1], not only is the utility function unique (up to affine transformations, so that we can replace U by aU + b, where a > 0 and b are constants), but the probability is unique as well. Similarly, in the MMEU representation theorem of Gilboa and Schmeidler [7], the utility function is unique, and the set of probabilities is also unique, as long as one assume that the set is convex and closed.\nTo get uniqueness in the representation theorem for MWER, we need to consider a different representation of weighted probabilities. Define a sub-probability measure p on S to be like a probability measure (i.e., a function mapping measurable subsets of S to [0, 1] such that p(T \u222aT \u2032) = p(T )+p(T \u2032) for disjoint sets T and T \u2032), without the requirement that p = 1. We can identify a weighted probability distribution (Pr, \u03b1) with the sub-probability measure \u03b1Pr. (Note that given a sub-probability measure p, there is a unique pair (\u03b1,Pr) such that P = \u03b1Pr: we simply take \u03b1 = p(S) and Pr = p/\u03b1.) A set C of sub-probability measures is downward-closed if, whenever p \u2208 C and q \u2264 p, then q \u2208 C. We get a unique set of sub-probability measures in our representation theorem if we restrict to sets that are convex, downward-closed, closed, and contain at least one (proper) probability measure. (The latter requirement corresponds to\nhaving \u03b1Pr = 1 for some Pr \u2208 P +.) For convenience, we will call a set regular if it is convex, downward-closed, and closed. We identify each set of weighted probabilities P+ with the set of subprobability measures\nC(P+) = {\u03b1 Pr : (Pr, \u03b1Pr) \u2208 P +, 0 \u2264 \u03b1 \u2264 \u03b1Pr}.\nNote that if (\u03b1,Pr) \u2208 P+, then C(P+) includes all the sub-probability measures between the all-zero measure and \u03b1Pr Pr.\nWe need to restrict to closed and convex sets of sub-probability measures to get uniqueness in the representation of MWER for much the same reason that we need to restrict to closed and convex sets to get uniqueness in the representation of MMEU. To see why convexity is needed, consider the delivery example and the expected regrets in Table 2, and the distribution aPr1 +(1 \u2212 a) Pr10, for some a \u2208 (0, 1). The weighted expected regret of any act with respect to aPr1 +(1\u2212a) Pr10 is bounded above by the maximum weighted expected regret of that act with respect to Pr1 and Pr10. Therefore, adding aPr1 +(1\u2212a) Pr10 to P+ for some weight a \u2208 (0, 1) does not change the resulting family of preferences. Similarly, we need to restrict to closed sets for uniqueness, since if we start with a set C of sub-probability measures that is not closed, taking the closure of C would result in the same family of preferences.\nWhile convexity is easy to define for a set of sub-probability measures, there seems to be no natural notion of convexity for a set P+ of weighted probabilities. Moreover, the requirement that P+ is closed is different from the requirement that C(P+) is closed. The latter requirement seems more reasonable. For example, fix a probability measure Pr, and let P+ = {(1,Pr)}\u222a{(0,Pr\u2032) : Pr\u2032 6= Pr}. Thus, P+ essentially consists of a single probability measure, namely Pr, with weight 1; all the weighted probability measures (0,Pr\u2032) have no impact. This represents the uncertainty of an agent who is sure that that Pr is true probability. Clearly P+ is not closed, since we can find a sequence Prn such that (0,Prn) \u2192 (0,Pr), although (0,Pr) /\u2208 P\n+. But C(Pr+) is closed. Restricting to closed, convex sets of sub-probability measures does not suffice to get uniqueness; we also need to require downward-closedness. This is so because if p is in C, then adding any q \u2264 p to the set leaves all regrets unchanged. Finally, the presence of a proper probability measure is also required, since for any a \u2208 (0, 1], scaling each element in the set C by a leaves the family of preferences unchanged.\nIn summary, if we consider arbitrary sets of sub-probability measures, then the set of sub-probability measures that represent a given family of MWER preferences would be unique if we required the set to be regular and contain a probability measure.\nTheorem 1. For all Y , U , S, and P+, the family of preference orders S,Y,UM,P+ satisfies Axioms 1\u201310. Conversely, if a family of preference orders M on the acts in \u2206(Y )S satisfies Axioms 1\u201310, then there exist a a utility U on Y and a weighted set P+ of probabilities on S such that C(P+) is regular and\nM= S,Y,U M,P+. Moreover, U is unique up to affine transformations, and C(P +)\nis unique in the sense that if Q+ represents M , and C(Q +) is regular, then C(Q+) = C(P+).\nShowing that S,Y,UM,P+ satisfies Axioms 1\u201310 is fairly straightforward; we leave details to the reader. The proof of the converse is quite nontrivial, although it follows the lines of the proof of other representation theorems. We provide an outline of the proof here; details can be found in the appendix.\nUsing standard techniques, we can show that the axioms guarantee the existence of a utility function U on prizes that can be extended to lotteries in the obvious way, so that l\u2217 (l\u2032)\u2217 iff U(l) \u2265 U(l\u2032). We then use techniques of Stoye [21] to show that it suffices to get a representation theorem for a single menu, rather than all menus: the menu consisting of all acts f such that U(f(s)) \u2264 0 for all states s \u2208 S. This allows us to use techniques in the spirit of those used by by Gilboa and Schmeidler [6] to represent (unweighted) MMEU. However, there are technical difficulties that arise from the fact that we do not have a key axiom that is satisfied by MMEU: C-independence (discussed below). The heart of the proof involves dealing with the lack of C-independence; as we said, the details can be found in the appendix.\nIt is instructive to compare Theorem 1 to other representation results in the literature. Anscombe and Aumann [1] showed that the menu-independent versions of axioms 1\u20135 and 7 characterize SEU. The presence of Axiom 7 (menuindependent Independence) greatly simplifies things. Gilboa and Schmeidler [7] showed that axioms 1\u20136 together with one more axiom that they call Certaintyindependence characterizesMMEU. Certainty-independence, or C-independence for short, is a weakening of independence (which, as we observed, does not hold for MMEU), where the act h is required to be a constant act. Since MMEU is menu-independent, we state it in a menu-independent way.\nAxiom 11. (C-Independence) If h is a constant act, then f g iff pf + (1 \u2212 p)h pg + (1\u2212 p)h.\nAs we observed, in general, we have Ambiguity Aversion (Axiom 6) for regret. Betweenness [3] is a stronger notion than ambiguity aversion, which states that if an agent is indifferent between two acts, then he must also be indifferent among all convex combinations of these acts. While betweenness does not hold for regret, Stoye [20] gives a weaker version that does hold. A menu M has state-independent outcome distributions if the set L(s) = {y \u2208 \u2206(Y ) : \u2203f \u2208 M, f(s) = y} is the same for all states s.\nAxiom 12. If h is a constant act, and M has state-independent outcome distributions, then\nh \u223cM f \u21d2 pf + (1\u2212 p)h \u223cM\u222a{pf+(1\u2212p)h} f.\nThe assumption that the menu has state-independent outcome distributions is critical in Axiom 12.\nStoye [20] shows that Axioms 1\u20139 together with Axiom 12 characterize MER.5 Non-probabilistic regret (which we denote REG) can be viewed as a\n5Stoye actually worked with choice correspondences; see Section 7.\nspecial case of MER, where P consists of all distributions. This means that it satisfies all the axioms that MER satisfies. As Stoye [21] shows, REG is characterized by Axioms 1\u20139 and one additional axiom, which he calls Symmetry. We omit the details here.\nThe assumption that the menu has state-independent outcome distributions is critical in Axiom 12. For example, suppose that we change the payoffs in the delivery problem so that cont has the same maximum expected regret as back (10, 000). However, as seen in Table 4, 12cont + 1 2back has lower maximum expected regret (5, 000) than cont (10, 000), showing that the variant of Axiom 12 without the state-independent outcome distribution requirement does not hold.\nAlthough Axiom 12 is sound for unweighted minimax expected regret, it is no longer sound once we add weights. For example, suppose that we modified the delivery problem so that all states we care about have the same outcome distributions, as required by Axiom 12. Then the payoffs and regrets will be those shown in Table 5. Suppose that the weights on Pr1 and Pr10 are 1 and 0.5, respectively. Then cont has the same maximum weighted expected regret as back (10, 000). However, 12cont + 1 2back has lower maximum weighted expected regret (7, 500) than cont , showing that Axiom 12 with weighted probabilities does not hold.\nTable 6 describes the relationship between the axioms characterizing the decision rules."}, {"heading": "5 Characterizing MWER with Likelihood Up-", "text": "dating\nWe next consider a more dynamic setting, where agents learn information. For simplicity, we assume that the information is always a subset E of the state space. If the agent is representing her uncertainty using a set P+ of weighted probability measures, then we would expect her to update P+ to some new set Q+ of weighted probability measures, and then apply MWER with uncertainty represented byQ+. In this section, we characterize what happens in the special case that the agent uses likelihood updating, so that Q+ = (P+ | E).\nFor this characterization, we assume that the agent has a family of preference orders E,M indexed not just by the menu M , but by the information E. Each preference order E,M satisfies Axioms 1\u201310, since the agent makes decisions after learning E using MWER. Somewhat surprisingly, all we need is one extra axiom for the characterization; we call this axiom MDC, for \u2018menu-dependent dynamic consistency\u2019.\nTo explain the axiom, we need some notation. As usual, we take fEh to be the act that agrees with f on E and with h off of E; that is\nfEh(s) =\n{\nf(s) if s \u2208 E h(s) if s /\u2208 E.\nIn the delivery example, the act check can be thought of as (cont)E(back ), where E is the set of states where there is only one broken cake.\nRoughly speaking, MDC says that you prefer f to g once you learn E if and only if, for any act h, you also prefer fEh to gEh before you learn anything. This seems reasonable, since learning that the true state was in E is conceptually similar to knowing that none of your choices matter off of E.\nTo state MDC formally, we need to be careful about the menus involved. Let MEh = {fEh : f \u2208 M}. We can identify unconditional preferences with preferences conditional on S; that is, we identify M with S,M . We also need to restrict the sets E to which MDC applies. Recall that conditioning using likelihood updating is undefined for an event such that P + (E) = 0. That is, \u03b1Pr Pr(E) = 0 for all Pr \u2208 P . As is commonly done, we capture the idea that conditioning on E is possible using the notion of a non-null event.\nDefinition 1. An event E is null if, for all f, g \u2208 \u2206(Y )S and menus M with\nfEg, g \u2208 M , we have fEg \u223cM g.\nMDC. For all non-null events E, f E,M g iff fEh MEh gEh for some h \u2208 M .6\nThe key feature of MDC is that it allows us to reduce all the conditional preference orders E,M to the unconditional order M , to which we can apply Theorem 1.\nTheorem 2. For all Y , U , S, and P+, the family of preference orders S,Y,UP+|E,M for events E such that P + (E) > 0 satisfies Axioms 1\u201310 and MDC. Conversely, if a family of preference orders E,M on the acts in \u2206(Y ) S satisfies Axioms 1\u201310 and MDC, then there exists a utility U on Y and a weighted set P+ of probabilities on S such that C(P+) is regular, and for all non-null E, E,M= S,Y,U P+|E,M . Moreover, U is unique up to affine transformations, and C(P+) is unique in the sense that if Q+ represents E,M , and C(Q +) is regular, then C(Q+) = C(P+).\nProof. Since M= S,M satisfies Axioms 1\u201310, there must exist a weighted set P+ of probabilities on S and a utility function U such that f M g iff f S,Y,U M,P+ g. We now show that if E is non-null, then P + (E) > 0, and f E,M g iff f (S,X,u) M,P+|E g.\nFor the first part, it clearly is equivalent to show that if P + (E) = 0, then E is null. So suppose that P + (E) = 0. Then \u03b1Pr Pr(E) = 0 for all Pr \u2208 P . This means that \u03b1Pr Pr(s) = 0 for all Pr \u2208 P and s \u2208 E. Thus, for all acts f and g,\nregM,P+(fEg) = supPr\u2208P ( \u03b1Pr \u2211 s\u2208S Pr(s)regM (fEg, s) ) = supPr\u2208P ( \u03b1Pr ( \u2211 s\u2208E Pr(s)regM (f, s) )\n+ \u2211 s\u2208Ec Pr(s)regM (g, s) )\n= supPr\u2208P ( \u03b1Pr \u2211 s\u2208S Pr(s)regM (g, s) ) = regM,P+(g).\nThus, fEg \u223cM g for all acts f, g and menus M containing fEg and g, which means that E is null.\nFor the second part, we first show that if P + (E) > 0, then for all f, h \u2208 M ,\nwe have that regMEh,P+(fEh) = P + (E)regM,P+|E(f).\n6Although we do not need this fact, it is worth noting that the MWER decision rule has the property that fEh MEh gEh for some act h iff fEh MEh gEh for all acts h. Thus, this property follows from Axioms 1\u201310.\nWe proceed as follows:\nregMEh,P+(fEh) = supPr\u2208P ( \u03b1Pr \u2211 s\u2208S Pr(s)regMEh(fEH, s) ) = supPr\u2208P ( \u03b1Pr Pr(E) \u2211 s\u2208E Pr(s | E)regM (f, s)\n+\u03b1Pr \u2211 s\u2208Ec Pr(s)reg{h}(h, s) )\n= supPr\u2208P ( \u03b1Pr Pr(E) \u2211 s\u2208E Pr(s|E)regM (s, f) ) = supPr\u2208P ( P + (E)\u03b1Pr,E \u2211 s\u2208E Pr(s|E)regM (f, s) )\n[since \u03b1Pr,E = sup{Pr\u2032\u2208P:Pr\u2032|E=Pr|E} \u03b1Pr\u2032 Pr\n\u2032(E)\nP + (E)\n]\n= P + (E) \u00b7 regM,P+|E(f).\nThus, for all h \u2208 M ,\nregMEh,P+(fEh) \u2264 regMEh,P+(gEh)\niff P + (E) \u00b7 regM,P+|E(f) \u2264 P + (E) \u00b7 regM,P+|E(g)\niff regM,P+|E(f) \u2264 regM,P+|E(g).\nIt follows that the order induced by P+ satisfies MDC. Moreover, if 1\u201310 and MDC hold, then for a weighted set P+ that represents\nM , we have f E,M g\niff for some h \u2208 M, fEh MEh gEh iff regM,P+|E(f) \u2264 regM,P+|E(g),\nas desired. Finally, the uniqueness of C(P+) follows from Theorem 1, which says that the family S,M of preferences is already sufficient to guarantee the uniqueness of C(P+).\nAnalogues of MDC have appeared in the literature before in the context of updating preference orders. In particular, Epstein and Schneider [4] discuss a menu-independent version of MDC, although they do not characterize updating in their framework. Sinischalchi [19] also uses an analogue of MDC in his axiomatization of measure-by-measure updating of MMEU. Like us, he starts with an axiomatization for unconditional preferences, and adds an axiom called constant-act dynamic consistency (CDC), somewhat analogous to MDC, to extend the axiomatization of MMEU to deal with conditional preferences."}, {"heading": "6 Dynamic Inconsistency", "text": "There is an important issue when one attempts to apply MWER with likelihood updating to dynamic decision problems. If you want to execute a plan, at every step you\u2019ll need to stick with that plan and execute the corresponding part of the plan. However, after following the initial steps of an ex-ante optimal plan,\na MWER agent may no longer wish to adhere to the plan. In such a situation, the agent is said to have dynamically inconsistent preferences. Dyanmic inconsistency is well known to hold for regret. Indeed, as Epstein and Le Breton [4] show, dynamic inconsistency arises for any non-Bayesian approach to decision making (i.e., any approach that does not involve maximizing expected utility) that satisfies certain minimal assumptions. Not surprisingly, it arises for MWER as well. In the rest of this section, we discuss the problem and some standard approaches to dealing with it, and illustrate some subtleties that arise in dealing with it in the context of MWER.\nTo understand the problem in the context of regret, consider the two-stage decision problem of having dinner, represented as a decision tree in Figure 1. Solid circles denote decision points, and empty circles denote points where nature reveals information to the agent. The decision tree also includes information about what states are considered possible at each node. The set of states considered possible at the root is always the entire state space, and nature\u2019s actions at each nature decision point partitions the set of possible states.\nFirst, you have to choose between a Chinese restaurant and an Italian restaurant. Once you have arrived at a particular restaurant, you cannot change your mind and go to another; so in the second stage you must order something from the menu at the chosen restaurant. Your utility is a combination of how much you enjoy the food, and whether you get an allergic reaction. Initially, you know that there are two possible states: you must be either allergic to MSG (state m) or to basil (state b), but not both. Assume that all Italian foods will have traces of basil, and Chinese stir-fry has MSG but plain rice does not. However, you do not enjoy eating plain rice, so the utility of ordering rice is 0.\nSuppose that you make decisions using the minimax regret decision rule, viewing a plan (i.e., a strategy) as an act. A straightforward computation\nshows that, ex ante, going to the Chinese restaurant and ordering plain rice has the lowest regret (5). However, if you go to the Chinese restaurant, the choice of going to the Italian restaurant is now irrelevant. If we now compute regret with respect to the menu of the two remaining choices, then the regret of ordering stir-fry is lower (2) than that of ordering rice (3). You thus end up ordering the stir-fry. The plan of going to the Chinese restaurant and ordering plain rice cannot be carried out.\nMore generally, dynamic consistency requires that the plan considered optimal ex ante continues to be considered optimal at any later time. As we said earlier, Epstein and Le Breton [4] show that dynamic inconsistency will arise for essentially all non-Bayesidan decision rules. A standard approach for dealing with this lack of dynamic consistency in the literature is to consider \u2018sophsticated\u2019 agents, who are aware of the potential for dynamic inconsistency, and thus use backward induction to determine the feasible plans. In the restaurant example, a sophisticated agent believes correctly that she will prefer stir-fry over rice, once she is at the Chinese restaurant. Therefore, she no longer considers going to the Chinese restaurant and ordering plain rice a viable plan. The only feasible options are going to the Italian restaurant, or having stir-fry at the Chinese restaurant.\nA subtlety arises when trying to apply backward induction to menu-dependent decision rules: which menu do we use when comparing the viable plans? For example, in the restaurant example, do we use the menu consisting of all three plans, or the menu consisting of just the viable plans. It turns out not to matter in this example\u2014with respect to both menus, going to the Italian restaurant minimizes regret. However, in general, the choice of menu can matter. Hayashi [9] uses the menu of viable plans in computing for minimax expected regret agents in optimal stopping problems, but it seems to us that both choices (and perhaps others) can be justified.\nA second subtlety that arises when considering sophisticated agents: What choice do they make when they are indifferent between two plans? Sinischalchi [19] axiomatizes consistent planning (with menu-independent preferences over plans), which augments backward induction with a tie-breaking assumption. This tie-breaking assumption in consistent planning allows an agent to commit to a plan as long as each stage of the plan is considered to be one of the best at each local decision node.\nIn order to axiomatize consistent planning, Siniscalchi must assume that the agent has preferences that are more general than preferences over plans. Rather, the agent must be assumed to have preferences over decision trees (such as that in Figure 1). Plans are the special case of decision trees with no branching at decision nodes; we can identify a decision tree with a set of plans (essentially, the branches in the decision tree). Sophistication is captured by an axiom that says, roughly, that the agent is indifferent between a decision tree and the same tree with a non-optimal (based on backward-induction) plan removed. Preferences over decision trees are similar in spirit to preferences over menus [11].\nIf we try to apply Siniscalchi\u2019s approach to regret, we encounter further difficulties. In a menu-independent setting, we can compare two decision trees\nby comparing the best plans in each decision tree (if we identify a decision tree with a set of plans). But once menus become relevant, we must decide what menu to use when making this comparison. It is not clear which menu to choose. What we really have here are menus over menus; it is not even clear how to apply regret in this setting. Defining and axiomatizing consistent planning in a regret-based setting remains an open problem."}, {"heading": "7 Conclusion", "text": "We proposed an alternative belief representation using weighted sets of probabilities, and described a natural approach to updating in such a situation and a natural approach to determining the weights. We also showed how weighted sets of probabilities can be combined with regret to obtain a decision rule, MWER, and provided an axiomatization that characterizes static and dynamic preferences induced by MWER.\nWe have considered preferences indexed by menus here. Stoye [21] used a different framework: choice functions. A choice function maps every finite set M of acts to a subset M \u2032 of M . Intuitively, the set M \u2032 consists of the \u2018best\u2019 acts in M . Thus, a choice function gives less information than a preference order; it gives only the top elements of the preference order. The motivation for working with choice functions is that an agent can reveal his most preferred acts by choosing them when the menu is offered. In a menu-independent setting, the agent can reveal his whole preference order; to decide if f \u227b g, it suffices to present the agent with a choice among {f, g}. However, with regret-based choices, the menu matters; the agent\u2019s most preferred choice(s) when presented with {f, g}might no longer be the most preferred choice(s) when presented with a larger menu. Thus, a whole preference order is arguably not meaningful with regret-based choices. Stoye [21] provides a representation theorem for MER where the axioms are described in terms of choice functions. The axioms that we have attributed to Stoye are actually the menu-based analogue of his axioms. We believe that it should be possible to provide a characterization of MWER using choice functions, although we have not yet proved this.\nFinally, we briefly considered the issue of dynamic consistency and consistent planning. As we showed, making this precise in the context of regret involves a number of subtleties. We hope to return to this issue in future work."}, {"heading": "A Proof of Theorem 1", "text": "We show here that if a family of menu-dependent preferences M satisfies axioms 1-10, then M can be represented as minimizing expected regret with respect to a set of weighted probabilities and a utility function. Since the proof is somewhat lengthy and complicated, we split it into several steps, each in a separate subsection.\nA.1 Simplifying the Problem\nOur proof starts in much the same way as the proof by Stoye [21] of a representation theorem for regret. Lemma 1 guarantees the existence of a utility function U on prizes that can be extended to lotteries in the obvious way, so that l\u2217 (l\u2032)\u2217 iff U(l) \u2265 U(l\u2032). In other words, preferences over all constant acts are represented by the maximization of U on the corresponding lotteries that the constant acts map to. Lemma 1 is a consequence of standard results. Our menus are arbitrary sets of acts, as opposed to convex hulls of a finite number of acts in [21]; Lemma 3 shows that Stoye\u2019s technique can be adapted to work when menus are arbitrary sets of acts. Finally, following Stoye [21], we reduce the proof of existence of a minimax weighted regret representation for the family M to the proof of existence of a minimax weighted regret representation for a single menu-independent preference ordering (Lemma 4).\nLemma 1. If Axioms 1-3, 5, 7, and 8 hold, then there exists a nonconstant function U : X \u2192 R, unique up to positive affine transformations, such that for all constant acts l\u2217 and (l\u2032)\u2217 and menus M ,\nl\u2217 M (l \u2032)\u2217 \u21d4\n\u2211\n{y: l\u2217(y)>0}\nl(y)U(y) \u2265 \u2211\n{y: l\u2032(y)>0}\nl\u2032(y)U(y).\nProof. By menu independence for constant acts, the family of preferences M all agree when restricted to constant acts. The lemma then follows from standard results (see, e.g., [12]), since menu-independence for constant acts, combined with independence, gives the standard independence (substitution) axiom from expected utility theory.\nAs is commonly done, given U , we define u(l) = \u2211\n{y: l(y)>0} l(y)U(y). Thus,\nu(l) is the expected utility of lottery l. We extend u to contsant acts by taking u(l\u2217) = u(l). Thus, Lemma 1 says that, for all menus M , l\u2217 (l\u2032)\u2217 iff u(l\u2217) \u2265 u(l\u2032). If c is the utility of some lottery, let l\u2217c be a constant lottery that u(l \u2217 c) = c. The following is now immediate. We state it as a lemma so that we can refer to it later.\nLemma 2. u(l\u2217c ) \u2265 u(l \u2217 c\u2032) iff l \u2217 c l \u2217 c\u2032 ; similarly, u(l \u2217 c ) = u(l \u2217 c\u2032) iff l \u2217 c \u223c l \u2217 c\u2032 , and u(l\u2217c) > u(l \u2217 c\u2032) iff l \u2217 c \u227b l \u2217 c\u2032 .\nThe key step in showing that we can reduce to a single menu is to show that, roughly speaking, for each menu, there exists a menu-dependent function gM such that u(gM (s)) = \u2212 supf\u2208M u(f(s)). Stoye [21] proved a similar result, but he assumed that all menus were obtained by taking the convex hull of a finite set of acts. Because we allow arbitrary bounded menus, this result is not quite true for us. For example, suppose that the range of u is (\u22121,\u221e]. Then there may be a menu M such that supf\u2208M u(f(s)) = 5, so \u2212 supf\u2208M u(f(s)) = \u22125. But there is no act g such that u(g(s)) = \u22125, since u is bounded below by \u22121. The following weakening of this result suffices for our purpose.\nLemma 3. There exists a utility function U such that for every menu M , there exists \u01eb \u2208 (0, 1] and constant act l\u2217 such that for all f, g \u2208 M , f M g \u21d4 t(f) t(M) t(g), where t has the form t(f) = \u01ebf + (1 \u2212 \u01eb)l\n\u2217 and t(M) = {t(f) : f \u2208 M}. Moreover, there exists an act gt(M) such that u(gt(M)(s)) = \u2212 supf\u2208t(M) u(f(s)) for all s \u2208 S.\nProof. The nontriviality and monotonicity axioms imply there must exist prizes x and y such that U(x) > U(y). We consider four cases.\nCase 1: The range of U is bounded above and below. Then we can rescale so that the range of U is [\u22121, 1]. Thus, there must be prizes x and y such that U(x) = 1 and U(y) = \u22121. For all c \u2208 [\u22121, 1], there must be a prize x\u2032 that is a convex combination of x and y such that u(x\u2032) = c, so we can clearly define a function gM such that, for all s \u2208 S, we have u(gM (s)) = \u2212 supf\u2208M u(f(s)). Furthermore, we know that such a gM exists because it can be formed as an act which maps each state to an appropriate lottery over the prizes x and y. More generally, we know that an act with a certain utility profile exists if its utility for each state is within the range of U . This fact will be used in the other cases as well.\nThus, in this case we can take t to be the identity (i.e., \u01eb = 1). Case 2: The range of U is (\u2212\u221e,\u221e). Again, for all c \u2208 (\u221e,\u221e), there must exist a prize x such that u(x) = c. Since menus are assumed to be bounded above, we can again define the required function g and take \u01eb = 1.\nCase 3: The range of U is bounded above and unbounded below. Then we can assume without loss of generality that the range is (\u2212\u221e, 1], and for all c in the range, there is a prize x such that u(x) = c. For all menus M , \u01eb > 0, and acts f, g \u2208 M , by Independence, we have that\nf M g \u21d4 \u01ebf + (1\u2212 \u01eb)l \u2217 1 \u01ebM+(1\u2212\u01eb)l\u22171 \u01ebg + (1\u2212 \u01eb)l \u2217 1.\nThere exists an \u01eb > 0 such that for all s \u2208 S,\n1 \u2265 sup f\u2208M \u01ebu(f(s)) + (1\u2212 \u01eb) \u2265 \u22121.\nLet t(f) = \u01ebf+(1\u2212\u01eb)l\u22171. Clearly there exists an act gt(M) such that u(gt(M)(s)) = \u2212 supf\u2208t(M) u(f(s)) for all s \u2208 S.\nCase 4: The range of U is bounded below and unbounded above. By the upper-boundedness axiom, every menu has an upper bound on its utility range. Therefore, for every menuM , \u01eb > 0, and all acts f and g inM , by Independence,\nf M g \u21d4 \u01ebf + (1\u2212 \u01eb)l \u2217 \u22121 \u01ebM+(1\u2212\u01eb)l\u2217 \u22121 \u01ebg + (1 \u2212 \u01eb)l\u2217\u22121.\nThere exists \u01eb > 0 such that for all s \u2208 S,\nsup f\u2208M\n\u01ebu(f(s)) + (1\u2212 \u01eb)u(l\u2217\u22121(s)) \u2264 1.\nLet t(f) = \u01ebf + (1\u2212 \u01eb)l\u2217\u22121. Again, it is easy to see that gt(M) exists.\nIn light of Lemma 3, we henceforth assume that the utility function u derived from U is such that its range is either (\u2212\u221e,\u221e), [\u2212, 1, 1], (\u2212\u221e, 1], or [\u22121,\u221e). In any case, its range always includes [\u22121, 1].\nBefore proving the key lemma, we establish some useful notation for acts and utility acts. Given a utility act b, let fb, the act corresponding to b, be the act such that fb(s) = lb(s), if such an act exists. Conversely, let bf , the utility act corresponding to the act f , be defined by taking bf (s) = u(f(s)). Note that monotonicity implies that if fb = gb, then f \u223cM g for all menus M . That is, only utility acts matter. If c is a real, we take c\u2217 to be the constant utility act such that c\u2217(s) = c for all s \u2208 S.\nLemma 4. Let M\u2217 be the menu consisting of all acts f such that (\u22121)\u2217 \u2264 bf \u2264 0\u2217. Then (U,P+) represents M\u2217 (i.e., M\u2217= S,X,U M\u2217,P+) iff (U,P\n+) represents M for all menus M .\nProof. Our arguments are similar in spirit to those of Stoye [21]. By Lemma 3, there exists t such that t(f) = \u01ebf + (1 \u2212 \u01eb)h for a constant function h such that\nf M g iff t(f) t(M) t(g);\nmoreover, for this choice of t, the act gt(M) defined in Lemma 3 exists. By Independence,\nt(f) t(M) t(g) iff 1\n2 t(f) +\n1 2 gt(M) 1 2 t(M)+ 1 2 gt(M) 1 2 t(g) + 1 2 gt(M).\nLet M\u2217 be the menu that contains all acts with utilities in [\u22121, 0]. By INA, we know that for all acts f and g, and menus M for which gM is defined, we have\nf M g iff 1\n2 f +\n1 2 gM M\u2217 1 2 g + 1 2 gM .\nThis is because acts of the form 12f+ 1 2gM are never strictly optimal with respect to the menu 12M + 1 2gM . At every state there must be some act in 1 2M + 1 2gM that has utility 0 (namely, the mixture that involves the act argmaxf\u2208M u(f(s)). Thus,\nf M g iff 1\n2 t(f) +\n1 2 gt(M) M\u2217 1 2 t(g) + 1 2 gt(M).\nSince the MWER representation also satisfies Independence and INA, we know that for all menus M , and acts f and g in M ,\nf S,X,UM,P+ g \u21d4 t(f) S,X,U t(M),P+ t(g) \u21d4\n1 2 t(f) + 1 2 gt(M) S,X,U M\u2217,P+ 1 2 t(g) + 1 2 gt(M).\nTherefore, to show that M has a MWER representation with respect to (U,P+), it suffices to show that M\u2217 has a MWER representation with respect to (U,P+).\nIn the sequel, we drop the menu subscript when we refer to the family of preferences, and just write (to denote M\u2217); by Lemma 4, it suffices to consider M\u2217 .\nA.2 Defining a functional on utility acts\nAs we said, Stoye [20] also started his proof of a representation theorem for MER by reducing to a single preference order M\u2217 . He then noted that, the expected regret of an act f with respect to a probability Pr and menu M\u2217 is just the negative of the expected utility of f . Thus, the worst-case expected regret of f with respect to a set P of probability measures is the negative of the worstcase expected utility of f with respect to P . Thus, it sufficed for Stoye to show that M\u2217 had an MMEU representation, which he did by showing that M\u2217 satisfied Gilboa and Schmeidler\u2019s [6] axioms for MMEU, and then appealing to their representation theorem.\nThis argument does not quite work for us, because now M\u2217 does not satisfy the C-independence axiom. (This is because our preference order M\u2217 is based on weighted regret, not regret.) However, we can get a representation theorem for weighted regret by using some of the techniques used by Gilboa and Schmeidler to get a representation theorem for MMEU, appropriately modified to deal with lack of C-independence. Specifically, like Gilboa and Schmeidler, we define a functional I on utility acts such that the preference order on utility acts is determined by their value according to I (see Lemma 6). Using I, we can then determine the weight of each probability in \u2206(S), and prove the desired representation theorem.\nRecall that u represents on constant acts, and that only utility acts matter to . The space of all utility acts is the Banach space B of real-valued functions on S. Let B\u2212 be the set of nonpositive functions in B, where the function b is nonpositive if b(s) \u2264 0 for all s \u2208 S.\nWe now define a functional I on utility acts in B\u2212 such that for all f, g with bf , bg \u2208 B \u2212, we have I(bf ) \u2265 I(bg) iff f g. Let\nRf = {\u03b1 \u2032 : l\u2217\u03b1\u2032 f}.\nIf 0\u2217 \u2265 b \u2265 (\u22121)\u2217, then fb exists, and we define\nI(b) = inf(Rfb).\nFor the remaining b \u2208 B\u2212, we extend I by homogeneity. Let ||b|| = |mins\u2208S b(s)|. Note that if b \u2208 B\u2212, then 0\u2217 \u2265 b/||b|| \u2265 (\u22121)\u2217, so we define\nI(b) = ||b||I(b/||b||).\nLemma 5. If bf \u2208 B \u2212, then f \u223c l\u2217I(bf ).\nProof. Suppose that bf \u2208 B \u2212 and, by way of contradiction, that l\u2217I(bf ) \u227a f . If f \u223c l\u22170 , then it must be the case that I(bf ) = 0, since I(bf ) \u2264 0 by definition of inf, and f \u223c l\u22170 \u227b l \u2217 \u01eb for all \u01eb < 0 by Lemma 2, so I(bf ) > \u01eb for all \u01eb < 0. Therefore, f \u223c l\u2217I(bf ). Otherwise, since bf \u2208 B \u2212, by monotonicity, we must have l\u22170 \u227b f , and thus l \u2217 0 \u227b f \u227b l \u2217 I(bf ) . By mixture continuity, there is some q \u2208 (0, 1) such that q \u00b7 l\u22170 +(1\u2212 q) \u00b7 l \u2217 I(bf) \u223c l(1\u2212q)I(bf ) \u227a f , contradicting the fact that I(b) is the greatest lower bound of Rf .\nIf, on the other hand, l\u2217I(bf ) \u227b f , then l \u2217 I(bf ) \u227b f l\u2217c for some c \u2208 R. If\nf \u223c l\u2217c then it must be the case that I(bf ) = c. I(bf ) \u2264 c since l \u2217 c l \u2217 c , and I(bf ) \u2265 c since for all c \u2032 < c, l\u2217c\u2032 \u227a f \u223c l \u2217 c .\nOtherwise, l\u2217I(bf ) \u227b f \u227b l \u2217 c , and by mixture continuity, there is some q \u2208 (0, 1) such that q \u00b7l\u2217I(bf )+(1\u2212q)l \u2217 c \u227b f . Since qI(bf )+(1\u2212q)c < I(bf ), this contradicts the fact that I(bf ) is a lower bound of Rf . Therefore, it must be the case that l\u2217I(bf ) \u223c f .\nWe can now show that I has the required property.\nLemma 6. For all acts f, g such that bf , bg \u2208 B \u2212, f g iff I(bf ) \u2265 I(bg).\nProof. Suppose that bf , bg \u2208 B \u2212. By Lemma 5, l\u2217I(bf ) \u223c f and g \u223c l \u2217 I(bg) . Thus, f g iff l\u2217I(bf ) l \u2217 I(bg) , and by Lemma 2, l\u2217I(bf ) l \u2217 I(bg) iff I(bf ) \u2265 I(bg).\nIn order to invoke a standard separation result for Banach spaces, we extend the definition of I to the Banach space B. We extend I to B by taking I(b) = I(b\u2212) for b \u2208 B \u2212 B\u2212, where for all b \u2208 B, b\u2212 is defined as\nb\u2212(s) =\n{\nb(s), if b(s) \u2264 0,\n0, if b(s) > 0.\nClearly b\u2212 \u2208 B\u2212 and b = b\u2212 if b \u2208 B\u2212. We show that the axioms guarantee that I has a number of standard properties. Since we have artificially extended I to B, our arguments require more cases than those in [6]. (We remark that such an \u201cartificial\u201d extension seem unavoidable in our setting.) Moreover, we must work harder to get the result that we want. We need different arguments from that for MMEU [6], since the preference order induced by MMEU satisfies C-independence, while our preference order does not.\nLemma 7. (a) If c \u2264 0, then I(c\u2217) = c.\n(b) I satisfies positive homogeneity: if b \u2208 B and c > 0, then I(cb) = cI(b).\n(c) I is monotonic: if b, b\u2032 \u2208 B and b \u2265 b\u2032, then I(b) \u2265 I(b\u2032).\n(d) I is continuous: if b, b1, b2, . . . \u2208 B, and bn \u2192 b, then I(bn) \u2192 I(b).\n(e) I is superadditive: if b, b\u2032 \u2208 B, then I(b+ b\u2032) \u2265 I(b) + I(b\u2032).\nProof. For part (a), If c is in the range of u, then it is immediate from the defintion of I and Lemma 2 that I(c\u2217) = c. If c is not in the range of u, then since [\u22121, 0] is a subset of the range of u, we must have c < \u22121, and by definition of I, we have I(c\u2217) = |c|I(c\u2217/|c|) = c.\nFor part (b), first suppose that ||b|| \u2264 1 and b \u2208 B\u2212 (i.e., 0\u2217 \u2265 b \u2265 (\u22121)\u2217). Then there exists an act f such that bf = b. By Lemma 5, f \u223c l \u2217 I(b). We now need to consider the case that c \u2264 1 and c > 1 separately. If c \u2264 1, by\nIndependence, cfb+(1\u2212c)l \u2217 0 \u223c cl \u2217 I(b)+(1\u2212c)l \u2217 0 . By Lemma 6, I(bcfb+(1\u2212c)l\u22170 ) = I(bcl\u2217 I(b) +(1\u2212c)l\u22170 ). It is easy to check that bcfb+(1\u2212c)l\u22170 = cb, and bcl\u2217I(b) + (1 \u2212 c)l\u22170 = cI(b) \u2217. Thus, I(cb) = I(cI(b)\u2217). By part (a), I(cI(b)\u2217) = cI(b). Thus, I(cb) = cI(b), as desired. If c > 1, there are two subcases. If ||cb|| \u2264 1, since 1/c < 1, by what we have just shown I(b) = I(1c (cb)) = 1 c I(cb). Crossmultiplying, we have that I(cb) = cI(b), as desired. And if ||cb|| > 1, by definition, I(cb) = ||cb||I(bc/||cb||) = c||b||I(b/||b||) (since bc/||cb|| = b/||b||). Since ||b|| \u2264 1, by what we have shows I(b) = I(||b||(b/||b||) = ||b||I(b/||b||), so I(b/||b||) = 1||b||I(b). Again, it follows that I(cb) = cI(b). Now suppose that ||b|| > 1. Then I(b) = ||b||I(b/||b||). Again, we have two subcases. If ||cb|| > 1, then\nI(cb) = ||cb||I(cb/||cb||) = c||b||I(b/||b||) = cI(b).\nAnd if ||cb|| \u2264 1, by what we have shown for the case ||b|| \u2264 1,\nI(b) = I( 1\nc (cb)) =\n1 c I(cb),\nso again I(cb) = cI(b). For part (c), first note that if b, b\u2032 \u2208 B\u2212. If ||b|| \u2264 1 and |b\u2032|| \u2264 \u22121, then the acts fb and fb\u2032 exist. Moreover, since b \u2265 b \u2032, we must have (fb(s)) \u2217 (fb\u2032) \u2217(s) for all states s \u2208 S. Thus, by Monotocity, fb fb\u2032 . If either ||b|| > 1 or ||b\u2032|| > 1, let n = max(||b||, ||b\u2032||). Then ||b/n|| \u2264 1 and ||b\u2032/n|| \u2264 1. Thus, I(b/n) \u2265 I(b\u2032/n), by what we have just shown. By part (b), I(b) \u2265 I(b\u2032). Finally, if either b \u2208 B\u2212B\u2212 or b\u2032 \u2208 B\u2212B\u2212, note that if b \u2265 b\u2032, then b\u2212 \u2265 (b\u2032)\u2212. By definition, I(b) = I(b\u2212) and I(b\u2032) = I(b\u2032)\u2212; moreover, b\u2212, (b\u2032)\u2212 \u2208 B\u2212. Thus, by the argument above, I(b) \u2265 I(b\u2212).\nFor part (d), note that if bn \u2192 b, then for all k, there exists nk such that bn \u2212 (1/k) \u2217 \u2264 bn \u2264 bn + (1/k) \u2217 for all n \u2265 nk. Moreover, by the monotonicity of I (part (c)), we have that I(b \u2212 (1/k)\u2217) \u2264 I(bn) \u2264 I(b + (1/k) \u2217). Thus, it suffices to show that I(b\u2212 (1/k)\u2217) \u2192 I(b) and that I(b+ (1/k)\u2217) \u2192 I(b). To show that I(b \u2212 (1/k)\u2217) \u2192 I(b), we must show that for all \u01eb > 0, there exists k such that I(b \u2212 (1/k)\u2217) \u2265 I(b) \u2212 \u01eb. By positive homogeneity (part (b)), we can assume without loss of generality that ||b \u2212 (1/2)\u2217|| \u2264 1 and that ||b|| \u2264 1. Fix \u01eb > 0. If I(b \u2212 (1/2)\u2217) \u2265 I(b) \u2212 \u01eb, then we are done. If not, then I(b) > I(b) \u2212 \u01eb > I(b \u2212 (1/2)\u2217). Since ||b|| \u2264 1 and ||b \u2212 (1/2)\u2217|| \u2264 1, fb and fb\u2212(1/2)\u2217 exist. Moreover, by Lemma 6, fb \u227b f(I(b)\u2212\u01eb)\u2217 \u227b fb\u2212(1/2)\u2217 . By mixture continuity, for some p \u2208 (0, 1), we have pfb + (1\u2212 p)f(b\u2212(1/2)\u2217 \u227b f(I(b)\u2212\u01eb)\u2217 . It is easy to check that bpfb+(1\u2212p)fb\u2212(1/2)\u2217 = b \u2212 (1 \u2212 p)(1/2)\n\u2217. Thus, by Lemma 6, fb\u2212(1\u2212p)(1/2)\u2217 f(I(b)\u2212\u01eb)\u2217 , and I(b \u2212 (1 \u2212 p)1/2)\n\u2217) > I(b) \u2212 \u01eb. Choose k such that 1/k < (1 \u2212 p)(1/2). Then I(b \u2212 (1/k)\u2217) \u2265 I(b \u2212 (1 \u2212 p)1/2)\u2217) > I(b) \u2212 \u01eb, as desired.\nThe argument that I(b + (1/k)\u2217) \u2192 I(b) is similar and left to the reader. For part (e), first suppose that b, b\u2032 \u2208 B\u2212. If ||b||, ||b\u2212|| \u2264 1, and I(b), I(b\u2032) 6=\n0, consider bI(b) and b\u2032 I(b\u2032) . Since I( b I(b) ) = I( b\u2032 I(b\u2032) ) = 1, it follows from Lemma 5\nthat f b I(b) \u223c f b\u2032 I(b\u2032) . By Ambiguity Aversion, for all p \u2208 (0, 1], pf b I(b) + (1 \u2212\np)f b\u2032 I(b\u2032) f b I(b)\n. Thus, I( I(b)I(b)+I(b\u2032) b I(b) + I(b\u2032) I(b)+I(b\u2032) b\u2032 I(b\u2032) ) \u2265 I( b I(b) ) = I( b\u2032 I(b\u2032)) = 1.\nHence, I(b+ b\u2032) \u2265 I(b) + I(b\u2032). If b, b\u2212 \u2208 B\u2212 and either ||b|| > 1 or ||b\u2032|| > 1, and both I(b) 6= 0 and I(b\u2032) 6= 0, then the result easily follows by positive homogeneity (property (b)). If b, b\u2212 \u2208 B\u2212 and either I(b) = 0 or I(b\u2032) = 0, let bn = b\u2212 1 n \u2217 and b\u2032n = b \u2032\u2212 1n \u2217 . Clearly ||bn|| > 0, ||b \u2032 n|| > 0, bn \u2192 b, and b \u2032 n \u2192 b \u2032 n. By our argument above, I(bn+ b \u2032 n) \u2265 I(bn)+ I(b \u2032 n) for all n \u2265 1. The result now follows from continuity.\nFinally, if either b \u2208 B \u2212 B\u2212 or b\u2032 \u2208 B \u2212 B\u2212, observe that\n(b+ b\u2032)\u2212(s)\n\n   \n   \n= b\u2212(s) + b\u2032\u2212(s), if b(s) \u2264 0, b\u2032(s) \u2264 0 = b\u2212(s) + b\u2032\u2212(s), if b(s) \u2265 0, b\u2032(s) \u2265 0 \u2265 b\u2212(s) + b\u2032\u2212(s), if b(s) > 0, b\u2032(s) \u2264 0 \u2265 b\u2212(s) + b\u2032\u2212(s), if b(s) \u2264 0, b\u2032(s) > 0.\nTherefore, (b+ b\u2032)\u2212 \u2265 b\u2212 + b\u2032\u2212. Thus, I(b+ b\u2032) = I((b+ b\u2032)\u2212) \u2265 I(b\u2212 + b\u2032\u2212) by the monotonicity of I, and I(b\u2212 + b\u2032\u2212) \u2265 I(b\u2212) + I(b\u2032\u2212) by superadditivity of I on B\u2212. Therefore, I(b+ b\u2032) \u2265 I(b) + I(b\u2032).\nA.3 Defining the weights\nIn this section, we use I to define a weight \u03b1Pr for each probability Pr \u2208 \u2206(S). The heart of the proof involves showing that the resulting set P+ so determined gives us the desired representation.\nGiven a set P+ of weighted probability measures, for b \u2208 B\u2212, define\nNWREG(b) = inf Pr\u2208P\n\u03b1Pr( \u2211\ns\u2208S\nb(s) Pr(s)).\nNote that NWREG is the negative of the weighted regret when the menu is B\u2212. Define\nNREG(b) = inf Pr\u2208P\n\u2211\ns\u2208S\nb(s) Pr(s).\nand NREGPr(b) = \u2211\ns\u2208S\nb(s) Pr(s) = EPrb.\nFor each probability Pr \u2208 \u2206(S), define\n\u03b1Pr = sup{\u03b1 \u2208 R : \u03b1NREGPr(b) \u2265 I(b) for all b \u2208 B \u2212}. (1)\nNote that \u03b1Pr \u2265 0 for all distributions Pr \u2208 \u2206(S), since 0 \u2265 I(b) for b \u2208 B \u2212 (by monotonicity); and \u03b1Pr \u2264 1, since NREGPr((\u22121) \u2217) = I((\u22121)\u2217) = \u22121 for all distributions Pr. Thus, \u03b1Pr \u2208 [0, 1]. Moreover, it is immediate from the definition of \u03b1Pr that \u03b1PrNREGPr(b) \u2265 I(b) for all b \u2208 B\n\u2212. The next lemma shows that there exists a probability Pr where we have equality.\nLemma 8. (a) For some distribution Pr, we have \u03b1Pr = 1.\n(b) For all b \u2208 B\u2212, there exists Pr such that \u03b1PrNREGPr(b) = I(b).\nProof. The proofs of both part (a) and (b) use a standard separation result: If U is an open convex subset of B, and b /\u2208 U , then there is a linear functional \u03bb that separates U from b, that is, \u03bb(b\u2032) > \u03bb(b) for all b\u2032 \u2208 U . We proceed as follows\nFor part (a), we must show that for some Pr, for all b \u2208 B\u2212, NREGPr(b) \u2265 I(b). Since NREGPr(b) = EPrb, it suffices to show that EPr(b) \u2265 I(b) for all b \u2208 B\u2212.\nLet U = {b\u2032 \u2208 B : I(b\u2032) > \u22121}. U is open (by continuity of I), and convex (by positive homogeneity and superadditivity of I), and (\u22121)\u2217 /\u2208 U . Thus, there exists a linear functional \u03bb such that \u03bb(b\u2032) > \u03bb((\u22121)\u2217) for b\u2032 \u2208 U .\nWe want to show that \u03bb is a positive linear functional, that is, that \u03bb(b) \u2265 0 if b \u2265 0\u2217. Since 0\u2217 \u2208 U , and \u03bb(0\u2217) = 0, it follows that \u03bb((\u22121)\u2217) < 0. Since \u03bb is linear, we can assume without loss of generality that \u03bb((\u22121)\u2217) = \u22121. Thus, for all b\u2032 \u2208 B\u2212, I(b\u2032) > \u22121 implies \u03bb(b\u2032) > \u22121. (The fact that I(cb\u2032) = I(0\u2217) follows from the definition of I on elements in B\u2212B\u2212.) Suppose that c > 0 and b\u2032 \u2265 0\u2217. From the definition of I, it follows that I(cb\u2032) = I(0\u2217) = 0 > \u22121. So c\u03bb(b\u2032) = \u03bb(cb\u2032) > \u22121, so \u03bb(b\u2032) > \u22121/c. Since this is true for all c > 0, it must be the case that \u03bb(b\u2032) \u2265 0. Thus, \u03bb is a positive functional.\nDefine the probability distribution Pr on S by taking Pr(s) = \u03bb(1s). To see that Pr is indeed a probability distribution, note that since 1s \u2265 0 and \u03bb is positive, we must have \u03bb(1s) \u2265 0. Moreover, \u2211 s\u2208S Pr(s) = \u03bb(1 \u2217) = 1. In addition, for all b\u2032 \u2208 B, we have\n\u03bb(b\u2032) = \u2211\ns\u2208S\n\u03bb(1s)b \u2032(s) =\n\u2211\ns\u2208S\nPr(s)b\u2032(s) = EPr(b \u2032).\nNext note that, for b \u2208 B\u2212,\nfor all c < 0, if I(b) > c, then \u03bb(b) > c. (2)\nFor if I(b) > c, then I(b/|c|) > \u22121 by positive homogeneity, so \u03bb(b/|c|) > \u22121 and \u03bb(b) > c. The result now follows. For if b \u2208 B\u2212, then I(b) \u2264 I(0\u2217) = 0 by monotonicity. Thus, if c < I(b), then c < 0, so, by (2), \u03bb(b) > c. Since \u03bb(b) > c whenever I(b) > c, it follows that EPr(b) = \u03bb(b) \u2265 I(b), as desired.\nThe proof of part (b) is similar to that of part (a). We want to show that, given b \u2208 B\u2212, there exists Pr such that \u03b1PrNREGPr(b) = I(b). First supose that ||b|| \u2264 1. If I(b) = 0, then there must exist some s such that b(s) = 0, for otherwise there exists c < 0 such that b \u2264 c\u2217, so I(b) \u2264 c. If b(s) = 0, let Prs be such that Prs(s) = 1. Then NREGPrs(b) = 0, so (b) holds in this case.\nIf ||b|| \u2264 1 and I(b) < 0, let U = {b\u2032 : I(b\u2032) > I(b)}. Again, U is open and convex, and b /\u2208 U , so there exists a linear functional \u03bb such that \u03bb(b\u2032) > \u03bb(b) for b\u2032 \u2208 U . Since 0\u2217 \u2208 U and \u03bb(0\u2217) = 0, we must have \u03bb(b) < 0. Since (\u22121)\u2217 \u2264 b, (\u22121)\u2217 is not in U , and therefore we also have \u03bb((\u22121)\u2217) < 0. Thus, we can\nassume without loss of generality that \u03bb((\u22121)\u2217) = \u22121, and hence \u03bb((1)\u2217) = 1. The same argument as above shows that \u03bb is positive: for all c > 0 and b\u2032 \u2265 0\u2217, I(cb\u2032) = 0 as before. Since I(b) < 0, it follows that I(cb\u2032) > I(b), so cb\u2032 \u2208 U and \u03bb(cb\u2032) > \u03bb(b) \u2265 \u03bb((\u22121)\u2217) = \u22121. Thus, as before, for all c > 0, b\u2032 \u2265 0\u2217, \u03bb(b\u2032) > \u22121c , so \u03bb is a positive functional.\nTherefore, \u03bb determines a probability distribution Pr such that, for all b\u2032 \u2208 B\u2212, we have \u03bb(b\u2032) = EPr(b\n\u2032). This, of course, will turn out to be the desired distribution. To show this, we need to show that \u03b1Pr = I(b)/NREGPr(b). Clearly \u03b1Pr \u2264 I(b)/NREGPr(b), since if \u03b1 > I(b)/NREGPr(b), then \u03b1NREGPr(b) < I(b) (since NREGPr(b) = \u03bb(b) < 0). To show that \u03b1Pr \u2265 I(b)/NREGPrb, we must show that (I(b)/NREGPr(b))NREGPr(b\n\u2032) \u2265 I(b\u2032) for all b\u2032 \u2208 B\u2212. Equivalently, we must show that I(b)\u03bb(b\u2032)/\u03bb(b) \u2265 I(b\u2032) for all b\u2032 \u2208 B\u2212.\nEssentially the same argument used to prove (2) also shows\nfor all c > 0, if I(b\u2032) > cI(b), then \u03bb(b\u2032) > c\u03bb(b).\nIn particular, if I(b\u2032) > cI(b), then by positive homogeneity, I(b \u2032)\nc > I(b), so b\u2032\nc \u2208 U , and \u03bb( b\u2032 c ) > \u03bb(b) and hence \u03bb(b \u2032) > c\u03bb(b).\nThus, if I(b\u2032)/(\u2212I(b)) > c and c < 0, then I(b\u2032) > \u2212cI(b), and hence \u03bb(b\u2032)/(\u2212\u03bb(b)) > c. It follows that \u03bb(b\u2032)/(\u2212\u03bb(b)) \u2265 I(b\u2032)/(\u2212I(b)) for all b\u2032 \u2208 B\u2212. Thus, I(b)\u03bb(b\u2032)/\u03bb(b) \u2265 I(b\u2032) for all b\u2032 \u2208 B\u2212, as required.\nFinally, if ||b|| > 1, let b\u2032 = b/||b||. By the argument above, there exists a probability measure Pr such that \u03b1PrNREGPr(b/||b||) = I(b/||b||). Since NREGPr(b/||b||) = NREGPr(b)/||b||, and I(b/||b||) = I(b)/||b||, we must have that \u03b1PrNREGPr(b) = I(b).\nWe can now complete the proof of Theorem 1. By Lemma 8 and the definition of \u03b1Pr, for all b \u2208 B \u2212,\nI(b) = inf Pr\u2208\u2206(S) \u03b1PrNREG(b) (3)\n= inf Pr\u2208\u2206(S)\n(\n\u03b1Pr \u2211\ns\u2208S\nb(s) Pr(s)\n)\n= sup Pr\u2208P\n(\n\u2212\u03b1Pr \u2211\ns\u2208S\nb(s) Pr(s)\n)\n.\nRecall that, by Lemma 6, for all acts f, g such that bf , bg \u2208 B \u2212, f g iff I(bf ) \u2265 I(bg). Thus, f g iff\nsup Pr\u2208\u2206(S)\n(\n\u2212\u03b1Pr \u2211\ns\u2208S\nu(f(s)) Pr(s)\n)\n\u2264 sup Pr\u2208\u2206(S)\n(\n\u2212\u03b1Pr \u2211\ns\u2208S\nu(g(s)) Pr(s)\n)\n.\nNote that, for f \u2208 M\u2217 = B\u2212, we have regM\u2217,Pr(f) = sup(\u2212u(f(s)) Pr(s), since 0\u2217 dominates all acts in M\u2217. Thus, = S,Y,UM\u2217,P+ , where P + = {(Pr, \u03b1Pr : Pr \u2208\n\u2206(S)}. By Lemma 4, this means (U,P+) represents M for all menus M , as required.\nWe have already observed that U is unique up to affine transformations, so it remains to show that P+ is maximal. This follows from the definition of \u03b1Pr. If M= S,Y,U M,(P\u2032)+ , and (\u03b1 \u2032,Pr) \u2208 (P \u2032)+, then we claim that \u03b1\u2032 \u2208 {\u03b1 \u2208 R : \u03b1NREGPr(b) \u2265 I(b) for all b \u2208 B \u2212}. If not, there would be some b \u2208 B\u2212 with ||b|| \u2264 12 , such that \u03b1 \u2032NREGPr(b) < I(b), which, by the definition of \u227aS,Y,UM\u2217,(P\u2032)\u2217 , means that l \u2217 \u22121 \u227a S,Y,U M\u2217,(P\u2032)+ fb \u227a S,Y,U M\u2217,(P\u2032)+ l \u2217 I(b). Recall that I(bf ) = inf{\u03b3 : l \u2217 \u03b3 M\u2217 f}. Moreover, since \u227a S,Y,U M\u2217,(P\u2032)+ satisfies the Mixture Continuity, there exists some p \u2208 (0, 1) such that fb \u227a S,Y,U M\u2217,(P\u2032)+ pl\u2217\u22121 + (1 \u2212 p)l \u2217 I(b) \u227a S,Y,U M\u2217,(P\u2032)+\u227a S,Y,U M\u2217,(P\u2032)+ l \u2217 I(b). This contradicts the definition of I(b). Therefore, \u03b1\u2032 \u2208 {\u03b1 \u2208 R : \u03b1NREGPr(b) \u2265 I(b) for all b \u2208 B \u2212}, and hence \u03b1\u2032 \u2264 \u03b1Pr.\nA.4 Uniqueness of Representation\nIn the preceding sections, we have shown that if a family of menu-dependent preferences M satisfies axioms 1 \u2212 10, then M can be represented as minimizing weighted expected regret with respect to a canonical set P+ of weighted probabilities and a utility function. We now want to show uniqueness.\nIn this section, we show that the canonical set of weighted probabilities we constructed, when viewed as a set of subnormal probability measures, is regular and includes at least one proper probability measure. Moreover, this set of sub-probability measures is the only regular set that induces a family of preferences M that satisfies axioms 1 \u2212 10. Our uniqueness result is analogous to the uniqueness results of Gilboa and Schmeidler [7], who show that the convex, closed, and non-empty set of probability measures in their representation theorem for MMEU is unique.\nBy Lemma 4, it suffices to consider the preference relation M\u2217 . The argument is based on two lemmas: the first lemma says that the canonical set of sub-probability measures is regular; and the second lemma says that a set of subprobability measures representing M\u2217 that is regular and contains at least one proper probability measure is unique. The proof of this second lemma, like the proof of uniqueness in Gilboa and Schmeidler [7], uses a separating hyperplane theorem to show the existence of acts on which two different representations must \u2018disagree\u2019. However, a slightly different argument is required in our case, since our acts in M\u2217 must have utilities corresponding to nonpositive vectors in R |S|.\nLemma 9. Let P+ be the canonical set of weighted probability measures representing M\u2217 . The set C(P +) of sub-probability measures is regular.\nProof. It is useful to note that, by definition, p \u2208 C(P+) if and only if\nEp(b) \u2265 I(b) for all b \u2208 B \u2212\n(where expectation with respect to a subnormal probability measure is defined in the obvious way).\nRecall that a set is regular if it is convex, closed, and downward-closed. We first show that C(P+) is downward-closed. Suppose that p \u2208 C(P+) and q \u2264 p (i.e., q(s) \u2264 \u03b1Pr(s) for all s \u2208 S. Since p \u2208 C(P+), Ep(b) \u2265 I(b) for all b \u2208 B\u2212. Since q \u2264 p and, if b \u2208 cB\u2212, we have b \u2264 0\u2217, it follows that Eq(b) \u2265 Ep(b) \u2265 I(b) for all b \u2208 B\n\u2212, and thus q \u2208 C(P+). To see that C(P+) is closed, let p = limn\u2192\u221e pn, where each pn \u2208 C(P\n+). Since pn \u2208 C(P +) it must be the case that Epn(b) \u2265 I(b) for all b \u2208 B \u2212. By the continuity of expectation, it follows that Ep(b) \u2265 I(b) for all b \u2208 B \u2212. Thus, p \u2208 C(P+). To show that C(P+) is convex, suppose that p,q \u2208 C(P+). Then Ep(b) \u2265 I(b) and Eq(b) \u2265 I(b) for all b \u2208 B \u2212. It easily follows that for all a \u2208 (0, 1), Eap+(1\u2212a)q(b) \u2265 I(b) for all b \u2208 B \u2212. Thus, ap+ (1\u2212 a)q \u2208 C(P+).\nLemma 10. A set of sub-probability measures representing M\u2217 that is regular, and has at least one proper probability measure is unique.\nProof. Suppose for contradiction that there exists two regular sets of subnormal probability distributions, C1 and C2, that represent M\u2217 and have at least one proper probability measure.\nFirst, without loss of generality, let q \u2208 C2\\C1. We actually look at an extension of C1 that is downward-closed in each component to \u2212\u221e. Let C1 = {p \u2208 R|S| : p \u2264 p\u2032}. Note an element p of C1 may not be subnormal probability measures; we do not require that p(s) \u2265 0 for all s \u2208 S. Since C1 and {q} are closed, convex, and disjoint, and {q} is compact, the separating hyperplane theorem [15] says that there exists \u03b8 \u2208 R|S| and c \u2208 R such that\n\u03b8 \u00b7 p > c for all p \u2208 C1, and \u03b8 \u00b7 q < c. (4)\nBy scaling c appropriately, we can assume that |\u03b8(s)| \u2264 1 for all s \u2208 S. Now we argue that it must be the case that \u03b8(s) \u2264 0 for all s \u2208 S (so that \u03b8 corresponds to the utility profile of some act in M\u2217). Suppose that \u03b8(s\u2032) > 0 for some s\u2032 \u2208 S. By (4), \u03b8 \u00b7 p > c for all p \u2208 C1. However, consider p \u2217 \u2208 C1 defined by\np\u2217(s) =\n{\n0, if s 6= s\u2032 \u2212|c| \u03b8(s) , if s = s \u2032.\nClearly, \u03b8 \u00b7p\u2217 \u2264 c, contradicting (4). Thus it must be the case that \u03b8(s) \u2264 0 for all s \u2208 S.\nConsider the \u03b8 given by the separating hyperplane theorem, and let f be an act such that u \u25e6 f = \u03b8. By continuity, f \u223cM\u2217 l \u2217 d for some constant act l \u2217 d. Since C1 and C2 both represent M\u2217 , and C1 and C2 both contain a proper probability measure,\nmin p\u2208C1 p \u00b7 (u \u25e6 f) = min p\u2208C1 p \u00b7 (u \u25e6 l\u2217d) = d = min p\u2208C2 p \u00b7 (u \u25e6 f).\nHowever, by (4),\nmin p\u2208C1 p \u00b7 (u \u25e6 f) > c > min p\u2208C2 p \u00b7 (u \u25e6 f),\nwhich is a contradiction."}], "references": [{"title": "A definition of subjective probability", "author": ["F. Anscombe", "R. Aumann"], "venue": "Annals of Mathematical Statistics,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 1963}, {"title": "Ambiguity through confidence functions", "author": ["A. Chateauneuf", "J. Faro"], "venue": "Journal of Mathematical Economics,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2009}, {"title": "A generalization of the quasilinear mean with applications to the measurement of income inequality and decision theory resolving the allais paradox", "author": ["S.H. Chew"], "venue": null, "citeRegEx": "3", "shortCiteRegEx": "3", "year": 1983}, {"title": "Dynamically consistent beliefs must be Bayesian", "author": ["L.G. Epstein", "M. Le Breton"], "venue": "Journal of Economic Theory,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 1993}, {"title": "Learning under ambiguity", "author": ["L.G. Epstein", "M. Schneider"], "venue": "Review of Economic Studies,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2007}, {"title": "Maxmin expected utility with a non-unique prior", "author": ["I. Gilboa", "D. Schmeidler"], "venue": "Journal of Mathematical Economics,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 1989}, {"title": "Maxmin expected utility with non-unique prior", "author": ["I. Gilboa", "D. Schmeidler"], "venue": "Journal of Mathematical Economics,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 1989}, {"title": "Regret aversion and opportunity dependence", "author": ["T. Hayashi"], "venue": "Journal of Economic Theory,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2008}, {"title": "Stopping with anticipated regret", "author": ["T. Hayashi"], "venue": "Unpublished manuscript.,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2009}, {"title": "Dynamic decision making with belief functions", "author": ["J.-Y. Jaffray"], "venue": "Advances in the Dempster- Shafer Theory of Evidence,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 1994}, {"title": "A representation theorem for \u201cpreference for flexibility", "author": ["D.M. Kreps"], "venue": null, "citeRegEx": "11", "shortCiteRegEx": "11", "year": 1979}, {"title": "Notes on the Theory of Choice", "author": ["D.M. Kreps"], "venue": null, "citeRegEx": "12", "shortCiteRegEx": "12", "year": 1988}, {"title": "Zur preisbildung bei ungewissen erwartungen", "author": ["J. Niehans"], "venue": "Schweizerische Zeitschrift fu\u0308r Volkswirtschaft und Statistik,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 1948}, {"title": "A rule for updating ambiguous beliefs", "author": ["C.P. Pires"], "venue": "Theory and Decision,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2002}, {"title": "Convex Analysis", "author": ["R.T. Rockafellar"], "venue": null, "citeRegEx": "15", "shortCiteRegEx": "15", "year": 1970}, {"title": "Anticipating regret: Why fewer options may be", "author": ["T. Sarver"], "venue": "better. Econometrica,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2008}, {"title": "The theory of statistical decision", "author": ["L. Savage"], "venue": "Journal of the American Statistical Association,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 1951}, {"title": "The Foundations of Statistics", "author": ["L. Savage"], "venue": null, "citeRegEx": "18", "shortCiteRegEx": "18", "year": 1954}, {"title": "Dynamic choice under ambiguity", "author": ["M. Siniscalchi"], "venue": "Theoretical Economics,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2011}, {"title": "Axioms for minimax regret choice correspondences", "author": ["J. Stoye"], "venue": "Journal of Economic Theory,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2011}, {"title": "Statistical decisions under ambiguity", "author": ["J. Stoye"], "venue": "Theory and Decision,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2011}], "referenceMentions": [{"referenceID": 12, "context": "MER is a probabilistic variant of the minimax regret decision rule proposed by Niehans [13] and Savage [17].", "startOffset": 87, "endOffset": 91}, {"referenceID": 16, "context": "MER is a probabilistic variant of the minimax regret decision rule proposed by Niehans [13] and Savage [17].", "startOffset": 103, "endOffset": 107}, {"referenceID": 7, "context": "It is well known that the order on acts induced by minimizing expected regret is identical to that induced by maximizing expected utility (see [8] for a proof).", "startOffset": 143, "endOffset": 146}, {"referenceID": 15, "context": "Sarver [16] also proves a representation theorem that involves putting a multiplicative weight on a regret quantity.", "startOffset": 7, "endOffset": 11}, {"referenceID": 17, "context": "For example, Savage [18] showed that if an agent\u2019s preferences satisfied several axioms, such as completeness and transitivity, then the agent is behaving as if she is maximizing expected utility with respect to some utility function and probabilistic belief.", "startOffset": 20, "endOffset": 24}, {"referenceID": 6, "context": "MMEU has been axiomatized by Gilboa and Schmeidler [7].", "startOffset": 51, "endOffset": 54}, {"referenceID": 7, "context": "MER was axiomatized by Hayashi [8] and Stoye [20].", "startOffset": 31, "endOffset": 34}, {"referenceID": 19, "context": "MER was axiomatized by Hayashi [8] and Stoye [20].", "startOffset": 45, "endOffset": 49}, {"referenceID": 19, "context": "We make use of ideas introduced by Stoye [20] in his axiomatization of MER, but the extension seems quite nontrivial.", "startOffset": 41, "endOffset": 45}, {"referenceID": 9, "context": "We remark that a dynamic version of MMEU with measure-by-measure updating has been axiomatized by Jaffray [10], Pires [14], and Siniscalchi [19].", "startOffset": 106, "endOffset": 110}, {"referenceID": 13, "context": "We remark that a dynamic version of MMEU with measure-by-measure updating has been axiomatized by Jaffray [10], Pires [14], and Siniscalchi [19].", "startOffset": 118, "endOffset": 122}, {"referenceID": 18, "context": "We remark that a dynamic version of MMEU with measure-by-measure updating has been axiomatized by Jaffray [10], Pires [14], and Siniscalchi [19].", "startOffset": 140, "endOffset": 144}, {"referenceID": 4, "context": "Likelihood updating is somewhat similar in spirit to an updating method implicitly proposed by Epstein and Schneider [5].", "startOffset": 117, "endOffset": 120}, {"referenceID": 1, "context": "Chateauneuf and Faro [2] also consider weighted sets of probabilities (they model the weights using what they call confidence functions), although they impose more constraints on the weights than we do.", "startOffset": 21, "endOffset": 24}, {"referenceID": 0, "context": "A set P of weighted probability measures on a set S consists of pairs (Pr, \u03b1Pr), where \u03b1Pr \u2208 [0, 1] and Pr is a probability measure on S.", "startOffset": 93, "endOffset": 99}, {"referenceID": 1, "context": "2 We remark that, just as we do, Chateaunef and Faro [2] take weights to be in the interval [0, 1].", "startOffset": 53, "endOffset": 56}, {"referenceID": 0, "context": "2 We remark that, just as we do, Chateaunef and Faro [2] take weights to be in the interval [0, 1].", "startOffset": 92, "endOffset": 98}, {"referenceID": 0, "context": "By dividing by P + (E), we guarantee that \u03b1Pr,E \u2208 [0, 1], and that there is some measure Pr such that \u03b1Pr,E = 1, as long as there is some pair (\u03b1Pr,Pr) \u2208 P such that \u03b1Pr Pr(E) = P + (E).", "startOffset": 50, "endOffset": 56}, {"referenceID": 20, "context": "3 Stoye [21] assumes that, for each menu M , there is a finite set AM of acts such that M consists of all the convex combinations of the acts in AM .", "startOffset": 8, "endOffset": 12}, {"referenceID": 0, "context": "To get such an axiomatic characterization, we restrict to what is known in the literature as the Anscombe-Aumann (AA) framework [1], where outcomes are restricted to lotteries.", "startOffset": 128, "endOffset": 131}, {"referenceID": 0, "context": "This framework is standard in the decision theory literature; axiomatic characterizations of SEU [1], MMEU [7], and MER [8, 20] have already been obtained in the AA framework.", "startOffset": 97, "endOffset": 100}, {"referenceID": 6, "context": "This framework is standard in the decision theory literature; axiomatic characterizations of SEU [1], MMEU [7], and MER [8, 20] have already been obtained in the AA framework.", "startOffset": 107, "endOffset": 110}, {"referenceID": 7, "context": "This framework is standard in the decision theory literature; axiomatic characterizations of SEU [1], MMEU [7], and MER [8, 20] have already been obtained in the AA framework.", "startOffset": 120, "endOffset": 127}, {"referenceID": 19, "context": "This framework is standard in the decision theory literature; axiomatic characterizations of SEU [1], MMEU [7], and MER [8, 20] have already been obtained in the AA framework.", "startOffset": 120, "endOffset": 127}, {"referenceID": 20, "context": "Stoye [21] assumed that menus were convex, so that if f, g \u2208 M , then so is pf + (1\u2212 p)g.", "startOffset": 6, "endOffset": 10}, {"referenceID": 0, "context": "In the representation theorem for SEU [1], not only is the utility function unique (up to affine transformations, so that we can replace U by aU + b, where a > 0 and b are constants), but the probability is unique as well.", "startOffset": 38, "endOffset": 41}, {"referenceID": 6, "context": "Similarly, in the MMEU representation theorem of Gilboa and Schmeidler [7], the utility function is unique, and the set of probabilities is also unique, as long as one assume that the set is convex and closed.", "startOffset": 71, "endOffset": 74}, {"referenceID": 0, "context": ", a function mapping measurable subsets of S to [0, 1] such that p(T \u222aT ) = p(T )+p(T ) for disjoint sets T and T ), without the requirement that p = 1.", "startOffset": 48, "endOffset": 54}, {"referenceID": 20, "context": "We then use techniques of Stoye [21] to show that it suffices to get a representation theorem for a single menu, rather than all menus: the menu consisting of all acts f such that U(f(s)) \u2264 0 for all states s \u2208 S.", "startOffset": 32, "endOffset": 36}, {"referenceID": 5, "context": "This allows us to use techniques in the spirit of those used by by Gilboa and Schmeidler [6] to represent (unweighted) MMEU.", "startOffset": 89, "endOffset": 92}, {"referenceID": 0, "context": "Anscombe and Aumann [1] showed that the menu-independent versions of axioms 1\u20135 and 7 characterize SEU.", "startOffset": 20, "endOffset": 23}, {"referenceID": 6, "context": "Gilboa and Schmeidler [7] showed that axioms 1\u20136 together with one more axiom that they call Certaintyindependence characterizesMMEU.", "startOffset": 22, "endOffset": 25}, {"referenceID": 2, "context": "Betweenness [3] is a stronger notion than ambiguity aversion, which states that if an agent is indifferent between two acts, then he must also be indifferent among all convex combinations of these acts.", "startOffset": 12, "endOffset": 15}, {"referenceID": 19, "context": "While betweenness does not hold for regret, Stoye [20] gives a weaker version that does hold.", "startOffset": 50, "endOffset": 54}, {"referenceID": 19, "context": "Stoye [20] shows that Axioms 1\u20139 together with Axiom 12 characterize MER.", "startOffset": 6, "endOffset": 10}, {"referenceID": 20, "context": "As Stoye [21] shows, REG is characterized by Axioms 1\u20139 and one additional axiom, which he calls Symmetry.", "startOffset": 9, "endOffset": 13}, {"referenceID": 3, "context": "In particular, Epstein and Schneider [4] discuss a menu-independent version of MDC, although they do not characterize updating in their framework.", "startOffset": 37, "endOffset": 40}, {"referenceID": 18, "context": "Sinischalchi [19] also uses an analogue of MDC in his axiomatization of measure-by-measure updating of MMEU.", "startOffset": 13, "endOffset": 17}, {"referenceID": 3, "context": "Indeed, as Epstein and Le Breton [4] show, dynamic inconsistency arises for any non-Bayesian approach to decision making (i.", "startOffset": 33, "endOffset": 36}, {"referenceID": 3, "context": "As we said earlier, Epstein and Le Breton [4] show that dynamic inconsistency will arise for essentially all non-Bayesidan decision rules.", "startOffset": 42, "endOffset": 45}, {"referenceID": 8, "context": "Hayashi [9] uses the menu of viable plans in computing for minimax expected regret agents in optimal stopping problems, but it seems to us that both choices (and perhaps others) can be justified.", "startOffset": 8, "endOffset": 11}, {"referenceID": 18, "context": "A second subtlety that arises when considering sophisticated agents: What choice do they make when they are indifferent between two plans? Sinischalchi [19] axiomatizes consistent planning (with menu-independent preferences over plans), which augments backward induction with a tie-breaking assumption.", "startOffset": 152, "endOffset": 156}, {"referenceID": 10, "context": "Preferences over decision trees are similar in spirit to preferences over menus [11].", "startOffset": 80, "endOffset": 84}, {"referenceID": 20, "context": "Stoye [21] used a different framework: choice functions.", "startOffset": 6, "endOffset": 10}, {"referenceID": 20, "context": "Stoye [21] provides a representation theorem for MER where the axioms are described in terms of choice functions.", "startOffset": 6, "endOffset": 10}, {"referenceID": 20, "context": "Our proof starts in much the same way as the proof by Stoye [21] of a representation theorem for regret.", "startOffset": 60, "endOffset": 64}, {"referenceID": 20, "context": "Our menus are arbitrary sets of acts, as opposed to convex hulls of a finite number of acts in [21]; Lemma 3 shows that Stoye\u2019s technique can be adapted to work when menus are arbitrary sets of acts.", "startOffset": 95, "endOffset": 99}, {"referenceID": 20, "context": "Finally, following Stoye [21], we reduce the proof of existence of a minimax weighted regret representation for the family M to the proof of existence of a minimax weighted regret representation for a single menu-independent preference ordering (Lemma 4).", "startOffset": 25, "endOffset": 29}, {"referenceID": 11, "context": ", [12]), since menu-independence for constant acts, combined with independence, gives the standard independence (substitution) axiom from expected utility theory.", "startOffset": 2, "endOffset": 6}, {"referenceID": 20, "context": "Stoye [21] proved a similar result, but he assumed that all menus were obtained by taking the convex hull of a finite set of acts.", "startOffset": 6, "endOffset": 10}, {"referenceID": 20, "context": "Our arguments are similar in spirit to those of Stoye [21].", "startOffset": 54, "endOffset": 58}, {"referenceID": 19, "context": "As we said, Stoye [20] also started his proof of a representation theorem for MER by reducing to a single preference order M .", "startOffset": 18, "endOffset": 22}, {"referenceID": 5, "context": "Thus, it sufficed for Stoye to show that M had an MMEU representation, which he did by showing that M satisfied Gilboa and Schmeidler\u2019s [6] axioms for MMEU, and then appealing to their representation theorem.", "startOffset": 136, "endOffset": 139}, {"referenceID": 5, "context": "Since we have artificially extended I to B, our arguments require more cases than those in [6].", "startOffset": 91, "endOffset": 94}, {"referenceID": 5, "context": "We need different arguments from that for MMEU [6], since the preference order induced by MMEU satisfies C-independence, while our preference order does not.", "startOffset": 47, "endOffset": 50}, {"referenceID": 0, "context": "Thus, \u03b1Pr \u2208 [0, 1].", "startOffset": 12, "endOffset": 18}, {"referenceID": 6, "context": "Our uniqueness result is analogous to the uniqueness results of Gilboa and Schmeidler [7], who show that the convex, closed, and non-empty set of probability measures in their representation theorem for MMEU is unique.", "startOffset": 86, "endOffset": 89}, {"referenceID": 6, "context": "The proof of this second lemma, like the proof of uniqueness in Gilboa and Schmeidler [7], uses a separating hyperplane theorem to show the existence of acts on which two different representations must \u2018disagree\u2019.", "startOffset": 86, "endOffset": 89}, {"referenceID": 14, "context": "Since C1 and {q} are closed, convex, and disjoint, and {q} is compact, the separating hyperplane theorem [15] says that there exists \u03b8 \u2208 R and c \u2208 R such that", "startOffset": 105, "endOffset": 109}], "year": 2016, "abstractText": "We consider a setting where an agent\u2019s uncertainty is represented by a set of probability measures, rather than a single measure. Measureby-measure updating of such a set of measures upon acquiring new information is well-known to suffer from problems; agents are not always able to learn appropriately. To deal with these problems, we propose using weighted sets of probabilities: a representation where each measure is associated with a weight, which denotes its significance. We describe a natural approach to updating in such a situation and a natural approach to determining the weights. We then show how this representation can be used in decision-making, by modifying a standard approach to decision making\u2014minimizing expected regret\u2014to obtain minimax weighted expected regret (MWER). We provide an axiomatization that characterizes preferences induced by MWER both in the static and dynamic case.", "creator": "LaTeX with hyperref package"}}}