{"id": "1302.6803", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "27-Feb-2013", "title": "An Ordinal View of Independence with Application to Plausible Reasoning", "abstract": "An ordinal view of independence is studied in the framework of possibility theory. We investigate three possible definitions of dependence, of increasing strength. One of them is the counterpart to the multiplication law in probability theory, and the two others are based on the notion of conditional possibility theory. We describe the concept of conditional possibility theory in relation to the multiplicity of independent probability theory.\n\n\n\n\n\n\n\nThe second theory is a model of possibility theory that explores the possibilities of probability theory. In the case of a certain type of probability theory, there exists a definite number of possible possibilities, but in the case of a certain type of probability theory, there exists a certain number of possible possibilities, but in the case of a certain type of probability theory, there exists a certain number of possible possibilities, and in the case of a certain type of probability theory, there exists a certain number of possible possibilities, but in the case of a certain type of probability theory, there exists a certain number of possible possibilities, and in the case of a certain type of probability theory, there exists a certain number of possible possibilities, and in the case of a certain type of probability theory, there exists a certain number of possible possibilities, and in the case of a certain type of probability theory, there exists a certain number of possible possibilities, and in the case of a certain type of probability theory, there exists a certain number of possible possibilities, and in the case of a certain type of probability theory, there exists a certain number of possible possibilities, and in the case of a certain type of probability theory, there exists a certain number of possible possibilities, and in the case of a certain type of probability theory, there exists a certain number of possible possibilities, and in the case of a certain type of probability theory, there exists a certain number of possible possibilities, and in the case of a certain type of probability theory, there exists a certain number of possible possibilities, and in the case of a certain type of probability theory, there exists a certain number of possible possibilities, and in the case of a certain type of probability theory, there exists a certain number of possible possibilities, and in the case of a certain type of probability theory, there exists a certain number of possible possibilities, and in the case of a certain type of probability theory, there exists a certain number of possible possibilities, and in the case of a certain type of probability theory, there exists a certain number of possible possibilities, and in the case of a certain type of probability theory, there exists a", "histories": [["v1", "Wed, 27 Feb 2013 14:15:38 GMT  (718kb)", "http://arxiv.org/abs/1302.6803v1", "Appears in Proceedings of the Tenth Conference on Uncertainty in Artificial Intelligence (UAI1994)"]], "COMMENTS": "Appears in Proceedings of the Tenth Conference on Uncertainty in Artificial Intelligence (UAI1994)", "reviews": [], "SUBJECTS": "cs.AI", "authors": ["didier dubois", "luis farinas del cerro", "reas herzig", "henri prade"], "accepted": false, "id": "1302.6803"}, "pdf": {"name": "1302.6803.pdf", "metadata": {"source": "CRF", "title": "An ordinal view of independence with application to plausible reasoning", "authors": ["Didier Dubois", "Luis Farinas del Cerro", "Andreas Herzig", "Henri Prade", "Paul Sabatier"], "emails": ["@irit.fr,"], "sections": [{"heading": null, "text": "An ordinal view of independence is studied in the framework of possibility theory. We investigate three possible definitions of dependence, of increasing strength. One of them is the counterpart to the multiplication law in probability theory, and the two others are based on the notion of conditional possibility. These two have enough expressive power to support the whole possibility theory, and a complete axiomatization is provided for the strongest one. Moreover we show that weak independence is well-suited to the problems of belief change and plausible reasoning, especially to address the problem of blocking of property inheritance in exception-tolerant taxonomic reasoning.\n0 INTRODUCTION\nThe notion of epistemic independence can be studied in the framework of reasoning under uncertainty. It can be derived naturally using conditioning: \"C is independent of A iff one's opinion about C is not affected by the fact of knowing A.\" Dually, we say that C depends on A if it is not the case that C is independent of A. A synonymous expression for \"C depends on A\" is \"A is relevant for C'. Traditionally, the formal basis of the dependence relation (also called relevance relation) is conditional probability: Given two events A and C and a probability measure Prob, C is (probabilistically) independent of A iff Prob(CIA) = Prob(C).\nIn this paper we show that independence based on possibility theory (Zadeh 1978, Dubois and Prade 1988) has quite different properties. We present three definitions of independence and study their formal properties. We call them unrelatedness, strong and weak independence. We show that strong independence has enough expressive power to support the whole possibility theory, and we give a complete ax.iomatization not explicitly involving the underlying uncertainty theory. Then we apply these notions to the problems of belief revision and exception tolerant reasoning.\nThroughout the paper A, B, C, D and E stand for events belonging to a Boolean algebra of subsets of a set Q.We use the symbols: conjunction A, disjunction v, and\nnegation ...,. True and False are propositional constants denoting the true and false events respectively.\n1 PROBABILISTIC INDEPENDENCE\n1. 1 The Multiplication Law\nThe standard definition of probabilistic independence is via the Multiplication Law: A and C are probabilistically independent iff Prob(AAC ) = Prob(A) * Prob(C). A priori we find it more natural to define independence as : C is probabilistically independent of A iff Prob(C IA) = Prob(C ), relying thus on conditioning. In fact this conditioning-based notion of independence is equivalent to the multiplication law. It follows from the axioms of probability theory that independence defined in this way is a symmetric relation, and that it is not sensitive to negation. In other words:\n(symmetry) If C is independent of A then A i s independent of C. (negation) If C is independent of A then C IS independent of ...,A.\nSymmetry justifies to say \"A and C are independent\" instead of \"A is independent of C\". Moreover we have\n(truth) A and True are independent.\nNote that there are no such simple properties governing the interplay of independence with conjunction and disjunction.\nThe above properties are not enough to completely characterize the notion of probabilistic independence. To get completeness we need two more axioms (Kolmogorov 1956), cited in (Fine 1973):\n(prob v) If A and B are independent, A and C are independent and B and C are mutually exclusive, then A and BvC are independent.\n(prob A) If A and B are independent, C and D are independent, B \ufffd D and A \ufffd C then AAB \ufffd CAD.\nHence the ax.iomatisation of dependence involves not only logical truth, but also a qualitative probability relation \"\ufffd\". It follows that - at least for the simple definition via conditioning - we cannot study the formal properties of probabilistic dependence separately from the probabilistic framework.\n196 Dubois, Farinas del Cerro, Herzig, and Prade\nThe Multiplication Law has been criticized by several authors. R. von Mises (1964) has argued that the Multiplication Law could be fulfilled just because of \"pure numerical accidents\", although A and B are not intuitively independent in the sense of 'being separated' or 'not influencing each other'. He gives an example where Prob(A) = Prob(B) = Prob(C) = Prob(D) = 1/4, and A, B, C and D are pairwise mutually exclusive. Then he investigates whether AvB and BvC are independent. According to von Mises they are intuitively dependent (because they have B in common), whereas the Multiplication Law says that they are independent.\nH. Reichenbach ( 1949) has argued that dependence and independence should be ternary rather than binary relations, where the third element in the relation is the evidence on which we declare that A and C are independent. From the ternary relation we can get back the binary one as follows: A and C are independent if! there is some evidence E such that A and C are independent on evidence E. We do not treat ternary relations in the sequel except in the last section. Nevertheless our analysis carries over to the ternary case. In the rest of the section we formally present two important principles that are not validated by the Multiplication Law.\n1. 2 Conjunction and (in)dependence\nA formal objection to the multiplication Law has been given by J. M. Keynes (1921, cited in (Giirdenfors 1978)). According to Keynes, the following conjunction criterion for dependence (called conjunction criterion for relevance in (Giirdenfors 1978)) should be valid:\n(CCD) If C depends on A, and C depends on B then C depends on At\\13.\nHe notes that (CCD) is not validated by the Multiplication Law. Keynes proposes a stronger definition of probabilistic independence that does it: Cis independent of\nA iff there is noB such that A implies Band Prob(CIB) ;t: Prob(C). R. Carnap (1950) has shown that this definition leads to a trivial notion of independence: It entails that C depends on A as soon as C and A are consistent.\nGiirdenfors (1978) has suggested a conjunction criterion for independence dual to (CCD):\n(CCI) If C is independent of A, and C is independent of B then C is independent of AAB.\nis a natural principle that should be valid. Gardenfors criticizes the Multiplication Law because it does not guarantee this principle, and investigates a series of stronger definitions of independence. He finally comes up with: C is independent of A iff Prob(A) == 0, or Prob(CIAAB) = Prob(C)forall B such that Prob(AAB) > 0 and Prob(C IB) = Prob(C ). This definition validates (CCI).\nNote that Gardenfors' independence relation is non symmetric. Here we show that in an ordinal setting where uncertainty is described by ordering the states of the world by their plausibility, we capture similar regularities in terms of disjunction, in a much simpler way.\n2 POSSIBILITY THEORY\nWe introduce the notions of possibility measure and distribution and of conditional possibility.\n2. 1 Possibility Measures\nPossibility measures allow to associate an uncertainty degree to the elements of the set of events. Following e.g., Dubois and Prade (1986), a function ll from 20. into the real interval [0, 1] is a possibility measure if it satisfies the following axioms:\nI1(True) > IT(False) ; I1(AvB) = max(TI(A),TI(B))\nAny totally ordered set can stand for the unit interval, that we keep here for the sake of simplicity. By convention I1(True) == 1, IT(False) = 0. ITCA) = 1 only means that A is possibly true, while I1(A) = 0 means that A is certainly false. Particularly, when ITCA) = TIC-.A) = 1, it means total ignorance about the truth of A. The basic max decomposability axiom is due to the purely ordinal setting. It can also be viewed as enforcing IT(A u B) to its lowest bound since for any reasonable confidence measure, we should have \"if A implies B then IT(A) \ufffd I1(B)\". Note that n cannot be decomposable with respect to conjunction because TI(AA...,A) = 0 for all A, but IT(A) = f1(-,A) = 1 is permitted. Moreover, max(IT(A),IJ(-,A)) = I1(True), since Av-,A = True. The quantity N(A) == 1 - IJ( ..,A) is called the necessity of A, and represents a level of certainty, or acceptance of A. Especially N(A) > 0 means that A is accepted, while ..,A is not (since N(A) > 0 entails N(\u2022A) = 0 in the absence of inconsistency). And we have the reasonable axiom of acceptance saying that if A is accepted and so is B, then AAB is accepted too, since N(AAB) == min(N(A),N(B)) holds. Note that the fact that A is not accepted (N(A) = 0) does not entail that it is rejected (which is expressed by N(...,A) > 0).\nIn the finite case a possibility measure can be represented by a possibility distribution 1t on 0. the set of interpretations of the language. Namely IT(A) = sup{n{ro) I w I= A}. 1t encodes a complete partial ordering of interpretations, with the intended meaning that if n(ro) > n(w'), ro is a more plausible description of the current situation than ro'. Reasoning in the setting of possibility theory comes down to assume that the current situation is always one of the most plausible ones. Accepting A (N(A) > 0) means that I1(A) > f1(-,A), i.e., that \"normally A should be true\". This way of modelling uncertainty is in full accordance with Shoham (1988)'s view of preferential logic, Lehmann (1989)'s notion of ranked models, also encoded in Pearl ( 1990)'s system Z. See (Benferhat et al. 1992). Especially N(A) > 0 can be written True lv A in the terminology of conditional assertions in Lehmann's rational nonmonotonic setting. True lv A means \"A is plausibly true\" (unconditionally).\nEvery possibility measure induces a relation \"\ufffd\" defined by A \ufffd B if and only if ll(A) \ufffd I1(B). We call \ufffd a relation agreeing strictly with IT. A \ufffd B is read \"A is at\nAn Ordinal View of Independence with Application to Plausible Reasoning 197\nleast as possible as B\". This relation is called qualitative possibility ordering and satisfies the following conditions:\n{non triviality) True >False (tautology) True;:: A (transitivity) if A ;:: B and B ;:: C then A ;:: C (disjunctiveness) AvC \ufffd A or AvC \ufffdC. (dominance) If A implies B then A \ufffd B\nRemark. Often, (disjunctiveness) is replaced by the two axioms of connectedness {A ;:: B or B ;:: A) and disjunctive stability (if A;:: B then AvC;:: BvC)\nThat these conditions are sufficient follows from the following formal relation between possibility theory and qualitative possibility orderings (Dubois 1986): The only functions mapping events into [0, 1] which strictly agree with qualitative possibility orderings are possibility measures, and a strictly agreeing possibility measure always exists. In our presentation of possibility theory, this result can be expressed as follows:\nTheorem (soundness and completeness of qualitative possibility orderings). Let IT be any measure on n, and ;:: any binary relation on the subsets of n. Then IT is a possibility measure iff ;:: is a qualitative possibility ordering.\nConditional possibility relations first appear in Lewis (1973)'s logics of counterfactuals whose semantics are systems of spheres. But as indicated in Dubois and Prade (1991) a system of spheres is equivalent to a possibility distribution. Formal links between possibility theory and conditional logics are studied in Farinas del Cerro and Herzig (1991). Lastly, the dual qualitative certainty relation, equivalent to necessity measures (A ;;>:N C iff ...,c ;:: -,A) is closely related to expectation-orderings of Gardenfors and Makinson (1994). The characteristic axiom of ;::N is\n(conjunctiveness)\n2 . 2 Conditional Possibility\nFollowing Hisdal ( 1978) and Dubois and Prade ( 1986, 1992) the conditional possibility IT(CIA) is defined as the maximal solution of the equation IT(AAC) = min(fl(CIA), IT(A)). This definition is clearly inspired from Bayes' Rule, where min corresponds to the product. The choice of the maximal solution is due to the principle of minimal specificity which urges to select the least committed possibility measures, i.e. the one which allows each event to have the greatest possibility level:\nIT(CIA) = 1 if fl(A) = fl(A\u00b7'.C) IT(CIA) = Il(A .. \\C) if fl(A) > fl(AAC)\nFacts. 1. If Il(A) = 0 then fl(CIA) = I 2. If fl(AAC) = I then fi(CIA) = 1 3. If fl(A) > 0 and IT(C) = 0 then IT(CIA) = 0 4. IT(ChC) = 1 iff fi(-q = 0 5. Il(ChC) = 0 iff fi(...,C) > 0\nSome of these facts deserve some comments. Fact 1 suggests that nothing is sure when assuming that a certainly false proposition is true (since in this case anything and its contrary is plausible). This leads to the convention IT(False I False)= I which does not agree with the non-triviality axiom (it is not compulsory anyway). Fact 2 says that if A and C are fully consistent, assuming A true keeps C possibly true. Fact 3 says that a certainly false proposition remains false via conditioning by a non certainly false proposition. However if IT(A) = 0 then the conditional possibility again disagrees with the non triviality axiom.\nIn the next sections we present three different ordinal definitions of (in)dependence. Two of them are based on the notion of conditional possibility. We show that these two can express qualitative possibility, and that complete axiomatizations is given for one of them. We conjecture that this is not possible for the third one, originally due to Zadeh. In all three cases, a necessary condition for the independence of A and C will be that the conjunction AAC can be interpreted truth-functionally, in the sense that fl(AAC) =min (fl(A),fl(C)) for these particular events.\nThe conditional necessity is N(...,CIA) = 1 - IT(CIA), defined by duality. Note that N(CIA) = N(-,AvC) if N(CIA) > 0. The following property will be used at length in the sequel:\nN(CIA) > 0 iff fl(AAC) > fl(AN\u00b7\u2022C)\nN(CIA) > 0 means that C is accepted as true when A is assumed to be true. It corresponds to the conditional assertion A tv C in the sense of Lehmann's rational inference, and can be viewed as the (nonmonotonic) plausible entailment of C from A in the presence of an ordering of interpretations. The above clearly show that A tv C means AAC is more plausible than AA..,C (or equivalently fi(AAC) > fl(AA..,C) in terms of possibility measure).\n3 (UN)RELA TED NESS\nZadeh (1978) has introduced a symmetric definition of independence called \"non-interactivity\" between possibilistic variables that is not based on conditional possibilities.This notion has also been studied by Nahmias (1978) for events, under the name \"unrelatedness\".\n(Def \"\"z) A and C are related propositions in lildeh's sense (denoted by A \"\"z C) iff Il(AAC) * min(fi(A),fl(C)).\nIt is interesting to characterize the constraints induced by unrelatedness on the ordering of interpretations AAC, ..,AAC, AA..,C, ...,AA..,C respectively.\nProposition. A and C are unrelated if and only if fl(AAC);:: min(fl(AA-,C),IT(...,AAC)). Proof IT ( A A C) = min(max(Il(AAC ),Il( A A...,C ) ) , max(fl(AAC),IT(..,AAC))). Clearly as soon as Il(AAC) :2: fl(AA..,C), unrelatedness holds. And the same when fl(AAC) ;;>: fiC-,AAC). However if Il(AAC) < IT(AA...,C)\n198 Dubois, Farinas del Cerro, Herzig, and Prade\nand Il(A/\\C) < IT(...,A/\\C), then ITCA) = Il(A/\\\u2022C) and TICC) = I1(-,A/\\C), and A and C are related.\nClearly, A and C are related implies that A/\\C is an implausible situation (since in any case it holds Il(A/\\C) :::.:; min(IT(A),IT(C)) ), i.e., A and C are (more or less) mutually exclusive:\nCorollary. A and C are related if and only if N(...,CIA) > 0 and N(-,AIC) > 0.\nOn the contrary when A and C are unrelated the two propositions are totally allowed to be true together. Zadeh's independence is an extension of the logical notion of consistency. This notion is not very demanding. Moreover this notion is local in the sense that it is sensitive to negation: if A and C are unrelated, it does not say anything about the other literals ..,A and C, C and ..,A, -,c and -,A, Other properties are as follows.\nFacts. l . A \"\"z C iff C \"\"z A 2. If A \"\"z BvC then A \"\"z B or A \"\"z C 3. If AvB \"\"z C then A \"\"z C or B \"\"z C\n(due to symmetry) 4. If A \"\"z C and B \"\"z C then AvB \"\"z C 5. If A \"\"z B and A \"\"z C then A \"\"z BvC\n(due to symmetry) 6. False ::tz A (where ::tz means \"not(-=z ))\" 7. True ::tz A 8. A ::tz A 9. A ::tz -,A iff IT(A) = 0 or I1(-,A) = 0 ; 10. AvC \"1:-z A\nFacts 2 and 3 are disjunction-oriented. However, none of the two conjunction criteria (CCD) and (CCI) are valid with unrelatedness. Note also that facts 8 and 10 is certainly a strange property for an independence relation. There seems to be no way to express I1 by means of \"\"z, the reason being that we cannot express Il(A) = 1. Therefore, we conjecture that (just as for probabilistic independence) \"\"Z cannot be axiomatized alone.\n4 STRONG INDEPENDENCE\nIt is tempting to define dependence in possibility theory in a way similar to probability theory, namely to define C as independent of A when the conditional measure of C given A is equal to the unconditional measure of C. Here we have two uncertainty functions I1 and N. Hence we can define independence as ITCCIA) = Il(C) or N(CIA) = N(C). Notice that N(CIA) = N(C) is equivalent to IJ(-,CIA) = Il(...,C). In (Farinas and Herzig 1994a) the independence relation defined by ITCCIA) = [l(C) is studied. A complete axiomatisation has been given.\nNote that if Il(CIA) = Il(C) < 1 then we are in the situation where C is plausibly rejected (since fl(...,C) = 1 > ITCC)). Hence the meaning of IT(CIA) = Il(C) < 1 is that when A is assumed to be true, it does not affect the plausible rejection of C. This expresses the negative statement that accepting ...,c is independent of A. It suggests to use N(CIA) = N(C) in order to express a positive statement. Note that we also have\nIl(CIA) = I1(C) < 1 implies [1(-,CIA) = ITC...,C) = 1\nbut not the converse. Hence fl(-,CIA) = ITC\u2022C) = 1 is a very weak statement saying that not accepting C (i.e. N(C) = 0) is not questioned by fact A. In particular, I1(CIA) = I1(C) = IJ(-,CIA) = Il(...,C) = 1 (which is never met in the probabilistic case), means that in the presence of A, C, which was originally ignored, is still ignored. In this paper we shall restrict to independence of accepted propositions with respect to other propositions; independence of ignored propositions turns out to be a very distinct issue, as suggested by the following result:\nProposition 4. 1. N(CIA) = N(C) iff either (i) 1 = max(I1(-,A/\\...,C),I1(A/\\-,C)), and Il(A/\\...,q \ufffd Il(A/\\C), or (ii) I1(A/\\C) > IT(A\"...,q \ufffd IJ(-,A/\\...,C)\nMoreover, (i) is equivalent to N(CIA) = N(C) = 0, and (ii) is equivalent to N(CIA) = N(C) > 0. Note that the two situations (i) and (ii) correspond to (almost) reversed orderings of interpretations. We give the following definition of the strong independence relation:\n(Def \"1:->) C is strongly independent of A (denoted by A \"1:-> C) iff N(CIA) = N(C) > 0.\nNote that A \"1:-> C indicates that in the context where A is true C is accepted. Due to what we said above, C is strongly independent of A iff ITC ...,CIA) = Il( \u2022C) < I .\nIn the next theorem we characterize a dependence relation \"\">=not(\"#>) without using conditional necessities.\nTheorem (construction of \"\"> from IT). Let IT be a possibility measure, and let \"\"> be defined from its dual N through (Def\"l:->). l. A\"\ufffd:-> C iff I1(A) > I1(-,q = IT(A/\\\u2022C) 2. A \"\"> C iff [l(A) S: TIC \u2022C) or IT( ...,C) > IT(A/\\\u2022C) Proof Follows directly from Proposition 4.1.\nCorollary. Let IT be a possibility measure, and let => be defined from IT through (Def \"1:-> ). l . A \"1:-> C iff Il(A/\\\u2022C) = min(IT(A),[1(-,C)) and IT(\u2022C)\n< I1(A). 2. A\"\"> C iff IT(A/\\...,q :F- min(I1(A),I1(.C)) or [1(-,q \ufffd\n[1(A). 3. If A \"1:-> C then IT(A/\\C) = min(Il(A),IT(C)). 4. If IlC\u2022C) \ufffd I1(A) then A\"\"> C.\nFa cts. 1. If A\"\"> B/\\C then A -=> B or A\"\"> C 2. If A v B => C then A \"\"> C or B \"\"> C 3.1f A\"\"> C and B -=> C then AvB \"\"> C 4. If A \"\"> B and A \"\"> C then A \"\"> B\"C 5. False \"\"> C 6. True \"1:-> C iff N(C) > 0 7. A => False 8. A \"1:-> True iff [l(A) > 0 9. A/\\B \"\"> \u2022B\"C 10. If A implies -.c then A \"\"> C 11. AvC \"1:-> .C iff IJ(A) > IT(C) 12. A\"\ufffd:-> A iff N(A) = 1 ; 13. If Il(A) = 0 then A\"\"> C 14. If IT(C) = 1 then A \"'> \u00b7C 15. A\"\"> cor -,c \"\"> \u2022A\nLet us comment on these facts. Facts 2 and 3 are similar to the (CCI) and (CCD) axioms except that disjunction is used instead of conjunction. Facts 1 and 4 are also similar\nAn Ordinal View of Independence with Application to Plausible Reasoning 199\nbut the conjunction of influenced facts is considered instead of influencing facts. Fact 5 means that assuming a contradiction holds destroys all previously plausible propositions. On the contrary tautologies never affect the plausibility of already plausible propositions (Fact 6). Fact 7 is simply due to the impossibility to assert false propositions. Fact 8 says that we can only assert a tautology is plausible when taking for granted an impossible proposition. Fact 9 and 10 express equivalent properties. N amely if A implies that C is false then when learning that A is true affects our opinion about C when C was previously supposed to be plausible. Fact 11 shows that the possibilistic ordering can be translated in terms of strong independence. Fact 12 claims that the only case when the truth of A is independent of itself is when A is a tautology. Fact 13 is a more general statement than fact 5. Fact 14 holds because it cannot be the case that D(A) > I1(C). Similarly the reason for fact 15 is that TI(A) > D(\u2022C) cannot go along with IT( .C)> TI(A).\nClearly, probabilistic dependence and possi bilistic dependence are quite different concepts. Probabilistic properties such as symmetry (\"If B depends on A then A depends on B\") or transparency w.r.t. negation (\"If B depends on A then B depends on \u2022A'') do not hold in the possibilistic case. In other words, A i:-> B neither implies B i:-> A nor A i:-> \u2022B. On the other hand, possibilistic dependence has some \"nice\" regularities such as 1., 2., 3., 4., none of which holds in the probabilistic case. These regularities are quite close to the criteria (CCD) and (CCI).\nConcerning the expressivity of the dependence relation it is interesting to observe that it possesses the same expressivity as possibility theory itself. This follows from the next result.\nTheorem (construction of TI from i:->). Let TI be a possibility measure, and let i:-> be defined from TI. 1. I1(A) >TI(C) iff AvC *>.C. 2. ITCA) ::::rrcq iff Ave\"\"> \u00b7A. Proof By previous fact I I.\nThe theorem can be read as follows: C is strictly less possible than A if and only if learning that AvC is true does not change my rejection of C. The theorem should not be surprizing since the meaning of independence is to enforce constraints on the ordering between interpretations as shown in Proposition 4.1. It turns out that such constraints are enough to identify a single ordering, i.e. a comparative necessity relation.\nThus we are able to express qualitative possibility by means of strong independence. In a trivial manner, this correspondence enables us to obtain an axiomatization of the (in)dependence relation by translating the qualitative counterpart of possibility theory. N ote that this is in contrast with probability theory: There, the independence relation cannot completely capture qualitative probability (which in turn determines the probability measure). Here we give a simpler axiomatization of\"\">:\n( \"\"> 1) True *> True (o:> 2) A\"\"> False\n(=> 3) If AvB \"\"> \u2022B and BvC => ....C then AvC \"\"> -.c (=>4) A => \u2022A (=> 5) If A => BAC then A\"'> B or A\"\"> C\nTheorem (soundness and completeness of the axiomatics of \"'> w.r.t. possibility theory). Let => be a relation on events, and n a mapping from the set of events to [0,1] such that A i:-> C iff N(CIA) = N(C) > 0. Then => is a dependence relation iff N is a necessity measure. Proof From the right to the left, it is sufficient to prove that the above axioms (rewritten as qualitative necessities) are valid. Then we can use the soundness of qualitative necessity orderings w.r.t. possibility theory. From the left to the right, we prove that the axioms for qualitative necessity orderings are derivable from the above axiomatics (and then use the completeness of qualitative necessity orderings w.r.t. possibility theory). Using the previous theorem in terms of necessities, namely N(A) > N(C) iff \u2022Av\u2022C *>A; N(A);:: N(C) iff \u2022Av\u2022C \"'> C we express qualitative necessities with \"'>:\n1. (non triviality) True >N False becomes \u2022Falsev\u2022True *>True.\nIt is equivalent to True*> True which is an instance of (=> 1). 2. (transitivity) if A :=:N B and B :=:N C then A :=:N C becomes: If \u2022Av\u2022B \"'>B and \u2022Bv\u2022C \"'> C\nthen \u2022Av\u2022C => Cwhich is(\"'> 3). 3. (tautology) A \ufffdN True becomes \u2022Av\u2022True => True which is nothing else but(\"\"> 2). 4. (conjunctiveness) AA C :=:N A or AAC :=:N C becomes \u2022(AAC)v\u2022A => A or \u2022(AAC)v\u2022C => C, hence \u2022A v....C \"\"> A or \u2022A v\u2022C \"\"> C. The latter can be proved combining \u2022Av\u2022C \"'> AAC which is an instance of\n(\"\"> 4), and: If \u2022Av\u2022C => AAC then \u2022Av-,C \"'> A or \u2022Av-,C => C which is an instance of(\"'> 5). 5. {dominance) can be replaced by\n(equivalence) If A H C then A \ufffdN C and (monotony) A :=:N AAC. The latter is translated to \u2022 Av\u2022(AAC) => AAC, which is an instance of(=> 4). Hence what remains to prove is\nIf A H C then \u2022A v....C => C. N ow from A H C we get \u2022C H \u2022Av\u2022C. From the latter we get (\u2022C \"'> C iff \u2022Av\u2022C \"'>C). Then \u2022Av\u2022C \"'> C follows from(\"\"> 4).\nRemark. It is important to note that => is quite close to a qualitative possibility ordering: Replacing A \"='> C by TI(A) \ufffd TI(\u2022C) all our principles are possibilistically valid. In particular (connectedness) can be deduced from the axioms: From('\"\"> 4) and(\"'> 5) we can get AvC =>\u00b7A or AvC => \u2022C (see above). The other way round, the only (qualitative) axiom for \ufffdN that apparently does not follow from the above axioms is that of transitivity. As on the other hand we know by the above Corollary that A i:-> C implies TI(A) >TIC .....C), we obtain that for a given n. *> is a fragment of the\n200 Dubois, Farinas del Cerro, Herzig, and Prade\ncorresponding strict possibility ordering. This fragment is closed under all the axioms of possibility theory except that of transitivity.\n5 WEAK INDEPENDENCE\nThe notion of strong independence may be felt too strong because what we may wish to express is a more qualitative notion of independence. Now, strong independence requires that not only C remains more plausible than -,c when A is known to be true, but its level of acceptance should not be altered. This last requirement forces the inequality fl(A/\\...,C);:: fi(-,A/\\...,C) which implies that in the context where C would be false, it is forbidden to conclude that -,A should be accepted (see Fact 15 of the previous section). Hence we have the property\nC is strongly independent of A if and only if N(CIA) > 0 and ...,(N( \u00b7AhC) > 0).\nA milder notion of independence is that if C is accepted unconditionally, then if A is true, C remains accepted; then we do away with any commitment in the case when C would turn out to be false. Hence the following definition:\n(Def #>w) C is weakly independent of A (denoted A #>w C) iffN(CIA) > 0 and N(C) > 0.\nProposition 5.1. A #>w C iff I1(A/\\C) > fl(A/\\ \u2022 C ) and max(I1(C/\\A),I1(C/\\-,A)) > fl(...,A/\\\u2022C ). Proof Indeed A#>w C is equivalent to I1(A/\\C) > I1(A/\\...,C), I1CC) = 1 = max(I1(C/\\A), I1(C/\\-,A)) > I1(A/\\...,C) and max(I1(C/\\A),I1(C/\\\u2022A)) > I1C\u2022A/\\...,C), the first of which is redundant. Q.E.D.\nProposition 5.2. A -:t=> C iff A #>w C and fl(A/\\\u2022C)= IJ(...,C). (Obvious using Proposition 4.1.)\nProposition 5.3. A #w C implies A #>z C. Proof Obvious since I1(A/\\C) > fl(A/\\ ...,q, and then fl(A) = fl(A/\\C) :::; I1(C).\nHowever it is not true that, as for strong independence\nA #>w C implies I1(A/\\-,q = min(I1(A),f1C...,C))\nsince weak independence does not involve ll(A/\\...,C).\nIt can be checked that weak independence satisfies Facts 1, 2, etc. of the previous section except for a few ones, namely Fact 12, which becomes A #>w A iff N(A) > 0, and Fact 15. The latter is not surprizing since weak independence is meant to let the relationship between N(AIB) > 0 and N(...,BhA) > 0 loose. Hence it is possible to have A #>w C and -,c #>w ...,A. This occurs precisely when IT(...,A/\\C) > max(Il(A/\\C), fi(...,A/\\...,C)) and min(I1(A/\\C),IJ(-,A/\\-,C)) > I1(A/\\...,C). Besides, weak independence satisfies stronger forms of Facts 3 and 4 :\n3'. if A \"\">w C or B \"\">w C then AvB \"'>w C 4'. if A \"'>w B orA \"\"->w C then A \"\">w B/\\C\nLastly we have the following remarkable property\nVA,C, Av-,C #>w C iff Av....C #> C\nIndeed if Av...,C #>w C, then N(CIAv....C) > 0 is such that N(CIAv....C) = N((...,A/\\C)vC) = N(C).\nHence when C is weakly independent of A then it is also strongly independent of A as soon as ...,c 1-- A. As a consequence, it is easy to see that the theorem that constructs a possibility measure from the independence relation also holds when we change the strong independence into the weak independence. In fact only the part of the strong independence relation that is equivalent to weak independence is useful to recover the underlying possibility measure. However if ....C 1-- A does not hold, A #>w C does not enforce an inequality between I1(C) and fl(...,A) generally. Finally the six axioms that characterize strong independence with respect to possibilistic semantics also hold for weak independence, but more axioms are necessary to completely characterize weak independence.\nLet us show how weak independence can be related to the framework of belief revision (Gii.rdenfors, 1988). A central problem for the theory of belief revision is what is meant by a minimal change of a state of belief. As pointed out in Gardenfors (1990), \"the criteria of minimality that have been used [in the models for belief change] have been based on almost exclusively logical considerations. However, there are a number of non-logical factors that should be important when characterizing a process of belief revision\". Gardenfors focuses the notion of dependence (he uses the synonymous term 'relevance') and proposes the following criterion: If a belief state K is revised by a sentence A, then all sentences in K that are independent of the validity of A should be retained in the revised state of belief\nThis seems to be a very natural requirement for belief revision operations, as well as a useful tool when it comes to implement belief change operations. As noted by Gardenfors, \"a criterion of this kind cannot be given a technical formulation in a model based on belief sets built up from sentences in a simple propositional language because the notion of relevance is not available in such a language.\" However the above criterion does make sense in the ordinal setting of possibility theory.\nWe suppose given a theory K and an AGM revision operation * (Giirdenfors, 1988). K* A represents the result of revising K by A. According to Gardenfors and Makinson's characterization theorem, K and * can be represented equivalently by an epistemic entrenchment ordering, which in turn is nothing else than a qualitative necessity ordering. It can be proved that in terms of possibility theory the fact that C belongs to K* A is equivalent to having N(CIA) > 0 (Dubois and Prade, 1992); moreover C belongs to K is equivalent to N(C) > 0. If we translate the definition of the weak independence relation #>w in terms of revision we get\nA #>w C iff C E K and C E K* A\nwhich is exactly Gardenfors' above requirement for revision-based independence. Clearly, a companion\nAn Ordinal View of Independence with Application to Plausible Reasoning 201\ndefinition of a dependence relation \"\">- associated to a given qualitative necessity ordering can be defined via the following condition from a given AGM contraction operation (-):\n(Cond ::=>-) A ::=>- C iff C E K and C tl: K-A iff N(C) > 0 and N(A) \ufffd N(AvC).\nThis alternative notion is studied in (Farinas and Herzig, 1994b). The comparative analysis of revision-based and contraction-based notions of independence is beyond the scope of this paper.\n6 COMPARATIVE DISCUSSION\nWe have analysed three notions of (in)dependence that can be defined in possibility theory. A common feature to all of them is that the independence of A and C requires that the conjunction of A and C is interpreted truth functionally. In other words, we have\nA :F> C implies A :t>w C ; A :F.>w C implies A :F.z C\nHence, all notions of independence share the property Il(AAC) = min(IT(A),Il(C)). Moreover, we have shown that\nA :t:.> C iff A :F.z \u2022C and fl(\u2022C) < fl(A) A :F.> C iff A :F.>w C and IT(AA\u2022C)= fl(.C)\nWe now examine the validity of Keynes-Giirdenfors criteria of Section l in the ordinal setting of possibility theory. Namely the following requirements:\n(CCD) If A \"\"> C and B => C then AAB => C (CCI) If A :F> C and B :F> C then AAB :t> C Also consider symmetric counterparts of CCD and CCI:\n(CCD-r) If A ::=> B and A => C then A => BAC (CCI-r) If A :F> B and A :F> C then A :t> BAC and the corresponding properties changing conjunction into disjunction (DCD, DCI, etc).\n(DCI) (DCI-r) (DCD) (DCD-r) If A :t> C and B :t> C then AvB :t> C If A :F.> B and A :F.> C then A :F.> BvC If A \"\"> C and B \"\"> C then A v B \"\"> C If A \"\"> B and A \"\"> C then A => BvC\nFirst the relatedness property of Zadeh :tz satisfies the four above criteria concerning disjunctions. (CCD-r), (CCI-r), (DCI) (DCD) hold for strong and weak independence. The weak independence has the following stronger property:\nA :F>w BAC iff A :t>w B and A :F.>w C AvB :F->w C iff A :t>w C and B :t>w C\nthat is (DCI) and (CCI-r) with equivalence, due to Facts 3' and 4' of Section 5. This is natural if weak independence is considered in terms of belief revision: if we continue to accept BAC upon learning A we should continue to accept C and B as well.\nWe could have introduced as well a ternary dependence relation \"B and C are independent, given A\", as studied by Giirdenfors (1978, 1990) and Pearl ( 1988). For reasons of\nsimplicity we have restricted our analysis to binary dependence relations here, but it is clear that a ternary relation is certainly the most general one. This will be subject of further investigations.\n7 APPLICATION TO EXCEPTION TOLERANT REASONING\nPossibility theory is a natural framework for handling nonmonotonic reasoning problems, because it embeds what Lehmann calls rational inference (see Benferhat et al., 1992). Given a set of rules modelled by pairs of propositional formulas, it is possible to rank-order these exception-tainted rules in terms of their relative specificity. This ranking of rules generates an ordering of interpretations that can be encoded as a possibility distribution.\nThe algorithm for ranking rules (or interpretations) has been proposed by Lehmann, and also in a different form by Pearl. Benferhat et al. (1992) have shown that this ordering can be retrieved by means of the least specific possibility distribution that is consistent with the rules. Namely let K be a conditional knowledge base where rules are of the form Ai l'v Bi (read if A 1 is true, B1 is plausibly true). Each rule is interpreted as the constraint N(BiiAj) >0 or equivalently IT(A1AB1) > IT(A1A\u2022B1). Then the ranking of the interpretation obtained by considering the maximal element of the set { 1t, fl(AiAB1) > Il(AiA'Bi), V'i=l ,n}. This possibility distribution is unique and is denoted 1t*. Then the level of priority of rule (A1,B1) is simply computed as N*(\u2022A1vB1) (computed from n*). Then given evidence A, and knowledge K, B is a plausible conclusion of A in the context B if and only if N*(BIA) > 0, i.e. Il*(BAA) > IT*(\u2022BAA). This procedure suffers from the problem of blocking of property inheritance as shown in the following example.\nK = (p 1'v ..,f, b 1'v f, p fv b, b l'v I} where p =penguin, b = bird, f = fly, I = legs. It is well-established that the rational inference method classifies the rules of K into 2 sets of rule: {b 1'v f, b 1'v I} have lower priority than {p l'v \u2022f, p l'v b }. It can be encoded in possibilistic logic as N(\u2022bvl) \ufffd o:; N(\u2022bvf) \ufffd o:; N(\u2022pv\u2022f) \ufffd p; N(pvb) \ufffd p, with p > 0:. The corresponding minimally specific ranking is such that IT*(pAI) = IT*(pA...,l), hence forbidding the conclusion that penguins have legs, despite the fact that the rule b l'v I is not involved in the conflict between penguins and birds with respect to flying. Several solutions have been suggested to solve this problem including maximal entropy rankings, lexicographic methods and others. Here we suggest that weak independence solves the problem.\nConsider the graph induced by the rules of K.\n202 Dubois, Farinas del Cerro, Herzig, and Prade\nAny Bayesian-oriented AI researcher would suggest that I is conditionally independent of p in the context of birds (which is clearly not true for f). This is intuitive as well: If we learn that some bird is in fact a penguin, this does not influence our belief that it has legs. The conditional extension of weak independence reads\nN(llb) > 0 and N(llb/\\p) > 0.\nHere it leads to add the rule P-\"b 1--- I to K, i.e., to select another ranking of worlds that satisfies also 00-\"P-\"b) > Il(-..1-\"P-\"b) the level of priority of this rule will be the same as p 1--- b and p 1--- -.f. It is clear then that from p and K u {p-\"b 1--- I} one can deduce I plausibly.\nThere is no space to develop this point in detail here. However we plan to develop this methodology in the future (see, e.g. (Benferhat et al. 1994) for preliminary results). A first remark is that we do not use strong independence here. Strong independence would have two drawbacks\n1) It would introduce equality constraints (here of the form N(llp/\\b);;:; N(llb)) whose nature is different from that of the rules. As a consequence looking for the minimally specific possibility distribution that satisfies both rule-constraints and independence constraints may not lead to a unique solution. This is the problem already encountered by Goldzsmidt and Pearl (1992) with stratified rankings. The weak independence notion avoids this drawback. 2) It forbids the possibility of adding some contraposed rules since N(llp/\\ b) ;;:; N(llb) > 0 implies that Il(p-\"-..1/\\b) \ufffd Il(-..p/\\-.)1\\b), i.e., it is forbidden to claim that \"birds without legs are not penguins\" which seems to be a natural claim in the context of birds.\nThe idea of adding weak independence relationships to a rule base is to take advantage of the graphical structure of the knowledge base, as Bayesians do, and add just what is necessary. Part of the work is already done by the rational monotony property, i.e. N(AIB) > 0 and N(-.CIB);;:; 0 does imply N(AIB/\\C) > 0. However more conditional independence assertions are needed to overcome problems such as blocking of property inheritance. The problem is not to add too many assertions so as to avoid inconsistencies. Clearly we should stop imperatively once a total ordering of worlds is obtained. On the other hand the specification of conditional independence relation is extremely flexible and would enable to have tailored solutions to many inheritance problems. For instance if we add a bird that has no legs (n) to the above knowledge base, with rules saying that n 1--- -.1, and n fv b, we can solve the problem by \"reading on the graph\" the proper conditional independence assertions while most other approaches would fail due to the presence of two conflicts.\nHowever we cannot adapt the Bayesian methods readily for several reasons: here nodes of the graph are literals (not propositional variables), and cycles should be allowed (we must be able to say that \"students are young\" but \"young people are not usually students\"). Moreover there is no result that allow us to aggregate (via the min operation) a\nconditional possibility distribution into a global joint one (see, e.g., Fonck 1993). A third reason is that the weak independence relation is non-symmetric, i.e will not be a graphoid. Hence the mastering of weak conditional independence in the possibilistic setting for the purpose of handling exception-tolerant rule-bases is an open line of research, although a promising one.\n8 CONCLUSION\nThis paper has provided a preliminary but systematic study of independence in the framework of possibility theory when conditioning is defined in an ordinal way (via the min-operation). The case where conditional possibility is defined as O(A\"C);;:; il(CIA)\u00b7O(A) using product instead of min has been left for further research. It is also worth noticing that we have been working with events (or formulas) and not with variables (see (Studeny 1993) for an overview of the latter approach). It is well-known that in the probabilistic framework, the independence of A and B means, in terms of relative frequency, that the number of cases where A is true over the number of cases where A is false is left unchanged when B is known to be true. In the view of independence presented here, it can be checked that an analog property holds in terms of orderings: The possibilistic ordering between the interpretations with the greatest possibility which make A true and those which make A false is left unchanged when we restrict ourselves to interpretations where B is true. Besides, the transparency of probabilistic conditioning with respect to negation is closely related to the compositionality of probabilities with respect to negation. Similarly, the remarkable behavior of the possibilistic dependence and independence with respect to disjunction or conjunction stems from the fact that possibility measures are compositional with respect to disjunction, and necessity measures with respect to conjunctions.\nREFERENCES\nS. Benferhat, D. Dubois, H. Prade (1992) Representing default rules in possibilistic logic. Proc. KR'92 (B. Nebel et al. eds.), Cambridge, MA, Morgan & Kaufmann, San Mateo, 673-684.\nS. Benferhat, D. Dubois, H. Prade (1994) Expressing independence in a possibilistic framework and its application to default reasoning. Proc. ECA/'94, 150-154.\nR. Carnap ( 1950) Logical Foundations of Probability. University of Chicago Press.\nD. Dubois (1986) Belief structures, possibility theory, decomposable confidence measures on finite sets. Computer and Artificial Intelligence, 5(5), 403-417.\nD. Dubois, H. Prade (1986) Possibilistic inference under matrix form. In: F uzzy Logic in Knowledge Engineering (H. Prade, C.V. Negoita, eds.), Verlag TOV Rheinland, Ktiln, 112-126.\nD. Dubois, H. Prade ( 1988) Possibility Theory. Plenum Press, New York.\nAn Ordinal View of Independence with Application to Plausible Reasoning 203\nD. Dubois, H. Prade ( 1991) Epistemic entrenchment and possibilistic logic. J. of AI, 50, 223-239.\nD. Dubois, H. Prade ( 1992) Belief change and possibility theory. In: Belief Revision (P. Gardenfors, ed.), Cambridge University Press, 142-182.\nL. Farinas del Cerro, A. Herzig ( 1991) A modal analysis of possibility theory. LNCS, Vol. 535, Springer Verlag, Berlin, 11- 1 8.\nL. Farinas del Cerro, A. Herzig (1993) Interference logic = conditional logic + frame axiom. LNCS, VoL 747, Springer Verlag, Berlin, 105- 1 12.\nL . Farinas del Cerro, A. Herzig ( 1994a) Conditional possibility and dependence. Proc. IPMU-94, Paris, July 4-8.\nL. Farinas del Cerro, A. Herzig ( 1994b) Belief change and dependence. Internal Report, IRIT, Feb. 1 994.\nT. Fine (1973) Theories of Probability. Academic Press, New York.\nP. Fonck (1993) Reseaux d'inference pour le raisonnement possibiliste. Dissertation, Univ. of Liege, Belgium.\nP. Gardenfors ( 1978) On the logic of relevance. Synthese, 351-367.\nP. Giirdenfors (1990) Belief revision and irrelevance. PSA, 2 , 349-356.\nP. Gardenfors, D. Makinson ( 1 994) Nonmonotonic inference based on expectation ordering. J. of AI, 65, 197-245.\nM. Goldzsmidt, J. Pearl (1992) Rank-based systems: A simple approach to belief revision, belief update, and reasoning about evidence and actions. Proc. KR'92 (B. Nebel et al. eds. ) , Cambridge, MA, Morgan & Kaufmann, San Mateo, 661-672.\nE. Hisda1 (1978) Conditional possibilities, independence and noninteraction. Fuzzy Sets & Syst. , 1, 283-297.\nJ. M. Keynes (1921) A Treatise on Probability. MacMillan, London.\nA. Kolmogorov ( 1956) Foundations of the Theory of Probability. Chelsea, Bronx, New York.\nD. Lehmann ( 1989) What does a conditional knowledge base entail? Proc. KR'89 (R.I. Brachman et al. eds.), Morgan & Kaufmann, San Mateo, CA, 212-222.\nD. Lewis ( 1973) Counteifactuals. Blackwell, Oxford.\nR. von Mises, H. Geiringer ( 1964) The Mathematical Theory of Probability and Statistics. Academic Press, New York, 7-43.\nS. Nahmias ( l978) Fuzzy variables. Fuzzy Sets and Systems, 1 (2), 97- 1 1 0.\nJ. Pearl ( 1 988) Probabilistic Reasoning in Intelligent Systems Morgan & Kaufmann, San Mateo, CA.\nJ. Pearl ( 1990) System Z: A natural ordering of defaults with tractable applications to default reasoning. Proc. TARK-3 (M. Vardi, ed.), Morgan & Kaufmann, San Mateo, CA, 12 1-135.\nH. Reichenbach ( 1949) Theory of Probability. University of California Press, Berkeley.\nD. Scott (1964) Measurement structures and linear inequalities. J. of Math. Psychology, I, 233-247.\nK. Segerberg (1971) Qualitative probability in a modal setting. Proc. 2nd Scandinavian Logic Symp. (J.E. Fenstad, ed.), North-Holland, Amsterdam.\nM. Studeny (1993) Formal properties of conditional independence in different calculi of AI. LNCS, Vol. 747, Springer Verlag, Berlin, 341 -348.\nY. Shoham (1988) Reasoning About Change. The MIT Press, Cambridge, MA.\nL.A. Zadeh (1978), Fuzzy sets as a basis for a theory of possibility. Fuzzy Sets and Systems, 1, 3-28."}], "references": [{"title": "Representing default rules in possibilistic logic", "author": ["S. Benferhat", "D. Dubois", "H. Prade"], "venue": "Proc. KR'92 (B. Nebel et al. eds.),", "citeRegEx": "Benferhat et al\\.,? \\Q1992\\E", "shortCiteRegEx": "Benferhat et al\\.", "year": 1992}, {"title": "Expressing independence in a possibilistic framework and its application to default reasoning", "author": ["S. Benferhat", "D. Dubois", "H. Prade"], "venue": "Proc. ECA/'94,", "citeRegEx": "Benferhat et al\\.,? \\Q1994\\E", "shortCiteRegEx": "Benferhat et al\\.", "year": 1994}, {"title": "Belief structures, possibility theory, decomposable confidence measures on finite sets", "author": ["D. Dubois"], "venue": "Computer and Artificial Intelligence,", "citeRegEx": "Dubois,? \\Q1986\\E", "shortCiteRegEx": "Dubois", "year": 1986}, {"title": "Possibilistic inference under matrix form. In: F uzzy Logic in Knowledge Engineering (H", "author": ["D. Dubois", "H. Prade"], "venue": "Verlag TOV Rheinland,", "citeRegEx": "Dubois and Prade,? \\Q1986\\E", "shortCiteRegEx": "Dubois and Prade", "year": 1986}, {"title": "Epistemic entrenchment and possibilistic logic", "author": ["D. Dubois", "H. Prade"], "venue": "J. of AI,", "citeRegEx": "Dubois and Prade,? \\Q1991\\E", "shortCiteRegEx": "Dubois and Prade", "year": 1991}, {"title": "Belief change and possibility theory", "author": ["D. Dubois", "H. Prade"], "venue": "Belief Revision (P. Gardenfors,", "citeRegEx": "Dubois and Prade,? \\Q1992\\E", "shortCiteRegEx": "Dubois and Prade", "year": 1992}, {"title": "A modal analysis of possibility", "author": ["L. Farinas del Cerro", "A. Herzig"], "venue": "theory. LNCS,", "citeRegEx": "Cerro and Herzig,? \\Q1991\\E", "shortCiteRegEx": "Cerro and Herzig", "year": 1991}, {"title": "Interference logic = conditional logic + frame", "author": ["L. Farinas del Cerro", "A. Herzig"], "venue": "axiom. LNCS,", "citeRegEx": "Cerro and Herzig,? \\Q1993\\E", "shortCiteRegEx": "Cerro and Herzig", "year": 1993}, {"title": "Conditional possibility and dependence", "author": ["L . Farinas del Cerro", "A. Herzig"], "venue": "Proc. IPMU-94, Paris,", "citeRegEx": "Cerro and Herzig,? \\Q1994\\E", "shortCiteRegEx": "Cerro and Herzig", "year": 1994}, {"title": "Reseaux d'inference pour le raisonnement possibiliste", "author": ["P. Fonck"], "venue": "Dissertation, Univ. of Liege, Belgium", "citeRegEx": "Fonck,? \\Q1993\\E", "shortCiteRegEx": "Fonck", "year": 1993}, {"title": "Rank-based systems: A simple approach to belief revision, belief update, and reasoning about evidence and actions", "author": ["J.M. Goldzsmidt"], "venue": "Proc. KR'92 (B. Nebel et al. eds", "citeRegEx": "Goldzsmidt,? \\Q1992\\E", "shortCiteRegEx": "Goldzsmidt", "year": 1992}, {"title": "Conditional possibilities, independence and noninteraction", "author": ["E. Hisda"], "venue": "Fuzzy Sets & Syst. ,", "citeRegEx": "Hisda1,? \\Q1978\\E", "shortCiteRegEx": "Hisda1", "year": 1978}, {"title": "What does a conditional knowledge base entail", "author": ["D. Lehmann"], "venue": "Proc. KR'89 (R.I. Brachman et al. eds.),", "citeRegEx": "Lehmann,? \\Q1989\\E", "shortCiteRegEx": "Lehmann", "year": 1989}, {"title": "System Z: A natural ordering of defaults with tractable applications to default reasoning", "author": ["J. Pearl"], "venue": "Proc. TARK-3 (M. Vardi, ed.),", "citeRegEx": "Pearl,? \\Q1990\\E", "shortCiteRegEx": "Pearl", "year": 1990}, {"title": "Measurement structures and linear inequalities", "author": ["D. Scott"], "venue": "J. of Math. Psychology,", "citeRegEx": "Scott,? \\Q1964\\E", "shortCiteRegEx": "Scott", "year": 1964}, {"title": "Qualitative probability in a modal setting", "author": ["K. Segerberg"], "venue": "Proc. 2nd Scandinavian Logic Symp. (J.E. Fenstad, ed.),", "citeRegEx": "Segerberg,? \\Q1971\\E", "shortCiteRegEx": "Segerberg", "year": 1971}, {"title": "Formal properties of conditional independence in different calculi", "author": ["M. Studeny"], "venue": "of AI. LNCS,", "citeRegEx": "Studeny,? \\Q1993\\E", "shortCiteRegEx": "Studeny", "year": 1993}, {"title": "Reasoning About Change", "author": ["Y. Shoham"], "venue": null, "citeRegEx": "Shoham,? \\Q1988\\E", "shortCiteRegEx": "Shoham", "year": 1988}, {"title": "Fuzzy sets as a basis for a theory of possibility", "author": ["L.A. Zadeh"], "venue": "Fuzzy Sets and Systems,", "citeRegEx": "Zadeh,? \\Q1978\\E", "shortCiteRegEx": "Zadeh", "year": 1978}], "referenceMentions": [{"referenceID": 2, "context": ", Dubois and Prade (1986), a function ll from 20.", "startOffset": 2, "endOffset": 26}, {"referenceID": 0, "context": "See (Benferhat et al. 1992).", "startOffset": 4, "endOffset": 27}, {"referenceID": 13, "context": "This way of modelling uncertainty is in full accordance with Shoham (1988)'s view of preferential logic, Lehmann (1989)'s notion of ranked models, also encoded in Pearl ( 1990)'s system Z.", "startOffset": 61, "endOffset": 75}, {"referenceID": 10, "context": "This way of modelling uncertainty is in full accordance with Shoham (1988)'s view of preferential logic, Lehmann (1989)'s notion of ranked models, also encoded in Pearl ( 1990)'s system Z.", "startOffset": 105, "endOffset": 120}, {"referenceID": 2, "context": "That these conditions are sufficient follows from the following formal relation between possibility theory and qualitative possibility orderings (Dubois 1986): The only functions mapping events into [0, 1] which strictly agree with qualitative possibility orderings are possibility measures, and a strictly agreeing possibility measure always exists.", "startOffset": 145, "endOffset": 158}, {"referenceID": 2, "context": "But as indicated in Dubois and Prade (1991) a system of spheres is equivalent to a possibility distribution.", "startOffset": 20, "endOffset": 44}, {"referenceID": 2, "context": "But as indicated in Dubois and Prade (1991) a system of spheres is equivalent to a possibility distribution. Formal links between possibility theory and conditional logics are studied in Farinas del Cerro and Herzig (1991). Lastly, the dual qualitative certainty relation, equivalent to necessity measures (A ;;>:N C iff .", "startOffset": 20, "endOffset": 223}, {"referenceID": 2, "context": "But as indicated in Dubois and Prade (1991) a system of spheres is equivalent to a possibility distribution. Formal links between possibility theory and conditional logics are studied in Farinas del Cerro and Herzig (1991). Lastly, the dual qualitative certainty relation, equivalent to necessity measures (A ;;>:N C iff ...,c ;:: -,A) is closely related to expectation-orderings of Gardenfors and Makinson (1994). The characteristic axiom of ;:: N is", "startOffset": 20, "endOffset": 414}, {"referenceID": 5, "context": "It can be proved that in terms of possibility theory the fact that C belongs to K* A is equivalent to having N(CIA) > 0 (Dubois and Prade, 1992); moreover C belongs to K is equivalent to N(C) > 0.", "startOffset": 120, "endOffset": 144}, {"referenceID": 0, "context": "Benferhat et al. (1992) have shown that this ordering can be retrieved by means of the least specific possibility distribution that is consistent with the rules.", "startOffset": 0, "endOffset": 24}, {"referenceID": 1, "context": "(Benferhat et al. 1994) for preliminary results).", "startOffset": 0, "endOffset": 23}, {"referenceID": 10, "context": "This is the problem already encountered by Goldzsmidt and Pearl (1992) with stratified rankings.", "startOffset": 43, "endOffset": 71}, {"referenceID": 16, "context": "It is also worth noticing that we have been working with events (or formulas) and not with variables (see (Studeny 1993) for an overview of the latter approach).", "startOffset": 106, "endOffset": 120}], "year": 2011, "abstractText": "An ordinal view of independence is studied in the framework of possibility theory. We investigate three possible definitions of dependence, of increasing strength. One of them is the counterpart to the multiplication law in probability theory, and the two others are based on the notion of conditional possibility. These two have enough expressive power to support the whole possibility theory, and a complete axiomatization is provided for the strongest one. Moreover we show that weak independence is well-suited to the problems of belief change and plausible reasoning, especially to address the problem of blocking of property inheritance in exception-tolerant taxonomic reasoning.", "creator": "pdftk 1.41 - www.pdftk.com"}}}