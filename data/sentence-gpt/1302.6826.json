{"id": "1302.6826", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "27-Feb-2013", "title": "Using New Data to Refine a Bayesian Network", "abstract": "We explore the issue of refining an existent Bayesian network structure using new data which might mention only a subset of the variables. Most previous works have only considered the refinement of the network's conditional probability parameters, and have not addressed the issue of refining the network's structure. We develop a new approach for refining the network's structure using new data which might include the conditional probabilities of any variable in our model.\n\n\n\n\nThe Bayesian model is the basis for a theory of how the Bayesian Bayesian model is used to describe all variables in the model, including the Bayesian Bayesian distribution and the distribution of probabilities for all variables in the model. The model is modeled using the Bayesian Bayesian model.\nIn some cases, the Bayesian model is considered to be an approximation of the Bayesian distribution (a term typically used to describe other models). Bayesian models are based on the Bayesian model and the Bayesian model (a term generally used to describe other models).\nThe Bayesian model is a hierarchical method of modeling the distributions of probabilities. A simple, non-parametric model is a non-parametric model with no parameters.\nWe call this Bayesian model a model of the distributions of probability. The model is modeled using the Bayesian model.\nThe Bayesian model is a hierarchical method of modeling the distributions of probability. A simple, non-parametric model is a non-parametric model with no parameters. The model is based on the Bayesian model.\nThe model is a hierarchical method of modeling the distributions of probability. A simple, non-parametric model is a non-parametric model with no parameters. A simple, non-parametric model is a non-parametric model with no parameters. A simple, non-parametric model is a non-parametric model with no parameters.\nThe Bayesian model is a hierarchical method of modeling the distributions of probability. A simple, non-parametric model is a non-parametric model with no parameters. The model is a hierarchical method of modeling the distributions of probability. A simple, non-parametric model is a non-parametric model with no parameters. A simple, non-parametric model is a non-parametric model with no parameters. The model is a non-parametric model with no parameters.\nThe model is a non-parametric model with no parameters. The model is a non-parametric model with no parameters. A simple, non-parametric model is", "histories": [["v1", "Wed, 27 Feb 2013 14:17:54 GMT  (833kb)", "http://arxiv.org/abs/1302.6826v1", "Appears in Proceedings of the Tenth Conference on Uncertainty in Artificial Intelligence (UAI1994)"]], "COMMENTS": "Appears in Proceedings of the Tenth Conference on Uncertainty in Artificial Intelligence (UAI1994)", "reviews": [], "SUBJECTS": "cs.AI", "authors": ["wai lam", "fahiem bacchus"], "accepted": false, "id": "1302.6826"}, "pdf": {"name": "1302.6826.pdf", "metadata": {"source": "CRF", "title": "Using New Data to Refine a Bayesian Network*", "authors": ["Wai Lam", "Fahiem Bacchus"], "emails": [], "sections": null, "references": [{"title": "Learning and Refining Bayesian Network Structures from Data", "author": ["Wai Lam"], "venue": "PhD thesis, The University of Waterloo,", "citeRegEx": "Lam.,? \\Q1994\\E", "shortCiteRegEx": "Lam.", "year": 1994}, {"title": "Learning Bayesian belief networks - an approach based on the MDL principle", "author": ["W. Lam", "F. Bacchus"], "venue": "Technical Report CS-92-39,", "citeRegEx": "Lam and Bacchus.,? \\Q1992\\E", "shortCiteRegEx": "Lam and Bacchus.", "year": 1992}, {"title": "Using causal infor\u00ad mation and local measure to learn Bayesian networks", "author": ["W. Lam", "F. Bacchus"], "venue": "In Proceedings of the Confer\u00ad ence on Uncertainty in Artificial Intelli\u00ad gence,", "citeRegEx": "Lam and Bacchus.,? \\Q1993\\E", "shortCiteRegEx": "Lam and Bacchus.", "year": 1993}, {"title": "Minimal assumption distribu\u00ad tion propagation in Belief networks", "author": ["R. Musick"], "venue": "In Proceedings of the Conference on Uncer\u00ad tainty in Artificial Intelligence,", "citeRegEx": "Musick.,? \\Q1993\\E", "shortCiteRegEx": "Musick.", "year": 1993}, {"title": "Infer\u00ad ring decision trees using the minimum de\u00ad scription length principle", "author": ["J.R. Quinlan", "R. 1. Rivest"], "venue": "Information and Computation,", "citeRegEx": "Quinlan and Rivest.,? \\Q1989\\E", "shortCiteRegEx": "Quinlan and Rivest.", "year": 1989}, {"title": "Stochastic Complezity in Sta\u00ad tistical Inquiry", "author": ["J. Rissanen"], "venue": "World Scientific,", "citeRegEx": "Rissanen.,? \\Q1989\\E", "shortCiteRegEx": "Rissanen.", "year": 1989}, {"title": "Learn\u00ad ing in probabilistic expert systems", "author": ["D.J. Spiegelhalter", "R.G. Cowell"], "venue": "In Bayesian Statistics", "citeRegEx": "Spiegelhalter and Cowell.,? \\Q1992\\E", "shortCiteRegEx": "Spiegelhalter and Cowell.", "year": 1992}, {"title": "Se\u00ad quential updating of conditional probabilities on directed graphical structures", "author": ["D.J. Spiegelhalter", "S.L. Lauritzen"], "venue": "Net\u00ad works,", "citeRegEx": "Spiegelhalter and Lauritzen.,? \\Q1990\\E", "shortCiteRegEx": "Spiegelhalter and Lauritzen.", "year": 1990}, {"title": "Equivalence and synthesis of causal models", "author": ["T. Verma", "J. Pearl"], "venue": "In Proceedings of the Conference on Uncertainty in Artifi\u00ad cial Intelligence,", "citeRegEx": "Verma and Pearl.,? \\Q1990\\E", "shortCiteRegEx": "Verma and Pearl.", "year": 1990}], "referenceMentions": [], "year": 2011, "abstractText": "We explore the issue of refining an exis\u00ad tent Bayesian network structure using new data which might mention only a subset of the variables. Most previous works have only considered the refinement of the net\u00ad work's conditional probability parameters, and have not addressed the issue of refin\u00ad ing the network's structure. We develop a new approach for refining the network's structure. Our approach is based on the Minimal Description Length (MDL) princi\u00ad ple, and it employs an adapted version of a Bayesian network learning algorithm de\u00ad veloped in our previous work. One of the adaptations required is to modify the previ\u00ad ous algorithm to account for the structure of the existent network. The learning algo\u00ad rithm generates a partial network structure which can then be used to improve the exis\u00ad tent network. We also present experimental evidence demonstrating the effectiveness of our approach.", "creator": "pdftk 1.41 - www.pdftk.com"}}}