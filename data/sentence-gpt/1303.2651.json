{"id": "1303.2651", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "10-Mar-2013", "title": "Hybrid Q-Learning Applied to Ubiquitous recommender system", "abstract": "Ubiquitous information access becomes more and more important nowadays and research is aimed at making it adapted to users. Our work consists in applying machine learning techniques in order to bring a solution to some of the problems concerning the acceptance of the system by users. To achieve this, we propose a fundamental shift in terms of how we model the learning of recommender system: inspired by models of human reasoning developed in robotic, we combine reinforcement learning and case-base reasoning to define a recommendation process that uses these two approaches for generating recommendations on different context dimensions (social, temporal, geographic). We describe an implementation of the recommender system based on this framework. We also present preliminary results from experiments with the system and show how our approach increases the recommendation quality.", "histories": [["v1", "Sun, 10 Mar 2013 12:51:03 GMT  (501kb)", "http://arxiv.org/abs/1303.2651v1", "arXiv admin note: substantial text overlap witharXiv:1301.4351,arXiv:1303.2308"], ["v2", "Sun, 30 Mar 2014 08:26:31 GMT  (497kb)", "http://arxiv.org/abs/1303.2651v2", "arXiv admin note: substantial text overlap witharXiv:1301.4351,arXiv:1303.2308"]], "COMMENTS": "arXiv admin note: substantial text overlap witharXiv:1301.4351,arXiv:1303.2308", "reviews": [], "SUBJECTS": "cs.LG cs.IR", "authors": ["djallel bouneffouf"], "accepted": false, "id": "1303.2651"}, "pdf": {"name": "1303.2651.pdf", "metadata": {"source": "CRF", "title": "Hybrid Q-Learning Applied to Ubiquitous recommender system", "authors": ["D. Bouneffouf"], "emails": ["Djallel.Bouneffouf@it-sudparis.eu"], "sections": [{"heading": null, "text": "nowadays and research is aimed at making it adapted to users. Our work consists in applying machine learning techniques in order to bring a solution to some of the problems concerning the acceptance of the system by users. To achieve this, we propose a fundamental shift in terms of how we model the learning of recommender system: inspired by models of human reasoning developed in robotic, we combine reinforcement learning and case-base reasoning to define a recommendation process that uses these two approaches for generating recommendations on different context dimensions (social, temporal, geographic). We describe an implementation of the recommender system based on this framework. We also present preliminary results from experiments with the system and show how our approach increases the recommendation quality.\nCategories and Subject Descriptors H.3.3 [Information Search and Retrieval]: information filtering, Selection process, Relevance feedback .\nGeneral Terms Algorithms\nKeywords Context awareness, machine learning, user acceptance, recommender system"}, {"heading": "1. INTRODUCTION", "text": "The need for adapting information systems to the user context has been accentuated by the extensive development of mobile applications that provide a considerable amount of data of all types (images, texts, sounds, videos, etc.). It becomes thus crucial to help users by guiding them in their access to information.\nSystems should be able to recommend information helping the user to fulfill his/her goal. The information given by the system depends on the user\u2019s situation, i. e. an instance of the context. Possible situations and the associated actions reflect the user\u2019s work habits.\nMajor difficulties when applying techniques to adapt a system to the user follow: - Avoiding the intervention of experts: on one hand, experts are not sure of the interest of the user, may define wrong ideas about him; on the other hand, an expert is not always available. - Starting from scratch: in the initial state, the system\u2019s behavior should not be incoherent for the user to not refuse it quickly. - A slow learning process: the learning process has to be quick to avoid bothering the user with incorrect recommendation. -The evolution of the user\u2019s interest: the interest of the user may change with the time. The system has to be continuously adapted to this dynamic change using the user\u2019s context information to provide the relevant recommendations because, if the system behavior is incoherent, the user refuses it quickly.\nWe sum up all of these problems in the following scenario. Senario. Given the company Nomalys, the set of marketing staff people can access to the most relevant data of their company via their mobile phone. Paul is a new sales representative of the company; he is integrating a team of ten marketing staff members. Our recommender system has to retrieve the relevant information to this user to help him for doing his job.\nTo solve the problem of the scenario, our recommender system has to retrieve information about the user and his context from his mobile device that user brings into the environment. The system uses the context knowledge to propose relevant information to the user. For instance, regarding Paul\u2019s agenda, Paul has a meeting with a client in Paris at midday. When he arrives at his meeting, the system should recommend him the client\u2019s register of complaints, which would help Paul to better manage his meeting.\nOur system starts with a predefined set of actions defined by the user\u2019s social group and adapts it progressively to a particular user. This default behavior allows the system to be ready-to-use and the learning is a lifelong process. Thus, the system will, at first, be only acceptable to the user, and will, as time passes, give more\nand more satisfying results.\nIn summary, the recommender system observes the user and gets information from his context and his activity. For that it needs perceptive sensor modules capable of providing this kind of information. Our ubiquitous system is composed of sensor modules which can fire events, received by the recommender system. This input allows the recommender system to estimate the user\u2019s situation. The default behavior, possibly modified by acquired experience, indicates to the recommender system how to act in a certain situation. When the appropriate action is chosen, the recommender system executes it.\nIn the remaining of this paper, Section 2 is dedicated to the state of the art. Then, in section 3, we describe the current ideas of our ongoing work, followed by results in Section 4. Finally, we conclude, giving directions for future work."}, {"heading": "2. State of the art", "text": "The trend today on recommendation systems is to recommend relevant information to users, using supervised machine learning techniques. In that type of techniques, the recommender system has to pass by two steps: (1) The learning step, where examples are presented to the system; which \"learns\" from examples and gradually adjusts its parameters to the desired output. (2)Exploitation step: new examples never seen before are presented to the system and ask it for generalizing [10]. These approaches have good results. However, they need an amount of experience provided by an expert. They cannot start from scratch and they are slow. Moreover, the user\u2019s interest can change with the time, and the techniques cannot really follow this. Some works found in literature try to solve those problems, as explained in what follows.\n-Starting from scratch: to avoid this problem, which is commune to machine learning algorithms, in [7] authors use collaborative filtering to consider demographic information about users for providing them more accurate prediction, but their system does not follow the user\u2019s interest evolution. - Avoiding the intervention of experts: To avoid the intervention of an expert, in [9] the authors use Reinforcement Learning (RL), which is a good alternative because it does not need a previous experience to start work. However, a major difficulty when applying RL techniques to real world problems is their slow convergence. -Accelerate the learning process: In [9], the author proposes to accelerate RL by using indirect Q-learning. However, their recommendation system starts with a set of actions which are predefined by them. -The evolution of the user\u2019s interest: The authors on [19] propose to follow the interest of the user by using an exploration strategy on the q-learning algorithm. But they don\u2019t care about the others problems cited above. We can observe that each work cited above tries to solve only one of those problems and none of them proposes to solve all of them at the same time. To create a system avoiding all the problems, we propose to use the Q-learning algorithm with an exploration strategy to solve the problem of intervention of an expert and follow the user\u2019s interest evolution. For the starting from scratch problem, we give Qlearning algorithm the ability to explore the knowledge of other users by using collaborative filtering. To accelerate the Q-learning process, we mix it with case base reasoning techniques to allow the reuse of the case-base and satisfy the user more quickly. We were inspired by case base reasoning to accelerate reinforcement learning techniques introduced and implemented by [11] in robotic."}, {"heading": "3. Proposition", "text": ""}, {"heading": "3.1 Reinforcement learning and the Qlearning algorithm", "text": "The goal of the agent in a RL problem is to learn an optimal policy \u03c0\u2217: S \u2192 A that maps the current state s into the most desirable action a to be performed in s. One strategy to learn the optimal policy \u03c0\u2217 is to allow the agent to learn the evaluation function Q: S \u00d7 A \u2192 R. Each action value Q(s, a) represents the expected cost incurred by the agent when taking action a at state s and following an optimal policy thereafter. The Q\u2013learning algorithm [14] is a well-know RL technique that uses a strategy to learn an optimal policy \u03c0* via learning of the action values. It iteratively approximates Q, provided the system can be modeled as a Markov decision process (MDP), the reinforcement function is bounded, and actions are chosen so that every state-action pair can visit an infinite number of times. The Q-learning update rule is: Q(s, a) \u2190 Q(s, a) + \u03b1[r + \u03b3 maxa\u2032Q(s\u2032, a\u2032) \u2212 Q(s, a)] , (1) where s is the current state; a is the action performed in s; r is the\nreward received; s\u2032 is the new state; \u03b3 is the discount factor (0 \u2264 \u03b3\n< 1); and \u03b1 is the learning rate."}, {"heading": "3.2 Collaborative filtering", "text": "A Collaborative Filtering (CF) recommender system works as\nfollows. Given a set of transactions D, where each transaction T is\nof the form <id, item, rating>, a recommender model M is\nproduced. Each item is represented by a categorical value, while\nthe rating is a numerical value in a given scale (e.g. each item is a\nmovie rated with 1 to 5 stars). Such a model M can produce a list\nof top-N recommended items, and corresponding predicted\nratings, from a given set of known ratings [4]. In many situations,\nratings are not explicit. For example, if we want to recommend\nWeb pages to a Web site visitor, we can use the set of pages she\nor he has visited, assigning those pages an implicit rate of one,\nand zero to all the other pages.\nIn terms of CF, three major classes of algorithms exist: Memory-\nbased, Model-based and Hybrid-based [1, 4]. At the moment, in\nour work, we use the simplest of them which is the memory-based\nCF. In memory-based CF, the whole set of transactions is stored\nand is used by the recommender model. These algorithms employ\na notion of distance to find a set of users, known as neighbors,\nwho tend to agree with the target user. The preferences of\nneighbors are then combined to produce a prediction or top-N\nrecommendation for the active user."}, {"heading": "3.3 Case Based Reasoning", "text": "Case based reasoning (CBR) [12, 13] uses knowledge of previous situations (cases) to solve new problems, by finding a similar past case and reusing it in the new problem situation. According to Lopez de Mantaras et al [12], solving a problem by CBR involves \u201cobtaining a problem description, measuring the similarity of the current problem to previous problems stored in a case base with their known solutions, retrieving one or more similar cases, and attempting to reuse the solution of the retrieved case(s), possibly after adapting it to account for differences in problem descriptions\u201d. This is some works found in the literature which use this technique [17, 18]."}, {"heading": "3.4 The hybrid Q-learning (HyQL)", "text": "We improve the performance of the Q-learning, in the following point: -Reuse case: To accelerate the Q-learning algorithm, we propose to integrate CBR in the loop of the Q-learning algorithm. For each step of Q-learning, before choosing the best action, the algorithm computes the similarity and, if there is a case that can be reused, the algorithm retrieves and adapts it. -Using social group: In the Q-Learning algorithm, it is said that, for every state s, action a = Q (s) is chosen according to the current policy. The choice of the action by the policy must ensure a balance between exploration and exploitation. The exploitation is to choose the best action for the current state, thus exploiting the system\u2019s knowledge. The exploration is to choose an action other than the best one in order to test it, observe its consequences, and increase the knowledge of the system. There are several strategies to make the balance between exploration and exploitation. Here, we focus on two of them: the greedy strategy chooses always the best action from the Q-table; the \u03b5-greedy strategy adds some greedy exploration policy, choosing a random action at each step if the policy returns the greedy action (probability \u03b5) or a random action (probability 1 - \u03b5). To give the Q-Learning the ability to use advices from other users sharing the same ideas, we propose to extend the -\u03b5-greedy strategy of the Q-Learning algorithm with the ability to explore the knowledge of other users. In the -\u03b5-greedy strategy of the exploration/exploitation functions, we replace the random action by an action that is selected by calculating the similarity of user profiles applying the CF algorithm. The equation 2 shows how it is done.\nargmaxa Q(s, a) if q \u2264 p,\n\u03c0(s) = (2)\na users advises otherwise\nIn equation 2: \u2013 q is a random value uniformly distributed over [0, 1] and p (0 \u2264 p \u2264 1) is a parameter that defines the exploration/exploitation tradeoff: the larger is p, the smaller is the probability of executing a random exploratory action. \u2013 a users advises is an action chosen among those available in state s by applying the CF algorithm.\nThe complete proposed hybrid Q-learning algorithm, called HyQL algorithm follows. The HyQL algorithm:\nInitialize Qt(s, a) arbitrarily. Repeat (for each episode):\nInitialize s. Repeat (for each step):\nCompute similarity and cost. If there is a case that can be reused:\nRetrieve and adapt if necessary.\nSelect an action a using equation 2. Execute the action a, observe r(s, a), s\u2032. Update the values of Q(s, a) according to equation 1.\ns  s\u2032. Until s is terminal.\nUntil some stopping criterion is reached."}, {"heading": "4. Global mechanism", "text": "To evaluate our algorithm we implement it in a ubiquitous recommender system. Figure 1 summarizes the global mechanism of the recommender system. To detect the user\u2019s context, the recommender system receives events from the sensor module. These events constitute the input of the recommendation system and launch the reasoning module. Based on this input, the reasoning module allows choosing an action to be executed in the environment."}, {"heading": "4.1 Environment", "text": "We consider the environment being composed of all context dimensions described in [5], namely cognitive, time, geographic, material, social, source document, qualitative, psychological, and demographic."}, {"heading": "4.2 Sensor module", "text": "In our work, the sensor module detects time, geographic, social, and cognitive dimensions of the context in the following way:\n(1) The cognitive dimension is given by all the actions of the user, like for example: navigation (reads a document, opens a folder, etc\u2026), sending an email and calling.\n(2) The social group is predefined by the user. We suppose for example that all the marketing users of the company have probably the same need in general, thus being part of the same group.\n(3) The time is detected by the user mobile phone and the calendar of his/her company.\n(4) The geographic dimension is detected by the GPS of the user."}, {"heading": "4.3 Abstraction and aggregation", "text": "The abstraction is based on inference rules (e.g. specification / generalization) defined on the temporal or space ontology. For instance, if we consider the outputs of GPS, we use an operation of \"reverse geocoding\" to get the name and the type of the place.\nThe aggregation is the combination of the two dimensions of time and location, e.g. \"morning at home.\" It allows more description of situations in various levels granularity.\nTo represent and characterize the location of the user, a model for the representation of geographical locations is required. To allow adequate representation of geographic information, the trend is towards semantic approaches with spatial ontology. As in [16], we propose to use ontology to represent and reason about geographic data. To define the temporal aspects characterizing the situation of the user (morning, evening, weekend...), a clear model for representing and reasoning about time and time intervals is necessary.\nTo allow for an adequate representation of temporal information\nand its manipulation, the trend is towards semantic approaches with temporal ontology. The OWL-Time ontology [15] is today a reference for representing and reasoning about time. We propose to base our work on this ontology and extend it if necessary."}, {"heading": "4.4 Database", "text": "All modules of the system share a database divided into four parts: user, Preferences, history and devices.\nThe history part stores all occurred events and all actions taken by the system. This part is useful for inferring the good recommendation to the user and it is divided into: Action_history, which contains all the interaction of the system with the environment; Event_history, which contains all the events registered by the user on his calendar. The devices part contains information about the devices. This knowledge can be used to determine what the device can do. The Preferences is a part with contains the aggregation of actions of the recommender system with the users\u2019 rewards. The user part describes registered users (it stores user logins allowing identifying them)."}, {"heading": "4.5 Reasoning system", "text": "The reasoning system allows choosing an action to deliver on each situation. In our experiments, the reasoning module is controlled by each of the previously presented algorithms: CF, QLearning, CBR and HyQL."}, {"heading": "5. CONCLUSION", "text": "The aim of this work is to investigate the problems that we find when we try to adapt a recommender system to the user in a ubiquitous environment. The recommender system defines the observable situations and what actions should be executed in each situation in order to provide useful information to the user.\nTo achieve this goal, we propose to mix the RL algorithm with CBR and CF algorithms. As future work, we intend to carry out tests with more users and case-base from Nomalys company."}, {"heading": "6. ACKNOWLEDGMENTS", "text": "This work is partially funded by Nomalys French Company (www.nomalys.com)."}, {"heading": "7. REFERENCES", "text": "[1] J. S. Breese, , D. Heckerman, and C. Kadie, \u201cEmpirical\nAnalysis of Predictive Algorithms for Collaborative Filtering,\u201d Appears in Proceedings of the Fourteenth Conference on Uncertainty in Artificial Intelligence, Madison, WI, July, 1998. Morgan Kaufmann Publisher.\n[2] P. Melville, R.J. Mooney, and R. Nagarajan, \u201cContentboosted collaborative filtering for improved recommendations,\u201d in in Eighteenth National Conference on Artificial Intelligence, 2002, pp. 187\u2013192.\n[3] V. Ricquebourg, , D. Menga, D. Durand, B. Marhic, Delahoche, L., and Log, C. . The smart home concept: our immediate future. In Society, I. I. E., editor,Proceedings of the First International Conference on E-Learning in Industrial Electronics, Hammamet -Tunisia. ICELIE\u20192006.\n[4] B. Sarwar, , G. Karypis, , J. Konstan, and J. Reid, \u201cItembased Collaborative Filtering Recommendation Algorithms\u201d. Appears in WWW10, May 1-5, 2001, Hong Kong.\n[5] L. Tamine, M. Boughanem, and M. Daoud. Evaluation of contextual information retrieval : overview of issues and research. Knowl Inf Syst (Kais), in press, 2009\n[6] M. Vall\u00e9e, , F. Ramparany, , and L. Vercouter,. Dynamic service composition in ambient intelligence environments: a multi-agent approach. In Proceeding of the First European Young Researcher Workshop on Service-Oriented Computing, Leicester, UK.2005.\n[7] M. Vozalis and K. Margaritis, \u201cOn the enhancement of collaborative filtering by demographic data,\u201d Web Intelligence and Agent Systems, vol. 4, no. 2, pp. 117\u2013138, 2006.\n[8] C.J. Watkins, C.H. \u201cLearning from Delayed Rewards\u201d PhD thesis, University of Cambridge,1989.\n[9] S. Zaidenberg, P. Reignier, and J. Crowley L.\u201dAn architecture for ubiquitous applications,\u201d In IWUC, 2007.\n[10] T. Zhang and V. Iyengar, \u201cRecommender systems using linear classifiers,\u201d The Journal of Machine Learning Research, vol. 2, p. 334, 2002.\n[11] Reinaldo A. C. Bianchi, Raquel Ros, and Ram\u00b4on L\u00b4opez de M\u00b4antaras, : Improving Reinforcement Learning by using Case Based Heuristics\n[12] Aamodt, A., Plaza, E.: Case-based reasoning: foundational issues, methodological variations, and system approaches. AI Commun. 7(1) (1994) 39\u201359\n[13] de M\u00b4antaras, R.L., McSherry, D., Bridge, D., Leake, D., Smyth, B., Craw, S., Faltings, B., Maher, M.L., Cox, M.T.,\nForbus, K., Keane, M., Aamodt, A., Watson, I.: Retrieval, reuse, revision and retention in case-based reasoning. Knowl. Eng.Rev. 20(3) (2005) 215\u201324D\n[14] Watkins, C.J.C.H.: Learning from Delayed Rewards. PhD thesis, University of Cambridge (1989D\n[15] Pan, F. Representing complex temporal phenomena for the semantic web and natural language. Ph.D thesis, University of Southern California, Dec, 2007. [16] Chen, H., Perich, F., Finin, T., Joshi, A. Soupa:Standard Ontology for Ubiquitous & Pervasive Applications, Int. Conf. on mobile & ubiquitous systems: networking and services, 2004.\n[17] Esma Aimeur and Mathieu V\u00e9zeau: Short-Term Profiling for a Case-Based Reasoning Recommendation System MACHINE LEARNING: ECML 2000\n[18] Hassan, S., 2010. Soft systems methodology in environmentaware case-based reasoning system analysis. Inform. Technol. J., 9: 467-473\n[19] P. Maes. Agents that reduce work and information overload. ACM, 1994.\n[20] D. Bouneffouf, A. Bouzeghoub, A. L. Gan\u00e7arski. A ContextualBandit Algorithm for Mobile Context-Aware Recommender System. ICONIP (3) 2012: 324-331\n[21] D. Bouneffouf, A. Bouzeghoub, A. L. Gan\u00e7arski. Hybrid-\u03b5-greedy for Mobile Context-Aware Recommender System. PAKDD (1) 2012: 468-479\n[22] D. Bouneffouf, A. Bouzeghoub, A. L. Gan\u00e7arski. Exploration / Exploitation Trade-Off in Mobile Context-Aware Recommender Systems. Australasian Conference on Artificial Intelligence 2012: 591-601\n[23] D. Bouneffouf, A. Bouzeghoub, A. L. Gan\u00e7arski. Considering the High Level Critical Situations in Context-Aware Recommender Systems. IMMoA 2012: 26-32\n[24] D. Bouneffouf, A. Bouzeghoub, A. L. Gan\u00e7arski. Following the User's Interests in Mobile Context-Aware Recommender Systems: The Hybrid-e-greedy Algorithm. AINA Workshops 2012: 657-662\n[25] D. Bouneffouf. L'apprentissage automatique, une \u00e9tape importante dans l'adaptation des syst\u00e8mes d'information \u00e0 l'utilisateur. inforsid 2011 : 427-428\n[26] D. Bouneffouf. Applying machine learning techniques to improve user acceptance on ubiquitous environment. CAISE Doctoral Consortium 2011\n[27] D. Bouneffouf. Optimizing an Utility Function for Exploration/Exploitation Trade-off in Context-Aware Recommender System, arXiv preprint arXiv:1303.0485, 2013\n[28] D. Bouneffouf. Situation-Aware Approach to Improve Contextbased Recommender System, arXiv preprint arXiv:1303.0481, 2013\n[29] D. Bouneffouf., Learning and inference engine applied to ubiquitous recommender system, 2013.\n[30] D. Bouneffouf., Role of temporal inference in the recognition of textual inference, arXiv preprint arXiv:1302.5645, 2013\n[31] D. Bouneffouf., Role de l'inference temporelle dans la reconnaissance de l'inference textuelle, Universite des Sciences et de la Technologie Houari Boumediene, 2008"}], "references": [{"title": "Empirical Analysis of Predictive Algorithms for Collaborative Filtering", "author": ["J.S. Breese", "D. Heckerman", "C. Kadie"], "venue": "Appears in Proceedings of the Fourteenth Conference on Uncertainty in Artificial Intelligence, Madison, WI, July, 1998. Morgan Kaufmann Publisher.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 1998}, {"title": "Contentboosted collaborative filtering for improved recommendations", "author": ["P. Melville", "R.J. Mooney", "R. Nagarajan"], "venue": "in Eighteenth National Conference on Artificial Intelligence, 2002, pp. 187\u2013192.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2002}, {"title": "Itembased Collaborative Filtering Recommendation Algorithms", "author": ["B. Sarwar", "G. Karypis", "J. Konstan", "J. Reid"], "venue": "Appears in WWW10,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2001}, {"title": "Evaluation of contextual information retrieval : overview of issues and research", "author": ["L. Tamine", "M. Boughanem", "M. Daoud"], "venue": "Knowl Inf Syst (Kais), in press,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2009}, {"title": "Dynamic service composition in ambient intelligence environments: a multi-agent approach", "author": ["M. Vall\u00e9e", "F. Ramparany", "L. Vercouter"], "venue": "In Proceeding of the First European Young Researcher Workshop on Service-Oriented Computing,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2005}, {"title": "On the enhancement of collaborative filtering by demographic data", "author": ["M. Vozalis", "K. Margaritis"], "venue": "Web Intelligence and Agent Systems, vol. 4, no. 2, pp. 117\u2013138, 2006.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2006}, {"title": "Learning from Delayed Rewards", "author": ["C.H.C.J. Watkins"], "venue": "PhD thesis,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 1989}, {"title": "L.\u201dAn architecture for ubiquitous applications,", "author": ["S. Zaidenberg", "P. Reignier", "J. Crowley"], "venue": "In IWUC,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2007}, {"title": "Recommender systems using linear classifiers", "author": ["T. Zhang", "V. Iyengar"], "venue": "The Journal of Machine Learning Research, vol. 2, p. 334, 2002.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2002}, {"title": "Case-based reasoning: foundational issues, methodological variations, and system approaches", "author": ["A. Aamodt", "E. Plaza"], "venue": "AI Commun", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 1994}, {"title": "Retrieval, reuse, revision and retention in case-based reasoning. Knowl. Eng.Rev", "author": ["R.L. de M \u0301antaras", "D. McSherry", "D. Bridge", "D. Leake", "B. Smyth", "S. Craw", "B. Faltings", "M.L. Maher", "M.T. Cox", "K. Forbus", "M. Keane", "A. Aamodt", "I. Watson"], "venue": null, "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2005}, {"title": "Learning from Delayed Rewards", "author": ["Watkins", "C.J.C.H"], "venue": "PhD thesis,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 1989}, {"title": "Representing complex temporal phenomena for the semantic web and natural language", "author": ["F. Pan"], "venue": "Ph.D thesis,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2007}, {"title": "Soupa:Standard Ontology for Ubiquitous ", "author": ["H. Chen", "F. Perich", "T. Finin", "A. Joshi"], "venue": "Pervasive Applications, Int. Conf. on mobile & ubiquitous systems: networking and services,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2004}, {"title": "Soft systems methodology in environmentaware case-based reasoning system analysis", "author": ["S. Hassan"], "venue": "Inform. Technol. J.,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2010}, {"title": "Agents that reduce work and information", "author": ["P. Maes"], "venue": "overload. ACM,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 1994}, {"title": "A Contextual- Bandit Algorithm for Mobile Context-Aware Recommender System. ICONIP", "author": ["D. Bouneffouf", "A. Bouzeghoub", "A.L. Gan\u00e7arski"], "venue": null, "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2012}, {"title": "Hybrid-\u03b5-greedy for Mobile Context-Aware Recommender System", "author": ["D. Bouneffouf", "A. Bouzeghoub", "A.L. Gan\u00e7arski"], "venue": null, "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2012}, {"title": "Exploration / Exploitation Trade-Off in Mobile Context-Aware Recommender Systems", "author": ["D. Bouneffouf", "A. Bouzeghoub", "A.L. Gan\u00e7arski"], "venue": "Australasian Conference on Artificial Intelligence", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2012}, {"title": "Considering the High Level Critical Situations in Context-Aware Recommender Systems", "author": ["D. Bouneffouf", "A. Bouzeghoub", "A.L. Gan\u00e7arski"], "venue": "IMMoA", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2012}, {"title": "Following the User's Interests in Mobile Context-Aware Recommender Systems: The Hybrid-e-greedy Algorithm", "author": ["D. Bouneffouf", "A. Bouzeghoub", "A.L. Gan\u00e7arski"], "venue": "AINA Workshops", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2012}, {"title": "L'apprentissage automatique, une \u00e9tape importante dans l'adaptation des syst\u00e8mes d'information \u00e0 l'utilisateur", "author": ["D. Bouneffouf"], "venue": "inforsid", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2011}, {"title": "Applying machine learning techniques to improve user acceptance on ubiquitous environment", "author": ["D. Bouneffouf"], "venue": "CAISE Doctoral Consortium", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2011}, {"title": "Optimizing an Utility Function for Exploration/Exploitation Trade-off in Context-Aware Recommender System", "author": ["D. Bouneffouf"], "venue": "arXiv preprint arXiv:1303.0485,", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2013}, {"title": "Situation-Aware Approach to Improve Contextbased Recommender System", "author": ["D. Bouneffouf"], "venue": "arXiv preprint arXiv:1303.0481,", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 2013}, {"title": "Learning and inference engine applied to ubiquitous recommender", "author": ["D. Bouneffouf"], "venue": null, "citeRegEx": "29", "shortCiteRegEx": "29", "year": 2013}, {"title": "Role of temporal inference in the recognition of textual inference", "author": ["D. Bouneffouf"], "venue": "arXiv preprint arXiv:1302.5645,", "citeRegEx": "30", "shortCiteRegEx": "30", "year": 2013}, {"title": "Role de l'inference temporelle dans la reconnaissance de l'inference textuelle", "author": ["D. Bouneffouf"], "venue": "Universite des Sciences et de la Technologie Houari Boumediene,", "citeRegEx": "31", "shortCiteRegEx": "31", "year": 2008}], "referenceMentions": [{"referenceID": 8, "context": "(2)Exploitation step: new examples never seen before are presented to the system and ask it for generalizing [10].", "startOffset": 109, "endOffset": 113}, {"referenceID": 5, "context": "-Starting from scratch: to avoid this problem, which is commune to machine learning algorithms, in [7] authors use collaborative filtering to consider demographic information about users for providing them more accurate prediction, but their system does not follow the user\u2019s interest evolution.", "startOffset": 99, "endOffset": 102}, {"referenceID": 7, "context": "- Avoiding the intervention of experts: To avoid the intervention of an expert, in [9] the authors use Reinforcement Learning (RL), which is a good alternative because it does not need a previous experience to start work.", "startOffset": 83, "endOffset": 86}, {"referenceID": 7, "context": "-Accelerate the learning process: In [9], the author proposes to accelerate RL by using indirect Q-learning.", "startOffset": 37, "endOffset": 40}, {"referenceID": 15, "context": "-The evolution of the user\u2019s interest: The authors on [19] propose to follow the interest of the user by using an exploration strategy on the q-learning algorithm.", "startOffset": 54, "endOffset": 58}, {"referenceID": 11, "context": "The Q\u2013learning algorithm [14] is a well-know RL technique that uses a strategy to learn an optimal policy \u03c0* via learning of the action values.", "startOffset": 25, "endOffset": 29}, {"referenceID": 2, "context": "ratings, from a given set of known ratings [4].", "startOffset": 43, "endOffset": 46}, {"referenceID": 0, "context": "based, Model-based and Hybrid-based [1, 4].", "startOffset": 36, "endOffset": 42}, {"referenceID": 2, "context": "based, Model-based and Hybrid-based [1, 4].", "startOffset": 36, "endOffset": 42}, {"referenceID": 9, "context": "3 Case Based Reasoning Case based reasoning (CBR) [12, 13] uses knowledge of previous situations (cases) to solve new problems, by finding a similar past case and reusing it in the new problem situation.", "startOffset": 50, "endOffset": 58}, {"referenceID": 10, "context": "3 Case Based Reasoning Case based reasoning (CBR) [12, 13] uses knowledge of previous situations (cases) to solve new problems, by finding a similar past case and reusing it in the new problem situation.", "startOffset": 50, "endOffset": 58}, {"referenceID": 9, "context": "According to Lopez de Mantaras et al [12], solving a problem by CBR involves \u201cobtaining a problem description, measuring the similarity of the current problem to previous problems stored in a case base with their known solutions, retrieving one or more similar cases, and attempting to reuse the solution of the retrieved case(s), possibly after adapting it to account for differences in problem descriptions\u201d.", "startOffset": 37, "endOffset": 41}, {"referenceID": 14, "context": "This is some works found in the literature which use this technique [17, 18].", "startOffset": 68, "endOffset": 76}, {"referenceID": 0, "context": "In equation 2: \u2013 q is a random value uniformly distributed over [0, 1] and p (0 \u2264 p \u2264 1) is a parameter that defines the exploration/exploitation tradeoff: the larger is p, the smaller is the probability of executing a random exploratory action.", "startOffset": 64, "endOffset": 70}, {"referenceID": 3, "context": "1 Environment We consider the environment being composed of all context dimensions described in [5], namely cognitive, time, geographic, material, social, source document, qualitative, psychological, and demographic.", "startOffset": 96, "endOffset": 99}, {"referenceID": 13, "context": "As in [16], we propose to use ontology to represent and reason about geographic data.", "startOffset": 6, "endOffset": 10}, {"referenceID": 12, "context": "The OWL-Time ontology [15] is today a reference for representing and reasoning about time.", "startOffset": 22, "endOffset": 26}], "year": 2013, "abstractText": "Ubiquitous information access becomes more and more important nowadays and research is aimed at making it adapted to users. Our work consists in applying machine learning techniques in order to bring a solution to some of the problems concerning the acceptance of the system by users. To achieve this, we propose a fundamental shift in terms of how we model the learning of recommender system: inspired by models of human reasoning developed in robotic, we combine reinforcement learning and case-base reasoning to define a recommendation process that uses these two approaches for generating recommendations on different context dimensions (social, temporal, geographic). We describe an implementation of the recommender system based on this framework. We also present preliminary results from experiments with the system and show how our approach increases the recommendation quality.", "creator": "Microsoft\u00ae Word 2010"}}}