{"id": "1303.2975", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "12-Mar-2013", "title": "Towards Automated Proof Strategy Generalisation", "abstract": "The ability to automatically generalise (interactive) proofs and use such generalisations to discharge related conjectures is a very hard problem which remains unsolved. Here, we develop a notion of goal types to capture key properties of goals, which enables abstractions over the specific order and number of sub-goals arising when composing tactics. We show that the goal types form a lattice, and utilise this property in the techniques we develop to automatically generalise proof strategies in order to reuse it for proofs of related conjectures. We illustrate our approach with an example.\n\n\nA simple example of a concept is to write a proof of a system and then to write a proof of a set of goals. In the example, we implement a concept of a set of goals. We write a proof of a system and then to write a proof of a set of goals.\nA simple example of a concept is to write a system and then to write a proof of a set of goals. In the example, we implement a concept of a set of goals. We define a property called the property called the property called the property called the property called the property called the property called the property called the property called the property called the property called the property called the property called the property called the property called the property called the property called the property called the property called the property called the property called the property called the property called the property called the property called the property called the property called the property called the property called the property called the property called the property called the property called the property called the property called the property called the property called the property called the property called the property called the property called the property called the property called the property called the property called the property called the property called the property called the property called the property called the property called the property called the property called the property called the property called the property called the property called the property called the property called the property called the property called the property called the property called the property called the property called the property called the property called the property called the property called the property called the property called the property called the property called the property called the property called the property called the property called the property called the property called the property called the property called the property called the property called the property called the property called the property called the property called the property called the property called the property called the property called the property called the property called the property called the property called the property called the property called the property called the property called", "histories": [["v1", "Tue, 12 Mar 2013 18:18:33 GMT  (1826kb,D)", "https://arxiv.org/abs/1303.2975v1", null], ["v2", "Sun, 9 Jun 2013 15:39:10 GMT  (2379kb,D)", "http://arxiv.org/abs/1303.2975v2", null]], "reviews": [], "SUBJECTS": "cs.LO cs.AI", "authors": ["gudmund grov", "ewen maclean"], "accepted": false, "id": "1303.2975"}, "pdf": {"name": "1303.2975.pdf", "metadata": {"source": "CRF", "title": "Towards Automated Proof Strategy Generalisation", "authors": ["Gudmund Grov", "Ewen Maclean"], "emails": ["G.Grov@hw.ac.uk", "E.Maclean@ed.ac.uk"], "sections": [{"heading": "1 Introduction", "text": "When verifying large systems one often ends up applying the same proof strategy many times \u2013 albeit with small variations. An expert user/developer of a theorem proving system would often implement common proof patterns as a so-called tactics, and use this to automatically discharge \u201csimilar\u201d conjectures. However, other users often need to manually prove each conjecture. Our ultimate goal is to automate the process of generalising a proof (possibly a few proofs) into a sufficiently generic proof strategy capable of proving \u201csimilar\u201d conjectures. In this paper we make a small step towards this goal by developing a suitable representation with necessary strong formal properties, and give two generic methods which utilises this representation to generalise a proof.\nWhilst the manual repetition of similar proofs have been observed across different formal methods, for example Event-B, B and VDM (see [5]), we will focus on a subset of separation logic [23], used to reason about pointer-based programs1. In the subset, there are two binary operations \u2217 and \u2227 and a predicate pure, with the following axioms:\n(A\u2217B)\u2217C \u21d4 A\u2217 (B\u2217C) (ax1) pure(B) \u2192 (A\u2227B)\u2217C \u21d4 (A\u2217C)\u2227B (ax2)\nThese axioms pertain specifically to separation logic, and allow pure/functional content to be expressed apart from shape content, used to describe resources. Now, consider the conjecture:\np : pure(e),h : c\u2217 (( f \u2217 (d \u2217b)\u2227 e)\u2227 e)\u2217a ` ((c\u2217 f )\u2217 (d\u2227 e))\u2217 ((b\u2227 e)\u2217a) (1)\nwhich demonstrate the typical form of a goal resulting from proving properties about heap structures, which involve some resource content and some functional content. For example, one could view the a,b,c,d, f as propositions about space on a heap, with e containing some functional information \u2013 for example about order.\nFigure 1 illustrates a proof of this conjecture in the Isabelle theorem prover. Next, consider the following \u201csimilar\u201d conjecture:\np\u2032 : pure(d),h\u2032 : a\u2217 (((b\u2217 c)\u2227d)\u2217 e) ` ((a\u2217 ((b\u2227d)\u2217 c))\u2217 e) (2) 1However, note that we believe that our approach is still generic across different formal methods.\nar X\niv :1\n30 3.\n29 75\nv2 [\ncs .L\nO ]\n9 J\nun 2\n01 3\nwhich again demonstrate the form of a typical proof. This conjecture can be proven by the following sequence of tactic applications:\napply (subst ax1); apply (subst ax2); apply (rule p\u2019); apply (rule h\u2019)\nOur goal is to be able to apply some form of analogous reasoning to use the proof shown in Figure 1 to automatically discharge (2). However, a naive reuse of this proof will not work since:\n\u2022 There are different number of tactic applications in the two proofs.\n\u2022 Naive generalisations such as \u201capply subst ax1 until it fails\u201d will fail, since subst ax1 is still applicable for (2) after the first application. Continued application will cause the rest of the proof to fail.\n\u2022 The \u201canalogous\u201d assumptions have different names, e.g. p and p\u2032, thus rule p will not work for (2).\nEven if the proofs are not identical, they are still captured by the same proof strategy. In fact, the proofs can be described as simple version of the the mutation proof strategy developed to reason about functional properties in separation logic [19]. Here, we assume the existence of a hypothesis H (i.e. h or h\u2032), with some desirable properties we will return to. The strategy can then be described as:\nThe rest of the paper will focus on how we can automatically discover such strategy from the proof shown in Figure 1. To achieve this a suitable proof strategy representation is required. Firstly, as we can see from the strategy, the representation needs to include properties about the sub-goals/proof states as well as information about tactics. Moreover, sub-goals arising from a tactic application are often treated differently (e.g. the condition arising from the use of ax2), thus some \u201cflow information\u201d is required. From this we argue that\nA graph where the nodes contains the goals, and edges annotated with goal information working as channels for the goals, is a suitable representation to support the automatic generalisation of proof strategies from proofs.\nPreviously, a graph-based language to express proof strategy has been developed [10], and we will briefly summarise this in the next section. However, the annotation of goals on edges has not been developed, and developing this is a key challenge in achieving our ambitious goal. A key contribution of this paper is the development of such a goal type which serves as a specification of a particular goal and can be generalised across proofs. The example has shown that there is vast number of information required which the goal type need to capture:\n\u2022 The conclusion to be proven, e.g. (((c\u2217 f )\u2217 (d\u2227 e))\u2217b)\u2217a initially.\n\u2022 The facts available, including local assumptions (such as p and q), and axioms/lemmas (e.g. ax1 and ax2).\n\u2022 Properties between facts and the conclusion (or other facts). For example, ax2 is applied because the condition of it can be discharged by p.\n\u2022 Properties relating goals to tactics; e.g. after applying ax2 one subgoal is discharged by p but not the other.\nMoreover, other information could also be essential for a particular proof strategy, for example: definitions; fixed/shared variables; and variance between steps (e.g. for each step a \u201cdistance\u201d between h and the goal is reduced).\nWe argue that a language need to be able to capture such properties, and we are not familiar with any proof language which can capture them in a natural way. The development of a goal type to capture this is a key contributions and the topic of \u00a73. We then briefly show how this can be utilised when evaluating a conjecture over the strategy in \u00a74. The second key contribution of this paper is the topic of \u00a75. Here, we utilise the graph language and goal types to generalise a proof into a proof strategy, illustrated by re-discovering the mutation strategy. A key feature here is that we see the goal types as a lattice which can naturally be generalised. This is combined with graph transformations to find common generalisable sub-strategies and loops with termination conditions. We discuss related work and conclude in \u00a76 and \u00a77."}, {"heading": "2 Background on the Proof Strategy Language", "text": "The graphical proof strategy language was introduced in [10] built upon the mathematical formalism of string diagrams [6]. A string diagram consists of boxes and wires, where the wires are used to connect the boxes. Both boxes and wires can contain data, and data on the edges provides a type-safe mechanism of composing two graphs. Crucially, string diagrams allow dangling edges. If such edge has no source, then this becomes and input for the graph, and dually, if an edge as no destination then it is the output of the graph.\nIn a proof strategy graph [10], the wires are labelled with goal types, which is developed in the next section. A box is either a tactic or a list of goals. Such goal boxes are used for evaluation by propagating them towards the outputs as shown in Figure 3.\nThere are two types of tactics. The first type is known as a graph tactic, which is simple a node holding one or more graphs which be unfolded. This is used to introduce hierarchies to enhance readability. A second usage, in the case it holds more then one child graphs, is to represent branching in the search space, as there multiple ways of unfolding such graph. Note however that, as explained in [10], graph tactics are evaluated in-place and are thus not unfolded first.\nThe other type of tactic is an atomic tactic. This corresponds to a tactic of the underlying theorem prover. Here, we here assume works on a proof state (containing named hypothesis, the open conjecture, fixed variables etc). When evaluated, such tactic turn a proof state (goal) into a list of new proof states (sub-goals). Since this may also involve search it is returns a set of such list of proof state, thus it has the type\nproof state\u2192{[proof state]}\nHere, for a type \u03c4 , [\u03c4] is the type of finite lists of \u03c4 and {\u03c4} is the type of finite sets whose elements are of type \u03c4 .\nFor this paper, we assume two atomic tactics: subst \u3008arg\u3009 and rule \u3008arg\u3009, which performs a single substitution or resolution step, respectively. Here, \u3008arg\u3009 may be both a single rule or a set of rules (all of them are then attempted). It can also be a description of a set of rules, which we call a class and is introduced in the next section.\nIn order to apply an atomic tactic in the strategy language, it has to be typed with goal types, also introduced next. Let \u03b1 and the \u03b2i represent goal type variables. A typed tactic is then a function of the form:\n\u03b1 \u2192{[\u03b21]\u00d7 [\u03b22]\u00d7 . . .\u00d7 [\u03b2n]}\nThis type has to be reflected in our representation of goal nodes, which we will return in \u00a74 after we have developed our notion of goal types, which is the next topic."}, {"heading": "3 Towards a Theory of Goal Types", "text": ""}, {"heading": "3.1 Classes", "text": "A goal type must be able to capture the intuition of the user, potentially using all the information listed in \u00a71. This information is then used to guide the proof and send sub-goals to the correct tactic. To achieve this we firstly need to capture important properties of the conclusion of the conjecture. Next, it is important to note that, in general, most of the information available is not relevant, inclusion of it will\nact as noise (and increase the chance of \u201cover-fitting\u201d a strategy to a particular proof). Thus, we need to be able to separate the wheat from the chaff, and capture properties of the \u2018relevant\u2019 facts, where facts refer to both lemmas/axioms, and assumptions which are local to the conclusion. Henceforth we will term a fact or conclusion an element. There are a large set of such element properties, e.g.:\n\u2022 a particular shape or sub-shape;\n\u2022 the symbols used, or symbols at particular positions (e.g. top symbol);\n\u2022 certain types of operators are available, e.g. (1) contains associative-commutative operators;\n\u2022 the element contains variables we can apply induction to or (shared) meta-variables;\n\u2022 certain rules are applicable;\n\u2022 the element\u2019s origin, e.g. it is from group theory or it is a property of certain operator.\nThis list is by no means complete, and here we will focus on two such properties:\n\u2022 top symbol describes the top level symbol;\n\u2022 has symbol describes the symbols it must contain.\nEach such feature will have data associated:\ndata := int | term | position | boolean\nwhere term refers to the term of the underlying logic, and a position refers to an index of a term tree. A class describes a family of elements where certain such features hold. A class, for example, could be a conclusion or a hypothesis, for which certain properties hold.\nDefinition 1. A class is a map class := name m\u2192 [[data]]\nsuch that for each name in the domain of a class, there is an associated predicate on an element, termed the matcher. There are two special cases where the predicates always succeeds or always fails on certain data, denoted by > f and \u22a5 f as described below. A class matches to a conclusion/fact if the predicate on each element holds.\nThe intuition behind the list of lists of data is that it represent a property in DNF form, e.g. [[a,b], [c]], which is equivalent to (a\u2227 b)\u2228 c. For the conjecture in (1), {(top symbol 7\u2192 [[\u2217]]),(has symbol 7\u2192 [[\u2217,\u2227]])} identifies the conclusion, while {(has symbol 7\u2192 [[pure]])} identifies the first assumption, but not the second, and {(has symbol 7\u2192 [[pure], [\u2217]])} captures both assumptions and the goal. We call this a semantic representation of the data.\nWe write the constant space of feature names as N and, for a class C, with n \u2208N , C(n) is the data associated with feature n for class C. We define the semantic representation of the data for a particular feature in a class using the notation xs for some data x. By semantic representation, we mean that the structure of the list of data is mapped to a representation about which we can reason \u2013 for example, above where a list of lists of data represents a formula in DNF. It is then possible to reason about this data. For example, for the feature has symbol in the conjecture (1) we write for C(has symbol)s:\n[[a1 \u00b7 \u00b7 \u00b7am], \u00b7 \u00b7 \u00b7 , [b1 \u00b7 \u00b7 \u00b7bn]]s = ((Ja1K\u2229\u00b7\u00b7 \u00b7\u2229 JamK)\u222a\u00b7\u00b7 \u00b7\u222a (Jb1K\u2229\u00b7\u00b7 \u00b7\u2229 JbnK)) (3)\nwhere JaK denotes a as an atom.\nClasses form a bounded lattice (C,\u2228,\u2227,>,\u22a5), on which we can define a meet and a join. We show how to compute the join (\u2227: least upper bound), and meet (\u2228: greatest lower bound) for two classes C1 and C2. We define the most general class as > and the empty class as \u22a5. We write the most general element of C( f ) as > f and the least general to be \u22a5 f .\nDefinition 2. C1\u2227C2 is the greatest lower bound of C1 and C2 if \u2200n\u2208N .(C1\u2227C2)(n) =C1(n)\u2227n C2(n), where \u2227n computes the greatest lower bound for feature n.\nDefinition 3. C1\u2228C2 is the least upper bound of C1 and C2 if \u2200n \u2208N .(C1\u2228C2)(n) = C1(n)\u2228n C2(n), where \u2228n computes the least upper bound for feature n.\nFor f = top symbol or f = has symbol we define \u2227 f and \u2228 f as:\nDefinition 4. C1( f )\u2227 f C2( f ) := C1( f )s\u2229C2( f )s and C1( f )\u2228 f C2( f ) := C1( f )s\u222aC2( f )s\nWe further define>sf and\u22a5sf to be U (the universal set) and /0 respectively. To show that classes form a partial order, we prove the following properties about meet and joint:\nTheorem 1. \u2227 and \u2228 are commutative and associative operations.\nProof. It suffices to prove that \u2227 f and \u2228 f commutative and associative for each f \u2208N . In our example we use Definition 4. This is provable since \u2229 and \u222a are commutative, associative and idempotent operations in set theory.\nTheorem 2. \u2227 and \u2228 follow the absorption laws a\u2228 (a\u2227b) = a, and a\u2227 (a\u2228b) = a.\nProof. It suffices to prove that \u2227 f follow the absorption laws. This follows from the fact that \u2229 and \u222a are set theoretic operations. It also follows that \u2227 and \u2228 are idempotent; a\u2227a = a, a\u2228a = a.\nSince \u22a5 is /0 and > is U, it is trivial to show that C\u2228\u22a5 = C and C\u2227> = C for a class C. Thus, a class form form a bounded lattice.\nOrthogonality is a key property to reduce non-determinism during evaluation of a strategy, whilst subtyping of classes is a key feature for our generalisation techniques discussed in \u00a75:\nDefinition 5. C1 and C2 are orthogonal if \u2203 f \u2208N .C1( f )\u2227C2( f ) =\u22a5 f . We write this as C1\u22a5C2. C1 is a subtype of C2, written C1 <: C2, if \u2200 f \u2208N . (C1( f )\u2227C2( f )) =C1( f ).\nAs an example, consider a goal class with features has symbol and top symbol:\nC1 : {(top symbol 7\u2192 [[\u2217]]),(has symbol 7\u2192 [[\u2217,\u2227], [\u2228,\u2217]])} C2 : {(top symbol 7\u2192 [[\u2227]]),(has symbol 7\u2192 [[\u2217,\u2227], [\u2228,\u2217]])} (4) C3 : {(top symbol 7\u2192 [[\u2217]]),(has symbol 7\u2192 [[\u2217,\u2227,\u2228]])} (5)\nC2\u22a5C3 as there is a feature (top symbol) for which C2( f )\u22a5 fC3( f ), since by the semantics J\u2227K\u2229J\u2217K= /0. In order to determine whether C1 is a subtype of C3 we must show that (C1( f )\u2227C3( f )) =C3( f ) for all features. Using definition 4 we must prove for has symbol:\n((J\u2217 K\u2229 J\u2227 K)\u222a (J\u2228 K\u2229 J\u2217 K))\u2229 (J\u2217 K\u2229 J\u2227 K\u2229 J\u2228 K) = (J\u2217 K\u2229 J\u2227 K\u2229 J\u2228 K)\nwhich is true and the same for top symbol which in this case follows trivially."}, {"heading": "3.2 Links", "text": "A class identifies a cluster of elements with certain common properties. However, certain types of properties are between elements \u2013 e.g. a conditional fact can only be applied if the condition can be discharged. Moreover, certain properties rely on information pertaining to previous nodes in the proof tree, e.g. a measure has to be reduced in a rewriting step to ensure termination. Such properties include;\n\u2022 common symbols between two elements, or the position they are at;\n\u2022 common shapes between two elements;\n\u2022 embedding of one element into another;\n\u2022 some form of difference between elements\n\u2022 some sort of measure reduces/increases between elements;\nWe call such properties links. Moreover, we abstract links to make them relations between classes rather than between elements. Links are given an existential meaning: a link between two classes entails that there exists elements in them such that a property holds. In addition, we introduce a parent function on links to refer to the parent node. The meaning of this will become clearer in the next section, where we discuss evaluation.\nDefinition 6. A link is a map\nlink := name\u00d7 class\u00d7 class m\u2192 [[data]]\nsuch that for each name n in the domain of a link, there is an associated predicate n : [[data]]\u00d7element\u00d7 element\u2192 B called a matcher. A link matches to a conclusion/fact if the predicate on each element holds.\nWe write the constant space of link names as NL and for a link L, with n \u2208NL, L(n,C1,C2) is the data associated with feature n, classes C1 and C2, for link L.\nWe will only consider the link features is match and symb at pos for this exposition. The data of the former are booleans in DNF, and its matcher succeeds if the result of an exact match between the elements is the same as the semantic value of the data. The data of the latter is lists of position, where for example\n{(symb at pos,C1,C2) 7\u2192 [[pos]]}\nstates that there exists elements of classes C1 and C2 where the symbol at position pos is the same. To state that there is no position where this is the case, we introduce an element \u22a5 f for each f \u2208NL, as we did with classes. In general, there will be more complicated links, with more complicated output data values. Defining these is ongoing work.\nIn order to define orthogonality and subtyping we define the meet and join for each name in NL.\nDefinition 7. L1\u2227L2 is the greatest lower bound of L1 and L2 if \u2200n \u2208LN .(L1\u2227L2)(n) = L1(n)\u2227n L2(n), where \u2227n computes the greatest lower bound for link feature n.\nDefinition 8. L1 \u2228L2 is the least upper bound of L1 and L2 if \u2200n \u2208LN .(L1 \u2228L2)(n) = L1(n)\u2228n L2(n), where \u2228n computes the least upper bound for link feature n.\nAs with classes, we introduce a semantic representation for the links using notation xs for some data x. Since the data is a list of lists of positions, we use the same semantics as in (3). The intuition is that we should be able to generalise the link class to account for the same symbol to exist at multiple positions within the hypothesis and conclusions. The proofs and definitions of the lattice theory follow similarly to those for classes.\nWe then define orthogonality and subtyping for links:\nDefinition 9. L1 and L2 are orthogonal if \u2203 f \u2208LN .L1( f )\u2227L2( f ) =\u22a5 f . We write this as L1\u22a5L2 L1 is a subtype of L2, written L1 <: L2, if \u2200 f \u2208LN . L1( f )\u2227L2( f ) = L1( f )."}, {"heading": "3.3 Goal Types", "text": "A goal type is a description of the conclusion, the related facts, and the links between them:\nDefinition 10. A goal type is a record:\nGoalType := { link : link, facts : { class } , concl : class }\nwhere concl is the class describing the conclusion of a goal, facts is a set of classes of relevant facts, and link is a link relating classes of facts and concl.\nNote that we keep a set of classes of facts to account for specifying the existence of multiple classes of hypotheses. For example, in the our example conjecture, hypothesis p forms a class P (with top symbol pure), while h forms a class H (with has symbols [[\u2227,\u2217]]). Henceforth we assume that all members of facts are orthogonal \u2013 dealing with the general case which allows overlapping is future work. Orthogonality and subtyping of two goal types reduces to orthogonality of their respective classes. Due to the assumptions of orthogonality between the facts, they have an universal interpretation for \u22a5 and an existential interpretation for <:\nG1 \u22a5 G2 := G1(concl) \u22a5 G2(concl) \u2228 G1(link) \u22a5 G2(link) \u2228 \u2200 f1 \u2208 G1(fact), f2 \u2208 G2(fact). f1 \u22a5 f2 G1 <: G2 := G1(concl) <: G2(concl) \u2227 G1(link) <: G2(link) \u2227 \u2203 f1 \u2208 G1(fact), f2 \u2208 G2(fact). f1 <: f2"}, {"heading": "4 Lifting of Goals and Tactics", "text": "Here, we will briefly outline how evaluation is achieved with the goal type introduced. Firstly, recall from Figure 3 that a single evaluation step is achieved by a tactic by consuming the input goal node on the input and produce the resulting sub-goals on the correct output edges. Since a goal nodes contains list of goals, this can be captured by meta graphical rewrite-rule shown in Figure 4. The details are given in [10], but one evaluation step works as follows:\n1. Match and partly instantiate the LHS of the meta-rule.\n2. Evaluate the tactic function for the matched input and output types.\n3. Finish instantiating the RHS with the lists gsi from the tactic.\n4. Apply the fully instantiated rule(s).\n\u03b1\n[g]\nt\n\u03b21 \u03b22 \u03b2n...\ngsngs1 gs2\n\u03b2n...\nt\n\u03b22\u03b21\n\u03b22 \u03b2n\u03b21 ...\n\u03b1\n\u03b1\nFigure 4: Evaluation meta-rule\nwhere \u03b1 and \u03b2i are goal type variables. We assume t is an atomic tactic, but this is trivial to extend to graph tactics. Further note that there are additional rules to split a list into a sequence of singleton lists and delete empty list nodes. For more details we refer to [10].\nIn the second step of this algorithm, the underlying tactic has to be lifted from proof state\u2192{[proof state]} to the form \u03b1 \u2192{[\u03b21]\u00d7 [\u03b22]\u00d7 . . .\u00d7 [\u03b2n]}.\nFirst we need to introduce a goal. This can be seen as an instance of a goal type for a particular proof state:\nDefinition 11. A goal is a record:\ngoal := { f map : class m\u2192{fact}, ps : proof state, parent : {goal}}\nwhere parent is either a singleton or empty set \u2013 empty if this is the first goal. Type checking relies on the \u201ctyping predicates\u201d associated with classes and links. A goal g is of type G, iff\n\u2022 The conclusion in g(ps) matches G(concl).\n\u2022 For each class c\u2208G( f acts), g( f map)(c) is defined, not empty, and each f \u2208 g( f map)(c) matches c.\n\u2022 For each (l,c1,c2) 7\u2192 d \u2208 G(links) there exists elements e1 \u2208 g( f map)(c1) and e1 \u2208 g( f map)(c1) such that the l(d,e1,e2) holds. Moreover, for each e1 \u2208 g( f map)(c1) there must be an e2 \u2208 g( f map)(c2), such that l(d,e1,e2) (and dually the other way around).\nNow, to lift a tactic we need to: unlift goal g to project the underlying proof state; apply the tactic; and lift the resulting proof states to goals of a type in {\u03b21, . . . ,\u03b2n} (which becomes instantiated to specific goal types when matching the RHS in the first step). Then, for a list L of proof states, let l p(\u03b21, . . . ,\u03b2n;L) be the set of all partitions of L lifted into n lists of goals {(map lift L1), . . . , (map lift Ln)}, such that all of the goals in the i-th list have goal type \u03b2i. Then, we define lifting as:\nlift(tac) = \u03bbg. {\nl p(\u03b21, . . . ,\u03b2n; tac(unlift(g))) if g is of type \u03b1 /0 otherwise\nWe are then left to define unlifting and lifting for a single goal node and a single goal type. Firstly, a naive unlifting of a goal simply projects the goal state. More elaborate unliftings are tactic dependent, and may e.g. add all facts from a particular fact class as active assumptions beforehand.\nLifting is a partial function, and an element of lp is only defined if lifting of all elements succeeds. There are several (type-safe) ways to implement lifting. Here, we show a procedure which assumes that all relevant information is passed down the graph from the original goal node. Any fact \u201cadded\u201d to a goal node is thus a fact generated by the tactic. However, one may \u201cactivate\u201d existing facts explicitly in the tactic which will then be used by lifting. A new goal g\u2032 is then lifted as follows, using the (new) proof state ps\u2032, previous goal g, and goal type G as follows:\n1. Set fields g\u2032(parent) to g, and g\u2032(ps) to ps\u2032, fail if the conclusion does not match G(concl).\n2. For each c\u2208G( f acts), set g\u2032( f acts)(c) to be all facts in the range of g( f acts) and newly generated facts which matches c. If for any c \u2208 G( f acts), g\u2032( f acts)(c) is empty (or undefined) then fail.\n3. Check all link features. For each c\u2208G( f acts) which is used by a link feature, filter out any element e \u2208 g\u2032( f acts)(c) not \u201ccaptured\u201d by a link related link match. Fail if there does not exist an element in the related classes which holds for any of the links or any g\u2032( f acts)(c) (for c \u2208 G( f acts)) is empty after this filtering step."}, {"heading": "5 Generalising Strategies", "text": "A proof is generalised into a strategy by first lifting the proof tree into a proof strategy graph, and then apply graph transformation techniques which utilises the goal type lattice to generalise goal types. Simple generalisation of tactics are also used. One important property when performing such generalisations, is that any valid proofs on a strategy should also be valid after, which we will provide informal justification for below. However, note that we do not deal with termination."}, {"heading": "5.1 Deriving Goal Types from Proof States", "text": "In this section we will discuss how to generalise the proof shown in Figure 1 into the mutation strategy shown in Figure 2, utilising the lattice structure of goal types.\nHowever, first we need to turn the proof tree of Figure 1 into a low-level proof strategy graph of the same shape. We utilise techniques described in [25] to get the initial proof tree. Now, since the shape is the same this reduces to (1) generalising proof states into goal types and (2) generalising the tactics.\n(1) To generalise the proof state into goal type we have taken an approach which can be seen as a \u201clocally maximum\u201d derivation of goal type, where each assumption becomes a separate class, and make each class as specific as possible. Any link features that holds are also included. Consequently, the goal type will be as far down the lattice as possible whilst still being able to lift the goal state it is derived from. To illustrate, we will show how the proof state (1) is lifted to goal type GT 1. Let\nH = {has symbol 7\u2192 [[\u2217,\u2227]]},{top symbol 7\u2192 [[\u2217]]} P = {has symbol 7\u2192 [[pure]], top symbol 7\u2192 [[pure]]} G = {has symbol 7\u2192 [[\u2217,\u2227]], top symbol 7\u2192 [[\u2217]]} L = {(symb at pos,G,H) 7\u2192 [[\u22a5]],(symb at pos,G,P) 7\u2192 [[\u22a5]],(symb at pos,H,P) 7\u2192 [[\u22a5]]}.\nThen GT 1 becomes {link : L, f acts : {H,P},concl : G}. Note that the last two link features are useless, and are therefore ignored henceforth. However, this shows that in the presence of larger goal states and/or more properties heuristics will be required to reduce the size of the goal types, and filter out such \u201cuseless information\u201d. This is future work.\n(2) Tactics are kept with the difference that if a local assumption is used (e.g. h or p) their respective class is used instead.\nThe resulting tree is shown left-most of Figure 5. For space reasons we have not included the goal types, but provided a name when referred to in the text. This is slightly more general than the original proof as it allows a very slight variation of the goals. However, it still e.g. relies on the exact number of application of each tactic."}, {"heading": "5.2 Generalising Tactics", "text": "Next, we need to generalise tactics, A simple example of this is when sets of rules are used as arguments for the subst and rule tactics. Here, subst R1 and subst R2 can be generalised into subst (R1 \u222aR2). Another example turns a tactic into a graph tactic which nest both these tactics (and can be unfolded to either). A proviso for both is that their input and output goal types can be generalised. Both these generalisations only increases the search space and are thus proper generalisations.\nGraph tactics can also be generalised by generalising the graph they nest into one. We return to this with an example below. We will use the notation gen(t1, t2) for the generalisation of the two given tactics."}, {"heading": "5.3 Generalising Goal Types", "text": "In the context of goal types: generalisation refers to computing the most general goal type for two existing goal types; while weakening applies to only one goal type and makes the description of it more general. Crucial to both generalisation and weakening is that multiple possible generalised and weakened goal types exist.\nWe use the notion of a least upper bound for a goal type lattice, described in \u00a73 using the join operator \u2228, to define generalisation for goal types. For a class C, we write:\nDefinition 12. C is a generalisation of C1 and C2, also written C = gen(C1,C2), if \u2200 f \u2208 N . C( f ) = C1( f )\u2228C2( f ).\nAs an example, consider the two classes shown in (4) and (5). We can compute G = gen(C1,C2) by appealing to the set theoretic semantics and tranferring back to the class representation. For f1 = top symbol and f2 = has symbol we compute\nC( f1)s = (J\u2227 K\u222a J\u2217 K) ;C( f1) = [[\u2227], [\u2217]] C( f2)s = ((J\u2217 K\u2229 J\u2227 K)\u222a (J\u2228 K\u2229 J\u2217 K))\u222a (J\u2217 K\u2229 J\u2227 K\u2229 J\u2228 K)\n= ((J\u2217 K\u2229 J\u2227 K)\u222a (J\u2228 K\u2229 J\u2217 K)) ;C( f2) = [[\u2217,\u2227], [\u2228,\u2217]]\nproducing a generalised class:\nC : {(top symbol 7\u2192 [[\u2228], [\u2217]]),(has symbol 7\u2192 [[\u2217,\u2227], [\u2227,\u2228]])}\nThe definition of generalisation for links extends similarly from its associated lattice theory described in \u00a73.2. Recall that we assume orthogonality of fact classes. We define a function gen map over two sets of (fact) classes, which generalises pairwise each fact class. Here, for any two fact classes H1 and H2 in the generalised set of fact classes, where (H1 <: H2) \u2227 \u00ac(H1 \u22a5 H2) we only retain H2, thus ensuring orthogonality. We can then define a function gen on goal types to be\ngen(G1, G2) := { concl = gen(G1(concl),G2(concl)), facts = gen map(G1(facts),G2(facts)), link = gen(G1(link),G2(link))"}, {"heading": "5.4 (Re-)Discovering the Mutation Strategy", "text": "Armoured with the techniques for generalising the edges and nodes of a proof strategy, we now develop two techniques which allows us to generate our proof into the required mutation strategy.\nFirstly, we need to abstract over the number of repeated sequential applications of the same tactic \u2013 i.e. we need to discover loops. When working in a standard LCF tactic language [9], the problem is to know: (a) on which goals (in the case of side conditions) the tactic should be repeated, and (b) when to stop. This was highlighted in [7], where a regular expression language, closely aligned with common LCF tacticals, was used to learn proof tactics, and hand-crafted heuristics were defined to state when to stop a loop (which by the way would fail for our example).\nThe advantage of our approach, is that we can utilise the goal types to identify termination conditions \u2013 reducing termination and goal focus to the same case, thus also handling the more general proof-bycases paradigm. We illustrate our approach with what can be seen as an inductive representation of tactic looping, as shown by rules loop1 and loop2 of Figure 6. For loop1, we can see that it is correct since B\u22a5C ensures that a goal will exit the loop when it matches C. Moreover, the B <: A pre-condition ensures that the tactic can handle the input type. For loop2, similar arguments holds for the generalised gen(B,B\u2032) edge.\nConsider the left most graph of Figure 5, which is the proof tree lifted to a graph. Here, the stippled box highlights the sub-graph which matches with the rules shown above. loop1 is applied first, followed by two applications of loop2. The classes are identical so we only discuss link classes, which have the following values:\nGT 1(link) = GT 2n(link) = {(symb at pos,G,H) 7\u2192 [[\u22a5]]} GT 3(link) = {(symb at pos,G,H) 7\u2192 [[1]]}\nwhere GT 2n denote the goal types in the intermediate stages of the repeated application of tactic subst ax1. Now, for the sequence to be detected as a loop, we must first discover\nGT 2\u2032 = gen(gen(GT 21,GT 22),gen(GT 23) = GT 21\nand show GT 2\u2032 <: GT 0 and GT 2\u2032\u22a5GT 3. These are both true since GT 2\u2032 and GT 1 are equal, and GT 2\u2032 and GT 3 are orthogonal due to the existence of \u22a5 in the data argument denoting an empty feature.\nThe next step (s2) of Figure 5 layers the highlighted sub-graphs into the graph tactics pax2a and pax2b. Such layering can be done for a (connected) sub-graph if the inputs and outputs of the sub-graphs are respectively orthogonal.\nNext, we again apply rule loop1 to the pax2a and pax2b sequence. However, this requires us to generalise these two graph tactics, i.e. combining the two graphs they contain into one. Now, as shown in [6], in the category of string graphs, two graphs are composed by a push-out over a common boundary. We can combine two graph tactics in the same way by a push-out over the largest common sub-graph. This is shown on the right-most diagram of Figure 6, which becomes the last step (s3) of Figure 5.\nThis graph is in fact the mutation strategy of Figure 2, with the addition that we have given semantics to the edges. Now, the first feedback loop is identified by {(symb at pos,concl,H) 7\u2192 [[\u22a5]]}, while the second feedback loop is identified by {(is match,concl,H) 7\u2192 [[ f alse]]}."}, {"heading": "6 Related Work", "text": "We extend [10], which introduces the underlying strategy language, by developing a theory for goal types which we show form a lattice, and using this property to develop techniques for generalising strategies.\nOur goal types can be seen as a lightweight implementation of pre/post-condition used in proof planning [4] \u2013 with the additional property that the language captures the flow of goals. It can be seen as further extending the marriage of procedural and declarative approaches to proof strategies [2, 13, 8], and addressing issues related to goal flow and goal focus highlighted in [1] \u2013 for a more detailed comparison we refer to [10].\nThe lattice based techniques developed for goal type generalisation is similar to antiunification [22] which generalises two terms into one (with substitutions back to the original terms). Whilst each feature is primitive, the goal type has several dimensions. More expressive class/link features, which is future work, may require higher-order anti-unification [18] \u2013 and such ideas may also be applicable to graph generalisations. Other work that may become relevant for our techniques are graph abstractions/transformations used in algorithmic heap-based program verification techniques, such as [3], and for parallelisation of functional programs [12].\nAs already discussed, the problem when ignoring goal information, is that one cannot describe e.g. where to send a goal or when to terminate a loop, in a way sufficiently abstract to capture a large class of proofs. Instead, often crude, heuristics have to be used in the underlying tactic language. This is the case for [7], which uses a regular expression language (close to LCF tactics), originally developed in [14] to learn proof plans. [14] further claims that explanation based generalisation (EBG)[21] is applied to derive pre/post-conditions, but no details of this are provided. An EBG approach is also applied to generalise Isabelle proof terms into more generic theorems in [15]. This could provide an alternative starting point for us, however, one may argue that much of the user intent will be lost by working in the low-level proof term representation. Further, note that our work focuses on proof of conjectures which requires structure, meaning machine learning techniques \u2013 such as [24], which learns heuristics to select relevant axioms/rules for automated provers \u2013 are not sufficient. However, in [11], an approach to combine essentially our techniques, with more probabilistic techniques to cluster interactive proofs [17], was outlined.\nWe would also like to utilise work on proof and proof script refactoring [26]. This could be achieved either as a pre-processing step, or by porting these techniques to our graph based language. Finally, albeit for source code, [20] argues for the use of graphs to perform refactorings, which further justifies our graph based representation of proof strategies for the work presented here."}, {"heading": "7 Conclusion and Future Work", "text": "In this paper we have reported on our initial results in creating a technique to generalise proof into highlevel proof strategies which can be used to automatically discharged similar conjectures. This paper\nhas two contributions: (1) the introduction of goal type to describe properties of goals using a lattice structure to enable generalisations; (2) two generic techniques, based upon loop discovery to generalise a proof strategy. The techniques was motivated and illustrated by an example from separation logic. We are in the process of implementation in Isabelle combined with the Quantomatic graph rewriting engine [16]. Next plan to implement these methods in order to test them on more examples, using a larger set of properties to represent the goal types. In particular, we are interested in less syntactic properties, such as the origin of a goal, or if it is in a decidable sub-logic.\nWe also showed how the lattice structure corresponds to sub-typing, and we plan to incorporate subtyping in the underlying theory of the language in order to utilise it when composing graphs. Further, we plan to develop more techniques for generalising graphs, which may include develop an underlying theory of graph generalisation, which will be less restrictive than rewriting.\nFinally, we have already touched upon the need for heuristic guidance in this work, as there will be many ways of generalising. We are also planning to apply the techniques to extract strategies from a corpus of proofs. Here we believe we have a much better chance of finding and generalising common sub-strategies, and may also incorporate probabilistic techniques as a pre-filter [11]. Such work may help to indicate which class/link features are more common, and can be used to improve the generalisation heuristics discussed above. Further, we would like to remove the restriction that facts have to be orthogonal, and improve the sub-typing to handle this case.\nWe only briefly discussed the process of turning proofs into initial low-level proof strategy graphs. With partners on the AI4FM project (www.ai4fm.org) we are working on utilising their work on capturing the full proof process, where the user may (interactively) highlight the key features of a proof (step) [25]. This can further help the generalisation heuristics."}, {"heading": "Acknowledgements", "text": "This work has been supported by EPSRC grants: EP/H023852, EP/H024204 and EP/J001058. We would like to thank Alan Bundy, Aleks Kissinger, Lucas Dixon, members of the AI4FM project, Katya Komendantskaya, Jonathan Heras and Colin Farquhar for feedback and discussions."}], "references": [{"title": "A new type for tactics", "author": ["A. Asperti", "W. Ricciotti", "C. Sacerdoti", "C. Tassi"], "venue": "PLMMS\u201909, pages 229\u2013232", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2009}, {"title": "A tactic language for declarative proofs", "author": ["Serge Autexier", "Dominik Dietrich"], "venue": "In ITP\u201910,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2010}, {"title": "Graph abstraction and abstract graph transformation", "author": ["I.B. Boneva", "A. Rensink", "M.E. Kurban", "J. Bauer"], "venue": "Technical Report TR-CTI,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2007}, {"title": "The use of explicit plans to guide inductive proofs", "author": ["A. Bundy"], "venue": "R. Lusk and R. Overbeek, editors, CADE9, pages 111\u2013120. Springer-Verlag", "citeRegEx": "4", "shortCiteRegEx": null, "year": 1988}, {"title": "Learning from experts to aid the automation of proof search", "author": ["A. Bundy", "G. Grov", "C.B. Jones"], "venue": "PreProc of AVoCS\u201909, pages 229\u2013232", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2009}, {"title": "Open graphs and monoidal theories", "author": ["Lucas Dixon", "Aleks Kissinger"], "venue": "CoRR, abs/1011.4114,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2010}, {"title": "The use of Data-Mining for the Automatic Formation of Tactics", "author": ["Hazel Duncan"], "venue": "PhD thesis, University of Edinburgh,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2002}, {"title": "MMode, a mizar mode for the proof assistant coq", "author": ["M. Giero", "F. Wiedijk", "Mariusz Giero"], "venue": "Technical report, January", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2004}, {"title": "Edinburgh LCF, volume", "author": ["Michael J.C. Gordon", "Robin Milner", "Christopher P. Wadsworth"], "venue": "Lecture Notes in Computer Science. Springer,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 1979}, {"title": "Hume box calculus: robust system development through software transformation", "author": ["G. Grov", "G. Michaelson"], "venue": "HOSC, 23:191\u2013226", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2010}, {"title": "A mizar mode for HOL", "author": ["John Harrison"], "venue": "In TPHOLs, volume 1125 of LNCS,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 1996}, {"title": "Learning Method Outlines in Proof Planning", "author": ["M. Jamnik", "M. Kerber", "C. E Benzmuller"], "venue": "Technical Report CSRP-01-8, University of Birmingham (CS)", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2001}, {"title": "Theorem reuse by proof term transformation", "author": ["E.B. Johnsen", "C. L\u00fcth"], "venue": "TPHOLs 2004, volume 3223 of LNCS, pages 152\u2013167. Springer", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2004}, {"title": "and B", "author": ["A. Kissinger", "A. Merry", "L. Dixon", "R. Duncan", "M. Soloviev"], "venue": "Frot. Quantomatic", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2011}, {"title": "Machine learning in proof general: Interfacing interfaces", "author": ["E. Komendantskaya", "J. Heras", "G. Grov"], "venue": "CoRR, abs/1212.3618", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2012}, {"title": "Restricted higher-order anti-unification for analogy making", "author": ["U. Krumnack", "A. Schwering", "H. Gust", "K-U K\u00fchnberger"], "venue": "AJAI 2007, volume 4830 of LNAI, pages 273\u2013282. Springer", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2007}, {"title": "Mutation in linked data structures", "author": ["Ewen Maclean", "Andrew Ireland"], "venue": "In ICFEM, volume 6991 of LNCS,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2011}, {"title": "Formalizing refactorings with graph transformations", "author": ["T. Mens", "N. Van Eetvelde", "S. Demeyer", "D. Janssens"], "venue": "Journal of Software Maintenance, 17(4):247\u2013276", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2005}, {"title": "A note on inductive generalization", "author": ["G.D. Plotkin"], "venue": "Machine Intelligence 5, pages 153\u2013163, Edinburgh", "citeRegEx": "22", "shortCiteRegEx": null, "year": 1969}, {"title": "Separation logic: A logic for shared mutable data structures", "author": ["J.C. Reynolds"], "venue": "Logic in Computer Science, pages 55\u201374. IEEE Computer Society", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2002}, {"title": "Semantic graph kernels for automated reasoning", "author": ["E. Tsivtsivadze", "J. Urban", "H. Geuvers", "T. Heskes"], "venue": "Proc. 11th SIAM Int. Conf. on Data Mining, pages 795\u2013803. SIAM / Omnipress", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2011}, {"title": "Inferring the proof process", "author": ["Andrius Velykis"], "venue": "In Christine Choppy, David Delayahe, and Ka\u0131\u0308s Kla\u0131\u0308, editors,", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2012}, {"title": "Towards formal proof script refactoring", "author": ["I. Whiteside", "D. Aspinall", "L. Dixon", "G. Grov"], "venue": "CICM\u201911, volume 6824 of LNCS, pages 260\u2013275. Springer", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2011}], "referenceMentions": [{"referenceID": 4, "context": "Whilst the manual repetition of similar proofs have been observed across different formal methods, for example Event-B, B and VDM (see [5]), we will focus on a subset of separation logic [23], used to reason about pointer-based programs1.", "startOffset": 135, "endOffset": 138}, {"referenceID": 19, "context": "Whilst the manual repetition of similar proofs have been observed across different formal methods, for example Event-B, B and VDM (see [5]), we will focus on a subset of separation logic [23], used to reason about pointer-based programs1.", "startOffset": 187, "endOffset": 191}, {"referenceID": 16, "context": "In fact, the proofs can be described as simple version of the the mutation proof strategy developed to reason about functional properties in separation logic [19].", "startOffset": 158, "endOffset": 162}, {"referenceID": 5, "context": "The graphical proof strategy language was introduced in [10] built upon the mathematical formalism of string diagrams [6].", "startOffset": 118, "endOffset": 121}, {"referenceID": 21, "context": "We utilise techniques described in [25] to get the initial proof tree.", "startOffset": 35, "endOffset": 39}, {"referenceID": 8, "context": "When working in a standard LCF tactic language [9], the problem is to know: (a) on which goals (in the case of side conditions) the tactic should be repeated, and (b) when to stop.", "startOffset": 47, "endOffset": 50}, {"referenceID": 6, "context": "This was highlighted in [7], where a regular expression language, closely aligned with common LCF tacticals, was used to learn proof tactics, and hand-crafted heuristics were defined to state when to stop a loop (which by the way would fail for our example).", "startOffset": 24, "endOffset": 27}, {"referenceID": 0, "context": "GT 1(link) = GT 2n(link) = {(symb at pos,G,H) 7\u2192 [[\u22a5]]} GT 3(link) = {(symb at pos,G,H) 7\u2192 [[1]]}", "startOffset": 92, "endOffset": 95}, {"referenceID": 5, "context": "Now, as shown in [6], in the category of string graphs, two graphs are composed by a push-out over a common boundary.", "startOffset": 17, "endOffset": 20}, {"referenceID": 3, "context": "Our goal types can be seen as a lightweight implementation of pre/post-condition used in proof planning [4] \u2013 with the additional property that the language captures the flow of goals.", "startOffset": 104, "endOffset": 107}, {"referenceID": 1, "context": "It can be seen as further extending the marriage of procedural and declarative approaches to proof strategies [2, 13, 8], and addressing issues related to goal flow and goal focus highlighted in [1] \u2013 for a more detailed comparison we refer to [10].", "startOffset": 110, "endOffset": 120}, {"referenceID": 10, "context": "It can be seen as further extending the marriage of procedural and declarative approaches to proof strategies [2, 13, 8], and addressing issues related to goal flow and goal focus highlighted in [1] \u2013 for a more detailed comparison we refer to [10].", "startOffset": 110, "endOffset": 120}, {"referenceID": 7, "context": "It can be seen as further extending the marriage of procedural and declarative approaches to proof strategies [2, 13, 8], and addressing issues related to goal flow and goal focus highlighted in [1] \u2013 for a more detailed comparison we refer to [10].", "startOffset": 110, "endOffset": 120}, {"referenceID": 0, "context": "It can be seen as further extending the marriage of procedural and declarative approaches to proof strategies [2, 13, 8], and addressing issues related to goal flow and goal focus highlighted in [1] \u2013 for a more detailed comparison we refer to [10].", "startOffset": 195, "endOffset": 198}, {"referenceID": 18, "context": "The lattice based techniques developed for goal type generalisation is similar to antiunification [22] which generalises two terms into one (with substitutions back to the original terms).", "startOffset": 98, "endOffset": 102}, {"referenceID": 15, "context": "More expressive class/link features, which is future work, may require higher-order anti-unification [18] \u2013 and such ideas may also be applicable to graph generalisations.", "startOffset": 101, "endOffset": 105}, {"referenceID": 2, "context": "Other work that may become relevant for our techniques are graph abstractions/transformations used in algorithmic heap-based program verification techniques, such as [3], and for parallelisation of functional programs [12].", "startOffset": 166, "endOffset": 169}, {"referenceID": 9, "context": "Other work that may become relevant for our techniques are graph abstractions/transformations used in algorithmic heap-based program verification techniques, such as [3], and for parallelisation of functional programs [12].", "startOffset": 218, "endOffset": 222}, {"referenceID": 6, "context": "This is the case for [7], which uses a regular expression language (close to LCF tactics), originally developed in [14] to learn proof plans.", "startOffset": 21, "endOffset": 24}, {"referenceID": 11, "context": "This is the case for [7], which uses a regular expression language (close to LCF tactics), originally developed in [14] to learn proof plans.", "startOffset": 115, "endOffset": 119}, {"referenceID": 11, "context": "[14] further claims that explanation based generalisation (EBG)[21] is applied to derive pre/post-conditions, but no details of this are provided.", "startOffset": 0, "endOffset": 4}, {"referenceID": 12, "context": "An EBG approach is also applied to generalise Isabelle proof terms into more generic theorems in [15].", "startOffset": 97, "endOffset": 101}, {"referenceID": 20, "context": "Further, note that our work focuses on proof of conjectures which requires structure, meaning machine learning techniques \u2013 such as [24], which learns heuristics to select relevant axioms/rules for automated provers \u2013 are not sufficient.", "startOffset": 132, "endOffset": 136}, {"referenceID": 14, "context": "However, in [11], an approach to combine essentially our techniques, with more probabilistic techniques to cluster interactive proofs [17], was outlined.", "startOffset": 134, "endOffset": 138}, {"referenceID": 22, "context": "We would also like to utilise work on proof and proof script refactoring [26].", "startOffset": 73, "endOffset": 77}, {"referenceID": 17, "context": "Finally, albeit for source code, [20] argues for the use of graphs to perform refactorings, which further justifies our graph based representation of proof strategies for the work presented here.", "startOffset": 33, "endOffset": 37}, {"referenceID": 13, "context": "We are in the process of implementation in Isabelle combined with the Quantomatic graph rewriting engine [16].", "startOffset": 105, "endOffset": 109}, {"referenceID": 21, "context": "org) we are working on utilising their work on capturing the full proof process, where the user may (interactively) highlight the key features of a proof (step) [25].", "startOffset": 161, "endOffset": 165}], "year": 2017, "abstractText": "The ability to automatically generalise (interactive) proofs and use such generalisations to discharge related conjectures is a very hard problem which remains unsolved; this paper shows how we hope to make a start on solving this problem. We develop a notion of goal types to capture key properties of goals, which enables abstractions over the specific order and number of sub-goals arising when composing tactics. We show that the goal types form a lattice, and utilise this property in the techniques we develop to automatically generalise proof strategies in order to reuse it for proofs of related conjectures. We illustrate our approach with an example.", "creator": "LaTeX with hyperref package"}}}