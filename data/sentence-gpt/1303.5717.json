{"id": "1303.5717", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "20-Mar-2013", "title": "A Reason Maintenace System Dealing with Vague Data", "abstract": "A reason maintenance system which extends an ATMS through Mukaidono's fuzzy logic is described. It supports a problem solver in situations affected by incomplete information and vague data, by allowing nonmonotonic inferences and the revision of previous conclusions when contradictions are detected.\n\nThe only way I can safely infer this from the experience of my friend's wife, her daughter and myself is in the data set of a remote server at the time of the incident. She is not aware of the fact that the local data center, which holds some data from the other side of the river, has closed down and the state is experiencing problems. The state is not cooperating, and there is no way to know when or if the data centers are going to reopen after the incident, so there is no way to know if there will be any immediate intervention.\nThe problem that I see when I am talking about this is that if someone is a part of a remote server that is not open for maintenance, it is not sufficient to tell me what to do when it is time to start repairing.\nThe problem that I have noticed is that this is not the case. It is a very real issue that I have been working on for a few years, working on a remote server. I have started my own server as I have not known it for a long time. It is not the case that I have been working on for a long time. I am not sure how I would like to know if this problem exists. It is a complex issue which can easily cause multiple parties to fail to provide enough information in time. Therefore, if it is not possible to tell me that the problem exists, I am not sure why.\nThis is a very serious problem. The issue that I have been working on for several years has been completely unresolved. I have been working on a remote server for several years. I have started my own server as I have not known it for a long time. It is not the case that I have been working on for a long time. It is not the case that I have been working on for a long time.\nI am aware of the fact that there is no way to know if there will be any immediate intervention. This is a very serious problem. The problem that I have been working on for a long time. I have started my own server as I have not known it for a long time. It is not the case that I have been working on for a long time. It is not the case that I", "histories": [["v1", "Wed, 20 Mar 2013 15:30:37 GMT  (174kb)", "http://arxiv.org/abs/1303.5717v1", "Appears in Proceedings of the Seventh Conference on Uncertainty in Artificial Intelligence (UAI1991)"]], "COMMENTS": "Appears in Proceedings of the Seventh Conference on Uncertainty in Artificial Intelligence (UAI1991)", "reviews": [], "SUBJECTS": "cs.AI", "authors": ["b fringuelli", "s marcugini", "a milani", "s rivoira"], "accepted": false, "id": "1303.5717"}, "pdf": {"name": "1303.5717.pdf", "metadata": {"source": "CRF", "title": "A REASON MAINTENANCE SYSTEM DEALING WITH VAGUE DATA", "authors": [], "emails": [], "sections": [{"heading": null, "text": "INTRODUCTION\nAny reasoning system must deal with belief revision at some extent.\nIn recent years truth maintenance systems have been proposed as powerful tools able to perform belief revision at a general level.\nThese systems can be viewed as constraint propagation mechanisms which tell a problem solver what things it is currently obliged to believe, given a single set of premises and a set of deduction constraints, some of which may be nonmonotonic.\nJustification-based TMS (Doyle 1979) (McAllester 1980) (McDermott 1983) maintain a single context of belief and support nonmonotonic justifications, while assumption-based TMS (de Kleer 1986) (Martins 1 988) avoid the restriction that the overall set of premises is contradiction free, maintaining multiple contexts of belief.\nEarly truth maintenance systems dealt with certain beliefs only, but several successive works extended them in order to allow handling of some kind of uncertainty.\nDe Kleer and Williams (de Kleer 1987) have assigned probabilities to assumptions in an A TMS which diagnoses multiple mutually indipcndent faults.\nFalkenheiner (Falkenheiner 1988) has introduced Dempster-Shafer theory into Doyle's TMS.\nD'Ambrosio (D'Ambrosio 1989) has used an ATMS to compute beliefs for a special case of the Dempster Shafer model.\nProvan (Provan 1989) has incorporated belief functions into A TMS and Laskey and Lehner (Laskey 1989) have shown that any Dempster-Shafer inference system can be represented in a ATMS by attaching probabilities to assumptions that represent hypotheses in a background frame.\nDubois et a!. (Dubois 1990) extended an ATMS in order to handle uncertainty, pervading justifications or grading assumptions, represented in the framework of possibility and necessity measures.\nIn this paper we describe a Fuzzy Truth Maintenance System (FTMS) obtained by extending an ATMS through fuzzy logic.\nThe general idea and motivations of our approach are very close to those of Dubois et a!. (Dubois 1990).\nThe main difference from their work lies in the fact that in our system propositions involve vague predicates which may have intermediary degrees of truth and the underlying logic is truth-functional, while Dubois et al. consider propositions which are true or false, but due to the lack of precision of the available information it can only be estimated to what extent it is possible or necessary that a proposition is true.\nIn the following the basic definitions and properties of the adopted fuzzy logic are reported and, successively, definitions and functionalities of the FTMS are discussed.\nMANY-VALUED RESOLUTION\nLOGI C S AND\nThe work described in this paper is part of a research aiming to compare existing theories of uncertainty (both logical and probabilistic) from the viewpoint\n112 Fringuelli, Marcugini, Milani, Rivoira\nof the efficiency of inference rules and revision mechanisms.\nSince the resolution principle (Robinson 1 965) encompasses several inference rules in classical logic (modus ponens, modus tollens, disjunctive and hypothetical syllogisms, constructive and desctructive dilemmas) and it is widely used in reasoning systems, we firstly focused our attention on extensions of the resolution principle dealing with some kind of uncertainty.\nDubois and Prade (Dubois 1987) extended the resolution principle in the case of uncertain propositions where the uncertainty involves non-vague predicates and it is modeled in terms of necessity measures.\nThe first attempt to a theory of fuzzy resolution was proposed by Lee (Lee 1972) for a fuzzy logic defined as follows.\nLet [S] denote the truth value of a formula S:\n[S] E [0,1]\n[-,S] = 1-[S]\n[R v S] = max([R],[S])\n[R\" S] = min([R],[S])\n[R \ufffd S] = [-,R v S] = max(l-[R],[S]).\nAn interpretation I is said to satisfy a formula S if [S] ;:>: 0.5 under I.\nThe resolution principle corresponds to the following rule of inference:\nlet s1 = x v L1 ;\nSz= -,x vLz;\na logical consequence of S 1 \" Sz is the resolvent:\nand, in fuzzy logic, if [S 1 \" S2l > 0.5 then:\n0.5 < [SJA S2l :5 [R(SJ,S2)l :5 [SJ v S2].\nBasically Lee proved that the resolution principle is complete in fuzzy logic and if every clause in a set has a truth-value greater than 0.5, then all the logical\nconsequences obtained by repeatedly applying the resolution principle will have truth-value at least equal to the most unreliable clause, but never exceeding the truth value of the most reliable one.\nThese results were extended to a more general case by Mukaidono (Mukaidono 1982) (Mukaidono 1989) which allowed the truth value of all the clauses to be taken in the closed interval [0,1], introducing an inference strategy for fuzzy Prolog based on the following definitions.\nThe confidence c(S) of a formula S is defined as\nc(S) =([S] - 0.5) * 2\nand the fuzzy resolution principle asserts that the confidence of resolution Cr of the resolvent R(S 1 ,S2) is:\nCr(R(SJ ,S2))= (max([x],[-,x]) - 0.5) * 2 = lc(x)l\nwhere x is the key predicate in the resolution.\nIf S2 = R(S3, S4) then\nCr(R(Sl , S2)) = min(cr(S2), lc(x)l).\nThe definition [R \ufffd S] = [-,R v S] = max(l -[R],[S]) adopted for implication in fuzzy logic allows the inference of S from R ( or -,R from -,S) only when\n[R \ufffd S] \ufffd [-,R] (or [R \ufffd S] \ufffd [S] respectively).\nThis resolution principle is proved to be complete and significant for any truth value in the closed interval [0,1].\nThe confidence of resolution of an inferred formula S represents the degree of derivability of S from the formulas used in the inference process.\nMukaidono introduced an additional concept for implication (weight of rule) defined as the product of the confidence values of premise and conclusion:\nWR\ufffdS = c(R) * c(S)\nThe weight of rule (usually defined as a closed interval) represents the degree of truth of an implication and it establishes the applicability of the rule, given the confidence of either the premise or the conclusion.\nIn fact it is easy to prove that a rule R w ->S can be applied if and only if:\nA Reason Maintenance System Dealing with Vague Data 113\nlwl \ufffd lc(R)I and lwl \ufffd lc(S)I.\nAccording to the previous definitions it is possible to derive from a given set of fuzzy Hom clauses all the fuzzy logical consequences, together with their confidences of resolution.\nThe following example shows the inference mechanism applied to propositional clauses (first order predicate logic can be easily obtained by introducing unification ).\nFrom:\nrl) A\ufffdB (wl = 0.3}\nr2) B\ufffdC (w2 = -0.4}\nr3) A\ufffdD (w3 = -0.7}\nr4) D\ufffdC (w4 = OJ}\nr5) A ([A]= 0.8}\nit is possible to derive:\nc(A) = ([A]-0.5) * 2 = 0.6; Cr(A) = 1; (from r5)\nc(B) = w1 /c(A) = 0.5 Cr(B) = min(cr(A),Ic(A)I) = 0.6 (from r1, rS)\nSince lw31 > ci(A)I, r3 cannot be applied.\nc(C) = w2/c(B) = -0.8; Cr(C) = min (cr(B), lc(B)I) = 0.5 (from r5,rl ,r2)\nThe fuzzy propositiOn C is therefore a logical consequence of proposition S r5, r1 and r2. The inferred truth-value of C is:\n[C] = c(C)/2 + 0.5 = 0.1\nwhile its confidence of resolution, that represents the degree of derivability of C from the axioms, is:\nCr(C) = 0.5.\nThe confidence c(P) of a conclusion P and its confidence of resolution Cr(P) can be combined to give the confidence of resolved consequence:\ncrc(P) = c(P) * Cr(P).\nDEFINITION OF A FUZZY TRUTH MAINTENANCE SYSTEM\nExtending De Kleer 's definition of ATMS (de Kleer 1986), we define an FfMS in the following way.\nEvery fuzzy formula introduced or derived by the attached problem solver corresponds to an FTMS node. A special kind of node is represented by the atom 1_, corresponding to \"falsity\", for which [1_] = 0 holds in any interpretation.\nA justification is a triple:\n<j,c(n),cr(n)>\nwhere j: XJ,X2, ... ,xm -> n is a propositional Horn clause asserting that the consequent node n is derivable from the conjunction of the antecedent nodes x 1 , ... ,xm and where c(n) and Cr(n) are respectively the confidence and the confidence of resolution established by j for the node n.\nA justification <j,-l,cr(l_)>, where the derived node is falsity, is communicated by the problem solver every time a contradiction is detected.\nAn assumption is a self-justifying node representing the decision of introducing an hypothesis; it is connected to the assumed data through justifications.\nAn en vir o n m e n t is a set of logically con juncted assumptions .\nAn environment E has consistency cs(E) equal to the opposite of the maximal confidence of resolved consequence with which falsity can be derived from E and the current set J of justifications:\ncs(E) = - max Cr(l_)E j\nAn FTMS context is defined as the set formed by the assumptions of an environment and all the nodes derivable from those assumptions.\nThe goal of FTMS is to efficiently update the contexts when new assumptions or justifications are provided by the problem solver.\nThis goal is achieved by associating with every node a description (label) of every context in which the node holds.\nMore formally, a label Ln of the node n is defined as\n114 Fringuelli, Marcugini, Milani, Rivoira\nthe set of all the environments from which n can be derived:\nLn = (Ei : Ei \ufffd n) j\nIn order to save space and time, a problem solver may wish to consider only environments whose consistency is greater than some threshold a and/or from which nodes can be derived with a degree of derivability greater than some threshold \ufffd , where a and \ufffd depend on the problem domain.\nTherefore, given the two lower bounds a and \ufffd four important properties can be defined for the labels:\na label Ln is a-consistent if the consistency of each of its environments is not less than a; a label Ln is \ufffd-sound if n is derivable from each of its environments with a confidence of resolution not less than \ufffd;\na label Ln is a-\ufffd-complete if every a-consistent environment from which n can be derived with a confidence of resolution not less than \ufffd is a superset of some environment in Ln;\na label Ln is minimal if no environment Ei in Ln is a superset of another environment Ek in Ln with crci(n)\ufffdcrck(n).\nThe task of FfMS is to ensure that each label in each node is a-consistent, \ufffd-sound, a-\ufffd-complete and minimal with respect to the current set of justifications .\nThis task is performed by invoking the following label-updating algorithm every time the problem solver adds a new justification.\nFirstly the justification is recorded and then the new label and new confidence values are evaluated for the justified node.\nIf the new label or confidence values are different from the old ones, the algorithm considers the datum associated with the node. If it is not the falsity ,then the updating process recursively involves the labels and confidences of all the consequent nodes .\nIf the newly justified node is falsity , the consistency of each environment in the label is computed and the environment database is updated.\nIt is worth noticing that the revision of node confidences can make no more significant previously applied rules , forcing the system to retract the corresponding justifications.\nJustifications are made retractable by conjoining them\nwith extra assumptions which represent their defeasability.\nOnly the minimal environment database (MEDB) is maintained in the sense that an environment Ez is recorded in the database only if no environment E1 exists such that:\n(E1 c Ez) and (cs(El) > cs(Ez)).\nIn contrast with ATMS, where inconsistent environments are removed from every node label, FfMS always keeps the environments in their labels, since consistency can be changed by successive justifications.\nFfMS maintains for each fuzzy formula S introduced or derived by an attached problem solver the following information:\n-the truth value of S, represented by the confidence established by the justifications of the corresponding node;\n-the degree of derivability of S from the current knowledge, represented by the confidence of resolution of the corresponding node;\n-the minimal set of environments from which S can be derived, together with their consistency values.\nAt each step of the reasoning process, the problem solver can therefore rank the partial solutions currently available on the basis of several ordering criteria (truth value, degree of derivability, consistency of the hypotheses), discarding or eliminating solutions which are not enough founded.\nThe main mechanisms for updating labels and confidences and their possible effects on the reasoning process are illustrated by the following example.\nLet us suppose that the problem solver, on the basis of its own domain knowledge and inference procedures, has already derived and communicated to FfMS the justifications reported in figure 1 (where 1t, p, cr, 't are assumptions and j_ indicates falsity) from which FfMS has determined the labels and the minimal environment database reported in figure 2.\nThe consequent net of dependencies between assumptions and derived propositions is shown in figure 3.\nR5: A,B \ufffd E, { w5= 0.2}\nR6: A,C \ufffd F, {w6= 0.3}\nR7: E,F \ufffd H, {w7= 0.4}\nR8: C,D \ufffd F, {w8= 0.4}\nR9: B,F \ufffd E, { w9= 0.3} R1 0: C,B \ufffd j_, {wlO= 0.2}\nR1 1: F,D \ufffd G, (w11= 0.2}\nR12: A,H \ufffd G, {wl2= 0.4}\nR13: F,G \ufffd E, {wl3= 0.4}\nR 14: D,E \ufffd j_, { wl4= 0.5}\nfigure Ia: set of inference rules\nJ1 : < 1t \ufffd A, c(A) = 0.6, cr(A) = 1>\nJ2: < p \ufffd B, c(B) = 0.4, Cr(B) = 1>\nh < cr \ufffd C, c(C) = 0.4, cr(C) = I>\nJ4: < 't \ufffd D, c(D) = 0.4, Cr(D) = 1>\n15: <A,B \ufffd E, c(E) = 0.5, cr(E) = 0.5>\n16: <A,C \ufffd F, c(F) = 0.75, Cr(F) = 0.75>\nJ7: <E,F \ufffd H, c(H) = 0.8, Cr(H) = 0.8>\nJ8: <C,D \ufffd F, c(F) = 1, Cr(F) = 1>\nJ9: <B,F \ufffd E, c(E) = 0.75, cr(E) = 0.75>\nJ 1 0: <C,B \ufffd j_, c(j_) = 0.5, Cr(j_) = 0.5>\nJ 1 1 : <F,D \ufffd G, c(G) = 0.75, Cr(G) = 0.75>\nJ 1 2: <A,H \ufffd G, c(G) = 0.76, Cr(G) = 0.53>\nfigure 1 b: a current set of justifications\nLA = {[(x), cs=ll}\nLB = ([(p), cs=l]}\nLc = {[(cr), CS=ll}\nLo = {[('t), cs=ll}\nLE = ([(7t,p), CS=l), [(7t,cr,'t), cs=-0.5)}\nLp = ([(x,cr), cs=l), [(cr,'t), cs=ll}\nLa= ([(x,p,cr), cs=-0.5), [(cr,'t), cs=ll}\nLH = {[(p,cr,'t), cs=-0.5]}\nfigure 2a: the label of each node\nA Reason Maintenance System Dealing with Vague Data 115\nMEDB: [(p,cr), cs=-0.5)\nfigure 2b: the minimal environment database\nfigure 3: The current dependency net\nLet now the problem solver adds the justification (see figure 4):\nJ 13 <F,G \ufffd E, c(E) = 0.8, Cr(E) = 0.75>\nSince a new confidence value for E is introduced, it is necessary to update the truth-values of all the consequent nodes. In this case the updating process terminates after the new values for H have been evaluated, because the connfidence in G is not affected.\nc(H) = 0.5 Cr(H) = 0.5\n116 Fringuelli, Marcugini, Milani, Rivoira\nfigure 4: The added justification J 13\nThe effect of J 1 3 on the labels is the following:\nLE = ([(1t,p), CS=l], [(cr;t), CS=l])\nLH = ([(7t,p,cr), CS=-0.5], [(cr;t), cs = l])\nLG = ( [(7t,p,cr), cs=-0.5], [(cr,t), cs=l])\nLet us finally suppose that a new contradiction, represented by the justification J 1 4, is detected by the problem solver:\nJ 14: <D,E \ufffd l_, c(_l_) = 0.4, Cr(_l_) = 0.4>\nThis justification modifies the minimal environment database, introducing two new entries:\nMEDB:\n[(cr,t), cs=-0.5]\n[(7t,p,t), cs=-0.4] [(cr,t), cs=-0.4]\nTherefore the new labels become:\nLE = ([(7t,p), cs=l], [(cr,t), cs=-0.4])\nLF = ([(1t,cr), cs=l], [(cr,t), cs=-0.4])\nLG = ([(7t,p,cr), cs=-0.5], [(cr,t), cS=-0.4])\nLH = {[(7t,p,cr), CS=-0.5], [(cr,t), cs = -0.4])\nCONCLUSION\nThe system described in this paper supports a problem solver in the task of selecting among several alternatives in situations affected by incomplete information , uncertain knowledge and vague data.\nFTMS allows the problem solver to make nonmonotonic inferences, revising previous conclusions if contradictions are detected.\nEvery derived belief is associated with three parameters: a confidence which shows how much it is true, a confidence of resolution, which tells to what extent it is derivable from the current knowledge, and a consistency, which represents the degree of contradiction of the hypotheses which it relies on.\nDependencies between beliefs are recorded so that when new information is supplied, only the affected beliefs are involved in the updating process.\nFTMS has been successfully implemented in Prolog.\nAcknowledgements.\nThe authors wish to thank Settimo Termini fro the valuable discussions about many valued logics.\nThis work has been supported by P.F. Robotica Consiglio N azionale delle Ricerche grant n.90.00556.67 and M.U.R.S.T.- 40% \"Tecniche di Ragionamento Automatico e Sistemi Intelligenti\".\nReferences\nB.D'Ambrosio (1989). A Hybrid Approach to Reasoning Under Uncertainty. In L.N.Kanal, T.S.Levitt, J.F.Lemmer (eds.) Uncertainty in Artificial Intelligence: 3rd Conference, North-Holland, pp.267283.\nJ.Doyle (1 979). A Truth Maintenance System. In Artificial Intelligence, 12 (3) ,pp 231 - 272.\nD.Dubois, J.Lang, H.Prade (1990). Handling Uncertain Knowledge in an A TMS Using Possibilistic Logic. In Proceeding of ECAI Workshop on Truth Maintenance Systems ,Stockolm.\nD.Dubois, H.Prade (1987). Necessity Measures and the Resolution Principle. In IEEE Trans. on Systems, Man and Cyberneticss , vol.SMC-17, n.3, pp.474-478.\nB.Falkenheiner (1988). Towards a General Purpose Belief Maintenance System. In J.F.Lemmer, L.N.Kanal\nA Reason Maintenance System Dealing with Vague Data 117\n(eds.) Uncertainty in A rtificial Intelligence: 2nd Conference, North-Holland, pp.125- l32.\nJ.de Kleer (1986). An Assumption-based TMS. In Artificial Intelligence , 28 (2) , pp.127-162.\nJ.de Kleer, B.C.Williams (1987). Diagnosing Multiple Faults. In Artificial Intelligence , 32, pp. 97-130.\nK.B.Laskey, P.E. Lehner(1989). Assumptions, Beliefs and Probabilities. In Artificial Intelligence 41, pp. 65- 77.\nR.C.T.Lee (1972). Fuzzy Logic and the Resolution Principle. In Journal of ACM, 19 (1), pp.1 09-1 19.\nJ.P.Martins, S.C.Shapiro (1988). A Model for Belief Revision. In Artificial Intelligence , 35, pp. 25-79.\nD.McAIIester (1980). An Outlook on Truth Maintenance. In A I Memo 551 , AI Lab., MIT, Cambridge (MA).\nD.McDermott (1983). Context and Data Dependencies. In A Synthesis, IEEE Trans. Pattern Anai.Mach. Intell., 5 (3), pp. 237-246.\nM.Mukaidono (1982 ). Fuzzy Inference of Resolution Style. In R.R. Yager (Ed.) Fuzzy Set and Possibility Theory, Pergamon Press, New York , pp. 224-231.\nM.Mukaidono, Z. Shen, L. Ding (1989 ). Fundamentals of Fuzzy Prolog. In International Journal o f Approximate Reasoning, 3, pp. 179-193.\nG.M. Provan (1989). An Analysis of ATMS-based Techniques for Computing Dempster-Shafer Belief Functions. In Proceedings of the.9th IJCAI , Detroit Aug. 1989 , pp. 1115-1120.\nJ .A.Robinson (1965). A Machine-oriented Logic Based on the Resolution Principle. In Journal of ACM, 12 (1), pp. 23-41."}], "references": [{"title": "A Hybrid Approach to Reasoning Under Uncertainty", "author": ["B.D'Ambrosio"], "venue": "L.N.Kanal, T.S.Levitt, J.F.Lemmer (eds.) Uncertainty in Artificial Intelligence: 3rd Conference, North-Holland, pp.267283.", "citeRegEx": "B.D.Ambrosio,? 1989", "shortCiteRegEx": "B.D.Ambrosio", "year": 1989}, {"title": "An Outlook on Truth Maintenance", "author": ["D.McAIIester"], "venue": "A I Memo 551 , AI Lab., MIT, Cambridge (MA).", "citeRegEx": "D.McAIIester,? 1980", "shortCiteRegEx": "D.McAIIester", "year": 1980}, {"title": "Context and Data Dependencies", "author": ["D.McDermott"], "venue": "A Synthesis, IEEE Trans. Pattern Anai.Mach. Intell., 5 (3), pp. 237-246.", "citeRegEx": "D.McDermott,? 1983", "shortCiteRegEx": "D.McDermott", "year": 1983}], "referenceMentions": [], "year": 2011, "abstractText": "A reason maintenance system which extends an ATMS through Mukaidono's fuzzy logic is described. It supports a problem solver in situations affected by incomplete information and vague data, by allowing nonmonotonic inferences and the revision of previous conclusions when contradictions are detected.", "creator": "pdftk 1.41 - www.pdftk.com"}}}