{"id": "1305.0208", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "1-May-2013", "title": "Perceptron Mistake Bounds", "abstract": "We present a brief survey of existing mistake bounds and introduce novel bounds for the Perceptron or the kernel Perceptron algorithm. Our novel bounds generalize beyond standard margin-loss type bounds, allow for any convex and Lipschitz loss function, and admit a very simple proof. A new technique of learning the perceptron is used. We are currently using a new method to detect new mistakes in some of the Perceptron algorithms, and are actively improving our understanding of the behavior of those algorithms. We will continue to use this method for further research.", "histories": [["v1", "Wed, 1 May 2013 15:45:34 GMT  (22kb)", "https://arxiv.org/abs/1305.0208v1", null], ["v2", "Tue, 23 Jul 2013 02:13:57 GMT  (22kb)", "http://arxiv.org/abs/1305.0208v2", null]], "reviews": [], "SUBJECTS": "cs.LG", "authors": ["mehryar mohri", "afshin rostamizadeh"], "accepted": false, "id": "1305.0208"}, "pdf": {"name": "1305.0208.pdf", "metadata": {"source": "CRF", "title": null, "authors": ["Mehryar Mohri", "Afshin Rostamizadeh"], "emails": [], "sections": [{"heading": null, "text": "ar X\niv :1\n30 5.\n02 08\nv2 [\ncs .L\nG ]\n2 3\nJu l 2\n01 3"}, {"heading": "1 Introduction", "text": "The Perceptron algorithm belongs to the broad family of on-line learning algorithms (see Cesa-Bianchi and Lugosi [2006] for a survey) and admits a large number of variants. The algorithm learns a linear separator by processing the training sample in an on-line fashion, examining a single example at each iteration [Rosenblatt, 1958]. At each round, the current hypothesis is updated if it makes a mistake, that is if it incorrectly classifies the new training point processed. The full pseudocode of the algorithm is provided in Figure 1. In what follows, we will assume that w0 = 0 and \u03b7 = 1 for simplicity of presentation, however, the more general case also allows for similar guarantees which can be derived following the same methods we are presenting. This paper briefly surveys some existing mistake bounds for the Perceptron algorithm and introduces new ones which can be used to derive generalization bounds in a stochastic setting. A mistake bound is an upper bound on the number of updates, or the number of mistakes, made by the Perceptron algorithm when processing a sequence of training examples. Here, the bound will be expressed in terms of the performance of any linear separator, including the best. Such mistake bounds can be directly used to derive generalization guarantees for a combined hypothesis, using existing on-line-to-batch techniques."}, {"heading": "2 Separable case", "text": "The seminal work of Novikoff [1962] gave the first margin-based bound for the Perceptron algorithm, one of the early results in learning theory and probably one of the first based on the notion of margin. Assuming that the data is separable with some margin \u03c1, Novikoff showed that the number of mistakes made by the Perceptron algorithm can be bounded as a function of the normalized margin \u03c1/R, where R is the radius of the sphere containing the training instances. We start with a Lemma that can be used to prove Novikoff\u2019s theorem and that will be used throughout.\nLemma 1. Let I denote the set of rounds at which the Perceptron algorithm makes an update when processing a sequence of training instances x1, . . . ,xT \u2208 RN . Then, the following inequality holds: \u2225\u2225\u2225 \u2211\nt\u2208I\nytxt \u2225\u2225\u2225 \u2264\n\u221a\u2211\nt\u2208I\n\u2016xt\u20162 .\nProof. The inequality holds using the following sequence of observations,\n\u2225\u2225\u2225 \u2211\nt\u2208I\nytxt \u2225\u2225\u2225 = \u2225\u2225\u2225 \u2211\nt\u2208I\n(wt+1 \u2212wt) \u2225\u2225\u2225 (definition of updates)\n= \u2016wT+1\u2016 (telescoping sum, w0 = 0)\n=\n\u221a\u2211\nt\u2208I\n\u2016wt+1\u20162 \u2212 \u2016wt\u20162 (telescoping sum, w0 = 0)\n=\n\u221a\u2211\nt\u2208I\n\u2016wt + ytxt\u20162 \u2212 \u2016wt\u20162 (definition of updates)\n= \u221a\u221a\u221a\u221a \u2211\nt\u2208I 2 ytwt \u00b7 xt\ufe38 \ufe37\ufe37 \ufe38 \u22640 +\u2016xt\u20162\n\u2264 \u221a\u2211\nt\u2208I\n\u2016xt\u20162 .\nThe final inequality uses the fact that an update is made at round t only when the current hypothesis makes a mistake, that is, yt(wt \u00b7xt) \u2264 0. \u2293\u2294\nThe lemma can be used straightforwardly to derive the following mistake bound for the separable setting.\nTheorem 1 ([Novikoff, 1962]). Let x1, . . . ,xT \u2208 RN be a sequence of T points with \u2016xt\u2016 \u2264 r for all t \u2208 [1, T ], for some r > 0. Assume that\nthere exist \u03c1 > 0 and v \u2208 RN , v 6= 0, such that for all t \u2208 [1, T ], \u03c1 \u2264 yt(v\u00b7xt)\n\u2016v\u2016 . Then, the number of updates made by the Perceptron algorithm\nwhen processing x1, . . . ,xT is bounded by r 2/\u03c12.\nProof. Let I denote the subset of the T rounds at which there is an update, and let M be the total number of updates, i.e., |I | = M . Summing up the inequalities yields:\nM\u03c1 \u2264 v \u00b7\u2211t\u2208I ytxt \u2016v\u2016 \u2264 \u2225\u2225\u2225 \u2211\nt\u2208I\nytxt \u2225\u2225\u2225 \u2264 \u221a\u2211\nt\u2208I\n\u2016xt\u20162 \u2264 \u221a Mr2,\nwhere the second inequality holds by the Cauchy-Schwarz inequality, the third by Lemma 1 and the final one by assumption. Comparing the leftand right-hand sides gives \u221a M \u2264 r/\u03c1, that is, M \u2264 r2/\u03c12. \u2293\u2294"}, {"heading": "3 Non-separable case", "text": "In real-world problems, the training sample processed by the Perceptron algorithm is typically not linearly separable. Nevertheless, it is possible to give a margin-based mistake bound in that general case in terms of the radius of the sphere containing the sample and the margin-based loss of an arbitrary weight vector. We present two different types of bounds: first, a bound that depends on the L1-norm of the vector of \u03c1-margin hinge losses, or the vector of more general losses that we will describe, next a bound that depends on the L2-norm of the vector of margin losses, which extends the original results presented by Freund and Schapire [1999].\n3.1 L1-norm mistake bounds\nWe first present a simple proof of a mistake bound for the Perceptron algorithm that depends on the L1-norm of the losses incurred by an arbitrary weight vector, for a general definition of the loss function that covers the \u03c1-margin hinge loss. The family of admissible loss functions is quite general and defined as follows.\nDefinition 1 (\u03b3-admissible loss function). A \u03b3-admissible loss function \u03c6\u03b3 : R \u2192 R+ satisfies the following conditions: 1. The function \u03c6\u03b3 is convex.\n2. \u03c6\u03b3 is non-negative: \u2200x \u2208 R, \u03c6\u03b3(x) \u2265 0. 3. At zero, the \u03c6\u03b3 is strictly positive: \u03c6\u03b3(0) > 0. 4. \u03c6\u03b3 is \u03b3-Lipschitz: |\u03c6\u03b3(x)\u2212 \u03c6\u03b3(y)| \u2264 \u03b3|x\u2212 y|, for some \u03b3 > 0.\nThese are mild conditions satisfied by many loss functions including the hinge-loss, the squared hinge-loss, the Huber loss and general p-norm losses over bounded domains.\nTheorem 2. Let I denote the set of rounds at which the Perceptron algorithm makes an update when processing a sequence of training instances x1, . . . ,xT \u2208 RN . For any vector u \u2208 RN with \u2016u\u2016 \u2264 1 and any \u03b3-admissible loss function \u03c6\u03b3, consider the vector of losses incurred by u: L\u03c6\u03b3 (u) = [ \u03c6\u03b3(yt(u \u00b7 xt)) ] t\u2208I\n. Then, the number of updates MT = |I | made by the Perceptron algorithm can be bounded as follows:\nMT \u2264 inf \u03b3>0,\u2016u\u2016\u22641\n1\n\u03c6\u03b3(0) \u2016L\u03c6\u03b3 (u)\u20161 +\n\u03b3\n\u03c6\u03b3(0)\n\u221a\u2211\nt\u2208I\n\u2016xt\u20162 . (1)\nIf we further assume that \u2016xt\u2016 \u2264 r for all t \u2208 [1, T ], for some r > 0, this implies\nMT \u2264 inf \u03b3>0,\u2016u\u2016\u22641\n( \u03b3r\n\u03c6\u03b3(0) +\n\u221a \u2016L\u03c6\u03b3 (u)\u20161\n\u03c6\u03b3(0)\n)2 . (2)\nProof. For all \u03b3 > 0 and u with \u2016u\u2016 \u2264 1, the following statements hold. By convexity of \u03c6\u03b3 we have\n1 MT \u2211 t\u2208I \u03c6\u03b3(ytu \u00b7 xt) \u2265 \u03c6\u03b3(u \u00b7 z), where\nz = 1 MT \u2211 t\u2208I ytxt. Then, by using the Lipschitz property of \u03c6\u03b3 we have,\n\u03c6\u03b3(u \u00b7 z) = \u03c6\u03b3(u \u00b7 z)\u2212 \u03c6\u03b3(0) + \u03c6\u03b3(0) = \u2212 \u2223\u2223\u03c6\u03b3(0)\u2212 \u03c6\u03b3(u \u00b7 z) \u2223\u2223+ \u03c6\u03b3(0)\n\u2265 \u2212\u03b3|u \u00b7 z|+ \u03c6\u03b3(0) .\nCombining the two inequalities above and multiplying both sides by MT implies\nM\u03c6\u03b3(0) \u2264 \u2211\nt\u2208I\n\u03c6\u03b3(ytu \u00b7 xt) + \u03b3 \u2223\u2223\u2223 \u2211\nt\u2208I\nytu \u00b7 xt \u2223\u2223\u2223 .\nFinally, using the Cauchy-Schwartz inequality and Lemma 1 yields\n\u2223\u2223\u2223 \u2211\nt\u2208I\nytu \u00b7 xt \u2223\u2223\u2223 = \u2223\u2223\u2223u \u00b7 (\u2211\nt\u2208I\nytxt )\u2223\u2223\u2223 \u2264 \u2016u\u2016 \u2225\u2225\u2225 \u2211\nt\u2208I\nytxt \u2225\u2225\u2225 \u2264\n\u221a\u2211\nt\u2208I\n\u2016xt\u20162 ,\nwhich completes the proof of the first statement after re-arranging terms. If it is further assumed that \u2016xt\u2016 \u2264 r for all t \u2208 I , then this implies M\u03c6\u03b3(0)\u2212r \u221a M\u2212\u2211t\u2208I \u03c6\u03b3(ytu\u00b7xt) \u2264 0. Solving this quadratic expression\nin terms of \u221a M proves the second statement. \u2293\u2294\nIt is straightforward to see that the \u03c1-margin hinge loss \u03c6\u03c1(x) = (1 \u2212 x/\u03c1)+ is (1/\u03c1)-admissible with \u03c6\u03c1(0) = 1 for all \u03c1, which gives the following corollary.\nCorollary 1. Let I denote the set of rounds at which the Perceptron algorithm makes an update when processing a sequence of training instances x1, . . . ,xT \u2208 RN . For any \u03c1 > 0 and any u \u2208 RN with \u2016u\u2016 \u2264 1, consider the vector of \u03c1-hinge losses incurred by u: L\u03c1(u) = [ (1 \u2212 yt(u\u00b7xt) \u03c1 )+ ] t\u2208I\n. Then, the number of updates MT = |I | made by the Perceptron algorithm can be bounded as follows:\nMT \u2264 inf \u03c1>0\u2016u\u2016\u22641 \u2016L\u03c1(u)\u20161 +\n\u221a\u2211 t\u2208I \u2016xt\u20162\n\u03c1 . (3)\nIf we further assume that \u2016xt\u2016 \u2264 r for all t \u2208 [1, T ], for some r > 0, this implies\nMT \u2264 inf \u03c1>0,\u2016u\u2016\u22641\n( r\n\u03c1 +\n\u221a \u2016L\u03c1(u)\u20161 )2 . (4)\nThe mistake bound (3) appears already in Cesa-Bianchi et al. [2004] but we could not find its proof either in that paper or in those it references for this bound. Another application of Theorem 2 is to the squared-hinge loss \u03c6\u03c1(x) = (1 \u2212 x/\u03c1)2+. Assume that \u2016x\u2016 \u2264 r, then the inequality \u2016y(u \u00b7 x)\u2016 \u2264 \u2016u\u2016\u2016x\u2016 \u2264 r implies that the derivative of the hinge-loss is also bounded, achieving a maximum absolute value |\u03c6\u2032\u03c1(r)| = | 2\u03c1 ( r\u03c1 \u2212 1)| \u2264 2r\u03c12 . Thus, the \u03c1-margin squared hinge loss is (2r/\u03c12)-admissible with \u03c6\u03c1(0) = 1 for all \u03c1. This leads to the following corollary.\nCorollary 2. Let I denote the set of rounds at which the Perceptron algorithm makes an update when processing a sequence of training instances x1, . . . ,xT \u2208 RN with \u2016xt\u2016 \u2264 r for all t \u2208 [1, T ]. For any \u03c1 > 0 and any u \u2208 RN with \u2016u\u2016 \u2264 1, consider the vector of \u03c1-margin squared hinge losses incurred by u: L\u03c1(u) = [ (1\u2212 yt(u\u00b7xt)\n\u03c1 )2+ ] t\u2208I . Then, the num-\nber of updates MT = |I | made by the Perceptron algorithm can be bounded as follows:\nMT \u2264 inf \u03c1>0\u2016u\u2016\u22641\n\u2016L\u03c1(u)\u20161 + 2r\n\u221a\u2211 t\u2208I \u2016xt\u20162\n\u03c12 . (5)\nThis also implies\nMT \u2264 inf \u03c1>0,\u2016u\u2016\u22641\n( 2r2\n\u03c12 +\n\u221a \u2016L\u03c1(u)\u20161 )2 . (6)\nTheorem 2 can be similarly used to derive mistake bounds in terms of other admissible losses.\n3.2 L2-norm mistake bounds\nThe original results of this section are due to Freund and Schapire [1999]. Here, we extend their proof to derive finer mistake bounds for the Perceptron algorithm in terms of the L2-norm of the vector of hinge losses of an arbitrary weight vector at points where an update is made.\nTheorem 3. Let I denote the set of rounds at which the Perceptron algorithm makes an update when processing a sequence of training instances x1, . . . ,xT \u2208 RN . For any \u03c1 > 0 and any u \u2208 RN with \u2016u\u2016 \u2264 1, consider the vector of \u03c1-hinge losses incurred by u: L\u03c1(u) = [ (1 \u2212 yt(u\u00b7xt) \u03c1 )+ ] t\u2208I\n. Then, the number of updates MT = |I | made by the Perceptron algorithm can be bounded as follows:\nMT \u2264 inf \u03c1>0,\u2016u\u2016\u22641\n\n \u2016L\u03c1(u)\u20162\n2 + \u221a\u221a\u221a\u221a\u2016L\u03c1(u)\u201622 4 + \u221a\u2211 t\u2208I \u2016xt\u20162 \u03c1   2 . (7)\nIf we further assume that \u2016xt\u2016 \u2264 r for all t \u2208 [1, T ], for some r > 0, this implies\nMT \u2264 inf \u03c1>0,\u2016u\u2016\u22641\n( r\n\u03c1 + \u2016L\u03c1(u)\u20162\n)2 . (8)\nProof. We first reduce the problem to the separable case by mapping each input vector xt \u2208 RN to a vector in x\u2032t \u2208 RN+T as follows:\nxt =\n\n xt,1 ...\nxt,N\n  7\u2192 x\u2032t = [ xt,1 . . . xt,N 0 . . . 0 \u2206\ufe38\ufe37\ufe37\ufe38\n(N + t)th component\n0 . . . 0 ]\u22a4\n,\nwhere the first N components of x\u2032t coincide with those of x and the only other non-zero component is the (N + t)th component which is set to \u2206, a parameter \u2206 whose value will be determined later. Define lt by lt = (1 \u2212 ytu\u00b7xt\u03c1 )1t\u2208I . Then, the vector u is replaced by the vector u \u2032 defined by\nu\u2032 = [ u1 Z . . . uN Z y1l1\u03c1 \u2206Z . . . yT lT \u03c1 \u2206Z ]\u22a4 .\nThe first N components of u\u2032 are equal to the components of u/Z and the remaining T components are functions of the labels and hinge losses. The normalization factor Z is chosen to guarantee that \u2016u\u2032\u2016 = 1: Z =\u221a\n1 + \u03c12\u2016L\u03c1(u)\u20162\n\u22062 . Since the additional coordinates of the instances are\nnon-zero exactly once, the predictions made by the Perceptron algorithm for x\u2032t, t \u2208 [1, T ] coincide with those made in the original space for xt, t \u2208 [1, T ]. In particular, a change made to the additional coordinates of w\u2032 does no affect any subsequent prediction. Furthermore, by definition of u\u2032 and x\u2032t, we can write for any t \u2208 I :\nyt(u \u2032 \u00b7 x\u2032t) = yt (u \u00b7 xt Z +\u2206 ytlt\u03c1 Z\u2206 )\n= ytu \u00b7 xt\nZ +\nlt\u03c1\nZ\n\u2265 ytu \u00b7 xt Z + \u03c1\u2212 yt(u \u00b7 xt) Z = \u03c1 Z ,\nwhere the inequality results from the definition of lt. Summing up the inequalities for all t \u2208 I and using Lemma 1 yields MT \u03c1Z \u2264 \u2211 t\u2208I yt(u\n\u2032 \u00b7 x\u2032t) \u2264 \u221a\u2211 t\u2208I \u2016x\u2032t\u20162. Substituting the value of Z and re-writing in terms of x implies:\nM2T \u2264 ( 1 \u03c12 + \u2016L\u03c1(u)\u20162 \u22062 )( R2 +MT\u2206 2 )\n= R2\n\u03c12 + R2\u2016L\u03c1(u)\u20162 \u22062 + MT\u2206 2 \u03c12 +MT \u2016L\u03c1(u)\u20162 ,\nwhere R = \u221a\u2211\nt\u2208I \u2016xt\u20162. Now, solving for \u2206 to minimize this bound gives \u22062 =\n\u03c1\u2016L\u03c1(u)\u2016R\u221a MT and further simplifies the bound\nM2T \u2264 R2\n\u03c12 + 2\n\u221a MT \u2016L\u03c1(u)\u2016R\n\u03c1 +MT \u2016L\u03c1(u)\u20162\n= (R \u03c1 + \u221a MT \u2016L\u03c1(u)\u20162 )2 .\nSolving the second-degree inequality MT \u2212 \u221a MT \u2016L\u03c1(u)\u20162\u2212R\u03c1 \u2264 0 proves the first statement of the theorem. The second theorem is obtained by first bounding R with r \u221a MT and then solving the second-degree inequality. \u2293\u2294"}, {"heading": "3.3 Discussion", "text": "One natural question this survey raises is the respective quality of the L1- and L2-norm bounds. The comparison of (4) and (8) for the \u03c1-margin hinge loss shows that, for a fixed \u03c1, the bounds differ only by the following two quantities:\nmin \u2016u\u2016\u22641 \u2016L\u03c1(u)\u20161 = min \u2016u\u2016\u22641\n\u2211\nt\u2208I\n(1\u2212 yt ( u \u00b7 xt)/\u03c1 ) +\nmin \u2016u\u2016\u22641 \u2016L\u03c1(u)\u201622 = min \u2016u\u2016\u22641\n\u2211\nt\u2208I\n(1\u2212 yt ( u \u00b7 xt)/\u03c1 )2 + .\nThese two quantities are data-dependent and in general not comparable. For a vector u for which the individual losses (1\u2212 yt ( u \u00b7 xt)) are all less than one, we have \u2016L\u03c1(u)\u201622 \u2264 \u2016L\u03c1(u)\u20161, while the contrary holds if the individual losses are larger than one."}, {"heading": "4 Generalization Bounds", "text": "In this section, we consider the case where the training sample processed is drawn according to some distribution D. Under some mild conditions on the loss function, the hypotheses returned by an on-line learning algorithm can then be combined to define a hypothesis whose generalization error can be bounded in terms of its regret. Such a hypothesis can be determined via cross-validation Littlestone [1989] or using the online-tobatch theorem of Cesa-Bianchi et al. [2004]. The latter can be combined with any of the mistake bounds presented in the previous section to derive generalization bounds for the Perceptron predictor. Given \u03b4 > 0, a sequence of labeled examples (x1, y1), . . . , (yT , xT ), a sequence of hypotheses h1, . . . , hT , and a loss function L, define the penalized risk minimizing hypothesis as h\u0302 = hi\u2217 with\ni\u2217 = argmin i\u2208[1,T ]\n1\nT \u2212 i+ 1\nT\u2211\nt=i\nL(ythi(xt)) +\n\u221a log T (T+1)\n\u03b4\n2(T \u2212 i+ 1) .\nThe following theorem gives a bound on the expected loss of h\u0302 on future examples.\nTheorem 4 (Cesa-Bianchi et al. [2004]). Let S be a labeled sample ((x1, y1), . . . , (xT , yT )) drawn i.i.d. according to D, L a loss function bounded by one, and h1, . . . , hT the sequence of hypotheses generated by an on-line algorithm A sequentially processing S. Then, for any \u03b4 > 0, with probability at least 1\u2212 \u03b4, the following holds:\nE (x,y)\u223cD [L(yh\u0302(x))] \u2264 1 T\nT\u2211\ni=1\nL(yihi(xi)) + 6\n\u221a 1\nT log\n2(T + 1)\n\u03b4 . (9)\nNote that this theorem does not require the loss function to be convex. Thus, if L is the zero-one loss, then the empirical loss term is precisely the average number of mistakes made by the algorithm. Plugging in any of the mistake bounds from the previous sections then gives us a learning guarantee with respect to the performance of the best hypothesis as measured by a margin-loss (or any \u03b3-admissible loss if using Theorem 2). Let w\u0302 denote the weight vector corresponding to the penalized risk minimizing Perceptron hypothesis chosen from all the intermediate hypotheses generated by the algorithm. Then, in view of Theorem 2, the following corollary holds.\nCorollary 3. Let I denote the set of rounds at which the Perceptron algorithm makes an update when processing a sequence of training instances x1, . . . ,xT \u2208 RN . For any vector u \u2208 RN with \u2016u\u2016 \u2264 1 and any \u03b3-admissible loss function \u03c6\u03b3, consider the vector of losses incurred by u: L\u03c6\u03b3 (u) = [ \u03c6\u03b3(yt(u \u00b7 xt)) ] t\u2208I\n. Then, for any \u03b4 > 0, with probability at least 1\u2212 \u03b4, the following generalization bound holds for the penalized risk minimizing Perceptron hypothesis w\u0302:\nPr (x,y)\u223cD\n[y(w\u0302 \u00b7 x) < 0]\n\u2264 inf \u03b3>0,\u2016u\u2016\u22641 \u2016L\u03c6\u03b3 (u)\u20161 \u03c6\u03b3(0)T\n+ \u03b3 \u221a\u2211 t\u2208I \u2016xt\u20162\n\u03c6\u03b3(0)T + 6\n\u221a 1\nT log\n2(T + 1)\n\u03b4 .\nAny \u03b3-admissible loss can be used to derive a more explicit form of this bound in special cases, in particular the hinge loss or the squared hinge loss. Using Theorem 3, we obtain the following L2-norm generalization bound.\nCorollary 4. Let I denote the set of rounds at which the Perceptron algorithm makes an update when processing a sequence of training instances x1, . . . ,xT \u2208 RN . For any \u03c1 > 0 and any u \u2208 RN with \u2016u\u2016 \u2264 1, consider the vector of \u03c1-hinge losses incurred by u: L\u03c1(u) = [ (1 \u2212 yt(u\u00b7xt) \u03c1 )+ ] t\u2208I\n. Then, for any \u03b4 > 0, with probability at least 1 \u2212 \u03b4, the following generalization bound holds for the penalized risk minimizing\nPerceptron hypothesis w\u0302:\nPr (x,y)\u223cD\n[y(w\u0302 \u00b7 x) < 0]\n\u2264 inf \u03c1>0,\u2016u\u2016\u22641\n1\nT\n\n \u2016L\u03c1(u)\u20162\n2 + \u221a\u221a\u221a\u221a\u2016L\u03c1(u)\u201622 4 + \u221a\u2211 t\u2208I \u2016xt\u20162 \u03c1   2\n+ 6\n\u221a 1\nT log\n2(T + 1)\n\u03b4 ."}, {"heading": "5 Kernel Perceptron algorithm", "text": "The Perceptron algorithm of Figure 1 can be straightforwardly extended to define a non-linear separator using a positive definite kernel K [Aizerman et al., 1964]. Figure 2 gives the pseudocode of that algorithm known as the kernel Perceptron algorithm. The classifier sgn(h) learned by the algorithm is defined by h : x 7\u2192 \u2211Tt=1 \u03b1tytK(xt, x). The results of the previous sections apply similarly to the kernel perceptron algorithm with \u2016xt\u20162 replaced with K(xt, xt). In particular, the quantity \u221a\u2211\nt\u2208I \u2016xt\u20162 appearing in several of the learning guarantees can be replaced with the familiar trace Tr[K] of the kernel matrix K = [K(xi, xj)]i,j\u2208I over the set of points at which an update is made, which is a standard term appearing in margin bounds for kernel-based hypothesis sets."}], "references": [{"title": "Theoretical foundations of the potential function method in pattern recognition learning", "author": ["Mark A. Aizerman", "E.M. Braverman", "Lev I. Rozono\u00e8r"], "venue": "Automation and Remote Control,", "citeRegEx": "Aizerman et al\\.,? \\Q1964\\E", "shortCiteRegEx": "Aizerman et al\\.", "year": 1964}, {"title": "Prediction, Learning, and Games", "author": ["Nicol\u00f2 Cesa-Bianchi", "Gabor Lugosi"], "venue": null, "citeRegEx": "Cesa.Bianchi and Lugosi.,? \\Q2006\\E", "shortCiteRegEx": "Cesa.Bianchi and Lugosi.", "year": 2006}, {"title": "On the generalization ability of on-line learning algorithms", "author": ["Nicol\u00f2 Cesa-Bianchi", "Alex Conconi", "Claudio Gentile"], "venue": "IEEE Transactions on Information Theory,", "citeRegEx": "Cesa.Bianchi et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Cesa.Bianchi et al\\.", "year": 2004}, {"title": "Large margin classification using the perceptron algorithm", "author": ["Yoav Freund", "Robert E. Schapire"], "venue": "Machine Learning,", "citeRegEx": "Freund and Schapire.,? \\Q1999\\E", "shortCiteRegEx": "Freund and Schapire.", "year": 1999}, {"title": "From on-line to batch learning", "author": ["Nick Littlestone"], "venue": "In COLT,", "citeRegEx": "Littlestone.,? \\Q1989\\E", "shortCiteRegEx": "Littlestone.", "year": 1989}, {"title": "On convergence proofs on perceptrons", "author": ["Albert B.J. Novikoff"], "venue": "In Proceedings of the Symposium on the Mathematical Theory of Automata,", "citeRegEx": "Novikoff.,? \\Q1962\\E", "shortCiteRegEx": "Novikoff.", "year": 1962}, {"title": "The perceptron: A probabilistic model for information storage and organization in the brain", "author": ["Frank Rosenblatt"], "venue": "Psychological Review,", "citeRegEx": "Rosenblatt.,? \\Q1958\\E", "shortCiteRegEx": "Rosenblatt.", "year": 1958}], "referenceMentions": [{"referenceID": 6, "context": "The algorithm learns a linear separator by processing the training sample in an on-line fashion, examining a single example at each iteration [Rosenblatt, 1958].", "startOffset": 142, "endOffset": 160}, {"referenceID": 1, "context": "The Perceptron algorithm belongs to the broad family of on-line learning algorithms (see Cesa-Bianchi and Lugosi [2006] for a survey) and admits a large number of variants.", "startOffset": 89, "endOffset": 120}, {"referenceID": 5, "context": "The seminal work of Novikoff [1962] gave the first margin-based bound for the Perceptron algorithm, one of the early results in learning theory and probably one of the first based on the notion of margin.", "startOffset": 20, "endOffset": 36}, {"referenceID": 6, "context": "Perceptron algorithm [Rosenblatt, 1958].", "startOffset": 21, "endOffset": 39}, {"referenceID": 5, "context": "Theorem 1 ([Novikoff, 1962]).", "startOffset": 11, "endOffset": 27}, {"referenceID": 3, "context": "We present two different types of bounds: first, a bound that depends on the L1-norm of the vector of \u03c1-margin hinge losses, or the vector of more general losses that we will describe, next a bound that depends on the L2-norm of the vector of margin losses, which extends the original results presented by Freund and Schapire [1999].", "startOffset": 306, "endOffset": 333}, {"referenceID": 2, "context": "The mistake bound (3) appears already in Cesa-Bianchi et al. [2004] but we could not find its proof either in that paper or in those it references for this bound.", "startOffset": 41, "endOffset": 68}, {"referenceID": 3, "context": "2 L2-norm mistake bounds The original results of this section are due to Freund and Schapire [1999]. Here, we extend their proof to derive finer mistake bounds for the Perceptron algorithm in terms of the L2-norm of the vector of hinge losses of an arbitrary weight vector at points where an update is made.", "startOffset": 73, "endOffset": 100}, {"referenceID": 3, "context": "Such a hypothesis can be determined via cross-validation Littlestone [1989] or using the online-tobatch theorem of Cesa-Bianchi et al.", "startOffset": 57, "endOffset": 76}, {"referenceID": 2, "context": "Such a hypothesis can be determined via cross-validation Littlestone [1989] or using the online-tobatch theorem of Cesa-Bianchi et al. [2004]. The latter can be combined with any of the mistake bounds presented in the previous section to derive generalization bounds for the Perceptron predictor.", "startOffset": 115, "endOffset": 142}, {"referenceID": 2, "context": "Theorem 4 (Cesa-Bianchi et al. [2004]).", "startOffset": 11, "endOffset": 38}, {"referenceID": 0, "context": "The Perceptron algorithm of Figure 1 can be straightforwardly extended to define a non-linear separator using a positive definite kernel K [Aizerman et al., 1964].", "startOffset": 139, "endOffset": 162}], "year": 2013, "abstractText": "We present a brief survey of existing mistake bounds and introduce novel bounds for the Perceptron or the kernel Perceptron algorithm. Our novel bounds generalize beyond standard margin-loss type bounds, allow for any convex and Lipschitz loss function, and admit a very simple proof.", "creator": "dvips(k) 5.991 Copyright 2011 Radical Eye Software"}}}