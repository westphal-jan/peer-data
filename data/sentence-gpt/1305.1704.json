{"id": "1305.1704", "review": {"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "8-May-2013", "title": "The Extended Parameter Filter", "abstract": "The parameters of temporal models, such as dynamic Bayesian networks, may be modelled in a Bayesian context as static or atemporal variables that influence transition probabilities at every time step. Particle filters fail for models that include such variables, while methods that use Gibbs sampling of parameter variables may incur a per-sample cost that grows linearly with the length of the observation sequence. Storvik devised a method for incremental computation of exact sufficient statistics that, for some cases, reduces the per-sample cost to a constant. The cost of these procedures is determined by the number of pixels and the number of pixels, which are represented by the following values:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "histories": [["v1", "Wed, 8 May 2013 03:21:31 GMT  (4611kb,D)", "http://arxiv.org/abs/1305.1704v1", null]], "reviews": [], "SUBJECTS": "stat.ML cs.AI", "authors": ["yusuf erol", "lei li", "bharath ramsundar", "stuart j russell"], "accepted": true, "id": "1305.1704"}, "pdf": {"name": "1305.1704.pdf", "metadata": {"source": "META", "title": "The Extended Parameter Filter", "authors": ["Yusuf B. Erol", "Lei Li", "Bharath Ramsundar", "Stuart Russell"], "emails": ["yberol@eecs.berkeley.edu", "leili@cs.berkeley.edu", "rbharath@stanford.edu", "russell@cs.berkeley.edu"], "sections": [{"heading": null, "text": "Yusuf B. Erol\u2020 yberol@eecs.berkeley.edu Lei Li\u2020 leili@cs.berkeley.edu Bharath Ramsundar rbharath@stanford.edu\nComputer Science Department, Stanford University\nStuart Russell\u2020 russell@cs.berkeley.edu \u2020EECS Department, University of California, Berkeley\nAbstract\nThe parameters of temporal models, such as dynamic Bayesian networks, may be modelled in a Bayesian context as static or atemporal variables that influence transition probabilities at every time step. Particle filters fail for models that include such variables, while methods that use Gibbs sampling of parameter variables may incur a per-sample cost that grows linearly with the length of the observation sequence. Storvik (2002) devised a method for incremental computation of exact sufficient statistics that, for some cases, reduces the per-sample cost to a constant. In this paper, we demonstrate a connection between Storvik\u2019s filter and a Kalman filter in parameter space and establish more general conditions under which Storvik\u2019s filter works. Drawing on an analogy to the extended Kalman filter, we develop and analyze, both theoretically and experimentally, a Taylor approximation to the parameter posterior that allows Storvik\u2019s method to be applied to a broader class of models. Our experiments on both synthetic examples and real applications show improvement over existing methods."}, {"heading": "1. Introduction", "text": "Dynamic Bayesian networks are widely used to model the processes underlying sequential data such as speech signals, financial time series, genetic sequences, and medical or physiological signals. State estimation\nAppearing in Proceedings of the 30 th International Conference on Machine Learning, Atlanta, Georgia, USA, 2013. Copyright 2013 by the author(s)/owner(s).\n000 001 002 003 004 005 006 007 008 009 010 011 012 013 014 015 016 017 018 019 020 021 022 023 024 025 026 027 028 029 030 031 032 033 034 035 036 037 038 039 040 041 042 043 044 045 046 047 048 049 050 051 052 053 054\n055 056 057 058 059 060 061 062 063 064 065 066 067 068 069 070 071\n078 079 080 081 082 083 084 085 086 087 088 089 090 091 092 093 094 095 096 097 098 099 100 101 102 103 104 105 106 107 108 109\nThe Extended Parameter Filter Abstract The parameters of temporal models such as dynamic Bayesian networks may be viewed in the Bayesian context as static or atemporal variables that influence the transition probabilities at every time step. Particle filters fail for models that include such variables, while methods that use Gibbs sampling of parameter variables may incur a per-sample cost\nthat grows linearly with the length of the ob-\nservation sequence. Storvik (2002) devised a\nmethod for incremental computation of ex-\nact sufficient statistics that, for some cases, reduces the per-sample cost to a constant. In this paper, we demonstrate a connection between Storvik\u2019s filter and a Kalman filter in parameter sp ce a d establish more general conditions under which it works. Drawing on an analogy to the extended Kalman filter, we develop and an lyze, both theoretically and experimentally, a Taylor approximation to the parameter posterior that allows Storvik\u2019s ethod to be applied to a broader class of models. Our experiments on both synthetic examples and real applications show improvement over existing methods. 1. Introduction Dynamic Bayesian networks are widely used to model the process s un erlying sequential data such as speech signals, financial time series, genetic sequences, and medical or physiological signals. State estimation or filtering\u2014computing the posterior distribution over the state of a partially observable Markov process from a sequence of observations\u2014is one of the most widely studied problems in control theory, statistics and AI. Exact filtering is intractable except for certain special cases (linear\u2013Gaussian models and discrete HMMs), but approximate filtering using the particle filter (a sePreliminary work. Under review by the International Conference on Machine Learning (ICML). Do not distribute.\n\u03b8 X1 Y1 X2 Y2 X3 Y3 \u00b7 \u00b7 \u00b7 XT YT\nquential Monte Carlo method) is feasible in many realworld applications (Arulampalam et al., 2002; Doucet and Johansen, 2008). In the machine learning context, model parameters may be represented by static parameter variables that define the transition and sensor model probabilities of the Markov process, but do not themselves change over time (Figure 1). The posterior parameter distribution (usually) converges to a delta function at the true value in the limit of infinitely many observations. Unfortunately, particle filters fail for such models: the algorithm samples parameter values for each particle at time t= 0, but these remain fixed; over time, the particle resampling process removes all but one set of values; and these are highly unlikely to be correct. The degeneracy problem is especially severe in high-dimensional parameter spaces, whether discrete or continuous. Hence, although learning requires inference, the most successful inference algorithm for temporal models is inapplicable. Kantas et al. (2009); Carvalho et al. (2010) describe several algorithms that have been proposed to solve this degeneracy problem, but the issue remains open because known algorithms either suffer from bias or computational inefficiency. For example, the \u201cartificial dynamics\u201d approach (Liu and West, 2001) introduces a stochastic transition model for the parameter variables, allowing exploration of parameter space, but this may result in biased estimates. Online EM algorithms (Andrieu et al., 2005) provide only point estimates of static parameters, may converge to local optima, and are biased unless used with the full smoothing distribution. The particle MCMC algorithm (An-\nFigure 1. A state-space mo l with static parameters \u03b8. X1:T are latent states and Y1:T are observations.\nor filtering\u2014computing the posterior distribution over the state of a partially observable Markov process from a sequence of observations\u2014is one of the most widely s udied problems in control theory, statistics and AI. Exact filtering is intractable except f r certain special c ses (linear\u2013Gaussian models and discrete HMMs), but appr ximate filterin using th p ticl filter (a sequential Monte Carlo method) is feasible in many realworld applications (Arulampalam et al., 2002; Doucet and Johansen, 2011). In the machine learning context, model parameters may be represented by static parameter variables tha define the transition and sensor model probabilities of the Markov process, but do not themselves change over time (Figure 1). The posterior parameter distribution (usually) conv rges to a delta function at the true value in the li it of infinitely many observations. Unfortunately, particle filters fail for such models: the algorith samples p rameter values for each particle at time t= 0, but these remain fixed; over time, th particle resampling process removes all but one set of values; and these are highly unlikely to be correct. The degeneracy problem is especially severe in high-dimensional parameter spaces, whether discrete or continuous. Hence, although learning requires inference, the most successful inference algorithm for temporal models is inapplicable.\nKantas et al. (2009) and Carvalho et al. (2010) describe several algorithms that have been proposed to\nar X\niv :1\n30 5.\n17 04\nv1 [\nst at\n.M L\n] 8\nM ay\n2 01\n3\nsolve this degeneracy problem, but the issue remains open because known algorithms either suffer from bias or computational inefficiency. For example, the \u201cartificial dynamics\u201d approach (Liu and West, 2001) introduces a stochastic transition model for the parameter variables, allowing exploration of the parameter space, but this may result in biased estimates. Online EM algorithms (Andrieu et al., 2005) provide only point estimates of static parameters, may converge to local optima, and are biased unless used with the full smoothing distribution. The particle MCMC algorithm (Andrieu et al., 2010) converges to the true posterior, but requires computation growing with T , the length of the data sequence.\nThe resample-move algorithm (Gilks and Berzuini, 2001) includes Gibbs sampling of parameter variables\u2014that is, in Figure 1, P (\u03b8 | X1, . . . , XT ). This method requires O(T ) computation per sample, leading Gilks and Berzuini to propose a sampling rate proportional to 1/T to preserve constant-time updates. Storvik (2002) and Polson et al. (2008) observe that a fixed-dimensional sufficient statistic (if one exists) for \u03b8 can be updated in constant time. Storvik describes an algorithm for a specific family of linear-in-parameters transition models.\nWe show that Storvik\u2019s algorithm is a special case of the Kalman filter in parameter space and identify a more general class of separable systems to which the same approach can be applied. By analogy with the extended Kalman filter, we propose a new algorithm, the extended parameter filter (EPF), that computes a separable approximation to the parameter posterior and allows a fixed-dimensional (approximate) sufficient statistic to be maintained. The method is quite general: for example, with a polynomial approximation scheme such as Taylor expansion any analytic posterior can be handled.\nSection 2 briefly reviews particle filters and Storvik\u2019s method and introduces our notion of separable models. Section 3 describes the EPF algorithm, and Section 4 discusses the details of a polynomial approximation scheme for arbitrary densities, which Section 4.2 then applies to estimate posterior distributions of static parameters. Section 5 provides empirical results comparing the EPF to other algorithms. All details of proofs are given in the appendix of the full version (Erol et al., 2013)."}, {"heading": "2. Background", "text": "In this section, we review state-space dynamical models and the basic framework of approximate filtering\nalgorithms."}, {"heading": "2.1. State-space model and filtering", "text": "Let \u0398 be a parameter space for a partially observable Markov process {Xt}t\u22650 , {Yt}t\u22650 as shown in Figure 1 and defined as follows:\nX0 \u223c p(x0 |\u03b8) (1) Xt |xt\u22121 \u223c p(xt |xt\u22121, \u03b8) (2) Yt |xt \u223c p(yt |xt, \u03b8) (3)\nHere the state variables Xt are unobserved and the observations Yt are assumed conditionally independent of other observations given Xt. We assume in this section that states Xt, observations Yt, and parameters \u03b8 are real-valued vectors in d, m, and p dimensions respectively. Here both the transition and sensor models are parameterized by \u03b8. For simplicity, we will assume in the following sections that only the transition model is parameterized by \u03b8; however, the results in this paper can be generalized to cover sensor model parameters.\nThe filtering density p(xt | y0:t, \u03b8) obeys the following recursion:\np(xt |y0:t, \u03b8) = p(yt |xt, \u03b8)p(xt |y0:t\u22121, \u03b8)\np(yt |y0:t\u22121, \u03b8)\n= p(yt |xt, \u03b8)\np(yt |y0:t\u22121, \u03b8)\n\u222b p(xt\u22121 |y0:t\u22121, \u03b8)p(xt |xt\u22121, \u03b8)dxt\u22121\n(4)\nwhere the update steps for p(xt | y0:t\u22121, \u03b8) and p(yt | y0:t\u22121, \u03b8) involve the evaluation of integrals that are not in general tractable."}, {"heading": "2.2. Particle filtering", "text": "With known parameters, particle filters can approximate the posterior distribution over the hidden state Xt by a set of samples. The canonical example is the sequential importance sampling-resampling algorithm (SIR) (Algorithm 1).\nThe SIR filter has various appealing properties. It is modular, efficient, and easy to implement. The filter takes constant time per update, regardless of time T , and as the number of particles N \u2192\u221e, the empirical filtering density converges to the true marginal posterior density under suitable assumptions.\nParticle filters can accommodate unknown parameters by adding parameter variables into the state vector with an \u201cidentity function\u201d transition model. As noted in Section 1 this approach leads to degeneracy problems\u2014especially for high-dimensional parameter\nAlgorithm 1: Sequential importance samplingresampling (SIR)\nInput: N : number of particles; y0, . . . , yT : observation sequence Output: x\u03041:N1:T initialize { xi0 }\n; for t = 1, . . . , T do\nfor i = 1, . . . , N do sample xit \u223c p(xt |xit\u22121); wit \u2190 p(yt |xit);\nsample {\n1 N , x\u0304 i t\n} \u2190Multinomial { wit, x i t } ;{\nxit } \u2190 { x\u0304it } ;\nspaces. To ensure that some particle has initial parameter values with bounded error, the number of particles must grow exponentially with the dimension of the parameter space."}, {"heading": "2.3. Storvik\u2019s algorithm", "text": "To avoid the degeneracy problem, Storvik (2002) modifies the SIR algorithm by adding a Gibbs sampling step for \u03b8 conditioned on the state trajectory in each particle (see Algorithm 2). The algorithm is developed in the SIS framework and consequently inherits the theoretical guarantees of SIS. Storvik considers unknown parameters in the state evolution model and assumes a perfectly known sensor model. His analysis can be generalized to unknown sensor models.\nStorvik\u2019s approach becomes efficient in an on-line setting when a fixed-dimensional sufficient statistic St exists for the static parameter (i.e., when p(\u03b8|x0:t) = p(\u03b8|St) holds). The important property of this algorithm is that the parameter value simulated at time t does not depend on the values simulated previously. This property prevents the impoverishment of the parameter values in particles.\nOne limitation of the algorithm is that it can only be applied to models with fixed-dimensional sufficient statistics. However, Storvik (2002) analyze the sufficient statistics for a specific family.\nStorvik (2002) shows how to obtain a sufficient statistic in the context of what he calls the Gaussian system process, a transition model satisfying the equation\nxt = F T t \u03b8 + t, t \u223c N(0,Q) (5)\nwhere \u03b8 is the vector of unknown parameters with a prior of N(\u03b80,C0) and Ft = F(xt\u22121) is a matrix where elements are possibly nonlinear functions of xt\u22121. An arbitrary but known observation model\nAlgorithm 2: Storvik\u2019s filter.\nInput: N : number of particles; y0, . . . , yT : observation sequence Output: x\u03041:N1:T , \u03b8 1:N\ninitialize { xi0 }\n; for t = 1, . . . , T do\nfor i = 1, . . . , N do sample \u03b8i \u223c p(\u03b8|xi0:t\u22121); sample xit \u223c p(xt|xit\u22121, \u03b8i); wi \u2190 p(yt|xit);\nsample {\n1 N , x\u0304 i t\n} \u2190Multinomial { wit, x i t } ;{\nxit } \u2190 { x\u0304it } ;\nis assumed. Then the standard theory states that \u03b8 |x0:t \u223c N(mt,Ct) where the recursions for the mean and the covariance matrix are as follows:\nDt = F T t Ct\u22121Ft + Q Ct = Ct\u22121 \u2212Ct\u22121FtD\u22121t FTt Ct\u22121 mt = mt\u22121 + Ct\u22121FtD \u22121 t (xt \u2212 FTt mt\u22121) (6)\nThus, mt and Ct constitute a fixed-dimensional sufficient statistic for \u03b8.\nThese updates are in fact a special case of Kalman filtering applied to the parameter space. Matching terms with the standard KF update equations (Kalman, 1960), we find that the transition matrix for the KF is the identity matrix, the transition noise covariance matrix is the zero matrix, the observation matrix for the KF is Ft, and the observation noise covariance matrix is Q. This correspondence is of course what one would expect, since the true parameter values are fixed (i.e., an identity transition). See the supplementary material (Erol et al., 2013) for the derivation."}, {"heading": "2.4. Separability", "text": "In this section, we define a condition under which there exist efficient updates to parameters. Again, we focus on the state-space model as described in Figure 1 and Equation (3). The model in Equation (3) can also be expressed as\nxt = f\u03b8(xt\u22121) + vt\nyt = g(xt) + wt (7)\nfor some suitable f\u03b8, g, vt, and wt.\nDefinition 1. A system is separable if the transition function f\u03b8(xt\u22121) can be written as f\u03b8(xt\u22121) = l(xt\u22121)\nTh(\u03b8) for some l(\u00b7) and h(\u00b7) and if the stochastic i.i.d. noise vt has log-polynomial density.\nTheorem 1. For a separable system, there exist fixeddimensional sufficient statistics for the Gibbs density, p(\u03b8 | x0:T ).\nThe proof is straightforward by the Fisher\u2013Neyman factorization theorem; more details are given in the supplementary material of the full version (Erol et al., 2013).\nThe Gaussian system process models defined in Equation (5) are separable, since the transition function FTt \u03b8 = (Ft)\nT \u03b8, but the property\u2014and therefore Storvik\u2019s algorithm\u2014applies to a much broader class of systems. Moreover, as we now show, non-separable systems may in some cases be well-approximated by separable systems, constructed by polynomial density approximation steps applied to either the Gibbs distribution p(\u03b8 | x0:t) or to the transition model."}, {"heading": "3. The extended parameter filter", "text": "Let us consider the following model.\nxt = f\u03b8(xt\u22121) + vt; vt \u223c N(0,\u03a3) (8)\nwhere x \u2208 Rd,\u03b8 \u2208 Rp and f\u03b8(\u00b7) : Rd \u2192 Rd is a vectorvalued function parameterized by \u03b8. We assume that the transition function f\u03b8 may be non-separable. Our algorithm will create a polynomial approximation to either the transition function or to the Gibbs distribution, p(\u03b8 | x0:t). To illustrate, let us consider the transition model f\u03b8(xt\u22121) = sin(\u03b8xt\u22121). It is apparent that this transition model is non-separable. If we approximate the transition function with a Taylor series in \u03b8 centered around zero\nf\u03b8(xt\u22121) \u2248 f\u0302\u03b8(xt\u22121) = xt\u22121\u03b8 \u2212 1\n3! x3t\u22121\u03b8 3 + . . . (9)\nand use f\u0302 as an approximate transition model, the system will become separable. Then, Storvik\u2019s filter can be applied in constant time per update. This Taylor approximation leads to a log-polynomial density of the form of Equation (12).\nOur approach is analogous to that of the extended Kalman filter (EKF). EKF linearizes nonlinear transitions around the current estimates of the mean and covariance and uses Kalman filter updates for state estimation (Welch and Bishop, 1995). Our proposed algorithm, which we call the extended parameter filter (EPF), approximates a non-separable system with a separable one, using a polynomial approximation of some arbitrary order. This separable, approximate model is well-suited for Storvik\u2019s filter and allows for\nAlgorithm 3: Extended Parameter Filter\nResult: Approximate the Gibbs density p(\u03b8 | x0:t, y0:t) with the log-polynomial density p\u0302(\u03b8 | x0:t, y0:t) Output: x\u03031 . . . x\u0303N\ninitialize { xi0 }\nand Si0 \u2190 0; for t = 1, . . . , T do\nfor i = 1, . . . , N do Sit = update(S i t\u22121, xt\u22121) ; // update\nstatistics for polynomial approximation log(p\u0302(\u03b8|x\u03040:t\u22121, y0:t\u22121)) sample \u03b8i \u223c p\u0302(\u03b8 | x\u0304i0:t\u22121, y0:t\u22121) = p\u0302(\u03b8 | Sit) ; sample xit \u223c p(xt | x\u0304it\u22121, \u03b8i) ; wi \u2190 p(yt | xit, \u03b8i);\nsample {\n1 N , x\u0304 i t, S\u0304 i t\n} \u2190Multinomial { wit, x i t, S i t } ;{\nxit, S i t } \u2190 { x\u0304it, S\u0304 i t } ;\nconstant time updates to the Gibbs density of the parameters.\nAlthough we have described an analogy to the EKF, it is important to note that the EPF can effectively use higher-order approximations instead of just first-order linearizations as in EKF. In EKF, higher order approximations lead to intractable integrals. The prediction integral for EKF\np(xt | y0:t\u22121) = \u222b p(xt\u22121 | y0:t\u22121)p(xt | xt\u22121)dxt\u22121\ncan be calculated for linear Gaussian transitions, in which case the mean and the covariance matrix are the tracked sufficient statistic. However, in the case of quadratic transitions (or any higher-order transitions), the above integral is no longer analytically tractable.\nIn the case of EPF, the transition model is the identity transition and hence the prediction step is trivial. The filtering recursion is\np(\u03b8 | x0:t) \u221d p(xt | xt\u22121, \u03b8)p(\u03b8 | x0:t\u22121). (10)\nWe approximate the transition p(xt | xt\u22121, \u03b8) with a log-polynomial density p\u0302 (log-polynomial in \u03b8), so that the Gibbs density, which satisfies the recursions in equation 10, has a fixed log-polynomial structure at each time step. Due to the polynomial structure, the approximate Gibbs density can be tracked in terms of its sufficient statistic (i.e., in terms of the coefficients of the polynomial). The log-polynomial structure is derived in Section 4.2. Pseudo-code for EPF is shown in Algorithm 3.\nNote that the approximated Gibbs density will be a log-multivariate polynomial density of fixed order\n(proportional to the order of the polynomial approximation). Sampling from such a density is not straightforward but can be done by Monte Carlo sampling. We suggest slice sampling (Neal, 2003) or the MetropolisHastings algorithm (Robert and Casella, 2005) for this purpose. Although some approximate sampling scheme is necessary, sampling from the approximated density remains a constant-time operation when the dimension of p\u0302 remains constant.\nIt is also important to note that performing a polynomial approximation for a p-dimensional parameter space may not be an easy task. However, we can reduce the computational complexity of such approximations by exploiting locality properties. For instance, if f\u03b8(\u00b7) = h\u03b81,...,\u03b8p\u22121(\u00b7) + g\u03b8p(\u00b7), where h is separable and g is non-separable, we only need to approximate g.\nIn section 4, we discuss the validity of the approximation in terms of the KL-divergence between the true and approximate densities. In section 4.1, we analyze the distance between an arbitrary density and its approximate form with respect to the order of the polynomial. We show that the distance goes to zero superexponentially. Section 4.2 analyzes the error for the static parameter estimation problem and introduces the form of the log-polynomial approximation."}, {"heading": "4. Approximating the conditional distribution of parameters", "text": "In this section, we construct approximate sufficient statistics for arbitrary one\u2013dimensional state space models. We do so by exploiting log-polynomial approximations to arbitrary probability densities. We prove that such approximations can be made arbitrarily accurate. Then, we analyze the error introduced by log-polynomial approximation for the arbitrary one\u2013 dimensional model."}, {"heading": "4.1. Taylor approximation to an arbitrary density", "text": "Let us assume a distribution p (known only up to a normalization constant) expressed in the form p(x) \u221d exp(S(x)), where S(x) is an analytic function on the support of the distribution. In general we need a Monte Carlo method to sample from this arbitrary density. In this section, we describe an alternative, simpler sampling method. We propose that with a polynomial approximation P (x) (Taylor, Chebyshev etc.) of sufficient order to the function S(x), we may sample from a distribution p\u0302 \u221d exp(P (x)) with a simpler (i.e. log-polynomial) structure. We show that the distance between the distributions p and p\u0302 reduces to\n0 as the order of the approximation increases.\nThe following theorem is based on Taylor approximations; however, the theorem can be generalized to handle any polynomial approximation scheme. The proof is given in (Erol et al., 2013).\nTheorem 2. Let S(x) be a M + 1 times differentiable function with bounded derivatives, and let P (x) be its M -th order Taylor approximation. Then the KLdivergence between distributions p and p\u0302 converges to 0, super-exponentially as the order of approximation M \u2192\u221e.\nWe validate the Taylor approximation approach for the log-density S(x) = \u2212x2+5 sin2(x). Figure 2 shows the result for this case."}, {"heading": "4.2. Online approximation of the Gibbs density of the parameter", "text": "In our analysis, we will assume the following model.\nxt = f\u03b8(xt\u22121) + vt, vt \u223c N(0, \u03c32) yt = g(xt) + wt, wt \u223c N(0, \u03c32o)\nThe posterior distribution for the static parameter is\np(\u03b8|x0:T ) \u221d p(\u03b8) T\u220f t=1 p(xt|xt\u22121, \u03b8).\nThe product term, which requires linear time, is the bottleneck for this computation. A polynomial approximation to the transition function f\u03b8(\u00b7) (the Taylor approximation around \u03b8 = 0) is:\nf\u03b8(xt\u22121) = h(xt\u22121, \u03b8) = M\u2211 i=0 1 i! dih(xt\u22121, \u03b8 i) d\u03b8 \u2223\u2223 \u03b8=0\ufe38 \ufe37\ufe37 \ufe38\nHi(xt\u22121)\n\u03b8i +RM (\u03b8)\n= M\u2211 i=0 Hi(xt\u22121)\u03b8 i +RM (\u03b8) = f\u0302(\u03b8) +RM (\u03b8)\nwhere RM is the error for the M -dimensional Taylor approximation. We define coefficients J ixt\u22121 to satisfy(\u2211M\ni=0H i(xt\u22121)\u03b8\ni )2\n= J2Mxt\u22121\u03b8 2M + \u00b7 \u00b7 \u00b7+ J0xt\u22121\u03b80.\nLet p\u0302(\u03b8 | x0:T ) denote the approximation to p(\u03b8 | x0:T ) obtained by using the polynomial approximation to f\u03b8 introduced above. Theorem 3. p\u0302(\u03b8 | x0:T ) is in the exponential family with the log-polynomial density\nlog p(\u03b8)+ (12) \u03b81 ... \u03b8M \u03b8M+1\n... \u03b82M\n T\n\ufe38 \ufe37\ufe37 \ufe38 T (\u03b8)T\n.  1 \u03c32 \u2211T k=1 xkH 1(xk\u22121)\u2212 12\u03c32 \u2211T k=1 J 1 xk\u22121 ... 1 \u03c32 \u2211T k=1 xkH M (xk\u22121)\u2212 12\u03c32 \u2211T k=1 J M xk\u22121 \u2212 1 2\u03c32 \u2211T k=1 J M+1 xk\u22121 ...\n\u2212 1 2\u03c32 \u2211T k=1 J 2M xk\u22121  \ufe38 \ufe37\ufe37 \ufe38\n\u03b7(x0,...,xt)\nThe proof is given in the supplementary material.\nThis form has finite dimensional sufficient statistics. Standard sampling from p(\u03b8 | x0:t) requires O(t) time, whereas with the polynomial approximation we can sample from this structured density of fixed dimension in constant time (given that sufficient statistics were tracked). We can furthermore prove that sampling from this exponential form approximation is asymptotically correct.\nTheorem 4. Let pT (\u03b8 | x0:T ) denote the Gibbs distribution and p\u0302T (\u03b8 | x0:T ) its order M exponential family approximation. Assume that parameter \u03b8 has support S\u03b8 and finite variance. Then as M \u2192\u221e, T \u2192\u221e, the KL divergence between pT and p\u0302T goes to zero.\nlim M,T\u2192\u221e\nDKL(pT || p\u0302T ) = 0\nThe proof is given in the supplementary material (Erol et al., 2013). Note that the analysis above can be generalized to higher dimensional parameters. The one dimensional case is discussed for ease of exposition.\nIn the general case, an order M Taylor expansion for a p dimensional parameter vector \u03b8 will have Mp terms. Then each update of the sufficient statistics will cost O(Mp) per particle, per time step, yielding the total complexity O(NTMp). However, as noted before, we can often exploit the local structure of f\u03b8 to speed up the update step. Notice that in either case, the update cost per time step is fixed (independent of T )."}, {"heading": "5. Experiments", "text": "The algorithm is implemented for three specific cases. Note that the models discussed do not satisfy the Gaussian process model assumption of Storvik (2002)."}, {"heading": "5.1. Single parameter nonlinear model", "text": "Consider the following model with sinusoid transition dynamics (SIN):\nxt = sin(\u03b8xt\u22121) + vt, vt \u223c N(0, \u03c32) yt = xt + wt, wt \u223c N(0, \u03c32obs) (13)\nwhere \u03c3 = 1, \u03c3obs = 0.1 and the Gaussian prior for parameter \u03b8 is N(0, 0.22). The observation sequence is generated by sampling from SIN with true parameter value \u03b8 = 0.7.\nFigure 3 shows how the Gibbs density p(\u03b8 | x0:t) shrinks with respect to time, hence verifying identifiability for this model. Notice that as T grows, the densities concentrate around the true parameter value.\nA Taylor approximation around \u03b8 = 0 has been applied to the transition function sin(\u03b8xt). Figure 4(a) shows the approximate densities for different polynomial orders for T = 1024. Notice that as the polynomial order increases, the approximate densities converge to the true density p(\u03b8 | x0:1024). The KL-divergence DKL(p || p\u0302) for different polynomial orders (N) and different data lengths (T) is illus-\ntrated in Figure 4(b). The results are consistent with the theory developed in Section 4.1.\nThe degeneracy of a bootstrap filter with N = 50000 particles can be seen from figure 5(a). The Liu\u2013 West approach with N = 50000 particles is shown in 5(b). The perturbation is \u03b8t = \u03c1\u03b8t\u22121 + (1 \u2212 \u03c1)\u03b8\u0304t\u22121+ \u221a 1\u2212 \u03c12 std(\u03b8t\u22121)N(0, 1), where \u03c1 = 0.9. Notice that even with N = 50000 particles and large perturbations, the Liu\u2013West approach converges slowly compared to our method. Furthermore, for highdimensional spaces, tuning the perturbation parameter \u03c1 for Liu\u2013West becomes difficult.\nThe EPF has been implemented on this model with N = 1000 particles with a 7-th order Taylor approximation to the posterior. The time complexity is O(NT ). The mean and the standard deviation of the particles are shown in figure 5(c)."}, {"heading": "5.2. Cauchy dynamical system", "text": "We consider the following model.\nxt = axt\u22121 + Cauchy(0, \u03b3) (14)\nyt = xt +N(0, \u03c3obs) (15)\nHere Cauchy is the Cauchy distribution centered at 0 and with shape parameter \u03b3 = 1. We use a = 0.7, \u03c3obs = 10, where the prior for the AR(1) parameter is N(0, 0.22). This model represents autoregressive time evolution with heavy-tailed noise. Such heavy-tailed noises are observed in network traffic data and clickstream data. The standard Cauchy distribution we use is\nfv(v; 0, 1) = 1\n\u03c0(1 + v2) = exp\n( \u2212 log(\u03c0)\u2212 log(1 + v2) ) .\nWe approximate log(1 + v2) by v2 \u2212 v4/2 + v6/3 \u2212 v8/4 + . . . (the Taylor approximation at 0).\nFigure 6(a) shows the simulated hidden state and the observations (\u03c3obs = 10). Notice that the simulated process differs substantially from a standard AR(1) process due to the heavy-tailed noise. Storvik\u2019s filter cannot handle this model since the necessary sufficient statistics do not exist.\nFigure 6(b) displays the mean value estimated by a bootstrap filter with N = 50000 particles. As before the bootstrap filter is unable to perform meaningful inference. Figure 6(c) shows the performance of the Liu\u2013West filter with both N = 100 and N = 10000 particles. The Liu\u2013West filter does not converge for N = 100 particles and converges slowly for N = 10000 particles. Figure 6(d) demonstrates the rapid convergence of the EPF for only N = 100 particles with 10th order approximation. The time complexity is O(NT ).\nOur empirical results confirm that the EPF proves useful for models with heavy-tailed stochastic perturbations."}, {"heading": "5.3. Smooth Transition AR model", "text": "The smooth transition AR (STAR) model is a smooth generalization of the self-exciting threshold autoregressive (SETAR) model, (van Dijk et al., 2002). It is generally expressed in the following form.\nxt = (a1xt\u22121 + a2xt\u22122 + \u00b7 \u00b7 \u00b7+ apxt\u2212p) [1\u2212G(xt\u2212d; \u03b3, c)] + (b1xt\u22121 + b2xt\u22122 + \u00b7 \u00b7 \u00b7+ bpxt\u2212p) [G(xt\u2212d; \u03b3, c)] + t\nwhere t is i.i.d. Gaussian with mean zero and variance \u03c32 and G(\u00b7) is a nonlinear function of xt\u2212d, where d > 0. We will use the logistic function\nG(yt\u2212d; \u03b3, c) = 1\n1 + exp (\u2212\u03b3(xt\u2212d \u2212 c)) (16)\nFor high \u03b3 values, the logistic function converges to the indicator function, I(xt\u2212d > c), forcing STAR to\nconverge to SETAR (SETAR corresponds to a switching linear\u2013Gaussian system). We will use p = 1 = d, where a1 = 0.9 and b1 = 0.1 and \u03c3 = 1 (corresponding to two different AR(1) processes with high and low memory). We attempt to estimate parameters \u03b3, c of the logistic function, which have true values \u03b3 = 1 and c = 3. Data (of length T = 1000) is generated from the model under fixed parameter values and with observation model yt = xt + wt, where wt is additive Gaussian noise with mean zero and standard deviation \u03c3obs = 0.1. Figure 7(a) shows the shrinkage of the Gibbs density p(\u03b3, c | x0:T ), verifying identifiability.\nThe non-separable logistic term is approximated as\n1\n1 + exp (\u2212\u03b3(xt\u22121 \u2212 c)) \u2248 1 2 \u2212 1 4 \u03b3(c\u2212 xt\u22121) + 1 48 \u03b33(c\u2212 xt\u22121)3 + . . .\nFigure 7(b) displays the failure of the Liu\u2013West filter for N = 50000 particles. Figure 7(c) shows the mean values for \u03b3, c from EPF for only N = 100 particles with 9th order Taylor approximation. Sampling from the log-polynomial approximate density is done through the random-walk Metropolis\u2013Hastings algo-\nrithm. For each particle path, at each time step t, the Metropolis\u2013Hastings sampler is initialized from the parameter values at t \u2212 1. The burn-in period is set to be 0, so only one MH step is taken per time step (i.e., if a proposed sample is more likely it is accepted, else it is rejected with a specific probability). The whole filter has time complexity O(NT )."}, {"heading": "6. Conclusion", "text": "Learning the parameters of temporal probability models remains a significant open problem for practical applications. We have proposed the extended parameter filter (EPF), a novel approximate inference algorithm that combines Gibbs sampling of parameters with computation of approximate sufficient statistics. The update time for EPF is independent of the length of the observation sequence. Moreover, the algorithm has provable error bounds and handles a wide variety of models. Our experiments confirm these properties and illustrate difficult cases on which EPF works well.\nOne limitation of our algorithm is the complexity of Taylor approximation for high-dimensional parameter vectors. We noted that, in some cases, the process can be decomposed into lower-dimensional subproblems. Automating this step would be beneficial."}, {"heading": "A. Storvik\u2019s filter as a Kalman filter", "text": "Let us consider the following model.\nxt = Axt\u22121 + vt, vt \u223c N(0,Q) yt = Hxt + wt, wt \u223c N(0,R) (17)\nWe will call the MMSE estimate Kalman filter returns as xt|t = E[xt | y0:t] and the variance Pt|t = cov(xt | y0:t). Then the update for the conditional mean estimate is as follows.\nxt|t = Axt\u22121|t\u22121\n+ Pt|t\u22121H T (HPt|t\u22121H T + R)\u22121\ufe38 \ufe37\ufe37 \ufe38 Kt (yt \u2212HAxt\u22121|t\u22121)\nwhere as for the estimation covariance\nPt|t\u22121 = APt\u22121|t\u22121A T + Q\nPt|t = (I\u2212KtH)Pt|t\u22121 (18)\nMatching the terms above to the updates in equation 6, one will obtain a linear model for which the transition matrix is A = I, the observation matrix is H = Ft, the state noise covariance matrix is Q = 0, and the observation noise covariance matrix is R = Q"}, {"heading": "B. Proof of theorem 1", "text": "Let us assume that x \u2208 Rd,\u03b8 \u2208 Rp and f\u03b8(\u00b7) : Rd \u2192 Rd is a vector valued function parameterized by \u03b8. Moreover, due to the assumption of separability f\u03b8(xt\u22121) = l(xt\u22121)\nTh(\u03b8), where we assume that l(\u00b7) : Rd \u2192 Rm\u00d7d and h(\u00b7) : Rp \u2192 Rm and m is an arbitrary constant. The stochastic perturbance will have the logpolynomial density p(vt) \u221d exp(\u039b1vt + vTt \u039b2vt + . . . ) Let us analyze the case of p(vt) \u221d exp(\u039b1vt+vTt \u039b2vt), for mathematical simplicity.\nProof.\nlog p(\u03b8 | x0:T ) \u221d log p(\u03b8) + T\u2211 t=1 log p(xt | xt\u22121, \u03b8)\n\u221d log p(\u03b8) + T\u2211 t=1 \u039b1 ( xt \u2212 l(xt\u22121)Th(\u03b8) ) +\n( xt \u2212 l(xt\u22121)Th(\u03b8) )T \u039b2 ( xt \u2212 l(xt\u22121)Th(\u03b8) ) \u221d log p(\u03b8) +\n( T\u2211 t=1 \u2212(\u039b1 + 2xTt \u039b2)l(xt\u22121)T )\n\ufe38 \ufe37\ufe37 \ufe38 S1\nh(\u03b8)\n+ hT (\u03b8) ( T\u2211 t=1 l(xt\u22121)\u039b2l T (xt\u22121) ) \ufe38 \ufe37\ufe37 \ufe38\nS2\nh(\u03b8) + constants\nTherefore, sufficient statistics (S1 \u2208 R1\u00d7m and S2 \u2208 Rm\u00d7m) exist. The analysis can be generalized for higher-order terms in vt in similar fashion."}, {"heading": "C. Proof of theorem 2", "text": "Proposition 1. Let S(x) be a M + 1 times differentiable function and P (x) its order M Taylor approximation. Let I = (x \u2212 a, x + a) be an open interval around x. Let R(x) be the remainder function, so that S(x) = P (x) +R(x). Suppose there exists constant U such that\n\u2200y \u2208 I, \u2223\u2223\u2223f (k+1)(y)\u2223\u2223\u2223 \u2264 U\nWe may then bound\n\u2200y \u2208 I, |R(y)| \u2264 U a M+1\n(M + 1)!\nWe define the following terms\n= U aM+1\n(M + 1)!\nZ = \u222b I exp(S(x))dx\nZ\u0302 = \u222b I exp(P (x))dx\nSince exp(\u00b7) is monotone and increasing and |S(x)\u2212 P (x)| \u2264 , we can derive tight bounds relating Z and Z\u0302.\nZ = \u222b I exp(S(x))dx \u2264 \u222b I exp(P (x) + )dx\n= Z\u0302 exp( )\nZ = \u222b I exp(S(x))dx \u2265 \u222b I exp(P (x)\u2212 )dx\n= Z\u0302 exp(\u2212 )\nProof. DKL(p||p\u0302) = \u222b I ln ( p(x) p\u0302(x) ) p(x)dx\n= \u222b I ( S(x)\u2212 P (x) + ln(Z\u0302)\u2212 ln(Z) ) p(x)dx\n\u2264 \u222b I |S(x)\u2212 P (x)| p(x)dx\n+ \u222b I \u2223\u2223\u2223ln(Z\u0302)\u2212 ln(Z)\u2223\u2223\u2223 p(x)dx \u2264 2 \u221d a M+1\n(M + 1)! \u2248 1\u221a\n2\u03c0(M + 1)!\n( ae\nM + 1 )M+1 where the last approximation follows from Stirling\u2019s approximation. Therefore, DKL(p||p\u0302) \u2192 0 as M \u2192 \u221e."}, {"heading": "D. Proof of theorem 3", "text": "Proof. log p\u0302(\u03b8 | x0:T ) = log ( p(\u03b8)\nT\u220f k=0\np\u0302(xk|xk\u22121, \u03b8) )\n= log p(\u03b8) + T\u2211 k=0 log p\u0302(xk | xk\u22121, \u03b8)\nWe can calculate the form of log p\u0302(xk | xk\u22121, \u03b8) explicitly.\nlog p\u0302(xk | xk\u22121, \u03b8) = logN (f\u0302(xk\u22121, \u03b8), \u03c32) = \u2212 log(\u03c3 \u221a 2\u03c0)\u2212 (xk \u2212 f\u0302(xk\u22121, \u03b8)) 2\n2\u03c32\n= \u2212 log(\u03c3 \u221a 2\u03c0)\u2212 x 2 k \u2212 2xkf\u0302(xk\u22121, \u03b8) + f\u0302(xk\u22121, \u03b8)2\n2\u03c32\n= \u2212 log(\u03c3 \u221a 2\u03c0)\u2212 x 2 k 2\u03c32 \u2212 \u2211M i=0 xkH i(xk\u22121)\u03b8 i \u03c32\n+\n\u22112M i=0 J i xk\u22121 \u03b8i\n2\u03c32\nUsing this expansion, we calculate log p\u0302(\u03b8 | x0:T ) = log p(\u03b8) + T\u2211 k=0 log p\u0302(xk | xk\u22121, \u03b8)\n= log p(\u03b8)\u2212 (T + 1) log(\u03c3 \u221a 2\u03c0)\n\u2212 1 2\u03c32 ( T\u2211 k=0 x2k ) \u2212 T (\u03b8)T \u03b7(x0, . . . , xT )\nwhere we expand T (\u03b8)T \u03b7(x0, . . . , xT ) as in 3. The form for log p\u0302(\u03b8 | x0:T ) is in the exponential family."}, {"heading": "E. Proof of theorem 4", "text": "Proof. Assume that function f has bounded derivatives and bounded support I. Then the maximum error satisfies \u2223\u2223\u2223f\u03b8(xk\u22121)\u2212 f\u0302\u03b8(xk\u22121)\u2223\u2223\u2223 \u2264 k. It follows\nthat f\u0302\u03b8(xk\u22121) 2 \u2212 f\u03b8(xk\u22121)2 = \u2212 2k \u2212 2f\u0302\u03b8(xk\u22121) k \u2248 \u22122f\u0302\u03b8(xk\u22121) k. Then the KL-divergence between the real posterior and the approximated posterior satisfies the following formula.\nDKL(pT ||p\u0302T ) (19)\n= \u222b S\u03b8 ( 1 \u03c32 T\u2211 k=1 k(xk \u2212 f\u0302\u03b8(xk\u22121)) ) pT (\u03b8|x0:T )d\u03b8\nMoreover, recall that as T \u2192\u221e the posterior shrinks to \u03b4(\u03b8\u2212 \u03b8\u2217) by the assumption of identifiability. Then we can rewrite the KL-divergence as (assuming Taylor approximation centered around \u03b8c)\nlim T\u2192\u221e\nDKL(pT ||p\u0302T ) (20)\n= 1\n\u03c32 lim T\u2192\u221e T\u2211 k=1 k \u222b S\u03b8 (xk \u2212 f\u0302\u03b8(xk\u22121))pT (\u03b8|x0:T )d\u03b8\n= 1\n\u03c32 lim T\u2192\u221e T\u2211 k=1\nk\u00b7 (21)( xk \u2212\nM\u2211 i=0 Hi(xk\u22121) \u222b S\u03b8 (\u03b8 \u2212 \u03b8c)ip(\u03b8|x0:T )d\u03b8 )\n= 1\n\u03c32 lim T\u2192\u221e T\u2211 k=1 k\n( xk \u2212\nM\u2211 i=0 Hi(xk\u22121)(\u03b8 \u2217 \u2212 \u03b8c)i\n)\nIf the center of the Taylor approximation \u03b8c is the true parameter value \u03b8\u2217, we can show that\nlim T\u2192\u221e\nDKL(pT ||p\u0302T ) = 1\n\u03c32 lim T\u2192\u221e T\u2211 k=1 k (xk \u2212 f\u03b8\u2217(xk\u22121)))\n= 1\n\u03c32 lim T\u2192\u221e T\u2211 k=1 kvk = 0 (22)\nwhere the final statement follows from law of large numbers. Thus, as T \u2192\u221e, the Taylor approximation of any order will converge to the true posterior given that \u03b8c = \u03b8 \u2217. For an arbitrary center value \u03b8c,\nDKL(pT ||p\u0302T ) = 1\n\u03c32 T\u2211 k=1 k\n( xk \u2212\nM\u2211 i=0 Hi(xk\u22121)(\u03b8 \u2217 \u2212 \u03b8c)i ) (23)\nNotice that k \u221d 1(M+1)! (by our assumptions that f has bounded derivative and is supported on interval I) and Hi(\u00b7) \u221d 1M ! . The inner summation will be bounded since M ! > aM ,\u2200a \u2208 R as M \u2192 \u221e. Therefore, as M \u2192\u221e, DKL(p||p\u0302)\u2192 0."}], "references": [{"title": "On-line parameter estimation in general state-space models", "author": ["C. Andrieu", "A. Doucet", "V. Tadic"], "venue": "In Proceedings of the 44th Conference on Decision and Control,", "citeRegEx": "Andrieu et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Andrieu et al\\.", "year": 2005}, {"title": "Particle Markov chain Monte Carlo methods", "author": ["Christophe Andrieu", "Arnaud Doucet", "Roman Holenstein"], "venue": "Journal of the Royal Statistical Society: Series B (Statistical Methodology),", "citeRegEx": "Andrieu et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Andrieu et al\\.", "year": 2010}, {"title": "A tutorial on particle filters for on-line non-linear/non-Gaussian Bayesian tracking", "author": ["Sanjeev Arulampalam", "Simon Maskell", "Neil Gordon", "Tim Clapp"], "venue": "IEEE Transactions on Signal Processing,", "citeRegEx": "Arulampalam et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Arulampalam et al\\.", "year": 2002}, {"title": "Particle Learning and Smoothing", "author": ["Carlos M. Carvalho", "Michael S. Johannes", "Hedibert F. Lopes", "Nicholas G. Polson"], "venue": "Statistical Science,", "citeRegEx": "Carvalho et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Carvalho et al\\.", "year": 2010}, {"title": "A tutorial on particle filtering and smoothing: fifteen years later", "author": ["Arnaud Doucet", "Adam M. Johansen"], "venue": "The Oxford Handbook of Nonlinear Filtering,", "citeRegEx": "Doucet and Johansen.,? \\Q2011\\E", "shortCiteRegEx": "Doucet and Johansen.", "year": 2011}, {"title": "The extended parameter filter", "author": ["Yusuf Erol", "Lei Li", "Bharath Ramsundar", "Stuart J. Russell"], "venue": "Technical Report UCB/EECS-2013-48, EECS Department,", "citeRegEx": "Erol et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Erol et al\\.", "year": 2013}, {"title": "Following a moving target \u2013 Monte Carlo inference for dynamic bayesian models", "author": ["Walter R. Gilks", "Carlo Berzuini"], "venue": "Journal of the Royal Statistical Society. Series B (Statistical Methodology),", "citeRegEx": "Gilks and Berzuini.,? \\Q2001\\E", "shortCiteRegEx": "Gilks and Berzuini.", "year": 2001}, {"title": "A new approach to linear filtering and prediction problems", "author": ["Rudolf E. Kalman"], "venue": "Transactions of the ASME \u2013 Journal of Basic Engineering,", "citeRegEx": "Kalman.,? \\Q1960\\E", "shortCiteRegEx": "Kalman.", "year": 1960}, {"title": "Combined parameter and state estimation in simulation-based filtering", "author": ["Jane Liu", "Mike West"], "venue": "In Sequential Monte Carlo Methods in Practice", "citeRegEx": "Liu and West.,? \\Q2001\\E", "shortCiteRegEx": "Liu and West.", "year": 2001}, {"title": "Practical filtering with sequential parameter learning", "author": ["Nicholas G. Polson", "Jonathan R. Stroud", "Peter M\u00fcller"], "venue": "Journal of the Royal Statistical Society: Series B (Statistical Methodology),", "citeRegEx": "Polson et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Polson et al\\.", "year": 2008}, {"title": "Monte Carlo Statistical Methods", "author": ["Christian P. Robert", "George Casella"], "venue": null, "citeRegEx": "Robert and Casella.,? \\Q2005\\E", "shortCiteRegEx": "Robert and Casella.", "year": 2005}, {"title": "Particle filters for state-space models with the presence of unknown static paramaters", "author": ["Geir Storvik"], "venue": "IEEE Transactions on Signal Processing,", "citeRegEx": "Storvik.,? \\Q2002\\E", "shortCiteRegEx": "Storvik.", "year": 2002}, {"title": "Smooth transition autoregressive models \u2013 a survey of recent developments", "author": ["Dick van Dijk", "Timo Tersvirta", "Philip Hans Franses"], "venue": "Econometric Reviews,", "citeRegEx": "Dijk et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Dijk et al\\.", "year": 2002}, {"title": "An introduction to the Kalman filter", "author": ["Greg Welch", "Gary Bishop"], "venue": null, "citeRegEx": "Welch and Bishop.,? \\Q1995\\E", "shortCiteRegEx": "Welch and Bishop.", "year": 1995}], "referenceMentions": [{"referenceID": 10, "context": "Storvik (2002) devised a method for incremental computation of exact sufficient statistics that, for some cases, reduces the per-sample cost to a constant.", "startOffset": 0, "endOffset": 15}, {"referenceID": 10, "context": "Storvik (2002) devised a method for incremental computation of exact sufficient statistics that, for some cases, reduces the per-sample cost to a constant.", "startOffset": 0, "endOffset": 15}, {"referenceID": 2, "context": "quential Monte Carlo method) is feasible in many realworld applications (Arulampalam et al., 2002; Doucet and Johansen, 2008).", "startOffset": 72, "endOffset": 125}, {"referenceID": 8, "context": "For example, the \u201cartificial dynamics\u201d approach (Liu and West, 2001) introduces a stochastic transition model for the parameter variables, allowing exploration of parameter space, but this may result in biased estimates.", "startOffset": 48, "endOffset": 68}, {"referenceID": 0, "context": "Online EM algorithms (Andrieu et al., 2005) provide only point estimates of static parameters, may converge to local optima, and are biased unless used with the full smoothing distribution.", "startOffset": 21, "endOffset": 43}, {"referenceID": 0, "context": "quential Monte Carlo method) is feasible in many realworld applications (Arulampalam et al., 2002; Doucet and Johansen, 2008). In the machine learning context, model parameters may be represented by static parameter variables that define the transition and sensor model probabilities of the Markov process, but do not themselves change over time (Figure 1). The posterior parameter distribution (usually) converges to a delta function at the true value in the limit of infinitely many observations. Unfortunately, particle filters fail for such models: the algorithm samples parameter values for each particle at time t= 0, but these remain fixed; over time, the particle resampling process removes all but one set of values; and these are highly unlikely to be correct. The degeneracy problem is especially severe in high-dimensional parameter spaces, whether discrete or continuous. Hence, although learning requires inference, the most successful inference algorithm for temporal models is inapplicable. Kantas et al. (2009); Carvalho et al.", "startOffset": 73, "endOffset": 1028}, {"referenceID": 0, "context": "quential Monte Carlo method) is feasible in many realworld applications (Arulampalam et al., 2002; Doucet and Johansen, 2008). In the machine learning context, model parameters may be represented by static parameter variables that define the transition and sensor model probabilities of the Markov process, but do not themselves change over time (Figure 1). The posterior parameter distribution (usually) converges to a delta function at the true value in the limit of infinitely many observations. Unfortunately, particle filters fail for such models: the algorithm samples parameter values for each particle at time t= 0, but these remain fixed; over time, the particle resampling process removes all but one set of values; and these are highly unlikely to be correct. The degeneracy problem is especially severe in high-dimensional parameter spaces, whether discrete or continuous. Hence, although learning requires inference, the most successful inference algorithm for temporal models is inapplicable. Kantas et al. (2009); Carvalho et al. (2010) describe several algorithms that have been proposed to solve this degeneracy problem, but the issue remains open because known algorithms either suffer from bias or computational inefficiency.", "startOffset": 73, "endOffset": 1052}, {"referenceID": 2, "context": "Exact filtering is intractable except f r certain special c ses (linear\u2013Gaussian models and discrete HMMs), but appr ximate filterin using th p ticl filter (a sequential Monte Carlo method) is feasible in many realworld applications (Arulampalam et al., 2002; Doucet and Johansen, 2011).", "startOffset": 233, "endOffset": 286}, {"referenceID": 4, "context": "Exact filtering is intractable except f r certain special c ses (linear\u2013Gaussian models and discrete HMMs), but appr ximate filterin using th p ticl filter (a sequential Monte Carlo method) is feasible in many realworld applications (Arulampalam et al., 2002; Doucet and Johansen, 2011).", "startOffset": 233, "endOffset": 286}, {"referenceID": 2, "context": "Exact filtering is intractable except f r certain special c ses (linear\u2013Gaussian models and discrete HMMs), but appr ximate filterin using th p ticl filter (a sequential Monte Carlo method) is feasible in many realworld applications (Arulampalam et al., 2002; Doucet and Johansen, 2011). In the machine learning context, model parameters may be represented by static parameter variables tha define the transition and sensor model probabilities of the Markov process, but do not themselves change over time (Figure 1). The posterior parameter distribution (usually) conv rges to a delta function at the true value in the li it of infinitely many observations. Unfortunately, particle filters fail for such models: the algorith samples p rameter values for each particle at time t= 0, but these remain fixed; over time, th particle resampling process removes all but one set of values; and these are highly unlikely to be correct. The degeneracy problem is especially severe in high-dimensional parameter spaces, whether discrete or continuous. Hence, although learning requires inference, the most successful inference algorithm for temporal models is inapplicable. Kantas et al. (2009) and Carvalho et al.", "startOffset": 234, "endOffset": 1186}, {"referenceID": 2, "context": "Exact filtering is intractable except f r certain special c ses (linear\u2013Gaussian models and discrete HMMs), but appr ximate filterin using th p ticl filter (a sequential Monte Carlo method) is feasible in many realworld applications (Arulampalam et al., 2002; Doucet and Johansen, 2011). In the machine learning context, model parameters may be represented by static parameter variables tha define the transition and sensor model probabilities of the Markov process, but do not themselves change over time (Figure 1). The posterior parameter distribution (usually) conv rges to a delta function at the true value in the li it of infinitely many observations. Unfortunately, particle filters fail for such models: the algorith samples p rameter values for each particle at time t= 0, but these remain fixed; over time, th particle resampling process removes all but one set of values; and these are highly unlikely to be correct. The degeneracy problem is especially severe in high-dimensional parameter spaces, whether discrete or continuous. Hence, although learning requires inference, the most successful inference algorithm for temporal models is inapplicable. Kantas et al. (2009) and Carvalho et al. (2010) describe several algorithms that have been proposed to ar X iv :1 30 5.", "startOffset": 234, "endOffset": 1213}, {"referenceID": 8, "context": "For example, the \u201cartificial dynamics\u201d approach (Liu and West, 2001) introduces a stochastic transition model for the parameter variables, allowing exploration of the parameter space, but this may result in biased estimates.", "startOffset": 48, "endOffset": 68}, {"referenceID": 0, "context": "Online EM algorithms (Andrieu et al., 2005) provide only point estimates of static parameters, may converge to local optima, and are biased unless used with the full smoothing distribution.", "startOffset": 21, "endOffset": 43}, {"referenceID": 1, "context": "The particle MCMC algorithm (Andrieu et al., 2010) converges to the true posterior, but requires computation growing with T , the length of the data sequence.", "startOffset": 28, "endOffset": 50}, {"referenceID": 6, "context": "The resample-move algorithm (Gilks and Berzuini, 2001) includes Gibbs sampling of parameter variables\u2014that is, in Figure 1, P (\u03b8 | X1, .", "startOffset": 28, "endOffset": 54}, {"referenceID": 0, "context": "Online EM algorithms (Andrieu et al., 2005) provide only point estimates of static parameters, may converge to local optima, and are biased unless used with the full smoothing distribution. The particle MCMC algorithm (Andrieu et al., 2010) converges to the true posterior, but requires computation growing with T , the length of the data sequence. The resample-move algorithm (Gilks and Berzuini, 2001) includes Gibbs sampling of parameter variables\u2014that is, in Figure 1, P (\u03b8 | X1, . . . , XT ). This method requires O(T ) computation per sample, leading Gilks and Berzuini to propose a sampling rate proportional to 1/T to preserve constant-time updates. Storvik (2002) and Polson et al.", "startOffset": 22, "endOffset": 673}, {"referenceID": 0, "context": "Online EM algorithms (Andrieu et al., 2005) provide only point estimates of static parameters, may converge to local optima, and are biased unless used with the full smoothing distribution. The particle MCMC algorithm (Andrieu et al., 2010) converges to the true posterior, but requires computation growing with T , the length of the data sequence. The resample-move algorithm (Gilks and Berzuini, 2001) includes Gibbs sampling of parameter variables\u2014that is, in Figure 1, P (\u03b8 | X1, . . . , XT ). This method requires O(T ) computation per sample, leading Gilks and Berzuini to propose a sampling rate proportional to 1/T to preserve constant-time updates. Storvik (2002) and Polson et al. (2008) observe that a fixed-dimensional sufficient statistic (if one exists) for \u03b8 can be updated in constant time.", "startOffset": 22, "endOffset": 698}, {"referenceID": 5, "context": "All details of proofs are given in the appendix of the full version (Erol et al., 2013).", "startOffset": 68, "endOffset": 87}, {"referenceID": 11, "context": "To avoid the degeneracy problem, Storvik (2002) modifies the SIR algorithm by adding a Gibbs sampling step for \u03b8 conditioned on the state trajectory in each particle (see Algorithm 2).", "startOffset": 33, "endOffset": 48}, {"referenceID": 7, "context": "Matching terms with the standard KF update equations (Kalman, 1960), we find that the transition matrix for the KF is the identity matrix, the transition noise covariance matrix is the zero matrix, the observation matrix for the KF is Ft, and the observation noise covariance matrix is Q.", "startOffset": 53, "endOffset": 67}, {"referenceID": 5, "context": "See the supplementary material (Erol et al., 2013) for the derivation.", "startOffset": 31, "endOffset": 50}, {"referenceID": 5, "context": "The proof is straightforward by the Fisher\u2013Neyman factorization theorem; more details are given in the supplementary material of the full version (Erol et al., 2013).", "startOffset": 146, "endOffset": 165}, {"referenceID": 13, "context": "EKF linearizes nonlinear transitions around the current estimates of the mean and covariance and uses Kalman filter updates for state estimation (Welch and Bishop, 1995).", "startOffset": 145, "endOffset": 169}, {"referenceID": 10, "context": "We suggest slice sampling (Neal, 2003) or the MetropolisHastings algorithm (Robert and Casella, 2005) for this purpose.", "startOffset": 75, "endOffset": 101}, {"referenceID": 5, "context": "The proof is given in (Erol et al., 2013).", "startOffset": 22, "endOffset": 41}, {"referenceID": 5, "context": "The proof is given in the supplementary material (Erol et al., 2013).", "startOffset": 49, "endOffset": 68}, {"referenceID": 11, "context": "Note that the models discussed do not satisfy the Gaussian process model assumption of Storvik (2002). 0 0.", "startOffset": 87, "endOffset": 102}], "year": 2013, "abstractText": "The parameters of temporal models, such as dynamic Bayesian networks, may be modelled in a Bayesian context as static or atemporal variables that influence transition probabilities at every time step. Particle filters fail for models that include such variables, while methods that use Gibbs sampling of parameter variables may incur a per-sample cost that grows linearly with the length of the observation sequence. Storvik (2002) devised a method for incremental computation of exact sufficient statistics that, for some cases, reduces the per-sample cost to a constant. In this paper, we demonstrate a connection between Storvik\u2019s filter and a Kalman filter in parameter space and establish more general conditions under which Storvik\u2019s filter works. Drawing on an analogy to the extended Kalman filter, we develop and analyze, both theoretically and experimentally, a Taylor approximation to the parameter posterior that allows Storvik\u2019s method to be applied to a broader class of models. Our experiments on both synthetic examples and real applications show improvement over existing methods.", "creator": "LaTeX with hyperref package"}}}