{"id": "1306.2347", "review": {"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "10-Jun-2013", "title": "Auditing: Active Learning with Outcome-Dependent Query Costs", "abstract": "We propose a learning setting in which unlabeled data is free, and the cost of a label depends on its value, which is not known in advance. We study binary classification in an extreme case, where the algorithm only pays for negative labels. Our motivation are applications such as fraud detection, in which investigating an honest transaction should be avoided if possible. A model like these can lead to useful insights, and help people to better understand what is happening. We also consider the existence of self-report data which provides some hope for new insights.", "histories": [["v1", "Mon, 10 Jun 2013 20:18:48 GMT  (122kb,D)", "https://arxiv.org/abs/1306.2347v1", "25 pages"], ["v2", "Fri, 27 Sep 2013 17:57:33 GMT  (122kb,D)", "http://arxiv.org/abs/1306.2347v2", "25 pages"], ["v3", "Tue, 15 Oct 2013 18:27:07 GMT  (120kb,D)", "http://arxiv.org/abs/1306.2347v3", "Corrections in section 5"], ["v4", "Sun, 12 Jul 2015 10:11:57 GMT  (120kb,D)", "http://arxiv.org/abs/1306.2347v4", "Corrections in section 5"]], "COMMENTS": "25 pages", "reviews": [], "SUBJECTS": "cs.LG", "authors": ["sivan sabato", "anand d sarwate", "nati srebro"], "accepted": true, "id": "1306.2347"}, "pdf": {"name": "1306.2347.pdf", "metadata": {"source": "CRF", "title": "Auditing: Active Learning with Outcome-Dependent Query Costs", "authors": ["Sivan Sabato", "Anand Sarwate", "Nathan Srebro"], "emails": ["sivan.sabato@microsoft.com", "asarwate@ttic.edu", "nati@ttic.edu"], "sections": [{"heading": "1 Introduction", "text": "Active learning algorithms seek to mitigate the cost of learning by using unlabeled data and sequentially selecting examples to query for their label to minimize total number of queries. In some cases, however, the actual cost of each query depends on the true label of the example and is thus not known before the label is requested. For instance, in detecting fraudulent credit transactions, a query with a positive answer is not wasteful, whereas a negative answer is the result of a wasteful investigation of an honest transaction, and perhaps a loss of good-will. More generally, in a multiclass setting, different queries may entail different costs, depending on the outcome of the query. In this work we focus on the binary case, and on the extreme version of the problem, as described in the example of credit frauds, in which the algorithm only pays for queries which return a negative label. We term this setting auditing, and the cost incurred by the algorithm its auditing complexity.\nThere are several natural ways to measure performance for auditing. For example, we may wish for the algorithm to maximize the number of positive labels it finds for a fixed \u201cbudget\u201d of negative labels, or to minimize the number of negative labels while finding a certain number or fraction of positive labels. In this work we focus on the classical learning problem, in which one attempts to learn a classifier from a fixed hypothesis class, with an error close to the best possible. Similar to active learning, we assume we are given a large set of unlabeled examples, and aim to learn with minimal labeling cost. But unlike active learning, we only incur a cost when requesting the label of an example that turns out to be negative.\n\u2217Microsoft Research New England, Cambridge, MA USA, sivan.sabato@microsoft.com \u2020Toyota Technological Institute at Chicago, Chicago, IL USA, asarwate@ttic.edu \u2021Toyota Technological Institute at Chicago, Chicago, IL USA, nati@ttic.edu\nar X\niv :1\n30 6.\n23 47\nv4 [\ncs .L\nG ]\n1 2\nJu l 2\n01 5\nThe close relationship between auditing and active learning raises natural questions. Can the auditing complexity be significantly better than the label complexity in active learning? If so, should algorithms be optimized for auditing, or do optimal active learning algorithms also have low auditing complexity? To answer these questions, and demonstrate the differences between active learning and auditing, we study the simple hypothesis classes of thresholds and of axis-aligned rectangles in Rd, in both the realizable and the agnostic settings. We then also consider a general competitive analysis for arbitrary hypothesis classes.\nExisting work on active learning with costs (Margineantu, 2007; Kapoor et al., 2007; Settles et al., 2008; Golovin and Krause, 2011) typically assumes that the cost of labeling each point is known a priori, so the algorithm can use the costs directly to select a query. Our model is significantly different, as the costs depend on the outcome of the query itself. Kapoor et al. (2007) do mention the possibility of class-dependent costs, but this possibility is not studied in detail. An unrelated game-theoretic learning model addressing \u201cauditing\u201d was proposed by Blocki et al. (2011)."}, {"heading": "Notation and Setup", "text": "For an integer m, let [m] = {1, 2, . . . ,m}. The function I[A] is the indicator function of a set A. For a function f and a sub-domain X, f |X is the restriction of f to X. For vectors a and b in Rd, the inequality a \u2264 b implies ai \u2264 bi for all i \u2208 [d].\nWe assume a data domain X and a distribution D over labeled data points in X \u00d7{\u22121,+1}. A learning algorithm may sample i.i.d. pairs (X,Y ) \u223c D. It then has access to the value of X, but the label Y remains hidden until queried. The algorithm returns a labeling function h\u0302 : X \u2192 {\u22121,+1}. The error of a function h : X \u2192 {\u22121,+1} on D is err(D,h) = E(X,Y )\u223cD[h(X) 6= Y ]. The error of h on a multiset S \u2286 X \u00d7{\u22121,+1} is given by err(S, h) = 1|S| \u2211 (x,y)\u2208S I[h(x) 6= y]. The passive sample complexity of an algorithm is the number of pairs it draws from D. The active label complexity of an algorithm is the total number of label queries the algorithm makes. Its auditing complexity is the number of queries the algorithm makes on points with negative labels.\nWe consider guarantees for learning algorithms relative to a hypothesis class H \u2286 {\u22121,+1}X . We denote the error of the best hypothesis in H on D by err(D,H) = minh\u2208H err(D,h). Similarly, err(S,H) = minh\u2208H err(S, h). We usually denote the best error for D by \u03b7 = err(D,H).\nTo describe our algorithms it will be convenient to define the following sample sizes, using universal constants C, c > 0. Let \u03b4 \u2208 (0, 1) be a confidence parameter, and let \u2208 (0, 1) be an error parameter. Let mag( , \u03b4, d) = C(d + ln(c/\u03b4))/ 2. If a sample S is drawn from D with |S| = mag( , \u03b4, d) then with probability 1 \u2212 \u03b4, \u2200h \u2208 H, err(D,h) \u2264 err(S, h) + and err(S,H) \u2264 err(D,H)+ (Bartlett and Mendelson, 2002). Let m\u03bd( , \u03b4, d) = C(d ln(c/\u03bd )+ln(c/\u03b4))/\u03bd2 . Results of Vapnik and Chervonenkis (1971) show that if H has VC dimension d and S is drawn from D with |S| = m\u03bd , then for all h \u2208 H,\nerr(S, h) \u2264 max {err(D,h)(1 + \u03bd), err(D,h) + \u03bd } and (1) err(D,h) \u2264 max {err(S, h)(1 + \u03bd), err(S, h) + \u03bd } ."}, {"heading": "2 Active Learning vs. Auditing: Summary of Results", "text": "The main point of this paper is that the auditing complexity can be quite different from the active label complexity, and that algorithms tuned to minimizing the audit label complexity give improvements over standard active learning algorithms. Before presenting these differences, we note that in some regimes, neither active learning nor auditing can improve significantly over the passive sample complexity. In particular, a simple adaptation of a result of Beygelzimer et al. (2009) establishes the following lower bound.\nLemma 2.1. Let H be a hypothesis class with VC dimension d > 1. If an algorithm always finds a hypothesis h\u0302 with err(D, h\u0302) \u2264 err(D,H) + for > 0, then for any \u03b7 \u2208 (0, 1) there is a distribution D with \u03b7 = err(D,H) such that the auditing complexity of this algorithm for D is \u2126(d\u03b72/ 2).\nThat is, when \u03b7 is fixed while \u2192 0, the auditing complexity scales as \u2126(d/ 2), similar to the passive sample complexity. Therefore the two situations which are interesting are the realizable case, corresponding to \u03b7 = 0, and the agnostic case, when we want to guarantee an excess error such that \u03b7/ is bounded. We provide results for both of these regimes.\nWe will first consider the realizable case, when \u03b7 = 0. Here it is sufficient to consider the case where a fixed pool S of m points is given and the algorithm must return a hypothesis h\u0302 such that err(S, h\u0302) = 0 with probability 1. A pool labeling algorithm can be used to learn a hypothesis which is good for a distribution by drawing and labeling a large enough pool. We define auditing complexity for an unlabeled pool as the minimal number of negative labels needed to perfectly classify it. It is easy to see that there are pools with an auditing complexity at least the VC dimension of the hypothesis class.\nFor the agnostic case, when \u03b7 > 0, we denote \u03b1 = /\u03b7 and say that an algorithm (\u03b1, \u03b4)-learns a class of distributions D with respect to H if for all D \u2208 D, with probability 1 \u2212 \u03b4, h\u0302 returned by the algorithm satisfies err(D, h\u0302) \u2264 (1 + \u03b1)\u03b7. By Lemma 2.1 an auditing complexity of \u2126(d/\u03b12) is unavoidable, be we can hope to improve over the passive sample complexity lower bound of \u2126(d/\u03b7\u03b12) (Devroye and Lugosi, 1995) by avoiding the dependence on \u03b7.\nOur main results are summarized in Table 1, which shows the auditing and active learning complexities in the two regimes, for thresholds on [0, 1] and axis-aligned rectangles in Rd, where we assume that the hypotheses label the points in the rectangle as negative and points outside as positive.\nIn the realizable case, for thresholds, the optimal active learning algorithm performs binary search, resulting in \u2126(lnm) labels in the worst case. This is a significant improvement over the\npassive label complexity of m. However, a simple auditing procedure that scans from right to left queries only a single negative point, achieving an auditing complexity of 1. For rectangles, we present a simple coordinate-wise scanning procedure with auditing complexity of at most 2d, demonstrating a huge gap versus active learning, where the labels of all m points might be required. Not all classes enjoy reduced auditing complexity: we also show that for rectangles with positive points on the inside, there exists pools of size m with an auditing complexity of m.\nIn the agnostic case we wish to (\u03b1, \u03b4)-learn distributions with a true error of \u03b7 = err(D,H), for constant \u03b1, \u03b4. For active learning, it has been shown that in some cases, the \u2126(d/\u03b7) passive sample complexity can be replaced by an exponentially smaller O(d ln(1/\u03b7)) active label complexity (Hanneke, 2011), albeit sometimes with a larger polynomial dependence on d. In other cases, an \u2126(1/\u03b7) dependence exists also for active learning. Our main question is whether the dependence on \u03b7 in the active label complexity can be further reduced for auditing.\nFor thresholds, active learning requires \u2126(ln(1/\u03b7)) labels (Kulkarni et al., 1993). Using auditing, we show that the dependence on \u03b7 can be completely removed, for any true error level \u03b7 > 0, if we know \u03b7 in advance. We also show that if \u03b7 is not known at least approximately, the logarithmic dependence on 1/\u03b7 is also unavoidable for auditing. For rectangles, we show that the active label complexity is at least \u2126(d/\u03b7). In contrast, we propose an algorithm with an auditing complexity of O(d2 ln2(1/\u03b7)), reducing the linear dependence on 1/\u03b7 to a logarithmic dependence. We do not know whether a linear dependence on d is possible with a logarithmic dependence on 1/\u03b7.\nMost of the proofs are provided in Appendix A."}, {"heading": "3 Auditing for Thresholds on the Line", "text": "The first question to ask is whether the audit label complexity can ever be significantly smaller than the active or passive label complexities, and whether a different algorithm is required to achieve this improvement. The following simple case answers both questions in the affirmative. Consider the hypothesis class of thresholds on the line, defined over the domain X = [0, 1]. A hypothesis with threshold a is ha(x) = I[x\u2212a \u2265 0]. The hypothesis class is Ha = {ha | a \u2208 [0, 1]}. Consider the pool setting for the realizable case. The optimal active label complexity of \u0398(log2m) can be achieved by a binary search on the pool. The auditing complexity of this algorithm can also be as large as \u0398(log2(m)). However, auditing allows us to beat this barrier. This case exemplifies an interesting contrast between auditing and active learning. Due to information-theoretic considerations, any algorithm which learns an unlabeled pool S has an active label complexity of at least log2 |H|S | (Kulkarni et al., 1993), where H|S is the set of restrictions of functions in H to the domain S. For Ha, the active label complexity is thus log2 |Ha|S | = \u2126(log2m). However, the same considerations are invalid for auditing.\nWe showed that for the realizable case, the auditing label complexity for Ha is a constant. We now provide a more complex algorithm that guarantees this for (\u03b1, \u03b4)-learning in the agnostic case. The intuition behind our approach is that in a pool with at most k errors, querying from highest to lowest until observing k+ 1 negative points, and finding the minimal error threshold on the labeled points, yields the optimal threshold.\nLemma 3.1. Let S be a pool of size m in [0, 1], and assume that err(S,Ha) \u2264 k/m. Then the procedure above finds h\u0302 such that err(S, h\u0302) = err(S,Ha) with an auditing complexity of k + 1.\nProof. Denote the last queried point by x0, and let ha\u2217 = argminh\u2208Ha err(S,Ha). Since err(S, ha\u2217) \u2264\nk/m, a\u2217 > x0. Denote by S \u2032 \u2286 S the set of points queried by the procedure. For any a > x0, err(S\u2032, ha) = err(S, ha) + |{(x, y) \u2208 S | x < x0, y = 1}|/m. Therefore, minimizing the error on S\u2032 results in a hypothesis that minimizes the error on S.\nTo learn from a distribution, one can draw a random sample and use it as the pool in the procedure above. However, the sample size required for passive (\u03b1, \u03b4)-learning of thresholds is \u2126(ln(1/\u03b7)/\u03b7). Thus, the number of errors in the pool would be k = \u03b7 \u00b7\u2126(ln(1/\u03b7)/\u03b7) = \u2126(ln(1/\u03b7)), which depends on \u03b7. To avoid this dependence, the auditing algorithm we propose uses Alg. 1 below to select a subset of the random sample, which still represents the distribution well, but its size is only \u2126(1/\u03b7).\nAlgorithm 1: Representative Subset Selection\n1: Input: pool S = (x1, . . . , xm) (with hidden labels), xi \u2208 [0, 1], \u03b7max \u2208 (0, 1], \u03b4 \u2208 (0, 1). 2: T \u2190 max{b1/3\u03b7maxc, 1}. 3: Let U = {x1, . . . , x1\ufe38 \ufe37\ufe37 \ufe38\nT copies , . . . , xm, . . . , xm\ufe38 \ufe37\ufe37 \ufe38 T copies } be the multiset with T copies of each point in S.\n4: Sort and rename the points in U such that x\u2032i \u2264 x\u2032i+1 for all i \u2208 [Tm]. 5: Let Sq be an empty multiset. 6: for t = 1 to T do 7: S(t)\u2190 {x\u2032(t\u22121)m+1, . . . , x \u2032 tm}. 8: Draw 14 ln(8/\u03b4) random points from S(t) independently uniformly at random and add them to Sq (with duplications).\n9: end for 10: Return Sq (with the corresponding hidden labels).\nLemma 3.2. Let \u03b4, \u03b7max \u2208 (0, 1). Let S be a pool such that err(S,Ha) \u2264 \u03b7max. Let Sq be the output of Alg. 1 with inputs S, \u03b7max, \u03b4, and let h\u0302 = argminh\u2208Ha err(Sq,Ha). Then with probability 1\u2212 \u03b4,\nerr(Sq, h\u0302) \u2264 6\u03b7max and err(S, h\u0302) \u2264 17\u03b7max.\nAlgorithm 2: Auditing for Thresholds with a constant \u03b1\n1: Input: \u03b7max, \u03b4, \u03b1 \u2208 (0, 1), access to distribution D such that err(D,Ha) \u2264 \u03b7max. 2: \u03bd \u2190 \u03b1/5. 3: Draw a random labeled pool (with hidden labels) S0 of size m\u03bd(\u03b7, \u03b4/2, 1) from D. 4: Draw a random sample S of size mag((1 + \u03bd)\u03b7max, \u03b4/2, 1) uniformly from S0. 5: Get a subset Sq using Alg. 1 with inputs S, 2(1 + \u03bd)\u03b7max, \u03b4/2. 6: Query points in Sq from highest to lowest. Stop after d12|Sq|(1 + \u03bd)\u03b7maxe+ 1 negatives. 7: Find a\u0302 such that ha\u0302 minimizes the error on the labeled part of Sq. 8: Let S1 be the set of the 36(1 + \u03bd)\u03b7max|S0| closest points to a\u0302 in S from each side of a\u0302. 9: Draw S2 of size m\nag(\u03bd/72, \u03b4/2, 1) from S1 (see definition on page 2). 10: Query all points in S2, and return h\u0302 that minimizes the error on S2.\nThe algorithm for auditing thresholds on the line in the agnostic case is listed in Alg. 2. This algorithm first achieves (C, \u03b4) learning of Ha for a fixed C (in step 7, based on Lemma 3.2 and\nLemma 3.1, and then improves its accuracy to achieve (\u03b1, \u03b4)-learning for \u03b1 > 0, by additional passive sampling in a restricted region. The following theorem provides the guarantees for Alg. 2.\nTheorem 3.3. Let \u03b7max, \u03b4, \u03b1 \u2208 (0, 1). Let D be a distribution with error err(D,Ha) \u2264 \u03b7max. Alg. 2 with input \u03b7max, \u03b4, \u03b1 has an auditing complexity of O(ln(1/\u03b4)/\u03b1\n2), and returns h\u0302 such that with probability 1\u2212 \u03b4, err(D, h\u0302) \u2264 (1 + \u03b1)\u03b7max.\nIt immediately follows that if \u03b7 = err(D,H) is known, (\u03b1, \u03b4)-learning is achievable with an auditing complexity that does not depend on \u03b7. This is formulated in the following corollary.\nCorollary 3.4 ((\u03b1, \u03b4)-learning for Ha). Let \u03b7, \u03b1, \u03b4 \u2208 (0, 1]. For any distribution D with error err(D,Ha) = \u03b7, Alg. 2 with inputs \u03b7max = \u03b7, \u03b1, \u03b4 (\u03b1, \u03b4)-learns D with respect to Ha with an auditing complexity of O(ln(1/\u03b4)/\u03b12).\nA similar result holds if the error is known up to a multiplicative constant. But what if no bound on \u03b7 is known? The following lower bound shows that in this case, the best active complexity for threshold this similar to the best active label complexity.\nTheorem 3.5 (Lower bound on auditing Ha without \u03b7max). Consider any constant \u03b1 \u2265 0. For any \u03b4 \u2208 (0, 1), if an auditing algorithm (\u03b1, \u03b4)-learns any distribution D such that err(D,Ha) \u2265 \u03b7min, then the algorithm\u2019s auditing complexity is \u2126(ln(1\u2212\u03b4\u03b4 ) ln(1/\u03b7min)).\nNonetheless, in the next section show that there are classes with a significant gap between active and auditing complexities even without an upper bound on the error."}, {"heading": "4 Axis Aligned Rectangles", "text": "A natural extension of thresholds to higher dimension is the class of axis-aligned rectangles, in which the labels are determined by a d-dimensional hyperrectangle. This hypothesis class, first introduced in Blumer et al. (1989), has been studied extensively in different regimes (Kearns, 1998; Long and Tan, 1998), including active learning (Hanneke, 2007b). An axis-aligned-rectangle hypothesis is a disjunction of 2d thresholds. For simplicity of presentation, we consider here the slightly simpler class of disjunctions of d thresholds over the positive orthant Rd+. It is easy to reduce learning of an axis-aligned rectangle in Rd to learning of a disjunction of thresholds in R2d, by mapping each point x \u2208 Rd to a point x\u0303 \u2208 R2d such that for i \u2208 [d], x\u0303[i] = max(x[i], 0) and x\u0303[i + d] = max(0,\u2212x[i])). Thus learning the class of disjunctions is equivalent, up to a factor of two in the dimensionality, to learning rectangles.1 Because auditing costs are asymmetric, we consider two possibilities for label assignment. For a vector a = (a[1], . . . , a[d]) \u2208 Rd+, define the hypotheses ha and h\u2212a by\nha(x) = 2I[\u2203i \u2208 [d], x[i] \u2265 a[i]]\u2212 1, and h\u2212a (x) = \u2212ha(x).\nDefine H2 = {ha | a \u2208 Rd+} and H\u22122 = {h\u2212a | a \u2208 Rd+}. In H2 the positive points are outside the rectangle and in H\u22122 the negatives are outside. Both classes have VC dimension d. All of our results for these classes can be easily extended to the corresponding classes of general axis-aligned rectangles on Rd, with at most a factor of two penalty on the auditing complexity.\n1This reduction suffices if the origin is known to be in the rectangle. Our algorithms and results can all be extended to the case where rectangles are not required to include the origin. To keep the algorithm and analysis as simple as possible, we state the result for this special case."}, {"heading": "4.1 The Realizable Case", "text": "We first consider the pool setting for the realizable case, and show a sharp contrast between the auditing complexity and the active label complexity for H2 and H\u22122 . Assume a pool of size m. While the active learning complexity for H2 and H\u22122 can be as large as m, the auditing complexities for the two classes are quite different. For H\u22122 , the auditing complexity can be as large as m, but for H2 it is at most d. We start by showing the upper bound for auditing of H2.\nTheorem 4.1 (Pool auditing upper bound for H2). The auditing complexity of any unlabeled pool Su of size m with respect to H2 is at most d.\nProof. The method is a generalization of the approach to auditing for thresholds. Let h\u2217 \u2208 H2 such that err(S, h\u2217) = 0. For each i \u2208 [d], order the points x in S by the values of their i-th coordinates x[i]. Query the points sequentially from largest value to the smallest (breaking ties arbitrarily) and stop when the first negative label is returned, for some point xi. Set a[i]\u2190 xi[i], and note that h\u2217 labels all points in {x | x[i] > a[i]} positive. Return the hypothesis h\u0302 = ha. This procedure clearly queries at most d negative points and agrees with the labeling of h\u2217.\nIt is easy to see that for full Axis-Aligned Rectangles, an auditing complexity of 2d can be achieved in a similar fashion. We now show the lower bound for the auditing complexity of H\u22122 . This immediately implies the same lower bound for active label complexity of H\u22122 and H2.\nTheorem 4.2 (Pool auditing lower bound for H\u22122). For any m and any d \u2265 2, there is a pool Su \u2286 Rd+ of size m such that its auditing complexity with respect to H\u22122 is m.\nProof. The construction is a simple adaptation of a construction due to Dasgupta (2004), originally showing an active learning lower bound for the class of hyperplanes. Let the pool be composed of m distinct points on the intersection of the unit circle and the positive orthant: Su = {(cos \u03b8j , sin \u03b8j)} for distinct \u03b8j \u2208 [0, \u03c0/2]. Any labeling which labels all the points in Su negative except any one point is realizable forH\u22122 , and so is the all-negative labeling. Thus, any algorithm that distinguishes between these different labelings with probability 1 must query all the negative labels.\nCorollary 4.3 (Realizable active label complexity of H2 and H\u22122). For H2 and H\u22122 , there is a pool of size m such that its active label complexity is m."}, {"heading": "4.2 The Agnostic Case", "text": "We now consider H2 in the agnostic case, where \u03b7 > 0. The best known algorithm for active learning of rectangles (2, \u03b4)-learns a very restricted class of distributions (continuous product distributions which are sufficiently balanced in all directions) with an active label complexity of O\u0303(d3p(ln(1/\u03b7)p(ln(1/\u03b4))), where p(\u00b7) is a polynomial (Hanneke, 2007b). However, for a general distribution, active label complexity cannot be significantly better than passive label complexity. This is formalized in the following theorem.\nTheorem 4.4 (Agnostic active label complexity of H2). Let \u03b1, \u03b7 > 0, \u03b4 \u2208 (0, 12). Any learning algorithm that (\u03b1, \u03b4)-learns all distributions such that err(D,H) = \u03b7 for \u03b7 > 0 with respect to H2 has an active label complexity of \u2126(d/\u03b7).\nIn contrast, the auditing complexity of H2 can be much smaller, as we show for Alg. 3 below.\nAlgorithm 3: Auditing for H2 1: Input: \u03b7min > 0, \u03b1 \u2208 (0, 1], access to distribution D over Rd+ \u00d7 {\u22121,+1}. 2: \u03bd \u2190 \u03b1/25. 3: for t = 0 to blog2(1/\u03b7min)c do 4: \u03b7t \u2190 2\u2212t. 5: Draw a sample St of size m\u03bd(\u03b7t, \u03b4/ log2(1/\u03b7min), 10d) with hidden labels. 6: for i = 1 to d do 7: j \u2190 0 8: while j \u2264 d(1 + \u03bd)\u03b7t|St|e+ 1 do 9: If unqueried points exist, query the unqueried point with highest i\u2019th coordinate;\n10: If query returned \u22121, j \u2190 j + 1. 11: end while 12: bt[i]\u2190 the i\u2019th coordinate of the last queried point, or 0 if all points were queried. 13: end for 14: Set Sbt to St, with unqueried labels set to \u22121. 15: Vt \u2190 V\u03bd(Sbt , \u03b7t,H2[bt]). 16: \u03b7\u0302t \u2190 maxh\u2208Vt errneg(Sbt , h). 17: if \u03b7\u0302t > \u03b7t/4 then 18: Skip to step 21 19: end if 20: end for 21: Return h\u0302 \u2261 argminh\u2208H2[bt] err(Sbt , h).\nTheorem 4.5 (Auditing complexity of H2). For \u03b7min, \u03b1, \u03b4 \u2208 (0, 1), Alg. 3 (\u03b1, \u03b4)-learns all distributions with \u03b7 \u2265 \u03b7min with respect to H2 with an auditing complexity of O(d 2 ln(1/\u03b1\u03b4) \u03b12 ln2(1/\u03b7min)).\nIf \u03b7min is polynomially close to the true \u03b7, we get an auditing complexity of O(d 2 ln2(1/\u03b7)), compared to the active label complexity of \u2126(d/\u03b7), an exponential improvement in \u03b7. It is an open question whether the quadratic dependence on d is necessary here.\nAlg. 3 implements a \u2018low-confidence\u2019 version of the realizable algorithm. It sequentially queries points in each direction, until enough negative points have been observed to make sure the threshold in this direction has been overstepped. To bound the number of negative labels, the algorithm iteratively refines lower bounds on the locations of the best thresholds, and an upper bound on the negative error, defined as the probability that a point from D with negative label is classified as positive by a minimal-error classifier. The algorithm uses queries that mostly result in positive labels, and stops when the upper bound on the negative error cannot be refined. The idea of iteratively refining a set of possible hypotheses has been used in a long line of active learning works (Cohn et al., 1994; Balcan et al., 2006; Hanneke, 2007a; Dasgupta et al., 2008). Here we refine in a particular way that uses the structure of H2, and allows bounding the number of negative examples we observe.\nWe use the following notation in Alg. 3. The negative error of a hypothesis is errneg(D,h) = P(X,Y )\u223cD[h(X) = 1 and Y = \u22121]. It is easy to see that the same convergence guarantees that hold for err(\u00b7, \u00b7) using a sample size m\u03bd( , \u03b4, d) hold also for the negative error errneg(\u00b7, \u00b7) (see Lemma A.4). For a labeled set of points S, an \u2264 (0, 1) and a hypothesis class H, denote\nV\u03bd(S, ,H) = {h \u2208 H | err(S, h) \u2264 err(S,H) + (2\u03bd + \u03bd2) \u00b7max(err(S,H), )}. For a vector b \u2208 Rd+, define H2[b] = {ha \u2208 H2 | a \u2265 b}.\nTheorem 4.5 is proven in Section A.4.3. The proof idea is to show that at each round t, Vt includes any h\u2217 \u2208 argminh\u2208H err(D,h), and \u03b7\u0302t is an upper bound on errneg(D,h\u2217). Further, at any given point minimizing the error on Sbt is equivalent to minimizing the error on the entire (unlabeled) sample. We conclude that the algorithm obtains a good approximation of the total error. Its auditing complexity is bounded since it queries a bounded number of negative points at each round."}, {"heading": "5 Outcome-dependent Costs for a General Hypothesis Class", "text": "In this section we return to the realizable pool setting and consider finite hypothesis classes H. We consider general outcome-dependent costs and a general space of labels Y, so that H \u2286 YX . Let S \u2286 X be an unlabeled pool, and let cost : S \u00d7 H \u2192 R+ denote the cost of a query: For x \u2208 S and h \u2208 H, cost(x, h) is the cost of querying the label of x given that h is the true (unknown) hypothesis. In the auditing setting, Y = {\u22121,+1} and cost(x, h) = I[h(x) = \u22121]. For active learning, cost \u2261 1. Note that under this definition of cost function, the algorithm may not know the cost of the query until it reveals the true hypothesis.\nDefine OPTcost(S) to be the minimal cost of an algorithm that for any labeling of S which is consistent with some h \u2208 H produces a hypothesis h\u0302 such that err(S, h\u0302) = 0. In the active learning setting, where cost \u2261 1, it is NP-hard to obtain OPTcost(S) for general H and S. This can be shown by a reduction to set-cover (Hyafil and Rivest, 1976). A simple adaptation of the reduction for the auditing complexity, which we defer to the full version of this work, shows that it is also NP-hard to obtain OPTcost(S) in the auditing setting.\nFor active learning, and for query costs that do not depend on the true hypothesis (that is cost(x, h) \u2261 cost(x)), Golovin and Krause (2011) showed an efficient greedy strategy that achieves a cost of O(OPTcost(S) \u00b7 ln(|H|)) for any S. This approach has also been shown to provide considerable performance gains in practical settings (Gonen et al., 2013). The greedy strategy consists of iteratively selecting a point whose label splits the set of possible hypotheses as evenly as possible, with a normalization proportional on the cost of each query.\nWe now show that for outcome-dependent costs, if there are two labels and the cost depends only on the label, then another greedy strategy provides similar approximation guarantees for OPTcost(S). The algorithm is defined as follows: Suppose that so far the algorithm requested labels for x1, . . . , xt and received the corresponding labels y1, . . . , yt. Letting St = {(x1, y1), . . . , (xt, yt)}, denote the current version space by V (St) = {h \u2208 H|S | \u2200(x, y) \u2208 St, h(x) = y}. The next query selected by the algorithm is\nx \u2208 argmax x\u2208S min h\u2208H |V (St) \\ V (St \u222a {(x, h(x))})| cost(x, h) .\nThat is, the algorithm selects the query that in the worst-case over the possible hypotheses, would remove the most hypotheses from the version spaces, when normalizing by the outcome-dependent cost of the query. The algorithm terminates when |V (St)| = 1, and returns the single hypothesis in the version space.\nTheorem 5.1. For any hypothesis class H with |Y| = 2, any pool S, and any true hypothesis h \u2208 H, if cost(x, h) \u2261 cost(x, h(x)), then the cost of the proposed algorithm is at most (ln(|H|S | \u2212 1) + 1) \u00b7OPT.2\nIf cost is the auditing cost, the proposed algorithm is mapped to the following intuitive strategy: At every round, select a query such that, if its result is a negative label, then the number of hypotheses removed from the version space is the largest. This strategy is consistent with a simple principle based on a partial ordering of the points: For points x, x\u2032 in the pool, define x\u2032 x if {h \u2208 H | h(x\u2032) = \u22121} \u2287 {h \u2208 H | h(x) = \u22121}, so that if x\u2032 has a negative label, so does x. In the auditing setting, it is always preferable to query x before querying x\u2032. Therefore, for any realizable auditing problem, there exists an optimal algorithm that adheres to this principle. It is thus encouraging that our greedy algorithm is also consistent with it.\nAn O(ln(|H|S |)) approximation factor for auditing is less appealing than the same factor for active learning. By information-theoretic arguments, active label complexity is at least log2(|H|S |) (and hence the approximation at most squares the cost), but this does not hold for auditing. Nonetheless, hardness of approximation results for set cover (Feige, 1998), in conjunction with the reduction to set cover of Hyafil and Rivest (1976) mentioned above, imply that such an approximation factor cannot be avoided for a general auditing algorithm."}, {"heading": "6 Conclusion and Future Directions", "text": "In this paper we propose a model of active learning with query costs that depend on the outcome of the query. We show that the auditing complexity can be significantly different from the active learning complexity, and that tailoring algorithms for auditing can be beneficial. Our algorithms take advantage of the fact that positive labels are free, to improve error at less cost than in active learning. We also described a general approach to designing auditing procedures for finite hypothesis classes, based on a greedy strategy and on a partial ordering of points, which takes advantage of the asymmetric label costs.\nThere are many interesting directions suggested by this work. First, it is known that for some hypothesis classes, active learning cannot improve over passive learning for certain distributions (Dasgupta, 2004), and the same is true for auditing. However, exponential speedups are possible for active learning on certain classes of distributions (Balcan et al., 2006; Dasgupta et al., 2008), in particular ones with a small disagreement coefficient (Hanneke, 2007a). This quantity is related to the Alexander capacity function (Koltchinskii, 2010), which appears in lower bounds for active learning (Raginsky and Rakhlin, 2011). It would be interesting if a similar property of the distribution can guarantee an improvement with auditing over active or passive learning.\nInvestigating such a general property might shed light on auditing for other important hypothesis classes such as decision trees or halfspaces. It is well known that for some important settings, such as learning with hyperplanes, there are distributions which resist any improvement using active learning (Dasgupta, 2004). Recent work by Gonen et al. (2013) has shown that both theoretically and empirically, more aggressive learning strategies can be effective in the realizable case. These strategies are based on heuristics (Tong and Koller, 2001) that query the most \u201cinformative\u201d points. It would be interesting to see how such approaches should change in the presence of asymmetric label costs.\n2A stronger version was erroneously given in the short version of this paper. However, our proof holds only for this weaker version.\nThe name \u201cauditing\u201d suggests an imbalance in the number of points per class (this is the case in fraud). Prior work on learning from unbalanced data was surveyed by He and Garcia (2009). Some of these approaches (Ertekin et al., 2007) use the same active learning heuristics (Tong and Koller, 2001), and it would be interesting to see how these apply to auditing.\nIn this work we considered algorithms which aim to minimize the number of negative labels needed to classify all of the points accurately, but this is not the only way to measure the performance in an auditing setting. For example, we may wish to maximize the number of positive points the algorithm finds subject to a bound on the number of negative labels encountered. In addition, auditing is an extreme version of asymmetric label costs \u2013 positive labels are free \u2013 but it would be interesting to study more general label costs. An interesting generalization along these lines is a multiclass setting with a different cost for each label. These measures and costs are different from those studied in active learning, and may lead to new algorithmic insights."}, {"heading": "A Proofs omitted from the text", "text": ""}, {"heading": "A.1 Additional notation", "text": "We use C,C1, C2, . . . , c, c \u2032 etc. to denote positive numerical constants. Their values may change between expressions. We use the shorthand \u2200\u03b4 to say that a statement holds with probability at least 1 \u2212 c\u03b4, for some constant c. Denote a multiplicative/additive upper bound for a by aJn, \u03bbK = max{na, a+ (n\u2212 1)\u03bb}. We will use the following easy fact.\nFact 1. For any non-negative numbers a, b, c, , n,m, if a \u2264 bJn, K then aJm,\u03bbK \u2264 bJmn, \u03bbK.\nA.2 Standard results from probability\nThese are included for the ease of the reader.\nTheorem A.1 (Hoeffding\u2019s Inequality (Hoeffding, 1963)). Let the random variables X1, . . . , Xn be independent with Xi \u2208 [0, 1], and let X = 1n \u2211 i\u2208[n]Xi. Then for any t > 0,\nP[X > E[X] + t] \u2264 exp ( \u22122nt2 ) .\nTheorem A.2 (Bernstein\u2019s Inequality (Bernstein, 1946)). Let the random variables X1, . . . , Xn be independent with Xi\u2212E[Xi] \u2264 1. Let X = 1n \u2211n i=1Xi and let \u03c3 2 = 1n \u2211n\ni=1 Var(Xi) be the variance of X. Then for any t > 0,\nP[X > E[X] + t] \u2264 exp ( \u2212 nt 2\n2(\u03c32 + t/3)\n) .\nIn particular, by setting the right hand side to \u03b4 and solving for t, we get that with probability 1\u2212 \u03b4,\nX \u2264 E[X] + 2 3\nln(1/\u03b4)/n+ \u221a 2\u03c32 ln(1/\u03b4)/n."}, {"heading": "A.3 Proofs for Section 3", "text": "Proof of Lemma 3.2. We start with the first inequality. If \u03b7max \u2265 1/6 then the inequality trivially holds. Thus assume \u03b7max < 1/6. Let W = 14 ln(8/\u03b4) and let N = WT be the size of the subset Sq. Let h\n\u2217 \u2208 argminh\u2208Ha err(S,Ha) be a minimizer of the error on S. By assumption err(S, h\u2217) \u2264 \u03b7max. For each t, let {Xt(l) | l \u2208 [W ]} be the W points drawn from S(t) by the procedure and Yt(l) be their corresponding labels given by S. Let Zt(l) = I[Yt(l) 6= h\u2217(Xt(l))] and note that {Zt(l)} for l \u2208 [W ] are i.i.d. random variables, and Zt(l) \u2212 E[Zt(l)] \u2264 1. Furthermore, we have Var[Zt(l)] \u2264 E[Z2t (l)] \u2264 E[Zt(l)]. Therefore\n1\nN \u2211 t\u2208[T ],l\u2208[W ] Var[Zt(l)] \u2264 1 N \u2211 t\u2208[T ],l\u2208[W ] E[Zt(l)] \u2264 err(S, h\u2217) \u2264 \u03b7max.\nTherefore by Bernstein\u2019s inequality (Bernstein, 1946, see Theorem A.2), with probability 1\u2212 \u03b4,\nerr(Sq, h \u2217) =\n1\nN \u2211 t\u2208[T ],l\u2208[W ] Zt(l) \u2264 \u03b7max + 2 3 ln(1/\u03b4)/N + \u221a 2\u03b7max ln(1/\u03b4)/N.\nBecause T = max{b1/3\u03b7c, 1}, for \u03b7max < 1/6 we have T \u2265 1/6\u03b7. Therefore N \u2265 14 ln(8/\u03b4)/6\u03b7. Substituting N and \u03b4 in the inequality above we get that with probability 1 \u2212 \u03b4/8, err(Sq, h\u0302) \u2264 err(Sq, h\n\u2217) \u2264 6\u03b7max. For the second claim, if \u03b7max > 1/17 the claim trivially holds. Thus assume \u03b7max \u2264 1/17. We now show that the error of a threshold h\u0302 \u2208 argminh\u2208Ha err(Sq,Ha) on the original set S is at most 17\u03b7max. Let A(h) = {x \u2208 U | h(x) = 1} be the points in the set U labeled 1 by a hypothesis h, and let gi = hx\u2032\n(i\u22121)m+1 be the hypothesis corresponding to the threshold at the leftmost point of S(i). Note that A(gi) = \u22c3 j>i S(j).\nWe claim that for any hypothesis h such that err(S, h) > err(S, h\u2217) + 4/T , the error on the sampled set Sq must satisfy err(Sq, h) > err(Sq, h \u2217) with high probability, and therefore h cannot be a minimizer h\u0302. We consider two cases, depending on whether the threshold for h is larger or smaller than h\u2217. First suppose that the threshold is larger so that A(h) \u2286 A(h\u2217). Let i be the smallest index such that A(gi) \u2286 A(h\u2217) and j be the largest index such that A(h) \u2286 A(gj). The situation is illustrated in Figure 1. Since err(S, h) > err(S, h\u2217) + 4/T , there must be three full intervals S(t) between gi and gj , so |j \u2212 i| \u2265 3. Define \u2206 = |j \u2212 i|.\nThen using the fact that a single S(t) can contribute at most 1/T to the error on Sq, we can\nbound the gap:\nerr(Sq, h)\u2212 err(Sq, h\u2217) = err(Sq, h)\u2212 err(Sq, gj) + err(Sq, gj)\u2212 err(Sq, gi) + err(Sq, gi)\u2212 err(Sq, h\u2217) \u2265 err(Sq, gj)\u2212 err(Sq, gi)\u2212 2/T.\nTherefore for any h whose threshold is between those for gj and gj+1, in order to show that err(Sq, h) > err(Sq, h\n\u2217) with high probability it is sufficient to show that err(Sq, gj)\u2212 err(Sq, gi) \u2265 2/T with high probability.\nNote that the number of points in Sq on which gi and gj disagree is W\u2206, corresponding to the subsamples in the \u2206 segments S(i+ 1), S(i+ 2), . . . , S(j) in Algorithm 1. For each pair (x, y) in those segments, either gi or gj errs, and err((x, y), gj) \u2212 err((x, y), gi) = 1 \u2212 2I[gi(x) 6= y]. Let Zit(l) = I[Yt(l) 6= hi(Xt(l))]. Then\nerr(Sq, gj)\u2212 err(Sq, gi) = 1\nWT j\u2211 t=i+1 \u2211 l\u2208[W ] (1\u2212 2Zit(l)) = \u2206 T \u2212 2 WT j\u2211 t=i+1 \u2211 l\u2208[W ] Zit(l).\nThe event that this difference is smaller than 2/T is equivalent to\n1\nW\u2206 j\u2211 t=i+1 \u2211 l\u2208[W ] Zit(l) \u2265 \u2206\u2212 2 2\u2206 \u2265 1 6 .\nNote that hi agrees with h \u2217 on \u22c3j t=i+1 S(t), so\nE  1 W\u2206 j\u2211 t=i+1 \u2211 l\u2208[W ] Zit(l)  \u2264 err(S, h\u2217) \u2264 \u03b7max. By Hoeffding\u2019s inequality (Hoeffding, 1963, see Theorem A.1), and since \u03b7max \u2264 1/17,\nP[err(Sq, gj)\u2212 err(Sq, gi) \u2264 2/T ] \u2264 P  1 W\u2206 j\u2211 t=i+1 \u2211 l\u2208[W ] Z \u2032t(l) \u2265 1 6  \u2264 exp ( \u22122W\u2206 ( 1\n6 \u2212 \u03b7max )2) \u2264 exp (\u2212W\u2206/42) .\nNow taking a union bound over all j such that j > i+ 3, we have\nP[\u2200j \u2265 i+ 3, err(Sq, gj)\u2212 err(Sq, gi) \u2264 2/T ] \u2264 T\u2211\n\u2206=3\nexp (\u2212W\u2206/42)\n\u2264 exp(\u2212W/14)\u2212 exp(\u2212W (T + 1)/42) 1\u2212 exp(\u2212W/42) \u2264 exp(\u2212W/14) 1\u2212 exp(\u2212W/42) .\nThe other case when h < h\u2217 is symmetric, so we see that if err(S, h) > err(S, h\u2217) + 4/T then\nP[err(Sq, h) > err(Sq, h\u2217)] \u2264 2 exp(\u2212W/14)\n1\u2212 exp(\u2212W/42) .\nSince W = 14 ln(8/\u03b4), we get that the total probability is bounded by \u03b4/2. Since T > 13\u03b7max \u2212 1, we have for \u03b7max \u2264 1/17 that T > 13\u03b7max \u2212 1 17\u03b7max\n\u2265 1/4\u03b7max. Therefore for h\u0302 which minimizes the error on Sq we have err(S, h\u0302) < err(S, h\n\u2217) + 4/T < 17\u03b7max. To prove Theorem 3.3, we require the following lemma.\nLemma A.3. For S0 and ha\u0302 in Alg. 2, if err(S0,Ha) \u2264 (1 + \u03bd)\u03b7max, then the auditing complexity of step 6 of Alg. 2 is at most 85 ln(16/\u03b4) and with probability 1\u2212 \u03b4, err(S0, ha\u0302) \u2264 35(1 + \u03bd)\u03b7max.\nProof. Denote \u03b3 = (1 + \u03bd)\u03b3. Let h\u2217 \u2208 argminh\u2208H err(S0,H). Since |S| = mag(\u03b3, \u03b4/2, 1), with probability 1\u2212 \u03b4/2, err(S,Ha) \u2264 err(S0,H) +\u03b3 \u2264 2\u03b3. By Lemma 3.2, the total number of negative errors in Sq is at most d12\u03b3 \u00b7 |Sq|e+ 1. Therefore, by Lemma 3.1, step 6 finds a hypothesis ha\u0302, that minimizes the error on Sq. By Lemma 3.2, with probability 1 \u2212 \u03b4/2, err(S, ha\u0302) \u2264 34\u03b3. Therefore, due to the size of |S| again, with probability 1\u2212 \u03b4, err(S0, ha\u0302) \u2264 35\u03b3.\nThe auditing complexity of step 6 is at most 6\u03b3 \u00b7 |Sq|+ 1. Now, from Alg. 1, |Sq| \u2264 14 ln(16/\u03b4) \u00b7 max{b1/3\u03b3c, 1}. Since \u03b3 \u00b7 max{b1/3\u03b3c, 1} \u2264 1, the auditing complexity of Alg. 2 is at most d6\u03b3 \u00b7 |Sq|e+ 1 \u2264 85 ln(16/\u03b4).\nWe are now ready to prove the theorem. Proof of Theorem 3.3. We first bound err(D, h\u0302). Let h\u2217 \u2208 argminh\u2208H err(D,h), and h\u22170 \u2208 argminh\u2208H err(S0, h). Since |S0| = m\u03bd(\u03b7max, \u03b4/2, 1), with probability 1\u2212 \u03b4/2,\nerr(S0, h \u2217 0) \u2264 err(S0, h\u2217) \u2264 err(D, \u03b7max)J(1 + \u03bd), \u03b7maxK \u2264 (1 + \u03bd)\u03b7max. (2)\nTherefore, by Lemma A.3, ha\u0302 satisfies \u2200\u03b4, err(S0, h\u0302) \u2264 35(1 + \u03bd)\u03b7max. It follows that\nP(X,Y )\u223cS0 [h \u2217 0(X) 6= h\u0302(X)] \u2264 err(S0, h\u0302) + err(S0, h\u22170) \u2264 36(1 + \u03bd)\u03b7max.\nIn other words, h\u22170 classifies at most 36(1 + \u03bd)\u03b7max|S0| points differently from ha\u0302. Therefore h\u22170 \u2208 argminh\u2208H err(S1, h), where S1 is defined in step 8, since all points in S0 \\S1 are classified the same by all possible candidates for h\u22170.\nWe have\nerr(S1, h \u2217 0) \u2264 |S0| |S1| err(S0, h \u2217 0) \u2264 |S0| 2 \u00b7 36(1 + \u03bd)\u03b7max|S0| (1 + \u03bd)\u03b7max \u2264 1 72 . (3)\nSince |S2| = mag(\u03bd/72, \u03b4/2, 1), with probability 1\u2212 \u03b4/2,\nerr(S1, h\u0302) \u2264 err(S2, h\u0302) + \u03bd/72 \u2264 err(S2, h\u22170) + \u03bd/72,\nand err(S2, h \u2217 0) \u2264 err(S1, h\u22170)J(1 + \u03bd), 172K. Therefore\n\u2200\u03b4, err(S1, h\u0302) \u2264 err(S1, h\u22170)J(1 + \u03bd), 1 72 K + \u03bd/72 \u2264 err(S1, h\u22170) + \u03bd/36,\nwhere the last inequality follows from Eq. (3). Note also that err(S0 \\ S1, h\u0302) = err(S0 \\ S1, h\u22170).\nerr(S0, h\u0302) = |S0| \u2212 |S1| |S0| err(S0 \\ S1, h\u22170) + |S1| |S0| err(S1, h\u0302)\n\u2264 |S0| \u2212 |S1| |S0| err(S0 \\ S1, h\u22170) + |S1| |S0| (err(S1, h \u2217 0) + \u03bd/36) = err(S0, h \u2217 0) + 72(1 + \u03bd)\u03b7max(\u03bd/36) \u2264 err(S0, h\u22170) + 4\u03bd\u03b7max.\nIn the last inequality we used the fact that \u03bd \u2264 1. Therefore err(S0, h\u0302) \u2264 err(S0, h\u22170) + 4\u03bd\u03b7max. Combining this with Eq. (2) we conclude that with probability 1 \u2212 \u03b4, err(S0, h\u0302) \u2264 \u03b7max(1 + 5\u03bd). Since \u03bd = \u03b1/5, this proves the lemma.\nThe auditing complexity of Alg. 2 is at most the auditing complexity of step 6, which is O(ln(1/\u03b4)) by Lemma A.3, plus mag(\u03bd/72, \u03b4/2, 1) = O(ln(1/\u03b4)/\u03bd2)O(ln(1/\u03b4)/\u03b12). Thus the total auditing complexity is also O(ln(1/\u03b4)/\u03b12). Proof of Theorem 3.5. Fix \u03b7min and define \u03b2 = \u03b1+ 1. Assume without loss of generality that the algorithm returns a hypothesis h\u0302 after having queried exactly M negative labels. We will define a finite set of distributions such that if the algorithm emits a correct answer for all of them, then the given lower bound on M must hold.\nWe consider distributions with a uniform marginal over [0, 1], and define several conditional labeling distributions for points on [0, 1]. First, we define the distribution D\u2212, which assigns \u22121 to all x \u2208 [0, 1\u22122\u03b7min]\u222a[1\u2212\u03b7min, 1], and +1 to x \u2208 (1\u22122\u03b7min, 1\u2212\u03b7min). Note that err(D\u2212,Ha) = \u03b7min, so the guarantee of the algorithm is that err(h\u0302, D\u2212) \u2264 \u03b2\u03b7min with probability 1\u2212 \u03b4. Thus for D\u2212 the algorithm produces a hypothesis h\u0302 = ha for some threshold value a \u2265 1 \u2212 (1 + \u03b2)\u03b7min with probability 1\u2212 \u03b4.\nSecond, we define a family of distributions D1, . . . , DN , for N = bln(1/2\u03b7\u03b2)/ ln(4\u03b2)c, such that for each Di, the algorithm cannot return ha with a \u2265 1\u2212 (\u03b2 + 1)\u03b7 with probability more than \u03b4.\nLet \u03bb = 1/8\u03b2. Define a0 = 1 \u2212 (1 + \u03b2)\u03b7min, and for i \u2208 [N ] define li = \u03b2(4\u03b2)i\u03b7min and ai = a0 \u2212 \u2211 j\u2264i lj . Define the distribution Di as follows (See Figure 2):\nPDi [Y = +1 | X = x] =  0 x \u2208 [0, ai] \u222a [ai\u22121, 1\u2212 2\u03b7min] \u222a [1\u2212 \u03b7min, 1] 1 x \u2208 (1\u2212 2\u03b7min, 1\u2212 \u03b7min) 1\u2212 \u03bb x \u2208 (ai, ai\u22121).\nThe distribution Di agrees with the distribution D\u2212 except on the interval (ai, ai\u22121), where it is positive with probability 1 \u2212 \u03bb and negative with probability \u03bb. We claim that if the algorithm returns a threshold greater than a0 on Di with probability more than \u03b4, it violates the (\u03b1, \u03b4)-learning\nguarantee. For a0, and \u03b2 \u2265 1,\nerr(Di, ha0) \u2265 (1\u2212 \u03bb)li > 7\n8 \u03b2(4\u03b2)i\u03b7min.\nFor ai,\nerr(Di, hai) = \u03b2\u03b7min + \u2211 j<i lj + \u03bbli\n=  i\u22121\u2211 j=0 \u03b2(4\u03b2)j + 1 8\u03b2 \u03b2(4\u03b2)i  \u03b7min Hence\nerr(Di, hai) = \u03b2 ( (4\u03b2)i \u2212 1 4\u03b2 \u2212 1 + 1 8 (4\u03b2)i ) \u03b7min\n< 7\n8 \u03b2(4\u03b2)i\n( 8\n7(4\u03b2 \u2212 1) +\n1\n7\n) \u03b7min\n< 7\n8 (4\u03b2)i.\nFrom this we can see that err(Di, ha0) > \u03b2err(Di, hai), violating the guarantee of the algorithm. It follows that for any i, if the true labeling is Di, then the probability that the algorithm returns ha for a \u2265 1\u2212 (\u03b2 + 1)\u03b7 is at most \u03b4. We now show that this implies a lower bound on M .\nFirst, since all distributions label [a0, 1] in the same way, we may assume without loss of generality that the algorithm never queries points in this segment. It follows that if the true distribution is D\u2212, the algorithm observes only negative labels.\nDenote by Yt the random variable whose value is the label the algorithm receives for its t\u2019th query, or 0 if the algorithm stopped before querying t points. Denote by Zt the random variable whose value is j if on round t, the algorithm queries a point in [aj , aj\u22121], and \u22121 if the algorithm stops before round t. Denote by At the event that \u2200i \u2208 [t], Yi = \u22121. Also denote ptj = P[Zt = j | At\u22121]. We will show a lower bound on P[AM ], that is the probability that all first M queries return a negative label. Since in this case the algorithm cannot distinguish Dj from D\u2212, this probability must be small, which implies a lower bound on M .\nBy definition, \u2211\nj\u2208[N ] p t j = 1 for all t \u2264 M . Thus, there exists some j \u2208 [N ] such that\u2211\nt\u2208[M ] p t j \u2264M/N . Fix j to one such value. Assume that the true labeling is Dj . Then\nP[A1] = \u03bbp1j + (1\u2212 p1j ) = 1\u2212 (1\u2212 \u03bb)p1j , P[At] = P[At\u22121]P[Yt = \u22121 | At\u22121] = P[At\u22121](1\u2212 (1\u2212 \u03bb)ptj).\nIt follows that if the true distribution is Dj , then P[AM ] = \u220f t\u2208[M ] (1\u2212 (1\u2212 \u03bb)ptj). We consider two kinds of indices t \u2208 [M ]. First let Ij = {t \u2208 [M ] | ptj > 1/2(1\u2212 \u03bb)}. Since\u2211 t\u2208[M ] p t j \u2264 M/N , we have |Ij | \u2264 2(1\u2212 \u03bb)M/N . For t \u2208 I we use the bound 1 \u2212 (1 \u2212 \u03bb)ptj \u2265 \u03bb.\nFor t /\u2208 I, we use the bound 1 \u2212 (1 \u2212 \u03bb)ptj \u2265 exp(\u22122(1 \u2212 \u03bb)ptj). This follows from the inequality exp(\u22122x) \u2264 1\u2212 x, which holds for x \u2208 [0, 12 ]. Combining the two cases, we get\nP[AM ] = \u220f i\u2208[M ] (1\u2212 (1\u2212 \u03bb)ptj) \u2265 exp\n( \u22122(1\u2212 \u03bb)\n\u2211 t/\u2208I ptj\n) \u03bb|I|\n\u2265 exp ( \u22122(1\u2212 \u03bb)M\nN\n) \u03bb2(1\u2212\u03bb)(M/N)\n= exp ( \u22122(1\u2212 \u03bb)M\nN (1 + ln(1/\u03bb))\n) . (4)\nThe algorithm must stop after seeing M negative labels, thus it must return an answer at time M if AM occurs. If the true distribution is D\u2212, then AM occurs with probability 1. Therefore, if AM occurs the algorithm must return ha for a \u2265 a0 with probability at least 1 \u2212 \u03b4. Thus, if the true distribution is Dj , the probability that the algorithm errs is at least P[AM ](1\u2212 \u03b4). Since the algorithm errs with probability at most \u03b4, we have\n\u03b4 \u2265 P[AM ](1\u2212 \u03b4),\nSolving for M using Eq. (4), we get\nM \u2265 N ln(1\u2212\u03b4\u03b4 )\n2(1\u2212 \u03bb)(1 + ln(1/\u03bb)) .\nTreating \u03b2, and hence \u03bb, as constants, we get that N \u2265 C ln(1/\u03b7min) \u2212 C \u2032, therefore M \u2265 C ln(1\u2212\u03b4\u03b4 ) ln(1/\u03b7min)\u2212 C \u2032 for some positive constants C,C \u2032."}, {"heading": "A.4 Proofs for Section 4", "text": "Here we gather proof details for the hypothesis class H2 and H\u22122 of axis-aligned rectangles."}, {"heading": "A.4.1 Proof of Theorem 4.4", "text": "Proof of Theorem 4.4. We will show that in the realizable case, an algorithm that returns h\u0302 such that \u2200\u03b4err(D, h\u0302) \u2264 requires \u2126(d/ ) labels. The statement of the theorem follows by adding an unavoidable error of \u03b7 to all distributions.\nWithout loss of generality, suppose d is even and 1/4 is an integer, and partition the d dimensions in d/2 pairs of coordinates {(1, 2), (3, 4), . . . , (d\u2212 1, d)}. For each coordinate pair (2i\u2212 1, 2i) choose 14 distinct points Si on the unit circle in the subspace spanned by the i and (i + 1)-th coordinates, as in the proof of Theorem 4.2. Consider distributions D with a uniform marginal over the points in S1, . . . , Sd/2, so that the probability of each point is 4 /d. Any distribution such that all points are labeled negative, except perhaps a single point in every Si, is realizable. To get err(D, h\u0302) \u2264 with probability more than half, the algorithm must find whether there is a positive point in at least half of the Si\u2019s.\nLet Ti be the number of points queried by the algorithm in set Si. If the total number of queries that the algorithm makes is less than d|Si|/16, then E[Ti] < |Si|/8 for at least half of the i\u2019s. If E[Ti] < |Si|/8 then with probability at least 1/2, Ti \u2264 1/4. Thus there exists a point in Si such that with probability at least 1/2 the algorithm does not query this point, and therefore cannot tell whether it is positive. It follows that the algorithm must make at least d|Si|/16 = \u2126(d/ ) queries on negative points.\nA.4.2 Approximation bounds for error on samples\nLemma A.4. Let H be a hypothesis class with VC dimension d \u2265 1, and let S be a sample of size m\u03bd( , \u03b4, d) drawn i.i.d. from a distribution D. With probability 1\u2212 \u03b4, \u2200h \u2208 H,\nerrneg(S, h) \u2264 errneg(D,h)J(1 + \u03bd), K and errneg(D,h) \u2264 errneg(S, h)J(1 + \u03bd), K.\nProof. Let f [h] : (Rd+ \u00d7 {\u22121,+1})\u2192 {\u22121,+1} such that f [h](x, y) = I[h(x) = 1 and y = \u22121]. For any distribution over Rd+\u00d7{\u22121,+1}, consider a distribution D\u2032 over (Rd+\u00d7{\u22121,+1})\u2192 {\u22121,+1} that draws ((X,Y ), Z) \u223c D\u2032 such that (X,Y ) is drawn from D and Z is deterministically 1. Then errneg(D,h) = err(D\n\u2032, f [h]). The VC-dimension of F = {f [h] | h \u2208 H} is at most that of H: Any set ((x1, y1), . . . , (xn, yn)) shattered by F must have yi = \u22121 for all i \u2208 [n]. Therefore \u2200h \u2208 H, f [h](xi, yi) = h(xi), hence x1, . . . , xd is shattered by H. The result follows by applying Eq. (1) to err(D\u2032, f [h])."}, {"heading": "A.4.3 Proof of Theorem 4.5", "text": "Theorem 4.5 is proven using several lemmas. We will need the following auxiliary result.\nLemma A.5. Let H be a hypothesis class of VC-dimension d, and let f [h1, h2] : (Rd+\u00d7{\u22121,+1})\u2192 {\u22121,+1} be the function f [h1, h2](x) = I[h1(x) = y or h2(x) = 1]. The VC-dimension of F = {f [h] | h \u2208 H} is at most 10d.\nProof. Let S = ((x1, y1), . . . , (xn, yn)) be a set shattered by F . Then |F|S | = 2n. In addition, |F|S | \u2264 |H|S \u00d7 H|S | \u2264 |H|S |2. By Sauer\u2019s lemma, |H|S | \u2264 (en/d)d. Therefore 2n \u2264 (en/d)2d. It follows that n \u2264 10d.\nThe next lemma will help prove that the set of hypotheses maintained by the algorithm includes the best hypothesis for the distribution.\nLemma A.6. Let \u03bd, > 0 and \u03b4 \u2208 (0, 1). Let S be a random labeled sample of size m\u03bd( , \u03b4, 10d) drawn from D . For b \u2208 Rd+, let Sb be identical to sample S except that if (x, y) \u2208 S and x \u2264 b, then (x,\u22121) \u2208 Sb instead of (x, y). Let h\u2217 \u2208 argminh\u2208H2 err(D,h), and let a \u2217 such that h\u2217 = ha\u2217. Let h\u0302b = argminh\u2208H2[b] err(Sb, h). Then \u2200 \u03b4, for all b \u2264 a\u2217,\nh\u2217 \u2208 V\u03bd(Sb, ,H2[b]), and err(D, h\u0302b) \u2264 err(D,h\u2217)J(1 + \u03bd)2, K.\nProof of Lemma A.6. For the first claim, it suffices to show that \u2200\u03b4, for all b \u2264 a\u2217,\nerr(Sb, h \u2217) \u2264 err(Sb, h\u0302b)J(1 + \u03bd)2, K. (5)\nDefine fa,b : Rd+ \u00d7 {\u22121,+1} \u2192 {\u22121,+1} such that fa,b(x, y) = I[ha(x) = y or hb(x) = \u22121]. Let S\u2032 = {((x, y), 1) | (x, y) \u2208 S}, and let D\u2032 be a distribution over (Rd+ \u00d7 {\u22121,+1}) \u00d7 {\u22121,+1} generated by drawing ((X,Y ), Z) \u223c D\u2032 where (X,Y ) \u223c D and Z = 1. Then S\u2032 is drawn i.i.d. from D\u2032. Note that for any a \u2265 b, ha classifies all points x \u2264 b as negative. It follows that there is some \u03bb > 0 such that for all a \u2265 b, \u03bb = err(D,ha)\u2212 err(D\u2032, fa,b).\nThe VC-dimension of F = {fa,b | a \u2265 b} is at most 10d (see Lemma A.5 in the appendix). Since |S\u2032| \u2265 m\u03bd( , \u03b4, 10d), \u2200\u03b4,\u2200f \u2208 F , err(S\u2032, f) \u2264 err(D\u2032, f)J1 + \u03bd, K and err(D\u2032, f) \u2264 err(S\u2032, f)J1 + \u03bd, K.\nLet a\u0302b \u2208 Rd+ such that h\u0302b = ha\u0302b . We have err(D,ha\u2217) \u2264 err(D,ha\u0302b), therefore err(D\u2032, fa\u2217,b) \u2264 err(D\u2032, ha\u0302b,b). Combining these inequalities and using Fact 1, we get\n\u2200\u03b4, \u2200b \u2208 Rd+, err(S\u2032, fa\u2217,b) \u2264 err(D\u2032, fa\u2217,b)J1 + \u03bd, K \u2264 err(D\u2032, fa\u0302b,b)J1 + \u03bd, K \u2264 err(S\u2032, fa\u0302b,b)J(1 + \u03bd)2, K.\nNoting that for a \u2265 b, err(S\u2032, fa,b) = err(Sb, ha), this proves Eq. (5). For the second claim,\n\u2200\u03b4,\u2200b \u2208 Rd+, err(D\u2032, fa\u0302b,b) \u2264 err(S \u2032, fa\u0302b,b)J1 + \u03bd, K\n\u2264 err(S\u2032, fa\u2217,b)J1 + \u03bd, K \u2264 err(D\u2032, fa\u2217,b)J(1 + \u03bd)2, K.\nDenoting \u03bb = err(D,ha\u2217)\u2212 err(D\u2032, fa\u2217,b) = err(D,ha\u0302b)\u2212 err(D\u2032, fa\u0302b,b), we get\nerr(D,ha\u0302b)\u2212 \u03bb \u2264 (err(D,ha\u2217)\u2212 \u03bb)J(1 + \u03bd)2, K.\nSince \u03bb > 0, this implies err(D,ha\u0302b) \u2264 err(D,ha\u2217)J(1 + \u03bd)2, K. The following lemma shows that \u03b7t is indeed an upper bound for the negative error of the best hypothesis.\nLemma A.7. If the algorithm reaches round T , then \u2200\u03b4, \u2200t \u2264 T, \u2200h\u2217 \u2208 argminh\u2208H2 err(D,h), the following claims hold:\n\u2022 Claim A(t): errneg(D,h\u2217) \u2264 \u03b7t.\n\u2022 Claim B(t): h\u2217 \u2208 Vt, where Vt is defined in step 15 of Algorithm 3\n\u2022 Claim C(t): errneg(D,h\u2217) \u2264 \u03b7\u0302tJ1 + \u03bd, \u03b7tK.\nProof of Lemma A.7. We will prove the claims by induction on t. At each round t \u2264 T \u2264 1/ log2(1/\u03b7min), |St| \u2265 m(\u03b7t, \u03b4/ log2(1/\u03b7min), d), thus \u2200\u03b4, uniform convergence as stated in Eq. (1) holds for all rounds simultaneously. We assume this for the rest of the proof .\nFirst, claim A(0) trivially holds since \u03b70 = 1. It is also easy to see that if claim C(t) holds, and the algorithm reaches round t+1, then claim A(t+1) holds: If Alg. 3 reached round t+1, then the condition in step 17 failed at time t, meaning \u03b7\u0302t \u2264 \u03b7t/4. By C(t), errneg(D,h\u2217) \u2264 \u03b7\u0302tJ1 + \u03bd, \u03b7tK \u2264 \u03b7t/2 = \u03b7t+1 (since \u03bd \u2264 1), which proves A(t+ 1).\nWe have left to show that claim A(t) implies claims C(t) and B(t). Assume that A(t) holds. First, suppose not all the points in St are queried. To prove B(t), note that errneg(St, h\n\u2217) \u2264 errneg(D,h\n\u2217)J1 + \u03bd, \u03b7tK. Since errneg(D,h\u2217) \u2264 \u03b7t, this implies an upper bound errneg(St, h\u2217) \u2264 (1 + \u03bd)\u03b7t.\nWe now show that h\u2217 \u2208 H2[bt]. If all the points in St are queried, then bt is the zero vector, thus H2[bt] = H2 and h\u2217 \u2208 H2[bt]. If not all the points in St are queried, then the algorithm queried more than (1 + \u03bd)\u03b7t|St| negative points in each direction, thus at least one of those points is labeled negative by h\u2217. The smallest value of coordinate i queried in iteration i of round t is bt[i]. Therefore the threshold of h \u2217 in direction i is at most bt[i]. This implies h \u2217 \u2208 H2[bt] and\nfurthermore that h\u2217 = ha\u2217 for some a \u2217 \u2265 bt. By Lemma A.6, h\u2217 \u2208 V\u03bd(Sbt , 4, ,H2[bt]) = Vt. This proves B(t). For C(t), note that \u03b7\u0302t = maxh\u2208Vt errneg(Sbt , h), hence byB(t), \u03b7\u0302t \u2265 errneg(Sbt , h\u2217) = errneg(St, h\u2217). The claim follows since errneg(D,h \u2217) \u2264 errneg(St, h\u2217)J1 + \u03bd, \u03b7tK.\nThe last lemma provides a the stopping condition of the algorithm.\nLemma A.8. If err(D,H) > \u03b7min then \u2200\u03b4 the algorithm stops at round at least log2(1/8err(D,H)).\nProof. Let T = log2(1/8err(D,H)). We show that \u2200\u03b4 the algorithm does not stop at any t \u2264 T , by showing that the condition in step 17 does not hold, that is \u03b7\u0302t = maxh\u2208Vt errneg(Sbt , h) \u2264 \u03b7t/4. By Lemma A.7, claim B(t), h\u2217 \u2208 Vt. Therefore, by definition of Vt, for all h \u2208 Vt,\nerrneg(Sbt , h) \u2264 err(Sbt , h) \u2264 err(Sbt , h\u2217)J(1 + \u03bd)2, \u03b7tK \u2264 err(St, h\u2217)J(1 + \u03bd)2, \u03b7tK.\nDue to the size of St we also have \u2200\u03b4,\u2200t \u2264 T, err(St, h\u2217) \u2264 err(D,h\u2217)J1 + \u03bd, \u03b7tK. Combining these inequalities we get \u03b7\u0302t \u2264 err(D,h\u2217)J(1 + \u03bd)3, \u03b7tK. For t \u2264 T , err(D,h\u2217) \u2264 2\u2212t/8 = \u03b7t/8. \u03b7\u0302t \u2264 err(D,h\u2217)+((1+\u03bd3)\u22121)\u03b7t \u2264 \u03b7t(1/8+((1+\u03bd3)\u22121)). Since \u03bd \u2264 1/25, one can check that \u03b7\u0302t \u2264 \u03b7t/4.\nWe are finally ready to prove Theorem 4.5. Proof of Theorem 4.5. Let T be the round in which the algorithm returns h\u0302. The number of negative labels N observed by the algorithm satisfies\nN \u2264 T\u2211 t=0 d(1 + \u03bd)\u03b7t(dm\u03bd(\u03b7t, \u03b4/ log2(1/\u03b7min), 10d)e+ 1)\nBy the definition on page 2, m\u03bd(\u03b7, \u03b4, d) = C(d ln(c/\u03bd\u03b7) + ln(c/\u03b4))/\u03bd 2\u03b7. Also 1 + \u03bd \u2264 2. Therefore\nN \u2264 C(T + d \u03bd2 T\u2211 t=0 (d ln(c/\u03bd\u03b7t) + ln(c log2(1/\u03b7min)/\u03b4))\n\u2264 Cd(d T\u2211 t=0 ln(c/\u03bd\u03b7t) + T ln(c ln(1/\u03b7min)/\u03b4)).\nWe have \u2211T t=0 ln(c/\u03b7t) \u2264 C \u2211T\nt=0 t+ C \u2264 CT 2 + C. In addition, T \u2264 log2(1/\u03b7min). Therefore the algorithm observes at most Cd2 ln2(1/\u03b7min) ln(c/\u03bd\u03b4)/\u03bd\n2 negative examples. Since \u03bd = \u03b1/25, we get the same auditing complexity for \u03b1.\nFor the second part of the theorem, by Lemma A.7, \u2200\u03b4 argminh\u2208H2 err(D,h) \u2208 VT = V (SbT , \u03b7T ,H2[bT ]). Therefore, by Lemma A.6, err(D, h\u0302) \u2264 err(D,H2)J(1 + \u03bd)2, \u03b7T K. By Lemma A.8, we have that T \u2265 min{log2(1/8err(D,H), log2(1/2\u03b7min)}, and therefore \u03b7T \u2264 max{8err(D,H2), 2\u03b7min}. It follows that\n\u2200\u03b4 err(D, h\u0302) \u2264 max {\n(1 + \u03bd)2err(D,H2), err(D,H2) + ((1 + \u03bd)2 \u2212 1) \u00b7max{8err(D,H2), 2\u03b7min} } \u2264 max{(1 + 8((1 + \u03bd)2 \u2212 1))err(D,H2), err(D,H2) + 2((1 + \u03bd)2 \u2212 1)\u03b7min\n} \u2264 err(D,H2)J(1 + 8((1 + \u03bd)2 \u2212 1)), \u03b7minK.\nNow, since \u03bd \u2264 1 and \u03bd = \u03b1/25, we have 8((1 + \u03bd)2 \u2212 1) = 8(2\u03bd + \u03bd2) \u2264 24\u03bd \u2264 \u03b1. The statement of the theorem immediately follows."}, {"heading": "A.5 Proofs for Section 5", "text": "Proof of Theorem 5.1. Assume without loss of generality that H|S = H. For an algorithm A, let QkA,h = (q 1 A,h, . . . , q k A,h) be the sequence of first k queries the algorithm makes if h is the true hypothesis. QA,h stands for the entire sequence until the algorithm stops with V (QA,h, h) = {h}. Denote by \u25e6 the concatenation of two sequences. Let cost(Q, h) be the total cost of a set or sequence of queries Q if the true hypothesis is h. For a set of points X \u2286 X and a hypothesis h \u2208 H, let V (X,h) be the set of hypotheses that are consistent with the labeling of h on X, that is V (X,h) = {g \u2208 H | \u2200x \u2208 S, g(x) = h(x)}.\nBy definition, there exists an algorithm A such that for any h \u2208 H, cost(QA,h) \u2264 OPTcost. Denote OPTcost by OPT for brevity. Now, consider a greedy algorithm B. If h is the true hypothesis then after k queries, the version space is V (QkB,h, h). Consider running A after executing QkB,h. Let the hypothesis h\u0304 \u2208 V (QkB,h, h) be such that for every length of sub-sequence n \u2264 |QA,h\u0304|, and for every y \u2208 Y,\n|V (QkB,h \u25e6Q n\u22121 A,h\u0304 , h\u0304) \\ V (Q k B,h \u25e6QnA,h\u0304, h\u0304)|\ncost(qnA,h\u0304, h\u0304(q n A,h\u0304))\n\u2264 |V (QkB,h \u25e6Q n\u22121 A,h\u0304 , g) \\ V (Q k B,h \u25e6QnA,h\u0304, g)|\ncost(qnA,h\u0304, y) , (6)\nwhere g is equal to h\u0304 on QkB,h \u25e6Q n\u22121 A,h\u0304 but labels q n A,h\u0304 differently. Such a hypothesis clearly exists if there are two possible labels: it can be found by selecting, at each iteration, the hypothesis with the label for qnA,h\u0304 that would incur the smaller ratio.\nBy the definition of OPT,\n|QA,h\u0304|\u2211 n=1 cost(qnA,h\u0304, h\u0304) = cost(QA,h\u0304) \u2264 OPT.\nAlso |V (QkB,h \u25e6QA,h\u0304, h\u0304)| = 1. Therefore\n|QA,h\u0304|\u2211 n=1 |V (QkB,h \u25e6Qn\u22121A,h\u0304 , h\u0304) \\ V (Q k B,h \u25e6QnA,h\u0304, h\u0304)| = |V (Q k B,h, h\u0304) \\ V (QkB,h \u25e6QA,h\u0304, h\u0304)|\n= |V (QkB,h, h\u0304)| \u2212 1 = |V (QkB,h, h)| \u2212 1.\nIt follows that there exists at least one n such that\n|V (QkB,h \u25e6Q n\u22121 A,h\u0304 , h\u0304) \\ V (Q k B,h \u25e6QnA,h\u0304, h\u0304)|\ncost(qnA,h\u0304, h\u0304) \u2265 |V (QkB,h, h)| \u2212 1 OPT .\nMoreover, for this n, due to Eq. (6),\nmin y\u2208Y\n|V (QkB,h \u25e6Q n\u22121 A,h\u0304 , g) \\ V (Q k B,h \u25e6QnA,h\u0304, g)|\ncost(qnA,h\u0304, y) \u2265 |V (QkB,h, h)| \u2212 1 OPT .\nIt follows that\nmin y\u2208Y |V (QkB,h, g) \\ V (QkB,h \u25e6 qnA,h\u0304, g)| cost(qnA,h\u0304, y) \u2265 |V (QkB,h, h)| \u2212 1 OPT .\nTherefore, the query qk+1B,h , selected by the greedy algorithm at step k + 1, satisfies\n|V (QkB,h, h) \\ V (Q k+1 B,h , h)| cost(qk+1B,h , h) \u2265 |V (QkB,h, h)| \u2212 1 OPT .\nIt follows that cost(qk+1B,h , h) \u2264 OPT. In addition, it follows that\n|V (Qk+1B,h , h)| \u2212 1 \u2264 (|V (Q k B,h, h)| \u2212 1)(1\u2212 cost(qk+1B,h , h)/OPT)\n\u2264 (|V (QkB,h, h)| \u2212 1) exp(\u2212cost(qk+1B,h , h)/OPT).\nThis analysis holds for every length k of a sub-sequence QB,h. Therefore by induction\n|V (QkB,h, h)| \u2212 1 \u2264 (|H| \u2212 1) k\u220f i=1 exp(\u2212cost(qiB,h, h)/OPT)\n= (|H| \u2212 1) exp(\u2212cost(QkB,h, h)/OPT).\nB terminates at the minimal k such that |V (QkB,h, h)| \u2212 1 < 1. This holds for any k such that exp(\u2212cost(QkB,h, h)/OPT) < 1/(|H|\u2212 1), which means cost(QkB,h, h) > ln(|H|\u2212 1) \u00b7OPT. Let k\u2032 be the minimal integer that satisfies this inequality. Then cost(Qk\n\u2032\u22121 B,h , h) \u2264 ln(|H| \u2212 1) \u00b7 OPT. Since\ncost(qk \u2032 B,h, h) \u2264 OPT, it follows that cost(Qk \u2032 B,h, h) \u2264 (ln(|H|\u2212 1) + 1) \u00b7OPT. This analysis holds for any h \u2208 H, thus the worst-case cost of the greedy algorithm is at most (ln(|H| \u2212 1) + 1) \u00b7OPT."}], "references": [{"title": "Agnostic active learning", "author": ["M.F. Balcan", "A. Beygelzimer", "J. Langford"], "venue": "In Proceedings of the 23rd international conference on Machine learning (ICML),", "citeRegEx": "Balcan et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Balcan et al\\.", "year": 2006}, {"title": "Rademacher and Gaussian complexities: Risk bounds and structural results", "author": ["P.L. Bartlett", "S. Mendelson"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Bartlett and Mendelson.,? \\Q2002\\E", "shortCiteRegEx": "Bartlett and Mendelson.", "year": 2002}, {"title": "The Theory of Probabilities", "author": ["S. Bernstein"], "venue": "Gastehizdat Publishing House, Moscow,", "citeRegEx": "Bernstein.,? \\Q1946\\E", "shortCiteRegEx": "Bernstein.", "year": 1946}, {"title": "Importance weighted active learning", "author": ["A. Beygelzimer", "S. Dasgupta", "J. Langford"], "venue": "In Proceedings of the 26th Annual International Conference on Machine Learning (ICML),", "citeRegEx": "Beygelzimer et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Beygelzimer et al\\.", "year": 2009}, {"title": "Regret minimizing audits: A learning-theoretic basis for privacy protection", "author": ["J. Blocki", "N. Christin", "A. Dutta", "A. Sinha"], "venue": "In Proceedings of 24th IEEE Computer Security Foundations Symposium,", "citeRegEx": "Blocki et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Blocki et al\\.", "year": 2011}, {"title": "Learnability and the VapnikChervonenkis dimension", "author": ["A. Blumer", "A. Ehrenfeucht", "D. Haussler", "M.K. Warmuth"], "venue": "J. ACM,", "citeRegEx": "Blumer et al\\.,? \\Q1989\\E", "shortCiteRegEx": "Blumer et al\\.", "year": 1989}, {"title": "Improving generalization with active learning", "author": ["D. Cohn", "L. Atlas", "R. Ladner"], "venue": "Machine Learning,", "citeRegEx": "Cohn et al\\.,? \\Q1994\\E", "shortCiteRegEx": "Cohn et al\\.", "year": 1994}, {"title": "Analysis of a greedy active learning strategy", "author": ["S. Dasgupta"], "venue": "Advances in neural information processing systems,", "citeRegEx": "Dasgupta.,? \\Q2004\\E", "shortCiteRegEx": "Dasgupta.", "year": 2004}, {"title": "A general agnostic active learning algorithm", "author": ["S. Dasgupta", "D. Hsu", "C. Monteleoni"], "venue": "Advances in Neural Information Processing Systems", "citeRegEx": "Dasgupta et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Dasgupta et al\\.", "year": 2008}, {"title": "Lower bounds in pattern recognition and learning", "author": ["L. Devroye", "G. Lugosi"], "venue": "Pattern recognition,", "citeRegEx": "Devroye and Lugosi.,? \\Q1995\\E", "shortCiteRegEx": "Devroye and Lugosi.", "year": 1995}, {"title": "Learning on the border: Active learning in imbalanced data classification", "author": ["\u015eeyda. Ertekin", "J. Huang", "L. Bottou", "C.L. Giles"], "venue": "In Proceedings of the ACM Sixteenth Conference on Information and Knowledge Management (CIKM", "citeRegEx": "Ertekin et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Ertekin et al\\.", "year": 2007}, {"title": "A threshold of ln n for approximating set cover", "author": ["U. Feige"], "venue": "Journal of the ACM (JACM),", "citeRegEx": "Feige.,? \\Q1998\\E", "shortCiteRegEx": "Feige.", "year": 1998}, {"title": "Adaptive submodularity: Theory and applications in active learning and stochastic optimization", "author": ["D. Golovin", "A. Krause"], "venue": "Journal of Artificial Intelligence Research,", "citeRegEx": "Golovin and Krause.,? \\Q2011\\E", "shortCiteRegEx": "Golovin and Krause.", "year": 2011}, {"title": "Efficient active learning of halfspaces: an aggressive approach", "author": ["A. Gonen", "S. Sabato", "S. Shalev-Shwartz"], "venue": "In The 30th International Conference on Machine Learning (ICML),", "citeRegEx": "Gonen et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Gonen et al\\.", "year": 2013}, {"title": "A bound on the label complexity of agnostic active learning", "author": ["S. Hanneke"], "venue": "In Proceedings of the 24th international conference on Machine learning,", "citeRegEx": "Hanneke.,? \\Q2007\\E", "shortCiteRegEx": "Hanneke.", "year": 2007}, {"title": "Teaching dimension and the complexity of active learning. In Learning Theory, pages 66\u201381", "author": ["S. Hanneke"], "venue": null, "citeRegEx": "Hanneke.,? \\Q2007\\E", "shortCiteRegEx": "Hanneke.", "year": 2007}, {"title": "Rates of convergence in active learning", "author": ["S. Hanneke"], "venue": "The Annals of Statistics,", "citeRegEx": "Hanneke.,? \\Q2011\\E", "shortCiteRegEx": "Hanneke.", "year": 2011}, {"title": "Learning from imbalanced data", "author": ["H. He", "E.A. Garcia"], "venue": "IEEE Transactions on Knowledge and Data Engineering,", "citeRegEx": "He and Garcia.,? \\Q2009\\E", "shortCiteRegEx": "He and Garcia.", "year": 2009}, {"title": "Probability inequalities for sums of bounded random variables", "author": ["W. Hoeffding"], "venue": "Journal of the American Statistical Association,", "citeRegEx": "Hoeffding.,? \\Q1963\\E", "shortCiteRegEx": "Hoeffding.", "year": 1963}, {"title": "Constructing optimal binary decision trees is NP-complete", "author": ["L. Hyafil", "R.L. Rivest"], "venue": "Information Processing Letters,", "citeRegEx": "Hyafil and Rivest.,? \\Q1976\\E", "shortCiteRegEx": "Hyafil and Rivest.", "year": 1976}, {"title": "Selective supervision: Guiding supervised learning with decision-theoretic active learning", "author": ["A. Kapoor", "E. Horvitz", "S. Basu"], "venue": "In Proceedings of IJCAI,", "citeRegEx": "Kapoor et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Kapoor et al\\.", "year": 2007}, {"title": "Efficient noise-tolerant learning from statistical queries", "author": ["M. Kearns"], "venue": "Journal of the ACM (JACM),", "citeRegEx": "Kearns.,? \\Q1998\\E", "shortCiteRegEx": "Kearns.", "year": 1998}, {"title": "Rademacher complexities and bounding the excess risk of active learning", "author": ["V. Koltchinskii"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Koltchinskii.,? \\Q2010\\E", "shortCiteRegEx": "Koltchinskii.", "year": 2010}, {"title": "Active learning using arbitrary binary valued queries", "author": ["S.R. Kulkarni", "S.K. Mitter", "J.N. Tsitsiklis"], "venue": "Machine Learning,", "citeRegEx": "Kulkarni et al\\.,? \\Q1993\\E", "shortCiteRegEx": "Kulkarni et al\\.", "year": 1993}, {"title": "On the uniform convergence of relative frequencies of events", "author": ["V.N. Vapnik", "A.Y. Chervonenkis"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Vapnik and Chervonenkis.,? \\Q2001\\E", "shortCiteRegEx": "Vapnik and Chervonenkis.", "year": 2001}], "referenceMentions": [{"referenceID": 20, "context": "Existing work on active learning with costs (Margineantu, 2007; Kapoor et al., 2007; Settles et al., 2008; Golovin and Krause, 2011) typically assumes that the cost of labeling each point is known a priori, so the algorithm can use the costs directly to select a query.", "startOffset": 44, "endOffset": 132}, {"referenceID": 12, "context": "Existing work on active learning with costs (Margineantu, 2007; Kapoor et al., 2007; Settles et al., 2008; Golovin and Krause, 2011) typically assumes that the cost of labeling each point is known a priori, so the algorithm can use the costs directly to select a query.", "startOffset": 44, "endOffset": 132}, {"referenceID": 11, "context": ", 2008; Golovin and Krause, 2011) typically assumes that the cost of labeling each point is known a priori, so the algorithm can use the costs directly to select a query. Our model is significantly different, as the costs depend on the outcome of the query itself. Kapoor et al. (2007) do mention the possibility of class-dependent costs, but this possibility is not studied in detail.", "startOffset": 8, "endOffset": 286}, {"referenceID": 4, "context": "An unrelated game-theoretic learning model addressing \u201cauditing\u201d was proposed by Blocki et al. (2011).", "startOffset": 81, "endOffset": 102}, {"referenceID": 1, "context": "If a sample S is drawn from D with |S| = mag( , \u03b4, d) then with probability 1 \u2212 \u03b4, \u2200h \u2208 H, err(D,h) \u2264 err(S, h) + and err(S,H) \u2264 err(D,H)+ (Bartlett and Mendelson, 2002).", "startOffset": 139, "endOffset": 169}, {"referenceID": 1, "context": "If a sample S is drawn from D with |S| = mag( , \u03b4, d) then with probability 1 \u2212 \u03b4, \u2200h \u2208 H, err(D,h) \u2264 err(S, h) + and err(S,H) \u2264 err(D,H)+ (Bartlett and Mendelson, 2002). Let m\u03bd( , \u03b4, d) = C(d ln(c/\u03bd )+ln(c/\u03b4))/\u03bd2 . Results of Vapnik and Chervonenkis (1971) show that if H has VC dimension d and S is drawn from D with |S| = m\u03bd , then for all h \u2208 H, err(S, h) \u2264 max {err(D,h)(1 + \u03bd), err(D,h) + \u03bd } and (1) err(D,h) \u2264 max {err(S, h)(1 + \u03bd), err(S, h) + \u03bd } .", "startOffset": 140, "endOffset": 258}, {"referenceID": 3, "context": "In particular, a simple adaptation of a result of Beygelzimer et al. (2009) establishes the following lower bound.", "startOffset": 50, "endOffset": 76}, {"referenceID": 9, "context": "1 an auditing complexity of \u03a9(d/\u03b12) is unavoidable, be we can hope to improve over the passive sample complexity lower bound of \u03a9(d/\u03b7\u03b12) (Devroye and Lugosi, 1995) by avoiding the dependence on \u03b7.", "startOffset": 137, "endOffset": 163}, {"referenceID": 16, "context": "For active learning, it has been shown that in some cases, the \u03a9(d/\u03b7) passive sample complexity can be replaced by an exponentially smaller O(d ln(1/\u03b7)) active label complexity (Hanneke, 2011), albeit sometimes with a larger polynomial dependence on d.", "startOffset": 177, "endOffset": 192}, {"referenceID": 23, "context": "For thresholds, active learning requires \u03a9(ln(1/\u03b7)) labels (Kulkarni et al., 1993).", "startOffset": 59, "endOffset": 82}, {"referenceID": 23, "context": "Due to information-theoretic considerations, any algorithm which learns an unlabeled pool S has an active label complexity of at least log2 |H|S | (Kulkarni et al., 1993), where H|S is the set of restrictions of functions in H to the domain S.", "startOffset": 147, "endOffset": 170}, {"referenceID": 21, "context": "(1989), has been studied extensively in different regimes (Kearns, 1998; Long and Tan, 1998), including active learning (Hanneke, 2007b).", "startOffset": 58, "endOffset": 92}, {"referenceID": 5, "context": "This hypothesis class, first introduced in Blumer et al. (1989), has been studied extensively in different regimes (Kearns, 1998; Long and Tan, 1998), including active learning (Hanneke, 2007b).", "startOffset": 43, "endOffset": 64}, {"referenceID": 7, "context": "The construction is a simple adaptation of a construction due to Dasgupta (2004), originally showing an active learning lower bound for the class of hyperplanes.", "startOffset": 65, "endOffset": 81}, {"referenceID": 6, "context": "The idea of iteratively refining a set of possible hypotheses has been used in a long line of active learning works (Cohn et al., 1994; Balcan et al., 2006; Hanneke, 2007a; Dasgupta et al., 2008).", "startOffset": 116, "endOffset": 195}, {"referenceID": 0, "context": "The idea of iteratively refining a set of possible hypotheses has been used in a long line of active learning works (Cohn et al., 1994; Balcan et al., 2006; Hanneke, 2007a; Dasgupta et al., 2008).", "startOffset": 116, "endOffset": 195}, {"referenceID": 8, "context": "The idea of iteratively refining a set of possible hypotheses has been used in a long line of active learning works (Cohn et al., 1994; Balcan et al., 2006; Hanneke, 2007a; Dasgupta et al., 2008).", "startOffset": 116, "endOffset": 195}, {"referenceID": 19, "context": "This can be shown by a reduction to set-cover (Hyafil and Rivest, 1976).", "startOffset": 46, "endOffset": 71}, {"referenceID": 13, "context": "This approach has also been shown to provide considerable performance gains in practical settings (Gonen et al., 2013).", "startOffset": 98, "endOffset": 118}, {"referenceID": 12, "context": "For active learning, and for query costs that do not depend on the true hypothesis (that is cost(x, h) \u2261 cost(x)), Golovin and Krause (2011) showed an efficient greedy strategy that achieves a cost of O(OPTcost(S) \u00b7 ln(|H|)) for any S.", "startOffset": 115, "endOffset": 141}, {"referenceID": 11, "context": "Nonetheless, hardness of approximation results for set cover (Feige, 1998), in conjunction with the reduction to set cover of Hyafil and Rivest (1976) mentioned above, imply that such an approximation factor cannot be avoided for a general auditing algorithm.", "startOffset": 61, "endOffset": 74}, {"referenceID": 11, "context": "Nonetheless, hardness of approximation results for set cover (Feige, 1998), in conjunction with the reduction to set cover of Hyafil and Rivest (1976) mentioned above, imply that such an approximation factor cannot be avoided for a general auditing algorithm.", "startOffset": 62, "endOffset": 151}, {"referenceID": 7, "context": "First, it is known that for some hypothesis classes, active learning cannot improve over passive learning for certain distributions (Dasgupta, 2004), and the same is true for auditing.", "startOffset": 132, "endOffset": 148}, {"referenceID": 0, "context": "However, exponential speedups are possible for active learning on certain classes of distributions (Balcan et al., 2006; Dasgupta et al., 2008), in particular ones with a small disagreement coefficient (Hanneke, 2007a).", "startOffset": 99, "endOffset": 143}, {"referenceID": 8, "context": "However, exponential speedups are possible for active learning on certain classes of distributions (Balcan et al., 2006; Dasgupta et al., 2008), in particular ones with a small disagreement coefficient (Hanneke, 2007a).", "startOffset": 99, "endOffset": 143}, {"referenceID": 22, "context": "This quantity is related to the Alexander capacity function (Koltchinskii, 2010), which appears in lower bounds for active learning (Raginsky and Rakhlin, 2011).", "startOffset": 60, "endOffset": 80}, {"referenceID": 7, "context": "It is well known that for some important settings, such as learning with hyperplanes, there are distributions which resist any improvement using active learning (Dasgupta, 2004).", "startOffset": 161, "endOffset": 177}, {"referenceID": 0, "context": "However, exponential speedups are possible for active learning on certain classes of distributions (Balcan et al., 2006; Dasgupta et al., 2008), in particular ones with a small disagreement coefficient (Hanneke, 2007a). This quantity is related to the Alexander capacity function (Koltchinskii, 2010), which appears in lower bounds for active learning (Raginsky and Rakhlin, 2011). It would be interesting if a similar property of the distribution can guarantee an improvement with auditing over active or passive learning. Investigating such a general property might shed light on auditing for other important hypothesis classes such as decision trees or halfspaces. It is well known that for some important settings, such as learning with hyperplanes, there are distributions which resist any improvement using active learning (Dasgupta, 2004). Recent work by Gonen et al. (2013) has shown that both theoretically and empirically, more aggressive learning strategies can be effective in the realizable case.", "startOffset": 100, "endOffset": 882}, {"referenceID": 10, "context": "Some of these approaches (Ertekin et al., 2007) use the same active learning heuristics (Tong and Koller, 2001), and it would be interesting to see how these apply to auditing.", "startOffset": 25, "endOffset": 47}, {"referenceID": 16, "context": "Prior work on learning from unbalanced data was surveyed by He and Garcia (2009). Some of these approaches (Ertekin et al.", "startOffset": 60, "endOffset": 81}, {"referenceID": 18, "context": "1 (Hoeffding\u2019s Inequality (Hoeffding, 1963)).", "startOffset": 26, "endOffset": 43}, {"referenceID": 2, "context": "2 (Bernstein\u2019s Inequality (Bernstein, 1946)).", "startOffset": 26, "endOffset": 43}], "year": 2015, "abstractText": "We propose a learning setting in which unlabeled data is free, and the cost of a label depends on its value, which is not known in advance. We study binary classification in an extreme case, where the algorithm only pays for negative labels. Our motivation are applications such as fraud detection, in which investigating an honest transaction should be avoided if possible. We term the setting auditing, and consider the auditing complexity of an algorithm: the number of negative labels the algorithm requires in order to learn a hypothesis with low relative error. We design auditing algorithms for simple hypothesis classes (thresholds and rectangles), and show that with these algorithms, the auditing complexity can be significantly lower than the active label complexity. We also discuss a general competitive approach for auditing and possible modifications to the framework.", "creator": "LaTeX with hyperref package"}}}