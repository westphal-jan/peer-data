{"id": "1307.0253", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "1-Jul-2013", "title": "Exploratory Learning", "abstract": "In multiclass semi-supervised learning (SSL), it is sometimes the case that the number of classes present in the data is not known, and hence no labeled examples are provided for some classes. In this paper we present variants of well-known semi-supervised multiclass learning methods that are robust when the data contains an unknown number of classes. In particular, we present an \"exploratory\" extension of expectation-maximization (EM) that explores different numbers of classes while learning them. To further address these issues we propose a combination of a special approach to EMC. This approach consists of a partial-model approach to EMC. Each class represents a set of parameters defined by a set of parameters in the input, and each represents a subset of the parameters in the output. The parameter is a type with a special value of at least 0 (where at least one class is not explicitly included in the input). Each class contains a unique (for example: a special value of at least one class is not explicitly included in the input). The parameters are the properties of the variables, and the parameters can be modified for each class in a way that permits the use of a parameter.\n\n\n\n\n\n\n\n\nIn this paper, we have implemented the concept of semantically-unspecified semantics: for example, an EMC can be assumed to be semantically-unspecified because of its use of a given parameter, and the parameters can be assigned to the variables that are non-semantically-unspecified, and the parameters can be assigned to the variables that are non-semantically-unspecified, and the parameters can be assigned to the variables that are non-semantically-unspecified, and the parameters can be assigned to the variables that are non-semantically-unspecified, and the parameters can be assigned to the variables that are non-semantically-unspecified, and the parameters can be assigned to the variables that are non-semantically-unspecified, and the parameters can be assigned to the variables that are non-semantically-unspecified, and the parameters can be assigned to the variables that are non-semantically-unspecified, and the parameters can be assigned to the variables that are non-semantically-unspecified, and the parameters can be assigned to the variables that are non-semantically-unspecified, and the parameters can be assigned to the variables that are non-semantically-unspecified, and the parameters can be assigned to the variables that", "histories": [["v1", "Mon, 1 Jul 2013 01:09:25 GMT  (825kb,D)", "http://arxiv.org/abs/1307.0253v1", "16 pages; European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases, 2013"]], "COMMENTS": "16 pages; European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases, 2013", "reviews": [], "SUBJECTS": "cs.LG", "authors": ["bhavana dalvi", "william w cohen", "jamie callan"], "accepted": false, "id": "1307.0253"}, "pdf": {"name": "1307.0253.pdf", "metadata": {"source": "CRF", "title": "Exploratory Learning", "authors": ["Bhavana Dalvi", "William W. Cohen", "Jamie Callan"], "emails": ["callan}@cs.cmu.edu"], "sections": [{"heading": "1 Introduction", "text": "In multiclass semi-supervised learning (SSL), it is sometimes the case that the number of classes present in the data is not known. For example, consider the task of classifying noun phrases into a large hierarchical set of categories such as \u201cperson\u201d, \u201corganization\u201d, \u201csports team\u201d, etc., as is done in broad-domain information extraction systems (e.g., [5]). A sufficiently large corpus will certainly contain some unanticipated natural clusters\u2014e.g., kinds of musical scales, or types of dental procedures. Hence, it is unrealistic to assume some examples have been provided for each class: a more plausible assumption is that an unknown number of classes exist in the data, and that labeled examples have been provided for some subset of these classes.\nThis raises the natural question: how robust are existing SSL methods to unanticipated classes? As we will show experimentally below, SSL methods can perform quite poorly in this setting: the instances of the unanticipated classes might be forced into one or more of the expected classes, leading to a cascade of errors in class parameters, and then to class assignments to other unlabeled examples. To address this problem, we present an \u201cexploratory\u201d extension of expectation-maximization (EM) which explores different numbers of classes while learning.\nMore precisely, in a traditional SSL task, the learner assumes a fixed set of classes C1, C2, . . . Ck, and the task is to construct a k-class classifier using labeled datapoints X l and unlabeled datapoints Xu, where X l contains a (usually small) set of \u201cseed\u201d examples of each class. In exploratory SSL, we assume the same inputs, but allow the classifier to predict labels from the set C1, . . . , Cm, where m \u2265 k: in other words, every example x may be predicted to be in either a known class Ci \u2208 C1 . . . Ck, or an unknown class Ci \u2208 Ck+1 . . . Cm.\nar X\niv :1\n30 7.\n02 53\nv1 [\ncs .L\nG ]\n1 J\nul 2\n01 3\nWe will show that exploratory SSL can greatly improve performance on nounphrase classification tasks and document classification tasks, for several well-known SSL methods. E.g. Figure 1 (b) top row shows, the confusion matrices for a traditional SSL method on a 20-class problem at the end of iteration 1 and 15, when the algorithm is presented with seeds for 6 of the classes. Here, red indicates overlap between classes, and dark blue indicates no overlap. So we see that many of the seed classes are getting confused with the unknown classes at the end of 15 iterations of SSL showing semantic drift. With the same inputs, our novel \u201cexploratory\u201d EM algorithm performs quite well (Figure 1 (b) bottom row); i.e. it introduces additional clusters and at the end of 15 iterations improves F1 on classes for which seed examples were provided.\nContributions. We focus on the novel problem of dealing with learning when only fraction of classes are known upfront, and there are unknown classes hidden in the data. We propose a variant of the EM algorithm where new classes can be introduced in each EM iteration. We discuss the connections of this algorithm to the structural EM algorithm. Next we propose two heuristic criteria for predicting when to create new class during an EM iteration, and show that these two criteria work well on three publicly available datasets. Further we evaluate third criterion, that introduces classes uniformly at random and show that our proposed heuristics are more effective than this baseline. Experimentally, Exploratory EM outperforms a semi-supervised variant of nonparametric Bayesian clustering (Gibbs sampling with Chinese Restaurant Process)\u2014a technique which also \u201cexplores\u201d different numbers of classes while learning. We also compare our method against a semi-supervised EM method withm extra classes (trying different values of m).\nIn this paper, Exploratory EM is instantiated to produce exploratory versions of three well-known SSL methods: semi-supervised Naive Bayes, seeded K-Means, and a seeded version of EM using a von Mises-Fisher distribution [1]. Our experiments focus on improving accuracy on the classes that do have seed examples\u2014i.e., the classes which are expected to be in the data.\nOutline. In Section 2, we first introduce an exploratory version of EM, and then discuss several instantiations of it, based on different models for the classifiers (mixtures of multinomials, K-Means, and mixtures of von Mises-Fisher distributions) and different approaches to introducing new classes. We then compare against an alternative exploratory SSL approach, namely Gibbs sampling with Chinese restaurant process [14]. Section 3 presents experimental results, followed by related work and conclusions."}, {"heading": "2 Exploratory SSL Methods", "text": ""}, {"heading": "2.1 A Generic Exploratory Learner", "text": "Many common approaches to SSL are based on EM. In a typical EM setting, the Mstep finds the best parameters \u03b8 to fit the data,X l\u222aXu, and the E-step probabilistically labels the unknown points with a distribution over the known classes C1, C2, . . . Ck. In some variants of EM, including the ones we consider here, a \u201chard\u201d assignment is made to classes instead, an approach named classification EM [6]. Our exploratory version of EM differs in that it can introduce new classes Ck+1 . . . Cm during the E-step.\nAlgorithm 1 EM algorithm for exploratory learning with model selection 1: function Exploratory EM (Xl, Y l, Xu, {C1 . . . Ck}): {Ck+1 . . . Cm}, \u03b8m, Y u 2: Input: Xl labeled data points; Y l labels for datapoints Xl; Xu unlabeled datapoints (same\nfeature space as Xl); {C1 . . . Ck} set of known classes to which x\u2019s belong. 3: Output: {Ck+1 . . . Cm} newly-discovered classes; {\u03b81, . . . , \u03b8m} parameters for all m\nclasses; Y u labels for unlabeled data points Xu\n{Initialize model parameters using labeled data} 4: \u03b810, . . . , \u03b8k0 = argmax\u03b8L(Xl, Y l|\u03b8k) 5: i is # new classes ; i = 0; CanAddClasses = true 6: while data likelihood not converged AND #classes not converged do {E step: (Iteration t) Make predictions for the unlabeled data-points} 7: iold = i; Compute baseline log-likelihood BaselineLL = logP (X|\u03b81t , . . . , \u03b8k+ioldt ) 8: for x \u2208 Xu do 9: Predict P (Cj |x, \u03b81t , . . . , \u03b8k+it ) for all labels 1 \u2264 j \u2264 k + i\n10: if nearlyUniform(P (C1|x), . . . , P (Ck+i|x)) AND CanAddClasses then 11: Increment i; Let Ck+i be the new class. 12: Label x with Ck+i in Y u, and compute parameters \u03b8k+it for the new class. 13: else 14: Assign x to (argmaxCjP (Cj |x)) in Y u where 1 \u2264 j \u2264 k + i 15: end if 16: end for 17: inew = i; Compute ExploreEM loglikelihood ExploreLL = logP (X|\u03b81t , . . . , \u03b8k+inewt ) {M step : Recompute model parameters using current assignments for Xu} 18: if Penalized data likelihood is better for exploratory model than baseline model then {Adopt the new model with k + inew classes} 19: \u03b8k+inewt+1 = argmax\u03b8L(X\nl, Y l, Xu, Y ut |\u03b8k+inew ) 20: else {Keep the old model with k + iold classes} 21: \u03b8k+ioldt+1 = argmax\u03b8L(X\nl, Y l, Xu, Y ut |\u03b8k+iold) 22: CanAddClasses = false 23: end if 24: end while 25: end function\nAlgorithm 1 presents a generic Exploratory EM algorithm (without specifying the model being used). There are two main differences between the algorithm and standard classification-EM approaches to SSL. First, in the E step, each of the unlabeled datapoint x is either assigned to one of the existing classes, or to a newly-created class. We will discuss the \u201cnearUniform\u201d routine below, but the intuition we use is that a new class should be introduced to hold x when the probability of x belonging to existing classes is close to uniform. This suggests that x is not a good fit to any existing classes, and that adding x to any existing class will lower the total data likelihood substantially. Second, in the M-step of iteration t, we choose either the model proposed by Exploratory EM method that might have more number of classes than previous iteration t\u2212 1 or the baseline version with same number of classes as iteration t\u2212 1. This choice is based on whether exploratory model satisfies a model selection criterion in terms of increased data likelihood and model complexity. If the algorithm decides that baseline\nmodel is better than exploratory model in iteration t, then from iteration t+ 1 onwards the algorithm won\u2019t introduce any new classes."}, {"heading": "2.2 Discussion", "text": "Friedman [13] proposed the Structural EM algorithm that combines the standard EM algorithm, which optimizes parameters, with structure search for model selection. This algorithm learns networks based on penalized likelihood scores, in the presence of missing data. In each iteration it evaluates multiple models based on the expected scores of models with missing data, and selects the model with best expected score. This algorithm converges at local maxima for penalized log likelihood (the score includes penalty for increased model complexity).\nSimilar to Structural EM, in each iteration of Algorithm 1, we evaluate two models, one with and one without adding extra classes. These two models are scored using a model selection criterion like AIC or BIC, and the model with best penalized data likelihood score is selected in each iteration. Further when the model selection criterion fails, the algorithm reverts to standard semi-supervised EM algorithm. Say this model switch happens at iteration tswitch, then from iteration 1 to tswitch, Algorithm 1 acts like the structural EM algorithm [13]. From iteration tswitch + 1 till the data likelihood converges, the algorithm acts as semi-supervised EM algorithm.\nNext let us discuss the applicability of this algorithm for clustering as well as classification tasks. Notice that Algorithm 1 reverts to an unsupervised clustering method if Xl is empty, and reverts to a supervised generative learner if Xu is empty. Likewise, if no new classes are generated, then it behaves as a multiclass SSL method; for instance, if the classes are well-separated and Xl contains enough labels for every class to approximate these classes, then it is unlikely that the criterion of nearly-uniform class probabilities will be met, and the algorithm reverts to SSL. Henceforth we will use the terms \u201cclass\u201d and \u201ccluster\u201d interchangeably."}, {"heading": "2.3 Model Selection", "text": "For model penalties we tried multiple well known criteria like BIC, AIC and AICc. Burnham and Anderson [4] have experimented with AIC criteria and proposed AICc for datasets where, the number of datapoints is less than 40 times number of features. The formulae for scoring a model using each of the three criteria that we tried are:\nBIC(g) = \u22122 \u2217 L(g) + v \u2217 ln(n) (1) AIC(g) = \u22122 \u2217 L(g) + 2 \u2217 v (2) AICc(g) = AIC(g) + 2 \u2217 v \u2217 (v + 1)/(n\u2212 v \u2212 1) (3)\nwhere g is the model being evaluated, L(g) is the log-likelihood of the data given g, v is the number of free parameters of the model and n is the number of data-points. While comparing two models, a lower value is preferred. The extended Akaike information criterion (AICc) suited best for our experiments since our datasets have large number of features and small number of data points. With AICc criterion, the objective function that Algorithm 1 optimizes is:\nmax m,{\u03b81...\u03b8m},m\u2265k\n{Log Data Likelihood\u2212Model penalty}\ni.e., max m,{\u03b81...\u03b8m},m\u2265k\n{logP (X|\u03b81, . . . , \u03b8m)} \u2212 {v + (v \u2217 (v + 1)/(n\u2212 v \u2212 1))} (4)\nHere, k is the number of seed classes given as input to the algorithm and m is the number of classes in the resultant model (m \u2265 k)."}, {"heading": "2.4 Exploratory versions of well-known SSL methods", "text": "In this section we will consider various SSL techniques, and propose exploratory extensions of these algorithms.\nSemi-Supervised Naive Bayes Nigam et al. [21] proposed an EM-based semi-supervised version of multinomial Naive Bayes. In this model P (Cj |x) \u221d P (x|Cj) \u2217 P (Cj), for each unlabeled point x. The probability P (x|Cj) is estimated by treating each feature in x as an independent draw from a class-specific multinomial. In document classification, the features are word occurrences, and the number of outcomes of the multinomial is the vocabulary size.\nThis method can be naturally used as an instance of Exploratory EM, using the multinomial model to compute P (Cj |x) in Line 1. The M step is also trivial, requiring only estimates of P (w|Cj) for each word/feature w.\nSeeded K-Means It has often been observed that K-Means and EM are algorithmically similar. Basu and Mooney [2] proposed a seeded version of K-Means, which is very analogous to Nigam et al\u2019s semi-supervised Naive Bayes, as another technique for semisupervised learning. Seeded K-Means takes as input a number of clusters, and seed examples for each cluster. The seeds are used to define an initial set of cluster centroids, and then the algorithm iterates between an \u201cE step\u201d (assigning unlabeled points to the closest centroid) and an \u201cM step\u201d (recomputing the centroids).\nIn the seeded K-Means instance of Exploratory EM, we again define P (Cj |x) \u221d P (x|Cj) \u2217 P (Cj), but define P (x|Cj) = x \u00b7 Cj , i.e., the inner product of a vector representing x and a vector representing the centroid of cluster j. Specifically, x and Cj both are represented as L1 normalized TFIDF feature vectors. The centroid of a new cluster is initialized with smoothed counts from x. In the \u201cM step\u201d, we recompute the centroids of clusters in the usual way.\nSeeded Von-Mises Fisher The connection between K-Means and EM is explicated by Banerjee et al. [1], who described an EM algorithm that is directly inspired by K-Means and TFIDF-based representations. In particular, they describe generative cluster models based on the von Mises-Fisher (vMF) distribution, which describes data distributed on the unit hypersphere. Here we consider the \u201chard-EM\u201d algorithm proposed by Banerjee et al, and use it in the seeded (semi-supervised) setting proposed by Basu et al. [2]. This natural extension of Banerjee et al[1]\u2019s work can be easily extended to our exploratory setting.\nAs in seeded K-Means, the parameters of vMF distribution are initialized using the seed examples for each known cluster. In each iteration, we compute the probability of Cj given data point x, using vMF distribution, and then assign x to the cluster for which this probability is maximized. The parameters of the vMF distribution for each cluster are then recomputed in the M step. For this method, we use a TFIDF-based L2 normalized vectors, which lie on the unit hypersphere.\nAlgorithm 2 JS criterion for new class creation 1: function JSCriterion([P (C1|x) . . . P (Ck|x)]): 2: Input: [P (C1|x) . . . P (Ck|x)] probability distribution of existing classes for a data point x 3: Output: decision : true iff new class needs to be created 4: u = [1/k . . . 1/k] {i.e., the uniform distribution with current number of classes = k} 5: decision = false 6: if Jensen-Shannon-Divergence(u, P (Cj |x)) < 1k then 7: decision = true 8: end if 9: end function\nAlgorithm 3 MinMax criterion for new class creation 1: function MinMaxCriterion([P (C1|x) . . . P (Ck|x)]): 2: Input: [P (C1|x) . . . P (Ck|x)] probability distribution of existing classes for a data point x 3: Output: decision : true iff new class needs to be created 4: k is the current number of classes 5: maxProb = max(P (Cj |x)); minProb = min(P (Cj |x)) 6: if maxProb\nminProb < 2 then\n7: decision = true 8: end if 9: end function\nSeeded vMF and seeded K-Means are closely related\u2014in particular, seeded vMF can be viewed as a more probabilistically principled version of seeded K-Means. Both methods allow use of TFIDF-based representations, which are often preferable to unigram representations for text: for instance, it is well-known that unigram representations often produce very inaccurate probability estimates."}, {"heading": "2.5 Strategies for inducing new clusters/classes", "text": "In this section we will formally describe some possible strategies for introducing new classes in the E step of the algorithm. They are presented in detail in Algorithms 2 and 3, and each of these is a possible implementation of the \u201cnearUniform\u201d subroutine of Algorithm 1. As noted above, the intuition is that new classes should be introduced to hold x when the probabilities of x belonging to existing classes are close to uniform. In the JS criterion, we require that Jensen-Shanon divergence1 between the posterior class distribution for x to the uniform distribution be less than 1k . The MinMax criterion is a somewhat simpler approximation to this intuition: a new cluster is introduced if the maximum probability is no more than twice the minimum probability."}, {"heading": "2.6 Baseline Methods", "text": "Next, we will take a look at various baseline methods that we implemented to measure the effectiveness of our proposed approach.\n1 The Jensen-Shannon divergence between p and q is the average Kullback-Leiber divergence of p and q to a, the average of p and q, i.e., 1\n2 (KL(p||a+KL(q||a)).\nAlgorithm 4 Exploratory Gibbs Sampling with Chinese Restaurant Process 1: function GibbsCRP (Xl, Y l, Xu, {C1 . . . Ck}) : Ck+1 . . . Cm, Y u 2: Input: Xl labeled data points; Y l labels of Xl; Xu unlabeled data points; {C1 . . . Ck} set of known classes x\u2019s belong to; Pnew probability of creating a new class.\n3: Output: Ck+1 . . . Cm newly-discovered classes; Y u labels for Xu 4: for x in Xu do 5: Save a random class from {C1 . . . Ck} for x in Y u 6: end for 7: Set m = k 8: for t : 1 to numEpochs do 9: for xi in Xu do\n10: Let yi\u2019s be xi\u2019s label in epoch t\u2212 1 11: predict P (Cj |xi, Y l \u222a Y u \u2212 {yi}) for all labels 1 \u2264 j \u2264 m 12: y\u2032i,m\n\u2032 = CRPPick(Pnew, P (C1|xi), . . . , P (Cm+1|xi)) 13: Save y\u2032i as xi\u2019s label in epoch t 14: m = m\u2032 15: end for 16: end for 17: end function\nRandom new class creation criterion: To measure the effectiveness of criteria proposed in Algorithms 2 and 3, we experimented with a random baseline criterion, that returns \u201ctrue\u201d uniformly at random with probability equal to that of MinMax or JS criterion returning true for the same dataset. This is referred to as Random criterion below.\nSemi-supervised EM with m extra classes: One might argue that the goal of the Exploratory EM algorithm can also be achieved by adding a random number of empty classes to the semi-supervised EM algorithm. We compare our method against the best possible value of this baseline, i.e. by choosing the number of classes that maximizes F1 on the seed classes. Note that in practice, the test labels are not available, so this is the upper bound on performance of this baseline. We compare our method with this upper bound in Section 3. Our method is different from this baseline in two ways. First, it does not need the number of extra clusters as input. Second, it seeds the extra clusters with those datapoints that are unlikely to belong to existing classes, as compared to initializing them randomly.\nA seeded Gibbs sampler with CRP: The Exploratory EM method is broadly similar to non-parametric Bayesian methods, such as the Chinese Restaurant process (CRP) [14]. CRP is often used in non-parametric models (e.g., topic models) that are based on Gibbs sampling, and indeed, since it is straightforward to replace EM with Gibbssampling, one can use this approach to estimate the parameters of any of the models considered here (i.e., multinomial Naive Bayes, K-Means, and the von Mises-Fisher distribution). Algorithm 4 presents a seeded version of a Gibbs sampler based on this idea. In brief, Algorithm 4, starts with a classifier trained on the labeled data. Collapsed Gibbs sampling is then performed over the latent labels of unlabeled data, incorporat-\nAlgorithm 5 Modified CRP criterion for new class creation 1: function ModCRPPick (Pnew, P (C1|x), . . . , P (Ck+i|x)) : y, i\u2032 2: Input: Pnew probability of creating new class; P (C1|x), . . . , P (Ck+i|x) probability of existing classes given x\n3: Output: y class for x; i\u2032 new number of classes 4: u = [1/k + i . . . 1/k + i] {uniform distribution with k + i classes} 5: d = Jensen-Shannon-Divergence(u, P (Cj |x)) 6: q = Pnew ((k+i)\u2217d) 7: if a coin with bias q is heads then {create a new class and assign to that} 8: y = k + i+ 1 and i\u2032 = i+ 1 9: else\n{assign to an existing class} 10: i\u2032 = i and y = sample from distribution [P (C1|x) . . . P (Ck|x)] 11: end if 12: end function\ning the CRP into the Gibbs sampling to introduce new classes. (In fact, we use block sampling for these variables, to make the method more similar to the EM variants.)\nNote that this algorithm is naturally \u201cexploratory\u201d, in our sense, as it can produce a number of classes larger than the number of classes for which seed labels exist. However, unlike our exploratory EM variants, the introduction of new classes is not driven by examples that are \u201chard to classify\u201d\u2014i.e., have nearly-uniform posterior probability of membership in existing classes. In CRP method, the probability of creating a new class depends on the data point, but it does not explicitly favor cases where the posterior over existing classes is nearly uniform.\nTo address this issue, we also implemented a variant of the seeded Gibbs sampler with CRP, in which the examples with nearly-uniform distributions are more likely to be assigned to new classes. This variant is shown in Algorithm 5, which replaces the routine CRPPick in the Gibbs sampler\u2014in brief, we simply scale down the probability of creating a new class by the Jensen-Shannon divergence of the posterior class distribution for x to the uniform distribution. Hence the probability of creating new class explicitly depends on how well the given data point fits in one of the existing classes. An experimental comparison of our proposed method with Gibbs sampling and CRP based baselines is shown in Section 3.2."}, {"heading": "3 Experimental Results", "text": "We now seek to experimentally answer the questions raised in the introduction. How robust are existing SSL methods, if they are given incorrect information about the number of classes present in the data, and seeds for only some of these classes? Do the exploratory versions of the SSL methods perform better? How does Exploratory EM compare with the existing \u201cexploratory\u201d method of Gibbs sampling with CRP?\nWe used three publicly available datasets for our experiments. The first is the widelyused 20-Newsgroups dataset [23]. We used the \u201cbydate\u201d dataset, which contains total of 18,774 text documents, with vocabulary size of 61,188. There are 20 non-overlapping\nclasses and the entire dataset is labeled. The second dataset is the Delicious Sports dataset, published by [9]. This is an entity classification dataset, which contains items extracted from 57K HTML tables in the sports domain (from pages that had been tagged by the social bookmarking system del.icio.us). The features of an entity are ids for the HTML table columns in which it appears. This dataset contains 282 labeled entities described by 721 features and 26 non-overlapping classes (e.g., \u201cNFL teams\u201d, \u201cCricket teams\u201d). The third dataset is the Reuters-21578 dataset published by Cai et al. [10]. This corpus originally contained 21,578 documents from 135 overlapping categories. Cai et al. discarded documents with multiple category labels, resulting in 8,293 documents (vocabulary size=18,933) in 65 non-overlapping categories."}, {"heading": "3.1 Exploratory EM vs. SemisupEM with few seed classes", "text": "Table 1 shows the performance of seeded K-Means, seeded Naive Bayes, and seeded vMF using 5 different algorithms. For each dataset only a few of the classes present in the data (5 for Delicious Sports, and 6 for 20-Newsgroups and 10 for Reuters), are given as seed classes to all the algorithms. Five percent datapoints were given as training data for each \u201cseeded\u201d class. The first method, shown in the column labeled SemisupEM, uses these methods as conventional SSL learners. The second method is Exploratory EM with the simple MinMax new-class introduction criterion, and the third is Exploratory EM with the JS criterion. Forth method is Exploratory EM with the Random criterion. The last one is upper bound on SemisupEM with m extra classes.\nExploreEM performs hard clustering of the dataset i.e. each datapoint belongs to only one cluster. For all methods, for each cluster we assign a label that maximizes accuracy (i.e. majority label for the cluster). Thus using complete set of labels we can generate a single label per datapoint. Reported Avg. F1 value is computed by macro averaging F1 values of seed classes only. Note that, for a given dataset, number of seed classes and training percentage per seed class there are many ways to generate a traintest partition. We report results using 10 random train-test partitions of each dataset.\nThe same partitions are used to run all the algorithms being compared and to compute the statistical significance of results.\nWe first consider the value of exploratory learning. With the JS criterion, the exploratory extension gives comparable or improved performance on 8 out of 9 cases. In 5 out of 8 cases the gains are statistically significant. With the simpler MinMax criterion, the exploratory extension results in performance improvements in 6 out of 8 cases, and significantly reduces performance only in one case. The number of classes finally introduced by the MinMax criterion is generally smaller than those introduced by JS criterion.\nFor both SSL and exploratory systems, the seeded K-Means method gives good results on all 3 datasets. In our MATLAB implementation, the running time of Exploratory EM is longer, but not unreasonably so: on average for 20-Newsgroups dataset Semisup-KMeans took 95 sec. while Explore-KMeans took 195 sec. and for Reuters dataset, Semisup-KMeans took 7 sec. while Explore-KMeans took 28 sec.\nWe can also see that Random criterion shows significant improvements over the baseline SemisupEM method in 4 out of 9 cases. While Exploratory EM method with MinMax and JS criterion shows significant improvements in 5 out of 9 cases. In terms of magnitude of improvements, JS is superior to Random criterion.\nNext we compare Exploratory EM with baseline named \u201cSemisupEM with m extra classes\u201d. The last column of Table 1 shows the best performance of this baseline by varying m = {0, 1, 2, 5, 10, 20, 40}, and choosing that value of m for which seed class F1 is maximum. Since the \u201cbestm extra classes\u201d baseline is making use of the test labels to pick right number of classes, it cannot be used in practice; however Exploratory EM methods produce comparable or better performance with this strong baseline.\nTo better understand the qualitative behavior of our methods, we conducted some further experiments with Semisup-KMeans with the MinMax criterion (which appears\nto be a reasonable baseline method.) We constructed confusion matrices for the classification task, to check how different methods perform on each dataset.2 Figure 1 (a) shows the confusion matrices for SemisupEM (top row) and Exploratory EM (bottom row) with five and fifteen seeded classes. We can see that SemisupEM with only five seed classes clearly confuses the unexpected classes with the seed classes, while Exploratory EM gives better quality results. Having seeds for more classes helps both SemisupEM and Exploratory EM, but SemisupEM still tends to confuse the unexpected classes with the seed classes. Figure 1 (b) shows similar results on the 20-Newsgroups dataset, but shows the confusion matrix after 1 iteration and after 15 iterations of EM. It shows that SemisupEM after 15 iterations has made limited progress in improving its classifier when compared to Exploratory EM.\nFinally, we compare the two class creation criteria, and show a somewhat larger range of seeded classes, ranging from 5 to 15 (out of 20 actual classes). In Figure 2 each of the confusion-matrices is annotated with the strategy, the number of seed classes and the number of classes produced. (E.g., plot \u201cMinMax-C5(23)\u201d describes ExploreKMeans with MinMax criterion and 5 seed classes which produces 23 clusters.) We can see that MinMax criterion usually produces a more reasonable number of clusters, closer to the ideal value of 20; however, performance of the JS method in terms of seed class accuracy is comparable to the MinMax method.\nThese trends are also shown quantitatively in Figure 3, which shows the result of varying the number of seeded classes (with five seeds per class) for Explore-KMeans and Semisup-KMeans; the top shows the effect on F1, and the bottom shows the effect on the number of classes produced (for Explore-KMeans only). Figure 4 shows a similar effect on the Delicious Sports dataset: here we systematically vary the number of seeded classes (using 5 seeds per seeded class, on the top), and also vary the number of seeds per class (using 10 seeded classes, on the bottom.) The left-hand side compares the F1 for Semisup-KMeans and Explore-KMeans, and the right-hand side shows the number of classes produced by Explore-KMeans. For all parameter settings, Explore-KMeans is better than or comparable to Semisup-KMeans in terms of F1 on seed classes."}, {"heading": "3.2 Comparison with the Chinese Restaurant Process", "text": "As discussed in Section 2.6, a seeded version of the Chinese Restaurant Process with Gibbs sampling (CRPGibbs) is an alternative exploratory learning algorithm. In this\n2 For purposes of visualization, introduced classes were aligned optimally with the true classes.\nsection we compare the performance of CRPGibbs with Explore-KMeans and SemisupKMeans. We consider two versions of CRP-Gibbs, one using the standard CRP and one using our proposed modified CRP criterion for new class creation that is sensitive to the near-uniformity of instance\u2019s posterior class distribution. CRP-Gibbs uses the same instance representation as our K-Means variants i.e. L1 normalized TFIDF features.\nIt is well-known that CRP is sensitive to the concentration parameter Pnew . Figures 5 and 6 show the performance of all the exploratory methods, as well as SemisupKMeans, as the concentration parameter is varied from 10\u22128 to 10\u22122. (For ExploreKMeans and Semisup-KMeans methods, this parameter is irrelevant). We show F1, the number of classes produced, and run-time (which is closely related to the number of classes produced.) The results show that a well-tuned seeded CRP-Gibbs can obtain good F1-performance, but at the cost of introducing many unnecessary clusters. The modified Explore-CRP-Gibbs performs consistently better, but not better than ExploreKMeans, and Semisup-KMeans performs the worst."}, {"heading": "4 Related Work", "text": "In this paper we describe and evaluate a novel multiclass SSL method that is more robust when there are unanticipated classes in the data\u2014or equivalently, when the algorithm is given seeds from only some of the classes present in the data. To the best of our knowledge this specific problem has not been explored in detail before, even though in real-world settings, there can be unanticipated (and hence unseeded) classes in any sufficiently large-scale multiclass SSL task.\nMore generally, however, it has been noted before that SSL may suffer due to the presence of unexpected structure in the data. For instance, Nigam et al\u2019s early work on SSL based EM with multinomial Naive Bayes [21] noted that adding too much unlabeled data sometimes hurt performance on SSL tasks, and discusses several reasons this might occur, including the possibility that there might not be a one-to-one correspondence between the natural mixture components (clusters) and the classes. To address this problem, they considered modeling the positive class with one component, and the negative class with a mixture of components. They propose to choose the number of such components by cross-validation; however, this approach is relatively expensive, and inappropriate when there are only a small number of labeled examples (which is a typical case in SSL). More recently, McIntosh [18] described heuristics for introducing new \u201cnegative categories\u201d in lexicon bootstrapping, based on a domain-specific heuristic for detecting semantic drift with distributional similarity metrics. Our setting is broadly similar to these works, except that we consider this task in a general multiclasslearning setting, and do not assume seeds from an explicitly-labeled \u201cnegative\u201d class, which is a mixture; instead, we assume seeds from known classes only. Thus we assume that data fits a mixture model with a one-to-one correspondence with the classes, but only after the learner introduces new classes hidden in the data. We also explore this issue in much more depth experimentally, by systematically considering the impact of having too few seed classes, and propose and evaluate a solution to the problem. There has also been substantial work in the past to automatically decide the right \u201cnumber of clusters\u201d in unsupervised learning [11,22,15,7,19,27]. Many of these techniques are built around K-Means and involve running it multiple times for different values of K. Exploratory learning differs in that we focus on a SSL setting, and evaluate specifically the performance difference on the seeded classes, rather than overall performance differences.\nThere is also a substantial body of work on constrained clustering; for instance, Wagstaff et al [26] describe a constrained clustering variant of K-Means \u201cmust-link\u201d and \u201ccannot-link\u201d constraints between pairs. This technique changes the cluster assignment phase of K-Means algorithm by assigning each example to the closest cluster such that none of the constraints are violated. SSL in general can be viewed as a special case of constrained clustering, as seed labels can be viewed as constraints on the clusters; hence exploratory learning can be viewed as a subtype of constrained clustering, as well as a generalization of SSL. However, our approach is different in the sense that there are more efficient methods for dealing with seeds than arbitrary constraints.\nIn this paper we focused on EM-like SSL methods. Another widely-used approach to SSL is label propagation. In the modified adsorption algorithm [25], one such graphbased label propagation method, each datapoint can be marked with one or more known labels, or a special dummy label meaning \u201cnone of the above\u201d. Exploratory learning is an extension that applies to a different class of SSL methods, and has some advantages over label propagation: for instance, it can be used for inductive tasks, not only transductive tasks. Exploratory EM also provides more information by introducing multiple \u201cdummy labels\u201d which describe multiple new classes in the data.\nA third approach to SSL involves unsupervised dimensionality reduction followed by supervised learning (e.g., [8]). Although we have not explored their combination, these techniques are potentially complementary with exploratory learning, as one could also apply EM-like methods, in a lower-dimensional space (as is typically done in spectral clustering). If this approach were followed then an exploratory learning method like Exploratory EM could be used to introduce new classes, and potentially gain better performance, in a semi-supervised setting.\nOne of our benchmark tasks, entity classification, is inspired by the NELL (Never Ending Language Learning) system [5]. NELL performs broad-scale multiclass SSL. One subproject within NELL [20] uses a clustering technique for discovering new relations between existing noun categories\u2014relations not defined by the existing handdefined ontology. Exploratory learning addresses the same problem, but integrates the introduction of new classes into the SSL process. Another line of research considers the problem of \u201copen information extraction\u201d, in which no classes or seeds are used at all [28,12,9]. Exploratory learning, in contrast, can exploit existing information about classes of interest and seed labels to improve performance.\nAnother related area of research is novelty detection. Topic detection and tracking task aims to detect novel documents at time t by comparing them to all documents till time t \u2212 1 and detects novel topics. Kasiviswanathan et al. [16] assumes the number of novel topics is given as input to the algorithm. Masud et al. [17] develop techniques on streaming data to predict whether next data chunk is novel or not. Our focus is on improving performance of semi-supervised learning when the number of new classes is unknown. Bouveyron [3] worked on the EM approach to model unknown classes, but the entire EM algorithm is run for multiple numbers of classes. Our algorithm jointly learns labels as well as new classes. Scho\u0308lkopf et al. [24] defines a problem of learning a function over the data space that isolates outliers from class instances. Our approach is different in the sense we do not focus on detecting outliers for each class."}, {"heading": "5 Conclusion", "text": "In this paper, we investigate and improve the robustness of SSL methods in a setting in which seeds are available for only a subset of the classes\u2014the subset of most interest to the end user. We performed systematic experiments on fully-labeled multiclass problems, in which the number of classes is known. We showed that if a user provides seeds for only some, but not all, classes, then SSL performance is degraded for several popular EM-like SSL methods (semi-supervised multinomial Naive Bayes, seeded K-Means, and a seeded version of mixtures of von Mises-Fisher distributions). We then described a novel extension of the EM framework called Exploratory EM, which makes these methods much more robust to unseeded classes. Exploratory EM introduces new classes on-the-fly during learning based on the intuition that hard-to-classify examples\u2014specifically, examples with a nearly-uniform posterior class distribution\u2014 should be assigned to new classes. The exploratory versions of these SSL methods often obtained dramatically better performance\u2014e.g., on Delicious Sports dataset up to 90% improvements in F1, on 20-Newsgroups dataset up to 27% improvements in F1, and on Reuters dataset up to 200% improvements in F1. In comparative experiments, one exploratory SSL method, Explore-KMeans, emerged as a strong baseline approach.\nBecause Exploratory EM is broadly similar to non-parametric Bayesian approaches, we also compared Explore-KMeans to a seeded version of an unsupervised mixture learner that explores differing numbers of mixture components with the Chinese Restaurant process (CRP). Explore-KMeans is faster than this approach, and more accurate as well, unless the parameters of the CRP are very carefully tuned. Explore-KMeans also generates a model that is more compact, having close to the true number of clusters. The seeded CRP process can be improved, moreover, by adapting some of the intuitions of Explore-KMeans, in particular by introducing new clusters most frequently for hard-to-classify examples (those with nearly-uniform posteriors).\nThe exploratory learning techniques we described here are limited to problems where each data point belongs to only one class. An interesting direction for future research can be to develop such techniques for multi-label classification, and hierarchical classification. Another direction can be create more scalable parallel versions of Explore-KMeans for much larger datasets, e.g., large-scale entity-clustering task.\nAcknowledgments: This work is supported in part by the Intelligence Advanced Research Projects Activity (IARPA) via Air Force Research Laboratory (AFRL) contract number FA8650-10-C-7058. The U.S. Government is authorized to reproduce and distribute reprints for Governmental purposes notwithstanding any copyright annotation thereon. This work is also partially supported by the Google Research Grant. The views and conclusions contained herein are those of the authors and should not be interpreted as necessarily representing the official policies or endorsements, either expressed or implied, of Google, IARPA, AFRL, or the U.S. Government."}], "references": [{"title": "Clustering on the unit hypersphere using von mises-fisher distributions", "author": ["A. Banerjee", "I.S. Dhillon", "J. Ghosh", "S. Sra"], "venue": "In JMLR,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2005}, {"title": "Semi-supervised clustering by seeding", "author": ["S. Basu", "A. Banerjee", "R. Mooney"], "venue": null, "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2002}, {"title": "Adaptive mixture discriminant analysis for supervised learning with unobserved classes", "author": ["C. Bouveyron"], "venue": null, "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2010}, {"title": "Multimodel inference understanding aic and bic in model selection", "author": ["K.P. Burnham", "D.R. Anderson"], "venue": "Sociological methods & research,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2004}, {"title": "Coupled semi-supervised learning for information extraction", "author": ["A. Carlson", "J. Betteridge", "R.C. Wang", "E.R. Hruschka", "Jr.", "T.M. Mitchell"], "venue": "In WSDM,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2010}, {"title": "A classification em algorithm for clustering and two stochastic versions", "author": ["G. Celeux", "G. Govaert"], "venue": "Computational statistics & Data analysis,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 1992}, {"title": "Intelligent choice of the number of clusters in k-means clustering: An experimental study with different cluster spreads", "author": ["M.M.-T. Chiang", "B. Mirkin"], "venue": "J. Classification,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2010}, {"title": "Very fast similarity queries on semi-structured data from the web", "author": ["B. Dalvi", "W. Cohen"], "venue": "In SDM", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2013}, {"title": "Websets: Extracting sets of entities from the web using unsupervised information extraction", "author": ["B. Dalvi", "W. Cohen", "J. Callan"], "venue": "In WSDM,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2012}, {"title": "Probabilistic dyadic data analysis with local and global consistency", "author": ["X.W. Deng Cai", "X. He"], "venue": null, "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2009}, {"title": "Learning parameters of the k-means algorithm from subjective human", "author": ["H. Dutta", "R. Passonneau", "A. Lee", "A. Radeva", "B. Xie", "D. Waltz", "B. Taranto"], "venue": "annotation. FLAIRS,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2011}, {"title": "Web-scale information extraction in knowitall", "author": ["O. Etzioni", "M. Cafarella", "D. Downey", "S. Kok", "A.-M. Popescu", "T. Shaked", "S. Soderland", "D.S. Weld", "A. Yates"], "venue": "In WWW,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2004}, {"title": "A structural em algorithm for phylogenetic inference", "author": ["N. Friedman", "M. Ninio", "I. Pe\u2019er", "T. Pupko"], "venue": "Journal of Computational Biology,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2002}, {"title": "Hierarchical topic models and the nested chinese restaurant process", "author": ["D. Griffiths", "M. Tenenbaum"], "venue": "In NIPS,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2004}, {"title": "Learning the k in k-means", "author": ["G. Hamerly", "C. Elkan"], "venue": "In NIPS,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2003}, {"title": "Emerging topic detection using dictionary learning", "author": ["S.P. Kasiviswanathan", "P. Melville", "A. Banerjee", "V. Sindhwani"], "venue": "In CIKM,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2011}, {"title": "Integrating novel class detection with classification for concept-drifting data streams", "author": ["M.M. Masud", "J. Gao", "L. Khan", "J. Han", "B. Thuraisingham"], "venue": "In ECML/PKDD", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2009}, {"title": "Unsupervised discovery of negative categories in lexicon bootstrapping", "author": ["T. McIntosh"], "venue": null, "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2010}, {"title": "A methodology for workload characterization of e-commerce sites", "author": ["D.A. Menasce", "V.A.F. Almeida", "R. Fonseca", "M.A. Mendes"], "venue": null, "citeRegEx": "19", "shortCiteRegEx": "19", "year": 1999}, {"title": "Discovering relations between noun categories", "author": ["T. Mohamed", "E. Hruschka Jr.", "T. Mitchell"], "venue": "In EMNLP,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2011}, {"title": "Text classification from labeled and unlabeled documents using em", "author": ["K. Nigam", "A. McCallum", "S. Thrun", "T. Mitchell"], "venue": "Machine learning,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2000}, {"title": "X-means: Extending k-means with efficient estimation of the number of clusters", "author": ["D. Pelleg", "A. Moore"], "venue": "In ICML,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2000}, {"title": "Support vector method for novelty detection", "author": ["B. Sch\u00f6lkopf", "R.C. Williamson", "A.J. Smola", "J. Shawe-Taylor", "J. Platt"], "venue": null, "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2000}, {"title": "New regularized algorithms for transductive learning", "author": ["P. Talukdar", "K. Crammer"], "venue": "In ECML-PKDD", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2009}, {"title": "Constrained k-means clustering with background knowledge", "author": ["K. Wagstaff", "C. Cardie", "S. Rogers", "S. Schrodl"], "venue": null, "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2001}, {"title": "Bayesian k-means as a maximization-expectation algorithm", "author": ["M. Welling", "K. Kurihara"], "venue": "In ICDM,", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2006}, {"title": "Textrunner: Open information extraction on the web", "author": ["A. Yates", "M. Cafarella", "M. Banko", "O. Etzioni", "M. Broadhead", "S. Soderland"], "venue": "In NAACL,", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 2007}], "referenceMentions": [{"referenceID": 4, "context": ", [5]).", "startOffset": 2, "endOffset": 5}, {"referenceID": 0, "context": "In this paper, Exploratory EM is instantiated to produce exploratory versions of three well-known SSL methods: semi-supervised Naive Bayes, seeded K-Means, and a seeded version of EM using a von Mises-Fisher distribution [1].", "startOffset": 221, "endOffset": 224}, {"referenceID": 13, "context": "We then compare against an alternative exploratory SSL approach, namely Gibbs sampling with Chinese restaurant process [14].", "startOffset": 119, "endOffset": 123}, {"referenceID": 5, "context": "In some variants of EM, including the ones we consider here, a \u201chard\u201d assignment is made to classes instead, an approach named classification EM [6].", "startOffset": 145, "endOffset": 148}, {"referenceID": 12, "context": "2 Discussion Friedman [13] proposed the Structural EM algorithm that combines the standard EM algorithm, which optimizes parameters, with structure search for model selection.", "startOffset": 22, "endOffset": 26}, {"referenceID": 12, "context": "Say this model switch happens at iteration tswitch, then from iteration 1 to tswitch, Algorithm 1 acts like the structural EM algorithm [13].", "startOffset": 136, "endOffset": 140}, {"referenceID": 3, "context": "Burnham and Anderson [4] have experimented with AIC criteria and proposed AICc for datasets where, the number of datapoints is less than 40 times number of features.", "startOffset": 21, "endOffset": 24}, {"referenceID": 20, "context": "[21] proposed an EM-based semi-supervised version of multinomial Naive Bayes.", "startOffset": 0, "endOffset": 4}, {"referenceID": 1, "context": "Basu and Mooney [2] proposed a seeded version of K-Means, which is very analogous to Nigam et al\u2019s semi-supervised Naive Bayes, as another technique for semisupervised learning.", "startOffset": 16, "endOffset": 19}, {"referenceID": 0, "context": "[1], who described an EM algorithm that is directly inspired by K-Means and TFIDF-based representations.", "startOffset": 0, "endOffset": 3}, {"referenceID": 1, "context": "[2].", "startOffset": 0, "endOffset": 3}, {"referenceID": 0, "context": "This natural extension of Banerjee et al[1]\u2019s work can be easily extended to our exploratory setting.", "startOffset": 40, "endOffset": 43}, {"referenceID": 13, "context": "A seeded Gibbs sampler with CRP: The Exploratory EM method is broadly similar to non-parametric Bayesian methods, such as the Chinese Restaurant process (CRP) [14].", "startOffset": 159, "endOffset": 163}, {"referenceID": 8, "context": "The second dataset is the Delicious Sports dataset, published by [9].", "startOffset": 65, "endOffset": 68}, {"referenceID": 9, "context": "[10].", "startOffset": 0, "endOffset": 4}, {"referenceID": 20, "context": "For instance, Nigam et al\u2019s early work on SSL based EM with multinomial Naive Bayes [21] noted that adding too much unlabeled data sometimes hurt performance on SSL tasks, and discusses several reasons this might occur, including the possibility that there might not be a one-to-one correspondence between the natural mixture components (clusters) and the classes.", "startOffset": 84, "endOffset": 88}, {"referenceID": 17, "context": "More recently, McIntosh [18] described heuristics for introducing new \u201cnegative categories\u201d in lexicon bootstrapping, based on a domain-specific heuristic for detecting semantic drift with distributional similarity metrics.", "startOffset": 24, "endOffset": 28}, {"referenceID": 10, "context": "There has also been substantial work in the past to automatically decide the right \u201cnumber of clusters\u201d in unsupervised learning [11,22,15,7,19,27].", "startOffset": 129, "endOffset": 147}, {"referenceID": 21, "context": "There has also been substantial work in the past to automatically decide the right \u201cnumber of clusters\u201d in unsupervised learning [11,22,15,7,19,27].", "startOffset": 129, "endOffset": 147}, {"referenceID": 14, "context": "There has also been substantial work in the past to automatically decide the right \u201cnumber of clusters\u201d in unsupervised learning [11,22,15,7,19,27].", "startOffset": 129, "endOffset": 147}, {"referenceID": 6, "context": "There has also been substantial work in the past to automatically decide the right \u201cnumber of clusters\u201d in unsupervised learning [11,22,15,7,19,27].", "startOffset": 129, "endOffset": 147}, {"referenceID": 18, "context": "There has also been substantial work in the past to automatically decide the right \u201cnumber of clusters\u201d in unsupervised learning [11,22,15,7,19,27].", "startOffset": 129, "endOffset": 147}, {"referenceID": 25, "context": "There has also been substantial work in the past to automatically decide the right \u201cnumber of clusters\u201d in unsupervised learning [11,22,15,7,19,27].", "startOffset": 129, "endOffset": 147}, {"referenceID": 24, "context": "There is also a substantial body of work on constrained clustering; for instance, Wagstaff et al [26] describe a constrained clustering variant of K-Means \u201cmust-link\u201d and \u201ccannot-link\u201d constraints between pairs.", "startOffset": 97, "endOffset": 101}, {"referenceID": 23, "context": "In the modified adsorption algorithm [25], one such graphbased label propagation method, each datapoint can be marked with one or more known labels, or a special dummy label meaning \u201cnone of the above\u201d.", "startOffset": 37, "endOffset": 41}, {"referenceID": 7, "context": ", [8]).", "startOffset": 2, "endOffset": 5}, {"referenceID": 4, "context": "One of our benchmark tasks, entity classification, is inspired by the NELL (Never Ending Language Learning) system [5].", "startOffset": 115, "endOffset": 118}, {"referenceID": 19, "context": "One subproject within NELL [20] uses a clustering technique for discovering new relations between existing noun categories\u2014relations not defined by the existing handdefined ontology.", "startOffset": 27, "endOffset": 31}, {"referenceID": 26, "context": "Another line of research considers the problem of \u201copen information extraction\u201d, in which no classes or seeds are used at all [28,12,9].", "startOffset": 126, "endOffset": 135}, {"referenceID": 11, "context": "Another line of research considers the problem of \u201copen information extraction\u201d, in which no classes or seeds are used at all [28,12,9].", "startOffset": 126, "endOffset": 135}, {"referenceID": 8, "context": "Another line of research considers the problem of \u201copen information extraction\u201d, in which no classes or seeds are used at all [28,12,9].", "startOffset": 126, "endOffset": 135}, {"referenceID": 15, "context": "[16] assumes the number of novel topics is given as input to the algorithm.", "startOffset": 0, "endOffset": 4}, {"referenceID": 16, "context": "[17] develop techniques on streaming data to predict whether next data chunk is novel or not.", "startOffset": 0, "endOffset": 4}, {"referenceID": 2, "context": "Bouveyron [3] worked on the EM approach to model unknown classes, but the entire EM algorithm is run for multiple numbers of classes.", "startOffset": 10, "endOffset": 13}, {"referenceID": 22, "context": "[24] defines a problem of learning a function over the data space that isolates outliers from class instances.", "startOffset": 0, "endOffset": 4}], "year": 2013, "abstractText": "In multiclass semi-supervised learning (SSL), it is sometimes the case that the number of classes present in the data is not known, and hence no labeled examples are provided for some classes. In this paper we present variants of well-known semi-supervised multiclass learning methods that are robust when the data contains an unknown number of classes. In particular, we present an \u201cexploratory\u201d extension of expectation-maximization (EM) that explores different numbers of classes while learning. \u201cExploratory\u201d SSL greatly improves performance on three datasets in terms of F1 on the classes with seed examples\u2014i.e., the classes which are expected to be in the data. Our Exploratory EM algorithm also outperforms a SSL method based non-parametric Bayesian clustering.", "creator": "LaTeX with hyperref package"}}}