{"id": "1307.0339", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "1-Jul-2013", "title": "Syntactic sensitive complexity for symbol-free sequence", "abstract": "This work uses the L-system to construct a tree structure for the text sequence and derives its complexity. It serves as a measure of structural complexity of the text. It is applied to anomaly detection in data transmission networks (SDRs). The L-system is implemented on a large scale in network performance, with the L-system running on a single server on a single server in parallel. The L-system is the simplest of these systems for data transmission networks. The structure of the data is used to determine which parts of the system are needed for transmission networks, and how it is used to determine which parts of the system are needed to generate it. This structure is used for the transmission network and also for all kinds of data transmission networks. Data transmission networks are composed of many different sets of information, from the types of data transmitted and whether they can be found or not. The L-system is used to provide the most efficient information about the system, with the most efficient and efficient. The L-system is used to ensure that a node is properly integrated with a network of users, as well as to provide the most efficient information about the system. In addition, it helps to ensure that the L-system is distributed efficiently, and in the case of the L-system, there is no need to use special features such as the L-system. The L-system is used to monitor the number of nodes per network, and provide the lowest number of nodes per network. The L-system also provides a mechanism for using the system for monitoring the number of nodes per network, in order to reduce the number of nodes per network. There are several ways to store the data in a single format: a file, or even a video file. In the example shown below, all of these types of information are stored in a single document in each file of file. The L-system is used to provide the most efficient information about the system, with the most efficient and efficient. The L-system is used to provide the most efficient information about the system, with the most efficient and efficient. The L-system is used to provide the most efficient information about the system, with the most efficient and efficient. The L-system is used to provide the most efficient information about the system, with the most efficient and efficient. The L-system is used to provide the most efficient information about the system, with the most efficient and efficient. The L-system is used to provide the most efficient information about the system, with the most efficient", "histories": [["v1", "Mon, 1 Jul 2013 12:00:59 GMT  (243kb)", "https://arxiv.org/abs/1307.0339v1", "11 pages, 5 figures"], ["v2", "Tue, 2 Jul 2013 02:08:48 GMT  (256kb,D)", "http://arxiv.org/abs/1307.0339v2", "11 pages, 5 figures"]], "COMMENTS": "11 pages, 5 figures", "reviews": [], "SUBJECTS": "cs.AI", "authors": ["cheng-yuan liou", "bo-shiang huang", "daw-ran liou", "alex a simak"], "accepted": false, "id": "1307.0339"}, "pdf": {"name": "1307.0339.pdf", "metadata": {"source": "CRF", "title": "Syntactic sensitive complexity for symbol-free sequence", "authors": ["Cheng-Yuan Liou", "Bo-Shiang Huang", "Daw-Ran Liou", "Alex A. Simak"], "emails": [], "sections": [{"heading": null, "text": "Keyword: text complexity, anomaly detection, structural complexity, rewriting rule, context-free grammar, L-system"}, {"heading": "1 Introduction", "text": "Complexity of the text has been developed with varying degrees of success, [2][3]. This work devised a novel measure based on L-system [1] that can compute the structural complexity of a text sequence. Given a text, we first transform it into a binary string. Then, use L-system to model the tree structure of this string and get its structural complexity. We will introduce how to use L-system to model the string in this section. The measure of complexity for the text sequence is included in the next section."}, {"heading": "1.1 Transforming binary string into rewriting rules", "text": "The Lindenmayer system, or L-system, is a parallel rewriting system which was introduced by the biologist Aristid Lindenmayer in 1968. The major operation of L-system is rewriting. A set of rewriting rules, or productions, are operated to define a complex object by successively replacing parts of a simple initial object. The operations for a hierarchical tree can be represented by a set of rewriting rules. These rules can be further transformed into a bracketed string. A binary tree can be represented by a bracketed string and the tree can be restored from the string. This bracked string contains five symbols, F , +, \u2212, [ , and ] . These symbols are defined in the following paragraph.\n\u2022 F denotes the current location of a tree node. It can be replaced by any word or be omitted.\nar X\niv :1\n30 7.\n03 39\nv2 [\ncs .A\nI] 2\nJ ul\n\u2022 + denotes the following string that represents the right subtree.\n\u2022 \u2212 denotes the following string that represents the left subtree.\n\u2022 [ is pairing with ]. \u201c[. . .]\u201d denotes a subtree where \u201c. . . \u201d indicates all the bracketed string of its subtree.\nGiven a binary tree, the direct way to represent it with L-system is to construct rewriting rules that replace a tree with two smaller subtrees. An example is shown in Fig. 1. The left tree in Fig. 1 is expressed as P \u2192 [\u2212FTL][+FTR]. The right tree is expressed as P \u2192 [\u2212FTL][+FTR] and TR \u2192 [\u2212FTRL ][+FTRR ]. We see that the two rules, P \u2192 [\u2212FTL][+FTR] and TR \u2192 [\u2212FTRL ][+FTRR ], are similar. The binary tree example in Fig.2 can be transformed into the set of rewriting rules in Table 1.\nFig.2 shows an example with four fixed tree elements representing the four 2-bit strings, { 00, 10, 01, and 11}. In this figure, every two leaves are combined into a small tree, and two small trees are combined into a bigger tree recursively. In this way, we can get a whole binary tree for a long binary string. Each node of the tree represents all its descendant string sections. The binary tree example in Fig.2 can be transformed into the set of rewriting rules in Table 1."}, {"heading": "1.2 Classifying rewriting rules into different sets", "text": "Two similarity definitions are used in classifying the rewriting rules.\nDefinition 1 Homomorphism in rewriting rules. We say rewriting rule R1 and rewriting rule R2 are homomorphic to each other if and only if they have the same structure.\nDefinition 2 Isomorphism on level X in rewriting rules. Rewriting rule R1 and rewriting rule R2 are isomorphic on depth X if they are homomophic and their non-terminals are relatively isomophic on depth X \u2212 1. Isomorphic on level 0 indicates homomorphism.\nAfter defining the similarity between rules by homomorphism and isomorphism, we can classify all the rules into different subsets where each subset has the same similarity relation. We will use the rule name as the class name. For example, we asign the terminal rewriting rule a class, \u201cC3 \u2192 null\u201d. Assign a rule linked to two terminals, \u201cC2 \u2192 C3C3\u201d, here C3 is the terminal class. After classification, we obtain a context free grammar set, which can be converted into an automata. After transforming the binary tree in Fig, 2 into the set of rewriting rules in Table 1, we can do classification and get the results listed in Table 2."}, {"heading": "1.3 Complexity for classified rules", "text": "The generating function of a context free grammar is defined in the following paragraph.\nDefinition 3 Generating function of a context free grammar.\n1. Assume that there are n classes of rules, {C1, C2, . . . , Cn}, and the class Ci contains ni rules. Let Vi \u2208 {C1, C2, . . . , Cn}, Uij \u2208 {Rij , i = 1, 2, . . . , n; j = 1, 2, . . . , ni}, and aijk \u2208 {x : x = 1, 2, . . . , n}, where each Uij has the\nfollowing form for a binary tree:\nUi1 \u2192 Vai11Vai12 Ui2 \u2192 Vai21Vai22 . . . \u2192 . . . Uini \u2192 Vaini1Vaini2 .\n2. The generating function of Vi, Vi(z) has a form,\nVi(z) =\nni\u2211 p=1 nipz kVaip1(z)Vaip2(z)\nni\u2211 q=1 niq\n.\nIf Vi does not have any non-terminal, we set Vi(z) = 1. The parameter k is set to 1, k = 1, in [1]. An alternative setting is to weight the redundancy of rewriting rules by setting k = 1/nip.\n3. After formulating the generating function Vi(z), we plan to find the largest value of z, zmax, where V1(z\nmax) is convergent. Note that we will use V1 to denote the function of the root node of the binary tree. After obtaining the largest value, zmax, of V1(z), we set R = z\nmax, where R is the radius of convergence of V1(z). The complexity, K0, of the binary tree is\nK0 = \u2212 lnR.\n4. Since computing the maximum value, zmax, directly is not feasible, we use iterations and region tests to accomplish the complexity. Rewrite the generating function in an iterative form,\nV mi (z \u2032) =\nni\u2211 p=1 nipz \u2032kV m\u22121aip1 (z\u2032)V m\u22121aip2 (z\u2032)\nni\u2211 q=1 niq\n; m = 1, 2, 3, ...; and\nV 0i (z \u2032) = 1.\n5. The value of the function Vi at a specific z \u2032 can be calculated by iterations\nof the form. In each iteration, calculate the values from V 0i (z \u2032) to V mi (z \u2032). When V m\u22121i (z \u2032) = V mi (z \u2032) is satisfied for all rules, we stop the iteration. From experiences, we set m = 200.\n6. Now we can test whether Vi(z \u2032) is convergent or divergent at a value z\u2032.\nWe use binary seaching to test the values between 0 and 1. In each test, when Vi(z\n\u2032) is convergent, we set a bigger value z\u2032 in the next test. When Vi(z\n\u2032) is divergent, we set a smaller value z\u2032 in the next test. We expect that this test will approach the radius, R = zmax, closely."}, {"heading": "2 Complexity of encoded text", "text": "We show how to compute the complexity of the text. A text sequence is first transformed into a binary string by any giving encoding method. One can directly set each character be an integer and obtain a binary string for the text. For example, use the integer indexes, 1 to 27, to represent the 26 alphabets plus the space character. We use the term BIN to call this encoding method. This method is simple and doesn\u2019t apply any sophisticated encoding algorithm. A different method, Lempel-Ziv-Welch (LZW), is also applied to encode the text. LZW is designed for lossless data compression and is a dictionary-based encoding [4]. In LZW, when certain substring appears frequently in the text, it will be saved in the dictionary. These two methods will be used in this work to accomplish the binary strings.\nBefore LZW processing, its dictionary contains all possible single characters of the text. LZW searches through the text sequence, successively, for a longer substring until it finds one that is not in the dictionary. Whenever LZW finds a substring that is in the dictionary, its index is retrieved from the dictionary and this index will replace the substring\u2019s place in the encoded sequence. LZW will add a new substring to the dictionary and attach a new index to the substring. The last character of the newly replaced substring will be used as the next starting character to scan for new substrings. Longer strings are saved, successively, in the dictionary and made available for subsequent encoding. When LZW works on sequence with many repeated patterns, its compression efficiency is high.\nFor example, suppose there are only three characters \u201ca\u201d, \u201cb\u201d, \u201cc\u201d in the dictionary before we start searching. The indeices, \u201c1\u201d, \u201c2\u201d, and \u201c3\u201d, are used to represent them respectively. Giving a text \u201cabcabcabc\u201d, the substrings, \u201cab\u201d, \u201cbc\u201d, \u201cca\u201d, \u201cabc\u201d, \u201ccab\u201d, will be saved in the dictionary successively with their new assigned indeices, \u201c4\u201d, \u201c5\u201d, \u201c6\u201d, \u201c7\u201d, \u201c8\u201d. This string \u201cabcabcabc\u201d will be transformed into an array [1,2,3,4,6,5]. By using binary numbers, the array [1,2,3,4,6,5] can be transformed into a binary string \u201d001 010 011 100 110 101\u201d."}, {"heading": "Example", "text": "The article \u201cThe Declaration of Independence\u201d is used as the text sequence. After removing all punctuation, the total number of characters are 7930. Apply the two encoding methods and obtain its two binary strings. We calculate the complexity every 512 bits along the string. Figure 3 shows that the complexity values of BIN are roughly fixed across the text sequence. The complexity values of LZW near the front end of the text are lower than those near the rear end of the text. Those lower valuses reveals the encoding features of LZW. Since the LZW dictionary saves a lot of regular patterns in the front end and absorbs the regularity, there will be no\nsuch regular patterns in the rear end. A string with high regularity has low complexity. So, the represented string near the rear end becomes much random with high complexity."}, {"heading": "3 Comparison with other Measures", "text": "Two other measures of complexity, topological entropy (TE) [2] and linguistic complexity (LC) are discussed and compared with the proposed method."}, {"heading": "Topological entropy", "text": "An information function Ai(s) is defined as,\nAl(s) = |{u : |u| = l and u is a distinct substring in s}|,\nwhere Ai(s) represents the total number of distinct substrings with length l in the sequence s. The entropy [5] is defined as,\nHl(s) = logkAl(s)\nl ,\nwhere k is the size of all alphabets of the sequence. Since there are many values for l and this definition can\u2019t produce a single value\nof complexity for the whole sequence. A new definition [2] for the topological entropy is in the following paragraph.\nDefinition 4 Let s be a finite sequence of length |s| and k be the size of alphabet, let l be the unique integer such that\nkl + l \u2212 1 \u2264 |s| \u2264 kl+1 + (l + 1)\u2212 1\nWe use sk l+l\u22121\n1 to represent the first k l + l \u2212 1 letters of s.\nHTE(s) := logk(Al(s\nkl+l\u22121 1 ))\nl\nwhere Al(s kl+l\u22121 1 ) is the number of distinct substrings with length l in sequence sk l+l\u22121\n1 ."}, {"heading": "Linguistic complexity", "text": "Linguistic complexity [6, 8] is a measure of the vocabulary richness of a text. LC is defined as the ratio of the number of substrings presented in the string of interest to the maximum number of substrings of the same length string over the same alphabet. Thus, the more complex a text sequence, the richer its vocabulary, whereas a repetitious sequence has relatively lower complexity. Some notations are used in LC. Let |s| be the length of the binary string s. Let Ml(s) denote the maximal possible number of distinct substrings with length l, and Ml(s) is equal to min(2\ni, |s| \u2212 i + 1). Let M(s) be the sum of M1(s), M2(s),.., and M|s|(s). Let Al(s) be the actual number of distinct substrings with length l. Let A(s) be the sum of A1(s), A2(s),..., and A|s|(s). Then, LC of the sequence s is A(s)/M(s).\nFor example, consider the binary string \u201cs1 : 0111001100\u201d. The length of s1 is equal to |s1| = 10. The M(s1) value is M(s1) = 2+4+8+7+6+5+4+3+2+1 = 42. Note that this value depends only on the length of the string and the alphabet size. We then use the suffix tree to calculate the actual number of distinct substrings, A(s1) = 38. The LC value of s1 is equal to 38/42 = 0.904762.\nWe take another example \u201cs2 : 0101010101\u201d. The length of s2 is equal to 10, and the value M(s2) = 42 is also equal to M(s1). The A(s2) value A(s2) = 19 is smaller than that of A(s1). This is because s2 is more regular. The LC of s2 is equal to 19/42 = 0.45238."}, {"heading": "Comparison and analysis", "text": "Topological entropy focuses on only one subword length and computes its complexity. In contrast, linguistic complexity computes the complexity of all possible subword lengths. LC uses much more computations than that of TE. The proposed method uses the binary tree to represent a binary sequence that has a length of power of 2. It reveals the structural information of the sequence.\nFinally, we discuss some potential applications. The proposed complexity can be used to assist encoding and data compression. By monitoring the complexity of a text sequence, we can encode certain text sections of low complexity with better compression ratios and with fewer bits. We can also use the proposed complexity to detect anomaly in data transmission."}], "references": [{"title": "Modeling complexity in musical rhythm", "author": ["C.Y. Liou", "T.H. Wu", "C.Y. Lee"], "venue": "Complexity", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2010}, {"title": "Topological entropy of DNA sequences", "author": ["D. Koslicki"], "venue": null, "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2011}, {"title": "Spatial representation of symbolic sequences through iterative function systems. Systems, Man and Cybernetics, Part A: Systems and Humans", "author": ["P. Ti\u00f1o"], "venue": "IEEE Transactions on", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 1999}, {"title": "A technique for high-performance data compression", "author": ["T.A. Welch"], "venue": "IEEE Computer", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 1984}, {"title": "Entropy concepts and DNA investigations", "author": ["O.V. Kirillova"], "venue": "Physics Letters A", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2000}, {"title": "Sequence complexity and DNA curvature", "author": ["A.E. Gabrielian", "A. Bolshoy"], "venue": "Computers & Chemistry", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 1999}, {"title": "On the average complexity for the verification of compatible sequences", "author": ["C. Koukouvinos", "V. Pillwein", "D.E. Simos", "Z. Zafeirakopoulos"], "venue": "Inf. Process. Lett", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2011}, {"title": "Making sense of the human genome. In: Structure and Methods: Human Genome Initiative and DNA Recombination", "author": ["E. Trifonov"], "venue": "Volume 1. Adenine Press", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 1990}, {"title": "Sequence complexity profiles of prokaryotic genomic 10  sequences: A fast algorithm for calculating linguistic complexity", "author": ["O.G. Troyanskaya", "O. Arbell", "Y. Koren", "G.M. Landau", "A. Bolshoy"], "venue": "Bioinformatics", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2002}], "referenceMentions": [{"referenceID": 0, "context": "Abstract This work uses the L-system to construct a tree structure for the text sequence and derives its complexity [1].", "startOffset": 116, "endOffset": 119}, {"referenceID": 1, "context": "Complexity of the text has been developed with varying degrees of success, [2][3].", "startOffset": 75, "endOffset": 78}, {"referenceID": 2, "context": "Complexity of the text has been developed with varying degrees of success, [2][3].", "startOffset": 78, "endOffset": 81}, {"referenceID": 0, "context": "This work devised a novel measure based on L-system [1] that can compute the structural complexity of a text sequence.", "startOffset": 52, "endOffset": 55}, {"referenceID": 0, "context": "The parameter k is set to 1, k = 1, in [1].", "startOffset": 39, "endOffset": 42}, {"referenceID": 3, "context": "LZW is designed for lossless data compression and is a dictionary-based encoding [4].", "startOffset": 81, "endOffset": 84}, {"referenceID": 0, "context": "This string \u201cabcabcabc\u201d will be transformed into an array [1,2,3,4,6,5].", "startOffset": 58, "endOffset": 71}, {"referenceID": 1, "context": "This string \u201cabcabcabc\u201d will be transformed into an array [1,2,3,4,6,5].", "startOffset": 58, "endOffset": 71}, {"referenceID": 2, "context": "This string \u201cabcabcabc\u201d will be transformed into an array [1,2,3,4,6,5].", "startOffset": 58, "endOffset": 71}, {"referenceID": 3, "context": "This string \u201cabcabcabc\u201d will be transformed into an array [1,2,3,4,6,5].", "startOffset": 58, "endOffset": 71}, {"referenceID": 5, "context": "This string \u201cabcabcabc\u201d will be transformed into an array [1,2,3,4,6,5].", "startOffset": 58, "endOffset": 71}, {"referenceID": 4, "context": "This string \u201cabcabcabc\u201d will be transformed into an array [1,2,3,4,6,5].", "startOffset": 58, "endOffset": 71}, {"referenceID": 0, "context": "By using binary numbers, the array [1,2,3,4,6,5] can be transformed into a binary string \u201d001 010 011 100 110 101\u201d.", "startOffset": 35, "endOffset": 48}, {"referenceID": 1, "context": "By using binary numbers, the array [1,2,3,4,6,5] can be transformed into a binary string \u201d001 010 011 100 110 101\u201d.", "startOffset": 35, "endOffset": 48}, {"referenceID": 2, "context": "By using binary numbers, the array [1,2,3,4,6,5] can be transformed into a binary string \u201d001 010 011 100 110 101\u201d.", "startOffset": 35, "endOffset": 48}, {"referenceID": 3, "context": "By using binary numbers, the array [1,2,3,4,6,5] can be transformed into a binary string \u201d001 010 011 100 110 101\u201d.", "startOffset": 35, "endOffset": 48}, {"referenceID": 5, "context": "By using binary numbers, the array [1,2,3,4,6,5] can be transformed into a binary string \u201d001 010 011 100 110 101\u201d.", "startOffset": 35, "endOffset": 48}, {"referenceID": 4, "context": "By using binary numbers, the array [1,2,3,4,6,5] can be transformed into a binary string \u201d001 010 011 100 110 101\u201d.", "startOffset": 35, "endOffset": 48}, {"referenceID": 1, "context": "Two other measures of complexity, topological entropy (TE) [2] and linguistic complexity (LC) are discussed and compared with the proposed method.", "startOffset": 59, "endOffset": 62}, {"referenceID": 4, "context": "The entropy [5] is defined as,", "startOffset": 12, "endOffset": 15}, {"referenceID": 1, "context": "A new definition [2] for the topological entropy is in the following paragraph.", "startOffset": 17, "endOffset": 20}, {"referenceID": 5, "context": "Linguistic complexity [6, 8] is a measure of the vocabulary richness of a text.", "startOffset": 22, "endOffset": 28}, {"referenceID": 7, "context": "Linguistic complexity [6, 8] is a measure of the vocabulary richness of a text.", "startOffset": 22, "endOffset": 28}], "year": 2013, "abstractText": "This work uses the L-system to construct a tree structure for the text sequence and derives its complexity [1]. It serves as a measure of structural complexity of the text. It is applied to anomaly detection in data transmission. Keyword: text complexity, anomaly detection, structural complexity, rewriting rule, context-free grammar, L-system", "creator": "LaTeX with hyperref package"}}}