{"id": "1307.3435", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "12-Jul-2013", "title": "On Nicod's Condition, Rules of Induction and the Raven Paradox", "abstract": "Philosophers writing about the ravens paradox often note that Nicod's Condition (NC) holds given some set of background information, and fails to hold against others, but rarely go any further. That is, it is usually not explored which background information makes NC true or false. The present paper aims to fill this gap.\n\n\nIn particular, this paper seeks to draw attention to the possibility that NGC does not need background information for its analysis. We provide a way to compare the effects of NGC on an average degree of uncertainty between NC and NC. The NGC also presents a comprehensive (but not necessarily comprehensive) review of the evidence (or, more appropriately, more general) of NC on its own.", "histories": [["v1", "Fri, 12 Jul 2013 12:28:38 GMT  (40kb)", "https://arxiv.org/abs/1307.3435v1", "On raven paradox, Nicod's condition, projectability, induction"], ["v2", "Tue, 16 Jul 2013 02:22:09 GMT  (32kb)", "http://arxiv.org/abs/1307.3435v2", "On raven paradox, Nicod's condition, projectability, induction"]], "COMMENTS": "On raven paradox, Nicod's condition, projectability, induction", "reviews": [], "SUBJECTS": "cs.AI", "authors": ["hadi mohasel afshar", "peter sunehag"], "accepted": false, "id": "1307.3435"}, "pdf": {"name": "1307.3435.pdf", "metadata": {"source": "CRF", "title": "On Nicod\u2019s Condition, Rules of Induction and the Raven Paradox", "authors": ["Hadi Mohasel Afshar", "Peter Sunehag"], "emails": ["hadi.afshar@anu.edu.au", "peter.sunehag@anu.edu.au"], "sections": [{"heading": null, "text": "ar X\niv :1\n30 7.\n34 35\nv2 [\ncs .A\nI] 1\n6 Ju\nKeywords\nNicod\u2019s condition (NC), Raven paradox, weak projectability (PJ), reasoning by analogy (RA), inductive inference."}, {"heading": "1 Introduction", "text": "In this article, we study induction and in particular Nicod\u2019s Condition (NC) from a Bayesian (in the sense of subjective probability) point of view. Rules of induction can be thought of as such restrictions on the class of probability measures (or equivalently, on the class of rational agents1 ).\nThe question is: \u201cHow can we agree that any particular rule of induction is plausible and generally entails sensible consequences and therefore should be accepted a priori?\u201d. We are interested in a specific rule, namely NC which informally speaking states that \u201cA proposition of the form All F are G is supported by the observation that a particular object is both F and G\u201d [Hem45]. Does the fact that NC, does not seem to be counterintuitive suffice to persuade us that it is a plausible rule of induction? How can we be sure that it does not violate other intuitively acceptable rules and principles? As the notorious raven paradox [Hem45] shows, NC actually does entail counterintuitive consequences, and more than seven decades of discussion about this paradox shows that assessment of rules of induction can be extremely problematic.\nA summary of the raven paradox is as follows: The hypothesis H := \u201cAll ravens are black\u201d is logically equivalent to H\u0302 := \u201cEvery thing that is not black is not a raven\u201d. A green apple is neither black nor a raven therefore according to NC its observation should confirm H\u0302. But H is logically equivalent to H\u0302 , so we end up with a Paradoxical Conclusion (PC), that an observation of a green apple confirms that all ravens are black, which is counterintuitive. In order to resolve the paradox, either it should be shown that NC is not a plausible rule of induction or it should be claimed that PC holds and should not be considered as being counterintuitive.2\nIn order to study the paradox from a Bayesian perspective, first we make a distinction between (objective) background knowledge by which we exclusively refer to the knowledge that can be represented (and consequently can be thought of) as previously observed events, and any other kinds of information which we consider as being subjective and a property of the a priori chosen probability measure (i.e. the initial degrees of beliefs). The cogency of inductive rules is significantly affected by the given background knowledge and the chosen measures. For example, it is already known that relative to some background knowledge, NC violates intuition (e.g. see [Goo67]). In Section 2.1, we argue that relative to unrestricted background knowledge, not only NC but any rule of induction can be refuted. Hempel himself believed that NC and the raven paradox should be considered in the context of absolutely no background information [Hem67]. From a Bayesian perspective,\n1 The term rational agent (that is, the performer of induction), as used in fields such as decision theory and artificial intelligence [RN03], by definition, refers to an agent that satisfies certain consistency axioms (see [Sav54]). Representation theorems show that this implies that the agent has a probability distribution representing a priori beliefs for what will happen and utilities for the various possible outcomes, such that decisions can be explained as maximizing expected utility. Given utilities we can from simpler axioms [SH11] infer the existence of a probability distribution.\n2Some authors have even denied the equivalence of H and H\u0302 [SG72].\nhowever, this does not solve the problem. The reason is that background knowledge and priors are convertible (in the sense that they can produce the same effects). For example if we are not allowed to consider NC in the context that we possess the background knowledge that \u201can object a has a property F\u201d (denoted as: Fa), we can (approximately) produce the same situation by subjectively believing that the probability that that object has the property F , is sufficiently close to 1 (denoted as: pr(Fa) \u2248 1).\n3,4 Therefore, if we want to restrict ourselves to the context of perfect ignorance, not only should we possess no objective knowledge, we should also only be permitted to reason based on an absolutely unbiased probability measure. This raises an important question: \u201cWhat is an unbiased measure?\u201d Due to its subjective nature, this question does not have a definitive answer but by far, the most widely considered choice is the uniform measure.5,6 On the other hand, it is well known that using the uniform measure, inductive learning is not possible [Car50]. This shows that from the subjective probabilistic perspective, choosing a probability measure that satisfies the condition of perfect ignorance and allows inductive learning, is arguably impossible.\nIt is also notable that demonstrating that a specific probability measure does (or does not) comply with a rule of induction (or a statement such as PC), does not illuminate the reason why a typical human observer believes that such a rule (or statement) is implausible (or plausible). Conversely, one might argue that compliance of a probability measure with a counterintuitive statement such as PC, may\n3 According to Cournot\u2019s principle [Cou43], we do not allow 1 (or 0) priors for events that may or may not happen. If it was allowed then assuming pr(Fa) = 1, would exactly produce the same effect that possessing the background knowledge \u201ca is F\u201d would. This would be problematic, because assigning probability 1 to the events that are not determined (by background knowledge) may lead to undefined conditional probabilities (in case the complement events occur). However, assigning a probability that is arbitrarily close to one (i.e. pr(Fa) \u2248 1) does not cause such a problem while it approximately produces the effect of the same background knowledge to arbitrary precision.\n4 Although for Hempel and his contemporaries, the confirmation theory was (more or less) a logical relation, akin to deductive entailment, rather than a probabilistic relation (in the formal sense) [FH10], what we mentioned about the convertibility of objective information and subjective beliefs, was in a way reflected in their discussions: Good\u2019s Red Herring [Goo67] provided a hypothetical objective background setting with respect to which, NC does not hold. Hempel\u2019s assertion that \u201cNC should be considered in the context of no (objective) background information\u201d was in fact an attempt to address such an issue. However, nothing could prevent Good from producing the same effect by simply replacing the objective information with subjective a priori beliefs of a new born baby (Good\u2019s baby [Goo68]).\n5 The main justification is due to the principle of maximum entropy [Jay03]. This principle recommends that one choose, among all the probability measures satisfying a constraint, the measure which maximizes the Shannon entropy. In the absence of any background knowledge (i.e. no constraint), the uniform probability measure maximizes entropy.\n6 An alternative to the uniform measure is Solomonoff\u2019s theory of universal inductive inference [Sol64] which mathematically formalizes and puts together Occam\u2019s razor (the principle that the simplest model consistent with the background knowledge should be chosen) and Epicurus\u2019 principle of multiple explanations (that all explanations consistent with background knowledge should be kept) (see [Hut07] or [RH11]).\nsuggest that this measure does not provide a suitable model for inductive reasoning. As an example, consider the following two works: [Mah99] and [Mah04]. They are among the most famous answers to the raven paradox. Using Carnap\u2019s measure [Car80], in 1999 Maher argued that both NC and PC hold. In 2004 he suggested a more complex measure that led to opposite results: Maher showed that for this latter measure, neither NC nor PC holds in all settings. Although Maher\u2019s works successfully show that at least for one probability measures NC holds and for another probability measures it does not, they do not show whether NC and PC are generally plausible or not.\nThe mainstream contemporary Bayesian solutions are not restricted to a particular measure and in this sense, are more general. According to [FH06] almost all of them accept PC and argue that observation of a non-black non-raven does provide evidence in support of H ; however, in comparison with the observation of a black raven, the amount of confirmation is very small. This difference, they argue, is due to the fact that the number of ravens is much less than the number of non-black objects. However as [Vra04] explains, these arguments have only been able to reach their intended conclusion by adding some extra assumptions about the characteristics of the chosen probability measure. He shows that the standard Bayesian solution relies on the almost never explicitly defended assumption that \u201cthe probability of H should not be affected by evidence that an object is non-black.\u201d \u2013 a supposition that he believes, is implausible, i.e. may hold or not.\nTo summarize the above discussion: the general plausibility of a rule of induction cannot be determined if we restrict our study to particular (objective) background knowledge or a particular probability measure. On the other hand, no rule of induction holds in the presence of an unrestricted choice of background knowledge and probability measure. We conclude that rules of induction should be studied for different classes of background knowledge and priors. If a rule of induction holds relative to a large class of reasonable background knowledge (i.e. information similar to our actual configuration of knowledge obtained from observations that often take place in real life) and relative to reasonable probability measures (i.e. measures that have intuitively reasonable characteristics e.g. comply with other rules of induction which are more directly justified by our intuitive notion of induction), then we can claim that the studied rule is plausible, otherwise we cannot.\nIn this paper, we study NC with such an approach. In Section 2, we present a formal representation for three rules of induction, namely, projectability (PJ), reasoning by analogy (RA) and Nicod\u2019s condition (NC). We also define the form of background knowledge that is studied throughout the paper. Informally speaking, we only study pieces of knowledge that do not link the properties of one object to another object. They can be though of as knowledge that can be gained directly by observing the properties of some distinct objects. For example, the background knowledge: \u201cif object a is a raven, then object b is not a raven\u201d, is not of this form. While one can easily constitute pieces of information that do not have such a form and violate the aforementioned rules of induction, we have not found any\nilluminating counterexample to the assumption that relative to a piece of information that does not link properties of distinct objects together, PJ and RA comply with intuition. In the case of NC, we are more inquiring. In the next two sections, we study the restrictions of the probability measures that guarantee the validity of NC relative to two more specific background configurations (that can be expressed in the mentioned form). In Section 3, we find some sufficient conditions for the validity of NC and some sufficient conditions for its invalidity, relative to information about the kind (i.e. being raven or not) and color (i.e. being black or not) of some objects. The sufficient condition that we present for the validity of NC is less restrictive. However, this is insufficient for claiming that in this setting NC is generally plausible. Section 4 deals with the setting where the exact number of objects having one property is known. For example we know how many ravens (or how many non-black objects) exist. We show that in this setting, measures that comply with Nicod\u2019s condition, do not always comply with PJ which seems to be the simplest formalization of inductive inference. It is also shown that in the case of contradiction, intuition (arguably) follows PJ rather than NC. We think that this result is both interesting and somewhat surprising and should be considered as a main contribution of this paper.\nOne limitation of our basic setup is that it limits us to a universe with an arbitrary but known size. However, in Section 5, this strong assumption is replaced by the weaker assumption that there is a probability distribution over the possible sizes of the universe and this distribution is not affected by an observation of a single object. We show that under this weaker assumption, the results from the former sections remain valid.\nIn Section 6, we summarize the paper and conclude that there is a tension between NC and our intuitive notion of inductive reasoning. We also suggest that reasoning by analogy provides a viable alternative to formalize the seemingly intuitive statement that \u201cthe observation that a particular object is both F and G confirms the hypothesis that any object that is F is also G\u201d without suffering form the shortcomings of NC. All theorems are proven in Section 7."}, {"heading": "1.1 Notation, Basic Definitions and Assumptions", "text": "Throughout sections 2 to 4 we work with a first-order language L whose only nonlogical symbols are a pair of monadic predicates F and G and a set of constants U (officially shown as) {u1, u2, . . . , uN} where N is a known positive integer. However, for simplicity we drop \u201cu\u201d and refer to each constant by its index. We rely on the domain closure axiom [Rei80], that is:\n\u2200x (x = 1) \u2228 (x = 2) \u2228 . . . \u2228 (x = N) (1.1)\nwhere 1 to N are distinct constants i.e. (1 6= 2) \u2227 (1 6= 3) \u2227 . . .. Clearly, models of this axiom are restricted to interpretations with domains containing exactly N distinct individuals (objects) each of which is denoted by a constant in U . Using\nthis bijection between the elements of the domain and constants, we refer to U as the universe.\nNegation, conjunction, disjunction and material implication are respectively represented by \u201c\u00ac\u201d, \u201c.\u201d (or \u201c\u2227\u201d), \u201c\u2228\u201d and \u201c\u2192\u201d. If b is an individual and \u03c8 is a 1-place predicate (either atomic or a sentential combination of atomic predicates), \u03c8b is defined as a proposition that involves predicate \u03c8 and indicates: \u201cb has (or satisfies or is described by) \u03c8\u201d. Conjunction of several propositions \u03c8m, \u03c8m+1, . . . , \u03c8n is abbreviated by \u03c8m:n. By definition, for n < m, \u03c8m:n := \u22a4 (i.e. tautology) and \u03c8m:m := \u03c8m. More generally, if bm to bn are some objects (not necessarily consecutive), \u03c8bm:bn := \u03c8bm\u2227 . . . \u2227 \u03c8bn . The general hypothesis H := (\u2200x F\u2192Gx) (which is equivalent to F\u2192G1:N) where F\u2192Gb := Fb \u2192 Gb. We also let:\nF\u0304G\u0304b := \u00acFb.\u00acGb; F\u0304Gb := \u00acFb.Gb; FG\u0304b := \u00ac(F\u2192Gb) = Fb.\u00acGb; FGb := Fb.Gb (1.2) Any of F\u0304G\u0304b to FGb defined by relation (1.2) is referred to as a complete description of an object b.7 For example if F and G represent \u201cravenhood\u201d and \u201cblackness\u201d properties respectively, then F\u0304G\u0304b means \u201cb is not a raven and is not black\u201d and so on. F\u2192Gb means \u201cif b is a raven then it is black\u201d and H is the general hypothesis that \u201cfor all b, if b is a raven then it is black\u201d. Clearly all complete descriptions which provide counterexample to H are in the form FG\u0304b.\nWe define \u2206 as the set of all propositions \u03c1 which are in the following form (or by simplification can be converted to it):\n\u03c1 := \u03c81b1 .\u03c8 2 b2 . . . . \u03c8kbk =\nk \u2227\nx=1\n\u03c8xbx (1.3)\nwhere \u03c81 to \u03c8k are some predicates in {F , \u00acF , G, \u00acG, F\u0304G\u0304, \u00acF\u0304G\u0304, F\u0304G, \u00acF\u0304G, FG\u0304, F\u2192G, FG, \u00acFG} and b1 to bk are some mutually distinct objects: {b1, b2, . . . bk} \u2286 U . Note that \u2206 is in fact the set of all propositions that do not link the properties of different objects together. We define the set of all individuals described by \u03c1 as: I\u03c1 := {b1, b2, . . . bk}. We refer to the set of (simple) predicates involved in \u03c1 by: A\u03c1 := {\u03c8\n1, . . . , \u03c8k}. For example, the proposition \u03c1\u2032 := FG1 \u2228 FG\u03043 is not in \u2206 but \u03c1\u2032\u2032 := FG1.FG3.F\u2192G4 \u2208 \u2206 (assuming N \u2265 4). I\u03c1\u2032\u2032 = {1, 3, 4} and A\u03c1\u2032\u2032 = {FG, F\u2192G}. By definition, empty (or tautologous) proposition \u22a4 is a member of \u2206 with I\u22a4 = \u2205. Two subsets of \u2206 are defined as follows:\n\u03b4 := { d \u2208 \u2206 : Ad = {F\u0304G\u0304, F\u0304G, FG} }\n\u2126 := { d \u2208 \u2206 : Id = U,Ad = {F\u0304G\u0304, F\u0304G, FG\u0304, FG} }\nInformally speaking, \u03b4 is the set of propositions that completely describe some individuals and do not falsify H . Likewise, \u2126 is the set of propositions that completely\n7 F\u0304G\u0304, F\u0304G, FG\u0304 and FG are what Maher calls Q4, Q3, Q2 and Q1 respectively. What we call complete description, he calls sample proposition [Mah99].\ndescribe all objects of the universe. We refer to any member of \u2126 as a Complete Description Vector (CDV). Note that each CDV corresponds to a unique model or world (up to isomorphism). In other words, every interpretation that makes a CDV (and aforementioned axiom (1.1)) true, uniquely determines the value of any sentence in L,8 therefore we can consider them as (representatives of) different worlds. The probability measures which we are concerned with, are defined over the sample space \u2126 with the power set as \u03c3-algebra. No other restriction is imposed on the choice of measure unless it is mentioned explicitly. For each proposition \u03c1, let \u03c9\u2126\u03c1 := {o \u2208 \u2126 : o |= \u03c1} be the set of all CDVs that entail \u03c1. We say that the event \u03c9\u2126\u03c1 corresponds to the proposition \u03c1 (and vice versa). For convenience\u2019 sake, except in Section 5, we represent the probability of events by the probability of their corresponding propositions9; formally, for propositions \u03c1, we let pr(\u03c1) := pr(\u03c9\u2126\u03c1 ). According to Cournot\u2019s principle [Cou43], we do not allow 1 (resp. 0) priors to the sentences that are not valid (resp. unsatisfiable).\nObjective background knowledge (or simply background knowledge) is what we are certain about and can be represented by a subset of \u2126. The more formal definition of the background setting studied throughout this paper and its corresponding restrictions are given in Section 2.1.\nWe equate \u201cinductive support\u201d with \u201cprobability increment\u201d: It is said that in the presence of background knowledge D, evidence E confirms hypothesis H iff:\npr(H|E.D) > pr(H|D)\nWe are only interested in the case where E and D are consistent, pr(E) and pr(D) are positive and E is not determined by D, i.e. 0 < pr(E|D) < 1."}, {"heading": "2 Inductive Reasoning and Nicod\u2019s Condition", "text": "The fundamental assumption behind inductive inference is the so-called principle of the uniformity of nature [Hum88] (or the immutability of natural processes [Pop59]) based on which, uniformity and trend are more probable than diversity and anomaly a priori. Let us assume that \u2206 is a set of background knowledge configurations for which we \u201cintuitively\u201d expect that inductive inference holds (for more discussion refer to Section 2.1). Relative to pieces of information in \u2206, we present the following varieties of inductive inference (i.e. inductive rules):\n8 The proof is straightforward. With respect to the domain closure axiom, all quantifiers are bounded. Therefore all sentences are convertible to quantifier-free forms and consequently convertible to full disjunctive normal form (DNF) which is in fact a disjunction of some CDVs. In any world, only one CDV is true, therefore only sentences containing that CDV (when expressed in full DNF) are true.\n9 In Section 5, we simultaneously deal with more than one sample space. While w.r.t. different sample spaces, propositions may correspond to different events, in that section we directly represent probability events by their relevant sample space subsets.\nProjectability. For all objects a and b and background knowledge D \u2208 \u2206 that does not determine \u03c8a or \u03c8b, based on [Mah04], one (and apparently the simplest) kind of inductive inference, namely projectability10,11, is defined as follows:\nStrong projectability: \u2200a, b \u2208 U pr(\u03c8b|\u03c8a.D) > pr(\u03c8b|D)\nWeak projectability (PJ): \u2200a, b \u2208 U pr(\u03c8b|\u03c8a.D) \u2265 pr(\u03c8b|D) (2.1)\nProjectability (relative to predicate \u03c8) can be justified as follows: The evidence \u03c8a increases the proportion of the observed individuals that have the predicate \u03c8. Thus, according to the principle of the uniformity of nature, the estimated frequency of the predicate \u03c8 in the total population should also be increased because the uniformity between the characteristics of the sample and the total population is considered to be likely.\nReasoning by Analogy (RA). The observation that two individuals have some common properties, increases the probability that their unobserved properties are also alike, because it is likely that there is a uniformity between the characteristics of unobserved properties and the observed ones. Maher has formalized one variation of reasoning by analogy (or inference by analogy [Car50]) as: \u2200a, b \u2208 U pr(Gb|Fb.FGa) > pr(Gb|Fb) [Mah04]. We generalize the relation to cover the case where background knowledge D \u2208 \u2206 (that does not determine the value of Fa, Ga and Gb) is also present:\nReasoning by analogy (RA): \u2200a, b \u2208 U pr(Gb|Fb.FGa.D) > pr(Gb|Fb.D) (2.2)\nNicod\u2019s Condition (NC). For U := {1, . . . , N}, H := F\u2192G1:N , all a \u2208 U and D \u2208 \u2206 that does not determine the value of FGa or H , we say NC holds for D iff:\nNicod\u2019s Condition (NC): pr(H|FGa.D) > pr(H|D) (2.3)\nNC is stronger than PJ or RA in the sense that it deals with the confirmation of a generalization rather than a singular prediction. In other words, NC is a form of enumerative induction but PJ and RA are forms of singular predictive inference."}, {"heading": "2.1 Restrictions on the Background Knowledge", "text": "Obviously, relative to unconstrained background knowledge, no rule of induction holds in general. For example, in the presence of background knowledge D\u2032 := F1 \u2192 (\u00acF )2:N , at least relative to evidence F1, PJ does not hold. Similarly, (as\n10 According to [Car50] predictive inference (i.e. inference from a sample to another sample) is the most important kind of inference and the most important special kind of it, singular predictive inference, is inference from a sample to an individual object. Maher\u2019s projectability is in fact a special kind of singular predictive inference: inference from one individual to another individual.\n11Maher\u2019s original relation does not mention background knowledge, and only deals with strong projectability (which he calls absolute projectability).\n[Mah04], Theorem 12 formally shows), in the presence of background knowledge D\u2032\u2032 := FG1 \u2192 \u00acH , NC does not hold (for evidence FG1).\nTo prevent such problems, the biggest set of background configurations studied through out this paper is \u220612, which according to its definition in Section 1.1, is the set of all consistent propositions that can be expressed in the form of a conjunction of some propositions that involve F , G, F\u0304G\u0304, F\u0304G, FG\u0304, FG or their negations.\nObviously, each member of \u2206 can be expressed in the form of a conjunction of some propositions each of which describes only one individual. Consequently, problematic statements that interlink properties of different individuals are not expressible. As an example, the mentioned pathological examples D\u2032 and D\u2032\u2032 are not in \u2206.\nIn the case of PJ and RA, we did not find a pathological example in \u2206, relative to which, the rule of induction contradicts intuition. However, in the case of NC it is already claimed that relative to background knowledge D\u2032\u2032\u2032 := \u00acFa \u2208 \u2206, it is not intuitively sound to expect that the evidence F\u0304G\u0304a confirms H [FH10]. In Sections 3 and 4, we will investigate the validity of NC relative to two interesting subsets of \u2206."}, {"heading": "2.2 Restrictions on the probability measure.", "text": "In Section 3 (Setting 1), we impose no restriction on the choice of the probability measure but in Section 4 (Setting 2), we assume that the probability measure is exchangeable [Car80] in a sense that probabilities are not changed by permuting individuals (i.e. swapping the name of objects). To introduce this restriction formally, we need the following definitions:\nDefinition. By the term permutation, we always refer to a bijection from a set of all objects U to itself. Throughout this paper, we denote any arbitrary permutation by \u03c0 (or \u03c0\u2032 and \u03c0\u2032\u2032 when we deal with more than one permutation). Having a proposition \u03c1, the proposition \u03c1\u03c0 is obtained from \u03c1 by replacing any occurrence of any individual b with \u03c0(b).\nExample 1. If U := {1, 2, 3}, the function \u03c0 : U \u2192 U defined by \u03c0(1) = 1; \u03c0(2) = 3 and \u03c0(3) = 2, is a permutation with a fixed point 1. For short we write \u03c0 := {2/3; 3/2}. If we define \u03c1 := F1 \u2228G3, then \u03c1 \u03c0 = F1 \u2228G2. \u2666\nExchangeability. The probability measure pr is exchangeable if for all propositions A and B and all permutations \u03c0, pr(A|B) = pr(A\u03c0|B\u03c0).\n12 Note that we do not claim that no background knowledge that is not a member of \u2206 is not plausible. Investigation of rule of inductions relative to such knowledge, is simply beyond the scope of this paper."}, {"heading": "3 Validity of NC when Background Knowledge", "text": "Consists of Complete Descriptions of Some In-\ndividuals (Setting 1)\nIn Section 1.1, \u03b4 was defined as the set of all background knowledge that do not refute H and describe some individuals completely (e.g. in the case of the raven paradox, members of \u03b4 represent the knowledge that we are already aware of the color and kind (i.e. the state of being raven) of some individuals and none of these known objects have been a non-black raven). Clearly, \u03b4 \u2282 \u2206. Theorem 3.1 shows that if the chosen probability measure satisfies some conditions, then for any background knowledge D \u2208 \u03b4, NC holds (for predicates F and G). On the other hand, Theorem 3.2 shows that under alternative conditions, for some D \u2208 \u03b4, NC does not hold.\nTheorem 3.1. If a probability measure complies with the following relation:\n\u2200B \u2208 \u2206, \u2200a, b /\u2208 IB pr(FG\u0304b|FGa.B) \u2264 pr(FG\u0304b|B) (3.1)\nthen, for this measure and any D \u2208 \u03b4 that does not determine FGa or H , NC holds, i.e. relation (3.1) entails: pr(H|FGa.D) > pr(H|D).\nExample 2. If background knowledge consists of complete descriptions of some individuals, by Theorem 3.1 for all pairs of predicates F and G, the uniform measure complies with NC since regardless of the interpretation of F and G, for this measure, \u2200B \u2208 \u2206 & \u2200a, b /\u2208 IB pr(FG\u0304b|FGa.B) = pr(FG\u0304b|B). This is not surprising since using this measure, learning is impossible (see [Car50]). This means that no observation changes the probability of being FG\u0304 for an unobserved object. Nonetheless, for this measure NC is valid because any evidence in the form of F\u0304G\u0304a, F\u0304Ga or FGa confirms H for the simple reason that it removes the possibility that the observed object (i.e. a) is a counterexample to H . \u2666\nExample 3. In Carnap\u2019s theory of inductive probability [Car80]:\npr(\u03c8b|E) = n\u03c8 + \u03bb \u00b7 pr(\u03c8b)\nn + \u03bb\nIn the above relations, n is the number of objects mentioned by evidence E; n\u03c8 is the number of mentioned objects which satisfy predicate \u03c8, and \u03bb is a constant measuring the resistance to generalization. Note that b should not be mentioned by E, i.e. b 6\u2208 IE . Using this measure and choosing \u03c8 \u2208 {F\u0304G\u0304, F\u0304G, FG\u0304, FG}, in the presence of background knowledge D \u2208 \u03b4 such that a, b /\u2208 ID: pr(FG\u0304b|FGa.D) = \u03bb.pr(FG\u0304b|D)\n1+\u03bb < pr(FG\u0304b|D). Thus by Theorem 3.1, for the class of background knowledge in the form of conjunction of some F\u0304G\u0304, F\u0304G and/or FG for distinct individuals, this measure complies with NC. This is equivalent to the setting chosen by [Mah99] and its corresponding results. \u2666\nTheorem 3.2. If a probability measure complies with restrictions (3.2) and (3.3), then for this measure (and predicates F and G) and background knowledge D \u2208 \u03b4, NC does not hold.\n\u2200B\u2208\u2206, \u2200a, b /\u2208 IB pr(FG\u0304b|FGa.B) > pr(FG\u0304b|B) (3.2)\n\u2200a /\u2208ID pr(\u00acF\u2192Ga|F\u2192Gb1: bn .D) < pr(FG\u0304b1 |FGa.D)\u2212 pr(FG\u0304b1 |D) (3.3)\nIn the above relations a 6= b and b1 to bn represent an arbitrary enumeration of all individuals (except a) that are not mentioned by D (that is, ID = U\\{b1 . . . bn, a}).\nAccording to restriction (3.3), the probability that a is not F\u2192G given that all other objects in the universe are F\u2192G should be less than the degree of confirmation by evidence FGa of a hypothesis that an unobserved object b1 is FG\u0304. Note that b1 can be the index of any unobserved object.\nExample 4. [Mah04] proposes a measure based on the formula:\npr(FG\u0304b|E) = pr(I) \u00b7 nF + \u03bb \u00b7 pr(Fb) n+ \u03bb \u00b7 nG + \u03bb \u00b7 pr(\u00acGb) n+ \u03bb + pr(\u00acI) \u00b7 nFG\u0304 + \u03bb \u00b7 pr(FG\u0304b) n+ \u03bb\nIn the above relation, n is the number of objects mentioned by E; nF and nG denote the number of mentioned objects which are F and \u00acG respectively. In this expression, the prior probability of FG\u0304 i.e. pr(FG\u0304b) has to be equal to pr(Fb) \u00b7 pr(\u00acGb) and pr(I) and \u03bb are parameters. Maher proposes a counterexample for NC where N = 2 (Let U := {a, b}), \u03bb = 2, pr(I) = 0.5 and prior probabilities are pr(Fb) = 0.001 and pr(Gb) = 0.1. This conclusion can be confirmed independently by Theorem 3.2 as follows: 1. For these parameters, the only member of \u2206 that does not contain a and b, is B = \u2205 for which relation (3.2) holds if pr(Fb) < 0.25. 2. By assuming: ( pr(FG\u0304b|FGa)\u2212pr(FG\u0304b) )\n\u2265 0.06 and pr(Gb) = 0.1, a cumbersome calculation shows that (for empty background knowledge) relation (3.3) holds if: pr(Fb) < 0.0983 which covers Maher\u2019s proposed configuration. \u2666\nComparing Theorems 3.1 and 3.2 shows that creating a probability measure that contradicts NC (w.r.t. D \u2208 \u03b4) is harder than making a measure that complies with it (for the same background setting) because the former measure has to satisfy more constraints. The reason is that even if in a measure, evidence E := FGa does not affect the probability of FG\u0304 for unobserved objects (as in the case of the uniform distribution), every hypothesis that is not refuted by E (including H) is confirmed by it since the observation has reduced the number of possible counterexamples by one. On the other hand, in the case of a measure that does not comply with NC, not only should E confirm FG\u0304 for unobserved objects, but the effect of this confirmation should be so substantial that it overwhelms the effect of the elimination of one counterexample to H .13 However, in the case where the size of the universe\n13 To see how the effect of elimination of one possible counterexample leads to relation (3.3), refer to the proof of Theorem 3.2 in Section 7.\nis large, the latter effect should be minute. This is reflected in relation (3.3) as follows: If N is large, then at least for measures that comply with projectability, pr(\u00acF\u2192Ga|F\u2192Gb1: bn .D) \u2248 0, because if it is known that all objects in the universe except a are F\u2192G, then it should be quite probable that a is F\u2192G too. Therefore, even if the degree of confirmation of FG\u0304b1 by evidence FGa (i.e. pr(FG\u0304b1|FGa.D)\u2212 pr(FG\u0304b1 |D)) is very small 14 , relation (3.3) holds.15 To summarize:\n\u2022 If regardless of the choice of background knowledge, an observation Fa.Ga does not confirm that any unobserved individual is an F that is not G, then relative to any background knowledge in \u03b4, NC holds.\n\u2022 If regardless of the choice of background knowledge, an observation Fa.Ga confirms that any unobserved individual is an F that is not G, and on the other hand, the effect of elimination of one counterexample via an observation is\nnegligible, then relative to any background knowledge in \u03b4, NC does not hold.\nThe above statements delegate the assessment of NC (a form of enumerative induction) to the assessment of expressions which deal with singular predictions. Hence, a new perspective on the nature of NC is provided: Should regardless of the interpretation of F and G, (the observation of) an F that is G disconfirm that any unobserved object is F but not G?\nFor example, relative to background knowledge and a probability measure that reflect our actual configuration of knowledge, should the observation of an F=\u201cwalnut\u201d that is G=\u201cround\u201d decrease the probability that any unobserved object is a walnut but not round? Indeed yes; therefore by Theorem 3.1, in this case and for these predicates, NC holds. Should the observation of an F=\u201cround\u201d, G=\u201cwalnut\u201d decrease the probability that any unobserved object is \u201cround\u201d but not a \u201cwalnut\u201d? Arguably not. Should the observation of an F=\u201cogre\u201d which is G=\u201cold\u201d decrease the probability that we might encounter an ogre which is not old? Definitely not! 16 Therefore, in\n14 Note that by relation (3.2), this degree of confirmation is positive. 15 Here is another justification for the above argument: By definition, a probability measure defined over a first-order language with an infinite domain is Gaifman iff the probability of the generalization of any predicate (in our case, F\u2192G) is equal to the probability of the conjunction of some positive instances when their number tends to infinity [GS82] or alternatively, pr(\u2200x \u03c8x|\u03c81:n) n\u2192\u221e \u2212\u2212\u2212\u2212\u2192 1 (see [HLNU13] thm. 27) and consequently pr(\u00ac\u03c8a|\u03c81:n) n\u2192\u221e \u2212\u2212\u2212\u2212\u2192 0. Since the Gaifman condition is what we intuitively expect from generalization over an infinite universe, it can be considered as a very simple and intuitive rule of induction. In our case, if the universe was infinite and the measure was assumed to be Gaifman, inequality (3.3) would always hold. However we have assumed that the universe is finite therefore we cannot remove this inequality. What we can say is that for very large domains, relation (3.3) is a very weak condition.\n16 This confirmation asymmetry may be due to possible asymmetry in background knowledge and/or prior possibilities of different predicates. For example according to our actual configuration of knowledge, the prior probability of \u201cbeing an ogre\u201d (for any individual) is quite low. This is a key point in the existing arguments: Good\u2019s baby [Goo68] (that assigns low probability to ravenhood) and Maher\u2019s unicorn [Mah04]. But unlike our discussion, these arguments do not reduce the assessment of NC to a singular prediction.\nthis case, we are intuitively using a probability measure that satisfies the condition (3.2). Now assume that we have seen all objects of the world except one. It has happened that any observed object that has been an ogre has been old as well. Is it reasonable to believe that it is improbable that the last unobserved object is a young ogre? If yes, then our intuitive measure also complies with restriction (3.3), hence by Theorem 3.2, by this denotation for F and G, plausible probability measures do not comply with Nicod\u2019s condition."}, {"heading": "4 NC vs. PJ when the Number of Objects having", "text": "One Predicate is Known (Setting 2)\nThis section studies NC in the presence of a completely different background setting where we know that exactly k individuals are F (e.g. ravens) and the rest are not F , but we do not know anything about the other property (e.g. their color).\nFirst we focus on a simpler setting where we know exactly which objects are F and which objects are not F (e.g. we know that objects 1 to k are F and the rest of the universe i.e. objects k + 1 to N are not F ).\nTheorem 4.1. For U := {1, 2, . . .N} and D := F1:k.(\u00acF )k+1:N , weak projectability (PJ) entails:\npr(H |Gk . D) > pr(H|D) (4.1)\npr(H |GN . D) \u2265 pr(H|D) (4.2)\npr(H | \u00acGN . D) \u2264 pr(H|D) (4.3)\nand reasoning by analogy (RA) entails:17\npr(H |Gk . D) > pr(H|D) (4.4)\nNext, we show that these results are valid in the general setting where the background knowledge is such that we only know the exact number of objects being F but we do not know their names. In other words, we know that exactly one combination of k out of N objects of the universe are F but we do not know which combination. But before that, we should formalize such knowledge in the form of an event (i.e. a subset of the sample space).\nDefinition. CU,k := {C : C \u2286 U, |C| = k} is defined as the set of all (distinct) subsets of U which contain exactly k individuals. Obviously, the cardinality of CU,k is ( N\nk\n)\n.\n17 Therefore, in this setting both PJ and RA suggest thatH := \u2200b F\u2192Gb is confirmed by evidence Gk but RA provides no answer whether or not evidence GN should confirm (or disconfirm) H . The reason is that (as the proof of the theorem which is provided in Section 7 shows) in the presence of background knowledge F1:k.(\u00acF )k+1:N , validity of H only depends on property G of objects 1 to k that do not have a common property with object N .\nExample 5. Given U := {1, 2, 3, 4}, CU,2 = {\n{1, 2}, {1, 3}, {1, 4}, {2, 3}, {2, 4}, {3, 4} } . \u2666\nDefinition. For 1 \u2264 k \u2264 N , \u201cExactly k objects of the universe U are F\u201d is formally defined as follows:\nExact(k, U, F ) := \u2228\nC\u2208CU,k\n(\n\u2227\nb\u2032\u2208C\nFb\u2032 . \u2227\nb\u2032\u2032 6\u2208C\n\u00acFb\u2032\u2032 )\n(4.5)\nExample 6. In the previous example, Exact(2, U, F ) = (F1.F2.\u00acF3.\u00acF4) \u2228 (F1.F3.\u00acF2.\u00acF4) \u2228 (F1.F4.\u00acF2.\u00acF3) \u2228 (F2.F3.\u00acF1.\u00acF4) \u2228 (F2.F4.\u00acF1.\u00acF3) \u2228 (F3.F4.\u00acF3.\u00acF4). \u2666\nBy comparing definition (4.5) with the definition of \u2206, it becomes clear that for 1 < k < N , Exact(k, U, F ) 6\u2208 \u2206, therefore we do not expect that in the presence of such background knowledge, rules of induction hold in general and they actually don\u2019t. For instance, knowing that exactly k objects are F , the evidence that a particular object is F , confirms that any other object is not F ,18 which contradicts PJ:\n(intuitively): \u2200b 6= a \u2208 U pr ( Fb|Fa.Exact(k, U, F ) ) < pr ( Fb|Exact(k, U, F ) )\nHowever, the following theorem shows that for the hypothesis that we are interested in i.e. H := \u2200b F\u2192Gb, the background knowledge Exact(k, U, F ) is equivalent to F1:k.\u00acFk+1:N which is a member of \u2206. Therefore, in the case of the raven paradox and background knowledge Exact(k, U, F ), the rules of induction (that are assumed to hold relative to background knowledge in \u2206) should still hold.\nTheorem 4.2. If U = {1, . . . , N} and a is an arbitrary member of U and assuming that a probability measure pr is exchangeable:\npr ( H|Exact(k, U, F ) ) = pr ( H|F1:k.\u00acFk+1:N )\n(4.6)\npr ( H|Exact(k, U, F ).Fa.Ga ) = pr ( H|F1:k.\u00acFk+1:N .Gk )\n(4.7)\npr ( H|Exact(k, U, F ).\u00acFa.Ga ) = pr ( H|F1:k.\u00acFk+1:N .GN )\n(4.8)\npr ( H|Exact(k, U, F ).\u00acFa.\u00acGa ) = pr ( H|F1:k.\u00acFk+1:N .\u00acGN )\n(4.9)\nThe formal proof of this theorem is presented in Section 7.3, but the following simple example shows the main idea behind the general proof.\nExample 7. Having U := {1, 2, 3}, we show that: pr ( H|Exact(2, U, F ).F3.G3 ) = pr ( H|F1.F2.\u00acF3.G2 ) (that is relation (4.7) for a :=\n18 Suppose that you are in a camp populated by 100 captives, and it is known that 10 of them will be chosen randomly to be executed; Whenever someone except you is chosen, it is reasonable to be more optimist about your fate, for the simple reason that 9\n99 < 10 100 .\n3 and k := 2) as follows:\npr ( Exact(2, U, F ).F3.G3|H )\n= pr ( (F1.F2.\u00acF3 \u2228 F1.F3.\u00acF2 \u2228 F2.F3.\u00acF1).(F3.G3)|F\u2192G1.F\u2192G2.F\u2192G3 ) , by def.\n= pr(F1.F3.\u00acF2.G3 \u2228 F2.F3.\u00acF1.G3|F\u2192G1.F\u2192G2.F\u2192G3), by simplification\n= pr(F1.F3.\u00acF2.G3|F\u2192G1.F\u2192G2.F\u2192G3) + pr(F2.F3.\u00acF1.G3|F\u2192G1.F\u2192G2.F\u2192G3),\nby \u03c3-additivity of disjoint events (3rd Kolmogorov probability axiom)\n= pr(F1.F2.\u00acF3.G2|F\u2192G1.F\u2192G3.F\u2192G2) + pr(F1.F2.\u00acF3.G2|F\u2192G3.F\u2192G1.F\u2192G2),\nby exchangeability assumption, using premutation \u03c0\u2032 := {3/2; 2/3} on the first term and \u03c0\u2032\u2032 := {3/2; 1/3; 2/1} on the second term\n= 2 \u00b7 pr(F1.F2.\u00acF3.G2|H)\nSimilarly it can easily be shown that: pr ( Exact(2, U, F ).F3.G3 ) = 2 \u00b7 pr ( F1.F2.\u00acF3.G2 ) . Therefore by Bayes rule:\npr ( H|Exact(2, U, F ).F3.G3 ) = pr ( H ) \u00b7 pr ( Exact(2, U, F )|H )\npr ( Exact(2, U, F ) )\n= 2 \u00b7 pr(H) \u00b7 pr(F1.F2.\u00acF3.G2|H)\n2 \u00b7 pr(F1.F2.\u00acF3.G2) = pr(H|F1.F2.\u00acF3.G2)\nwhich is what we wanted to show by this example. \u2666\nTheorems 4.1 and 4.2 directly entail the main theorem of this section:\nTheorem 4.3. If Exact(k, U, F ) := \u201cexactly k objects (of the universe U) are F\u201d and a \u2208 U is an object, and the probability measure pr is exchangeable, weak projectability (PJ) entails:\npr ( H |Exact(k, U, F ).Fa.Ga ) > pr ( H |Exact(k, U, F ) )\n(4.10)\npr ( H |Exact(k, U, F ).\u00acFa.Ga ) \u2265 pr ( H |Exact(k, U, F ) )\n(4.11)\npr ( H |Exact(k, U, F ).\u00acFa.\u00acGa ) \u2264 pr ( H |Exact(k, U, F ) )\n(4.12)\nand reasoning by analogy (RA) assumption entails:\npr ( H |Exact(k, U, F ).Fa.Ga ) > pr ( H |Exact(k, U, F ) )\n(4.13)\nThe above relations seem to be compatible with intuition. While the total number of objects that satisfy F is known in advance, the consideration of Fa or \u00acFa should not affect our estimation of the frequency of the objects being F . On the other hand, the probability of G can still be affected by observations. Therefore, assuming PJ, consideration of Ga increases the probability of G and consequently decreases the probability of FG\u0304. As a result it seems reasonable that the evidence Ga confirms H = (\u00acFG\u0304)1:N , and the evidence \u00acGa disconfirms it.\nMoreover, an observation Fa.Ga has an extra effect: While it is known that only k objects can be counterexamples to H (because in order to be FG\u0304, one should be F ), the observation Fa.Ga decreases the number of possible counterexamples by one. This holds even in the case where the chosen measure is such that inductive reasoning is not possible (e.g. the uniform measure is used). Consequently, in (4.10) inequality is strict, but in (4.11) and (4.12) it is not. Theorem (4.3) implies the following results:\nCorollary 4.4. If F := raven and G := black, according to relation (4.10) (or 4.13), PJ (or RA) leads to: pr(H| (exactly k objects are ravens).(a specific object is raven and black)) > pr(H|exactly k objects are ravens)\nCorollary 4.5. If F := nonBlack & G := nonRaven w.r.t. relation (4.10) (or 4.13), PJ (or RA) leads to: pr(H|(exactly k objects are not black).(a specific object is nonBlack and nonRaven)) > pr(H| exactly k objects are not black)\nCorollary 4.6. If F := raven and G := black, w.r.t. (4.11), PJ leads to: pr(H|(exactly k objects are ravens).(a specific object is nonRaven and black)) \u2265 pr(H|exactly k individuals are ravens)\nCorollary 4.7. If F :=nonBlack & G:=nonRaven w.r.t. (4.11), PJ leads to: pr(H|(exactly k individuals are not black).(a specific object is black and not raven)) \u2265 pr(H|exactly k individuals are not black)\nCorollary 4.8. If F := raven and G := black, w.r.t. (4.12), PJ leads to: pr(H|(exactly k individuals are ravens).(a specific object is not raven and not black)) \u2264 pr(H|exactly k individuals are ravens)\nCorollary 4.9. If F := nonBlack & G := nonRaven, w.r.t. (4.12), PJ leads to: pr(H|(exactly k individuals are not black).(a specific object is black and raven)) \u2264 pr(H|exactly k individuals are not black)\nCorollaries (4.4) to (4.9) are summarized in (Table 1). NC, if assumed to hold in this setting, suggests that the observation of a non-black non-raven and the observation of a black raven (i.e. entries in the first and fourth rows of the table) should confirm H which clearly contradicts what PJ suggests, therefore, there is a tension between these two rules. When background knowledge is neglected, intuition goes with PJ in the first column of the table. On the other hand, it does not completely match the suggestions of either NC or PC in the second column. This may indicate that intuition is more inclined to the case where \u201cthe number of ravens\u201d and not \u201cthe number of non-blacks\u201d is known in advance. In real life, none of these numbers is known but the total number of ravens can be estimated much easier than the\nnumber of non-black objects. On the other hand, if we are explicitly informed of the total number of non-black objects, at least in cases similar to the following example, intuition seems to follow PJ\u2019s suggestions in the second column:\nImagine that you are only concerned about objects which are placed inside a bag (i.e. U := set of objects inside a bag). Also imagine that you are told that only 4 objects are not black. In this case, there are just four possible counterexamples to H . Now suppose that a green apple comes out of the bag. Since it is green, it is one of those 4 non-blacks. Therefore, one possible counterexample is removed. Meanwhile, the fact that it is a non-raven may increase the probability of non-ravenhood (w.r.t. PJ). Therefore it is more probable that the 3 remaining non-blacks are also nonraven. Thus, this observation should confirm H . Now suppose that a black raven comes out. Its color informs us that it is not among the possible counterexamples but its kind increases the probability of ravenhood which is not in favor of H . So, this observation cannot confirm H . Therefore, this example suggests that in Setting 2, given the proper background knowledge, intuition does not follow NC. It follows PJ even if it advises that the observation of a green apple confirms that \u201call ravens are black\u201d and the observation of a black raven does not!\nClearly, we can never \u201cprove\u201d that a particular measure or a particular proposition is (or is not) \u201cintuitively plausible\u201d, due to the subjective nature of the problem. The former example presented a particular method of reasoning that relative to a given configuration supports PJ more than NC. This has convinced us that generally in setting 2, PJ is more plausible than NC but as we mentioned, some people might not be convinced. For example, one might argue that if we are told that the number of non-black objects is precisely 7 million, we can still believe that black ravens confirm that all ravens are black. Such reasoning might be on grounds of\nsome \u201chidden\u201d background information such as knowing that ravens are animals and animals of the same kind often have similar colors. This particular background knowledge is not in \u2206 (and therefore not in Setting 2) however as it was mentioned in the introduction, this knowledge is convertible to the subjectively chosen a priori probability measure. Of course given such knowledge, there will be no surprise if NC holds for F :=raven and G:=black but not for F := non-black and G:= non-raven. However, it is up to the readers to judge about what is intuitive for them and what is not. What was formally provable (and is proved formally) is that in setting 2, no probability measure can simultaneously satisfy PJ and NC for a couple of predicates F and G. Reasoning by analogy vs. Nicod\u2019s condition: Table 1 clearly shows that the only cases where PJ and NC do not contradict is when according to RA, the general hypothesis H should be confirmed. In other cases, RA do not impose a restriction; therefore, it never contradicts either PJ or NC.\nA little thought reveals that RA and NC have many commonalities. We go a step further and propose a conjecture that NC may seem intuitively valid since it can easily be conflated with RA as follows:\nAccording to the informal definition of NC: \u201cThe observation of an F that is G confirms that all F are G (or any F is G).\u201d Although this informal statement seems to be plausible a priori, it is vague and NC is not necessarily its only possible formalization. To begin with, it should be noticed that in informal language, the scopes of quantifiers are often ambiguous; For example the informal expression \u201cfor all b, the probability of \u03c8b . . . \u201d can easily be mistaken for \u201cthe probability that for all b, \u03c8b\u201d. However the most suitable formalization of the former (i.e. \u2200b pr(\u03c8b)) differs from that of the latter (i.e. pr(\u2200b \u03c8b)). On the other hand, the informal \u201cif\u201d does not exclusively stand for material implication; in a proper context it can also mean conditional probability. Putting these together, it can be seen that:\n(Informal NC): \u201cThe observation of an object a which is both F and G confirms that all (or any) object b that is F is also G.\u201d\ncan alternatively be formalized as: \u2200b pr(Gb |Fb.Fa.Ga) > pr(Gb |Fb). This relation is the definition of RA (see relation 2.2) \u2013 a rule of induction which is used in many fields (e.g. in case-based reasoning [AP94]), is directly justified by the principle of the uniformity of nature and does not suffer from the shortcomings of NC such as contradicting PJ or producing counterintuitive conclusions such as PC in the raven paradox."}, {"heading": "5 When the Size of the Universe is Unknown", "text": "In Section 1.1, we defined our probability space using the sample space \u2126, the set of all complete description vectors (CDVs), all involving N objects. Thus, from the beginning, we had to assume that the cardinality of the universe is known. In this section, we instead assume that:\n1. The size of the universe (i.e. N) is unknown; however it is known that it is fixed and bounded by some known constants \u03b1 and \u03b2. E.g. assume it is known that the number of the objects of the universe is larger than \u03b1 = 1010 and less than \u03b2 = 101000.\n2. The new evidence E := Fa.Ga, does not affect the way the rational agent estimates the size of the universe. E.g., the observation of a black raven does not change the probability distribution over the possible sizes of the universe.\nWe show that in this setting, our previous conclusions are still valid. Informally speaking, the reason is that all (in)equalities of the previous sections hold for any arbitrary (but fixed) size of the universe, therefore this number does not play a role, and consequently, even if it is unknown, (as long as new evidence does not affect the agent\u2019s beliefs about it) all (qualitative) relations should still hold.\nTo justify this claim formally, we need some new notation: If it is known that the size of universe is \u03c5, we let the enumeration of its objects be U\u03c5 := {1, 2, . . . \u03c5} (created recursively by U\u03c5 := U\u03c5\u22121 \u2294 {\u03c5}).\n19 Instead of \u2206, we write \u2206\u03c5 to indicate that the members of this set describe individuals which belong to the universe U\u03c5. Similarly, instead of \u2126, we write \u2126\u03c5 to emphasize that the sample space corresponds to a universe of size \u03c5 (i.e. U\u03c5).\n20 Similarly, instead of pr(\u00b7), we write pr\u03c5(\u00b7) to indicate that by definition, pr\u03c5 (defined on \u2126\u03c5) is a measure that provides a probabilistic model for the rational agent (who performs induction), only if he/she/it knows the cardinality of the universe is \u03c5.\nTo prevent ambiguity, instead of representing the events by propositions, we directly use subsets of the sample spaces: The event that corresponds to an arbitrary proposition \u03c1 relative to a sample space \u2126\u03c5 is: \u03c9 \u2126\u03c5 \u03c1 := {o \u2208 \u2126\u03c5 : o |= \u03c1}. For example, if \u03c1 := F1, then \u03c9 \u21261 \u03c1 represents the event {FG\u03041,FG1}, while \u03c9 \u21262 \u03c1 stands for the event {FG\u03041F\u0304G\u03042, FG\u03041F\u0304G2, FG\u03041FG\u03042, . . ., FG1FG2}. The Complete Description Vectors (CDVs) are here bold-faced and conjunction symbols \u201c.\u201d are dropped to emphasize that they are not ordinary propositions. For example FG1FG2 is a CDV that not only entails the ordinary proposition FG1.FG2, but also indicates that the universe is U2 = {1, 2}. The reason is that by definition, each CDV describes all objects of the universe (see Section 1.1).\nLet \u03b1 and \u03b2 be some known lower and upper bound for the size of the universe.21 We define a new sample space \u2126\u03b1:\u03b2 as a set that contains all members of all sample spaces that correspond to universes with sizes at least equal to \u03b1 and at most equal to \u03b2:\n\u2200\u03b1, \u03b2 \u2208 N s.t. \u03b1 \u2264 \u03b2 \u2126\u03b1:\u03b2 :=\n\u03b2 \u2294\n\u03c5=\u03b1\n\u2126\u03c5 (5.1)\n19 Note that \u2018\u2294\u2019 denotes the disjoint union operation. 20 While \u2126\u03c5 contains CDVs that exactly describe \u03c5 objects, for all distinct \u03c5\n\u2032 and \u03c5\u2032\u2032, \u2126\u03c5\u2032\u2229\u2126\u03c5\u2032\u2032=\u2205. 21 \u03b1 is at least equal to the number objects mentioned by background knowledge or evidence. \u03b2 can be arbitrarily large but for simplicity, we assume that it is finite. To see what would be needed if we wanted to allow \u03b2 \u2192 \u221e, refer to Footnote 23.\nRelative to the sample space \u2126\u03b1:\u03b2 and for all \u03c5 \u2208 [\u03b1, \u03b2], the subset \u2126\u03c5 represents the event that \u201cthe size of the universe is \u03c5\u201d. We let:\n\u03c9\u03c1 := {o \u2208 \u2126\u03b1:\u03b2 : o |= \u03c1} =\n\u03b2 \u2294\n\u03c5=\u03b1\n{o \u2208 \u2126\u03c5 : o |= \u03c1} =\n\u03b2 \u2294\n\u03c5=\u03b1\n\u03c9\u2126\u03c5\u03c1 =\n\u03b2 \u2294\n\u03c5=\u03b1\n(\u03c9\u2126\u03c5\u03c1 \u2229 \u2126\u03c5)\n\u03c9\u03c1 corresponds to the event that regardless of the size of the universe, proposition \u03c1 holds.22 We refer to \u03c9\u03c1 as the generalized correspondent of \u03c1. While \u03c9 \u2126\u03c5 \u03c1 \u2286 \u2126\u03c5 and for all \u03c5\u2032 6= \u03c5\u2032\u2032, \u2126\u03c5\u2032 \u2229 \u2126\u03c5\u2032\u2032 = \u2205, the above relation entails:\n\u03c9\u2126\u03c5\u03c1 = \u03c9\u03c1 \u2229 \u2126\u03c5 (5.2)\nLikewise, the event that represents \u201cexactly k objects of a universe of unknown size (but bounded by \u03b1 and \u03b2) are F\u201d is defined as follows:\n\u03c9Exact(k,F ) :=\n\u03b2 \u2294\n\u03c5=\u03b1\n\u03c9\u2126\u03c5 Exact(k,U\u03c5,F ) =\n\u03b2 \u2294\n\u03c5=\u03b1\n(\u03c9\u2126\u03c5 Exact(k,U\u03c5,F ) \u2229 \u2126\u03c5)\nWe refer to \u03c9Exact(k,F ) as the generalized correspondent of Exact(k, U\u03b1, F ) to Exact(k, U\u03b2, F ).\nOver the sample space \u2126\u03b1:\u03b2, we let Pr denote the probability measure that explains the rational agent \u2019s a priori degrees of beliefs in the events. As mentioned in footnote (1), the existence of such a measure is deduced from the rationality axioms23 [Sav54]. Note that:\n\u2200\u03c9 \u2286 \u2126\u03b1:\u03b2 , \u2200\u03c5 \u2208 N s.t. \u03b1 \u2264 \u03c5 \u2264 \u03b2 Pr(\u03c9 |\u2126\u03c5) = pr\u03c5(\u03c9) (5.3)\nThe reason is that by definition, both sides of the above equation represent the probability measure chosen by the rational agent, when the size of the universe is known to be i.24\nLet E := Fa.Ga where a \u2208 U\u03b1 (consequently for all \u03c5 \u2265 \u03b1, a \u2208 U\u03c5), and \u03c9D be either the generalized correspondent of Exact(k, U\u03b1, F ) to Exact(k, U\u03b2, F ) or the generalized correspondent of any D \u2208 \u2206\u03b1. Roughly speaking, this means that \u03c9D is the generalized correspondent of any piece of background knowledge which is discussed in the previous sections. Based on these notations, relation (5.4) represents a formal version of Assumption (2) (i.e. the assumption that the estimated size of the universe is not affected by evidence E):\n(Assumption) \u2200\u03c5 \u2208 [\u03b1, \u03b2] s.t. Pr(\u2126\u03c5) > 0 Pr(\u2126\u03c5 |\u03c9E \u2229 \u03c9D) = Pr(\u2126\u03c5 |\u03c9D) (5.4)\n22 More specifically, \u03c9\u03c1 represents: \u201cN=\u03b1 and \u03c1 w.r.t. U\u03b1\u201d or \u201cN=\u03b1+1 and \u03c1 w.r.t. U\u03b1+1\u201d or . . . or \u201cN=\u03b2 and \u03c1 w.r.t. U\u03b2\u201d.\n23 For the case where \u2126\u03b1:\u03b2 is finite, Savages axioms are sufficient. If we wanted to study the case where it is infinite (i.e. no upper bound exists: \u03b2 \u2192 \u221e), we needed to add the monotone continuity assumption [Arr70] to the rationality axioms to guarantee countable additivity.\n24 Evidently, if Pr(\u2126\u03c5) = 0, both Pr(\u03c9 |\u2126\u03c5) and pr\u03c5(\u03c9) are undefined.\nHaving this setting, it is easy to show that all (in)equalities of the previous sections hold for the case where the exact number of objects in the universe is unknown. As an example, consider the relation (5.5). This is a typical inequality that informally speaking states that \u201cfor any possible universe-size \u03c5, if it is known that the size of the universe is equal to \u03c5, relative to background knowledge D, the evidence E confirms the hypothesis H .\u201d (Note that by the notation that we were using in the previous sections, this equation would be represented by pr(H|E.D) > pr(H|D) where the size of the universe was not mentioned explicitly.)\n\u2200\u03c5 \u2208 N s.t. \u03b1 \u2264 \u03c5 \u2264 \u03b2, Pr(\u2126\u03c5) > 0 pr\u03c5(\u03c9 \u2126\u03c5 H |\u03c9 \u2126\u03c5 E \u2229 \u03c9 \u2126\u03c5 D ) > pr\u03c5(\u03c9 \u2126\u03c5 H |\u03c9 \u2126\u03c5 D ) (5.5)\nProposition 5.1 proves that the mentioned typical inequality entails that: Pr(\u03c9H |\u03c9E \u2229 \u03c9D) > Pr(\u03c9H |\u03c9D), which informally speaking asserts that relative to a universe of an unknown size (that is bounded by \u03b1 and \u03b2), in the presence of background knowledge D, the evidence E confirms H .\nProposition 5.1. Let the size of the universe be unknown but known to be bounded by \u03b1 and \u03b2. Let Pr be a probability measure that corresponds to the degrees of beliefs of a rational agent in the events of the sample space \u2126\u03b1:\u03b2 , defined by relation (5.1). If Pr complies with relation (5.4), then relation (5.5) entails:\nPr(\u03c9H |\u03c9E \u2229 \u03c9D) > Pr(\u03c9H |\u03c9D)\nProof. Let S := {s \u2208 N : \u03b1 \u2264 s \u2264 \u03b2, Pr(\u2126s) > 0} be the set of all possible sizes of the universe.\n\u2200\u03c5 \u2208 S pr\u03c5(\u03c9 \u2126\u03c5 H |\u03c9 \u2126\u03c5 E \u2229 \u03c9 \u2126\u03c5 D ) > pr\u03c5(\u03c9 \u2126\u03c5 H |\u03c9 \u2126\u03c5 D ), by (5.5) and definition of S \u21d2 \u2200\u03c5 \u2208 S Pr(\u03c9\u2126\u03c5H |\u03c9 \u2126\u03c5 E \u2229 \u03c9 \u2126\u03c5 D \u2229 \u2126\u03c5) > Pr(\u03c9 \u2126\u03c5 H |\u03c9 \u2126\u03c5 D \u2229 \u2126\u03c5), by relation (5.3) \u21d2 \u2200\u03c5 \u2208 S Pr ( \u03c9H\u2229\u2126\u03c5 | (\u03c9E\u2229\u2126\u03c5)\u2229(\u03c9D\u2229\u2126\u03c5)\u2229\u2126\u03c5 ) > Pr ( \u03c9H\u2229\u2126\u03c5 | (\u03c9D\u2229\u2126\u03c5)\u2229\u2126\u03c5 )\n, by relation (5.2)\n\u21d2 \u2200\u03c5 \u2208 S Pr(\u03c9H |\u03c9E \u2229 \u03c9D \u2229 \u2126\u03c5) > Pr(\u03c9H |\u03c9D \u2229 \u2126\u03c5), by simplification\n\u21d2 \u2200\u03c5 \u2208 S Pr(\u2126\u03c5 |\u03c9E\u2229\u03c9D)\u00b7Pr(\u03c9H |\u03c9E\u2229\u03c9D\u2229\u2126\u03c5) > Pr(\u2126\u03c5 |\u03c9D)\u00b7Pr(\u03c9H |\u03c9D\u2229\u2126\u03c5), by multiplying the r.h.s. and l.h.s. by the r.h.s. and l.h.s. of relation (5.4)\n\u21d2 \u2211\n\u03c5\u2208S\nPr(\u2126\u03c5 |\u03c9E\u2229\u03c9D) \u00b7Pr(\u03c9H |\u03c9E\u2229\u03c9D\u2229\u2126\u03c5) > \u2211\n\u03c5\u2208S\nPr(\u2126\u03c5 |\u03c9D) \u00b7Pr(\u03c9H |\u03c9D\u2229\u2126\u03c5)\nThe above inequality is equivalent to Pr(\u03c9H |\u03c9E \u2229 \u03c9D) > Pr(\u03c9H |\u03c9D) (where \u2126\u03c5 is marginalized out), which is the intended result."}, {"heading": "6 Conclusion", "text": "We argued that from a Bayesian perspective, (a) objective background information (from previous observations) and subjective prior information (i.e. prior degrees of\nbeliefs) can produce the same effects and in this sense, are convertible; therefore, in this context, \u201cthe state of perfect ignorance\u201d should be interpreted as \u201cthe state of possessing no objective information and no subjective biased beliefs\u201d. On the other hand, if we assume that the uniform probability measure corresponds to unbiased subjective degrees of beliefs (as it is often assumed), then we should conclude that: (b) with unbiased subjective beliefs, inductive reasoning is impossible. Therefore, based on (a) and (b), induction in a condition of perfect ignorance is impossible.\nIn addition, by examples we have shown that relative to unrestricted objective/subjective prior information, common rules of induction do not always hold. We concluded that rules of induction should be considered plausible, if they hold relative to a large class of plausible (objective) background knowledge (i.e. knowledge similar to our actual background knowledge) and plausible probability measures (i.e. measures with reasonable characteristics such as complying with more intuitive rules of induction). Subsequently, we scrutinized the plausibility of NC by fixing the background knowledge and studying the characteristics of measures that do or do not comply with it.\nIn the first setting, the background knowledge is composed of complete descriptions of several objects. It is shown that in this setting, validity of NC is implied by the answer to a simpler question that does not seem to have a general intuitive answer i.e. for distinct objects a and b, whether E = Fa.Ga confirms Fb.\u00acGb or not. While due to the chosen probability measure and characteristics of F and G, the latter condition does not hold in general, we concluded that in this setting NC is not significantly more reasonable than \u00acNC.\nIn the second setting, the number of objects satisfying a particular predicate is known by background knowledge. It is shown that in this case, NC may contradict PJ while seemingly, intuition follows the latter. In summary:\n1. There are reasonable (i.e. not implausible a priori) probability measures for which NC does not hold;\n2. There are reasonable probability measures for which weak projectability, i.e. one of the simplest forms of inductive inference, opposes NC;\n3. In the case of contradiction, intuition \u201cseems to\u201d follow projectability rather than NC;\nHence, we conclude that we have gathered some evidence against the assumption that NC is a generally reliable rule of induction. If NC is not considered plausible then the raven paradox is also dispelled since even if NC holds for two predicates F and G, it does not mean that it should hold for \u00acG and \u00acF . This asymmetry may be due to possible asymmetry in background knowledge and/or priors.\nOf the three mentioned points, point (1) had already been demonstrated [Mah04]. The distinction is that we have dealt with NC without relying on any particular a priori measure. As mentioned throughout the paper, in the Bayesian framework one\u2019s choice of prior probability distribution is subjective. Nevertheless, Bayesian\nagents\u2019 beliefs at any time are (heavily) dependent on their prior distributions. Therefore, different subjective choices may lead to contradictory results. In the case of variations of Carnap\u2019s measure, this freedom of choice also resurfaces in the form of one or several arbitrary parameters. [Mah99] and [Mah04] are two variations of Carnap\u2019s measure but for the former, NC always holds and for the latter, for some parameter configurations, it does not. Although one might claim that the existence of at least one measure that does not comply with NC is sufficient to discredit NC, one should note that any rule of induction can be violated by some measures and remains valid for some others. In fact one might contrarily claim that contradiction of a measure with an \u201cintuitive\u201d rule of induction should discredit that particular measure rather than the rule. Therefore, our sufficient condition for (\u00acNC) that covers a class of measures rather than a specific one, should be considered a more general and interesting relation.\nThe main contribution of our work is the conjunction of points (2) and (3). We believe that compared to the raven paradox\u2019s PC and other counterintuitive consequences of NC, the conflict between NC and PJ is more important. To our knowledge, other counterintuitive consequences (such as The red herring [Goo67] and Good\u2019s baby [Goo68] problems) are either related to arguably implausible background configurations, or as is the case with PC, some claim that they are not counterintuitive. PJ is a very simple form of inductive inference. It is more directly justified by our intuitive notion of inductive reasoning than NC, and it\u2019s plausibility cannot be challenged as easily.\nWe also proposed a conjecture that NC seems to be plausible because it can be mistaken for reasoning by analogy (RA) which has a closely related informal representation. We proved that in the case where the exact number of objects satisfying one property is known, RA is compatible with both PJ and NC. It is a conservative condition that intuitively seems plausible and does not suffer from the shortcomings of NC (such as contradicting PJ or producing counterintuitive conclusions such as PC) and is directly justified by the principle of the uniformity of nature."}, {"heading": "7 Proof of Theorems", "text": ""}, {"heading": "7.1 Proof of Theorems 3.1 and 3.2", "text": "Lemma 1. In relation (2.3), if D \u2208 \u03b4, NC is equivalent to \u039e1 \u00b7 \u039e2 > 1 where: U\\ID := {b1, . . . bn, a} is \u201cthe set of objects not described by D\u201d, \u039e1 := pr(F\u2192Gb1:bn |FGa.D)\npr(F\u2192Gb1:bn |D) and \u039e2 := 1 pr(F\u2192Ga|F\u2192Gb1:bn .D) .\nProof. Objects are either completely described by D \u2208 \u03b4 or are not described at all.\nTherefore:\npr(F\u2192G1:N |D) = pr(F\u2192Gb1:bn .F\u2192Ga|D) (7.1)\npr(F\u2192G1:N |FGa.D) = pr(F\u2192Gb1:bn |FGa.D) (7.2)\nCombination of (7.1), (7.2) and (2.3) proves the lemma.25\nProof of Theorem 3.1. Due to pr(FG\u0304b|\u00b7) = 1\u2212pr(F\u2192Gb|\u00b7), relation (3.1) is equal to:\n\u2200B \u2208 \u2206, \u2200a, b /\u2208 IB pr(F\u2192Gb|FGa.B) \u2265 pr(F\u2192Gb|B) (7.3)\nLet arbitrary D \u2208 \u03b4 and ID = U\\{b1, . . . , bn, a} (i.e. b1 to bn are the objects not mentioned by background knowledge or evidence). According to the definitions of \u03b4 and \u2206, for all i < n: F\u2192Gb1. . . F\u2192Gbi .D \u2208 \u2206 (because it is consistent) and a, bi+1 /\u2208 IF\u2192Gb1...F\u2192Gbi .D. Therefore, from (7.3) it follows that:\n\u2200i < n pr(F\u2192Gbi+1 |F\u2192Gb1:bi.FGa.D) \u2265 pr(F\u2192Gbi+1|F\u2192Gb1:bi .D)\n=\u21d2 n\u22121 \u220f\ni=0\npr(F\u2192Gbi+1 |F\u2192Gb1:bi.FGa.D) \u2265 n\u22121 \u220f\ni=0\npr(F\u2192Gbi+1 |F\u2192Gb1:bi.D) (7.4)\nDue to the chain rule, the r.h.s. of the above equation is equal to pr(F\u2192Gb1:bn |D):\nn\u22121 \u220f\ni=0\npr(F\u2192Gbi+1|F\u2192Gb1:bi.D) =\npr(F\u2192Gb1|D)\u00b7pr(F\u2192Gb2|F\u2192Gb1.D) . . . pr(F\u2192Gbn|F\u2192Gb1. . . F\u2192Gbn\u22121.D) = pr(F\u2192Gb1:bn |D)\nSimilarly, the l.h.s. of (7.4) is equal to pr(F\u2192Gb1:bn |FGa.D). Therefore:\npr(F\u2192Gb1:bn|FGa.D) \u2265 pr(F\u2192Gb1:bn|D)\nThis entails \u039e1 \u2265 1 and since \u039e2 > 1, according to Lemma 1, NC holds.\nProof of Theorem 3.2. Similar to the method used in the proof of Theorem 3.1 and by using inequality (3.2) instead of inequality (3.1) it can be proved that:\n\u2200i < n pr(F\u2192Gbi+1|F\u2192Gb1:bi. FGa. D) < pr(F\u2192Gbi+1|F\u2192Gb1:bi. D)\nConsequently:\n\u039e1 = \u220fn\u22121 i=1 pr(F\u2192Gbi+1 |F\u2192Gb1:bi.FGa.D) \u220fn\u22121 i=1 pr(F\u2192Gbi+1 |F\u2192Gb1:bi.D) \u00b7 pr(F\u2192Gb1 |FGa.D) pr(F\u2192Gb1 |D) < pr(F\u2192Gb1 |FGa.D)\npr(F\u2192Gb1 |D) (7.5)\n25Note that \u039e1 indicates the effect of the observation Fa.Ga, on the probability that unobserved individuals satisfy F\u2192G and \u039e2 corresponds to the effect of elimination of the possibility that the observed object is a counterexample to the generalization.\nFor conciseness, let p := pr(F\u2192Gb1 |FGa.D) and q := pr(F\u2192Gb1 |D).\npr(\u00acF\u2192Ga|F\u2192Gb1: bn .D) < (1\u2212 p)\u2212 (1\u2212 q), since F\u2192G = \u00acFG\u0304 and by inequality (3.3)\n=\u21d2 pr(F\u2192Ga|F\u2192Gb1: bn .D) > 1\u2212 q + p (7.6)\nFinally,\n1\u2212 p > 1\u2212 q =\u21d2 p < q, since D \u2208 \u2206 and by (3.2)\n=\u21d2 p \u00b7 (1\u2212 q) < q \u00b7 (1\u2212 q) =\u21d2 p < q \u00b7 (1\u2212 q + p), since q < 1 =\u21d2 p\nq < 1\u2212 q + p since q > 0\n=\u21d2 \u039e1 < pr(F\u2192Ga|F\u2192Gb1:bn .D), by (7.5) and (7.6) =\u21d2 \u039e1 \u00b7 \u039e2 < 1 =\u21d2 NC does not hold. by Lemma 1"}, {"heading": "7.2 Proof of Theorem 4.1", "text": "Lemma 2. Under PJ, for any set of objects {1, 2, . . ., n} \u2286 U , a \u2208 U and any D \u2208 \u2206 that does not determine the value of \u03c8a:\n(Group PJ) pr(\u03c81:n|\u03c8a.D) \u2265 pr(\u03c81:n|D) (7.7)\n(Negative Group PJ) pr(\u03c81:n| \u00ac\u03c8a.D) \u2264 pr(\u03c81:n|D) (7.8)\nProof. The proof is based on mathematical induction. 1. Proof of relation (7.7): (I) For n = 1, relation (7.7) is equivalent to relation (2.1) and therefore valid. (II) Assume for n = k relation (7.7) holds. We prove that for n = k + 1, it holds as well:\npr(\u03c81:k+1|\u03c8a.D) = pr(\u03c81:k.\u03c8k+1|\u03c8a.D)\n= pr(\u03c8k+1|\u03c8a.D) \u00b7 pr(\u03c81:k|\u03c8a.\u03c8k+1.D)\n\u2265 pr(\u03c8k+1|D) \u00b7 pr(\u03c81:k|\u03c8a.\u03c8k+1.D), by inequality (2.1)\n\u2265 pr(\u03c8k+1|D) \u00b7 pr(\u03c81:k|\u03c8k+1.D), (2.1) applied to (\u03c8k+1.D) \u2208 \u2206\n= pr(\u03c81:k+1|D)\nBy (I) & (II), mathematical induction implies (7.7) for all n. 2. Proof of relation (7.8): Under PJ: \u2200b pr(\u00ac\u03c8b| \u00ac\u03c8a.D) \u2265 pr(\u00ac\u03c8b|D), therefore:\n1\u2212 pr(\u03c8b| \u00ac\u03c8a.D) \u2265 1\u2212 pr(\u03c8b|D) =\u21d2 pr(\u03c8b| \u00ac\u03c8a.D) \u2264 pr(\u03c8b|D) (7.9)\nSimilar to the previous case and by using (7.9) instead of (2.1), inequality (7.8) can be proved easily.\nLemma 3. For all 1 \u2264 k \u2264 N , D := F1:k.(\u00acF )k+1:N and E being an arbitrary proposition: pr(H|E .D) = pr(G1:k|E .D).\nProof. l.h.s. = pr ( F\u2192G1:k.F\u2192Gk+1:N |E . F1:k.(\u00acF )k+1:N ) = pr ( F\u2192G1:k.F1:k.F\u2192Gk+1:N .(\u00acF )k+1:N |E . F1:k.(\u00acF )k+1:N ) = pr ( (F\u2192G.F )1:k.(F\u2192G.\u00acF )k+1:N |E . F1:k.(\u00acF )k+1:N ) = pr ( (F.G)1:k.(\u00acF )k+1:N |E . F1:k.(\u00acF )k+1:N )\n(since F\u2192Gb.Fb \u2261 Fb.Gb and F\u2192Gb.\u00acFb \u2261 \u00acFb) = pr ( F1:k.G1:k.(\u00acF )k+1:N |E . F1:k.(\u00acF )k+1:N ) = pr ( G1:k|E . F1:k.(\u00acF )k+1:N ) = r.h.s.\nProof of Theorem 4.1. In the following relations, D := F1:k.(\u00acF )k+1:N . (I) Proof of relation (4.1), i.e. pr(H |Gk . D) > pr(H|D) by PJ:\npr(H|Gk . D) = pr(G1:k|Gk . D), by Lemma 3\n= pr(G1:k\u22121|Gk . D) \u2265 pr(G1:k\u22121|D), by Lemma 2\n> pr(G1:k|D), adding Gk & Cournot\u2019s pp. (note: D 0 Gk)\n= pr(H|D), by Lemma 3.\n(II) Proof of relation (4.2), i.e. pr(H |GN . D) \u2265 pr(H|D) by PJ:\npr(H|GN . D) = pr(G1:k|GN . D), by Lemma 3\n\u2265 pr(G1:k|D), by relation (7.7) (Group PJ)\n= pr(H|D), by Lemma 3.\n(III) Proof of relation (4.3) i.e. pr(H | \u00acGN . D) \u2264 pr(H|D) by PJ:\npr(H|\u00acGN . D) = pr(G1:k|\u00acGN . D), by Lemma 3\n\u2264 pr(G1:k|D), by relation (7.8) (Neg.GroupPJ)\n= pr(H|D), by Lemma 3.\n(IV) Proof of relation (4.4) , i.e. pr(H |Gk . D) > pr(H|D) by RA:\npr(H|Gk . D) = pr(G1:k\u22121|Gk . D), by Lemma 3\n=\nk\u22121 \u220f\ni=1\npr(Gi|G1:i\u22121.Gk.D), by the chain rule\n=\nk\u22121 \u220f\ni=1\npr(Gi|Fi.Fk.Gk.G1:i\u22121.D), since D \u22a2 Fi.Fk\n>\nk\u22121 \u220f\ni=1\npr(Gi|Fi.G1:i\u22121.D), by RA (and since G1:i\u22121.D \u2208 \u2206)\n= k\u22121 \u220f\ni=1\npr(Gi|G1:i\u22121.D), since for i \u2208 {1, . . . , k} : D \u22a2 Fi\n= pr(G1:k\u22121|D), by the chain rule\n> pr(G1:k|D), by adding Gk & Cournot\u2019s pp. (note: D 0 Gk)\n= pr(H|D), by Lemma 3."}, {"heading": "7.3 Proof of Theorem 4.2", "text": "Definition. Having a set C \u2286 U and \u03c0 being a permutation (of U), C\u03c0 is defined as: C\u03c0 := {\u03c0(b) : b \u2208 C}. It is obvious that U\u03c0 = U .\nThe following two relations directly follows from the assumption that \u03c0 is a bijection:\n\u2200C \u2286 U |C| = |C\u03c0| (7.10) \u2200C,C \u2032 \u2286 U C 6= C \u2032 =\u21d2 C\u03c0 6= C \u2032\u03c0 (7.11)\nLemma 4. H = H\u03c0 where \u03c0 is an arbitrary permutation (of U).\nProof. H\u03c0 = \u2227\nb\u2208U\nF\u2192G\u03c0(b) = \u2227\n\u03c0(b)\u2208U\u03c0\nF\u2192G\u03c0(b) = \u2227\nb\u2032\u2208U\u03c0\nF\u2192Gb\u2032 = \u2227\nb\u2032\u2208U\nF\u2192Gb\u2032 = H\nThe first equality holds by definition. The second equality holds because: b \u2208 U \u21d0\u21d2 \u03c0(b) \u2208 U\u03c0. In the r.h.s. of the third equality, \u03c0(b) is renamed to b\u2032. The fourth equality holds because U = U\u03c0 (note that \u03c0 is a permutation in U). The last equality is the definition of H .\nLemma 5. For all 1 \u2264 k \u2264 N , all permutations \u03c0 and CU,k being defined as the set of all subsets of U which have size k:\nC \u03c0 U,k := {C \u03c0 : C \u2208 CU,k} = CU,k (7.12)\nProof. Equality (7.10) implies, \u2200C\u03c0 \u2208 C\u03c0U,k |C \u03c0| = |C| = k, which means: C\u03c0 is a k-combination from U ; So from the definition of CU,k it follows that C \u03c0 \u2208 CU,k. Therefore, C\u03c0U,k \u2286 CU,k. Conversely, according to relation (7.11) and the definition of C\u03c0U,k in (7.12), there is a one-to-one relation between the members of CU,k and C \u03c0 U,k. This entails: |C \u03c0 U,k| = |CU,k|. Thus: C \u03c0 U,k = CU,k.\nLemma 6. For all permutations \u03c0 (of the set U), and for all integers k \u2208 [1, N ]: Exact(k, U, F ) = Exact\u03c0(k, U, F )\nProof. By definition, Exact\u03c0(k, U, F ) := \u2228\nC\u2208CU,k\n( \u2227\na\u2208C\nF\u03c0(a) . \u2227\nb6\u2208C\n\u00acF\u03c0(b))\n= \u2228\nC\u2208CU,k\n( \u2227\n\u03c0(a)\u2208C\u03c0\nF\u03c0(a) . \u2227\n\u03c0(b)6\u2208C\u03c0\n\u00acF\u03c0(b)), since c \u2208 C \u21d0\u21d2 \u03c0(c) \u2208 C \u03c0\n= \u2228\nC\u03c0\u2208C\u03c0 U,k\n( \u2227\n\u03c0(a)\u2208C\u03c0\nF\u03c0(a) . \u2227\n\u03c0(b)6\u2208C\u03c0\n\u00acF\u03c0(b)), since C \u2208 CU,k \u21d0\u21d2 C \u03c0 \u2208 C\u03c0U,k\n= \u2228\nC\u2032\u2208C\u03c0 U,k\n( \u2227\na\u2032\u2208C\u2032\nFa\u2032 . \u2227\nb\u2032 6\u2208C\u2032\n\u00acFb\u2032), renaming C \u03c0 to C \u2032 and \u03c0(c) to c\u2032\n= \u2228\nC\u2032\u2208CU,k\n( \u2227\na\u2032\u2208C\u2032\nFa\u2032 . \u2227\nb\u2032 6\u2208C\u2032\n\u00acFb\u2032), since C \u03c0 U,k = CU,k, (Lemma 5)\n= Exact(k, U, F ), by definition.\nDefinition. For each C \u2286 U , the proposition Z(C,F ) is defined as:\nZ(C,F ) := \u2227\na\u2208C\nFa . \u2227\nb6\u2208C\n\u00acFb (7.13)\nwhich allows to write definition (4.5) as: Exact(k, U, F ) := \u2228\nC\u2208CU,k Z(C,F )\nLemma 7. For arbitrary propositions A and B and 1 \u2264 k \u2264 N :\npr(Exact(k, U, F ).A|B) = \u2211\nC\u2208CU,k\npr(Z(C,F ).A|B) (7.14)\nProof. \u2200C \u2032 6= C \u2032\u2032 \u2208 CU,k:\n\u2203b \u2208 U b \u2208 C \u2032 and b 6\u2208 C \u2032\u2032, C \u2032 &C \u2032\u2032 being distinct with same size\n=\u21d2 Z(C\u2032,F ) |= Fb and Z(C\u2032\u2032,F ) |= \u00acFb, by definition (7.13)\n=\u21d2 Z(C\u2032,F ).Z(C\u2032\u2032,F ) |= Fb .\u00acFb \u2261 \u22a5\nTherefore, the sequence {Z(C,F )}C\u2208CU,k consists of mutually disjoint events. Hence, by the third Kolmogorov probability axiom, for all propositions A and B:\npr(Exact(k, U, F ).A|B) = pr (\n\u2228\nC\u2208CU,k\n(Z(C,F ).A)|B ) = \u2211\nC\u2208CU,k\npr(Z(C,F ).A|B) (7.15)\nLemma 8. Let 1 \u2264 k \u2264 N . For all C \u2208 CU,k and for all permutations \u03c0:\nZ\u03c0(C,F ) = Z(C\u03c0 ,F )\nProof.\nZ\u03c0(C,F ) = \u2227\na\u2208C\nF\u03c0(a) . \u2227\nb6\u2208C\n\u00acF\u03c0(b) by relation (7.13)\n= \u2227\n\u03c0(a)\u2208C\u03c0\nF\u03c0(a) . \u2227\n\u03c0(b)6\u2208C\u03c0\n\u00acF\u03c0(b) by def. c \u2208 C \u21d0\u21d2 \u03c0(c) \u2208 C \u03c0\n= \u2227\na\u2032\u2208C\u03c0\nFa\u2032 . \u2227\nb\u2032 6\u2208C\u03c0\n\u00acFb\u2032 renaming \u03c0(a) to a \u2032 and \u03c0(b) to b\u2032\n= Z(C\u03c0 ,F ) by relation (7.13).\nProof of Theorem 4.2. For the sake of conciseness, here we only prove relation (4.7) i.e.:\n\u2200a \u2208 U, 1 \u2264 k \u2264 N pr ( H|Exact(k, U, F ) .Fa.Ga ) = pr ( H|F1:k.\u00acFk+1:N .Gk )\nThe remaining relations (4.6, 4.8 & 4.9) can be proved using the same method and by small (and obvious) appropriate modifications.\nFor the sake of simplicity, we first swap the names of the objects a and 1 as follows: Let \u03c0\u2032 := {a/1; 1/a}. By the exchangeability assumption:\npr ( H|Exact(k, U, F ) .Fa.Ga ) = pr ( H\u03c0 \u2032 |Exact\u03c0 \u2032 (k, U, F ) .F\u03c0\u2032(a).G\u03c0\u2032(a) )\n= pr ( H|Exact(k, U, F ) .F1.G1 ) , by Lemmas 4 and 6\n= pr(H) \u00b7 pr\n( Exact(k, U, F ). F1.G1|H )\npr ( Exact(k, U, F ) .F1.G1 ) , by Bayes rule. (7.16)\nNow:\npr ( Exact(k, U, F ) .F1.G1|H ) = \u2211\nC\u2208CU,k\npr(Z(C,F ).F1.G1|H), by Lemma 7\n= \u2211\nC\u2208CU,k s.t. 1\u2208C\npr(Z(C,F ).F1.G1|H) + \u2211\nC\u2208CU,k s.t. 16\u2208C\npr(Z(C,F ).F1.G1|H)\n= \u2211\nC\u2208CU,k s.t. 1\u2208C\npr(Z(C,F ).F1.G1|H) (7.17)\nThe second summation is eliminated because in the case of any C \u2208 CU,k such that 1 6\u2208 C, Z(C,F ) \u00acF1 (see definition (7.13)), therefore in this case, pr(Z(C,F ).F1.G1|H) = pr(Z(C,F ).\u00acF1.F1.G1|H) = pr(\u22a5|H) = 0.\nDue to the exchangeability assumption, the members of the first summation are all equal. The reasoning is as follows: In the case of any C \u2208 CU,k such that 1 \u2208 C, there exists some permutation that map each of the members of C to the set {1, 2, . . . k} with 1 as a fixed point i.e.:\n\u2200C \u2208 CU,k s.t. 1 \u2208 C : \u2203\u03c0 C \u03c0 = {1, 2, . . . , k}, \u03c0(1) = 1 (7.18)\nIn fact, for any member of CU,k, exactly (k \u2212 1)! permutations with such properties exist. Using such permutations, \u2200C \u2208 CU,k s.t. 1 \u2208 C:\n\u2203\u03c0 pr(Z(C,F ).F1.G1|H) = pr(Z \u03c0 (C,F ).F\u03c0(1).G\u03c0(1)|H \u03c0), by exchangeability\n= pr(Z({1,...,k},F ).F\u03c0(1).G\u03c0(1)|H \u03c0), using (7.18) in Lemma 8 = pr(Z({1,...,k},F ).F1.G1|H \u03c0), 1 being a fix point\n= pr(Z({1,...,k},F ).F1.G1|H), by Lemma 4\n= pr(F1:k.\u00acFk+1:N .G1|H), expanding Z(.,.) by def. (7.13) (7.19)\nThus, combining (7.17) and (7.19):\npr ( Exact(k, U, F ).F1.G1|H ) = \u2211\nC\u2208CU,k s.t. 1\u2208C\npr(Z(C,F ).F1.G1|H)\n=\n(\nN \u2212 1\nk \u2212 1\n)\npr(F1:k.\u00acFk+1:N .G1|H) (7.20)\nBy a similar justification:\npr ( Exact(k, U, F ).F1.G1 ) =\n(\nN \u2212 1\nk \u2212 1\n)\npr(F1:k.\u00acFk+1:N .G1) (7.21)\nCombining equations (7.20), (7.21) and (7.16):\npr ( Exact(k, U, F ) .F1.G1|H ) = pr(H) \u00b7 pr\n( Exact(k, U, F ) .F1.G1|H )\npr ( Exact(k, U, F ) .F1.G1 )\n=\n(\nN\u22121 k\u22121\n)\npr(H) pr(F1:k\u00acFk+1:N .G1|H) (\nN\u22121 k\u22121\n) pr(F1:k\u00acFk+1:N .G1) = pr(H|F1:k\u00acFk+1:N .G1)"}, {"heading": "A List of Notation", "text": "Symbol Explanation\nU = {1, 2, . . . , \u03c5} universe of arbitrary size N\n1, 2, . . . , N objects of universe U (short form) \u03c5, \u03c5\u2032, \u03c5\u2032\u2032 \u2208 N symbols used to denote the size of universe\nU\u03c5 = {1, 2, . . . , \u03c5} universe of size \u03c5 \u03b1 \u2264 \u03b2 lower and higher bounds for the size of the universe\na, b, c and b1, b2, . . . typical objects (or individuals) (not necessarily consecutive) \u03c8 typical 1-place predicate\n\u03c8b a proposition assigning predicate \u03c8 to object b\n\u03c8bi:bj \u03c8bi .\u03c8bi+1 . . . \u03c8bj F,G atomic 1-place predicates\nFb, Gb propositions assigning F and G to object b, respectively F\u0304G\u0304b, F\u0304Gb, FG\u0304b, FGb complete descriptions (of object b) F\u2192Gb Fb \u2192 Gb \u2261 \u00acFb \u2228Gb \u2261 \u00acFG\u0304b H General hypothesis: \u2200b \u2208 U F\u2192Gb E evidence: Fa.Ga B,D typical (objective) background knowledge\n\u03c1 a typical proposition\nI\u03c1 set of all individuals described by \u03c1\nA\u03c1 set of all (simple) predicates involved in \u03c1\n\u22a4 tautologous proposition\n\u2206 set of all propositions in form of relation (1.3) (on universe U)\n\u2206\u03c5 set of all propositions in form of relation (1.3) (on universe U\u03c5) \u03b4 set of all complete descriptions that do not falsify H\nCDV complete description vector\n\u2126 set of all CDVs (w.r.t universe U)\n\u2126\u03c5 set of all CDVs (w.r.t. universe U\u03c5) \u2126\u03b1:\u03b2 union of \u2126\u03b1 to \u2126\u03b2 \u03c9\u2126\u03c5\u03c1 \u2286 \u2126\u03c5 an event that corresponds proposition \u03c1 (w.r.t. sample space \u2126\u03c5) \u03c9\u03c1 \u2286 \u2126\u03b1:\u03b2 an event that corresponds proposition \u03c1 (w.r.t. sample space \u2126\u03b1:\u03b2) pr probability (over sample space \u2126)\npr\u03c5 probability (over sample space \u2126\u03c5) Pr probability (over sample space \u2126\u03b1:\u03b2) \u03c0, \u03c0\u2032, \u03c0\u2032\u2032 typical permutations (i.e. bijections) in U\n\u03c0(b) an object that b \u2208 U is mapped to by bijection \u03c0 \u03c1\u03c0 a proposition obtained from \u03c1 by replacing any b \u2208 I\u03c1 with \u03c0(b) C,C \u2032, C \u2032\u2032 \u2286 U typical subsets of U C\u03c0 {\u03c0(b) : b \u2208 C}\nCU,k set of all subsets of U with cardinality k C \u03c0 U,k {C \u03c0 : C \u2208 CU,k} Z(C,F ) \u2227 a\u2208CFa . \u2227 b6\u2208C\u00acFb Exact(k, U, F ) a proposition representing: \u201cexactly k members of U are F\u201d"}], "references": [{"title": "Case-Based Reasoning: Foundational Issues, Methodological Variations, and System Approaches", "author": ["A. Aamodt", "E. Plaza"], "venue": "Artificial Intelligence Communications", "citeRegEx": "Aamodt and Plaza,? \\Q1994\\E", "shortCiteRegEx": "Aamodt and Plaza", "year": 1994}, {"title": "Essays in the Theory of Risk-Bearing, North-Holland", "author": ["K. Arrow"], "venue": null, "citeRegEx": "Arrow,? \\Q1970\\E", "shortCiteRegEx": "Arrow", "year": 1970}, {"title": "R", "author": ["Carnap"], "venue": "(1950). Logical Foundations of Probability, Chicago: Chicago University Press. 2nd Ed.", "citeRegEx": "Car50", "shortCiteRegEx": null, "year": 1962}, {"title": "A Basic System of Inductive Logic, Part II", "author": ["R. Carnap"], "venue": "Studies in Inductive Logic and Probability,", "citeRegEx": "Carnap,? \\Q1980\\E", "shortCiteRegEx": "Carnap", "year": 1980}, {"title": "How Bayesian Confirmation Theory Handles the Paradox of the Ravens", "author": ["B. Fitelson", "J. Hawthorne"], "venue": "(In E. Eells & J. Fetzer (Eds.) Probability in Science). http://fitelson.org/research.htm", "citeRegEx": "Fitelson and Hawthorne,? \\Q2006\\E", "shortCiteRegEx": "Fitelson and Hawthorne", "year": 2006}, {"title": "The Wason Task(s) and the Paradox of Confirmation", "author": ["B. Fitelson", "J. Hawthorne"], "venue": "Philosophical Perspectives", "citeRegEx": "Fitelson and Hawthorne,? \\Q2010\\E", "shortCiteRegEx": "Fitelson and Hawthorne", "year": 2010}, {"title": "The White Shoe is a Red Herring", "author": ["J. Good I"], "venue": "British Journal for the Philosophy of Science,", "citeRegEx": "I.,? \\Q1967\\E", "shortCiteRegEx": "I.", "year": 1967}, {"title": "The White Shoe qua Red Herring is Pink", "author": ["I.J. Good"], "venue": "British Journal for the Philosophy of Science", "citeRegEx": "Good,? \\Q1968\\E", "shortCiteRegEx": "Good", "year": 1968}, {"title": "Probabilities over rich languages, testing and randomness", "author": ["H. Gaifman", "M. Snir"], "venue": "Journal of Symbolic Logic,", "citeRegEx": "Gaifman and Snir,? \\Q1982\\E", "shortCiteRegEx": "Gaifman and Snir", "year": 1982}, {"title": "Studies in the Logic of Confirmation", "author": ["C.G. Hempel"], "venue": "Mind 54:", "citeRegEx": "Hempel,? \\Q1945\\E", "shortCiteRegEx": "Hempel", "year": 1945}, {"title": "The White Shoe - No Red Herring", "author": ["C.G. Hempel"], "venue": "British Journal for the Philosophy of Science,", "citeRegEx": "Hempel,? \\Q1967\\E", "shortCiteRegEx": "Hempel", "year": 1967}, {"title": "Probabilities on Sentences in an Expressive Logic", "author": ["Hutter M", "J.W. Lloyd", "K.S. Ng", "W.T.B. Uther"], "venue": "Journal of Applied Logic", "citeRegEx": "M. et al\\.,? \\Q2013\\E", "shortCiteRegEx": "M. et al\\.", "year": 2013}, {"title": "On universal prediction and Bayesian confirmation", "author": ["M. Hutter"], "venue": "Theoretical Computer Science,", "citeRegEx": "Hutter,? \\Q2007\\E", "shortCiteRegEx": "Hutter", "year": 2007}, {"title": "Probability theory: The logic of science", "author": ["E.T. Jaynes"], "venue": null, "citeRegEx": "Jaynes,? \\Q2003\\E", "shortCiteRegEx": "Jaynes", "year": 2003}, {"title": "Inductive Logic and the Ravens Paradox", "author": ["P. Maher"], "venue": "Philosophy of Science", "citeRegEx": "Maher,? \\Q1999\\E", "shortCiteRegEx": "Maher", "year": 1999}, {"title": "Probability Captures the Logic of Scientific Confirmation", "author": ["P. Maher"], "venue": "(In C. Hitchcock (Ed.) Contemporary Debates in the Philosophy of Science,", "citeRegEx": "Maher,? \\Q2004\\E", "shortCiteRegEx": "Maher", "year": 2004}, {"title": "K", "author": ["Popper"], "venue": "(1959). The Logic of Scientific Discovery. London: Hutchinson. (1st German Ed., Logik der Forschung,", "citeRegEx": "Pop59", "shortCiteRegEx": null, "year": 1935}, {"title": "Equality and domain closure in first-order databases", "author": ["R. Reiter"], "venue": null, "citeRegEx": "Reiter,? \\Q1980\\E", "shortCiteRegEx": "Reiter", "year": 1980}, {"title": "A Philosophical Treatise of Universal Induction, Enthropy", "author": ["S. Rathmanner", "Hutter M"], "venue": null, "citeRegEx": "Rathmanner and M.,? \\Q2011\\E", "shortCiteRegEx": "Rathmanner and M.", "year": 2011}, {"title": "Artificial Intelligence: A Modern Approach, (2nd ed.)", "author": ["S.J. Russell", "P. Norvig"], "venue": null, "citeRegEx": "Russell and Norvig,? \\Q2003\\E", "shortCiteRegEx": "Russell and Norvig", "year": 2003}, {"title": "Selective Confirmation and the Ravens", "author": ["I. Scheffler", "N.J. Goodman"], "venue": "Journal of Philosophy", "citeRegEx": "Scheffler and Goodman,? \\Q1972\\E", "shortCiteRegEx": "Scheffler and Goodman", "year": 1972}, {"title": "Axioms for rational reinforcement learning Proceedings of 22:nd international conference on algorithmic learning theory, Springer Lecture Notes in Computer Science 6925:338\u2013352", "author": ["P. Sunehag", "M. Hutter"], "venue": null, "citeRegEx": "Sunehag and Hutter,? \\Q2011\\E", "shortCiteRegEx": "Sunehag and Hutter", "year": 2011}, {"title": "A formal theory of inductive inference: Parts 1 and 2, Information and Control, 7:1\u201322 and 224\u2013254", "author": ["R.J. Solomonoff"], "venue": null, "citeRegEx": "Solomonoff,? \\Q1964\\E", "shortCiteRegEx": "Solomonoff", "year": 1964}, {"title": "Hempel\u2019s Raven Paradox: A Lacuna in the Standard Bayesian Solution", "author": ["P. Vranas"], "venue": "British Journal for the Philosophy of Science", "citeRegEx": "Vranas,? \\Q2004\\E", "shortCiteRegEx": "Vranas", "year": 2004}], "referenceMentions": [{"referenceID": 2, "context": "On the other hand, it is well known that using the uniform measure, inductive learning is not possible [Car50].", "startOffset": 103, "endOffset": 110}, {"referenceID": 16, "context": "The fundamental assumption behind inductive inference is the so-called principle of the uniformity of nature [Hum88] (or the immutability of natural processes [Pop59]) based on which, uniformity and trend are more probable than diversity and anomaly a priori.", "startOffset": 159, "endOffset": 166}, {"referenceID": 2, "context": "Maher has formalized one variation of reasoning by analogy (or inference by analogy [Car50]) as: \u2200a, b \u2208 U pr(Gb|Fb.", "startOffset": 84, "endOffset": 91}, {"referenceID": 2, "context": "Similarly, (as 10 According to [Car50] predictive inference (i.", "startOffset": 31, "endOffset": 38}, {"referenceID": 2, "context": "This is not surprising since using this measure, learning is impossible (see [Car50]).", "startOffset": 77, "endOffset": 84}], "year": 2013, "abstractText": "Philosophers writing about the ravens paradox often note that Nicod\u2019s Condition (NC) holds given some set of background information, and fails to hold against others, but rarely go any further. That is, it is usually not explored which background information makes NC true or false. The present paper aims to fill this gap. For us, \u201c(objective) background knowledge\u201d is restricted to information that can be expressed as probability events. Any other configuration is regarded as being subjective and a property of the a priori probability distribution. We study NC in two specific settings. In the first case, a complete description of some individuals is known, e.g. one knows of each of a group of individuals whether they are black and whether they are ravens. In the second case, the number of individuals having a particular property is given, e.g. one knows how many ravens or how many black things there are (in the relevant population). While some of the most famous answers to the paradox are measure-dependent, our discussion is not restricted to any particular probability measure. Our most interesting result is that in the second setting, NC violates a simple kind of inductive inference (namely projectability). Since relative to NC, this latter rule is more closely related to, and more directly justified by our intuitive notion of inductive reasoning, this tension makes a case against the plausibility of NC. In the end, we suggest that the informal representation of NC may seem to be intuitively plausible because it can easily be mistaken for reasoning by analogy.", "creator": "LaTeX with hyperref package"}}}