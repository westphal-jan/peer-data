{"id": "1307.8279", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "31-Jul-2013", "title": "Tracking Extrema in Dynamic Environment using Multi-Swarm Cellular PSO with Local Search", "abstract": "Many real-world phenomena can be modelled as dynamic optimization problems. In such cases, the environment problem changes dynamically and therefore, conventional methods are not capable of dealing with such problems. In this paper, a novel multi-swarm cellular particle swarm optimization algorithm is proposed by clustering and local search. In the proposed algorithm, the search space is partitioned into cells, while the particles identify changes in the search space and form clusters to create sub-swarms. Then a local search is applied to improve the solutions in the each cell. Simulation results for static standard benchmarks and dynamic environments show superiority of the proposed method over other alternative approaches.\n\n\n\nAbstract\n\nThe classical microcluster model is the basis of many previous work in this field. Although classical microcluster models are more compact and less complicated than most microcluster models, recent studies have shown that the classical microcluster model has improved efficiency of the search space and increase the speed of the search. Recent advances in machine learning and computational techniques have made it possible to solve many of these problems in a fraction of a second. In a paper titled The Anesthetics of Computer Science, I propose that the application of an object-oriented approach to building a microcluster is possible using a multi-sensor algorithm. The first possible implementation involves a computational algorithm that can be applied to a particular application, which can be optimized and evaluated by a computer at large. In an experimental example, the approach has been used in experiments on large areas of the earth, such as the Arctic.\nThe first step of the algorithm is to obtain the maximum throughput of the search space and determine the maximum throughput of the search space using a multi-sensor algorithm. The results will be presented in an online forum at the end of the paper. For further information, see this paper in Part One of my article, for more information.\nThe search space, or search space, is comprised of the following dimensions: the size of the area and the size of the target area, and the size of the target area. In general, we observe that the area of the target area in the target area is approximately 4 million square meters, and the size of the target area is about 60,000 square meters. In particular, the size of the target area is approximately 1,000 square meters. The size of the target area is about 1,000 square meters. The size of the target area is about 2,000 square meters. This is the approximate maximum throughput of the search", "histories": [["v1", "Wed, 31 Jul 2013 10:57:47 GMT  (666kb)", "http://arxiv.org/abs/1307.8279v1", "8 pages, 3 figures"]], "COMMENTS": "8 pages, 3 figures", "reviews": [], "SUBJECTS": "cs.AI cs.NE", "authors": ["somayeh nabizadeh", "alireza rezvanian", "mohammad reza meybodi"], "accepted": false, "id": "1307.8279"}, "pdf": {"name": "1307.8279.pdf", "metadata": {"source": "CRF", "title": "Tracking Extrema in Dynamic Environment using Multi-Swarm Cellular PSO with Local Search", "authors": ["Somayeh Nabizadeh", "Alireza Rezvanian", "Mohammad Reza Meybodi"], "emails": ["s_nabizadeh@qiau.ac.ir", "a.rezvanian@aut.ac.ir", "mmeybodi@aut.ac.ir", "s_nabizadeh@qiau.ac.ir"], "sections": [{"heading": null, "text": "1\nARTICLE HISTORY\nReceived: XXXX Revised: XXX1 Accepted: XXXX\nPublished online:\nMany real-world phenomena can be modelled as dynamic optimization problems. In such cases, the environment problem changes dynamically and therefore, conventional methods are not capable of dealing with such problems. In this paper, a novel multi-swarm cellular particle swarm optimization algorithm is proposed by clustering and local search. In the proposed algorithm, the search space is partitioned into cells, while the particles identify changes in the search space and form clusters to create sub-swarms. Then a local search is applied to improve the solutions in the each cell. Simulation results for static standard benchmarks and dynamic environments show superiority of the proposed method over other alternative approaches.\nKeywords: Dynamic Environment, Tracking Extrema, Multi Swarm Cellular PSO, Local Search.\nI. INTRODUCTION1\nIn many real-world problems, which are dynamic in nature, fitness function changes over time. In such cases, due to dynamic changes in the search space, conventional evolutionary algorithms are not applicable. To be more specific, an algorithm can tackle such problems if it is capable of identifying changes in the environment and finding new optimum solutions [1]. In this regard, different methods such as maintenance diversity, increased diversity, memory-based and multi-swarm methods are proposed for solving dynamic\nAUTHORS INFO\n1* Somayeh Nabizadeh e-mail: s_nabizadeh@qiau.ac.ir Qazvin branch, Islamic Azad University, Qazvin, Iran\n2 Alireza Rezvanian e-mail: a.rezvanian@aut.ac.ir Amirkabir University of Technology (Tehran Polytechnic), Tehran, Iran\n3 Mohammad Reza Meybodi e-mail: mmeybodi@aut.ac.ir Amirkabir University of Technology (Tehran Polytechnic), Tehran, Iran\n*Corresponding author Somayeh Nabizadeh e-mail: s_nabizadeh@qiau.ac.ir Tel: +98-21-64545120\noptimization problems [2]. In this research, the main focus is on a hybrid method of maintenance diversity and multi-swarm. Evolutionary algorithms such as genetic algorithm [3], differential evolution [4], artificial immune system [5,6], and ant colony optimization make these methods applicable for solving dynamic optimization problems by appropriate mechanisms.\nParticle swarm optimization (PSO) algorithm has gained a significant attraction due to its simplicity and efficiency [8]. In addition, different versions of PSO are applied in dynamic environments. In the multi-swarm algorithm proposed by [9], parents maintain diversity and identify promising regions while offspring searches local areas to find local optima. In recent years, because of their satisfying results, multi-swarm algorithms, in which the particles are clustered into search groups, have got significant attention. Partly, focus of the recent works has been concentrated on methods and types of particles grouping. Recently, a new promising method based on cellular automata is proposed by Hashemi et al. for partitioning the solution space into cells [10,11]. In this paper, two mechanisms are proposed to maintain the diversity in cellular PSO. In the first one, clustering is used to form sub-swarms in each cell instead of searching the whole cell in order to speed up the search, whereas the second mechanism, local search is applied in each cell to improve the quality of solutions.\n2\nThe rest of this paper is organized as follows: in section 2, the cellular PSO is introduced briefly. The proposed method is discussed in section 3. Section 4, provides the simulation results for static standard benchmark and dynamic environment. Finally, section 5 concludes the paper."}, {"heading": "II. CELLULAR PSO", "text": "The original PSO, introduced in 1990s, is based on swarm behaviour. In PSO, each solution is considered as a particle which represents a single bird in a swarm. Initially, the particles are created and positioned randomly within the search space. Afterwards, each particle is updated iteratively according to the best observed value for personal and global fitness to reach optimal fitness [12].\nIn Cellular PSO, the search space is partitioned and a cellular automaton (CA) is fitted to the partitioned space to maintain diversity and provide an appropriate search on the space. Each cell in the CA searches and controls its corresponding region according to some predefined rules. Each particle is assigned to a cell based on its position in the space with search procedure being performed separately for each cell and its neighbours by using the PSO. This search method provides enough diversity as well as the ability to follow multiple optimum solutions. In addition, neighbouring cells communicate information about their best known solutions which results in a more appropriate cooperation between neighbouring cells for sharing their experiences. This in turn increases efficiency of the algorithm [11].\nDuring each iteration of the algorithm, velocity, and position of the particles are updated according to the equations below:\ni i 1 1 i i\n2 2 ik\nv (t 1) wv (t) c r (pBest p\nBestM\n(t))\nemc r (l p (t))\n   \n  (1)\n     i i ip t 1 p t v t i 1,...,m    (2)\nWhere vi is the velocity of the ith particle and pi is its position. r1 and r2 are uniformly distributed random variables in (0,1), while c1 and c2 are the learning parameters which are usually considered as equal. w represents the inertia weight which may be constant or variable. pBesti denotes the best known solution for the ith particle and lBestMemk is the best known solution of kth cell neighbour to which particle i belongs.\nOne major drawback of cellular PSO is that the number of cells increases exponentially as dimension of the problem and/or the number of the partitions increase. Moreover, it is not possible to change the number of cells during runtime. To overcome the problem of fixed number of cells, clustering is used to dynamically create groups in each cell whenever needed. By application of the clustering technique, it would be unnecessary to increase the number of cells in order to obtain a more precise search. Therefore, exponential increase in the number of cells is prevented. Furthermore, a local search procedure is applied for solution improvement."}, {"heading": "III. PROPOSED ALGORITHM", "text": "In cellular PSO, a CA is used for solution space partitioning. CA is known as a mathematical model of systems with several simple components which have local interactions. Using the local rules on CA, an ordered structure may be obtained from a completely random state. In CA, two wellknown neighborhood structures of Von Neumann and Moore are utilized as Figure 1.\nIn the proposed method, after partitioning the space into cells, clustering is generally applied to form groups of particles on which local search is applied during the cellular PSO procedure. In this algorithm each cell contains some groups, which are considered as multiswarm having Moore neighbourhood structure.\nVelocity of particles in each swam are updated as follows:\nk 1 1 k k\nNBest\n2 2 i k k\nv (t 1) a r (pBest p )\na r (c p ) wv (t)\n  \n  \n(3)\nWhere CiBbest gives the best position in the neighbor for cell i. The velocity of swarm is\ndefined by (4):\nk k kp (t 1) p (t) v (t 1)    (4)\nMoreover, the velocities of particles are\nupdated in each case by equation (5).\nBest\nk 1 1 k k 2 2 i k\nk\nv (t 1) a r (pBest p ) a r (c p )\nwv (t)\n    \n\n(5)\nIn the proposed algorithm, after each change a local search is performed for each swarm which increases the efficiency of the algorithm,. The local search is applied to the CBest of each cell. The overall process includes definition of a magnitude and a direction of movement for each dimension to determine magnitude and direction of the search in that dimension. Moving in each dimension according to the specified magnitude and direction, fitness is calculated for the obtained position and the current position is substituted by the obtained one if improved. Otherwise, the movement direction is reversed in that dimension and a new direction is followed there. An update is implemented when the fitness is improved performing the latter action, and if not, magnitude of movement is decreased and the process begins for the next dimension. The whole procedure is performed for all dimensions until further improvement becomes impossible in all dimensions for a given movement and the minimum magnitude of movement is reached in all dimensions.\nAccording to what discussed above, the proposed algorithm can be considered as the following steps:\n1. Initialize the cells and their regions 2. Distribute the particles normally among\ncells in each region\n3. Repeat the following steps until the\ntermination criteria is met 3.1. Evaluate particles 3.2. If the change detected in the\nenvironment by memory particle\n3.2.1. Re-initialize the parameters 3.2.2. Perform cellular movement of\nswarms\n3.2.3. Re-evaluate the particles\n3.3. Clustering the particles into each cell 3.4. Update velocity and position of the\nparticles\n3.5. Evaluate groups and cells 3.6. Perform local search in each group 3.7. Replace the particles in each inactive\ngroup\n4. End\nIn the algorithm above, when particles in a group converge to a point, the group becomes inactive and its particles are used as free particles for finding better solutions in other groups of the cell or within the neighbor cells. Fig. 2 depicts the running of the algorithm and clustering of the particles in a 2-D search space.\nIV. SIMULATION RESULTS"}, {"heading": "A. Static Environments", "text": "In the first experiment, the algorithm is performed on static standard benchmark unimodal and multimodal functions including, Sphere, Rastrigin, Griewank and Rosenbrock are defined in table I [12-14].\nTable I. Standard static functions for the experiments\nRange Function Name\n[-100,100]D  \n n\ni ixxf 1\n2\n1 )( Sphere\n[-.5.12,5.12]D\nn 2\n2 i i\ni 1 f (x) (x 10cos(2 x ) 10)      Griewank\n[-600,600]D   nn 2 i 3 i\ni 1 i 1 x1f (x) x cos 1 4000 i            Rastrigin\n[-5, 10]D    n 1 2 4 i 1 i\ni 1\nf (x) 100 x x 1 \n\n\n   Rosenbrock\nThe experiments are accomplished assuming different dimensions of 20, 30 and 50 and population size of 3 to 5 particles in each cell by using Von Neumann neighborhood structure and 3-cell partitioning. The results for 30 independent runs of the algorithm for 1000 iterations are provided in table II, table III and table IV. The inertia weight is considered as a random variable with values between 0.4 and 0.9. A comparison of the proposed algorithm, as CPSOL, with other versions of PSO, standard PSO as SPSO [16], Fuzzy PSO as FPSO [17], Linear PSO as LPSO [18] and Robust PSO as RPSO [19] is reported."}, {"heading": "B. Dynamic Environments", "text": "In order to evaluate the proposed algorithm in dynamic environments, several experiments performed on two famous dynamic environments as moving parabolic function and moving peaks benchmarks.\nB.1. Experiments on moving parabolic function\nIn the first experiment, order to evaluate the proposed method in dynamic environment, dynamic moving parabolic function generator, developed by Angeline [20] is employed, which is illustrated in figure 3. A moving parabolic benchmark changes by k using the following equation in this dynamic environment,:\n  2 2 2, ,   f x y z x y z (6)\nWhere, according to the movements one\nmay consider the equation:\n3\n2\n1 ( ) ( )    i i\nf x x k (7)\nThe movements are linear, circular or Gaussian with a magnitude of  and frequency of f satisfying the following equations.\n   k k  (8)\n2 sin\n25\n2 cos\n25\n       \n    \n         \nt k k oven\nk\nt k k odd\n \n \n(9)\n 0,1   k k N (10)\nWhere t in equation (9) denotes the cumulative number of changes in the function.\nDifferent types of changes are used in the experiments with d=30, f=200, 1000 and =0.01, 0.1. The dynamic moving parabolic is applied to Sphere function in the interval [-50, 50].\nIn order to compare the proposed method with other algorithms, the offline error (OE), provided by the equation (12) is used [15].\n  1\n( ) 1\n( \n  T\nbest\nt\ntOE f p T\n(11)\nWhere, f is the fitness function, T represents the maximum number of iterations and pBest(t) is the best known global solution\nfound by the algorithm in iteration t.\nIn this experiment, the proposed algorithm as CPSOL is compared with RPSO [21], mQSO 10(5+1q) [22], AmQSO [23] and CPSO [11] by offline error. For each one of the three different movements the results of OE are provided in Table VI, VII, and VIII.\nThe proposed method is superior to original Cellular PSO for all three types of movements while RPSO has the best performance among all the existing algorithms and provides more satisfying results. Generally, the proposed algorithm demonstrates acceptable performance in comparison with the original PSO.\nB.2. Experiments on moving peaks benchmark\nIn the second experiment, In order to evaluate the proposed algorithm in dynamic environments, several experiments are performed on Moving Peaks Benchmark (MPB). In the MPB, there are some peaks in a multi-dimensional space, where the height, width, and position of each peak alter when the environment changes. Unless stated otherwise, the parameters of MPB are set to the values listed in table 1 [4, 11].\nFor the proposed method the inertia weight is considered as a random variable between 0.4 and 0.9. The acceleration coefficient is set\nto 1.496180, the number of particles is 40; the type of neighborhood structure is Moore and the size of partition is 5.\nIn these experiments, proposed algorithm so called multi swarm cellular PSO based on local search as CPSOCL is compared with Hibernating Multi Swarm Optimization as (HmSO) [24], Learning Automata based Immune Algorithm as (LAIA) [5], Cellular Differential Evolution as (CDE) [4], Cellular Particle Swarm Optimization as (CPSO) [11], by offline error. For each experiment, the average offline error and standard deviation of 30 time-independent runs is addressed. The results of several dynamics are also listed in the table X, to XIII."}, {"heading": "M HmSO LAIA CDE CPSO CPSOL", "text": ""}, {"heading": "100 2.72\u00b10.04 3.14\u00b10.35 3.36\u00b10.01 4.23\u00b10.09 3.22\u00b10.07", "text": ""}, {"heading": "200 2.81\u00b10.04 3.08\u00b10.32 3.13\u00b10.01 4.09\u00b10.10 3.09\u00b10.12", "text": ""}, {"heading": "M HmSO LAIA CDE CPSO CPSOL", "text": ""}, {"heading": "100 1.68\u00b10.03 3.06\u00b10.24 2.73\u00b10.03 3.24\u00b10.09 2.84\u00b10.12", "text": ""}, {"heading": "200 1.71\u00b10.02 2.95\u00b10.23 2.61\u00b10.02 3.15\u00b10.08 2.69\u00b10.08", "text": "According to the results of the table X to XIII, the proposed algorithm is relatively advantageous over alternative algorithms."}, {"heading": "V. CONCLUSIONS", "text": "In this paper, an extension of cellular PSO algorithm augmented by clustering and local search in cellular environment is proposed. The inspiration for this research was to perform a more precise search without increasing the number of partitions. This is obtained by defining and using groups in each cell. The simulation results on both static and dynamic environments reveal an improvement as compared with its original version.\nREFERENCES\n[1] C. Cruz, J. R. Gonz\u00e1lez, D. A. Pelta,\n\u201cOptimization in dynamic environments: a survey\non problems, methods and measures,\u201d Intl. Journal\nof Soft Computing, Vol. 157, No. 7, 2011, pp. 1427-\n1448.\n[2] D. Ayvaz, H. R. Topcuoglu, F. Gurgen,\n\u201cPerformance evaluation of evolutionary heuristics\nin dynamic environments,\u201d Intl. Journal of Applied\nIntelligence, Vol. 37, No. 1, 2011, pp. 130\u2013144.\n[3] H. Wang, S. Yang, W. Ip, D. Wang, \u201cAdaptive\nPrimal\u2013Dual Genetic Algorithms in Dynamic\nEnvironments,\u201d Intl. Journal of IEEE Transactions\non Systems, Man, and Cybernetics, Part B:\nCybernetics, Vol. 39, No. 6, 2009, pp. 1348\u20131361.\n[4] V. Noroozi, A. Hashemi, M. R. Meybodi,\n\u201cCellularDE: a cellular based differential evolution\nfor dynamic optimization problems,\u201d in Adaptive\nand Natural Computing Algorithms, Vol. 6593, A.\nDobnikar, Ed. Springer-Verlag Berlin Heidelberg\n2010, pp. 340-349.\n[5] A. Rezvanian, M. R. Meybodi, \u201cAn adaptive\nmutation operator for artificial immune network\nusing learning automata in dynamic\nenvironments,\u201d in Proc. of 2010 Second World"}, {"heading": "Congress on Nature and Biologically Inspired", "text": "Computing (NaBIC), 2010, Kitakyshu, Japan, pp.\n479-483.\n[6] A. Rezvanian, M. R. Meybodi, \u201cTracking\nExtrema in Dynamic Environments Using a\nLearning Automata-Based Immune Algorithm,\u201d in"}, {"heading": "Grid and Distributed Computing, Control and", "text": "Automation, Vol. 121, T. H. Kim, Ed. Springer-\nVerlag Berlin Heidelberg 2010, pp. 216-225.\n[7] M. Mavrovouniotis, S. Yang, \u201cAnt colony\noptimization with immigrants schemes in dynamic\nenvironments,\u201d in Parallel Problem Solving from\nNature\u2013PPSN, vol. 6239, R. Schaefer, Ed. Springer-\nVerlag Berlin Heidelberg 2010, pp. 371-380.\n8\n[8] S. Nabizadeh, K. Faez, S. Tavassoli, A.\nRezvanian, \u201cA novel method for multi-level image\nthresholding using particle swarm Optimization\nalgorithms,\u201d in Proc. 2010 2nd Int. Conf. on\nComputer Engineering and Technology (ICCET),\n2010, Vol. 4, pp. 271-275.\n[9] R. I. Lung, D. Dumitrescu, \u201cA collaborative\nmodel for tracking optima in dynamic\nenvironments,\u201d in Proc. of IEEE Intl. Conf. on\nEvolutionary Computation (CEC), 2007, pp. 564-\n567.\n[10] A. B. Hashemi, M. R. Meybodi, \u201cA multi-role\ncellular PSO for dynamic environments,\u201d in Proc.\n14th Int. Conf. Of CSI, 2009, pp. 412-417.\n[11] A. B. Hashemi, M. R. Meybodi, \u201cCellular PSO: A\nPSO for dynamic environments,\u201d in Advances in\nComputation and Intelligence, vol. 5821, Z. Cai, Ed.\nSpringer-Verlag Berlin Heidelberg 2009, pp. 422-\n433.\n[12] A. B. Hashemi, M. R. Meybodi, \u201cA note on the\nlearning automata based algorithms for adaptive\nparameter selection in PSO,\u201d Intl. Journal of Applied\nSoft Computing, Vol. 11, No. 1, 2011, pp. 689-705.\n[13] A. Rezvanian, M. R. Meybodi, \u201cLACAIS:\nLearning Automata based Cooperative Artificial"}, {"heading": "Immune System for Function Optimization,\u201d in", "text": "Contemporary Computing, vol. 94, S. Ranka, Ed.\nSpringer-Verlag Berlin Heidelberg 2010, pp. 64-75.\n[14] S. Nabizadeh, M. R. Meybodi, A. Rezvanian,\n\u201cInertia Weight Tuning for PSO using FLC and LA-"}, {"heading": "AIS\u201d, in Proc. 10th Iranian Conf. on Fuzzy Systems", "text": "(IFS), Tehran, Iran, 2010, pp. 1-5.\n[15] S. Nabizadeh, A. Rezvanian, M. R. Meybodi, \u201cA\nMulti-Swarm Cellular PSO based on Clonal\nSelection Algorithm in Dynamic Environments,\u201d in"}, {"heading": "Proc. of IEEE Intl. Conf. on Informatics, Electronics &", "text": "Vision (ICIEV), 2012, Dhaka, Bangladesh, pp. 482-\n486.\n[16] J. Kennedy, R. Eberhart, \u201cParticle swarm\noptimization,\u201d in Proc. IEEE Int. Conf. on Neural\nNetworks (ICNN), 1995, Perth, USA, pp. 1942-1948.\n[17] Y. Shi, R. C. Eberhart, \u201cFuzzy adaptive particle\nswarm optimization,\u201d in Proc. of IEEE Intl. Conf. on\nEvolutionary Computation (CEC), 2001, Seoul,\nKorea, pp. 101-106.\n[18] Y. Shi, R. C. Eberhart, \u201cEmpirical study of\nparticle swarm optimization,\u201d in Proc. of IEEE Intl.\nConf. on Evolutionary Computation (CEC), 1999,\nWashington, USA, pp. 1945-1950.\n[19] Q. Luo, D. Yi, \u201cA co-evolving framework for\nrobust particle swarm optimization,\u201d Intl. Journal of\nApplied Mathematics and Computation, vol. 199,\n2008, pp. 611-622.\n[20] P. Angeline, \u201cTracking extrema in dynamic\nenvironments,\u201d in Evolutionary Programming VI,\nVol. 1213, 1997, pp. 335\u2013345.\n[21] X. Hu, R. C. Eberhart, \u201cAdaptive particle swarm\noptimization: detection and response to dynamic\nsystems,\u201d in Proc. of IEEE Intl. Conf. on Evolutionary\nComputation (CEC), 2002, Honolulu, USA, pp.\n1666-1670.\n[22] T. Blackwell, J. Branke, \u201cMultiswarms,\nexclusion, and anti-convergence in dynamic\nenvironments,\u201d Intl. Journal of IEEE Transactions on\nEvolutionary Computation, Vol. 10, No. 4, 2006, pp.\n459-472.\n[23] T. Blackwell, J. Branke, X. Li, \u201cParticle swarms\nfor dynamic optimization problems,\u201d in Swarm\nIntelligence, 2008, pp. 193-217.\n[24] M. Kamosi, A. B. Hashemi, M. R. Meybodi, \u201cA\nhibernating multi-swarm optimization algorithm for\ndynamic environments,\u201d in Proc. of 2010 Second"}, {"heading": "World Congress on Nature and Biologically Inspired", "text": "Computing (NaBIC), 2010, Kitakyshu, Japan, pp.\n363-369."}], "references": [{"title": "Optimization in dynamic environments: a survey on problems, methods and measures", "author": ["C. Cruz", "J.R. Gonz\u00e1lez", "D.A. Pelta"], "venue": "Intl. Journal of Soft Computing, Vol. 157, No. 7, 2011, pp. 1427- 1448.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2011}, {"title": "Performance evaluation of evolutionary heuristics in dynamic environments", "author": ["D. Ayvaz", "H.R. Topcuoglu", "F. Gurgen"], "venue": "Intl. Journal of Applied Intelligence, Vol. 37, No. 1, 2011, pp. 130\u2013144.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2011}, {"title": "Adaptive Primal\u2013Dual Genetic Algorithms in Dynamic Environments", "author": ["H. Wang", "S. Yang", "W. Ip", "D. Wang"], "venue": "Intl. Journal of IEEE Transactions on Systems, Man, and Cybernetics, Part B: Cybernetics, Vol. 39, No. 6, 2009, pp. 1348\u20131361.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2009}, {"title": "CellularDE: a cellular based differential evolution for dynamic optimization problems", "author": ["V. Noroozi", "A. Hashemi", "M.R. Meybodi"], "venue": "Adaptive and Natural Computing Algorithms, Vol. 6593, A. Dobnikar, Ed. Springer-Verlag Berlin Heidelberg 2010, pp. 340-349.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2010}, {"title": "An adaptive mutation operator for artificial immune network using learning automata in dynamic environments", "author": ["A. Rezvanian", "M.R. Meybodi"], "venue": "Proc. of 2010 Second World Congress on Nature and Biologically Inspired Computing (NaBIC), 2010, Kitakyshu, Japan, pp. 479-483.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2010}, {"title": "Tracking Extrema in Dynamic Environments Using a Learning Automata-Based Immune Algorithm", "author": ["A. Rezvanian", "M.R. Meybodi"], "venue": "Grid and Distributed Computing, Control and Automation, Vol. 121, T. H. Kim, Ed. Springer- Verlag Berlin Heidelberg 2010, pp. 216-225.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2010}, {"title": "Ant colony optimization with immigrants schemes in dynamic environments", "author": ["M. Mavrovouniotis", "S. Yang"], "venue": "Parallel Problem Solving from Nature\u2013PPSN, vol. 6239, R. Schaefer, Ed. Springer- Verlag Berlin Heidelberg 2010, pp. 371-380.  Tracking Extrema in Dynamic Environment using Multi-Swarm Cellular PSO with Local Search 8", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2010}, {"title": "A novel method for multi-level image thresholding using particle swarm Optimization algorithms", "author": ["S. Nabizadeh", "K. Faez", "S. Tavassoli", "A. Rezvanian"], "venue": "Proc. 2010 2nd Int. Conf. on Computer Engineering and Technology (ICCET), 2010, Vol. 4, pp. 271-275.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2010}, {"title": "A collaborative model for tracking optima in dynamic environments", "author": ["R.I. Lung", "D. Dumitrescu"], "venue": "Proc. of IEEE Intl. Conf. on Evolutionary Computation (CEC), 2007, pp. 564- 567.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2007}, {"title": "A multi-role cellular PSO for dynamic environments", "author": ["A.B. Hashemi", "M.R. Meybodi"], "venue": "Proc. 14th Int. Conf. Of CSI, 2009, pp. 412-417.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2009}, {"title": "Cellular PSO: A PSO for dynamic environments", "author": ["A.B. Hashemi", "M.R. Meybodi"], "venue": "Advances in Computation and Intelligence, vol. 5821, Z. Cai, Ed. Springer-Verlag Berlin Heidelberg 2009, pp. 422- 433.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2009}, {"title": "A note on the learning automata based algorithms for adaptive parameter selection in PSO", "author": ["A.B. Hashemi", "M.R. Meybodi"], "venue": "Intl. Journal of Applied Soft Computing, Vol. 11, No. 1, 2011, pp. 689-705.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2011}, {"title": "LACAIS: Learning Automata based Cooperative Artificial Immune System for Function Optimization", "author": ["A. Rezvanian", "M.R. Meybodi"], "venue": "Contemporary Computing, vol. 94, S. Ranka, Ed. Springer-Verlag Berlin Heidelberg 2010, pp. 64-75.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2010}, {"title": "Inertia Weight Tuning for PSO using FLC and LA- AIS", "author": ["S. Nabizadeh", "M.R. Meybodi", "A. Rezvanian"], "venue": "in Proc. 10th Iranian Conf. on Fuzzy Systems (IFS),", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2010}, {"title": "A Multi-Swarm Cellular PSO based on Clonal Selection Algorithm in Dynamic Environments", "author": ["S. Nabizadeh", "A. Rezvanian", "M.R. Meybodi"], "venue": "Proc. of IEEE Intl. Conf. on Informatics, Electronics & Vision (ICIEV), 2012, Dhaka, Bangladesh, pp. 482- 486.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2012}, {"title": "Particle swarm optimization", "author": ["J. Kennedy", "R. Eberhart"], "venue": "Proc. IEEE Int. Conf. on Neural Networks (ICNN), 1995, Perth, USA, pp. 1942-1948.", "citeRegEx": "16", "shortCiteRegEx": null, "year": 1995}, {"title": "Fuzzy adaptive particle swarm optimization", "author": ["Y. Shi", "R.C. Eberhart"], "venue": "Proc. of IEEE Intl. Conf. on Evolutionary Computation (CEC), 2001, Seoul, Korea, pp. 101-106.", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2001}, {"title": "Empirical study of particle swarm optimization", "author": ["Y. Shi", "R.C. Eberhart"], "venue": "Proc. of IEEE Intl. Conf. on Evolutionary Computation (CEC), 1999, Washington, USA, pp. 1945-1950.", "citeRegEx": "18", "shortCiteRegEx": null, "year": 1999}, {"title": "A co-evolving framework for robust particle swarm optimization", "author": ["Q. Luo", "D. Yi"], "venue": "Intl. Journal of Applied Mathematics and Computation, vol. 199, 2008, pp. 611-622.", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2008}, {"title": "Tracking extrema in dynamic environments", "author": ["P. Angeline"], "venue": "Evolutionary Programming VI, Vol. 1213, 1997, pp. 335\u2013345.", "citeRegEx": "20", "shortCiteRegEx": null, "year": 1997}, {"title": "Adaptive particle swarm optimization: detection and response to dynamic systems", "author": ["X. Hu", "R.C. Eberhart"], "venue": "Proc. of IEEE Intl. Conf. on Evolutionary Computation (CEC), 2002, Honolulu, USA, pp. 1666-1670.", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2002}, {"title": "Multiswarms, exclusion, and anti-convergence in dynamic environments", "author": ["T. Blackwell", "J. Branke"], "venue": "Intl. Journal of IEEE Transactions on Evolutionary Computation, Vol. 10, No. 4, 2006, pp. 459-472.", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2006}, {"title": "Particle swarms for dynamic optimization problems", "author": ["T. Blackwell", "J. Branke", "X. Li"], "venue": "Swarm Intelligence, 2008, pp. 193-217.", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2008}, {"title": "A hibernating multi-swarm optimization algorithm for dynamic environments", "author": ["M. Kamosi", "A.B. Hashemi", "M.R. Meybodi"], "venue": "Proc. of 2010 Second World Congress on Nature and Biologically Inspired Computing (NaBIC), 2010, Kitakyshu, Japan, pp. 363-369.", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2010}], "referenceMentions": [{"referenceID": 0, "context": "To be more specific, an algorithm can tackle such problems if it is capable of identifying changes in the environment and finding new optimum solutions [1].", "startOffset": 152, "endOffset": 155}, {"referenceID": 1, "context": "ir Tel: +98-21-64545120 optimization problems [2].", "startOffset": 46, "endOffset": 49}, {"referenceID": 2, "context": "Evolutionary algorithms such as genetic algorithm [3], differential evolution [4], artificial immune system [5,6], and ant colony optimization make these methods applicable for solving dynamic optimization problems by appropriate mechanisms.", "startOffset": 50, "endOffset": 53}, {"referenceID": 3, "context": "Evolutionary algorithms such as genetic algorithm [3], differential evolution [4], artificial immune system [5,6], and ant colony optimization make these methods applicable for solving dynamic optimization problems by appropriate mechanisms.", "startOffset": 78, "endOffset": 81}, {"referenceID": 4, "context": "Evolutionary algorithms such as genetic algorithm [3], differential evolution [4], artificial immune system [5,6], and ant colony optimization make these methods applicable for solving dynamic optimization problems by appropriate mechanisms.", "startOffset": 108, "endOffset": 113}, {"referenceID": 5, "context": "Evolutionary algorithms such as genetic algorithm [3], differential evolution [4], artificial immune system [5,6], and ant colony optimization make these methods applicable for solving dynamic optimization problems by appropriate mechanisms.", "startOffset": 108, "endOffset": 113}, {"referenceID": 7, "context": "Particle swarm optimization (PSO) algorithm has gained a significant attraction due to its simplicity and efficiency [8].", "startOffset": 117, "endOffset": 120}, {"referenceID": 8, "context": "In the multi-swarm algorithm proposed by [9], parents maintain diversity and identify promising regions while offspring searches local areas to find local optima.", "startOffset": 41, "endOffset": 44}, {"referenceID": 9, "context": "for partitioning the solution space into cells [10,11].", "startOffset": 47, "endOffset": 54}, {"referenceID": 10, "context": "for partitioning the solution space into cells [10,11].", "startOffset": 47, "endOffset": 54}, {"referenceID": 11, "context": "Afterwards, each particle is updated iteratively according to the best observed value for personal and global fitness to reach optimal fitness [12].", "startOffset": 143, "endOffset": 147}, {"referenceID": 10, "context": "This in turn increases efficiency of the algorithm [11].", "startOffset": 51, "endOffset": 55}, {"referenceID": 11, "context": "Static Environments In the first experiment, the algorithm is performed on static standard benchmark unimodal and multimodal functions including, Sphere, Rastrigin, Griewank and Rosenbrock are defined in table I [12-14].", "startOffset": 212, "endOffset": 219}, {"referenceID": 12, "context": "Static Environments In the first experiment, the algorithm is performed on static standard benchmark unimodal and multimodal functions including, Sphere, Rastrigin, Griewank and Rosenbrock are defined in table I [12-14].", "startOffset": 212, "endOffset": 219}, {"referenceID": 13, "context": "Static Environments In the first experiment, the algorithm is performed on static standard benchmark unimodal and multimodal functions including, Sphere, Rastrigin, Griewank and Rosenbrock are defined in table I [12-14].", "startOffset": 212, "endOffset": 219}, {"referenceID": 9, "context": "[-5, 10]D \uf028 \uf029 \uf028 \uf029 n 1 2 4 i 1 i i 1 f (x) 100 x x 1 \uf02d", "startOffset": 0, "endOffset": 8}, {"referenceID": 15, "context": "A comparison of the proposed algorithm, as CPSOL, with other versions of PSO, standard PSO as SPSO [16], Fuzzy PSO as FPSO [17], Linear PSO as LPSO [18] and Robust PSO as RPSO [19] is reported.", "startOffset": 99, "endOffset": 103}, {"referenceID": 16, "context": "A comparison of the proposed algorithm, as CPSOL, with other versions of PSO, standard PSO as SPSO [16], Fuzzy PSO as FPSO [17], Linear PSO as LPSO [18] and Robust PSO as RPSO [19] is reported.", "startOffset": 123, "endOffset": 127}, {"referenceID": 17, "context": "A comparison of the proposed algorithm, as CPSOL, with other versions of PSO, standard PSO as SPSO [16], Fuzzy PSO as FPSO [17], Linear PSO as LPSO [18] and Robust PSO as RPSO [19] is reported.", "startOffset": 148, "endOffset": 152}, {"referenceID": 18, "context": "A comparison of the proposed algorithm, as CPSOL, with other versions of PSO, standard PSO as SPSO [16], Fuzzy PSO as FPSO [17], Linear PSO as LPSO [18] and Robust PSO as RPSO [19] is reported.", "startOffset": 176, "endOffset": 180}, {"referenceID": 19, "context": "Experiments on moving parabolic function In the first experiment, order to evaluate the proposed method in dynamic environment, dynamic moving parabolic function generator, developed by Angeline [20] is employed, which is illustrated in figure 3.", "startOffset": 195, "endOffset": 199}, {"referenceID": 14, "context": "In order to compare the proposed method with other algorithms, the offline error (OE), provided by the equation (12) is used [15].", "startOffset": 125, "endOffset": 129}, {"referenceID": 19, "context": "Example dynamics; (a) Linear dynamic; (b) Circular dynamic; (c) Gaussian dynamic [20].", "startOffset": 81, "endOffset": 85}, {"referenceID": 20, "context": "In this experiment, the proposed algorithm as CPSOL is compared with RPSO [21], mQSO 10(5+1q) [22], AmQSO [23] and CPSO [11] by offline error.", "startOffset": 74, "endOffset": 78}, {"referenceID": 21, "context": "In this experiment, the proposed algorithm as CPSOL is compared with RPSO [21], mQSO 10(5+1q) [22], AmQSO [23] and CPSO [11] by offline error.", "startOffset": 94, "endOffset": 98}, {"referenceID": 22, "context": "In this experiment, the proposed algorithm as CPSOL is compared with RPSO [21], mQSO 10(5+1q) [22], AmQSO [23] and CPSO [11] by offline error.", "startOffset": 106, "endOffset": 110}, {"referenceID": 10, "context": "In this experiment, the proposed algorithm as CPSOL is compared with RPSO [21], mQSO 10(5+1q) [22], AmQSO [23] and CPSO [11] by offline error.", "startOffset": 120, "endOffset": 124}, {"referenceID": 3, "context": "Unless stated otherwise, the parameters of MPB are set to the values listed in table 1 [4, 11].", "startOffset": 87, "endOffset": 94}, {"referenceID": 10, "context": "Unless stated otherwise, the parameters of MPB are set to the values listed in table 1 [4, 11].", "startOffset": 87, "endOffset": 94}, {"referenceID": 0, "context": "0] cone width range W [1, 12] cone standard height I 50.", "startOffset": 22, "endOffset": 29}, {"referenceID": 11, "context": "0] cone width range W [1, 12] cone standard height I 50.", "startOffset": 22, "endOffset": 29}, {"referenceID": 23, "context": "In these experiments, proposed algorithm so called multi swarm cellular PSO based on local search as CPSOCL is compared with Hibernating Multi Swarm Optimization as (HmSO) [24], Learning Automata based Immune Algorithm as (LAIA) [5], Cellular Differential Evolution as (CDE) [4], Cellular Particle Swarm Optimization as (CPSO) [11], by offline error.", "startOffset": 172, "endOffset": 176}, {"referenceID": 4, "context": "In these experiments, proposed algorithm so called multi swarm cellular PSO based on local search as CPSOCL is compared with Hibernating Multi Swarm Optimization as (HmSO) [24], Learning Automata based Immune Algorithm as (LAIA) [5], Cellular Differential Evolution as (CDE) [4], Cellular Particle Swarm Optimization as (CPSO) [11], by offline error.", "startOffset": 229, "endOffset": 232}, {"referenceID": 3, "context": "In these experiments, proposed algorithm so called multi swarm cellular PSO based on local search as CPSOCL is compared with Hibernating Multi Swarm Optimization as (HmSO) [24], Learning Automata based Immune Algorithm as (LAIA) [5], Cellular Differential Evolution as (CDE) [4], Cellular Particle Swarm Optimization as (CPSO) [11], by offline error.", "startOffset": 275, "endOffset": 278}, {"referenceID": 10, "context": "In these experiments, proposed algorithm so called multi swarm cellular PSO based on local search as CPSOCL is compared with Hibernating Multi Swarm Optimization as (HmSO) [24], Learning Automata based Immune Algorithm as (LAIA) [5], Cellular Differential Evolution as (CDE) [4], Cellular Particle Swarm Optimization as (CPSO) [11], by offline error.", "startOffset": 327, "endOffset": 331}], "year": 2013, "abstractText": "Many real-world phenomena can be modelled as dynamic optimization problems. In such cases, the environment problem changes dynamically and therefore, conventional methods are not capable of dealing with such problems. In this paper, a novel multi-swarm cellular particle swarm optimization algorithm is proposed by clustering and local search. In the proposed algorithm, the search space is partitioned into cells, while the particles identify changes in the search space and form clusters to create sub-swarms. Then a local search is applied to improve the solutions in the each cell. Simulation results for static standard benchmarks and dynamic environments show superiority of the proposed method over other alternative approaches.", "creator": "Microsoft\u00ae Word 2010"}}}