{"id": "1311.5836", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "22-Nov-2013", "title": "Automatic Ranking of MT Outputs using Approximations", "abstract": "Since long, research on machine translation has been ongoing. Still, we do not get good translations from MT engines so developed. Manual ranking of these outputs tends to be very time consuming and expensive, so our goal is to create better quality-of-life translations from the data and analysis of these outputs. Therefore, we will use this to evaluate whether or not the results are correct in the published data. As a result, the final results from the MTLM project are still not perfect.\n\n\n\nI can't say yet that we have to create any perfect results from the data and analysis of this project, but I will show you how to perform it. In the next section, I will try to give you the best available results from the various MTLM projects available at this time.\nA detailed list of the MTLM projects available here:\nMTLM :\nMTLM :\nMTLM :\nMTLM :\nMTLM :\nMTLM :\nMTLM :\nMTLM :\nMTLM :\nMTLM :\nMTLM :\nMTLM :\nMTLM :\nMTLM :\nMTLM :\nMTLM :\nMTLM :\nMTLM :\nMTLM :\nMTLM :\nMTLM :\nMTLM :\nMTLM :\nMTLM :\nMTLM :\nMTLM :\nMTLM :\nMTLM :\nMTLM :\nMTLM :\nMTLM :\nMTLM :\nMTLM :\nMTLM :\nMTLM :\nMTLM :\nMTLM :\nMTLM :\nMTLM :\nMTLM :\nMTLM :\nMTLM :\nMTLM :\nMTLM :\nMTLM :\nMTLM :\nMTLM :\nMTLM :\nMTLM :\nMTLM :\nMTLM :\nMTLM :\nMTLM :\nMTLM :\nMTLM :\nMTLM :\nMTLM :\nMTLM :\nMTLM :\nMTLM :\nMTLM :\nMTLM :\nMTLM :\nMTLM :\nMTLM :\nMTLM :\nMTLM :\nM", "histories": [["v1", "Fri, 22 Nov 2013 18:13:06 GMT  (537kb)", "http://arxiv.org/abs/1311.5836v1", null]], "reviews": [], "SUBJECTS": "cs.CL", "authors": ["pooja gupta", "nisheeth joshi", "iti mathur"], "accepted": false, "id": "1311.5836"}, "pdf": {"name": "1311.5836.pdf", "metadata": {"source": "CRF", "title": "Automatic Ranking of MT Outputs using Approximations", "authors": ["Pooja Gupta", "Nisheeth Joshi", "Iti Mathur"], "emails": ["poojagupta2291@gmail.com", "nisheeth.joshi@rediffmail.com", "mathur_iti@rediffmail.com"], "sections": [{"heading": "General Terms", "text": "Natural Language Processing, Machine Translation"}, {"heading": "Keywords", "text": "N-gram Language Models, Trigram Approximations, Maximum Likelihood Estimation."}, {"heading": "1. INTRODUCTION", "text": "Ngram approximation is the subtask of Natural Language Processing (NLP), which is the branch of artificial intelligence. Approximation has many applications mainly in machine translation and natural language processing. In this paper we present an unsupervised learning approach for the development of a Ranking System. For this, we have done our study on English-Hindi language pair. We describe the discriminative training approach of machine learning in detail to identify the best MT Engine Output. The main idea behind the use of MT Engine output is to predict the correct translation of a sentence. Assessing the correct machine translation output is very difficult. There are lots of MT engines being developed in the world and there are various measures through which the quality of machine translation can be computed. With the help of Ranking System we can find out the best and accurate translation in minimum time.\nThe rest of the paper is organized as follows: Section 2 reviews the work that has been done in this area. Section 3 describes our approach. Section 4 describes the evaluation and results of the study. Finally section 5 concludes the paper."}, {"heading": "2. LITERATURE SURVEY", "text": "A lot of research work has been done and is still going on in machine translation. As we know that Machine Translation (MT) is becoming very popular among end-users. The main idea of estimating the quality of automatic translations for a particular task is called as the confidence estimation [1]. This confidence estimations task has been transformed into quality estimation task where the central idea remains the same. This\nquality estimation task is a rather recent aspect in research on Machine Translation.\nIn this area, previous work includes statistical methods on predicting word-level confidence [2] where just by looking at words people tried to analyze the quality of the translation. This method was extended by Specia et al. [3] who applied a regression technique and used SVM based classifiers. Raybaud et al., 2009) [4] further extended this study by estimating correctness using several probabilistic measures. In this direction, Rosti et al. [5] also performed sentence-level selections with generalized linear models that were based on re-ranking of N-best lists merged from many MT systems. Ye et al. [6] have described machine translation evaluation as a ranking problem as it is often done by the humans. The results show that the greater co-relation with human assessment at the sentence level can be achieved if ranking of translations is done. The authors have also used the n-gram match.\nSoricut and Narsal [7] used machine learning for ranking the candidate translations; they then selected the highest-ranked translation as the final output. Avramidis [8] showed an approach of ranking the outputs using grammatical features. He used statistical parser to analyze and generate ranks for several MT outputs. Gupta et al. [9] applied a na\u00efve bayes classifier on English-Hindi Machine Translation System and ranked them. They have used the baseline system that was provided for quality estimation task of WMT 2012 workshop to extract the features of English sentences and its translations produced by MT systems. For evaluating the quality of the systems the authors have used some linguistic features. The authors have also compared the results of the automatic evaluation metrics. Moore and Quirk [10] described smoothing method for N-gram language models based on ordinary counts for generation of language models which can be used for quality estimation task. Setiawan and Zhou [11] employed discriminative training of 150 million translation parameters and its applications to pruning. They had used various pruning techniques for estimation of quality and thus ranking the translations."}, {"heading": "3. OUR APPROACH", "text": "We have used a language model for ranking MT outputs. As language models can very easy capture the structure (grammar) of the language. For this they do not rely on any linguistic analysis but instead requires a large corpus onto which they can apply mathematical models. In this study we have used markov assumption and have used markov chains of order 2."}, {"heading": "3.1 Experimental Setup", "text": "For development of our system, we used 35,000 sentences from tourism domain. These were English sentences with their translations provided by a human. We generated the unigrams, bigrams and trigrams on these 35K sentences. The statistics of this study is shown in table 1. Equations 1, 2 and 3 show the generation of uni, bi and trigarms.\n( ) = ( )| | (1) ( ) = ( )( ) (2) ( ) = ( )( ) (3)"}, {"heading": "Corpus Sentences Trigrams Bigrams Unigrams", "text": "We also used GIZA++ to generate English-Hindi parallel lexicons which we then manually checked and corrected. We used the following algorithm to generate the n-grams for our study. We applied this algorithm on both English as well as Hindi sentences separately. Input: Raw sentences Output: Annotated Text (N-grams text)"}, {"heading": "LM Algorithm", "text": "Step1. Input raw sentence file and repeat steps 2 to 4 for each sentence. Step2. Split each word of the sentence. Step3. Generate trigrams, bigrams and unigrams for the entire sentence. Step4. If n-gram is already present than increase the frequency count. Step5. If n-gram is unique than it will sort in descending order by their frequencies. Step6. Generate Probability of trigrams using equation 3. Step7. Generate Probability of bigrams using equation 2. Step8. Generate Probability of unigrams using equation 1. Step9. Output obtained in file is in our desired n-garm\nformat.\nFor our study we have used 1300 English sentences and used six MT engines. The list of engines is shown in table 2. Among these E1, E2 and E3 are MT engines freely available on the internet. E4, E5 and E6 are MT engines that we have developed using different MT toolkits. E4 was a MT system which was trained using Moses MT toolkit [12]. This system used syntax based model [13]. We used Collins parser to generate parses of English sentences and used a tree to string model to train the system. E5 was a simple phrase based MT system which also used Moses MT toolkit. E6 was an example based MT system that was developed by Joshi et al. [14] [15]. These three systems used the 35000 English-Hindi parallel corpora to train and tune themselves. We used 80-20 ratio for training and tuning i.e. we used 28000 sentences to train the systems and remaining 7000 sentences to tune the systems."}, {"heading": "3.2 Methodology", "text": "To rank MT outputs of various systems we first generated the trigrams of English sentence as well as its translations which were produced by different MT engines. To rank the translations we applied the following algorithm:\nInput: English Sentence with MT outputs Output: Ranked MT output list"}, {"heading": "Ranking Algorithm", "text": "Step1. Trigrams from English sentences are generated. Step2. These trigrams are matched with English language model and matched ones are retained. Step3. Match retained English trigram\u2019s lexicons with English-Hindi parallel lexicon list. Step4. If a match is found then register corresponding Hindi lexicon. Step5. Match Hindi language model with registered Hindi lexicons and sum the probabilities of each match. Step6. Perform these steps on all MT outputs. Step7. Sort MT outputs in descending order with respect to\ntheir cumulative probabilities.\nTable 2. MT Systems"}, {"heading": "Engine No. Description", "text": "E1 Microsoft Bing MT Engine1 E2 Google MT Engine2 E3 Babylon MT Engine3 E4 Moses Syntax Based Model E5 Moses Phrase Model E6 Example Based MT Engine\nFigure 1 shows the working of this entire approach. To have a better understanding of the functionality, we have illustrated the entire process through the following example.\nEnglish Sentence: Jim Corbett National Park is the oldest national park in India and was established in 1936 as Hailey National Park to protect the endangered Bengal tiger."}, {"heading": "E1 Output: \u093f\u091c\u092e \u0915\u0949\u092c\u091f \u0928\u0947\u0936\u0928\u0932 \u092a\u093e\u0915 \u092d\u093e\u0930\u0924 \u092e \u0938\u092c\u0938 \u0947 \u092a\u0941\u0930\u093e\u0928\u093e", "text": "\u0930\u093e \u092f \u0909 \u092f\u093e\u0928 \u0939\u0948 \u0914\u0930 1936 \u092e Hailey \u0930\u093e \u092f \u0909 \u092f\u093e\u0928 \u0915\u0947 \u092a \u092e \u0932\u0941 \u0924 \u093e\u092f \u092c\u0917\u0902\u093e\u0932 \u092c\u093e\u0918 \u0915 \u0930 \u093e \u0915\u0947 \u0932\u090f \u0925\u093e \u092a\u0924 \u0915\u092f\u093e \u0917\u092f\u093e \u0925\u093e\u0964"}, {"heading": "E2 Output: \u093f\u091c\u092e \u0915\u0949\u092c\u091f \u0928\u0936\u0947\u0928\u0932 \u092a\u093e\u0915 \u092d\u093e\u0930\u0924 \u092e \u0938\u092c\u0938 \u0947\u092a\u0941\u0930\u093e\u0928\u093e", "text": "\u0930\u093e \u092f \u0909 \u092f\u093e\u0928 \u0939\u0948 \u0914\u0930 \u0932\u0941 \u0924 \u093e\u092f \u092c\u0917\u0902\u093e\u0932 \u091f\u093e\u0907\u0917\u0930 \u0915 \u0930 \u093e \u0915\u0947 \u0932\u090f \u0939\u0947\u0932 \u0928\u0947\u0936\u0928\u0932 \u092a\u093e\u0915 \u0915\u0947 \u092a \u092e 1936 \u092e \u0925\u093e \u092a\u0924 \u0915\u092f\u093e \u0917\u092f\u093e \u0925\u093e."}, {"heading": "E3 Output: \u093f\u091c\u092e \u0915\u093e\u092c\u091f \u0930\u093e \u092f \u0909 \u092f\u093e\u0928 \u0915 \u0925\u093e\u092a\u0928\u093e \u0915 \u0917\u0908", "text": "\u0925\u0940 \u0914\u0930 \u092d\u093e\u0930\u0924 \u092e \u0938\u092c\u0938\u0947 \u092a\u0941\u0930\u093e\u0928\u0947 \u0930\u093e \u092f \u0909 \u092f\u093e\u0928 \u092e 1936 \u092e \u0930\u093e \u092f \u092a\u093e\u0915 \u0915\u094b \u092c\u091a\u093e\u0928\u0947 \u0915\u0947 \u0932\u090f \u0939\u0947\u0932 \u0938\u0915\u0902\u091f\u093e\u092a \u0928 \u092c\u0917\u0902\u093e\u0932 \u091f\u093e\u0907\u0917\u0930 \u0939\u0948\u0964"}, {"heading": "E4 Output: \u093f\u091c\u092e \u0915\u094b\u092c\u0924 \u0928\u093e\u0936\u0928\u0932 \u092a\u093e\u0915 \u092d\u093e\u0930\u0924 \u092e \u0938\u092c\u0938 \u0947\u092a\u0941\u0930\u093e\u0928\u093e", "text": "\u0930\u093e \u092f \u092a\u093e\u0915 \u0939\u0948 \u0914\u0930 \u092f\u093e \u0939\u0947 \u0932 \u0928\u093e\u0936\u0928\u0932 \u092a\u093e\u0915\n1 http://www.microsofttranslator.com 2 http://translate.goolge.com 3 http://translation.babylon.com\n\u0915 \u0924\u0930\u0939 1936 \u092e \u0925\u093e \u092a\u0924 \u0915\u092f\u093e \u0939\u0941 \u0906 \u0938\u0915\u0902\u091f\u093e\u092a \u0928 \u092c\u0902\u0917\u093e\u0932 \u092c\u093e\u0918 \u092c\u091a\u093e\u0928\u093e \u0925\u093e \u0964\nE5 Output: \u093f\u091c\u092e \u0915\u0949\u092c \u0924 \u0928\u093e\u0917 \u0930\u0915 \u0909 \u092f\u093e\u0928 \u092d\u093e\u0930\u0924 \u092e 1936 \u092e \u0939\u0948\u0932\u092f\u0947 \u0928\u093e\u0917 \u0930\u0915 \u0909 \u092f\u093e\u0928 \u0915\u0947 \u092a \u092e \u092c\u0941 \u0922\u093e \u0930\u093e \u092f \u0909 \u092f\u093e\u0928 \u0910 \u0921\u091c\u0930\u0947\u0926 \u092c\u0902\u0917\u093e\u0932 \u092c\u093e\u0918 \u0930 \u093e \u0915\u0930\u0924 \u0947\u0939 \u0939\u0948 |"}, {"heading": "E6 Output: \u093f\u091c\u092e \u0915\u0949\u092c\u091f \u0928\u0936\u0928\u0932 \u092a\u093e\u0915 \u0915\u094b \u092d\u093e\u0930\u0924 \u092e \u093e\u091a\u0940\u0928", "text": "\u0930\u093e \u092f \u092a\u093e\u0915 \u0939 \u0914\u0930 \u091c\u0947 \u0916\u092e \u092e \u0921\u093e\u0932\u093e \u0917\u092f\u093e \u092c\u0917\u0902\u093e\u0932 \u0936\u0947\u0930 \u0930 \u093e \u0915\u0930\u0928\u0947 \u0915\u0947 \u0932\u090f \u0939\u0948\u0932\u0940\u0947 \u0928\u0936\u0928\u0932 \u092a\u093e\u0915 \u0915\u0947 \u092a \u092e 1936 \u092e \u0925\u093e \u092a\u0924 \u0915\u092f\u093e \u0917\u092f\u093e \u0925\u093e"}, {"heading": "Engine Unigrams Bigrams Trigrams Prob.", "text": "Table 3 shows the n-gram statistics of these sentences and also shows the sum of cumulative probabilities of these trigrams. By looking at the data we can rank the system according to their probabilities."}, {"heading": "4. EVALUATION", "text": "To evaluate the performance of our system we collected 1300 sentences from tourism domain. These sentences were not part of 35000 that were used to train the models. To validate our results we compared the ranks of the system with the ranks given to MT systems by a human evaluator. The human evaluator used a subjective human evaluation metric that we used by Joshi et al. [16]. This metric evaluated an MT output on ten parameters. These were:\n1. Translation of Gender and Number of the Noun(s). 2. Identification of the Proper Noun(s). 3. Use of Adjectives and Adverbs corresponding to the\nNouns and Verbs. 4. Selection of proper words/synonyms (Lexical Choice). 5. Sequence of phrases and clauses in the translation. 6. Use of Punctuation Marks in the translation 7. Translation of tense in the sentence 8. Translation of Voice in the sentence 9. Maintaining the semantics of the source sentence in the\ntranslation 10. Fluency of translated text and translator\u2019s proficiency\nEach MT outputs were adjudged on these 10 parameters. The human evaluator was asked to give a score on a 5-point scale. The scale is shown is table 4. Each sentence\u2019s 10 scores were then averaged to get a single score which was then used to rank MT outputs. Joshi et al. [17] have illustrated the entire working and detailed evaluation of this metric.\nWe evaluated the system generated ranks with human ranks in three different categories. At first we compared the ranks of all the systems, irrespective of their type. In second category we compared the ranks of only web based systems and in third category we compared the ranks of only MT toolkits or system which had very limited corpora to train and tune themselves.\nIn combined category, engine E1 performed better than any other MT engine. It scored the highest rank. Out of 1300 sentences, it managed to score highest rank for 467 sentences. Engine E2 was the second best while engines E3 and E4 did not performed so well. Table 5 shows the results of this ranking. These ranks were similar to the ranks provided by human evaluator.\nIn web-based category, again E1 and E2 performed better and were the top ranking systems while E3 was the worst. Table 6 shows the results of this study. In MT Toolkits category, E6 performed better than other MT engines and E4 was the worst engine. Table 7 shows the results of this study. Figure 2, 3 and 4 summarizes this data."}, {"heading": "5. CONCLUSION", "text": "In this paper, we have shown the effective use of language models in ranking MT systems. For this we had generated language models for English as well as Hindi. We have also\nused parallel lexicons to align the trigrams so produced. We also evaluated the MT engines against 1300 sentences which were not part of the training corpus and compared the ranks provided by a human judge. It was found that the ranks produced by LM based ranking and the ranks of human judge were similar. Thus we came to the conclusion that we can use this technique to automatic rank MT systems.\nThis can be considered as a preliminary study as we still need to perform more experiments to make any sound assumptions. Moreover as an immediate future study we can incorporate part of speech and morphological features into language models and then perform the rank and see if the performance of the system improves or not. Moreover we can also train classifiers and do the ranking. In both these studies this ranking system can be considered as a baseline system."}, {"heading": "6. REFERENCES", "text": "[1] Blatz, J., Fitzgerald, E., Foster, G., Gandrabur, S.,\nGoutte, C., Kulesza, A., Sanchis, A, & Ueffing, N. 2004. Confidence estimation for machine translation. In proceedings of 20th Coling, Geneva.\n[2] Ueffing, N., & Ney, H. 2005. Word-level confidence estimation for machine translation using phrase-based translation models. Computational Linguistics.\n[3] Specia, L., Turchi, M., Cancedda, N., Dymetman, M., & Cristianini, N. 2009. Estimating the Sentence-Level Quality of Machine Translation Systems. In 13th Annual Meeting of the European Association for Machine Translation (EAMT-2009) Barcelona, Spain.\n[4] Raybaud, S., Lavecchia, C., David, L., & Kamel, S. 2009. Word-and sentence-level confidence measures for machine translation. In 13th Annual Meeting of the European Association for Machine Translation (EAMT2009), Barcelona, Spain. European Association of Machine Translation.\n[5] Rosti, A.-V., Ayan, N. F., Xiang, B., Matsoukas, S., Schwartz, R., & Dorr, B. J. 2007. Combining Outputs from Multiple Machine Translation Systems. In Proceedings of the North American Chapter of the Association for Computational Linguistics Human Language Technologies. Rochester, New York. Association for Computational Linguistics.\n[6] Tavel, P. 2007 Modeling and Simulation Design. AK Peters Ltd.\n[7] Soricut, R., & Narsale, S. 2012. Combining Quality Prediction and System Selection for Improved Automatic Translation Output. In Proceedings of the Seventh Workshop on Statistical Machine Translation, Montr\u00e9al, Canada. Association for Computational Linguistics.\n[8] Avramidis E. 2012. Quality Estimation for Machine Translation output using linguistic analysis and decoding features. In Proceedings of the 7th Workshop on Statistical Machine Translation, Montr\u00e9al, Canada June7-8, 2012\n[9] Gupta, R., Joshi, N., & Mathur, I. 2013. Analysing Quality of English-Hindi Machine Translation Engine Outputs Using Bayesian Classification. International Journal of Artificial Intelligence and Applications, Vol 4, No 4, pp 165-171.\n[10] Moore, R.C., & Quirk, C. 2009. Improved Smoothing for N-gram Language Models Based on Ordinary Counts. In Proceedings of the ACL-IJCNLP 2009 Conference Short Papers.\n[11] Setiawan, H., & Zhou, B. 2013. Discriminative Training of 150 Million Translation Parameters and Its Application to Pruning. In Proceedings of NAACL-HLT 2013.\n[12] Koehn, P., Hoang, H., Birch, A., Callison-Burch, C., Federico, M., Bertoldi, N., Cowan, B., Shen, W., Moran, C., Zens, R., Dyer, C., Bojar, O., Constantin, A., & Herbst, E. 2007. Moses: Open source toolkit for statistical machine translation. In Proceedings of the Annual Meeting of the Association for Computational Linguistics, demonstration session.\n[13] Hoang, H., Koehn, P., & Lopez, A. 2009. A unified framework for phrase-based, hierarchical, and syntaxbased statistical machine translation. In Proc. of the International Workshop on Spoken Language Translation, Tokyo, Japan.\n[14] Joshi N., Mathur I., and Mathur S. 2011. Translation Memory for Indian Languages: An Aid for Human Translators, Proceedings of 2nd International Conference and Workshop in Emerging Trends in Technology\n[15] Joshi, N., and Mathur, I. 2012. Design of English-Hindi Translation Memory for Efficient Translation. In Proc. of National Conference on Recent Advances in Computer Engineering.\n[16] Joshi, N., Darbari, H, & Mathur, I. 2012, Human and Automatic Evaluation of English to Hindi Machine Translation Systems.\" Advances in Computer Science, Engineering & Applications. Springer Berlin Heidelberg, 2012. 423-432.\n[17] Joshi, N., Mathur, I., Darbari, H, & Kumar, A. 2013, HEval: Yet Another Human Evaluation Metric. International Journal of Natural Language Computing, Vol 2, No 5, pp 21-36.\nIJCATM: www.ijcaonline.org"}], "references": [{"title": "Confidence estimation for machine translation", "author": ["J. Blatz", "E. Fitzgerald", "G. Foster", "S. Gandrabur", "C. Goutte", "A. Kulesza", "A Sanchis", "N. Ueffing"], "venue": "In proceedings of 20th Coling, Geneva", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2004}, {"title": "Word-level confidence estimation for machine translation using phrase-based translation models", "author": ["N. Ueffing", "H. Ney"], "venue": null, "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2005}, {"title": "Estimating the Sentence-Level Quality of Machine Translation Systems. In 13th Annual Meeting of the European Association for Machine Translation (EAMT-2009) Barcelona, Spain", "author": ["L. Specia", "M. Turchi", "N. Cancedda", "M. Dymetman", "N. Cristianini"], "venue": null, "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2009}, {"title": "Word-and sentence-level confidence measures for machine translation. In 13th Annual Meeting of the European Association for Machine Translation (EAMT", "author": ["S. Raybaud", "C. Lavecchia", "L. David", "S. Kamel"], "venue": "European Association of Machine Translation", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2009}, {"title": "Combining Outputs from Multiple Machine Translation Systems", "author": ["Rosti", "A.-V", "N.F. Ayan", "B. Xiang", "S. Matsoukas", "R. Schwartz", "B.J. Dorr"], "venue": "In Proceedings of the North American Chapter of the Association for Computational Linguistics Human Language Technologies", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2007}, {"title": "Modeling and Simulation Design", "author": ["P. Tavel"], "venue": "AK Peters Ltd", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2007}, {"title": "Combining Quality Prediction and System Selection for Improved Automatic Translation Output", "author": ["R. Soricut", "S. Narsale"], "venue": "In Proceedings of the Seventh Workshop on Statistical Machine Translation,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2012}, {"title": "Quality Estimation for Machine Translation output using linguistic analysis and decoding features", "author": ["E. Avramidis"], "venue": "In Proceedings of the 7th Workshop on Statistical Machine Translation, Montre\u0301al, Canada", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2012}, {"title": "Analysing Quality of English-Hindi Machine Translation Engine Outputs Using Bayesian Classification", "author": ["R. Gupta", "N. Joshi", "I. Mathur"], "venue": "International Journal of Artificial Intelligence and Applications,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2013}, {"title": "Improved Smoothing for N-gram Language Models Based on Ordinary Counts", "author": ["R.C. Moore", "C. Quirk"], "venue": "In Proceedings of the ACL-IJCNLP 2009 Conference Short Papers", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2009}, {"title": "Discriminative Training of 150 Million Translation Parameters and Its Application to Pruning", "author": ["H. Setiawan", "B. Zhou"], "venue": "In Proceedings of NAACL-HLT", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2013}, {"title": "A unified framework for phrase-based, hierarchical, and syntaxbased statistical machine translation", "author": ["H. Hoang", "P. Koehn", "A. Lopez"], "venue": "In Proc. of the International Workshop on Spoken Language Translation,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2009}, {"title": "Translation Memory for Indian Languages: An Aid for Human Translators", "author": ["N. Joshi", "I. Mathur", "S. Mathur"], "venue": "Proceedings of 2nd International Conference and Workshop in Emerging Trends in Technology", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2011}, {"title": "Design of English-Hindi Translation Memory for Efficient Translation", "author": ["N. Joshi", "I. Mathur"], "venue": "In Proc. of National Conference on Recent Advances in Computer Engineering", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2012}, {"title": "Human and Automatic Evaluation of English to Hindi Machine Translation Systems.\" Advances in Computer Science, Engineering & Applications", "author": ["N. Joshi", "H Darbari", "I. Mathur"], "venue": null, "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2012}, {"title": "HEval: Yet Another Human Evaluation Metric", "author": ["N. Joshi", "I. Mathur", "H Darbari", "A. Kumar"], "venue": "International Journal of Natural Language Computing,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2013}], "referenceMentions": [{"referenceID": 0, "context": "The main idea of estimating the quality of automatic translations for a particular task is called as the confidence estimation [1].", "startOffset": 127, "endOffset": 130}, {"referenceID": 1, "context": "In this area, previous work includes statistical methods on predicting word-level confidence [2] where just by looking at words people tried to analyze the quality of the translation.", "startOffset": 93, "endOffset": 96}, {"referenceID": 2, "context": "[3] who applied a regression technique and used SVM based classifiers.", "startOffset": 0, "endOffset": 3}, {"referenceID": 3, "context": ", 2009) [4] further extended this study by estimating correctness using several probabilistic measures.", "startOffset": 8, "endOffset": 11}, {"referenceID": 4, "context": "[5] also performed sentence-level selections with generalized linear models that were based on re-ranking of N-best lists merged from many MT systems.", "startOffset": 0, "endOffset": 3}, {"referenceID": 5, "context": "[6] have described machine translation evaluation as a ranking problem as it is often done by the humans.", "startOffset": 0, "endOffset": 3}, {"referenceID": 6, "context": "Soricut and Narsal [7] used machine learning for ranking the candidate translations; they then selected the highest-ranked translation as the final output.", "startOffset": 19, "endOffset": 22}, {"referenceID": 7, "context": "Avramidis [8] showed an approach of ranking the outputs using grammatical features.", "startOffset": 10, "endOffset": 13}, {"referenceID": 8, "context": "[9] applied a na\u00efve bayes classifier on English-Hindi Machine Translation System and ranked them.", "startOffset": 0, "endOffset": 3}, {"referenceID": 9, "context": "Moore and Quirk [10] described smoothing method for N-gram language models based on ordinary counts for generation of language models which can be used for quality estimation task.", "startOffset": 16, "endOffset": 20}, {"referenceID": 10, "context": "Setiawan and Zhou [11] employed discriminative training of 150 million translation parameters and its applications to pruning.", "startOffset": 18, "endOffset": 22}, {"referenceID": 11, "context": "This system used syntax based model [13].", "startOffset": 36, "endOffset": 40}, {"referenceID": 12, "context": "[14] [15].", "startOffset": 0, "endOffset": 4}, {"referenceID": 13, "context": "[14] [15].", "startOffset": 5, "endOffset": 9}, {"referenceID": 14, "context": "[16].", "startOffset": 0, "endOffset": 4}, {"referenceID": 15, "context": "[17] have illustrated the entire working and detailed evaluation of this metric.", "startOffset": 0, "endOffset": 4}], "year": 2013, "abstractText": "Since long, research on machine translation has been ongoing. Still, we do not get good translations from MT engines so developed. Manual ranking of these outputs tends to be very time consuming and expensive. Identifying which one is better or worse than the others is a very taxing task. In this paper, we show an approach which can provide automatic ranks to MT outputs (translations) taken from different MT Engines and which is based on N-gram approximations. We provide a solution where no human intervention is required for ranking systems. Further we also show the evaluations of our results which show equivalent results as that of human ranking. General Terms Natural Language Processing, Machine Translation", "creator": null}}}