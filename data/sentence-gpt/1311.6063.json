{"id": "1311.6063", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "23-Nov-2013", "title": "A Short Introduction to NILE", "abstract": "In this paper, we briefly introduce MiniNLP, a natural language processing library for clinical narratives. MiniNLP is an experiment of our ideas on efficient and effective medical language processing. We introduce the overall design of MiniNLP and its major components, and show the performance of it in real projects. It is a natural language processing library for clinical narratives.\n\n\n\n\nIntroduction\n\n\nMiniNLP is a relatively new type of natural language processing library. In its initial incarnation, the miniNLP was not supported in the traditional way, so there was no development into a full-fledged language processor. In fact, the basic development stage of MiniNLP was quite recent. At the time of this paper, we had already been writing a few papers on the underlying features of miniNLP, such as the introduction of the new multi-tasking memory controller, and more. The paper describes the advantages and disadvantages of MiniNLP on the one hand and the limitations of MiniNLP on the other.\nThe introduction of a miniNLP as a language\nThe primary issue of MiniNLP was the design of the miniNLP which took a lot of work to do. The purpose of the project was to introduce miniNLP in the first place. It would make the language an easy to use language to communicate with clients. The basic features of MiniNLP are the following:\n1. High frequency sampling: The high frequency sampling is the basic feature of the microservice and in most cases it involves simple or even very high frequency processing. The microservice will be easy to use and it will be easy to read.\n2. Low frequency sampling: High frequency sampling is the basic feature of the microservice and in most cases it involves simple or even very high frequency processing. The microservice will be easy to read.\n3. Low frequency sampling: Low frequency sampling is the basic feature of the microservice and in most cases it involves simple or even very high frequency processing. The microservice will be easy to read.\nThe microservice will be easy to read. It will be simple to read.\n4. High frequency sampling: Low frequency sampling is the basic feature of the microservice and in most cases it involves simple or even very high frequency processing. The microservice will be easy to read.\nThe microservice will be easy to read. It will be easy to read.\nThe microservice will be easy to read. It will be easy to read.\n5. High", "histories": [["v1", "Sat, 23 Nov 2013 22:39:52 GMT  (99kb,D)", "http://arxiv.org/abs/1311.6063v1", null], ["v2", "Fri, 14 Feb 2014 23:21:43 GMT  (99kb,D)", "http://arxiv.org/abs/1311.6063v2", null], ["v3", "Wed, 2 Apr 2014 03:34:41 GMT  (99kb,D)", "http://arxiv.org/abs/1311.6063v3", null], ["v4", "Mon, 13 Oct 2014 20:43:09 GMT  (99kb,D)", "http://arxiv.org/abs/1311.6063v4", null]], "reviews": [], "SUBJECTS": "cs.CL", "authors": ["sheng yu", "tianxi cai"], "accepted": false, "id": "1311.6063"}, "pdf": {"name": "1311.6063.pdf", "metadata": {"source": "CRF", "title": "A Short Introduction to MiniNLP", "authors": ["Sheng Yu", "Tianxi Cai"], "emails": [], "sections": [{"heading": null, "text": "In this paper, we briefly introduce MiniNLP, a natural language processing library for clinical narratives. MiniNLP is an experiment of our ideas on efficient and effective medical language processing. We introduce the overall design of MiniNLP and its major components, and show the performance of it in real projects."}, {"heading": "1 Introduction", "text": "The electronic medical record (EMR) is a rich source of clinical information that can substantially support biomedical research and healthcare improvement [1, 2]. In addition to the structured data such as billing codes, EMR consists of free text clinical narrative recorded by physicians. The unstructured nature of the narrative data necessitates the need for natural language processing (NLP) technology to unlock the information they contain for further analysis. Clinical narratives also possess unique linguistic features both in syntax and semantics, making generic NLP programs and modules not directly applicable to the interpretation of EMR. For instance, a question mark, while normally seen as the end of a sentence, is usually placed before a disease name in clinical narratives, meaning \u201cto diagnose\u201d; a plus sign, when used after a lab test, means \u201cpositive\u201d or \u201cabove normal\u201d. Medical language processing (MLP) is a subfield of NLP that addresses to these distinct features in clinical text.\nThe work flow in most MLP systems has at least two stages: named entity recognition and semantic analysis. Named entity recognition (NER), also known as entity identification or entity extraction, is the process of locating atom elements in text and classifying them into predefined categories, such as disease, symptom, quantity, time, etc. Multitudes of approaches exist, ranging from a simple and straightforward string matching to a subsystem that matches phrases of interest (such\nar X\niv :1\n31 1.\n60 63\nv1 [\ncs .C\nL ]\n2 3\nN ov\nas noun phrases) against a dictionary after doing part-of-speech (POS) tagging and either deep parsing to obtain the complete grammar tree or shallow parsing to only identify certain types of phrases. Another dimension that distinguishes the approaches is whether the algorithm is based on grammar or on statistical models, and an NER subsystem can be a mixture of both, using grammar in some modules, and statistical models in the others.\nThe semantic analysis step uses the result of the NER step to interpret the meaning of the clinical text. Common analyses about the mention of a named entity (disease, symptom, medication, operation, etc.) include whether it is positive, negative, conditional, or whether it is a speculation, a general discussion, past medical history, or family history. Common analyses about the state of a disease/problem include determining its location, severity, and chronicity. There are plenty of other specialized analyses. Examples are determining the smoking state of a patient [3], value extraction from semi-structured EMR [4, 5], extraction of drug and food allergies [6] and medication information [7]. Again, there are many ways to achieve the goal. In addition to using grammar and statistical models, it is also popular to use simple rules (e.g., any mention within a certain range after \u201cno\u201d is negative) and pattern matching, both of which have been proved effective in practice. [8, 9]\nMiniNLP is our experiment of several ideas on MLP. One of the ideas is that a straightforward string matching for longest left-most phrases (similar to the behavior of DFA regex engines) should work great for NER in English clinical narratives. Another idea is that semantic analysis can be performed effectively and efficiently in most cases by scanning and interpreting the sentence linearly with finite-state machines, which is similar to how humans read. If these ideas work, then one may prefer such programming paradigm for MLP for its coding simplicity and execution speed.\nMiniNLP does not conform with NLP frameworks such as UIMA [10] and GATE [11]. The major benefit of these frameworks is that they standardize the interfaces of modules, resulting in better reusability of them across projects and easier collaborations among teams. The architecture of MiniNLP specifies a standard interface of its analyzers, with each of which as a pluggable component in an analysis pipeline. However, since we do not have this multi-team scenario, we choose to abandon the frameworks for better programming flexibility.\nMiniNLP got its name because it is light and fast as compared to programs with fuller grammar parsing and heavily reliant on statistical models. However, we do not intend to sacrifice any analysis power or accuracy on clinical narratives. Ideally, we hope that MiniNLP can accomplish more by doing less."}, {"heading": "2 How MiniNLP Works", "text": "The general work flow of MiniNLP is similar to many other MLP systems. It has three stages: preprocessing, named entity recognition, and semantic analysis. Figure 1 shows some of the major components of MiniNLP with illustration on the processing flow."}, {"heading": "2.1 Preprocessing", "text": "The preprocessing stage includes cleaning artificial formats (such as line breaks imposed by some EHR systems for formatting that beautifies the display but cut sentences in pieces), sentence boundary detection (so that \u201cDiff. Diagnosis\u201d is not cut in half), and tokenization. Section recognition is currently not a component of MiniNLP, and should to be done outside the library."}, {"heading": "2.2 Named Entity Recognition", "text": "MiniNLP uses a generalized prefix tree as its dictionary data structure, with tokens (mostly, words) at intermediate nodes and full phrase information at leaf nodes. The matching algorithm reads a sentence as a series of tokens, and matches the longest phrase (by the number of tokens) from the left. For instance, when MiniNLP sees \u201cpatient had a heart attack in 2006. . . \u201d it identifies\n\u201cheart attack\u201d rather than \u201cheart\u201d, and goes on to find the next phrase starting from \u201cin\u201d. The algorithm is capable of handling prefix and suffix sharing, so it can interpret \u201cno mediastinal, hilar, or axillary lymphadenopathy\u201d as \u201cno mediastinal lymphadenopathy, hilar lymphadenopathy, or axillary lymphadenopathy\u201d, and \u201cright upper, middle, and lower lobes\u201d as \u201cright upper lobe, right middle lobe, and right lower lobe\u201d.\nConventionally, with general text, like web pages, such string matching would have high sensitivity and low specificity, due to the ambiguity of word sense . However, when limited to the context of medicine, the ambiguity has substantially reduced, making such string matching approach attractive, since its speed is among the fastest that one could have. When implemented properly, the dictionary size will not affect the look up speed, and the processing time is majorly proportional to the length of the input text.\nOne the other hand, the commonly adopted NLP approaches using POS tagging + shallow parsing (or deep parsing) could have problems. Clinical narratives contain plenty of grammar errors, and physicians frequently use all kinds of shorthands (e.g. \u201cdx\u201d for \u201cdiagnose\u201d or \u201cdiagnosis\u201d, \u201ctx\u201d for \u201ctreat\u201d or \u201ctreated\u201d, \u201chx\u201d for \u201chistory\u201d, etc.) and acronyms, which are not in regular dictionaries, making POS tagging and the following parsing difficult and resulting in low recall. Since such approaches do not have a clear advantage over string matching and are expensive in terms of computational cost and training cost, we would just go string matching for the speed.\nThe identified words and phrases are encapsulated in what the program calls \u201csemantic objects\u201d. A semantic object contains the text of the identified phrase, the concept code of the phrase (which is shared among inflections and synonyms, e.g., \u201cpulmonary embolism\u201d, \u201cpulmonary emboli\u201d, and \u201cPE\u201d all have the same code), its semantic role, and its location in the sentence. It also contains fields to be filled by later semantic analyses, such as references to other semantic objects that modify it, and attributes such as certainty (present/absent/unclear) and experiencer (self/family). The semantic role tells the role or function of the phrase in the sentence. Categories of roles include grammatical words, meaning cues, and medical terms. Grammatical words are words that have little lexical meaning, but serve to help express meanings of the other words in the sentence. Some of the semantic roles in this category are pronouns, conjunctions, prepositions, link verbs, and auxiliary verbs. Comma \u201c,\u201d is also a role in this category as it has important functions in grammar. Meaning cues are words and phrases that tell us how to interpret the sentence meaning. Roles of this category include confirmation cues, negation cues, speculation cues, ignore cues (to ignore patterns such as \u201cassess for PE\u201d, \u201cin case of PE\u201d, and \u201cPE study\u201d that do not indicate presence of absence of pulmonary embolism), and etc. The medical terms are concepts that are related to diagnosis or treatment, such as fact, modifier, and anatomical location, where fact can be disorder, finding, procedure, test, substance (like drugs), etc. Although locations are a type of modifiers, MiniNLP distinguishes them from the others in order to use dedicated location analyzers.\nMiniNLP has a built-in basic dictionary of grammatical words and meaning cues that are common to all applications. The medical terms need to be populated by the application, and it is generally recommended to load all the terms that may appear in the notes of the target field, which benefits the following semantic analysis. All terms in the dictionary are easily customizable. MiniNLP allows term sense ambiguity, i.e. a term can have multiple concept codes. However, in the current implementation, a term can only have one semantic role. Eventually, the output of NER is a list of semantic objects, where the order of semantic objects is the same as the left-to-right order of the identified terms in the sentence."}, {"heading": "2.3 Semantic Analysis", "text": "Humans read sentences from left to right linearly to understand the meaning. We want to mimic this process with finite-state machines. Finite-state machines are a type of simple programs. In theory, they are not powerful enough to understand all languages [12], but we imagine they are good enough to extract the information interesting to MLP, such as certainty and modification relations, from clinical text.\nMiniNLP does semantic analysis by sending the NER result of a sentence to a pipeline of analyzers. Each analyzer is a finite-state machine and focuses on a single task. The state typically includes what the machine has just read and an interpretation mode, such as Negation On/Off. The analyzer reads the semantic objects one by one and switches the state accordingly, generally by the semantic role of the term, the distance from the previous term, and occasionally the actual text. Recall that the identified terms include grammatical words, which are hints to how to interpret the text. Also recall that clinical texts contain plenty of grammar errors, thus we avoid using strict grammar. The result is that we use a mixture of grammar and pattern analysis.\nIn this section we introduce some analyzers of MiniNLP to show that this proposed methodology is very capable at capturing information in MLP tasks."}, {"heading": "2.3.1 Certainty", "text": "Analysis of certainty includes negation analysis and speculation analysis, and assigns Yes, No, or Maybe to the certainty attribute of each fact semantic object. It uses meaning cues and grammatical words to determine the meaning and its scope. It also looks at combinations of meaning cues and grammatical words, and can merge phrases and modify semantic roles accordingly. For example, originally in the dictionary, \u201cfound\u201d is a past participle for confirmation, \u201cnot\u201d is a negation cue, \u201cis\u201d and \u201cbeen\u201d are positive link verbs, \u201cis not\u201d and \u201cisn\u2019t\u201d are negative link verbs, \u201chave\u201d is an\npositive auxiliary verb, and \u201chave not\u201d and \u201chaven\u2019t\u201d are negative auxiliary verbs. Table 1 shows the effects when these phrases appear together. Note that the analyzer looks at the sequence of the identified semantic objects, rather than the raw words in the sentence, thus \u201chaven\u2019t yet been found\u201d is treated the same as \u201chaven\u2019t been found\u201d because \u201cyet\u201d is not picked up as a semantic object.\nThe certainty analyzer can correctly understand the meaning of the sentences most of the times, including subtle differences as shown in Table 2 (though the example sentences may not make sense clinically). It also understands whether negation applies to a fact or a certain aspect of the fact. For instance, in \u201cno change in the pleural effusion\u201d, the negation only applies to \u201cchange\u201d but not to \u201cpleural effusion\u201d, where \u201cchange\u201d is a recognizable term with a semantic role that represents a fact attribute.\nOverall, the certainty analyzer covers most of the ways that physicians express negation and speculation. There are certain patterns the current implementation does not cover. For instance, it does not do cross-sentence inference, such as in \u201cThe study is of good diagnostic quality for pulmonary embolus and the vein thrombosis. There is no evidence of either\u201d, it cannot apply the negation from the second sentence to \u201cpulmonary embolus\u201d and \u201cvein thrombosis\u201d in the first sentence. Also, plenty of negation-like expressions should have a time property. For example, \u201cproblem has\ndisappeared\u201d implies problem was present earlier, but absent now. Such time property is also missing in the current implementation, which simply considers such patterns as negation."}, {"heading": "2.3.2 Location", "text": "Location analysis is another sophisticated component of MiniNLP. Descriptions of anatomical locations usually involve compounded nested modifications, which can be expressed in very diverse ways. The simplest patterns of nested modifications are \u201clocation A location B\u201d and \u201clocation A of/in/within/... location B\u201d. MiniNLP treats the former as \u201clocation B (location A)\u201d and the latter as \u201clocation A (location B)\u201d, where the inside of the parentheses modifies the outside. These patterns can be chained. For instance, \u201clocation A location B location C\u201d is interpreted as \u201clocation C (location B (location A))\u201d. However, it becomes difficult when conjunction comes in. Take a look at the following sentence, which is an excerpt from a CTPA report that we have processed:\n\u201cThere are segmental and subsegmental filling defects in the right upper lobe, superior segment of the right lower lobe, and subsegmental filling defect in the in the anterolateral segment of the left lower lobe pulmonary arteries. [sic]\u201d\nApparently, this sentence has problems. It is better to use \u201cand\u201d to replace the first comma, because the \u201cand\u201d after the second comma does not connect to a third location modifier of the \u201cfilling defects\u201d of the first line; instead, it is another \u201cfilling defect\u201d. And \u201cin the in the\u201d is obviously a typo. Despite of these, this sentence is a good example that includes multiple entities, each entity having multiple location modifiers, some of which being nested and some being not. The location analyzer reads the semantic objects in sequence, looks at their semantic roles, and uses an empirical rule to determine the modification relations. Also, as mentioned before, MiniNLP is designed to tolerate certain level of grammar problems in clinical text. For the above sentence, MiniNLP returned: filling defects: YES (right upper lobe; superior segment (right lower lobe); segmental; subsegmental), filling defect: YES (segment (pulmonary arteries (left lower lobe)); subsegmental), which is the same as the intended meaning, except that \u201canterolateral segment\u201d was not in our dictionary for that project.\nThis location analyzer is written for general purpose. There are also times when domain knowledge is needed. For instance, consider the following sentences: 1. There are filling defects in the right upper lobe and superior segment of the right lower lobe. 2. There are filling defects in the anterior basal segment and superior segment of the right lower lobe. These two sentences have identical structures, but the first one means\nfilling defects: YES (right upper lobe; superior segment (right lower lobe)), while the second means filling defects: YES (anterior basal segment (right lower lobe); superior segment (right lower lobe)). We know that they should be such because we know that: (i) the superior segment is comparable to the anterior basal segment, and both are in the right lower lobe; and (ii) the superior segment is not of the same level as the right upper lobe. If one wishes to write a dedicated analyzer for a domain, such free-form knowledge would be hard to fit into statistical learning models, but would be easily coded if using the proposed analysis methodology."}, {"heading": "2.3.3 Other Analyses", "text": "MiniNLP uses a generic analyzer to handle all other modifications. Generic modifications do not nest. Another important analyzer determines if some part of the sentence should be ignored by looking for ignore cues such as \u201cexam\u201d, \u201cevaluate\u201d, and \u201cdiff diagnosis\u201d. The default scope to ignore is the whole sentence, but certain semantic objects such as confirmation and negation cues can modify that. Another analyzer checks if the sentence contains words like \u201cmother\u201d, \u201cuncle\u201d, etc (there is a semantic role for relatives). If it does, every fact in the sentence will be labeled as family history. New analyzers are actively being added to the library as new need arises.\nIn the end, after all the analyses are done, MiniNLP returns only the semantic objects that are facts, which may contain other semantic objects like locations and modifiers in their attributes."}, {"heading": "3 Results", "text": "MiniNLP has been used in several research occasions. In a study to detect pulmonary embolism from CTPA reports, a statistical algorithm using information extracted by MiniNLP achieved AUC = 0.998 (cross-validated) in classifying PE present/absent, and AUC = 0.986 in detecting subsegmental PE. Other similar studies that used MiniNLP includes classifying whether patients have rheumatoid arthritis and congestive heart failure.\nThe processing speed of MiniNLP is fast enough for real time analysis. It took less than 6 seconds for MiniNLP to analyze 10330 CTPA reports (an 18 megabyte text file on a local drive), which equals less than 0.6 ms per report (this is the overall time that includes I/O and additional work done outside the MiniNLP, such as report sectioning and post-processing analyses). In another project, MiniNLP processed 21 million clinical notes from a remote SQL Server database in 21 hours, or 3.6 ms per note (again, this is overall time that includes database querying, data transfer\nover the network and decryption, additional text cleaning, and writing to the local hard drive). The former job was done using an Intel Core i5-2500K CPU, single thread, on Java HotSpot Client VM. The latter job was done in a virtual machine with a slower single core CPU, on Java HotSpot Server VM (faster than the Client).\nThe accuracy and speed demonstrate the effectiveness and efficiency of the library. In addition, the subsegmental PE detection task could not be done without the nesting modification structure of the locations, which is a unique feature of MiniNLP and an illustration of the merit of the methodology it uses for semantic analysis. In conclusion, we consider this experiment of MLP ideas a success, and will further develop MiniNLP following this paradigm."}], "references": [{"title": "Using electronic health records to drive discovery in disease genomics", "author": ["Isaac S Kohane"], "venue": "Nature Reviews Genetics,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2011}, {"title": "Extracting information from textual documents in the electronic health record: a review of recent research", "author": ["St\u00e9phane M Meystre", "Guergana K Savova", "Karin C Kipper-Schuler", "John F Hurdle"], "venue": "IMIA Year Book of Medical Informatics,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2008}, {"title": "Identifying patient smoking status from medical discharge records", "author": ["\u00d6zlem Uzuner", "Ira Goldstein", "Yuan Luo", "Isaac Kohane"], "venue": "Journal of the American Medical Informatics Association,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2008}, {"title": "Identification of clinical characteristics of large patient cohorts through analysis of free text physician", "author": ["Alexander Turchin"], "venue": "notes. Master\u2019s thesis, Massachusetts Institute of Technology,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2005}, {"title": "Data extraction from a semistructured electronic medical record system for outpatients: a model to facilitate the access and use of data for quality control and research", "author": ["Krister J Kristianson", "Henrik Ljunggren", "Lars L Gustafsson"], "venue": "Health Informatics Journal,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2009}, {"title": "Automated identification of drug and food allergies entered using nonstandard terminology", "author": ["Richard H Epstein", "Paul St Jacques", "Michael Stockin", "Brian Rothman", "Jesse M Ehrenfeld", "Joshua C Denny"], "venue": "Journal of the American Medical Informatics Association,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2013}, {"title": "Medex: a medication information extraction system for clinical narratives", "author": ["Hua Xu", "Shane P Stenner", "Son Doan", "Kevin B Johnson", "Lemuel R Waitman", "Joshua C Denny"], "venue": "Journal of the American Medical Informatics Association,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2010}, {"title": "A simple algorithm for identifying negated findings and diseases in discharge summaries", "author": ["Wendy W Chapman", "Will Bridewell", "Paul Hanbury", "Gregory F Cooper", "Bruce G Buchanan"], "venue": "Journal of Biomedical Informatics,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2001}, {"title": "A general natural-language text processor for clinical radiology", "author": ["Carol Friedman", "Philip O Alderson", "John HM Austin", "James J Cimino", "Stephen B Johnson"], "venue": "Journal of the American Medical Informatics Association,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 1994}, {"title": "Uima: an architectural approach to unstructured information processing in the corporate research environment", "author": ["David Ferrucci", "Adam Lally"], "venue": "Natural Language Engineering,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2004}, {"title": "Gate, a general architecture for text engineering", "author": ["Hamish Cunningham"], "venue": "Computers and the Humanities,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2002}, {"title": "Finite state languages", "author": ["Noam Chomsky", "George A Miller"], "venue": "Information and Control,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 1958}], "referenceMentions": [{"referenceID": 0, "context": "The electronic medical record (EMR) is a rich source of clinical information that can substantially support biomedical research and healthcare improvement [1, 2].", "startOffset": 155, "endOffset": 161}, {"referenceID": 1, "context": "The electronic medical record (EMR) is a rich source of clinical information that can substantially support biomedical research and healthcare improvement [1, 2].", "startOffset": 155, "endOffset": 161}, {"referenceID": 2, "context": "Examples are determining the smoking state of a patient [3], value extraction from semi-structured EMR [4, 5], extraction of drug and food allergies [6] and medication information [7].", "startOffset": 56, "endOffset": 59}, {"referenceID": 3, "context": "Examples are determining the smoking state of a patient [3], value extraction from semi-structured EMR [4, 5], extraction of drug and food allergies [6] and medication information [7].", "startOffset": 103, "endOffset": 109}, {"referenceID": 4, "context": "Examples are determining the smoking state of a patient [3], value extraction from semi-structured EMR [4, 5], extraction of drug and food allergies [6] and medication information [7].", "startOffset": 103, "endOffset": 109}, {"referenceID": 5, "context": "Examples are determining the smoking state of a patient [3], value extraction from semi-structured EMR [4, 5], extraction of drug and food allergies [6] and medication information [7].", "startOffset": 149, "endOffset": 152}, {"referenceID": 6, "context": "Examples are determining the smoking state of a patient [3], value extraction from semi-structured EMR [4, 5], extraction of drug and food allergies [6] and medication information [7].", "startOffset": 180, "endOffset": 183}, {"referenceID": 7, "context": "[8, 9]", "startOffset": 0, "endOffset": 6}, {"referenceID": 8, "context": "[8, 9]", "startOffset": 0, "endOffset": 6}, {"referenceID": 9, "context": "MiniNLP does not conform with NLP frameworks such as UIMA [10] and GATE [11].", "startOffset": 58, "endOffset": 62}, {"referenceID": 10, "context": "MiniNLP does not conform with NLP frameworks such as UIMA [10] and GATE [11].", "startOffset": 72, "endOffset": 76}, {"referenceID": 11, "context": "In theory, they are not powerful enough to understand all languages [12], but we imagine they are good enough to extract the information interesting to MLP, such as certainty and modification relations, from clinical text.", "startOffset": 68, "endOffset": 72}], "year": 2017, "abstractText": "In this paper, we briefly introduce MiniNLP, a natural language processing library for clinical narratives. MiniNLP is an experiment of our ideas on efficient and effective medical language processing. We introduce the overall design of MiniNLP and its major components, and show the performance of it in real projects.", "creator": "LaTeX with hyperref package"}}}