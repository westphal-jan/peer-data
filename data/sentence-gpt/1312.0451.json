{"id": "1312.0451", "review": {"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "2-Dec-2013", "title": "Consistency of weighted majority votes", "abstract": "We revisit the classical decision-theoretic problem of weighted expert voting from a statistical learning perspective. In particular, we examine the consistency (both asymptotic and finitary) of the optimal Nitzan-Paroush weighted majority and related rules. In the case of known expert competence levels, we give precise necessary and sufficient conditions for consistency. The main challenge for the evaluation is to evaluate whether a particular member of the population is a Nitzan-Paroush representative of the majority (i.e., he is not representative of a majority) and how this is done. We provide a series of four components for analysis that relate to the voting and of the vote as well as their impact on the selection of voting groups.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "histories": [["v1", "Mon, 2 Dec 2013 13:41:44 GMT  (313kb)", "https://arxiv.org/abs/1312.0451v1", null], ["v2", "Thu, 5 Dec 2013 13:02:17 GMT  (312kb)", "http://arxiv.org/abs/1312.0451v2", null], ["v3", "Mon, 9 Dec 2013 17:13:01 GMT  (310kb)", "http://arxiv.org/abs/1312.0451v3", null], ["v4", "Sun, 22 Dec 2013 11:23:48 GMT  (310kb)", "http://arxiv.org/abs/1312.0451v4", null], ["v5", "Tue, 21 Jan 2014 08:24:07 GMT  (310kb)", "http://arxiv.org/abs/1312.0451v5", null]], "reviews": [], "SUBJECTS": "math.PR cs.LG stat.ML", "authors": ["daniel berend", "aryeh kontorovich"], "accepted": true, "id": "1312.0451"}, "pdf": {"name": "1312.0451.pdf", "metadata": {"source": "CRF", "title": "Consistency of weighted majority votes", "authors": ["Daniel Berend", "Aryeh Kontorovich"], "emails": [], "sections": [{"heading": null, "text": "ar X\niv :1\n31 2.\n04 51\nv5 [\nm at\nh. PR\n] 2\n1 Ja"}, {"heading": "1 Introduction", "text": "The problem of weighting the input of several experts arises in many situations and is of considerable theoretical and practical importance. The rigorous study of majority vote has its roots in the work of Condorcet (1785). By the 70s, the field of decision theory was actively exploring various voting rules (see Nitzan & Paroush (1982) and the references therein). A typical setting is as follows. An agent is tasked with predicting some random variable Y \u2208 {\u00b11} based on input Xi \u2208 {\u00b11} from each of n experts. Each expert Xi has a competence level pi \u2208 (0, 1), which is the probability of making a correct prediction: P(Xi = Y ) = pi. Two simplifying assumptions are commonly made:\n(i) Independence: The random variables {Xi : i \u2208 [n]} are mutually independent.\n(ii) Unbiased truth: P(Y = +1) = P(Y = \u22121) = 1/2. We will discuss these assumptions below in greater detail; for now, let us just take them as given. (Since the bias of Y can be easily estimated from data, only the independence assumption is truly restrictive.) A decision rule is a mapping f : {\u00b11}n \u2192 {\u00b11} from the n expert inputs to the agent\u2019s final decision. Our quantity of interest throughout the paper will be the agent\u2019s probability of error,\nP(f(X) 6= Y ). (1)\nA decision rule f is optimal if it minimizes the quantity in (1) over all possible decision rules. Nitzan & Paroush (1982) showed that, when Assumptions (i)\u2013 (ii) hold and the true competences pi are known, the optimal decision rule is obtained by an appropriately weighted majority vote:\nfOPT(x) = sign\n(\nn \u2211\ni=1\nwixi\n)\n, (2)\nwhere the weights wi are given by\nwi = log pi\n1\u2212 pi , i \u2208 [n]. (3)\nThus, wi is the log-odds of expert i being correct \u2014 and the voting rule in (2), also known as naive Bayes (Hastie et al., 2009), may be seen as a simple consequence of the Neyman-Pearson lemma (Neyman & Pearson, 1933).\nMain results. The formula in (2) raises immediate questions, which apparently have not previously been addressed. The first one has to do with the consistency of the Nitzan-Paroush optimal rule: under what conditions does the probability of error decay to zero and at what rate? In Section 3, we show that the probability of error is controlled by the committee potential \u03a6, defined by\n\u03a6 =\nn \u2211\ni=1\n(pi \u2212 12 )wi = n \u2211\ni=1\n(pi \u2212 12 ) log pi\n1\u2212 pi . (4)\nMore precisely, we prove in Theorem 1 that\n\u2212 logP(fOPT(X) 6= Y ) \u224d \u03a6,\nwhere \u224d denotes equivalence up to universal multiplicative constants. Another issue not addressed by the Nitzan-Paroush result is how to handle the case where the competences pi are not known exactly but rather estimated empirically by p\u0302i. We present two solutions to this problem: a frequentist and a Bayesian one. As we show in Section 4, the frequentist approach does not admit an optimal empirical decision rule. Instead, we analyze empirical decision rules in various settings: high-confidence (i.e., |p\u0302i \u2212 pi| \u226a 1) vs. low-confidence, adaptive vs. nonadaptive. The low-confidence regime requires no additional assumptions, but provides weaker guarantees (Theorem 5). In the high-confidence regime, the adaptive approach provides error estimates in terms of the empirical p\u0302is (Theorem 10), while the nonadaptive approach gives a bound in terms of the unknown pis, but still gives useful asymptotics (Theorem 9). The Bayesian solution sidesteps the various cases above, as it admits a simple, provably optimal empirical decision rule (Section 5). Unfortunately, we are unable to compute (or even nontrivially estimate) the probability of error induced by this rule; this is posed as a challenging open problem."}, {"heading": "2 Background and related work", "text": "Machine learning theory typically clusters weighted majority (Littlestone &Warmuth, 1989, 1994) within the framework of online algorithms; see Cesa-Bianchi & Lugosi (2006) for a modern treatment. Since the online setting is considerably more adversarial than ours, we obtain very different weighted majority rules and consistency guarantees. The weights wi in (2) bear a striking similarity to the Adaboost update rule (Freund & Schapire, 1997; Schapire & Freund, 2012). However, the latter assumes weak learners with access to labeled examples, while in our setting the experts are \u201cstatic\u201d. Still, we do not rule out a possible deeper connection between the Nitzan-Paroush decision rule and boosting. In a recent line of work Lacasse et al. (2006); Laviolette & Marchand (2007); Roy et al. (2011) have developed a PAC-Bayesian theory for the majority vote of simple classifiers. This approach facilitates data-dependent bounds and is even flexible enough to capture some simple dependencies among the classifiers \u2014 though, again, the latter are learners as opposed to our experts. Even more recently, experts with adversarial noise have been considered (Mansour et al., 2013). More directly related to the present work are the papers of Berend & Paroush (1998), which characterizes the consistency of the simple majority rule, and Boland et al. (1989); Berend & Sapir (2007) which analyze various models of dependence among the experts."}, {"heading": "3 Known competences", "text": "In this section we assume that the expert competences pi are known and analyze the consistency of the Nitzan-Paroush optimal decision rule (2). Our main result here is that the probability of error P(fOPT(X) 6= Y ) is small if and only if the committee potential \u03a6 is large.\nTheorem 1. Suppose that the experts X = (X1, . . . , Xn) satisfy Assumptions (i)-(ii) and f : {\u00b11}n \u2192 {\u00b11} is the Nitzan-Paroush optimal decision rule. Then\n(i) P(fOPT(X) 6= Y ) \u2264 exp ( \u2212 12\u03a6 ) .\n(ii) P(fOPT(X) 6= Y ) \u2265 3 4[1 + exp(2\u03a6 + 4 \u221a \u03a6)] .\nOpen problem. Exhibit (if possible) a function g : R \u2192 R such that P(fOPT(X) 6= Y ) \u224d g(\u03a6).\nThe remainder of this section is devoted to proving Theorem 1."}, {"heading": "3.1 Proof of Theorem 1(i)", "text": "Define the {0, 1}-indicator variables \u03bei = 1{Xi=Y }, (5)\ncorresponding to the event that the ith expert is correct. A mistake fOPT(X) 6= Y occurs precisely when1 the sum of the correct experts\u2019 weights fails to exceed half the total mass:\nP(fOPT(X) 6= Y ) = P ( n \u2211\ni=1\nwi\u03bei \u2264 1\n2\nn \u2211\ni=1\nwi\n)\n. (6)\nSince E\u03bei = pi, we may rewrite the probability in (6) as\nP\n(\n\u2211\ni\nwi\u03bei \u2264 E [ \u2211\ni\nwi\u03bei\n]\n\u2212 \u2211\ni\n(pi \u2212 12 )wi ) . (7)\nA standard tool for estimating such sum deviation probabilities is Hoeffding\u2019s inequality. Applied to (7), it yields the bound\nP(fOPT(X) 6= Y ) \u2264 exp ( \u22122 [ \u2211 i(pi \u2212 12 )wi ]2 \u2211\ni w 2 i\n)\n, (8)\nwhich is far too crude for our purposes. Indeed, consider a finite committee of highly competent experts with pi\u2019s arbitrarily close to 1 and X1 the most competent of all. Raising X1\u2019s competence sufficiently far above his peers will cause both the numerator and the denominator in the exponent to be dominated by w21 , making the right-hand-side of (8) bounded away from zero. The inability of Hoeffding\u2019s inequality to guarantee consistency even in such a felicitous setting is an instance of its generally poor applicability to highly heterogeneous sums, a phenomenon explored in some depth in McAllester & Ortiz (2003). Bernstein\u2019s and Bennett\u2019s inequalities suffer from a similar weakness (see ibid.). Fortunately, an inequality of Kearns & Saul (1998) is sufficiently sharp to yield the desired estimate: For all p \u2208 [0, 1] and all t \u2208 R,\n(1 \u2212 p)e\u2212tp + pet(1\u2212p) \u2264 exp ( 1\u2212 2p 4 log((1\u2212 p)/p)t 2 ) . (9)\nRemark 1. The Kearns-Saul inequality (9) may be seen as a distributiondependent refinement of Hoeffding\u2019s (which bounds the left-hand-side of (9) by et 2/8), and is not nearly as straightforward to prove. An elementary rigorous proof is given in Berend & Kontorovich (2013b). Following up, Raginsky & Sason (2013) gave a \u201csoft\u201d proof based on transportation and information-theoretic techniques.\nPut \u03b8i = \u03bei \u2212 pi, substitute into (6), and apply Markov\u2019s inequality:\nP(fOPT(X) 6= Y ) = P ( \u2212 \u2211\ni\nwi\u03b8i \u2265 \u03a6 )\n(10)\n\u2264 e\u2212t\u03a6Eexp ( \u2212t \u2211\ni\nwi\u03b8i\n)\n.\n1Without loss of generality, ties are considered to be errors.\nNow\nEe\u2212twi\u03b8i = pie \u2212(1\u2212pi)wit + (1 \u2212 pi)epiwit\n\u2264 exp ( \u22121 + 2pi 4 log(pi/(1\u2212 pi)) w2i t 2 )\n(11)\n= exp [ 1 2 (pi \u2212 12 )wit2 ] ,\nwhere the inequality follows from (9). By independence,\nE exp\n(\n\u2212t \u2211\ni\nwi\u03b8i\n)\n= \u220f\ni\nEe\u2212twi\u03b8i\n\u2264 exp (\n1 2\n\u2211\ni\n(pi \u2212 12 )wit 2\n)\n= exp ( 1 2\u03a6t 2 )\nand hence\nP(fOPT(X) 6= Y ) \u2264 exp ( 1 2\u03a6t 2 \u2212 \u03a6t ) .\nChoosing t = 1 yields the bound in Theorem 1(i)."}, {"heading": "3.2 Proof of Theorem 1(ii)", "text": "Define the {\u00b11}-indicator variables\n\u03b7i = 21{Xi=Y } \u2212 1, (12)\ncorresponding to the event that the ith expert is correct and put qi = 1 \u2212 pi. The shorthand w \u00b7\u03b7 = \u2211ni=1 wi\u03b7i will be convenient. We will need some simple lemmata:\nLemma 2.\nP(fOPT(X) = Y ) = \u2211\n\u03b7\u2208{\u00b11}n\nmax {P (\u03b7), P (\u2212\u03b7)}\nand\nP(fOPT(X) 6= Y ) = \u2211\n\u03b7\u2208{\u00b11}n\nmin {P (\u03b7), P (\u2212\u03b7)} ,\nwhere\nP (\u03b7) = \u220f\ni:\u03b7i=1\npi \u220f\ni:\u03b7i=\u22121\nqi.\nProof. The identities (5), (6) and (12) imply that a mistake occurs precisely when\nn \u2211\ni=1\nwi \u03b7i + 1 2 \u2264 1 2\nn \u2211\ni=1\nwi,\nwhich is equivalent to\nw \u00b7 \u03b7 \u2264 0. (13)\nExponentiating both sides,\nexp (w \u00b7 \u03b7) = n \u220f\ni=1\newi\u03b7i\n= \u220f\ni:\u03b7i=1\npi qi \u00b7 \u220f\ni:\u03b7i=\u22121\nqi pi\n= P (\u03b7)\nP (\u2212\u03b7) \u2264 1. (14)\nWe conclude from (14) that among two \u201cantipodal\u201d atoms \u00b1\u03b7 \u2208 {\u00b11}n, the one with the greater mass contributes to the probability being correct and the one with the smaller mass contributes to the probability of error, which proves the claim.\nRemark 2. The proof of Lemma 2 also establishes the optimality of the NitzanParoush decision rule.\nLemma 3. Suppose that s, s\u2032 \u2208 (0,\u221e)m satisfy m \u2211\ni=1\n(si + s \u2032 i) \u2265 a\nand\n1 R \u2264 si s\u2032i \u2264 R, i \u2208 [m]\nfor some R < \u221e. Then m \u2211\ni=1\nmin {si, s\u2032i} \u2265 a\n1 +R .\nProof. Immediate from\nsi + s \u2032 i \u2264 min {si, s\u2032i} (1 +R).\nLemma 4. Define the function F : (0, 1) \u2192 R by\nF (x) = x(1 \u2212 x) log(x/(1\u2212 x))\n2x\u2212 1 .\nThen sup0<x<1 F (x) = 1 2 .\nProof. Deferred to the Appendix.\nContinuing with the main proof, observe that\nE [w \u00b7 \u03b7] = n \u2211\ni=1\n(pi \u2212 qi)wi = 2\u03a6 (15)\nand\nVar [w \u00b7 \u03b7] = 4 n \u2211\ni=1\npiqiw 2 i .\nBy Lemma 4,\npiqiw 2 i \u2264 12 (pi \u2212 qi)wi,\nand hence\nVar [w \u00b7 \u03b7] \u2264 4\u03a6. (16)\nDefine the segment I \u2282 R by\nI = [ 2\u03a6\u2212 4 \u221a \u03a6, 2\u03a6 + 4 \u221a \u03a6 ] . (17)\nChebyshev\u2019s inequality together with (15) and (16) implies that\nP (w \u00b7 \u03b7 \u2208 I) \u2265 3 4 . (18)\nConsider an atom \u03b7 \u2208 {\u00b11}n for which w \u00b7\u03b7 \u2208 I. The proof of Lemma 2 shows that\nP (\u03b7) P (\u2212\u03b7) = exp (w \u00b7 \u03b7) \u2264 exp(2\u03a6 + 4 \u221a \u03a6), (19)\nwhere the inequality follows from (17). Lemma 2 further implies that\nP(fOPT(X) 6= Y ) \u2265 \u2211\n\u03b7\u2208{\u00b11}n:w\u00b7\u03b7\u2208I\nmin {P (\u03b7), P (\u2212\u03b7)}\n\u2265 3/4 1 + exp(2\u03a6 + 4 \u221a \u03a6) ,\nwhere the second inequality follows from Lemma 3, (18) and (19). This completes the proof."}, {"heading": "4 Unknown competences: frequentist approach", "text": "Our goal in this section is to obtain, insofar as possible, analogues of Theorem 1 for unknown expert competences. When the pis are unknown, they must be estimated empirically before any useful weighted majority vote can be applied. There are various ways to model partial knowledge of expert competences (Baharad et al., 2011, 2012). Perhaps the simplest scenario for estimating the pis is to assume that the ith expert has been queried independently mi times, out of which he gave the correct prediction ki times. Taking the {mi} to be fixed, define the committee profile by k = (k1, . . . , kn); this is the aggregate of the agent\u2019s empirical knowledge of the experts\u2019 performance. An empirical decision rule f\u0302 : (x,k) 7\u2192 {\u00b11} makes a final decision based on the expert inputs x together with the committee profile. Analogously to (1), the probability of a mistake is\nP(f\u0302(X,K) 6= Y ). (20)\nNote that now the committee profile is an additional source of randomness. Here we run into our first difficulty: unlike the probability in (1), which is minimized by the Nitzan-Paroush rule, the agent cannot formulate an optimal decision rule f\u0302 in advance without knowing the pis. This is because no decision rule is optimal uniformly over the range of possible pis. Our approach will be to consider weighted majority decision rules of the form\nf\u0302(x,k) = sign\n(\nn \u2211\ni=1\nw\u0302(ki)xi\n)\n(21)\nand to analyze their consistency properties under two different regimes: lowconfidence and high-confidence. These refer to the confidence intervals of the frequentist estimate of pi, given by\np\u0302i = ki mi . (22)"}, {"heading": "4.1 Low-confidence regime", "text": "In the low-confidence regime, the sample sizes mi may be as small as 1, and we define2\nw\u0302(ki) = w\u0302 LC i := p\u0302i \u2212 12 , i \u2208 [n], (23)\nwhich induces the empirical decision rule f\u0302LC. It remains to analyze f\u0302LC\u2019s probability of error. Recall the definition of \u03bei from (5) and observe that\nE [w\u0302LCi \u03bei] = E[(p\u0302i \u2212 12 )\u03bei] = (pi \u2212 12 )pi, (24) 2For mi min {pi, qi} \u226a 1, the estimated competences p\u0302i may well take values in {0, 1}, in which case log(p\u0302i/q\u0302i) = \u00b1\u221e. The rule in (23) is essentially a first-order Taylor approximation to w(\u00b7) about p = 1\n2 .\nsince p\u0302i and \u03bei are independent. As in (6), the probability of error (20) is\nP\n(\nn \u2211\ni=1\nw\u0302LCi \u03bei \u2264 1\n2\nn \u2211\ni=1\nw\u0302LCi\n)\n= P\n(\nn \u2211\ni=1\nZi \u2264 0 ) , (25)\nwhere Zi = w\u0302 LC i (\u03bei \u2212 12 ). Now the {Zi} are independent random variables, EZi = (pi \u2212 12 )2 (by (24)), and each Zi takes values in an interval of length 12 . Hence, the standard Hoeffding bound applies:\nP(f\u0302LC(X,K) 6= Y ) \u2264 exp\n\n\u2212 8 n\n(\nn \u2211\ni=1\n(pi \u2212 12 ) 2\n)2 \n . (26)\nWe summarize these calculations in\nTheorem 5. A sufficient condition for P(f\u0302LC(X,K) 6= Y ) \u2192 0 is\n1\u221a n\nn \u2211\ni=1\n(pi \u2212 12 ) 2 \u2192 \u221e.\nSeveral remarks are in order. First, notice that the error bound in (26) is stated in terms of the unknown {pi}, providing the agent with large-committee asymptotics but giving no finitary information; this limitation is inherent in the low-confidence regime. Secondly, the condition in Theorem 5 is considerably more restrictive than the consistency condition \u03a6 \u2192 \u221e implicit in Theorem 1. Indeed, the empirical decision rule f\u0302LC is incapable of exploiting a single highly competent expert in the way that fOPT from (2) does. Our analysis could be sharpened somewhat for moderate sample sizes {mi} by using Bernstein\u2019s inequality to take advantage of the low variance of the p\u0302is. For sufficiently large sample sizes, however, the high-confidence regime (discussed below) begins to take over. Finally, there is one sense in which this case is \u201ceasier\u201d to analyze than that of known {pi}: since the summands in (25) are bounded, Hoeffding\u2019s inequality gives nontrivial results and there is no need for more advanced tools such as the Kearns-Saul inequality (9) (which is actually inapplicable in this case)."}, {"heading": "4.2 High-confidence regime", "text": "In the high-confidence regime, each estimated competence p\u0302i is close to the true value pi with high probability. To formalize this, fix some 0 < \u03b4 < 1, 0 < \u03b5 \u2264 5, and put\nqi = 1\u2212 pi, q\u0302i = 1\u2212 p\u0302i.\nWe will set the empirical weights according to the \u201cplug-in\u201d Nitzan-Paroush rule\nw\u0302HCi := log p\u0302i q\u0302i , i \u2208 [n], (27)\nwhich induces the empirical decision rule f\u0302HC and raises immediate concerns about w\u0302HCi = \u00b1\u221e. We give two kinds of bounds on P(f\u0302HC 6= Y ): nonadaptive and adaptive. In the nonadaptive analysis, we show that for mimin {pi, qi}i \u226b 1, with high probability |wi \u2212 w\u0302HCi | \u226a 1, and thus a \u201cperturbed\u201d version of Theorem 1(i) holds (and in particular, wHCi will be finite with high probability). In the adaptive analysis, we allow w\u0302HCi to take on infinite values\n3 and show (perhaps surprisingly) that this decision rule also asymptotically achieves the rate of Theorem 1(i).\nNonadaptive analysis. Define \u03b5\u0303 \u2208 (0, 1) by \u03b5 = 2\u03b5\u0303+ 4\u03b5\u03032 or, explicitly,\n\u03b5\u0303 =\n\u221a 4\u03b5+ 1\u2212 1\n4 . (28)\nLemma 6. If\n\u03b5\u03032mipi \u2265 3 log(2n/\u03b4), i \u2208 [n], (29)\nthen\nP\n(\n\u2203i \u2208 [n] : p\u0302i pi /\u2208 (1\u2212 \u03b5\u0303, 1 + \u03b5\u0303) ) \u2264 \u03b4.\nProof. The multiplicative Chernoff bound yields\nP (p\u0302i < (1 \u2212 \u03b5\u0303)pi) \u2264 e\u2212\u03b5\u0303 2mipi/2\nand\nP (p\u0302i > (1 + \u03b5\u0303)pi) \u2264 e\u2212\u03b5\u0303 2mipi/3.\nHence,\nP\n(\np\u0302i pi /\u2208 (1\u2212 \u03b5\u0303, 1 + \u03b5\u0303) ) \u2264 2e\u2212\u03b5\u03032mipi/3.\nThe claim follows from (29) and the union bound.\nLemma 7. Let wi be the optimal Nitzan-Paroush weight (3). If\n1\u2212 \u03b5\u0303 \u2264 p\u0302i pi , q\u0302i qi \u2264 1 + \u03b5\u0303\nthen\n|wi \u2212 w\u0302HCi | \u2264 \u03b5. 3When the decision rule is faced with evaluating sums involving \u221e\u2212\u221e, we automatically\ncount this as an error.\nProof. We have\n|wi \u2212 w\u0302HCi | = \u2223 \u2223 \u2223\n\u2223 log pi qi \u2212 log p\u0302i q\u0302i\n\u2223 \u2223 \u2223 \u2223\n=\n\u2223 \u2223 \u2223 \u2223 log pi p\u0302i \u2212 log q\u0302i qi \u2223 \u2223 \u2223 \u2223\n=\n\u2223 \u2223 \u2223 \u2223 log pi p\u0302i \u2223 \u2223 \u2223 \u2223 + \u2223 \u2223 \u2223 \u2223 log q\u0302i qi \u2223 \u2223 \u2223 \u2223 .\nNow4\n[log(1\u2212 \u03b5\u0303), log(1 + \u03b5\u0303)] \u2286 [\u2212\u03b5\u0303\u2212 2\u03b5\u03032, \u03b5\u0303] \u2286 [\u2212 12\u03b5, 12\u03b5],\nwhence \u2223\n\u2223 \u2223 \u2223 log pi p\u0302i\n\u2223 \u2223 \u2223 \u2223 + \u2223 \u2223 \u2223 \u2223 log q\u0302i qi \u2223 \u2223 \u2223 \u2223 \u2264 \u03b5.\nCorollary 8. If\n\u03b5\u03032mimin {pi, qi}i \u2265 3 log(4n/\u03b4), i \u2208 [n],\nthen\nP\n(\nmax i\u2208[n]\n|wi \u2212 w\u0302HCi | > \u03b5 ) \u2264 \u03b4.\nProof. An immediate consequence of applying Lemma 6 to pi and qi with the union bound.\nTo state the next result, let us arrange the plug-in weights (27) as a vector w\u0302\nHC \u2208 Rn, as was done with w and \u03b7 from Section 3.1. The corresponding weighted majority rule f\u0302HC yields an error precisely when\nw\u0302 HC \u00b7 \u03b7 \u2264 0\n(cf. (13)). Our nonadaptive approach culminates in the following result.\nTheorem 9. Let 0 < \u03b4 < 1 and 0 < \u03b5 < min {5, 2\u03a6/n}. If\nmi min {pi, qi}i \u2265 3 ( \u221a 4\u03b5+ 1\u2212 1\n4\n)\u22122\nlog 4n\n\u03b4 , i \u2208 [n], (30)\nthen\nP\n( f\u0302HC(X,K) 6= Y ) \u2264 \u03b4 + exp [ \u2212 (2\u03a6\u2212 \u03b5n) 2\n8\u03a6\n]\n. (31)\n4The first containment requires log(1 \u2212 x) \u2265 \u2212x \u2212 2x2, which holds (not exclusively) on (0, 0.9). The restriction \u03b5 \u2264 5 ensures that \u03b5\u0303 is in this range.\nRemark 3. For fixed {pi} and mini\u2208[n] mi \u2192 \u221e, we may take \u03b4 and \u03b5 arbitrarily small \u2014 and in this limiting case, the bound of Theorem 1(i) is recovered.\nProof of Theorem 9. Since\n|w \u00b7 \u03b7 \u2212 w\u0302HC \u00b7 \u03b7| = |(w \u2212 w\u0302HC) \u00b7 \u03b7|\n\u2264 n \u2211\ni=1\n|wi \u2212 wHCi | = \u2016w\u2212 w\u0302HC\u20161 ,\nwe have\nP (w\u0302HC \u00b7 \u03b7 \u2264 0) \u2264 P(\u2016w \u2212 w\u0302HC\u20161 > \u03b5n) + P(w \u00b7 \u03b7 \u2264 \u03b5n).\nCorollary 8 upper-bounds the first term on the right-hand side by \u03b4. The second term is estimated by replacing \u03a6 by \u03a6\u2212 \u03b5n in (10) and repeating the argument following that formula.\nAdaptive analysis. Theorem 9 has the drawback of being nonadaptive, in that its assumptions (30) and conclusions (31) depend on the unknown {pi} and hence cannot be evaluated by the agent (the bound in (26) is also nonadaptive). In the adaptive approach, all results are stated in terms of empirically observed quantities:\nTheorem 10. Put5\n\u03b4 =\nn \u2211\ni=1\n1\u221a mi\nand let R be the event\nexp\n(\n\u22121 2\nn \u2211\ni=1\n(p\u0302i \u2212 12 )w\u0302HCi\n)\n\u2264 \u03b4 2 . (32)\nThen\nP\n( R \u2229 { f\u0302HC(X,K) 6= Y }) \u2264 \u03b4.\nRemark 4. Our interpretation for Theorem 10 is as follows. The agent observes the committee profile K, which determines the {p\u0302i, w\u0302HCi }, and then checks whether the event R has occurred. If not, the adaptive agent refrains from making a decision (and may choose to fall back on the low-confidence approach described previously). If R does hold, however, the agent predicts Y according to\nf\u0302HC. As explained above, there does not exist a nontrivial a priori upper bound on P(f\u0302HC(X,K) 6= Y ) absent any knowledge of the pis. Instead, Theorem 10\n5 Actually, as the proof will show, we may take \u03b4 to be a smaller value, but with a more complex dependence on {mi}, which simplifies to 2[1\u2212 (1 \u2212 (2 \u221a m)\u22121)n] for mi \u2261 m.\nbounds the probability of the agent being \u201cfooled\u201d by an unrepresentative committee profile.6 Observe that for mini\u2208[n] mi \u226b 1, we have p\u0302i \u2248 pi and w\u0302HCi \u2248 wi, and thus Theorem 1(i) is recovered as a limiting case. Note that we have done nothing to prevent w\u0302HCi = \u00b1\u221e, and this may indeed happen. Intuitively, there are two reasons for infinite w\u0302HCi : (a) noisy p\u0302i due to mi being too small, or (b) the ith expert is actually highly (in)competent, which causes p\u0302i \u2208 {0, 1} even for large mi. The 1/ \u221a mi term in the bound ensures against case (a), while in case (b), choosing infinite w\u0302HCi causes no harm (as we show in the proof).\nProof. We will write the probability and expectation operators with subscripts (such as K) to indicate the random variable(s) being summed over. Thus,\nPK,X,Y\n( R \u2229 { f\u0302HC(X,K) 6= Y })\n= PK,\u03b7 (R \u2229 {w\u0302HC \u00b7 \u03b7 \u2264 0}) = EK [1R \u00b7 P\u03b7 (w\u0302HC \u00b7 \u03b7 \u2264 0 |K)] .\n(33)\nRecall that the random variable \u03b7 \u2208 {\u00b11}n, with probability mass function\nP (\u03b7) = \u220f\ni:\u03b7i=1\npi \u220f\ni:\u03b7i=\u22121\nqi,\nis independent of K, and hence\nP\u03b7 (w\u0302 HC \u00b7 \u03b7 \u2264 0 |K) = P\u03b7 (w\u0302HC \u00b7 \u03b7 \u2264 0) . (34)\nDefine the random variable \u03b7\u0302 \u2208 {\u00b11}n (conditioned on K) by the probability mass function\nP (\u03b7\u0302) = \u220f\ni:\u03b7i=1\np\u0302i \u220f\ni:\u03b7i=\u22121\nq\u0302i,\nand the set A \u2286 {\u00b11}n by A = {x : w\u0302HC \u00b7 x \u2264 0} . Now\n|P\u03b7 (w\u0302HC \u00b7 \u03b7 \u2264 0)\u2212 P\u03b7\u0302 (w\u0302HC \u00b7 \u03b7\u0302 \u2264 0)| = |P\u03b7 (A)\u2212 P\u03b7\u0302 (A)| \u2264 max\nA\u2286{\u00b11}n |P\u03b7 (A)\u2212 P\u03b7\u0302 (A)|\n= \u2016P\u03b7 \u2212 P\u03b7\u0302\u2016TV \u2264 n \u2211\ni=1\n|pi \u2212 p\u0302i| =: M,\nwhere the inequality follows from a standard tensorization property of the total variation norm \u2016\u00b7\u2016\nTV , see e.g. (Kontorovich, 2012, Lemma 2.2). By Theo-\nrem 1(i), we have\nP\u03b7\u0302 (w\u0302 HC \u00b7 \u03b7\u0302 \u2264 0) \u2264 exp\n(\n\u2212 12 n \u2211\ni=1\n(p\u0302i \u2212 12 )w\u0302 HC i\n)\n,\n6These adaptive bounds are similar in spirit to empirical Bernstein methods, (Audibert et al., 2007; Mnih et al., 2008; Maurer & Pontil, 2009), where the player\u2019s confidence depends on the empirical variance.\nand hence\nP\u03b7 (w\u0302 HC \u00b7 \u03b7 \u2264 0) \u2264 M + exp\n(\n\u2212 12 n \u2211\ni=1\n(p\u0302i \u2212 12 )w\u0302 HC i\n)\n.\nInvoking (34), we substitute the right-hand side above into (33) to obtain\nPK,X,Y\n( R \u2229 { f\u0302HC(X,K) 6= Y }) \u2264 EK [ 1R \u00b7 ( M + exp ( \u2212 12 n \u2211\ni=1\n(p\u0302i \u2212 12 )w\u0302 HC i\n))]\n\u2264 EK[M ] + EK [ 1R exp ( \u2212 12 n \u2211\ni=1\n(p\u0302i \u2212 12 )w\u0302 HC i\n)]\n.\nBy the definition of R, the second term on the last right-hand side is upperbounded by \u03b4/2. To estimate M , we invoke a simple mean absolute deviation bound (cf. Berend & Kontorovich (2013a)):\nEK |pi \u2212 p\u0302i| \u2264 \u221a\npi(1\u2212 pi) mi \u2264 1 2 \u221a mi ,\nwhich finishes the proof.\nRemark 5. The improvement mentioned in Footnote 5 is achieved via a refinement of the bound \u2016P\u03b7 \u2212 P\u03b7\u0302\u2016TV \u2264 \u2211n i=1 |pi \u2212 p\u0302i| to \u2016P\u03b7 \u2212 P\u03b7\u0302\u2016TV \u2264 \u03b1 ({|pi \u2212 p\u0302i| : i \u2208 [n]}), where \u03b1(\u00b7) is the function defined in Kontorovich (2012, Lemma 4.2).\nOpen problem. As argued in Remark 4, Theorem 10 achieves the optimal asymptotic rate in {pi}. Can the dependence on {mi} be improved, perhaps through a better choice of w\u0302HC?"}, {"heading": "5 Unknown competences: Bayesian approach", "text": "A shortcoming of Theorem 10 is that when condition R fails, the agent is left with no estimate of the error probability. An alternative (and in some sense cleaner) approach to handling unknown expert competences pi is to assume a known prior distribution over the competence levels pi. The natural choice of prior for a Bernoulli parameter is the Beta distribution, namely\npi \u223c Beta(\u03b1i, \u03b2i)\nwith density\np\u03b1i\u22121i q \u03b2i\u22121 i\nB(\u03b1i, \u03b2i) , \u03b1i, \u03b2i > 0,\nwhere qi = 1\u2212pi and B(x, y) = \u0393(x)\u0393(y)/\u0393(x+y). Our full probabilistic model is as follows. Each of the n expert competences pi is drawn independently from\na Beta distribution with known parameters \u03b1i, \u03b2i. Then the i th expert, i \u2208 [n], is queried independently mi times, with ki correct predictions and mi \u2212 ki incorrect ones. As before, K = (k1, . . . , kn) is the (random) committee profile. Absent direct knowledge of the pis, the agent relies on an empirical decision rule f\u0302 : (x,k) 7\u2192 {\u00b11} to produce a final decision based on the expert inputs x together with the committee profile k. A decision rule f\u0302Ba is Bayes-optimal if it minimizes\nP(f\u0302(X,K) 6= Y ), (35) which is formally identical to (20) but semantically there is a difference: the probability in (35) is over the pi in addition to (X, Y,K). Unlike the frequentist approach, where no optimal empirical decision rule was possible, the Bayesian approach readily admits one. For a given x \u2208 {\u00b11}, define I+(x) to be the set of YES votes\nI+(x) = {i \u2208 [n] : xi = +1} and I\u2212(x) = [n] \\ I+(x) to be the set of NO votes. Let us fix some A \u2286 [n], B = [n] \\A and compute\nP(Y = +1, I+(X) = A, I\u2212(X) = B)\n=\nn \u220f\ni=1\n\u222b 1\n0\np\u03b1i\u22121i q \u03b2i\u22121 i\nB(\u03b1i, \u03b2i)\n(\nmi ki\n)\npkii q mi\u2212ki i p 1{i\u2208A} i q 1{i\u2208B} i dpi\n=\nn \u220f\ni=1\n(\nmi ki\n)\npkii q mi\u2212ki i\nB(\u03b1i, \u03b2i)\n\u222b 1\n0\np \u03b1i+ki\u22121+1{i\u2208A} i q \u03b2i+mi\u2212ki\u22121+1{i\u2208B} i dpi\n=\nn \u220f\ni=1\n(\nmi ki\n)\nB(\u03b1i + ki + 1{i\u2208A}, \u03b2i +mi \u2212 ki + 1{i\u2208B}) B(\u03b1i, \u03b2i) .\nAnalogously,\nP(Y = \u22121, I+(X) = A, I\u2212(X) = B)\n= n \u220f\ni=1\n(\nmi ki\n)\nB(\u03b1i + ki + 1{i\u2208B}, \u03b2i +mi \u2212 ki + 1{i\u2208A}) B(\u03b1i, \u03b2i) .\nLet us use the shorthand P (+1, A,B) and P (\u22121, A,B) for the joint probabilities in the last two displays, along with their corresponding conditionals P (\u00b11 |A,B). Obviously,\nP (1|A,B) > P (\u22121|A,B) \u21d0\u21d2 P (1, A,B) > P (\u22121, A,B), which occurs precisely if\nn \u220f\ni=1\nB(\u03b1i + ki + 1{i\u2208A}, \u03b2i +mi \u2212 ki + 1{i\u2208B})\n>\nn \u220f\ni=1\nB(\u03b1i + ki + 1{i\u2208B}, \u03b2i +mi \u2212 ki + 1{i\u2208A}).\nThis is equivalent to\n\u220f\ni\u2208A\n(\u03b1i + ki) \u220f\ni\u2208B\n(\u03b2i +mi \u2212 ki) > \u220f\ni\u2208B\n(\u03b1i + ki) \u220f\ni\u2208A\n(\u03b2i +mi \u2212 ki),\nwhich further simplifies to\n\u220f\ni\u2208A\n\u03b1i + ki \u03b2i +mi \u2212 ki > \u220f\ni\u2208B\n\u03b1i + ki \u03b2i +mi \u2212 ki .\nHence, the choice\nw\u0302Bai = log \u03b1i + ki\n\u03b2i +mi \u2212 ki guarantees that the decision rule\nf\u0302Ba(x,k) = sign\n(\nn \u2211\ni=1\nw\u0302Bai xi\n)\nmaximizes the probability of being correct for each input x \u2208 {\u00b11}n. Notice that for 0 < pi < 1, we have\nw\u0302Bai \u2212\u2192mi\u2192\u221ewi, i \u2208 [n],\nalmost surely, both in the frequentist and the Bayesian interpretations. Unfortunately, although\nP(f\u0302Ba(X,K) 6= Y ) = P(w\u0302Ba \u00b7 \u03b7 \u2264 0)\nis a deterministic function of {\u03b1i, \u03b2i,mi}, we are unable to compute it at this point, or even give a non-trivial bound. One source of the problem is the coupling between w\u0302Ba and \u03b7.\nOpen problem. Give a non-trivial estimate for P(f\u0302Ba(X,K) 6= Y )."}, {"heading": "6 Experiments", "text": "It is most instructive to take the committee size n to be small when comparing the different voting rules. Indeed, for a large committee of \u201cmarginally competent\u201d experts with pi = 1 2 + \u03b3 for some \u03b3 > 0, even the simple majority rule fMAJ(x) = sign( \u2211n\ni=1 xi) has a probability of error decaying as exp(\u22124n\u03b32), as can be easily seen from Hoeffding\u2019s bounds. The more sophisticated voting rules discussed in this paper perform even better in this setting. Hence, small committees provide the natural test-bed for gauging a voting rule\u2019s ability to exploit highly competent experts. In our experiments, we set n = 5 and the sample sizes mi were identical for all experts. The results were averaged over 105 trials. Two of our experiments are described below.\nLow vs. high confidence. The goal of this experiment was to contrast the extremal behavior of f\u0302LC vs. f\u0302HC. To this end, we numerically optimized the p \u2208 [0, 1]n so as to maximize the absolute gap\n\u2206n(p) := P(f LC(X) 6= Y )\u2212 P(fOPT(X) 6= Y ),\nwhere fLC(x) = sign ( \u2211n i=1(pi \u2212 12 )xi )\n. We were surprised to discover that, though the ratio P(fLC(X) 6= Y )/P(fOPT(X) 6= Y ) can be made arbitrarily large by setting p1 \u2248 1 and the remaining pi < 1 \u2212 \u03b5, the absolute gap appears to be rather small: we conjecture (with some heuristic justification) that\nsupn\u22651 supp\u2208[0,1]n \u2206n(p) = 1/16. For f\u0302 Ba, we used \u03b1i = \u03b2i = 1 for all i. The results are reported in Figure 1.\nBayesian setting. In each trial, a vector of expert competences p \u2208 [0, 1]n was drawn independently componentwise, with pi \u223c Beta(1, 1). These values (i.e., \u03b1i = \u03b2i \u2261 1) were used for f\u0302Ba. The results are reported in Figure 2."}, {"heading": "7 Discussion", "text": "The classic and seemingly well-understood problem of the consistency of weighted majority votes continues to reveal untapped depth and suggest challenging unresolved questions. We hope that the results and open problems presented here will stimulate future research."}, {"heading": "Appendix: Deferred proofs", "text": "Proof of Lemma 4. Since F is symmetric about x = 12 , it suffices to prove the claim for 12 \u2264 x < 1. We will show that F is concave by examining its second derivative:\nF \u2032\u2032(x) = \u22122x\u2212 1\u2212 2x(1\u2212 x) log(x/(1\u2212 x)) x(1\u2212 x)(2x \u2212 1)3 .\nThe denominator is obviously nonnegative on [ 12 , 1], while the numerator has the Taylor expansion\n\u221e \u2211\nn=1\n22(n+1)(x \u2212 12 )2n+1 4n2 \u2212 1 \u2265 0,\n1 2 \u2264 x < 1\n(verified through tedious but straightforward calculus). Since F is concave and symmetric about 12 , its maximum occurs at F ( 1 2 ) = 1 2 ."}], "references": [{"title": "Tuning bandit algorithms in stochastic environments", "author": ["Audibert", "Jean-Yves", "Munos", "R\u00e9mi", "Szepesv\u00e1ri", "Csaba"], "venue": "In ALT, pp", "citeRegEx": "Audibert et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Audibert et al\\.", "year": 2007}, {"title": "Distilling the wisdom of crowds: weighted aggregation of decisions on multiple issues", "author": ["Baharad", "Eyal", "Goldberger", "Jacob", "Koppel", "Moshe", "Nitzan", "Shmuel"], "venue": "Autonomous Agents and Multi-Agent Systems,", "citeRegEx": "Baharad et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Baharad et al\\.", "year": 2011}, {"title": "A sharp estimate of the binomial mean absolute deviation with applications", "author": ["Berend", "Daniel", "Kontorovich", "Aryeh"], "venue": "Statistics & Probability Letters,", "citeRegEx": "Berend et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Berend et al\\.", "year": 2013}, {"title": "On the concentration of the missing mass", "author": ["Berend", "Daniel", "Kontorovich", "Aryeh"], "venue": "Electron. Commun. Probab.,", "citeRegEx": "Berend et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Berend et al\\.", "year": 2013}, {"title": "When is Condorcet\u2019s jury theorem valid", "author": ["Berend", "Daniel", "Paroush", "Jacob"], "venue": "Soc. Choice Welfare,", "citeRegEx": "Berend et al\\.,? \\Q1998\\E", "shortCiteRegEx": "Berend et al\\.", "year": 1998}, {"title": "Monotonicity in Condorcet\u2019s jury theorem with dependent voters", "author": ["Berend", "Daniel", "Sapir", "Luba"], "venue": "Social Choice and Welfare,", "citeRegEx": "Berend et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Berend et al\\.", "year": 2007}, {"title": "Modelling dependence in simple and indirect majority systems", "author": ["Boland", "Philip J", "Proschan", "Frank", "Y.L. Tong"], "venue": "J. Appl. Probab.,", "citeRegEx": "Boland et al\\.,? \\Q1989\\E", "shortCiteRegEx": "Boland et al\\.", "year": 1989}, {"title": "Prediction, learning, and games", "author": ["Cesa-Bianchi", "Nicol\u00f2", "Lugosi", "G\u00e1bor"], "venue": null, "citeRegEx": "Cesa.Bianchi et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Cesa.Bianchi et al\\.", "year": 2006}, {"title": "A decision-theoretic generalization of online learning and an application to boosting", "author": ["Freund", "Yoav", "Schapire", "Robert E"], "venue": "J. Comput. Syst. Sci.,", "citeRegEx": "Freund et al\\.,? \\Q1997\\E", "shortCiteRegEx": "Freund et al\\.", "year": 1997}, {"title": "The Elements of Statistical Learning: Data Mining, Inference, and Prediction", "author": ["Hastie", "Trevor", "Tibshirani", "Robert", "Friedman", "Jerome"], "venue": null, "citeRegEx": "Hastie et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Hastie et al\\.", "year": 2009}, {"title": "Large deviation methods for approximate probabilistic inference", "author": ["Kearns", "Michael J", "Saul", "Lawrence K"], "venue": "In UAI,", "citeRegEx": "Kearns et al\\.,? \\Q1998\\E", "shortCiteRegEx": "Kearns et al\\.", "year": 1998}, {"title": "Obtaining measure concentration from Markov contraction", "author": ["Kontorovich", "Aryeh"], "venue": "Markov Processes and Related Fields,", "citeRegEx": "Kontorovich and Aryeh.,? \\Q2012\\E", "shortCiteRegEx": "Kontorovich and Aryeh.", "year": 2012}, {"title": "PAC-Bayes bounds for the risk of the majority vote and the variance of the gibbs classifier", "author": ["Lacasse", "Alexandre", "Laviolette", "Fran\u00e7ois", "Marchand", "Mario", "Germain", "Pascal", "Usunier", "Nicolas"], "venue": "In NIPS, pp", "citeRegEx": "Lacasse et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Lacasse et al\\.", "year": 2006}, {"title": "PAC-Bayes risk bounds for stochastic averages and majority votes of sample-compressed classifiers", "author": ["Laviolette", "Fran\u00e7ois", "Marchand", "Mario"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Laviolette et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Laviolette et al\\.", "year": 2007}, {"title": "The weighted majority algorithm", "author": ["Littlestone", "Nick", "Warmuth", "Manfred K"], "venue": "In FOCS, pp", "citeRegEx": "Littlestone et al\\.,? \\Q1989\\E", "shortCiteRegEx": "Littlestone et al\\.", "year": 1989}, {"title": "The weighted majority algorithm", "author": ["Littlestone", "Nick", "Warmuth", "Manfred K"], "venue": "Inf. Comput.,", "citeRegEx": "Littlestone et al\\.,? \\Q1994\\E", "shortCiteRegEx": "Littlestone et al\\.", "year": 1994}, {"title": "Robust aggregation of experts signals", "author": ["Mansour", "Yishay", "Rubinstein", "Aviad", "Tennenholtz", "Moshe"], "venue": null, "citeRegEx": "Mansour et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Mansour et al\\.", "year": 2013}, {"title": "Empirical Bernstein bounds and sample-variance penalization", "author": ["Maurer", "Andreas", "Pontil", "Massimiliano"], "venue": "In COLT,", "citeRegEx": "Maurer et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Maurer et al\\.", "year": 2009}, {"title": "Concentration inequalities for the missing mass and for histogram rule error", "author": ["McAllester", "David A", "Ortiz", "Luis E"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "McAllester et al\\.,? \\Q2003\\E", "shortCiteRegEx": "McAllester et al\\.", "year": 2003}, {"title": "Empirical Bernstein stopping", "author": ["Mnih", "Volodymyr", "Szepesv\u00e1ri", "Csaba", "Audibert", "Jean-Yves"], "venue": "In ICML, pp", "citeRegEx": "Mnih et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Mnih et al\\.", "year": 2008}, {"title": "On the problem of the most efficient tests of statistical hypotheses", "author": ["Neyman", "Jerzy", "Pearson", "Egon S"], "venue": "Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences,", "citeRegEx": "Neyman et al\\.,? \\Q1933\\E", "shortCiteRegEx": "Neyman et al\\.", "year": 1933}, {"title": "Optimal decision rules in uncertain dichotomous choice situations", "author": ["Nitzan", "Shmuel", "Paroush", "Jacob"], "venue": "International Economic Review,", "citeRegEx": "Nitzan et al\\.,? \\Q1982\\E", "shortCiteRegEx": "Nitzan et al\\.", "year": 1982}, {"title": "Concentration of measure inequalities in information theory, communications and coding", "author": ["Raginsky", "Maxim", "Sason", "Igal"], "venue": "Foundations and Trends in Communications and Information Theory,", "citeRegEx": "Raginsky et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Raginsky et al\\.", "year": 2013}, {"title": "From PAC-Bayes bounds to quadratic programs for majority votes", "author": ["Roy", "Jean-Francis", "Laviolette", "Fran\u00e7ois", "Marchand", "Mario"], "venue": "In ICML, pp", "citeRegEx": "Roy et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Roy et al\\.", "year": 2011}, {"title": "Boosting. Foundations and algorithms. Adaptive Computation and Machine Learning", "author": ["Schapire", "Robert E", "Freund", "Yoav"], "venue": null, "citeRegEx": "Schapire et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Schapire et al\\.", "year": 2012}], "referenceMentions": [{"referenceID": 9, "context": "(3) Thus, wi is the log-odds of expert i being correct \u2014 and the voting rule in (2), also known as naive Bayes (Hastie et al., 2009), may be seen as a simple consequence of the Neyman-Pearson lemma (Neyman & Pearson, 1933).", "startOffset": 111, "endOffset": 132}, {"referenceID": 16, "context": "Even more recently, experts with adversarial noise have been considered (Mansour et al., 2013).", "startOffset": 72, "endOffset": 94}, {"referenceID": 11, "context": "In a recent line of work Lacasse et al. (2006); Laviolette & Marchand (2007); Roy et al.", "startOffset": 25, "endOffset": 47}, {"referenceID": 11, "context": "In a recent line of work Lacasse et al. (2006); Laviolette & Marchand (2007); Roy et al.", "startOffset": 25, "endOffset": 77}, {"referenceID": 11, "context": "In a recent line of work Lacasse et al. (2006); Laviolette & Marchand (2007); Roy et al. (2011) have developed a PAC-Bayesian theory for the majority vote of simple classifiers.", "startOffset": 25, "endOffset": 96}, {"referenceID": 11, "context": "In a recent line of work Lacasse et al. (2006); Laviolette & Marchand (2007); Roy et al. (2011) have developed a PAC-Bayesian theory for the majority vote of simple classifiers. This approach facilitates data-dependent bounds and is even flexible enough to capture some simple dependencies among the classifiers \u2014 though, again, the latter are learners as opposed to our experts. Even more recently, experts with adversarial noise have been considered (Mansour et al., 2013). More directly related to the present work are the papers of Berend & Paroush (1998), which characterizes the consistency of the simple majority rule, and Boland et al.", "startOffset": 25, "endOffset": 560}, {"referenceID": 6, "context": "More directly related to the present work are the papers of Berend & Paroush (1998), which characterizes the consistency of the simple majority rule, and Boland et al. (1989); Berend & Sapir (2007) which analyze various models of dependence among the experts.", "startOffset": 154, "endOffset": 175}, {"referenceID": 6, "context": "More directly related to the present work are the papers of Berend & Paroush (1998), which characterizes the consistency of the simple majority rule, and Boland et al. (1989); Berend & Sapir (2007) which analyze various models of dependence among the experts.", "startOffset": 154, "endOffset": 198}, {"referenceID": 0, "context": ", These adaptive bounds are similar in spirit to empirical Bernstein methods, (Audibert et al., 2007; Mnih et al., 2008; Maurer & Pontil, 2009), where the player\u2019s confidence depends on the empirical variance.", "startOffset": 78, "endOffset": 143}, {"referenceID": 19, "context": ", These adaptive bounds are similar in spirit to empirical Bernstein methods, (Audibert et al., 2007; Mnih et al., 2008; Maurer & Pontil, 2009), where the player\u2019s confidence depends on the empirical variance.", "startOffset": 78, "endOffset": 143}], "year": 2014, "abstractText": "We revisit the classical decision-theoretic problem of weighted expert voting from a statistical learning perspective. In particular, we examine the consistency (both asymptotic and finitary) of the optimal NitzanParoush weighted majority and related rules. In the case of known expert competence levels, we give sharp error estimates for the optimal rule. When the competence levels are unknown, they must be empirically estimated. We provide frequentist and Bayesian analyses for this situation. Some of our proof techniques are non-standard and may be of independent interest. The bounds we derive are nearly optimal, and several challenging open problems are posed. Experimental results are provided to illustrate the theory.", "creator": "dvips(k) 5.991 Copyright 2011 Radical Eye Software"}}}