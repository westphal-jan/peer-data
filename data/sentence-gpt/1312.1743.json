{"id": "1312.1743", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "6-Dec-2013", "title": "Dual coordinate solvers for large-scale structural SVMs", "abstract": "This manuscript describes a method for training linear SVMs (including binary SVMs, SVM regression, and structural SVMs) from large, out-of-core training datasets. Current strategies for large-scale learning fall into one of two camps; batch algorithms which solve the learning problem given a finite datasets, and online algorithms which can process out-of-core datasets. The former typically requires datasets small enough to fit in memory. The latter is often phrased as a stochastic optimization problem; such algorithms enjoy strong theoretical properties but often require manual tuned annealing schedules, and may converge slowly for problems with large output spaces (e.g., structural SVMs). We discuss an algorithm for an \"intermediate\" regime in which the data is too large to fit in memory, but the active constraints (support vectors) are small enough to remain in memory. In this case, one can design rather efficient learning algorithms that are as stable as batch algorithms, but capable of processing out-of-core datasets. We have developed such a MATLAB-based solver and used it to train a collection of recognition systems for articulated pose estimation, facial analysis, 3D object recognition, and action classification, all with publicly-available code. This writeup describes the solver in detail.\n\n\nThe algorithm is described as a continuous learning system. A training tree can be implemented in a sequence of three or more samples, but the training trees are limited to the number of steps each has taken, which is more often than not significant. The training tree is not an individual training tree; the training tree is a large, flexible, and iterative tree with multiple instructions, and therefore is very efficient. Each step of the training tree consists of a sequence of instructions and an output tree that includes a fixed number of instructions, and has a single output tree that includes a total of multiple instructions, and that consists of a total of many instructions, and that consists of a total of a number of instructions. The training tree, called a continuous learning system (i.e., a linear learning system, or SVM), consists of three different levels of learning: a linear learning network with no fixed number of instructions, a continuous learning system, and an output tree that includes a total of many instructions, and that consists of a total of many instructions, and that consists of a total of many instructions, and that consists of a total of many instructions, and that consists of a total of many instructions, and that consists of a total of many instructions", "histories": [["v1", "Fri, 6 Dec 2013 00:55:51 GMT  (18kb)", "https://arxiv.org/abs/1312.1743v1", null], ["v2", "Fri, 13 Jun 2014 04:10:06 GMT  (71kb,D)", "http://arxiv.org/abs/1312.1743v2", null]], "reviews": [], "SUBJECTS": "cs.LG cs.CV", "authors": ["deva ramanan"], "accepted": false, "id": "1312.1743"}, "pdf": {"name": "1312.1743.pdf", "metadata": {"source": "CRF", "title": "Dual coordinate solvers for large-scale structural SVMs", "authors": ["Deva Ramanan"], "emails": [], "sections": [{"heading": null, "text": "Dual coordinate solvers for large-scale structural SVMs"}, {"heading": "Deva Ramanan", "text": "UC Irvine\nThis manuscript describes a method for training linear SVMs (including binary SVMs, SVM regression, and structural SVMs) from large, out-of-core training datasets. Current strategies for large-scale learning fall into one of two camps; batch algorithms which solve the learning problem given a finite datasets, and online algorithms which can process out-of-core datasets. The former typically requires datasets small enough to fit in memory. The latter is often phrased as a stochastic optimization problem [4, 21]; such algorithms enjoy strong theoretical properties but often require manual tuned annealing schedules, and may converge slowly for problems with large output spaces (e.g., structural SVMs). We discuss an algorithm for an \u201cintermediate\u201d regime in which the data is too large to fit in memory, but the active constraints (support vectors) are small enough to remain in memory. In this case, one can design rather efficient learning algorithms that are as stable as batch algorithms, but capable of processing out-of-core datasets. We have developed such a MATLAB-based solver and used it to train a series of recognition systems [25, 8, 28, 14, 19, 20, 26, 15, 13] for articulated pose estimation, facial analysis, 3D object recognition, and action classification, most of which has publicly-available code. This writeup describes the solver in detail.\nApproach: Our approach is closely based on data-subsampling algorithms for collecting hard examples [10, 11, 7], combined with the dual coordinate quadratic programming (QP) solver described in liblinear [9]. The latter appears to be current fastest method for learning linear SVMs. With regard to liblinear, we make two extensions (1) We generalize the solver to other types of SVM problems such as (latent) structural SVMs (2) We modify it to behave as a partially-online algorithm, which only requires access to small amounts of in-memory data at a time. Data-subsampling algorithms typically operate by iterating between searching for hard examples and optimization over a batch of hard-examples in memory. With regard to these approaches, our approach differs in that (1) we use previously-computed solutions to\u201chot-start\u201d optimizations, making frequent calls to a batch solver considerable cheaper and (2) we track upper and lower bounds to derive an \u201coptimal\u201d schedule for exploring new data versus optimizing over the existing batch.\nOverview: Sec. A describes a general formulation of an SVM problem that encompasses many standard tasks such as multi-class classification and (latent) structural prediction. Sec. 1 derives its dual QP, and Sec. 2 describes a dual coordinate descent optimization algorithm. Sec. 3 describes modifications for optimizing in an online fashion, allowing one to learn near-optimal models with a single pass over large, out-of-core datasets. Sec. 4 briefly touches on some theoretical issues that are necessary to ensure convergence. Finally, Sec. 5 and Sec. 6 describe modifications to our basic formulation to accommodate non-negativity constraints and flexible regularization schemes during learning."}, {"heading": "1 Generalized SVMs", "text": "We first describe a general formulation of a SVM which encompasses various common problems such as binary classification, regression, and structured prediction. Assume we are given training data where the ith example is described by a set of Ni vectors {xij} and a set of Ni scalars {lij}, where j varies from 1 to Ni. We wish to solve the following optimization problem:\nargmin w\nL(w) = 1\n2 ||w||2 + \u2211 i max j\u2208Ni (0, lij \u2212 wTxij) (1)\nar X\niv :1\n31 2.\n17 43\nv2 [\ncs .L\nG ]\n1 3\nJu n\n20 14\nWe can write the above optimization as the following quadratic program (QP):\nargmin w,\u03be\u22650\n1 2 ||w||2 + N\u2211 i \u03bei (2)\ns.t. \u2200i, j \u2208 Ni wTxij \u2265 lij \u2212 \u03bei\nEq. (1) and its QP variant (2) is a general form that encompasses binary SVMs, multiclass SVMs[6], SVM regression [22], structural SVMs [23, 24] the convex variant of latent SVMs [10, 11] and the convex variant of latent structural SVMs [27]. In Appendix A, we explicitly derive the various special cases. We will describe algorithms for handling large numbers of examples i, as well as (possibly exponentially) large values of Ni.\nThe above generalizes a traditional SVM learning formulation in several ways. Firstly, each example xij comes equipped with its own margin lij . We shall see that this involves a relatively small modification to the QP solver. A more significant modification is that slack variables are now shared across linear constraints. If each example xij had its own slack variable \u03beij , then (2) would be structurally equivalent to a standard SVM and amenable to standard QP optimization techniques. Intuitively, with independent slack variables, the set of examples xij could contribute Ni \u201cdollars\u201d to the loss. This could be a problem when Ni is exponentially-large (as is the case for structured output spaces). By sharing slacks, the set of examples can only contribute at most one \u201cdollar\u201d to the loss.\nTo further analyze the effect of shared slacks, we derive the dual QP by writing down the associated Lagrangian:\nL(w, \u03be, \u03b1, \u00b5) = 1\n2 ||w||2 + \u2211 i \u03bei \u2212 \u2211 ij \u03b1ij(w \u00b7 xij \u2212 lij + \u03bei)\u2212 \u2211 i \u00b5i\u03bei (3)\nBy strong duality\nmin w,\u03be\n[ max\n\u03b1\u22650,\u00b5\u22650 L(w,\u03b1, \u00b5) ] = max \u03b1\u22650,\u00b5\u22650 [ min w,\u03be L(w,\u03b1, \u00b5) ]\n(4)\nWe take the derivative of the Lagrangian with respect to the primal variables to get the KKT conditions:\n\u2202L(w,\u03b1, \u00b5)\n\u2202w = 0 \u2192 w = \u2211 ij \u03b1ijxij (5)\n\u2202L(w,\u03b1, \u00b5)\n\u2202\u03bei = 0 \u2192 \u2211 j \u03b1ij \u2264 1 \u2200i (6)\nWe write the dual of the QP in (2) as\nF (\u03b1) = \u22121 2 \u2211 ij,kl \u03b1ijx T ijxkl\u03b1kl + \u2211 ij lij\u03b1ij (7)\ns.t. \u2200i, \u2211 j \u03b1ij \u2264 1 (8)\n\u2200i, j \u2208 Ni, \u03b1ij \u2265 0\nWe wish to maximize (7) over the dual variables \u03b1. We can further analyze the nature of the optimal solution by considering complementary slackness conditions, which states that either a primal constraint is active, or its corresponding dual Lagrangian multiplier is 0:\n\u2200i, j \u2208 Ni s.t \u03b1ij > 0, wTxij = lij \u2212 \u03bei (9)\nThe above condition states that all examples with non-zero alpha (support vectors) associated with a single i will incur the same slack loss \u03bei. In order words, these examples correspond to \u201cties\u201d in the\nmaximization over maxj(0, lij \u2212 w \u00b7 xij) from (1). At the optimal dual solution, the linear constraint from (8) delicately balances the influence of support vectors associated with i to ensure they all pay the same slack loss. If each example xij had its own slack variable \u03beij , (8) would be replaced by independent \u201cbox constraints\u201d \u03b1ij \u2264 1 for all ij. Box constraints are simpler to deal with because they decouple across the dual variables. Indeed, we show that the linear constraints considerable complicate the optimization problem."}, {"heading": "2 Batch optimization", "text": "We now describe efficient training algorithms for solving dual QPs of the general form from (7). We begin by describing a solver that operates in a batch setting, requiring access to all training examples i and all sets of constaints for each example j \u2208 Ni. Our online algorithm will remove both these restrictions. The fastest current batch solver for linear SVMs appears to be liblinear [9], which is a dual coordinate descent method. A naive implementation of a dual solver would require maintaining a N \u00d7 N kernel matrix. The innovation of liblinear is the realization that one can implicitly represent the kernel matrix for linear SVMs by maintaining the primal weight vector w, which is much smaller. We show a similar insight can be used to design efficient dual solvers for generalized SVMs of the form from (36). Shared slacks considerably complicate coordinate-wise updates, but importantly, we describe an optimization schedule that is as fast as liblinear for much of the optimization.\nTo derive the modified optimization, let us first try to naively apply dual coordinate descent to optimizing (7): let us pick a single dual variable \u03b1ij , and update it holding all other \u03b1\u2019s fixed. This reduces to maximizing a 1-D quadratic function subject to box constraints. This appears easy at first; solve for the maximum of the quadratic and clip the solution to lie within the box constraint. We solve for the offset a that maximizes:\nF (\u03b1+ a\u03b4ij) = 1\n2 hija\n2 + gija+ constant (10)\ns.t. 0 \u2264 \u03b1i + a \u2264 1\nwhere \u03b1i = \u2211 j \u03b1ij , hij = \u2212xTijxij (which can be precomputed), and the gradient can be efficiently\ncomputed using w:\ngij = lij \u2212 \u2211 kl xTijxkl\u03b1kl\n= lij \u2212 wTxij (11)\nThere are four scenarios one can encounter when attempting to maximize (10), which are visually depicted in Fig. 1:\n1. gij = 0, in which case \u03b1ij is optimal for the current \u03b1.\n2. gij < 0, in which case decreasing \u03b1ij will increase the dual.\n3. gij > 0 and \u03b1i < 1, in which case increasing \u03b1ij will increase the dual.\n4. gij > 0 and \u03b1i = 1, in which case increasing \u03b1ij may increase the dual.\nFor the first three scenarios, we can apply \u201cstandard\u201d coordinate-wise updates that maximize (10) in closed form:\na\u2217 = min ( max ( \u2212 \u03b1i,\ngij hij\n) , 1\u2212 \u03b1i ) (12)\nyielding the update rule\naij := aij + a \u2217 (13)\nFor the last scenario, we would like to increase \u03b1ij but cannot because of the active linear constraint\u2211 j \u03b1ij = 1. Let us select another dual variable (\u03b1ik, k 6= j) that shares this constraint to possibly decrease. We would like to find the offset a that maximizes:\nF (\u03b1+ a\u03b4ij \u2212 a\u03b4ik) = 1\n2 h\u2032a2 + g\u2032a+ constant (14)\ns.t. 0 \u2264 \u03b1ij + a \u2264 1 and 0 \u2264 \u03b1ik \u2212 a \u2264 1\nwhere h\u2032 = hij + hik \u2212 2xTijxij and g\u2032 = gij \u2212 gik. Any value of a will ensure that the linear constraint is satisfied. The above maximization can be computed in closed form:\na\u2217 = min ( max ( a0,\ngij hij\n) , a1 ) where (15)\na0 = \u2212max(\u03b1ij , 1\u2212 \u03b1ik) and a1 = min(\u03b1ik, 1\u2212 \u03b1ij)\nwhich yields the following coordinate updates:\n\u03b1ij := \u03b1ij + a \u2217 and \u03b1ik := \u03b1ik \u2212 a\u2217 (16)"}, {"heading": "2.1 Tracking w and \u03b1i", "text": "In order to enable efficient computation of the gradient for the next coordinate step, we track the change in w using the KKT condition (5):\nw := w + a\u2217xij for single dual update; e.g., conditions 1-3 hold (17) w := w + a\u2217(xij \u2212 xik) for pairwise dual update; e.g., condition 4 holds (18)\nSimilarly, we can track the change in \u03b1i from (10) :\n\u03b1i := \u03b1i + a \u2217 (19)\nwhich only needs to updated for the single dual update."}, {"heading": "2.2 Dual coordinate-descent", "text": "We provide pseudocode for our overall batch optimization algorithm below.\nInput: {xij , lij} Output: w\n1 \u2200ij, \u03b1ij := 0, \u03b1i := 0, w := 0 ; // Initialize variables (if not passed as arguments) 2 Repeat 3 Randomly pick a dual variable \u03b1ij ; 4 Compute gradient gij from (11); 5 if gij > and \u03b1i = 1 then // Find another variable if linear constraint is active 6 Randomly pick another dual variable with same i (\u03b1ik for k 6= j); 7 Compute a\u2217 with (15) ; 8 Update \u03b1ij , \u03b1ik, w with (16),(17)\n9 else if |gij | > then /* Else update single dual variable */ 10 Compute a\u2217 with (12); 11 Update \u03b1ij , \u03b1i, w with (13), (19),(17) 12 end\n13\nAlgorithm 1: Optimize({xij , lij}) performs batch optimization of a fixed dataset using multiple passes of dual coordinate descent. We also define a variant that can be \u201chot-started\u201d with an existing set of dual variables, and optimized until some tolerance threshold tol is met Optimize({xij , lij , aij}, tol). Random sampling: One may question the need for random sampling; why not iterate over dual variables \u201cin order\u201d? The answer is that in practice, neighboring examples xij will tend to be correlated (e.g., consider examples extracted from overlapping sliding windows in an image). In the extreme case, consider two identical training examples x1 and x2. After performing a dual update on x1, x1 will usually score better, and often pass the margin test under the newly-updated w. If we immediately visit x2, it will also pass the margin test and w will not be updated. However, assume we first visit an uncorrelated example (that does trigger w to be updated) and then visit x2. This allows us to effectively \u201crevisit\u201d x1 in a single pass over our data. Hence a single (but randomly permuted) pass of coordinate descent effectively mimics multiple passes of (sequential) coordinate descent over correlated datasets. Lecun et al make similar observations to motivate random perturbations of data for stochastic gradient descent [18].\nSpeed: In practice, we apply our randomized batch algorithm by performing a large number of sequential passes over random permutations of a fixed dataset. During initial iterations, dual variables tend to be small and the linear inequality constraints in (8) are not active. This means that for much of our optimization, our solver updates a single dual variable at a time using (13), making it essentially is fast as liblinear. In later passes, the linear constraint tends to be active, and the solver is slower because update from (13) requires computing a dot product between two feature vectors with shared slack variables. In theory, one could cache these dot products in a reduced kernel matrix (since one needs to only store dot products between examples\nwith shared slacks, rather than all N2 examples). We found that computing them on-the-fly is still rather fast, and simplifies code.\nConvergence: With enough passes, the batch algorithm is guaranteed to converge (Sec. 4). In the following, we provide a practical stopping criteria for convergence (within some tolerance). In the next section on online-learning, we will make use of such a tolerance to manage computation to repeated calls of a dynamic QP-solver. To define our stopping criteria, we closely follow the duality-based stopping criteria described in [12]. Let OPT = minw L(w), the optimal primal objective function value from (1). Let us consider a candidate solution to the dual problem specified by a particular setting of dual variables \u03b1 = {\u03b1ij}. We can compute a lower bound on OPT by with F (\u03b1), since all dual solutions are a lower bound on OPT (by strong duality). We can also compute the associated primal weight vector w(\u03b1) = \u2211 ij \u03b1ijxij . We know that L(w(\u03b1)) must be an upper bound on OPT , since OPT is the minimal possible primal objective over all w:\nLB \u2264 OPT \u2264 UB where (20)\nLB = F (\u03b1) = \u22121 2 w(\u03b1)Tw(\u03b1) + l(\u03b1) (21) UB = L(w(\u03b1)) = 1\n2 w(\u03b1)Tw(\u03b1) + \u2211 ij max j (0, lij \u2212 w(\u03b1)Txij) (22)\nw(\u03b1) = \u2211 ij \u03b1ijxij\nl(\u03b1) = \u2211 ij lij\u03b1ij\nIt is straightforward to track changes to the lower bound from (21) by modifying lines 8 and 11 from Alg. 1 to maintain a running estimate of l(\u03b1) as dual variables are sequentially updated. The upper bound cannot be easily tracked, and instead has to be computed by passing over the entire set of data to compute the loss from (22) for a particular dual solution \u03b1. In practice, one can simply update the upper bound occasionally, after a large number of dual updates. Once the upper and lower bound are found to lie within some tolerance tol, the batch algorithm terminates. Sec. 4 suggests that given sufficient iterations, the bounds must meet. The full interface to our batch algorithm is Optimize({xij , lij , \u03b1ij}, tol) .\nApproximate upper-bound: We now describe an approximate upper bound that is easily tracked given a single sequential pass over a fixed dataset. Recall that our batch algorithm performs a large number of sequential passes over random permutations of our fixed dataset. The intuition behind our approximate upper bound is that we can use gradients gij , computed during dual updates from (11) to approximate the loss lij \u2212 w(\u03b1)Txij :\nUB\u2032 = 1\n2 w(\u03b1)Tw(\u03b1) + \u2211 ij max j (0, gij(\u03b1 t)) (23)\nWith some abuse of notation, we write gij(\u03b1 t) to explicitly denote the fact that gradients are computed with a changing set of dual variables at step t of coordinate descent. If no dual variables are updated during a single sequential pass over the fixed dataset, then \u03b1t = \u03b1 and the approximation is exact UB\u2032 = UB. In general we find that UB\u2032 > UB since the loss due to a data example lij \u2212w(\u03b1)Txij typically decreases after optimizing the dual variable associated with that data example. In practice, we keep track of this approximate upper bound, and whenever the tolerance criteria is satisfied with respect to this approximation, we compute the true upper-bound and perform another sequential pass if the true tolerance is not met. We find this speeds up batch optimization to convergence (up to tol) by factor of 2, compared to explicitly recomputing the true upper-bound after each sequential pass."}, {"heading": "3 Online learning", "text": "In this section, we describe an efficient algorithm for online optimization, given large streaming datasets. Importantly, our online algorithm requires caching a small number of constraints ij, and so is appropriate for problems with large numbers of examples i and/or problems with large numbers of shared constraints per example j \u2208 Ni. The later is important for solving structured prediction problems, where Ni may be exponentially large and pratically difficult to explicitly enumerate. When applied in a cyclic fashion on finite datasets, our online algorithm is garuanteed to converge to the optimal solution.\nLoss-augmented inference: To deal with exponentially-large Ni, our online algorithm does not require access to the entire set of constraints {xij , j \u2208 Nj} associated with example i, but rather assumes that this set can be efficiently searched. Specifically, we assume the user provides a function that, given a current weight vector w and example i, computes the \u201cworst-offending\u201d constraint j \u2208 Ni. This is often known as a \u201closs-augmented inference\u201d problem:\nWorstOffenderi = argmax j\u2208Ni\n[ lij \u2212 wTxij ] (24)\n= argmax j gij where gij is defined as (11) (25)\nThe above assumption is often quite reasonable as a similar maximization problem (maxj w Txij) must typically be solved for inference at test-time (e.g., for structured prediction). We make two additional notes. Firstly, the max corresponding to the above argmax is the loss due to example i for the current model w, which is required to to compute L(w) from (1). Secondly, the worst-offender is equivalent to the constraint j with largest gradient gij . This property can be used to to efficiently select \u201cgood\u201d constraints for coordinate updates, that are likely to increase the dual objective.\nOne-pass coordinate-descent: The batch algorithm from Alg.1 can be \u201ctrivially\u201d turned into a online algorithm by performing a single, sequential pass over a streaming dataset. Given a new data point i, one can sample a random j \u2208 Ni (or select j with the largest gradient, through loss augmented inference as described above) and compute its associated dual variable \u03b1ij . Because this is first time example i is encountered, its associated linear constraint \u2211 ij \u03b1ij \u2264 1 is not active. This means one can apply a simple coordinate-wise update of \u03b1ij , without the need to consider pairs of variables. This online algorithm has two notable properties. (1) This optimization step is guaranteed to not decrease the dual objective function. This is in contrast to online algorithms such as the perceptron or stochastic gradient descent that may take steps in the wrong direction. (2) The algorithm never requires the computation of the kernel matrix, and instead maintains an estimate of the primal variable w. This means that the storage requirement is constant with respect to the number of training examples, rather than quadratic (as required for a kernel matrix).\nExploration vs optimization: A crucial question in terms of convergence time is the order of optimization of the dual variables \u03b1ij . The above one-pass sequential algorithm takes an online perspective, where one continually explores new training examples. As w is being learned, at some point many (if not most) new examples will be \u201ceasy\u201d and pass the margin test. For such cases, \u03b1ij = 0 and gij \u2264 0, implying that the given dual coordinate step does not trigger an update, making learning inefficient. The LaRank algorithm [2] makes the observation that it is beneficial to frequently revisit past examples with a non-zero alpha, since they are more likely to trigger an update to their dual value. Previously examples that looked \u201chard\u201d often tend to remain \u201chard\u201d. This can be implemented by maintaining a cache of \u201chard examples\u201d [11], or support vectors and routinely optimizing over them while exploring new examples. This is basis for much of the literature on both batch and online SVMs, through the use of heuristics such as active-set selection [9, 24] and new-process/optimization steps [2]. We find that the precise scheduling of the optimization over new points (which we call exploration) versus existing support vectors (which we call optimization) is crucial.\nScheduling strategies: One scheduling strategy is to continually explore a new data point, analogous to the one-pass algorithm described above. Instead, LaRank suggests a exploring/optimization ratio of 10:1; revisit 10 examples from the cache for every new training example. Still another popular approach is to explore new data points by adding them to cache up to some fixed memory limit, and then optimize the\ncache to convergence and repeat. The hard-negative mining solver of [11] does exactly this. We make a number of observations to derive our strategy. First, successive calls to a dual solver can be hot-started from the previous dual solution, making them quite cheap. Secondly, it is advantageous to behave like an online algorithm (explore) during initial stages of learning, and behave more batch-like (optimize) during later stages of learning when the model is close to convergence. We propose here a novel on-line cutting plane algorithm [16, 17] that maintains running estimates of lower and upper bounds of the primal objective that naturally trade off the exploration of new data points versus the optimization of existing support vectors.\nOnline duality-gap: At any point in time during learning, we have a cache of examples and associated dual variables in memory {xij , lij , \u03b1ij : ij \u2208 A}. Together, these completely specify a primal weight vector w(\u03b1) = \u2211 ij\u2208A \u03b1ijxij . We must decide between two choices; we can either further optimize \u03b1 over the current examples in memory, or we can query for a brand new, unseen datapoint. From one perspective, the current cache of examples specifies a well-defined finite QP, and we may as well optimize that QP to completion. This would allow us to define a good w that would, in-turn, allow us to collect more relevant hard examples in the future. From another perspective, we might always choose to optimize with respect to new data (explore) rather than optimize over an example that we have already seen. We posit that one should ideally make the choice that produces the greatest increase in dual objective function value. Since it is difficult to compute the potential increase, we adopt the following strategy: we always choose to explore a new, unseen data point, unless the duality gap for the current QP solution is large (above tol), in which case we would rather optimize over the current cache to reduce the duality gap. We efficiently track the duality gap in an online fashion with the following streaming algorithm:\nInput: Streaming dataset {xij , lij} and tol Output: w\n1 A = {}; 2 w := 0; UB := 0; LB := 0 ; // Initialize variables 3 for i = 1 :\u221e do 4 Consider new example xi = {xij : j \u2208 Ni} ; // Explore new example 5 Compute j with maximum gradient maxj gij from (11); ; // Find \u2018\u2018worst offender\u2019\u2019 6 if gij > 0 then // Add to cache if it violates margin 7 UB := UB + gij ; 8 \u03b1ij := 0; 9 A := A \u2229 (ij)"}, {"heading": "10 end", "text": "11 if UB - LB > tol then // Optimize over cache if duality gap is violated 12 (w,\u03b1A, LB,UB) = Optimize({xA, lA, \u03b1A}, tol); 13 A := A \\ {ij : \u03b1ij = 0} ; // (Optionally) remove non-support-vectors from cache 14 end"}, {"heading": "15 end", "text": "Algorithm 2: The above online algorithm performs one pass of learning across a dataset by maintaining a cache of examples indices A = {(ij)}. At any point in time, the associated dual variables {\u03b1ij} encode the optimal model w for the QP defined by the cached examples, up to the duality gap tol.\nConvergence: To examine the convergence of the online algorithm, let us make a distinction between two QP problems. The cached-QP is the QP defined by the current set of examples in cache A. The fullQP is the QP defined by the possibly infinitely-large set of examples in the full dataset. During the online algorithm, UB and LB are always upper and lower bounds on the cached-QP. LB is also a lower bound on the full-QP. One can derive this fact by setting dual variables for all examples not in the cache to 0, and scoring the resulting full-\u03b1 vector under the dual objective, which must be F (\u03b1) = LB. Crucially though, UB is not an upper bound on the full-QP. This makes intuitive sense; it is hard to upper bound our loss without seeing all the data. Hence convergence for the online algorithm cannot be strictly guaranteed. However, if we apply the online algorithm by cycling over the dataset multiple times, one can ensure convergence with similar arguments to our batch optimization algorithm. Moreover, after learning a weight vector w(\u03b1A), we\ncan verify that it is optimal by computing a true upper bound L(w(\u03b1A)). This can be computed with a single, out-of-core pass over the entire dataset. We find that in practice, a single pass through large datasets often suffices for convergence (where if desired, convergence can be explicitly verified with an additional single pass).\nPruning: The last step of our online algorithm includes an optional pruning phase that removes non support vectors from the cache. It is crucial to note that pruning does not affect the lower-bound LB, since the dual objective F (\u03b1) will not change by removing constraints with zero \u03b1 values. Importantly, this lower-bound still holds even if the current cache is not optimized to convergence. Hence overall convergence (with cyclic online passes) is still guaranteed. However, it is possible that a pruned constraint later becomes a support vector after future updates to w, making the optimization somewhat inefficient and slowing convergence. Other active set methods make use of various heuristics for pruning a constraint, such as waiting until it remains inactive for a fixed number (50) of iterations [?]. For large datasets, we found it useful to aggressively prune; one a constraint appears easy, immediately remove it from the cache. Our intuition is that large datasets contain many correlated examples, so the solver will encounter a similar example later on during online optimization."}, {"heading": "4 Theoretical guarantees", "text": "In this section, we briefly point to some theoretical analysis that is necessary to ensure to show that the batch and cyclical-online version of our algorithm will converge to the global optimum. In particular, this analysis reveals that convergence of coordinate-wise updates does not necessarily produce the globally optimal solution, motivating the need for optimizing pairs of dual variables in Alg. 1.\nGlobal optimality: It is straightforward to define the optimality conditions of differentiable, unconstrained convex functions - the gradient of the function must be zero. Our dual objective function is differentiable, but constrained (7). Boyd shows that optimality conditions in such cases is more subtle [5]. Specifically, \u03b1 is optimal if and only if there is no feasible descent direction. Or in other words, it suffices to show that any small step along any direction that is feasible (in the convex set defined by our constraints) increases the value of the dual objective. [3] prove that is suffices to show that no improvement can be made along a set of \u201cwitness\u201d directions that form a basis for the feasible set of directions.\nJoint optimization: If no constraints are active at a given \u03b1, the coordinate axes do define a basis set. This means that for examples i for which the linear constraint \u2211 j \u03b1ij \u2264 1 is not active, it suffices to ensure that the dual cannot be improved by independently perturbing each dual variable \u03b1ij . However, this is not true for examples i with active linear constraints; its possible that no improvement can be made by taking a step along any dual variable, but an improvement can be made along a direction that changes a pair of dual variables (Fig. 1-(4)). This necessitates the need for the switch clauses in Alg. 1 that enumerate possibly active constraints, and precisely the reason why shared slacks in a structural SVM require joint optimization over pairs of dual variables.\nCyclic optimization: Consider an algorithm that randomly samples update directions with any distribution such that all feasible directions can be drawn with non-zero probability; [3] show that such an algorithm probably convergences to the optimum, within some specified tolerance, in finite time. Our batch algorithm and cyclic variant of our online algorithm satisfy this premise because they consider directions along each dual variable, as well as linear combinations of linearly-constrained variables."}, {"heading": "5 Non-negativity constraints", "text": "We now describe a simple modification to our proposed algorithms that accept non-negativity constraints on parameters w:\nL(w, \u03be) = 1\n2 ||w||2 + \u2211 i \u03bei (26)\ns.t. wTxij > lij \u2212 \u03bei \u03bei \u2265 0 wk \u2265 0 \u2200k \u2208 N (27)\nThe above is equivalent to our original formulation from (2) with an additional set of non-negativity constraints for a subset of parameters wk (27). The associated Lagrangian is\nL(w, b, \u03be, \u03b1, \u00b5, \u03b2k) = 1\n2 ||w||2 + \u2211 i \u03bei \u2212 \u2211 ij \u03b1ij(w \u00b7 xij \u2212 lij + \u03bei)\u2212 \u2211 i \u00b5i\u03bei \u2212 \u03b2 \u00b7 w (28)\nTo simplify notation, we have assumed that all parameters are constrained to be non-negative in the above Lagrangian, but our final algorithm will allow for an abitrary subset N . By strong duality\nmin w,b,\u03be\n[ max\n\u03b1\u22650,\u00b5\u22650,\u03b2\u22650 L(w, b, \u03b1, \u00b5) ] = max \u03b1\u22650,\u00b5\u22650,\u03b2\u22650 [ min w,b,\u03be L(w, b, \u03b1, \u00b5) ]\n(29)\nWe take the derivative of the Lagrangian with respect to the primal variables to get the KKT conditions: w = \u2211 ij\n\u03b1ijxij + \u03b2 (30)\u2211 j \u03b1ij \u2264 1 \u2200i (31)\nWe can write the dual of the QP in (26) as F (\u03b1, \u03b2) = \u22121 2 || \u2211 ij \u03b1ijxij + \u03b2||2 + \u2211 ij lij\u03b1ij (32)\ns.t. \u2211 j \u03b1ij \u2264 1\n\u03b1ij \u2265 0\nWe iterate between optimizing a single \u03b1i holding \u03b2 fixed, followed by optimizing \u03b2. One can show this is equivalent to zero-ing our negative parameters during dual updates:\n1. Update \u03b1ij , w with a coordinate descent update.\n2. Update \u03b2 by w[k] = max(w[k], 0),\u2200k \u2208 {1 . . . N}."}, {"heading": "6 Flexible regularization", "text": "This section will describe a method for using the aforementioned solver to solve a more general SVM problem with a Gaussian regularization or \u201cprior\u201d on w given by (\u00b5,\u03a3):\nargmin w,\u03be\n1 2 ||(w \u2212 w0)R||2 + \u2211 i \u03bei (33)\ns.t. wTxij > lij \u2212 \u03bei \u03bei \u2265 0\nwhere w0 = \u00b5, and R = \u03a3 \u22121/2. We can massage (33) into (2) with the substitution w\u0302 = (w \u2212 w0)R:\nargmin w\u0302,\u03be\n1 2 ||w\u0302||2 + \u2211 i \u03bei (34)\ns.t. w\u0302T x\u0302ij > l\u0302ij \u2212 \u03bei \u03bei \u2265 0 where w\u0302 = (w \u2212 w0)R x\u0302ij = R \u22121xij\nl\u0302ij = lij \u2212 wo \u00b7 xij\nWe assume that \u03a3 is full rank, implying that R\u22121 exists. An important special case is given by a diagonal matrix \u03a3, which corresponds to an arbitrary regularization of each parameter associated with a particular feature. This is useful, for example, when regularizing a feature vector constructed from heterogeneous features (such as appearance features, spatial features, and biases). After solving for the re-parametrized weight vector w\u0302 by optimizing the QP from (34), one can recover the score of the original weight vector with the following:\nw \u00b7 xij = (w\u0302 + w0R) \u00b7 x\u0302ij (35)"}, {"heading": "7 Conclusion", "text": "We have described a dual coordinate solver for solving general SVM problems (including multiclass, structural, and latent variations) with out-of-core, or even streaming datasets. The ideas described here are implemented in publicly available solvers released in [25, 8, 28, 14, 20].\nAcknowledgements: Funding for this research was provided by NSF Grant 0954083 and ONR-MURI Grant N00014-10-1-0933. We also gladly acknowledge co-authors for numerous discussions and considerable debugging efforts."}, {"heading": "A Generalized SVMs", "text": "In this section, we show that various SVM problems can be written as general cases of our underlying QP (2). This allows our optimization algorithms and solver to be applicable to a wide range of problems, including binary prediction, regression, structured prediction, and latent estimation. For conciseness, we write the QP from (2) here:\nargmin w,\u03be\u22650\n1 2 ||w||2 + N\u2211 i \u03bei (36)\ns.t. \u2200i, j \u2208 Ni wTxij \u2265 lij \u2212 \u03bei"}, {"heading": "A.1 Binary classification", "text": "A linearly-parametrized binary classifier predicts a binary label for an input x:\nLabel(x) = {wTx > 0} (37)\nThe associated learning problem is defined by a dataset of labeled examples {xi, yi}, where xi \u2208 RN , yi \u2208 {\u22121, 1}:\nargmin \u03b2\n1 2 ||\u03b2||2 + C \u2211 i \u03bei (38)\ns.t. yi(\u03b2 Txi + b) \u2265 1\u2212 \u03bei\nOne can convert the above into (2) with the following: first append a constant value v to each feature to model the bias term with x\u2032i = (xi, v) where v = 1 is the typical choice. This allows us to write \u03b2 Txi + b = w Tx\u2032i where w = (\u03b2, b). We then multiply in the class label yi and slack scaling C into each feature x \u2032, yielding xij = (Cyixi, Cyi), where j \u2208 {1}, Ni = 1 and lij = C. Bias term: The above mapping does not precisely correspond to (2) because the bias b is now regularized. This means the learning objective function will prefer biases closer to 0, while (38) does not favor any particular bias. This may or may not be desired. In practice, one can decrease the effect of regularization by appending a large constant value v. For example, a model learned with v = 100 will tend to produce larger effective biases b than v = 1. In the limit that v \u2192\u221e, (38) does map directly to (2). In Sec. 6, we describe a modification to (2) that allows for arbitrary (but finite) regularization factors for individual parameters. For the description of subsequent SVM problems, we omit the bias term for notational simplicity.\nMargin-rescaling: The above formulation can easily handle example-specific margins: for example, we may require that certain \u201cprototypical\u201d positives score higher than 2 rather than the standard margin of 1. This can be done by defining lij = margini, where margini is the margin associated with example i. In the literature, this modification is sometimes known as margin-rescaling. We will see that margin rescaling is one core component of structural SVM problems.\nCost-sensitive examples (slack-rescaling): The above formulation can be easily extended to costsensitive SVMs by defining lij = Ci and xij = (Ciyixi, Ciyi). This is sometimes known as slack rescaling. For example, one could define a different cost penalty for positive versus negative examples. Such class-specific costs have been shown be useful for learning classifiers from imbalanced datasets [1]. For the description of subsequent SVM problems, we omit any slack rescaling term (C or Ci) for notational simplicity, though they can always be incorporated by scaling xij and lij ."}, {"heading": "A.2 Multiclass SVMs", "text": "A linearly-parametrized multiclass predictor produces a class label for x with the following:\nLabel(x) = argmax j\u2208{1...K}\nwTj x\nThe associated learning problem is defined by a dataset {xi, yi} where xi \u2208 RN and yi \u2208 {1, 2, . . .K}. There exist many approaches to multiclass prediction that reduce the problem to a series of binary prediction problems (say, by training K 1-vs-all predictors or K2 pairwise predictors). Each of the core binary prediction problems can be written as (38), and so can be directly mapped to (2). Here, we describe the particular multiclass formulation from [6] which requires an explicit mapping:\nargmin w,\u03be\u22650\n1\n2 \u2211 j ||wj ||2 + \u2211 i \u03bei (39)\ns.t.\u2200i, j 6= yi wTyixi \u2212 w T j xi \u2265 loss(yi, j)\u2212 \u03bei (40)\nThe above formulation states that for example i, the score of the true class yi should dominate the score of any other class j by loss(yi, j); if not, we should pay the difference (the slack). For example, given a multi-class problem where the class labels are car, bus, and person, one may wish to penalize mistakes that label a car as a person higher than those that label a car as a bus. In the general setting, this can be specified with a loss function loss(yi, j) that specifies the cost of labeling class yi as class j. The original formulation\nfrom [6] defined a 0-1 loss where loss(yi, j) = 0 for j = yi and loss(yi, j) = 1 for j 6= yi. Finally, we have omitted an explicit class-specific bias term bj in the above formulation, but one can apply the same trick of appending a constant value to feature xi.\nThe above form can be massaged into (2) by the following: let us define w = (w1, . . . , wK) as a NKlong vector of concatenated class-specific weights wj , and \u03c6(xi, j) as a NK-length sparse vector with N non-zero entries corresponding to the interval given by class j. These two definitions allow us to write wTj xi = w\nT\u03c6(xi, j). This in turn allows us to define xij = \u03c6(xi, yi) \u2212 \u03c6(xi, j) , which then maps the above into (2), where Ni = (K \u2212 1)."}, {"heading": "A.3 Structural SVMs", "text": "A linearly-parametrized structural predictor produces a label of the form\nLabel(x) = argmax y\u2208Y\nwT\u03c6(xi, y)\nwhere Y represents a (possibly exponentially-large) structured output space. The associated learning problem is given by a dataset {xi, yi} where xi \u2208 RN and yi \u2208 Y :\nargmin w,\u03be\u22650\n1 2 ||w||2 + \u2211 i \u03bei (41)\ns.t.\u2200i, h \u2208 Y wT\u03c6(xi, yi)\u2212 wT\u03c6(xi, h) \u2265 loss(yi, h)\u2212 \u03bei (42)\nOne can define Ni = |Y |, xij = \u03c6(xi, yi) \u2212 \u03c6(xi, j) and lij = loss(yi, j), where j = h is interpreted as an index into the output space Y ."}, {"heading": "A.4 Latent SVMs", "text": "A latent SVM produces a binary prediction by searching over a latent variable\nLabel(x) = {max z\u2208Z w \u00b7 (x, z) > 0} (43)\nwhere Z represents a (possibly exponentially-large) latent space. In latent-SVM learning, and in particular, the convex optimization stage of coordinate descent [10], each training example is given by {xi, zi, yi} where yi \u2208 {\u22121, 1}, and zi are latent variables specified for positive examples:\nargmin w,\u03be\u22650\n1 2 ||w||2 + \u2211 i \u03bei (44)\ns.t.\u2200i \u2208 pos wT\u03c6(xi, zi) \u2265 1\u2212 \u03bei (45) s.t.\u2200i \u2208 neg, g \u2208 Z wT\u03c6(xi, g) \u2264 \u22121 + \u03bei (46)\nOne can map this to the above problem with the following: for i \u2208 pos, Ni = 1, xij = \u03c6(xi, zi), lij = 1. For i \u2208 neg, Ni = |Z|, xij = \u2212\u03c6(xi, j), lij = \u22121 where j = g."}, {"heading": "A.5 Latent structural SVMs", "text": "One can extend the above model to the latent structural case, where the predictor behaves as follows:\nLabel(x) = argmax y\u2208Y [ max z\u2208Z wT\u03c6(x, y, z) ]\nThe associated learning problem is defined by a dataset {xi, zi, yi} where yi \u2208 Y is a structured label rather than a binary one. In this scenario, the analogous convex step of \u201ccoordinate descent\u201d corresponds the\noptimizing the following optimization:\nargmin w,\u03be\u22650\n1 2 ||w||2 + \u2211 i \u03bei (47)\ns.t.\u2200i, h \u2208 Y, g \u2208 Z, wT\u03c6(xi, yi, zi)\u2212 wT\u03c6(xi, h, g) \u2265 loss(yi, h, g)\u2212 \u03bei\nThis can be mapped to our general formulation by defining Ni = |Y ||Z|, xij = \u03c6(xi, yi, zi) \u2212 \u03c6(xi, j) for j \u2208 Y \u00d7 Z."}, {"heading": "A.6 Regression", "text": "A linear regressor makes the following predictions\nLabel(x) = wTx\nThe associated SVM regression problem is specified by a dataset {xi, yi} where xi \u2208 RN and yi \u2208 R:\nargmin w,\u03be\u22650\n1 2 ||w||2 + \u2211 i (\u03bei + \u03be \u2217 i ) (48)\ns.t.\u2200i, wTxi \u2265 yi \u2212 \u2212 \u03bei wTxi \u2264 yi + + \u03be\u2217i\nThe above constraints can be converted to the from (2) by doubling the number of constraints by defining (x\u2032i, y \u2032 i) = (xi, yi \u2212 ) and (x\u20322i, y\u20322i) = (\u2212xi,\u2212yi \u2212 ) and Ni = N2i = 1.\nSummary: In this section, we have shown that many previously-proposed SVM problems can be written as instances of the generic problem in (1), which can be written as the quadratic program (QP) in (2)."}], "references": [{"title": "Applying support vector machines to imbalanced datasets", "author": ["Rehan Akbani", "Stephen Kwek", "Nathalie Japkowicz"], "venue": "In Machine Learning: ECML", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2004}, {"title": "Solving multiclass support vector machines with LaRank", "author": ["A. Bordes", "L. Bottou", "P. Gallinari", "J. Weston"], "venue": "In ICML,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2007}, {"title": "Fast kernel classifiers with online and active learning", "author": ["A. Bordes", "S. Ertekin", "J. Weston", "L. Bottou"], "venue": "The Journal of Machine Learning Research,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2005}, {"title": "The tradeoffs of large scale learning", "author": ["L. Bottou", "O. Bousquet"], "venue": "Advances in neural information processing systems,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2008}, {"title": "On the algorithmic implementation of multiclass kernel-based vector machines", "author": ["K. Crammer", "Y. Singer"], "venue": "The Journal of Machine Learning Research,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2002}, {"title": "Histograms of oriented gradients for human detection", "author": ["N. Dalal", "B. Triggs"], "venue": "In IEEE Computer Society Conference on Computer Vision and Pattern Recognition,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2005}, {"title": "Detecting actions, poses, and objects with relational phraselets", "author": ["Chaitanya Desai", "Deva Ramanan"], "venue": "Computer Vision\u2013ECCV", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2012}, {"title": "LIBLINEAR: A library for large linear classification", "author": ["R.E. Fan", "K.W. Chang", "C.J. Hsieh", "X.R. Wang", "C.J. Lin"], "venue": "The Journal of Machine Learning Research,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2008}, {"title": "A discriminatively trained, multiscale, deformable part model", "author": ["P. Felzenszwalb", "D. McAllester", "D. Ramanan"], "venue": "Computer Vision and Pattern Recognition,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2008}, {"title": "Object detection with discriminatively trained part based models", "author": ["Pedro F. Felzenszwalb", "Ross B. Girshick", "David McAllester", "Deva Ramanan"], "venue": "IEEE TPAMI,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2010}, {"title": "Optimized cutting plane algorithm for support vector machines", "author": ["V. Franc", "S. Sonnenburg"], "venue": "In Proceedings of the 25th international conference on Machine learning,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2008}, {"title": "Parsing occluded people", "author": ["D. Ramanan. C. Fowlkes G. Ghiasi", "Y. Yang"], "venue": "In Computer Vision and Pattern Recognition (CVPR). IEEE,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2014}, {"title": "Analyzing 3d objects in cluttered images", "author": ["Mohsen Hejrati", "Deva Ramanan"], "venue": "In Advances in Neural Information Processing Systems, pages 602\u2013610,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2012}, {"title": "Analysis by synthesis: 3d object recognition by object reconstruction", "author": ["Mohsen Hejrati", "Deva Ramanan"], "venue": "In Computer Vision and Pattern Recognition (CVPR). IEEE,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2014}, {"title": "Training linear SVMs in linear time", "author": ["T. Joachims"], "venue": "In Proceedings of the 12th ACM SIGKDD international conference on Knowledge discovery and data mining,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2006}, {"title": "Efficient backprop", "author": ["Yann A LeCun", "L\u00e9on Bottou", "Genevieve B Orr", "Klaus-Robert M\u00fcller"], "venue": "In Neural networks: Tricks of the trade,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2012}, {"title": "Steerable part models", "author": ["Hamed Pirsiavash", "Deva Ramanan"], "venue": "In Computer Vision and Pattern Recognition (CVPR),", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2012}, {"title": "Histograms of sparse codes for object detection", "author": ["Xiaofeng Ren", "Deva Ramanan"], "venue": "In Computer Vision and Pattern Recognition (CVPR),", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2013}, {"title": "Pegasos: Primal estimated sub-gradient solver for svm", "author": ["S. Shalev-Shwartz", "Y. Singer", "N. Srebro"], "venue": "In Proceedings of the 24th international conference on Machine learning,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2007}, {"title": "A tutorial on support vector regression", "author": ["Alex J Smola", "Bernhard Sch\u00f6lkopf"], "venue": "Statistics and computing,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2004}, {"title": "Max-margin markov networks", "author": ["B. Taskar", "C. Guestrin", "D. Koller"], "venue": "Advances in neural information processing systems,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2003}, {"title": "Support vector machine learning for interdependent and structured output spaces", "author": ["I. Tsochantaridis", "T. Hofmann", "T. Joachims", "Y. Altun"], "venue": "In ICML. ACM New York, NY,", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2004}, {"title": "Articulated human detection with flexible mixtures of parts", "author": ["Yi Yang", "Deva Ramanan"], "venue": "Pattern Analysis and Machine Intelligence, IEEE Transactions on,", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2013}, {"title": "Learning structural svms with latent variables", "author": ["C.N.J. Yu", "T. Joachims"], "venue": "In Proceedings of the 26th Annual International Conference on Machine Learning,", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2009}, {"title": "Face detection, pose estimation, and landmark localization in the wild", "author": ["Xiangxin Zhu", "D Ramanan"], "venue": "In Computer Vision and Pattern Recognition (CVPR),", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 2012}], "referenceMentions": [{"referenceID": 3, "context": "The latter is often phrased as a stochastic optimization problem [4, 21]; such algorithms enjoy strong theoretical properties but often require manual tuned annealing schedules, and may converge slowly for problems with large output spaces (e.", "startOffset": 65, "endOffset": 72}, {"referenceID": 18, "context": "The latter is often phrased as a stochastic optimization problem [4, 21]; such algorithms enjoy strong theoretical properties but often require manual tuned annealing schedules, and may converge slowly for problems with large output spaces (e.", "startOffset": 65, "endOffset": 72}, {"referenceID": 6, "context": "We have developed such a MATLAB-based solver and used it to train a series of recognition systems [25, 8, 28, 14, 19, 20, 26, 15, 13] for articulated pose estimation, facial analysis, 3D object recognition, and action classification, most of which has publicly-available code.", "startOffset": 98, "endOffset": 133}, {"referenceID": 24, "context": "We have developed such a MATLAB-based solver and used it to train a series of recognition systems [25, 8, 28, 14, 19, 20, 26, 15, 13] for articulated pose estimation, facial analysis, 3D object recognition, and action classification, most of which has publicly-available code.", "startOffset": 98, "endOffset": 133}, {"referenceID": 12, "context": "We have developed such a MATLAB-based solver and used it to train a series of recognition systems [25, 8, 28, 14, 19, 20, 26, 15, 13] for articulated pose estimation, facial analysis, 3D object recognition, and action classification, most of which has publicly-available code.", "startOffset": 98, "endOffset": 133}, {"referenceID": 16, "context": "We have developed such a MATLAB-based solver and used it to train a series of recognition systems [25, 8, 28, 14, 19, 20, 26, 15, 13] for articulated pose estimation, facial analysis, 3D object recognition, and action classification, most of which has publicly-available code.", "startOffset": 98, "endOffset": 133}, {"referenceID": 17, "context": "We have developed such a MATLAB-based solver and used it to train a series of recognition systems [25, 8, 28, 14, 19, 20, 26, 15, 13] for articulated pose estimation, facial analysis, 3D object recognition, and action classification, most of which has publicly-available code.", "startOffset": 98, "endOffset": 133}, {"referenceID": 22, "context": "We have developed such a MATLAB-based solver and used it to train a series of recognition systems [25, 8, 28, 14, 19, 20, 26, 15, 13] for articulated pose estimation, facial analysis, 3D object recognition, and action classification, most of which has publicly-available code.", "startOffset": 98, "endOffset": 133}, {"referenceID": 13, "context": "We have developed such a MATLAB-based solver and used it to train a series of recognition systems [25, 8, 28, 14, 19, 20, 26, 15, 13] for articulated pose estimation, facial analysis, 3D object recognition, and action classification, most of which has publicly-available code.", "startOffset": 98, "endOffset": 133}, {"referenceID": 11, "context": "We have developed such a MATLAB-based solver and used it to train a series of recognition systems [25, 8, 28, 14, 19, 20, 26, 15, 13] for articulated pose estimation, facial analysis, 3D object recognition, and action classification, most of which has publicly-available code.", "startOffset": 98, "endOffset": 133}, {"referenceID": 8, "context": "Approach: Our approach is closely based on data-subsampling algorithms for collecting hard examples [10, 11, 7], combined with the dual coordinate quadratic programming (QP) solver described in liblinear [9].", "startOffset": 100, "endOffset": 111}, {"referenceID": 9, "context": "Approach: Our approach is closely based on data-subsampling algorithms for collecting hard examples [10, 11, 7], combined with the dual coordinate quadratic programming (QP) solver described in liblinear [9].", "startOffset": 100, "endOffset": 111}, {"referenceID": 5, "context": "Approach: Our approach is closely based on data-subsampling algorithms for collecting hard examples [10, 11, 7], combined with the dual coordinate quadratic programming (QP) solver described in liblinear [9].", "startOffset": 100, "endOffset": 111}, {"referenceID": 7, "context": "Approach: Our approach is closely based on data-subsampling algorithms for collecting hard examples [10, 11, 7], combined with the dual coordinate quadratic programming (QP) solver described in liblinear [9].", "startOffset": 204, "endOffset": 207}, {"referenceID": 4, "context": "(1) and its QP variant (2) is a general form that encompasses binary SVMs, multiclass SVMs[6], SVM regression [22], structural SVMs [23, 24] the convex variant of latent SVMs [10, 11] and the convex variant of latent structural SVMs [27].", "startOffset": 90, "endOffset": 93}, {"referenceID": 19, "context": "(1) and its QP variant (2) is a general form that encompasses binary SVMs, multiclass SVMs[6], SVM regression [22], structural SVMs [23, 24] the convex variant of latent SVMs [10, 11] and the convex variant of latent structural SVMs [27].", "startOffset": 110, "endOffset": 114}, {"referenceID": 20, "context": "(1) and its QP variant (2) is a general form that encompasses binary SVMs, multiclass SVMs[6], SVM regression [22], structural SVMs [23, 24] the convex variant of latent SVMs [10, 11] and the convex variant of latent structural SVMs [27].", "startOffset": 132, "endOffset": 140}, {"referenceID": 21, "context": "(1) and its QP variant (2) is a general form that encompasses binary SVMs, multiclass SVMs[6], SVM regression [22], structural SVMs [23, 24] the convex variant of latent SVMs [10, 11] and the convex variant of latent structural SVMs [27].", "startOffset": 132, "endOffset": 140}, {"referenceID": 8, "context": "(1) and its QP variant (2) is a general form that encompasses binary SVMs, multiclass SVMs[6], SVM regression [22], structural SVMs [23, 24] the convex variant of latent SVMs [10, 11] and the convex variant of latent structural SVMs [27].", "startOffset": 175, "endOffset": 183}, {"referenceID": 9, "context": "(1) and its QP variant (2) is a general form that encompasses binary SVMs, multiclass SVMs[6], SVM regression [22], structural SVMs [23, 24] the convex variant of latent SVMs [10, 11] and the convex variant of latent structural SVMs [27].", "startOffset": 175, "endOffset": 183}, {"referenceID": 23, "context": "(1) and its QP variant (2) is a general form that encompasses binary SVMs, multiclass SVMs[6], SVM regression [22], structural SVMs [23, 24] the convex variant of latent SVMs [10, 11] and the convex variant of latent structural SVMs [27].", "startOffset": 233, "endOffset": 237}, {"referenceID": 7, "context": "The fastest current batch solver for linear SVMs appears to be liblinear [9], which is a dual coordinate descent method.", "startOffset": 73, "endOffset": 76}, {"referenceID": 15, "context": "Lecun et al make similar observations to motivate random perturbations of data for stochastic gradient descent [18].", "startOffset": 111, "endOffset": 115}, {"referenceID": 10, "context": "To define our stopping criteria, we closely follow the duality-based stopping criteria described in [12].", "startOffset": 100, "endOffset": 104}, {"referenceID": 1, "context": "The LaRank algorithm [2] makes the observation that it is beneficial to frequently revisit past examples with a non-zero alpha, since they are more likely to trigger an update to their dual value.", "startOffset": 21, "endOffset": 24}, {"referenceID": 9, "context": "This can be implemented by maintaining a cache of \u201chard examples\u201d [11], or support vectors and routinely optimizing over them while exploring new examples.", "startOffset": 66, "endOffset": 70}, {"referenceID": 7, "context": "This is basis for much of the literature on both batch and online SVMs, through the use of heuristics such as active-set selection [9, 24] and new-process/optimization steps [2].", "startOffset": 131, "endOffset": 138}, {"referenceID": 21, "context": "This is basis for much of the literature on both batch and online SVMs, through the use of heuristics such as active-set selection [9, 24] and new-process/optimization steps [2].", "startOffset": 131, "endOffset": 138}, {"referenceID": 1, "context": "This is basis for much of the literature on both batch and online SVMs, through the use of heuristics such as active-set selection [9, 24] and new-process/optimization steps [2].", "startOffset": 174, "endOffset": 177}, {"referenceID": 9, "context": "The hard-negative mining solver of [11] does exactly this.", "startOffset": 35, "endOffset": 39}, {"referenceID": 14, "context": "We propose here a novel on-line cutting plane algorithm [16, 17] that maintains running estimates of lower and upper bounds of the primal objective that naturally trade off the exploration of new data points versus the optimization of existing support vectors.", "startOffset": 56, "endOffset": 64}, {"referenceID": 2, "context": "[3] prove that is suffices to show that no improvement can be made along a set of \u201cwitness\u201d directions that form a basis for the feasible set of directions.", "startOffset": 0, "endOffset": 3}, {"referenceID": 2, "context": "Cyclic optimization: Consider an algorithm that randomly samples update directions with any distribution such that all feasible directions can be drawn with non-zero probability; [3] show that such an algorithm probably convergences to the optimum, within some specified tolerance, in finite time.", "startOffset": 179, "endOffset": 182}, {"referenceID": 6, "context": "The ideas described here are implemented in publicly available solvers released in [25, 8, 28, 14, 20].", "startOffset": 83, "endOffset": 102}, {"referenceID": 24, "context": "The ideas described here are implemented in publicly available solvers released in [25, 8, 28, 14, 20].", "startOffset": 83, "endOffset": 102}, {"referenceID": 12, "context": "The ideas described here are implemented in publicly available solvers released in [25, 8, 28, 14, 20].", "startOffset": 83, "endOffset": 102}, {"referenceID": 17, "context": "The ideas described here are implemented in publicly available solvers released in [25, 8, 28, 14, 20].", "startOffset": 83, "endOffset": 102}, {"referenceID": 0, "context": "Such class-specific costs have been shown be useful for learning classifiers from imbalanced datasets [1].", "startOffset": 102, "endOffset": 105}, {"referenceID": 4, "context": "Here, we describe the particular multiclass formulation from [6] which requires an explicit mapping:", "startOffset": 61, "endOffset": 64}, {"referenceID": 4, "context": "from [6] defined a 0-1 loss where loss(yi, j) = 0 for j = yi and loss(yi, j) = 1 for j 6= yi.", "startOffset": 5, "endOffset": 8}, {"referenceID": 8, "context": "In latent-SVM learning, and in particular, the convex optimization stage of coordinate descent [10], each training example is given by {xi, zi, yi} where yi \u2208 {\u22121, 1}, and zi are latent variables specified for positive examples:", "startOffset": 95, "endOffset": 99}], "year": 2014, "abstractText": "This manuscript describes a method for training linear SVMs (including binary SVMs, SVM regression, and structural SVMs) from large, out-of-core training datasets. Current strategies for large-scale learning fall into one of two camps; batch algorithms which solve the learning problem given a finite datasets, and online algorithms which can process out-of-core datasets. The former typically requires datasets small enough to fit in memory. The latter is often phrased as a stochastic optimization problem [4, 21]; such algorithms enjoy strong theoretical properties but often require manual tuned annealing schedules, and may converge slowly for problems with large output spaces (e.g., structural SVMs). We discuss an algorithm for an \u201cintermediate\u201d regime in which the data is too large to fit in memory, but the active constraints (support vectors) are small enough to remain in memory. In this case, one can design rather efficient learning algorithms that are as stable as batch algorithms, but capable of processing out-of-core datasets. We have developed such a MATLAB-based solver and used it to train a series of recognition systems [25, 8, 28, 14, 19, 20, 26, 15, 13] for articulated pose estimation, facial analysis, 3D object recognition, and action classification, most of which has publicly-available code. This writeup describes the solver in detail. Approach: Our approach is closely based on data-subsampling algorithms for collecting hard examples [10, 11, 7], combined with the dual coordinate quadratic programming (QP) solver described in liblinear [9]. The latter appears to be current fastest method for learning linear SVMs. With regard to liblinear, we make two extensions (1) We generalize the solver to other types of SVM problems such as (latent) structural SVMs (2) We modify it to behave as a partially-online algorithm, which only requires access to small amounts of in-memory data at a time. Data-subsampling algorithms typically operate by iterating between searching for hard examples and optimization over a batch of hard-examples in memory. With regard to these approaches, our approach differs in that (1) we use previously-computed solutions to\u201chot-start\u201d optimizations, making frequent calls to a batch solver considerable cheaper and (2) we track upper and lower bounds to derive an \u201coptimal\u201d schedule for exploring new data versus optimizing over the existing batch. Overview: Sec. A describes a general formulation of an SVM problem that encompasses many standard tasks such as multi-class classification and (latent) structural prediction. Sec. 1 derives its dual QP, and Sec. 2 describes a dual coordinate descent optimization algorithm. Sec. 3 describes modifications for optimizing in an online fashion, allowing one to learn near-optimal models with a single pass over large, out-of-core datasets. Sec. 4 briefly touches on some theoretical issues that are necessary to ensure convergence. Finally, Sec. 5 and Sec. 6 describe modifications to our basic formulation to accommodate non-negativity constraints and flexible regularization schemes during learning.", "creator": "LaTeX with hyperref package"}}}