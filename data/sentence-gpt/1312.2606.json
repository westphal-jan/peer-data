{"id": "1312.2606", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "9-Dec-2013", "title": "Multi-Task Classification Hypothesis Space with Improved Generalization Bounds", "abstract": "This paper presents a RKHS, in general, of vector-valued functions intended to be used as hypothesis space for multi-task classification. It extends similar hypothesis spaces that have previously considered in the literature. Assuming this space, an improved Empirical Rademacher Complexity-based generalization bound is derived from a number of proposed generalizations, including a generalized RKHS. The RKHS and its associated generalizations were originally proposed by R. B. (1769). The purpose of this paper is to investigate the use of a generalization for non-parametric-equivalent functions. This paper investigates the applicability of a generalization for generalization using the Generalization for multivariate-equivalent functions. It will present a generalization for both types of generalizations. The generalization in this paper is proposed by J. A. D. J. (1821-1827) as a generalization. This paper proposes generalizations in generalization. This paper is a generalization for the generalization in generalization.", "histories": [["v1", "Mon, 9 Dec 2013 21:27:23 GMT  (46kb)", "http://arxiv.org/abs/1312.2606v1", "18 pages, 4 figures, submitted to IEEE Transactions on Neural Networks and Learning Systems"]], "COMMENTS": "18 pages, 4 figures, submitted to IEEE Transactions on Neural Networks and Learning Systems", "reviews": [], "SUBJECTS": "cs.LG", "authors": ["cong li", "michael georgiopoulos", "georgios c anagnostopoulos"], "accepted": false, "id": "1312.2606"}, "pdf": {"name": "1312.2606.pdf", "metadata": {"source": "META", "title": "Multi-Task Classification Hypothesis Space with Improved Generalization Bounds", "authors": ["Cong Li", "Michael Georgiopoulos", "Georgios C. Anagnostopoulos"], "emails": ["congli@eecs.ucf.edu,", "michaelg@ucf.edu", "georgio@fit.edu"], "sections": [{"heading": null, "text": "ar X\niv :1\n31 2.\n26 06\nv1 [\ncs .L\nG ]\n9 D\nec 2\nKeywords: Multi-task Learning, Kernel Methods, Generalization Bound, Support Vector Machines"}, {"heading": "1 Introduction", "text": "Multi-Task Learning (MTL) has been an active research field for over a decade [4]. The fundamental philosophy of MTL is to simultaneously train several related tasks with shared information, so that the hope is to improve the generalization performance of each task by the assistance of other tasks. More formally, in a typical MTL setting with T tasks, we want to choose T functions f = (f1, \u00b7 \u00b7 \u00b7 , fT ) from a Hypothesis Space (HS) F = {x 7\u2192 [f1(x), \u00b7 \u00b7 \u00b7 , fT (x)]\u2032}, where x is an instance of some input set X , such that the performance of each task is optimized based on a problem-specific criterion. Here [f1(x), \u00b7 \u00b7 \u00b7 , fT (x)]\u2032 denotes the transposition of row vector [f1(x), \u00b7 \u00b7 \u00b7 , fT (x)]. MTL has been successfully applied in feature selection [2, 8, 10], regression [19, 16], metric learning [28][23], and kernel-based MTL [7, 3, 24, 1] among other applications.\nDespite the abundance of MTL applications, relevant generalization bounds have only been developed for special cases. A theoretically well-studied MTL framework is regularized linear MTL model, whose generalization bound is studied in [21, 13, 22]. In this framework, each function ft is featured as a linear function with weight wt \u2208 H, such that \u2200x \u2208 X \u2286 H, ft(x) = \u3008wt,x\u3009, where H is a real Hilbert space equipped with inner product \u3008\u00b7, \u00b7\u3009. Different regularizers can be employed to the weightsw = (w1, \u00b7 \u00b7 \u00b7 ,wT ) \u2208 H\u00d7 . . .\u00d7H \ufe38 \ufe37\ufe37 \ufe38\nT times\nto fulfill different requirements of the problem at hand. Formally, given { xit, y i t } \u2208 X \u00d7 Y, i =\n1, \u00b7 \u00b7 \u00b7 , nt, t = 1, \u00b7 \u00b7 \u00b7 , T , where X and Y are the input and output space for each task, the framework can be written as\nmin w\nR(w) + \u03bb \u2211\ni,t\nL(ft(x i t), y i t) (1)\nwhere R(\u00b7) and L(\u00b7, \u00b7) are the regularizer and loss function respectively. Many MTL models fall into this framework. For example, [5] looks for group sparsity of w, [29] discovers group structure of multiple tasks, and [8, 10] select features in a MTL context.\nIn the previous framework, tasks are implicitly related by regularizers on w. On the other hand, another angle of considering information sharing amongst tasks is by pre-processing the data from all tasks by a common processor, and subsequently, a linear model is learned based on the processed data. One scenario of this learning framework is subspace learning, where data of each task are projected to a common subspace by an operator A, and then the wt\u2019s are learned in that subspace. Such an approach is followed in [2, 14]. Another particularly straightforward and useful adaptation of this framework is kernel-based MTL. In this situation, the role of the operatorA is assumed by the non-linear feature mapping \u03c6 associated with the kernel function in use. In this case, all data are pre-processed by a common kernel function, which is pre-selected or learned during the training phase, while the wt\u2019s are then learned in the corresponding Reproducing Kernel Hilbert Space (RKHS). One example of this technique is given in [26].\nOne previous work which discussed the generalization bound of this method in a classification context is [20]. Given a set A of bounded self-adjoint linear operators on X and T linear functions with weights wt\u2019s, the HS is given as F = {x 7\u2192 [\u3008w1, Ax\u3009, \u00b7 \u00b7 \u00b7 , \u3008wT , Ax\u3009]\u2032 : \u2016wt\u20162 \u2264 R,A \u2208 A}. Clearly, in this HS, data are pre-processed by the operator A to a common space, as a strategy of information sharing amongst tasks. By either cleverly choosing A beforehand or by learning A \u2208 A, it is expected that a tighter generalization bound can be attained compared to learning each task independently. It is straightforward to see that pre-selecting A beforehand is a special case of learning A \u2208 A, i.e., pre-selecting A is equivalent to A = {A}.\nHowever, the limitations of F are two-fold. First, in F , all wt\u2019s are equally constrained in a ball, whose radius R is determined prior to training. However, in practice, the HS that lets each task have its own radius for the corresponding norm-ball constraint may be more appropriate and may lead to a better generalization bound and performance.\nThe second limitation is that it cannot handle the models which learn a common kernel function for all tasks, e.g., the Multi-Task Multiple Kernel Learning (MT-MKL) models. One way to incorporate such kernel learning models into F is to let A be the feature mapping \u03c6 : X 7\u2192 H\u03c6, where H\u03c6 is the output space of the feature mapping \u03c6 and \u03c6 corresponds to the common kernel function k. In other words, this setting defines F = {x 7\u2192 [\u3008w1, \u03c6(x)\u3009, \u00b7 \u00b7 \u00b7 , \u3008wT , \u03c6(x)\u3009]\u2032 : \u2016wt\u20162 \u2264 R, \u03c6 \u2208 \u2126(\u03c6)}, where \u2126(\u03c6) is the set of feature mappings that \u03c6 is learned from. Obviously, the HS that is considered in [20] does not cover this scenario, since it only allows the operator A to be linear operator, which is not the case when A = \u03c6. Yet another limitation reveals itself, when one considers the equivalent HS: F = {x 7\u2192 [\u3008w1,x\u3009, \u00b7 \u00b7 \u00b7 , \u3008wT ,x\u3009]\u2032 : \u2016wt\u20162 \u2264 R,x \u2208 H\u03c6, \u03c6 \u2208 \u2126(\u03c6)}, where, as mentioned above, H\u03c6 is the output space of the feature mapping \u03c6. Obviously, the HS in [20] fails to cover this HS, due to the lack of the constraint \u03c6 \u2208 \u2126(\u03c6), which indicates that the feature mapping \u03c6 (hence, its corresponding kernel function) is learned during the training phase instead of of being selected beforehand.\nTherefore, in this paper, we generalize F , particularly for kernel-based classification problems, by considering the common operator \u03c6 (which is associated with a kernel function) for all tasks and by imposing norm-ball constraints on the wt\u2019s with different radii that are learned during the training process, instead of being chosen prior to training. Specifically, we consider the HS\nFs , {x 7\u2192 [\u3008w1, \u03c6(x)\u3009, \u00b7 \u00b7 \u00b7 , \u3008wT , \u03c6(x)\u3009]\u2032 : \u2016wt\u20162 \u2264 \u03bb2tR,\u03bb \u2208 \u2126s(\u03bb)} (2) and\nFs,r , {x 7\u2192 [\u3008w1, \u03c6(x)\u3009, \u00b7 \u00b7 \u00b7 , \u3008wT , \u03c6(x)\u3009]\u2032 : \u2016wt\u20162 \u2264 \u03bb2tR,\u03bb \u2208 \u2126s(\u03bb), \u03c6 \u2208 \u2126r(\u03c6)} (3)\nwhere \u2126s(\u03bb) , {\u03bb 0, \u2016\u03bb\u2016s \u2264 1, s \u2265 1}, and \u2126r(\u03c6) = {\u03c6 : \u03c6 = ( \u221a \u03b81\u03c61, \u00b7 \u00b7 \u00b7 , \u221a \u03b8M\u03c6M ), \u03b8 0, \u2016\u03b8\u2016r \u2264 1, r \u2265 1}, \u03c6m \u2208 Hm, \u03c6 \u2208 H1 \u00d7 \u00b7 \u00b7 \u00b7 \u00d7 HM . The objective of our paper is to derive and analyze the generalization bounds of these two HS. Specifically, the first HS, Fs, has fixed feature mapping \u03c6, which is pre-selected, and the second HS, Fs,r, learns the feature mapping via a Multiple Kernel Learning (MKL) approach. We refer readers to [18] and a survey paper [9] for details on MKL.\nObviously, by letting all \u03bbt\u2019s equal 1, Fs degrades to the equal-radius HS, which is a special case of Fs when s \u2192 +\u221e, as we will show in the sequel. By considering the generalization bound of Fs based on the Empirical Rademacher Complexity (ERC) [21], we first demonstrate that the ERC is monotonically increasing with s, which implies that the tightest bound is achieved, when s = 1. We then provide an upper bound for the ERC of Fs, which also monotonically increases with respect to s. In the optimal case (s = 1),\nwe achieve a generalization bound of order O( \u221a log T T\n), which decreases relatively fast with increasing T . On the other hand, when s \u2192 +\u221e, the bound does not decrease with increasing T , thus, it is less preferred.\nWe then derive the generalization bound for the HS Fs,r, which still features a bound of order O( \u221a log T T\n) when s = 1, as in the single-kernel setting. Additionally, if M kernel functions are involved, the bound is of order O( \u221a logM), which has been proved to be the best bound that can be obtained in single-task multi-kernel classification [6]. Therefore, the optimal order of the bound is also preserved in the MT-MKL case. Note that the proofs of all theoretical results are in the Appendix.\nAfter investigating the generalization bounds, we experimentally show that our bound on the ERC matches the real ERC very well. Moreover, we propose a MTL model based on Support Vector Machines (SVMs) as an example of a classification framework that uses Fs as its HS. It is further extended to an MT-MKL setting, whose HS becomes Fs,r. Experimental results on multi-task classification problems show the effect of s on the generalization ability of our model. In most situations, the optimal results are indeed achieved, when s = 1, which matches our technical analysis. For some other results that are not optimal as expected, when s = 1, we provide a justification."}, {"heading": "2 Fixed Feature Mapping", "text": "Let { xit, y i t } \u2208 X \u00d7{\u22121, 1} , i = 1, \u00b7 \u00b7 \u00b7 , N, t = 1, \u00b7 \u00b7 \u00b7 , T be i.i.d. training samples from some joint distribution. Without loss of generality and on grounds of convenience, we will assume an equal number of training samples for each task. Let H be a RKHS with reproducing kernel function k(\u00b7, \u00b7) : X \u00d7X 7\u2192 R, and associated feature mapping \u03c6 : X 7\u2192 H. In what follows we give the theoretical analysis of our HS Fs, when the feature mapping \u03c6 is fixed."}, {"heading": "2.1 Theoretical Results", "text": "Given T tasks, our objective is to learn T linear functionals ft(\u00b7) : H 7\u2192 R, such that ft(\u03c6(x)) = \u3008wt, \u03c6(x)\u3009 , t = 1, \u00b7 \u00b7 \u00b7 , T , x \u2208 X . Next, let f , [f1, \u00b7 \u00b7 \u00b7 , fT ]\u2032, and define the multi-task classification error as\ner(f) , 1\nT\nT\u2211\nt=1\nE{1(\u2212\u221e,0](ytft(\u03c6(xt)))} (4)\nwhere 1(\u2212\u221e,0](\u00b7) is the characteristic function of (\u2212\u221e, 0] and referred to as the 0/1 loss function. The empirical error based on a surrogate loss function L\u0304 : R 7\u2192 [0, 1], which is a Lipschitz-continuous function that upper-bounds the 0/1 loss function, is defined as\ne\u0302r(f) , 1\nTN\nT,N \u2211\nt,i=1\nL\u0304(yitft(\u03c6(x i t))) (5)\nFor the constraints on the wt\u2019s, instead of pre-defining a common radius R for all tasks as discussed in [20], we let \u2016wt\u20162 \u2264 \u03bb2tR, where \u03bbt is learned during the training phase. This motivates our consideration of Fs as given in (2), which we repeat here:\nFs , {x 7\u2192 [\u3008w1, \u03c6(x)\u3009, \u00b7 \u00b7 \u00b7 , \u3008wT , \u03c6(x)\u3009]\u2032 : \u2016wt\u20162 \u2264 \u03bb2tR,\u03bb \u2208 \u2126s(\u03bb)} (6) Note that the feature mapping \u03c6 is determined before training. In order to derive the generalization bound for Fs, we first provide the following lemma.\nLemma 1. Let Fs be as defined in Equation (6). Let L\u0304 : R 7\u2192 [0, 1] be a Lipschitz-continuous loss function with Lipschitz constant \u03b3 and upper-bound the 0/1 loss function 1(\u2212\u221e,0](\u00b7). Then, with probability 1 \u2212 \u03b4 we have\ner(f) \u2264 e\u0302r(f) + 1 \u03b3 R\u0302(Fs) +\n\u221a\n9 log 2 \u03b4\n2TN , \u2200f \u2208 Fs (7)\nwhere R\u0302(Fs) is the ERC for MTL problems defined in [21]:\nR\u0302(Fs) , E\u03c3{ sup f\u2208Fs\n2\nTN\nTN\u2211\nt,i=1\n\u03c3itft(\u03c6(x i t))} (8)\nwhere the \u03c3it\u2019s are i.i.d. Rademacher-distributed (i.e., Bernoulli ( 1 2 ) -distributed random variables with sample space {\u22121,+1}).\nThis lemma can be simply proved by utilizing Theorem 16 and 17 in [20]. By using the same proving strategy, it is easy to show that (7) is valid for all HSs that are considered in this paper. Therefore, we will not explicitly state a specialization of it for each additional HS encountered in the sequel. In the next, we first define the following duality mapping for all a \u2208 R:\n(\u00b7)\u2217 : a 7\u2192 a\u2217 , {\na a\u22121 , \u2200a 6= 1 +\u221e, a = 1 (9)\nthen we give the following results which show that R\u0302(Fs) is monotonically increasing with respect to s.\nLemma 2. Let \u03c3t , [\u03c3 1 t , \u00b7 \u00b7 \u00b7 , \u03c3Nt ]\u2032, ut ,\n\u221a\n\u03c3 \u2032\ntKt\u03c3t, where Kt is the kernel matrix that consists of elements\nk(xit,x j t ), t = 1, \u00b7 \u00b7 \u00b7 , T , u , [u1, \u00b7 \u00b7 \u00b7 , uT ]\u2032. Then \u2200s \u2265 1\nR\u0302(Fs) = 2\nTN\n\u221a RE\u03c3{\u2016u\u2016s\u2217} (10)\nLeveraging from Equation (10), one can show the following theorem.\nTheorem 1. R\u0302(Fs) is monotonically increasing with respect to s.\nDefine F\u0303 , {x 7\u2192 [\u3008w1, \u03c6(x)\u3009, \u00b7 \u00b7 \u00b7 , \u3008wT , \u03c6(x)\u3009]\u2032 : \u2016wt\u20162 \u2264 R}, which is the HS that is given in [20] under kernelized MTL setting, then F\u0303 is the HS with equal radius for each \u2016wt\u20162. Obviously, it is the special case of Fs with all \u03bbt\u2019s be set to 1. We have the following result:\nTheorem 2. R\u0302(F\u0303) = R\u0302(F+\u221e).\nThe above results imply that the tightest generalization bound is obtained when s = 1, while, on the other hand, the bound of F+\u221e that sets equal radii for all wt\u2019s is the least preferred. It is clear that, to derive a generalization bound for Fs, we need to compute, or, at least find an upper bound for R\u0302(Fs). The following theorem addresses this requisite.\nTheorem 3. Let Fs be as defined in Equation (6), and let \u03c1 , 2 lnT . Assume that \u2200x \u2208 X , k(x,x) = \u3008\u03c6(x), \u03c6(x)\u3009 \u2264 1. Then the ERC can be bounded as follows:\nR\u0302(Fs) \u2264 2\nT \u221a N\n\u221a\n\u03c4RT 2 s\u2217 (11)\nwhere \u03c4 , (max {s, \u03c1\u2217})\u2217."}, {"heading": "2.2 Analysis", "text": "It is worth pointing out some observations regarding the result of Theorem 3.\n\u2022 It is not difficult to see that the bound of the ERC in (11) is monotonically increasing in s, as is R\u0302(Fs). \u2022 As s \u2192 +\u221e, Fs degrades to F\u0303 . In this case, R\u0302(F+\u221e) \u2264 2 \u221a R N . Note that this bound matches the one\nthat is given in [20]. This is because of the following relation between F\u0303 and the HS of [20], F , that is introduced in Section 1: First, let the operator A in F be the identity operator, and then let x in F be an element of H, i.e., let x in F be \u03c6(x) in F\u0303 . Then F becomes F\u0303 .\n\u2022 Obviously, when s is finite, the bound for Fs, which is of order O( 1 T 1 s\n\u221a 1 N ), is more preferred over the\naforementioned O( 1\u221a N ) bound, as it asymptotically decreases with increasing number of tasks.\n\u2022 When s = \u03c1\u2217, R\u0302(F\u03c1\u2217) \u2264 2 T \u221a N\n\u221a 2eR logT . Here we achieve a bound of order O( \u221a log T T ), which decreases\nfaster with increasing T compared to the bound, when s > \u03c1\u2217.\n\u2022 When s = 1, R\u0302(F1) \u2264 2 T \u221a N\n\u221a 2R logT . While being of order O( \u221a log T T ), it features a smaller constant\ncompared to the bound of R\u0302(F\u03c1\u2217). In fact, due to the monotonicity of the bound that is given in (11), the tightest bound is obtained when s = 1.\nIn the next section, we derive and analyze the generalization bound by letting \u03c6 to be learned during the training phase."}, {"heading": "3 Learning the Feature Mapping", "text": "In this section, we consider the selection of the feature mapping \u03c6 during training via an MKL approach. In particular, we will assume that \u03c6 = ( \u221a \u03b81\u03c61, \u00b7 \u00b7 \u00b7 , \u221a \u03b8M\u03c6M ) \u2208 H1 \u00d7 \u00b7 \u00b7 \u00b7 \u00d7 HM , where each \u03c6m : X 7\u2192 Hm is selected before training."}, {"heading": "3.1 Theoretical Results", "text": "Consider the following HS\nFs,r , {x 7\u2192 [\u3008w1, \u03c6(x)\u3009, \u00b7 \u00b7 \u00b7 , \u3008wT , \u03c6(x)\u3009]\u2032 : \u2016wt\u20162 \u2264 \u03bb2tR,\u03bb \u2208 \u2126s(\u03bb), \u03c6 \u2208 \u2126r(\u03c6)} (12) where \u2126r(\u03c6) = {\u03c6 : \u03c6 = ( \u221a \u03b81\u03c61, \u00b7 \u00b7 \u00b7 , \u221a \u03b8M\u03c6M ), \u03b8 0, \u2016\u03b8\u2016r \u2264 1}. By following the same derivation procedure of Lemma 1, we can verify that (7) is also valid for Fs,r. Therefore, we only need to estimate its ERC. Similar to the previous section, we first give results regarding the monotonicity of R\u0302(Fs,r).\nLemma 3. Let \u03c3t , [\u03c3 1 t , \u00b7 \u00b7 \u00b7 , \u03c3Nt ]\u2032, umt , \u03c3 \u2032 tK m t \u03c3t, ut , [u 1 t , \u00b7 \u00b7 \u00b7 , uMt ]\u2032, vm , \u2211T t=1 \u03bbt\u03c3 \u2032 tK m t \u03b1t, v , [v1, \u00b7 \u00b7 \u00b7 , vM ]\u2032, where Kmt is the kernel matrix that contains elements km(xit,xjt ). Then \u2200s \u2265 1 and r \u2265 1,\nR\u0302(Fs,r) = 2\nTN\n\u221a RE\u03c3{ sup\n\u03b8\u2208\u2126r(\u03b8)\nT\u2211\nt=1\n(\u03b8\u2032ut) s\u2217 2 } 1s\u2217 = 2 TN E\u03c3{ sup \u03bb\u2208\u2126s(\u03bb),\u03b1\u2208\u2126(\u03b1) \u2016v\u2016r\u2217} (13)\nwhere \u2126r(\u03b8) , {\u03b8 : \u03b8 0, \u2016\u03b8\u2016r \u2264 1}, and \u2126(\u03b1) , {\u03b1t : \u03c3 \u2032 tK m t \u03b1t \u2264 R, \u2200t}.\nBased on Equation (13), we have the following result:\nTheorem 4. R\u0302(Fs,r) is monotonically increasing with respect to s.\nWe extend F\u0303 to a MT-MKL setting by letting \u03c6 \u2208 \u2126r(\u03c6), for \u03c6 in F\u0303 , which gives F\u0303r , {x 7\u2192 (\u3008w1, \u03c6(x)\u3009 , \u00b7 \u00b7 \u00b7 , \u3008wT , \u03c6(x)\u3009)\u2032 : \u2016wt\u20162 \u2264 R, \u03c6 \u2208 \u2126r(\u03c6)}. Then, Equation (13) leads to the following result:\nTheorem 5. R\u0302(F\u0303r) = R\u0302(F+\u221e,r) and, thus, F\u0303r is a special case of Fs,r.\nAgain, the above results imply that the tightest bound is obtained, when s = 1. In the following theorem, we provide an upper bound for R\u0302(Fs,r).\nTheorem 6. Let Fs,r be as defined in Equation (12). Assume that \u2200x \u2208 X , m = 1, \u00b7 \u00b7 \u00b7 ,M , km(x,x) = \u3008\u03c6m(x), \u03c6m(x)\u3009 \u2264 1. The ERC can be bounded as follows:\nR\u0302(Fs,r) \u2264 2\nT \u221a N\n\u221a\nRs\u2217T 2 s\u2217 Mmax{ 1 r\u2217 , 2 s\u2217 } (14)\nThe above theorem can be explicitly refined under the following two situations:\nCorollary 1. Under the conditions that are given in Theorem 6, we have\nR\u0302(Fs,r) \u2264 2\nT \u221a N\n\u221a\n\u03c4RT 2 s\u2217 M 1 r\u2217 if r\u2217 \u2264 logT\nR\u0302(Fs,r) \u2264 2\nT \u221a N\n\u221a\n\u03c4RT 2 s\u2217 M 2 \u03c4 if r\u2217 \u2265 logMT\n(15)\n\u2200s \u2265 1, where \u03c4 , (max {s, \u03c1\u2217})\u2217, and\n\u03c1 ,\n{ 2 lnT, r\u2217 \u2264 ln T\n2 lnMT, r\u2217 \u2265 lnMT (16)"}, {"heading": "3.2 Analysis", "text": "Once again, it is worth commenting on the results given in Theorem 6 and Corollary 1:\n\u2022 Generally, \u2200s \u2265 1, (15) gives a bound of order O( 1 T 1 s ). Obviously, s \u2192 +\u221e is least preferred, since its bound does not decrease with increasing number of tasks. Moreover, based on (14), \u2200r \u2265 1, R\u0302(F1,r)\u2019s bound is of order O( \u221a M 1 r\u2217 ). Compared to the O( \u221a M 1 r\u2217 min(\u2308logM\u2309, \u2308r\u2217\u2309)) bound of single-task\nMKL scenario, which is examined in [15], our bound for MT-MKL is tighter, for almost all M , when r is small, which is usually a preferred setting.\n\u2022 When r\u2217 \u2265 logMT , the bound given in (15) is monotonically increasing with respect to s. When s = \u03c1\u2217, we have R\u0302(F\u03c1\u2217,r) \u2264 2\nT \u221a N\n\u221a 2eR logMT . This gives a O( \u221a logMT T ) bound. Note that it is\nproved that the best bound that can be obtained in single-task multiple kernel classification is of order O( \u221a logM) [6]. Obviously, this logarithmic bound is preserved in the MT-MKL context. When s\nfurther decreases to 1, we have R\u0302(F1,r) \u2264 2 T \u221a N\n\u221a\n2RM 1 log MT logMT . Since M 1 log MT can never be\nlarger than e, this bound is even tighter than the one obtained, when s = \u03c1\u2217.\n\u2022 When r\u2217 \u2264 logT , the bound that is given in (15) is monotonically increasing with respect to s. When\ns = \u03c1\u2217, we have R\u0302(F\u03c1\u2217,r) \u2264 2 T \u221a N\n\u221a\n2eRM 1 r\u2217 logT . This gives a O(\n\u221a\nM 1 r\u2217 log T T ) bound. When s further\ndecreases to 1, we have R\u0302(F1,r) \u2264 2 T \u221a N\n\u221a\n2RM 1 r\u2217 log T . As we can see, it further decreases the bound\nby a constant factor e.\n\u2022 Compared to the optimum bounds that are given in the previous two situations, i.e., r\u2217 \u2265 logMT and r\u2217 \u2264 logT , we can see that, when r\u2217 \u2265 logMT , we achieve a better bound with respect to M , i.e., O( \u221a logM) versus O( \u221a M 1 r\u2217 ). On the other hand, with regards to T , even though we get a O( \u221a log T T\n) bound in both cases, the case of r\u2217 \u2264 logT features a lower constant factor. To summarize, MT-MKL not only preserves the optimal O( \u221a logM) bound encountered in single-task\nMKL, but also preserves the optimal O( \u221a log T T\n) bound encountered in the single-kernel MTL case, which was given in the previous section."}, {"heading": "4 Discussion", "text": ""}, {"heading": "4.1 Relation to Group-Lasso type regularizer", "text": "In the next theorem, we show the relation between our HS and the one that is based on Group-Lasso type regularizer.\nTheorem 7. The HS Fs is equivalent to\nFGLs , {x 7\u2192 [\u3008w1, \u03c6(x)\u3009, \u00b7 \u00b7 \u00b7 , \u3008wT , \u03c6(x)\u3009]\u2032 : ( T\u2211\nt=1\n\u2016wt\u2016s) 2 s \u2264 R} (17)\nSimilarly, Fs,r is equivalent to\nFGLs,r , {x 7\u2192 [\u3008w1, \u03c6\u0303(x)\u3009, \u00b7 \u00b7 \u00b7 , \u3008wT , \u03c6\u0303(x)\u3009]\u2032 : ( T\u2211\nt=1\n\u2016wt\u2016s) 2 s \u2264 R, \u03b8 \u2208 \u2126r(\u03b8)} (18)\nwhere \u2016wt\u20162 = \u2211M m=1 \u2016wmt \u20162 \u03b8m , \u03c6\u0303 = (\u03c61, \u00b7 \u00b7 \u00b7 , \u03c6M ), \u2126r(\u03b8) = {\u03b8 : \u03b8 0, \u2016\u03b8\u2016r \u2264 1}.\nObviously, by employing the Group-Lasso type regularizer, one can obtain the HSs that are proposed in previous sections. Below is a Regularization-Loss framework based on this regularizer with pre-selected kernel:\nmin w1,\u00b7\u00b7\u00b7 ,wT (\nT\u2211\nt=1\n\u2016wt\u2016s) 2 s + C\n\u2211\ni,t\nL(\u3008wt, \u03c6(xit)\u3009, yit) (19)\nThe MKL-based model can be similarly defined."}, {"heading": "4.2 Other related works", "text": "There has been substantial efforts put on the research of kernel-based MTL and also MT-MKL. We in this subsection discuss four closely related papers, and emphasize the difference between this paper and these works.\nFirst, we consider [1] and [24]. Both of these two papers consider Group-Lasso type regularizer to achieve different level of sparsity. Specifically, [1] utilized the regularizer\n(\nn\u2211\nj=1\n(\nnj\u2211\nk=1\n\u2016wjk\u2016)s) 2 s , s \u2265 2 (20)\nwhere l1 norm regularization is applied to the weights of each of the n groups (i.e.the inner summation), and the group-wise regularization is achieved via ls norm regularizer. It is hoped that by utilizing this regularizer, one can achieve inner-group sparsity and group-wise non-sparsity. This regularizer can be applied to MT-MKL, by letting wjk to be w m t , which yields the regularizer\n(\nT\u2211\nt=1\n(\nM\u2211\nm=1\n\u2016wmt \u2016)s) 2 s , s \u2265 2 (21)\nThis is similar to the one that appeared in FGLs,r . However, the major difference between our regularizer and (21) is that, in FGLs,r , instead of applying an l1 norm to the inner summation, we used \u2211M m=1 \u2016wmt \u20162 \u03b8m\n, where \u03b8m has a feasible region that is parametrized by r. Therefore, our regularizer encompasses MT-MKL with common kernel function, which is learned during training, while (21) does not.\nIn [24], the authors considered\nM\u2211\nm=1\n( T\u2211\nt=1\n\u2016wmt \u2016q) p q , 0 \u2264 p \u2264 1, q \u2265 1 (22)\nBy applying the lp (pseudo-)norm, the authors intended to achieve sparsity over the outer summation, while variable sparsity is obtained for the inner summation, due to the lq norm. The major difference between (22) and FGLs,r are twofold. First, the order of the double summation is different, i.e., in (22), the wmt \u2019s that belong to the same RKHS is considered as a group, while FGLs,r treats each task as a group. Second, similar to the reason that is discussed above, (22) does not encompasses the MT-MKL with common kernel function, which is learned during the training phase.\nIn the following, we discuss the difference between our work and the two theoretical works, [22] and [13], which derived generalization bound of the HSs that are similar to ours. In [22], the authors consider the regularizer\n\u2016w\u2016M , inf{ \u2211\nM\u2208M \u2016vM\u2016 : vM \u2208 H,\n\u2211\nM\u2208M MvM = w} (23)\nwhere M is an almost countable set of symmetric bounded linear operators on H. This general form covers several regularizers, such as Lasso, Group-Lasso, weighted Group-Lasso, etc. A key observation is that, in order for a specific regularizer to be covered by this general expression, the regularizer needs to be either summation of several norms, or the infimum of such a summation over a feasible region. For our regularizer ( \u2211T\nt=1 \u2016wt\u2016s) 2 s , obviously, it is not summation of norms (note the power outside the summation). Also, it is not immediately clear, if it can be represented by an infimum, which we just mentioned. Therefore, it appears that there is no succinct way to represent our regularizer as a special case of (23) and the same seems to be the case for our MT-MKL regularizer.\nAlso, for our HSs, it is clear how the generalization bounds relate to the number of tasks T and number of kernels M , in Fs and Fs,r, and under which circumstances the logarithmic bound can be achieved. This observation may be hard to obtain from the bound that is derived in (23), even though one may view our regularizers as special cases of (23).\nIn [13], the authors derived generalization bound for regularization-based MTL models, with regularizer \u2016W \u2016r,p , \u2016(\u2016w1\u2016r, \u00b7 \u00b7 \u00b7 , \u2016wn\u2016r)\u2016p. However, their work assumes W \u2208 Rm\u00d7n, while we assume our wt\u2019s be vectors of a potentially infinite-dimensional Hilbert space. Also, such group norm does not generalize our MT-MKL regularizer, therefore their bound cannot be applied to our HS, even if their results were to be extended to infinite-dimensional vector spaces."}, {"heading": "5 Experiments", "text": "In this section, we investigate via experimentation the generalization bounds of our HSs. We first evaluate the discrepancy between the ERC of Fs, Fs,r and their bounds. We show experimentally that the bound gives a good estimate of the relevant ERC. Then, we consider a new SVM-based MTL model that uses Fs as its HS. The model is subsequently extended to allow for MT-MKL by using Fs,r as its HS."}, {"heading": "5.1 ERC Bound Evaluation", "text": "For Fs, given a data set and a pre-selected kernel function, we can calculate its kernel matrices Kt, t = 1, \u00b7 \u00b7 \u00b7 , T . Then, the ERC is given by Equation (10). In order to approximate the expectation E\u03c3{\u2016u\u2016s\u2217}, we resort to Monte Carlo simulation by drawing a large number, D, of i.i.d samples for the \u03c3t\u2019s from a uniform distribution on the hyper-cube {\u22121, 1}N . Subsequently, for each sample we evaluate the argument of the expectation and average the results. For Fs,r, the ERC is calculated as in the first equation of (13). For each of the D samples of \u03c3t, we can calculate the corresponding ut. Then, we solve the maximization problem by using CVX [11, 12]. Finally, we calculate the average of the D values to approximate the ERC. For the experiment related to Fs,r, we only considered the case, when s \u2265 2. Under these circumstances, the maximization problem in (13) is concave and can be easily solved, unlike the case, when s \u2208 [1, 2).\nWe used the Letter data set 1 for this set of experiments. It is a collection of handwritten words compiled by Rob Kassel of the MIT Spoken Language Systems Group. The associated MTL problem involves 8 tasks, each of which is a binary classification problem for handwritten letters. The 8 tasks are: \u2018C\u2019 vs. \u2018E\u2019, \u2018G\u2019 vs. \u2018Y\u2019, \u2018M\u2019 vs. \u2018N\u2019, \u2018A\u2019 vs. \u2018G\u2019, \u2018I\u2019 vs. \u2018J\u2019, \u2018A\u2019 vs. \u2018O\u2019, \u2018F\u2019 vs. \u2018T\u2019 and \u2018H\u2019 vs. \u2018N\u2019. Each letter is represented by a 8\u00d7 16 pixel image, which forms a 128-dimensional feature vector. We chose 100 samples for each letter, and set D = 104. To calculate the kernel matrix, we used a Gaussian kernel with spread parameter 27 for Fs, and 9 different Gaussian kernels with spreads {2\u22127, 2\u22125, 2\u22123, 2\u22121, 20, 21, 23, 25, 27} for Fs,r. Finally, R was set to 1.\nThe experimental results are shown in Figure 1. In both sub-figures, it is obvious that both our bound and the real ERC are monotonically increasing. For Fs, it can be seen that the bound is tight everywhere.\n1Available at: http://www.cis.upenn.edu/~taskar/ocr/\nFor Fs,r, even though the difference between our bound and the Monte Carlo estimated ERC becomes larger when s grows, the bound is still tight for small s. This experiment shows a good match between the real ERC and our bound, which verifies our theoretical analysis in Section 2 and Section 3."}, {"heading": "5.2 SVM-based Model", "text": "In this subsection we present a new SVM-based model which reflects our proposed HS. For training data {xit, yit} \u2208 X \u00d7{\u22121, 1}, i = 1, \u00b7 \u00b7 \u00b7 , Nt, t = 1, \u00b7 \u00b7 \u00b7 , T and fixed feature mapping \u03c6 : X 7\u2192 H, our model is given as follows:\nmin w,\u03be,b (\nT\u2211\nt=1\n( \u2016wt\u20162\n2 )\ns 2 ) 2 s + C\nT,Nt\u2211\nt,i=1\n\u03beit\ns.t.yit( \u2329 wt, \u03c6(x i t) \u232a + bt) \u2265 1\u2212 \u03beit , \u03beit \u2265 0, \u2200i, t\n(24)\nObviously, Fs is the HS of (24). Such minimization problem can be solved as follows. First, note that when 1 \u2264 s \u2264 2, the problem is equivalent to\nmin w,\u03be,b,\u03bb\nT\u2211\nt=1\n\u2016wt\u20162 2\u03bbt + C\nT,Nt\u2211\nt,i=1\n\u03beit\ns.t.yit( \u2329 wt, \u03c6(x i t) \u232a + bt) \u2265 1\u2212 \u03beit, \u03beit \u2265 0, \u2200i, t\n\u03bb 0, \u2016\u03bb\u2016 s 2\u2212s \u2264 1\n(25)\nwhich can be easily solved via block coordinate descent method, with {w, \u03be, b} as a group and \u03bb as another. When s > 2, (24) is equivalent to\nmin w,\u03be,b max \u03bb\nT\u2211\nt=1\n\u03bbt\u2016wt\u20162 2 + C\nT,Nt\u2211\nt,i=1\n\u03beit\ns.t.yit( \u2329 wt, \u03c6(x i t) \u232a + bt) \u2265 1\u2212 \u03beit , \u03beit \u2265 0, \u2200i, t\n\u03bb 0, \u2016\u03bb\u2016 s s\u22122 \u2264 1\n(26)\nSince it is a convex-concave min-max problem with compact feasible region, the order of min and max can be interchanged [25], which gives the objective function\nmax \u03bb min w,\u03be,b\nT\u2211\nt=1\n\u03bbt( \u2016wt\u20162\n2 +\nC\n\u03bbt\nNt\u2211\ni=1\n\u03beit) (27)\nCalculating the dual form of the inner SVM problem gives the following maximization problem:\nmax \u03b1,\u03bb\nT\u2211\nt=1\n\u03bbt(\u03b1 \u2032 t1\u2212\n1 2 \u03b1\u2032tY tKtY t\u03b1t)\ns.t.0 \u03b1t C \u03bbt 1, \u03b1\u2032tyt = 0, \u2200t\n\u03bb 0, \u2016\u03bb\u2016 s s\u22122 \u2264 1\n(28)\nwhere Y t , diag([y 1 t , \u00b7 \u00b7 \u00b7 , yNtt ]\u2032) and Kt is the kernel matrix that is calculated based on the training data from the t-th task. Group coordinate descent can be utilized to solve (28), with \u03bb as a group and \u03b1 as another group.\nThe model can be extended so that it can accommodate MKL as follows:\nmin wt,\u03bet,bt,\u03b8 (\nT\u2211\nt=1\n(\nM\u2211\nm=1\n\u2016wmt \u20162 2\u03b8m ) s 2 ) 2 s + C\nT,Nt\u2211\nt,i=1\n\u03beit\ns.t.yit( \u2329 wt, \u03c6(x i t) \u232a + bt) \u2265 1\u2212 \u03beit, \u03beit \u2265 0, \u2200i, t\n\u03b8 0, \u2016\u03b8\u2016r \u2264 1\n(29)\nwhere \u03c6 = (\u03c61, \u00b7 \u00b7 \u00b7 , \u03c6M ). Obviously, its HS is Fs,r. This model can be solved via the similar strategy of solving (24). The only situation that needs a different algorithm is the case when s > 2, where (29) will be transformed to\nmin \u03b8 max \u03b1,\u03bb\nT\u2211\nt=1\n\u03bbt(\u03b1 \u2032 t1\u2212\n1 2 \u03b1\u2032tY t(\nM\u2211\nm=1\n\u03b8mK m t )Y t\u03b1t)\ns.t.0 \u03b1t C \u03bbt 1, \u03b1\u2032tyt = 0, \u2200t\n\u03bb 0, \u2016\u03bb\u2016 s s\u22122 \u2264 1 \u03b8 0, \u2016\u03b8\u2016r \u2264 1\n(30)\nThis min-max problem cannot be solved via group coordinate descent. Instead, we use the Exact Penalty Function method to solve it. We omit the details of this method and refer the readers to [27], since it is not the focus of this paper."}, {"heading": "5.3 Experimental Results on the SVM-based model", "text": "We performed our experiments on two well-known and frequently-used multi-task data sets, namely Letter and Landmine, and two handwritten digit data sets, namely MNIST and USPS. The Letter data set was described in the previous sub-section. Due to the large size of the original Letter data set, we randomly sampled 200 points for each letter to construct a training set. One exception is the letter j, as it contains only 189 samples in total. The Landmine data set2 consists of 29 binary classification tasks. Each datum is a 9-dimensional feature vector extracted from radar images that capture a single region of landmine fields. Tasks 1 \u2212 15 correspond to regions that are relatively highly foliated, while the other 14 tasks correspond to regions that are bare earth or desert. The tasks entail different amounts of data, varying from 30 to 96 samples. The goal is to detect landmines in specific regions.\n2Available at: http://people.ee.duke.edu/~lcarin/LandmineData.zip\nRegarding the MNIST 3 and USPS 4 data sets, each of the two are grayscale images containing handwritten digits from 0 to 9 with 784 and 256 features respectively. As was the case with the Letter data set, due to the large size of the original data set, we randomly sampled 100 data from each digit population to form a training set consisting of 1000 samples in total. To simulate the MTL scenario, we split the data into 45 binary classification tasks by applying a one-versus-one strategy. The classification accuracy was then calculated as the average of classification accuracies over all tasks.\nFor all our experiments, the training set size was set to 10% of the available data. We did not choose large training sets, since, as we can see from the generalization bound in (11), (14) and (15), when N is large, the effect of s becomes minor. For MT-MKL, we chose the 9 Gaussian kernels that were introduced in Section 5.1, as well as a linear and a 2nd-order polynomial kernel. For the single kernel case, we selected the optimal kernel from these 11 kernel function candidates via cross-validation. SVM\u2019s regularization parameter C was selected from the set {1/81, 1/27, 1/9, 1/3, 1, 3, 9, 27, 81}. In the MT-MKL case, the norm parameter r for \u03b8 was set to 1 to induce sparsity on \u03b8. We varied s from 1 to 100, and reported the best average classification accuracy over 20 runs. For s > 100, the results are almost always the same as that when s = 100, therefore we did not report these results. In fact, as show below, the model performance deteriorates quickly when s > 2, and changes very few when s > 10. The experimental results are given in Figure 2.\nIt can be seen that, the classification accuracy is roughly monotonically decreasing with respect to s, and the performance deteriorates significantly when s > 2. In many situations, the best performance is achieved, when s = 1. This result supports our theoretical analysis that the lowest generalization bound is obtained when s = 1. On the other hand, in some situations, such as the cases which consider the USPS data set in a single kernel setting, and the Letter data set in multiple kernel setting, the optimum model is not obtained when s = 1. This seems contradictory to our previously stated claims. However, this phenomenon can be explained similarly to the discussion in Section 5.1 of [15], which we summarize here: Obviously, for different s, the optimal solution (ft\u2019s) may be different. To get the optimal solution, we need to tune the \u201csize\u201d of the HS, such that the optimum ft\u2019s are contained in the HS. This implies that the size of the HS, which is parametrized by R, could be different for different s, instead of being fixed as discussed in previous sections. It is possible that the HS size (thus R) is very small, when s 6= 1. In this scenario, the lowest bound could be obtained when s 6= 1. For a more detailed discussion, we refer the reader to Section 5.1 in [15]. Finally, it is interesting to see how the performance deteriorates when s becomes large. The reason for the bad performance is as follows. Observe that the regularizer is the l s\n2 norm of the T SVM regularizers. Consider\n3Available at: http://yann.lecun.com/exdb/mnist/ 4Available at: http://www.cs.nyu.edu/~roweis/data.html\nthe extreme case, when s \u2192 \u221e, the l s 2 norm becomes the l\u221e norm, which is maxt{ \u2016wt\u2016 2 2 }. In this scenario, the regularizer of the model is only the one which has the smallest margin, while the regularizers of other tasks are ignored. Therefore, it is not a surprise that the performance of the other tasks is bad, which leads to low average classification accuracy. For large s value, even though it is not infinity, the bad result can be similarly analyzed."}, {"heading": "6 Conclusions", "text": "In this paper, we proposed a Multi-Task Learning (MTL) Hypothesis Space (HS) Fs involving T discriminative functions parametrized by weights wt. The weights are controlled by norm-ball constraints, whose radii are variable and estimated during the training phase. It extends an HS F\u0303 that has been previously investigated in the literature, where the radii are pre-determined. It is shown that the latter space is a special case of Fs, when s \u2192 +\u221e. We derived and analyzed the generalization bound of Fs and have shown that the bound is monotonically increasing with respect to s. Also, in the optimal case (s = 1), a bound of order O( \u221a log T T\n) is achieved. We further extended the HS to Fs,r, which is suitable for Multi-Task Multiple Kernel Learning (MT-MKL). Similar results were obtained, including a bound that is monotonically increasing with s and an optimal bound of order O( \u221a logMT T\n), when s = 1. The experimental results shown that our Empirical Rademacher Complexity (ERC) bound is tight and matches the real ERC very well. We then demonstrated the relation between our HS and the Group-Lasso type regularizer, and a Support Vector Machine (SVM)-based model was proposed with HS Fs, that was further extended to handle MT-MKL by using the HS Fs,r. The experimental results on multi-task classification data sets showed that the classification accuracy is monotonically decreasing with respect to s, and the optimal results for most experiments are indeed achieved, when s = 1, as indicated by our analysis. The presence of results that, contrary to our analysis, are optimal, when s 6= 1, can be justified similarly to Section 5.1 in [15]."}, {"heading": "Acknowledgments", "text": "C. Li acknowledges partial support from National Science Foundation (NSF) grant No. 0806931. Moreover, M. Georgiopoulos acknowledges partial support from NSF grants No. 0525429, No. 0963146, No. 1200566 and No. 1161228. Finally, G. C. Anagnostopoulos acknowledges partial support from NSF grants No. 0717674 and No. 0647018. Any opinions, findings, and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of the NSF."}, {"heading": "7 Appendix", "text": ""}, {"heading": "7.1 Preliminaries", "text": "In this subsection, we provide two results that will be used in the following subsections.\nLemma 4. Let p \u2265 1, x,a \u2208 Rn such that a 0 and a 6= 0. Then,\nmax x\u2208\u2126(x)\na\u2032x = \u2016a\u2016p (31)\nwhere \u2126(x) , {x : \u2016x\u2016p\u2217 \u2264 1}.\nThis lemma can be simply proved by utilizing Lagrangian multiplier method with respect to the maximization problem.\nLemma 5. Let x1, \u00b7 \u00b7 \u00b7 ,xn \u2208 H, then we have that\nE\u03c3\u2016 n\u2211\ni=1\n\u03c3ixi\u2016p \u2264 (p n\u2211\ni=1\n\u2016xi\u20162) p 2 (32)\nfor any p \u2265 1, where \u03c3i\u2019s are the Rademacher-distributed random variables.\nFor 1 \u2264 p < 2, the above result can be simply proved using Lyapunov\u2019s inequality. When p \u2265 2, the lemma can be proved by using Proposition 3.3.1 and 3.4.1 in [17]."}, {"heading": "7.2 Proof to Lemma 2", "text": "Proof. First notice that Fs is equivalent to the following HS:\nFs , {x 7\u2192 (\u03bb1 \u3008w1, \u03c6(x)\u3009 , \u00b7 \u00b7 \u00b7 , \u03bbT \u3008wT , \u03c6(x)\u3009)\u2032 : \u2016wt\u20162 \u2264 R,\u03bb \u2208 \u2126s(\u03bb)} (33)\nAccording to the same reasoning of Equations (1) and (2) in [6], we know that wt = \u2211N i=1 \u03b1 i t\u03c6(x i t), and the constraint \u2016wt\u20162 \u2264 R is equivalent to \u03b1 \u2032\ntKt\u03b1t \u2264 R. Therefore, based on the definition of ERC that is given in Equation (8), we have that\nR\u0302(Fs) = 2\nTN E\u03c3{ sup\n\u03b1t\u2208Fs\nT\u2211\nt=1\n\u03bbt\u03c3 \u2032 tKt\u03b1t} (34)\nwhere Fs = {\u03b1t | \u03b1 \u2032 tKt\u03b1t \u2264 \u03bb2tR, \u2200t;\u03bb \u2208 \u2126s(\u03bb)}. To solve the maximization problem with respect to \u03b1t, we observe that the T problems are independent and thus can be solved individually. Based on Cauchy-Schwartz inequality, the optimal \u03b1t is achieved when K 1 2 t \u03b1t = ctK 1 2\nt \u03c3t where ct is a constant. Substituting this result into each of the T maximization problems, we have the following:\nmax ct\nct\u03c3 \u2032 tKt\u03c3t\ns.t. c2t\u03c3 \u2032 tKt\u03c3t \u2264 R (35)\nObviously, the optimal ct is obtained when ct = \u221a R\n\u03c3 \u2032 tKt\u03c3t . Therefore the ERC becomes now\nR\u0302(Fs) = 2\nTN E\u03c3{ sup\n\u03bb\u2208\u2126s(\u03bb)\nT\u2211\nt=1\n\u03bbt\n\u221a\n\u03c3 \u2032 tKt\u03c3tR} (36)\nSince s \u2265 1, based on Lemma 4, it is not difficult to get the solution of the maximization problem with respect to \u03bb, which gives\nR\u0302(Fs) = 2 \u221a R\nTN E\u03c3{[\nT\u2211\nt=1\n(\u03c3 \u2032 tKt\u03c3t) s\u2217 2 ] 1 s\u2217 }\n= 2 \u221a R\nTN E\u03c3{\u2016u\u2016s\u2217}\n(37)"}, {"heading": "7.3 Proof to Theorem 1", "text": "Proof. First note that \u2200s1 > s2 \u2265 1, we have that 1 \u2264 s\u22171 < s\u22172, which means \u2016u\u2016s\u2217 1 \u2265 \u2016u\u2016s\u2217 2 . Based on Equation (37), we immediately have R\u0302(Fs1) \u2265 R\u0302(Fs2). This gives the monotonicity of R\u0302(Fs) with respect to s."}, {"heading": "7.4 Proof to Theorem 2", "text": "Proof. Similar to the proof to Lemma 2, we write the ERC of F\u0303 :\nR\u0302(F\u0303) = 2 TN\nE\u03c3{ sup \u03b1t\u2208F\u0303\nT\u2211\nt=1\n\u03c3 \u2032 tKt\u03b1t} (38)\nOptimize with respect to \u03b1t gives\nR\u0302(F\u0303) = 2 \u221a R\nTN E\u03c3{\nT\u2211\nt=1\n\u221a\n\u03c3 \u2032 tKt\u03c3t} (39)\nBased on Lemma 2, we immediately obtain R\u0302(F\u0303) = R\u0302(F+\u221e)."}, {"heading": "7.5 Proof to Theorem 3", "text": "Proof. According to Equation (37) and Jensen\u2019s Inequality, we have\nR\u0302(Fs) \u2264 2 \u221a R\nTN (\nT\u2211\nt=1\nE\u03c3{(\u03c3 \u2032 tKt\u03c3t) s\u2217 2 }) 1s\u2217\n= 2 \u221a R\nTN (\nT\u2211\nt=1\nE\u03c3{\u2016 N\u2211\ni=1\n\u03c3it\u03c6(x i t)\u2016s\n\u2217}) 1s\u2217 (40)\nBased on Lemma 5, we have that\nR\u0302(Fs) \u2264 2 \u221a R\nTN (\nT\u2211\nt=1\n(s\u2217tr(Kt)) s\u2217 2 ) 1 s\u2217\n= 2\nTN\n\u221a\nRs\u2217\u2016tr(Kt)Tt=1\u2016 s\u2217 2\n(41)\nwhere \u2016tr(Kt)Tt=1\u2016 s\u2217 2 denotes the l s\u2217 2 -norm of vector [tr(K1), \u00b7 \u00b7 \u00b7 , tr(KT )]\u2032. Since we assumed that k(x,x) \u2264 1, \u2200x, we have\nR\u0302(Fs) \u2264 2\nTN\n\u221a \u221a \u221a \u221aRs\u2217( T\u2211\nt=1\nN s\u2217 2 ) 2 s\u2217\n= 2\nT \u221a N\n\u221a\nRT 2 s\u2217 s\u2217\n(42)\nNote that this bound can be further improved for the interval s \u2208 [1, \u03c1\u2217]. To make this improvement, we first prove that R\u0302(Fs) \u2264 T 1 s\u2032 \u2212 1 s R\u0302(Fs\u2032) for any s\u2032 \u2265 s \u2265 1.\nR\u0302(Fs) = 2\nTN E\u03c3{ sup\n\u03bb 0,\u2016\u03bb\u2016s\u22641\nT\u2211\nt=1\n\u03bbt\n\u221a\n\u03c3 \u2032 tKt\u03c3tR}\n\u2264 2 TN\nE\u03c3{ sup \u03bb 0,\u2016\u03bb\u2016s\u2032\u2264T 1 s\u2032 \u2212 1 s\nT\u2211\nt=1\n\u03bbt\n\u221a\n\u03c3 \u2032 tKt\u03c3tR}\n= 2\nTN E\u03c3{ sup\n\u03bb 0,\u2016\u03bb\u2016s\u2032\u22641\nT\u2211\nt=1\nT 1 s\u2032 \u2212 1\ns\u03bbt\n\u221a\n\u03c3 \u2032 tKt\u03c3tR}\n= T 1 s\u2032 \u2212 1 s R\u0302(Fs\u2032)\n(43)\nBased on this conclusion, we have that \u2200s \u2208 [1, \u03c1\u2217],\nR\u0302(Fs) \u2264 T 1 \u03c1\u2217 \u2212 1 s R\u0302(F\u03c1\u2217)\n= T 1 \u03c1\u2217 \u2212 1 s\n2\nTN\n\u221a\n2eRN logT\n= T 1 \u03c1\u2217 \u22121+1\u2212 1 s\n2\nTN\n\u221a\n2eRN logT\n= T\n1 s\u2217\nT 1 \u03c1\n2\nTN\n\u221a\n2eRN logT\n= T 1 s\u2217\u221a e 2 TN \u221a 2eRN logT\n= 2\nT \u221a N\n\u221a\nRT 2 s\u2217 \u03c1\n(44)\nNote that this is always less than 2 T \u221a N\n\u221a\nRT 2 s\u2217 s\u2217 that is given in (42); \u03c1\u2217 is the global minimizer of the\nexpression in (42) as a function of s. In summary, we have R\u0302(Fs) \u2264 2 T \u221a N\n\u221a\nRT 2 s\u2217 \u03c1 when s \u2208 [1, \u03c1\u2217], and\nR\u0302(Fs) \u2264 2 T \u221a N\n\u221a\nRT 2 s\u2217 s\u2217 when s > \u03c1\u2217."}, {"heading": "7.6 Proof to Lemma 3", "text": "Proof. Define Kt , \u2211M m=1 \u03b8mK m t , \u2200t, then we can write\nR\u0302(Fs,r) = 2\nTN E\u03c3{ sup\n\u03b1t\u2208Fs,r\nT\u2211\nt=1\n\u03bbt\u03c3 \u2032 tKt\u03b1t} (45)\nwhere Fs = {\u03b1t | \u03b1 \u2032 tKt\u03b1t \u2264 \u03bb2tR, \u2200t;\u03bb \u2208 \u2126s(\u03bb); \u03b8 \u2208 \u2126r(\u03b8)}. Then using the similar proof of Lemma 2, we have that\nR\u0302(Fs,r) = 2 \u221a R\nTN E\u03c3{ sup \u03b8\u2208\u2126r(\u03b8) [\nT\u2211\nt=1\n(\u03c3 \u2032 tKt\u03c3t) s\u2217 2 ] 1 s\u2217 }\n= 2 \u221a R\nTN E\u03c3{ sup\n\u03b8\u2208\u2126r(\u03b8)\nT\u2211\nt=1\n(\u03b8\u2032ut) s\u2217 2 } 1s\u2217 (46)\nThis gives the first equation in Equation (13). To prove the second equation, we simply optimize (46) with respect to \u03b8, which directly gives the result."}, {"heading": "7.7 Proof to Theorem 4", "text": "Proof. Consider Equation (13) and let g(\u03bb) , sup\u03b1\u2208\u2126(\u03b1) \u2016v\u2016r\u2217 . Then\nR\u0302(Fs,r) = 2\nTN E\u03c3{ sup \u03bb\u2208\u2126s(\u03bb) g(\u03bb)} (47)\nNote that \u22001 \u2264 s1 < s2, we have the relation \u2126s1(\u03bb) \u2286 \u2126s2(\u03bb). Therefore, let \u03bb\u03021, \u03bb\u03022 be the solution of problems sup\u03bb\u2208\u2126s1(\u03bb) g(\u03bb) and sup\u03bb\u2208\u2126s2(\u03bb) g(\u03bb) correspondingly, we must have g(\u03bb\u03021) \u2264 g(\u03bb\u03022). This directly implies R\u0302(Fs1,r) \u2264 R\u0302(Fs2,r)."}, {"heading": "7.8 Proof to Theorem 5", "text": "Proof. Define Kt , \u2211M m=1 \u03b8mK m t , \u2200t, then\nR\u0302(F\u0303r) = 2\nTN E\u03c3{ sup\n\u03b1t\u2208F\u0303\nT\u2211\nt=1\n\u03c3 \u2032 tKt\u03b1t} (48)\nFix \u03b8 and optimize with respect to \u03b1t gives\nR\u0302(F\u0303r) = 2\nTN\n\u221a RE\u03c3{ sup\n\u03b8\u2208\u2126r(\u03b8)\nT\u2211\nt=1\n\u221a\n\u03b8\u2032ut} (49)\nBased on Equation (13), we immediately obtain R\u0302(F\u0303r) = R\u0302(F+\u221e,r)."}, {"heading": "7.9 Proof to Theorem 6", "text": "Proof. Based on Equation (13) and Ho\u0308lder\u2019s Inequality, let c , max{0, 1 r\u2217 \u2212 2 s\u2217 } we have that\nR\u0302(Fs,r) \u2264 2\nTN\n\u221a RE\u03c3{ sup\n\u03b8\u2208\u2126r(\u03b8)\nT\u2211\nt=1\n(\u2016\u03b8\u2016r\u2016ut\u2016r\u2217) s\u2217 2 } 1s\u2217\n= 2\nTN\n\u221a RE\u03c3{ T\u2211\nt=1\n\u2016ut\u2016 s\u2217 2 r\u2217 } 1 s\u2217\n\u2264 2 TN\n\u221a RM cE\u03c3{ T\u2211\nt=1\n\u2016ut\u2016 s\u2217 2 s\u2217\n2\n} 1s\u2217\n(50)\nApplying Jensen\u2019s Inequality, we have that\nR\u0302(Fs,r) \u2264 2\nTN\n\u221a RM c( T,M \u2211\nt,m=1\nE\u03c3{(umt ) s\u2217 2 }) 1s\u2217\n= 2\nTN\n\u221a RM c( T,M \u2211\nt,m=1\nE\u03c3\u2016 N\u2211\ni=1\n\u03c3it\u03c6m(x i t)\u2016s\n\u2217 ) 1 s\u2217\n(51)\nUsing Lemma 5, we have that\nR\u0302(Fs,r) \u2264 2\nTN\n\u221a RM cs\u2217( T,M \u2211\nt,m=1\n(tr(Kmt )) s\u2217 2 ) 1 s\u2217 (52)\nSince we assume that km(x,x) \u2264 1, \u2200m,x, we have that\nR\u0302(Fs,r) \u2264 2\nT \u221a N\n\u221a\nRs\u2217T 2 s\u2217 Mmax{ 1 r\u2217 , 2 s\u2217 } (53)"}, {"heading": "7.10 Proof to Corollary 1", "text": "Proof. First, by following the same proof of R\u0302(Fs) \u2264 T 1 s\u2032 \u2212 1 s R\u0302(Fs\u2032) for any s\u2032 \u2265 s \u2265 1, we can directly obtain the conclusion that R\u0302(Fs,r) \u2264 T 1 s\u2032 \u2212 1\ns R\u0302(Fs\u2032,r) for any s\u2032 \u2265 s \u2265 1. When r\u2217 \u2264 logT and s \u2208 [1, \u03c1\u2217], where \u03c1 = 2 logT , we have that\nR\u0302(Fs,r) \u2264 T 1 \u03c1\u2217 \u2212 1 s R\u0302(F\u03c1\u2217,r)\n= 2T\n1 s\u2217\nT \u221a Ne\n\u221a\n2eRM 1 r\u2217 logT\n= 2\nT \u221a N\n\u221a\nRT 2 s\u2217 \u03c1M 1 r\u2217\n(54)\nWhen s > \u03c1\u2217, obviously, we have R\u0302(Fs,r) \u2264 2 T \u221a N\n\u221a\nRT 2 s\u2217 s\u2217M 1 r\u2217\nSimilarly, for r\u2217 \u2265 logMT and s \u2208 [1, \u03c1\u2217], where \u03c1 = 2 logMT , we have that\nR\u0302(Fs,r) \u2264 T 1 \u03c1\u2217 \u2212 1 s R\u0302(F\u03c1\u2217,r)\n= T\n1 s\u2217\n\u221a\nT 1 log MT\n2\nT \u221a N\n\u221a\n2Re logMT\n= 2\nT \u221a N\n\u221a\n2RT 2 s\u2217 M 1 log MT logMT\n= 2\nT \u221a N\n\u221a\nRT 2 s\u2217 \u03c1M 2 \u03c1\n(55)\nWhen s > \u03c1\u2217, obviously, we have R\u0302(Fs,r) \u2264 2 T \u221a N\n\u221a\nRT 2 s\u2217 s\u2217M 2 s\u2217"}, {"heading": "7.11 Proof to Theorem 7", "text": "Proof. We have already show that the ERC of Fs is\nR\u0302(Fs) = 2\nTN E\u03c3{sup\n\u03b1,\u03bb\nT\u2211\nt=1\n\u03c3\u2032tKt\u03b1t} (56)\nIt is not difficult to see that optimizing the following problem\nsup \u03b1,\u03bb\nT\u2211\nt=1\n\u03c3\u2032tKt\u03b1t\ns.t. \u03b1\u2032tKt\u03b1t \u2264 \u03bb2tR \u2016\u03bb\u2016s \u2264 1\n(57)\nwith respect to \u03b1t must achieves its optimum at the boundary, i.e., the optimal \u03b1t must satisfy \u03b1 \u2032 tK\u03b1t = \u03bb2tR. Therefore, Problem (57) can be re-written as\nsup \u03b1,\u03bb\nT\u2211\nt=1\n\u03c3\u2032tKt\u03b1t\ns.t. \u03b1\u2032tKt\u03b1t = \u03bb 2 tR\n\u2016\u03bb\u2016s \u2264 1\n(58)\nSubstituting the first constraint into the second one directly leads to the result. The proof regarding to Fs,r is similar, and therefore we omit it."}], "references": [{"title": "Variable sparsity kernel learning", "author": ["Jonathan Aflalo", "Aharon Ben-Tal", "Chiranjib Bhattacharyya", "Jagarlapudi Saketha Nath", "Sankaran Raman"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2011}, {"title": "Convex multi-task feature learning", "author": ["Andreas Argyriou", "Theodoros Evgeniou", "Massimiliano Pontil"], "venue": "Machine Learning,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2008}, {"title": "Universal multi-task kernels", "author": ["Andrea Caponnetto", "Charles A. Micchelli", "Massimiliano Pontil", "Yiming Ying"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2008}, {"title": "Multitask learning", "author": ["Rich Caruana"], "venue": "Machine Learning,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 1997}, {"title": "Integrating low-rank and group-sparse structures for robust multi-task learning", "author": ["Jianhui Chen", "Jiayu Zhou", "Jieping Ye"], "venue": "In KDD,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2011}, {"title": "Generalization bounds for learning kernels", "author": ["Corinna Cortes", "Mehryar Mohri", "Afshin Rostamizadeh"], "venue": "In ICML,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2010}, {"title": "Learning multiple tasks with kernel methods", "author": ["Theodoros Evgeniou", "Charles A. Micchelli", "Massimiliano Pontil"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2005}, {"title": "Structured feature selection and task relationship inference for multi-task learning", "author": ["Hongliang Fei", "Jun Huan"], "venue": "In ICDM,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2011}, {"title": "Multiple kernel learning algorithms", "author": ["Mehmet Gonen", "Ethem Alpaydin"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2011}, {"title": "Multi-stage multi-task feature learning", "author": ["Pinghua Gong", "Jieping Ye", "Changshui Zhang"], "venue": "In NIPS,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2012}, {"title": "Graph implementations for nonsmooth convex programs", "author": ["M. Grant", "S. Boyd"], "venue": "Recent Advances in Learning and Control, Lecture Notes in Control and Information Sciences,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2008}, {"title": "CVX: Matlab software for disciplined convex programming, version 1.21", "author": ["M. Grant", "S. Boyd"], "venue": null, "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2011}, {"title": "Regularization techniques for learning with matrices", "author": ["Sham M. Kakade", "Shai Shalev-Shwartz", "Ambuj Tewari"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2012}, {"title": "Learning with whom to share in multi-task feature learning", "author": ["Zhuoliang Kang", "Kristen Grauman", "Fei Sha"], "venue": "In ICML,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2011}, {"title": "lp-norm multiple kernel learning", "author": ["Marius Kloft", "Ulf Brefeld", "Soren Sonnenburg", "Alexander Zien"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2011}, {"title": "Marginal regression for multitask learning", "author": ["Mladen Kolar", "Han Liu"], "venue": "In NIPS,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2012}, {"title": "Random Series and Stochastic Integrals: Single and Multiple", "author": ["Stanislaw Kwapien", "Wojbor A. Woyczynski"], "venue": null, "citeRegEx": "17", "shortCiteRegEx": "17", "year": 1992}, {"title": "Learning the kernel matrix with semidefinite programming", "author": ["Gert R.G. Lanckriet", "Nello Cristianini", "Peter Bartlett", "Laurent El Ghaoui", "Michael I. Jordan"], "venue": "J. Mach. Learn. Res.,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2004}, {"title": "Multi-level lasso for sparse multi-task regression", "author": ["Aurelie C. Lozano", "Grzegorz Swirszcz"], "venue": "In NIPS,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2012}, {"title": "Bounds for linear multi-task learning", "author": ["Andreas Maurer"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2006}, {"title": "The rademacher complexity of linear transformation classes", "author": ["Andreas Maurer"], "venue": "In Gbor Lugosi and HansUlrich Simon, editors, Learning Theory, volume 4005 of Lecture Notes in Computer Science,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2006}, {"title": "Structured sparsity and generalization", "author": ["Andreas Maurer", "Massimiliano Pontil"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2012}, {"title": "Large margin multi-task metric learning", "author": ["Shibin Parameswaran", "Kilian Q. Weinberger"], "venue": "In NIPS,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2012}, {"title": "lp\u2212lq penalty for sparse linear and sparse multiple kernel multitask learning", "author": ["Alain Rakotomamonjy", "Remi Flamary", "Gilles Gasso", "Stephane Canu"], "venue": "IEEE Transactions on Neural Networks,", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2011}, {"title": "On general minimax theorems", "author": ["M. Sion"], "venue": "Pacific Journal of Mathematics,", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 1958}, {"title": "On multiple kernel learning with multiple labels", "author": ["Lei Tang", "Jianhui Chen", "Jieping Ye"], "venue": "In IJCAI,", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2009}, {"title": "Globally convergent methods for semi-infinite programming", "author": ["G.A. Watson"], "venue": "BIT Numerical Mathematics,", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 1981}, {"title": "Transfer metric learning by learning task relationships", "author": ["Yu Zhang", "Dit-Yan Yeung"], "venue": "In KDD,", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 2010}, {"title": "Convex multitask learning with flexible task clusters", "author": ["Leon wenliang Zhong", "James T. Kwok"], "venue": "In ICML,", "citeRegEx": "29", "shortCiteRegEx": "29", "year": 2012}], "referenceMentions": [{"referenceID": 3, "context": "1 Introduction Multi-Task Learning (MTL) has been an active research field for over a decade [4].", "startOffset": 93, "endOffset": 96}, {"referenceID": 1, "context": "MTL has been successfully applied in feature selection [2, 8, 10], regression [19, 16], metric learning [28][23], and kernel-based MTL [7, 3, 24, 1] among other applications.", "startOffset": 55, "endOffset": 65}, {"referenceID": 7, "context": "MTL has been successfully applied in feature selection [2, 8, 10], regression [19, 16], metric learning [28][23], and kernel-based MTL [7, 3, 24, 1] among other applications.", "startOffset": 55, "endOffset": 65}, {"referenceID": 9, "context": "MTL has been successfully applied in feature selection [2, 8, 10], regression [19, 16], metric learning [28][23], and kernel-based MTL [7, 3, 24, 1] among other applications.", "startOffset": 55, "endOffset": 65}, {"referenceID": 18, "context": "MTL has been successfully applied in feature selection [2, 8, 10], regression [19, 16], metric learning [28][23], and kernel-based MTL [7, 3, 24, 1] among other applications.", "startOffset": 78, "endOffset": 86}, {"referenceID": 15, "context": "MTL has been successfully applied in feature selection [2, 8, 10], regression [19, 16], metric learning [28][23], and kernel-based MTL [7, 3, 24, 1] among other applications.", "startOffset": 78, "endOffset": 86}, {"referenceID": 27, "context": "MTL has been successfully applied in feature selection [2, 8, 10], regression [19, 16], metric learning [28][23], and kernel-based MTL [7, 3, 24, 1] among other applications.", "startOffset": 104, "endOffset": 108}, {"referenceID": 22, "context": "MTL has been successfully applied in feature selection [2, 8, 10], regression [19, 16], metric learning [28][23], and kernel-based MTL [7, 3, 24, 1] among other applications.", "startOffset": 108, "endOffset": 112}, {"referenceID": 6, "context": "MTL has been successfully applied in feature selection [2, 8, 10], regression [19, 16], metric learning [28][23], and kernel-based MTL [7, 3, 24, 1] among other applications.", "startOffset": 135, "endOffset": 148}, {"referenceID": 2, "context": "MTL has been successfully applied in feature selection [2, 8, 10], regression [19, 16], metric learning [28][23], and kernel-based MTL [7, 3, 24, 1] among other applications.", "startOffset": 135, "endOffset": 148}, {"referenceID": 23, "context": "MTL has been successfully applied in feature selection [2, 8, 10], regression [19, 16], metric learning [28][23], and kernel-based MTL [7, 3, 24, 1] among other applications.", "startOffset": 135, "endOffset": 148}, {"referenceID": 0, "context": "MTL has been successfully applied in feature selection [2, 8, 10], regression [19, 16], metric learning [28][23], and kernel-based MTL [7, 3, 24, 1] among other applications.", "startOffset": 135, "endOffset": 148}, {"referenceID": 20, "context": "A theoretically well-studied MTL framework is regularized linear MTL model, whose generalization bound is studied in [21, 13, 22].", "startOffset": 117, "endOffset": 129}, {"referenceID": 12, "context": "A theoretically well-studied MTL framework is regularized linear MTL model, whose generalization bound is studied in [21, 13, 22].", "startOffset": 117, "endOffset": 129}, {"referenceID": 21, "context": "A theoretically well-studied MTL framework is regularized linear MTL model, whose generalization bound is studied in [21, 13, 22].", "startOffset": 117, "endOffset": 129}, {"referenceID": 4, "context": "For example, [5] looks for group sparsity of w, [29] discovers group structure of multiple tasks, and [8, 10] select features in a MTL context.", "startOffset": 13, "endOffset": 16}, {"referenceID": 28, "context": "For example, [5] looks for group sparsity of w, [29] discovers group structure of multiple tasks, and [8, 10] select features in a MTL context.", "startOffset": 48, "endOffset": 52}, {"referenceID": 7, "context": "For example, [5] looks for group sparsity of w, [29] discovers group structure of multiple tasks, and [8, 10] select features in a MTL context.", "startOffset": 102, "endOffset": 109}, {"referenceID": 9, "context": "For example, [5] looks for group sparsity of w, [29] discovers group structure of multiple tasks, and [8, 10] select features in a MTL context.", "startOffset": 102, "endOffset": 109}, {"referenceID": 1, "context": "Such an approach is followed in [2, 14].", "startOffset": 32, "endOffset": 39}, {"referenceID": 13, "context": "Such an approach is followed in [2, 14].", "startOffset": 32, "endOffset": 39}, {"referenceID": 25, "context": "One example of this technique is given in [26].", "startOffset": 42, "endOffset": 46}, {"referenceID": 19, "context": "One previous work which discussed the generalization bound of this method in a classification context is [20].", "startOffset": 105, "endOffset": 109}, {"referenceID": 19, "context": "Obviously, the HS that is considered in [20] does not cover this scenario, since it only allows the operator A to be linear operator, which is not the case when A = \u03c6.", "startOffset": 40, "endOffset": 44}, {"referenceID": 19, "context": "Obviously, the HS in [20] fails to cover this HS, due to the lack of the constraint \u03c6 \u2208 \u03a9(\u03c6), which indicates that the feature mapping \u03c6 (hence, its corresponding kernel function) is learned during the training phase instead of of being selected beforehand.", "startOffset": 21, "endOffset": 25}, {"referenceID": 17, "context": "We refer readers to [18] and a survey paper [9] for details on MKL.", "startOffset": 20, "endOffset": 24}, {"referenceID": 8, "context": "We refer readers to [18] and a survey paper [9] for details on MKL.", "startOffset": 44, "endOffset": 47}, {"referenceID": 20, "context": "By considering the generalization bound of Fs based on the Empirical Rademacher Complexity (ERC) [21], we first demonstrate that the ERC is monotonically increasing with s, which implies that the tightest bound is achieved, when s = 1.", "startOffset": 97, "endOffset": 101}, {"referenceID": 5, "context": "Additionally, if M kernel functions are involved, the bound is of order O( \u221a logM), which has been proved to be the best bound that can be obtained in single-task multi-kernel classification [6].", "startOffset": 191, "endOffset": 194}, {"referenceID": 0, "context": "The empirical error based on a surrogate loss function L\u0304 : R 7\u2192 [0, 1], which is a Lipschitz-continuous function that upper-bounds the 0/1 loss function, is defined as", "startOffset": 65, "endOffset": 71}, {"referenceID": 19, "context": "For the constraints on the wt\u2019s, instead of pre-defining a common radius R for all tasks as discussed in [20], we let \u2016wt\u2016 \u2264 \u03bbtR, where \u03bbt is learned during the training phase.", "startOffset": 105, "endOffset": 109}, {"referenceID": 0, "context": "Let L\u0304 : R 7\u2192 [0, 1] be a Lipschitz-continuous loss function with Lipschitz constant \u03b3 and upper-bound the 0/1 loss function 1(\u2212\u221e,0](\u00b7).", "startOffset": 14, "endOffset": 20}, {"referenceID": 20, "context": "where R\u0302(Fs) is the ERC for MTL problems defined in [21]:", "startOffset": 52, "endOffset": 56}, {"referenceID": 19, "context": "This lemma can be simply proved by utilizing Theorem 16 and 17 in [20].", "startOffset": 66, "endOffset": 70}, {"referenceID": 19, "context": "Define F\u0303 , {x 7\u2192 [\u3008w1, \u03c6(x)\u3009, \u00b7 \u00b7 \u00b7 , \u3008wT , \u03c6(x)\u3009]\u2032 : \u2016wt\u2016 \u2264 R}, which is the HS that is given in [20] under kernelized MTL setting, then F\u0303 is the HS with equal radius for each \u2016wt\u2016.", "startOffset": 99, "endOffset": 103}, {"referenceID": 19, "context": "Note that this bound matches the one that is given in [20].", "startOffset": 54, "endOffset": 58}, {"referenceID": 19, "context": "This is because of the following relation between F\u0303 and the HS of [20], F , that is introduced in Section 1: First, let the operator A in F be the identity operator, and then let x in F be an element of H, i.", "startOffset": 67, "endOffset": 71}, {"referenceID": 14, "context": "Compared to the O( \u221a M 1 r min(\u2308logM\u2309, \u2308r\u2217\u2309)) bound of single-task MKL scenario, which is examined in [15], our bound for MT-MKL is tighter, for almost all M , when r is small, which is usually a preferred setting.", "startOffset": 102, "endOffset": 106}, {"referenceID": 5, "context": "Note that it is proved that the best bound that can be obtained in single-task multiple kernel classification is of order O( \u221a logM) [6].", "startOffset": 133, "endOffset": 136}, {"referenceID": 0, "context": "First, we consider [1] and [24].", "startOffset": 19, "endOffset": 22}, {"referenceID": 23, "context": "First, we consider [1] and [24].", "startOffset": 27, "endOffset": 31}, {"referenceID": 0, "context": "Specifically, [1] utilized the regularizer", "startOffset": 14, "endOffset": 17}, {"referenceID": 23, "context": "In [24], the authors considered", "startOffset": 3, "endOffset": 7}, {"referenceID": 21, "context": "In the following, we discuss the difference between our work and the two theoretical works, [22] and [13], which derived generalization bound of the HSs that are similar to ours.", "startOffset": 92, "endOffset": 96}, {"referenceID": 12, "context": "In the following, we discuss the difference between our work and the two theoretical works, [22] and [13], which derived generalization bound of the HSs that are similar to ours.", "startOffset": 101, "endOffset": 105}, {"referenceID": 21, "context": "In [22], the authors consider the regularizer \u2016w\u2016M , inf{ \u2211", "startOffset": 3, "endOffset": 7}, {"referenceID": 12, "context": "In [13], the authors derived generalization bound for regularization-based MTL models, with regularizer \u2016W \u2016r,p , \u2016(\u2016w\u2016r, \u00b7 \u00b7 \u00b7 , \u2016w\u2016r)\u2016p.", "startOffset": 3, "endOffset": 7}, {"referenceID": 10, "context": "Then, we solve the maximization problem by using CVX [11, 12].", "startOffset": 53, "endOffset": 61}, {"referenceID": 11, "context": "Then, we solve the maximization problem by using CVX [11, 12].", "startOffset": 53, "endOffset": 61}, {"referenceID": 24, "context": "Since it is a convex-concave min-max problem with compact feasible region, the order of min and max can be interchanged [25], which gives the objective function", "startOffset": 120, "endOffset": 124}, {"referenceID": 26, "context": "We omit the details of this method and refer the readers to [27], since it is not the focus of this paper.", "startOffset": 60, "endOffset": 64}, {"referenceID": 14, "context": "1 of [15], which we summarize here: Obviously, for different s, the optimal solution (ft\u2019s) may be different.", "startOffset": 5, "endOffset": 9}, {"referenceID": 14, "context": "1 in [15].", "startOffset": 5, "endOffset": 9}, {"referenceID": 14, "context": "1 in [15].", "startOffset": 5, "endOffset": 9}], "year": 2013, "abstractText": "This paper presents a RKHS, in general, of vector-valued functions intended to be used as hypothesis space for multi-task classification. It extends similar hypothesis spaces that have previously considered in the literature. Assuming this space, an improved Empirical Rademacher Complexity-based generalization bound is derived. The analysis is itself extended to an MKL setting. The connection between the proposed hypothesis space and a Group-Lasso type regularizer is discussed. Finally, experimental results, with some SVM-based Multi-Task Learning problems, underline the quality of the derived bounds and validate the paper\u2019s analysis.", "creator": "LaTeX with hyperref package"}}}