{"id": "1401.2011", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "9-Jan-2014", "title": "A logic for reasoning about ambiguity", "abstract": "Standard models of multi-agent modal logic do not capture the fact that information is often \\emph{ambiguous}, and may be interpreted in different ways by different agents. We propose a framework that can model this, and consider different semantics that capture different assumptions about the agents' beliefs regarding whether or not there is ambiguity. We examine the expressive power of logics of ambiguity compared to logics that cannot model ambiguity, with respect to the different semantics that we propose. Theoretically, we can use a system of logics that can distinguish between different agents of the same agent and see if a model is able to distinguish between agents and those that are similar to that that of the agent. We propose that this system will also provide a way for agents to differentiate between agents and the agent. Theoretically, we would create a system that can distinguish between different agents and the agent. For instance, we could use a system of logics that can distinguish between agents and the agent. If we could choose to distinguish between a model that is identical to that of the agent, then there would be a more precise way to distinguish between agents. This would be more robust than one would expect. We have identified many models of ambiguity, but our focus is on one that can distinguish between the agent and the agent. We suggest a formal model for this problem, and the formal model is the same as the formal model. Theoretically, the agent should be able to distinguish between agents and the agent, even without assuming that it is an agent. In short, there are two possible ways of distinguishing between the agent and the agent. For example, if we could use a system that can distinguish between agents and the agent, then that would represent the agent. If the agent is a agent, then the agent should be able to distinguish between agents and the agent, even without assuming that it is an agent. We propose a framework for this problem, and the formal model is the same as the formal model. Theoretically, the agent should be able to distinguish between agents and the agent. For instance, if we could use a system that can distinguish between agents and the agent, then that would represent the agent. If we could choose to distinguish between agents and the agent, then that would represent the agent. If we could use a system that could distinguish between agents and the agent, then that would represent the agent. But the agent should be able to distinguish between agents and the agent. We propose a framework for this problem, and the formal model", "histories": [["v1", "Thu, 9 Jan 2014 14:19:54 GMT  (41kb)", "http://arxiv.org/abs/1401.2011v1", "Some of the material in this paper appeared in preliminary form in \"Ambiguous langage and differences of belief\" (seearXiv:1203.0699)"]], "COMMENTS": "Some of the material in this paper appeared in preliminary form in \"Ambiguous langage and differences of belief\" (seearXiv:1203.0699)", "reviews": [], "SUBJECTS": "cs.AI cs.GT cs.LO", "authors": ["joseph y halpern", "willemien kets"], "accepted": false, "id": "1401.2011"}, "pdf": {"name": "1401.2011.pdf", "metadata": {"source": "CRF", "title": null, "authors": [], "emails": ["halpern@cs.cornell.edu", "w-kets@kellogg.northwestern.edu"], "sections": [{"heading": null, "text": "ar X\niv :1\n40 1.\n20 11"}, {"heading": "1 Introduction", "text": "In the study of multi-agent modal logics, it is implicitly assumed that all agents interpret all formulas the same way. While they may have different beliefs regarding whether a formula \u03d5 is true, they agree on what \u03d5 means. Formally, this is captured by the fact that the truth of \u03d5 does not depend on the agent.\nOf course, in the real world, there is ambiguity; different agents may interpret the same utterance in different ways. For example, consider a public announcement p. Each player i may interpret p as corresponding to some event Ei, where Ei may be different from Ej if i 6= j. This seems natural: even if people have a common background, they may still disagree on how\nto interpret certain phenomena or new information. Someone may interpret a smile as just a sign of friendliness; someone else may interpret it as a \u201cfalse\u201d smile, concealing contempt; yet another person may interpret it as a sign of sexual interest.\nTo model this formally, we can use a straightforward approach already used in [Halpern 2009; Grove and Halpern 1993]: formulas are interpreted relative to a player. But once we allow such ambiguity, further subtleties arise. Returning to the announcement p, not only can it be interpreted differently by different players, it may not even occur to the players that others may interpret the announcement in a different way. Thus, for example, i may believe that Ei is common knowledge. The assumption that each player believes that her interpretation is how everyone interprets the announcement is but one assumption we can make about ambiguity. It is also possible that player i may be aware that there is more than one interpretation of p, but believes that player j is aware of only one interpretation. For example, think of a politician making an ambiguous statement which he realizes that different constituencies will interpret differently, but will not realize that there are other possible interpretations. In this paper, we investigate a number of different semantics of ambiguity that correspond to some standard assumptions that people make with regard to ambiguous statements, and investigate their relationship.\nOur interest in ambiguity was originally motivated by a seminal result in game theory: Aumann\u2019s [1976] theorem showing that players cannot \u201cagree to disagree.\u201d More precisely, this theorem says that agents with a common prior on a state space cannot have common knowledge that they have different posteriors. This result has been viewed as paradoxical in the economics literature. Trade in a stock market seems to require common knowledge of disagreement (about the value of the stock being traded), yet we clearly observe a great deal of trading. One well known explanation for the disagreement is that we do not in fact have common priors: agents start out with different beliefs. In a companion paper [Halpern and Kets 2013], we provide a different explanation, in terms of ambiguity. It is easy to show that we can agree to disagree when there is ambiguity, even if there is a common prior.\nAlthough our work is motivated by applications in economics, ambiguity has long been a concern in philosophy, linguistics, and natural language processing. For example, there has been a great deal of work on word-sense disambiguation (i.e., trying to decide from context which of the multiple meanings of a word are intended); see Hirst [1988] for a seminal contribution, and Navigli [2009] for a recent survey. However, there does not seem to be much work on incorporating ambiguity into a logic. Apart from the literature on the logic of context and on underspecification (see Van Deemter and Peters [1996]), the only papers that we are aware of that does this are ones by Monz [1999] and Kuijer [2013]. Monz allows for statements that have multiple interpretations, just as we do. But rather than incorporating the ambiguity directly into the logic, he considers updates by ambiguous statements.\nKuijer models the fact that ambiguous statements can have multiple meanings by using a nondeterministic propositional logic, which, roughly speaking allows him to consider all the meanings simultaneously. He then defines a notion of implication such that an ambiguous statement A entails another ambiguous statement B if and only if every possible interpreta-\ntions of A entails every possible interpretation of B. This idea of considering all possible interpretations of an ambiguous statement actually has a long tradition in the philosophy literature. For example, Lewis [1982] considers assigning truth values to an ambiguous formula \u03c6 by considering all possible disambiguations of \u03c6. This leads to a semantics where a formula can, for example, have the truth value {true, false}. Lewis views this as a potential justification for relevance logic (a logic where a formula can be true, false, both, or neither; cf. [Rescher and Brandom 1979]). Our approach is somewhat different. We assume that each agent uses only one interpretation of a given ambiguous formula \u03c6, but an agent may consider it possible that another agent interprets \u03c6 differently. In our applications, this seems to be the most appropriate way to dealing with ambiguity (especially when it comes to considering the strategic implications of ambiguity).\nThere are also connections between ambiguity and vagueness. Although the two notions are different\u2014a term is vague if it is not clear what its meaning is, and is ambiguous if it can have multiple meanings, Halpern [2009] also used agent-dependent interpretations in his model of vagueness, although the issues that arose were quite different from those that concern us here.\nGiven the widespread interest in ambiguity, in this paper we focus on the logic of ambiguity. We introduce the logic in Section 2. The rest of the paper is devoted to arguing that, in some sense, ambiguity is not necessary. In Section 3, we show that a formula is satisfiable in a structure with ambiguity (i.e., one where different agents interpret formulas differently) if and only if it is satisfiable in a structure without ambiguity. Then in Section 4, we show that, by extending the language so that we can talk explicitly about how agents interpret formulas, we do not need structures with ambiguity. Despite that, we argue in Section 5 that we it is useful to be able to model ambiguity directly, rather than indirectly."}, {"heading": "2 Syntax and Semantics", "text": ""}, {"heading": "2.1 Syntax", "text": "We want a logic where players use a fixed common language, but each player may interpret formulas in the language differently. Although we do not need probability for the points we want to make in this paper, for the applications that we have in mind it is also important for the agents to be able to reason about their probalistic beliefs. Thus, we take as our base logic a propositional logic for reasoning about probability.\nThe syntax of the logic is straightforward (and is, indeed, essentially the syntax already used in papers going back to Fagin and Halpern [1994]). There is a finite, nonempty set N = {1, . . . , n} of players, and a countable, nonempty set \u03a6 of primitive propositions. Let LCn (\u03a6) be the set of formulas that can be constructed starting from \u03a6, and closing off under conjunction, negation, the modal operators {CBG}G\u2286N,G 6=\u2205, and the formation of probability formulas. (We omit the \u03a6 if it is irrelevant or clear from context.) Probability formulas are constructed as\nfollows. If \u03d51, . . . , \u03d5k are formulas, and a1, . . . , ak, b \u2208 Q, then for i \u2208 N ,\na1pr i(\u03d51) + . . .+ akpr i(\u03d5k) \u2265 b\nis a probability formula, where pr i(\u03d5) denotes the probability that player i assigns to a formula \u03d5. Note that this syntax allows for nested probability formulas. We use the abbreviation Bi\u03d5 for pr i(\u03d5) = 1, EB 1 G\u03d5 for \u2227i\u2208GBi\u03d5, and EB m+1 G \u03d5 for EB m GEB 1 G\u03d5 for m = 1, 2 . . .. Finally, we take true to be the abbreviation for a fixed tautology such as p \u2228 \u00acp."}, {"heading": "2.2 Epistemic probability structures", "text": "There are standard approaches for interpreting this language [Fagin and Halpern 1994], but they all assume that there is no ambiguity, that is, that all players interpret the primitive propositions the same way. To allow for different interpretations, we use an approach used earlier [Halpern 2009; Grove and Halpern 1993]: formulas are interpreted relative to a player.\nAn (epistemic probability) structure (over \u03a6) has the form\nM = (\u2126, (\u03a0j)j\u2208N , (Pj)j\u2208N , (\u03c0j)j\u2208N),\nwhere \u2126 is the state space, and for each i \u2208 N , \u03a0i is a partition of \u2126, Pi is a function that assigns to each \u03c9 \u2208 \u2126 a probability space Pi(\u03c9) = (\u2126i,\u03c9,Fi,\u03c9, \u00b5i,\u03c9), and \u03c0i is an interpretation that associates with each state a truth assignment to the primitive propositions in \u03a6. That is, \u03c0i(\u03c9)(p) \u2208 {true, false} for all \u03c9 and each primitive proposition p. Intuitively, \u03c0i describes player i\u2019s interpretation of the primitive propositions. Standard models use only a single interpretation \u03c0; this is equivalent in our framework to assuming that \u03c01 = \u00b7 \u00b7 \u00b7 = \u03c0n. We call a structure where \u03c01 = \u00b7 \u00b7 \u00b7 = \u03c0n a common-interpretation structure; we call a structure where \u03c0i 6= \u03c0j for some agents i and j a structure with ambiguity. Denote by [[p]]i the set of states where i assigns the value true to p. The partitions \u03a0i are called information partitions. While it is more standard in the philosophy and computer science literature to use models where there is a binary relation Ki on \u2126 for each agent i that describes i\u2019s accessibility relation on states, we follow the common approach in economics of working with information partitions here, as that makes it particularly easy to define a player\u2019s probabilistic beliefs. Assuming information partitions corresponds to the case that Ki is an equivalence relation (and thus defines a partition). The intuition is that a cell in the partition \u03a0i is defined by some information that i received, such as signals or observations of the world. Intuitively, agent i receives the same information at each state in a cell of \u03a0i. Let \u03a0i(\u03c9) denote the cell of the partition \u03a0i containing \u03c9. Finally, the probability space Pi(\u03c9) = (\u2126i,\u03c9,Fi,\u03c9, \u00b5i,\u03c9) describes the beliefs of player i at state \u03c9, with \u00b5i,\u03c9 a probability measure defined on the subspace \u2126i,\u03c9 of the state space \u2126. The \u03c3-algebra Fi,\u03c9 consists of the subsets of \u2126i,\u03c9 to which \u00b5i,\u03c9 can assign a probability. (If \u2126i,\u03c9 is finite, we typically take Fi,\u03c9 = 2\u2126i,\u03c9 , the set of all subsets of \u2126i,\u03c9.) The interpretation is that \u00b5i,\u03c9(E) is the probability that i assigns to event E \u2208 Fi,\u03c9 in state \u03c9.\nThroughout this paper, we make the following assumptions regarding the probability assignments Pi, i \u2208 N :\nA1. For all \u03c9 \u2208 \u2126, \u2126i,\u03c9 = \u03a0i(\u03c9).\nA2. For all \u03c9 \u2208 \u2126, if \u03c9\u2032 \u2208 \u03a0i(\u03c9), then Pi(\u03c9\u2032) = Pi(\u03c9).\nA3. For all j \u2208 N, \u03c9, \u03c9\u2032 \u2208 \u2126, \u03a0i(\u03c9) \u2229\u03a0j(\u03c9\u2032) \u2208 Fi,\u03c9.\nFurthermore, we make the following joint assumption on players\u2019 interpretations and information partitions:\nA4. For all \u03c9 \u2208 \u2126, i \u2208 N , and primitive proposition p \u2208 \u03a6, \u03a0i(\u03c9) \u2229 [[p]]i \u2208 Fi,\u03c9.\nThese are all standard assumptions. A1 says that the set of states to which player i assigns probability at state \u03c9 is just the set \u03a0i(\u03c9) of worlds that i considers possible at state \u03c9. A2 says that the probability space used is the same at all the worlds in a cell of player i\u2019s partition. Intuitively, this says that player i knows his probability space. Informally, A3 says that player i can assign a probability to each of j\u2019s cells, given his information. A4 says that primitive propositions (as interpreted by player i) are measurable according to player i."}, {"heading": "2.3 Prior-generated beliefs", "text": "One assumption that we do not necessarily make, but want to examine in this framework, is the common-prior assumption. The common-prior assumption is an instance of a more general assumption, that beliefs are generated from a prior, which we now define. The intuition is that players start with a prior probability; they then update the prior in light of their information. Player i\u2019s information is captured by her partition \u03a0i. Thus, if i\u2019s prior is \u03bdi, then we would expect \u00b5i,\u03c9 to be \u03bdi(\u00b7 | \u03a0i(\u03c9)).\nDefinition 2.1 An epistemic probability structure M = (\u2126, (\u03a0j)j\u2208N , (Pj)j\u2208N , (\u03c0j)j\u2208N) has prior-generated beliefs (generated by (F1, \u03bd1), . . . , (Fn, \u03bdn)) if, for each player i, there exist probability spaces (\u2126,Fi, \u03bdi) such that\n\u2022 for all i, j \u2208 N and \u03c9 \u2208 \u2126, \u03a0j(\u03c9) \u2208 Fi;\n\u2022 for all i \u2208 N and \u03c9 \u2208 \u2126, Pi(\u03c9) = (\u03a0i(\u03c9),Fi | \u03a0i(\u03c9), \u00b5i,\u03c9), where Fi | \u03a0i(\u03c9) is the restriction of Fi to \u03a0i(\u03c9),1 and \u00b5i,\u03c9(E) = \u03bdi(E | \u03a0i(\u03c9)) for all E \u2208 Fi | \u03a0i(\u03c9) if \u03bdi(\u03a0i(\u03c9)) > 0. (There are no constraints on \u03bdi,\u03c9 if \u03bdi(\u03a0i(\u03c9)) = 0.)\nIt is easy to check that if M has prior-generated beliefs, then M satisfies A1, A2, and A3. More interestingly for our purposes, the converse also holds for a large class of structures. Say that a structure is countably partitioned if for each player i, the information partition \u03a0i has countably many elements, i.e., \u03a0i is a finite or countably infinite collection of subsets of \u2126.\n1Recall that the restriction of Fi to \u03a0i(\u03c9) is the \u03c3-algebra {B \u2229 \u03a0i(\u03c9) : B \u2208 Fi}.\nProposition 2.2 If a structure M has prior-generated beliefs, then M satisfies A1, A2, and A3. Moreover, every countably partitioned structure that satisfies A1, A2, and A3 is one with prior-generated beliefs, with the priors \u03bdi satisfying \u03bdi(\u03a0i(\u03c9)) > 0 for each player i \u2208 N and state \u03c9 \u2208 \u2126.\nProof. The first part is immediate. To prove the second claim, suppose that M is a structure satisfying A1\u2013A3. Let Fi be the unique algebra generated by \u222a\u03c9\u2208\u2126Fi,\u03c9. To define \u03bdi, if there are Ni < \u221e cells in the partition \u03a0i, define \u03bdi(\u03c9) = 1Ni\u00b5i,\u03c9(\u03c9). Otherwise, if the collection \u03a0i is countably infinite, order the elements of \u03a0i as p1i , p 2 i , . . .. Choose some state \u03c9k \u2208 p k i for each k, with associated probability space Pi(\u03c9k) = (\u2126i,\u03c9k ,Fi,\u03c9k , \u00b5i,\u03c9k). By A2, each choice of \u03c9k in pki gives the same probability measure \u00b5i,\u03c9k . Define \u03bdi = \u2211 k 1 2k \u00b5i,\u03c9k . It is easy to see that \u03bdi is a probability measure on \u2126, and that M is generated by (F1, \u03bd1), . . . , (Fn, \u03bdn).\nNote that the requirement that that M is countably partitioned is necessary to ensure that we can have \u03bdi(\u03a0i(\u03c9)) > 0 for each player i and state \u03c9.\nIn light of Proposition 2.2, when it is convenient, we will talk of a structure satisfying A1\u2013A3 as being generated by (F1, \u03bd1), . . . , (Fn, \u03bdn).\nThe common-prior assumption discussed in the introduction is essentially just the special case of prior-generated beliefs where all the priors are identical."}, {"heading": "2.4 Capturing ambiguity", "text": "We use epistemic probability structures to give meaning to formulas. Since primitive propositions are interpreted relative to players, we must allow the interpretation of arbitrary formulas to depend on the player as well. Exactly how we do this depends on what further assumptions we make about what players know about each other\u2019s interpretations. There are many assumptions that could be made. We focus on two of them here, ones that we believe arise in applications of interest, and then reconsider them under the assumption that there may be some ambiguity about the partitions.\nBelieving there is no ambiguity The first approach is appropriate for situations where players may interpret statements differently, but it does not occur to them that there is another way of interpreting the statement. Thus, in this model, if there is a public announcement, all players will think that their interpretation of the announcement is common knowledge. We write (M,\u03c9, i) out \u03d5 to denote that \u03d5 is true at state \u03c9 according to player i (that is, according to i\u2019s interpretation of the primitive propositions in \u03d5). The superscript out denotes outermost scope, since the formulas are interpreted relative to the \u201coutermost\u201d player, namely the player i on the left-hand side of out . We define out , as usual, by induction.\nIf p is a primitive proposition,\n(M,\u03c9, i) out p iff \u03c0i(\u03c9)(p) = true.\nThis just says that player i interprets a primitive proposition p according to his interpretation function \u03c0i. This clause is common to all our approaches for dealing with ambiguity.\nFor conjunction and negation, as is standard,\n(M,\u03c9, i) out \u00ac\u03d5 iff (M,\u03c9, i) 6 out\u03d5,\n(M,\u03c9, i) out \u03d5 \u2227 \u03c8 iff (M,\u03c9, i) out \u03d5 and (M,\u03c9, i) out \u03c8.\nNow consider a probability formula of the form a1pr j(\u03d51)+ . . .+akpr j(\u03d5k) \u2265 b. The key feature that distinguishes this semantics is how i interprets j\u2019s beliefs. This is where we capture the intuition that it does not occur to i that there is another way of interpreting the formulas other than the way she does. Let\n[[\u03d5]]outi = {\u03c9 : (M,\u03c9, i) out \u03d5}.\nThus, [[\u03d5]]outi is the event consisting of the set of states where \u03d5 is true, according to i. Note that A1 and A3 guarantee that the restriction of \u2126j,\u03c9 to \u03a0i(\u03c9) belongs to Fi,\u03c9. Assume inductively that [[\u03d51]]outi \u2229 \u2126j,\u03c9, . . . , [[\u03d5k]] out\ni \u2229 \u2126j,\u03c9 \u2208 Fj,\u03c9. The base case of this induction, where \u03d5 is a primitive proposition, is immediate from A3 and A4, and the induction assumption clearly extends to negations and conjunctions. We now define\n(M,\u03c9, i) out a1pr j(\u03d51) + . . .+ akpr j(\u03d5k) \u2265 b iff\na1\u00b5j,\u03c9([[\u03d51]] out i \u2229 \u2126j,\u03c9) + . . .+ ak\u00b5j,\u03c9([[\u03d5k]] out i \u2229 \u2126j,\u03c9) \u2265 b.\nNote that it easily follows from A2 that (M,\u03c9, i) out a1pr j(\u03d51) + . . . + akpr j(\u03d5k) \u2265 b if and only if (M,\u03c9\u2032, i) out a1pr j(\u03d51) + . . . + akpr j(\u03d5k) \u2265 b for all \u03c9\n\u2032 \u2208 \u03a0j(\u03c9). Thus, [[a1pr j(\u03d51) + . . .+ akpr j(\u03d5k) \u2265 b]]i is a union of cells of \u03a0j , and hence [[a1pr j(\u03d51) + . . .+ akpr j(\u03d5k) \u2265 b]]i \u2229 \u2126j,\u03c9 \u2208 Fj,\u03c9.\nWith this semantics, according to player i, player j assigns \u03d5 probability b if and only if the set of worlds where \u03d5 holds according to i has probability b according to j. Intuitively, although i \u201cunderstands\u201d j\u2019s probability space, player i is not aware that j may interpret \u03d5 differently from the way she (i) does. That i understands j\u2019s probability space is plausible if we assume that there is a common prior and that i knows j\u2019s partition (this knowledge is embodied in the assumption that i intersects [[\u03d5k]]outi with \u2126j,\u03c9 when assessing what probability j assigns to \u03d5k).2\nGiven our interpretation of probability formulas, the interpretation of Bj\u03d5 and EB k\u03d5 fol-\nlows. For example, (M,\u03c9, i) out Bj\u03d5 iff \u00b5j,\u03c9([[\u03d5]] out i ) = 1.\n2Note that at state \u03c9, player i will not in general know that it is state \u03c9. In particular, even if we assume that i knows which element of j\u2019s partition contains \u03c9, i will not in general know which of j\u2019s cells describes j\u2019s current information. But we assume that i does know that if the state is \u03c9, then j\u2019s information is described by \u2126j,\u03c9. Thus, as usual, \u201c(M, i, \u03c9) out \u03d5\u201d should perhaps be understood as \u201caccording to i, \u03d5 is true if the actual world is \u03c9\u201d. This interpretational issue arises even without ambiguity in the picture.\nFor readers more used to belief defined in terms of a possibility relation, note that if the probability measure \u00b5j,\u03c9 is discrete (i.e., all sets are \u00b5j,\u03c9-measurable, and \u00b5j,\u03c9(E) = \u2211 \u03c9\u2032\u2208E \u00b5j,\u03c9(\u03c9\n\u2032) for all subsets E \u2282 \u03a0j(\u03c9)), we can define Bj = {(\u03c9, \u03c9\u2032) : \u00b5j,\u03c9(\u03c9\u2032) > 0}; that is, (\u03c9, \u03c9\u2032) \u2208 Bj if, in state \u03c9, agent j gives state \u03c9\u2032 positive probability. In that case, (M,\u03c9, i) out Bj\u03d5 iff (M,\u03c9\u2032, i) out \u03d5 for all \u03c9\u2032 such that (\u03c9, \u03c9\u2032) \u2208 Bj . That is, (M,\u03c9, i) out Bj\u03d5 iff \u03d5 is true according to i in all the worlds to which j assigns positive probability at \u03c9.\nIt is important to note that (M,\u03c9, i) \u03d5 does not imply (M,\u03c9, i) Bi\u03d5: while (M,\u03c9, i) out\n\u03d5 means \u201c\u03d5 is true at \u03c9 according to i\u2019s interpretation,\u201d this does not mean that i believes \u03d5 at state \u03c9. The reason is that i can be uncertain as to which state is the actual state. For i to believe \u03d5 at \u03c9, \u03d5 would have to be true (according to i\u2019s interpretation) at all states to which i assigns positive probability.\nFinally, we define\n(M,\u03c9, i) out CBG\u03d5 iff (M,\u03c9, i) out EBkG\u03d5 for k = 1, 2, . . .\nfor any nonempty subset G \u2286 N of players.\nAwareness of possible ambiguity We now consider the second way of interpreting formulas. This is appropriate for players who realize that other players may interpret formulas differently. We write (M,\u03c9, i) in \u03d5 to denote that \u03d5 is true at state \u03c9 according to player i using this interpretation, which is called innermost scope. The definition of in is identical to that of out except for the interpretation of probability formulas. In this case, we have\n(M,\u03c9, i) in a1pr j(\u03d51) + . . .+ akpr j(\u03d5k) \u2265 b iff\na1\u00b5j,\u03c9([[\u03d51]] in j \u2229 \u2126j,\u03c9) + . . .+ ak\u00b5j,\u03c9([[\u03d5k]] in j \u2229 \u2126j,\u03c9) \u2265 b,\nwhere [[\u03d5]]inj is the set of states \u03c9 such that (M,\u03c9, j) in \u03d5. Hence, according to player i, player j assigns \u03d5 probability b if and only if the set of worlds where \u03d5 holds according to j has probability b according to j. Intuitively, now i realizes that j may interpret \u03d5 differently from the way that she (i) does, and thus assumes that j uses his (j\u2019s) interpretation to evaluate the probability of \u03d5. Again, in the case that \u00b5j,\u03c9 is discrete, this means that (M,\u03c9, i) in Bj\u03d5 iff (M,\u03c9\u2032, j) in \u03d5 for all \u03c9\u2032 such that (\u03c9, \u03c9\u2032) \u2208 Bj .\nNote for future reference that if \u03d5 is a probability formula or a formula of the form CBG\u03d5\u2032, then it is easy to see that (M,\u03c9, i) in \u03d5 if and only if (M,\u03c9, j) in \u03d5; we sometimes write (M,\u03c9) in \u03d5 in this case. Clearly, out and in agree in the common-interpretation case, and we can write . There is a sense in which innermost scope is able to capture the intuitions behind outermost scope. Specifically, we can capture the intuition that player i is convinced that all players interpret everything just as he (i) does by assuming that in all worlds \u03c9\u2032 that player i considers possible, \u03c0i(\u03c9\u2032) = \u03c0j(\u03c9\u2032) for all players j.\nAmbiguity about information partitions Up to now, we have assumed that players \u201cunderstand\u201d each other\u2019s probability spaces. This may not be so reasonable in the presence of\nambiguity and prior-generated beliefs. We want to model the following type of situation. Players receive information, or signals, about the true state of the world, in the form of strings (formulas). Each player understands what signals he and other players receive in different states of the world, but players may interpret signals differently. For instance, player i may understand that j sees a red car if \u03c9 is the true state of the world, but i may or may not be aware that j has a different interpretation of \u201cred\u201d than i does. In the latter case, i does not have a full understanding of j\u2019s information structure.\nWe would like to think of a player\u2019s information as being characterized by a formula (intuitively, the formula that describes the signals received). Even if the formulas that describe each information set are commonly known, in the presence of ambiguity, they might be interpreted differently.\nTo make this precise, let \u03a6\u2217 be the set of formulas that is obtained from \u03a6 by closing off under negation and conjunction. That is, \u03a6\u2217 consists of all propositional formulas that can be formed from the primitive propositions in \u03a6. Since the formulas in \u03a6\u2217 are not composed of probability formulas, and thus do not involve any reasoning about interpretations, we can extend the function \u03c0i(\u00b7) to \u03a6\u2217 in a straightforward way, and write [[\u03d5]]i for the set of the states of the world where the formula \u03d5 \u2208 \u03a6\u2217 is true according to i.\nThe key new assumption that we make to model players\u2019 imperfect understanding of the other players\u2019 probability spaces is that i\u2019s partition cell at \u03c9 is described by a formula \u03d5i,\u03c9 \u2208 \u03a6\u2217. Roughly speaking, this means that \u03a0i(\u03c9) should consist of all states where the formula \u03d5i,\u03c9 is true. More precisely, we take \u03a0i(\u03c9) to consist of all states where \u03c6i,\u03c9 is true according to i. If player j understands that i may be using a different interpretation than he does (i.e., the appropriate semantics are the innermost-scope semantics), then j correctly infers that the set of states that i thinks are possible in \u03c9 is \u03a0i(\u03c9) = [[\u03d5i,\u03c9]]i. But if j does not understand that i may interpret formulas in a different way (i.e., under outermost scope), then he thinks that the set of states that i thinks are possible in \u03c9 is given by [[\u03d5i,\u03c9]]j . Of course, [[\u03d5i,\u03c9]]j does not in general coincide with \u03a0i(\u03c9). Indeed, [[\u03d5i,\u03c9]]j may even be empty. If this happens, j might well wonder if i is interpreting things the same way that he (j) is. In any case, we require that j understand that these formulas form a partition and that \u03c9 belongs to [[\u03d5i,\u03c9]]j . Thus, we consider structures that satisfy A1\u2013A5, and possibly A6 (when we use outermost scope semantics).\nA5. For each i \u2208 N and \u03c9 \u2208 \u2126, there is a formula \u03d5i,\u03c9 \u2208 \u03a6\u2217 such that \u03a0i(\u03c9) = [[\u03d5i,\u03c9]]i.\nA6. For each i, j \u2208 N , the collection {[[\u03d5i,\u03c9]]j : \u03c9 \u2208 \u2126} is a partition of \u2126 and for all \u03c9 \u2208 \u2126, \u03c9 \u2208 [[\u03d5i,\u03c9]]j .\nAssumption A6 ensure that the signals for player i define an information partition according to every player j when we consider the outermost scope semantics. With innermost scope, this already follows from A5 and the definition of \u03a0i(\u03c9).\nWe can now define analogues of outermost scope and innermost scope in the presence of ambiguous information. Thus, we define two more truth relations, out ,ai and in,ai . (The \u201cai\u201d here stands for \u201cambiguity of information\u201d.) The only difference between out ,ai and\nout is in the semantics of probability formulas. In giving the semantics in a structure M , we assume that M has prior-generated beliefs, generated by (F1, \u03bd1), . . . , (Fn, \u03bdn). As we observed in Proposition 2.2, this assumption is without loss of generality as long as the structure is countably partitioned. However, the choice of prior beliefs is relevant, as we shall see, so we have to be explicit about them. When i evaluates j\u2019s probability at a state \u03c9, instead of using \u00b5j,\u03c9, player i uses \u03bdj(\u00b7 | [[\u03d5j,\u03c9]]i). When i = j, these two approaches agree, but in general they do not. Thus, assuming that M satisfies A5 and A6 (which are the appropriate assumptions for the outermost-scope semantics), we have\n(M,\u03c9, i) out ,ai a1pr j(\u03d51) + . . .+ akpr j(\u03d5k) \u2265 b iff a1\u03bdj([[\u03d51]] out ,ai i | [[\u03d5j,\u03c9]] out ,ai i ) + . . .\n+ak\u03bdj([[\u03d5k]] out ,ai i | [[\u03d5j,\u03c9]] out ,ai i ) \u2265 b,\nwhere [[\u03c8]]out ,aii = {\u03c9 \u2032 : (M,\u03c9, i) out ,ai \u03c8}.\nThat is, at \u03c9 \u2208 \u2126, player j receives the information (a string) \u03d5j,\u03c9, which he interprets as [[\u03d5j,\u03c9]]j . Player i understands that j receives the information \u03d5j,\u03c9 in state \u03c9, but interprets this as [[\u03d5j,\u03c9]]i. This models a situation such as the following. In state \u03c9, player j sees a red car, and thinks possible all states of the world where he sees a car that is red (according to j). Player i knows that at world \u03c9 player j will see a red car (although she may not know that the actual world is \u03c9, and thus does not know what color of car player j actually sees). However, i has a somewhat different interpretation of \u201cred car\u201d (or, more precisely, of j seeing a red car) than j; i\u2019s interpretation corresponds to the event [[\u03d5j,\u03c9]]i. Since i understands that j\u2019s beliefs are determined by conditioning her prior \u03bdj on her information, i can compute what she believes j\u2019s beliefs are.\nWe can define in,ai in an analogous way. Thus, the semantics for formulas that do not involve probability formulas are as given by in , while the semantics of probability formulas is defined as follows (where M is assumed to satisfy A5, which is the appropriate assumption for the innermost-scope semantics):\n(M,\u03c9, i) in,ai a1pr j(\u03d51) + . . .+ akpr j(\u03d5k) \u2265 b iff a1\u03bdj([[\u03d51]] in,ai j | [[\u03d5j,\u03c9]] in,ai j ) + . . .\n+ak\u03bdj([[\u03d5k]] in,ai j | [[\u03d5j,\u03c9]] in,ai j ) \u2265 b.\nNote that although we have written [[\u03d5j,\u03c9]] in,ai i , since \u03d5j,\u03c9 is a propositional formula, [[\u03d5j,\u03c9]] in,ai i = [[\u03d5j,\u03c9]] out ,ai i = [[\u03d5j,\u03c9]] out i = [[\u03d5j,\u03c9]] in\ni . It is important that \u03d5j,\u03c9 is a propositional formula here; otherwise, we would have circularities in the definition, and would somehow need to define [[\u03d5j,\u03c9]] in,ai i .\nAgain, here it may be instructive to consider the definition of Bj\u03d5 in the case that \u00b5j,\u03c9 is discrete for all \u03c9. In this case, Bj becomes the set {(\u03c9, \u03c9\u2032) : \u03bdj(\u03c9\u2032 | [[\u03d5j,\u03c9]] in,ai j ) > 0. That is, state \u03c9\u2032 is considered possible by player j in state \u03c9 if agent j gives \u03c9\u2032 positive probability after conditioning his prior \u03bdj on (his interpretation of) the information \u03d5j,\u03c9 he receives in state \u03c9. With this definition of Bj , we have, as expected, (M,\u03c9, i) in,ai Bj\u03d5 iff (M,\u03c9\u2032, i) in,ai \u03d5 for all \u03c9\u2032 such that (\u03c9, \u03c9\u2032) \u2208 Bj .\nThe differences in the different semantics arise only when we consider probability formulas. If we go back to our example with the red car, we now have a situation where player j sees a red car in state \u03c9, and thinks possible all states where he sees a red car. Player i knows that in state \u03c9, player j sees a car that he (j) interprets to be red, and that this determines his posterior. Since i understands j\u2019s notion of seeing a red car, she has a correct perception of j\u2019s posterior in each state of the world. Thus, the semantics for in,ai are identical to those for in (restricted to the class of structures with prior-generated beliefs that satisfy A5), though the information partitions are not predefined, but rather generated by the signals.\nNote that, given an epistemic structure M satisfying A1\u2013A4, there are many choices for \u03bdi that allow M to be viewed as being generated by prior beliefs. All that is required of \u03bdj is that for all \u03c9 \u2208 \u2126 and E \u2208 Fj,\u03c9 such that E \u2286 [[\u03d5j,\u03c9]] out ,ai j , it holds that \u03bdj(E \u2229 [[\u03d5j,\u03c9]] out ,ai j )/\u03bdj([[\u03d5j,\u03c9]] out ,ai j ) = \u00b5j,\u03c9(E). However, because [[\u03d5j,\u03c9]] out ,ai i may not be a subset of [[\u03d5j,\u03c9]] out ,ai j = \u03a0j(\u03c9), we can have two prior probabilities \u03bdj and \u03bd \u2032 j that generate the same posterior beliefs for j, and still have \u03bdj([[\u03d5k]] out ,ai i | [[\u03d5j,\u03c9]] out ,ai i ) 6= \u03bd \u2032 j([[\u03d5k]] out ,ai i | [[\u03d5j,\u03c9]] out ,ai i ) for some formulas \u03d5k. Thus, we must be explicit about our choice of priors here."}, {"heading": "3 Common interpretations suffice", "text": "In this section, we show in there is a sense in which we do not need structures with ambiguity. Specifically, we show that the same formulas are valid in common-interpretation structures as in structures that do not have a common interpretation, no matter what semantics we use, even if we have ambiguity about information partitions.\nTo make this precise, we need some notation. Fix a nonempty, countable set \u03a8 of primitive propositions, and let M(\u03a8) be the class of all structures that satisfy A1\u2013A4 and that are defined over some nonempty subset \u03a6 of \u03a8 such that \u03a8 \\ \u03a6 is countably infinite.3 Given a subset \u03a6 of \u03a8, a formula \u03d5 \u2208 LCn (\u03a6), and a structure M \u2208 M(\u03a8) over \u03a6, we say that \u03d5 is valid in M according to outermost scope, and write M out \u03d5, if (M,\u03c9, i) out \u03d5 for all \u03c9 \u2208 \u2126 and i \u2208 N . Given \u03d5 \u2208 \u03a8, say that \u03d5 is valid according to outermost scope in a class N \u2286 M(\u03a8) of structures, and write N out \u03d5, if M out \u03d5 for all M \u2208 N defined over a set \u03a6 \u2282 \u03a8 of primitive propositions that includes all the primitive propositions that appear in \u03d5.\nWe get analogous definitions by replacing out by in , out ,ai and in,ai throughout (in the latter two cases, we have to restrict N to structures that satisfy A5 and A6 or just A5, respectively, in addition to A1\u2013A4). Finally, given a class of structures N , let Nc be the subclass of N in which players have a common interpretation. Thus, Mc(\u03a8) denotes the structures in M(\u03a8) with a common interpretation. Let Mai(\u03a8) denote all structures in M(\u03a8)\n3Most of our results hold if we just consider the set of structures defined over some fixed set \u03a6 of primitive propositions. However, for one of our results, we need to be able to add fresh primitive propositions to the language. Thus, we allow the set \u03a6 of primitive propositions to vary over the structures we consider, but require \u03a8 \\ \u03a6 to be countably infinite so that there are always \u201cfresh\u201d primitive propositions that we can add to the language.\nwith prior-generated beliefs that satisfy A5 and A6 (where we assume that the prior \u03bd that describes the initial beliefs is given explicitly).4\nTheorem 3.1 For all formulas \u03d5 \u2208 LCn (\u03a8), the following are equivalent:\n(a) Mc(\u03a8) \u03d5;\n(b) M(\u03a8) out \u03d5;\n(c) M(\u03a8) in \u03d5;\n(d) Maic (\u03a8) \u03d5;\n(e) Mai(\u03a8) out ,ai \u03d5;\n(f) Mai(\u03a8) in,ai \u03d5.\nProof. Since the set of structures with a common interpretation is a subset of the set of structures, it is immediate that (c) and (b) both imply (a). Similarly, (e) and (f) both imply (d). The fact that (a) implies (b) is also immediate. For suppose that Mc(\u03a8) \u03d5 and that M = (\u2126, (\u03a0j)j\u2208N , (Pj)j\u2208N , (\u03c0j)j\u2208N) \u2208 M(\u03a8) is a structure over a set \u03a6 \u2282 \u03a8 of primitive propositions that contains the primitive propositions that appear in \u03d5. We must show that M out \u03d5. Thus, we must show that (M,\u03c9, i) out \u03d5 for all \u03c9 \u2208 \u2126 and i \u2208 N . Fix \u03c9 \u2208 \u2126 and i \u2208 N , and let M \u2032i = (\u2126, (\u03a0j)j\u2208N , (Pj)j\u2208N , (\u03c0 \u2032 j)j\u2208N), where \u03c0 \u2032 j = \u03c0i for all j. Thus, M \u2032i is a common-interpretation structure over \u03a6, where the interpretation coincides with i\u2019s interpretation in M . Clearly M \u2032i satisfies A1\u2013A4, so M \u2032 i \u2208 Mc(\u03a8). It is easy to check that (M,\u03c9, i) out \u03c8 if and only if (M \u2032i , \u03c9, i) \u03c8 for all states \u03c9 \u2208 \u2126 and all formulas \u03c8 \u2208 L C n (\u03a6). Since M \u2032i \u03d5, we must have that (M,\u03c9, i) out \u03d5, as desired.\nTo see that (a) implies (c), given a structure M = (\u2126, (\u03a0j)j\u2208N , (Pj)j\u2208N , (\u03c0j)j\u2208N) \u2208 M(\u03a8) over some set \u03a6 \u2282 \u03a8 of primitive propositions and a player j \u2208 N , let \u2126j be a disjoint copy of \u2126; that is, for every state \u03c9 \u2208 \u2126, there is a corresponding state \u03c9j \u2208 \u2126j . Let \u2126\u2032 = \u21261\u222a . . .\u222a\u2126n. Given E \u2286 \u2126, let the corresponding subset Ej \u2286 \u2126j be the set {\u03c9j : \u03c9 \u2208 E}, and let E \u2032 be the subset of \u2126\u2032 corresponding to E, that is, E \u2032 = {\u03c9j : \u03c9 \u2208 E, j \u2208 N}.\nDefine M \u2032 = (\u2126\u2032, (\u03a0\u2032j)j\u2208N , (P \u2032 j)j\u2208N , (\u03c0 \u2032 j)j\u2208N), where \u2126 \u2032 = \u21261\u222a . . .\u222a\u2126n and, for all \u03c9 \u2208 \u2126 and i, j \u2208 N , we have\n\u2022 \u03a0\u2032i(\u03c9j) = (\u03a0i(\u03c9)) \u2032;\n\u2022 \u03c0i(\u03c9j)(p) = \u03c0j(\u03c9)(p) for a primitive proposition p \u2208 \u03a6;\n\u2022 P \u2032i(\u03c9j) = (\u2126 \u2032 i,\u03c9j ,F \u2032i,\u03c9j , \u00b5 \u2032 i,\u03c9j ), where \u2126\u2032i,\u03c9j = \u2126 \u2032 i,\u03c9, F \u2032 i,\u03c9j = {E\u2113 : E \u2208 Fi,\u03c9, \u2113 \u2208 N}, \u00b5\u2032i,\u03c9j(Ei) = \u00b5i,\u03c9(E), \u00b5 \u2032 i,\u03c9j (E\u2113) = 0 if \u2113 6= i.\n4For ease of exposition, we assume A6 even when dealing with innermost scope.\nThus, \u03c01 = \u00b7 \u00b7 \u00b7 = \u03c0n, so that M \u2032 is a common-interpretation structure; on a state \u03c9j , these interpretations are all determined by \u03c0j . Also note that the support of the probability measure \u00b5\u2032i,\u03c9j is contained in \u2126i, so for different players i, the probability measures \u00b5 \u2032 i,\u03c9j\nhave disjoint supports. Now an easy induction on the structure of formulas shows that(M \u2032, \u03c9j) \u03c8 if and only if (M,\u03c9, j) in \u03c8 for any formula \u03c8 \u2208 LCn (\u03a6). It easily follows that if M \u2032 \u03d5, then M in \u03d5 for all \u03d5 \u2208 LCn (\u03a6).\nThe argument that (d) implies (e) is essentially identical to the argument that (a) implies (b); similarly, the argument that (d) implies (f) is essentially the same as the argument that (a) implies (c). Since Maic (\u03a8) \u2286 Mc(\u03a8), (a) implies (d). To show that (d) implies (a), suppose that Maic (\u03a8) \u03d5 for some formula \u03d5 \u2208 L C n (\u03a8). Given a structure M = (\u2126, (\u03a0j)j\u2208N , (Pj)j\u2208N , \u03c0) \u2208 Mc(\u03a8) over a set \u03a6 \u2282 \u03a8 of primitive propositions that includes the primitive propositions that appear in \u03d5, we want to show that (M,\u03c9, i) \u03d5 for each state \u03c9 \u2208 \u2126 and player i. Fix \u03c9. Recall that RN(\u03c9) consists of the set of states N-reachable from \u03c9. Let M \u2032 = (RN(\u03c9), (\u03a0\u2032j)j\u2208N , (P \u2032 j)j\u2208N , \u03c0 \u2032), with \u03a0\u2032j and P \u2032 j the restriction of \u03a0j and Pj , respectively, to the states in RN (\u03c9), be a structure over a set \u03a6\u2032 of primitive propositions, where \u03a6\u2032 contains \u03a6 and new primitive propositions that we call pi,\u03c9 for each player i and state \u03c9 \u2208 RN(\u03c9).5 Note that there are only countably many information sets in RN (\u03c9), so \u03a6\u2032 is countable. Define \u03c0\u2032 so that it agrees with \u03c0 (restricted to RN(\u03c9)) on the propositions in \u03a6, and so that [[pi,\u03c9]]i = \u03a0i(\u03c9). Thus, M \u2032 satisfies A5 and A6. It is easy to check that, for all \u03c9\u2032 \u2208 RN (\u03c9) and all formulas \u03c8 \u2208 LCn (\u03a6), we have that (M,\u03c9\n\u2032, i) \u03c8 iff (M \u2032, \u03c9\u2032, i) \u03c8. Since M \u2032 \u03d5, it follows that (M,\u03c9, i) \u03d5, as desired.\nFrom Theorem 3.1 it follows that for formulas in LCn (\u03a8), we can get the same axiomatization with respect to structures in M(\u03a8) for both the out and in semantics; moreover, this axiomatization is the same as that for the common-interpretation case. An axiomatization for this case is already given in [Fagin and Halpern 1994]; there is also a complete characterization of the complexity of determining whether a formula is valid.\nHowever, the equivalence in Theorem 3.1 does not extend to subclasses of M, Mc, and Mai . As shown in our companion paper [Halpern and Kets 2013], the equivalence result does not hold if we consider the innermost scope semantics and restrict attention to the subclasses of M and Mc that satisfy the common-prior assumption. We defer a further discussion of the modeling implications of this result to Section 5."}, {"heading": "4 A more general language", "text": "Although, when considering innermost scope, we allowed for agents that were sophisticated enough to realize that different agents might interpret things in different ways, our syntax did\n5This is the one argument that needs the assumption that the set of primitive propositions can be different in different structures in M(\u03a8), and the fact that every \u03a8 \\ \u03a6 is countable. We have assumed for simplicity that the propositions pi,\u03c9 are all in \u03a8 \\ \u03a6, and that they can be chosen in such a way so that \u03a8 \\ (\u03a6 \u222a {pi,\u03c9 : i \u2208 {1, . . . , n}, \u03c9 \u2208 \u2126}) is countable.\nnot reflect that sophistication. Specifically, the language does not allow the modeler (or the agents) to reason about how other agents interpret formulas. Here we consider a language that is rich enough to allow this. Specifically, we have primitive propositions of the form (p, i), that can be interpreted as \u201ci\u2019s interpretation of p.\u201d With this extended language, we do not need to have a different interpretation function \u03c0i for each i; it suffices in a precise sense to use a single (common) interpretation function. We now make this precise, and show that this approach is general enough to capture both outermost and innermost scope.\nMore precisely, we consider the same syntax as in Section 2.1, with the requirement that the set \u03a6 of primitive propositions have the form \u03a6\u2032 \u00d7 N , for some set \u03a6\u2032; that is, primitive propositions have the form (p, i) for some p \u2208 \u03a6\u2032 and some agent i \u2208 N . We interpret these formulas using a standard epistemic probability structure M = (\u2126, (\u03a0j)j\u2208N , (Pj)j\u2208N , \u03c0), with a common interpretation \u03c0, as in [Fagin and Halpern 1994]. Thus, truth is no longer agentdependent, so we have only (M,\u03c9) on the left-hand side of , not (M,\u03c9, i). In particular, if (p, i) is a primitive proposition,\n(M,\u03c9) (p, i) iff \u03c0(\u03c9)((p, i)) = true.\nAs expected, we have\n(M,\u03c9) a1pr j(\u03d51) + . . .+ akpr j(\u03d5k) \u2265 b iff\na1\u00b5j,\u03c9([[\u03d51]] \u2229 \u2126j,\u03c9) + . . .+ ak\u00b5j,\u03c9([[\u03d5k]] \u2229 \u2126j,\u03c9) \u2265 b.\nWe no longer need to write [[\u03d5j]]oui or [[\u03d5j]] in i , since all agents interpret all formulas the same way.\nWe now show how we can capture innermost and outermost scope using this semantics. Specifically, suppose that we start with an epistemic probability structureM = (\u2126, (\u03a0j)j\u2208N , (Pj)j\u2208N , (\u03c0j)j\u2208N) over some set \u03a6 of primitive propositions. Consider the corresponding common-interpretation structure Mc = (\u2126, (\u03a0j)j\u2208N , (Pj)j\u2208N , \u03c0) over \u03a6 \u00d7 N , where \u03c0(\u03c9)(p, i) = \u03c0i(\u03c9)(p). Thus, M and Mc are identical except in the primitive propositions that they interpret, and how they interpret them. In Mc, the primitive proposition (p, i) \u2208 \u03a6 \u00d7 N is interpreted the same way that i interprets p in M .\nWe can now define, for each formula \u03c6, two formulas \u03c6ini and \u03c6 out i with the property that (M,\u03c9, i) in \u03c6 iff (Mc, \u03c9) \u03c6ini and (M,\u03c9, i) out \u03c6 iff (Mc, \u03c9) \u03c6outi . We start with \u03c6 in\ni , defining it by induction on structure:\n\u2022 pini = (p, i)\n\u2022 (\u03c8 \u2227 \u03c8\u2032)ini = \u03c8 in i \u2227 (\u03c8 \u2032 i) in\n\u2022 (a1pr j(\u03d51) + . . .+ akpr j(\u03d5k) \u2265 b) in i = a1pr j((\u03d51) in j ) + . . .+ akpr j((\u03d5k) in j ) \u2265 b\n\u2022 (CBG\u03c8)ini = CBG(\u2227j\u2208GBj\u03c8 in j ).\nNote that \u03c6ini is independent of i if \u03c6 is a probability formula or of the form CBG\u03c8. This is to be expected, since, as we have seen, with innermost scope, the semantics of such formulas is independent of i. The definition of (CBG\u03c8)ini is perhaps the only somewhat surprising clause here; as we discuss after the proof of Theorem 4.1 below, the more natural definition, (CBG\u03c8) in i = CBG(\u03c8 in i ), does not work.\nFor outermost scope, the first two clauses of the translation are identical to those above; the latter two change as required for outermost scope. Thus, we get\n\u2022 pouti = (p, i)\n\u2022 (\u03c8 \u2227 \u03c8\u2032)outi = \u03c8 out i \u2227 (\u03c8 \u2032 i) out\n\u2022 (a1pr j(\u03d51) + . . .+ akpr j(\u03d5k) \u2265 b) out i = a1pr j((\u03d51) out i ) + . . .+ akpr j((\u03d5k) out i ) \u2265 b\n\u2022 (CBG\u03c8) out i = CBG(\u03c8 out i ).\nInterestingly, here the natural definition of (CBG\u03c8)outi does work.\nTheorem 4.1 If M is a probabilistic epistemic structure over \u03a6 and Mc is the corresponding common-interpretation structure over \u03a6\u00d7N , then\n(a) (M,\u03c9, i) in \u03c6 iff (Mc, \u03c9) \u03c6ini ;\n(b) (M,\u03c9, i) out \u03c6 iff (Mc, \u03c9) \u03c6outi .\nProof. We prove the result by induction on the structure of \u03c6. The argument for outermost scope is completely straightforward, and left to the reader. The argument for innermost scope is also straightforward, except for the case that \u03c6 has the form CBG\u03c8. We now consider this case carefully.\nBy definition,\n(Mc, \u03c9) (CBG\u03c8) in\ni\niff (Mc, \u03c9) CBG(\u2227j\u2208GBj\u03c8inj ) iff (Mc, \u03c9) (EBG)k(\u2227j\u2208GBj\u03c8inj ) for k = 1, 2, 3, . . ..\nNote that, by definition, (EBG\u03c8)ini = \u2227j\u2208GBj\u03c8 in j . Thus, by the induction hypothesis, it follows that\n(Mc, \u03c9) \u2227j\u2208GBj\u03c8 in j iff (M,\u03c9, i) in EBG.\nNow by a straightforward induction on k, we can show that\n(Mc, \u03c9) EB k(\u2227j\u2208GBj\u03c8 in j ) iff (M,\u03c9, i) in EBk+1G \u03c8.\nThat is,\n(Mc, \u03c9) CB(\u2227j\u2208GBj\u03c8 in j ) iff (M,\u03c9, i) in EBkG\u03c8 for k = 2, 3, 4, . . .. (1)\nIt immediately follows from (1) that if (M,\u03c9, i) in CBG\u03c8, then (Mc, \u03c9) CB(\u2227j\u2208GBj\u03c8inj ). The converse also follows from (1), once we show that (M,\u03c9, i) in EB2G\u03c8 implies (M,\u03c9, i) in EBG\u03c8. But this too follows easily since\n(M,\u03c9, i) in EB2G\u03c8 implies (M,\u03c9, i) in \u2227j\u2208GBj(\u2227j\u2208GBj\u03c8) implies (M,\u03c9, i) in \u2227j\u2208GBj(Bj\u03c8) iff (M,\u03c9, i) in \u2227j\u2208GBj\u03c8 iff (M,\u03c9, i) in EB\u03c8.\nThis completes the argument.\nTo see why we need we need the more complicated definition of (CBG\u03c8)ini , it is perhaps best to consider an example. By definition, (CB{1,2}p)in1 = CB{1,2}(B1(p, 1) \u2227 B2(p, 2)). By way of contrast, CB{1,2}(pin1 ) = CB{1,2}(p, 1), which (using arguments similar in spirit to those used above) can be shown to be equivalent to CB{1,2}(B1(p, 1) \u2227 B2(p, 1)). They key point here is whether we have B2(p, 1) or B2(p, 2). We want the latter, which is what we get from the more complicated translation that we use; it is easy to show that the former does not give the desired result. These issues do not arise with outermost scope.\nTheorem 4.1 shows that, from a modeler\u2019s point of view, there is no loss in working with common-interpretations structures. Any structure that uses ambiguous propositions can be converted to one that uses unambiguous propositions of the form (p, i). In a sense, this can be viewed as a strengthening of Theorem 3.1. Theorem 3.1 says that any formula that is satisfiable using innermost or outermost semantics in the presence of ambiguity is also satisfiable in a common-interpretation structure. However, that common-interpretation structure might be quite different from the original structure. Theorem 4.1 shows that if a formula \u03c6 is true according to agent i at a state \u03c9 in a structure M , then a variant of \u03c6 (namely, \u03c6ini or \u03c6 out\ni ) is true at state \u03c9 in essentially the same structure.\nMoreover, once we add propositions of the form (p, i) to the language, we have a great deal of additional expressive power. For example, we can say directly that agent i believes that all agents interpret p the same way that he does by writing Bi(\u2227j((p, i) \u21d4 (p, j))). We can also make more complicated statements, such as \u201cagent i believes that agents j and k interpret p the same way, although they interpret p differently from him: Bi((p, j) \u21d4 (p, k)) \u2227 \u00acBi((p, i) \u21d4 (p, j)). Clearly, far more subtle relationships among agents\u2019 interpretations of primitive propositions can be expressed in this language."}, {"heading": "5 Discussion", "text": "We have defined a logic for reasoning about ambiguity, and then showed that, in two senses, we really do not need structures with ambiguity: (1) the same axioms hold whether or not we have ambiguity, and (2) we can use a richer language to talk about the ambiguity, while giving\nan unambigious interpretation to all formulas. So why do we bother using structures with ambiguity? Perhaps the main reason is that it allows us to describe the situation from the agent\u2019s point of view. For example, if we are dealing with outermost scope, an agent does not realize that there are other interpretations possible other than the one he is using. Thus, the simpler language more directly captures agents\u2019 assertions. Similarly, a structure with ambiguity may more accurately describe a situation than a structure with a common interpretation. We thus believe that structures with ambiguity will prove to be a useful addition to a modeler\u2019s toolkit. In any case, whatever modeling framework and language is used, it is clear that we need to take ambiguity into account, and reason explicitly about it.\nThere are two extensions of our framework that we have not considered. First, we model ambiguity by allowing a formula to be interpreted differently by different agents, we assume that each individual agent disambiguates each formula. That is, no agent says \u201cI\u2019m not sure how to disambiguate \u03c6. It could correspond to the U of worlds, or it could correspond to U \u2032; I\u2019m not sure which is right.\u201d As we mentioned earlier, this view is closer to that of Lewis [1982] and Kuijer [2013]. It would involve a nontrivial change to our framework to capture this. Second, we have allowed only ambiguity about the meaning of primitive propositions (which then extends to ambiguity about the meaning of arbitrary formulas). But we have not considered ambiguity about the meaning of belief; for example, i might interpret belief in \u03c6 terms of having a proof of \u03c6 in some axiom system, while j might use a possible-worlds interpretation (as we do in this paper). Capturing this seems interesting, but quite difficult. Indeed, even without ambiguity, it is not nontrivial to design a logic that captures various resource-bounded notions of belief. (See [Fagin, Halpern, Moses, and Vardi 1995][Chapters 9\u201310] for more on this topic.)\nAcknowledgments: We thank Moshe Vardi and the anonymous reviewers of this paper for helpful comments. Halpern\u2019s work was supported in part by NSF grants IIS-0534064, IIS0812045, IIS-0911036, and CCF-1214844, A preliminary version of this work appeared as \u201cAmbiguous language and differences in beliefs\u201d in the Principles of Knowledge Representation and Reasoning: Proceedings of the Thirteenth International Conference, 2012, pp. 329\u2013 338. by AFOSR grants FA9550-08-1-0438, FA9550-12-1-0040, and FA9550-09-1-0266, and by ARO grant W911NF-09-1-0281. The work of Kets was supported in part by AFOSR grant FA9550-08-1-0389."}], "references": [{"title": "Agreeing to disagree", "author": ["R.J. Aumann"], "venue": "Annals of Statistics", "citeRegEx": "Aumann,? \\Q1976\\E", "shortCiteRegEx": "Aumann", "year": 1976}, {"title": "Reasoning about knowledge and probability", "author": ["R. Fagin", "J.Y. Halpern"], "venue": "Journal of the ACM", "citeRegEx": "Fagin and Halpern,? \\Q1994\\E", "shortCiteRegEx": "Fagin and Halpern", "year": 1994}, {"title": "Reasoning About Knowledge. Cambridge, Mass.: MIT Press. A slightly revised paperback", "author": ["R. Fagin", "J.Y. Halpern", "Y. Moses", "M.Y. Vardi"], "venue": null, "citeRegEx": "Fagin et al\\.,? \\Q1995\\E", "shortCiteRegEx": "Fagin et al\\.", "year": 1995}, {"title": "Naming and identity in epistemic logics, Part I: the propositional case", "author": ["A.J. Grove", "J.Y. Halpern"], "venue": "Journal of Logic and Computation", "citeRegEx": "Grove and Halpern,? \\Q1993\\E", "shortCiteRegEx": "Grove and Halpern", "year": 1993}, {"title": "Intransitivity and vagueness", "author": ["J.Y. Halpern"], "venue": "Review of Symbolic Logic", "citeRegEx": "Halpern,? \\Q2009\\E", "shortCiteRegEx": "Halpern", "year": 2009}, {"title": "Ambiguous language and consensus", "author": ["J.Y. Halpern", "W. Kets"], "venue": null, "citeRegEx": "Halpern and Kets,? \\Q2013\\E", "shortCiteRegEx": "Halpern and Kets", "year": 2013}, {"title": "Semantic interpretation and ambiguity", "author": ["G. Hirst"], "venue": "Artificial Intelligence", "citeRegEx": "Hirst,? \\Q1988\\E", "shortCiteRegEx": "Hirst", "year": 1988}, {"title": "Sequent systems for nondeterministic propostiinal logic without reflexivity", "author": ["L. Kuijer"], "venue": "In Fourth International Workshop on Logic, Rationality, and Interaction (LORI-IV), LNCS, Volume", "citeRegEx": "Kuijer,? \\Q2013\\E", "shortCiteRegEx": "Kuijer", "year": 2013}, {"title": "Logic for equivocators", "author": ["D. Lewis"], "venue": "Nou\u0302s", "citeRegEx": "Lewis,? \\Q1982\\E", "shortCiteRegEx": "Lewis", "year": 1982}, {"title": "Modeling ambiguity in a multi-agent system", "author": ["C. Monz"], "venue": "Proc. 12th Amsterdam Colloquium,", "citeRegEx": "Monz,? \\Q1999\\E", "shortCiteRegEx": "Monz", "year": 1999}, {"title": "Word sense disambiguation: a survey", "author": ["R. Navigli"], "venue": "ACM Computing Surveys", "citeRegEx": "Navigli,? \\Q2009\\E", "shortCiteRegEx": "Navigli", "year": 2009}, {"title": "The Logic of Inconsistency", "author": ["N. Rescher"], "venue": "Brandom", "citeRegEx": "Rescher and R.,? \\Q1979\\E", "shortCiteRegEx": "Rescher and R.", "year": 1979}, {"title": "Semantic Ambiguity and Underspecification", "author": ["K. van Deemter", "S. Peters"], "venue": null, "citeRegEx": "Deemter and Peters,? \\Q1996\\E", "shortCiteRegEx": "Deemter and Peters", "year": 1996}], "referenceMentions": [{"referenceID": 4, "context": "To model this formally, we can use a straightforward approach already used in [Halpern 2009; Grove and Halpern 1993]: formulas are interpreted relative to a player.", "startOffset": 78, "endOffset": 116}, {"referenceID": 3, "context": "To model this formally, we can use a straightforward approach already used in [Halpern 2009; Grove and Halpern 1993]: formulas are interpreted relative to a player.", "startOffset": 78, "endOffset": 116}, {"referenceID": 5, "context": "In a companion paper [Halpern and Kets 2013], we provide a different explanation, in terms of ambiguity.", "startOffset": 21, "endOffset": 44}, {"referenceID": 0, "context": "Our interest in ambiguity was originally motivated by a seminal result in game theory: Aumann\u2019s [1976] theorem showing that players cannot \u201cagree to disagree.", "startOffset": 87, "endOffset": 103}, {"referenceID": 6, "context": ", trying to decide from context which of the multiple meanings of a word are intended); see Hirst [1988] for a seminal contribution, and Navigli [2009] for a recent survey.", "startOffset": 92, "endOffset": 105}, {"referenceID": 6, "context": ", trying to decide from context which of the multiple meanings of a word are intended); see Hirst [1988] for a seminal contribution, and Navigli [2009] for a recent survey.", "startOffset": 92, "endOffset": 152}, {"referenceID": 6, "context": ", trying to decide from context which of the multiple meanings of a word are intended); see Hirst [1988] for a seminal contribution, and Navigli [2009] for a recent survey. However, there does not seem to be much work on incorporating ambiguity into a logic. Apart from the literature on the logic of context and on underspecification (see Van Deemter and Peters [1996]), the only papers that we are aware of that does this are ones by Monz [1999] and Kuijer [2013].", "startOffset": 92, "endOffset": 370}, {"referenceID": 6, "context": ", trying to decide from context which of the multiple meanings of a word are intended); see Hirst [1988] for a seminal contribution, and Navigli [2009] for a recent survey. However, there does not seem to be much work on incorporating ambiguity into a logic. Apart from the literature on the logic of context and on underspecification (see Van Deemter and Peters [1996]), the only papers that we are aware of that does this are ones by Monz [1999] and Kuijer [2013].", "startOffset": 92, "endOffset": 448}, {"referenceID": 6, "context": ", trying to decide from context which of the multiple meanings of a word are intended); see Hirst [1988] for a seminal contribution, and Navigli [2009] for a recent survey. However, there does not seem to be much work on incorporating ambiguity into a logic. Apart from the literature on the logic of context and on underspecification (see Van Deemter and Peters [1996]), the only papers that we are aware of that does this are ones by Monz [1999] and Kuijer [2013]. Monz allows for statements that have multiple interpretations, just as we do.", "startOffset": 92, "endOffset": 466}, {"referenceID": 8, "context": "For example, Lewis [1982] considers assigning truth values to an ambiguous formula \u03c6 by considering all possible disambiguations of \u03c6.", "startOffset": 13, "endOffset": 26}, {"referenceID": 4, "context": "Although the two notions are different\u2014a term is vague if it is not clear what its meaning is, and is ambiguous if it can have multiple meanings, Halpern [2009] also used agent-dependent interpretations in his model of vagueness, although the issues that arose were quite different from those that concern us here.", "startOffset": 146, "endOffset": 161}, {"referenceID": 1, "context": "The syntax of the logic is straightforward (and is, indeed, essentially the syntax already used in papers going back to Fagin and Halpern [1994]).", "startOffset": 120, "endOffset": 145}, {"referenceID": 1, "context": "There are standard approaches for interpreting this language [Fagin and Halpern 1994], but they all assume that there is no ambiguity, that is, that all players interpret the primitive propositions the same way.", "startOffset": 61, "endOffset": 85}, {"referenceID": 4, "context": "To allow for different interpretations, we use an approach used earlier [Halpern 2009; Grove and Halpern 1993]: formulas are interpreted relative to a player.", "startOffset": 72, "endOffset": 110}, {"referenceID": 3, "context": "To allow for different interpretations, we use an approach used earlier [Halpern 2009; Grove and Halpern 1993]: formulas are interpreted relative to a player.", "startOffset": 72, "endOffset": 110}, {"referenceID": 1, "context": "An axiomatization for this case is already given in [Fagin and Halpern 1994]; there is also a complete characterization of the complexity of determining whether a formula is valid.", "startOffset": 52, "endOffset": 76}, {"referenceID": 5, "context": "As shown in our companion paper [Halpern and Kets 2013], the equivalence result does not hold if we consider the innermost scope semantics and restrict attention to the subclasses of M and Mc that satisfy the common-prior assumption.", "startOffset": 32, "endOffset": 55}, {"referenceID": 1, "context": "We interpret these formulas using a standard epistemic probability structure M = (\u03a9, (\u03a0j)j\u2208N , (Pj)j\u2208N , \u03c0), with a common interpretation \u03c0, as in [Fagin and Halpern 1994].", "startOffset": 147, "endOffset": 171}, {"referenceID": 6, "context": "\u201d As we mentioned earlier, this view is closer to that of Lewis [1982] and Kuijer [2013].", "startOffset": 58, "endOffset": 71}, {"referenceID": 6, "context": "\u201d As we mentioned earlier, this view is closer to that of Lewis [1982] and Kuijer [2013]. It would involve a nontrivial change to our framework to capture this.", "startOffset": 75, "endOffset": 89}], "year": 2014, "abstractText": "Standard models of multi-agent modal logic do not capture the fact that information is often ambiguous, and may be interpreted in different ways by different agents. We propose a framework that can model this, and consider different semantics that capture different assumptions about the agents\u2019 beliefs regarding whether or not there is ambiguity. We examine the expressive power of logics of ambiguity compared to logics that cannot model ambiguity, with respect to the different semantics that we propose.", "creator": "LaTeX with hyperref package"}}}