{"id": "1401.3890", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "16-Jan-2014", "title": "Analyzing Search Topology Without Running Any Search: On the Connection Between Causal Graphs and h+", "abstract": "The ignoring delete lists relaxation is of paramount importance for both satisficing and optimal planning. In earlier work, it was observed that the optimal relaxation heuristic h+ has amazing qualities in many classical planning benchmarks, in particular pertaining to the complete absence of local minima. The proofs of this are hand-made, raising the question whether such proofs can be lead automatically by domain analysis techniques. In contrast to earlier disappointing results -- the analysis method has exponential runtime and succeeds only in two extremely simple benchmark domains -- we herein answer this question in the affirmative. We establish connections between causal graph structure and h+ topology. This results in low-order polynomial time analysis methods, implemented in a tool we call TorchLight. Of the 12 domains where the absence of local minima has been proved, TorchLight gives strong success guarantees in 8 domains. Empirically, its analysis exhibits strong performance in a further 2 of these domains, plus in 4 more domains where local minima may exist but are rare. In this way, TorchLight can distinguish easy domains from hard ones. By summarizing structural reasons for analysis failure, TorchLight also provides diagnostic output indicating domain aspects that may cause local minima. The following table displays an example of an example of an example of an example of an example of an example of an example of an example of an example of an example of an example of an example of an example of an example of an example of an example of an example of an example of an example of an example of an example of an example of an example of an example of an example of an example of an example of an example of an example of an example of an example of an example of an example of an example of an example of an example of an example of an example of an example of an example of an example of an example of an example of an example of an example of an example of an example of an example of an example of an example of an example of an example of an example of an example of an example of an example of an example of an example of an example of an example of an example of an example of an example of an example of an example of an example of an example of an example of an example of an example of an example of an example of an example of an example of an example of an example of an example of an example of an example of an example of an example of an example of an example of an example of an example of an example of an example of an example of an example of an", "histories": [["v1", "Thu, 16 Jan 2014 05:16:17 GMT  (578kb)", "http://arxiv.org/abs/1401.3890v1", null]], "reviews": [], "SUBJECTS": "cs.AI", "authors": ["joerg hoffmann"], "accepted": false, "id": "1401.3890"}, "pdf": {"name": "1401.3890.pdf", "metadata": {"source": "CRF", "title": "Analyzing Search Topology Without Running Any Search: On the Connection Between Causal Graphs and h+", "authors": ["J\u00f6rg Hoffmann"], "emails": ["joerg.hoffmann@inria.fr"], "sections": [{"heading": "1. Introduction", "text": "The ignoring delete lists relaxation has been since a decade, and still is, of paramount importance for effective satisficing planning (e.g., McDermott, 1999; Bonet & Geffner, 2001; Hoffmann & Nebel, 2001a; Gerevini, Saetti, & Serina, 2003; Helmert, 2006; Richter & Westphal, 2010). More recently, heuristics making this relaxation have also been shown to boost optimal planning (Karpas & Domshlak, 2009; Helmert & Domshlak, 2009). The planners using the relaxation approximate, in a variety of ways, the optimal relaxation heuristic h+ which itself is NP-hard to compute (Bylander, 1994). As was observed in earlier work (Hoffmann, 2005), h+ has some rather amazing qualities in many classical planning benchmarks. Figure 1 gives an overview of these results.1\nThe results divide domains into classes along two dimensions. We herein ignore the horizontal dimension, pertaining to dead ends, for which domain analysis is already available: easy-to-test powerful criteria implying that a task is \u201cundirected\u201d/\u201dharmless\u201d are known (e.g., Hoffmann, 2005). The vertical dimension divides the domains into three classes, with respect to the behavior of exit distance, defined as d\u2212 1 where d is the distance to a state with strictly smaller h+ value. In the \u201ceasiest\u201d bottom class, there exist constant upper\n1. We omit ADL domains, and we add the more recent IPC benchmarks Elevators and Transport (without action costs), for which these properties are trivial to prove based on the earlier results. Blocksworld-Arm is the classical blocksworld, Blocksworld-NoArm is a variant allowing to \u201cmove A from B to C\u201d directly.\nc\u00a92011 AI Access Foundation. All rights reserved.\nbounds on exit distance from both, states on local minima and states on benches (flat regions). In the figure, the bounds are given in square brackets. For example, in Logistics, the bound for local minima is 0 \u2013 meaning that no local minima exist at all \u2013 and the bound for benches is 1. In the middle class, a bound exists only for local minima; that bound is 0 (no local minima at all) for all domains shown. In the \u201chardest\u201d top class, both local minima and benches may take arbitrarily many steps to escape.\nThe proofs underlying Figure 1 are hand-made. For dealing with unseen domains, the question arises whether we can design domain analysis methods leading such proofs automatically. The potential uses of such analysis methods are manifold; we discuss this at the end of the paper. For now, note that addressing this question is a formidable challenge. We are trying to automatically infer properties characterizing the informativeness (or lack thereof) of a heuristic function. We wish to do this based on a static analysis, not actually running any search. Formally characterizing the informativeness of a heuristic function is, in most cases, hardly possible even for experienced researchers, which explains perhaps why no-one so far has even attempted to do it automatically. The single exception, to the best of the author\u2019s knowledge, is an analysis method mentioned on the side in the author\u2019s earlier work (Hoffmann, 2005). This analysis method builds an exponentially large tree structure summarizing all ways in which relaxed plans may generate facts. The tree size, and therewith the analysis runtime, explodes quickly with task size. Worse, the analysis succeeds only in Movie and Simple-TSP \u2013 arguably the two most simplistic planning benchmarks in existence.2\nBy contrast, the TorchLight tool developed herein has low-order polynomial runtime and usually terminates in split seconds. Distinguishing between global (per task) and local (per state) analysis, it proves the global absence of local minima in Movie, Simple-TSP, Logistics, and Miconic-STRIPS. It gives a strong guarantee for local analysis \u2013 to succeed in every state \u2013 in Ferry, Gripper, Elevators, and Transport. Taking the success rate to be the fraction of states for which local analysis succeeds, TorchLight empirically exhibits strong performance \u2013 delivering high success rates \u2013 also in Zenotravel, Satellite, Tyreworld, Grid, Driverlog, and\n2. Simple-TSP encodes TSP but on a fully connected graph with uniform edge cost. The domain was introduced by Fox and Long (1999) as a benchmark for symmetry detection.\nRovers. Thus TorchLight\u2019s success rates tend to be high in the \u201ceasy\u201d domains of Figure 1, while they are low in the \u201chard\u201d ones, serving to automatically distinguish between these two groups.3 By summarizing structural reasons for analysis failure, TorchLight finally provides diagnostic output indicating problematic aspects of the domain, i.e., operator effects that potentially cause local minima under h+.\nWhat is the key to this performance boost? Consider Logistics and Blocksworld-Arm. At the level of their PDDL domain descriptions, the difference is not evident \u2013 both have delete effects, so why do those in Blocksworld-Arm \u201churt\u201d and those in Logistics don\u2019t? What does the trick is to move to the finite-domain variable representation (e.g., Jonsson & Ba\u0308ckstro\u0308m, 1998; Helmert, 2006, 2009) and to consider the associated structures, notably the causal graph (e.g., Knoblock, 1994; Jonsson & Ba\u0308ckstro\u0308m, 1995; Domshlak & Dinitz, 2001; Helmert, 2006) capturing the precondition and effect dependencies between variables. The causal graph of Blocksworld-Arm contains cycles. That of Logistics doesn\u2019t. Looking into this, it was surprisingly easy to derive the following basic result:\nIf the causal graph is acyclic, and every variable transition is invertible, then there are no local minima under h+.\nThis result is certainly interesting in that, for the first time, it establishes a connection between causal graph structure and h+ topology. However, by itself the result is much too weak for domain analysis \u2013 of the considered benchmarks, it applies only in Logistics. We devise generalizations and approximations yielding the analysis results described above. Aside from their significance for domain analysis, our techniques are also interesting with respect to research on causal graphs. Whereas traditional methods (e.g., Jonsson & Ba\u0308ckstro\u0308m, 1995; Brafman & Domshlak, 2003; Jonsson, 2009; Gime\u0301nez & Jonsson, 2009a) seek execution paths solving the overall task, we seek \u201conly\u201d execution paths decreasing the value of h+. In local analysis, this enables us to consider only small fragments of the causal graph, creating the potential to successfully analyze states in tasks whose causal graphs are otherwise arbitrarily complex.\nThe next section gives a brief background on planning with finite-domain variables, and the associated notions such as causal graphs and the definition of h+ and its topology. Section 3 then gives an illustrative example explaining our basic result, and Section 4 provides a synopsis of our full technical results relating causal graphs and h+ topology. Sections 5 and 6 present these results in some detail, explaining first how we can analyze a state s provided we are given an optimal relaxed plan for s as the input, and thereafter providing criteria on causal graph structure implying that such analysis will always succeed. We evaluate the domain analysis technique by proving a number of domain-specific performance guarantees in Section 7, and reporting on a large-scale experiment with TorchLight in Section 8. We point to related work within its context where appropriate, and discuss details in Section 9. We close the paper with a discussion of future work in Section 10. To improve readability, the main text omits many technical details and only outlines the proofs. The full details including proofs are in Appendix A.\n3. To some extent, this particular result can also be achieved by simpler means (limited search probing). We discuss this along with the experiments in Section 8."}, {"heading": "2. Background", "text": "We adopt the terminology and notation of Helmert (2006), with a number of modifications suiting our purposes. A (finite-domain variable) planning task is a 4-tuple (X, sI , sG, O). X is a finite set of variables, where each x \u2208 X is associated with a finite domain Dx. A partial state over X is a function s on a subset Xs of X, so that s(x) \u2208 Dx for all x \u2208 Xs; s is a state if Xs = X. The initial state sI is a state. The goal sG is a partial state. O is a finite set of operators. Each o \u2208 O is a pair o = (preo, effo) of partial states, called its precondition and effect. As simple non-restricting sanity conditions, we assume that |Dx| > 1 for all x \u2208 X, and preo(x) 6= effo(x) for all o \u2208 O and x \u2208 Xpreo \u2229Xeffo .\nWe identify partial states with sets of variable-value pairs, which we will often refer to as facts. The state space S of the task is the directed graph whose vertices are all states over X, with an arc (s, s\u2032) iff there exists o \u2208 O such that preo \u2286 s, effo \u2286 s\u2032, and s(x) = s\u2032(x) for all x \u2208 X \\Xeffo . A plan is a path in S leading from sI to a state s with sG \u2286 s.\nWe next define the two basic structures in our analysis: domain transition graphs and causal graphs. For the former, we diverge from Helmert\u2019s definition (only) in that we introduce additional notations indicating the operator responsible for the transition, as well as the \u201cside effects\u201d of the transition, i.e., any other variable values set when executing the responsible operator. In detail, let x \u2208 X. The domain transition graph DTGx of x is the labeled directed graph with vertex set Dx and the following arcs. For each o \u2208 O where x \u2208 Xpreo \u2229Xeffo with c := preo(x) and c\n\u2032 := effo(x), DTGx contains an arc (c, c\u2032) labeled with responsible operator rop(c, c\u2032) := o, with conditions cond(c, c\u2032) := preo \\ {(x, c)}, and with side effects seff(c, c\u2032) := effo \\ {(x, c\u2032)}. For each o \u2208 O where x \u2208 Xeffo \\Xpreo with c\u2032 := effo(x), for every c \u2208 Dx with c 6= c\u2032, DTGx contains an arc (c, c\u2032) labeled with rop(c, c\u2032) := o, cond(c, c\u2032) := preo, and seff(c, c\u2032) := effo \\ {(x, c\u2032)}.\nThe reader familiar with causal graphs may have wondered why we introduced a notion of side effects, seeing as causal graphs can be acyclic only if all operators are unary (affect only a single variable). The reason is that we do handle cases where operators are nonunary. The variant of causal graphs we use can still be acyclic in such cases, and indeed this happens in some of our benchmark domains, specifically in Simple-TSP, Movie, MiconicSTRIPS, and Satellite. We define the support graph SG to be the directed graph with vertex set X, and with an arc (x, y) iff DTGy has a relevant transition (c, c\u2032) so that x \u2208 Xcond(c,c\u2032). Here, a transition (c, c\u2032) on variable x is called relevant iff (x, c\u2032) \u2208 sG \u222a \u22c3 o\u2208O preo.\nOur definition modifies the most commonly used one in that it uses relevant transitions only, and that it does not introduce arcs between variables co-occurring in the same operator effect (unless these variables occur also in the precondition). Transitions with side effects are handled separately in our analysis. Note that irrelevant transitions occur naturally, in domains with non-unary operators. For example, unstacking a block induces the irrelevant transition making the arm non-empty, and departing a passenger in Miconic-STRIPS makes the passenger \u201cnot-boarded\u201d.4\nConsider now the definition of h+. In the more common Boolean-variable setting of PDDL, this is defined as the length of a shortest plan solving the problem when ignoring\n4. We remark that relevant transitions correspond to what has been called \u201crequestable values\u201d in some works, (e.g., Jonsson & Ba\u0308ckstro\u0308m, 1998; Haslum, 2007). In Fast Downward\u2019s implementation, the causal graph includes only precondition-effect arcs, similarly as the support graph defined here.\nall delete lists, i.e., the negative operator effects (Bylander, 1994; McDermott, 1999; Bonet & Geffner, 2001). This raises the question what h+ actually is, in finite-domain variable planning, where there are no \u201cdelete lists\u201d. That question is easily answered. \u201cIgnoring deletes\u201d essentially means to act as if \u201cwhat was true once will remain true forever\u201d. In the finite-domain variable setting, this simply means to not over-write any values that the variables had previously. To our knowledge, this generalization was first described by Helmert (2006). Consider the directed graph S+ whose vertices are all sets s+ of variablevalue pairs over X, with an arc (s+1 , s + 2 ) iff there exists o \u2208 O such that preo \u2286 s + 1 and s+2 = s + 1 \u222a effo. If s is a state, then a relaxed plan for s is a path in S+ leading from s to s+ with sG \u2286 s+. By h+(s) we denote the length of a shortest relaxed plan for s, or h+(s) = \u221e if no such plan exists. It is easy to see that this definition corresponds to the common Boolean one: if we translate the finite-domain variables into Boolean ones by creating one Boolean variable \u201cis-(x, c)-true?\u201d for every fact (x, c), then standard h+ in the Boolean task is identical to h+ in the finite-domain variable task.\nBylander (1994) proved that it is intractable to compute h+. Many state-of-the-art planners approximate h+, in a variety of ways (e.g., McDermott, 1999; Bonet & Geffner, 2001; Hoffmann & Nebel, 2001a; Gerevini et al., 2003; Helmert, 2006; Richter, Helmert, & Westphal, 2008; Richter & Westphal, 2010). A popular approximation in satisficing planning \u2013 that gives no guarantees on the quality of the relaxed plan returned \u2013 is the so-called relaxed plan heuristic first proposed in the FF system (Hoffmann & Nebel, 2001a), which approximates h+ in terms of the length of some not necessarily shortest relaxed plan. Such relaxed plans can be computed in low-order polynomial time using techniques inspired by Graphplan (Blum & Furst, 1997).\nWe next introduce the relevant notations pertaining to search space topology under h+. Let s \u2208 S be a state where 0 < h+(s) < \u221e. Then an exit is a state s\u2032 reachable from s in S, so that h+(s\u2032) = h+(s) and there exists a neighbor s\u2032\u2032 of s\u2032 so that h+(s\u2032\u2032) < h+(s\u2032) (and thus h+(s\u2032\u2032) < h+(s)). The exit distance ed(s) of s is the length of a shortest path to an exit, or ed(s) = \u221e if no exit exists. A path in S is called monotone iff there exist no two consecutive states s1 and s2 on it so that h+(s1) < h+(s2). We say that s is a local minimum if there exists no monotone path to an exit.\nThe topology definitions, adapted from the author\u2019s previous work (Hoffmann, 2005), are specific to h+ only for the sake of simplicity (we will herein not consider any heuristics other than h+).5 States with infinite heuristic value are ignored because they are correctly identified, by the heuristic, to be dead ends (relaxed-plan based approximations like that of FF do identify all these cases). If the heuristic value is 0 then we have already reached the goal, so this case can also be safely ignored. Note that we do not force exit paths to be monotone, i.e., we will also talk about exit distances in situations where s may be a local minimum. This is necessary to capture the structure of domains like Satellite and Zenotravel, where local minima exist but their exit distance is bounded. Also, some of our analysis methods guarantee an upper bound on the length of an exit path only, not that the heuristic values on that path will decrease monotonically.\n5. We remark that the original definitions are significantly more involved, e.g., defining \u201clocal minima\u201d not based on individual states but based on strongly connected sub-graphs of the state space. None of these complications is relevant to the results herein.\nFinally, let us say a few words on domain analysis. Generally speaking, domain analysis aims at automatically obtaining non-trivial information about a domain or planning task. Such analysis has a long tradition in planning (e.g., Nebel, Dimopoulos, & Koehler, 1997; Fox & Long, 1998; Gerevini & Schubert, 1998; Edelkamp & Helmert, 1999; Rintanen, 2000). Most often, the information sought pertains to reachability or relevance properties, i.e., which entities or combinations thereof are reachable from the initial state/relevant to the goal. A notable exception is the work of Long and Fox (2000) which automatically recognizes certain \u201cgeneric types\u201d of domains, like transportation. However, there exists no prior work at all trying to automatically infer topological properties of a heuristic function. The single exception are the aforementioned disappointing results reported (as an aside) in the author\u2019s previous work (Hoffmann, 2005). This method builds a structure called \u201cfact generation tree\u201d, enumerating all ways in which facts may support each other in a non-redundant relaxed plan. If there is no \u201cconflict\u201d then h+ is the exact solution distance. Clearly, this is a far too strong property to be applicable in any reasonably complex domain. Of the considered benchmarks, the property applies only in Simple-TSP. A slightly more general property, also identified in this work, applies in Movie as well as trivial Logistics tasks with 2 locations, 1 truck, and 1 package.\nIt is worth noting that analyzing the topology of h+ is computationally hard:\nTheorem 1. It is PSPACE-complete to decide whether or not the state space of a given planning task contains a local minimum, and given an integer K it is PSPACE-complete to decide whether or not for all states s we have ed(s) \u2264 K. Further, it is PSPACE-complete to decide whether or not a given state s is a local minimum, and given an integer K it is PSPACE-complete to decide whether or not ed(s) \u2264 K.\nThese results are hardly surprising, but have not been stated anywhere yet. The membership results in Theorem 1 are easy to prove based on guess-and-check arguments similar as given by Bylander (1994), exploiting the fact that NPSPACE=PSPACE. The hardness results still hold when restricting the input to solvable tasks/states. Their proofs work by reducing plan existence, respectively bounded plan existence (with a bound in non-unary representation). Given a task whose plan existence we wish to decide, we flatten h+ by a new operator that can always achieve the goal but that has a fatal side effect. Then we give the planner the choice between solving this task, or solving a new alternative task. That latter task is designed so that a local minimum exists/that the exit distance exceeds the bound iff the planner must choose the alternative task, i.e., iff the original task is unsolvable/iff it cannot be solved within a given number of steps. The full proof is in Appendix A.1.\nIn practice, computational hardness here is particularly challenging because, in most applications of domain analysis, we are not willing to run a worst-case exponential search. After all, the analysis will not actually solve the problem. Consequently, in the present research, we restrict ourselves to analysis methods with low-order polynomial runtime.\nThe reader will have noticed the state-specific analysis problems in Theorem 1. We distinguish between global analysis per-task, and local analysis per-state. More precisely, we herein devise three kinds of analyses:\n(I) Guaranteed global analysis. Taking as input the planning task description, this analysis returns \u201cyes, d\u201d only if the state space does not contain any local minima and the exit distance from any state is bounded by d.\n(II) Guaranteed local analysis. Taking as input the planning task description and a state s, this analysis returns \u201cyes, d\u201d only if s is not a local minimum, and the exit distance from s is bounded by d.\n(III) Approximate local analysis. Taking as input the planning task description and a state s, this analysis returns \u201cyes, d\u201d to indicate that s is not a local minimum, and that the exit distance from s is bounded by d. Both may be wrong, i.e., the analysis is not guaranteed to be sound. Compared to analysis (II), this trades soundness for the ability to successfully analyze more states.\nDomain analysis traditionally considers only the global variant (I), or even more generalizing variants looking at only the PDDL domain file. While global once-and-for-all analysis is also the \u201choly grail\u201d in our work, local analysis has strong advantages. If a planning task does contain local minima \u2013 which one would expect to typically be the case in interesting domains \u2013 then analysis (I) is useless. It will simply answer \u201cno\u201d. By contrast, local analysis (II,III) may still detect some individual states, that we sample randomly in our experiments, to not be local minima. The percentage of such states, which we refer to as the success rate, can deliver useful information no matter what the structure of the planning task is. Note also that, while the contrast between a PSPACE-hard problem and low-order polynomial analysis runtime necessarily implies that all analyses are incomplete, the local analyses have a chance to ameliorate this by averaging their outcome over a set of sample states."}, {"heading": "3. An Illustrative Example", "text": "The basic connection we identify between causal graphs and h+ topology \u2013 more precisely, between support graphs, domain transition graphs, and h+ topology \u2013 is quite simple. It is instructive to understand this first, before delving into the full results. Figure 2 shows fragments of the domain transition graphs (DTGs) of three variables x0, x1, and x2. All DTG transitions here are assumed to be invertible, and to have no side effects.\nThe imaginative reader is invited to think of x0 as a car whose battery is currently empty and that therefore requires the help of two people, x1 and x2, in order to push-start it. The people may, to solve different parts of the task, be required for other purposes too, but here we consider only the sub-problem of achieving the goal x0 = g0. We wish to take\nthe x0 transition t0, which has the two conditions c1 and c2. These conditions are currently not fulfilled. In the state s at hand, x1 is in s1 and x2 is in s2. We must move to a different state, s0, in which x1 = c1 and x2 = c2. What will happen to h+ along the way?\nSay that an optimal relaxed plan P+(s) for s moves x1 to c1 along the path marked T1, and moves x2 to c2 along the path marked T2 \u2013 clearly, some such paths will have to be taken by any P+(s). Key observation (1) is similar to a phenomenon known from transportation benchmarks. When moving x1 and x2, whichever state s\u2032 we are in, as long as s\u2032 remains within the boundaries of the values traversed by T1 and T2, we can construct a relaxed plan P+(s\u2032) for s\u2032 so that |P+(s\u2032)| \u2264 |P+(s)|. Namely, to obtain P+(s\u2032), we simply replace the respective move sequence \u2212\u2192o i in P+(s), for i = 1, 2, with its inverse \u2190\u2212o i. For example, say we got to s\u2032 by \u2212\u2192o 1 = \u3008R1, R2, R3\u3009 moving x1 to c1, as indicated in Figure 2. Then wlog P+(s) has the form \u3008R1, R2, R3\u3009 \u25e6 P . We define P+(s\u2032) := \u3008L3, L2, L1\u3009 \u25e6 P . The postfix P of both relaxed plans is the same; at the end of the prefix, the set of values achieved for x1, namely s1, c1, and the two values in between, is also the same. Thus P+(s\u2032) is a relaxed plan for s\u2032.6 This is true in general, i.e., \u2190\u2212o 1 is necessarily applicable in s\u2032, and will achieve, within relaxed execution of P+(s\u2032), the same set of facts as achieved by \u2212\u2192o 1 in P+(s). Thus h+(s\u2032) \u2264 h+(s) for any state s\u2032, including the state s0 we\u2019re after.\nKey observation (2) pertains to the \u201cleaf\u201d variable, x0. Say that x0 moves only for its own sake, i.e., the car position is not important for any other goal. Then executing t0 in s0 does not delete anything needed anywhere else. Thus we can remove rop(t0) from the relaxed plan P+(s0) for s0 \u2013 constructed as per observation (1) \u2013 to obtain a relaxed plan for the state s1 that results from executing t0 in s0. Hence h+(s1) < h+(s). With observation (1), the heuristic values along the path to s1 are all \u2264 h+(s). We know that at least one state s\u2032\u2032 on the path has a heuristic value strictly smaller than h+(s): this happens at the latest in s\u2032\u2032 = s1, and may happen earlier on in case the relaxed plan P+(s\u2032\u2032) as constructed here is not optimal (cf. Footnote 6). Let s\u2032\u2032 be the earliest state with h+(s\u2032\u2032) < h+(s) on the path, and let s\u2032 be the state preceding s\u2032\u2032. Then s\u2032 is an exit for s, and the path to that exit is monotone. Thus s is not a local minimum. As for the exit distance, in the worst case we have s\u2032\u2032 = s1 and s\u2032 = s0, so ed(s) is bounded by the length of the path up to s0.\nIt is not difficult to imagine that the above works also if preconditions need to be established recursively, as long as no cyclic dependencies exist. A third person may be needed to first persuade x1 and x2, the third person may need to take a bus, and so on. The length of the path to s0 may grow exponentially \u2013 if x1 depends on x3 then each move of x1 may require several moves of x3, and so forth \u2013 but we will still be able to construct P+(s\u2032) by inverting the moves of all variables individually. Further, the inverting transitions may have conditions, too, provided these conditions are the same as required by the original moves. For example, in the above, the inverting operator L1 may have an arbitrary condition p if that condition is also required for R1. This is because any conditions that are required for the original moves (like p for R1) are established in P+(s), and thus will be established in P+(s\u2032) in time for the inverse moves (like L1).\n6. Note that P+(s\u2032) may not be an optimal relaxed plan for s\u2032. If P+(s) does not move x1 for anything other than attaining c1, then the postfix P alone is a relaxed plan for s\n\u2032: there is no need to insert the inverted prefix \u3008L3, L2, L1\u3009. In cases like this, we obtain an exit state already on the path to s0; we get back to this below.\nNow, say that the support graph is acyclic, and that all transitions are invertible and have no side effects. Given any state s, unless s is already a goal state, some variable x0 moving only for its own sake necessarily exists. But then, within any optimal relaxed plan for s, a situation as above exists, and therefore we have a monotone exit path, Q.E.D. for no local minima under h+.\nThe execution path construction just discussed is not so different from known results exploiting causal graph acyclicity and notions of connectedness or invertibility of domain transition graphs (e.g., Jonsson & Ba\u0308ckstro\u0308m, 1995; Williams & Nayak, 1997). What is new here is the connection to h+.\nWe remark that the hand-made analysis of h+ (Hoffmann, 2005) uses a notion of operators \u201crespected by the relaxation\u201d. An operator o is respected by the relaxation iff, whenever o starts an optimal plan for s, then o also starts an optimal relaxed plan for s. A core property of many of the hand-made proofs is that all operators are respected by the relaxation. This motivated the speculation that recognizing this property automatically could be key to domain analysis recognizing the absence of local minima under h+. We do not explore this option herein, however we note that even the basic result we just outlined contains cases not covered by this property. Even with acyclic support graph and invertible transitions without side effects, there are examples where an operator is not respected by the relaxation. We give such a construction in Example 1, Appendix A.4."}, {"heading": "4. Synopsis of Technical Results", "text": "Our technical results in what follows are structured in a way similar to the proof argument outlined in the previous section. The results are structured into two parts, (A) and (B). In (A), Section 5, we identify circumstances under which we can deduce from an optimal relaxed plan that a monotone exit path exists. In (B), Section 6, we devise support-graph based sufficient criteria implying that analysis (A) will always succeed. Technique (B) underlies TorchLight\u2019s conservative analysis methods, i.e., guaranteed global analysis (I) and guaranteed local analysis (II) as described at the end of Section 2. By feeding technique (A) with the usual relaxed plans as computed, e.g., by FF\u2019s heuristic function, we obtain TorchLight\u2019s approximate local analysis (III). That analysis does not give a guarantee, because (and only because) FF\u2019s relaxed plans are not guaranteed to be optimal.\nFor ease of reading, we now give a brief synopsis of the results obtained in (A) and (B), and how they provide the analysis methods (I)\u2013(III). The synopsis contains sufficient information to understand the rest of the paper, so the reader may choose to skip Sections 5 and 6, moving directly to the evaluation.\nEach analysis method is based on a particular kind of sub-graph of the support graph. Table 1 overviews these. Their role in parts (A) and (B) is as follows:\n(A) Given an optimal relaxed plan P+(s) for a state s, an optimal rplan dependency graph oDG+ is a sub-graph of SG with a single leaf variable x0 with transition t0 as in our example (rop(t0) will be frequently referred to as o0). An arc (x, x\u2032) is in oDG+ if P+(s) relies on x\u2032 to achieve the conditions of t0, and P+(s) relies on x for moving x\u2032. We say that oDG+ is successful if it is acyclic, all involved transitions will be usable in our exit path construction (e.g., they have no harmful side effects), and the deletes of t0\nare either not relevant to P+(s) at all, or are being recovered inside P+(s). The main result, Theorem 2, states that s is no local minimum if there exists a successful oDG+ for s. It also derives an exit distance bound from oDG+. Approximating Theorem 2 by applying it to a relaxed plan as computed by FF\u2019s heuristic yields analysis (III).\n(B) Given a state s, a local dependency graph lDG is a sub-graph of SG with a single leaf variable x0, whose goal value is yet unachieved, and all of whose transitive successors in SG have already attained their goal values. In this setting, x0 \u201cmoves for its own sake\u201d as in the example. The graph lDG simply includes all SG predecessors of x0, the single exception pertaining to arcs (x, x0) into x0 itself, which are not inserted if the corresponding condition of t0 is already satisfied in s. We say that lDG is successful if it is acyclic, all involved transitions will be usable in our exit path construction, and t0 does not have any relevant deletes. This implies that there exists a successful oDG+\ncontained in lDG, and thus we have Theorem 3, stating that s is no local minimum and giving a corresponding exit distance bound. This result underlies analysis (II).\nA global dependency graph gDG is a sub-graph of SG that identifies any goal variable x0, and includes all SG predecessors of x0. Being successful is defined in the same way as for lDGs. If all gDGs are successful, then Theorem 3 will apply to every state because each lDG is contained in a successful gDG. Thus we have Theorem 4, stating that the state space does not contain any local minima. The exit distance bound is obtained by maximizing over all gDGs. This result underlies analysis (I).\nFor understanding the practical performance of TorchLight, it is important to note that (A) is not only a minimal result that would suffice to prove (B). The cases identified by Theorem 2 are much richer than what we can actually infer from support graphs. For this reason, analysis (III), while not sound due to the use of potentially non-optimal relaxed plans, is able to analyze a much larger class of states than analysis (II). In a little detail, the difference between the two methods pertains to (1) whether \u201cP+(s) relies on values of x for moving x\u2032\u201d, and (2) whether \u201cthe deletes of t0 are being recovered inside P+(s)\u201d. Neither (1) nor (2) are visible in the support graph, because both rely on details of the form of the relaxed plan P+(s). For example, consider the Gripper domain. Notion (1) is important because the support graph contains the arcs (\u201ccarry-ball-b\u201d, \u201dfree-gripper\u201d) \u2013 due to dropping ball b \u2013 and (\u201dfree-gripper\u201d, \u201ccarry-ball-b\u201d) \u2013 due to picking up ball b. Thus, looking only at SG, it seems that \u201ccarry-ball-b\u201d may support itself (free the gripper\nby dropping the ball we want to pick up). Of course, that doesn\u2019t happen in an optimal relaxed plan. Notion (2) is important because some operators (picking up a ball) do have harmful side effects (making the gripper hand non-empty), but these side effects are always recovered inside the relaxed plan (when dropping the ball again later on). It remains future work to extend analyses (I,II) so that they can detect these kinds of phenomenona."}, {"heading": "5. Analyzing Optimal Relaxed Plans", "text": "We consider a state s and an optimal relaxed plan P+(s) for s. To describe the circumstances under which a monotone exit path is guaranteed to exist, we will need a number of notations pertaining to properties of transitions etc. We will introduce these notations along the way, rather than up front, in the hope that this makes them easier to digest.\nGiven o0 \u2208 P+(s), by P+<0(s) and P + >0(s) we denote the parts of P +(s) in front of o0 and behind o0, respectively. By P+(s, x) we denote the sub-sequence of P+(s) affecting x. We capture the dependencies between the variables used in P+(s) for achieving the precondition of o0, as follows:\nDefinition 1. Let (X, sI , sG, O) be a planning task, let s \u2208 S with 0 < h+(s) < \u221e, let P+(s) be an optimal relaxed plan for s, let x0 \u2208 X, and let o0 \u2208 P+(s) be an operator taking a relevant transition of the form t0 = (s(x0), c).\nAn optimal rplan dependency graph for P+(s), x0 and o0, or optimal rplan dependency graph for P+(s) in brief, is a graph oDG+ = (V,A) with unique leaf vertex x0, and where x \u2208 V and (x, x\u2032) \u2208 A if either: x\u2032 = x0, x \u2208 Xpreo0 , and preo0(x) 6= s(x); or x 6= x\n\u2032 \u2208 V \\ {x0} and there exists o \u2208 P+<0(s) taking a relevant transition on x\u2032 so that x \u2208 Xpreo and preo(x) 6= s(x).\nFor x \u2208 V \\ {x0}, by oDTG+x we denote the sub-graph of DTGx that includes only the values true at some point in P+<0(s, x), the relevant transitions t using an operator in P+<0(s, x), and at least one relevant inverse of such t where a relevant inverse exists. We refer to the P+<0(s, x) transitions as original, and to the inverse transitions as induced.\nThe transition t0 with responsible operator o0 will be our candidate for reaching the exit state, like t0 in Figure 2. oDG+ collects all variables x connected to a variable x\u2032 insofar as P+<0(s) uses an operator preconditioned on x in order to move x \u2032. These are the variables we will need to move, like x1 and x2 in Figure 2, to obtain a state s0 where t0 can be taken. For any such variable x, oDTG+x captures the domain transition graph fragment that P+<0(s) traverses and within which we will stay, like T1 and T2 in Figure 2.\nNote that there is no need to consider the operators P+>0(s) behind o0, simply because these operators are not used in order to establish o0\u2019s precondition. This is of paramount importance in practice. An example is the Gripper situation mentioned above. if o0 picks up a ball b in Gripper, then P+(s) will also contain \u2013 behind o0, i.e., in P+>0(s) \u2013 an operator o\u2032 dropping b. If we considered o\u2032 in Definition 1, then oDG+ would contain the mentioned cycle assuming that o\u2032 is used for making the gripper hand free for picking up b. In TorchLight\u2019s approximate local analysis, whenever we consider an operator o0, before we build oDG+ we re-order P+(s) by moving operators behind o0 if possible. This minimizes P+<0(s), and oDG + thus indeed contains only the necessary variables and arcs.\nUnder which circumstances will t0 actually \u201cdo the job\u201d? The sufficient criterion we identify is rather complex. To provide an overview of the criterion, we next state its definition. The items in this definition will be explained below.\nDefinition 2. Let (X, sI , sG, O), s, P+(s), x0, o0, t0, and oDG+ = (V,A) be as in Definition 1. We say that oDG+ is successful if all of the following holds:\n(1) oDG+ is acyclic.\n(2) We have that either:\n(a) the oDG+-relevant deletes of t0 are P+>0(s)-recoverable; or (b) s(x0) is not oDG+-relevant, and t0 has replaceable side effect deletes; or (c) s(x0) is not oDG+-relevant, and t0 has recoverable side effect deletes.\n(3) For x \u2208 V \\ {x0}, all oDTG+x transitions either have self-irrelevant deletes, or are invertible/induced and have irrelevant side effect deletes and no side effects on V \\{x0}.\nAs already outlined, our exit path construction works by staying within the ranges of oDTG+x , for x \u2208 V \\ {x0}, until we have reached a state s0 where the transition t0 can be taken. To make this a little more precise, consider a topological order xk, . . . , x1 of V \\{x0} with respect to oDG+ \u2013 such an order exists due to Definition 2 condition (1). (If there are cycles, then moving a variable may involve moving itself in the first place, which is not covered by our exit path construction.) Now consider, for 0 \u2264 d \u2264 k, the d-abstracted task. This is like the original task except that, for every transition t of one of the graphs oDTG+xi with i \u2264 d, we remove each condition (xj , c) \u2208 cond(t) where j > d. The exit path construction can then be understood as an induction over d, proving the existence of an execution path \u2212\u2192o at whose end t0 can be taken. We construct \u2212\u2192o exclusively by operators responsible for transitions in oDTG+x , for x \u2208 V \\ {x0}. For the base case, in the 0-abstracted task, t0 is directly applicable. For the inductive case, if we have constructed a suitable path \u2212\u2192o d for the d-abstracted task, then a suitable path \u2212\u2192o d+1 for the d + 1- abstracted task can be constructed as follows. Assume that o is an operator in \u2212\u2192o d, and that o has a precondition (xd+1, c) that is not true in the current state. Then, in \u2212\u2192o d+1, in front of o we simply insert a path through oDTG+xd+1 that ends in c. Note here that, by construction, (xd+1, c) is a condition of a transition t in oDTG+xi , for some i < d + 1. If t is taken in P+<0(s, x), then (xd+1, c) must be achieved by P + <0(s) and thus c is a node in oDTG+xd+1 . If t is an induced transition \u2013 inverting a transition taken in P + <0(s, x) \u2013 then the same is the case unless the inverse may introduce new outside conditions. We thus need to exclude this case, leading to the following definition of \u201cinvertibility\u201d:\n\u2022 Let t = (c, c\u2032) be a transition on variable x. We say that t is invertible iff there exists a transition (c\u2032, c) in DTGx so that cond(c\u2032, c) \u2286 cond(c, c\u2032).\nA transition is invertible if we can \u201cgo back\u201d without introducing any new conditions (e.g., driving trucks in Logistics). There are subtle differences to previous definitions of \u201cinvertible operators\u201d, like the author\u2019s (Hoffmann, 2005). We do not allow new conditions even if they are actually established by the operator rop(t) responsible for t. This is because, on \u2212\u2192o , we do not necessarily execute t before executing its inverse \u2013 we may have got to the endpoint of t via a different path in oDTG+x . On the other hand, our definition is also more generous\nthan common ones because, per se, it does not care about any side effects the inverse transition may have (side effects are constrained separately as stated in Definition 2).\nConsider Definition 2 condition (3). Apart from the constraints on conditions of induced transitions, for the oDTG+x transitions taken by\n\u2212\u2192o , we must also make sure that there are no harmful side effects. Obviously, this is the case if, as in the example from Section 3, the transitions have no side effects at all. However, we can easily generalize this condition. Let t = (c, c\u2032) be a transition on variable x.\n\u2022 The context of t is the set ctx(t) of all facts that may be deleted by side effects of t. For each (y, d) \u2208 seff(t), (y, cond(t)(y)) \u2208 ctx(t) if a condition on y is defined; else all Dy values 6= d are inserted.\n\u2022 We say that t has irrelevant side effect deletes iff ctx(t) \u2229 (sG \u222a \u22c3 o\u2208O preo) = \u2205.\n\u2022 We say that t has self-irrelevant side effect deletes iff ctx(t)\u2229(sG\u222a \u22c3\nrop(t)6=o\u2208O preo) = \u2205.\n\u2022 We say that t has self-irrelevant deletes iff it has self-irrelevant side effect deletes and (x, c) 6\u2208 sG \u222a \u22c3 rop(t)6=o\u2208O preo.\nIrrelevant side effect deletes capture the case where no side effect delete occurs in the goal or in the precondition of any operator. Self-irrelevant side effect deletes are slightly more generous in that they allow to delete conditions needed only for the responsible operator rop(t) itself. Self-irrelevant deletes, finally, extend the latter notion also to t\u2019s \u201cown delete\u201d. In a nutshell, we need to postulate irrelevant side effect deletes for transitions that may be executed again, on our path. Examples of irrelevant side effect deletes are transitions with no side effects at all, or a move in Simple-TSP, whose side effect, when x0=\u201dat\u201d, deletes the target location\u2019s being \u201cnot-visited\u201d. An example of an operator with selfirrelevant side effect deletes, but no irrelevant side effect deletes, is departing a passenger in Miconic-STRIPS, whose side effect, when x0=\u201dserved\u201d, deletes \u201cboarded(passenger)\u201d which is used only for the purpose of this departure. In fact, this transition has selfirrelevant deletes because its own effect deletes \u201cnot-served(passenger)\u201d which obviously is irrelevant. Another example of self-irrelevant deletes is inflating a spare wheel in Tyreworld \u2013 the wheel is no longer \u201cnot-inflated\u201d.\nClearly, if all oDTG+x transitions t we may be using on \u2212\u2192o have irrelevant side effect deletes, then, as far as not invalidating any facts needed elsewhere is concerned, this is just as good as having no side effects at all. To understand why we need to require that t\u2019s side effect is not used to move another variable x\u2032 \u2208 V \\ {x0}, recall that, for the states s\u2032 visited by \u2212\u2192o , we construct relaxed plans P+(s\u2032) with |P+(s\u2032)| \u2264 |P+(s)| by inverting such transitions t. Now, say that t\u2019s side effect is used to move another variable x\u2032 \u2208 V \\ {x0}. Then we may have to invert both transitions separately (with different operators), and thus we would have |P+(s\u2032)| > |P+(s)|.\nRegarding the own delete of t, this may be important for two reasons. First, the deleted fact may be needed in the relaxed plan for s\u2032. Second, x may have to traverse oDTG+x several times, and thus we may need to traverse the deleted value again later on. Both are covered if t is invertible, like we earlier on assumed for all transitions. Now, what if t is not invertible? This does not constitute a problem in case that t has self-irrelevant deletes: in that case,\nall deletes of t are irrelevant except maybe for the responsible operator itself. Therefore, to obtain P+(s\u2032), we can simply remove rop(t) from the relaxed plan constructed for the predecessor state s\u2032\u2032. Thus |P+(s\u2032)| < |P+(s)| so we have reached an exit and there is no need to continue the construction of \u2212\u2192o . For example, consider t that inflates a spare wheel W in Tyreworld. This deletes only \u201cnot-inflated(W)\u201d, and thus has self-irrelevant deletes (\u201cnot-inflated(W)\u201d is irrelevant for the goal and any other operator). Say that we are in a state s\u2032\u2032 with relaxed plan P+(s\u2032\u2032) constructed as described. We have |P+(s\u2032\u2032)| \u2264 |P+(s)|. We also have rop(t) =\u201cinflate-W\u201d\u2208 P+(s\u2032\u2032), because \u201cinflate-W\u201d\u2208 P+(s), and because \u201cinflate-W\u201d was not executed as yet on our path, and was hence not removed from the relaxed plan. Applying \u201cinflate-W\u201d to s\u2032\u2032, we get to a state s\u2032 identical to s\u2032\u2032 except that W is now inflated. Clearly, the relaxed plan for s\u2032 no longer needs to apply \u201cinflate-W\u201d, and the rest of the relaxed plan P+(s\u2032\u2032) still works unchanged. Thus P+(s\u2032) can be obtained by removing \u201cinflate-W\u201d from P+(s\u2032\u2032), yielding |P+(s\u2032)| < |P+(s)| as desired.\nConsider now our endpoint transition t0 and its responsible operator o0. We previously demanded that x0 \u201cmoves for its own sake\u201d, i.e., that x0 has a goal value and is not important for achieving any other goal. This is unnecessarily restrictive. For example, in Miconic-STRIPS, if we board a passenger then h+ decreases because we can remove the boarding operator from the relaxed plan. However, boarding is only a means for serving the passenger later on, so this variable x0 has no own goal. In Driverlog, a driver may have its own goal and be needed to drive vehicles, and still t0 moving the driver results in decreased h+ if the location moved away from is not actually needed anymore. The latter example immediately leads to a definition capturing also the first one: all we want is that \u201cany deletes of t0 are not needed in the rest of the relaxed plan\u201d. We can then remove o0 from the relaxed plan for s0, and have reached an exit as desired.\nTo make this precise, recall the situation we are addressing. We have reached a state s0 in which t0 = (s(x0), c) can be applied, yielding a state s1. We have a relaxed plan P+(s0) for s0 so that |P+(s0)| \u2264 |P+(s)|, where P+(s0) is constructed from P+(s) by replacing some operators of P+<0(s) with operators responsible for induced oDTG + x transitions for x \u2208 V \\ {x0}. We construct P+1 by removing o0 from P+(s0), and we need P + 1 to be a relaxed plan for s1. What are the facts possibly needed in P+1 ? A safe approximation is the union of sG, the precondition of any o0 6= o \u2208 P+(s), and any oDTG+x values needed by induced oDTG+x transitions.\n7 Denote that set with R+1 . The values potentially deleted by t0 are contained in C0 := {(x0, s(x0))} \u222a ctx(t0). Thus if R+1 \u2229 C0 = \u2205 then we are fine. Simple examples for this have been given above already. In Miconic-STRIPS, the only delete of o0 boarding passenger \u201cP\u201d is \u201cnot-boarded(P)\u201d, which is not contained in any operator precondition or the goal and thus the intersection of R+1 with C0 = {\u201dnotboarded(P)\u201d} is empty. In Driverlog, C0 = {\u201dat(D,A)\u201d} is the delete of o0 moving driver \u201cD\u201d away from location \u201cA\u201d. If that location is irrelevant to the rest of the task, then we will have \u201dat(D,A)\u201d6\u2208 R+1 and thus, again, R + 1 \u2229 C0 = \u2205.\nWe can sharpen this further. Consider the set of facts F0 := s \u222a \u22c3 o\u2208P+<0(s) effo that are true after relaxed execution of P+<0(s). Say that p 6\u2208 F0. Then p is not needed for\n7. To understand the latter two items, note first that operators preceding o0 in P +(s), i.e., operators from\nP+<0(s), may still be contained in P + 1 and thus it does not suffice to include the preconditions only of operators o \u2208 P+>0(s). As for oDTG+x values needed by induced oDTG+x transitions, these may be needed in P+1 but not in P + <0(s).\nP+1 to be a relaxed plan for s1. To see this, note first that p is not needed in the part of P+1 pertaining to P + <0(s). More precisely, p cannot be an operator precondition in P + <0(s) because this condition would not be satisfied in (relaxed) execution of P+(s). Also, p cannot be the start value of an induced oDTG+x transition because, by definition, all such values are added by operators in P+<0(s). Now, what about the part of P + 1 pertaining to P+>0(s)? Assume that p is either a goal, or is an operator precondition in P + >0(s). Then, since p 6\u2208 F0 and P+(s) is a relaxed plan, either o0 or an operator in P+>0(s) must establish p. As for o0, all its effects are true in s1 anyway. As for P+>0(s), this remains unchanged in P+1 and thus this part is covered, too. Altogether, it thus suffices if R + 1 \u2229 C0 \u2229 F0 = \u2205. An example where this helps is the Satellite domain. Say that o0 switches on instrument \u201cI\u201d. This deletes calibration, i.e., \u201ccalibrated(I)\u201d\u2208 C0. The only purpose of switching \u201cI\u201d on can be to take images with it, and thus \u201ccalibrated(I)\u201d\u2208 R+1 \u2229C0. However, the instrument may not actually be calibrated in s. If that is so, then we need to switch \u201cI\u201d on before it can be calibrated \u2013 because the calibration operator requires to have power in \u201cI\u201d \u2013 and thus \u201ccalibrated(I)\u201d will be false in the relaxed execution of P+(s), up to at least o0. In particular, we have \u201ccalibrated(I)\u201d 6\u2208 F0 and thus R+1 \u2229 C0 \u2229 F0 = \u2205.\nEven the condition R+1 \u2229 C0 \u2229 F0 = \u2205 can still be sharpened. Say that there exists a (possibly empty) sub-sequence \u2212\u2192o0 of P+>0(s) so that\n\u2212\u2192o0 is guaranteed to be applicable at the start of P+1 , and so that\n\u2212\u2192o0 re-achieves all facts in R+1 \u2229 C0 \u2229 F0 (both are easy to define and test). Then moving \u2212\u2192o0 to the start of P+1 does the job. We say in this case that the oDG+-relevant deletes of t0 are P+>0(s)-recoverable \u2013 Definition 2 condition (2a). For example, consider o0 that picks up a ball b in the Gripper domain. This operator deletes a fact p =\u201cfree-gripper\u201d which may be needed in the remainder of the relaxed plan, and thus p \u2208 R+1 \u2229 C0 \u2229 F0. However, P + >0(s) will necessarily contain a sub-sequence\n\u2212\u2192o0 that moves to another room and then puts b down again. We can re-order P+1 to put\n\u2212\u2192o0 right at the start, re-achieving p. Similar patterns occur in any transportation domain with capacity constraints, or more generally in domains with renewable resources.\nFinally, we have identified two simple alternative sufficient conditions under which t0 is suitable, Definition 2 conditions (2b) and (2c). For the sake of brevity, we only sketch them here. Both require that s(x0), i.e., the start value of t0, is not contained in R+1 as defined above. We say in this case that s(x0) is not oDG+-relevant. Note that, then, R+1 \u2229 C0 = \u2205 unless t0 has side effects. Side effects do not hurt if t0 has replaceable side effect deletes, i.e., if any operator whose precondition may be deleted can be replaced with an alternative operator o\u2032 that is applicable and has the same effect (this happens, e.g., in Simple-TSP). Another possibility is that where t0 has recoverable side effect deletes: there exists an operator o\u2032 that is necessarily applicable directly after execution of t0, and that recovers all relevant side effect deletes. This happens quite frequently, for example in Rovers where taking a rock/soil sample fills a \u201cstore\u201d, but we can free the store again simply by emptying it anywhere. We can replace o0 with o\u2032 to obtain a relaxed plan P+1 for s1 (and thus h+(s1) \u2264 h+(s)). Then we can apply o\u2032, yielding a state s2 which has h+(s2) < h+(s) because we can obtain a relaxed plan for s2 by removing o\u2032 from P+1 .\nWhat will the length of the exit path be? We have one move for x0. Each nonleaf variable x must provide a new value at most once for every move of a variable x\u2032 depending on it, i.e., where (x, x\u2032) \u2208 A. The new value can be reached by a oDTG+x traversal. Denote the maximum length of such a traversal, i.e., the diameter of oDTG+x ,\nby diam(oDTG+x ). 8 Now, we may have diam(oDTG+x ) > diam(DTGx) because oDTG + x removes not only vertices but also arcs. There may be \u201cshort-cuts\u201d not traversed by P+(s). Under certain circumstances it is safe to take these short-cuts, namely if:\n(*) all oDTG+x transitions are invertible/induced and have irrelevant side effect deletes and no side effects on V \\ {x0}, and all other DTGx transitions either are irrelevant, or\nhave empty conditions and irrelevant side effect deletes.\nWhen traversing a short-cut under this condition, as soon as we reach the end of the shortcut, we are back in the region of states s\u2032 where a relaxed plan P+(s\u2032) can be constructed as before. The rest of our exit path construction remains unaffected. Thus, denote by V \u2217\nthe subset of V \\ {x0} for which (*) holds. We define costd\u2217(oDG+) := \u2211 x\u2208V cost d\u2217(x), where costd\u2217(x) := 1 x = x0 diam(oDTG+x ) \u2217 \u2211 x\u2032:(x,x\u2032)\u2208A cost d\u2217(x\u2032) x 6= x0, x 6\u2208 V \u2217\nmin(diam(oDTG+x ),diam(DTGx)) \u2217 \u2211 x\u2032:(x,x\u2032)\u2208A cost d\u2217(x\u2032) x 6= x0, x \u2208 V \u2217\nNote that costd\u2217(.) is exponential in the depth of the graph. This is not an artifact of our length estimation. It is easy to construct examples where exit distance is exponential in that parameter. This is because, as hinted, a variable may have to move several times for each value required by other variables depending on it. See Example 6 in Appendix A.4 for such a construction (following an earlier construction in Domshlak & Dinitz, 2001).\nThat said, of course costd\u2217(.) may over-estimate the length of a shortest exit path. It assumes that, whenever a variable x\u2032 with (x, x\u2032) \u2208 A makes a move, then x must move through its entire oDTG+ respectively DTG. This is very conservative: (1) it may be that the move of x\u2032 does not actually have a condition on x; (2) even if such a condition exists, x may need less steps in order to reach it. One might be able to ameliorate (1) by making more fine-grained distinctions which part of costd\u2217(x\u2032) pertains to moves conditioned on x. We leave this open for future work. For now, we note that the over-estimation can be exponential even just due to (2), i.e., costd\u2217(oDG+) may be exponentially larger than the length of a shortest exit path even if, for all (x, x\u2032) \u2208 A, all moves of x\u2032 depend on x. This can be shown by a simple variant of Example 6; we discuss this in Appendix A.4.\nExit paths using short-cuts in the described way may be non-monotone. Example 5 in Appendix A.4 contains a construction showing this. For an intuitive understanding, imagine a line l0, . . . , ln where our current task, to achieve the precondition of another operator, is to move from l0 to ln. Say that all locations on the line need to be visited, in the relaxed plan, e.g. because we need to load or unload something at all of these locations. Say further that there is a shortcut via l\u2032 that needs not be visited. If we move to l\u2032 then h+ increases because we have made it 1 step more costly \u2013 for the relaxed plan \u2013 to reach all the locations l0, . . . , ln. For the same reason, costd\u2217(oDG+) is not an upper bound on the length of a shortest monotone exit path. This is also shown in Example 5, where we construct a\n8. More precisely, diam(.) is not the diameter of a graph but the maximum distance from vertex v to vertex v\u2032 where there exists a path from v to v\u2032.\nsituation in which the shortest monotone exit path is longer than costd\u2217(oDG+).9 To obtain a bound on monotone exit paths, we can simply set V \u2217 := \u2205 in the definition of costd\u2217.\nIf we have Definition 2 condition (2a) or (2b), then the exit distance is bounded by costd\u2217(oDG+) \u2212 1 because costd\u2217(oDG+) counts the last step reducing h+. If we have Definition 2 condition (2c), then after that last step we need 1 additional operator to reduce h+, and so the exit distance is bounded by costd\u2217(oDG+). Putting the pieces together yields our main result of this section:\nTheorem 2. Let (X, sI , sG, O), s, P+(s), and oDG+ be as in Definition 1. If oDG+ is successful, then s is not a local minimum, and ed(s) \u2264 costd\u2217(oDG+). If we have Definition 2 condition (2a) or (2b), then ed(s) \u2264 costd\u2217(oDG+)\u2212 1.\nThe full proof is in Appendix A.2. As pointed out earlier, for approximate local analysis (III) we simply feed Theorem 2 with the relaxed plans returned by FF\u2019s heuristic function (Hoffmann & Nebel, 2001a). It is important to note that, this way, we do not give any guarantees, i.e., Theorem 2 does not hold if P+(s) is not optimal, and even if P+(s) is non-redundant and parallel-optimal like those computed by FF. At the end of the \u201cexit path\u201d we may obtain a relaxed plan shorter than P+(s) but not shorter than h+(s). In a nutshell, the reason is that a parallel-optimal relaxed plan \u2013 more generally, a relaxed plan not minimizing the number of operators \u2013 may take very different decisions than a sequentially-optimal relaxed plan, thus constructing an \u201cexit path\u201d leading into the wrong direction. Example 8 in Appendix A.4 gives a full construction proving this.\nFeeding Theorem 2 with non-optimal relaxed plans can of course also be imprecise \u201cin the other direction\u201d, i.e., Theorem 2 may not apply although it does apply for an optimal relaxed plan. Thus \u201cgood cases\u201d may go unrecognized. We demonstrate this with a simple modification of Example 8, explained below the example in Appendix A.4. Importantly, as we will point out in Section 8, our empirical results suggest that this weakness does not tend to occur in practice, at least as far as represented by the benchmarks."}, {"heading": "6. Conservative Approximations", "text": "We now identify sufficient criteria guaranteeing that the prerequisites of Theorem 2 hold true. We consider both the local case where a particular state s is given, and the global case where the criterion implies the prerequisites of Theorem 2 for every state s in the task at hand. We approximate optimal rplan dependency graphs as follows:\nDefinition 3. Let (X, sI , sG, O) be a planning task, let s \u2208 S with 0 < h+(s) < \u221e, let x0 \u2208 XsG, and let t0 = (s(x0), c) be a relevant transition in DTGx0 with o0 := rop(t0).\nA local dependency graph for s, x0, and o0, or local dependency graph in brief, is a graph lDG = (V,A) with unique leaf vertex x0, and where x \u2208 V and (x, x\u2032) \u2208 A if either: x\u2032 = x0, x \u2208 Xpreo0 , and preo0(x) 6= s(x); or x\n\u2032 \u2208 V \\ {x0} and (x, x\u2032) is an arc in SG. A global dependency graph for x0 and o0, or global dependency graph in brief, is a graph gDG = (V,A) with unique leaf vertex x0, and where x \u2208 V and (x, x\u2032) \u2208 A if either: x\u2032 = x0 and x0 6= x \u2208 Xpreo0 ; or x \u2032 \u2208 V \\ {x0} and (x, x\u2032) is an arc in SG\n9. We remark that, due to the mentioned sources of over-estimation in costd\u2217, constructing such an example requires fairly awkward constructs that do not appear likely to occur in practice.\nIf an optimal relaxed plan P+(s) for s contains o0, then oDG+ as per Definition 1 will be a sub-graph of lDG and gDG as defined here. This is simply because any optimal rplan dependency graph has only arcs (x, x\u2032) contained in the support graph of the task.10 As previously indicated, the support graph may contain a lot more arcs than actually necessary. SG captures what may ever support what else, not what will support what else in an optimal relaxed plan. Consider our earlier point that, when constructing oDG+, we take into account only the operators in front of o0 in P+(s). This information is not contained in SG, thus in Gripper we get the aforementioned cycle dropping a ball to support \u201cfree-gripper\u201d for picking up the same ball.\nThe reader who has waded through the cumbersome details in the previous section will be delighted to hear that defining when an lDG respectively gDG is successful does not involve any additional notation:\nDefinition 4. Let (X, sI , sG, O), s, x0, t0, o0, and G = lDG or G = gDG be as in Definition 3. We say that G = (V,A) is successful if all of the following hold:\n(1) G is acyclic.\n(2) If G = lDG then sG(x0) 6= s(x0), and there exists no transitive successor x\u2032 of x0 in SG so that x\u2032 \u2208 XsG and sG(x\u2032) 6= s(x\u2032).\n(3) We have that t0 either:\n(a) has self-irrelevant side effect deletes; or (b) has replaceable side effect deletes; or (c) has recoverable side effect deletes.\n(4) For x \u2208 V \\ {x0}, all DTGx transitions either are irrelevant, or have self-irrelevant deletes, or are invertible and have irrelevant side effect deletes and no side effects on V \\ {x0}.\nConsider first only local dependency graphs G = lDG; we will discuss G = gDG below. Assume that we have an optimal relaxed plan P+(s) for s that contains o0, and thus oDG+ is a sub-graph of lDG. Then condition (1) obviously implies Definition 2 condition (1). Condition (4) implies Definition 2 condition (3) because oDTG+x does not contain any irrelevant transitions. Condition (2) implies that (*) s(x0) is not oDG+-relevant, i.e., s(x0) is not needed in the rest of the relaxed plan. This is simply because no other un-achieved goal depends on x0. With (*), condition (3a) implies Definition 2 condition (2a), because R+1 \u2229 C0 = \u2205, in the notation introduced previously. Conditions (3b) and Definition 2 condition (2b), respectively (3c) and Definition 2 condition (2c), are equivalent given (*).\nRegarding exit distance, we do not know which parts of the domain transition graphs of the variables x \u2208 V \\{x0} will be traversed by P+(s). An obvious bound on diam(oDTG+x ) is the length maxPath(DTGx) of a longest non-redundant path through the graph (a path visiting each vertex at most once). Unfortunately, we cannot compute maxPath(.) efficiently. A Hamiltonian path (Garey & Johnson, 1979) exists in a graph G = (V,A) iff\n10. For gDG, note that preo0(x0), if defined, will be = s(x0) and thus x0 does not need to be recorded as its own predecessor.\nmaxPath(G) = |V | \u2212 1. Thus the corresponding decision problem is NP-hard. TorchLight over-approximates maxPath(G) simply by |V | \u2212 1. However, we can sometimes use diam(DTGx) instead of maxPath(DTGx), namely if we are certain that x is one of the variables V \u2217 used in the definition of costd\u2217(oDG+). This is certain if:\n(**) all DTGx transitions either are irrelevant, or are invertible and have empty conditions, irrelevant side effect deletes, and no side effects on V \\ {x0}.\nNote that this is a strictly stronger requirement than Definition 4 condition (4). Clearly, it implies Definition 2 condition (3) as well as condition (*) in Section 5. Denote by V \u2217\u2217 the subset of V \\ {x0} for which (**) holds. We define costD\u2217(G) := \u2211 x\u2208V cost\nD\u2217(x), where costD\u2217(x) :=  1 x = x0 maxPath(DTGx) \u2217 \u2211 x\u2032:(x,x\u2032)\u2208A cost D\u2217(x\u2032) x 6= x0, x 6\u2208 V \u2217\u2217\ndiam(DTGx) \u2217 \u2211 x\u2032:(x,x\u2032)\u2208A cost D\u2217(x\u2032) x 6= x0, x \u2208 V \u2217\u2217\nBecause x0 must move \u2013 to attain its own goal \u2013 every optimal relaxed plan must take at least one transition leaving s(x0). Thus, with Theorem 2 and the above, we have that:\nTheorem 3. Let (X, sI , sG, O) be a planning task, and let s \u2208 S be a state with 0 < h+(s) < \u221e. Say that x0 \u2208 X so that, for every o0 = rop(s(x0), c) in DTGx0 where (s(x0), c) is relevant, lDGo0 is a successful local dependency graph. Then s is not a local minimum, and ed(s) \u2264 maxo0 costD\u2217(lDGo0). If, for every lDGo0, we have Definition 4 condition (3a) or (3b), then ed(s) \u2264 maxo0 costD\u2217(lDGo0)\u2212 1.\nTheorem 3 is our tool for guaranteed local analysis (II). For guaranteed global analysis (I), we simply look at the set of all global dependency graphs gDG, requiring them to be successful. In particular, all gDG are then acyclic, from which it is not difficult to deduce that any non-goal state s will have a variable x0 fulfilling Definition 4 (2). For that x0, we can apply Theorem 3 and thus get:\nTheorem 4. Let (X, sI , sG, O) be a planning task. Say that all global dependency graphs gDG are successful. Then S does not contain any local minima and, for any state s \u2208 S with 0 < h+(s) < \u221e, ed(s) \u2264 maxgDG costD\u2217(gDG). If, for every gDG, we have Definition 4 condition (3a) or (3b), then ed(s) \u2264 maxgDG costD\u2217(gDG)\u2212 1.\nThe full proofs of Theorems 3 and 4 are in Appendix A.3. If SG is acyclic and all transitions are invertible and have no side effects, then Theorem 4 applies, whereby we have now in particular proved our basic result. Vice versa, note that, if Theorem 4 applies, then SG is acyclic. As far as local minima are concerned, one may thus reformulate Theorem 4 in simpler terms not relying on a notion of \u201csuccessful dependency graphs\u201d. Apart from allowing to also determine an exit distance bound, the present formulation already paves the way for future research: a gDG is defined relative to a concrete variable x0 and operator o0, and may thus allow for more accurate analysis of which other variables may actually become important for x0 and o0, in an optimal relaxed plan.\nThe use of diam(DTGx) instead of maxPath(DTGx) in costD\u2217(.), for the variables in V \u2217\u2217, has a rather significant effect on the quality of the bounds computed in many\nbenchmarks. A typical example is a transportation domain where vehicle positions are leaf variables in SG whose transitions have no side effects. Such variables qualify for V \u2217\u2217. Using maxPath(DTGx) instead, we would obtain exceedingly large bounds even for trivial road maps. For example, consider Logistics where the road map is fully connected. We have diam(DTGx) = 1 and thus costD\u2217(.) delivers the correct bound 1. Using maxPath(DTGx) we instead get the bound N \u2212 1, N being the total number of locations in DTGx.\nNote that, within the scope of Theorem 4, i.e., the class of planning tasks to which Theorem 4 applies, plan existence is tractable. Namely, there exists a plan for the task iff there exists a relaxed plan for the initial state. This is because, starting from an optimal relaxed plan, we are guaranteed to be able to construct an exit path; iterating this argument gets us to the goal. In our view, this tractability is a weakness of this form of global analysis. The analysis does not apply in intractable classes of tasks that do not contain local minima. Note that such classes do exist, cf. Theorem 1. On the other hand, plan existence is tractable in all known benchmark domains where local minima are absent, so in practice this does not appear to be a major limitation. Also, note that plan construction, as well as optimal planning, are still intractable within the scope of Theorem 4. Plan construction is intractable because the plans may be exponentially long, cf. Example 6 in Appendix A.4. As for optimal planning, just consider Logistics and Miconic-STRIPS. We will see shortly (Proposition 1, next section) that these are fully covered by Theorem 4. However, in both of them, deciding bounded plan existence is NP-hard (Helmert, 2003).\nInterestingly, the fact that Theorem 2, and therewith indirectly also Theorem 4, rely on optimal relaxed plans is not a source of intractability of plan construction here. If Theorem 4 applies, then any non-redundant relaxed plan P+ has a successful oDG+, enabling us to construct a path to a state where that particular relaxed plan (although not necessarily an optimal relaxed plan) can be shortened. Iterating this argument gives us a constructive method for obtaining a plan, where the only worst-case exponential behavior lies in the length of the individual path segments. That said, of course the plan constructed in this way may be highly non-optimal. Indeed, as is shown in Example 7 in Appendix A.4, this plan may be exponentially longer than an optimal plan. Thus, even if Theorem 4 applies and we do not need an optimality guarantee, running a planner still makes sense.\nWe will discuss the relation of the scope of Theorem 4 to known tractable classes in Section 9. A basic fact is that one can construct local minima even in very small examples involving only two variables and complying with our basic result except that either the support graph is cyclic (Example 2, Appendix A.4), or there is a non-invertible transition whose own delete is relevant (Example 3, Appendix A.4), or there is a transition with a relevant side effect delete (Example 4, Appendix A.4). These examples are contained in many known tractable classes, thus underlining that the automatic analysis of h+ topology and the identification of tractable classes are different (although related) enterprises."}, {"heading": "7. Benchmark Performance Guarantees", "text": "We now state some guarantees that our analyses (I)\u2013(III) give in benchmark domains. The underlying finite-domain variable formalizations are straightforward, and correspond\nto formulations that can be found automatically by Fast Downward. They are listed in Appendix A.5, where we also give the proofs of the following two simple observations.11\nIn four of our benchmark domains, guaranteed global analysis (I) will always succeed :\nProposition 1. Let (X, sI , sG, O) be a planning task from the Logistics, Miconic-STRIPS, Movie, or Simple-TSP domain. Then Theorem 4 applies, and the bound delivered is at most 1, 3, 1, and 1 respectively.\nIt follows trivially from Proposition 1 that guaranteed local analysis (II) succeeds in these domains as well. If s is any state in one of the four listed domains, then Theorem 3 applies to s, and the bound delivered is as stated.\nNote that the bounds for Logistics and Movie are the correct ones, i.e., they are tight. For Miconic-STRIPS, the over-estimation of the actual bound (which is 1, not 3) arises because the analysis does not realize that boarding a passenger can be used as the leaf variable x0. For Simple-TSP, the correct bound is 0 (since h+ is the exact goal distance). The over-estimation arises because, in every goal variable x0 =\u201dvisited(location)\u201d, the gDG includes also the variable \u201cat\u201d, not realizing that the value of \u201cat\u201d does not matter because any location can be visited from any other one.\nFor the transportation benchmarks involving capacity constraints, approximate local analysis (III) will always succeed, if provided with suitable optimal relaxed plans:\nProposition 2. Let (X, sI , sG, O) be a planning task from the Elevators, Ferry, Gripper, or Transport domain, and let s \u2208 S. In Ferry and Gripper, for every optimal relaxed plan P+(s) there exists oDG+ so that Theorem 2 applies, the bound being at most 1. In Elevators and Transport, there exists at least one P+(s) and oDG+ so that Theorem 2 applies, the bound being at most 1 in Elevators and at most the road map diameter in Transport.\nThe relevant deletes of t0, in all these cases, are due to the effects decreasing the remaining vehicle capacity, like \u201cfree-gripper\u201d in the Gripper domain. A decrease of capacity is always due to a \u201cload\u201d type of operator, which is matched by an \u201cunload\u201d type of operator later on inside the relaxed plan. Thus these deletes are always recovered inside P+(s) (we have Definition 2 condition (2a)). Further, relaxed plans never use an \u201cunload\u201d action to free a capacity for \u201cload\u201ding the same object, thus the oDG+s are cycle-free. Hence the oDG+s are successful, and Theorem 2 applies. For Elevators and Transport, Proposition 2 is slightly weaker because a vehicle may have capacity > 1, allowing \u2013 but not forcing \u2013 relaxed plans to use unloading operators recovering a capacity not actually present.\nWe note that similar patterns are likely to occur in any domain with renewable resources, and will be recognized by Definition 2 condition (2a) in the same way.\nProposition 2 does not hold for Theorems 3 and 4, i.e., for lDGs and gDGs. This is due to two deficiencies (cf. the discussion at the end of Section 4). First, SG contains cycles \u201cunload\u201ding an object in order to free the capacity for \u201cload\u201ding it. Second, Definition 2 condition (3a) is more restrictive than Definition 2 condition (2a), postulating the deletes of t0 to be entirely irrelevant. If we had a way of removing these deficiencies, then the guaranteed analyses (I,II) would succeed in the four domains from Proposition 2.\n11. We say \u201ccan be found automatically\u201d here because Fast Downward\u2019s translator is not deterministic, i.e., it may return different finite-domain variable encodings even when run several times on the same planning task. Some but not all of these encodings correspond to our domain formalizations. For Elevators, we do not give a full definition because, without action costs, this is merely a variant of Transport."}, {"heading": "8. Experiments", "text": "We report on a large-scale experiment with TorchLight. We fill in a few details on TorchLight\u2019s implementation, and we describe a simple alternative analysis technique based on search probing. We explain the experiments set-up, report runtime results for the different stages of TorchLight, and describe TorchLight\u2019s analysis results on a per-domain basis. We assess the quality of that analysis in terms of its predictive capability. We finally summarize the outcome of TorchLight\u2019s diagnosis facility in our benchmarks."}, {"heading": "8.1 TorchLight", "text": "TorchLight is implemented in C based on FF.12 TorchLight currently handles STRIPS only, i.e., no ADL domains. It uses Fast Downward\u2019s translator (Helmert, 2009) to find the finitedomain variables. Establishing the correspondence between these variables (respectively their values) and FF\u2019s internally used ground facts is mostly straightforward. There are a few details to take care of; we omit these for brevity.\nAfter parsing Fast Downward\u2019s variables, TorchLight creates data structures representing the support graph and the domain transition graphs. It then enters a phase we refer to as static analysis, where it determines fixed properties such as, for every transition t, whether t is irrelevant, invertible, etc. The next step is guaranteed global analysis (I), checking the preconditions of Theorem 4 by enumerating all global dependency graphs and testing whether they are successful. To be able to report the percentage of successful gDGs, we do not stop at the first unsuccessful one.\nThe local analysis techniques \u2013 guaranteed local analysis (II) using Theorem 3 and approximate local analysis (III) using Theorem 2 \u2013 are run on a set LS of states comprising the initial state as well as a number R of sample states obtained by random walks starting in sI . The set LS is identical for both analyses, and we run each technique on each state s \u2208 LS regardless of what the outcome of running the respective other technique on s is. Given s, analysis (II) checks Theorem 3 by constructing the local dependency graph for every suitable variable x0 and every transition t0 leaving s(x0). If we find a non-successful t0, we stop considering x0. We minimize exit distance bounds across different x0.\nAnalysis (III) checks Theorem 2 on a relaxed plan P+(s) computed by FF\u2019s heuristic function. In case that no relaxed plan exists for s, the analysis reports failure. Otherwise, the analysis proceeds over all operators o0 in P+(s), from start to end, and over all variables x0 affected by o0. For each pair o0, x0 we build the optimal rplan dependency graph oDG+ as per Definition 1. We skip variables x0 where effo0(x0) is not actually used as a precondition or goal, in the rest of P+(s). If oDG+ is successful, we stop. (Relaxed plans can be big in large examples, so continuing the analysis for exit bound minimization was sometimes costly.) As mentioned in Section 5, before we build oDG+ we re-order P+(s) by moving operators behind o0 if possible. This is of paramount importance because it avoids including unnecessary variables into oDG+. The re-ordering process is straightforward. It starts at the direct predecessor o of o0, and tests whether P+(s) is still a relaxed plan when moving o directly behind o0. If yes, this arrangement is kept. Then we iterate to the predecessor of o, and so forth. It is easy to see that, this way, oDG+ will contain exactly the variables\n12. The source code of TorchLight is an online appendix to this paper. It is available for download also at http://www.loria.fr/~hoffmanj/TorchLight.zip.\nand transitions used in P+(s) to achieve preo0 . Finally, when we check whether the oDG +- relevant deletes of t0 are P+>0(s)-recoverable, we use a simple technique allowing to recognize situations where failure due to one operator can be avoided by replacing with an alternative operator. For example, if in Transport o0 is a loading operator reducing capacity level k to k \u2212 1, then P+(s) may still contain an unloading operator relying on level k. Thus level k will be contained in R+1 \u2229 C0, causing failure. However, the unloading can just as well be performed based on capacity level k \u2212 1, removing this difficulty. We catch cases like this during construction of R+1 . Whenever we find o whose precondition overlaps C0, we test whether we can replace o with a similar operator.\nThe local analyses return simple statistics, namely the minimum, mean, and maximal exit distance bound found, as well as the success rate, i.e., the fraction of sample states where guaranteed local analysis (II)/approximate local analysis (III) succeeded. Analysis (III) success rates will be a main focus, because these turn out to be very informative.\nWe run R = 1, 10, 100, 1000 in the experiment. The length of each random walk is chosen uniformly between 0 and 5 \u2217 hFF(sI), i.e., 5 times the FF heuristic value for the initial state. We do not play with the parameter 5. It is important, however, that this parameter is not chosen too small. In domains with many dead ends \u2013 where one may do things that are fatally wrong \u2013 it is likely that the \u201cbad\u201d things will happen only if doing a sufficiently large number of random choices. Consequently, the dead-end rate, i.e., the fraction of sample states for which no relaxed plan exists, tends to be larger for longer random walks. Since analysis (III) fails on states that have no relaxed plan, this exerts an important influence on analysis (III) success rates. We illustrate this below by comparing some results for sampled states to results obtained using the initial states only."}, {"heading": "8.2 Search Probing", "text": "For approximate analysis of sample states, there exists a simple (and rather obvious) alternative to TorchLight\u2019s causal graph based technology. One can use search to determine whether or not a given sample state s is a local minimum, and what its exit distance is. Since we cannot compute h+ effectively, such a search-based analysis is necessarily approximate. The straightforward method is to replace h+ with a relaxed-plan based approximation. Herein, we replace h+ with hFF, i.e., with FF\u2019s heuristic function. Precisely, given a state s, we run a single iteration of FF\u2019s Enforced Hill-Climbing, i.e., a breadth-first search for a state with better heuristic value. In this search, like FF does, we use helpful actions pruning to avoid huge search spaces. Unlike FF, to focus on the detection of states not on local minima, we allow only monotone paths (thus restricting the search space to states s\u2032 where hFF(s\u2032) = hFF(s)). We refer to this technique as search probing, SP in brief. We also experiment with a variant imposing a 1 second runtime cut-off on the search. We refer to this as limited search probing, SP1s in brief. SP and SP1s are run on the same set LS of states as TorchLight\u2019s local analyses (II,III).\nAs it turns out, empirically \u2013 in the present benchmarks \u2013 SP and SP1s are very competitive with TorchLight\u2019s analysis (III). Since that analysis is a main focus of our experiments, it is relevant to understand the commonalities and differences between these techniques.\nAs far as analysis quality guarantees are concerned, all 3 techniques \u2013 analysis (III), SP, SP1s \u2013 have similar properties: there are no guarantees whatsoever. Each may report\nsuccess although s is a local minimum (false positives), and each may fail although s is not a local minimum (false negatives). In all cases, false positives are due to the use of non-optimal relaxed plans (hFF instead of h+). False negatives are inherent in analysis (III) because this covers only certain special cases; they are inherent in SP1s due to the search limit. SP can have false negatives due to helpful actions pruning, however that could in principle be turned off; the more fundamental source of false negatives are the non-optimal relaxed plans. These are also responsible for a lack of connections across the techniques. The only implication is the trivial one that SP1s success on a state s implies SP success on s. In particular, if analysis (III) correctly identifies s to not be a local minimum, then this does not imply that SP will do so as well. The causal graph analysis may be less affected by irregularities in the hFF surface. This happens, for example, in the Transport domain of IPC 2008, resulting in higher success rates for analysis (III).\nThere are some obvious \u2013 but important \u2013 differences regarding runtime performance and the danger of false negatives. SP runtime is worst-case exponential in the size of the (grounded) input, whereas analysis (III) and SP1s runtime is low-order polynomial in that size. For SP, decreasing the number R of sample states merely reduces the chance of hitting a \u201cbad\u201d state (a sample state on a large flat region), whereas analysis (III) and SP1s scale linearly in R. On the other hand, both analysis (III) and SP1s buy their efficiency with incompleteness, i.e., increased danger of false negatives. Analysis (III) simply recognizes only special cases. SP1s effectively bounds the lookahead depth, i.e., the search depth in which exit states can be detected.\nAs indicated, SP and SP1s turn out to be competitive in the benchmarks. Large search spaces are rare for SP. The success rates of SP and SP1s are similar, and as far as predictive capability is concerned are similarly informative as those of analysis (III). Thus goodquality success rates can be obtained with much simpler techniques than TorchLight.13 This notwithstanding, (a) TorchLight has other functions \u2013 the guaranteed analyses (I,II) as well as diagnosis \u2013 that cannot be simulated, and (b) results in benchmarks only ever pertain to these examples. TorchLight\u2019s analysis (III) offers unlimited lookahead depth at low-order polynomial cost. This does not appear to matter much in the present benchmarks, but there are natural cases where it does matter. We get back to this below."}, {"heading": "8.3 Experiments Set-Up", "text": "We run experiments in a set of 37 domains. These include the domains investigated in the hand-made analysis of h+ topology (Hoffmann, 2005), as shown in Figure 1, which include all domains from the international planning competitions (IPC) up to IPC 2004. Our remaining domains are the STRIPS (versions of the) domains from IPC 2006 and IPC 2008, except IPC 2008 Cyber-Security which we omit due to parsing difficulties.14 The test instances were collected from the IPC collection(s) where applicable (removing action cost constructs from the IPC 2008 domains), and randomly generated elsewhere. In total, our test set contains 1160 instances.\n13. In particular, search probing appears to be a rather useful technique, raising the question why such techniques have not yet been used for performance prediction purposes. Roberts and Howe (2009), for example, use very simple features only. We get back to this in the conclusion. 14. The instances are too large for FF\u2019s parser in its standard configuration. When tweaking bison to allow larger parse trees, we obtained a segmentation fault even in the smallest instance of IPC 2008.\nAll experiments are run on a 1.8 GHZ CPU, with a 30 minute runtime and 2 GB memory cut-off. We run 4 different planners/tools. Apart from TorchLight (and SP/SP1s), these include FF (Hoffmann & Nebel, 2001a), and LAMA (Richter et al., 2008; Richter & Westphal, 2010). The purpose of running these planners is to assess to what extent TorchLight\u2019s output \u2013 in particular analysis (III) success rate \u2013 can predict planner success or failure. To examine this also for a very plain planner, we also run a version of FF that uses no goal ordering techniques, and that runs only Enforced Hill-Climbing, without resorting to best-first search if that fails. We will refer to this planner as EHC in what follows."}, {"heading": "8.4 Runtime", "text": "Our code is currently optimized much more for readability than for speed. Still, TorchLight is fast. Up to R = 100, the bottleneck is Fast Downward\u2019s translator. With R = 1, 10, 100, the actual analysis takes at most as much time as the translator in 99.74%, 99.74%, and 96.21% of the instances respectively. To assess this in more detail, consider Table 2 which gives the timing of the different stages of TorchLight, and of the other planners/tools.\nThe translation runtime sometimes hurts considerably, with a peak of 690.59 seconds in the most costly instance of the Scanalyzer domain. This is rather exceptional, however. The second most costly domain is Blocksworld-NoArm, with a peak of 138.33 seconds. In\n20 of the 37 domains, the most costly instance is translated in less than 10 seconds. In 57.24% of the instances, Fast Downward\u2019s translator takes at most 1 second.\nFor static analysis, the peak behavior of 31.42 seconds (also in Scanalyzer) is even more exceptional: in 95.34% of the instances, static analysis takes at most 1 second. The second highest domain peak is 7.88 seconds in Pipesworld-Tankage. Similarly, while analysis (I) takes a peak of 53.29 seconds \u2013 in Blocksworld-NoArm \u2013 in 96.12% of the instances it completes in at most 1 second. The only domain other than Blocksworld-NoArm where the peak instance takes more than 10 seconds is Airport, with a peak of 41.71 seconds; the next highest domain peaks are Pipesworld-Tankage (6.8), Scanalyzer (2.91), Logistics (1.89), and Woodworking (1.17). In all other domains, analysis (I) always completes within a second.\nTurning focus on the local analyses, we see that they are even more effective. In particular, we will concentrate below mostly on approximate local analysis (III). We will see that R = 1000 does not offer advantages over R \u2264 100 as far as the information obtained goes, so we will mostly concentrate on R \u2264 100. For R = 1, 10, 100, analysis (III) completes in at most 1 second for 99.66%, 99.40%, 95.60% of the instances respectively. For R = 1000 this still holds for 76.55% of the instances. The peak runtime of 20.09 seconds for R = 100 occurs in Scanalyzer. The next highest domain peaks are Blocksworld-NoArm (9.23), Pipesworld-Tankage (4.24), Ferry(3.21), Logistics (2.99), Blocksworld-Arm (2.77), Optical-Telegraph (1.97), and Airport (1.41). In all other 29 domains, analysis (III) with R = 100 always completes within a second.\nThe bottleneck in local analysis is the generation of sample states. This can be costly because it involves the repeated computation of applicable operators during the random walks. Its R \u2264 100 peak of 50.35 seconds is in the Scanalyzer domain. However, once again, this peak behavior is exceptional. With R = 1, 10, 100, the sampling completes within at most 1 second for 100%, 98.28%, 87.41% of the instances respectively.\nThe main competitor of TorchLight analysis (III) success rates is search probing, i.e., SP and SP1s. Consider for the moment only the analysis methods themselves, i.e., row \u201cAnalysis (III)\u201d vs. rows \u201cSP\u201d and \u201cSP1s\u201d in Table 2. Compared to SP1s, analysis (III) is consistently in the advantage (except for maximum runtime with R = 1), but the difference is not dramatic. This is to be expected, given that SP1s trades completeness against a small fixed maximum runtime. Compared to the complete search in SP, analysis (III) consistently has a significant advantage. However, for R \u2264 10 the mean runtime of SP is tolerable, and even the maximum runtime is not too bad. Further, bad runtime behavior is exceptional. For R = 1, 10, SP completes in at most 1 second for 99.83% and 98.45% of the instances respectively. In 35 (R = 1) respectively 32 (R = 10) of the 37 domains even the maximum runtime is below 1 second. With R = 100, SP has two time-outs, both in Blocksworld-Arm. With R = 1000, there are 11 time-outs, in Blocksworld-Arm, Blocksworld-NoArm, Freecell, and Pipesworld-NoTankage. With R = 100, the maximum runtime is above 10 seconds in 7 domains; with R = 1000, in 12. However, with R = 100, 1000, SP still completes in at most 1 second for 92.33% and 71.98% of the instances respectively (compared to 95.60% and 76.55% for analysis (III), cf. above).\nNeither analysis (III) nor search probing are stand-alone methods. The former requires all of TorchLight except analyses (I,II). The latter requires the sampling of random states. The respective total data is given in rows \u201cTorchLight (III)\u201d and \u201cSP total\u201d/ \u201cSP1s total\u201d in Table 2. Here the picture changes dramatically in favor of SP and especially SP1s. It should\nbe noted, though, that this is mostly due to the overhead for the translation to finite-domain variables. This overhead is an artifact of the implementation. Our approach is defined for finite-domain variables, while the benchmarks are not, even though the finite-domain representation is in most cases more natural than the Boolean one. Further, many planners (notably Fast Downward and its quickly growing set of derivatives) use the translation anyway. The runtimes without translation are given in the row \u201cTorchLight (III) no FD\u201d.\nAs one would hope and expect, the analysis methods are much faster than actual planners. LAMA has 112 time-outs in our test suite, FF has 173."}, {"heading": "8.5 Analyzing Domains", "text": "We now discuss the actual analysis outcomes, on a per-domain basis. We first consider only TorchLight, then give some details on the comparison of analysis (III) success rates to those obtained by search probing. Before we begin, a few words are in order regarding the comparison between SP and SP1s. With R = 1, 10, 100, 1000, the success rates are identical in 99.83%, 99.14%, 97.5%, 94.66% of our 1160 benchmark instances respectively; in 99.83%, 99.14%, 99.31%, 98.97% of the instances, the success rates differ by at most 5%. Thus, a small runtime cut-off does not adversely affect the success rates of search probing (because long searches are rare). This being so, we henceforth do not discuss the data for SP vs. SP1s separately. We compare TorchLight\u2019s analysis (III) success rates to those of SP only.\nThe guarantees of Proposition 1 are confirmed, i.e., guaranteed global analysis (I) succeeds as described in Logistics, Miconic-STRIPS, Movie, and Simple-TSP. It never succeeds in any other domain, though. In some domains, fractions of the gDGs are successful. Precisely, the maximum fraction of successful gDGs is 97% in Satellite, 50% in Ferry, 33.33% in TPP, 22.22% in Driverlog, 20% in Depots, 13.33% in Tyreworld, and 12.5% in BlocksworldArm. However, if the fraction is below 100% then nothing is proved, so this data may at best be used to give an indication of which aspects of the domain are \u201cgood-natured\u201d. Guaranteed local analysis (II) generally is not much more applicable than global analysis. Thus we now concentrate on approximate local analysis (III) exclusively.\nProposition 2 is backed up impressively. Even with R = 1000, analysis (III) succeeds in every single sample state of Ferry, Gripper, Elevators, and Transport.15 This indicates strongly that the potentially sub-optimal relaxed plans do not result in a loss of information here. Indeed, the analysis yields high success rates in almost all domains where local minima are non-present or limited. This is not the case for the other domains, and thus TorchLight can distinguish domains with \u201ceasy\u201d h+ topology from the \u201chard\u201d ones. Consider Figure 3, showing mean analysis (III) success rates per-domain with R = 1. (The picture is similar for R = 10, 100, 1000; cf. Table 3 below.)\nThe domains whose h+ topology is not known are shown separately on the right hand side in Figure 3. For the other domains, we see quite nicely that \u201charder\u201d domains tend to have lower success rates. In particular, the easiest domains in the bottom class all have 100% success rates (95% in the case of Zenotravel), whereas the hardest domains in the top right corner only have around 50% or less. In the latter domains, to some extent the\n15. Historically, this observation preceded Proposition 2, as well as the h+ topology categorization of Elevators and Transport as per Figure 1. That is, these hand-made analyses were motivated by observing TorchLight\u2019s analysis outcome.\nlow success rates result from the recognition of dead ends by FF\u2019s heuristic function. For example, if during random sampling we make random vehicle moves consuming fuel, like in Mystery and Mprime, then of course chances are we will end up in a state where fuel is so scarce that even a relaxed plan does not exist anymore. This is most pronounced in Airport, where all sample states here have infinite heuristic values. However, the capabilities of the analysis go far beyond counting states on recognized dead ends. In Blocksworld-Arm, for example, there are no dead ends at all and still the success rate is only 30%, clearly indicating this as a domain with a difficult topology.\nTo some extent, based on the success rates we can even distinguish Pipesworld-Tankage from Pipesworld-NoTankage, and Mprime from Mystery (in Mprime, fuel can be transferred between locations). The relatively high success rate in Depots probably relates to its transportation aspects. In Grid, in 20% of cases our analysis is not strong enough to recognize the reasons behind non-existence of local minima; these reasons can be quite complicated (Hoffmann, 2003). Dining-Philosophers does not really have a favorable h+ topology. Its rather excessive bound 31 is due to the very particular domain structure where philosophers behave in strictly symmetrical ways (Hoffmann, 2005). Apart from this, the only strong outliers are Driverlog, Rovers, Hanoi, and Blocksworld-NoArm. All of these are more problems of the hand-made analysis than of TorchLight\u2019s. In Driverlog and Rovers, deep local minima do exist, but only in awkward situations that don\u2019t tend to arise in the IPC instances. Thus the hand-made analysis, which is of a worst-case nature, is too pessimistic here. The opposite happens in Hanoi and Blocksworld-NoArm, where the absence of local minima is due to rather idiosyncratic reasons. For example, in Hanoi the reason is that h+ is always equal to the number of discs not yet in goal position \u2013 in the relaxation, one can always accomplish the remaining goals one-by-one, regardless of the constraints entailed by their positioning. Hanoi and Blocksworld-NoArm are not actually \u201ceasy to solve\u201d for\nFF, and in that sense, from a practical perspective, the low success rates of TorchLight\u2019s analysis (III) provide the more accurate picture.\nTable 3 gives a complete account of per-domain averaged success rates data, including all domains, all values of R, the rates obtained on initial states, and using SP instead of TorchLight. This serves to answer three questions:\n(1) Is it important to sample random states, rather than only analyzing the initial state?\n(2) Is it important to sample many random states?\n(3) How competitive is analysis (III) with respect to a search-based analysis?\nThe answer to question (1) is a clear \u201cyes\u201d. Most importantly, this pertains to domains with dead ends, cf. our brief discussion above. It is clear from Table 3 that, in such domains, analyzing sI results in a tendency to be too optimistic. To see this, just consider the entries for Airport, Dining-Philosophers, Freecell, Mystery, Openstacks, Parc-Printer, Pathways, TPP, Trucks, and Woodworking. All these domains have dead ends, for a variety of reasons. The dead ends do not occur frequently at initial state level, but do occur frequently during random walks \u2013 cf. column \u201cDE\u201d in Table 3. (Interestingly, in a few domains \u2013 most notably the two Pipesworlds \u2013 the opposite happens, i.e., success rates are lower for sI than for the sample states. It is not clear to us what causes this phenomenon.)\nIf we simply compare the sI column with the R = 1000 column for analysis (III), then we find that the result is \u201ca lot\u201d different \u2013 more than 10% \u2013 in 22 of the 37 domains. To some extent, this difference between initial states and sample states may be just due to the way these benchmarks are designed. Often, the initial states of every instance are similar in certain ways (no package loaded yet, etc). On the other hand, it seems quite natural, at least for offline problems, that the initial state is different from states deeper down in the state space (consider transportation problems or card games, for example).\nThe answer to question (2) is a clear \u201cno\u201d. For example, compare the R = 1 and R = 1000 columns for analysis (III). The difference is greater than 10% in only 6 of the 37 domains. The peak difference is in Openstacks, with 16.6% for R = 1000 vs. 0% for R = 1. The average difference over all domains is 4.17%. Similarly, comparing the R = 1 and R = 1000 columns for SP results in only 5 of 37 domains where the difference is greater than 10%, the peak being again in Openstacks, 20.8% for R = 1000 vs. 4.4% for R = 1. The average difference over all domains is 3.7%.\nThe answer to question (3) is a bit more complicated. Look at the columns for analysis (III) respectively SP with R = 1000. The number of domains where the difference is larger than 10% is now 11 out of 37, with a peak of 64.6% difference in Scanalyzer. On the one hand, this still means that in 26 out of 37 domains the analysis result we get is very close to that of search (average difference 2.18%), without actually running any search! On the other hand, what happens in the other 11 domains? In all of these, the success rate of SP is higher than that of TorchLight. This is not surprising \u2013 it basically means that TorchLight\u2019s analysis is not strong enough here to recognize all states that are not on local minima.\nInterestingly, this weakness can turn into an unexpected advantage. Of the 11 domains in question, 8 domains \u2013 Blocksworld-Arm, Depots, Mprime, Pipesworld-Tankage, PipesworldNoTankage, PSR, Scanalyzer, and Sokoban \u2013 do contain deep local minima.16 Thus, in these 8 domains, we would wish our analysis to return small success rates. TorchLight grants this wish much more than SP does. Consider what happens when using SP instead of analysis (III) in Figure 3. For Mystery, PSR, and Sokoban, the change is not dramatic. However, Blocksworld-Arm is marked with average success rate 93 instead of 30, putting it almost on par with the very-simple-topology domains in the bottom class. Similarly, PipesworldTankage, Pipesworld-NoTankage, and Scanalyzer are put almost on par with these. Depots\n16. Sokoban has unrecognized dead-ends (in the relaxation, blocks can be pushed across each other) and therefore local minima. In Scanalyzer, analyzing plants misplaces them as a side effect, and bringing them back to their start position, across a large circle of conveyor belts, may take arbitrarily many steps. See Figure 3 for the other 6 domains.\nactually receives a 100, putting it exactly on par with them. Thus the SP analysis outcome actually looks quite a bit worse, in 5 of the domains.\nWhat causes these undesirably high success rates for SP? The author\u2019s best guess is that, in many domains, the chance of randomly finding a state on a local minimum is low. In large-scale experiments measuring statistics on the search space surface under FF\u2019s heuristic function (Hoffmann, 2003), it was observed that many sampled states were not local minima themselves, but where contained in \u201cvalleys\u201d. Within a valley, there is no monotonically decreasing path to a goal state. Such a state may not be a local minimum because, and only because, one can descend deeper into the valley. It seems that SP correctly identifies most valley states to not be local minima, thus counting as \u201cgood\u201d many states that actually are located in difficult regions of the search space. This is a weakness not of SP, but of success rate as a search space feature.17 Why does this weakness not manifest itself as much in analysis (III)? Because that analysis is \u201cmore picky\u201d \u2013 it takes as \u201cgood\u201d only states that qualify for particular special cases. These tend to not occur as often in the difficult domains.\nOf course, it is easy to construct examples turning the discussed \u201cstrength\u201d into a real weakness of TorchLight\u2019s analysis quality. This just does not seem to happen a lot in the present benchmarks. Now, having said that, the present benchmarks aren\u2019t well suited to bring out the theoretical advantage of analysis (III) either. The analysis offers unlimited lookahead depth at low-order polynomial cost. However, even with R = 1000, in 23 of the 37 domains the highest exit distance bound returned is 0, i.e., every exit path identified consists of a single operator. These cases could be handled with a much simpler variant of analysis (III), looking only at operators o0 that are directly applicable in s, and thus removing the entire machinery pertaining to SG predecessors of x0. Still, that machinery does matter in cases that are quite natural. The highest exit distance bound returned is 10 in Grid and 7 in Transport. More generally, in any transportation domain with a non-trivial road-map, it is easy to construct relevant situations. For example, say the road map in Transport forms N \u201ccities\u201d, each with diameter D and at least one vehicle, distances between cities being large relative to D. Then, in a typical state, around N vehicle moves will be considered helpful by FF: at least 1 per city since local vehicles will be preferred by the relaxed plan. All successor states will have identical h+ until a package can be loaded/unloaded. The typical number of steps required to do so will grow with D. If, for example, the vehicle is in the \u201coutskirts\u201d and the packages are in the \u201ccity center\u201d, then around D/2 steps are required, and finding an exit takes runtime around ND/2. Then small values of N and D already render search probing either devoid of information (if the runtime cut-off is too small), or computationally infeasible (recall that the probing should be a \u201cquick\u201d pre-process to the actual planning). By contrast, analysis (III) easily delivers the correct success rate 100%."}, {"heading": "8.6 Predicting Planner Performance", "text": "As a direct measure of the \u201cpredictive quality\u201d of success rates, we conducted preliminary experiments examining the behavior of primitive classifiers, and of runtime distributions for large vs. small success rates. We consider first the classifiers. They predict, given a planning task, whether EHC/FF/LAMA will succeed in solving the task, within the given\n17. Note that we cannot use \u201cvalley rate\u201d instead, in a cheap domain analysis, since determining whether or not s lies on a valley implies finding a plan for s and thus solving the task as a side effect.\ntime and memory limits. The classifiers answer \u201cyes\u201d iff the success rate is \u2265 a threshold T in 0, 10, . . . , 100. Obviously, to do this, we need R > 1. We consider in what follows only R = 10 and R = 100 because, as shown above, R = 1000 can be costly.\nFor EHC, both TorchLight analysis (III) and SP deliver fairly good-quality predictions, considering that no actual machine learning is involved. The prediction quality of TorchLight is just as good as \u2013 sometimes slightly better than \u2013 that of search. Whether we use R = 10 or R = 100 does not make a big difference. EHC solves 60.69% of the instances, so that is the rate of correct predictions for a trivial baseline classifier always answering \u201cyes\u201d. For R = 10, the best rate of correct predictions is 71.90% for TorchLight (with T = 80) and 70.17% for SP (with T = 90). For R = 100, these numbers are 71.76% (T = 60) and 71.16% (T = 100). Dead-end rate is a very bad predictor. Its best prediction is for the baseline classifier T = 0, and the second best classifier (T = 100) is only 36.79% correct.\nInterestingly, there are major differences between the different sets of domains. On the domains previously analyzed by hand (Hoffmann, 2005; as in Figure 1 but without Elevators and Transport), the best prediction is 75.75% correct for TorchLight with T = 70, and 74.07% correct for SP with T = 100, vs. a baseline of 63.81%. On the IPC 2006 domains, these numbers are 57.98% and 61.34% vs. baseline 55.46%, and T = 10 in both cases, i.e., the best classifier is very close to the baseline. IPC 2008, on the other hand, appears to be exceptionally good-natured, the numbers being 79.52% (T = 60) and 82.38% (T = 80) vs. baseline 51.90%. It is not clear to us what causes these phenomena.18\nIn summary, the quality of prediction is always clearly above the baseline, around 10% when looking at all domains, and even up to 30% when looking at the IPC 2008 domains only. For comparison, using state-of-the-art classification techniques but only simple features, Roberts and Howe (2009) get 69.47% correctness vs. baseline 74% (for saying \u201cno\u201d), on unseen testing domains for FF. Having said that, if setting T in the above is considered to be the \u201clearning\u201d, then the above does not actually distinguish between learning data and testing data. Roberts and Howe\u2019s unseen testing domains are those of IPC 2006 (in a different setting than ours including also all ADL test suites). If we set T on only the domains from before 2006 (Figure 1 without Elevators and Transport), then we get the best prediction at T = 70 for TorchLight and T = 100 for SP. With this setting of T , the prediction correctness on our IPC 2006 suite is 29.41% respectively 51.26% only, vs. the baseline 55.46%. On the other hand, this seems to pertain only to IPC 2006 specifically. For IPC 2008, T = 70 respectively T = 100 are good settings, giving 76.67% respectively 76.19% correctness vs. the baseline 51.90%.\nImportantly, Roberts and Howe are not predicting the performance of EHC but that of FF, which is a more complex algorithm. For FF and LAMA, the prediction quality of both TorchLight and SP is rather bleak, using the described primitive classifiers. In all cases, the best prediction correctness is obtained when always answering \u201cyes\u201d. The best that can be said is that success rate still predicts much better than dead-end rate. To give some example data, with R = 10 across all domains for FF, the baseline is 85.09% correct. With T = 10, this goes down to 77.50% for TorchLight, 79.31% for SP, and 34.57% for dead-end rate. For LAMA, the baseline is 90.26% correct, and with T = 10 this goes down to 81.81%\n18. The bad prediction quality in IPC 2006 domains might be related to the fact that these are fully grounded, potentially impeding the ability of Fast Downward\u2019s translator to find useful finite-domain variables.\nfor TorchLight, 83.97% for SP, and 29.91% for dead-end rate. For both FF and LAMA, with growing T the prediction quality decreases monotonically in all cases.\nWhy is prediction quality so much worse for FF than for EHC, which after all is the main building block of FF? Whereas EHC typically fails on tasks whose h+ topology is not favorable, FF\u2019s and LAMA\u2019s complete search algorithms are able to solve many of these cases, too. For example, with TorchLight success rates and R = 10, EHC solves only 34.07% of the tasks with success rate 0, and solves less than 50% up to success rate 70%. By contrast, FF and LAMA solve 74.18% respectively 76.92% of the tasks with success rate 0, and solve at least 70% for all success rates.\nDespite this, success rates are far from devoid of information for FF and LAMA. Setting the threshold T in 10, . . . , 100, we look at the distribution of planner runtime in the instance subset (A) where success rate is < T , vs. instance subset (B) where success rate is \u2265 T . Taking the null hypothesis to be that the means of the two runtime distributions are the same, we run the Student\u2019s T-test for unequal sample sizes to determine the confidence with which the null hypothesis can be rejected. That is, we determine the confidence with which distribution (B) has a lower mean than distribution (A). Using TorchLight\u2019s success rate on FF runtimes, with both R = 10 and R = 100, and in all 10 settings of T , we get a confidence of at least 99.9%. The difference between the means in our data, i.e., the mean runtime of (A) minus the mean runtime of (B), tends to grow over T . It peaks at 336 respectively 361 seconds for R = 10 respectively R = 100; the average difference over all values of T is 239 respectively 240. Likewise, for LAMA runtimes all settings of T and R yield a confidence of 99.9%, with average differences 242 respectively 235. The results for SP are comparable for LAMA. They are slightly worse for FF, though. With R = 10 the confidence is 99.9% only for T = 10, 20; the confidence is 95% for all other values of T . The difference peaks at 241 seconds (vs. 336 for TorchLight), with an average of 150 seconds (vs. 239). With R = 100, thresholds T = 30, 40, 50, 100 yield 99.9% confidence, the average difference being 160.\nAgain perhaps a little surprisingly, for the simpler planner EHC the runtime distributions behave very differently. For TorchLight success rates, we do get several cases with confidence < 95%, and average differences of around 80 seconds. For SP, in most cases we get a 99.9% confidence that the mean of (B) is larger than that of (A). Again, the reason is simple. On many tasks with unfavorable h+ topology, enforced hill-climbing quickly exhausts the space of states reachable by FF\u2019s helpful actions. EHC then gives up on solving the task, although it has consumed only little runtime \u2013 a peculiar behavior that one would certainly not expect from a planner trying to be competitive.\nSumming up, success rates as a planning task feature provide a very good coverage predictor for EHC even without any significant learning. For FF and LAMA, things are not that easy, however the consideration of runtime distributions clearly shows that the feature is highly informative. Exploiting this informativeness for predicting planner performance presumably requires combination with other features, and actual machine learning techniques, along the lines of Roberts and Howe (2009). This is a topic for future research."}, {"heading": "8.7 Diagnosis", "text": "Let us finally consider TorchLight\u2019s diagnosis facility. The idea behind this facility is to summarize the reasons for analysis failure. Testing sufficient criteria for the absence of local\nminima, such diagnosis is not guaranteed to identify domain features causing their presence. Still, at least for analysis using Theorem 2, the diagnosis can be quite accurate.\nThe current diagnosis facility is merely a first-shot implementation based on reporting all pairs (operator o0, variable x) that caused an oDG+ for o0 to not be successful. That is, we report the pair (o0, x) if o0 has an effect on x, and a context fact (x, c) of the transition t0 taken by o0 is contained in R+1 \u2229 C0 \u2229 F0, and is not recoverable by a sub-sequence of P+>0(s). In brief, we record (o0, x) if o0 has a harmful effect on x. We perform a test whether the \u201cmain\u201d effect of o0, i.e., that on x0, is invertible; in this case we do not record x0 since the problem appear to be the side effects. To avoid redundancies in the reporting, we record not the grounded operator o0 but only the name of the action schema (\u201cload\u201d instead of \u201cload(package1 truck7)\u201d). Similarly, as an option we record not x but the name of the predicate underlying the fact (x, c). In that configuration, the diagnosis comes in the form of \u201caction-name, predicate-name\u201d, which has a direct match with the high-level PDDL input files. To have some measure of which parts of the diagnosis are \u201cmore important\u201d, we associate each pair with a count of occurrences, and weigh the pairs by frequency.\nIn Zenotravel, the diagnosis output always has the form \u201cfly, fuel-level\u201d and \u201czoom, fuel-level\u201d, indicating correctly that it\u2019s the fuel consumption which is causing the local minima. In Mprime and Mystery, the cause of local minima is the same, however the diagnosis is not as reliable because of the specific structure of the domain, associating fuel with locations instead of vehicles. This sometimes causes the diagnosis to conclude that it is the effect changing locations which is causing the trouble. Concretely, with R = 1000 in Mystery, fuel consumption is the top-weighted diagnosis in 17 out of the 28 tasks; in Mprime, this happens in 30 out of the 35 tasks. In Satellite and Rovers, the diagnosis always takes the form \u201cswitch-on, calibrated\u201d respectively \u201ctake-image, calibrated\u201d, thus reporting the problem to be that switching on an instrument, respectively taking an image, deletes calibration. This is precisely the only reason why local minima exist here.19 In Tyreworld, most often the diagnosis reports the problem to be that jacking up a hub results in no longer having the jack (which is needed elsewhere, too). While this does not actually cause local minima (there are none), it indeed appears to be a crucial aspect of the domain. Similarly, in Grid the most frequent diagnosis is that picking up a key results in the arm no longer being empty \u2013 again, not actually a cause of local minima, but a critical resource in the domain. In Blocksworld-Arm, the dominant diagnoses are that a block is no longer clear if we stack something on top of it, and that the hand is no longer empty when picking up a block. Similarly, in Freecell, the dominant diagnoses are \u201csend-to-free, cellspace\u201d and \u201csend-to-new-col, colspace\u201d.\nOne could make the above list much longer, however it seems clear already that this diagnosis facility, although as yet primitive, has the potential to identify interesting aspects of the domain. Note that we are making use of only one of the information sources in TorchLight. There are many other things to be recorded, pertaining to other reasons for analysis failure, like support graph cycles etc, and also to reasons for analysis success, like successful gDGs and x0, o0 pairs yielding successful oDG+s. It appears promising to try to improve diagnosis by combining some of these information sources. A combination with\n19. Since analysis failure is rare in these two domains, often diagnosis does not give any output at all. With R = 1000, the output is non-empty in 10 instances of Satellite and in 8 instances of Rovers. For R = 100 this reduces to 4 instances in Satellite, and not a single one in Rovers.\nother domain analysis techniques, like landmarks or invariants extraction, could also be useful. This is a direction for future work.20"}, {"heading": "9. Related Work", "text": "There is no prior work \u2013 other than the aforementioned one of the author (Hoffmann, 2005) \u2013 trying to automatically infer topological properties of a heuristic function. Thus our work does not relate strongly to other domain analysis techniques. The closest relation is to other techniques relying on causal graphs. In what follows we discuss this in some detail, along with some other connections arising in this context.\nIf local analysis succeeds, then we can construct a path to the exit identified. In this, our work relates to work on macro-actions (e.g., Botea, Mu\u0308ller, & Schaeffer, 2004; Vidal, 2004). Its distinguishing feature is that this macro-action is (would be) constructed in a very targeted and analytical way, even giving a guarantee, in the conservative case, to make progress towards the goal. The machinery behind the analysis is based on causal graphs, and shares some similarities with known causal-graph based execution path generation methods (e.g., Jonsson & Ba\u0308ckstro\u0308m, 1995; Williams & Nayak, 1997; Brafman & Domshlak, 2003). The distinguishing feature here is that we focus on h+ and individual states rather than the whole task. This allows us to consider small fragments of otherwise arbitrarily complex planning tasks \u2013 we look at oDG+ instead of SG. Note that this ability is quite powerful as far as applicability goes. As we have seen in Section 8, the success rate of (local) approximate analysis \u2013 and therewith the fraction of states for which we would be able to generate a macro-action \u2013 is non-zero in almost all benchmark domains. Of course, this broad applicability comes with a prize. While traditional causal graph methods guarantee to reach the goal, in the worst case the macro-actions may only lead into h+ local minima. Still, it may be interesting to look into whether other, traditional, causal-graph based methods can be \u201clocalized\u201d in this (or a similar) manner as well.\nGlobal analysis, where we focus on the whole planning task and thus the whole causal graph, is even more closely related to research on causal graphs based tractability analysis. The major difference between tractability analysis and h+ topology analysis, in principle, is that tractability and absence of local minima are orthogonal properties \u2013 in general, neither one implies the other. Now, as we pointed out at the end of Section 6, our global analysis does imply tractability (of plan existence). Vice versa, do the restrictions made in known tractable classes imply the absence of local minima? In many cases, we can answer this question with a definite \u201cno\u201d; some interesting questions are open; in a single case \u2013 corresponding to our basic result \u2013 the answer is \u201cyes\u201d.\nExample 3 in Appendix A.4 shows that one can construct a local minimum with just 2 variables of domain size 3, 1-arc SG, unary operators, and strongly connected DTGs with a single non-invertible transition. This example (and various scaling extensions not breaking the respective conditions) falls into a variety of known tractable classes. The example is in\n20. In particular, Fast Downward\u2019s translator is not always perfect in detecting the finite-domain variables underlying benchmarks. For example, in Satellite it often does not detect that electricity is available in exactly one of the instruments mounted on a satellite. This can lead to pointless diagnosis output, which for now is handled using a simple notion of predicates \u201cexchanged\u201d by every operator. For doing things like this in a more principled manner, further invariants analysis would be useful.\nthe tractable class F\u2228n identified by Domshlak and Dinitz (2001), because every transition of the dependent variable depends on the other variable. The example is in Helmert\u2019s (2004, 2006) SAS+-1 class with strongly connected DTGs. The example is \u201csolved\u201d, i.e., reduced to the empty task, by Haslum\u2019s (2007) simplification techniques (also, these techniques solve tasks from the Satellite domain, which do contain local minima). The example has a fork and inverted fork causal graph, with bounded domain size and 1-dependent actions only (actions with at most 1 prevail condition), thus it qualifies for the tractable classes identified by Katz and Domshlak (2008b). The example\u2019s causal graph is a chain, and thus in particular a polytree with bounded indegree, corresponding to the tractable class identified by Brafman and Domshlak (2003) except that, there, variables are restricted to be binary (domain size 2). It is an open question whether plan existence with chain causal graphs and domain size 3 is tractable; the strongest known result is that it is NP-hard for domain size 5 (Gime\u0301nez & Jonsson, 2009b).21 Similarly, the example fits the prerequisites stated by Katz and Domshlak (2008a) except that these are for binary variables only; it is an open question whether local minima exist in the tractable classes identified there. Finally, the example, and a suitable scaling extension, obviously qualifies for two theorems stated by Chen and Gimenez (2010). Their Theorem 3.1 (more precisely, the first part of that theorem) requires only a constant bound on the size of the connected components in the undirected graph induced by the causal graph. The first part of their Theorem 4.1 requires a constant bound on the size of the strongly connected components in the causal graph, and pertains to a notion of \u201creversible\u201d tasks requiring that we can always go back to the initial state.\nNext, consider the line of works restricting not the causal graph but the DTGs of the task (Ba\u0308ckstro\u0308m & Klein, 1991; Ba\u0308ckstro\u0308m & Nebel, 1995; Jonsson & Ba\u0308ckstro\u0308m, 1998). The simplest class identified here, contained in all other classes, is SAS+-PUBS where each fact is achieved by at most one operator (\u201cpost-unique\u201d, \u201cP\u201d), all operators are unary (\u201cU\u201d), all variables are binary (\u201cB\u201d), and all variables have at most one value required in the condition of a transition on any other variable (\u201csingle-valued\u201d, \u201cS\u201d). Now, Example 2 in Appendix A.4 shows a local minimum in an example that has the U and S properties. The example has two variables, x and y, and the local minimum arises because a cyclic dependency prevents y from attaining its goal value dn via the shortest path as taken by an optimal relaxed plan. If we remove all but two values from the domain of y, and remove the alternative way of reaching dn,22 then the example still contains a local minimum and also has the P and B properties. We remark that the modified example is unsolvable. It remains an open question whether solvable SAS+-PUBS tasks with local minima exist; more generally, this question is open even for the larger SAS+-PUS class, and for the (yet larger) SAS+-IAO class identified by Jonsson and Ba\u0308ckstro\u0308m (1998).\nAnother open question is whether the \u201c3S\u201d class of Jonsson and Ba\u0308ckstro\u0308m (1995) contains local minima. The class works on binary variables only; it requires unary operators and acyclic causal graphs, however it allows facts to be \u201csplitting\u201d instead of reversible. If p is splitting then, intuitively, the task can be decomposed into three independent subtasks with respect to p; it is an open question whether local minima can be constructed\n21. Although, of course, it is clear that, if the DTGs are strongly connected as in our case, then deciding plan existence is tractable no matter what the domain size is. 22. This modification is given in detail below the example in Appendix A.4.\nwhile satisfying this property. Disallowing the \u201csplitting\u201d option in 3S, we obtain the single \u201cpositive\u201d case, where a known tractable class does not contain any local minima. This class corresponds to our basic result \u2013 acyclic causal graphs and invertible transitions \u2013 except that the variables are restricted to be binary. Williams and Nayak (1997) mention restrictions (but do not make formal claims regarding tractability) corresponding exactly to our basic result except that they allow irreversible \u201crepair\u201d actions. The latter actions are defined relative to a specialized formal framework for control systems, but in spirit they are similar to what we term \u201ctransitions with self-irrelevant deletes\u201d herein.\nFinally, it is easy to see that, of Bylander\u2019s (1994) three tractability criteria, those two allowing several effects do not imply the absence of local minima. For his third criterion, restricting action effects to a single literal and preconditions to positive literals (but allowing negative goals), we leave it as an open question whether or not local minima exist. We remark that this criterion does not apply in any benchmark we are aware of.\nTo close this section, while we certainly do not wish to claim the identification of tractable classes to be a contribution of our work, we note that the scope of Theorem 4 \u2013 which is a tractable class, cf. the above \u2013 is not covered by the known tractable classes.23 The tractable cases identified by Bylander (1994) obviously do not cover any of Logistics, Miconic-STRIPS, Movie, and Simple-TSP. Many causal graph based tractability results require unary operators (Jonsson & Ba\u0308ckstro\u0308m, 1995; Domshlak & Dinitz, 2001; Brafman & Domshlak, 2003; Helmert, 2004, 2006; Katz & Domshlak, 2008a, 2008b; Jonsson, 2009; Gime\u0301nez & Jonsson, 2008, 2009a), which does not cover Miconic-STRIPS, Movie, and Simple-TSP. In the work of Chen and Gimenez (2010), Theorem 4.1 requires reversibility which is not given in either of Movie, Miconic-STRIPS, or Simple-TSP, and Theorem 3.1 requires a constant bound on the size of the connected components in the undirected graph induced by the causal graph, which is given in none of Logistics, MiconicSTRIPS, and Simple-TSP. Other known tractability results make very different restrictions on the DTGs (Ba\u0308ckstro\u0308m & Klein, 1991; Ba\u0308ckstro\u0308m & Nebel, 1995; Jonsson & Ba\u0308ckstro\u0308m, 1998). Even the most general tractable class identified there, SAS+-IAO, covers none of Miconic-STRIPS, Logistics, and Simple-TSP (because vehicle variables are not \u201cacyclic with respect to requestable values\u201d), and neither does it cover Movie (because rewinding a movie is neither unary nor \u201cirreplaceable\u201d: it has a side effect un-setting the counter, while not breaking the DTG of the counter into two disjoint components).\nAs far as coverage of the benchmarks goes, the strongest competitor of Theorem 4 are Haslum\u2019s (2007) simplification techniques. These iteratively remove variables where all paths relevant for attaining required conditions are \u201cfree\u201d, i.e., can be traversed using transitions that have neither conditions nor side effects. Haslum\u2019s Theorem 1 states that such removal can be done without jeopardizing solution existence, i.e., a plan for the original task can be reconstructed easily from a plan for the simplified task. In particular, if the task is \u201csolved\u201d \u2013 simplified completely, to the empty task \u2013 then a plan can be constructed in polynomial time. Haslum combines this basic technique with a number of domain reformulation techniques, e.g., replacing action sequences by macros under certain conditions. The choice which combination of such techniques to apply is not fully automated, and parts\n23. This is not true of our basic result, which as just explained is essentially covered by the works of Jonsson and Ba\u0308ckstro\u0308m (1995) and Williams and Nayak (1997). Formally, its prerequisites imply those of (the first part of) Theorem 4.1 in the work of Chen and Gimenez (2010), namely, the postulated bound is 1.\nof these techniques are not fully described, making a comparison to Theorem 4 difficult. Haslum reports his techniques to solve tasks from Logistics, Miconic-STRIPS, and Movie, plus Gripper and Satellite. Haslum does not experiment with Simple-TSP. His Theorem 1, in its stated form, does not solve Simple-TSP, because there the transitions of the root variable have side effects (with irrelevant deletes). Extending the theorem to cover such irrelevant deletes should be straightforward. A more subtle weakness of Haslum\u2019s Theorem 1 relative to our Theorem 4 pertains to reaching required values from externally caused values. Haslum requires these moves to be free, whereas, in the definition of recoverable side effect deletes, Theorem 4 allows the recovering operators to affect several variables and to take their precondition from the prevails and effects of o0."}, {"heading": "10. Conclusion", "text": "We identified a connection between causal graphs and h+, and devised a tool allowing to analyze search space topology without actually running any search. The tool is not yet an \u201cautomatic Hoffmann\u201d, but its analysis quality is impressive even when compared to unlimited search probing.\nAt a very generic level, a conclusion of this work is that, sometimes, it is possible to automatically infer topological properties of a heuristic function. An interesting question for future work is whether this can also be done for heuristics other than h+ (cf. also the comments regarding causal graph research below). Methodologically, it is noteworthy that the analysis is based on syntactic restrictions on the problem description, which has traditionally been used to identify tractable fragments (of planning and other computationally hard problems). The present work showcases that very similar techniques can apply to the analysis of the search spaces of general problem solvers.\nA main open question is whether global analysis can more tightly approximate the scope of Theorem 2. As indicated, a good starting point appears to be trying to include, in a gDG for operator o0, only variable dependencies induced by operators o that may actually precede o0 in an optimal relaxed plan. An approach automatically recognizing such operators could possibly be developed along the lines of Hoffmann and Nebel (2001b), or using a simplified version of the aforementioned \u201cfact generation tree\u201d analysis technique (Hoffmann, 2005). Additionally, it would be great to recognize situations in which harmful side effects of o0 \u2013 like making the hand non-empty if we pick up a ball in Gripper \u2013 will necessarily be recovered inside the relaxed plan. Possibly, such analysis could be based on a variant of action landmarks (Hoffmann, Porteous, & Sebastia, 2004; Karpas & Domshlak, 2009).\nAnother interesting line of research is to start from results given for individual states s by local analysis, then extract the reasons for success on s, and generalize those reasons to determine a generic property under which success is guaranteed. Taken to the extreme, it might be possible to automatically identify domain sub-classes, i.e., particular combinations of initial state and goal state, in which the absence of local minima is proved.\nThis work highlights two new aspects of causal graph research. First, it shows that, in certain situations, one can \u201clocalize\u201d the causal graph analysis, and consider only the causal graph fragment relevant for solving a particular state. Second, one can use causal graphs for constructing paths not to the global goal, but to a state where the value of a heuristic h is decreased. The former enables the analysis to succeed in tasks whose causal graphs are\notherwise arbitrarily complex, and thus has the potential to greatly broaden the scope of applicability. The latter is not necessarily limited to only h+ \u2013 as a simple example, it is obvious that similar constructions can be made for the trivial heuristic counting the number of unsatisfied goals \u2013 and thus opens up a completely new avenue of causal graph research.\nAnother possibility is planner performance prediction, along the lines of Roberts and Howe (2009). Our experimental results indicate that TorchLight\u2019s problem features, and also those of search probing, are highly informative. This has the potential to significantly improve the results of Roberts and Howe for unseen domains \u2013 they currently use only very simple features, like counts of predicates and action schemes, that hardly capture a domainindependent structure relevant to planner performance. Like limited search probing (SP1s), TorchLight generates its features without jeopardizing runtime, thus enabling automatic planner configuration. Unlike for search probing, this may even work on-line during search: a single relaxed plan can already deliver interesting information. For example, one might make the search more or less greedy \u2013 choosing a different search strategy, switching helpful actions on or off, etc. \u2013 depending on the outcome of checking Theorem 2.\nAs mentioned in Section 9, a direction worth trying is to use local analysis for generating macro-actions. In domains with high success rate, it seems likely that the macro-actions would lead to the goal with no search at all. It is a priori not clear, though, whether such an approach would significantly strengthen, at least in the present benchmarks, existing techniques for executing (parts of) a relaxed plan (e.g., Vidal, 2004).\nOne could use TorchLight\u2019s diagnosis facility as the basis of an abstraction technique for deriving search guidance, much as is currently done with other relaxation/abstraction techniques. The diagnosis can pin-point which operator effects are causing problems for search. If we remove enough harmful effects to end up with a task to which Theorem 4 applies, then the abstracted problem is tractable. For example, in transportation domains, this process could abstract away the fuel consumption. If we do not abstract that much, then the information provided may still outweigh the effort for abstract planning, i.e., for using an actual planner inside the heuristic function. For example, in Grid the abstract task could be a problem variant allowing to carry several keys at once. One could also focus the construction of different heuristics \u2013 not based on ignoring deletes \u2013 on the harmful effects.\nFinally, an interesting research line is domain reformulation. As is well known, the domain formulation can make a huge difference for planner performance. However, it is very difficult to choose a \u201cgood\u201d formulation, for a given planner. This is a black art even if the reformulation is done by the developer of the planner in question. The lack of guidance is one of the main open problems identified by Haslum (2007) for his automatic reformulation approach. The most frequent question the author has been asked by non-expert users is how to model a domain so that FF can handle it more easily.\nTorchLight\u2019s diagnosis facility, pin-pointing problematic effects, might be instrumental for addressing these difficulties. For the case where the reformulation is done by a computer, one possibility to use the analysis outcome could be to produce macro-actions \u201chiding\u201d within them the operators having harmful effects. Another possibility could be to precompose variable subsets touched by the harmful effects.\nFor the case where the reformulation is done by a human user, the sky is the limit. To name just one example, the local minima in Satellite could be removed by allowing to switch on an instrument only when pointing in a direction where that instrument can\nbe calibrated. More generally, note that end-user PDDL modeling \u2013 writing of PDDL by a non-expert user wanting to solve her problem using off-the-shelf planners \u2013 is quite different from the PDDL modeling that planning experts do when developing benchmarks. For example, if an expert models a transportation benchmark with fuel consumption, then it may seem quite pointless for TorchLight to determine that fuel consumption will hurt planner performance. Indeed this may be the reason why the fuel consumption was included in the first place. By contrast, for an end-user (a) this information may come as a surprise, and (b) the user may actually choose to omit fuel consumption because this may yield a better point in the trade-off between planner performance and plan usability. Generally speaking, such an approach could give the user guidance in designing a natural hierarchy of increasingly detailed \u2013 and increasingly problematic \u2013 domain formulations. This could help making planning technology more accessible, and thus contribute to a challenge that should be taken much more seriously by the planning community."}, {"heading": "Acknowledgments", "text": "I would like to thank the anonymous reviewers of both, the article at hand and the ICAPS 2011 short version, for their constructive comments. In particular, one of the reviewers proved the completeness results in Theorem 1, and another reviewer suggested the future research line trying to generalize the reasons for success in local analysis.\nI thank Carmel Domshlak for discussions, feedback on early stages of this work \u2013 contributing in particular the \u201cd-abstracted task\u201d construction in the proof of Lemma 3 \u2013 and an executive summary of the status quo of causal graph research.\nA very special thanks goes to Carlos Areces and Luciana Benotti, for inspiring this work in the first place. I had long ago given up on this problem. It was Carlos\u2019 and Luciana\u2019s insistence that finally made me see the connection to causal graphs \u2013 while trying to convince them that an analysis like this is impossible."}, {"heading": "Appendix A. Technical Details and Proofs", "text": "We give the full proofs and, where needed, fill in some technical definitions. We first prove our complexity result (Appendix A.1, Theorem 1), then the result pertaining to the analysis of optimal relaxed plans (Appendix A.2, Theorem 2), then the result pertaining to conservative approximations (Appendix A.3, Theorems 3 and 4). We construct a number of examples relevant to both kinds of analysis (Appendix A.4), before giving the proofs of domain-specific performance guarantees (Appendix A.5, Propositions 1 and 2).\nA.1 Computational Complexity\nTheorem 1. It is PSPACE-complete to decide whether or not the state space of a given planning task contains a local minimum, and given an integer K it is PSPACE-complete to decide whether or not for all states s we have ed(s) \u2264 K. Further, it is PSPACE-complete to decide whether or not a given state s is a local minimum, and given an integer K it is PSPACE-complete to decide whether or not ed(s) \u2264 K.\nProof. Throughout the proof, since PSPACE is closed under complementation, we do not distinguish the mentioned PSPACE-complete decision problems from their complements.\nThe membership results are all easy to prove. Note first that, given a state s, we can compute h+(s) within polynomial space: generate a potentially non-optimal relaxed plan, of length n, with the known methods; then iteratively decrement n and test for each value whether a relaxed plan of that length still exists; stop when that test answers \u201cno\u201d. The test for bounded relaxed plan existence is in NP and thus in PSPACE. From here, we can prove the membership results by simple modifications of the guess-and-check argument showing that PLANSAT, the problem of deciding whether a given planning task is solvable, is in NPSPACE and hence in PSPACE (Bylander, 1994). That argument works by starting in the initial state, guessing actions, and terminating successfully if a goal state is reached. Unsuccessful termination occurs if the guessed path is longer than the trivial upper bound B := \u03a0x\u2208X |Dx| on the number of different states. To be able to check this condition in polynomial space, the path length is maintained in a binary counter.\nTo decide whether a given state s is (not) a local minimum, we run this guess-and-check algorithm from s, modified to: compute h+ for each encountered state; to terminate unsuccessfully if the bound B is exceeded or if h+ increases after an operator application; and to terminate successfully if h+ decreases after an operator application. To decide whether ed(s) \u2264 K, we use the same algorithm except that the bound B is replaced by the bound K, increases of h+ are permitted, and success occurs if h+ decreases from h+(s) to h+(s)\u22121. To decide whether the state space of an entire planning task contains local minima, or whether all states s in the state space have ed(s) \u2264 K, we simply run Bylander\u2019s guess-and-check algorithm as a way of enumerating all reachable states, then for each individual state s we run the modified guess-and-check algorithms just described. Clearly, all these algorithms run in non-deterministic polynomial space, which shows this part of the claim.\nWe now show the PSPACE-hardness results. We first consider the problem of deciding whether or not a given state s is a local minimum. The proof works by reducing PLANSAT, which is known to be PSPACE-hard for propositional STRIPS (Bylander, 1994), from which it trivially follows that PLANSAT is PSPACE-hard also for the finitedomain variable planning tasks we use herein.\nLet (X, sI , sG, O) be the planning task whose solvability we wish to decide. We design a modified task (X \u2032, s\u2032I , s \u2032 G, O\n\u2032) by starting with (X, sI , sG, O) and making the following modifications:\n\u2022 Add a new variable ChooseTask to X \u2032, with domain {nil, org, alt}, s\u2032I(ChooseTask) = nil, and s \u2032 G(ChooseTask) undefined.\nThe role of this variable will be to give the planner a choice whether to solve the original task (X, sI , sG, O), or whether to solve an alternative task custom-designed for this proof.\n\u2022 Add a new variable DistAlt to X \u2032, with domain {0, 1}, s\u2032I(DistAlt) = 1, and s\u2032G(DistAlt) = 1.\nThis variable simply serves to control the length of the solution of the alternative task. That solution length will be 1 plus the number of steps needed to bring DistAlt from\nvalue 0 to its goal value. (Here, only 1 step will be needed for doing so; later on in this proof, we will increase this distance.)\n\u2022 Add two new operators oOrg = ({(ChooseTask, nil)}, {(ChooseTask, org)}) and oAlt = ({(ChooseTask, nil)}, {(ChooseTask, alt), (DistAlt, 0)}). This implements the choice of planning task. Note that, if we choose the alternative task, then DistAlt is set to 0, thus forcing the solution to bridge this distance. By contrast, for the original task, this variable keeps residing in its goal value as was already assigned by s\u2032I(DistAlt).\n\u2022 Add a new operator oDistAlt = ({(ChooseTask, alt), (DistAlt, 0)}, {(DistAlt, 1)}). This allows to bridge the distance intended for the solution of the alternative task.\n\u2022 Add a new operator osGAlt = ({(ChooseTask, alt), (DistAlt, 1)}, sG). This allows us to accomplish the original goal, as the final step in solving the alternative task.\n\u2022 Add (ChooseTask, org) as a new precondition into all original operators, i.e., those taken from O.\nThis forces the planner to choose the original task, for executing any of its operators.\n\u2022 Add a new variable StillAlive to X, with domain {yes, no}, s\u2032I(StillAlive) = yes, and sG(StillAlive) = yes. Add a new operator osGDead = (\u2205, sG\u222a{(StillAlive, no)}). The osGDead operator allows us to accomplish the original goal in a single step, no matter which task we have chosen to solve, and also in the new initial state s\u2032I already. However, the operator also sets the new variable StillAlive to value no, whereas the goal value of that variable is yes. That value cannot be re-achieved, and thus the operator leads into a dead-end. Its function in the proof is to flatten the value of h+ in the original task, and in s\u2032I , to be constantly 1 unless we are in a goal state. This extreme flattening does not happen in the alternative task because, there, the distance variable DistAlt also needs to be handled.\nIn summary, (X \u2032, s\u2032I , s \u2032 G, O \u2032) is designed by setting:\n\u2022 X \u2032 := X \u222a {ChooseTask,DistAlt, StillAlive}\n\u2022 s\u2032I := sI \u222a {(ChooseTask, nil), (DistAlt, 1), (StillAlive, yes)}\n\u2022 s\u2032G := sG \u222a {(DistAlt, 1), (StillAlive, yes)}\n\u2022 O\u2032 := {(pre \u222a {(ChooseTask, org)}, eff) | (pre, eff) \u2208 O} \u222a {oOrg, oAlt, oDistAlt, osGAlt, osGDead}\nNow consider the new initial state s\u2032I . It has exactly three successor states: sDead produced by osGDead, sOrg produced by oOrg, and sAlt produced by oAlt. We have h\n+(sDead) = \u221e because sDead(StillAlive) = no. We have h+(s\u2032I) = h+(sOrg) = 1 due to the relaxed\nplan \u3008osGDead\u3009. Finally, we have h+(sAlt) = 2 because oAlt sets the DistAlt variable to 0 whereas its goal is 1. Thus a shortest relaxed plan for sAlt is \u3008oDistAlt, osGAlt\u3009.\nFrom this, it clearly follows that s\u2032I is not a local minimum iff sOrg has a monotone path to a state s with h+(s) < h+(sOrg). Since h+(sOrg) = 1, the latter is equivalent to the existence of a monotone path from sOrg to a goal state, i.e., a path to a goal state on which h+ is constantly 1. Since, for all states reachable from sOrg, the single-step sequence \u3008osGDead\u3009 is a relaxed plan, this is equivalent to the existence of a path from sOrg to a goal state. Clearly, the latter is equivalent to solvability of the original task (X, sI , sG, O). Thus s\u2032I is not a local minimum iff (X, sI , sG, O) is solvable, which shows this part of the claim.\nWe next prove PSPACE-hardness of deciding whether or not a given planning task contains a local minimum. This follows easily from the above. Observe that the alternative task does not contain any local minima. As described, we have h+(sAlt) = 2. If we apply oDistAlt to sAlt, then we obtain a state sAltDist where h+(sAltDist) = 1 because of the relaxed plan \u3008osGAlt\u3009. Applying osGAlt in sAltDist yields a goal state, and thus both sAlt and sAltDist have better evaluated neighbors. Any other states descending from sAlt must be produced by osGDead and thus have h\n+ value \u221e. So, (X \u2032, s\u2032I , s\u2032G, O\u2032) contains a local minimum iff the part of its state space descended from sOrg does. Since all those states have h+ value 1 unless they are goal states, cf. the above, the latter is equivalent to unsolvability of (X, sI , sG, O) which shows this part of the claim.\nAssume now that we are given an integer K and need to decide for an individual state s whether or not ed(s) \u2264 K. We reduce Bounded-PLANSAT, the problem of deciding whether any given planning task is solvable within a given number of steps. Bounded-PLANSAT is known to be PSPACE-complete if the bound is given in non-unary representation. We modify the task (X \u2032, s\u2032I , s \u2032 G, O\n\u2032) given above, in a way that increases the solution length of the alternative task to be K. We introduce a binary counter using dlog2(K\u22122)e new binary variables Biti that are all at 0 in sI . We introduce an operator for each bit, allowing to set the bit to 1 if all the lower bits are already 1, and in effect setting all these lower bits back to O. Each such operator has the additional precondition (ChooseTask, alt), but has no effect other than modifying the bits. We then modify the operator oDistAlt by adding new preconditions encoding counter position K\u22122. With this construction, clearly h+(sAlt) > 1, and the distance to goal of sAlt is K: a plan is to count up to K \u2212 2, then apply oDistAlt, then apply osGAlt. Thus, the shortest exit path for sI via oAlt has length K + 1. But then, with the above, ed(sI) \u2264 K iff (X, sI , sG, O) has a plan of length at most K \u2212 1, which concludes this part of the claim.\nFinally, say we need to decide whether or not, for all s \u2208 S, we have ed(s) \u2264 K. Note first that sAlt and all its successors necessarily have exit distance at most K (the goal can be reached in at most that many steps), and that the exit distance of sOrg and all its successors is equal to the length of a shortest plan for the corresponding state in (X, sI , sG, O). The latter length may, for some states in (X, sI , sG, O), be longer than K even if the shortest plan for (X, sI , sG, O) (i.e., for the original initial state) has length K. We thus introduce another binary counter, this time counting up to K\u22121, conditioned on (ChooseTask, org), and with a new operator whose precondition demands the new counter to be at K \u2212 1 and that achieves all goals. Then, clearly, sOrg and all its descendants have exit distance at most K. Thus the only state that may have exit distance greater than K is s\u2032I \u2013 precisely, we\nhave ed(s\u2032I) = K+ 1 iff the new counter is the shortest plan for sOrg, which obviously is the case iff (X, sI , sG, O) has no plan of length at most K\u22121. This concludes the argument.\nA.2 Analyzing Optimal Relaxed Plans\nWe need to fill in some notations. For the sake of self-containedness of this section, we first re-state the definitions given in Section 5:\nDefinition 1. Let (X, sI , sG, O) be a planning task, let s \u2208 S with 0 < h+(s) < \u221e, let P+(s) be an optimal relaxed plan for s, let x0 \u2208 X, and let o0 \u2208 P+(s) be an operator taking a relevant transition of the form t0 = (s(x0), c).\nAn optimal rplan dependency graph for P+(s), x0 and o0, or optimal rplan dependency graph for P+(s) in brief, is a graph oDG+ = (V,A) with unique leaf vertex x0, and where x \u2208 V and (x, x\u2032) \u2208 A if either: x\u2032 = x0, x \u2208 Xpreo0 , and preo0(x) 6= s(x); or x 6= x\n\u2032 \u2208 V \\ {x0} and there exists o \u2208 P+<0(s) taking a relevant transition on x\u2032 so that x \u2208 Xpreo and preo(x) 6= s(x).\nFor x \u2208 V \\ {x0}, by oDTG+x we denote the sub-graph of DTGx that includes only the values true at some point in P+<0(s, x), the relevant transitions t using an operator in P+<0(s, x), and at least one relevant inverse of such t where a relevant inverse exists. We refer to the P+<0(s, x) transitions as original, and to the inverse transitions as induced.\nDefinition 2. Let (X, sI , sG, O), s, P+(s), x0, t0, and oDG+ = (V,A) be as in Definition 1. We say that oDG+ is successful if all of the following holds:\n(1) oDG+ is acyclic.\n(2) We have that either:\n(a) the oDG+-relevant deletes of t0 are P+>0(s)-recoverable; or (b) s(x0) is not oDG+-relevant, and t0 has replaceable side effect deletes; or (c) s(x0) is not oDG+-relevant, and t0 has recoverable side effect deletes.\n(3) For x \u2208 V \\ {x0}, all oDTG+x transitions either have self-irrelevant deletes, or are invertible/induced and have irrelevant side effect deletes and no side effects on V \\{x0}.\nWe next define two general notions that will be helpful to state our proofs.\n\u2022 The prevail condition prevo of an operator o \u2208 O results from restricting preo to the set of variables Xpreo \\Xeffo .\n\u2022 Let x \u2208 X, let (c, c\u2032) be a transition in DTGx, and let (y, d) \u2208 seff(c, c\u2032) be a side effect of the transition. The context of (y, d) in (c, c\u2032) is ctx(c, c\u2032, y, d) :={\n(y,prerop(c,c\u2032)(y)) y \u2208 Xprerop(c,c\u2032) {(y, d\u2032) | d\u2032 \u2208 Dy, d\u2032 6= d} y 6\u2208 Xprerop(c,c\u2032)\nThe context of (c, c\u2032) is the set ctx(c, c\u2032) of all partial variable assignments \u03c8 so that, for every (y, d) \u2208 seff(c, c\u2032), y \u2208 X\u03c8 and (y, \u03c8(y)) \u2208 ctx(c, c\u2032, y, d). We identify ctx(c, c\u2032) with the set of all facts that occur in any of its assignments.\nNote here that the definition of ctx(c, c\u2032) over-writes our previous one from Section 5, but only in the sense that we now also distinguish all possible tuples of context values, rather than just collecting the overall set. We need the more fine-grained definition to precisely formulate Definition 2 condition (2c), i.e., under which conditions a transition has \u201crecoverable side effect deletes\u201d. Namely, Definition 2 conditions (2b) and (2c) are formalized as follows:\n\u2022 A transition (c, c\u2032) has replaceable side effect deletes iff ctx(c, c\u2032)\u2229sG = \u2205 and, for every rop(c, c\u2032) 6= o \u2208 O where preo \u2229 ctx(c, c\u2032) 6= \u2205 there exists o\u2032 \u2208 O so that effo\u2032 = effo and preo\u2032 \u2286 prevrop(c,c\u2032) \u222a effrop(c,c\u2032).\n\u2022 A transition (c, c\u2032) has recoverable side effect deletes iff the following two conditions hold:\n\u2013 Either (c, c\u2032) has irrelevant side effect deletes or, for every \u03c8 \u2208 ctx(c, c\u2032), there exists a recovering operator o so that preo \u2286 prevrop(c,c\u2032)\u222aeffrop(c,c\u2032) and effo \u2286 \u03c8, effo \u2287 \u03c8 \u2229 (sG \u222a \u22c3 rop(c,c\u2032)6=o\u2032\u2208O preo\u2032). \u2013 Every (y, d) \u2208 seff(c, c\u2032) is not in the goal and appears in no operator precondition other than possibly those of the recovering operators.\nIf t0 has replaceable side effect deletes, then upon its execution we can remove o0 from the relaxed plan because any operator relying on deleted facts can be replaced. If t0 has recoverable side effect deletes, then, due to the first clause of this definition, no matter what the state s0 in which we apply t0 is \u2013 no matter which context \u03c8 holds in s0 \u2013 we have a recovering operator o that is applicable after t0 and that re-achieves all relevant facts. Due to the second clause, o will not delete any facts relevant elsewhere in the relaxed plan (note here that anything deleted by o must have been a side effect of t0).\nFinally, to formally define the notion used in Definition 2 condition (2a) \u2013 \u201cthe oDG+relevant deletes of t0 are P+>0(s)-recoverable\u201d \u2013 we now assume the surroundings pertaining to Theorem 2, i.e., (X, sI , sG, O) is a planning task, s is a state, P+(s) is an optimal relaxed plan for s, oDG+ = (V,A) is an optimal rplan dependency graph with leaf variable x0 and transition t0 = (s(x0), c) with responsible operator o0. We are considering a state s0 where t0 can be executed, reaching a state s1, and we are examining a relaxed plan P+1 for s1 constructed from P+(s) by removing o0, and by replacing some operators of P+<0(s) with operators responsible for induced oDTG+x transitions for x \u2208 V \\ {x0}.\n\u2022 By C0 := {(x0, s(x0))} \u222a ctx(t0) we denote the values potentially deleted by t0.\n\u2022 By R+1 we denote the union of sG, the precondition of any P+(s) operator other than o0, and the precondition of any operator which is the responsible operator for an induced transition in oDTG+x , with x \u2208 V \\ {x0}. As discussed in Section 5, this is a super-set of the facts possibly needed in P+1 .\n\u2022 By F0 := s\u222a \u22c3 o\u2208P+<0(s) effo we denote the set of facts true after the relaxed execution\nof P+<0(s) in s. As discussed in Section 5, if p 6\u2208 F0 then p is not needed in s1 for P + 1 to be a relaxed plan.\n\u2022 By S1 we denote the union of: (1) prevo0 \u222a effo0 ; (2) the set of facts (x, c) \u2208 s where there exists no o such that x \u2208 Xeffo and o is either o0 or in P+<0(s) or is the responsible operator for an induced transition in oDTG+x , with x \u2208 V \\{x0}; (3) the set F defined as F := {(x, c) | (x, c) \u2208 F0, x \u2208 V \\{x0}} if Xeffo0 \u2229 (V \\{x0}) = \u2205, else F := \u2205. Here, (1) and (2) are facts of which we are certain that they will be true in s1; (3) is a set of facts that we will be able to achieve at the start of P+1 , by appropriately re-ordering the operators.\n\u2022 If\u2212\u2192o = \u3008o1, . . . , on\u3009 is a sub-sequence of P+(s), then the relaxed-plan macro-precondition of \u2212\u2192o is defined as pre+\u2212\u2192o := \u22c3n i=1(preoi \\ \u22c3i\u22121 j=1 effoj ). The relaxed-plan macro-effect of\u2212\u2192o is defined as eff+\u2212\u2192o := \u22c3n i=1 effoi . If\n\u2212\u2192o is empty then both sets default to the empty set. These notions simply capture the \u201coutside\u201d needs and effects of a relaxed plan sub-sequence.\n\u2022 The oDG+-relevant deletes of t0 are P+>0(s)-recoverable iff P + >0(s) contains a sub-\nsequence \u2212\u2192o0 so that pre+\u2212\u2192o0 \u2286 S1 and eff + \u2212\u2192o0 \u2287 R+1 \u2229 C0 \u2229 F0. The first condition here ensures that \u2212\u2192o0 will be applicable at the appropriate point within P+1 . The second clause ensures that all facts relevant for P+1 will be re-achieved by \u2212\u2192o0 .\nWe now proceed with our exit path construction. In what follows, we first consider the part of the path leading up to s0, i.e., where we move only the non-leaf variables x \u2208 V \\{x0}. We show how to construct the relaxed plans P+(s\u2032) for the states s\u2032 visited on this path.\nFirst, note that we can assume P+(s) to be sorted according to the optimal rplan dependency graph oDG+ = (V,A). Precisely, let xk, . . . , x1 be a topological ordering of V \\ {x0} according to the arcs A. Due to the construction of (V,A) as per Definition 1, and because previous values are never removed in the relaxed state space, we can re-order P+(s) to take the form P+<0(s, xk) \u25e6 \u00b7 \u00b7 \u00b7 \u25e6 P + <0(s, x1) \u25e6 P . That is, we can perform all moves within each oDTG+x up front, in an order conforming with A. We will henceforth assume, wlog, that P+(s) has this form.\nRecall in what follows that original oDTG+x transitions are those taken by P + <0(s), whereas induced oDTG+x transitions are those included as the inverse of an original transition. For a path \u2212\u2192p of invertible transitions traversing \u3008c0, . . . , cn\u3009, the inverse path \u2190\u2212p traverses \u3008cn, . . . , c0\u3009 by replacing each transition with its inverse. By rop(\u2212\u2192p ) we denote the operator sequence responsible for the path.\nWe say that a state s\u2032 \u2208 S is in the invertible surroundings of s according to oDG+ if s\u2032 is reachable from s by executing a sequence \u2212\u2192o of responsible operators of invertible/induced transitions in oDTG+x for x \u2208 V \\ {x0}. The adapted relaxed plan for such s\u2032, denoted P+(s\u2192s\u2032), is constructed as follows. Let xk, . . . , x1 be a topological ordering of V \\ {x0} according to A, and denote P+(s) = P+(s, xk) \u25e6 \u00b7 \u00b7 \u00b7 \u25e6P+(s, x1) \u25e6P . Initialize P+(s\u2192s\u2032) := P+(s). Then, for each xi \u2208 V \\ {x0}, let \u2212\u2192p be a path of original invertible transitions in oDTG+xi leading from s(xi) to s\n\u2032(xi) \u2013 clearly, such a path must exist. Remove rop(\u2212\u2192p ) from P+(s\u2192s\u2032), and insert rop(\u2190\u2212p ) at the start of P+(s\u2192s\u2032, xi).\nWe next show that adapted relaxed plans indeed are relaxed plans, under restricting conditions that are in correspondence with Definition 2 condition (3):\nLemma 1. Let (X, sI , sG, O) be a planning task, let s \u2208 S be a state with 0 < h+(s) <\u221e, and let P+(s) be an optimal relaxed plan for s. Say that oDG+ = (V,A) is an optimal rplan\ndependency graph for P+(s) where, for every x \u2208 V \\ {x0}, the invertible/induced oDTG+x transitions have irrelevant side effect deletes and no side effects on V \\ {x0}. Let s\u2032 \u2208 S be a state in the invertible surroundings of s according to oDG+. Then P+(s\u2192s\u2032) is a relaxed plan for s\u2032, and |P+(s\u2192s\u2032)| \u2264 |P+(s)|. Proof. By definition, we know that P+(s) takes the form P+<0(s, xk) \u25e6 \u00b7 \u00b7 \u00b7 \u25e6 P + <0(s, x1) \u25e6 P , and that P+(s\u2192s\u2032) takes the form P+<0(s\u2032, xk) \u25e6 \u00b7 \u00b7 \u00b7 \u25e6 P + <0(s\n\u2032, x1) \u25e6 P , where xk, . . . , x0 is a topological ordering of V , and P is some operator sequence that is common to both, but whose content will not be important for this proof. For simplicity, we denote in the rest of the proof P+(s\u2192s\u2032) as P+(s\u2032), and we leave away the \u201c< 0\u201d subscripts.\nConsider first the (relaxed) execution of P+(s, xk) and P+(s\u2032, xk). Say that \u2212\u2192p is the path in oDTG+xk considered in the definition of P\n+(s\u2032), i.e., a path of original invertible transitions in oDTG+xi leading from s(xk) to s\n\u2032(xk). Clearly, \u3008o1, . . . , on\u3009 := rop(\u2212\u2192p ) is a sub-sequence of P+(s, xk). Say that \u2212\u2192p visits the vertices s(xk) = c0, . . . , cn = s\u2032(xk); denote C := {c0, . . . , cn}. Assume wlog that P+(s, xk) starts with \u3008o1, . . . , on\u3009 \u2013 note here that we can re-order P+(s, xk) (and relaxed plans in general) in any way we want as long as we do not violate operator preconditions. The latter is not the case here because: \u3008o1, . . . , on\u3009 constitutes a path in oDTG+xk ; because all other operators depending on a value in C are ordered to occur later on in P+(s, xk); and because, since all transitions in \u2212\u2192p have no side effects on V \\{x0}, by construction of (V,A) as per Definition 1 the operators in \u3008o1, . . . , on\u3009 do not support each other in any way, in P+(s), other than by affecting the variable xk.\nGiven the above, wlog P+(s, xk) has the form \u3008o1, . . . , on\u3009 \u25e6 P1. By construction, P+(s\u2032, xk) has the form rop(\u2190\u2212p ) \u25e6 P1 =: \u3008\u2190\u2212on, . . . ,\u2190\u2212o1\u3009 \u25e6 P1. Consider now the endpoints of the prefixes, i.e., s+1 := s \u222a \u22c3n i=1 effoi and s + 2 := s \u2032 \u222a \u22c31 i=n eff\u2190\u2212oi . Clearly, since all the transitions on \u2212\u2192p have irrelevant side effect deletes, we have that the relevant part of s is contained in s\u2032. But then, as far as the variables outside V \\ {x0, xk} are concerned, the relevant part of s+1 is contained in s + 2 : any relevant side effects of \u3008o1, . . . , on\u3009 are already contained in s\u2032; the values C are obviously true in s+2 ; if the induced transitions have side effects, then these can only increase the fact set s+2 . Further, the sequence \u3008\n\u2190\u2212on, . . . ,\u2190\u2212o1\u3009 is applicable in the relaxation. To see this, note first that the preconditions on xk itself are satisfied by definition, because \u3008\u2190\u2212on, . . . ,\u2190\u2212o1\u3009 constitutes a path in DTGxk . Any side effects, if they occur, are not harmful because old values are not over-written in the relaxation. As for preconditions on other variables, due to invertibility \u2013 the outside conditions of \u2190\u2212oi are contained in those of oi \u2013 those are a subset of those for \u3008o1, . . . , on\u3009. Hence, with Definition 1 and since xk has no incoming edges in oDG+, all these preconditions are satisfied in s. They are then also satisfied in s\u2032 because (vk being a root of oDG+) these variables x are not contained in V and hence s\u2032(x) = s(x) by prerequisite \u2013 note here that precondition facts cannot have been deleted by the side effects whose deletes are irrelevant by prerequisite.\nThe above has shown that the relevant part of the outcome of relaxed execution of P+(s, xk) in s is contained in the outcome of relaxed execution of P+(s\u2032, xk) in s\u2032, on all variables outside V \\ {x0, xk}. We can now iterate this argument. Assume as induction hypothesis that we have already shown that the relevant part of the outcome of relaxed execution of P+(s, xk)\u25e6 . . . P+(s, xi+1) in s is contained in the outcome of relaxed execution of P+(s\u2032, xk) \u25e6 \u00b7 \u00b7 \u00b7 \u25e6 P+(s\u2032, xi+1) in s\u2032, on all variables outside V \\ {x0, xk, . . . , xi+1}. Now consider P+(s, xi) and P+(s\u2032, xi). The only thing that changes with respect to xk above is that there may be preconditions on variables xj that are not true in s; we have j > i\nbecause such preconditions must belong to predecessors of xi in oDG+ by Definition 1. Since P+(s) = P+(s, xk) \u25e6 \u00b7 \u00b7 \u00b7 \u25e6 P+(s, x1) \u25e6 P is a relaxed plan for s, those conditions are established after relaxed execution of P+(s, xk) \u25e6 \u00b7 \u00b7 \u00b7 \u25e6 P+(s, xi+1) in s. Given this, by induction hypothesis the conditions \u2013 which are clearly not irrelevant \u2013 are established also after relaxed execution of P+(s\u2032, xk) \u25e6 \u00b7 \u00b7 \u00b7 \u25e6P+(s\u2032, xi+1) in s\u2032, which concludes the argument for the inductive case. With i = 1, it follows that the relevant part of the outcome of relaxed execution of P+(s, xk) \u25e6 \u00b7 \u00b7 \u00b7 \u25e6P+(s, x1) in s is contained (on all variables) in the outcome of relaxed execution of P+(s\u2032, xk) \u25e6 \u00b7 \u00b7 \u00b7 \u25e6 P+(s\u2032, x1) in s\u2032. From this, the claim follows trivially because P+(s) is a relaxed plan for s, and the remainder P of both operator sequences is identical.\nThe second part of the claim follows because, for any i 6= j, we have that the original transitions we use for xi respectively xj have no operators in common. This is because, as argued above, all the relevant operators have no side effects on V \\{x0}. Since each of these operators affects the variable xi, it cannot affect any other variable in V \\ {x0}. Thus, for each inverse transition that we introduce via an inverse operator, P+(s) contains a separate operator. From this, obviously we get that |P+(s\u2192s\u2032)| \u2264 |P+(s)|.\nLemma 1 captures the second case of Definition 2 condition (3), transitions that are invertible/induced and have irrelevant side effect deletes and no side effects on V \\ {x0}. The next lemma captures the first case of Definition 2 condition (3):\nLemma 2. Let (X, sI , sG, O) be a planning task, let s \u2208 S be a state with 0 < h+(s) <\u221e, and let P+(s) be an optimal relaxed plan for s. Say that oDG+ = (V,A) is an optimal rplan dependency graph for P+(s) where, for every x \u2208 V \\ {x0}, the invertible/induced oDTG+x transitions have irrelevant side effect deletes and no side effects on V \\{x0}. Let s\u2032 \u2208 S be a state in the invertible surroundings of s according to oDG+. Let s\u2032\u2032 be a state reached from s\u2032 by a P+(s\u2192s\u2032, x) operator o constituting a transition (c, c\u2032) for x \u2208 V , where s\u2032(x) = c, that has self-irrelevant deletes. Then removing o from P+(s\u2192s\u2032) yields a relaxed plan for s\u2032\u2032.\nProof. By Lemma 1, P+(s\u2192s\u2032) is a relaxed plan for s\u2032. Now, upon execution of o, in s\u2032\u2032, its effects are true, i.e., we have (x, c\u2032) and any side effects (if present). On the other hand, obviously the only facts (z, e) that are true in s\u2032 but not in s\u2032\u2032 are in ctx(c, c\u2032)\u222a{(x, c)}. Since, by prerequisite, the transition (c, c\u2032) has self-irrelevant deletes, all facts in ctx(c, c\u2032)\u222a{(x, c)} are either irrelevant or rop(c, c\u2032)-only relevant, meaning they are not in the goal and occur in no operator precondition other than, possibly, that of o itself. The claim follows directly from that.\nWe remark that a much more easily formulated, and more general, version of Lemma 2 could be proved simply by associating the notion of \u201cself-irrelevant deletes\u201d with operators rather than transitions, and postulating only that o be used in P+(s). That argument corresponds to part (A) in the proof to Lemma 3 in the author\u2019s previous work (Hoffmann, 2005). We state the argument in the particular form above since that will be the form we need below.\nWe are now almost ready to prove the main lemma behind our exit path construction. We need one last notation, capturing a simpler form of the cost function costd\u2217(oDG+)\nthat we considered in Section 5. The simpler function does not make use of the \u201cshortcut\u201d construction; that construction will be introduced separately further below. We define costd(oDG+) := \u2211 x\u2208V cost\nd(x), where costd(x) :={ 1 x = x0\ndiam(oDTG+x ) \u2217 \u2211 x\u2032:(x,x\u2032)\u2208A cost d(x\u2032) x 6= x0\nLemma 3. Let (X, sI , sG, O) be a planning task, let s \u2208 S be a state with 0 < h+(s) <\u221e, and let P+(s) be an optimal relaxed plan for s. Say that oDG+ = (V,A) is a successful optimal rplan dependency graph for P+(s). Then there exists an operator sequence \u2212\u2192o so that:\n(I) \u2212\u2192o constitutes a monotone path in S from s to a state s1 with h+(s) > h+(s1).\n(II) The length of \u2212\u2192o is at most costd(oDG+) if we have Definition 2 condition (2a) or (2b), and is at most costd(oDG+) + 1 if we have Definition 2 condition (2c).\nProof. Let xk, . . . , x1 be a topological ordering of V \\{x0} according to the arcs A. Consider a state s0 where for every x \u2208 V \\ {x0} we have that s0(x) is a vertex in oDTG+x , and for every variable x outside V \\ {x0} we have that s0(x) = s(x) unless s(x) is irrelevant. Say that preo0 \u2286 s0. Note first that such a state s0 exists. By definition, we have that either preo0(x0) is undefined or that preo0(x0) = s(x0) = s0(x0). (Note that \u201cfor every variable x outside V \\ {x0} we have that s0(x) = s(x) unless s(x) is irrelevant\u201d covers also the case where a transition on V \\ {x0} has a side effect on x0, whose delete must then by prerequisite be irrelevant and thus either the side effect is x0 := s(x0) or o0 is not actually preconditioned on x0.) By Definition 1 and because P+(s) is a relaxed plan for s, each variable x \u2208 Xpreo0 is contained in V unless preo0(x) = s(x). For the same reasons, by construction of oDTG+x , we have that preo0(x) is a vertex in oDTG + x .\nNow, consider the state s1 that results from applying o0 to s0. We first consider the situation where s0 is in the invertible surroundings of s according to oDG+; the opposite case will be discussed further below. We can apply Lemma 1 to s0, and hence have a relaxed plan P+(s\u2192s0) for s0 that results from replacing, in P+(s), some moves of P+<0(s, x), for x \u2208 V \\ {x0}, with their inverses. In particular, h+(s) \u2265 h+(s0), and P+(s\u2192s0, x\u2032) = P+(s, x\u2032) for all x\u2032 6\u2208 V . What is a relaxed plan for s1? We distinguish Definition 2 condition (2) cases (a), (b), and (c).\nIn case (a), by definition we have that P+>0(s) contains a sub-sequence \u2212\u2192o0 so that pre+\u2212\u2192o0 \u2286 S1 and eff+\u2212\u2192o0 \u2287 R + 1 \u2229 C0 \u2229 F0. This implies that we can remove o0 from P+(s\u2192s0) and obtain a relaxed plan P+1 for s1, thus getting h +(s) > h+(s1). More precisely, we construct P+1 by: removing o0 from P +(s\u2192s0); if Xeffo0 \u2229 (V \\ {x0}) 6= \u2205 then moving\n\u2212\u2192o0 to occur at the start of P+1 ; if Xeffo0 \u2229 (V \\ {x0}) = \u2205 then moving\n\u2212\u2192o0 to occur at the start of P+>0(s) (which is unchanged in P+(s\u2192s0)).\nObserve first that o0 \u2208 P+(s\u2192 s0) and \u2212\u2192o0 is a sub-sequence of P+(s\u2192 s0) since the adaptation pertains exclusively to operators that precede o0 in P+(s). Second, of course the values established by o0 are true in s1.\nThird, \u2212\u2192o0 is applicable (in the relaxation) at its assigned point in P+1 . To see this, consider first the case where Xeffo0 \u2229 (V \\ {x0}) 6= \u2205. Then, by definition of S1, pre + \u2212\u2192o0 is\ncontained in (prevo0 \u222a effo0) and the set of facts (x, c) \u2208 s where there exists no o such that x \u2208 Xeffo and o is either o0 or in P+<0(s) or is the responsible operator for the inverse of a transition taken by an operator o\u2032 \u2208 P+<0(s). All these facts will be true in s1. This is obvious for prevo0 \u222a effo0 and follows for the other facts because they were true in s and cannot have been affected by any operator on the path to s1. Consider now the case where Xeffo0 \u2229 (V \\ {x0}) = \u2205. By definition of S1, pre + \u2212\u2192o0\nis contained in the previous sets of facts, plus {(x, c) | (x, c) \u2208 F0, x \u2208 V \\ {x0}}. The latter facts, as far as relevant, will all be true at the start of \u2212\u2192o0 in P+1 . This is because execution of o0 does not affect the execution of P+(s\u2192s0), and thus of P+1 , up to this point. But then, with what was argued in Lemma 1, we have that the outcome of such execution in s0 contains, on the variables V \\ {x0}, the relevant part of the outcome of P+<0(s) in s \u2013 that is, the relevant part of F0. Since o0 does not affect these variables, the same is true of s1, which concludes this point.\nFinally, consider any facts (z, e) that are true in s0 but not in s1, and that may be needed by P+1 behind\n\u2212\u2192o0 , i.e., that either are in the goal or in the precondition of any of these operators. Observe that, since inverse operators are performed only for transitions on variables V \\ {x0}, and since they do not include any new outside preconditions, any such (z, e) is contained in R+1 .\n24 Now, say first that (z, e) \u2208 F0. Then, with the above, (z, e) \u2208 (ctx(s(x0), c)\u222a{(x0, s(x0))})\u2229F0\u2229R+1 and thus (z, e) \u2208 eff + \u2212\u2192o0\nby prerequisite and we are done. What if (z, e) 6\u2208 F0? Note that, then, (z, e) 6\u2208 preo for any o \u2208 P+<0(s) \u2013 else, this precondition would not be true in the relaxed execution of P+(s) and thus P+(s) would not be a relaxed plan. Neither is (z, e) added by any o \u2208 P+<0(s), and thus (z, e) is not needed as the precondition of any inverse operator used in P+(s\u2192 s0) \u2013 these operators do not introduce new outside preconditions, and of course use only own-preconditions previously added by other operators affecting the respective variable. Thus the only reason why (z, e) could be needed in P+1 is if either (z, e) \u2208 sG or (z, e) \u2208 preo for some o \u2208 P + >0(s). If (z, e) \u2208 sG then certainly, since P+(s) is a relaxed plan, it is achieved by some operator o in P+(s). We cannot have o = o0 since the effect of o0 is true in s1, and we cannot have o \u2208 P+<0(s) since (z, e) 6\u2208 F0. Thus o \u2208 P + >0(s), and thus o is contained in P + 1 and we are done. If (z, e) \u2208 preo\u2032 for some o\u2032 \u2208 P+>0(s), the same arguments apply, i.e., there must be o \u2208 P+>0(s), ordered before o\u2032, that adds (z, e). This concludes the proof for case (a).\nConsider now case (b), where s(x0) 6\u2208 R+1 , and the transition (s(x0), c) has replaceable side effect deletes, i.e., ctx(s(x0), c) \u2229 sG = \u2205 and, for every o0 6= o \u2208 O where preo \u2229 ctx(s(x0), c) 6= \u2205 there exists o\u2032 \u2208 O so that effo\u2032 = effo and preo\u2032 \u2286 prevo0 \u222a effo0 . We obtain a relaxed plan for P+1 by removing o0 from P\n+(s\u2192 s0), and replacing any other operators o with the respective o\u2032 if needed. Precisely, say that (z, e) is true in s0 but not in s1. If z = x0 then e = s(x0) is not needed in P+1 by construction. For every other z, we must have (z, e) \u2208 ctx(s(x0), c). Then (z, e) is not a goal by prerequisite. For any operator o \u2208 P+1 that has (z, e) as a precondition, we can replace o with the postulated operator o1 that is obviously applicable in s1 and has the same effect. This concludes this case.\nConsider last case (c), where by definition s(x0) 6\u2208 R+1 , and the transition (s(x0), c) has recoverable side effect deletes. Here, the guarantee to decrease h+ is obtained not for s1\n24. Note in particular the special case of inverse transitions on non-leaf variables x, which may have a precondition in x that is added by, but not needed as a prerequisite of, the operators in P+(s, x). Such preconditions \u2013 and only such preconditions \u2013 may be needed in P+(s\u2192s0) and thus in P+1 , but not in P+(s). It is for this reason that we include these facts in the definition of R+1 .\nitself, but for a successor state s2 of s1. Namely, let o0 be the operator recovering the relevant side effect deletes of (s(x0), c). Precisely, let \u03c8 \u2208 ctx(s(x0), c) so that \u03c8 \u2286 s0 (such a \u03c8 exists by definition of ctx(s(x0), c)). Then, let o0 be an operator so that preo0 \u2286 (prevo0 \u222a effo0) and effo0 \u2286 \u03c8, effo0 \u2287 \u03c8 \u2229 (sG \u222a \u22c3 o0 6=o\u2032\u2208O preo\u2032) (such an operator exists by case (b)). Say that we obtain P+1 by replacing, in P +(s\u2192s0), o0 with o0. Then P+1 is a relaxed plan for s1. To see this, note first that o0 is applicable in s1 by virtue of preo0 \u2286 (prevo0 \u222a effo0). Further, note that the only values deleted by o0 are those in \u03c8 plus (x0, s0(x0)). Since s0(x0) = s(x0), by s(x0) 6\u2208 R+1 we know that s0(x0) 6\u2208 R + 1 and thus this delete is of no\nconsequence. As for \u03c8, by virtue of effo0 \u2287 \u03c8 \u2229 (sG \u222a \u22c3 o0 6=o\u2032\u2208O preo\u2032) all facts that could possibly be relevant are re-achieved by o0. Finally, the values established by o0 are true in s1.\nNow, say we obtain s2 by applying o0 in s1. Then removing o0 from P+1 yields a relaxed plan for s2. This is simply because its established effects are true in s2, and by virtue of effo0 \u2286 \u03c8 the only facts it deletes are side-effects of the transition (s(x0), c). By case (c), these are not relevant for anything except possibly the recovering operators. The recovering operator o0 we have just removed from P+1 . As for any other recovering operators o that could still be contained in P+1 , since effo \u2286 \u03c8 and effo0 \u2287 \u03c8 \u2229 (sG \u222a \u22c3 o0 6=o\u2032\u2208O preo\u2032), all relevant facts that o could possibly achieve are already true in s2 and thus we can remove o as well. Hence, overall, h+(s) > h+(s2).\nIn cases (a) and (b) we can prove (I) by constructing a monotone path to s1, in case (c) the same is true of s2. (Of course, we will also show (II), by constructing a path that has at most the specified length; we will ignore this issue for the moment.) The only difficulty in constructing such a path is achieving the preconditions of o0. These preconditions may not be satisfied in s, so we need to reach the state s0 where they are satisfied. We need to do so without ever increasing the value of h+. Note that, if we decrease the value of h+ somewhere along the way, then we have already reached an exit on a monotone path, and are done. Thus in what follows we will only show the upper bound h+(s). With Lemma 1, this bounding can be accomplished by starting at s, and always taking only oDTG+x transitions of variables x \u2208 V pertaining to the second case in Definition 2 condition (3), i.e., transitions that are invertible/induced and have irrelevant side effect deletes and no side effects on V \\ {x0}. In what follows we will, for brevity, refer to such transitions as \u201ccase2\u201d. Note here that, this way, we will reach only states in the invertible surroundings of s according to oDG+. For any such operator sequence \u2212\u2192o , by Lemma 1 we know that h+(s) \u2265 h+(s\u2032) for all states s\u2032 along the way. Now, what if we cannot reach s0 by using such a sequence, i.e., what if we would have to take a non-case2 oDTG+x transition (c, c\n\u2032) of variable x, at some state s\u2032? By prerequisite we know that transition (c, c\u2032) has self-irrelevant deletes. We can apply Lemma 2 because: s\u2032 is in the invertible surroundings of s according to oDG+; since we\u2019re following a transition path, clearly s\u2032(x) = c, i.e., the value of the relevant variable in s\u2032 is the start value of the last transition we are taking; and by construction, P+(s\u2192s\u2032) changes P+(s) only in the case2 transitions, and thus the responsible operator rop(c, c\u2032) (which is not case2) is guaranteed to be contained in P+(s\u2192s\u2032). Note here that rop(c, c\u2032) cannot be used in any of the case2 transitions for any other V \\ {x0} variable we might have taken on the path to s\u2032, because by prerequisite all these transitions have no side effects on V \\ {x0}, in contradiction to o constituting a transition for the variable x at hand. Thus we know that h+(s) > h+(s\u2032) so we have already constructed our desired monotone path to an exit\nand can stop. Else, if we can reach s0 by such a sequence \u2212\u2192o , then with the above, \u2212\u2192o \u25e6 \u3008o0\u3009 (respectively \u2212\u2192o \u25e6 \u3008o0, o0\u3009, in case (c)) constitutes the desired path.\nIt remains to show how exactly to construct the operator sequence \u2212\u2192o . Consider a topological ordering of V , xk, . . . , x1. In what follows, we consider \u201cdepth\u201d indices k \u2265 d \u2265 0, and we say that a variable x \u2208 V \u201chas depth\u201d d, written depth(x) = d, iff x = xd. Each d characterizes the d-abstracted planning task which is identical to the original planning task except that all (and only) those outside preconditions, of all oDTG+x transitions for variables x where depth(x) \u2264 d, are removed that pertain to values of variables x\u2032 where depth(x\u2032) > d. We prove by induction over d that:\n(*) For the d-abstracted task, there exists an operator sequence \u2212\u2192o d so that:\n(a) either (1) \u2212\u2192o d\u25e6\u3008o0\u3009 is an execution path applicable in s, or (2) \u2212\u2192o d is an execution path applicable in s, and the last transition (c, c\u2032) for variable x taken in \u2212\u2192o d is relevant, has self-irrelevant deletes, its responsible operator is contained in the adapted relaxed plan for the state s\u2032 it is applied to, and s\u2032(x) = c;\n(b) \u2212\u2192o d, except in the last step in case (2) of (a), uses only case2 oDTG+x transitions for variables x with 1 \u2264 depth(x) \u2264 d;\n(c) the number of operators in \u2212\u2192o d \u25e6 \u3008o0\u3009 pertaining to any x \u2208 V is at most costd(x).\nOur desired path \u2212\u2192o then results from setting d := k. To see this, note that the kabstracted planning task is identical to the original planning task. The claim then follows with our discussion above: (a) and (b) together mean that h+ decreases monotonically on \u2212\u2192o d and is less than h+(s) at its end. Given (c), the length of \u2212\u2192o d is bounded by\u2211\nx\u2208V,depth(x)\u2264d cost d(x). This proves the claim when adding the trivial observation that, if we have Definition 2 condition (2) case (c) as discussed above, then we need to add one additional operator at the end of the path.\nWe now give the proof of (*). The base case, d = 0, is trivial. Just set \u2212\u2192o 0 to be empty. By the construction of (V,A) as per Definition 1, and by construction of the 0-abstracted task, all outside preconditions of o0 are either true in s or have been removed. All of (a) (case (1)), (b), (c) are obvious.\nInductive case, d\u2192 d+ 1. Exploiting the induction hypothesis, let \u2212\u2192o d be the operator sequence as per (*). We now turn \u2212\u2192o d into the requested sequence \u2212\u2192o d+1 for the d + 1- abstracted planning task.\nFor the remainder of this proof, we will consider oDTG+x , for any x \u2208 V \\ {x0}, to contain also any irrelevant transitions, i.e., we omit this restriction from Definition 1. This is just to simplify our argumentation \u2013 as we will show, the oDTG+x paths we consider do not contain any irrelevant transitions, and hence are contained in the actual oDTG+x as per Definition 1.\nLet o be the first operator in \u2212\u2192o d \u25e6 \u3008o0\u3009. o may not be applicable in s, in the d + 1-abstracted planning task. The only reason for that, however, may be a precondition that was removed in the d-abstracted planning task but that is not removed in the d + 1- abstracted planning task. By construction, that precondition must pertain to xd+1. Say the precondition is (xd+1, c). By induction hypothesis, we know that o is contained in P+<0(s), or is responsible for an inverse transition of such an operator. In both cases, since inverse transitions introduce no new outside preconditions, (xd+1, c) is a precondition of an\noperator in P+<0(s). Thus c is a vertex in oDTG + xd+1 \u2013 this is trivial if (xd+1, c) is true in s (which actually cannot be the case here because else o would be applicable in s in the d + 1-abstracted planning task), and if (xd+1, c) is not true in s it follows because P+(s) is a relaxed plan and must thus achieve (xd+1, c) before it is needed as a precondition. Hence, P+<0(s, xd+1) must contain a shortest path\n\u2212\u2192q in oDTG+xd+1 from s(xd+1) to c. All the transitions on the path are not irrelevant. To see this, note first that the endpoint is an operator precondition by construction, and thus the last transition (c1, c) is not irrelevant. But then, neither is the previous transition, (c2, c1): if it was, then (xd+1, c1) would be in no operator precondition; but then, rop(c1, c) \u2013 which is contained in P+<0(s) by construction \u2013 would also constitute the transition (c2, c) in oDTG+xd+1 and thus\n\u2212\u2192q would not be a shortest path in contradiction. Iterating the argument, \u2212\u2192q does not contain any irrelevant transitions. Thus, since depth(xd+1) = d + 1, by Definition 1 (which includes all nonsatisfied preconditions of relevant transitions) and by construction of the d + 1-abstracted planning task, all the outside preconditions used in rop(\u2212\u2192q ) are either true in s or have been removed. Hence we can execute rop(\u2212\u2192q ). We do so until either we have reached the end of the sequence, or until the last transition taken in oDTG+xd+1 was not case2, and hence has self-irrelevant deletes by prerequisite. In the latter case, since we are following a path and since as discussed above the adapted relaxed plan exchanges only operators pertaining to case2 transitions and thus not the last one we just executed, we clearly have attained (a) case (2) and can stop \u2013 the part of rop(\u2212\u2192q ) that we executed is, on its own, an operator sequence \u2212\u2192o d+1 as desired. In the former case, we reach a state s\u2032 where s\u2032(xd+1) = c (and nothing else of relevance has been deleted, due to the non-existence of relevant side-effect deletes). In s\u2032, o can be applied, leading to the state s\u2032\u2032.\nLet now o\u2032 be the second operator in \u2212\u2192o d \u25e6 \u3008o0\u3009. Like above, if o\u2032 is not applicable in s\u2032\u2032, then the only reason may be an unsatisfied precondition of the form (xd+1, c\u2032). Like above, o\u2032 or its inverse is contained in P+<0(s), and hence c\n\u2032 is a vertex in oDTG+xd+1 . Likewise, s\u2032\u2032(xd+1) = c is a vertex in oDTG+xd+1 . Now, we have not as yet used any non-case2 transition in oDTG+xd+1 , or else we wouldn\u2019t get here. This means that we are still in the invertible surroundings around s(xd+1) of oDTG+xd+1 . Clearly, this implies that there exists a path in oDTG+xd+1 from c to c\n\u2032 (we could simply go back to s(xd+1) and move to c\u2032 from there). Taking the shortest such path \u2212\u2192q , clearly the path length is bounded by the diameter of oDTG+xd+1 . The path does not contain any irrelevant transitions \u2013 the endpoint c\u2032 has been selected for being an operator precondition, the values in between are part of a shortest path in oDTG+xd+1 , and thus the same argument as given above applies. Thus the outside preconditions used by the operators constituting \u2212\u2192q are either true in s or have been removed \u2013 this follows from the construction of (V,A) as per Definition 1 and by construction of the d+ 1-abstracted planning task for operators in P+<0(s), and follows for inverses thereof because inverse operators introduce no new outside preconditions. Hence we can execute \u2212\u2192q in s\u2032\u2032. We do so until either we have reached the end of the path, or until the last transition taken was not case2, and hence has self-irrelevant deletes by prerequisite.\nConsider the latter case. The state s\u2032 just before the last transition is reached only by case2 transitions, and since the transition is in oDTG+xd+1 but not case2, the responsible operator must be contained in P+(s) and with that in the adapted relaxed plan P+(s\u2192s\u2032) for s\u2032 \u2013 recall here that, as pointed out above, since case2 transitions are postulated to have\nno side effects on V \\{x0}, the responsible operator cannot be used by any of them. Further, clearly since we are following a path of transitions, we have that the value of xd+1 in s\u2032 is the start value of the transition. Hence we have attained (a) case (2) and can stop. In the former case, we have reached a state where o\u2032 can be applied (and nothing of relevance has been deleted, due to the postulated non-existence of relevant side-effect deletes, for case2 transitions). Iterating the argument, we get to a state where the last operator of \u2212\u2192o d \u25e6 \u3008o0\u3009 can be applied, by induction hypothesis reaching a state s1 as desired by (a) case (1).\nProperties (a) and (b) are clear from construction. As for property (c), to support any operator of \u2212\u2192o d \u25e6 \u3008o0\u3009, clearly in the above we apply at most diam(oDTG+xd+1) operators pertaining to xd+1 (or we stop the sequence earlier than that). Note further that, for all operators o in \u2212\u2192o d \u25e6\u3008o0\u3009 with unsatisfied preconditions on xd+1 in the above, if o pertains to variable x then we have (xd+1, x) \u2208 A. This is a consequence of the construction of (V,A) as per Definition 1, and the fact that inverse transitions do not introduce new outside preconditions. Thus, in comparison to \u2212\u2192o d \u25e6 \u3008o0\u3009, overall we execute at most\ndiam(oDTG+xd+1) \u2217 \u2211\nx:(xd+1,x)\u2208A\nk(x)\nadditional operators in \u2212\u2192o d+1 \u25e6 \u3008o0\u3009, where k(x) is the number of operators in \u2212\u2192o d \u25e6 \u3008o0\u3009 pertaining to variable x. By induction hypothesis, property (c) of (*), we have that k(x) \u2264 costd(x), for all x with depth(x) < d + 1, and thus for all x with (xd+1, x) \u2208 A. Hence we get, for the newly inserted steps affecting xd+1, the upper bound\ndiam(oDTG+xd+1) \u2217 \u2211\nx:(xd+1,x)\u2208A\ncostd(x)\nwhich is identical to costd(xd+1). This concludes the argument.\nWe next note that we can improve the exit distance bound in case we do not insist on monotone exit paths:\nLemma 4. Let (X, sI , sG, O) be a planning task, let s \u2208 S be a state with 0 < h+(s) <\u221e, and let P+(s) be an optimal relaxed plan for s. Say that oDG+ = (V,A) is a successful optimal rplan dependency graph for P+(s). Let V \u2217 \u2286 V \\ {x0} so that, for every x \u2208 V \u2217, all oDTG+x transitions are invertible/induced and have irrelevant side effect deletes and no side effects on V \\{x0}, and all other DTGx transitions either are irrelevant, or have empty conditions and irrelevant side effect deletes. Then there exists an operator sequence \u2212\u2192o so that:\n(I) \u2212\u2192o constitutes a path in S from s to a state s1 with h+(s) > h+(s1).\n(II) The length of \u2212\u2192o is at most costd\u2217(oDG+) if we have Definition 2 condition (2a) or (2b), and is at most costd\u2217(oDG+) + 1 if we have Definition 2 condition (2c).\nProof. This is a simple adaptation of Lemma 3, and we adopt in what follows the terminology of the proof of that lemma. The only thing that changes is that the bound imposed on exit path length is sharper, and that we do not insist on that path being monotone. At the level of the proof mechanics, what happens is that, whenever xd+1 \u2208 V \u2217, when we choose a\npath \u2212\u2192q to achieve the next open precondition of an operator o already chosen to participate in \u2212\u2192o d\u25e6\u3008o0\u3009, then we do not restrict ourselves to paths within oDTG+xd+1 , but allow also any shortest path through DTGxd+1 . Being a shortest path in DTGxd+1 to a value that occurs as an operator precondition, \u2212\u2192q contains no irrelevant transitions (same argument as in the proof of Lemma 3). Further, \u2212\u2192q will be executable because by prerequisite the alternative (non-oDTG+x ) transitions in it have no outside conditions; for original/induced transitions, precondition achievement works exactly as before. Note here the important property that open preconditions to be achieved for xd+1 will only ever pertain to values contained in oDTG+xd+1 . This is trivial to see by induction because alternative transitions do not have any outside preconditions. Since by prerequisite any deletes of the alternative transitions are irrelevant, executing them does no harm \u2013 all we need is a minor extension to Lemma 1, allowing s\u2032 to be identical with a state s\u2032\u2032 in the invertible surroundings of s, modulo a set of irrelevant values that hold in s\u2032\u2032 but not in s; it is obvious that this extension is valid. With this extension, it is also obvious that the arguments pertaining to s0 and s1 remain valid. Finally, consider the case where \u2212\u2192q involves a non-case2 oDTG+xd+1 transition. Then the state where this transition is applied is in the invertible surroundings of s. This holds for any x 6\u2208 V \u2217 because for these our construction remains the same. It holds for any x \u2208 V \u2217 because, first, alternative transitions have no outside conditions, hence cause no higher-depth transitions to be inserted in between, hence the value of all lower-depth variables x is in oDTG+x ; second, by prerequisite, oDTG + x does not contain any non-case2 transitions, and thus the value of x we\u2019re at clearly can be reached by case2 transitions.\nTheorem 2. Let (X, sI , sG, O), s, P+(s), and oDG+ be as in Definition 1. If oDG+ is successful, then s is not a local minimum, and ed(s) \u2264 costd\u2217(oDG+). If we have Definition 2 condition (2a) or (2b), then ed(s) \u2264 costd\u2217(oDG+)\u2212 1.\nProof. This is a direct consequence of Lemmas 3 and 4.\nWe note that the prerequisites of Lemma 4 could be weakened by allowing, for x \u2208 V \u2217, outside conditions that are already true in s. This extension obviously does not break the proof arguments. We have omitted it here to not make the lemma prerequisite even more awkward than it already is.\nAs indicated, the exit path constructed in Lemma 4 is not necessarily monotone. Example 5 in Appendix A.4 contains a construction showing this.\nA.3 Conservative Approximations\nFor the sake of self-containedness of this section, we re-state the definitions given in Section 6:\nDefinition 3. Let (X, sI , sG, O) be a planning task, let s \u2208 S with 0 < h+(s) < \u221e, let x0 \u2208 XsG, and let t0 = (s(x0), c) be a relevant transition in DTGx0 with o0 := rop(t0).\nA local dependency graph for s, x0, and o0, or local dependency graph in brief, is a graph lDG = (V,A) with unique leaf vertex x0, and where x \u2208 V and (x, x\u2032) \u2208 A if either: x\u2032 = x0, x \u2208 Xpreo0 , and preo0(x) 6= s(x); or x \u2032 \u2208 V \\ {x0} and (x, x\u2032) is an arc in SG.\nA global dependency graph for x0 and o0, or global dependency graph in brief, is a graph gDG = (V,A) with unique leaf vertex x0, and where x \u2208 V and (x, x\u2032) \u2208 A if either: x\u2032 = x0 and x0 6= x \u2208 Xpreo0 ; or x \u2032 \u2208 V \\ {x0} and (x, x\u2032) is an arc in SG.\nDefinition 4. Let (X, sI , sG, O), s, t0, o0, and G = lDG or G = gDG be as in Definition 3. We say that G = (V,A) is successful if all of the following holds:\n(1) G is acyclic.\n(2) If G = lDG then sG(x0) 6= s(x0), and there exists no transitive successor x\u2032 of x0 in SG so that x\u2032 \u2208 XsG and sG(x\u2032) 6= s(x\u2032).\n(3) We have that t0 either:\n(a) has self-irrelevant side effect deletes; or (b) has replaceable side effect deletes; or (c) has recoverable side effect deletes.\n(4) For x \u2208 V \\ {x0}, all DTGx transitions either are irrelevant, or have self-irrelevant deletes, or are invertible and have irrelevant side effect deletes and no side effects on V \\ {x0}.\nLemma 5. Let (X, sI , sG, O) be a planning task, and let s \u2208 S be a state with 0 < h+(s) < \u221e. Say that x0 \u2208 X and, for every o0 = rop(s(x0), c) in DTGx0 where t0 = (s(x0), c) is relevant, lDGo0 is a successful local dependency graph for s, x0, and o0. Then, for at least one of the o0, there exist an optimal relaxed plan P+(s) for s, and a successful optimal rplan dependency graph oDG+ for P+(s), x0, and o0, where oDG+ is a sub-graph of lDGo0.\nProof. Observe first that Definition 4 property (2) forces any relaxed plan P+(s) to move x0, i.e., we have that P+(s, x0) is non-empty. In particular, P+(s, x0) takes a path in DTGx0 from s(x0) to sG(x0). Let\n\u2212\u2192q be a shortest such path taken by P+(s, x0), and let o0 be the responsible operator of the first transition in \u2212\u2192q . Clearly, this transition has the form (s(x0), c), i.e., o0 is one of the operators o0 in the claim. Lying on a shortest path from s(x0) to sG(x0) in the sub-graph of DTGx0 taken by P\n+(s, x0), the transition (s(x0), c) is not irrelevant. This can be seen with exactly the same argument as given in the proof to Lemma 3 for the transitions on the paths \u2212\u2192q constructed there, except that the endpoint is now a goal instead of an operator precondition.\nNext, observe that any optimal P+(s) contains at most one operator o with x0 \u2208 Xpreo and preo(x0) = s(x0). This also follows from Definition 4 property (2): x0 cannot become important for any non-achieved goal, i.e., no P+(s) operator outside P+(s, x0) relies on a precondition on x0. To see this, assume that such an operator o does exist. Then, since P+(s) is optimal, there exists a \u201creason\u201d for the inclusion of o. Precisely, o must achieve at least one fact that is \u201cneeded\u201d in the terms of Hoffmann and Nebel (2001b): a fact that is either in the goal or in the precondition of another operator o\u2032 behind o in P+(s). Iterating this argument for o\u2032 (if necessary), we obtain a sequence o = o1, (x1, c1), o2, (x2, c2), . . . , on, (xn, cn) where (xn, cn) is a goal fact not satisfied in s and where oi achieves (xi, ci) in P+(s). Obviously, SG then contains a path from x0 to xn, and xn \u2208 XsG and sG(xn) 6= s(xn), in contradiction to Definition 4 property (2). Thus such o does not exist. With the same argument, it follows also that every operator in P+(s, x0)\neither has no side effect used elsewhere in the relaxed plan, or has no precondition on x0. Thus those operators in P+(s, x0) that are preconditioned on x0 serve only to transform s(x0) into sG(x0). Of course, then, at most a single one of these operators relies on s(x0) or else P+(s) is not optimal.\nSay in what follows that lDGo0 = (V,A). Denote by (V \u2032, A\u2032) the result of backchaining by Definition 1 from o0 with P+<0(s). Definition 3 will include all variables and arcs included by Definition 1. To see this, just note that all arcs (x, x\u2032) included by Definition 1 are due to relevant transitions. Hence (V \u2032, A\u2032) is a sub-graph of (V,A). In particular, since (V,A) is acyclic, (V \u2032, A\u2032) is acyclic as well.\nOur next observation is that, assuming that Definition 4 condition (2) holds true, Definition 4 condition (3a) implies Definition 2 condition (2a), Definition 4 condition (3b) implies Definition 2 condition (2b), and Definition 4 condition (3c) implies Definition 2 condition (2c).\nConsider first case (a) where t0 has self-irrelevant side effect deletes. We show that R+1 \u2229C0 = \u2205. Recall here the notations of Appendix A.2 \u2013 C0 = {(x0, s(x0))}\u222a ctx(t0), and R+1 is a super-set of the set of facts that we will need for the relaxed plan after removing o0. For all variables except x0, it is clear that there is no fact in this intersection: all facts in ctx(t0) are irrelevant or o0-only relevant by prerequisite, and are thus not contained in R+1 . Hence, (x0, s(x0)) remains as the only possible content of R+1 \u2229C0. We show in what follows that (x0, s(x0)) 6\u2208 R+1 , and thus (x0, s(x0)) 6\u2208 R + 1 \u2229C0 and the latter intersection is empty, as desired. Recall that R+1 denotes the union of sG, the precondition of any o0 6= o \u2208 P+(s), and the precondition of any operator which is the responsible operator for an induced transition in oDTG+x , with x \u2208 V \\ {x0}. By Definition 4 condition (2), (x0, s(x0)) 6\u2208 sG. As argued above, o0 is the only operator in P+(s) that may be preconditioned on s(x0) and thus it is not in the precondition of any o0 6= o \u2208 P+(s). Lastly, say that p is a precondition of a responsible operator for an induced transition in oDTG+x , the corresponding original transition being t. Then, since inverse transitions do not introduce any new conditions, p \u2208 cond(t) and thus p \u2208 prerop(t) where, by definition, rop(t) \u2208 P+<0(s). But then, since o0 6= rop(t) \u2208 P+(s), we have (x0, s(x0)) 6\u2208 prerop(t), which implies that p 6= (x0, s(x0)). Thus (x0, s(x0)) 6\u2208 R+1 like we needed to show.\nConsider now case (b) where t0 has recoverable side effect deletes. To show Definition 2 condition (2b) for o0 = rop(t0), all we need to prove is that s(x0) is not oDG+-relevant, i.e., that s(x0) 6\u2208 R+1 . This was already shown above.\nFor case (c), t0 has replaceable side effect deletes. Again, to show Definition 2 condition (2c) for t0), all we need to prove is that s(x0) is not oDG+-relevant.\nConsider finally the conditions imposed on non-leaf variables x \u2208 V \\ {x0}, i.e., Definition 4 condition (4) and Definition 2 condition (3). By Definition 4 condition (4), the DTGx transitions of every x \u2208 V \\ {x0} either are irrelevant, or have self-irrelevant deletes, or are invertible and have irrelevant side effect deletes and no side effects on V \\ {x0}. If a DTGx transitions is irrelevant then it cannot be in oDTG+x , thus the 2nd or 3rd case is true of the oDTG+x transitions of every x \u2208 V \u2032 \\ {x0}. This concludes the argument.\nTheorem 3. Let (X, sI , sG, O) be a planning task, and let s \u2208 S be a state with 0 < h+(s) < \u221e. Say that x0 \u2208 X so that, for every o0 = rop(s(x0), c) in DTGx0 where (s(x0), c) is relevant, lDGo0 is a successful local dependency graph. Then s is not a local\nminimum, and ed(s) \u2264 maxo0 costD\u2217(lDGo0). If, for every lDGo0, we have Definition 4 condition (3a) or (3b), then ed(s) \u2264 maxo0 costD\u2217(lDGo0)\u2212 1.\nProof. By Lemma 5, for some choice of o0 = rop(s(x0), c) there exists an optimal relaxed plan P+(s) and a successful optimal rplan dependency graph oDG+ = (V \u2032, A\u2032) for P+(s), so that oDG+ is a sub-graph of lDGo0 with the same unique leaf vertex x0. We can apply Lemma 3 and obtain that s is not a local minimum.\nTo see the other part of the claim, let V \u2217\u2217 be defined as in Section 6, i.e., V \u2217\u2217 is the subset of V \\ {x0} for which all DTGx transitions either are irrelevant, or are invertible and have empty conditions, irrelevant side effect deletes, and no side effects on V \\ {x0}. Then, for each DTGx transition t where x \u2208 V \u2217\u2217, t satisfies both the restriction required by Lemma 4 on oDTG+x transitions \u2013 if t is irrelevant, then it cannot be in oDTG + x , else it is invertible and has irrelevant side effect deletes and no side effects on V \\ {x0} \u2013 and the restriction required by Lemma 4 on the other transitions \u2013 either irrelevant, or empty conditions and irrelevant side effect deletes. We can hence apply Lemma 4 to oDG+, and obtain a (not necessarily monotone) path to an exit, with length bound costd\u2217(oDG+) if (s(x0), c) has irrelevant side effect deletes or replaceable side effect deletes, and costd\u2217(oDG+) + 1 if (s(x0), c) has recoverable side effect deletes. It thus suffices to show that costD\u2217(lDGo0) \u2265 costd\u2217(oDG+). That, however, is obvious because V \u2287 V \u2032, costD\u2217(x) \u2265 0 for all x, and maxPath(DTGx) \u2265 diam(oDTG+x ) for all x \u2208 V \u2032.\nTheorem 4. Let (X, sI , sG, O) be a planning task. Say that all global dependency graphs gDG are successful. Then S does not contain any local minima and, for any state s \u2208 S with 0 < h+(s) < \u221e, ed(s) \u2264 maxgDG costD\u2217(gDG). If, for every gDG, we have Definition 4 condition (3a) or (3b), then ed(s) \u2264 maxgDG costD\u2217(gDG)\u2212 1.\nProof. Let s \u2208 S be a state. We need to prove that s is no local minimum. If h+(s) = 0 or h+(s) = \u221e, there is nothing to show. Else, assume that the variables X are topologically ordered according to the strongly connected components of SG, and let x0 \u2208 X be the uppermost variable so that x0 \u2208 XsG and sG(x0) 6= s(x0); obviously, such x0 exists. Clearly, the only chance for x0 to not satisfy Definition 4 condition (2) \u2013 \u201cthere exists no transitive successor x\u2032 of x0 in SG so that x\u2032 \u2208 XsG and sG(x\u2032) 6= s(x\u2032)\u201d \u2013 is if there exists x\u2032 in the same strongly connected SG component, with x\u2032 \u2208 XsG (and sG(x\u2032) 6= s(x\u2032)). But then, there exists a transition t\u2032 in DTGx\u2032 with an outside condition eventually leading, by backwards chaining in SG, to x0. Let gDG\u2032 be the global dependency graph for x\u2032 and rop(t\u2032) (such a gDG\u2032 exists because x\u2032 \u2208 XsG). Since Definition 3 includes all transitive SG-predecessors of x\u2032 pertaining to the conditions of t\u2032, gDG\u2032 includes x0. But then, since x0 and x\u2032 lie in the same strongly connected component, Definition 3 eventually reaches x\u2032. Thus gDG\u2032 contains a cycle, in contradiction to the prerequisite. It follows that the strongly connected SG component of x0 contains only x0, and thus Definition 4 condition (2) holds true.\nNow, say that o0 is responsible for a relevant transition of the form (s(x0), c) in DTGx0 . Then there exists a local dependency graph lDG for s, x0, and o0 so that lDG is a sub-graph of gDG. This follows from the simple observation that Definition 3 will include, for gDG, all variables and arcs that it will include for lDG. (Note here that any precondition of o0\non x0, if present, is satisfied in s because o0 = rop(s(x0), c), and thus Definition 3 will not include x0 as a predecessor for achieving o0 preconditions in lDG.)\nObviously, given the above, lDG is successful. Since this works for any choice of notirrelevant (s(x0), c), we can apply Theorem 3. The claim follows directly from this and the fact that costD\u2217(gDG) \u2265 costD\u2217(lDG). The latter is obvious because costD\u2217 increases monotonically when adding additional variables.\nA.4 Example Constructions\nOur first example shows that, even within the scope of our basic result, operators are not necessarily respected by the relaxation, i.e., an operator may start an optimal real plan yet not occur in any optimal relaxed plan.\nExample 1. Consider the planning task in Figure 4. Variables are shown (in dark green) on the left hand side of their respective DTG. Circles represent variable values, and lines represent DTG transitions. Transitions with a condition are longer lines, with the condition inscribed below the line (in blue). For each variable, a dashed arrow indicates the value in the initial state sI . Where a goal value is defined, this is indicated by a circled value. Where needed, we will refer to the operators responsible for a transition in terms of the respective variable followed by the indices of the start and end value. For example, the operator moving x from c1 to c2 will be referred to as \u201cx12\u201d. We abbreviate states {(x, c), (y, d)} as (c, d). We stick to these conventions throughout this section.\nAs shown in Figure 4, the DTG of x consists of three vertices whose connection requires the conditions d1 and d3, or alternatively d7 as a shortcut. The domain of y is a line of length 6 requiring no conditions.\nClearly, the support graph of this planning task is acyclic, and all transitions in all DTGs have no side effects and are invertible. However, operator y34 (for example) is not respected by the relaxation. To see this, note first that h+(sI) = 4: the only optimal relaxed plan is \u3008y32, y21, x12, x23\u3009 because the relaxed plan ignores the need to \u201cmove back\u201d to d3 for operator x23. On the other hand, the only optimal (real) plan for sI is \u3008y34, y45, y56, y67, x17\u3009. If we choose to use y32 instead, like the optimal relaxed plan does, then we end up with the sequence \u3008y32, y21, x12, y12, y23, x23\u3009 which is 1 step longer. Hence, in sI , y34 starts an optimal plan, but does not start an optimal relaxed plan.\nWe next give three examples showing how local minima can arise in very simple situations generalizing our basic result only minimally. We consider, in this order: cyclic support graphs; non-invertible transitions; transitions with side effects.\nExample 2. Consider the planning task in Figure 5.\nc2c1 d1\nx\nThe DTG of x is just two vertices whose connection requires the condition d1. The domain of y is a line of length n requiring no conditions, with a shortcut between d1 and dn that requires c1 as condition. Clearly, all transitions in all DTGs have no side effects and are invertible. However, SG contains a cycle between x and y because they mutually depend on each other. We will show now that this mutual dependence causes the initial state sI = {(x, c1), (y, d1)} to be a local minimum, for n \u2265 5. We abbreviate, as before, states {(x, c), (y, d)} as (c, d). We have h+(sI) = 2: the only optimal relaxed plan is \u3008x12, y1n\u3009. Now consider the operators applicable to sI = (c1, d1):\n\u2022 Execute x12, leading to s1 = (c2, d1) with h+(s1) = 2 due to \u3008x21, y1n\u3009. From here, the only new state to be reached is via y12, giving s2 = (c2, d2) with h+(s2) = 3 due to \u3008y21, x21, y1n\u3009. (Note here that n\u2212 2 \u2265 3 by prerequisite, so a relaxed plan composed of yi(i + 1) operators also has \u2265 3 steps.) We have h+(s2) > h+(sI) so this way we cannot reach an exit on a monotone path.\n\u2022 Execute y12, leading to s3 = (c1, d2) with h+(s3) = 3 due to \u3008y21, x12, y1n\u3009. (Note here that n \u2212 2 \u2265 3 by prerequisite, so a relaxed plan moving y by ypp operators has \u2265 4 steps.) Again, the path is not monotone.\n\u2022 Execute y1n, leading to s4 = (c1, dn) with h+(s4) = 2 due to \u3008yn1, x12\u3009. From here, the only new state to be reached is via yn(n\u22121), giving s5 = (c1, dn\u22121) with h+(s5) = 3 due to \u3008y(n\u22121)n, yn1, x12\u3009. (Note here that n\u22122 \u2265 3 by prerequisite, so a relaxed plan moving y to d1 via dn\u22122, . . . , d2 has \u2265 3 + 2 steps.) Again, the path is not monotone.\nNo other operators are applicable to sI , thus we have explored all states reachable from sI on monotone paths. None of those states is an exit, proving that sI is a local minimum (as are s1 and s4). There is, in fact, only a single state s with h+(s) = 1, namely s = (c2, dn\u22121). Clearly, reaching s from sI takes n\u22121 steps: first apply x12, then traverse d2, . . . , dn\u22122. So the exit distance of sI is n\u2212 3, thus this distance is unbounded.\nIn Section 9, the following modification of Example 2 is considered. We set n := 2, i.e., the domain of y is reduced to the two values d1, d2; and we remove the line d2, . . . , dn\u22122, i.e., y can move only via what was previously the short-cut. This modified example falls into the SAS+-PUBS tractable class identified by Ba\u0308ckstro\u0308m and Klein (1991), and it still contains a local minimum (the example is unsolvable, though).\nExample 3. Consider the planning task in Figure 6.\nc2c1 c3\nd2 1d\nx\nThe DTG of x is three vertices whose connection requires (starting from the initial value c1) first condition d2, then condition d1. The domain of y is a circle of length n requiring no conditions, and being invertible except for the arc from d1 to d2.\nClearly, the support graph is acyclic and all transitions in all DTGs have no side effects. However, the non-invertible arc from d1 to d2 causes the initial state sI = (c1, d1) to be a local minimum for all n \u2265 3. This is very easy to see. We have h+(sI) = 3 due to the only optimal relaxed plan \u3008y12, x12, x23\u3009. Note here that the relaxed plan does not have to \u201cmove y back\u201d because (y, d1) is still true after executing y12. Now, the operators applicable to sI are y12 and y1n. The latter, reaching the state sn = (c1, dn), immediately increases the value of h+. This is because, with n \u2265 3, y1n does not get y closer to d2, while moving it farther away from d1 (both of which need to be achieved). The shortest relaxed for sn is \u3008yn1, y12, x12, x23\u3009. Alternatively, say we apply y12 in sI , reaching the state s2 = (c1, d2). We have h+(s2) = n+ 1: we need to apply, in the relaxation, x12, n\u2212 1 steps to complete the circle from d2 back to d1, and x23. Thus, for n \u2265 3, s2 has a larger h+ value than sI . It follows that sI is a local minimum. The nearest exit to sI is sn\u22121 = (c2, dn\u22121): sn\u22121 has the relaxed plan \u3008y(n \u2212 1)n, yn1, x23\u3009 of length 3, and after applying y(n \u2212 1)n we get h+ value 2. Reaching sn\u22121 from sI takes 1 step moving x and n \u2212 2 steps moving y. So the exit distance of sI is n\u2212 1, thus this distance is unbounded. Example 4. Consider the planning task in Figure 7.\nThe DTG of x consists of two kinds of transitions. First, there is a line c1, . . . , cn of transitions requiring no conditions. Second, there are direct links, called short-cuts in what follows, between cn and every other ci, conditioned on value d1 of y. The DTG of y contains just two vertices that are connected unconditionally. Moving from d1 to d2 has the side-effect cn. (That side-effect is responsible for the \u201ctowards-cn direction\u201d of the short-cuts in the DTG of x.)\nThe support graph is acyclic. Its only arc goes from y to x, due to the short-cuts in the DTG of x, and due to the operator y12 which has an effect on x and a precondition on y. The transitions are all invertible; in particular each short-cut has both, a direction towards cn and vice versa. However, the side-effect of y12 causes the initial state sI = (c1, d1) to be a local minimum for all n \u2265 3.\nWe have h+(sI) = 1 due to the only optimal relaxed plan \u3008y12\u3009. Note here that the relaxed plan does not care about the side effect of y12, because c1 is still true afterward. Now, if we apply any operator in sI that leaves c1, then clearly we increase h+ by 1: no matter what move we make, the relaxed plan must include both y12 and a move back to c1. The only other available option in sI is to apply y12. We get the state s1 = (cn, d2). There, h+(s1) = 2 as well, because the relaxed plan needs to re-achieve c1. Since n \u2265 3, doing so via the unconditional sequence cn, . . . , c1 takes \u2265 2 steps. The only alternative is to use the short-cut xn1 from cn to c1; doing so involves applying y21 in the first place, giving us a relaxed plan of length 2. Hence all direct successors of sI have a heuristic value > 1, and so sI is a local minimum. Note also that the exit distance of sI grows with n. The nearest exit is a state from which the goal can be reached in a single step. Clearly, the only such state is (c2, d2). The shortest path to that state, from sI , applies y12 and then moves along the unconditional line cn, . . . , c2, taking 1 + (n\u2212 2) = n\u2212 1 steps.\nWe next show that the exit path constructed using \u201cshort-cuts\u201d, leading to the improved bound costd\u2217 instead of costd, may be non-monotone, and that the improved bound may indeed under-estimate the length of a shortest monotone exit path.\nExample 5. Consider the planning task in Figure 8. In this example, the only optimal relaxed plan for the initial state moves z along the path e0, . . . , e2n \u2013 note here that all these values are needed for moving y \u2013 then moves y to d2k+2n, then moves x to c1. This gives a total of h+(sI) = 2n+ (2k+ 2n) + 1 = 4n+ 2k+ 1 steps.\nThe only operators applicable to sI move z. If we move along the line e0, . . . , e2n, then h+ remains constant: we always need to include the moves back in order to achieve the own goal of z. Once we reach e2n, we can move y one step, then need to move z back, etc. During all these moves, up to the state where y = d2k+2n, as long as z stays within\nd2k+2n\ne2n d1 d2 e0 e2n d2k e0 e1 e2n\nc0 c1\nd0 d2k+1 e2 d2k+2n\ny\nx\ne0, . . . , e2n, h+ remains constant. To see this, observe first that of course it suffices for a relaxed plan to reach once, with z, all the values on this line, taking 2n moves wherever we are on the line; the moves for y are as before. Second, observe that indeed all these moves are needed: wherever y is on the line d0, . . . , d2k+2n, it needs to move to d2k+2n in order to suit x, and it needs to move to d0 to suit its own goal. Every value in e0, . . . , e2n appears as a condition of at least one of these y moves. Thus, from sI , the nearest exit reached this way is the state s where y = d2k+2n and z = e2n: there, we can move x to c1 which decreases h+ to 4n + 2k. The length of the exit path \u2212\u2192o we just described, from sI to s, obviously is 2k \u2217 (2n+ 1) + 2n \u2217 2 = 4kn+ 2k + 4n.\nWhat happens if we move z to e\u2032? Consider first that we do this in sI . Then h+ increases to 4n+ 2k + 2: we need to reach all values on the line e0, . . . , e2n, which from e\u2032 takes one step more. The same argument applies for any state traversed by \u2212\u2192o , because, as argued, in any such state we still need to reach all values on the line e0, . . . , e2n. Thus \u2212\u2192o is the shortest monotone path to an exit.\nThe only optimal rplan dependency graph oDG+ for sI is the entire SG, and oDTG+z contains all of DTGz except e\u2032. The only global dependency graph gDG is the entire SG.\nClearly, in sI , the next required value to reach for any variable is e2n, so the construction in the proof to Theorem 2 will first try to reach that value. When using \u201cshort-cuts\u201d as accounted for by costd\u2217(.), the exit path constructed will move to e2n via e\u2032 rather than via the line e0, . . . , e2n, and thus as claimed this exit path is not monotone.\nFinally, consider the bound returned by costd\u2217(oDG+). Obviously, costd\u2217(oDG+) = costD\u2217(gDG). We obtain the bound (\u22121) + costd\u2217(oDG+) = (\u22121) + 1[costd\u2217(x)] + 1 \u2217 (2k+ 2n)[costd\u2217(x) \u2217 diam(oDTG+y )] + (2k + 2n) \u2217 (n + 1)[costd\u2217(y) \u2217 diam(DTGz)]. Note here that diam(DTGz) = n + 1 because DTGz is a circle with 2n + 2 nodes. Overall, we have (\u22121)+costd\u2217(oDG+) = (2k+2n)\u2217(n+2) = 2kn+4k+2n2+4n. For sufficiently large k, this is less than 4kn+2k+4n, as claimed. In detail, we have 4kn+2k+4n > 2kn+4k+2n2 +4n iff 2kn \u2212 2k > 2n2 iff kn \u2212 k > n2 iff k > n2n\u22121 . This holds, for example, if we set n := 2 and k := 5.\nThe reader will have noticed that Example 5 is very contrived. The reason why we need such a complicated unrealistic example is that costd, and with that costd\u2217, contains two sources of over-estimation, cf. the discussion in Section 5. In particular, every move of non-\nleaf variables is supposed to take a whole oDTG+/DTG diameter. To show that costd\u2217 is not in general an upper bound on the length of a monotone exit path, we thus need the presented construction around k so that its under-estimation \u2013 considering diam(DTGz) instead of diam(oDTG+z ) \u2013 outweighs this over-estimation. Importantly, constructing examples where the \u201cshort-cuts\u201d temporarily increase h+ (but costd\u2217 nevertheless delivers an upper bound on monotone exit path length) is much easier. All that needs to happen is that, for whatever reason, we have a variable z like here, where the currently required value (e2n in Example 5) is reached in oDTG+z values along an unnecessarily long path all of whose values are needed in the relaxed plan. This happens quite naturally, e.g., in transportation domains if the same vehicle needs to load/unload objects along such a longer path.\nWe now demonstrate that, in a case where our analyses apply, exit distance may be exponential.\nExample 6. Consider the planning task in Figure 9.\nc 1 0\nc 2 0\nc 5 1\n0\nx\nThe DTG of x0 is two vertices whose connection is conditioned on c15. For all other variables xi, we have five vertices on a line, alternatingly requiring the last vertex ci+15 of xi+1 and the first vertex ci+11 of xi+1. Clearly, the only optimal rplan dependency graph oDG+ for sI , and the only global dependency graph gDG for the task is the full support graph SG. This is acyclic, and all transitions are invertible and have no side effects, thus our analyses apply.\nWhat are h+(sI) and ed(sI)? For a relaxed plan, we need to move x0 to c02. Due to the conditioning, for each variable both \u201cextreme\u201d values \u2013 left and right hand side \u2013 are required so we need 4 moves for each xi with 1 \u2264 i \u2264 n. Thus h+(sI) = 1 + 4n.\nNow, consider any state s where s(x0) = c01. To construct a relaxed plan, obviously we still need 1 move for x0. We also still need 4 moves for each other variable. Consider x1. If s(x1) = c11 then we need to move it to c 1 5 in order to be able to move x0. If s(x1) = c 1 2 then we need to move it to c15 in order to be able to move x0, and to c 1 1 for its own goal, and so forth. In all cases, all four transitions must be taken in the relaxed plan. Due to the conditioning, recursively the same is true for all other variables. Thus, h+(s) = 1 + 4n.\nThis means that the nearest exit is a state s\u2032 where x0 has value c01 and x1 has value c 1 5: in s\u2032, we can move x0 and afterward, definitely, 4n steps suffice for a relaxed plan. What is the distance to a state s\u2032? We need to move x1 four times. Let\u2019s denote this as d(x1) = 4. Each move requires 4 moves of x2, so d(x2) = 16. The sequence of moves for x2 \u201cinverses direction\u201d three times. At these points, x3 does not need to move so d(x3) = (d(x2)\u2212 3) \u2217 4. Generalizing this, we get d(xi+1) = [d(xi)\u2212 (d(xi)4 \u2212 1)] \u2217 4 = 3d(xi) + 4, so the growth over n is exponential.\nObviously, Example 6 also shows that plan length can be exponential in cases where Theorem 4 applies. We remark that Example 6 is very similar to an example given by Domshlak and Dinitz (2001). The only difference is that Domshlak and Dinitz\u2019s example uses different conditions for transitions to the left/to the right, which enables them to use smaller DTGs with only 3 nodes. In our setting, we cannot use different conditions because we need the transitions to be invertible. This causes the \u201closs\u201d of exit path steps in those situations where the next lower variable \u201cinverses direction\u201d and thus relies on the same outside condition as in the previous step. Indeed, for DTGs of size 3, this loss of steps results in a polynomially bounded exit distance. The recursive formula for d(xi) becomes d(xi+1) = [d(xi) \u2212 (d(xi)2 \u2212 1)] \u2217 2 = d(xi) + 2, resulting in ed(sI) = n\n2 + n. On the other hand, costd\u2217 and costD\u2217 still remain exponential in this case, because they do not consider the loss incurred by inversing directions. Precisely, it is easy to see that costd\u2217(oDG+) = costD\u2217(gDG) = 1 + \u2211n i=1 2\ni = 2n+1 \u2212 1. This proves that these bounds can over-estimate by an exponential amount.\nThe next example shows that the exit path constructed (implicitly) by our analyses may be exponentially longer than an optimal plan for the task.\nExample 7. Consider the planning task in Figure 10.\nIn this example, the only optimal relaxed plan for the initial state is the same as in Example 6, because the \u201calternative\u201d route via c\u203201, . . . , c \u2032 0(4n+1) takes 1 + 4n+ 1 = 4n+ 2 > 4n+ 1 steps. Thus the exit path constructed remains the same, too, with length exponential in n. However, the length of the shortest plan is 4n+ 2.\nNote in Example 7 that the observed weakness \u2013 being guided into the \u201cwrong\u201d direction \u2013 is caused by a weakness of optimal relaxed planning, rather than by a weakness of our analysis. The relaxation overlooks the fact that moving via x1, . . . , xn will incur high costs due to the need to repeatedly undo and re-do conditions achieved beforehand. Note also that, in this example too, we get an exponential over-estimation of exit distance.\nWe finally show that feeding Theorem 2 with non-optimal relaxed plans does not give any guarantees:\nExample 8. Consider the planning task in Figure 11.\nThere are two ways to achieve the goal c2: either via moving y and z, or by moving v1, . . . , vn+2. The only optimal relaxed plan chooses the former option, giving h+(sI) = n+1. As soon as n \u2265 3, however, the only parallel-optimal relaxed plan P+(sI) chooses the latter option because moving y and z results in n + 1 sequential moves, whereas v1, . . . , vn+2 can be moved in parallel, giving parallel length 3.\nConsider what happens to h+ in either of the options. If we move z, then h+ remains constant because we need to move z back into its own goal. As soon as we reach z = en, h+ =\u221e because the last transition is uni-directional and we can no longer achieve the own goal of z. Thus there is no exit path, and in particular no monotone exit path, via this option.\nSay we move v1, . . . , vn+2 instead. In the first move (whichever vi we choose), h+ increases because the shortest option is to undo this move and go via y and z: this takes n+ 2 steps whereas completing the vi moves and going via c\u2032 takes (n+ 1) + 2 = n+ 3 steps.\nThus there is no monotone exit path via this option either, and sI is a local minimum. After completing the n+ 2 moves of vi and moving to x = c\u2032, we have h+ = (n+ 2) + 1 due to the shortest relaxed plan that moves back all vi and moves to x = c2. To reduce this heuristic value to the initial value h+(sI) = n+ 1, we need to execute a further 2 of these steps. The state we have then reached has a better evaluated neighbor, so the exit distance is n+ 5.\nConsider now the effect of feeding Theorem 2 with the parallel-optimal plan P+(sI). Clearly, the optimal rplan dependency graph oDG+ constructed for P+(sI) consists of x and all the vi variables, but does not include y nor z. Thus the theorem applies, and it wrongly concludes that sI is not a local minimum. The exit distance bound computed is (\u22121)+costd\u2217(oDG+) = (\u22121)+1[costd\u2217(x)]+ \u2211n+2 i=1 (1\u22171)[costd\u2217(x)\u2217diam(DTGvi)] = n+2. This is less than the actual distance ed(sI) = n+ 5, and thus this result is also wrong.\nSay we modify Example 8 by making the last transition of z undirected, but making one of the vi transitions unidirectional to the right. Then the v1, . . . , vn+2 option leads into a dead end, whereas the y, z option succeeds. In particular, Theorem 2 does not apply to oDG+ constructed for the parallel-optimal relaxed plan P+(sI), and thus this is an example where using non-optimal relaxed plans results in a loss of information.\nA.5 Benchmark Performance Guarantees\nWe give definitions of the 7 domains mentioned in Propositions 1 and 2. For each domain, we explain why the respective property claimed holds true. In most of the domains, we assume some static properties as are used in PDDL to capture unchanging things like the shape of the road network in a transportation domain. We assume in what follows that such static predicates have been removed prior to the analysis, i.e., prior to testing the prerequisites of Theorem 4.\nDefinition 5. The Logistics domain is the set of all planning tasks \u03a0 = (V,O, sI , sG) whose components are defined as follows. V = P\u222aV where P is a set of \u201cpackage-location\u201d variables p, with Dp = L \u222a V where L is some set representing all possible locations, and V is a set of \u201cvehicle-location\u201d variables v, with Dv = Lv for a subset Lv \u2286 L of locations. O contains three types of operators: \u201cmove\u201d, \u201cload\u201d, and \u201cunload\u201d, where move(v, l1, l2) = ({v = l1}, {v = l2}) for l1 6= l2, load(v, l, p) = ({v = l, p = l}, {p = v}), and unload(v, l, p) = ({v = l, p = v}, {p = l}). sI assigns an arbitrary value to each of the variables, and sG assigns an arbitrary value to some subset of the variables.\nEvery global dependency graph gDG in Logistics either has a package p as the leaf variable x0, or has a vehicle variable v as the leaf variable x0. In the latter case gDG consists of only x0, with no arcs. In the former case, o0 is preconditioned on a single vehicle v only, leading to a single non-leaf variable v. In both cases, gDG is acyclic, all involved transitions have no side effects, and all involved transitions are invertible. Thus we can apply Theorem 4. We have costD\u2217(gDG) = 1 + 1 \u2217 1 for packages and costD\u2217(gDG) = 1 for vehicles, thus overall we obtain the correct bound 1.\nDefinition 6. The Miconic-STRIPS domain is the set of all planning tasks \u03a0 = (V,O, sI , sG) whose components are defined as follows. V = O \u222a D \u222a B \u222a S \u222a {e} where |O| = |D| = |B| = |S| and: O is a set of \u201cpassenger-origin\u201d variables o, with Do = L where L\nis some set representing all possible locations (floors); D is a set of \u201cpassenger-destination\u201d variables d with Dd = L; B is a set of \u201cpassenger-boarded\u201d variables b with Db = {1, 0}; S is a set of \u201cpassenger-served\u201d variables s with Ds = {1, 0}; e is the \u201celevator-location\u201d variable with De = L. O contains three types of operators: \u201cmove\u201d, \u201cboard\u201d, and \u201cdepart\u201d, where move(l1, l2) = ({e = l1}, {e = l2}) for l1 6= l2, board(l, i) = ({e = l, oi = l}, {bi = 1}), and depart(l, i) = ({e = l, di = l, bi = 1}, {bi = 0, si = 1}). sI assigns arbitrary locations to the variables O, D, and e, and assigns 0 to the variables B and S. sG assigns 1 to the variables S.\nPassenger-origin and passenger-destination variables are static, i.e., not affected by any operator. Thus the common pre-processes will remove these variables, using them only to statically prune the set of operators that are reachable. We assume in what follows that such removal has taken place.\nEvery global dependency graph gDG in Miconic-STRIPS has a passenger-served variable si as the leaf variable x0. This leads to non-leaf variables bi and e, with arcs from e to both other variables and from bi to si. Clearly, gDG is acyclic. The transitions of e are all invertible and have no side effects. The transition (0, 1) of bi (is not invertible since departing has a different condition on e but) has an irrelevant own-delete \u2013 bi = 0 does not occur anywhere in the goal or preconditions \u2013 and has no side effects and thus irrelevant side effect deletes. The transition (1, 0) of bi (is not invertible but) is irrelevant \u2013 bi = 0 doesn\u2019t occur anywhere. The transition (0, 1) of the leaf variable si has self-irrelevant side effect deletes \u2013 bi = 1 occurs only in the precondition of the transition\u2019s own responsible operator rop(0, 1) = depart(ld, i). Hence we can apply Theorem 4. This delivers the bound costD\u2217(gDG)\u2212 1 = \u22121 + 1[si] + (1 \u2217 1)[costD\u2217(si) \u2217maxPath(DTGbi)] + (2 \u2217 1)[(costD\u2217(si) + costD\u2217(bi)) \u2217 diam(DTGe)] = 3.\nDefinition 7. The Simple-TSP domain is the set of all planning tasks \u03a0 = (V,O, sI , sG) whose components are defined as follows. V = {p} \u222a V where: p is the \u201cposition\u201d variable, with Dp = L where L is some set representing all possible locations; and V , with |V | = |L|, is a set of \u201clocation-visited\u201d variables v, with Dv = {1, 0}. O contains a single type of operators: move(l1, l2) = ({p = l1}, {p = l2, vl2 = 1}) for l1 6= l2. sI assigns an arbitrary value to p and assigns 0 to the variables V . sG assigns 1 to the variables V .\nEvery global dependency graph gDG in Simple-TSP has a location-visited variable vi as the leaf variable x0. This leads to the single non-leaf variable p. Clearly, gDG is acyclic. Every transition (0, 1) of vi considered, induced by o0 = move(l1, li), has replaceable side effect deletes. Any operator o = move(l1, x) can be replaced by the equivalent operator move(li, x) unless x = li. In the latter case, we have o0 = o which is excluded in the definition of replaceable side effect deletes. Every transition (l1, l2) of p clearly is invertible; it has the irrelevant side effect delete vl2 = 0; its side effect is only on vl2 which is not a non-leaf variable of gDG. Hence we can apply Theorem 4. This delivers the bound costD\u2217(gDG)\u2212 1 = \u22121 + 1[vi] + (1 \u2217 1)[costD(vi) \u2217 diam(DTGp)] = 1.\nWe consider an extended version of the Movie domain, in the sense that, whereas the original domain version considers only a fixed range of snacks (and thus the state space is constant across all domain instances), we allow to scale the number of different snacks.25\n25. The original domain version allows to scale the number of operators adding the same snack. All these operators are identical, and can be removed by trivial pre-processes.\nDefinition 8. The Movie domain is the set of all planning tasks \u03a0 = (V,O, sI , sG) whose components are defined as follows. V = {c0, c2, re} \u222a H. Here, c0 is the \u201ccounterat-zero\u201d variable, with Dc0 = {1, 0}; c2 is the \u201ccounter-at-two-hours\u201d variable, with Dc2 = {1, 0}; re is the \u201cmovie-rewound\u201d variable, with Dre = {1, 0}; H are \u201chave-snack\u201d variables h with Dh = {1, 0}. O contains four types of operators: \u201crewindTwo\u201d, \u201crewindOther\u201d, \u201cresetCounter\u201d, and \u201cgetSnack\u201d, where rewindTwo = ({c2 = 1}, {re = 1}), rewindOther = ({c2 = 0}, {re = 1, c0 = 0}), resetCounter = (\u2205, {c0 = 1}), and getSnack(i) = (\u2205, {hi = 1}). sI assigns an arbitrary value to all variables. sG assigns the re, c0, and H variables to 1.\nNote that, depending on the value of the static variable c2, the operator set will be different: if sI(c2) = 1 then rewindOther is removed, if sI(c2) = 0 then rewindTwo is removed. We refer to the former as case (a) and to the latter as case (b).\nEvery global dependency graph gDG consists of a single (leaf) variable. The transitions of each h variable have no side effects and thus have irrelevant side effect deletes. The transition (0, 1) of c0 has no side effects and thus has irrelevant side effect deletes. The transition (1, 0) of c0 is irrelevant. For case (a), the transition (0, 1) of re has no side effects and thus has irrelevant side effect deletes so we can apply Theorem 4. For case (b), the transition (0, 1) of re has the side effect c0 = 0. Observe that (1) this fact itself is irrelevant; and (2) that the only \u03c8 \u2208 ctx(0, 1) is {c0 = 1}, and o := resetCounter satisfies \u2205 = preo \u2286 (prevrop(0,1) \u222a effrop(0,1)) = {re = 1, c0 = 0}, {c0 = 1} = effo \u2286 \u03c8 = {c0 = 1}, and {c0 = 1} = effo \u2287 {(y, d) | (y, d) \u2208 \u03c8, (y, d) \u2208 sG \u222a \u22c3 rop(c,c\u2032)6=o\u2032\u2208O preo\u2032} = {c0 = 1}. Thus the transition has recoverable side effect deletes, and again we can apply Theorem 4. In case (a), for all gDGs the bound costD(gDG) \u2212 1 applies. Obviously, costD(gDG) = 1 and thus we obtain the correct bound 0. In case (b), the bound costD(gDG) applies, and again costD(gDG) = 1 so we obtain the correct bound 1.\nDefinition 9. The Ferry domain is the set of all planning tasks \u03a0 = (V,O, sI , sG) whose components are defined as follows. V = C \u222a {f, e} where: C is a set of \u201ccar-location\u201d variables c, with Dc = L \u222a {f} where L is some set representing all possible locations; f is the \u201cferry-location\u201d variable with Df = L; e is the \u201cferry-empty\u201d variable with De = {1, 0}. O contains three types of operators: \u201csail\u201d, \u201cboard\u201d, and \u201cdebark\u201d, where sail(l1, l2) = ({f = l1}, {f = l2}) for l1 6= l2, board(l, c) = ({f = l, c = l, e = 1}, {c = f, e = 0}), and debark(l, c) = ({f = l, c = f}, {c = l, e = 1}). sI assigns 1 to variable e, assigns an arbitrary value to variable f , and assigns an arbitrary value other than f to the variables C. sG assigns an arbitrary value 6= f to (some subset of) the variables C and f .\nLet s be an arbitrary reachable state where 0 < h+(s) < \u221e, and let P+(s) be an arbitrary optimal relaxed plan for s. Then we can always apply Theorem 2. To show this, we distinguish three cases: (a) s(e) = 1, o0 = board(l, c) is the first board operator in P+(s), and we set x0 = c; (b) s(e) = 0, o0 = debark(l, c) is the first debark operator in P+(s), and we set x0 = c; (c) P+(s) contains no board or debark operator and we set o0 to be the first operator, sail(l1, l2), in P+(s), with x0 = f . Obviously, exactly one of these cases will hold in s. Let oDG+ = (V,A) be the sub-graph of SG including x0 and the variables/arcs included as per Definition 1. Let t0 be the transition taken by o0.\nIn case (a), obviously we can reorder P+(s) so that either board(l, c) is the first operator in P+(s), or all its predecessors are sail operators. oDG+ then either (1) includes no new\n(non-leaf) variables at all, or (2) includes only f . As for f , clearly all its transitions are invertible and have no side effects. The transition t0 has the own effect (c, f) deleting (c, l) which clearly is not needed in the rest of P+(s). It has the side effect e = 0 deleting e = 1. That latter fact may be needed by other board operators in P+(s). However, necessarily P+(s) contains an operator of the form debark(l\u2032, c), which is applicable after board(l, c) and a sequence of moves that P+(s) must contain from l to l\u2032; debark(l\u2032, c) recovers e = 1. Thus the oDG+-relevant deletes of t0 are P+>0(s)-recoverable. In case (b), similarly we can reorder P+(s) so that either (1) debark(l, c) is the first operator in P+(s), or (2) all its predecessors are sail operators. The transition t0 has the own effect (c, l) deleting (c, f) which clearly is not needed in the rest of P+(s); it has the side effect e = 1 deleting e = 0 which clearly is not needed in the rest of P+(s). Thus, again, the oDG+-relevant deletes of t0 are P+>0(s)-recoverable (the recovering sub-sequence of P + >0(s) being empty because no recovery is required). In case (c), finally, oDG+ contains only f , t0 has no side effects, and its own delete (f, l1) is not needed anymore (in fact, in this case l2 must be the goal for f , and P+(s) contains only the single operator o0). Hence, in all cases, we can apply Theorem 2. costd\u2217(oDG+) = 1 in cases (a1), (b1), and (c) so there we get the bound 0. costd\u2217(oDG+) = 1 + diam(DTGf ) = 2 in cases (a2) and (b2) so there we get the bound 1.\nDefinition 10. The Gripper domain is the set of all planning tasks \u03a0 = (V,O, sI , sG) whose components are defined as follows. V = {ro, f1, f2} \u222a B. Here, ro is the \u201crobotlocation\u201d variable, with Dro = {L,R}; f1, f2 are \u201cgripper-free\u201d variables, with Df1 = Df2 = {1, 0}; and B are \u201cball-location\u201d variables, with Db = {L,R, 1, 2}. O contains three types of operators: \u201cmove\u201d, \u201cpickup\u201d, and \u201cdrop\u201d, where move(l1, l2) = ({ro = l1}, {ro = l2}) for l1 6= l2, pickup(g, b, l) = ({ro = l, b = l, fg = 1}, {b = g, fg = 0}), and drop(g, b, l) = ({ro = l, b = g}, {b = l, fg = 1}). sI assigns L to ro, assigns 1 to f1 and f2, and assigns L to the variables B. sG assigns R to the variables B.\nLet s be an arbitrary reachable state where 0 < h+(s) < \u221e, and let P+(s) be an arbitrary optimal relaxed plan for s. Then we can always apply Theorem 2. We distinguish two cases: (a) there exists b \u2208 B so that s(b) = g for g \u2208 {1, 2}, o0 = drop(g, b, R), and we set x0 = b; (b) there exists no b \u2208 B so that s(b) = g for g \u2208 {1, 2}, o0 = pickup(g, b, L) for some b \u2208 B is in P+(s), and we set x0 = b. Obviously, exactly one of these cases will hold in s. Let oDG+ = (V,A) be the sub-graph of SG including x0 and the variables/arcs included as per Definition 1. Let t0 be the transition taken by o0.\nIn case (a), obviously we can reorder P+(s) so that either drop(g, b, R) is the first operator in P+(s), or its only predecessor is move(L,R). oDG+ then either (1) includes no new (non-leaf) variables at all, or (2) includes only ro. As for ro, clearly all its transitions are invertible and have no side effects. The transition t0 has the own effect (b, R) deleting (b, g) which clearly is not needed in the rest of P+(s); it has the side effect fg = 1 deleting fg = 0 which clearly is not needed in the rest of P+(s). Thus the oDG+-relevant deletes of t0 are P+>0(s)-recoverable. In case (b), similarly we can reorder P\n+(s) so that either (1) pickup(g, b, L) is the first operator in P+(s), or (2) its only predecessor is move(R,L). The transition t0 has the own effect (b, g) deleting (b, L) which clearly is not needed in the rest of P+(s). It has the side effect fg = 0 deleting fg = 1; that latter fact may be needed by other pickup operators in P+(s). However, necessarily P+(s) contains the operators move(L,R) and drop(g, b, R), which are applicable after board(l, c); drop(g, b, R) recovers fg = 1. Thus,\nagain, the oDG+-relevant deletes of t0 are P+>0(s)-recoverable. Hence, in both cases, we can apply Theorem 2. costd\u2217(oDG+) = 1 in cases (a1) and (b1), so there we get the bound 0. costd\u2217(oDG+) = 1 + diam(ro) = 2 in cases (a2) and (b2) so there we get the bound 1.\nDefinition 11. The Transport domain is the set of all planning tasks \u03a0 = (V,O, sI , sG) whose components are defined as follows. V = P \u222a V E \u222a C where: P is a set of \u201cpackagelocation\u201d variables p, with Dp = L \u222a V E where L is some set representing all possible locations; V E is a set of \u201cvehicle-location\u201d variables v, with Dv = L; and C is a set of \u201cvehicle-capacity\u201d variables cv, with Dcv = {0, . . . ,K} where K is the maximum capacity. O contains three types of operators: \u201cdrive\u201d, \u201cpickup\u201d, and \u201cdrop\u201d, where: drive(v, l1, l2) = ({v = l1}, {v = l2}) for (l1, l2) \u2208 R where GR = (L,R) is an undirected graph of roads over L; pickup(v, l, p, c) = ({v = l, p = l, cv = c}, {p = v, cv = c\u2212 1}), and drop(v, l, p, c) = ({v = l, p = v, cv = c}, {p = l, cv = c + 1}). sI assigns an arbitrary value in L to each of the variables P \u222a V E, and assigns K to the variables C. sG assigns an arbitrary value in L to some subset of the variables P \u222a V E.\nNote here the use of numbers and addition/subtraction. These are, of course, not part of the planning language we consider here. However, they can be easily encoded (on the finite set of number {0, . . . ,K}) via static predicates. After pre-processing, in effect the resulting task will be isomorphic to the one obtained by the simple arithmetic above, which we thus choose to reduce notational clutter.\nLet s be an arbitrary reachable state where 0 < h+(s) < \u221e. Then there exists an optimal relaxed plan P+(s) for s so that we can apply Theorem 2. We distinguish three cases: (a) there exists p \u2208 P so that s(p) = v for v \u2208 V E, o0 = drop(v, l, p, c) where s(cv) = c is in P+(s), and we set x0 = p; (b) there exists no p \u2208 P so that s(p) = v for v \u2208 V E, o0 = pickup(v, l, p,K) for some p \u2208 P is in P+(s), and we set x0 = p; (c) P+(s) contains no drop or pickup operator and we set o0 to be the first operator, drive(v, l1, l2), in P+(s), with x0 = v. Obviously, we can choose P+(s) so that exactly one of these cases will hold in s (the choice of P+(s) is arbitrary for (b) and (c), but in (a) there may exist optimal relaxed plans where s(cv) 6= c). Let oDG+ = (V,A) be the sub-graph of SG including x0 and the variables/arcs included as per Definition 1. Let t0 be the transition taken by o0.\nIn case (a), obviously we can reorder P+(s) so that either o0 = drop(v, l, p, c) is the first operator in P+(s), or all its predecessors are drive operators. oDG+ then either (1) includes no new (non-leaf) variables at all, or (2) includes only v. As for v, clearly all its transitions are invertible and have no side effects. The transition t0 has the own effect (p, v) deleting (p, l) which clearly is not needed in the rest of P+(s). It has the side effect cv = c+1 deleting cv = c. That latter fact may be needed by other operators in P+(s), either taking the form drop(v, l\u2032, p\u2032, c) or the form pickup(v, l\u2032, p\u2032, c). Clearly, if P+(s) contains these operators then we can replace them with drop(v, l\u2032, p\u2032, c + 1) and pickup(v, l\u2032, p\u2032, c + 1) respectively \u2013 the value (cv, c + 1) will be true at their point of (relaxed) execution. Thus we can choose P+(s) so that the P+(s)-relevant deletes of t0 are P+(s)-recoverable on V \\ {x0}. In case (b), similarly we can reorder P+(s) so that either (1) o0 = pickup(v, l, p,K) is the first operator in P+(s), or (2) all its predecessors are drive operators. The transition t0 has the own effect (p, v) deleting (p, l) which clearly is not needed in the rest of P+(s). It has the side effect cv = K \u2212 1 deleting cv = K. That latter fact may be needed by other operators in P+(s), taking the form pickup(v, l\u2032, p\u2032,K). However, necessarily P+(s)\ncontains an operator of the form drop(v, l\u2032, p, c\u2032). If c\u2032 6= K \u2212 1 then we can replace this operator with drop(v, l\u2032, p,K \u2212 1) since, clearly, the value (cv,K \u2212 1) will be true at the point of (relaxed) execution. Now, drop(v, l\u2032, p,K \u2212 1) is applicable after pickup(v, l, p,K) and a sequence of drive operators that P+(s) must contain from l to l\u2032; drop(v, l\u2032, p,K \u2212 1) recovers cv = K. Thus, again, we can choose P+(s) so that the P+(s)-relevant deletes of t0 are P+(s)-recoverable on V \\ {x0}. In case (c), finally, oDG+ contains only v, t0 has no side effects, and its own delete (v, l1) is not needed anymore. Hence, in all cases, we can apply Theorem 2. costd\u2217(oDG+) = 1 in cases (a1), (b1), and (c) so there we get the bound 0. costd\u2217(oDG+) = 1 + min(diam(oDTG+v ),diam(DTGv)) in cases (a2) and (b2) so there the bound is at most the diameter of the road map GR.\nWhen ignoring action costs, the Elevators domain of IPC 2008 is essentially a variant of Transport. The variant is more general in that (a) each vehicle (each elevator) may have its own maximal capacity, and (b) each vehicle can reach only a subset of the locations, i.e., each vehicle has an individual road map. On the other hand, Elevators is more restricted than Transport in that (c) each vehicle road map is fully connected (every reachable floor can be navigated to directly from every other reachable floor), and (d) goals exist only for packages (passengers, that is), not for vehicles. Even when ignoring restrictions (c) and (d), it is trivial to see that the arguments given above for Transport still hold true. Therefore, whenever s is a reachable state with 0 < h+(s) < \u221e, there exists an optimal relaxed plan P+(s) for s so that we can apply Theorem 2. As before, the bound is at most the diameter of the road map. Due to (c), this diameter is 1."}], "references": [{"title": "Planning in polynomial time: The SAS-PUBS class", "author": ["C. B\u00e4ckstr\u00f6m", "I. Klein"], "venue": "Computational Intelligence,", "citeRegEx": "B\u00e4ckstr\u00f6m and Klein,? \\Q1991\\E", "shortCiteRegEx": "B\u00e4ckstr\u00f6m and Klein", "year": 1991}, {"title": "Fast planning through planning graph analysis", "author": ["A.L. Blum", "M.L. Furst"], "venue": "Artificial Intelligence,", "citeRegEx": "Blum and Furst,? \\Q1997\\E", "shortCiteRegEx": "Blum and Furst", "year": 1997}, {"title": "Planning as heuristic search", "author": ["B. Bonet", "H. Geffner"], "venue": "Artificial Intelligence,", "citeRegEx": "Bonet and Geffner,? \\Q2001\\E", "shortCiteRegEx": "Bonet and Geffner", "year": 2001}, {"title": "Using component abstraction for automatic generation of macro-actions", "author": ["A. Botea", "M. M\u00fcller", "J. Schaeffer"], "venue": null, "citeRegEx": "Botea et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Botea et al\\.", "year": 2004}, {"title": "Structure and complexity in planning with unary operators", "author": ["R. Brafman", "C. Domshlak"], "venue": "Journal of Artificial Intelligence Research,", "citeRegEx": "Brafman and Domshlak,? \\Q2003\\E", "shortCiteRegEx": "Brafman and Domshlak", "year": 2003}, {"title": "The computational complexity of propositional STRIPS planning", "author": ["T. Bylander"], "venue": "Artificial Intelligence,", "citeRegEx": "Bylander,? \\Q1994\\E", "shortCiteRegEx": "Bylander", "year": 1994}, {"title": "Recent Advances in AI Planning", "author": ["A. Cesta", "D. Borrajo"], "venue": "European Conference on Planning (ECP\u201901),", "citeRegEx": "Cesta and Borrajo,? \\Q2001\\E", "shortCiteRegEx": "Cesta and Borrajo", "year": 2001}, {"title": "Causal graphs and structurally restricted planning", "author": ["H. Chen", "O. Gim\u00e9nez"], "venue": "Journal of Computer and System Sciences,", "citeRegEx": "Chen and Gim\u00e9nez,? \\Q2010\\E", "shortCiteRegEx": "Chen and Gim\u00e9nez", "year": 2010}, {"title": "Multi-agent offline coordination: Structure and complexity", "author": ["C. Domshlak", "Y. Dinitz"], "venue": "In Cesta & Borrajo (Cesta & Borrajo,", "citeRegEx": "Domshlak and Dinitz,? \\Q2001\\E", "shortCiteRegEx": "Domshlak and Dinitz", "year": 2001}, {"title": "Exhibiting knowledge in planning problems to minimize state encoding length", "author": ["S. Edelkamp", "M. Helmert"], "venue": "Recent Advances in AI Planning. 5th European Conference on Planning (ECP\u201999), Lecture Notes in Artificial Intelligence,", "citeRegEx": "Edelkamp and Helmert,? \\Q1999\\E", "shortCiteRegEx": "Edelkamp and Helmert", "year": 1999}, {"title": "The automatic inference of state invariants in TIM", "author": ["M. Fox", "D. Long"], "venue": "Journal of Artificial Intelligence Research,", "citeRegEx": "Fox and Long,? \\Q1998\\E", "shortCiteRegEx": "Fox and Long", "year": 1998}, {"title": "The detection and exploitation of symmetry in planning problems", "author": ["M. Fox", "D. Long"], "venue": "Proceedings of the 16th International Joint Conference on Artificial Intelligence", "citeRegEx": "Fox and Long,? \\Q1999\\E", "shortCiteRegEx": "Fox and Long", "year": 1999}, {"title": "Computers and Intractability\u2014A Guide to the Theory of NP-Completeness", "author": ["M.R. Garey", "D.S. Johnson"], "venue": null, "citeRegEx": "Garey and Johnson,? \\Q1979\\E", "shortCiteRegEx": "Garey and Johnson", "year": 1979}, {"title": "Planning through stochastic local search and temporal action graphs", "author": ["A. Gerevini", "A. Saetti", "I. Serina"], "venue": "Journal of Artificial Intelligence Research,", "citeRegEx": "Gerevini et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Gerevini et al\\.", "year": 2003}, {"title": "Inferring state-constraints for domain independent planning", "author": ["A. Gerevini", "L. Schubert"], "venue": "Proceedings of the 15th National Conference of the American Association for Artificial Intelligence", "citeRegEx": "Gerevini and Schubert,? \\Q1998\\E", "shortCiteRegEx": "Gerevini and Schubert", "year": 1998}, {"title": "The complexity of planning problems with simple causal graphs", "author": ["O. Gim\u00e9nez", "A. Jonsson"], "venue": "Journal of Artificial Intelligence Research,", "citeRegEx": "Gim\u00e9nez and Jonsson,? \\Q2008\\E", "shortCiteRegEx": "Gim\u00e9nez and Jonsson", "year": 2008}, {"title": "The influence of k-dependence on the complexity of planning", "author": ["O. Gim\u00e9nez", "A. Jonsson"], "venue": "In Gerevini et al. (Gerevini,", "citeRegEx": "Gim\u00e9nez and Jonsson,? \\Q2009\\E", "shortCiteRegEx": "Gim\u00e9nez and Jonsson", "year": 2009}, {"title": "Planning over chain causal graphs for variables with domains of size 5 is NP-hard", "author": ["O. Gim\u00e9nez", "A. Jonsson"], "venue": "Journal of Artificial Intelligence Research,", "citeRegEx": "Gim\u00e9nez and Jonsson,? \\Q2009\\E", "shortCiteRegEx": "Gim\u00e9nez and Jonsson", "year": 2009}, {"title": "Reducing accidental complexity in planning problems", "author": ["P. Haslum"], "venue": "Proceedings of the 20th International Joint Conference on Artificial Intelligence", "citeRegEx": "Haslum,? \\Q2007\\E", "shortCiteRegEx": "Haslum", "year": 2007}, {"title": "Complexity results for standard benchmark domains in planning", "author": ["M. Helmert"], "venue": "Artificial Intelligence,", "citeRegEx": "Helmert,? \\Q2003\\E", "shortCiteRegEx": "Helmert", "year": 2003}, {"title": "A planning heuristic based on causal graph analysis", "author": ["M. Helmert"], "venue": "In Koenig et al. (Koenig et al.,", "citeRegEx": "Helmert,? \\Q2004\\E", "shortCiteRegEx": "Helmert", "year": 2004}, {"title": "The fast downward planning system", "author": ["M. Helmert"], "venue": "Journal of Artificial Intelligence Research,", "citeRegEx": "Helmert,? \\Q2006\\E", "shortCiteRegEx": "Helmert", "year": 2006}, {"title": "Concise finite-domain representations for PDDL planning tasks", "author": ["M. Helmert"], "venue": "Artificial Intelligence,", "citeRegEx": "Helmert,? \\Q2009\\E", "shortCiteRegEx": "Helmert", "year": 2009}, {"title": "Landmarks, critical paths and abstractions: What\u2019s the difference anyway", "author": ["M. Helmert", "C. Domshlak"], "venue": "In Gerevini et al. (Gerevini et al.,", "citeRegEx": "Helmert and Domshlak,? \\Q2009\\E", "shortCiteRegEx": "Helmert and Domshlak", "year": 2009}, {"title": "Utilizing Problem Structure in Planning: A Local Search Approach, Vol. 2854 of Lecture Notes in Artificial Intelligence", "author": ["J. Hoffmann"], "venue": null, "citeRegEx": "Hoffmann,? \\Q2003\\E", "shortCiteRegEx": "Hoffmann", "year": 2003}, {"title": "Where \u2018ignoring delete lists\u2019 works: Local search topology in planning benchmarks", "author": ["J. Hoffmann"], "venue": "Journal of Artificial Intelligence Research,", "citeRegEx": "Hoffmann,? \\Q2005\\E", "shortCiteRegEx": "Hoffmann", "year": 2005}, {"title": "The FF planning system: Fast plan generation through heuristic search", "author": ["J. Hoffmann", "B. Nebel"], "venue": "Journal of Artificial Intelligence Research,", "citeRegEx": "Hoffmann and Nebel,? \\Q2001\\E", "shortCiteRegEx": "Hoffmann and Nebel", "year": 2001}, {"title": "RIFO revisited: Detecting relaxed irrelevance", "author": ["J. Hoffmann", "B. Nebel"], "venue": "In Cesta & Borrajo (Cesta & Borrajo,", "citeRegEx": "Hoffmann and Nebel,? \\Q2001\\E", "shortCiteRegEx": "Hoffmann and Nebel", "year": 2001}, {"title": "Ordered landmarks in planning", "author": ["J. Hoffmann", "J. Porteous", "L. Sebastia"], "venue": "Journal of Artificial Intelligence Research,", "citeRegEx": "Hoffmann et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Hoffmann et al\\.", "year": 2004}, {"title": "The role of macros in tractable planning", "author": ["A. Jonsson"], "venue": "Journal of Artificial Intelligence Research,", "citeRegEx": "Jonsson,? \\Q2009\\E", "shortCiteRegEx": "Jonsson", "year": 2009}, {"title": "Incremental planning", "author": ["P. Jonsson", "C. B\u00e4ckstr\u00f6m"], "venue": "In European Workshop on Planning", "citeRegEx": "Jonsson and B\u00e4ckstr\u00f6m,? \\Q1995\\E", "shortCiteRegEx": "Jonsson and B\u00e4ckstr\u00f6m", "year": 1995}, {"title": "State-variable planning under structural restrictions: Algorithms and complexity", "author": ["P. Jonsson", "C. B\u00e4ckstr\u00f6m"], "venue": "Artificial Intelligence,", "citeRegEx": "Jonsson and B\u00e4ckstr\u00f6m,? \\Q1998\\E", "shortCiteRegEx": "Jonsson and B\u00e4ckstr\u00f6m", "year": 1998}, {"title": "Cost-optimal planning with landmarks", "author": ["E. Karpas", "C. Domshlak"], "venue": "Proceedings of the 21st International Joint Conference on Artificial Intelligence", "citeRegEx": "Karpas and Domshlak,? \\Q2009\\E", "shortCiteRegEx": "Karpas and Domshlak", "year": 2009}, {"title": "New islands of tractability of cost-optimal planning", "author": ["M. Katz", "C. Domshlak"], "venue": "Journal of Artificial Intelligence Research,", "citeRegEx": "Katz and Domshlak,? \\Q2008\\E", "shortCiteRegEx": "Katz and Domshlak", "year": 2008}, {"title": "Structural patterns heuristics via fork decomposition", "author": ["M. Katz", "C. Domshlak"], "venue": "Proceedings of the 18th International Conference on Automated Planning and Scheduling", "citeRegEx": "Katz and Domshlak,? \\Q2008\\E", "shortCiteRegEx": "Katz and Domshlak", "year": 2008}, {"title": "Automatically generating abstractions for planning", "author": ["C. Knoblock"], "venue": "Artificial Intelligence,", "citeRegEx": "Knoblock,? \\Q1994\\E", "shortCiteRegEx": "Knoblock", "year": 1994}, {"title": "Automatic synthesis and use of generic types in planning", "author": ["D. Long", "M. Fox"], "venue": "Proceedings of the 5th International Conference on Artificial Intelligence Planning Systems", "citeRegEx": "Long and Fox,? \\Q2000\\E", "shortCiteRegEx": "Long and Fox", "year": 2000}, {"title": "Using regression-match graphs to control search in planning", "author": ["D.V. McDermott"], "venue": "Artificial Intelligence,", "citeRegEx": "McDermott,? \\Q1999\\E", "shortCiteRegEx": "McDermott", "year": 1999}, {"title": "Ignoring irrelevant facts and operators in plan generation", "author": ["B. Nebel", "Y. Dimopoulos", "J. Koehler"], "venue": "Recent Advances in AI Planning. 4th European Conference on Planning (ECP\u201997),", "citeRegEx": "Nebel et al\\.,? \\Q1997\\E", "shortCiteRegEx": "Nebel et al\\.", "year": 1997}, {"title": "Landmarks revisited", "author": ["S. Richter", "M. Helmert", "M. Westphal"], "venue": "Proceedings of the 23rd National Conference of the American Association for Artificial Intelligence", "citeRegEx": "Richter et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Richter et al\\.", "year": 2008}, {"title": "The LAMA planner: Guiding cost-based anytime planning with landmarks", "author": ["S. Richter", "M. Westphal"], "venue": "Journal of Artificial Intelligence Research,", "citeRegEx": "Richter and Westphal,? \\Q2010\\E", "shortCiteRegEx": "Richter and Westphal", "year": 2010}, {"title": "An iterative algorithm for synthesizing invariants", "author": ["J. Rintanen"], "venue": "Proceedings of the 17th National Conference of the American Association for Artificial Intelligence", "citeRegEx": "Rintanen,? \\Q2000\\E", "shortCiteRegEx": "Rintanen", "year": 2000}, {"title": "Learning from planner performance", "author": ["M. Roberts", "A. Howe"], "venue": "Artificial Intelligence,", "citeRegEx": "Roberts and Howe,? \\Q2009\\E", "shortCiteRegEx": "Roberts and Howe", "year": 2009}, {"title": "A lookahead strategy for heuristic search planning", "author": ["V. Vidal"], "venue": "In Koenig et al. (Koenig et al.,", "citeRegEx": "Vidal,? \\Q2004\\E", "shortCiteRegEx": "Vidal", "year": 2004}, {"title": "A reactive planner for a model-based executive", "author": ["B.C. Williams", "P.P. Nayak"], "venue": "Proceedings of the 15th International Joint Conference on Artificial Intelligence", "citeRegEx": "Williams and Nayak,? \\Q1997\\E", "shortCiteRegEx": "Williams and Nayak", "year": 1997}], "referenceMentions": [{"referenceID": 21, "context": "The ignoring delete lists relaxation has been since a decade, and still is, of paramount importance for effective satisficing planning (e.g., McDermott, 1999; Bonet & Geffner, 2001; Hoffmann & Nebel, 2001a; Gerevini, Saetti, & Serina, 2003; Helmert, 2006; Richter & Westphal, 2010).", "startOffset": 135, "endOffset": 281}, {"referenceID": 5, "context": "The planners using the relaxation approximate, in a variety of ways, the optimal relaxation heuristic h+ which itself is NP-hard to compute (Bylander, 1994).", "startOffset": 140, "endOffset": 156}, {"referenceID": 25, "context": "As was observed in earlier work (Hoffmann, 2005), h+ has some rather amazing qualities in many classical planning benchmarks.", "startOffset": 32, "endOffset": 48}, {"referenceID": 25, "context": "Figure 1: Overview of h+ topology (Hoffmann, 2005).", "startOffset": 34, "endOffset": 50}, {"referenceID": 25, "context": "The single exception, to the best of the author\u2019s knowledge, is an analysis method mentioned on the side in the author\u2019s earlier work (Hoffmann, 2005).", "startOffset": 134, "endOffset": 150}, {"referenceID": 10, "context": "introduced by Fox and Long (1999) as a benchmark for symmetry detection.", "startOffset": 14, "endOffset": 34}, {"referenceID": 21, "context": ", Jonsson & B\u00e4ckstr\u00f6m, 1998; Helmert, 2006, 2009) and to consider the associated structures, notably the causal graph (e.g., Knoblock, 1994; Jonsson & B\u00e4ckstr\u00f6m, 1995; Domshlak & Dinitz, 2001; Helmert, 2006) capturing the precondition and effect dependencies between variables.", "startOffset": 118, "endOffset": 207}, {"referenceID": 29, "context": "Whereas traditional methods (e.g., Jonsson & B\u00e4ckstr\u00f6m, 1995; Brafman & Domshlak, 2003; Jonsson, 2009; Gim\u00e9nez & Jonsson, 2009a) seek execution paths solving the overall task, we seek \u201conly\u201d execution paths decreasing the value of h+.", "startOffset": 28, "endOffset": 128}, {"referenceID": 19, "context": "We adopt the terminology and notation of Helmert (2006), with a number of modifications suiting our purposes.", "startOffset": 41, "endOffset": 56}, {"referenceID": 18, "context": "works, (e.g., Jonsson & B\u00e4ckstr\u00f6m, 1998; Haslum, 2007).", "startOffset": 7, "endOffset": 54}, {"referenceID": 5, "context": ", the negative operator effects (Bylander, 1994; McDermott, 1999; Bonet & Geffner, 2001).", "startOffset": 32, "endOffset": 88}, {"referenceID": 37, "context": ", the negative operator effects (Bylander, 1994; McDermott, 1999; Bonet & Geffner, 2001).", "startOffset": 32, "endOffset": 88}, {"referenceID": 13, "context": "Many state-of-the-art planners approximate h+, in a variety of ways (e.g., McDermott, 1999; Bonet & Geffner, 2001; Hoffmann & Nebel, 2001a; Gerevini et al., 2003; Helmert, 2006; Richter, Helmert, & Westphal, 2008; Richter & Westphal, 2010).", "startOffset": 68, "endOffset": 239}, {"referenceID": 21, "context": "Many state-of-the-art planners approximate h+, in a variety of ways (e.g., McDermott, 1999; Bonet & Geffner, 2001; Hoffmann & Nebel, 2001a; Gerevini et al., 2003; Helmert, 2006; Richter, Helmert, & Westphal, 2008; Richter & Westphal, 2010).", "startOffset": 68, "endOffset": 239}, {"referenceID": 5, "context": ", the negative operator effects (Bylander, 1994; McDermott, 1999; Bonet & Geffner, 2001). This raises the question what h+ actually is, in finite-domain variable planning, where there are no \u201cdelete lists\u201d. That question is easily answered. \u201cIgnoring deletes\u201d essentially means to act as if \u201cwhat was true once will remain true forever\u201d. In the finite-domain variable setting, this simply means to not over-write any values that the variables had previously. To our knowledge, this generalization was first described by Helmert (2006). Consider the directed graph S+ whose vertices are all sets s+ of variablevalue pairs over X, with an arc (s1 , s + 2 ) iff there exists o \u2208 O such that preo \u2286 s + 1 and s2 = s + 1 \u222a effo.", "startOffset": 33, "endOffset": 535}, {"referenceID": 5, "context": ", the negative operator effects (Bylander, 1994; McDermott, 1999; Bonet & Geffner, 2001). This raises the question what h+ actually is, in finite-domain variable planning, where there are no \u201cdelete lists\u201d. That question is easily answered. \u201cIgnoring deletes\u201d essentially means to act as if \u201cwhat was true once will remain true forever\u201d. In the finite-domain variable setting, this simply means to not over-write any values that the variables had previously. To our knowledge, this generalization was first described by Helmert (2006). Consider the directed graph S+ whose vertices are all sets s+ of variablevalue pairs over X, with an arc (s1 , s + 2 ) iff there exists o \u2208 O such that preo \u2286 s + 1 and s2 = s + 1 \u222a effo. If s is a state, then a relaxed plan for s is a path in S+ leading from s to s+ with sG \u2286 s+. By h+(s) we denote the length of a shortest relaxed plan for s, or h+(s) = \u221e if no such plan exists. It is easy to see that this definition corresponds to the common Boolean one: if we translate the finite-domain variables into Boolean ones by creating one Boolean variable \u201cis-(x, c)-true?\u201d for every fact (x, c), then standard h+ in the Boolean task is identical to h+ in the finite-domain variable task. Bylander (1994) proved that it is intractable to compute h+.", "startOffset": 33, "endOffset": 1241}, {"referenceID": 25, "context": "The topology definitions, adapted from the author\u2019s previous work (Hoffmann, 2005), are specific to h+ only for the sake of simplicity (we will herein not consider any heuristics other than h+).", "startOffset": 66, "endOffset": 82}, {"referenceID": 41, "context": "Such analysis has a long tradition in planning (e.g., Nebel, Dimopoulos, & Koehler, 1997; Fox & Long, 1998; Gerevini & Schubert, 1998; Edelkamp & Helmert, 1999; Rintanen, 2000).", "startOffset": 47, "endOffset": 176}, {"referenceID": 25, "context": "The single exception are the aforementioned disappointing results reported (as an aside) in the author\u2019s previous work (Hoffmann, 2005).", "startOffset": 119, "endOffset": 135}, {"referenceID": 19, "context": ", Nebel, Dimopoulos, & Koehler, 1997; Fox & Long, 1998; Gerevini & Schubert, 1998; Edelkamp & Helmert, 1999; Rintanen, 2000). Most often, the information sought pertains to reachability or relevance properties, i.e., which entities or combinations thereof are reachable from the initial state/relevant to the goal. A notable exception is the work of Long and Fox (2000) which automatically recognizes certain \u201cgeneric types\u201d of domains, like transportation.", "startOffset": 94, "endOffset": 370}, {"referenceID": 5, "context": "The membership results in Theorem 1 are easy to prove based on guess-and-check arguments similar as given by Bylander (1994), exploiting the fact that NPSPACE=PSPACE.", "startOffset": 109, "endOffset": 125}, {"referenceID": 25, "context": "We remark that the hand-made analysis of h+ (Hoffmann, 2005) uses a notion of operators \u201crespected by the relaxation\u201d.", "startOffset": 44, "endOffset": 60}, {"referenceID": 25, "context": "There are subtle differences to previous definitions of \u201cinvertible operators\u201d, like the author\u2019s (Hoffmann, 2005).", "startOffset": 98, "endOffset": 114}, {"referenceID": 19, "context": "However, in both of them, deciding bounded plan existence is NP-hard (Helmert, 2003).", "startOffset": 69, "endOffset": 84}, {"referenceID": 22, "context": "It uses Fast Downward\u2019s translator (Helmert, 2009) to find the finitedomain variables.", "startOffset": 35, "endOffset": 50}, {"referenceID": 25, "context": "These include the domains investigated in the hand-made analysis of h+ topology (Hoffmann, 2005), as shown in Figure 1, which include all domains from the international planning competitions (IPC) up to IPC 2004.", "startOffset": 80, "endOffset": 96}, {"referenceID": 42, "context": "Roberts and Howe (2009), for", "startOffset": 0, "endOffset": 24}, {"referenceID": 39, "context": "Apart from TorchLight (and SP/SP1s), these include FF (Hoffmann & Nebel, 2001a), and LAMA (Richter et al., 2008; Richter & Westphal, 2010).", "startOffset": 90, "endOffset": 138}, {"referenceID": 24, "context": "In Grid, in 20% of cases our analysis is not strong enough to recognize the reasons behind non-existence of local minima; these reasons can be quite complicated (Hoffmann, 2003).", "startOffset": 161, "endOffset": 177}, {"referenceID": 25, "context": "Its rather excessive bound 31 is due to the very particular domain structure where philosophers behave in strictly symmetrical ways (Hoffmann, 2005).", "startOffset": 132, "endOffset": 148}, {"referenceID": 25, "context": "Upper part: domains whose h+ topology was previously examined by hand (Hoffmann, 2005) or is trivial to examine based on these results; lower part: IPC 2006/2008 domains where that is not the case.", "startOffset": 70, "endOffset": 86}, {"referenceID": 24, "context": "In large-scale experiments measuring statistics on the search space surface under FF\u2019s heuristic function (Hoffmann, 2003), it was observed that many sampled states were not local minima themselves, but where contained in \u201cvalleys\u201d.", "startOffset": 106, "endOffset": 122}, {"referenceID": 42, "context": "For comparison, using state-of-the-art classification techniques but only simple features, Roberts and Howe (2009) get 69.", "startOffset": 91, "endOffset": 115}, {"referenceID": 42, "context": "Exploiting this informativeness for predicting planner performance presumably requires combination with other features, and actual machine learning techniques, along the lines of Roberts and Howe (2009). This is a topic for future research.", "startOffset": 179, "endOffset": 203}, {"referenceID": 25, "context": "There is no prior work \u2013 other than the aforementioned one of the author (Hoffmann, 2005) \u2013 trying to automatically infer topological properties of a heuristic function.", "startOffset": 73, "endOffset": 89}, {"referenceID": 43, "context": "In this, our work relates to work on macro-actions (e.g., Botea, M\u00fcller, & Schaeffer, 2004; Vidal, 2004).", "startOffset": 51, "endOffset": 104}, {"referenceID": 7, "context": "the tractable class Fn identified by Domshlak and Dinitz (2001), because every transition of the dependent variable depends on the other variable.", "startOffset": 37, "endOffset": 64}, {"referenceID": 7, "context": "the tractable class Fn identified by Domshlak and Dinitz (2001), because every transition of the dependent variable depends on the other variable. The example is in Helmert\u2019s (2004, 2006) SAS+-1 class with strongly connected DTGs. The example is \u201csolved\u201d, i.e., reduced to the empty task, by Haslum\u2019s (2007) simplification techniques (also, these techniques solve tasks from the Satellite domain, which do contain local minima).", "startOffset": 37, "endOffset": 308}, {"referenceID": 7, "context": "the tractable class Fn identified by Domshlak and Dinitz (2001), because every transition of the dependent variable depends on the other variable. The example is in Helmert\u2019s (2004, 2006) SAS+-1 class with strongly connected DTGs. The example is \u201csolved\u201d, i.e., reduced to the empty task, by Haslum\u2019s (2007) simplification techniques (also, these techniques solve tasks from the Satellite domain, which do contain local minima). The example has a fork and inverted fork causal graph, with bounded domain size and 1-dependent actions only (actions with at most 1 prevail condition), thus it qualifies for the tractable classes identified by Katz and Domshlak (2008b). The example\u2019s causal graph is a chain, and thus in particular a polytree with bounded indegree, corresponding to the tractable class identified by Brafman and Domshlak (2003) except that, there, variables are restricted to be binary (domain size 2).", "startOffset": 37, "endOffset": 666}, {"referenceID": 4, "context": "The example\u2019s causal graph is a chain, and thus in particular a polytree with bounded indegree, corresponding to the tractable class identified by Brafman and Domshlak (2003) except that, there, variables are restricted to be binary (domain size 2).", "startOffset": 147, "endOffset": 175}, {"referenceID": 4, "context": "The example\u2019s causal graph is a chain, and thus in particular a polytree with bounded indegree, corresponding to the tractable class identified by Brafman and Domshlak (2003) except that, there, variables are restricted to be binary (domain size 2). It is an open question whether plan existence with chain causal graphs and domain size 3 is tractable; the strongest known result is that it is NP-hard for domain size 5 (Gim\u00e9nez & Jonsson, 2009b).21 Similarly, the example fits the prerequisites stated by Katz and Domshlak (2008a) except that these are for binary variables only; it is an open question whether local minima exist in the tractable classes identified there.", "startOffset": 147, "endOffset": 532}, {"referenceID": 4, "context": "The example\u2019s causal graph is a chain, and thus in particular a polytree with bounded indegree, corresponding to the tractable class identified by Brafman and Domshlak (2003) except that, there, variables are restricted to be binary (domain size 2). It is an open question whether plan existence with chain causal graphs and domain size 3 is tractable; the strongest known result is that it is NP-hard for domain size 5 (Gim\u00e9nez & Jonsson, 2009b).21 Similarly, the example fits the prerequisites stated by Katz and Domshlak (2008a) except that these are for binary variables only; it is an open question whether local minima exist in the tractable classes identified there. Finally, the example, and a suitable scaling extension, obviously qualifies for two theorems stated by Chen and Gimenez (2010). Their Theorem 3.", "startOffset": 147, "endOffset": 801}, {"referenceID": 29, "context": "Next, consider the line of works restricting not the causal graph but the DTGs of the task (B\u00e4ckstr\u00f6m & Klein, 1991; B\u00e4ckstr\u00f6m & Nebel, 1995; Jonsson & B\u00e4ckstr\u00f6m, 1998). The simplest class identified here, contained in all other classes, is SAS+-PUBS where each fact is achieved by at most one operator (\u201cpost-unique\u201d, \u201cP\u201d), all operators are unary (\u201cU\u201d), all variables are binary (\u201cB\u201d), and all variables have at most one value required in the condition of a transition on any other variable (\u201csingle-valued\u201d, \u201cS\u201d). Now, Example 2 in Appendix A.4 shows a local minimum in an example that has the U and S properties. The example has two variables, x and y, and the local minimum arises because a cyclic dependency prevents y from attaining its goal value dn via the shortest path as taken by an optimal relaxed plan. If we remove all but two values from the domain of y, and remove the alternative way of reaching dn, then the example still contains a local minimum and also has the P and B properties. We remark that the modified example is unsolvable. It remains an open question whether solvable SAS+-PUBS tasks with local minima exist; more generally, this question is open even for the larger SAS+-PUS class, and for the (yet larger) SAS+-IAO class identified by Jonsson and B\u00e4ckstr\u00f6m (1998). Another open question is whether the \u201c3S\u201d class of Jonsson and B\u00e4ckstr\u00f6m (1995) contains local minima.", "startOffset": 142, "endOffset": 1297}, {"referenceID": 29, "context": "Next, consider the line of works restricting not the causal graph but the DTGs of the task (B\u00e4ckstr\u00f6m & Klein, 1991; B\u00e4ckstr\u00f6m & Nebel, 1995; Jonsson & B\u00e4ckstr\u00f6m, 1998). The simplest class identified here, contained in all other classes, is SAS+-PUBS where each fact is achieved by at most one operator (\u201cpost-unique\u201d, \u201cP\u201d), all operators are unary (\u201cU\u201d), all variables are binary (\u201cB\u201d), and all variables have at most one value required in the condition of a transition on any other variable (\u201csingle-valued\u201d, \u201cS\u201d). Now, Example 2 in Appendix A.4 shows a local minimum in an example that has the U and S properties. The example has two variables, x and y, and the local minimum arises because a cyclic dependency prevents y from attaining its goal value dn via the shortest path as taken by an optimal relaxed plan. If we remove all but two values from the domain of y, and remove the alternative way of reaching dn, then the example still contains a local minimum and also has the P and B properties. We remark that the modified example is unsolvable. It remains an open question whether solvable SAS+-PUBS tasks with local minima exist; more generally, this question is open even for the larger SAS+-PUS class, and for the (yet larger) SAS+-IAO class identified by Jonsson and B\u00e4ckstr\u00f6m (1998). Another open question is whether the \u201c3S\u201d class of Jonsson and B\u00e4ckstr\u00f6m (1995) contains local minima.", "startOffset": 142, "endOffset": 1378}, {"referenceID": 29, "context": "Many causal graph based tractability results require unary operators (Jonsson & B\u00e4ckstr\u00f6m, 1995; Domshlak & Dinitz, 2001; Brafman & Domshlak, 2003; Helmert, 2004, 2006; Katz & Domshlak, 2008a, 2008b; Jonsson, 2009; Gim\u00e9nez & Jonsson, 2008, 2009a), which does not cover Miconic-STRIPS, Movie, and Simple-TSP.", "startOffset": 69, "endOffset": 246}, {"referenceID": 37, "context": "Williams and Nayak (1997) mention restrictions (but do not make formal claims regarding tractability) corresponding exactly to our basic result except that they allow irreversible \u201crepair\u201d actions.", "startOffset": 0, "endOffset": 26}, {"referenceID": 5, "context": "Finally, it is easy to see that, of Bylander\u2019s (1994) three tractability criteria, those two allowing several effects do not imply the absence of local minima.", "startOffset": 36, "endOffset": 54}, {"referenceID": 5, "context": "Finally, it is easy to see that, of Bylander\u2019s (1994) three tractability criteria, those two allowing several effects do not imply the absence of local minima. For his third criterion, restricting action effects to a single literal and preconditions to positive literals (but allowing negative goals), we leave it as an open question whether or not local minima exist. We remark that this criterion does not apply in any benchmark we are aware of. To close this section, while we certainly do not wish to claim the identification of tractable classes to be a contribution of our work, we note that the scope of Theorem 4 \u2013 which is a tractable class, cf. the above \u2013 is not covered by the known tractable classes.23 The tractable cases identified by Bylander (1994) obviously do not cover any of Logistics, Miconic-STRIPS, Movie, and Simple-TSP.", "startOffset": 36, "endOffset": 766}, {"referenceID": 5, "context": "Finally, it is easy to see that, of Bylander\u2019s (1994) three tractability criteria, those two allowing several effects do not imply the absence of local minima. For his third criterion, restricting action effects to a single literal and preconditions to positive literals (but allowing negative goals), we leave it as an open question whether or not local minima exist. We remark that this criterion does not apply in any benchmark we are aware of. To close this section, while we certainly do not wish to claim the identification of tractable classes to be a contribution of our work, we note that the scope of Theorem 4 \u2013 which is a tractable class, cf. the above \u2013 is not covered by the known tractable classes.23 The tractable cases identified by Bylander (1994) obviously do not cover any of Logistics, Miconic-STRIPS, Movie, and Simple-TSP. Many causal graph based tractability results require unary operators (Jonsson & B\u00e4ckstr\u00f6m, 1995; Domshlak & Dinitz, 2001; Brafman & Domshlak, 2003; Helmert, 2004, 2006; Katz & Domshlak, 2008a, 2008b; Jonsson, 2009; Gim\u00e9nez & Jonsson, 2008, 2009a), which does not cover Miconic-STRIPS, Movie, and Simple-TSP. In the work of Chen and Gimenez (2010), Theorem 4.", "startOffset": 36, "endOffset": 1193}, {"referenceID": 5, "context": "Finally, it is easy to see that, of Bylander\u2019s (1994) three tractability criteria, those two allowing several effects do not imply the absence of local minima. For his third criterion, restricting action effects to a single literal and preconditions to positive literals (but allowing negative goals), we leave it as an open question whether or not local minima exist. We remark that this criterion does not apply in any benchmark we are aware of. To close this section, while we certainly do not wish to claim the identification of tractable classes to be a contribution of our work, we note that the scope of Theorem 4 \u2013 which is a tractable class, cf. the above \u2013 is not covered by the known tractable classes.23 The tractable cases identified by Bylander (1994) obviously do not cover any of Logistics, Miconic-STRIPS, Movie, and Simple-TSP. Many causal graph based tractability results require unary operators (Jonsson & B\u00e4ckstr\u00f6m, 1995; Domshlak & Dinitz, 2001; Brafman & Domshlak, 2003; Helmert, 2004, 2006; Katz & Domshlak, 2008a, 2008b; Jonsson, 2009; Gim\u00e9nez & Jonsson, 2008, 2009a), which does not cover Miconic-STRIPS, Movie, and Simple-TSP. In the work of Chen and Gimenez (2010), Theorem 4.1 requires reversibility which is not given in either of Movie, Miconic-STRIPS, or Simple-TSP, and Theorem 3.1 requires a constant bound on the size of the connected components in the undirected graph induced by the causal graph, which is given in none of Logistics, MiconicSTRIPS, and Simple-TSP. Other known tractability results make very different restrictions on the DTGs (B\u00e4ckstr\u00f6m & Klein, 1991; B\u00e4ckstr\u00f6m & Nebel, 1995; Jonsson & B\u00e4ckstr\u00f6m, 1998). Even the most general tractable class identified there, SAS+-IAO, covers none of Miconic-STRIPS, Logistics, and Simple-TSP (because vehicle variables are not \u201cacyclic with respect to requestable values\u201d), and neither does it cover Movie (because rewinding a movie is neither unary nor \u201cirreplaceable\u201d: it has a side effect un-setting the counter, while not breaking the DTG of the counter into two disjoint components). As far as coverage of the benchmarks goes, the strongest competitor of Theorem 4 are Haslum\u2019s (2007) simplification techniques.", "startOffset": 36, "endOffset": 2180}, {"referenceID": 44, "context": "and B\u00e4ckstr\u00f6m (1995) and Williams and Nayak (1997). Formally, its prerequisites imply those of (the", "startOffset": 25, "endOffset": 51}, {"referenceID": 25, "context": "An approach automatically recognizing such operators could possibly be developed along the lines of Hoffmann and Nebel (2001b), or using a simplified version of the aforementioned \u201cfact generation tree\u201d analysis technique (Hoffmann, 2005).", "startOffset": 222, "endOffset": 238}, {"referenceID": 24, "context": "An approach automatically recognizing such operators could possibly be developed along the lines of Hoffmann and Nebel (2001b), or using a simplified version of the aforementioned \u201cfact generation tree\u201d analysis technique (Hoffmann, 2005).", "startOffset": 100, "endOffset": 127}, {"referenceID": 42, "context": "Another possibility is planner performance prediction, along the lines of Roberts and Howe (2009). Our experimental results indicate that TorchLight\u2019s problem features, and also those of search probing, are highly informative.", "startOffset": 74, "endOffset": 98}, {"referenceID": 18, "context": "The lack of guidance is one of the main open problems identified by Haslum (2007) for his automatic reformulation approach.", "startOffset": 68, "endOffset": 82}, {"referenceID": 5, "context": "From here, we can prove the membership results by simple modifications of the guess-and-check argument showing that PLANSAT, the problem of deciding whether a given planning task is solvable, is in NPSPACE and hence in PSPACE (Bylander, 1994).", "startOffset": 226, "endOffset": 242}, {"referenceID": 5, "context": "The proof works by reducing PLANSAT, which is known to be PSPACE-hard for propositional STRIPS (Bylander, 1994), from which it trivially follows that PLANSAT is PSPACE-hard also for the finitedomain variable planning tasks we use herein.", "startOffset": 95, "endOffset": 111}, {"referenceID": 25, "context": "That argument corresponds to part (A) in the proof to Lemma 3 in the author\u2019s previous work (Hoffmann, 2005).", "startOffset": 92, "endOffset": 108}, {"referenceID": 24, "context": "Precisely, o must achieve at least one fact that is \u201cneeded\u201d in the terms of Hoffmann and Nebel (2001b): a fact that is either in the goal or in the precondition of another operator o\u2032 behind o in P+(s).", "startOffset": 77, "endOffset": 104}, {"referenceID": 0, "context": "This modified example falls into the SAS+-PUBS tractable class identified by B\u00e4ckstr\u00f6m and Klein (1991), and it still contains a local minimum (the example is unsolvable, though).", "startOffset": 77, "endOffset": 104}, {"referenceID": 8, "context": "We remark that Example 6 is very similar to an example given by Domshlak and Dinitz (2001). The only difference is that Domshlak and Dinitz\u2019s example uses different conditions for transitions to the left/to the right, which enables them to use smaller DTGs with only 3 nodes.", "startOffset": 64, "endOffset": 91}], "year": 2011, "abstractText": "The ignoring delete lists relaxation is of paramount importance for both satisficing and optimal planning. In earlier work, it was observed that the optimal relaxation heuristic h has amazing qualities in many classical planning benchmarks, in particular pertaining to the complete absence of local minima. The proofs of this are hand-made, raising the question whether such proofs can be lead automatically by domain analysis techniques. In contrast to earlier disappointing results \u2013 the analysis method has exponential runtime and succeeds only in two extremely simple benchmark domains \u2013 we herein answer this question in the affirmative. We establish connections between causal graph structure and h topology. This results in low-order polynomial time analysis methods, implemented in a tool we call TorchLight. Of the 12 domains where the absence of local minima has been proved, TorchLight gives strong success guarantees in 8 domains. Empirically, its analysis exhibits strong performance in a further 2 of these domains, plus in 4 more domains where local minima may exist but are rare. In this way, TorchLight can distinguish \u201ceasy\u201d domains from \u201chard\u201d ones. By summarizing structural reasons for analysis failure, TorchLight also provides diagnostic output indicating domain aspects that may cause local minima.", "creator": "TeX"}}}