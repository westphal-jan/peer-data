{"id": "1401.5334", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "21-Jan-2014", "title": "A Microkernel Architecture for Constraint Programming", "abstract": "This paper presents a microkernel architecture for constraint programming organized around a number of small number of core functionalities and minimal interfaces. The architecture contrasts with the monolithic nature of many implementations. Experimental results indicate that the software engineering benefits are not incompatible with runtime efficiency or power of small or large application systems.\n\n\n\n\n\nThe paper discusses a small set of microkernel features. They represent a relatively large number of small, very small, and highly complex applications, each described in the paper. The paper summarizes two sets of microkernel features, including an improved kernel architecture for the task of designing an application.\nThis paper shows a simple, straightforward and easy to install application that uses a very small number of functionalities.\nThe results of this paper indicate a fairly large set of microkernel features, including a very small, and highly complex application system that is capable of implementing more than 40 unique applications, which can be optimized for small or large application systems.\nThe following microkernel features are provided by the authors:\nCompatibility: A standard Java application, a microkernel based on a single core Java application, an app that uses a Java interface for the task of managing the application. A standard Java app that uses a Java interface for the task of managing the application.\nCompatibility: An example application running a single core Java interface using a Java interface for the task of managing the application.\nCloning a single core Java interface using a Java interface for the task of managing the application. Cloning a single core Java interface using a Java interface for the task of managing the application. Compatibility: An example application using a Java interface for the task of managing the application. Cloning a single core Java interface using a Java interface for the task of managing the application. Compatibility: An example application using a Java interface for the task of managing the application. Cloning a single core Java interface using a Java interface for the task of managing the application.\nCloning a single core Java interface using a Java interface for the task of managing the application. Cloning a single core Java interface using a Java interface for the task of managing the application. Compatibility: An example application using a Java interface for the task of managing the application. Cloning a single core Java interface using a Java interface for the task of managing the application. Cloning a single core Java interface using a Java interface for the task of managing the application.\nCloning a single core Java interface using a Java interface for the task of managing the application. Cl", "histories": [["v1", "Tue, 21 Jan 2014 14:56:14 GMT  (88kb,D)", "http://arxiv.org/abs/1401.5334v1", null]], "reviews": [], "SUBJECTS": "cs.AI cs.PL", "authors": ["laurent michel", "pascal van hentenryck"], "accepted": false, "id": "1401.5334"}, "pdf": {"name": "1401.5334.pdf", "metadata": {"source": "CRF", "title": "A Microkernel Architecture for Constraint Programming", "authors": ["P. Van Hentenryck"], "emails": ["ldm@engr.uconn.edu", "pvh@nicta.com.au"], "sections": [{"heading": "1 Introduction", "text": "Over the years, the constraint programming community has built and experimented with a variety of system design and implementation Historically, solvers were embedded in logic programming languages, CHIP [3], CLP(R) [11], and Prolog III [2] being prime examples. Later solvers were packaged as libraries hosted in traditional object-oriented and imperative languages. Examples abound starting with Ilog Solver [10], Gecode [22] and Minion [8] for C++ and Choco [12] or JacOP [13] for Java (to name just a few). The success of algebraic modeling languages in the mathematical programming community as well as the desire to not be constrained by the host language prompted advances in domain-specific languages, a trend examplified by Oz/Mozart [23], Opl [24], Salsa [14], and Comet [25] for instance. In all cases, the traditional constraint-programming capabilities are exposed by an API capturing the mantra"}, {"heading": "CP = Model + Search", "text": "However, in these implementations, the solver is delivered as a monolithic piece of software incorporating key notions such as variables, constraints, events, propagation protocols, propagators, and search support. Perhaps even more strikingly, propagation engines include provisions to deal with decisions variables of many different types (e.g., int,float,set), possibly replicating the APIs for each variant. Orthogonal features (e.g., the support for AC-5, views, and advisors) further contribute to complexity as APIs must be duplicated to transmit additional information to the propagators when events of specific classes occur. While conceptually simple, this approach does not scale very well. Consider the\nar X\niv :1\n40 1.\n53 34\nv1 [\ncs .A\nI] 2\n1 Ja\nn 20\nComet API shown in Figure 1. It blends support for AC-3, AC-5, and the ability to convey the index of a variable to a propagator along with two types of decision variables. The protocol AC5Constraint<CP> in lines 1\u201313 only captures the methods that a propagator supporting AC-5 could implement. Line 9, for instance, specifies method valRemoveIdx which is called whenever variable v appearing at index vIdx in some array has lost value val. Similarly, the integer variable VarInt<CP> offers one registration method for each class of events that the variable is susceptible to raise. The net result is a large APIs encompassing the union of core capabilities for all variable types and event classes.\nThis paper examines a possible alternative to such a design: It describes the microkernel of the Objective-CP [28] system, a new constraint programming system that refines the core mantra to\nOptimization Program = Model + Search+ Solver\nObjective-CP isolates all the responsibilities associated with model manipulation, rewriting, specialization and reformulation in the modeling component. This factorizes key capabilities that are reusable by multiple solvers and promotes the idea of model combinators described in [5]. Objective-CP also supports search facilities through a technology-neutral search library featuring combinators and a seamless symbiosis with the host language, i.e., ObjectiveC. The search library [29] makes it possible to specify and execute complex search procedures with minimal effort and delivers competitive performance. The Objective-CP constraint-programming solver embraces the idea of a mi-\ncrokernel architecture inspired by recent develoments in operating systems. The constraint engine features a number of small components with parsimonious interfaces. Microkernel architectures have become very popular in operating systems as they favor extensibility and maintenance, and make proofs of correctness easier. The constraint-programming engine underlying Objective-CP delivers a truly modular architecture where variables, domains, and constraints all remain completely external to the microkernel. Each computational domain (e.g., booleans, reals, integers, sets) becomes a service on top of the microkernel, providing the necessary infrastructure for propagation-driven inferencing. In particular the microkernel isolates the propagation logic and events protocols from the variables and constraint definitions. This architecture is therefore a departure from the monolithic organization prevalent in modern solvers. It is designed to encourage the construction of separate libraries each featuring different domains, variable representation (e.g., finite-domains, intervals, sets, MDDs) and constraints.\nThe rest of the paper is organized as follows. Section 2 provides a brief overview of Objective-CP and the vision for the system. Section 3 covers the functionalities of the microkernel. Section 4 discusses how to use the microkernel to implement a finite-domain solver. Section 5 offers empirical evidence of the platform capabilities and Section 6 concludes the paper."}, {"heading": "2 Overview of Objective-CP", "text": "The design of Objective-CP takes the view that\nOptimization Program = Model + Search + Solver\nor, in other words, that an optimization program consits of a model, a search, and an underlying solver. The overall architecture is illustrated in Figure 2 where a model is concretized into a solver. The solver is the composition of an engine (responsible for the representation of constraint, variables, and the inferencing) and an explorer (responsible for technology-neutral search capabilities). The kernel itself implements the two interfaces shown on the left-hand side to drive the propagation (the CPUKernel) and to register constraints and variables (the Engine)."}, {"heading": "2.1 The Vision underlying Objective-CP", "text": "Models Models are first-class objects in Objective-CP. They follow the style of constraint programming and are solver-independent. This allows for easy experimentation with different technologies and smooth hybridizations [5, 6]. Models can be transformed and refined through a sequence of operators that, for instance, replace algebraic equations with lower-level elementary constraints. The final model is then concretized into a specific solver to obtain an optimization program, (e.g., a constraint program or a mixed-integer program). Given a model M , a sequence of model operators \u03c40, \u00b7 \u00b7 \u00b7 \u03c4k, and a concretization function \u03b3T for a solver technology T , the application\n\u03b3T (\u03c4k(\u00b7 \u00b7 \u00b7 \u03c41(\u03c40(M)) \u00b7 \u00b7 \u00b7 ))\nderives a concrete program based on technology T . The resulting program can be solved using a black-box search or a dedicated search procedure expressed in terms of the model variables present in M .\nSearch Search procedures in Objective-CP are specified in terms of high-level nondeterministic constructs, search combinators, and node selection strategies, merging the benefits of search controllers and continuations [27] on the one hand and compositional combinators (e.g., [21]) on the other hand. The search language is generic and independent of the underlying solver. Naturally, search procedures call the underlying engine for adding constraints, binding variables, and querying the search state.\nEngine The underlying engines can leverage any combinatorial optimization technology ranging from linear programming and integer programming to constraint programming and constraint-based local search. The role of the engine is to isolate the state representation and inferencing capabilities. This paper focuses on a microkernel architecture for the inference engine focused on \u201ctraditional\u201d (finite-domain) constraint programming."}, {"heading": "2.2 First-Order Functions", "text": "Objective-CP leans heavily on its host language (Objective-C) to implement its capabilities. In particular, it relies on closures and first-order functions. In Objective-C, it is straightforward to turn any C block into a first-order function. For instance, the fragment\n1 [S enumerateWithBlock: ^(id obj) { 2 printf(\"object: %@\\n\" ,[obj description ]); 3 }];\nuses an Objective-C block to produce a first-order function capable of printing an object (obj). The first-order function is then used to visit a set S and print its entire content. The syntax of Objective-C block is reminiscent of the syntax for function pointers in C: The caret symbol indicates a block creation."}, {"heading": "2.3 An Objective-CP Primer", "text": "This section is a brief primer to Objective-CP. Consider the Steel Mill Slab problem as an example. An abridged3 Objective-CP implementation is shown in Figure 3. In this program, line 1 first creates a model m, while lines 5 and 6 create two decision variable arrays slab and load to represent the slab assignment and the load of each slab. Lines 8\u201311 state the model constraints, i.e., a global packing constraint and a coloring constraint for each slab, and the objective function (line 11) which minimizes the total loss. The model is not specific to constraint programming and Line 13 transforms and concretizes this high-level model into a constraint program. While m is clearly constructed with algebraic expressions, the microkernel underlying the CP engine operates on a rewriting of the model featuring exclusively low-level and global constraints. To be more precise, line 13 is equivalent to\ncp = \u03b3CP (\u03c40(m));\nwhere \u03c40(m) is a flattening operator that creates a new model based on m in which all relations and expressions have been replaced by basic constraints. \u03b3CP (M) is a concretization function that associates a concrete variable with each modeling variable in m, as well as a propagator with every modeling constraint in m. The concretized model is then loaded into the engine of a constraintprogramming solver. Finally, lines 15\u201325 implement the search and rely on the tryall: combinator to specify the non-deterministic choices. It is worth noticing how Objective-CP blends the control primitive of the host language with\n3 The data reading part of the program is omitted for brevity.\nsearch combinators in a completely transparent and fully compositional way. From an Objective-CP end-user standpoint, the entire search is expressed in terms of the decision variables from m. Method calls such as label:with: and diff:with: are exclusively manipulating model variables, yet they are automatically recasted in term of concrete variables and delegated to the underlying engine. Indeed, the call in the closure on line 21 becomes\n1 [[cp engine] add: \u03b3CP (\u03c40(slab[i] == s))];\nwhere the abstract constraint slab[i] == s is flattened with \u03c40 and concretized with \u03b3CP before being transmitted to the underlying engine."}, {"heading": "2.4 A Solver Interface", "text": "A solver is the composition of an explorer responsible for the search and an engine responsible for inferencing. The engine implements two distinct interfaces. The engine interface is the solver-facing part of Objective-CP needed for concretizing models: It offers the necessary capabilities to register variables, constraints, and objective functions. The microkernel interface is used by system developers when building new propagators: It offers the functionalities for propagation-related activities such as the dispatching of events.\nThe Engine The interface shown in Figure 4 is the visible tip of the iceberg for microkernel users. It is the API needed to load constraints and objective functions. It offers only three methods to register a concrete constraint over concrete variables (line 2); to set the objective function via the setObjective: method (line 3); and to execute an arbitrary closure and propagate its effects with the enforce: method (line 4). The closure cl passed to enforce: returns a status (i.e., an element in the set {fail, suspend, succeed}) to report the propagation outcome.\nConstraints The CPConstraint protocol used by the engine is shown below\n1 @protocol CPConstraint 2 -(ORUInt) getId; 3 -(void) post; 4 @end\nIt only requires that a constraint carries a unique identifier and responds to a post request. Naturally, constraints have additional methods but these are not mandated by the microkernel.\nObjective The ORObjective protocol is shown below alongside a protocol to describe the value of an objective function.\n1 @protocol ORObjective 2 -(id <ORObjectiveValue >) value; 3 @end 4 5 @protocol ORObjectiveValue 6 -(id <ORObjectiveValue >) best: (id <ORObjectiveValue >) other; 7 -(ORInt) compare: (id<ORObjectiveValue >) other; 8 @end\nAt its most abstract level, one can query an objective to retrieve its current value represented as an abstract object as well. Note how ORObjectiveValue instances can be compared to pick the best value. Naturally, one should only compare objective values issued by the same objective function, so that the optimization direction is correctly taken into account. For instance, a call to best: on an objective value a receiving an objective value b returns the best overall objective value. If the objective function was a minimization over the real, the returned result encapsulates a value ranging over the reals and retains the knowledge that it is coming from a minimization."}, {"heading": "3 The Microkernel Architecture", "text": "The purpose of the microkernel is to act as a relay for messages pertaining to the propagation of constraints. The key challenge is to design a small set of capabilities to suppot variables, constraints, and propagation techniques of different forms. While it is always possible to define a kernel offering the union of all the required capabilities, the approach does not scale and is truly intrusive when designing new classes of constraints with different messaging requirements as illustrated in the introductory example with the Comet API in Figure 1.\nThe constraint-programming microkernel of Objective-CP presents an alternative design based on a minimalistic API with two capabilities:\n\u2013 scheduling events \u2013 propagating events.\nThe API of the microkernel per se is shown in Figure 5. Line 2 descibes the method for scheduling constraint events, Line 3 the method for scheduling value events, Line 4 the method for scheduling all triggers associated with a value loss, and line 5 the method for scheduling all triggers associated with a value\nbinding. Finally, line 6 is the method needed to trigger the inferencing. These APIs only require a handful of other protocols that embody the concept of event lists and maps. Namely, they reference CPClosureEvent, CPValueEvent, and CPTriggerMap. In the following section, responding to events is best understood as executing an arbitrary piece of code represented by a function. The exact nature of the response is discussed in Section 3.3."}, {"heading": "3.1 Propagation Preliminaries", "text": "Events The concept of event is the cornerstone of the microkernel. Events are the vehicle of choice to relay information and takes a very abstract form that is independent of the nature of the variables involved. In this paper, events are closures in a functional-programming sense. Namely, they are blocks of code that capture the computational state at the time of their definition and are wrapped in a first-order function (of type void \u2192 void) that can be saved, called, or passed to other functions.\nPriority Space The microkernel supports event priorities, using a range of numerical values 0..P , where P is the highest priority and 0 is the lowest. Two priorities in this range have special statuses. Priority 0 is always dispatched regardless of the outcome of the propagation, i.e., even in case of a failure. Priority P is reserved for value-driven events. The remaining priorities (1..P \u2212 1) are available for general use. The existence of a special priority 0 may sound surprising at first. However, it is the ideal vehicle to implement key functionalities in a non-intrusive way. To illustrate, simply consider black-box search heuristics such as Ibs and Abs. Both necessitate that, at the end of a propagation cycle and irrespective of the outcome, variable statistics be updated for every variable involved in the fixpoint (e.g., for Abs search, one must update the activity of the variables that participated in the fixpoint computation). In a traditional kernel, such a support requires the instrumentation of the solver to invoke, at the end of the fixpoint, the code fragment responsible for updating those statistics. An always priority (i.e., priority 0) solves this problem. Indeed, one can simply attach a daemon with every variable and schedule it at priority 0. When the daemon runs at the end of the propagation, it updates the statistics stored in the implementation of Ibs or Abs. Priority 0 can also be useful for implementing visualizations where some redraw must be done regardless of the propagation outcome and are driven by the variables touched during the propagation.\nQueues The microkernel of Objective-CP is responsible for dispatching events arising as a result of the propagation of constraints. To this end, it relies on an array of P queues in which Qi refers to a queue at priority i."}, {"heading": "3.2 The Propagation Engine", "text": "While an OS microkernel is tasked with continuously dispatching messages to the processes it manages, the Objective-CP microkernel only dispatches accumulated messages at specific points during the execution. This section is concerned\nwith the dispatching process alone and it presents the implementation of the propagate method of Figure 5.\nThe Propagation Loop The dispatching algorithm is shown in Figure 6: It processes each non-empty queue in turn from the highest (P ) to the lowest (1) priority. Line 5 finds the index of the highest priority queue with some events. Lines 6\u20139 pick the first highest priority event, dispatch it (line 7) and carry on until p = 0 which indicates that all queues in the 1..P range are empty. Finally, lines 12\u201313 unconditionally execute all the events held in Q0. As is customary, the dispatching of messages may schedule additional events that will be handled during this cycle. Since individual events are represented by closures of the form B : void\u2192 void, dispatching an event is modeled by a simple instruction call(B) that executes closure B.\nHandling Inconsistencies Producing an elegant propagator implementation can be a challenge with modern constraint-programming solvers. Variable updates triggered by a propagator can lead to domain wipe-outs, revealing an inconsistent computation state (aka a failure). Programmers are therefore expected to lace the propagator implementation with failure checks and to abort the propagation when a failure is encountered. Each propagator must also return a suitable status, indicating whether the propagation failed.\nObjective-CP relies on an alternative design and relies on native exceptions to report failures. The block spanning lines 4\u201314 in Figure 6 invokes closures that capture the logic of propagators and can potentially induce failures. It is therefore captured in a closure and passed alongside a second closure (lines 16\u201318) to the utility function tryfail. The semantics of tryfail(b0,b1) is similar to a try-catch block, i.e., it can be understood as the rewriting:\n1 try { 2 b0 3 } catch (FailException* fx) { 4 b1 5 }\nthat executes b0 and transfers control to b1 in case a failure exception is raised.\nExceptions, however, are meant to alter the control flow in rare and exceptional conditions. As a result, the implementation of exceptions, e.g., the libunwind library in C++, induces a negligible overhead when executing try blocks but incurs a more significant cost when throwing and unwinding the stack to catch and handle the exception. Failures in constraint programming are rather frequent however and such an implementation would produce nonnegligible slowdowns.\nTo remedy this potential limitation, Objective-CP implements a low-cost exception mechanism. Function tryfail is not implemented in terms of native exceptions but relies on continuations to achieve the control-flow transfer. Its pseudo-code is shown in Figure 7. The implementation is reentrant and threadsafe. Line 1 declares a thread-local variable pointing to a resume continuation failPoint. tryfail starts by saving, in local storage, the current resumption point in line 4. Line 5 creates a lightweight continuation representing the catch block. If the fresh resume continuation was never called (line 6), this is the equivalent of the try block and lines 7\u201310 execute b0 after installing the catch handler k in thread-local storage failPoint. If b0 succeeds, the previous catch handler is restored in line 9 and executions leaves the tryfail. If an \u201cexception\u201d is raised (via a call to fail shown in lines 16\u201319), the current continuation in failPoint is called and the control flow reaches line 6 again, but this time the number of calls is positive and the block in lines 12\u201313 executes. This final step also restores the previous resume continuation and proceeds with a call to b1. Observe that this implementation does not use the full power of a continuation, merely its ability to alter the control-flow and shrink the system stack. Therefore, it can be implemented in term of the classic C functions setjmp and longjmp for an even lower overhead."}, {"heading": "3.3 Dispatching Events", "text": "This section discusses how to dispatch events for propagation, i.e., how the various closures are inserted in the propagation queues and where they come from. Broadly speaking, the microkernel handles three classes of events:\nClosure Events: These events simply insert a closure in a queue when responding to an event;\nValue Events: These events insert a closure obtained from a first-order function and a value;\nTrigger Events: These events associate closures with values and can dispatch all the closures associated with a specific value.\nFor finite-domain constraint programming, closure events are typically used for constraint-based propagation in the style of AC-3. Value events are typically used for implementing AC-5 style of propagation, e.g., to propagate the fact that a variable has lost a value. Trigger events can be used to implement the concept of watched literals and the \u201cdynamic and backtrack stable triggers\u201d described in Minion [9]. The microkernel provides abstractions representing lists or maps of these events. These are used outside the microkernel for dispatching events as appropriate. Section 4 illustrate their use in the finite-domain service of Objective-CP.\nClosure-Event Lists Closure-Event lists are simply a set of closures and their associated priorities.\nDefinition 1 (Closure-Event List). A closure-event list is a list\nl = (\u3008f0, p0\u3009, \u00b7 \u00b7 \u00b7 , \u3008fk, pk\u3009)\nwhere fi : void\u2192 void is a closure and pi \u2208 0..P \u2212 1 denotes a priority.\nThe CPClosureEvent protocol in Objective-CP is used to represent closureevent lists which are ubiquitous in the implementation: They are used for instance for propagating constraints, in which case the closure invokes method propagate on the constraint. Closure-event lists are dispatched using method\n1 -(void) scheduleClosureEvt: (id<CPClosureEvent >) list;\nwhose specification is given by the following definition.\nDefinition 2 (Closure-Event Scheduling). Given a closure-event list l = (\u3008f0, p0\u3009, \u00b7 \u00b7 \u00b7 , \u3008fk\u22121, pk\u22121\u3009), scheduling l amounts to enqueueing each function in its respective queue, i.e.,\nQpi = enQueue(Qpi , fi) (0 \u2264 i \u2264 k \u2212 1).\nValue-Event Lists Value-Event list contains unary first-order functions used to respond to generic events that are instantiated with specific values. A typical example in finite-domain constraint programming is a propagation event dispatched every time a value is removed from the domain, in which case the first-order function expects the removed value as argument.\nDefinition 3 (Value-Event List). A value-event list is a list l = (f0, \u00b7 \u00b7 \u00b7 , fk) where each entry fi is a first-order function of signature E \u2192 void.\nThe exact nature of the event is captured by the opaque datatype E . Consider, for example, a finite-domain solver over integer variables where the domain of a variable x is a set D(x) = {0, 1, 2, 3, \u00b7 \u00b7 \u00b7 , k \u2212 1} of k distinct integers. In this case, E = Z and, whenever v disappears from D(x), a closure f : int \u2192 void must be executed on value v to relay the loss to the interested propagator. The CPValueEvent protocol of Objective-CP is used to represent value-event lists.\nDispatching a value-event amounts to creating a closure that applies the firstorder function on the arguments. More precisely, value-event lists are dispatched using the method\n1 -(void) scheduleValueEvt: (id<CPValueEvent >) list with:(id)e;\nwhose specification is given by the following definition.\nDefinition 4 (Value-Event Scheduling). Given a value event e \u2208 E and a value-event list l = (f0, \u00b7 \u00b7 \u00b7 , fk) with fi : E \u2192 void, scheduling e amounts to adding the 0-ary closure \u03bb.f(e) into QP , i.e.,\nQP = enQueue(QP , \u03bb.f(e)) 0 \u2264 i \u2264 k \u2212 1\nObserve that \u03bb.f(e) is a closure whose role is to evaluate f(e).4 Clearly, this closure delays the evaluation of function f on e until the event is pulled from the queue and propagated.5. The above definition can easily be extended with priorities although, in general, value-events are not time-consuming and used to perform simple propagation steps and/or to update some internal data structures.\nTrigger-Events Maps Triggers are used in variety of constraint-programming systems (e.g., [30, 9]) and can serve as a basis for implementing generalizations of watched literals in SAT [19]. Objective-CP supports a general form of triggerevents, making them independent of finite-domain constraint programming.\nTo illustrate the type of propagation supported by triggers, consider for instance a constraint\nn\u2211 i=0 bi \u2265 c\n4 It is given in lambda-calculus notation [1] for simplicity. 5 An alternative implementation can easily store in QP objects representing pairs of\nthe form \u3008fi, e\u3009 and delegate to a method of the pair the task to evaluate fi(e) when the pair is dequeued from QP . To a large extent, this is an implementation detail.\nwhere each bi i \u2208 0..n is a boolean variable. The idea is that a propagation algorithm only needs to listen to c + 1 variables which can be a substantial saving when c is much smaller than n. Assume that the propagator is listening to c + 1 variables bk which all satisfy 1 \u2208 D(bk). When such a variable bi loses value 1, the propagator searches for a replacement support bj among the nonwatched variables. If such a support is found, the propagator starts listening to bj instead of to bi. If no such support is found, the c variables that still have 1 in their domains must be equal 1.\nDefinition 5 (Trigger Map). A trigger map\nTm = {vi 7\u2192 {fi,0, . . . , fi,ik} | 1 \u2264 i \u2264 n}\nis a dictionary associating value vi with closures fi,0, . . . , fi,ik (1 \u2264 i \u2264 n). We use Tm(vi) to denote the set {fi,0, . . . , fi,ik}, dom(Tm) the set of values {v1, . . . , vn}, and Tm[w 7\u2192 S] the map Tm where the closures associated with value w are replaced by S.\nThe CPTriggerMap protocol in Figure 8 offers four methods to build and use a trigger map. The add:forValue: registers a response closure for a value, i.e., a call add:f forValue:w updates Tm as follows{\nTm \u222a {w 7\u2192 {f}} if w /\u2208 dom(Tm); Tm[w 7\u2192 {f} \u222a Tm(w)] if w \u2208 dom(Tm).\nIt is worth noting that triggers do not refer to variables and provide a generic capability of the microkernel. Method dispatch: is used to execute the triggers associated with a value.\nDefinition 6 (Trigger-Event Scheduling). Given a trigger map Tm and a value v, scheduling the trigger event for tm and v amounts to enqueuing the closures in Tm(v), i.e.,\nQP\u22121 = enQueue(QP\u22121, f) \u2200f \u2208 Tm(v).\nFinally, the protocol provides two methods for removing and inserting triggers (an opaque protocol) directly. The CPTrigger protocol encapsulates a closure and includes data structure to remove them in constant time. Section 4 illustrates the use of triggers for implementing a propagator for \u2211n i=0 bi \u2265 c."}, {"heading": "3.4 Informers", "text": "In addition to messaging via propagation, the Objective-CP microkernel offers a simple messaging abstraction for thread-aware multicasting through the ORInformer abstract data type. A similar idea was already present in Comet where \u201cevents\u201d were used for decoupling meta-strategies in CBLS [26] supporting parallel search [17, 18] and implementing visualizations [4]. Objective-CP generalizes it further. An ORInformer embodies the idea of the publish-subscribe design pattern [7] and extends it to a concurrent setting. Two protocols are shown in Figure 9 and specify the abstract informer protocol and a concrete informer protocol. Informally speaking, the abstract protocol in lines 1\u20134 provides two methods whenNotifiedDo: and wheneverNotifiedDo: receive two first-order functions to be executed only when (respectively each time) the informer is notified. The facility is convenient to request the execution of an arbitrary piece of code when some notification occurs. The concrete protocol in lines 6\u20138 extends the core capability with a single notification method notifyWith: responsible for relaying its argument to every subscriber. An informer implementation maintains two lists of first-order functions (once and always). When an occurrence is notified via the notification API, the closures are scheduled for execution in the thread that performed the subscription."}, {"heading": "3.5 Microkernels as First-Class Objects", "text": "Microkernels in Objective-CP are first-class objects and can have their own dedicated propagation algorithms by overloading the propagate method. Each microkernel, except the root microkernel, has a parent microkernel that initiates its propagation. All the events presented earlier can be generalized to specify the microkernel in which they must dispatched. Consider, for instance, a closure event of the form \u3008f, p, k\u3009, where k is a microkernel. Dispatching such an event consists of two steps: (1) Scheduling the event, i.e.,\nQkp = enQueue(Q k p, f),\nwhere Qgp denotes the queue of priority p in microkernel k; and (2) Dispatching the propagation of microkernel k, i.e.,\nQukpk = enQueue(Q uk pk , \u03bb.propagate(k))\nwhere pk is the priority of microkernel k and uk is its parent microkernel. Groups [15] can be naturally implemented as microkernels in Objective-CP by overloading method propagate."}, {"heading": "4 A Finite Domain Service", "text": "This section shows how to create a finite-domain solver over integers o top of the microkernel. It reviews some of the core ideas underlying the Objective-CP implementation."}, {"heading": "4.1 Variables", "text": "Definition 7 (Variable). A variable is a tuple \u3008D,m,M,B, I, L, T \u3009 associating a domain representation with five constraint event lists and a trigger map. The event lists m,M,B, I, L are associated with with the constraint events monitoring changes to the minimum m, changes to the maximum M , changes to either bounds B, instantiation I, loss of value L. The trigger map T monitors value losses as well.\nVariables are a key building block for stating constraints and Objective-CP provides (a superset) of the class definition shown in Figure 10. It includes the APIs needed to register different types of events. The dom instance variable is a reference to a suitable domain representation such as a range, a bit-vector, or a list of intervals. Methods such as whenChangeMinDo: and whenLoseValueDo: simply delegate to their respective event lists: Their implementation is as follows:\n1 -(void) whenChangeMinDo :(void ^())f priority :( ORInt)p { 2 [_min insert:f withPriority:p]; 3 } 4 -(void) whenLoseValueDo :(void^(ORInt ))f { 5 [_loss insert:f];\n6 } 7 -(void) whenLoseValue :( ORInt)v trigger :(void ^())f { 8 [_triggers loseTrigger:f forValue:v]; 9 }\nThe methods responsible for domain updates are expected to schedule the proper events. Consider method removeValue:\n1 -(void) removeValue: (ORInt) value { 2 BOOL rMin = value == [_dom min]; 3 BOOL rMax = value == [_dom max]; 4 BOOL changed = [_dom remove:value]; 5 if (changed) { 6 if (rMin) [_engine scheduleClosureEvt:_min]; 7 if (rMax) [_engine scheduleClosureEvt:_max]; 8 if (rMin || rMax) [_engine scheduleClosureEvt:_bounds ]; 9 if ([_dom size] == 1) [_engine scheduleClosureEvt:_bind ];\n10 [_engine scheduleValueEvt: _loss with: value ]; 11 [_engine dispatch: _triggers with: value ]; 12 } 13 }\nThe method performs the domain update but most of its body is devoted to scheduling the relevant events. For instance, if the value removed is the smallest value in the domain, it schedules the events in min. If the domain is now a singleton, line 9 also schedules the events on the bind list. Finally, lines 10- 11 schedule the value events and dispatches the triggers. If the domain update results in a wipe-out, method remove: method on the domain calls the fail method described in Figure 7 to report the failure: There is no need to obfuscate the code of method removeValue: with consistency tests.\nOverall, the variable tracks response behaviors that are suitable for each type of events and schedules the messages with the microkernel whenever an event of that class is recognized. The number and the semantics of the events are solely the variable responsibility and completely orthogonal to the microkernel."}, {"heading": "4.2 Constraints", "text": "This section reviews how to implement constraints using the microkernel functionalities.\nClosure-Based Propagation Consider constraint x = y+c and its implementation in Figure 11 which is exclusively in method post. When posted, the constraint first updates the domains of x and y. It then states (lines 11\u201313) that, whenever the lower or upper bound of x change, the specified closure should be executed. The process is repeated for y to update x. The two closures capture all the names that are in the lexical scope of their definitions. Namely, both closures capture the names x, y, c, and self and refer to them within their implementations. While seemingly innocuous, this capability is essential to pass information to, and share information with, the closures.\nValue-Based Propagation Consider a domain-consistent propagator for the same constraint. Figure 12 showns the bulk of the propagator implementation which\nalso takes place in the post method. Lines 8\u201312 cover the trivial cases where one of the variables is bound: The other variable is simply updated accordingly. Lines 13\u201314 initiate the domain filtering of x and y by tightening their respective bounds. Lines 15\u201320 proceed with two tight loops to discard the images of values that are not in the domains. Lines 22\u201323 setup two closures to respond to value losses in the domains. The implementations take constant time and simply remove the correct image from the domain of the other variable. Lines 24\u201325 are handling the constraint events that arise when a variable is bound.\nThe code is simple thanks to the use of closures which blend references to parameters (e.g., v) and to local and instance variables. The code mimics the inference rules and lexically binds the specifications of events (whenXXX messages sent to variables) with the proper response (the closures passed to the message). Trigger-Based Propagation Consider the linear inequality constraint \u2211n i=0 xi \u2265 c, where each xi is a boolean variable and c is a constant. The key idea behind the implementation is to monitor the loss of the value true from the domains. Triggers are useful to listen to only c+ 1 variables among {b0, \u00b7 \u00b7 \u00b7 , bn}. As soon as a variable loses its true value, the constraint seeks another witness among the variables not listened to. If no such witness can be found, the remaining variables must necessarily be all true.\nFigure 13 provides the class definition for the propagator. The class has a few attributes to track the input array x, its size, the constant c, the array of triggers at as well as the array nt of variables not listened to. Following the original algorithm in [9], the instance variable last tracks the place where the implementation resumes its scanning for another witness.\nFigure 14 shows the entire implementation of the propagator. The constructor in lines 2\u201310 is straightforward. The post method first allocates memory to hold the triggers, the identification of the variables they are listening to, as well as the identifiers of the variables not monitored. Lines 18\u201322 ensure that each\nvariable is boolean and compute the number of variables already bound to true. Lines 23\u201331 deal with the trivial cases when the constraint is obviously true, always false, or just satisfiable if all possible variable are bound to true now. The loop spanning lines 36\u201366 is the core of the implementation. It looks for c+1 variables that still have true in their domains. Each time such a variable is found, a trigger is added to the trigger map and recorded in array at (line 39). Line 38 also remembers that the trigger listens to variable i at this point. Line 66 stores in nt the variables that are not listened to (because they no longer have true in their domains or because c+ 1 variables are already listened to.).\nThe trigger listens to the loss of the true value. If the variable loses this value, the closure in lines 40\u201363) is executed. As usual, each closure captures the local variables in scope and remembers their values at the time of the closure creation. In particular, the variable listen always correctly refers to the right entry in\nat. The closure accomplishes the following tasks. First, it seeks a replacement witness among the variables in nt (lines 42\u2013 48). If such an alternate support is found, the trigger is moved to the new supporting variable (lines 50\u201356). If no such support is found, the remaining c variables with triggers must necessarily be bound to true, which is done by the code in lines 59\u201361.\nConstraint-Based Propagation Many constraints are implemented through two methods: a post method that initializes some data structures and possibly create some events to update them dynamically; and a propagate method that performs the domain reduction based on these data structures. In particular, this is the case of many global constraints. For illustration purposes, Figure 15 depicts a constraint-based propagation of constraint x = y + c. Observe line 10 where the closure simply calls method propagate. This pattern is so frequent that it is encapsulated in methods of the form\n1 -(void) whenChangeMinPropagate: (CPConstraint) c priority: (ORInt) p\nin the API of the variables and the kernel. It is also optimized to avoid redundant calls to propagate.\nFlexibility of the Microkernel It is useful to conclude this section by highlighting the flexibility of the microkernel on a slightly more complicated propagator. Consider the element constraint z = y[x], where x and z are variables and y is an array of variables. Assume, in addition, that the implementation maintains the following data structures:\n\u2013 Ik = D(z)\u2229D(yk): The intersection between the kth entry of array y and z; \u2013 H: A local copy of the domain of variable x; \u2013 sv = |{k \u2208 D(x)|v \u2208 D(yk)}|: The number of supports for value v of z.\nAn implementation enforcing domain consistency may perform the following actions when variable yk loses value k \u2208 H: sv \u2190 sv \u2212 1 Ik \u2190 Ik \\ {v} Ik = \u2205 \u21d2 D(x)\u2190 D(x) \\ {k} sv = 0\u21d2 D(z)\u2190 D(z) \\ {v}.\nFigure 16 describes how to implement these ideas in Objective-CP. All the actions are enclosed in a first-order function that uses both the local variables in scope and the removed value, which is an argument to the first-order function. It is a compact implementation where the event and its response are jointly specified.\nA similar behavior can be achieved in Comet using method valRemoveIdx on line 9 of the AC5Constraint protocol in Figure 1. Method valRemoveIdx was added to the protocol to implement such propagation rule: Indeeed it is necessary to transmit the index k of the variable yk to achieve the desired behavior. Hencem, while no extension to the Objective-CP microkernel were necessary to implement this constraint, the Comet API had to be duplicated to integrate the rather ad-hoc concept of index. Moreover, the Comet code loses the textual proximity between the event and its response."}, {"heading": "4.3 Implementating Black-Box Searches", "text": "This section illustrates how to implement search heuristics using informers. Consider, for instance, Ibs [20]. The heuristic requires that, after a branching decision x = v, the impact of the assignment be evaluated and recorded in a data structure for the heuristic to use during the next variable selection. The impact depends upon the outcome of the propagation. When x = v succeeds, the impact I(x = v) = 1.0 \u2212 S(P k)\nS(Pk\u22121) where S(P ) evaluates an upper-bound on the size of\nthe search space P that uses the product of the domain sizes. Note that P k\u22121 and P k respectively refers to the state before and after enforcing x = v. When x = v fails, the impact is maximal, i.e., I(x = v) = 1.0.\nTo implement this logic, two informers relay the outcome of posting the branching decision. Consider the code in Figure 17. The concrete CP solver holds two informer instances returnLabel and failLabel. The labeling method of the concrete solver uses (line 8) the enforce: method of the microkernel to propagate the effects of x = v. If the outcome is a failure, line 10 notifies the failLabel informer and proceeds by asking the explorer to backtrack on line 11. If x = v succeeds, the control flows to line 13 where the solver notifies the returnLabel informer.\nThe object encaspulating the Ibs implementation can subscribe to both notifications and execute code fragments to compute the actual impact. An abridged version of Ibs is shown in Figure 18. The initInternal method receives the array of variables. Line 5 creates a monitor daemon and attaches it to every variables. This monitor is responsible for computing S(P k)\nS(Pk\u22121) automatically with\nan amount of work linear in the number of variables affected by x = v. Lines 9\u201311 setup a listener on the solver\u2019s retLabel informer. The listening closure computes the actual impact from the search space reduction established by the monitor and updates the impacts dictionary accordingly. Lines 12\u201314 echo the same logic when x = v fails with a listener on the failLabel informer of the solver. The result is a nice modular implementation of IBS."}, {"heading": "5 Empirical Results", "text": "To measure the performance of Objective-CP microkernel, this section compares its behavior (space and time performance) against the COMET 2.1.0 implementation. In particular, it reports on three sets of experiments. First, it considers micro-benchmarks where the bulk of the computation time takes place inside the propagation engine due to a large number of propagation events (prop-\nagators are fast and there is virtually no search). Second, it reports profiling benchmarks obtained from development tools (i.e., dtrace) that measure the cost of each method and functions in the implementation. This sheds some light on the cost of dynamic dispatching. Third, it selects representative application benchmarks featuring a mix of global constraints, arithmetic constraints, reified constraints, and logical constraints. In this case, there is an actual effort expanded in the search, but the benchmarks offer some insights about the cost of the propagation engine when embedded inside a real solver and in realistic conditions."}, {"heading": "5.1 Micro-Benchmarks", "text": "The micro-benchmarks represent the worst situation for the engine as there are many events, each of which propagates quickly. These benchmarks thus indicate the cost of generality and compositionality in the microkernel. Four models were considered:\norder correspond to a pathological model with n variables with a domain 1..n and n \u2212 1 binary constraints of the form xi < xi+1\u2200i \u2208 1..n \u2212 1. Without a dedicated group and a custom scheduler exploiting Berge acyclicity, the propagation engine triggers a quadratic number of propagation events taking constant time. magic/s is the magic series benchmark where each term si is subjected to a counting constraints expressed algebraically as si = \u2211 j\u22081..n(sj = i). There\nare no redundant constraints, the labeling is static, and the model searches for all solutions. magic/r is the magic series again, but with the two traditional redundant constraints and a labeling procedure that considers the variables in a static order and chooses values in decreasing order. slow is a benchmark used in the MiniZinc challenge (slowConvergence and designed to \u201cstress test\u201d propagation engines.\nIn all cases, care was taken to make sure that the number of choices made during the search were identical. Figure 19 offers a quick overview of the comparative performance between the latest version of Comet and Objective-CP. In particular, the curve reports the relative speed difference as\n\u00b5(TComet)\u2212 \u00b5(TObjective-CP) size\nNamely, a positive value indicates that Comet is slower and the time difference is weighted by the benchmark size. Given that the micro-benchmarks are deterministic, only 10 runs are included (to account for speed variation caused by dynamic frequency scaling of the CPU and/or activity of the operating system).\nThe simplest micro-benchmark is order where the propagation of each event runs in constant time and the volume of events grows quadratically with the instance size. The initial, large advantage of Objective-CP over Comet can be attributed to the fact that Objective-CP being compiled while Comet use a Just-In-Time (JIT) compiler. However, as the problem size grows to 8192, the two solvers are in a near tie with a very minimal advantage to ObjectiveCP. It is worth noting that the implementation of variables and domains in Objective-CP relies on dynamic dispatching for the delivery of key messages such as updating the bounds, whereas Comet uses a polymorphic implementation in C++. Benchmark slowConvergence is a slightly refined version of order.\nOne notices the same initial edge of Objective-CP over Comet due to JIT phase. As instance size grows, the advantage returns to Objective-CP. It is important to realize that the model is a collection of many algebraic constraints and most of the runtime is spent building the model which exercises the dynamic dispatching code quite a lot. Since the model creates a quadratic number of constraints, its memory consumption is also a key factor. Note how, for instances of size 2048, the model allocates up to 1.6 gigabytes of memory (Comet uses 2 gigabytes for the same instance). The Objective-CPmodel is shown in Figure 20 for completeness. Benchmark magic-simple creates a large number of reified equalities and auxiliary boolean variables. Instances of size 8..128 were used in the experiment and Objective-CP is almost always faster (with the exception of instance 64). It is worth noting that the Objective-CP implementation uses non-injective views for the reifications [16]. Benchmark magic-redundant has been evaluated for instances of sizes 8..1024. The curve shows the same shape as slowConvergence.\nDetailed numerical results (including the average peak memory consumption) are shown in Tables 1 and 2. Note how the numbers of failures (search effort) are identical in both solvers, and the number of propagation events are identical for order and usually smaller for the other benchmarks. The main reason is the reliance on non-injective views for the reified equalities. The running times are given in seconds and the peak memory usage in kilobytes. Finally, it is worth highligthing that Comet uses a dedicated memory allocator. The allocator relies on block allocation through the mmap APIs, allocates at least 32 megabytes, and uses a grouping strategy based on block sizes. It follows, for instance, that all domains are contiguous in memory which leads to better cache behavior. The current implementation of Objective-CP, on the other hand, relies on malloc directly, which does not exploit the locality just mentioned. Small standard deviations on running times are to be expected since all the benchmarks are deterministic."}, {"heading": "5.2 Profiling Benchmarks", "text": "Table 3 reports the profiling results for the magic-simple benchmark of size 128 with Instruments6. Instruments uses a sampling-based approach to profiling. The run lasted almost 16 seconds with a sample captured every millisecond. Each sample is a snapshot of the runtime stack giving insights into which functions are running and on whose behalf. The report highlights that the function for retrieving the bounds of a variable is responsible for almost half the runtime. The second most expensive call is method propagate of the linear equation propagator which accounts for 34.3%. The third highest is objc gSend, the Objective-C runtime function responsible for implementing dynamic dispatching at 4.5%. The scheduling of closure events follows closely at 3.7%. The next function (an Objective-C closure) is the propagation loop at 1.1%. The remaining lines show increasingly small contributors that include views, updates to the bounds, event notifications to the literals (for the reified views), and the trail-based backtracking logic.\nThe most important message is that dynamic dispatching is a mere 4.5% of the runtime on a benchmark that depends on the propagation engine to relay\n6 Instruments is Apple\u2019s version of the Sun MicroSytem tool DTrace.\nevents and implement views. As expected, the search is virtually invisible from the profile as only 1,011 failures occur.\nTo assess the impact of views, reified equality constraints of the form\nbk \u21d4 x = k\nwere substituted to refied views and the model flattening used the traditional encoding with explicitly reified constraints. Table 4 shows the performance profile for the same instance of magic-simple. Naturally, the number of choices remains the same, but the number of propagation events increases from 4, 650, 800 to 19, 692, 586 for a profiling time of 18 seconds (rather than 16 seconds). The profile shows three new closures created inside the post method of the CPReifyEqualDC constraint: Together they implement the AC-5 protocol for each reification and account for 1.8% + 0.9% + 0.8% = 3.7% of the total execution time while CPDenseTriggerMap is the object devoted to triggers installed on values of variables as in cc(fd). Clearly, using views for reifications does improve the running time, but even with a flood of events, the microkernel performance remains solid."}, {"heading": "5.3 Application Benchmarks", "text": "This section considers some application benchmarks to conclude the experimental study.\nBenchmarks The benchmarks were selected to exercise the engine over a reasonably broad set of constraint types. This paragraph briefly reviews each benchmark and highlights the modeling choices\nGolomb This is an optimization benchmark with a blend of arithmetic and global constraints (i.e., alldifferent). Both solvers enforce domain consistency on the alldifferent constraints. The arithmetic constraints contain a mix of equalities and inequalities of low arity. The size was picked to have a very long running test. Knapsack An optimization benchmark where each knapsack relies on the global constraint. The objective function is simply to maxinimize the profit. Perfect This is a constraint satisfaction benchmark. It uses arithmetic constraints and logical constraints to state the non-overlapping requirements and to demand that the squares cutting through any horizontal (vertical) cut line fit exactly within the container. Its labeling first focuses on the x axis attempting to choose, for each abscissa, a square to pin at that location. It carries on with an identical process over the y axis. PPP This is a constraint satisfaction benchmark. It uses alldifferent, packing, reified and arithmetic constraints to impose all the requirements. The labeling focuses on the earliest periods first and uses a static variable ordering within each period when considering each guest.\nSteel Mill The is an optimization problem where the objective function uses element constraints to aggreggate the losses incurred on each slab and the requirements are expressed with packing, arithmetic and logical constraints. The search scans the slab using the first fail principle and uses a dynamic symmetry breaking for the value labeling to avoid considering more than one unused value.\nSport This a constraint satisfaction problem that uses several global constraint types. It relies on alldifferent, cardinality, and table constraints (all using domain consistency) alongside with static symmetry breaking (ordering the home-away variables for each period and game).\nEach benchmark used a search heuristic whose behavior is identical for both Objective-CP and Comet and was evaluated over a series of 10 runs on both systems. Three sets of benchmarks (knapsack, golomb ruler, perfect square) produce exactly the same dynamic search tree whereas the remaining benchmarks exhibit some differences in the number of choices due to randomization. The objective in selecting the search heuristic was not to get the absolute best-known result for each benchmark but to ensure that both systems were performing the same search (possibly modulo some randomization) in order to focus on the the propagation engine.\nTable 5 reports the results for Objective-CP (left) and Comet (right) on 7 benchmarks: The Golomb ruler (size 13), the optimization version of the knapsack problem (instance 3), the progressive party benchmark (parameters 1,9), the Steel Mill Slab Design problem with symmetry breaking, the perfect square problem, and sport scheduling. For each benchmark, the table reports the average CPU time and wall-clock time, the standard deviation over computing times, the number of choices, and the peak memory consumed (in megabytes).\nRunning Time Figure 21 offers a quick overview of the performance ratio between the two implementations. Each bar is a percentage established as\n\u00b5(TCometcpu )\u2212 \u00b5(TObjective-CPcpu ) \u00b5(TCometcpu ) \u00b7 100.0\nIt shows that the Objective-CP implementation is generally competitive with Comet when comparing running times. A detailed view appears in Table 5. The main conclusion drawn from the results is that, despite its generality, the preliminary status of the implementation, and the reliance on dynamic dispatching within the implementation, the microkernel of Objective-CP is competitive with the polished Comet implementation. The narrow loss on the larger Golomb instances appear to be due to the difference in memory management\nPerformance gain\nstyle. Comet, with its dedicated allocator, clusters all the objects of identical sizes in contiguous regions of virtual memory leading to good cache behavior. Objective-CP currently relies exclusively on malloc and seems to suffer slightly from that choice. The observation was confirmed with DTrace that shows a larger volume of L3 cache misses per time unit.\nMemory Consumption The memory behavior of Objective-CP shows a significant improvement over Comet. This is easily explained as the former is based on a thin object-oriented layer on top of C whereas Comet relies on a compiler and a just-in-time code generation that both add some overhead. Nonetheless, the gains are so significant that they are worth highlighting. Column |P | gives the peak memory consumptions (in megabytes) as reported by malloc for Objective-CP and by the garbage collector library for Comet. The peak usage memory footprint drops by up to a factor of 60 on golomb, at least a factor of 4 on the largest knapsack instance. Overall, Objective-CP exhibits frugal memory needs. Finally, it is worth remembering that the entire implementation adopts the reference counting strategy of the underlying NextStep Foundation libraries rather than a garbage collector."}, {"heading": "6 Conclusion", "text": "This paper presented a microkernel architecture for a new constraint programming solver. The microkernel strives to offer a minimal API which remains domain agnostic and facilitates the construction of any domain-specific engine as a service on top of the microkernel. The paper showed that such a microkernel can be built for constraint programming and provides a small but versatile set of functionalities. Moreover, the resulting microkernel can be implemented to be competitive with state-of-the-art monolithic solvers."}, {"heading": "Acknowledgments", "text": "We would like to express our gratitude to Thibaux Freydy and Peter Stuckey for many interesting discussions. In particular, Thibaux encouraged us to eliminate the explicit handling of failures in propagators. NICTA is funded by the Australian Government as represented by the Department of Broadband, Communications and the Digital Economy and the Australian Research Council through the ICT Centre of Excellence program."}], "references": [{"title": "The Lambda Calculus \u2013 Its Syntax and Semantics, volume 103 of Studies in Logic and the Foundations of Mathematics", "author": ["Hendrik Pieter Barendregt"], "venue": null, "citeRegEx": "1", "shortCiteRegEx": "1", "year": 1984}, {"title": "An Introduction to Prolog III", "author": ["A. Colmerauer"], "venue": "Commun. ACM,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 1990}, {"title": "The Constraint Logic Programming Language CHIP", "author": ["M. Dincbas", "P. Van Hentenryck", "H. Simonis", "A. Aggoun", "T. Graf", "F. Berthier"], "venue": "In Proceedings of the International Conference on Fifth Generation Computer Systems,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 1988}, {"title": "Model-driven visualizations of constraint-based local search. Constraints, 14:294\u2013324", "author": ["Gr\u00e9goire Dooms", "Pascal Hentenryck", "Laurent Michel"], "venue": null, "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2009}, {"title": "Model Combinators for Hybrid Optimization", "author": ["D. Fontaine", "L. Michel", "P. Van Hentenryck"], "venue": "In Proceedings of the 19 International Conference on Principles and Practice of Constraint Programming,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2013}, {"title": "A High Level Language for Solver Independent Model Manipulation and Generation of Hybrid Solvers", "author": ["Daniel Fontaine", "Laurent Michel"], "venue": "editors, CPAIOR,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2012}, {"title": "Design Patterns: Elements of Reusable Object-Oriented Software. Addison-Wesley Professional, 1 edition", "author": ["Erich Gamma", "Richard Helm", "Ralph Johnson", "John Vlissides"], "venue": null, "citeRegEx": "7", "shortCiteRegEx": "7", "year": 1994}, {"title": "Minion: A fast scalable constraint solver", "author": ["Ian P. Gent", "Chris Jefferson", "Ian Miguel"], "venue": "Proceedings of ECAI", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2006}, {"title": "Watched literals for constraint propagation in minion", "author": ["IanP. Gent", "Chris Jefferson", "Ian Miguel"], "venue": "Principles and Practice of Constraint Programming - CP 2006,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2006}, {"title": "The CLP(<) Language and System", "author": ["J. Jaffar", "S. Michaylov", "P.J. Stuckey", "R. Yap"], "venue": "ACM Trans. on Programming Languages and Systems,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 1992}, {"title": "The choco constraint programming solver. In CPAIOR\u201908 Workshop on Open-Source Software for Integer and Contraint Programming (OSSICP\u201908)", "author": ["N. Jussien", "G. Rochart", "X. Lorca"], "venue": "OSSICP,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2008}, {"title": "JaCoP Library User\u2019s Guide", "author": ["K. Kuchcinski", "R. Szymanek"], "venue": "Technical report,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2012}, {"title": "SALSA: A Language for Search Algorithms", "author": ["F. Laburthe", "Y. Caseau"], "venue": "In Fourth International Conference on the Principles and Practice of Constraint Programming (CP\u201998),", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 1998}, {"title": "Domain views for constraint programming. In TRICS13: Techniques foR Implementing Constraint programming", "author": ["L. Michel", "P. Van Hentenryck"], "venue": null, "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2013}, {"title": "Parallel and distributed local search in COMET", "author": ["Laurent Michel", "Andrew See", "Pascal Van Hentenryck"], "venue": "Computers & Operations Research,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2009}, {"title": "Transparent Parallelization of Constraint Programming", "author": ["Laurent Michel", "Andrew See", "Pascal Van Hentenryck"], "venue": "INFORMS Journal on Computing,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2009}, {"title": "Chaff: engineering an efficient sat solver", "author": ["Matthew W. Moskewicz", "Conor F. Madigan", "Ying Zhao", "Lintao Zhang", "Sharad Malik"], "venue": "In Proceedings of the 38th annual Design Automation Conference,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2001}, {"title": "Impact-based search strategies for constraint programming", "author": ["Philippe Refalo"], "venue": "CP, volume 3258 of Lecture Notes in Computer Science,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2004}, {"title": "Gecode, the generic constraint development environment", "author": ["C. Schulte", "al"], "venue": null, "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2009}, {"title": "The Oz Programming Model", "author": ["G. Smolka"], "venue": "Computer Science Today, pages 324\u2013343", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 1995}, {"title": "The OPL Optimization Programming Language", "author": ["P. Van Hentenryck"], "venue": null, "citeRegEx": "24", "shortCiteRegEx": "24", "year": 1999}, {"title": "Constraint-Based Local Search", "author": ["P. Van Hentenryck"], "venue": null, "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2005}, {"title": "Constraint-Based Local Search", "author": ["P. Van Hentenryck", "L. Michel"], "venue": null, "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2005}, {"title": "Nondeterministic Control For Hybrid Search. In Proceedings of the Second International Conference on the Integration of AI and OR Techniques in Constraint Programming for Combinatorial Optimisation Problems (CP-AI-OR\u201904)", "author": ["P. Van Hentenryck", "L. Michel"], "venue": null, "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2005}, {"title": "The Objective-CP Optimization System", "author": ["P. Van Hentenryck", "L. Michel"], "venue": "In 19th International Conference on the Principles and Practice of Constraint Programming", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 2013}, {"title": "Search = continuations + controllers", "author": ["P. Van Hentenryck", "L. Michel"], "venue": "In Proceedings of the 19 International Conference on Principles and Practice of Constraint Programming,", "citeRegEx": "29", "shortCiteRegEx": "29", "year": 2013}, {"title": "The Design, Implementation, and Evaluation of the Constraint Language cc(FD). In Constraint Programming: Basics and Trends", "author": ["P. Van Hentenryck", "V. Saraswat", "Y. Deville"], "venue": null, "citeRegEx": "30", "shortCiteRegEx": "30", "year": 1995}], "referenceMentions": [{"referenceID": 2, "context": "Over the years, the constraint programming community has built and experimented with a variety of system design and implementation Historically, solvers were embedded in logic programming languages, CHIP [3], CLP(R) [11], and Prolog III [2] being prime examples.", "startOffset": 204, "endOffset": 207}, {"referenceID": 9, "context": "Over the years, the constraint programming community has built and experimented with a variety of system design and implementation Historically, solvers were embedded in logic programming languages, CHIP [3], CLP(R) [11], and Prolog III [2] being prime examples.", "startOffset": 216, "endOffset": 220}, {"referenceID": 1, "context": "Over the years, the constraint programming community has built and experimented with a variety of system design and implementation Historically, solvers were embedded in logic programming languages, CHIP [3], CLP(R) [11], and Prolog III [2] being prime examples.", "startOffset": 237, "endOffset": 240}, {"referenceID": 18, "context": "Examples abound starting with Ilog Solver [10], Gecode [22] and Minion [8] for C++ and Choco [12] or JacOP [13] for Java (to name just a few).", "startOffset": 55, "endOffset": 59}, {"referenceID": 7, "context": "Examples abound starting with Ilog Solver [10], Gecode [22] and Minion [8] for C++ and Choco [12] or JacOP [13] for Java (to name just a few).", "startOffset": 71, "endOffset": 74}, {"referenceID": 10, "context": "Examples abound starting with Ilog Solver [10], Gecode [22] and Minion [8] for C++ and Choco [12] or JacOP [13] for Java (to name just a few).", "startOffset": 93, "endOffset": 97}, {"referenceID": 11, "context": "Examples abound starting with Ilog Solver [10], Gecode [22] and Minion [8] for C++ and Choco [12] or JacOP [13] for Java (to name just a few).", "startOffset": 107, "endOffset": 111}, {"referenceID": 19, "context": "The success of algebraic modeling languages in the mathematical programming community as well as the desire to not be constrained by the host language prompted advances in domain-specific languages, a trend examplified by Oz/Mozart [23], Opl [24], Salsa [14], and Comet [25] for instance.", "startOffset": 232, "endOffset": 236}, {"referenceID": 20, "context": "The success of algebraic modeling languages in the mathematical programming community as well as the desire to not be constrained by the host language prompted advances in domain-specific languages, a trend examplified by Oz/Mozart [23], Opl [24], Salsa [14], and Comet [25] for instance.", "startOffset": 242, "endOffset": 246}, {"referenceID": 12, "context": "The success of algebraic modeling languages in the mathematical programming community as well as the desire to not be constrained by the host language prompted advances in domain-specific languages, a trend examplified by Oz/Mozart [23], Opl [24], Salsa [14], and Comet [25] for instance.", "startOffset": 254, "endOffset": 258}, {"referenceID": 21, "context": "The success of algebraic modeling languages in the mathematical programming community as well as the desire to not be constrained by the host language prompted advances in domain-specific languages, a trend examplified by Oz/Mozart [23], Opl [24], Salsa [14], and Comet [25] for instance.", "startOffset": 270, "endOffset": 274}, {"referenceID": 24, "context": "This paper examines a possible alternative to such a design: It describes the microkernel of the Objective-CP [28] system, a new constraint programming system that refines the core mantra to", "startOffset": 110, "endOffset": 114}, {"referenceID": 4, "context": "This factorizes key capabilities that are reusable by multiple solvers and promotes the idea of model combinators described in [5].", "startOffset": 127, "endOffset": 130}, {"referenceID": 25, "context": "The search library [29] makes it possible to specify and execute complex search procedures with minimal effort and delivers competitive performance.", "startOffset": 19, "endOffset": 23}, {"referenceID": 4, "context": "This allows for easy experimentation with different technologies and smooth hybridizations [5, 6].", "startOffset": 91, "endOffset": 97}, {"referenceID": 5, "context": "This allows for easy experimentation with different technologies and smooth hybridizations [5, 6].", "startOffset": 91, "endOffset": 97}, {"referenceID": 23, "context": "Search Search procedures in Objective-CP are specified in terms of high-level nondeterministic constructs, search combinators, and node selection strategies, merging the benefits of search controllers and continuations [27] on the one hand and compositional combinators (e.", "startOffset": 219, "endOffset": 223}, {"referenceID": 8, "context": "Trigger events can be used to implement the concept of watched literals and the \u201cdynamic and backtrack stable triggers\u201d described in Minion [9].", "startOffset": 140, "endOffset": 143}, {"referenceID": 26, "context": ", [30, 9]) and can serve as a basis for implementing generalizations of watched literals in SAT [19].", "startOffset": 2, "endOffset": 9}, {"referenceID": 8, "context": ", [30, 9]) and can serve as a basis for implementing generalizations of watched literals in SAT [19].", "startOffset": 2, "endOffset": 9}, {"referenceID": 16, "context": ", [30, 9]) and can serve as a basis for implementing generalizations of watched literals in SAT [19].", "startOffset": 96, "endOffset": 100}, {"referenceID": 0, "context": "4 It is given in lambda-calculus notation [1] for simplicity.", "startOffset": 42, "endOffset": 45}, {"referenceID": 22, "context": "A similar idea was already present in Comet where \u201cevents\u201d were used for decoupling meta-strategies in CBLS [26] supporting parallel search [17, 18] and implementing visualizations [4].", "startOffset": 108, "endOffset": 112}, {"referenceID": 14, "context": "A similar idea was already present in Comet where \u201cevents\u201d were used for decoupling meta-strategies in CBLS [26] supporting parallel search [17, 18] and implementing visualizations [4].", "startOffset": 140, "endOffset": 148}, {"referenceID": 15, "context": "A similar idea was already present in Comet where \u201cevents\u201d were used for decoupling meta-strategies in CBLS [26] supporting parallel search [17, 18] and implementing visualizations [4].", "startOffset": 140, "endOffset": 148}, {"referenceID": 3, "context": "A similar idea was already present in Comet where \u201cevents\u201d were used for decoupling meta-strategies in CBLS [26] supporting parallel search [17, 18] and implementing visualizations [4].", "startOffset": 181, "endOffset": 184}, {"referenceID": 6, "context": "An ORInformer embodies the idea of the publish-subscribe design pattern [7] and extends it to a concurrent setting.", "startOffset": 72, "endOffset": 75}, {"referenceID": 8, "context": "Following the original algorithm in [9], the instance variable last tracks the place where the implementation resumes its scanning for another witness.", "startOffset": 36, "endOffset": 39}, {"referenceID": 17, "context": "Consider, for instance, Ibs [20].", "startOffset": 28, "endOffset": 32}, {"referenceID": 13, "context": "It is worth noting that the Objective-CP implementation uses non-injective views for the reifications [16].", "startOffset": 102, "endOffset": 106}], "year": 2014, "abstractText": "This paper presents a microkernel architecture for constraint programming organized around a number of small number of core functionalities and minimal interfaces. The architecture contrasts with the monolithic nature of many implementations. Experimental results indicate that the software engineering benefits are not incompatible with", "creator": "TeX"}}}