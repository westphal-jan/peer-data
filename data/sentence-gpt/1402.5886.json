{"id": "1402.5886", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "24-Feb-2014", "title": "Near Optimal Bayesian Active Learning for Decision Making", "abstract": "How should we gather information to make effective decisions? We address Bayesian active learning and experimental design problems, where we sequentially select tests to reduce uncertainty about a set of hypotheses. Instead of minimizing uncertainty per se, we consider a set of overlapping decision regions of these hypotheses. Our goal is to drive uncertainty into a single decision region as quickly as possible.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "histories": [["v1", "Mon, 24 Feb 2014 16:59:21 GMT  (6536kb,D)", "http://arxiv.org/abs/1402.5886v1", "Extended version of work appearing in the International conference on Artificial Intelligence and Statistics (AISTATS) 2014"]], "COMMENTS": "Extended version of work appearing in the International conference on Artificial Intelligence and Statistics (AISTATS) 2014", "reviews": [], "SUBJECTS": "cs.LG cs.AI", "authors": ["shervin javdani", "yuxin chen", "amin karbasi", "reas krause", "j", "rew bagnell", "siddhartha srinivasa"], "accepted": false, "id": "1402.5886"}, "pdf": {"name": "1402.5886.pdf", "metadata": {"source": "META", "title": "Near Optimal Bayesian Active Learning for Decision Making", "authors": ["Shervin Javdani", "Yuxin Chen", "Amin Karbasi", "Andreas Krause", "J. Andrew Bagnell", "Siddhartha Srinivasa"], "emails": [], "sections": [{"heading": null, "text": "How should we gather information to make effective decisions? We address Bayesian active learning and experimental design problems, where we sequentially select tests to reduce uncertainty about a set of hypotheses. Instead ofminimizing uncertainty per se, we consider a set of overlapping decision regions of these hypotheses. Our goal is to drive uncertainty into a single decision region as quickly as possible.\nWe identify necessary and sufficient conditions for correctly identifying a decision region that contains all hypotheses consistent with observations. We develop a novel Hyperedge Cutting (HEC) algorithm for this problem, and prove that is competitive with the intractable optimal policy. Our efficient implementation of the algorithm relies on computing subsets of the complete homogeneous symmetric polynomials. Finally, we demonstrate its effectiveness on two practical applications: approximate comparison-based learning and active localization using a robotmanipulator."}, {"heading": "1 Introduction", "text": "Bayesian active learning addresses the problem of selecting a sequence of experiments, or tests, to determine a hypothesis consistent with observations. This fundamental problem arises in a wide range of applications such as medical procedures, content search, and robotics. It has been studied in several domains, including machine learning (Dasgupta, 2004; Balcan et al., 2006; Nowak, 2009), statistics (LindAppearing in Proceedings of the 17th International Conference on Artificial Intelligence and Statistics (AISTATS) 2014, Reykjavik, Iceland. JMLR: W&CP volume 33. Copyright 2014 by the authors.\nley, 1956; Chaloner and Verdinelli, 1995), decision theory (Howard, 1966), and others.\nFor instance, in automated medical diagnosis (Kononenko, 2001) we are presented with hypotheses about the state of a patient, and select medical tests to infer their illness. In comparison-based learning (Goyal et al., 2008; Karbasi et al., 2012), we infer a target in a database by sequentially presenting a user with pairs of candidates, and having the user select which is closer. In robotic active localization, the robot attempts to identify its own or an object\u2019s location by probing, e.g., with touch or vision (Fox et al., 1998; Kollar and Roy, 2008; Hsiao et al., 2008; Javdani et al., 2013). In general, the goal is to gather the necessary information while minimizing test cost.\nIn this paper, we develop a general framework for addressing these problems. Instead of indiscriminately minimizing uncertainty about hypotheses directly, we aim to reduce uncertainty in a structured way to facilitate decision making. We suppose the hypothesis space is covered by a set of decision regions: Each region identifies the set of hypotheses for which it would succeed. Our goal is to select tests that quickly concentrate all consistent hypotheses in a single decision region.\nSpecial cases of this general problem have been studied. In the so calledOptimal Decision Tree (ODT) problem, each decision region corresponds to a single hypothesis. In this case, a greedy algorithm called Generalized Binary Search (GBS) is known to perform near optimally, i.e., the expected number of observations is O(log n) more than the optimum policy where n indicate the number of hypotheses (Dasgupta, 2004; Guillory and Bilmes, 2009; Kosaraju and Borgstrom, 1999). GBS greedily selects tests in expectation over the test outcomes to maximize the probability mass of eliminated hypotheses. Another special instance of our setting is the Equivalence Class Determination (ECD) problem (Golovin et al., 2010) where the set of hypotheses is (disjointly) partitioned\u2013 that is, decision\nar X\niv :1\n40 2.\n58 86\nv1 [\ncs .L\nG ]\n2 4\nFe b\n20 14\nregions do not overlap and collectively cover the set of hypotheses. In this case, it is known that GBS performs poorly while greedily optimizing a more informative objective known as EC2 exhibits an O(log n) approximation guarantee (Golovin et al., 2010).\nIn both aforementioned settings, decision regions are disjoint. In this paper, we tackle the general case of overlapping decision regions, a problem that is less understood. We develop a novel surrogate objective function, which we call Hyperedge Cutting (HEC), and prove that the policy which greedily maximizes this objective has strong theoretical guarantees. It relies on the fact that our proposed objective function satisfies adaptive submodularity (Golovin and Krause, 2011), a natural diminishing returns property that generalizes the classical notion of submodularity to policies.\nWe empirically evaluate our algorithm on two applications: approximate comparison-based learning (Karbasi et al., 2012), and active localization with a robot hand. In approximate comparison-based learning, a user is searching through set of items (e.g., movies), and is not particularly interested in a single item, but rather any suggestion from a given category (e.g., the horror genre). The search terminates once all items consistent with user responses are contained in a single category. Similarly, many actions in robotic manipulation, such as pushing a button or grasping an object, inherently tolerate some uncertainty. The robot need not know the exact location of an object, but rather must localize an object to a decision region to ensure it can successfully accomplish the task. An optimal policy achieves each of these with the smallest test cost.\nWe make the following contributions:\n1. We provide a necessary and sufficient condition for identifying if a decision region contains all hypotheses that are consistent with the tests performed.\n2. We develop a novel algorithm \u2013 Hyperedge Cutting (HEC) \u2013 and prove that it is competitive with the intractable optimal algorithm.\n3. We provide an efficient way to implement our algorithm based on computing sums of the complete homogeneous symmetric polynomials.\n4. We demonstrate the empirical effectiveness of our approach for both comparison-based learning and active localization in a manipulation task."}, {"heading": "2 Problem Statement", "text": "We formalize our Bayesian active learning problem by assuming a prior probability distribution P on a set of hypothesesH (e.g., state of patient, location of target). By conducting tests from a set of tests T , we gain infor-\nmation about the true, initially unknown hypothesis.\nMore formally, for a given hypothesis h \u2208 H, running a test t \u2208 T produces an outcome (deterministically) from a finite set of outcomes/observations O. Thus, each hypothesis h \u2208 H can be considered a function h : T \u2192 O mapping tests to outcomes. Suppose we have executed a set of tests T = {t1, . . . , tm} \u2286 T (e.g., medical tests we ran, items shown to the user, moves made by the robot), and have observed their outcomes h(t1), . . . , h(tm). Our evidence so far is captured by a set of test-outcome pairs, S \u2286 T \u00d7 O, where S = {(t1, h(t1)), . . . , (tm, h(tm))}.\nUpon observing S, we can rule out hypotheses inconsistent with our observations. We denote the resulting set of hypotheses by\nV(S) = {h \u2208 H : \u2200(t, o) \u2208 S, h(t) = o} (1)\nIn principle, we can now choose tests that reduce our uncertainty about the set of hypotheses directly. In many practical problems, we are primarily concerned about reducing uncertainty for the purpose of making a decision: it is not necessary to remove all uncertainty, but it is necessary to reduce uncertainty in a structured way to ensure a decision action will be successful. Choosing tests that reduce uncertainty dramatically, but still leave it unclear what action to choose, will not be effective. We now formalize this idea.\nActive learning for decision making. Suppose we have a set of decisionsR, and the eventual goal of selecting a decision r \u2208 R after gathering information. For example, in medical diagnosis, we choose a treatment; in robotic manipulation, we press a button (Fig. 5); in content search, we recommend a particular movie.\nEach decision region r corresponds to the set of hypotheses for which it would succeed, i.e., r \u2286 H. Our problem is then captured by a hypergraph, a generalization of a graph in which an edge can connect to any number of nodes. Briefly, a hypergraph G is a pair G = (X,E), where X is a set of elements called nodes, and E is a collection of sets of X called hyperedges. We can specify our problem with a hypergraph, which we refer to as the region hypergraph Gr = (H,R).1\nNote that in general, multiple decisions are equally suitable for a hypothesis: In the robot example, multiple manipulation actions may succeed for an object location (Fig. 5); in movie recommendation, the user may be indifferent among sets of movies. Hence, we allow the decision regions to overlap (Fig. 1(a)). Formally, we also assume that the set of hypotheses is covered by the collection of decision regions, i.e., H = \u222aRr.\n1We illustrate decision regions as circles (e.g., Fig. 1(a)) - however, our method treats regions as arbitrary sets.\nThe ultimate goal is to find a policy \u03c0 for running tests that allows us to determine a decision region r the true hypothesis is guaranteed to lie in. In other words, upon termination we require that V(S) \u2286 r for some r \u2208 R.\nThus, we seek a policy for selecting a minimal number of tests to determine a suitable decision. A policy \u03c0 is a function from a set of evidence so far S, to the next test to choose (or to stop running tests). A policy is feasible if and only if it drives all remaining uncertainty into any single decision region, V(S) \u2286 r. We define the expected cost (i.e., number of tests2) of policy \u03c0 as:\nC(\u03c0) = \u2211 h\u2208H P (h)|T (\u03c0, h)|,\nwhere T (\u03c0, h) is the set of tests policy \u03c0 chooses in case the correct hypothesis is h. Given this, we seek a feasible policy of minimal cost, i.e.,\n\u03c0\u2217 = arg min \u03c0 C(\u03c0) s.t. \u2200h,\u2203r : V(T (\u03c0, h)) \u2286 r (2)\nWe call Problem (2) theDecision Region Determination (DRD) Problem.\nSpecial cases of Problem (2) have been studied before. In particular, the special case where each hypothesis is contained in a dedicated region is called the Optimal Decision Tree (ODT) problem (Kosaraju and Borgstrom, 1999). More generally, the special case where the regions partition the hypothesis space (i.e., do not overlap), is called the Equivalence Class Determination (ECD) Problem (Golovin et al., 2010). For both of these special cases, it is known that finding a policy \u03c0 for which C(\u03c0) \u2264 C(\u03c0\u2217)o(log n) is NP-hard (Chakaravarthy et al., 2007). Here, \u03c0\u2217 indicates the optimum policy. To the best of our knowledge, there are no efficient algorithms with theoretical approximation guarantees for the general DRD problem. In the following, we present such an algorithm.\n2Note that while we focus on tests with unit cost, our results generalize to tests with non-uniform costs.\n3 The HEC Algorithm\nWe now introduce and analyze our algorithm \u2013 the Hyperedge Cutting (HEC) approach."}, {"heading": "3.1 Overview", "text": "Our key strategy is to transform the DRD Problem (2) into an alternative representation \u2013 a different hypergraph for splitting decision regions. Observing certain test outcomes corresponds to downweighting or cutting hyperedges in this hypergraph. The construction is chosen so that cutting all hyperedges is a necessary and sufficient condition for driving all uncertainty into a single decision region. We then prove that a simple greedy algorithm, which chooses tests that reduce hyperedge weight maximally (in expectation), implements a policy that is competitive with the optimal (intractable) policy for Problem (2). In Sec. 4, we show how this greedy algorithm can be efficiently implemented."}, {"heading": "3.2 Splitting hypergraph construction", "text": "We construct a different hypergraph, the splitting hypergraph Gs, and define our objective on that. Here, our hyperedges are not sets, butmultisets, a generalization of sets where members are allowed to appear more than once. As a result, a node can potentially appear in a hyperedge multiple times. The cardinality of a hyperedge refers to how many nodes it is connected to.\nWe observe that for solving the DRD problem, we can group together all hypotheses that share the same region assignments. We refer to this grouping as a subregion g, and the set of all subregions as G. More formally, for any pair hk \u2208 gi and hl \u2208 gi, we have hk \u2208 rj if and only if hl \u2208 rj . In a slight abuse of notation, we say that a subregion is contained in a region, g \u2208 r, if \u2200h \u2208 g, h \u2208 r (Fig. 1(b)). Similarly, we say that h \u2208 e if \u2203g \u2208 e s.t. h \u2208 g. It is easy to see that\nall remaining hypotheses V(S) are contained in r if and only if all remaining subregions are contained in r.\nWe construct the splitting hypergraph Gs over these subregions. Each subregion g \u2208 G corresponds to a node. The hyperedges e \u2208 E consist of all multisets of precisely k subregions, e = {g1, . . . , gk}, such that a single decision region does not contain them all (we will describe how k is selected momentarily). Note that hyperedges can contain the same subregion multiple times. Formally,\nE = {e : |e| = k \u2227 @ r s.t. \u2200h \u2208 e, h \u2208 r}. (3)\nOur splitting hypergraph is defined as Gs = (G, E). Fig. 1(b) illustrates the splitting hypergraph obtained from the DRD instance of Fig. 1(a).\nHyperedge Cardinality k. Key to attaining our results is the proper selection of hyperedge cardinality k. If k is too small, our results won\u2019t hold, and our algorithm won\u2019t solve the DRD problem. If k is too large, we waste computational effort, and our theoretical bounds loosen. Here, we define the cardinality we use practically. Our theorems hold for a smaller, more difficult to compute k as well. SeeAppendix for details.\nk = min ( max h\u2208H |{r :h \u2208 r}|,max r\u2208R |{g :g \u2208 r}| ) + 1 (4)\nNote that each term is a property of the original region hypergraph Gr defined in Sec. 2: maxh |{r : h \u2208 r}| is the maximum degree of any node, and maxr |{g :g \u2208 r}| bounds the maximum cardinality of hyperedges inGr.3\n3.3 Relating DRD and HEC\nHow does the hypergraph capture our progress towards solving Problem (2)? Observing a set of test-outcomes S \u2286 T \u00d7O eliminates inconsistent hypotheses, and consequently downweights or eliminates (\u201ccuts\u201d) incident hyperedges (Fig. 1(c)). Analogous to the definition of V(S) in (5), we define the set of hyperedges consistent with S by\nE(S) = {e \u2208 E : \u2200(i, o) \u2208 S \u2200h \u2208 e, h(i) = o} (5)\nThe following result guarantees that cutting all hyperedges is a necessary and sufficient condition for success, i.e., driving all uncertainty into a single decision region. Theorem 1. Suppose we construct a splitting hypergraph by drawing hyperedges of cardinality k according to (3). Let S \u2286 T \u00d7 O be a set of evidence. All consistent hypotheses lie in some decision region if and only if all hyperedges are cut, i.e.,\nE(S) = \u2205 \u21d4 \u2203r : V(S) \u2286 r 3It is precisely the maximum cardinality of any hyperedge if we grouped hypotheses into subregions in Gr.\nThus, the DRD Problem (2) is equivalent to finding a policy of minimum cost that cuts all hyperedges. This insight suggests a natural algorithm: select tests that cut as many edges as possible (in expectation). In the following, we formalize this approach.\n3.4 The Hyperedge Cutting (HEC) Algorithm\nGiven the above construction, we define a suitable objective function whose maximization will ensure that we pick tests to remove hyperedges quickly, thus providing us with an algorithm that identifies a correct decision region. First, we define the weight of a subregion as the sum of hypothesis weights, p(g) = \u2211 h\u2208g p(h). We define the weight of a hyperedge\ne = {g1, . . . , gk} as w(e) = \u220fk i=1 P (gi). More generally, we define the weight of a collection of hyperedges as w({e1, . . . , en}) = \u2211n l=1 w(el). Now, given a pair of test/observation (t, o), we can identify the set of inconsistent hypotheses, which in turn implies the set of hyperedges that should be downweighted or removed. Formally, given a set of test/observation pairs S \u2286 T \u00d7O, we define its utility fHEC(S) as\nfHEC(S) = w(E)\u2212 w(E(S)). (6)\nThus fHEC(S) is the total mass of all the edges cut via observing set S.\nA natural approach to the DRD Problem is thus to seek policies that maximize (6) as quickly as possible. Arguably the simplest approach is a greedy approach that iteratively chooses the test that increases (6) as much as possible, in expectation over test outcomes.\nFormally, we define the expected marginal gain of a test t given evidence S \u2286 T \u00d7O as follows:\n\u2206(t |S)= \u2211 h P (h |S) ( fHEC(S\u222a{(t, h(t))})\u2212fHEC(S) ) Thus, \u2206(t |S) quantifies, for test t, the expected reduction in hyperedge mass upon observing the outcome of the test. Hereby, the expectation is taken w.r.t. the distribution over hypotheses conditioned on our evidence so far. It is apparent that all hyperedges are cut if and only if \u2206(t |S) = 0 for all tests t \u2208 T . Given this, our HEC Algorithm simply starts with S = \u2205. It then proceeds in an iterative manner, greedily selecting the test t\u2217 that maximizes the expected marginal benefit, t\u2217 = arg maxt \u2206(t | S), observes the outcome h(t\u2217) and adds the pair (t\u2217, h(t\u2217)) to S. It stops as soon as all edges are cut (i.e., the marginal gain of all tests is 0)."}, {"heading": "3.5 Theoretical Analysis", "text": "The key insight behind our analysis is that the marginal gain \u2206(t | S) satisfies two properties: adaptive monotonicity and adaptive submodularity, introduced by\nGolovin and Krause (2011) and associated with certain sequential decision problems. Formally, adaptive monotonicity simply states that the benefit of each test is nonnegative, \u2206(t | S) \u2265 0 for all tests t \u2208 T and evidence S \u2286 T \u00d7 O. This is straightforward, since carrying out a test can never introduce hyperedges, but only remove them. The second, slightly more subtle property \u2013 adaptive submodularity \u2013 states that the marginal gain of any fixed test t \u2208 T can never increase as we gain additional evidence. Formally, whenever S \u2286 S \u2032 \u2286 T \u00d7O, it must hold that\u2206(t | S) \u2265 \u2206(t | S \u2032). Those properties are formally established for our fHEC objective and the associated marginal gain \u2206 in the following Theorem: Theorem 2. The objective function fHEC defined in (6) is adaptive submodular and strongly adaptive monotone.\nWhy are these properties useful? Golovin and Krause (2011) prove that for sequential decision problems satisfying adaptive monotonicity and adaptive submodularity, greedy policies are competitive with the optimal policy. In particular, as a consequence of Theorem 2 and Theorem 5.8 of Golovin and Krause (2011), we obtain the following result for our HEC Algorithm: Theorem 3. Assume that the prior probability distribution P on the set of hypotheses is rational. Then, the performance of \u03c0HEC is bounded as follows\nC(\u03c0HEC) \u2264 (k ln(1/pmin) + 1)C(\u03c0\u2217),\nwhere pmin = minh\u2208H P (h).\nFor the special case of disjoint regions (i.e., the ECD Problem, corresponding to k = 2), our objective fHEC is equivalent to the objective function proposed by Golovin et al. (2010), and hence our Theorem 3 strictly generalizes their result. Furthermore, in the special case where each test can have at most two outcomes, and we set k = 1, the HEC Algorithm is equivalent to the Generalized Binary Search algorithm for the ODT problem, and recovers its approximation guarantee."}, {"heading": "4 Efficient Implementation", "text": "Our HEC algorithm computes \u2206(t |S) for every test in T , and greedily selects one at each time step. Naively computing this quantity involves constructing the splitting hypergraphGs for every possible observation, and summing the edge weights. This is computationally expensive, as constructing the graph requires enumerating every multiset of order k and checking if any region contains them all, resulting in a runtime of O(|G|k). We can, however, quickly prune checks and iteratively consider multisets of growing cardinality during our computation by utilizing the following fact:\nAlgorithm 1 Hyperedge Weight procedure Hyperedge Weight(H, k)\nCompute subregions G from H W \u2190 CHPk(G) Initialize queue Q1 with every subregion g \u2208 G for all k\u0302 \u2264 k do\nfor all \u03b6k\u0302 \u2208 Qk\u0302 do if \u2203r s.t. \u2200h \u2208 \u03b6k\u0302, h \u2208 r then\nW \u2190W \u2212 \u220f g\u2208\u03b6\nk\u0302 p(g)CHPk\u2212k\u0302(\u03b6k\u0302)\nAdd all supersets of \u03b6k\u0302 to Qk\u0302+1 return W\nProposition 1. A set of subregions G shares a region only if all subsets G\u2032 \u2282 G also share that region."}, {"heading": "4.1 Utilizing Complete Homogeneous Symmetric Polynomials", "text": "Our general strategy will be to compute the sum of weights over all multisets of cardinality k, and subtract those that correspond to a shared region. To do so efficiently, we identify algebraic structure in computing a sum of multisets, where a multiset corresponds to a product. Namely, it is equivalent to computing a complete homogeneous symmetric polynomial.\nFor any G \u2286 G and cardinality k\u0302, we define Gk\u0302(G) as all multisets over groups G of cardinality k\u0302. Unlike hyperedges, these multisets can share a region. Formally\nGk\u0302(G) = { {g1, . . . , gk\u0302} \u2286 G } Recall that w(Gk\u0302(G)) = \u2211 G k\u0302 (G) \u220f g P (g). Computing w(Gk\u0302(G)) can be performed efficiently as this quantity is exactly equivalent to the complete homogeneous symmetric polynomial (CHP) of degree k\u0302 over G. We will briefly review a well known variant of the Newton-Girard formulae which will make an efficient algorithm for computing w(Gk\u0302(G)) clear.\nDefine any set of variables x = {x1, \u00b7 \u00b7 \u00b7 , xn}. PSi(x) = \u2211 x\u2208x xi\nCHPi(x) = \u2211\nl1+...ln=i;lj\u22650 \u220f xj\u2208x x lj j\nHere PSi is the i-th power sum, and CHPi is the i-th complete homogeneous symmetric polynomial.\nWe have the identity (Macdonald, 1998; Seroul, 2000):\nCHPi(x) = 1\ni i\u2211 j=1 CHPi\u2212j(x)PSj(x)\nThus, we iteratively computeCHP1(G). . .CHPk\u0302(G) to computew(Gk\u0302(G)) = CHPk\u0302(G)with runtimeO(k\u0302|G|).\nWe now turn our attention to efficiently computing the weight of all multisets that correspond to subregions encapsulated by a region. Let \u03b6 be a set (not multiset) of subregions that shares a region. Formally:\n\u03b6 = {g1 . . . gk\u0302} k\u0302 \u2264 k, @r s.t. \u03b6 \u2286 r\nWe compute the term corresponding to \u03b6 we want to subtract from CHPk(G) when \u03b6 shares a region . To avoid double counting, we want the polynomial to include \u220f g\u2208\u03b6 p(g) as a factor, i.e. if we think of a hyperedge as a product, we force one link to each element of \u03b6.\nw(\u03b6) = \u220f g\u2208\u03b6 p(g) \u2211\nl1+...lk\u0302=k\u2212k\u0302;li>0\np(g1) l1 . . . p(g k\u0302 )lk\u0302\n= \u220f g\u2208\u03b6 p(g)CHPk\u2212k\u0302(\u03b6)\nUsing this, we computew(E) = CHPk(G)\u2212 \u2211\n\u03b6\u2286G w(\u03b6) by finding every set \u03b6 \u2286 G that shares a region. Furthermore, we can utilize Proposition 1 to prune sets, and only consider \u03b6k\u0302+1 which are supersets of any \u03b6k\u0302. The algorithm is detailed in Alg. 1, and depicted in Fig. 2.\nAdditionally, we note that region assignments do not change as observations are received. In practice, we find all sets of subregions that share a region once. At each time step, we need only sum over the terms corresponding to remaining hypotheses.\nNote that in the worst case, this algorithm still has complexity O(|G|k). This occurs when many, at least k, subregions share a single region. The complexity is then controlled by how many distinct subregions a single region can be shattered into, and the largest number of regions a single hypothesis can belong to. However, for many practical problems, wemight expect many regions to be separated, e.g., when |R| k. In this case, Alg. 1 will be significantly more efficient.\nFinally, we note that we can utilize an accelerated adaptive greedy algorithm applicable to all adaptive\nsubmodular functions, which directly uses the diminishing returns property to skip reevaluation of actions (Golovin and Krause, 2011)."}, {"heading": "5 Experiments", "text": "In this section, we empirically evaluateHEC on the two applications - approximate comparison-based learning and touch based localization with a robotic end effector.\nWe compare HEC with five baselines. The first two are variants of algorithms for the specialized versions of the DRD problem described earlier - generalized binary search (Nowak, 2009) and equivalence class edge cutting (Golovin et al., 2010). For generalized binary search (GBS), we assign each hypothesis to its own decision region, and runHEC on this hypothesis-region assignment until only one hypothesis remains. To apply equivalence class edge cutting (EC2), decision regions must be disjoint. Thus, we randomly assign each hypothesis to one of the decision regions that it belongs to, and run EC2 until only one of these new regions remains. For each of these, we also run a slightly modified version, termed GBS-HEC and EC2-HEC respectively, which selects tests based on these algorithms, but terminates once all hypotheses are contained in one decision region in the original DRD problem (i.e. when the HEC termination condition is met).\nThe last baseline is a classic heuristic from decision theory: myopic value of information (VoI) (Howard, 1966). We define a utility function U(h, r) which is 1 if h \u2208 r and 0 otherwise. The utility of V(S) corresponds to the maximimum expected utility of any decision region, i.e. the expected utility if we made a decision now. VoI greedily chooses the test that maximizes (in expectation over observations) the gain in this utility. Note that if we could solve the intractable problem of nonmyopically optimizing VoI (i.e., look ahead arbitrarily to consider outcomes of sequences of tests),\nwe could solve the DRD problem optimally. In some sense, HEC can be viewed as a surrogate function for nonmyopic value of information."}, {"heading": "5.1 Approximate comparison-based learning", "text": "We evaluate HEC on the MovieLens 100k4 dataset, which consists of 1 to 5 ratings of 1682 movies from 943 users. We partition movies into decision regions using these ratings, with the goal of recommending any movie in a decision region. In order to get a similarity measurement between movies, we map them into a 10-dimensional feature space by computing a low-rank approximation of the user/rating matrix through SVD. We then use k-means to partition the set of movies into |R| (non-overlapping) clusters, corresponding to decision regions. Each movie is then assigned to the \u03b1 closest cluster centroids. See Fig. 4 for an illustration. A test corresponds to comparing two movies, an observation to selecting one of the two, and consist hypotheses are those which are closer to the selectedmovie (euclidean distance in 10-dimensional feature space).\nEach experiment corresponds to sampling one movie as the \u201ctrue\u201d movie. As the number of regions increases, the size of each decision region shrinks. The size of a decision region determines how close our solution is to this (exact) target hypothesis. As a result, the problem requires the selected movie be closer to the true target, at the expense of increased query complexity. Fig. 3(a) shows the query complexity of different algorithms as a function of the number of regions, with the cardinality of the HEC hypergraph fixed to k = 3 (i.e., each hypothesis belongs to two decision regions). An extreme case is when there are only two regions and all hypotheses belong to both regions, giving a query complexity of 0. Other than that, we see that HEC performs consistently better than other methods (e.g., to identify the true region out of 8 regions, it takes on average 6.7 queries forHEC, as opposed to 8 queries for EC2-HEC, 8.5 queries for GBS-HEC, and 10.3 queries for VoI).\nTo see how the cardinality and region overlap influence performance, we compare the query complexity of different algorithms by varying the number of regions each hypothesis is assigned to. If we assignmore regions to a hypothesis, then the search result is allowed to be further away from the true target, and thus the number of queries required for approximated search should be smaller. Fig. 3(b) demonstrates such an effect. We fix the number of clusters to 12, and vary the number of assigned regions (and thus the hyperedge cardinality) from 1 to 4 (k from 2 to 5, respectively). We see that higher cardinality enables HEC to saves more queries. For k = 5, it takes HEC 5.3 queries to identify a movie,\n4http://www.grouplens.org/datasets/movielens/\nwhereas VoI, GBS-HEC, and EC2-HEC took 8.8, 7.4, and 6.4 queries, respectively. Additionally, Table 5.1 shows the running time of HEC for these instances. We see that the accelerated implementation described in Sec. 4 enablesHEC to run efficiently with reasonable hyperedge cardinality on this data set."}, {"heading": "5.2 Touch Based localization", "text": "We evaluate HEC on a simple robotic manipulation example. Our task is to push a button with the finger of a robotic end effector. Given a distribution over object location, we generate a set of decisions, corresponding to the end effector going to a particular pose and moving forward in a straight line. Each of these decisions will succeed on a subset of hypotheses, corresponding to a decision region. Decision regions may overlap, as a button can be pushed with many decision actions. See Fig. 5.\nAll hypotheses are not contained in a single decision region, so we perform tests to reduce uncertainty. These tests correspond to guarded moves (Will andGrossman, 1975), where the end effector moves along a path until contact is sensed. After sensing contact, hypotheses are updatedby eliminating object locationswhich could not have produced contact, e.g., if they are far away. Our goal is to find the shortest sequence of tests such that after performing them, there is a single button-push decision that would succeed for all remaining hypotheses.\nGiven some object location Xs, we generate an initial set of 2000 hypotheses H by sampling from N(\u00b5,\u03a3) with \u00b5 = Xs, and \u03a3 a diagonal matrix with \u03a3xx = \u03a3yy = \u03a3zz = 0.04. The robot generates 50\ndecision regions by picking different locations and simulating the end effector forward, and noting which object poses it would succeed on. Hypotheses range from being in zero decision regions to 6, giving us a cardinality k = 7. For tests, the robot generates 150 guardedmoves by sampling a random start location and orientation.\nWe conduct experiments on 10 random environments, and randomly sample 100 hypotheses to be the \u201ctrue\u201d object location (for producing observations during execution), for a total of 1000 experiments. Fig. 3(c) shows the query complexity of different algorithms averaged over these instances. We see that HEC performs well, outperforming GBS, GBS-HEC, EC2, and EC2-HEC handily. Note that myopic VoI performs essentially the same as HEC on these experiments. This is likely due to the short horizon, where 2-3 actions were usually sufficient for reducing uncertainty to a single decision region. We would expect that for longer horizons, myopic VoI would not perform as well."}, {"heading": "6 Conclusions", "text": "In this paper, we have addressed the problem of active learning in order to facilitate decision making. We defined the Decision Region Determination (DRD) problem, requiring that at the end of information gathering, all remaining hypotheses are confined within a single\ndecision region (i.e., do not require further distinction from a decision making point of view). To address this problem, we proposed an equivalent representation in terms of a hypergraph. We prove that eliminating all edges in this hypergraph is a necessary and sufficient condition for success, suggesting a natural objective function. We show that this objective satisfies adaptivemonotonicity and adaptive submodularity. This insight enabled us to prove that a greedy policy for removing hyperedges (HEC) has an approximation guarantee compared to the optimal policy. Finally, we note that at each iteration, we compute a particular polynomial, and can utilize a faster algorithm through efficient computations of complete homogeneous symmetric polynomials.\nWhile our algorithm enables us to tackle problems of reasonable size, our computation is still exponential in hyperedge cardinality k. Additionally, our current scheme assumes noise-free observations, where a hypothesis deterministicallymaps a test to an observation. We hope to alleviate these limitations in future work."}, {"heading": "Acknowledgements", "text": "This work was supported in part by the Intel Embedded Computing ISTC, NSF Grant No. 0946825, NSF-IIS1227495, DARPA MSEE FA8650-11-1-7156, ERC StG 307036, and a Microsoft Research Faculty Fellowship."}, {"heading": "7 Appendix", "text": "In this section, we provide proofs for theorems stated throughout the paper."}, {"heading": "7.1 k for bounds", "text": "We start by showing that for a properly defined k, the DRD problem is solved (V(S) \u2286 r) if and only if the HEC objective is maximized. However, we sometimes require a slightly greater k to ensure the objective fHEC is adaptive submodular. We define these below.\nLet R be a set of regions, the length of which is related to k. To get equivalence of the DRD and HEC, we require that for every region in R, there is some hypothesis in all but one region of R.\nRiff = arg max R\n|R| s.t. \u2200r \u2208 R,\u2203h : h /\u2208 r, h \u2208 R\\r\nkiff = |Riff|\nSometimes, this is not sufficient for adaptive submodularity. For this, we also require that there is some hypothesis in every region of R, and we also add one to the length of R.\nRas = arg max R\n|R| s.t. 1 \u2203h\u0303 \u2208 R 2 \u2200r \u2208 R,\u2203h : h /\u2208 r, h \u2208 R\\r\nkas = |Ras|+ 1\nBefore moving on, we prove that kas \u2265 kiff. Proposition 2. kas \u2265 kiff\nProof. There are two cases:\n1. \u2203h \u2208 Riff. In this case, Ras = Riff and kas = |Ras|+ 1 = kiff + 1.\n2. 6 \u2203h \u2208 Riff. Define R\u0303 = Riff \\ r for some r \u2208 Riff. We know by definition of Riff that \u2203h \u2208 R\u0303. Additionally, we know by definition of kiff that \u2200r \u2208 R\u0303,\u2203h, h /\u2208 r, h \u2208 Riff \\ r, so it follows that h \u2208 R\u0303 \\ r. Therefore, we know R\u0303 satisfies the constraints for Ras, and kas \u2265 |R\u0303|+ 1 = |Riff| = kiff.\nOur algorithm actually utilizes k = min (\nmax h\u2208H |{r : h \u2208 r}|,max r\u2208R |{g : g \u2208 r}|\n) + 1. We briefly show that each of\nthese also upper bound kas.\nProposition 3. maxh\u2208H |{r : h \u2208 r}|+ 1 \u2265 kas\nProof. Note that condition 1 in Ras bounds |Ras| by maxh\u2208H |{r : h \u2208 r}|. The result follows.\nProposition 4. maxr\u2208R |{g : g \u2208 r}|+ 1 \u2265 kas\nProof. Let r be an element of Ras. By definition, it is required that at least |Ras| different subregions g1 \u00b7 \u00b7 \u00b7 g|Ras| be in that region - one which is in every other region in Ras to satisfy condition 1 , and |Ras| \u2212 1 which are in all but one of the Ras \u2212 1 other regions to satisfy condition 2 . The result follows. Thus, we can utilize k = min (\nmax h\u2208H |{r : h \u2208 r}|,max r\u2208R |{g : g \u2208 r}|\n) + 1 and apply the proofs using cardinality at\nleast kas and kiff. While our bounds and algorithm are better if we knew the correct kas to use, finding that value is itself hard to compute - thus, our implementation uses the value defined in Sec. 3 and copied above.\n7.2 Theorem 1: Equivalence of DRD and HEC\nProof. We first prove that if all h are contained in one region, then all edges are cut, i.e. \u2203r : V(S) \u2286 r \u21d2 E(S) = \u2205. This is by construction, since a hyperedge e \u2208 E(S) is only between subregions (or hypotheses) that do not share any regions. More concretely, our definition of e requires 6 \u2203r s.t. \u2200h \u2208 e : h \u2208 r. Since all remaining nodes V(S) \u2286 r, there will be no such such set of hypotheses.\nNext, we prove that if all edges are removed, then all h are contained in one region, i.e., E(S) = \u2205 \u21d2 \u2203r : V(S) \u2286 r. Clearly, if we set |V(S)| \u2264 k, this condition would be met - E(S) would check every subset of V(S) to see if they shared a region, and would draw a hyperedge i.f.f. they do not. To complete the proof, we will make use of the following lemma:\nLemma 1. Define \u03b2 as some constant s.t. \u03b2 \u2265 k. \u2200H \u2286 H, |H| = \u03b2,\u2203r : H \u2286 r \u21d2 \u2200{H\u222ah} \u2286 H,\u2203r : {H\u222ah} \u2208 r\nProof. For the sake of contradiction, suppose @r : {H \u222a h} \u2208 r. This must mean h 6\u2208 H. Let {H \u222a h} = {h1, h2, . . . , h\u03b2+1}. Let Hi be the subset of {H \u222a h} which does not include the ith h from {H \u222a h}, i.e. Hi = {h1 . . . , hi\u22121, hi+1, . . . h\u03b2+1}. By assumption, we know \u2203r : Hi \u2208 r. Let ri be that region for Hi. If ri = rj , for any i, j, this would imply {Hi \u222a Hj} = {H \u222a h} \u2208 ri. Thus, each ri must be unique if 6 \u2203r : {H \u222a h} \u2208 r. Furthermore, this implies hi 6\u2208 ri, and h \u2208 rj ,\u2200j 6= i. Let R\u03b2+1 = {r1 . . . r\u03b2+1}. By definition of \u03b2, we know \u03b2 \u2265 k \u2265 kiff . But this causes a contradiction - by definition of kiff , the maximum set of regions R where hi 6\u2208 ri, hi \u2208 rj\u2200j 6= i is kiff. But R\u03b2+1 would require such a set of regions where |R\u03b2+1| = \u03b2 + 1 \u2265 kiff + 1. Thus, we have a contradiction, and have shown \u2203r : {H \u222a h} \u2208 r.\nBy construction, we know that if E(S) = \u2205 \u21d2 \u2200H \u2286 H, |H| \u2264 k, \u2203r : H \u2286 r. Applying Lemma 1 inductively, this implies, \u2200{H \u222a h1} \u2286 V(S),\u2203r : {H \u222a h1} \u2286 r \u21d2 \u2200{H \u222a h1 \u222a h2} \u2286 V(S),\u2203r : {H \u222a h1 \u222a h2} \u2286 r \u21d2 \u00b7 \u00b7 \u00b7 \u21d2 \u2203r : V(S) \u2286 r."}, {"heading": "7.3 Theorem 2: strong adaptive monotonicity and adaptive submodularity", "text": "Proof. We start with showing our formulation is strongly adaptive monotone.\nLemma 2. The function fHEC described above is strongly adaptive monotone, i.e.\nfHEC(S \u222a {(t, h(t))})\u2212 fHEC(S) \u2265 0 \u2200t, h\nProof. This states that our utility function must always increase as we take additional actions and receive observations. Intuitively, we can see that additional action observation pairs can only cut edges, and thus our utility function always increases. More concretely:\nfHEC(S \u222a {(t, h(t))})\u2212 fHEC(S) = ( w(E)\u2212 w(E(S \u222a {(t, h(t))})) ) \u2212 ( w(E)\u2212 w(E(S)) ) = w(E(S))\u2212 w(E(S \u222a {(t, h(t))}))\n= w({e \u2208 E : \u2200(i, o) \u2208 S \u2200h\u0303 \u2208 e, h\u0303(i) = o})\n\u2212 w({e \u2208 E : \u2200(i, o) \u2208 S \u2200h\u0303 \u2208 e, h\u0303(i) = o, h\u0303(t) = h(t)}) by definition of E(S)\n= w({e \u2208 E : \u2200(i, o) \u2208 S \u2200h\u0303 \u2208 e, h\u0303(i) = o, h\u0303(t) 6= h(t)}) \u2265 0 since w(e) \u2265 0 \u2200e\nNext, we prove that our formulation is adaptive submodular:\nLemma 3. The function fHEC described above is adaptive submodular for any prior with rational values, i.e. for S \u2286 S\u0302 \u2286 T \u00d7O\n\u2206(t |S) \u2265 \u2206(t | S\u0302) \u2200t \u2208 T \\ST\nwhere ST are the set of tests in S.\nProof. This states that our expected utility for a fixed action t decreases as we take additional actions and receive observations. We rewrite our expected marginal utility in a more convenient form:\n\u2206(t |S) = \u2211 h P (h |S) ( fHEC(S \u222a {(t, h(t))})\u2212 fHEC(S) ) = \u2211 h P (h |S) ( [w(E)\u2212 w(E(S \u222a {(t, h(t))}))]\u2212 [w(E)\u2212 w(E(S))] )\n= \u2211 h P (h |S) ( w(E(S))\u2212 w(E(S \u222a {(t, h(t))})) )\nFor convenience, we define noi to be the total probability mass in gi consistent with all evidence in S and observation o. We define ni and no similarly. More formally:\nnoi = \u2211 h\u2208gi P (h)1(h \u2208 V(S \u222a {(t, o)}))\nni = \u2211 o\u2208O noi\nno = \u2211 gi\u2208G noi\nN = \u2211 gi\u2208G \u2211 o\u2208O noi\nw(E(S)) = \u2211 e\u2208E \u220f i\u2208e ni\nSimilarly, we can also write w(E(S \u222a {(t, o)})) = \u2211 e\u2208E \u220f i\u2208e n o i . We can rewrite our objective as:\n\u2206(t |S) = \u2211 h P (h |S) (\u2211 e\u2208E \u220f i\u2208e ni \u2212 \u2211 e\u2208E \u220f i\u2208e n h(t) i ) = \u2211 o no N (\u2211 e\u2208E \u220f i\u2208e ni \u2212 \u2211 e\u2208E \u220f i\u2208e noi\n) = \u2211 e\u2208E \u220f i\u2208e ni \u2212 \u2211 o no N \u2211 e\u2208E \u220f i\u2208e noi\nSimilarly, we define variables for the evidence S\u0302, i.e. n\u0302oi for the total probability mass in gi consistent with all evidence in S\u0302 and observation o:\n\u2206(t | S\u0302) = \u2211 e\u2208E \u220f i\u2208e n\u0302i \u2212 \u2211 o n\u0302o N\u0302 \u2211 e\u2208E \u220f i\u2208e n\u0302oi\nWe rewrite what we would like to show as:\n\u2206(t |S)\u2212\u2206(t | S\u0302) = (\u2211 e\u2208E \u220f i\u2208e ni \u2212 \u2211 o no N \u2211 e\u2208E \u220f i\u2208e noi ) \u2212 (\u2211 e\u2208E \u220f i\u2208e n\u0302i \u2212 \u2211 o n\u0302o N\u0302 \u2211 e\u2208E \u220f i\u2208e n\u0302oi ) \u2265 0\nWe will show that for any single action observation pair, which corresponds to eliminating a single hypothesis, the expected utility of a test will always decrease. General adaptive submodularity, which states the expected utility decreases with any additional evidence, follows easily. For convenience, we consider rescaling our function so that all noi are integers, which is possible since we assumed a rational prior. Note that a function f is adaptive submodular i.f.f. cf is adaptive submodular for any constant c > 0, so showing adaptive submodularity in the rescaled setting implies adaptive submodularity for our setting.\nLemma 3.1. If we remove one hypothesis from subregion k which agrees with observation c, i.e.\nn\u0302oi = { noi \u2212 1 if i = l and o = c noi else\nthen\n\u2206 = (\u2211 e\u2208E \u220f i\u2208e ni \u2212 \u2211 o no N \u2211 e\u2208E \u220f i\u2208e noi ) \u2212 (\u2211 e\u2208E \u220f i\u2208e n\u0302i \u2212 \u2211 o n\u0302o N\u0302 \u2211 e\u2208E \u220f i\u2208e n\u0302oi ) \u2265 0\nProof. Based on our definitions, it follows that:\nn\u0302i = { ni \u2212 1 if i = l ni else\nn\u0302o = { no \u2212 1 if o = c no else\nN\u0302 = N \u2212 1\nWe split the difference into three terms:\n\u2206a = \u2211 e\u2208E (\u220f i\u2208e ni \u2212 \u220f i\u2208e n\u0302i )\n\u2206b = \u2211 o\u2208O\\c \u2211 e\u2208E\n( \u2212n o\nN \u220f i\u2208e noi + n\u0302o N\u0302 \u220f i\u2208e n\u0302oi\n)\n\u2206c = \u2211 e\u2208E\n( \u2212n c\nN \u220f i\u2208e nci + n\u0302c N\u0302 \u220f i\u2208e n\u0302ci ) \u2206a + \u2206b + \u2206c = \u2206\nTo aid in notation, we define El = {e \u2208 E : gl \u2208 e}, hyperedges that contain region l, and El = E\\El, all other hyperedges. Additionally, let |el| be the number of times gl appears in the multiset e.\nFirst term:\n\u2206a = \u2211 e\u2208E (\u220f i\u2208e ni \u2212 \u220f i\u2208e n\u0302i )\n= \u2211 e\u2208El [\u220f i\u2208e ni \u2212 \u220f i\u2208e n\u0302i ] + \u2211 e\u2208El [\u220f i\u2208e ni \u2212 \u220f i\u2208e n\u0302i ] = \u2211 e\u2208El [\u220f i\u2208e ni \u2212 \u220f i\u2208e ni ] + \u2211 e\u2208El  \u220f i\u2208e,i 6=l ni n|el|l \u2212  \u220f i\u2208e,i 6=l ni  (nl \u2212 1)|el|  = \u2211 e\u2208El  \u220f i\u2208e,i6=l ni\n(n|el|l \u2212 (nl \u2212 1)|el|) \u2265 0 (since nl \u2265 1)\nSecond term:\n\u2206b = \u2211 o\u2208O\\c \u2211 e\u2208E\n( \u2212n o\nN \u220f i\u2208e noi + n\u0302o N\u0302 \u220f i\u2208e n\u0302oi\n)\n= \u2211 o\u2208O\\c \u2211 e\u2208E\n( \u2212n o\nN \u220f i\u2208e noi + no N \u2212 1 \u220f i\u2208e noi\n)\n= \u2211 o\u2208O\\c \u2211 e\u2208E\nno N(N \u2212 1) \u220f i\u2208e noi\n\u2265 0 (since each term \u2265 0)\nThird term:\n\u2206c = \u2211 e\u2208E\n( \u2212n c\nN \u220f i\u2208e nci + n\u0302c N\u0302 \u220f i\u2208e n\u0302ci\n)\n= \u2212n c\nN \u2211 e\u2208E \u220f i\u2208e nci + nc \u2212 1 N \u2212 1 \u2211 e\u2208E  \u220f i\u2208e,i6=l nci  (ncl \u2212 1)|el| \n= \u2212n c\nN \u2211 e\u2208E \u220f i\u2208e nci + nc \u2212 1 N \u2212 1 \u2211 e\u2208E  \u220f i\u2208e,i6=l nci ((ncl )|el| \u2212 (ncl )|el| + (ncl \u2212 1)|el|) \n= \u2212n c\nN \u2211 e\u2208E \u220f i\u2208e nci + nc \u2212 1 N \u2212 1 \u2211 e\u2208E \u220f i\u2208e nci \u2212 \u2211 e\u2208El  \u220f i\u2208e,i 6=l nci ((ncl )|el| \u2212 (ncl \u2212 1)|el|) \n= \u2212 N \u2212 n c N(N \u2212 1) \u2211 e\u2208E \u220f i\u2208e nci \u2212 nc \u2212 1 N \u2212 1 \u2211 e\u2208El  \u220f i\u2208e,i 6=l nci ((ncl )|el| \u2212 (ncl \u2212 1)|el|) \n\u2264 0 (since each term \u2264 0)\nWe also define:\n\u2206c =\n( N \u2212 nc\nN(N \u2212 1)\n) \u2206c1 + ( nc \u2212 1 N \u2212 1 ) \u2206c2\n\u2206c1 = \u2212 \u2211 e\u2208E \u220f i\u2208e nci\n\u2206c2 = \u2212 \u2211 e\u2208El  \u220f i\u2208e,i 6=l nci ((ncl )|el| \u2212 (ncl \u2212 1)|el|) \n\u2206a = ( N(N \u2212 nc) N(N \u2212 1) + nc \u2212 1 N \u2212 1 ) \u2206a\n=\n( N \u2212 nc\nN(N \u2212 1)\n) \u2206a1 + ( nc \u2212 1 N \u2212 1 ) \u2206a2\n\u2206a1 = N \u2211 e\u2208El  \u220f i\u2208e,i 6=l ni (n|el|l \u2212 (nl \u2212 1)|el|) \u2206a2 = \u2211 e\u2208El  \u220f i\u2208e,i 6=l ni (n|el|l \u2212 (nl \u2212 1)|el|)\nThe constants in front of the sum for \u2206c1 and \u2206c2 were from the equation, and \u2206a was split up to include the same constants. Now we will show that \u2206a1 + \u2206c1 \u2265 0 and \u2206a2 + \u2206c2 \u2265 0. We start with the latter:\n\u2206a2 + \u2206 c 2 = \u2211 e\u2208El  \u220f i\u2208e,i6=l ni (n|el|l \u2212 (nl \u2212 1)|el|)\u2212  \u220f i\u2208e,i 6=l nci ((ncl )|el| \u2212 (ncl \u2212 1)|el|) \n\u2265 \u2211 e\u2208El  \u220f i\u2208e,i6=l ni (n|el|l \u2212 (nl \u2212 1)|el|)\u2212  \u220f i\u2208e,i 6=l ni (n|el|l \u2212 (nl \u2212 1)|el|)  (7)\n= 0\nWhere (7) follows from ni \u2265 nci \u2200i.\n\u2206a1 + \u2206 c 1 = N \u2211 e\u2208El  \u220f i\u2208e,i 6=l ni (n|el|l \u2212 (nl \u2212 1)|el|)\u2212\u2211 e\u2208E \u220f i\u2208e nci\n\u2265 N \u2211 e\u2208El  \u220f i\u2208e,i 6=l ni (n|el|l \u2212 (nl \u2212 1)|el|)\u2212\u2211 e\u2208E \u220f i\u2208e ni (8) \u2265 N \u2211 e\u2208El  \u220f i\u2208e,i 6=l ni n|el|\u22121l \u2212\u2211 e\u2208E \u220f i\u2208e ni (9) = (N \u2212 nl) \u2211 e\u2208El  \u220f i\u2208e,i 6=l ni n|el|\u22121l + \u2211 e\u2208El  \u220f i\u2208e,i 6=l ni n|el|l \u2212\u2211 e\u2208E \u220f i\u2208e ni = (N \u2212 nl) \u2211 e\u2208El  \u220f i\u2208e,i 6=l ni n|el|\u22121l \u2212\u2211 e\u2208El \u220f i\u2208e ni (10)\n\u2265 (N \u2212 nl) \u2211 e\u2208El \u220f i\u2208e,i6=l ni \u2212 \u2211 e\u2208El \u220f i\u2208e ni\nWhere (8) follows from ni \u2265 nci \u2200i, (9) follows from n |el| l \u2212 (nl \u2212 1)|el| \u2265 n |el| l \u2212 n |el|\u22121 l (nl \u2212 1) = n |el|\u22121 l , and (10) cancels edges in El exactly, leaving only edges in El.\nWe again want to separate out terms that cancel. We define:\nE k\u0302 = {e : |e| = k\u0302 \u2227 @ j s.t. \u2200g \u2208 e : g \u2286 rj} Emin = {e : e \u2208 E ,@e\u0302 \u2282 e : e\u0302 \u2208 Ek\u22121}\nEmin = E\\Emin\nWe defined E k\u0302 as the hyperedges for any specified cardinality k\u0302. We call Emin the minimal hyperedges if k is the minimal cardinality at which these regions should be seperated. Thus, these are the hyperedges where no subset of subregions {g1 . . . gk\u22121} \u2282 e would have a seperation hyperedge. All other hyperedges are called non-minimal. We also define Eminl , Eminl , Eminl , Eminl as the minimal and non-minimal hyperedges of El and El:\nEminl = {e : e \u2208 El,@e\u0302 \u2282 e : e\u0302 \u2208 Ek\u22121}\nEminl = {e : e \u2208 El,@e\u0302 \u2282 e : e\u0302 \u2208 E k\u22121}\nEminl = El\\Eminl Eminl = El\\Eminl\nWe also note that: \u2211 e\u2208Eminl \u220f i\u2208e ni \u2264 \u2211 gj\u2208G\\gl nj \u2211 e\u2208El k\u22121 \u220f i\u2208e ni\n= (N \u2212 nl) \u2211\ne\u2208El k\u22121\n\u220f i\u2208e ni\nFor convenience, we define one additional set of hyperedges E\u0302l. These are hyperedges in El such that no subset of k \u2212 1 elements which do not include k are in El.\nE\u0302l = {e : e \u2208 El \u2227 @ek\u22121 \u2282 e s.t. ek\u22121 \u2208 El k\u22121}\nThis enables us to split the set El up into edges where El k\u22121\nare a subset, and E\u0302l. We note that since there is no region shared by all elements ek\u22121 \u2208 El k\u22121 , then there will be no region shared by e = ek\u22121 \u222a gl. Thus, this will be an element of El. This gives us: \u2211 e\u2208El \u220f i\u2208e,i 6=l ni = \u2211\ne\u2208El k\u22121\n\u220f i\u2208e ni + \u2211 e\u2208E\u0302l \u220f i\u2208e,i6=l ni\nApplying these:\n\u2206a1 + \u2206 c 1 \u2265 (N \u2212 nl) \u2211 e\u2208El \u220f i\u2208e,i6=l ni \u2212 \u2211 e\u2208El \u220f i\u2208e ni\n= (N \u2212 nl)  \u2211 e\u2208El k\u22121 \u220f i\u2208e ni + \u2211 e\u2208E\u0302l \u220f i\u2208e,i 6=l ni \u2212 \u2211 e\u2208Eminl \u220f i\u2208e ni \u2212 \u2211 e\u2208Eminl \u220f i\u2208e ni\n\u2265 (N \u2212 nl)  \u2211 e\u2208El k\u22121 \u220f i\u2208e ni + \u2211 e\u2208E\u0302l \u220f i\u2208e,i 6=l ni \u2212 (N \u2212 nl) \u2211 e\u2208El k\u22121 \u220f i\u2208e ni \u2212 \u2211 e\u2208Eminl \u220f i\u2208e ni\n= (N \u2212 nl) \u2211 e\u2208E\u0302l \u220f i\u2208e,i 6=l ni \u2212 \u2211 e\u2208Eminl \u220f i\u2208e ni\nAt this point, we use the structure of our edge construction and definition of k to show this sum is \u2265 0. We have a positive term, consisting of edges which include k, and a negative term, consisting of edges that do not include k. We will show that for every product in the negative term, there is a corresponding product in the positive term.\nTo do so, we show that for any e \u2208 Eminl , there is at least one corresponding e\u2032 \u2208 E\u0302l to cancel the terms out. More concretely:\nLemma 3.1.1. Let e \u2208 Eminl . There exists some ek\u22121 \u2282 e, |ek\u22121| = k \u2212 1 such that e\u2032 = (ek\u22121 \u222a gl) \u2208 E\u0302l.\nProof. Recall that e is a multiset of subregions. It is straightforward to see that because e is minimal, there can be no repeated elements in the multiset - and thus it is equivalent to a set. Define this set as e = {g\u03021 . . . g\u0302k}. Define each distinct subset which does not include g\u0302i as ei = e\\g\u0302i, 1 \u2264 i \u2264 k. By our definition of minimal hyperedges Eminl , we know that \u2200ei,\u2203ri : ei \u2286 ri, which implies that ei 6\u2208 El k\u22121 . Note that each ri must be distinct. If ri = rj , for any i, j, this would imply (ei \u222a ej) = e \u2208 ri. But since there exists a separating hyperedge e, 6 \u2203r : e \u2286 r. This implies g\u0302i 6\u2286 ri. Combining this with our definition of E\u0302l, if 6 \u2203r : (ei \u222a gl) \u2286 r \u21d2 (ei \u222a gl) \u2208 E\u0302l. To prove this lemma, we will show that this region cannot exist for all ei.\nIf gl 6\u2286 ri \u21d2 ei \u222a gl 6\u2286 ri. For the sake of contradiction, suppose gl \u2286 ri\u2200i. Let R = {r1 . . . rk}. For this to be true, it must be that: 1 \u2200h \u2208 gl, h \u2208 R 2 \u2200ri \u2208 R,\u2200h\u0302 \u2208 g\u0302i : h\u0302 /\u2208 ri, h\u0302 \u2208 R\\ri where |R| = k. However, by definition of k this cannot be true: the largest such R where this holds |R| = k \u2212 1. Thus, we have a contradiction, and have shown such a set of regions {r1 . . . rk} = R : gl \u2286 ri \u2200ri cannot exist. Therefore, \u2203ei : (ei \u222a gl) \u2208 E\u0302l.\nIn order to apply Lemma 3.1.1, we split every e \u2208 Eminl it up into ek\u22121 and g, where ek\u22121 is the subset of e such that (ek\u22121 \u222a gl) \u2208 E\u0302l, and g = e\\ek\u22121. Let n be the number of particles in subregion g, which we will use in ((11)):\n\u2206a1 + \u2206 c 1 \u2265 (N \u2212 nl) \u2211 e\u2208E\u0302l \u220f i\u2208e,i 6=l ni \u2212 \u2211 e\u2208Eminl \u220f i\u2208e ni\n= (N \u2212 nl) \u2211 e\u2208E\u0302l \u220f i\u2208e,i 6=l ni \u2212 \u2211 e\u2208Eminl n \u220f i\u2208ek\u22121 ni (11)\n\u2265 (N \u2212 nl) \u2211 e\u2208E\u0302l \u220f i\u2208e,i 6=l ni \u2212 \u2211 gj\u2208G\\gl nj \u2211 e\u2208E\u0302l \u220f i\u2208e,i 6=l ni  (12) = (N \u2212 nl)\n\u2211 e\u2208E\u0302l \u220f i\u2208e,i 6=l ni \u2212 (N \u2212 nl) \u2211 e\u2208E\u0302l \u220f i\u2208e,i 6=l ni  = 0\nWhere ((12)) applies Lemma 3.1.1.\nAt this point, we have shown that \u2206 = \u2206a + \u2206b + \u2206c \u2265 0, since \u2206b \u2265 0 and \u2206a + \u2206c \u2265 0, which is what we needed to show.\nIt is not hard to see that for any S \u2286 S\u0302 \u2286 T \u00d7 O, we could show that \u2206(t |S) \u2265 \u2206(t | S\u03021) \u2265 \u2206(t | S\u03022) \u00b7 \u00b7 \u00b7 \u2265 \u2206(t | S\u0302) In other words, we can always find a sequence of removing one hypothesis at a time to get from S to S\u0302 when S \u2286 S\u0302 \u2286 T \u00d7O."}, {"heading": "7.4 Theorem 3: Greedy Performance Bound", "text": "Wewould like to apply Theorem 5.8 of Golovin and Krause (2011). We have already shown adaptive submodularity and strong adaptive monotonicty in Sec. 7.3. The theorem also requires that instances are self-certifying, which means that when the policy knows it has obtained the maximum possible objective value immediately upon doing so. See Golovin and Krause (2011) for details. As our objective is equivalent for all remaining hypotheses in V(S), our function fHEC is self-certifying.\nThe performance bound now follows directly from Theorem 5.8 of Golovin and Krause (2011). To apply the theorem, we needed to define two constants: a bound on the maximum value of fHEC(S),Q = 1, and the minimum our objective function can change by, which corresponds to removing one hyperedge, \u03b7 = pkmin. Plugging those into Theorem 5.8 of Golovin and Krause (2011) gives C(\u03c0HEC) \u2264 (k ln(1/pmin) + 1)C(\u03c0\u2217)."}], "references": [], "referenceMentions": [], "year": 2014, "abstractText": "How should we gather information to make effective decisions? We address Bayesian active learning and experimental design problems, where we sequentially select tests to reduce uncertainty about a set of hypotheses. Instead ofminimizing uncertainty per se, we consider a set of overlapping decision regions of these hypotheses. Our goal is to drive uncertainty into a single decision region as quickly as possible. We identify necessary and sufficient conditions for correctly identifying a decision region that contains all hypotheses consistent with observations. We develop a novel Hyperedge Cutting (HEC) algorithm for this problem, and prove that is competitive with the intractable optimal policy. Our efficient implementation of the algorithm relies on computing subsets of the complete homogeneous symmetric polynomials. Finally, we demonstrate its effectiveness on two practical applications: approximate comparison-based learning and active localization using a robotmanipulator.", "creator": "LaTeX with hyperref package"}}}