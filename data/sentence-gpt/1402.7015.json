{"id": "1402.7015", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "27-Feb-2014", "title": "Data-driven HRF estimation for encoding and decoding models", "abstract": "Despite the common usage of a canonical, data-independent, hemodynamic response function (HRF), it is known that the shape of the HRF varies across brain regions and subjects. This suggests that a data-driven estimation of this function could lead to more statistical power when modeling BOLD fMRI data. However, unconstrained estimation of the HRF can yield highly unstable results when the number of free parameters is large (Fig. 1). Nevertheless, some findings indicate that the HRF can sometimes vary significantly depending on the degree of the HRF. The first study showed that the HRF is highly stable at all regions and to a greater degree within the cortical region (Fig. 1). Furthermore, the HRF is also very stable in the brain as it may also occur in areas that are non-autistic (Fig. 1a). These findings are of concern for the use of different types of functional MRI to study the HRF, including fMRI (Fig. 1b). These results are of concern for the use of different types of functional MRI to study the HRF, including fMRI (Fig. 1c). However, it is clear that the results from the two studies suggest that the HRF is stable at all regions, and to a greater extent within the brain (Fig. 1d). In a previous study (2006), a subset of healthy and obese people, both of whom received a data-driven HRF (Fig. 1f), had observed that these groups were highly stable for many decades, which could have been the reason that they had been very stable in the same regions and hence, the HRF is highly stable at all regions. The differences in HRF were due to the differences in the number of free parameters in the brain regions, and because the number of free parameters in the brain regions has been significantly correlated with a non-autistic response to data-driven models (Fig. 1d). However, these results are of concern for the use of different types of functional MRI to study the HRF, including fMRI (Fig. 1d). Although this study provides a useful tool to assess brain function within the brain, we did not provide evidence of such a wide range of functional MRI results. In the first study, we investigated the presence of several different data-driven models in the hippocampus and hippocampus, which also showed significant change in HRF, particularly those with the use of the same data-driven model. Moreover, the data-driven model showed that the HRF is stable at", "histories": [["v1", "Thu, 27 Feb 2014 18:50:58 GMT  (2050kb,D)", "https://arxiv.org/abs/1402.7015v1", null], ["v2", "Sun, 6 Apr 2014 06:11:17 GMT  (3095kb,D)", "http://arxiv.org/abs/1402.7015v2", null], ["v3", "Tue, 15 Jul 2014 11:14:00 GMT  (2256kb,D)", "http://arxiv.org/abs/1402.7015v3", null], ["v4", "Mon, 6 Oct 2014 16:39:55 GMT  (2265kb,D)", "http://arxiv.org/abs/1402.7015v4", null], ["v5", "Fri, 31 Oct 2014 13:47:01 GMT  (2260kb,D)", "http://arxiv.org/abs/1402.7015v5", "appears in NeuroImage (2015)"], ["v6", "Fri, 7 Nov 2014 11:27:19 GMT  (2265kb,D)", "http://arxiv.org/abs/1402.7015v6", "appears in NeuroImage (2015)"]], "reviews": [], "SUBJECTS": "cs.CE cs.LG", "authors": ["fabian pedregosa", "michael eickenberg", "philippe ciuciu", "bertrand thirion", "alexandre gramfort"], "accepted": false, "id": "1402.7015"}, "pdf": {"name": "1402.7015.pdf", "metadata": {"source": "CRF", "title": "Data-driven HRF estimation for encoding and decoding models", "authors": ["Fabian Pedregosa", "Michael Eickenberg", "Philippe Ciuciu", "Bertrand Thirion", "Alexandre Gramfort"], "emails": ["fabian.pedregosa@inria.fr."], "sections": [{"heading": null, "text": "Despite the common usage of a canonical, data-independent, hemodynamic response function (HRF), it is known that the shape of the HRF varies across brain regions and subjects. This suggests that a data-driven estimation of this function could lead to more statistical power when modeling BOLD fMRI data. However, unconstrained estimation of the HRF can yield highly unstable results when the number of free parameters is large. We develop a method for the joint estimation of activation and HRF by means of a rank constraint, forcing the estimated HRF to be equal across events or experimental conditions, yet permitting it to differ across voxels. Model estimation leads to an optimization problem that we propose to solve with an efficient quasi-Newton method, exploiting fast gradient computations. This model, called GLM with Rank-1 constraint (R1-GLM), can be extended to the setting of GLM with separate designs which has been shown to improve decoding accuracy in brain activity decoding experiments. We compare 10 different HRF modeling methods in terms of encoding and decoding score on two different datasets. Our results show that the R1-GLM model outperforms competing methods in both encoding and decoding settings, positioning it as an attractive method both from the points of view of accuracy and computational efficiency.\nKeywords: Functional MRI (fMRI), Hemodynamic response function (HRF), machine learning, optimization, BOLD, Finite inpulse response (FIR), decoding, encoding\n1. Introduction\nThe use of machine learning techniques to predict the cognitive state of a subject from their functional MRI (fMRI) data recorded during task performance has become a popular analysis approach for neuroimaging studies over the last decade (Cox and Savoy, 2003; Haynes and Rees, 2006). It is now commonly referred to as brain reading or decoding. In this setting, the BOLD signal is used to predict the task or stimulus that the subject was performing. Although it is possible to perform decoding directly on raw BOLD signal (Moura\u0303o Miranda et al., 2007; Miyawaki et al., 2008), the common approach in fast event-related designs consists in extracting the activation coefficients (beta-maps) from the BOLD signal to perform the decoding analysis on these estimates. Similarly, in the voxel-based encoding models (Kay et al., 2008; Naselaris et al., 2011), the activation coefficients are extracted from the BOLD signal, this time to learn a model to predict the BOLD response in a given voxel, based on a given representation of the stimuli. In addition, a third approach, known as representational similarity analysis or RSA (Kriegeskorte et al., 2008) takes as input the activation coefficients.\n\u2217Corresponding author. Email: fabian.pedregosa@inria.fr. Tel: +33 1 69 08 79 92\n1Authors contributed equally 2Parietal Team, INRIA Saclay-\u0302Ile-de-France, Saclay, France 3Institut Mines-Telecom, Telecom ParisTech, CNRS LTCI, 37-39 Rue Dareau, 75014 Paris, France 4NeuroSpin, CEA Saclay, Bat. 145, 91191 Gif-sur-Yvette Cedex, France\nIn this case a comparison is made between the similarity observed in the activation coefficients, quantified by a correlation measure, and the similarity between the stimuli, quantified by a similarity measure defined from the experimental setting.\nThese activation coefficients are computed by means of the General Linear Model (GLM) (Friston et al., 1995). While this approach has been successfully used in a wide range of studies, it does suffer from limitations (Poline and Brett, 2012). For instance, the GLM commonly relies on a data-independent canonical form of the hemodynamic response function (HRF) to estimate the activation coefficient. However it is known (Handwerker et al., 2004; Badillo et al., 2013b) that the shape of this response function can vary substantially across subjects and brain regions. This suggests that an adaptive modeling of this response function should improve the accuracy of subsequent analysis.\nTo overcome the aforementioned limitation, Finite Impulse Response (FIR) models have been proposed within the GLM framework (Dale, 1999; Glover, 1999). These models do not assume any particular shape for the HRF and amount to estimating a large number of parameters in order to identify it. While the FIR-based modeling makes it possible to estimate the activation coefficient and the HRF simultaneously, the increased flexibility has a cost. The estimator is less robust and prone to overfitting, i.e. to generalize badly to unseen data. In general, FIR models are most appropriate for studies focused on the characterization of the shape of the hemodynamic response, and not\nPreprint submitted to Elsevier November 10, 2014\nar X\niv :1\n40 2.\n70 15\nv6 [\ncs .C\nE ]\n7 N\nov 2\n01 4\nfor studies that are primarily focused on detecting activation (Poldrack et al., 2011, Chapter 5).\nSeveral strategies aiming at reducing the number of degrees of freedom of the FIR model - and thus at limiting the risk of overfitting - have been proposed. One possibility is to constrain the shape of the HRF to be a linear combination of a small number of basis functions. A common choice of basis is formed by three elements consisting of a reference HRF as well as its time and dispersion derivatives (Friston et al., 1998), although it is also possible to compute a basis set that spans a desired function space (Woolrich et al., 2004). More generally, one can also define a parametric model of the HRF and estimate the parameters that best fit this function (Lindquist and Wager, 2007). However, in this case the estimated HRF may no longer be a linear function of the input parameters.\nSensitivity to noise and overfitting can also be reduced through regularization. For example, temporal regularization has been used in the smooth FIR (Goutte et al., 2000; Ciuciu et al., 2003; Casanova et al., 2008) to favor solutions with small second order time derivative. These approaches require the setting of one or several hyperparameters, at the voxel or potentially at the parcel level (if several voxels in a pre-defined parcel are assumed to share some aspects of the HRF timecourse). Even if efficient techniques such as generalized cross-validation (Golub et al., 1979) can be used to choose the regularization parameters, these methods are inherently more costly than basis-constrained methods. Basis-constrained methods also require setting the number of basis elements; however, this parameter is not continuous (as in the case of regularized methods), and in practice only few values are explored: for example the 3-element basis set formed by a reference HRF plus derivatives and the FIR model. This paper focuses on basis-constrained regularization of the HRF to avoid dealing with hyperparameter selection with the goal of remaining computationally attractive. A different approach to increase robustness of the estimates consists in linking the estimated HRFs across a predefined brain parcel, taking advantage of the spatially dependent nature of fMRI (Wang et al., 2013). However, hemodynamically-informed parcellations (Chaari et al., 2012; Badillo et al., 2013a) rely on the computation of a large number of estimations at the voxel or sub-parcel level. In this setting, the development of voxel-wise estimation procedures is complementary to the development of parcellation methods in that more robust estimation methods at the voxel level would naturally translate into more robust parcellation methods. In this paper we focus on voxel-wise estimation methods.\nWe propose a method for the simultaneous estimation of HRF and activation coefficients based on low-rank modeling. Within this model, and as in (Makni et al., 2008; Kay et al., 2008; Vincent et al., 2010; Degras and Lindquist, 2014), the HRF is constrained to be equal across the different conditions, yet permitting it to be different across voxels. Unlike previous works, we formulate this model as a constrained least squares problem, where the vector of\ncoefficients is constrained to lie within the space of rank one matrices. We formulate the model within the framework of smooth optimization and use quasi-Newton methods to find the vector of estimates. This model was briefly presented in the conference paper (Pedregosa et al., 2013). Here we provide more experimental validation and a more detailed presentation of the method. We also added results using a GLM with separate designs (Mumford et al., 2012). Ten alternative approaches are now compared on two publicly available datasets. The solver has also been significantly improved to scale to full brain data.\nThe contributions of this paper are two-fold. First, we quantify the importance of HRF estimation in encoding and decoding models. While the benefit of data-driven estimates of the HRF have already been reported in the case of decoding (Turner et al., 2012) and encoding approaches (Vu et al., 2011), we here provide a comprehensive comparison of models. Second, we evaluate a method called GLM with Rank-1 constraint (R1-GLM) that improves encoding and decoding scores over state-of-the-art methods while remaining computationally tractable on a full brain volume. We propose an efficient algorithm for this method and discuss practical issues such as initialization. Finally, we provide access to an open source software implementation of the methods discussed in this paper.\nNotation: \u2016 \u00b7 \u2016 and \u2016 \u00b7 \u2016\u221e denote the Euclidean and infinity norm for vectors. We use lowercase boldface letter to denote vectors and uppercase boldface letter to denote matrices. I denotes the identity matrix, 1n denotes the vector of ones of size n, \u2297 denotes the Kronecker product and vec(A) denotes the concatenation of the columns of a matrix A into a single column vector. A\u2020 denotes the MoorePenrose pseudoinverse. Given the vectors {a1, . . . , ak} with ai \u2208 Rn for each 1 \u2264 i \u2264 k, we will use the notation [a1, . . . , ak] \u2208 Rn\u00d7k to represents the columnwise concatenation of the k vectors into a matrix of size n \u00d7 k. We will use Matlab-style colon notation to denote slices of an array, that is x(1 : k) will denote the first k elements of x.\n2. Methods\nIn this section we describe different methods for extracting the HRF and activation coefficients from BOLD signals. We will refer to each different stimulus as condition and we will call trial a unique presentation of a given stimulus. We will denote by k the total number of stimuli, y \u2208 Rn the BOLD signal at a single voxel and n the total number of images acquired.\n2.1. The General Linear Model\nThe original GLM model (Friston et al., 1995) makes the assumption that the hemodynamic response is a linear transformation of the underlying neuronal signal. We define the n \u00d7 k-matrix XGLM as the columnwise stacking of different regressors, each one defined as the convolution of a reference HRF (Boynton et al., 1996; Glover, 1999)\nwith the stimulus onsets for the given condition. In this work we used as reference HRF the one provided by the software SPM 8 (Friston et al., 2011). Assuming additive white noise, n \u2265 k and XGLM to be full rank, the vector of estimates is given by \u03b2\u0302GLM = X \u2020 GLMy, where \u03b2\u0302GLM is a vector of size k representing the amplitude of each one of the conditions in a given voxel.\nA popular modification of this setting consists in extending the GLM design matrix with the temporal and width derivatives of the reference HRF. This basis, formed by the reference HRF and its derivatives with respect to time and width parameters, will be used throughout this work. We will refer to it as the 3HRF basis. In this case, each one of the basis elements is convolved with the stimulus onsets of each condition, obtaining a design matrix of size n\u00d7 3k. This way, for each condition, we estimate the form of the HRF as a sum of basis functions that correspond to the first order Taylor expansion of the parametrization of the response function. Another basis set that will be used is the Finite Impulse Response (FIR) set. This basis set spans the complete ambient vector space (of dimension corresponding to the length of the impulse response) and it is thus a flexible model for capturing the HRF shape. It consists of the canonical unit vectors (also known as stick function) for the given duration of the estimated HRF. Other basis functions such as FMRIB\u2019s Linear Optimal Basis Sets (Woolrich et al., 2004) are equally possible but were not considered in this work.\nMore generally, one can extend this approach to any set of basis functions. Given the matrix formed by the stacking of d basis elements B = [b1,b2, . . . ,bd], the design matrix XB is formed by successively stacking the regressors obtained by convolving each of the basis elements with the stimulus onsets of each condition. This results in a matrix of size n\u00d7 dk and under the aforementioned conditions the vector of estimates is given by \u03b2\u0302B = X \u2020 By. In this case, \u03b2\u0302B is no longer a vector of size k: it has length k \u00d7 d instead and can no longer be interpreted as the amplitude of the activation. One possibility to recover the trial-bytrial reponse amplitude is to select the parameters from a single time point as done by some of the models considered in (Mumford et al., 2012), however this procedure assumes that the peak BOLD response is located at that time point. Another possibility is to construct the estimated HRF and take as amplitude coefficient the peak amplitude of this estimated HRF. This is the approach that we have used in this paper.\n2.2. GLM with rank constraint\nIn the basis-constrained GLM model, the HRF estimation is performed independently for each condition. This method works reliably whenever the number of conditions is small, but in experimental designs with a large number of conditions it performs poorly due to the limited conditioning of the problem and the increasing variance of the estimates.\nAt a given voxel, it is expected that for similar stimuli the estimated HRF are also similar (Henson et al., 2002). Hence, a natural idea is to promote a common HRF across the various stimuli (given that they are sufficiently similar), which should result in more robust estimates (Makni et al., 2008; Vincent et al., 2010). In this work we consider a model in which a common HRF is shared across the different stimuli. Besides the estimation of the HRF, a unique coefficient is obtained per column of our event matrix. This amounts to the estimation of k + d free parameters instead of k \u00d7 d as in the standard basis-constrained GLM setting.\nThe novelty of our method stems from the observation that the formulation of the GLM model with a common HRF across conditions translates to a rank constraint on the vector of estimates. This assumption amounts to enforcing the vector of estimates to be of the form \u03b2B = [h\u03b21,h\u03b22, \u00b7 \u00b7 \u00b7 ,h\u03b2k] for some HRF h \u2208 Rd and a vector of coefficients \u03b2 \u2208 Rk. More compactly, this can be written as \u03b2B = vec(h\u03b2\nT ). This can be seen as a constraint on the vector of coefficients to be the vectorization of a rank-one matrix, hence the name Rank-1 GLM (R1-GLM).\nIn this model, the coefficients have no longer a closed form expressions, but can be estimated by minimizing the mean squared error of a bilinear model. Given XB and y as before, Z \u2208 Rn\u00d7q a matrix of nuisance parameters such as drift regressors, we define FR1(h,\u03b2,\u03c9,XB, y,Z) = 1 2\u2016y \u2212 XB vec(h\u03b2\nT ) \u2212 Z\u03c9\u20162 to be the objective function to be minimized. The optimization problem reads:\nh\u0302, \u03b2\u0302, \u03c9\u0302 = arg min h,\u03b2,\u03c9 FR1(h,\u03b2,\u03c9,XB, y,Z)\nsubject to \u2016Bh\u2016\u221e = 1 and \u3008Bh,href\u3009 > 0 , (1)\nThe norm constraint is added to avoid the scale ambiguity between h and \u03b2 and the sign is chosen so that the estimated HRF correlates positively with a given reference HRF href. Otherwise the signs of the HRF and \u03b2 can be simultaneously flipped without changing the value of the cost function. Within its feasible set, the optimization problem is smooth and is convex with respect to h, \u03b2 and \u03c9, however it is not jointly convex in variables h, \u03b2 and \u03c9.\nFrom a practical point of view this formulation has a number of advantages. First, in contrast with the GLM without rank-1 constraint the estimated coefficients are already factored into the estimated HRF and the activation coefficients. That is, once the estimation of the model parameters from Eq. (1) is obtained, \u03b2\u0302 is a vector of size k and h\u0302 is a vector of size d that can be both used in subsequent analysis, while in models without rank-1 constraint only the vector of coefficients (equivalent to vec(h\u03b2T ) in rank-1 constrained models) of size k \u00d7 d is estimated. In the latter case, the estimated HRF and the beta-maps still have to be extracted from this vector by methods such as normalization by the peak of the HRF, averaging or projecting to the set of Rank-1 matrices.\nSecond, it is readily adapted to prediction on unseen trials. While for classical (non rank-1 models) the HRF estimation is performed per condition with no HRF associated with unseen conditions, in this setting, because the estimated HRF is linked and equal across conditions it is natural to use this estimate on unseen conditions. This setting occurs often in encoding models where prediction on unseen trials is part of the cross-validation procedure.\nThis model can also be extended to a parametric HRF model. That is, given the hemodynamic response defined as a function h : Rd1 \u2192 Rd of some parameters \u03b1, we can formulate the analogous model of Eq. (1) as an optimization over the parameters \u03b1 and \u03b2 with the design matrix XFIR given by the convolution of the event matrix with the FIR basis:\n\u03b1\u0302, \u03b2\u0302, \u03c9\u0302 = arg min \u03b1,\u03b2,\u03c9 FR1(h(\u03b1),\u03b2,\u03c9,XFIR, y,Z)\nsubject to \u2016h(\u03b1)\u2016\u221e = 1 and \u3008h(\u03b1),href\u3009 > 0 (2)\nIn section 2.4 we will discuss optimization strategies for both models.\n2.3. Extension to separate designs\nAn extension to the classical GLM that improves the estimation with correlated designs was proposed in (Mumford et al., 2012). In this setting, each voxel is modeled as a linear combination of two regressors in a design matrix XGLM. The first one is the regressor associated with a given condition and the second one is the sum of all other regressors. This results in k design matrices, one for each condition. The estimate for a given condition is given by the first element in the two-dimensional array XSi\u2020y, where XSi is the design matrix for condition i. We will denote this model GLM with separate designs (GLMS). It has been reported to find a better estimate in rapid event designs leading to a boost in accuracy for decoding tasks (Mumford et al., 2012; Schoenmakers et al., 2013; Lei et al., 2013).\nThis approach was further extended in (Turner et al., 2012) to include FIR basis instead of the predefined canonical function. Here we employ it in the more general setting of a predefined basis set. Given a set of basis functions we construct the design matrix for condition i as the columnwise concatenation of two matrices X0BSi and X 1 BSi. X 0 BSi is given by the columns associated with the current condition in the GLM matrix and X1BSi is the sum of all other columns. In this case, the vector of estimates is given by the first d vectors of X\u2020BSiy. See (Turner et al., 2012) for a more complete description of the matrices X0BSi and X 1 BSi.\nIt is possible to use the same rank-1 constraint as before in the setting of separate designs, linking the HRF across conditions. We will refer to this model as Rank-1 GLM with separate designs (R1-GLMS). In this case the objective function has the form FR1-S(h,\u03b2,\u03c9, r,XB, y,Z) = 1 2 \u2211k\ni \u2016y\u2212\u03b2iX0BSih\u2212riX1BSih\u2212Z\u03c9\u20162, where r \u2208 Rd is a vector representing the activation of all events except the event of interest and will not be used in subsequent analyses. We\ncan compute the vector of estimates \u03b2\u0302 as the solution to the optimization problem\n\u03b2\u0302, \u03c9\u0302, h\u0302, r\u0302 = arg min h,\u03b2,\u03c9,r FR1-S(h,\u03b2,\u03c9, r,XB, y,Z)\nsubject to \u2016Bh\u2016\u221e = 1 and \u3008Bh,href\u3009 > 0 (3)\n2.4. Optimization\nFor the estimation of rank-1 models on a full brain volume, a model is estimate at each voxel separately. Since a typical brain volume contains more than 40,000 voxels, the efficiency of the estimation at a single voxel is of great importance. In this section we will detail an efficient procedure based on quasi-Newton methods for the estimation of R1-GLM and R1-GLMS models on a given voxel.\nOne approach to minimize (1) is to alternate the minimization with respect to the variables \u03b2, h and \u03c9. By recalling the Kronecker product identities (Horn and Johnson, 1991, Chapter 4.3), and using the identity vec(h\u03b2T ) = \u03b2\u2297 h we can rewrite the objective function (1) to be minimized as:\n1 2 \u2016y \u2212 XB(\u03b2 \u2297 h) \u2212 Z\u03c9\u20162 = (4) 1 2 \u2016y \u2212 XB(I \u2297 h)\u03b2 \u2212 Z\u03c9\u20162 = (5) 1 2 \u2016y \u2212 XB(\u03b2 \u2297 I)h \u2212 Z\u03c9\u20162 . (6)\nUpdating h, \u03b2 or \u03c9 sequentially thus amounts to solving a (constrained) least squares problem at each iteration. A similar procedure is detailed in (Degras and Lindquist, 2014). However, this approach requires computing the matrices XB(\u03b2 \u2297 I) and XB(I \u2297 h) at each iteration, which are typically dense, resulting in a high computational cost per iteration. Note also that the optimization problem is not jointly convex in variables h,\u03b2,\u03c9, therefore we cannot apply convergence guarantees from convex analysis.\nWe rather propose a more efficient approach by optimizing both variables jointly. We define a global variable z as the concatenation of (h,\u03b2,\u03c9) into a single vector, z = vec([h,\u03b2,\u03c9]), and cast the problem as an optimization with respect to this new variable. Generic solvers for numerical optimization (Nocedal and Wright, 2006) can then be used. The solvers that we will consider take as input an objective function and its gradient. In this case, the partial derivatives with respect to variable z can be written as \u2202FR1/\u2202z = vec([\u2202FR1/\u2202h, \u2202FR1/\u2202\u03b2, \u2202FR1/\u2202\u03c9]), whose expression can be easily derived using the aforementioned Kronecker product identities: \u2202FR1 \u2202h = \u2212 (\u03b2T \u2297 I)XT (y \u2212 X vec(h\u03b2T ) \u2212 Z\u03c9) \u2202FR1 \u2202\u03b2 = \u2212 (I \u2297 hT )XT (y \u2212 X vec(h\u03b2T ) \u2212 Z\u03c9)\n\u2202FR1 \u2202\u03c9 = \u2212 ZT (y \u2212 X vec(h\u03b2T ) \u2212 Z\u03c9)\nIf instead a parametric model of the HRF is used as in Eq. (2), the equivalent partial derivatives can be easily computed by the chain rule.\nFor the sake of efficiency, it is essential to avoid evaluating the Kronecker products naively, but rather reformulate them using the above mentioned Kronecker identities. For example, the matrix M = X(I\u2297h) should not be computed explicitly but should rather be stored as a linear operator such that when applied to a vector \u03b2 \u2208 Rk it computes M(\u03b2) = X(\u03b2 \u2297 h), avoiding thus the explicit computation of I \u2297 h.\nSimilar equations can be derived for the rank-1 model with separate designs of Eq. (3) (R1-GLMS), in which case the variable z is defined as the concatenation of (h,\u03b2,\u03c9, r), i.e. z = vec([h,\u03b2,\u03c9, r]). The gradient of FR1-S with respect to z can be computed as \u2202FR1-S/\u2202z = vec([\u2202FR1-S/\u2202h, \u2202FR1-S/\u2202\u03b2, \u2202FR1-S/\u2202\u03c9, FR1-S/\u2202r]). The partial derivatives read: \u2202F \u2202h = \u2211k i \u2212(X0BSi\u03b2i \u2212 X 1 BSi ri)T (y \u2212 \u03b2iX0BSi h \u2212 wiX 1 BSi h) \u2202F \u2202\u03b2i = \u2212(X0BSi h) T (y \u2212 \u03b2iX0BSi h \u2212 wiX 1 BSi h) \u2202F \u2202\u03c9i = \u2212ZT (y \u2212 \u03b2iX0BSi h \u2212 wiX 1 BSi\nh) \u2202F \u2202ri = \u2212(X1BSi h) T (y \u2212 \u03b2iX0BSi h \u2212 wiX 1 BSi h)\nA good initialization plays a crucial role in the convergence of any iterative algorithm. Furthermore, for nonconvex problems a good initialization prevents the algorithm from converging to undesired local minima. We have used as initialization for the R1-GLM and R1-GLMS models the solution given by the GLM with separate designs (GLMS). Since the GLM with separate designs scales linearly in the number of voxels, this significantly reduces computation time whenever an important number of voxels is considered.\nWhenever the design matrix XB has more rows than columns (as is the case in both datasets we consider with B the 3HRF basis), it is possible to find an orthogonal transformation that significantly speeds up the computation of the Rank-1 model. Let Q,R be the \u201cthin\u201d QR decomposition of XB \u2208 Rn\u00d7dk, that is, QR = XB with Q \u2208 Rn\u00d7dk an orthogonal matrix and R \u2208 Rdk\u00d7dk a triangular matrix. Because of the invariance of the Euclidean norm to orthogonal transformations, the change of variable XB \u2190 QT XB, y\u2190 QT y yields a Rank-1 model in Eq. (1) with equivalent solutions. This reduces the size of the design matrix to a square triangular matrix of size dk \u00d7 dk (instead of n \u00d7 dk) and reduces the explained variable y to a vector of size kd (instead of n). After this change of variable, the convergence of the Rank-1 model is significantly faster due to the faster computation of the objective function and its partial derivatives. We have observed that the total running time of the algorithm can be reduced by 30% using this transformation.\nSome numerical solvers such as L-BFGS-B (Liu and Nocedal, 1989) require the constraints to be given as box constraints. While our original problem includes an equality constraint we can easily adapt it to use convex box\nconstraints instead. We replace the equality constraint \u2016Bh\u2016\u221e = 1 by the convex inequality constraint \u2016Bh\u2016\u221e \u2264 1, which is equivalent to the box constraint \u22121 \u2264 (Bh)i \u2264 1 supported by the above solver. However, this change of constraint allows solutions in which h can be arbitrarily close to zero. To avoid such degenerate cases we add the smooth term \u2212\u2016B(:, 1)h1\u201622 to the cost function. Since there is a free scale parameter between h and \u03b2, this does not bias the problem, but forces Bh to lie as far as possible from the origin (thus saturating the box constraints). Once a descent direction has been found by the L-BFGS-B method we perform a line search procedure to determine the step length. The line-search procedure was implemented to satisfy the strong Wolfe conditions (Nocedal and Wright, 2006). Finally, when the optimization algorithm has converged to a stationary point, we rescale the solution setting to ensure that the equality constraint. This still leaves a sign ambiguity between the estimated HRF and the associated beta-maps. To make these parameters identifiable, the sign of the estimated HRF will be chosen so that these correlate positively with the reference HRF.\nWe have compared several first-order (Conjugate Gradient), quasi-Newton (L-BFGS) and Newton methods on this problems and found that in general quasi-Newton methods performed best in terms of computation time. In our implementation, we adopt the L-BFGS-B as the default solver.\nIn Algorithm 1 we describe an algorithm based on LBFGS that can be used to optimize R1-GLM and R1GLMS models (a reference implementation for the Python language is described in subsection Software). Variable r is only used for the R1-GLMS method and its use is denoted within parenthesis, i.e. (, r), so that for the R1-GLM it can simply be ignored.\nThe full estimation of the R1-GLM model with 3HRF basis for one subject of the dataset described in section Dataset 2: decoding of potential gain levels (16 \u00d7 3 conditions, 720 time points, 41, 622 voxels) took 14 minutes in a 8-cores Intel Xeon 2.67GHz machine. The total running time for the 17 subjects was less than four hours.\n2.5. Software\nWe provide a software implementation of all the models discussed in this section in the freely available (BSD licensed) pure-Python package hrf estimation 5.\n3. Data description\nWith the aim of making the results in this paper easily reproducible, we have chosen two freely available datasets to validate our approach and to compare different HRF modeling techniques.\n5https://pypi.python.org/pypi/hrf estimation\nAlgorithm 1 Optimization of R1-GLM and R1-GLMS models Input: Given initial points \u03b20 \u2208 Rk,h0 \u2208 Rd,\u03c90 \u2208 Rq (, r0 \u2208 Rk), convergence tolerance > 0, inverse Hessian approximation H0. Output: \u03b2m,hm 1: (Optional): Compute the QR decomposition of XB,\nQR = XB, and replace XB \u2190 QT XB, y\u2190 QT y 2: Initialization. Set m\u2190 0, z\u2190 vec([h0,\u03b20,\u03c90(, r0)]) 3: while \u2016\u2207 f \u2016 > do 4: Compute search direction. Set pm \u2190\n\u2212Hm\u2207 f (hm,\u03b2m,\u03c9m(, rm)) by means of the L-BFGS algorithm.\n5: Set zm+1 = zm + \u03b3mpm, where \u03b3m is computed from a line search procedure subject to the box constraints \u2016hm\u2016\u221e \u2264 1. 6: m\u2190 m + 1 7: end while 8: Extract R1-GLM(S) parameters from zm. Set hm \u2190\nzm(1 : d),\u03b2m \u2190 zm(d + 1 : m + d) 9: Normalize and set sign so that the estimated HRF\nis positively correlated with a reference HRF: qm \u2190 \u2016hm\u2016\u221esign(hTmhref), hm \u2190 hm/qm, \u03b2m \u2190 \u03b2mqm\n3.1. Dataset 1: encoding of visual information\nThe first dataset we will consider is described in (Kay et al., 2008; Naselaris et al., 2009; Kay et al., 2011). It contains BOLD fMRI responses in human subjects viewing natural images. As in (Kay et al., 2008), we performed prediction of BOLD signal following the visual presentation of natural images and compared it against the measured fMRI BOLD signal. As the procedure consists of predicting the fMRI data from stimuli descriptors, it is an encoding model. This dataset is publicly available from http://crcns.org\nTwo subjects viewed 1750 training images, each presented twice, and 120 validation images, each presented 10 times, while fixating a central cross. Images were flashed 3 times per second (200 ms on-off-on-off-on) for one second every 4 seconds, leading to a rapid event-related design. The data were acquired in 5 scanner sessions on 5 different days, each comprising 5 runs of 70 training images \u2013each image being presented twice within the run\u2013 and 2 runs of validation images showing 12 images, 10 times each. The images were recorded from the occipital cortex at a spatial resolution of 2mm\u00d72mm\u00d72.5mm and a temporal resolution of 1 second. Every brain volume for each subject has been aligned to the first volume of the first run of the first session for that subject. Across-session alignment was performed manually. Additionally, data were temporally interpolated to account for slice-timing differences. See (Kay et al., 2008) for further preprocessing details.\nWe performed local detrending using a Savitzky-Golay filter (Savitzky and Golay, 1964) with a polynomial of degree 4 and a window length of 91 TR. The activation co-\nefficients (beta-map) and HRF were extracted from the training set by means of the different methods we would like to compare. The training set consisted of 80% of the original session (4 out of 5 runs). This resulted in estimated coefficients (beta-map) for each of the 70\u00d74 images in the training set.\nWe proceed to train the encoding model. The stimuli are handled as local image contrasts, that are represented by spatially smoothed Gabor pyramid transform modulus with 2 orientations and 4 scales. Ridge regression (regularization parameter chosen by Generalized CrossValidation (Golub et al., 1979)) was then used to learn a predictor of voxel activity on the training set. By using this encoding model and the estimated HRF it is possible to predict the BOLD signal for the 70 images in the test set (20 % of the original session). We emphasize that learning the HRF on the training set instead of on the full dataset is necessary to avoid overfitting while assessing the quality of the estimated HRF by any HRF-learning method: otherwise, the estimation of the HRF may incorporate specificities of the test set leading to artificially higher scores.\nIn a first step, we perform the image identification task from (Kay et al., 2008). From the training set we estimate the activation coefficients that will be used to compute the activation maps. We use an encoding model using Gabor filters that predicts the activation coefficient from the training stimuli. From the stimuli in the validation set we predict the activation coefficients that we then use to identify the correct image. The predicted image is the one yielding the highest correlation with the measured activity. This procedure mimics the one presented in (Kay et al., 2008, Supplementary material).\nIn a second step, we report score as the Pearson correlation between the measurements and the predicted BOLD signal on left out data. The prediction of BOLD signal on the test set is performed from conditions that were not present in the train set. In order to do this, an HRF for these conditions is necessary. As highlighted in the methods section, the construction of an HRF for these conditions is ambiguous for non Rank-1 methods that perform HRF estimation on the different stimuli. In these cases we chose to use the mean HRF across conditions as the HRF for unseen conditions. Finally, linear predictions on the left out fold were compared to the measured BOLD signals.\n3.2. Dataset 2: decoding of potential gain levels\nThe second dataset described in (Tom et al., 2007) is a gambling task where each of the 17 subjects was asked to accept or reject gambles that offered a 50/50 chance of gaining or losing money. The magnitude of the potential gain and loss was independently varied across 16 levels between trials. Each gamble has an amount of potential gains and potential losses that can be used as class label. In this experiment, we only considered gain levels. This leads to the challenge of predicting or decoding the gain\nlevel from brain images. The dataset is publicly available from http://openfmri.org under the name mixedgambles task dataset.\nThe data preprocessing included slice timing, motion correction, coregistration to the anatomical images, tissue segmentation, normalization to MNI space and was performed using the SPM 8 software through the Pypreprocess6 interface.\nFor all subjects three runs were recorded, each consisting of 240 images with a repetition time (TR) of 2 seconds and a stimulus presentation at every 4 seconds. In order to perform HRF estimation on more data than what is available on a single run, we performed the estimation on the three runs simultaneously. This assumes HRF consistency across runs, which was obtained by concatenating the data from the three runs and creating a block-diagonal design matrix correspondingly (each block is the design of one run).\nAfter training a regression model on 90% of the data, we predict the gain level on the remaining 10%. As a performance measure we use Kendall tau rank correlation coefficient (Kendall, 1938) between the true gain levels and the predicted levels, which is a measure for the orderings of the data. We argue that this evaluation metric is better suited than a regression loss for this task because of the discrete and ordered nature of the labels. Also, this loss is less sensible to shrinkage of the prediction that might occur when penalizing a regression model (Bekhti et al., 2014). The Kendall tau coefficient always lies within the interval [\u22121, 1], with 1 being perfect agreement between the two rankings and \u22121 perfect disagreement. Chance level lies at zero. This metric was previously proposed for fMRI decoding with ordered labels in (Doyle et al., 2013).\n4. Results\nIn order to compare the different methods discussed previously, we ran the same encoding and decoding studies while varying the estimation method for the activation coefficients (beta-maps). The methods we considered are standard GLM (denoted GLM), GLM with separate designs (GLMS), Rank-1 GLM (R1-GLM) and Rank-1 GLM with separate designs (R1-GLMS). For all these models we consider different basis sets for estimating the HRF: a set of three elements formed by the reference HRF and its time and dispersion derivative, a FIR basis set (of size 20 in the first dataset and of size 10 in the second dataset) formed by the canonical vectors and the single basis set formed by the reference HRF (denoted \u201cfixed HRF\u201d), which in this case is the HRF used by the SPM 8 software.\nIt should be reminded that the focus of this study is not the study of the HRF in itself (such as variability across subjects, tasks or regions) but instead its possible impact on the accuracy of encoding and decoding paradigms. For\n6https://github.com/neurospin/pypreprocess\nthis reason we report encoding and decoding scores but we do not investigate any of the possible HRF variability factors.\n4.1. Dataset 1: encoding of visual information\nIn the original study, 500 voxels were used to perform image identification. These voxels were selected as the voxels with the highest correlation with the true BOLD signal on left-out data using a (classical) GLM with the reference HRF. These voxels are therefore not the ones naturally benefiting the most from HRF estimation.\nWe first present the scores obtained in the image identification task for different variants of the GLM. This can be seen in Figure 1. The displayed score is the count of correctly identified images over the total number of images (chance level is therefore at 1/120). The identification algorithm here only uses the beta-maps obtained from the train and validation set. This makes the estimation of the HRF an intermediate result in this model. However, we expect that a correct estimation of the HRF directly translates into a better estimation of the activation coefficients in the sense of being able to acheive higher predictive accuracy. Our results are consistent with this hypothesis and in this task the rank-one (R1) and glm-separate (GLMS) models outperform the classical GLM model. The benefits range from 0.9% for R1-GLM in subject 2 to 8.2% for the same method and subject 1. It is worth noticing that methods with FIR basis obtain a higher score than methods using the 3HRF basis.\nIn order to test whether this increase is statistically significant we performed the following statistical test. The success of recovering the correct image can be modeled as a binomial distribution, with pA being be the probability of recovering the correct image with method A and pB be the probability of recovering the correct image with method B. We define the null hypothesis H0 as the statement that both probabilities are equal, H0 : pA = pB, and the alternate hypothesis that both probabilities and not equal, H1 : p1 , p2 (this test is sometimes known as the binomial proportion test (Ro\u0308hmel and Mansmann, 1999)). The score test statistic for\nthe one-tailed test is T = (pA \u2212 pB)/ \u221a\np(1 \u2212 p) 2n , where p = (pA + pB)/2 and n is the number of repetitions, in this case n = 120. This statistic is normally distributed for large n. The p-value associated with this statistical test when comparing every model (by order of performance) with the model \u201cGLM with with fixed HRF\u201d is (0.10, 0.10, 0.15, 0.19, 0.21, 0.26, 0.5, 0.5, 0.82, 0.81) for the first subject and (0.18, 0.18, 0.25, 0.34, 0.34, 0.44, 0.5, 0.5, 0.86, 0.93) for the second.\nWe will now use a different metric for evaluating the performance of the encoding model. This metric is the Pearson correlation between the BOLD predicted by the encoding model and the true BOLD signal, averaged across\nvoxels. We will compute the this metric on a left-out session, which results in five scores for each method, corresponding to each of the cross-validation folds. Given two methods, a Wilcoxon signed-rank test can be used on these cross-validation scores to assess whether the score obtained by the two methods are significantly different. This way, irrespective of the variance across voxels, which is inherent to the study, we can reliably assess the relative ranking of the different models. In Figure 2 we show the scores for each method (averaged across sessions) and the p-value corresponding the Wilcoxon test between a given method and the previous one by order of performance.\nWe observed in Figure 2 that methods that learn the HRF together with some sort of regularization (be it Rank1 constraint or induced by separate designs) perform noticeably better than methods that perform unconstrained HRF estimation, highlighting the importance of a robust estimation of the HRF as opposed to a free estimation as performed by the standard GLM model with FIR basis. This suggests that R1 and GLMS methods permit including FIR basis sets while minimizing the risk of overfitting inherent to the classical GLM model.\nWe also observed that models using the GLM with separate designs from (Mumford et al., 2012) perform significantly better on this dataset than the standard design, which is consistent with the purpose of these models. It improves estimation in highly correlated designs. The best performing model for both subjects in this task is the R1GLMS with FIR basis, followed by the R1-GLM with FIR basis model for subject 1 and GLMS with FIR basis for subject 2. The difference between both models (Wilcoxon signed-rank test) was significant with a p-value < 10\u22126. Since the results for both subjects are similar, we will only use subject 1 for the rest of the figures.\nTo further inspect the results, we investigated the estimation and encoding scores at the voxel level. This provides some valuable information. For example, parameters such as time-to-peak, width and undershoot of the estimated HRF can be used to characterize the mis-modeling of a reference HRF for the current study. Also, a voxelwise comparison of the different methods can be used to identify which voxels exhibit a greater improvement for a given method. In the upper part of Figure 3 we show the HRF estimated on the first subject by our best performing method (the Rank-1 with separate designs and FIR basis). For comparison we also present two commonly used reference HRFs: one used in the software SPM and one defined in (Glover, 1999, auditory study) and used by software such as NiPy7 and fmristat8. Because the HRF estimation will fail on voxels for which there is not enough signal, we only show the estimated HRF for voxels for which the encoding score is above the mean encoding score. In this plot the time-to-peak of the estimated HRF is color coded. One can observe a substantial variability in the time to peak,\n7http://nipy.org 8http://www.math.mcgill.ca/keith/fmristat/\nconfirming the existence of a non-negligeable variability of the estimated HRFs, even within a single subject and a single task. In particular, we found that only 50% of the estimated HRFs on the full brain volume peaked between 4.5 and 5.5 seconds.\nIn the lower part of Figure 3 we can see a scatter plot in which the coordinates of each point are the encoding scores with two different methods. The first coordinate (Xaxis) is given by the score using a canonical GLM whilst the second coordinate (Y-axis) corresponds to the Rank-1 separate with FIR basis. Points above the black diagonal exhibit a higher score with our method than with a canonical GLM. As previously, the color represents the time to peak of the estimated HRF. From this plot we can see that voxels that have a low correlation score using a canonical GLM do not gain significant improvement by using a Rank-1 Separate FIR model instead. However, voxels that already exhibit a sufficiently high correlation score using a canonical GLM (> 0.05) see a significant increase in performance when estimated using our method.\nThese results suggest as a strategy to limit the computational cost of learning the HRF on an encoding study to perform first a standard GLM (or GLMS) on the full volume and then perform HRF estimation only on the best performing voxels.\nThe methods that we have considered for HRF estimation can be subdivided according to the design matrices they use (standard or separate) and the basis they use to generate the estimated HRF (3HRF and FIR). We now focus on the performance gains of each of these individual components. In the upper part of Figure 4 we consider the top-performing model, the Rank-1 GLMS, and compare the performance of two different basis sets: FIR with 20 elements in the Y-axis and the reference HRF plus its time and dispersion derivatives (3HRF) in the X-axis. The abundance of points above the diagonal demonstrates the superiority of the FIR basis on this dataset. The color trend in this plot suggests that the score improvement of the FIR basis with respect to the 3HRF basis becomes more pronounced as the time-to-peak of the estimated HRF deviates from the reference HRF (peak at 5s), which can be explained by observing that the 3HRF basis corresponds to a local model around the time-to-peak. In the bottom part of this figure we compare the different design matrices (standard or separate). Here we can see the voxel-wise encoding score for two Rank-1 models with FIR basis and different design matrices: separate design on the Y-axis and classical design on the X-axis. Although both models give similar results, a Wilcoxon signed-rank test on the leave-one-session-out cross-validation score confirmed the superiority of the separate designs model in this dataset with p-value < 10\u22123.\nIn Figure 5 we can see the voxel-wise encoding score on a single acquisition slice. In the upper column, the score is plotted on each voxel and thresholded at a value of 0.045, which would correspond to a p-value < 0.05 for testing non-correlation assuming each signal is normally\ndistributed, while in the bottom row the 0.055 contour (p-value < 0.001) for the same data is shown as a green line. Here it can be seen how the top performing voxels follow the gray matter. A possible hypothesis to explain the increase of the encoding score between the method R1GLMS with FIR basis and the same method with 3HRF basis could be related either to the shape of the HRF deviating more from a canonical shape in lateral visual areas or to the higher signal-to-noise ratio often found in the visual cortex when compared to lateral visual areas.\n4.2. Dataset 2: decoding of potential gain levels\nThe mean decoding score was computed over 50 random splittings of the data, with a test set of size 10%. The decoding regression model consisted of univariate feature selection (ANOVA) followed by a Ridge regression classifier as implemented in scikit-learn (Pedregosa et al., 2011). Both parameters, number of voxels and amount of `2 regularization in Ridge regression, were chosen by cross-validation.\nThe mean score for the 10 models considered can be seen in Figure 6. Similarly to how we assessed superiority of a given method in encoding, we will say that a given method outperforms another if the paired difference of both scores (this time across folds) is significantly greater than zero. This is computed by performing a Wilcoxon signed rank test across voxels. For this reason we report p-values together with the mean score in Figure 6.\nAs was the case in encoding, Rank-1 constrained methods obtain the highest scores. In this case however, methods with 3HRF basis outperform methods using FIR basis."}, {"heading": "Average Decoding Score", "text": "This can be explained by factors such as smaller sample size of each of the runs, smaller number of trials in the dataset and experimental design.\n5. Discussion\nWe have compared different HRF modeling techniques and examined their generalization score on two different datasets: one in which the main task was an encoding task and one in which it was a decoding task. We compared 10 different methods that share a common formulation within the context of the General Linear Model. This includes models with canonical and separate designs, with and without HRF estimation constrained by a basis set, and with and without rank-1 constraint. We have focused on voxel-independent models of the HRF, possibly constrained by a basis set, and have omitted for efficiency reasons other possible models such as Bayesian models (Marrelec et al., 2003; Ciuciu et al., 2003; Makni et al., 2005) and regularized methods (Goutte et al., 2000; Casanova et al., 2008).\nOther models such as spatial models (Vincent et al., 2010), and multi-subject methods (Zhang et al., 2012, 2013) that adaptively learn the HRF across several subjects are outside the scope of this work. The latter models are more relevant in the case of standard group studies and second level analysis.\nOur first dataset consists of an encoding study and revealed that it is possible to boost the encoding score by appropriately modeling the HRF. We used two different metrics to assess the quality of our estimates. The first metric is the fraction of correctly identified images by an encoding model. For this we computed the activation coefficients on both the training and validation dataset. We then learned a predictive model of the activation coefficients from the stimuli. This was used to identify a novel image from a set\nof 120 potential images from which the activation coefficients were previously computed. The benefits range from 0.9% points to 8.2% points across R1-constrained methods and subjects. The best-performing model in this task is the R1-GLM with FIR basis. The second metric is the Pearson correlation. By considering the voxel-wise score on a full brain volume we observed that the increase in performance obtained by estimating the HRF was not homogeneous across voxels and more important for voxels that already exhibited a good score with a classical design (GLM) and a fixed HRF. The best-performing method is the Rank-1 with separate designs (R1-GLMS) and FIR basis model, providing a significant improvement over the second best-performing model. We also found substantial variability of the shape in the estimated HRF within a single subject and a single task.\nThe second dataset consists of a decoding task and the results confirmed that constrained (rank-1) estimation of the HRF also increased the decoding score of a classifier. The metric here is Kendall tau. However, in this case the best performing basis was no longer FIR basis consisting of ten elements but the three elements 3HRF basis (HRF and derivatives) instead, which can be explained by factors such as differences in acquisition parameters, signal-to-noise ratio or by the regions involved in the task.\nA higher performance increase was observed when considering the correlation score within the encoding model. This higher sensitivity to a correct (or incorrect) estimation of the HRF can be explained by the fact that the estimation of the HRF is used to generate the BOLD signal on the test set. The metric is the correlation between the generated signal and the BOLD signal. It is thus natural to expect that a correct estimation of the HRF has a higher impact on the results.\nIn the decoding setup, activation coefficients (beta-map) are computed but the evaluation metric is the accuracy at predicting the stimulus type. The validation metric used for decoding is less sensitive to the HRF estimation procedure than the correlation metric from the encoding study, although it allowed us to observe a statistically significant improvement.\n6. Conclusion\nWe have presented a method for the joint estimation of HRF and activation coefficients within the GLM framework. Based on ideas from previous literature (Makni et al., 2008; Vincent et al., 2010) we assume the HRF to be equal across conditions but variable across voxels. Unlike previous work, we cast our model as an optimization problem and propose an efficient algorithm based on quasi-Newton methods. We also extend this approach to the setting of GLM with separate designs.\nWe quantify the improvement in terms of generalization score in both encoding and decoding settings. Our results show that the rank-1 constrained method (R1-GLM and\nR1-GLMS) outperforms competing methods in both encoding and decoding settings.\nAcknowledgements This work was supported by grants IRMGroup ANR-10-BLAN-0126-02 and BrainPedia ANR10-JCJC 1408-01. We would like to thank our colleagues Ronald Phlypo and Gael Varoquaux for fruitful discussions.\nReferences\nBadillo, S., Varoquaux, G., Ciuciu, P., Jun. 2013a. Hemodynamic Estimation Based on Consensus Clustering. 2013 International Workshop on Pattern Recognition in Neuroimaging, 211\u2013215. Badillo, S., Vincent, T., Ciuciu, P., Nov. 2013b. Group-level impacts of within- and between-subject hemodynamic variability in fMRI. NeuroImage 82, 433\u2013448. Bekhti, Y., Zilber, N., Pedregosa, F., Ciuciu, P., Van Wassenhove, V., Gramfort, A., 2014. Decoding perceptual thresholds from MEG/EEG. In: Pattern Recoginition in Neuroimaging (PRNI) (2014). Tubingen, Germany. Boynton, G. M., Engel, S. A., Glover, G. H., Heeger, D. J., 1996. Linear Systems Analysis of Functional Magnetic Resonance Imaging in Human V1 16 (13), 4207\u20134221. Casanova, R., Ryali, S., Serences, J., Yang, L., Kraft, R., Laurienti, P. J., Maldjian, J. a., May 2008. The impact of temporal regularization on estimates of the BOLD hemodynamic response function: a comparative analysis. NeuroImage 40 (4), 1606\u201318. Chaari, L., Forbes, F., Vincent, T., Ciuciu, P., Jan. 2012. Hemodynamic-informed parcellation of fMRI data in a joint detection estimation framework. International Conference on Medical Image Computing and Computer-Assisted Intervention 15 (Pt 3), 180\u20138. Ciuciu, P., Poline, J.-B., Marrelec, G., Idier, J., Pallier, C., Benali, H., Oct. 2003. Unsupervised robust nonparametric estimation of the hemodynamic response function for any fMRI experiment. IEEE transactions on Medical Imaging 22 (10), 1235\u201351. Cox, D. D., Savoy, R. L., Jun. 2003. Functional magnetic resonance imaging (fMRI) brain reading: detecting and classifying distributed patterns of fMRI activity in human visual cortex. NeuroImage 19 (2), 261\u2013270. Dale, a. M., Jan. 1999. Optimal experimental design for event-related fMRI. Human brain mapping 8 (2-3), 109\u201314. Degras, D., Lindquist, M. A., 2014. A hierarchical model for simultaneous detection and estimation in multi-subject fMRI studies. NeuroImage 98C, 61\u201372. Doyle, O. M., Ashburner, J., Zelaya, F. O., Williams, S. C. R., Mehta, M. a., Marquand, a. F., Nov. 2013. Multivariate decoding of brain images using ordinal regression. NeuroImage 81, 347\u201357. Friston, K. J., Ashburner, J. T., Kiebel, S. J., Nichols, T. E., Penny, W. D., 2011. Statistical parametric mapping: The analysis of functional brain images: The analysis of functional brain images. Academic Press. Friston, K. J., Holmes, A. P., Poline, J. P., 1995. Statistical parametric maps in functional imaging : A general linear approach. Friston, K. J., Josephs, O., Rees, G., Turner, R., 1998. Nonlinear event-related responses in fMRI. Magnetic Resonance in Medicine 39 (1), 41\u201352. Glover, G. H., Apr. 1999. Deconvolution of impulse response in eventrelated BOLD fMRI. NeuroImage 9 (4), 416\u201329. Golub, G. H., Heath, M., Wahba, G., 1979. Generalized crossvalidation as a method for choosing a good ridge parameter. Technometrics 21 (2), 215\u2013223. Goutte, C., Nielsen, F. a., Hansen, L. K., Dec. 2000. Modeling the haemodynamic response in fMRI using smooth FIR filters. IEEE transactions on Medical Imaging 19 (12), 1188\u2013201. Handwerker, D. a., Ollinger, J. M., D\u2019Esposito, M., Apr. 2004. Variation of BOLD hemodynamic responses across subjects and brain regions and their effects on statistical analyses. NeuroImage 21 (4), 1639\u201351.\nHaynes, J.-D., Rees, G., Jul. 2006. Decoding mental states from brain activity in humans. Nature reviews. Neuroscience 7 (7), 523\u201334. Henson, R. N. a., Price, C. J., Rugg, M. D., Turner, R., Friston, K. J., Jan. 2002. Detecting latency differences in event-related BOLD responses: application to words versus nonwords and initial versus repeated face presentations. NeuroImage 15 (1), 83\u201397. Horn, R. A., Johnson, C. R., 1991. Topics in matrix analysis. Cambridge university press. Kay, K. N., Naselaris, Gallant, J. L., 2011. fMRI of human visual areas in response to natural images. CRCNS.org. Kay, K. N., Naselaris, T., Prenger, R. J., Gallant, J. L., Mar. 2008. Identifying natural images from human brain activity. Nature 452 (7185), 352\u20135. Kendall, M. G., 1938. A new measure of rank correlation. Biometrika 30 (1/2), 81\u201393. Kriegeskorte, N., Mur, M., Bandettini, P., 2008. Representational similarity analysis\u2013connecting the branches of systems neuroscience. Frontiers in systems neuroscience 2. Lei, Y., Tong, L., Yan, B., Jan. 2013. A mixed L2 norm regularized HRF estimation method for rapid event-related fMRI experiments. Computational and mathematical methods in medicine 2013, 643129. Lindquist, M. A., Wager, T. D., 2007. Validity and power in hemodynamic response modeling: A comparison study and a new approach. Hum Brain Mapp 28 (8), 764\u2013784. Liu, D. C., Nocedal, J., 1989. On the limited memory BFGS method for large scale optimization. Mathematical programming 45 (1-3), 503\u2013528. Makni, S., Beckmann, C., Smith, S., Woolrich, M., Oct. 2008. Bayesian deconvolution of fMRI data using bilinear dynamical systems. NeuroImage 42 (4), 1381\u201396. Makni, S., Ciuciu, P., Idier, J., Poline, J.-B., Sep. 2005. Joint detection-estimation of brain activity in functional MRI: a Multichannel Deconvolution solution. IEEE Transactions on Signal Processing 53 (9), 3488\u20133502. Marrelec, G., Benali, H., Ciuciu, P., Pe\u0301le\u0301grini-Issac, M., Poline, J.-B., 2003. Robust bayesian estimation of the hemodynamic response function in event-related BOLD fMRI using basic physiological information. Human Brain Mapping 19 (1), 1\u201317. Miyawaki, Y., Uchida, H., Yamashita, O., Sato, M.-a., Morito, Y., Tanabe, H. C., Sadato, N., Kamitani, Y., Dec. 2008. Visual image reconstruction from human brain activity using a combination of multiscale local image decoders. Neuron 60 (5), 915\u201329. Moura\u0303o Miranda, J., Friston, K. J., Brammer, M., May 2007. Dynamic discrimination analysis: a spatial-temporal SVM. NeuroImage 36 (1), 88\u201399. Mumford, J. a., Turner, B. O., Ashby, F. G., Poldrack, R. a., Feb. 2012. Deconvolving BOLD activation in event-related designs for multivoxel pattern classification analyses. NeuroImage 59 (3), 2636\u201343. Naselaris, T., Kay, K. N., Nishimoto, S., Gallant, J. L., May 2011. Encoding and decoding in fMRI. NeuroImage 56 (2), 400\u201310. Naselaris, T., Prenger, R. J., Kay, K. N., Oliver, M., Gallant, J. L., 2009. Bayesian reconstruction of natural images from human brain activity. Neuron 63 (6), 902\u2013915. Nocedal, J., Wright, S., 2006. Numerical optimization, series in operations research and financial engineering. Springer, New York. Pedregosa, F., Eickenberg, M., Thirion, B., Gramfort, A., 2013. HRF estimation improves sensitivity of fMRI encoding and decoding models. Proceedings of the 3nd International Workshop on Pattern Recognition in NeuroImaging (2013), 3\u20136. Pedregosa, F., Grisel, O., Weiss, R., Passos, A., Brucher, M., 2011. Scikit-learn : Machine learning in python. Journal of Machine Learning Research 12, 2825\u20132830. Poldrack, R. A., Mumford, J. A., Nichols, T. E., 2011. Handbook of Functional MRI Data Analysis. Cambridge University Press. Poline, J.-B., Brett, M., Aug. 2012. The general linear model and fMRI: does love last forever? NeuroImage 62 (2), 871\u201380. Ro\u0308hmel, J., Mansmann, U., 1999. Unconditional non-asymptotic one-sided tests for independent binomial proportions when the interest lies in showing non-inferiority and/or superiority. Biomet-\nrical Journal 41 (2), 149\u2013170. Savitzky, A., Golay, M. J., 1964. Smoothing and differentiation of\ndata by simplified least squares procedures. Analytical chemistry 36 (8), 1627\u20131639. Schoenmakers, S., Barth, M., Heskes, T., van Gerven, M., Jul. 2013. Linear reconstruction of perceived images from human brain activity. NeuroImage 83, 951\u2013961. Tom, S. M., Fox, C. R., Trepel, C., Poldrack, R. a., Jan. 2007. The neural basis of loss aversion in decision-making under risk. Science (New York, N.Y.) 315 (5811), 515\u20138. Turner, B. O., Mumford, J. a., Poldrack, R. a., Ashby, F. G., Sep. 2012. Spatiotemporal activity estimation for multivoxel pattern analysis with rapid event-related designs. NeuroImage 62 (3), 1429\u201338. Vincent, T., Risser, L., Ciuciu, P., 2010. Spatially adaptive mixture modeling for analysis of fMRI time series. IEEE Transactions on Medical Imaging 29 (4), 1059\u20131074. Vu, V. Q., Ravikumar, P., Naselaris, T., Kay, K. N., Gallant, J. L., Yu, B., 2011. Encoding and decoding V1 fMRI responses to natural images with sparse nonparametric models. The annals of applied statistics 5 (2B), 1159. Wang, J., Zhu, H., Fan, J., Giovanello, K., Lin, W., Jun. 2013. Multiscale adaptive smoothing models for the hemodynamic response function in fMRI. The Annals of Applied Statistics 7 (2), 904\u2013935. Woolrich, M. W., Behrens, T. E. J., Smith, S. M., Apr. 2004. Constrained linear basis sets for HRF modelling using variational bayes. NeuroImage 21 (4), 1748\u201361. Zhang, T., Li, F., Beckes, L., Brown, C., Coan, J. A., Nov. 2012. Nonparametric inference of the hemodynamic response using multisubject fMRI data. NeuroImage 63 (3), 1754\u201365. Zhang, T., Li, F., Beckes, L., Coan, J. a., Jul. 2013. A semiparametric model of the hemodynamic response for multi-subject fMRI data. NeuroImage 75, 136\u201345."}], "references": [{"title": "Hemodynamic Estimation Based on Consensus Clustering", "author": ["S. Badillo", "G. Varoquaux", "P. Ciuciu", "Jun."], "venue": "2013 International Workshop on Pattern Recognition in Neuroimaging, 211\u2013215.", "citeRegEx": "Badillo et al\\.,? 2013a", "shortCiteRegEx": "Badillo et al\\.", "year": 2013}, {"title": "Group-level impacts of within- and between-subject hemodynamic variability in fMRI", "author": ["S. Badillo", "T. Vincent", "P. Ciuciu", "Nov."], "venue": "NeuroImage 82, 433\u2013448.", "citeRegEx": "Badillo et al\\.,? 2013b", "shortCiteRegEx": "Badillo et al\\.", "year": 2013}, {"title": "Decoding perceptual thresholds from MEG/EEG", "author": ["Y. Bekhti", "N. Zilber", "F. Pedregosa", "P. Ciuciu", "V. Van Wassenhove", "A. Gramfort"], "venue": "Pattern Recoginition in Neuroimaging (PRNI)", "citeRegEx": "Bekhti et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Bekhti et al\\.", "year": 2014}, {"title": "Linear Systems Analysis of Functional Magnetic Resonance Imaging in Human V1", "author": ["G.M. Boynton", "S.A. Engel", "G.H. Glover", "D.J. Heeger"], "venue": null, "citeRegEx": "Boynton et al\\.,? \\Q1996\\E", "shortCiteRegEx": "Boynton et al\\.", "year": 1996}, {"title": "The impact of temporal regularization on estimates of the BOLD hemodynamic response function: a comparative analysis", "author": ["R. Casanova", "S. Ryali", "J. Serences", "L. Yang", "R. Kraft", "P.J. Laurienti", "Maldjian", "J. a.", "May"], "venue": "NeuroImage 40 (4), 1606\u201318.", "citeRegEx": "Casanova et al\\.,? 2008", "shortCiteRegEx": "Casanova et al\\.", "year": 2008}, {"title": "Hemodynamic-informed parcellation of fMRI data in a joint detection estimation framework", "author": ["L. Chaari", "F. Forbes", "T. Vincent", "P. Ciuciu", "Jan."], "venue": "International Conference on Medical Image Computing and Computer-Assisted Intervention 15 (Pt 3), 180\u20138.", "citeRegEx": "Chaari et al\\.,? 2012", "shortCiteRegEx": "Chaari et al\\.", "year": 2012}, {"title": "Unsupervised robust nonparametric estimation of the hemodynamic response function for any fMRI experiment", "author": ["P. Ciuciu", "Poline", "J.-B.", "G. Marrelec", "J. Idier", "C. Pallier", "H. Benali", "Oct."], "venue": "IEEE transactions on Medical Imaging 22 (10), 1235\u201351.", "citeRegEx": "Ciuciu et al\\.,? 2003", "shortCiteRegEx": "Ciuciu et al\\.", "year": 2003}, {"title": "Functional magnetic resonance imaging (fMRI) brain reading: detecting and classifying distributed patterns of fMRI activity in human visual cortex", "author": ["D.D. Cox", "R.L. Savoy", "Jun."], "venue": "NeuroImage 19 (2), 261\u2013270.", "citeRegEx": "Cox et al\\.,? 2003", "shortCiteRegEx": "Cox et al\\.", "year": 2003}, {"title": "Optimal experimental design for event-related fMRI", "author": ["Dale", "a. M", "Jan"], "venue": "Human brain mapping", "citeRegEx": "Dale et al\\.,? \\Q1999\\E", "shortCiteRegEx": "Dale et al\\.", "year": 1999}, {"title": "A hierarchical model for simultaneous detection and estimation in multi-subject fMRI studies", "author": ["D. Degras", "M.A. Lindquist"], "venue": "NeuroImage 98C,", "citeRegEx": "Degras and Lindquist,? \\Q2014\\E", "shortCiteRegEx": "Degras and Lindquist", "year": 2014}, {"title": "Multivariate decoding of brain images using ordinal regression", "author": ["O.M. Doyle", "J. Ashburner", "F.O. Zelaya", "S.C.R. Williams", "Mehta", "M. a", "Marquand", "a. F", "Nov"], "venue": null, "citeRegEx": "Doyle et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Doyle et al\\.", "year": 2013}, {"title": "Statistical parametric mapping: The analysis of functional brain images: The analysis of functional brain", "author": ["K.J. Friston", "J.T. Ashburner", "S.J. Kiebel", "T.E. Nichols", "W.D. Penny"], "venue": null, "citeRegEx": "Friston et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Friston et al\\.", "year": 2011}, {"title": "Statistical parametric maps in functional imaging : A general linear approach", "author": ["K.J. Friston", "A.P. Holmes", "J.P. Poline"], "venue": null, "citeRegEx": "Friston et al\\.,? \\Q1995\\E", "shortCiteRegEx": "Friston et al\\.", "year": 1995}, {"title": "Nonlinear event-related responses in fMRI", "author": ["K.J. Friston", "O. Josephs", "G. Rees", "R. Turner"], "venue": "Magnetic Resonance in Medicine", "citeRegEx": "Friston et al\\.,? \\Q1998\\E", "shortCiteRegEx": "Friston et al\\.", "year": 1998}, {"title": "Deconvolution of impulse response in eventrelated BOLD fMRI", "author": ["G.H. Glover", "Apr."], "venue": "NeuroImage 9 (4), 416\u201329.", "citeRegEx": "Glover and Apr.,? 1999", "shortCiteRegEx": "Glover and Apr.", "year": 1999}, {"title": "Generalized crossvalidation as a method for choosing a good ridge", "author": ["G.H. Golub", "M. Heath", "G. Wahba"], "venue": "parameter. Technometrics", "citeRegEx": "Golub et al\\.,? \\Q1979\\E", "shortCiteRegEx": "Golub et al\\.", "year": 1979}, {"title": "Modeling the haemodynamic response in fMRI using smooth FIR filters", "author": ["C. Goutte", "Nielsen", "F. a.", "L.K. Hansen", "Dec."], "venue": "IEEE transactions on Medical Imaging 19 (12), 1188\u2013201.", "citeRegEx": "Goutte et al\\.,? 2000", "shortCiteRegEx": "Goutte et al\\.", "year": 2000}, {"title": "Decoding mental states from brain activity in humans", "author": ["Haynes", "J.-D.", "G. Rees", "Jul."], "venue": "Nature reviews. Neuroscience 7 (7), 523\u201334.", "citeRegEx": "Haynes et al\\.,? 2006", "shortCiteRegEx": "Haynes et al\\.", "year": 2006}, {"title": "Detecting latency differences in event-related BOLD responses: application to words versus nonwords and initial versus repeated face presentations", "author": ["Henson", "R.N. a.", "C.J. Price", "M.D. Rugg", "R. Turner", "K.J. Friston", "Jan."], "venue": "NeuroImage 15 (1), 83\u201397.", "citeRegEx": "Henson et al\\.,? 2002", "shortCiteRegEx": "Henson et al\\.", "year": 2002}, {"title": "Topics in matrix analysis", "author": ["R.A. Horn", "C.R. Johnson"], "venue": null, "citeRegEx": "Horn and Johnson,? \\Q1991\\E", "shortCiteRegEx": "Horn and Johnson", "year": 1991}, {"title": "fMRI of human visual areas in response to natural images. CRCNS.org", "author": ["K.N. Kay", "Naselaris", "J.L. Gallant"], "venue": null, "citeRegEx": "Kay et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Kay et al\\.", "year": 2011}, {"title": "Identifying natural images from human brain activity", "author": ["K.N. Kay", "T. Naselaris", "R.J. Prenger", "J.L. Gallant", "Mar."], "venue": "Nature 452 (7185), 352\u20135.", "citeRegEx": "Kay et al\\.,? 2008", "shortCiteRegEx": "Kay et al\\.", "year": 2008}, {"title": "A new measure of rank correlation", "author": ["M.G. Kendall"], "venue": "Biometrika", "citeRegEx": "Kendall,? \\Q1938\\E", "shortCiteRegEx": "Kendall", "year": 1938}, {"title": "Representational similarity analysis\u2013connecting the branches of systems neuroscience. Frontiers in systems neuroscience", "author": ["N. Kriegeskorte", "M. Mur", "P. Bandettini"], "venue": null, "citeRegEx": "Kriegeskorte et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Kriegeskorte et al\\.", "year": 2008}, {"title": "A mixed L2 norm regularized HRF estimation method for rapid event-related fMRI experiments", "author": ["Y. Lei", "L. Tong", "B. Yan", "Jan."], "venue": "Computational and mathematical methods in medicine 2013, 643129.", "citeRegEx": "Lei et al\\.,? 2013", "shortCiteRegEx": "Lei et al\\.", "year": 2013}, {"title": "Validity and power in hemodynamic response modeling: A comparison study and a new approach", "author": ["M.A. Lindquist", "T.D. Wager"], "venue": "Hum Brain Mapp", "citeRegEx": "Lindquist and Wager,? \\Q2007\\E", "shortCiteRegEx": "Lindquist and Wager", "year": 2007}, {"title": "On the limited memory BFGS method for large scale optimization", "author": ["D.C. Liu", "J. Nocedal"], "venue": "Mathematical programming", "citeRegEx": "Liu and Nocedal,? \\Q1989\\E", "shortCiteRegEx": "Liu and Nocedal", "year": 1989}, {"title": "Bayesian deconvolution of fMRI data using bilinear dynamical systems", "author": ["S. Makni", "C. Beckmann", "S. Smith", "M. Woolrich", "Oct."], "venue": "NeuroImage 42 (4), 1381\u201396.", "citeRegEx": "Makni et al\\.,? 2008", "shortCiteRegEx": "Makni et al\\.", "year": 2008}, {"title": "Joint detection-estimation of brain activity in functional MRI: a Multichannel Deconvolution solution", "author": ["S. Makni", "P. Ciuciu", "J. Idier", "Poline", "J.-B.", "Sep."], "venue": "IEEE Transactions on Signal Processing 53 (9), 3488\u20133502.", "citeRegEx": "Makni et al\\.,? 2005", "shortCiteRegEx": "Makni et al\\.", "year": 2005}, {"title": "Robust bayesian estimation of the hemodynamic response function in event-related BOLD fMRI using basic physiological information", "author": ["G. Marrelec", "H. Benali", "P. Ciuciu", "M. P\u00e9l\u00e9grini-Issac", "Poline", "J.-B"], "venue": "Human Brain Mapping", "citeRegEx": "Marrelec et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Marrelec et al\\.", "year": 2003}, {"title": "Visual image reconstruction from human brain activity using a combination of multiscale local image decoders", "author": ["Y. Miyawaki", "H. Uchida", "O. Yamashita", "Sato", "M.-a.", "Y. Morito", "H.C. Tanabe", "N. Sadato", "Y. Kamitani", "Dec."], "venue": "Neuron 60 (5), 915\u201329.", "citeRegEx": "Miyawaki et al\\.,? 2008", "shortCiteRegEx": "Miyawaki et al\\.", "year": 2008}, {"title": "Dynamic discrimination analysis: a spatial-temporal SVM", "author": ["J. Mour\u00e3o Miranda", "K.J. Friston", "M. Brammer", "May"], "venue": "NeuroImage 36 (1), 88\u201399.", "citeRegEx": "Miranda et al\\.,? 2007", "shortCiteRegEx": "Miranda et al\\.", "year": 2007}, {"title": "Deconvolving BOLD activation in event-related designs for multivoxel pattern classification analyses", "author": ["Mumford", "J. a.", "B.O. Turner", "F.G. Ashby", "Poldrack", "R. a.", "Feb."], "venue": "NeuroImage 59 (3), 2636\u201343.", "citeRegEx": "Mumford et al\\.,? 2012", "shortCiteRegEx": "Mumford et al\\.", "year": 2012}, {"title": "Encoding and decoding in fMRI", "author": ["T. Naselaris", "K.N. Kay", "S. Nishimoto", "J.L. Gallant", "May"], "venue": "NeuroImage 56 (2), 400\u201310.", "citeRegEx": "Naselaris et al\\.,? 2011", "shortCiteRegEx": "Naselaris et al\\.", "year": 2011}, {"title": "Bayesian reconstruction of natural images from human brain", "author": ["T. Naselaris", "R.J. Prenger", "K.N. Kay", "M. Oliver", "J.L. Gallant"], "venue": "activity. Neuron", "citeRegEx": "Naselaris et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Naselaris et al\\.", "year": 2009}, {"title": "Numerical optimization, series in operations research and financial engineering", "author": ["J. Nocedal", "S. Wright"], "venue": null, "citeRegEx": "Nocedal and Wright,? \\Q2006\\E", "shortCiteRegEx": "Nocedal and Wright", "year": 2006}, {"title": "HRF estimation improves sensitivity of fMRI encoding and decoding models", "author": ["F. Pedregosa", "M. Eickenberg", "B. Thirion", "A. Gramfort"], "venue": "Proceedings of the 3nd International Workshop on Pattern Recognition", "citeRegEx": "Pedregosa et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Pedregosa et al\\.", "year": 2013}, {"title": "Scikit-learn : Machine learning in python", "author": ["F. Pedregosa", "O. Grisel", "R. Weiss", "A. Passos", "M. Brucher"], "venue": "Journal of Machine Learning Research", "citeRegEx": "Pedregosa et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Pedregosa et al\\.", "year": 2011}, {"title": "Handbook of Functional MRI Data Analysis", "author": ["R.A. Poldrack", "J.A. Mumford", "T.E. Nichols"], "venue": null, "citeRegEx": "Poldrack et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Poldrack et al\\.", "year": 2011}, {"title": "The general linear model and fMRI: does love last forever", "author": ["Poline", "J.-B", "M. Brett", "Aug"], "venue": "NeuroImage 62", "citeRegEx": "Poline et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Poline et al\\.", "year": 2012}, {"title": "Unconditional non-asymptotic one-sided tests for independent binomial proportions when the interest lies in showing non-inferiority and/or superiority", "author": ["J. R\u00f6hmel", "U. Mansmann"], "venue": null, "citeRegEx": "R\u00f6hmel and Mansmann,? \\Q1999\\E", "shortCiteRegEx": "R\u00f6hmel and Mansmann", "year": 1999}, {"title": "Smoothing and differentiation of data by simplified least squares procedures", "author": ["A. Savitzky", "M.J. Golay"], "venue": "Analytical chemistry", "citeRegEx": "Savitzky and Golay,? \\Q1964\\E", "shortCiteRegEx": "Savitzky and Golay", "year": 1964}, {"title": "Linear reconstruction of perceived images from human brain activity", "author": ["S. Schoenmakers", "M. Barth", "T. Heskes", "M. van Gerven", "Jul"], "venue": null, "citeRegEx": "Schoenmakers et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Schoenmakers et al\\.", "year": 2013}, {"title": "The neural basis of loss aversion in decision-making under risk", "author": ["S.M. Tom", "C.R. Fox", "C. Trepel", "Poldrack", "R. a.", "Jan."], "venue": "Science (New York, N.Y.) 315 (5811), 515\u20138.", "citeRegEx": "Tom et al\\.,? 2007", "shortCiteRegEx": "Tom et al\\.", "year": 2007}, {"title": "Spatiotemporal activity estimation for multivoxel pattern analysis with rapid event-related designs", "author": ["B.O. Turner", "Mumford", "J. a.", "Poldrack", "R. a.", "F.G. Ashby", "Sep."], "venue": "NeuroImage 62 (3), 1429\u201338.", "citeRegEx": "Turner et al\\.,? 2012", "shortCiteRegEx": "Turner et al\\.", "year": 2012}, {"title": "Spatially adaptive mixture modeling for analysis of fMRI time series", "author": ["T. Vincent", "L. Risser", "P. Ciuciu"], "venue": "IEEE Transactions on Medical Imaging", "citeRegEx": "Vincent et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Vincent et al\\.", "year": 2010}, {"title": "Encoding and decoding V1 fMRI responses to natural images with sparse nonparametric models. The annals of applied statistics 5 (2B), 1159", "author": ["V.Q. Vu", "P. Ravikumar", "T. Naselaris", "K.N. Kay", "J.L. Gallant", "B. Yu"], "venue": null, "citeRegEx": "Vu et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Vu et al\\.", "year": 2011}, {"title": "Multiscale adaptive smoothing models for the hemodynamic response function in fMRI", "author": ["J. Wang", "H. Zhu", "J. Fan", "K. Giovanello", "W. Lin", "Jun."], "venue": "The Annals of Applied Statistics 7 (2), 904\u2013935.", "citeRegEx": "Wang et al\\.,? 2013", "shortCiteRegEx": "Wang et al\\.", "year": 2013}, {"title": "Constrained linear basis sets for HRF modelling using variational bayes", "author": ["M.W. Woolrich", "T.E.J. Behrens", "S.M. Smith", "Apr."], "venue": "NeuroImage 21 (4), 1748\u201361.", "citeRegEx": "Woolrich et al\\.,? 2004", "shortCiteRegEx": "Woolrich et al\\.", "year": 2004}, {"title": "Nonparametric inference of the hemodynamic response using multisubject fMRI data", "author": ["T. Zhang", "F. Li", "L. Beckes", "C. Brown", "J.A. Coan", "Nov."], "venue": "NeuroImage 63 (3), 1754\u201365.", "citeRegEx": "Zhang et al\\.,? 2012", "shortCiteRegEx": "Zhang et al\\.", "year": 2012}, {"title": "A semiparametric model of the hemodynamic response for multi-subject fMRI data", "author": ["T. Zhang", "F. Li", "L. Beckes", "Coan", "J. a.", "Jul."], "venue": "NeuroImage 75, 136\u201345. 13", "citeRegEx": "Zhang et al\\.,? 2013", "shortCiteRegEx": "Zhang et al\\.", "year": 2013}], "referenceMentions": [{"referenceID": 30, "context": "ing directly on raw BOLD signal (Mour\u00e3o Miranda et al., 2007; Miyawaki et al., 2008), the common approach in fast event-related designs consists in extracting the activation coefficients (beta-maps) from the BOLD signal to perform the decoding analysis on these estimates.", "startOffset": 32, "endOffset": 84}, {"referenceID": 23, "context": "In addition, a third approach, known as representational similarity analysis or RSA (Kriegeskorte et al., 2008) takes as input the activation coefficients.", "startOffset": 84, "endOffset": 111}, {"referenceID": 12, "context": "the General Linear Model (GLM) (Friston et al., 1995).", "startOffset": 31, "endOffset": 53}, {"referenceID": 1, "context": "However it is known (Handwerker et al., 2004; Badillo et al., 2013b) that the shape of this response function can vary substantially across subjects and brain regions.", "startOffset": 20, "endOffset": 68}, {"referenceID": 13, "context": "A common choice of basis is formed by three elements consisting of a reference HRF as well as its time and dispersion derivatives (Friston et al., 1998), although it is also possible to compute a basis set that spans a desired function", "startOffset": 130, "endOffset": 152}, {"referenceID": 48, "context": "space (Woolrich et al., 2004).", "startOffset": 6, "endOffset": 29}, {"referenceID": 25, "context": "More generally, one can also define a parametric model of the HRF and estimate the parameters that best fit this function (Lindquist and Wager, 2007).", "startOffset": 122, "endOffset": 149}, {"referenceID": 16, "context": "For example, temporal regularization has been used in the smooth FIR (Goutte et al., 2000; Ciuciu et al., 2003; Casanova et al., 2008) to favor solutions with small second order time derivative.", "startOffset": 69, "endOffset": 134}, {"referenceID": 6, "context": "For example, temporal regularization has been used in the smooth FIR (Goutte et al., 2000; Ciuciu et al., 2003; Casanova et al., 2008) to favor solutions with small second order time derivative.", "startOffset": 69, "endOffset": 134}, {"referenceID": 4, "context": "For example, temporal regularization has been used in the smooth FIR (Goutte et al., 2000; Ciuciu et al., 2003; Casanova et al., 2008) to favor solutions with small second order time derivative.", "startOffset": 69, "endOffset": 134}, {"referenceID": 15, "context": "Even if efficient techniques such as generalized cross-validation (Golub et al., 1979) can be used to choose the regularization parameters, these methods are inherently more costly than basis-constrained", "startOffset": 66, "endOffset": 86}, {"referenceID": 47, "context": "vantage of the spatially dependent nature of fMRI (Wang et al., 2013).", "startOffset": 50, "endOffset": 69}, {"referenceID": 5, "context": "However, hemodynamically-informed parcellations (Chaari et al., 2012; Badillo et al., 2013a) rely on the computation of a large number of estimations at the voxel or sub-parcel level.", "startOffset": 48, "endOffset": 92}, {"referenceID": 0, "context": "However, hemodynamically-informed parcellations (Chaari et al., 2012; Badillo et al., 2013a) rely on the computation of a large number of estimations at the voxel or sub-parcel level.", "startOffset": 48, "endOffset": 92}, {"referenceID": 27, "context": "Within this model, and as in (Makni et al., 2008; Kay et al., 2008; Vincent et al., 2010; Degras and Lindquist, 2014), the HRF is constrained to be equal across the different conditions, yet permitting it to be different across voxels.", "startOffset": 29, "endOffset": 117}, {"referenceID": 21, "context": "Within this model, and as in (Makni et al., 2008; Kay et al., 2008; Vincent et al., 2010; Degras and Lindquist, 2014), the HRF is constrained to be equal across the different conditions, yet permitting it to be different across voxels.", "startOffset": 29, "endOffset": 117}, {"referenceID": 45, "context": "Within this model, and as in (Makni et al., 2008; Kay et al., 2008; Vincent et al., 2010; Degras and Lindquist, 2014), the HRF is constrained to be equal across the different conditions, yet permitting it to be different across voxels.", "startOffset": 29, "endOffset": 117}, {"referenceID": 9, "context": "Within this model, and as in (Makni et al., 2008; Kay et al., 2008; Vincent et al., 2010; Degras and Lindquist, 2014), the HRF is constrained to be equal across the different conditions, yet permitting it to be different across voxels.", "startOffset": 29, "endOffset": 117}, {"referenceID": 36, "context": "This model was briefly presented in the conference paper (Pedregosa et al., 2013).", "startOffset": 57, "endOffset": 81}, {"referenceID": 32, "context": "We also added results using a GLM with separate designs (Mumford et al., 2012).", "startOffset": 56, "endOffset": 78}, {"referenceID": 44, "context": "case of decoding (Turner et al., 2012) and encoding approaches (Vu et al.", "startOffset": 17, "endOffset": 38}, {"referenceID": 46, "context": ", 2012) and encoding approaches (Vu et al., 2011), we here provide a comprehensive comparison of models.", "startOffset": 32, "endOffset": 49}, {"referenceID": 12, "context": "The original GLM model (Friston et al., 1995) makes the assumption that the hemodynamic response is a linear transformation of the underlying neuronal signal.", "startOffset": 23, "endOffset": 45}, {"referenceID": 3, "context": "We define the n \u00d7 k-matrix XGLM as the columnwise stacking of different regressors, each one defined as the convolution of a reference HRF (Boynton et al., 1996; Glover, 1999)", "startOffset": 139, "endOffset": 175}, {"referenceID": 11, "context": "In this work we used as reference HRF the one provided by the software SPM 8 (Friston et al., 2011).", "startOffset": 77, "endOffset": 99}, {"referenceID": 48, "context": "Other basis functions such as FMRIB\u2019s Linear Optimal Basis Sets (Woolrich et al., 2004) are equally possible but", "startOffset": 64, "endOffset": 87}, {"referenceID": 32, "context": "in (Mumford et al., 2012), however this procedure assumes that the peak BOLD response is located at that time point.", "startOffset": 3, "endOffset": 25}, {"referenceID": 18, "context": "At a given voxel, it is expected that for similar stimuli the estimated HRF are also similar (Henson et al., 2002).", "startOffset": 93, "endOffset": 114}, {"referenceID": 27, "context": "the various stimuli (given that they are sufficiently similar), which should result in more robust estimates (Makni et al., 2008; Vincent et al., 2010).", "startOffset": 109, "endOffset": 151}, {"referenceID": 45, "context": "the various stimuli (given that they are sufficiently similar), which should result in more robust estimates (Makni et al., 2008; Vincent et al., 2010).", "startOffset": 109, "endOffset": 151}, {"referenceID": 32, "context": "An extension to the classical GLM that improves the estimation with correlated designs was proposed in (Mumford et al., 2012).", "startOffset": 103, "endOffset": 125}, {"referenceID": 32, "context": "It has been reported to find a better estimate in rapid event designs leading to a boost in accuracy for decoding tasks (Mumford et al., 2012; Schoenmakers et al., 2013; Lei et al., 2013).", "startOffset": 120, "endOffset": 187}, {"referenceID": 42, "context": "It has been reported to find a better estimate in rapid event designs leading to a boost in accuracy for decoding tasks (Mumford et al., 2012; Schoenmakers et al., 2013; Lei et al., 2013).", "startOffset": 120, "endOffset": 187}, {"referenceID": 24, "context": "It has been reported to find a better estimate in rapid event designs leading to a boost in accuracy for decoding tasks (Mumford et al., 2012; Schoenmakers et al., 2013; Lei et al., 2013).", "startOffset": 120, "endOffset": 187}, {"referenceID": 44, "context": "This approach was further extended in (Turner et al., 2012) to include FIR basis instead of the predefined canon-", "startOffset": 38, "endOffset": 59}, {"referenceID": 44, "context": "See (Turner et al., 2012) for a more complete description of the matrices XBSi and X 1 BSi.", "startOffset": 4, "endOffset": 25}, {"referenceID": 9, "context": "A similar procedure is detailed in (Degras and Lindquist, 2014).", "startOffset": 35, "endOffset": 63}, {"referenceID": 35, "context": "Generic solvers for numerical optimization (Nocedal and Wright, 2006) can then be used.", "startOffset": 43, "endOffset": 69}, {"referenceID": 26, "context": "Some numerical solvers such as L-BFGS-B (Liu and Nocedal, 1989) require the constraints to be given as box constraints.", "startOffset": 40, "endOffset": 63}, {"referenceID": 35, "context": "The line-search procedure was implemented to satisfy the strong Wolfe conditions (Nocedal and Wright, 2006).", "startOffset": 81, "endOffset": 107}, {"referenceID": 21, "context": "The first dataset we will consider is described in (Kay et al., 2008; Naselaris et al., 2009; Kay et al., 2011).", "startOffset": 51, "endOffset": 111}, {"referenceID": 34, "context": "The first dataset we will consider is described in (Kay et al., 2008; Naselaris et al., 2009; Kay et al., 2011).", "startOffset": 51, "endOffset": 111}, {"referenceID": 20, "context": "The first dataset we will consider is described in (Kay et al., 2008; Naselaris et al., 2009; Kay et al., 2011).", "startOffset": 51, "endOffset": 111}, {"referenceID": 21, "context": "As in (Kay et al., 2008), we performed prediction of BOLD signal following the visual presentation of natural images and compared it against the mea-", "startOffset": 6, "endOffset": 24}, {"referenceID": 21, "context": "See (Kay et al., 2008) for further preprocessing details.", "startOffset": 4, "endOffset": 22}, {"referenceID": 41, "context": "We performed local detrending using a Savitzky-Golay filter (Savitzky and Golay, 1964) with a polynomial of degree 4 and a window length of 91 TR.", "startOffset": 60, "endOffset": 86}, {"referenceID": 15, "context": "(regularization parameter chosen by Generalized CrossValidation (Golub et al., 1979)) was then used to learn a predictor of voxel activity on the training set.", "startOffset": 64, "endOffset": 84}, {"referenceID": 21, "context": "In a first step, we perform the image identification task from (Kay et al., 2008).", "startOffset": 63, "endOffset": 81}, {"referenceID": 43, "context": "The second dataset described in (Tom et al., 2007) is a gambling task where each of the 17 subjects was asked", "startOffset": 32, "endOffset": 50}, {"referenceID": 22, "context": "As a performance measure we use Kendall tau rank correlation coefficient (Kendall, 1938) between the true gain levels and the predicted levels, which is a measure for the orderings of the data.", "startOffset": 73, "endOffset": 88}, {"referenceID": 2, "context": "Also, this loss is less sensible to shrinkage of the prediction that might occur when penalizing a regression model (Bekhti et al., 2014).", "startOffset": 116, "endOffset": 137}, {"referenceID": 10, "context": "This metric was previously proposed for fMRI decoding with ordered labels in (Doyle et al., 2013).", "startOffset": 77, "endOffset": 97}, {"referenceID": 40, "context": "We define the null hypothesis H0 as the statement that both probabilities are equal, H0 : pA = pB, and the alternate hypothesis that both probabilities and not equal, H1 : p1 , p2 (this test is sometimes known as the binomial proportion test (R\u00f6hmel and Mansmann, 1999)).", "startOffset": 242, "endOffset": 269}, {"referenceID": 32, "context": "We also observed that models using the GLM with separate designs from (Mumford et al., 2012) perform significantly better on this dataset than the standard design, which is consistent with the purpose of these models.", "startOffset": 70, "endOffset": 92}, {"referenceID": 37, "context": "The decoding regression model consisted of univariate feature selection (ANOVA) followed by a Ridge regression classifier as implemented in scikit-learn (Pedregosa et al., 2011).", "startOffset": 153, "endOffset": 177}, {"referenceID": 29, "context": "focused on voxel-independent models of the HRF, possibly constrained by a basis set, and have omitted for efficiency reasons other possible models such as Bayesian models (Marrelec et al., 2003; Ciuciu et al., 2003; Makni et al., 2005) and regularized methods (Goutte et al.", "startOffset": 171, "endOffset": 235}, {"referenceID": 6, "context": "focused on voxel-independent models of the HRF, possibly constrained by a basis set, and have omitted for efficiency reasons other possible models such as Bayesian models (Marrelec et al., 2003; Ciuciu et al., 2003; Makni et al., 2005) and regularized methods (Goutte et al.", "startOffset": 171, "endOffset": 235}, {"referenceID": 28, "context": "focused on voxel-independent models of the HRF, possibly constrained by a basis set, and have omitted for efficiency reasons other possible models such as Bayesian models (Marrelec et al., 2003; Ciuciu et al., 2003; Makni et al., 2005) and regularized methods (Goutte et al.", "startOffset": 171, "endOffset": 235}, {"referenceID": 16, "context": ", 2005) and regularized methods (Goutte et al., 2000; Casanova et al., 2008).", "startOffset": 32, "endOffset": 76}, {"referenceID": 4, "context": ", 2005) and regularized methods (Goutte et al., 2000; Casanova et al., 2008).", "startOffset": 32, "endOffset": 76}, {"referenceID": 45, "context": "Other models such as spatial models (Vincent et al., 2010), and multi-subject methods (Zhang et al.", "startOffset": 36, "endOffset": 58}, {"referenceID": 27, "context": "Based on ideas from previous literature (Makni et al., 2008; Vincent et al., 2010) we assume the HRF to be equal across conditions but variable across voxels.", "startOffset": 40, "endOffset": 82}, {"referenceID": 45, "context": "Based on ideas from previous literature (Makni et al., 2008; Vincent et al., 2010) we assume the HRF to be equal across conditions but variable across voxels.", "startOffset": 40, "endOffset": 82}], "year": 2014, "abstractText": "Despite the common usage of a canonical, data-independent, hemodynamic response function (HRF), it is known that the shape of the HRF varies across brain regions and subjects. This suggests that a data-driven estimation of this function could lead to more statistical power when modeling BOLD fMRI data. However, unconstrained estimation of the HRF can yield highly unstable results when the number of free parameters is large. We develop a method for the joint estimation of activation and HRF by means of a rank constraint, forcing the estimated HRF to be equal across events or experimental conditions, yet permitting it to differ across voxels. Model estimation leads to an optimization problem that we propose to solve with an efficient quasi-Newton method, exploiting fast gradient computations. This model, called GLM with Rank-1 constraint (R1-GLM), can be extended to the setting of GLM with separate designs which has been shown to improve decoding accuracy in brain activity decoding experiments. We compare 10 different HRF modeling methods in terms of encoding and decoding score on two different datasets. Our results show that the R1-GLM model outperforms competing methods in both encoding and decoding settings, positioning it as an attractive method both from the points of view of accuracy and computational efficiency.", "creator": "LaTeX with hyperref package"}}}