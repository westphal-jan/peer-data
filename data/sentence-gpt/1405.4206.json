{"id": "1405.4206", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "16-May-2014", "title": "Model revision inference for extensions of first order logic", "abstract": "I am Joachim Jansen and this is my research summary, part of my application to the Doctoral Consortium at ICLP'14. I am a PhD student in the Knowledge Representation and Reasoning (KRR) research group, a subgroup of the Declarative Languages and Artificial Intelligence (DTAI) group at the department of Computer Science at KU Leuven. I started my PhD in September 2012, and has been a Fellow of the Technical University of KU Leuven for 18 years, and a Fellow of the Technical University of KU Leuven for 19 years. I have been the Editor of the online news site \"the KML\" for over a year. In recent years I have had quite a few interviews with numerous other scientists. Recently, I have had many conversations with people who are very interested in data science. I have seen a lot of people from across the globe asking me to help the PhD candidates in the field. It is important to mention that there is a huge gap between the number and the number of people that want to work as a scientific scientist. I am not trying to mislead anyone by being biased. I am trying to educate people on the importance of open communication and understanding the fundamental scientific method for understanding the underlying systems and principles of science, and the importance of communication and understanding fundamental science in the fields of biology, artificial intelligence, biology, biology, computer science, computer science. It is my focus that I have decided to contribute to the PhD candidates. As a student, I am always interested in learning about scientific principles and techniques.\n\nI am currently completing my PhD in philosophy, economics, and computer science from a doctoral degree from the University of Oslo. I am now a research fellow and an adviser on KRS research. During my career, I received numerous requests from experts on many issues including artificial intelligence, machine learning, deep learning, and artificial intelligence. However, my research background is highly varied, which is why I decided to pursue my research. I have a background in science, economics, and computer science.\nI have an interest in artificial intelligence, artificial intelligence, artificial intelligence, and AI. I have a strong interest in artificial intelligence and artificial intelligence. My interests in artificial intelligence are deep. In my first job as Professor of Philosophy at KU Leuven I was initially responsible for building a new database of academic papers (ESMA), an academic database that can serve as a repository of all the research papers in KU Leuven", "histories": [["v1", "Fri, 16 May 2014 15:23:24 GMT  (562kb,D)", "http://arxiv.org/abs/1405.4206v1", null]], "reviews": [], "SUBJECTS": "cs.AI", "authors": ["joachim jansen"], "accepted": false, "id": "1405.4206"}, "pdf": {"name": "1405.4206.pdf", "metadata": {"source": "CRF", "title": "Model revision inference for extensions of first order logic", "authors": ["Joachim Jansen"], "emails": ["joachim.jansen@cs.kuleuven.be"], "sections": [{"heading": null, "text": "I can be contacted at joachim.jansen@cs.kuleuven.be or at:\nRoom 01.167 Celestijnenlaan 200A 3001 Heverlee Belgium\nAn extended abstract / full version of a paper accepted to be presented at the Doctoral Consortium of the 30th International Conference on Logic Programming (ICLP 2014), July 19-22, Vienna, Austria"}, {"heading": "1 Problem description", "text": ""}, {"heading": "1.1 Introduction", "text": "The IDP system is a state-of-the-art system for declarative problem solving; complex searchand optimizationproblems are solved in an efficient and generic manner. As time passes on however, the found solution has to be revised: new information (e.g., changed circumstances) has to be taken into account. In this case it is desirable to start from the old (near-)solution and by perfroming a limited amount of changes transform it into a solution in which the new information is processed. At the moment there are no efficient, general solutions for these kind of problems; the only way this problem is currently solved is by writing special-purpose algorithms. During my thesis I would like to devise a general way to solve these problems using IDP as a system supporting an expressive modeling language.\nThe Knowledge Base System (KBS) (De Pooter et al. 2011) paradigm is a declarative approach in which one specifies what needs to be solved, instead of writing procedures that depict how to do this (Apt 2003; Gebser et al. 2012). A KBS represents the knowledge in its explicit form using an expressive modeling language and provides inferences to solve different kinds of problems. The expressive modeling language has as advantage that domains with a very complex or quickly changing knowledge can be expressed in a concise and clear way. Additionally, knowledge can be reused to solve different problems sharing the same scope. Because the inferences are domain independent, they can be reused across different scopes as well.\nOne of these inferences is model revision; the adaptation of an existing solution to new\nar X\niv :1\n40 5.\n42 06\nv1 [\ncs .A\nI] 1\n6 M\nay 2\nFigure 1. An example of a train routing situation\ninformation. In a train dispatching toy-problem for example there are a plethora of unforeseen circumstances (e.g., track defects, delays, copper cable thefts) and the dispatching schedule needs to be adapted to new requirements. Model revision also tries to maintain as much as possible of the original solution (dispatching schedule) when processing the change. This is a consequence of the solution technique that is generally efficient (start from the \u2018old\u2019 solution and apply a limited amount of changes), but is also a desirable property of the computed solution. Indeed, when a train is delayed in Paris, it doesn\u2019t make a lot of sense to change the dispatching schedule of trains in London when this is not necessary."}, {"heading": "1.2 Model revision: a motivating example", "text": "Here we introduce a small motivating example of the model revision inference using the situation depicted in Figure 1.2. In this figure the train tracks are indicated using grey lines between nodes. The train starting in S1 (which we will also call Train1) has to go past stations Brussels and London and the train that starts in S2 ((which we will call Train2) has to visit stations Brussels and Paris. The dispatched route for this is indicated using a green dotted line, that of Train2 is indicated with a red dotted line. Imagine the train track between S1 (Shunting 1, shuntings are intermediary crossroads in train tracks where one can change direction) and P1B (Platform 1 in Brussels) is detected to have broken down. By using model revision we can construct a new route for Train2 in S1 that does not use any broken down train tracks. Figure 2(a) shows a high-quality revised model: a route has been found for Train1 without changing too much to the existing dispatching. Figure 2(b) shows a low-quality revised model: the route for Train1 is correct but an unnecessary change to the route of Train2 was made. The change to the route of Train2 was needed because there is a requirement that states that two trains cannot enter the same station on the same platform (at the same time)."}, {"heading": "1.3 Formal definition of model revision", "text": "The formal definition for the model revision problem is as follows (Wittocx et al. 2009): Given a FO(\u00b7) theory T , a model M for this theory and a collection of domain atoms C. Henceforth C are called the required changes. In the example C is the usage of the tracks between S1 and P1B. Solving model revision for \u3008T,M,C\u3009 means searching a new model M \u2032 of T such that all domain atoms in C all have a different value compaired to their old one in M . M \u2032 is also called the revised model. Figure 2 shows two possible revised models for the example; the broken down train tracks are not used in either case.\n(a) A high-quality revised model (b) A low-quality revised model\nFigure 2. Examples of high- and low-quality revised models\nIn addition to the required changes, one usually has to change other parts of the original solution as well to construct the revised model. We call these other changes between M and M \u2032 the additional changes and denote them with S. In the example the usage of the new route is the additional change.\nOften it is not desirable that the entire original model M is be changed; some elements are immutable. In the example the structure of the train tracks is considered immutable: we are not interested in new solutions that would require us to build additional train tracks (e.g., one between London and Paris). These immutable elements in the problem domain are represented by the limitation G, a set of domain atoms whose value must remain fixed. The revision problem for \u3008T,M,C,G\u3009 is the same as the revision problem for \u3008T,M,C\u3009, except for the extra condition that the additional changes cannot include any of the limitations (i.e., S is disjoint with G)."}, {"heading": "2 Existing Literature", "text": "Model revision allows us to flexibly use with a computed solution by imposing new restrictions. Although this kind of flexible reasoning is essential to a KBS, there is no research for model revision (in its general sense) in the context of an expressive modeling language. Comparable research has been performed in areas of incremental constraint programming (Freeman-Benson et al. 1990) and reactive answer set programming (Gebser et al. 2011). In this research only a limited form of new requirements are supported: one takes into account specific forms of new types of knowledge, but e.g. there is no way to apply previously onforeseen changes. Recent research are also trying to tackle this problem on the SAT level (Abo et al. 2011). These SATlevel techniques are interesting for the implementation that will be provided eventually because IDP uses a SAT solver in its workflow, but do not work in the context of a complex modeling language. There has also been work on trying to construct the solution in such a way that it is \u2018robust\u2019 w.r.t. changes (Climent et al. 2014). For first order logic there is a basic algorithm that takes general changes into account (Wittocx et al. 2009). This will serve as a starting point for my thesis."}, {"heading": "3 Background", "text": "This section contains a short introduction to the used terminology. The following concepts are introduced briefly: Knowledge Base System paradigm (De Pooter et al. 2011), FO(\u00b7) (Blockeel et al. 2013), and the IDP system (De Cat et al. 2013; IDP 2013).\nFigure 3. A conceptual representation of a Knowledge Base System"}, {"heading": "3.1 The language: FO(\u00b7)", "text": "Each declarative system requires a language in which the problems are represented. This language is preferably expressive, so the problem domain can be intuitively expressed. The FO(\u00b7) family of languages has been developed at the KRR group for this purpose.\nFO(\u00b7) is a family of expressive knowledge representation languages that extend classical First Order Logic (FO) with various concepts. Apart from the logical symbols (\u2227, \u2228, \u00ac,\u21d2,\u21d4, \u2203, \u2200), FO(\u00b7) also contains:\nInductive definitions are represented as a set of defining rules. Set expressions of the form {x y : p(x) \u2227 q(y) \u2227 r(x, y)} represent the set of all combinations of x and y such that p(x) \u2227 q(y) \u2227 r(x, y). Aggregates express the result of an aggregate function of a set expression together with a cost\nfunction (for each element in the set). The following aggregate functions are supported: minimum, maximum, sum, product and cardinality.\nExpressive quantifiers such as \u2203=1 (there exists exactly one), \u2203\u22652 (there exists at least two) ... Types and subtypes : each variable is typed in FO(\u00b7). (Partial) functions . These are non-Herbrand functions. Arithmetic operators such as + \u2212, \u00d7, \u00f7, |x|, and %.\nA problem specification in FO(\u00b7) consists of at least three parts: a vocabulary that depicts the domain ontology, a theory containing the constraints for this problem, and a structure that contains the known data about the problem.\nFor a more hands-on introduction to FO(\u00b7) and IDP, the reader is directed to our webpage of examples at http://dtai.cs.kuleuven.be/krr/software/idp-examples"}, {"heading": "3.2 Knowledge Base System", "text": "In a Knowledge Base System (KBS) the data and knowledge (expressed in the modeling language, e.g., FO(\u00b7)) are maintained in a Knowledge Base. A KBS then offers a variety of inferences to solve problems with the knowledge. A conceptual representation of a KBS is displayed in Figure 3.\nAmong these inferences are model expansion (extend a three-valued structure such that it satisfies a theory), model checking (verify whether a given structure satisfies a theory), optimization (extend a three-valued structure to a two-valued structure that satisfies a theory that has the least cost), and model revision (see Section 1.3).\n3.3 The IDP system\nThe IDP system is a state-of-the-art implementation of the KBS paradigm using FO(\u00b7)IDP as its modeling language. The workflow of the IDP system is as follows (De Cat et al. 2013). First the FO(\u00b7) theory is ground into a low-level propositional representation. This representation is called \u201cExtended CNF\u201d or ECNF. It is an extension of CNF with concepts such as inductive definitions (that are ground). Next IDP uses a SAT-solver, MINISAT(ID), to generate solutions based on the grounding. IDP as well as MINISAT(ID) are open-source and available at https://bitbucket.org/krr/idp and respectively https://bitbucket.org/krr/minisatid.\nThe goal of my thesis is to provide support for model revision in the IDP system."}, {"heading": "4 Goal of the research", "text": "The goal of my PhD thesis is to develop logic inference methods for different forms of model revision in the context of the FO(\u00b7) modeling language.\nIn order for this to be possible, we need a mechanism to reason about changes propagating through a theory. To this end, the approximating definition for a theory (Wittocx 2010; Vlaeminck 2012; Vaezipoor et al. 2011) needs to be computed and used to propagate impact of a change to the solution throughout the theory of the problem. The theory behind this currently supports basic FO. For my thesis, I will extend the scope of approximating definition to theories containing more expressive constructs such as inductive definitions, aggregates...\nBecause the approximating definition is a definition that needs to be calculated, there need to be efficient techniques for doing so. It was proposed in (Wittocx 2010) that the definition can be evaluated using any external system that can evaluate definitions (or rules).\nFor model revision there are typically a multitude of possible revisions. There is a need for proper criteria that quantify the quality of a revision. I intend to construct criteria using a domain independent as well as a domain dependent approach. For the domain independent criteria some brute-force metrics such the number of changed domain atoms will be used. In order to properly support domain dependent criteria, a user needs to able to express which revisions are preferred over others. This can be done either by expressing them beforehand using some sort of cost function. For this the knowledge representation language needs to be extended. Another way to do this is to let the user interactively guide the search process for the revision, indicating which choices are preferred."}, {"heading": "5 Current status of the research", "text": "The first part of my PhD consisted of constructing an interface between XSB and IDP for calculating definitions that can be completely evaluated. For this work, the inductive definitions are transformed into rules for tabled Prolog. This was published in TPLP (Jansen et al. 2013).\nFurther I extended IDP to compute the approximating definition using the existing theory concerning this topic. Additionally, IDP was also extended with the possibility to making the input structure as two-valued as possible before grounding using the approximating definition (De Cat et al. 2013) as an alternative approach to the \u201cGround With Bounds\u201d (GWB) technique depicted in (Wittocx 2010; Vlaeminck 2012). Currently benchmarks are being run to compare the two approaches. According to (Vaezipoor et al. 2011) the new approach using approximating definition outperforms the classical GWB technique because it will always\ncompute all possible unit propagation possible (at SAT-level) beforehand. GWB on the other hand sometimes performs cutoffs to increase performance. Preliminary results however contratict this claim.\nAnother claim from (Vaezipoor et al. 2011) is currently being investigated: a \u201csmarter\u201d grounding will affect the search tree as well. A smarter grounding can contain fewer introduced symbols (i.e., Tseitins) because it was detected beforehand that they need not be generated at all. Since these Tseitins are not removed by performing unit propagation at SAT-level, a smarter grounding thus contains (according to the above authors) possbily fewer \u201cautarkies\u201d - irrelevant parts of the search space in which the solver possbibly can waste time. Currently experiments are being run that compare the search behaviour of solver runs on smart, respectively \u201cnaive\u201d groundings."}, {"heading": "6 Preliminary results", "text": "Benchmarks over problems in the P complexity class that are generally solved by evaluating definitions for completely given structures show that a great speedup is achieved compared to the classical approach (Jansen et al. 2013).\nPreliminary results (a complete study is being performed) suggest that making the input structure as two-valued as possible before grounding using approximating definitions is not superior to its counterpart the classic GWB workflow already implemented in IDP. Additionally, there were only very few problems where the grounding was smaller."}, {"heading": "7 Open Issues", "text": "Tasks that still need addressing are the extension of the approximating definition for theories that contain more expressive constructs such as inductive definitions, aggregates... Additionally, the solver MINISAT(ID) will need to be adapted to support model revision. For support of interactively searching for a revision, the solver workflow also needs to be updated to work interactively with user input."}], "references": [{"title": "Reducing chaos in sat-like search: Finding solutions close to a given one", "author": ["I. ABO", "M. DETERS", "R. NIEUWENHUIS", "P. STUCKEY"], "venue": "Theory and Applications of Satisfiability Testing - SAT 2011. 273\u2013286.", "citeRegEx": "ABO et al\\.,? 2011", "shortCiteRegEx": "ABO et al\\.", "year": 2011}, {"title": "Principles of Constraint Programming", "author": ["APT K.R."], "venue": "Cambridge University Press.", "citeRegEx": "R.,? 2003", "shortCiteRegEx": "R.", "year": 2003}, {"title": "Predicate logic as a modeling language: Modeling and solving some machine learning and data mining problems with idp3", "author": ["H. BLOCKEEL", "M. BRUYNOOGHE", "B. BART", "B. DE CAT", "S. DE POOTER", "M. DENECKER", "A. LABARRE", "J. RAMON", "S. VERWER"], "venue": "CoRR abs/1309.6883.", "citeRegEx": "BLOCKEEL et al\\.,? 2013", "shortCiteRegEx": "BLOCKEEL et al\\.", "year": 2013}, {"title": "Robustness and stability in constraint programming under dynamism and uncertainty", "author": ["L. CLIMENT", "R.J. WALLACE", "M.A. SALIDO", "F. BARBER"], "venue": "J. Artif. Intell. Res. (JAIR) 49, 49\u201378.", "citeRegEx": "CLIMENT et al\\.,? 2014", "shortCiteRegEx": "CLIMENT et al\\.", "year": 2014}, {"title": "IDP3: Combining symbolic and ground reasoning for model generation", "author": ["B. DE CAT", "J. JANSEN", "G. JANSSENS"], "venue": "Workshop on Grounding and Transformations for Theories with Variables, La Coru\u00f1a, 15 Sept 2013.", "citeRegEx": "CAT et al\\.,? 2013", "shortCiteRegEx": "CAT et al\\.", "year": 2013}, {"title": "A prototype of a knowledge-based programming environment", "author": ["S. DE POOTER", "J. WITTOCX", "M. DENECKER"], "venue": "CoRR abs/1108.5667.", "citeRegEx": "POOTER et al\\.,? 2011", "shortCiteRegEx": "POOTER et al\\.", "year": 2011}, {"title": "An incremental constraint solver", "author": ["B.N. FREEMAN-BENSON", "J. MALONEY", "A. BORNING"], "venue": "Commun. ACM 33, 1, 54\u201363.", "citeRegEx": "FREEMAN.BENSON et al\\.,? 1990", "shortCiteRegEx": "FREEMAN.BENSON et al\\.", "year": 1990}, {"title": "Reactive answer set programming", "author": ["M. GEBSER", "T. GROTE", "R. KAMINSKI", "T. SCHAUB"], "venue": "Logic Programming and Nonmonotonic Reasoning. Lecture Notes in Computer Science, vol. 6645. 54\u201366.", "citeRegEx": "GEBSER et al\\.,? 2011", "shortCiteRegEx": "GEBSER et al\\.", "year": 2011}, {"title": "Answer Set Solving in Practice", "author": ["M. GEBSER", "R. KAMINSKI", "B. KAUFMANN", "T. SCHAUB"], "venue": "Synthesis Lectures on Artificial Intelligence and Machine Learning. Morgan & Claypool Publishers.", "citeRegEx": "GEBSER et al\\.,? 2012", "shortCiteRegEx": "GEBSER et al\\.", "year": 2012}, {"title": "The IDP system", "author": ["IDP"], "venue": "http://dtai.cs.kuleuven.be/krr/software. JANSEN, J., JORISSEN, A., AND JANSSENS, G. 2013. Compiling input\u2217 FO(\u00b7) inductive definitions into tabled Prolog rules for IDP. Theory and Practice of Logic Programming (TPLP) 13, 4-5, 691\u2013704.", "citeRegEx": "IDP,? 2013", "shortCiteRegEx": "IDP", "year": 2013}, {"title": "Lifted unit propagation for effective grounding", "author": ["P. VAEZIPOOR", "D. MITCHELL", "M. MARI\u00cbN"], "venue": "CoRR abs/1109.1317.", "citeRegEx": "VAEZIPOOR et al\\.,? 2011", "shortCiteRegEx": "VAEZIPOOR et al\\.", "year": 2011}, {"title": "Applications of feasible inference for expressive logics", "author": ["H. VLAEMINCK"], "venue": "Ph.D. thesis, Department of Computer Science, K.U.Leuven, Leuven, Belgium. Approximating Definitions are introduced in chapter", "citeRegEx": "VLAEMINCK,? 2012", "shortCiteRegEx": "VLAEMINCK", "year": 2012}, {"title": "Finite domain and symbolic inference methods for extensions of first-order logic", "author": ["J. WITTOCX"], "venue": "Ph.D. thesis, Department of Computer Science, K.U.Leuven, Leuven, Belgium.", "citeRegEx": "WITTOCX,? 2010", "shortCiteRegEx": "WITTOCX", "year": 2010}, {"title": "Towards computing revised models for FO theories", "author": ["J. WITTOCX", "B. DE CAT", "M. DENECKER"], "venue": "INAP, S. Abreu and D. Seipel, Eds. 199\u2013212.", "citeRegEx": "WITTOCX et al\\.,? 2009", "shortCiteRegEx": "WITTOCX et al\\.", "year": 2009}], "referenceMentions": [{"referenceID": 8, "context": "2011) paradigm is a declarative approach in which one specifies what needs to be solved, instead of writing procedures that depict how to do this (Apt 2003; Gebser et al. 2012).", "startOffset": 146, "endOffset": 176}, {"referenceID": 13, "context": "The formal definition for the model revision problem is as follows (Wittocx et al. 2009): Given a FO(\u00b7) theory T , a model M for this theory and a collection of domain atoms C.", "startOffset": 67, "endOffset": 88}, {"referenceID": 6, "context": "Comparable research has been performed in areas of incremental constraint programming (Freeman-Benson et al. 1990) and reactive answer set programming (Gebser et al.", "startOffset": 86, "endOffset": 114}, {"referenceID": 7, "context": "1990) and reactive answer set programming (Gebser et al. 2011).", "startOffset": 42, "endOffset": 62}, {"referenceID": 0, "context": "Recent research are also trying to tackle this problem on the SAT level (Abo et al. 2011).", "startOffset": 72, "endOffset": 89}, {"referenceID": 3, "context": "changes (Climent et al. 2014).", "startOffset": 8, "endOffset": 29}, {"referenceID": 13, "context": "For first order logic there is a basic algorithm that takes general changes into account (Wittocx et al. 2009).", "startOffset": 89, "endOffset": 110}, {"referenceID": 2, "context": "2011), FO(\u00b7) (Blockeel et al. 2013), and the IDP system (De Cat et al.", "startOffset": 13, "endOffset": 35}, {"referenceID": 9, "context": "2013), and the IDP system (De Cat et al. 2013; IDP 2013).", "startOffset": 26, "endOffset": 56}, {"referenceID": 12, "context": "To this end, the approximating definition for a theory (Wittocx 2010; Vlaeminck 2012; Vaezipoor et al. 2011) needs to be computed and used to propagate impact of a change to the solution throughout the theory of the problem.", "startOffset": 55, "endOffset": 108}, {"referenceID": 11, "context": "To this end, the approximating definition for a theory (Wittocx 2010; Vlaeminck 2012; Vaezipoor et al. 2011) needs to be computed and used to propagate impact of a change to the solution throughout the theory of the problem.", "startOffset": 55, "endOffset": 108}, {"referenceID": 10, "context": "To this end, the approximating definition for a theory (Wittocx 2010; Vlaeminck 2012; Vaezipoor et al. 2011) needs to be computed and used to propagate impact of a change to the solution throughout the theory of the problem.", "startOffset": 55, "endOffset": 108}, {"referenceID": 12, "context": "It was proposed in (Wittocx 2010) that the definition can be evaluated using any external system that can evaluate definitions (or rules).", "startOffset": 19, "endOffset": 33}, {"referenceID": 12, "context": "2013) as an alternative approach to the \u201cGround With Bounds\u201d (GWB) technique depicted in (Wittocx 2010; Vlaeminck 2012).", "startOffset": 89, "endOffset": 119}, {"referenceID": 11, "context": "2013) as an alternative approach to the \u201cGround With Bounds\u201d (GWB) technique depicted in (Wittocx 2010; Vlaeminck 2012).", "startOffset": 89, "endOffset": 119}, {"referenceID": 10, "context": "According to (Vaezipoor et al. 2011) the new approach using approximating definition outperforms the classical GWB technique because it will always", "startOffset": 13, "endOffset": 36}, {"referenceID": 10, "context": "Another claim from (Vaezipoor et al. 2011) is currently being investigated: a \u201csmarter\u201d grounding will affect the search tree as well.", "startOffset": 19, "endOffset": 42}], "year": 2014, "abstractText": "I am Joachim Jansen and this is my research summary, part of my application to the Doctoral Consortium at ICLP\u201814. I am a PhD student in the Knowledge Representation and Reasoning (KRR) research group, a subgroup of the Declarative Languages and Airtificial Intelligence (DTAI) group at the department of Computer Science at KU Leuven. I started my PhD in September 2012. My promotor is prof. dr. ir. Gerda Janssens and my co-promotor is prof. dr. Marc Denecker. I can be contacted at joachim.jansen@cs.kuleuven.be or at:", "creator": "LaTeX with hyperref package"}}}