{"id": "1405.5646", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "22-May-2014", "title": "Mathematical Programming Strategies for Solving the Minimum Common String Partition Problem", "abstract": "The minimum common string partition problem is an NP-hard combinatorial optimization problem with applications in computational biology. In this work we propose the first integer linear programming model for solving this problem. Moreover, on the basis of the integer linear programming model we develop a deterministic 2-phase heuristic which is applicable to larger problem instances with a minimum number of iterations. We propose that this model should represent a realizable problem problem in a linear manner. This model has a high-level and non-implemented-linear algorithm which will help solve any problems, especially problems where multiple integers or the smallest number of iterations will result in a single linear programming solution. It also has a robust computational framework.\n\n\n\n\n\nFigure 2. Example 1. Linear-programming models for linear programming.\nIn this simulation, a small number of integers can be assigned to the solution and solved by the algorithm.\nThis model will show a linear programming model, where the number of iterations in the solution is defined as a given integer.\nThis model will show an algorithm with a minimum number of iterations and has a minimum number of iterations with a minimum number of iterations with a minimum number of iterations. The resulting results are shown as linear-programming model:\nFigure 2. Example 2. Linear-programming models for linear programming.\nIn this simulation, the algorithm will show the algorithm with a minimum number of iterations and has a minimum number of iterations with a minimum number of iterations with a minimum number of iterations with a minimum number of iterations with a minimum number of iterations with a minimum number of iterations with a minimum number of iterations with a minimum number of iterations with a minimum number of iterations with a minimum number of iterations with a minimum number of iterations with a minimum number of iterations with a minimum number of iterations with a minimum number of iterations with a minimum number of iterations with a minimum number of iterations with a minimum number of iterations with a minimum number of iterations with a minimum number of iterations with a minimum number of iterations with a minimum number of iterations with a minimum number of iterations with a minimum number of iterations with a minimum number of iterations with a minimum number of iterations with a minimum number of iterations with a minimum number of iterations with a minimum number of iterations with a minimum number of iterations with a minimum number of iterations with a minimum number of iterations with a minimum number of iterations with a minimum number of iterations with a minimum number of iterations with a minimum number of iterations with a minimum number of iterations with a minimum number of iterations with a", "histories": [["v1", "Thu, 22 May 2014 07:37:56 GMT  (46kb,D)", "http://arxiv.org/abs/1405.5646v1", null]], "reviews": [], "SUBJECTS": "cs.AI cs.DS", "authors": ["christian blum", "jos\\'e a lozano", "pedro pinacho davidson"], "accepted": false, "id": "1405.5646"}, "pdf": {"name": "1405.5646.pdf", "metadata": {"source": "CRF", "title": "Mathematical Programming Strategies for Solving the Minimum Common String Partition Problem", "authors": ["Christian Blum", "Jos\u00e9 A. Lozano", "Pedro Pinacho Davidson"], "emails": ["christian.blum@ehu.es", "ja.lozano@ehu.es", "ppinacho@santotomas.cl"], "sections": [{"heading": "1 Introduction", "text": "Optimization problems related to strings\u2014such as protein or DNA sequences\u2014are very common in bioinformatics. Examples include string consensus problems such as the far-from most string problem [20, 19], the longest common subsequence problem and its variants [14, 22], and alignment problems [12]. These problems are often computationally very hard, if not even NP -hard [9]. In this work we deal with the minimum common string partition (MCSP) problem, which can be described as follows. We are given two related input strings that have to be partitioned each into the same collection of substrings. The size of the collection is subject to minimization. A formal description of the problem will be provided in Section 1.1. The MCSP problem has applications, for example, in the bioinformatics field. Chen et al. [2] point out that the MCSP problem is closely related to the problem of sorting by reversals with duplicates, a key problem in genome rearrangement.\nar X\niv :1\n40 5.\n56 46\nv1 [\ncs .A\nIn this paper we introduce the first integer linear program (ILP) for solving the MCSP problem. An experimental evaluation on problem instances from the related literature shows that this ILP can be efficiently solved, for example, by using any version of IBM ILOG CPLEX. However, a study on new instances of larger size demonstrates the limitations of the model. Therefore, we additionally introduce a deterministic 2-phase heuristic which is strongly based on the original ILP. The experimental evaluation shows that the heuristic is applicable to larger problem instances than the original ILP. Moreover, it is shown that the heuristic outperforms competitor algorithms from the related literature on known problem instances."}, {"heading": "1.1 Problem Description", "text": "The MCSP problem can technically be described as follows. Given are two input strings s1 and s2, both of length n over a finite alphabet \u03a3. These two strings are required to be related, which means that each letter appears the same number of times in each of them. Note that this definition implies that s1 and s2 have the same length. A valid solution to the MCSP problem is obtained by partitioning s1 into a set P1 of non-overlapping substrings, and s2 into a set P2 of non-overlapping substrings, such that P1 = P2. Moreover, we are interested in finding a valid solution such that |P1| = |P2| is minimal.\nConsider the following example. Given are DNA sequences s1 = AGACTG and s2 = ACTAGG. Obviously, s1 and s2 are related because A and G appear twice in both input strings, while C and T appear once. A trivial valid solution can be obtained by partitioning both strings into substrings of length 1, that is, P1 = P2 = {A,A,C,T,G,G}. The objective function value of this solution is 6. However, the optimal solution, with objective function value 3, is P1 = P2 = {ACT,AG,G}."}, {"heading": "1.2 Related Work", "text": "The MCSP problem has been introduced by Chen et al. [2] due to its relation to genome rearrangement. More specifically, it has applications in biological questions such as: May a given DNA string possibly be obtained by rearrangements of another DNA string? The general problem has been shown to be NP -hard even in very restrictive cases [10]. Other papers concerning problem hardness consider, for example, the k-MCSP problem, which is the version of the MCSP problem in which each letter occurs at most k times in each input string. The 2-MCSP problem was shown to be APX-hard in [10]. When the input strings are over an alphabet of size c, the corresponding problem is denoted as MCSPc. Jiang et al. proved that the decision version of the MCSPc problem is NP -complete when c \u2265 2 [15].\nThe MCSP has been considered quite extensively by researchers dealing with the approximability of the problem. Cormode and Muthukrishnan [4], for example, proposed an O(lognlog\u2217n)-approximation for the edit distance with moves problem, which is a more general case of the MCSP problem. Shapira and Storer [21] extended on this result. Other approximation approaches for the MCSP problem have been proposed in [18]. In this context, Chrobak et al. [3] studied a simple greedy approach for the MCSP problem, showing that the approximation ratio concerning the 2-MCSP problem is 3, and for the 4-MCSP problem the approximation ratio is \u2126(log(n)). In the case of the general MCSP problem, the approximation ratio is between \u2126(n0.43) and O(n0.67), assuming that the input strings use an alphabet of size O(log(n)). Later Kaplan and Shafir [16] raised the lower bound to \u2126(n0.46).\nKolman proposed a modified version of the simple greedy algorithm with an approximation ratio of O(k2) for the k-MCSP [17]. Recently, Goldstein and Lewenstein proposed a greedy algorithm for the MCSP problem that runs in O(n) time (see [11]). He [13] introduced a greedy algorithm with the aim of obtaining better average results.\nDamaschke [5] was the first one to study the fixed-parameter tractability (FPT) of the problem. Later, Jiang et al. [15] showed that both the k-MCSP and MCSPc problems admit FPT algorithms when k and c are constant parameters. Finally, Fu et al. [8] proposed a O(2nnO(1)) time algorithm for the general case and an O(n(logn)2) time algorithm applicable under some constraints.\nTo our knowledge, the only metaheuristic approaches that have been proposed in the related literature for the MCSP problem are (1) the MAX -MIN Ant System by Ferdous and Sohel [6, 7] and (2) the probabilistic tree search algorithm by Blum et al. [1]. Both works applied their algorithm to a range of artificial and real DNA instances from [6]."}, {"heading": "1.3 Organization of the Paper", "text": "The remaining part of the paper is organized as follows. In Section 2, the ILP model for solving the MCSP is outlined. Moreover, an experimental evaluation is provided. The deterministic heuristic, together with an experimental evaluation, is described in Section 3. Finally, in Section 4 we provide conclusions and an outlook to future work."}, {"heading": "2 An Integer Linear Program to Solve the MCSP", "text": "In the following we present the first ILP model for solving the MCSP. For this, the definitions provided in the following are required. Note that an illustrative example is provided in Section 2.3."}, {"heading": "2.1 Preliminaries", "text": "Henceforth, a common block bi of input strings s1 and s2 is denoted as a triple (ti, k1i, k2i) where ti is a string which can be found starting at position 1 \u2264 k1i \u2264 n in string s1 and starting at position 1 \u2264 k2i \u2264 n in string s2. Moreover, let B = {b1, . . . , bm} be the (ordered) set of all possible common blocks of s1 and s2.\n1 Given the definition of B, any valid solution S to the MCSP problem is a subset of B\u2014that is, S \u2282 B\u2014such that:\n1. \u2211\nbi\u2208S |ti| = n, that is, the sum of the length of the strings corresponding to the common blocks in S is equal to the length of the input strings.\n2. For any two common blocks bi, bj \u2208 S it holds that their corresponding strings neither overlap in s1 nor in s2.\nMoreover, any (valid) partial solution Spartial is a subset of B fulfilling the following conditions: (1) \u2211 bi\u2208Spartial |ti| < n and (2) for any two common blocks bi, bj \u2208 Spartial it holds that their corresponding strings neither overlap in s1 nor in s2. Note that any valid partial solution can be extended to be a valid solution. Furthermore, given a partial solution Spartial, set B(Spartial) \u2282 B denotes the set of common blocks that may be used in order to extend Spartial such that the result is again a valid (partial) solution.\n1The way in which B is ordered is of no importance."}, {"heading": "2.2 The Integer Linear Program", "text": "First, two binary m \u00d7 n matrices M1 and M2 are defined as follows. In both matrices, row 1 \u2264 i \u2264 m corresponds to common block bi \u2208 B. Moreover, a column 1 \u2264 j \u2264 n corresponds to position j in input string s1, respectively s2. In general, the entries of matrix M1 are set to zero. However, in each row i, the positions that string ti (of common block bi) occupies in input string s1 are set to one. Correspondingly, the entries of matrix M2 are set to zero, apart from the fact that in each row i the positions occupied by string ti in input string s2 are set to one. Henceforth, the position (i, j) of a matrix M is denoted by Mi,j . Finally, we introduce for each common block bi \u2208 B a binary variable xi. With these definitions we can express the MCSP in form of the following integer linear program, henceforth referred to by Ilporig.\nmin m\u2211 i=1 xi\nsubject to: m\u2211 i=1 |ti| \u00b7 xi = n\nm\u2211 i=1 M1i,j \u00b7 xi = 1 for j = 1, . . . , n\nm\u2211 i=1 M2i,j \u00b7 xi = 1 for j = 1, . . . , n\nxi \u2208 {0, 1} for i = 1, . . . ,m\n(1)\n(2)\n(3)\n(4)\nHereby, the objective function minimizes the number of selected common blocks. Constraint (2) ensures that the sum of the length of the strings corresponding to the selected common blocks is equal to n. Finally, constraints (3) make sure that the strings corresponding to the selected common blocks do not overlap in input string s1, while constraints (4) make sure that the strings corresponding to the selected common blocks do not overlap in input string s2."}, {"heading": "2.3 Example", "text": "As an example, consider the small problem instance from Section 1.1. The complete set of common blocks (B) as induced by input strings s1 = AGACTG and s2 = ACTAGG is as\nfollows:\nB =  b1 =(ACT, 3, 1) b2 =(AG, 1, 4) b3 =(AC, 3, 1) b4 =(CT, 4, 2) b5 =(A, 1, 1) b6 =(A, 1, 4) b7 =(A, 3, 1) b8 =(A, 3, 4) b9 =(C, 4, 2) b10 =(T, 5, 3) b11 =(G, 2, 5) b12 =(G, 2, 6) b13 =(G, 6, 5) b14 =(G, 6, 6)  Given set B, matrices M1 and M2 are the following ones:\nM1 =  0 0 1 1 1 0 1 1 0 0 0 0 0 0 1 1 0 0 0 0 0 1 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 \nM2 =  1 1 1 0 0 0 0 0 0 1 1 0 1 1 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 1  The optimal solution to this instance is S = {b1, b2, b14}. It can easily be verified that this\nsolution respects constraints (2-4) of the ILP model."}, {"heading": "2.4 Experimental Evaluation", "text": "In the following we will provide an experimental evaluation of model Ilporig. The model was implemented in ANSI C++ using GCC 4.7.3 for compiling the software. Moreover, the model was solved with IBM ILOG CPLEX V12.1. The experimental results that we outline in the following were obtained on a cluster of PCs with \u201dIntel(R) Xeon(R) CPU 5130\u201d CPUs of 4 nuclei of 2000 MHz and 4 Gigabyte of RAM."}, {"heading": "2.4.1 Problem Instances", "text": "For testing model Ilporig we chose the same set of benchmark instances that was used by Ferdous and Sohel in [6] for the experimental evaluation of their ant colony optimization approach. This set contains, in total, 30 artificial instances and 15 real-life instances consisting\nof DNA sequences. Remember, in this context, that each problem instance consists of two related input strings. Moreover, the benchmark set consists of four subsets of instances. The first subset (henceforth labelled Group1) consists of 10 artificial instances in which the input strings are maximally of length 200. The second set (Group2) consists of 10 artificial instances with input string lengths between 201 and 400. In the third set (Group3) the input strings of the 10 artificial instances have lengths between 401 and 600. Finally, the fourth set (Real) consists of 15 real-life instances of various lengths."}, {"heading": "2.4.2 Results", "text": "The results are shown in Tables 1-4, in terms of one table per instance set. The structure of these tables is as follows. The first column provides the instance identifiers. The second column contains the results of the greedy algorithm from [3] (results were taken from [6]). The third column provides the value of the best solution found in four independent runs per problem instance (with a CPU time limit of 7200 seconds per run) by the Aco approach by Ferdous and Sohel [6, 7].2 The fourth column provides the value of the best solution found in 10 independent runs per problem instance (with a CPU time limit of 1000 seconds per run) by the probabilistic tree search algorithm (henceforth labelled TreSea) by Blum et al. [1]. TreSea was run on the same machines as the ones used for the current work. Finally, the last four table columns are dedicated to the presentation of the results provided by solving model Ilporig. The first one of these columns provides the value of the best solution found within 3600 CPU seconds. In case the optimality of the corresponding solution was proved by CPLEX, the value is marked by an asterix. The second column dedicated to Ilporig provides the computation time (in seconds). In case of having solved the corresponding problem to optimality, this column only displays one value indicating the time needed by CPLEX to solve the problem. Otherwise, this column provides two values in the form X/Y, where X corresponds to the time at which CPLEX was able to find the first valid solution, and Y corresponds to the time at which CPLEX found the best solution within 3600 CPU seconds. The third one of the columns dedicated to Ilporig shows the optimality gap, which refers to the gap between the value of the best valid solution and the current lower bound at the time of stopping a run. Finally, the last column indicates the size of set B, that is, the size of the complete set of common blocks. Note that this value corresponds to the number of variables used by Ilporig. The best result (among all algorithms) for each problem instance is marked by a grey background, and the last row of each table provides averages over the whole table.\nThe following conclusions can be drawn when analyzing the results. First, CPLEX is able to solve all instances of Group1 to optimality. This is done, on average, in about 13 seconds. Moreover, none of the existing algorithms was able to find any of these optimal solutions. Second, CPLEX was also able to find new best-known solutions for all remaining 35 problem instances, even though it was not able to prove optimality within 3600 CPU seconds, which is indicated by the positive optimality gaps. An exception is instance 1 of set Real which also could be solved to optimality. Third, the improvements over the competitor algorithms obtained by solving Ilporig with CPLEX are remarkable. In particular, the average improvement (in percent) over TreSea, the best competitor from the literature, is 4.8% in the case of Group1, 9.2% in the case of Group2, 9.7% in the case of Group3, and 9.8% in the case\n2In this context, note that the experiments for Aco were performed on a computer with an \u201dIntel(R) 2 Quad\u201d CPU with 2.33 GHz and 4 GB of RAM.\nof Real.\nIn order to study the limits of solving Ilporig with CPLEX we randomly generated larger DNA instances. In particular, we generated one random instance for each input string size from {800, 1000, 1200, 1400, 1600, 1800, 2000}. CPLEX was stopped when at least 3600 CPU seconds had passed and at least one feasible solution had been found. However, if after 12 CPU hours still no feasible solution was found, the execution was stopped as well. The\nresults are shown in Table 5. The first column of this table provides the length of the corresponding random instance. The remaining four columns contain the same information as already explained in the context of Tables 1-4, just that column time (s) simply provides the computation time (in seconds) at which the best solution was found. Analyzing the results we can observe that the application of CPLEX to Ilporig quickly becomes unpractical with growing input string size. For example, the first valid solution for the instance with string length 1400 was found after 20616 seconds. Concerning the largest problem instance, no valid solution was found within 12 CPU hours."}, {"heading": "3 A MIP-Based Heuristic", "text": "As shown at the end of the previous section, the application of CPLEX to Ilporig reaches its limits starting from an input string size of about 1200. However, if it were possible to considerably reduce the size of the set of common blocks (B), mathematical programming might still be an option to obtain good (heuristic) solutions. With this idea in mind we studied the distribution of the lengths of the strings of the common blocks in B for all 45 problem instances. This distribution is shown\u2014averaged over the instances of each of the four instance sets\u2013in Figure 1. Analyzing these distributions it can be observed, first of all,\nthat the distribution does not seem to depend on instance size.3 However, the important aspect to observe is that around 75% of all the common blocks contain strings of length 1. Moreover, only a very small portion of these common blocks will form part of an optimal solution. In comparison, it is reasonable to assume that a much larger percentage of the blocks corresponding to large strings will form part of an optimal solution. These observations gave rise to the heuristic which is outlined in the following."}, {"heading": "3.1 Heuristic", "text": "The proposed heuristic works in two phases. In the first phase, a subset of B (the complete set of common blocks) must be chosen. For this purpose, let B\u2265l (where l \u2265 1) denote the subset of B that contains all common blocks bi from B with |ti| \u2265 l, that is, all blocks whose corresponding string is longer or equal than l. Note, in this context, that B\u22651 = B. Moreover, note that |B\u22651| \u2265 |B\u22652| \u2265 |B\u22653| \u2265 . . . \u2265 |B\u2265\u221e|. Let lmax be the smallest value for l such that |B\u2265lmax | > 0. Observe that B\u2265lmax only contains the common blocks with the longest strings. Having chosen a specific value for l from [2, lmax], the following ILP, henceforth referred to as Ilpph1, may be solved.\n3Most probably the distribution would change in some way when changing the size of the alphabet.\nmax \u2211\nbi\u2208B\u2265l\n(C \u00b7 |ti| \u2212 1) \u00b7 xi\nsubject to:\u2211 bi\u2208B\u2265l |ti| \u00b7 xi \u2264 n\n\u2211 bi\u2208B\u2265l M1i,j \u00b7 xi \u2264 1 for j = 1, . . . , n\n\u2211 bi\u2208B\u2265l M2i,j \u00b7 xi \u2264 1 for j = 1, . . . , n\nxi \u2208 {0, 1} for bi \u2208 B\u2265l\n(5)\n(6)\n(7)\n(8)\nIlpph1 is based on a binary variable xi for each common block bi \u2208 B\u2265l. Moreover, matrices M1 and M2 are the same as the ones introduced in Section 2.2, that is, they are defined over the whole set B. The objective function basically maximizes the sum of the lengths of the strings corresponding to the chosen common blocks. However, the length of the string corresponding to each block is multiplied by a large-enough constant C, and the result is decremented by one. This has the following effect. In case of several solutions for which the sum of the lengths of the strings corresponding to the selected common blocks is equal, the program prefers the solution that reaches this sum with fewer common blocks. The constraints (6-8) are the same as in Ilporig (see Section 2.2), apart from the fact that all equality symbols are replaced by the \u2264-symbol. In short, the idea of Ilpph1 is to produce a partial solution for the original MCSP that covers as much as possible of both input strings, while choosing as few common blocks as possible.\nSolving Ilpph1 will henceforth be referred to as phase 1 of the proposed heuristic. Let us denote by Sph1 the solution provided by phase 1.4 Due to the constraints of Ilpph1 this solution is a valid partial solution to the original MCSP problem. The idea of the second phase is then to produce the best complete solution possible that contains Sph1. This is done by solving the following ILP, henceforth referred to as Ilpph2.\nmin \u2211\nbi\u2208Bph2\nxi\nsubject to:\u2211 bi\u2208Bph2 |ti| \u00b7 xi = n\n\u2211 bi\u2208Bph2 M1i,j \u00b7 xi = 1 for j = 1, . . . , n\n\u2211 bi\u2208Bph2 M2i,j \u00b7 xi = 1 for j = 1, . . . , n\nxi = 1 for bi \u2208 Sph1 xi \u2208 {0, 1} for bi \u2208 Bph2\n(9)\n(10)\n(11)\n(12)\n(13)\n4Remember that solutions are subsets of B.\nHereby, Bph2 := B(Sph1) \u2282 B is the set of common blocks that may be added to Sph1 without violating any constraints.5 Note that model Ilpph2 is the same as model Ilporig, just that Ilpph2 only considers common blocks from Bph2 and that it forces any solution to contain all common blocks from Sph1; see constraints (13). This completes the description of the heuristic."}, {"heading": "3.2 Experimental Evaluation", "text": "Just like model Ilporig, the heuristic was implemented in ANSI C++ using GCC 4.7.3 for compiling the software. The two ILP models were solved with IBM ILOG CPLEX V12.1, and the same machines as for the experimental evaluation of Ilporig were used for running the experiments.\nAs mentioned before, the heuristic may be applied for any value of l from the interval [2, lmax]. In fact, we applied the heuristic to each of the 45 problem instances from sets Group1, Group2, Group3, and Real, with all possible values for l. In order not to spend too much computation time the following stopping criterion was used for each call to CPLEX concerning any of the two involved ILP models. CPLEX was stopped (1) in case a provenly optimal solution was obtained or (2) in case at least 50 CPU seconds were spent and the first valid solution was obtained. The overall result of the heuristic for a specific problem instance is the value of the best solution found for any value of l. Moreover, as computation time we provide the sum of the computation times spend for all applications for different value of l.\nThe results are shown in Table 6, which contains one subtable for each of the four instance sets. Each subtable has the following format. The first column provides the instance identifier. The second column contains the value of the best solution found in the literature. Finally, the last two table columns present the results of our heuristic. The first one of these columns contains the value of the best solution generated by the heuristic, while the second column provides the total computation time (in seconds). The last row of each subtable presents averages over the whole subtable. Moreover, the best result for each instance is marked by a grey background, and those cases in which the result of applying CPLEX to Ilporig could be matched are marked by a \u201d+\u201d symbol.\nThe results allow to make the following observations. First, our heuristic is able to improve the best-known result from the literature in 37 out of 46 cases. In further six cases the bestknown results from the literature are matched. Finally, in two remaining cases the heuristic is not able to produce a solution that is at least as good as the best-known solution known from the literature. Overall, the heuristic improves by 3.4% (on average) over the best known results from the literature. On the downside, the heuristic is only able to match the results of applying CPLEX to model Ilporig in three out of 45 cases. However, this changes with growing instance size, as we will show later in Section 3.4."}, {"heading": "3.3 Gaining Insight into the Behavior of the Heuristic", "text": "With the aim of gaining more insight into the behavior of the heuristic with respect to the choice of a value for parameter l, the following information is presented in graphical form in Figure 2. Two graphics are shown for each of the four chosen problem instances. More precisely, we chose to present information for the largest problem instances from each of the four\n5See Section 2.1 for the definition of B(\u00b7).\ninstance sets (see subfigures (a) to (d) of Figure 2). The left graphic of each subfigure has to be read as follows. The x-axis ranges over the possible values for l, while the y-axis indicates the size of the set of common blocks that is used for solving models Ilpph1 and Ilpph2. The graphic shows two curves. The one with a black line concerns solving model Ilpph1 in phase 1 of the heuristic, while the other one (shown by means of a grey line) concerns solving model Ilpph2 in phase two of the heuristic. The dots indicate for each value of l the size of the set of common blocks used by the corresponding models. Moreover, in case the interior of a dot is light-grey (yellow in the online version) this means that the corresponding model could not be solved to optimality within 50 CPU seconds, while a black interior of a dot indicates that the corresponding model was solved to optimality. Finally, the bars in the background of the graphic present the values of the solutions that were generated with different values of l. The graphics on the right hand side present the corresponding computation times required by solving the different models.\nThe following observations can be made. When the value of l is close to the lower or\nthe upper bound\u2014that is, either close to 2 or close to lmax\u2014one of the two involved sets of common blocks is quite large, and, therefore, the computation time needed for solving the corresponding ILP may be large, in particular when the input instance is rather large. On the contrary, for intermediate values of l, the size of both involved sets of common blocks is moderate, and, therefore, CPLEX is rather fast in providing solutions, even if the optimal solution is not found (or can not be proven) within 50 CPU seconds. Moreover, the best results are usually obtained for intermediate values of l. This is with the exception of instance 10 of Group1, which might be an anomaly caused by the rather small size of the problem instance."}, {"heading": "3.4 Results of Heuristic for Larger Instances", "text": "Based on the findings of the previous subsection the heuristic was applied with an intermediate value of l = 5 to all problem instances from the set of larger instances described at the end of Section 2.4.2. The results are shown in Table 7. The first table column provides the length of the input strings of the corresponding random instance. The second column indicates the result of applying CPLEX with a computation time limit of 3600 CPU seconds to Ilporig. 6 The remaining five columns contain the results of heuristic. The first one of these columns provides the value of the solution generated by the heuristic, while the second column shows the corresponding computation time. The next two columns provide the size of the sets of common blocks used in phase 1, respectively phase 2, of the heuristic. Finally, the last column gives information about the number of common blocks considered by the heuristic in comparison to the size of the complete set of common blocks (which can be found in Table 5). In particular, summing the common block set sizes from phases 1 and 2 of the heuristic and comparing this number with the size of the complete set of common blocks, the percentage of the common blocks considered by the heuristic can easily be calculated. This percentage is given in the last table column. As in all tables of this paper, the best result per table row is marked by a grey background.\nThe following observations can be made. First, apart from the smallest problem instance, the heuristic outperforms the application of CPLEX to model Ilporig. Moreover, this is achieved in a fraction of the time needed by CPLEX. Finally, it is reasonable to assume that the success of the heuristic is due to an important reduction of the common blocks that are considered (see last table column). In general, the heuristic only considers between 3.3% and 6.5% of all common blocks. This is why the computation times are rather low in comparison to CPLEX.\n6Remember that the results of applying CPLEX to Ilporig were described in detail in Section 2.4.2."}, {"heading": "4 Conclusions and Future Work", "text": "In this paper we considered a problem with applications in bioinformatics known as the minimum common string partition problem. First, we introduced an integer linear programming model for this problem. By applying the IBM ILOG CPLEX solver to this model we were able to improve all best-known solutions from the literature for a problem instance set consisting of 45 instances of different sizes. The smallest ones of these problem instances could even be solved to optimality in very short computation time. The second contribution of the paper concerned a 2-phase heuristic which is strongly based on the developed integer linear programming model. The results have shown that, first, the heuristic outperforms competitor algorithms from the literature, and second, that it is applicable to larger problem instances.\nConcerning future work, we aim at studying the incorporation of mathematical programming strategies based on the introduced integer linear programming model into metaheuristic techniques such as GRASP and iterated greedy algorithms. Moreover, we aim at identifying other string-based optimization problems for which a 2-phase strategy such as the one introduced in this paper might work well.\nAcknowledgements C. Blum was supported by project TIN2012-37930 of the Spanish Government. In addition, support is acknowledged from IKERBASQUE (Basque Foundation for Science). J. A. Lozano was partially supported by the Saiotek and IT609-13 programs (Basque Government), TIN2010-14931 (Spanish Ministry of Science and Innovation), COMBIOMED network in computational bio-medicine (Carlos III Health Institute)"}], "references": [{"title": "Iterative probabilistic tree search for the minimum common string partition problem", "author": ["C. Blum", "J.A. Lozano", "P. Pinacho Davidson"], "venue": "Proceedings of HM 20104\u2013 9th International Workshop on Hybrid Metaheuristics,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2014}, {"title": "Computing the assignment of orthologous genes via genome rearrangement", "author": ["X. Chen", "J. Zheng", "Z. Fu", "P. Nan", "Y. Zhong", "S. Lonardi", "T. Jiang"], "venue": "In Proceedings of the Asia Pacific Bioinformatics Conference", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2005}, {"title": "The greedy algorithm for the minimum common string partition problem", "author": ["M. Chrobak", "P. Kolman", "J. Sgall"], "venue": "Proceedings of APPROX 2004 \u2013 7th International Workshop on Approximation Algorithms for Combinatorial Optimization Problems,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2004}, {"title": "The string edit distance matching problem with moves", "author": ["G. Cormode", "S. Muthukrishnan"], "venue": "ACM Transactions on Algorithms,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2007}, {"title": "Minimum common string partition parameterized", "author": ["P. Damaschke"], "venue": "Proceedings of WABI 2008 \u2013 8th International Workshop on Algorithms in Bioinformatics,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2008}, {"title": "Solving the minimum common string partition problem with the help of ants", "author": ["S.M. Ferdous", "M.S. Rahman"], "venue": "Proceedings of ICSI 2013 \u2013 4th International Conference on Advances in Swarm Intelligence,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2013}, {"title": "A MAX-MIN ant colony system for minimum common string partition problem", "author": ["S.M. Ferdous", "M.S. Rahman"], "venue": "CoRR, abs/1401.4539,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2014}, {"title": "Exponential and polynomial time algorithms for the minimum common string partition problem", "author": ["B. Fu", "H. Jiang", "B. Yang", "B. Zhu"], "venue": "Proceedings of COCOA 2011 \u2013 5th International Conference on Combinatorial Optimization and Applications,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2011}, {"title": "Computers and intractability; a guide to the theory of NP-completeness", "author": ["M.R. Garey", "D.S. Johnson"], "venue": null, "citeRegEx": "9", "shortCiteRegEx": "9", "year": 1979}, {"title": "Minimum common string partition problem: Hardness and approximations", "author": ["A. Goldstein", "P. Kolman", "J. Zheng"], "venue": "Proceedings of ISAAC 2004 \u2013 15th International Symposium on Algorithms and Computation,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2005}, {"title": "Quick greedy computation for minimum common string partitions", "author": ["I. Goldstein", "M. Lewenstein"], "venue": "Proceedings of CPM 2011 \u2013 22nd Annual Symposium on Combinatorial Pattern Matching,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2011}, {"title": "Algorithms on Strings, Trees, and Sequences. Computer Science and Computational Biology", "author": ["D. Gusfield"], "venue": null, "citeRegEx": "12", "shortCiteRegEx": "12", "year": 1997}, {"title": "A novel greedy algorithm for the minimum common string partition problem", "author": ["D. He"], "venue": "Proceedings of ISBRA 2007 \u2013 Third International Symposium on Bioinformatics Research and Applications,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2007}, {"title": "Computing a longest common subsequence for a set of strings", "author": ["W.J. Hsu", "M.W. Du"], "venue": "BIT Numerical Mathematics,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 1984}, {"title": "Minimum common string partition revisited", "author": ["H. Jiang", "B. Zhu", "D. Zhu", "H. Zhu"], "venue": "Journal of Combinatorial Optimization,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2012}, {"title": "The greedy algorithm for edit distance with moves", "author": ["H. Kaplan", "N. Shafrir"], "venue": "Information Processing Letters,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2006}, {"title": "Approximating reversal distance for strings with bounded number of duplicates", "author": ["P. Kolman"], "venue": "Proceedings of MFCS 2005 \u2013 30th International Symposium on Mathematical Foundations of Computer Science,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2005}, {"title": "Wale\u0144. Reversal distance for strings with duplicates: Linear time approximation using hitting set", "author": ["T.P. Kolman"], "venue": "Proceedings of WAOA 2007 \u2013 4th International Workshop on Approximation and Online Algorithms,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2007}, {"title": "Optimization techniques for string selection and comparison problems in genomics", "author": ["C.N. Meneses", "C.A.S. Oliveira", "P.M. Pardalos"], "venue": "IEEE Engineering in Medicine and Biology Magazine,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2005}, {"title": "An improved heuristic for the far from most strings problem", "author": ["S.R. Mousavi", "M. Babaie", "M. Montazerian"], "venue": "Journal of Heuristics,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2012}, {"title": "Edit distance with move operations", "author": ["D. Shapira", "J.A. Storer"], "venue": "Proceedings of CPM 2002 \u2013 13th Annual Symposium on Combinatorial Pattern Matching,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2002}, {"title": "Identification of common molecular subsequences", "author": ["T. Smith", "M. Waterman"], "venue": "Journal of Molecular Biology,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 1981}], "referenceMentions": [{"referenceID": 19, "context": "Examples include string consensus problems such as the far-from most string problem [20, 19], the longest common subsequence problem and its variants [14, 22], and alignment problems [12].", "startOffset": 84, "endOffset": 92}, {"referenceID": 18, "context": "Examples include string consensus problems such as the far-from most string problem [20, 19], the longest common subsequence problem and its variants [14, 22], and alignment problems [12].", "startOffset": 84, "endOffset": 92}, {"referenceID": 13, "context": "Examples include string consensus problems such as the far-from most string problem [20, 19], the longest common subsequence problem and its variants [14, 22], and alignment problems [12].", "startOffset": 150, "endOffset": 158}, {"referenceID": 21, "context": "Examples include string consensus problems such as the far-from most string problem [20, 19], the longest common subsequence problem and its variants [14, 22], and alignment problems [12].", "startOffset": 150, "endOffset": 158}, {"referenceID": 11, "context": "Examples include string consensus problems such as the far-from most string problem [20, 19], the longest common subsequence problem and its variants [14, 22], and alignment problems [12].", "startOffset": 183, "endOffset": 187}, {"referenceID": 8, "context": "These problems are often computationally very hard, if not even NP -hard [9].", "startOffset": 73, "endOffset": 76}, {"referenceID": 1, "context": "[2] point out that the MCSP problem is closely related to the problem of sorting by reversals with duplicates, a key problem in genome rearrangement.", "startOffset": 0, "endOffset": 3}, {"referenceID": 1, "context": "[2] due to its relation to genome rearrangement.", "startOffset": 0, "endOffset": 3}, {"referenceID": 9, "context": "More specifically, it has applications in biological questions such as: May a given DNA string possibly be obtained by rearrangements of another DNA string? The general problem has been shown to be NP -hard even in very restrictive cases [10].", "startOffset": 238, "endOffset": 242}, {"referenceID": 9, "context": "The 2-MCSP problem was shown to be APX-hard in [10].", "startOffset": 47, "endOffset": 51}, {"referenceID": 14, "context": "proved that the decision version of the MCSPc problem is NP -complete when c \u2265 2 [15].", "startOffset": 81, "endOffset": 85}, {"referenceID": 3, "context": "Cormode and Muthukrishnan [4], for example, proposed an O(lognlog\u2217n)-approximation for the edit distance with moves problem, which is a more general case of the MCSP problem.", "startOffset": 26, "endOffset": 29}, {"referenceID": 20, "context": "Shapira and Storer [21] extended on this result.", "startOffset": 19, "endOffset": 23}, {"referenceID": 17, "context": "Other approximation approaches for the MCSP problem have been proposed in [18].", "startOffset": 74, "endOffset": 78}, {"referenceID": 2, "context": "[3] studied a simple greedy approach for the MCSP problem, showing that the approximation ratio concerning the 2-MCSP problem is 3, and for the 4-MCSP problem the approximation ratio is \u03a9(log(n)).", "startOffset": 0, "endOffset": 3}, {"referenceID": 15, "context": "Later Kaplan and Shafir [16] raised the lower bound to \u03a9(n0.", "startOffset": 24, "endOffset": 28}, {"referenceID": 16, "context": "Kolman proposed a modified version of the simple greedy algorithm with an approximation ratio of O(k2) for the k-MCSP [17].", "startOffset": 118, "endOffset": 122}, {"referenceID": 10, "context": "Recently, Goldstein and Lewenstein proposed a greedy algorithm for the MCSP problem that runs in O(n) time (see [11]).", "startOffset": 112, "endOffset": 116}, {"referenceID": 12, "context": "He [13] introduced a greedy algorithm with the aim of obtaining better average results.", "startOffset": 3, "endOffset": 7}, {"referenceID": 4, "context": "Damaschke [5] was the first one to study the fixed-parameter tractability (FPT) of the problem.", "startOffset": 10, "endOffset": 13}, {"referenceID": 14, "context": "[15] showed that both the k-MCSP and MCSPc problems admit FPT algorithms when k and c are constant parameters.", "startOffset": 0, "endOffset": 4}, {"referenceID": 7, "context": "[8] proposed a O(2nnO(1)) time algorithm for the general case and an O(n(logn)2) time algorithm applicable under some constraints.", "startOffset": 0, "endOffset": 3}, {"referenceID": 5, "context": "To our knowledge, the only metaheuristic approaches that have been proposed in the related literature for the MCSP problem are (1) the MAX -MIN Ant System by Ferdous and Sohel [6, 7] and (2) the probabilistic tree search algorithm by Blum et al.", "startOffset": 176, "endOffset": 182}, {"referenceID": 6, "context": "To our knowledge, the only metaheuristic approaches that have been proposed in the related literature for the MCSP problem are (1) the MAX -MIN Ant System by Ferdous and Sohel [6, 7] and (2) the probabilistic tree search algorithm by Blum et al.", "startOffset": 176, "endOffset": 182}, {"referenceID": 0, "context": "[1].", "startOffset": 0, "endOffset": 3}, {"referenceID": 5, "context": "Both works applied their algorithm to a range of artificial and real DNA instances from [6].", "startOffset": 88, "endOffset": 91}, {"referenceID": 5, "context": "For testing model Ilporig we chose the same set of benchmark instances that was used by Ferdous and Sohel in [6] for the experimental evaluation of their ant colony optimization approach.", "startOffset": 109, "endOffset": 112}, {"referenceID": 2, "context": "The second column contains the results of the greedy algorithm from [3] (results were taken from [6]).", "startOffset": 68, "endOffset": 71}, {"referenceID": 5, "context": "The second column contains the results of the greedy algorithm from [3] (results were taken from [6]).", "startOffset": 97, "endOffset": 100}, {"referenceID": 5, "context": "The third column provides the value of the best solution found in four independent runs per problem instance (with a CPU time limit of 7200 seconds per run) by the Aco approach by Ferdous and Sohel [6, 7].", "startOffset": 198, "endOffset": 204}, {"referenceID": 6, "context": "The third column provides the value of the best solution found in four independent runs per problem instance (with a CPU time limit of 7200 seconds per run) by the Aco approach by Ferdous and Sohel [6, 7].", "startOffset": 198, "endOffset": 204}, {"referenceID": 0, "context": "[1].", "startOffset": 0, "endOffset": 3}], "year": 2014, "abstractText": "The minimum common string partition problem is an NP-hard combinatorial optimization problem with applications in computational biology. In this work we propose the first integer linear programming model for solving this problem. Moreover, on the basis of the integer linear programming model we develop a deterministic 2-phase heuristic which is applicable to larger problem instances. The results show that provenly optimal solutions can be obtained for problem instances of small and medium size from the literature by solving the proposed integer linear programming model with CPLEX. Furthermore, new best-known solutions are obtained for all considered problem instances from the literature. Concerning the heuristic, we were able to show that it outperforms heuristic competitors from the related literature.", "creator": "LaTeX with hyperref package"}}}