{"id": "1406.0175", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "1-Jun-2014", "title": "Evolutionary Search in the Space of Rules for Creation of New Two-Player Board Games", "abstract": "Games have always been a popular test bed for artificial intelligence techniques. Game developers are always in constant search for techniques that can automatically create computer games minimizing the developer's task. In this work we present an evolutionary strategy based solution towards the automatic generation of two player board games (the first one with the first player and the second one with the last player).\n\n\nWe are going to introduce you to the latest development of the Artificial Intelligence Game (AIDG), where we are going to build the game and introduce us to the next one. It is known as the Artificial Intelligence Game (AI Game) which is a term that refers to AI technology for building artificial intelligence. This idea is a new type of game based on a common theme of the game. AI technology is very well known in the industry, but we are going to address some of the issues that can be posed by AI technology and learn more about the technology.\nThe Artificial Intelligence Game (AI Game) will begin its development in the next few days. We will be introducing your new game, AIDG (AIDG) with its game code.\nThe AIDG is based on a popular science game from 1984 called AI AI. It has become known as the first game with a real-world human on the planet and a virtual reality machine. AIDG (AIDG) allows players to use AI technology for a variety of tasks. To create AIDG, you need to be able to play the game from any other area. To create AIDG, you have to be able to create an AI game system that contains an AI system. The AI system requires only a few key words, you have to have a computer which can play the game in one or more ways.\nThe AI system is based on a series of two player boards: the first and the second player, based on a single AI card. All of the games are currently on AIDG and have an AI game.\nAIDG, which allows players to create an AI game system that contains an AI system. This makes it easy for a human to create an AI game system that can be used in any game.\nIf you are interested in the AI system or the computer program, the AIDG is not available in a game or any other type of game system. You must not download, modify, create or make a game that contains a player card. As a player, you must be able to create an AI game system that has a game to play", "histories": [["v1", "Sun, 1 Jun 2014 16:04:04 GMT  (879kb)", "http://arxiv.org/abs/1406.0175v1", null]], "reviews": [], "SUBJECTS": "cs.NE cs.AI", "authors": ["zahid halim"], "accepted": false, "id": "1406.0175"}, "pdf": {"name": "1406.0175.pdf", "metadata": {"source": "CRF", "title": "EVOLUTIONARY SEARCH IN THE SPACE OF RULES FOR CREATION OF NEW TWO-PLAYER BOARD GAMES", "authors": ["Zahid Halim", "Ghulam Ishaq Khan"], "emails": ["zahid.halim@giki.edu.pk", "rauf.baig@nu.edu.pk", "kashif.zafar@nu.edu.pk"], "sections": [{"heading": null, "text": "1\nEVOLUTIONARY SEARCH IN THE SPACE OF RULES FOR CREATION OF NEW\nTWO-PLAYER BOARD GAMES\nZahid Halim\nFaculty of Computer Science and Engineering, Ghulam Ishaq Khan Institute of Engineering Sciences and Technology, Topi, Pakistan\nzahid.halim@giki.edu.pk\nRauf Baig\nAl Imam Mohammad Ibn Saud Islamic University (IMSIU), Riyadh, Saudi Arabia\nrauf.baig@nu.edu.pk\nKashif Zafar\nDepartment of Computer Science, National University of Computer and Emerging Science, Lahore, Pakistan\nkashif.zafar@nu.edu.pk\nGames have always been a popular test bed for artificial intelligence techniques. Game developers are always in constant search for techniques that can automatically create computer games minimizing the developer's task. In this work we present an evolutionary strategy based solution towards the automatic generation of two player board games. To guide the evolutionary process towards games, which are entertaining, we propose a set of metrics. These metrics are based upon different theories of entertainment in computer games. This work also compares the entertainment value of the evolved games with the existing popular board based games. Further to verify the entertainment value of the evolved games with the entertainment value of the human user a human user survey is conducted. In addition to the user survey we check the learnability of the evolved games using an artificial neural network based controller. The proposed metrics and the evolutionary process can be employed for generating new and entertaining board games, provided an initial search space is given to the evolutionary algorithm.\nKeywords: Evolutionary algorithm; board based games; measuring entertainment; game content generation."}, {"heading": "1. Introduction", "text": "Games have an importance in everyone\u2019s life. Some of them are centuries old and others are a product of the last few decades. They have proven to be an excellent test bed for testing algorithms falling under the umbrella of computational intelligence. Researchers have developed software agents which not only play games but also have the ability of learning first the concept of the game itself. Games popular with the computational intelligence researchers can be categorized in many ways. One such categorization can be (a) classical\ngames which are played indoors (e.g. chess and bridge) [1], (b) video games which need a computing resource and a video display [2], (c) robotic games which are replicas of popular games played by robots [3], and (d) physically activating games which are played on playgrounds requiring electronic gadgetry (e.g. electronic tiles, laser beams) [4].\nPerhaps many of us have wondered how a popular game, e.g. chess, might have originated and what were its rules at the beginning and how and why they evolved over centuries to reach their present state. Also, can we introduce our own modifications to make the game even better? Video games, being a recent phenomenon, can have their history more easily traced. The popular ones have their versions upgraded, based on user surveys which act as a sort of fitness function for guiding their evolution. Everyone would agree that it would be nice to have a reliable method for game creation. The next question is whether an evolutionary algorithm can be applied for that purpose. The answer is yes, and initial ground breaking experiments have already been reported [5, 6]. We need a space of game rules in which the search for an optimum rule set can be made and a fitness function to guide the search. One way to specify the search space can be to generalize the rules of existing games of the same genre which we are trying to create. The design of fitness function is a much more difficult task.\nFor developing a fitness function, the fundamental question is: how do we compare two games of the same genre? The one providing more entertainment would be better. However, it is not simple to quantify entertainment. A source of entertainment for one person may be source of annoyance for another. Even though entertainment is subjective, some games are enjoyed by a vast majority of people. The common elements in popular games can be studied and attempts can be made to develop metrics for quantifying entertainment. These metrics can be used as a fitness function to guide the evolution for creating, new games.\nIn our present work, we report experiments in creation of new board games for two\nplayers. The novelty of this paper is that we employ evolutionary computation to address two issues in game development; a) measuring entertainment value of a board based game and b) automatic generation of entertaining board games. We propose an entertainment metric to quantitatively measure the entertainment value of the game. Our proposed metrics consider four criterion of entertainment, namely: (a) duration of the game, (b) intelligence required for playing the game, (c) dynamism exhibited by the pieces and (d) usability of the play area. We have further shown the utility of the proposed entertainment metrics by generating new and entertaining games through an evolutionary process which utilizes our entertainment metrics as fitness function, guiding the evolution towards an entertaining set of games. We define an initial search space for the evolution of new board based games. The search space is specified by taking some aspects of two popular board based games, chess and checkers. This search space is utilized to initialize and produce games using an evolutionary algorithm. In order to guide the evolutionary algorithm towards a more entertaining game, we develop a set of metrics for quantifying entertainment value of board games and use them as a fitness function. Further we create two different types of agents that play and evaluate the new games generated, against the proposed entertainment metrics. The first type of agent makes\nEvolutionary search in the space of rules for creation of new two-player board games 3\nrandom but legal moves to play the game whereas the second agent is relatively intelligent as it uses min-max algorithm with a rule based evaluation function. We conduct a human user survey to counter check the entertainment value of the evolved games against the human\u2019s entertainment value. In addition to the user survey, the entertainment value of evolved games is also verified by learnibility of the evolved games using an artificial neural network based controller, as proposed in Schmidhuber\u2019s theory of artificial curiosity [7].\nThe paper is arranged as follows: section II lists the search space in detail; section III\ncovers the theoretical studies on different entertainment theories and based upon these theories defines our proposed entertainment metrics along with the evolutionary algorithm used; section IV describes the software agent and its types which we use to evaluate the generated games; section V contains the detailed experimentations including the effect of different types of controllers, user survey and controller learnability and section VI concludes the paper."}, {"heading": "2. Search Space", "text": "We first need to define a search space in which search for an entertaining set of rules can\ntake place. One way to do this is to study the rules of some famous games and generalize them. Two famous board games, checkers and chess are selected for this purpose. Following is a discussion on different features of both these games and which features we select for our search space.\n2.1. Size of play area: Both, the games checkers as well as chess, consist of a grid of 8x8 squares, alternating white and black. White squares are never used in checkers but in case of chess both are used. The size of play area in our search space is also a grid of 8x8 squares, alternating white and black and all squares can be used. In principle, this should have been one of the dimensions of search and one of the two possibilities (white squares never used, as is done in checkers or all the squares used, as is the case for chess) should be committed for a proposed game. However, if the white squares never used option is selected, then the search space collapses considerably. Therefore we opt for using both white and black squares.\n2.2. Types of pieces, their quantities & their initial positions: Checkers has a total of 12 pieces, called checkers; these can later be converted to a king. King is not present initially but comes into being by promotion when it reaches the first row of the opponent. Number of kings is a variable quantity but maximum can be 12. Initial positions of the pieces are the three rows nearest to the player and are placed only on black cells. Chess consist of a total of six types of pieces which are: (1) piece king, (one piece) queen, (2) pieces knight, (2) pieces bishop, (2) pieces rook, (8) pieces soldiers. Initial positions of the pieces are the two rows nearest to the player.\nCombining the rule space of chess and checkers we have total six types of pieces in our search space. Each type can have a minimum of 0 and a maximum of 16 pieces. However, total pieces should not be zero nor exceed 16. The initial positions of the pieces are the nearest three rows of a player. A cell can have one piece of type 0 to 6, type 0 means no piece\nis present in that cell. For the ease of reference we do not name the types rather we call them by their type number. Evolution decides the initial positions, the number of types present and the number of pieces of a type.\n2.3. Movement direction of each piece & step size: The pieces of checkers can move only in diagonal, forward direction with a step size of one. The diagonal jumps are allowed if the cell behind the opponent\u2019s cell is empty. In case a sequence of jumps is possible then all of them have to be taken. Only king is allowed to jump in diagonal forward and backwards, but the step size is same as that of a normal (checker) piece. Turn passing is not allowed. In the game of chess each type has a different movement logic and step size. A king is allowed to move in all directions with a step size of one. Queen can also move in all directions but there is no limit on number of steps. A knight can also move in all directions, but the move should be L shaped, thus the step size becomes two in one direction and then one step either left or right. A jump over other pieces is allowed to a knight. Bishop can move only diagonally, forward and backwards, with no limit on steps. A rook moves straight, forward and backwards, with no limit on steps. Soldiers are allowed to move straight, with step size of one, except for opening soldier movement. Turn passing is not allowed in chess and only one move per turn is allowed.\nThe search space to evolve new games consists of the six movement logics found in chess. The step size for a piece can either be one or up to an occupied cell.\n2.4. Capturing logic: In checkers capturing is done by jumping over an opponent\u2019s piece. Whereas in chess capturing is done by moving into the cell occupied by the opponent\u2019s piece. Jumping over pieces is not allowed in chess, except for knight. For the knight, nothing happens to the pieces being jumped over. In both cases (of chess and checkers) the opponent\u2019s piece dies and is removed from the board.\nThe search space that we define for the new games is as follows: for each type capturing is done by jumping over or moving into the opponent\u2019s cell. The result of capturing is death of captured piece. There must be a vacant cell behind the cells when jump over is performed. In case several jumps are possible in a sequence, then all of them will have to be taken.\n2.5. Game ending logic & rules defining wins & draws: The game of checkers ends when no moves are possible for a player. The player with greater number of checkers is winner. If, both the players have same number of checkers then a draw is declared. In the game of chess a game ends if no move is possible for the king. The player whose king cannot move is loser. A game can be declared a draw by consent of both players.\nIn our search space we specify the type of piece for which the game ends if there are no more pieces left of that type. We call this piece a piece of honor. There can be zero or one piece type declared to be a piece of honor. The restriction of one type has been done to keep the search space limited. The evolution will only decide which type of piece has this honor. A game ends if a piece of honor of any player is dead or the player without any possible move is the loser. We restrict the maximum number of moves in a game to be a maximum of 100. If\nEvolutionary search in the space of rules for creation of new two-player board games 5\nthe game ends due to number of moves increasing 100 then a player with greater number of pieces is winner. If both have same number than a draw is declared.\n2.6. Conversion to pieces of some other type after reaching last row: In checkers a piece is converted into a king when it reaches the last row (or the first row of opponent). In chess this option is available to soldiers only. They convert into a queen or any piece of choice.\nIn our case evolution decides which type is convertible. Each piece has a conversion logic which decides which type it will convert to when last row is reached. There is also a chance that no type conversion occurs.\n2.7 If a piece is being capture, is it mandatory to capture it? In checkers it is mandatory but in chess it is not to kill/capture an opponent's piece if it's possible to do so. In our search space we keep both the options.\n2.8. Turn passing allowed? Both in chess and checkers turn passing is not allowed so we fix the same in our search space. Table 1 summarizes the search space."}, {"heading": "2.9 Structure of the chromosome", "text": "1. The chromosome consists of a total 50 genes. First 24 genes may contain values from 0 to 6 were 1 represents a piece of type 1, 2 for piece of type 2 and so on. Zero is interpreted as no piece. The piece type represented by gene 1 is placed in the cell 1 of the game board; piece\ntype represented by gene 2 is placed in the cell 2 of the game board and so on.\nGene 25 to 30 represents movement logic for each piece type respectively, where 1 is\nfor diagonal forward, 2 for diagonal forward and backward, 3 for all directions, 4 for L shaped movement, 5 for straight forward and backward and 6 for straight forward. Genes 31 to 36 are used for step size of each type, where 0 is used to indicate single step size and 1 for multiple step size. Genes 37 to 42 are used for step size of each type, where 0 is used to indicate step into and 1 for step over. Gene number 43 indicates the type of piece that will be the piece of honor, possible values include 0-6, where 1-6 indicate the piece type and 0 represents that there is no piece of honor in the game. Genes 44-49 represents the conversion logic, of piece type 1 to 6 respectively, when they reach the last row of the game board. Where 0 represents the piece will not be converted to any type and 1-6 represents the type of piece. The last gene represent whether if it is mandatory in the game to capture the opponent piece in case it could be, 0 represents no and 1 represents yes."}, {"heading": "3. Fitness Function and Evolutionary Algorithm", "text": "Evolutionary algorithms need a mechanism to evaluate the fitness of individuals of the\npopulation. Our aim is to evolve new games which are entertaining to play. Hence the fitness function must have features which can somehow quantify the entertainment value of a game. Actually we are looking for an answer to the question: \u201cWhat are the factors which makes one board game more interesting than another?\u201d To answer this question a peek at the literature on psychology might help. Some theories which are of interest are described in the following paragraphs."}, {"heading": "3.1. Theories on Entertainment", "text": "According to Csikszentmihalyi\u2019s theory of flow [8, 9], the optimal experience for a\nperson is when he is in a state of flow. In this state the person is fully concentrated on the task that he is performing and has a sense of full control. The state of flow can only be reached if the task is neither too easy nor too hard. In other words the task should pose the right amount of challenge.\nEvolutionary search in the space of rules for creation of new two-player board games 7\nIn addition to the right amount of challenge, Malone [10] proposes two more factors\nthat make games engaging: fantasy and curiosity. If a game has the capability of evoking the player\u2019s fantasy and makes him feel that he is somewhere else or doing something exotic then that game is more enjoyable than a game which does not do so. Curiosity refers to the game environment. The game environment should have the right amount of informational complexity: novel but not incomprehensible. Koster\u2019s theory of fun [11] states that the main source of enjoyment while playing a game is the act of mastering it. If a game is such that it is mastered easily and the player does not learn anything new while playing then the enjoyment value of that game is low.\nRauterberg [12, 13] has introduced the concept of incongruity as a measure of interest in\na task. Given a task, humans make an internal mental model about its complexity. Incongruity refers to the difference between the actual complexity of the task and the mental model of that complexity. We have positive congruity if this difference is positive and negative congruity otherwise. In case of negative incongruity a person would be able to accomplish the task easily. Interest in a task is highest when the incongruity is neither too positive nor negative. In case of large positive incongruity the humans have a tendency to avoid the task and in situations of large negative incongruity they get bored. This requirement of right amount of incongruity is similar to the right amount of challenge in the concept of flow mentioned above. It has been further proposed that in case of reasonable positive incongruity the humans have a tendency to learn more about the task so that their mental model comes at par with the actual complexity of the task.\nSeveral other related and derivative works are available on this topic. Many of them are\ncovered in Yananakakis\u2019s recent survey [14]."}, {"heading": "3.2. Quantification of Entertainment", "text": "In addition to the debate about the comprehensiveness or accuracy of the above\nmentioned theories, we are faced with the problem of converting them into something quantifiable for the problem at hand, i.e. two player board games. The three possible methods of collecting data are as follows:\n(a) One obvious method of quantification can be to have a human player survey about a\nset of games. If the number of participants of the survey is large enough then some meaningful information about the games being compared can be obtained.\n(b) Statistics obtained from the games played can be used. (c) Physiological signals of the human players during the games can be used.\nIf we are using an evolutionary algorithm for evolving games then the number of game\nevaluations is usually in order of thousands. There is a population of games in each of the several generations which have to be evaluated and compared. This large magnitude excludes the reliance on human game playing and we cannot use option (a) or (c). The only option available is to collect statistics from automatic game playing.\nIida [15], in 2003, has proposed a measure of entertainment for games and used it to\nanalyze the evolution of game of chess over the centuries. This measure is considered to be the pioneer in quantification of entertainment. Even though Iida\u2019s work is limited to chess variants the measure of entertainment can be easily applied to other board games. According to this measure, the entertainment value of a game is equal to the length of the game divided by the average number of moves considered by a player on his turn. The game is more entertaining if the value of this measure is low. The main idea is that the player should have many choices (moves) on the average and the length of the game should not be large. Long games with few choices per move are boring. The authors differentiate between possible moves and the moves considered by a player. The set of considered moves is smaller than the set of possible moves and the metric is based on the moves considered by a player. Except for Iida\u2019s work, all other research has been in context of computer (video) games and physically interactive games.\nIn [16] the authors introduce the uncertainty of game outcome as a metric of entertainment. If the outcome is known at an early stage then there is not much interest in playing it. Similarly if it is found at the last move then it is probably probabilistic. The outcome should be unknown for a large duration of the game and should become known in the last few moves.\nTogelius [6] has presented an approach to evolve entertaining car racing tracks for a\nvideo game. Tracks were represented as b-splines and the fitness of a track depended on how an evolved neural network based controller (modeled after a player) performed on the track. The objectives were for the car to have made maximum progress in a limited number of time steps (high average speed), high maximum speed, and high variability in performance between trials. In [17] Togelius evolves entertaining computer games and uses a fitness function based on the learnability of the games. A game which is either too hard or too easy to learn (by a population of ANNs) is assigned a low fitness. All other games are assigned fitness according to the degree to which they can be learnt in a fixed time.\nIn [18] three metrics (which are combined into one) have been proposed for measuring\nthe entertainment value of predator/prey games. The first metric is called appropriate level of challenge (T). It is calculated as the difference between the maximum of a player\u2019s lifetime and his average lifetime over N games. This metric has a higher value if the game is neither too hard nor too easy and the opponents are able to kill the player in some of the games but not always. The second metric is behavior diversity metric (S). It is standard deviation of a player\u2019s lifetime over N games. It has a high value if there is diversity in opponent\u2019s behavior. The third metric is spatial diversity metric E{Hn}. It is the average entropy of gridcell visits by the opponents over N games. Its value is high if the opponents move all the time and cover the cells uniformly. This movement portrays aggressive opponent behavior and gives an impression of intelligent game play. The three metrics are combined into one single metric I = [\u03b3T + \u03b4S + \u03b5E{Hn}]/[\u03b3 + \u03b4 + \u03b5] where I is the interest value of the predator/prey\nEvolutionary search in the space of rules for creation of new two-player board games 9\ngame; \u03b3, \u03b4 and \u03b5 are weight parameters. Work in [31, 32] presents evolution of rules for predator/pray games based on somewhat same metrics as proposed in [18].\nIn [19], the authors have developed a computer game called \u201cGlove\u201d with three levels of\nincongruity: hard, easy and balanced. There assumption is that the player would get frustrated or bored respectively, with the first two settings and would enjoy with the third one. They argue that the actual complexity of a game can be defined as its difficulty level and the incongruity, i.e. the difference between the actual complexity and a player\u2019s mental complexity of a game can be measured indirectly by observing the player\u2019s behavior in the game. If the player progresses easily through a game or does not progress at all then the incongruity is too easy or hard respectively. If the player has just enough health to reach a game\u2019s goal, but not more than the incongruity is balanced.\nAn interesting fact is that data pertinent to interestingness of games can be obtained by\nmeasuring the physical signals of human beings. However, that again requires a tremendous number of games to be played and thus cannot be used for two player board games. Variations in physiological signals of game players have also been shown to correlate with the enjoyment experienced by them. Some signals which have been investigated include cardiovascular measures, skin responses, facial and jaw electromyography, and respiration. Most of these studies are related to computer games [9, 20-28, 33, 35, 36] or physically interactive games [29] and none were done in the context of board games except [21]."}, {"heading": "3.3. Proposed Fitness Function", "text": "In context of two person board games the opponent is part of the gaming environment\nand his capabilities have a direct influence on the entertainment value of a game. Since we are concerned with evolving games we assume an opponent of abilities equal to the player. By doing so, we ignore the effect of opponent while analyzing the above mentioned theories.\nAccording to theory of flow, the gaming environment should pose a right amount of\nchallenge to the player. It implies that the game which is able to take a player into the state of flow would be better than a game which is not able to do so. The first of Malone\u2019s three factors, i.e. challenge is the same as that covered by theory of flow. Furthermore, Rauterberg\u2019s theory of incongruity is also similar to the theory of flow. Koster\u2019s theory of fun and the third Malone\u2019s factor of curiosity are similar in nature. The state space of the game should be sufficiently rich so that even the experienced players would find fresh avenues to explore and new situations to master. Malone\u2019s second factor of fantasy is different from the rest and would relate to the interpretation of the board layout and the pieces (e.g. king and queen of chess, property buying of Monopoly).\nTogelius has categorized the entertainment theories into two types. Static theories, which\nrely on monitoring the process of game playing, and dynamic theories, which require monitoring of the process of learning the game. Theory of Flow, Malone\u2019s factors and Rauterberg\u2019s theory can be considered as static theories. They can be used to judge the\nentertainment value of a game for a player given his current capabilities of playing that game (assuming the opponent player to be part of the game environment). Koster\u2019s theory is a dynamic theory and judges a game by observing how a player adapts to it over time.\nIn the present work we have based our fitness function on metrics which can be\ndescribed as adhering to the static theories. However, after evolution we do check some of the evolved games for their compatibility with the dynamic theories.\nWe now turn our attention to what can be quantitatively measured in two-player board\ngames. We can measure the average game duration, the average branching factor, the number of wins for the first and second player, the number of games drawn, the average number of cells changed by a piece in its lifetime, the average number of pieces visiting a cell during a game.\nTo calculate the above mentioned statistics we might be able to construct the complete\ntree of all possible moves for some of the games. However, calculations on the basis of a complete tree may be misleading as we have earlier assumed that both the players are of equal intelligence and a complete tree is bound to have a considerable amount of foolish game play. A more realistic approach would be to calculate these quantities from actual game play. The amount of game play needed to have reliable statistics, especially if a population of games is to be evolved as is being done in this paper, prohibits human game play and our only choice is to have automated game play.\nIn the present work, a chromosome encodes the rules of a game. In other words, it is a\ncomplete game. The aim of the evolutionary process is to evolve a population of games and find a best one which is entertaining for the player. For this purpose we have assumed that better entertainment is based on four aspects described below. In three of these aspects we assume that both the players play each game with the same strategy (random controller). Hence both have the same chances of winning.\n3.3.1. Duration of the game: In general, a game should not be too short or too long, as both are uninteresting. For example, if a game is such that it usually ends after a few moves (like Tic-Tac-Toe) then it would not appeal to adults. On the other hand, if a game usually continues for several hundred moves then the players may choose not to play it due to lack of enough time. The fitness function should be such that it discourages games which routinely end after a few moves as well as the games which take more than an upper threshold of moves.\nThe duration of play (D) of a game is calculated by playing the game n times and taking\nthe average number of moves over these n games. For the games evolved in this paper, the maximum moves are fixed at 100 (50 for each player). If a game does not end in 100 moves then it is declared a draw. The average value of D is taken because if the game is played multiple times with a different strategy, (or even by the same strategy which has probabilistic\nEvolutionary search in the space of rules for creation of new two-player board games 11\ncomponents) then we do not get the same value of D every time. For averaging, the game is played n = 20 times in our experiments. Equation (1) shows the mathematical representation of D.\n\u2211\n(1)\nWhere is the life of the game playing agent in game K. In order to reward games neither too short nor too long raw value of D is scaled in range 0-1. The boundaries for scaled value of D are shown in Fig. 2.\nFor the raw duration of games 0 to 10 and 100 to 90 a scaled value of 0 is assigned, for ranges 11-20 and 81-90 a value of 0.2 is assigned, for 21-30 and 71-80 a scaled value of 0.5 is used, 31-40 and 61-70 are converted to 0.8 and a range of 41-60 is assigned the highest value i.e. 1.\n3.3.2. Intelligence for playing the game: A game is interesting if the rules of the game are such that the player having more intelligence should be able to win. In such a case, a win increases his motivation to play the game again. Too many draws or loses even after an intelligent game play are discouraging. There can be two reasons if a controller with superior intelligence does not win. Either the game is too simple or there are some inherent aspects which frustrate intelligent game play (e.g. very few pieces with limited step sizes making it impossible to corner the opponent).\nThe intelligence (I) is defined as the number of wins of an intelligent controller over a controller making random (but legal) moves. For this purpose the game is played n times (n = 20 times in our experiments). Higher number of wins against the random controller means that the game requires intelligence to be played and does not have too many frustrating dead ends. Intelligence I is calculated using equation (2).\n\u2211\n(2)\nWhere, IK is 1 if intelligent controller wins the game otherwise its 0.\nDuration of Game D"}, {"heading": "3.3.3. Game Liveliness:", "text": ""}, {"heading": "A. Dynamism exhibited by the pieces:", "text": "This aspect assumes that a game whose rules encourage greater dynamism of movement in its pieces would be more entertaining than a game in which many pieces remain stuck in their cells for the entire duration of the game. The dynamism is captured by the following fitness function given in equation (3).\n\u2211 ( \u2211 ( ) \u2044 )\n(3)\nWhere,\nCi is the Number of cell changes made by piece i during a game Li is life of the piece i And m is the total number of pieces specified in a chromosome. The dynamism is averaged by calculating it for 20 games for the same chromosome. This fitness function has a higher value if the pieces show a more dynamic behavior.\nB. Usability of the play area: It is interesting to have the play area maximally utilized during the game. If most of the moving pieces remain in a certain region of the play area then the resulting game may seem strange. The usability is captured using equation (4).\n\u2211 ( \u2211 ( ) )\n(4)\nwhere\nusability counter value for a cell k. is the total number of usable cells. n is 20 as explained previously.\nA usability counter is set up for each cell which increments when a piece arrives in the cell. The usability U is averaged by playing twenty different games for a chromosome. A cell which is never visited during a game will have a counter value of zero, thus contributing nothing to the usability formula. Furthermore, a cell which has a few visits would contribute less than a cell having large number of visits. This formula is another facet of the liveliness aspect.\n3.3.4. Combined fitness function: The above four metrics are combined in the following manner. All chromosomes in a population are evaluated separately according to each of the four fitness functions. Then the population is sorted on \u201cduration of game\u201d and a rank based fitness is assigned to each chromosome. The best chromosome of the sorted population is assigned the highest fitness (in our case it is 20 because we have 10 parents and 10 offsprings), the second best chromosome is assigned the second best fitness (in our case 19), and so on. The population is again sorted on the basis of \u201cintelligence\u201d and a rank based fitness is assigned to each chromosome. Similarly, rank based fitness is assigned after sorting on \u201cdiversity\u201d and \u201cusability\u201d. The four rank based fitness values obtained for each chromosome are multiplied by corresponding weights and then added to get its final fitness.\nEvolutionary search in the space of rules for creation of new two-player board games 13"}, {"heading": "FF = w1D + w2I + w3Dyn + w4U (5)", "text": "where w1, w2, w3, and w4 are constants. In our experiments we keep the value of these constants fixed at 1. The multiplication with a corresponding weight allows us to control the relative influence of an aspect. The calculation of rank based fitness gets rid of the problem of one factor having higher possible values than another factor."}, {"heading": "4. Software Agents for Playing the Games", "text": "Since evolutionary algorithm evolves a population of games and the fitness of each\ngame has to be determined in each generation we may have a total of several thousands of such fitness evaluations. Fitness evaluation means playing the game several times, it is not possible to do so manually. We need software game playing agents. The more intelligent the agent the better will be the accuracy of fitness evaluation. We have developed two types of such agents.\n Random agent.\n Agent using Min-Max with rule based evaluation function."}, {"heading": "4.1. Random Agent", "text": "As the name suggests the random game playing agent plays the game by randomly\nselecting a legal move at each step. The agent follows the following algorithm listed in Fig. 3:\nThe agent initially generates all the legal moves and stores them in a queue. The queue is\nshuffled once all the moves are saved in it. Shuffling is important, as we take an average of 20 games to calculate the individual metrics values. If the queue is not shuffled then each time the game is played it will use the same sequence of moves to play the game and fitness values will remain the same in each iteration of the game play. If the mandatory to capture bit is \"on\" in a chromosome which is being evaluated then the agent first tries to find a move that will capture an opponent's piece. If no such move is found it randomly selects a move from the queue."}, {"heading": "4.2. Agent using Min-Max with rule based evaluation function", "text": "Intelligent agent generates all the possible one ply depth game boards using a min-max\nalgorithm. Each of the resulting game board is evaluated using a rule based evaluation function and the one with the highest evaluation is selected as a next move.\nEvaluation function assigns priorities (weights) to piece-type according to whether its\ndisappearance would cause the game to end, flexibility of movement, and capturing logic. Once the priority of a piece is calculated we multiply each piece with its corresponding weight and calculate weighted summation for self and opponent. The board evaluation is the self-weighted summation minus opponents weighted summation. Fig. 4 lists the algorithm for the evaluation function we use.\nSince we are using min-max of single ply hence we had to incorporate a mechanism in\nthe evaluation function to overcome the randomness effect near the end of the game when pieces are few and may be far apart. In such cases the evaluation function listed in Fig. 4 gives same evaluation for all the board positions thus increasing the duration of game. To avoid such situation we restrict the agent to select the move which decreases distance between its own piece and one of an opponent's pieces, provided all next game board position\nEvolutionary search in the space of rules for creation of new two-player board games 15\nhave equal evaluation.\nThere can be other options to an intelligent controller; such as an artificial neural network (ANN) based controller. For an ANN based controller we would require training the connection weights and/or optimizing the ANN architecture. Thus ANN based controller will introduce computational overhead. Since the min-max algorithm is used with one ply depth, which overcomes the computational overhead."}, {"heading": "5. Experiments", "text": "Different experiments carried out are explained in the sub-sections below. The\nmethodology of the experimentations is such as we first conduct an experiment on the existing games of chess and checkers to calculate the individual values of our proposed metrics. The results of this experiment are shown in table 8-11 (appendix I). We will use these results to compare with the metrics values for the evolved games in section 5.1 of this paper. Afterwards we evolve new board based games using 1+1 Evolutionary Strategy (ES). Once we get a set of evolved games we first select minimum number of games, using equation (7), for analysis. In order to analyze and study the entertainment value contained in the evolved games we follow a threefold strategy i.e. by conducting a controller learnability experiment, a human user survey and lastly comparing the individual metrics values of the evolved games with the popular games of chess and checkers."}, {"heading": "5.1. Evolution of New Games", "text": "In order to generate new and entertaining board based games we use 1+1 Evolutionary\nStrategy (ES). Initially a population of 10 chromosomes is randomly initialized with permissible values. The evolutionary algorithm is run for 100 iterations. Mutation is the only genetic operator used with a mutation probability of 30 percent. In each iteration of the ES one parent produce one child and a fitness difference is calculated between them. If it is greater than 4 (i.e. the child is at least half times better than its parent) child is promoted to the next population. We use the formula given in equation (6) to calculate the fitness difference.\n\u2211 ( - -\n)\n(6)\nWhere,\nis the fitness value of parent for current metrics\nis the fitness value of child for current metrics\nWe keep an archive of 8 slots and in each iteration update it with the best 2\nchromosomes based on each of the fitness metrics. Fig. 5 shows the metrics values of one family of chromosome in shape of a graph (Fig. 5), over a period of 100 iterations.\nAs we use 1+1 ES the best chromosome found in an iteration may get lost in iterations to\ncome. For this purpose as mentioned previously we keep an archive of 8 for best 2 chromosomes against each of the metrics. As the evolutionary process progresses the number of changes, child beating its parent using fitness difference formula (equation (6)) decreases."}, {"heading": "5.2. Games for Analysis", "text": "The evolutionary process gives 8 games evolved against the entertainment based on\nduration, intelligence, dynamism and usability. For further analysis of these games we select the set of most diverse games. Diversity (from each other) of these games is calculated using their fitness values and is listed in table 2 for one experiment.\nWe calculate the diversity based on each of the four metrics for all pair of games using equation (7).\nEvolutionary search in the space of rules for creation of new two-player board games 17\n-\n(7)\nSelecting a threshold value of 0.6 table 3 shows the diversity count of evolved games. Diversity count indicates that a game is different from how many other games based on all the four metrics of entertainment.\nWe select these three for further analysis. From this point onwards we will refer to these as game 1, 2 and 3 respectively. Rules of these games are listed in Fig. 8 - Fig. 10 (appendix I). For the sake of simplicity we do not name the pieces rather we identify them by their type number which range from 1-6.\nWe also create a randomly initialized game that has not been passed through the\nevolutionary process for optimization of entertainment. This game is used to analyze the learnability of the game experiment covered in section 5.4 and also in the user survey, to compare with the evolved games. Rules of the random game are shown in Fig. 11 (appendix I)."}, {"heading": "5.3 Comparison of Evolved Games with Other Board Based Games", "text": "It would be quite informative to see performance comparisons of the proposed\ntechnique against other heuristic-type solvers used to create board based game. Other techniques like [21] may end up making a different board game thus two games may only be comparable, not the techniques. Having said this, game of chess has a history of 1500 years [34] and monopoly goes back to 1903. It would be more suitable to see the performance of evolved games and the game of chess and checkers using the of individual entertainment metrics (proposed earlier in this paper) as a gauge. Table 4 list the effect and values of each type of controller on the individual entertainment metrics. The results in table 4 suggest that the entertainment value of the popular games of chess and checkers are comparable to those\nevolved using the proposed entertainment metrics.\nThe data listed in table 4 shows the average value of duration, dynamism, intelligence and usability recorded by playing each of the listed game 100 times. For the individual metrics of duration, intelligence and usability the evolved games have either performed better or at least equal to the games of chess and checkers."}, {"heading": "5.4. Learnability of Evolved Games", "text": "The entertainment value of the evolved games needs to be verified against some criteria\nother than the proposed entertainment metrics. For this purpose we use the Schmidhuber\u2019s theory of artificial curiosity [7]. We need to see how quickly a player learns an evolved game. Games learned very quickly will be trivial for the player and thus not contributing anything towards entertainment. Those taking large amount of time to learn will be too difficult. Games between these two boundaries will fall in the range of entertaining games. To observe the learnability of the evolved games there are two options first is to ask a human to play a game multiple times and see how fast she/he learns and second is to do the same task using a software based controller.\nWe have used an ANN based controller. The architecture of the controller is the same\narchitecture used by Chellapilla [30] for evolving an expert checkers player. There are total 5 layers in the ANN, input with 64 neurons, first hidden layer with 91 neurons; second hidden layer with 40 neurons third with 10 neurons and the output layer with 1 neuron. A hyperbolic tangent function is used in each neuron. The connection weights range from [-2, 2]. The training of the ANN is done using co-evolution. A set of genetic algorithm (GA) population is initialized that represent the weight of the ANN. Each individual of the population is played against randomly selected 5 others. Mutation is the only genetic operator used; we have kept the ANN and its training as close to Chellapilla [30] work as possible, except for the number of iteration for which the ANN is trained. We train the set of ANN until we get a set of weights that beats all others. Such individual will have its fitness equal to 1. The number of iterations that take to get such individual in the archive is called the learning duration or learnability of the game. Fig. 6 show the learnability of all the 4 games including the random game (referred to as game 4).\nEvolutionary search in the space of rules for creation of new two-player board games 19\nIt takes about 80 to 110 iterations to get a chromosome representing ANN weights that\nachieve a fitness of 1 during co-evolution, for the evolved games. In case of the randomly initialized game (game 4) it takes only 30 iterations, thus showing game 4 is trivial and uninteresting. Thus we can conclude that game 1, 2 and 3 proof to be entertaining as an ANN based controller neither takes too short a time nor too long to learn these games."}, {"heading": "5.5. User Survey on Entertainment Value of Evolved Games", "text": "To validate the results produced against human entertainment value we have to perform\na human user survey. For this purpose we select a set of 10 subjects. Subjects are chosen such that they have at least some level of interest towards computer games. Each individual was given 4 games while s/he was supposed to play each game 3 times, the rules of the game were already explained to the subjects and also displayed on the software they used. This makes a total of 12 games to be played by each subject. The demographics of the subjects are summarized in table 5; listing subject age, gender and subject\u2019s likeness towards board games 1 being lowest and 10 being highest.\nLearnability\nRules are shown in Fig. 8- Fig. 11. Game 4 is the randomly initialized one (but will legal values) whereas remaining three games are evolved for entertainment. Each subject was asked to rank the game they play as 1- liked, 2-disliked and 3-neutral.\nThe results of the human user survey are shown in table 6. For visual purposes we use\nfor \u221a liked, \u00d7 for disliked and ~ for neutral.\nEvolutionary search in the space of rules for creation of new two-player board games 21\nFor the purpose of collecting statistics from the human user survey we mark a game\nliked by the subject if during any run he has liked the game and for rest he has either liked or been neutral. If in any run he has disliked the game we mark the game to be disliked. Fig. 7 shows the statistics based upon this scheme. About 70- 90 percent subjects have liked the evolved games and found these entertaining, whereas only 10 percent say that the random game (game 4) was entertaining."}, {"heading": "5.6. Hypothesis testing", "text": "For the purpose of testing whether or not the given hypothesis, that the evolved games\nare entertaining, is true, we conduct a hypothesis testing. For this purpose we first formulate the null hypothesis which is as follows:\nH0: The correlation between the human value of entertainment and the entertainment\ncontained in the evolved games, using combined fitness function, is a result of randomness.\nThe alternate hypothesis Ha is as Ha: The evolved game using combined fitness function is entertaining.\nTo form a statistical test, we calculate a correlation coefficient c (z') using equation (8).\nSuch that, given two games A and B, it can be established that A is more entertaining than B or otherwise, calculated as follows.\n\u2211\n(8)\nN is the number of samples in the experiment.\nGame liked %\nZn = 1, if subject finds game entertaining\n-1, if subject do not finds game entertaining (9) 0, otherwise\nWe select the cut-off point, to reject null hypothesis, to be \u03ac = 0.17. Table 7 shows the\nsubject\u2019s answer to the question \"Is game in row is more entertaining than game 4(random game)?\u201d For visual purposes we use for \u221a yes, \u00d7 for no and ~ for neutral. This data is collected after the user survey is completed from the same set of subjects.\nhypothesis H0, as a result alternate hypothesis Ha is true."}, {"heading": "6. Conclusion", "text": "The idea of evolution of game rules to produce new and entertaining games is intriguing.\nIn this work we have presented automatic search of entertaining and new board based games. For this purpose we initially define a search space that is extracted using the popular board based games of chess and checkers. This search space is provided in shape of population of chromosomes to the evolutionary algorithm. To guide the evolutionary algorithm towards entertaining games we propose a set of metrics extracted based on different theories of entertainment. The metrics include duration of game, intelligence required to play the game, dynamism exhibited by the pieces and the usability of the play area. The results of our\nEvolutionary search in the space of rules for creation of new two-player board games 23\nexperiments are verified against the human user's entertainment value by conducting a human user survey and an experiment on controller learning ability. Results suggest that the evolved games using the fitness function (entertainment metrics) are interesting and much better than randomly generated games. The idea of measuring entertainment and automatic generation of entertaining games can be extended to other genres of game like platform games and real time strategy games. It will be interesting to see the effect of different types of controllers that play the game to evaluate its fitness on the entertainment value of the evolved games"}], "references": [{"title": "World championship caliber checkers program", "author": ["J. Culberson", "N. Treloar", "B. Knight", "P. Lu", "D.A Szafron"], "venue": "Artificial Intelligence,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 1992}, {"title": "Playware Technology for Physically Activating Play, Artificial Life and Robotics", "author": ["H.H.H. Lund", "T. Klitbo", "C Jessen"], "venue": "Journal 9:4,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2005}, {"title": "Towards automatic personalised content creation for racing games", "author": ["J. Togelius", "R.D. Nardi", "S.M. Lucas"], "venue": "Proceedings of the IEEE Symposium on Computational Intelligence and Games,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2007}, {"title": "Computational intelligence in racing games, Advanced Intelligent Paradigms in Computer Games, Springer", "author": ["J. Togelius", "S.M. Lucas", "R.D. Nardi"], "venue": "Series on Studies in Computational Intelligence,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2007}, {"title": "Flow: The Psychology of Optimal Experience", "author": ["M. Csikszentmihalyi"], "venue": null, "citeRegEx": "8", "shortCiteRegEx": "8", "year": 1990}, {"title": "Introduction to Part IV in Optimal Experience, Psychological Studies of Flow in Consciousness", "author": ["M. Csikszentmihalyi", "I. Csikszentmihalyi"], "venue": null, "citeRegEx": "9", "shortCiteRegEx": "9", "year": 1988}, {"title": "What makes computer games fun", "author": ["T.W. Malone"], "venue": "Byte, vol. 6,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 1981}, {"title": "A Theory of Fun for Game Design", "author": ["R. Koster"], "venue": null, "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2005}, {"title": "An Automatic Mental Model Evaluation to Analyze User Behavior Traced in a Finite", "author": ["M. Rauterberg", "Amme"], "venue": "Discrete State Space, Ergonomics,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 1993}, {"title": "About a Framework for Information and Information", "author": ["M. Rauterberg"], "venue": "Processing of Learning Systems,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 1995}, {"title": "How to Model and Augment Player Satisfaction: A Review, in Proceedings of the 1st Workshop on Child, Computer and Interaction, ICMI'08", "author": ["G.N. Yannakakis"], "venue": null, "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2008}, {"title": "A Metric for Entertainment of Board Games Its Application for Evolution of Chess Variants", "author": ["H. Iida", "N. Takeshita", "J. Yoshimura"], "venue": "Entertainment Computing: Technologies and Applications (Proceedings of IWEC", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2002}, {"title": "Outcome Uncertainty And Interestedness In Game-Playing: A Case Study Using Synchronized Hex", "author": ["A. Cincotti", "H. Iida"], "venue": "In New Mathematics and Natural Computation (NMNC),", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2006}, {"title": "An experiment in automatic game design", "author": ["J. Togelius", "R.D. Nardi", "S.M. Lucas"], "venue": "Proceedings of the IEEE Symposium on Computational Intelligence and Games,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2008}, {"title": "Towards Optimizing Entertainment", "author": ["G N. Yannakakis", "J. Hallam"], "venue": "In Computer Games, Applied Artificial Intelligence, v.21 n.10,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2007}, {"title": "A Generic Approach for Obtaining Higher Entertainment in Predator/Prey Computer Games, Journal of Game Development", "author": ["G. Yannakakis", "J. Hallam"], "venue": null, "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2005}, {"title": "Automatic Generation and Evaluation of recombination Games, PhD dissertation, Queensland", "author": ["C. Browne"], "venue": null, "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2008}, {"title": "What makes things fun to learn? Heuristics for designing instructional computer games", "author": ["T.W. Malone"], "venue": "Proceedings of the 3rd ACM SIGSMALL symposium and the 1st SIGPC symposium on Small systems,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 1980}, {"title": "GameFlow: A Model for Evaluating Player Enjoyment in Games", "author": ["P. Sweetser", "P. Wyeth"], "venue": "ACM Computers in Entertainment,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2005}, {"title": "Real-time Game Adaptation for Optimizing Player Satisfaction", "author": ["G.N. Yannakakis", "J. Hallam"], "venue": "IEEE Transactions on Computational Intelligence and AI in Games,", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2009}, {"title": "Preference Learning for Cognitive Modeling: A Case Study on Entertainment Preferences, IEEE Systems, Man and Cybernetics", "author": ["G.N. Yannakakis", "M. Maragoudakis", "J. Hallam"], "venue": "Part A: Systems and Humans,", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2009}, {"title": "Optimization of platform game levels for player experience, in Proceedings of Artificial Intelligence and Interactive Digital Entertainment (AIIDE'09)", "author": ["C. Pedersen", "J. Togelius", "G.N. Yannakakis"], "venue": null, "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2009}, {"title": "Evolving an expert checkers playing program without using human expertise", "author": ["K. Chellapilla", "David B. Fogel"], "venue": "IEEE Trans. Evolutionary Computation", "citeRegEx": "30", "shortCiteRegEx": "30", "year": 2001}, {"title": "Towards Evolutionary Game Generation", "author": ["Z. H", "A.R. Baig"], "venue": "International Arab Conference on Information", "citeRegEx": "31", "shortCiteRegEx": "31", "year": 2009}, {"title": "The earliest evidence of chess in western literature: the Einsiedeln Verses.\" Speculum: A", "author": ["M.H. Gamer"], "venue": "Journal of Mediaeval Studies,", "citeRegEx": "34", "shortCiteRegEx": "34", "year": 1954}, {"title": "McQUADE. \"Experiments with learning opening strategy in the game of Go.", "author": ["T. Huang", "C. Graemel", "B.R.Y.A. N"], "venue": "International Journal on Artificial Intelligence Tools", "citeRegEx": "35", "shortCiteRegEx": "35", "year": 2004}, {"title": "Examples as Interaction: On Humans Teaching a Computer to Play a Game", "author": ["K. Dimitris", "I. Fykouras"], "venue": "International Journal on Artificial Intelligence Tools 19.06,", "citeRegEx": "36", "shortCiteRegEx": "36", "year": 2010}], "referenceMentions": [{"referenceID": 0, "context": "chess and bridge) [1], (b) video games which need a computing resource and a video display [2], (c) robotic games which are replicas of popular games played by robots [3], and (d) physically activating games which are played on playgrounds requiring electronic gadgetry (e.", "startOffset": 18, "endOffset": 21}, {"referenceID": 1, "context": "electronic tiles, laser beams) [4].", "startOffset": 31, "endOffset": 34}, {"referenceID": 2, "context": "The answer is yes, and initial ground breaking experiments have already been reported [5, 6].", "startOffset": 86, "endOffset": 92}, {"referenceID": 3, "context": "The answer is yes, and initial ground breaking experiments have already been reported [5, 6].", "startOffset": 86, "endOffset": 92}, {"referenceID": 4, "context": "Theories on Entertainment According to Csikszentmihalyi\u2019s theory of flow [8, 9], the optimal experience for a person is when he is in a state of flow.", "startOffset": 73, "endOffset": 79}, {"referenceID": 5, "context": "Theories on Entertainment According to Csikszentmihalyi\u2019s theory of flow [8, 9], the optimal experience for a person is when he is in a state of flow.", "startOffset": 73, "endOffset": 79}, {"referenceID": 6, "context": "In addition to the right amount of challenge, Malone [10] proposes two more factors that make games engaging: fantasy and curiosity.", "startOffset": 53, "endOffset": 57}, {"referenceID": 7, "context": "Koster\u2019s theory of fun [11] states that the main source of enjoyment while playing a game is the act of mastering it.", "startOffset": 23, "endOffset": 27}, {"referenceID": 8, "context": "Rauterberg [12, 13] has introduced the concept of incongruity as a measure of interest in a task.", "startOffset": 11, "endOffset": 19}, {"referenceID": 9, "context": "Rauterberg [12, 13] has introduced the concept of incongruity as a measure of interest in a task.", "startOffset": 11, "endOffset": 19}, {"referenceID": 10, "context": "Many of them are covered in Yananakakis\u2019s recent survey [14].", "startOffset": 56, "endOffset": 60}, {"referenceID": 11, "context": "Iida [15], in 2003, has proposed a measure of entertainment for games and used it to analyze the evolution of game of chess over the centuries.", "startOffset": 5, "endOffset": 9}, {"referenceID": 12, "context": "In [16] the authors introduce the uncertainty of game outcome as a metric of entertainment.", "startOffset": 3, "endOffset": 7}, {"referenceID": 3, "context": "Togelius [6] has presented an approach to evolve entertaining car racing tracks for a video game.", "startOffset": 9, "endOffset": 12}, {"referenceID": 13, "context": "In [17] Togelius evolves entertaining computer games and uses a fitness function based on the learnability of the games.", "startOffset": 3, "endOffset": 7}, {"referenceID": 14, "context": "In [18] three metrics (which are combined into one) have been proposed for measuring the entertainment value of predator/prey games.", "startOffset": 3, "endOffset": 7}, {"referenceID": 23, "context": "Work in [31, 32] presents evolution of rules for predator/pray games based on somewhat same metrics as proposed in [18].", "startOffset": 8, "endOffset": 16}, {"referenceID": 14, "context": "Work in [31, 32] presents evolution of rules for predator/pray games based on somewhat same metrics as proposed in [18].", "startOffset": 115, "endOffset": 119}, {"referenceID": 5, "context": "Most of these studies are related to computer games [9, 20-28, 33, 35, 36] or physically interactive games [29] and none were done in the context of board games except [21].", "startOffset": 52, "endOffset": 74}, {"referenceID": 15, "context": "Most of these studies are related to computer games [9, 20-28, 33, 35, 36] or physically interactive games [29] and none were done in the context of board games except [21].", "startOffset": 52, "endOffset": 74}, {"referenceID": 16, "context": "Most of these studies are related to computer games [9, 20-28, 33, 35, 36] or physically interactive games [29] and none were done in the context of board games except [21].", "startOffset": 52, "endOffset": 74}, {"referenceID": 17, "context": "Most of these studies are related to computer games [9, 20-28, 33, 35, 36] or physically interactive games [29] and none were done in the context of board games except [21].", "startOffset": 52, "endOffset": 74}, {"referenceID": 18, "context": "Most of these studies are related to computer games [9, 20-28, 33, 35, 36] or physically interactive games [29] and none were done in the context of board games except [21].", "startOffset": 52, "endOffset": 74}, {"referenceID": 19, "context": "Most of these studies are related to computer games [9, 20-28, 33, 35, 36] or physically interactive games [29] and none were done in the context of board games except [21].", "startOffset": 52, "endOffset": 74}, {"referenceID": 20, "context": "Most of these studies are related to computer games [9, 20-28, 33, 35, 36] or physically interactive games [29] and none were done in the context of board games except [21].", "startOffset": 52, "endOffset": 74}, {"referenceID": 21, "context": "Most of these studies are related to computer games [9, 20-28, 33, 35, 36] or physically interactive games [29] and none were done in the context of board games except [21].", "startOffset": 52, "endOffset": 74}, {"referenceID": 25, "context": "Most of these studies are related to computer games [9, 20-28, 33, 35, 36] or physically interactive games [29] and none were done in the context of board games except [21].", "startOffset": 52, "endOffset": 74}, {"referenceID": 26, "context": "Most of these studies are related to computer games [9, 20-28, 33, 35, 36] or physically interactive games [29] and none were done in the context of board games except [21].", "startOffset": 52, "endOffset": 74}, {"referenceID": 16, "context": "Most of these studies are related to computer games [9, 20-28, 33, 35, 36] or physically interactive games [29] and none were done in the context of board games except [21].", "startOffset": 168, "endOffset": 172}, {"referenceID": 16, "context": "Other techniques like [21] may end up making a different board game thus two games may only be comparable, not the techniques.", "startOffset": 22, "endOffset": 26}, {"referenceID": 24, "context": "Having said this, game of chess has a history of 1500 years [34] and monopoly goes back to 1903.", "startOffset": 60, "endOffset": 64}, {"referenceID": 22, "context": "The architecture of the controller is the same architecture used by Chellapilla [30] for evolving an expert checkers player.", "startOffset": 80, "endOffset": 84}, {"referenceID": 22, "context": "Mutation is the only genetic operator used; we have kept the ANN and its training as close to Chellapilla [30] work as possible, except for the number of iteration for which the ANN is trained.", "startOffset": 106, "endOffset": 110}, {"referenceID": 0, "context": "Subject Age Gender Like Computer Games [1-10]", "startOffset": 39, "endOffset": 45}, {"referenceID": 1, "context": "Subject Age Gender Like Computer Games [1-10]", "startOffset": 39, "endOffset": 45}, {"referenceID": 2, "context": "Subject Age Gender Like Computer Games [1-10]", "startOffset": 39, "endOffset": 45}, {"referenceID": 3, "context": "Subject Age Gender Like Computer Games [1-10]", "startOffset": 39, "endOffset": 45}, {"referenceID": 4, "context": "Subject Age Gender Like Computer Games [1-10]", "startOffset": 39, "endOffset": 45}, {"referenceID": 5, "context": "Subject Age Gender Like Computer Games [1-10]", "startOffset": 39, "endOffset": 45}, {"referenceID": 6, "context": "Subject Age Gender Like Computer Games [1-10]", "startOffset": 39, "endOffset": 45}], "year": 2014, "abstractText": "Games have always been a popular test bed for artificial intelligence techniques. Game developers are always in constant search for techniques that can automatically create computer games minimizing the developer's task. In this work we present an evolutionary strategy based solution towards the automatic generation of two player board games. To guide the evolutionary process towards games, which are entertaining, we propose a set of metrics. These metrics are based upon different theories of entertainment in computer games. This work also compares the entertainment value of the evolved games with the existing popular board based games. Further to verify the entertainment value of the evolved games with the entertainment value of the human user a human user survey is conducted. In addition to the user survey we check the learnability of the evolved games using an artificial neural network based controller. The proposed metrics and the evolutionary process can be employed for generating new and entertaining board games, provided an initial search space is given to the evolutionary algorithm.", "creator": "Microsoft\u00ae Word 2010"}}}