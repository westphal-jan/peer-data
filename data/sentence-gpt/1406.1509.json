{"id": "1406.1509", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "5-Jun-2014", "title": "Systematic N-tuple Networks for Position Evaluation: Exceeding 90% in the Othello League", "abstract": "N-tuple networks have been successfully used as position evaluation functions for board games such as Othello or Connect Four. The effectiveness of such networks depends on their architecture, which is determined by the placement of constituent n-tuples, sequences of board locations, providing input to the network. The most popular method of placing n-tuples consists in randomly generating a small number of long, snake-shaped board location sequences. In comparison, we show that learning n-tuple networks is significantly more effective if they involve a large number of systematically placed, short, straight n-tuples. Moreover, we demonstrate that in order to obtain the best performance and the steepest learning curve for Othello it is enough to use n-tuples of size just 2, yielding a network consisting of only 288 weights. The best such network evolved in this study has been evaluated in the online Othello League, obtaining the performance of nearly 96% --- more than any other player to date.\n\n\n\n\n\nWe conducted in-depth research using a standard procedure known as the \"Othello League\" that allows us to study different types of n-tuples at different speeds and distances. The data was presented at the 2013 World Meeting of Science Communication.\nIn the 2013 World Meeting of Science Communication, participants were asked to place a set of 12 n-tuples on a 2-passing, 1-passing, 1-passing, 1-passing system. As a group, participants were asked to place a list of 8 n-tuples on a 2-passing, 1-passing, 1-passing, 1-passing, 1-passing system. Participants placed a set of 12 n-tuples on a 2-passing, 1-passing, 1-passing, 1-passing, 1-passing, 1-passing, 1-passing, 1-passing, 1-passing, 1-passing, 1-passing, 1-passing, 1-passing, 1-passing, 1-passing, 1-passing, 1-passing, 1-passing, 1-passing, 1-passing, 1-passing, 1-passing, 1-passing, 1-passing, 1-passing, 1-passing, 1-passing, 1-passing, 1-passing, 1-passing, 1-pass", "histories": [["v1", "Thu, 5 Jun 2014 20:10:48 GMT  (318kb,D)", "http://arxiv.org/abs/1406.1509v1", "8 pages, 7 figures, 4 tables"], ["v2", "Tue, 24 Jun 2014 10:06:29 GMT  (318kb,D)", "http://arxiv.org/abs/1406.1509v2", "Fixed a typo ($\\eps=0.01$ instead of $\\eps=0.1$ on page 8"], ["v3", "Wed, 25 Jun 2014 20:12:19 GMT  (318kb,D)", "http://arxiv.org/abs/1406.1509v3", "Added technical report number"]], "COMMENTS": "8 pages, 7 figures, 4 tables", "reviews": [], "SUBJECTS": "cs.NE cs.AI cs.LG", "authors": ["wojciech ja\\'skowski"], "accepted": false, "id": "1406.1509"}, "pdf": {"name": "1406.1509.pdf", "metadata": {"source": "CRF", "title": "Systematic N-tuple Networks for Position Evaluation: Exceeding 90% in the Othello League", "authors": ["Wojciech Ja\u015bkowski"], "emails": ["wjaskowski@cs.put.poznan.pl"], "sections": [{"heading": null, "text": "Systematic N-tuple Networks for Position Evaluation: Exceeding 90% in the Othello League\nWojciech Jas\u0301kowski Institute of Computing Science, Poznan University of Technology, Poznan\u0301, Poland\nwjaskowski@cs.put.poznan.pl\nAbstract\u2014N-tuple networks have been successfully used as position evaluation functions for board games such as Othello or Connect Four. The effectiveness of such networks depends on their architecture, which is determined by the placement of constituent n-tuples, sequences of board locations, providing input to the network. The most popular method of placing ntuples consists in randomly generating a small number of long, snake-shaped board location sequences. In comparison, we show that learning n-tuple networks is significantly more effective if they involve a large number of systematically placed, short, straight n-tuples. Moreover, we demonstrate that in order to obtain the best performance and the steepest learning curve for Othello it is enough to use n-tuples of size just 2, yielding a network consisting of only 288 weights. The best such network evolved in this study has been evaluated in the online Othello League, obtaining the performance of nearly 96% \u2014 more than any other player to date.\nKeywords: Othello, Reversi, evolution strategy, n-tuple networks, Othello League, tabular value functions, strategy representation\nI. INTRODUCTION\nBoard games have always attracted attention in AI due to they clear rules, mathematical elegance and simplicity. Since the early works of Claude Shannon on Chess [1] and Arthur Samuel on Checkers [2], a lot of research have been conducted in the area of board games towards finding either perfect players (Connect-4, [3]), or stronger than human players (Othello, [4]). The bottom line is that board games still constitute valuable test-beds for improving general artificial and computational intelligence game playing methods such as reinforcement learning, Monte Carlo tree search, branch and bound, and (co)evolutionary algorithms.\nMost of these techniques employ a position evaluation function to quantify the value of a given game state. In the context of Othello, one of the most successful position evaluation functions is tabular value function [5] or n-tuple network [6]. It consists of a number of n-tuples, each associated with a look up table, which maps contents of n board fields into a real value. The effectiveness of n-tuple network highly depends on the placement of n-tuples [7]. Typically, n-tuples architectures consist of a small number of long, randomly generated, snakeshaped n-tuples [8], [7], [9].\nDespite the importance of network architecture, to the best of our knowledge no study exist that studies and evaluates different ways of placing n-tuples on the board.\nIn this paper, we propose an n-tuple network architecture consisting of a large number of short, straight n-tuples, gen-\nerated in a systematic way. In the extensive computational experiments, we show that for learning position evaluation for Othello, such an architecture is significantly more effective than the one involving randomly generated n-tuples. We also investigate how the length of n-tuples affects the learning results. Finally, the performance of the best evolved n-tuple network is evaluated in the online Othello League.\nII. METHODS"}, {"heading": "A. Othello", "text": "Othello (a.k.a. Reversi) is a two player, deterministic, perfect information strategic game played on an 8 \u00d7 8 board. There are 64 pieces being black on one side and white on the other. The game starts with two white and two black pieces forming an askew cross in the center on the board. The players take turns putting one piece on the board with their color facing up. A legal move consists in placing a piece on a field so that it forms a vertical, horizontal, or diagonal line with another player\u2019s piece, with a continuous, non-empty sequence of opponent\u2019s pieces in between (see Fig. 1), which are reversed after the piece is placed. Player passes if and only if it cannot make a legal move. The game ends when both players passed consecutively. Then, the player having more pieces with their color facing up wins.\nar X\niv :1\n40 6.\n15 09\nv1 [\ncs .N\nE ]\n5 J\nun 2\n01 4\nOthello has been found to have around 1028 legal positions [10] and has is not been solved; this is one reason why it has become such a popular domain for computational intelligence methods [11], [12], [13], [14], [15], [16], [7], [17]."}, {"heading": "B. Position Evaluation Functions", "text": "In this paper, our goal is not to design state-of-the-art Othello players, but to evaluate position evaluation functions. That is why our players are simple state evaluators in a 1-ply setup: given the current state of the board, a player generates all legal moves and applies the position evaluation function to the resulting states. The state gauged as the most desirable determines the move to be played. Ties are resolved at random.\nThe simplest position evaluation function is positionweighted piece counter (WPC), which is a linear weighted board function. It assigns a weight wrc to a board location (r, c) and uses scalar product to calculate the utility f of a board state b = (brc)r,c=1...8:\nf (b) = 8\u2211 r=1 8\u2211 c=1 wrcbrc,\nwhere bij is 0 in the case of an empty location, +1 if a black piece is present or \u22121 in the case of a white piece.\nA WPC player often used in Othello research as an expert opponent [18], [6], [19], [13], [16], [7] is Standard WPC Heuristic Player (SWH). Its weights, hand-crafted by Yoshioka et al. [20], are presented in Table I."}, {"heading": "C. Othello Position Evaluation Function League", "text": "WPC is only one of the possible position evaluation functions. Others popular ones include neural networks and n-tuple networks. To allow direct comparison between various position evaluation functions and algorithms capable of learning their parameters, Lucas and Runarsson [18] have appointed the Othello Position Evaluation Function League 1. Othello League, for short, is an on-line ranking of Othello 1-ply state evaluator players. The players submitted to the league are evaluated against SWH (the Standard WPC Heuristic Player).\nBoth the game itself and the players are deterministic (with an exception of the rare situation when at least two positions have the same evaluation value). Therefore, to provide more continuous performance measure, Othello League introduces some randomization to Othello. Both players are forced to make random moves with the probability of = 0.1. As\n1http://algoval.essex.ac.uk:8080/othello/League.jsp\na consequence the players no longer play (deterministic) Othello, but stochastic -Othello. However, it was argued that the ability to play -Othello is highly correlated with the ability to play Othello [18].\nThe performance in Othello League is determined by the number of wins against SWH player in -Othello in 50 double games, each consisting of two single games played once white and once black. To aggregate the performance into a scalar value, we assume that a win counts as 1 point, while a draw 0.5 points. The average score obtained in this way against SWH constitutes the Othello League performance measure, which we incorporate in this paper."}, {"heading": "D. N-tuple Network", "text": "The best performing evaluation function in the Othello League is n-tuple network [16]. N-tuple networks have been first applied to optical character recognition problem by Bledsoe and Browning [21]. For games, it have been used first by Buro under the name of tabular value functions [5], and later popularized by Lucas [6]. According to Szubert et al. their main advantages of n-tuple networks \u201cinclude conceptual simplicity, speed of operation, and capability of realizing nonlinear mappings to spaces of higher dimensionality\u201d [7].\nN-tuple network consists of m ni-tuples, where ni is tuple\u2019s size. For a given board position b, it returns the sum of values returned by the individual n-tuples. The ith ni-tuple, for i = 1 . . .m, consists of a predetermined sequence of board locations (locij)j=1...ni , and a look up table LUTi. The latter contains values for each board pattern that can be observed on the sequence of board locations. Thus, n-tuple network is a function\nf(b) = m\u2211 i=1 fi(b) = m\u2211 i=1 LUTi [ index ( bloci1 , . . . , blocini )] .\nAmong possible ways to map the sequence to an index in the look up table, the following one is arguably convenient and computationally efficient:\nindex(v) = |v|\u2211 j=1 vjc j\u22121,\nwhere c is a constant denoting the number of possible values on a single board square, and v is the sequence of board values (the observed pattern) such that 0 \u2264 vj < c for j = 1 . . . |v|. In the case of Othello, c = 3, and white, empty, and black squares are encoded as 0, 1, and 2, respectively.\nThe effectiveness of n-tuple networks is improved by using symmetric sampling, which exploits the inherent symmetries of the Othello board [11]. In symmetric sampling, a single n-tuple is employed eight times, returning one value for each possible board rotation and reflection. See Fig. 2 for an illustration."}, {"heading": "E. N-tuple Network Architecture", "text": "Due to the spatial nature of game boards, n-tuples are usually consecutive snake-shaped sequences of locations, although this is not a formal requirement. If each n-tuple in a network is of the same size, we denote it as m\u00d7n-tuple network, having m\u00d7 3n weights. Apart from choosing n and m, an important design issue of n-tuples network architecture is the location of individual n-tuples on the board [7].\n1) Random Snake-shaped N-tuple Network: Thus it is surprising that so many investigations in game strategy learning have involved randomly generated snake-shaped n-tuple networks. Lucas [6] generated individual n-tuples by starting from a random board location, then taking a random walk of 6 steps in any of the eight orthogonal or diagonal directions. The repeated locations were ignored, thus the resulting n-tuples were from 2 to 6 squares long. The same method Krawiec and Szubert used for generating 7\u00d7 4, 9\u00d7 5 and 12\u00d7 6-tuple\nnetworks [22], [7], and Thill et al. [23] for generating 70\u00d7 8 tuple networks playing Connect Four.\nAn m \u00d7 n-tuple network generated in this way we will denote as rand-m\u00d7 n (see Fig. 3a for an example).\n2) Systematic Straight N-tuple Network: Alternatively, we propose a deterministic method of constructing n-tuple networks. Our systematic straight n-tuple networks consist of all possible vertical, horizontal or diagonal n-tuples placed on the board. Its smallest representative is a network of 1-tuples. Thanks to symmetric sampling, only 10 of them is required for an 8 \u00d7 8 Othello board, and such 10 \u00d7 1-tuple network, which we denote as all-1 contains 3\u00d7 101 = 30 weights. all2 network containing 32 2-tuples is shown in Fig. 3b. Table II shows the number of weights in selected architectures of rand-* and all-* networks.\n3) Other Approaches: Logistello [4], computer player, which beat the human Othello world champion in 1997, used 11 n-tuples of n \u2208 {3, 10}, hand-crafted by an expert. External knowledge has also been used by Manning [8], who, generated a diverse 12 \u00d7 6-tuple network using random inputs method from Breiman\u2019s Random Forests basing on a set of 10 000 labeled random games."}, {"heading": "F. Learning to Play Both Sides", "text": "When a single player defined by its evaluation function is meant to play both as black and white, it must interpret the result of the evaluation function complementary depending on the color it plays. There are three methods serving this purpose.\nThe first one is doubled function (e.g., [23]), which simply employs two separate functions: one for playing white and the other for playing black. It allows to fully separate the strategy for white and black players. However, its disadvantage consists in that two times more weights must be learned, and\nthe experience learned when playing as black does not used when playing as white and vice versa.\nOutput negation and board inversion (e.g., [9]) are alternatives to doubled function. They use only single set of weights, reducing the search space and allowing to transfer the experience between the white and black player. When using output negation, black selects the move leading to a position with the maximal value of the evaluation function whereas white selects the move leading to a position with the minimal value.\nIf a player uses board inversion it learns only to play black. As the best black move it selects the one leading to the position with the maximum value. If it has to play white, it temporarily flips all the pieces on the board, so it can interpret the board as if it played black. Then it selects the best \u2018black\u2019 move, flips all the pieces back, and plays the white piece in the selected location.\nThe SWH player uses output negation."}, {"heading": "III. EXPERIMENTS AND RESULTS", "text": ""}, {"heading": "A. Common Settings", "text": "1) Evolutionary Setup: In order to compare different ntuple network architectures, we performed several computational experiments. In each of them the weights of n-tuple networks have been learned by (10 + 90) evolution strategy [24] for 5000 generations. The weights of individuals in the initial population were drawn from the [\u22120.1, 0.1] interval. Evolution strategy used Gaussian mutation with \u03c3 = 1.0. The individual\u2019s fitness was calculated using the Othello League performance measure estimated over 1000 double games (cf. II-C).\nIn total, 1010 games were played in each evolutionary run. This makes our experiments exceptionally large compared to the previous studies. For example, in a recent study concerning n-tuple networks [7] 3\u00d7106 games were played. Also, despite using the much simpler WPC representation, Samothrakis et al. [16] performed 108 games per run.\nSuch extensive experiment was possible due to efficient n-tuple network and Othello implementation in Java, which is capable of running about 1000 games per second on a single CPU core. Thanks to it, we were able to finish one evolutionary run in 28 hours on a 6-core Intel(R) Core(TM) i7-2600 CPU @3.40GHz.\n2) Performance Evaluation: We repeated each evolutionary 10 times. Every 10 generations, we measured the (Othello League) performance of the fittest individual in the population\nusing 50 000 double games. The performance of the fittest individual from the last generation is identified with method\u2019s performance. Since, the sample size is only 10 per method, for statistical analysis of the following experiments, we used nonparametric Wilcoxon rank sum test (a.k.a. the Mann-Whitney U test) with the significance level \u03b1 = 0.01 and Holm\u2019s correction when comparing more than two methods at once."}, {"heading": "B. Preliminary: Board Inversion vs. Output Negation", "text": "Figure 4 presents the results of learning with board inversion against output negation for representatives of both types of ntuple networks architectures: rand-8\u00d7 4 having 8\u00d7 43 = 648, and all-1 with 10\u00d7 31 = 30 weights.\nThe figure shows that board inversion surpasses output negation regardless of the player architecture, which confirms a previous study of the two methods for preference learning [9]. The differences between the methods are statistically significant (see also the detailed results in Table IV).\nMoreover, visual inspection of the violin plots reveals that board inversion leads to more robust learning, since the variance of performances is lower. Therefore, in the following experiments we employ exclusively board inversion."}, {"heading": "C. All Short Straight vs. Random Long Snake-shaped N-tuples", "text": "In the main experiment, we compare n-tuple networks consisting of all possible short straight n-tuples (all-2, all-3, and all-4) with long random snake-shaped ones (rand-10\u00d7 3, rand-8 \u00d7 4 and rand-7 \u00d7 5). We chosen the number of ntuples and size of them to make the number of weights in of\ncorresponding architectures are equal, or, if impossible, similar (see Table II).\nThe results of the experiment are shown in Figure 5 as violin plots. Statistical analysis of three pairs having equal or similar number of weights reveals that: \u2022 all-2 is better than rand-10\u00d7 3, \u2022 all-3 is better than rand-8\u00d7 4, and \u2022 all-4 is better than rand-7\u00d7 5.\nLet us notice that the differences in performance are substantial: for the pair all-2 vs. rand-10\u00d7 3, where the difference in performance is the lowest, the best result obtained by rand10 \u00d7 3 is still lower than the worst result obtained by all-2 (see Table IV for details).\nAll-* architectures are also more robust, due to lower variances than rand-* architectures (cf. Fig. 5). This is because the variance of rand-* architectures is attributed to both its random initialization and non-deterministic learning process, while the variance of all-* is only due to the latter.\nD. 2-tuples are Long Enough\nIntuitively, longer n-tuples should lead to higher network\u2019s performance, since they can \u2018react\u2019 to patterns that the shorter ones cannot. However, the results presented in Fig. 5 show no evidence that this is a case. Despite having two times more weights, all-3 does not provide better performance than all-2 (no statistical difference). Furthermore, all-4 is significantly worse than both than all-2 and all-3.\nFigure 6 shows the pace of learning for each of six analyzed architectures. It plots methods\u2019 performance as a function of computational effort, which is proportional to the number of generations.\nThe figure suggests that all-2 is not only the best (together with all-3) in the long run, but it is also the method that learns the quickest. all-3 catches up all-2 eventually, but it does not\nseem to be able to surpass it. all-4 learns even slower than all-3. Although the gap between all-3 and all-4 decreases over time, it is still noticeable after 5000 generations.\nThus, our results suggest that for Othello, all-2 with just 288 weights, the smallest among the six considered n-tuple network architectures, is also the best one."}, {"heading": "E. Othello League Results", "text": "The best player obtained in this research consists of all 2- tuples; its performance is 0.9592 with 95% confidence delta of \u00b10.0012. This result is significantly higher than the best results reported to this date in the Othello League (see III). Notice also how small it is (in terms of the number of weights) compared to other players in the league. Unfortunately, the online Othello League accepts only players employing output negation; it does not allow for board inversion. Thus, our player could not be submitted to the Othello League.\nTo be accepted in the Othello League, we performed some experiments also with output negation. The best output negation player we were able to evolve was submitted under the name of wj-1-2-3-tuples. It consists of all straight 1-, 2-, and 3-tuples, thus having 966 weights in total.\nwj-1-2-3-tuples took the lead in the league and is the first player exceeding the performance of 0.9. It obtained 0.94 in the league, but this result should be taken with care, since to evaluate player\u2019s performance Othello League plays just 100 games. We estimate its performance to 0.9149\u00b10.0017 basing on 50 000 double games.\nWe suspect that the performance of ca. 0.96 against Standard WPC Heuristic player that all-2 and all-3 converge to, cannot be significantly improved at 1-ply. = 0.1 random moves using in all games leads to the situation when even a perfect-playing player cannot guarantee not losing a game.\nDespite the first place obtained in the Othello League, the evolved player is not good in \u2018general\u2019, against a variety of opponents, because is was evolved specifically to play against the Standard WPC Heuristic player. When evaluated against random WPC players (the expected utility measure [14], [25]), the best all-2 player obtains a score of only 0.9584\u00b1 0.0012. This is not much, since with considerably less computational effort that used in this paper, it is possible to evolve an n-tuple player scoring > 0.99 [26], [7]. However, our goal here was not to design good players in general, but to compare different position evaluation functions.\nThe best all-2 player evolved in this paper is printed in Fig. 7."}, {"heading": "IV. DISCUSSION: THE MORE WEIGHTS, THE WORSE FOR EVOLUTION?", "text": "We have shown that among all-* methods, the more weights the worse results; the same applies to rand-* methods (see Fig. 5). This finding confirms the one of Szubert et al. [7], who found out that among the networks of rand-12\u00d7 6 (8748 weights), rand-9 \u00d7 5 (2187 weights), and rand-7 \u00d7 4 (567 weights), it is the latter that allows (co)evolutionary algorithm for obtaining best results. The authors stated that this effect it due to the higher dimensionality of the search space, for which \u201cthe weight mutation operator is not sufficiently efficient to elaborate fast progress\u201d.\nAlthough we do not challenge this claim, our results suggest that the number of weights in a network is not the only performance factor. all-4 has 1701 weights, thus, the dimensionality of its search space is considerably higher than the one for rand-10\u00d7 3 and rand-8\u00d7 4, which have 270 and 648 weights, respectively. Nonetheless, among these three architectures, it is the all-4 network that obtains the highest performance (see Fig. 5). Therefore, the second performance factor in learning an n-tuple network is its (proper or not) architecture.\nFinally, let us notice that an alternative to a fixed n-tuple network architecture is a self-adaptive one, which can change in response to variation operators [7], such as mutation or crossover. Although such architecture is, in principle, more flexible, it adds another dimension to the search space, making the learning problem even harder."}, {"heading": "V. CONCLUSIONS", "text": "In this paper, we have analyzed n-tuple network architectures for position evaluation function in board games. We have shown that a network consisting of all possible, systematically generated, short n-tuples leads to a significantly better play than long random snake-shaped tuples originally used by Lucas [11]. With a simple network consisting of all possible straight 2-tuples (with just 288 weights) we were able to beat the best result in the on-line Othello League (having usually many times more weights).\nMoreover, our results suggest that tuples longer than 2 give no advantage, causing slower learning rate, at the same time. This is surprising, since capturing opponent\u2019s pieces in Othello requires a line of at least three pieces (e.g. white, black, white).\nLet us emphasize that our result has been obtained in an intensive computational experiment involving 5000 generations, an order of magnitude more than other studies in this domain. Nevertheless, it remains to be seen whether they hold for different experimental settings. We used evolution against an expert player in 1-ply -Othello. The interesting questions are: i) whether our systematic short 2-tuple network is also advantageous for reinforcement learning, such as temporal difference learning, and ii) whether such networks are also profitable for other board games, e.g. Connect Four."}, {"heading": "ACKNOWLEDGMENT", "text": "This work has been supported by the Polish National Science Centre grant no. DEC-2013/09/D/ST6/03932. The\n{ 2 8 { 38 46 } { 12 13 } { 52 53 } { 22 30 } { 50 51 } { 10 11 } { 33 41 } { 17 25 }\n{ 2 8 { 41 42 } { 13 21 } { 45 46 } { 45 53 } { 10 18 } { 21 22 } { 17 18 } { 42 50 }\n{ 2 8 { 37 46 } { 10 19 } { 17 26 } { 43 50 } { 22 29 } { 44 53 } { 13 20 } { 34 41 }\n{ 2 8 { 25 26 } { 12 20 } { 11 19 } { 33 34 } { 44 52 } { 43 51 } { 37 38 } { 29 30 }\n{ 2 8 { 30 37 } { 43 52 } { 29 38 } { 26 33 } { 44 51 } { 25 34 } { 11 20 } { 12 19 }\n{ 2 8 { 42 51 } { 21 30 } { 45 52 } { 11 18 } { 12 21 } { 18 25 } { 38 45 } { 33 42 }\n{ 2 8 { 34 42 } { 21 29 } { 20 21 } { 18 26 } { 18 19 } { 42 43 } { 37 45 } { 44 45 }\n{ 2 8 { 20 28 } { 34 35 } { 28 29 } { 36 37 } { 26 27 } { 35 43 } { 36 44 } { 19 27 }\n{ 2 8 { 19 28 } { 36 43 } { 29 36 } { 20 27 } { 26 35 } { 27 34 } { 35 44 } { 28 37 }\ncomputations have been performed in Poznan\u0301 Supercomputing and Networking Center. The author would like to thank Marcin Szubert for his helpful remarks on an earlier version of this article."}], "references": [{"title": "XXII. Programming a computer for playing chess", "author": ["C.E. Shannon"], "venue": "Philosophical magazine, vol. 41, no. 314, pp. 256\u2013275, 1950.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 1950}, {"title": "Some studies in machine learning using the game of checkers", "author": ["A.L. Samuel"], "venue": "IBM Journal of Research and Development, vol. 3, no. 3, pp. 211\u2013229, 1959.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 1959}, {"title": "A knowledge-based approach of connect-four", "author": ["L.V. Allis"], "venue": "Vrije Universiteit, Subfaculteit Wiskunde en Informatica,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 1988}, {"title": "Experiments with Multi-ProbCut and a new high-quality evaluation function for Othello", "author": ["M. Buro"], "venue": "Games in AI Research, pp. 77\u201396, 2000.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2000}, {"title": "An evaluation function for othello based on statistics", "author": ["\u2014\u2014"], "venue": "NEC, Princeton, NJ, NECI 31, Tech. Rep., 1997", "citeRegEx": "5", "shortCiteRegEx": null, "year": 1997}, {"title": "Learning to play Othello with n-tuple systems", "author": ["S. Lucas"], "venue": "Australian Journal of Intelligent Information . . . , no. 4, pp. 1\u201320, 2008", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2008}, {"title": "On Scalability, Generalization, and Hybridization of Coevolutionary Learning: a Case Study for Othello", "author": ["M. Szubert", "W. Ja\u015bkowski", "K. Krawiec"], "venue": "IEEE Transactions on Computational Intelligence and AI in Games, 2013.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2013}, {"title": "Using Resource-Limited Nash Memory to Improve an Othello Evaluation Function", "author": ["E.P. Manning", "A. Othello"], "venue": "IEEE Transactions on Computational Intelligence and AI in Games, vol. 2, no. 1, pp. 40\u201353, 2010.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2010}, {"title": "Preference Learning for Move Prediction and Evaluation Function Approximation in Othello", "author": ["T. Runarsson", "S. Lucas"], "venue": "Computational Intelligence and AI in Games, IEEE Transactions on, 2014.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2014}, {"title": "Searching for solutions in games and artificial intelligence", "author": ["V.L. Allis"], "venue": "Ph.D. dissertation, University of Limburg, Maastricht, The Netherlands, 1994.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 1994}, {"title": "Learning to play Othello with N-tuple systems", "author": ["S.M. Lucas"], "venue": "Australian Journal of Intelligent Information Processing Systems, Special Issue on Game Technology, vol. 9, no. 4, pp. 01\u201320, 2007.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2007}, {"title": "An Othello evaluation function based on Temporal Difference Learning using probability of winning", "author": ["Y. Osaki", "K. Shibahara", "Y. Tajima", "Y. Kotani"], "venue": "2008 IEEE Symposium On Computational Intelligence and Games, pp. 205\u2013211, Dec. 2008", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2008}, {"title": "Using resource-limited nash memory to improve an othello evaluation function", "author": ["E.P. Manning"], "venue": "Computational Intelligence and AI in Games, IEEE Transactions on, vol. 2, no. 1, pp. 40 \u201353, march 2010.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2010}, {"title": "Improving Generalization Performance in Co-Evolutionary Learning", "author": ["S.Y. Chong", "P. Tino", "D.C. Ku", "Y. Xin"], "venue": "IEEE Transactions on Evolutionary Computation, vol. 16, no. 1, pp. 70\u201385, 2012", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2012}, {"title": "Neural-Fitted TD-Leaf Learning for Playing Othello With Structured Neural Networks", "author": ["S. van den Dries", "M.A. Wiering"], "venue": "IEEE Transactions on Neural Networks and Learning Systems, vol. 23, no. 11, pp. 1701\u20131713, Nov. 2012", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2012}, {"title": "Coevolving Game-Playing Agents: Measuring Performance and Intransitivities", "author": ["S. Samothrakis", "S. Lucas", "T. Runarsson", "D. Robles"], "venue": "IEEE Transactions on Evolutionary Computation, no. 99, pp. 1\u201315, 2012", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2012}, {"title": "Multi-criteria comparison of coevolution and temporal difference learning on othello", "author": ["W. Ja\u015bkowski", "M. Szubert", "P. Liskowski"], "venue": "EvoGames, ser. Lectures Notes in Computer Science, 2014.", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2014}, {"title": "Temporal difference learning versus co-evolution for acquiring othello position evaluation", "author": ["S.M. Lucas", "T.P. Runarsson"], "venue": "IEEE Symposium on Computational Intelligence and Games. IEEE, 2006, pp. 52\u201359.", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2006}, {"title": "Coevolutionary Temporal Difference Learning for Othello", "author": ["M. Szubert", "W. Ja\u015bkowski", "K. Krawiec"], "venue": "IEEE Symposium on Computational Intelligence and Games, 2009, Conference proceedings (article), pp. 104\u2013111", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2009}, {"title": "Strategy acquisition for the game", "author": ["T. Yoshioka", "S. Ishii", "M. Ito"], "venue": "Strategy Acquisition for the Game \"Othello\" Based on Reinforcement Learning, vol. 82, no. 12, pp. 1618\u20131626, 1999.", "citeRegEx": "20", "shortCiteRegEx": null, "year": 1999}, {"title": "Pattern recognition and reading by machine", "author": ["W.W. Bledsoe", "I. Browning"], "venue": "Proc. Eastern Joint Comput. Conf., 1959, pp. 225\u2013232.", "citeRegEx": "21", "shortCiteRegEx": null, "year": 1959}, {"title": "Learning n-tuple networks for othello by coevolutionary gradient search", "author": ["K. Krawiec", "M. Szubert"], "venue": "GECCO 2011 Proceedings, N. K. et al, Ed., ACM. ACM, 2011, pp. 355\u2013362.", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2011}, {"title": "Reinforcement Learning with Ntuples on the Game Connect-4", "author": ["M. Thill", "P. Koch", "W. Konen"], "venue": "Parallel Problem Solving from Nature - PPSN XII, ser. Lecture Notes in Computer Science, C. A. C. Coello, V. Cutello, K. Deb, S. Forrest, G. Nicosia, and M. Pavone, Eds., vol. 7491. Springer, 2012, pp. 184\u2013194.", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2012}, {"title": "Evolution strategies\u2013a comprehensive introduction", "author": ["H.-G. Beyer", "H.-P. Schwefel"], "venue": "Natural computing, vol. 1, no. 1, pp. 3\u201352, 2002.", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2002}, {"title": "Improving coevolution by random sampling", "author": ["W. Ja\u015bkowski", "P. Liskowski", "M. Szubert", "K. Krawiec"], "venue": "GECCO\u201913: Proceedings of the 15th annual conference on Genetic and Evolutionary Computation, C. Blum, Ed. Amsterdam, The Netherlands: ACM, July 2013, pp. 1141\u20131148.", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2013}], "referenceMentions": [{"referenceID": 0, "context": "Since the early works of Claude Shannon on Chess [1] and Arthur Samuel on Checkers [2], a lot of research have been conducted in the area of board games towards finding either perfect players (Connect-4, [3]), or stronger than human players (Othello, [4]).", "startOffset": 49, "endOffset": 52}, {"referenceID": 1, "context": "Since the early works of Claude Shannon on Chess [1] and Arthur Samuel on Checkers [2], a lot of research have been conducted in the area of board games towards finding either perfect players (Connect-4, [3]), or stronger than human players (Othello, [4]).", "startOffset": 83, "endOffset": 86}, {"referenceID": 2, "context": "Since the early works of Claude Shannon on Chess [1] and Arthur Samuel on Checkers [2], a lot of research have been conducted in the area of board games towards finding either perfect players (Connect-4, [3]), or stronger than human players (Othello, [4]).", "startOffset": 204, "endOffset": 207}, {"referenceID": 3, "context": "Since the early works of Claude Shannon on Chess [1] and Arthur Samuel on Checkers [2], a lot of research have been conducted in the area of board games towards finding either perfect players (Connect-4, [3]), or stronger than human players (Othello, [4]).", "startOffset": 251, "endOffset": 254}, {"referenceID": 4, "context": "In the context of Othello, one of the most successful position evaluation functions is tabular value function [5] or n-tuple network [6].", "startOffset": 110, "endOffset": 113}, {"referenceID": 5, "context": "In the context of Othello, one of the most successful position evaluation functions is tabular value function [5] or n-tuple network [6].", "startOffset": 133, "endOffset": 136}, {"referenceID": 6, "context": "The effectiveness of n-tuple network highly depends on the placement of n-tuples [7].", "startOffset": 81, "endOffset": 84}, {"referenceID": 7, "context": "Typically, n-tuples architectures consist of a small number of long, randomly generated, snakeshaped n-tuples [8], [7], [9].", "startOffset": 110, "endOffset": 113}, {"referenceID": 6, "context": "Typically, n-tuples architectures consist of a small number of long, randomly generated, snakeshaped n-tuples [8], [7], [9].", "startOffset": 115, "endOffset": 118}, {"referenceID": 8, "context": "Typically, n-tuples architectures consist of a small number of long, randomly generated, snakeshaped n-tuples [8], [7], [9].", "startOffset": 120, "endOffset": 123}, {"referenceID": 9, "context": "Othello has been found to have around 10 legal positions [10] and has is not been solved; this is one reason why it has become such a popular domain for computational intelligence methods [11], [12], [13], [14], [15], [16], [7], [17].", "startOffset": 57, "endOffset": 61}, {"referenceID": 10, "context": "Othello has been found to have around 10 legal positions [10] and has is not been solved; this is one reason why it has become such a popular domain for computational intelligence methods [11], [12], [13], [14], [15], [16], [7], [17].", "startOffset": 188, "endOffset": 192}, {"referenceID": 11, "context": "Othello has been found to have around 10 legal positions [10] and has is not been solved; this is one reason why it has become such a popular domain for computational intelligence methods [11], [12], [13], [14], [15], [16], [7], [17].", "startOffset": 194, "endOffset": 198}, {"referenceID": 12, "context": "Othello has been found to have around 10 legal positions [10] and has is not been solved; this is one reason why it has become such a popular domain for computational intelligence methods [11], [12], [13], [14], [15], [16], [7], [17].", "startOffset": 200, "endOffset": 204}, {"referenceID": 13, "context": "Othello has been found to have around 10 legal positions [10] and has is not been solved; this is one reason why it has become such a popular domain for computational intelligence methods [11], [12], [13], [14], [15], [16], [7], [17].", "startOffset": 206, "endOffset": 210}, {"referenceID": 14, "context": "Othello has been found to have around 10 legal positions [10] and has is not been solved; this is one reason why it has become such a popular domain for computational intelligence methods [11], [12], [13], [14], [15], [16], [7], [17].", "startOffset": 212, "endOffset": 216}, {"referenceID": 15, "context": "Othello has been found to have around 10 legal positions [10] and has is not been solved; this is one reason why it has become such a popular domain for computational intelligence methods [11], [12], [13], [14], [15], [16], [7], [17].", "startOffset": 218, "endOffset": 222}, {"referenceID": 6, "context": "Othello has been found to have around 10 legal positions [10] and has is not been solved; this is one reason why it has become such a popular domain for computational intelligence methods [11], [12], [13], [14], [15], [16], [7], [17].", "startOffset": 224, "endOffset": 227}, {"referenceID": 16, "context": "Othello has been found to have around 10 legal positions [10] and has is not been solved; this is one reason why it has become such a popular domain for computational intelligence methods [11], [12], [13], [14], [15], [16], [7], [17].", "startOffset": 229, "endOffset": 233}, {"referenceID": 17, "context": "A WPC player often used in Othello research as an expert opponent [18], [6], [19], [13], [16], [7] is Standard WPC Heuristic Player (SWH).", "startOffset": 66, "endOffset": 70}, {"referenceID": 5, "context": "A WPC player often used in Othello research as an expert opponent [18], [6], [19], [13], [16], [7] is Standard WPC Heuristic Player (SWH).", "startOffset": 72, "endOffset": 75}, {"referenceID": 18, "context": "A WPC player often used in Othello research as an expert opponent [18], [6], [19], [13], [16], [7] is Standard WPC Heuristic Player (SWH).", "startOffset": 77, "endOffset": 81}, {"referenceID": 12, "context": "A WPC player often used in Othello research as an expert opponent [18], [6], [19], [13], [16], [7] is Standard WPC Heuristic Player (SWH).", "startOffset": 83, "endOffset": 87}, {"referenceID": 15, "context": "A WPC player often used in Othello research as an expert opponent [18], [6], [19], [13], [16], [7] is Standard WPC Heuristic Player (SWH).", "startOffset": 89, "endOffset": 93}, {"referenceID": 6, "context": "A WPC player often used in Othello research as an expert opponent [18], [6], [19], [13], [16], [7] is Standard WPC Heuristic Player (SWH).", "startOffset": 95, "endOffset": 98}, {"referenceID": 19, "context": "[20], are presented in Table I.", "startOffset": 0, "endOffset": 4}, {"referenceID": 17, "context": "To allow direct comparison between various position evaluation functions and algorithms capable of learning their parameters, Lucas and Runarsson [18] have appointed the Othello Position Evaluation Function League 1.", "startOffset": 146, "endOffset": 150}, {"referenceID": 17, "context": "However, it was argued that the ability to play -Othello is highly correlated with the ability to play Othello [18].", "startOffset": 111, "endOffset": 115}, {"referenceID": 15, "context": "The best performing evaluation function in the Othello League is n-tuple network [16].", "startOffset": 81, "endOffset": 85}, {"referenceID": 20, "context": "N-tuple networks have been first applied to optical character recognition problem by Bledsoe and Browning [21].", "startOffset": 106, "endOffset": 110}, {"referenceID": 4, "context": "For games, it have been used first by Buro under the name of tabular value functions [5], and later popularized by Lucas [6].", "startOffset": 85, "endOffset": 88}, {"referenceID": 5, "context": "For games, it have been used first by Buro under the name of tabular value functions [5], and later popularized by Lucas [6].", "startOffset": 121, "endOffset": 124}, {"referenceID": 6, "context": "their main advantages of n-tuple networks \u201cinclude conceptual simplicity, speed of operation, and capability of realizing nonlinear mappings to spaces of higher dimensionality\u201d [7].", "startOffset": 177, "endOffset": 180}, {"referenceID": 10, "context": "The effectiveness of n-tuple networks is improved by using symmetric sampling, which exploits the inherent symmetries of the Othello board [11].", "startOffset": 139, "endOffset": 143}, {"referenceID": 6, "context": "Apart from choosing n and m, an important design issue of n-tuples network architecture is the location of individual n-tuples on the board [7].", "startOffset": 140, "endOffset": 143}, {"referenceID": 5, "context": "Lucas [6] generated individual n-tuples by starting from a random board location, then taking a random walk of 6 steps in any of the eight orthogonal or diagonal directions.", "startOffset": 6, "endOffset": 9}, {"referenceID": 21, "context": "The same method Krawiec and Szubert used for generating 7\u00d7 4, 9\u00d7 5 and 12\u00d7 6-tuple networks [22], [7], and Thill et al.", "startOffset": 92, "endOffset": 96}, {"referenceID": 6, "context": "The same method Krawiec and Szubert used for generating 7\u00d7 4, 9\u00d7 5 and 12\u00d7 6-tuple networks [22], [7], and Thill et al.", "startOffset": 98, "endOffset": 101}, {"referenceID": 22, "context": "[23] for generating 70\u00d7 8 tuple networks playing Connect Four.", "startOffset": 0, "endOffset": 4}, {"referenceID": 3, "context": "3) Other Approaches: Logistello [4], computer player, which beat the human Othello world champion in 1997, used 11 n-tuples of n \u2208 {3, 10}, hand-crafted by an expert.", "startOffset": 32, "endOffset": 35}, {"referenceID": 7, "context": "External knowledge has also been used by Manning [8], who, generated a diverse 12 \u00d7 6-tuple network using random inputs method from Breiman\u2019s Random Forests basing on a set of 10 000 labeled random games.", "startOffset": 49, "endOffset": 52}, {"referenceID": 22, "context": ", [23]), which simply employs two separate functions: one for playing white and the other for playing black.", "startOffset": 2, "endOffset": 6}, {"referenceID": 8, "context": ", [9]) are alternatives to doubled function.", "startOffset": 2, "endOffset": 5}, {"referenceID": 23, "context": "In each of them the weights of n-tuple networks have been learned by (10 + 90) evolution strategy [24] for 5000 generations.", "startOffset": 98, "endOffset": 102}, {"referenceID": 6, "context": "For example, in a recent study concerning n-tuple networks [7] 3\u00d7106 games were played.", "startOffset": 59, "endOffset": 62}, {"referenceID": 15, "context": "[16] performed 10 games per run.", "startOffset": 0, "endOffset": 4}, {"referenceID": 8, "context": "The figure shows that board inversion surpasses output negation regardless of the player architecture, which confirms a previous study of the two methods for preference learning [9].", "startOffset": 178, "endOffset": 181}, {"referenceID": 6, "context": "2011-01-30 epTDLmpx_12x6 [7] n-tuple network 3240 0.", "startOffset": 25, "endOffset": 28}, {"referenceID": 6, "context": "2011-01-25 epTDLxover [7] n-tuple network 4698 0.", "startOffset": 22, "endOffset": 25}, {"referenceID": 6, "context": "The performances of all-2 and wj-1-2-3-tuples players have been estimated using 50 000 double games, and the performance of epTDLmpx_12x6 has been reported in [7].", "startOffset": 159, "endOffset": 162}, {"referenceID": 13, "context": "When evaluated against random WPC players (the expected utility measure [14], [25]), the best all-2 player obtains a score of only 0.", "startOffset": 72, "endOffset": 76}, {"referenceID": 24, "context": "When evaluated against random WPC players (the expected utility measure [14], [25]), the best all-2 player obtains a score of only 0.", "startOffset": 78, "endOffset": 82}, {"referenceID": 6, "context": "99 [26], [7].", "startOffset": 9, "endOffset": 12}, {"referenceID": 6, "context": "[7], who found out that among the networks of rand-12\u00d7 6 (8748 weights), rand-9 \u00d7 5 (2187 weights), and rand-7 \u00d7 4 (567 weights), it is the latter that allows (co)evolutionary algorithm for obtaining best results.", "startOffset": 0, "endOffset": 3}, {"referenceID": 6, "context": "Finally, let us notice that an alternative to a fixed n-tuple network architecture is a self-adaptive one, which can change in response to variation operators [7], such as mutation or crossover.", "startOffset": 159, "endOffset": 162}, {"referenceID": 10, "context": "We have shown that a network consisting of all possible, systematically generated, short n-tuples leads to a significantly better play than long random snake-shaped tuples originally used by Lucas [11].", "startOffset": 197, "endOffset": 201}], "year": 2017, "abstractText": "N-tuple networks have been successfully used as position evaluation functions for board games such as Othello or Connect Four. The effectiveness of such networks depends on their architecture, which is determined by the placement of constituent n-tuples, sequences of board locations, providing input to the network. The most popular method of placing ntuples consists in randomly generating a small number of long, snake-shaped board location sequences. In comparison, we show that learning n-tuple networks is significantly more effective if they involve a large number of systematically placed, short, straight n-tuples. Moreover, we demonstrate that in order to obtain the best performance and the steepest learning curve for Othello it is enough to use n-tuples of size just 2, yielding a network consisting of only 288 weights. The best such network evolved in this study has been evaluated in the online Othello League, obtaining the performance of nearly 96% \u2014 more than any other player to date.", "creator": "LaTeX with hyperref package"}}}