{"id": "1406.5600", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "21-Jun-2014", "title": "From conformal to probabilistic prediction", "abstract": "This paper proposes a new method of probabilistic prediction, which is based on conformal prediction. The method is applied to the standard USPS data set and gives encouraging results. It should be a more complete tool than usual.\n\n\nThis paper is available on the Google Scholar and the Web page of the journal.\nI recently made a request to the authors to study the effects of the system on the performance of the data set. The following was originally presented in the Proceedings of the National Academy of Sciences (PNAS).", "histories": [["v1", "Sat, 21 Jun 2014 11:47:21 GMT  (13kb)", "http://arxiv.org/abs/1406.5600v1", "12 pages, 2 tables"]], "COMMENTS": "12 pages, 2 tables", "reviews": [], "SUBJECTS": "cs.LG", "authors": ["vladimir vovk", "ivan petej", "valentina fedorova"], "accepted": false, "id": "1406.5600"}, "pdf": {"name": "1406.5600.pdf", "metadata": {"source": "CRF", "title": null, "authors": [], "emails": ["volodya.vovk@gmail.com", "ivan.petej@gmail.com", "alushaf@gmail.com"], "sections": [{"heading": null, "text": "ar X\niv :1\n40 6.\n56 00\nv1 [\ncs .L\nG ]\n2 1\nThis paper proposes a new method of probabilistic prediction, which is based on conformal prediction. The method is applied to the standard USPS data set and gives encouraging results."}, {"heading": "1 Introduction", "text": "In essence, conformal predictors output systems of p-values: to each potential label of a test object a conformal predictor assigns the corresponding p-value, and a low p-value is interpreted as the label being unlikely. It has been argued, especially by Bayesian statisticians, that p-values are more difficult to interpret than probabilities; besides, in decision problems probabilities can be easily combined with utilities to obtain decisions that are optimal from the point of view of Bayesian decision theory. In this paper we will apply the idea of transforming p-values into probabilities (used in a completely different context in, e.g., [10], Sect. 9, and [7]) to conformal prediction: the p-values produced by conformal predictors will be transformed into probabilities.\nThe approach of this paper is as follows. It was observed in [12] that some criteria of efficiency for conformal prediction (called \u201cprobabilistic criteria\u201d) encourage using the conditional probability Q(y | x) as the conformity score for an observation (x, y), Q being the data-generating distribution. In this paper we extend this observation to label-conditional predictors (Sect. 2).\nNext we imagine that we are given a conformal predictor \u0393 that is nearly optimal with respect to a probabilistic criterion (such a conformal predictor might be an outcome of a thorough empirical study of various conformal predictors using a probabilistic criterion of efficiency). Essentially, this means that in the limit of a very large training set the p-value that \u0393 outputs for an observation (x, y) is a monotonic transformation of the conditional probability Q(y | x) (Theorem 1 in Sect. 3).\nFinally, we transform the p-values back into conditional probabilities using the distribution of p-values in the test set (Sect. 5). Following [10] and [7], we will say that at this step we calibrate the p-values into probabilities,\nIn Sect. 6 we give an example of a realistic situation where use of the techniques developed in this paper improves on a standard approach. The performance of the probabilistic predictors considered in that section is measured using standard loss functions, logarithmic and Brier (Sect. 4).\nComparisons with related work\nIt should be noted that in the process of transforming p-values into probabilities suggested in this paper we lose a valuable feature of conformal prediction, its automatic validity. Our hope, however, is that the advantages of conformal prediction will translate into accurate probabilistic predictions.\nThere is another method of probabilistic prediction that is related to conformal prediction, Venn prediction (see, e.g., [13], Chap. 6, or [14]). This method does have a guaranteed property of validity (perhaps the simplest being Theorem 1 in [14]); however, the price to pay is that it outputs multiprobabilistic predictions rather than sharp probabilistic predictions. There are natural ways of transforming multiprobabilistic predictions into sharp probabilistic predictions (see, e.g., [14], Sect. 4), but such transformations, again, lead to the loss of the formal property of validity.\nAs preparation, we study label-conditional conformal prediction. For a general discussion of conditionality in conformal prediction, see [11]. Objectconditional conformal prediction has been studied in [5] (in the case of regression)."}, {"heading": "2 Criteria of efficiency for label-conditional con-", "text": "formal predictors and transducers\nLet X be a measurable space (the object space) and Y be a finite set equipped with the discrete \u03c3-algebra (the label space); the observation space is defined to be Z := X \u00d7 Y. A conformity measure is a measurable function A that assigns to every sequence (z1, . . . , zn) \u2208 Z\n\u2217 of observations a same-length sequence (\u03b11, . . . , \u03b1n) of real numbers and that is equivariant with respect to permutations: for any n and any permutation \u03c0 of {1, . . . , n},\n(\u03b11, . . . , \u03b1n) = A(z1, . . . , zn) =\u21d2 ( \u03b1\u03c0(1), . . . , \u03b1\u03c0(n) ) = A ( z\u03c0(1), . . . , z\u03c0(n) ) .\nThe label-conditional conformal predictor determined by A is defined by\n\u0393\u01eb(z1, . . . , zl, x) := {y | p y > \u01eb} , (1)\nwhere (z1, . . . , zl) \u2208 Z \u2217 is a training sequence, x is a test object, \u01eb \u2208 (0, 1) is a given significance level, and for each y \u2208 Y the corresponding label-conditional p-value py is defined by\npy :=\n\u2223 \u2223 { i = 1, . . . , l+ 1 | yi = y & \u03b1 y i < \u03b1 y l+1 }\u2223 \u2223\n|{i = 1, . . . , l + 1 | yi = y}|\n+ \u03c4\n\u2223 \u2223 { i = 1, . . . , l + 1 | yi = y & \u03b1 y i = \u03b1 y l+1 }\u2223 \u2223\n|{i = 1, . . . , l + 1 | yi = y}| , (2)\nwhere \u03c4 is a random number distributed uniformly on the interval [0, 1] and the corresponding sequence of conformity scores is defined by\n(\u03b1y1 , . . . , \u03b1 y l , \u03b1 y l+1) := A(z1, . . . , zl, (x, y)).\nIt is clear that the system of prediction sets (1) output by a conformal predictor is nested, namely decreasing in \u01eb.\nThe label-conditional conformal transducer determined by A outputs the system of p-values (py | y \u2208 Y) defined by (2) for each training sequence (z1, . . . , zl) of observations and each test object x."}, {"heading": "Four criteria of efficiency", "text": "Suppose that, besides the training sequence, we are also given a test sequence, and would like to measure on it the performance of a label-conditional conformal predictor or transducer. As usual, let us define the performance on the test set to be the average performance (or, equivalently, the sum of performances) on the individual test observations. Following [12], we will discuss the following four criteria of efficiency for individual test observations; all the criteria will work in the same direction: the smaller the better.\n\u2022 The sum \u2211 y\u2208Y p y of the p-values; referred to as the S criterion. This is\napplicable to conformal transducers (i.e., the criterion is \u01eb-independent).\n\u2022 The size |\u0393\u01eb| of the prediction set at a significance level \u01eb; this is the N criterion. It is applicable to conformal predictors (\u01eb-dependent).\n\u2022 The sum of the p-values apart from that for the true label: the OF (\u201cobserved fuzziness\u201d) criterion.\n\u2022 The number of false labels included in the prediction set \u0393\u01eb at a significance level \u01eb; this is the OE (\u201cobserved excess\u201d) criterion.\nThe last two criteria are simple modifications of the first two (leading to smoother and more expressive pictures).\nRemark 1. Equivalently, the S criterion can be defined as the arithmetic mean 1 |Y| \u2211 y\u2208Y p y of the p-values; the proof of Theorem 1 below will show that, in fact, we can replace arithmetic mean by any mean ([3], Sect. 3.1), including geometric, harmonic, etc."}, {"heading": "3 Optimal idealized conformity measures for a", "text": "known probability distribution\nIn this section we consider the idealized case where the probability distribution Q generating independent observations z1, z2, . . . is known (as in [12]). The\nmain result of this section, Theorem 1, is the label-conditional counterpart of Theorem 1 in [12]; the proof of our Theorem 1 is also modelled on the proof of Theorem 1 in [12]. In this section we assume, for simplicity, that the set Z is finite and that Q({z}) > 0 for all z \u2208 Z.\nAn idealized conformity measure is a function A(z,Q) of z \u2208 Z andQ \u2208 P(Z) (where P(Z) is the set of all probability measures on Z). We will sometimes write the corresponding conformity scores as A(z), as Q will be clear from the context. The idealized smoothed label-conditional conformal predictor corresponding to A outputs the following prediction set \u0393\u01eb(x) for each object x \u2208 X and each significance level \u01eb \u2208 (0, 1). For each potential label y \u2208 Y for x define the corresponding label-conditional p-value as\npy = p(x, y) := Q({(x\u2032, y) | x\u2032 \u2208 X & A((x\u2032, y), Q) < A((x, y), Q)})\nQY({y})\n+ \u03c4 Q({(x\u2032, y) | x\u2032 \u2208 X & A((x\u2032, y), Q) = A((x, y), Q)})\nQY({y}) (3)\n(this is the idealized analogue of (2)), where QY is the marginal distribution of Q on Y and \u03c4 is a random number distributed uniformly on [0, 1]. The prediction set is\n\u0393\u01eb(x) := {y \u2208 Y | p(x, y) > \u01eb} . (4)\nThe idealized smoothed label-conditional conformal transducer corresponding to A outputs for each object x \u2208 X the system of p-values (py | y \u2208 Y) defined by (3); in the idealized case we will usually use the alternative notation p(x, y) for py."}, {"heading": "Four idealized criteria of efficiency", "text": "In this subsection we will apply the four criteria of efficiency that we discussed in the previous section to the idealized case of infinite training and test sequences; since the sequences are infinite, they carry all information about the data-generating distribution Q. We will write \u0393\u01ebA(x) for the \u0393\n\u01eb(x) in (4) and pA(x, y) for the p(x, y) in (3) to indicate the dependence on the choice of the conformity measure A. Let U be the uniform probability measure on the interval [0, 1].\nAn idealized conformity measure A is:\n\u2022 S-optimal if E(x,\u03c4)\u223cQX\u00d7U \u2211 y pA(x, y) \u2264 E(x,\u03c4)\u223cQX\u00d7U \u2211\ny pB(x, y) for any idealized conformity measure B, where QX is the marginal distribution of Q on X;\n\u2022 N-optimal if E(x,\u03c4)\u223cQX\u00d7U |\u0393 \u01eb A(x)| \u2264 E(x,\u03c4)\u223cQX\u00d7U |\u0393 \u01eb B(x)| for any idealized\nconformity measure B and any significance level \u01eb;\n\u2022 OF-optimal if\nE((x,y),\u03c4)\u223cQ\u00d7U\n\u2211\ny\u2032 6=y\npA(x, y \u2032) \u2264 E((x,y),\u03c4)\u223cQ\u00d7U\n\u2211\ny\u2032 6=y\npA(x, y \u2032)\nfor any idealized conformity measure B;\n\u2022 OE-optimal if\nE((x,y),\u03c4)\u223cQ\u00d7U |\u0393 \u01eb A(x) \\ {y}| \u2264 E((x,y),\u03c4)\u223cQ\u00d7U |\u0393 \u01eb B(x) \\ {y}|\nfor any idealized conformity measure B and any significance level \u01eb.\nThe conditional probability (CP) idealized conformity measure is\nA((x, y), Q) := Q(y | x).\nAn idealized conformity measure A is a (label-conditional) refinement of an idealized conformity measure B if\nB((x1, y)) < B((x2, y)) =\u21d2 A((x1, y)) < A((x2, y)) (5)\nfor all x1, x2 \u2208 Z and all y \u2208 Y. (Notice that this definition, being labelconditional, is different from the one given in [12].) Let R(CP) be the set of all refinements of the CP idealized conformity measure. If C is a criterion of efficiency (one of the four discussed above), we let O(C) stand for the set of all C-optimal idealized conformity measures.\nTheorem 1. O(S) = O(OF) = O(N) = O(OE) = R(CP).\nProof. We start from proving R(CP) = O(N). Fix a significance level \u01eb. A smoothed confidence predictor at level \u01eb is defined as a random set of observations (x, y) \u2208 Z; in other words, to each observation (x, y) is assigned the probability P (x, y) that the observation will be outside the prediction set. Under the restriction that the sum of the probabilities Q(x, y) of observations (x, y) outside the prediction set (defined as \u2211\nxQ(x, y)P (x, y) in the smoothed case) is bounded by \u01ebQY(y) for a fixed y, the N criterion requires us to make the sum of QX(x) for (x, y) outside the prediction set (defined as \u2211\nx QXP (x, y) in the smoothed case) as large as possible. It is clear that the set should consist of the observations with the smallest Q(y | x) (by the usual Neyman\u2013Pearson argument: cf. [4], Sect. 3.2).\nNext we show that O(N) \u2286 O(S). Let an idealized conformity measure A be N-optimal. By definition,\nEx,\u03c4 |\u0393 \u01eb A(x)| \u2264 Ex,\u03c4 |\u0393 \u01eb B(x)|\nfor any idealized conformity measure B and any significance level \u01eb. Integrating over \u01eb \u2208 (0, 1) and swapping the order of integrals and expectations,\nEx,\u03c4\n\u222b 1\n0\n|\u0393\u01ebA(x)| d\u01eb \u2264 Ex,\u03c4\n\u222b 1\n0\n|\u0393\u01ebB(x)| d\u01eb. (6)\nSince |\u0393\u01eb(x)| = \u2211\ny\u2208Y\n1{p(x,y)>\u01eb},\nwe can rewrite (6), after swapping the order of summation and integration, as\nEx,\u03c4\n\u2211\ny\u2208Y\n( \u222b 1\n0\n1{pA(x,y)>\u01eb} d\u01eb\n)\n\u2264 Ex,\u03c4 \u2211\ny\u2208Y\n( \u222b 1\n0\n1{pB(x,y)>\u01eb} d\u01eb\n)\n.\nSince \u222b 1\n0\n1{p(x,y)>\u01eb} d\u01eb = p(x, y),\nwe finally obtain\nEx,\u03c4\n\u2211\ny\u2208Y\npA(x, y) \u2264 Ex,\u03c4 \u2211\ny\u2208Y\npB(x, y).\nSince this holds for any idealized conformity measure B, A is S-optimal. The argument in the previous paragraph in fact shows that O(S) = O(N) = R(CP). Indeed, that argument shows that\n\u2211\ny\u2208Y\np(x, y) =\n\u222b 1\n0\n|\u0393\u01eb(x)| d\u01eb,\nand so to optimize a conformity measure in the sense of the S criterion it suffices to optimize it in the sense of the N criterion for all \u01eb simultaneously (which can, and therefore should, be done). More generally, for any continuous increasing function \u03c6 we have\n\u2211\ny\u2208Y\n\u03c6(p(x, y)) = \u2211\ny\u2208Y\n\u222b 1\n0\n1{\u03c6(p(x,y))>\u01eb} d\u01eb =\n\u222b 1\n0\n\u2211\ny\u2208Y\n1{p(x,y)>\u03c6\u22121(\u01eb)} d\u01eb\n=\n\u222b 1\n0\n\u2223 \u2223 \u2223 \u0393\u03c6 \u22121(\u01eb)(x) \u2223 \u2223 \u2223 d\u01eb =\n\u222b\n\u2223 \u2223 \u2223 \u0393\u01eb \u2032 (x) \u2223 \u2223 \u2223 \u03c6\u2032(\u01eb\u2032) d\u01eb\u2032,\nwhich proves Remark 1. The equality O(S) = O(OF) follows from\nEx,\u03c4\n\u2211\ny\np(x, y) = E(x,y),\u03c4 \u2211\ny\u2032 6=y\np(x, y\u2032) + 1\n2 ,\nwhere we have used the fact that p(x, y) is distributed uniformly on [0, 1] when ((x, y), \u03c4) \u223c Q\u00d7 U (see [13] and [12]).\nFinally, we notice that O(N) = O(OE). Indeed, for any significance level \u01eb,\nEx,\u03c4 |\u0393 \u01eb(x)| = E(x,y),\u03c4 |\u0393 \u01eb(x) \\ {y}|+ (1\u2212 \u01eb),\nagain using the fact that p(x, y) is distributed uniformly on [0, 1] and so P(x,y),\u03c4 (y \u2208 \u0393 \u01eb(x)) = 1\u2212 \u01eb."}, {"heading": "4 Criteria of efficiency for probabilistic predic-", "text": "tors\nGiven a training set (z1, . . . , zl) and a test object x, a probabilistic predictor outputs a probability measure P \u2208 P(Y), which is interpreted as its probabilistic prediction for the label y of x; we let P(Y) stand for the set of all probability measures on Y. The two standard way of measuring the performance of P on the actual label y are the logarithmic (or log) loss \u2212 lnP ({y}) and the Brier loss\n\u2211\ny\u2032\u2208Y\n(\n1{y\u2032=y} \u2212 P ({y \u2032})\n)2\n,\nwhere 1E stands for the indicator of an event E: 1E = 0 if E happens and 1E = 0 otherwise. The efficiency of probabilistic predictors will be measured by these two loss functions.\nSuppose we have a test sequence (zl+1, . . . , zl+k), where zi = (xi, yi) for i = l + 1, . . . , l + k, and we want to evaluate the performance of a probabilistic predictor (trained on a training sequence z1, . . . , zl) on it. In the next section we will use the average log loss\n\u2212 1\nk\nl+k \u2211\ni=l+1\nlnPi({yi})\nand the standardized Brier loss \u221a\n\u221a \u221a \u221a 1\nk |Y|\nl+k \u2211\ni=l+1\n\u2211\ny\u2032\u2208Y\n(\n1{y\u2032=yi} \u2212 Pi({y \u2032})\n)2\n,\nwhere Pi \u2208 P(Y) is the probabilistic prediction for xi. Notice that in the binary case, |Y| = 2, the average log loss coincides with the mean log error (used in, e.g., [14], (12)) and the standardized Brier loss coincides with the root mean square error (used in, e.g., [14], (13))."}, {"heading": "5 Calibration of p-values into conditional prob-", "text": "abilities\nThe argument of this section will be somewhat heuristic, and we will not try to formalize it in this paper. Fix y \u2208 Y. Suppose that q := P (y | x) has an absolutely continuous distribution with density f when x \u223c QX. (In other words, f is the density of the image of QX under the mapping x 7\u2192 P (y | x).) For the CP idealized conformity measure, we can rewrite (3) as\np(q) :=\n\u222b q\n0\nq\u2032f(q\u2032)dq\u2032 / D , (7)\nAlgorithm 1 Conformal-type probabilistic predictor\nInput: training sequence (z1, . . . , zl) \u2208 Z l Input: calibration sequence (xl+1, . . . , xl+k) \u2208 X k Input: test object x0 Output: probabilistic prediction P \u2208 P(Y) for the label of x0 for y \u2208 Y do for each xi in the calibration sequence find the p-value p y i by (2)\n(with l + i in place of l + 1) let gy be the antitonic density on [0, 1] fitted to p y l+1, . . . , p y l+k find the p-value py0 by (2) (with 0 in place of l + 1) for each y \u2208 Y, set P \u2032({y}) := gy(1)/gy(p y 0)\nend for set P ({y}) := P \u2032({y})/ \u2211\ny\u2032 P \u2032({y\u2032}) for each y \u2208 Y\nwhere D := QY({y}); alternatively, we can set D := \u222b 1 0 q \u2032f(q\u2032)dq\u2032 to the normalizing constant ensuring that p(1) = 1. To see how (7) is a special case of (3) for the CP idealized conformity measure, notice that the probability that Y = y and P (Y | X) \u2208 (q\u2032, q\u2032 + dq\u2032), where (X,Y ) \u223c f , is q\u2032f(q\u2032)dq\u2032. In (7) we write p(q) rather than py since py depends on y only via q.\nWe are more interested in the inverse function q(p), which is defined by the condition\np =\n\u222b q(p)\n0\nq\u2032f(q\u2032)dq\u2032\n/\nD .\nWhen q \u223c f , we have\nP(p(q) \u2264 a) = P(q \u2264 q(a)) =\n\u222b q(a)\n0\nf(q\u2032)dq\u2032.\nTherefore, when q \u223c f , we have\nP(a \u2264 p(q) \u2264 a+ da) =\n\u222b q(a+da)\nq(a)\nf(q\u2032)dq\u2032 \u2248 1\nq(a)\n\u222b q(a+da)\nq(a)\nq\u2032f(q\u2032)dq\u2032 = Dda\nq(a) ,\nand so\nq(c) \u2248 D\n/\nP(c \u2264 p(q) \u2264 c+ dc)\ndc .\nThis gives rise to the algorithm given as Algorithm 1, which uses real pvalues (2) instead of the ideal p-values (3). The algorithm is transductive in that it uses a training sequence of labelled observations and a calibration sequence of unlabelled objects (in the next section we use the test sequence as the calibration sequence); the latter is used for calibrating p-values into conditional probabilities. Given all the p-values for the calibration sequence with postulated label y, find the corresponding antitonic density g(p) (remember that the function q(p) is known to be monotonic, namely isotonic) using Grenander\u2019s\nestimator (see [2] or, e.g., [1], Chap. 8). Use D/g(p) as the calibration function, where D := g(1) is chosen in such a way that a p-value of 1 is calibrated into a conditional probability of 1. (Alternatively, we could set D to the fraction of observations labelled as y in the training sequence; this approximates setting D := QY({y}).) The probabilities produced by this procedure are not guaranteed to lead to a probability measure: the sum over y can be different from 1 (and this phenomenon has been observed in our experiments). Therefore, in the last line of Algorithm 1 we normalize the calibrated p-values to obtain genuine probabilities."}, {"heading": "6 Experiments", "text": "In our experiments we use the standard USPS data set of hand-written digits. The size of the training set is 7291, and the size of the test set is 2007; however, instead of using the original split of the data into the two parts, we randomly split all available data (the union of the original training and test sets) into a training set of size 7291 and test set of size 2007. (Therefore, our results somewhat depend on the seed used by the random number generator, but the dependence is minor and does not affect our conclusions at all; we always report results for seed 0.)\nA powerful algorithm for the USPS data set is the 1-Nearest Neighbour (1- NN) algorithm using tangent distance [8]. However, it is not obvious how this algorithm could be transformed into a probabilistic predictor. On the other hand, there is a very natural and standard way of extracting probabilities from support vector machines, which we will refer to it as Platt\u2019s algorithm in this paper: it is the combination of the method proposed by Platt [6] with pairwise coupling [15] (unlike our algorithm, which is applicable to multi-class problems directly, Platt\u2019s method is directly applicable only to binary problems). In this section we will apply our method to the 1-NN algorithm with tangent distance and compare the results to Platt\u2019s algorithm as implemented in the function svm from the e1071R package (for our multi-class problem this function calculates probabilities using the combination of Platt\u2019s binary method and pairwise coupling).\nThere is a standard way of turning a distance into a conformal predictor ([13], Sect. 3.1): namely, the conformity score \u03b1i of the ith observation in a sequence of observations can be defined as\nminj:yj 6=yi d(xi, xj)\nminj 6=i:yj=yi d(xi, xj) , (8)\nwhere d is the distance; the intuition is that an object is considered conforming if it is close to an object labelled in the same way and far from any object labelled in a different way.\nTable 1 compares the performance of the conformal-type probabilistic predictor based on the 1-NN conformity measure (8), where d is tangent distance,\nwith the performance of Platt\u2019s algorithm with the optimal values of its parameters. The conformal predictor is parameter-free but Platt\u2019s algorithm depends on the choice of the kernel. We chose the polynomial kernel of degree 3 (since it is known to produce the best results: see [9], Sect. 12.2) and the cost parameter C := 2.9 in the case of the average log loss and C := 3.4 in the case of the standardized Brier loss (the optimal values in our experiments). (Reporting the performance of Platt\u2019s algorithm with optimal parameter values may look like data snooping, but it is fine in this context since we are helping our competitor.) Table 2 reports the performance of Platt\u2019s algorithm as function of the degree of the polynomial kernel with the cost parameter set at C := 10 (the dependence on C is relatively mild, and C = 10 gives good performance for all degrees that we consider)."}, {"heading": "Acknowledgments.", "text": "In our experiments we used the R package e1071 (by David Meyer, Evgenia Dimitriadou, Kurt Hornik, Andreas Weingessel, Friedrich Leisch, ChihChung Chang, and Chih-Chen Lin) and the implementation of tangent distance by Daniel Keysers. This work was partially supported by EPSRC (grant EP/K033344/1, first author) and Royal Holloway, University of London (third author)."}], "references": [{"title": "A Course in Density Estimation", "author": ["Luc Devroye"], "venue": null, "citeRegEx": "1", "shortCiteRegEx": "1", "year": 1987}, {"title": "On the theory of mortality", "author": ["Ulf Grenander"], "venue": "measurement. Part II. Skandinavisk Aktuarietidskrift,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 1956}, {"title": "John E", "author": ["G.H. Hardy"], "venue": "Littlewood, and George P\u00f3lya. Inequalities. Cambridge University Press, Cambridge, England, second edition", "citeRegEx": "3", "shortCiteRegEx": null, "year": 1952}, {"title": "Testing Statistical Hypotheses", "author": ["Erich L. Lehmann"], "venue": null, "citeRegEx": "4", "shortCiteRegEx": "4", "year": 1986}, {"title": "Distribution free prediction bands for nonparametric regression", "author": ["Jing Lei", "Larry Wasserman"], "venue": "Journal of the Royal Statistical Society B,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2014}, {"title": "Probabilities for SV machines", "author": ["John C. Platt"], "venue": "Advances in Large Margin Classifiers,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2000}, {"title": "Calibration of p-values for testing precise null hypotheses", "author": ["Thomas Sellke", "M.J. Bayarri", "James Berger"], "venue": "American Statistician,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2001}, {"title": "Efficient pattern recognition using a new transformation distance", "author": ["Patrice Simard", "Yann LeCun", "John Denker"], "venue": "Advances in Neural Information Processing Systems,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 1993}, {"title": "Statistical Learning Theory", "author": ["Vladimir N. Vapnik"], "venue": null, "citeRegEx": "9", "shortCiteRegEx": "9", "year": 1998}, {"title": "A logic of probability, with application to the foundations of statistics (with discussion)", "author": ["Vladimir Vovk"], "venue": "Journal of the Royal Statistical Society B,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 1993}, {"title": "Conditional validity of inductive conformal predictors", "author": ["Vladimir Vovk"], "venue": "Technical Report arXiv:1209.2673 [cs.LG], arXiv.org e-Print archive,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2012}, {"title": "Criteria of efficiency for conformal prediction, On-line Compression Modelling project (New Series), http://alrw.net", "author": ["Vladimir Vovk", "Valentina Fedorova", "Alex Gammerman", "Ilia Nouretdinov"], "venue": "Working Paper", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2014}, {"title": "Algorithmic Learning in a Random World", "author": ["Vladimir Vovk", "Alex Gammerman", "Glenn Shafer"], "venue": null, "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2005}, {"title": "Venn\u2013Abers predictors. Technical Report arXiv:1211.0025v2 [cs.LG], arXiv.org e-Print archive", "author": ["Vladimir Vovk", "Ivan Petej"], "venue": "To appear in the UAI 2014 Proceedings", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2014}, {"title": "Probability estimates for multi-class classification by pairwise coupling", "author": ["Ting-Fan Wu", "Chih-Jen Lin", "Ruby C. Weng"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2004}], "referenceMentions": [{"referenceID": 9, "context": ", [10], Sect.", "startOffset": 2, "endOffset": 6}, {"referenceID": 6, "context": "9, and [7]) to conformal prediction: the p-values produced by conformal predictors will be transformed into probabilities.", "startOffset": 7, "endOffset": 10}, {"referenceID": 11, "context": "It was observed in [12] that some criteria of efficiency for conformal prediction (called \u201cprobabilistic criteria\u201d) encourage using the conditional probability Q(y | x) as the conformity score for an observation (x, y), Q being the data-generating distribution.", "startOffset": 19, "endOffset": 23}, {"referenceID": 9, "context": "Following [10] and [7], we will say that at this step we calibrate the p-values into probabilities,", "startOffset": 10, "endOffset": 14}, {"referenceID": 6, "context": "Following [10] and [7], we will say that at this step we calibrate the p-values into probabilities,", "startOffset": 19, "endOffset": 22}, {"referenceID": 12, "context": ", [13], Chap.", "startOffset": 2, "endOffset": 6}, {"referenceID": 13, "context": "6, or [14]).", "startOffset": 6, "endOffset": 10}, {"referenceID": 13, "context": "This method does have a guaranteed property of validity (perhaps the simplest being Theorem 1 in [14]); however, the price to pay is that it outputs multiprobabilistic predictions rather than sharp probabilistic predictions.", "startOffset": 97, "endOffset": 101}, {"referenceID": 13, "context": ", [14], Sect.", "startOffset": 2, "endOffset": 6}, {"referenceID": 10, "context": "For a general discussion of conditionality in conformal prediction, see [11].", "startOffset": 72, "endOffset": 76}, {"referenceID": 4, "context": "Objectconditional conformal prediction has been studied in [5] (in the case of regression).", "startOffset": 59, "endOffset": 62}, {"referenceID": 0, "context": ", l + 1 | yi = y}| , (2) where \u03c4 is a random number distributed uniformly on the interval [0, 1] and the corresponding sequence of conformity scores is defined by (\u03b1y1 , .", "startOffset": 90, "endOffset": 96}, {"referenceID": 11, "context": "Following [12], we will discuss the following four criteria of efficiency for individual test observations; all the criteria will work in the same direction: the smaller the better.", "startOffset": 10, "endOffset": 14}, {"referenceID": 2, "context": "Equivalently, the S criterion can be defined as the arithmetic mean 1 |Y| \u2211 y\u2208Y p y of the p-values; the proof of Theorem 1 below will show that, in fact, we can replace arithmetic mean by any mean ([3], Sect.", "startOffset": 199, "endOffset": 202}, {"referenceID": 11, "context": "is known (as in [12]).", "startOffset": 16, "endOffset": 20}, {"referenceID": 11, "context": "main result of this section, Theorem 1, is the label-conditional counterpart of Theorem 1 in [12]; the proof of our Theorem 1 is also modelled on the proof of Theorem 1 in [12].", "startOffset": 93, "endOffset": 97}, {"referenceID": 11, "context": "main result of this section, Theorem 1, is the label-conditional counterpart of Theorem 1 in [12]; the proof of our Theorem 1 is also modelled on the proof of Theorem 1 in [12].", "startOffset": 172, "endOffset": 176}, {"referenceID": 0, "context": "For each potential label y \u2208 Y for x define the corresponding label-conditional p-value as p = p(x, y) := Q({(x, y) | x \u2208 X & A((x, y), Q) < A((x, y), Q)}) QY({y}) + \u03c4 Q({(x, y) | x \u2208 X & A((x, y), Q) = A((x, y), Q)}) QY({y}) (3) (this is the idealized analogue of (2)), where QY is the marginal distribution of Q on Y and \u03c4 is a random number distributed uniformly on [0, 1].", "startOffset": 369, "endOffset": 375}, {"referenceID": 0, "context": "Let U be the uniform probability measure on the interval [0, 1].", "startOffset": 57, "endOffset": 63}, {"referenceID": 11, "context": "(Notice that this definition, being labelconditional, is different from the one given in [12].", "startOffset": 89, "endOffset": 93}, {"referenceID": 3, "context": "[4], Sect.", "startOffset": 0, "endOffset": 3}, {"referenceID": 0, "context": "where we have used the fact that p(x, y) is distributed uniformly on [0, 1] when ((x, y), \u03c4) \u223c Q\u00d7 U (see [13] and [12]).", "startOffset": 69, "endOffset": 75}, {"referenceID": 12, "context": "where we have used the fact that p(x, y) is distributed uniformly on [0, 1] when ((x, y), \u03c4) \u223c Q\u00d7 U (see [13] and [12]).", "startOffset": 105, "endOffset": 109}, {"referenceID": 11, "context": "where we have used the fact that p(x, y) is distributed uniformly on [0, 1] when ((x, y), \u03c4) \u223c Q\u00d7 U (see [13] and [12]).", "startOffset": 114, "endOffset": 118}, {"referenceID": 0, "context": "Indeed, for any significance level \u01eb, Ex,\u03c4 |\u0393 (x)| = E(x,y),\u03c4 |\u0393 (x) \\ {y}|+ (1\u2212 \u01eb), again using the fact that p(x, y) is distributed uniformly on [0, 1] and so P(x,y),\u03c4 (y \u2208 \u0393 (x)) = 1\u2212 \u01eb.", "startOffset": 147, "endOffset": 153}, {"referenceID": 13, "context": ", [14], (12)) and the standardized Brier loss coincides with the root mean square error (used in, e.", "startOffset": 2, "endOffset": 6}, {"referenceID": 13, "context": ", [14], (13)).", "startOffset": 2, "endOffset": 6}, {"referenceID": 0, "context": ", xl+k) \u2208 X k Input: test object x0 Output: probabilistic prediction P \u2208 P(Y) for the label of x0 for y \u2208 Y do for each xi in the calibration sequence find the p-value p y i by (2) (with l + i in place of l + 1) let gy be the antitonic density on [0, 1] fitted to p y l+1, .", "startOffset": 247, "endOffset": 253}, {"referenceID": 1, "context": "estimator (see [2] or, e.", "startOffset": 15, "endOffset": 18}, {"referenceID": 0, "context": ", [1], Chap.", "startOffset": 2, "endOffset": 5}, {"referenceID": 7, "context": ") A powerful algorithm for the USPS data set is the 1-Nearest Neighbour (1NN) algorithm using tangent distance [8].", "startOffset": 111, "endOffset": 114}, {"referenceID": 5, "context": "On the other hand, there is a very natural and standard way of extracting probabilities from support vector machines, which we will refer to it as Platt\u2019s algorithm in this paper: it is the combination of the method proposed by Platt [6] with pairwise coupling [15] (unlike our algorithm, which is applicable to multi-class problems directly, Platt\u2019s method is directly applicable only to binary problems).", "startOffset": 234, "endOffset": 237}, {"referenceID": 14, "context": "On the other hand, there is a very natural and standard way of extracting probabilities from support vector machines, which we will refer to it as Platt\u2019s algorithm in this paper: it is the combination of the method proposed by Platt [6] with pairwise coupling [15] (unlike our algorithm, which is applicable to multi-class problems directly, Platt\u2019s method is directly applicable only to binary problems).", "startOffset": 261, "endOffset": 265}, {"referenceID": 12, "context": "There is a standard way of turning a distance into a conformal predictor ([13], Sect.", "startOffset": 74, "endOffset": 78}, {"referenceID": 8, "context": "We chose the polynomial kernel of degree 3 (since it is known to produce the best results: see [9], Sect.", "startOffset": 95, "endOffset": 98}], "year": 2014, "abstractText": "This paper proposes a new method of probabilistic prediction, which is based on conformal prediction. The method is applied to the standard USPS data set and gives encouraging results.", "creator": "dvips(k) 5.991 Copyright 2011 Radical Eye Software"}}}