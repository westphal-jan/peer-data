{"id": "1406.7445", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "28-Jun-2014", "title": "Contrastive Feature Induction for Efficient Structure Learning of Conditional Random Fields", "abstract": "Structure learning of Conditional Random Fields (CRFs) can be cast into an L1-regularized optimization problem. To avoid optimizing over a fully linked model, gain-based or gradient-based feature selection methods start from an empty model and incrementally add top ranked features to it. However, for high-dimensional problems like statistical relational learning, training time of these incremental methods can be dominated by the cost of evaluating the gain or gradient of a large collection of candidate features (e.g., model-based or gradient-based).\n\n\n\n\n\n\nIn an interesting paper published in Psychological Science (2010), we propose that the cost of learning from such a deep domain can be as little as a factor of one (i.e., a factor of two or more) in a highly gradient-based model.\nThis is an interesting idea. For example, if we could design a high-dimensional learning framework with recurrent and random-domain training to find the maximum number of different types of training data over a much longer time period, it could be as little as a factor of two (i.e., a factor of two or more) in a highly gradient-based model. We have shown that the costs of learning from such a deep domain can be as little as a factor of two (i.e., a factor of two or more) in a highly gradient-based model. However, we cannot find an optimization approach that avoids any significant cost, because learning from such a deep domain will simply be a much less expensive and costly task than training for learning from a high-dimensional framework.\nWe suggest that learning from the gradient-based approach reduces the costs of learning to a low-dimensional model (see [9], [18], [23], [30]. We propose that a high-dimensional learning approach, the L1-regularization model, has an advantage of avoiding any significant cost in training to search for the lowest training data over a much longer time period, and in such a high-dimensional model, we find that the cost of learning from such a deep domain can be as little as a factor of two (i.e., a factor of two or more) in a highly gradient-based model. However, the cost of learning from such a deep domain can be as little as a factor of two (i.e., a factor of two or more) in a highly gradient-based model.\nThe idea for using recurrent L1-regularization and random-domain training to", "histories": [["v1", "Sat, 28 Jun 2014 22:13:52 GMT  (511kb)", "http://arxiv.org/abs/1406.7445v1", null]], "reviews": [], "SUBJECTS": "cs.LG", "authors": ["ni lao", "jun zhu"], "accepted": false, "id": "1406.7445"}, "pdf": {"name": "1406.7445.pdf", "metadata": {"source": "CRF", "title": "Contrastive Feature Induction for Efficient Structure Learning of Conditional Random Fields", "authors": ["Ni Lao", "Jun Zhu"], "emails": ["nlao@cs.cmu.edu", "junzhu@cs.cmu.edu"], "sections": [{"heading": null, "text": "MF ). CFI only evaluates a\nsubset of features which involve variables with high signals (deviation from mean) or errors (prediction residue). We prove that the gradient of candidate features can be represented solely as a function of signals and errors, and that CFI is an efficient approximation of gradient-based evaluation methods. Experiments on synthetic and real datasets show competitive learning speed and accuracy of CFI on pairwise CRFs, compared to state-of-the-art structure learning methods such as full optimization over all features, and Grafting. More interestingly, CFI is not only faster than other methods but also produces models with higher prediction accuracy by focusing on large prediction errors during induction."}, {"heading": "1. Introduction", "text": "Conditional Random Fields (CRFs) [12] are widely used in applications like computer vision, natural language processing, information extraction, relational learning, computational biology etc. However, as the variety and scale of problems increase, hand-crafting random fields become less applicable. Learning random field structure from data not only provides prediction efficiency and accuracy, but also provides insight about the underlying structure in the domain. For a very long time, the dominant solution to this structure learning problem has been greedy local search [2][14]. Because of the greediness of these procedures, features which become useless in later iterations are not removed from the model, which leads to suboptimal models. Recent work has formulated this structure selection problem as an optimization problem by applying L1-regularization to a fully linked model [1]. However, full optimization requires inference on potentially very dense graphs, which is time prohibitive and inaccurate [13]. Approximate inference methods such as loopy Belief Propagation (BP) [16] are likely to give highly inaccurate estimates of the gradient, leading to poorly learned models [13]. Gain-based or gradient-based feature selection methods avoid this problem by starting from an empty model and incrementally adding top ranked features to it [17][13]. However, for high dimensional problems, the training time of these selection methods can be dominated by the cost of evaluating the gain or gradient of candidate features.\nWhen exhaustively evaluating the gradient of candidate features, much of the calculation is\nwasted, in two ways. First, for a particular feature f:A=a,B=b and a particular training instance, if both A=a and B=b have ignorable prediction error (see precise definition in section 3) then the gradient of f on this instance is also ignorable. Second, even if A=a has significant error in many instances, but B=b is not informative (having the same expectation in all the instances), then the gradient of f on different instances would cancel each other, under a mild assumption that the errors of A=a have zero mean when considering all instances. In other words, instead of enumerating all candidate features for evaluation, it is sufficient only to evaluate a subset of features which involve variables with high signal or error. For example, for a pairwise CRFs of 1000 nodes, if only 10% of the variables are considered for a training instance, then the number of features evaluated is reduced from 500k down to 5k, which reduces time spent on evaluation by a factor of 100.\nBased on this insight, we propose a fast feature evaluation algorithm called Contrastive Feature Induction (CFI) based on Mean Field Contrastive Divergence (CD MF ) [22]. We prove that the gradient of candidate features can be represented solely as function of signals and errors, and, by ignoring small signals and errors, CFI efficiently approximates the gradient-based evaluation methods. We test our method on synthetic data generated from known MRFs and on two real datasets of relation learning problems. We found that CFI is not only faster than other methods, but also produces models with higher prediction accuracy by focusing on large prediction errors during induction.\nRelated work: Elidan et al.\u2019s \"ideal parent\" algorithm [4] for continuous variable Bayes networks provides a nice principle for detecting potential graph structures. It uses a monotonic function of the cosine similarity between signal vectors and error vectors of variables to filter candidate structures before scoring them with more costly BIC [20]. Our CFI algorithm adapts this idea to categorical variable CRFs, but is different in two aspects. First, \"ideal parent\" uses signals and errors to estimate the gain of Bayes net log-likelihood, while CFI uses them to estimate the gradient of the Mean Field Contrastive Divergence objective function. Second, \"ideal parent\" is targeted toward reducing the very costly BIC scoring, and therefore evaluates all possible candidate structures. In contrast, CFI is targeted to avoid evaluating all possible candidates for efficient learning of high dimensional problems. This goal is achieved by ignoring small signals and errors. However, the two algorithms are connected, as they both apply a dot product between error and signal vectors. Furthermore, if the error and signal vectors of \"ideal parent\" are also sparsified (by ignoring small terms), we would expect similar reductions in training time as CFI. These insights suggest a strong connection between continuous and categorical variable structure learning, and we can think of the two algorithms as one principle instantiated in two different types of graphical models.\nThe rest of this paper is organized as follows. Section 2 introduces preliminary concepts of CRFs. Section 3 describes the CFI method. Section 4 presents and analyzes experimental results on synthetic and real data, and Section 5 concludes with a summary of contributions."}, {"heading": "2. Prel iminaries", "text": "Conditional Random Fields (CRFs [12]) are Markov Random Fields (MRFs) that are globally conditioned on observations. We use upper case letters like X, Y for random variables, and lower case letters like x, y for variable assignments. Bolded letters are vectors of variables or assignments. Let G=(V,E) be an undirected model, over observed variables O, labeled variables Y, and hidden variables H. Here we consider the general case with hidden variables and it subsumes regular CRFs without hidden variables when H is empty. Let X=(Y,H) be the joint of hidden and labeled variables. Then X has the distribution (1) according to the model. Feature functions fk(x,o) count how many times a feature fires in the CRFs. \u03b8 is a vector of feature weights. Z(\u03b8) is called the partition function.\n( ; ) exp( ( )) / ( )Tp Z  x | o f x,o\n1..( ) [... ( )...] T k k Kf f x,o x,o\n(1)\nFor general structure CRFs, inference cannot be performed efficiently with dynamic programming. In this case, p(x|o;\u03b8) can be approximated by methods like belief propagation [15], or mean field approximation [8]. In this study we use mean field approximation, which\napproximates the true distribution p(x|o;\u03b8) with a fully factorized distribution q(x) as in Eq. (2) by minimizing their KL divergence. The variational parameters \u03bc(Xk=xk) are updated iteratively according to Eq. (3). nb(fr) is the set of states (e.g. Xk=xk ) involved in feature fr. nb(Xk=xk) is the set of features involving state Xk=xk. The expectation of a feature being activated is given by Eq. (4).\n( | ; ) ( ) ( ) ( )k k k kk kp q x q X x X x      x o (2)\n( ) ( ) \\{ }\n1 ( ) exp ( )\nr k k j j r k k\nnew\nk k r j j\nf nb X x X x nb f X xk\nX x X x Z        \n     \n     (3)\n( ) ( ) j j r r j j X x nb f f X x     (4)\nGiven a set of labeled training data D={(y i ,o i )}, parameter learning of the CRFs can be formulated as maximizing regularized log-likelihood as in Eq. (5), where \u03bb1 controls L1-regularization to help structure selection [1], and \u03bb2 controls L2- regularization to prevent over fitting. Differentiating l(\u03b8) with respect to \u03b8, we get its gradient g as in Eq. (7), where p is the expectation under the\ndistribution p.\n1 1 2 2\n1.. ( ) ( ) | | | | / 2m m M L l          (5)\n( ) log ( | ; ) log ( , | ; )l p p    hy o y h o (6)\n( , | ; ) ( | , ; ) ( ) ( ) / p p l          h y o h o y g f f (7)\nSince l(\u03b8) and g(\u03b8) are intractable to compute, we use 1-step Mean Field Contrastive Divergence (CD MF ) [22] as an approximation. The objective function CD in Eq. (8) is an approximation to a lower bound of l(\u03b8). Here q0 is the mean-field approximation of p(h|y,o;\u03b8). q1 is the approximation of p(h,y|o;\u03b8) obtained by applying one mean field update to q0. Generally, Ft is the free energy of the model at t-th mean-field update, and F0\u2265Ft\u2265F\u221e. 1-step CD MF utilizes F1 as approximation of F\u221e. One main advantage of CD is that it avoids been trapped in possible multimodal distribution of p(h,y|o;\u03b8). By starting from q0, q1 always goes to the same mode as q0 [22]. When there are no hidden variables, q0 is just the empirical distribution in training data. When there are hidden variables, inference is needed to estimate q0.\n0 1 0 1 0\n( , ; ) ( ) ( )ln ( || ) ( || ) ( )\n( )h\np y h l q h F F F F KL q p KL q p CD\nq h\n         (8)\n[ || ] ln ( , | ) ( ) i i iq KL q p p h y o H q  \n(9)\n1 0\n( ) ( ) / q q\nCD      g f f (10)\n0 1 0 1 0 1CD( ) ( ) ( ) ( ) ( ) ( )q q\nH q H q H q H q             f f g (11)\nWe use orthant-wise L-BFGS [1] to tune \u03b8. Update is terminated if the change of both objective and ||\u03b8||1 are smaller than a threshold for several consecutive iterations."}, {"heading": "3. Contrastive Feature Induction (CFI)", "text": "Although we define CRFs with hidden variables in the previous section, CFI can be applied to CRFs with or without hidden variables. We just refer to each training sample as (x i ,o i ) to subsume both cases. Let's first consider pairwise Markov networks, where each feature function is an indicator function for a certain assignment to either a pair of nodes or a single node. As we have stated earlier, training time of existing gain-based or gradient-based feature selection methods can be dominated by evaluating the gain or gradient of candidate features for high dimensional problems. Here we present a fast approximation method.\nBefore diving into the exposition of the algorithm details, let\u2019s first define two key concepts. Let\nq0(X i =x) and q1(X i =x) be the estimations of variable X having value x in instance (x i ,o i ) under distribution q0 and q1 as defined in Section 2. We define the error and signal of a state as follows:\nDefinition 1: We define error of state X=x in instance (x i ,o i ) be err(X i =x)=q1(X i =x) - q0(X i =x).\nDefinition 2: We define signal of state X=x in instance (x i ,o i ) be \u03b5t(X i =x)=qt(X i =x) - Et[X=x], where Et[X=x]=\u2211j qt(X j =x )/M is the mean of qt(X i =x) in all instances under distribution qt.\nWe found that much of the calculation in Grafting is wasted, in two ways. First, for a particular feature f:A=a,B=b and a particular training sample (x i ,o i ), if both A=a and B=b have ignorable prediction error then from Eq. (4) we know that g i (f), the gradient of f on sample (x i ,o i ), is ignorable. Second, even if A=a has significant error in many instances, but B=b is not informative (having the same expectation in all the instances) then \u2211ig i (f) is zero assuming the error of A=a has zero mean when considering all the training samples. This is a reasonable assumption since single node features generally converge quickly. In other words, instead of enumerating all candidate features for evaluation, it is sufficient to only evaluate a subset which involves variables with high signal or error. For example, for the pairwise CRFs of 1000 nodes, if only 10% of the variables are considered for a sample, then the number of features evaluated is reduced from 500k down to 5k, which reduces training time by a factor of 100.\nMore formally, we prove that CFI is an efficient approximation to the gradient based evaluation methods.\nTheorem 3 (Gradient Decomposition Theorem: GDT): The gradient in Eq. (10) can be represented purely as a function F(\u2022) of signals and errors\n, 0 0( ) ( ( ), ( ), ( ), ( )) i i i i A a B b i g F A a B b err A a err B b        \nProof: As in Eq. (12) and (13), g can be decomposed into signals, errors and means. Assuming weights of unary features have already converged, we have g(\u03b8X=x)/M=E1[X=x]-E0[X=x]=0 (or E1[X=x]=E0[X=x]=E[X=x], regularization is ignored here). Then the last two terms in Eq. (13) will be canceled in Eq. (12) with other samples\n, ,( ) ( ) i A a B b A a B bi g g     (12)\n, 1 1 0 0\n0 0\n0 0\n1 0 1 0\n( ) ( ) ( ) ( ) ( )\n( ) ( ) ( ) ( ) ( ) ( )\n( ) [ ] ( ) [ ]\n[ ( ) ( )]* ( ) / 2 [ ( ) ( )]* ( ) /\ni i i i i\nA a B b\ni i i i i i\ni i i i\ni i i i i i\ng q A a q B b q A a q B b\nerr A a B b err B b A a err A a err B b\nerr A a E B b err B b E A a\nA a A a err B b B b B b err A a\n\n \n   \n       \n        \n     \n         \n0 0\n2\n( ) [ ] ( ) [ ]i i i ierr A a E B b err B b E A a     \n(13)\nIf we further ignore small errors and signals with magnitudes smaller than thresholds terr and tsig in Eq. (13), we can effectively ignore many terms in Eq. (12). At each training iteration, the Contrastive Gradient Approximation algorithm (as outlined in Algorithm 1) estimates a sparse vector (hA=a,B=b) as an approximation of (g(\u03b8A=a,B=b)), and adds top J features to the model. We call J the batch size.\nAlgorithm 1: Contrastive Gradient Approximation\nInput: \u03b50, \u03b51, err of all states of all training samples Output: sparse vector (hA=a,B=b) Set hA=a,B=b=0, for any pair of states A=a, B=b For each sample (x i ,o i )\nFind the set of states Serr(i) with |err| > terr , Find the set of states Ssig(i) with |\u03b50+\u03b51|/2 > tsig. For any pair A i =a Ssig(i), B i =b Serr(i),\nSet hA=a,B=b+=[\u03b50(A i =a)+ \u03b51(A i =a)]* err (B i =b)/2.\nTo fulfill the assumption that unary features have already converged, we can split the training into\ntwo stages: the first stage adds all unary features to the model and optimizes until convergence; the second stage incrementally induces pairwise features during optimization. In our experience, however, merging the two stages into one does not affect the accuracy of the learned model. So we start inducing binary features right after adding all the unary features, and save the iterations (usually 5) spent on waiting for unary features to converge.\nThe CFI algorithm shares the same principle suggested by the \u2015ideal parent\u2016 algorithm [4] \u2014 if one variable has high correlation to another variable\u2019s prediction error, a link should be formed between them. If we concatenate errors and signals of a state in all samples into two vectors, then the approximated feature gradients given by CFI are exactly the dot products between sparse error vectors and signal vectors. This suggests the connection between CFI and \"ideal parent\" which also involves dot product between error vectors and signal vectors. Furthermore, if the error and signal vectors of \"ideal parent\" are also sparsified (by ignoring small terms), we would expect similar reductions in training time as CFI on high dimensional problems. We can think the two algorithms as one principle instantiated in two different types of graphical models.\nTo go beyond pairwise networks, similar techniques can be used to decompose the gradient of higher order features f:X1=x1,\u2026,XK=xK as in Eq. (14).\n1 1 ,... 1 0\n0 0\n( ) ( ) ( )\n{ ( ) [ ]} ( )\nK K\ni i i\nX x X x k k k kk k\ni i i\nk k k k k kk k\ng q X x q X x\nq X x err X x q X x\n      \n     \n \n  (14)\nAlthough GDT hinges on the independence of variables (mean field estimation) when calculating the gradient of features, it does not restrict the type of inference used to optimize the model. One can surely induce features with CFI while optimizing the model with loopy BP. However, it remains an interesting research question whether similar decomposition results can be found for other types of objective functions that do not have as strong independence assumption as mean field."}, {"heading": "4. Experiment", "text": "In this study, we report empirical results for pairwise networks by comparing CFI with state-of-the-art structure learning methods including full optimization over all features (Full-L1) [1], and Grafting [17]. The original Grafting method optimizes the model until convergence after adding each batch of new features. Empirically we found it is more efficient to update only one iteration after each batch of features are added, and the quality of the learnt models is not sacrificed.\nFollowing the methodology of Kok and Domingos [10], we situate our experiment in prediction tasks. Ten-fold cross validation is performed as follows. We first mark a randomly selected 10% labels in the data as hidden during training, and then evaluate on these labels during testing, conditioned on the observed training labels. Performances of the systems are measured by training time, prediction error rate, average Conditional Log-Likelihood (CLL), and Area Under precision-recall Curve (AUC) [10]. CLL is calculated by \u2211i lnq0(h i |y i ), where h i are the marked 10% of the labels, and y i are the remaining 90% of the labels. AUC is calculated in three steps. We first sort all states of the testing variables in decreasing order of q0(H i =h i |y i ), then treat all the true states as relevant and calculate precision and recall at each position. Finally, we integrate the area under the precision/recall curve. In all experiments we fix \u03bb2=1, and \u03bb1 is grossly tuned for Grafting. We found that within the range of 30-100, batch size J does not affect the performance of Grafting and CFI much, so we set the batch size to 50 in all experiments. All algorithms are implemented in Java 6.0."}, {"heading": "4 .1 . Sy nthe t i c Da ta", "text": "Following the method described by Lee et al. [13] we generated synthetic data through Gibbs sampling (10000 iteration burn-in, 1000 iteration thinning) on synthetic networks. A network structure with N nodes was generated by treating each possible edge as a Bernoulli random variable and sampling the edges. We chose the parameter of Bernoulli distribution so that each node had K neighbors on average. Weights of the chosen edges are drawn from an even distribution within [-5, 5]. We fix \u03bb1=2, M=200 (number of sample), k=5, and vary N. We also compare to TrueGraph, for which features in the true models are optimized and no feature induction is applied.\nTo check the distribution of signals and errors we draw their histograms in Figure 1. We can see that since signals and errors mostly concentrate around 0, substantial saving of computation can be expected from ignoring small terms. In this study we set terr and teps to have the same value. Figure 2 shows relation between training time and the threshold. We can see that as tsig and terr gets larger, CFI is increasingly faster. When terr=teps=0, CFI falls back to similar training time as Grafting. There is a sharp drop in number of features when terr=tsig passes 0.5, because most signals and errors have magnitude smaller than 0.5. More interestingly, when thresholds are not too large (<0.4), CFI leads to better prediction than Grafting. In the rest of this study, we fix terr=tsig=0.2.\nFigure 3 compares different methods on different network size. We can see that among the three methods, full-L1 is the slowest, because it lets all features participate in inference, but it also has the best CLL and AUC. CFI is not only the fastest but also has the smallest error rate. This shows that CFI has an effect similar to that observed in large margin approaches, where the focus is on reducing large prediction errors which potentially leads to flip of decisions. CFI even has a smaller error rate than the true graph, because features not in the true graph are also useful in prediction. Note that if we use a more costly inference method like loopy BP rather than mean field, then the time difference between full -L1 and the other two methods would be larger. CFI produces slightly less number of active features (features with non-zero weights) than Grafting, even though they introduce almost the same number of features in total."}, {"heading": "4 .2 . Re la t io na l Lea rning Da ta", "text": "There has been a surge of interests in Statistical Relational Learning (SRL [5]) driven by applications like collective classification, information extraction and integration, bioinformatics, et al. Among many proposed SRL models, Template-Based Relation Markov Random Fields (TR-MRFs [7]) is a powerful model. It does not have the acyclic constraint as Probabilistic Relational Model (PRM) (which is based on Bayes network), nor does it confine itself to binary random variables as Markov Logic Network (MLN). The binary representation of MLN causes deterministic dependencies when modeling multi-category concepts, and requires special treatment like slice-sampling during inference to help find separate modes of distribution [19]. However, there is no previous work on learning structure of TR-MRFs. In this section, we compare different structure learning methods for TR-MRFs, and compare their performance to other state of the art relational learning models.\nTR-MRFs define a random field on a set of entities. Each entity can be seen as a training instance, and has a set of attributes (variables). However, the entities are not independent; features can be defined between attributes of different entities through the concept of templates. Therefore, all the training samples are connected into a single random field and are collectively called a mega-sample. For formal definitions, please refer to Jaimovich et al. [7]; we leave out implementation details here due to the limitation of space.\nNote that instead of using lifted belief propagation for inference [7], we use generalized mean field approximation [23], which is fast and easier to implement. We treat each entity as a sub-graph. The joint distribution of all entities is estimated by doing mean field update one entity at a time with the variational parameters of its neighbors fixed. The joint distribution converges after iterating through all entities for several rounds. Within each round, the entities are visited with a fixed order, and iteration terminates when maximum change of expectation in a round is smaller than \u03b5=0.1.\nWe used two relational datasets that have relatively large number of attributes (available at http://alchemy.cs.washington.edu [10]). The Animal dataset contains a set of animals and their attributes. It consists exclusively of unary predicates of the form f(a), where f is a feature and a is an animal (e.g., Swims(Dolphin)). There are 50 animals, and 85 attributes. This is a simple propositional dataset with no relational structure, but is useful as a \u2015base case\u2016 for comparison. There are 3,655 candidate features in its pairwise random field. The Nation dataset contains attributes of nations and relations among them. The binary predicates are of the form r(n, n0), where n, n0 are nations, and r is a relation between them (e.g., ExportsTo, GivesEconomicAidTo). The unary predicates are of the form f(n), where n is a nation and f is a feature (e.g., Communist, Monarchy). There are 14 nations, 56 relations and 111 attributes. There are 20,244 candidate features in its pairwise random field.\nWe compare TR-MRF with the results of state-of-the-art relational learning algorithms\nreported in [10]. The MLN structure learning algorithm (MSL [11]) creates candidate clauses by adding literals to the current clauses. The weight of each candidate clause is learned by optimizing a weighted pseudo-log-likelihood (WPLL) measure, and the best one is added to the MLN. There are two relational learning algorithms that induce hidden variables. Infinite Relational Model (IRM [9]) simultaneously clusters objects and relations. It defines a generative model for the predicates and cluster assignments. It uses a Chinese restaurant process prior (CRP [18]) on the cluster assignments to automatically control number of clusters. Multiple Relational Clusterings (MRC [10]) is based on MLN. Similar to IRM, it automatically invents predicates by clustering objects, attributes and relations. Moreover, MRC can learn multiple clusterings, rather than just one.\nTable 1 compares performance of different methods on the two data sets , where the result of MSL/IRM/MRC are directly cited from [10]. Kok & Domingos [10] did not report error rates. We can see that when the number of candidate features is small (3,655 for Animal data), selectively adding features (Grafting and CFI) does not benefit learning speed or prediction accuracy. However, when the problem dimension is large (20,244 for Nation data), avoiding training on a dense graph becomes more important. For CLL and AUC, CFI performs significantly better than Grafting, which is significantly better than Full-L1. For error rate, CFI and Grafting are not significantly different, but both are significantly better than Full -L1. This indicates that adding top-ranked features instead of all features to a model is beneficial for prediction tasks. Although MLN is more flexible in defining complex features (clauses) than pairwise fields, it is very challenging to search through the large space of possible structures, which is evidenced by the much larger training time. As shown in Figure 4, although errors mostly concentrate around 0, signals have a two mode distribution on this data. Therefore, the saving of time is mainly from considering less number of error terms."}, {"heading": "5. Conclusion", "text": "In this study we propose a fast feature evaluation algorithm called Contrastive Feature Induction (CFI). It evaluates a subset of features which involve variables with high signal (deviation from mean) or error (prediction residues). We prove that CFI is an efficient approximation of the gradient-based evaluation methods. Experiments on synthetic and real datasets show that CFI is not only faster than Grafting and full optimization of all the features, but also produces models of higher prediction accuracy by focusing on large prediction errors."}], "references": [{"title": "Scalable training of L1-regularized log-linear models", "author": ["G. Andrew", "J. Gao"], "venue": "In ICML", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2007}, {"title": "Inducing Features of Random Fields", "author": ["S. Della Pietra", "V. Della Pietra", "Lafferty"], "venue": "IEEE Transactions Pattern Analysis And Machine Intelligence,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 1997}, {"title": "Markov Logic: A Unifying Framework for Statistical Relational Learning", "author": ["P. Domingos", "M. Richardson"], "venue": "Proceedings of the ICML-2004 Work-shop on Statistical Relational Learning and its Connections to Other Fields (pp. 49-54)", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2004}, {"title": "Ideal Parent\u2016 Structure Learning for Continuous Variable Bayesian Networks", "author": ["G. Elidan", "G. Nachman", "N. Friedman"], "venue": "Journal of Machine Learning Research", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2007}, {"title": "Introduction to statistical relational learning", "author": ["L. Getoor", "B. Taskar"], "venue": null, "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2007}, {"title": "Discriminative Structure and Parameter Learning for Markov Logic Networks", "author": ["T. Huynh", "R. Mooney"], "venue": "In Proceedings of the 25th Inter-national Conference on Machine Learning", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2008}, {"title": "Template based inference in symmetric relational Markov random fields", "author": ["A. Jaimovich", "O. Meshi", "N. Friedman"], "venue": "In Proc", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2007}, {"title": "An introduction to variational methods for graphical models", "author": ["M.I. Jordan", "Z. Ghahramani", "T.S. Jaakkola", "Saul L. K"], "venue": "Learning in Graphical Models,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 1999}, {"title": "Learning systems of concepts with an infinite relational model", "author": ["C. Kemp", "J.B. Tenenbaum", "T.L. Griffiths", "T. Yamada", "N. Ueda"], "venue": null, "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2006}, {"title": "Statistical Predicate Invention", "author": ["S. Kok", "P. Domingos"], "venue": "Proceedings of the Twenty-Fourth International Conference on Machine Learning (pp. 433-440)", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2007}, {"title": "Learning Markov Logic Network Structure via Hypergraph Lifting", "author": ["S. Kok", "P. Domingos"], "venue": "Proceedings of the Twenty-Sixth International Conference on Machine Learning", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2009}, {"title": "Conditional random fields: Probabilistic models for segmenting and labeling sequence data", "author": ["J. Lafferty", "A. McCallum", "F. Pereira"], "venue": null, "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2001}, {"title": "Efficient Structure Learning of Markov Networks using L1-Regularization.\" Advances in Neural In-formation Processing Systems", "author": ["Lee", "S.-I", "V. Ganapathi", "D. Koller"], "venue": null, "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2006}, {"title": "Efficiently inducing features of conditional random fields", "author": ["A. McCallum"], "venue": "In Proc. UAI", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2003}, {"title": "Loopy belief propagation for approximate inference: an empirical study", "author": ["K.P. Murphy", "Y. Weiss", "M.I. Jordan"], "venue": null, "citeRegEx": "15", "shortCiteRegEx": "15", "year": 1999}, {"title": "Probabilistic Reasoning in Intelligent Systems", "author": ["J. Pearl"], "venue": null, "citeRegEx": "16", "shortCiteRegEx": "16", "year": 1988}, {"title": "Grafting: Fast, incremental feature selection by gradient descent in function spaces", "author": ["S. Perkins", "K. Lacker", "J. Theiler"], "venue": null, "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2003}, {"title": "Combinatorial stochastic processes (Technical Report 621)", "author": ["J. Pitman"], "venue": "Department of Statistics,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2002}, {"title": "Joint inference in information extraction", "author": ["H. Poon", "P. Domingos"], "venue": "In Proc. AAAI-07", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2007}, {"title": "Estimating the dimension of a model", "author": ["G. Schwarz"], "venue": "Ann. Stat.,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 1978}, {"title": "Discriminative probabilistic models for relational data", "author": ["B. Taskar", "P. Abbeel", "D. Koller"], "venue": "Proc. UAI-02", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2002}, {"title": "A New Learning Algorithm for Mean Field Boltzmann Machines", "author": ["M. Welling", "G.E. Hinton"], "venue": "ICANN", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2002}, {"title": "A generalized mean field algorithm for variational inference in exponential families, Uncertainty in Artificial Intelligence (UAI2003), (eds", "author": ["E.P. Xing", "M.I. Jordan", "S. Russell"], "venue": null, "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2003}], "referenceMentions": [{"referenceID": 11, "context": "Introduction Conditional Random Fields (CRFs) [12] are widely used in applications like computer vision, natural language processing, information extraction, relational learning, computational biology etc.", "startOffset": 46, "endOffset": 50}, {"referenceID": 1, "context": "For a very long time, the dominant solution to this structure learning problem has been greedy local search [2][14].", "startOffset": 108, "endOffset": 111}, {"referenceID": 13, "context": "For a very long time, the dominant solution to this structure learning problem has been greedy local search [2][14].", "startOffset": 111, "endOffset": 115}, {"referenceID": 0, "context": "Recent work has formulated this structure selection problem as an optimization problem by applying L1-regularization to a fully linked model [1].", "startOffset": 141, "endOffset": 144}, {"referenceID": 12, "context": "However, full optimization requires inference on potentially very dense graphs, which is time prohibitive and inaccurate [13].", "startOffset": 121, "endOffset": 125}, {"referenceID": 15, "context": "Approximate inference methods such as loopy Belief Propagation (BP) [16] are likely to give highly inaccurate estimates of the gradient, leading to poorly learned models [13].", "startOffset": 68, "endOffset": 72}, {"referenceID": 12, "context": "Approximate inference methods such as loopy Belief Propagation (BP) [16] are likely to give highly inaccurate estimates of the gradient, leading to poorly learned models [13].", "startOffset": 170, "endOffset": 174}, {"referenceID": 16, "context": "Gain-based or gradient-based feature selection methods avoid this problem by starting from an empty model and incrementally adding top ranked features to it [17][13].", "startOffset": 157, "endOffset": 161}, {"referenceID": 12, "context": "Gain-based or gradient-based feature selection methods avoid this problem by starting from an empty model and incrementally adding top ranked features to it [17][13].", "startOffset": 161, "endOffset": 165}, {"referenceID": 21, "context": "Based on this insight, we propose a fast feature evaluation algorithm called Contrastive Feature Induction (CFI) based on Mean Field Contrastive Divergence (CD MF ) [22].", "startOffset": 165, "endOffset": 169}, {"referenceID": 3, "context": "\u2019s \"ideal parent\" algorithm [4] for continuous variable Bayes networks provides a nice principle for detecting potential graph structures.", "startOffset": 28, "endOffset": 31}, {"referenceID": 19, "context": "It uses a monotonic function of the cosine similarity between signal vectors and error vectors of variables to filter candidate structures before scoring them with more costly BIC [20].", "startOffset": 180, "endOffset": 184}, {"referenceID": 11, "context": "Prel iminaries Conditional Random Fields (CRFs [12]) are Markov Random Fields (MRFs) that are globally conditioned on observations.", "startOffset": 47, "endOffset": 51}, {"referenceID": 14, "context": "In this case, p(x|o;\u03b8) can be approximated by methods like belief propagation [15], or mean field approximation [8].", "startOffset": 78, "endOffset": 82}, {"referenceID": 7, "context": "In this case, p(x|o;\u03b8) can be approximated by methods like belief propagation [15], or mean field approximation [8].", "startOffset": 112, "endOffset": 115}, {"referenceID": 0, "context": "(5), where \u03bb1 controls L1-regularization to help structure selection [1], and \u03bb2 controls L2- regularization to prevent over fitting.", "startOffset": 69, "endOffset": 72}, {"referenceID": 21, "context": "Since l(\u03b8) and g(\u03b8) are intractable to compute, we use 1-step Mean Field Contrastive Divergence (CD MF ) [22] as an approximation.", "startOffset": 105, "endOffset": 109}, {"referenceID": 21, "context": "By starting from q0, q1 always goes to the same mode as q0 [22].", "startOffset": 59, "endOffset": 63}, {"referenceID": 0, "context": "We use orthant-wise L-BFGS [1] to tune \u03b8.", "startOffset": 27, "endOffset": 30}, {"referenceID": 3, "context": "The CFI algorithm shares the same principle suggested by the \u2015ideal parent\u2016 algorithm [4] \u2014 if one variable has high correlation to another variable\u2019s prediction error, a link should be formed between them.", "startOffset": 86, "endOffset": 89}, {"referenceID": 0, "context": "Experiment In this study, we report empirical results for pairwise networks by comparing CFI with state-of-the-art structure learning methods including full optimization over all features (Full-L1) [1], and Grafting [17].", "startOffset": 198, "endOffset": 201}, {"referenceID": 16, "context": "Experiment In this study, we report empirical results for pairwise networks by comparing CFI with state-of-the-art structure learning methods including full optimization over all features (Full-L1) [1], and Grafting [17].", "startOffset": 216, "endOffset": 220}, {"referenceID": 9, "context": "Following the methodology of Kok and Domingos [10], we situate our experiment in prediction tasks.", "startOffset": 46, "endOffset": 50}, {"referenceID": 9, "context": "Performances of the systems are measured by training time, prediction error rate, average Conditional Log-Likelihood (CLL), and Area Under precision-recall Curve (AUC) [10].", "startOffset": 168, "endOffset": 172}, {"referenceID": 12, "context": "[13] we generated synthetic data through Gibbs sampling (10000 iteration burn-in, 1000 iteration thinning) on synthetic networks.", "startOffset": 0, "endOffset": 4}, {"referenceID": 4, "context": "Weights of the chosen edges are drawn from an even distribution within [-5, 5].", "startOffset": 71, "endOffset": 78}, {"referenceID": 4, "context": "Re la t io na l Lea rning Da ta There has been a surge of interests in Statistical Relational Learning (SRL [5]) driven by applications like collective classification, information extraction and integration, bioinformatics, et al.", "startOffset": 108, "endOffset": 111}, {"referenceID": 6, "context": "Among many proposed SRL models, Template-Based Relation Markov Random Fields (TR-MRFs [7]) is a powerful model.", "startOffset": 86, "endOffset": 89}, {"referenceID": 18, "context": "The binary representation of MLN causes deterministic dependencies when modeling multi-category concepts, and requires special treatment like slice-sampling during inference to help find separate modes of distribution [19].", "startOffset": 218, "endOffset": 222}, {"referenceID": 6, "context": "[7]; we leave out implementation details here due to the limitation of space.", "startOffset": 0, "endOffset": 3}, {"referenceID": 6, "context": "Note that instead of using lifted belief propagation for inference [7], we use generalized mean field approximation [23], which is fast and easier to implement.", "startOffset": 67, "endOffset": 70}, {"referenceID": 22, "context": "Note that instead of using lifted belief propagation for inference [7], we use generalized mean field approximation [23], which is fast and easier to implement.", "startOffset": 116, "endOffset": 120}, {"referenceID": 9, "context": "edu [10]).", "startOffset": 4, "endOffset": 8}, {"referenceID": 9, "context": "reported in [10].", "startOffset": 12, "endOffset": 16}, {"referenceID": 10, "context": "The MLN structure learning algorithm (MSL [11]) creates candidate clauses by adding literals to the current clauses.", "startOffset": 42, "endOffset": 46}, {"referenceID": 8, "context": "Infinite Relational Model (IRM [9]) simultaneously clusters objects and relations.", "startOffset": 31, "endOffset": 34}, {"referenceID": 17, "context": "It uses a Chinese restaurant process prior (CRP [18]) on the cluster assignments to automatically control number of clusters.", "startOffset": 48, "endOffset": 52}, {"referenceID": 9, "context": "Multiple Relational Clusterings (MRC [10]) is based on MLN.", "startOffset": 37, "endOffset": 41}, {"referenceID": 9, "context": "Table 1 compares performance of different methods on the two data sets , where the result of MSL/IRM/MRC are directly cited from [10].", "startOffset": 129, "endOffset": 133}, {"referenceID": 9, "context": "Kok & Domingos [10] did not report error rates.", "startOffset": 15, "endOffset": 19}], "year": 2012, "abstractText": "Structure learning of Conditional Random Fields (CRFs) can be cast into L1-regularized optimization problems, which can be solved by efficient gradient-based optimization methods. However, optimizing a fully linked model may require inference on dense graphs which can be time prohibitive and inaccurate. Gain-based or gradient-based feature selection methods avoid this problem by starting from an empty model and incrementally adding top ranked features to it. However, training time with these incremental methods can be dominated by the cost of evaluating the gain or gradient of candidate features for high-dimensional problems. In this study we propose a fast feature evaluation algorithm called Contrastive Feature Induction (CFI) based on Mean Field Contrastive Divergence (CD MF ). CFI only evaluates a subset of features which involve variables with high signals (deviation from mean) or errors (prediction residue). We prove that the gradient of candidate features can be represented solely as a function of signals and errors, and that CFI is an efficient approximation of gradient-based evaluation methods. Experiments on synthetic and real datasets show competitive learning speed and accuracy of CFI on pairwise CRFs, compared to state-of-the-art structure learning methods such as full optimization over all features, and Grafting. More interestingly, CFI is not only faster than other methods but also produces models with higher prediction accuracy by focusing on large prediction errors during induction.", "creator": "Microsoft\u00ae Word 2010"}}}