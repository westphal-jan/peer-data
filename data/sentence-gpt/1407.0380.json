{"id": "1407.0380", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "27-Jun-2014", "title": "A Multi Level Data Fusion Approach for Speaker Identification on Telephone Speech", "abstract": "Several speaker identification systems are giving good performance with clean speech but are affected by the degradations introduced by noisy audio conditions. To deal with this problem, we investigate the use of complementary information at different levels for computing a combined match score for the unknown speaker. In this work, we observe the effect of two supervised machine learning approaches including support vectors machines (SVM) and na\\\"ive bayes (NB) as a means to measure the accuracy of the discriminant expression and its effects across the frequency spectrum (CAL). The authors propose that the use of complementary information has become an important factor in the implementation of machine learning algorithms, and thus we will investigate the possibility of a formal implementation of the present algorithm.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "histories": [["v1", "Fri, 27 Jun 2014 20:34:05 GMT  (235kb)", "http://arxiv.org/abs/1407.0380v1", "10 pages, 4 figures, International Journal of Signal Processing, Image Processing and Pattern Recognition Vol. 6, No. 2, April, 2013"]], "COMMENTS": "10 pages, 4 figures, International Journal of Signal Processing, Image Processing and Pattern Recognition Vol. 6, No. 2, April, 2013", "reviews": [], "SUBJECTS": "cs.SD cs.LG", "authors": ["imen trabelsi", "dorra ben ayed"], "accepted": false, "id": "1407.0380"}, "pdf": {"name": "1407.0380.pdf", "metadata": {"source": "CRF", "title": "A Multi Level Data Fusion Approach for Speaker Identification on Telephone Speech", "authors": ["Imen Trabelsi", "Dorra Ben Ayed"], "emails": ["trabelsi.imen1@gmail.com,", "Dorra.mezghani@isi.rnu.tn"], "sections": [{"heading": null, "text": "Several speaker identification systems are giving good performance with clean speech but are affected by the degradations introduced by noisy audio conditions. To deal with this problem, we investigate the use of complementary information at different levels for computing a combined match score for the unknown speaker. In this work, we observe the effect of two supervised machine learning approaches including support vectors machines (SVM) and na\u00efve bayes (NB).\nWe define two feature vector sets based on mel frequency cepstral coefficients (MFCC) and relative spectral perceptual linear predictive coefficients (RASTA-PLP). Each feature is modeled using the Gaussian Mixture Model (GMM). Several ways of combining these information sources give significant improvements in a text-independent speaker identification task using a very large telephone degraded NTIMIT database.\nKeywords: Fusion, GMM, SVM, Na\u00efve Bayes, MFCC, RASTA-PLP"}, {"heading": "1. Introduction", "text": "The task of automatic speaker identification consists of labeling an unknown voice sample as one of a set of known voices samples. Speaker identification methods can be divided into text-dependent and text-independent methods. For text dependent methods, the test utterance is known while for text independent methods, it is not known [9]. In this study, we performed experiments for text independent tasks in phone quality speech.\nIn general, speaker identification system is considered as comprised two major units namely enrollment (modeling) and identification (matching) as shown in (Figure 1). In enrollment phase, all samples from speakers are trained and stored in a database. The goal of enrollment is to construct a model for each speaker based on the features extracted from his/her speech samples. The identification is a process of computing a matching score between the input speech feature vector and a model of the speaker\u2019s voice. Success in speaker identification tasks depends on these two phases. Nowadays, and in order to improve the identification performance, attention has turned to the applicability of fusing different systems at different levels.\nThis technique can be divided in two main categories: systems based on features diversity [18] and systems based on classifiers diversity [19]. Hence, searchers are looking for the best set of features and the best set of classifiers.\nIn this paper, we study these two categories. It consists on comparing the use of individual classifiers and combined classifiers, applied in individual data and in combined data. This task is of a high interest in vocal applications through the telephone network. We use for our\nexperiments the NTIMIT database [12]. This database represents a challenge due to the unpredictable channel noises.\nThe remainder of the paper is organized as follows. Section 2 reviews the basic of the gaussian mixture speaker model. Section 3 defines the structure of the used classifiers. Section 4 describes the application of the data fusion for text independent speaker identification. Section 5 describes the experimental conditions and presents the experimental results. Conclusion is drawn in the final section."}, {"heading": "2. Speaker Modeling", "text": "The feature vectors extracted from training data are used to create a set of speaker models. The modeling of a speaker may be implemented according to various techniques. The widely used one is the Gaussian Mixture Model (GMM).\nA GMM aims to approximate a complex nonlinear distribution using a mixture of simple gaussian models. A GMM is a weighted sum of M component Gaussian densities as given by (1):\n1\n( / ) ( ). M\ni i\ni p x p b x  \n\nWhere x is a d-dimensional vector, bi (x) are the component densities, pi are the mixture\nweights. Each component density is a d-variant Gaussian function having the form:\n1\n1\n22\n1 1 ( ) exp{ ( ) ( ).\n2 (2 )\nt\ni i id i\ni\nb x x x      \n  \n\n\nWith mean vector \u00b5i and covariance matrix \u2211i, the mixture weights satisfy the constraint\nthat:\n1\n1. M\ni\ni p \n  \nIn this approach, a universal background model (UBM) learns the acoustic feature space. A standard approach in estimating the parameters of GMM-UBM aims to learn the mean vector, covariance matrix and the weight through expectation-maximization (EM) algorithm [13] from a background dataset.\nEach speaker is then modeled and referred by adapting only the mean vectors of UBM using maximum a posteriori (MAP) criteria [5], while the weights and covariance matrix were set to the corresponding parameters of the UBM. All gaussian means vectors are pooled together to get one GMM supervector [3]. We produced GMM supervector on a per sequence. The GMM supervector can be thought of as a mapping between an utterance and a highdimensional vector."}, {"heading": "3. Classifiers", "text": "This section gives below a brief description of two supervised learning methods used to\nclassify the GMM speaker models, namely NB and SVM."}, {"heading": "3.1. Na\u00efve Bayes (NB)", "text": "The naive bayes classification model is a simple classification technique based on Bayes\u2019 theorem. This classifier assumes that the effect of an attribute value on a given class label is independent of the values of the other attributes. This assumption is called class conditional independence. This classifier simply computes the conditional probabilities of the different classes given the values of attributes and then selects the class with the highest conditional probability.\nIf an instance is described with n attributes ai (i=1\u2026n), then the class that instance is classified to a class c from set of possible classes C according to a Maximum a Posteriori (MAP) Naive Bayes classifier is:\n1 arg max ( ) ( ( ))\nj\nn\nj i j i\nc C\nc p c p a c \n\n  \nDespite its simplicity, Naive Bayes can often outperform more sophisticated classification\nmethods. For speaker recognition, NB algorithm is largely used, such in [8].\nIn our work, we propose the combination of both methods GMM and NB. We present the NB classifier in the supervector GMM space. This method is a novel approach substantially different from existing techniques."}, {"heading": "3.2. Support Vector Machines (SVM)", "text": "Support vector machines are a new technique of the statistical learning theory proposed by Vapnick in 1995 [6] and are based on the structural risk minimization principle [11] from computational learning theory. SVMs are a new kernel method suitable for binary classification tasks that makes its decisions by constructing a hyperplane that optimally separates two classes.\nIn order to tackle non-linear classification problems, the input feature space is typically transformed to a higher dimensional space via a kernel function, where it is possible to define a hyperplane to separate both classes with maximum margin.\nFor speaker recognition, the first approach in using SVM classifier was implemented by Schmidt where SVM were trained directly on the acoustic space [6]. Another approach became recently more popular; consist of using an hybrid GMM-SVM [1, 2] in a way that the\nrobustness advantage of generative models of GMM is combined with the discriminative power of SVM."}, {"heading": "4. Multi Level Data Fusion", "text": "Data fusion techniques encompass any area which deals with applying a combination of different sources of information. The essential idea is to more accurately estimate the classification results via fusing the final outcomes of different experts (features, classifiers\u2026) in an efficient way. Then the output of such combinations can be superior to all the individual experts."}, {"heading": "4.1. Feature Level Fusion", "text": "4.1.1. Vector Concatenation: The idea of fusing different sources of features in speaker identification is not new. A well-known data fusion strategy is to concatenate the cepstral vectors with their delta (\u2206) and delta-delta (\u2206\u2206) cepstra into a single feature vector, as shown in (Figure 2).\nIn general, vector concatenation is termed as classifier input fusion [10].\n4.1.2. GMM Supervectors Level Fusion: We propose another multi input fusion by concatenating the GMM supervectors from features. In this case, we concatenate the outputs of modeling stage as summarized in (Figure 3).\nThe multi-supervector is then presented to the speaker-independent classifier for scoring."}, {"heading": "4.2. Scores Level Fusion", "text": "Researches in recent years show that fusion can be done in different levels and the score level fusion is the best in sense of simplicity and amount of information which supposed to be combined. The basic idea behind classifier combination is that when making a decision, one should not rely only on a single classifier, but rather classifiers need to participate in decision making by combining their individual scores.\nIn our case, each data is treated separately and each classifier independently makes its\ndecisions as shown in (Figure 4)."}, {"heading": "5. Experiments and Results", "text": ""}, {"heading": "5.1. Corpus Description", "text": "The NTIMIT database is made of TIMIT utterances which are transmitted over a variety of telephone lines conditions. Each sentence of a speaker is transmitted over a different telephone line in order to have realistic conditions. All the utterances are different across speakers except utterance \u2018SA1\u2019 and \u2018SA2\u2019, which are common. We performed experiments on the dialect DR1 (New England dialect) for 28 speaker (14 female and 14 males). Each speaker spoke ten utterances, eight utterances are selected for training and two utterances are selected for the identification test. The data was digitized using 16 kHz sampling frequency with 16 bits per sample."}, {"heading": "5.2. Feature Extraction", "text": "The speech feature extraction (front-end) is a key focus in robust speech recognition which\nsignificantly affects the recognition performance.\nEach feature vector was extracted from pre-emphasized speech at 8ms intervals using a 16\nms window. A Hamming window was then applied to the speech frame.\nIn this study, we utilize mel-scale frequency cepstral coefficient (MFCC), these coefficients have been used as a standard acoustic feature set for identification system. Actually MFCC coefficients are the less vulnerable coefficient to noise perturbation [15].\nWe also use relative spectral perceptual linear predictive (RASTA-PLP) coefficients, this choice is emphasized by the fact that these coefficients are proved to be more robust for noisy environment [4] and have shown good recognition performance in a previous study [16].\nWe furthermore added the dynamic cepstrum parameters due to their popularity in\nautomatic speaker recognition systems [17].\nIn our work, we construct 5 features data:\n Feature 1: characterized by the use of 12 MFCC coefficients.\n Feature 2: characterized by the use of 13 RASTA-PLP.\n Feature 3: characterized by the use of 12 MFCC coefficients accompanied by Delta and\ndelta (Delta) coefficients, which sums to a 36 features.\n Feature 4: characterized by the use of 13 RASTA-PLP coefficients accompanied by\nDelta and Delta (Delta) coefficients, which sums to a 39 features.\n Feature 5: characterized by the concatenation of the supervectors issued from feature 1\nand feature 2."}, {"heading": "5.3. Baseline System", "text": "Our baseline system consists of a 128 component GMM-UBM built using the training\nutterances of all the 28 speakers. Individual speaker models are MAP-adapted; only mean\nvectors, with a relevance factor of 16.\nAfter modeling speaker according to each feature data, we use individually the SVM and\nthe NB for scoring and as a final step; we combine for each feature these two classifiers.\nWe construct three systems:\n System 1: SVM classifier.\n System 2: NB classifier.\n System 3: combination of SVM and NB classifiers.\nTo train SVM, we use a new learning algorithm called sequential Minimal Optimization\n(SMO) [14]. SVM algorithm was evaluated using linear kernel given by (5).\n( , ) . .i ik x v x v  \nWhere x is the input data and vi are the support vectors.\nTo handle with the SVM multi class, we are considered the one versus one approach. The\nSVM algorithm is implemented using the library LIBSVM [7].\nOnly for SVM, data were scaled to [0, 1] before the classification process.\nThe performance is measured as the identification rate (IR).\n(%) . Number of correct assignments\nIR Number of total assignments\n "}, {"heading": "5.4. Results", "text": "The results of the individual features are shown in (Table 1) for the three systems.\nTable 1 shows that the Identification rate is varied between (50%) and (75%). We note that Feature 2 (RASTA-PLP) outperform Feature1 (MFCC) for the three systems. We also note that System1 (SVM) performs better than System2 (NB). The table shows also that the maximum IR is generated by combined classifiers for the two sets of feature.\nThe results of the combined features are shown in (Table 2) for the three systems.\nTable 2 shows that the Identification rate is varied between (50%) and (71, 42%). For Feature 3, results prove that SVM classifier (System 1) performs better (60, 71%) than NB classifier (System 2) (53, 57%). For Feature 4, results prove that SVM classifier (System 1) performs better (57, 14%) than NB classifier (System 2) (50%). As observed, fusion score in System 3 improves accuracy, it provides the best IR equal to (71, 42%) for the two features data.\nThe performance of fusing supervectors for the three tested systems is evaluated in (Table\n3).\nTable 3 shows that the Identification rate is varied between (60, 71%) and (85, 71%). It is noted that for the three systems, Feature 5 improve accuracy, the highest recognition accuracy is obtained using the System3 (85, 71%). The combination of the two feature type GMM supervectors shows a promising result."}, {"heading": "6. Conclusion", "text": "In this paper, we have proposed several methods for text speaker identification which is\nvery difficult through the telephone network, by fusing different feature extraction methods\nand different classifiers in order to improve the recognition accuracy.\nThe best recognition results are obtained from the concatenation of GMM supervectors\nfrom Rasta-PLP features and MFCC features with the use of combined classifiers.\nIn further work, we will try to study the performance of the proposed systems on the whole\nNTIMIT corpus."}], "references": [{"title": "Robust Text Independent Speaker Identification Using Hybrid GMM-SVM System", "author": ["S.Z. Boujelbene", "D.B.A. Mezghani", "N. Ellouze"], "venue": "Journal of Convergence Information Technology \u2013 JDCTA,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2009}, {"title": "Evaluation d\u2019une approche hybride GMM-SVM pour l\u2019identification de locuteurs", "author": ["I. Trabelsi", "D.B. Ayed"], "venue": "La revue e-STA,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2011}, {"title": "Rasta plp speech analysis", "author": ["H. Hermansky", "N. Morgan", "A. Bayya", "P. Kohn"], "venue": "International Computer Science Institute,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 1947}, {"title": "Speakerverification using adapted gaussian mixture models", "author": ["D. Reynolds", "T. Quatieri", "R. Dunn"], "venue": "DSP, vol. 10,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2000}, {"title": "Speaker Identification via Support Vector Machies", "author": ["M. Schmidt", "H. Gish"], "venue": "in ICASSP,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 1996}, {"title": "LIBSVM: a library for support vector machines", "author": ["C. -C. Chang", "C. -J. Lin"], "venue": null, "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2001}, {"title": "On naive bayes in speech recognition", "author": ["L. Toth", "A. Kocsor", "J. Csirik"], "venue": "nt. J. Appl. Math. Comput. Sci.,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2005}, {"title": "An Overview of Automatic Speaker Recognition Technology", "author": ["D. Reynolds"], "venue": "the International Conference on Acoustics, Speech, and Signal Processing ICASSP 02,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2002}, {"title": "A Comparison of fusion techniques in mel-cepstral based speaker idenficication", "author": ["S. Slomka", "S. Sridharan", "V. Chandran"], "venue": "Proc. ICSLP", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 1998}, {"title": "Statistical learning theory", "author": ["V. Vapnik"], "venue": null, "citeRegEx": "11", "shortCiteRegEx": "11", "year": 1998}, {"title": "An Acoustic-Phonetic Data Base", "author": ["W. Fisher", "V. Zue", "J. Bernstein", "D. Pallet"], "venue": "J. Acoust. Soc. Amer. Suppl. (A),", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 1986}, {"title": "Maximum Likelihood from incomplete data via the EMalgorithm", "author": ["A.P.N. Dempster", "M.D. Laid", "B. Durbin"], "venue": "J. Royal Statistical Soc., vol", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 1977}, {"title": "Sequential minimal optimization: A fast algorithm for training support vector machines", "author": ["J.C. Platt"], "venue": "Rapport interne, Microsoft Research,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 1998}, {"title": "Comparison of Parametric Representation for Monosyllabic Word Recognition in Continuously Spoken Sentences", "author": ["S.B. Davis", "P. Mermelstein"], "venue": "IEEE Trans. On ASSP, vol. ASSP 28,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 1980}, {"title": "Strat\u00e9gies de fusion de param\u00e8tres pour une t\u00e2che d'identification du locuteur en mode ind\u00e9pendant du texte en environnement bruit\u00e9: Application sur le corpus Ntimit", "author": ["I. Trabelsi", "D. Ben Ayed"], "venue": null, "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2011}, {"title": "On the Use of Instantaneous and Transitional Spectral Information in Speaker Recognition", "author": ["F.K. Soong", "A.E. Rosenberg"], "venue": "IEEE Trans. Acoustics, Speech and Signal Processing,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 1988}, {"title": "Sole-Casals, \u201cMaximum Likelihood Linear Programming Data Fusion for Speaker Recognition", "author": ["E. Monte-Moreno", "M. Chetouani", "J.M. Faundez-Zanuy"], "venue": "Speech Communication,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2009}, {"title": "On Combining Classifiers", "author": ["J. Kittler", "M. Hatef", "R.P.W. Duin", "J. Matas"], "venue": "IEEE Trans. Pattern Analysis and Machine Intelligence,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 1998}], "referenceMentions": [{"referenceID": 7, "context": "For text dependent methods, the test utterance is known while for text independent methods, it is not known [9].", "startOffset": 108, "endOffset": 111}, {"referenceID": 16, "context": "This technique can be divided in two main categories: systems based on features diversity [18] and systems based on classifiers diversity [19].", "startOffset": 90, "endOffset": 94}, {"referenceID": 17, "context": "This technique can be divided in two main categories: systems based on features diversity [18] and systems based on classifiers diversity [19].", "startOffset": 138, "endOffset": 142}, {"referenceID": 10, "context": "34 experiments the NTIMIT database [12].", "startOffset": 35, "endOffset": 39}, {"referenceID": 11, "context": "A standard approach in estimating the parameters of GMM-UBM aims to learn the mean vector, covariance matrix and the weight through expectation-maximization (EM) algorithm [13] from a background dataset.", "startOffset": 172, "endOffset": 176}, {"referenceID": 3, "context": "Each speaker is then modeled and referred by adapting only the mean vectors of UBM using maximum a posteriori (MAP) criteria [5], while the weights and covariance matrix were set to the corresponding parameters of the UBM.", "startOffset": 125, "endOffset": 128}, {"referenceID": 6, "context": "For speaker recognition, NB algorithm is largely used, such in [8].", "startOffset": 63, "endOffset": 66}, {"referenceID": 4, "context": "Support Vector Machines (SVM) Support vector machines are a new technique of the statistical learning theory proposed by Vapnick in 1995 [6] and are based on the structural risk minimization principle [11] from computational learning theory.", "startOffset": 137, "endOffset": 140}, {"referenceID": 9, "context": "Support Vector Machines (SVM) Support vector machines are a new technique of the statistical learning theory proposed by Vapnick in 1995 [6] and are based on the structural risk minimization principle [11] from computational learning theory.", "startOffset": 201, "endOffset": 205}, {"referenceID": 4, "context": "For speaker recognition, the first approach in using SVM classifier was implemented by Schmidt where SVM were trained directly on the acoustic space [6].", "startOffset": 149, "endOffset": 152}, {"referenceID": 0, "context": "Another approach became recently more popular; consist of using an hybrid GMM-SVM [1, 2] in a way that the", "startOffset": 82, "endOffset": 88}, {"referenceID": 1, "context": "Another approach became recently more popular; consist of using an hybrid GMM-SVM [1, 2] in a way that the", "startOffset": 82, "endOffset": 88}, {"referenceID": 8, "context": "In general, vector concatenation is termed as classifier input fusion [10].", "startOffset": 70, "endOffset": 74}, {"referenceID": 13, "context": "Actually MFCC coefficients are the less vulnerable coefficient to noise perturbation [15].", "startOffset": 85, "endOffset": 89}, {"referenceID": 2, "context": "We also use relative spectral perceptual linear predictive (RASTA-PLP) coefficients, this choice is emphasized by the fact that these coefficients are proved to be more robust for noisy environment [4] and have shown good recognition performance in a previous study [16].", "startOffset": 198, "endOffset": 201}, {"referenceID": 14, "context": "We also use relative spectral perceptual linear predictive (RASTA-PLP) coefficients, this choice is emphasized by the fact that these coefficients are proved to be more robust for noisy environment [4] and have shown good recognition performance in a previous study [16].", "startOffset": 266, "endOffset": 270}, {"referenceID": 15, "context": "We furthermore added the dynamic cepstrum parameters due to their popularity in automatic speaker recognition systems [17].", "startOffset": 118, "endOffset": 122}, {"referenceID": 12, "context": "To train SVM, we use a new learning algorithm called sequential Minimal Optimization (SMO) [14].", "startOffset": 91, "endOffset": 95}, {"referenceID": 5, "context": "The SVM algorithm is implemented using the library LIBSVM [7].", "startOffset": 58, "endOffset": 61}, {"referenceID": 0, "context": "Only for SVM, data were scaled to [0, 1] before the classification process.", "startOffset": 34, "endOffset": 40}], "year": 2013, "abstractText": "Several speaker identification systems are giving good performance with clean speech but are affected by the degradations introduced by noisy audio conditions. To deal with this problem, we investigate the use of complementary information at different levels for computing a combined match score for the unknown speaker. In this work, we observe the effect of two supervised machine learning approaches including support vectors machines (SVM) and na\u00efve bayes (NB). We define two feature vector sets based on mel frequency cepstral coefficients (MFCC) and relative spectral perceptual linear predictive coefficients (RASTA-PLP). Each feature is modeled using the Gaussian Mixture Model (GMM). Several ways of combining these information sources give significant improvements in a text-independent speaker identification task using a very large telephone degraded NTIMIT database.", "creator": "Microsoft\u00ae Word 2010"}}}