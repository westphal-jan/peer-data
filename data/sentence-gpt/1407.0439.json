{"id": "1407.0439", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "2-Jul-2014", "title": "Geometric Tight Frame based Stylometry for Art Authentication of van Gogh Paintings", "abstract": "This paper is about authenticating genuine van Gogh paintings from forgeries. The authentication process depends on two key steps: feature extraction and outlier detection. In this paper, a geometric tight frame and some low order moment statistics of the tight frame coefficients are used to extract features from the paintings. As a result, the trick we learned is to apply the process to paintings and thus create a flat-frame. In the previous paper, we were working with this method as a proof of concept. We used the technique to analyze van Gogh paintings from forgery using the image of the Dutch painting studio Dorn-G\u00f6der. In order to analyze the paintings, we used the technique to analyze Van Gogh paintings from forgery using the image of the Dutch painting studio Dorn-G\u00f6der. As a result, the trick we learned is to apply the process to paintings and thus create a flat-frame. In this paper, a geometric tight frame and some low order moment statistics of the tight frame coefficients are used to extract features from the paintings. As a result, the trick we learned is to apply the process to paintings and thus create a flat-frame. In this paper, a geometric tight frame and some low order moment statistics of the tight frame coefficients are used to extract features from the paintings. As a result, the trick we learned is to apply the process to paintings and thus create a flat-frame. In this paper, a geometric tight frame and some low order moment statistics of the tight frame coefficients are used to extract features from the paintings. As a result, the trick we learned is to apply the process to paintings and thus create a flat-frame. In this paper, a geometric tight frame and some low order moment statistics of the tight frame coefficients are used to extract features from the paintings. As a result, the trick we learned is to apply the process to paintings and thus create a flat-frame. In this paper, a geometric tight frame and some low order moment statistics of the tight frame coefficients are used to extract features from the paintings. As a result, the trick we learned is to apply the process to paintings and thus create a flat-frame. In this paper, a geometric tight frame and some low order moment statistics of the tight frame coefficients are used to extract features from the paintings. As a result, the trick we learned is to apply the process to paintings and thus create a flat-frame. In this paper, a geometric tight frame and some low order moment statistics of the tight frame coefficients are used", "histories": [["v1", "Wed, 2 Jul 2014 01:55:37 GMT  (209kb)", "https://arxiv.org/abs/1407.0439v1", "14 pages, 10 figures"], ["v2", "Sat, 13 Sep 2014 00:53:16 GMT  (0kb,I)", "http://arxiv.org/abs/1407.0439v2", "This paper has been withdrawn by the author due to a critical error in numerical result"], ["v3", "Tue, 13 Jan 2015 07:20:12 GMT  (778kb)", "http://arxiv.org/abs/1407.0439v3", "14 pages, 13 figures"]], "COMMENTS": "14 pages, 10 figures", "reviews": [], "SUBJECTS": "cs.LG cs.CV", "authors": ["haixia liu", "raymond h chan", "yuan yao"], "accepted": false, "id": "1407.0439"}, "pdf": {"name": "1407.0439.pdf", "metadata": {"source": "CRF", "title": "GEOMETRIC TIGHT FRAME BASED STYLOMETRY FOR ART AUTHENTICATION OF VAN GOGH PAINTINGS", "authors": ["HAIXIA LIU", "RAYMOND H. CHAN", "YUAN YAO"], "emails": [], "sections": [{"heading": null, "text": "ar X\niv :1\n40 7.\n04 39\nv3 [\ncs .L\nG ]\n1 3\nJa n\n20 15\n1. Introduction. Art authentication is the identification of genuine paintings by famous artists and detection of forgery paintings by imitators. The traditional way in art authentication is to rely on the discerning eyes and experience of experts who are dedicated in the work and life of the artist(s). Physical means such as ultraviolet fluorescence [23], infrared reflectography [10], x-ray radiography [27], painting sampling [6], and canvas weave count [3] have also been used for art authentication. The term stylometry refers to the application of statistical or quantitative techniques for authorship and style evolution in literary arts [28]. In the past decade, research in stylometry for paintings has been benefited from the rapid progress in image data acquisition technology. By using high-resolution digital images of artists\u2019 collections, image analysis researchers and art historians have engaged in cross-disciplinary stylometric analysis of art paintings via computational techniques [30, 24, 19, 1, 2, 17, 18, 20, 29].\nAlthough many art authentication methods were proposed and used, the authorship of many paintings is still questioned by experts, with different art scholars having different opinions. Stylometry for paintings, in particular, is still a long way from being a mature field, even for paintings from well-known artists. Here, we propose a new stylometric technique for art authentication of Vincent van Gogh paintings. Our results on 79 paintings provided by van Gogh Museum and Kro\u0308ller-Muller Museum show that our method is better than existing van Gogh paintings authentication methods [29, 18, 24].\nStylometry is based on the assumption that there are some distinctions in styles among different artists. Each artist exhibited particular traces of natural style and habitual physical movements when painting. Therefore, characteristics reflecting these\n\u2217Department of Mathematics, The Chinese University of Hong Kong, Hong Kong, China. Research of Raymond H. Chan is supported in part by HKRGCGRF Grant No. CUHK400412, HKRGC CRF Grant No. CUHK2/CRF/11G, HKRGC AoE Grant AoE/M-05/12, CUHK DAG No. 4053007, and CUHK FIS Grant No. 1902036. (mahxliu@ust.hk, rchan@math.cuhk.edu.hk).\n\u2020School of Mathematical Sciences, LMAM-LMEQF-LMPR, Peking University, Beijing, China 100871. The research of Yuan Yao is supported in part by National Basic Research Program of China (973 Program 2012CB825501,2015CB856000), NSFC grant 61071157 and 61370004. (yuany@math.pku.edu.cn).\nhabits can be considered as features to identify the authorship of paintings. In the past two decades, various specialized features have been used in stylometric analysis, and many paintings are authenticated. An early study was given by Taylor et al. in 1999 on fractal analysis of Pollock\u2019s drip paintings [30]. They showed that the fractal dimensions increased steadily through Pollock\u2019s career and fractal analysis could be used as a quantitative and objective technique for analyzing his paintings. In a 2004 paper by Lyu et al. [24], the moment statistics of wavelet coefficients and the log error in a linear predictor are used as features to authenticate the drawings by Pieter Bruegel the Elder. In the same year, Li and Wang [19] put 2D multi-resolution Hidden Markov Model (HMM) in use to classify paintings from some China\u2019s famous artists in different dynasty periods. Later, Berezhnoy et al. [2] gave an orientation extraction technique based on circular filters for brushstroke extraction. Recently, the moment statistics of 2-D Empirical Mode Decomposition (EMD) coefficients were used by Hughes et al. [17] for stylometric analysis of drawings by Pieter Bruegel the Elder and Rembrandt van Rijn. For each forgery in their dataset, a binary classifier was trained based on this forgery together with all but one genuine drawings. Then the left-out genuine drawing was classified according to the trained classifier. However, in the paper, there is no authentication done on the forgery drawings.\nIn 2008, three research groups from Penn State, Princeton, and Maastricht focusing on authenticating van Gogh paintings reported their analysis of van Gogh\u2019s brushstrokes in [18]. In the work of the Penn state group, the similarity among paintings were assessed via texture and brushstroke geometry modeling. The Princeton group applied the complex wavelet and Hidden Markov Tree (HMT) for feature extraction, and then similarity distances between paintings were calculated using the first few features ranked according to their effectiveness in distinguishing van Gogh\u2019s and non-van Gogh\u2019s patches. Finally a multidimensional scaling embeds the paintings into a 3D space where the separation of genuine paintings from forgery ones was done. Binary support vector machine was used to determine the authorship by the Maastricht group. It is based on the fact that the total energy, as calculated using the Gabor wavelet coefficients from the patches, was larger in the non-van Gogh\u2019s paintings. These studies are quite encouraging as initial works for identifying the authorship of van Gogh paintings.\nIn 2012, Li et al. [20] made an effort to extract those visually salient brushstrokes of van Gogh based on an integrative technique of both edge detection and clusteringbased segmentation. With the extracted brushstrokes, some definitions of brushstroke features for art authentication were given in distinguishing van Gogh paintings from forgeries. In their numerical test, they compared the brushstrokes obtained manually with those extracted using their algorithm and showed that the combined brushstroke features were consistent throughout van Gogh\u2019s works during his French periods (1886- 1890).\nMore recently in 2013, Qi. et al. [29] use background selection and waveletHMT-based Fisher information distance for authorship and dating of impressionist and post-impressionist paintings. Two novel points were introduced in this work. The first point is that background information is much more reliable than the details of an intricate object which cannot represent the artist\u2019s natural style because of multiple edits and corrections. Therefore they proposed to seek out sections in the paintings that have been painted quickly without too much modification. However, in their tests the labeling of painting patches, either \u201cbackground\u201d or \u201cdetail\u201d, is done manually by a non-expert. The second point is that an artist\u2019s style should be interpreted as a\nprobability distribution over a set of possible textures, and not just simply from the textures themselves.\nFor art authentication, the key point is to find the appropriate features which give a good separation between the artist\u2019s paintings and those by his imitators. In this paper we aim to find an appropriate measure so that the paintings drawn by one artist, such as van Gogh, are much more similar than those by the imitators. As in [18], we first start by analyzing the brushstrokes in the paintings by some analysis operators. Instead of using the variety of techniques such as wavelets, EMD, HMM and HMT in [24, 17, 18, 29], here we propose to use a special tight frame, called geometric tight frame [22], to extract brushstroke information from the given paintings. Tight-frame transforms are redundant bases that can provide overcomplete but stable coding of directional variations [7]. The geometric tight frame we used has 18 filters that give the first- and second-order differences in the horizontal, vertical and diagonal directions in small neighborhoods. Therefore it can capture subtle oriented variations in the texture of the paintings.\nNext to find our features, we follow the moment statistics approach explored in [24, 17] and propose to use 3 simple statistics of the geometric tight frame coefficients as our features. They are the mean of the coefficients, the standard deviation of the coefficients, and the percentage of those coefficients that are more than one standard deviation away from the mean. That gives a total of 54 features for each painting. Then we select the discriminatory features by a forward stage-wise boosting procedure [13, 15]. It selects features by maximizing the area under the Receiver Operating Characteristic (ROC) [13] curve such that van Gogh\u2019s paintings are highly concentrated while the forgeries are widely spread. We also used the leave-one-out cross-validation procedure to avoid overfitting while maximizing the amount of training data.\nOnce the features are selected, we use a simple thresholding rule to authenticate the paintings. Our test on the 79 paintings shows that we can achieve 86.08% classification accuracy and it reveals that 5 of the 54 features are predominant. By using just these 5 features, we can get a 88.61% classification accuracy which is highest so far reported in the literature [29, 18, 24]. Evaluation of the five features is also performed on two hundred 79-painting datasets generated by bootstrap sampling with replacement [12]. The 95% confidence interval is (78.48%, 94.94%) with median 88.61% and mean 87.77%. Our results show that a small set of statistics of the tight frame coefficients along certain orientations in small neighborhood can serve as discriminative features for van Gogh paintings. This reflects a highly consistent style in van Gogh\u2019s brushstroke movements, where many forgeries demonstrate a more diverse spread in these features.\nOur proposed method, though tested only on van Gogh dataset, can easily be applied to paintings by other artists. We hope that our method may help art scholars to identify more digital evidences discriminating different artists\u2019 paintings from forgeries.\nThis paper is organized as follows. Section 2 describes the dataset we used for our art authentication. Section 3 introduces how we construct our features. Section 4 explains how we select the most discriminatory features among the features we constructed. Section 5 describes how we used the selected features so obtained to do the authentication. Section 6 gives the numerical results. We draw a conclusion in Section 7.\n2. Dataset. Our dataset consists of 79 digitalized impressionist and post impressionist paintings provided to us by the Maastricht group [18]. They are high-resolution\ncolor copies of paintings from the van Gogh museum and Kro\u0308ller-Muller museum by professional scanners and are suitable for art research. These paintings vary in sizes, with the smallest one being 1452-by-833 pixels and the largest one 5614-by-7381 pixels. Among the 79 paintings, 64 paintings were drawn by van Gogh himself and the remaining 15 paintings were by his contemporaries. In the following, we will abbreviate them as vG (van Gogh) and nvG (non-van Gogh) paintings respectively. Sample images of vG and nvG paintings are given in Figures 6.1 and 6.2. It should be noted that the 15 forgeries are very similar to the 64 van Gogh\u2019s artworks, with 6 of them historically attributed to van Gogh, but have been known to be forgeries now. Table 2.1 lists these six once-debatable paintings, which are regarded as difficult examples for stylometric analysis. We make a note about the boundary of the paintings here.\nAs pointed out in Qi et al. [29], the edges of the canvas in the paintings may not be useful information for art authentication, and hence we have excluded these edges in our numerical experiments. More precisely, for each painting in the dataset, we crop off 100 pixels from its four sides, and use only the interior of the image in our numerical tests.\nIn the following we focus on finding a small set of features to automatically classify the 79 paintings into vG and nvG. With a small set of samples, to avoid the problem of overfitting, we adopt the leave-one-out test method [14]. Then a forward stage-wise boosting procedure [13, 15] is used to construct a small set of features such that in such feature space those vG\u2019s are highly concentrated in a cluster while the nvG\u2019s are mostly spread away from such a cluster. More precisely, we consider the art authentication problem as an outlier detection problem, where vG\u2019s are the normal data and nvG\u2019s are the outliers. In the next three sections we introduce the methodology to achieve this goal and here is the outline of these three sections.\nSection 3 introduces our approach of extracting features from the paintings. It is based on an 18-filter geometric tight frame and 3 simple statistics so that each painting is represented by a 54-dimensional vector after feature extraction. The accuracy of our method is tested by a leave-one-out test scheme which uses one painting from the original dataset as the test painting and the remaining 78 paintings as the training data. In Section 4, we describe how the forward stage-wise boosting procedure is used to select 5 important features among the 54 features. In Section 5, we focus on the classification of the test painting. In Subsection 5.1, we describe how to construct the classification rule once the 5 features are selected and in Subsection 5.2 how to use the rule to classify the test painting. This procedure is repeated 79 times such that each painting in the dataset is tested once. The classification accuracy of our method is measured by the results of these 79 tests.\n3. Feature Extraction. Tight frames have been used successfully in different applications in image processing [11, 8, 7]. The geometric tight frame we use to analyze the brushstrokes in our paintings is proposed in [21, 22] and it can capture the firstand second-order differences in the horizontal, vertical and diagonal directions in every small neighborhood of the paintings. As discovered in [24, 17, 29], statistical properties of quantities such as wavelet coefficients, EMD coefficients or HMT-parameters are useful in authenticating paintings by various artists. Here we combine the two ideas and propose to use some simple statistics of the geometric tight frame coefficients of each painting as our features. We will see from the numerical results in Section 6 that our features can do a good job in capturing the rapid, rhythmic, and vigorous brushstroke movements of van Gogh, and hence discriminating his paintings from those forgeries of his contemporaries.\nIn the following, we introduce the geometric tight frame and the statistics used in this paper.\n3.1. Geometric tight frame. The geometric tight frame we use has 18 filters \u03c40, \u03c41, \u00b7 \u00b7 \u00b7 , \u03c417:\n\u03c40 = 1\n16\n\n 1 2 1 2 4 2 1 2 1\n\n , \u03c41 = 1\n16\n\n 1 0 \u22121 2 0 \u22122 1 0 \u22121\n\n , \u03c42 = 1\n16\n\n 1 2 1 0 0 0 \u22121 \u22122 \u22121\n\n ,\n\u03c43 =\n\u221a 2\n16\n\n 1 1 0 1 0 \u22121 0 \u22121 \u22121\n\n , \u03c44 =\n\u221a 2\n16\n\n 0 1 1 \u22121 0 1 \u22121 \u22121 0\n\n , \u03c45 =\n\u221a 7\n24\n\n 1 0 \u22121 0 0 0 \u22121 0 1\n\n ,\n\u03c46 = 1\n48\n\n \u22121 2 \u22121 \u22122 4 \u22122 \u22121 2 \u22121\n\n , \u03c47 = 1\n48\n\n \u22121 \u22122 \u22121 2 4 2 \u22121 \u22122 \u22121\n\n , \u03c48 = 1\n12\n\n 0 0 \u22121 0 2 0 \u22121 0 0\n\n ,\n\u03c49 = 1\n12\n\n \u22121 0 0 0 2 0 0 0 \u22121\n\n , \u03c410 =\n\u221a 2\n12\n\n 0 1 0 \u22121 0 \u22121 0 1 0\n\n , \u03c411 =\n\u221a 2\n16\n\n \u22121 0 1 2 0 \u22122 \u22121 0 1\n\n ,\n\u03c412 =\n\u221a 2\n16\n\n \u22121 2 \u22121 0 0 0 1 \u22122 1\n\n , \u03c413 = 1\n48\n\n 1 \u22122 1 \u22122 4 \u22122 1 \u22122 1\n\n , \u03c414 =\n\u221a 2\n12\n\n 0 0 0 \u22121 2 \u22121 0 0 0\n\n ,\n\u03c415 =\n\u221a 2\n24\n\n \u22121 2 \u22121 0 0 0 \u22121 2 \u22121\n\n , \u03c416 =\n\u221a 2\n12\n\n 0 \u22121 0 0 2 0 0 \u22121 0\n\n , \u03c417 =\n\u221a 2\n24\n\n \u22121 0 \u22121 2 0 2 \u22121 0 \u22121\n\n ,\n(3.1)\nsee [21, 22]. We note that \u03c40 is the low-pass filter. The filters \u03c41, \u03c42, \u03c43 and \u03c44 are the Sobel operators in the vertical, horizontal, \u2212\u03c04 , and \u03c04 directions, respectively whereas the filters \u03c48, \u03c49, \u03c414, \u03c415, \u03c416 and \u03c417 are the second-order difference operators in different directions.\nGiven the i-th color painting, 1 \u2264 i \u2264 79, with mi-by-ni pixels, we represent its grey-scale intensity by an mi-by-ni matrix Pi. Then we convolve Pi with each \u03c4j , 0 \u2264 j \u2264 17, to get the corresponding mi-by-ni tight frame coefficient matrices:\nA(i,j) = Pi \u2217 \u03c4j =\n\n  \na (i,j) 1,1 \u00b7 \u00b7 \u00b7 a (i,j) 1,ni\n... ...\na (i,j) mi,1 \u00b7 \u00b7 \u00b7 a(i,j)mi,ni\n\n   , 1 \u2264 i \u2264 79, 0 \u2264 j \u2264 17. (3.2)\nTherefore, there are 18 corresponding coefficient matrices for each painting after the decomposition by the geometric tight frame. We remark that we only use one level of the tight frame transform without any down-sampling. Our numerical result shows that using 2 levels of tight frame transform gives a bad classification accuracy, see Table 6.1. Moreover, it increases the number of features significantly.\n3.2. Three statistics. Moment statistics has been used successfully to extract features in art authentication, see [24, 17, 25]. In [17], the moment statistics of the \u201coutlier pixels\u201d, defined as those that are greater than the mean plus one standard deviation, are also considered as features. Thus here we propose to use the following three statistics as features. They are (i) the mean of the entries in the coefficient matrix, (ii) the standard deviation of the entries in the coefficient matrix, and (iii) the percentage of the \u201ctail entries\u201d which are those entries that are more than one standard deviation from the mean. To be precise, given a coefficient matrix A(i,j) in (3.2) with entries a (i,j) l,k , the three statistics are defined as follows:\n(i) the mean of A(i,j):\n\u00b5(i,j) = 1\nmini\nmi \u2211\nl=1\nni \u2211\nk=1\na (i,j) l,k ,\n(ii) the standard deviation of A(i,j):\n\u03c3(i,j) =\n(\n1\nmini \u2212 1\nmi \u2211\nl=1\nni \u2211\nk=1\n(\na (i,j) l,k \u2212 \u00b5(i,j)\n)2 )\n1 2\n,\n(iii) the percentage of the tail entries p(i,j) = #(A\u0302(i,j))/(mini).\nHere #(A\u0302(i,j)) is the number of nonzero entries in the tail matrix A\u0302(i,j) which is defined by\na\u0302 (i,j) l,k =\n{\na (i,j) l,k , if |a (i,j) l,k \u2212 \u00b5(i,j)| > \u03c3(i,j),\n0, otherwise.\nThus the feature vector of the i-th painting is represented by\n[ \u00b5(i,0), \u00b7 \u00b7 \u00b7 , \u00b5(i,17), \u03c3(i,0), \u00b7 \u00b7 \u00b7 , \u03c3(i,17), p(i,0), \u00b7 \u00b7 \u00b7 , p(i,17) ] \u2208 R54. (3.3)\nIn summary, we have 79 paintings and 54 features. The accuracy of our method is tested by a leave-one-out procedure where a painting, say P , in the dataset is used as the testing data and the remaining 78 paintings in the dataset are used as the training data to select a small feature subset G \u2286 {1, 2, . . . , 54}. Then G is used to train a classifier to test the left-out painting P . The next section describes how to select G.\n4. Forward stage-wise feature selection procedure. Considering the highly rhythmic brushstroke movements of van Gogh, it is unlikely that all the 54 features are discriminative between van Gogh and his contemporaries. If we include some noisy features in our classification task, the accuracy will deteriorate. Therefore, in this section we develop a feature selection method based on a forward stage-wise rank boosting [15] to boost the discriminating power of our feature sets. Such a feature\nselection plays an indispensable role in our method, which not only greatly improves our classification accuracy but also leads to interpretable models\u2014where with only five features we can reach a classification accuracy of 88.61%. In this section, we describe our procedure to select a good feature subset from the given training dataset.\nThe way we discriminate van Gogh\u2019s paintings from the forgeries is based on the assumption that van Gogh exhibits highly consistent brushstroke movements in some of the texture features. Therefore under these features van Gogh\u2019s paintings will be highly concentrated toward some center points while forgeries are spread as outliers. To be more precise, let the training dataset be X = {x1, \u00b7 \u00b7 \u00b7 ,x78} and\nX =\n\n  x1 ...\nx78\n\n  \u2208 R78\u00d754\nbe the data matrix of X and X\u0303 be the normalization of X such that each column in X\u0303 has a unit standard deviation. Let {1, . . . , 78} = TvG \u222a TnvG where TvG (respectively TnvG) denotes the set of vG (respectively nvG) paintings in X . For any feature subset F , denote |F| the number of elements in the set F and F = {i1, \u00b7 \u00b7 \u00b7 , i|F|}. Define X\u0303jF = (X\u0303ji1 , \u00b7 \u00b7 \u00b7 , X\u0303ji|F| ), i.e. X\u0303jF is the j-th row of X\u0303 restricted onto the index set F . Then we define the vG center w.r.t. F as the mean vector of vG on F , i.e.\ncF = 1 |TvG| \u2211\nj\u2208TvG\nX\u0303jF . (4.1)\nWith this we define the distance between the j-th painting in X and the vG center cF by\ndFj = \u2016X\u0303jF \u2212 cF\u20162, 1 \u2264 j \u2264 78. (4.2)\nFor F to be a good feature set, dFj should be small for j \u2208 TvG and large for j \u2208 TnvG, i.e. nvG should be far from the vG center and regarded as outliers.\nTo quantitatively measure any given F , we use the theory of the ROC curve which has been widely used in literature [31, 4, 16, 26, 9, 13]. Let us sort {dFj }78j=1 in (4.2) in an ascending order such that dFj1 \u2264 dFj2 \u2264 . . . \u2264 dFj78 . For any number \u03c1 (smaller than dFj1 , larger than d F j78 or in between dFj1 and d F j78\n), we can use it as a binary classifier to label all the paintings in X . From that we can determine the true positive rate and the false positive rate w.r.t. \u03c1 (see (6.1) for the definitions of the rates). By plotting the true positive rate versus the false positive rate for different \u03c1, we obtain the ROC curve w.r.t. F . Then we can compute the area under the ROC curve AUC(F). Notice that the larger AUC(F) is, the better F is as more vG are close to the vG center and more nvG are far from the vG center [13]. In the maximal case that AUC(F) = 1, the nvG\u2019s distances are all greater than any vG\u2019s distances and there is a suitable \u03c1 that can classify all paintings correctly.\nTherefore, the best feature subset F would be the one that maximizes AUC(F). However this is intractable due to the curse of dimensionality with an exponential blow-up of computational complexity. Thus we adopt the following forward stagewise approach (see [15]) to maximize AUC(F). We start from the empty set F (0) = \u2205 and iterate. Suppose at the j-th iteration, we already find F (j). Then in the (j+1)-th iteration, we greedily select the next feature by\nlj+1 = arg max l 6\u2208F(j)\nAUC ( F (j) \u222a {l} ) ,\nand update F (j+1) = F (j) \u222a{lj+1}. In our numerical experiment, we stop at the fifth iteration. Thus the resulting feature set for X is G = F (5), and it has 5 features.\nNote that for a dataset of n paintings with f features (ours has f = 54 and n = 78) such a forward procedure has a computational cost of O(nj(f \u2212 j)) at the j-th iteration.\n5. Classification and Validation. In the following, we give the classification rule and how to use the classification rule to determine whether the left-out painting is genuine or fake.\n5.1. Classification rule. Given the selected features in G, we already have (see (4.1) and (4.2)) the vG center cG corresponding to G and the distance dGi of the i-th painting in X to cG , for 1 \u2264 i \u2264 78. If G is a good feature set, we expect dGi to be small for vG and large for nvG. Therefore our classifier is based on a simple threshold \u03b4, such that paintings with dGi < \u03b4 will be classified into vGs, or into nvGs if otherwise.\nTo determine \u03b4, a natural choice will be to maximize the classification accuracy (see (6.2) for the definition). To be precise, let us sort {dGi }78i=1 as dGi1 \u2264 d G i2\n\u2264 \u00b7 \u00b7 \u00b7 \u2264 dGi78 and define (e1, \u00b7 \u00b7 \u00b7 , e78) = (d G i1 , \u00b7 \u00b7 \u00b7 , dGi78 ). Let (b1, \u00b7 \u00b7 \u00b7 , b78) be the labels of the paintings in X , i.e. bj = 1 if the ij-th painting is vG and \u22121 otherwise. For any threshold inside the interval (dGij\u22121 , d G ij ), its accuracy is\n\u01ebj =\nj\u22121 \u2211\nl=1\n|{l : bl = 1}|+ 78 \u2211\nl=j\n|{l : bl = \u22121}|\n78 , j = 1, \u00b7 \u00b7 \u00b7 , 79.\nWe should therefore choose j to be the one that maximizes \u01ebj . But as such j may not be unique, we choose j\u2217 = max{argmaxj \u01ebj}, and then the classification threshold is defined to be \u03b4 = ej\u2217\u22121+ej\u2217\n2 .\n5.2. Classifying the left-out painting. With the classification threshold \u03b4 defined, now we are ready to classify the left-out painting P . Let z \u2208 R5 be the feature vector extracted from P according to the feature set G. Then we normalize z to get z\u0303, i.e. we divide each entry in z by the corresponding column standard deviation of X . Then the distance between the test painting P and the vG center cG is d = \u2016z\u0303\u2212 cG\u20162. We now classify P as vG if d < \u03b4, or as nvG if otherwise. Since we have 79 paintings in the dataset, the leave-one-out cross-validation procedure described in Sections 3\u20135 is repeated 79 times such that each painting in the dataset is tested as a left-out painting once. In particular, our method is used 79 times to authenticate each of the 79 paintings in our dataset once. The classification accuracy of the method is defined to be the percentage of correct classifications (either genuine or forgery) in these 79 tests. We will carry out these tests in Section 6.\n6. Experimental Results. This section gives the experimental results. In Subsection 6.1, we give the result for our method and compare it with those of others. Subsection 6.2 identifies the most discriminatory features obtained from our methods. In Subsection 6.3, we statistically evaluate our method and also the most discriminatory features selected by our method.\n6.1. Results comparison. True positive (TP) is defined as the number of correct detection in the vG test cases and true negative (TN) is the number of correct detection in the nvG test cases. Then the true positive rate (TPR), true negative rate\n(TNR), and the classification accuracy are defined as\nTPR = TP\nvG number , TNR =\nTN\nnvG number , (6.1)\nclassification accuracy = TP + TN\ntotal number . (6.2)\nWe have performed our method on the 79 paintings in our dataset. Recall that there are 64 vG and 15 nvG paintings. In our experiment, 60 out of the 64 van Gogh paintings are detected correctly by our method as genuine (i.e. TP = 60) and 8 out of the 15 imitations are detected correctly as forgery (i.e. TN = 8). Therefore (60+ 8)/79 = 86.08% of these paintings are classified correctly by our method. Table 6.1 gives the classification results by our method as compared with some previous methods. We emphasize that there are 3 datasets: our dataset (64 vG, 15 nvG), IP4AI1 (54 vG, 11 nvG) and IP4AI2 (65vG, 15 nvG). The numbers reported on IP4AI1 and IP4AI2 are all computed by Qi et al. [29].\nWe see from Table 6.1 that our method gives the highest true positive rate and a rather good classification rate. In the second row of Table 6.1, we list the result if no feature selection is done and all 54 features are used in our method. We see that the result is bad and it is indeed necessary to perform feature selection to exclude those features which are irrelevant or noisy and hence may obscure accurate classification. In the third row of Table 6.1, we give the results when the 2-level geometric tight frame is used instead of 1-level. We see that the classification accuracy is also bad, indicating features with bigger neighborhood are not good in discriminating van Gogh\u2019s paintings. Note that, in the 2-level case, we have 105 features to begin with instead of 54.\nIn Figures 6.1 and 6.2, we give the misclassified paintings together with their ID numbers. In particular, there are 3 forgeries (f253a, f418, and f687) which were once wrongly regarded as van Gogh\u2019s paintings and are indeed highly similar in such a stylometric analysis, see Table 2.1. They successfully cheat both experts and our method. On the other hand, van Gogh\u2019s paintings f249, f371 and f752 exhibit so many unusually diverse movements of brushstroke that they look different from van Gogh\u2019s other paintings.\nComparing the results in Table 6.1, the TPR of our method is quite high while its TNR is a bit low. In Section 6.2, we show that we can significantly improve the TNR while keeping the TPR by carefully selecting the features.\n6.2. Feature analysis. Recall that in our method for each test painting a set of five features G is selected, see Section 4. In order to identify the most discriminatory features which are useful in accurate classification, we gather the features sets G in all 79 tests and count the frequency of each feature that occurs in these 79 G\u2019s. It turns out that only 11 out of the 54 features occur in these 79 feature sets and they are listed in Table 6.2.\nFrom the table, we see that the first five features occurs with an average of 96.96% frequency (total 383 occurrences out of 5\u00d779). Thus they are the most discriminatory features. Notice that the features on standard derivation are not selected at all. Thus in hindsight, we could start our method with only 2 statistics, i.e. the mean \u00b5(i,j) and the percentage p(i,j) (see (3.3)), and end up with the same result.\nTo test the discriminatory power of the top features in Table 6.2, we use the top four and five features to do the classification under the leave-one-out cross-validation. They give the accuracies of 86.08% and 88.61% (see Table 6.3), respectively. Indeed using the top five features, we can further identify Figure 6.1 (f) and (g) to be forgery, thus improving the TNR. The accuracy of our method using only the top five features (i.e. 88.61%) is better than the best ones (87.69% for IP4AI1 and 85.0% for IP4AI2) obtained by others so far or by us (86.08%), see Table 6.1.\nThe success of this small set of five features reflects a highly consistent style in van Gogh\u2019s brushstroke movements, where many forgeries demonstrate a more diverse spread in these features. Our method also leads to an interpretable model: e.g. the first feature in Table 6.2 is related to filter \u03c43 (see (3.1)) indicating that the \u2212\u03c0/4 direction is an important direction in discriminating van Gogh\u2019s paintings.\n6.3. Method evaluation. In this section, we statistically evaluate our method and the top 5 features we selected in Section 6.2. Since we only have one dataset of 79 paintings, we generate 200 similar datasets by bootstrap sampling with replacement [12, p.12]. More precisely, each of these 200 datasets are generated by randomly choosing 64 samples from the 64 vG paintings with replacement and 15 samples from 15 nvG painting with replacement. We will compute the accuracy of our method and also the accuracy of the top 5 features on these 200 datasets. Suppose the accuracy of the i-th dataset is yi, i = 1, \u00b7 \u00b7 \u00b7 , 200. The 95% confidence interval we give below is defined to be (yi6 , yi195 ) with yi1 \u2264 \u00b7 \u00b7 \u00b7 \u2264 yi200 , see [5].\n6.3.1. Evaluation of our method. As mentioned above, there are 200 randomly chosen datasets for evaluation of our method, with each dataset having 79 samples and 54 features. For each such dataset, the accuracy of our method is again tested by using the leave-one-out cross-validation described in Sections 3\u20135, where a painting in the dataset is used as a testing data and the remaining 78 samples are the training data to select the five important features. Then a classifier is trained for authentication of the left-out painting. This procedure is repeated 79 times until each painting in the 79 samples is tested once and a classification accuracy value is\nobtained from these 79 tests. Figure 6.3 (left) is the histogram of the 200 accuracy values for these 200 datasets. The mean, median and standard deviation are 83.73%, 83.54% and 0.0507 respectively. The 95% confidence interval is (73.42%, 92.41%).\n6.3.2. Evaluation of the top five features. Here we evaluate the top five features given in Table 6.2. Similar to Section 6.3.1, for each of the 200 datasets, the accuracy is tested under the leave-one-out cross-validation, except that everything is done w.r.t the top five features only. Figure 6.3 (right) is the histogram of the 200 accuracy values. The mean, median and standard deviation are 87.77%, 88.61% and 0.0435 respectively. The 95% confidence interval is (78.48%, 94.94%). Using only the best five out of the 54 features, the classification accuracy is quite good and the results reflect the consistency of van Gogh\u2019s habitual brushstroke movements.\n7. Conclusion. We have proposed a geometric tight frame based visual stylometry method to discriminate paintings by van Gogh from those by imitators. The methodology consists of some simple statistics of the geometric tight frame coefficients, as well as a boosting procedure for feature selection. Our methodology has been tested on a data set of 79 paintings provided by the van Gogh museum and Kro\u0308ller-Muller museum. The classification accuracy of our method is 86.08%. The high classification accuracy shows that our features are appropriate in identifying the authorship of van Gogh\u2019s paintings. In particular, our method identifies five robust features such that van Gogh\u2019s paintings show a higher degree of similarity in that feature space while forgeries exhibit a wider spread tendency as outliers. The accuracy using these 5 features is 88.61% which is the best one compared with the existing methods so far (see Tables 6.1 and 6.3). The success of this small set of features reflects the consistency of van Gogh\u2019s habitual brushstroke movements. From our results, we see that the \u201cstatistical outliers\u201d of certain tight frame coefficients are not noise, but important signals to distinguish van Gogh\u2019s painting from his contemporaries. Such \u201coutliers\u201d and their tail distributions may due to the intrinsic creativity of the maestro expressed through his brushstroke styles. We hope these features may help art scholars to find new digital evidences in van Gogh\u2019s art authentication. Our methodology can easily be generalized to authenticate paintings for other artists and that will be our future research directions.\nAcknowledgement: We thank Profs. Haixiang Lin and Eric Postma for their helpful\ndiscussions and providing us with the 79 paintings used in this paper."}], "references": [{"title": "Weave interference in vacuum lining of pictures", "author": ["Gustav A. Berger"], "venue": "Studies in Conservation,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 1966}, {"title": "The skill plot: a graphical technique for evaluating continuous diagnostic", "author": ["William M. Briggs", "Russell Zaretzki"], "venue": "tests, Biometrics,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2008}, {"title": "Forensic examination of glass and paint: Analysis and interpretation", "author": ["Brian Caddy"], "venue": "CRC Press,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2002}, {"title": "Image restoration: Total variation, wavelet frames, and beyond", "author": ["Jian-Feng Cai", "Bin Dong", "Stanley Osher", "Zuowei Shen"], "venue": "Journal of the American Mathematical Society,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2012}, {"title": "Tight frame: an efficient way for high-resolution image reconstruction", "author": ["Raymond H. Chan", "Sherman D. Riemenschneider", "Lixin Shen", "Zuowei Shen"], "venue": "Applied and Computational Harmonic Analysis,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2004}, {"title": "The relationship between Precision-Recall and ROC curves", "author": ["Jesse Davis", "Mark Goadrich"], "venue": "Proceedings of the 23rd International Conference on Machine Learning,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2006}, {"title": "A note on the use of an improved infrared vidicon for reflectography of paintings", "author": ["J.R.J. Van Asperen De Boer"], "venue": "Studies in Conservation,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 1974}, {"title": "MRA based wavelet frames and applications, IAS Lecture Notes Series, Summer Program on \u201cThe Mathematics of Image Processing", "author": ["Bin Dong", "Zuowei Shen"], "venue": "Park City Mathematics Institute,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2010}, {"title": "An introduction to the bootstrap (monographs on statistics and applied probability)", "author": ["Bradley Efron", "Robert J. Tibshirani"], "venue": null, "citeRegEx": "12", "shortCiteRegEx": "12", "year": 1994}, {"title": "ROC graphs: Notes and practical considerations for researchers", "author": ["Tom Fawcett"], "venue": "Machine Learning,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2004}, {"title": "Evaluating the predictiveness of a continuous marker, Biometrics", "author": ["Ying Huang", "Margaret Sullivan Pepe", "Ziding Feng"], "venue": null, "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2007}, {"title": "Empirical mode decomposition analysis for visual stylometry", "author": ["James M. Hughes", "Dong Mao", "Daniel N. Rockmore", "Yang Wang", "Qiang Wu"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2012}, {"title": "Image processing for artist identification", "author": ["C. Richard Johnson", "Jr.", "Ella Hendriks", "Igor J. Berezhnoy", "Eugene Brevdo", "Shannon M. Hughes", "Ingrid Daubechies", "Jia Li", "Eric Postma", "James Z. Wang"], "venue": "Signal Processing Magazine, IEEE,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2008}, {"title": "Studying digital imagery of ancient paintings by mixtures of stochastic models", "author": ["Jia Li", "James Z. Wang"], "venue": "IEEE Transactions on Image Processing,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2004}, {"title": "Rhythmic brushstrokes distinguish van Gogh from his contemporaries: findings via automated brushstroke extraction", "author": ["Jia Li", "Lei Yao", "Ella Hendriks", "James Z Wang"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2012}, {"title": "Multiframe super-resolution reconstruction using sparse directional regularization", "author": ["Yan-Ran Li", "Dao-Qing Dai", "Lixin Shen"], "venue": "IEEE Transactions on Circuits and Systems for Video Technology,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2010}, {"title": "Framelet algorithms for deblurring images corrupted by impulse plus Gaussian noise", "author": ["Yan-Ran Li", "Lixin Shen", "Dao-Qing Dai", "Bruce W. Suter"], "venue": "IEEE Transactions on Image Processing,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2011}, {"title": "Apparatus and methods for authentication using partially fluorescent graphic images and OCR characters, Apr", "author": ["Louis H Liang"], "venue": null, "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2002}, {"title": "A digital technique for art authentication", "author": ["Siwei Lyu", "Daniel Rockmore", "Hany Farid"], "venue": "Proceedings of the National Academy of Sciences of the United States of America,", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2004}, {"title": "A new approach for analyzing physiological time series", "author": ["Dong Mao", "Yang Wang", "Qiang Wu"], "venue": null, "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2010}, {"title": "Quantifying and comparing the predictive accuracy of continuous prognostic factors for binary outcomes, Biostatistics", "author": ["Chaya S. Moskowitz", "Margaret S. Pepe"], "venue": null, "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2004}, {"title": "Applications of x rays in art authentication: radiography, x-ray diffraction, and x-ray fluorescence, in Photonics West\u201998 Electronic Imaging, International Society for Optics and Photonics", "author": ["Richard Newman"], "venue": null, "citeRegEx": "27", "shortCiteRegEx": "27", "year": 1998}, {"title": "Pacewicz, Wincenty Lutos  lawski (1863\u20131954): Philosophe, hell\u00e9niste ou fondateur sous-estim\u00e9 de la stylom\u00e9trie", "author": ["Adam Paw  lowski", "Artur"], "venue": "Historiographia Linguistica,", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 2004}, {"title": "Visual stylometry using background selection and wavelet-HMT-based Fisher information distances for attribution and dating of impressionist paintings", "author": ["Hanchao Qi", "Armeen Taeb", "Shannon M. Hughes"], "venue": "Signal Processing,", "citeRegEx": "29", "shortCiteRegEx": "29", "year": 2013}, {"title": "Fractal analysis of Pollock\u2019s drip", "author": ["Richard P. Taylor", "Adam P. Micolich", "David Jonas"], "venue": "paintings, Nature,", "citeRegEx": "30", "shortCiteRegEx": "30", "year": 1999}, {"title": "Receiver-operating characteristic (ROC) plots: a fundamental evaluation tool in clinical medicine", "author": ["Mark H. Zweig", "Gregory Campbell"], "venue": "Clinical Chemistry,", "citeRegEx": "31", "shortCiteRegEx": "31", "year": 1993}], "referenceMentions": [{"referenceID": 17, "context": "Physical means such as ultraviolet fluorescence [23], infrared reflectography [10], x-ray radiography [27], painting sampling [6], and canvas weave count [3] have also been used for art authentication.", "startOffset": 48, "endOffset": 52}, {"referenceID": 6, "context": "Physical means such as ultraviolet fluorescence [23], infrared reflectography [10], x-ray radiography [27], painting sampling [6], and canvas weave count [3] have also been used for art authentication.", "startOffset": 78, "endOffset": 82}, {"referenceID": 21, "context": "Physical means such as ultraviolet fluorescence [23], infrared reflectography [10], x-ray radiography [27], painting sampling [6], and canvas weave count [3] have also been used for art authentication.", "startOffset": 102, "endOffset": 106}, {"referenceID": 2, "context": "Physical means such as ultraviolet fluorescence [23], infrared reflectography [10], x-ray radiography [27], painting sampling [6], and canvas weave count [3] have also been used for art authentication.", "startOffset": 126, "endOffset": 129}, {"referenceID": 0, "context": "Physical means such as ultraviolet fluorescence [23], infrared reflectography [10], x-ray radiography [27], painting sampling [6], and canvas weave count [3] have also been used for art authentication.", "startOffset": 154, "endOffset": 157}, {"referenceID": 22, "context": "The term stylometry refers to the application of statistical or quantitative techniques for authorship and style evolution in literary arts [28].", "startOffset": 140, "endOffset": 144}, {"referenceID": 24, "context": "By using high-resolution digital images of artists\u2019 collections, image analysis researchers and art historians have engaged in cross-disciplinary stylometric analysis of art paintings via computational techniques [30, 24, 19, 1, 2, 17, 18, 20, 29].", "startOffset": 213, "endOffset": 247}, {"referenceID": 18, "context": "By using high-resolution digital images of artists\u2019 collections, image analysis researchers and art historians have engaged in cross-disciplinary stylometric analysis of art paintings via computational techniques [30, 24, 19, 1, 2, 17, 18, 20, 29].", "startOffset": 213, "endOffset": 247}, {"referenceID": 13, "context": "By using high-resolution digital images of artists\u2019 collections, image analysis researchers and art historians have engaged in cross-disciplinary stylometric analysis of art paintings via computational techniques [30, 24, 19, 1, 2, 17, 18, 20, 29].", "startOffset": 213, "endOffset": 247}, {"referenceID": 11, "context": "By using high-resolution digital images of artists\u2019 collections, image analysis researchers and art historians have engaged in cross-disciplinary stylometric analysis of art paintings via computational techniques [30, 24, 19, 1, 2, 17, 18, 20, 29].", "startOffset": 213, "endOffset": 247}, {"referenceID": 12, "context": "By using high-resolution digital images of artists\u2019 collections, image analysis researchers and art historians have engaged in cross-disciplinary stylometric analysis of art paintings via computational techniques [30, 24, 19, 1, 2, 17, 18, 20, 29].", "startOffset": 213, "endOffset": 247}, {"referenceID": 14, "context": "By using high-resolution digital images of artists\u2019 collections, image analysis researchers and art historians have engaged in cross-disciplinary stylometric analysis of art paintings via computational techniques [30, 24, 19, 1, 2, 17, 18, 20, 29].", "startOffset": 213, "endOffset": 247}, {"referenceID": 23, "context": "By using high-resolution digital images of artists\u2019 collections, image analysis researchers and art historians have engaged in cross-disciplinary stylometric analysis of art paintings via computational techniques [30, 24, 19, 1, 2, 17, 18, 20, 29].", "startOffset": 213, "endOffset": 247}, {"referenceID": 23, "context": "Our results on 79 paintings provided by van Gogh Museum and Kr\u00f6ller-Muller Museum show that our method is better than existing van Gogh paintings authentication methods [29, 18, 24].", "startOffset": 169, "endOffset": 181}, {"referenceID": 12, "context": "Our results on 79 paintings provided by van Gogh Museum and Kr\u00f6ller-Muller Museum show that our method is better than existing van Gogh paintings authentication methods [29, 18, 24].", "startOffset": 169, "endOffset": 181}, {"referenceID": 18, "context": "Our results on 79 paintings provided by van Gogh Museum and Kr\u00f6ller-Muller Museum show that our method is better than existing van Gogh paintings authentication methods [29, 18, 24].", "startOffset": 169, "endOffset": 181}, {"referenceID": 24, "context": "in 1999 on fractal analysis of Pollock\u2019s drip paintings [30].", "startOffset": 56, "endOffset": 60}, {"referenceID": 18, "context": "[24], the moment statistics of wavelet coefficients and the log error in a linear predictor are used as features to authenticate the drawings by Pieter Bruegel the Elder.", "startOffset": 0, "endOffset": 4}, {"referenceID": 13, "context": "In the same year, Li and Wang [19] put 2D multi-resolution Hidden Markov Model (HMM) in use to classify paintings from some China\u2019s famous artists in different dynasty periods.", "startOffset": 30, "endOffset": 34}, {"referenceID": 11, "context": "[17] for stylometric analysis of drawings by Pieter Bruegel the Elder and Rembrandt van Rijn.", "startOffset": 0, "endOffset": 4}, {"referenceID": 12, "context": "In 2008, three research groups from Penn State, Princeton, and Maastricht focusing on authenticating van Gogh paintings reported their analysis of van Gogh\u2019s brushstrokes in [18].", "startOffset": 174, "endOffset": 178}, {"referenceID": 14, "context": "[20] made an effort to extract those visually salient brushstrokes of van Gogh based on an integrative technique of both edge detection and clusteringbased segmentation.", "startOffset": 0, "endOffset": 4}, {"referenceID": 23, "context": "[29] use background selection and waveletHMT-based Fisher information distance for authorship and dating of impressionist and post-impressionist paintings.", "startOffset": 0, "endOffset": 4}, {"referenceID": 12, "context": "As in [18], we first start by analyzing the brushstrokes in the paintings by some analysis operators.", "startOffset": 6, "endOffset": 10}, {"referenceID": 18, "context": "Instead of using the variety of techniques such as wavelets, EMD, HMM and HMT in [24, 17, 18, 29], here we propose to use a special tight frame, called geometric tight frame [22], to extract brushstroke information from the given paintings.", "startOffset": 81, "endOffset": 97}, {"referenceID": 11, "context": "Instead of using the variety of techniques such as wavelets, EMD, HMM and HMT in [24, 17, 18, 29], here we propose to use a special tight frame, called geometric tight frame [22], to extract brushstroke information from the given paintings.", "startOffset": 81, "endOffset": 97}, {"referenceID": 12, "context": "Instead of using the variety of techniques such as wavelets, EMD, HMM and HMT in [24, 17, 18, 29], here we propose to use a special tight frame, called geometric tight frame [22], to extract brushstroke information from the given paintings.", "startOffset": 81, "endOffset": 97}, {"referenceID": 23, "context": "Instead of using the variety of techniques such as wavelets, EMD, HMM and HMT in [24, 17, 18, 29], here we propose to use a special tight frame, called geometric tight frame [22], to extract brushstroke information from the given paintings.", "startOffset": 81, "endOffset": 97}, {"referenceID": 16, "context": "Instead of using the variety of techniques such as wavelets, EMD, HMM and HMT in [24, 17, 18, 29], here we propose to use a special tight frame, called geometric tight frame [22], to extract brushstroke information from the given paintings.", "startOffset": 174, "endOffset": 178}, {"referenceID": 3, "context": "Tight-frame transforms are redundant bases that can provide overcomplete but stable coding of directional variations [7].", "startOffset": 117, "endOffset": 120}, {"referenceID": 18, "context": "Next to find our features, we follow the moment statistics approach explored in [24, 17] and propose to use 3 simple statistics of the geometric tight frame coefficients as our features.", "startOffset": 80, "endOffset": 88}, {"referenceID": 11, "context": "Next to find our features, we follow the moment statistics approach explored in [24, 17] and propose to use 3 simple statistics of the geometric tight frame coefficients as our features.", "startOffset": 80, "endOffset": 88}, {"referenceID": 9, "context": "Then we select the discriminatory features by a forward stage-wise boosting procedure [13, 15].", "startOffset": 86, "endOffset": 94}, {"referenceID": 9, "context": "It selects features by maximizing the area under the Receiver Operating Characteristic (ROC) [13] curve such that van Gogh\u2019s paintings are highly concentrated while the forgeries are widely spread.", "startOffset": 93, "endOffset": 97}, {"referenceID": 23, "context": "61% classification accuracy which is highest so far reported in the literature [29, 18, 24].", "startOffset": 79, "endOffset": 91}, {"referenceID": 12, "context": "61% classification accuracy which is highest so far reported in the literature [29, 18, 24].", "startOffset": 79, "endOffset": 91}, {"referenceID": 18, "context": "61% classification accuracy which is highest so far reported in the literature [29, 18, 24].", "startOffset": 79, "endOffset": 91}, {"referenceID": 8, "context": "Evaluation of the five features is also performed on two hundred 79-painting datasets generated by bootstrap sampling with replacement [12].", "startOffset": 135, "endOffset": 139}, {"referenceID": 12, "context": "Our dataset consists of 79 digitalized impressionist and post impressionist paintings provided to us by the Maastricht group [18].", "startOffset": 125, "endOffset": 129}, {"referenceID": 23, "context": "[29], the edges of the canvas in the paintings may not be useful information for art authentication, and hence we have excluded these edges in our numerical experiments.", "startOffset": 0, "endOffset": 4}, {"referenceID": 9, "context": "Then a forward stage-wise boosting procedure [13, 15] is used to construct a small set of features such that in such feature space those vG\u2019s are highly concentrated in a cluster while the nvG\u2019s are mostly spread away from such a cluster.", "startOffset": 45, "endOffset": 53}, {"referenceID": 7, "context": "Tight frames have been used successfully in different applications in image processing [11, 8, 7].", "startOffset": 87, "endOffset": 97}, {"referenceID": 4, "context": "Tight frames have been used successfully in different applications in image processing [11, 8, 7].", "startOffset": 87, "endOffset": 97}, {"referenceID": 3, "context": "Tight frames have been used successfully in different applications in image processing [11, 8, 7].", "startOffset": 87, "endOffset": 97}, {"referenceID": 15, "context": "The geometric tight frame we use to analyze the brushstrokes in our paintings is proposed in [21, 22] and it can capture the firstand second-order differences in the horizontal, vertical and diagonal directions in every small neighborhood of the paintings.", "startOffset": 93, "endOffset": 101}, {"referenceID": 16, "context": "The geometric tight frame we use to analyze the brushstrokes in our paintings is proposed in [21, 22] and it can capture the firstand second-order differences in the horizontal, vertical and diagonal directions in every small neighborhood of the paintings.", "startOffset": 93, "endOffset": 101}, {"referenceID": 18, "context": "As discovered in [24, 17, 29], statistical properties of quantities such as wavelet coefficients, EMD coefficients or HMT-parameters are useful in authenticating paintings by various artists.", "startOffset": 17, "endOffset": 29}, {"referenceID": 11, "context": "As discovered in [24, 17, 29], statistical properties of quantities such as wavelet coefficients, EMD coefficients or HMT-parameters are useful in authenticating paintings by various artists.", "startOffset": 17, "endOffset": 29}, {"referenceID": 23, "context": "As discovered in [24, 17, 29], statistical properties of quantities such as wavelet coefficients, EMD coefficients or HMT-parameters are useful in authenticating paintings by various artists.", "startOffset": 17, "endOffset": 29}, {"referenceID": 15, "context": "see [21, 22].", "startOffset": 4, "endOffset": 12}, {"referenceID": 16, "context": "see [21, 22].", "startOffset": 4, "endOffset": 12}, {"referenceID": 18, "context": "Moment statistics has been used successfully to extract features in art authentication, see [24, 17, 25].", "startOffset": 92, "endOffset": 104}, {"referenceID": 11, "context": "Moment statistics has been used successfully to extract features in art authentication, see [24, 17, 25].", "startOffset": 92, "endOffset": 104}, {"referenceID": 19, "context": "Moment statistics has been used successfully to extract features in art authentication, see [24, 17, 25].", "startOffset": 92, "endOffset": 104}, {"referenceID": 11, "context": "In [17], the moment statistics of the \u201coutlier pixels\u201d, defined as those that are greater than the mean plus one standard deviation, are also considered as features.", "startOffset": 3, "endOffset": 7}, {"referenceID": 25, "context": "To quantitatively measure any given F , we use the theory of the ROC curve which has been widely used in literature [31, 4, 16, 26, 9, 13].", "startOffset": 116, "endOffset": 138}, {"referenceID": 1, "context": "To quantitatively measure any given F , we use the theory of the ROC curve which has been widely used in literature [31, 4, 16, 26, 9, 13].", "startOffset": 116, "endOffset": 138}, {"referenceID": 10, "context": "To quantitatively measure any given F , we use the theory of the ROC curve which has been widely used in literature [31, 4, 16, 26, 9, 13].", "startOffset": 116, "endOffset": 138}, {"referenceID": 20, "context": "To quantitatively measure any given F , we use the theory of the ROC curve which has been widely used in literature [31, 4, 16, 26, 9, 13].", "startOffset": 116, "endOffset": 138}, {"referenceID": 5, "context": "To quantitatively measure any given F , we use the theory of the ROC curve which has been widely used in literature [31, 4, 16, 26, 9, 13].", "startOffset": 116, "endOffset": 138}, {"referenceID": 9, "context": "To quantitatively measure any given F , we use the theory of the ROC curve which has been widely used in literature [31, 4, 16, 26, 9, 13].", "startOffset": 116, "endOffset": 138}, {"referenceID": 9, "context": "Notice that the larger AUC(F) is, the better F is as more vG are close to the vG center and more nvG are far from the vG center [13].", "startOffset": 128, "endOffset": 132}, {"referenceID": 23, "context": "[29].", "startOffset": 0, "endOffset": 4}], "year": 2015, "abstractText": "This paper is about authenticating genuine van Gogh paintings from forgeries. The authentication process depends on two key steps: feature extraction and outlier detection. In this paper, a geometric tight frame and some simple statistics of the tight frame coefficients are used to extract features from the paintings. Then a forward stage-wise rank boosting is used to select a small set of features for more accurate classification so that van Gogh paintings are highly concentrated towards some center point while forgeries are spread out as outliers. Numerical results show that our method can achieve 86.08% classification accuracy under the leave-one-out cross-validation procedure. Our method also identifies five features that are much more predominant than other features. Using just these five features for classification, our method can give 88.61% classification accuracy which is the highest so far reported in literature. Evaluation of the five features is also performed on two hundred datasets generated by bootstrap sampling with replacement. The median and the mean are 88.61% and 87.77% respectively. Our results show that a small set of statistics of the tight frame coefficients along certain orientations can serve as discriminative features for van Gogh paintings. It is more important to look at the tail distributions of such directional coefficients than mean values and standard deviations. It reflects a highly consistent style in van Gogh\u2019s brushstroke movements, where many forgeries demonstrate a more diverse spread in these features.", "creator": "LaTeX with hyperref package"}}}