{"id": "1408.0055", "review": {"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "1-Aug-2014", "title": "Thurstonian Boltzmann Machines: Learning from Multiple Inequalities", "abstract": "We introduce Thurstonian Boltzmann Machines (TBM), a unified architecture that can naturally incorporate a wide range of data inputs at the same time. Our motivation rests in the Thurstonian view that many discrete data types can be considered as being generated from a subset of underlying latent continuous variables, and in the observation that each realisation of a discrete type imposes certain inequalities on those variables. Thus learning and inference in TBM reduce to making sense of a set of inequalities on all of the underlying latent variables. In general, for instance, while TBM is quite efficient, it is also difficult to explain in detail the properties of the tBM. For instance, we are interested in the following principle: that the data type that we want to learn is the real TBM. In TBM, we are interested in the following principle: that the data type that we want to learn is the real TBM. In TBM, we are interested in the following principle: that the data type that we want to learn is the real TBM. In TBM, we are interested in the following principle: that the data type that we want to learn is the real TBM. In TBM, we are interested in the following principle: that the data type that we want to learn is the real TBM. In TBM, we are interested in the following principle: that the data type that we want to learn is the real TBM. In TBM, we are interested in the following principle: that the data type that we want to learn is the real TBM. In TBM, we are interested in the following principle: that the data type that we want to learn is the real TBM. In TBM, we are interested in the following principle: that the data type that we want to learn is the real TBM. In TBM, we are interested in the following principle: that the data type that we want to learn is the real TBM. In TBM, we are interested in the following principle: that the data type that we want to learn is the real TBM. In TBM, we are interested in the following principle: that the data type that we want to learn is the real TBM. In TBM, we are interested in the following principle: that the data type that we want to learn is the real TBM. In TBM, we are interested in the following principle: that the data type that we want to learn is the real TBM. In TBM,", "histories": [["v1", "Fri, 1 Aug 2014 00:32:32 GMT  (903kb,D)", "http://arxiv.org/abs/1408.0055v1", "Proceedings of the 30 th International Conference on Machine Learning, Atlanta, Georgia, USA, 2013. JMLR: W&amp;CP volume 28"]], "COMMENTS": "Proceedings of the 30 th International Conference on Machine Learning, Atlanta, Georgia, USA, 2013. JMLR: W&amp;CP volume 28", "reviews": [], "SUBJECTS": "stat.ML cs.LG stat.ME", "authors": ["truyen tran 0001", "dinh q phung", "svetha venkatesh"], "accepted": true, "id": "1408.0055"}, "pdf": {"name": "1408.0055.pdf", "metadata": {"source": "META", "title": "Thurstonian Boltzmann Machines: Learning from Multiple Inequalities", "authors": ["Truyen Tran", "Dinh Phung", "Svetha Venkatesh"], "emails": ["truyen.tran@deakin.edu.au", "dinh.phung@deakin.edu.au", "svetha.venkatesh@deakin.edu.au"], "sections": [{"heading": "1 Introduction", "text": "Restricted Boltzmann machines (RBMs) have proved to be a versatile tool for a wide variety of machine learning tasks and as a building block for deep architectures [12, 24, 28]. The original proposals mainly handle binary visible and hidden units. Whilst binary hidden units are broadly applicable as feature detectors, non-binary visible data requires different designs. Recent extensions to other data types result in type-dependent models: the Gaussian for continuous inputs [12], Beta for bounded continuous inputs [16], Poisson for count data [9], multinomial for unordered categories [25], and ordinal models for ordered categories [37, 35].\nThe Boltzmann distribution permits several types to be jointly modelled, thus making the RBM a good tool for multimodal and complex social survey analysis. The work of [20, 29, 40] combines continuous (e.g., visual and audio) and discrete modalities (e.g., words). The work of [34] extends the idea further to incorporate ordinal and rank data. However, there are conceptual drawbacks: First, conditioned on the hidden layer, they are still separate type-specific models; second, handling ordered categories and ranks is not natural; and third, specifying direct correlation between these types remains difficult.\nThe main thesis of this paper is that many data types can be captured in one unified model. The key observations are that (i) type-specific properties can be modelled using\nar X\niv :1\n40 8.\n00 55\nv1 [\nst at\n.M L\n] 1\nA ug\none or several underlying continuous variables, in the spirit of Thurstonian models1 [31], and (ii) evidences be expressed in the form of one or several inequalities of these underlying variables. For example, a binary visible unit is turned on if the underlying variable is beyond a threshold; and a category is chosen if its utility is the largest among all those of competing categories. The use of underlying variables is desirable when we want to explicitly model the generative mechanism of the data. In psychology and economics, for example, it gives much better interpretation on why a particular choice is made given the perceived utilities [2]. Further, it is natural to model the correlation among type-specific inputs using a covariance structure on the underlying variables.\nThe inequality observation is interesting in its own right: Instead of learning from assigned values, we learn from the inequality expression of evidences, which can be much more relaxed than the value assignments. This class of evidences indeed covers a wide range of practical situations, many of which have not been studied in the context of Boltzmann machines, as we shall see throughout the paper.\nTo this end, we propose a novel class of models called Thurstonian Boltzmann Machine (TBM). The TBM utilises the Gaussian restricted Boltzmann machine (GRBM): The top layer consists of binary hidden units as in standard RBMs; the bottom layer contains a collection of Gaussian variable groups, one per input type. The main difference is that TBM does not require valued assignments for the bottom layer but a set of inequalities expressing the constraints imposed by the evidences. Except for a limiting case of point assignments where the inequalities are strictly equalities, the Gaussian layer is never fully observed. The TBM supports more data types in a unified manner than ever before: For any combination of the point assignments, intervals, censored values, binary, unordered categories, multi-categories, ordered categories, (in)-complete ranks with and without ties, all we need to do is to supply relevant subset of inequalities.\nWe evaluate the proposed model on three applications of very different natures: handwritten digit recognitions, collaborative filtering and complex survey analysis. For the first two applications, the performance is competitive against methods designed for those data types. On the last application, we believe we are among the first to propose a scalable and generic machinery for handle those complex data types."}, {"heading": "2 Gaussian RBM", "text": "Let x = (x1, x2, ..., xN ) > \u2208 RN be a vector of input variables. Let h = (h1, h2, ..., hK)> \u2208 {0, 1}K be a set of hidden factors which are designed to capture the variations in the observations. The input layer and the hidden layer form an undirected bipartite graph, i.e., only cross-layer connections are allowed. The model admits the Boltzmann distribution\nP (x,h) = 1\nZ exp {\u2212E(x,h)} (1) where Z = \u2211\nh\n\u00b4 exp {\u2212E(x,h)} dx is the normalising constant and E(x,h) is the state\nenergy. The energy is decomposed as\nE(x,h) = \u2211 i ( x2i 2 \u2212 (\u03b1i +Wi\u2022h)xi ) \u2212 \u03b3>h (2)\n1Whilst Thurstonian models often refer to human\u2019s judgment of discrete choices, we use the term \u201cThurstonian\u201d more freely without the notion of human\u2019s decision.\nwhere{\u03b1i}Ni=1 ,W = {Wik},\u03b3 = {\u03b3k} are free parameters and Wi\u2022 denotes the i-th row. Given the input x, the posterior has a simple form\nP (h | x) = \u220f k P (hk | x) (3)\nP (hk = 1 | x) = 1\n1 + e\u2212\u03b3k\u2212W \u2032 \u2022kx\nwhere W\u2022k denotes the k-th column. Similarly, the generative process given the binary factor h is also factorisable\nP (x | h) = \u220f i P (xi | h) (4)\nP (xi | h) = N (\u03b1i +Wi\u2022h, 1)\nwhere N (\u00b5, 1) is the normal distribution of mean \u00b5 and unit deviation."}, {"heading": "3 Thurstonian Boltzmann Machines", "text": "We now generalise the Gaussian RBM into the Thurstonian Boltzmann Machine (TBM). Denote by e an observed evidence of x. Standard evidences are the point assignment of x to some specific real-valued vector, i.e., x = e. Generalised evidences can be expressed using inequality constraints\nb \u2264 Ax \u2264 c (5)\nfor some transform matrix A \u2208 RM\u00d7N and vectors b, c \u2208 RM , where \u2264 denotes elementwise inequalities. Thus an evidence can be completely realised by specifying the triple \u3008A, b, c\u3009. For example, for the point assignment, \u3008A = I, b = e, c = e\u3009, where I is the identity matrix. In what follows, we will detail other useful popular realisations of these quantities."}, {"heading": "3.1 Boxed Constraints", "text": "This refers to the case where input variables are independently constrained, i.e., A = I, and thus we need only to specify the pair \u3008b, c\u3009.\nCensored observations. This refers to situation where we only know the continuous observation beyond a certain point, i.e., b = e and c = +\u221e. For example, in survival analysis, the life expectancy of a person might be observed up to a certain age, and we have no further information afterward.\nInterval observations. When the measurements are imprecise, it may be better to specify the range of possible observations with greater confidence rather than a singe point, i.e., b = e \u2212 \u03b4 and c = e + \u03b4 for some pair (e, \u03b4). For instance, missile tracking may estimate the position of the target with certain precision.\nBinary observations. A binary observation ei can be thought as a result of clipping xi by a threshold \u03b8i, that is ei = 1 if xi \u2265 \u03b8i and ei = 0 otherwise. The boundaries in Eq. (3.2) become:\n\u3008bi, ci\u3009 = { \u3008\u2212\u221e, \u03b8i\u3009 ei = 0 \u3008\u03b8i,+\u221e\u3009 ei = 1\n(6)\nThus, this model offers an alternative2 to standard binary RBMs of [28, 8].\nOrdinal observations. Denote by e = (e1, e2, ..., eN ) the set of ordinal observations, where each ei is drawn from an ordered set {1, 2, .., L}. The common assumption is that the ordinal level ei = l is observed given xi \u2208 [\u03b8l\u22121, \u03b8l] for some thresholds \u03b81 \u2264 \u03b82 \u2264 ...\u03b8L\u22121. The boundaries thus read\n\u3008bi, ci\u3009 =  \u3008\u2212\u221e, \u03b81\u3009 l = 1 \u3008\u03b8l\u22121, \u03b8l\u3009 l = 2, 3, ..L\u2212 1 \u3008\u03b8L\u22121,+\u221e\u3009 otherwise\n(7)\nThis offers an alternative3 to the ordinal RBMs of [37]."}, {"heading": "3.2 Inequality Constraints", "text": "Categorical observations. This refers to the situation where out of an unordered set of categories, we observe only one category at a time. This can be formulated as follows. Each category is associated with a \u201cutility\u201d variable. The category l is observed (i.e., ei = m) if it has the largest utility, that is xil \u2265 maxm 6=l xim. Thus, xil is the upperthreshold for all other utilities. On the other hand, maxm 6=l xim is the lower-threshold for xil. This suggests an EM-style procedure: (i) fix xil (or treat it as a threshold) and learn the model under the intervals xim \u2264 xil for all m 6= l, and (ii) fix all categories other than l, learn the model under the interval xil \u2265 maxm6=l xim. This offers an alternative4 to the multinomial logit treatment in [26].\nTo illustrate the point, suppose there are only four variables z1, z2, z3, z4, and z1 is observed, then we have z1 \u2265 max {z2, z3, z4}. This can be expressed as z1 \u2212 z2 \u2265 0; z1 \u2212 z3 \u2265 0 and z1 \u2212 z4 \u2265 0. These are equivalent to\u2329\nA =  1 \u22121 0 01 0 \u22121 0 1 0 0 \u22121  ; b = 0; c = +\u221e\u232a\nImprecise categorical observations. This generalises the categorical case: The observation is a subset of a set, where any member of the subset can be a possible observation5. For example, when asked to choose the best sport team of interest, a person\n2To be consistent with the statistical literature, we can call it the probit RBM, which we will study in Section 6.1.\n3This can be called ordered probit RBM. 4We can call this model multinomial probit RBM. 5This is different from saying that all the members of the subset must be observed.\nmay pick two teams without saying which is the best. For instance, suppose the subset is {z1, z2}, then min {z1, z2} \u2265 max{z3, z4}, which can be expressed as z1 \u2212 z3 \u2265 0; z2 \u2212 z3 \u2265 0, z1 \u2212 z4 \u2265 0 and z2 \u2212 z4 \u2265 0. This translates to the following triple\n\u2329 A =  1 0 \u22121 0 1 0 0 \u22121 0 1 \u22121 0 0 1 0 \u22121  ; b = 0; c = +\u221e \u232a\nRank (with Ties) observations. This generalises the imprecise categorical cases: Here we have a (partially) ranked set of categories. Assume that the rank is produced in a stagewise manner as follows: The best category subset is selected out of all categories, the second best is selected out of all categories except for the best one, and so on. Thus, at each stage we have an imprecise categorical setting, but now the utilities of middle categories are constrained from both sides \u2013 the previous utilities as the upper-bound, and the next utilities as the lower-bound.\nAs an illustration, suppose there are four variables z1, z2, z3, z4 and a particular rank (with ties) imposes that min {z1, z2} \u2265 z3 \u2265 z4. This be rewritten as z1 \u2265 z3; z2 \u2265 z3; z3 \u2265 z4, which is equivalent to\u2329\nA =  1 0 \u22121 00 1 \u22121 0 0 0 1 \u22121  ; b = 0; c = +\u221e\u232a"}, {"heading": "4 Inference Under Linear Constraints", "text": "Under the TBM, MCMC-based inference without evidences is simple: we alternate between P (h | x) and P (x | h). This is efficient because of the factorisations in Eqs. (3,4). Inference with inequality-based evidence e is, however, much more involved except for the limiting case of point assignments.\nDenote by \u2126(e) = { x | b \u2264 Ax \u2264 c } the constrained domain of x defined by the evidence e. Now we need to specify and sample from the constrained distribution P (x,h | e) defined on \u2126(e). Sampling P (h | x) remains unchanged, and in what follows we focus on sampling from P (x | h, e)."}, {"heading": "4.1 Inference under Boxed Constraints", "text": "For boxed constraints (Section 3.1), due to the conditional independence, we still enjoy the factorisation P (x | h, e) = \u220f i P (xi | h, e). We further have\nP (xi | h, e) = P (xi | h)\n\u03a6(ci | h)\u2212 \u03a6(bi | h)\nwhere \u03a6(\u00b7 | h) is the normal cumulative distribution function of P (xi | h). Now P (xi | h, e) is a truncated normal distribution, from which we can sample using the simple rejection method, or more advanced methods such as those in [23]."}, {"heading": "4.2 Inference under Inequality Constraints", "text": "For general inequality constraints (Section 3.2), the input variables are interdependent due to the linear transform A. However, we can specify the conditional distribution P (xi | x\u00aci,h, e) (here x\u00aci = x\\xi) by realising that\nbm \u2212 \u2211 j 6=i Amjxj \u2264 Amixi \u2264 cm \u2212 \u2211 j 6=i Amjxj\nwhere Ami 6= 0 for m = 1, 2, ...,M . In other words, xi is conditionally box-constrained given other variables.\nThis suggests a Gibbs procedure by looping through x1, x2, ..., xN . With some abuse of notation, let b\u0303mi = ( bm \u2212 \u2211 j 6=iAmjxj ) /Ami and c\u0303mi = ( cm \u2212 \u2211 j 6=iAmjxj ) /Ami. The constraints can be summarised as\nxi \u2208 \u2229Mm=1 [ min { b\u0303mi, c\u0303mi } ,max { b\u0303mi, c\u0303mi }] = [ max m min { b\u0303mi, c\u0303mi } ,min m max { b\u0303mi, c\u0303mi\n}] The min and max operators are needed to handle change in inequality direction with the sign of Ami, and the join operator is due to multiple constraints.\nFor more sophisticated Gibbs procedures, we refer to the work in [10]."}, {"heading": "4.3 Estimating the Binary Posteriors", "text": "We are often interested in the posteriors P (h | e), e.g., for further processing. Unlike the standard RBMs, the binary latent variables here are coupled through the unknown Gaussians and thus there are no exact solutions unless the evidences are all point assignments. The MCMC-based techniques described above offer an approximate estimation\nby averaging the samples { h(s) }S s=1 . For the case of boxed constraints, mean-field offers an alternative approach which may be numerically faster. In particular, the mean-field updates are recursive:\nQk \u2190 1 1 + exp {\u2212\u03b3k \u2212 \u2211 iWik\u00b5\u0302i}\n\u00b5i \u2190 \u03b1i + \u2211 k WikQk \u00b5\u0302i = \u00b5i + \u03c6(bi \u2212 \u00b5i)\u2212 \u03c6(ci \u2212 \u00b5i) \u03a6(ci \u2212 \u00b5i)\u2212 \u03a6(bi \u2212 \u00b5i)\nwhere Qk is the probability of the unit k being activated, \u00b5\u0302i is the mean of the normal distribution truncated in the interval [bi, ci], \u03c6(z) is the probability density function, and \u03a6(z) is normal cumulative distribution function. Interested readers are referred to the Supplement6 for more details.\n6Supplement material will be available at: http://truyen.vietlabs.com"}, {"heading": "4.4 Estimating Probability of Evidence Generation", "text": "Given the hidden states h we want to estimate the probability that hidden states generate a particular evidence e\nP (e | h) = \u02c6 \u2126(e) P (x | h)dx\nFor boxed constraints, analytic solution is available since the Gaussian variables are decoupled, i.e., P (ei | h) = \u03a6(ci \u2212 \u00b5i) \u2212 \u03a6(bi \u2212 \u00b5i), where \u00b5i = \u03b1i + \u2211 kWikhk. For general inequality constraints, however, these variables are coupled by the inequalities. The general strategy is to sample from P (x | h) and compute the portion of samples falling into the constrained domain \u2126(e). For certain classes of inequalities we can approximate the Gaussian by appropriate distributions from which the integration has the closed form. In particular, those inequalities imposed by the categorical and rank evidences can be dealt with by using the extreme value distributions. The integration will give the logit form on distribution of categories and Plackett-Luce distribution of ranks. For details, we refer to the Supplement."}, {"heading": "5 Stochastic Gradient Learning with Persistent Markov", "text": "Chains\nLearning is based on maximising the evidence likelihood\nL = logP (e) = log \u2211 h \u02c6 \u2126(e) P (h,x)dx\nwhere P (h,x) is defined in Eq. (1). Let Z(e) = \u2211\nh \u00b4 \u2126(e)\nexp {\u2212E(x,h)} dx, then L = logZ(e)\u2212 logZ. The gradient w.r.t. the mapping parameter reads\n\u2202WikL = EP (xi,hk|e) [xihk]\u2212 EP (xi,hk) [xihk] (8)\nThe derivation is left to the Supplement."}, {"heading": "5.1 Estimating Data Statistics", "text": "The data-dependent statistics EP (xi,hk|e) [xihk] and the data-independent statistics EP (xi,hk) [xihk] are not tractable to compute in general, and thus approximations are needed.\nData-dependent statistics. Under the box constraints, the mean-field technique (Section 4.3) can be employed as follows\nEP (xi,hk|e) [xihk] \u2248 \u00b5\u0302iQk\nFor general cases, sampling methods are applicable. In particular, we maintain one persistent Markov chain [42, 32] per data instance and estimate the statistics after a very short run. This would explore the space of the data-dependent distribution P (x,h | e) by alternating between P (h | x) and P (x | h, e) using techniques described in Section 4.\nData-independent statistics. Mean-field distributions are not appropriate for exploring the entire state space because they tend to fit into one mode. One practical solution is based on the idea of Hinton\u2019s Contrastive Divergence (CD), where we create another Markov chain on-the-fly starting from the latest state of the clamped chain. This chain will be discarded after each parameter update. This is particular useful when the models are instance-specific, e.g., in collaborative filtering, it is much cheaper to build one model per user, all share the same parameters. If it is not the case, then we can maintain a moderate set of parallel chains and collect the samples after a short run at every updating step [42, 32]."}, {"heading": "5.2 Learning the Box Boundaries", "text": "In the case of boxed constraints, sometimes it is helpful to learn the boundaries \u3008bi, ci\u3009 themselves. The gradient of the log-likelihood w.r.t. the lower boundaries reads\n\u2202biL = 1\nZ(e) \u2211 h \u2202bi \u02c6 \u2126(e) exp {\u2212E(x,h)} dx\n= \u2211 h \u2202bi \u02c6 \u2126(e) P (x,h | e) dx \u2248 1 S \u2202bi \u02c6 ci bi \u02c6 \u2126(e)\\[bi,ci] P ( x | h(s), e ) dx\u00acidxi = \u2212 1 S \u2211 h P ( xi = bi | h(s), e )\nwhere { h(s) }S s=1 are samples collected during the MCMC procedure running on the datadependent distribution P (x,h | e). Similarly we would have the gradient w.r.t. the upper boundaries:\n\u2202ciL = 1\nS \u2211 h P ( x = ci | h(s), e ) ."}, {"heading": "6 Applications", "text": "In this section, we describe applications of the TBM for three realistic domains, namely handwritten digit recognition, collaborative filtering and worldwide survey analysis. Before going to the details, let us first address key implementation issues (see Supplement for more details).\nOne observed difficulty in training the TBM is that the hidden samples can get stuck in one of the two ends and thus learning cannot progress. The reasons might be the large mapping parameters or the unbounded nature of the underlying Gaussian variables, which can saturate the hidden units. We can control the norm of the mapping parameters, either by using the standard `2-norm regularisation, or by rescaling the norm of the parameter vector for each hidden unit. To deal with the non-boundedness of the Gaussian variables, then we can restrict their range, making the model bounded.\nAnother effective solution is to impose a constraint on the posteriors by adding the\nregularising term to the log-likelihood, e.g.,\n\u03bb {\u2211 k [ \u03c1 logP (h1k | e) + (1\u2212 \u03c1) log ( 1\u2212 P (h1k | e) )]}\nwhere \u03c1 \u2208 (0, 1) is the expected probability that a hidden unit will turn on given the evidence and \u03bb > 0 is the regularisation weight. Maximising this quantity is essentially minimising the Kullback-Leibler divergence between the expected posteriors and the true posteriors. In our experiments, we found \u03c1 \u2208 (0.1, 0.3) and \u03bb \u2208 (0.1, 1) gave satisfying results.\nThe main technical issue is that P (h1k | e) does not have a simple form due to the integration over all the constrained Gaussian variables. Approximation is thus needed. The use of mean-field methods will lead to the simple sigmoid form, but it is only applicable for boxed constraints since it breaks down deterministic constraints among variables (Section 4.3). However, we can estimate the \u201cmean\u201d truncated Gaussian \u00b5\u0302i by averaging the recent samples of the Gaussian variables in the data-dependent phase.\nOnce these safeguards are in place, learning can greatly benefit from quite large learning rate and small batches as it appears to quickly get the samples out off the local energy traps by significantly distorting the energy landscape. Depending on the problem sizes, we vary the batch sizes in the range [100, 1000]."}, {"heading": "6.1 Probit RBM for Handwritten Digits", "text": "We use the name Probit RBM to denote the special case of TBM where the observations are binary (i.e., boxed constraints, see Section 3.1). The threshold \u03b8i for each visible unit i is chosen so that under the zero mean, the probability of generating a binary evidence equals the empirical probability, i.e., 1\u2212\u03a6(\u03b8i) = e\u0304i, and thus \u03b8i = \u03a6\u22121(1\u2212 e\u0304i). Since any mismatch in thresholds can be corrected by shifting the corresponding biases, we do not need to update the thresholds further.\nWe report here the result of the mean-field method for computing data-dependent statistics, which are averaged over a random batch of 500 images. For the data-independent statistics, 500 persistent chains are run in parallel with samples collected after every 5 Gibbs steps. The sparsity level \u03c1 is set to 0.3 and the sparseness weight \u03bb is set to 0.5. Once the model has been learned, mean-field is used to estimate the hidden posteriors. Typically this mean-field is quite fast as it converges in a few steps.\nWe take the data from MNIST and binarize the images using a mid-intensity threshold. The learned representation is shown in Figure 2. Most digits are well separated in 2D except for digits 4 and 9. The learned representation can be used for classifications, e.g., by feeding to the multiclass logistic classifier. For 500 hidden units, the Probit RBM achieves the error rate of 3.28%, comparable with those obtained by the RBM trained with CD-1 (3.02%), and much better than the raw pixels (8.46%). The features discovered by the Probit RBM and RBM with CD-1 are very different (Figure 1), and this is expected because they operate on different input representations. The energy surface learned by the Probit RBM is smooth enough to allow efficient exploration of modes, as shown in Figure 3."}, {"heading": "6.2 Rank Evidences for Collaborative Filtering", "text": "In collaborative filtering, one of the main goals is to produce a personalized ranked list of items. Until very recently, the majority in the area, on the other hand, focused on predicting the ratings, which are then used for ranking items. It can be arguably more efficient to learn a rank model directly instead of going through the intermediate steps.\nWe build one TBM for ranking with ties (i.e., inequality constraints, see Section 3.2) per user due to the variation in item choices but all the TBMs share the same parameter set. The handling of ties is necessary because during training, many items share the same rating. Unseen items are simply not accounted for in each model: We only need to compare the utilities between the items seen by each person. The result is that the models are very sparse and fast to run. For the data-dependent statistics, we maintain one Markov chain per user. Since there is no single model for all data instances, the dataindependent statistics cannot be estimated from a small set of Markov chains. Rather we also maintain a data-independent chain per data instance, which can be persistent on their own, or restarted from the data-dependent chains after every parameter updating step. The latter case, which is reported here, is in the spirit of the Hinton\u2019s Contrastive Divergence, where the data-independent chain is just a few steps away from the datadependent chain.\nOnce the model has been trained, the hidden posterior vector h\u0302 = ( h\u03021, h\u03022, ..., h\u0302K ) ,\nwhere h\u0302k = P (hk = 1 | eu), is used as the new representation of the tastes of user u. The rank of unseen movies is the mode of the distribution P (e\u2217 | h\u0302), where e\u2217 are the rankbased evidences (see Section 4.4). For fast computation of P (e\u2217 | h\u0302), we approximate the Gaussian by a Gumbel distribution, which leads to a simple way of ranking movies using the mean \u201cutility\u201d \u00b5ui = \u03b1i +Wi\u2022h\u0302u for user u (see the Supplement for more details).\nThe data used in this experiment is the MovieLens, which contains 1M ratings by approximately 6K users on 4K movies. To encourage diversity in the rank lists, we remove the top 10% most popular movies. We then remove users with less than 30 ratings on the\nremaining movies. The most recently rated 10 movies per user are held out for testing, the next most recent 5 movies are used for tuning hyper-parameters, and the rest for training.\nFor comparison, we implement a simple baseline using item popularity for ranking, and thus offering a naive non-personalized solution. For personalized alternatives, we implement two recent rank-based matrix factorisation methods, namely ListRank.MF [27] and PMOP [36]. Two ranking metrics from the information retrieval literature are used: the ERR [3] and the NDCG@T [13]. These metrics place more emphasis on the top-ranked items. Table 1 reports the movie ranking results on test subset (each user is presented with a ranked list of unseen movies), demonstrating that the TBM is a clear winner in all metrics."}, {"heading": "6.3 Mixed Evidences for World Attitude Analysis", "text": "Finally, we demonstrate the TBM on mixed evidences. The data is from the survey analysis domain, which mostly consists of multiple questions of different natures such as basic facts (e.g., ages and genders) and opinions (e.g., binary choices, single choices, multiple choices, ordinal judgments, preferences and ranks). The standard approach to deal with such heterogeneity is to perform the so-called \u201ccoding\u201d, which converts types into some numerical representations (e.g., ordinal scales into stars, ranks into multiple pairwise comparisons) so that standard processing tools can handle. However, this coding process breaks the structure in the data and thus significant information will be lost. Thus our TBM offers a scalable and generic machinery to process the data in its native format and then convert the mixed types into a more homogeneous posterior vector.\nWe use the global attitude survey dataset collected by the PewResearch Centre7. The survey was conducted on 24, 717 people from 24 countries during the period of March 17 \u2013 April 21, 2008 on a variety of topics concerning people\u2019s life, opinions on issues in their countries and around the world as well as future expectations. There are 52 binary, 124 categorical (of variable category sizes), 3 continuous, 165 ordinal (of variable level sizes) question types.\nLike the case of collaborative filtering, we build one TBM per respondent due to the variation in questions and answers but all the TBMs share the same parameter set. Unanswered/inappropriate questions are ignored. For each respondent, we maintain 2 persistent and non-interacting Markov chains for the data-dependent statistics and the data-independent statistics, respectively.\nFigure 4 shows the 2D distribution of respondents from 24 countries obtained by feeding the posteriors to the t-SNE [38] (here no explicit information of countries is used).\n7The datasets are publicly available from http://pewresearch.org/\nIt is interesting to see the cultural/social clustering and gaps between countries as opposed to the geographical distribution (e.g., between Indonesia and Egypt, Australia and UK and the relative separation of the China, Pakistan, Turkey and the US from the rest). To predict the 24 countries, we feed the posteriors into the standard multiclass logistic regression and achieve an error rate of 0.49%, suggesting that the TBM has captured the intrastate regularities and separated the interstate variations well."}, {"heading": "7 Related Work", "text": "Latent multivariate Gaussian variables have been widely studied in statistical analysis, initially to model correlated binary data8 [1, 4] then now used for a variety of data types such as ordered categories [15], unordered categories [43], and the mixture of types [6]. Learning with the underlying Gaussian model is notoriously difficult for large-scale setting: independent sampling costs cubic time due to the need of inverting the covariance matrix, while MCMC techniques such as Gibbs sampling can be very slow if the graph is dense and the interactions between variables are strong. This can be partly overcome by adding one more layer of latent variables as in factor analysis [39, 14] and probabilistic principle component analysis [33]. The main difference from our TBM is that those models are directed with continuous factors while ours is undirected with binary factors.\nGaussian RBMs have been used for modelling continuous data such as visual features [12], where the evidences are the value assignments, and thus a limiting case of our evidence system. Some restrictions to the continuous Boltzmann machines have been studied: In [5], Gaussian variables are assumed to be non-negative, and in [41], continuous variables are bounded. However, we do not make these restrictions on the model but rather placing restrictions during the training phase only. GRBMs that handle ordinal evidences have been studied in [35], which is an instance of the boxed-constraints in our TBM."}, {"heading": "8 Discussion and Conclusion", "text": "Since the underlying variables of the TBM are Gaussian, various extensions can be made without much difficulty. For example, direct correlations among variables, regardless of their types, can be readily modelled by introducing the non-identity covariance matrix [22]. This is clearly a good choice for image modelling since nearby pixels are strongly correlated. Another situation is when the input units are associated with their own attributes. Each unit can be extended naturally by adding a linear combination of attributes to the mean structure of the Gaussian.\nThe additive nature of the mean-structure allows the natural extension to matrix modelling (e.g., see [37, 35]). That is, we do not distinguish the role of rows and columns, and thus each row and column can be modelled using their own hidden units (the row parameters and columns parameters are different). Conditioned on the row-based hidden units, we return to the standard TBM for column vectors. Inversely, conditioned on the column-based hidden units, we have the TBM for row vectors.\nTo sum up, we have proposed a generic class of models called Thurstonian Boltzmann machine (TBM) to unify many type-specific modelling problems and generalise them\n8This is often known as multivariate probit models.\nto the general problem of learning from multiple groups of inequalities. Our framework utilises the Gaussian restricted Boltzmann machines, but the Gaussian variables are never observed except for one limiting case. Rather, those variables are subject to inequality constraints whenever an evidence is observed. Under this representation, the TBM supports a very wide range of evidences, many of which were not possible before in the Boltzmann machine literature, without the need to specify type-specific models. In particular, the TBM supports any combination of the point assignments, intervals, censored values, binary, unordered categories, multi-categories, ordered categories, (in)-complete ranks with and without ties.\nWe demonstrated the TBM on three applications of very different natures, namely handwritten digit recognition, collaborative filtering and complex survey analysis. The results are satisfying and the performance is competitive with those obtained by typespecific models."}, {"heading": "A Supplementary Material", "text": "A.1 Inference"}, {"heading": "A.1.1 Estimating the Partition Function", "text": "For convenience, let us re-parameterise the distribution as follows\n\u03c6i(xi) = exp\n{ \u2212x 2 i\n2 + \u03b1ixi\n} (9)\n\u03c8ik(xi, hk) = exp {Wikxihk} \u03c6k(hk) = exp {\u03b3khk}\nThe model potential is then the product of all local potentials\n\u03a8(x,h) = [\u220f i \u03c6i(xi) ][\u220f ik \u03c8ik(xi, hk) ][\u220f k \u03c6k(hk) ] (10)\nThe partition function can be rewritten as\nZ = \u2211 h \u02c6 x \u03a8(x,h)dx\n= \u2211 h \u2126(h)\nwhere \u2126(h) = \u00b4 x \u03a8(x,h)dx. We now proceed to compute \u2126(h):\n\u2126(h) = [\u220f k \u03c6k(hk) ] \u02c6 x [\u220f i \u03c6i(xi) ][\u220f ik \u03c8ik(xi, hk) ] dx\n= [\u220f k \u03c6k(hk) ]\u220f i \u02c6 xi exp { \u2212x 2 i 2 + (\u03b1i + \u2211 k Wikhk)xi } dxi\n= [\u220f k \u03c6k(hk) ]\u220f i Ci \u02c6 xi exp { \u2212 (xi \u2212 \u00b5i(h)) 2 2 } dxi\n= [\u220f k \u03c6k(hk) ]\u220f i Ci \u221a 2\u03c0\u03c32i\nwhere\n\u00b5i(h) = \u03b1id + K\u2211 k=1 Wikhk\nCi = exp\n{ 1\n2\n( \u00b5i(h)\n\u03c3i\n)2}\nNow we can define the distribution over the hidden layer as follows\nP (h) = 1\nZ \u2126(h)\nNow we apply the Annealed Importance Sampling (AIS) [19]. The idea is to introduces the notion of inverse-temperature \u03c4 into the model, i.e., P (h|\u03c4) \u221d \u2126(h)\u03c4 .\nLet {\u03c4s}Ss=0 be the (slowly) increasing sequence of temperature, where \u03c40 = 0 and \u03c4S = 1, that is \u03c40 < \u03c41... < \u03c4S . At \u03c40 = 0, we have a uniform distribution, and at \u03c4S = 1, we obtain the desired distribution. At each step s, we draw a sample h\ns from the distribution P (h|\u03c4s\u22121) (e.g. using some Metropolis-Hastings procedure). Let P \u2217(h|\u03c4) be the unnormalised distribution of P (h|\u03c4), that is P (h|\u03c4) = P \u2217(h|\u03c4)/Z(\u03c4). The final weight after the annealing process is computed as\n\u03c9 = P \u2217(h1|\u03c41) P \u2217(h1|\u03c40) P \u2217(h2|\u03c42) P \u2217(h2|\u03c41) ... P \u2217(hS |\u03c4S) P \u2217(hS |\u03c4S\u22121)\nThe above procedure is repeated T times. Finally, the normalisation constant at \u03c4 = 1 is computed as Z(1) \u2248 Z(0) (\u2211T\nt=1 \u03c9 (t)/T\n) where Z(0) = 2K , which is the number of\nconfigurations of the hidden variables h."}, {"heading": "A.1.2 Estimating Posteriors using Mean-field", "text": "Recall that for evidence e we want to estimate posteriors P (h | e) = \u2211\nx\u2208\u2126(e) P\u2126(e)(h,x | e). Assume that the evidences can be expressed in term of boxed constraints, which lead\nto the following factorisation P (x | e,h) = \u220f i P (xi | e,h)\nThis factorisation is critical because it ensures that there are no deterministic constraints among {xi}ni=1, which are the conditions that variational methods such as mean-fields would work well. This is because mean-field solution will generally not satisfy deterministic constraints, and thus may assign non-zeros probability to improbably areas.\nTo be more concrete, the mean-field approximation would be Q(h,x) \u2248 P (h,x | e)\nQ(h,x) = \u220f k Qk(hk) \u220f i Qi(xi)\ns.t. x \u2208 \u2126(e)\nThe best mean-field approximation will be the minimiser of the Kullback-Leibler divergence\nD (Q||P ) = \u2211 h \u2211 x\u2208\u2126(e) Q(h,x) log Q(h,x) P (h,x | e)\n= \u2212H [Q(h,x)]\u2212 \u2211 h \u2211 x\u2208\u2126(e) Q(h,x) logP (h,x | e) (11)\nwhereH [Q(h,x)] is the entropy function. Now first, exploit the fact thatQ is factorisable, and thus its entropy is decomposable, i.e.,\nH [Q(h,x)] = \u2211 k H [Qk(hk)] + \u2211 i H [Qi(xi)] (12)\nSecond recall from Eq. (17) that\nP (h,x | e) = 1 Z(e) exp {\u2212E(x,h)}\nand thus\u2211 h \u2211 x\u2208\u2126(e) Q(h,x) logP (h,x | e) = \u2212 \u2211 h \u2211 x\u2208\u2126(e) Q(h,x)E(x,h)\u2212 logZ(e)\nSince logZ(e) is a constraint w.r.t. Q(h,x), we can safely ignore it here. Now since E(x,h) is decomposable (see Eq. (2)), we have \u2211 h \u2211 x\u2208\u2126(e) Q(h,x)E(x,h) = \u2211 i \u2211 xi\u2208\u2126(ei) Qi(xi)Ei(xi) +(\u2211 k \u2211 hk Qk(hk)Ek(hk) ) +\n+ \u2211 i \u2211 k \u2211 xi\u2208\u2126(ei) \u2211 hk Qi(xi)Qk(hk)Eik(xi, hk) \nwhere\nEi(xi) = x2i 2 \u2212 \u03b1ixi Ek(hk) = \u2212\u03b3khk Eik(xi, hk) = \u2212Wikxihk\nCombining this decomposition and Eq. (12), we have completely decomposed the Kullback-Leibler divergence in Eq. (11) into local terms: D (Q||P ) = \u2211 i \u2211 xi\u2208\u2126(ei) Qi(xi)Ei(xi) + \u2211 k \u2211 hk Qk(hk)Ek(hk) +\n+ \u2211 i \u2211 k \u2211 xi\u2208\u2126(ei) \u2211 hk Qi(xi)Qk(hk)Eik(xi, hk) \u2212\u2211 i H [Qi(xi)]\u2212 \u2211 k H [Qk(hk)]\nNow we wish to minimise the divergence with respect to the local distributions {Qi(xi), Qk(hk)} for i = 1, 2, ..., N andk = 1, 2, ...,K knowing the proper distribution constraints\n\u02c6 xi\u2208\u2126(ei)\nQi(xi) = 1\u2211 hk Qk(hk) = 1\nBy the method of Lagrangian multiplier, we have\nL(\u03bb) = D (Q||P ) + \u2211 i \u03bbi (\u02c6 xi\u2208\u2126(ei) Qi(xi)\u2212 1 ) + \u2211 k \u03bak (\u2211 hk Qk(hk)\u2212 1 )\n\u2022 Let us compute the partial derivative w.r.t. Qi(xi):\n\u2202Qi(xi)L(\u03bb) = logQi(xi) + 1 + Ei(xi) + \u2211 k Qk(h 1 k)Eik(xi, h 1 k) + \u03bbi\nwhere h1k is a short hand for hk = 1 and we have made use of the fact that Eik(xi, hk = 0) = 0. Setting this gradient to zero yields\nQi(xi) = exp\n{ \u2212 ( Ei(xi) +\n\u2211 k Qk(h 1 k)Eik(xi, h 1 k)\n) \u2212 1\u2212 \u03bbi }\n= exp \u221212 ( xi \u2212 ( \u03b1i + \u2211 k Qk(h 1 k)Wik ))2 \u2212 1\u2212 \u03bbi  (13) for xi \u2208 \u2126(ei). Normalising this distribution would lead to the truncated form of the normal distribution those the mean is\n\u00b5i = \u03b1i + \u2211 k Qk(h 1 k)Wikhk (14)\n\u2022 In a similar way, the partial derivative w.r.t. Qk(hk) would be\n\u2202Qk(hk)L(\u03bb) = logQk(hk)\u2212 hk \u03b3k +\u2211 i Wik \u2211\nxi\u2208\u2126(ei)\nQi(xi)xi + 1 + \u03bak Equating the gradient to zero, we have\nQk(hk) \u221d exp { hk ( \u03b3k +\n\u2211 i Wik\u00b5\u0302i\n)}\nwhere \u00b5\u0302i is the mean of the truncated normal distribution \u00b5\u0302i = \u2211\nxi\u2208\u2126(ei)\nQi(xi)xi\nNormalising Qk(hk) would lead to\nQk(h 1 k) =\n[ 1 + exp { \u2212\u03b3k \u2212\n\u2211 i Wik\u00b5\u0302i\n}]\u22121 (15)\n\u2022 Finally, combining these findings in Eqs. (13,14,15), and letting \u2126(ei) = [bi, ci] be the boxed constraint, and using the fact that the mean of the truncated distribution is\n\u00b5\u0302i = \u00b5i + \u03c6(bi \u2212 \u00b5i)\u2212 \u03c6(ci \u2212 \u00b5i) \u03a6(ci \u2212 \u00b5i)\u2212 \u03a6(bi \u2212 \u00b5i)\nwe would arrive at the three recursive equations\nqk \u2190 1 1 + exp {\u2212\u03b3k \u2212 \u2211 iWik\u00b5\u0302i}\n\u00b5i \u2190 \u03b1i + \u2211 k Wikqk \u00b5\u0302i \u2190 \u00b5i + \u03c6(bi \u2212 \u00b5i)\u2212 \u03c6(ci \u2212 \u00b5i) \u03a6(ci \u2212 \u00b5i)\u2212 \u03a6(bi \u2212 \u00b5i)\nwhere qk is a short hand for Qk(h 1 k) and\u03c6(z) is the normal probability density function, and \u03a6(z) is the cumulative distribution function \u2663"}, {"heading": "A.1.3 Seeking Modes and Generating Representative Samples", "text": "Once the model has been learned, samples can be generated straightforwardly by first sampling the underlying Gaussian RBM and then collect the true samples that satisfy the inequalities of interest. For example, for binary samples, if the generated Gaussian value for a visible unit is larger than the threshold, then we have an active sample. Likewise, rank samples, we only need to rank the sampled Gaussian values.\nHowever, this may suffer from the poor mixing if we use standard Gibbs sampling, that is the Markov chain may get stuck in some energy traps. To jump out of the trap\nwe propose to periodically raise the temperature to a certain level (e.g., 10) and then slowly cool down to the original temperature (which is 1). In our experiment, the cooling is scheduled as follows\nT \u2190 \u03b7T\nwhere \u03b7 \u2208 (0, 1) is estimated so that for n steps, the temperature will drop from Tmax to Tmin. That is, Tmin = \u03b7 nTmax, leading to \u03b7 = (Tmin/Tmax) 1/n\n. To locate a basis of attraction, we can lower the temperature further (e.g., to 0.1) to trap the particles there. Then we collect k successive samples and take the average to be the representative sample. In our experiments, k = 50."}, {"heading": "A.2 Learning", "text": ""}, {"heading": "A.2.1 Gradient of the Likelihood", "text": "The log-likelihood of an evidence is\nL = logP (e) = log \u2211 h \u02c6 \u2126(e) P (h,x)dx\n= log \u2211 h \u02c6 \u2126(e) exp {\u2212E(x,h)} dx\u2212 logZ = logZ(e)\u2212 logZ\nwhere Z(e) = \u2211\nh \u00b4 \u2126(e)\nexp {\u2212E(x,h)} dx. The gradient of logZ(e) w.r.t. the mapping parameter Wik reads\n\u2202Wik logZ(e) = \u22121 Z(e) \u2211 h \u02c6 \u2126(e) exp {\u2212E(x,h)} \u2202WikE(x,h)dx\n= \u2212 \u2211 h \u02c6 \u2126(e) P (x,h | e)\u2202WikE(x,h)dx (16)\nwhere we have moved the constant Z\u22121(e) into the sum and integration and make use of the fact that\nP (x,h | e) = P (x,h) P (e) = 1 Z(e) exp {\u2212E(x,h)} (17)\nwhere the domain of the Gaussian is constrained to x \u2208 \u2126(e). From the definition of the energy function in Eq. (2), we know that the energy is decomposable, and thus the gradient w.r.t. Wik only involves the pair (xi, hk). In particular\n\u2202WikE(x,h) = \u2212xihk\nThis simplifies Eq. (16)\n\u2202Wik logZ(e) = \u2212 \u2211 hi \u02c6 \u2126(ei) P (xi, hk | e)\u2202WikE(x,h)dxi\n= EP (x,h|e) [xihk]\nA similar process would lead to\n\u2202Wik logZ = EP (xi,hk) [xihk]\nand finally:\n\u2202WikL = EP (xi,hk|e) [xihk]\u2212 EP (xi,hk) [xihk]\u2663"}, {"heading": "A.2.2 Regularising the Markov Chains", "text": "One undesirable feature of the MCMC chains used in learning we have experiences so far is the tendency for the binary hidden states to get stuck, i.e., after some point they do not flip their assignments as learning progresses. We conjecture that this phenomenon may be due to the saturation effect inherent in the factor posterior:\nP (hk = 1 | x) = 1 1 + exp (\u2212\u03b3k \u2212 \u2211 iWikxi)\ni.e., once the collected value to a node (\u03b3k + \u2211 iWikxi) is too high or too low, it is very hard to over turn. Fortunately, there is a known technique to regularise the chain: we enforce that at a time, there should be only a fraction \u03c1 of nodes which are active, where \u03c1 \u2208 (0, 1). One way is to maximise the following objective function\nL2 = L+ \u03bb \u02c6 [\u2211\nk \u2211 hk \u03c1(hk) logP (hk | x)\n] P (x | e)dx\nwhere \u03bb > 0 is the weighting factor, \u03c1(hk) = \u03c1 if hk = 1 and \u03c1(hk) = 1\u2212 \u03c1 otherwise. The gradient with respect to gk = (\u03b3k + \u2211 iWikxi) is then\n\u2202gkL2 = \u2202gkL+ \u03bb \u02c6 [ \u2202gk \u2211 hk \u03c1(hk) logP (hk | x) ] P (x|e)dx\n= \u2202gkL+ \u03bb \u02c6 [ \u03c1\u2212 P (h1k | x) ] P (x|e)dx\n\u2248 \u2202gkL+ 1 S \u03bb \u2211 s [ \u03c1\u2212 P (h1k | x(s)) ] where S is the number of samples and P (h1k | x) is a shorthand for P (hk = 1 | x). Using the chain rule, we have:\n\u2202\u03b3kL2 \u2248 \u2202\u03b3kL+ 1 S \u03bb \u2211 s [ \u03c1\u2212 P (h1k | x(s)) ] \u2202WikL2 \u2248 \u2202wikdL+ 1\nS \u03bb \u2211 s xi [ \u03c1\u2212 P (h1k | x(s)) ]"}, {"heading": "A.2.3 Online Estimation of Posteriors", "text": "For tasks such as data completion (e.g., collaborative filtering) we need the posteriors P (h | e) for the prediction phase. One way is to run the Markov chain or doing meanfield from scratch. Here we suggest a simple way to obtain an approximation directly from the training phase without any further cost. The idea is to update the estimated posterior h\u0302 at each learning step t in an exponential smoothing fashion:\nh\u0302 (t) \u2190 \u03b7h\u0302 (t\u22121) + (1\u2212 \u03b7)h\u0302 (t)\nfor some smoothing factor \u03b7 \u2208 (0, 1) and initial h\u0302 (0) , where h\u0304 (t) k = P (h 1 k | x(t), e) and x(t) is the sampled Gaussian at time t. As learning progresses, early samples, which are from incorrect models, will be exponentially weighted down. Typically we choose \u03b7 close to 1, e.g., \u03b7 = 0.9."}, {"heading": "A.2.4 Monitoring the Learning Progress", "text": "It is often of practical importance to track the learning progress, either by the reconstruction errors or by the data likelihood. The data likelihood can be estimated as\nP (e) \u2248 1 S S\u2211 s=1 \u02c6 \u2126(e) P (x | h(s))dx\nwhere h(s) are those samples collected as learning progressed in the data-independent phase, and the integration can be carried out using the technique described in the main text."}, {"heading": "A.3 Extreme Value Distributions", "text": "Extreme value distributions are a class of distributions of extremal measurements [11]. Here we are concerned about the popular Gumbel\u2019s distribution."}, {"heading": "A.3.1 Gumbel Distribution for Categorical Choices", "text": "Let us start from the Gumbel density function\nP (x) = 1\n\u03c3 exp { \u2212 ( x\u2212 \u00b5 \u03c3 + e\u2212 x\u2212\u00b5 \u03c3 )} where \u00b5 is the mode (location) and \u03c3 is the scale parameter.\nUsing Laplace\u2019s approximation (e.g., via Taylor\u2019s expansion of ( x\u2212\u00b5 \u03c3 + e \u2212 x\u2212\u00b5\u03c3 ) using\nthe second-order polynomial around \u00b5), we have\nP (x) \u221d 1 e\u03c3 exp\n{ \u2212 (x\u2212 \u00b5) 2\n2\u03c32 } Renormalising this distribution, e.g., by replacing e \u2248 2.7183 by \u221a 2\u03c0 \u2248 2.5066 we obtain the standard Gaussian distribution. Thus, we can use the Gumbel as an approximation to the Gaussian distribution.\nNow we turn to the categorical model using Gumbel variables. We maintain one variable per category, which plays the role of the utility for the category. Assume that all utilities share the same scale parameter \u03c3. The existing literature [18] asserts that the probability of choosing the m-th category is\nP (e = cm) = e\u00b5m/\u03c3\u2211 l e \u00b5l/\u03c3\nwhere \u00b5l is the location of the l-th utility. When we choose a the m-th category we must ensure that xm > maxl 6=m xl. Let yl = exp ( \u2212xl\u2212\u00b5l\u03c3 ) or equivalently xl = \u00b5l \u2212 \u03c3 log yl. Thus xl < xm means\n\u00b5l \u2212 \u03c3 log yl < \u00b5m \u2212 \u03c3 log ym, or yl > ym exp ( \u00b5l\u2212\u00b5m \u03c3 ) .\nThe CDF of the l-th Gumbel distribution is Fl(xm) = exp ( \u2212e\u2212 xm\u2212\u00b5l \u03c3 ) = exp ( \u2212e\u2212 xm\u2212\u00b5m \u03c3 e \u00b5l\u2212\u00b5m \u03c3\n) = exp ( \u2212yme \u00b5l\u2212\u00b5m \u03c3\n) Thus choosing category cm would mean\nP (e = cm) = \u02c6 P (xm) \u220f l 6=m \u02c6 xm P (xl)dxl  dxm = \u02c6 P (xm)\n\u220f l 6=m Fl(xm)dxm\nWe rewrite the Gumbel density function by changing variable from xm to ym:\nP (ym) = 1\n\u03c3 ym exp {\u2212ym}\nfor ym \u2265 0. Thus\nP (xm) \u220f l 6=m Fl(xm) = 1 \u03c3 ym exp \u2212ym 1 + \u2211 l 6=m e \u00b5l\u2212\u00b5m \u03c3  \nNow, by changing variable under the integration from xm to ym, we have\nP (e = cm) = \u03c3 \u02c6 \u221e 0 P (ym) \u220f l 6=m Fl(ym) 1 yl dym\n= \u02c6 \u221e 0 exp \u2212ym 1 + \u2211\nl 6=m\ne \u00b5l\u2212\u00b5m \u03c3   dym\n= 1 1 + \u2211 l 6=m e \u00b5l\u2212\u00b5m \u03c3 = e\u00b5m/\u03c3\u2211 l e \u00b5l/\u03c3"}, {"heading": "A.3.2 Gumbel Distribution for Rank", "text": "We now extend the case of categorical evidences rank evidences. Again we maintain one Gaussian variable per category. Without loss of generality, for a particular rank \u03c0 we assume that we must ensure that x1 > x2 > ... > xD. This is equivalent to[\nx1 > max l>1 xl\n] \u2229 [ x2 > max\nl>2 xl\n] \u2229 ... \u2229 [xD\u22121 > xD]\nThe probability of this is essentially P ( {em = m}Dm=1 ) = P (e1 = 1) \u220f m>2 P ( el = m | {ed = l}m\u22121l=1 ) In words, this offers a stagewise process to rank categories: first we pick the best category, the pick the second best from the remaining categories and so on (see also [7]). The probability of picking the best category out of a subset is already given in Appendix A.3.1:\nP (e1 = 1) = e\u00b51/\u03c3\u2211 l\u22651 e \u00b5l/\u03c3\nP ( el = m | {ed = l}m\u22121l=1 ) =\ne\u00b5m/\u03c3\u2211 l\u2265m e \u00b5l/\u03c3\nThis gives us the Plackett-Luce model [17, 21] as mentioned in [30]."}, {"heading": "A.4 Global Attitude: Sample Questions", "text": "\u2022 Q4 (Ordinal): [...] how would you describe the current economic situation in (survey country) \u2013 {very good, somewhat good, somewhat bad, or very bad}?\n\u2022 Q11a (Binary): How do you think people in other countries of the world feel about China? \u2013 {like, disliked}?\n\u2022 Q35,35a (Category-ranking): Which one of the following, if any, is hurting the world\u2019s environment the most/second-most {India, Germany, China, Brazil, Japan, United States, Russia, Other}?\n\u2022 Q76 (Continuous): How old were you at your last birthday?\n\u2022 Q85 (Categorical): What is your current employment situation {A list of employment categories}?"}, {"heading": "A.5 Other Supporting Materials", "text": ""}, {"heading": "A.5.1 Laplace Approximation", "text": "Laplace approximation is the technique using a Gaussian distribution to approximate another distribution. For the univariate case, assume that the original density distribution has the form\nP (x) \u221d exp {\u2212f(x)}\nFirst we find the mode \u00b5 of P (x) or equivalently the minimiser of f(x) given it exists. Then we apply Taylor\u2019s expansion\nf(x) \u2248 f(\u00b5) + f \u2032\u2032(\u00b5) (x\u2212 \u00b5) 2\n2\nThe Gaussian approximation has the form\nP \u2217(x) \u221d exp { \u2212f \u2032\u2032(\u00b5) (x\u2212 \u00b5) 2\n2\n}\nwhere 1/f \u2032\u2032(\u00b5) is the new variance."}, {"heading": "A.5.2 Some Properties of the Truncated Normal Distribution", "text": "For a normal distribution P (x|\u00b5, \u03c3) of mean \u00b5 and standard deviation \u03c3 truncated from both sides, i.e., \u03b1 < x < \u03b2, the new density reads\nP\u0304[\u03b1,\u03b2](x |, \u00b5, \u03c3) = Q(x\u2217)\n\u03c3 [\u03a6(\u03b2\u2217)\u2212 \u03a6(\u03b1\u2217)] where\nx\u2217 = x\u2212 \u00b5 \u03c3 ; \u03b1\u2217 = \u03b1\u2212 \u00b5 \u03c3 ; \u03b2\u2217 = \u03b2 \u2212 \u00b5 \u03c3\nand Q(\u00b7) and \u03a6(\u00b7) are the probability density function and the cumulative distribution of the standard normal distribution, respectively. In particular, we are interested in the mean of the distribution P\u0304[\u03b1,\u03b2]:\n\u00b5\u0304 = \u00b5i + \u03c3 Q(\u03b1\u2217)\u2212Q(\u03b2\u2217) \u03a6(\u03b2\u2217)\u2212 \u03a6(\u03b1\u2217)\nSome special cases:\n\u2022 When \u03b1 = \u03b2, this distribution reduces to the Dirac\u2019s delta.\n\u2022 When \u03b1 = \u2212\u221e, we have a one-sided truncation from above since \u03a6(\u03b1\u2217) = 0.\n\u2022 When \u03b2 = +\u221e, we obtain a one-sided truncation form below since \u03a6(\u03b2\u2217) = 0."}], "references": [{"title": "Multi-variate probit analysis", "author": ["JR Ashford", "RR Sowden"], "venue": "Biometrics, pages 535\u2013 546,", "citeRegEx": "1", "shortCiteRegEx": null, "year": 1970}, {"title": "Thurstonian-based analyses: past, present, and future utilities", "author": ["U. B\u00f6ckenholt"], "venue": "Psychometrika, 71(4):615\u2013629,", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2006}, {"title": "Expected reciprocal rank for graded relevance", "author": ["O. Chapelle", "D. Metlzer", "Y. Zhang", "P. Grinspan"], "venue": "CIKM, pages 621\u2013630. ACM,", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2009}, {"title": "Analysis of multivariate probit models", "author": ["S. Chib", "E. Greenberg"], "venue": "Biometrika, 85(2):347\u2013361,", "citeRegEx": "4", "shortCiteRegEx": null, "year": 1998}, {"title": "The nonnegative Boltzmann machine", "author": ["O.B. Downs", "D.J.C. MacKay", "D.D. Lee"], "venue": "Advances in Neural Information Processing Systems, 12:428\u2013434,", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2000}, {"title": "Bayesian latent variable models for mixed discrete outcomes", "author": ["D.B. Dunson", "A.H. Herring"], "venue": "Biostatistics, 6(1):11,", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2005}, {"title": "Multistage ranking models", "author": ["M.A. Fligner", "J.S. Verducci"], "venue": "Journal of the American Statistical Association, 83(403):892\u2013901,", "citeRegEx": "7", "shortCiteRegEx": null, "year": 1988}, {"title": "Unsupervised learning of distributions on binary vectors using two layer networks", "author": ["Y. Freund", "D. Haussler"], "venue": "Advances in Neural Information Processing Systems, pages 912\u2013919,", "citeRegEx": "8", "shortCiteRegEx": null, "year": 1993}, {"title": "The rate adapting Poisson model for information retrieval and object recognition", "author": ["P.V. Gehler", "A.D. Holub", "M. Welling"], "venue": "Proceedings of the ICML, pages 337\u2013344,", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2006}, {"title": "Efficient simulation from the multivariate normal and student-t distributions subject to linear constraints and the evaluation of constraint probabilities", "author": ["J. Geweke"], "venue": "Computing science and statistics: Proceedings of the 23rd symposium on the interface, pages 571\u2013578,", "citeRegEx": "10", "shortCiteRegEx": null, "year": 1991}, {"title": "Statistical of extremes", "author": ["EJ Gumbel"], "venue": "Columbia University Press, New York,", "citeRegEx": "11", "shortCiteRegEx": null, "year": 1958}, {"title": "Reducing the dimensionality of data with neural networks", "author": ["G.E. Hinton", "R.R. Salakhutdinov"], "venue": "Science, 313(5786):504\u2013507,", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2006}, {"title": "Cumulated gain-based evaluation of IR techniques", "author": ["K. J\u00e4rvelin", "J. Kek\u00e4l\u00e4inen"], "venue": "ACM Transactions on Information Systems (TOIS), 20(4):446,", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2002}, {"title": "Variational bounds for mixed-data factor analysis", "author": ["E. Khan", "B. Marlin", "K. Murphy"], "venue": "Proc. of Neural Information Processing Systems,", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2010}, {"title": "Nonparametric Bayesian modeling for multivariate ordinal data", "author": ["A. Kottas", "P. M\u00fcller", "F. Quintana"], "venue": "Journal of Computational and Graphical Statistics, 14(3):610\u2013 625,", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2005}, {"title": "Learning a generative model of images by factoring appearance and shape", "author": ["N. Le Roux", "N. Heess", "J. Shotton", "J. Winn"], "venue": "Neural Computation, 23(3):593\u2013650,", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2011}, {"title": "Individual choice behavior", "author": ["R.D. Luce"], "venue": "Wiley New York,", "citeRegEx": "17", "shortCiteRegEx": null, "year": 1959}, {"title": "Conditional logit analysis of qualitative choice behavior", "author": ["D. McFadden"], "venue": "Frontiers in Econometrics, pages 105\u2013142,", "citeRegEx": "18", "shortCiteRegEx": null, "year": 1973}, {"title": "Annealed importance sampling", "author": ["R.M. Neal"], "venue": "Statistics and Computing, 11(2):125\u2013139,", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2001}, {"title": "Multimodal deep learning", "author": ["J. Ngiam", "A. Khosla", "M. Kim", "J. Nam", "H. Lee", "A.Y. Ng"], "venue": "ICML,", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2011}, {"title": "The analysis of permutations", "author": ["R.L. Plackett"], "venue": "Applied Statistics, pages 193\u2013202,", "citeRegEx": "21", "shortCiteRegEx": null, "year": 1975}, {"title": "Modeling pixel means and covariances using factorized third-order Boltzmann machines", "author": ["M.A. Ranzato", "G.E. Hinton"], "venue": "CVPR, pages 2551\u20132558. IEEE,", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2010}, {"title": "Simulation of truncated normal variables", "author": ["C.P. Robert"], "venue": "Statistics and computing, 5(2):121\u2013125,", "citeRegEx": "23", "shortCiteRegEx": null, "year": 1995}, {"title": "Deep Boltzmann Machines", "author": ["R. Salakhutdinov", "G. Hinton"], "venue": "Proceedings of 20th AISTATS, volume 5, pages 448\u2013455,", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2009}, {"title": "Replicated softmax: an undirected topic model", "author": ["R. Salakhutdinov", "G. Hinton"], "venue": "Advances in Neural Information Processing Systems, 22,", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2009}, {"title": "Restricted Boltzmann machines for collaborative filtering", "author": ["R. Salakhutdinov", "A. Mnih", "G. Hinton"], "venue": "Proceedings of the 24th ICML, pages 791\u2013798,", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2007}, {"title": "List-wise learning to rank with matrix factorization for collaborative filtering", "author": ["Y. Shi", "M. Larson", "A. Hanjalic"], "venue": "ACM RecSys, pages 269\u2013272. ACM,", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2010}, {"title": "Information processing in dynamical systems: Foundations of harmony theory", "author": ["P. Smolensky"], "venue": "Parallel distributed processing: Explorations in the microstructure of cognition, 1:194\u2013281,", "citeRegEx": "28", "shortCiteRegEx": null, "year": 1986}, {"title": "Multimodal learning with deep Boltzmann machines", "author": ["N. Srivastava", "R. Salakhutdinov"], "venue": "NIPS, pages 2231\u20132239,", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2012}, {"title": "Models for distributions on permutations", "author": ["H. Stern"], "venue": "Journal of the American Statistical Association, 85(410):558\u2013564,", "citeRegEx": "30", "shortCiteRegEx": null, "year": 1990}, {"title": "A law of comparative judgment", "author": ["L.L. Thurstone"], "venue": "Psychological review, 34(4):273,", "citeRegEx": "31", "shortCiteRegEx": null, "year": 1927}, {"title": "Training restricted Boltzmann machines using approximations to the likelihood gradient", "author": ["T. Tieleman"], "venue": "Proceedings of the 25th ICML, pages 1064\u20131071,", "citeRegEx": "32", "shortCiteRegEx": null, "year": 2008}, {"title": "Probabilistic principal component analysis", "author": ["M.E. Tipping", "C.M. Bishop"], "venue": "Journal of the Royal Statistical Society: Series B, 61(3):611\u2013622,", "citeRegEx": "33", "shortCiteRegEx": null, "year": 1999}, {"title": "Mixed-variate restricted Boltzmann machines", "author": ["T. Tran", "D.Q. Phung", "S. Venkatesh"], "venue": "Proc. of 3rd Asian Conference on Machine Learning (ACML), Taoyuan, Taiwan,", "citeRegEx": "34", "shortCiteRegEx": null, "year": 2011}, {"title": "Cumulative restricted Boltzmann machines for ordinal matrix data analysis", "author": ["T. Tran", "D.Q. Phung", "S. Venkatesh"], "venue": "Proc. of 4th Asian Conference on Machine Learning (ACML), Singapore,", "citeRegEx": "35", "shortCiteRegEx": null, "year": 2012}, {"title": "Probabilistic models over ordered partitions with applications in document ranking and collaborative filtering", "author": ["T. Truyen", "D.Q Phung", "S. Venkatesh"], "venue": "Proc. of SIAM Conference on Data Mining (SDM), Mesa, Arizona, USA,", "citeRegEx": "36", "shortCiteRegEx": null, "year": 2011}, {"title": "Ordinal Boltzmann machines for collaborative filtering", "author": ["T.T. Truyen", "D.Q. Phung", "S. Venkatesh"], "venue": "Twenty-Fifth Conference on Uncertainty in Artificial Intelligence (UAI), Montreal, Canada, June", "citeRegEx": "37", "shortCiteRegEx": null, "year": 2009}, {"title": "Visualizing data using t-SNE", "author": ["L. van der Maaten", "G. Hinton"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "38", "shortCiteRegEx": "38", "year": 2008}, {"title": "Factor analysis with (mixed) observed and latent variables in the exponential family", "author": ["M. Wedel", "W.A. Kamakura"], "venue": "Psychometrika, 66(4):515\u2013530,", "citeRegEx": "39", "shortCiteRegEx": null, "year": 2001}, {"title": "Mining associated text and images with dual-wing harmoniums", "author": ["E. Xing", "R. Yan", "A.G. Hauptmann"], "venue": "Proceedings of the 21st UAI,", "citeRegEx": "40", "shortCiteRegEx": null, "year": 2005}, {"title": "Boltzmann machines with bounded continuous random variables", "author": ["M. Yasuda", "K. Tanaka"], "venue": "Interdisciplinary Information Sciences, 13(1):25\u201331,", "citeRegEx": "41", "shortCiteRegEx": null, "year": 2007}, {"title": "Parametric inference for imperfectly observed Gibbsian fields", "author": ["L. Younes"], "venue": "Probability Theory and Related Fields, 82(4):625\u2013645,", "citeRegEx": "42", "shortCiteRegEx": null, "year": 1989}, {"title": "Bayesian analysis of multivariate nominal measures using multivariate multinomial probit models", "author": ["X. Zhang", "W.J. Boscardin", "T.R. Belin"], "venue": "Computational statistics & data analysis, 52(7):3697\u20133708,", "citeRegEx": "43", "shortCiteRegEx": null, "year": 2008}], "referenceMentions": [{"referenceID": 11, "context": "1 Introduction Restricted Boltzmann machines (RBMs) have proved to be a versatile tool for a wide variety of machine learning tasks and as a building block for deep architectures [12, 24, 28].", "startOffset": 179, "endOffset": 191}, {"referenceID": 23, "context": "1 Introduction Restricted Boltzmann machines (RBMs) have proved to be a versatile tool for a wide variety of machine learning tasks and as a building block for deep architectures [12, 24, 28].", "startOffset": 179, "endOffset": 191}, {"referenceID": 27, "context": "1 Introduction Restricted Boltzmann machines (RBMs) have proved to be a versatile tool for a wide variety of machine learning tasks and as a building block for deep architectures [12, 24, 28].", "startOffset": 179, "endOffset": 191}, {"referenceID": 11, "context": "Recent extensions to other data types result in type-dependent models: the Gaussian for continuous inputs [12], Beta for bounded continuous inputs [16], Poisson for count data [9], multinomial for unordered categories [25], and ordinal models for ordered categories [37, 35].", "startOffset": 106, "endOffset": 110}, {"referenceID": 15, "context": "Recent extensions to other data types result in type-dependent models: the Gaussian for continuous inputs [12], Beta for bounded continuous inputs [16], Poisson for count data [9], multinomial for unordered categories [25], and ordinal models for ordered categories [37, 35].", "startOffset": 147, "endOffset": 151}, {"referenceID": 8, "context": "Recent extensions to other data types result in type-dependent models: the Gaussian for continuous inputs [12], Beta for bounded continuous inputs [16], Poisson for count data [9], multinomial for unordered categories [25], and ordinal models for ordered categories [37, 35].", "startOffset": 176, "endOffset": 179}, {"referenceID": 24, "context": "Recent extensions to other data types result in type-dependent models: the Gaussian for continuous inputs [12], Beta for bounded continuous inputs [16], Poisson for count data [9], multinomial for unordered categories [25], and ordinal models for ordered categories [37, 35].", "startOffset": 218, "endOffset": 222}, {"referenceID": 36, "context": "Recent extensions to other data types result in type-dependent models: the Gaussian for continuous inputs [12], Beta for bounded continuous inputs [16], Poisson for count data [9], multinomial for unordered categories [25], and ordinal models for ordered categories [37, 35].", "startOffset": 266, "endOffset": 274}, {"referenceID": 34, "context": "Recent extensions to other data types result in type-dependent models: the Gaussian for continuous inputs [12], Beta for bounded continuous inputs [16], Poisson for count data [9], multinomial for unordered categories [25], and ordinal models for ordered categories [37, 35].", "startOffset": 266, "endOffset": 274}, {"referenceID": 19, "context": "The work of [20, 29, 40] combines continuous (e.", "startOffset": 12, "endOffset": 24}, {"referenceID": 28, "context": "The work of [20, 29, 40] combines continuous (e.", "startOffset": 12, "endOffset": 24}, {"referenceID": 39, "context": "The work of [20, 29, 40] combines continuous (e.", "startOffset": 12, "endOffset": 24}, {"referenceID": 33, "context": "The work of [34] extends the idea further to incorporate ordinal and rank data.", "startOffset": 12, "endOffset": 16}, {"referenceID": 30, "context": "one or several underlying continuous variables, in the spirit of Thurstonian models [31], and (ii) evidences be expressed in the form of one or several inequalities of these underlying variables.", "startOffset": 84, "endOffset": 88}, {"referenceID": 1, "context": "In psychology and economics, for example, it gives much better interpretation on why a particular choice is made given the perceived utilities [2].", "startOffset": 143, "endOffset": 146}, {"referenceID": 27, "context": "Thus, this model offers an alternative to standard binary RBMs of [28, 8].", "startOffset": 66, "endOffset": 73}, {"referenceID": 7, "context": "Thus, this model offers an alternative to standard binary RBMs of [28, 8].", "startOffset": 66, "endOffset": 73}, {"referenceID": 36, "context": "This offers an alternative to the ordinal RBMs of [37].", "startOffset": 50, "endOffset": 54}, {"referenceID": 25, "context": "This offers an alternative to the multinomial logit treatment in [26].", "startOffset": 65, "endOffset": 69}, {"referenceID": 22, "context": "Now P (xi | h, e) is a truncated normal distribution, from which we can sample using the simple rejection method, or more advanced methods such as those in [23].", "startOffset": 156, "endOffset": 160}, {"referenceID": 9, "context": "For more sophisticated Gibbs procedures, we refer to the work in [10].", "startOffset": 65, "endOffset": 69}, {"referenceID": 41, "context": "In particular, we maintain one persistent Markov chain [42, 32] per data instance and estimate the statistics after a very short run.", "startOffset": 55, "endOffset": 63}, {"referenceID": 31, "context": "In particular, we maintain one persistent Markov chain [42, 32] per data instance and estimate the statistics after a very short run.", "startOffset": 55, "endOffset": 63}, {"referenceID": 41, "context": "If it is not the case, then we can maintain a moderate set of parallel chains and collect the samples after a short run at every updating step [42, 32].", "startOffset": 143, "endOffset": 151}, {"referenceID": 31, "context": "If it is not the case, then we can maintain a moderate set of parallel chains and collect the samples after a short run at every updating step [42, 32].", "startOffset": 143, "endOffset": 151}, {"referenceID": 26, "context": "MF [27] and PMOP [36].", "startOffset": 3, "endOffset": 7}, {"referenceID": 35, "context": "MF [27] and PMOP [36].", "startOffset": 17, "endOffset": 21}, {"referenceID": 2, "context": "Two ranking metrics from the information retrieval literature are used: the ERR [3] and the NDCG@T [13].", "startOffset": 80, "endOffset": 83}, {"referenceID": 12, "context": "Two ranking metrics from the information retrieval literature are used: the ERR [3] and the NDCG@T [13].", "startOffset": 99, "endOffset": 103}, {"referenceID": 37, "context": "Figure 4 shows the 2D distribution of respondents from 24 countries obtained by feeding the posteriors to the t-SNE [38] (here no explicit information of countries is used).", "startOffset": 116, "endOffset": 120}, {"referenceID": 0, "context": "7 Related Work Latent multivariate Gaussian variables have been widely studied in statistical analysis, initially to model correlated binary data [1, 4] then now used for a variety of data types such as ordered categories [15], unordered categories [43], and the mixture of types [6].", "startOffset": 146, "endOffset": 152}, {"referenceID": 3, "context": "7 Related Work Latent multivariate Gaussian variables have been widely studied in statistical analysis, initially to model correlated binary data [1, 4] then now used for a variety of data types such as ordered categories [15], unordered categories [43], and the mixture of types [6].", "startOffset": 146, "endOffset": 152}, {"referenceID": 14, "context": "7 Related Work Latent multivariate Gaussian variables have been widely studied in statistical analysis, initially to model correlated binary data [1, 4] then now used for a variety of data types such as ordered categories [15], unordered categories [43], and the mixture of types [6].", "startOffset": 222, "endOffset": 226}, {"referenceID": 42, "context": "7 Related Work Latent multivariate Gaussian variables have been widely studied in statistical analysis, initially to model correlated binary data [1, 4] then now used for a variety of data types such as ordered categories [15], unordered categories [43], and the mixture of types [6].", "startOffset": 249, "endOffset": 253}, {"referenceID": 5, "context": "7 Related Work Latent multivariate Gaussian variables have been widely studied in statistical analysis, initially to model correlated binary data [1, 4] then now used for a variety of data types such as ordered categories [15], unordered categories [43], and the mixture of types [6].", "startOffset": 280, "endOffset": 283}, {"referenceID": 38, "context": "This can be partly overcome by adding one more layer of latent variables as in factor analysis [39, 14] and probabilistic principle component analysis [33].", "startOffset": 95, "endOffset": 103}, {"referenceID": 13, "context": "This can be partly overcome by adding one more layer of latent variables as in factor analysis [39, 14] and probabilistic principle component analysis [33].", "startOffset": 95, "endOffset": 103}, {"referenceID": 32, "context": "This can be partly overcome by adding one more layer of latent variables as in factor analysis [39, 14] and probabilistic principle component analysis [33].", "startOffset": 151, "endOffset": 155}, {"referenceID": 11, "context": "Gaussian RBMs have been used for modelling continuous data such as visual features [12], where the evidences are the value assignments, and thus a limiting case of our evidence system.", "startOffset": 83, "endOffset": 87}, {"referenceID": 4, "context": "Some restrictions to the continuous Boltzmann machines have been studied: In [5], Gaussian variables are assumed to be non-negative, and in [41], continuous variables are bounded.", "startOffset": 77, "endOffset": 80}, {"referenceID": 40, "context": "Some restrictions to the continuous Boltzmann machines have been studied: In [5], Gaussian variables are assumed to be non-negative, and in [41], continuous variables are bounded.", "startOffset": 140, "endOffset": 144}, {"referenceID": 34, "context": "GRBMs that handle ordinal evidences have been studied in [35], which is an instance of the boxed-constraints in our TBM.", "startOffset": 57, "endOffset": 61}, {"referenceID": 21, "context": "For example, direct correlations among variables, regardless of their types, can be readily modelled by introducing the non-identity covariance matrix [22].", "startOffset": 151, "endOffset": 155}, {"referenceID": 36, "context": ", see [37, 35]).", "startOffset": 6, "endOffset": 14}, {"referenceID": 34, "context": ", see [37, 35]).", "startOffset": 6, "endOffset": 14}, {"referenceID": 18, "context": "Now we apply the Annealed Importance Sampling (AIS) [19].", "startOffset": 52, "endOffset": 56}, {"referenceID": 10, "context": "3 Extreme Value Distributions Extreme value distributions are a class of distributions of extremal measurements [11].", "startOffset": 112, "endOffset": 116}, {"referenceID": 17, "context": "The existing literature [18] asserts that the probability of choosing the m-th category is", "startOffset": 24, "endOffset": 28}, {"referenceID": 6, "context": "In words, this offers a stagewise process to rank categories: first we pick the best category, the pick the second best from the remaining categories and so on (see also [7]).", "startOffset": 170, "endOffset": 173}, {"referenceID": 16, "context": "P (e1 = 1) = e1 \u2211 l\u22651 e \u03bcl/\u03c3 P ( el = m | {ed = l} l=1 ) = em \u2211 l\u2265m e \u03bcl/\u03c3 This gives us the Plackett-Luce model [17, 21] as mentioned in [30].", "startOffset": 113, "endOffset": 121}, {"referenceID": 20, "context": "P (e1 = 1) = e1 \u2211 l\u22651 e \u03bcl/\u03c3 P ( el = m | {ed = l} l=1 ) = em \u2211 l\u2265m e \u03bcl/\u03c3 This gives us the Plackett-Luce model [17, 21] as mentioned in [30].", "startOffset": 113, "endOffset": 121}, {"referenceID": 29, "context": "P (e1 = 1) = e1 \u2211 l\u22651 e \u03bcl/\u03c3 P ( el = m | {ed = l} l=1 ) = em \u2211 l\u2265m e \u03bcl/\u03c3 This gives us the Plackett-Luce model [17, 21] as mentioned in [30].", "startOffset": 138, "endOffset": 142}], "year": 2014, "abstractText": "We introduce Thurstonian Boltzmann Machines (TBM), a unified architecture that can naturally incorporate a wide range of data inputs at the same time. Our motivation rests in the Thurstonian view that many discrete data types can be considered as being generated from a subset of underlying latent continuous variables, and in the observation that each realisation of a discrete type imposes certain inequalities on those variables. Thus learning and inference in TBM reduce to making sense of a set of inequalities. Our proposed TBM naturally supports the following types: Gaussian, intervals, censored, binary, categorical, muticategorical, ordinal, (in)-complete rank with and without ties. We demonstrate the versatility and capacity of the proposed model on three applications of very different natures; namely handwritten digit recognition, collaborative filtering and complex social survey analysis.", "creator": "LaTeX with hyperref package"}}}