{"id": "1411.1119", "review": {"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "5-Nov-2014", "title": "Projecting Markov Random Field Parameters for Fast Mixing", "abstract": "Markov chain Monte Carlo (MCMC) algorithms are simple and extremely powerful techniques to sample from almost arbitrary distributions. The flaw in practice is that it can take a large and/or unknown amount of time to converge to the stationary distribution. This paper gives sufficient conditions to guarantee that univariate Gibbs sampling on Markov Random Fields (MRFs) will be fast mixing, in a precise sense. Further, an algorithm is given to project onto this set of fast-mixing parameters in the Euclidean norm. Following recent work, we give an example use of this to project in various divergence measures, comparing univariate marginals obtained by sampling after projection to common variational methods and Gibbs sampling on the original parameters.\n\n\n\nGiven that we already know that all distributions are the same, given that all distributions were just the same, we would expect that Monte Carlo and MFC estimation to be in place within a finite time horizon. For example, we would expect that Monte Carlo and MFC estimation can be performed for linear distributions, rather than an arbitrary distribution. Therefore, we might expect that Monte Carlo and MFC estimation can be performed in the finite time horizon, or to use an additive approximation, and hence, Monte Carlo and MFC estimation can be performed in the finite time horizon. This could be done without much care from our current collaborators, however, as these estimates may be the best candidate to predict a given distribution in a time horizon.\n\nWe expect that Monte Carlo and MFC estimation can be performed in the finite time horizon in any order, as we have shown in our previous paper. This is probably not the case for the MFC estimation we are currently using, however, in some cases we can use a number of techniques to generate an exponential distribution. In the previous paper, we did not think that Monte Carlo and MFC estimation could be performed using the same method. As previously described, Monte Carlo and MFC estimation have been performed in the finite time horizon, even if one assumes that the MFC estimates are based on a number of different conditions. If you are interested in how this is accomplished, we recommend using the following technique:\nMFC estimation\nThe method, known as Gaussian distribution estimation, relies on the principle that all of the variance is the sum of the distributions, or the sum of variance, or the sum of variance, or the sum of variance. Therefore, MFC estimation, which can be made by using Gaussian distribution estimation, is the simplest method in which you can calculate", "histories": [["v1", "Wed, 5 Nov 2014 00:43:08 GMT  (1957kb,D)", "https://arxiv.org/abs/1411.1119v1", "Neural Information Processing Systems 2014"], ["v2", "Fri, 7 Nov 2014 05:38:17 GMT  (3377kb,D)", "http://arxiv.org/abs/1411.1119v2", "Neural Information Processing Systems 2014"], ["v3", "Wed, 12 Nov 2014 00:05:12 GMT  (3377kb,D)", "http://arxiv.org/abs/1411.1119v3", "Neural Information Processing Systems 2014"]], "COMMENTS": "Neural Information Processing Systems 2014", "reviews": [], "SUBJECTS": "cs.LG stat.ML", "authors": ["xianghang liu", "justin domke"], "accepted": true, "id": "1411.1119"}, "pdf": {"name": "1411.1119.pdf", "metadata": {"source": "CRF", "title": "Projecting Markov Random Field Parameters for Fast Mixing", "authors": ["Xianghang Liu", "Justin Domke"], "emails": ["xianghang.liu@nicta.com.au", "justin.domke@nicta.com.au"], "sections": [{"heading": "1 Introduction", "text": "Exact inference in Markov Random Fields (MRFs) is generally intractable, motivating approximate algorithms. There are two main classes of approximate inference algorithms: variational methods and Markov chain Monte Carlo (MCMC) algorithms [13].\nAmong variational methods, mean-field approximations [9] are based on a \u201ctractable\u201d family of distributions, such as the fully-factorized distributions. Inference finds a distribution in the tractable set to minimize the KL-divergence from the true distribution. Other methods, such as loopy belief propagation (LBP), generalized belief propagation [14] and expectation propagation [10] use a less restricted family of target distributions, but approximate the KL-divergence. Variational methods are typically fast, and often produce high-quality approximations. However, when the variational approximations are poor, estimates can be correspondingly worse.\nMCMC strategies, such as Gibbs sampling, simulate a Markov chain whose stationary distribution is the target distribution. Inference queries are then answered by the samples drawn from the Markov chain. In principle, MCMC will be arbitrarily accurate if run long enough. The principal difficulty is that the time for the Markov chain to converge to its stationary distribution, or the \u201cmixing time\u201d, can be exponential in the number of variables.\nThis paper is inspired by a recent hybrid approach for Ising models [3]. This approach minimizes the divergence from the true distribution to one in a tractable family. However, the tractable family is a \u201cfast mixing\u201d family where Gibbs sampling is guaranteed to quickly converge to the stationary distribution. They observe that an Ising model will be fast mixing if the spectral norm of a matrix containing the absolute values of all interactions strengths is controlled. An algorithm projects onto this fast mixing parameter set in the Euclidean norm, and projected gradient descent (PGD) can minimize various divergence measures. This often leads to inference results that are better than either simple variational methods or univariate Gibbs sampling (with a limited time budget). However, this approach is limited to Ising models, and scales poorly in the size of the model, due to the difficulty of projecting onto the spectral norm.\n1\nar X\niv :1\n41 1.\n11 19\nv3 [\ncs .L\nG ]\n1 2\nN ov\nThe principal contributions of this paper are, first, a set of sufficient conditions to guarantee that univariate Gibbs sampling on an MRF will be fast-mixing (Section 4), and an algorithm to project onto this set in the Euclidean norm (Section 5). A secondary contribution of this paper is considering an alternative matrix norm (the induced \u221e-norm) that is somewhat looser than the spectral norm, but more computationally efficient. Following previous work [3], these ideas are experimentally validated via a projected gradient descent algorithm to minimize other divergences, and looking at the accuracy of the resulting marginals. The ability to project onto a fast-mixing parameter set may also be of independent interest. For example, it might be used during maximum likelihood learning to ensure that the gradients estimated through sampling are more accurate."}, {"heading": "2 Notation", "text": "We consider discrete pairwise MRFs with n variables, where the i-th variable takes values in {1, ..., Li}, E is the set of edges, and \u03b8 are the potentials on each edge. Each edge in E is an ordered pair (i, j) with i \u2264 j. The parameters are a set of matrices \u03b8 := {\u03b8ij |\u03b8ij \u2208 RLi\u00d7Lj ,\u2200(i, j) \u2208 E}. When i > j, and (j, i) \u2208 E , we let \u03b8ij denote the transpose of \u03b8ji. The corresponding distribution is\np(x; \u03b8) = exp  \u2211 (i,j)\u2208E \u03b8ij(xi, xj)\u2212A(\u03b8)  , (1) where A(\u03b8) := log \u2211 x exp (\u2211 (i,j)\u2208E \u03b8 ij(xi, xj) ) is the log-partition function, and \u03b8ij(xi, xj)\ndenotes the entry in the xi-th row and xj-th column of \u03b8ij . It is easy to show that any parametrization of a pairwise MRF can be converted into this form. \u201cSelf-edges\u201d (i, i) can be included in E if one wishes to explicitly represent univariate terms.\nIt is sometimes convenient to work with the exponential family representation p(x; \u03b8) = exp{f(x) \u00b7 \u03b8 \u2212A(\u03b8)}, (2)\nwhere f(x) is the sufficient statistics for configuration x. If these are indicator functions for all configurations of all pairs in E , then the two representations are equivalent."}, {"heading": "3 Background Theory on Rapid Mixing", "text": "This section reviews background on mixing times that will be used later in the paper. Definition 1. Given two finite distributions p and q, the total variation distance \u2016 \u00b7 \u2016TV is defined as \u2016p(X)\u2212 q(X)\u2016TV = 12 \u2211 x |p(X = x)\u2212 q(X = x)|.\nNext, one must define a measure of how fast a Markov chain converges to the stationary distribution. Let the state of the Markov chain after t iterations be Xt. Given a constant , this is done by finding some number of iterations \u03c4( ) such that the induced distribution p(Xt|X0 = x) will always have a distance of less than from the stationary distribution, irrespective of the starting state x. Definition 2. Let {Xt} be the sequence of random variables corresponding to running Gibbs sampling on a distribution p. The mixing time \u03c4( ) is defined as \u03c4( ) = min{t : d(t) < }, where d(t) = maxx \u2016P(Xt|X0 = x)\u2212 p(X)\u2016TV is the maximum distance at time t when considering all possible starting states x.\nNow, we are interested in when Gibbs sampling on a distribution p can be shown to have a fast mixing time. The central property we use is the dependency of one variable on another, defined informally as how much the conditional distribution over Xi can be changed when all variables other than Xj are the same. Definition 3. Given a distribution p, the dependency matrix R is defined by\nRij = max x,x\u2032:x\u2212j=x\u2032\u2212j\n\u2016p(Xi|x\u2212i)\u2212 p(Xi|x\u2032\u2212i)\u2016TV .\nHere, the constraint x\u2212j = x\u2032\u2212j indicates that all variables in x and x \u2032 are identical except xj . The central result on rapid mixing is given by the following Theorem, due to Dyer et al. [5], generalizing the work of Hayes [7]. Informally, it states that if \u2016R\u2016 < 1 for any sub-multiplicative norm \u2016 \u00b7 \u2016, then mixing will take on the order of n lnn iterations, where n is the number of variables.\n2\nTheorem 4. [5, Lemma 17] If \u2016 \u00b7 \u2016 is any sub-multiplicative matrix norm and ||R|| < 1, the mixing time of univariate Gibbs sampling on a system with n variables with random updates is bounded by \u03c4( ) \u2264 n1\u2212\u2016R\u2016 ln ( \u20161n\u2016 \u20161Tn\u2016 ) .\nHere, \u20161n\u2016 denotes the same matrix norm applied to a matrix of ones of size n \u00d7 1, and similarly for 1Tn . In particular, if \u2016 \u00b7 \u2016 induced by a vector p-norm, then \u20161n\u2016 \u20161Tn\u2016 = n. Since this result is true for a variety of norms, it is natural to ask, for a given matrix R, which norm will give the strongest result. It can be shown that for symmetric matrices (such as the dependency matrix), the spectral norm \u2016 \u00b7 \u20162 is always superior. Theorem 5. [5, Lemma 13] If A is a symmetric matrix and \u2016 \u00b7 \u2016 is any sub-multiplicative norm, then \u2016A\u20162 \u2264 \u2016A\u2016.\nUnfortunately, as will be discussed below, the spectral norm can be more computationally expensive than other norms. As such, we will also consider the use of the \u221e-norm \u2016 \u00b7 \u2016\u221e. This leads to additional looseness in the bound in general, but is limited in some cases. In particular if R = rG whereG is the adjacency matrix for some regular graph with degree d, then for all induced p-norms, \u2016R\u2016 = rd, since \u2016R\u2016 = maxx 6=0 \u2016Rx\u2016/\u2016x| = rmaxx 6=0 \u2016Gx\u2016/\u2016x\u2016 = r\u2016Go\u2016/\u2016o\u2016 = rd, where o is a vector of ones. Thus, the extra looseness from using, say, \u2016 \u00b7 \u2016\u221e instead of \u2016 \u00b7 \u20162 will tend to be minimal when the graph is close to regular, and the dependency is close to a constant value. For irregular graphs with highly variable dependency, the looseness can be much larger."}, {"heading": "4 Dependency for Markov Random Fields", "text": "In order to establish that Gibbs sampling on a given MRF will be fast mixing, it is necessary to compute (a bound on) the dependency matrix R, as done in the following result. The proof of this result is fairly long, and so it is postponed to the Appendix. Note that it follows from several bounds on the dependency that are tighter, but less computationally convenient. Theorem 6. The dependency matrix for a pairwise Markov random field is bounded by\nRij(\u03b8) \u2264 max a,b\n1 2 \u2016\u03b8ij\u00b7a \u2212 \u03b8 ij \u00b7b\u2016\u221e.\nHere, \u03b8ij\u00b7a indicates the a\u2212th column of \u03b8ij . Note that the MRF can include univariate terms as selfedges with no impact on the dependency bound, regardless of the strength of the univariate terms. It can be seen easily that from the definition of R (Definition 3), for any i the entry Rii for self-edges (i, i) should always be zero. One can, without loss of generality, set each column of \u03b8ii to be the same, meaning that Rii = 0 in the above bound."}, {"heading": "5 Euclidean Projection Operator", "text": "The Euclidean distance between two MRFs parameterized respectively by \u03c8 and \u03b8 is \u2016\u03b8 \u2212 \u03c8\u20162 :=\u2211 (i,j)\u2208E \u2016\u03b8ij \u2212 \u03c8ij\u20162F . This section considers projecting a given vector \u03c8 onto the fast mixing set or, formally, finding a vector \u03b8 with minimum Euclidean distance to \u03c8, subject to the constraint that a norm \u2016 \u00b7 \u2016\u2217 applied to the bound on the dependency matrix R is less than some constant c. Euclidean projection is considered because, first, it is a straightforward measure of the closeness between two parameters and, second, it is the building block of the projected gradient descent for projection in other distance measures. To begin with, we do not specify the matrix norm \u2016 \u00b7 \u2016\u2217, as it could be any sub-multiplicative norm (Section 3).\nThus, in principle, we would like to find \u03b8 to solve\nprojc(\u03c8) := argmin \u03b8:\u2016R(\u03b8)\u2016\u2217\u2264c\n\u2016\u03b8 \u2212 \u03c8\u20162. (3)\nUnfortunately, while convex, this optimization turns out to be somewhat expensive to solve, due to a lack of smoothness Instead, we introduce a matrix Z, and constrain that Zij \u2265 Rij(\u03b8), where Rij(\u03b8) is the bound on dependency in Thm 6 (as an equality). We add an extra quadratic term\n3\n\u03b1\u2016Z \u2212 Y \u20162F to the objective, where Y is an arbitrarily given matrix and \u03b1 > 0 is trade-off between the smoothness and the closeness to original problem (3). The smoothed projection operator is\nprojC(\u03c8, Y ) := argmin (\u03b8,Z)\u2208C \u2016\u03b8 \u2212 \u03c8\u20162 + \u03b1\u2016Z \u2212 Y \u20162F , C = {(\u03b8, Z) : Zij \u2265 Rij(\u03b8), \u2016Z\u2016\u2217 \u2264 c}. (4)\nIf \u03b1 = 0, this yields a solution that is identical to that of Eq. 3. However, when \u03b1 = 0, the objective in Eq. 4 is not strongly convex as a function of Z, which results in a dual function which is nonsmooth, meaning it must be solved with a method like subgradient descent, with a slow convergence rate. In general, of course, the optimal point of Eq. 4 is different to that of Eq. 3. However, the main usage of the Euclidean projection operator is the projection step in the projected gradient descent algorithm for divergence minimization. In these tasks the smoothed projection operator can be directly used in the place of the non-smoothed one without changing the final result. In situations when the exact Euclidean projection is required, it can be done by initializing Y1 arbitrarily and repeating (\u03b8k+1, Yk+1)\u2190 projC(\u03c8, Yk), for k = 1, 2, . . . until convergence."}, {"heading": "5.1 Dual Representation", "text": "Theorem 7. Eq. 4 has the dual representation maximize \u03c3,\u03c6,\u2206,\u0393 g(\u03c3, \u03c6,\u2206,\u0393)\nsubject to \u03c3ij(a, b, c) \u2265 0, \u03c6ij(a, b, c) \u2265 0, \u2200(i, j) \u2208 E , a, b, c , (5)\nwhere\ng(\u03c3, \u03c6,\u2206,\u0393) = min Z h1(Z;\u03c3, \u03c6,\u2206,\u0393) + min \u03b8 h2(\u03b8;\u03c3, \u03c6)\nh1(Z;\u03c3, \u03c6,\u2206,\u0393) = \u2212tr(Z\u039bT ) + I(\u2016Z\u2016\u2217 \u2264 c) + \u03b1\u2016Z \u2212 Y \u20162F\nh2(\u03b8;\u03c3, \u03c6) = \u2016\u03b8 \u2212 \u03c8\u20162 + 1\n2 \u2211 i,j\u2208E \u2211 a,b,c ( \u03c3ij(a, b, c)\u2212 \u03c6ij(a, b, c) ) (\u03b8ijc,a \u2212 \u03b8 ij c,b),\nin which \u039bij := \u2206ijDij + \u0393\u0302ij + \u2211 a,b,c \u03c3ij(a, b, c) + \u03c6ij(a, b, c), where \u0393\u0302ij :={\n\u0393ij if (i, j) \u2208 E \u2212\u0393ij if (j, i) \u2208 E , and D is an indicator matrix with Dij = 0 if (i, j) \u2208 E or (j, i) \u2208 E , and Dij = 1 otherwise. The dual variables \u03c3ij and \u03c6ij are arrays of size Lj \u00d7Li\u00d7Li for all pairs (i, j) \u2208 E while \u2206 and \u0393 are of size n\u00d7 n.\nThe proof of this is in the Appendix. Here, I(\u00b7) is the indicator function with I(x) = 0 when x is true and I(x) =\u221e otherwise. Being a smooth optimization problem with simple bound constraints, Eq. 5 can be solved with LBFGS-B [2]. For a gradient-based method like this to be practical, it must be possible to quickly evaluate g and its gradient. This is complicated by the fact that g is defined in terms of the minimization of h1 with respect to Z and h2 with respect to \u03b8. We discuss how to solve these problems now. We first consider the minimization of h2. This is a quadratic function of \u03b8 and can be solved analytically via the condition that \u2202\u2202\u03b8h2(\u03b8;\u03c3, \u03c6) = 0. The closed form solution is\n\u03b8ijc,a = \u03c8 ij c,a \u2212\n1\n4 [\u2211 b \u03c3ij(a, b, c)\u2212 \u2211 b \u03c3ij(b, a, c)\u2212 \u2211 b \u03c6ij(a, b, c) + \u2211 b \u03c6ij(b, a, c) ] \u2200(i, j) \u2208 E , 1 \u2264 a, c \u2264 m.. The time complexity is linear in the size of \u03c8. Minimizing h1 is more involved. We assume to start that there exists an algorithm to quickly project a matrix onto the set {Z : \u2016Z\u2016\u2217 \u2264 c}, i.e. to solve the optimization problem of\nmin \u2016Z\u2016\u2217\u2264c\n\u2016Z \u2212A\u20162F . (6)\nThen, we observe that arg minZ h1 is equal to\narg min Z \u2212tr(Z\u039bT ) + I(\u2016Z\u2016\u2217 \u2264 c) + \u03b1\u2016Z \u2212 Y \u20162F = arg min\u2016Z\u2016\u2217\u2264c \u2016Z \u2212 (Y + 1 2\u03b1 \u039b)\u20162F .\n4\nFor different norms \u2016 \u00b7 \u2016\u2217, the projection algorithm will be different and can have a large impact on efficiency. We will discuss in the followings sections the choices of \u2016 \u00b7 \u2016\u2217 and an algorithm for the \u221e-norm. Finally, once h1 and h2 have been solved, the gradient of g is (by Danskin\u2019s theorem [1])\n\u2202g\n\u2202\u2206ij =\u2212DijZ\u0302ij ,\n\u2202g\n\u2202\u0393ij =Z\u0302ji \u2212 Z\u0302ij ,\n\u2202g\n\u2202\u03c3ij(a, b, c) =\n1 2 (\u03b8\u0302ijc,a \u2212 \u03b8\u0302 ij c,b)\u2212 Z\u0302ij ,\n\u2202g\n\u2202\u03c6ij(a, b, c) =\u2212 \u2202\u03c3ij(a,b,c)g,\nwhere Z\u0302 and \u03b8\u0302 represent the solutions to the subproblems."}, {"heading": "5.2 Spectral Norm", "text": "When \u2016\u00b7\u2016\u2217 is set to the spectral norm, i.e. the largest singular value of a matrix, the projection in Eq. 6 can be performed by thresholding the singular values of A [3]. Theoretically, using spectral norm will give a tighter bound on Z than other norms (Section 3). However, computing a full singular value decomposition can be impractically slow for a graph with a large number of variables."}, {"heading": "5.3 \u221e-norm", "text": "Here, we consider setting \u2016 \u00b7 \u2016\u2217 to the \u221e-norm, \u2016A\u2016\u221e = maxi \u2211 j |Aij |, which measures the maximum l1 norm of the rows of A. This norm has several computational advantages. Firstly, to project a matrix onto a \u221e-norm ball {A : \u2016A\u221e\u2016 \u2264 c}, we can simply project each row ai of the matrix onto the l1-norm ball {a : \u2016a\u20161 \u2264 c}. Duchi et al. [4] provide a method linear in the number of nonzeros in a and logarithmic in the length of a. Thus, if Z is an n \u00d7 n, matrix, Eq. 6 for the \u221e-norm can be solved in time n2 and, for sufficiently sparse matrices, in time n log n. A second advantage of the\u221e-norm is that (unlike the spectral norm) projection in Eq. 6 preserves the sparsity of the matrix. Thus, one can disregard the matrix D and dual variables \u2206 when solving the optimization in Theorem 7. This means that Z itself can be represented sparsely, i.e. we only need variables for those (i, j) \u2208 E . These simplifications significantly improve the efficiency of projection, with some tradeoff in accuracy."}, {"heading": "6 Projection in Divergences", "text": "In this section, we want to find a distribution p(x; \u03b8) in the fast mixing family closest to a target distribution p(x;\u03c8) in some divergence D(\u03c8, \u03b8). The choice of divergence depends on convenience of projection, the approximate family and the inference task. We will first present a general algorithmic framework based on projected gradient descent (Algorithm 1), and then discuss the details of several previously proposed divergences [11, 3]."}, {"heading": "6.1 General algorithm framework for divergence minimization", "text": "The problem of projection in divergences is formulated as\nmin \u03b8\u2208C\u0304 D(\u03c8, \u03b8), (7)\nD(\u00b7, \u00b7) is some divergence measure, and C\u0304 := {\u03b8 : \u2203Z, s.t.(\u03b8, Z) \u2208 C}, where C is the feasible set in Eq. 4. Our general strategy for this is to use projected gradient descent to solve the optimization\nmin (\u03b8,Z)\u2208C D(\u03c8, \u03b8), (8)\nusing the joint operator to project onto C described in Section 5. For different divergences, the only difference in projection algorithm is the evaluation of the gradient \u2207\u03b8D(\u03c8, \u03b8). It is clear that if (\u03b8\u2217, Z\u2217) is the solution of Eq. 8, then \u03b8\u2217 is the solution of 7.\n6.2 Divergences\n5\nAlgorithm 1 Projected gradient descent for divergence projection Initialize (\u03b81, Z1), k \u2190 1. repeat \u03b8\u2032 \u2190 \u03b8k \u2212 \u03bb\u2207\u03b8D(\u03c8, \u03b8k) (\u03b8k+1, Zk+1)\u2190 projC(\u03b8\u2032, Zk) k \u2190 k + 1\nuntil convergence\nIn this section, we will discuss the different choices of divergences and corresponding projection algorithms."}, {"heading": "6.2.1 KL-divergence", "text": "The KL-divergence KL(\u03c8\u2016\u03b8) :=\u2211 x p(x;\u03c8) log p(x;\u03c8) p(x;\u03b8) is arguably the optimal divergence for marginal inference because it strives to preserve the marginals of p(x; \u03b8) and p(x;\u03c8). However, projection in KL-divergence is intractable here because the evaluation of the gradient \u2207\u03b8KL(\u03c8\u2016\u03b8) requires the marginals of distribution \u03c8."}, {"heading": "6.2.2 Piecewise KL-divergence", "text": "One tractable surrogate of KL(\u03c8\u2016\u03b8) is the piecewise KL-divergence [3] defined over some tractable subgraphs. Here, D(\u03c8, \u03b8) := maxT\u2208T KL(\u03c8T \u2016\u03b8T ), where T is a set of low-treewidth subgraphs. The gradient can be evaluated as \u2207\u03b8D(\u03c8, \u03b8) = \u2207\u03b8KL(\u03c8T\u2217\u2016\u03b8T\u2217) where T \u2217 = arg maxT\u2208T KL(\u03c8T \u2016\u03b8T ). For any T in T , KL(\u03c8T \u2016\u03b8T ) and its gradient can be evaluated by the junction-tree algorithm."}, {"heading": "6.2.3 Reversed KL-divergence", "text": "The \u201creversed\u201d KL-divergence KL(\u03b8\u2016\u03c8) is minimized by mean-field methods. In general KL(\u03b8\u2016\u03c8) is inferior to KL(\u03c8\u2016\u03b8) for marginal inference since it tends to underestimate the support of the distribution [11]. Still, it often works well in practice. \u2207\u03b8KL(\u03b8\u2016\u03c8) can computed as \u2207\u03b8KL(\u03b8\u2016\u03c8) = \u2211 x p(x; \u03b8)(\u03b8 \u2212 \u03c8) \u00b7\nf(x) ( f(x) \u2212 \u00b5(\u03b8) ) , which can be approxi-\nmated by samples generated from p(x; \u03b8) [3]. In implementation, we maintain a \u201cpool\u201d of samples, each of which is updated by a single Gibbs step after each iteration of Algorithm 1."}, {"heading": "7 Experiments", "text": "The experiments below take two stages: first, the parameters are projected (in some divergence) and then we compare the accuracy of sampling with the resulting marginals. We focus on this second aspect. However, we provide a comparison of the computation time for various projection algorithms in Table 1, and when comparing the accuracy of sampling with a given amount of time, provide two\n6\ncurves for sampling with the original parameters, where one curve has an extra amount of sampling effort roughly approximating the time to perform projection in the reversed KL divergence.\n7.1 Synthetic MRFs\nOur first experiment follows that of [8, 3] in evaluating the accuracy of approximation methods in marginal inference. In the experiments, we approximate randomly generated MRF models with rapid-mixing distributions using the projection algorithms described previously. Then, the marginals of fast mixing approximate distributions are estimated by running a Gibbs chain on each distribution. These are compared against exact marginals as computed by the junction tree algorithm. We use the mean absolute difference of the marginals |p(Xi = 1)\u2212 q(Xi = 1)| as the accuracy measure. We compare to Naive mean-field (MF), Gibbs sampling on original parameters (Gibbs), and Loopy belief propagation (LBP). Many other methods have been compared against a similar benchmark [6, 8].\nWhile our methods are for general MRFs, we test on Ising potentials because this is a standard benchmark. Two graph topologies are used: two-dimensional 16 \u00d7 16 grids and 10 node random graphs, where each edge is independently present with probability pe \u2208 {0.3, 0.5, 0.7}. Node parameters \u03b8i are uniform from [\u2212dn, dn] with fixed field strength dn = 1.0. Edge parameters \u03b8ij are uniform from [\u2212de, de] or [0, de] to obtain mixed or attractive interactions respectively, with interaction strengths de \u2208 {0, 0.5, . . . , 4}. Figure 1 shows the average marginal error at different interaction strengths. Error bars show the stan-\ndard error normalized by the number of samples, which can be interpreted as a 68.27% confidence interval. We also include time-accuracy comparisons in Figure 2. All results are averaged over 50 random trials. We run Gibbs long enough ( 106 samples) to get a fair comparison in terms of running time.\nExcept where otherwise stated, parameters are projected onto the ball {\u03b8 : \u2016R(\u03b8)\u2016\u221e \u2264 c}, where c = 2.5 is larger than the value of c = 1 suggested by the proofs above. Better results are obtained by using this larger constraint set, presumably because of looseness in the bound. For piecewise projection, grids use simple vertical and horizontal chains of treewidth either one or two. For random graphs, we randomly generate spanning trees until all edges are covered. Gradient descent uses a fixed step size of \u03bb = 0.1. A Gibbs step is one \u201csystematic-scan\u201d pass over all variables between. The reversed KL divergence maintains a pool of 500 samples, each of which is updated by a single Gibbs step in each iteration.\nWe wish to compare the trade-off between computation time and accuracy represented by the choice between the use of the \u221e and spectral norms. We measure the running time on 16 \u00d7 16 grids in Table 1, and compare the accuracy in Figure 3.\nThe appendix contains results for a three-state Potts model on an 8\u00d78 grid, as a test of the multivariate setting. Here, the intractable divergence KL(\u03c8\u2016\u03b8) is included for reference, with the projection computed with the help of the junction tree algorithm for inference.\n7\n7.2 Berkeley binary image denoising\nThis experiment evaluates various methods for denoising binary images from the Berkeley segmentation dataset downscaled from 300 \u00d7 200 to 120 \u00d7 80. The images are binarized by setting Yi = 1 if pixel i is above the average gray scale in the image, and Yi = \u22121. The noisy image X is created by setting: Xi = Yi+12 i(1 \u2212 t 1.25 i ) + 1\u2212Yi 2 t 1.25 i , in which ti is sampled uniformly from [0, 1]. For inference purposes, the conditional distribution Y is modeled as P (Y |X) \u221d exp ( \u03b2 \u2211 ij YiYj + \u03b1 2 \u2211 i(2Xi \u2212 1)Yi ) , where the pairwise strength \u03b2 > 0 encourages smoothness. On this attractive-only Ising potential, the Swendsen-Wang method [12] mixes rapidly, and so we use the resulting samples to estimate the ground truth. The parameters \u03b1 and \u03b2 are heuristically chosen to be 0.5 and 0.7 respectively.\nFigure 4 shows the decrease of average marginal error. To compare running time, Euclidean and K(\u03b8\u2016\u03c8) projection cost approximately the same as sampling 105 and 4.8\u00d7 105 samples respectively. Gibbs sampling on the original parameter converges very slowly. Sampling the approximate distributions from our projection algorithms converge quickly in less than 104 samples."}, {"heading": "8 Conclusions", "text": "We derived sufficient conditions on the parameters of an MRF to ensure fast-mixing of univariate Gibbs sampling, along with an algorithm to project onto this set in the Euclidean norm. As an example use, we explored the accuracy of samples obtained by projecting parameters and\nthen sampling, which is competitive with simple variational methods as well as traditional Gibbs sampling. Other possible applications of fast-mixing parameter sets include constraining parameters during learning."}, {"heading": "Acknowledgments", "text": "NICTA is funded by the Australian Government through the Department of Communications and the Australian Research Council through the ICT Centre of Excellence Program.\n8"}, {"heading": "9 Appendix", "text": ""}, {"heading": "9.1 Proof of MRF Dependency Bound", "text": "This section gives a proof of the bound on the dependency matrix stated in Section 4 above.\nTo start with, we observe the conditional distribution of a single variable xi when all others are fixed, which is easy to calculate. Lemma 8. The conditional probability of one variable given all others is\np(Xi = \u00b7|X\u2212i = x\u2212i) = sig  \u2211 k\u2208N(i) \u03b8ik\u00b7xk  , where sig is the \u201cmultivariate sigmoid\u201d defined as (v) = exp(v)/1T exp(v), and N(i) is the set of indices that are in a pair with i.\nNow, to compute the influence matrix, we must consider what configuration of all the variables other than xi and xj will allow a change in xj to induce the greatest change in xi (Definition 3). Lemma 9. The dependency matrix is given by\nRij = max x,y:x\u2212j=y\u2212j\n1 2 \u2016sig(\u03b8ij\u00b7xj + s)\u2212 sig(\u03b8 ij \u00b7yj + s)\u20161\ns = \u2211\nk\u2208N(i)\\j\n\u03b8ik\u00b7xk\nProof. Using the previous Lemma inside the definition of the dependency matrix (Definition 3) gives that\nRij = max x,y:x\u2212j=y\u2212j\n\u2016p(Xi = \u00b7|x\u2212i)\u2212 p(Xi = \u00b7|y\u2212i)\u2016TV\n= max x,y:x\u2212j=y\u2212j\n1 2 \u2016sig( \u2211 k\u2208N(i) \u03b8ik\u00b7xk)\u2212 sig( \u2211 k\u2208N(i) \u03b8ik\u00b7yk)\u20161.\nSubstituting the definition of s inside each of the sig() terms gives the result.\nWhile the previous Lemma bounds the dependency, it is not in a very convenient form. Hence, the rest of this section will apply a series of relaxations to obtain more convenient upper-bounds. The first of these is obtained by letting s be an arbitrary vector, rather than determined by \u03b8 and x.\nLemma 10. The dependency matrix for an MRF is bounded by\nRij \u2264 max xj ,yj max s\n1 2 \u2016sig(\u03b8ij\u00b7xj + s)\u2212 sig(\u03b8 ij \u00b7yj + s)\u20161.\nThe following Lemma will be needed in what follows. Lemma 11. For vectors x, y, s,\nmax s \u2016sig(x+ s)\u2212 sig(y + s)\u20161 = 2|2a\u2212 1|,\nwhere a = \u03c3 (\n1 2 range(y \u2212 x) ) . Here, range(z) is defined as maxi zi \u2212min zi.\nNow, applying this Lemma to the previous result on the dependency matrix gives the following Theorem. Theorem 12. The dependency matrix for an MRF is bounded by\nRij \u2264 1\n4 max a,b |range(\u03b8ij\u00b7a \u2212 \u03b8 ij \u00b7b )|.\n10\nProof. The previous result gives us the bound\nRij \u2264 max a,b |2\u03c3(1 2 range(\u03b8ij\u00b7a \u2212 \u03b8 ij \u00b7b )\u2212 1|.\nUsing the easily-proven fact that |2\u03c3( 12x)\u2212 1| \u2264 1 4 |x| gives the result.\nCorollary 13. The dependency matrix for an MRF is bounded by\nRij \u2264 max a,b\n1 4 \u2016\u03b8ij\u00b7a \u2212 \u03b8 ij \u00b7b\u20161, Rij \u2264 max a,b 1 2 \u2016\u03b8ij\u00b7a \u2212 \u03b8 ij \u00b7b\u2016\u221e.\nProof. This follows immediately from the observations that |range(x)| \u2264 \u2016x\u20161 and that |range(x)| \u2264 2\u2016x\u2016\u221e."}, {"heading": "9.2 Proof of Dual Representation for Euclidean Projection Operator", "text": "This section gives a proof of the main result of Section 5.1, as stated below.\nTheorem 14. The projection operator\nprojC(\u03c8, Y ) := argmin (\u03b8,Z)\u2208C \u2016\u03b8 \u2212 \u03c8\u20162 + \u03b1\u2016Z \u2212 Y \u20162F , C = {(\u03b8, Z) : Zij \u2265 Rij(\u03b8), \u2016Z\u2016\u2217 \u2264 c} (9)\nhas the dual representation of\nmaximize \u03c3,\u03c6,\u2206,\u0393 g(\u03c3, \u03c6,\u2206,\u0393) subject to \u03c3ij(a, b, c) \u2265 0, \u03c6ij(a, b, c) \u2265 0, \u2200(i, j) \u2208 E , a, b, c , (10)\nwhere\ng(\u03c3, \u03c6,\u2206,\u0393) = min Z h1(Z;\u03c3, \u03c6,\u2206,\u0393) + min \u03b8 h2(\u03b8;\u03c3, \u03c6)\nh1(Z;\u03c3, \u03c6,\u2206,\u0393) = \u2212tr(Z\u039bT ) + I(\u2016Z\u2016\u2217 \u2264 c) + \u03b1\u2016Z \u2212 Y \u20162F\nh2(\u03b8;\u03c3, \u03c6) = \u2016\u03b8 \u2212 \u03c8\u20162 + 1\n2 \u2211 i,j\u2208E \u2211 a,b,c ( \u03c3ij(a, b, c)\u2212 \u03c6ij(a, b, c) ) (\u03b8ijc,a \u2212 \u03b8 ij c,b),\nin which \u039bij := \u2206ijDij + \u0393\u0302ij + \u2211 a,b,c \u03c3ij(a, b, c) + \u03c6ij(a, b, c), where \u0393\u0302ij :={\n\u0393ij if (i, j) \u2208 E \u2212\u0393ij if (j, i) \u2208 E , and D is an indicator matrix with Dij = 0 if (i, j) \u2208 E or (j, i) \u2208 E , and Dij = 1 otherwise. The dual variables \u03c3ij and \u03c6ij are arrays of size Lj \u00d7Li\u00d7Li for all pairs (i, j) \u2208 E while \u2206 and \u0393 are of size n\u00d7 n.\nProof. Firstly, we observe that the minimization in Eq. 9 is equivalent to\nminimize \u03b8,Z \u2016\u03b8 \u2212 \u03c8\u20162 + \u03b1\u2016Z \u2212 Y \u20162F\nsubject to \u2016Z\u2016\u2217 \u2264 c Zij = Zji, \u2200(i, j) \u2208 E\nZij \u2265 max 1\u2264a,b\u2264m\n1 2 \u2016\u03b8ij.a \u2212 \u03b8 ij .b\u2016\u221e,\u2200(i, j) \u2208 E\nDijZij = 0, 1 \u2264 i, j \u2264 n.\n(11)\n11\nNow, consider the Lagrangian of this problem,\nL(\u03b8, Z, \u03c3, \u03c6,\u2206,\u0393) := \u2016\u03b8 \u2212 \u03c8\u20162 + \u03b1\u2016Z \u2212 Y \u20162F + I(\u2016Z\u2016\u2217 \u2264 c) \u2212 \u2211\n(i,j)\u2208E \u2211 a,b,c \u03c3ij(a, b, c) ( Zij \u2212 1 2 (\u03b8ijc,a \u2212 \u03b8 ij c,b) ) \u2212 \u2211 (i,j)\u2208E \u2211 a,b,c \u03c6ij(a, b, c) ( Zij + 1 2 (\u03b8ijc,a \u2212 \u03b8 ij c,b) )\n\u2212 \u2211 i,j \u2206ijDijZij \u2212 \u2211 (i,j)\u2208E \u0393ij(Zij \u2212 Zji).\nHere, \u0393, \u2206, \u03c3ij and \u03c6ij , 1 \u2264 i, j \u2264 n are dual variables and \u2211 i,j denotes \u2211 1\u2264i,j\u2264n for simplicity of notation. Here, note that L is independent of \u0393ij , \u03c3ij and \u03c6ij for (i, j) 6\u2208 E . For convenience, one can simply set these to zero.\nIt is straightforward to verify that the problem in Eq. 11 is convex and Slater\u2019s conditions hold. Thus, by strong duality we have the the solution of Eq. 11 is equal to\nmin \u03b8,Z max \u03c3\u22650,\u03c6\u22650,\u2206,\u0393 L(\u03b8, Z, \u03c3, \u03c6,\u2206,\u0393) = max \u03c3\u22650,\u03c6\u22650,\u2206,\u0393 g(\u03c3, \u03c6,\u2206,\u0393),\nwhere we define the dual function\ng(\u03c3, \u03c6,\u2206,\u0393) = min \u03b8,Z L(\u03b8, Z, \u03c3, \u03c6,\u2206,\u0393).\nFinally, by a simple manipulation of terms, we can see that\ng(\u03c3, \u03c6,\u2206,\u0393) = min Z h1(Z;\u03c3, \u03c6,\u2206,\u0393) + min \u03b8 h2(\u03b8;\u03c3, \u03c6)\nh1(Z;\u03c3, \u03c6,\u2206,\u0393) = \u2212tr(Z\u039bT ) + I(||Z||\u2217 \u2264 c) + \u03b1||Z \u2212 Y ||2F\nh2(\u03b8;\u03c3, \u03c6) = \u2016\u03b8 \u2212 \u03c8\u20162 + 1\n2 \u2211 i,j\u2208E \u2211 a,b,c ( \u03c3ij(a, b, c)\u2212 \u03c6ij(a, b, c) ) (\u03b8ijc,a \u2212 \u03b8 ij c,b)."}, {"heading": "9.3 Additional Experimental Results", "text": "The rest of the appendix contains extra experimental results that could not fit in the main paper.\n12\n13"}], "references": [{"title": "Nonlinear Programming", "author": ["Dimitri Bertsekas"], "venue": "Athena Scientific,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2004}, {"title": "A limited memory algorithm for bound constrained optimization", "author": ["Richard H. Byrd", "Peihuang Lu", "Jorge Nocedal", "Ciyou Zhu"], "venue": "SIAM J. Sci. Comput.,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 1995}, {"title": "Projecting Ising model parameters for fast mixing", "author": ["Justin Domke", "Xianghang Liu"], "venue": "In NIPS,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2013}, {"title": "Efficient projections onto the l1-ball for learning in high dimensions", "author": ["John C. Duchi", "Shai Shalev-Shwartz", "Yoram Singer", "Tushar Chandra"], "venue": "In ICML,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2008}, {"title": "Matrix norms and rapid mixing for spin systems", "author": ["Martin E. Dyer", "Leslie Ann Goldberg", "Mark Jerrum"], "venue": "Ann. Appl. Probab.,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2009}, {"title": "Approximate inference using conditional entropy decompositions", "author": ["Amir Globerson", "Tommi Jaakkola"], "venue": "In UAI,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2007}, {"title": "A simple condition implying rapid mixing of single-site dynamics on spin systems", "author": ["Thomas P. Hayes"], "venue": "In FOCS,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2006}, {"title": "Convergent message-passing algorithms for inference over general graphs with convex free energies", "author": ["Tamir Hazan", "Amnon Shashua"], "venue": "In UAI,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2008}, {"title": "Probabilistic Graphical Models: Principles and Techniques", "author": ["D. Koller", "N. Friedman"], "venue": null, "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2009}, {"title": "Expectation propagation for approximate bayesian inference", "author": ["Thomas Minka"], "venue": "In UAI,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2001}, {"title": "Divergence measures and message passing", "author": ["Thomas Minka"], "venue": "Technical report,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2005}, {"title": "Nonuniversal critical dynamics in monte carlo simulations", "author": ["Robert H. Swendsen", "Jian-Sheng Wang"], "venue": "Phys. Rev. Lett.,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 1987}, {"title": "Graphical models, exponential families, and variational inference", "author": ["Martin Wainwright", "Michael Jordan"], "venue": "Found. Trends Mach. Learn.,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2008}, {"title": "Constructing free energy approximations and generalized belief propagation algorithms", "author": ["Jonathan Yedidia", "William Freeman", "Yair Weiss"], "venue": "IEEE Transactions on Information Theory,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2005}], "referenceMentions": [{"referenceID": 12, "context": "There are two main classes of approximate inference algorithms: variational methods and Markov chain Monte Carlo (MCMC) algorithms [13].", "startOffset": 131, "endOffset": 135}, {"referenceID": 8, "context": "Among variational methods, mean-field approximations [9] are based on a \u201ctractable\u201d family of distributions, such as the fully-factorized distributions.", "startOffset": 53, "endOffset": 56}, {"referenceID": 13, "context": "Other methods, such as loopy belief propagation (LBP), generalized belief propagation [14] and expectation propagation [10] use a less restricted family of target distributions, but approximate the KL-divergence.", "startOffset": 86, "endOffset": 90}, {"referenceID": 9, "context": "Other methods, such as loopy belief propagation (LBP), generalized belief propagation [14] and expectation propagation [10] use a less restricted family of target distributions, but approximate the KL-divergence.", "startOffset": 119, "endOffset": 123}, {"referenceID": 2, "context": "This paper is inspired by a recent hybrid approach for Ising models [3].", "startOffset": 68, "endOffset": 71}, {"referenceID": 2, "context": "Following previous work [3], these ideas are experimentally validated via a projected gradient descent algorithm to minimize other divergences, and looking at the accuracy of the resulting marginals.", "startOffset": 24, "endOffset": 27}, {"referenceID": 4, "context": "[5], generalizing the work of Hayes [7].", "startOffset": 0, "endOffset": 3}, {"referenceID": 6, "context": "[5], generalizing the work of Hayes [7].", "startOffset": 36, "endOffset": 39}, {"referenceID": 1, "context": "5 can be solved with LBFGS-B [2].", "startOffset": 29, "endOffset": 32}, {"referenceID": 0, "context": "Finally, once h1 and h2 have been solved, the gradient of g is (by Danskin\u2019s theorem [1]) \u2202g \u2202\u2206ij =\u2212Dij\u1e90ij , \u2202g \u2202\u0393ij =\u1e90ji \u2212 \u1e90ij ,", "startOffset": 85, "endOffset": 88}, {"referenceID": 2, "context": "6 can be performed by thresholding the singular values of A [3].", "startOffset": 60, "endOffset": 63}, {"referenceID": 3, "context": "[4] provide a method linear in the number of nonzeros in a and logarithmic in the length of a.", "startOffset": 0, "endOffset": 3}, {"referenceID": 10, "context": "We will first present a general algorithmic framework based on projected gradient descent (Algorithm 1), and then discuss the details of several previously proposed divergences [11, 3].", "startOffset": 177, "endOffset": 184}, {"referenceID": 2, "context": "We will first present a general algorithmic framework based on projected gradient descent (Algorithm 1), and then discuss the details of several previously proposed divergences [11, 3].", "startOffset": 177, "endOffset": 184}, {"referenceID": 2, "context": "2 Piecewise KL-divergence One tractable surrogate of KL(\u03c8\u2016\u03b8) is the piecewise KL-divergence [3] defined over some tractable subgraphs.", "startOffset": 92, "endOffset": 95}, {"referenceID": 10, "context": "In general KL(\u03b8\u2016\u03c8) is inferior to KL(\u03c8\u2016\u03b8) for marginal inference since it tends to underestimate the support of the distribution [11].", "startOffset": 129, "endOffset": 133}, {"referenceID": 2, "context": "\u2207\u03b8KL(\u03b8\u2016\u03c8) can computed as \u2207\u03b8KL(\u03b8\u2016\u03c8) = \u2211 x p(x; \u03b8)(\u03b8 \u2212 \u03c8) \u00b7 f(x) ( f(x) \u2212 \u03bc(\u03b8) ) , which can be approximated by samples generated from p(x; \u03b8) [3].", "startOffset": 142, "endOffset": 145}, {"referenceID": 7, "context": "Our first experiment follows that of [8, 3] in evaluating the accuracy of approximation methods in marginal inference.", "startOffset": 37, "endOffset": 43}, {"referenceID": 2, "context": "Our first experiment follows that of [8, 3] in evaluating the accuracy of approximation methods in marginal inference.", "startOffset": 37, "endOffset": 43}, {"referenceID": 5, "context": "Many other methods have been compared against a similar benchmark [6, 8].", "startOffset": 66, "endOffset": 72}, {"referenceID": 7, "context": "Many other methods have been compared against a similar benchmark [6, 8].", "startOffset": 66, "endOffset": 72}, {"referenceID": 0, "context": "25 i , in which ti is sampled uniformly from [0, 1].", "startOffset": 45, "endOffset": 51}, {"referenceID": 11, "context": "On this attractive-only Ising potential, the Swendsen-Wang method [12] mixes rapidly, and so we use the resulting samples to estimate the ground truth.", "startOffset": 66, "endOffset": 70}, {"referenceID": 0, "context": "References [1] Dimitri Bertsekas.", "startOffset": 11, "endOffset": 14}, {"referenceID": 1, "context": "[2] Richard H.", "startOffset": 0, "endOffset": 3}, {"referenceID": 2, "context": "[3] Justin Domke and Xianghang Liu.", "startOffset": 0, "endOffset": 3}, {"referenceID": 3, "context": "[4] John C.", "startOffset": 0, "endOffset": 3}, {"referenceID": 4, "context": "[5] Martin E.", "startOffset": 0, "endOffset": 3}, {"referenceID": 5, "context": "[6] Amir Globerson and Tommi Jaakkola.", "startOffset": 0, "endOffset": 3}, {"referenceID": 6, "context": "[7] Thomas P.", "startOffset": 0, "endOffset": 3}, {"referenceID": 7, "context": "[8] Tamir Hazan and Amnon Shashua.", "startOffset": 0, "endOffset": 3}, {"referenceID": 8, "context": "[9] D.", "startOffset": 0, "endOffset": 3}, {"referenceID": 9, "context": "[10] Thomas Minka.", "startOffset": 0, "endOffset": 4}, {"referenceID": 10, "context": "[11] Thomas Minka.", "startOffset": 0, "endOffset": 4}, {"referenceID": 11, "context": "[12] Robert H.", "startOffset": 0, "endOffset": 4}, {"referenceID": 12, "context": "[13] Martin Wainwright and Michael Jordan.", "startOffset": 0, "endOffset": 4}, {"referenceID": 13, "context": "[14] Jonathan Yedidia, William Freeman, and Yair Weiss.", "startOffset": 0, "endOffset": 4}], "year": 2014, "abstractText": "Markov chain Monte Carlo (MCMC) algorithms are simple and extremely powerful techniques to sample from almost arbitrary distributions. The flaw in practice is that it can take a large and/or unknown amount of time to converge to the stationary distribution. This paper gives sufficient conditions to guarantee that univariate Gibbs sampling on Markov Random Fields (MRFs) will be fast mixing, in a precise sense. Further, an algorithm is given to project onto this set of fast-mixing parameters in the Euclidean norm. Following recent work, we give an example use of this to project in various divergence measures, comparing univariate marginals obtained by sampling after projection to common variational methods and Gibbs sampling on the original parameters.", "creator": "LaTeX with hyperref package"}}}