{"id": "1411.1420", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "5-Nov-2014", "title": "Eigenvectors of Orthogonally Decomposable Functions", "abstract": "In this paper we formulate the framework of recovering a hidden orthonormal basis given access to a certain \"Basis Encoding Function\". We describe the class of Basis Encoding Functions (BEF), such that their local maxima on the unit sphere are in one-to-one correspondence with the basis elements. This description relies on a certain \"hidden convexity\" property of these functions. The basic definition of a base is the basic principle of the base \"basis encoding function\". For example, the base \"basis encoding function\" has a base element, and a base element can be a base element, and a base element can be a base element. In particular, the base element \"base element\" should always have a base element, and a base element can be a base element.\n\n\n\nThe base element of the base function depends on a given base element that is defined by the base element in the base function. The base element \"basis encoding function\" has the \"basis encoding function\" in the base function as the base element. In other words, the base element \"basis encoding function\" in the base function should always have a base element. In other words, the base element \"basis encoding function\" in the base function as the base element. In other words, the base element \"basis encoding function\" in the base function as the base element.\nThe base element \"basis encoding function\" can only be described in the base function of the base function. The base element is defined as a base element (that is, a base element or a base element, as the base element) of the base element. In the case of a base element, the base element has a base element that must be encoded as the base element. This is the case for the base element:\nThe base element \"basis encoding function\" must include a base element (that is, a base element, or a base element) of the base element. In other words, the base element \"basis encoding function\" must include a base element (that is, a base element or a base element, as the base element) of the base element. In other words, the base element \"basis encoding function\" must include a base element (that is, a base element, or a base element, as the base element) of the base element. In other words, the base element \"basis encoding function\" must include a base element (that is,", "histories": [["v1", "Wed, 5 Nov 2014 21:07:20 GMT  (64kb)", "http://arxiv.org/abs/1411.1420v1", "39 pages"], ["v2", "Mon, 11 May 2015 16:08:28 GMT  (84kb,D)", "http://arxiv.org/abs/1411.1420v2", "45 pages"], ["v3", "Tue, 3 Nov 2015 17:22:20 GMT  (89kb,D)", "http://arxiv.org/abs/1411.1420v3", "56 pages"], ["v4", "Tue, 24 May 2016 18:10:04 GMT  (93kb,D)", "http://arxiv.org/abs/1411.1420v4", "61 pages"], ["v5", "Sat, 26 Nov 2016 20:03:30 GMT  (104kb,D)", "http://arxiv.org/abs/1411.1420v5", "77 pages"]], "COMMENTS": "39 pages", "reviews": [], "SUBJECTS": "cs.LG", "authors": ["mikhail belkin", "luis rademacher", "james voss"], "accepted": false, "id": "1411.1420"}, "pdf": {"name": "1411.1420.pdf", "metadata": {"source": "CRF", "title": "Learning a Hidden Basis Through Imperfect Measurements: An Algorithmic Primitive", "authors": ["Mikhail Belkin"], "emails": ["mbelkin@cse.ohio-state.edu", "lrademac@cse.ohio-state.edu", "vossj@cse.ohio-state.edu"], "sections": [{"heading": null, "text": "ar X\niv :1\n41 1.\n14 20\nv1 [\ncs .L\nG ]\n5 N\nWe describe a new algorithm, \u201cgradient iteration\u201d, for provable recovery of the hidden basis. We provide a complete theoretical analysis of Gradient Iteration both for the exact case as well as for the case when the observed function is a perturbation of the \u201ctrue\u201d underlying BEF. In both cases we show convergence and complexity bounds polynomial in dimension and other relevant parameters, such as perturbation size. Our perturbation results can be considered as a very general non-linear version of the classical Davis-Kahan theorem for eigenvectors of perturbations of symmetric matrices. In addition we show that in the exact case the algorithm converges superlinearly and give conditions relating the degree of convergence to properties of the Basis Encoding Function. Our algorithm can be viewed as a generalization of the classical power iteration method for eigenanalysis of symmetric matrices as well as a generalization of power iterations for tensors. Moreover, the Gradient Iteration algorithm can be easily and efficiently implemented in practice."}, {"heading": "1 Introduction", "text": "A good algoritmic primitive is a procedure which is simple, allows for theoretical analysis and, ideally, for efficient implementation. It should also be applicable to a range of interesting problems. An example of an extremely successful and widely used primitive, both in theory and practice, is diagonalization/eigendecomposition of symmetric matrices.\nThe goal of this paper is to propose learning a hidden basis from noisy observations as a new algorithmic primitive and to provide the underlying algorithmic framework and its theoretical analysis. Our approach can be viewed as a non-linear/non-tensorial generalization of the classical matrix diagonalization results and perturbation analyses. We will show that a number of problems of recent theoretical and practical interest can be viewed within our setting.\nConsider {z1, . . . , zm} a set of orthogonal unit vectors in Rd. Choosing a set of one-dimensional contrast functions1 gi : R \u2192 R, we define the Basis Encoding Function (BEF) F : Rd \u2192 R as\nF (u) := m \u2211\ni=1\ngi(\u3008u, zi\u3009) . (1)\nOur goal will be to recover the set {z1, . . . , zm} (fully or partially) through access to F (u) (the exact setting), or to provide a provable approximation to these given vectors given an estimate of F (u) (noisy/perturbation setting). We will see that in a number of different settings, the relevant information about the problem can be encoded as a BEF (Section 2.1).\nIn what follows, we will primarily be interested in the behavior of the BEF F (u) restricted to the unit sphere in Rd. It turns out that the behavior of F (u) on the sphere is closely related to the structure of the basis elements. We will describe a large class of admissible contrast functions gi such that local maxima of F (u) on the sphere are in one-to-one correspondence to the basis vectors zi (or their opposite directions). This perhaps surprising behavior (as F (u) can have lots of minima and other critical points) is due to certain \u201chidden convexity\u201d of the BEF on the sphere. Moreover, it turns out that these maxima are stable under perturbations of F (u) and no spurious maxima are created.\nWe propose an algorithm for recovering the hidden basis based on what may be called a \u201cgradient iteration\u201d algorithm. The basic algorithm consists simply of replacing the point with the gradient at each step of the iteration using the map u 7\u2192 \u2207F (u)/\u2016\u2207F (u)\u2016. We will show that the maxima of F (u) on the sphere are the only stable fixed points of this map. While in general it is possible (although not likely in practice) for the iteration to converge to an unstable fixed point, we will provide a slight modification of this algorithm (by appropriately resetting the starting point) that can be guaranteed to converge to one of the basis vectors (or to approximate such vectors in the noisy case). By repeating the procedure appropriately we can provably recover the basis. We provide complete theoretical analysis in terms of the perturbation size and the computational complexity of the algorithm. Our bounds are low degree polynomial in all relevant parameters, including the dimension, the number of basis elements to be recovered and the perturbation size. They can be considered as a non-linear version of the classical Davis-Kahan perturbation theorem [11] for eigenvectors of symmetric matrices. Moreover, for the non-perturbed case we show superlinear convergence, in contrast to the linear convergence of the standard power iteration for matrices. We provide additional conditions on the contrast functions gi to obtain specific higher orders of convergence.\nWe proceed to show that a number of problems can be viewed in terms of hidden basis recovery. In particular, we briefly discuss how our primitive can be used to recover clusters in spectral clustering, independent components in Independent Component Analysis (ICA), parameters of Gaussian mixtures and certain tensor decompositions.\n1We call gi\u2019s contrast functions following the Independent Component Analysis (ICA) terminology. Note, however, that in the ICA setting our \u201ccontrast functions\u201d correspond to different scalings of the ICA contrast function.\nConnection to the power method for symmetric matrices and tensors. Our algorithm can be viewed as a generalization of the classical power iteration method for eigendecomposition of symmetric matrices. Let A be a symmetric matrix. Put F (u) = \u3008Au,u\u3009. From the spectral theorem for matrices, we have F (u) = \u2211\ni \u03bbi(\u3008u, zi\u3009)2. We see that F (u) is a BEF with the hidden basis zi representing the eigenvectors of A and the contrast functions gi(x) = \u03bbix2, with \u03bbi being the eigenvalues of A. It is easy to see that our gradient iteration is exactly the power method based on the map u 7\u2192 Au/\u2016Au\u2016. We note that it is not necessary to know gi(x) to have access to the BEF F (u).\nIn a recent work [2], a form of orthogonal tensor decomposition was proposed for solving a variety of problems by generalizing previous works on learning mixtures of spherical Gaussians [14], latent Dirichlet allocation [1], and learning hidden Markov models [3]. The authors also introduced a tensor power method. We will see (Sections 2.1 and 4.2) their setting also fits within our framework by choosing the contrast functions to be gi(x) = \u03bbixr, r \u2265 3.\nPerhaps counter-intuitively, our results imply that the success of these methods for certain problems does not rely on their tensorial structure but on certain \u201chidden convexity\u201d inherent in the problem."}, {"heading": "2 Problem description and main results", "text": "We consider a function optimization framework for hidden basis recovery. More formally, let {z1, . . . , zm} be a non-empty set of orthogonal unit vectors in Rd. These unit vectors form the unseen basis. A function on a closed unit ball F : B(0, 1) \u2192 R is defined from \u201ccontrast functions\u201d gi : [\u22121, 1] \u2192 R as:\nF (u) :=\nm \u2211\ni=1\ngi(\u3008u, zi\u3009) . (2)\nWe call F a basis encoding function (BEF) with the associated tuples {(gi, zi) | i \u2208 [m]}. The goal is to recover the hidden basis vectors zi for i \u2208 [m] up to sign given evaluation access to F and its gradient. We will assume that d \u2265 2 since otherwise the problem is trivial. We only consider contrast functions gi \u2208 C(2)([\u22121, 1]) which satisfy the following assumptions:\nA1. Each gi is either an even or odd function. A2. For each i, either gi( \u221a x) or \u2212gi( \u221a x) is strictly convex on [0, 1]. A3. For each i \u2208 [m], ddxgi( \u221a x)|x=0 = 0.\nA4. For each i \u2208 [m], gi(0) = 0. From now on F and the term BEF will refer to a BEF with associated zi\u2019s and gi\u2019s satisfying Assumptions A1\u2013A4 unless otherwise stated. Remark: The Assumption A4 is non-essential. If each gi satisfies A1\u2013A3, then x 7\u2192 [gi(x)\u2212gi(0)] satisfies A1\u2013A4 making [F (u)\u2212 F (0)] =\u2211mi=1[gi(\u3008u, zi\u3009)\u2212 gi(0)] a BEF of the desired form.\nWe shall see that BEFs arise naturally in a number of problems, and also that given a BEF, the directions z1, . . . , zm can be efficiently recovered up to sign."}, {"heading": "2.1 Examples of algorithmic problems solvable via basis encoding functions", "text": "Spectral clustering. Spectral clustering is a class of methods for multiway cluster analysis. We describe now a prototypical version of the method that works in two phases [5, 21, 23, 27]. The first phase, spectral embedding, constructs a similarity graph based on the features of the data and then embeds the data in Rd\n(where d is the number of clusters) using the bottom d eigenvectors of the Laplacian matrix of the similarity graph. The second phase clusters the embedded data using a variation of the k-means algorithm. A key aspect in the justification of spectral clustering is the following observation: If the graph has d connected components, then a pair of data points is either mapped to the same vector if they are in the same connected component or mapped to orthogonal vectors if they are in different connected components [26]. If the graph\nis close to this ideal case, which can be interpreted as a realistic graph with d clusters, then the embedding is close to that ideal embedding.\nThis suggests the following alternate approach (introduced in [7]) to the second phase of spectral clustering by interpreting it as a hidden basis recovery problem: Let x1, . . . ,xn \u2208 Rd be the embedded points. Let g : R \u2192 R be a function satisfying Assumptions A1\u2013A4. Let\nF (u) =\nn \u2211\ni=1\ng(\u3008u, xi\u3009). (3)\nIn the ideal case we have {x1, . . . ,xn} = {b1Z1, . . . , bdZd}, where {Zj}dj=1 is an orthonormal basis and {bj}dj=1 are positive scalars. Thus, in the ideal case we can write\nF (u) = d \u2211\nj=1\najg(bj\u3008u, Zj\u3009)\nwhere aj is the number of points in the jth connected component. That is, F is a BEF in the ideal case. In the general case it is a perturbed BEF and the hidden basis can be approximately recovered using our robust algorithm (Section 6). Note that, via (3), F and its derivatives can be evaluated at any u just with the knowledge of the xis, without knowing the hidden basis.\nIndependent component analysis (ICA). In the ICA model, one observes samples of the random vector X = AS where A \u2208 Rd\u00d7d is a mixing matrix and S = (S1, . . . , Sd) is a latent random vector such that the Sis are mutually independent and non-Gaussian. The goal is to recover the mixing matrix A = [A1| \u00b7 \u00b7 \u00b7 |Ad], typically with the goal of using A\u22121 to invert the mixing process and recover the original signals. This recovery is possible up to natural indeterminacies, namely the ordering of the columns of A and the choice of the sign of each Ai [9]. ICA has a vast literature (see the books [10, 16] for a broad overview) with numerous applications including speech separation [20], denoising of EEG/MEG brain recordings [24], and various vision tasks [6, 8] to name a few.\nTo demonstrate that ICA fits within our BEF framework, we rely on the properties of the cumulant statistics2 In particular, letting \u03bar(X) denote the rth cumulant of a random variable X, then \u03bar(X) satisfies the following: (1) Homogeneity: \u03bar(\u03b1X) = \u03b1r\u03bar(X) for any \u03b1 \u2208 R and (2) Additivity: if X and Y are independent, then \u03bar(X+Y ) = \u03bar(X)+\u03bar(Y ). Given an ICA model X = AS, these properties imply that for any u \u2208 Rd, \u03bar(\u3008u, X\u3009) = \u03bar( \u2211d i=1\u3008u, Ai\u3009Si) = \u2211d i=1\u3008u, Ai\u3009r\u03bar(Si). A preprocessing step called whitening (i.e., linearly transforming the observed data to have identity covariance) makes the columns of A into orthogonal unit vectors. Under whitening, the columns of A form a hidden basis of the space. In particular, defining the contrast functions gi(x) := xr\u03bar(Si) and the basis encoding elements zi := Ai, then the function F (u) := \u03bar(\u3008u, X\u3009) = \u2211d i=1 gi(\u3008u, zi\u3009) is a BEF so long as each \u03bar(Si) 6= 0. Further, the cumulants and their derivatives have natural sample estimates (see e.g.,[18, 25] for the third and fourth order estimates), and as such this choice of F will be admissible to our algorithmic framework for basis recovery.\nInterestingly, it has been noted in several places (see e.g., [15, 22, 28]) that cubic convergence rates can be achieved using optimization techniques for recovering the directions Ai, particularly when performing ICA using the fourth cumulant or the closely related fourth moment. One explanation as to why this is possible arises from the dual interpretation of the \u201cgradient iteration\u201d algorithm (discussed at length later in this paper) as both an optimization technique and as a power method. In the ICA setting, the gradient iteration algorithm for cumulants was introduced in our paper [25]. This paper provides a significant generalization of those ideas as well as a theoretical analysis.\n2 An important class of ICA methods with guaranteed convergence to the columns of A are based on the optimization of \u03ba4(\u3008u, X\u3009) over Sd\u22121 (see e.g., [4, 12, 15]). Other contrast functions are also frequently used in the practical implementations of ICA (see e.g., [17]). However these do not have analogous guarantees of the non-existence of spurious maxima.\nOrthogonal tensor decompositions. In a recent work [2], it was shown that a form of orthogonal tensor decomposition applies to a variety of problems including ICA and previous works on learning mixtures of spherical Gaussians [14], latent Dirichlet allocation [1], and learning hidden Markov models [3].\nTheir framework involves using the moments of the various models to obtain a tensor of the form T = \u2211m\nk=1wk\u00b5 \u2297r k where (1) each wk \u2208 R\\{0}, (2) each \u00b5k \u2208 Rd is a unit vector, and (3) \u00b5\u2297rk is the tensor outer power defined by (\u00b5\u2297rk )i1...ir = (\u00b5k)i1 . . . (\u00b5k)ir . The \u00b5ks may be assumed to have unit norm by changing the wks appropriately. In the special case where the \u00b5ks are orthogonal, then the directions of \u00b5k can be recovered using the tensor power methods introduced in [2]. Treating T as an operator using the definition Tur := \u2211\ni1,...,ik\u2208[d]k Ti1...irui1 \u00b7 \u00b7 \u00b7 uir , it can be seen that Tu r = \u2211m k=1wk\u3008u, \u00b5k\u3009r. In particular, the\nfunction F (u) = Tur is a BEF with the contrasts gi(x) := wixr and hidden basis elements zk := \u00b5k. In section 4.2, we will show that the tensor power method is a special case of our gradient iteration.\nParameter estimation in a Spherical Gaussian Mixture Model. A Gaussian Mixture Model (GMM) is a parametric family of probability distributions. A spherical GMM is a distribution whose density can be written in the form f(x) =\n\u2211k i=1wifi(x), where wi \u2265 0, \u2211\niwi = 1 and fi is an d-dimensional Normal density with mean \u00b5i and covariance matrix \u03c3 2 i I , for \u03c3i > 0. The parameter estimation problem is to estimate wi,\u00b5i, \u03c3i given i.i.d. samples of random vector x with density f . For clarity of exposition, we only discuss the case k = d and \u03c3i = \u03c3 for some fixed, unknown \u03c3. Our argument is a variation of the moment method in [14]. As in [14], similar ideas should work for the case k < d and non-identical \u03c3is.\nWe explain how to recover the different parameters from observable moments. Firstly, \u03c32 is the smallest eigenvalue of the covariance matrix of x. This recovers \u03c3. Let v be any unit norm eigenvector corresponding to the eigenvalue \u03c32. Define M2 = E(xxT ) \u2212 \u03c32I \u2208 Rd\u00d7d. Then we have M2 = \u2211d i=1wi\u00b5i\u00b5 T i . Denote D = diag(w1, . . . , wd), A = (\u00b51, . . . ,\u00b5d) \u2208 Rd\u00d7d. With this notation we have M2 = ADAT . Let M = M\n1/2 2 (symmetric). This implies\nM = AD1/2R, (4)\nwhere R is some unitary matrix. We have E(\u3008x, u\u30093) =\u2211di=1 wi\u3008\u00b5i, u\u30093 + 3\u03c32\u2016u\u20162 E(\u3008x, u\u3009). Then\nF (u) := E(\u3008x, M\u22121u\u30093)\u2212 3\u03c32\u2016M\u22121u\u20162 E(\u3008x, M\u22121u\u3009) = d \u2211\ni=1\nwi\u3008\u00b5i, M\u22121u\u30093\n= d \u2211\ni=1\nwi(u TRTD\u22121/2ei) 3 = d \u2211\ni=1\nw \u22121/2 i \u3008u, Ri\u00b7\u30093\nis a BEF encoding the rows of R, with basis vectors zi = Ri\u00b7 and contrasts gi(t) = w \u22121/2 i t\n3. The recovery of the rows of R allows, via (4), the recovery of the directions of the columns of A, that is, the directions of \u00b5is. The actual \u00b5is then can be recovered from the identity \u3008\u00b5i, v\u3009 = \u3008E(x), v\u3009. Finally, denoting w = (w1, . . . , wd) we have E(x) = Aw and we recover w = A\u22121 E(x)."}, {"heading": "2.2 Summary of the results", "text": "It will be convenient to we append arbitrary directions zm+1, . . . , zd to our hidden basis z1, . . . , zm such that z1, . . . , zd are orthonormal. For the remainder of this paper, we simplify our notation by indexing vectors in Rd with respect to this hidden basis z1, . . . , zd. In particular, for u \u2208 Rd we have that ui is shorthand for the unobserved value \u3008u, zi\u3009, and we may thus write F (u) = \u2211m i=1 gi(ui).\nWe now state the first result indicating that a BEF may be used to recover the unseen basis.\nTheorem 2.1. The set {\u00b1zi | i \u2208 [m]} is a complete enumeration of the local maxima of |F | with respect to the domain Sd\u22121.\nWe note that assumption A1 is stronger than is actually required in Theorem 2.1. In particular, we could replace Assumption A1 with the assumption that x 7\u2192 gi(\u2212 \u221a\n|x|) is either strictly convex or strictly concave on [\u22121, 0] for each i \u2208 [m].\nTheorem 2.1 implies that a form of gradient ascent can be used to recover maxima of |F | and hence the hidden basis. However, the performance of gradient ascent is dependent on the choice of a learning the rate parameter. It turns out that there is a simple and practical parameter-free alternative to gradient ascent for finding the hidden basis elements zi in this setting.\nWe associate with F the gradient iteration function G : Sd\u22121 \u2192 Sd\u22121 defined by\nG(u) := { \u2207F (u) \u2016\u2207F (u)\u2016 if \u2207F (u) 6= 0 u otherwise.\nWe would like to treat G as a fixed point method for recovering the hidden basis elements. However, there is a difficulty: At any given step, the derivative \u2202iF (u) := \u2202\u2202uiF (u) can be of a different sign than ui causing ui and Gi(u) to have opposite sign. Given a sequence {u(n)}\u221en=0 defined recursively by u(n) = G(u(n\u2212 1)), it may happen that for oscillating sign values s(i) \u2208 {\u22121,+1} the sequence s(n)u(n) \u2192 zi as n \u2192 \u221e. Since we do not distinguish between recovery of zi and \u2212zi, the sequence {u(n)}\u221ei=0 should be viewed as recovering zi even though it is oscillating.\nTo fix this issue, we divide Sd\u22121 into equivalence classes using the equivalence relation v \u223c u if |vi| = |ui| for each i \u2208 [d]. Given v \u2208 Sd\u22121, we denote by [v] its corresponding equivalence class. The resulting quotient space Sd\u22121/\u223c may informally be thought of as an orthant of the sphere, i.e., Qd\u22121+ := {u \u2208 Sd\u22121 | ui \u2265 0 for each i \u2208 [d]}. There is a bijection \u03c6 : Sd\u22121/\u223c \u2192 Qd\u22121+ given by \u03c6([u]) = \u2211d i=1 |ui|zi, and we treat Sd\u22121/\u223c as a metric space with the metric \u00b5([u], [v]) = \u2016\u03c6([v]) \u2212 \u03c6([u])\u2016. Under Assumption A1, if u \u223c v then G(u) \u223c G(v). As such, sequences are consistently defined modulo this equivalence class, and we consider the fixed points of G/\u223c.\nWe will use the following terminology. A class [v] is a fixed point of G/\u223c if G(v) \u223c v. Consider sequences of the form {u(n)}\u221en=0 defined recursively by u(n) = G(u(n \u2212 1)). A class [v] is Lyapunov stable if for every neighborhood N of [v] there exists a neighborhood N \u2032 \u2282 N of [v] such that if [u(0)] \u2208 N \u2032 then [u(n)] \u2208 N \u2032 for every n \u2208 N. A class [v] is unstable if it is not Lyapunov stable. Finally, a Lyapunov stable class [v] is an attractor of G/\u223c if there exists a neighborhood N of [v] such that for any [u(0)] \u2208 N , the sequence [u(n)] \u2192 [v] as n \u2192 \u221e.\nIn addition, we will sometimes refer to a vector v \u2208 Sd\u22121 as a fixed point of G/\u223c. This is a slight abuse of terminology which should be understood to mean that [v] is a fixed point of G/\u223c.\nThe following results demonstrate that the attractors of G/\u223c are precisely the hidden basis elements, and that convergence to these fixed points is fast (super-linear).\nTheorem 2.2 (Gradient iteration stability). The classes {[zi] | i \u2208 [m]} are fixed points of the G/\u223c. Further, the following hold:\n1. The equivalence classes {[zi] | i \u2208 [m]} are attractors of G/\u223c. 2. All fixed points of G/\u223c not in the set {zi | i \u2208 [m]} are unstable.\nTheorem 2.3 (Gradient iteration convergence). Let {u(n)}\u221en=0 be a sequence defined recursively from a starting u(0) \u2208 Sd\u22121 and u(n) = G(u(n \u2212 1)). Then following hold:\n1. If [u(n)] \u2192 [zi] as n \u2192 \u221e, then the convergence is superlinear. Further, if there exists r \u2265 2 such that x 7\u2192 gi(x1/r) is convex on [0, 1], then the rate of convergence is at least order r \u2212 1. 2. If u(0) \u22a5 zi, then [u(n)] 6\u2192 [zi] as n \u2192 \u221e.\nThe above Theorems imply the following practical algorithm for recovering the hidden basis elements: First choose a vector u \u2208 Sd\u22121 and perform the iteration u \u2190 G(u) until convergence is achieved to\nrecover a single hidden basis direction. Note that convergence can be measured by looking at min(\u2016G(u)\u2212 u\u2016, \u2016\u2212G(u) \u2212 u\u2016). Then, to recover an additional hidden basis direction, one may repeat the procedure with a new starting vector u in the orthogonal complement to previously found hidden basis elements. We refer to this process as the Gradient iteration algorithm.\nThe gradient iteration algorithm forms an interesting link between function optimization and power method techniques. In Section 4.1, we show that the gradient iteration update performs an implicit gradient ascent step with an adaptive learning rate. In Section 4.2, we show that the gradient iteration algorithm is also an extension of the power method for matrices.\nFrom a practical standpoint, the fast convergence properties of the gradient iteration make it an ideal algorithm for hidden basis recovery. However, it is possible (though unlikely) to get stuck in an unstable fixed point of G/\u223c. However, it is possible to augment the gradient iteration algorithm with Hessian informed restarts in order to achieve guaranteed basis recovery even when we only observe a perturbation of F . More formally, we call F\u0302 an \u01eb-approximation of F if for every u \u2208 B(0, 1) the following hold: |F (u)\u2212 F\u0302 (u)| < \u01eb, \u2016\u2207F (u) \u2212 \u2207F\u0302 (u)\u2016 < \u01eb, and \u2016HF (u) \u2212 HF\u0302 (u)\u2016 < \u01eb. If F satisfies a strong version of Assumption A2, namely that for some strictly positive cmin and cmax such that cmin \u2264 \u2223 \u2223 \u2223 d2 dx2 gi( \u221a x)|x=x0 \u2223 \u2223 \u2223 \u2264 cmax for each x0 \u2208 [\u22121, 1] and for each i \u2208 [m], then we call F a (cmin, cmax)robust BEF and we have the following result.\nTheorem 2.4. There exist positive constants C1, C2 such that the following holds. Suppose that \u01eb \u2264 C1cmin m3/2d2 \u00b7 ( cmincmax ) 7/2. If F\u0302 is an \u01eb-approximation to a (cmin, cmax)-robust BEF F , then there exists a deterministic algorithm ROBUSTGI-RECOVERY which approximately recover the hidden basis elements using the following operations: Oracle computations of \u2207F\u0302 (u), oracle eigendecompositions of HF\u0302 (u), basic arithmetic operations on scalars, the square root, and inner products in Rd. ROBUSTGI-RECOVERY recovers each zi (i \u2208 [m]) up to sign within error 4m \u221a 2d\ncmin \u01eb when run for sufficiently many steps N .\n\u2022 If m is known, it suffices that N \u2265 C2[ c 2 maxm 3d c2min log(2 \u221a 2mcmax cmin )+log( cmin\u01eb )+md 2]. Further, ROBUSTGI-\nRECOVERY uses at most 4m2 eigendecompositions of HF\u0302 (u). \u2022 If m is unknown, it suffices that N \u2265 C2[ c 2 maxmd 3\nc2min log(mcmaxcmin )+ log( cmin \u01eb )+d 3]. Further, ROBUSTGI-\nRECOVERY uses at most 4d2 eigendecompositions of HF\u0302 (u). In section 6, we state the algorithm ROBUSTGI-RECOVERY and give explicit values for the constants\nC1 and C2. It should also be noted that in the special case where we have exact access to F , then F is an \u01eb-approximation to itself for any \u01eb > 0. As a corollary to Theorem 2.4, given exact access to F and its derivatives we may efficiently recover the hidden basis elements within any error \u03b4."}, {"heading": "3 Extrema structure of the optimization framework", "text": "The optima structure of F relies heavily upon a hidden convexity structure implied by Assumption A2. To better capture this structure, we define functions hi : [\u22121, 1] \u2192 R as hi(x) := gi(sign(x) \u221a\n|x|) for i \u2208 [m] and hi := 0 for i \u2208 [d] \\ [m]. We may thus write\nF (u) =\nm \u2211\ni=1\nhi(sign(ui)u 2 i ) . (5)\nNote that on [0, 1] (or respectively on [\u22121, 0]), each of these functions hi is either strictly convex or strictly concave. The functions hi have the following properties:\nLemma 3.1. Let s \u2208 {+1,\u22121} be a sign value. Let \u03c3i+ = 1 if gi if it is convex on [0, 1], \u03c3i+ = \u22121 otherwise. Let \u03c3i\u2212 = 1 if gi if it is convex on [\u22121, 0], \u03c3i\u2212 = \u22121 otherwise. Let I+ = [0, 1] and let I\u2212 = [\u22121, 0]. For each i \u2208 [m], the following hold:\n1. The function \u03c3ishi is strictly convex on the domain Is. 2. h\u2032i(0) = 0. 3. hi is continuously differentiable. 4. The derivative function \u03c3ish\u2032i is strictly increasing on Is. In particular, s\u03c3ish \u2032 i(x) > 0 for any x \u2208\nIs \\ {0}, and the function s\u03c3ishi is strictly increasing on Is.\nProof. That \u03c3ishi is strictly convex follows directly from Assumption A2 and (when s = \u22121) the subsequent definition of \u03c3i\u2212. That h\u2032i(0) = 0 is an implication of Assumption A3. That hi is continuously differentiable follows from the fact that\nh\u2032i(x) =\n{\n1 2g \u2032 i( \u221a x)/ \u221a x if x 6= 0\n0 if x = 0\nexists everywhere, and is thus continuous due to the convexity of \u03c3ishi (see [13, Corollary 4.2.3]). Property 4 can be seen using properties of convex functions. Let D+ denote the right derivative function. By strict convexity, D+(\u03c3ishi) is a strictly increasing functions on Is. Since \u03c3ishi is differentiable on Is, \u03c3ish \u2032 i(x) and D+(\u03c3ishi)(x) coincide for each x \u2208 Is. As such, \u03c3ish\u2032i is strictly increasing on Is.\nIn order to avoid dealing with unnecessary sign values, it will be convenient to restrict ourselves to analyzing F over the domain Qd\u22121+ . We demonstrate that this can be done without loss of generality using Lemma 3.2 below. We identify each orthant by a sign vector v where each vi \u2208 {+1,\u22121}, and in particular we define Qv := {u \u2208 Sd\u22121 | viui \u2265 0 for each i \u2208 [d]} as the orthant of Sd\u22121 containing v.\nLemma 3.2. Let F be a BEF with hidden basis z1, . . . , zd, and let v = \u2211d i=1 sizi for sign values si \u2208 {\u00b11}. Define an isometry \u03c8 : Sd\u22121 \u2192 Sd\u22121 by \u03c8i(u) := siui. Then the function F\u0303 := F\u25e6\u03c8 is a BEF. In particular, F\u0303 |Qd\u22121+ is the pullback of F |Qd\u22121v with respect to \u03c8.\nProof. To construct F\u0303 = \u2211m i=1 g\u0303i(\u3008u, z\u0303i\u3009), we set z\u0303i = sizi and g\u0303i = gi for each i \u2208 [m]. It is easily verified that F\u0303 is a BEF. Further, our construction implies that for any u \u2208 Sd\u22121 we have that\nF \u25e6 \u03c8(u) = m \u2211\ni=1\ngi(siui) = m \u2211\ni=1\ngi(\u3008u, z\u0303i\u3009) = F\u0303 (u) .\nLemma 3.2 demonstrates that by a simple manipulation of the signs of zi, we may relabel any of the hidden orthants Qv of Sd\u22121 as being the all positive orthant Q d\u22121 + within a new BEF F\u0303 . Thus when proving Theorem 2.1, it suffices to show that for a BEF F , the vectors z1, z2, . . . , zm give a complete enumeration of the maxima of |F ||Qd\u22121+ .\nTo characterize the extrema structure of |F ||Qd\u22121+ , we analyze the Lagrangian function L : B(0, 1) \u00d7 R defined as: L(u, \u03bb) := F (u) \u2212 \u03bb[\u2016u\u20162 \u2212 1]. The following result enumerates the critical points of F with respect to the sphere.\nLemma 3.3. The pair (u, \u03bb) is a critical point of L if and only if \u03bb\u03c7[vi 6=0] = h\u2032i(v2i ) for each i \u2208 [d].\nProof. We set the derivative \u2202\n\u2202ui L(u, \u03bb) = 2h\u2032i(u2i )ui \u2212 2\u03bbui (6)\nequal to 0 to obtain h\u2032i(u 2 i )ui = \u03bbiui. Noting that when ui = 0, h \u2032 i(v 2 i ) = h \u2032 i(0) = 0 by Assumption A3 gives the result.\nWhile there are potentially exponentially many critical points of L, it turns out that only the hidden basis directions correspond to maxima of F on the sphere.\nProposition 3.4. If j \u2208 [m], then zj is a strict local maximum of |F | with respect to Qd\u22121+ .\nProof. We will prove the case where hj is strictly convex and note that the case hj is strictly concave is exactly the same when replacing F with \u2212F .\nWe first note that F (zj) = hj(1) > 0 since hj is strictly increasing (see Lemma 3.1 property 4). In particular, using continuity of each gi, it follows that F (u) > 0 on a neighborhood of zj , and it suffices to demonstrate that F takes on a maximum with respect to Sd\u22121 at zj . Continuing from equation (6), we obtain\nD2 u L(u, \u03bb) =\nm \u2211\ni=1\n\u03c7[ui 6=0][4h \u2032\u2032 i (u 2 i )u 2 i + 2h \u2032 i(ui)]ziz T i \u2212 2\u03bbI , (7)\nwhere Du is the derivative operator with respect to the variable u. The main difficulty in this calculation is showing that (\u22022i F )(v) = 0 when vi = 0, which gives rise to the indicator function in the formula above. To see this, we note by the definition that for each i \u2208 [m],\ng\u2032\u2032i (0) = lim c\u21920 g\u2032i(c)\u2212 g\u2032i(0) c = 2 lim c\u21920+ 1 2 g\u2032i( \u221a c)\u221a c = 2 lim c\u21920+ ( d dx gi( \u221a x) ) \u2223 \u2223 \u2223 \u2223\nx=c\n= 0 .\nThe second equality uses that g\u2032i(0) = 0, a fact which is implied by Assumption A3. The final equality uses that ddxgi( \u221a x) is continuous (see [13, Corollary 4.2.3]). As (\u22022i F )(v) when vi = 0 is exactly g \u2032\u2032 i (0), the formula (7) follows as claimed. We now use the Lagrangian criteria for constrained extrema (see e.g., [19, chapter 11] for a discussion\nof the first order necessary and second order sufficient conditions for constrained extrema) to show that zj is a maximum of F |Qd\u22121+ . From Lemma 3.3, we see that (zj , h \u2032 j(1)) is a critical point of L. Further, for any non-zero v \u2208 Rd \u2229 z\u22a5j , we have that vT (D2uL)(zj , h\u2032j(1))v = \u22122h\u2032j(1)\u2016v\u20162. As h\u2032j(1) > 0, it follows that vT (D2\nu L)(zj , h\u2032j(1))v < 0. Thus, zj is a local maximum of F .\nProposition 3.5. If v \u2208 Qd\u22121+ is not contained in the set {zi | i \u2208 [m]}, then v is not a local maximum of |F | with respect to Qd\u22121+ .\nProof. We first consider the case in which v 6\u22a5 zi for at most one i \u2208 [m]. We will call this i \u2208 [m] for which vi 6= 0 as j if it exists and otherwise let j \u2208 [m] be arbitrary. Fix any w \u2208 Qd\u22121+ such that wj > vj and wi = 0 for i \u2208 [m] \\ {j}. Such a choice is possible since v 6= zj implies vj < 1. Then, |F (v)| = |hj(v2j )| and |F (w)| = |hj(w2j )|. Since hj is a strictly increasing function on [0, 1] from hj(0) = 0 (see Lemma 3.1), it follows that |F (w)| > |F (v)|. Since w can be constructed in any open neighborhood of v, v is not a local maximum of |F | with respect to Qd\u22121+ .\nNow suppose that v is an extremum (either a maximum or a minimum) of |F | with respect to Qd\u22121+ such that there exists j, k \u2208 [m] distinct such that vj 6= 0 and vk 6= 0. We will demonstrate that this implies that v is a minimum of |F |. Fix \u03b7 > 0 sufficiently small that for any choice of \u03b4 such that |\u03b4| \u2208 (0, \u03b7) has w(\u03b4) := (v\u30082\u3009 + \u03b4zj \u2212 \u03b4zk)\u30081/2\u3009 \u2208 Qd\u22121+ . We now consider the difference F (w(\u03b4)) \u2212 F (v):\nF (w(\u03b4)) \u2212 F (v) = hj(wj(\u03b4)2)\u2212 hj(v2j ) + hk(wk(\u03b4)2)\u2212 hk(v2k) = h\u2032j(xj(\u03b4) 2)[wj(\u03b4) 2 \u2212 v2j ] + h\u2032k(xk(\u03b4)2)[wk(\u03b4)2 \u2212 v2k]\n= \u03b4[h\u2032j(xj(\u03b4) 2)\u2212 h\u2032k(xk(\u03b4)2)] ,\nwhere xi(\u03b4) \u2208 (vj , wj(\u03b4)) and xi(\u03b4) \u2208 (wk(\u03b4), vk) under the mean value theorem.\nAs v must be an extremum of F in order to be an extremum of |F |, there exists \u03bb such that the pair (v, \u03bb) is a critical point of L. Let S = {i | vi 6= 0}. Lemma 3.3 implies that \u03bb = h\u2032i(v2i ) for i \u2208 S . In particular, sign(h\u2032i(v 2 i )) is the same for each i \u2208 S , and we will call this sign value s. Under equation (5), we have F (v) = \u2211\ni\u2208S hi(v 2 i ). By Lemma 3.1, shi is strictly increasing from shi(0) = 0 on [0, 1] for each\ni \u2208 S . As such, F (v) is separated from 0 and sign(F (v)) = s. Further,\ns[F (w(\u03b4)) \u2212 F (v)] = s\u03b4[h\u2032j(xj(\u03b4)2)\u2212 h\u2032k(xk(\u03b4)2)] < s\u03b4[\u03bb\u2212 \u03bb] = 0\nholds by noting that each sh\u2032i is strictly increasing on [0, 1]. Thus, v is a minimum of |F |.\nTheorem 2.1 follows by combining Propositions 3.4 and 3.5 with Lemma 3.2."}, {"heading": "4 Interpreting the gradient iteration", "text": "In this section, we demonstrate that the gradient iteration algorithm has two main interpretations, first as an adaptive form of gradient ascent (section 4.1) and second as a generalization of the power method (section 4.2). These dual interpretations closely link the gradient iteration and other power methods with hill climbing techniques for finding the maxima of a function3 . Both interpretations of the gradient iteration are most easily understood using a special form of BEF defined below.\nDefinition 4.1. A BEF F (u) = \u2211m i=1 gi(ui) is called a positive basis encoding function (PBEF) if x 7\u2192 gi(sign(x) \u221a |x|) is strictly convex for each i \u2208 [m].\nA PBEF has several nice properties not shared by all BEFs. Its name is justified by the fact that for a PBEF F , then for any u \u2208 Sd\u22121, we have that F (u) \u2265 0. Further, when we expand F (u) = \u2211m\ni=1 hi(sign(ui)u 2 i ) = \u2211m i=1 hi(u 2 i ) under equation 5, we see that each hi is strictly convex over its entire\ndomain. Finally, given a BEF F , we construct a PBEF F\u0304 (u) := \u2211m i=1 g\u0304i(ui) where g\u0304i(x) = |gi(x)|. We call F\u0304 the PBEF associated with F .\nFor PBEF the gradient iteration G becomes a true fixed point method without a need to consider equivalence classes (as in section 2.2). In particular, if \u03c6 and \u00b5 are defined as in section 2.2, then we have the following.\nLemma 4.2. Let v \u2208 Rd be a sign vector (that is, vi \u2208 {\u00b11} for each i \u2208 [d]). If u,w \u2208 Qd\u22121v , then \u00b5([u], [w]) = \u2016u\u2212w\u2016.\nProof. By direct calculation we see:\n\u00b5([u], [w])2 =\n\u2225\n\u2225\n\u2225\n\u2225\n\u2225\nd \u2211\ni=1\n|ui|zi \u2212 d \u2211\ni=1\n|wi|zi \u2225 \u2225 \u2225 \u2225\n\u2225\n2\n= d \u2211\ni=1\n(|ui| \u2212 |wi|)2 = d \u2211\ni=1\n(ui \u2212 wi)2 = \u2016u\u2212w\u20162 .\nThe first equality uses the definition of \u00b5, and the third equality uses that u,w \u2208 Qd\u22121 v\n, i.e., ui and wi share the same sign (up to the possibility of being 0) for each i \u2208 [d].\nIn the following proposition, we see that G/\u223c and G\u0304|Qd\u22121+ are equivalent updates on metric spaces which are isometric under the map \u03c6. In particular, these iterations have equivalent fixed point properties, and it will suffice to analyze G\u0304|Qd\u22121+ in place of G/\u223c.\nProposition 4.3. Let v be a sign vector in Rd. Then, G\u0304 has the following properties: 1. If u \u2208 Qd\u22121\nv , then G\u0304(u) \u2208 Qd\u22121 v .\n2. If u,w \u2208 Sd\u22121 are such that u \u223c w, then G(u) \u223c G\u0304(w). 3We note that in a special setting of recovering a parallelopiped a closely related observation was made in [22].\nProof. We first demonstrate property 1. Letting h\u03041, . . . , h\u0304d be defined for F\u0304 similarly to h1, . . . , hd from section 3, we have that \u2202iF\u0304 (u) = 2h\u0304\u2032i(u 2 i )ui. Under Lemma 3.1, we have that h\u0304 \u2032 i \u2265 0 on R for each i \u2208 [m]. As each h\u0304i := 0 for each i \u2208 [d] \\ [m], it follows that sign(ui)\u2202iF\u0304 (u) \u2265 0 for each i \u2208 [d]. It follows that G\u0304(u) \u2208 Qd\u22121\nv .\nWe now demonstrate that property 2 holds. Since u \u223c w, there exist sign values si \u2208 {+1,\u22121} such that ui = siwi. By Assumption A1 (i.e., gi and hence its derivative is either an even or odd function), we see that |\u2202iF (u)| = |g\u2032i(ui)| = |g\u2032i(wi)| = |\u2202iF\u0304 (w)|. In particular, it follows that \u2016\u2207F\u0304 (w)\u2016 = \u2016\u2207F (u)\u2016 6= 0, and that |G\u0304i(w)| = |Gi(u)| for each i \u2208 [d]. Thus, G\u0304(w) \u223c G(u).\nCorollary 4.4. Given a sequence {u(n)}\u221en=0 in Sd\u22121 defined recursively by u(n) := G(u(n \u2212 1)), then we may consider a parallel sequence {v(n)}\u221ei=0 in Qd\u22121+ defined by v(0) := \u03c6([u(0)]) and v(n) := G\u0304(v(n \u2212 1)). Then, for any w \u2208 Qd\u22121+ and any fixed n, \u00b5([u(n)], [w]) = \u2016v(n)\u2212w\u2016."}, {"heading": "4.1 Gradient iteration as adaptive gradient ascent", "text": "For the remainder of this section, we take F to be a PBEF. Given a u \u2208 Sd\u22121, the function F = |F | can be maximized on the unit sphere using a variation on gradient ascent. The projected gradient ascent update (with learning rate \u03b7) is given in the function GRADASCENTUPDATE.\nAlgorithm 1 A single of projected gradient ascent step for function maximization over Sd\u22121.\n1: function GRADASCENTUPDATE(u, \u03b7) 2: u\u2032 \u2190 u+ \u03b7P\nu\u22a5 \u2207F (u)\n3: return u \u2032 \u2016u\u2032\u2016 4: end function\nThe update in GRADASCENTUPDATE differs from the standard gradient ascent in two ways. First, the update occurs in the direction P\nu\u22a5 \u2207F (u) rather than \u2207F (u). This takes into account the geometry\nstructure of Sd\u22121 by updating within the plane tangent to Sd\u22121 at u. This arises naturally when treating Sd\u22121 as a manifold with the local coordinate system defined by the projective space centered at u. Then, u\u2032 is projected back onto the sphere in order to stay within Sd\u22121. We now compare the updates u \u2190 GRADASCENTUPDATE(u, \u03b7) and u \u2190 G(u). If P\nu\u22a5 \u2207F (u) = 0, then both updates are the identity map\nand are thus identical. If P u\u22a5\n\u2207F (u) 6= 0, then\nG(u) = \u2207F (u)\u2016\u2207F (u)\u2016 = \u3008\u2207F (u), u\u3009u+ P u\u22a5 \u2207F (u) \u2016\u2207F (u)\u2016 = u+ P u\u22a5 \u2207F (u)/\u3008\u2207F (u), u\u3009 \u2016\u2207F (u)\u2016/\u3008\u2207F (u), u\u3009 . (8)\nThe numerator of the rightmost fraction can be interpreted as line 2 of GRADASCENTUPDATE(u, \u03b7) using the choice \u03b7 = \u3008u, \u2207F (u)\u3009\u22121. Lemma 3.1 implies that ui > 0 if and only if \u2202iF (u) = 2h\u2032i(u2i )ui > 0. As such, \u03b7 = \u3008u, \u2207F (u)\u3009\u22121 > 0 is a valid learning rate. The denominator of the rightmost fraction in equation (8) gives the normalization to project back onto the unit sphere (line 3 of GRADASCENTUPDATE). We thus have the following result.\nLemma 4.5. The update u \u2190 G(u) is an adaptive form of projective gradient ascent. Specifically, 1. If \u2207F (u) 6= 0, then G(u) = GRADASCENTUPDATE(u, \u3008u, \u2207F (u)\u3009\u22121). 2. If \u2207F (u) = 0 and \u03b7 \u2208 (0,\u221e) is fixed, then G(u) = GRADASCENTUPDATE(u, \u03b7).\nWe note that the step size chosen by the gradient iteration function is in many ways very good. By Proposition 4.3, we see that G(u) and hence \u2207F (u) belong to the same orthant as u, and as such we never overshoot a basis direction zi during the ascent procedure. Further, we will see that the gradient iteration has the fast convergence properties stated in Theorem 2.3."}, {"heading": "4.2 Gradient iteration extends the power method", "text": "We now show how our gradient iteration relates to the classic power method for matrix eigenvector recovery. Given a symmetric matrix A \u2208 Rd\u00d7d, the power iteration update is given by u \u2190 Au/\u2016Au\u2016. If A has the eigendecomposition\n\u2211d i=1 \u03bbiviv T i , then the gradient iteration may be rewritten as u \u2190\n1 \u2016Au\u2016 \u2211d i=1 \u03bbi\u3008u, vi\u3009vi. It can be seen that in the coordinate system of the eigenvectors, the coordinate value \u3008u, vi\u3009 corresponding to the maximum eigenvalue increases the most so long as \u3008u, vi\u3009 6= 0. Given a generic starting point, the power method converges to the top eigenvector of A. Additional eigenvectors can be recovered by choosing a new starting point in the orthogonal complement of previously found eigenvectors.\nConsider the function f : Sd\u22121 \u2192 R defined as f(u) := uTAu. The derivative \u2207f(u) = 2Au differs from Au only by the multiplicative constant 2. As such, the gradient iteration u \u2190 \u2207f(u)\u2016\u2207f(u)\u2016 and the power iteration u \u2190 Au/\u2016Au\u2016 are identical, making the matrix power iteration a special case of gradient iteration.\nFrom the eigendecomposition of A, we obtain f(u) = \u2211d i=1 \u03bbi\u3008u, vi\u30092. Defining gi(x) := \u03bbix2 and zi := vi, we see that f(u) = \u2211d i=1 gi(\u3008u, zi\u3009) is a basis encoding function that fails to satisfy Assumption A2. The stability structure of the matrix power iteration differs from the stability structure shown for the BEFs satisfying A1\u2013A4 in this paper. In particular, the only attractor of the power method for matrices is the top eigenvector rather than each of the hidden basis elements. Nevertheless, the matrix power method is a border case of our framework. If f(u) =\n\u2211d i=1 gi(x) had contrasts gi(x) = \u03bbi|x|2+\u01eb for some \u01eb > 0\nrather than contrasts gi(x) = \u03bbix2, then f(u) would be a BEF satisfying Assumptions A1\u2013A4. We now switch back to considering PBEFs with Assumptions A1\u2013A4 in place and write the gradient iteration as a generailized power method. Given u \u2208 Sd\u22121 for which \u2207F (u) 6= 0, we obtain\nG(u) = \u2207F (u)\u2016\u2207F (u)\u2016 = 2 \u2016\u2207F (u)\u2016\nm \u2211\ni=1\nh\u2032i(u 2 i )\u3008u, zi\u3009zi .\nThis is the same form as obtained for the matrix power iteration u \u2190 2\u2016\u2207f(u)\u2016 \u2211d i=1 \u03bbi\u3008u, vi\u3009vi except with the \u03bbis replaced by the functions h\u2032i(u 2 i ). These h \u2032 is are 0 at the origin and strictly increasing (see Lemma 3.1). For any fixed i, there is a neighborhood of zi on Sd\u22121 such that hi(u2i ) > hj(u 2 j) for any j \u2208 [d] \\ {i}. In this neighborhood, the gradient iteration converges to zi. In addition, the strict convexity of the his combined with the fact that h\u2032i(0) = 0 for each i gives rise to the super-linear convergence rates of Theorem 2.3 not achieved in by the matrix power method. We formalize and prove these convergence properties in section 5.\nFinally, we note that Anandkumar et al. [2] have recently proposed a generalization of the matrix power method for decomposing orthogonal, symmetric tensors. It turns out that the tensor power methods are also special cases of gradient iteration. We continue with the notation from the paragraph on orthogonal tensor decompositions in section 2.1. Let T =\n\u2211m i=1wi\u00b5 \u2297r i where r \u2265 2, each wi \u2208 R \\ {0}, and each\n\u00b5i \u2208 Rd. We extend the definition of Txr to include lower powers: For k \u2208 [r], we define (Txk)i1\u00b7\u00b7\u00b7ir := \u2211\ni1\u2208[d] \u00b7 \u00b7 \u00b7 \u2211 ik\u2208[d] Ti1,...,irxi1 \u00b7 \u00b7 \u00b7 xik . It can be seen that Tx r\u22121 = \u2211d i=1 wi\u3008x, \u00b5i\u3009r\u22121\u00b5i. In [2], the following update x \u2190 Txr\u22121/\u2016Txr\u22121\u2016 was proposed and analyzed as a generalized power method. As noted in section 2.1, the function F (u) := Tur is a BEF with the hidden contrast functions gi(x) = wix r and basis encoding elements zi = \u00b5i. The product rule implies that \u2207F (u) = rTur\u22121. We see that the gradient iteration u \u2190 \u2207F (u)\u2016\u2207F (u)\u2016 = rTu r\u22121 \u2016rTur\u22121\u2016 is identical to the tensor power iteration u \u2190 Tu r\u22121 \u2016Tur\u22121\u2016 ."}, {"heading": "5 Fixed point structure of the gradient iteration", "text": "In this section, we proceed with a formal analysis of the gradient iteration algorithm. In particular, in subsection 5.1, we demonstrate that the distinguished basis directions [z1], . . . , [zm] are the only stable\nfixed points of the gradient iteration update (Theorem 2.2). Further, we demonstrate in subsection 5.2 that convergence to these stable fixed points is fast (Theorem 2.3).\nThroughout this section, we will assume that F (u) = \u2211m\ni=1 gi(ui) is a PBEF unless otherwise stated and that the functions hi for i \u2208 [d] are defined with respect to F as in section 3 unless otherwise stated. We will analyze the associated gradient iteration function G on the domain Qd\u22121+ . It suffices to analyze this function due to Corollary 4.4.\nThe proofs in this section largely uses the power method interpretation of G."}, {"heading": "5.1 Fixed point stability", "text": "We now proceed with the proof of Theorem 2.2. The proof of this theorem has two main parts, namely demonstrating that the directions z1, . . . , zm are stable attractors of G|Qd\u22121+ and demonstrating that all other fixed points of G|\nQd\u22121+ are unstable. The first part is the simpler part, and we prove it first. We will make use\nof the following notation: u\u3008r\u3009 is the elementwise rth power of u\nProposition 5.1. The directions z1, . . . , zm are attractors of G|Qd\u22121+ .\nThe proof of the proposition is based on analyzing the properties of the power method iteration in a small neighbourhood of the hidden basis directions.\nProof. It is sufficient to show that z1 is an attractor of G|Qd\u22121+ . Since h\u2032i is a strictly increasing continuous function which is 0 at the origin, there exists \u03b4 \u2208 (0, 12 ) such that x \u2208 [0, \u03b4) implies h\u2032i(x2) \u2208 [0, 14h\u20321(1)) for each i and h\u20321((1 \u2212 x)2) \u2208 (34h\u20321(1), h\u2032(1)]. Consider the neighborhood N \u2282 Qd\u22121+ of z1 given by N := {u \u2208 Qd\u22121+ | |(z1 \u2212 u\u30082\u3009)i| < \u03b4 \u2200i \u2208 [d]}. For each u \u2208 N , taking derivatives of equation (5) yields:\n1 2 \u22021F (u) > 3 4 h\u20321(1)u1 and\n1 2 \u2202iF (u) \u2264 1 4 h\u20321(1)ui for each i 6= 1 . (9)\nFix a u \u2208 N \\ {z1}. Let \u039bu := {i | i > 1, ui 6= 0}. For each i \u2208 \u039bu, equation (9) implies that\nG1(u) Gi(u) = \u22021F (u) \u2202iF (u) > 3 u1 ui . (10)\nIt follows that\n1\u2212 G1(u)2 = \u2211 i\u2208\u039bu Gi(u)2 < G1(u)2 9u21 \u2211 i\u2208\u039bu u2i = G1(u)2 9u21 (1\u2212 u21) \u2264 1 9u21 (1\u2212 u21) .\nIn the above, the first inequality is arrived at using equation (10) when multiplying \u2211 i\u2208\u039bu Gi(u)2 by G1(u) G1(u) . By the assumption u1 > 12 , it follows that\n1\u2212 G1(u)2 < 4\n9 (1\u2212 u21) (11)\nWe will use this update to demonstrate the stability of z1.\nClaim 5.1.1. If u \u2208 N , then G(u) \u2208 N .\nProof of Claim. An implication of equation (11) is that 1 \u2212 G1(u)2 < 1 \u2212 u21, and hence that G1(u) > u1. It follows that 1 \u2212 G1(u)2 < 1 \u2212 u1 < \u03b4. By reorganizing equation 10, for i \u2208 \u039bu we obtain Gi(u) < G1(u) 3u1 ui < 2 3ui < \u03b4. Finally, for i 6\u2208 (\u039bu \u222a {1}), ui = 0 implies that Gi(u) = 0 < \u03b4. \u25b3\nWe now consider a sequence u(0),u(1),u(2), . . . formed by choosing u(0) \u2208 N and recursively defining u(n) = G(u(n\u2212 1)) for each n \u2265 1. By the preceding Claim and induction, u(n) \u2208 N for each n \u2208 N. It only remains to be seen that u(n) \u2192 z1 as n \u2192 \u221e.\nBy induction on equation (11), we get 1 \u2212 u1(n)2 < ( 4 9 )n (1 \u2212 u1(0)2) < ( 4 9 )n \u03b4. It follows that\nu1(n) \u2192 1 as n \u2192 \u221e. Under the constraint \u2016u(n)\u2016 = 1, it follows that u(n) \u2192 z1 as n \u2192 \u221e.\nWe now wish to demonstrate that stationary points of G|Qd\u22121+ outside of the set {zi | i \u2208 [m]} are unstable. We will actually prove something stronger, namely given v a stable point of G|Qd\u22121+ with at least two non-zero coordinates vi1 and vi2 and and a neighborhood N of v, then there exists a sequence {u(n)}\u221en=0 with u(0) \u2208 N defined recursively by the gradient iteration u(n) = G(u(n \u2212 1)) such that ui1(n) \u2192 0 as n \u2192 \u221e. The following characterization of the stationary points of G will turn out to be useful.\nObservation 5.2. A vector v \u2208 Qd\u22121+ is stationary point of G if and only if there exists \u03bb\u2217 such that (v, \u03bb\u2217) is a critical point of the Lagrangian4 function L(u, \u03bb) = F (u) \u2212 \u03bb[\u2016u\u20162 \u2212 1]. In particular, if v is a stationary point of G, then \u03bb\u2217\u03c7[vi 6=0] = h\u2032i(v2i ) for each i \u2208 [d].\nProof. This is a result of Lemmas 4.5 and 3.3.\nWith this characterization, we are actually able to characterize the stationary points G. Note that if vi = 0 for each i \u2208 [m], then by the definition of G, v is a stationary point. The remaining stationary points are enumerated by the following Lemma.\nLemma 5.3. Let S \u2282 [m] be non-empty. Then there exists exactly one stationary point v of G|Qd\u22121+ such that vi 6= 0 for each i \u2208 S and vi = 0 for each i \u2208 [m] \\ S . Further, vi = 0 for each i \u2208 [d] \\ S .\nProof. We prove this in two parts. First, we show that a v exists with all of the desired properties. Then, we show uniqueness.\nClaim 5.3.1. There exists v a stationary point of G|Qd\u22121+ such that vi 6= 0 if and only if i \u2208 S .\nProof of Claim. We will construct v as the limit of a sequence. Consider the following construction of an approximation to v whose precision depends on the magnitude of 1N where N \u2208 N.\nfunction APPROXFIXPT(N ) u \u2190 0 for i \u2190 1 to N do\nj \u2190 arg mink\u2208S h\u2032k(u2k) uj \u2190 \u221a u2j + 1 N\nend for return u\nend function Let \u01eb0 > 0 be fixed. Let \u01ebk = 1 k \u01eb0 for each k \u2208 N. Since [0, 1] is a compact space, the h\u2032is are uniformly equicontinuous on this domain. Thus for each k \u2208 N \u222a {0}, there exists \u03b4k > 0 such that for x, y \u2208 [0, 1], |x\u2212 y| \u2264 \u03b4k implies that |h\u2032i(x)\u2212 h\u2032i(y)| \u2264 \u01ebk for each i \u2208 S . We fix constants Nk \u2208 N\u222a {0} such that (1) 1 Nk\n\u2264 \u03b4k for each k and (2) for each k \u2265 1, Nk is an integer multiple of N0. Then we construct a sequence {u(k)}\u221ek=0 by setting u(k) = APPROXFIXPT(Nk) for each k \u2208 N \u222a {0}. It follows by construction that |h\u2032i(u2i (k))\u2212 h\u2032j(u2j (k))| \u2264 \u01ebk for each i, j \u2208 S .\n4This is the Lagrangian equation which arises from optimizing F over the unit sphere introduced in Section 3.\nIt can be seen that mini\u2208S h\u2032i(u 2 i (k)) \u2265 mini\u2208S h\u2032i(u2i (0)) > 0 for each k \u2208 N. To see the second in-\nequality mini\u2208S h\u2032i(u 2 i (0)) > 0, we note that the h \u2032 is are strictly increasing from 0 by Lemma 3.1, and in particular during the first |S| iterations of the loop in APPROXFIXPT, a new coordinate of u will be incremented. To see the second inequality mini\u2208S h\u2032i(u 2 i (k)) \u2265 mini\u2208S for each k \u2208 N, we argue by contradiction. Let j = arg mini\u2208S h \u2032 i(u 2 i (k)). If h \u2032 j(u 2 j (k)) < minmin i\u2208S h \u2032 i(u 2 i (0)), then u 2 j(k) < mini\u2208S u 2 i (0), and thus there exists \u2113 \u2208 S with \u2113 6= j such that u2\u2113(k) > u2\u2113(0). However, for this to be true, then during course of the execution of APPROXFIXPT(Nk ) the decision must be made at line 4 that \u2113 = arg mink\u2208S h \u2032 k(u 2 k) when u2\u2113 = u 2 \u2113(0) (since Nk is an integer multiple of N0). During this update, strict monotonicity of h \u2032 i implies that h\u2032j(u 2 j ) \u2264 h\u2032j(u2j(k)) < minmin i\u2208S h\u2032i(u2i (0)) \u2264 h\u2032\u2113(u2\u2113 ). But this contradicts that \u2113 = arg mink\u2208S h\u2032k(u2k) at line 4. It follows that there exists a \u2206 > 0 such that for each i \u2208 S and each k \u2208 {0, 1, 2, . . . } we have h\u2032i(u 2 i (k)) > \u2206, and in particular that u 2 i (k) \u2265 minj\u2208S(h\u2032j)\u22121(\u2206) > 0.\nSince Sd\u22121 has a compact topology, there exists a subsequence i1, i2, i3, . . . of {0, 1, 2, . . . } such that {u(ik)}\u221ek=1 converges to a vector v \u2208 Sd\u22121. Since each u(ik) \u2208 Qd\u22121+ , v \u2208 Qd\u22121+ . Further, since the u2j(ik)s are bounded from below by a constant \u2206 \u2032 = minj\u2208S(h\u2032j) \u22121(\u2206) > 0 for each j \u2208 S , we see that v2j \u2265 \u2206\u2032 > 0 for each j \u2208 S . Thus by construction, vi = 0 if and only if i \u2208 S . By continuity of the h\u2032\u2113s, it follows that for any j, \u2113 \u2208 S , h\u2032\u2113(v2\u2113 ) \u2212 h\u2032j(v2j ) = limk\u2192\u221e[h\u2032\u2113(u2\u2113 (ik)) \u2212 h\u2032j(u2j (ik))] = 0, and in particular h\u2032\u2113(v 2 \u2113 ) = h \u2032 j(v 2 j ). Observation 5.2 implies that v is a stationary point of G. \u25b3\nClaim 5.3.2. There exists only one stationary point v of G|Qd\u22121+ such that the following hold: (1) vi 6= 0 if i \u2208 S and (2) vi = 0 if i \u2208 [m] \\ S . Proof of Claim. We first show that if v is a stationary point of G|Qd\u22121+ meeting the conditions of the claim, then vi = 0 for each i \u2208 [d] \\ [m]. To see this, we use Observation 5.2, and we note that for each i, j \u2208 [d] such that ui 6= 0 and uj 6= 0, then h\u2032i(u2i ) = h\u2032j(u2j ). In particular, choosing i \u2208 S , we see that h\u2032i(u2i ) > 0. But for each i \u2208 [d] \\ [m], hi := 0 implies that h\u2032i(u2i ) = 0. In particular, for i \u2208 [d] \\ [m], ui = 0.\nNow suppose that there are two stationary points v and w meeting the requirements of this Claim. By Observation 5.2, there exists \u03bbv and \u03bbw such that h\u2032i(v 2 i ) = \u03bbv and h \u2032 i(w 2 i ) = \u03bbw for each i \u2208 S . If \u03bbv < \u03bbw, then strict monotonicity of each h\u2032i implies that v 2 i < w 2 i for each i \u2208 S . But this contradicts that \u2211\ni\u2208S v 2 i = 1 =\n\u2211\ni\u2208S w 2 i . By similar reasoning, it cannot be that \u03bbw < \u03bbv. As such, \u03bbv = \u03bbw, and further\nfor each i \u2208 S it follows that h\u2032i(v2i ) = h\u2032i(w2i ). Using strict monotonicity of the h\u2032is, we see that v = w. Note that the v constructed in Claim 5.3.1 gives the unique solution to this Claim.\nWe now demonstrate that all stationary points except z1, . . . , zm of G|Qd\u22121+ are unstable. Most of the difficulty will arise when considering a stationary point v of G such that vi 6= 0 for each i \u2208 [m]. We will first demonstrate that such a stationary point of G is unstable. Actually we will prove something stronger, namely that within any neighborhood N of such a choice of v, there exists a vector u(0) \u2208 N such that the resulting sequence {u(n)}\u221en=0 defined recursively by u(n) = G(u(n \u2212 1), then mini\u2208[m] ui(n) \u2192 0 as n \u2192 \u221e. We will generalize this result to the other relevant stationary points of G. The following Lemma captures the main technical difficulties.\nLemma 5.4. Let v \u2208 Qd\u22121+ be a stationary point of G such that vi 6= 0 for each i \u2208 [m] and vi = 0 for each i \u2208 [d] \\ [m]. Let {u(n)}\u221en=0 be a sequence defined recursively by u(n) = G(u(n \u2212 1)) with base element u(0) 6= v such that ui(0) 6= 0 for each i \u2208 [m] and ui(0) = 0 for each i \u2208 [d] \\ [m]. We define the sets \u039b+n := {i \u2208 [m] | ui(n) \u2265 vi} and \u039b\u2212n := {i \u2208 [m] | ui(n) < vi}. Then, the following hold:\n1. The sets \u039b+n and \u039b \u2212 n are non-empty for each n \u2208 N \u222a {0}. 2. Define Mn := max{uj(n)/vjui(n)/vi | j \u2208 \u039b + n , i \u2208 \u039b\u2212n }. Then M0 > 1, and there exists a constant C > 1\nsuch that Mn > C nM0 (12)\nfor each n \u2208 N. At this point, it is worth noting a key difference in the structure of the sequences {u(n)}\u221en=0 in this work and in the most closely related works (i.e., [2, 25]). In these other works, the contrasts gi satisfy a homogeneity assumption, namely that for some fixed r > 2, gi(\u03b1x) = \u03b1rgi(x) when \u03b1 \u2265 0 and x \u2265 0. Then, on its positive domain, gi becomes simply gi(x) = xrgi(1). Given any starting point u(0), homogeneity implies an ordering on [m] defined by i & j if |ui|r\u22122(0)gi(1) > |uj |r\u22122(0)gj(1) such that |ui(n)| |uj(n)| \u2192 \u221e as a strictly increasing if i & j (see e.g., the proof of Theorem 4.2 in the long version of [25]). This ordering provides a complete characterization of the basins of attraction for the gradient iteration with homogeneity. We assume neither homogeneity nor such an ordering. Nevertheless, we are able to obtain the slightly weaker guarantee maxi,j\u2208[m] |ui(n)| |uj(n)| \u2192 \u221e as a strictly increasing sequence as an implication of Lemma 5.4, which is sufficient to show that the Gs only stable fixed points are the hidden basis elements.\nProof of Lemma 5.4. We first prove part 1. Since u(0) 6= v, it follows that there exists i \u2208 [m] such that ui(0) 6= vi. Further, since \u2211 i\u2208[m] u 2 i = \u2211 i\u2208[m] v 2 i = 1, the existence of i \u2208 [m] such that ui(0) < vi (or ui(0) > vi resp.) implies the existence of j \u2208 [m] such that uj(0) > vi (or uj(0) < vj resp.). Thus \u039b+0 and \u039b\u22120 are both non-empty.\nWe proceed by induction on n. In particular, assume that \u039b+n\u22121 and \u039b \u2212 n\u22121 are non-empty. Let us assume\nthat i \u2208 \u039b+n\u22121 and j \u2208 \u039b\u2212n\u22121. Then,\nuj(n) ui(n) = Gj(u(n \u2212 1)) Gi(u(n\u2212 1)) = h\u2032j(uj(n\u2212 1)2)uj(n\u2212 1) h\u2032i(ui(n\u2212 1)2)ui(n\u2212 1) .\nBy Observation 5.2, there exists \u03bb 6= 0 such that h\u2032\u2113(v2\u2113 ) = \u03bb for each \u2113 \u2208 [m]. Since each h\u2032\u2113 is strictly increasing on [0, 1] from h\u2032\u2113(0) = 0 for each \u2113 \u2208 [m] (see Lemma 3.1), since uj(n \u2212 1) < vj , and since ui(n \u2212 1) \u2265 vi, it follows that uj(n)ui(n) < \u03bbuj(n\u22121) \u03bbui(n\u22121) < vj vi\n. In particular, u(n) 6= v(n). We note that for each \u2113 6\u2208 [m], u\u2113(n) = 0 since h\u2113 := 0. Then, it follows by the the same reasoning that made both \u039b+0 and \u039b\u22120 non-empty that \u039b+n and \u039b \u2212 n are both non-empty.\nWe now prove part 2. By part 1, there exists i \u2208 \u039b\u22120 and j \u2208 \u039b+0 . In particular, M0 \u2265 uj(0)/vj ui(0)/vi > 1. There exists \u03b7 \u2208 (0, 12) such that M0 > 1 + \u03b7. Claim 5.4.1. Let w 6= v be a vector such that wi 6= 0 for each i \u2208 [m] and wi = 0 for each i 6\u2208 [m]. Let (k, \u2113) = arg max(i,j){ wi/viwj/vj | (i, j) \u2208 [m] \u00d7 [m]}. If wk/vk w\u2113/v\u2113\n\u2265 M0 then there exists a constant C > 1 depending only on \u03b7 such that G(wk)/vkG(w\u2113)/v\u2113 > C wk/vk w\u2113/v\u2113 .\nProof of claim. Explicit calculation yields:\nG(wk)/vk G(w\u2113)/v\u2113 = h\u2032k(w 2 k)wk/vk h\u2032\u2113(w 2 \u2113 )w\u2113/v\u2113 . (13)\nPart 1 with the sequence {u(n)}\u221en=0 constructed such that u(0) = w implies that wk \u2265 vk and w\u2113 < v\u2113. By assumption, wk/vkw\u2113/v\u2113 \u2265 M0 > 1 + \u03b7. One of the following conditions must hold: either wk/vk > 1 + \u03b7/4 or w\u2113/v\u2113 < 1\u2212 \u03b7/4. In particular, if neither condition holds, then we obtain:\nwk/vk w\u2113/v\u2113 \u2264 1 + \u03b7/4 1\u2212 \u03b7/4 = 1 + \u03b7/2 1\u2212 \u03b7/4 < 1 + \u03b7\nusing that 1\u2212 \u03b7/4 < 12 . This yields a contradiction. Using Observation 5.2, there exists \u03bb such that \u03bb = h\u2032i(v 2 i ) for each i \u2208 [m]. Since h\u2032i is a strictly increasing function on [0, 1], there exists C > 1 which depends only on \u03b7 satisfying\n1. Whenever x > vi + \u03b7/4, then h\u2032i(x 2) \u03bb > C for each i \u2208 [m]. 2. Whenever x < vi \u2212 \u03b7/4, then h \u2032 i(x 2) \u03bb < 1 C for each i \u2208 [m].\nWith this choice of C , continuing from equation (13), we obtain:\nG(wk)/vk G(w\u2113)/v\u2113 = h\u2032k(w 2 k)/\u03bb h\u2032\u2113(w 2 \u2113 )/\u03bb \u00b7 wk/vk w\u2113/v\u2113 > C wk/vk w\u2113/v\u2113 . \u25b3\nWe now proceed by induction on n in showing that equation (12) holds. Equation (12) holds trivially when n = 0. Now suppose that equation (12) holds for n = N\u22121. If we let (k, \u2113) = arg max(i,j){ ui(N\u22121)/viuj(N\u22121)/vj | (i, j) \u2208 [m]\u00d7 [m]}, then it follows that\nmax (i,j)\u2208[m]2 ui(N)/vi uj(N)/vj = max (i,j)\u2208[m]2 G(ui(N \u2212 1))/vi G(uj(N \u2212 1))/vj \u2265 G(uk(N \u2212 1))/vkG(u\u2113(N \u2212 1))/v\u2113 > C \u00b7 CN\u22121M0 = CNM0 .\nHere, the strict inequality follows from the inductive hypothesis and Claim 5.4.1.\nProposition 5.5. Any stationary point of G|Qd\u22121+ not contained in the set {zi | i \u2208 [m]} is unstable.\nProof. We do this proof in three cases for a choice of stationary point v \u2208 Qd\u22121+ such that v 6\u2208 {zi | i \u2208 [m]}. Case 1. For each i \u2208 [m], vi 6= 0.\nLemma 5.3 implies that vi = 0 for each i 6\u2208 [m]. We assume that m \u2265 2 since otherwise v = z1 and there is nothing to prove. We construct a sequence {u(n)}\u221ei=0 such that u(0) 6= v, ui(0) 6= 0 for each i \u2208 [m], ui(0) = 0 for each i \u2208 [d \\ [m], and u(n) = G(u(n \u2212 1)) for each n > 0. Defining Mn := max(i,j) ui(n)/vi(n) uj(n)/vj (n)\nas in Lemma 5.4, we get that Mn \u2192 \u221e as n \u2192 \u221e. Since ui(n)/vi \u2264 maxj\u2208[m](1/vj) is finitely bounded for each i \u2208 [m], this implies that mini\u2208[m] ui(n)/vi \u2192 0 as n \u2192 \u221e. Hence, mini\u2208[m] ui(n) \u2192 0 as n \u2192 \u221e. In particular, v is unstable.\nCase 2. There exists at least one i \u2208 [m] such that vi 6= 0.\nWe will reduce this case to that of case 1.\nLet \u039b = {i : vi 6= 0} be enumerated as i1, . . . , ik, and let A = {u \u2208 Qd\u22121+ | ui = 0 if i 6\u2208 \u039b}. We define a bijection \u03c8 : Qd\u22121+ |A \u2192 Qk\u22121+ as \u03c8j(u) = uij . We define F\u0303 : Rk \u2192 R and G\u0303 : Sk\u22121 \u2192 Sk\u22121 as F and G similar to before except on the image of \u03c8:\nF\u0303 (u\u0303) =\nk \u2211\nj=1\ngij (u\u0303j) G\u0303(u\u0303) = { \u2207F\u0303 (u\u0303) \u2016\u2207F\u0303 (u\u0303)\u2016 if \u2207F\u0303 (u\u0303) 6= 0 u\u0303 otherwise .\nWe note that F\u0303 is a PBEF in a lower dimensional space. Since Gi(u) = \u2202iF (u)\u2016F (u)\u2016 = 2h\u2032i(u 2 i )ui\n\u2016F (u)\u2016 , it follows that when ui = 0, then Gi(u) = 0. In particular for any u \u2208 A it can be seen that G(u) = \u03c8\u22121(G\u0303(\u03c8(u))).\nBut by case 1, \u03c8(v) is an unstable point of G\u0303. More precisely, the proof of case 1 implies (1) {i1, i2, . . . , ik} \u2282 [m] and (2) Given any neighborhood N of \u03c8(v), there exists j \u2208 [k] and a sequence {x(n)}\u221ei=0 in Rk defined recursively by the rule x(n) = G\u0303(x(n\u2212 1)) such that xi(n) \u2192 0 as n \u2192 \u221e. Note that the sequence {u(n)}\u221en=0 defined by u(0) = \u03c8\u22121(x(0)) and recursive step u(n) = G(u(n \u2212 1)) also obeys the rule u(n) = \u03c8\u22121(x(n)). In particular, uij (n) \u2192 0 as n \u2192 0. Since \u2016\u03c8(v)\u2212x(0)\u2016 = \u2016v\u2212u(0)\u2016, and since the neighborhood N is arbitrary, this implies that v is unstable.\nAlgorithm 2 A practical algorithm which uses Gradient Iteration to recover the hidden basis. The inputs are m\u0302 which is the desired number of basis elements to recover, and N which determines how long to run the gradient iteration algorithm when attempting to achieve convergence. If k = min(m, m\u0302), then the first k outputs \u00b51, . . . ,\u00b5k recover estimates to a subset of z1, . . . , zm.\nfunction PRACTICALGI-RECOVERY(m\u0302, N ) for i \u2190 1 to m\u0302 do\nGenerate u uniformly at random in Sd\u22121 \u2229 span(\u00b51, . . . ,\u00b5i)\u22a5 repeat\nu \u2190 G(u) until Convergence (up to sign) \u00b5i \u2190 u\nend for return \u00b51, . . .\u00b5m\u0302\nend function\nCase 3. For each i \u2208 [m], vi = 0.\nIn this case, \u2207F (v) = 0, leading to the degenerate update G(v) = v. We may fix any \u03b4 > 0, and we let u = [(1\u2212 \u03b4)v\u30082\u3009 + \u03b4z1]\u3008 1 2 \u3009. Then \u22021F (u) > 0 and \u2202iF (u) = 0 for each i 6= 1 implies that G(u) = z1, which is a fixed point of G. In particular, defining a sequence recursively by u(n) = G(u(n \u2212 1)) with base element u(0) = u yields a sequence for which \u2016u(n) \u2212 v\u2016 = 1/ \u221a 2 for each n \u2265 1. As u(0) can\nbe chosen arbitrarily close to v, it follows that v is unstable.\nUnder Corollary 4.4 and the subsequent discussion, Theorem 2.2 is implied by Propositions 5.1 and 5.5.\nThe stability structure the fixed points of G/\u223c suggest a very practical algorithm for recovering the hidden basis elements z1, . . . , zm which we outline in PRACTICALGI-RECOVERY (Algorithm 2). The idea is as follows: We first choose a random starting point u on the unit sphere and apply G (or an approximation G\u0302 of G) repeatedly. We would expect the resulting sequence to converge to one of the stable points zi for i \u2208 [m]. Given an estimate to zi, we may choose a new starting on the orthogonal space Sd\u22121 \u2229 z\u22a5i , and noting that F |\nz \u22a5 i\nis also a BEF encoding the basis elements z1, . . . , zi\u22121, zi+1, . . . , zm, we would expect a\nsequence starting in Sd\u22121 \u2229 z\u22a5i to recover one of the other hidden basis elements. In Section 6, we will show that this practical algorithm can be modified to give a deterministic algorithm\nwith full recovery guarantees."}, {"heading": "5.2 Fast convergence of the gradient iteration", "text": "We now proceed with the proof of Theorem 2.3. The stability analysis relied on the change of variable u 7\u2192 u\u30082\u3009 (which gave rise to the definitions of hi for i \u2208 [d]) due the fact that for each i \u2208 [m], gi(x1/2) is convex on [0, 1]. The fast convergence of the gradient iteration algorithm relies on a more general change of variable u 7\u2192 u\u3008r\u3009 where r \u2265 2, and in particular it is assumed that gi(x1/r) is convex on [0, 1] for each i \u2208 [m]. We encode this potentially stronger convexity constraint within our BEF by extending the definition of the hi\u2019s from section 3 to the more general family of maps \u03b3\u2032ir : [0, 1] \u2192 R defined by \u03b3ir(x) := gi(x 1 r ) for i \u2208 [m] and \u03b3ir = 0 for i 6\u2208 [m]. We note that hi = \u03b3i2 on [0, 1] for each i \u2208 [d]. We then write\nF (u) = m \u2211\ni=1\ngi(ui) = m \u2211\ni=1\n\u03b3ir(u r i ) , (14)\nwhere each \u03b3ir is a convex function.\nLemma 5.6. For i \u2208 [m], the functions \u03b3\u2032ir and \u03b3\u2032i2 are related by \u03b3\u2032ir(x) = 2r\u03b3\u2032i2(x 2 r )x 2\u2212r r on the domain (0, 1].\nProof. This is by direct computation. We have the formulas:\n\u03b3\u2032i2(x) = 1 2 g\u2032i(x 1 2 )x\u2212 1 2 \u03b3\u2032ir(x) = 1 r g\u2032i(x 1 r )x 1\u2212r r\nWe may rewrite \u03b3\u2032ir(x) as follows:\n\u03b3\u2032ir(x) = 2 r \u00b7 1 2 g\u2032i((x 2 r ) 1 2 )(x 2 r )\u2212 1 2x 2\u2212r r = 2 r \u03b3\u20322(x 2 r )x 2\u2212r r .\nProposition 5.7. Suppose that {u(n)}\u221en=0 is a sequence in Qd\u22121+ defined recursively by u(n) = G(u(n\u22121)) which converges to a zj for some j \u2208 [m]. Then, the following hold:\n1. The sequence {u(n)}\u221en=0 converges to zj at a super-linear rate. 2. Fix r \u2265 2. If x 7\u2192 gi(x 1 r ) is convex for every i \u2208 [m], then {u(n)}\u221en=0 converges to zj with order of\nconvergence at least r \u2212 1.\nProof. It is sufficient to consider a sequence converging to z1. If there exists n0 such that u(n0) = z1, then there is nothing to prove as z1 is a stationary point of G. So, we assume that u(n) 6= z1 for all n \u2208 N.\nTaking derivatives of F from equation (14), we get: \u2202iF (v) = r\u03b3\u2032ir(v r i )v r\u22121 i . We will make use of the\nfollowing ratios in analyzing the rate of convergence of u(n):\n\u03c1(i, j;n) := ui(n)\nuj(n) = \u03b3\u2032ir(ui(n\u2212 1)r)ui(n\u2212 1)r\u22121 \u03b3\u2032jr(uj(n\u2212 1)r)uj(n\u2212 1)r\u22121 .\nDefine U = \u03b3\u20321r(1) and L = maxj 6=1{limx\u21920+ \u03b3\u2032jr(x)}. We note that the strict convexity of x 7\u2192 gi( \u221a x) (for i \u2208 [m]) implies that \u03b3\u2032i2(1) > 0, and since Lemma 5.6 implies \u03b3\u2032ir(1) = 2r\u03b3\u2032i2(1) > 0, it follows that U > 0. Since \u03b3ir is convex, \u03b3\u2032jr is a non-decreasing function. It follows that L is well defined and is also equal to maxj 6=1{infx>0 \u03b3\u2032jr(x)}. Finally, noting that \u03b3\u2032i2 is non-negative on [0, 1] (indeed, \u03b3\u2032i2 is increasing from \u03b3\u2032i2(0) = 0 by Lemma 3.1), it follows from Lemma 5.6 that \u03b3 \u2032 ir(x) \u2265 0 for all x > 0, and in particular m \u2265 0. Fix \u01eb \u2208 (0, 12U). There exists \u03b4 > 0 such that:\n1. If v \u2208 Qd\u22121+ is such that 1 \u2212 v1 < \u03b4, then \u03b3\u20321r(u1) > U \u2212 \u01eb. The existence of such a choice for \u03b4 is implied by the continuity of g\u20321 and hence \u03b3 \u2032 1r near 1.\n2. If v \u2208 Qd\u22121+ is such that vj < \u03b4 for some j 6= 1, then \u03b3\u2032jr(uj) < L + \u01eb. The existence of such a \u03b4 follows from the characterization of L as maxj 6=1{infx>0 \u03b3\u2032jr(x)} and \u03b3\u2032jr being non-increasing on [0, 1].\nFix N sufficiently large that for each n \u2265 N , \u2016z1 \u2212 u(n)\u20161 < \u03b4. With any fixed j 6= 1 and n \u2265 N + 1, it follows that\n\u03c1(j, 1;n) = \u03b3\u2032jr(uj(n \u2212 1)r)uj(n\u2212 1)r\u22121 \u03b3\u20321r(ui(n\u2212 1)r)u1(n\u2212 1)r\u22121 < L+ \u01eb U \u2212 \u01eb \u00b7 uj(n\u2212 1)r\u22121 u1(n\u2212 1)r\u22121 .\nDenote by u\u2032 the vector \u2211d\ni=2 uizi. Then,\n\u2016z1 \u2212 u(n)\u2016 = \u2016z1(1\u2212 u1(n))\u2212 (u(n)\u2212 u1(n)z1)\u2016 \u2264 \u2016z1(1\u2212 u1(n))\u2016 + \u2016u\u2032(n)\u2016 = 1\u2212 u1(n) + \u2016u\u2032(n)\u2016 .\nSince u is a unit vector, we see that u1(n)+\u2016u\u2032(n)\u2016 \u2265 u1(n)2+\u2016u\u2032(n)\u20162 = 1. It follows that 1\u2212u1(n) \u2264 \u2016u\u2032(n)\u2016. Thus,\n\u2016z1 \u2212 u(n)\u2016 \u2264 2\u2016u\u2032(n)\u2016 \u2264 2\u2016u\u2032(n)\u20161 = 2 d \u2211\ni=2\nui(n) \u2264 2\u03c1(i, 1;n) < 2 \u00b7 L+ \u01eb U \u2212 \u01eb \u00b7 uj(n\u2212 1)r\u22121 u1(n\u2212 1)r\u22121 .\nIn particular,\n\u2016z1 \u2212 u(n)\u2016 < 2 \u00b7 L+ \u01eb (U \u2212 \u01eb)r \u00b7 uj(n\u2212 1) r\u22121 .\nSince uj(n\u2212 1) \u2264 \u2016z1 \u2212 u(n\u2212 1)\u2016, it follows that:\n\u2016z1 \u2212 u(n)\u2016 \u2016z1 \u2212 u(n\u2212 1)\u2016r\u22121 < 2 \u00b7 L+ \u01eb (U \u2212 \u01eb)r\u22121 .\nAs the right hand side is a finite constant, the sequence has order of convergence at least r \u2212 1. In the case where r = 2, Lemma 3.1 combined with the fact that \u03b3i2 = 0 for each i \u2208 [d] \\ [m] implies that limx\u21920+ \u03b3 \u2032 i2(x) = 0 for each i \u2208 [d]; and in particular, L = 0. Since \u01eb can be chosen arbitrarily small, the sequence {u(n)}\u221en=0 has super-linear convergence even when r = 2.\nUnder Corollary 4.4 and the subsequent discussion, part 1 of Theorem 2.3 is implied by Proposition 5.7. Part 2 of Theorem 2.3 follows from the fact that for any i such that u \u22a5 zi, then \u2202iF (u) = 0 implies that G(u) \u22a5 zi. In particular, induction implies that for a sequence defined recursively by u(n) = G(n) and u(0) \u22a5 zi, then u(n) \u22a5 zi for all n \u2208 N, and hence u(n) 6\u2192 zi."}, {"heading": "6 A robust gradient iteration algorithm", "text": "In section 5, we saw that the only stable fixed points of the gradient iteration correspond to the hidden basis elements zi and that convergence to these points is super-linear. Nevertheless, the analysis is incomplete for two reasons: First, it is possible (though probably unlikely) for the gradient iteration to converge to an unstable fixed point and therefore fail to recover any basis vector zi. Second, in many practical settings, we would have evaluation access to an approximation F\u0302 of F . In this section, we propose and analyze an algorithm which is guaranteed to approximately recover the hidden basis elements z1, . . . , zm given access to F\u0302 and its first and second derivatives. Hatted objects such as F\u0302 and G\u0302 will represent the natural estimates of un-hatted objects, and in particular G\u0302(u) := {\n\u2207F\u0302 (u)/\u2016\u2207F\u0302 (u)\u2016 if \u2207F\u0302 (u) 6= 0 u otherwise .\nThroughout this section, we will assume that F is an (cmin, cmax)-robust BEF and that F\u0302 is an \u01ebapproximation to F . That is (recalling the definitions from section 2.2), we assume that for strictly positive constants cmin and cmax, each gi satisfies the following robust version assumption A2:\nA2\u2032. For each i \u2208 [m] and each x0 \u2208 [\u22121, 1], \u2223 \u2223 \u2223 d2\ndx2 gi( \u221a x)|x=x0 \u2223 \u2223 \u2223 \u2208 [cmin, cmax].\nWe further assume that for some choice of \u01eb > 0 and for each u \u2208 B(0, 1), we have that |F\u0302 (u)\u2212 F (u)| \u2264 \u01eb, \u2016\u2207F\u0302 (u)\u2212\u2207F (u)\u2016 \u2264 \u01eb, and \u2016HF\u0302 (u)\u2212HF (u)\u2016 \u2264 \u01eb.\nUnder these assumptions, FINDBASISELEMENT (page 21) robustly recovers a single hidden basis element \u00b1zi using F\u0302 and its derivatives. Further, FINDBASISELEMENT may be run repeatedly to recover all hidden basis elements. We have the following main theoretical results:\nTheorem 6.1. Suppose \u01eb \u2264 7cmin 10240 \u221a 2m3/2d2 \u00b7 ( cmin cmax )7/2 . Let k < m be non-negative, let p be a permutation of [m], and let s1, . . . , sk \u2208 {\u22121,+1} be sign values such that \u2016si\u00b5i \u2212 zp(i)\u2016 \u2264 4m \u221a 2d cmin \u01eb for each i \u2208\nAlgorithm 3 Perform the gradient iteration for a predetermined number of iterations. The inputs are u(0) (an initialization vector) and N (the number of iterations). The output is u(N) (the N th element of the resulting gradient iteration sequence).\nfunction GI-LOOP(u(0), N ) for n \u2190 1 to N do\nu(n) \u2190 G\u0302(u(n\u2212 1)) end for return u(N)\nend function\n[k]. Suppose N1 \u2265 log2( cmin8\u221a2m3/2\u01eb \u00b7 ( cmin cmax\n)1/2) and N2 \u2265 320c 2 maxmd\n3c2min loge\n( 2 \u221a 2mcmax cmin ) + log2( cmin 8 \u221a 2m3/2\u01eb\n\u00b7 ( cmincmax )\n1/2) + 1. If we execute \u00b5k+1 \u2190 FINDBASISELEMENT({\u00b51, . . . ,\u00b5k}, m\u0302) for any choice of m\u0302 \u2265 m, then there will exist a sign value sk+1 \u2208 {+1,\u22121} and an index j \u2208 [m]\\[k] such that \u2016sk+1\u00b5k+1\u2212zp(j)\u2016 \u2264 4m \u221a d\ncmin \u01eb.\nTheorem 6.2. Suppose that \u01eb \u2264 7cmin 10240 \u221a 2m3/2d2 \u00b7 ( cmin cmax )7/2 . Suppose that m\u0302 \u2265 m, that N1 \u2265 log2( cmin8\u221a2m3/2\u01eb \u00b7 ( cmincmax ) 1/2), and that N2 \u2265 log2( cmin8\u221a2m3/2\u01eb \u00b7 ( cmin cmax )1/2) + 320c 2 maxmd 3c2min loge ( 2 \u221a 2mcmax cmin ) + 1. If we execute\n\u00b51, . . . ,\u00b5m\u0302 \u2190 ROBUSTGI-RECOVERY(m\u0302), then \u00b51, . . . ,\u00b5m forms a 4m \u221a 2d\ncmin \u01eb-approximation to the hid-\nden basis. More precisely, there exists a permutation \u03c9 of [m] and signs s1, . . . , sm \u2208 {+1,\u22121} such that \u2016si\u00b5i \u2212 z\u03c9(i)\u2016 \u2264 4m \u221a 2d cmin \u01eb for each i \u2208 [m].\nThe parameters N1 and N2 determine the running time of ROBUSTGI-RECOVERY. In particular, ROBUSTGIRECOVERY uses O(m\u03022(N1+N2)) oracle steps including O(m\u03022) eigendecompositions of HF\u0302 and O(m\u03022[N1+ N2]) evaluations of \u2207F\u0302 to compute gradient iteration updates. When the desired number of basis elements m is known, then m\u0302 can be chosen as m. When the number of basis elements is unknown, then m\u0302 may be chosen as d, and in a more practical setting the values of \u2016\u2207F\u0302 (\u00b5\u2113)\u2016 may be thresholded to determine which returned vectors correspond to hidden basis elements. To obtain the time bound seen in Theorem 2.4, we choose N1 = N2, we note that the main loop runs at most m\u03022 times, and we use a somewhat larger, simplified lower bound for m\u03022N2 + Cm\u0302d2 as our lower bound for N (with C a constant). The Cm\u0302d2 portion of this bound comes from step 3, which can be implemented using Gram-Schmidt orthogonalization involving the \u00b5is and canonical vectors in the ambient space.\nIn addition, we note that F is an \u01eb-approximation to itself for any \u01eb > 0. As such, Theorem 6.2 also implies a polynomial time algorithm for recovering each hidden basis element within arbitrary precision. In particular, the following Corollary of Theorem 6.2 characterizes the running time of ROBUSTGI-RECOVERY as a function of the precision of the hidden basis estimate.\nCorollary 6.3. Let \u03b4 \u2208 (\n0, 7 2560m1/2d \u00b7 ( cmin cmax\n)7/2 ]\nand let m\u0302 \u2265 m. Suppose that F\u0302 is a cmin 4m \u221a 2d -approximation\nof F , N1 \u2265 log2( \u221a cmind 2\u03b4 \u221a cmaxm ), and N2 \u2265 log2( \u221a cmind 2\u03b4 \u221a cmaxm ) + 320c 2 maxmd 3c2min loge ( 2 \u221a 2mcmax cmin ) + 1. After executing \u00b51, . . . ,\u00b5m\u0302 \u2190 ROBUSTGI-RECOVERY(m\u0302), then \u00b51, . . . ,\u00b5m forms a \u03b4-approximation to the hidden basis. More precisely, there exists a permutation \u03c9 of [m] and signs s1, . . . , sm \u2208 {+1,\u22121} such that \u2016si\u00b5i \u2212 z\u03c9(i)\u2016 \u2264 \u03b4 for each i \u2208 [m].\nThe proof of Theorem 6.1 has a number of technical details. We define several projections of particular interest: (1) P\u2295u := \u2211m i=1 uizi and (2) P0u := \u2211d i=m+1 uizi. Further, given a set S \u2282 [d], we will denote its complement by S\u0304 := [d] \\ S and the associated projection PSu := \u2211\ni\u2208S uizi. At a high level, we demonstrate two things. First, we show that starting with step 5, \u2016P0u\u2016 is small for every for every\nAlgorithm 4 A robust extension to the gradient iteration algorithm for guaranteed recovery of a single hidden basis element. In this algorithm, given a vector u \u2208 Sd\u22121, U\u0302(u)\u039b\u0302(u)U\u0302 (u)T is the eigendecomposition of H\u0302F (u) with eigenvalues \u03bb\u0302i(u) = \u039b\u0302ii(u) ordered as |\u03bb1(u)| \u2264 \u00b7 \u00b7 \u00b7 \u2264 |\u03bbd(u)|. We also define \u03bb\u03020(u) = 0 as it will simplify some steps. Inputs: {\u00b51, . . . ,\u00b5k} A (possibly empty) set of approximate hidden basis directions. m\u0302 The desired number of basis elements. It is required that m\u0302 \u2265 m.\nOutputs: \u00b5 An approximate basis element not estimated by any of \u00b51, . . . ,\u00b5k. 1: function FINDBASISELEMENT({\u00b51, . . . ,\u00b5k}, m\u0302) 2: // Find a starting vector sufficiently outside the subspace span(zm+1, . . . , zd). 3: Let x1, . . . ,xd\u2212k be orthonormal vectors in span(\u00b51, . . . ,\u00b5k)\n\u22a5. 4: j \u2190 arg maxi\u2208[d\u2212k]\u2016\u2207F\u0302 (xi)\u2016 5: u \u2190 G\u0302(xj) // \u201cZero\u201d the values of um+1, . . . , ud. 6: u \u2190 GI-LOOP(u, N1) 7: for i \u2190 1 to m\u0302\u2212 k \u2212 1 do // Start of the main loop 8: if d = arg maxj\u2208[d][|\u03bb\u0302j(u)| \u2212 |\u03bb\u0302j\u22121(u)|] then 9: \u00b5 \u2190 GI-LOOP(U\u0302d(u), N1)\n10: return \u00b5 11: end if 12: // Identify a good new starting location and \u201czero\u201d one of its coordinates 13: for j \u2190 1 to 3 do 14: uj \u2190 U\u03021(u) cos(\u03c03 (j \u2212 1)) + U\u03022(u) sin(\u03c03 (j \u2212 1)) 15: uj \u2190 GI-LOOP(uj , N2) 16: end for 17: \u2113 \u2190 arg minj\u2208[3] |\u03bb\u0302k+i(uj)| 18: u \u2190 GI-LOOP(u\u2113, N1) 19: end for 20: \u00b5 \u2190 u 21: return \u00b5 22: end function\nvector that we run through the gradient iteration. As such, our GI-LOOPs will work essentially within the non-trivial subspace span(z1, . . . , zm). Second, we show that after the ith iteration through the main loop of FINDBASISELEMENT, at least k + i coordinates of u are approximately zeroed with respect to the hidden basis zm+1, . . . , zd. These two parts combine to demonstrate that FINDBASISELEMENT recovers a good approximation of a single hidden basis element. Once Theorem 6.1 is proven, then Theorem 6.2 follows fairly easily by noting that ROBUSTGI-RECOVERY runs FINDBASISELEMENT repeatedly, each time obtaining a new hidden basis element. We now proceed with the proofs."}, {"heading": "6.1 Controlling \u2016P0u\u2016", "text": "The following two Lemmas allow us to demonstrate that \u2016P0u\u2016 becomes small during the gradient iteration updates u \u2190 G\u0302(u) which occur in GI-LOOP. Lemma 6.4. Suppose that \u2016P0u\u2016 \u2264 35 and \u01eb \u2264 12mcmin. Then, \u2016P0G\u0302(u)\u2016 \u2264 2mcmin \u01eb. Proof. The proof uses the following auxiliary result:\nClaim 6.4.1. If \u2016P\u2295u\u2016 > 0 and there exists \u03b3 \u2208 (0, 1] such that \u01eb \u2264 \u03b3mcmin\u2016P\u2295u\u20163, then \u2016P0G\u0302(u)\u2016 \u2264 \u03b3.\nAlgorithm 5 A robust algorithm to recover approximations to all of the hidden basis elements. Inputs: m\u0302 The desired number of basis elements to recover. It is required that m\u0302 \u2265 m.\nOutputs: \u00b51, . . . ,\u00b5m\u0302 The first m of these are approximate hidden basis elements. 1: function ROBUSTGI-RECOVERY(m\u0302) 2: for i \u2190 1 to m\u0302 do 3: \u00b5i \u2190 FINDBASISELEMENT({\u00b51, . . . ,\u00b5i\u22121}, m\u0302) 4: end for 5: return \u00b51, . . . ,\u00b5m\u0302 6: end function\nProof of Claim. Using Lemma B.1, we note that \u2016\u2207F (u)\u2016 \u2265 2mcmin\u2016P\u2295u\u20163. As such, we see:\n\u2016P0G\u0302(u)\u2016 = \u2016P0\u2207F\u0302 (u)\u2016 \u2016\u2207F\u0302 (u)\u2016 \u2264 \u01eb\u2016\u2207F (u)\u2016 \u2212 \u01eb \u2264 \u01eb\n2 mcmin\u2016P\u2295u\u20163 \u2212 \u01eb \u2264 \u01eb1 mcmin\u2016P\u2295u\u20163 .\nIn the last step, we use that \u01eb \u2264 \u03b3mcmin\u2016P\u2295u\u20163 \u2264 1mcmin\u2016P\u2295u\u20163. Using the given bound on \u01eb, we see that \u2016P0G\u0302(u)\u2016 \u2264 \u03b3 as desired. \u25b3\nNow, by the bound on \u2016P0u\u2016, we see that \u2016P\u2295u\u20163 = (1\u2212\u2016P0u\u20162)3/2 \u2265 (45)3 \u2265 12 . Choosing \u03b3 = 2m\u01ebcmin , we see that \u01eb \u2264 \u03b3mcmin\u2016P\u2295u\u20163. Thus, Claim 6.4.1 gives the desired result.\nLemma 6.5. Let S = {\u00b51, . . . ,\u00b5k} be the set of unit vectors passed into FINDBASISELEMENT. Suppose that k < m, that there exists \u03b4 \u2208 [0, 14dm ), and that there exists a permutation \u03c0 on [m] and sign values s1, . . . , sk such that for each i \u2208 [k], \u2016si\u00b5i\u2212z\u03c0(i)\u2016 \u2264 \u03b4. Then, at the end of step 5 of FINDBASISELEMENT, the following hold:\n1. If \u01eb \u2208 [0, cmin md3/2 ], then \u2016P0u\u2016 \u2264 md 3/2 cmin \u01eb. 2. If \u01eb \u2208 [0, c 3/2 min\n8(2)3/4md3/2c 1/2 max\n], \u03b4 \u2264 4m \u221a 2d\ncmin \u01eb, and i \u2208 {\u03c0(j) | j \u2208 [k]}, then |ui| \u2264 3md\n3/2\ncmin \u01eb.\nProof of Lemma 6.5. First, we demonstrate that one of the vectors xi for i \u2208 [d \u2212 k] from step 3 of FINDBASISELEMENT has \u2016P\u2295xi\u20162 \u2265 m\u2212kd . We then use this to demonstrate that for the chosen value of j in step 4, \u2016P0G\u0302(xj)\u2016 is small. Claim 6.5.1. There exists i \u2208 [d\u2212 k] such that \u2016P\u2295xi\u20162 \u2265 m\u2212kd .\nProof of Claim. We define the projection operators PSv := \u2211k i=1 v\u03c0(i)z\u03c0(i) and PS\u0303v := \u2211m\ni=k+1 v\u03c0(i)z\u03c0(i). Notice that \u2016P\u2295v\u2016 \u2265 \u2016PS\u0303v\u2016 for any v \u2208 Rd.\nWe extend the list of vectors x1, . . . ,xd\u2212k to be an orthonormal basis of the space: x1, . . . ,xd. Since each zi is a unit vector, it follows:\n1\nd\n[ d \u2211\ni=1\n\u2016PS\u0303xi\u20162 ] = 1\nd\nm \u2211\nj=k+1\n[ d \u2211\ni=1\n\u3008xi, z\u03c0(j)\u30092 ] = m\u2212 k\nd . (15)\nTreating equation (15) as a sample average, there exists i \u2208 [d] such that \u2016PS\u0303xi\u2016 \u2265 m\u2212kd . To complete the proof, we need only demonstrate that for any i > d\u2212 k, \u2016PS\u0303u\u2016 < m\u2212kd . To show this, we first demonstrate that \u00b51, . . . ,\u00b5k span a k dimensional space. Note that this implies that x1, . . . ,xd\u2212k\nspan the space span(\u00b51, . . . ,\u00b5k) \u22a5. Therefore, for any i > d\u2212 k we have xi \u2208 span(\u00b51, . . . ,\u00b5k). Then to complete the proof, we demonstrate that for any v \u2208 span(\u00b51, . . . ,\u00b5k), we have \u2016PS\u0303u\u2016 < m\u2212kd . We now consider the matrices A = A0 = \u2211k i=1 \u00b5i\u00b5 T i and A\u0303 = A\u03030 = \u2211k i=1 z\u03c0(i)z T \u03c0(i). We note:\n\u2016A0 \u2212 A\u03030\u2016 = \u2225 \u2225 \u2225\nk \u2211\ni=1\n[(\u00b5i \u2212 z\u03c0(i))\u00b5Ti + zi(\u00b5i \u2212 zi)T ] \u2225 \u2225 \u2225 \u2264 2\nk \u2211\ni=1\n\u2016\u00b5i \u2212 z\u03c0(i)\u2016\u2016\u00b5i\u2016 \u2264 2k\u03b4 < k\n2dm .\nIn particular, Weyl\u2019s inequality (reproduced in Theorem C.1) implies that the kth lowest eigenvalue \u03bbk(A0) > 1\u2212 k2dm > 0. As such, the vectors \u00b51, . . . ,\u00b5k ar linearly independent. As the k eigenvalues of A0 are contained in the interval [1\u2212 k2dm , 1+ k2dm ] by Weyl\u2019s inequality, Theorem C.2 (the Davis-Kahan sin \u0398 theorem) with A\u03031 = \u2211d i=k+1 0z\u03c0(i)z T \u03c0(i), implies that\n[ 1\u2212 k 2dm ] \u2016Pspan(z\u03c0(k+1),...,z\u03c0(d))Pspan(\u00b51,...,\u00b5k)\u2016 < k 2dm\n\u2016Pspan(z\u03c0(k+1),...,z\u03c0(d))Pspan(\u00b51,...,\u00b5k)\u2016 < k 2dm\u2212 k \u2264 k dm \u2264 1 d \u2264 m\u2212 k d .\nAs such, if v \u2208 span(\u00b51, . . . ,\u00b5k), then \u2016PS\u0303v\u2016 \u2264 \u2016Pspan(z\u03c0(k+1),...,z\u03c0(d))Pspan(\u00b51,...,\u00b5k)\u2016 < m\u2212k d . \u25b3\nWe now fix i \u2208 [d \u2212 k] such that \u2016P\u2295xi\u20162 \u2265 m\u2212kd according to claim 6.5.1, and we fix j according to step 4 from FINDBASISELEMENT. By Lemma B.1, we have \u2016\u2207F (xi)\u2016 \u2265 2cmin(m\u2212k) 3/2\nmd3/2 . As such,\n\u2016\u2207F\u0302 (xj)\u2016 \u2265 \u2016\u2207F\u0302 (xi)\u2016 \u2265 2cmin(m\u2212k) 3/2\nmd3/2 \u2212 \u01eb. We now show part 1:\n\u2016P0G\u0302(xj)\u2016 \u2264 \u01eb \u2016\u2207F\u0302 (xj)\u2016 \u2264 md\n3/2\u01eb\n2cmin(m\u2212 k)3/2 \u2212md3/2\u01eb \u2264 md\n3/2\u01eb\n2cmin \u2212md3/2\u01eb \u2264 md\n3/2\u01eb\ncmin .\nWe now show part 2. We let w = xj . We let \u2113 \u2208 [k], and noting that w \u22a5 \u00b5\u2113 by construction, we obtain the following bound for |w\u03c0(\u2113)|:\n|w\u03c0(\u2113)| = |\u3008xj , z\u03c0(\u2113) \u2212 s\u2113\u00b5\u2113 + s\u2113\u00b5\u2113\u3009| = |\u3008xj , z\u03c0(\u2113) \u2212 s\u2113\u00b5\u2113\u3009| \u2264 \u2016xj\u2016\u2016z\u03c0(\u2113) \u2212 s\u2113\u00b5\u2113\u2016 \u2264 4m\n\u221a 2d\ncmin \u01eb .\nWe now fix i \u2208 {\u03c0(\u2113) | \u2113 \u2208 [k]} and bound |ui| = |G\u0302i(w)|:\n|G\u0302i(w)| \u2264 2|h\u2032i(w2i )wi|+ \u01eb \u2016\u2207F\u0302 (w)\u2016 \u2264 2cmax|wi| 3 + \u01eb 2cmin(m\u2212k)3/2\nmd3/2 \u2212 \u01eb\n= md3/2[2cmax|wi|3 + \u01eb]\n2cmin(m\u2212 k)3/2 \u2212md3/2\u01eb\n\u2264 md3/2[2cmax(\n4m \u221a 2d\ncmin \u01eb)3 + \u01eb]\ncmin \u2264 md\n3/2[2\u01eb+ \u01eb]\ncmin =\n3md3/2\u01eb\ncmin .\nIn the above, the second to last inequality uses that (1) m\u2212 k \u2265 1, (2) that \u01eb \u2264 cmin md3/2 , and (3) our bound on |wi|. The final inequality uses the that \u01eb \u2264 c 3/2 min\n8(2)3/4md3/2c 1/2 max\n< c 3/2 min\n8(2)3/4m3/2d3/4c 1/2 max\n.\nIn addition to controlling \u2016P0u\u2016 under the Gradient iteration update u \u2190 G\u0302(u), we must also control \u2016P0x\u2016 for any x \u2208 span(U\u0302j(u), . . . , U\u0302d(u)) (defined as in steps 9 and 14 of FINDBASISELEMENT). For any such x, the following result demonstrates that \u2016P0x\u2016 is small, and in addition gives conditions into which other coordinates of x are small which will be useful later.\nLemma 6.6. Let u \u2208 Sd\u22121 be fixed. Suppose that \u2016P\u2295u\u2016 > 0 and that \u01eb \u2264 dd+1 \u00b7 \u2016P\u2295u\u20162 dm cmin. Let U\u0302i(u) and \u03bb\u0302i(u) for each i \u2208 [d] \u222a {0} be defined as in FINDBASISELEMENT. Let j = arg maxi\u2208[d][|\u03bb\u0302i(u)| \u2212 |\u03bb\u0302i\u22121(u)|]. Let X = span(U\u0302j(u), . . . , U\u0302d(u)). Let \u03c0 be a permutation of [d] such that when defining \u03bbi := \u2202 2 \u03c0(i)F (u) for each i \u2208 [m] and \u03bb0 = 0, then |\u03bb0| \u2264 |\u03bb1| \u2264 \u00b7 \u00b7 \u00b7 \u2264 |\u03bbd|. Let S = {\u03c0(i) | i < j}. The following hold: 1. If x \u2208 X , then \u2016PSx\u2016 \u2264 dm\u01eb5\u2016P\u2295u\u20162cmin 2. The set [d] \\ [m] \u2282 S . In particular, if x \u2208 X , then \u2016P0x\u2016 \u2264 dm\u01eb5\u2016P\u2295u\u20162cmin . 3. If S \u2032 = {i \u2208 [m] | u2i < 5\u2016P\u2295u\u20162 6dm \u00b7 cmincmax } \u222a ([d] \\ [m]), then S\n\u2032 \u2282 S . In particular, if x \u2208 X then \u2016PS\u2032x\u2016 \u2264 dm\u01eb5\u2016P\u2295v\u20162cmin .\nProof. We will make use of the following Claim:\nClaim 6.6.1. |\u03bb\u0302j | \u2212 |\u03bb\u0302j\u22121| \u2265 6\u2016P\u2295u\u2016 2 dm cmin \u2212 \u01ebd .\nProof of Claim. Since \u2016P\u2295u\u20162 = \u2211m \u0131=1 u 2 i , it follows that there exists \u2113 \u2208 [m] such that u2\u2113 \u2265 \u2016P\u2295u\u20162 m . Using Lemma B.1, we see that |\u03bb\u03c0\u22121(\u2113)| = |\u22022\u2113F (u)| \u2265 6u2\u2113cmin \u2265 6\u2016P\u2295u\u20162\nm cmin. It follows that \u2016[HF\u0302 (u)]z\u2113\u2016 \u2265 \u2016[HF (u)]z\u2113\u2016 \u2212 \u01eb = |\u03bb\u03c0\u22121(\u2113)| \u2212 \u01eb. Thus, maxi\u2208[d] |\u03bb\u0302i| \u2265 |\u03bb\u03c0\u22121(\u2113)| \u2212 \u01eb \u2265 6\u2016P\u2295u\u2016 2\nm cmin \u2212 \u01eb. To complete the proof, we note that |\u03bb\u03020|, . . . , |\u03bb\u0302d| partitions the interval [0,maxi\u2208[d] |\u03bb\u0302i|] into d pieces.\nAs such, |\u03bb\u0302j| \u2212 |\u03bb\u0302j\u22121| \u2265 maxi\u2208[d] |\u03bb\u0302i|\u22120d \u2265 6\u2016P\u2295u\u20162 dm cmin \u2212 \u01ebd . \u25b3\nWe now prove part 1 using the Davis-Kahan sin\u0398 theorem [11] (reproduced in Theorem C.2). Following the notation of Theorem C.2, we partition HF\u0302 (u) into spectral parts A0 = \u2211d i=j \u03bb\u0302iU\u0302i(u)U\u0302i(u) T and A1 = \u2211j\u22121 i=1 \u03bb\u0302iU\u0302i(u)U\u0302i(u) T . We also define the projection operator \u03a00 := \u2211d i=j U\u0302i(u)U\u0302i(u) T . We split HF (u) into its spectral parts A\u03030 = \u2211d i=j \u03bbiz\u03c0(i)z T \u03c0(i) and A\u03031 = \u2211j\u22121 i=1 \u03bbiz\u03c0(i)z T \u03c0(i), and we define the projection operators \u03a0\u03030 = \u2211d i=j z\u03c0(i)z T \u03c0(i) and \u03a0\u03031 = I \u2212 \u03a0\u03030 = \u2211j\u22121 i=1 z\u03c0(i)z T \u03c0(i). The error matrix for Theorem C.2 is precisely H = HF (u)\u2212HF\u0302 (u). Note that the eigenvalues of A0 all lie outside the interval\n[\u2212|\u03bb\u0302j |, |\u03bb\u0302j |] \u2283 [ \u2212 |\u03bb\u0302j\u22121| \u2212 6\u2016P\u2295u\u20162\ndm cmin +\n\u01eb d , |\u03bb\u0302j\u22121|+ 6\u2016P\u2295u\u20162 dm cmin \u2212 \u01eb d ]\nby Claim 6.6.1. Further, the eigenvalues of A\u03031 all lie within [\u2212|\u03bbj\u22121|, |\u03bbj\u22121|] \u2282 [\u2212|\u03bb\u0302j\u22121| \u2212 \u01eb, |\u03bb\u0302j\u22121|+ \u01eb] by Weyl\u2019s inequality (Theorem C.1). Applying the sin \u0398 theorem with \u03b4 = 6\u2016P\u2295u\u2016 2\ndm cmin \u2212 \u01ebd \u2212 \u01eb yields \u2016\u03a0\u03031\u03a00\u2016 \u2264 1\u03b4 \u2016H\u2016 \u2264 1\u03b4 \u01eb. As such, if x \u2208 R(\u03a00) = span(U\u0302 (u)j , . . . , U\u0302 (u)d), then \u2016\u03a0\u03031x\u2016 \u2264 1\u03b4 \u01eb.\nBounding 1\u03b4 \u01eb and use Claims 6.6.2 and 6.6.3 completes the proof of part 1:\n\u2016\u03a0\u03031x\u2016 \u2264 1\n\u03b4 \u01eb = \u01eb 6\u2016P\u2295u\u20162 dm cmin \u2212 (d+1d )\u01eb \u2264 \u01eb (5\u2016P\u2295u\u20162 dm cmin ) = dm\u01eb 5\u2016P\u2295u\u20162cmin .\nParts 2 and 3 follow from the following claims.\nClaim 6.6.2. If \u03c0(i) \u2208 [d] \\ [m], then j > i.\nProof of Claim. Note that |\u03bb\u0302i| \u2264 \u01eb by Weyl\u2019s inequality (Theorem C.1). Since 0 is a lower bound on the |\u03bb\u0302\u2113|s, it suffices to show that |\u03bb\u0302i| < |\u03bb\u0302j |\u2212|\u03bb\u0302j\u22121|. By Claim 6.6.1, it suffices to show that \u01eb < 6\u2016P\u2295u\u2016 2\ndm cmin\u2212 \u01eb d , or alternatively ( d+1 d )\u01eb < 6\u2016P\u2295u\u20162 dm cmin. This follows from the assumptions on \u01eb. In particular, d+1 d \u01eb \u2264 \u2016P\u2295u\u20162 dm cmin < 6\u2016P\u2295u\u20162 dm cmin. \u25b3\nClaim 6.6.3. If \u03c0(i) \u2208 [m] is such that u2\u03c0(i) \u2264 5\u2016P\u2295u\u20162 6dm \u00b7 cmin cmax , then j > i.\nProof of Claim. By Lemma B.1, we see that |\u03bbi| = |\u22022\u03c0(i)F (u)| \u2264 6u2\u03c0(i)cmax. As such, using Weyl\u2019s inequality (see Theorem C.1), we see\n|\u03bb\u0302i| \u2264 6u2\u03c0(i)cmax + \u01eb \u2264 5\u2016P\u2295u\u20162\nmd cmin +\nd d+ 1 \u00b7 \u2016P\u2295u\u2016 2 md cmin\n= \u2016P\u2295u\u20162 md cmin [ 6\u2212 1 d ] < 6\u2016P\u2295u\u20162 md cmin \u2212 \u01eb d \u2264 |\u03bb\u0302j| \u2212 |\u03bb\u0302j\u22121| ,\nusing Claim 6.6.1. Since 0 lower bounds the |\u03bb\u0302\u2113|s and |\u03bb\u0302i| < |\u03bb\u0302j| \u2212 |\u03bb\u0302j\u22121|, it follows that i < j.\nWe now demonstrate that FINDBASISELEMENT largely works within the non-trivial subspace span(z1, . . . , zm) throughout its execution.\nProposition 6.7. Let v be defined at any step of FINDBASISELEMENT after step 6 among the subset of {u,u1,u2,u3,\u00b5} which has been generated during the execution of FINDBASISELEMENT. Suppose that k < m. Suppose there exists \u03b4 \u2208 [0, 14dm ), sign values s1, . . . , sk, and a permutation \u03c0 of [m] such that \u2016si\u00b5i \u2212 z\u03c0(i)\u2016 \u2264 \u03b4 for each i \u2208 [k]. Suppose that N1 and N2 are strictly positive integers. If \u01eb \u2264 cmin\n3md3/2 , then \u2016P0v\u2016 \u2264 2dmcmin \u01eb. Further, at the start of the execution of each iteration of the main loop of\nFINDBASISELEMENT, \u2016P0u\u2016 \u2264 2mcmin \u01eb.\nProof of Proposition 6.7. We first apply Lemma 6.5 to see that at the end of step 5 of FINDBASISELEMENT, \u2016P0u\u2016 \u2264 md 3/2\ncmin \u01eb \u2264 13 . As such, by Lemma 6.4, it follows that at the end of step 6, \u2016P0u\u2016 \u2264 2mcmin \u01eb, which\nis clearly upper bounded by 2dmcmin \u01eb.\nNow we let the \u03bb\u0302i(v) and U\u0302(v) be defined as in FINDBASISELEMENT (page 21). We will make use of the following claims in completing the proof.\nClaim 6.7.1. For a vector y, let j = arg maxi\u2208[d][|\u03bb\u0302j(y)| \u2212 |\u03bb\u0302j\u22121(y)|] and define the subspace X (y) := span(U\u0302j(y), . . . , U\u0302d(y)). If \u2016P0y\u2016 \u2264 2mcmin \u01eb, then \u2016P0x\u2016 < 2dm cmin \u01eb for any x \u2208 X (y)\nProof of Claim. We first note that \u2016P\u2295y\u20162 = 1 \u2212 \u2016P0y\u20162 \u2265 1 \u2212 ( 2mcmin \u01eb) 2 \u2265 1 \u2212 (23 )2 \u2265 12 . We see that\nd d+1 \u00b7 \u2016P\u2295y\u20162 dm cmin \u2265 dd+1 \u00b7 1/2 dm cmin. Since d \u2265 2, we see that dd+1 \u2265 23 , and hence dd+1 \u00b7 \u2016P\u2295y\u20162 dm cmin \u2265 1 3 \u00b7 cmindm \u2265 \u01eb, which is the required assumption of Lemma 6.6.\nApplying Lemma 6.6, we see that if x \u2208 X (y), then \u2016P0x\u20162 \u2264 dm\u01eb5\u2016P\u2295y\u20162cmin \u2264 2dm\u01eb 5cmin < 2dmcmin \u01eb. \u25b3\nClaim 6.7.2. For any vector v such that \u2016P0v\u2016 \u2264 2dmcmin \u01eb, then \u2016P0G\u0302(v)\u2016 \u2264 2m cmin \u01eb.\nProof of Claim. We note (using that d \u2265 2) that \u2016P0v\u2016 \u2264 2dmcmin \u01eb \u2264 2 3 \u221a 2 < 35 . As such, we may apply Lemma 6.4, which yields the claim. \u25b3\nCompleting the proof involves tracing what can happen during the execution of the main loop of FINDBASISELEMENT for any generated choice of v \u2208 {u,u1,u2,u3,\u00b5}. At the beginning of the first execution of the loop, the vector \u2016P0u\u2016 \u2264 2mcmin \u01eb as shown before the above Claims. Then, letting y = u Claim 6.7.1, we note that all the vectors u1,u2,u3 if generated are generated within the subspace of X (u). Therefore, at the step of generation, \u2016P0ui\u2016 \u2264 2dmcmin \u01eb for i \u2208 [d], and (with u still being its value at the start of the loop) \u2016P0U\u0302d(u)\u2016 \u2264 2dmcmin \u01eb. Finally, we complete the argument for the first run through the loop using Claim 6.7.2. We note that applications of GI-LOOP makes it so that for any y among any of u1, . . . ,u5 which has been generated or U\u0302d(u), we have that \u2016P0(GI-LOOP(y, N))\u2016 \u2264 2mcmin \u01eb whenever N \u2265 1. In\nparticular, at the end of the loop\u2019s execution, if v is among any of u,u1,u2,u3,\u00b5 which has been generated, then \u2016P0v\u2016 \u2264 2mcmin \u01eb.\nNote that this implies the following loop invariant: If \u2016P0u\u2016 \u2264 2mcmin \u01eb at the start of the main loop\u2019s execution, then \u2016P0u\u2016 \u2264 2mcmin \u01eb at the end of the main loop\u2019s execution. As all of the other desired bounds internal to the loop follow from the fact that \u2016P0u\u2016 \u2264 2mcmin \u01eb at the start of the loop, we obtain the desired bounds during every execution of the loop. Finally, if \u00b5 is generated in step 20, then \u2016P0\u00b5\u2016 = \u2016P0u\u2016 \u2264 2m cmin \u01eb holds due to the loop invariant."}, {"heading": "6.2 Progress of the gradient iteration", "text": "The core idea behind our robust gradient iteration algorithm FINDBASISELEMENT comes from part 2 of Lemma 5.4. There it is seen that for almost every u \u2208 Sd\u22121, repeated application of the update u \u2190 G(u) drives ui \u2192 0 for some non-zero coordinate i of u. In the noisy setting, this zeroing phenomenon has two parts: (1) for coordinates i such that ui is sufficiently close to 0, ui remains \u201ctrapped\u201d near zero, and (2) for an appropriate starting choice of u (of which there are many), a new coordinate of u is driven towards under repeated application of the gradient iteration. In this section, we formalize this zero trapping phenomenon. The following Lemma demonstrates the first part of this zero trapping effect.\nLemma 6.8. Suppose that \u03b30 \u2208 [0, 1), that u \u2208 Sd\u22121, and that \u01eb \u2208 [ 0, c 3/2 min(1\u2212\u03b30)3/2\u2016P\u2295u\u20169/2\n2 \u221a 2m3/2c 1/2 max\n)\n. If i \u2208 [d] is\nsuch that |ui| \u2264 \u221a (1\u2212\u03b30)cmin\u2016P\u2295u\u20163 2mcmax , then |G\u0302i(u)| \u2264 max ( (1\u2212 \u03b30)|ui|, 2m\u01ebcmin\u2016P\u2295u\u20163 ) .\nProof. The proof is based on the following claim.\nClaim 6.8.1. Suppose that \u03b30 \u2208 [0, 1), that u \u2208 Sd\u22121, that M2 \u2264 (1\u2212\u03b30)cmin\u2016P\u2295u\u2016 3\n2mcmax , and that \u01eb \u2264\n1 2mcmin(1\u2212 \u03b30)\u2016P\u2295u\u20163M . If i \u2208 [d] is such that |ui| \u2264 M , then |G\u0302i(u)| \u2264 (1\u2212 \u03b30)M .\nProof of Claim. From Lemma B.1, we have \u2016\u2207F (u)\u2016 \u2265 2mcmin\u2016P\u2295u\u20163. We note that \u01eb can be further bounded as:\n\u01eb \u2264 1 2m cmin\u2016P\u2295u\u20163(1\u2212 \u03b30)M \u2264 1 4 \u2016\u2207F (u)\u2016(1 \u2212 \u03b30)M (16)\nThus for any i \u2208 [d] such that u2i \u2264 M2, we have:\n|G\u0302i(u)| = |\u2202iF\u0302 (u)| \u2016\u2207F\u0302 (u)\u2016 \u2264 |\u2202iF (u)|+ \u01eb\u2016\u2207F (u)\u2016 \u2212 \u01eb \u2264 2|h\u2032i(u2i )ui|+ \u01eb\n3 4\u2016\u2207F (u)\u2016\n\u2264 2cmax|ui| 3\n3 2m \u22121cmin\u2016P\u2295u\u20163 + \u01eb 3 4\u2016\u2207F (u)\u2016\n\u2264 2 3 (1\u2212 \u03b30)|ui|+ 1 3 (1\u2212 \u03b30)M \u2264 (1\u2212 \u03b30)M .\nIn the above, the second inequality uses equation (16) for the denominator noting that both (1 \u2212 \u03b30) and M are at most 1. The third inequality uses the mean value theorem for the numerator and the lower bound \u2016\u2207F (u)\u2016 \u2265 2mcmin\u2016P\u2295u\u20163 from Lemma B.1 for the denominator. The fourth inequality uses the bound u2i \u2264 M2 \u2264 (1\u2212\u03b30)cmin\u2016P\u2295u\u20163 2mcmax and equation (16). \u25b3\nLet i \u2208 [d] be fixed. If |ui| \u2208 [\n2m\u01eb cmin(1\u2212\u03b30)\u2016P\u2295u\u20163 ,\n\u221a\n(1\u2212\u03b30)cmin\u2016P\u2295u\u20163 2mcmax\n]\n, then we apply Claim 6.8.1 with\nthe choice M = |ui| to obtain |ui| \u2264 (1 \u2212 \u03b30)|ui|. If |ui| < 2m\u01ebcmin(1\u2212\u03b30)\u2016P\u2295u\u20163 , then we apply Claim 6.8.1 with the choice M = 2m\u01eb\ncmin(1\u2212\u03b30)\u2016P\u2295u\u20163 to obtain |ui| \u2264 2m\u01eb cmin\u2016P\u2295u\u20163 .\nWe now a corresponding time bound for zero trapping sufficiently small coordinates of u.\nLemma 6.9. Let \u03b30 \u2208 (0, 1). Suppose that \u01eb \u2208 ( 0, c 3/2 min(1\u2212\u03b30)3/2\n10m3/2c 1/2 max\n)\n. Let {u(n)}\u221en=0 be a sequence\nsuch that \u2016P0u(0)\u2016 \u2264 35 . Suppose that i \u2208 [m] is such that |ui(0)| \u2264 \u221a (1\u2212\u03b30)cmin 4mcmax , and suppose N \u2265 loge ( (1\u2212\u03b30)1/2c3/2min\n8m3/2c 1/2 max\u01eb\n)\n/ loge( 1 1\u2212\u03b30 ) . Then, |ui(n)| \u2264 4m\u01ebcmin for every n \u2265 N .\nProof. Repeated application of Lemma 6.4 implies that \u2016P0u(n)\u2016 \u2264 2mcmin \u01eb < 3 5 for every n \u2208 N. This also implies that \u2016P\u2295u(n)\u20163 \u2265 (1\u2212 (35)2)3/2 = (45)3 > 12 . We have that for every n \u2208 N:\n\u01eb \u2264 c 3/2 min(1\u2212 \u03b30)3/2\n10m3/2c 1/2 max\n<\n\u221a 2c\n3/2 min(1\u2212 \u03b30)3/2\u2016P\u2295u(n)\u20169/2\n5m3/2c 1/2 max\n< c 3/2 min(1\u2212 \u03b30)3/2\u2016P\u2295u\u20169/2\n2 \u221a 2m3/2c 1/2 max\n.\nFurther, |ui(0)| \u2264 \u221a (1\u2212\u03b30)cmin 4mcmax \u2264 \u221a (1\u2212\u03b30)cmin\u2016P\u2295u(n)\u20163 2mcmax for each n \u2208 N \u222a {0}. Noting that upon applications of Lemma 6.8 that \u221a\n(1\u2212\u03b30)cmin 4mcmax and hence \u221a (1\u2212\u03b30)cmin\u2016P\u2295u(n)\u20163 2mcmax\nfor each n \u2208 N remains an upper bound for our |ui(k)|s, it follows that we may apply Lemma 6.8 at will.\nBy repeated application of Lemma 6.8, we see that |u(n)| \u2264 max ( (1\u2212 \u03b30)n|ui(0)|, 4m\u01ebcmin ) . It suffices\nto show that when n \u2265 N , then (1\u2212 \u03b30)n|ui(0)| \u2264 4m\u01ebcmin . To show this, we note:\n(1\u2212 \u03b30)n|ui(0)| \u2264 ( 1\n1\u2212 \u03b30\n)\u2212N |ui(0)| \u2264 ( 1\n1\u2212 \u03b30\n)\u2212 log1/(1\u2212\u03b30)\n(\n(1\u2212\u03b30) 1/2c 3/2 min\n8m3/2c 1/2 max\u01eb\n)\n\u00b7 \u221a\n(1\u2212 \u03b30)cmin 4mcmax\n=\n(\n8m3/2c 1/2 max\u01eb\n(1\u2212 \u03b30)1/2c3/2min\n) \u00b7 \u221a\n(1\u2212 \u03b30)cmin 4mcmax = 4m cmin \u01eb .\nThe following result (used in conjunction with the Lemma 6.8) allows us to demonstrate that for an appropriately chosen starting vector u, a new coordinate of u will be driven towards 0 by the gradient iteration. More precisely, it can be used to show that for an appropriately chosen u, the coordinate values of u diverge under the gradient iteration until some coordinate becomes small.\nLemma 6.10. Let u \u2208 Sd\u22121 be such that the set S = {i | |ui| > 4mdcmin \u01eb} is a subset of [m] containing at least 2 elements. Let v \u2208 Qd\u22121+ be the fixed point of G/\u223c such that vi 6= 0 if and only if i \u2208 S . Let \u03b30 \u2208 (0, 1), \u21130 = arg maxi\u2208S |ui|vi , and k0 = arg mini\u2208S |ui| vi . If \u01eb \u2264 7(1\u2212\u03b30)3/2cmin 5120m3/2d2 \u00b7 ( cmin cmax ) 7 2 , if |u\u21130 | \u2265 v\u21130 , and if |ui| > \u221a (1\u2212\u03b30)cmin 4mcmax\nfor each i \u2208 S , then the following hold: 1. If \u03b4 \u2208 [ 120d , 12 ] and |u\u21130 |/v\u21130 |uk0 |/vk0 \u2265 (1 + \u03b4)2, then maxi,j\u2208S |G\u0302i(u)|/vi|G\u0302j(u)|/vj \u2265 (1 + 7c2min\u03b4 32c2maxm ) |u\u21130 |/v\u21130 |uk0 |/vk0 2. If ( u\u21130/v\u21130 u0/vk0 )2 \u2265 (1 + 14d ), then maxi\u2208S |G\u0302i(u)|/vi \u2265 1.\nProof. We first prove part 1. We will make use of the following claims.\nClaim 6.10.1. Suppose there exists \u2206 \u2208 (0, 12) such that one of the following holds: (1) h\u2032\u21130(u2\u21130) \u2265 (1 + \u2206)h\u2032\u21130(v 2 \u21130 ) or (2) h\u2032k0(u 2 k0 ) \u2264 (1 + \u2206)\u22121h\u2032k0(v2k0). Suppose there exists \u03b2 \u2208 (0, 1 8\u2206] such that \u01eb \u2264 \u03b2mini\u2208S |\u2202iF (u)|. Then, maxi,j\u2208S |G\u0302i(u)|/vi|G\u0302j(u)|/vj \u2265 (1 + 1 4\u2206) |u\u21130 |/v\u21130 |uk0 |/vk0 .\nProof of Claim. We first bound the error on calculating Gi(u). For each i \u2208 S , we have:\n|G\u0302i(u)| = |\u2202iF\u0302 (u)| \u2016\u2207F\u0302 (u)\u2016 \u2264 |\u2202iF (u)|+ \u01eb\u2016\u2207F (u)\u2016 \u2212 \u01eb \u2264 1 + \u03b2 1\u2212 \u03b2 \u00b7 |\u2202iF (u)| \u2016\u2207F (u)\u2016 \u2264 1 + \u03b2 1\u2212 \u03b2 \u00b7 |Gi(u)|\n|G\u0302i(u)| = |\u2202iF\u0302 (u)| \u2016\u2207F\u0302 (u)\u2016 \u2265 |\u2202iF (u)| \u2212 \u01eb\u2016\u2207F (u)\u2016 + \u01eb \u2265 1\u2212 \u03b2 1 + \u03b2 \u00b7 |\u2202iF (u)|\u2016\u2207F (u)\u2016 \u2265 1\u2212 \u03b2 1 + \u03b2 \u00b7 |Gi(u)| .\nWe note that since \u2211 i\u2208S u 2 i \u2264 \u2211 i\u2208S v 2 i = 1, it follows that |uk0 | \u2264 vk0 . As such, we have both that |uk0 | \u2264 vk0 and |u\u21130 | \u2265 v\u21130 . We have that\nmax i,j\u2208S |G\u0302i(u)|/vi |G\u0302j(u)|/vj \u2265 (1\u2212 \u03b2 1 + \u03b2 )2 max i,j\u2208S |Gi(u)|/vi |Gj(u)|/vj = (1\u2212 \u03b2 1 + \u03b2 )2 max i,j\u2208S |h\u2032i(u2i )||ui|/vi |h\u2032j(u2j )||uj|/vj\n\u2265 (1\u2212 \u03b2 1 + \u03b2 )2 |h\u2032\u21130(u2\u21130)||u\u21130 |/v\u21130 |h\u2032k0(u2k0)||uk0 |/vk0 \u2265 (1\u2212 \u03b2 1 + \u03b2 )2 (1 + \u2206)|h\u2032\u21130(v2\u21130)||u\u21130 |/v\u21130 |h\u2032k0(v2k0)||uk0 |/vk0 \u2265 (1 + \u2206) (1\u2212 \u03b2 1 + \u03b2 )2 |u\u21130 |/v\u21130 |uk0 |/vk0 .\nIn the second to last inequality, we use the monotonicity of h\u2032i (see Lemma 3.1) along with the the assumption that one of the following holds: either (1) h\u2032\u21130(u 2 \u21130 ) \u2265 (1+\u2206)h\u2032\u21130(v2\u21130) or (2) h\u2032k0(u2k0) \u2264 (1+\u2206)\u22121h\u2032k0(v2k0). In the last inequality, we use Observation 5.2 to note that h\u2032\u21130(v 2 \u21130 ) = h\u2032k0(v 2 k0 ).\nWe now only need bound (1 + \u2206) ( 1\u2212\u03b2 1+\u03b2 )2 . We first note that ( 1\u2212\u03b2 1+\u03b2 )2 = ( 1 \u2212 2\u03b21+\u03b2 )2 \u2265 (1 \u2212 2\u03b2)2 \u2265\n1 \u2212 4\u03b2. Thus, (1 + \u2206) ( 1\u2212\u03b2 1+\u03b2 )2 \u2265 1 + \u2206 \u2212 4\u03b2 \u2212 4\u03b2\u2206. But since \u03b2 \u2264 18\u2206 and since \u2206 \u2264 12 , we see that 1 + \u2206\u2212 4\u03b2 \u2212 4\u03b2\u2206 \u2265 1 + 12\u2206\u2212 12\u22062 \u2265 1 + 14\u2206. Thus, we get that:\nmax i,j\u2208S |G\u0302i(u)|/vi |G\u0302j(u)|/vj \u2265 (1 + 1 4 \u2206)max i,j\u2208S |ui|/vi |uj|/vj . \u25b3\nClaim 6.10.2. Suppose that \u2206 > 0 is such that \u03b4 \u2265 8\u2206mc2max 7c2min and |u\u21130 |/v\u21130 |uk0 |/vk0\n\u2265 (1 + \u03b4)2. Then one of the following holds: either (1) h\u2032\u21130(u 2 \u21130 ) \u2265 (1 + \u2206)h\u2032\u21130(v2\u21130) or (2) h\u2032k0(u2k0) \u2264 (1 + \u2206)\u22121h\u2032k0(v2k0).\nProof of Claim. By the assumption |u\u21130 |/v\u21130 |uk0 |/vk0\n\u2265 (1 + \u03b4)2, one of the following must hold: (1) |u\u21130 |/v\u21130 \u2265 (1 + \u03b4) or (2) |uk0 |/vk0 \u2264 (1 + \u03b4)\u22121. We consider these cases separately, and demonstrate that in each case one of our desired results holds.\nCase 1. |u\u21130 |/v\u21130 \u2265 (1 + \u03b4).\nSince |u\u21130 | \u2265 (1 + \u03b4)v\u21130 , we see that |h\u2032\u21130(u2\u21130)| \u2265 |h\u2032\u21130((1 + 2\u03b4 + \u03b42)v2\u21130)| \u2265 |h\u2032\u21130(v2\u21130)|+ 2\u03b4v2\u21130cmin \u2265 |h\u2032\u21130(v2\u21130)| + 2\u03b4 c2min cmaxm\n, where the last inequality uses Lemma B.2. Noting that |h\u2032\u21130(v2\u21130)| \u2264 cmax, it suffice to show that 2\u03b4 c 2 min\ncmaxm \u2265 (1 + \u2206)cmax. But by the assumptions on \u03b4, we have that 2\u03b4 c\n2 min\ncmaxm \u2265\n16 7 \u2206cmax > \u2206cmax.\nCase 2. |uk0 |/vk0 \u2264 (1 \u2212 \u03b4)\u22121.\nWe note that |uk0 | \u2264 (1 + \u03b4)\u22121vk0 . Further, we bound (1 + \u03b4)\u22121 = 1+\u03b4\u2212\u03b41+\u03b4 \u2264 1 \u2212 12\u03b4. In particular, u2k0 \u2264 (1\u2212 \u03b4 + 1 4\u03b4 2)v2k0 \u2264 (1\u2212 7 8\u03b4)v 2 k0 . It follows that\n|h\u2032k0(u2k0)| \u2264 |h\u2032k0(v2k0(1\u2212 7 8 \u03b4)| \u2264 |h\u2032k0(v2k0)| \u2212 7 8 \u03b4v2k0cmin \u2264 |h\u2032k0(v2k0)| \u2212 7 8 \u03b4 c2min cmaxm ,\nwhere the last inequality uses Lemma B.2. We now note that |h\u2032k0(v2k0)|(1 + \u2206)\u22121 = |h\u2032k0(v2k0)|[1 \u2212 \u2206\n1+\u2206 ] \u2265 |h\u2032k0(v2k0)|(1 \u2212 \u2206). Since |h\u2032k0(v2k0)| \u2212 7 8\u03b4 c2min cmaxm \u2265 |h\u2032k0(u2k0)|, it suffices to show that\n|h\u2032k0(v2k0)|(1 \u2212 \u2206) \u2265 |h\u2032k0(v2k0)| \u2212 7 8\u03b4 c2min cmaxm , or alternatively, it suffices to show that 78\u03b4 c2min cmaxm \u2265 \u2206|h\u2032k0(v2k0)|. But by the assumptions on \u03b4, we have that 7 8\u03b4 c2min cmaxm \u2265 \u2206cmax \u2265 \u2206|h \u2032 k0 (vk0) 2|. \u25b3\nTo use these claims, we set the parameter choices \u2206 = 7c 2 min\u03b4\n8c2maxm and \u03b2 = 18\u2206. We note that\n\u03b2min i\u2208S |\u2202iF (u)| = 2\u03b2min i\u2208S |h\u2032i(u2i )ui| \u2265 2\u03b2cmin min i\u2208S |ui|3 \u2265 1 4 \u2206cmin (1\u2212 \u03b30)cmin 4mcmax )3/2\n= 7(1\u2212 \u03b30)3/2cmin\u03b4 256m5/2 \u00b7 ( cmin cmax )7/2 \u2265 \u01eb .\nWe apply Claim 6.10.2 followed by Claim 6.10.1 to complete the proof of part 1. We now proceed to prove part 2. Let \u21131 = arg maxi\u2208S |G\u0302i(u)|, and let k1 = arg mini\u2208S |G\u0302i(u)|. We assume for the sake of contradiction that |G\u0302\u21131(u)| < v\u21131 . By part 1 with the choice of \u03b4 = 120d , we obtain ( G\u0302\u21131(u)/v\u21131 G\u0302k1(u)/vk1 )2 \u2265 ( u\u21130/v\u21130 uk0/vk0\n)2 \u2265 1 + 14d . In particular, (G\u0302k1(u)/vk1)2 < (1 + 14d)\u22121 = 4d4d+1 , which may alternatively be written G\u0302k1(u)2 < 4d4d+1v2k1 .\nWe use the following notation: For sets S \u2282 [d], we have the complement set S\u0304 := [d] \\ S and the projection PSw := \u2211\ni\u2208S wizi for any w \u2208 Rd. Define S1 := {i | |G\u0302i(u)| > 4mdcmin \u01eb}. We note that \u2016P0u\u2016 \u2264 \u2016PS\u03040u\u2016 \u2264 4md 3/2 cmin \u01eb < 35 . As such, \u2016P\u2295u\u20163 \u2265 (1\u2212(35 )2)3/2 > 12 , and thus the Lemmas 6.4 and 6.8 combine to imply that S1 \u2282 S0. As such, \u2016PS\u03040 G\u0302(u)\u2016 \u2264 \u2016PS\u03041 G\u0302(u)\u2016 \u2264 4md 3/2 cmin \u01eb < 1\u221a 5m1/2d1/2 \u00b7 ( cmincmax ) 1/2, where we use a weak bound on \u01eb in the final inequality. In particular, \u2016PS0 G\u0302(u)\u20162 \u2265 1 \u2212 cmin5mdcmax . Expanding, we obtain:\nG\u0302\u21131(u)2 \u2265 1\u2212 cmin\n5mdcmax \u2212\n\u2211\ni\u2208S0\\{\u21131} G\u0302i(u)2 = v2\u21131 \u2212 cmin 5mdcmax + \u2211 i\u2208S0\\{\u21131} (v2i \u2212 G\u0302i(u)2)\n\u2265 v2\u21131 \u2212 cmin\n5mdcmax + (v2k1 \u2212 G\u0302k1(u)2) > v2\u21131 \u2212 cmin 5mdcmax + 1 4d+ 1 v2k1\n\u2265 v2\u21131 \u2212 cmin\n5mdcmax + cmin cmaxm(4d+ 1) \u2265 v2l1 .\nIn the above, the second to last inequality uses Lemma B.2. This is a direct direct contradiction to our assumption that |G\u0302\u21131(u)| < vl1 .\nFinally, we provide a method to find a good starting point u in order to guarantee progress using the gradient iteration under Lemma 6.10. The idea is captured line 14 of FINDBASISELEMENT. We identify a subspace on which u has large coordinate values using the spectral decomposition of HF\u0302 (u), and we choose several starting locations within that subspace. The following Lemma shows that one of these choices will be good.\nLemma 6.11. Let X be a great circle of Sd\u22121. Suppose there exists a set of coordinates S \u2282 [m] such that for any u \u2208 X , \u2016PS\u0304u\u20162 < 14d . Let p1,p2 be an orthonomral basis of span(X ), and define the angles \u03b8k = k\u03c0 3 and vectors uk = p1 cos \u03b8k + p2 sin \u03b8k for each k \u2208 [3]. Let v \u2208 Qd\u22121+ be the stationary point of G/\u223c such that vi 6= 0 if and only if i \u2208 S . Then there exists i \u2208 S and \u2113 \u2208 [3] such that \u3008u\u2113, zi\u30092 \u2265 (1 + 14d )v2i .\nProof. First, we extend our set of candidate vectors u1,u2,u3 to be u1, . . . ,u6 by setting \u03b8k = k\u03c0 3 and uk = p1 cos \u03b8k+p2 sin \u03b8k for each k \u2208 [6]. Note that for each k \u2208 [3], uk+3 = \u2212uk and hence uk \u223c uk+3. In particular, if k \u2208 [3] and j \u2208 S are such that \u3008uk+3, zj\u30092 \u2265 (1 + 14d)v2j , then \u3008uk, zj\u30092 \u2265 (1 + 14d)v2j . It suffices to find a j \u2208 S and an \u2113 \u2208 [6] such that \u3008u\u2113, zj\u30092 \u2265 (1 + 14d)v2j .\nClaim 6.11.1. There exists j \u2208 S and i1, i2 \u2208 [6] such that (1) \u3008ui1 , zj\u3009 and \u3008ui2 , zj\u3009 belong to the same interval among [\u22121, 0] and [0, 1], and (2) |\u3008ui2 , zj\u3009 \u2212 \u3008ui1 , zj\u3009| \u2265 1\u221a2d .\nProof of Claim. Let j = arg maxi\u2208S \u221a \u3008p1, zi\u30092 + \u3008p2, zi\u30092, and let c = \u221a \u3008p1, zj\u30092 + \u3008p2, zj\u30092. For each k \u2208 [6], we note that \u3008uk, zj\u3009 = \u3008p1, zj\u3009 cos \u03b8k + \u3008p2, zj\u3009 sin \u03b8k. By a trigonometric identity, there exists an angle \u03d5 such that \u3008uk, zj\u3009 = c sin(\u03b8k + \u03d5) for each k \u2208 [6].\nBy the pigeon hole principle, there exists indices i1, i2 \u2208 [6] such that \u03b8i1 + \u03d5 and \u03b8i2 + \u03d5 belong to the same quadrant. In particular, this choice of i1 and i2 gives part (1) of our Claim. Since mod(|\u03b8i1 + \u03d5\u2212 (\u03b8i2 + \u03d5)|, 2\u03c0) \u2264 \u03c02 , it follows that i1 and i2 can be chosen such that i2 \u2261 i1 + 1 (mod 6). Under this choice of i1 and i2, mod(\u03b8i2 \u2212 \u03b8i1 , 2\u03c0) = \u03c03 . We assume this choice without loss of generality. Then,\n|\u3008ui2 , zj\u3009 \u2212 \u3008ui1 , zj\u3009| = c| sin(\u03b8i2 + \u03d5)\u2212 sin(\u03b8i1 + \u03d5)| = 2c| sin( \u03b8i2\u2212\u03b8i1 2 ) cos( \u03b8i1+\u03b8i2+2\u03d5 2 )| , (17)\nwhere the last equality uses the trigonometric identity sin(x) \u2212 sin(y) = 2 sin(x\u2212y2 ) cos( x+y 2 ). We note sin( \u03b8i2\u2212\u03b8i1\n2 ) = sin( \u03c0 6 ) = 1 2 . Bounding | cos(\n\u03b8i1+\u03b8i2+2\u03d5\n2 )| makes use of the fact that \u03b8i1 + \u03d5 and \u03b8i2 + \u03d5 are in the same quadrant. In particular, there exists \u03c9 \u2208 {0, \u03c02 , \u03c0, 3\u03c02 } and \u03b4 \u2208 [0, \u03c06 ] such that \u03b8i1 + \u03d5 \u2261 \u03c9 + \u03b4 (mod 2\u03c0) and \u03b8i2 + \u03d5 \u2261 \u03c9 + \u03b4 + \u03c03 (mod 2\u03c0). As such, \u03b8i1+\u03b8i2+2\u03d5\n2 \u2208 (\u03c9 + [\u03c06 , \u03c03 ] + \u03c0r) for some integer r. In particular, | cos(\u03b8i1+\u03b8i2+2\u03d52 )| \u2265 cos \u03c03 \u2265 12 . Continuing from equation (17), we see that |\u3008ui2 , zj\u3009 \u2212 \u3008ui1 , zj\u3009| \u2265 12c.\nTo complete the result, we only need to lower bound c. We note that since z1, . . . , zd is a basis of the space, we have:\nmax i\u2208[d]\n(\u3008p1, zi\u30092 + \u3008p2, zi\u30092) \u2265 1\nd\nd \u2211\ni=1\n(\u3008p1, zi\u30092 + \u3008p2, zi\u30092) = 2\nd .\nHowever, for each i 6\u2208 S , we have that \u3008p1, zi\u30092 + \u3008p2, zi\u30092 < 2 \u00b7 14d \u2264 2d by assumption. As such, it follows that c2 \u2265 2d , and in particular |\u3008ui2 , zj\u3009 \u2212 \u3008ui1 , zj\u3009| \u2265 12c \u2265 1\u221a2d . \u25b3\nClaim 6.11.2. Let w \u2208 X . If w2j < (1 + 14d )v2j for each j \u2208 S , then w2j > v2j \u2212 14d [1 + \u2211 i\u2208S\\{j} v 2 i ] for each j \u2208 S .\nProof of Claim. We note \u2211 i\u2208S w 2 i \u2265 1\u2212 14d = \u2211 i\u2208S v 2 i \u2212 14d . In particular, fixing some j \u2208 S obtain\nw2j \u2265 v2j + \u2211 i\u2208S\\{j} (v2i \u2212 w2i )\u2212\n1\n4d > v2j \u2212\n1\n4d\n\u2211\ni\u2208S\\{j} v2i \u2212\n1\n4d ,\nwhere the last inequality follows by rewriting the given w2i < (1 + 1 4d )v 2 i as (v 2 i \u2212 w2i ) > \u2212 14dv2i . \u25b3\nWe let ui1 and ui2 be as in Claim 6.11.1, and let u = ui1 and w = ui2 . If there exists i \u2208 S such that u2i \u2265 (1 + 14d )v2i , then there is nothing to prove. So we assume that for each i \u2208 S , u2i < (1 + 14d )v2i . But letting j be as in Claim 6.11.1 we get:\n|w2j \u2212 u2j | = |wj \u2212 uj | \u00b7 |wj + uj| \u2265 1\u221a 2d \u00b7 1\u221a 2d = 1 2d (18)\nIn the above, the first inequality uses that since wj and uj are in the same half space, |wj + uj | \u2265 |wj \u2212 uj |. Noting that (1 + 14d)v 2 j \u2212 [v2j \u2212 14d [1 + \u2211 i\u2208S\\{j} v 2 i ] = 1 4d [1 + \u2211 i\u2208S v 2 i = 1 2d ]. Claim 6.11.2 implies that u2j \u2208 ((1+ 14d )v2j , v2j \u2212 14d [1+ \u2211 i\u2208S\\{j} v 2 i ]) =: Ij . It follows from equation (18) that wj 6\u2208 Ij . In particular, the contrapositive of Claim 6.11.2 implies the existence of an i \u2208 S such that w2i \u2265 (1 + 14d)v2i .\nFinally, we provide a time bound for the second part of the zeroing phenomenon.\nLemma 6.12. Suppose that {u(n)}\u221en=0 is a sequence defined recursively by u(n) = G(u(n \u2212 1)). Let \u03b30 \u2208 (0, 1). Suppose that \u01eb \u2264 7(1\u2212\u03b30) 3/2cmin 5120m3/2d2 \u00b7 ( cmin cmax )7/2 . Define the sets S := {i | |ui(n)| > 4mdcmin \u01eb} and An := {i \u2208 S | |ui(n)| \u2264 \u221a (1\u2212\u03b30)cmin 4mcmax\n}. Suppose that |S| \u2265 2 and that v \u2208 Qd\u22121+ is the stationary point of G/\u223c such that vi 6= 0 if and only if i \u2208 S . Let N0 be the first occurrence of k such that Ak 6= \u2205. If there exists \u2113 \u2208 S such that u 2 \u2113(0)\nv2\u2113 \u2265 1 + 14d , then N0 \u2264 1 + 320c2maxmd 3c2min loge ( 2mcmax (1\u2212\u03b30)1/2cmin ) .\nProof. We first choose \u03b4 = 120d for use in Lemma 6.10. We note:\n(1 + \u03b4)4 = 1 + 4\u03b4 + 6\u03b42 + 4\u03b43 + \u03b44 \u2264 1 + 4\u03b4 + 6 20 \u03b4 + 1 100 \u03b4 + 1 8000 \u03b4 < 1 + 5\u03b4 \u2264 1 + 1 4d .\nIn particular, we have that u2\u2113 (0)\nv2\u2113 \u2265 (1+\u03b4)2, and thus (noting that there must be an j \u2208 S such that |uj | \u2264 vj)\nwe obtain maxi,j\u2208S |ui(0)|/vi |uj(0)|/vj \u2265 (1 + \u03b4) 2. Repeated application of Lemma 6.10 implies that\nmax i,j\u2208S |ui(N0 \u2212 1)|/vi |uj(N0 \u2212 1)|/vj \u2265 ( 1 + 7c2min\u03b4 32c2maxm\n)N0\u22121 u2\u2113(0)\nv2\u2113 \u2265 ( 1 + 7c2min 640c2maxmd\n)N0\u22121\nHowever, first using the bounds for the vis from Lemma B.2 and then using the lower bound on the |ui|s from the sets An, we see that maxi,j\u2208S\n|ui(N0\u22121)|/vi |uj(N0\u22121)|/vj \u2264 ( mcmax cmin ) 1 2 maxj\u2208S 1 |uj(N0\u22121)|/vj \u2264 2mcmax (1\u2212\u03b30)1/2cmin . It\nfollows (\n1 + 7c2min\n640c2maxmd\n)N0\u22121 \u2264 2mcmax\n(1\u2212 \u03b30)1/2cmin From this, we obtain:\nN0 \u2264 1 + loge\n(\n2mcmax (1\u2212\u03b30)1/2cmin\n)\nloge (\n1 + 7c2min\n640c2maxmd\n)\n\u2264 1 + 320c 2 maxmd\n3c2min loge\n( 2mcmax\n(1\u2212 \u03b30)1/2cmin\n)\n.\nThe first inequality is obtained by taking logs and rearranging terms. The second inequality uses that loge(1+ x) \u2265 x \u2212 x2. Then, setting x = 7c 2 min\n640c2maxmd , it can be seen that x \u2212 x2 \u2265 x \u2212 7640x > 67x. In particular,\nloge(1 + 7c2min\n640c2maxmd ) > 3c2min 320c2maxmd .\nCorollary 6.13. Suppose that {u(n)}\u221en=0 is a sequence defined recursively by u(n) = G(u(n \u2212 1)). Let \u03b30 \u2208 (0, 1). Suppose that \u01eb \u2264 7(1\u2212\u03b30) 3/2cmin 5120m3/2d2 \u00b7 ( cmin cmax )7/2 . Suppose that \u2016P0u(0)\u2016 \u2264 4mdcmin \u01eb. Define the set S := {i | |ui(n)| > 4mdcmin \u01eb}. Let v \u2208 Q d\u22121 + be the stationary point of G/\u223c such that vi 6= 0 if and only if i \u2208 S . If there exists \u2113 \u2208 S such that u 2 \u2113(0)\nv2\u2113 \u2265 1 + 14d , and if N \u2265 1 + 320c2max 3c2min loge ( 2mcmax (1\u2212\u03b30)1/2cmin ) md +\nloge\n( (1\u2212\u03b3)1/2c3/2min 8m3/2c 1/2 max\u01eb ) / loge( 1\n1\u2212\u03b30 ), then there exists j \u2208 S such that for every n \u2265 N and for every i \u2208 ([d] \\ S) \u222a {j} we have that |ui(N)| \u2264 4m\u01ebcmin .\nProof. Using Lemma 6.12, it follows that for some choice of N0 \u2264 1 + 320c 2 max\n3c2min loge\n(\n2mcmax (1\u2212\u03b30)1/2cmin\n)\nmd,\nthere exists j \u2208 S such that |uj(N0)| \u2264 \u221a (1\u2212\u03b30)cmin 4mcmax . However, if we consider the sequence starting at N0 and set N1 = loge ( (1\u2212\u03b3)1/2c3/2min 8m3/2c 1/2 max\u01eb ) / loge( 1\n1\u2212\u03b30 ), then Lemma 6.9 implies that for any n \u2265 N0+N1 we obtain |uj(n)| \u2264 4mcmin \u01eb. Further, Lemma 6.4 implies that if i \u2208 [d] \\ [m], then |ui(n)| \u2264 2m cmin\n\u01eb for each n \u2208 N; and Lemma 6.8 implies that if i \u2208 S\u0304 \u2229 [m], then |ui(n)| \u2264 4mcmin \u01eb for every n \u2208 N."}, {"heading": "6.3 Gradient iteration proof of robustness", "text": "We now have all of the technical tools needed to prove that ROBUSTGI-RECOVERY robustly recovers the hidden basis elements. To do so, we first demonstrate that FINDBASISELEMENT can be used to approximate a single undiscovered basis element. We then show that by repeated application of FINDBASISELEMENT, all hidden basis elements may be recovered. In particular, we now prove this section\u2019s main theoretical results (Theorems 6.1 and 6.2). For the reader\u2019s convenience, we restate each theorem before its proof.\nTheorem 6.14. Suppose \u01eb \u2264 7cmin 10240 \u221a 2m3/2d2 \u00b7 ( cmin cmax )7/2 . Let k < m be non-negative, let p be a permutation of [m], and let s1, . . . , sk \u2208 {\u22121,+1} be sign values such that \u2016si\u00b5i \u2212 zp(i)\u2016 \u2264 4m \u221a 2d cmin \u01eb for each i \u2208 [k]. Suppose N1 \u2265 log2( cmin8\u221a2m3/2\u01eb \u00b7 ( cmin cmax )1/2) and N2 \u2265 320c 2 maxmd 3c2min loge ( 2 \u221a 2mcmax cmin ) + log2( cmin 8 \u221a 2m3/2\u01eb\n\u00b7 ( cmincmax )\n1/2) + 1. If we execute \u00b5k+1 \u2190 FINDBASISELEMENT({\u00b51, . . . ,\u00b5k}, m\u0302) for any choice of m\u0302 \u2265 m, then there will exist a sign value sk+1 \u2208 {+1,\u22121} and an index j \u2208 [m]\\[k] such that \u2016sk+1\u00b5k+1\u2212zp(j)\u2016 \u2264 4m \u221a d\ncmin \u01eb.\nProof. Throughout the proof, we will fix a choice of \u03b30 = 12 for use in Lemma 6.9. It can be verified that for this choice of \u03b30, then fixing Nmin1 to be the constant N from Lemma 6.9, we get N min 1 =\nloge\n(\nc 3/2 min\n8 \u221a 2m3/2c 1/2 max\u01eb\n)\n/ loge(2) = log2\n(\nc 3/2 min\n8 \u221a 2m3/2c 1/2 max\u01eb\n)\n\u2264 N1. Further, setting Nmin2 to be constant N from\nCorollary 6.13 with the same choice of \u03b30, we see that Nmin2 = 320c2maxmd\n3c2min loge\n( 2 \u221a 2mcmax cmin ) +log2 (\nc 3/2 min\n8 \u221a 2m3/2c 1/2 max\u01eb\n)\n+\n1 \u2264 N2. Claim 6.14.1. Let S = {p(\u2113) | \u2113 \u2208 [k]}. At the start of the first execution of the main loop of FINDBASISELEMENT, u is such that |u\u03b1| \u2264 4mcmin \u01eb for each \u03b1 \u2208 ([d] \\ [m]) \u222a S .\nProof of Claim. For each \u2113 \u2208 [d] \\ [m], this follows directly from Proposition 6.7. Let S = {p(\u2113) | \u2113 \u2208 [k]}. Immediately following step 5 of FINDBASISELEMENT, Lemma 6.5 implies that (1) \u2016P0u\u2016 \u2264 md 3/2\ncmin \u01eb and (2) for each \u2113 \u2208 S , |ui| \u2264 3md\n3/2\ncmin \u01eb. Using (weak) bounds on \u01eb, we note that\n\u2016P0u\u2016 < 35 and |ui| < \u221a (1\u2212\u03b30)cmin 4mcmax . In particular, we may apply Lemma 6.9, and we obtain that the end of step 6, |u\u2113| \u2264 4m\u01ebcmin for each \u2113 \u2208 S . \u25b3\nBy Proposition 6.7, we see that following step 6 of FINDBASISELEMENT, we have that for any w among u,u1,u2,u3,\u00b5 which has been generated, \u2016P0w\u2016 \u2264 2dmcmin \u01eb < 3 5 . In particular, we will have the following lower bound for all relevant vectors during the execution of the main loop of FINDBASISELEMENT: \u2016P\u2295w\u20163 \u2265 (1\u2212 (35)2)3/2 = (45 )3 \u2265 12 . We continue our analysis strictly after step 6 and consider this to be an additional assumption.\nClaim 6.14.2. Define S(u) := {j | |uj | > 4mcmin \u01eb} at the start of iteration i of FINDBASISELEMENT\u2019s main loop, and define S \u2032(u) := {j | |uj | > 4mcmin \u01eb} at the end of iteration i of the main loop. Execution of FINDBASISELEMENT\u2019s main loop satisfies the following: If |S(u)| \u2264 m\u0302 \u2212 (i + k \u2212 1) and line 10 is not executed during iteration i, then (1) S \u2032(u) \u2282 S(u) and (2) |S \u2032(u)| \u2264 m\u0302\u2212 (i+ k).\nProof of Claim. For each j \u2208 [3] and each \u2113 \u2208 S\u0304(u), the following hold: 1. At the end of the execution of line 14, we have |\u3008uj , z\u2113\u3009| < \u221a\ncmin 8mcmax . To see this, we note that\nu2\u2113 \u2264 ( 4m cmin )2 < 5\u2016P\u2295u\u2016 2 6dm \u00b7 cmin cmax (for each \u2113 \u2208 S\u0304(u)). Applying Lemma 6.6, we obtain |\u3008uj , z\u2113\u3009| \u2264 dm\u01eb\n5\u2016P\u2295u\u20162cmin < \u221a cmin 8mcmax .\n2. At the end of the execution of line 15, |\u3008uj , z\u2113\u3009| \u2264 4mcmin \u01eb. If \u2113 \u2208 [m], then this follows from Lemma 6.9 by noting that N2 > Nmin1 . Otherwise, this is a result of Lemma 6.4. 3. Consider uj at the end of the execution of line 15, and let w = GI-LOOP(uj , N1). Then |w\u2113| \u2264 4mcmin \u01eb. This can be seen using Lemma 6.8 (if \u2113 \u2208 [m]) or by Lemma 6.4 (if \u2113 \u2208 [d] \\ [m]). In particular, at the end of the execution of the main loop, |u\u2113| \u2264 4mcmin \u01eb. Note that the above imply that S \u2032(u) \u2282 S(u) (which gives the first part of the claim). Now, we show the second part of this claim. If |S(u)| \u2264 m\u0302 \u2212 (i + k), then by the first part there is nothing to prove. So, we assume that |S(u)| = m\u0302\u2212 (i+ k \u2212 1). Let j = arg max\u2113\u2208[d][|\u03bb\u0302\u2113(u)| \u2212 |\u03bb\u0302\u2113\u22121(u)|] with the |\u03bb\u0302\u2113(u)|s defined as in line 8 of FINDBASISELEMENT. Note that for any \u2113 \u2208 S\u0304(u), it follows that u2\u2113 \u2264 16m\u01eb 2\nc2min < 512dm \u2264 5\u2016P\u2295u\u20163 6dm using a (weak) bound on\n\u01eb. Defining X = span(U\u0302j(u), . . . , U\u0302d(u)), then Lemma 6.6 implies that \u2016PS\u0304(u)x\u2016 \u2264 dm\u01eb5\u2016P\u2295u\u20162cmin for any x \u2208 X . In particular, using our choice of \u01eb and using that \u2016P\u2295u\u2016 \u2265 45 , it can be seen that \u2016PS\u0304(u)x\u20162 < 14d . Let v \u2208 Qd\u22121+ be the fixed point of G/\u223c such that v\u2113 = 0 if and only if \u2113 \u2208 S(u). Lemma 6.11 implies that for some choice \u03b11 \u2208 [3] and \u03b12 \u2208 S(u), u\u03b11 at the time of generation in line 14 of FINDBASISELEMENT satisfies |\u3008u\u03b11 , z\u03b12\u3009|/v\u03b12 \u2265 (1 + 14d).\nFor each \u2113 \u2208 [3], we let {u\u2113(n)}\u221en=0 be the sequence defined recursively by u\u2113(0) = u\u2113 and u\u2113(n) = G\u0302(u\u2113(n \u2212 1)). Define S(u\u2113(n) := {\u03b2 | \u3008u\u2113(n), z\u03b2\u3009} for each \u2113 \u2208 [3] and n \u2208 N \u222a {0} Noting that each u\u03b11(0) \u2208 X and that \u2016PS\u0304(u)u\u2113(0)\u2016 \u2264 dm\u01eb5\u2016P\u2295u\u20162cmin \u2264 4md cmin \u01eb, then Corollary 6.13 implies that there exists \u03b13 \u2208 S(u) such that S(u\u03b11(N2)) \u2282 S(u) \\ {\u03b13}. Further, Lemma 6.9 combined with Lemma 6.4 implies that S(u\u2113(N2)) \u2282 S(u) for each \u2113 \u2208 [3].\nNow we let \u2113 = arg minj\u2208[3] |\u03bb\u0302k+i(uj)| be defined as in step 17. If \u2113 = \u03b11, then Lemmas 6.4 and 6.8 imply that S \u2032(u) \u2282 S(u\u03b11(N2)), which gives the claim. If \u2113 6= \u03b11, then we note:\n6cmax\u3008u\u03b11(N2), z\u03b13\u30092 + \u01eb \u2265 |\u22022\u03b13F (u\u03b11(N2))|+ \u01eb \u2265 |\u03bb\u0302k+i(u\u03b11(N2))| \u2265 |\u03bb\u0302k+i(u\u2113(N2))| \u2265 |\u22022\u03b13F (u\u2113(N2))| \u2212 \u01eb \u2265 6cmin\u3008u\u2113(N2), z\u03b13\u30092 \u2212 \u01eb .\nIn the above, the first inequality uses Lemma B.1, the second inequality uses Weyl\u2019s inequality (Theorem C.1), the third inequality uses the definition of \u2113, the fourth inequality uses Weyl\u2019s inequality again, and the fifth inequality uses Lemma B.1 again. As such,\n|\u3008u\u2113(N2), z\u03b13\u3009| \u2264 \u221a cmax cmin |\u3008u\u03b11(N2), z\u03b12\u3009|2 + \u01eb 3 \u2264 \u221a 16m2cmax c3min \u01eb2 + \u01eb 3 \u2264 \u221a cmin 8mcmax ,\nwhere the last inequality uses a (weak) upper bound on \u01eb. It follows by Lemma 6.9 and Lemma 6.4 that S(u\u2113(N2)) \u2282 S(u) \\ {\u03b13}. In particular, S \u2032(u) \u2282 S(u\u2113(N2)) \u2282 S(u) \\ {\u03b12}. \u25b3\nClaim 6.14.3. If the line 10 of FINDBASISELEMENT is executed, then there exists a sign s \u2208 {\u00b11} and \u03b11 \u2208 [m] \\ [k] such that the resulting \u00b5 satisfies \u2016s\u00b5\u2212 zp(\u03b11)\u2016 \u2264 4m \u221a 2d cmin \u01eb.\nProof of Claim. Consider u in its form at the time that the loop is exited. Let the permutation \u03c0 be defined as in Lemma 6.6, and let A = {\u03c0(\u03b1) \u2208 [d] | \u03b1 < d}. Then, we obtain:\n\u2016PAU\u0302d(u)\u2016 \u2264 dm\u01eb 5\u2016P\u2295u\u20162cmin \u2264 dm\u01eb\n5(45 ) 2cmin\n<\n\u221a\n(1\u2212 \u03b30)cmin 4mcmax .\nwhere the first inequality uses Lemma 6.6, and the third inequality uses a (weak) bound on \u01eb. As Lemma 6.6 implies that \u2016P0U\u0302(u)\u2016 \u2264 dm\u01eb5\u2016P\u2295u\u20162cmin < 3 5 , the Lemmas 6.4 and Lemma 6.9 imply that for \u00b5 recovered on\nline 10, we have |\u00b5\u2113| \u2264 4m\u01ebcmin for each \u2113 \u2208 A. We note that |A| = d \u2212 1, and in particular there exists only one \u2113 \u2208 [d] \\ A. For this choice of \u2113, it follows that \u00b52\u2113 \u2265 1 \u2212 \u2211 \u03b1\u2208A \u00b5 2 \u03b1 \u2265 1 \u2212 d ( 4m cmin \u01eb )2 . In particular, there exists a sign value s such that \u2016s\u00b5\u2212 z\u2113\u2016 \u2264 \u221a [1\u2212 \u00b52\u2113 ] + \u2211 \u03b1\u2208A \u00b5 2 \u03b1 \u2264 4m \u221a 2d cmin \u01eb. It remains to be seen that our choice of \u2113 recovers a new hidden basis element as opposed to one which has already been found. To see this, we define the sets Si := {\u03b1 | |u\u03b1| > 4mcmin \u01eb} at the start of the i\nth iteration of the loop. By Claim 6.14.1, S1 \u2282 {p(\u03b11) | \u03b11 \u2208 [m] \\ [k]}. Let t give the iteration on which we exit the loop. Using Claim 6.14.2, we see that St \u2282 St\u22121 \u2282 \u00b7 \u00b7 \u00b7 \u2282 S1. Finally, after verifying that 4mcmin \u01eb < 5\u2016P\u2295u\u20162 6dm \u00b7 cmincmax , Lemma 6.6 implies that for each \u03b1 \u2208 S\u0304t, we have that \u03b1 \u2208 A. As \u2211d\n\u03b1=1 u 2 \u03b1 = 1 > d \u00b7 4mcmin \u01eb, it follows that\nS\u0304t is nonempty, and hence that the lone element \u2113 \u2208 A\u0304 satisfies \u2113 \u2208 S \u2032t \u2282 S \u20321 \u2282 {p(\u03b11) | \u03b11 \u2208 [m]\\[k]}. \u25b3\nNote that if the main loop of FINDBASISELEMENT exits at step 10, then by Claim 6.14.3 there is nothing to prove. So, we assume that step 10 is never executed. We let S1,S2, . . . ,Sm\u0302\u2212k be the sets defined by: (1) If i < m\u0302 \u2212 k, then Si := {\u2113 | |u\u2113| > 4mcmin \u01eb} using u at the start of iteration i of the main loop, and (2) Sm\u0302\u2212k := {\u2113 | |u\u2113| > 4mcmin \u01eb} using u at the end of the last iteration (i = m\u0302\u2212 k \u2212 1) of the main loop. Then, Claim 6.14.1 implies that S1 \u2282 {p(\u2113) | \u2113 \u2208 [m] \\ [k]}. Repeated application of Claim 6.14.2 implies that Sm\u0302\u2212k \u2282 S1 \u2282 {p(\u2113) | \u2113 \u2208 [m] \\ [k]} and further that |Sm\u0302\u2212k| \u2264 1. Since u is a unit vector, it is impossible for each |ui| \u2264 4mcmin \u01eb, and in particular it follows that |Sm\u0302\u2212k| = 1.\nLet \u00b5 = u be as generated at the end of the execution of FINDBASISELEMENT. Since \u00b5 is a unit vector, then, for the choice of \u2113 \u2208 Sm\u0302\u2212k we have that \u00b52\u2113 = \u2211 \u03b1\u2208S\u0304m\u0302\u2212k \u00b5 2 \u03b1 > 1 \u2212 d( 4mcmin \u01eb) 2. In particular, there exists a sign value s such that \u2016s\u00b5\u2212 z\u2113\u2016 \u2264 \u221a [1\u2212 \u00b52\u2113 ] + \u2211 \u03b1\u2208S\u0304m\u0302\u2212k \u00b5 2 \u03b1 \u2264 4m \u221a 2d cmin \u01eb.\nTheorem 6.15. Suppose that \u01eb \u2264 7cmin 10240 \u221a 2m3/2d2 \u00b7 ( cmin cmax )7/2 . Suppose that m\u0302 \u2265 m, that N1 \u2265 log2( cmin8\u221a2m3/2\u01eb \u00b7 ( cmincmax ) 1/2), and that N2 \u2265 log2( cmin8\u221a2m3/2\u01eb \u00b7 ( cmin cmax )1/2) + 320c 2 maxmd 3c2min loge ( 2 \u221a 2mcmax cmin ) + 1. If we execute\n\u00b51, . . . ,\u00b5m\u0302 \u2190 ROBUSTGI-RECOVERY(m\u0302), then \u00b51, . . . ,\u00b5m forms a 4m \u221a 2d\ncmin \u01eb-approximation to the hid-\nden basis. More precisely, there exists a permutation \u03c9 of [m] and signs s1, . . . , sm \u2208 {+1,\u22121} such that \u2016si\u00b5i \u2212 z\u03c9(i)\u2016 \u2264 4m \u221a 2d cmin \u01eb for each i \u2208 [m].\nProof. We let \u00b51, . . . ,\u00b5m denote the firstm approximate basis elements returned by ROBUSTGI-RECOVERY. We proceed by induction on the following statement (with k \u2208 [m] \u222a {0}).\nInductive Hypothesis: There exist sign values s1, . . . , sk and a permutation \u03c9k of [m] such that \u2016si\u00b5i \u2212 z\u03c9k(i)\u2016 \u2264 4m \u221a 2d cmin \u01eb.\nThe base case k = 0 holds trivially. Suppose that the inductive hypothesis holds for some k = n with n < m. Then, by Theorem 6.1, there exists j \u2208 [m] \\ {\u03c9n(i) | i \u2208 [n]} and a sign s such that \u2016s\u00b5n+1 \u2212 zj\u2016 \u2264 4m \u221a 2d\ncmin \u01eb. Letting sn+1 = s and letting \u03c9n+1 be a permutation of [m] such that \u03c9n+1(n + 1) = j and\n\u03c9n+1(i) = \u03c9n(i) for i \u2264 n gives the inductive hypothesis with k = n+ 1."}, {"heading": "A Chart of notation", "text": "We use a number of notations throughout this paper, many of which are standard and some of which are not. For the reader\u2019s reference, we list notations used throughout the paper here.\n\u2207 Gradient operator. H Hessian operator. \u2202i The derivative operator with respect to the direction of the ith basis element of the space. When\nworking in [d], this is the derivative with respect to the direction zi. \u223c The equivalence relation defined on Sd\u22121 given by u \u223c v if for each i \u2208 [d], |ui| = |vi|. [u] The equivalence class {v | v \u223c u}. \u03c6 The map from Sd\u22121/\u223c to Qd\u22121+ given by \u03c6i([u]\u223c) = |ui|. \u00b5 The distance metric on Sd\u22121/ \u223c defined by \u00b5([u], [v]) := \u2016\u03c6(u)\u2212 \u03c6(v)\u2016. [k] The set {1, 2, . . . , k}. | \u00b7 | The modulus or absolute value operation. \u2016\u00b7\u2016 The standard Euclidean 2-norm. \u3008\u00b7, \u00b7\u3009 The standard Euclidean inner product, i.e., the dot product.\nB(x, r) The closed ball centered at x with radius r. d Dimensionality of the ambient space. F A BEF with expanded form F (u) =\n\u2211m i=1 \u03b1ig(\u03b2iui), defined on page 2.\nF\u0304 The PBEF associated with BEF F . G The gradient iteration functions associated with a BEF F . I The identity matrix. m Number of distinguished hidden basis vectors z1, . . . , zm. Note that m \u2264 d.\nQd\u22121+ The all positive orthant of S d\u22121: {u \u2208 Sd\u22121 | ui \u2265 0 for all i \u2208 [d]}. Qd\u22121 v\nIt is assumed that v \u2208 Rd is a vector of signs (vi \u2208 {+1,\u22121} for all i \u2208 [d]). Then, Qd\u22121v := {u \u2208 Sd\u22121 | viui \u2265 0} is the orthant of Sd\u22121 containing v.\nSd\u22121 The unit sphere in Rd: {u \u2208 Rd | \u2016u\u2016 = 1}.\nsign(\u00b7) The sign indicator on R defined by sign(x) := { x/|x| if x 6= 0 0 if x = 0 .\nv\u3008r\u3009 Vector v taken to the element-wise exponent of r, i.e., (v\u3008r\u3009)i = vri . \u03c7[E] The indicator function of the event E. zi The vectors z1, . . . , zm are the hidden basis elements encoded within a BEF. The vectors\nzm+1, . . . , zd are chosen arbitrarily in order to make z1, . . . , zd an orthonormal basis of Rd."}, {"heading": "B Function bounds", "text": "In this section, we provide some useful bounds for (cmin, cmax)-robust BEFs and PBEFs.\nLemma B.1. For a (cmin, cmax)-robust BEF F , we have the following bounds for any u \u2208 B(0, 1): 1. 2mcmin\u2016P\u2295u\u20163 \u2264 \u2016\u2207F (u)\u2016 \u2264 2cmax\u2016P\u2295u\u20163. 2. If i \u2208 [m], then |\u22022i F (u)| \u2208 6u2i [cmin, cmax].\nProof. We first bound \u2016\u2207F (u)\u2016:\n\u2016\u2207F (u)\u20162 = m \u2211\ni=1\n(2h\u2032i(u 2 i )ui)\n2 \u2264 4 m \u2211\ni=1\n(h\u2032\u2032i (xi)u 3 i ) 2\n\u2264 4 m \u2211\ni=1\nc2maxu 6 i \u2264 4\u2016P\u2295u\u20166\nm \u2211\ni=1\nc2max ( ui \u2016P\u2295u\u2016 )6 \u2264 4c2max\u2016P\u2295u\u20166\nwhere xi \u2208 (0, u2i ) by the mean value theorem. We now lower bound \u2016\u2207F (u)\u2016:\n\u2016\u2207F (u)\u20162 = 4 m \u2211\ni=1\nh\u2032i(u 2 i ) 2u2i \u2265 4c2min m \u2211\ni=1\nu6i = 4mc 2 min\nm \u2211\ni=1\n(u6i /m)\n\u2265 4mc2min (\nm \u2211\ni=1\nu2i /m )3 = 4m\u22122c2min\u2016P\u2295u\u20166\nwhere the last inequality uses Jensen\u2019s inequality. We now bound \u22022i F (u):\n|\u22022i F (u)| = |4h\u2032\u2032i (u2i )u2i + 2h\u2032i(u2i )| = |4h\u2032\u2032i (u2i )u2i + 2h\u2032\u2032i (x)| \u2208 6u2i [cmin, cmax] ,\nwhere x \u2208 (0, u2i ) by the mean value theorem.\nLemma B.2. Let F be a (cmin, cmax)-robust BEF, and let v be a fixed point of G/\u223c. Let S = {i | vi 6= 0}. Suppose that S \u2282 [m]. If i \u2208 S , then v2i \u2265 cmincmaxm .\nProof. There exists j \u2208 S such that v2j \u2265 1|S| . Using Observation 5.2, we see that h\u2032j(v2j ) = h\u2032k(v2k) for any k \u2208 S . In particular, h\u2032k(v2k) = hj(v2j ) \u2265 cminv2j \u2265 cminm . But noting that h\u2032k(v2k) \u2264 v2kcmax, it follows that v2k \u2265 cmincmaxm ."}, {"heading": "C Error bounds on eigenvalues and eigenspaces", "text": "As part of our error analysis of ROBUSTGIRECOVERY in section 6, we require bounds on the error of estimating the eigenvalues and eigenvectors of HF (u) given access to HF\u0303 (u). The following inequality is a known version of Weyl\u2019s inequality for matrix eigenvalues.\nTheorem C.1 (Weyl\u2019s inequality). Let A, A\u0303, and H be symmetric (or more generally Hermetian) n \u00d7 n matrices such that A\u0303 = A+H . Let the eigenvalues of A, A\u0303, and H be given by \u03bb1, . . . , \u03bbn, \u03bb\u03031, . . . , \u03bb\u0303n, and \u03c11, . . . , \u03c1n respectively. Assume that the eigenvalues are indexed in decreasing order, i.e., \u03bb1 \u2265 \u00b7 \u00b7 \u00b7 \u2265 \u03bbn. Then, for each i \u2208 [n], \u03bbi + \u03c1i \u2264 \u03bb\u0303i \u2264 \u03bbi\u03c1n.\nThe next Theorem (namely the Davis-Kahan sin\u0398 theorem from [11]) allows us to bound the error in eigenvector subspaces of a matrix under a perturbation. This theorem requires a bit more explanation. In particular, we will still assume that we have a Hermitian matrix A which is the matrix we are interested in, and that A\u0303 = A + H is a perturbed version of A (with A\u0303 and H also both Hermitian). Suppose that A =\n\u2211n i=1 \u03bbiviv T i and A\u0303 \u2211n i=1 \u03bb\u0303iv\u0303iv\u0303i T give eigendecompositions with the ordering of the eigenvalues \u03bbi not yet determined. We may split the indices at a point k and define the matrices A0 = \u2211k i=1 \u03bbiviv T i , A1 = \u2211n i=k+1 \u03bbiviv T i , A\u03030 = \u2211k i=1 \u03bb\u0303iv\u0303iv\u0303i T , A\u03030 = \u2211m i=k+1 \u03bb\u0303iv\u0303iv\u0303i T .\nTheorem C.2 (Davis-Kahan sin\u0398 theorem). Suppose that there exists an interval [\u03b1, \u03b2] and a \u03b4 > 0 such that the eigenvalues of A0 lie within [\u03b1, \u03b2] and the eigenvalues of A\u03031 all lie outside the interval (\u03b1\u2212\u03b4, \u03b2+\u03b4) [or alternatively, the eigenvalues of A\u03031 lie within [\u03b1, \u03b2] and the eigenvalues of A0 all lie outside the interval (\u03b1\u2212 \u03b4, \u03b2 + \u03b4)]. Then, \u03b4\u2016sin\u03980\u2016 \u2264 \u2016H\u2016.\nThe definition of sin\u03980 is somewhat involved and can be found in [11], however for our setting it suffices to note that \u2016sin\u03980\u2016 bounds certain projection operators. In particular, if we define \u03a00 = \u2211k i=1 viv T i and \u03a0\u03030 = \u2211k i=1 v\u0303iv\u0303i T , then \u2016(I \u2212 \u03a0\u03030)\u03a00\u2016 \u2264 \u2016sin\u03980\u2016 \u2264 1\u03b4 \u2016H\u2016."}], "references": [], "referenceMentions": [], "year": 2017, "abstractText": "In this paper we formulate the framework of recovering a hidden orthonormal basis given access to a<lb>certain \u201cBasis Encoding Function\u201d. We describe the class of Basis Encoding Functions (BEF), such that<lb>their local maxima on the unit sphere are in one-to-one correspondence with the basis elements. This<lb>description relies on a certain \u201chidden convexity\u201d property of these functions. A number of theoretical<lb>and practical problems of recent interest can be interpreted as recovering a hidden basis from potentially<lb>noisy observations. Specifically, we show how our simple and general framework applies to Independent<lb>Component Analysis (ICA), tensor decompositions, spectral clustering and Gaussian mixture learning.<lb>We describe a new algorithm, \u201cgradient iteration\u201d, for provable recovery of the hidden basis. We<lb>provide a complete theoretical analysis of Gradient Iteration both for the exact case as well as for the<lb>case when the observed function is a perturbation of the \u201ctrue\u201d underlying BEF. In both cases we show<lb>convergence and complexity bounds polynomial in dimension and other relevant parameters, such as<lb>perturbation size. Our perturbation results can be considered as a very general non-linear version of<lb>the classical Davis-Kahan theorem for eigenvectors of perturbations of symmetric matrices. In addition<lb>we show that in the exact case the algorithm converges superlinearly and give conditions relating the<lb>degree of convergence to properties of the Basis Encoding Function. Our algorithm can be viewed as a<lb>generalization of the classical power iteration method for eigenanalysis of symmetric matrices as well as<lb>a generalization of power iterations for tensors. Moreover, the Gradient Iteration algorithm can be easily<lb>and efficiently implemented in practice.", "creator": "LaTeX with hyperref package"}}}