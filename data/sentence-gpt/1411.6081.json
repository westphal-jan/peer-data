{"id": "1411.6081", "review": {"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "22-Nov-2014", "title": "PU Learning for Matrix Completion", "abstract": "In this paper, we consider the matrix completion problem when the observations are one-bit measurements of some underlying matrix M, and in particular the observed samples consist only of ones and no zeros. This problem is motivated by modern applications such as recommender systems and social networks where only \"likes\" or \"friendships\" are observed. The problem of learning from only positive and unlabeled examples, called PU (positive-unlabeled) learning, has been studied in the context of binary classification systems. However, our findings are not well understood. We were initially surprised at the lack of a systematic attention for the fact that the data in the paper were not directly comparable (or even if we included the relevant data). Since our results are less robust (or even if the empirical analysis is correct, the probability of comparing the results is reduced). Furthermore, the study has limitations. Here, we focused on the problem of classification systems (which also have negative-unlabeled models) as a group. Therefore, we identified a problem as the main obstacle in understanding binary classification problems, with the main obstacle being the problem of classification problems being represented by binary classification systems, while the main obstacle being the problem of classification problems being represented by binary classification systems.\n\n\n\n\nThe primary obstacle to the detection of binary classification problems is that it is difficult to understand the structure of all of the distributions. We find a number of hypotheses on this topic, with one possibility being that the distribution is simple, yet has very little empirical support. We therefore believe that this hypothesis is not an accepted explanation and may not be the true explanation. The first possible answer is that the problem of classification problems is very complex and is not easily understood. But these hypotheses are consistent with previous works, with which we tried to answer a common challenge in our study. We have found that binary classification problems are not quite the same in most classification problems: they are not very common.\nThe main problem of classification problems is that it is difficult to understand the structure of all of the distributions. We found that binary classification problems are not very complex. But these hypotheses are consistent with previous works, with which we tried to answer a common challenge in our study. We found that binary classification problems are not very complex. But these hypotheses are consistent with previous works, with which we tried to answer a common challenge in our study. We have found that binary classification problems are not very complex. But these hypotheses are consistent with previous works, with which we tried to answer a common challenge", "histories": [["v1", "Sat, 22 Nov 2014 04:37:15 GMT  (167kb,D)", "http://arxiv.org/abs/1411.6081v1", null]], "reviews": [], "SUBJECTS": "cs.LG cs.NA stat.ML", "authors": ["cho-jui hsieh", "nagarajan natarajan", "inderjit s dhillon"], "accepted": true, "id": "1411.6081"}, "pdf": {"name": "1411.6081.pdf", "metadata": {"source": "CRF", "title": "PU Learning for Matrix Completion", "authors": ["Cho-Jui Hsieh", "Nagarajan Natarajan", "Inderjit S. Dhillon"], "emails": [], "sections": [{"heading": null, "text": "1 (1\u2212\u03c1)n\n) , where 1\u2212\u03c1 denotes the fraction of ones observed. This implies a sample complexity\nof O(n log n) ones to achieve a small error, when M is dense and n is large. We extend our methods and guarantees to the recently proposed inductive matrix completion problem, where rows and columns of M have associated features. We provide efficient and scalable optimization procedures for both the methods and demonstrate the effectiveness of the proposed methods for link prediction (on real-world networks consisting of over 2 million nodes and 90 million links) and semi-supervised clustering tasks."}, {"heading": "1 Introduction", "text": "The problem of recovering a matrix from a given subset of its entries arises in many practical problems of interest. The famous Netflix problem of predicting user-movie ratings is one example that motivates the traditional matrix completion problem, where we would want to recover the underlying (ratings) matrix given partial observations. Strong theoretical guarantees have been developed in the recent past for the low-rank matrix completion problem [Cande\u0300s and Plan, 2009, Cande\u0300s and Recht, 2009, Cande\u0300s and Tao, 2010]. An important variant of the matrix completion problem is to recover an underlying matrix from one-bit quantization of its entries. Modern applications of the matrix completion problem reveal a conspicuous gap between existing matrix completion theory and practice. For example, consider the problem of link prediction in social networks. Here, the goal is to recover the underlying friendship network from a given snapshot of the social graph consisting of observed friendships. We can pose the problem as recovering the adjacency matrix of\nar X\niv :1\n41 1.\n60 81\nv1 [\ncs .L\nG ]\n2 2\nN ov\n2 01\nthe network A such that Aij = 1 if users i and j are related and Aij = 0 otherwise. In practice, we only observe positive relationships between users corresponding to 1\u2019s in A. Thus, there is not only one-bit quantization in the observations, but also a one-sided nature to the sampling process here \u2014 no \u201cnegative\u201d entries are sampled. In the context of classification, methods for learning in the presence of positive and unlabeled examples only, called positive-unlabeled (PU in short) learning, have been studied in the past [Elkan and Noto, 2008, Liu et al., 2003]. For matrix completion, can one guarantee recovery when only a subset of positive entries is observed? In this paper, we formulate the PU matrix completion problem and answer the question in the affirmative under different settings.\nMinimizing squared loss on the observed entries corresponding to 1\u2019s, subject to the low-rank constraints, yields a degenerate solution \u2014 the rank-1 matrix with all its entries equal to 1 achieves zero loss. In practice, a popular heuristic used is to try and complete the matrix by treating some or all of the missing observations as true 0\u2019s, which seems to be a good strategy when the underlying matrix has a small number of positive examples, i.e., small number of 1\u2019s. This motivates viewing the problem of learning from only positive samples as a certain noisy matrix completion problem. Existing theory for noise-tolerant matrix completion [Cande\u0300s and Plan, 2009, Davenport et al., 2012] does not sufficiently address recoverability under PU learning (see Section 2).\nIn our work, we assume that the true matrix M \u2208 Rm\u00d7n has a bounded nuclear norm \u2016M\u2016\u2217. The PU learning model for matrix completion is specified by a certain one-bit quantization process that generates a binary matrix Y from M and a one-sided sampling process that reveals a subset of positive entries of Y . In particular, we consider two recovery settings for PU matrix completion: The first setting is non-deterministic \u2014 M parameterizes a probability distribution which is used to generate the entries of Y . We show that it is possible to recover M using only a subset of positive entries of Y . The idea is to minimize an unbiased estimator of the squared loss between the estimated and the observed \u201cnoisy\u201d entries, motivated by the approach in Natarajan et al. [2013]. We recast the objective as a \u201cshifted matrix completion\u201d problem that facilitates in obtaining a scalable optimization algorithm. The second setting is deterministic \u2014 Y is obtained by thresholding the entries of M (modeling how the users vote), and then a subset of positive entries of Y is revealed. While recovery of M is not possible (see Section 2), we show that we can recover Y with low error. To this end, we propose a scalable biased matrix completion method where the observed and the unobserved entries of Y are penalized differently. Recently, an inductive approach to matrix completion was proposed [Jain and Dhillon, 2013] where the matrix entries are modeled as a bilinear function of real-valued features associated with the rows and the columns. We extend our methods under the two aforementioned settings to the inductive matrix completion problem and establish similar recovery guarantees. Our contributions are summarized below:\n1. To the best of our knowledge, this is the first paper to formulate and study PU learning for matrix completion, necessitated by the applications of matrix completion. Furthermore, we extend our results to the recently proposed inductive matrix completion problem. 2. We provide strong guarantees for recovery; for example, in the non-deterministic setting, the error in recovering an n \u00d7 n matrix is O( 1(1\u2212\u03c1)n) for our method compared to O( 1 (1\u2212\u03c1) \u221a n )\nimplied by the method in Davenport et al. [2012], where (1 \u2212 \u03c1) is the fraction of observed 1\u2019s. 3. Our results provide a theoretical insight for the heuristic approach used in practice, namely, biased matrix completion. 4. We give efficient, scalable optimization algorithms for our methods; experiments on simulated\nand real-world data (social networks consisting of over 2 million users and 90 million links) demonstrate the superiority of the proposed methods for the link prediction problem.\nOutline of the paper. We begin by establishing some hardness results and describing our PU learning settings in Section 2. In Section 3, we propose methods and give recovery guarantees for the matrix completion problem under the different settings. We extend the results to PU learning for inductive matrix completion problem in Section 4. We describe efficient optimization procedures for the proposed methods in Section 5. Experimental results on synthetic and real-world data are presented in Section 6.\nRelated Work. In the last few years, there has been a tremendous amount of work on the theory of matrix completion since the remarkable result concerning recovery of low-rank matrices by Cande\u0300s and Recht [2009]. Strong results on recovery from noisy observations have also been established [Cande\u0300s and Plan, 2009, Keshavan et al., 2010]. Recently, Davenport et al. [2012] studied the problem of recovering matrices from 1-bit observations, motivated by the nature of observations in domains such as recommender systems where matrix completion is heavily applied. Our work draws motivation from recommender systems as well, but differs from Davenport et al. [2012] in that we seek to understand the case when only 1\u2019s in the matrix are observed. One of the algorithms we propose for PU matrix completion is based on using different costs in the objective for observed and unobserved entries. The approach has been used before, albeit heuristically, in the context of matrix completion in recommender system applications [Sindhwani et al., 2010]. Compressed sensing is a field that is closely related to matrix completion. Here the goal is to recover an ssparse vector in Rd using a limited number of linear measurements. Recently, compressed sensing theory has been extended to the case of single-bit quantization [Boufounos and Baraniuk, 2008]. Here, the goal is to recover an s-sparse signal when the observations consist of only the signs of the measurements, and remarkable recovery guarantees have been proved for the single-bit quantization case [Boufounos and Baraniuk, 2008]."}, {"heading": "2 Problem Settings", "text": "We assume that the underlying matrix M \u2208 Rm\u00d7n has a bounded nuclear norm, i.e., \u2016M\u2016\u2217 \u2264 t, where t is a constant independent of m and n. If Mij \u2208 {0, 1} for all (i, j), stating the PU matrix completion problem is straight-forward: we only observe a subset \u21261 randomly sampled from {(i, j) | Mij = 1} and the goal is to recover M based on this \u201cone-sided\u201d sampling. We call this the \u201cbasic setting\u201d. However, in real world applications it is unlikely that the underlying matrix is binary. In the following, we consider two general settings, which include the basic setting as a special case."}, {"heading": "2.1 Non-deterministic setting", "text": "In the non-deterministic setting, we assume Mij has bounded values and without loss of generality we can assume Mij \u2208 [0, 1] for all (i, j) by normalizing it. We then consider each entry as a probability distribution which generates a clean 0-1 observation Y \u2208 Rm\u00d7n:\nP (Yij = 1) = Mij , P (Yij = 0) = 1\u2212Mij ,\nIn the classical matrix completion setting, we will observe partial entries sampled randomly from Y ; In our PU learning model, we assume only a subset of positive entries of Y is observed. More precisely, we observe a subset \u21261 from Y where \u21261 is sampled uniformly from {(i, j) | Yij = 1}. We assume |\u21261| = s\u0304 and denote the number of 1\u2019s in Y by s. With only \u21261 given, the goal of PU matrix completion is to recover the underlying matrix M . Equivalently, letting A \u2208 {0, 1}m\u00d7n to denote the observations, where A\u21261 = 1 and Aij = 0 for all (i, j) /\u2208 \u21261, the non-deterministic setting can be specified as observing A by the process:\nP (Aij = 1) = Mij(1\u2212 \u03c1), P (Aij = 0) = 1\u2212Mij(1\u2212 \u03c1), (1)\nwhere \u03c1 = 1\u2212 s\u0304/s is the noise rate of flipping a 1 to 0 (or equivalently, 1\u2212 \u03c1 is the sampling ratio to obtain \u21261 from Y ).\nHardness of recovering M : The 1-bit matrix completion approach of Davenport et al. [2012] can be applied to this setting \u2014 Given a matrix M , a subset \u2126 is sampled uniformly at random from M , and the observed values are \u201cquantized\u201d by a known probability distribution. We can transform our problem to the 1-bit matrix completion problem by assuming all the unobserved entries are zeros. For convenience we assume M \u2208 Rn\u00d7n. We will show that the one-bit matrix completion approach in [Davenport et al., 2012] is not satisfactory for PU matrix completion in the non-deterministic setting. In [Davenport et al., 2012], the underlying matrix M is assumed to satisfy \u2016M\u2016\u2217 \u2264 t and \u2016M\u2016\u221e \u2264 \u03b1; we are given a subset (chosen uniformly random) \u2126 with |\u2126| = m and we observe the following quantity on \u2126:\nYi,j =\n{ 1 with probability f(Mij),\n\u22121 with probability 1\u2212 f(Mij). (2)\nBy setting f(Mij) = (1\u2212 \u03c1)Mij and 1 \u2265Mij \u2265 0, and assuming \u2126 contains all the n2 entries, it is equivalent to our problem.\nThe estimator is obtained by solving the following optimization problem:\nM\u0302 = argmax X:\u2016X\u2016\u2217\u2264t \u2211 i,j\u2208\u2126  \u2211 i,j:Yij=1 log(f(Xij)) + \u2211 i,j:Yij=0 log(1\u2212 f(Xij))  . (3) The following result shows that M\u0302 is close to M :\nTheorem 1 (Davenport et al. [2012]). Assume \u2016M\u2016\u2217 \u2264 t, and Y is generated by (2), then\n1\nn2 \u2016M\u0302 \u2212M\u20162F \u2264\n\u221a 2C\u03b1\n\u221a 2nr\nm , (4)\nwhere m = |\u2126|, C\u03b1 := C2\u03b1L\u03b1\u03b2\u03b1 where C2 is a constant and\nL\u03b1 = sup |x|\u2264\u03b1 |f \u2032(x)| f(x)(1\u2212 f(x)) and \u03b2\u03b1 = sup |x|\u2264\u03b1 f(x)(1\u2212 f(x)) (f \u2032(x))2 .\nBy substituting f(x) = (1 \u2212 \u03c1)x into the above formulas we can find L\u03b1 \u2265 1\u03b1(1\u2212(1\u2212\u03c1)\u03b1) and \u03b2\u03b1 \u2265 \u03b1(1\u2212(1\u2212\u03c1)\u03b1)1\u2212\u03c1 , so L\u03b1\u03b2\u03b1 \u2265 1 1\u2212\u03c1 . Therefore the above theorem suggests that\n1\nn2 \u2016M\u0302 \u2212M\u20162F \u2264 O\n( \u221a nr\n(1\u2212 \u03c1) \u221a m\n) .\nIn our setting, m = n2, so we have\n1\nn2 \u2016M\u0302 \u2212M\u20162F \u2264 O\n( \u221a r\n(1\u2212 \u03c1) \u221a n\n) . (5)\nThus the recovery error is O (\n1 (1\u2212\u03c1) \u221a n\n) , which implies that the sample complexity for recovery\nusing this approach is quite high: For example, observing O(n log n) 1\u2019s, when M is dense, is not sufficient.\nThe main drawback of using this approach for PU matrix completion is computation \u2014 time complexity of solving (3) is O(n2) which makes the approach prohibitive for large matrices. Moreover, the average error on each element is O(1/ \u221a n) (in contrast, our algorithm has O(1/n) average\nerror). To see how this affects sample complexity for recovery, assume \u2211\ni,jMi,j = O(n 2) (number\nof 1\u2019s are of the same order as the number of 0\u2019s in the original matrix) and O(n log n) 1\u2019s are observed. Then (1\u2212 \u03c1) = O( lognn ) and the average error according to (5) is 1 n2 \u2016M\u0302 \u2212M\u20162F = O( \u221a rn\nlogn), which diverges as n\u2192\u221e. In contrast, we will show that the average error of our estimator vanishes as n\u2192\u221e."}, {"heading": "2.2 Deterministic setting", "text": "In the deterministic setting, a clean 0-1 matrix Y is observed from M by the thresholding process: Yij = I(Mij > q), where I(\u00b7) is the indicator function and q \u2208 R is the threshold. Again, in our PU learning model, we assume only a subset of positive entries of Y are observed, i.e. we observe \u21261 from Y where \u21261 is sampled uniformly from {(i, j) | Yij = 1}. Equivalently, we will use A to denote the observations, where Aij = 1 if (i, j) \u2208 \u21261, and Aij = 0 otherwise.\nIt is impossible to recover M even if we observe all the entries of Y . A trivial example is that all the matrices \u03b7eeT will give Y = eeT if \u03b7 > q, and we cannot recover \u03b7 from Y . Therefore, in the deterministic setting we can only hope to recover the underlying 0-1 matrix Y from the given observations. To the best of our knowledge, there is no existing work that gives a reasonable guarantee of recovering Y . For example, if we apply the noisy matrix completion algorithm proposed in [Cande\u0300s and Plan, 2009], the estimator Y\u0302 has an error bound \u2016Y\u0302 \u2212Y \u2016 \u2264 \u2016A\u2212Y \u2016, which indicates the error in Y\u0302 is not guaranteed to be better than the trivial estimator A.\nHardness of applying noisy matrix completion to our deterministic setting: An easy way to model PU matrix completion problem in the deterministic setting is to think of it as a traditional matrix completion problem with n2 \u201cnoisy\u201d observed entries. In [Cande\u0300s and Plan, 2009], it is assumed that A = M + Z where Z is noise and \u03b4 = \u2016Z\u2016F . The idea is to solve:\nmin \u2016X\u2016\u2217 such that \u2016P\u2126(X \u2212A)\u2016F \u2264 \u03b4, (6)\nwhere \u03b4 is total amount of noise. Cande\u0300s and Plan [2009] established the following recovery guarantee:\nTheorem 2 (Cande\u0300s and Plan [2009]). Let M \u2208 Rn\u00d7n be a fixed matrix of rank r, and assume M is \u00b5-incoherent, i.e.,\n\u2016ui\u2016\u221e \u2264 \u221a \u00b5/n and \u2016vi\u2016\u221e \u2264 \u221a \u00b5/n, (7)\nwhere ui,vi are eigenvectors of M . Suppose we observe m entries of M with locations sampled uniformly at random, and\nm \u2265 C\u00b52nr log6 n, (8)\nwhere C is a numerical constant, then\n\u2016M\u0302 \u2212M\u2016 \u2264 4\n\u221a (2 + p)n\np \u03b4 + 2\u03b4, (9)\nwhere p = m/n2.\nIf we apply Theorem 2 to our case, \u03b4 = \u2016Z\u2016F = \u03c11\u2212\u03c1 s\u0304, the error of the recovered matrix M\u0302 using (6) can be bounded as:\n\u2016M\u0302 \u2212M\u2016F \u2264 \u2016A\u2212M\u2016F , (10)\nand clearly this bound is not very useful."}, {"heading": "3 Proposed Algorithms for PU Matrix Completion", "text": "In this section, we introduce two algorithms: shifted matrix completion for non-deterministic PU matrix completion, and biased matrix completion for deterministic PU matrix completion. All proofs are deferred to Appendix A."}, {"heading": "3.1 Shifted Matrix Completion for Non-deterministic Setting (ShiftMC)", "text": "We want to find a matrix X such that the loss \u2016M \u2212X\u20162F is bounded, using the noisy observation matrix A generated from M by (1). Observe that conditioned on Y , the noise in Aij is asymmetric, i.e. P (Aij = 0|Yij = 1) = \u03c1 and P (Aij = 1|Yij = 0) = 0. Asymmetric label noise has been studied in the context of binary classification, and recently Natarajan et al. [2013] proposed a method of unbiased estimator to bound the true loss using only noisy observations. In our case, we aim to find a matrix minimizing the unbiased estimator defined on each element, which leads to the following optimization problem:\nmin X \u2211 i,j \u02dc\u0300(Xij , Aij) such that \u2016X\u2016\u2217 \u2264 t, 0 \u2264 Xij \u2264 1 \u2200(i, j). (11)\nwhere \u02dc\u0300(Xij , Aij) =\n{ (Xij\u22121)2\u2212\u03c1X2ij\n1\u2212\u03c1 if Aij = 1,\nX2ij if Aij = 0. (12)\nThe bound constraint on X in the above estimator ensures the loss has bounded Lipschitz constant. This optimization problem is equivalent to the traditional trace-norm regularization problem\nmin X \u2211 i,j \u02dc\u0300(Xij , Aij) + \u03bb\u2016X\u2016\u2217, such that 0 \u2264 Xij \u2264 1 \u2200(i, j), (13)\nwhere \u03bb has a one-to-one mapping to t. We use \u02dc\u0300 instead of the original loss ` because it is the unbiased estimator of the underlying squared loss `(Xij ,Mij) = (Xij \u2212Mij)2, as formalized below. Thus, we use \u02dc\u0300 on the observed Aij , we minimize the loss w.r.t. Yij in expectation.\nLemma 1. For any X \u2208 Rm\u00d7n, 1mnE [\u2211 i,j(Xij \u2212 Yij)2 ] = 1mnE [\u2211 i,j \u02dc\u0300(Xij , Aij) ] .\nInterestingly, we can rewrite \u02dc\u0300 as \u02dc\u0300(Xij , 1) = ( Xij \u2212 11\u2212\u03c1 )2 \u2212 \u03c1 (1\u2212\u03c1)2 . Therefore, (13) can be\nrewritten as the following \u201cshifted matrix completion\u201d problem:\nX\u0302 = argmin X \u2211 i,j:Aij=1 ( Xij \u2212 1 1\u2212 \u03c1 )2 + \u2211 i,j:Aij=0 X2ij + \u03bb\u2016X\u2016\u2217 s.t. 0 \u2264 Xij \u2264 1 \u2200(i, j). (14)\nWe want to show that the average error of the ShiftMC estimator X\u0302 decays as O(1/n). In order to do so, we first need to bound the difference between the expected error and the empirical error. We define the hypothesis space to be X := {X | X \u2208 Rm\u00d7n and \u2016W\u2016\u2217 \u2264 t}. The expected error can be written as EA[R\u02dc\u0300(W )] = EA[ 1 mn \u2211 i,j\n\u02dc\u0300(Wij , Aij)], and the empirical error is R\u0302\u02dc\u0300(W ) = 1 mn \u2211 i,j\n\u02dc\u0300(Wij , Aij). We first show that the difference between expected error and empirical error can be upper bounded:\nTheorem 3. Let X := {X \u2208 Rm\u00d7n | \u2016X\u2016\u2217 \u2264 t, 0 \u2264 X \u2264 1}, then\nmax X\u2208X \u2223\u2223\u2223EA[R\u02dc\u0300(X)]\u2212 R\u0302\u02dc\u0300(X)\u2223\u2223\u2223 \u2264 tC\u221an+\u221am+ 4\u221as (1\u2212 \u03c1)mn + 3 \u221a log(2/\u03b4)\u221a mn(1\u2212 \u03c1)\n(15)\nwith probability at least 1 \u2212 \u03b4, where C is a constant, E[R\u02dc\u0300(X)] := E[ 1mn \u2211 i,j \u02dc\u0300(Xij , Aij)] is the expected error, and R\u0302\u02dc\u0300(X) = 1 mn \u2211 i,j \u02dc\u0300(Xij , Aij) is the empirical error.\nCombining Lemma 1 and Theorem 3, we have our first main result:\nTheorem 4 (Main Result 1). With probability at least 1\u2212 \u03b4,\n1\nmn \u2211 i,j (Mij \u2212 X\u0302ij)2 \u2264 6 \u221a log(2/\u03b4)\u221a mn(1\u2212 \u03c1) + 2Ct \u221a n+ \u221a m+ 4 \u221a s (1\u2212 \u03c1)mn .\nThe average error is of the order of O( 1n(1\u2212\u03c1)) when M \u2208 R n\u00d7n, where 1 \u2212 \u03c1 denotes the ratio of observed 1\u2019s. This shows that even when we only observe a very small ratio of 1\u2019s in the matrix, we can still estimate M accurately when n is large enough."}, {"heading": "3.2 Biased Matrix Completion for Deterministic Setting (BiasMC)", "text": "In the deterministic setting, we propose to solve the matrix completion problem with label-dependent loss [Scott, 2012]. Let `(x, a) = (x \u2212 a)2 denote the squared loss, for a \u2208 {0, 1}. The \u03b1-weighted loss is defined by\n`\u03b1(x, a) = \u03b11a=1`(x, 1) + (1\u2212 \u03b1)1a=0`(x, 0), (16)\nwhere 1a=1, 1a=0 are indicator functions. We then recover the groundtruth by solving the following biased matrix completion (biasMC) problem:\nX\u0302 = argmin X:\u2016X\u2016\u2217\u2264t \u2211 i,j `\u03b1(Xij , Aij) = argmin X:\u2016X\u2016\u2217\u2264t \u03b1 \u2211\ni,j:Aij=1\n(Xij \u2212 1)2 + (1\u2212 \u03b1) \u2211\ni,j:Aij=0\nX2ij (17)\nThe underlying binary matrix Y is then recovered by the thresholding operator X\u0304ij = I(X\u0302ij > q). A similar formulation has been used in [Sindhwani et al., 2010] to recommend items to users in the \u201cwho-bought-what\u201d network. Here, we show that this biased matrix factorization technique can be used to provably recover Y . For convenience, we define the thresholding operator thr(x) = 1 if x > q, and thr(x) = 0 if x \u2264 q. We first define the recovery error as R(X) = 1mn \u2211 i,j 1thr(Xij) 6=Yij , where Y is the underlying 0-1 matrix. Define the label-dependent error:\nU\u03b1(x, a) = (1\u2212 \u03b1)1thr(x)=11a=\u22121 + \u03b11thr(x)=\u221211a=1. (18)\nand \u03b1-weighted expected error and expected \u03b1-weighted loss: R\u03b1,\u03c1(X) = E [\u2211 i,j U\u03b1(Xij , Aij) ] , Rl\u03b1,\u03c1(X) = E [\u2211 i,j l\u03b1(Xij , Aij) ] . (19)\nThe following lemma is a special case of Theorem 9 in [Natarajan et al., 2013], showing that R(X) and R\u03b1,\u03c1(X) can be related by a linear transformation:\nLemma 2. For the choice \u03b1\u2217 = 1+\u03c12 and a = 1+\u03c1\n2 , there exists a constant b that is independent of"}, {"heading": "X such that, for any matrix X,", "text": "R\u03b1\u2217,\u03c1(X) = aR(X) + b.\nTherefore, minimizing the \u03b1-weighed expected error in the partially observed situation is equivalent to minimizing the true recovery error R. By further relating R\u03b1\u2217,\u03c1(X) and R`\u03b1\u2217 ,\u03c1(X) we can show:\nTheorem 5 (Main Result 2). Let X\u0302 be the minimizer of (17), and X\u0304 be the thresholded 0-1 matrix of X\u0302, then with probability at least 1\u2212 \u03b4, we have\nR(X\u0304) \u2264 2\u03b7 1 + \u03c1\n( Ct \u221a n+ \u221a m+ 4 \u221a s\nmn + 3 \u221a log(2/\u03b4)\u221a mn(1\u2212 \u03c1) ) ,\nwhere \u03b7 = max(1/q2, 1/(1\u2212 q)2) and C is a constant.\nThe average error is of the order of O( 1n(1\u2212\u03c1)) when M \u2208 R n\u00d7n, where 1 \u2212 \u03c1 denotes the ratio\nof observed 1\u2019s, similar to the ShiftMC estimator."}, {"heading": "4 PU Inductive Matrix Completion", "text": "In this section, we extend our approaches to inductive matrix completion problem, where in addition to the samples, row and column features Fu \u2208 Rm\u00d7d, Fv \u2208 Rn\u00d7d are also given. In the standard inductive matrix completion problem [Jain and Dhillon, 2013], the observations A\u2126 are sampled\nfrom the groundtruth M \u2208 Rm\u00d7n, and we want to recover M by solving the following optimization problem:\nmin D\u2208Rd\u00d7d \u2211 i,j\u2208\u2126 (Aij \u2212 (FuDF Tv )ij)2 + \u03bb\u2016D\u2016\u2217. (20)\nMatrix completion is a special case of inductive matrix completion when Fu = I, Fv = I. In the multi-label learning problem, M represents the label matrix and Fu corresponds to examples (typically Fv = I) [Yu et al., 2014, Xu et al., 2013]. This technique has also been applied to genedisease prediction [Natarajan and Dhillon, 2014], semi-supervised clustering [Yi et al., 2013], and theoretically studied in [Jain and Dhillon, 2013].\nThe problem is fairly recent and we wish to extend PU learning analysis to this problem, which is also well motivated in many real world applications. For example, in multi-label learning with partially observed labels, negative labels are usually not available. In the experiments, we will consider another interesting application \u2014 semi-supervised clustering problem with only positive and unlabeled relationships."}, {"heading": "4.1 Shifted Inductive Matrix Completion for Non-deterministic Setting", "text": "In the non-deterministic setting, we consider the inductive version of ShiftMC:\nmin D\u2208Rd\u00d7d \u2211 i,j \u02dc\u0300((FuDF T v )ij , Aij) such that \u2016D\u2016\u2217 \u2264 t, 1 \u2265 FuDF Tv \u2265 0, (21)\nwhere the unbiased estimator of loss \u02dc\u0300(\u00b7) is defined in (12). Note that we can assume that Fu, Fv are orthogonal (otherwise we can conduct a preprocessing step to normalize it). Let ui be the i-th row of Fu (the feature for row i) and vj be the j-th row of Fv. Define constants Xu = maxi \u2016ui\u2016,Xv = maxj \u2016vj\u2016.\n\u03b3 = min ( mini \u2016ui\u2016 Xu , mini \u2016vi\u2016 Xv ) .\nIn practice if one does an instance-wise scaling of features, \u00b5 will be 1. Assume Fu = U\u03a3V , then we define F\u0304u = Ud\u0304\u03a3d\u0304Vd\u0304 where \u03c3d\u0304 is the smallest singular value with \u03c3d \u2265 \u00b5\u03c31. By the same way we can define F\u0304v. We assume the column space of the ground truth M lies in span(F\u0304u) and the row space of M lies in span(F\u0304v). We expect \u00b5 to be not too small, which indicates that the ground truth matrix lies in a more informative subspace of Fu and Fv. Since the output of inductive matrix completion is FuDFv, it can only recover the original matrix when the underlying matrix M can be written in such form. Following Xu et al. [2013], Yi et al. [2013], we assume the features are good enough such that M = Fu(Fu) TMFv(Fv) T . Recall \u2016M\u2016\u2217 \u2264 t. We now extend Theorem 4 to PU inductive matrix completion.\nTheorem 6. Assume D\u0302 is the optimal solution of (21) and the groundtruth M is in the subspace formed by Fu and Fv: M = Fu(Fu) TMFv(Fv) T , then\n1\nmn \u2211 i,j (Mij \u2212 (F Tu D\u0302Fv)ij)2 \u2264 6 \u221a log(2/\u03b4)\u221a mn(1\u2212 \u03c1) + 4t \u221a log 2d\u221a mn \u221a 1\u2212 \u03c1 XuXv. (22)\nwith probability at least 1\u2212 \u03b4.\nTherefore if t and d are bounded, the mean square error of shiftMC is O(1/n)."}, {"heading": "4.2 Biased Inductive Matrix Completion for Deterministic Setting", "text": "In the deterministic setting, we propose to solve the inductive version of BiasMC:\nD\u0302 = arg min D:\u2016D\u2016\u2217\u2264t\n\u03b1 \u2211\ni,j:Aij=1\n((FuDF T v )ij \u2212 1)2 + (1\u2212 \u03b1) \u2211 i,j:Aij=0 (FuDF T v ) 2 ij . (23)\nThe clean 0-1 matrix Y can then be recovered by Y\u0302ij = I((FuD\u0302F T v )ij > q).\nY\u0302ij =\n{ 1 if (FuD\u0302F T v )ij \u2265 q\n0 if (FuD\u0302F T v )ij < q.\n(24)\nSimilar to the case of matrix completion, Lemma 2 shows that the expected 0-1 error R(X) and the \u03b1-weighted expected error in noisy observation R\u03b1,\u03c1(X) can be related by a linear transformation when \u03b1\u2217 = 1+\u03c12 . With this choice of \u03b1\n\u2217, Lemma 2 continues to hold in this case, which allows us to extend Theorem 5 to PU inductive matrix completion:\nTheorem 7. Let D\u0302 be the minimizer of (23) with \u03b1\u2217 = (1 + \u03c1)/2, and let Y\u0302 be generated from D\u0302 by thresholding, then with probability at least 1\u2212 \u03b4, we have\nR(Y\u0302 ) = 1\nmn \u2016Y \u2212 Y\u0302 \u20162F \u2264\n2\u03b7\n1 + \u03c1\n( 4t \u221a\nlog 2d\u221a mn \u221a 1\u2212 \u03c1 XuXv + 6 \u221a log(2/\u03b4)\u221a mn(1\u2212 \u03c1) ) ,\nwhere \u03b7 = max(1/q2, 1/(1\u2212 q)2).\nAgain, we have that if t and d are bounded, the mean square error of BiasMC is O(1/n)."}, {"heading": "5 Optimization Techniques for PU Matrix Completion", "text": "In this section, we show that BiasMC can be solved very efficiently for large-scale (millions of rows and columns) datasets, and that ShiftMC can be solved efficiently after a relaxation.\nFirst, consider the optimization problem for BiasMC:\nargmin X\n\u03b1 \u2211\ni,j:Aij=1\n(Xij \u2212 1)2 + (1\u2212 \u03b1) \u2211\ni,j:Aij=0\nX2ij + \u03bb\u2016X\u2016\u2217 := fb(X) + \u03bb\u2016X\u2016\u2217, (25)\nwhich is equivalent to the constrained problem (17) with suitable \u03bb. The typical proximal gradient descent update isX \u2190 S(X\u2212\u03b7\u2207fb(X), \u03bb), where \u03b7 is the learning rate and S is the soft thresholding operator on singular values [Ji and Ye, 2009]. The (approximate) SVD of G := (X\u2212 \u03b7\u2207fb(X)) can be computed efficiently using power method or Lanczos algorithm if we have a fast procedure to compute GP for a tall-and-thin matrix P \u2208 Rn\u00d7k. In order to do so, we first rewrite fb(X) as\nfb(X) = (1\u2212 \u03b1)\u2016X \u2212A\u20162F + (2\u03b1\u2212 1) \u2211\ni,j:Aij=1\n(Xij \u2212Aij)2. (26)\nAssume the current solution is stored in a low-rank form X = WHT and R = (X \u2212 A)\u21261 is the residual on \u21261, then\nGP = XP \u2212 2\u03b7 ((1\u2212 \u03b1)(X \u2212A) + (2\u03b1\u2212 1)(X \u2212A)\u21261)P = (1\u2212 2\u03b7(1\u2212 \u03b1))WHTP + 2\u03b7(1\u2212 \u03b1)AP \u2212 2\u03b7(2\u03b1\u2212 1)RP,\nwhere the first term can be computed in O(mk2 + nk2) flops, and the remaining terms can be computed in O(|\u21261|k) flops. With this approach, we can efficiently compute the proximal operator. This can also be applied to other faster nuclear norm solvers (for example, [Hsieh and Olsen, 2014]).\nNext we show that the non-convex form of BiasMC can also be efficiently solved, and thus can scale to millions of nodes and billions of observations. It is well known that the nuclear norm regularized problem minX fb(X) + \u03bb\u2016X\u2016\u2217 is equivalent to\nmin W\u2208Rm\u00d7k,H\u2208Rn\u00d7k\nfb(WH T ) +\n\u03bb 2 (\u2016W\u20162F + \u2016H\u20162F ) (27)\nwhen k is sufficiently large. We can use a trick similar to (26) to compute the gradient and Hessian efficiently:\n\u2207W fb(WHT ) = 2(1\u2212 \u03b1)(WHTH \u2212AH) + 2(2\u03b1\u2212 1)R\u2126H and \u22072Wi,\u00b7fb(WH T ) = 2(1\u2212 \u03b1)HTH + 2(2\u03b1\u2212 1)HT\u2126iH\u2126i ,\nwhereH\u2126i is the sub-matrix with columns {hj : j \u2208 \u2126i}, and \u2126i is the column indices of observations in the i-th row. Thus, we can efficiently apply Alternating Least Squares (ALS) or Coordinate Descent (CD) for solving (27). For example, when applying CCD++ in [Yu et al., 2013], each coordinate descent update only needs O(|\u2126i| + k) flops. We apply this technique to solve largescale link prediction problems (see Section 6).\nThe optimization problem for ShiftMC is harder to solve because of the bounded constraint. We can apply the bounded matrix factorization technique [Kannan et al., 2014] to solve the non-convex form of (13), where the time complexity is O(mn) because of the constraint 0 \u2264 (WHT )ij \u2264 1 for all (i, j). To scale it to large datasets, we relax the bounded constraint and solve:\nmin W\u2208Rm\u00d7k,H\u2208Rn\u00d7k\n\u2016A\u2212WHT \u20162F + \u03bb\n2 (\u2016W\u20162F + \u2016H\u20162F ) s.t. 0 \u2264W,H \u2264\n\u221a 1/k (28)\nThis approach (ShiftMC-relax) is easy to solve by ALS or CD with O(|\u2126|k) complexity per sweep (similar to the BiasMC). In our experiments, we show ShiftMC-relax performs even better than shiftMC in practice."}, {"heading": "6 Experiments", "text": "We first use synthetic data to show that our bounds are meaningful and then demonstrate the effectiveness of our algorithms in real world applications."}, {"heading": "6.1 Synthetic Data", "text": "We assume the underlying matrix M \u2208 Rn\u00d7n is generated by UUT , where U \u2208 Rn\u00d7k is the orthogonal basis of a random Gaussian n by k matrix with mean 0 and variance 1. For the nondeterministic setting, we linearly scale M to have values in [0, 1], and then generate training samples as described Section 2. For deterministic setting, we choose q so that Y has equal number of zeros and ones. We fix \u03c1 = 0.9 (so that only 10% 1\u2019s are observed). From Lemma 2, \u03b1 = 0.95 is optimal. We fix k = 10, and test our algorithms with different sizes n. The results are shown in Figure 1(a)-(b). Interestingly, the results reflect our theory: error of our estimators decreases with n; in\nparticular, error linearly decays with n in log-log scaled plots, which suggests a rate of O(1/n), as shown in Theorems 4 and 5. Directly minimizing \u2016A\u2212X\u20162F gives very poor results. For BiasMF, we also plot the performance of estimators with various \u03b1 values in Figure 1(b). As our theory suggests, \u03b1 = 1+\u03c12 performs the best. We also observe that the error is well-behaved in a certain range of \u03b1. A principled way of selecting \u03b1 is an interesting problem for further research."}, {"heading": "6.2 Parameter Selection", "text": "Before showing the experimental results on real-world problems, we discuss the selection of the parameter \u03c1 in our PU matrix completion model (see eq (1)). Note that \u03c1 indicates the noise rate of flipping a 1 to 0. If there are equal number of positive and negative elements in the underlying matrix Y , we will have \u03c1 = 1 \u2212 2s where s = (# positive entries)/(# total entries). In practice (e.g., link prediction problems) number of 1\u2019s are usually less than number of 0 in the underlying matrix, but we do not know the ratio. Therefore, in all the experiments we chose \u03c1 from the set {1 \u2212 2s, 10(1 \u2212 2s), 100(1 \u2212 2s), 1000(1 \u2212 2s)} based on a random validation set, and use the corresponding \u03b1 in the optimization problems."}, {"heading": "6.3 Matrix completion for link prediction", "text": "One of the important applications that motivated our analysis in this paper is the link prediction problem. Here, we are given n nodes (users) and a set of edges \u2126train (relationships) and the goal is to predict missing edges, i.e. \u2126test. We use 4 real-world datasets: 2 co-author networks ca-GrQc (4,158 nodes and 26,850 edges) and ca-HepPh (11,204 nodes and 235,368 edges), where we randomly split edges into training and test such that |\u2126train| = |\u2126test|; 2 social networks LiveJournal (1,770,961 nodes, |\u2126train| = 83,663,478 and |\u2126test| = 2,055,288) and MySpace (2,137,264 nodes, |\u2126train| = 90,333,122 and |\u2126test| = 1,315,594), where train/test split is done using timestamps. For our proposed methods BiasMC, ShiftMC and ShiftMC-relax, we solve the non-convex form with k = 50 for ca-GrQc, ca-HepPh and k = 100 for LiveJournal and MySpace. The \u03b1 and \u03bb values are chosen by a validation set.\nWe compare with competing link prediction methods [Kiben-Nowell and Kleinberg, 2003] Common Neighbors, Katz, and SVD-Katz (compute Katz using the rank-k approximation, A \u2248 Uk\u03a3kVk). Note that the classical matrix factorization approach in this case is equivalent to SVD on the given 0-1 training matrix, and SVD-Katz slightly improves over SVD by further computing the Katz values based on the low rank approximation (see Kiben-Nowell and Kleinberg [2003]), so we omit the SVD results in the figures.\nBased on the training matrix, each link prediction method will output a list of k candidate entries. The quality of the top-k entries can be evaluated by computing the False Positive Rate (FPR) and False Negative Rate (FNR) defined by\nFPR = # of incorrectly predicted links # of non-friend links , FNR = 1\u2212 # of correctly predicted links # of actual links ,\nwhere the groundtruth is given in the test snapshot. The results are shown in Figure 1. ca-GrQc is a small dataset, so we can solve the original ShiftMC problem accurately, although ShiftMCrelax achieves a similar performance here. For larger datasets, we show only the performance of ShiftMC-relax. In general BiasMC performs the best, and ShiftMC tends to perform better in the beginning. Overall, our methods achieve lower FPR and FNR comparing to other methods,\nwhich indicate that we obtain a better link prediction model by solving the PU matrix completion problem. Also, BiasMC is highly efficient \u2014 it takes 516 seconds for 10 coordinate descent sweeps on the largest dataset (MySpace), whereas computing top 100 eigenvectors using eigs in Matlab requires 2408 seconds."}, {"heading": "6.4 Inductive matrix completion", "text": "We use the semi-supervised clustering problem to evaluate our PU inductive matrix completion methods. PU inductive matrix completion can be applied to many real-world problems, including recommender systems with features and 0-1 observations, and the semi-supervised clustering problem when we can only observed positive relationships. Here we use the latter as an example to demonstrate the usefulness of our algorithm.\nIn semi-supervised clustering problems, we are given n samples with features {xi}ni=1 and pairwise relationships A \u2208 Rn\u00d7n, where Aij = 1 if two samples are in the same cluster, Aij = \u22121 if they are in different clusters, and Aij = 0 if the relationship is unobserved. Note that the groundtruth matrix M \u2208 {+1,\u22121}n\u00d7n exhibits a simple structure and is a low rank as well as low trace norm matrix; it is shown in [Yi et al., 2013] that we can recover M using IMC when there are both positive and negative observations.\nNow we consider the setting where only positive relationships are observed, so A is a 0-1 matrix. We show that biased IMC can recover M using very few positive relationships. We test the algorithms on two datasets: the Mushroom dataset with 8142 samples, 112 features, and 2 classes; the Segment dataset with 2310 samples, 19 features, and 7 classes. The results are presented in Figure 2.\nWe compare BiasMC-inductive with (a) MC-inductive, which considers all the unlabeled pairs as zeros and minimizes \u2016FuDF Tv \u2212 A\u20162F , and (b) spectral clustering, which does not use feature information. Since the data is from classification datasets, the ground truth M is known and can\nbe used to evaluate the results. In Figure 2, the vertical axis is the clustering error rate defined by\n(number of entries in M predicted with correct sign)/n2.\nFigure 2 shows that BiasMC-inductive is much better than other approaches for this task."}, {"heading": "7 Conclusions", "text": "Motivated by modern applications of matrix completion, our work attempts to bridge the gap between the theory of matrix completion and practice. We have shown that even when there is noise in the form of one-bit quantization as well as one-sided sampling process revealing the measurements, the underlying matrix can be accurately recovered. We have considered two recovery settings, both of which are natural for PU learning, and have provided similar recovery guarantees for the two. Our error bounds are strong and useful in practice. Our work serves to provide the first theoretical insight into the biased matrix completion approach that has been employed as a heuristic for similar problems in the past. Experimental results on synthetic data conform to our theory; effectiveness of our methods are evident for the link prediction task in real-world networks. A principled way of selecting or estimating the bias \u03b1 in BiasMC seems worthy of exploration given our encouraging results."}, {"heading": "A Proofs", "text": "A.1 Proof of Lemma 1\nProof.\n1\nmn E [\u2211 i,j l\u0303(Xij , Aij) ] = 1 mn \u2211 i,j E [ l\u0303(Xij , Aij) ]\n= 1\nmn \u2211 i,j\n( P (Yij = 0)X 2 ij + P (Yij = 1) ( \u03c1X2ij + (1\u2212 \u03c1)( (Xij \u2212 1)2 \u2212 \u03c1X2ij 1\u2212 \u03c1 ) ))\n= 1\nmn \u2211 i,j ( P (Yij = 0)X 2 ij + P (Yij = 1)(Xij \u2212 1)2 ) = 1\nmn E [\u2211 i,j (Xij \u2212 Yij)2 ] = 1 mn E [ l(Xij , Yij) ] .\nA.2 Proof of Theorem 3\nProof. We want to bound supX\u2208X \u2223\u2223\u2223R\u0302l\u0303(X)\u2212 EA[Rl\u0303(X)]\u2223\u2223\u2223. First, EA[Rl\u0303(X)] \u2264 R\u0302l\u0303(X) + sup\nX\u2208X\n( EA[ 1\nmn \u2211 i,j l\u0303(Xij , Aij)]\u2212 1 mn \u2211 i,j l\u0303(Xij , Aij) ) .\nApply McDiarmid\u2019s Theorem in [Shawe-Taylor and Cristianini, 2004]; since each l\u0303(Xij , Aij) can be either X2ij or (Xij\u22121)2\u2212\u03c1X2ij 1\u2212\u03c1 , when changing one random variable Aij , in the worst case the quantity\nsupX\u2208X ( EA[Rl\u0303(X)]\u2212 1 mn \u2211 i,j l\u0303(Xij , Aij) ) can be changed by \u2223\u2223\u2223X2ij \u2212 (Xij \u2212 1)2 \u2212 \u03c1X2ij1\u2212 \u03c1 \u2223\u2223\u2223 \u2264 \u2223\u2223\u22232Xij + 11\u2212 \u03c1 \u2223\u2223\u2223 \u2264 31\u2212 \u03c1. So by McDiarmid\u2019s Theorem, with probability 1\u2212 \u03b4/2,\nsup X\u2208X\n( EA(Rl\u0303(X))\u2212 1\nmn \u2211 i,j l\u0303(Xij , Aij) ) \u2264 EA  sup X\u2208X ( EA(Rl\u0303(X))\u2212 1 mn \u2211 i,j l\u0303(Xij , Aij) )+3 \u221alog(2/\u03b4)\u221a mn(1\u2212 \u03c1) .\n(29)\nAlso,\nEA  sup X\u2208X ( EA[Rl\u0303(X)]\u2212 1 mn \u2211 i,j l\u0303(Xij , Aij) ) (30)\n\u2264 EA,A\u0303  sup X\u2208X ( 1 mn \u2211 i,j l\u0303(Xij , A\u0303ij)\u2212 1 mn \u2211 i,j l\u0303(Xij , Aij) ) (31)\n= EA,A\u0303  sup X\u2208X 1 mn \u2211 i,j (l\u0303(Xij , A\u0303ij)\u2212 l\u0303(Xij , Aij))  (32) = 1\nmn EA,A\u2032,\u03c3  sup X\u2208X \u2211 i,j:Mij=1 \u03c3ij(l\u0303(Xij , A\u0303ij)\u2212 l\u0303(Xij , Aij))  (33) \u2264 1 mn EA,\u03c3  sup X\u2208X \u2211 i,j:Mij=1 \u03c3ij l\u0303(Xij , Aij)\n (34) where \u03c3ij are random variables with half chance to be +1 and half chance to be -1. Where from (32) to (33) we use the fact that Aij = 0 with probability 1 if Mij = 0. Next we want to bound the\nRademacher complexity EA,\u03c3 [ supX\u2208X \u2211 i,j:Mij=1 \u03c3ij l\u0303(Xij , Aij) ] . When Mij = 1,\nl\u0303(Xij , Aij) = { X2ij with probability \u03c1 (Xij\u22121)2\u2212\u03c1X2ij\n1\u2212\u03c1 with probability 1\u2212 \u03c1\nSince 0 \u2264 Xij \u2264 1, the Lipschitz constant for l\u0303(Xij , Aij) is at most 1/(1\u2212 \u03c1), so\n(34) \u2264 1 mn E\u03c3( sup X\u2208X \u2211 i,j:Mij=1 \u03c3ijXij)\n\u2264 1 (1\u2212 \u03c1)mn E\u03c3 [ sup X\u2208X \u2016PMij=1(\u03c3)\u20162\u2016X\u2016\u2217 ] .\nAs pointed out in Shamir and Shalev-Shwartz [2011], we can then apply the main Theorem in Latala [2005], when Z is an independent zero mean random matrix,\nE[\u2016Z\u20162] \u2264 C max i \u221a\u2211 j E[Z2ij ] + maxj \u221a\u2211 i E[Z2ij ] + 4 \u221a\u2211 ij E[Z4ij ]  with a universal constant C.\nSo in our case E[\u2016\u03c3\u20162] \u2264 C ( \u221a n+ \u221a m+ 4 \u221a s), so (34) \u2264 tC \u221a n+ \u221a m+ 4 \u221a s\n(1\u2212\u03c1)mn .\nA.3 Proof of Theorem 4\nLet X\u0302 be the minimizer of (11), and\nP := tC\n\u221a n+ \u221a m+ 4 \u221a s\n(1\u2212 \u03c1)mn + 3 \u221a log(2/\u03b4)\u221a mn(1\u2212 \u03c1) ,\nwe have\nE [ 1 mn \u2211 i,j (X\u0302ij \u2212 Yij)2 ] = E [ 1 mn \u2211 i,j l\u0303(X\u0302ij , Aij) ] (Lemma 1)\n\u2264 R\u0302l\u0303(X\u0302) + P (Theorem 3) \u2264 R\u0302l\u0303(M) + P (by the definition of X\u0302)\n\u2264 E [ 1 mn l\u0303(Mij , Aij) ] + 2P (Theorem 3)\n= E [ 1 mn \u2211 i,j (Mij \u2212 Yij)2 ] (Lemma 1)\nTherefore 1\nmn \u2211 i,j E [ (Xij \u2212 Yij)2 \u2212 (Mij \u2212 Yij)2 ] \u2264 2P.\nSince P (Yij = 1) = Mij , we have E [ (Xij \u2212 Yij)2 \u2212 (Mij \u2212 Yij)2] = Mi,j ( (Xij \u2212 1)2 \u2212 (Mij \u2212 1)2 ) + (1\u2212Mij)(X2ij \u2212M2ij)\n= (Xij \u2212Mij)2,\ntherefore 1\nmn \u2211 i,j (Xij \u2212Mij)2 \u2264 2P.\nA.4 Proof of Theorem 5\nProof. We want to show\nR\u03b1,\u03c1(X)\u2212min X R\u03b1,\u03c1(X) \u2264 \u03b7(Rl\u03b1,\u03c1(X)\u2212min X Rl\u03b1,\u03c1(X)), (35)\nwhere \u03b7 = max(1/q2, 1/(1\u2212 q)2). Consider the following two cases. If Yij = 0, then\nR\u03b1,\u03c1(Xij) = \u03b11Xij>q, min Xij R\u03b1,\u03c1(Xij) = 0 Rl\u03b1,\u03c1(Xij) = \u03b1X 2 ij , min\nXij Rl\u03b1,\u03c1(Xij) = 0,\nso the left hand side of (35) is \u03b11Xij>q and the right hand side is \u03b1X 2 ij . Therefore we can simply verify that (35) holds with \u03b7 = 1/q2. For the second case if Yij = 1,\nR\u03b1,\u03c1(Xij) = \u03c1(1\u2212 \u03b1\u2217)1Xij>q + (1\u2212 \u03c1)\u03b1\u22171Xij<q = (1\u2212 \u03c1)(1 + \u03c1)\n2 1Xij<q + \u03c1(1\u2212 \u03c1) 2 1Xij>q,\nRl\u03b1,\u03c1(Xij) = (1\u2212 \u03c1)(1 + \u03c1)\n2 (Xij \u2212 1)2 + \u03c1(1\u2212 \u03c1) 2 X2ij .\nWe can see (1\u2212\u03c1)(1+\u03c1)1Xij<q \u2264 1(1\u2212q)2 (1\u2212\u03c1)(1+\u03c1)(Xij\u22121) 2 and \u03c1(1\u2212\u03c1)1Xij<q < 1q2 \u03c1(1\u2212\u03c1)X 2 ij , so both will satisfied by our chosen \u03b7.\nNext we compute minXij R\u03b1,\u03c1(Xij) and minXij Rl\u03b1,\u03c1(Xij). By definition\nR\u03b1\u2217,\u03c1(Xij) = { \u03c1(1\u2212 \u03b1\u2217) = \u03c1(1\u2212\u03c1)2 if Xij > q (1\u2212 \u03c1)\u03b1\u2217 = (1+\u03c1)(1\u2212\u03c1)2 if Xij < q.\nTherefore\nmin Xij\nR\u03b1,\u03c1(Xij) = \u03c1(1\u2212 \u03c1)\n2 . (36)\nOn the other hand,\nRl\u03b1,\u03c1(x) = \u03c1(1\u2212 \u03b1\u2217)x2 + (1\u2212 \u03c1)\u03b1\u2217(x\u2212 1)2 = \u03c1(1\u2212 \u03c1)\n2 x2 + (1\u2212 \u03c1)(1 + \u03c1) 2 (x\u2212 1)2.\nTaking gradient equals to zero we get x\u2217 = \u03c1+12\u03c1+1 , and therefore\nmin x Rl\u03b1,\u03c1(x) = (1 + \u03c1)\u03c1(1\u2212 \u03c1) 2 \u2264 \u03c1(1\u2212 \u03c1). (37)\nCombining (36) and (37), we have\nmin x R\u03b1,\u03c1 \u2265 min x Rl\u03b1,\u03c1/2,\ntherefore we need \u03b7 \u2265 2. But this is satisfied by \u03b7 = max(1/q2, 1/(1\u2212 q)2). Combining the above arguments, we proved that (35) holds.\nNext we show an upper bound of (35). Using the proof similar to Theorem 3 we have\nRl\u03b1,\u03c1(X)\u2212min X\nRl\u03b1,\u03c1(X) \u2264 Ct \u221a n+ \u221a m+ 4 \u221a s\nmn + 3 \u221a log(2/\u03b4)\u221a mn(1\u2212 \u03c1)\n(38)\nNow for the left hand side R\u03b1,\u03c1(X)\u2212minX R\u03b1,\u03c1(X). By Theorem 2, we know that\nR\u03b1\u2217,\u03c1(X)\u2212min X R\u03b1\u2217,\u03c1(X) =\n( 1 + \u03c1\n2\n) R(X). (39)\nHere we use the fact that minX R(X) = 0 because R(Y ) = 0, and the term B vanished because it is a constant for both sides. Combining (39), (38) and (35), we have(\n1 + \u03c1\n2\n) R(X) \u2264 \u03b7 ( Ct \u221a n+ \u221a m+ 4 \u221a s\nmn + 3 \u221a log(2/\u03b4)\u221a mn(1\u2212 \u03c1) ) ,\ntherefore\nR(X) \u2264 2\u03b7 1 + \u03c1\n( Ct \u221a n+ \u221a m+ 4 \u221a 3s\nmn + 3 \u221a log(2/\u03b4)\u221a mn(1\u2212 \u03c1) ) .\nA.5 Proof of Theorem 6\nProof. For convenience, we let X = FuDF T v . We first apply the same argument in to the proof in Appendix A.2 to get (34). Now we want to bound the Rademacher compelxity EA,\u03c3[supw\u2208W \u2211 i,j \u03c3ij l\u0303(Xij , Aij)] (upper bound of (34)). Since l\u0303(Xij , Aij) is Lipchitz continuous with constant 1\n1\u2212\u03c1 (use the fact that\nXij is bounded between 0 and 1), we have l\u0303(Xij , Aij) \u2264 11\u2212\u03c1(Xij \u2212Aij). Therefore,\nEA,\u03c3[ sup w\u2208W \u2211 i,j:Aij=1 \u03c3ij l\u0303((FuDF T v )ij , Aij)]\n\u2264 EA,\u03c3[ sup w\u2208W \u2211 i,j:Aij=1 \u03c3ij 1\u2212 \u03c1 (FuDF T v )ij ] + EA,\u03c3[ \u03c3ij 1\u2212 \u03c1 ] = 1\n1\u2212 \u03c1 EA,\u03c3[ sup\nw\u2208W \u2211 i,j:Aij=1 \u03c3ijtr(uiv T j D)]\nWe then use the following Lemma, which is a special case of Theorem 1 in Kakade et al. [2008] when taking \u2016 \u00b7 \u2016 to be the matrix 2 norm and \u2016 \u00b7 \u2016\u2217 (the dual norm) is the trace norm: Lemma 3. Let D := {D | D \u2208 Rd\u00d7d and \u2016D\u2016\u2217 \u2264 D1} (where \u2016W\u2016\u2217 is the trace norm of W ), and W = maxi \u2016Wi\u20162, then\nE\u03c3[ sup D\u2208D\n1\np m\u2211 i=1 \u03c3itr(DWi)] \u2264 2WD1\n\u221a log 2d\np .\nNow the set D is {D : \u2016D\u2016\u2217 \u2264 t} and number of terms that Aij = 1 is p = n2(1\u2212 \u03c1), so using the above lemma we have\nEA,\u03c3[ sup D\u2208D \u2211 i,j:Aij=1 \u03c3ij l\u0303((FuDF T v )ij , Aij)] \u2264 2 1\u2212 \u03c1 t ( max i,j \u2016uivTj \u20162 )\u221a log 2d \u221a p\n\u2264 2 1\u2212 \u03c1\ntXuXv \u221a log 2d \u221a mn \u221a 1\u2212 \u03c1\n= 2 \u221a mnt \u221a\nlog 2d\u221a 1\u2212 \u03c1 XuXv.\nTherefore, 1\nmn EA,\u03c3[ sup\nD\u2208D \u2211 i,j:Aij=1 \u03c3ij l\u0303((FuDF T v )ij , Aij)] \u2264 2t \u221a log 2d\u221a mn \u221a 1\u2212 \u03c1 XuXv.\nCombined with other part of the proof of Theorem 3 we have\n1\nmn \u2211 i,j (Mij \u2212 FuD\u0302F Tv )2 \u2264 6 \u221a log(2/\u03b4)\u221a mn(1\u2212 \u03c1) + 4t \u221a log 2d\u221a mn \u221a 1\u2212 \u03c1 XuXv.\nA.6 Proof of Theorem 7\nProof. We follow the proof for Theorem 5. Again let X = FuDF T v . First, we show that (35) is still true for the inductive case. The only difference here is to show that minX:\u2016X\u2016\u2217\u2264tR\u03b1,\u03c1 \u2265 \u03b7minX:\u2016X\u2016\u2217\u2264tRl\u03b1,\u03c1(X) because now all the (i, j) elements are dependent. However, as discussed in the previous proof, if we treat each (i, j) independently, the optimal value for each (i, j) elements will be\nZij =\n{ > q if Aij = 1,\n\u2264 q if Aij = 0.\nBy assumption we know there exists an D with \u2016FuDF Tv \u2016\u2217 = \u2016D\u2016\u2217 \u2264 t and X = FuDF Tv satisfies the above condition. Therefore the value of minX:\u2016X\u2016\u2217\u2264tR\u03b1,\u03c1 still takes the same value with Theorem 5. On the other hand, since now we enforce a more strict constraint that X = FuDF T v , Theorem 5 gives an upper bound of minD:\u2016D\u2016\u2217\u2264tRl\u03b1,\u03c1(FuDF T v ). Therefore, equation (35) still holds. We then also have\nRl\u03b1,\u03c1(FuDF T v )\u2212min\nD Rl\u03b1,\u03c1(FuDF\nT v ) \u2264 6 \u221a log(2/\u03b4)\u221a mn(1\u2212 \u03c1) + 4t \u221a log 2d\u221a mn \u221a 1\u2212 \u03c1 XuXv (40)\nusing the similar proof to Theorem 6. Combining (40), (35) and Theorem 2, the proof is complete."}], "references": [{"title": "Learning classifiers from only positive and unlabeled data", "author": ["C. Elkan", "K. Noto"], "venue": null, "citeRegEx": "Elkan and Noto.,? \\Q2012\\E", "shortCiteRegEx": "Elkan and Noto.", "year": 2012}, {"title": "Provable inductive matrix completion", "author": ["P. Jain", "I.S. Dhillon"], "venue": "CoRR, abs/1306.0626,", "citeRegEx": "2014", "shortCiteRegEx": "2014", "year": 2013}, {"title": "Some estimates of norms of random matrices", "author": ["R. Latala"], "venue": "Proceedings of the AMS,", "citeRegEx": "2003", "shortCiteRegEx": "2003", "year": 2005}, {"title": "Calibrated asymmetric surrogate losses", "author": ["C. Scott"], "venue": "Electronic J. of Stat.,", "citeRegEx": "2013", "shortCiteRegEx": "2013", "year": 2012}], "referenceMentions": [{"referenceID": 0, "context": "In the context of classification, methods for learning in the presence of positive and unlabeled examples only, called positive-unlabeled (PU in short) learning, have been studied in the past [Elkan and Noto, 2008, Liu et al., 2003]. For matrix completion, can one guarantee recovery when only a subset of positive entries is observed? In this paper, we formulate the PU matrix completion problem and answer the question in the affirmative under different settings. Minimizing squared loss on the observed entries corresponding to 1\u2019s, subject to the low-rank constraints, yields a degenerate solution \u2014 the rank-1 matrix with all its entries equal to 1 achieves zero loss. In practice, a popular heuristic used is to try and complete the matrix by treating some or all of the missing observations as true 0\u2019s, which seems to be a good strategy when the underlying matrix has a small number of positive examples, i.e., small number of 1\u2019s. This motivates viewing the problem of learning from only positive samples as a certain noisy matrix completion problem. Existing theory for noise-tolerant matrix completion [Cand\u00e8s and Plan, 2009, Davenport et al., 2012] does not sufficiently address recoverability under PU learning (see Section 2). In our work, we assume that the true matrix M \u2208 Rm\u00d7n has a bounded nuclear norm \u2016M\u2016\u2217. The PU learning model for matrix completion is specified by a certain one-bit quantization process that generates a binary matrix Y from M and a one-sided sampling process that reveals a subset of positive entries of Y . In particular, we consider two recovery settings for PU matrix completion: The first setting is non-deterministic \u2014 M parameterizes a probability distribution which is used to generate the entries of Y . We show that it is possible to recover M using only a subset of positive entries of Y . The idea is to minimize an unbiased estimator of the squared loss between the estimated and the observed \u201cnoisy\u201d entries, motivated by the approach in Natarajan et al. [2013]. We recast the objective as a \u201cshifted matrix completion\u201d problem that facilitates in obtaining a scalable optimization algorithm.", "startOffset": 193, "endOffset": 2015}, {"referenceID": 0, "context": "In the context of classification, methods for learning in the presence of positive and unlabeled examples only, called positive-unlabeled (PU in short) learning, have been studied in the past [Elkan and Noto, 2008, Liu et al., 2003]. For matrix completion, can one guarantee recovery when only a subset of positive entries is observed? In this paper, we formulate the PU matrix completion problem and answer the question in the affirmative under different settings. Minimizing squared loss on the observed entries corresponding to 1\u2019s, subject to the low-rank constraints, yields a degenerate solution \u2014 the rank-1 matrix with all its entries equal to 1 achieves zero loss. In practice, a popular heuristic used is to try and complete the matrix by treating some or all of the missing observations as true 0\u2019s, which seems to be a good strategy when the underlying matrix has a small number of positive examples, i.e., small number of 1\u2019s. This motivates viewing the problem of learning from only positive samples as a certain noisy matrix completion problem. Existing theory for noise-tolerant matrix completion [Cand\u00e8s and Plan, 2009, Davenport et al., 2012] does not sufficiently address recoverability under PU learning (see Section 2). In our work, we assume that the true matrix M \u2208 Rm\u00d7n has a bounded nuclear norm \u2016M\u2016\u2217. The PU learning model for matrix completion is specified by a certain one-bit quantization process that generates a binary matrix Y from M and a one-sided sampling process that reveals a subset of positive entries of Y . In particular, we consider two recovery settings for PU matrix completion: The first setting is non-deterministic \u2014 M parameterizes a probability distribution which is used to generate the entries of Y . We show that it is possible to recover M using only a subset of positive entries of Y . The idea is to minimize an unbiased estimator of the squared loss between the estimated and the observed \u201cnoisy\u201d entries, motivated by the approach in Natarajan et al. [2013]. We recast the objective as a \u201cshifted matrix completion\u201d problem that facilitates in obtaining a scalable optimization algorithm. The second setting is deterministic \u2014 Y is obtained by thresholding the entries of M (modeling how the users vote), and then a subset of positive entries of Y is revealed. While recovery of M is not possible (see Section 2), we show that we can recover Y with low error. To this end, we propose a scalable biased matrix completion method where the observed and the unobserved entries of Y are penalized differently. Recently, an inductive approach to matrix completion was proposed [Jain and Dhillon, 2013] where the matrix entries are modeled as a bilinear function of real-valued features associated with the rows and the columns. We extend our methods under the two aforementioned settings to the inductive matrix completion problem and establish similar recovery guarantees. Our contributions are summarized below: 1. To the best of our knowledge, this is the first paper to formulate and study PU learning for matrix completion, necessitated by the applications of matrix completion. Furthermore, we extend our results to the recently proposed inductive matrix completion problem. 2. We provide strong guarantees for recovery; for example, in the non-deterministic setting, the error in recovering an n \u00d7 n matrix is O( 1 (1\u2212\u03c1)n) for our method compared to O( 1 (1\u2212\u03c1) \u221a n ) implied by the method in Davenport et al. [2012], where (1 \u2212 \u03c1) is the fraction of observed 1\u2019s.", "startOffset": 193, "endOffset": 3474}, {"referenceID": 3, "context": "[2013], Yi et al. [2013], we assume the features are good enough such that M = Fu(Fu) MFv(Fv) T .", "startOffset": 1, "endOffset": 25}, {"referenceID": 2, "context": "We compare with competing link prediction methods [Kiben-Nowell and Kleinberg, 2003] Common Neighbors, Katz, and SVD-Katz (compute Katz using the rank-k approximation, A \u2248 Uk\u03a3kVk). Note that the classical matrix factorization approach in this case is equivalent to SVD on the given 0-1 training matrix, and SVD-Katz slightly improves over SVD by further computing the Katz values based on the low rank approximation (see Kiben-Nowell and Kleinberg [2003]), so we omit the SVD results in the figures.", "startOffset": 79, "endOffset": 455}], "year": 2014, "abstractText": "In this paper, we consider the matrix completion problem when the observations are one-bit measurements of some underlying matrix M , and in particular the observed samples consist only of ones and no zeros. This problem is motivated by modern applications such as recommender systems and social networks where only \u201clikes\u201d or \u201cfriendships\u201d are observed. The problem of learning from only positive and unlabeled examples, called PU (positive-unlabeled) learning, has been studied in the context of binary classification. We consider the PU matrix completion problem, where an underlying real-valued matrix M is first quantized to generate one-bit observations and then a subset of positive entries is revealed. Under the assumption that M has bounded nuclear norm, we provide recovery guarantees for two different observation models: 1) M parameterizes a distribution that generates a binary matrix, 2) M is thresholded to obtain a binary matrix. For the first case, we propose a \u201cshifted matrix completion\u201d method that recovers M using only a subset of indices corresponding to ones, while for the second case, we propose a \u201cbiased matrix completion\u201d method that recovers the (thresholded) binary matrix. Both methods yield strong error bounds \u2014 if M \u2208 Rn\u00d7n, the Frobenius error is bounded as O ( 1 (1\u2212\u03c1)n ) , where 1\u2212\u03c1 denotes the fraction of ones observed. This implies a sample complexity of O(n log n) ones to achieve a small error, when M is dense and n is large. We extend our methods and guarantees to the recently proposed inductive matrix completion problem, where rows and columns of M have associated features. We provide efficient and scalable optimization procedures for both the methods and demonstrate the effectiveness of the proposed methods for link prediction (on real-world networks consisting of over 2 million nodes and 90 million links) and semi-supervised clustering tasks.", "creator": "LaTeX with hyperref package"}}}