{"id": "1501.02732", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "12-Jan-2015", "title": "Predicting Performance During Tutoring with Models of Recent Performance", "abstract": "In educational technology and learning sciences, there are multiple uses for a predictive model of whether a student will perform a task correctly or not. For example, an intelligent tutoring system may use such a model to estimate whether or not a student has mastered a skill. We analyze the significance of data recency in making such predictions, i.e., asking whether relatively more recent observations of a student's performance matter more than relatively older observations. We develop a new Recent-Performance Factors Analysis model that takes data recency into account. The new model significantly improves predictive accuracy over both existing logistic-regression performance models and over novel baseline models in evaluations on real-world and synthetic datasets. As a secondary contribution, we demonstrate how the widely used cross-validation with 0-1 loss is inferior to AIC and to cross-validation with L1 prediction error loss as a measure of model performance. In addition to a significant improvement in predictive accuracy over existing data models, we have shown that non-cognitively trained models perform significantly better with the cross-validation with 2-4 loss as a measure of model performance.", "histories": [["v1", "Mon, 12 Jan 2015 17:39:53 GMT  (1643kb,D)", "http://arxiv.org/abs/1501.02732v1", null]], "reviews": [], "SUBJECTS": "cs.AI", "authors": ["april galyardt", "ilya goldin"], "accepted": false, "id": "1501.02732"}, "pdf": {"name": "1501.02732.pdf", "metadata": {"source": "CRF", "title": "Predicting Performance During Tutoring with Models of Recent Performance", "authors": ["April Galyardt", "Ilya Goldin"], "emails": ["galyardt@uga.edu", "ilya.goldin@pearson.com"], "sections": [{"heading": null, "text": "Predicting Performance During Tutoring with Models of Recent Performance April Galyardt University of Georgia galyardt@uga.edu Ilya Goldin Pearson ilya.goldin@pearson.com\nIn educational technology and learning sciences, there are multiple uses for a predictive model of whether a student will perform a task correctly or not. For example, an intelligent tutoring system may use such a model to estimate whether or not a student has mastered a skill. We analyze the significance of data recency in making such predictions, i.e., asking whether relatively more recent observations of a student\u2019s performance matter more than relatively older observations. We develop a new Recent-Performance Factors Analysis model that takes data recency into account. The new model significantly improves predictive accuracy over both existing logistic-regression performance models and over novel baseline models in evaluations on real-world and synthetic datasets. As a secondary contribution, we demonstrate how the widely used cross-validation with 0-1 loss is inferior to AIC and to cross-validation with L1 prediction error loss as a measure of model performance."}, {"heading": "1. INTRODUCTION", "text": "A central field of research in educational technology and assessment is concerned with modeling the probability that a student will respond correctly to some question. This modeling is used to analyze test answers, as with Item Response Theory; in adaptive learning technologies, such as the use of Bayesian Knowledge Tracing (Corbett and Anderson, 1995) in intelligent tutoring systems; to analyze the domains that students study, such as the study of transfer across tasks (Pavlik et al., 2011); and to understand student behaviors like gaming the system (Baker et al., 2004).\nOur work advances this field by examining alternative representations of recency. The intuition is simple: as students practice a skill, we expect their understanding to increase and their performance to improve. Having recently succeeded at a task may make it more likely that learning has taken place, and such a moment of learning ought to contribute to our prediction of successful performance. This work is the first thorough investigation of recency effects in performance modeling.\nWe begin by describing a space of models of recency that fits into the logistic regression approach to performance modeling, as exemplified by Item Response Theory models. This space subsumes many existing modeling efforts, including the Additive Factors Model (AFM) (Cen et al., 2006a), Performance Factors Analysis (PFA) (Pavlik et al., 2009), and the recencyweighted model by Gong and colleagues (Gong et al., 2011). We then propose the RecentPerformance Factors Analysis (R-PFA) model. We evaluate this model\u2019s accuracy on a realworld dataset of student performance from the Assistments system (Baker et al., 2011). Finally,\nar X\niv :1\n50 1.\n02 73\n2v 1\n[ cs\n.A I]\n1 2\nJa n\n20 15\nsince real-world datasets exhibit certain data limitations, we further examine the properties of the new R-PFA model and several alternatives on a range of simulated datasets."}, {"heading": "2. PRIOR WORK IN PERFORMANCE MODELING", "text": "To predict whether or not a student will succeed at completing a task, at a minimum, we ought to take into account some characteristic of the student and the task. There are two chief approaches to such modeling in the literature: graphical models, notably including Bayesian Knowledge Tracing, and logistic regression models.\nIn the best-known examples of logistic regression modeling, Item Response Theory and Rasch models include predictors relating to the ability of the student and the difficulty of the task. A refinement on this approach is Linear Logistic Test Models (LLTM) (Fischer, 1973; de Boeck and Wilson, 2004). These logistic regression models replace the predictor relating to the difficulty of the individual tasks with a predictor that groups together tasks that share an underlying skill or Knowledge Component (KC). Because task difficulty is estimated from data, replacing per-task parameters with per-skill parameters reduces the number of model parameters, and leverages the power of task-level observations to provide a relatively more robust estimate of skill difficulty.\nThe LLTM class of models includes Additive Factors Model (AFM) and Performance Factors Analysis (PFA) (Cen et al., 2006a; Pavlik et al., 2009; Chi et al., 2011). These models differ only in how they reflect prior practice to predict a student\u2019s future performance. The original LLTM is meant to reflect student knowledge during a short examination where we assume no learning is occurring, and therefore it does not include any summaries for the effects of practice, only effects of student and skill (i.e., student and KC intercepts). AFM introduces a slope coefficient for the total number of prior opportunities a student has had to practice a KC. The claim is that the more practice a student has had, the more likely they should be to get the next item correct. PFA decomposes the number of total prior practice opportunities into separate counts of successes and failures; with the assumption that successful and unsuccessful practice may have differential value for student learning and thus for probability of correctness on the next task."}, {"heading": "3. MODEL COMPARISON AND MODEL DESIGN", "text": "Because performance modeling is rooted in statistics and machine learning, models of performance are often evaluated in terms of predictive accuracy. We take the position that models of task performance need to be interpretable above all. This stance disfavors models with good predictive accuracy when such models are black boxes, because such models make it difficult to advance the science of learning, or to develop systems that act on model predictions. Nonetheless, predictive accuracy is a sensible way to choose among multiple interpretable models.\nWe consider interpretability in terms of model realism and complexity. Model realism considers that many aspects of the world may affect student performance; a model should reflect as many of the biggest effects as possible, and do so as accurately or plausibly as possible in terms of both structure and estimated parameters. The danger of realistic models is that they can be highly complex. Models that are excessively complex may not be fully identified, or they may \u201doverfit\u201d the available data, i.e., they may reflect data characteristics that are minor at best, or inaccurate at worst.\nBy way of example, we can place Bayesian Knowledge Tracing (BKT) & PFA on the realism-complexity continuum. BKT has a generative structure that represents (to a degree) human learning, but this structure also leads to mathematical complexity and may lead to implausible parameter values (Beck and Chang, 2007). PFA is relatively simpler mathematically because of its linear structure, but may still yield implausible parameters. For example, unless the parameters are artificially restricted, PFA may estimate that practice on a skill is associated with a decrease in the probability that a student will correctly answer a problem on that skill. BKT and PFA have comparable (and mediocre) predictive accuracy. (Pavlik et al., 2009; Gong et al., 2011)\nAccordingly, we aim for a model that is realistic, not excessively complex, and with good predictive accuracy. This is no small goal; for instance, models may have similar predictive accuracy but different parameter interpretations. For example, (Kaser et al., 2014) find that AFM only estimates positive slopes for practice on about 50% of the skills whereas other models estimate positive slopes for practice of almost all skills. However, if improvement in parameter plausibility does not lead to reliable improvement in predictive accuracy (Kaser et al., 2014), it is hard to decide which model is preferable.\nWe use AIC as an operational definition of model quality. AIC is a likelihood-based measure of model accuracy that incorporates a penalty for model complexity. Minimizing AIC is equivalent to minimizing KL-divergence risk. An alternative technique for model comparison is cross-validation. An especially important technique in educational data mining is studentstratified cross-validation, where a model is trained on one set of students, and used to make predictions for a held-out set of students. In this way, one can claim to have a reasonable expectation of how well the model will perform on entirely new students. Still, AIC is known to be asymptotically equivalent to cross-validation (Akaike, 1985; Wasserman, 2004; James et al., 2013). In fact, in section 5. we demonstrate that AIC is superior as a measure of model fit to the oft-used cross-validation with a 0-1 loss function.\nOne way to consider the distinction between AIC and cross-validation is to consider that these measures represent different loss functions. Cross-validation can use any loss function, but 0-1 loss is most common, while the KL-divergence that AIC uses is more similar to an L1 prediction error (PE) loss.\nLet L be the loss function, let Yij the actual correct (1) or incorrect (0) outcome for student i on a practice opportunity on skill j, and let p\u0302ij = P\u0302 (Yij = 1) be the estimated probability of a correct answer (i.e. the continuous output from the logistic regression model).\n0-1 loss L(p\u0302ij, Yij) = {\n0 if |p\u0302ij \u2212 Yij| < 0.5 1 otherwise (1)\nPE loss L(p\u0302ij, Yij) = |p\u0302ij \u2212 Yij| (2)\nThe primary difference between these loss functions is in whether we are interested in only prediction accuracy, or in accuracy and model confidence. The more confident a particular model is in it\u2019s predictions, the closer the estimated probability of a correct response, p\u0302ij , will be to the actual student response. Under PE loss, a hypothetical model that is accurate but not confident in its prediction is considered to perform worse than a model that is accurate and confident. By contrast, 0-1 loss discards information on model confidence, and treats confident and non-confident models equally. When p\u0302ij is near 0.5, the two measures may disagree. The\n0-1 loss function may prefer a model that has high predictive accuracy even if p\u0302 is near 0.5, i.e., even if the model is not confident in its predictions. As model confidence increases, agreement in model ranking between the two loss functions will increase.\nFor example, suppose that for a particular individual with two opportunities for practice on KC j, we observe Yij = (0, 1). Now suppose that Model 1 estimates the probability of a correct response as p\u0302 = (0.48, 0.52), while Model 2 estimates the probability of a correct response as p\u0302 = (0.1, 0.9). Then 0-1 loss will not distinguish between these two models, but PE loss will prefer the model that is more confident in predicting that the first attempt response is incorrect, and the second attempt a correct.\nWhen cross-validation uses 0-1 loss, it ignores model confidence, but AIC considers both model accuracy and model confidence. The significance of this distinction will become apparent in the model comparisons below."}, {"heading": "3.1. RECENT-PERFORMANCE FACTORS ANALYSIS", "text": "Recent-performance Factors Analysis (R-PFA) focuses on recent history, rather than the complete practice history of a student (Galyardt and Goldin, 2014). The first intuition behind this model is that having learned a skill makes it more likely that the student will get the next item correct; not having learned the skill makes an incorrect response more likely than a correct. The second intuition is that recent practice history with a KC may contain all the necessary information about whether or not a student has acquired the KC. We can relate this idea to a \u2018moment-of-learning\u2019. If a student has been successful with recent practice, then a momentof-learning has likely already occurred. If recent attempts have not been successful, then the student has most likely not yet learned the KC."}, {"heading": "3.2. FORMAL MODEL DESCRIPTIONS", "text": "To evaluate R-PFA comprehensively, we examine a number of alternative models. The notation we use differs from other publications of some models, but we hope that our consistent use of notation across all models will facilitate the comparison. We use the following notation: j KC index, j = 1, . . . , J i student index, i = 1, . . . , N t practice opportunity index, t = 1, . . . , Oij Xijt response by student i, on opportunity t of KC j,\nXijt = { 0 if incorrect 1 if correct\npijt Probability of a correct response: Pr(Xijt = 1) Tijt count of past opportunities Sijt recency-weighted count of previous successes, up to trial t Fijt recency-weighted count of previous failures, up to trial t Rijt recency-weighted proportion of past successes\nAll the models we examine are logistic regressions, where the general form is\npijt = Pr(Xijt = 1|Z = z) = exp(z\u2032\u03b2)\n1 + exp(z\u2032\u03b2) . (3)\nEach of the main models that we examine uses a different representation of a student\u2019s prior practice. These terms, which replace the generic Z\u2019s in equation 3, are displayed for clear\ncomparison in table 1. The previously published models are Additive Factors Model (AFM) (Cen et al., 2007; Cen et al., 2008), Performance Factors Analysis (PFA) (Pavlik et al., 2009), and PFA-decay (Gong et al., 2011). We additionally include baseline models S-only, R-only, and R-AFM.\nAFM represents prior practice as the total number of prior opportunities for a student to practice the KC:\nlogit(pijt) = \u03b8i + \u03b2j + \u03b3jTijt. (4)\nPFA distinguishes effects of prior successes and prior failures in predicting future success:\nlogit(pijt) = \u03b8i + \u03b2j + \u03b1jSijt + \u03c1jFijt. (5)\nPFA-decay (Gong et al., 2011) is an adjustment to PFA that uses a decay weight to account for recency of observations:\nSijt = t\u22121\u2211 p=1 dt\u22121\u2212pXijp (6) Fijt = t\u22121\u2211 p=1 dt\u22121\u2212p(Xijp \u2212 1) (7)\nAside from the decay weight, PFA-decay uses the same predictors S and F as original PFA. In fact, when d = 1, PFA-decay and PFA are exactly the same. Thus, we refer to both these models that only include (possibly decayed) counts S and F as PFA.\nAnother common approach in general regression modeling, is to perform a logarithmic transformation on count variables. In educational applications (e.g., Yudelson et al. 2014; Chi et al. 2011), a logarithmic transformation of practice counts is an argument that practice beyond some threshold amount has only a marginal effect on the probability of a correct response. The transformation represents a sensible, realistic intuition about performance, but the regression coefficient on a log-transformed count is difficult to interpret. Moreover, the logarithmic transformation is simply a down-weighting of the total amount of practice, it does not account for any recency effects.\nAs an alternative for the count of successes, we introduce an exponentially decayed proportion of successes, Rijt.\nRijt =\n\u2211t\u22121 p=\u22122 d\n(t\u2212p)Xijp\u2211t\u22121 p=\u22122 d (t\u2212p) (8)\nAside from the decay weighting, which is explained below, the proportion of successes is quite simply the count of prior successes divided by the count of total prior attempts.\nThere are two issues to consider in decay weighting: the weighting function (kernel) and the weight strength. In non-parametric methods, the choice of kernel is generally less important than the decay weight (Wasserman, 2006). An example of an alternate weighting function is the box kernel, where the tuning parameter is window size k in the sense of the \u2018last k attempts\u2019. The interpretation is simple, but box kernel treats all attempts within k as equally important, which may not be sensible. In the PFA model, k covers the entire practice history, which weighs all attempts as equally important, and does not discard even the oldest evidence.\nR-PFA and PFA-decay (Gong et al., 2011) both place an exponential decay weight on prior practice. Importantly, Gong et al. (2011) fix d at 0.9, aiming not to \u201celiminate the effects of further practices too quickly.\u201d This is an overly simplistic choice, and as we shall demonstrate in section 4.2., simply tuning the decay parameter in the PFA models appropriately produces large improvements in predictive accuracy. In exponential weighting, different values of the decay weight d control the \u2018smoothing\u2019 of Sijt (PFA-decay) and Rijt (R-PFA) over the history of practice. If d = 1, then a student\u2019s entire history of practice gets equal weight. Alternatively, if d = 0.1, then 90% of the weight is on the single previous trial, and 9% is placed on the 2nd most recent attempt, so that effectively only the last attempt is counted in the recent history. Choosing a weight d is precisely analogous to choosing smoothing bandwidth in nonparametric statistics (e.g., Wasserman 2006, figure 4.5). For exponential decay, the decay parameter d ranges from 0 to 1, while for the box kernel, the window size k ranges from 1 to infinity, so that selecting the optimal d has a more tractable search space. Thus the exponential decay function has both a computational advantage for tuning decay weight, and interpretability advantage since older evidence is down-weighted.\nWe can see the effect of the different values of d most clearly in the pattern \u201cStudent Slips Twice\u201d (Figure 1). This student has the attempt history Xij = (0, 1, 1, 1, 0, 0, 1, 1, 1), as indicated by the red diamonds in the figure. With a decay weight d = 0.2, after 1 error followed by 3 corrects, Sij5 = 1.24, but then when the student misses the next item, Sij6 drops to 0.248. Without decay, i.e., when d = 1.0, Sijt grows slowly with each item that a student gets right, and never decreases after errors. For the highlighted decay weight d = 0.7, Sijt increases at a moderate pace with each correct, until Sij5 = 2.19. Then, when the student answers incorrectly on trial 5, Sij6 = 1.53, a small drop, and with the subsequent error drops further to Sij7 = 1.07. The impact is similar on the proportion of successes Rijt.\nThe behavior of Sijt and Rijt with d = 0.7 mirrors our intuition. If we were tutoring a student one-on-one, on the third correct attempt in a row, we might think \u2018Ok, they\u2019ve mastered this skill.\u2019 When the next attempt is incorrect, we might think \u2018That was probably just a slip.\u2019 On the second incorrect attempt, we might revise our assessment of the student\u2019s knowledge: \u2018Hmm, maybe they don\u2019t know this.\u2019 But after 3 subsequent correct responses in a row, we might be fairly convinced the student has learned the KC. This parallels exactly the Bayesian updating of the probability that a student has learned a KC that takes place in a Bayesian Knowledge Tracing (BKT) model. In this way, exponential decay weighting is capturing student performance in a\nsimilar way BKT, but without the complexity of a Hidden Markov Model. The recency-weighted proportion of successes R is similar to the recency-weighted count of successes S, but there are differences. The interpretation of Rijt is consistent across different values of the decay parameter. If Rijt is near 1, then the student has been successful in recent attempts; if it is near zero, then the student has recently been unsuccessful. If the student has a fully successful history of practice, R will converge to 1 no matter the value of the decay weight. By contrast, S does not have a consistent interpretation. For any value of d, R is scaled to fall between 0 and 1, implying thatR is easily interpretable as some proportion, e.g., \u2018a student has a success rate of about 80% over the last few items.\u2019 By contrast, S has asymptotic properties that complicate interpretation. Since each Xijt is either 1 or 0, the counts Sijt and Fijt are bounded by they geometric series \u2211\u221e p=1 d\np = (1\u2212 d)\u22121. If d = 1, the series does not converge. For every d < 1, the series will converge to a different number. The asymptotic limit of this series is visible in the pattern \u201cStudent Never Slips\u201d in figure 1. For d = 0.9 the limit is (1\u2212 0.9)\u22121 = 10; for d = 0.2, the limit is 1.25. The meaning of a particular value of S, but not R, depends on d.\nThe consistent interpretation of R also allows us to interpret R as a proxy for whether or not a student has experienced a moment of learning. As an example, consider two students with histories Xij = {0, 0, 1, 1, 1, 1}, and Xij = {0, 0, 1, 1, 1, 1, 1, 1, 1, 1}. Intuitively, we would tend to believe that both of these students have experienced a moment of learning and are likely to get the next item correct. For any value of d, these two students will have a similar R value. However, for a small value of d, S will be the same for these two students, but for a d closer to 1, S will be different, and the predictions will be different. Thus S is not interpretable as a proxy for a moment of learning. This gives an interpretative advantage to the recency-weighted proportion R, and may or may not give a predictive advantage as well.\nEarly observations of practice on a skill necessarily contain less evidence of student mastery than the accumulation of early and later observations. Thus, bothRijt and Sijt are noisy on early attempts on a KC. To illustrate, consider two students: the first student has the performance history of Xij = (1, 0). The second student has a performance history of Xi\u2032j = (0, 1, 1, 1, 1). We would be highly doubtful that the former student has mastered the KC, while the latter student has likely mastered the KC. After one trial, the proportion of recent successes is 1 and 0, respectively. The first student has a higher proportion of success after the first trial than the second student does after 5 trials, including 4 successful attempts in a row. Thus, the proportion of successes is a noisy representation for the first student.\nTo adjust for this noise on the first few attempts, Rijt incorporates the assumption that 3 attempts prior to the first attempt would have been incorrect. That is, we stipulate ghost attempts Xi,j,\u22122 = Xi,j,\u22121 = Xi,j,0 = 0. This is making explicit an assumption that at time 0, a student has not already learned the KC, which is very plausible in educational data. These ghost attempts only affect the calculation of Rijt, i.e., they do not affect Tijt, and they are not extra instances in the dataset. Note that such ghost attempts implicitly also exist in the calculation of Sijt, in the sense that on trial one, the count of previous successes is zero. The ghost attempts are included in equation 8 and figure 1.\nMODEL VARIANTS INCLUDING R To separate the effects of recent practice, total practice, and the differential predictive effects of recent success and failure, we compare three model\nvariants that contain R:\nR-only logit(pijt) = \u03b8i + \u03b2j + \u03b4jRijt, (9)\nR-AFM logit(pijt) = \u03b8i + \u03b2j + \u03b3jTijt + \u03b4jRijt, (10)\nR-PFA logit(pijt) = \u03b8i + \u03b2j + \u03c1jFijt + \u03b4jRijt. (11)\nWe compare these three recent-history models with the established AFM and PFA models, as well as the S-only baseline model that uses only the count of successes. For PFA & RPFA, which include two decay-weighted variables, we consider both the case where the tuning parameters are equal and the case where they are tuned separately. This allows for the potentially differential predictive power of recent successes vs. recent failures."}, {"heading": "4. MODEL APPLICATION TO REAL-WORLD DATA", "text": ""}, {"heading": "4.1. METHODS", "text": "We evaluate the models described above in modeling student performance in the Assistments data used in the \u201cmoment of learning\u201d work by Baker and colleagues (Baker et al., 2011). The data contain first attempts by 4138 students on problem sets involving 54 knowledge components (KC), for a total of 187,309 first attempts. Each problem is coded with only a single KC. Each KC was attempted between 89 and 16,200 times, and had an overall percent correct between 23% and 95%. The data are from the mastery learning \u201cSkill Builder\u201d feature of Assistments, which allows teachers to set a threshold for the number of problems a student must correctly answer in a row to be considered proficient. For this data set, the threshold was set at either 3 or 5.\nThis data set is sparse at the student level. First, the median number of KCs seen by each student is 3, and 75% of students practice 7 or fewer different KCs. Second, the median number of total attempts per student summing across all KC\u2019s is 20, and 435 students (11%) made 3 or fewer total problem-solving attempts. This sparsity of data at the student level means that any student effects in a model should be fit as random effects coming from a common distribution. In this way, we \u2018pool\u2019 the data, so the student effects \u03b8i for students with less data shrink towards the mean student effect. The ghost attempts necessarily have the greatest influence on practice strings that are relatively short, i.e., they reduce the noise that would otherwise be present in Rij for these attempts.\nThere are a large number of students per KC; of the 54 KC\u2019s, only one is practiced by fewer than 25 students, and the median number of students per KC is 410. However, the number of attempts for each student on each KC is small, with a median of 4, and a mean of 8. For this reason, we also treat all KC intercepts and slopes as random effects. We did not include the covariance matrix for KC parameters in the model.\nThe number of students per KC makes student-stratified cross-validation unreliable, if not entirely untenable. There are 54 KCs, but 27 of them are encountered by fewer than 410 students, i.e., fewer than 10% of the students. Moreover, the sparsity is not uniform; which KCs were attempted by particular students is not uniformly random. Omitting 10-20% of the students in a cross-validation fold leads to omitting a number of KCs. Therefore 5-fold or 10-fold crossvalidation will result in very poor estimates of KC parameters, or an inability to use the model\nto make predictions. Instead, AIC is used as the measure of model fit; as we demonstrate in section 5., AIC is at least as reliable, if not better than cross-validation.\nWe used the glmer function in the R package lme4 to fit all models listed in Table 1 (Bates et al., 2013). Counting all of the different tunings of relevant decay weights, we fit a total of 111 models, though below we display only the results for the most illuminating comparisons. Data1 and analysis code2 are posted online."}, {"heading": "4.2. RESULTS AND DISCUSSION", "text": "IMPORTANCE OF RECENCY WEIGHTING We first compare PFA and AFM to models where the prior practice representation is the recency-weighted count of successes Sijt (S-only) or the recency-weighted proportion of successes Rijt (R-only), as in figure 2. First, we find that PFA outperforms AFM, replicating prior research (Pavlik et al., 2009; Chi et al., 2011). Second, S-only with decay weight d = 1 outperforms AFM. With a decay parameter of 1, Sijt is simply the total count of all prior successes for person i on KC j. Thus, a simple count of successes is a better predictor of future success than the total count of practice.\nThird, recent success is a better predictor of learning than the entire history of practice, since both S-only and R-only outperform AFM and PFA. Fourth, Rijt and Sijt have the same predictive value when the decay parameters are small, d < 0.3, but R becomes a more powerful predictor than S as the decay parameter increases. In other words, as the predictor includes more practice history, the proportion of successes becomes more valuable than the count of successes. With d = 0.9, AIC for R-only is 1200 less than AIC for S-only, a substantial difference.\nIMPORTANCE OF FAILURES AND TOTAL PRACTICE Given the baseline value of tracking recency-weighted successes, which already outperforms PFA without recency weighting, what is the value of additionally incorporating total practice or failed practice? Comparing R-only and R-AFM enables us to judge the additional predictive value of amount of total practice compared to recent success rate, and recency-weighted PFA (holding constant the decay weight for the success and failure counts) allows us to judge the additional predictive value of failed practice (figure 3). We find that adding a predictor for total amount of practice (R-AFM) improves on the performance of R-only, but recency-weighted PFA with separate success and recent failure counts produces even larger gains in predictive accuracy. The best model so far is PFA with d = 0.6, i.e., that the most relevant information for predicting future performance is contained in the most recent 3-5 attempts, including separate counts of successes and failures.\nCOMPARING COUNT versus PROPORTION OF SUCCESSES As seen in figure 2,R alone is a better predictor than S alone once d grows sufficiently large, even though they contain similar information. This finding stands even after incorporating failure information (figure 4). At each value of the decay parameter, R-PFA (with R and F ) outperforms PFA (S and F ), and once again, the difference increases as the recency weight approaches 1.\nDIFFERENTIAL RECENCY OF SUCCESSES AND FAILURES Starting with the PFA model, we allow the decay weight for F to vary, while holding constant the decay weight for S at d = 0.6, which was optimal in the R-only, S-only, and PFA models (figure 4). We find that\n1https://sites.google.com/site/assistmentsdata/home/goldstein-baker-heffernan 2https://sites.google.com/site/aprilgalyardt/research\nfailure counts deserve the lowest possible decay weight, implying that only a failure on the single most recent attempt contains relevant information for predicting future performance, and prior failures are less informative. The result is the same for the R-PFA model, allowing the decay weight for F to vary, while holding constant the decay weight for R at d = 0.6.\nFigure 4 suggests that tuning the success rate and the failure rate separately offers a distinct advantage. The final set of model comparisons verifies this finding. Figure 5 shows R-PFA models where the recency weight for R varies between 0.5 and 0.8, and the recency weight for F ranges from 0.1 to 1.0. (Only the R-PFA models are shown, since the PFA models using S performed uniformly worse than equivalent models using R.)\nOf the models we compared on this dataset, the model with the highest predictive accuracy is R-PFA with recency weight d = 0.7 for the proportion of successes R, and recency weight d = 0.1 for count of failures F . For successes, with d = 0.7, the weights of the last 6 actions are respectively: {0.340, 0.238, 0.167, 0.117, 0.082, 0.057}. The 5 most-recent actions receive substantial weight, but 58% of the weight is on the two most-recent actions. In contrast, with d = 0.1, the weights for failures on the last 6 actions are:{0.9, 0.09, 0.009, 0.0009, 0.00009, 0.000009}. Applying the weight, if the last action is incorrect d \u00b7 F \u2248 0.9, and if the last action is correct, d \u00b7 F \u2248 0.1. Thus, in this best-performing model, R acts like a running average over the last 2-5 actions, while F is effectively a binary indicator for whether the last action was correct or incorrect.\nThe difference between the optimal tuning parameters for recent successes and recent failures may also be accounting for the difference in slips and guesses. If a student knows the KC and has been correctly responding, then R \u2248 1 and F \u2248 0. If this student then slips and responds incorrectly, with the optimal decay parameters, R will decrease to 0.7, and F jumps to 0.9. If the incorrect answer was truly a slip then the student will likely answer correctly on the next attempt, so thatR increases towards 1 again, and F falls back toward zero. (See also Figure 1, \u201cStudent slips once\u201d.) In this way, R is largely unaffected by slips, while F is an indicator that the last response may have been a slip. Now consider a student who does not know the KC, and has a history of incorrect practice attempts, so that R \u2248 0 and F \u2248 1. If this student then guesses correctly on an item, R only increases to 0.3, and F falls to 0.1. Here R is largely unaffected by the correct guess, while F is an indicator that the last response may have been a guess."}, {"heading": "4.3. INTERPRETING THE BEST-PERFORMING MODEL", "text": "The best overall model for predicting future success from a student\u2019s history is R-PFA with 3 parameters for each KC: \u03b2j , the \u2018easiness\u2019 of the KC; \u03c1j , the effect of recent failures with the KC, and \u03b4j , the effect of recent successes with the KC. To examine model parameters in detail, consider that in a logistic regression model with random effects, the estimates of the coefficients may not be normally distributed when the data is sparse. This means that it may be inappropriate to use the estimated standard errors to obtain confidence intervals for the parameters. To address this issue, we re-fit the best-performing model using a Markov Chain Monte Carlo algorithm, as implemented in the MCMCglmm package in R (Hadfield, 2010).\nWe examine the 95% posterior credible intervals (CI) for each KC parameter (Figure 6). Recall that these were estimated with no restrictions on any coefficients. First, for 49 of the 54 KC\u2019s, the \u03b4 coefficients for the effect of recent successes are significantly positive. The remaining 5 KCs have very wide CI\u2019s and are not significantly different than zero. These 5 KCs\nare among the easiest and hardest KCs, and were practiced by few students. In general, the more recent successes a student has had, the higher the probability of correctly responding to the next item, which corresponds to our intuitions about learning.\nWe further examined the covariance among the KC parameters. The 95% CIs are r(\u03b2, \u03c1) = (\u22120.62,\u22120.36), r(\u03c1, \u03b4) = (0.32, 0.60), and r(\u03b2, \u03b4) = (\u22120.49,\u22120.10). Notably, there is a significant negative correlation between KC easiness and the effect of recent failures; for relatively more difficult KCs, the effect of recent failure on predicting a correct response is positive, while for relatively easier KCs, the effect of recent failure is negative. With easy KCs, recent failure would predict subsequent failure for students who are not acquiring the KC, or who are engaged in non-productive behaviors, e.g., gaming the system. Interestingly, for difficult KCs, recent failure is positively associated with subsequent success.\nIt has been previously documented in PFA and AFM that the slopes for the effect of the count of past failures Fij (and occasionally even for the count of past successes Sij) are often negative, e.g., (Kaser et al., 2014). Such negative slopes signal an area of concern (with the performance model itself or with the KC decomposition), because more practice, successful or unsuccessful, should increase the probability of a correct response. The R-PFA result that recent success is predictive of future success counters the negative-slope phenomenon.\nWHAT IS THE SOURCE OF R-PFA\u2019S ADVANTAGE OVER PFA? Although it is inappropriate to examine errors in prediction on a held-out or cross-validation set given the sparsity in our dataset, even comparing predictive accuracy on the training set is very illuminating. We present the difference in the predictions in figure 7. The two rows of the figure correspond to actually incorrect (top) and actually correct (bottom) outcomes. Each row is divided into 4 facets according to the value of the R predictor:\n\u2022 R in [0, 0.3] indicates that the student has produced either 1 or fewer right answers in the last 4 attempts, or is at the very beginning of practice.\n\u2022 R in (0.3, 0.5] indicates 2 correct answers in the last 3-4 attempts.\n\u2022 R in (0.5, 0.7] implies that the most recent 2 answers were correct.\n\u2022 R in (0.7, 1] means that at least the last 3 answers were correct.\nThe X and Y axes indicate the predictions from the PFA and R-PFA, respectively. This (x, y) position has a different meaning for the actually correct and actually incorrect outcomes. For example, the top-right quadrant for the actually incorrect outcomes indicates false positive values, due to both PFA and R-PFA wrongly predicting that the student will respond correctly. The top-right quadrant for the actually correct outcomes indicates indicates true positive values, due to both PFA and R-PFA accurately predicting that the student will respond correctly.\nThere are notable difference between the models in two cases, roughly corresponding to very early practice on a skill and to relatively late practice. First, when the true outcome is an incorrect response and the student has had few recent successes, R-PFA is much better at predicting these incorrect outcomes than PFA (top row, R in [0, 0.3], TN Win). This is most often the case when the attempt is after the second (note the bubble color); both PFA and RPFA often wrongly predict a correct response for this R value when the attempt is the first or the second (top row, R in [0, 0.3], FP). This improvement in predicting when a student will fail\n[0 ,0\n.3 ]\n(0 .3\n,0 .5\n] (0\n.5 ,0\n.7 ]\n(0 .7\n,1 ]\n\u25cf\u25cf\u25cf \u25cf\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\n\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\n\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\n\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\nF P\nF P\nL os\ns\nT N\nT N\nW in\n\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf \u25cf\n\u25cf\n\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\nF P\nF P\nL os\ns\nT N\nT N\nW in\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\n\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\n\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\u25cf\u25cf\nF P\nF P\nL os\ns\nT N\nT N\nW in\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf \u25cf\u25cf\u25cf \u25cf\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\n\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\u25cf\u25cf\nF P\nF P\nL os\ns\nT N\nT N\nW in\n0. 00 0. 25 0. 50 0. 75 1. 00\nIncorrect\n0. 00\n0. 25\n0. 50\n0. 75\n1. 00\n0. 00\n0. 25\n0. 50\n0. 75\n1. 00\n0. 00\n0. 25\n0. 50\n0. 75\n1. 00\n0. 00\n0. 25\n0. 50\n0. 75\n1. 00\nP FA\nR\u2212PFA s(0.7) f(0.1)\n025507510 0\nP ct\no f\nA tt\nem p\nts 1\no r\n2\nN \u25cf \u25cf \u25cf \u25cf \u25cf\n10 0 50 0 10 00 20 00 40 00\nP re\ndi ct\nio ns\nfr om\nP FA\na nd\nR \u2212\nP FA\nm od\nel s\n[0 ,0\n.3 ]\n(0 .3\n,0 .5\n] (0\n.5 ,0\n.7 ]\n(0 .7\n,1 ]\n\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\u25cf \u25cf\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\u25cf \u25cf\u25cf\u25cf \u25cf\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\n\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\n\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\nT P\nT P\nW in\nF N\nF N\nL os\ns\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\n\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\n\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\nT P\nT P\nW in\nF N\nF N\nL os\ns\n\u25cf\n\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\n\u25cf\n\u25cf \u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\n\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\n\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\nT P\nT P\nW in\nF N\nF N\nL os\ns\n\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\u25cf \u25cf\u25cf\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\n\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\n\u25cf\u25cf\n\u25cf \u25cf\u25cf\u25cf\u25cf\u25cf\n\u25cf\n\u25cf \u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\n\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\u25cf\n\u25cf\n\u25cf\u25cf \u25cf\u25cf\u25cf\u25cf \u25cf\u25cf\u25cf\u25cf\u25cf\u25cf T\nP T P W in\nF N\nF N\nL os s 0. 00 0. 25 0. 50 0. 75 1. 00\nCorrect\n0. 00\n0. 25\n0. 50\n0. 75\n1. 00\n0. 00\n0. 25\n0. 50\n0. 75\n1. 00\n0. 00\n0. 25\n0. 50\n0. 75\n1. 00\n0. 00\n0. 25\n0. 50\n0. 75\n1. 00\nP FA\nR\u2212PFA s(0.7) f(0.1)\n025507510 0\nP ct\no f\nA tt\nem p\nts 1\no r\n2\nN \u25cf \u25cf \u25cf \u25cf \u25cf\n10 0 50 0 10 00 20 00 40 00\nP re\ndi ct\nio ns\nfr om\nP FA\na nd\nR \u2212\nP FA\nm od\nel s\nFi gu\nre 7:\nPF A\nvs .\nR -P\nFA pr\ned ic\ntio ns\nin te\nrm s\nof th\ne p\u0302\nva lu\ne fr\nom th\ne lo\ngi st\nic m\nod el\n. T\nhe bu\nbb le\ns di\nsp la\ny p\u0302\nva lu\nes fr\nom th\ne tw\no lo\ngi st ic m od el s; th e m or e da ta po in ts th er e ar e ne ar th at (x ,y ) po si tio n, th e bi gg er th e bu bb le . T he co lo r of th e bu bb le in di ca te s th e pe rc en ta ge at te m pt s in th at po si tio n th at ar e 1s to r 2n d at te m pt s by a st ud en to n a pa rt ic ul ar sk ill . T he tw o ro w s of th e fig ur e co rr es po nd to ac tu al ly in co rr ec t( to p) an d ac tu al ly co rr ec t( bo tto m )o ut co m es .E ac h ro w is di vi de d in to 4 fa ce ts ac co rd in g to th e va lu e of th e R pr ed ic to r. T he cl os er p\u0302 is to th e bo un da ry va lu es of 1. 0 or 0. 0, th e m or e co nfi de nt th e m od el is in th e pr ed ic tio n. T he ab br ev ia tio ns ar e: T P - tr ue po si tiv e, FP - fa ls e po si tiv e, T N - tr ue ne ga tiv e, FN - fa ls e ne ga tiv e. W in an d lo ss ar e fo r R -P FA re la tiv e to PF A A p\u0302 > 0. 5 is a pr ed ic tio n of a co rr ec t ou tc om e, an d p\u0302 < 0 .5 is a pr ed ic tio n of an in co rr ec to ut co m e.\nto answer correctly is an important contribution of R-PFA for intelligent tutors and adaptive systems.\nSecond, when the student has had successes on the most recent items, R-PFA is more likely to predict a correct outcome than PFA. This is true both when the true outcome is correct, and when it is not, i.e., when the incorrect outcome is likely a slip. Ultimately, the number of false positive losses for R-PFA (top row, R in (0.5, 0.7] or (0.7, 1.0]) is much lower than the number of true positive wins (bottom row, same R). To an intelligent tutor, accurately predicting slips is arguably unimportant. An intelligent tutor using R-PFA rather than PFA would be more aggressive and more accurate at predicting student mastery of a skill, allowing students to graduate from practicing a skill more quickly than PFA.\nWhen the student has had 2 correct answers in the last 3-4 attempts (R in (0.3, 0.5]), it is hard to know whether to expect a correct or an incorrect outcome. In the aggregate, PFA and R-PFA perform comparably in this case."}, {"heading": "5. SIMULATION STUDY", "text": "The purpose of the simulation study was to compare R-PFA against other performance models without the limitations of real datasets. Two characteristics of the Assistments dataset examined above complicate a thorough model comparison. First, the data sparsity in the Assistments data (section 4.) precludes the use of cross-validation for model ranking. Nonetheless, crossvalidation is a popular tool model comparison because holding out data during the model training can help prevent overfitting. Thus, we compare R-PFA to the other models both according to cross-validation and according to AIC. By using simulated data, we demonstrate that AIC is not only an appropriate model selection measure, but that it is better than cross-validation with the oft-used 0-1 loss function, and it can accommodate sparse data.\nSecond, the stopping criterion used in the Skill Builder feature of Assistments leads to data missing non-randomly. Once Assistments determines that a student has mastered a skill, there are no further practice opportunities for the student on this skill. In fact, we expect that no mastery criterion is perfect, and even \u201cmastered\u2019 students may have future incorrect practice. Thus, we would like to use data with evidence of post-mastery performance to train and evaluate our models. We demonstrate that decay weight d in the 0.6-0.8 range is optimal even when there is no stopping rule that affects data generation."}, {"heading": "5.1. METHODS", "text": "We first simulated data from the Bayesian Knowledge Tracing (BKT) model and two adaptations of BKT. We then compared the fit of seven logistic test models on each simulated data set. Classic BKT describes \u2018ideal\u2019 student behavior, which may not capture all student behavior. Our two adaptations of the BKT model address this by incorporating more realistic student behavior. Thus, we can compare the logistic models in the presence of less than ideal student responses.\nIn one adaptation of the classic 2-state BKT model, we posit a 3-state BKT model. In classic BKT, there are two states: a learned state where the student has a high probability of correctly responding to a question, and an unlearned state where the student has a low probability of correctly responding. In the 3-state BKT model, the states are unlearned, practicing, and fluent. In the unlearned state, students have a very low probability of correctly responding to a question.\nIn the fluent state, students have a very high probability of correctly responding. In the practicing state, students are learning the KC, but their understanding is not complete, so they have only moderate probabilities of a correct response. When generating data, this specification will produce more interwoven sequences of 0\u2019s and 1\u2019s than the 2-state BKT model. For example, we will see more patterns like Xij = (0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1), rather than primarily patterns of the form Xij = (0, 0, 0, 0, 1, 1, 1, 1). In this way, 3-state BKT incorporates realistic \u201cstruggling\u201d students\u2019 behavior. This 3-state model only serves a generative purpose; data generated from the 3-state model could also be fit by the 2-state model.\nIn the (BKT+FS) adaptation to the BKT model, we vary the behavior of different simulated students. We include a small proportion of students who occasionally engage in unproductive learning behavior that produces long strings of incorrect responses. In real datasets, such data may be produced by various causal mechanisms, e.g., by lacking mastery of a prerequisite KC, by abusing hints (Aleven and Koedinger, 2000), or by gaming the system (Baker et al., 2004). Specifically, a fraction of students may be likely to generate long strings of incorrect responses; the probability of being such a student is 0.08. These students then generate long strings of incorrect responses with a probability that varies by KC. When a student is engaged in this behavior, the probability of a correct response is 0.02; when a student is not engaged in this behavior, data is generated from the usual two-state BKT model. We refer to this model as BKT with failure sequences (BKT+FS).\nThe data size in each simulation is near the size of the Assistments dataset (section 4.), with 50 KCs and 3500 students. Each student practiced a random number of KCs, generated by a Poisson distribution with a mean of 5. The number of opportunities for a student to practice each KC also varied randomly, generated by a Poisson distribution with a mean of 8. This means the number of opportunities for practice is statistically independent of the KC. This eliminates the uneven sparsity observed in the real data set. Uniform sparsity makes it possible to use cross-validation over students, and to compare cross-validation to AIC.\nFor each of the three variations of BKT (classic and two adaptations), we ran 100 simulations. For each of the 300 simulated data sets, we fit 7 models: AFM, PFA with no decay, and R-PFA with 5 different values of the decay weight for the weighted proportion of successes Rij: d = 0.2, 0.4, 0.6, 0.8, 1.0. For the count of failures, we fixed the decay weight d = 0.1, since the smallest decay parameter for failures was always optimal for the Assistments data. Complete details for each of the BKT variations are provided in appendix A, and code is posted online.3\nTo allow model evaluation with cross-validation, we modified the 7 models in two ways from the ones that we fit on Assistments data: we omitted the student effect, and we used fixed rather than random effects for the KC parameters. First, omitting student effects allows us to make predictions for new students. It also implicitly assumes that any new student for whom we will be generating predictions is of average ability. Second, the uneven sparsity in the Assistments data necessitated random effects for KCs and students, but when there is sufficient data at each level, the estimates for random effects from the R function glmer and fixed effects from the R function glm, used here, will be effectively the same.\nMEASURES OF MODEL FIT On each simulated data set, we compared the 7 models using 3 different measures of model fit: AIC, 5-fold cross-validation (CV) with 0-1 loss (equation 1), and 5-fold CV with L1 prediction error loss (PE loss, equation 2). We omitted the comparison\n3https://sites.google.com/site/aprilgalyardt/research\nto 0-1 loss with a single test set (i.e., 1-fold CV), because that measure is noisy and unreliable due to high variance of the estimate (James et al., 2013)."}, {"heading": "5.2. RESULTS AND DISCUSSION", "text": "Model rankings for the simulations by each of the goodness-of-fit measures are displayed in figures 8, 9, and 10.\nCROSS-VALIDATION WITH 0-1 LOSS HAS HIGH VARIANCE When two models have a very similar fit to the data, measures of model ranking might reasonably diverge in which one they rank as slightly better. For example, in the two-state BTK model in figure 8: AIC ranks RPFA(d = 0.6) as the best model in about 80% of the simulations, and ranks R-PFA(d = 0.8) in second place. In contrast, CV-PE ranks R-PFA(d=0.6) as the best model only about 40% of the time, and puts R-PFA(d=0.8) in first place in 60% of the simulations. This is the kind of behavior we expect when two models are similar. Both model measures clearly agree that these are the best two models compared to the rest of the available models.\nBy contrast, in about 40% of the simulations, CV 0-1 ranks PFA as the best model, and in another 40% of the simulations it ranks PFA in 6th place. This implies that either the PFA regression has highly unstable performance, or that cross-validation with 0-1 loss is an unreliable metric. However, CV with PE loss and AIC are very reliable; they always rank AFM in 7th place, PFA in 6th place, and R-PFA r(0.2) f(0.1) in 5th place.\nMoreover, CV with 0-1 loss also fails to reliably rank R-PFA models with the varying decay parameters, while CV with PE loss and AIC do rank them reliably. R-PFA with d = 0.6 and d = 0.8 are the highest-ranked (and both very close to the best-performing model on the Assistments data, which had d = 0.7). R-PFA with bandwidths of 0.4 and 1.0 are not as good. These all outrank R-PFA with d = 0.2, PFA and AFM in 100% of the simulations.\nThe three measures of model fit do not have equal discriminating power. CV with PE loss and AIC rank the models reliablys, and they also largely agree with each other. Cross validation with 0-1 loss is an unreliable measure of model fit.\nMODEL RANKINGS In all 3 simulation conditions (classic BKT, 3-state BKT, and BKT+FS), in 100% of the simulations, the R-PFA models had higher predictive accuracy (judged by AIC and cross-validation with PE loss) than PFA or AFM. For all 3 conditions, the best model was R-PFA with a decay parameter of 0.6 or 0.8.\nIn the two-state BKT simulation, AIC and CV-PE rank the models in the same order. CV 0-1 produces ambiguous and unreliable model rankings. R-PFA with decay parameters of 0.6 and 0.8 are the best. R-PFA with bandwidths of 0.4 and 1.0 are not as good. The bandwidth of d=0.2 is ranked as the worst R-PFA model in 100% of the simulations, with PFA in 6th place 100% of the time, and AFM in last place 100% of the time.\nIn the three-state BKT simulation, once again, CV with 0-1 loss produces ambiguous and unreliable model rankings. According to AIC and CV-PE, R-PFA(d=0.6) is ranked best 100% of the time, with d = 0.4 most often in second place and d = 0.8 most often in third place. PFA and AFM are again in 6th and 7th place respectively.\nFinally, in the BKT+FS simulation, CV with 0-1 loss agrees with the other measures. R-PFA with d = 0.6 or d = 0.8 are ranked as the best models, while PFA is ranked in 6th place in 100% of the simulations by all three measures. The presence of long strings of incorrect answers,\nwhich are produced occasionally by 8% of the students, makes total number of practice attempts and total number of failures very poor predictors of future success. But because R-PFA only considers recent history, it is not affected by these patterns. A student who was incorrect on the last couple of opportunities for any reason is estimated to have a low probability of responding correctly on the next opportunity.\nThe consistent model rankings across all 3 simulation conditions indicates that recent history is a better predictor of learning than a student\u2019s full history. The optimal decay parameter range is consistently 0.6-0.8. Thus, the last 3-5 practice opportunities contain sufficient information to judge whether or not a student has learned the KC.\nSimulating from the two- or three-state BKT model offers a best-case scenario for the AFM and PFA models. In a BKT model with no forgetting, the more opportunities that a student has to practice, the more likely it is that a student will transition from the unlearned state to the learned state. Therefore, on average, the total number of opportunities to practice should be proportional to the probability of a correct response. Yet even in this case, R-PFA makes better predictions than PFA.\nWhen realistic student behavior is added in the BKT+FS simulation, the advantage of RPFA over PFA becomes even more distinct. The analysis on Assistments data reveals two ways in which the predictions of R-PFA differ from the predictions of PFA: First, R-PFA is better at predicting incorrect answers. Second, the difference between 0-1 loss and prediction error loss indicates that R-PFA has higher confidence in its accurate predictions."}, {"heading": "6. CONCLUSIONS", "text": "The primary contributions of this work are:\n\u2022 the R-PFA model itself, and its publicly available implementation\n\u2022 the comparison of R-PFA to published models and novel baselines on real-world and simulated data, which demonstrates how a student\u2019s recent performance history evidences whether or not they have acquired a particular knowledge component\n\u2022 the novel visualizations comparing PFA and R-PFA performance, which facilitate logistic regression diagnostics and reveal the source of R-PFA\u2019s improvement over alternative models\n\u2022 the comparison of measures of model performance, which demonstrates how cross-validation with 0-1 loss is inferior to AIC and to cross-validation with L1 prediction error loss\nON R-PFA R-PFA leverages prior work, including the separation of student and item characteristics (IRT), the grouping of items by skill and the significance of past performance (AFM), the separation of prior successful and unsuccessful practice (PFA), and discounting of older evidence by Gong et al.\nR-PFA adds several novel insights to this model evolution. First, a decay-weighted proportion of successes is a better predictor than a decay-weighted count of successes. Second, decay weights should be tuned, rather than determined heuristically (as in the work by Gong et al.).\nThird, decay weights for successes and failures should be tuned separately. Fourth, it is reasonable and effective to inform the model with a prior \u201dbelief\u201d that students who have never attempted the skill will likely fail to answer correctly, e.g., using ghost attempts.\nIn aggregate, these insights lead to improvements in predictive accuracy in the true negative rate when recent history contains few correct attempts, and in the true positive rate when recent history mostly consists of correct attempts.\nThe optimal amount of recent history for modeling is consistent across all of the simulations, and the Assistments data; the best decay parameter for recent successes is consistently d = {0.6, 0.7, 0.8}. With these decay rates 75-93% of the weight is on the last 5 attempts, and 55-78% of the weight is on the last 3 attempts. Thus, empirically, these last 3-5 attempts contain sufficient information about the student\u2019s knowledge state to make accurate predictions. Interestingly, this d supports the heuristic, implemented in some adaptive learning systems (Heffernan and Heffernan, 2014), that a student has mastered a skill if a student responds correctly to 3-5 questions in a row on the skill. However, the R predictor is a kind of average that does not require an unbroken streak of correct attempts.\nR-PFA is relatively simple mathematically, adding only two tuning weights beyond the parameter structure of PFA. The stability of the decay weights identified in this work implies these weights might be reasonably treated as fixed in new uses of R-PFA, further reducing complexity of R-PFA. R-PFA is more realistic than PFA, because it distinguishes the predictive value of recent performance and older performance. Its predictor and parameter values are easily interpreted, even in the presence of student behaviors that are undesirable or unproductive for learning. Finally, its predictive accuracy improves on PFA. Thus, our ultimate assessment of R-PFA is that it is preferable to PFA and other logistic models in many circumstances where such a model might be used.\nThe findings here cast doubt on the validity of the AFM model, because a non-decayed count of successes only, i.e., S-only with d = 1, outperforms AFM. At present, AFM has uses aside from prediction, including in skill model selection in Learning Factors Analysis (Cen et al., 2006b), which may need to adopt different models.\nAlthough we did not compare the predictive accuracy of R-PFA to BKT (although BKT and PFA often have similar accuracy), R-PFA has a strength here as well. Knowledge Tracing is a rather complex Hidden Markov Model. It offers a plausible generative structure for student performance, but notoriously can fail to return interpretable or accurate estimates of parameters (e.g., Beck and Chang 2007). The allure of BKT is the posterior updating of the probability that a student knows the KC after each practice opportunity. R-PFA accomplishes the same thing in simpler way.\nNonetheless, the R-PFA project is by no means complete. In the future, we will consider the relationship of R-PFA to Bayesian Knowledge Tracing, because preliminary work suggests that the two models reveal interesting aspects in each other. We will consider how R-PFA may incorporate richer Q-matrices (multiple skills per item), and how R-PFA may be used to improve cognitive models. We will also extend the R-PFA model with additional predictors, as informed by the comparison to PFA reported above.\nON METHODS This work brings to bear several methodological strengths in terms of model comparison, model fitting, and model analysis.\nWe evaluated models on both real-world and simulated data. Although simulated data evaluations are rare in the educational data mining literature, they are very popular in statistics. In\nfact, we argue that real-world datasets have sparse data properties that necessitate both kinds of comparisons.\nThe model fitting used random effects for all model parameters for students and knowledge components, for both intercepts and slopes. This was necessitated by the sparsity in the Assistments dataset. The random effects were used in both R-PFA and alternative models for a fair comparison.\nOur model analysis provides evidence that cross-validation with 0-1 loss, an immensely popular metric in educational data mining, is a poor choice for model comparison. Instead, we argue for the use of AIC as measure of model fit. AIC is seen to be equivalent to cross validation with an L1 prediction error loss. This equivalency is a known result (e.g., (Wasserman, 2004)), but we demonstrate that this holds even when cross validation is making predictions for new students. Any divergence in model choice between AIC and cross validation is due to normal sampling variation, and usually indicates that the fit of the models is similar. A severe divergence in agreement (which we did not see in our simulation) may indicate that the sample size is too small for the model complexity. We note that these conclusions about AIC extend to the Bayesian information criterion (BIC), save that BIC has a higher penalty for model complexity. Cross-validation can be a computationally and time intensive process. AIC and BIC offer a faster and simpler equivalent alternative."}, {"heading": "A SIMULATION DETAILS", "text": ""}, {"heading": "A1. TWO-STATE BKT SIMULATION", "text": "This is the usual BKT model, it is a hidden Markov model with an unlearned and a learned state.\n\u2022 Knowledge components are indexed j = 1, . . . , K\n\u2022 Students indexed i = 1, . . . , N\n\u2022 Student i\u2019s response on the tth opportunity to practice KC j:\nXijt = { 0 if incorrect 1 if correct\n\u2022 Denote student i\u2019s unobserved knowledge of KC j on the tth opportunity as\nZijt = { 1 if unlearned state 2 if learned state\n\u2022 Probability of initially knowing KC j: Pr(Zij1 = 2) = \u03c0j \u223c Beta(1, 2). This distribution has positive probability for all values on the interval [0,1], but is centered at a mean of E[\u03c0j] = 13 . This encapsulates our expectation that in a well-targeted educational intervention, most of the students would not already know the majority of topics which will be taught. The density is shown in figure 11.\n\u2022 Transition matrices for the Markov process are\nPj =\n( 1\u2212 Lj Lj\n0 1\n)\nDensity of Beta(1,2)\nLj is the probability of learning KC k following a practice attempt, generated according to Lj \u223c Beta(2, 2). This distribution positive probability for all values on the interval [0,1], but is centered at E[Lk] = 12 . If Lk is near 1, then a student has a high probability of learning the skill after a single practice attempt. In the same way if Lk is near 0, then a student has a low probability of learning the skill, regardless of how much they practice. This Beta distribution places more probability near 0.5, and lower probability near 0 or 1, reflecting the idea that most students need to practice KCs a couple of times before they learn them. The density is shown in figure 12.\nDensity of Beta(2,2)\n\u2022 Probability of a correct answer in the unlearned state (guessing): Cuj \u223c Unif(0.02, 0.3)\nPr(Xijt = 1|Zijt = 1) = Cuj\n\u2022 Probability of a correct answer in the learned state (1-slip): Clj \u223c Unif(0.7, 0.98)\nPr(Xijt = 1|Zijt = 2) = Clj\n\u2022 Average number of KC\u2019s seen by each student is fixed at K.n = 5\n\u2022 Number of KC\u2019s seen by student i is generated Ji \u223c min{K,Poisson(K.n)}.\n\u2022 The KC\u2019s that student i answers are drawn without replacement from {1, . . . , K}.\n\u2022 T.avg = 8 is the average number of practice opportunities for any student on any KC.\n\u2022 The number of practice opportunities for student i on KC k isOij \u223c max{Poisson(T.avg), 2}. So that if a student practiced a KC, they practiced it at least twice.\nA1.1. Three-state BKT simulation\nThe 3-state BKT model uses the states unlearned, practicing, and fluent. Students in the unlearned state have a low probability of answering correctly. Students in the practicing state have moderate probabilities of answering correctly. We may think of students in this state as largely understanding the ideas and knowing what to do, but slipping frequently perhaps due to high working memory loads or other causes. Students in the fluent state have a very high probability of answering correctly.\n\u2022 Student i\u2019s response on the tth opportunity to practice KC j:\nXijt = { 0 if incorrect 1 if correct\n\u2022 Denote student i\u2019s unobserved knowledge of KC j on the tth opportunity as\nZijt =  1 if unlearned state 2 if practicing state 3 if fluent state\n\u2022 Probability for initial states: \u03c0j = (\u03c0j1, \u03c0j2, \u03c0j3).\nP (Zij0 = 1) = \u03c0j1 \u223c Beta(2, 2) P (Zij0 = 2) = \u03c0j2 = 1\u2212 \u03c0j1 P (Zij0 = 3) = \u03c0j3 = 0\nThis distribution for \u03c0j assumes that no student begins practice in the fluent state, so that practice will benefit all students. The Beta(2, 2) distribution is shown in figure 12. \u03c0j1 can take any value between 0 an 1, but it is more likely to take values nearer to 0.5. This simulates the idea that for an average KC approximately half the students will start out not knowing the KC at all, and the other half of the students need more practice.\n\u2022 Transition matrices for the Markov process are\nLj = Lj11 1\u2212 Lj11 00 Lj22 1\u2212 Lj22 0 0 1 \nwhere Lj11, Lj22 \u223c Beta(2, 2).\nWith these transition matrices, a student may not transition directly from the unlearned to the fluent state over a single opportunity. However, since this is a 1st order Markov process, it is possible and fairly likely that some students will transition from unlearned to fluent within 2 practice opportunities.\n\u2022 Probability of a correct answer in the unlearned state (guessing): Cuj \u223c Unif(0.02, 0.2)\nPr(Xijt = 1|Zijt = 1) = Cuj\n\u2022 Probability of a correct answer in the practicing state: Cpj \u223c Unif(0.4, 0.7)\nPr(Xijt = 1|Zijt = 2) = Cpj\n\u2022 Probability of a correct answer in the fluent state (1-slip): Cfj \u223c Unif(0.85, 1)\nPr(Xijt = 1|Zijt = 3) = Cfj\n\u2022 Average number of KC\u2019s seen by each student is fixed at K.n = 5\n\u2022 Number of KC\u2019s seen by student i is generated Ji \u223c min(K,Poisson(K.n)).\n\u2022 The KC\u2019s that student i answers are drawn without replacement from {1, . . . , K}.\n\u2022 T.avg = 8 is the average number of practice opportunities for any student on any KC.\n\u2022 The number of practice opportunities for student i on KC k isOij \u223c max(Poisson(T.avg), 2). So that if a student practiced a KC, they practiced it at least twice.\nA1.2. BKT+FS simulation\nThe second adaptation to the familiar 2-state BKT model includes a small proportion of students who occasionally engage in unproductive learning behavior, which produces long strings of incorrect responses, or failure sequences. This behavior might appear for many different reasons, such as the student engaging in hint-abuse or other gaming behaviors, or the student may simply lack a key prerequisite KC. As a shorthand, we shall refer to students who engage in this behavior as FS-students.\nOn each KC, the FS-students will have a probability of engaging in the FS behavior for that KC. The probability that these students will engage in the behaviors depends on the KC, not the student. Whether a student ever engages in the FS-behavior depends on the student. When a student does so depends on the KC.\nWhen a student does engage in FS-behavior, their responses will be a string of primarily incorrect responses with high probability. When a student is not engaging in FS-behavior, data is generated according to an unmodified two-state BKT model.\n\u2022 Student i\u2019s response on the tth opportunity to practice KC j:\nXijt = { 0 if incorrect 1 if correct\n\u2022 Denote student i\u2019s unobserved knowledge of KC j on the tth opportunity as\nZijt = { 1 if unlearned state 2 if learned state\n\u2022 Probability for initial states: \u03c0j = (\u03c0j1, \u03c0j2). Note that E[\u03c0j1] = 13 , and the distribution is shown in figure 11).\nP (Zij0 = 1) = \u03c0j1 \u223c Beta(1, 2) P (Zij0 = 2) = \u03c0j2 = 1\u2212 \u03c0j1\n\u2022 Transition matrices for the Markov process are\nPj =\n( 1\u2212 Lj Lj\n0 1 ) Lj is the probability of learning KC j following a practice attempt, generated according to Lj \u223c Beta(2, 2). (figure 12).\n\u2022 Probability of a correct answer in the unlearned state (guessing): Cuj \u223c Unif(0.02, 0.3)\nPr(Xijt = 1|Zijt = 1) = Cuj\n\u2022 Probability of a correct answer in the learned state (1-slip): Clj \u223c Unif(0.7, 0.98)\nPr(Xijt = 1|Zijt = 2) = Clj\n\u2022 To simulate the FS-behavior:\n\u2013 For each student draw the indicator Gi for whether student i engages in the FSbehavior, Gi \u223c Bernoulli(0.08).\n\u2013 For each KC j, draw a probability that one of the FS-students will engage in this behavior on this KC. Bj \u223c Uniform(0, 1).\n\u2013 Draw an indicator for whether student i will engage in this behavior on KC j\nWij|Gi = 1 \u223c Bernoulli(Bj) Wij|Gi = 0 = 0\n\u2013 If Wij = 0, then generate Xij from the 2-state BKT model. \u2013 If Wij = 1, then for t = 1, . . . , Tij , Xijt|Wij = 1 \u223c Bernoulli(0.2).\n\u2022 Average number of KC\u2019s seen by each student is fixed at K.n = 5\n\u2022 Number of KC\u2019s seen by student i is generated Ji \u223c min(K,Poisson(K.n)).\n\u2022 The KC\u2019s that student i answers are drawn without replacement from {1, . . . , K}.\n\u2022 T.avg = 8 is the average number of practice opportunities for any student on any KC.\n\u2022 The number of practice opportunities for student i on KC k isOij \u223c max(Poisson(T.avg), 2). So that if a student practiced a KC, they practiced it at least twice."}, {"heading": "ACKNOWLEDGEMENTS", "text": "We thank Neil Heffernan, Ryan Baker, and Yutao Wang for providing the Assistments data set."}], "references": [{"title": "Prediction and entropy", "author": ["H. AKAIKE"], "venue": "In A Celebration of Statistics,", "citeRegEx": "AKAIKE,? \\Q1985\\E", "shortCiteRegEx": "AKAIKE", "year": 1985}, {"title": "Limitations of student control: Do students know when they need help", "author": ["V. ALEVEN", "K.R. KOEDINGER"], "venue": "In Intelligent Tutoring Systems,", "citeRegEx": "ALEVEN and KOEDINGER,? \\Q2000\\E", "shortCiteRegEx": "ALEVEN and KOEDINGER", "year": 2000}, {"title": "Off-task behavior in the cognitive tutor classroom: when students game the system", "author": ["R.S. BAKER", "A.T. CORBETT", "K.R. KOEDINGER", "A.Z. WAGNER"], "venue": "In Proceedings of the SIGCHI conference on Human factors in computing systems", "citeRegEx": "BAKER et al\\.,? \\Q2004\\E", "shortCiteRegEx": "BAKER et al\\.", "year": 2004}, {"title": "Detecting learning moment-bymoment", "author": ["R.S. BAKER", "A.B. GOLDSTEIN", "N.T. HEFFERNAN"], "venue": "In IJAIED", "citeRegEx": "BAKER et al\\.,? \\Q2011\\E", "shortCiteRegEx": "BAKER et al\\.", "year": 2011}, {"title": "lme4: Linear mixed-effects models using eigen and s4", "author": ["D. BATES", "M. MAECHLER", "B. BOLKER", "S. WALKER"], "venue": "Computer Program", "citeRegEx": "BATES et al\\.,? \\Q2013\\E", "shortCiteRegEx": "BATES et al\\.", "year": 2013}, {"title": "Identifiability: A fundamental problem of student modeling", "author": ["J.E. BECK", "CHANG", "K.-M"], "venue": "Modeling", "citeRegEx": "BECK et al\\.,? \\Q2007\\E", "shortCiteRegEx": "BECK et al\\.", "year": 2007}, {"title": "Learning factors analysis \u2013 a general method for cognitive model evaluation and improvement", "author": ["H. CEN", "K. KOEDINGER", "B. JUNKER"], "venue": "In Proceedings of 8th ITS Conference", "citeRegEx": "CEN et al\\.,? \\Q2006\\E", "shortCiteRegEx": "CEN et al\\.", "year": 2006}, {"title": "Learning factors analysis \u2013 a general method for cognitive model evaluation and improvement", "author": ["H. CEN", "K. KOEDINGER", "B. JUNKER"], "venue": null, "citeRegEx": "CEN et al\\.,? \\Q2006\\E", "shortCiteRegEx": "CEN et al\\.", "year": 2006}, {"title": "Comparing two irt models for conjunctive skills", "author": ["H. CEN", "K. KOEDINGER", "B. JUNKER"], "venue": "Proceedings of the Proceedings of the 9th International Conference on Intelligent Tutoring Systems,", "citeRegEx": "CEN et al\\.,? \\Q2008\\E", "shortCiteRegEx": "CEN et al\\.", "year": 2008}, {"title": "Is over practice necessary? \u2013improving learning efficiency with the cognitive tutor through educational data mining", "author": ["H. CEN", "K.R. KOEDINGER", "B. JUNKER"], "venue": "In Proceedings of the 2007 conference on Artificial Intelligence in Education: Building Technology Rich Learning Contexts", "citeRegEx": "CEN et al\\.,? \\Q2007\\E", "shortCiteRegEx": "CEN et al\\.", "year": 2007}, {"title": "Instructional factors analysis: A cognitive model for multiple instructional interventions", "author": ["M. CHI", "K. KOEDINGER", "G. GORDON", "P. JORDAN", "K. VANLEHN"], "venue": "In Proceedings of the 4th EDM Conference", "citeRegEx": "CHI et al\\.,? \\Q2011\\E", "shortCiteRegEx": "CHI et al\\.", "year": 2011}, {"title": "Knowledge tracing: Modeling the acquisition of procedural knowledge", "author": ["A.T. CORBETT", "J.R. ANDERSON"], "venue": "User Modeling and User-Adapted Interaction", "citeRegEx": "CORBETT and ANDERSON,? \\Q1995\\E", "shortCiteRegEx": "CORBETT and ANDERSON", "year": 1995}, {"title": "Explanatory item response models: a generalized linear and nonlinear approach", "author": ["P. DE BOECK", "M. WILSON", "Eds"], "venue": null, "citeRegEx": "BOECK et al\\.,? \\Q2004\\E", "shortCiteRegEx": "BOECK et al\\.", "year": 2004}, {"title": "The linear logistic test model as an instrument in educational research", "author": ["G.H. FISCHER"], "venue": "Acta Psychologica", "citeRegEx": "FISCHER,? \\Q1973\\E", "shortCiteRegEx": "FISCHER", "year": 1973}, {"title": "Recent-performance factors analysis", "author": ["A. GALYARDT", "I.M. GOLDIN"], "venue": "In Proceedings of 7th International Conference on Educational Data Mining", "citeRegEx": "GALYARDT and GOLDIN,? \\Q2014\\E", "shortCiteRegEx": "GALYARDT and GOLDIN", "year": 2014}, {"title": "How to construct more accurate student models: Comparing and optimizing knowledge tracing and performance factor analysis", "author": ["Y. GONG", "J.E. BECK", "N.T. HEFFERNAN"], "venue": "International Journal of Artificial Intelligence in Education", "citeRegEx": "GONG et al\\.,? \\Q2011\\E", "shortCiteRegEx": "GONG et al\\.", "year": 2011}, {"title": "Mcmc methods for multi-response generalized linear mixed models: The MCMCglmm R package", "author": ["J.D. HADFIELD"], "venue": "Journal of Statistical Software", "citeRegEx": "HADFIELD,? \\Q2010\\E", "shortCiteRegEx": "HADFIELD", "year": 2010}, {"title": "The ASSISTments ecosystem: Building a platform that brings scientists and teachers together for minimally invasive research on human learning and teaching", "author": ["N.T. HEFFERNAN", "C.L. HEFFERNAN"], "venue": "International Journal of Artificial Intelligence in Education", "citeRegEx": "HEFFERNAN and HEFFERNAN,? \\Q2014\\E", "shortCiteRegEx": "HEFFERNAN and HEFFERNAN", "year": 2014}, {"title": "An Introduction to Statistical Learning", "author": ["G. JAMES", "D. WITTEN", "T. HASTIE", "R. TIBSHIRANI"], "venue": null, "citeRegEx": "JAMES et al\\.,? \\Q2013\\E", "shortCiteRegEx": "JAMES et al\\.", "year": 2013}, {"title": "Different parameters-same prediction: An analysis of learning curves", "author": ["T. KASER", "K. KOEDINGER", "M. GROSS"], "venue": "In Proceedings of 7th International Conference on Educational Data Mining", "citeRegEx": "KASER et al\\.,? \\Q2014\\E", "shortCiteRegEx": "KASER et al\\.", "year": 2014}, {"title": "Using contxtual factors analysis to explain transfer of least common multiple skills", "author": ["P. PAVLIK", "M. YUDELSON", "K. KOEDINGER"], "venue": "In Artificial intelligence in education,", "citeRegEx": "PAVLIK et al\\.,? \\Q2011\\E", "shortCiteRegEx": "PAVLIK et al\\.", "year": 2011}, {"title": "Performance factors analysis \u2013a new alternative to knowledge tracing", "author": ["P.I. PAVLIK", "H. CEN", "K. KOEDINGER"], "venue": "In Proceedings of AIED", "citeRegEx": "PAVLIK et al\\.,? \\Q2009\\E", "shortCiteRegEx": "PAVLIK et al\\.", "year": 2009}, {"title": "Investigating automated student modeling in a java mooc", "author": ["M. YUDELSON", "R. HOSSEINI", "A. VIHAVAINEN", "P. BRUSILOVSKY"], "venue": "In Proceedings of 7th International Conference on Educational Data Mining", "citeRegEx": "YUDELSON et al\\.,? \\Q2014\\E", "shortCiteRegEx": "YUDELSON et al\\.", "year": 2014}], "referenceMentions": [], "year": 2015, "abstractText": "In educational technology and learning sciences, there are multiple uses for a predictive model of whether a student will perform a task correctly or not. For example, an intelligent tutoring system may use such a model to estimate whether or not a student has mastered a skill. We analyze the significance of data recency in making such predictions, i.e., asking whether relatively more recent observations of a student\u2019s performance matter more than relatively older observations. We develop a new Recent-Performance Factors Analysis model that takes data recency into account. The new model significantly improves predictive accuracy over both existing logistic-regression performance models and over novel baseline models in evaluations on real-world and synthetic datasets. As a secondary contribution, we demonstrate how the widely used cross-validation with 0-1 loss is inferior to AIC and to cross-validation with L1 prediction error loss as a measure of model performance.", "creator": "LaTeX with hyperref package"}}}