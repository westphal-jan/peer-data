{"id": "1501.06206", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "25-Jan-2015", "title": "Dynamics of Belief: Abduction, Horn Knowledge Base And Database Updates", "abstract": "The dynamics of belief and knowledge is one of the major components of any autonomous system that should be able to incorporate new pieces of information. In order to apply the rationality result of belief dynamics theory to various practical problems, it should be generalized in two respects: first it should allow a certain part of belief to be declared as immutable; and second, the belief state need not be deductively closed. Such a generalization of belief dynamics, referred to as base dynamics, is presented in this paper, along with the concept of a generalized revision algorithm for knowledge bases (Horn or Horn logic with stratified negation). We show that knowledge base dynamics has an interesting connection with kernel change via hitting set and abduction. In this paper, we show how techniques from disjunctive logic programming can be used for efficient (deductive) database updates. The key idea is to transform the given database together with the update request into a disjunctive (datalog) logic program and apply disjunctive techniques (such as minimal model reasoning) to solve the original update problem. The approach extends and integrates standard techniques for efficient query answering and integrity checking. The generation of a hitting set is carried out through a hyper tableaux calculus and magic set that is focused on the goal of minimality. The present paper provides a comparative study of view update algorithms in rational approach. For, understand the basic concepts with abduction, we provide an abductive framework for knowledge base dynamics. Finally, we demonstrate how belief base dynamics can provide an axiomatic characterization for insertion a view atom to the database. We give a quick overview of the main operators for belief change, in particular, belief update versus database update. For example, the next question in the paper is on the first step of a system that could easily be updated using a system that can be modified without compromising its accuracy. Thus, we show that this system can be used to integrate knowledge base dynamics into a model that can be modified without compromising its accuracy. For example, we describe how knowledge base dynamics can be used to integrate knowledge base dynamics into a model that can be modified without compromising its accuracy. We provide a comparative study of view update algorithms in rational approach. For, understand the basic concepts with abduction, we provide an abductive framework for knowledge base dynamics. Finally, we demonstrate how belief base dynamics can provide an axiomatic characterization for insertion a view atom to the database. We give a quick overview of the main operators for belief change, in particular, belief update versus database update. For, understand the basic", "histories": [["v1", "Sun, 25 Jan 2015 20:48:53 GMT  (397kb,D)", "https://arxiv.org/abs/1501.06206v1", "arXiv admin note: substantial text overlap witharXiv:1411.2499,arXiv:1405.2642,arXiv:1407.3512,arXiv:1301.5154"], ["v2", "Tue, 27 Jan 2015 09:59:49 GMT  (397kb,D)", "http://arxiv.org/abs/1501.06206v2", "arXiv admin note: substantial text overlap witharXiv:1411.2499,arXiv:1405.2642,arXiv:1407.3512,arXiv:1301.5154"]], "COMMENTS": "arXiv admin note: substantial text overlap witharXiv:1411.2499,arXiv:1405.2642,arXiv:1407.3512,arXiv:1301.5154", "reviews": [], "SUBJECTS": "cs.LO cs.AI cs.DB", "authors": ["radhakrishnan delhibabu"], "accepted": false, "id": "1501.06206"}, "pdf": {"name": "1501.06206.pdf", "metadata": {"source": "CRF", "title": "Dynamics of Belief: Abduction, Horn Knowledge Base And Database Updates", "authors": ["Radhakrishnan Delhibabu"], "emails": ["delhibabu@kbsg.rwth-aachen.de"], "sections": [{"heading": null, "text": "Keyword: AGM, Belief Revision, Belief Update, Horn Knowledge Base Dynamics, Kernel Change, Abduction, Hyber Tableaux, Magic Set, View update, Update Propagation."}, {"heading": "1 Introduction", "text": "We live in a constantly changing world, and consequently our beliefs have to be revised whenever there is new information. When we encounter a new piece of information that contradicts our current beliefs, we revise our beliefs rationally.\nar X\niv :1\n50 1.\n06 20\n6v 2\n[ cs\n.L O\n] 2\n7 Ja\nn 20\nIn the last three decades, the field of computer science has grown substantially beyond mere number crunching, and aspires to imitate rational thinking of human beings. A separate branch of study, artificial intelligence (AI) has evolved, with a number of researchers attempting to represent and manipulate knowledge in a computer system. Much work has been devoted to study the statics of the knowledge, i.e. representing and deducting from fixed knowledge, resulting in the development of expert systems. The field of logic programming, conceived in last seventies, has proved to be an important tool for handling static knowledge. However, such fixed Horn knowledge based systems can not imitate human thinking, unless they are accomplish revising their knowledge in the light of new information. As mentioned before, this revision has to take place rationally. This has led to a completely new line of research, the dynamics of belief.\nStudies in dynamics of belief are twofold: What does it mean to rationally revise a belief state? How can a belief state be represented in a computer and revised? The first question is more philosophical theory, and a lot of works have been carried out from epistemological perspective to formalize belief dynamics. The second question is computation oriented, and has been addressed differently from various perspectives of application. For example, a lot of algorithms have been proposed in logic programming to revise a Horn knowledge base or a database represented as a logic program; number of algorithms are there to carry out a view update in a rational database; algorithm to carry out diagnosis; algorithm for abduction reasoning and so on. We need the concept of \u201dchange\u201d in some form or other and thus need some axiomatic characterization to ensure that the algorithms are rational. Unfortunately, till this date, these two tracks remain separate, with minimal sharing of concepts and results. The primary purpose of the paper is to study these two developments and integrate them.\nWhen a new piece of information is added to a Horn knowledge base (Delgrande 2008 and Delgrande & Peppas 2011), (Papini 2000) it may become inconsistent. Revision means modifying the Horn knowledge base in order to maintain consistency, by keeping the new information and removing the least possible previous information. In our case, update means revision and contraction, that is insertion and deletion in database perspective. Previous works (Aravindan & Dung 1994), (Aravindan 1995) have explained connections between contraction and knowledge base dynamics. Our Horn knowledge base dynamics is defined in two parts: an immutable part (Horn formulae) and updatable part (literals) (for definition and properties see the works of Nebel 1998, Segerberg 1998, Hansson et al 2001 and Ferme\u0301 & Hansson 2001). Knowledge bases have a set of integrity constraints. In the case of finite knowledge bases, it is sometimes hard to see how the update relations should be modified to accomplish certain Horn knowledge base updates. ."}, {"heading": "2 Motivation", "text": "In the general case of arbitrary formulae, the revision problem for knowledge bases is hard to solve. So we restrict the revision problem to Horn formulae. The connection between belief change and database change is an interesting one since so far the two communities have independently considered two problems that are very similar, and our aim is to bring out this connection.\nWe aim to bridge the gap between philosophical and database theory. In such a case, Hansson\u2019s (Hansson 1997) kernel change is related to the abductive method. Aliseda\u2019s (Aliseda 2006) book on abductive reasoning is one of our key motivation. Wrobel\u2019s (Wrobel 1995) definition of first-order theory revision was helpful to frame our algorithm. On the other hand, we are dealing with the view update problem. Keller and Minker\u2019s (Keller 1985 and Minker 1996) work is one the motivation for the view update problem. In Figure 1 understand the concept of view update problem in rational way. Figure show that foundation form Belief Revision theory, intermediate step handle to Horn knowledge base, this step very impairment that agent have background knowledge and he/she made decision with postulate may require to process next step. Target of the application is connect database updates via Horn knowledge base with abduction reasoning. All clear procedure shown in each section.\nFollowing example illustrates the motivation of the paper:\nExample 1. Consider a database with an (immutable) rule that a staff member is a person who is currently working in a research group under a chair. Additional (updatable) facts are that matthias and gerhard are group chairs, and\ndelhibabu and aravindan are staff members in group infor1. Our first integrity constraint (IC) is that each research group has only one chair ie. \u2200x, y, z (y=z)\u2190 group chair(x,y) \u2227 group chair(x,z). Second integrity constraint is that a person can be a chair for only one research group ie. \u2200x, y, z (y=z)\u2190 group chair(y,x) \u2227 group chair(z,x).\nImmutable part: staff chair(x,y)\u2190 staff group(x,z),group chair(z,y).\nUpdatable part: group chair(infor1,matthias)\u2190 group chair(infor2,gerhard)\u2190 staff group(delhibabu,infor1)\u2190 staff group(aravindan,infor1)\u2190\nSuppose we want to update this database with the information, staff chair(aravindan,gerhard); From the immutable part, we can deduce that this can be achieved by asserting staff group(aravindan,z) \u2227 group chair(z,gerhard)\nIf we are restricted to definite clauses, there are three plausible ways to do this: first case is, aravindan and gerhard belong to infor1, i.e, staff group(aravindan,infor1) \u2227 group chair(info1,gerhard). We need to delete both base facts group - chair(infor1,matthias)\u2190 and group chair(infor2,gerhard)\u2190, because our first IC as well as second IC would be violated otherwise. In order to change the view, we need to insert group chair(infor1,gerhard)\u2190 as a base fact. Assume that we have an algorithm that deletes the base facts staff group(delhibabu,infor1)\u2190 from the database. But, no rational person will agree with such an algorithm, because the fact staff group(delhibabu,infor1)\u2190 is not \u201drelevant\u201d to the view atom.\nSecond case, aravindan and gerhard belong to infor2, that is staff group(aravindan,infor2) \u2227 group chair(infor2,gerhard). Simply, insert the new fact staff group(aravindan,infor2)\u2190 to change the view. Suppose an algorithm deletes the base facts staff group(aravindan,infor1)\u2190 from the database, then it can not be \u201drational\u201d since these facts are not \u201drelevant\u201d to the view atom.\nThird case, aravindan and gerhard belong to infor3 (free assignment of the group value), that is staff group(aravindan,infor3) \u2227 group chair(info3,gerhard). Suppose, we insert new base fact group chair(infor3,gerhard) \u2190, our second IC does not follow. Suppose an algorithm inserts the new base fact staff group(aravindan,infor2)\u2190 or staff group(aravindan,infor1)\u2190 is deleted, then it can not be \u201drational\u201d.\nThe above example highlights the need for some kind of \u201drelevance policy\u201d to be adopted when a view atom is to be inserted to a deductive database. How many such axioms and policies do we need to characterize a \u201dgood\u201d view update? When are we sure that our algorithm for view update is \u201drational\u201d? Clearly, there is a need for an axiomatic characterization of view updates. By axiomatic characterization, we mean explicitly listing all the rationality axioms that are to be satisfied by any algorithm for view update.\nThe basic idea in (Behrend & Manthey 2008), (Aravindan & Baumgartner 1997) is to employ the model generation property of hyper tableaux and magic set to generate models, and read off diagnosis from them. One specific feature\nof this diagnosis algorithm is the use of semantics (by transforming the system description and the observation using an initial model of the correctly working system) in guiding the search for a diagnosis. This semantical guidance by program transformation turns out to be useful for database updates as well. More specifically we use a (least) Herbrand model of the given database to transform it along with the update request into a logic program in such a way that the models of this transformed program stand for possible updates.\nWe discuss two ways of transforming the given database together with the view update (insert and delete) request into a logic program resulting in two variants of view update algorithms. In the first variant, a simple and straightforward transformation is employed. Unfortunately, not all models of the transformed program represent a rational update using this approach. The second variant of the algorithm uses the least Herbrand model of the given database for the transformation. In fact what we referred to as offline preprocessing before is exactly this computation of the least Herbrand model. This variant is very meaningful in applications where views are materialized for efficient query answering. The advantage of using the least Herbrand model for the transformation is that all models of the transformed logic program (not just the minimal ones) stand for a rational update.\nWhen dealing with the revision of a Horn knowledge base (both insertions and deletions), there are other ways to change a Horn knowledge base and it has to be performed automatically also (Ferme\u0301 1992 and Rodrigues& Benevidas 1994). Considering the information, change is precious and must be preserved as much as possible. The principle of minimal change (Ga\u0308rdenfors 1998, Dalal 1988 and Herzig & Rifi 1999), (Schulte 1999) can provide a reasonable strategy. On the other hand, practical implementations have to handle contradictory, uncertain, or imprecise information, so several problems can arise: how to define efficient change in the style of Carlos Alchourro\u0301n, Peter Ga\u0308rdenfors, and David Makinson (AGM) (Alchourron et al. 1985b); what result has to be chosen (Lakemeyer 1995), (Lobo & Trajcevski 1997), (Nayak et al. 2006); and finally, according to a practical point of view, what computational model to explore for the Horn knowledge base revision has to be provided?\nThe rest of the paper is organized as follows: First we start with preliminaries in Section 3. In Section 4, we give a quick overview of belief changes and belief update. In Section 5, we introduce knowledge base dynamics along with the concept of generalized revision, and revision operator for knowledge base. Section 6 studies the relationship between knowledge base dynamics and abduction and shows how abductive procedures could be used to realize revision. In Section 7, we give a quick overview of belief update versus knowledge base update. In Section 8, we discuss an important application of knowledge base dynamics in providing an axiomatic characterization for insertion view atoms to databases; and nature of view update problem for incomplete to complete information shown. We give a quick overview of belief update versus database update in Section 9. In Section 10, we provide an abductive framework for Horn knowledge base dynamics in first order version. In Section 11, we give brief overview\nof related works. In Section 12, we draw conclusions with a summary of our contribution and indicate future directions of our investigation."}, {"heading": "3 Preliminaries", "text": "We consider a propositional language LP defined from a finite set of propositional variables P and the standard connectives. We use a, b, x, y, ...\u03d5, \u03c6, \u03c8, ... for propositional formulae. Sets of formulae are denoted by upper case Roman letters A,B, F,K, ..... A literal is an atom (positive literal), or a negation of an atom (negative literal).\nFor any formula \u03d5, we write E(\u03d5) to mean the set of the elementary letters that occur in \u03d5. The same notation also applies to a set of formulae. For any set F of formulae, L(F ) represents the sub-language generated by E(F ), i.e. the set of all formulae \u03d5 with E(\u03d5) \u2286 E(F ).\nHorn formulae are defined (Delgrande & Peppas 2011) as follows:\n1. Every a \u2208 \u03a6 where \u03a6 \u2208 LP \u222a {\u22a5} , a and \u00aca are Horn clauses. 2. a\u2190 a1\u2227a2\u2227 ...\u2227an is a Horn clause, where n \u2265 0 and a, ai \u2208 \u03a6 (1 \u2264 i \u2264 n). 3. Every Horn clause is a Horn formula, a is called head and ai is body of the\nHorn formula. 4. If \u03d5 and \u03c8 are Horn formulae, so is \u03d5 \u2227 \u03c8.\nA definite Horn clause is a finite set of literals (atoms) that contains exactly one positive literal which is called the head of the clause. The set of negative literals of this definite Horn clause is called the body of the clause. A Horn clause is non-recursive, if the head literal does not occur in its body. We usually denote a Horn clause as head\u2190body. Let LH be the set of all Horn formulae with respect to LP . A formula \u03c6 is a syntactic consequence within LP of a set \u0393 of formulas if there is a formal proof in LP of \u03c6 from the set \u0393 `LP \u03c6.\nA Horn logic with stratified negation (Jackson & Schulte 2008) is similar to a set of Horn formulae. An immutable part is a function-free clause of the form a \u2190 a1 \u2227 a2 \u2227 ... \u2227 an, with n \u2265 1 where a is an atom denoting the immutable part\u2019s head and a1 \u2227 a2 \u2227 ... \u2227 an are literals. i.e. positive or negative atoms, representing the body of the Horn clauses.\nFormally, a finite Horn knowledge base KB (Horn or Horn logic with stratified negation) is defined as a finite set of formulae from language LH, and divided into three parts: an immutable theory KBI is a Horn formula (head\u2190body), which is the fixed part of the knowledge; updatable theory KBU is a Horn clause (head\u2190); and integrity constraint KBIC representing a set of clauses (Horn logic with stratified negation) (\u2190body).\nDefinition 1 (Horn Knowledge Base). A Horn knowledge base, KB is a finite set of Horn formulae from language LH, s.t KB = KBI \u222aKBU \u222aKBIC , KBI \u2229KBU = \u2205 and KBU \u2229KBIC = \u2205.\nHorn knowledge base change deals with situations in which an agent has to modify its beliefs about the world, usually due to new or previously unknown\nincoming information, also represented as formulae of the language. Common operations of interest in Horn knowledge base change are the expansion of an agent\u2019s current Horn knowledge base KB by a given Horn clause \u03d5 (usually denoted as KB+\u03d5), where the basic idea is to add regardless of the consequences, and the revision of its current beliefs by \u03d5 (denoted as KB * \u03d5), where the intuition is to incorporate \u03d5 into the current beliefs in some way while ensuring consistency of the resulting theory at the same time. Perhaps the most basic operation in Horn knowledge base change, like belief change, is that of contraction AGM (Alchourron et al. 1985b), which is intended to represent situations in which an agent has to give up \u03d5 from its current stock of beliefs (denoted as KB-\u03d5).\nDefinition 2 (AGM Contraction). Let KB be a Horn knowledge base, and \u03b1 a belief that is present in KB. Then contraction of KB by \u03b1, denoted as KB\u2212\u03b1, is a consistent belief set that ignore \u03b1\nDefinition 3 (Levi Identity). Let - be an AGM contraction operator for KB. A way to define a revision is by using Generalized Levi Identity:\nKB \u2217 \u03b1 = (KB \u2212 \u00ac\u03b1) \u222a \u03b1\nThen, the revision can be trivially achieved by expansion, and the axiomatic characterization could be straightforwardly obtained from the corresponding characterizations of the traditional models (Alchourron, CE et al 1985). The aim of our work is not to define revision from contraction, but rather to construct and axiomatically characterize revision operators in a direct way."}, {"heading": "4 Belief Changes", "text": "Working at an abstract philosophical level, the aim of belief dynamics is to formalize the rationality of change, without worrying much about the syntactic representation of belief. However, it is not possible to completely ignore belief representation, and works on belief dynamics assume as little necessary things as possible about the representation of the belief. In this Section based on Konieczny\u2019s (Konieczny 2011) work, we recall the definition of the main belief change operators and the links between them. We focus on the classical case, where the belief represent use propositional logic. This is a very quick presentation of belief change theory. For a complete introduction the reader is referred to seminal books on belief revision ((Ga\u0308rdenfors 1992 & 1998), (Hansson 1997a), (Rott 2001)) or the recent special issue of Journal of Philosophical Logic on the 25 Years of AGM Theory (Ferme & Hansson 2011).\nA belief base K is a finite set of propositional formulae. In order to simplify the notations we identify the base K with the formula. which is the conjunction of the formulae of K 1 1 There are two major interpretations of belief bases. One of them, supported by Dalal\n1998, uses belief bases as mere expressive devices; hence if Cn(B1) = Cn(B2) then\nBelief revision aims at changing the status of some beliefs in the base that are contradicted by a more reliable piece of information. Several principles are govern this revision operation:\n\u2013 First is the primacy of update principle: the new piece of information has to be accepted in the belief base after the revision. This is due to the hypothesis that the new piece of information is more reliable than the current beliefs 2 \u2013 Second is the principle of coherence: the new belief base after the revision should be a consistent belief base. Asking the beliefs to be consistent is a natural requirement if one wants to conduct reasoning tasks from her belief base \u2013 Third is the principle of minimal change: the new belief base after the revision should be as close as possible from the current belief base. This important principle aims at ensuring that no unnecessary information (noise) is added to the beliefs during the revision process, and that no unnecessary information is lost during the process: information/beliefs are usually costly to obtain, we do not want to throw them away without any serious reason.\nlet \u03c8 and \u00b5 be two formulae denoting respectively the belief base, and a new piece of information. Then \u03c8 \u25e6 \u00b5 is a formula representing the new belief base. An operator \u25e6 is an AGM belief revision operator if it satisfies the following properties.\nDefinition 4 (Belief revision).\n(R1) \u03c8 \u25e6 \u00b5 implies \u00b5. (R2) If \u03c8 \u2227 \u00b5 is satisfiable, then \u03c8 \u25e6 \u00b5 \u2261 \u03c8 \u2227 \u00b5. (R3) If \u00b5 is satisfiable, then so is \u03c8 \u25e6 \u00b5. (R4) If \u03c81 \u2261 \u03c82 and \u00b51 \u2261 \u00b52, then \u03c81 \u25e6 \u00b51 \u2261 \u03c82 \u25e6 \u00b52. (R5) (\u03c8 \u25e6 \u00b5) \u2227 \u03c6 implies \u03c8 \u25e6 (\u00b5 \u2227 \u03c6). (R6) If (\u03c8 \u25e6 \u00b5) \u2227 \u03c6 is satisfiable, then \u03c8 \u25e6 (\u00b5 \u2227 \u03c6) implies (\u03c8 \u25e6 \u00b5) \u2227 \u03c6.\nWhen one works with a finite propositional language the above postulates, proposed by Katsuno and Mendelzon (Katsuno, H & Mendelzon, AO. 1991b), are equivalent to AGM ((Alchourron et al 1985b) and (Ga\u0308rdenfors 1998)) (R1) states that the new piece of information must be believed after the revision. (R2) says that when there is no conflict between the new piece of information and the current belief, the revision is just the conjunction. (R3) says that revision always a consistent belief base, unless the new piece of information is not consistent. (R4) is an irrelevance of syntax condition, it states that logically equivalent bases\nB1 and B2 represent the same belief state and yield the same outcome under all operations of change. The other, more common approach treats inclusion in the belief base as epistemically significant. The belief base contains those sentences that have an epistemic standing of their own (Ferme 2011) 2 If this is not the case one should use a non-prioritized revision operator (Hansson 1997b)\nmust lead to the same result. (R5) and (R6) give conditions on the revision by a conjunction.\nAGM also defined contraction operators, that aim to remove some piece of information from the beliefs of the agent. These contraction operators are closely related to revision operators, since each contraction operator can be used to define a revision operator, through the Levy identity and conversely each revision operator can be used to define a contraction operator through the Harper identity ((Alchourron et al 1985b) and (Ga\u0308rdenfors 1998)). So one can study indifferently revision or contraction operators. So we focus on revision here.\nSeveral representation theorems, that give constructive ways to define AGM revision/ contraction operators, have been proposed, such as partial meet contraction/revision (Alchourron et al 1985b), epistemic entrenchments (Ga\u0308rdenfors 1992) and (Ga\u0308rdenfors & Makinson 1988), safe contraction (Alchourron et al 1985a), etc. In (Katsuno & Mendelzon 1991b and 1992) (Benferhat et al. 2005), Katsuno and Mendelzon give a representation theorem, showing that each revision operator corresponds to a faithful assignment, that associates to each base a plausibility preorder on interpretations (this idea can be traced back to Grove systems of spheres (Grove 1988)).\nAssume a total pre-order \u2264\u03c8 on W (set of possible world). That is to say, KB = min(W,\u2264\u03c8). As usual we take \u2264\u03c8 to be an ordering of plausibility on the worlds, with worlds lower down in the ordering seen as more plausible. In what follows '\u03c8 will always denote the symmetric closure of \u2264\u03c8, i.e., W1 '\u03c8 W2 iff both W1 \u2264\u03c8 W2 and W2 \u2264\u03c8 W1.\nDefinition 5 ((Konieczny 2011)). A faithful assignment is a function mapping each base \u03c8 to a pre-order \u2264\u03c8 over interpretations such that\n1. if \u03c9 |= \u03c8 and \u03c9\u2032 |= \u03c8, then \u03c9 '\u03c8 \u03c9\u2032 2. if \u03c9 |= \u03c8 and \u03c9\u2032 6|= \u03c8, then \u03c9 <\u03c8 \u03c9\u2032 3. if \u03c8 \u2261 \u03c8\u2032, then \u2264\u03c8=\u2264\u03c8\u2032\nTheorem 1 ((Katsuno & Mendelzon 1991b and 1991b)). An operator \u25e6 is an AGM revision operator (i.e. it satisfies (R1)-(R6)) if and only if there exists a faithful assignment that maps each base \u03c8 to a total pre-order \u2264\u03c8 such that mod(\u03c8 \u25e6 \u00b5)= min(mod(\u00b5),\u2264\u03c8).\nProof. Follows from the definition 5 and the result of Konieczny 2011.\nOne of the main problems of this characterization of belief revision is that it does not constrain the operators enough for ensuring a good behavior when we do iteratively several revisions. So one needs to add more postulates and to represent the beliefs of the agent with a more complex structure than a simple belief base. In (Darwiche & Pearl 1997) Darwiche and Pearl proposed a convincing extension of AGM revision. This proposal have improved by an additional condition in ((Booth & Meyer 2006) and (Jin & Thielscher 2007), (Konieczny, et al. 2010) and (Konieczny & Pino Prez 2008)) define improvement operators that are a generalization of iterated revision operators.\nWhereas belief revision should be used to improve the beliefs by incorporating more reliable pieces of evidence, belief update operators aim at maintaining the belief base up-to-date, by allowing modifications of the base according to a reported change in the world. This distinction between revision and update was made clear in Katsuno & Mendelzon 1991 and 1992, where Katsuno & Mendelzon 1991 proposed postulates for belief update.\nDefinition 6 (Belief Update). An operator is a (partial) update operator if it satisfied the properties (U1)(U8). It is a total update operator if it satisfies the property (U1)-(U5),(U8),(U9).\n(U1) \u03c8 \u00b5 implies \u00b5. (U2) if\u03c8 implies \u00b5, then \u03c8 \u00b5 \u2261 \u03c8 (U3) if\u03c8 not implies \u22a5 and \u00b5 not implies \u22a5 then \u03c8 \u00b5 not implies \u22a5 (U4) If \u03c81 \u2261 \u03c82 and \u00b51 \u2261 \u00b52, then \u03c81 \u00b51 \u2261 \u03c82 \u00b52. (U5) If (\u03c8 \u00b5) \u2227 \u03c6 implies \u03c8 (\u00b5 \u2227 \u03c6) (U6) If (\u03c8 \u00b51) implies \u00b52 and (\u03c8 \u00b52) implies \u00b52 then \u03c8 \u00b51 \u2261 \u03c8 \u00b52 (U7) If \u03c8 is a complete formula, then (\u03c8 \u00b51) \u2227 (\u03c8 \u00b52) implies \u03c8 (\u00b51 \u2228 \u00b52) (U8) (\u03c81 \u2228 \u03c82) \u00b5 \u2261 (\u03c81 \u00b5) \u2228 (\u03c82 \u00b5) (U9) If \u03c8 is a complete formula and (\u03c8 \u00b5) \u2227 \u03c8 not implies \u22a5 then \u03c8 (\u00b5 \u2227 \u03c8)\nimplies (\u03c8 \u00b5) \u2227 \u03c8\nMost of these postulates are close to the ones of revision. The main differences lie in postulate (U2) that is much weaker than (R2): conversely to revision, even if the new piece of information is consistent with the belief base, the result is generally not simply the conjunction. This illustrates the fact that revision can be seen as a selection process of the most plausible worlds of the current beliefs with respect to the new piece information, whereas update is a transition process: each world of the current beliefs have to be translated to the closest world allowed by the new piece of information. This world-by-world treatment is expressed by postulate (U8).\nAs for revision, there is a representation theorem in terms of faithful assignment.\nDefinition 7 ([25]). A faithful assignment is a function mapping each interpretation \u03c9 to a pre-order \u2264\u03c9 over interpretations such that if \u03c9 , \u03c9\u2032, then \u03c9 <\u03c9 \u03c9 \u2032\nTheorem 2. An update operator satisfies (U1)-(U8) if and only if there exists a faithful assignment that maps each interpretation \u03c9 to a partial pre-order \u2264\u03c9 such that mod(\u03c8 \u00b5)= \u22c3 \u03c9|=\u03c8 min(mod(\u00b5),\u2264\u03c9).\nProof. Follows from the observation and the result of Konieczny 2011.\nBut there is also a second theorem corresponding to total pre-orders.\nTheorem 3. An update operator satisfies (U1)-(U5), (U8) and (U9) if and only if there exists a faithful assignment that maps each interpretation \u03c9 to a total preorder \u2264\u03c9 such that mod(\u03c8 \u00b5)= \u22c3 \u03c9|=\u03c8 min(mod(\u00b5),\u2264\u03c9).\nProof. Follows from the observation and the result of Konieczny 2011.\nDefinition 8 ([3]). Let M=(W.w) be a K-model and \u00b5 a formula. A k-model M \u2032 = (W \u2032, w\u2032) is called a possible resulting k-model after updating M with \u00b5 if and only if the following conditions hold:\n1. M\u2019|= \u00b5; 2. there does not exist another k-model M \u2032\u2032 = (W \u2032\u2032, w\u2032\u2032) such that M \u2032\u2032 |= \u00b5 and\nM \u2032\u2032 <M M \u2032.\nThe set of all possible resulting k-models after updating M with \u00b5 as Res(M,\u00b5).\nTheorem 4. Knowledge update operator defined in definition 8 satisfies (U1)(U9).\nProof. Follows from the definition 8 and the result of Baral & Zhang 2005.\nNote 1. Horn knowledge base is a subset of belief base, KB \u2286 B, so everything that follows for belief base, also follows for Horn Knowledge base."}, {"heading": "5 Horn Knowledge base dynamics", "text": "In the AGM framework, a belief set is represented by a deductively closed set of propositional formulae. While such sets are infinite, they can\u2019t always be finitely representable. However, working with deductively closed, infinite belief sets is not very attractive from a computational point of view. The AGM approach to belief dynamics is very attractive in its capture the rationality of change, but it is not always easy to implement either Horn formula based partial meet revision or generalized kernel revision. In artificial intelligence and database applications, what is required is to represent the knowledge using a finite Horn knowledge base. Further, a certain part of the knowledge is treated as immutable and should not be changed.\nAGM (Alchourron et al. 1985b) proposed a formal framework in which revision is interpreted as belief change. In this section, we focus on the Horn knowledge base revision and propose new rationality postulates that are adopted from AGM postulates for revision.\nDefinition 9. Let KB be a Horn knowledge base with an immutable part KBI . Let \u03b1 and \u03b2 be any two Horn clauses from LH. Then, \u03b1 and \u03b2 are said to be KB-equivalent iff the following condition is satisfied: \u2200 set of Horn clauses E \u2286 LH and IC: KBI \u222a E \u222a IC ` \u03b1 iff KBI \u222a E \u222a IC ` \u03b2.\nThese postulates stem from three main principles: the new item of information has to appear in the revised Horn knowledge base, the revised base has to be consistent and revision operation has to change the least possible beliefs. Now we consider the revision of a Horn clause \u03b1 with respect to KB, written as KB \u2217 \u03b1. The rationality postulates for revising \u03b1 from KB can be formulated.\nDefinition 10 (Rationality postulates for Horn knowledge base revision).\n(KB*1) Closure: KB \u2217 \u03b1 is a Horn knowledge base. (KB*2) Weak Success: if \u03b1 is consistent with KBI \u222aKBIC then \u03b1 \u2286 KB \u2217 \u03b1. (KB*3.1) Inclusion: KB \u2217 \u03b1 \u2286 Cn(KB \u222a \u03b1). (KB*3.2) Immutable-inclusion: KBI \u2286 Cn(KB \u2217 \u03b1). (KB*4.1) Vacuity 1: if \u03b1 is inconsistent with KBI \u222aKBIC then KB \u2217\u03b1 = KB. (KB*4.2) Vacuity 2: if KB \u222a \u03b1 0\u22a5 then KB \u2217 \u03b1 = KB \u222a \u03b1. (KB*5) Consistency: if \u03b1 is consistent with KBI \u222aKBIC then KB \u2217 \u03b1 con-\nsistent with KBI \u222aKBIC . (KB*6) Preservation: If \u03b1 and \u03b2 are KB-equivalent, then KB \u2217 \u03b1\u2194 KB \u2217 \u03b2. (KB*7.1) Strong relevance: KB \u2217 \u03b1 ` \u03b1 if KBI 0 \u00ac\u03b1 (KB*7.2) Relevance: If \u03b2 \u2208 KB\\KB \u2217 \u03b1, then there is a set KB\u2032 such that\nKB \u2217 \u03b1 \u2286 KB\u2032 \u2286 KB \u222a \u03b1, KB\u2032 is consistent KBI \u222a KBIC with \u03b1, but KB\u2032 \u222a {\u03b2} is inconsistent KBI \u222aKBIC with \u03b1. (KB*7.3) Weak relevance: If \u03b2 \u2208 KB\\KB \u2217\u03b1, then there is a set KB\u2032 such that KB\u2032 \u2286 KB \u222a \u03b1, KB\u2032 is consistent KBI \u222aKBIC with \u03b1, but KB\u2032 \u222a {\u03b2} is inconsistent KBI \u222aKBIC with \u03b1.\nTo revise KB by \u03b1, only those informations that are relevant to \u03b1 in some sense can be added (as example in the introduction illustrates). (KB \u2217 7.1) is very strong axiom allowing only minimum changes, and certain rational revision can not be carried out. So, relaxing this condition (example with more details can be found in (Aravindan 1995, Hansson, SO 1997a, Ferme & Hansson 2011 and Falappa, MA et al 2012), this can be weakened to relevance. (KB \u2217 7.2) is relevance policy that still can not permit rational revisions, so we need to go next step. With (KB \u2217 7.3) the relevance axiom is further weakened and it is referred to as \u201dcore-retainment\u201d."}, {"heading": "5.1 Revision function", "text": "Suppose that we want to revise Horn knowledge base KB with respect to a single clause without using negation. We may construct revision using generalizing techniques from classical belief (base) revision (Falappa et al. 2012). Partial meet revision operator is syntax dependent and based on the foundational approach. In order to define it, first we need to define \u03b1-consistent-remainders.\nDefinition 11 (Remainder Set). Let a Horn knowledge base KB be a set of Horn formulae, where \u03b1 is Horn clause. The \u03b1-consistent-remainders of KB, noted by KB \u2193> \u03b1, is the set of KB\u2032 such that:\n1. KB\u2032 \u2286 KB, ensuring that KBI \u2286 KB\u2032 and KBIC \u2286 KB\u2032. 2. KB\u2032 \u222a \u03b1 is consistent with KBI \u222aKBIC . 3. For any KB\u201d such that KB\u2032 \u2282 KB\u2032\u2032 \u2286 KB then KB\u2032\u2032 \u222a \u03b1 is inconsistent\nwith KBI \u222aKBIC .\nThat is, KB \u2193> \u03b1 is the set of maximal KB-subsets consistent with \u03b1.\nExample 2. Suppose that KB={KBI : p\u2190 a\u2227 b, p\u2190 a, q \u2190 a\u2227 b; KBU : a\u2190, b\u2190; KBIC : \u2205} and \u03b1= \u2190 p. Then we have that:\n- KB \u2193> \u03b1= {{p\u2190 a \u2227 b}, {p\u2190 a},{\u2190 a}, {\u2190 b}}.\nRevision by a Horn clause is based on the concept of a \u03b1-consistent-remainders. In order to complete the construction, we must define a selection function that selects consistent remainders."}, {"heading": "5.2 Principle of minimal change", "text": "Let a Horn knowledge base KB be a set of Horn formulae and \u03c8 is a Horn clause such that KB = {\u03c6 | \u03c8 ` \u03c6} is derived by \u03c6. Now we consider the revision of a Horn clause \u03b1 wrt KB, that is KB \u2217 \u03b1.\nThe principle of minimal change (PMC) leads to the definition of orders between interpretations. Let I be the set of all the interpretations and Mod(\u03c8) be the set of models of \u03c8. A pre-order on I, denoted \u2264\u03c8 is linked with \u03c8. The relation <\u03c8 is defined from \u2264\u03c8 as usual:\nI <\u03c8 I \u2032 iff I \u2264\u03c8 I \u2032 and I \u2032 \u03c8 I.\nThe pre-order \u2264\u03c8 is faithful to \u03c8 if it verifies the following conditions:\n1) If I, I \u2032 \u2208Mod(\u03c8) then I <\u03c8 I \u2032 does not hold; 2) If I \u2208Mod(\u03c8) and I \u2032 <Mod(\u03c8) then I <\u03c8 I \u2032 holds; 3) if \u03c8 \u2261 \u03c6 then \u2264\u03c8=\u2264\u03c6.\nA minimal interpretation may thus be defined by: M\u2286 I, the set of minimal interpretations inM according to \u2264\u03c8 is denoted Min(M,\u2264\u03c8). And I is minimal in M according to \u2264\u03c8, if I \u2208 M and there is no I \u2032 \u2208M such that I \u2032 <\u03c8 I.\nRevision operation * satisfies the postulates (KB*1) to (KB*6) and (KB*7.3) if and only if there exists a total pre-order \u2264\u03c8 such that:\nMod(\u03c8 \u2217 \u03c6) = Min(Mod(\u03c6),\u2264\u03c8).\nDefinition 12 (Selection function). Let KB be a Horn knowledge base. \u03b3 is a selection function for KB iff for all Horn clauses \u03b1\n1. If KB \u2193> \u03b1 , \u2205 then \u2205 , \u03b3(KB \u2193> \u03b1) \u2286 KB \u2193> \u03b1. 2. If KB \u2193> \u03b1 = \u2205 then \u03b3(KB \u2193> \u03b1) = {KB}\nObservation 1 Let KB, KB\u2019 be an Horn knowledge base, KB\u2019 be consistent. Suppose that \u03b1 \u2208 KB and \u03b1 \u2208 KB\u2032. Then \u03b1 \u2208 X for all X \u2208 KB \u2193> KB\u2032 and, therefore, \u03b1 \u2208 \u22c2 (KB \u2193> KB\u2032).\nFrom the above observation and definition 11 it follows that all the Horn knowledge base of KB\u2229\u03b1 are \u201dprotected\u201d, in the sense that they are included in the intersection of any collection of remainders. That is, a consolidated selection function selects a subset of the set KB \u2193> \u03b1 whose elements all contain the set KB \u2229 \u03b1.\nDefinition 13 (Partial meet revision). Let KB be a Horn knowledge base with an immutable part KBI and \u03b3 a selection function for KB. The partial meet revision on KB that is generated by \u03b3 is the operator \u2217\u03b3 such that, for all Horn clauses \u03b1:\nKB \u2217\u03b3 \u03b1 = { \u2229\u03b3(KB \u2193> \u03b1) \u222a \u03b1 if \u03b1 is consistent with KBI \u222aKBIC\nKB otherwise.\nAn operator * is a generalized revision (partial meet revision) on KB if and only if there is a selection function \u03b3 for KB such that for all Horn clauses \u03b1, KB*\u03b1 = KB\u2217\u03b3\u03b1.\nExample 3. Given KB={KBI : p\u2190 a \u2227 b, p\u2190 a, q \u2190 a \u2227 b; KBU : a\u2190, b\u2190; KBIC : \u2205}, \u03b1= \u2190 p and KB \u2193> \u03b1= {{p \u2190 a \u2227 b}, {p \u2190 a}, {\u2190 a}, {\u2190 b}}. We have two possible results for the selection function and its associated partial meet revision operator\n\u03b31(KB \u2193> \u03b1) = {\u2190 p} and KB \u2217\u03b31 \u03b1 = {p\u2190 a \u2227 b,\u2190 a,\u2190 b} \u03b32(KB \u2193> \u03b1) = {\u2190 p} and KB \u2217\u03b32 \u03b1 = {p\u2190 a,\u2190 a}\nThe partial meet revision on KB that is generated by \u03b32 gives minimal interpretation with respect to PMC.\nTheorem 5. For every Horn knowledge base KB, \u2217 is a generalized revision function iff it satisfies the postulates (KB*1) to (KB*6) and (KB*7.3).\nProof. (If part) * satisfies (KB*1) to (KB*6) and (KB*7.3). We must show that \u2217 is a generalized revision. When KBI ` \u03b1, (KB*1) to (KB*6) and (KB*7.3) imply that KB \u2217 \u03b1 = KB is coinciding with generalized revision.\nWhen KBI ` \u00ac\u03b1, the required result follows from the two observations: 1. \u2203KB\u2032 \u2208 KB \u2193> \u03b1 s.t.KB \u2217 \u03b1 \u2286 KB\u2032 (when KB \u2217 \u03b1 = KB \u222a {\u03b1})\nLet \u03b3 be an selection function for KB and \u2217\u03b3 be the generalized revision on KB that is generated by \u03b3. Since * satisfies closure (KB*1), KB \u2217\u03b3 \u03b1 is KB contained in \u03b1. Also, satisfaction of weak success postulate (KB*2) ensures that \u03b1 \u2286 KB\u2217\u03b3\u03b1. Every element of KB \u2193> \u03b1 is a inclusion maximal subset that does drive \u03b1, and so any subset of KB that does derive \u03b1 must be contained in a member of KB \u2193> \u03b1.\n2. \u22c2\n(KB \u2193> \u03b1) \u2286 KB \u2217\u03b3 \u03b1 (when KB \u2217 \u03b1 = KB \u222a {\u03b1}) Consider any \u03b2 \u2208 \u22c2 (KB \u2193> \u03b1). Assume that \u03b2 < KB \u2217 \u03b1. Since * satisfies weak relevance postulate (KB*7.3), it follows that there exists a set KB\u2019 s.t. KB\u2032 \u2286 KB \u222a \u03b1; KB\u2032 is consistent with \u03b1; and KB\u2032 \u222a {\u03b2} is inconsistent with \u03b1. But this contradicts the that \u03b2 is present in every maximal subset of KB that does derive \u03b1. Hence \u03b2 must not be in KB \u2217\u03b3 \u03b1.\n(Only if part) Let KB \u2217 \u03b1 be a generalized revision of \u03b1 for KB. We have to show that KB \u2217 \u03b1 satisfies the postulate (KB*1) to (KB*6) and (KB*7.3).\nLet \u03b3 be an selection function for KB and \u2217\u03b3 be the generalized revision on KB that is generated by \u03b3.\nClosure Since KB \u2217\u03b3 \u03b1 is a Horn knowledge base, this postulate is trivially shown. Weak Success Suppose that \u03b1 is consistent. Then it is trivial by definition that \u03b1 \u2286 KB \u2217\u03b3 \u03b1. Inclusion Since every X \u2208 KB \u2193> \u03b1 is such that X \u2286 KB then this postulate is trivially shown. Immutable-inclusion Since every X \u2208 KB \u2193> \u03b1 is such that X \u2286 KBI then this postulate is trivially shown. Vacuity 1 Trivial by definition. Vacuity 2 If KB\u222a{\u03b1} is consistent then KB \u2193> \u03b1 = {{KB}}. Hence KB \u2217\u03b3 \u03b1\n= KB \u222a {\u03b1}. Consistency Suppose that \u03b1 is consistent. Then KB \u2193> \u03b1 ,= \u2205 and by defini-\ntion, every X \u2208 KB \u2193> \u03b1 is consistent with \u03b1. Therefore, the intersection of any subset of KB \u2193> \u03b1 is consistent with \u03b1. Finally, KB \u2217\u03b3 \u03b1 is consistent. Uniformity If \u03b1 and \u03b2 are KB-equivalent, then KB \u2193> \u03b1 = KB \u2193> \u03b2 Weak relevance Suppose that KB \u2193> \u03b1 , \u2205. Let \u03b2 \u2208 KB. Then there is\nsome X \u2208 KB \u2193> \u03b1 such that \u03b2 < X. Therefore, there is some X such that \u03b2 < X \u2286 KB, X \u222a \u03b1 is consistent but X \u222a \u03b1 \u222a {\u03b2} is inconsistent. Suppose that KB \u2193> \u03b1 = {\u2205} in which case \u03b1 is inconsistent. By definition, KB \u2217\u03b3 \u03b1 = KB and weak relevance is vacuously satisfied."}, {"heading": "5.3 Horn knowledge base revision with hitting set", "text": "In this section, we show that Horn knowledge base revision has an interesting connection with kernel change via hitting set."}, {"heading": "Kernel revision system", "text": "To revise a Horn formula \u03b1 from a Horn knowledge base KB, the idea of kernel revision is to keep at least one element from every inclusion-minimal subset of KB that derives \u03b1. Because of the immutable-inclusion postulate, no Horn formula from KBI can be deleted.\nDefinition 14 (Kernel sets). Let a Horn knowledge base KB be a set of Horn formulae, where \u03b1 is Horn clause. The \u03b1-inconsistent kernel of KB, noted by KB\u22a5\u22a5\u03b1, is the set of KB\u2032 such that:\n1. KB\u2032 \u2286 KB ensuring that KBI \u2286 KB\u2032 and KBIC \u2286 KB\u2032. 2. KB\u2032 \u222a \u03b1 is inconsistent with KBI \u222aKBIC . 3. For any KB\u201d such that KB\u2032\u2032 \u2282 KB\u2032 \u2286 KB then KB\u2032\u2032\u222a\u03b1 is consistent with\nKBI \u222aKBIC .\nThat is, given a consistent \u03b1, KB\u22a5\u22a5\u03b1 is the set of minimal KB-subsets inconsistent with \u03b1.\nExample 4. Suppose that KB={KBI : p\u2190 a \u2227 b, p\u2190 a, q \u2190 a \u2227 b; KBU : a\u2190 , b\u2190; KBIC : \u2205} and \u03b1= \u2190 p. Then we have that:\nKB\u22a5\u22a5\u03b1= {{p\u2190 a \u2227 b}, {p\u2190 a}}.\nRevision by a Horn clause is based on the concept of a \u03b1-inconsistent-kernels. In order to complete the construction, we must define a incision function that cuts in each inconsistent-kernel.\nDefinition 15 (Incision function). Let KB be a set of Horn formulae. \u03c3 is a incision function for KB if and only if, for all consistent Horn clauses \u03b1\n1. \u03c3(KB\u22a5\u22a5\u03b1) \u2286 \u22c3 KB\u22a5\u22a5\u03b1 2. If KB\u2032 \u2208 KB\u22a5\u22a5\u03b1 then KB\u2032 \u2229 (\u03c3(KB\u22a5\u22a5\u03b1)) , 0\nDefinition 16 (Hitting set). A hitting set H for KB\u22a5\u22a5\u03b1 is defined as a set s.t. (i) H \u2286 \u22c3 (KB\u22a5\u22a5\u03b1), (ii) H\u2229KBI is empty and (iii) \u2200X \u2208 KB\u22a5\u22a5\u03b1, X , \u2205 and X \u2229KBU is not empty, then X \u2229H , \u2205.\nA hitting set is said to be maximal when H consists of all updatable statements from \u22c3 (KB\u22a5\u22a5\u03b1) and minimal if no proper subset of H is a hitting set for KB\u22a5\u22a5\u03b1.\nObservation 2 Let KB, KB\u2019 be an Horn knowledge base, KB\u2019 be consistent. Suppose that \u03b1 \u2208 KB and \u03b1 \u2208 KB\u2032. Then \u03b1 < \u22c3 (KB\u22a5\u22a5KB\u2032) and, therefore,\nKB\u2032 \u2229 \u22c3 (KB\u22a5\u22a5KB\u2032) = 0\nFrom the above observation and definition 15 it follows that all the Horn knowledge base of \u03b1 are \u201dprotected\u201d, in the sense that they can not be considered for removing by the consolidated incision function. That is, a consolidated incision function selects among the sentences of KB\\\u03b1 that make KB \u222a \u03b1 inconsistent.\nDefinition 17 (Generalized Kernel revision). An incision function for KB is a function s.t. for all \u03b1, \u03c3(KB\u22a5\u22a5\u03b1) is a hitting set for KB\u22a5\u22a5\u03b1. Generalized kernel revision on KB that is generated by \u03c3 is the operator \u2217\u03c3 such that, for all Horn clauses \u03b1:\nKB \u2217\u03c3 \u03b1 = {\n(KB\\\u03c3(KB\u22a5\u22a5\u03b1) \u222a \u03b1 if \u03b1 is consistent KBI \u222aKBIC KB otherwise.\nAn operator \u2217 is a generalized kernel revision for KB if and only if there is an incision function \u03c3 for KB such that for all Horn clauses \u03b1, KB \u2217\u03b1 = KB \u2217\u03c3 \u03b1.\nFrom the definition of hitting set, it is clear that when KB ` \u00ac\u03b1, \u03b1 is the hitting set of KB\u22a5\u22a5\u03b1. On the other hand, when KBI ` \u03b1, the definition ensures that only updatable elements are inserted, and \u03b1 does follow from the revision. Thus, weak success (KB*2), immutable-inclusion (KB*3.2) and vacuity (KB*4.1) are satisfied by generalized kernel revision of \u03b1 from KB.\nExample 5. Given KB={KBI : p \u2190 a \u2227 b, p \u2190 a, q \u2190 a \u2227 b; KBU : a \u2190, b \u2190 ; KBIC : \u2205 }, \u03b1= \u2190 p and KB\u22a5\u22a5\u03b1 = {{p \u2190 a \u2227 b}, {p \u2190 a}}. We have two possible results for the incision function and its associated kernel revision operator:\n\u03c31(KB\u22a5\u22a5\u03b1) = {p\u2190 a \u2227 b} and KB \u2217\u03c31 \u03b1 = {{\u2190 a}, {\u2190 b}}, \u03c32(KB\u22a5\u22a5\u03b1) = {p\u2190 a} and KB \u2217\u03c32 \u03b1 = {{\u2190 a}}.\nIncision function \u03c32 produces minimal hitting set for KB\u22a5\u22a5\u03b1.\nTheorem 6. For every Horn knowledge base KB, \u2217\u03c3 is a generalized kernel revision function iff it satisfies the postulates (KB*1) to (KB*6) and (KB*7.3).\nProof. (If part) * satisfies (KB*1) to (KB*6) and (KB*7.3). We must show that \u2217 is a generalized kernel revision. Let \u03c3 be a incision function and \u03b1 Horn formula. When KBI ` \u03b1, (KB*1) to (KB*6) and (KB*7.3) imply that KB \u2217 \u03b1 = KB coincides with generalized revision and follow PMC.\nWhen KBI ` \u00ac\u03b1, the required result follows from the two observations:\n1. \u2203KB\u2032 \u2208 KB\u22a5\u22a5\u03b1 s.t.KB \u2217 \u03b1 \u2286 KB\u2032 (when KBI ` \u03b1) Let \u03c3 be an incision function for KB and \u2217\u03c3 be the generalized revision on KB that is generated by \u03c3. Since * satisfies closure (KB*1), KB \u2217\u03c3 \u03b1 is KB contained in \u03b1. Also, satisfaction of weak success postulate (KB*2) ensures that \u03b1 \u2286 KB \u2217\u03c3 \u03b1. Every element of KB\u22a5\u22a5\u03b1 is a inclusion minimal subset that does derive \u03b1, and so any subset of KB that does derive \u03b1 must be contained in a member of KB\u22a5\u22a5\u03b1.\n2. \u22c2\n(KB\u22a5\u22a5\u03b1) \u2286 KB \u2217\u03c3 \u03b1 (when KBI ` \u03b1) Consider any \u03b2 \u2208 \u22c2 (KB\u22a5\u22a5\u03b1). Assume that \u03b2 < KB \u2217 \u03b1. Since * satisfies weak relevance postulate (KB*7.3), it follows that there exists a set KB\u2019 s.t. KB\u2032 \u2286 KB \u222a \u03b1; KB\u2032 is a consistent with \u03b1; and KB\u2032 \u222a {\u03b2} is inconsistent with \u03b1. But this contradicts that \u03b2 is present in every minimal subset of KB that does derive \u03b1. Hence \u03b2 must not be in KB \u2217\u03c3 \u03b1.\n(Only if part) Let KB \u2217 \u03b1 be a generalized revision of \u03b1 for KB. We have to show that KB \u2217 \u03b1 satisfies the postulate (KB*1) to (KB*6) and (KB*7.3).\nLet \u03c3 be an incision function for KB and \u2217\u03c3 be the generalized revision on KB that is generated by \u03c3.\nClosure Since KB \u2217\u03c3 \u03b1 is a Horn knowledge base, this postulate is trivially shown. Weak Success Suppose that \u03b1 is consistent. Then it is trivial by definition that \u03b1 \u2286 KB \u2217\u03c3 \u03b1. Inclusion Trivial by definition. Immutable-inclusion Since every X \u2208 KB\u22a5\u22a5\u03b1 is such that X \u2286 KBI then\nthis postulate is trivially shown. Vacuity 1 Trivial by definition.\nVacuity 2 If KB \u222a{\u03b1} is consistent then KB\u22a5\u22a5\u03b1 = {{KB}}. Hence KB \u2217\u03c3 \u03b1 = KB \u222a {\u03b1}. Consistency Suppose that \u03b1 is consistent. Then KB\u22a5\u22a5\u03b1 ,= \u2205 and by definition, every X \u2208 KB\u22a5\u22a5\u03b1 is consistent with \u03b1. Therefore, the intersection of any subset of KB\u22a5\u22a5\u03b1 is consistent with \u03b1. Finally, KB \u2217\u03c3 \u03b1 is consistent. Uniformity If \u03b1 and \u03b2 are KB-equivalent, then KB\u22a5\u22a5\u03b1 = KB\u22a5\u22a5\u03b2 Weak relevance Let \u03b2 \u2208 KB and \u03b2 < KB \u2217\u03c3 \u03b1. Then KB \u2217\u03c3 \u03b1 , KB and,\nfrom the definition of \u2217\u03c3,it follows that:\nKB \u2217\u03c3 \u03b1=(KB\\\u03c3(KB\u22a5\u22a5\u03b1)) \u222a \u03b1\nTherefore, from \u03b2 < (KB\\\u03c3(KB\u22a5\u22a5\u03b1)) \u222a \u03b1 and \u03b2 \u2208 KB, we can conclude that \u03b2 \u2208 \u03c3(KB\u22a5\u22a5\u03b1). By definition \u03c3(KB\u22a5\u22a5\u03b1) \u2286 \u22c3 KB\u22a5\u22a5\u03b1, and it follows that there is some X \u2208 KB\u22a5\u22a5\u03b1 such that \u03b2 \u2208 X. X is a minimal KB-subset inconsistent with \u03b1. Let Y = X\\{\u03b2}. Then Y is such that Y \u2282 X \u2286 KB \u2286 KB \u222a \u03b1. Y is consistent with \u03b1 but Y \u222a {\u03b2} is consistent with \u03b1.\nFrom the Theorem 5 and 6, it immediately follows that a revision operation on a Horn knowledge base is a generalized kernel revision iff it is a generalized revision. The following theorem formalizes this with additional insights into the relationship between kernel and generalized revisions.\nTheorem 7.\n1. A revision operation over a Horn knowledge base KB is a generalized kernel revision over KB iff it is a generalized revision over KB. 2. When the incision function \u03c3 is minimal, i.e. the hitting set defined by \u03c3 is inclusion-minimal, then the generalized kernel revision defined by \u03c3 is a partial meet revision of \u03b1 from KB. 3. When the incision function \u03c3 is maximal, i.e. \u03c3(KB\u22a5\u22a5\u03b1) consists of all updatable statements from \u22c3 (KB\u22a5\u22a5\u03b1), then the kernel contraction defined\nby \u03c3 is the minimal generalized revision of \u03b1 from KB.\nProof. Follows from the Definition 16, Theorem 5 and 6"}, {"heading": "6 Knowledge base dynamics and abduction", "text": "In this Section, we study the relationship between Horn knowledge base dynamics, discussed in the previous Section, and abduction that was introduced by the philosopher Peirce (see Aliseda 2006, Boutilier & Beche 1995 and Pagnucco 1996). We show how an abduction grammar could be used to realize revision with an immutability condition. A special subset of literals (atoms) of language LH, abducibles Ab, are designated for abductive reasoning. Our work is based on atoms (literals), so we combine Christiansen and Dahl (Christiansen & Dahl 2009) grammars approach. Simply, we want to compute abducibles for Horn knowledge base (Horn or Horn logic with stratified negation).\nExample 6. Consider a Horn logic with stratified negation knowledge base KB with immutable part KBI , updatable part KBU and integrity constraint KBIC .\nKBI : flies(x)\u2190 bird(x), not ab(x), KBU :bird(tweety)\u2190 KBIC : \u2205 ab(x)\u2190 broken wing(x) bird(opus)\u2190\nbroken wing(tweety)\u2190\nIf we observe that tweety flies, there is a good reason to assume that the wound has already healed. Then, removing the fact broken wing(tweety) from the KB explains the observation flies(tweety). On the other hand, suppose that we later notice that opus does not fly anymore. Since flies(opus) is entailed by KBI , we now have to revise the Horn knowledge base to block the derivation of flies(opus) by assuming, for instance, broken wing(opus). In nonmonotonic theories, deletion of formulae may introduce new formulae, thus positive (\u2206+) and negative (\u2206\u2212) explanations play a complementary role in accounting for an observation in nonmonotonic theories. (more explanation in Sakama & Inoue 2003)\nDefinition 18 (Abductive grammar). A abductive grammar \u0393 is a 6-tuple \u3008N,T, IC, KB,R, S\u3009 where:\n- N are nonterminal symbols in the immutable part (KBI). - T is a set of terminal symbols in the updatable part (KBU ). - IC is the set of integrity constraints for the Horn knowledge base (KBIC). - KB is the Horn knowledge base which consists of KB = KBI\u222aKBU\u222aKBIC . - R is a set of rules, R \u2286 KB. - S is the revision of literals (atoms), called the start symbol.\nExample 7. Consider a Horn knowledge base KB (with immutable part KBI , updatable part KBU and integrity constraint KBIC) and a Horn clause \u03b1 (p is \u03b1) be revise.\nKBI : p\u2190 q \u2227 a KBU : a\u2190 KBIC :\u2190 b p\u2190 r \u2227 b r \u2190 q \u2190 c \u2227 d r \u2190 e \u2227 f p\u2190 b\nKB be a Horn knowledge base, represented by the grammar (\u0393 = \u3008N,T,KB,R, S\u3009) as follows:\nN={p} T={a,b,c,d,e,f,q,r} IC={b} KB=KBI \u222aKBU \u222aKBIC R={p\u2190 q, a; p\u2190 r, b; q \u2190 c, d; r \u2190 e, f ; p\u2190 b; a; r}\nS={p}\nDefinition 19 (Constraint system). A constraint system for abduction is a pair \u3008KBAb, KBBG\u3009, where KBAb(\u2206) is a set of propositions (abducibles) and KBBG a background Horn knowledge base.\nNote 2. In the sequel, without any loss of generality, we assume that KBI is a set of rules and KBU is a set of abducibles from Horn knowledge base perspective. With respect to the considered grammars, KBBG is a set all Horn formulae from R and KBAb is set of abducibles from T.\nNote 3. Given a Horn knowledge base KB and a Horn clause \u03b1, the problem of abduction is to explain \u03b1 in terms of an abduction, i.e. to generate a set of abducibles KBAb, \u2206 s.t. KBBG \u222a\u2206 ` \u03b1.\nDefinition 20 (Minimal abductive explanation). Let KB be a Horn knowledge base and \u03b1 an observation to be explained. Then, for a set of abducibles (KBAb), \u2206 is said to be an abductive explanation with respect to KBBG iff KBBG \u222a \u2206 ` \u03b1. \u2206 is said to be minimal with respect to KBBG iff no proper subset of \u2206 is an abductive explanation for \u03b1, i.e. @\u2206\u2032 s.t. KBBG \u222a\u2206\u2032 ` \u03b1.\nSince an incision function is adding and removing only updatable elements from each member of the kernel set, to compute a generalized revision of \u03b1 from KB, we need to compute only the abduction in every \u03b1-kernel of KB. So, it is now necessary to characterize precisely the abducibles present in every \u03b1-kernel of KB. The notion of minimal abductive explanation is not enough to capture this, and we introduce locally minimal and KB-closed abductive explanations explanations.\nDefinition 21 (Local minimal abductive explanations). Let KBBG\u2032 be a subset of KBBG, s.t \u2206 is a minimal abductive explanation of \u03b1 with respect to KBBG\u2032 (for some \u2206). Then \u2206 is called local minimal for \u03b1 with respect to KBBG.\nExample 8. From example 7, suppose {p \u2190 q \u2227 a, p \u2190 a}, where a and f are abducibles in the grammar system R. Clearly, \u22061 = {a} is the only minimal abductive explanation for p with respect to R. \u22062 = {a, q} is an abductive explanation for p with respect to R, but not a minimal one. However, \u22062 is a locally minimal abductive explanation for p with respect to R, since it is a minimal explanation for p with respect to {p\u2190 q \u2227 a} which is a subset of R.\nThe concept of locally minimal abductive explanation is computationally attractive, since minimal abductive explanation is more expensive to compute (Aravindan 1995). To find a minimal admissible and denial literal (atom) from KBAb that is positive and negative literal (atom) from KBAb, we need to introduce a constraint system (C) with integrity constraint (IC).\nDefinition 22 (Constraint abduction system). A constrained abductive grammar is a pair \u3008\u0393,C\u3009, where \u0393 is an abductive grammar and C a constraint system for abduction, \u0393=\u3008N,T,R, S\u3009 and C=\u3008KBBG,KBAb, IC\u3009.\nGiven a constrained abductive grammar \u3008\u0393,C\u3009 as above, the constrained abductive recognition problem for \u03c4 \u2208 T \u2217 is the problem of finding an admissible and denial knowledge base (Horn knowledge base contained set of positive and negative literal (atoms)) from KBAb and such that \u03c4 \u2208 LP (\u0393KBAb) where LP (\u0393KBAb) is propositional language over abducibles in \u0393 , where \u0393KBAb = \u3008N,T,KBBG \u222aKBAb, R, S\u3009. In this case, KBAb is called a constrained (abductive) system of \u03c4 . Such that KBAb is minimal whenever no proper subset of it is in \u03c4 given \u3008\u0393,C\u3009.\nExample 9. We extend example 7, in order to show that C is constraint system C, with C =\u3008KBBG,KBAb, IC\u3009\nKBBG = {p\u2190 q, a; p\u2190 r, b; q \u2190 c, d; r \u2190 e, f ; p\u2190 b; a; r} KBAb = {a, b, c, d, e, f, q, r} IC ={\u2190 b}\nNote 4. Let KBAb \u2208 ({\u2206+, \u2206\u2212}). Here \u2206+ refers to admission Horn knowledge base (positive atoms) and \u2206\u2212 refers to denial Horn knowledge base (negative atoms) with respect to given \u03b1. The abduction problem is to explain \u2206 with abducibles (KBAb), s.t. KBBG \u222a\u2206+ \u222a\u2206\u2212 |= \u03b1 and KBBG \u222a\u2206+ |= \u03b1\u222a\u2206\u2212 are both consistent with IC.\nAn admission and denial Horn knowledge base, based on \u3008KBBG,KBAb\u3009 is a set KBAb of atoms (literals) whose propositions are in KBAb such that KBBG \u222aKBAb is consistent with IC.\nExample 10. From Example 9 and Note 4, the constraint system C, with C =\u3008KBBG,KBAb, IC\u3009\nKBBG = {p\u2190 q, a; p\u2190 r, b; q \u2190 c, d; r \u2190 e, f ; p\u2190 b; a; r} KBAb = {\u2206+ = {a, c, d, e, f, q, r} and \u2206\u2212 = {a, b, r}} IC ={\u2190 b}\nDefinition 23 (KB-closed abductive explanations). For a set of abducibles (KBAb), \u2206+ and \u2206\u2212 are said to be closed abductive explanations with respect to KBBG iff KBBG \u222a \u2206+ \u222a \u2206\u2212 |= \u03b1 and KBBG \u222a \u2206+ |= \u03b1 \u222a \u2206\u2212. \u2206+ and \u2206\u2212 are said to be minimal with respect to KBBG iff no proper subset of \u2206+ and \u2206\u2212 is an abductive explanation for \u03b1, i.e. @\u2206+ \u2032 ( \u2206+ and @\u2206\u2212 \u2032\n( \u2206\u2212 s.t. KBBG \u222a\u2206+ \u2032 \u222a\u2206\u2212 \u2032 |= \u03b1 and KBBG \u222a\u2206+ \u2032 |= \u03b1\u222a\u2206\u2212 \u2032 both consistent with IC.\nKB-closed abductive explanations are also known as KB-closed local minimal explanations.\nObservation 3 Let KBBG\u2032 be a smallest subset of KBBG s.t, \u2206+ and \u2206\u2212 minimal abductive explanations of \u03b1 with respect to KBAb\u2032 and KBBG\u2032 (for some \u2206+ and \u2206\u2212). Then \u2206+ and \u2206\u2212 are called locally minimal for \u03b1 with respect to KBAb\u2032 and KBBG and consistent with IC.\nExample 11. \u2206+ = {a, c, d} and \u2206\u2212 = {c} with respect to IC are only locally minimal abductive explanations for p with respect to KBBG\u2032 (more explanations can be found in (Lu W 1999)).\nFrom example 10 and definition 23, we want to show that the constraint system C, with C =\u3008KBBG,KBAb, IC\u3009\nKBBG = {p\u2190 q, a; q \u2190 c, d; a; c; d} KBAb = {\u2206+ = {a, c, d} and \u2206\u2212 = {b, r}} and IC ={\u2190 b}\nNow, we need to connect the grammar system \u0393 to the Horn (stratified) knowledge base KB, such that KBI \u222a KBU \u222a KBIC = KBBG \u222a KBAb \u222a IC holds. The connection between locally minimal abductive explanation for \u03b1 with respect to KBI and \u03b1-kernel of KB, which is shown by the following lemma immediately follows from their respective definitions.\nObservation 4\n1. Let KB be a Horn (stratified) knowledge base and \u03b1 a Horn clause s.t. 0 \u00ac\u03b1. Let \u2206+ and \u2206\u2212 be a KB-closed locally minimal abductive explanation for \u03b1 with respect to KBI . Then, there exists an \u03b1-kernel X of KB s.t. X\u2229KBU = \u2206+ \u222a\u2206\u2212. 2. Let KB be a Horn (Horn logic with stratified negation) knowledge base and \u03b1 a Horn clause s.t. 0 \u00ac\u03b1. Let X be a \u03b1-kernel of KB and \u2206+\u222a\u2206\u2212 = X\u2229KBU . Then, \u2206+ and \u2206\u2212 are KB - closed locally minimal abductive explanations for \u03b1 with respect to KBI .\nProof.\n1. The fact that 0 \u00ac\u03b1 and there exists a KB - closed locally minimal abductive explanation for \u03b1 with respect to KBI , it is clear that there exists at least one \u03b1- kernel of KB. Suppose \u2206 (\u2206 \u2208 \u2206+ \u222a\u2206\u2212) is empty (i.e. KBI |= \u00ac\u03b1), then the required result follows immediately. If not, since \u2206 is a locally minimal abductive explanation, there exists a minimal subset KB\u2032I \u2286 KBI , s.t. \u2206 is minimal abductive explanation of \u03b1 with respect to KB\u2032I . Since, \u2206 is KB-closed, it is not difficult to see that KB\u2032I \u222a\u2206+ \u222a\u2206\u2212 is a \u03b1 - kernel of KB. 2. Since X is a \u03b1 - kernel of KB and \u2206 is the set of all abducibles in X, it follows that \u2206+ \u222a\u2206\u2212 is a minimal abductive explanation of \u2206 with respect to X\\\u2206\u2212 \u222a \u2206+. It is obvious that \u2206+ \u222a \u2206\u2212 is KB- closed, and so \u2206 is a KB-closed locally minimal abductive explanation for \u03b1 with respect to KBI .\nTheorem 8. Consider a constrained abductive grammar AG = \u3008\u0393,C\u3009 with \u0393 = \u3008N,T,KB,R, S\u3009 and C = \u3008KBBG,KBAb, IC\u3009. Construct a abductive grammar \u2206(AG) = \u3008N,T,KBBG, R, S\u3009 by having, for any (\u2206+) (or) (\u2206\u2212) from KBAb, the set of acceptable results for accommodate (\u03b1,KBBG \u2208 \u2206+) being of the form (KBAb\\\u2206+) where (\u2206+ \u2208 KBAb\u2032). \u2206+ is a locally minimal set of atoms (literals) KBBG\u222a\u2206+ and KBBG\u222a\u2206+ |= \u03b1 is consistent with IC; if (\u2206\u2212) exists procedure is similar, (like denial (\u2206\u2212) being of the form (KBAb\\\u2206\u2212). \u2206\u2212 is a locally minimal set of atoms (literals) KBBG \u222a \u2206\u2212 and KBBG \u222a \u2206\u2212 |= \u03b1 is consistent with IC), otherwise accommodate (\u03b1,KBBG \u2208 \u2206\u2212) is not possible.\nProof. From Observation 3, Let KBBG\u2032 be a smallest subset of KBBG s.t, \u2206+ and \u2206\u2212 minimal abductive explanations of \u03b1 with respect to KBAb\u2032 and KBBG\u2032 (for some \u2206+ and \u2206\u2212). Then \u2206+ and \u2206\u2212 are called locally minimal for \u03b1 with respect to KBAb\u2032 and KBBG and consistent with IC.\nFrom Observation 4, (\u2206\u2212) is follow to the kernel of KB and \u2206 is the set of all abducibles in (\u03b1,KBBG \u2208 \u2206+), it follows that \u2206+ \u222a\u2206\u2212 is a minimal abductive explanation of \u2206 with respect to KB\\\u2206\u2212 \u222a\u2206+. It is obvious that \u2206+ \u222a\u2206\u2212 is KB- closed, and so \u2206 is a KB-closed locally minimal abductive explanation for \u03b1 with respect to KBI .\n(\u2206\u2212) is not follow from KB - closed locally minimal abductive explanation for \u03b1 with respect to KBI , it is clear that there exists at least one \u03b1- kernel of KB.\nAn immediate consequence of the above observation 4 is that it is enough to compute all the KB-closed locally minimal abductive explanations for \u03b1 with respect to KBI in order to revise \u03b1 from KB. Thus, a well-known abductive procedure to compute an abductive explanation for \u03b1 with respect to KBI could be used:\nTheorem 9. Let KB be a Horn (stratified) knowledge base and \u03b1 a Horn clause.\n1. If Algorithm 1 produces KB\u2032 as a result of revision \u03b1 to KB, then KB\u2032 is a generalized revision of \u03b1 from KB. 2. If KB\u2032 is a generalized revision of \u03b1 from KB, then there exists an incision function \u03c3 s.t. KB\u2032 is produced by Algorithm 1 as a result of revision \u03b1 from KB, using \u03c3.\nProof. Follows from Observation 4 and Theorem 7"}, {"heading": "6.1 Generalized revision algorithm", "text": "The problem of Horn knowledge base revision is concerned with determining how a request to change can be appropriately translated into one or more atoms or literals. In this section we develop a new generalized revision algorithm. Note that it is enough to compute all the KB-locally minimal abduction explanations for \u03b1 with respect to KBI \u222a KBU \u222a KBIC . If \u03b1 is consistent with KB then a well-known abductive procedure for compute an abductive explanation for \u03b1\nwith respect to KBI could be used to compute kernel revision.\nAlgorithm 1 Generalized revision algorithm Input : A Horn knowledge base KB = KBI \u222aKBU \u222aKBIC\nand a Horn clause \u03b1 to be revised. Output: A new Horn knowledge base KB\u2032 = KBI \u222aKB\u2217U \u222aKBIC ,\ns.t. KB\u2032is a generalized revision \u03b1 to KB. Procedure KB(KB,\u03b1)\nbegin 1. Let V:= {c \u2208 KBIC | KBI \u222aKBIC inconsistent with \u03b1 with respect to c}\nP := N := \u2205 and KB\u2032 = KB 2. While (V , \u2205)\nselect a subset V \u2032 \u2286 V For each v \u2208 V \u2032, select a literal to be\nremove (add to N) or a literal to be added (add to P) with respect to KB Let KB := KR(KB,P,N)\nLet V:= {c \u2208 KBIC | KBI inconsistent with \u03b1 with respect to c} return\n3. Produce a new Horn knowledge base KB\u2032 end.\nProcedure KR(KB,\u2206+, \u2206\u2212) begin\n1. Let P := {e \u2208 \u2206+| KBI 6|= e} and N := {e \u2208 \u2206\u2212| KBI |= e} 2. While (P , 0) or (N , 0)\nselect a subset P \u2032 \u2286 P or N \u2032 \u2286 N Construct a set S1 = {X | X is a KB-closed locally\nminimal abductive wrt P explanation for \u03b1 wrt KBI}. Construct a set S2 = {X | X is a KB-closed locally\nminimal abductive wrt N explanation for \u03b1 wrt KBI}. 3. Determine a hitting set \u03c3(S1) and \u03c3(S2)\nIf ((N = 0) and (P , 0)) Produce KB\u2032 = KBI \u222a {(KBU \u222a \u03c3(S1)} else Produce KB\u2032 = KBI \u222a {(KBU\\\u03c3(S2) \u222a \u03c3(S1)} end if If ((N , 0) and (P = 0)) Produce KB\u2032 = KBI \u222a {(KBU\\\u03c3(S2)} else Produce KB\u2032 = KBI \u222a {(KBU\\\u03c3(S2) \u222a \u03c3(S1)} end if\n4. return KB\u2032 end."}, {"heading": "Reasoning about Abduction", "text": "Definition 24 ((Teniente & Olive 1995)). Let KB=(KBI ,KBU ,KBIC) be a Horn knowledge base, T is updatable part from KB. We define the abduction framework \u3008KBBG,KBAb, IC\u3009. After Algorithm 1 is executed, u is derived part from KB\u2032. The abduction explanation for u in \u3008KBI \u222aKB\u2217U ,KBIC\u3009 is any set Ti, where Ti \u2286 KBAb such that: KBI \u222aKB\u2217U \u222a T |= u.\nAn explanation Ti is minimal if no proper subset of Ti is also an explanation, i.e. if it does not exist any explanation Tj for u such that Tj \u2282 Ti"}, {"heading": "Reasoning about Deduction", "text": "Definition 25 ((Teniente & Olive 1995)). Let KB=(KBI ,KBU ,KBIC) be a Horn knowledge base, T is updatable part from KB. After Algorithm 1 is executed, u is derived part from KB\u2032. The deduction consequence on u due to the application of T , KBI \u222aKB\u2217U \u222a T \u222a u is the answer to any question.\nExample 12. Consider a Horn knowledge base KB with immutable part KBI , updatable part KBU and integrity constraint KBIC , compute closed local minimum with respect to to p.\nKBI : p\u2190 q \u2227 a KBU : a\u2190 KBIC :\u2190 b p\u2190 r \u2227 b r \u2190 q \u2190 c \u2227 d r \u2190 e \u2227 f p\u2190 b\nFrom algorithm 1, the above example execute following steps:\nStep number with execution\n(Input) KBI : p\u2190 q \u2227 a, p\u2190 r \u2227 b, q \u2190 c \u2227 d, r \u2190 e \u2227 f, p\u2190 b KBU : a\u2190, r \u2190 KBIC :\u2190 b\n(0) {p\u2190 q, a; p\u2190 r, b; q \u2190 c, d; r \u2190 e, f ; p\u2190 b; a; r} (1) {V = b} (2) {P = {a, c, d, e, f, q, r} and N = {a, r}}\n(2.1) {\u2206+ = {a, c, d, e, f, q, r} and \u2206\u2212 = {a, r}} (2.2) {\u2206+ = {a, c, d} and \u2206\u2212 = {}}\n(3) {p\u2190 q, a; q \u2190 c, d; a; c; d; r} (Output) KBI : p\u2190 q \u2227 a, p\u2190 r \u2227 b, q \u2190 c \u2227 d, r \u2190 e \u2227 f, p\u2190 a, p\u2190 b\nKB\u2217U : a\u2190, c\u2190, d\u2190, r \u2190 KBIC :\u2190 b\nTheorem 10. Let KB be a Horn knowledge base and \u03b1 is (Horn or Horn logic with stratified negation) formula.\n1. If Algorithm 1 produced KB\u2019 as a result of revising \u03b1 from KB, then KB\u2019 satisfies all the rationality postulates (KB*1) to (KB*6) and (KB*7.3).\n2. Suppose KB\u2032\u2032 satisfies all these rationality postulates for revising \u03b1 from KB, then KB\u2032\u2032 can be produced by Algorithm 1.\nProof. Follows from Theorem 6 and Theorem 9"}, {"heading": "7 Belief update VS Knowledge base update", "text": "In this section we give overview of how belief update is related to knowledge base update. This section is motivated by the works of Konieczny 2011 and Baral & Zhang 2005."}, {"heading": "7.1 Belief revision vs Belief update", "text": "Intuitively, revision operators bring a minimal change to the base by selecting the most plausible models among the models of the new information. Whereas update operators Konieczny 2011 bring a minimal change to each possible world (model) of the base in order to take into account the change described by the new information, whatever the possible world.\nTheorem 11 ([29]). If \u25e6 is a revision operator (i.e. it satisfies (R1)-(R6)), then the update operator defined by \u03c8 \u00b5 = \u2228 w|=\u03c8 \u03c8{w} \u25e6 \u00b5 is an update operator that satisfies (U1)-(U9).\nThis theorem states that update can be viewed as a kind of pointwise revision."}, {"heading": "7.2 Knowledge base revision vs Knowledge base update", "text": "Generalized revision algorithm brings principle of minimal change, according to new information; how a request to change Horn knowledge base can be appropriately translated into one or more literals. Whereas update operators (Baral & Zhang 2005). bring a minimal change to each possible world (model) of the base in order to take into account the change described by the new information.\nTheorem 12 ([3]). If \u2217\u03c3 is a revision operator (i.e. it satisfies (KB*1)-(KB*6) and (KB*7.3) and Theorem 9 and Lemma 4), then the update operator defined by \u03c8 \u00b5 = \u2228 w|=\u03c8 \u03c8{w} \u2217\u03c3 \u00b5 is an update operator that satisfies (U1)-(U9)."}, {"heading": "7.3 Belief update vs Knowledge base update", "text": "Formally speaking, both updates are aiming at maintaining the base of the knowledge or belief up-to-date.\nTheorem 13. If \u25e6 are revision operators (i.e. they satisfy (R1)-(R6)), then the update operator defined by \u03c8 \u00b5 = \u2228 w|=\u03c8 \u03c8{w} \u25e6 \u00b5 is an update operator that satisfies (U1)-(U9)."}, {"heading": "8 Deductive database", "text": "A Deductive database DDB consists of three parts: an intensional database IDB (KBI), a set of definite program clauses, extensional database EDB (KBU ), a set of ground facts; and integrity constraints IC. The intuitive meaning of DDB is provided by the Least Herbrand model semantics and all the inferences are carried out through SLD-derivation. All the predicates that are defined in IDB are referred to as view predicates and those defined in EDB are referred to as base predicates. Extending this notion, an atom with a view predicate is said to be a view atom, and similarly an atom with base predicate is a base atom. Further we assume that IDB does not contain any unit clauses and no predicate defined in a given DDB is both view and base.\nTwo kinds of view updates can be carried out on a DDB: An atom, that does not currently follow from DDB, can be inserted, or an atom, that currently follows from DDB can be deleted. When an atom A is to be updated, the view update problem is to insert or delete only some relevant EDB facts, so that the modified EDB together with IDB will satisfy the update of A to DDB.\nNote that a DDB can be considered as a Horn knowledge base to be revised. The IDB is the immutable part of the Horn knowledge base dynamics, while the EDB forms the updatable part. In general, it is assumed that the language underlying a DDB is fixed and the semantics of DDB is the least Herbrand model over this fixed language. We assume that there are no function symbols implying that the Herbrand Base is finite. Therefore, the IDB is practically a shorthand of its ground instantiation 3 written as IDBG. In the sequel, technically we mean IDBG when we refer simply to IDB. Thus, a DDB represents a Horn knowledge base dynamics where the immutable part is given by IDBG and updatable part is the EDB. Hence, the rationality postulates (KB*1)-(KB*6) and (KB*7.3) provide an axiomatic characterization for updating (insert and delete) a view atom A into a definite database DDB.\nBut before discussing the rationality postulates and algorithm, we want to make it precise, how a relational database, along with operations on relations,\n3 a ground instantiation of a definite program P is the set of clauses obtained by substituting terms in the Herbrand Universe for variables in P in all possible ways\ncan be represented by definite deductive database. We assume the reader is familiar with relational database concepts. A relation scheme R can be thought of as a base predicate whose arguments define the attributes A of the scheme. Its relational extension r, is a finite set of base atoms R(A) containing the predicate R. A database schema consists of finite collection of relational schemes < R1, . . . , Rn >, and a relational database is a specific extension of database schema, denoted as < r1, . . . , rn >. In our context, relational database can be represented by EDB = \u22c3 i=1,...,nRi(Ai).\nJoin is a binary operator for combining two relations. Let r and s be two relational extensions of schema R (with attributes R) and S (with attributes S), respectively. Let T = R \u222a S. The join of r and s, written as r \u2297 s, is the relational extension q(T) of all tuples t over T such that there are tr \u2208 r and ts \u2208 s, with tr = t(R) and ts = t(S). Join can be captured by a constraint clause Q(T)\u2190 R(R), S(S).\nLet us consider two relational schemes R and S from Example 1, with attributes R={Group,Chair} and S={Staff,Group}.Consider the following extensions r and s: (see definition and properties of similarity in works of Christiansen (Christiansen & Rekouts 2007) and Godfrey (Godfrey et al. 1998)).\nThe following rule, T(Staff,Group,Chair)\u2190 S(Staff,Group),R(Group,Chair) represents the join of s and r, which is given in Table 5.2:\nOur first integrity constraint (IC) is that each research group has only one chair ie. \u2200x, y, z (y=z) \u2190 group chair(x,y) \u2227 group chair(x,z). Second integrity constraint is that a person can be a chair for only one research group ie. \u2200x, y, z (y=z)\u2190 group chair(y,x) \u2227 group chair(z,x).\nAn update request U = A, where A is a set of base facts that are not true in KB. Then, we need to find a transaction T = Tins \u222a Tdel, where Tins(\u2206i) (resp.\nTdel(\u2206j)) is the set of facts, such that U is true in DDB\u2032 = ((EDB \u2212 Tdel \u222a Tins)\u222a IDB \u222a IC). Since we consider stratifiable (definite) deductive databases, SLD-trees can be used to compute the required abductive explanations. The idea is to get all EDB facts used in a SLD-derivation of A with respect to DDB, and construct that as an abductive explanation for A with respect to IDBG.\nTraditional methods translate a view update request into a transaction combining insertions and deletions of base relations for satisfying the request (Mota-Herranz et al. 2000). Furthermore, a stratifiable (definite) deductive database can be considered as a knowledge base, and thus the rationality postulates and insertion algorithm from the previous section can be applied for solving view update requests in deductive databases.\nThere are two ways to find minimal elements (insertion and deletion) in the presence of integrity constraints. Algorithm 2 first checks consistency with integrity constraints and then reduces steps with abductive explanation for A . Algorithm 3 is doing vice versa, but both algorithm outputs are similar.\nAlgorithm 2 Algorithm to compute all DDB-closed locally minimal abductive explanation of an atom(literals)\nInput : A definite deductive database DDB = IDB \u222a EDB \u222a IC an literals A\nOutput : Set of all DDB-closed locally minimal abductive explanations for A wrt IDBG\nbegin 1. Let V := {c \u2208 IC | IDB \u222a IC inconsistent with A wrt c }\nWhile (V , 0) Construct a complete SLD-tree for\u2190 A wrt DDB.\nFor every successful branch i: construct \u2206i = {D | D \u2208 EDB and D is used as an input clause in branch i} For every unsuccessful branch j: construct \u2206j = {D | D \u2208 EDB and D is used as an input clause in branch j}\nProduce set of all \u2206i and \u2206j computed in the previous step as the result. return\n2. Produce all DDB-closed locally minimal abductive explanations in \u2206i and \u2206j\nend.\nHorn knowledge base revision algorithm 1, may be applied to compute all DDB-closed locally minimal abductive explanation of an atom (literals). Unfortunately, this algorithm does not work as intended for any deductive database, and a counter example is produced below. Thus, general algorithms 2 and 3 produced some unexpected sets in addition to locally minimal abductive explanations\nAlgorithm 3 Algorithm to compute all DDB-closed locally minimal abductive explanation of an atom(literals)\nInput : A definite deductive database DDB = IDB \u222a EDB \u222a IC an literals A\nOutput : Set of all DDB-closed locally minimal abductive explanations for A wrt IDBG\nbegin 1. Construct a complete SLD-tree for\u2190 A wrt DDB.\nFor every successful branch i: construct \u2206i = {D | D \u2208 EDB and D is used as an input clause in branch i} For every unsuccessful branch j: construct \u2206j = {D | D \u2208 EDB and D is used as an input clause in branch j}\n2. Let V := {c \u2208 IC | IDB \u222a IC inconsistent with A wrt c } While (V , 0)\nProduce set of all \u2206i and \u2206j is consistent with IC as the result. return Produce all DDB-closed locally minimal abductive explanations in \u2206i and \u2206j\nend.\nExample 14. Consider a stratifiable (definite) deductive database DDB as follows:"}, {"heading": "IDB : p\u2190 a \u2227 e EDB : e\u2190 IC :\u2190 b", "text": "q \u2190 a \u2227 f f \u2190 p\u2190 b \u2227 f q \u2190 b \u2227 e p\u2190 q q \u2190 a\nSuppose we want to insert p. First, we need to check consistency with IC and afterwards, we have to find \u2206i and \u2206j via tree deduction.\n(Input) IDB : p\u2190 a \u2227 e, q \u2190 a \u2227 f, p\u2190 b \u2227 f, q \u2190 b \u2227 e, p\u2190 q, q \u2190 a EDB : e\u2190, f \u2190 IC :\u2190 b\n(0) {p\u2190 a, e; q \u2190 a, f ; p\u2190 b, f ; q \u2190 b, e; p\u2190 q; q \u2190 a; e; f} (1) {V = b} (2) \u2190 p\n\u2190 a, e\n\u2190 q\n\u2190 a, f \u2190 a \u2190 b, e\n\u2190 b, f\n(3-4) \u2206i = {a, e} and \u2206j = {} (5) p\u2190 a, e; q \u2190 a, f ; p\u2190 q; q \u2190 a; b; e; f\n(Output) IDB : p\u2190 a \u2227 e, q \u2190 a \u2227 f, p\u2190 q, q \u2190 a EDB\u2032 : a\u2190, e\u2190, f \u2190 IC :\u2190 b\nFrom the step, it is easy to conclude which branches are consistent with respect to IC (indicated in the depicted tree by the symbol ). For the next step, we need to find minimal accommodate (positive literal) and denial literal (negative literal) with with respect to to p. The subgoals of the tree are \u2190 a, e and \u2190 a, f , which are minimal tree deductions of only facts. Clearly, \u2206i = {a, e} and \u2206j = {f} with respect to IC, are the only locally minimal abductive explanations for p with respect to IDBG, but these result are not closed-locally minimal explanations.\nFor processing a given view update request, a set of all explanations for that atom has to be generated through a complete SLD-tree. The resulting hitting set of these explanations is then a base update of the EDB satsifying the view update request. We present a different approach which is also rational. The generation of a hitting set is carried out through a hyper tableaux calculus (bottom-up) for implementing the deletion process as well as through the magic sets approach (top-down) for performing insertions focussed on the particular goal given."}, {"heading": "8.1 View update method", "text": "View update (Behrend & Manthey 2008) aims at determining one or more base relation updates such that all given update requests with respect to derived relations are satisfied after the base updates have been successfully applied.\nDefinition 26 (View update). Let DDB = \u3008IDB,EDB, IC\u3009 be a stratifiable (definite) deductive database DDB(D). A VU request \u03bdD is a pair \u3008\u03bd+D, \u03bd \u2212 D\u3009 where \u03bd+D and \u03bd \u2212 D are sets of ground atoms representing the facts to be inserted into D or deleted from D, resp., such that pred(\u03bd+D \u222a \u03bd \u2212 D) \u2286 pred(IDB), \u03bd + D \u2229 \u03bd \u2212 D = \u2205, \u03bd+D \u2229 PMD = \u2205 and \u03bd \u2212 D \u2286 PMD.\nNote that we consider again true view updates only, i.e. ground atoms which are presently not derivable for atoms to be inserted, or are derivable for atoms to be deleted, respectively. A method for view update determines sets of alternative updates satisfying a given request. A set of updates leaving the given database consistent after its execution is called VU realization.\nDefinition 27 (Induced update). Let DDB = \u3008IDB,EDB, IC\u3009 be a stratifiable (definite) deductive database and DDB = \u03bdD a VU request. A VU realization is a base update uD which leads to an induced update uD\u2192D\u2032 from D to D\u2032 such that \u03bd+D \u2286 PMD\u2032 and \u03bd \u2212 D \u2229 PMD\u2032 = \u2205.\nThere may be infinitely many realizations and even realizations of infinite size which satisfy a given VU request. A breadth-first search (BFS) is employed for determining a set of minimal realizations \u03c4D = {u1D, . . . , uiD}. Any uiD is minimal in the sense that none of its updates can be removed without losing the property of being a realization for \u03bdD."}, {"heading": "Magic Set (Top-down computation):", "text": "Given a VU request \u03bdDDB , view update methods usually determine further VU requests in order to find relevant base updates. Similar to delta relations for UP we will use the notion VU relation to access individual view updates with respect to the relations of our system. For each relation p \u2208 pred(IDB \u222aEDB) we use the VU relation \u2207+p (x) for tuples to be inserted into DDB and \u2207\u2212p (x) for tuples to be deleted from DDB. The initial set of delta facts resulting from a given VU request is again represented by so-called VU seeds.\nDefinition 28 (View update seeds). Let DDB(D) be a stratifiable (definite) deductive database and \u03bdDDB = \u3008\u03bd+D, \u03bd \u2212 D\u3009 a VU request. The set of VU seeds vu seeds(\u03bdD) with respect to \u03bdD is defined as follows:\nvu seeds(\u03bdD) := { \u2207\u03c0p (c1, . . . , cn)|p(c1, . . . , cn) \u2208 \u03bd\u03c0D and \u03c0 \u2208 {+,\u2212} } .\nDefinition 29 (View update rules). Let IDB be a normalized stratifiable (definite) deductive rule set. The set of VU rules for true view updates is denoted IDB\u2207 and is defined as the smallest set satisfying the following conditions:\n1. For each rule of the form p(x) \u2190 q(y) \u2227 r(z) \u2208 IDB with vars(p(x)) = (vars(q(y)) \u222a vars(r(z))) the following three VU rules are in IDB\u2207:\n\u2207+p (x) \u2227 \u00acq(y)\u2192 \u2207+q (y) \u2207\u2212p (x)\u2192 \u2207\u2212q (y) \u2228\u2207\u2212r (z) \u2207+p (x) \u2227 \u00acr(z)\u2192 \u2207+r (z)\n2. For each rule of the form p(x) \u2190 q(x) \u2227 \u00acr(x) \u2208 IDB the following three VU rules are in IDB\u2207:\n\u2207+p (x) \u2227 \u00acq(x)\u2192 \u2207+q (x) \u2207\u2212p (x)\u2192 \u2207\u2212q (x) \u2228\u2207+r (x) \u2207+p (x) \u2227 r(x)\u2192 \u2207\u2212r (x)\n3. For each two rules of the form p(x) \u2190 q(x) and p(x) \u2190 r(x) the following three VU rules are in IDB\u2207:\n\u2207\u2212p (x) \u2227 q(x)\u2192 \u2207\u2212q (x) \u2207+p (x)\u2192 \u2207+q (x) \u2228\u2207+r (x) \u2207\u2212p (x) \u2227 r(x)\u2192 \u2207\u2212r (x)\n4. a) For each relation p defined by a single rule p(x) \u2190 q(y) \u2208 IDB with vars(p(x)) = vars(q(y)) the following two VU rules are in IDB\u2207:\n\u2207+p (x)\u2192 \u2207+q (y) \u2207\u2212p (x)\u2192 \u2207\u2212q (y)\nb) For each relation p defined by a single rule p\u2190 \u00acq \u2208 IDB the following two VU rules are in IDB\u2207:\n\u2207+p \u2192 \u2207\u2212q \u2207\u2212p \u2192 \u2207+q 5. Assume without loss of generality that each projection rule in IDB is of the\nform p(x) \u2190 q(x, Y ) \u2208 IDB with Y < vars(p(x)). Then the following two VU rules\n\u2207\u2212p(x) \u2227 q(x, Y )\u2192 \u2207\u2212q (x, Y ) \u2207+p (x)\u2192 \u2207+q (x, c1) \u2228 . . . \u2228\u2207+q (x, cn) \u2228\u2207+q (x, cnew)\nare in IDB\u2207 where all ci are constants from the Herbrand universe UDDB of DDB and cnew is a new constant, i.e. cnew < UDDB.\nTheorem 14. Let DDB = \u3008IDB,EDB, IC\u3009 be a stratifiable (definite)deductive database(D), \u03bdD a view update request and \u03c4D = {u1D, . . . , unD} the corresponding set of minimal realizations. Let D\u2207 = \u3008EDB \u222a vu seeds(\u03bdD), IDB \u222a IDB\u2207\u3009 be the transformed deductive database of D. Then the VU relations in PM\u2207D with respect to base relations of D correctly represent all direct consequences of \u03bdD. That is, for each realization uiD = \u3008ui + D , u i\u2212 D \u3009 \u2208 \u03c4D the following condition holds:\n\u2203p(t) \u2208 ui + D : \u2207+p (t) \u2208MS\u2207D \u2228 \u2203p(t) \u2208 ui \u2212 D : \u2207\u2212p (t) \u2208MS\u2207D .\nProof. Follows from the result of (Behrend & Manthey 2008)."}, {"heading": "Hyper Tableau (Bottom-up computation):", "text": "In (Aravindan & Baumgartner 1997) a variant of clausal normal form tableaux called \u201dhyper tableaux\u201d is introduced for view deletion method. Since the hyper tableaux calculus constitutes the basis for our view update algorithm, Clauses, i.e. multisets of literals, are usually written as the disjunction A1 \u2228 A2 \u2228 \u00b7 \u00b7 \u00b7 \u2228 Am \u2228 not B1 \u2228 not B2 \u00b7 \u00b7 \u00b7 \u2228 not Bn (M \u2265 0, n \u2265 0). The literals A1, A2, . . . Am (resp. B1, B2, . . . , Bn) are called the head (resp. body) of a clause. With L we denote the complement of a literal L. Two literals L and K are complementary if L = K.\nFrom now on D always denotes a finite ground clause set, also called database, and \u03a3 denotes its signature, i.e. the set of all predicate symbols occurring in it. We consider finite ordered trees T where the nodes, except the root node, are labeled with literals. In the following we will represent a branch b in T by the sequence b = L1, L2, . . . , Ln (n \u2265 0) of its literal labels, where L1 labels an immediate successor of the root node, and Ln labels the leaf of b. The branch b is called regular iff Li , Lj for 1 \u2264 i, j \u2264 n and i , j, otherwise it is called irregular. The tree T is regular iff every of its branches is regular, otherwise it is irregular. The set of branch literals of b is lit(b) = {L1, L2, . . . , Ln}. For brevity, we will write expressions like A \u2208 b instead of A \u2208 lit(b). In order to memorize the fact that a branch contains a contradiction, we allow to label a branch as either open or closed. A tableau is closed if each of its branches is closed, otherwise it is open.\nDefinition 30 (Hyper Tableau). A literal set is called inconsistent iff it contains a pair of complementary literals, otherwise it is called consistent. Hyper tableaux for D are inductively defined as follows:\nInitialization step: The empty tree, consisting of the root node only, is a hyper tableau for D. Its single branch is marked as \u201dopen\u201d.\nHyper extension step: If (1) T is an open hyper tableau for D with open branch b, and (2) C = A1\u2228A2\u2228\u00b7 \u00b7 \u00b7\u2228Am \u2190 B1\u2227B2 \u00b7 \u00b7 \u00b7\u2227Bn is a clause fromD (n \u2265 0,m \u2265 0), called extending clause in this context, and (3) {B1, B2, . . . , Bn} \u2286 b (equivalently, we say that C is applicable to b)then the tree T is a hyper tableau for D, where T is obtained from T by extension of b by C: replace b in T by the new branches\n(b, A1), (b, A2), . . . , (b, Am), (b,\u00acB1), (b,\u00acB2), . . . , (b,\u00acBn)\nand then mark every inconsistent new branch as \u201dclosed\u201d, and the other new branches as \u201dopen\u201d.\nThe applicability condition of an extension expresses that all body literals have to be satisfied by the branch to be extended. From now on, we consider only regular hyper tableaux. This restriction guarantees that for finite clause sets no branch can be extended infinitely often. Hence, in particular, no open finished branch can be extended any further. This fact will be made use of below occasionally. Notice as an immediate consequence of the above definition that open branches never contain negative literals.\nThis paper work focused on stratified (definite) deductive database without any auxiliary variable. In magic set rule play in minimal case, our future goal is similar foundation using auxiliary variable (Deductive Databases) side and more details found in Behrend\u2019s (Behrend & Manthey 2008) work."}, {"heading": "8.2 View update algorithm", "text": "The key idea of the algorithm presented in this paper is to transform the given database along with the view update request into a logic program and apply known minimality techniques to solve the original view update problem. The intuition behind the transformation is to obtain a logic program in such a way that each (minimal) model of this transformed program represent a way to update the given view atom. We present two variants of our algorithm. The one that is discussed in this section employs a trivial transformation procedure but has to look for minimal models; and another performs a costly transformation, but dispenses with the requirement of computing the minimal models."}, {"heading": "Minimality test", "text": "We start presenting an algorithm for stratifiable (definite) deductive databases by first defining precisely how the given database is transformed into a logic program for the view deletion process (Aravindan & Baumgartner 1997)\nDefinition 31 (IDB Transformation). Given an IDB and a set of ground atoms S, the transformation of IDB with respect to S is obtained by translating each clause C \u2208 IDB as follows: Every atom A in the body (resp. head) of C that is also in S is moved to the head (resp. body) as \u00acA.\nNote 5. If IDB is a stratifiable deductive database then the transformation introduced above is not necessary.\nDefinition 32 (IDB\u2217 Transformation). Let IDB\u222aEDB be a given database. Let S0 = EDB \u222a{A | A is a ground IDB atom}. Then, IDB\u2217 is defined as the transformation of IDB with respect to S0.\nNote 6. IDB\u2217 is in general a logic program. The negative literals (\u00acA) appearing in the clauses are intuitively interpreted as deletion of the corresponding atom (A) from the database. Technically, a literal \u00acA is to be read as a positive atom, by taking the \u00ac-sign as part of the predicate symbol. To be more precise, we treat \u00acA as an atom with respect to IDB\u2217, but as a negative literal with respect to IDB.\nNote that there are no facts in IDB\u2217. So when we add a delete request such as \u00acA to this, the added request is the only fact and any bottom-up reasoning strategy is fully focused on the goal (here the delete request)\nDefinition 33 (Update Tableaux Hitting Set). An update tableau for a database IDB \u222a EDB and delete request \u00acA is a hyper tableau T for IDB\u2217 \u222a {\u00acA\u2190} such that every open branch is finished. For every open finished branch b in T we define the hitting set (of b in T ) as HS(b) = {A \u2208 EDB|\u00acA \u2208 b}.\nThe next step is to consider the view insertion process (Behrend & Manthey 2008):\nDefinition 34 (IDB\u2022 Transformation). Let IDB\u222aEDB be a given database. Let S1 = EDB \u222a {A | A is a ground IDB atom} (that is either body or head empty). Then, IDB\u2022 is defined as the transformation of IDB with respect to S1.\nNote 7. IDB is in general a (stratifiable) logic program. The positive literals (A) appearing in the clauses are intuitively interpreted as an insertion of the corresponding atom (A) from the database.\nDefinition 35 (Update magic Hitting Set). An update magic set rule for a database IDB \u222a EDB and insertion request A is a magic set rule M for IDB\u2022 \u222a {A\u2190} such that every close branch is finished. For every close finished branch b in M we define the magic set rule (of b in M) as HS(b) = {A \u2208 EDB|A \u2208 b}.\nExample 15. Given stratifiable (definite) deductive database DDB = IDB \u222a EDB \u222a IC and insert p."}, {"heading": "IDB : p\u2190 a \u2227 e EDB : a\u2190 IC : \u2205", "text": "q \u2190 a \u2227 e c\u2190 p\u2190 a \u2227 f q \u2190 c\nIDB\u2217 Transformation:\nIDB\u2217 : \u00aca \u2228 \u00ace\u2190 \u00acp EDB : a\u2190 IC : \u2205 \u00aca \u2228 \u00ace\u2190 \u00acq c\u2190 \u00aca \u2228 \u00acf \u2190 \u00acp \u00acc\u2190 \u00acq\nIDB\u2022 Transformation: (Body empty)\nIDB\u2022 : p \u2228 \u00aca \u2228 \u00ace\u2190 EDB : a\u2190 IC : \u2205 q \u2228 \u00aca \u2228 \u00ace\u2190 c\u2190 p \u2228 \u00aca \u2228 \u00acf \u2190 q \u2228 \u00acc\u2190\nIDB\u2022 Transformation: (Head empty)\nIDB\u2022 : \u2190 \u00acp \u2227 a \u2227 e EDB : a\u2190 IC : \u2205 \u2190 \u00acq \u2227 a \u2227 e c\u2190 \u2190 \u00acp \u2227 a \u2227 f \u2190 \u00acq \u2227 c\nThe set S0 is determined by all the IDB atoms and the current EDB atoms and in our case it is {p, q, a, c, e, f}. IDB\u2217 and IDB\u2022 is the transformation of IDB with respect to S0 which is given above.\nSuppose a ground view atom A is to be insert. Then, an update tableau for IDB\u2022 with insert request A (IDB\u2217 with delete request \u00acA) is built. The intuition is that the set of EDB atoms appearing in a model (open/close branch) constitute a hitting set, and removing/adding this set from EDB should achieve the required view insertion. Unfortunately, this does not result in a rational insertion, as relevance policy may be violated.\nExample 16. Let us continue with example 15 Suppose the view atom p is to be insert. Then according to the above proposal, an update tableau for IDB\u2022 ( IDB\u2217 ) and p (\u00acp) is to be built. This is illustrated in the accompanying figure below. As shown, open/close branches constitute two hitting sets {a} and {f, a} ({\u00aca} and {\u00acf,\u00aca}). It is not difficult to see that {f, a}({\u00acf,\u00aca}) does not satisfy any of the relevance policies (KB*7.1) or (KB*7.2) or (KB*7.3). Hence simple model computation using hyper tableau calculus does not result in rational hitting sets. The branch is closed if the corresponding hitting set does not satisfy this strong relevance postulate.\nDefinition 36 (Minimality test). Let T be an update tableau for IDB\u2217 \u222a EDB and delete request \u00acA. We say that open finished branch b in T satisfies the strong minimality test iff \u2200s \u2208 HS(b) : IDB\u2217 \u222a EDB\\HS(b) \u222a {s} ` \u00acA.\nDefinition 37 (Update Tableau satisfying strong minimality). An update tableau for given IDB \u222a EDB and delete request \u00acA is transformed into an update tableau satisfying strong minimality by marking every open finished branch as closed which does not satisfy strong minimality.\nThe next step is to consider the view insertion process (Behrend & Manthey 2008):\nDefinition 38 (Minimality test). Let M be an update magic set rule for IDB \u222a EDB and insert request A. We say that close finished branch b in M satisfies the strong minimality test iff \u2200s \u2208 HS(b) : IDB\u2022\u222aEDB\\HS(b)\u222a{s} ` A.\nDefinition 39 (Update magic set rule satisfying strong minimality). An update magic set rule for given IDB\u222aEDB and insert request A is transformed into an update magic set rule satisfying strong minimality by marking every close finished branch as open which does not satisfy strong minimality.\nExample 17. Continuing with the above example, after constructing the branch corresponding to the hitting set {f, a}({\u00acf,\u00aca}), the strong minimality test is carried out as follows: It is checked if the resulting database with each member of hitting set implies the insert atom p. For example, IDB\u222aEDB\\{f, a}\u222a{a} 0 p, and hence this branch fails the strong minimality test.\nInterestingly, this minimality test is equivalent to the groundedness test used for generating minimal models of logic programs. The key idea of the groundedness test is to check if the members in the model are implied by the program together with the negation/positive of the atoms not present in the model. The groundedness test for generating minimal models can be stated\nas follows: Let T be an update tableau for IDB \u222a EDB and insert request A.We say that open finished branch b in T satisfies the groundedness test iff \u2200s \u2208 HS(b) : IDB\u2022 \u222a EDB\\HS(b) \u222a {A} ` s, similar for IDB\u2217 (\u2200s \u2208 HS(b) : IDB\u2217 \u222a EDB\\HS(b) \u222a {\u00acA} ` \u00acs). It is not difficult to see that this is equivalent to the minimality test. This means that every minimal model (minimal with respect to the base atoms) of IDB\u2217 \u222a {A} provides a minimal hitting set for insertion the ground view atom A.\nAlgorithm 4 View update Algorithm based on minimality test Input : A stratifiable (definite) deductive database DDB = IDB \u222a EDB \u222a IC\nan literals A Output: A new stratifiable (definite) database IDB \u222a EDB\u2032 \u222a IC\nbegin 1. Let V := {c \u2208 IC | IDB \u222a IC inconsistent with A with respect to c }\nWhile (V , \u2205) 2. Construct a complete SLD-tree for\u2190 A with respect to DDB. 3. For every successful branch i:construct \u2206i = {D | D \u2208 EDB}\nand D is used as an input clause in branch i. Construct a branch i of an update tableau satisfying minimality\nfor IDB \u222a EDB and delete request \u00acA. Produce IDB \u222a EDB\\HS(i) as a result\n4. For every unsuccessful branch j:construct \u2206j = {D | D \u2208 EDB} and D is used as an input clause in branch j.\nConstruct a branch j of an update magic set rule satisfying minimality for IDB \u222a EDB and insert request A. Produce IDB \u222a EDB\\HS(j) as a result Let V := {c \u2208 IC | IDB \u222a IC inconsistent with A with respect to c }\nreturn 5. Produce DDB as the result.\nend.\nThis means that every minimal model (minimal with respect to the base atoms) of IDB\u2217\u222a{\u00acA} (IDB\u2022\u222a{A} )provides a minimal hitting set for deleting the ground view atom A. Similarly, IDB\u2217 \u222a {A} provides a minimal hitting set for inserting the ground view atom A. We are formally present our algorithms.\nGiven a database and a view atom to be updated, we first transform the database into a logic program and use hyper tableaux calculus to generate models of this transformed program for deletion of an atom. Second, magic sets transformed rules are used is used to generate models of this transformed program for determining an induced insertion of an atom. Models that do not represent rational update are filtered out using the strong minimality test. The procedure for stratifiable (definite) deductive databases is presented in Algorithms in 4 and 5.\nAlgorithm 5 View update Algorithm based on minimality test Input : A stratifiable (definite) deductive database DDB = IDB \u222a EDB \u222a IC\nan literals A Output: A new stratifiable (definite) database IDB \u222a EDB\u2032 \u222a IC\nbegin 1. Construct a complete SLD-tree for\u2190 A with respect to DDB. 2. For every successful branch i:construct \u2206i = {D | D \u2208 EDB}\nand D is used as an input clause in branch i. 3. For every unsuccessful branch j:construct \u2206j = {D | D \u2208 EDB} and D is used as an input clause in branch j. 4. Let V := {c \u2208 IC | IDB \u222a IC inconsistent with A with respect to c }\nWhile (V , \u2205) Construct a branch i of an update tableau satisfying minimality\nfor IDB \u222a EDB and delete request \u00acA. Produce IDB \u222a EDB\\HS(i) as a result\nConstruct a branch j of an update magic set rule satisfying minimality for IDB \u222a EDB and insert request A. Produce IDB \u222a EDB\\HS(j) as a result Let V := {c \u2208 IC | IDB \u222a IC inconsistent with A with respect to c }\nreturn 5. Produce DDB as the result.\nend.\nLemma 1. The strong minimality test and the groundedness test are equivalent.\nProof. Follows from the result of (Aravindan & Baumgartner 1997).\nExample 18."}, {"heading": "IDB : p\u2190 a \u2227 e EDB : a\u2190 IC :\u2190 b", "text": "q \u2190 a \u2227 e f \u2190 p\u2190 b \u2227 f q \u2190 b \u2227 f p\u2190 g \u2227 a q \u2190 p\nSuppose we want to insert p. First, we need to check consistency with IC and afterwards, we have to find \u2206i and \u2206j via tree deduction.\nFrom algorithm 4 or 5 (only different is checking IC condition), the above example execute following steps:\nStep number with execution\n(Input) IDB : p\u2190 a \u2227 e; q \u2190 a \u2227 e; p\u2190 b \u2227 f ; q \u2190 b \u2227 f ; p\u2190 g \u2227 a; q \u2190 p EDB : a\u2190, f \u2190 IC :\u2190 b\n(0) {p\u2190 a, e; q \u2190 a, e; p\u2190 b, f ; q \u2190 b, f ; p\u2190 g, a; q \u2190 p; a; f}\n(1) {V = b}\n(2.1) a. a\ne\nq p\nb. f\nb\na\ne\nq p\nc. f\nb\na\ne\nq p\nq d. g\nf\nb\na\ne\nq p\nq\ne. g\nf\nb\na\ne\nq\np\nq\n(2.2) a. a\ne\nq p\nb. a\ne\nq p\nc. a\ne\nq p\nq d. g\na\ne\nq p\nq\ne. g\na\ne\nq\np\nq\n(3-4) \u2206i = {a, e, g} and \u2206j = {}\n(5) p\u2190 a, e; q \u2190 a, e; p\u2190 g, a; q \u2190 p; a; e; f ; g (Output) IDB : p\u2190 a \u2227 e; q \u2190 a \u2227 e; p\u2190 g \u2227 a; q \u2190 p\nEDB\u2032 : a\u2190, e\u2190, f \u2190, g \u2190 IC :\u2190 b\nTo show the rationality of this approach, we study how this is related to the previous approach presented in the last section, i.e. generating explanations and computing hitting sets of these explanations. To better understand the relationship it is imperative to study where the explanations are in the hyper tableau approach and magic set rules. We first define the notion of an EDB-cut and then view update seeds.\nDefinition 40 (EDB-Cut). Let T be update tableau with open branches b1, b2, . . . , bn. A set S = {A1, A2, . . . , An} \u2286 EDB is said to be EDB-cut of T iff \u00acAi \u2208 bi (Ai \u2208 bi), for 1 \u2264 i \u2264 n.\nDefinition 41 (EDB seeds). Let M be an update seeds with close branches b1, b2, . . . ,bn. A set S = {A1, A2, . . . , An} \u2286 EDB is said to be a EDB-seeds of M iff EDB seeds vu seeds(\u03bdD) with respect to \u03bdD is defined as follows:\nvu seeds(\u03bdD) := { \u2207\u03c0p (c1, . . . , cn)|p(c1, . . . , cn) \u2208 \u03bd\u03c0D and \u03c0 \u2208 {+,\u2212} } .\nLemma 2. Let T be an update tableau for IDB \u222a EDB and update request A. Similarly, for M be an update magic set rule. Let S be the set of all EDB-closed minimal abductive explanations for A with respect to. IDB. Let S\u2032 be the set of all EDB-cuts of T and EDB-seeds of M . Then the following hold\n\u2022 S \u2286 S\u2032.\n\u2022 \u2200\u2206\u2032 \u2208 S\u2032 : \u2203\u2206 \u2208 Ss.t.\u2206 \u2286 \u2206\u2032.\nProof.\n1. Consider a \u2206(\u2206 \u2208 \u2206i \u222a \u2206j) \u2208 S. We need to show that \u2206 is generated by algorithm 4 at step 2. From observation 4, it is clear that there exists a A-kernel X of DDBG s.t. X \u2229 EDB = \u2206j and X \u222a EDB = \u2206i. Since X ` A, there must exist a successful derivation for A using only the elements of X as input clauses and similarly X 0 A. Consequently \u2206 must have been constructed at step 2. 2. Consider a \u2206\u2032((\u2206\u2032 \u2208 \u2206i \u222a\u2206j) \u2208 S\u2032. Let \u2206\u2032 be constructed from a successful (unsuccessful) branch i via \u2206i(\u2206j). Let X be the set of all input clauses used in the refutation i. Clearly X ` A(X 0 A). Further, there exists a minimal (with respect to set-inclusion) subset Y of X that derives A (i.e. no proper subset of Y derives A). Let \u2206 = Y \u2229 EDB (Y \u222a EDB). Since IDB does not (does) have any unit clauses, Y must contain some EDB facts, and so \u2206 is not empty (empty) and obviously \u2206 \u2286 \u2206\u2032. But, Y need not (need) be a A-kernel for IDBG since Y is not ground in general. But it stands for several A-kernels with the same (different) EDB facts \u2206 in them. Thus, from observation 4, \u2206 is a DDB-closed locally minimal abductive explanation for A with respect to IDBG and is contained in \u2206\u2032. minimal.\nThe above lemma precisely characterizes what explanations are generated by an update tableau. It is obvious then that a branch cuts through all the explanations and constitutes a hitting set for all the generated explanations. This is formalized below.\nLemma 3. Let S and S\u2032 be sets of sets s.t. S \u2286 S\u2032 and every member of S\u2032\\S contains an element of S. Then, a set H is a minimal hitting set for S iff it is a minimal hitting set for S\u2032.\nProof.\n1. (Only if part) Suppose H is a minimal hitting set for S. Since S \u2286 S\u2032, it follows that H \u2286 \u22c3 S\u2032. Further, H hits every element of S\u2032, which is evident\nfrom the fact that every element of S\u2032 contains an element of S. Hence H is a hitting set for S\u2032. By the same arguments, it is not difficult to see that H is minimal for S\u2032 too.\n(If part) Given that H is a minimal hitting set for S\u2032, we have to show that it is a minimal hitting set for S too. Assume that there is an element E \u2208 H that is not in \u22c3 S. This means that E is selected from some Y \u2208 S\u2032\\S. But Y contains an element of S, say X. Since X is also a member of S\u2032, one member of X must appear in H. This implies that two elements have been\nselected from Y and hence H is not minimal. This is a contradiction and hence H \u2286 \u22c3 S. Since S \u2286 S\u2032, it is clear that H hits every element in S, and so H is a hitting set for S. It remains to be shown that H is minimal. Assume the contrary, that a proper subset H \u2032 of H is a hitting set for S. Then from the proof of the only if part, it follows that H \u2032 is a hitting set for S\u2032 too, and contradicts the fact that H is a minimal hitting set for S\u2032 . Hence, H must be a minimal hitting set for S.\nLemma 4. Let T be an update tableau for IDB \u222a EDB and update request A that satisfies the strong minimality test. Similarly, for M be an updating magic set rule. Then, for every open (close) finished branch b in T , HS(b) (M , HS(b)) is a minimal hitting set of all the abductive explanations of A.\nProof. Follows from the Observation 4 (minimal test) in and (Behrend & Manthey 2008).\nSo, Algorithms 4 and 5 generate a minimal hitting set (in polynomial space) of all EDB-closed locally minimal abductive explanations of the view atom to be deleted. From the belief dynamics results recalled in section 5.3, it immediately follows that Algorithms 4 and 5 are rational, and satisfy the strong relevance postulate (KB*7.1).\nTheorem 15. Algorithms 4 and 5 are rational, in the sense that they satisfy all the rationality postulates (KB*1)-(KB*6) and the strong relevance postulate (KB*7.1). Further, any update that satisfies these postulates can be computed by these algorithms.\nProof. Follows from Observation 4,4 and Theorem 7."}, {"heading": "8.3 Materialized view", "text": "In many cases, the view update to be materialized, i.e. the least Herbrand Model is computed and kept, for efficient query answering. In such a situation, rational hitting sets can be computed without performing any minimality test. The idea is to transform the given IDB with respect to the materialized view.\nDefinition 42 (IDB+ Transformation). Let IDB\u222aEDB be a given database. Let S be the Least Herbrand Model of this database. Then, IDB+ is defined as the transformation of IDB with respect to S.\nNote 8. If IDB is a stratifiable deductive database then the transformation introduced above is not necessary.\nDefinition 43 (Update Tableau based on Materialized view). An update tableau based on materialized view for a database IDB\u222aEDB and delete request \u00acA is a hyper tableau T for IDB+ \u222a {\u00acA \u2190} such that every open branch is finished.\nDefinition 44 (IDB\u2212 Transformation). Let IDB\u222aEDB be a given database. Let S1 be the Least Herbrand Model of this database (that is either body or head empty). Then, IDB\u2212 is defined as the transformation of IDB with respect to S1.\nDefinition 45 (Update magic set rule based on Materialized view). An update magic set rule based on materialized view for a database IDB \u222a EDB and insert request A is a magic set M for IDB+ \u222a {A\u2190} such that every close branch is finished.\nNow the claim is that every model of IDB+ \u222a {\u00acA \u2190} (A \u2190) constitutes a rational hitting set for the deletion and insertion of the ground view atom A. So, the algorithm works as follows: Given a database and a view update request, we first transform the database with respect to its Least Herbrand Model (computation of the Least Herbrand Model can be done as a offline preprocessing step. Note that it serves as materialized view for efficient query answering). Then the hyper tableaux calculus (magic set rule) is used to compute models of this transformed program. Each model represents a rational way of accomplishing the given view update request. This is formalized in Algorithms 6 and 7.\nLike the approach with minimality test, this algorithm runs on not polynomial space. This approach require minimality test, but our focus on integrity constrain open/close branch. Again, this requires some offline pre-processing of computing the Least Herbrand Model. Note that, our future direction to construct minimality test, this method may generate a non-minimal (but rational) hitting set.\nExample 19. Given stratifiable (definite) deductive database DDB = IDB \u222a EDB \u222a IC and insert p."}, {"heading": "IDB : p\u2190 a EDB : c\u2190 IC : \u2205", "text": "q \u2190 a d\u2190\nq \u2190 c \u2227 b q \u2190 p\nIDB+ Transformation:\nIDB+ : \u00aca\u2190 \u00acp EDB : c\u2190 IC : \u2205 \u00aca\u2190 \u00acq d\u2190\n\u00acc \u2228 \u00acb\u2190 \u00acp \u00acp\u2190 \u00acq\nIDB\u2212 Transformation: (Body empty)\nIDB\u2212 : p \u2228 \u00aca\u2190 EDB : c\u2190 IC : \u2205 q \u2228 \u00aca\u2190 d\u2190\nq \u2228 \u00acc \u2228 \u00acb\u2190 q \u2228 \u00acp\u2190\nIDB\u2212 Transformation: (Head empty)\nThe Least Herbrand Model of this database is {p, q, a, b}. The transformed database IDB+ and IDB\u2212 based on this model, together with an update tableaux for insertion request p based on materialised view is as above figure:\nObserve that the last two clauses are never used and the necessarily failing attempt of deleting t to delete p is never made, thus greatly reducing the search space. Also note that the two cuts with only EDB atoms {a, b} and {a} are exactly the two locally minimal explanations for p. The two open branches provide the two models of IDB+ \u222a {\u00acp} (IDB\u2212 \u222a {p} which stand for the hitting sets {a, b} and {a}. Clearly, {a, b} not minimal.\nAlgorithm 6 View update algorithm based on Materialized view Input : A stratifiable (definite) deductive database DDB = IDB \u222a EDB \u222a IC\nan literals A Output: A new stratifiable (definite) database IDB \u222a EDB\u2032 \u222a IC\nbegin 1. Let V := {c \u2208 IC | IDB \u222a IC inconsistent with A with respect to c }\nWhile (V , \u2205) 2. Construct a complete SLD-tree for\u2190 A with respect to DDB. 3. For every successful branch i:construct \u2206i = {D | D \u2208 EDB}\nand D is used as an input clause in branch i. Construct a branch i of an update tableau based on view\nfor IDB \u222a EDB and delete request \u00acA. Produce IDB \u222a EDB\\HS(i) as a result\n4. For every unsuccessful branch j:construct \u2206j = {D | D \u2208 EDB} and D is used as an input clause in branch j.\nConstruct a branch j of an update magic set rule based on view for IDB \u222a EDB and insert request A.\nProduce IDB \u222a EDB\\HS(j) as a result Let V := {c \u2208 IC | IDB \u222a IC inconsistent with A with respect to c }\nreturn 5. Produce DDB as the result.\nend.\nExample 20."}, {"heading": "IDB : p\u2190 a EDB : f \u2190 IC :\u2190 b", "text": "q \u2190 a g \u2190\np\u2190 b \u2227 f q \u2190 b \u2227 f p\u2190 g \u2227 a\nSuppose we want to insert p. First, we need to check consistency with IC and afterwards, we have to find \u2206i and \u2206j via tree deduction.\nFrom algorithm 6 or 7 (only different is checking IC condition), the above example execute following steps:\nAlgorithm 7 View update algorithm based on Materialized view Input : A stratifiable (definite) deductive database DDB = IDB \u222a EDB \u222a IC\nan literals A Output: A new stratifiable (definite) database IDB \u222a EDB\u2032 \u222a IC\nbegin 1. Construct a complete SLD-tree for\u2190 A with respect to DDB. 2. For every successful branch i:construct \u2206i = {D | D \u2208 EDB}\nand D is used as an input clause in branch i. 3. For every unsuccessful branch j:construct \u2206j = {D | D \u2208 EDB} and D is used as an input clause in branch j. 4. Let V := {c \u2208 IC | IDB \u222a IC inconsistent with A with respect to c }\nWhile (V , \u2205) Construct a branch i of an update tableau satisfying based on view\nfor IDB \u222a EDB and delete request A. Produce IDB \u222a EDB\\HS(i) as a result\nConstruct a branch j of an update magic set rule based on view for IDB \u222a EDB and insert request A.\nProduce IDB \u222a EDB\\HS(j) as a result Let V := {c \u2208 IC | IDB \u222a IC inconsistent with A with respect to c }\nreturn 5. Produce DDB as the result.\nend.\nStep number with execution\n(Input) IDB : p\u2190 a, q \u2190 a, p\u2190 b \u2227 f, q \u2190 b \u2227 f, p\u2190 g \u2227 a EDB : f \u2190, g \u2190 IC :\u2190 b\n(0) {p\u2190 a; q \u2190 a; p\u2190 b, f ; q \u2190 b, f ; p\u2190 g, a; b; g}\n(1) {V = b}\n(2.1) a. a\nq p\nb. f\nb\na\nq p\nc. f\nb\na\nq p\ng\nd. g\nf\nb\na\nq\np\ng\n(2.2) a. a\nq p\nb. a\nq p\nc. a\nq p\ng\nd. g\na\nq\np\ng\n(3-4) \u2206i = {a, g} and \u2206j = {} (5) p\u2190 a; q \u2190 a; p\u2190 g \u2227 a; a, f, g\n(Output) IDB : p\u2190 a, q \u2190 a, p\u2190 g \u2227 a EDB\u2032 : a\u2190; f \u2190; g \u2190 IC :\u2190 b\nThis approach for view update may not satisfy (KB*7.1) in general. But, as shown in the sequel, conformation to (KB*7.3) is guaranteed and thus this approach results in rational update.\nLemma 5. Let T be an update tableau based on a materialized view for IDB \u222a EDB and delete request \u00acA (A), Similarly, let M be an update magic set rule. Let S be the set of all EDB-closed locally minimal abductive explanations for A with respect to IDB. Let S\u2032 be the set of all EDB-cuts of T and EDB-seeds of M . Then, the following hold:\n\u2022 S \u2286 S\u2032. \u2022 \u2200\u2206\u2032 \u2208 S\u2032 : \u2203\u2206 \u2208 S s.t. \u2206 \u2286 \u2206\u2032. \u2022 \u2200\u2206\u2032 \u2208 S\u2032 : \u2206\u2032 \u2286 \u22c3 S.\nProof.\n1. Consider a \u2206(\u2206 \u2208 \u2206i \u222a \u2206j) \u2208 S. We need to show that \u2206 is generated by algorithm 6 at step 2. From observation 4, it is clear that there exists a A-kernel X of DDBG s.t. X \u2229 EDB = \u2206j and X \u222a EDB = \u2206i. Since X ` A, there must exist a successful derivation for A using only the elements of X as input clauses and similarly X 0 A. Consequently \u2206 must have been constructed at step 2. 2. Consider a \u2206\u2032((\u2206\u2032 \u2208 \u2206i \u222a\u2206j) \u2208 S\u2032. Let \u2206\u2032 be constructed from a successful(unsuccessful) branch i via \u2206i(\u2206j). Let X be the set of all input clauses used in the refutation i. Clearly X ` A(X 0 A). Further, there exists a minimal (with respect to set-inclusion) subset Y of X that derives A (i.e. no proper subset of Y derives A. Let \u2206 = Y \u2229 EDB (Y \u222a EDB). Since IDB does not (does) have any unit clauses, Y must contain some EDB facts, and so \u2206 is not empty (empty) and obviously \u2206 \u2286 \u2206\u2032. But, Y need not (need) be a A-kernel for IDBG since Y is not ground in general. But it stands for several A-kernels with the same (different) EDB facts \u2206 in them. Thus, from observation 4, \u2206 is a DDB-closed locally minimal abductive explanation for A with respect to IDBG and is contained in \u2206\u2032. minimal.\nLemma 6. Let S and S\u2019 be sets of sets s.t. S \u2286 S\u2032 and for every member X of S\u2032\\S: X is a superset of some member of S and X is a subset of \u22c3 S. Then, a set H is a hitting set for S iff it is a hitting set for S\u2019\nProof.\n1. (If part) Given that H is a hitting set for S\u2032, we have to show that it is a hitting set for S too. First of all, observe that \u22c3 S = \u22c3 S\u2032, and so H \u2286 \u22c3 S.\nMoreover, by definition, for every non-empty member X of S\u2032, H \u2229X is not empty. Since S \u2286 S\u2032, it follows that H is a hitting set for S too.\n(Only if part) Suppose H is a hitting set for S. As observed above, H \u2286\u22c3 S\u2032 . By definition, for every non-empty member X \u2208 S, X \u2229 H is not empty. Since every member of S\u2032 is a superset of some member of S, it is clear that H hits every member of S\u2032, and hence a hitting set for S\u2032 .\nLemma 7. Let T and M as in Lemma 5. Then HS(b) is a rational hitting set for A, for every open finished branch b in T (close finished branch b in M).\nProof. Follows from the observation 4 (materialized view) in and (Behrend & Manthey 2008)\nTheorem 16. Algorithms 6 and 7 are rational, in the sense that they satisfy all the rationality postulates (KB*1) to (KB*6) and (KB*7.3).\nProof. Follows from Observation 4,7 and Theorem 7."}, {"heading": "8.4 Incomplete to Complete Information", "text": "Many of the proposals in the literature on incomplete databases have focussed on the extension of the relational model by the introduction of null values. In this section, we show how view update provides completion of incomplete information. More detailed surveys of this area can be found in (Meyden 1998).\nThe earliest extension of the relational model to incomplete information was that of Codd (Codd 1979) who suggested that missing values should be represented in tables by placing a special null value symbol \u2032\u2217\u2032 at any table location for which the value is unknown. Table 5.3, shows an example of a database using this convention. Codd proposed an extension to the relational algebra for tables containing such nulls, based on three valued logic and a null substitution principle.\nIn terms of our general semantic scheme, the intended semantics of a database D consisting of Codd tables can be described by defining Mod(D) to be the set of structures MD\u2032 , where D\u2032 ranges over the relational databases obtained by replacing each occurrence of \u2032\u2217\u2032 in the database D by some domain value. Different values may be substituted for different occurrences.\nA plausible integrity constraint on the meaning of a relational operator on tables in T is that the result should be a table that represents the set of relations obtained by pointwise application of the operator on the models of these tables. For example, if R and S are tables in T then the result of the join R Z S should be equal to a table T in T such that\nMod(T ) = {r Z t | r \u2208Mod(R), s \u2208Mod(S)}\nIn case the definitions of the operators satisfy this integrity constraint (with respect to the definition of the semantics Mod on T ).\nLet us consider what above equation requires if we take R and S to be the Codd Tables 5.3. First of all, note that in each model, if we take the value of the null in the tuple (delhibabu,*) to be v, then the join will contain one tuples (delhibabu, v), which include the value v. If T is to be a Codd table, it will need to contain tuples (delhibabu,X) to generate each of these tuples, where X are either constants or \u2019*\u2019. We now face a problem. First, X cannot be a constant c, for whatever the choice of c we can find an instance r \u2208Mod(R) and s \u2208Mod(S) for which the tuple (delhibabu, c) does not occur in r Z s. If they were, X would have their values in models of T assigned independently.\nHere the repetition of \u2217 indicates that the same value is to be occurrence of the null in constructing a model of the table. Unfortunately, this extension does not suffice to satisfy the integrity constraint (\u2200x, y, z (y=x) \u2190 group chair(x,y) \u2227 group chair(x,z)).\nIn the model of these tables in which \u2217 = infor1, the join contains the tuple (delhibabu, infor1) and (infor1, aravindan).\nThe following table shows completion of incomplete information with application of integrity constraint and redundancy:"}, {"heading": "8.5 A Comparative Study of view update algorithm and integrity constraint with our axiomatic method", "text": "During the process of updating database, two interrelated problems could arise. On one hand, when an update is applied to the database, integrity constraints could become inconsistent with request, then stop the process. On the other hand, when an update request consist on updating some derived predicate, a view update mechanism must be applied to translate the update request into correct updates on the underlying base facts. Our work focus on the integrity constraint maintenance approach. In this section, we extend Mayol and Teniente\u2019s (Mayol & Teniente 1999) survey for view update and integrity constraint.\nThe main aspects that must be taken into account during the process of view update and integrity constraint enforcement are the following: the problem addressed, the considered database schema, the allowed update requests, the used technique, update change and the obtained solutions. These six aspects provide the basic dimensions to be taken into account. We explain each dimension in this section and results are presented in Appendix.\nProblem Addressed\n(Type) - What kind of program to be used (stratified (S), Horn clause (H), Disjunctive database (D), Normal Logic program (N) and Other (O)). (View Update) - Whether they are able to deal with view update or not (indicated by Yes or No in the second column in the appendix section). (integrity-constraint Enforcement) - Whether they incorporate an integrity constraint checking (C)or an integrity constraint maintenance (M) or both apply (C-M) approach (indicated by check or maintain in the third column). (Run/Comp) - Whether the method follows a run-time (transaction) or a compiletime approach (indicated by Run or Compile in the fourth column).\nDatabase Schema Considered\n(Definition Language) - The language mostly used is logic (L), although some methods use a relational language (R) and also uses an object-oriented (OO). (The DB Schema Contains Views) - All methods that deal with view update need views to be defined in the database schema. Some of other method allow to define views. (Restrictions Imposed on the Integrity Constraints) - Some proposals impose certain restrictions on the kind of integrity constraints that can be defined and, thus, handled by their methods. (Static vs Dynamic Integrity Constraints) - Integrity constraints may be either static (S), and impose restrictions involving only a certain state of the database, or dynamic (D).\nUpdate Request Allowed\n(Multiple Update Request) - An update request is multiple if it contains several updates to be applied together to the database. (Update Operators) - Traditionally, three different basic update operators are distinguished: insertion (\u03b9), deletion (\u03b4) and modification (\u03c7). Modification can always be simulated by a deletion followed by an insertion.\nUpdate Processing Mechanism\n(Applied Technique) - The techniques applied by these methods can be classified according to four different kinds of procedures, unfolding, SLD, active and predefined programs, respectively. (Taking Base Facts into Account - Base facts can either be taken into account or not during update processing.\n(User Participation) - User participation during update processing or not.\nUpdate Changing Mechanism\n(Type of modification) - Changing table by singleton like atom (S), sets of each types of modification(SS) and group of changes (G). (Changing Base Fact) - Base fact can be changed either using principle of minimal change or complete change (maximal change). (Changing View Definition) - Whether update process view definition is changed or not.\nObtained Solution\n(Our Axiom follow) - When update process done, we are comparing our axiomatized method and which relevance policy holds ((KB*1) to (KB*6),(KB*7.1),(KB*7.2) and (KB*7.3) is enumerated 1 to 9) (Soundness) - A method is correct if it only obtains solutions that satisfy the requested update, note NP mean Not Proved. (Completeness) - A method is complete if it is able to obtain all solutions that satisfy a given update request.\nResults of each method according to these features are summarized in Appendix."}, {"heading": "9 Belief Update Vs Database Update", "text": "In this section we give overview of how belief update is related to database update. This section is motivated by works of Hansson\u2019s (Hansson 1991) and Keller\u2019s (Keller 1985)"}, {"heading": "9.1 View update vs Database update", "text": "The view update problem exists already three decades Chen & Liao 2010 and Minker 1996. We are taking proof from Keller 1985, given a view definition of the question of choosing a view update translator arises.\nThis requires understanding the ways in which individual view update requests may be satisfied by database updates. Any particular view update request may result in a view state that does not correspond to any database state. Such a view update request may not be translated without relaxing the constraint which precludes view side effects. Otherwise, the update request is rejected by the view update translator. If we are lucky, there will be precisely one way to perform the database update that results in the desired view update. Since the view is many-to-one, the new view state may correspond to many database states. Of these database states, we would like to choose one that is \u201das close as possible\u201d, under some measure, to the original database state. That is, we would like to minimize the effect of the view update on the database."}, {"heading": "9.2 Belief update vs Database update", "text": "If we look closely to the section (6.3 and 8.1), we easily find the following results. With evidence of Hansson\u2019s (Hansson 1991) and Liberatore (Liberatore & Schaerf 2004). Here BR and BU mean Belief Revision and Belief Update, respectively."}, {"heading": "10 Abductive framework for Horn knowledge base dynamics", "text": "As discussed in Section 5, we introduced Horn knowledge base dynamics to deal with two important points: first, to handle belief states that need not be\ndeductively closed; and the second point is the ability to declare certain parts of the belief as immutable. There is yet another, radically new approach to handle this problem, and this Section addresses this. In fact, this approach is very close to the Hansson\u2019s (Hansson 1992) dyadic representation of belief. In the similar abduction model by Boutilier & Beche 1995 and Pagnucco 1996 Here, we consider the immutable part as defining a new logical system. By a logical system, we mean that it defines its own consequence relation and closure operator. Based on this, we provide an abductive framework for Horn knowledge base dynamics.\nA first order language consists of an alphabet A of a language L. We assume a countable universe of variables Var, ranged over x,y,z, and a countable universe of relation (i.e. predicate) symbols, ranged over by A are finite. The following defines FOL, the language of first order logic with equality and binary relations:\n\u03d5 ::= x = x | a(x, x) | \u00ac\u03d5 | \u2228 \u03c6 | \u2227 \u03c6 | \u2203X : \u03c6.\nHere \u03c6 \u2286 FOL and X \u2286 V ar are finite sets of formulae and variables, respectively.\nDefinition 46 (Normal Logic Program (NLP) [22]). By an alphabet A of a language L we mean disjoint sets of constants, predicate symbols, and function symbols, with at least one constant. In addition, any alphabet is assumed to contain a countably infinite set of distinguished variable symbols. A term over A is defined recursively as either a variable, a constant or an expression of the form f(t1, ..., tn) where f is a function symbol of A, n its arity, and the ti are terms. An atom over A is an expression of the form P (t1, ..., tn) where P is a predicate symbol of A and the ti are terms. A literal is either an atom A or its default negation not A. We dub default literals those of the form not A. A term (atom or literal) is said ground if it does not contain variables. The set of all ground terms (atoms) of A is called the Herbrand universe (base) of A. A Normal Logic Program is a possibly infinite set of rules (with no infinite descending chains of syntactical dependency) of the form:\nH \u2190 B1, ..., Bn, not C1, ..., not Cm, (with m, n \u2265 0)\nWhere H,Bi and Cj are atoms, and each rule stands for all its ground instances. In conformity with the standard convention, we write rules of the form H \u2190 also simply as H (known as fact). An NLP P is called definite if none of its rules contain default literals. H is the head of the rule r, denoted by head(r), and body(r) denotes the set {B1, ..., Bn, not C1, ..., not Cm} of all the literals in the body of r.\nWhen doing problem modeling with logic programs, rules of the form\n\u22a5 \u2190 B1, ..., Bn, not C1, ..., not Cm, (with m, n \u2265 0)\nwith a non-empty body are known as a type of integrity constraints (ICs), specifically denials, and they are normally used to prune out unwanted candidate solutions. We abuse the not default negation notation applying it to\nnon-empty sets of literals too: we write not S to denote {not s : s \u2208 S}, and duality of not not a \u2261 a. When S is an arbitrary, non-empty set of literals S = {B1, ..., Bn, not C1, ..., not Cm} we use:\n- S+ denotes the set {B1, . . . , Bn} of positive literals in S . - S\u2212 denotes the set {not C1, . . . , not Cm} of negative literals in S . - |S| = S+ \u222a (not S\u2212) denotes the set {B1, . . . , Bn, C1, . . . , Cm} of atoms of S.\nAs expected, we say a set of literals S is consistent iff S+ \u2229 |S\u2212| = \u2205. We also write heads(P ) to denote the set of heads of non-IC rules of a (possibly constrained) program P , i.e. heads(P ) = {head(r) : r \u2208 P}\\{\u22a5}, and facts(P ) to denote the set of facts of P - facts(P ) = {head(r) : r \u2208 P \u2227 body(r) = \u2205}.\nDefinition 47 (Level mapping[4]). Let P be a normal logic program and BP its Herbrand base. A level mapping for P is a function \u2016: BP \u2192 N of ground atoms to natural numbers. The mapping \u2016 is also extended to ground literals by assigning | \u00acA | = | A | for all ground atoms A \u2208 BP . For every ground literal L, | L | is called as the level of L in P.\nDefinition 48 (Acyclic program [4]). Let P be a normal logic program and \u2016 a level mapping for P. P is called as acyclic with respect to \u2016 if for every ground clause H \u2190 L1, ..., Ln (with n \u2265 0 and finit) in P the level of A is higher then the level of every Li (1 \u2264i\u2264 n). Moreover P is called acyclic if P is acyclic with respect to some level mapping for P.\nUnlike Horn knowledge base dynamics, where knowledge is defined as a set of sentences, here we wish to define a Horn knowledge base KB with respect to a language L, as an abductive framework < P,Ab, IC,K >, where,\n* P is an acyclic normal logic program with all abducibles in P at level 0 and no non-abducible at level 0. P is referred to as a logical system. This in conjunction with the integrity constraints corresponds to immutable part of the Horn knowledge base, here P is defined by immutable part. This is discussed further in the next subsection;\n* Ab is a set of atoms from L, called the abducibles. This notion is required in an abductive framework, and this corresponds to the atoms that may appear in the updatable part of the knowledge;\n* IC is the set of integrity constraints, a set of sentences from language L. This specifies the integrity of a Horn knowledge base and forms a part of the knowledge that can not be modified over time;\n* K is a set of sentences from L. It is the current knowledge, and the only part of KB that changes over time. This corresponds to the updatable part of the Horn knowledge base. The main requirement here is that no sentence in K can have an atom that does not appear in Ab."}, {"heading": "10.1 Logical system", "text": "The main idea of our approach is to consider the immutable part of the knowledge to define a new logical system. By a logical system, we mean that P defines its own consequence relation |=P and its closure Cnp. Given P , we have the Herbrand Base HBP and GP , the ground instantiation of P .\nAn abductive interpretation I is a set of abducibles, i.e. I \u2286 Ab. How I interprets all the ground atoms of L 4 is defined, inductively on the level of atoms with respect to P , as follows:\n* An atom A at level 0 (note that only abducibles are at level 0) is interpreted as: A is true in I iff A \u2208 I, else it is false in I. * An atom (literal) A at level n is interpreted as: A is true in I iff \u2203 clause A\u2190 L1, . . . , Ln in GP s.t. \u2200Lj (1 \u2264 j \u2264 n) if Lj is an atom then Lj is true in I, else if Lj is a negative literal \u00acBj , then Bj is false in I.\nThis interpretation of ground atoms can be extended, in the usual way, to interpret sentences in L, as follows (where \u03b1 and \u03b2 are sentences):\n* \u00ac\u03b1 is true in I iff \u03b1 is false in I. * \u03b1 \u2227 \u03b2 is true in I iff both \u03b1 and \u03b2 are true in I. * \u03b1 \u2228 \u03b2 is true in I iff either \u03b1 is true in I or \u03b2 is true in I. * \u2200\u03b1 is true in I iff all ground instantiations of \u03b1 are true in I. * \u2203\u03b1 is true in I iff some ground instantiation of \u03b1 is true in I.\nGiven a sentence \u03b1 in L, an abductive interpretation I is said to be an abductive model of \u03b1 iff \u03b1 is true in I. Extending this to a set of sentences K, I is a abductive model of K iff I is an abductive model of every sentence \u03b1 in K.\nGiven a set of sentences K and a sentence \u03b1, \u03b1 is said to be a P -consequence of K, written as K |=P \u03b1, iff every abductive model of K is an abductive model of \u03b1 also. Putting it in other words, letMod(K) be the set of all abductive models of K. Then \u03b1 is a P -consequence of K iff \u03b1 is true in all abductive interpretations in Mod(K). The consequence operator CnP is then defined as CnP (K) = {\u03b1 | K |=P \u03b1} = {\u03b1 | \u03b1 is true in all abductive interpretations in Mod(K)}. K is said to be P-consistent iff there is no expression \u03b1 s.t. \u03b1 \u2208 CnP (K) and \u00ac\u03b1 \u2208 CnP (K). Two sentences \u03b1 and \u03b2 are said to be P -equivalent to each other, written as \u03b1 \u2261 \u03b2, iff they have the same set of abductive models , i.e. Mod(\u03b1) = Mod(\u03b2)."}, {"heading": "Properties of consequences operator", "text": "Since a new consequence operator is defined, it is reasonable, to ask whether it satisfies certain properties that are required in the Horn knowledge base dynamics context. Here, we observe that all the required properties, listed by various researchers in Horn knowledge base dynamics, are satisfied by the defined consequence operator. The following propositions follow from the above definitions, and can be verified easily. 4 the set of all the ground atoms of L, in fact depends of L, and is given as HBP , the\nHerbrand Base of P\nCnP satisfies inclusion, i.e. K \u2286 CnP (K).\nCnP satisfies iteration, i.e. CnP (K) = CnP (CnP (K)).\nAnther interesting property is monotony, i.e. if K \u2286 K \u2032, then CnP (K) \u2286 CnP (K \u2032). CnP satisfies monotony. To see this, first observe that Mod(K \u2032) \u2286 Mod(K).\nCnP satisfies superclassicality , i.e. if \u03b1 can be derived from K by first order classical logic, then \u03b1 \u2208 CnP (K).\nCnP satisfies deduction , i.e. if \u03b2 \u2208 CnP (K \u222a {\u03b1}), then (\u03b2 \u2190 \u03b1) \u2208 Cn(K). CnP satisfies compactness , i.e. if \u03b1 \u2208 CnP (K), then \u03b1 \u2208 CnP (K \u2032) for some\nfinite subset K \u2032 of K.\nStatics of a Horn knowledge base The statics of a Horn knowledge base KB, is given by the current knowledge K and the integrity constraints IC. An abductive interpretation M is an abductive model of KB iff it is an abductive model of K \u222a IC. Let Mod(KB) be the set of all abductive models of KB. The belief set represented by KB, written as KB\u2022 is given as,\nKB\u2022 = CnP (K \u222a IC) = {\u03b1|\u03b1 is true in every abductive model of KB}.\nA belief (represented by a sentence in L) \u03b1 is accepted in KB iff \u03b1 \u2208 KB\u2022 (i.e. \u03b1 is true in every model of KB). \u03b1 is rejected in KB iff \u00ac\u03b1 \u2208 KB\u2022 (i.e. \u03b1 is false in every model of KB). Note that there may exist a sentence \u03b1 s.t. \u03b1 is neither accepted nor rejected in KB (i.e. \u03b1 is true in some but not all models of KB), and so KB represents a partial description of the world.\nTwo Horn knowledge bases KB1 and KB2 are said to be equivalent to each other, written as KB1 \u2261 KB2, iff they are based on the same logical system and their current knowledge are P -equivalent, i.e. P1 = P2, Ab1 = Ab2, IC1 = IC2 and K1 \u2261 K2. Obviously, two equivalent Horn knowledge bases KB1 and KB2 represent the same belief set, i.e. KB\u20221 = KB\u20222 ."}, {"heading": "10.2 Horn knowledge base dynamics", "text": "In AGM (Alchourron et al. 1985b) three kinds of belief dynamics are defined: expansion, contraction and revision. We consider all of them, one by one, in the sequel."}, {"heading": "Expansion", "text": "Let \u03b1 be new information that has to be added to a knowledge base KB. Suppose \u00ac\u03b1 is not accepted in KB. Then, obviously \u03b1 is P - consistent with IC, and KB can be expanded by \u03b1, by modifying K as follows:\nKB + \u03b1 \u2261< P,Ab, IC,K \u222a {\u03b1} >\nNote that we do not force the presence of \u03b1 in the new K, but only say that \u03b1 must be in the belief set represented by the expanded Horn knowledge base. If in case \u00ac\u03b1 is accepted in KB (in other words, \u03b1 is inconsistent with IC), then expansion of KB by \u03b1 results in a inconsistent Horn knowledge base with no abductive models, i.e. (KB + \u03b1)\u2022 is the set of all sentences in L.\nPutting it in model-theoretic terms, KB can be expanded by a sentence \u03b1, when \u03b1 is not false in all models of KB. The expansion is defined as:\nMod(KB + \u03b1) = Mod(KB) \u2229Mod(\u03b1).\nIf \u03b1 is false in all models of KB, then clearly Mod(KB+\u03b1) is empty, implying that expanded Horn knowledge base is inconsistent."}, {"heading": "Revision", "text": "As usual, for revising and contracting a Horn knowledge base, the rationality of the change is discussed first. Later a construction is provided that complies with the proposed rationality postulates."}, {"heading": "Rationality postulates", "text": "Let KB =< P,Ab, IC,K > be revised by a sentence \u03b1 to result in a new Horn knowledge base KB u \u03b1 =< P \u2032, Ab\u2032, IC \u2032,K \u2032 >. When a Horn knowledge base is revised, we do not (generally) wish to modify the underlying logical system P or the set of abducibles Ab. This is refereed to as inferential constancy by Hansson (Hansson 1991 & 1992).\n(u1) (Inferential constancy) P \u2032 = P and Ab\u2032 = Ab,IC \u2032 = IC. (u2) (Success)\u03b1 is accepted in KB u \u03b1 , i.e. \u03b1 is true in all models of KB u \u03b1. (u3) (Consistency) \u03b1 is satisfiable and P -consistent with IC iff KB u \u03b1 is Pconsistent, i.e. Mod({\u03b1} \u222a IC) is not empty iff Mod(KB u \u03b1) is not empty. (u4) (Vacuity) If \u00ac\u03b1 is not accepted in KB, then KB u \u03b1 \u2261 KB + \u03b1, i.e. if \u03b1 is not false in all models of KB, then Mod(KB u \u03b1) = Mod(KB) \u2229Mod(\u03b1). (u5) (Preservation)If KB \u2261 KB\u2032 and \u03b1 \u2261 \u03b2, then KB u \u03b1 \u2261 KB\u2032 u \u03b2, i.e. if\nMod(KB) = Mod(KB\u2032) and Mod(\u03b1) = Mod(\u03b2), then Mod(KB u \u03b1) = Mod(KB u \u03b2).\n(u6) (Extended Vacuity 1)(KB u \u03b1) + \u03b2 implies KB u (\u03b1 \u2227 \u03b2), i.e. (Mod(KB u \u03b1) \u2229Mod(\u03b2)) \u2286Mod(KB u (\u03b1 \u2227 \u03b2)). (u7) (Extended Vacuity 2)If \u00ac\u03b2 is not accepted in (KB u \u03b1), then KB u (\u03b1 \u2227 \u03b2) implies (KB u \u03b1) + \u03b2, i.e. if \u03b2 is not false in all models of KB u \u03b1, then Mod(KB u (\u03b1 \u2227 \u03b2)) \u2286 (Mod(KB u \u03b1) \u2229Mod(\u03b2))."}, {"heading": "Construction", "text": "Let S stand for the set of all abductive interpretations that are consistent with IC, i.e. S = Mod(IC). We do not consider abductive interpretations that are not models of IC, simply because IC does not change during revision. Observe that when IC is empty, S is the set of all abductive interpretations. Given a Horn\nknowledge base KB, and two abductive interpretations I1 and I2 from S, we can compare how close these interpretations are to KB by using an order \u2264KB among abductive interpretations in S. I1 <KB I2 iff I1 \u2264KB I2 and I2 KB I1.\nLet F \u2286 S. An abductive interpretation I \u2208 F is minimal in F with respect to \u2264KB if there is no I \u2032 \u2208 F s.t. I \u2032 <KB I. Let, Min(F ,\u2264KB) = {I | I is minimal in F with respect to \u2264KB}.\nFor any Horn knowledge base KB, the following are desired properties of \u2264KB :\n(\u2264 1) (Pre-order)\u2264KB is a pre-order , i.e. it is transitive and reflexive. (\u2264 2) (Connectivity)\u2264KB is total in S, i.e. \u2200I1, I2 \u2208 S: either I1 \u2264KB I2 or I2 \u2264KB I1. (\u2264 3) (Faithfulness)\u2264KB is faithful to KB, i.e. I \u2208Min(S,\u2264KB) iff I \u2208Mod(KB). (\u2264 4) (Minimality)For any non-empty subset F of S, Min(F ,\u2264KB) is not empty. (\u2264 5) (Preservance)] For any Horn knowledge base KB\u2019, if KB \u2261 KB\u2032 then\n\u2264KB=\u2264KB\u2032 .\nLet KB (and consequently K) be revised by a sentence \u03b1, and \u2264KB be a rational order that satisfies (\u2264 1) to (\u2264 5). Then the abductive models of the revised Horn knowledge base are given precisely by: Min(Mod({\u03b1}\u222aIC),\u2264KB). Note that, this construction does not say what the resulting K is, but merely says what should be the abductive models of the new Horn knowledge base."}, {"heading": "Representation theorem", "text": "Now, we proceed to show that revision of KB by \u03b1, as constructed above, satisfies all the rationality postulates stipulated in the beginning of this section. This is formalized by the following lemma.\nLemma 8. Let KB be a Horn knowledge base, \u2264KB an order among S that satisfies (\u2264 1) to (\u2264 5). Let a revision operator u be defined as: for any sentence \u03b1, Mod(KB u \u03b1) = Min(Mod({\u03b1} \u222a IC),\u2264KB). Then u satisfies all the rationality postulates for revision (u1) to (u7).\nProof.(u1) P \u2032 = P and Ab\u2032 = Ab and IC \u2032 = IC This is satisfied obviously, since our construction does not touch P and Ab, and IC follows from every abductive interpretation in Mod(KB u \u03b1). (u2) \u03b1 is accepted in KB u \u03b1 Note that every abductive interpretation M \u2208 Mod(KB + \u03b1) is a model of \u03b1. Hence \u03b1 is accepted in KB u \u03b1. (u3) \u03b1 is satisfiable and P -consistent with IC iff KB u \u03b1 is P -consistent. If part: If KB u \u03b1 is P -consistent , then Mod(KB u \u03b1) is not empty. This implies that Mod({\u03b1} \u222a IC) is not empty, and hence \u03b1 is satisfiable and P -consistent with IC. Only if part: If \u03b1 is satisfiable and P-consistent with IC, then Mod({\u03b1}\u222aIC) is not empty, and (\u2264 4) ensures that Mod(KB u \u03b1) is not empty. Thus, KB u \u03b1 is P -consistent.\n(u4) If \u00ac\u03b1 is not accepted in KB, then KB u \u03b1 \u2261 KB + \u03b1. We have to establish thatMin(Mod({\u03b1}\u222aIC),\u2264KB) = Mod(KB)\u2229Mod(\u03b1). Since \u00ac\u03b1 is not accepted in KB, Mod(KB)\u2229Mod(\u03b1) is not empty. The required result follows immediately from the fact that \u2264KB is faithful to KB (i.e. satisfies \u2264 3), which selects only and all those models of \u03b1 which are also models of KB. (u5) If KB \u2261 KB\u2032 and \u03b1 \u2261 \u03b2 then KB u \u03b1 = KB\u2032 u \u03b2 (\u2264 5) ensures that \u2264KB=\u2264KB\u2032 . The required result follows immediately from this and the fact that Mod(\u03b1) = Mod(\u03b2). (u6) (KB u \u03b1) + \u03b2 implies KB u (\u03b1 \u2227 \u03b2). We consider this in two cases. When \u00ac\u03b2 is accepted in KBu\u03b1, (KBu\u03b1)+\u03b2 is the set of all sentences from L, and the postulate follows immediately. Instead when \u00ac\u03b2 is not accepted in KB u \u03b1, this postulates coincides with the next one. (u7) If \u00ac\u03b2 is not accepted in KB u \u03b1, then KB u (\u03b1 \u2227 \u03b2) implies (KB u \u03b1) + \u03b2. Together with the second case of previous postulate, we need to show that KB u (\u03b1 \u2227 \u03b2) = (KB u \u03b1) + \u03b2. In other words, we have to establish that Min(Mod({\u03b1 \u2227 \u03b2} \u222a IC),\u2264KB) = Mod(KB u \u03b1) \u2229Mod(\u03b2). For the sake of simplicity, let us represent Min(Mod({\u03b1 \u2227 \u03b2} \u222a IC),\u2264KB) by P, and Mod(KB u \u03b1) \u2229Mod(\u03b2), which is the same as Min(Mod({\u03b1} \u222a IC),\u2264KB ) \u2229Mod(\u03b2), by Q. The required result is obtained in two parts:\n1) \u2200 (abductive interpretation)M: if M \u2208 P , then M \u2208 Q Obviously M \u2208 Mod(\u03b2). Assume that M < Min(Mod({\u03b1} \u222a IC),\u2264KB). This can happen in two cases, and we show that both the cases lead to contradiction. Case A: No model of \u03b2 is selected by \u2264KB from Mod({\u03b1} \u222a IC). But this contradicts our initial condition that \u00ac\u03b2 is not accepted in KB u \u03b1. Case B: Some model, say M \u2032, of \u03b2 is selected by \u2264KB from Mod({\u03b1}\u222a IC). Since M is not selected, it follows that M \u2032 <KB M . But then this contradicts our initial assumption that M \u2208 P . So, P \u2286 Q. 2) \u2200 (abductive interpretation)M: if M \u2208 Q, then M \u2208 P M \u2208 Q implies that M is a model of both \u03b1 and \u03b2, and M is selected by \u2264KB from Mod({\u03b1}\u222aIC). Note that Mod({\u03b1\u2227\u03b2}\u222aIC) \u2286Mod({\u03b1}\u222aIC). Since M is selected by \u2264KB in a bigger set (i.e. Mod({\u03b1}\u222aIC)), \u2264KB must select M from its subset Mod({\u03b1 \u2227 \u03b2} \u222a IC) also. Hence Q \u2286 P .\nBut, that is not all. Any rational revision of KB by \u03b1, that satisfies all the rationality postulates, can be constructed by our construction method, and this is formalized below.\nLemma 9. Let KB be a Horn knowledge base and u a revision operator that satisfies all the rationality postulates for revision (u1) to (u7). Then, there exists an order \u2264KB among S, that satisfies (\u2264 1) to (\u2264 5), and for any sentence \u03b1, Mod(KB u \u03b1) is given in Min(Mod({\u03b1} \u222a IC),\u2264KB).\nProof. Let us construct an order \u2264KB among interpretations in S as follows: For any two abductive interpretations I and I \u2032 in S, define I \u2264KB I \u2032 iff either\nI \u2208 Mod(KB) or I \u2208 Mod(KB u form(I, I \u2032)), where form(I, I \u2032) stands for sentence whose only models are I and I \u2032. We will show that \u2264KB thus constructed satisfies (\u2264 1) to (\u2264 5) and Min(Mod({\u03b1} \u222a IC),\u2264KB) = Mod(KB u \u03b1).\nFirst, we show that Min(Mod({\u03b1} \u222a IC),\u2264KB) = Mod(KB u \u03b1).Suppose \u03b1 is not satisfiable, i.e. Mod(\u03b1) is empty, or \u03b1 does not satisfy IC, then there are no abductive models of {\u03b1} \u222a IC, and hence Min(Mod({\u03b1} \u222a IC),\u2264KB) is empty. From (u3), we infer that Mod(KB u \u03b1) is also empty. When \u03b1 is satisfiable and \u03b1 satisfies IC, the required result is obtained in two parts:\n1) If I \u2208Min(Mod({\u03b1} \u222a IC),\u2264KB), then I \u2208Mod(KB u \u03b1) Since \u03b1 is satisfiable and consistent with IC, (u3) implies that there exists at least one model, say I \u2032, for KBu\u03b1. From (u1), it is clear that I \u2032 is a model of IC, from (u2) we also get that I \u2032 is a model of \u03b1, and consequently I \u2264KB I \u2032 (because I \u2208 Min(Mod({\u03b1} \u222a IC),\u2264KB)). Suppose I \u2208 Mod(KB), then (u4) immediately gives I \u2208 Mod(KB u \u03b1). If not, from our definition of \u2264KB, it is clear that I \u2208Mod(KBuform(I, I \u2032)). Note that \u03b1\u2227form(I, I \u2032) \u2261 form(I, I \u2032), since both I and I \u2032 are models of \u03b1. From (u6) and (u7), we get Mod(KBu\u03b1)\u2229{I, I \u2032} = Mod(KBuform(I, I \u2032)). Since I \u2208Mod(KBu form(I, I \u2032)), it immediately follows that I \u2208Mod(KB u \u03b1). 2) If I \u2208Mod(KB u \u03b1), then I \u2208Min(Mod({\u03b1} \u222a IC),\u2264KB). From (u1) we get I is a model of IC, and from (u2), we obtain I \u2208Mod(\u03b1). Suppose I \u2208 Mod(KB), then from our definition of \u2264KB, we get I \u2264KB I \u2032, for any other model I \u2032 of \u03b1 and IC, and hence I \u2208 Min(Mod({\u03b1} \u222a IC),\u2264KB). Instead, if I is not a model of KB, then, to get the required result, we should show that I \u2208Mod(KB u form(I, I \u2032)), for every model I \u2032 of \u03b1 and IC. As we have observed previously, from (u6) and (u7), we get Mod(KBu\u03b1)\u2229{I, I \u2032} = Mod(KBuform(I, I \u2032)). Since I \u2208Mod(KBu\u03b1), it immediately follows that I \u2208Mod(KBuform(I, I \u2032)). Hence I \u2264KB I \u2032 for any model I \u2032 of \u03b1 and IC, and consequently, I \u2208Min(Mod({\u03b1}\u222aIC),\u2264KB ).\nNow we proceed to show that the order \u2264KB among S, constructed as per our definition, satisfies all the rationality axioms (\u2264 1) to (\u2264 5).\n(\u2264 1) \u2264KB is a pre-order. Note that we need to consider only abductive interpretations from S. From (u2) and (u3), we have Mod(KB u form(I, I \u2032)) = {I}, and so I \u2264KB I. Thus \u2264KB satisfies reflexivity. let I1 \u2208 Mod(IC) and I2 < Mod(IC). Clearly, it is possible that two interpretations I1 and I2 are not models of KB, and Mod(KB u form(I1, I2)) = {I1}. So, I1 \u2264KB I2 does not necessarily imply I2 \u2264KB I1, and thus \u2264KB satisfies anti-symmetry. To show the transitivity, we have to prove that I1 \u2264KB I3, when I1 \u2264KB I2 and I2 \u2264KB I3 hold. Suppose I1 \u2208Mod(KB), then I1 \u2264KB I3 follows immediately from our definition of \u2264KB. On the other case, when I1 <Mod(KB), we first observe that I1 \u2208Mod(KBuform(I1, I2)), which follows from definition of \u2264KB and I1 \u2264KB I2. Also observe that I2 <Mod(KB). If I2 were\na model of KB, then it follows from (u4) that Mod(KB u form(I1, I2)) = Mod(KB)\u2229{I1, I2} = {I2}, which is a contradiction, and so I2 <Mod(KB). This, together with I2 \u2264KB I3, implies that I2 \u2208 Mod(KB u form(I2, I3)). Now consider Mod(KB+ form(I1, I2, I3)). Since u satisfies (u2) and (u3), it follows that this is a non-empty subset of {I1, I2, I3}. We claim that Mod(KB u form(I1, I2, I3))\u2229{I1, I2} can not be empty. If it is empty, then it means that Mod(KB u form(I1, I2, I3)) = {I3}. Since u satisfies (u6) and (u7), this further implies that Mod(KB u form(I2, I3)) = Mod(KB u form(I1, I2, I3))\u2229{I2, I3} = {I3}. This contradicts our observation that I2 \u2208 Mod(KBuform(I2, I3)), and so Mod(KBuform(I1, I2, I3))\u2229{I1, I2} can not be empty. Using (u6) and (u7) again, we get Mod(KBuform(I1, I2)) = Mod(KB u form(I1, I2, I3))\u2229{I1, I2}. Since we know that I1 \u2208Mod(KB u form(I1, I2)), it follows that I1 \u2208 Mod(KB u form(I1, I2, I3)). From (u6) and (u7) we also get Mod(KBuform(I1, I3)) = Mod(KB+form(I1, I2, I3))\u2229 {I1, I3}, which clearly implies that I1 \u2208Mod(KB u form(I1, I3)). From our definition of \u2264KB, we now obtain I1 \u2264KB I3. Thus, \u2264KB is a pre-order.\n(\u2264 2) \u2264KB is total. Since u satisfies (u2) and (u3), for any two abductive interpretations I and I \u2032 in S, it follows that Mod(KB u form(I, I \u2032)) is a non-empty subset of {I, I \u2032}. Hence, \u2264KB is total. (\u2264 3) \u2264KB is faithful to KB. From our definition of \u2264KB, it follows that \u2200I1, I2 \u2208Mod(KB) : I1 <KB I2 does not hold. Suppose I1 \u2208 Mod(KB) and I2 < Mod(KB). Then, we have I1 \u2264KB I2. Since u satisfies (u4), we also have Mod(KB u form(I1, I2)) = {I1}. Thus, from our definition of \u2264KB, we can not have I2 \u2264KB I1. So, if I1 \u2208 Mod(KB) and I2 < Mod(KB), then I1 <KB I2 holds. Thus, \u2264KB is faithful to KB.\n(\u2264 4) For any non-empty subset F of S, Min(F ,\u2264KB) is not empty. Let \u03b1 be a sentence such that Mod({\u03b1} \u222a IC) = F . We have already shown that Mod(KB u \u03b1) = Min(F ,\u2264KB). Since, u satisfies (u3), it follows that Mod(KB u \u03b1) is not empty, and thus Min(F ,\u2264KB) is not empty. (\u2264 5) If KB \u2261 KB\u2032, then \u2264KB=\u2264KB\u2032 . This follows immediately from the fact that u satisfies (u5).\nThus, the order among interpretations \u2264KB , constructed as per our definition, satisfies (\u2264 1) to (\u2264 5), and Mod(KB u\u03b1) = Min(Mod({\u03b1}\u222a IC),\u2264KB).\nSo, we have a one to one correspondence between the axiomatization and the construction, which is highly desirable, and this is summarized by the following representation theorem.\nTheorem 17. Let KB be revised by \u03b1, and KB u \u03b1 be obtained by the construction discussed above. Then, u is a revision operator iff it satisfies all the rationality postulates (u1) to (u7).\nProof. Follows from Lemma 8 and Lemma 9"}, {"heading": "Contraction", "text": "Contraction of a sentence from a Horn knowledge base KB is studied in the same way as that of revision. We first discuss the rationality of change during contraction and proceed to provide a construction for contraction using duality between revision and contraction."}, {"heading": "Rationality Postulates", "text": "Let KB =< P,Ab, IC,K > be contracted by a sentence \u03b1 to result in a new Horn knowledge base KB\u2212\u0307\u03b1 =< P \u2032, Ab\u2032, IC \u2032,K \u2032 >.\n(\u2212\u03071) (Inferential Constancy)P \u2032 = P and Ab\u2032 = Ab and IC \u2032 = IC. (\u2212\u03072) (Success)If \u03b1 < CnP (KB), then \u03b1 is not accepted in KB\u2212\u0307\u03b1, i.e. if \u03b1 is not\ntrue in all the abductive interpretations, then \u03b1 is not true in all abductive interpretations in Mod(KB\u2212\u0307\u03b1).\n(\u2212\u03073) (Inclusion)\u2200 (belief) \u03b2:if \u03b2 is accepted in KB\u2212\u0307\u03b1, then \u03b2 is accepted in KB, i.e. Mod(KB) \u2286Mod(KB\u2212\u0307\u03b1). (\u2212\u03074) (Vacuity)If \u03b1 is not accepted in KB, then KB\u2212\u0307\u03b1 = KB, i.e. if \u03b1 is not true in all the abductive models of KB, then Mod(KB\u2212\u0307\u03b1) = Mod(KB). (\u2212\u03075) (Recovery)(KB\u2212\u0307\u03b1)+\u03b1 impliesKB, i.e.Mod(KB\u2212\u0307\u03b1)\u2229Mod(\u03b1) \u2286Mod(KB). (\u2212\u03076) (Preservation)If KB \u2261 KB\u2032 and \u03b1 \u2261 \u03b2, then KB\u2212\u0307\u03b1 = KB\u2032\u2212\u0307\u03b2, i.e. if\nMod(KB) = Mod(KB\u2032) and Mod(\u03b1) = Mod(\u03b2), then Mod(KB\u2212\u0307\u03b1) = Mod(KB\u2032\u2212\u0307\u03b2).\n(\u2212\u03077) (Conjunction 1) KB\u2212\u0307(\u03b1\u2227 \u03b2) implies KB\u2212\u0307\u03b1\u2229KB\u2212\u0307\u03b2, i.e. Mod(KB\u2212\u0307(\u03b1\u2227 \u03b2)) \u2286Mod(KB\u2212\u0307\u03b1) \u222aMod(KB\u2212\u0307\u03b2). (\u2212\u03078) (Conjunction 2)If \u03b1 is not accepted in KB\u2212\u0307(\u03b1 \u2227 \u03b2), then KB\u2212\u0307\u03b1 implies KB\u2212\u0307(\u03b1 \u2227 \u03b2), i.e. if \u03b1 is not true in all the models of KB\u2212\u0307(\u03b1 \u2227 \u03b2), then Mod(KB\u2212\u0307\u03b1) \u2286Mod(KB\u2212\u0307(\u03b1 \u2227 \u03b2)).\nBefore providing a construction for contraction, we wish to study the duality between revision and contraction. The Levi and Harper identities still holds in our case, and is discussed in the sequel.\nRelationship between contraction and revision Contraction and revision are related to each other. Given a contraction function \u2212\u0307, a revision function u can be obtained as follows:\n(Levi Identity) Mod(KB u \u03b1) = Mod(KB\u2212\u0307\u00ac\u03b1) \u2229Mod(\u03b1)\nThe following theorem formally states that Levi identity holds in our approach.\nTheorem 18. Let \u2212\u0307 be a contraction operator that satisfies all the rationality postulates (\u2212\u03071) to (\u2212\u03078). Then, the revision function u, obtained from \u2212\u0307 using the Levi Identity, satisfies all the rationality postulates (u1) to (u7).\nProof. Let KB =< P,Ab, IC,K > be contracted by a sentence \u03b1 to result in a new Horn knowledge base KB\u2212\u0307\u03b1 =< P \u2032, Ab\u2032, IC \u2032,K \u2032 >.\n(u1) (Inferential constancy) P \u2032 = P and Ab\u2032 = Ab,IC \u2032 = IC. (u2) (Success)\u03b1 is accepted inKBu\u03b1 , i.e. \u03b1 is true in all models of (Mod(KB\u2212\u0307\u00ac\u03b1)\u2229 Mod(\u03b1)). (u3) (Consistency) \u03b1 is satisfiable and P -consistent with IC iff KB u \u03b1 is P-\nconsistent, i.e. (Mod({\u03b1} \u222a IC)) is not empty iff Mod(KB\u2212\u0307\u00ac\u03b1) \u2229Mod(\u03b1) is not empty.\n(u4) (Vacuity) If \u00ac\u03b1 is not accepted in KB, then KB u \u03b1 \u2261 KB + \u03b1, i.e. if \u03b1 is not false in all models of KB, then (Mod(KB u \u03b1)) = (Mod(KB\u2212\u0307\u00ac\u03b1) \u2229 Mod(\u03b1)) \u2229Mod(\u03b1) (u5) (Preservation)If KB \u2261 KB\u2032 and \u03b1 \u2261 \u03b2, then KB u \u03b1 \u2261 KB\u2032 u \u03b2, i.e. if Mod(KB) = Mod(KB\u2032) and Mod(\u03b1) = Mod(\u03b2), then (Mod(KB\u2212\u0307\u00ac\u03b1) \u2229 Mod(\u03b1)) = (Mod(KB\u2212\u0307\u00ac\u03b2) \u2229Mod(\u03b2)). (u6) (Extended Vacuity 1)(KB u \u03b1) + \u03b2 implies ((KB\u2212\u0307\u00ac\u03b1) \u2229 (\u03b1)) \u2227 \u03b2), i.e. (Mod(KB u \u03b1) \u2229Mod(\u03b2)) \u2286Mod(KB u (\u03b1 \u2227 \u03b2)). (u7) (Extended Vacuity 2)If \u00ac\u03b2 is not accepted in (KB u \u03b1), then ((KB\u2212\u0307\u00ac\u03b1) \u2229 (\u03b1))\u2227 \u03b2) implies (KB u\u03b1) + \u03b2, i.e. if \u03b2 is not false in all models of KB u\u03b1, then Mod(KB u (\u03b1 \u2227 \u03b2)) \u2286 (Mod(KB u \u03b1) \u2229Mod(\u03b2)).\nSimilarly, a contraction function \u2212\u0307 can be constructed using the given revision function u as follows:\n(Harper Identity) Mod(KB\u2212\u0307\u03b1) = Mod(KB) \u222aMod(KB u \u00ac\u03b1)\nTheorem 19. Let u be a revision operator that satisfies all the rationality postulates (u1) to (u7). Then, the contraction function \u2212\u0307, obtained from u using the Harper Identity, satisfies all the rationality postulates (\u2212\u03071) to (\u2212\u03078).\nProof. Let KB =< P,Ab, IC,K > be contracted by a sentence \u03b1 to result in a new Horn knowledge base KB\u2212\u0307\u03b1 =< P \u2032, Ab\u2032, IC \u2032,K \u2032 >.\n(\u2212\u03071) (Inferential Constancy)P \u2032 = P and Ab\u2032 = Ab and IC \u2032 = IC. (\u2212\u03072) (Success)If \u03b1 < CnP (KB), then \u03b1 is not accepted in KB\u2212\u0307\u03b1, i.e. if \u03b1 is not\ntrue in all the abductive interpretations, then \u03b1 is not true in all abductive interpretations in Mod(KB) \u222aMod(KB u \u00ac\u03b1).\n(\u2212\u03073) (Inclusion)\u2200 (belief) \u03b2:if \u03b2 is accepted in KB\u2212\u0307\u03b1, then \u03b2 is accepted in KB, i.e. Mod(KB) \u2286 (Mod(KB) \u222aMod(KB u \u00ac\u03b1)). (\u2212\u03074) (Vacuity)If \u03b1 is not accepted in KB, then KB\u2212\u0307\u03b1 = KB, i.e. if \u03b1 is not true in all the abductive models of KB, then Mod(KB\u2212\u0307\u03b1) = Mod(KB). (\u2212\u03075) (Recovery)(KB\u2212\u0307\u03b1)+\u03b1 impliesKB, i.e. (Mod(KB\u2212\u0307\u03b1)\u2229Mod(\u03b1)) \u2286Mod(KB). (\u2212\u03076) (Preservation)If KB \u2261 KB\u2032 and \u03b1 \u2261 \u03b2, then KB\u2212\u0307\u03b1 = KB\u2032\u2212\u0307\u03b2, i.e.\nif Mod(KB) = Mod(KB\u2032) and Mod(\u03b1) = Mod(\u03b2), then (Mod(KB) \u222a Mod(KB u \u00ac\u03b1)) = (Mod(KB) \u222aMod(KB u \u00ac\u03b2)).\n(\u2212\u03077) (Conjunction 1) KB\u2212\u0307(\u03b1\u2227 \u03b2) implies KB\u2212\u0307\u03b1\u2229KB\u2212\u0307\u03b2, i.e. Mod(KB\u2212\u0307(\u03b1\u2227 \u03b2)) \u2286 (Mod(KB) \u222aMod(KB u \u00ac\u03b1)) \u222a (Mod(KB) \u222aMod(KB u \u00ac\u03b2)). (\u2212\u03078) (Conjunction 2)If \u03b1 is not accepted in KB\u2212\u0307(\u03b1 \u2227 \u03b2), then KB\u2212\u0307\u03b1 implies KB\u2212\u0307(\u03b1 \u2227 \u03b2), i.e. if \u03b1 is not true in all the models of KB\u2212\u0307(\u03b1 \u2227 \u03b2), then (Mod(KB) \u222aMod(KB u \u00ac\u03b1)) \u2286Mod(KB\u2212\u0307(\u03b1 \u2227 \u03b2))."}, {"heading": "Construction", "text": "Given the construction for revision, based on order among interpretation in S, a construction for contraction can be provided as:\nMod(KB\u2212\u0307\u03b1) = Mod(KB) \u222aMin(Mod({\u00ac\u03b1} \u222a IC),\u2264KB), where \u2264KB is the relation among interpretations in S that satisfies the rationality axioms (\u2264 1) to (\u2264 5). As in the case of revision, this construction says what should be the models of the resulting Horn knowledge base, and does not explicitly say what the resulting Horn knowledge base is."}, {"heading": "Representation theorem", "text": "Since the construction for contraction is based on a rational contraction for revision, the following lemma and theorem follow obviously. Lemma 10. Let KB be a Horn knowledge base, \u2264KB an order among S that satisfies (\u2264 1) to (\u2264 5). Let a contraction operator \u2212\u0307 be defined as: for any sentence \u03b1, Mod(KB\u2212\u0307\u03b1) = Mod(KB) \u222aMin(Mod({\u00ac\u03b1} \u222a IC),\u2264KB). Then \u2212\u0307 satisfies all the rationality postulates for contraction (\u2212\u03071) to (\u2212\u03078). Proof. Follows from Theorem 17 and Theorem 19 Lemma 11. Let KB be a Horn knowledge base and \u2212\u0307 a contraction operator that satisfies all the rationality postulates for contraction (\u2212\u03071) to (\u2212\u03078). Then, there exists an order \u2264KB among S, that satisfies(\u2264 1) to (\u2264 5), and for any sentence \u03b1, Mod(KB\u2212\u0307\u03b1) is given as Mod(KB)\u222aMin(Mod({\u00ac\u03b1}\u222aIC),\u2264KB). Proof. Follows from Theorem 18 and Theorem 19. Theorem 20. Let KB be contracted by \u03b1, and KB\u2212\u0307\u03b1 be obtained by the construction discussed above. Then \u2212\u0307 is a contraction operator iff it satisfies all the rationality postulates (\u2212\u03071) to (\u2212\u03078). Proof. Follows from Lemma 10 and Lemma 11"}, {"heading": "10.3 Relationship with the coherence approach of AGM", "text": "Given Horn knowledge base KB =< P,Ab, IC,K > represents a belief set KB\u2022 that is closed under CnP . We have defined how KB can be expanded, revised, or contracted. The question now is: does our foundational approach (with respect to classical first-order logic) on KB coincide with coherence approach (with respect to our consequence operator CnP ) of AGM on KB\u2022? There is a problem in answering this question (similar practical problem Baral & Zhang 2005) , since our approach, we require IC to be immutable, and only the current knowledge K is allowed to change. On the contrary, AGM approach treat every sentence in KB\u2022 equally, and can throw out sentences from CnP (IC). One way to solve this problem is to assume that sentences in CnP (IC) are more entrenched than others. However, one-to-one correspondence can be established, when IC is empty. The key is our consequence operator CnP , and in the following, we show that coherence approach of AGM with this consequence operator, is exactly same as our foundational approach, when IC is empty."}, {"heading": "Expansion", "text": "Expansion inAGM (Alchourron et al. 1985b) framework is defined asKB#\u03b1 = CnP (KB\u2022 \u222a {\u03b1}), is is easy to see that this is equivalent to our definition of expansion (when IC is empty), and is formalized below.\nTheorem 21. Let KB + \u03b1 be an expansion of KB by \u03b1. Then (KB + \u03b1)\u2022 = KB#\u03b1.\nProof. By our definition of expansion, (KB+\u03b1)\u2022 = CnP (IC \u222aK \u222a{\u03b1}), which is clearly the same set as CnP (KB\u2022 \u222a {\u03b1})."}, {"heading": "Revision", "text": "AGM puts forward rationality postulates (\u22171) to (\u22178) to be satisfied by a revision operator on KB\u2022. reproduced below:\n(*1) (Closure) KB\u2022 \u2217 \u03b1 is a belief set. (*2) (Success) \u03b1 \u2208 KB\u2022 \u2217 \u03b1. (*3) (Expansion 1) KB\u2022 \u2217 \u03b1 \u2286 KB\u2022#\u03b1. (*4) (Expansion 2) If \u00ac\u03b1 < KB\u2022, then KB\u2022#\u03b1 \u2286 KB\u2022 \u2217 \u03b1. (*5) (Consistency)KB\u2022 \u2217 \u03b1 is inconsistent iff ` \u00ac\u03b1. (*6) (Preservation) If ` \u03b1\u2194 \u03b2, then KB\u2022 \u2217 \u03b1 = KB\u2022 \u2217 \u03b2. (*7) (Conjunction 1) KB\u2022 \u2217 (\u03b1 \u2227 \u03b2) \u2286 (KB\u2022 \u2217 \u03b1)#\u03b2. (*8) (Conjunction 2) If \u00ac\u03b2 < KB\u2022 \u2217 \u03b1, then,(KB\u2022 \u2217 \u03b1)#\u03b2 \u2286 KB\u2022 \u2217 (\u03b1 \u2227 \u03b2).\nThe equivalence between our approach and AGM approach is brought out by the following two theorems.\nTheorem 22. Let KB a Horn knowledge base with an empty IC and u be a revision function that satisfies all the rationality postulates (u1) to (u7). Let a revision operator \u2217 on KB\u2022 be defined as: for any sentence \u03b1, KB\u2022 \u2217 \u03b1 = (KBu\u03b1)\u2022. The revision operator *, thus defined satisfies all the AGM -postulates for revision (\u22171) to (\u22178).\nProof.\n(*1) KB\u2022 \u2217 \u03b1 is a belief set. This follows immediately, because (KB u \u03b1)\u2022 is closed with respect to CnP . (*2) \u03b1 \u2208 KB\u2022 \u2217 \u03b1. This follows from the fact that u satisfies (u2). (*3) KB\u2022 \u2217 \u03b1 \u2286 KB\u2022#\u03b1.\n(*4) If \u00ac\u03b1 < KB\u2022, then KB\u2022#\u03b1 \u2286 KB\u2022 \u2217 \u03b1. These two postulates follow from (u4) and theorem 21. (*5) KB\u2022 \u2217 \u03b1 is inconsistent iff ` \u00ac\u03b1. This follows from from (u3) and our assumption that IC is empty. (*6) If ` \u03b1\u2194 \u03b2, then KB\u2022 \u2217 \u03b1 = KB\u2022 \u2217 \u03b2. This corresponds to (u5). (*7) KB\u2022 \u2217 (\u03b1 \u2227 \u03b2) \u2286 (KB\u2022 \u2217 \u03b1)#\u03b2. This follows from (u6) and theorem 21.\n(*8) If \u00ac\u03b2 < KB\u2022 \u2217 \u03b1, then,(KB\u2022 \u2217 \u03b1)#\u03b2 \u2286 KB\u2022 \u2217 (\u03b1 \u2227 \u03b2). This follows from (u7) and theorem 21\nTheorem 23. Let KB a Horn knowledge base with an empty IC and * a revision operator that satisfies all the AGM -postulates (\u22171) to (\u22178). Let a revision function + on KB be defined as: for any sentence \u03b1, (KB u \u03b1)\u2022 = KB\u2022 \u2217 \u03b1. The revision function +, thus defined, satisfies all the rationality postulates (u1) to (u7).\nProof.\n(u1) P,Ab and IC do not change. Obvious. (u2) \u03b1 is accepted in KB u \u03b1. Follows from (\u22172). (u3) If \u03b1 is satisfiable and consistent with IC, then KB u \u03b1 is consistent. Since we have assumed IC to be empty, this directly corresponds to (\u22175). (u4) If \u00ac\u03b1 is not accepted in KB, then KB u \u03b1 \u2261 KB + \u03b1. Follows from (\u22173) and (\u22174). (+5) If KB \u2261 KB\u2032 and \u03b1 \u2261 \u03b2, then KB u \u03b1 \u2261 KB\u2032 u \u03b2. Since KB \u2261 KB\u2032 they represent same belief set, i.e. KB\u2022 = KB\u2032\u2022. Now, this postulate follows immediately from (\u22176). (u6) (KB u \u03b1) + \u03b2 implies KB u (\u03b1 \u2227 \u03b2). Corresponds to (\u22177). (u7) If \u00ac\u03b2 is not accepted in KB u \u03b1, then KB u (\u03b1 \u2227 \u03b2) implies (KB u \u03b1) + \u03b2. Corresponds to (\u22178)."}, {"heading": "Contraction", "text": "AGM puts forward rationality postulates (\u22121) to (\u22128) to be satisfied by a contraction operator on closed set KB\u2022, reproduced below:\n(\u22121) (Closure) KB\u2022 \u2212 \u03b1 is a belief set. (\u22122) (Inclusion) KB\u2022 \u2212 \u03b1 \u2286 KB\u2022. (\u22123) (Vacuity) If \u03b1 < KB\u2022, then KB\u2022 \u2212 \u03b1 = KB\u2022. (\u22124) (Success) If 0 \u03b1, then \u03b1 < KB\u2022 \u2212 \u03b1. (\u22125) (Preservation) If ` \u03b1\u2194 \u03b2, then KB\u2022 \u2212 \u03b1 = KB\u2022 \u2212 \u03b2. (\u22126) (Recovery) KB\u2022 \u2282 (KB\u2022 \u2212 \u03b1) + \u03b1. (\u22127) (Conjunction 1)KB\u2022 \u2212 \u03b1 \u2229KB\u2022 \u2212 \u03b2 \u2286 KB\u2022 \u2212 (\u03b1 \u2227 \u03b2). (\u22128) (Conjunction 2) If \u03b1 < KB\u2022 \u2212 (\u03b1 \u2227 \u03b2), then KB\u2022 \u2212 (\u03b1 \u2227 \u03b2) \u2286 KB\u2022 \u2212 \u03b1.\nAs in the case of revision, the equivalence is brought out by the following theorems. Since contraction is constructed in terms of revision, these theorems are trivial.\nCorollary 1. Let KB be a Horn knowledge base with an empty IC and \u2212\u0307 be a contraction function that satisfies all the rationality postulates (\u2212\u03071) to (\u2212\u03078). Let a contraction operator \u2212 on KB\u2022 be defined as: for any sentence \u03b1, KB\u2022\u2212\u03b1 = (KB\u2212\u0307\u03b1)\u2022. The contraction operator \u2212, thus defined, satisfies all the AGM - postulates for contraction (\u22121) to (\u22128).\nProof. Follows from Theorem 18 and Theorem 22\nCorollary 2. Let KB be a Horn knowledge base with an empty IC and \u2212 be a contraction operator that satisfies all the AGM - postulates (\u22121) to (\u22128). Let a contraction function \u2212\u0307 on KB be defined as: for any sentence \u03b1, (KB\u2212\u0307\u03b1)\u2022 = KB\u2022 \u2212 \u03b1. The contraction function \u2212\u0307, thus defined, satisfies all the rationality postulates (\u2212\u03071) to (\u2212\u03078).\nProof. Follows from Theorem 19 and Theorem 23"}, {"heading": "10.4 Realizing Horn knowledge base dynamics using abductive explanations", "text": "In this section, we explore how belief dynamics can be realized in practice (see (Aravindan & Dung 1994), (Aravindan 1995) and (Bessant et al. 1998)). Here, we will see how revision can be implemented based on the construction using models of revising sentence and an order among them. The notion of abduction proves to be useful and is explained in the sequel.\nLet \u03b1 be a sentence in L. An abductive explanation for \u03b1 with respect to KB is a set of abductive literals 5 \u2206 s.t. \u2206 consistent with IC and \u2206 |=P \u03b1 (that is \u03b1 \u2208 CnP (\u2206)). Further \u2206 is said to be minimal iff no proper subset of \u2206 is an abductive explanation for \u03b1.\nThe basic idea to implement revision of a Horn knowledge base KB by a sentence \u03b1, is to realize Mod({\u03b1} \u222a IC) in terms of abductive explanations for \u03b1 with respect to KB. We first provide a useful lemma.\nDefinition 49. Let KB be a Horn knowledge base, \u03b1 a sentence, and \u22061 and \u22062 be two minimal abductive explanations for \u03b1 with respect to KB. Then, the disjunction of \u22061 and \u22062, written as \u22061 \u2228\u22062, is given as:\n\u22061 \u2228\u22062 = (\u22061 \u2229\u22062) \u222a {\u03b1 \u2228 \u03b2|\u03b1 \u2208 \u22061\\\u22062 and \u03b2 \u2208 \u22062\\\u22061}.\nExtending this to \u2206\u2022, a set of minimal abductive explanations for \u03b1 with respect to KB, \u2228\u2206\u2022 is given by the disjunction of all elements of \u2206\u2022.\nLemma 12. Let KB be a Horn knowledge base, \u03b1 a sentence,and \u22061 and \u22062 be two minimal abductive explanations for \u03b1 with respect to KB. Then,Mod(\u22061 \u2228 \u22062) = Mod(\u22061) \u222aMod(\u22062).\nProof. First we show that every model of \u22061 is a model of \u22061 \u2228\u22062. Clearly, a model M of \u22061 satisfies all the sentences in (\u22061 \u2229\u22062). The other sentences in (\u22061 \u2228\u22062) are of the form \u03b1 \u2228 \u03b2, where \u03b1 is from \u22061 and \u03b2 is from \u22062. Since M is a model of \u22061, \u03b1 is true in M , and hence all such sentences are satisfied by M . Hence M is a model of \u22061\u2228\u22062 too. Similarly, it can be shown that every model of \u22062 is a model of \u22061 \u2228\u22062 too. 5 An abductive literal is either an abducible A from Ab, or its negation \u00acA.\nNow, it remains to be shown that every model M of \u22061\u2228\u22062 is either a model of \u22061 or a model of \u22062. We will now show that if M is not a model of \u22062, then it must be a model of \u22061. Since M satisfies all the sentences in (\u22061 \u2229\u22062), we need only to show that M also satisfies all the sentences in \u22061\\\u22062. For every element \u03b1 \u2208 \u22061\\\u22062: there exists a subset of (\u22061 \u2228 \u22062), {\u03b1 \u2228 \u03b2|\u03b2 \u2208 \u22062\\\u22062}. M satisfies all the sentences in this subset. Suppose M does not satisfy \u03b1, then it must satisfy all \u03b2 \u2208 \u22061\\\u22062. This implies that M is a model of \u22062, which is a contradictory to our assumption. Hence M must satisfy \u03b1, and thus a model \u22061. Similarly, it can be shown that M must be a model of \u22062 if it is not a model of \u22061.\nAs one would expect, all the models of revising sentence \u03b1 can be realized in terms abductive explanations for \u03b1, and the relationship is precisely stated below.\nLemma 13. Let KB be a Horn knowledge base, \u03b1 a sentence, and \u2206\u2022 the set of all minimal abductive explanations for \u03b1 with respect to KB. Then Mod({\u03b1} \u222a IC) = Mod(\u2228\u2206\u2022).\nProof. It can be easily verified that every model M of a minimal abductive explanation is also a model of \u03b1. Since every minimal abductive explanation satisfies IC, M is a model of \u03b1 \u222a IC. It remains to be shown that every model M of {\u03b1} \u222a IC is a model of one of the minimal abductive explanations for \u03b1 with respect to KB. This can be verified by observing that a minimal abductive explanation for \u03b1 with respect to KB can be obtained from M .\nThus, we have a way to generate all the models of {\u03b1} \u222a IC, and we just need to select a subset of this based on an order that satisfies (\u2264 1) to (\u2264 5). Suppose we have such an order that satisfies all the required postulates, then this order can be mapped to a particular set of abductive explanations for \u03b1 with respect to KB. This is stated precisely in the following theorem. An important implication of this theorem is that there is no need to compute all the abductive explanations for \u03b1 with respect to KB. However, it does not say which abductive explanations need to be computed.\nTheorem 24. Let KB be a Horn knowledge base, and \u2264KB be an order among abductive interpretations in S that satisfies all the rationality axioms (\u2264 1) to (\u2264 5). Then, for every sentence \u03b1, there exists \u2206\u2022 a set of minimal abductive explanations for \u03b1 with respect to KB, s.t. Min(Mod({\u03b1} \u222a IC),\u2264KB) is a subset of Mod(\u2228\u2206\u2022), and this does not hold for any proper subset of \u2206\u2022.\nProof. From Lemma 12 and Lemma 13, it is clear that Mod({\u03b1} \u222a IC) is the union of all the models of all minimal abductive explanations of \u03b1 with respect to KB. Min selects a subset of this, and the theorem follows immediately. .\nThe above theorem 24, is still not very useful in realizing revision. We need to have an order among all the interpretations that satisfies all the required axioms, and need to compute all the abductive explanations for \u03b1 with respect to KB.\nThe need to compute all abductive explanations arises from the fact that the converse of the above theorem does not hold in general. This scheme requires an universal order \u2264, in the sense that same order can be used for any Horn knowledge base. Otherwise, it would be necessary to specify the new order to be used for further modifying (KB u \u03b1). However, even if the order can be worked out, it is not desirable to demand all abductive explanations of \u03b1 with respect to KB be computed. So, it is desirable to work out, when the converse of the above theorem is true. The following theorem says that, suppose \u03b1 is rejected in KB, then revision of KB by \u03b1 can be worked out in terms of some abductive explanations for \u03b1 with respect to KB.\nTheorem 25. Let KB be a Horn knowledge base, and a revision function u be defined as: for any sentence \u03b1 that is rejected in KB, Mod(KB u \u03b1) is a non-empty subset of Mod(\u2228\u2206\u2022), where \u2206\u2022 is a set of all minimal abductive explanations for \u03b1 with respect to KB. Then, there exists an order \u2264KB among abductive interpretations in S, s.t. \u2264KB satisfies all the rationality axioms (\u2264 1) to (\u2264 5) and Mod(KB u \u03b1) = Min(Mod({\u03b1} \u222a IC),\u2264KB).\nProof. Let us construct an order \u2264KB among interpretations in S as follows: For any two abductive interpretations I and I \u2032 in S, define I \u2264KB I \u2032 iff either I \u2208 Mod(\u2228\u2206\u2022) or I \u2208 Mod(KB u form(I, I \u2032)), where form(I, I \u2032) stands for sentence whose only models are I and I \u2032. We will show that \u2264KB thus constructed satisfies (\u2264 1) to (\u2264 5) and Min(Mod({\u03b1} \u222a IC),\u2264KB) = Mod(KB u \u03b1).\nFirst, we show that Min(Mod({\u03b1} \u222a IC),\u2264KB) = Mod(KB u \u03b1).Suppose \u03b1 is not satisfiable, i.e. Mod(\u03b1) is empty, or \u03b1 does not satisfy IC, then there are no abductive models of {\u03b1} \u222a IC, and hence Min(Mod({\u03b1} \u222a IC),\u2264KB) is empty. From (u3), we infer that Mod(KB u \u03b1) is also empty. When \u03b1 is satisfiable and \u03b1 satisfies IC, the required result is obtained in two parts:\n1) If I \u2208Min(Mod({\u03b1} \u222a IC),\u2264KB), then I \u2208Mod(KB u \u03b1) Since \u03b1 is satisfiable and consistent with IC, (u3) implies that there exists at least one model, say I \u2032, for KBu\u03b1. From (u1), it is clear that I \u2032 is a model of IC, from (u2) we also get that I \u2032 is a model of \u03b1, and consequently I \u2264KB I \u2032 (because I \u2208 Min(Mod({\u03b1} \u222a IC),\u2264KB)). Suppose I \u2208 (Mod(\u2228\u2206\u2022)), then (u4) immediately gives I \u2208 Mod(KB u \u03b1). If not, from our definition of \u2264KB, it is clear that I \u2208Mod(KBuform(I, I \u2032)). Note that \u03b1\u2227form(I, I \u2032) \u2261 form(I, I \u2032), since both I and I \u2032 are models of \u03b1. From (u6) and (u7), we get Mod(KBu\u03b1)\u2229{I, I \u2032} = Mod(KBuform(I, I \u2032)). Since I \u2208Mod(KBu form(I, I \u2032)), it immediately follows that I \u2208Mod(KB u \u03b1). 2) If I \u2208Mod(KB u \u03b1), then I \u2208Min(Mod({\u03b1} \u222a IC),\u2264KB). From (u1) we get I is a model of IC, and from (u2), we obtain I \u2208Mod(\u03b1). Suppose I \u2208 (Mod(\u2228\u2206\u2022)), then from our definition of \u2264KB, we get I \u2264KB I \u2032, for any other model I \u2032 of \u03b1 and IC, and hence I \u2208 Min(Mod({\u03b1} \u222a IC),\u2264KB). Instead, if I is not a model of KB, then, to get the required result, we should show that I \u2208Mod(KB u form(I, I \u2032)), for every model I \u2032 of \u03b1 and IC. As we have observed previously, from (u6) and (u7), we get Mod(KBu\u03b1)\u2229{I, I \u2032} = Mod(KBuform(I, I \u2032)). Since I \u2208Mod(KBu\u03b1),\nit immediately follows that I \u2208Mod(KBuform(I, I \u2032)). Hence I \u2264KB I \u2032 for any model I \u2032 of \u03b1 and IC, and consequently, I \u2208Min(Mod({\u03b1}\u222aIC),\u2264KB ).\nEvery model of Mod(KB u \u03b1) is strictly minimal than all other interpretations. It is easy to verify that such a pre-order satisfies (\u2264 1) to (\u2264 5). In particular, since \u03b1 is rejected in KB, (\u2264 3) faithfulness is satisfied, and since non-empty subset of Mod(\u2228\u2206\u2022) is selected, (\u2264 4) is also satisfied.\nAn important corollary of this theorem is that, revision of KB by \u03b1 can be realized just by computing one abductive explanation of \u03b1 with respect to KB, and is stated below.\nCorollary 3. Let KB be a Horn knowledge base, and a revision function u be defined as: for any sentence \u03b1 that is rejected in KB, Mod(KB u \u03b1) is a nonempty subset of Mod(\u2206), where \u2206 is an abductive explanations for \u03b1 with respect to KB. Then, there exists an order \u2264KB among abductive interpretations in S, s.t. \u2264KB satisfies all the rationality axioms (\u2264 1) to (\u2264 5) and Mod(KBu\u03b1) = Min(Mod({\u03b1} \u222a IC),\u2264KB).\nThe precondition that \u03b1 is rejected in KB is not a serious limitation in various applications such as database updates and diagnosis, where close world assumption is employed to infer negative information. For example, in diagnosis it is generally assumed that all components are functioning normally, unless otherwise there is specific information against it. Hence, a Horn knowledge base in diagnosis either accepts or rejects normality of a component, and there is no \u201ddon\u2019t know\u201d third state. In other words, in these applications the Horn knowledge base is assumed to be complete. Hence, when such a complete Horn knowledge base is revised by \u03b1, either \u03b1 is already accepted in KB or rejected in KB, and so the above scheme works fine."}, {"heading": "11 Related Works", "text": "We begin by recalling previous work on view deletion. Aravindan (Aravindan & Dung 1994), (Aravindan 1995), defines a contraction operator in view deletion with respect to a set of formulae or sentences using Hansson\u2019s (Hansson 1997a) belief change. Similar to our approach (Delhibabu & Lakemeyer 2013, Delhibabu & Behrend, 2014, Delhibabu 2014a, Delhibabu 2014b) he focused on set of formulae or sentences in knowledge base revision for view update with respect to insertion and deletion and formulae are considered at the same level. Aravindan proposed different ways to change knowledge base via only database deletion, devising particular postulate which is shown to be necessary and sufficient for such an update process.\nOur Horn knowledge base consists of two parts, immutable part and updatable part, but our focus is on minimal change computations. The related works are, Eiter (Eiter & Makino 2007), Langlois (Langlois et al. 2008) and Delgrande\n(Delgrande & Peppas 2011) are focus on Horn revision with different perspectives like prime implication, logical closure and belief level. Segerberg (Segerberg 1998) defined a new modeling technique for belief revision in terms of irrevocability on prioritized revision. Hansson constructed five types of non-prioritized belief revision. Makinson (Makinson 1997) developed dialogue form of revision AGM. Papini (Papini 2000) defined a new version of knowledge base revision. In this paper, we considered the immutable part as a Horn clause (Ferme\u0301 & Hansson 2001 shown shielded contraction similar to immutable part, the success postulate does not hold in general; some non-tautological beliefs are shielded from contraction and cannot be given up. Shielded contraction has close connections with credibility limited revision shown Hansson et al 2001) and the updatable part as an atom (literal). Knowledge bases have a set of integrity constraints.\nHansson\u2019s (Hansson 1997a) kernel change is related to abductive method. Aliseda\u2019s (Aliseda 2006) book on abductive reasoning is one of the motivation step. Christiansen\u2019s (Christiansen & Dahl 2009) work on dynamics of abductive logic grammars exactly fits our minimal change (insertion and deletion). Wrobel\u2019s (Wrobel 1995) definition of first order theory revision was helpful to frame our algorithm.\nOn the other hand, we are dealing with view update problem. Keller\u2019s (Keller 1985) thesis is motivation of the view update problem. There are many papers related to the view update problem (for example, the recent survey paper on view update by Chen and Liao (Chen & Liao 2010) and the survey paper on view update algorithms by Mayol and Teniente (Mayol & Teniente 1999). More similar to our work is the paper presented by Bessant (Bessant et al. 1998), which introduces a local search-based heuristic technique that empirically proves to be often viable, even in the context of very large propositional applications. Laurent (Laurent et al. 1998), considers updates in a deductive database in which every insertion or deletion of a fact can be performed in a deterministic way.\nFurthermore, and at a first sight more related to our work, some work has been done on \u201dcore-retainment\u201d (Hansson 1991) in the model of language splitting introduced by Parikh (Parikh 1999). More recently, Doukari (Doukari et al. 2008), O\u0308zc\u0327ep (O\u0308zc\u0327ep 2012) and Wu (Wu et al. 2011) applied similar ideas for dealing with knowledge base dynamics. These works represent motivation step for our future work. Second, we are dealing with how to change minimally in the theory of \u201dprinciple of minimal change\u201d, but current focus is on finding second best abductive explanation (Liberatore & Schaerf 2004 and 2012), 2-valued minimal hypothesis for each normal program (Pinto & Pereira 2011). Our work reflected in the current trends on Ontology systems and description logics (Qi and Yang (Qi & Yang 2008) and Kogalovsky (Kogalovsky 2012)). Finally, when we presented Horn knowledge base change in abduction framework, we did not talk about compilability and complexity (see the works of Liberatore (Liberatore 1997) and Zanuttini (Zanuttini 2003)).\nThe significance of our work can be summarized in the following:\n\u2013 To define a new kind of revision operator on Horn knowledge base and obtain axiomatic characterization for it.\n\u2013 To propose new generalized revision algorithm for Horn knowledge base dynamics, and study its connections with kernel change and abduction procedure. \u2013 To develop a new view insertion algorithm for databases. \u2013 To design a new view update algorithm for stratifiable Deductive Database\n(DDB), using an axiomatic method based on Hyper tableaux and magic sets. \u2013 To study an abductive framework for Horn knowledge base dynamics. \u2013 To present a comparative study of view update algorithms and integrity\nconstraint. \u2013 Finally, to shown connection between belief update versus database update."}, {"heading": "12 Conclusion and remarks", "text": "The main contribution of this research is to provide a link between theory of belief dynamics and concrete applications such as view updates in databases. We argued for generalization of belief dynamics theory in two respects: to handle certain part of knowledge as immutable; and dropping the requirement that belief state be deductively closed. The intended generalization was achieved by introducing the concept of Horn knowledge base dynamics and generalized revision for the same. Further, we studied the relationship between Horn knowledge base dynamics and abduction resulting in a generalized algorithm for revision based on abductive procedures. The successfully demonstrated how Horn knowledge base dynamics provide an axiomatic characterization for update an literals to a stratifiable (definite) deductive database.\nIn bridging the gap between belief dynamics and view updates, we observe that a balance has to be achieved between computational efficiency and rationality. While rationally attractive notions of generalized revision prove to be computationally inefficient, the rationality behind efficient algorithms based on incomplete trees is not clear at all. From the belief dynamics point of view, we may have to sacrifice some postulates, vacuity, to gain computational efficiency. Further weakening of relevance has to be explored, to provide declarative semantics for algorithms based on incomplete trees.\nOn the other hand, from the database side, we should explore various ways of optimizing the algorithms that would comply with the proposed declarative semantics. We believe that partial deduction and loop detection techniques, will play an important role in optimizing algorithms. Note that, loop detection could be carried out during partial deduction, and complete SLD-trees can be effectively constructed wrt a partial deduction (with loop check) of a database, rather than wrt database itself. Moreover, we would anyway need a partial deduction for optimization of query evaluation.\nWe have presented two variants of an algorithm for update a view atom from a definite database. The key idea of this approach is to transform the given database into a logic program in such a way that updates can be read off from the models of this transformed program. We have also shown that this algorithm is rational in the sense that it satisfies the rationality postulates that are justified\nfrom philosophical angle. In the second variant, where materialized view is used for the transformation, after generating a hitting set and removing corresponding EDB atoms, we easily move to the new materialized view. An obvious way is to recompute the view from scratch using the new EDB (i.e., compute the Least Herbrand Model of the new updated database from scratch) but it is certainly interesting to look for more efficient methods.\nThough we have discussed only about view updates, we believe that Horn knowledge base dynamics can also be applied to other applications such as view maintenance, diagnosis, and we plan to explore it further (see works (Biskup 2012) and (Caroprese et al. 2012)). Still, a lot of developments are possible, for improving existing operators or for defining new classes of change operators. In the relation of Horn KB revision with hitting set as to be describe similar construction for description logic. In particular assuming the T-Box to the hitting set and the rest with the A-Box (Delgrande, JP & Wassermann 2013). We did not talk about complexity (see the works of Liberatore ((Liberatore 1997) and (Liberatore & Schaerf 2004)), Caroprese (Caroprese 2012), Calvanese\u2019s (Calvanese 2012), and Cong (Cong et al. 2012)). In this thesis answer impotent question for experimental people that is,any real life application for AGM in 25 year theory? (Ferme & Hansson 2011). The revision and update are more challenging in logical view update problem (database theory), we extended the theory to combine our results similar in the Konieczny\u2019s (Konieczny 2011) and Nayak\u2019s (Nayak 2011)."}, {"heading": "Acknowledgement", "text": "I would like to thanks Chandrabose Aravindan and Gerhard Lakemeyer both my Indian and Germany PhD supervisor, give encourage to write the paper. I owe my deepest gratitude to Ramaswamy Ramanujam from Institute of Mathematical Sciences and Ulrich Furbach from University Koblenz-Landau for my PhD thesis member. I thank to my PhD thesis examiner\u2019s Eduardo Ferme\u0301 from University of Madeira, Mohua Banerjee from Indian Institute of Technology Kanpur and Arindama Singh form Indian Institute of Technology Madras. The author acknowledges the support of SSN College of Engineering research funds and RWTH Aachen, where he is visiting scholar with an Erasmus Mundus External Cooperation Window India4EU by the European Commission.\nM et\nho d\nP ro\nbl em\nD at\nab as\ne sc\nhe m\na U\np da\nte re\nq. M\nec ha\nni sm\nU p\nda te\nC ha\nng e\nSo lu\nti on\ns\nT yp\ne V\nie w\nIC R\nun /\nD ef\n. V\nie w\nIC K\nin d\nof M\nul .U\npd at\ne Te\nch -\nB as\ne U\nse r\nT yp\ne B\nas e\nV ie\nw A\nxi om\nSo un\nd. C\nom pl\net e.\nU pd\nat e\nE nf\nor ce\n. C\nom p.\nLa ng\n. de\nf. IC\nO pe\nra t.\nni qu\ne Fa\nct s\nPa rt\n. fa\nct s\nde f.\n[6 9]\nN Ye\ns C\nhe ck\nR un\nLo gi\nc Ye\ns Ye\ns St\nat ic\nN o\n\u03b9 \u03b4\nSL D\nN F\nN o\nN o\nS Ye\ns N\no 1-\n6, 9\nN o\nN ot pr ov\ned\n[8 6]\nN Ye\ns M\nai nt\nai n\nR un\nLo gi\nc Ye\ns Ye\ns St\nat ic\nYe s\n\u03b9 \u03b4\nSL D\nN F\nN o\nN o\nS Ye\ns N\no \u2014\nN o\nN o\n[9 6]\nS Ye\ns C\nhe ck\nR un\nLo gi\nc Ye\ns Ye\ns St\nat ic\nYe s\n\u03b9 \u03b4\n\u2014 Ye\ns N\no SS\nYe s\nYe s\n1- 6,\n7 N\not N ot pr ov ed pr ov\ned\n[1 18\n] N\nN o\nM ai\nnt ai\nn R\nun Lo\ngi c\nYe s\nYe s\nSt at\nic Ye\ns \u03b9 \u03b4\n\u2014 Ye\ns N\no S\nYe s\nN o\n1- 6,\n7 N\no N o pr ov ed\npr ov\ned\n[7 0]\nS Ye\ns C\nhe ck\nC om\np. R\nel at\nio n.\nN o\nN o\nSt at\nic Ye\ns \u03b9 \u03b4 \u03c7\npr ed\nef .\nYe s\nN o\nG Ye\ns N\no \u2014\nN o\nN o\nM ai\nnt ai\nn R\nun Lo\ngi c\nP ro\ngr am\ns\n[5 1]\nN Ye\ns C\nhe ck\nR un\nLo gi\nc Ye\ns N\no St\nat ic\nYe s\n\u03b9 \u03b4\npr ed\nef Ye\ns N\no S\nYe s\nN o\n1- 6,\n7 N\not N o P ro gr am s P ro ve d\n[1 46\n] S\nYe s\nC he\nck R\nun Lo\ngi c\nYe s\nYe s\nSt at\nic Ye\ns \u03b9 \u03b4 \u03c7\nSL D\nN F\nN o\nN o\nSS Ye\ns N\no 1-\n6, 7\nYe s\nN o\nM ai\nnt ai\nn\n[7 1]\nN Ye\ns M\nai nt\nai n\nR un\nLo gi\nc Ye\ns N\no St\nat ic\nYe s\n\u03b9 \u03b4\nU nf\nol d\nYe s\nN o\nSS Ye\ns N\no 1-\n6, 9\nYe s\nYe s\n[1 14\n] N\nYe s\nM ai\nnt ai\nn C\nom p.\nLo gi\nc Ye\ns Ye\ns St\nat ic\nYe s\n\u03b9 \u03b4 \u03c7\nSL D\nN F\nYe s\nN o\nS Ye\ns N\no 1-\n6, 9\nN ot\nN ot\nR un\nD yn\nam ic\npr ov\ned pr\nov ed\n[1 50\n] S\nYe s\nM ai\nnt ai\nn R\nun Lo\ngi c\nYe s\nYe s\nSt at\nic Ye\ns \u03b9 \u03b4\nU nf\nol d.\nN o\nYe s\nS Ye\ns N\no 1-\n6, 7\nN ot\nN o\npr ov\ned\n[8 ]\nH Ye\ns C\nhe ck\nR un\nLo gi\nc Ye\ns Ye\ns St\nat ic\nYe s\n\u03b9 \u03b4\nSL D\nYe s\nN o\nS Ye\ns N\no 1-\n6, 9\nYe s\nYe s\n[2 6]\nN N\no M\nai nt\nai n\nC om\np R\nel at\nio n\nYe s\nLi m\nite d\nSt at\nic Ye\ns \u03b9 \u03b4 \u03c7\nA ct\niv e\nYe s\nYe s\nS Ye\ns N\no \u2014\nN o\nN o\nR un\nLo gi\nc\n[6 6]\nN N\no M\nai nt\nai n\nC om\np R\nel at\nio n\nN o\nFl at\nSt at\nic Ye\ns \u03b9 \u03b4 \u03c7\nA ct\niv e\nYe s\nYe s\nS Ye\ns N\no \u2014\nN o\nN o\nR un\nLo gi\nc Li\nm ite\nd D\nyn am\nic\n[2 9]\nH Ye\ns C\nhe ck\nC om\np. O\n-O C\nla ss\nLi m\nite d\nSt at\nic Ye\ns \u03b9 \u03b4\nA ct\niv e\nYe s\nN o\nSS Ye\ns N\no 1-\n6, 9\nN o\nYe s\nM ai\nnt ai\nn R\nun A\ntt .\n[3 7]\nN Ye\ns M\nai nt\nai n\nR un\nLo gi\nc Ye\ns Fl\nat St\nat ic\nYe s\n\u03b9 \u03b4\nU nf\nol d.\nYe s\nN o\nS Ye\ns N\no 1-\n6, 9\nN ot\nYe s\nLi m\nite d\npr ov\ned\n[1 07\n] N\nYe s\nM ai\nnt ai\nn R\nun Lo\ngi c\nYe s\nLi m\nite d\nSt at\nic N\no \u03b9 \u03b4\nA ct\niv e\nYe s\nN o\nSS Ye\ns N\no 1-\n6, 7\nYe s\nN ot pr ov\ned\n[1 45\n] N\nYe s\nM ai\nnt ai\nn C\nom p\nLo gi\nc Ye\ns Ye\ns St\nat ic\nYe s\n\u03b9 \u03b4\nSL D\nN F\nYe s\nN o\nS Ye\ns N\no 1-\n6, 9\nYe s\nYe s\nR un\nD yn\nam ic\n[1 38\n] S\nYe s\nM ai\nnt ai\nn C\nom p\nLo gi\nc N\no Fl\nat St\nat ic\nYe s\n\u03b9 \u03b4\npr ed\nef \u2014\nYe s\nG N\no Ye\ns \u2014\nN o\nN ot\nLi m\nite d\nP ro\ngr am\ns pr\nov ed\nT ab\n. 1.\nSu m\nm ar\ny of\nvi ew\n-u pd\nat e\nan d\nin te\ngr ity\nco ns\ntr ai\nnt w\nith ou\nr ax\nio m\nat ic\nm et\nho d\nA pp\nen di\nx A\nM et\nho d\nP ro\nbl em\nD at\nab as\ne sc\nhe m\na U\np da\nte re\nq. M\nec ha\nni sm\nU p\nda te\nC ha\nng e\nSo lu\nti on\ns\nT yp\ne V\nie w\nIC R\nun /\nD ef\n. V\nie w\nIC K\nin d\nof M\nul .U\npd at\ne Te\nch -\nB as\ne U\nse r\nT yp\ne B\nas e\nV ie\nw A\nxi om\nSo un\nd. C\nom pl\net e.\nU pd\nat e\nE nf\nor ce\n. C\nom p.\nLa ng\n. de\nf. IC\nO pe\nra t.\nni qu\ne Fa\nct s\nPa rt\n. fa\nct s\nde f.\n[1 44\n] N\nN o\nM ai\nnt ai\nn C\nom p\nLo gi\nc Ye\ns Li\nm ite\nd St\nat ic\nYe s\n\u03b9 \u03b4 \u03c7\nP re\nde f\nYe s\nN o\nS Ye\ns N\no 1-\n6, 7\nYe s\nN o\nP ro\ngr am\n[1 0]\nH Ye\ns C\nhe ck\nR un\nLo gi\nc Ye\ns Li\nm ite\nd St\nat ic\nYe s\n\u03b9 \u03b4\nSL D\nYe s\nN o\nS Ye\ns N\no 1-\n6, 9\nYe s\nYe s\n[4 0]\nN Ye\ns M\nai nt\nai n\nR un\nLo gi\nc Ye\ns Ye\ns St\nat ic\nYe s\n\u03b9 \u03b4\nSL D\nN F\nN o\nN o\nS Ye\ns N\no 1-\n6, 7\nN o\nN ot P ro\nve d\n[1 05\n] N\nYe s\nM ai\nnt ai\nn R\nun Lo\ngi c\nYe s\nFl at\nSt at\nic Ye\ns \u03b9 \u03b4\nU nf\nol d\nN o\nYe s\nG Ye\ns N\no 1-\n6, 7\nN ot\nN o\nLi m\nite d\npr ov\ned\n[1 51\n] H\nN o\nM ai\nnt ai\nn C\nom p.\nR el\nat io\nn Ye\ns Li\nm ite\nd St\nat ic\nYe s\n\u03b9 \u03b4 \u03c7\nU nf\nol d\nYe s\nN o\nS Ye\ns N\no 1-\n6, 7\nN ot\nN ot\nR un\nD yn\nam ic\npr ov\ned pr\nov ed\n[1 09\n] N\nN o\nM ai\nnt ai\nn C\nom p\nLo gi\nc N\no Fl\nat St\nat ic\nYe s\n\u03b9 \u03b4\nA ct\niv e\nYe s\nN o\nG N\no N\no \u2014\nN o\nN o\nR es\nto re\nR un\nLi m\nite d\nD yn\nam ic\n[1 39\n] N\nN o\nM ai\nnt ai\nn C\nom p\nR el\nat io\nn N\no Fl\nat St\nat ic\nYe s\n\u03b9 \u03b4\nA ct\niv e\nYe s\nN o\nS N\no N\no \u2014\nN o\nN o\nR un\nLi m\nite d\n[1 08\n] N\nYe s\nC he\nck R\nun Lo\ngi c\nYe s\nLi m\nite d\nSt at\nic Ye\ns \u03b9 \u03b4\nSL D\nYe s\nN o\nS Ye\ns N\no 1-\n6, 9\nYe s\nYe s\n[1 ]\nO N\no M\nai nt\nai n\nR un\nLo gi\nc Ye\ns Li\nm ite\nd St\nat ic\nYe s\n\u03b9 \u03b4\n\u2014 Ye\ns N\no S\nYe s\nN o\n\u2014 N\no N\no\n[1 40\n] N\nN o\nM ai\nnt ai\nn C\nom p\nR el\nat io\nn N\no Li\nm ite\nd St\nat ic\nYe s\n\u03b9 \u03b4\nP re\nde f\nN o\nN o\nG N\no N\no \u2014\nN o\nN o\nP ro\ngr am\n[7 2]\nN N\no M\nai nt\nai n\nC om\np Lo\ngi c\nYe s\nLi m\nite d\nSt at\nic Ye\ns \u03b9 \u03b4\n\u2014 N\no N\no S\nN o\nN o\n\u2014 N\no N\no\n[3 0]\nN N\no M\nai nt\nai n\nC om\np. R\nel at\nio n\nYe s\nLi m\nite d\nSt at\nic Ye\ns \u03b9 \u03b4\n\u2014 Ye\ns N\no S\nYe s\nN o\n\u2014 N\not N ot R un D yn am ic pr ov ed pr ov\ned\n[5 2]\nH Ye\ns C\nhe ck\nR un\nLo gi\nc Ye\ns Ye\ns St\nat ic\nYe s\n\u03b9 \u03b4\nP re\nde f\nYe s\nN o\nS Ye\ns N\no 1-\n6, 7\nYe s\nN ot\nP ro\ngr am\ns pr\nov ed\n[7 8]\nO Ye\ns C\nhe ck\nR un\nR el\nat io\nn Ye\ns Li\nm ite\nd St\nat ic\nN o\n\u03b9 \u03b4\nU nf\nol d\nYe s\nN o\nS Ye\ns N\no 1-\n6, 9\nYe s\nYe s\n[1 4]\nO Ye\ns C\nhe ck\nR un\nR el\nat io\nn Ye\ns Li\nm ite\nd St\nat ic\nN o\n\u03b9 \u03b4\nU nf\nol d\nYe s\nN o\nS Ye\ns N\no 1-\n6, 9\nYe s\nYe s\n[5 6]\nN Ye\ns C\nhe ck\nR un\nLo gi\nc Ye\ns Ye\ns St\nat ic\nYe s\n\u03b9 \u03b4\nSL D\nN F\nYe s\nN o\nS Ye\ns N\no 1-\n6, 9\nYe s\nYe s\n[1 32\n] N\nN o\nM ai\nnt ai\nn R\nun Lo\ngi c\nYe s\nLi m\nite d\nSt at\nic Ye\ns \u03b9 \u03b4\nP re\nde f\nYe s\nN o\nS Ye\ns N\no 1-\n6, 7\nYe s\nN ot\nP ro\ngr am\ns pr\nov ed\n[8 1]\nO N\no M\nai nt\nai n\nC om\np R\nel at\nio n\nYe s\nLi m\nite d\nSt at\nic Ye\ns \u03b9 \u03b4\n\u2014 Ye\ns N\no S\nYe s\nN o\n\u2014 N\no N\no\nM et\nho d\nP ro\nbl em\nD at\nab as\ne sc\nhe m\na U\np da\nte re\nq. M\nec ha\nni sm\nU p\nda te\nC ha\nng e\nSo lu\nti on\ns\nT yp\ne V\nie w\nIC R\nun /\nD ef\n. V\nie w\nIC K\nin d\nof M\nul .U\npd at\ne Te\nch -\nB as\ne U\nse r\nT yp\ne B\nas e\nV ie\nw A\nxi om\nSo un\nd. C\nom pl\net e.\nU pd\nat e\nE nf\nor ce\n. C\nom p.\nLa ng\n. de\nf. IC\nO pe\nra t.\nni qu\ne Fa\nct s\nPa rt\n. fa\nct s\nde f.\n[1 35\n] N\nYe s\nC he\nck R\nun Lo\ngi c\nN o\nLi m\nite d\nSt at\nic Ye\ns \u03b9 \u03b4\nSL D\nN F\nYe s\nN o\nS Ye\ns N\no 1-\n6, 9\nYe s\nYe s\n[5 7]\nN Ye\ns C\nhe ck\nR un\nLo gi\nc Ye\ns Ye\ns St\nat ic\nN o\n\u03b9 \u03b4\nSL D\nN F\nN o\nN o\nS Ye\ns N\no 1-\n6, 9\nN ot\nN o pr ov\ned\n[1 13\n] N\nYe s\nC he\nck R\nun Lo\ngi c\nYe s\nYe s\nSt at\nic N\no \u03b9 \u03b4 \u03c7\nSL D\nYe s\nN o\nS Ye\ns N\no \u2014\nN o\nN o\nM ai\nnt ai\nn\n[1 9]\nN Ye\ns C\nhe ck\nR un\nLo gi\nc Ye\ns Ye\ns St\nat ic\nN o\n\u03b9 \u03b4 \u03c7\nSL D\nYe s\nN o\nSS Ye\ns N\no 1-\n6, 7\nYe s\nN ot\nM ai\nnt ai\nn C\nom p\npr ov\ned\n[3 1]\nN Ye\ns C\nhe ck\nR un\nLo gi\nc Ye\ns Ye\ns St\nat ic\nYe s\n\u03b9 \u03b4 \u03c7\nP re\nde f\nYe s\nN o\nS Ye\ns N\no 1-\n6, 9\nYe s\nYe s\nM ai\nnt ai\nn D\nyn am\nic P\nro gr\nam\n[2 5]\nN Ye\ns C\nhe ck\nC om\np Lo\ngi c\nYe s\nYe s\nD yn\nam ic\nYe s\n\u03b9 \u03b4\nP re\nde f\nYe s\nN o\nS Ye\ns N\no \u2014\nN ot\nN o\nP ro\ngr am\ns P\nro ve\nd pr\nov ed\n[3 2]\nN Ye\ns C\nhe ck\nR un\nLo gi\nc Ye\ns Ye\ns St\nat ic\nYe s\n\u03b9 \u03b4 \u03c7\nP re\nde f\nYe s\nN o\nS Ye\ns N\no 1-\n6, 9\nYe s\nYe s\nM ai\nnt ai\nn D\nyn am\nic P\nro gr\nam\n[3 5]\nN N\no M\nai nt\nai n\nC om\np Lo\ngi c\nYe s\nN o\n\u2014 Ye\ns \u03b9 \u03b4\n\u2014 Ye\ns N\no S\nYe s\nN o\n\u2014 N\no N\no\n[1 54\n] N\nN o\nM ai\nnt ai\nn R\nun R\nel at\nio n\nYe s\nN o\n\u2014 Ye\ns \u03b9 \u03b4 \u03c7\nU nf\nol d\nYe s\nN o\nSS N\no N\no \u2014\nN ot\nN ot\npr ov\ned pr\nov ed\n[7 9]\nO N\no M\nai nt\nai n\nC om\np. Lo\ngi c\nYe s\nN o\n\u2014 Ye\ns \u03b9 \u03b4\n\u2014 -\nYe s\nN o\nG N\no N\no \u2014\nYe s\nN ot\nR un\npr ov\ned\n[1 5]\nS Ye\ns C\nhe ck\nR un\nLo gi\nc Ye\ns Fl\nat St\nat ic\nYe s\n\u03b9 \u03b4\nSL D\nN F\nYe s\nN o\nS Ye\ns N\no 1-\n6, 9\nYe s\nN ot\nLi m\nite d\npr ov\ned\n[5 3]\nN Ye\ns C\nhe ck\nR un\nLo gi\nc Ye\ns Ye\ns St\nat ic\nYe s\n\u03b9 \u03b4\n\u2014 Ye\ns N\no S\nYe s\nN o\n\u2014 N\no N\no\n[2 7]\nO N\no M\nai nt\nai n\nR un\nR el\nat io\nn Ye\ns N\no St\nat ic\nYe s\n\u03b9 \u03b4\nSL D\nYe s\nYe s\nG N\no N\no \u2014\nN ot\nN ot\npr ov\ned pr\nov ed\n[1 6]\nO N\no M\nai nt\nai n\nC om\np R\nel at\nio n\nYe s\nN o\nSt at\nic Ye\ns \u03b9 \u03b4 \u03c7\n\u2014 Ye\ns N\no SS\nYe s\nN o\n\u2014 N\no N\no\n[4 ]\nO N\no M\nai nt\nai n\nC om\np. R\nel at\nio n\nN o\nLi m\nite d\nSt at\nic Ye\ns \u03b9 \u03b4\n\u2014 Ye\ns N\no G\nYe s\nN o\n\u2014 N\no N o R un D yn am ic\n[1 11\n] N\nN o\nM ai\nnt ai\nn C\nom p\nR el\nat io\nn N\no Ye\ns St\nat ic\nYe s\n\u03b9 \u03b4 \u03c7\nU nf\nol d\nN o\nYe s\nSS N\no N\no \u2014\nN o\nN o\n[1 37\n] N\nN o\nC he\nck C\nom p\nLo gi\nc N\no Ye\ns St\nat ic\nYe s\n\u03b9 \u03b4\nA ct\niv e\nYe s\nN o\nG Ye\ns N\no \u2014\nN o\nN o\n[4 1]\nN Ye\ns C\nhe ck\nR un\nLo gi\nc Ye\ns Ye\ns St\nat ic\nYe s\n\u03b9 \u03b4\nSL D\nYe s\nN o\nS Ye\ns N\no 1-\n6, 9\nYe s\nYe s"}], "references": [{"title": "Automated selection of materialized views and indexes in SQL databases", "author": ["S Agrawal", "S Chaudhuri"], "venue": "Proceedings of the 26th International Conference on Very Large Data Bases, ed", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2008}, {"title": "On the logic of theory change: Safe contraction", "author": ["CE Alchourron", "D Makinson"], "venue": "Studia Logica,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 1985}, {"title": "On the logic of theory change: Partial meet contraction and revision functions", "author": ["CE Alchourron", "G\u00e4rdenfors", "D Makinson"], "venue": "Journal of Symbolic Logic", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 1985}, {"title": "Filtering XML content for publication and presentation on the web\u2019,Digital Information Management (ICDIM)", "author": ["L Alexandre", "J Coelho"], "venue": null, "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2011}, {"title": "Abductive Resoning Logic Investigations into Discovery and Explanation", "author": ["A Aliseda"], "venue": "Springer book series,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2006}, {"title": "Abductive Reasoning: Challenges Ahead", "author": ["A Aliseda"], "venue": "THEORIA, vol. 22,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2007}, {"title": "Acyclic Programs", "author": ["Apt", "K.P", "M Bezem"], "venue": "New Generation Computing,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 1991}, {"title": "Belief Dynamics, Abduction, and Database", "author": ["C Aravindan", "PM Dung"], "venue": "Logics in Artificial Intelligence Lecture Notes in Computer Science, ed", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 1994}, {"title": "Dynamics of Belief: Epistmology, Abduction and Database Updat", "author": ["C Aravindan"], "venue": "Phd Thesis,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 1995}, {"title": "A Rational and Efficient Algorithm for View Deletion in Databases", "author": ["C Aravindan", "P Baumgartner"], "venue": "Logic Programming proceedng International Symposium,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 1997}, {"title": "2004,\u2019Coherent Integration of Databases by Abductive Logic Programming\u2019,Journal", "author": ["O Arieli", "M Denecker", "BV Nuffelen", "M Bruynooghe"], "venue": "Artificial Intelligence Research,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2004}, {"title": "Knowledge updates: Semantics and complexity issues", "author": ["C Baral", "Y Zhang"], "venue": "Atificial Intelligence,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2005}, {"title": "Semantically Guided Theorem Proving for Diagnosis Applications", "author": ["P Baumgartner", "P Fr\u00f6hlich", "U Furbach", "W Nejdl"], "venue": "Fifteenth International Joint Conference on. Artificial Intelligence,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 1997}, {"title": "On solving the view selection problem in distributed data warehouse architectures", "author": ["A Bauer", "W Lehne"], "venue": "15th International Conference on Scientific and Statistical Database Management,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2003}, {"title": "A Transformation-Based Approach to View Updating in Stratifiable Deductive Databases", "author": ["A Behrend", "R Manthey"], "venue": "Foundations of Information and Knowledge Systems Lecture Notes in Computer Science, ed. Hartmannp, S,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2008}, {"title": "A cooperative approach to view selection and placement in P2P systems", "author": ["Z Bellahsene", "M Cart", "N Kadi"], "venue": "Proceedings of the 2010 international conference on On the move to meaningful internet systems,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2010}, {"title": "Revision of partially ordered information: Axiomatization, semantics and iteration", "author": ["S Benferhat", "S Lagrue", "O Papini"], "venue": "International Joint Conference on Artificial Intelligence,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2005}, {"title": "Combining Nonmonotonic Reasoning and Belief Revision: A Practical Approach\u2019, Artificial Intelligence: Methodology, Systems, and Applications Lecture Notes in Computer Science, ed", "author": ["B Bessant", "E Gr\u00e9goire", "P Marquis", "L Sa\u00cfs"], "venue": null, "citeRegEx": "18", "shortCiteRegEx": "18", "year": 1998}, {"title": "Efficient Integrity Checking over XML Documents", "author": ["D Braga", "A Campi", "D Martinenghi"], "venue": "Current Trends in Database Technology EDBT 2006 Lecture Notes in Computer Science, ed", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2006}, {"title": "Inference-usability confinement by maintaining inference-proof views of an information system", "author": ["J Biskup"], "venue": "Journal International Journal of Computational Science and Engineering,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2012}, {"title": "Admissible and restrained revision", "author": ["R Booth", "T Meyer"], "venue": "Journal of Artificial Intelligence Research,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2006}, {"title": "Abduction as belief revision", "author": ["C Boutilier", "V Beche"], "venue": "Artificial Intelligence, vol. 77,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 1995}, {"title": "The ViewUpdate Problem for Indefinite Databases", "author": ["L Caroprese", "I Trubitsyna", "M Truszczynski"], "venue": "Logics in Artificial Intelligence Lecture Notes in Computer Science,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2012}, {"title": "View-based query answering in Description Logics Semantics and complexity", "author": ["D Calvanese", "GD Giacomob", "M Lenzerinib", "R Rosatib"], "venue": "Journal of Computer and System Sciences,", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2012}, {"title": "View Updating Through Active Integrity Constraints", "author": ["L Caroprese", "I Trubitsyna", "E Zumpano"], "venue": "Logic Programming Lecture Notes in Computer Science,", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2007}, {"title": "Automatic Generation of Production Rules for Integrity Maintenance", "author": ["S Ceri", "P Fraternali", "S Paraboschi", "L Tanca"], "venue": "ACM Transactions on Database Systems,", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 1994}, {"title": "Towards materialized view selection for distributed databases", "author": ["LWF Chaves", "E Buchmann", "F Hueske", "K B\u00f6hm"], "venue": "Proceedings of the 12th International Conference on Extending Database Technology: Advances in Database Technology,", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2009}, {"title": "A Comparative Study of View Update Problem", "author": ["H Chen", "H Liao"], "venue": "Data Storage and Data Engineering,", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 2010}, {"title": "An Execution Model for Limited Ambiguity Rules and Its Application to Derived Data Update", "author": ["IA Chen", "R Hull", "D McLeod"], "venue": "ACM Transactions on Database Systems, vol. 20,", "citeRegEx": "29", "shortCiteRegEx": "29", "year": 1995}, {"title": "The view-selection problem has an exponential-time lower bound for conjunctive queries and views", "author": ["R Chirkova"], "venue": "ACM Symposium on Principles of Database Systems,", "citeRegEx": "30", "shortCiteRegEx": "30", "year": 2002}, {"title": "On Simplification of Database Integrity Constraints", "author": ["H Christiansen", "D Martinenghi"], "venue": "Fundamenta Informaticae,", "citeRegEx": "31", "shortCiteRegEx": "31", "year": 2006}, {"title": "Integrity Checking and Maintenance with Active Rules in XML Databases", "author": ["H Christiansen", "M Rekouts"], "venue": "Databases BNCOD Workshops,", "citeRegEx": "32", "shortCiteRegEx": "32", "year": 2007}, {"title": "Abductive Logic Grammars\u2019, Logic, Language, Information and Computation Lecture Notes in Computer Science, ed", "author": ["H Christiansen"], "venue": null, "citeRegEx": "33", "shortCiteRegEx": "33", "year": 2009}, {"title": "Extending the Database Relational Model to Capture More Meaning", "author": ["EF Codd"], "venue": "ACM Transactions on Database Systems,", "citeRegEx": "34", "shortCiteRegEx": "34", "year": 1979}, {"title": "Type-Based Static and Dynamic Website Verification", "author": ["J Coelho", "M Florido"], "venue": "Internet and Web Applications and Services,", "citeRegEx": "35", "shortCiteRegEx": "35", "year": 2007}, {"title": "On the Complexity of View Update Analysis and Its Application to Annotation Propagation", "author": ["G Cong", "W Fan", "F Geerts", "J Li", "J Luo"], "venue": "Journal IEEE Transactions on Knowledge and Data Engineering,", "citeRegEx": "36", "shortCiteRegEx": "36", "year": 2012}, {"title": "The Role of Abduction in Database View Updating", "author": ["L Console", "ML Sapino", "DT Dupr\u00e9"], "venue": "Journal of Intelligent Information Systems,", "citeRegEx": "37", "shortCiteRegEx": "37", "year": 1995}, {"title": "Investigations into a Theory of Base Revision: Preliminary report", "author": ["M Dalal"], "venue": "In Seventh National Converence on Artificial Intelligence, (AAAI), St. Paul,", "citeRegEx": "38", "shortCiteRegEx": "38", "year": 1988}, {"title": "On the logic of iterated belief revision", "author": ["A Darwiche", "J Pearl"], "venue": "Artificial Intelligence,", "citeRegEx": "39", "shortCiteRegEx": "39", "year": 1997}, {"title": "One Abductive Logic Programming Procedure for two kind of Updates", "author": ["H Decker"], "venue": "Proceedings Workshop DINAMICS at Int. Logic Programming Symposium,", "citeRegEx": "40", "shortCiteRegEx": "40", "year": 1997}, {"title": "A Rational and Efficient Algorithm for View Revision in Databases", "author": ["R. Delhibabu", "G. Lakemeyer"], "venue": "Applied Mathematics & Information Sciences,", "citeRegEx": "41", "shortCiteRegEx": "41", "year": 2013}, {"title": "An Abductive Framework for Horn Knowledge Base Dynamics", "author": ["R Delhibabu"], "venue": "Applied Mathematics & Information Sciences,", "citeRegEx": "42", "shortCiteRegEx": "42", "year": 2014}, {"title": "Comparative Study of View Update Algorithms in Rational Choice Theory\u2019, Applied Intelligence - Accepted", "author": ["R Delhibabu"], "venue": null, "citeRegEx": "44", "shortCiteRegEx": "44", "year": 2014}, {"title": "A Better Understanding of the Dynamics of Belief Update VS Database Update", "author": ["R Delhibabu"], "venue": "Studia Logica - Submitted", "citeRegEx": "45", "shortCiteRegEx": "45", "year": 2014}, {"title": "Horn Clause Belief Change: Contraction Functions", "author": ["JP Delgrande"], "venue": null, "citeRegEx": "46", "shortCiteRegEx": "46", "year": 2008}, {"title": "Revising Horn Theories\u2019, of the Twenty-Second international joint conference on", "author": ["JP Delgrande", "P Peppas"], "venue": "Artificial Intelligence,", "citeRegEx": "47", "shortCiteRegEx": "47", "year": 2011}, {"title": "Horn Clause Contraction Functions", "author": ["JP Delgrande", "R Wassermann"], "venue": "Journal of Artificial Intelligence Research,", "citeRegEx": "48", "shortCiteRegEx": "48", "year": 2013}, {"title": "Abduction in Logic Programming", "author": ["M Denecker"], "venue": "Computational Logic: Logic Programming and Beyond,", "citeRegEx": "49", "shortCiteRegEx": "49", "year": 2002}, {"title": "Materialized View Selection in Data Warehousing: A Survey", "author": ["Dhote", "C. A", "MS Ali"], "venue": "Journal of Applied Sciences,", "citeRegEx": "50", "shortCiteRegEx": "50", "year": 2009}, {"title": "Incremental evaluation of datalog queries", "author": ["G Dong"], "venue": "In Database Theory - ICDT, ed. Biskup, J, Berlin, Germany,", "citeRegEx": "51", "shortCiteRegEx": "51", "year": 1992}, {"title": "Integrity Constraint Enforcement by Means of Trigger Templates", "author": ["E Dom\u0131\u0301nguez", "J Lloret", "MA Zapataet"], "venue": "Advances in Information Systems Lecture Notes in Computer Science, ed. Doml\u0301\u0142nguez, E, Izmir, Turkey,", "citeRegEx": "52", "shortCiteRegEx": "52", "year": 2002}, {"title": "Model-Driven, ViewBased Evolution of Relational Databases", "author": ["E Dom\u0131\u0301nguez", "J Lloret", "AL Rubio", "MA Zapata"], "venue": "Database and Expert Systems Applications Lecture Notes in Computer Science, ed", "citeRegEx": "53", "shortCiteRegEx": "53", "year": 2008}, {"title": "A New Framework for Local Belief Revision", "author": ["O Doukari", "R Jeansoulin", "E W\u00fcrbelet"], "venue": "Advances in Artificial Intelligence Lecture Notes in Computer Science,", "citeRegEx": "54", "shortCiteRegEx": "54", "year": 2008}, {"title": "On computing all abductive explanations from a propositional Horn theory", "author": ["T Eiter"], "venue": "Journal of ACM,", "citeRegEx": "55", "shortCiteRegEx": "55", "year": 2007}, {"title": "Handling Existential Derived Predicates in View Updating", "author": ["C Farr\u00e9", "E Teniente", "T Urp\u00ed"], "venue": "Logic Programming Lecture Notes in Computer Science,", "citeRegEx": "56", "shortCiteRegEx": "56", "year": 2003}, {"title": "A New Approach for Checking Schema Validation Properties", "author": ["C Farr\u00e9", "E Teniente", "T Urp\u00ed"], "venue": "Database and Expert Systems Applications Lecture Notes in Computer Science, ed", "citeRegEx": "57", "shortCiteRegEx": "57", "year": 2004}, {"title": "Prioritized and Non-prioritized Multiple Change on Belief Bases", "author": ["MA Falappa", "G Kern-Isberner", "MDL Reis", "GR Simari"], "venue": "Journal of Philosophical Logic, vol. 41,", "citeRegEx": "58", "shortCiteRegEx": "58", "year": 2012}, {"title": "Shielded Contraction\u2019, Frontiers in Belief Revision", "author": ["EL Ferm\u00e9", "SO Hansson"], "venue": "Applied Logic Series, Kluwer Academic Publishers,", "citeRegEx": "60", "shortCiteRegEx": "60", "year": 2001}, {"title": "AGM 25 Years - Twenty-Five Years of Research in Belief Change", "author": ["EL Ferm\u00e9", "SO Hansson"], "venue": "Journal of Philosophical Logic, vol. 40,", "citeRegEx": "61", "shortCiteRegEx": "61", "year": 2011}, {"title": "A Review of Repairing Techniques for Integrity Maintenance\u2019, Rules in Database Systems Workshops in Computing, ed", "author": ["P Fraternali", "S Paraboschi"], "venue": null, "citeRegEx": "62", "shortCiteRegEx": "62", "year": 1993}, {"title": "Belief Revision", "author": ["P G\u00e4rdenfors"], "venue": null, "citeRegEx": "63", "shortCiteRegEx": "63", "year": 1992}, {"title": "Knowledge in flux", "author": ["P G\u00e4rdenfors"], "venue": null, "citeRegEx": "64", "shortCiteRegEx": "64", "year": 1998}, {"title": "Revisions of knowledge systems using epistemic entrenchment", "author": ["P G\u00e4rdenfors", "D Makinson"], "venue": "Proceedings of the Second Conference on Theoretical Aspects of Reasoning about Knowledge,", "citeRegEx": "65", "shortCiteRegEx": "65", "year": 1988}, {"title": "Specifying Reactive Integrity Control for Active Databases", "author": ["M Gertz"], "venue": "Research Issues in Data Engineering, Active Database Systems,", "citeRegEx": "66", "shortCiteRegEx": "66", "year": 1994}, {"title": "Integrity Constraints: Semantics and Applications\u2019, Logics for Databases and Information Systems, Kluwer Academic Publishers", "author": ["P Godfrey", "J Grant", "J Gryz", "J Minker"], "venue": null, "citeRegEx": "67", "shortCiteRegEx": "67", "year": 1998}, {"title": "Two modellings for theory change", "author": ["A Grove"], "venue": "Journal of Philosophical Logic,", "citeRegEx": "68", "shortCiteRegEx": "68", "year": 1988}, {"title": "Updating Knowledge Bases", "author": ["A Guessoum", "JW Lloyd"], "venue": "New Generation Computing, vol. 8,", "citeRegEx": "69", "shortCiteRegEx": "69", "year": 1990}, {"title": "Counting solutions to the view maintenance problem", "author": ["A Gupta", "D Katiyar"], "venue": "Proceedings of the Workshop on Deductive Databases held in conjunction with the Joint International Conference and Symposium on Logic Programming,", "citeRegEx": "70", "shortCiteRegEx": "70", "year": 1992}, {"title": "Maintaining views incrementally", "author": ["A Gupta", "IS Mumick", "VS Subrahmanian"], "venue": "Proceedings of the 1993 ACM SIGMOD international conference on Management of data,", "citeRegEx": "71", "shortCiteRegEx": "71", "year": 1993}, {"title": "Answering queries using views: A survey", "author": ["AY Halevy"], "venue": "Journal The VLDB Journal,", "citeRegEx": "72", "shortCiteRegEx": "72", "year": 2001}, {"title": "Belief contraction without recovery", "author": ["SO Hansson"], "venue": "Studia Logica, vol. 50,no", "citeRegEx": "73", "shortCiteRegEx": "73", "year": 1991}, {"title": "A dyadic representation of belief", "author": ["SO Hansson"], "venue": null, "citeRegEx": "74", "shortCiteRegEx": "74", "year": 1992}, {"title": "A Textbook of Belief Dynamics", "author": ["SO Hansson"], "venue": null, "citeRegEx": "75", "shortCiteRegEx": "75", "year": 1997}, {"title": "Theoria\u2019, Special Issue on non-prioritized belief revision, Wiley, Chichester, vol", "author": ["SO Hansson"], "venue": null, "citeRegEx": "76", "shortCiteRegEx": "76", "year": 1997}, {"title": "Credibility-Limited Revision", "author": ["SO Hansson", "EL Ferm\u00e9", "J Cantwell", "Falappa M"], "venue": "Journal of Symbolic Logic, vol. 66,", "citeRegEx": "77", "shortCiteRegEx": "77", "year": 2001}, {"title": "Uniqueness of Update Strategies for Database Views", "author": ["SJ Hegner"], "venue": "Proceedings of the Second International Symposium on Foundations of Information and Knowledge Systems,", "citeRegEx": "78", "shortCiteRegEx": "78", "year": 2002}, {"title": "A Model of Database Components and their Interconnection Based upon Communicating Views", "author": ["SJ Hegner"], "venue": "Proceeding of the 2008 conference on Information Modelling and Knowledge Bases XIX,", "citeRegEx": "79", "shortCiteRegEx": "79", "year": 2007}, {"title": "Propositional Belief Base Update and Minimal Change", "author": ["A Herzig", "O Rifi"], "venue": "Artificial Intelligence,", "citeRegEx": "80", "shortCiteRegEx": "80", "year": 1999}, {"title": "Applying evolutionary algorithms to materialized view selection in a data warehouse", "author": ["JT Horng", "JY Chang", "BJ Liu"], "venue": "Soft Computing,", "citeRegEx": "81", "shortCiteRegEx": "81", "year": 2003}, {"title": "Comparing Abductive Theories", "author": ["K Inoue", "C Sakama"], "venue": "Proceedings of the 2008 conference on ECAI 2008: 18th European Conference on Artificial Intelligence,", "citeRegEx": "82", "shortCiteRegEx": "82", "year": 2008}, {"title": "Abductive Equivalence in First-order Logic", "author": ["K Inoue", "C Sakama"], "venue": "Logic Journal of the IGPL,", "citeRegEx": "83", "shortCiteRegEx": "83", "year": 2006}, {"title": "Model Generation for Horn Logic with Stratified Negation", "author": ["EK Jackson", "W. Schulte"], "venue": "Proceedings of the 28th IFIP WG 6.1 international conference on Formal Techniques for Networked and Distributed Systems,", "citeRegEx": "84", "shortCiteRegEx": "84", "year": 2008}, {"title": "Iterated belief revision, revised", "author": ["Y Jin", "M Thielscher"], "venue": "Artificial Intelligence,", "citeRegEx": "85", "shortCiteRegEx": "85", "year": 2007}, {"title": "Database Updates Through Abduction", "author": ["AC Kakas", "P Mancarella"], "venue": "Proceedings of the 16th International Conference on Very Large Data Bases,", "citeRegEx": "86", "shortCiteRegEx": "86", "year": 1990}, {"title": "Propositional knowledge base revision and minimal change", "author": ["H Katsuno", "Mendelzon", "AO"], "venue": "Artificial Intelligence,", "citeRegEx": "87", "shortCiteRegEx": "87", "year": 1991}, {"title": "On the difference between updating a knowledge base and revising it", "author": ["H Katsuno", "AO Mendelzon"], "venue": null, "citeRegEx": "88", "shortCiteRegEx": "88", "year": 1992}, {"title": "Updating Relational Databases Through Views", "author": ["A Keller"], "venue": null, "citeRegEx": "89", "shortCiteRegEx": "89", "year": 1985}, {"title": "Ontology-based data access systems", "author": ["MR Kogalovsky"], "venue": "Programming and Computer Software,", "citeRegEx": "90", "shortCiteRegEx": "90", "year": 2012}, {"title": "Improvement operators", "author": ["S Konieczny", "R Pino P\u00e9rez"], "venue": "Proceedings Eleventh International Conference on Principles of Knowledge Representation and Reasoning,", "citeRegEx": "92", "shortCiteRegEx": "92", "year": 2008}, {"title": "Taxonomy of improvement operators and the problem of minimal change", "author": ["S Konieczny", "MM Grespan", "RP P\u00e9rez"], "venue": "Proceedings of the Twelfth International Conference on the Principles of Knowledge Representation and Reasoning,", "citeRegEx": "93", "shortCiteRegEx": "93", "year": 2010}, {"title": "Dynamics of Beliefs", "author": ["S Konieczny"], "venue": "Scalable Uncertainty Management Lecture Notes in Computer Science,", "citeRegEx": "94", "shortCiteRegEx": "94", "year": 2011}, {"title": "Logic without model theory", "author": ["R Kowalski"], "venue": "Technical Report,", "citeRegEx": "95", "shortCiteRegEx": "95", "year": 1994}, {"title": "A Logical Account of Relevance", "author": ["G Lakemeyer"], "venue": "International Joint Conference on AI,", "citeRegEx": "97", "shortCiteRegEx": "97", "year": 1995}, {"title": "Horn Complements: Towards Horn-to-Horn Belief Revision", "author": ["M Langlois", "RH Sloan", "B Sz\u00f6r\u00e9nyi", "G Thr\u00e1n"], "venue": "Proceedings of the 23rd national conference on Artificial intelligence,", "citeRegEx": "98", "shortCiteRegEx": "98", "year": 2008}, {"title": "Updating Intensional Predicates in Deductive Databases", "author": ["D Laurent", "VP V. Luonga", "N Spyratosa"], "venue": "Data & Knowledge Engineering,", "citeRegEx": "99", "shortCiteRegEx": "99", "year": 1998}, {"title": "Speeding up materialized view selection in data warehouses using a randomized algorithm", "author": ["M Lee", "J Hammer"], "venue": "International Journal of Cooperative Information Systems,", "citeRegEx": "100", "shortCiteRegEx": "100", "year": 2001}, {"title": "The Complexity of Belief Update (Extended in 2003)", "author": ["P Liberatore"], "venue": "proceedings of the Fifteenth International Joint Conference on Artificial Intelligence1,", "citeRegEx": "101", "shortCiteRegEx": "101", "year": 1997}, {"title": "The Compactness of Belief Revision and Update Operators", "author": ["P Liberatore", "M Schaerf"], "venue": "Fundamenta Informaticae,", "citeRegEx": "102", "shortCiteRegEx": "102", "year": 2004}, {"title": "On the Complexity of Finding Second-Best Abductive Explanations", "author": ["P Liberatore", "M Schaerf"], "venue": "CoRR abs/1204.5859", "citeRegEx": "103", "shortCiteRegEx": "103", "year": 2012}, {"title": "Minimal and Consistent Evolution of Knowledge Bases", "author": ["J Lobo", "G Trajcevski"], "venue": "Journal of Applied Non-Classical Logics, vol:7,", "citeRegEx": "105", "shortCiteRegEx": "105", "year": 1997}, {"title": "Materialized View Selection: A Survey\u2019, IGI book chapter, View Management Techniques and Their Application to Data Stream Management\u2019, DOI: 10.4018/978-1-60566-816-1.ch005", "author": ["X Li"], "venue": null, "citeRegEx": "106", "shortCiteRegEx": "106", "year": 2010}, {"title": "Efficient maintenance of materialized mediated views", "author": ["JJ Lu", "G Moerkotte", "J Schue", "VS Subrahmanian"], "venue": "Proceedings of the 1995 ACM SIGMOD international conference on Management of data, vol.3,", "citeRegEx": "107", "shortCiteRegEx": "107", "year": 1995}, {"title": "View Updates in Disjunctive Deductive Databases Based on SLDResolution", "author": ["W Lu"], "venue": "Proceedings of the 6th International Workshop on Knowledge Representation meets Databases,", "citeRegEx": "108", "shortCiteRegEx": "108", "year": 1999}, {"title": "Maintaining and Restoring Database Consistency with Update Rules", "author": ["S Maabout"], "venue": "Workshop DYNAMICS, Joint International Conference and Symposium on Logic Programming", "citeRegEx": "109", "shortCiteRegEx": "109", "year": 1998}, {"title": "Screened Revision", "author": ["D Makinson"], "venue": "Theoria, vol. 63,", "citeRegEx": "110", "shortCiteRegEx": "110", "year": 1997}, {"title": "Modeling view selection as a constraint satisfaction problem", "author": ["I Mami", "R Coletta", "Z Bellahseneet"], "venue": "Database and Expert Systems Applications Lecture Notes in Computer Science, ed", "citeRegEx": "111", "shortCiteRegEx": "111", "year": 2011}, {"title": "A survey of view selection methods]", "author": ["I Mami", "Z Bellahsene"], "venue": "ACM SIGMOD Record,", "citeRegEx": "112", "shortCiteRegEx": "112", "year": 2012}, {"title": "Efficient Integrity Checking for Databases with Recursive Views", "author": ["D Martinenghi", "H Christiansen"], "venue": "Advances in Databases and Information Systems Lecture Notes in Computer Science, ed. Eder, J, Tallinn, Estonia,", "citeRegEx": "113", "shortCiteRegEx": "113", "year": 2005}, {"title": "Incorporating Modification Requests in Updating Consistent Knowledge Bases", "author": ["E Mayol", "E Teniente"], "venue": "Fourth Int. Works. on the Deductive Approach to Information Systems and Databases,", "citeRegEx": "114", "shortCiteRegEx": "114", "year": 1993}, {"title": "A Survey of Current Methods for Integrity Constraint Maintenance and View Updating", "author": ["E Mayol", "E Teniente"], "venue": "Advances in Conceptual Modeling Lecture Notes in Computer Science,", "citeRegEx": "115", "shortCiteRegEx": "115", "year": 1999}, {"title": "Logical Approaches to Incomplete Information: A Survey\u2019, Logics for Databases and Information", "author": ["R Meyden"], "venue": null, "citeRegEx": "116", "shortCiteRegEx": "116", "year": 1998}, {"title": "Logic and Databases: A 20 Year Retrospective", "author": ["J Minker"], "venue": "Logic in Databases,", "citeRegEx": "117", "shortCiteRegEx": "117", "year": 1996}, {"title": "Reactive Consistency Control in Deductive Databases", "author": ["G Moerkotte"], "venue": "ACM Transactions on Database Systems,", "citeRegEx": "118", "shortCiteRegEx": "118", "year": 1991}, {"title": "Transaction Trees for Knowledge Revision", "author": ["L Mota-Herranz", "M Celma-Gim\u013a\u0119nez", "H Decker"], "venue": "Flexible Query Answering Systems Advances in Soft Computing, ed. Prof. Larsen, HL,", "citeRegEx": "119", "shortCiteRegEx": "119", "year": 2000}, {"title": "Forgetting and Knowledge Update", "author": ["A Nayak", "Y Chen", "F Lin"], "venue": "AI 2006: Advances in Artificial Intelligence Lecture Notes in Computer Science,", "citeRegEx": "120", "shortCiteRegEx": "120", "year": 2006}, {"title": "Is Revision a Special Kind of Update?", "author": ["A Nayak"], "venue": "AI 2011: Advances in Artificial Intelligence Lecture Notes in Computer Science,", "citeRegEx": "121", "shortCiteRegEx": "121", "year": 2011}, {"title": "How Hard is it to Revise a Belief Base?", "author": ["B Nebel"], "venue": "Handbook of Defeasible Reasoning and Uncertainty Management Systems,", "citeRegEx": "122", "shortCiteRegEx": "122", "year": 1998}, {"title": "Knowledge-Base Revision Using Implications as Hypotheses", "author": ["\u00d6 \u00d6z\u00e7ep"], "venue": "KI 2012: Advances in Artificial Intelligence Lecture Notes in Computer Science, ed. Glimm, B, Saarbru\u0308cken, Germany,", "citeRegEx": "123", "shortCiteRegEx": "123", "year": 2012}, {"title": "Beliefs, belief revision, and splitting languages", "author": ["R Parikh"], "venue": "Journal of Logic, language, and Computation,", "citeRegEx": "124", "shortCiteRegEx": "124", "year": 1999}, {"title": "The Role of Abductive Reasoning within the Process of Belief Revision", "author": ["M Pagnucco"], "venue": "PhD Thesis,", "citeRegEx": "125", "shortCiteRegEx": "125", "year": 1996}, {"title": "Knowledge-base revision\u2019, The Knowledge Engineering", "author": ["O Papini"], "venue": "Review, vol. 15,", "citeRegEx": "126", "shortCiteRegEx": "126", "year": 2000}, {"title": "Each normal logic program has a 2-valued Minimal Hypotheses semantics", "author": ["AM Pinto", "LM Pereira"], "venue": "19th International Conference on Applications of Declarative Programming and Knowledge Management,", "citeRegEx": "127", "shortCiteRegEx": "127", "year": 2011}, {"title": "A Survey of Revision Approaches in Description Logics\u2019, Description Logics", "author": ["G Qi", "F Yang"], "venue": "Proceedings of the 2nd International Conference on Web Reasoning and Rule Systems,", "citeRegEx": "128", "shortCiteRegEx": "128", "year": 2008}, {"title": "Belief Revision in Pseudo-Definite Sets", "author": ["Rodrigues", "Benevidas M"], "venue": "In Proceeding of the 11th Brazilian Symposium on AI", "citeRegEx": "129", "shortCiteRegEx": "129", "year": 1994}, {"title": "Change, choice and inference: a study of belief revision and nonmonotonic reasoning\u2019, Oxford logic guides", "author": ["H Rott"], "venue": null, "citeRegEx": "130", "shortCiteRegEx": "130", "year": 2001}, {"title": "Interleaving belief revision and reasoning: preliminary report", "author": ["Sadri. F", "F Toni"], "venue": "In Proceedings of Convegno Italiano di Logica Computazionale", "citeRegEx": "131", "shortCiteRegEx": "131", "year": 2005}, {"title": "Incremental Evaluation of Tabled Logic Programs", "author": ["D Saha", "CR Ramakrishnan"], "venue": "Logic Programming Lecture Notes in Computer Science Volume,", "citeRegEx": "132", "shortCiteRegEx": "132", "year": 2003}, {"title": "Dishonest Reasoning by Abduction", "author": ["C Sakama"], "venue": "Proceedings of the TwentySecond international joint conference on Artificial Intelligence,", "citeRegEx": "133", "shortCiteRegEx": "133", "year": 2011}, {"title": "Equivalence issues in abduction and induction", "author": ["C Sakama", "K Inoue"], "venue": "Journal of Applied Logic, vol.7,", "citeRegEx": "134", "shortCiteRegEx": "134", "year": 2009}, {"title": "An abductive framework for computing Horn knowledge base updates", "author": ["C Sakama", "K Inoue"], "venue": "Journal Theory and Practice of Logic Programming,", "citeRegEx": "135", "shortCiteRegEx": "135", "year": 2003}, {"title": "Updating Extended Logic Programs through Abduction\u2019, Logic Programming and Nonmonotonic Reasoning Lecture Notes in Computer Science, ed", "author": ["C Sakama", "K Inoue"], "venue": null, "citeRegEx": "136", "shortCiteRegEx": "136", "year": 1999}, {"title": "Database Integrity Mechanism between OLTP and Offline Data", "author": ["M Salman", "NU Rehmanet", "M Shahid"], "venue": "Proceedings of the 4th Asian conference on Intelligent Information and Database Systems,", "citeRegEx": "137", "shortCiteRegEx": "137", "year": 2012}, {"title": "Tailoring Consistent Specializations as a Natural Approach to Consistency Enforcement\u2019, 6th Int. Workshop on Foundations of Models and Languages for Data and Objects: Integrity in Databases", "author": ["KD Schewe"], "venue": null, "citeRegEx": "138", "shortCiteRegEx": "138", "year": 1996}, {"title": "Consistency Enforcement in Entity-Relationship and Object Oriented Models", "author": ["KD Schewe"], "venue": "Data & Knowledge Eng,", "citeRegEx": "139", "shortCiteRegEx": "139", "year": 1998}, {"title": "Controlled Automation of Consistency Enforcement", "author": ["KD Schewe"], "venue": "Proceedings of the 15th IEEE international conference on Automated software engineering,", "citeRegEx": "140", "shortCiteRegEx": "140", "year": 2000}, {"title": "Minimal Belief Change and Pareto-Optimality", "author": ["O Schulte"], "venue": "Australian Joint Conference on Artificial Intelligence,", "citeRegEx": "141", "shortCiteRegEx": "141", "year": 1999}, {"title": "Irrevocable Belief Revision in Dynamic Doxastic Logic", "author": ["K Segerberg"], "venue": "Notre Dame Journal of Formal Logic, vol. 39,", "citeRegEx": "142", "shortCiteRegEx": "142", "year": 1998}, {"title": "Deductive Databases: Challenges, Opportunities and Future Directions (Panel Discussion)", "author": ["A Siebes", "S Tsur", "JD Ullman", "L Vieille", "C Zaniolo"], "venue": "Proceedings of the International Workshop on Logic in Databases,", "citeRegEx": "143", "shortCiteRegEx": "143", "year": 1996}, {"title": "Incremental maintenance of externally materialized views", "author": ["M Staudt", "M Jarke"], "venue": "22th International Conference on Very Large Data Bases,", "citeRegEx": "144", "shortCiteRegEx": "144", "year": 1996}, {"title": "A method for change computation in deductive databases", "author": ["T Ur\u1e55\u0131", "A Oliv\u00e9"], "venue": "Proceedings of the 18th International Conference on Very Large Data Bases,", "citeRegEx": "146", "shortCiteRegEx": "146", "year": 1992}, {"title": "Abductive Logics in a Belief Revision Framework", "author": ["B Walliser", "D Zwirnet", "H Zwirn"], "venue": "Journal of Logic, Language and Information, vol:14,", "citeRegEx": "147", "shortCiteRegEx": "147", "year": 2005}, {"title": "First order Theory Refinement\u2019, IOS Frontier in AI and Application Series, Advances in ILP, ed", "author": ["S Wrobel"], "venue": null, "citeRegEx": "148", "shortCiteRegEx": "148", "year": 1995}, {"title": "Language Splitting and Relevance-Based Belief Change in Horn Logic", "author": ["M Wu", "D Zhang", "M Zhang"], "venue": "Twenty-Fifth AAAI Conference on Artificial Intelligence,", "citeRegEx": "149", "shortCiteRegEx": "149", "year": 2011}, {"title": "On Updates and Inconsistency Repairing in Knowledge Bases", "author": ["B W\u00fcthrich"], "venue": "IEEE 9th International Conference on Data Engineering,", "citeRegEx": "150", "shortCiteRegEx": "150", "year": 1993}, {"title": "Algorithms for materialized view design in data warehousing environment", "author": ["J Yang", "K Karlapalem", "Q Liet"], "venue": "Proceedings of the 23rd International Conference on Very Large Data Bases,", "citeRegEx": "151", "shortCiteRegEx": "151", "year": 1997}, {"title": "New Polynomial Classes for Logic-Based Abduction", "author": ["B Zanuttini"], "venue": "Journal of Artificial Intelligence Research,", "citeRegEx": "152", "shortCiteRegEx": "152", "year": 2003}, {"title": "Genetic algorithm for materialized view selection in data warehouse environments\u2019, DataWarehousing and Knowledge Discovery, Lecture Notes in Computer Science, ed", "author": ["C Zhang", "Y Yang"], "venue": null, "citeRegEx": "153", "shortCiteRegEx": "153", "year": 1999}, {"title": "Dynamic materialized views", "author": ["J Zhou", "PA Larson", "J Goldstein", "L Ding"], "venue": "IEEE 23rd International Conference on Data Enginering,", "citeRegEx": "154", "shortCiteRegEx": "154", "year": 2007}], "referenceMentions": [{"referenceID": 24, "context": "Definition 7 ([25]).", "startOffset": 14, "endOffset": 18}, {"referenceID": 2, "context": "Definition 8 ([3]).", "startOffset": 14, "endOffset": 17}, {"referenceID": 28, "context": "Theorem 11 ([29]).", "startOffset": 12, "endOffset": 16}, {"referenceID": 2, "context": "Theorem 12 ([3]).", "startOffset": 12, "endOffset": 15}, {"referenceID": 21, "context": "Definition 46 (Normal Logic Program (NLP) [22]).", "startOffset": 42, "endOffset": 46}, {"referenceID": 3, "context": "Definition 47 (Level mapping[4]).", "startOffset": 28, "endOffset": 31}, {"referenceID": 3, "context": "Definition 48 (Acyclic program [4]).", "startOffset": 31, "endOffset": 34}, {"referenceID": 5, "context": "[6 9] N Ye s C he ck R un Lo gi c Ye s Ye s St at ic N o \u03b9 \u03b4 SL D N F N o N o S Ye s N o 16, 9 N o N ot pr ov ed", "startOffset": 0, "endOffset": 5}, {"referenceID": 8, "context": "[6 9] N Ye s C he ck R un Lo gi c Ye s Ye s St at ic N o \u03b9 \u03b4 SL D N F N o N o S Ye s N o 16, 9 N o N ot pr ov ed", "startOffset": 0, "endOffset": 5}, {"referenceID": 7, "context": "[8 6] N Ye s M ai nt ai n R un Lo gi c Ye s Ye s St at ic Ye s \u03b9 \u03b4 SL D N F N o N o S Ye s N o \u2014 N o N o", "startOffset": 0, "endOffset": 5}, {"referenceID": 5, "context": "[8 6] N Ye s M ai nt ai n R un Lo gi c Ye s Ye s St at ic Ye s \u03b9 \u03b4 SL D N F N o N o S Ye s N o \u2014 N o N o", "startOffset": 0, "endOffset": 5}, {"referenceID": 8, "context": "[9 6] S Ye s C he ck R un Lo gi c Ye s Ye s St at ic Ye s \u03b9 \u03b4 \u2014 Ye s N o SS Ye s Ye s 16, 7 N ot N ot", "startOffset": 0, "endOffset": 5}, {"referenceID": 5, "context": "[9 6] S Ye s C he ck R un Lo gi c Ye s Ye s St at ic Ye s \u03b9 \u03b4 \u2014 Ye s N o SS Ye s Ye s 16, 7 N ot N ot", "startOffset": 0, "endOffset": 5}, {"referenceID": 0, "context": "[1 18 ] N N o M ai nt ai n R un Lo gi c Ye s Ye s St at ic Ye s \u03b9 \u03b4 \u2014 Ye s N o S Ye s N o 16, 7 N o N o", "startOffset": 0, "endOffset": 7}, {"referenceID": 17, "context": "[1 18 ] N N o M ai nt ai n R un Lo gi c Ye s Ye s St at ic Ye s \u03b9 \u03b4 \u2014 Ye s N o S Ye s N o 16, 7 N o N o", "startOffset": 0, "endOffset": 7}, {"referenceID": 6, "context": "[7 0] S Ye s C he ck C om p.", "startOffset": 0, "endOffset": 5}, {"referenceID": 4, "context": "[5 1] N Ye s C he ck R un Lo gi c Ye s N o St at ic Ye s \u03b9 \u03b4 pr ed ef Ye s N o S Ye s N o 16, 7 N ot N o", "startOffset": 0, "endOffset": 5}, {"referenceID": 0, "context": "[5 1] N Ye s C he ck R un Lo gi c Ye s N o St at ic Ye s \u03b9 \u03b4 pr ed ef Ye s N o S Ye s N o 16, 7 N ot N o", "startOffset": 0, "endOffset": 5}, {"referenceID": 0, "context": "[1 46 ] S Ye s C he ck R un Lo gi c Ye s Ye s St at ic Ye s \u03b9 \u03b4 \u03c7 SL D N F N o N o SS Ye s N o 16, 7 Ye s N o", "startOffset": 0, "endOffset": 7}, {"referenceID": 44, "context": "[1 46 ] S Ye s C he ck R un Lo gi c Ye s Ye s St at ic Ye s \u03b9 \u03b4 \u03c7 SL D N F N o N o SS Ye s N o 16, 7 Ye s N o", "startOffset": 0, "endOffset": 7}, {"referenceID": 6, "context": "[7 1] N Ye s M ai nt ai n R un Lo gi c Ye s N o St at ic Ye s \u03b9 \u03b4 U nf ol d Ye s N o SS Ye s N o 16, 9 Ye s Ye s", "startOffset": 0, "endOffset": 5}, {"referenceID": 0, "context": "[7 1] N Ye s M ai nt ai n R un Lo gi c Ye s N o St at ic Ye s \u03b9 \u03b4 U nf ol d Ye s N o SS Ye s N o 16, 9 Ye s Ye s", "startOffset": 0, "endOffset": 5}, {"referenceID": 0, "context": "[1 14 ] N Ye s M ai nt ai n C om p.", "startOffset": 0, "endOffset": 7}, {"referenceID": 13, "context": "[1 14 ] N Ye s M ai nt ai n C om p.", "startOffset": 0, "endOffset": 7}, {"referenceID": 0, "context": "[1 50 ] S Ye s M ai nt ai n R un Lo gi c Ye s Ye s St at ic Ye s \u03b9 \u03b4 U nf ol d.", "startOffset": 0, "endOffset": 7}, {"referenceID": 48, "context": "[1 50 ] S Ye s M ai nt ai n R un Lo gi c Ye s Ye s St at ic Ye s \u03b9 \u03b4 U nf ol d.", "startOffset": 0, "endOffset": 7}, {"referenceID": 7, "context": "[8 ] H Ye s C he ck R un Lo gi c Ye s Ye s St at ic Ye s \u03b9 \u03b4 SL D Ye s N o S Ye s N o 16, 9 Ye s Ye s", "startOffset": 0, "endOffset": 4}, {"referenceID": 1, "context": "[2 6] N N o M ai nt ai n C om p R el at io n Ye s Li m ite d St at ic Ye s \u03b9 \u03b4 \u03c7 A ct iv e Ye s Ye s S Ye s N o \u2014 N o N o", "startOffset": 0, "endOffset": 5}, {"referenceID": 5, "context": "[2 6] N N o M ai nt ai n C om p R el at io n Ye s Li m ite d St at ic Ye s \u03b9 \u03b4 \u03c7 A ct iv e Ye s Ye s S Ye s N o \u2014 N o N o", "startOffset": 0, "endOffset": 5}, {"referenceID": 5, "context": "[6 6] N N o M ai nt ai n C om p R el at io n N o Fl at St at ic Ye s \u03b9 \u03b4 \u03c7 A ct iv e Ye s Ye s S Ye s N o \u2014 N o N o", "startOffset": 0, "endOffset": 5}, {"referenceID": 5, "context": "[6 6] N N o M ai nt ai n C om p R el at io n N o Fl at St at ic Ye s \u03b9 \u03b4 \u03c7 A ct iv e Ye s Ye s S Ye s N o \u2014 N o N o", "startOffset": 0, "endOffset": 5}, {"referenceID": 1, "context": "[2 9] H Ye s C he ck C om p.", "startOffset": 0, "endOffset": 5}, {"referenceID": 8, "context": "[2 9] H Ye s C he ck C om p.", "startOffset": 0, "endOffset": 5}, {"referenceID": 2, "context": "[3 7] N Ye s M ai nt ai n R un Lo gi c Ye s Fl at St at ic Ye s \u03b9 \u03b4 U nf ol d.", "startOffset": 0, "endOffset": 5}, {"referenceID": 6, "context": "[3 7] N Ye s M ai nt ai n R un Lo gi c Ye s Fl at St at ic Ye s \u03b9 \u03b4 U nf ol d.", "startOffset": 0, "endOffset": 5}, {"referenceID": 0, "context": "[1 07 ] N Ye s M ai nt ai n R un Lo gi c Ye s Li m ite d St at ic N o \u03b9 \u03b4 A ct iv e Ye s N o SS Ye s N o 16, 7 Ye s N ot pr ov ed", "startOffset": 0, "endOffset": 7}, {"referenceID": 0, "context": "[1 45 ] N Ye s M ai nt ai n C om p Lo gi c Ye s Ye s St at ic Ye s \u03b9 \u03b4 SL D N F Ye s N o S Ye s N o 16, 9 Ye s Ye s", "startOffset": 0, "endOffset": 7}, {"referenceID": 43, "context": "[1 45 ] N Ye s M ai nt ai n C om p Lo gi c Ye s Ye s St at ic Ye s \u03b9 \u03b4 SL D N F Ye s N o S Ye s N o 16, 9 Ye s Ye s", "startOffset": 0, "endOffset": 7}, {"referenceID": 0, "context": "[1 38 ] S Ye s M ai nt ai n C om p Lo gi c N o Fl at St at ic Ye s \u03b9 \u03b4 pr ed ef \u2014 Ye s G N o Ye s \u2014 N o N ot", "startOffset": 0, "endOffset": 7}, {"referenceID": 37, "context": "[1 38 ] S Ye s M ai nt ai n C om p Lo gi c N o Fl at St at ic Ye s \u03b9 \u03b4 pr ed ef \u2014 Ye s G N o Ye s \u2014 N o N ot", "startOffset": 0, "endOffset": 7}, {"referenceID": 0, "context": "[1 44 ] N N o M ai nt ai n C om p Lo gi c Ye s Li m ite d St at ic Ye s \u03b9 \u03b4 \u03c7 P re de f Ye s N o S Ye s N o 16, 7 Ye s N o", "startOffset": 0, "endOffset": 7}, {"referenceID": 42, "context": "[1 44 ] N N o M ai nt ai n C om p Lo gi c Ye s Li m ite d St at ic Ye s \u03b9 \u03b4 \u03c7 P re de f Ye s N o S Ye s N o 16, 7 Ye s N o", "startOffset": 0, "endOffset": 7}, {"referenceID": 0, "context": "[1 0] H Ye s C he ck R un Lo gi c Ye s Li m ite d St at ic Ye s \u03b9 \u03b4 SL D Ye s N o S Ye s N o 16, 9 Ye s Ye s", "startOffset": 0, "endOffset": 5}, {"referenceID": 3, "context": "[4 0] N Ye s M ai nt ai n R un Lo gi c Ye s Ye s St at ic Ye s \u03b9 \u03b4 SL D N F N o N o S Ye s N o 16, 7 N o N ot P ro ve d", "startOffset": 0, "endOffset": 5}, {"referenceID": 0, "context": "[1 05 ] N Ye s M ai nt ai n R un Lo gi c Ye s Fl at St at ic Ye s \u03b9 \u03b4 U nf ol d N o Ye s G Ye s N o 16, 7 N ot N o", "startOffset": 0, "endOffset": 7}, {"referenceID": 0, "context": "[1 51 ] H N o M ai nt ai n C om p.", "startOffset": 0, "endOffset": 7}, {"referenceID": 49, "context": "[1 51 ] H N o M ai nt ai n C om p.", "startOffset": 0, "endOffset": 7}, {"referenceID": 0, "context": "[1 09 ] N N o M ai nt ai n C om p Lo gi c N o Fl at St at ic Ye s \u03b9 \u03b4 A ct iv e Ye s N o G N o N o \u2014 N o N o", "startOffset": 0, "endOffset": 7}, {"referenceID": 0, "context": "[1 39 ] N N o M ai nt ai n C om p R el at io n N o Fl at St at ic Ye s \u03b9 \u03b4 A ct iv e Ye s N o S N o N o \u2014 N o N o", "startOffset": 0, "endOffset": 7}, {"referenceID": 38, "context": "[1 39 ] N N o M ai nt ai n C om p R el at io n N o Fl at St at ic Ye s \u03b9 \u03b4 A ct iv e Ye s N o S N o N o \u2014 N o N o", "startOffset": 0, "endOffset": 7}, {"referenceID": 0, "context": "[1 08 ] N Ye s C he ck R un Lo gi c Ye s Li m ite d St at ic Ye s \u03b9 \u03b4 SL D Ye s N o S Ye s N o 16, 9 Ye s Ye s", "startOffset": 0, "endOffset": 7}, {"referenceID": 0, "context": "[1 ] O N o M ai nt ai n R un Lo gi c Ye s Li m ite d St at ic Ye s \u03b9 \u03b4 \u2014 Ye s N o S Ye s N o \u2014 N o N o", "startOffset": 0, "endOffset": 4}, {"referenceID": 0, "context": "[1 40 ] N N o M ai nt ai n C om p R el at io n N o Li m ite d St at ic Ye s \u03b9 \u03b4 P re de f N o N o G N o N o \u2014 N o N o", "startOffset": 0, "endOffset": 7}, {"referenceID": 39, "context": "[1 40 ] N N o M ai nt ai n C om p R el at io n N o Li m ite d St at ic Ye s \u03b9 \u03b4 P re de f N o N o G N o N o \u2014 N o N o", "startOffset": 0, "endOffset": 7}, {"referenceID": 6, "context": "[7 2] N N o M ai nt ai n C om p Lo gi c Ye s Li m ite d St at ic Ye s \u03b9 \u03b4 \u2014 N o N o S N o N o \u2014 N o N o", "startOffset": 0, "endOffset": 5}, {"referenceID": 1, "context": "[7 2] N N o M ai nt ai n C om p Lo gi c Ye s Li m ite d St at ic Ye s \u03b9 \u03b4 \u2014 N o N o S N o N o \u2014 N o N o", "startOffset": 0, "endOffset": 5}, {"referenceID": 2, "context": "[3 0] N N o M ai nt ai n C om p.", "startOffset": 0, "endOffset": 5}, {"referenceID": 4, "context": "[5 2] H Ye s C he ck R un Lo gi c Ye s Ye s St at ic Ye s \u03b9 \u03b4 P re de f Ye s N o S Ye s N o 16, 7 Ye s N ot", "startOffset": 0, "endOffset": 5}, {"referenceID": 1, "context": "[5 2] H Ye s C he ck R un Lo gi c Ye s Ye s St at ic Ye s \u03b9 \u03b4 P re de f Ye s N o S Ye s N o 16, 7 Ye s N ot", "startOffset": 0, "endOffset": 5}, {"referenceID": 6, "context": "[7 8] O Ye s C he ck R un R el at io n Ye s Li m ite d St at ic N o \u03b9 \u03b4 U nf ol d Ye s N o S Ye s N o 16, 9 Ye s Ye s", "startOffset": 0, "endOffset": 5}, {"referenceID": 7, "context": "[7 8] O Ye s C he ck R un R el at io n Ye s Li m ite d St at ic N o \u03b9 \u03b4 U nf ol d Ye s N o S Ye s N o 16, 9 Ye s Ye s", "startOffset": 0, "endOffset": 5}, {"referenceID": 0, "context": "[1 4] O Ye s C he ck R un R el at io n Ye s Li m ite d St at ic N o \u03b9 \u03b4 U nf ol d Ye s N o S Ye s N o 16, 9 Ye s Ye s", "startOffset": 0, "endOffset": 5}, {"referenceID": 3, "context": "[1 4] O Ye s C he ck R un R el at io n Ye s Li m ite d St at ic N o \u03b9 \u03b4 U nf ol d Ye s N o S Ye s N o 16, 9 Ye s Ye s", "startOffset": 0, "endOffset": 5}, {"referenceID": 4, "context": "[5 6] N Ye s C he ck R un Lo gi c Ye s Ye s St at ic Ye s \u03b9 \u03b4 SL D N F Ye s N o S Ye s N o 16, 9 Ye s Ye s", "startOffset": 0, "endOffset": 5}, {"referenceID": 5, "context": "[5 6] N Ye s C he ck R un Lo gi c Ye s Ye s St at ic Ye s \u03b9 \u03b4 SL D N F Ye s N o S Ye s N o 16, 9 Ye s Ye s", "startOffset": 0, "endOffset": 5}, {"referenceID": 0, "context": "[1 32 ] N N o M ai nt ai n R un Lo gi c Ye s Li m ite d St at ic Ye s \u03b9 \u03b4 P re de f Ye s N o S Ye s N o 16, 7 Ye s N ot", "startOffset": 0, "endOffset": 7}, {"referenceID": 31, "context": "[1 32 ] N N o M ai nt ai n R un Lo gi c Ye s Li m ite d St at ic Ye s \u03b9 \u03b4 P re de f Ye s N o S Ye s N o 16, 7 Ye s N ot", "startOffset": 0, "endOffset": 7}, {"referenceID": 7, "context": "[8 1] O N o M ai nt ai n C om p R el at io n Ye s Li m ite d St at ic Ye s \u03b9 \u03b4 \u2014 Ye s N o S Ye s N o \u2014 N o N o", "startOffset": 0, "endOffset": 5}, {"referenceID": 0, "context": "[8 1] O N o M ai nt ai n C om p R el at io n Ye s Li m ite d St at ic Ye s \u03b9 \u03b4 \u2014 Ye s N o S Ye s N o \u2014 N o N o", "startOffset": 0, "endOffset": 5}, {"referenceID": 0, "context": "[1 35 ] N Ye s C he ck R un Lo gi c N o Li m ite d St at ic Ye s \u03b9 \u03b4 SL D N F Ye s N o S Ye s N o 16, 9 Ye s Ye s", "startOffset": 0, "endOffset": 7}, {"referenceID": 34, "context": "[1 35 ] N Ye s C he ck R un Lo gi c N o Li m ite d St at ic Ye s \u03b9 \u03b4 SL D N F Ye s N o S Ye s N o 16, 9 Ye s Ye s", "startOffset": 0, "endOffset": 7}, {"referenceID": 4, "context": "[5 7] N Ye s C he ck R un Lo gi c Ye s Ye s St at ic N o \u03b9 \u03b4 SL D N F N o N o S Ye s N o 16, 9 N ot N o pr ov ed", "startOffset": 0, "endOffset": 5}, {"referenceID": 6, "context": "[5 7] N Ye s C he ck R un Lo gi c Ye s Ye s St at ic N o \u03b9 \u03b4 SL D N F N o N o S Ye s N o 16, 9 N ot N o pr ov ed", "startOffset": 0, "endOffset": 5}, {"referenceID": 0, "context": "[1 13 ] N Ye s C he ck R un Lo gi c Ye s Ye s St at ic N o \u03b9 \u03b4 \u03c7 SL D Ye s N o S Ye s N o \u2014 N o N o", "startOffset": 0, "endOffset": 7}, {"referenceID": 12, "context": "[1 13 ] N Ye s C he ck R un Lo gi c Ye s Ye s St at ic N o \u03b9 \u03b4 \u03c7 SL D Ye s N o S Ye s N o \u2014 N o N o", "startOffset": 0, "endOffset": 7}, {"referenceID": 0, "context": "[1 9] N Ye s C he ck R un Lo gi c Ye s Ye s St at ic N o \u03b9 \u03b4 \u03c7 SL D Ye s N o SS Ye s N o 16, 7 Ye s N ot", "startOffset": 0, "endOffset": 5}, {"referenceID": 8, "context": "[1 9] N Ye s C he ck R un Lo gi c Ye s Ye s St at ic N o \u03b9 \u03b4 \u03c7 SL D Ye s N o SS Ye s N o 16, 7 Ye s N ot", "startOffset": 0, "endOffset": 5}, {"referenceID": 2, "context": "[3 1] N Ye s C he ck R un Lo gi c Ye s Ye s St at ic Ye s \u03b9 \u03b4 \u03c7 P re de f Ye s N o S Ye s N o 16, 9 Ye s Ye s", "startOffset": 0, "endOffset": 5}, {"referenceID": 0, "context": "[3 1] N Ye s C he ck R un Lo gi c Ye s Ye s St at ic Ye s \u03b9 \u03b4 \u03c7 P re de f Ye s N o S Ye s N o 16, 9 Ye s Ye s", "startOffset": 0, "endOffset": 5}, {"referenceID": 1, "context": "[2 5] N Ye s C he ck C om p Lo gi c Ye s Ye s D yn am ic Ye s \u03b9 \u03b4 P re de f Ye s N o S Ye s N o \u2014 N ot N o", "startOffset": 0, "endOffset": 5}, {"referenceID": 4, "context": "[2 5] N Ye s C he ck C om p Lo gi c Ye s Ye s D yn am ic Ye s \u03b9 \u03b4 P re de f Ye s N o S Ye s N o \u2014 N ot N o", "startOffset": 0, "endOffset": 5}, {"referenceID": 2, "context": "[3 2] N Ye s C he ck R un Lo gi c Ye s Ye s St at ic Ye s \u03b9 \u03b4 \u03c7 P re de f Ye s N o S Ye s N o 16, 9 Ye s Ye s", "startOffset": 0, "endOffset": 5}, {"referenceID": 1, "context": "[3 2] N Ye s C he ck R un Lo gi c Ye s Ye s St at ic Ye s \u03b9 \u03b4 \u03c7 P re de f Ye s N o S Ye s N o 16, 9 Ye s Ye s", "startOffset": 0, "endOffset": 5}, {"referenceID": 2, "context": "[3 5] N N o M ai nt ai n C om p Lo gi c Ye s N o \u2014 Ye s \u03b9 \u03b4 \u2014 Ye s N o S Ye s N o \u2014 N o N o", "startOffset": 0, "endOffset": 5}, {"referenceID": 4, "context": "[3 5] N N o M ai nt ai n C om p Lo gi c Ye s N o \u2014 Ye s \u03b9 \u03b4 \u2014 Ye s N o S Ye s N o \u2014 N o N o", "startOffset": 0, "endOffset": 5}, {"referenceID": 0, "context": "[1 54 ] N N o M ai nt ai n R un R el at io n Ye s N o \u2014 Ye s \u03b9 \u03b4 \u03c7 U nf ol d Ye s N o SS N o N o \u2014 N ot N ot", "startOffset": 0, "endOffset": 7}, {"referenceID": 52, "context": "[1 54 ] N N o M ai nt ai n R un R el at io n Ye s N o \u2014 Ye s \u03b9 \u03b4 \u03c7 U nf ol d Ye s N o SS N o N o \u2014 N ot N ot", "startOffset": 0, "endOffset": 7}, {"referenceID": 6, "context": "[7 9] O N o M ai nt ai n C om p.", "startOffset": 0, "endOffset": 5}, {"referenceID": 8, "context": "[7 9] O N o M ai nt ai n C om p.", "startOffset": 0, "endOffset": 5}, {"referenceID": 0, "context": "[1 5] S Ye s C he ck R un Lo gi c Ye s Fl at St at ic Ye s \u03b9 \u03b4 SL D N F Ye s N o S Ye s N o 16, 9 Ye s N ot", "startOffset": 0, "endOffset": 5}, {"referenceID": 4, "context": "[1 5] S Ye s C he ck R un Lo gi c Ye s Fl at St at ic Ye s \u03b9 \u03b4 SL D N F Ye s N o S Ye s N o 16, 9 Ye s N ot", "startOffset": 0, "endOffset": 5}, {"referenceID": 4, "context": "[5 3] N Ye s C he ck R un Lo gi c Ye s Ye s St at ic Ye s \u03b9 \u03b4 \u2014 Ye s N o S Ye s N o \u2014 N o N o", "startOffset": 0, "endOffset": 5}, {"referenceID": 2, "context": "[5 3] N Ye s C he ck R un Lo gi c Ye s Ye s St at ic Ye s \u03b9 \u03b4 \u2014 Ye s N o S Ye s N o \u2014 N o N o", "startOffset": 0, "endOffset": 5}, {"referenceID": 1, "context": "[2 7] O N o M ai nt ai n R un R el at io n Ye s N o St at ic Ye s \u03b9 \u03b4 SL D Ye s Ye s G N o N o \u2014 N ot N ot", "startOffset": 0, "endOffset": 5}, {"referenceID": 6, "context": "[2 7] O N o M ai nt ai n R un R el at io n Ye s N o St at ic Ye s \u03b9 \u03b4 SL D Ye s Ye s G N o N o \u2014 N ot N ot", "startOffset": 0, "endOffset": 5}, {"referenceID": 0, "context": "[1 6] O N o M ai nt ai n C om p R el at io n Ye s N o St at ic Ye s \u03b9 \u03b4 \u03c7 \u2014 Ye s N o SS Ye s N o \u2014 N o N o", "startOffset": 0, "endOffset": 5}, {"referenceID": 5, "context": "[1 6] O N o M ai nt ai n C om p R el at io n Ye s N o St at ic Ye s \u03b9 \u03b4 \u03c7 \u2014 Ye s N o SS Ye s N o \u2014 N o N o", "startOffset": 0, "endOffset": 5}, {"referenceID": 3, "context": "[4 ] O N o M ai nt ai n C om p.", "startOffset": 0, "endOffset": 4}, {"referenceID": 0, "context": "[1 11 ] N N o M ai nt ai n C om p R el at io n N o Ye s St at ic Ye s \u03b9 \u03b4 \u03c7 U nf ol d N o Ye s SS N o N o \u2014 N o N o", "startOffset": 0, "endOffset": 7}, {"referenceID": 10, "context": "[1 11 ] N N o M ai nt ai n C om p R el at io n N o Ye s St at ic Ye s \u03b9 \u03b4 \u03c7 U nf ol d N o Ye s SS N o N o \u2014 N o N o", "startOffset": 0, "endOffset": 7}, {"referenceID": 0, "context": "[1 37 ] N N o C he ck C om p Lo gi c N o Ye s St at ic Ye s \u03b9 \u03b4 A ct iv e Ye s N o G Ye s N o \u2014 N o N o", "startOffset": 0, "endOffset": 7}, {"referenceID": 36, "context": "[1 37 ] N N o C he ck C om p Lo gi c N o Ye s St at ic Ye s \u03b9 \u03b4 A ct iv e Ye s N o G Ye s N o \u2014 N o N o", "startOffset": 0, "endOffset": 7}, {"referenceID": 3, "context": "[4 1] N Ye s C he ck R un Lo gi c Ye s Ye s St at ic Ye s \u03b9 \u03b4 SL D Ye s N o S Ye s N o 16, 9 Ye s Ye s", "startOffset": 0, "endOffset": 5}, {"referenceID": 0, "context": "[4 1] N Ye s C he ck R un Lo gi c Ye s Ye s St at ic Ye s \u03b9 \u03b4 SL D Ye s N o S Ye s N o 16, 9 Ye s Ye s", "startOffset": 0, "endOffset": 5}], "year": 2015, "abstractText": "The dynamics of belief and knowledge is one of the major components of any autonomous system that should be able to incorporate new pieces of information. In order to apply the rationality result of belief dynamics theory to various practical problems, it should be generalized in two respects: first it should allow a certain part of belief to be declared as immutable; and second, the belief state need not be deductively closed. Such a generalization of belief dynamics, referred to as base dynamics, is presented in this paper, along with the concept of a generalized revision algorithm for knowledge bases (Horn or Horn logic with stratified negation). We show that knowledge base dynamics has an interesting connection with kernel change via hitting set and abduction. In this paper, we show how techniques from disjunctive logic programming can be used for efficient (deductive) database updates. The key idea is to transform the given database together with the update request into a disjunctive (datalog) logic program and apply disjunctive techniques (such as minimal model reasoning) to solve the original update problem. The approach extends and integrates standard techniques for efficient query answering and integrity checking. The generation of a hitting set is carried out through a hyper tableaux calculus and magic set that is focused on the goal of minimality. The present paper provides a comparative study of view update algorithms in rational approach. For, understand the basic concepts with abduction, we provide an abductive framework for knowledge base dynamics. Finally, we demonstrate how belief base dynamics can provide an axiomatic characterization for insertion a view atom to the database. We give a quick overview of the main operators for belief change, in particular, belief update versus database update. Keyword: AGM, Belief Revision, Belief Update, Horn Knowledge Base Dynamics, Kernel Change, Abduction, Hyber Tableaux, Magic Set, View update, Update Propagation.", "creator": "LaTeX with hyperref package"}}}