{"id": "1502.00598", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "2-Feb-2015", "title": "Lock in Feedback in Sequential Experiments", "abstract": "We often encounter situations in which an experimenter wants to find, by sequential experimentation, $x_{max} = \\arg\\max_{x} f(x)$, where $f(x)$ is a (possibly unknown) function of a well controllable variable $x$. Taking inspiration from physics and engineering, we have designed a new method to address this problem. In this paper, we first introduce the method in continuous time, and then present two algorithms for use in sequential experiments. Through a series of simulation studies, we show that the method is effective for finding maxima of unknown functions by experimentation, even when the maximum of the functions drifts or when the signal to noise ratio is low. To achieve this, we use a first-generation, independent approach by a single group of researchers in a group of researchers, with the goal of demonstrating the efficiency of these experiments. In our next paper we will show how to use the concept of continuous time as an integral principle.\n\n\n\nA computational model of computational time (C) is defined by the following formula:\n\\frac{2^{2^{2}}\\sqrt{2}^{2}^2(b2+b2+b2+b2+b2+b2+b2+b2+b2+b2+b2+b2+b2+b2+b2+b2+b2+b2+b2+b2+b2+b2+b2+b2+b2+b2+b2+b2+b2+b2+b2+b2+b2+b2+b2+b2+b2+b2+b2+b2+b2+b2+b2+b2+b2+b2+b2+b2+b2+b2+b2+b2+b2+b2+b2+b2+b2+b2+b2+b2+b2+b2+b2+b2+b2+b2+b2+b2+b2+b2+b2+b2+b2+b2+b2+b2+b2+b2+b2+b2+b2+b2+b2+b2+b2+b2+b2+b2+b2+b2+", "histories": [["v1", "Mon, 2 Feb 2015 20:00:13 GMT  (1387kb,D)", "http://arxiv.org/abs/1502.00598v1", "7 Pages, 4 Figures"], ["v2", "Tue, 3 Feb 2015 08:11:33 GMT  (1387kb,D)", "http://arxiv.org/abs/1502.00598v2", "7 Pages, 4 Figures"], ["v3", "Tue, 12 Jan 2016 08:20:21 GMT  (1825kb,D)", "http://arxiv.org/abs/1502.00598v3", "20 Pages, 7 Figures"]], "COMMENTS": "7 Pages, 4 Figures", "reviews": [], "SUBJECTS": "cs.LG", "authors": ["maurits kaptein", "davide iannuzzi"], "accepted": false, "id": "1502.00598"}, "pdf": {"name": "1502.00598.pdf", "metadata": {"source": "META", "title": "Thompson sampling with the online bootstrap", "authors": ["Maurits Kaptein", "Davide Iannuzzi"], "emails": [], "sections": [{"heading": "1. Introduction", "text": "We often encounter situations in which an experimenter wants to find, by sequential experimentation, ~xmax = arg max~x y = f(~x), where f(~x) is a (possibly unknown) function of a well controllable variable ~x. To solve this problem in physics and engineering applications, scientists have been routinely implemented techniques that rely on the idea of systematically changing the value of the controllable variable in time and following, via so-called lock-in amplifier techniques, how those changes affect the dependent variable y. Applications of the problem of finding arg maxx f(x) are manifold and prominent in a much wider range of fields. For example, in economics, firms might be able to manipulate features of a product (~x), such as the price, and observe the revenue (y). The exact functional relationship between product features and revenue might not be known but can sequentially be sampled (for examples see Kung et al., 2002; Jiang et al., 2011) (especially using modern interactive communication technologies, such as, for instance, e-commerce). The obvious aim of the firm is to select the product features that maximize the revenue. The problem also presents itself in the medical sciences when considering the dose of medication or composition of nutrition: often researchers seek for an optimal dosage according to some observable criterion, but the functional relationship between the dosage and the outcome measure is unknown (see, e.g., Sapareto and Dewey, 1984; Marschner, 2007). Despite the fact that the problem presents itself in many places, there is however no single agreed upon method to approach it. It is thus worth asking whether it be possible to adapt the lock-in a amplifier algorithm used in physics and engineering as a generic tool to find ~xmax = arg max~x y = f(~x). The goal of this paper is to address this topic. We focus on the simple case where x is a scalar. In the remainder of this paper, we index sequential trials by t \u2208 {1, . . . , T } and our ultimate aim is to describe a novel method for manipu-\n1\nimsart-generic ver. 2011/11/15 file: arXiv_Lockin.tex date: October 6, 2017\nar X\niv :1\n50 2.\n00 59\n8v 1\n[ cs\n.L G\n] 2\nF eb\n2 01\n5\nlating xt (in discrete time) to find, sequentially, the value of x that maximizes y. We coin the method Lock-in Feedback (LiF).\nThe problem of finding arg max~x f(~x) is treated in a number of branches in the experimental design and machine learning literature. The problem can be approached as an optimal design problem, in which the main aim is to design an experiment that efficiently provides us with information regarding f(~x) (see, e.g., O\u2019Brien and Funk, 2003; Myung and Pitt, 2009a). However, one could also frame the problem as a bandit problem (Berry and Fristedt, 1985), where the actions a \u2208 A are the choice for the (continuous) value of x, and the rewards at each interaction rt are (some function of) y (Bubeck et al., 2011). In this paper we focus on the introduction and examination of our novel approach to this specific problem, and defer the embedding within the bandit and optimal design literature to the discussion Section.\nAS mentioned above, our method is based on an approach used in physics and engineering, where, if a physical variable y depends on the value of a well controllable physical variable x, the search for arg maxx f(x) can be solved via what is nowadays considered as standard electronics. This approach relies on the possibility of making the variable x oscillate at a fixed frequency and to look at the response of the dependent variable y at the very same frequency by means of a lock-in amplifier (Meade, 1983). The method is particularly suitable when y is immersed in a high noise level, where other more direct methods would fail. Furthermore, should the entire curve shift (or, in other words, if arg maxx f(x) changes in time, also known as concept drift), the circuit will automatically adjust to the new situation and quickly reveal the new maximum position. This approach is widely used in a very large number of applications, both in industry and research (Meade, 1983), and is the basis for the Lock-in Feedback (LiF) method we introduce in this paper.\nIn the following sections we first introduce LiF in more detail. We present an analysis of LiF in continuous time and demonstrate how an oscillating manipulation of the independent variable x can be used as a strategy to find arg maxx y = f(x). Subsequently we present two algorithms to use LiF in sequential experiments. We then, by simulation, compare the two algorithms, and examine the performance of LiF in several scenario\u2019s of signal-to-noise ratio and in situations of concept drift (e.g., Gaber et al., 2005). Finally we discuss the opportunities that LiF may offer for future experiments and a number of open questions regarding this proposed experimental regime."}, {"heading": "2. Finding the maximum of a curve with a lock-in algorithm: a short introduction", "text": "In this section we detail the basic principles behind LiF assuming continuous time in which x can be manipulated. Let\u2019s assume that y is a continuous function f of x: y = f(x). Let\u2019s further assume that x oscillates with time according to:\nx(t) = x0 +A cos (\u03c9t) (1)\nimsart-generic ver. 2011/11/15 file: arXiv_Lockin.tex date: October 6, 2017\nwhere \u03c9 is the angular frequency of the oscillation, x0 its central value, and A its amplitude. For relatively small values of A, Taylor expanding f(x) around x0 to the second order, one obtains:\ny(x(t)) = f(x0) + (x0 \u2212 x0 \u2212A cos (\u03c9t))\n( \u2202f\n\u2202x \u2223\u2223\u2223\u2223 x=x0 )\n+ 1\n2 (x0 \u2212 x0 \u2212A cos (\u03c9t))2\n( \u22022f\n\u2202x2 \u2223\u2223\u2223\u2223 x=x0 ) (2) which can be simplified to:\ny(x(t)) = k \u2212A cos (\u03c9t)\n( \u2202f\n\u2202x \u2223\u2223\u2223\u2223 x=x0 )\n+ 1\n4 A2 cos (2\u03c9t)\n( \u22022f\n\u2202x2 \u2223\u2223\u2223\u2223 x=x0 ) (3)\nwhere k = f(x0) + 1/4 ( \u22022f/\u2202x2 \u2223\u2223 x=x0 ) . It is thus evident that, for small oscillations, y becomes the sum of three terms: a constant term, a term oscillating at angular frequency \u03c9, and a term oscillating at angular frequency 2\u03c9.\nSuppose we ourselves can actively manipulate x and measure y, and that f is continuous and only has one maximum and no minimum.1 Further suppose that one is interested to find the value arg maxx y = f(x) which we denote with xmax, and that our measurements of y contain noise\ny(t) = f(x(t)) + (4)\nwhere denotes the noise and \u223c \u03c0() where \u03c0 is some probability density function and E[ |x] = 0.\nFollowing the scheme used in physical lock-in amplifiers (see, e.g., Scofield, 1994), we multiply the observed y variable by cos (\u03c9t). Using eq. 3 and eq. 4, one obtains:\ny\u03c9(t) = cos (\u03c9t)\n[ k \u2212A cos (\u03c9t) ( \u2202f\n\u2202x \u2223\u2223\u2223\u2223 x=x0 )\n+ 1\n4 A2 cos (2\u03c9t)\n( \u22022f\n\u2202x2 \u2223\u2223\u2223\u2223 x=x0 ) + ] (5) where y\u03c9 is the value of y after it has been multiplied by cos (\u03c9t). Eq. 5 can be written more compactly as:\ny\u03c9 = \u2212 A\n2\n( \u2202f\n\u2202x \u2223\u2223\u2223\u2223 x=x0 ) + k\u03c9 cos (\u03c9t) + k2\u03c9 cos (2\u03c9t)\n+ k3\u03c9 cos (3\u03c9t) + cos (\u03c9t)\n(6)\n1For simplicity of exposure we only consider these well-behaved functions in this paper.\nimsart-generic ver. 2011/11/15 file: arXiv_Lockin.tex date: October 6, 2017\nwhere\nk\u03c9 = k +A 2/8 ( \u22022f/\u2202x2 \u2223\u2223 x=x0 ) (7)\nk2\u03c9 = \u2212A/2 ( \u22022f/\u2202x2 \u2223\u2223 x=x0 ) (8)\nk3\u03c9 = A 2/8 ( \u22022f/\u2202x2 \u2223\u2223 x=x0 ) . (9)\nIntegrating y\u03c9 over a time T = 2\u03c0N \u03c9 , where N is a positive integer and T denotes the time needed to integrate N full oscillations, one obtains:\ny\u2217\u03c9 = \u2212 TA\n2\n( \u2202f\n\u2202x \u2223\u2223\u2223\u2223 x=x0 ) + \u222b T 0 cos (\u03c9t) (10)\nDepending on the noise level, one can tailor the integration time, T , in such a way to reduce the second addendum of the right hand of eq. 10 to negligible levels, effectively averaging out the noise in the measurements. Under those circumstances, y\u2217\u03c9 provides a direct measurement of the value of the first derivative of f at x = x0.\nThe above method thus yields quantitative information regarding the first derivative of f at x = x0, providing, in this way, a logical update strategy of x0: if y \u2217 \u03c9 < 0, then x0 is larger than the value of x that maximizes f ; likewise, if y\u2217\u03c9 > 0, x0 is smaller than the value of x that maximizes f . Thus, based on the oscillation observed in y\u03c9 we are now able to move x0 closer to x = arg maxx f(x) using an update rule x0 := x0 + \u03b3y \u2217 \u03c9 where \u03b3 quantifies the learn rate of the procedure. Hence, we can setup a feedback loop that allows us to keep x0 close to xmax, even if f(x) changes over time.\nNote that, multiplying y by cos 2\u03c9t and using a similar approach as the one described above to extract the amplitude of the oscillation of y at frequency 2\u03c9, one would be able to measure the second derivative of the function f at x = x0. This property can be useful when, for instance, f(x) is known to be an exact parabola to not only derive the direction of the step towards the maximum, but to work out the exact step size (see Appendix A)."}, {"heading": "3. Algorithm for LiF in experiments", "text": "In practical terms, measurements can never run in continuous mode. Therefore, we now present an algorithm for LiF in discrete time. To simplify notation, we will index sequential measurements by yt where t = 1, . . . , t = T where T denotes the length\u2014possibly infinite\u2014of the experiment that is ran to find arg maxx f(x).\nIn discrete time we can use the same procedure as above in which we start with x0, and for each sample oscillate around x0 with a known frequency \u03c9 and known amplitude A:\nxt = x0 +A cos\u03c9t (11)\nimsart-generic ver. 2011/11/15 file: arXiv_Lockin.tex date: October 6, 2017\nwhich will result in measurements given by\nyt = f(x0 +A cos\u03c9t) + t (12)\nOn the basis of the arguments reported above, we can now implement a feedback loop that iteratively adjusts the value of x0 until x reaches xmax. After that, if the function f changes, the loop can follow the value of x to the new maximizing position and thus stay \u201clocked\u201d. The procedure is similar to that given in Equation 6 and 10, where we first multiply the outcome yt by cos(\u03c9t) and subsequently integrate out the noise term (summing in the discrete case). In the following sections we present two possible implementations for LiF in discrete time for use in sequential experiments."}, {"heading": "3.1. LiF-I: Batch updates of x0", "text": "Our first implementation of LiF (denoted LiF-I) is presented in Algorithm 1. In this implementation we summate observations yt, which we multiply by cos(\u03c9t), for a batch period of length T , after which we update x0. Variable y \u03a3 \u03c9 contains a running sum that is used for the integration.\nAlgorithm 1 Implementation of LiF-I for single variable maximization in data stream using a batch approach. Require: x0, A, T , \u03b3, y\u03a3\u03c9 = 0 \u03c9 = 2\u03c0\nT for t = 1, . . . , T do xt = x0 +A cos\u03c9t yt = f(x0 +A cos\u03c9t) + t y\u03a3\u03c9 = y \u03a3 \u03c9 + yt cos\u03c9t\nif (t mod T == 0) then y\u2217\u03c9 = y \u03a3 \u03c9 /T\nx0 = x0 + \u03b3y\u2217\u03c9 y\u03a3\u03c9 = 0\nend if end for\nThe tuning parameters for LiF-I, which should be set by the experimenter, are x0, A, T , \u03b3. Here below we describe some general criteria the choice may be based on:\n\u2022 It is advised to set x0 as close as possible to xmax. The choice can only be based on the available information on f . The more accurate the information, the closer the initial x0 to xmax, the faster the convergence of the loop to xmax. \u2022 The amplitude A affects the costs of the search procedure, because a large A implies querying a large range of x values with (possibly) low resulting y values. However, A also influence the learning speed: a very small A leads to small updates steps, while a large value of A might lead to a value of \u03b3y\u2217\u03c9 that \u201covershoots\u201d xmax.\nimsart-generic ver. 2011/11/15 file: arXiv_Lockin.tex date: October 6, 2017\n\u2022 The integration time T affects the variability of the update of x0, with larger integration times leading to a smoother update but slower convergence. \u2022 The learn-rate \u03b3 < 1 determines the step size at each update of x0. This can be interpreted, and tuned, akin learn-rates in, for instance, stochastic gradient descent methods (Poggio et al., 2011)."}, {"heading": "3.2. LiF-II: Continuous updates of x0", "text": "For some applications the batch updates of x0 \u2013 as implied by the continuous time analysis and defined in Algorithm 1 \u2013 might not be feasible. Algorithm 2 presents a modified version of LiF (denoted LiF-II) in which x0 is updated every observation. LiF-II starts by filling up a buffer of length T which we denote by the vector ~y\u03c9 = {NA1, . . . , NAT }, after which each observation leads to an update of x0. In the algorithm description the values yt\u2212T , . . . , yt are stored in the vector ~y\u03c9. By defining the learn rate as \u03b3 T the tuning parameters in LiF-II are the same as those discussed for LiF-I.\nAlgorithm 2 Implementation of LiF-II for single variable maximization in data stream using a batch. Require: x0, A, T , \u03b3, ~y\u03c9 = {NA1, . . . , NAT } \u03c9 = 2\u03c0\nT for t = 1, . . . , T do xt = x0 +A cos\u03c9t yt = f(x0 +A cos\u03c9t) + t ~y\u03c9 = push(~y\u03c9 , yt cos\u03c9t) if (t > T ) then y\u2217\u03c9 = ( \u2211 ~y\u03c9)/T\nx0 = x0 + \u03b3 T y\u2217\u03c9\nend if end for"}, {"heading": "4. Simulation study 1: Comparison of Batched and streaming LiF and examination of tuning parameters", "text": "In this section we study, by simulation, the differences between LiF-I and LiF-II, and the effects of the tuning parameters A, T , and \u03b3 in a situation in which y = f(x) is measured without noise.\nFigure 1 presents the performance of both LiF-I and LiF-II for data generated using\nf(x) = \u22122(x\u2212 5)2 + (13)\nwhere \u223c N (0, 0). The figure displays the performance of LiF for T = 10000 using the following tuning parameter settings\n\u2022 x0 = \u22125.\nimsart-generic ver. 2011/11/15 file: arXiv_Lockin.tex date: October 6, 2017\n\u2022 T \u2208 {10, 100, 100} \u2022 A \u2208 {.1, 1, 2, 10} \u2022 \u03b3 = .1\nThe rows of Figure 1 (top to bottom) present decreasing values of \u03b3, while the columns (left to right) present increasing values of T . We fix A = 1. Each panel presents the value of x0 during the data stream as selected using LiF-I (black solid line) and LiF-II (gray dotted line). It is clear that LiF can \u201covershoot\u201d the maximum for values of \u03b3 that are too high (top two rows). This happens for both LiF-I and LiF-II, although LiF-I seems more robust. For small values of \u03b3 the performance of the algorithms is very similar, and increases in the integration window T merely smooth the updating procedure.\nIn Figure 2 the results are plotted for the same setup, but this time we vary A, while \u03b3 = .1. Here it is clear that for large values of A LiF-I has a tendency to become unstable (see top rows), while the streaming LiF-II is much more robust for erroneous selection of A. Very small choices for the amplitude A lead to very slow updates of x0 in both cases. Again, increased in T merely smooth\nimsart-generic ver. 2011/11/15 file: arXiv_Lockin.tex date: October 6, 2017\nthe process. The simulations give an impression of the importance of the tuning parameters x0, A, T , \u03b3 and their relationships. In the remainder of this paper we will focus on the evaluation \u2013 through simulation \u2013 of the performance of LiF-II in cases of noise and concept drift."}, {"heading": "5. Simulation study 2: Effects of noise", "text": "To examine the impact of (measurement) noise on the performance of LiF-II we repeat the simulations as described in Section 4 using the data generating model described by Equation 14 with \u223c N (0, \u03c32) and \u03c32 \u2208 {10, 100, 1000, 10000}. We choose tuning parameters: x0 = \u22125, A = 1, T = 100, \u03b3 = .1. Contrary to the simulations presented in Section 4 we now repeat the procedure m = 100 times: Figure 3 presents the average x0 over the 100 simulation runs as well as the 95% confidence bounds. From Figure 3 it is clear that LiF-II performs very well also in the situation in which the noise levels are high.\nimsart-generic ver. 2011/11/15 file: arXiv_Lockin.tex date: October 6, 2017"}, {"heading": "6. Simulation study 3: Performance of LiF in cases of concept drift", "text": "One of the advantages of Lock in Feedback as opposed to other methods of finding xmax is the fact that LiF can also be used to find a maximum of a function in cases of concept drift (Gaber et al., 2005): even when f(x) changes over time, LiF provides a method to keep the value of the treatment x close to xmax.\nTo illustrate this latter advantage of LiF we setup a simulation using the following data generating model:\nf(x, t) = \u22122((x\u2212 .0025t)\u2212 5)2 + (14)\nwhere the (x \u2212 .0025t) ensures that during the stream running from t = 0 to t = 104 = T the value of xmax moves from 5 to 30. We choose x0 = \u221220 (note the different starting position compared to the previous simulations), A = 1, T = 100, \u03b3 = .1 and \u03c32 = 10. We investigate the performance of LiF-II in this case of concept drift.\nFigure 4 presents in the top panel y = f(x, t) for distinct values of t \u2208 {0, 1000, . . . , 10000} in different shades of grey. The concept drift is illustrated by the different locations of the parabola. Superimposed in blue is the value of x0 as selected by LiF-II. In the bottom panel the value of x0 as a function of the length of the stream is presented. It is clear that LiF-II quickly finds xmax and follows the maximum as it moves during the stream."}, {"heading": "7. Discussion and Future work", "text": "In this paper we presented Lock in Feedback as a method to find arg maxx f(x) through sequential experiments. The method is appealing since it a) does not require the functional form of f(x) to be known to derive its maximum, b) performs well in situations in which measurements are obtained with large noise, and c) allows following the maximum of a function even if that function changes over time. We have presented the basic mathematical arguments\nimsart-generic ver. 2011/11/15 file: arXiv_Lockin.tex date: October 6, 2017\nimsart-generic ver. 2011/11/15 file: arXiv_Lockin.tex date: October 6, 2017\nbehind LiF, demonstrating how known (or imposed) oscillations in x can be used to determine the derivative(s) of f(x) which can subsequently be used to find arg maxx f(x). Next, we detailed two possible implementations of LiF and examined their performance for a variety of tuning parameter settings. We then showed that a streaming version of LiF is robust both to noise as well as concept drift.\nThe current expose of LiF is however rudimentary. Relationships and comparisons to existing methods of optimization in sequential experiments have not yet been carried out and comprise obvious future work. Furthermore, the ability to use LiF for problems of higher dimension, e.g., where y = f(~x) is a function of multiple variables, has not been explored even though this extension relatively is easily made. In the remained of this discussion section we try to address these concern in more detail and give suggestions for future examinations of LiF."}, {"heading": "7.1. LiF for higher dimensional problems.", "text": "In this paper we have demonstrated the use of LiF only in cases where x is scalar. However, when x is a vector a very similar approach can be used to find the maximum of the function f(~x) in more than one dimension. In the two dimensional case LiF can be extended by oscillating both elements of x at different frequencies:\nx1,t = x1,0 +A1 cos\u03c91t\nx2,t = x2,0 +A2 cos\u03c92t\nAfter oscillating both elements of x we observe yt = f(x1,t, x2,t) and we can obtain information regarding the gradient by separately computing:\ny1,\u03c9 = yt cos\u03c91t\ny2,\u03c9 = yt cos\u03c92t\nThis simple extension allows for the use of LiF in higher dimensions. However, besides the fact that \u03c91 and \u03c92 should not be multiples of each other, the effects of the tuning parameters and the performance of this higher dimensional version of LiF need to be further examined."}, {"heading": "7.2. LiF and optimal design", "text": "Often, the problem of finding arg maxx f(x) is solved by performing an experiment to be able to estimate f(x), after which the solution can be derived analytically. There is a large literature on designing optimal experiment to to estimate the parameters of f(x) when its functional form is known (Antille and Weinberg, 2000; Myung and Pitt, 2009b). Future work should examine the efficiency of LiF compared to methods in which one first carries out an (optimal) experiment to estimate f(x) before deriving arg maxx f(x). Also, the robustness\nimsart-generic ver. 2011/11/15 file: arXiv_Lockin.tex date: October 6, 2017\nto model misspecification should be examined: one advantage of LiF over methods in which f(x) is examined through experimentation is that f(x) need not be known anywhere in the process. The practical benefit of the ability of LiF to uncover xmax without prior knowledge regarding f(x) in specific situations however needs more scrutiny."}, {"heading": "7.3. LiF in continuous bandit problems", "text": "The problem of finding arg maxx f(x) can also be cast as a bandit problem. In such a formalization the selected values of x present the actions chosen by the experimenter after which the rewards y are observed. Here, one is interested in finding a policy \u2013 a method to select values of x given the previous observations \u2013 which maximizes R = \u2211 yt.\n2 In such a setting one would not only be concerned about finding xmax, but one would like to be efficient in the search. Efficiency here can be quantified in terms of regret: the performance of the search procedure can be compared to the R\u2217 observed when xmax would be known.\nLiF might be an efficient method of solving such a (continuous) bandit problem. However, for LiF to be an asymptotically optimal solution to the continuous valued bandit problem, the learning costs, which relate directly to the amplitude of the induced oscillation, should be decreased over time: A\u21d2 0. However, LiF runs the risk of getting stuck in a local maximum thus suffering linear regret. Thus, the tuning parameter A relates directly to the exploration-exploitation behavior of LiF."}, {"heading": "7.4. Conclusion", "text": "In this paper we introduced LiF as a method for finding arg maxx f(x). LiF is appealing since it a) does not require knowledge of f(x), b) performs well in situations with large noise, and c) works in cases of concept drift. We have provided two algorithms to implement LiF in the simple scalar case. However, future work should examine higher dimensional implementations of LiF, and relations to other known approaches to find arg maxx f(x)."}, {"heading": "Appendix A: Algorithm for finding the exact maximum of a", "text": "parabola using the second order approximation.\nLet\u2019s know suppose that the curve y = f(x) is a parabola:\ny = \u2212\u03b1(x\u2212 x0)2 + \u03b3\nClearly, f(x) has a maximum for x = x0. Furthermore, the second derivative is always equal to \u22122\u03b1, regardless the value of x. Interestingly, the value of \u03b1 can be easily extracted from the data accumulated during the lock-in procedure. For this purpose, y(t) has to be multiplied by cos (2\u03c9t). Following the steps illustrated in eq. 5, eq. 6, and eq. 10, one obtains:\ny2\u03c9 = TA2\n8\n( \u22022f\n\u2202x2 \u2223\u2223\u2223\u2223 x=x0 )\n+ \u222b T 0 cos (2\u03c9t)\nimsart-generic ver. 2011/11/15 file: arXiv_Lockin.tex date: October 6, 2017\nwhich allows us to calculate \u03b1 as:\n\u03b1 = 4y2\u03c9 TA2\nimsart-generic ver. 2011/11/15 file: arXiv_Lockin.tex date: October 6, 2017"}], "references": [{"title": "A Study of D-optimal Designs Efficiency for Polynomial Regression", "author": ["G. Antille", "A. Weinberg"], "venue": "Universit\u00e9 de Gen\u00e8ve, Facult\u00e9 des sciences \u00e9conomiques et sociales, D\u00e9partement d\u2019\u00e9conom\u00e9trie.", "citeRegEx": "Antille and Weinberg,? 2000", "shortCiteRegEx": "Antille and Weinberg", "year": 2000}, {"title": "Bandit Problems: Sequential Allocation of Experiments", "author": ["D.A. Berry", "B. Fristedt"], "venue": "Springer. 2For simplicity we are not discussing discounting or rewards that are a function of the", "citeRegEx": "Berry and Fristedt,? 1985", "shortCiteRegEx": "Berry and Fristedt", "year": 1985}, {"title": "imsart-generic ver. 2011/11/15", "author": ["observable y"], "venue": "file: arXiv_Lockin.tex date: October", "citeRegEx": "y.,? \\Q2017\\E", "shortCiteRegEx": "y.", "year": 2017}, {"title": "Pure exploration in finitely-armed and continuous-armed bandits", "author": ["S. Bubeck", "R. Munos", "G. Stoltz"], "venue": "Theoretical Computer Science, 412(19):1832\u2013 1852.", "citeRegEx": "Bubeck et al\\.,? 2011", "shortCiteRegEx": "Bubeck et al\\.", "year": 2011}, {"title": "Mining data streams", "author": ["M.M. Gaber", "A. Zaslavsky", "S. Krishnaswamy"], "venue": "ACM SIGMOD Record, 34(2):18.", "citeRegEx": "Gaber et al\\.,? 2005", "shortCiteRegEx": "Gaber et al\\.", "year": 2005}, {"title": "Optimizing E-tailer Profits and Customer Savings: Pricing Multistage Customized Online Bundles", "author": ["Y. Jiang", "J. Shang", "C.F. Kemerer", "Y. Liu"], "venue": "Marketing Science, 30(4):737\u2013752.", "citeRegEx": "Jiang et al\\.,? 2011", "shortCiteRegEx": "Jiang et al\\.", "year": 2011}, {"title": "Pricing on the Internet", "author": ["M. Kung", "K.B. Monroe", "J.L. Cox"], "venue": "Journal of Product & Brand Management, 11(2):274\u2013288.", "citeRegEx": "Kung et al\\.,? 2002", "shortCiteRegEx": "Kung et al\\.", "year": 2002}, {"title": "Optimal design of clinical trials comparing several treatments with a control", "author": ["I.C. Marschner"], "venue": "Pharmaceutical statistics, 6(1):23\u201333.", "citeRegEx": "Marschner,? 2007", "shortCiteRegEx": "Marschner", "year": 2007}, {"title": "Lock-in amplifiers: principles and applications, volume 1", "author": ["M.L. Meade"], "venue": "Mike Meade.", "citeRegEx": "Meade,? 1983", "shortCiteRegEx": "Meade", "year": 1983}, {"title": "Bayesian adaptive optimal design of psychology experiments", "author": ["J. Myung", "M. Pitt"], "venue": "Proceedings of the 2nd International Workshop in Sequential Methodologies (IWSM2009), pages 1\u20136.", "citeRegEx": "Myung and Pitt,? 2009a", "shortCiteRegEx": "Myung and Pitt", "year": 2009}, {"title": "Optimal experimental design for model discrimination", "author": ["J.I. Myung", "M.A. Pitt"], "venue": "Psychological review, 116(3):499.", "citeRegEx": "Myung and Pitt,? 2009b", "shortCiteRegEx": "Myung and Pitt", "year": 2009}, {"title": "A gentle introduction to optimal design for regression models", "author": ["T.E. O\u2019Brien", "G.M. Funk"], "venue": null, "citeRegEx": "O.Brien and Funk,? \\Q2003\\E", "shortCiteRegEx": "O.Brien and Funk", "year": 2003}, {"title": "Online Learning, Stability, and Stochastic Gradient Descent", "author": ["T. Poggio", "S. Voinea", "L. Rosasco"], "venue": "Artificial Intelligence, 8(11):11.", "citeRegEx": "Poggio et al\\.,? 2011", "shortCiteRegEx": "Poggio et al\\.", "year": 2011}, {"title": "Thermal dose determination in cancer therapy", "author": ["S.A. Sapareto", "W.C. Dewey"], "venue": "International Journal of Radiation Oncology*Biology*Physics, 10(6):787\u2013800.", "citeRegEx": "Sapareto and Dewey,? 1984", "shortCiteRegEx": "Sapareto and Dewey", "year": 1984}, {"title": "Frequency-domain description of a lock-in amplifier", "author": ["J.H. Scofield"], "venue": "American Journal of Physics, 62(2):129.", "citeRegEx": "Scofield,? 1994", "shortCiteRegEx": "Scofield", "year": 1994}], "referenceMentions": [{"referenceID": 5, "context": "The exact functional relationship between product features and revenue might not be known but can sequentially be sampled (for examples see Kung et al., 2002; Jiang et al., 2011) (especially using modern interactive communication technologies, such as, for instance, e-commerce).", "startOffset": 122, "endOffset": 178}, {"referenceID": 7, "context": "The problem also presents itself in the medical sciences when considering the dose of medication or composition of nutrition: often researchers seek for an optimal dosage according to some observable criterion, but the functional relationship between the dosage and the outcome measure is unknown (see, e.g., Sapareto and Dewey, 1984; Marschner, 2007).", "startOffset": 297, "endOffset": 351}, {"referenceID": 9, "context": "The problem can be approached as an optimal design problem, in which the main aim is to design an experiment that efficiently provides us with information regarding f(~x) (see, e.g., O\u2019Brien and Funk, 2003; Myung and Pitt, 2009a).", "startOffset": 171, "endOffset": 229}, {"referenceID": 1, "context": "However, one could also frame the problem as a bandit problem (Berry and Fristedt, 1985), where the actions a \u2208 A are the choice for the (continuous) value of x, and the rewards at each interaction rt are (some function of) y (Bubeck et al.", "startOffset": 62, "endOffset": 88}, {"referenceID": 3, "context": "However, one could also frame the problem as a bandit problem (Berry and Fristedt, 1985), where the actions a \u2208 A are the choice for the (continuous) value of x, and the rewards at each interaction rt are (some function of) y (Bubeck et al., 2011).", "startOffset": 226, "endOffset": 247}, {"referenceID": 8, "context": "This approach relies on the possibility of making the variable x oscillate at a fixed frequency and to look at the response of the dependent variable y at the very same frequency by means of a lock-in amplifier (Meade, 1983).", "startOffset": 211, "endOffset": 224}, {"referenceID": 8, "context": "This approach is widely used in a very large number of applications, both in industry and research (Meade, 1983), and is the basis for the Lock-in Feedback (LiF) method we introduce in this paper.", "startOffset": 99, "endOffset": 112}, {"referenceID": 12, "context": "This can be interpreted, and tuned, akin learn-rates in, for instance, stochastic gradient descent methods (Poggio et al., 2011).", "startOffset": 107, "endOffset": 128}, {"referenceID": 4, "context": "One of the advantages of Lock in Feedback as opposed to other methods of finding xmax is the fact that LiF can also be used to find a maximum of a function in cases of concept drift (Gaber et al., 2005): even when f(x) changes over time, LiF provides a method to keep the value of the treatment x close to xmax.", "startOffset": 182, "endOffset": 202}, {"referenceID": 0, "context": "There is a large literature on designing optimal experiment to to estimate the parameters of f(x) when its functional form is known (Antille and Weinberg, 2000; Myung and Pitt, 2009b).", "startOffset": 132, "endOffset": 183}, {"referenceID": 10, "context": "There is a large literature on designing optimal experiment to to estimate the parameters of f(x) when its functional form is known (Antille and Weinberg, 2000; Myung and Pitt, 2009b).", "startOffset": 132, "endOffset": 183}], "year": 2017, "abstractText": "Abstract: We often encounter situations in which an experimenter wants to find, by sequential experimentation, xmax = arg maxx f(x), where f(x) is a (possibly unknown) function of a well controllable variable x. Taking inspiration from physics and engineering, we have designed a new method to address this problem. In this paper, we first introduce the method in continuous time, and then present two algorithms for use in sequential experiments. Through a series of simulation studies, we show that the method is effective for finding maxima of unknown functions by experimentation, even when the maximum of the functions drifts or when the signal to noise ratio is low.", "creator": "LaTeX with hyperref package"}}}