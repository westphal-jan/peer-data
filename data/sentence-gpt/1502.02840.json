{"id": "1502.02840", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "10-Feb-2015", "title": "An Integrated Semantic Web Service Discovery and Composition Framework", "abstract": "In this paper we present a theoretical analysis of graph-based service composition in terms of its dependency with service discovery. Driven by this analysis we define a composition framework by means of integration with fine-grained I/O service discovery that enables the generation of a graph-based composition which contains the set of services that are semantically relevant for an input-output request. The proposed framework also includes an optimal composition search algorithm to extract the best composition from the graph minimising the length and the number of services, and different graph optimisations to improve the scalability of the system.\n\n\n\n\nThis paper outlines some of the properties of the graph-based service discovery.\nThe principles outlined in the paper\nAs mentioned earlier, the design of graph-based service discovery is based on the use of two approaches:\nA classical solution which can be implemented in combination with an asynchronous approach.\nA synchronised solution which can be implemented in combination with an asynchronous approach. A asynchronous approach which can be implemented in combination with an asynchronous approach. A new approach which can be implemented in combination with an asynchronous approach. A new approach which can be implemented in combination with an asynchronous approach. A new approach which can be implemented in combination with an asynchronous approach. A new approach which can be implemented in combination with an asynchronous approach. A new approach which can be implemented in combination with an asynchronous approach. A new approach which can be implemented in combination with an asynchronous approach. A new approach which can be implemented in combination with an asynchronous approach.\nThis approach enables for the generation of a graph-based composition that uses a composable interface (such as an I/O interface) which enables the generation of a graph-based composition.\nThe most commonly used method is the simple graph-based service discovery. This way enables for the generation of a graph-based composition. This way enables for the generation of a graph-based composition. This way enables for the generation of a graph-based composition.\nThis implementation allows for the generation of a graph-based composition. This way enables for the generation of a graph-based composition. This method enables for the generation of a graph-based composition. This method enables for the generation of a graph-based composition. This method enables for the generation of a graph-based composition. This method enables for the generation of a graph-based composition. This method enables for the generation of a graph-based composition. This method enables for the generation of a graph-based composition.\nThis approach enables for", "histories": [["v1", "Tue, 10 Feb 2015 10:25:33 GMT  (411kb,D)", "http://arxiv.org/abs/1502.02840v1", "Accepted to appear in IEEE Transactions on Services Computing 2015"]], "COMMENTS": "Accepted to appear in IEEE Transactions on Services Computing 2015", "reviews": [], "SUBJECTS": "cs.AI cs.SE", "authors": ["pablo rodriguez-mier", "carlos pedrinaci", "manuel lama", "manuel mucientes"], "accepted": false, "id": "1502.02840"}, "pdf": {"name": "1502.02840.pdf", "metadata": {"source": "CRF", "title": "An Integrated Semantic Web Service Discovery and Composition Framework", "authors": ["Pablo Rodriguez-Mier", "Carlos Pedrinaci", "Manuel Lama", "Manuel Mucientes"], "emails": ["pablo.rodriguez.mier@usc.es", "manuel.lama@usc.es", "manuel.mucientes@usc.es", "carlos.pedrinaci@open.ac.uk"], "sections": [{"heading": null, "text": "Index Terms\u2014Semantic Web Services; Service Discovery; Service Composition Framework; Service Composition Performance.\nF"}, {"heading": "1 INTRODUCTION", "text": "S ERVICE discovery and composition are in generalcomplex tasks that require considerable effort, especially when vast amounts of services are available. Service discovery solutions range from the initial UDDI proposal that relied on the syntactic description of services and a prefixed categorisation [1], to more advanced generic solutions able to discover Web APIs and Web services across domains exploiting rich user-provided semantic service descriptions [2]. Similarly, a plethora of service composition solutions have been produced spanning from mere graphical support to completely automated solutions [3]\u2013[5]. Both discovery and composition engines essentially rely on the processing of service descriptions, which increasingly go beyond syntactic representations to include the semantics of the service(s) to enable more advanced computations [6], [7].\nAn analysis of the service composition literature highlights that, regardless of the approach, a central task that needs to be frequently performed throughout the composition activity, is the discovery of suitable services to use. Whether one looks at fully automated composition engines based on Artificial Intelligence (AI) planning techniques [8]\u2013[10], or at more constrained solutions that rely on pre-defined skeletal plans [11], [12], or at graph based approaches focused on semantic inputoutput parameter matching [13]\u2013[20], service discovery\n\u2022 P. Rodriguez-Mier, M. Lama and M. Mucientes work at the Centro de Investigacio\u0301n en Tecnolox\u0131\u0301as da Informacio\u0301n (CiTIUS), Universidade de Santiago de Compostela, Spain. E-mail: {pablo.rodriguez.mier,manuel.lama,manuel.mucientes}@usc.es \u2022 Carlos Pedrinaci is with The Open University, Milton Keynes, UK. E-mail: carlos.pedrinaci@open.ac.uk\nc\u00a9 2015 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works.\nis a central activity that needs to be carried out at every main step during the generation of the composition. Yet, despite the strong dependency between both activities, research and development in both areas has evolved for the most part independently.\nOn the one hand, service discovery has traditionally been approached as a one-of activity to be sporadically carried out by humans when looking for services. As a consequence the interface exposed by discovery engines assumes that requests are fully specified in terms of a well-defined interface and categorisation. Moreover, response times of discovery engines are orders of magnitude above what would be acceptable for a composition engine that should it delegate the thousands discovery requests it needs to issue at composition time [21]. These limitations hamper the development of fast composition systems where discovery and composition are two fundamental, interrelated activities.\nOn the other hand, partly due to the particularly demanding computational needs of composition algorithms, most composition engines reimplement locally their own discovery methods instead of integrating existing components providing state of the art discovery algorithms. Additionally, this approach relies on the unnecessary and often unrealistic assumption that the entire set of services should be locally available to the composition engine. This assumption requires preimporting all services locally which is only viable for those registries providing entire public dumps of the service descriptions they hold. Furthermore, most composition engines do not introduce optimisation techniques to improve the scalability by identifying equivalent or dominant functionality that could appear when many differents service registries are involved in the composition. This prevents the use of optimal search strategies since the complexity usually grows exponentially with the number of services. ar X\niv :1\n50 2.\n02 84\n0v 1\n[ cs\n.A I]\n1 0\nFe b\n20 15\nIn order to tackle the previous problems, a composition framework should consider the following characteristics: 1) provide convenient fine-grained discovery mechanisms that could help to discover services able to consume or produce (a subset of) certain types of data as usually required during composition; 2) improve the response time of service discovery to process requests very fast; 3) support the integration of third party service registries as a key activity in the composition phase; 4) incorporate optimizations to improve the scalability of the overall composition process; and 5) find optimal service compositions by minimizing different criteria such as the number of services or the length of the composition to avoid complex, unmanageable solutions.\nIn this paper we present a graph-based framework focused on the semantic input-output parameter matching of services\u2019 interfaces that efficiently integrates the automatic service composition and semantic service discovery. The provided framework takes into account all the characteristics indicated in the above paragraph. Notably, the main contributions are:\n1) A formal framework that presents a theoretical analysis of graph-based service composition in terms of its dependency with a service discovery and we provide a fine-grained I/O discovery interface which reduces the performance overhead without having to assume the local availability and in-memory preloading of service registries. The framework also includes an optimal composition search algorithm to extract the best composition from the graph minimising the length and the number of services, and different graph optimisations to improve the scalability of the system, which as far as we now are not included in other frameworks. 2) A reference implementation of this formal framework based on the adaptation of two independently developed components, namely ComposIT [22] and iServe [2], respectively in charge of service composition and discovery. 3) A detailed performance analysis of the integrated system, highlighting both the unacceptable performance achieved when using the typical out of the box discovery implementations, as well as the fact that top performance is achievable with the adequate discovery granularity and corresponding indexing optimisations.\nThe proposed framework is data-flow centric, focused on the semantic I/O parameter matching of services\u2019 interfaces and leaving aside preconditions and effects. This is essentially a pragmatic decision inline with the current tendency towards lightweight data-driven approaches. In fact, on the Web less than 5% of the semantic Web services include preconditions and effects [23].\nThe rest of the paper is organized as follows. Sec. 2 discusses the state-of-the-art. Sec. 3 formalizes the web service composition problem and Sec. 4 framework that defines the composition in terms of service discovery\ntasks. Sec. 5 describes our reference implementation. Sec. 6 explores the performance of the system for different scenarios and finally Sec. 7 gives some final remarks."}, {"heading": "2 RELATED WORK", "text": "Automatic composition of Web services is still an open problem that involves multiple research areas [5]. Concretely, lots of efforts have been devoted to automate the discovery and composition using different approaches and techniques [24]. However, most of the research in both areas has been evolved independently of each other, despite the significant overlap between these interrelated tasks. This has lead to a lack of integrated approaches in the field that consider the performance and the scalability of the overall integrated system as well as the impact of the discovery in terms of response time during the automatic composition task.\nFrom the discovery side, most of the work has been focused on improving the retrieval performance (i.e., precision-recall curve) without much concern about the response time requirements and/or the interface requirements to provide an efficient fine-grained discovery granularity for automatic composition. However, the response time of the discovery systems is recently gaining significant interest. A recent service discovery competition [21] shows some of the newest advances in the automatic discovery field. Most relevant examples are OWLS-MX3 [25], iSem 1.1 [26] and XSSD [27]. The main conclusions that can be drawn from this contest, from the perspective of service composition, are twofold: 1) research efforts are focused on response time improvement via caching and indexing, yet still not sufficient for fast, automatic composition of services and 2) the interface exposed by discovery engines assumes that requests are fully specified in terms of a well-defined interface and categorisation, i.e., discovery systems expect a precise description of the service in terms of inputs and outputs, and/or other characteristics such as preconditions and effects. However, these interfaces are not adequate for service composition, since one of the assumptions is that there is usually no single service that fully matches a request and therefore several services need to be combined instead. Indeed, during automatic composition, an exploratory search is usually required to guess which relevant services can be selected at each step. This requires to launch many partial requests (finegrained queries), rather than fully specified requests, in order to locate relevant services that match some partial information available to the algorithm (e.g., services that consume some inputs and/or produce some outputs). Fine-grained requests are simpler and can be solved faster than complex, fully specified requests. Thus they are more suitable for automatic composition systems.\nFrom the composition side, most approaches can be categorized into: 1) classical AI planning approaches [28], where the composition problem is translated into the planning domain and solved using general planners,\nand 2) graph-based I/O driven approaches that build a graph with the services and their input/output semantic relations (generally ommiting the preconditions and effects), and apply graph search techniques to extract (usually optimal) service compositions from the graph.\nRelevant approaches of the first group are [9], [10], [29]. These approaches differ from our work in the sense that they handle very expressive preconditions and effects to generate composition plans but: 1) the concept of external service registries is missing, services are assumed to be locally available; 2) average response time of these systems is usually high; and 3) optimizations to reduce the number of services by identifying redundant functionality are not considered.\nOn the other hand, graph-based I/O approaches are gaining much attention since the Web Service Challenge [30]. Some notable works in this field are [14]\u2013 [20]. Concretely, [14], [15], [20] are the top-3 algorithms of the WSC\u201908. Although these approaches show generally good performance and low response times, [14] and [15] do not find optimal solutions and [20] fails to find solutions in large data sets. Additionally, none of these systems consider neither the integration with service registries nor the use of service optimizations to deal with potential scalability problems.\nFrom the point of view of the integrated frameworks, a very interesting approach was proposed by Kona et al. in [13]. In this paper, the authors present an efficient framework for Web service composition that supports semantic Web service discovery. The composition is generated by performing a forward chaining of operators to find a feasible composition. The authors also evaluated the system with the datasets of the Web Service Challenge 2006 and presented a detailed experimentation. Their results demonstrate the capabilities and the good performance of this system which, however, exhibits some limtations: 1) the notion of an external service registry is missing, all the information required is preprocessed and loaded in the main memory, which is one of the main issues we set out to tackle with this work since it is otherwise not possible to deal with large and/or distributed datasets; 2) the framework does not contemplate service optimisations to remove redundant information and 3) the work does not perform an optimal search to minimise the cost or the number of services of the composition as all possible compositions with the shortest length are captured in the composition graph which should be further processed to extract the optimal composition. Similarly, in [31], Le\u0301cue\u0301 et al. develop an integrated framework for dynamic Web service composition. The framework exploits the semantic input-output matchmaking to discover relevant services and performs automatic composition using a graph-based approach, taking into account functional and non-functional properties. However, graph optimisations are not considered and the composition search is non-optimal, since the selection of the services is merely greedy-based.\nIn [32], Da Silva et al. present a framework that\neffectively supports both automatic semantic discovery and composition, among other relevant phases of the composition life-cycle, such as service publication and service selection, taking into account non-functional properties. One of the limitations of the discovery phase is that it does not support fine-grained requests. On the other hand, the framework does not include neither optimisations to reduce graph size nor an optimal search to extract the best composition from the graph.\nIn light of the above analysis, we propose a graphbased I/O framework that overcomes all of the analyzed limitations. In this framework the discovery is defined in terms of a fine-grained I/O interface which minimises the performance overhead between both composition and discovery without having to assume the local availability and in-memory preloading of service registries. The proposed framework also includes an optimal composition search algorithm to extract the best composition from the graph minimising the length and the number of services, and different graph optimisations to improve the scalability of the system."}, {"heading": "3 WEB SERVICE COMPOSITION PROBLEM", "text": "Service composition aims to help construct composite services that could fulfil a user request, e.g., booking an entire holiday, when no known service can achieve such a request on its own. A core activity for creating service compositions is, indeed, the discovery of relevant services. In this context, relevant services are those that could be invoked and contribute to obtaining an executable composition that would fulfil the needs set out by the client. We herein formalise the composition problem in close relationship with discovery as a means to better study and approach the integration of discovery and composition engines. The formalisation of the problem is data-flow centric, focussed on the semantic input-output parameter matching of services\u2019 interfaces."}, {"heading": "3.1 Semantic Web Service Discovery", "text": "The semantic Web service discovery problem consists of locating appropriate services from one or more service registries that are relevant to an input-output request.\nDefinition 1: A Semantic Web Service (SWS, hereafter \u201cservice\u201d) can be defined as a tuple w = {Inw, Outw} \u2208 W where Inw is a set of inputs required to invoke w, Outw is the set of outputs returned by w after its execution, and W is the set of all services available in the service registry. Each input and output is related to a semantic concept from an ontology O (Inw, Outw \u2286 O).\nSemantic inputs and outputs can be used to discover relevant services as well as to compose the functionality of multiple services by matching their inputs and outputs together. In order to measure the quality of the match, we need a matchmaking mechanism that exploits the semantic I/O information of the services. The different matchmaking degrees that are typically contemplated in the literature are [33]:\n\u2022 Exact (\u2261): An output ow1 \u2208 Outw1 of a service w1 matches an input iw2 \u2208 Inw2 of a service w2 with a degree of exact match if both concepts are equivalent. \u2022 Plugin (v): An output ow1 \u2208 Outw1 of a service w1 matches an input iw2 \u2208 Inw2 of a service w2 with a degree of plugin if ow1 is a sub-concept of iw2 (ow1 v iw2). \u2022 Subsume (w): An output ow1 \u2208 Outw1 of a service w1 matches an input iw2 \u2208 Inw2 of a service w2 with a degree of subsume if ow1 is a super-concept of iw2 (ow1 w iw2). \u2022 Fail (\u22a5): When none of the previous matches are found, then both concepts are incompatible and the match has a degree of fail (ow1 \u22a5 iw2).\nNote that, in order to discover relevant services to generate data-flow compatible service compositions, the only two valid degrees of match are exact and plugin. On this basis, we define the cmatch (compatible match) function that will be used to discover candidate services during the composition phase:\nDefinition 2: Given a, b \u2208 O, a compatible match cmatch(a,b) holds if and only if a \u2261 b (exact match) or a v b (plug-in match).\nUsing the previous compatible match function between concepts, we can define the matchmaking operator \u201c\u2297\u201d that given two sets of concepts C1, C2 \u2286 O, it returns the concepts from C2 matched by C1.\nDefinition 3: Given C1, C2 \u2286 O, we define \u201c\u2297 : O \u00d7 O \u2192 O\u201d such that C1\u2297C2 = {c2 \u2208 C2|cmatch(c1, c2), c1 \u2208 C1}. Note that this operator is not commutative.\nWe can use the previous operator to define the concepts of full and partial matching between concepts.\nDefinition 4: Given C1, C2 \u2286 O, a full matching between C1 and C2 exists if C1\u2297C2 = C2, whereas a partial matching exists if C1 \u2297 C2 \u2282 C2.\nTypically, a service w = {Inw, Outw} is relevant to a request r = {Inr, Outr}, where Inr \u2286 O are the provided inputs and Outr \u2286 O the expected outputs, if Inr \u2297 Inw = Inw and Outw \u2297 Outr = Outr, that is, there is a full match between the provided inputs and the service inputs and a full match between the service outputs and the expected outputs.\nWhile this approach is reasonable for discovering the services that best match an entire request (full match), for composition one needs to locate services that are relevant, that is, that match some inputs / outputs (partial match). Thus, rather than approaching the discovery problem based on a full input/output description, we split this problem into two finer-grained discovery problems that are more relevant for service composition: input discovery and output discovery.\nDefinition 5: Given a set of concepts C \u2286 O, the input discovery problem can be defined as finding a set of relevant services W = {w1, ..., wn} where wi = {Inwi , Outwi} such that \u2200wi \u2208W , C \u2297 Inwi \u2286 Inwi , that is, services that can consume some (partial match) of the inputs or are directly invokable (full match) with C.\nDefinition 6: Given a set of concepts C \u2286 O, the output discovery problem can be defined as finding a set of relevant services W = {w1, ..., wn} where wi = {Inwi , Outwi} such that \u2200wi \u2208 W , Outwi \u2297 C \u2286 C, that is, services that produce some or all outputs.\nBased on these definitions, we introduce the notion of input and output relevance:\nDefinition 7: A service w = {Inw, Outw}, where Inw, Outw \u2286 O, is input-relevant for a set of concepts C \u2286 O if C \u2297 Inw 6= \u2205, whereas the service w, is outputrelevant for a set of concepts C \u2286 O if Outw \u2297 C 6= \u2205."}, {"heading": "3.2 Semantic Web Service Composition", "text": "The semantic composition problem considered in this work is as follows: Given a request r = {Inr, Outr}, where Inr is a set of available semantic input concepts and Outr a set of requested semantic output concepts, we can define the problem of the automatic construction of a SWS composition as that of finding a composite Web service wc = {Inwc , Outwc , P = {S,\u2264}} such that Inr \u2297 Inwc = Inwc (the composite service is invokable with the available inputs) and Outwc\u2297Outr = Outr (the composite service retrieves all the requested outputs). This service consists of a partially ordered set P (a binary relation \u201c\u2264\u201d over a set of services S \u2286 W ). This partial ordered set of services is esentially a Directed Acyclic Graph (DAG) which models the implicit execution order of the services driven by the input/output matches, where nodes of the DAG are services and the arcs are valid semantic matches. This type of composition has many advantages: On one hand, mapping inputs and outputs to semantic concepts does allow to reason about data types to improve the matchmaking between service parameters, which leads to more possible semantically valid compositions. On the other hand, DAG representation formally captures the nature of a composition where services may be executed in different orders, i.e., there are many different total (sequential) orderings of a composition that lead to the same result. Moreover, since our approach is data-flow centric, a DAG representation is simpler than a general (possible cyclic) graph as cycles do not produce new data types in the composition.\nHowever there are also some drawbacks. First, a DAG representation could impose some restrictions in the compositions that can be generated, i.e, due the absence of cycles, a service could not explicitly be invoked twice. Second, compositions at different semantic levels rather than just concept matchmaking would deffinitely improve the quality of the compositions by capturing more possible cases. Furthermore, using input concepts and output concepts to define a composition request is not user friendly. A better way to specify a request would be to define it with keywords. This, nonetheless, could be achieved with a pre-processing step using automatic semantic annotation tools to translate the request from keywords to semantic concepts. Formally, we define a valid composition as follows:\nDefinition 8: Let r = {Inr, Outr} and let wc = {Inwc , Outwc , P = {S,\u2264}} be a composite service for the request r, where P is a partial order over the set of services S \u2286 W of the composite service wc. We say wc is a valid composition for request r if and only if, for any topological sort T = {w1, w2, ..., wN} of P , where wj = {Inwj , Outwj} \u2200j \u2208 [1, N ], the following expression is satisfied:\n(Inr \u2297 Inw1 = Inw1) \u2227 ((Inr \u222aOutw1)\u2297 Inw2 = Inw2) \u2227 . . . \u2227 ((Inr \u222aOutw1 \u222a ... \u222aOutwN )\u2297Outr = Outr).\nThis definition implies that every service of the composition must be invokable to obtain an invokable service composition. We say that a service w = {Inw, Outw} is invokable with a set of concepts C \u2286 O if each required input iw \u2208 Inw is semantically matched by a set of concepts C.\nDefinition 9: If C \u2286 O is the set of available input concepts, then a service w = {Inw, Outw} is invokable with C if C\u2297Inw = Inw, i.e., there exists a full matching between the available inputs and the service inputs.\nNote that if a service w is invokable with a set of concepts C, then it is also input-relevant for the same set of concepts since invokable implies input-relevant, but the inverse does not hold (see Def. 7). That is, the set of invokable services is included in the set of the relevant services.\nThe reader should note that we restrict the definition of a compatible match to exact and plugin in order to generate semantically complete compositions. However, the framework also supports the use of other match degrees (e.g., subsume) by relaxing the \u201ccmatch\u201d operator, which in practice means obtaining potentially more matched (but semantically weaker) concepts and thus bigger composition graphs with more services and match relations that could be semantically incomplete. This is supported not only in theory, but also by the reference implementation presented in Sec. 5."}, {"heading": "4 COMPOSITION FRAMEWORK", "text": "On the basis of the formal definition of the problem, in this section we present a graph-based framework for automatic semantic Web service composition. Fig. 1\nshows the overview of our approach with the different steps involved. The process is triggered by a composition request that specifies the user requirements in terms of inputs and the expected outputs. This information is used in the composition graph generation phase to build a graph with all the relevant services and the semantic relations between their inputs and outputs. In order to find the relevant services, the composition graph phase is interleaved with the discovery phase. The discovery phase is responsible for retrieving the relevant services given the data available at different stages during the composition graph generation phase. The relationships between the inputs and outputs of services are computed in the matchmaking phase, where the semantic matching degree between inputs and outputs is computed using a semantic reasoner. The service composition graph is eventually generated on the basis of the relevant services and the I/O matching information. This graph contains all possible service compositions that satisfy the composition request, in addition to a few others that, although invokable, do not manage to entirely fulfil the request. The service composition graph is then optimised applying different techniques to group and reduce the number of services and relations. Next, an optimal search is performed over the graph to find the optimal composition. This phase is interleaved with a search optimisation phase that analyses and reduces the search space. Finally, the optimised composition workflow is returned.\nIn this section, we analyse each phase and we provide generic strategies based on the problem description presented in the previous section."}, {"heading": "4.1 Semantic Matchmaking", "text": "A fundamental functionality that needs to be available for generating compositions and even for discovering services, is the ability to analyse the compatibility between different semantic types. This functionality, which we refer to as semantic matchmaking, is in charge of assessing the level of semantic compatibility between concepts, given an ontology (or set of ontologies). To do so, semantic matchmaking relies on semantic reasoning (notably subsumption reasoning) in order to be able to determine the relationships between the concepts (e.g., Plugin match). This mechanism can be used for example,\nto discover services that can consume or produce a concrete input/output by finding semantically compatible types. Such a mechanism is also particularly relevant for generating the service composition graph with all the matches between services inputs and outputs.\nThe matchmaking system provides a match(C1, C2) function which represents the concrete implementation function of the \u2297 operator defined in Def. 3. The match function tries to find a valid match between the source concepts of C1 and the target concepts of C2 calling the cmatch(ci, cj) function (Def. 2) for each pair (ci, cj) of concepts where ci \u2208 C1 and cj \u2208 C2. The compatible match function is calculated using a semantic reasoner that returns the semantic relation between two concepts. Then, it checks if the relation is considered a compatible match (i.e., exact or plugin). Each time a compatible match is found between ci and cj , cj is added to a set of matched concepts and removed from C2. The reader should note that the goal here is not to find the best match for each element but rather to get all compatible matches for each target element.\nThe best-case complexity (all C2 concepts matched by the first element from C1) is O(m), whereas the worstcase complexity (no compatible matches at all) is O(m\u00b7n) where n = |C1|,m = |C2|. This implies that, in the worst case, for two sets of elements, there will be at most m\u00d7n calls to the cmatch function which is ultimately answered by the semantic reasoner."}, {"heading": "4.2 Semantic Service Discovery", "text": "In order to generate service compositions, it is necessary to be able to discover appropriate services based on their interface. The goal of a typical discovery system is to find atomic services that match entirely a description representing the ideal service sought, i.e., all the inputs and outputs are compatible. However, from the viewpoint of generating data-flow compatible compositions, rather than looking for entire matches, we need to find suitable combinations of services that combined would satisfy a request. In this scenario, the ability to find partially matching services very fast is paramount in order to enable exploring efficiently the many possible combinations of services that could lead to a suitable composition. Therefore, in a nutshell, the type of service discovery that is required for supporting service composition is a more relaxed and finer-grain version of that typically provided by discovery engines whereby partial matches can be obtained in a very fast manner. This can be achieved by defining a simple fine-grained interface that supports the discovery of services using only partial information (some/any available inputs, some/any expected outputs). Fig. 2 shows the pseudocode of this simple interface to discover relevant services that can be used as a starting point to obtain semantic input/output relevant services, as defined in Def. 7 in Sec. 3.\nThe discovery algorithm sequentially scans all services and calls the Match function of the Matchmaker to determine if a service is relevant for an input (the service has\nat least one input compatible with the inputs provided) or for an output (the service has at least one output compatible with the outputs provided) depending on the Type selected. Therefore, the complexity of this type of discovery is O(w) where w = |W | is the size of the service repository. This implies at most |W | calls to Match in the worst-case scenario or O(w \u00b7 m \u00b7 n) if we consider the complexity of the Match method assuming every service has at most m outputs and n inputs."}, {"heading": "4.3 Service Composition Graph Generation", "text": "When the system receives a request, the Service Composition Graph Generator computes a graph with all the semantic relations between the relevant services for the request. A request is basically a set of input concepts, which represent the initial set of available inputs, and a set of output concepts, which are the outputs that the composite service should return. The service composition graph is basically a layered Directed Acyclic Graph (DAG), G = (V,E), where: \u2022 V = W \u222aC is the set of vertices of the graph, where W is the set of services and C the set of concepts (inputs and outputs).\n\u2022 E = CW \u222aWC\u222aCC is the set of edges in the graph where:\n\u2013 CW \u2286 {(c, w) | c, w \u2208 V \u2227 c \u2208 C \u2227w \u2208W} is the set of input edges, i.e., edges connecting input concepts to their services. \u2013 WC \u2286 {(w, c) | w, c \u2208 V \u2227 w \u2208 W \u2227 c \u2208 C} is the set of output edges, i.e., edges connecting services with their output concepts. \u2013 CC \u2286 {(c, c\u2032) | c, c\u2032 \u2208 V \u2227c, c\u2032 \u2208 C\u2227cmatch(c, c\u2032)} is the set of edges that represent a semantic match between concepts.\nThis graph contains all the known services that could directly or indirectly be invoked given the provided inputs. The graph is divided into N layers, whereby each layer i has all those services whose inputs are matched by the outputs produced in previous layers and, therefore, are invokable at layer i. The graph is augmented with two layers, namely L0 and LN+1. L0\ncontains the dummy service wO = {OR, \u2205} whereas LN+1 contains the dummy service wI = {\u2205, IR}. The first one is a service that provides as outputs the inputs of the request (IR) and the last one has the goal outputs (OR) as inputs. An example of a graph for IR={BookTitle, BookAuthor, CreditCard, Email, Address} and OR={Price, Payment, BookingCode} is shown in Fig. 3.\nThe first step of the composition graph construction is the calculation of the relevant services. These services can be easily calculated forwards, layer by layer, using the discovery mechanism previously presented. Fig. 4 shows an implementation of the forward composition graph generation algorithm for a request R. The algorithm selects all those services from the set of all available services W that are input-relevant for the available concepts (availCon) in each layer using the relevantIO function (L. 8). Then, for each input-relevant service, the algorithm performs a match between the available concepts and the unmatched inputs of each service. All the inputs that are matched are removed from the unmatched set of inputs for the current service. If there are no unmatched inputs, then the service is invokable and thus is eligible for the current layer. For example, the first eligible services for the request shown in Fig. 3 are the services in the layer L1, which correspond with the services whose inputs are fully matched by IR (the set of concepts in L0). The second eligible services are those services (placed in L2) whose inputs are fully matched by the outputs of the previous layers, and so on. Note that instead of performing the invokability check by finding a full match between C and the inputs of each service, we save those inputs of each service that have been matched before, and hence we only perform the match between the new outputs generated in the previous level (availCon) and the remaining unmatched inputs of each service (Uset). Hence, the unmatched inputs Uset of each service decreases monotonically with each level (i.e., the unmatched inputs of each service always decrease when a new match is found, and the effect is propagated at each layer). The complexity analysis for this algorithm (neglecting the optimisation\neffect due to the propagation of the matched inputs for simplification purposes) is O(l \u00b7 w \u00b7m \u00b7 n + l \u00b7 wk \u00b7m \u00b7 n) which can be simplified to O(l \u00b7m \u00b7 n( (k+1)wk ). The first part corresponds with the complexity of the calls to the relevantIO function which is invoked l times (one call per layer), whereas the second part corresponds with the complexity of the for loop to check the invokability of each input-relevant service. We can expect that only a small subset of the repository W is relevant for the availCon generated in the previous layer. Thus, each call to relevantIO function returns a small set of relevant services w/k where k (k 1) is a reduction factor that depends on the number of relevant services for a given set of concepts. This k factor is different for each request and service registry. For example, if we assume k = 100 for a given problem for a service registry of 1,000 services, then it means that each invokation of relevantIO(availCon,W, In) will return only the 1% of the services of the repository (w/k = 10). Consider the following example of a composition over a repository with 1,000 services (w = 1, 000), assuming that there are m = 5 new output concepts generated and n = 5 unmatched concepts at each layer, the composition graph has 10 layers (l = 10) and in each layer the relevantIO function returns on average w/k = 10 services (that is, k = 100). The complexity in this example is 10 \u00b71000 \u00b75 \u00b75 for the first part plus 10 \u00b7 1000100 \u00b7 5 \u00b7 5 for the second part, which is \u2248 2.5 \u00b7 105 calls to the matchmaking system to compute all the required matches at the concept level."}, {"heading": "4.3.1 Index-Based Optimisations", "text": "Although these improvements can save search time, one of the bottlenecks of the graph generation is still the size of the repository w, which is usually some orders of magnitude bigger than the other parameters involved in the complexity. One effective way to reduce\nthe impact of the size of the repository is precalculating and indexing the input-relevant set of services for each concept of the ontology. The indexing of services can be done independently of any composition request as it only depends on the information available, such as the services themselves and the ontologies.\nThe construction of an inverted index function to recover input-relevant services or output-relevant services can be done easily using the relevantIO function. The main idea behind the inverted index is to build a keyvalue hash map where the keys are the concepts of the ontology and the values are those services that are inputrelevant (or output-relevant) for that concept. This map allows to discovery relevant services in constant time during the graph generation.\nWe define a new function relevantIO\u2032 which is the cached-version of the original function. Instead of computing the relevance by using directly the matchmaking system, it first checks if the concept is cached in the inverted index. If the concept is in the index, then it is immediately returned (constant time). If not, the call is delegated to the relevantIO function. Assuming there is enough memory to keep the entire index, the index allows to provide relevant services at O(1) for each concept during the forward graph generation. Thus, we reduce the complexity associated to the parameter w. Concretely, since we can obtain at constant time the input-relevant services for each concept, the complexity of relevantIO(availCon,W, In) now depends only on the number of concepts in availCon (one access to the index per concept). Having m = |availCon| (number of new concepts at each layer) the complexity using indexes is O(l \u00b7m+ l \u00b7 wk \u00b7m \u00b7 n), simplified to O(l \u00b7m(1 + w k \u00b7 n)). The use of indexes to discover relevant services during the forward graph generation has a high impact on the global performance. Using the same example as before, with w = 1000, l = 10, m = 5, n = 5 and k = 100 we have 10 \u00b75(1+ 1000100 \u00b75) = 2.55 \u00b710\n3, 2 orders of magnitude lower than the non-indexed version."}, {"heading": "4.4 Graph-Based Optimisations", "text": "Once the graph is generated, the next step is to apply different optimisations to reduce the graph size in order to improve the optimal composition search performance. This part of the composition is independent of the discovery phase. All the information required to search for the optimal composition is in the graph, namely, the relevant services and the semantic relations between their inputs and outputs, so there is no need to communicate with the discovery/matchmaking systems. We distinguish at least two different techniques [22], [34]: backward pruning and interface dominance."}, {"heading": "4.4.1 Backward pruning", "text": "As explained earlier, the generation of the composition graph with the relevant services is done forwards, layer by layer. During this forward expansion of the graph, we\nare not interested in invoking services that have no explicit effects on the composition, that is, services that are not contributing to the output goals. When the graph is completed and the goal outputs are reached, a backward pruning is performed to remove all non-contributing services. A non-contributing service is essentially a service that is not contained in the transitive closure set of the output-relevant services. A service w\u2032 = {Inw\u2032 , Outw\u2032} is output-relevant for a service w = {Inw, Outw} if Outw\u2032 \u2297 Inw 6= \u2205 (def. 7). Thus, the set of all outputrelevant services for a service w can be defined as:\nX(w) = {w\u2032 \u2208W | Outw\u2032 \u2297 Inw 6= \u2205} (1) Recursively, we can define the set of X2(w) = X(X(w)) as the set of output-relevant services at the distance two. Extending this, the transitive closure of the output-relevant services can be defined as:\nX\u0302(w) = X(w) \u222aX2(w) \u222aX3(w) \u222a \u00b7 \u00b7 \u00b7 (2) Therefore, we can say that all those services of the graph that are not in the transitive closure of the outputrelevant services X\u0302 are not contributing to the composition goals, directly nor indirectly, and can therefore be removed from the graph.\nAn example of this can be seen in Fig. 3. Starting from the last layer, we compute the transitive closure of the service wO, which is a dummy service that represents the goal outputs. The output relevant services for wO at distance one are X(wO) = {w6, w7, w8, w9}, since Outw6\u2297 InwO 6= \u2205 and the same for w7, w8 and w9. We calculate now the output-relevant services at distance two, which is X(X(wO)) = X({w6, w7, w8, w9}). X({w6, w7, w8, w9}) can be simply computed as the union of X(w6)\u222aX(w7)\u222a X(w8)\u222aX(w9) which is {w1, w2, w3}. Repeating this, we finally have X\u0302 = {w6, w7, w8, w9} \u222a {w1, w2, w3} \u222a {wI}, where wI is the dummy service ommited in Fig. 3 that provides the input concepts of the request (concepts in L0). Since w4, w5, w8 /\u2208 X\u0302 , these services (w4=MoviesDB Service, w5=GeoLoc WS, w8=Zip Search) are not contributing to the goals and can be removed from the graph."}, {"heading": "4.4.2 Interface Dominance", "text": "Another strategy to reduce the graph size is to analyse the equivalence and dominance of some services over others in terms of the interface they offer. It is very frequent to find services from different providers that offer similar services with overlapping interfaces. In scenarios like this, it is easy to end up with large composition graphs that make very hard to find optimal compositions in reasonable time. One way to attack this problem is to analyse the interface dominance between services in order to find those that are equivalent or better than others in terms of the interface they provide.\nDefinition 10: Given a concept in a composition graph G (c \u2208 G), we denote \u03a6(c) as a function that returns the set of output-relevant services for concept c:\n\u03a6(c) = {w = {Inw, Outw} \u2208 G | Outw \u2297 {c} = {c}} (3)\nFor instance, \u03a6(Payment) in Fig. 3 is {w8, w9} since Outw8 \u2297 {Payment} = {Payment} and Outw9 \u2297 {Payment} = {Payment}, that is, concept Payment is matched by an output from w8 (PaymentID) and for an output from w9 (PayNum).\nDefinition 11: A service wi = {Inwi , Outwi} \u2208 G is input-equivalent (Inwi \u2261 Inwj ) with respect to a service wj = {Inwj , Outwj} \u2208 G in the composition graph G if:\u22c3\nci\u2208Inwi\n{\u03a6(ci)} = \u22c3\ncj\u2208Inwj\n{\u03a6(cj)} (4)\nThat is, the set of sets defined by the union of \u03a6(c) for each input concept c of each service must be equal. This definition formalises the idea of input equivalence of two services of the composition graph regarding the relation between their inputs and the services that match those inputs. That means that two services wi and wj of the graph are input equivalent if the services that provide the inputs of both services are the same.\nDefinition 12: A service wi = {Inwi , Outwi} \u2208 G is input-dominant (Inwi Inwj ) with respect to a service wj = {Inwj , Outwj} \u2208 G in the composition graph G if:\u22c3\nci\u2208Inwi\n{\u03a6(ci)} \u2282 \u22c3\ncj\u2208Inwj\n{\u03a6(cj)} (5)\nThus, informally, a service is input-dominant if it only needs a subset of the information required by the dominated service to be invoked. For example, in Fig. 3, w7 is input-dominant respect to w6, since {{w1, w2}} \u2282 {{w1, w2}, {wI}, {w3}}.\nDefinition 13: Given a concept in a composition graph G (c \u2208 G), we denote \u03a8(c) as the function that returns a set of input concepts in G that are matched by c, that is, there exists an arc from c to c\u2032 in G.\n\u03a8(c) = {c\u2032 | (c, c\u2032) \u2208 G} (6)\nDefinition 14: A service wi = {Inwi , Outwi} \u2208 G is output-equivalent (Outwi \u2261 Outwj ) respect to a service wj = {Inwj , Outwj} \u2208 G in the composition graph G if:\u22c3\nci\u2208Outwi\n\u03a8(ci) = \u22c3\ncj\u2208Outwj\n\u03a8(cj) (7)\nThat is, two services are output-equivalent if their outputs are matched to the same input concepts in the graph, which means that their outputs can be consumed in the same way by the same services in G.\nDefinition 15: A service wi = {Inwi , Outwi} \u2208 G is output-dominant (Outwi Outwj ) respect to a service wj = {Inwj , Outwj} \u2208 G if:\u22c3\nci\u2208Outwi\n\u03a8(ci) \u2283 \u22c3\ncj\u2208Outwj\n\u03a8(cj) (8)\nTherefore, one service is output-dominant with respect to another service of the graph G if their outputs match the same inputs of the same services in the composition graph but the dominant service also provides additional outputs to the same or different services.\nDefinition 16: a service wi = {Inwi , Outwi} is interfaceequivalent to a service wj = {Inwj , Outwj} (wi \u2261 wj) if Inwi \u2261 Inwj and Outwi \u2261 Outwj , that is, both are inputequivalent and output-equivalent.\nDefinition 17: A service wi interface-dominates a service wj (wi wj) if the first dominates the second in at least one aspect (input-dominant or output-dominant) and is at least equivalent in the other aspect. Formally, wi wj if (Inwi Inwj \u2227 Outwi Outwj ) \u2228 (Inwi \u2261 Inwj \u2227 Outwi Outwj ) \u2228 (Inwi Inwj \u2227Outwi \u2261 Outwj ).\nThis dominance definition can be generalised to include more features, such as preconditions, effects, or non-functional properties like QoS:\nDefinition 18: A service with multiple properties wi = {P 1wi , P 2 wi , . . . , P n wi} where P 1 wi are the inputs, P 2 wi the outputs and the rest of parameters are different properties, dominates another service wj (wi wj) with parameters Pwj = {P 1wj , P 2 wj , . . . , P n wj}, if \u2200 k \u2208 {1, ..., n} P k wi P kwj \u2227 \u2203 k \u2208 {1, ..., n}, P k wi P k wj .\nThe interface dominance optimisation allows to reduce the size of the composition graph by substituting the original services of the graph by abstract interfaces that capture the functionality of the dominant or equivalent services. By minimising the graph size we improve the performance of the search algorithms since they only explore a reduced search space. Once the search is performed and the optimal composition workflow is generated, a post-processing step can be used to replace the abstract service interfaces with specific implementations using the original dominant / equivalent services or by combinations of dominated services that satisfy the same functionality of the dominant service."}, {"heading": "4.5 Optimal Composition Search", "text": "The previous optimisations are intended to reduce the composition graph but keeping the same functionality. The next step is to perform a search over the graph to find the best composition among all the possible compositions that satisfy the input/output request. The search can be designed to optimise different criteria, such as the number of services, the execution path length or QoS properties. Typically, the search over the graph can be done forwards or backwards. In the first case, the composition starts from the inputs of the request (first layer), selecting invokable services until the goal outputs are obtained, whereas the second case starts with the goal outputs (last layer), selecting relevant services for the outputs until a composition that can be invoked with the initial inputs is found.\nFormally, the composition search can be modelled as a state-transition system, where the problem is divided into a set of states and transitions between states [35]. A state transition system is defined as a 3-tuple \u03a3 = (S,A, \u03b3), where: \u2022 S = {s1, s2, . . . } is a finite set of states. \u2022 A = {a1, a2, . . . } is a finite set of actions. \u2022 \u03b3 : S \u00d7A\u2192 S is a state-transition function.\nUsing the concept of the state-transition system, the state space search problem can be defined as P = {\u03a3, s0, G}, where s0 \u2208 S is the initial state and G \u2286 S is a set of goal states.\nThe state-transition system \u03a3 allows the search to navigate through the set of states applying different actions, where each action may be associated to a cost that we want to minimise. The state representation may vary depending on the strategy used. Typically, in the case of the backward search, the state will contain the information of the unsatisfied concepts at each state, starting with the goal outputs. The goal then is to find a succession of actions \u3008a1, a2, . . . , an\u3009 with the minimum cost that leads from the initial state, where unsatisfied concepts = goal outputs, to the goal state, where unsatisfied concepts = \u2205, that is, there are no unsatisfied concepts and the composition is invokable. The available transitions between states are given by the applicable actions to each state, i.e., the output relevant services that can be selected to resolve all the unsatisfied concepts.\nGiven a composition graph G = (V,E) as defined previously, where V = W \u222aC is the set of vertices which are the services and the concepts (inputs/outputs) of the graph, the state-transition system \u03a3 for the (backward) composition problem is defined as follows: \u2022 S \u2286 2|C| where C is the set of all concepts in the\ncomposition graph, i.e., a state is a set of concepts of the graph, s = {c1, . . . , cn}. \u2022 A \u2286 2|W | where W is the set of services in the composition graph, i.e., an action is a set of services from the graph, a = {w1, . . . , wn}.\n\u2022 \u03b3(a, s) = (s \u2212 \u22c3\n(\u03a8(ci) | ci \u2208 Out(a)) \u222a In(a)), i.e., the application of an action a = {w1, . . . , wn} to a state s = {c1, . . . , cn} generates a new state where all concepts that are matched by the outputs of the services of the actions are removed, and the inputs of the services of the actions are added as the new unsatisfied concepts. Functions In(a) and Out(a) return the union of the input concepts and the union of the output concepts of the services in a respectively.\nThe initial state s0 of the backward composition problem P = (\u03a3, s0, G) is defined as s0 = InwO , i.e., the input concepts of the output dummy service. For example, in Fig. 3, the initial state is s0 = {i18, i19}. On the other hand, there is just one goal state G = {sg = \u2205}, i.e., the goal state is reached when there are no unsatisfied concepts in the composition.\nThe efficiency of the search can also be improved using search optimisations depending on the search strategy followed. These optimisations can be applied to the available actions for each state by pruning actions that lead to dead-ends, actions that are equivalent, or actions that are dominated (cannot lead to a better solution)."}, {"heading": "5 REFERENCE IMPLEMENTATION", "text": "We developed a reference implementation of the integrated graph-based composition framework that is based\non two main components: iServe [2], a service warehouse with advanced discovery support which provides the service registry and takes care of the matchmaking and service discovery activities, and ComposIT [22], which is in charge of the graph-based composition part.\nFig. 5 depicts the architecture of the system. In a nutshell the composition process is carried out as follows. When a composition request is sent to the system through the Web UI, ComposIT starts computing the composition graph with all the relevant services for the request. To this end, all the relevant services are discovered layer by layer using the fine-grained I/O logic-based discovery support provided by the Semantic Discovery Engine of iServe. This engine relies on the Service Manager and the KB Manager to retrieve the relevant services using semantic reasoning capabilities. During the composition graph generation, ComposIT also makes intensive use of the KB Manager in order to carry out concept level matching and consequently figure out how the inputs and outputs of the services obtained can be connected. Once the composition graph is generated, ComposIT applies the backward pruning and the interface dominance optimisations to reduce the graph size. These optimisations are applicable using only the information contained in the graph, and thus there is no need to interact with the discovery component. Finally, an optimal search is performed over the graph using a backward A* algorithm that extracts the optimal composition from the graph.\nIn the next sections we shall cover in more detail the inner workings of iServe and ComposIT respectively."}, {"heading": "5.1 iServe", "text": "iServe [2], see right hand-side of Fig. 5, is a service warehouse whose functionality includes the core service registry anchored on Linked Data principles, semantic reasoning support, advanced discovery functionality, and further analysis components able to assist in automatically locating and generating semantic service descriptions out of Web resources. For the purposes of this work we have essentially exploited the registry and discovery functionality.\nThe service discovery functionality builds on top of the Storage Access Layer, which is in charge of managing the registry\u2019s data that includes Service descriptions, related documents and the corresponding Ontologies. This layer essentially provides a RDF/S and OWL storage and reasoning support, document storage, as well as basic crawling facilities to automatically obtain referenced Ontologies. RDF/S and OWL storage and reasoning support is delegated to dedicated engines which are accessed by means of the SPARQL 1.1 standard. Therefore, the reasoning capabilities depend largely on the actual configuration of the store. Concretely, the discovery infrastructure contacts the Service Manager to list services given basic criteria such as the input and output types provided, and the KB Manager to\nobtain concepts, properties, and their sub or super concepts. Depending on their implementation Service and KB Managers combine internal indexes with SPARQL queries issued to the triple store by means of Jena.\nServices are imported to iServe using a range of transformation engines able to import service descriptions in a variety of formalisms including SAWSDL, WSMO-Lite, OWL-S, and MicroWSMO. These plugins generate descriptions expressed in terms of a simple RDF/S model, Minimal Service Model (MSM) [2], which essentially captures the intersection of existing service description formalisms. By means of these transformations iServe provides an homogeneous description for services that were orginally annotated using heterogeneous means.\nGiven that, as we saw in Section 4, the response time of the overall composition is highly dependent on the performance of the service discovery and concept matchmaking tasks, we extended iServe with various implementations of the Service and Knowledge Base Managers. We tested different configurations to study their individual performance and the overall impact on composition response times. In particular, we used the following configurations:\n1) SPARQL D/M: pure SPARQL Discovery / Matchmaking where all interactions with the Service and Knowledge Base managers are directly implemented as SPARQL queries. This is the typical approach of discovery engines and was the original implementation of iServe. 2) Index. D/SPARQL+Cache M: I/O service discovery is based on an index. We additionally used herein an intermediate cache at the level of the concept matcher in order to avoid issuing recurrent SPARQL queries. 3) Full Indexed D/M: both service discovery and concept matchmaking relied on local indexes prepopulated at load time (and updated with writes). In this configuration, service discovery and concept matchmaking do not need to issue any SPARQL query to the backed."}, {"heading": "5.2 ComposIT", "text": "ComposIT [22], depicted in the left hand-side of Fig. 5, is the semantic Web service composition engine we rely on. It implements all the different graph-based composition phases of the framework described in Sec. 4. The semantic service discovery and matchmaking mechanisms, which originally were directly implemented internally, are delegated to iServe by means of integration adapters implemented for the purposes of this work. ComposIT nonetheless uses an internal cache and an index to efficiently recover the information of the generated composition graph. It is worth to note that the architecture supports the deployment of multiple, distributed iServe instances to provide different endpoints that can be used by ComposIT in the composition phase by aggregating the results of the registries at the ComposIT API level. Indeed, since the services to contemplate at composition time are identified by the remote registry and we just use them directly, composing this set of services out of just one API call or several calls in parallel (one per registry) is a trivial change. The overall response time analysis would still remain unchanged, and would have an upper-bound determined by the slowest registry. This also applies to other third-party discovery engines as long as they support fine-grained I/O discovery queries as described in Sec. 4.2. The integration of these thirdparty registries could be achieved by developing interface adapters (with capabilities to retrieve input and output relevant services) which could be plugged in to the system, keeping the generation of the composition graph isolated from the concrete registries used.\nThe generated composition graph can contain different compositions with the same or different length (number of layers) and with different number of services depending on the services that have been selected to generate the needed data. Among the different combinations that can be obtained, the goal of ComposIT is to find the shortest service composition with the minimum number of services. For this purpose, ComposIT searches for the optimal composition by carrying out a heuristic search\nbased on the A* algorithm [36]. This search was implemented using Hipster4j [37] to identify a minimal subset of the services from the graph that satisfy the request (in terms of inputs and outputs). Note that multiple compositions can be extracted from the composition graph since there may be different services that generate outputs of the same concept."}, {"heading": "6 EVALUATION", "text": "In this section we present a quantitative evaluation of our approach. The purposes of the evaluation are: 1) measure the scalability of the approach with many services; 2) study the impact of the discovery on the overall composition performance and 3) compare the performance with different optimisations.\nIn order to perform a standard and comparable evaluation, we selected the Web Service Challenge 2008 (WSC\u201908) service datasets. These datasets allow us to measure the scalability with an increasingly large set of services (from 158 to 8,119 services). Services were imported to iServe using an specific transformer plugin which translates each service description in the WSC\u201908 XML format into MSM, and the XML concept taxonomy into an equivalent OWL representation. iServe is responsible of identifying, loading and reasoning with the ontologies used in the service descriptions. Data types of the input and outputs of service descriptions are linked to their corresponding semantic concepts through the modelReference property of the MSM, which points to the concepts defined in the transformed OWL model.\nExperiments were run under Ubuntu 10.04 64-bit on a PC with an Intel Core 2 Duo E6550 at 2.33GHz and 4 GB of RAM. OWLIM-Lite 5.3 with OWL Horst reasoning was chosen in iServe as the RDF triple store for the semantic registries and deployed within Tomcat 7.\nTable 1 shows the characteristics of each WSC\u201908 dataset. The number of services and concepts in the ontology of each dataset are shown in columns #Serv. and #Con. respectively. The quality of the solutions is based on the number of services and the length (i.e., number of layers) of the composition. The optimal quality of solution for each dataset (according to the WSC\u201908 competition) are shown in columns #Serv.Sol. and Length.\nExperimentation was done using the configurations explained in Sec. 5 with one instance of iServe in order to\nmeasure the effect of the Discovery/Matchmaking over the whole composition process. Results with each configuration are shown in Table 2. The second column shows the size (number of services) of the resulting composition graph for each dataset. The next columns show the time taken to generate the composition graph (G. time) in seconds and the number of SPARQL queries generated during that process. The last three columns show the size of the graph after the graph-based optimisations, the time of the composition search (graph optimisations + optimal A* backward search) and the number of services and length of the optimal composition found. Note that the backward optimal search does not depend on the configuration selected since it only uses the information in the composition graph.\nThe analysis of these results reveals that the discovery and matchmaking phases take most of the time of the composition, even using the optimal configuration (Full Indexed D/M) to avoid the latency of the SPARQL queries. This is graphically represented in Fig. 6. This figure shows the overall composition time for each dataset including the relative time of the Full Indexed D/M (blue bar) and the Composition Search (red bar). The Full Indexed D/M takes 77% of the total composition time on average. This percentage is even higher (about 99%) if the discovery and matchmaking are not optimised using indexes and cache. In other words, as anticipated by the complexity analysis presented earlier, discovery and matchmaking are responsible for the majority of the computation that needs to be performed to compose services. Optimising both phases is thus fundamental.\nThe comparison of the scalability of the three configurations with respect to the number of services is shown in Fig. 7. As can be seen, directly querying the backend (see SPARQL D/M), which is the approach followed by most discovery engines, rapidly becomes prohibitively slow taking 1,656 seconds (i.e., 27.6 min) in the largest dataset. Indeed, the generation of the composition graph requires computing every semantic match between all inputs and outputs as well as discovering relevant services at each layer. Doing so leads to issuing thousands of SPARQL queries. This can be dramatically improved using a discovery index and a local cache for the matchmaking system as can be seen in the second\nTABLE 2 Evaluation results with different Discovery/Matchmaking (D/M) configurations with the WSC\u201908 datasets\nDiscovery/Matchmaking (D/M) Composition\n1) SPARQL D/M 2) Index. D/SPARQL+Cache M 3) Full Indexed D/M\nDataset G. size G. time (s) #SPARQL G. time (s) #SPARQL G. time (s) #SPARQL G. size (opt) Comp. time (s) Sol. (serv./length)\nWSC\u201908-01 35 28.52 3256 5.67 624 0,18 0 13 (-37%) 0.08 10/5\nWSC\u201908-02 35 63.30 7349 11.76 1830 0,38 0 13 (-37%) 0.07 5/3\nWSC\u201908-03 105 262.80 36619 20.05 3184 0.69 0 40 (-38%) 0.21 40/23\nWSC\u201908-04 44 136.20 13828 21.12 3481 0.60 0 25 (-57%) 0.12 10/5\nWSC\u201908-05 97 333.60 41148 26.05 4417 0.74 0 52 (-54%) 0.18 20/8\nWSC\u201908-06 189 1051.20 93682 48.21 8511 1.12 0 75 (-40%) 1.05 42/7\nWSC\u201908-07 124 1183.20 120881 35.76 6376 1.33 0 70 (-56%) 0.23 20/12\nWSC\u201908-08 121 1656.00 89518 78.00 15844 1.48 0 58 (-48%) 0.34 30/20\n0 1,000 2,000 3,000 4,000 5,000 6,000 7,000 8,000 0.10\n1.00\n10.00\n100.00\n1,000.00\n10,000.00\nSPARQLD/M Index. D / SPARQL+Cache M Full Indexed D/M\nNumber of services in the dataset\nG ra ph\nge ne\nra tio\nn tim\ne (s )\nFig. 7. Composition time for different configurations.\nconfiguration. In this case, almost every composition is calculated in less than a minute. The generated SPARQL queries in this case are reduced by up to 91% (for the WSC\u201908-3 dataset) leading to a significant performance improvement. Although such an improvement can be enough to solve the smaller datasets in a few seconds, the latency of the SPARQL queries still remains a bottleneck for bigger datasets like the WSC\u201908-08 dataset that still require evaluating 15,844 SPARQL queries for generating the composition graph in 78 seconds. Our tests show, however, that the full indexed configuration allows solving the largest problems very fast by avoiding the evaluation of SPARQL queries at composition time. This configuration entails the derived need for service registries to additionally calculate and maintain the indexes. Doing so, nonetheless, enables performing very efficient composition over remote 3rd party controlled service registries akin to what can be obtained by the fastest composition engines in the unrealistic scenarios where all services are available and pre-loaded in memory. Additionally, indeed, using those indexes allows service registries to provide highly efficient discovery for a controlled set of queries, while retaining the ability to offer fully flexible yet less efficient discovery support.\nWe have also evaluated our framework with the WSC\u201909-10 datasets. Results show a similar scalability\nbehaviour with the number of services for each configuration. Moreover, our approach is able to solve all the datasets with optimal results, which are shown at https://wiki.citius.usc.es/composit:wsc09."}, {"heading": "7 CONCLUSIONS", "text": "In this paper we have presented a theoretical analysis of service composition in terms of its dependency with service discovery. Driven by this analysis we have defined a formal integrated graph-based composition framework anchored on the integration of service discovery and matchmaking within the composition process. We have devised a reference implementation of this framework on the basis of two pre-existing separate components, namely iServe and ComposIT. This reference implementation has been used to empirically study the impact of discovery and matchmaking on service composition, and we have provided three different configurations with varying performance. Our empirical analysis shows that, indeed, typical approaches followed by discovery engines cannot serve as a suitable basis to support efficient service composition as they lead to prohibitive execution times. We have also shown, though, that with the adequate interface granularity and indexing, discovery engines can support highly efficient composition akin to that obtained by the fastest composition engines without having to assume to local availability and in-memory preloading of service registries.\nThis work proves the scalability and flexibility of our proposal and provides insights on how integrated composition systems can be designed in order to achieve good performance in real scenarios, where service registries and composition frameworks are likely to be distributed and controlled by diverse organisations."}, {"heading": "ACKNOWLEDGMENT", "text": "This work was partly supported by the Spanish Ministry of Economy and Competitiveness (MEC) under grant TIN2011-22935, and by the COMPOSE European Project (FP7-ICT-317862). Pablo Rodr\u0131\u0301guez-Mier is supported by an FPU Grant from the MEC (ref. AP2010-1078) and was also partially funded by Pedro Barrie\u0301 de la Maza Foundation (2013)."}], "references": [{"title": "iServe: a linked services publishing platform,", "author": ["C. Pedrinaci", "D. Liu", "M. Maleshkova", "D. Lambert", "J. Kopecky", "J. Domingue"], "venue": "CEUR Workshop Proceedings,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2010}, {"title": "Web Service Composition - Current Solutions and Open Problems,", "author": ["B. Srivastava", "J. Koehler"], "venue": "ICAPS 2003 workshop on Planning for Web Services,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2003}, {"title": "A Survey of Automated Web Service Composition Methods,", "author": ["J. Rao", "X. Su"], "venue": "Semantic Web Services and Web Process Composition,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2004}, {"title": "A survey on web services composition,", "author": ["S. Dustdar", "W. Schreiner"], "venue": "Int. J. of Web and Grid Services,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2005}, {"title": "Semantic web services,", "author": ["S.A. McIlraith", "T.C. Son", "H. Zeng"], "venue": "IEEE Intelligent Systems,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2001}, {"title": "Service-Oriented Computing: State of the Art and Research Challenges,", "author": ["M.P. Papazoglou", "P. Traverso", "S. Dustdar", "F. Leymann"], "venue": "Computer, vol. 40,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2007}, {"title": "Web Service Composition as Planning,", "author": ["M. Carman", "L. Serafini", "P. Traverso"], "venue": "ICAPS 2003 Workshop on planning for web services,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2003}, {"title": "HTN planning for Web Service composition using SHOP2,", "author": ["E. Sirin", "B. Parsia", "D. Wu", "J. Hendler", "D. Nau"], "venue": "Web Semantics: Science, Services and Agents on the World Wide Web,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2004}, {"title": "Semantic Web Service Composition Planning with OWLS-Xplan,", "author": ["M. Klusch", "A. Gerber", "M. Schmidt"], "venue": "Proceedings of the AAAI Fall Symposium on Semantic Web and Agents,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2005}, {"title": "Adapting golog for composition of semantic web services,", "author": ["S.A. McIlraith", "T.C. Son"], "venue": "Proceedings of the Eights Int. Conf. on Principles and Knowledge Representation and Reasoning", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2002}, {"title": "Template-based composition of semantic web services,", "author": ["E. Sirin", "B. Parsia", "J. Hendler"], "venue": "AAAI Fall Symposium on agents and the semantic web,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2005}, {"title": "Generalized Semantics-Based Service Composition,", "author": ["S. Kona", "A. Bansal", "M.B. Blake", "G. Gupta"], "venue": "IEEE Int. Conf. on Web Services,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2008}, {"title": "Automatic Service Composition Using AND/OR Graph,", "author": ["Y. Yan", "B. Xu", "Z. Gu"], "venue": "IEEE Conf. on E-Commerce Technology and the Fifth IEEE Conf. on Enterprise Computing, E-Commerce and E-Services,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2008}, {"title": "Visualizing Compositions of Services from Large Repositories,", "author": ["M. Aiello", "N. Benthem", "E. Khoury"], "venue": "IEEE Conf. on E-Commerce Technology and the Fifth IEEE Conf. on Enterprise Computing, E-Commerce and E-Services. IEEE,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2008}, {"title": "Type-Aware Web Service Composition Using Boolean Satisfiability Solver,", "author": ["W. Nam", "H. Kil", "D. Lee"], "venue": "10th IEEE Conf. on E-Commerce Technology and the Fifth IEEE Conf. on Enterprise Computing, E-Commerce and E-Services,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2008}, {"title": "Customizable Business Process Composition with Query Optimization,", "author": ["K. Raman", "Y.Z.Y. Zhang", "M. Panahi", "K.-J.L.K.-J. Lin"], "venue": "10th IEEE Conf. on E-Commerce Technology and the Fifth IEEE Conf. on Enterprise Computing, E-Commerce and E- Services,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2008}, {"title": "Thiell, \u201cAn Incremental Graphbased Approach to Automatic Service Composition,", "author": ["M. Shiaa", "J. Fladmark"], "venue": "IEEE Int. Conf. on Services Computing", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2008}, {"title": "Highly Scalable Web Service Composition Using Binary Tree-Based Parallelization,", "author": ["P. Hennig", "W.-T. Balke"], "venue": "IEEE Int. Conf. on Web Services,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2010}, {"title": "Web service planner (WSPR): an effective and scalable web service composition algorithm,", "author": ["S. Oh", "D. Lee", "S. Kumara"], "venue": "Int. Journal of Web Services Research,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2007}, {"title": "Overview of the S3 Contest: Performance Evaluation of Semantic Service Matchmakers,", "author": ["M. Klusch"], "venue": "Semantic Web Services. Springer,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2012}, {"title": "An Optimal and Complete Algorithm for Automatic Web Service Composition,", "author": ["P. Rodriguez-Mier", "M. Mucientes", "J. Vidal", "M. Lama"], "venue": "Int. J. of Web Services Research (IJWSR),", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2012}, {"title": "Toward the Next Wave of Services: Linked Services for the Web of Data,", "author": ["C. Pedrinaci", "J. Domingue"], "venue": "Journal of Universal Computer Science,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2010}, {"title": "Semantic web services,", "author": ["C. Pedrinaci", "J. Domingue", "A.P. Sheth"], "venue": "Handbook of semantic web technologies. Springer,", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2011}, {"title": "OWLS-MX3: an adaptive hybrid semantic service matchmaker for OWL-S,", "author": ["M. Klusch", "P. Kapahnke"], "venue": "Proceedings of 3rd Int. Workshop on Semantic Matchmaking and Resource Retrieval,", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2009}, {"title": "iSem: Approximated reasoning for adaptive hybrid selection of semantic services,", "author": ["M. Klusch", "P. Kapahnke"], "venue": "The semantic web: Research and applications. Springer,", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2010}, {"title": "XSSD: A Fast Hybrid Semantic Web Services Discovery Method,", "author": ["D. Chu", "J. Han", "J. Li", "Y. Zhao"], "venue": "in Int. Conf. on Computer Technology and Development,", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2011}, {"title": "Web Service Composition as AI Planning \u2013 a Survey,", "author": ["J. Peer"], "venue": "University of St. Gallen, Switzerland, Tech. Rep. March,", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 2005}, {"title": "An Integrated Approach to Automated Semantic Web Service Composition through Planning,", "author": ["O. Hatzi", "D. Vrakas", "M. Nikolaidou", "N. Bassiliades", "D. Anagnostopoulos", "I. Vlahavas"], "venue": "Transactions on Services Computing,", "citeRegEx": "29", "shortCiteRegEx": "29", "year": 2011}, {"title": "WSC-08: Continuing the Web Services Challenge,", "author": ["A. Bansal", "M.B. Blake", "S. Kona", "S. Bleul", "T. Weise", "M.C. Jaeger"], "venue": "IEEE Conf. on E-Commerce Technology and the Fifth IEEE Conf. on Enterprise Computing, E-Commerce and E-Services", "citeRegEx": "30", "shortCiteRegEx": "30", "year": 2008}, {"title": "Lecue, \u201cA framework for dynamic web services composition,", "author": ["F. L\u00e9cu\u00e9", "E. Silva", "L.F. Pires"], "venue": "ECOWS Workshop on Emerging Web Services Technology,", "citeRegEx": "31", "shortCiteRegEx": "31", "year": 2007}, {"title": "Towards runtime discovery, selection and composition of semantic services,", "author": ["E.G. da Silva", "L.F. Pires", "M. van Sinderen"], "venue": "Computer Communications,", "citeRegEx": "32", "shortCiteRegEx": "32", "year": 2011}, {"title": "Semantic Matching of Web Services Capabilities,", "author": ["M. Paolucci", "T. Kawamura", "T.R. Payne", "K. Sycara"], "venue": "The Semantic Web - ISWC 2002,", "citeRegEx": "33", "shortCiteRegEx": "33", "year": 2002}, {"title": "Automatic Web Service Composition with a Heuristic-Based Search Algorithm,", "author": ["P. Rodriguez-Mier", "M. Mucientes", "M. Lama"], "venue": "IEEE Int. Conf. on Web Services (ICWS),", "citeRegEx": "34", "shortCiteRegEx": "34", "year": 2011}, {"title": "A Formal Basis for the Heuristic Determination of Minimum Cost Paths,", "author": ["P.E. Hart", "N.J. Nilsson", "B. Raphael"], "venue": "IEEE Transactions of Systems Science and Cybernetics,", "citeRegEx": "36", "shortCiteRegEx": "36", "year": 1968}, {"title": "Hipster: An Open Source Java Library for Heuristic Search,", "author": ["P. Rodriguez-Mier", "A. Gonzalez-Sieira", "M. Mucientes", "M. Lama", "A. Bugarin"], "venue": "Iberian Conf. on Information Systems and Technologies,", "citeRegEx": "37", "shortCiteRegEx": "37", "year": 2014}], "referenceMentions": [{"referenceID": 0, "context": "services across domains exploiting rich user-provided semantic service descriptions [2].", "startOffset": 84, "endOffset": 87}, {"referenceID": 1, "context": "Similarly, a plethora of service composition solutions have been produced spanning from mere graphical support to completely automated solutions [3]\u2013[5].", "startOffset": 145, "endOffset": 148}, {"referenceID": 3, "context": "Similarly, a plethora of service composition solutions have been produced spanning from mere graphical support to completely automated solutions [3]\u2013[5].", "startOffset": 149, "endOffset": 152}, {"referenceID": 4, "context": "service descriptions, which increasingly go beyond syntactic representations to include the semantics of the service(s) to enable more advanced computations [6], [7].", "startOffset": 157, "endOffset": 160}, {"referenceID": 5, "context": "service descriptions, which increasingly go beyond syntactic representations to include the semantics of the service(s) to enable more advanced computations [6], [7].", "startOffset": 162, "endOffset": 165}, {"referenceID": 6, "context": "Whether one looks at fully automated composition engines based on Artificial Intelligence (AI) planning techniques [8]\u2013[10], or at more constrained solutions that rely on pre-defined skeletal plans [11], [12], or at graph based approaches focused on semantic inputoutput parameter matching [13]\u2013[20], service discovery", "startOffset": 115, "endOffset": 118}, {"referenceID": 8, "context": "Whether one looks at fully automated composition engines based on Artificial Intelligence (AI) planning techniques [8]\u2013[10], or at more constrained solutions that rely on pre-defined skeletal plans [11], [12], or at graph based approaches focused on semantic inputoutput parameter matching [13]\u2013[20], service discovery", "startOffset": 119, "endOffset": 123}, {"referenceID": 9, "context": "Whether one looks at fully automated composition engines based on Artificial Intelligence (AI) planning techniques [8]\u2013[10], or at more constrained solutions that rely on pre-defined skeletal plans [11], [12], or at graph based approaches focused on semantic inputoutput parameter matching [13]\u2013[20], service discovery", "startOffset": 198, "endOffset": 202}, {"referenceID": 10, "context": "Whether one looks at fully automated composition engines based on Artificial Intelligence (AI) planning techniques [8]\u2013[10], or at more constrained solutions that rely on pre-defined skeletal plans [11], [12], or at graph based approaches focused on semantic inputoutput parameter matching [13]\u2013[20], service discovery", "startOffset": 204, "endOffset": 208}, {"referenceID": 11, "context": "Whether one looks at fully automated composition engines based on Artificial Intelligence (AI) planning techniques [8]\u2013[10], or at more constrained solutions that rely on pre-defined skeletal plans [11], [12], or at graph based approaches focused on semantic inputoutput parameter matching [13]\u2013[20], service discovery", "startOffset": 290, "endOffset": 294}, {"referenceID": 18, "context": "Whether one looks at fully automated composition engines based on Artificial Intelligence (AI) planning techniques [8]\u2013[10], or at more constrained solutions that rely on pre-defined skeletal plans [11], [12], or at graph based approaches focused on semantic inputoutput parameter matching [13]\u2013[20], service discovery", "startOffset": 295, "endOffset": 299}, {"referenceID": 19, "context": "Moreover, response times of discovery engines are orders of magnitude above what would be acceptable for a composition engine that should it delegate the thousands discovery requests it needs to issue at composition time [21].", "startOffset": 221, "endOffset": 225}, {"referenceID": 20, "context": "2) A reference implementation of this formal framework based on the adaptation of two independently developed components, namely ComposIT [22] and iServe [2], respectively in charge of", "startOffset": 138, "endOffset": 142}, {"referenceID": 0, "context": "2) A reference implementation of this formal framework based on the adaptation of two independently developed components, namely ComposIT [22] and iServe [2], respectively in charge of", "startOffset": 154, "endOffset": 157}, {"referenceID": 21, "context": "In fact, on the Web less than 5% of the semantic Web services include preconditions and effects [23].", "startOffset": 96, "endOffset": 100}, {"referenceID": 3, "context": "problem that involves multiple research areas [5].", "startOffset": 46, "endOffset": 49}, {"referenceID": 22, "context": "Concretely, lots of efforts have been devoted to automate the discovery and composition using different approaches and techniques [24].", "startOffset": 130, "endOffset": 134}, {"referenceID": 19, "context": "competition [21] shows some of the newest advances in the automatic discovery field.", "startOffset": 12, "endOffset": 16}, {"referenceID": 23, "context": "Most relevant examples are OWLS-MX3 [25], iSem 1.", "startOffset": 36, "endOffset": 40}, {"referenceID": 24, "context": "1 [26] and XSSD [27].", "startOffset": 2, "endOffset": 6}, {"referenceID": 25, "context": "1 [26] and XSSD [27].", "startOffset": 16, "endOffset": 20}, {"referenceID": 26, "context": "From the composition side, most approaches can be categorized into: 1) classical AI planning approaches [28], where the composition problem is translated into", "startOffset": 104, "endOffset": 108}, {"referenceID": 7, "context": "Relevant approaches of the first group are [9], [10], [29].", "startOffset": 43, "endOffset": 46}, {"referenceID": 8, "context": "Relevant approaches of the first group are [9], [10], [29].", "startOffset": 48, "endOffset": 52}, {"referenceID": 27, "context": "Relevant approaches of the first group are [9], [10], [29].", "startOffset": 54, "endOffset": 58}, {"referenceID": 28, "context": "On the other hand, graph-based I/O approaches are gaining much attention since the Web Service Challenge [30].", "startOffset": 105, "endOffset": 109}, {"referenceID": 12, "context": "Some notable works in this field are [14]\u2013 [20].", "startOffset": 37, "endOffset": 41}, {"referenceID": 18, "context": "Some notable works in this field are [14]\u2013 [20].", "startOffset": 43, "endOffset": 47}, {"referenceID": 12, "context": "Concretely, [14], [15], [20] are the top-3 algorithms of", "startOffset": 12, "endOffset": 16}, {"referenceID": 13, "context": "Concretely, [14], [15], [20] are the top-3 algorithms of", "startOffset": 18, "endOffset": 22}, {"referenceID": 18, "context": "Concretely, [14], [15], [20] are the top-3 algorithms of", "startOffset": 24, "endOffset": 28}, {"referenceID": 12, "context": "Although these approaches show generally good performance and low response times, [14] and [15] do not find optimal solutions and [20] fails to find solutions in large data sets.", "startOffset": 82, "endOffset": 86}, {"referenceID": 13, "context": "Although these approaches show generally good performance and low response times, [14] and [15] do not find optimal solutions and [20] fails to find solutions in large data sets.", "startOffset": 91, "endOffset": 95}, {"referenceID": 18, "context": "Although these approaches show generally good performance and low response times, [14] and [15] do not find optimal solutions and [20] fails to find solutions in large data sets.", "startOffset": 130, "endOffset": 134}, {"referenceID": 11, "context": "in [13].", "startOffset": 3, "endOffset": 7}, {"referenceID": 29, "context": "Similarly, in [31], L\u00e9cu\u00e9 et al.", "startOffset": 14, "endOffset": 18}, {"referenceID": 30, "context": "In [32], Da Silva et al.", "startOffset": 3, "endOffset": 7}, {"referenceID": 31, "context": "The different matchmaking degrees that are typically contemplated in the literature are [33]:", "startOffset": 88, "endOffset": 92}, {"referenceID": 20, "context": "We distinguish at least two different techniques [22], [34]: backward pruning and interface dominance.", "startOffset": 49, "endOffset": 53}, {"referenceID": 32, "context": "We distinguish at least two different techniques [22], [34]: backward pruning and interface dominance.", "startOffset": 55, "endOffset": 59}, {"referenceID": 0, "context": "We developed a reference implementation of the integrated graph-based composition framework that is based on two main components: iServe [2], a service warehouse with advanced discovery support which provides the service registry and takes care of the matchmaking and service discovery activities, and ComposIT [22], which is in charge of the graph-based composition part.", "startOffset": 137, "endOffset": 140}, {"referenceID": 20, "context": "We developed a reference implementation of the integrated graph-based composition framework that is based on two main components: iServe [2], a service warehouse with advanced discovery support which provides the service registry and takes care of the matchmaking and service discovery activities, and ComposIT [22], which is in charge of the graph-based composition part.", "startOffset": 311, "endOffset": 315}, {"referenceID": 0, "context": "iServe [2], see right hand-side of Fig.", "startOffset": 7, "endOffset": 10}, {"referenceID": 0, "context": "These plugins generate descriptions expressed in terms of a simple RDF/S model, Minimal Service Model (MSM) [2], which essentially captures the intersection of existing service description formalisms.", "startOffset": 108, "endOffset": 111}, {"referenceID": 20, "context": "ComposIT [22], depicted in the left hand-side of Fig.", "startOffset": 9, "endOffset": 13}, {"referenceID": 33, "context": "based on the A* algorithm [36].", "startOffset": 26, "endOffset": 30}, {"referenceID": 34, "context": "mented using Hipster4j [37] to identify a minimal subset of the services from the graph that satisfy the request (in terms of inputs and outputs).", "startOffset": 23, "endOffset": 27}], "year": 2015, "abstractText": "In this paper we present a theoretical analysis of graph-based service composition in terms of its dependency with service discovery. Driven by this analysis we define a composition framework by means of integration with fine-grained I/O service discovery that enables the generation of a graph-based composition which contains the set of services that are semantically relevant for an input-output request. The proposed framework also includes an optimal composition search algorithm to extract the best composition from the graph minimising the length and the number of services, and different graph optimisations to improve the scalability of the system. A practical implementation used for the empirical analysis is also provided. This analysis proves the scalability and flexibility of our proposal and provides insights on how integrated composition systems can be designed in order to achieve good performance in real scenarios for the Web.", "creator": "LaTeX with hyperref package"}}}