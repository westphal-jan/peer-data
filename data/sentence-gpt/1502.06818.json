{"id": "1502.06818", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "24-Feb-2015", "title": "Tensor SimRank for Heterogeneous Information Networks", "abstract": "We propose a generalization of SimRank similarity measure for heterogeneous information networks. Given the information network, the intraclass similarity score s(a, b) is high if the set of objects that are related with a and the set of objects that are related with b are pair-wise similar according to all imposed relations.\n\n\n\n\n\n\n\nThe first of the steps to implement a classification for heterogeneous information networks is to identify the group of pairs and obtain the rank-dependent set of individual entities with identical rank-dependent rank-dependent ranking-dependent rank-dependent rank-dependent rank-dependent rank-dependent rank-dependent rank-dependent rank-dependent rank-dependent rank-dependent rank-dependent rank-dependent rank-dependent rank-dependent rank-dependent rank-dependent rank-dependent rank-dependent rank-dependent rank-dependent rank-dependent rank-dependent rank-dependent rank-dependent rank-dependent rank-dependent rank-dependent rank-dependent rank-dependent rank-dependent rank-dependent rank-dependent rank-dependent rank-dependent rank-dependent rank-dependent rank-dependent rank-dependent rank-dependent rank-dependent rank-dependent rank-dependent rank-independent rank-dependent rank-independent rank-dependent rank-dependent rank-dependent rank-independent rank-dependent rank-independent rank-dependent rank-dependent rank-dependent rank-dependent rank-independent rank-independent rank-independent rank-independent rank-independent rank-independent rank-independent rank-dependent rank-independent rank-independent rank-independent rank-independent rank-independent rank-independent rank-independent rank-independent rank-independent rank-independent rank-independent rank-independent rank-independent rank-independent rank-independent rank-independent rank-independent rank-independent rank-independent rank-independent rank-independent rank-independent rank-independent rank-independent rank-independent rank-independent rank-independent rank-independent rank-independent rank-independent rank-independent rank-independent rank-independent rank-independent rank-independent rank-independent rank-independent rank-independent rank-independent rank-independent rank-independent rank-independent rank-independent rank-independent rank-independent rank-independent rank-independent rank-independent rank-independent rank-independent rank-independent rank-independent rank-independent rank-independent rank-independent rank-independent rank-independent rank-independent rank-independent rank-independent rank-independent rank-independent rank-independent rank-independent rank-independent rank-independent rank-independent rank-independent rank-independent rank-independent", "histories": [["v1", "Tue, 24 Feb 2015 14:10:04 GMT  (126kb,D)", "http://arxiv.org/abs/1502.06818v1", "Submited on KDD'15"]], "COMMENTS": "Submited on KDD'15", "reviews": [], "SUBJECTS": "cs.AI", "authors": ["ben usman", "ivan oseledets"], "accepted": false, "id": "1502.06818"}, "pdf": {"name": "1502.06818.pdf", "metadata": {"source": "CRF", "title": "Tensor SimRank for Heterogeneous Information Networks", "authors": ["Ben Usman", "Ivan Oseledets"], "emails": ["ben.usman@skoltech.ru", "i.oseledets@skoltech.ru"], "sections": [{"heading": null, "text": "Categories and Subject Descriptors [Information systems]: Retrieval models and ranking\u2013 Similarity measures\nGeneral Terms SimRank, Probabilistic SVD, Tensor, Low-rank approximation"}, {"heading": "1. INTRODUCTION", "text": "Most data in the modern world can be treated as an information network, thus network node similarity measuring has wide range of applications: search [1], recommendation systems [2], research publication networks analysis [3], biology [4], transportation and logistics [5] and others.\nConsider a semantic network: set of types T , each type t \u2208 T is a set of entities; set of relations R, each relation is 2-order predicate defined on two types from T :\nR 3 rtp : t\u00d7 p 7\u2192 {1, 0}, t, p \u2208 T ,\nboth types in relation can be equal (rtt : t\u00d7 t\u2192 {0, 1}), few relations can share the same pair of types (\u2203r(1)tp 6= r (2) tp \u2208 {0, 1}t\u00d7p). That structure may be considered as a graph with colored vertices and colored edges: vertex color is its entity type, edge color correponds to a relation.\nThe question that we address is how to define similarity functions\nst : t\u00d7 t\u2192 R, \u2200t \u2208 T ,\nPermission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. 21st ACM SIGKDD\u201915 Sydney Copyright 2014 ACM X-XXXXX-XX-X/XX/XX ...$15.00.\nthat would reflect the closeness of objects based on \u201dsimilarity of relations\u201d they enter, and at the same time not mixing different relations as soon as \u201dobjects of different types and links carry different semantic meanings, and it does not make sense to mix them to measure the similarity without distinguishing their semantics\u201d [6]."}, {"heading": "1.1 Related work", "text": "The basic graph structure similarity measure is the classical SimRank [7] over a homogeneous graph G = (V,E) which is defined as follows:\nNG(a) = {v \u2208 V : (v, a) \u2208 E(G)},\ns(a, b) = C\nI(a)I(b) \u2211 v\u2208N(a) w\u2208N(b) s(w, v).\nThe main drawback of this approach is that we cannot induce multiple relations or object types, so the only option is mixing them up into blobs \u201drelation exists\u201d and \u201dall objects\u201d that is completely not applicable in the case we have multiple relations with different semantics, for example the OpenCyc ontology node of the concept \u201dGame\u201d (see Figure 1) cannot be easily expressed via a single type of relations and objects.\nPersonalized PageRank [8] is also often used to measure\nar X\niv :1\n50 2.\n06 81\n8v 1\n[ cs\n.A I]\n2 4\nFe b\n20 15\nsimilarity in homogeneous graphs:\n\u03c0a(b) = \u03b5\u03b4a(b) + (1\u2212 \u03b5) \u2211\n(w,b)\u2208E\n\u03c0a(w)\n\u03b1w,v ,\nthat it same as PageRank, except random jumps are made into some pre-chosen node b, rather then into random node.\nAnother option is PathRank [6] that measures path-similarity between objects a, b picked from the same class A of the heterogeneous information network N given a symmetric meta-path P (set of paths that satisfy composition of relations M1,M2, . . . ,Mn that A M1\u2212\u2212\u2192 C1 M2\u2212\u2212\u2192 C2 . . .\nMn\u2212\u2212\u2192 A, so A\nM1\u25e6M2\u25e6\u00b7\u00b7\u00b7\u25e6Mn\u2212\u2212\u2212\u2212\u2212\u2212\u2212\u2212\u2212\u2212\u2192 A) as a number of paths from the object a to the object b (each step i must satisfy corresponding relation Mi in P) normed over the number of paths from a to a plus the number of paths from b to b given P:\nsP(a, b) = \u2016{p \u2208 P : a p=\u21d2 b}\u2016\n\u2016{p \u2208 P : a p=\u21d2 a}\u2016+ \u2016{p \u2208 P : b p=\u21d2 b}\u2016\nThat approach can handle several relations and object types and is very useful when we know the structure of relations we want our similarity measure to be based on. In case we want just to \u201dput our relations into a black box\u201d that would find similarity that would capture all network relations as a whole, we might want to use something different. Recently, an approach [9] for building an optimal linear combination of meta-paths has been proposed.\nThere are several works on measuring similarity between objects from different classes, see, for example, [10]."}, {"heading": "2. TENSOR SIMRANK", "text": ""}, {"heading": "2.1 Problem statement", "text": "Let us consider a function st(a, b) that assigns similarity score for two objects from the same class t as follows: objects a, b \u2208 t \u2208 T are similar (value st(a, b) is high) if they relate to objects which are similar too. That interdependence can be expressed via the following definition:\nNrtp(a) = {b \u2208 p|rtp(a, b) = 1}, st(a, b) = 1\nZ \u2211 rtp\u2208R w(rtp) \u2211\nc\u2208Np(a) d\u2208Np(b)\nsp(c, d),\nwhere rtp is the relation between classes t, p \u2208 T , Nrtp is the neighbourhood function that returns set of objects from the class p that are related to the object a via the relation rtp, w(rtp) are the weights corresponding to the relation rtp, Z is the normalization constant.\nThis can be rewritten as a Tensor SimRank equation: s\u03b1\u03b2 = \u2211 \u03b3 w\u03b1\u03b2\u03b3 r\u03b1\u03b2\u03b3 s\u03b1\u03b2 r\u03b2\u03b1\u03b3 ,\ns = diag({st}t\u2208T ), s\u03b1\u03b1 = 1, (1)\nwhere s is a block-diagonal matrix (one block per each entity type), w are the relation weights, r\u03b1\u03b2\u03b3 are the stochastic relation tensors 1 (which have non-zero blocks where relations exist).\n1We have to use tensors instead of matrices to have multiple relations on the same pair of classes\nSimilarity scores between elements of different classes are equal to zero by the definition. Relation between objects of unrelated classes is equal to zero by definition too. Equation (1) is basically the classical SimRank equation with the adjacency tensor instead of the adjacency matrix: each nonzero layer of tensor encodes some relation on the same pair of types. If one has more than a single relation between types p, t \u2208 T , then r would have multiple non-zero layers on the intersection of indices associated with the classes t, p \u2014 one adjacency matrix per layer. In (1) the index \u03b3 stands for (weighted) summation over all layers of the tensor. That can be equivalently rewritten explicitly:\nS = \u2211 \u03b3 w\u03b3W\u03b3SW T \u03b3 +D, (2)\nwhere the diagonal matrix D has to be chosen in a such way that diag(S) = I."}, {"heading": "2.2 Computational algorithm", "text": "Simple iterations for (1) are computationally demanding due to large-scale matrix-by-matrix products, thus we propose a a method that exploits the fact that s is block diagonal and r is a three-dimensional block tensor with size of the last dimension (number of layers) much less then the overall amount of objects. On each iteration k for each r \u2208 R we recompute si updates independently (assuming all other sj fixed), see Algorithm 1.\nAlgorithm 1: Idea under Tensor SimRank\nData: T - classes, R - relations Result: S = {st(a, b)}t\u2208T repeat\nfor st \u2208 S do assume all S \\ st fixed for r \u2208 R : rtp : t\u00d7 p 7\u2192 {1, 0} do\nfor (a, b) \u2208 t do for (c, d) \u2208 p do\nsnextt (a, b) += rtp(a, c)sp(c, d)rtp(b, d)\n+= rtp(a, c)sp(c, d)rpt(d, b)\nend\nend\nend\nend\nupdate all st \u2190 snextt until \u2211 t \u2016st \u2212 s next t \u2016 < \u03b4;\nSo we just update the similarity score for each class assuming all other classes similarities are fixed in a way that the objects from the target class (t) that are related to objects from some other class (c, d) \u2208 p that are close (sp(c, d) is high) become closer too (st(a, b) \u2191).\nTo show actual vectorized algorithm of similarity computation, let us introduce some additional notations: set of entity types T = {ti}Ni=0, each entity type t is a set of entities, set of symmetric relation functions R = {r(j)tp }Lj=0 where r\n(j) tjpj : t\u00d7 p\u2192 {0, 1}, t, p \u2208 T , j is the order; columnstochastic matrix of pairwise types impacts (weights) w \u2208 RN\u00d7N ; operator W : r(j)tp \u2192 R\u2016t\u2016\u00d7\u2016p\u2016 that maps relation\ninto corresponding column-stochastic adjacency matrix. If rtp is not defined for some (t, p) \u2208 T 2, then wtp = 0.\nAlgorithm 2: Vectorised Tensor SimRank for HSM\nData: T - classes, R - relations, w - relation weights Result: S = {st(a, b)}t\u2208T for t \u2208 T do\ns (0) t = I\nend k = 0 repeat\nfor t \u2208 T do snewt = 0 for R 3 r : t\u00d7 p 7\u2192 {1, 0} do\nsnewt = s new t + wtpW (rtp)s (k) p W (rpt)\nend k = k + 1\nend for t \u2208 T do\ns (k+1) t = s new t \u2212 diag(snewt ) + I\nend until \u2211 t\u2208T \u2016s (k+1) t \u2212 s (k) t \u2016 \u2264 \u03b5;\nTo achieve better results (see above) on sparse relations we adopted the Low-Rank SimRank approximation [11] that uses Probabilistic Singular Value Decomposition [12] to perform fast approximate projections on low-rank matrix manifold at each step of the iterative process (Algorithm 3).\nThe only difference with Algorithm 2 is that on each step we perform probabilistic SVD decomposition of the matrix S \u2212 I, so that S \u2248 I + UDUT , and project it onto the manifold of matrices of rank at."}, {"heading": "2.3 Convergence conditions", "text": "Recall that the classical SimRank can be computed as a solution of the equation:\nS := WSWT \u2212 diag(WSWT ) + I.\nFixed-point iteration converges if W is a column-stochastic matrix. In the vector form (vec(\u00b7) operator maps an n \u00d7 n matrix into a n2 vector by taking column by column) that can be written as2:\n[W \u2297W \u2212 I] vec(S)\u2212 vec(diag(WSWT )) + vec(I) = 0,\nif matrix W is stochastic, then W \u2297W is stochastic too. Tensor SimRank (2) computation can be equivalently written in the form:\nS := \u2211 \u03b3 w\u03b3W\u03b3SW T \u03b3 \u2212 diag( \u2211 \u03b3 w\u03b3W\u03b3SW T \u03b3 ) + I, (3)\nor in the vectorized for [ \u2211 \u03b3 w\u03b3W\u03b3 \u2297W\u03b3 \u2212 I] vec(S)\u2212 vec(diag(. . . )) + vec(I) = 0.\nMoreover, SimRank is also commonly approximated by the solution of the discrete Lyapunov equation:\nS = cWSWT + (1\u2212 c)I,\n2vec(ABC) = (CT \u2297A)vec(B)\nAlgorithm 3: Low-rank Tensor SimRank for HSM\nData: T - classes, R - relations, w - relation weights, {at} - approximation ranks Result: S = {st(a, b)}t\u2208T for t \u2208 T do\ns (0) t = I\nend k = 0 ut = 0 dt = 0 repeat\nfor t \u2208 T do snewt = 0 for R 3 r : t\u00d7 p 7\u2192 {1, 0} do\nsnewt = s new t + wtp(W (rtp)W (rpt)+\n+W (rtp)updpu T pW (rpt))\nend k = k + 1\nend for t \u2208 T do\nsnewt = s new t \u2212 T ut, dt = ProbabilisticSVD(s new t , at) s (k+1) t = s new t + I\nend until \u2211 t\u2208T \u2016s (k+1) t \u2212 s (k) t \u2016 \u2264 \u03b5;\nwhich can be generalized to the tensor case as S = c \u2211 \u03b3 w\u03b3W\u03b3SW T \u03b3 + (1\u2212 c)I,\nand a fixed-point iteration converges [13] if:\u2211 \u03b3=1 w\u03b3\u2016W\u03b3\u201621 \u2264 1 \u2016W\u03b3\u20161=1\u21d0====\u21d2 stochastic \u2211 \u03b3 w\u03b3 \u2264 1.\nWe conjecture that fixed-point iterations for (3) converge if:\n1. Each W\u03b3 is stochastic 2. \u2211 \u03b3 w\u03b3 = 1\nIn the simplest form (we have no preferences among relations and classes) it reduces to (relations weight):\nwtp = 1\u2211\nm \u2016{r (j) tm \u2208 R}\u2016\n."}, {"heading": "3. COMPUTATIONAL EXPERIMENT", "text": ""}, {"heading": "3.1 Synthetic data: convergence test", "text": "To test convergence conditions we conducted series of tests on randomly generated sparse networks with different number of classes: K \u2208 {3, 5, 7, 10} and with randomly chosen number of objects in eachNreal \u2208 U[N/2;N ], N \u2208 {10 . . . 100}, full network of relation types (all possible types relations exists) with 2 min(N ireal, N j real) randomly chosen edges in each and default w matrix (no priority). All generated networks successfully converged that illustrates that convergent sufficient conditions listed in previous section were adequate, see Figures 2,3."}, {"heading": "3.2 Synthetic data: similarity reconstruction", "text": "To determine if model is capable of similarity reconstruction we generated a tree graph from randomly distributed points on a plane and tested if model can reconstruct points spatial similarity basing only on their relations.\nOn Figure 4 blue point represent 0-level point that are connected to 1-level point (red), that are connected to 2- level points (green).\nWe have measured the following similarity reconstruction S\u0302 quality compared to real S obtained from generated point coordinates:\nQ(S, S\u0302) =\n\u2211 a \u2211 b \u2211 c[Sab < Sac and S\u0302ab < S\u0302ac]\u2211\ni \u2211 j \u2211 k 1\nthat actually shows how many \u201da is closer to c then to b\u201d relations were preserved.\nFrom Figure 5 one can see that at level r \u2248 0.3 model gets saturated, but at the level r \u2248 0.15 models that use low-rank version of Tensor SimRank perform way better than the \u201dpure\u201d algorithm. The numbers in the brackets\nAlgorithm 4: Graph generation algorithm\nData: N - number of layers, {n1, . . . , nN} - number of dots on each layer, r - connection radius Result: T , R for k \u2208 {1..N} do\np(k) \u2190 generate nk point from U2[0;1] if k > 0 then\nR \u2190 rk(p(k)i , p (k\u22121) j ) if \u03c1(p (k) i , p (k\u22121) j ) < r\nend\nend\ndenote the dimensionality of the matrix space into which the similarity matrices were projected on each step (rank of approximation)."}, {"heading": "3.3 Book-Crossing Dataset test", "text": "The model was run on subsample from the Book-Crossing Dataset [14]. We have extracted only those authors who had highest (top100) number of books in the collection. The final network had the following structure:\nT = {Book,Author,Year,Publisher}\nR = {isAuthorOf(\u00b7, \u00b7), publishedBy(\u00b7, \u00b7), publishedIn(\u00b7, \u00b7)}\n#Book = 3625,#Author = 99,\n#Y ear = 65,#Publisher = 554\nModel convergence is shown on Figure 3.3, where successfull convergence to the best possible low-rank approximation can be seen. The similarity structure is clearly visible on Year similarity matrix heatmap (Figure (3.3)). We expect diagonal dominance as soon as temporarily close years should be more or less similar in terms of authors and publishers characteristic of that period. Tables 1 and 2 are examples of \u201dclosest book\u201d requests, we want to notice that no NLP-preprocessing was conducted, nevertheless model treated books from same storybook as similar basing on author/publisher/year similarities.\n4. DISCUSSION AND FURTHER WORK\nProposed model can be used in various problem areas where most of the information is available in the form of relations between entities rather than features of individual entities and no trivial vector representation of those entities can be induced. One can use the vector representation\n[st]ij = \u03b4ij + [ut]ik[dt]kl[ut]lj ,\nto embed the notion of relations into classical machine learning algorithms. Also, the proposed model can be used for relation generalisation, that might give interesting results since we work on heterogeneous graphs.\nFurther model improvements might also include treating relations as objects too (probably, via heterogeneous hypergraphs) and defining similarity matrix on relations."}, {"heading": "5. CONCLUSION", "text": "This paper proposes the generalization of SimRank for heterogeneous networks and a method for its computation that exploits the fact that the resulting similarity matrix is block-diagonal, thus its components might be computed in an iterative fashion. The convergence conditions are proposed and successfully tested. Few perspective application areas are suggested."}, {"heading": "6. REFERENCES", "text": "[1] L. Page, S. Brin, R. Motwani, and T. Winograd, \u201cThe\nPageRank citation ranking: Bringing order to the web.,\u201d 1999.\n[2] J. A. Konstan, B. N. Miller, D. Maltz, J. L. Herlocker, L. R. Gordon, and J. Riedl, \u201cGrouplens: applying collaborative filtering to usenet news,\u201d Communications of the ACM, vol. 40, no. 3, pp. 77\u201387, 1997.\n[3] C. L. Giles, \u201cThe future of Citeseer: Citeseer X,\u201d in Proceedings of the 10th European conference on Principle and Practice of Knowledge Discovery in Databases, pp. 2\u20132, Springer-Verlag, 2006.\n[4] S. Roy, T. Lane, and M. Werner-Washburne, \u201cIntegrative construction and analysis of condition-specific biological networks.,\u201d in Proceedings of the National Conference on Artificial Intelligence, vol. 22, p. 1898, Menlo Park, CA; Cambridge, MA; London; AAAI Press; MIT Press; 1999, 2007.\n[5] W. Jiang, J. Vaidya, Z. Balaporia, C. Clifton, and B. Banich, \u201cKnowledge discovery from transportation network data,\u201d in Data Engineering, 2005. ICDE 2005. Proceedings. 21st International Conference on, pp. 1061\u20131072, IEEE, 2005.\n[6] S. Lee, S. Park, M. Kahng, and S.-g. Lee, \u201cPathrank: Ranking nodes on a heterogeneous graph for flexible hybrid recommender systems,\u201d Expert Systems with Applications, vol. 40, no. 2, pp. 684\u2013697, 2013.\n[7] G. Jeh and J. Widom, \u201cSimrank: a measure of structural-context similarity,\u201d in Proceedings of the eighth ACM SIGKDD international conference on Knowledge discovery and data mining, pp. 538\u2013543, ACM, 2002.\n[8] G. Jeh and J. Widom, \u201cScaling personalized web search,\u201d in Proceedings of the 12th international conference on World Wide Web, pp. 271\u2013279, ACM, 2003.\n[9] Y. Sun and J. Han, \u201cMining heterogeneous information networks: a structural analysis approach,\u201d ACM SIGKDD Explorations Newsletter, vol. 14, no. 2, pp. 20\u201328, 2013.\n[10] C. Shi, X. Kong, Y. Huang, S. Y. Philip, and B. Wu, \u201cHetesim: A general framework for relevance measure in heterogeneous networks,\u201d IEEE Transactions on Knowledge & Data Engineering, no. 10, pp. 2479\u20132492, 2014.\n[11] I. V. Oseledets and G. V. Ovchinnikov, \u201cFast, memory efficient low-rank approximation of simrank,\u201d CoRR, vol. abs/1410.0717, 2014.\n[12] N. Halko, P.-G. Martinsson, and J. A. Tropp, \u201cFinding structure with randomness: Probabilistic algorithms for constructing approximate matrix decompositions,\u201d SIAM review, vol. 53, no. 2, pp. 217\u2013288, 2011.\n[13] J. Bierkens, O. v. Gaans, and S. V. Lunel, \u201cEstimate on the pathwise lyapunov exponent of linear stochastic differential equations with constant coefficients,\u201d Stochastic Analysis and Applications, vol. 28, no. 5, pp. 747\u2013762, 2010.\n[14] C.-N. Ziegler, S. M. McNee, J. A. Konstan, and G. Lausen, \u201cImproving recommendation lists through topic diversification,\u201d in Proceedings of the 14th international conference on World Wide Web, pp. 22\u201332, ACM, 2005."}], "references": [{"title": "The PageRank citation ranking: Bringing order to the web", "author": ["L. Page", "S. Brin", "R. Motwani", "T. Winograd"], "venue": "1999.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 1999}, {"title": "Grouplens: applying collaborative filtering to usenet news", "author": ["J.A. Konstan", "B.N. Miller", "D. Maltz", "J.L. Herlocker", "L.R. Gordon", "J. Riedl"], "venue": "Communications of the ACM, vol. 40, no. 3, pp. 77\u201387, 1997.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 1997}, {"title": "The future of Citeseer: Citeseer X", "author": ["C.L. Giles"], "venue": "Proceedings of the 10th European conference on Principle and Practice of Knowledge Discovery in Databases, pp. 2\u20132, Springer-Verlag, 2006.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2006}, {"title": "Integrative construction and analysis of condition-specific biological networks", "author": ["S. Roy", "T. Lane", "M. Werner-Washburne"], "venue": "Proceedings of the National Conference on Artificial Intelligence, vol. 22, p. 1898, Menlo Park, CA; Cambridge, MA; London; AAAI Press; MIT Press; 1999, 2007.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 1898}, {"title": "Knowledge discovery from transportation network data", "author": ["W. Jiang", "J. Vaidya", "Z. Balaporia", "C. Clifton", "B. Banich"], "venue": "Data Engineering, 2005. ICDE 2005. Proceedings. 21st International Conference on, pp. 1061\u20131072, IEEE, 2005.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2005}, {"title": "Pathrank: Ranking nodes on a heterogeneous graph for flexible hybrid recommender systems", "author": ["S. Lee", "S. Park", "M. Kahng", "S.-g. Lee"], "venue": "Expert Systems with Applications, vol. 40, no. 2, pp. 684\u2013697, 2013.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2013}, {"title": "Simrank: a measure of structural-context similarity", "author": ["G. Jeh", "J. Widom"], "venue": "Proceedings of the eighth ACM SIGKDD international conference on Knowledge discovery and data mining, pp. 538\u2013543, ACM, 2002.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2002}, {"title": "Scaling personalized web search", "author": ["G. Jeh", "J. Widom"], "venue": "Proceedings of the 12th international conference on World Wide Web, pp. 271\u2013279, ACM, 2003.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2003}, {"title": "Mining heterogeneous information networks: a structural analysis approach", "author": ["Y. Sun", "J. Han"], "venue": "ACM SIGKDD Explorations Newsletter, vol. 14, no. 2, pp. 20\u201328, 2013.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2013}, {"title": "Hetesim: A general framework for relevance measure in heterogeneous networks", "author": ["C. Shi", "X. Kong", "Y. Huang", "S.Y. Philip", "B. Wu"], "venue": "IEEE Transactions on Knowledge & Data Engineering, no. 10, pp. 2479\u20132492, 2014.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2014}, {"title": "Fast, memory efficient low-rank approximation of simrank", "author": ["I.V. Oseledets", "G.V. Ovchinnikov"], "venue": "CoRR, vol. abs/1410.0717, 2014.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2014}, {"title": "Finding structure with randomness: Probabilistic algorithms for constructing approximate matrix decompositions", "author": ["N. Halko", "P.-G. Martinsson", "J.A. Tropp"], "venue": "SIAM review, vol. 53, no. 2, pp. 217\u2013288, 2011.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2011}, {"title": "Estimate on the pathwise lyapunov exponent of linear stochastic differential equations with constant coefficients", "author": ["J. Bierkens", "O. v. Gaans", "S.V. Lunel"], "venue": "Stochastic Analysis and Applications, vol. 28, no. 5, pp. 747\u2013762, 2010.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2010}, {"title": "Improving recommendation lists through topic diversification", "author": ["C.-N. Ziegler", "S.M. McNee", "J.A. Konstan", "G. Lausen"], "venue": "Proceedings of the 14th international conference on World Wide Web, pp. 22\u201332, ACM, 2005.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2005}], "referenceMentions": [{"referenceID": 0, "context": "Most data in the modern world can be treated as an information network, thus network node similarity measuring has wide range of applications: search [1], recommendation systems [2], research publication networks analysis [3], biology [4], transportation and logistics [5] and others.", "startOffset": 150, "endOffset": 153}, {"referenceID": 1, "context": "Most data in the modern world can be treated as an information network, thus network node similarity measuring has wide range of applications: search [1], recommendation systems [2], research publication networks analysis [3], biology [4], transportation and logistics [5] and others.", "startOffset": 178, "endOffset": 181}, {"referenceID": 2, "context": "Most data in the modern world can be treated as an information network, thus network node similarity measuring has wide range of applications: search [1], recommendation systems [2], research publication networks analysis [3], biology [4], transportation and logistics [5] and others.", "startOffset": 222, "endOffset": 225}, {"referenceID": 3, "context": "Most data in the modern world can be treated as an information network, thus network node similarity measuring has wide range of applications: search [1], recommendation systems [2], research publication networks analysis [3], biology [4], transportation and logistics [5] and others.", "startOffset": 235, "endOffset": 238}, {"referenceID": 4, "context": "Most data in the modern world can be treated as an information network, thus network node similarity measuring has wide range of applications: search [1], recommendation systems [2], research publication networks analysis [3], biology [4], transportation and logistics [5] and others.", "startOffset": 269, "endOffset": 272}, {"referenceID": 5, "context": "that would reflect the closeness of objects based on \u201dsimilarity of relations\u201d they enter, and at the same time not mixing different relations as soon as \u201dobjects of different types and links carry different semantic meanings, and it does not make sense to mix them to measure the similarity without distinguishing their semantics\u201d [6].", "startOffset": 332, "endOffset": 335}, {"referenceID": 6, "context": "The basic graph structure similarity measure is the classical SimRank [7] over a homogeneous graph G = (V,E) which is defined as follows:", "startOffset": 70, "endOffset": 73}, {"referenceID": 7, "context": "Personalized PageRank [8] is also often used to measure ar X iv :1 50 2.", "startOffset": 22, "endOffset": 25}, {"referenceID": 5, "context": "Another option is PathRank [6] that measures path-similarity between objects a, b picked from the same class A of the heterogeneous information network N given a symmetric meta-path P (set of paths that satisfy composition of relations M1,M2, .", "startOffset": 27, "endOffset": 30}, {"referenceID": 8, "context": "Recently, an approach [9] for building an optimal linear combination of meta-paths has been proposed.", "startOffset": 22, "endOffset": 25}, {"referenceID": 9, "context": "There are several works on measuring similarity between objects from different classes, see, for example, [10].", "startOffset": 106, "endOffset": 110}, {"referenceID": 10, "context": "To achieve better results (see above) on sparse relations we adopted the Low-Rank SimRank approximation [11] that uses Probabilistic Singular Value Decomposition [12] to perform fast approximate projections on low-rank matrix manifold at each step of the iterative process (Algorithm 3).", "startOffset": 104, "endOffset": 108}, {"referenceID": 11, "context": "To achieve better results (see above) on sparse relations we adopted the Low-Rank SimRank approximation [11] that uses Probabilistic Singular Value Decomposition [12] to perform fast approximate projections on low-rank matrix manifold at each step of the iterative process (Algorithm 3).", "startOffset": 162, "endOffset": 166}, {"referenceID": 12, "context": "and a fixed-point iteration converges [13] if: \u2211", "startOffset": 38, "endOffset": 42}, {"referenceID": 13, "context": "The model was run on subsample from the Book-Crossing Dataset [14].", "startOffset": 62, "endOffset": 66}], "year": 2015, "abstractText": "We propose a generalization of SimRank similarity measure for heterogeneous information networks. Given the information network, the intraclass similarity score s(a, b) is high if the set of objects that are related with a and the set of objects that are related with b are pair-wise similar according to all imposed relations.", "creator": "LaTeX with hyperref package"}}}