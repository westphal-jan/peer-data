{"id": "1502.06956", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "24-Feb-2015", "title": "Transformation of basic probability assignments to probabilities based on a new entropy measure", "abstract": "Dempster-Shafer evidence theory is an efficient mathematical tool to deal with uncertain information. In that theory, basic probability assignment (BPA) is the basic element for the expression and inference of uncertainty. Decision-making based on BPA is still an open issue in Dempster-Shafer evidence theory. In this paper, a novel approach of transforming basic probability assignments to probabilities is proposed based on Deng entropy which is a new measure for the uncertainty of BPA. The principle of the proposed method is to minimize the difference of uncertainties involving in the given BPA and obtained probability distribution. Numerical examples are given to show the proposed approach. A basic example can be found in this paper.\n\n\nThe idea behind the proposed approach is to reduce the uncertainty of BPA by adding the following:\n1) by applying some basic mathematical methods (e.g., applying general probability distribution), (2) by applying a common mathematical method (e.g., applying general probability distribution), (3) by applying the common mathematical method (e.g., applying general probability distribution) to find a general probability distribution with general probabilities. This is a technique of using the popular probability distribution (i.e., a general probability distribution), to discover the general probability distribution with a general probability distribution. This is a technique of using the popular probability distribution (i.e., a general probability distribution), to discover the general probability distribution with a general probability distribution. This is a technique of using the popular probability distribution (i.e., a general probability distribution), to find a general probability distribution with a general probability distribution. This is a technique of using the popular probability distribution (i.e., a general probability distribution), to find a general probability distribution with a general probability distribution. This is a technique of using the popular probability distribution (i.e., a general probability distribution), to find a general probability distribution with a general probability distribution. This is a technique of using the popular probability distribution (i.e., a general probability distribution), to find a general probability distribution with a general probability distribution. This is a technique of using the popular probability distribution (i.e., a general probability distribution), to find a general probability distribution with a general probability distribution. This is a technique of using the popular probability distribution (i.e., a general probability distribution), to find a general probability distribution with a general probability distribution. This is a method of using the popular probability distribution (i.e., a general probability distribution), to find a general probability", "histories": [["v1", "Tue, 24 Feb 2015 04:02:00 GMT  (22kb)", "http://arxiv.org/abs/1502.06956v1", "14 pages"]], "COMMENTS": "14 pages", "reviews": [], "SUBJECTS": "cs.AI", "authors": ["xinyang deng", "yong deng"], "accepted": false, "id": "1502.06956"}, "pdf": {"name": "1502.06956.pdf", "metadata": {"source": "CRF", "title": "Transformation of basic probability assignments to probabilities based on a new entropy measure", "authors": ["Xinyang Deng", "Yong Deng"], "emails": ["prof.deng@hotmail.com"], "sections": [{"heading": null, "text": "ar X\niv :1\n50 2.\n06 95\n6v 1\n[ cs\n.A I]\nDempster-Shafer evidence theory is an efficient mathematical tool to deal with uncertain information. In that theory, basic probability assignment (BPA) is the basic element for the expression and inference of uncertainty. Decision-making based on BPA is still an open issue in Dempster-Shafer evidence theory. In this paper, a novel approach of transforming basic probability assignments to probabilities is proposed based on Deng entropy which is a new measure for the uncertainty of BPA. The principle of the proposed method is to minimize the difference of uncertainties involving in the given BPA and obtained probability distribution. Numerical examples are given to show the proposed approach. Keywords: Dempster-Shafer evidence theory, Belief function, Deng entropy, Shannnon entropy, Decision-making\n\u2217Corresponding author: Yong Deng, School of Computer and Information Science, Southwest University, Chongqing, 400715, China.\nEmail address: prof.deng@hotmail.com (Yong Deng)\nPreprint submitted to arXiv.org February 26, 2015"}, {"heading": "1. Introduction", "text": "Dempster-Shafer evidence theory is widely used in many disciplines since it allows to deal with uncertain information. Several familiar branches of its applications includes statistical learning [1, 2, 3], classification and clustering [4, 5, 6, 7], decision making [8, 9, 10], knowledge reasoning [11, 12], risk assessment and evaluation [13, 14, 15], and so forth [16, 17, 18, 19, 20]. In Dempster-Shafer evidence theory, several key research directions continuingly appeal to researcher\u2019s attention, for example, the combination of multiple evidences [21, 22, 23], conflict management [24, 25], generation of basic probability assignment (BPA) [26, 27, 28], and so on [29, 30, 31]. Among these points, decision-making based BPA is a crucial issue to be solved, and it has attracted much attention.\nA lot of works have been done to construct a reasonable model for the decision making based on the BPA [32, 33, 34, 35]. One widely used model is the transferable belief model (TBM) [32], pignistic probabilities are used for decision making in this model. In the TBM, a pignistic probability transformation (PPT) approach has been proposed to bring out probabilities from BPAs. Another well-known probability transformation method is proposed by Barry R. Cobb [36], which is based on the plausibility function. The main idea of the plausibility transformation method is to assign the uncertain according to the plausibility function with normalization. In [37], the semantics and properties of the relative belief transform have been discussed.\nOne method was mentioned namely proportional probability transformation [38]. Within the proportional probability transformation, a belief mass assigned to nonsingleton focal element X is distributed among X \u2019s elements with respect influenced by the proportion of BPAs assigned to singletons. The proportional probability transformation is influenced by the proportion of BPAs assigned to singletons.\nIn this paper, a novel probability transformation approach is proposed based on a new entropy measure of BPAs, Deng entropy [39]. Within the proposed approach, given a BPA, it is expected to find a probability distribution whose Shannon entropy is as close as possible to the entropy of given BPA. The rest of this paper is organized as follows. Section 2 introduces some basic background knowledge. In section 3 the proposed probability transformation approach is presented. Section 4 uses some examples to illustrate the effectiveness of the proposed approach. Conclusion is given in Section 5."}, {"heading": "2. Preliminaries", "text": ""}, {"heading": "2.1. Dempster-Shafer evidence theory", "text": "Dempster-Shafer evidence theory [40, 41], also called Dempster-Shafer theory or evidence theory, is used to deal with uncertain information. As an effective theory of uncertainty reasoning, Dempster-Shafer theory has an advantage of directly expressing various uncertainties. This theory needs weaker conditions than bayesian theory of probability, so it is often regarded\nas an extension of the bayesian theory. For completeness of the explanation, a few basic concepts are introduced as follows.\nDefinition 1. Let \u2126 be a set of mutually exclusive and collectively exhaustive, indicted by\n\u2126 = {E1, E2, \u00b7 \u00b7 \u00b7 , Ei, \u00b7 \u00b7 \u00b7 , EN} (1)\nThe set \u2126 is called frame of discernment. The power set of \u2126 is indicated by 2\u2126, where\n2\u2126 = {\u2205, {E1}, \u00b7 \u00b7 \u00b7 , {EN}, {E1, E2}, \u00b7 \u00b7 \u00b7 , {E1, E2, \u00b7 \u00b7 \u00b7 , Ei}, \u00b7 \u00b7 \u00b7 ,\u2126} (2)\nIf A \u2208 2\u2126, A is called a proposition.\nDefinition 2. For a frame of discernment \u2126, a mass function is a mapping m from 2\u2126 to [0, 1], formally defined by:\nm : 2\u2126 \u2192 [0, 1] (3)\nwhich satisfies the following condition:\nm(\u2205) = 0 and \u2211\nA\u22082\u2126\nm(A) = 1 (4)\nIn Dempster-Shafer theory, a mass function is also called a basic probability assignment (BPA). If m(A) > 0, A is called a focal element, the union of all focal elements is called the core of the mass function.\nDefinition 3. For a proposition A \u2286 \u2126, the belief function Bel : 2\u2126 \u2192 [0, 1] is defined as\nBel(A) = \u2211\nB\u2286A\nm(B) (5)\nThe plausibility function P l : 2\u2126 \u2192 [0, 1] is defined as\nP l(A) = 1\u2212Bel(A\u0304) = \u2211\nB\u2229A 6=\u2205\nm(B) (6)\nwhere A\u0304 = \u2126\u2212A.\nObviously, Bel(A) \u2264 P l(A), these functions Bel and P l are the lower\nlimit function and upper limit function of proposition A, respectively."}, {"heading": "3. Proposed probability transformation approach based on Deng", "text": "entropy\nIn this section, a new measure for the uncertainty of BPA, Deng entropy is introduced first, then a new approach of transforming BPA to probability distribution is proposed based on the concept of Deng entropy."}, {"heading": "3.1. Deng entropy", "text": "Deng entropy [39] is a generalized Shannon entropy to measure uncertainty involving in a BPA. Mathematically, Deng entropy can be presented as follows\nEd = \u2212 \u2211\ni\nm(Fi) log m(Fi)\n2|Fi| \u2212 1 (7)\nwhere, Fi is a proposition in mass function m, and |Fi| is the cardinality of Fi. As shown in the above definition, Deng entropy, formally, is similar with the classical Shannon entropy, but the belief for each proposition Fi is divided by a term (2|Fi| \u2212 1) which represents the potential number of states in Fi (of course, the empty set is not included).\nSpecially, Deng entropy can definitely degenerate to the Shannon entropy\nif the belief is only assigned to single elements. Namely,\nEd = \u2212 \u2211\ni\nm(\u03b8i) log m(\u03b8i)\n2|\u03b8i| \u2212 1 = \u2212\n\u2211\ni\nm(\u03b8i) logm(\u03b8i) (8)"}, {"heading": "3.2. Proposed probability transformation approach", "text": "In our view, a primary principle in the transformation process is to minimize the difference of uncertainties involving in the given BPA and obtained probability distribution. In order to implement such optimization transformation, it must be able to calculate the uncertainty of BPA. Exactly, Deng entropy provides a method to measure the uncertainty of BPA as well as probability distribution. Therefore, a novel probability transformation approach based on Deng entropy can be proposed as follows.\nAssume the frame of discernment is \u2126 = {\u03c91, \u03c92, \u00b7 \u00b7 \u00b7 , \u03c9n}, given a BPA m, a probability distribution P = (p(\u03c91), p(\u03c92), \u00b7 \u00b7 \u00b7 , p(\u03c9n)) associated with m is calculated by solving the following optimization problem:\nmin |Ed(m)\u2212 Ed(P )|\ns.t.\n  \n \nn \u2211\ni\np(\u03c9i) = 1;\nBel(\u03c9i) \u2264 p(\u03c9i) \u2264 P l(\u03c9i), i = 1, \u00b7 \u00b7 \u00b7 , n.\n(9)\nwhere Ed(m) and Ed(P ) are the entropies of BPA m and probability distribution P , respectively."}, {"heading": "4. Numerical examples", "text": "In this section, some illustrative examples are given to show the proposed\nprobability transformation approach.\nExample 1. Given a frame of discernment \u2126 = {\u03c91, \u03c92, \u03c93, \u03c94}, there is\na BPA m(\u03c91, \u03c92, \u03c93, \u03c94) = 1. According to Eqs. (5) and (6),\nBel(\u03c91) = Bel(\u03c92) = Bel(\u03c93) = Bel(\u03c94) = 0, P l(\u03c91) = P l(\u03c92) = P l(\u03c93) = P l(\u03c94) = 1. By using the proposed probability transformation approach, a probability\ndistribution is obtained by\nmin |Ed(m)\u2212 Ed(P )|\ns.t.\n \n\np(\u03c91) + p(\u03c92) + p(\u03c93) + p(\u03c94) = 1 0 \u2264 p(\u03c9i) \u2264 1, i = 1, 2, 3, 4.\nwe can obtain that P : p(\u03c91) = 0.25, p(\u03c92) = 0.25, p(\u03c93) = 0.25, p(\u03c94) = 0.25. The result shows that the transformed probability distribution has the maximum uncertainty (Shannon entropy) when the given BPA is totally unknown (i.e., m(\u2126) = 1).\nExample 2. Given a frame of discernment \u2126 = {\u03c91, \u03c92, \u03c93}, there is a BPA: m(\u03c91) = 0.4, m(\u03c92) = 0.05, m(\u03c93) = 0.1, m(\u03c91, \u03c92) = 0.1, m(\u03c91, \u03c93) = 0.2, m(\u03c91, \u03c92, \u03c93) = 0.15.\nDue toBel(\u03c91) = 0.4, Bel(\u03c92) = 0.05, Bel(\u03c93) = 0.1; P l(\u03c91) = 0.85, P l(\u03c92) =\n0.3, P l(\u03c93) = 0.45, the associated probability distribution can be calculated\nby\nmin |Ed(m)\u2212 Ed(P )|\ns.t.\n       \n       \np(\u03c91) + p(\u03c92) + p(\u03c93) = 1 0.4 \u2264 p(\u03c91) \u2264 0.85 0.05 \u2264 p(\u03c92) \u2264 0.3 0.1 \u2264 p(\u03c93) \u2264 0.45\nSo, we can get P : p(\u03c91) = 0.4, p(\u03c92) = 0.3, p(\u03c93) = 0.3."}, {"heading": "5. Conclusion", "text": "In this paper, the transformation of BPA to probability distribution has been studied. Based on an idea that minimizing the difference of uncertainties involving in the given BPA and obtained probability distribution, a novel probability transformation approach has been proposed. Finally, several illustrative examples have been given to show the proposed method."}, {"heading": "Acknowledgements", "text": "The work is partially supported by China Scholarship Council, National Natural Science Foundation of China (Grant No. 61174022), Specialized Research Fund for the Doctoral Program of Higher Education (Grant No. 20131102130002), R&D Program of China (2012BAH07B01), National High Technology Research and Development Program of China (863 Program) (Grant No. 2013AA013801), the open funding project of State Key Laboratory of Virtual Reality Technology and Systems, Beihang University (Grant\nNo.BUAA-VR-14KF-02), Fundamental Research Funds for the Central Universities (Grant No. XDJK2014D034)."}], "references": [{"title": "A geometric approach to the theory of evidence", "author": ["F. Cuzzolin"], "venue": "Systems, Man, and Cybernetics, Part C: Applications and Reviews, IEEE Transactions on 38 (4) ", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2008}, {"title": "A new decisionmaking method by incomplete preferences based on evidence distance", "author": ["S. Huang", "X. Su", "Y. Hu", "S. Mahadevan", "Y. Deng"], "venue": "Knowledge-Based Systems 56 ", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2014}, {"title": "A novel approximation of basic probability assignment based on rank-level fusion", "author": ["Y. Yang", "D. Han", "C. Han", "F. Cao"], "venue": "Chinese Journal of Aeronautics 26 (4) ", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2013}, {"title": "A k-nearest neighbor classification rule based on dempstershafer theory", "author": ["T. Denoeux"], "venue": "Systems, Man and Cybernetics, IEEE Transactions on 25 (5) ", "citeRegEx": "4", "shortCiteRegEx": null, "year": 1995}, {"title": "A neural network classifier based on dempster-shafer theory", "author": ["T. Denoeux"], "venue": "Systems, Man and Cybernetics, Part A: Systems and Humans, IEEE Transactions on 30 (2) ", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2000}, {"title": "Ecm: An evidential version of the fuzzy c-means algorithm", "author": ["M.-H. Masson", "T. Denoeux"], "venue": "Pattern Recognition 41 (4) ", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2008}, {"title": "Evidential classifier for imprecise data based on belief functions, Knowledge-Based Systems", "author": ["Z.-g. Liu", "Q. Pan", "J. Dezert"], "venue": null, "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2013}, {"title": "Quantifying influence of weather indices on pm based on relation map", "author": ["J. Liu", "Y. Li", "R. Sadiq", "Y. Deng"], "venue": "Stochastic Environmental Research and Risk Assessment 28 (6) ", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2014}, {"title": "The use of ordered weighted averaging method for decision making under uncertainty", "author": ["B.S. Ahn", "R.R. Yager"], "venue": "International Transactions in Operational Research 21 (2) ", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2014}, {"title": "Induced ordered weighted evidential reasoning approach for multiple attribute decision analysis with uncertainty", "author": ["S. Yao", "W.-Q. Huang"], "venue": "International Journal of Intelligent Systems 29 (10) ", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2014}, {"title": "Evidential cognitive maps", "author": ["B. Kang", "Y. Deng", "R. Sadiq", "S. Mahadevan"], "venue": "Knowledge-Based Systems 35 ", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2012}, {"title": "Maximum likelihood estimation from uncertain data in the belief function framework", "author": ["T. Denoeux"], "venue": "Knowledge and Data Engineering, IEEE Transactions on 25 (1) ", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2013}, {"title": "Ifsjsp: A novel methodology for the job-shop scheduling problem based on intuitionistic fuzzy sets", "author": ["X. Zhang", "Y. Deng", "F.T. Chan", "P. Xu", "S. Mahadevan", "Y. Hu"], "venue": "International Journal of Production Research 51 (17) ", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2013}, {"title": "Supplier selection using AHP methodology extended by D numbers", "author": ["X. Deng", "Y. Hu", "Y. Deng", "S. Mahadevan"], "venue": "Expert Systems with Applications 41 (1) ", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2014}, {"title": "On characterizing features of owa aggregation operators", "author": ["R.R. Yager", "N. Alajlan"], "venue": "Fuzzy Optimization and Decision Making 13 (1) ", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2014}, {"title": "Fuzzy sensor fusion based on evidence theory and its application", "author": ["S. Chen", "Y. Deng", "J. Wu"], "venue": "Applied Artificial Intelligence 27 (3) ", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2013}, {"title": "Environmental impact assessment based on D numbers", "author": ["X. Deng", "Y. Hu", "Y. Deng", "S. Mahadevan"], "venue": "Expert Systems with Applications 41 (2) ", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2014}, {"title": "A new method to determine basic probability assignment using core samples", "author": ["C. Zhang", "Y. Hu", "F.T. Chan", "R. Sadiq", "Y. Deng"], "venue": "Knowledge- Based Systems 69 ", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2014}, {"title": "Probabilistically weighted owa aggregation", "author": ["R.R. Yager", "N. Alajlan"], "venue": "IEEE Transactions on Fuzzy Systems 22 (1) ", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2014}, {"title": "Parameter estimation based on interval-valued belief structures", "author": ["X. Deng", "Y. Hu", "F.T. Chan", "S. Mahadevan", "Y. Deng"], "venue": "European Journal of Operational Research 241 (2) ", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2015}, {"title": "Combining belief functions when evidence conflicts", "author": ["C.K. Murphy"], "venue": "Decision support systems 29 (1) ", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2000}, {"title": "How to preserve the conflict as an alarm in the combination of belief functions", "author": ["E. Lef\u00e8vre", "Z. Elouedi"], "venue": "Decision Support Systems 56 ", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2013}, {"title": "An improved operator of combination with adapted conflict", "author": ["X. Deng", "Y. Deng", "F.T. Chan"], "venue": "Annals of Operations Research 223 (1) ", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2014}, {"title": "Analyzing the degree of conflict among belief functions", "author": ["W. Liu"], "venue": "Artificial Intelligence 170 (11) ", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2006}, {"title": "Conflict management in Dempster-Shafer theory using the degree of falsity", "author": ["J. Schubert"], "venue": "International Journal of Approximate Reasoning 52 (3) ", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2011}, {"title": "A non-parametric method to determine basic probability assignment for classification problems", "author": ["P. Xu", "X. Su", "S. Mahadevan", "C. Li", "Y. Deng"], "venue": "Applied Intelligence 41 (3) ", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2014}, {"title": "A new method to determine basic probability assignment using core samples", "author": ["C. Zhang", "Y. Hu", "F.T. Chan", "R. Sadiq", "Y. Deng"], "venue": "Knowledgebased Systems 69 ", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2014}, {"title": "A new method to determine basic probability assignment from training data", "author": ["P. Xu", "Y. Deng", "X. Su", "S. Mahadevan"], "venue": "Knowledge-Based Systems 46 ", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2013}, {"title": "On the persistence of income shocks over the life cycle: Evidence", "author": ["F. Karahan", "S. Ozkan"], "venue": "theory, and implications, Review of Economic Dynamics 16 (3) ", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2013}, {"title": "A multistep methodology for the evaluation of human resources using the evidence theory", "author": ["A. Certa", "M. Enea", "G.M. Galante", "C.M. La Fata"], "venue": "International Journal of Intelligent Systems 28 (11) ", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2013}, {"title": "A response surface approach for structural reliability analysis using evidence theory", "author": ["Z. Zhang", "C. Jiang", "X. Han", "D. Hu", "S. Yu"], "venue": "Advances in Engineering Software 69 ", "citeRegEx": "31", "shortCiteRegEx": null, "year": 2014}, {"title": "The transferable belief model", "author": ["P. Smets", "R. Kennes"], "venue": "Artificial intelligence 66 (2) ", "citeRegEx": "32", "shortCiteRegEx": null, "year": 1994}, {"title": "Decision making in the tbm: the necessity of the pignistic transformation", "author": ["P. Smets"], "venue": "International Journal of Approximate Reasoning 38 (2) ", "citeRegEx": "33", "shortCiteRegEx": null, "year": 2005}, {"title": "Decision making with dempster-shafer theory using fuzzy induced aggregation operators", "author": ["J.M. Merig\u00f3", "M. Casanovas"], "venue": "in: Recent developments in the ordered weighted averaging operators: Theory and practice, Springer", "citeRegEx": "34", "shortCiteRegEx": null, "year": 2011}, {"title": "A descriptive decision-making model under uncertainty: combination of dempster-shafer theory and prospect theory", "author": ["E. Nusrat", "K. Yamada"], "venue": "International Journal of Uncertainty, Fuzziness and Knowledge-Based Systems 21 (01) ", "citeRegEx": "35", "shortCiteRegEx": null, "year": 2013}, {"title": "On the plausibility transformation method for translating belief function models to probability models", "author": ["B.R. Cobb", "P.P. Shenoy"], "venue": "International Journal of Approximate Reasoning 41 (3) ", "citeRegEx": "36", "shortCiteRegEx": null, "year": 2006}, {"title": "On the relative belief transform", "author": ["F. Cuzzolin"], "venue": "International Journal of Approximate Reasoning 53 (5) ", "citeRegEx": "37", "shortCiteRegEx": null, "year": 2012}, {"title": "On transformations of belief functions to probabilities", "author": ["M. Daniel"], "venue": "International Journal of Intelligent Systems 21 (3) ", "citeRegEx": "38", "shortCiteRegEx": null, "year": 2006}, {"title": "Deng entropy: a generalized shannon entropy to measure uncertainty", "author": ["Y. Deng"], "venue": "arXiv.org ", "citeRegEx": "39", "shortCiteRegEx": null, "year": 2015}, {"title": "Upper and lower probabilities induced by a multivalued mapping", "author": ["A.P. Dempster"], "venue": "The annals of mathematical statistics 38 (2) ", "citeRegEx": "40", "shortCiteRegEx": null, "year": 1967}, {"title": "A mathematical theory of evidence", "author": ["G. Shafer"], "venue": "Princeton university press Princeton", "citeRegEx": "41", "shortCiteRegEx": null, "year": 1976}], "referenceMentions": [{"referenceID": 0, "context": "Several familiar branches of its applications includes statistical learning [1, 2, 3], classification and clustering [4, 5, 6, 7], decision making [8, 9, 10], knowledge reasoning [11, 12], risk assessment and evaluation [13, 14, 15], and so forth [16, 17, 18, 19, 20].", "startOffset": 76, "endOffset": 85}, {"referenceID": 1, "context": "Several familiar branches of its applications includes statistical learning [1, 2, 3], classification and clustering [4, 5, 6, 7], decision making [8, 9, 10], knowledge reasoning [11, 12], risk assessment and evaluation [13, 14, 15], and so forth [16, 17, 18, 19, 20].", "startOffset": 76, "endOffset": 85}, {"referenceID": 2, "context": "Several familiar branches of its applications includes statistical learning [1, 2, 3], classification and clustering [4, 5, 6, 7], decision making [8, 9, 10], knowledge reasoning [11, 12], risk assessment and evaluation [13, 14, 15], and so forth [16, 17, 18, 19, 20].", "startOffset": 76, "endOffset": 85}, {"referenceID": 3, "context": "Several familiar branches of its applications includes statistical learning [1, 2, 3], classification and clustering [4, 5, 6, 7], decision making [8, 9, 10], knowledge reasoning [11, 12], risk assessment and evaluation [13, 14, 15], and so forth [16, 17, 18, 19, 20].", "startOffset": 117, "endOffset": 129}, {"referenceID": 4, "context": "Several familiar branches of its applications includes statistical learning [1, 2, 3], classification and clustering [4, 5, 6, 7], decision making [8, 9, 10], knowledge reasoning [11, 12], risk assessment and evaluation [13, 14, 15], and so forth [16, 17, 18, 19, 20].", "startOffset": 117, "endOffset": 129}, {"referenceID": 5, "context": "Several familiar branches of its applications includes statistical learning [1, 2, 3], classification and clustering [4, 5, 6, 7], decision making [8, 9, 10], knowledge reasoning [11, 12], risk assessment and evaluation [13, 14, 15], and so forth [16, 17, 18, 19, 20].", "startOffset": 117, "endOffset": 129}, {"referenceID": 6, "context": "Several familiar branches of its applications includes statistical learning [1, 2, 3], classification and clustering [4, 5, 6, 7], decision making [8, 9, 10], knowledge reasoning [11, 12], risk assessment and evaluation [13, 14, 15], and so forth [16, 17, 18, 19, 20].", "startOffset": 117, "endOffset": 129}, {"referenceID": 7, "context": "Several familiar branches of its applications includes statistical learning [1, 2, 3], classification and clustering [4, 5, 6, 7], decision making [8, 9, 10], knowledge reasoning [11, 12], risk assessment and evaluation [13, 14, 15], and so forth [16, 17, 18, 19, 20].", "startOffset": 147, "endOffset": 157}, {"referenceID": 8, "context": "Several familiar branches of its applications includes statistical learning [1, 2, 3], classification and clustering [4, 5, 6, 7], decision making [8, 9, 10], knowledge reasoning [11, 12], risk assessment and evaluation [13, 14, 15], and so forth [16, 17, 18, 19, 20].", "startOffset": 147, "endOffset": 157}, {"referenceID": 9, "context": "Several familiar branches of its applications includes statistical learning [1, 2, 3], classification and clustering [4, 5, 6, 7], decision making [8, 9, 10], knowledge reasoning [11, 12], risk assessment and evaluation [13, 14, 15], and so forth [16, 17, 18, 19, 20].", "startOffset": 147, "endOffset": 157}, {"referenceID": 10, "context": "Several familiar branches of its applications includes statistical learning [1, 2, 3], classification and clustering [4, 5, 6, 7], decision making [8, 9, 10], knowledge reasoning [11, 12], risk assessment and evaluation [13, 14, 15], and so forth [16, 17, 18, 19, 20].", "startOffset": 179, "endOffset": 187}, {"referenceID": 11, "context": "Several familiar branches of its applications includes statistical learning [1, 2, 3], classification and clustering [4, 5, 6, 7], decision making [8, 9, 10], knowledge reasoning [11, 12], risk assessment and evaluation [13, 14, 15], and so forth [16, 17, 18, 19, 20].", "startOffset": 179, "endOffset": 187}, {"referenceID": 12, "context": "Several familiar branches of its applications includes statistical learning [1, 2, 3], classification and clustering [4, 5, 6, 7], decision making [8, 9, 10], knowledge reasoning [11, 12], risk assessment and evaluation [13, 14, 15], and so forth [16, 17, 18, 19, 20].", "startOffset": 220, "endOffset": 232}, {"referenceID": 13, "context": "Several familiar branches of its applications includes statistical learning [1, 2, 3], classification and clustering [4, 5, 6, 7], decision making [8, 9, 10], knowledge reasoning [11, 12], risk assessment and evaluation [13, 14, 15], and so forth [16, 17, 18, 19, 20].", "startOffset": 220, "endOffset": 232}, {"referenceID": 14, "context": "Several familiar branches of its applications includes statistical learning [1, 2, 3], classification and clustering [4, 5, 6, 7], decision making [8, 9, 10], knowledge reasoning [11, 12], risk assessment and evaluation [13, 14, 15], and so forth [16, 17, 18, 19, 20].", "startOffset": 220, "endOffset": 232}, {"referenceID": 15, "context": "Several familiar branches of its applications includes statistical learning [1, 2, 3], classification and clustering [4, 5, 6, 7], decision making [8, 9, 10], knowledge reasoning [11, 12], risk assessment and evaluation [13, 14, 15], and so forth [16, 17, 18, 19, 20].", "startOffset": 247, "endOffset": 267}, {"referenceID": 16, "context": "Several familiar branches of its applications includes statistical learning [1, 2, 3], classification and clustering [4, 5, 6, 7], decision making [8, 9, 10], knowledge reasoning [11, 12], risk assessment and evaluation [13, 14, 15], and so forth [16, 17, 18, 19, 20].", "startOffset": 247, "endOffset": 267}, {"referenceID": 17, "context": "Several familiar branches of its applications includes statistical learning [1, 2, 3], classification and clustering [4, 5, 6, 7], decision making [8, 9, 10], knowledge reasoning [11, 12], risk assessment and evaluation [13, 14, 15], and so forth [16, 17, 18, 19, 20].", "startOffset": 247, "endOffset": 267}, {"referenceID": 18, "context": "Several familiar branches of its applications includes statistical learning [1, 2, 3], classification and clustering [4, 5, 6, 7], decision making [8, 9, 10], knowledge reasoning [11, 12], risk assessment and evaluation [13, 14, 15], and so forth [16, 17, 18, 19, 20].", "startOffset": 247, "endOffset": 267}, {"referenceID": 19, "context": "Several familiar branches of its applications includes statistical learning [1, 2, 3], classification and clustering [4, 5, 6, 7], decision making [8, 9, 10], knowledge reasoning [11, 12], risk assessment and evaluation [13, 14, 15], and so forth [16, 17, 18, 19, 20].", "startOffset": 247, "endOffset": 267}, {"referenceID": 20, "context": "In Dempster-Shafer evidence theory, several key research directions continuingly appeal to researcher\u2019s attention, for example, the combination of multiple evidences [21, 22, 23], conflict management [24, 25], generation of basic probability assignment (BPA) [26, 27, 28], and so on [29, 30, 31].", "startOffset": 166, "endOffset": 178}, {"referenceID": 21, "context": "In Dempster-Shafer evidence theory, several key research directions continuingly appeal to researcher\u2019s attention, for example, the combination of multiple evidences [21, 22, 23], conflict management [24, 25], generation of basic probability assignment (BPA) [26, 27, 28], and so on [29, 30, 31].", "startOffset": 166, "endOffset": 178}, {"referenceID": 22, "context": "In Dempster-Shafer evidence theory, several key research directions continuingly appeal to researcher\u2019s attention, for example, the combination of multiple evidences [21, 22, 23], conflict management [24, 25], generation of basic probability assignment (BPA) [26, 27, 28], and so on [29, 30, 31].", "startOffset": 166, "endOffset": 178}, {"referenceID": 23, "context": "In Dempster-Shafer evidence theory, several key research directions continuingly appeal to researcher\u2019s attention, for example, the combination of multiple evidences [21, 22, 23], conflict management [24, 25], generation of basic probability assignment (BPA) [26, 27, 28], and so on [29, 30, 31].", "startOffset": 200, "endOffset": 208}, {"referenceID": 24, "context": "In Dempster-Shafer evidence theory, several key research directions continuingly appeal to researcher\u2019s attention, for example, the combination of multiple evidences [21, 22, 23], conflict management [24, 25], generation of basic probability assignment (BPA) [26, 27, 28], and so on [29, 30, 31].", "startOffset": 200, "endOffset": 208}, {"referenceID": 25, "context": "In Dempster-Shafer evidence theory, several key research directions continuingly appeal to researcher\u2019s attention, for example, the combination of multiple evidences [21, 22, 23], conflict management [24, 25], generation of basic probability assignment (BPA) [26, 27, 28], and so on [29, 30, 31].", "startOffset": 259, "endOffset": 271}, {"referenceID": 26, "context": "In Dempster-Shafer evidence theory, several key research directions continuingly appeal to researcher\u2019s attention, for example, the combination of multiple evidences [21, 22, 23], conflict management [24, 25], generation of basic probability assignment (BPA) [26, 27, 28], and so on [29, 30, 31].", "startOffset": 259, "endOffset": 271}, {"referenceID": 27, "context": "In Dempster-Shafer evidence theory, several key research directions continuingly appeal to researcher\u2019s attention, for example, the combination of multiple evidences [21, 22, 23], conflict management [24, 25], generation of basic probability assignment (BPA) [26, 27, 28], and so on [29, 30, 31].", "startOffset": 259, "endOffset": 271}, {"referenceID": 28, "context": "In Dempster-Shafer evidence theory, several key research directions continuingly appeal to researcher\u2019s attention, for example, the combination of multiple evidences [21, 22, 23], conflict management [24, 25], generation of basic probability assignment (BPA) [26, 27, 28], and so on [29, 30, 31].", "startOffset": 283, "endOffset": 295}, {"referenceID": 29, "context": "In Dempster-Shafer evidence theory, several key research directions continuingly appeal to researcher\u2019s attention, for example, the combination of multiple evidences [21, 22, 23], conflict management [24, 25], generation of basic probability assignment (BPA) [26, 27, 28], and so on [29, 30, 31].", "startOffset": 283, "endOffset": 295}, {"referenceID": 30, "context": "In Dempster-Shafer evidence theory, several key research directions continuingly appeal to researcher\u2019s attention, for example, the combination of multiple evidences [21, 22, 23], conflict management [24, 25], generation of basic probability assignment (BPA) [26, 27, 28], and so on [29, 30, 31].", "startOffset": 283, "endOffset": 295}, {"referenceID": 31, "context": "A lot of works have been done to construct a reasonable model for the decision making based on the BPA [32, 33, 34, 35].", "startOffset": 103, "endOffset": 119}, {"referenceID": 32, "context": "A lot of works have been done to construct a reasonable model for the decision making based on the BPA [32, 33, 34, 35].", "startOffset": 103, "endOffset": 119}, {"referenceID": 33, "context": "A lot of works have been done to construct a reasonable model for the decision making based on the BPA [32, 33, 34, 35].", "startOffset": 103, "endOffset": 119}, {"referenceID": 34, "context": "A lot of works have been done to construct a reasonable model for the decision making based on the BPA [32, 33, 34, 35].", "startOffset": 103, "endOffset": 119}, {"referenceID": 31, "context": "One widely used model is the transferable belief model (TBM) [32], pignistic probabilities are used for decision making in this model.", "startOffset": 61, "endOffset": 65}, {"referenceID": 35, "context": "Cobb [36], which is based on the plausibility function.", "startOffset": 5, "endOffset": 9}, {"referenceID": 36, "context": "In [37], the semantics and properties of the relative belief transform have been discussed.", "startOffset": 3, "endOffset": 7}, {"referenceID": 37, "context": "One method was mentioned namely proportional probability transformation [38].", "startOffset": 72, "endOffset": 76}, {"referenceID": 38, "context": "In this paper, a novel probability transformation approach is proposed based on a new entropy measure of BPAs, Deng entropy [39].", "startOffset": 124, "endOffset": 128}, {"referenceID": 39, "context": "Dempster-Shafer evidence theory Dempster-Shafer evidence theory [40, 41], also called Dempster-Shafer theory or evidence theory, is used to deal with uncertain information.", "startOffset": 64, "endOffset": 72}, {"referenceID": 40, "context": "Dempster-Shafer evidence theory Dempster-Shafer evidence theory [40, 41], also called Dempster-Shafer theory or evidence theory, is used to deal with uncertain information.", "startOffset": 64, "endOffset": 72}, {"referenceID": 0, "context": "For a frame of discernment \u03a9, a mass function is a mapping m from 2 to [0, 1], formally defined by: m : 2 \u2192 [0, 1] (3) which satisfies the following condition: m(\u2205) = 0 and \u2211", "startOffset": 71, "endOffset": 77}, {"referenceID": 0, "context": "For a frame of discernment \u03a9, a mass function is a mapping m from 2 to [0, 1], formally defined by: m : 2 \u2192 [0, 1] (3) which satisfies the following condition: m(\u2205) = 0 and \u2211", "startOffset": 108, "endOffset": 114}, {"referenceID": 0, "context": "For a proposition A \u2286 \u03a9, the belief function Bel : 2 \u2192 [0, 1] is defined as Bel(A) = \u2211", "startOffset": 55, "endOffset": 61}, {"referenceID": 0, "context": "The plausibility function P l : 2 \u2192 [0, 1] is defined as", "startOffset": 36, "endOffset": 42}, {"referenceID": 38, "context": "Deng entropy Deng entropy [39] is a generalized Shannon entropy to measure uncertainty involving in a BPA.", "startOffset": 26, "endOffset": 30}], "year": 2015, "abstractText": "Dempster-Shafer evidence theory is an efficient mathematical tool to deal with uncertain information. In that theory, basic probability assignment (BPA) is the basic element for the expression and inference of uncertainty. Decision-making based on BPA is still an open issue in Dempster-Shafer evidence theory. In this paper, a novel approach of transforming basic probability assignments to probabilities is proposed based on Deng entropy which is a new measure for the uncertainty of BPA. The principle of the proposed method is to minimize the difference of uncertainties involving in the given BPA and obtained probability distribution. Numerical examples are given to show the proposed approach.", "creator": "LaTeX with hyperref package"}}}