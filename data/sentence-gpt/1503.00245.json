{"id": "1503.00245", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "1-Mar-2015", "title": "Novel Metaknowledge-based Processing Technique for Multimedia Big Data clustering challenges", "abstract": "Past research has challenged us with the task of showing relational patterns between text-based data and then clustering for predictive analysis using Golay Code technique. We focus on a novel approach to extract metaknowledge in multimedia datasets. Our collaboration has been an on-going task of studying the relational patterns between datapoints based on metafeatures extracted from metaknowledge in multimedia datasets.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "histories": [["v1", "Sun, 1 Mar 2015 09:53:15 GMT  (748kb)", "http://arxiv.org/abs/1503.00245v1", "IEEE Multimedia Big Data (BigMM 2015)"]], "COMMENTS": "IEEE Multimedia Big Data (BigMM 2015)", "reviews": [], "SUBJECTS": "cs.DB cs.AI", "authors": ["nima bari", "roman vichr", "kamran kowsari", "simon y berkovich"], "accepted": false, "id": "1503.00245"}, "pdf": {"name": "1503.00245.pdf", "metadata": {"source": "CRF", "title": "Novel Metaknowledge-based Processing Technique for Multimedia Big Data clustering challenges", "authors": ["Nima Bari", "Kamran Kowsari"], "emails": ["nbari@gwu.edu", "Roman.vichr@exprentis.com", "Kowsari@gwu.edu", "Berkov@gwu.edu"], "sections": [{"heading": null, "text": "showing relational patterns between text-based data and then clustering for predictive analysis using Golay Code technique. We focus on a novel approach to extract metaknowledge in multimedia datasets. Our collaboration has been an on-going task of studying the relational patterns between datapoints based on metafeatures extracted from metaknowledge in multimedia datasets. Those selected are significant to suit the mining technique we applied, Golay Code algorithm. In this research paper we summarize findings in optimization of metaknowledge representation for 23-bit representation of structured and unstructured multimedia data in order to be processed in 23-bit Golay Code for cluster recognition.\nKeywords\u2014 Big Multimedia Data Processing and Analytics; Information Retrieval Challenges; Content Identification, Metafeature Extraction and Selection; Metalearning System; 23-Bit Meta-knowledge template; Knowledge Discovery, Golay Code.\nI. INTRODUCTION\nThe latest focus of Big Data Analytics has been centered on content extraction and knowledge discovery [1], [4], [5]. We\u2019ve done research developing the 23-bit metaknowledge template for Big Data clustering using mining and cluster techniques to confront the phenomena of Big Data. Our current research focuses on definition of datacube that is representative of data - each dimension of the cube - which can exceed 2 and even 3 dimensions - is an attribute of the data. This can theoretically allow us to converge specific datapoint as a result of an intended analysis. The 23-question Golay code template gives us a multi-dimensional platform for convergence towards predictive analysis.\nII. BIG MULTIMEDIA DATA CHALLENGES\nData retrieval from entities for the purpose of mining and analysis can prove difficult and is one of the challenging aspects of multimedia data clustering. Just as Osmar R. Zaiane and his collaborators explained utilizing the web to obtain data via crawling, such is the case then and now as a means for extracting the large amounts of data to create subrepositories as a means of testing our hypotheses and theories.\n[1] The authors of the Unified Framework for Representation, Analysis of Multimedia Content for Correlation and Prediction [3], Paul and Singh, highlighted some general challenges, which prove true when approaching any analysis of Big Data and especially Multimedia Big Data. First we must provide a structure where the multimedia data will be housed and represented effectively, i.e. prior to extracting any metaknowledge data. Next, given the amorphous nature of the data, we must consider both its multi-dimensional nature and conclude how to utilize the variety of attributes, have them coincide, and then apply methodologies [3].\nIII. METAKNOWLEDGE PROCESSING FOR MULTIMEDIA BIG DATA\nIn our case selection of a concept benefitting the Golay algorithm, building the datacube is critical. Our task is rather simplified by using the proposed 23-questions metadata template. It allows us to determine significant data points according to 23 predetermined attributes and then cluster the set using Golay Coding [2]. Data is first subjected to our method of metafeature extraction in order to formulate an ontology. The ontology [6] allows us to represent interdependencies within one or more entities, therefore allowing for an unbroken collaborative approach. There are several challenges. The first challenge was to determine the specific classification algorithms applicable for our proposed ontology as noted in [7].\nIV. METHODOLOGY OF CONSTRUCTING AN INPUT\nThe methodology of extracting and deriving the datacube of metaknowledge representation is accomplished through statistical approach and methodology applied to structured data, while semantic methodology is applied to unstructured big data. In both cases, the layer of metaknowledge is constructed as the input Golay Code algorithm. This input is mapped into a representation of 23 bits (binary attribute vector) to create a hash value of index prior to processing by the code itself (Figure 1.). The Golay code processing includes\nimplementation of fuzzy based on Hamming Distance (HD) [17]. The Golay code guarantees linear processing time (O(n)) to build a hash table of indices and constant time (O(1)) for indices access (Figure1.). The attribute labeling No.1\u2026No.23 is just a symbolic one and can represent Yes/No question or a presence of semantic element. In both cases it is then converted into binary representation of 0/1 (Figure 2.).\nThe result of the Golay code index lookup is represented by assigning a cluster label to the media record (the Golay code assigns only two label possibilities).\nV. (MULTIMEDIA) METAKNOWLEDGE REPRESENTATION AND STRUCTURED DATA\nWe applied our methodology to improve the extraction of metaknowledge representation from structured data, prior to applying the same to unstructured multimedia data. The classification algorithms we used are summarized in the table below, Table 1.\nDecision trees were very effective in the validation of selecting metaknowledge attributes used to represent the bits of 23-bit record. DMRT was useful to derive threshold in metaknowledge single attribute representations.\nThe sequence of algorithms applied provides guidance to determine appropriateness and strength of metaknowledge [13], [14]. It also helps with assertions about values (thresholds of boundaries) of meta-feature template questions. These questions (as bits 1\u201323) are to be used as a foundation to represent the extracted metaknowledge in binary 23-bit word on the input of Golay Code processing.\nThe main advantage of this approach is to embed in processing a greedy loopback to minimize the error of given algorithms. For example, given GLM, then the AUC ( value minimization is the target of deriving subset of metaknowledge attributes that process can be embedded into greedy algorithm processing.\nVI. (MULTIMEDIA) METAKNOWLEDGE REPRESENTATION -"}, {"heading": "SEMANTIC ONTOLOGY (UNSTRUCTURED DATA)", "text": "Applying the same methodology (described in V. Section) on unstructured data of multimedia file (in our collection html, .pdf, .jpg, .tiff) is much less effective as no structured data attributes with specific degrees of freedom are represented or easily extracted to construct datacubes. As Prof. Wen Gao from Peking University described in [17], text mining, which contains a lot of semantic information can contribute significantly on the retrieval process for content-based multimedia data such as video and audio. Therefore, naturally, we formulated a process to derive such metaknowledge utilizing semantic knowledge, so that multimedia can be categorized. In order to do that, a more generic characterization is done, i.e. not based on specific data value representations. It is based on the knowledge contained in the media file represented semantically. This turns out to be a more effective and accurate way to be useful in Golay Code\nprocessing when applied to multimedia file, and consequently applied to Big Data.\nIn order to test a solution to represent metaknowledge using semantic characterization of source files (hmtl, ms word, .pdf, .jpeg, etc.), we created a sample collection based on files obtained from [8], which is focused on the financial industry. It was easier to utilize the financial industry definition in terms of semantic structure and phrases.\nFirst the semantic and generic definition was derived (see in Figure 3.) with the intent to define each semantic element as a [Yes/No] answer (per template for structured data) to be represented as binary for Golay Code processing. Therefore each file identified as having a semantic element match in its content or not in order to construct the datacube of metaknowledge. Such semantic element presence is then scored as 1 for present and 0 for not present and consequently processed with Golay Code.\nThe order of attributes within the datacube corresponds to the order of the most generic semantic elements to be placed first on the 23 bit record, followed by the most important ones to distinguish the records in clusters. In this case, we mean the first corresponds to the lowest bits of the 23bit input Golay Code record.\nVII. GOLAY CODE PROCESSING STRUCTURED DATA\nThe discovered metaknowledge was applied to the structured data of movie IMDB records [16] and those were consequently processed with Golay Code algorithm and assigned cluster label1 or label2. The best results in terms of TPR (True Positive Rate) were obtained at HD=5, in Table 3. We then focused on optimization of metaknowledge attributes in Golay Code record to improve Specificity (SPC) and Positive Predictive Value (PPV), which was accomplished. and summarized in Table 4. The Accuracy (ACC) did not change dramatically in both cases.\nBased on these result the confusion matrix [10] for structured data is represented in Table 3 (Hamming Distance = 5) and Table 4 ((Hamming Distance = 6).\nAs Table 4. shows, the focus to enhace metaknowledge attributes to increase SPC (Specificity) lead to a drop in TPR (True Positive Rate), because of the drop in True Positives (TP) , but there was a significantly lower number of False Positives (FP). This was accomplished through the optimization of attributes into the metaknowledge datacube by placing the most significant metaknowledge attributes on the lowest bits of Golay code record input. At the same time we removed attributes duplicating the metaknowledge. The experiments show that the optimal HD (Hamming Distance) to produce the best outcomes of clustering is with HD=4 and even better with HD=5.\nVIII. GOLAY CODE PROCESSING UNSTRUCTURED DATA\nAs we applied the process depicted in Figure 3 , we produced semantic ontology metaknowledge representation of media unstructured records. The 23 bit record was constructed in such a way, that the lowest bits had generic semantic elements followed by the most distinct semantic element values. This is reflected in Table 5 (Run1). In this case the results were best for Hamming Distance (HD) = 2. An ideal result with True Positive Rate (TPR) = 1, i.e. all records were correctly clustered. Therefore for HD=2, Specificity (SPC) =1 , Positive Predictive Value (PPV) =1 and Accuracy (ACC) also 1. All these terms refer to confusion matrix [15].\nSince the semantic metaknowledge is very concrete and specific, we obtained more accurate outcome of Golay Code clustering with smaller HD value (in this case HD=2, Run1 per Table 5.), rather than large HD valule.\nIn several subsequent runs, the order of the semantic metaknowlege attributes in 23-bit input representation was changed to understand better the impact on the final cluster assessment. Inaccurately assessed semantic metaknowledge has to be compensated for by increasing HD value. This case is demonstrated in results in Table 6. (Especially, the comparison of results per HD=2 and HD=4.). However, Specificity (SPC) drops to zero. An increase to HD=6 does not bring improvement in results.\nIX. CONCLUSION AND FUTURE WORK\nOur experiments were performed with extracted metaknowledge on structured and unstructured data to which\nwe\u2019re applying Golay Code to categorize by label into cluster of records. Our approach had to be modified for media files to identify a proper metaknowledge, and therefore we introduced metaknowledge representation based on semantic ontology.\nThe experiments with unstructured data (media file) results\nshow that an approach using ontology based meta-knowledge to process multimedia for clustering using Golay Code algorithm is a beneficial one. This is very useful in case of big data of media collections given the Golay code processing properties. Our next research will also be focused into looking to utilize semantically driven metaknowledge attributes in order to dynamically derive processing rules, since the rules outcome can be defined as Yes/No (or True/False) outcome."}], "references": [{"title": "Mining multimedia data.\" Proceedings of the 1998 conference of the Centre for Advanced Studies on Collaborative research", "author": ["Za\u00efane", "Osmar R"], "venue": null, "citeRegEx": "1", "shortCiteRegEx": "1", "year": 1998}, {"title": "Challenges facing researchers using multimedia data: Tools for layering significance.", "author": ["Goldman-Segall", "Ricki"], "venue": "ACM SIGGRAPH Computer Graphics", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 1994}, {"title": "Unified framework for representation, analysis of multimedia content for correlation and prediction.", "author": ["Paul", "S. Nissi", "Y. Jayanta Singh"], "venue": "Emerging Trends and Applications in Computer Science (ICETACS),", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2013}, {"title": "Mediaprinting: Identifying multimedia content for digital rights management.", "author": ["Huang", "Tiejun", "Yonghong Tian", "Wen Gao", "Jian Lu"], "venue": null, "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2007}, {"title": "Clustering-based binary-class classification for imbalanced data sets.", "author": ["Chen", "Chao", "Mei-Ling Shyu"], "venue": "In Information Reuse and Integration (IRI),", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2011}, {"title": "Organization of Meta-knowledge in the Form of 23-bit Templates for Big Data Processing.\" In Computing for Geospatial Research and Application (COM", "author": ["Bari", "Nima", "Duoduo Liao", "Simon Berkovich"], "venue": "Geo),", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2014}, {"title": "23-Bit Metaknowledge Template towards Big Daata Knowledge Discovery and Management", "author": ["Bari", "Nima", "Roman Vichr", "Karmran Kowsari", "Simon Berkovich"], "venue": "The 2014 International Conference on Data Science and advanced Analytics", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2014}, {"title": "Investigation of FuzzyFind Searching with Golay Code Transformations", "author": ["Kamran Kowsari"], "venue": "M.Sc. Thesis,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2014}, {"title": "A robust Text Detection Algorithm, in Images and Video Frames", "author": ["Qixiang Ye", "Wen Gao", "Weiqiang Wang", "Wei Zeng"], "venue": "Fourth IEEE Pacific-Rim Conference On Multimedia,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2003}, {"title": "An efficient technique for searching very large files with fuzzy criteria using the pigeonhole principle", "author": ["Yammahi", "Maryam", "Kowsari", "Kamran", "Shen", "Chen", "Berkovich", "Simon"], "venue": "IEEE, Computing for Geospatial Research and Application (COM. Geo),", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2014}], "referenceMentions": [{"referenceID": 0, "context": "The latest focus of Big Data Analytics has been centered on content extraction and knowledge discovery [1], [4], [5].", "startOffset": 103, "endOffset": 106}, {"referenceID": 3, "context": "The latest focus of Big Data Analytics has been centered on content extraction and knowledge discovery [1], [4], [5].", "startOffset": 108, "endOffset": 111}, {"referenceID": 4, "context": "The latest focus of Big Data Analytics has been centered on content extraction and knowledge discovery [1], [4], [5].", "startOffset": 113, "endOffset": 116}, {"referenceID": 0, "context": "[1] The authors of the Unified Framework for Representation, Analysis of Multimedia Content for Correlation and Prediction [3], Paul and Singh, highlighted some general challenges, which prove true when approaching any analysis of Big Data and especially Multimedia Big Data.", "startOffset": 0, "endOffset": 3}, {"referenceID": 2, "context": "[1] The authors of the Unified Framework for Representation, Analysis of Multimedia Content for Correlation and Prediction [3], Paul and Singh, highlighted some general challenges, which prove true when approaching any analysis of Big Data and especially Multimedia Big Data.", "startOffset": 123, "endOffset": 126}, {"referenceID": 2, "context": "Next, given the amorphous nature of the data, we must consider both its multi-dimensional nature and conclude how to utilize the variety of attributes, have them coincide, and then apply methodologies [3].", "startOffset": 201, "endOffset": 204}, {"referenceID": 1, "context": "It allows us to determine significant data points according to 23 predetermined attributes and then cluster the set using Golay Coding [2].", "startOffset": 135, "endOffset": 138}, {"referenceID": 5, "context": "The ontology [6] allows us to represent interdependencies within one or more entities, therefore allowing for an unbroken collaborative approach.", "startOffset": 13, "endOffset": 16}, {"referenceID": 6, "context": "The first challenge was to determine the specific classification algorithms applicable for our proposed ontology as noted in [7].", "startOffset": 125, "endOffset": 128}, {"referenceID": 9, "context": "implementation of fuzzy based on Hamming Distance (HD) [17].", "startOffset": 55, "endOffset": 59}, {"referenceID": 7, "context": "Figure 1: Golay Code 23 bit processing [11].", "startOffset": 39, "endOffset": 43}, {"referenceID": 7, "context": "Figure 2: Golay Code 23bit index lookup and label resolution of clusters [11].", "startOffset": 73, "endOffset": 77}, {"referenceID": 0, "context": "> Assistance in deriving threshold driven questions to qualify answer Yes/No [1, 0].", "startOffset": 77, "endOffset": 83}, {"referenceID": 9, "context": "Wen Gao from Peking University described in [17], text mining, which contains a lot of semantic information can contribute significantly on the retrieval process for content-based multimedia data such as video and audio.", "startOffset": 44, "endOffset": 48}, {"referenceID": 8, "context": "The discovered metaknowledge was applied to the structured data of movie IMDB records [16] and those were consequently processed with Golay Code algorithm and assigned cluster label1 or label2.", "startOffset": 86, "endOffset": 90}], "year": 2015, "abstractText": "Past research has challenged us with the task of showing relational patterns between text-based data and then clustering for predictive analysis using Golay Code technique. We focus on a novel approach to extract metaknowledge in multimedia datasets. Our collaboration has been an on-going task of studying the relational patterns between datapoints based on metafeatures extracted from metaknowledge in multimedia datasets. Those selected are significant to suit the mining technique we applied, Golay Code algorithm. In this research paper we summarize findings in optimization of metaknowledge representation for 23-bit representation of structured and unstructured multimedia data in order to be processed in 23-bit Golay Code for cluster recognition. Keywords\u2014 Big Multimedia Data Processing and Analytics; Information Retrieval Challenges; Content Identification, Metafeature Extraction and Selection; Metalearning System; 23-Bit Meta-knowledge template; Knowledge Discovery, Golay Code.", "creator": "'Certified by IEEE PDFeXpress at 02/26/2015 7:24:33 PM'"}}}