{"id": "1503.01299", "review": {"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "4-Mar-2015", "title": "Telling cause from effect in deterministic linear dynamical systems", "abstract": "Inferring a cause from its effect using observed time series data is a major challenge in natural and social sciences. Assuming the effect is generated by the cause trough a linear system, we propose a new approach based on the hypothesis that nature chooses the \"cause\" and the \"mechanism that generates the effect from the cause\" independent of each other. We therefore postulate that the power spectrum of the time series being the cause is uncorrelated with the square of the transfer function of the linear filter generating the effect. This implies that the process of generating the effect varies as it is selected with a positive bias. In this model, we show that if the mean is given, it is generated by the sum of the mean, and then the sum of the mean is generated from a negative bias. This idea is not the same in theory, but more so in practice.\n\n\nI don't think the natural selection process produces a uniform rate of selection of all that is present at all. I think this is one of the main reasons why many natural selection processes fail because they are too short to have an optimal effect. Most natural selection processes rely on random selection to explain the order of things in which we work. The time series is always the shortest possible time series and the only way to predict which species we observe is to assume that the order of things is the shortest. If the length of the shortest of the longest is a set of values, then it is always a set of values that can be inferred to the order of things in which the length of the shortest is determined. The first example, in which the length of the shortest is specified, would be a set of values that have been defined as the longest given by the order of things in which the length of the shortest is determined.\nFor example, in the most general population, the population is always defined as a set of values with two values: a pair of pairs of pairs of pairs of pairs of pairs of pairs of pairs of pairs of pairs of pairs of pairs of pairs of pairs of pairs of pairs of pairs of pairs of pairs of pairs of pairs of pairs of pairs of pairs of pairs of pairs of pairs of pairs of pairs of pairs of pairs of pairs of pairs of pairs of pairs of pairs of pairs of pairs of pairs of pairs of pairs of pairs of pairs of pairs of pairs of pairs of pairs of pairs of pairs of pairs of pairs of pairs of pairs of pairs of pairs of pairs of pairs of pairs of pairs of pairs of pairs of pairs of", "histories": [["v1", "Wed, 4 Mar 2015 12:48:44 GMT  (1136kb)", "http://arxiv.org/abs/1503.01299v1", "This article is under review for a peer-reviewed conference"]], "COMMENTS": "This article is under review for a peer-reviewed conference", "reviews": [], "SUBJECTS": "cs.AI", "authors": ["naji shajarisales", "dominik janzing", "bernhard sch\u00f6lkopf", "michel besserve"], "accepted": true, "id": "1503.01299"}, "pdf": {"name": "1503.01299.pdf", "metadata": {"source": "CRF", "title": "Telling cause from effect in deterministic linear dynamical systems", "authors": ["Naji Shajarisales", "Dominik Janzing", "Bernhard Sch\u00f6lkopf", "Michel Besserve"], "emails": ["michel.besserve}@tuebingen.mpg.de"], "sections": [{"heading": null, "text": "ar X\niv :1\n50 3.\n01 29\n9v 1\n[ cs\n.A I]\nInferring a cause from its effect using observed time series data is a major challenge in natural\nand social sciences. Assuming the effect is generated by the cause trough a linear system,\nwe propose a new approach based on the hypothesis that nature chooses the \u201ccause\u201d and the\n\u201cmechanism that generates the effect from the cause\u201d independent of each other. We therefore\npostulate that the power spectrum of the time series being the cause is uncorrelated with the\nsquare of the transfer function of the linear filter generating the effect. While most causal\ndiscovery methods for time series mainly rely on the noise, our method relies on asymmetries of\nthe power spectral density properties that can be exploited even in the context of deterministic\nsystems. We describe mathematical assumptions in a deterministic model under which the\ncausal direction is identifiable with this approach. We also discuss the method\u2019s performance\nunder the additive noise model and its relationship to Granger causality. Experiments show\nencouraging results on synthetic as well as real-world data. Overall, this suggests that the\npostulate of Independence of Cause and Mechanism is a promising principle for causal inference\non empirical time series."}, {"heading": "1 Introduction", "text": "A major challenge in the study of complex natural systems is to infer the causal relationships between elementary characteristics of these systems. This provides key information to understand the underlying mechanisms at play and possibly allows to intervene on them to influence the overall behavior of the system. While causal knowledge is traditionally built by performing experiments, boiling down to modifying a carefully selected parameter of the system and analyzing the resulting changes, many natural systems do not allow such interventions without tremendous cost or complexity. For example, it is very difficult to influence the activity of a specific brain region without influencing other properties of the neural system [15]. Causal inference methods have been developed to avoid such intervention and infer the causal relationships from observational data only\n[23, 18]. To be able to build such knowledge without interventions, these approaches have to rely on key assumptions pertaining to the mechanisms generating the observed data.\nThe framework of causality in [23, 18] has originally addressed this question by modelling observations as i.i.d. random variables. However, observed data from complex natural system are often not i.i.d. and time dependent information reflects key aspects of those systems. Most causal inference methods for time series, including the most widely used Granger causality [8], assume the data is generated from a stochastic model through a structural equation linking past values to future ones through an i.i.d. additive noise term, the \u201cinnovation of the process\u201d [8, 19]. While these methods can successfully estimate the causal relationships when empirical data is generated according to the model assumptions, the results can be misleading when the model is misspecified. In particular, this is the case when unknown time lags are introduced in the measured time series.\nIn this paper, we introduce a new approach to inferring causal directions in time series, the Spectral Independence Criterion (SIC). The idea behind SIC, as well as several new approaches to causal inference [7, 11, 10, 26], is to rely on the \u2018philosophical\u2019 principle that the cause and the mechanism that generates the cause from the effect are chosen independently by Nature. Thus, these two objects should not contain any information about each other [12, 14, 21]. Here, we refer to this abstract principle as the postulate of Independence of Cause and Mechanism (ICM). The above mentioned methods relying on ICM refer to different domains and rely on quite different formalizations of the concept of \u201cindependence\u201d. SIC formalizes the ICM postulate in the context where both cause and effect are stationary time series and the cause generates the effect trough a linear time invariant filter. The SIC postulate assumes that the frequency spectrum of the cause does not correlate with the transfer function of the filter. This assumption is justified by its connection to the Trace Method [10] and by a generative model of the system. Under this postulate, we prove that SIC can tell the causal direction of the system from its anticausal counterpart. Moreover, we elaborate on the connection between this novel framework and linear Granger causality, showing they are exploiting fundamentally different information from the observed data. In addition, superiority to Granger causality is shown analytically in the context of time series measurements perturbed by an unknown time lag. We perform extensive experimental comparisons, both on simulated and real datasets. In particular, we show that our approach outperforms Granger causality to estimate the direction of causation between to structures of rat hippocampus using Local Field Potential (LFP) recordings.\nOverall, the proposed method offers a new approach to causal inference for time series data with identifiability results, and shows unprecedented robustness to measurement delays. The promising empirical results suggest the SIC postulate is a reasonable assumption for empirical data, and that it should be further exploited to develop novel causal inference techniques."}, {"heading": "2 Spectral Independence Criterion (SIC)", "text": ""}, {"heading": "2.1 Notations and model description", "text": "We refer to a sequence of real or complex numbers a = {at, t \u2208 Z} as a deterministic time series. Its discrete Fourier transform is defined by\na\u0302(\u03bd) = \u2211\nt\u2208Z\nat exp(\u2212i2\u03c0\u03bdt), \u03bd \u2208 [\u22121/2, 1/2] =: I\nThe energy of the deterministic time series is the squared l2 norm: \u2016a\u201622 = \u2211 t |at| 2. For ease of notation we will also use the Z-transform of a\na\u0303(z) = \u2211\nt\u2208Z\natz \u2212t, z \u2208 C\nsuch that a\u0302(\u03bd) = a\u0303(exp(i2\u03c0\u03bd)).\nWe assume that the causal mechanism is given by a (deterministic) Linear Time Invariant (LTI)\nfilter. That is, the causal mechanism is formalized by the convolution\ny = {yt} = { \u2211\n\u03c4\u2208Z\nxt\u2212\u03c4h\u03c4 } = x \u2217 h, (1)\nwhere h denotes the impulse response, x the input time series and y the output. We will assume that the filter satisfies the Bounded Input Bounded Output (BIBO) stability property [20], which boils down to the condition \u2016h\u20161 < +\u221e. Under this assumption, the Fourier transform h\u0302 is well defined and we call it the transfer function of the system.\nWe assume that the input time series x is a sample drawn from a stochastic process, {Xt, t \u2208 Z}. For a given index t, Xt represents the random variable at index t. We use {Xt} or simply X to represent the complete stochastic process. We useXt:s to indicate the random vector corresponding to the restriction of the time series to the integer interval [t .. s]. We use Xt:s to indicate the random vector corresponding to the restriction of the time series to the integer interval [t .. s]. Assuming X is a zero mean stationary process (in this paper, stationary will always stand for weakly or wide-sense stationary [5]), we will denote by Cxx(\u03c4) = E[XtXt+\u03c4 ] the autocovariance function of the process and assume it is absolutely summable. Then, we can define its Power Spectral Density (PSD) Sxx = C\u0302xx. Under these assumptions, the power of the process P (X) = E(|Xt| 2) is finite and P (X) = \u222b 1/2 \u22121/2 Sxx(\u03bd)d\u03bd, such that Sxx belongs to L 1. Moreover, we recall the following basic properties for our model:\nProposition 1. Assume the weakly stationary input X is filtered by the BIBO linear system of impulse response h to provide the output Y. Then \u2016h\u201622 < +\u221e, h\u0302 \u2208 L \u221e and Y is weakly stationary with summable autocovariance such that\nSyy(\u03bd) = |h\u0302(\u03bd)| 2Sxx(\u03bd), \u03bd \u2208 I (2)\nProof. Results from elementary properties of the Fourier transform and Proposition 3.1.2. in [5].\nIf such a linear filtering relationship exists for X as input and Y as output, but not in the opposite way, we can use this information to infer that X is causing Y and not the other way round. If there are such impulse responses exist for both directions, say hX\u2192Y and hY\u2192X, their Fourier transforms are related by\nh\u0302X\u2192Y = 1\nh\u0302Y\u2192X ,\nand we have to resort to a more refined criterion for the causal inference. We will assume this situation in the remaining of the paper."}, {"heading": "2.2 Definition of SIC", "text": "Assume we are given the two processes X := {Xt, t \u2208 Z} and Y := {Yt, t \u2208 Z}. Moreover, we assume that exactly one of the following two alternatives is true: (1) X causes Y or (2) Y causes X. We assume that there are no unobserved common causes of X and Y. Our causal inference problem thus reduces to a binary decision. In the spirit of ICM, we assume that in case (1), X and h should not contain information about each other and our Spectral Indpendance Criterion (SIC) assumes that the input power does not correlate with the amplifying factor, that is,\n\u3008Sxx|h\u0302| 2\u3009 = \u3008Sxx\u3009\u3008|h\u0302| 2\u3009 , (3)\nwhere \u3008f\u3009 = \u222b I f(\u03bd)d\u03bd denotes the average over the unit frequency interval I. Note that the left hand side of (eq. (3)) is the average intensity of the output signal {Yt, t \u2208 Z} over all frequencies. Hence, SIC states that the average output intensity is the same as amplifying all frequencies by the average amplifying factor. To motivate why we call (eq. (3)) an independence condition we note that the difference between the left and the right hand side can be written as a covariance:\n\u3008Sxx \u00b7 |h\u0302| 2\u3009 \u2212 \u3008Sxx\u3009\u3008|h\u0302| 2\u3009 = Cov ( Sxx, |h\u0302| 2 ) .\nwere we consider Sxx and |h\u0302| 2 as functions of the random variable \u03bd uniformly distributed on I. As a consequence statistical independence between those random variables implies that (eq. (3)) is satisfied.\nNote that the criterion (eq. (3)) can be rephrased in terms of the power spectra of X and Y\nalone using (eq. (2)), which are closer to observable quantities than h\u0302:\nPostulate 1 (Spectral Independence Criterion). If Y is generated from X by a linear deterministic translation invariant system then we have:\n\u3008Syy\u3009 = \u3008Sxx\u3009\u3008Syy/Sxx\u3009 . (4)"}, {"heading": "2.3 Quantifying violation of SIC", "text": "This motivates us to define a measure of dependence between the input PSD on one hand and transfer function of the mechanism on the other hand. To asses to what degree such a relation\nholds we introduce a scale invariant expression \u03c1X\u2192Y, that we call the spectral dependency ratio (SDR) from X to Y:\n\u03c1X\u2192Y := \u3008Syy\u3009\n\u3008Sxx\u3009\u3008Syy/Sxx\u3009 (5)\nHere, the value 1 means independence, which becomes more obvious by rewriting (eq. (5)) as\n\u03c1X\u2192Y = Cov[Sxx, |h\u0302|\n2]\n\u3008Sxx\u3009\u3008Syy/Sxx\u3009 + 1 .\nFinally, we note that \u03c1X\u2192Y can be written in terms of total power and energy:\n\u03c1X\u2192Y = P (Y)\nP (X)||h||22\nWe then define \u03c1Y\u2192X by exchanging the roles of X and Y:\n\u03c1Y\u2192X := \u3008Sxx\u3009\n\u3008Syy\u3009\u3008Sxx/Syy\u3009 (6)"}, {"heading": "2.4 Identifiability results", "text": "In order to identify the true causal direction from SIC, it is necessary to show that \u03c1X\u2192Y and \u03c1Y\u2192X take characteristic values that are informative about this inference problem. The following first result shows explicitly how dependence measures in both directions are related:\nProposition 2. (Forward-backward inequality) For a given linear filter with input PSD Sxx, output PSD Syy and a non-constant modulus transfer function h\u0302 we have\n\u03c1X\u2192Y.\u03c1Y\u2192X < 1 . (7)\nMoreover, if \u2203\u03b1 > 0, \u2200\u03bd \u2208 I, |h\u0302(\u03bd)|2 \u2264 (2\u2212 \u03b1)\u2016h\u201622 ,\nthen\n\u03c1X\u2192Y.\u03c1Y\u2192X \u2264\n 1 + \u03b1 \u222b\nI\n( |h\u0302(\u03bd)|2 \u2212 \u2016h\u201622\n\u2016h\u201622\n)2 d\u03bd   \u22121 < 1 . (8)\nProof of this proposition is given in supplementary material. Note that \u2016h\u201622 corresponds to the mean value of the transfer function due to Parseval\u2019s theorem. According to equation eq. (8), the less constant |h\u0302|2 is, the more the product of the independence measures will be inferior to 1. Assuming the SIC postulate is satisfied in the forward direction such that \u03c1X\u2192Y = 1, it follows naturally that \u03c1Y\u2192X < 1. The two causal directions can thus be distinguished well whenever the transfer function deviates significantly from its mean value such that \u03c1X\u2192Y\u03c1Y\u2192X is bounded away from 1. We then infer the causal direction to be the one with the largest \u03c1 value.\nTo further support that SDR values can be used empirically for causal inference, we need the SIC postulate to be approximately satisfied (see (eq. (4))) in systems generated according\nto the ICM principle. We now describe a model where h is generated by some random process, independently of X. To this end, assume we start with a Finite Impulse Response (FIR) h, that is, h\u03c4 = 0 for all \u03c4 \u2265 m, for some m. Then h is given by m real numbers b1, . . . , bm such that\nhi = bi i = 0, . . . ,m\u2212 1 .\nWe then apply an orthogonal transformation U, randomly drawn from the orthogonal group O(m) according to the \u2018uniform distribution\u2019 on O(m), that is, the Haar measure. In this way, we generate a new impulse response function\nh\u2032i := (Ub)i i = 0, . . . ,m\u2212 1 . (9)\nSince orthogonal transformations preserve the Euclidean norm by definition, they preserve the energy of the filter. Our procedure thus chooses a random filter among the set of filters having the same support of length m and the same energy. We now show that for large m the resulting filter will approximately satisfy SIC with high probability:\nTheorem 1. (concentration of measure for FIR filters) For some fixed Sxx, let \u03c1 U X\u2192Y be the dependence measure obtained for h\u2032 in (eq. (9)). If U is chosen from the Haar measure on O(m), then for any given \u03b5\n|\u03c1UX\u2192Y \u2212 1| \u2264 2\u03b5\nP (X) max \u03bd Sxx(\u03bd) .\nwith probability \u03b4 := 1 \u2212 exp(\u03ba(m \u2212 1)\u03b52) where \u03ba is a positive global constant independent of m, \u03b5, X and Y.\nProof of this theorem is provided in supplementary material. This result provides a justification for using SIC provided that the dimension of the vector of filter coefficients m is large enough. The relevance of m will be investigated in practice in the experimental section."}, {"heading": "2.5 Relation to the Trace Condition", "text": "We now describe the relation between SIC and a causal inference tool called Trace Method [10]. Let X and Y be n-dimensional variables, related by the linear structural equation\nY = AX + E ,\nwhere A is an m \u00d7 n structure matrix and E is a n-dimensional noise variable independent of X . [10] postulate the following independence condition between the covariance matrix of input distribution \u03a3X and A:\nPostulate 2 (Trace Condition).\n\u03c4m(A\u03a3XA T ) = \u03c4n(\u03a3X)\u03c4n(A TA) , (10)\napproximately, where \u03c4n(B) denotes the renormalized trace tr(B)/n.\nThe postulate can be justified by random matrix theory with large m when A and \u03a3X are independently chosen according to priors satisfying appropriate symmetry assumptions [10]. In the association between SIC and trace method we only consider square matrices and therefore m = n.\nTo quantify the violation of (eq. (10)) we introduce the following quantity:\nDefnition 1 (Tracial Dependency Ratio (TDR)). The tracial dependency ratio is given by\nrX\u2192Y := \u03c4n(A\u03a3XA\nT )\n\u03c4n(\u03a3X)\u03c4n(ATA) . (11)\nWe thus can see that the tracial ratio plays a role analog to our spectral dependency ratio \u03c1 in the finite dimensional case. We can actually show that SIC can be viewed as a limit case of the Trace Condition by defining the following truncated system.\nDefnition 2. To any given infinite dimensional linear system X 7\u2192 Y = h \u2217 X, the truncated system of order N is defined by zeroing the input and the output values for integers k such that \u2212N \u2264 k < N :\nX \u2032 N = X\u2212N :N\u22121 7\u2192 Y \u2032 N = (h \u2217X \u2032 N )\u2212N :N\u22121,\nNote that in this definition for each N , the vectors Y\u2032\u2212N :N\u22121 are inherently different. The mapping defined in this way is linear and can be written as Y\u2032 = HX\u2032 with [H ]ij = hi\u2212j , such that the trace method can be applied to it. We then have the following result showing that SIC can be obtained from the Trace Condition as an appropriate limit:\nTheorem 2. Let rX\u2032 N \u2192Y\u2032 N represent the tracial ratio for the truncated systems of order N for a given linear system with SDR \u03c1X\u2192Y. Then\nlim N\u2192\u221e rX\u2032 N \u2192Y\u2032 N = \u03c1X\u2192Y\nThe proof, together with two necessary lemmas is available in supplementary material."}, {"heading": "3 SIC for vector autoregressive models", "text": "SIC and Granger causality rely on completely different assumptions but both apply to linear time series models. In this section, we study the classical Vector Autoregressive (VAR) model used in Granger causality from the SIC perspective to better understand the relation."}, {"heading": "3.1 VAR model", "text": "We assume the observed time series are generated by a VAR model such that x Granger causes y.\nXt = \u2211\nk\nakXt\u2212k + \u01ebt (12)\nYt = \u2211\nk\nbkYt\u2212k + \u2211\nk\nckXt\u2212k + \u03bet (13)\nBoth noise terms \u01eb and \u03be in this expression are i.i.d normal noises."}, {"heading": "3.2 Applying SIC to VAR models", "text": "We want to rewrite this expression such that Y is obtained from X by a deterministic linear time invariant filter. We observe that the VAR model can be cast as linear time invariant filter if we neglect the additive noise \u03be. Indeed, then the mechanism is the following ARX (AutoRegressive with eXogenous input) model [13].\nYt = \u2211\nk\nbkYt\u2212k + \u2211\nk\nckXt\u2212k (14)\nUsing basic properties of the Z-transform, we can derive the following analytic expressions of the input PSD Sxx:\nSxx(\u03bd) = |n\u0302(\u03bd)| 2 = |n\u0303(exp(2\u03c0i\u03bd))|2 ,\nwith\nn\u0303(z) = 1\n1\u2212 \u2211\nk akz \u2212k\n.\nMoreover, the transfer function corresponding to the mechanism in equation eq. (14) is\nm\u0303(z) =\n\u2211 k ckz \u2212k\n1\u2212 \u2211\nk bkz \u2212k\nAs a consequence, testing SIC on the VAR model in the forward direction amounts (when neglecting the filtered noise \u03be), to test independence between\n|h\u0302(\u03bd)|2 = |m\u0303(exp(2\u03c0i\u03bd))|2 (15)\nand\nSxx(\u03bd) = |n\u0303(exp(2\u03c0i\u03bd)| 2 , (16)\nwhich are parametrized by the coefficients {bk, ck} and {ak} respectively. We conjecture that a concentration of measure result similar to Theorem 1 holds stating that independent choice of the coefficients from an appropriate symmetric distribution typically yields small correlations between (eq. (15)) and (eq. (16)). This will be tested empirically in the Experiments section. Additionally, the robustness of our approach to noise in the VAR model will be addressed extensively in a longer version of this manuscript."}, {"heading": "3.3 Comparison of SIC and Granger causality", "text": "The bivariate VAR model above is the typical model where Granger causality works. To recall the idea of the latter, note that it infers that there is an influence from X to Y whenever predicting Y from its past is improved by accounting for the past of X. Rephrasing this in terms of conditional independences, X is inferred to cause Y whenever Yt is not conditionally independent\nof Xt\u22121, Xt\u22122, . . . , given Yt\u22121, Yt\u22122, . . . . Within the context of the above linear model, knowing Xt\u22121, Xt\u22122, . . . reduces the variance of Yt, given Yt\u22121, Yt\u22122, . . . because then the noise \u03bdt is the only remaining source of uncertainty. Without knowing Xt\u22121, Xt\u22122, . . . , we have additional uncertainty due to the contribution of \u01ebt\u22121, \u01ebt\u22122, . . . .\nSIC, on the other hand, does not rely on detecting whether X helps in improving the prediction of Y. As demonstrated above, SIC applied to a bivariate VAR model boils down to quantifying independence between two linear filters defined by set of coefficients, the filter generating the input with transfer function n\u0302 and the filter of the mechanism with transfer function m\u0302. This is a completely different concept. One can easily imagine that the coefficients {bk, ck} and {ak} can be hand-designed such that the functions (eq. (15)) and (eq. (16)) are correlated. This would spoil SIC, but leave Granger unaffected. On the other hand, the following subsection describes a scenario where Granger fails but SIC still works."}, {"heading": "3.4 Sensitivity to Time Lag", "text": "Consider two time series {Xt} and {Yt} where {Xt} is a white noise and\n\u2200t \u2208 Z, Yt = cYt\u22121 +Xt\u22121,\nfor a given c. It can be easily seen that this type of input and output can be simulated using an IIR filter with (a1, a2) = (1, c) and b1 = 1 in (eq. (17)) and the rest of the coefficients are zero (please refer to the definition of coefficients in section section 4.1). The infinite DAG for this causal structure can be seen in fig. 1.\nNow if there would be a measurement delay of length k for Y, the observed values will be a new time series, say Y\u0303, where Y\u0303t = Yt\u2212k. Although the ground truth is X \u2192 Y\u0303 independent of k, Granger causality only infers the correct causal structure if k \u2264 0 (where there is a lag in measurement of X, but not Y). However SIC always infers the correct direction (except when c = 0 and the time structure is spoiled). This is because the PSD of the white noise X is constant and depends only on the total power, i.e,\nSxx(\u03bd) = Var(Xt) = P{X} ,\nfor all \u03bd \u2208 [\u22121/2, 1/2]. and obviously, this constant remains the same for the lagged time series. Thus, SIC correctly identifies the causal structure (except when c = 0 in which case the dependence to time is completely spoiled)."}, {"heading": "4 Experiments", "text": "In this section we study our causal inference algorithm using synthetic experiments and apply it to several real world data sets."}, {"heading": "4.1 Synthetic Data: ARMA filters and processes", "text": "We designed synthetic experiments to assess the validity of the SIC approach. The data generating process is as follows. The LTI system S modeling the mechanism is chosen among the family of ARMA(FO,BO) filters with parameters (a,b) defined by input-output difference equation:\nyn = 1 a0 ( FO\u2211\ni=0\nbixn\u2212i + BO\u2211\nj=1\najyn\u2212j). (17)\nFor these filters FO is known as the feedforward order and BO is the feedback order. ai\u2019s and bi\u2019s are known as feedback and feedforward coefficients respectively. Note that when FO(S) = 0, the system is called and autoregressive filter. Alternatively, BO(S) = 0 corresponds to the family of Finite Impulse Response (FIR) or Moving Average filters. Whenever BO(S) 6= 0, the filter has Infinite Impulse Response (IIR). The input of the causal model will be chosen among the family of ARMA(FO,BO) processes, which are generated by filtering an i.i.d noise input with an ARMA(FO,BO) filter. We thus chose two filters S and S \u2032, with parameters (a,b) and (a\u2032,b\u2032) respectively. To simulate a cause effect pair X,Y, we generated the cause X by applying S to a normally distributed i.i.d noise. Then, we generated Y by applying S \u2032 to X. The feedforward and feedback orders of both systems S and S \u2032 were chosen identical in all experiments.\nIn each trial all the elements of vectors a, a\u2032, b and b\u2032 except the first ones (i.e. a0, b0, a \u2032 0, b \u2032 0 which were fixed to one) were sampled from an isotropic multidimensional Gaussian distribution with variance 0.01. Coefficients are sampled using rejection sampling such that only BIBO-stable filters are kept.\nWe simulated sequences of length 10000. The PSD of X and Y were estimated using Welch\u2019s method [24]. We repeated this experiment 1000 times. Figure fig. 2 shows an example of the distribution of \u03c1X\u2192Y and \u03c1Y\u2192X and of their difference using FO(S) = BO(S) = FO(S \u2032) = BO(S \u2032) = 5.\nThe SDR for the correct direction of is concentrated around one, while in the wrong direction the estimator stays less inferior to one for most of its probability mass (in this example %97.3). This results in a positive difference between SDR for most of the probability mass. Accordingly, our inference algorithm based on the sign of this difference algorithm 1 will select the correct direction in most of the cases.\nBased on this inference algorithm, we test the effect of the filter orders on the performance of the method, where we evaluate the performance of each setting of FO(S \u2032) and BO(S \u2032) over 1000 trials. We varied the orders between 2 and 21 and compared the performance of the cases FO(S \u2032) = BO(S \u2032), FO(S \u2032) = 0 and BO(S \u2032) = 0. Considering that the experiments are independent and\nbased on the assumption that our method is successful with probability p where p has a binomial distribution, we calculated confidence intervals using Wilson\u2019s score interval [25] where \u03b1 = 0.05 (and therefore z\u03b1/2 = 1.96). The performance increases rapidly with filter order, as can be seen in the plots of fig. 3. Moreover, the feedforward filter coefficients seem the most beneficial to the approach, since their absence leads to the worst performance ( fig. 3 red line)."}, {"heading": "4.2 Real World Examples", "text": "We tried our method over several examples of real data where the ground truth about the causal structure of the data is known a priori and the data is labeled in a way that the ground truth is X \u2192 Y. In the first two examples we plotted the difference of SDR in both directions as a function of the window length used in Welch method which can be seen in fig. 4."}, {"heading": "4.2.1 Gas Furnace [4]", "text": "This dataset consists in 296 time points, with X the gas rate consumed by a gas furnace and Y the produced rate of CO2. fig. 4 shows \u03c1X\u2192Y \u2212 \u03c1Y\u2192X against the window length, which was ranging from 50 to 150 points. As illustrated, the difference is always positive and our method is able to correctly infer the right causal direction independent of window length. TiMiNO and Granger causality correctly identified the ground truth in this case as well [19].\nAlgorithm 1 SIC Inference\n1: procedure SIC Inference(X,Y) 2: Sxx \u2190 spectrum of X 3: Syy \u2190 spectrum of Y 4: Calculate \u03c1X\u2192Y and \u03c1Y\u2192X using (eq. (5)) 5: Inference Step: 6: if \u03c1X\u2192Y > \u03c1Y\u2192X then 7: return X \u2192 Y 8: else 9: return Y \u2192 X"}, {"heading": "4.2.2 Old Faithful Geyser [2]", "text": "N = 298 : X contains the duration of an eruption and Y is the time interval to the next eruption of the Old Faithful geyser. Figure fig. 4 represents the difference in SDRs as a function of win-\ndow length with the same configuration as the gas furnace experiment. Again the correct causal direction is inferred by our method independently from the window length as illustrated in fig. 4. In this case TiMiNO correctly identifies the cause from effect but neither linear nor non-linear Granger causality infer the correct causal direction [19]."}, {"heading": "4.2.3 LFP recordings of the Rat Hippocampus", "text": "It is known that contrary to neocortex where connectivity between areas is bidirectional, monosynaptic connections between several regions of the hippocampus are mostly unidirectional [1]. An important example of such connectivity is between the CA3 and CA1 subfields [1]. Despite this anatomical fact, a study of causality based on Local Field Potential (LFP) recordings of CA1 and CA3 of the hippocampus of the rat during sleep reports that Granger causality infers strong bidirectional relations between the two areas [3]. [3] explains the possible reasons of such result as feedback loops involving cortex and medial septum, and diffuse connections going from CA1 to CA3.\nTo do a comparison with Granger causality, we applied our framework to recordings from those regions using a publicly available dataset1 [16, 17]. LFP\u2019s were recorded using a 8 shank probe having 64 channels downsampled to 1252Hz. Shanks were attributed by experimentalists to the CA1 and CA3 areas (leaving 32 channels for each area). For more information on the details of gathered data please refer to [17]. We used the data for rat \u201cvvp01\u201d during a period of sleep and a period of active behaviour in a linear environment. We applied linear Granger causality using\n1http://crcns.org/data-sets/hc\nan implementation from the statsmodel Python library2. We considered a forced decision scheme for Granger causality (to make it comparable to our method), were we select the correct Granger causal direction as the one having the lowest p-value for the null hypothesis of absence of causal influence. Following the usual methodology of causality analysis [3, 6] we divided the duration of ten minutes into 300 intervals of two seconds (N = 2504) to reduce the effect of nonstationarity in data analysis, and performed SIC causal inference on each interval for each electrode pair. We took two different approaches to report assess the performance of methods: one, based on a majority vote over all 300 intervals for each channel pair, and two, by assessing the average performance based on individual time intervals. The results are plotted as histograms in fig. 5 and they show that SIC clearly outperforms Granger causality on this dataset. The confidence intervals are once again based on Wilson score but obviously this time the in dependancy assumption between the trials is not well justified, specially for pooling all the results.\n2Statsmodels: Statistical library for Python. More details on null hypothesis for Granger causality can be found\non the website."}, {"heading": "4.2.4 Characterizing the Echo", "text": "The echo effect of a room over a sound generated in the room can be well estimated by a convolution of the real signal with a function known as room impulse response function. In this experiment we used an open source database of room Impulse Response Function (IRF) available at the Open AIR library3. We chose the IRFs for Elevden Hall, Elevden, Suffolk, England and Hamilton Mausoleum, Hamilton, Scotland. We convolved these signals with 30\u00b15 seconds segments of two classical music pieces: the first movement of Vivaldi\u2019s Winter Concerto consisting of 9190656 data points, and the Lacrimosa of Mozart\u2019s Requiem, consisting of 8842752 points, both \u2018.wav\u2019 files with the rate of 44100Hz. Regardless of the segment the SDR in forward direction is considerably larger than the SDR in the backward direction as can be seen in fig. 6. In another experiment we used a computer\nto play the musical pieces above in an academic Lecture Hall (labelled as \u201cHall\u201d in plots) and in an office room (labelled as \u201cRoom\u201d in plots) and recorded the echoed version in the environment. In a series of different tests, we split the data into 9, 17, 33, 65, 129 pieces, and we ignored the last piece so that all the pieces would have an equal length. In each test we averaged the performance of our causal inference method over all the segments and plotted this performance against the size of the window length in Welch method. The window size was varied between 500 and half of the length of the music segment length (which is dependent on the number of segments). The results can be found in fig. 7 and show a very good performance of the approach for large window lengths .\n3Open AIR: Open source library for acoustic IRFs."}, {"heading": "5 Conclusion", "text": "We have introduced a causal discovery method for time series based on the SIC postulate, assuming a LTI relationship for a given pair of time series X and Y, such that either X \u2192 Y or Y \u2192 X. Theoretical justifications are provided for this postulate to lead to identifiability. Interestingly, the method provides and extension of the recently proposed Trace Method approach to the time series setting. Encouraging experimental results have been also presented on real world and synthetic data. Specially this method proved to be more effective than linear Granger causality on LFP recordings from CA1 and CA3 hippocampal areas of rat\u2019s brain, assuming a ground truth causal direction from CA3 to CA1 based on anatomy. We suggest that this method can provide a new\nperspective for causal inference in time series based on assumptions fundamentally different from Granger causality. We will address the existence of confounders, establish a statistical significance test (for example using a procedure inspired by [26]), and extend this method to multivariate time series in future work."}, {"heading": "6 Proof of Proposition 2", "text": "Lemma 1. For f \u2208 L2(I) positive, non-constant, such that 1/f \u2208 L2(I), we have \u222b\nI\nf(x)2dx.\n\u222b\nI\n1\nf(x)2 dx > 1\nProof. Using Cauchy-Schwartz inequality for the scalar product\n\u3008f(x) , 1\nf(x) \u3009 =\n\u222b\nI\nf(x). 1\nf(x) dx = 1 .\nInequality is strict since f and 1/f are not collinear (otherwise f would be constant). Lemma 2. Let f \u2208 L1(I) be positive, non-constant, such that 1/f \u2208 L1(I) and \u222b I f(x)dx = 1.\nAssume \u2203\u03b1 > 0, \u2200x \u2208 I, f(x) \u2264 2\u2212 \u03b1 ,\nthen \u222b\nI\nf(x)dx.\n\u222b\nI\n1\nf(x) dx \u2265 1 + \u03b1\n\u222b\nI\n(f(x)\u2212 1)2dx\nProof. We denote s(x) = f(x)\u2212 1. Then \u222b I s(x)dx = 0 and\n\u222b\nI\nf(x)dx.\n\u222b\nI\n1\nf(x) dx\u2212 1 =\n\u222b\nI\n\u2212s(x)\n1 + s(x) dx\nFor x > \u22121, we have\n\u2212x\n1 + x \u2265 x2 \u2212 x3 \u2212 x. (18)\nThe function on the l.h.s. of (eq. (18)) is convex because its second order derivative 2(1+x)3 is positive and using its tangent in x = 0, we get \u222b\nI\nf(x)dx.\n\u222b\nI\n1\nf(x) dx\u2212 1 \u2265\n\u222b\nI\ns(x)2(1\u2212 s(x))dx\nSince 1\u2212 s(x) = 2\u2212 f(x) \u2265 \u03b1 > 0, \u222b\nI\nf(x)dx.\n\u222b\nI\n1\nf(x) dx\u2212 1 \u2265 \u03b1\n\u222b\nI\ns(x)2dx\nProof of Proposition 2. By using the definition of Spectral Dependency Ratios and Lemma 1 we get\n\u03c1X\u2192Y\u03c1Y\u2192X = 1\n\u3008|h\u0302|2\u3009\u30081/|h\u0302|2\u3009 < 1\nMoreover, applying Lemma 2 to f = |h\u0302|2/ \u222b I |h\u0302| 2 = |h\u0302|2/\u2016h\u201622 we get inequality eq. (8)."}, {"heading": "7 Proof of Theorem 1", "text": "To prove this theorem we rely on a theorem from [10] and a corollary that we derive from it.\nTheorem 3 (concentration of measure for finite dimensional linear relationships). [10] Suppose \u03a3 is a given covariance matrix and suppose A \u2208 Mn\u00d7m(R) is also a given matrix. Then if one generates \u03a3X = U\u03a3U \u22a4 by uniformly choosing an orthogonal matrix U from O(n) then \u03a3X together with A, satisfies trace condition in probability when n tends to infinity. More precisely for a given \u03b5 there exist \u03b4 := 1\u2212 exp(\u03ba(n\u2212 1)\u03b52), \u03ba being a constant where\n|\u03c4m(A\u03a3XA \u22a4)\u2212 \u03c4n(\u03a3X)\u03c4m(AA \u22a4)| = |\u03c4m(AU\u03a3U \u22a4A\u22a4)\u2212 \u03c4n(\u03a3)\u03c4m(AA \u22a4)| \u2264 2\u03b5\u2016\u03a3\u2016\u2016AA\u22a4\u2016\nholds with probability \u03b4.\nIn the above theorem (and the rest of the document), \u2016.\u2016 applied to a matrix will refer to the\noperator norm. The following corollary is a direct consequence of the previous theorem:\nCorollary 1. Suppose \u03a3 is a given covariance matrix and suppose A \u2208 Mn\u00d7m(R) is also a given matrix. Then if one generates AU = AU by uniformly choosing an orthogonal matrix U from O(n) then AU together with \u03a3, satisfies trace condition in probability when n tends to infinity More precisely for a given \u03b5 there exist \u03b4 := 1\u2212 exp(\u03ba(n\u2212 1)\u03b52), \u03ba being a constant where\n|\u03c4m(AU\u03a3A \u22a4 U )\u2212 \u03c4n(\u03a3X)\u03c4m(AA \u22a4)| =\n|\u03c4m(AU\u03a3U \u22a4A\u22a4)\u2212 \u03c4n(\u03a3)\u03c4m(AA \u22a4)| \u2264 2\u03b5\u2016\u03a3\u2016\u2016AA\u22a4\u2016\nholds with probability \u03b4.\nTo prove the main theorem we will also need two lemmas that are stated below.\nLemma 3. [22] For a given Hermitian matrix H and any principal submatrix of H, H \u2032, their spectral radius \u03c1s satisfies\n\u03c1s(H) \u2265 \u03c1s(H \u2032).\nLemma 4. [9] Let f : [\u2212 12 , 1 2 ) \u2192 R f \u2208 L 1 be a bounded function and suppose tk is its Fourier series coefficients, i.e.\ntk =\n\u222b 1 2\n\u2212 1 2\nf(\u03bd)ei2\u03c0k\u03bdd\u03bd, t \u2208 Z.\nConsider Toeplitz matrices Tn defined as\n[Tn]ij = ti\u2212j i, j \u2208 {0, ..., n\u2212 1}\nwith eigenvalues \u03c4n,k(0 \u2264 k \u2264 n\u2212 1). Then if ti are absolutely summable we get:\nmin x\u2208[\u2212 1 2 , 1 2 ) f(x) \u2264 \u03c4n,i \u2264 max x\u2208[\u2212 1 2 , 1 2 ) f(x)\nProof of Theorem 1. Without loss of generality and for the sake of simplicity we only consider the positive indices of the time series and we take the filter to be causal; other cases can be treated in a similar way. Then the following relation holds between input and output of the filter:\n\u2200i, 0 \u2264 i \u2264 N \u2212 1 Yi =\nm\u22121\u2211\nj=0\nbjXi\u2212j\nFormulated in terms of matrices the above relation can be represented as   Y0 Y1 ...\nYN\u22122 YN\u22121\n  = B   X\u2212m+1 X\u2212m+2 ...\nXN\u22122 XN\u22121\n  ,\nwhere B is a N \u00d7 (N +m\u2212 1) matrix as follows:   bm\u22121 bm\u22122 \u00b7 \u00b7 \u00b7 b0 0 \u00b7 \u00b7 \u00b7 0 0 0 bm\u22121 \u00b7 \u00b7 \u00b7 b1 b0 \u00b7 \u00b7 \u00b7 0 0 . . .\n0 0 \u00b7 \u00b7 \u00b7 bm\u22121 \u00b7 \u00b7 \u00b7 b1 b0 0 0 0 \u00b7 \u00b7 \u00b7 0 bm\u22121 \u00b7 \u00b7 \u00b7 b1 b0\n \nWe define \u03a3iX \u2208 Mm\u00d7m(R) to be the covariance matrices as follows:\n\u2200i 0 \u2264 i \u2264 N \u2212 1 0 \u2264 j, k \u2264 m\u2212 1 [\u03a3iX ]jk =\nCov(Xi+j , Xi+k)\nSince the time series that we are dealing with are weakly stationary it is obvious that \u03a3iX is independent of i. If we take \u03a3X0:N\u22121 ,\u03a3Y0:N\u22121 \u2208 MN\u00d7N(R) to be the covariance matrices for X0:N\u22121 and Y0:N\u22121 respectively, then we have\n\u03a3Y0:N\u22121 = B\u03a3X\u2212m+1:N\u22121B \u22a4\nAlso define \u03a3UY0:N\u22121 to be the covariance matrix of the output for FIR S \u2032 with b\u2032 = U\u22a4b. Also assume the spectrum of the output for this filter is SUyy. One can write diagonal elements of \u03a3Y0:N\u22121 and \u03a3UY0:N\u22121 based on the above equation as follows:\n[\u03a3Y0:N\u22121]ii = b \u22a4\u03a3iXb, [\u03a3 U Y0:N\u22121 ]ii = b \u22a4U\u03a3iXU \u22a4b\nand therefore the normalized traces of \u03a3Y0:N\u22121 and \u03a3 U Y0:N\u22121 can be written as\n\u03c4N (\u03a3Y0:N\u22121) = 1\nN b\u22a4\nN\u22121\u2211\ni=0\n\u03a3iXb,\n\u03c4N (\u03a3 U Y0:N\u22121) =\n1\nN b\u22a4U\nN\u22121\u2211\ni=0\n\u03a3iXU \u22a4b\nDefine \u03a3 := \u2211N\u22121\ni=0 \u03a3 i X = \u03a3 0 X . Taking A = b \u22a4 in corollary corollary 1 for a randomly selected U\nwe get\n| 1\nN b\u22a4U\u03a3U\u22a4b\u2212\n1\nN \u03c4m(\u03a3)\u3008b,b\u3009| \u2264 2\u03b5\u2016\u03a3\u2016\n\u221a \u3008b,b\u3009\nand therefore\n|\u03c4N (\u03a3 U Y0:N\u22121)\u2212\n1\nN \u03c4m(\u03a3)\u2016b\u2016\n2 2| \u2264 2\u03b5\u2016\u03a3\u2016\u2016b\u2016 2 2 (19)\nwith probability \u03b4. On the other hand the elements of diagonals of \u03a3iX \u2019s are CX(0). Therefore:\n1\nN \u03c4m(\u03a3) =\nmNCX(0)\nmN = P (X)\nSince \u03a3iX \u2019s are principal submatrices of \u03a3X0:N\u22121 therefore by corollary lemma 3\n\u2016\u03a3\u2016 = \u03c1(\u03a3) = \u2016 1\nN\nN\u22121\u2211\ni=0\n\u03a3iX\u2016 \u2264 1\nN\nN\u22121\u2211\ni=0\n\u2016\u03a3iX\u2016 \u2264 \u03c1(\u03a3X0:N\u22121).\nBecause CX(\u03c4)\u2019s are absolutely summable we apply lemma lemma 4 and we get\n\u03c1(\u03a3X0:N\u22121) \u2264 max \u03bd Sxx(\u03bd),\nsuch that inequality eq. (19) can be rewritten\n| \u03c4N (\u03a3 U Y0:N\u22121 )\nP (X)\u2016b\u201622 \u2212 1| \u2264 2\n\u03b5\nP (X) \u2016\u03a3\u2016\nwhich completes the proof."}, {"heading": "8 Proof of Theorem 2", "text": "In this section we give a proof that the TDR (see eq. eq. (11)) asymptotically approaches the SDR (see eq. eq. (5)). We first state and prove two lemmas that are used to derive this result. As before suppose {Xt} and {Yt} are given input and output of an LTI filter that are related through the impulse response function {ht}. According to the definition of the truncated linear systems\n(see definition definition 2) of order N for the linear system above we get the following matrix relationship:\n  Y \u2032\u2212N Y \u2032\u2212N+1 ...\nY \u2032N\u22122 Y \u2032N\u22121\n  =   h0 h\u22121 \u00b7 \u00b7 \u00b7 h\u22122N+1 h1 h0 \u00b7 \u00b7 \u00b7 h\u22122N+2 ...\nh2N\u22122 h2N\u22123 \u00b7 \u00b7 \u00b7 h\u22121 h2N\u22121 h2N\u22122 \u00b7 \u00b7 \u00b7 h0\n    X\u2212N X\u2212N+1 ...\nXN\u22122 XN\u22121\n  .\nIf we name the vector on the left as yN , the matrix as H N and the right vector as xN then the associated TDR yields:\nrxN\u2192yN = \u03c4N (\u03a3yN )\n\u03c4N (\u03a3xN )\u03c42N (H NHN\nT )\n(20)\nDefine TN := \u03c42N (H NHN \u22a4 ). Now we show that TN converges to \u2016h\u2016 2 2 the energy of the impulse response.\nLemma 5. Assume \u2016h\u201622 < +\u221e, then\nlim N\u2192+\u221e\nTN = \u2016h\u2016 2 2\nProof. First lets simplify the expression for TN :\nTN := \u03c42N (H NHN \u22a4 ) =\n1\n2N\n\u2211\ni,j\n[HN ]2ij =\n2N\u22121\u2211\nk=\u22122N+1\n|hk| 2 2N \u2212 |k|\n2N =\n\u22121\u2211\nk=\u22122N+1\n|hk| 2 2N \u2212 |k|\n2N +\n2N\u22121\u2211\nk=0\n|hk| 2 2N \u2212 |k|\n2N . (21)\nIt is easy to see that TN is an increasing sequence of N . Moreover it is bounded by\n\u221e\u2211\n\u2212\u221e\n|hk| 2 < \u221e.\nTherefore this series converges. In order to show that it converges to \u2016h\u20162, we first notice that for a given \u03b5, there exist m0 \u2208 N such that\n\u2200m > m0 |\nm\u2211\nk=\u2212m\n|hk| 2 \u2212 \u2016h\u20162| < \u03b5. (22)\nNow take Nm0 > m02\nm0+1|hm0 | 2\n\u03b5 . We have\nNm0 > m02\nm0+1|hm0 | 2\n\u03b5 \u21d2\n|hm0 | 2m0\n2Nm0 <\n\u03b5\n2m0+2 .\nSame can be done for any 0 \u2264 k \u2264 m0, i.e. there exist Nk such that:\n|hk| 2k\n2Nk <\n\u03b5\n2k+2\nNow take Nmax = max{N0, N1, ..., Nm0}+ 1. Then obviously we get:\n\u2223\u2223\u2223\u2223|hk|2 \u2212 |hk| 2(2Nmax \u2212 k)\n2Nmax\n\u2223\u2223\u2223\u2223 < \u03b5\n2k+2\nAnd therefore:\nm0\u2211\nk=0\n\u2223\u2223\u2223\u2223|hk|2 \u2212 |hk| 2(2Nmax \u2212 k)\n2Nmax\n\u2223\u2223\u2223\u2223 < m0\u2211\nk=0\n\u03b5\n2k+2 <\n\u03b5 2 . (23)\nSimilar results hold for the first sum term in (eq. (21)) and by taking the maximum of two Nmax\u2019s (say N \u2032max) and considering the fact that TN is increasing and by the application of triangular inequality for (eq. (22)), we can easily infer that\n\u2200N > N \u2032max \u2223\u2223TN \u2212 \u2016h\u20162 \u2223\u2223 < \u03b5.\nIn order to get the main result, we also need to prove that Y \u2032k\u2019s in (section 8) are asymptotically\nconverging to Yk\u2019s in the following sense:\nLemma 6. Suppose an LTI filter S with zero mean weakly stationary processes as input ({Xt}) and output ({Yt}) and impulse response function {ht} has been given. Then for the truncated linear systems we have:\nlim N\u2192\u221e |\u03c4(\u03a3Y\u2212N :N\u22121)\u2212 \u03c4(\u03a3Y \u2032 \u2212N :N\u22121 )| = 0,\nProof. For simplicity of calculations we name 2N dimensional random vectors Y \u2032\u2212N :N\u22121 and Y\u2212N :N\u22121 as Y \u2032 and Y and their covariance matrices with \u03a3Y \u2032 and \u03a3Y respectively. Then we have: \u2223\u2223\u2223\u03c4(\u03a3Y\u2212N :N\u22121)\u2212 \u03c4(\u03a3Y \u2032 \u2212N :N\u22121 ) \u2223\u2223\u2223 = \u2223\u2223\u2223\u03c4(E(Y Y \u22a4))\u2212 \u03c4(E(Y \u2032Y \u2032\u22a4)) \u2223\u2223\u2223 \u2217= 1\n2N\n\u2223\u2223E(Y \u22a4Y )\u2212 E(Y \u2032\u22a4Y \u2032) \u2223\u2223 =\n1\n2N\n\u2223\u2223E ( (Y \u2212 Y \u2032)\u22a4(Y + Y \u2032) )\u2223\u2223 \u2264 1 2N E \u2223\u2223(Y \u2212 Y \u2032)\u22a4(Y + Y \u2032) \u2223\u2223 \u2264 1\n2N E\n(\u221a (Y \u2212 Y \u2032)\u22a4(Y \u2212 Y \u2032)\u00d7 \u221a (Y + Y \u2032)\u22a4(Y + Y \u2032) ) \u2264\n1\n2N\n\u221a E((Y \u2212 Y \u2032)\u22a4(Y \u2212 Y \u2032)) \u00d7 \u221a E((Y + Y \u2032)\u22a4(Y + Y \u2032)) =\n\u221a 1\n2N E((Y \u2212 Y \u2032)\u22a4(Y \u2212 Y \u2032))\u00d7\n\u221a 1\n2N E((Y + Y \u2032)\u22a4(Y + Y \u2032))\n\u2217\u2217 = \u221a \u03c4(\u03a3Y \u2212Y \u2032) \u221a \u03c4(\u03a3Y +Y \u2032)\nwhere (*) and (**) follows from the fact that one can take trace (or normalized trace) into expectation and vice versa, and moreover from the fact that tr(AB) = tr(BA) for any two matrices\nthat their multiplication is well defined. The inequalities are the result of the application of Cauchy-Schwartz inequality for covariances of random variables. First we show that \u221a \u03c4(\u03a3Y +Y \u2032) is bounded as a function of N . Define {h (j) t } as follows\nh (j) t =\n{ 2ht if \u2212N \u2264 t+ j \u2264 N \u2212 1\nht otherwise .\nWe can bound each element of diagonal of \u03a3Y +Y \u2032 as follows\n[\u03a3Y +Y \u2032 ]jj = E [ (Yj + Y \u2032 j ) 2 ] = E [ ( \u221e\u2211\nl=\u2212\u221e\nXj\u2212lh (j) l )\n2 ] \u2264 E [ ( \u221e\u2211\nl=\u2212\u221e\n|Xj\u2212l||h (j) l |)\n2 ] \u2264\n4E [ ( \u221e\u2211\nl=\u2212\u221e\n|Xj\u2212l||hl|) 2 ] = 4CY (0),\nand therefore \u03c4(\u03a3Y +Y \u2032) is bounded.\nNow we show that each element of diagonal of \u03a3Y \u2212Y \u2032 tends to zero when N tends to infinity\nwhich will complete the proof. With overload of notation, in this case define {h (j) t } as follows\nh (j) t =\n{ 0 if \u2212N \u2264 t+ j \u2264 N \u2212 1\nht otherwise.\nThen for the j-th element of diagonal of \u03a3Y\u2212Y \u2032 we have\n[\u03a3Y \u2212Y \u2032 ]jj = E [ (Yj \u2212 Y \u2032 j ) 2 ] = E [ ( \u221e\u2211\nl=\u2212\u221e\nXj\u2212lh (j) l )\n2 ] = E [ ( \u2211\nl\u2265N\u2212j l<\u2212N\u2212j\nXj\u2212lhl) 2 ]\nSince autocorrelation function attains its maximum at t = 0 and\n\u2200i, j \u2208 Z, E(XiXj) \u2264 \u221a E(X2i )E(X 2 j )\nwe get:\n\u2200i, j \u2208 Z, E(XiXj) \u2264 E(X 2 0 ).\nAs a result we have:\n[\u03a3Y\u2212Y \u2032 ]jj = E [ ( \u2211\nl\u2265N\u2212j l<\u2212N\u2212j\nXj\u2212lhl) 2 ] \u2264\n\u2211\nl,l\u2032\u2265N\u2212j l,l\u2032<\u2212N\u2212j\nE(X20 )hlhl\u2032 = E(X 2 0 )\n\u2211\nl,l\u2032\u2265N\u2212j l,l\u2032<\u2212N\u2212j\nhlhl\u2032 \u2264\nE(X20 )( \u2211\nl\u2265N\u2212j l<\u2212N\u2212j\nhl) 2 \u2264 E(X20 )(\n\u2211\nl\u2265N\u2212j l<\u2212N\u2212j\n|hl|) 2\nNow since {ht} is absolutely convergent, it follows that [\u03a3Y\u2212Y \u2032 ]jj can be arbitrarily reduced by increasing N . Then it follows that \u03c4(\u03a3Y \u2212Y \u2032) approaches to zero when N tends to infinity.\nFinally to complete the proof of the theorem regarding the asymptotic behaviour of trace condition in the truncated linear systems and the equivalence of trace condition (see postulate postulate 2) to SIC, we need one of the convergence theorems due to Szego\u0308:\nTheorem 4 (Szego\u0308\u2019s convergence theorem). [9] Let f : [\u2212 12 , 1 2 ) \u2192 R f \u2208 L 1 be a bounded function and suppose tk\u2019s are its Fourier series coefficients, i.e.\ntk =\n\u222b 1 2\n\u2212 1 2\nf(\u03bd)ei2\u03c0k\u03bdd\u03bd, t \u2208 Z.\nConsider Toeplitz matrices Tn defined as\n[Tn]ij = ti\u2212j i, j \u2208 {0, ..., n\u2212 1}\nwith eigenvalues \u03c4n,k(0 \u2264 k \u2264 n \u2212 1). Then if Tn\u2019s are Hermitian, i.e. ti = t\u0304i for any i, then for any continuous function F we have:\nlim n\u2192\u221e\n1 n\nn\u22121\u2211\nk=0\nF (\u03c4n,k) =\n\u222b 1 2\n\u2212 1 2\nF (f(\u03bd))d\u03bd\nWe are ready to state our convergence theorem:\nTheorem 5. For a given truncated linear time series, rX\u2032 N \u2192Y\u2032 N asymptotically approaches to the spectral values of time series on infinite domain. As a result the spectral density based estimator coincides with the trace based estimator in the limit, and more precisely\nlim N\u2192\u221e \u03c4(\u03a3xN) =\n1 2\u222b\n\u2212 1 2\nSxx(\u03bd)d\u03bd, lim N\u2192\u221e \u03c4(\u03a3yN) =\n1 2\u222b\n\u2212 1 2\nSyy(\u03bd)d\u03bd,\nand lim N\u2192\u221e TN =\n1 2\u222b\n\u2212 1 2\n|h\u0302(\u03bd)|2d\u03bd,\nwhere TN is defined as in (eq. (21)). And eventually:\nlim n\u2192\u221e rX\u2032 N \u2192Y\u2032 N = \u03c1X\u2192Y lim n\u2192\u221e rY\u2032 N \u2192X\u2032 N = \u03c1Y\u2192X\nProof. Both \u03a3xN and \u03a3yN are hermitian Toeplitz matrices and based on theorem theorem 4 where F has been chosen as identity function and also applying lemma lemma 6 we get:\nlim N\u2192\u221e \u03c4(\u03a3xN) =\n1 2\u222b\n\u2212 1 2\nSxx(\u03bd)d\u03bd (24)\nlim N\u2192\u221e \u03c4(\u03a3yN) =\n1 2\u222b\n\u2212 1 2\nSyy(\u03bd)d\u03bd (25)\nMoreover by Plancherel\u2019s theorem and lemma lemma 5 it follows that:\nlim N\u2192\u221e\nTN = \u2016h\u2016 2 2 =\n1 2\u222b\n\u2212 1 2\n|h\u0302(\u03bd)|2d\u03bd (26)\nThis theorem therefore shows that the trace ratios calculated for windowed version of time series are nothing but estimates of the spectral ratios and therefore justifies that these two different methods for causal inference are indeed consistent with each other."}], "references": [], "referenceMentions": [], "year": 2015, "abstractText": "<lb>Inferring a cause from its effect using observed time series data is a major challenge in natural<lb>and social sciences. Assuming the effect is generated by the cause trough a linear system,<lb>we propose a new approach based on the hypothesis that nature chooses the \u201ccause\u201d and the<lb>\u201cmechanism that generates the effect from the cause\u201d independent of each other. We therefore<lb>postulate that the power spectrum of the time series being the cause is uncorrelated with the<lb>square of the transfer function of the linear filter generating the effect. While most causal<lb>discovery methods for time series mainly rely on the noise, our method relies on asymmetries of<lb>the power spectral density properties that can be exploited even in the context of deterministic<lb>systems. We describe mathematical assumptions in a deterministic model under which the<lb>causal direction is identifiable with this approach. We also discuss the method\u2019s performance<lb>under the additive noise model and its relationship to Granger causality. Experiments show<lb>encouraging results on synthetic as well as real-world data. Overall, this suggests that the<lb>postulate of Independence of Cause and Mechanism is a promising principle for causal inference<lb>on empirical time series.", "creator": "LaTeX with hyperref package"}}}