{"id": "1503.01673", "review": {"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "5-Mar-2015", "title": "High Dimensional Bayesian Optimisation and Bandits via Additive Models", "abstract": "Bayesian Optimisation (BO) is a technique used in optimising a $D$-dimensional function which is typically expensive to evaluate. While there have been many successes for BO in low dimensions, scaling it to high dimensions has been a notoriously difficult problem. Existing literature on the subject are under very restrictive settings. In this paper, we identify two key challenges in this endeavour. We tackle these challenges by assuming an additive structure for the function. This setting is substantially more expressive and contains a richer class of functions than previous work. In our theoretical analysis we prove that for additive functions the regret has only linear (as opposed to exponential) dependence on $D$ even though the function depends on all $D$ dimensions. We also demonstrate several other statistical and computational benefits in our framework. Empirically via synthetic examples, a scientific simulation and a face detection problem we demonstrate that our method outperforms naive BO on additive functions and on several examples when the function is not additive. Using these models, we demonstrate the ability to predict the likelihood that an additive function will outperform $D$ over a given time frame. In addition to this paper, we present a general theory of optimization in a computational model based on three principles: a computational model and an analysis.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "histories": [["v1", "Thu, 5 Mar 2015 15:56:08 GMT  (2541kb,D)", "https://arxiv.org/abs/1503.01673v1", null], ["v2", "Fri, 12 Jun 2015 21:59:15 GMT  (2853kb,D)", "http://arxiv.org/abs/1503.01673v2", "Proceedings of The 32nd International Conference on Machine Learning 2015"], ["v3", "Fri, 13 May 2016 15:31:03 GMT  (2854kb,D)", "http://arxiv.org/abs/1503.01673v3", "Proceedings of The 32nd International Conference on Machine Learning 2015"]], "reviews": [], "SUBJECTS": "stat.ML cs.LG", "authors": ["kirthevasan kandasamy", "jeff g schneider", "barnab\u00e1s p\u00f3czos"], "accepted": true, "id": "1503.01673"}, "pdf": {"name": "1503.01673.pdf", "metadata": {"source": "META", "title": "High Dimensional Bayesian Optimisation and Bandits via Additive Models", "authors": ["Kirthevasan Kandasamy", "Jeff Schneider", "Barnab\u00e1s P\u00f3czos"], "emails": ["KANDASAMY@CS.CMU.EDU", "SCHNEIDE@CS.CMU.EDU", "BAPOCZOS@CS.CMU.EDU"], "sections": [{"heading": "1. Introduction", "text": "In many applications we are tasked with zeroth order optimisation of an expensive to evaluate function f in D dimensions. Some examples are hyper parameter tuning in expensive machine learning algorithms, experiment design, optimising control strategies in complex systems, and scientific simulation based studies. In such applications, f is a blackbox which we can interact with only by querying for the value at a specific point. Related to optimisation is the bandits problem arising in applications such as online advertising and reinforcement learning. Here the objective is to maximise the cumulative sum of all queries. In either case, we need to find the optimum of f using as few queries as possible by managing exploration and exploitation.\nProceedings of the 32nd International Conference on Machine Learning, Lille, France, 2015. JMLR: W&CP volume 37. Copyright 2015 by the author(s).\nBayesian Optimisation (Mockus & Mockus, 1991) refers to a suite of methods that tackle this problem by modeling f as a Gaussian Process (GP). In such methods, the challenge is two fold. At time step t, first estimate the unknown f from the query value-pairs. Then use it to intelligently query at xt where the function is likely to be high. For this, we first use the posterior GP to construct an acquisition function \u03d5t which captures the value of the experiment at a point. Then we maximise \u03d5t to determine xt.\nGaussian process bandits and Bayesian optimisation (GPB/ BO) have been successfully applied in many applications such as tuning hyperparameters in learning algorithms (Snoek et al., 2012; Bergstra et al., 2011; Mahendran et al., 2012), robotics (Lizotte et al., 2007; Martinez-Cantin et al., 2007) and object tracking (Denil et al., 2012). However, all such successes have been in low (typically < 10) dimensions (Wang et al., 2013). Expensive high dimensional functions occur in several problems in fields such as computer vision (Yamins et al., 2013), antenna design (Hornby et al., 2006), computational astrophysics (Parkinson et al., 2006) and biology (Gonzalez et al., 2014). Scaling GPB/ BO methods to high dimensions for practical problems has been challenging. Even current theoretical results suggest that GPB/ BO is exponentially difficult in high dimensions without further assumptions (Srinivas et al., 2010; Bull, 2011). To our knowledge, the only approach to date has been to perform regular GPB/ BO on a low dimensional subspace. This works only under strong assumptions.\nWe identify two key challenges in scaling GPB/ BO to high dimensions. The first is the statistical challenge in estimating the function. Nonparametric regression is inherently difficult in high dimensions with known lower bounds depending exponentially in dimension (Gyo\u0308rfi et al., 2002). The often exponential sample complexity for regression is invariably reflected in the regret bounds for GPB/ BO. The second is the computational challenge in maximising \u03d5t. Commonly used global optimisation heuristics used to maximise \u03d5t themselves require computation exponential in dimension. Any attempt to scale GPB/ BO to high dimensions must effectively address these two concerns.\nar X\niv :1\n50 3.\n01 67\n3v 3\n[ st\nat .M\nL ]\n1 3\nM ay\n2 01\nIn this work, we embark on this challenge by treating f as an additive function of mutually exclusive lower dimensional components. Our contributions in this work are:\n1. We present the Add-GP-UCB algorithm for optimisation and bandits of an additive function. An attractive property is that we use an acquisition function which is easy to optimise in high dimensions.\n2. In our theoretical analysis we bound the regret for Add-GP-UCB. We show that it has only linear dependence on the dimension D when f is additive1.\n3. Empirically we demonstrate that Add-GP-UCB outperforms naive BO on synthetic experiments, an astrophysical simulator and the Viola and Jones face detection problem. Furthermore Add-GP-UCB does well on several examples when the function is not additive.\nA Matlab implementation of our methods is available online at github.com/kirthevasank/add-gp-bandits."}, {"heading": "2. Related Work", "text": "GPB/ BO methods follow a family of GP based active learning methods which select the next experiment based on the posterior (Osborne et al., 2012; Ma et al., 2015; Kandasamy et al., 2015). In the GPB/ BO setting, common acquisition functions include Expected improvement (Mockus, 1994), probability of improvement (Jones et al., 1998), Thompson sampling (Thompson, 1933) and upper confidence bound (Auer, 2003). Of particular interest to us, is the Gaussian process upper confidence bound (GPUCB). It was first proposed and analysed in the noisy setting by Srinivas et al. (2010) and extended to the noiseless case by de Freitas et al. (2012). Some literature studies variants, such as combining several acquisition functions (Hoffman et al., 2011) and querying in batches (Azimi et al., 2010).\nTo our knowledge, most literature for GPB/ BO in high dimensions are in the setting where the function varies only along a very low dimensional subspace (Chen et al., 2012; Wang et al., 2013; Djolonga et al., 2013). In these works, the authors do not encounter either challenge as they perform GPB/ BO in either a random or carefully selected lower dimensional subspace. However, assuming that the problem is an easy (low dimensional) one hiding in a high dimensional space is often too restrictive. Indeed, our experimental results confirm that such methods perform poorly on real applications when the assumptions are not met. While our additive assumption is strong in its own right, it is considerably more expressive. It is more\n1Post-publication it was pointed out to us that there was a bug in our analysis. We are working on resolving it and will post an update shortly. See Section 6 for more details.\ngeneral than the setting in Chen et al. (2012). Even though it does not contain the settings in Djolonga et al. (2013); Wang et al. (2013), unlike them, we still allow the function to vary along the entire domain.\nUsing an additive structure is standard in high dimensional regression literature both in the GP framework and otherwise. Hastie & Tibshirani (1990); Ravikumar et al. (2009) treat the function as a sum of one dimensional components. Our additive framework is more general. Duvenaud et al. (2011) assume a sum of functions of all combinations of lower dimensional coordinates. These literature argue that using an additive model has several advantages even if f is not additive. It is a well understood notion in statistics that when we only have a few samples, using a simpler model to fit our data may give us a better trade off for estimation error against approximation error. This observation is crucial: in many applications for Bayesian optimisation we are forced to work in the low sample regime since calls to the blackbox are expensive. Though the additive assumption is biased for nonadditive functions, it enables us to do well with only a few samples. While we have developed theoretical results only for additive f , empirically we show that our additive model outperforms naive GPB/ BO even when the underlying function is not additive.\nAnalyses of GPB/ BO methods focus on the query complexity of f which is the dominating cost in relevant applications. It is usually assumed that \u03d5t can be maximised to arbitrary precision at negligible cost. Common techniques to maximise \u03d5t include grid search, Monte Carlo and multistart methods (Brochu et al., 2010). In our work we use the Dividing Rectangles (DiRect) algorithm of Jones et al. (1993). While these methods are efficient in low dimensions they require exponential computation in high dimensions. It is widely acknowledged in the community that this is a critical bottleneck in scaling GPB/ BO to high dimensions (de Freitas, 2014). While we still work in the paradigm where evaluating f is expensive and characterise our theoretical results in terms of query complexity, we believe that assuming arbitrary computational power to optimise \u03d5t is too restrictive. For instance, in hyperparameter tuning the budget for determining the next experiment is dictated by the cost of the learning algorithm. In online advertising and robotic reinforcement learning we need to act in under a few seconds or real time.\nIn this manuscript, Section 3 formally details our problem and assumptions. We present Add-GP-UCB in Section 4 and our theoretical results in Section 4.3. All proofs are deferred to Appendix B. We summarize the regrets for AddGP-UCB and GP-UCB in Table 1. In Section 5 we present the experiments."}, {"heading": "3. Problem Statement & Set up", "text": "We wish to maximise a function f : X \u2192 R where X is a rectangular region in RD. We will assume w.l.o.g X = [0, 1]D. f may be nonconvex and gradient information is not available. We can interact with f only by querying at some x \u2208 X and obtain a noisy observation y = f(x)+ . Let an optimum point be x\u2217 = argmaxx\u2208X f(x). Suppose at time t we choose to query at xt. Then we incur instantaneous regret rt = f(x\u2217) \u2212 f(xt). In the bandit setting, we are interested in the cumulative regret RT = \u2211T t=1 rt = \u2211T t=1 f(x\u2217) \u2212 f(xt), and in the optimisation setting we are interested in the simple regret ST = mint\u2264T rt = f(x\u2217) \u2212 maxxt f(xt). For a bandit algorithm, a desirable property is to have no regret: limT\u2192\u221e 1 TRT = 0. Since ST \u2264 1 TRT , any such procedure is also a consistent procedure for optimisation.\nKey structural assumption: In order to make progress in high dimensions, we will assume that f decomposes into the following additive form,\nf(x) = f (1)(x(1)) + f (2)(x(2)) + \u00b7 \u00b7 \u00b7+ f (M)(x(M)). (1)\nHere each x(j) \u2208 X (j) = [0, 1]dj are lower dimensional components. We will refer to the X (j)\u2019s as \u201cgroups\u201d and the grouping of different dimensions into these groups {X (j)}Mj=1 as the \u201cdecomposition\u201d. The groups are disjoint \u2013 i.e. if we treat the elements of the vector x as a set, x(i)\u2229x(j) = \u2205. We are primarily interestd in the case when D is very large and the group dimensionality is bounded: dj \u2264 d D. We have D dM \u2265 \u2211 j dj . Paranthesised superscripts index the groups and a union over the groups denotes the reconstruction of the whole from the groups (e.g. x = \u22c3 j x (j) and X = \u22c3 j X (j)). xt denotes the point chosen by the algorithm for querying at time t. We will ignore logD terms in O(\u00b7) notation. Our theoretical analysis assumes that the decomposition is known but we also present a modified algorithm to handle unknown decompositions and non-additive functions.\nSome smoothness assumptions on f are warranted to make the problem tractable. A standard in the Bayesian paradigm is to assume f is sampled from a Gaussian Process (Rasmussen & Williams, 2006) with a covarince kernel \u03ba : X \u00d7 X \u2192 R and that \u223c N (0, \u03b72). Two commonly used kernels are the squared exponential (SE) \u03ba\u03c3,h and the Mate\u0301rn \u03ba\u03bd,h kernels with parameters (\u03c3, h) and (\u03bd, h) re-\nspectively. Writing r = \u2016x\u2212 x\u2032\u20162, they are defined as\n\u03ba\u03c3,h(x, x \u2032) = \u03c3 exp\n( \u2212r2\n2h2\n) , (2)\n\u03ba\u03bd,h(x, x \u2032) =\n21\u2212\u03bd\n\u0393(\u03bd)\n(\u221a 2\u03bdr\nh\n)\u03bd B\u03bd (\u221a 2\u03bdr\nh\n) . (3)\nHere \u0393, B\u03bd are the Gamma and modified Bessel functions. A principal convenience in modelling our problem via a GP is that posterior distributions are analytically tractable.\nIn keeping with this, we will assume that each f (j) is sampled from a GP, GP(\u00b5(j), \u03ba(j)) where the f (j)\u2019s are independent. Here, \u00b5(j) : X (j) \u2192 R is the mean and \u03ba(j) : X (j) \u00d7 X (j) \u2192 R is the covariance for f (j). W.l.o.g let \u00b5(j) = 0 for all j. This implies that f itself is sampled from a GP with an additive kernel \u03ba(x, x\u2032) = \u2211 j \u03ba (j)(x(j), x(j) \u2032 ). We state this formally for nonzero mean as we will need it for the ensuing discussion.\nObservation 1. Let f be defined as in Equation (1), where f (j) \u223c GP(\u00b5(j)(x), \u03ba(j)(x(i), x(j)\u2032)). Let y = f(x) + where \u223c N (0, \u03b72). Denote \u03b4(x, x\u2032) = 1 if x = x\u2032, and 0 otherwise. Then y \u223c GP(\u00b5(x), \u03ba(x, x\u2032) + \u03b72\u03b4(x, x\u2032)) where\n\u00b5(x) = \u00b5(1)(x(1)) + \u00b7 \u00b7 \u00b7+ \u00b5(M)(x(M)) (4)\n\u03ba(x, x\u2032) = \u03ba(1)(x(1), x(1) \u2032 ) + \u00b7 \u00b7 \u00b7+ \u03ba(M)(x(M), x(M) \u2032 ).\nWe will call a kernel such as \u03ba(j) which acts only on d variables a dth order kernel. A kernel which acts on all the variables is a Dth order kernel. Our kernel for f is a sum of M at most dth order kernels which, we will show, is statistically simpler than a Dth order kernel.\nWe conclude this section by looking at some seemingly straightforward approaches to tackle the problem. The first natural question is of course why not directly run GP-UCB using the additive kernel? Since it is simpler than a Dth order kernel we can expect statistical gains. While this is true, it still requires optimising \u03d5t inD dimensions to determine the next point which is expensive.\nAlternatively, for an additive function, we could adopt a sequential approach where we use 1/M fraction of our query budget to maximise the first group by keeping the rest of the coordinates constant. Then we proceed to the second\ngroup and so on. While optimising a d dimensional acquisition function is easy, this approach is not desirable for several reasons. First, it will not be an anytime algorithm as we will have to pre-allocate our query budget to maximise each group. Once we proceed to a new group we cannot come back and optimise an older one. Second, such an approach places too much faith in the additive assumption. We will only have explored M d-dimensional hyperplanes in the entire space. Third, it is not suitable as a bandit algorithm as we suffer high regret until we get to the last group. We further elaborate on the deficiencies of this and other sequential approaches in Appendix A.2."}, {"heading": "4. Algorithm", "text": "Under an additive assumption, our algorithm has two components. First, we obtain the posterior GP for each f (j) using the query-value pairs until time t. Then we maximise a d dimensional GP-UCB-like acquisition function on each GP to construct the next query point. Since optimising \u03d5t depends exponentially in dimension, this is cheaper than optimising one acquisition on the combined GP."}, {"heading": "4.1. Inference on Additive GPs", "text": "Typically in GPs, given noisy labels, Y = {y1, . . . , yn} at points X = {x1, . . . , xn}, we are interested in inferring the posterior distribution for f\u2217 = f(x\u2217) at a new point x\u2217. In our case though, we will be primarily interested in the distribution of f (j)\u2217 = f (j)(x (j) \u2217 ) conditioned on X,Y . We have illustrated this graphically in Figure 1. The joint distribution of f (j)\u2217 and Y can be written as\n( f\n(j) \u2217 Y\n) \u223c N ( 0, [ \u03ba(j)(x (j) \u2217 , x (j) \u2217 ) \u03ba (j)(x (j) \u2217 , X (j))\n\u03ba(j)(X(j), x (j) \u2217 ) \u03ba(X,X) + \u03b7 2In\n]) .\nThe pth element of \u03ba(j)(X(j), x(j)\u2217 ) \u2208 Rn is \u03ba(x(j)p , x(j)\u2217 ) and the (p, q)th element of \u03ba(X,X) \u2208 Rn\u00d7n is \u03ba(xp, xq). We have used the fact Cov(f (i) \u2217 , yp) =\nCov(f (i) \u2217 , \u2211 j f (j)(x (j) p ) + \u03b72 ) = Cov(f (i) \u2217 , f (i)(x (i) p )) = \u03ba(i)(x (i) \u2217 , x (i) p ) as f (j) \u22a5 f (i),\u2200i 6= j. By writing \u2206 = \u03ba(X,X) + \u03b72In \u2208 Rn\u00d7n, the posterior for f (j)\u2217 is,\nf (j) \u2217 |x\u2217, X, Y \u223c N ( \u03ba(j)(x (j) \u2217 , X (j))\u2206\u22121Y, (5)\n\u03ba(j)(x (j) \u2217 , x (j) \u2217 )\u2212 \u03ba(j)(x(j)\u2217 , X(j))\u2206\u22121\u03ba(j)(X,x(j)) ) 4.2. The Add-GP-UCB Algorithm\nIn GPB/ BO algorithms, at each time step t we maximise an acquisition function \u03d5t to determine the next point: xt = argmaxx\u2208X \u03d5t(x). The acquisition function is itself constructed using the posterior GP. The GP-UCB acquisition function, which we focus on here is,\n\u03d5t(x) = \u00b5t\u22121(x) + \u03b2 1/2 t \u03c3t\u22121(x).\nIntuitively, the \u00b5t\u22121 term in the GP-UCB objective prefers points where f is known to be high, the \u03c3t\u22121 term prefers points where we are uncertain about f and \u03b21/2t negotiates the tradeoff. The former contributes to the \u201cexploitation\u201d facet of our problem, in that we wish to have low instantaneous regret. The latter contributes to the \u201cexploration\u201d facet since we also wish to query at regions we do not know much about f lest we miss out on regions where f is high. We provide a brief summary of GP-UCB and its theoretical properties in Appendix A.1.\nAs we have noted before, maximising \u03d5t which is typically multimodal to obtain xt is itself a difficult problem. In any grid search or branch and bound methods such as DiRect, maximising a function to within \u03b6 accuracy, requires O(\u03b6\u2212D) calls to \u03d5t. Therefore, for large D maximising \u03d5t is extremely difficult. In practical settings, especially in situations where we are computationally constrained, this poses serious limitations for GPB/ BO as we may not be able to optimise \u03d5t to within a desired accuracy.\nFortunately, in our setting we can be more efficient. We propose an alternative acquisition function which applies to an additive kernel. We define the Additive Gaussian Process Upper Confidence Bound (Add-GP-UCB) to be\n\u03d5\u0303t(x) = \u00b5t\u22121(x) + \u03b2 1/2 t M\u2211 j=1 \u03c3 (j) t\u22121(x (j)). (6)\nWe immediately see that we can write \u03d5\u0303t as a sum of functions on orthogonal domains: \u03d5\u0303t(x) = \u2211 j \u03d5\u0303 (j) t (x (j)) where \u03d5\u0303(j)t (x (j)) = \u00b5 (j) t\u22121(x (j)) + \u03b2 1/2 t \u03c3 (j) t\u22121(x\n(j)). This means that \u03d5\u0303t can be maximised by maximising each \u03d5\u0303\n(j) t separately on X (j). As we need to solve M at\nmost d dimensional optimisation problems, it requires only O(Md+1\u03b6\u2212d) calls to the utility function in total \u2013 far more favourable than maximising \u03d5t.\nSince the cost for maximising the acquisition function is a key theme in this paper let us delve into this a bit more. One call to \u03d5t requires O(Dt2) effort. For \u03d5\u0303t we need M calls each requiring O(djt2) effort. So both \u03d5t and \u03d5\u0303t require the same effort in this front. For \u03d5t, we need to know the posterior for only f whereas for \u03d5\u0303t we need to know the posterior for each f (j). However, the brunt of the work in obtaining the posterior is the O(t3) effort in inverting the t\u00d7tmatrix \u2206 in (5) which needs to be done for both \u03d5t and \u03d5\u0303t. For \u03d5\u0303t, we can obtain the inverse once and reuse it M times, so the cost of obtaining the posterior isO(t3+Mt2). Since the number of queries needed will be super linear in D and hence M , the t3 term dominates. Therefore obtaining each posterior f (j) is only marginally more work than obtaining the posterior for f . Any difference here is easily offset by the cost for maximising the acquisition function.\nThe question remains then if maximising \u03d5\u0303t would result in low regret. Since \u03d5t and \u03d5\u0303t are neither equivalent nor have the same maximiser it is not immediately apparent that this should work. Nonetheless, intuitively this seems like a reasonable scheme since the \u2211 j \u03c3 (j) t\u22121 term captures some notion of the uncertainty and contributes to exploration. In Theorem 5 we show that this intuition is reasonable \u2013 maximising \u03d5\u0303t achieves the same rates as \u03d5t for cumulative and simple regrets if the kernel is additive.\nWe summarise the resulting algorithm in Algorithm 1. In brief, at time step t, we obtain the posterior distribution for f (j) and maximise \u03d5\u0303(j)t to determine the coordinates x (j) t . We do this for each j and then combine them to obtain xt.\nAlgorithm 1 Add-GP-UCB Input: Kernels \u03ba(1), . . . , \u03ba(M), Decomposition (X (j))Mj=1 \u2022 D0 \u2190 \u2205, \u2022 for j = 1, . . . ,M , (\u00b5(j)0 , \u03ba (j) 0 )\u2190 (0, \u03ba(j)).\n\u2022 for t = 1, 2, . . . 1. for j = 1, . . . ,M ,\nx (j) t \u2190 argmaxz\u2208X (j) \u00b5 (j) t\u22121(z) + \u221a \u03b2t\u03c3 (j) t\u22121(z)\n2. xt \u2190 \u22c3M j=1 x (j) t . 3. yt \u2190 Query f at xt. 4. Dt = Dt\u22121 \u222a {(xt,yt)}. 5. Perform Bayesian posterior updates conditioned\non Dt to obtain \u00b5(j)t , \u03c3 (j) t for j = 1, . . . ,M ."}, {"heading": "4.3. Main Theoretical Results", "text": "Now, we present our main theoretical contributions. We bound the regret for Add-GP-UCB under different kernels. Following Srinivas et al. (2010), we first bound the\nstatistical difficulty of the problem as determined by the kernel. We show that under additive kernels the problem is much easier than when using a full Dth order kernel. Next, we show that the Add-GP-UCB algorithm is able to exploit the additive structure and obtain the same rates as GP-UCB. The advantage to using Add-GP-UCB is that it is much easier to optimise the acquisition function. For our analysis, we will need Assumption 2 and Definition 3.\nAssumption 2. Let f be sampled from a GP with kernel \u03ba. \u03ba(\u00b7, x) is L-Lipschitz for all x. Further, the partial derivatives of f satisfies the following high probability bound. There exists constants a, b > 0 such that,\nP (\nsup x \u2223\u2223\u2223\u2202f(x) \u2202xi \u2223\u2223\u2223 > J) \u2264 ae\u2212(J/b)2 . The Lipschitzian condition is fairly mild and the latter condition holds for four times differentiable stationary kernels such as the SE and Mate\u0301rn kernels for \u03bd > 2 (Ghosal & Roy, 2006). Srinivas et al. (2010) showed that the statistical difficulty of GPB/ BO is determined by the Maximum Information Gain as defined below. We bound this quantity for additive SE and Mate\u0301rn kernels in Theorem 4. This is our first main theorem.\nDefinition 3. (Maximum Information Gain) Let f \u223c GP(\u00b5, \u03ba), yi = f(xi) + where \u223c N (0, \u03b72). Let A = {x1, . . . , xT } \u2282 X be a finite subset, fA denote the function values at these points and yA denote the noisy observations. Let I be the Shannon Mutual Information. The Maximum Information Gain between yA and fA is\n\u03b3T = max A\u2282X ,|A|=T I(yA; fA).\nTheorem 4. Assume that the kernel \u03ba has the additive form of (4), and that each \u03ba(j) satisfies Assumption 2. W.l.o.g assume \u03ba(x, x\u2032) = 1. Then,\n1. If each \u03ba(j) is a dthj order squared exponential kernel (2) where dj \u2264 d, then \u03b3T \u2208 O(Ddd(log T )d+1).\n2. If each \u03ba(j) is a dthj order Mate\u0301rn kernel (3) where dj \u2264 d and \u03bd > 2, then \u03b3T \u2208 O(D2dT d(d+1) 2\u03bd+d(d+1) log(T )).\nWe use bounds on the eigenvalues of the SE and Mate\u0301rn kernels from Seeger et al. (2008) and a result from Srinivas et al. (2010) which bounds the information gain via the eigendecay of the kernel. We bound the eigendecay of the sum \u03ba via M and the eigendecay of a single \u03ba(j). The complete proof is given in Appendix B.1. The important observation is that the dependence on D is linear for an additive kernel. In contrast, for a Dth order kernel this is exponential (Srinivas et al., 2010).\nNext, we present our second main theorem which bounds the regret for Add-GP-UCB for an additive kernel as given in Equation 4.\nTheorem 5. Suppose f is constructed by sampling f (j) \u223c GP(0, \u03ba(j)) for j = 1, . . . ,M and then adding them. Let all kernels \u03ba(j) satisfy assumption 2 for some L, a, b. Further, we maximise the acquisition function \u03d5\u0303t to within \u03b60t \u22121/2 accuracy at time step t. Pick \u03b4 \u2208 (0, 1) and choose\n\u03b2t = 2 log\n( M\u03c02t2\n2\u03b4\n) + 2d log ( Dt3 ) \u2208 O (d log t) .\nThen, Add-GP-UCB attains cumulative regret RT \u2208 O (\u221a D\u03b3TT log T ) and hence simple regret ST \u2208\nO (\u221a D\u03b3T log T/T ) . Precisely, with probability > 1\u2212 \u03b4,\n\u2200T \u2265 1, RT \u2264 \u221a 8C1\u03b2TMT\u03b3t + 2\u03b60 \u221a T + C2.\nwhere C1 = 1/ log(1 + \u03b7\u22122) and C2 is a constant depending on a, b, D, \u03b4, L and \u03b7.\nPart of our proof uses ideas from Srinivas et al. (2010). We show that \u2211 j \u03b2t\u03c3 (j) t\u22121(\u00b7) forms a credible interval for f(\u00b7) about the posterior mean \u00b5t(\u00b7) for an additive kernel in Add-GP-UCB. We relate the regret to this confidence set using a covering argument. We also show that our regret doesn\u2019t suffer severely if we only approximately optimise the acquisition provided that the accuracy improves at rate O(t\u22121/2). For this we establish smoothness of the posterior mean. The correctness of the algorithm follows from the fact that Add-GP-UCB can be maximised by individually maximising \u03d5\u0303(j)t on each X (j). The complete proof is given in Appendix B.2. When we combine the results in Theorems 4 and 5 we obtain the rates given in Table 12.\nOne could consider alternative lower order kernels \u2013 one candidate is the sum of all possible dth order kernels (Duvenaud et al., 2011). Such a kernel would arguably allow us to represent a larger class of functions than our kernel in (4). If, for instance, we choose each of them to be a SE kernel, then it can be shown that \u03b3T \u2208 O(Dddd+1(log T )d+1). Even though this is worse than our kernel in poly(D) factors, it is still substantially better than using a Dth order kernel. However, maximising the corresponding utility function, either of the form \u03d5t or \u03d5\u0303t, is still a D dimensional problem. We reiterate that what renders our algorithm attractive in large D is not just the statistical gains due to the simpler kernel. It is also the fact that our acquisition function can be efficiently maximised."}, {"heading": "4.4. Practical Considerations", "text": "Our practical implementation differs from our theoretical analysis in the following aspects.\n2See Footnote 1.\nChoice of \u03b2t: \u03b2t as specified by Theorems 5, usually tends to be conservative in practice (Srinivas et al., 2010). For good empirical performance a more aggressive strategy is required. In our experiments, we set \u03b2t = 0.2d log(2t) which offered a good tradeoff between exploration and exploitation. Note that this captures the correct dependence on D, d and t in Theorems 5 and 6.\nData dependent prior: Our analysis assumes that we know the GP kernel of the prior. In reality this is rarely the case. In our experiments, we choose the hyperparameters of the kernel by maximising the GP marginal likelihood (Rasmussen & Williams, 2006) every Ncyc iterations.\nInitialisation: Marginal likelihood based kernel tuning can be unreliable with few data points. This is a problem in the first few iterations. Following the recommendations in Bull (2011) we initialise Add-GP-UCB (and GP-UCB) using Ninit points selected uniformly at random.\nDecomposition & Non-additive functions: If f is additive and the decomposition is known, we use it directly. But it may not always be known or f may not be additive. Then, we could treat the decomposition as a hyperparameter of the additive kernel and maximise the marginal likelihood w.r.t the decomposition. However, given that there are D!/d!MM ! possible decompositions, computing the marginal likelihood for all of them is infeasible. We circumvent this issue by randomly selecting a few (O(D)) decompositions and choosing the one with the largest marginal likelihood. Intuitively, if the function is not additive, with such a \u201cpartial maximisation\u201d we can hope to capture some existing marginal structure in f . At the same time, even an exhaustive maximisation will not do much better than a partial maximisation if there is no additive structure. Empirically, we found that partially optimising for the decomposition performed slightly better than using a fixed decomposition or a random decomposition at each step. We incorporate this procedure for finding an appropriate decomposition as part of the kernel hyper parameter learning procedure every Ncyc iterations.\nHow do we choose (d,M) when f is not additive? If d is large we allow for richer class of functions, but risk high variance. For small d, the kernel is too simple and we have high bias but low variance \u2013 further optimising \u03d5\u0303t is easier. In practice we found that our procedure was fairly robust for reasonable choices of d. Yet this is an interesting theoretical question. We also believe it is a difficult one. Using the marginal likelihood alone will not work as the optimal choice of d also depends on the computational budget for optimising \u03d5\u0303t. We hope to study this question in future work. For now, we give some recommendations at the end. Our modified algorithm with these practical considerations is given below. Observe that in this specification if we use d = D we have the original GP-UCB algorithm.\nAlgorithm 2 Practical-Add-GP-UCB Input: Ninit, Ncyc, d, M \u2022 D0 \u2190 Ninit points chosen uniformly at random. \u2022 for t = 1, 2, . . .\n1. if (t mod Ncyc = 0), Learn the kernel hyper parameters and the decomposition {Xj} by maximising the GP marginal likelihood.\n2. Perform steps 1-3 in Algorithm 1 with \u03b2t = 0.2d log 2t.\n3. Dt = Dt\u22121 \u222a {(xt,yt)}. 4. Perform Bayesian posterior updates conditioned\non Dt to obtain \u00b5(j)t , \u03c3 (j) t for j = 1, . . . ,M ."}, {"heading": "5. Experiments", "text": "To demonstrate the efficacy of Add-GP-UCB over GPUCB we optimise the acquisition function under a constrained budget. Following, Brochu et al. (2010) we use DiRect to maximise \u03d5t, \u03d5\u0303t. We compare Add-GP-UCB against GP-UCB, random querying (RAND) and DiRect3. On the real datasets we also compare it to the Expected Improvement (GP-EI) acquisition function which is popular in BO applications and the method of Wang et al. (2013) which uses a random projection before applying BO (REMBO). We have multiple instantiations of Add-GPUCB for different values for (d,M). For optimisation, we perform comparisons based on the simple regret ST and for bandits we use the time averaged cumulative regret RT /T .\nFor all GPB/ BO methods we set Ninit = 10, Ncyc = 25 in all experiments. Further, for the first 25 iterations we set the bandwidth to a small value (10\u22125) to encourage an explorative strategy. We use SE kernels for each additive kernels and use the same scale \u03c3 and bandwidth h hyperparameters for all the kernels. Every 25 iterations we maximise the marginal likelihood with respect to these 2 hyperparameters in addition to the decomposition.\n3There are several optimisation methods based on simulated annealing, cross entropy and genetic algorithms. We use DiRect since its easy to configure and known to work well in practice.\nIn contrast to existing literature in the BO community, we found that the UCB acquisitions outperformed GP-EI. One possible reason may be that under a constrained budget, UCB is robust to imperfect maximisation (Theorem 5) whereas GP-EI may not be. Another reason may be our choice of constants in UCB (Section 4.4)."}, {"heading": "5.1. Simulations on Synthetic Data", "text": "First we demonstrate our technique on a series of synthetic examples. For this we construct additive functions for different values for the maximum group size d\u2032 and the number of groups M \u2032. We use the prime to distinguish it from Add-GP-UCB instantiations with different combinations of (d,M) values. The d\u2032 dimensional function fd\u2032 is,\nfd\u2032(x) = log\n( 0.1 1\nhd \u2032 d\u2032\nexp\n( \u2016x\u2212 v1\u20162\n2h2d\u2032\n) + (7)\n0.1 1\nhd \u2032 d\u2032\nexp\n( \u2016x\u2212 v2\u20162\n2h2d\u2032\n) + 0.8 1\nhd \u2032 d\u2032\nexp\n( \u2016x\u2212 v3\u20162\n2h2d\u2032\n))\nwhere v1, v2, v3 are fixed d\u2032 dimensional vectors and hd\u2032 = 0.01d\u2032\n0.1. Then we create M \u2032 groups of coordinates by randomly adding d\u2032 coordinates into each group. On each such group we use fd\u2032 and then add them up to obtain the composite function f . Precisely,\nf(x) = fd\u2032(x (1)) + \u00b7 \u00b7 \u00b7+ fd\u2032(x(M))\nThe remaining D \u2212 d\u2032M \u2032 coordinates do not contribute to the function. Since fd\u2032 has 3 modes, f will have 3M \u2032 modes. We have illustrated fd\u2032 for d\u2032 = 2 in Figure 2.\nIn the synthetic experiments we use an instantiation of Add-GP-UCB that knows the decomposition\u2013i.e. (d,M) = (d\u2032,M \u2032) and the grouping of coordinates. We refer to this as Add-?. For the rest we use a (d,M) decomposition by creating M groups of size at most d and find a good grouping by partially maximising the marginal likelihood (Section 4.4). We refer to them as Add-d/M .\nFor GP-UCB we allocate a budget of min(5000, 100D) DiRect function evaluations to optimise the acquisition function. For all Add-d/M methods we set it to 90% of this amount4 to account for the additional overhead in posterior inference for each f (j). Therefore, in our 10D problem we maximise \u03d5t with \u03b2t = 2 log(2t) with 1000 DiRect evaluations whereas for Add-2/5 we maximise each \u03d5\u0303(j)t with \u03b2t = 0.4 log(2t) with 180 evaluations.\nThe results are given in Figures 3 and 4. We refer to each example by the configuration of the additive function\u2013its (D, d\u2032,M \u2032) values. In the (10, 3, 3) example Add-? does\n4While the 90% seems arbitrary, in our experiments this was hardly a factor as the cost was dominated by the inversion of \u2206.\nbest since it knows the correct model and the acquisition function can be maximised within the budget. However Add-3/4 and Add-5/2 models do well too and outperform GP-UCB. Add-1/10 performs poorly since it is statistically not expressive enough to capture the true function. In the (24, 11, 2), (40, 18, 2), (40, 35, 1), (96, 29, 3) and (120, 55, 2) examples Add-? outperforms GP-UCB. However, it is not competitive with the Add-d/M for small d. Even though Add-? knew the correct decomposition, there are two possible failure modes since d\u2032 is large. The kernel is complex and the estimation error is very high in the absence of sufficient data points. In addition, optimising the acquisition is also difficult. This illustrates our previous argument that using an additive kernel can be advantageous even if the function is not additive or the decomposition is not known. In the (24, 6, 4), (40, 5, 8) and (96, 5, 19) examples Add-? performs best as d\u2032 is small enough. But again, almost all Add-d/M instantiations outperform GPUCB. In contrast to the small D examples, for large D, GP-UCB and Add-d/M with large d perform worse than DiRect. This is probably because our budget for maximising \u03d5t is inadequate to optimise the acquisition function to sufficient accuracy. For some of the large D examples the cumulative regret is low for Add-GP-UCB and Addd/M with large d. This is probably since they have already started exploiting where as the Add-d/M with small\nd methods are still exploring. We posit that if we run for more iterations we will be able to see the improvements."}, {"heading": "5.2. SDSS Astrophysical Dataset", "text": "Here we used Galaxy data from the Sloan Digital Sky Survey (SDSS). The task is to find the maximum likelihood estimators for a simulation based astrophysical likelihood model. Data and software for computing the likelihood are taken from Tegmark et al (2006). The software itself takes in only 9 parameters but we augment this to 20 dimensions to emulate the fact that in practical astrophysical problems we may not know the true parameters on which the problem is dependent. This also allows us to effectively demonstrate the superiority of our methods over alternatives. Each query to this likelihood function takes about 2-5 seconds. In order to be wall clock time competitive with RAND and DiRectwe use only 500 evaluations for GP-UCB, GP-EI and REMBO and 450 for Add-d/M to maximise the acquisition function.\nWe have shown the Maximum value obtained over 400 iterations of each algorithm in Figure 5(a). Note that RAND outperforms DiRect here since a random query strategy is effectively searching in 9 dimensions. Despite this advantage to RAND all BO methods do better. Moreover, despite the fact that the function may not be additive, all\nAdd-d/M methods outperform GP-UCB. Since the function only depends on 9 parameters we use REMBO with a 9 dimensional projection. Yet, it is not competitive with the Add-d/M methods. Possible reasons for this may include the scaling of the parameter space by \u221a d in REMBO and the imperfect optimisation of the acquisition function. Here Add-5/4 performs slightly better than the rest since it seems to have the best tradeoff between being statistically expressive enough to capture the function while at the same time be easy enough to optimise the acquisition function within the allocated budget."}, {"heading": "5.3. Viola & Jones Face Detection", "text": "The Viola & Jones (VJ) Cascade Classifier (Viola & Jones, 2001) is a popular method for face detection in computer vision based on the Adaboost algorithm. The K-cascade has K weak classifiers which outputs a score for any given image. When we wish to classify an image we pass that image through each classifier. If at any point the score falls below a certain threshold the image is classified as negative. If the image passes through all classifiers then it is classified as positive. The threshold values at each stage are usually pre-set based on prior knowledge. There is no reason to believe that these threshold values are optimal. In this experiment we wish to find an optimal set of values for these thresholds by optimising the classification accuracy over a training set.\nFor this task, we use 1000 images from the Viola & Jones face dataset containing both face and non-face images. We use the implementation of the VJ classifier that comes with OpenCV (Bradski & Kaehler, 2008) which uses a 22-stage cascade and modify it to take in the threshold values as a parameter. As our domain X we choose a neighbourhood around the configuration given in OpenCV. Each function call takes about 30-40 seconds and is the the dominant cost in this experiment. We use 1000 DiRect evaluations to optimise the acquisition function for GP-UCB, GPEI and REMBO and 900 for the Add-d/M instantiations. Since we do not know the structure of the function we use REMBO with a 5 dimensional projection. The results are given in Figure 5(b). Not surprisingly, REMBO performs worst as it is only searching on a 5 dimensional space. Barring Add-1/22 all other instantiations perform better than GP-UCB and GP-EI with Add-6/4 performing the best. Interestingly, we also find a value for the thresholds that outperform the configuration used in OpenCV."}, {"heading": "6. Conclusion", "text": "Recommendations: Based on our experiences, we recommend the following. If f is known to be additive, the decomposition is known and d is small enough so that \u03d5\u0303t can be efficiently optimised, then running Add-GP-UCB\nwith the known decomposition is likely to produce the best results. If not, then use a small value for d and run AddGP-UCB while partially optimising for the decomposition periodically (Section 4.4). In our experiments we found that using d between 3 an 12 seemed reasonable choices. However, note that this depends on the computational budget for optimising the acquisition, the query budget for f and to a certain extent the the function f itself.\nSummary: Our algorithm takes into account several practical considerations in real world GPB/ BO applications such as computational constraints in optimising the acquisition and the fact that we have to work with a relatively few data points since function evaluations are expensive. Our framework effectively addresses these concerns without considerably compromising on the statistical integrity of the model. We believe that this provides a promising direction to scale GPB/ BO methods to high dimensions.\nFuture Work: Our experiments indicate that our methods perform well beyond the scope suggested by our theory. Developing an analysis that takes into account the biasvariance and computational tradeoffs in approximating and optimising a non-additive function via an additive model is an interesting challenge. We also intend to extend this framework to discrete settings, other acquisition functions\nand handle more general decompositions."}, {"heading": "Acknowledgements", "text": "We wish to thank Akshay Krishnamurthy and Andrew Gordon Wilson for the insightful discussions and Andreas Krause, Sham Kakade and Matthias Seeger for the helpful email conversations. This research is partly funded by DOE grant DESC0011114.\nOur current analysis, specifically equation 14, has an error. We are working on resolving this and will post an update shortly. We would like to thank Felix Berkenkamp and Andreas Krause from ETH Zurich for pointing this out."}, {"heading": "A. Some Auxiliary Material", "text": "A.1. Review of the GP-UCB Algorithm\nIn this subsection we present a brief summary of the GP-UCB algorithm in (Srinivas et al., 2010). The algorithm is given in Algorithm 3.\nThe following theorem gives the rate of convergence for GP-UCB. Note that under an additive kernel, this is the same rate as Theorem 5 which uses a different acquisition function. Note the differences in the choice of \u03b2t.\nTheorem 6. (Modification of Theorem 2 in (Srinivas et al., 2010)) Suppose f is constructed by sampling f (j) \u223c GP(0, \u03ba(j)) for j = 1, . . . ,M and then adding them. Let all kernels \u03ba(j) satisfy assumption 2 for some L, a, b. Further, we maximise the acquisition function \u03d5\u0303t to within \u03b60t\u22121/2 accuracy at time step t. Pick \u03b4 \u2208 (0, 1) and choose\n\u03b2t = 2 log\n( 2t2\u03c02\n\u03b4\n) + 2D log ( Dt3 ) \u2208 O (D log t) .\nThen, GP-UCB attains cumulative regretRT \u2208 O (\u221a D\u03b3TT log T ) and hence simple regret ST \u2208 O (\u221a D\u03b3T log T/T )\n. Precisely, with probability > 1\u2212 \u03b4,\n\u2200T \u2265 1, RT \u2264 \u221a 8C1\u03b2TMT\u03b3t + 2\u03b60 \u221a T + C2.\nwhere C1 = 1/ log(1 + \u03b7\u22122) and C2 is a constant depending on a, b, D, \u03b4, L and \u03b7.\nProof. Srinivas et al. (2010) bound the regret for exact maximisation of the GP-UCB acquisition \u03d5t. By following an analysis similar to our proof of Theorem 5 the regret can be shown to be the same for an \u03b60t\u22121/2- optimal maximisation.\nAlgorithm 3 GP-UCB Input: Kernel \u03ba, Input Space X . For t = 1, 2 . . . \u2022 D0 \u2190 \u2205, \u2022 (\u00b50, \u03ba0)\u2190 (0, \u03ba) \u2022 for t = 1, 2, . . .\n1. xt \u2190 argmaxz\u2208X \u00b5t\u22121(z) + \u221a \u03b2t\u03c3t\u22121(z) 2. yt \u2190 Query f at xt. 3. Dt = Dt\u22121 \u222a {(xt,yt)}. 4. Perform Bayesian posterior updates to obtain \u00b5t, \u03c3t for j = 1, . . . ,M .\nA.2. Sequential Optimisation Approaches\nIf the function is known to be additive, we could consider several other approaches for maximisation. We list two of them here and explain their deficiencies. We recommend that the reader read the main text before reading this section.\nA.2.1. OPTIMISE ONE GROUP AND PROCEED TO THE NEXT\nFirst, fix the coordinates of x(j), j 6= 1 and optimise w.r.t x(1) by querying the function for a pre-specified number of times. Then we proceed sequentially optimising with respect to x(2), x(3) . . . . We have outlined this algorithm in Algorithm 4. There are several reasons this approach is not desirable.\n\u2022 First, it places too much faith on the additive assumption and requires that we know the decomposition at the start of the algorithm. Note that this strategy will only have searched the space in M d-dimensional subspaces. In our approach even if the function is not additive we can still hope to do well since we learn the best additive approximation to the true function. Further, if the decomposition is not known we could learn the decomposition \u201con the go\u201d or at least find a reasonably good decomposition as we have explained in Section 4.4.\n\u2022 Such a sequential approach is not an anytime algorithm. This in particular means that we need to predetermine the number of queries to be allocated to each group. After we proceed to a new group it is not straightforward to come back and improve on the solution obtained for an older group.\n\u2022 This approach is not suitable for the bandits setting. We suffer large instantaneous regret up until we get to the last group. Further, after we proceed beyond a group since we cannot come back, we cannot improve on the best regret obtained in that group.\nOur approach does not have any of these deficiencies.\nAlgorithm 4 Seq-Add-GP-UCB Input: Kernels \u03ba(1), . . . , \u03ba(M), Decomposition (X (j))Mj=1, Query Budget T , \u2022 RD 3 \u03b8 = \u22c3M j=1 \u03b8\n(j) = rand([0, 1]d) \u2022 for j = 1, . . . ,M\n1. D(j)0 \u2190 \u2205, 2. (\u00b5(j)0 , \u03ba (j) 0 )\u2190 (0, \u03ba(j)). 3. for t = 1, 2, . . . T/M (a) x(j)t \u2190 argmaxz\u2208X (j) \u00b5(j)(z) + \u221a \u03b2t\u03c3 (j)(z)\n(b) xt \u2190 x(j)t \u22c3 k 6=j \u03b8\n(k). (c) yt \u2190 Query f at xt. (d) D(j)t = D (j) t\u22121 \u222a {(x (j) t ,yt)}. (e) Perform Bayesian posterior updates to obtain \u00b5(j)t , \u03c3 (j) t .\n4. \u03b8(j) \u2190 x(j)T/M \u2022 Return \u03b8\nA.2.2. ONLY CHANGE ONE GROUP PER QUERY\nIn this strategy, the approach would be very similar to Add-GP-UCB except that at each query we will only update one group at time. If it is the kth group the query point is determined by maximising \u03d5\u0303(k)t for x (k) t and for all other groups we use values from the previous rotation. After M iterations we cycle through the groups. We have outlined this in Algorithm 5.\nThis is a reasonable approach and does not suffer from the same deficiencies as Algorithm 4. Maximising the acquisition function will also be slightly easier O(\u03b6\u2212d) since we need to optimise only one group at a time. However, the regret for this approach would beO(M \u221a D\u03b3TT log T ) which is a factor ofM worse than the regret in our method (This can be show by following an analysis similar to the one in section B.2. This is not surprising, since at each iteration you are moving in d-coordinates of the space and you have to wait M iterations before the entire point is updated.\nAlgorithm 5 Add-GP-UCB-Buggy Input: Kernels \u03ba(1), . . . , \u03ba(M), Decomposition (X (j))Mj=1 \u2022 D0 \u2190 \u2205, \u2022 for j = 1, . . . ,M , (\u00b5(j)0 , \u03ba (j) 0 )\u2190 (0, \u03ba(j)).\n\u2022 for t = 1, 2, . . . 1. k = j mod M\n2. x(k)t \u2190 argmaxz\u2208X (k) \u00b5(k)(z) + \u221a \u03b2t\u03c3 (k)(z) 3. for j 6= k, x(j)t \u2190 x (j) t\u22121\n4. xt \u2190 \u22c3M j=1 x (j) t . 5. yt \u2190 Query f at xt. 6. Dt = Dt\u22121 \u222a {(xt,yt)}. 7. Perform Bayesian posterior updates to obtain \u00b5(j)t , \u03c3 (j) t for j = 1, . . . ,M ."}, {"heading": "B. Proofs of Results in Section 4.3", "text": "B.1. Bounding the Information Gain \u03b3T\nFor this we will use the following two results from Srinivas et al. (2010).\nLemma 7. (Information Gain in GP, (Srinivas et al., 2010) Lemma 5.3) Using the basic properties of a GP, they show that\nI(yA; fA) = 1\n2 n\u2211 t=1 log(1 + \u03b7\u22122\u03c32t\u22121(xt)).\nwhere \u03c32t\u22121 is the posterior variance after observing the first t\u2212 1 points.\nTheorem 8. (Bound on Information Gain, (Srinivas et al., 2010) Theorem 8) Suppose that X is compact and \u03ba is a kernel on d dimensions satisfying Assumption 2. Let nT = C9T \u03c4 log T where C9 = 4d+ 2. For any T\u2217 \u2208 {1, . . . ,min(T, nT )}, let B\u03ba(T\u2217) = \u2211 s>T\u2217 \u03bbs. Here (\u03bbn)n\u2208N are the eigenvalues of \u03ba w.r.t the uniform distribution over X . Then,\n\u03b3T \u2264 inf \u03c4\n( 1/2\n1\u2212 e\u22121 max r\u2208{1,...,T}\n( T\u2217 log(rnT /\u03b7 2) + C9\u03b7 2(1\u2212 r/T )(T \u03c4+1B\u03ba(T\u2217) + 1) log T ) +O(T 1\u2212\u03c4/d) ) .\nB.1.1. PROOF OF THEOREM 4-1\nProof. We will use some bounds on the eigenvalues for the simple squared exponential kernel given in (Seeger et al., 2008). It was shown that the eigenvalues {\u03bb(i)s } of \u03ba(i) satisfied \u03bb(i)s \u2264 cdBs\n1/di where B < 1 (See Remark 9). Since the kernel is additive, and x(i) \u2229 x(j) = \u2205 the eigenfunctions corresponding to \u03ba(i) and \u03ba(j) will be orthogonal. Hence the eigenvalues of \u03ba will just be the union of the eigenvalues of the individual kernels \u2013 i.e. {\u03bbs} = \u22c3M j=1{\u03bb (j) s }. As B < 1, \u03bb (i) s \u2264 cdBs 1/d . Let T+ = bT\u2217/Mc and \u03b1 = \u2212 logB. Then,\nB\u03ba(T\u2217) = \u2211 s>T\u2217 \u03bbs \u2264Mc \u2211 s>T+ Bs 1/d\n\u2264 cdM ( BT 1/d + + \u222b \u221e T+ exp(\u2212\u03b1x1/d) ) dx\n\u2264 cdM ( BT 1/d + + d\u03b1\u2212d\u0393(d, \u03b1T\n1/d + ) ) \u2264 cdMe\u2212\u03b1T 1/d + ( 1 + d!d\u03b1\u2212d(\u03b1T\n1/d + )\nd\u22121 ) .\nThe last step holds true whenever \u03b1T 1/d+ \u2265 1. Here in the second step we bound the series by an integral and in the third step we used the substitution y = \u03b1x1/d to simplify the integral. Here \u0393(s, x) = \u222b\u221e x ts\u22121e\u2212tdt is the (upper) incomplete Gamma function. In the last step we have used the following identity and the bound for integral s and x \u2265 1\n\u0393(s, x) = (s\u2212 1)!e\u2212x s\u22121\u2211 k=0 xk k! \u2264 s!e\u2212xxd\u22121.\nBy using \u03c4 = d and by using T\u2217 \u2264 (M + 1)T+, we use Theorem 8 to obtain the following bound on \u03b3T ,\n\u03b3T \u2264 1/2\n1\u2212 e\u22121 max r\u2208{1,...,T}\n( (M + 1)T+ log(rnT /\u03b7 2)+\nC9\u03b7 2(1\u2212 r/T ) log T ( 1 + cdMe\u2212\u03b1T 1/d + T d+1 ( 1 + d!d\u03b1\u2212d(\u03b1T 1/d + ) d\u22121 ))) . (8)\nNow we need to pick T+ so as to balance these two terms. We will choose T+ = ( log(TnT ) \u03b1 )d which is less than min(T, nT )/M for sufficiently large T . Then e\u2212\u03b1T 1/d + = 1/TnT . Then the first term S1 inside the paranthesis is,\nS1 = (M + 1) log d ( TnT \u03b1 ) log ( rnT \u03b72 ) \u2208 O ( M (log(TnT )) d log(rnT ) )\n\u2208 O ( M ( log(T d+1 log T ) )d log(rT d log T ) ) \u2208 O ( Mdd+1(log T )d+1 +Mdd(log T )d log(r) ) .\nNote that the constant in front has exponential dependence on d but we ignore it since we already have dd, (log T )d terms. The second term S2 becomes,\nS2 = C9\u03b7 2(1\u2212 r/T ) log T ( 1 + cdM\nTnT T d+1\n( 1 + d!d\u03b1\u2212d(log(TnT ) d\u22121))) \u2264 C9\u03b72(1\u2212 r/T ) ( log T + cdM\nC9\n( 1 + d!d\u03b1\u2212d(log(TnT ) d\u22121))) \u2264 C9\u03b72(1\u2212 r/T ) ( O(log T ) +O(1) +O(d!dd(log T )d\u22121)\n)) \u2208 O ( (1\u2212 r/T )d!dd(log T )d\u22121 ) .\nSince S1 dominates S2, we should choose r = T to maximise the RHS in (8). This gives us,\n\u03b3T \u2208 O ( Mdd+1(log T )d+1 ) \u2208 O ( Ddd(log T )d+1 ) .\nB.1.2. PROOF OF THEOREM 4-2\nProof. Once again, we use bounds given in (Seeger et al., 2008). It was shown that the eigenvalues {\u03bb(i)s } for \u03ba(i) satisfied \u03bb(i)s \u2264 cds \u2212 2\u03bd+dj dj (See Remark 9). By following a similar argument to above we have {\u03bbs} = \u22c3M j=1{\u03bb (j) s } and \u03bb(i)s \u2264 cds\u2212 2\u03bd+d d . Let T+ = bT\u2217/Mc. Then,\nB\u03ba(T\u2217) = \u2211 s>T\u2217 \u03bbs \u2264Mcd \u2211 s>T+ s\u2212 2\u03bd+d d \u2264Mcd ( T \u2212 2\u03bd+dd + + \u222b \u221e T+ s\u2212 2\u03bd+d d ) \u2264 C82dMT 1\u2212 2\u03bd+dd + .\nwhere C8 is an appropriate constant. We set T+ = (TnT ) d 2\u03bd+d (log(TnT )) \u2212 d2\u03bd+d and accordingly we have the following bound on \u03b3T as a function of T+ \u2208 {1, . . . ,min(T, nT )/M},\n\u03b3T \u2264 inf \u03c4\n( 1/2\n1\u2212 e\u22121 max r\u2208{1,...,T}\n( (M + 1)T+ log(rnT /\u03b7 2) + C9\u03b7 2(1\u2212 r/T ) ( log T + C82 dMT+ log(TnT ) )) +O(T 1\u2212\u03c4/d) ) .\n(9)\nSince this is a concave function on r we can find the optimum by setting the derivative w.r.t r to be zero. We get r \u2208 O(T/2d log(TnT )) and hence,\n\u03b3T \u2208 inf \u03c4\n( O ( MT+ log ( TnT\n2d log(TnT )\n)) +O ( M2dT+ log(TnT ) ) +O(T 1\u2212\u03c4/d) ) \u2208 inf\n\u03c4\n( O ( M2d log(TnT ) ( T \u03c4+1 log(T )\n(\u03c4 + 1) log(T ) + log log T\n) d 2\u03bd+d ) +O(T 1\u2212\u03c4/d) ) \u2208 inf\n\u03c4\n( O ( M2d log(TnT )T (\u03c4+1)d 2\u03bd+d ) +O(T 1\u2212\u03c4/d) ) \u2208 O ( M2dT d(d+1) 2\u03bd+d(d+1) log(T ) ) .\nHere in the second step we have substituted the values for T+ first and then nT . In the last step we have balanced the polynomial dependence on T in both terms by setting \u03c4 = 2\u03bdd2\u03bd+d(d+1) .\nRemark 9. The eigenvalues and eigenfunctions for the kernel are defined with respect to a base distribution on X . In the development of Theorem 8, Srinivas et al. (2010) draw nT samples from the uniform distribution on X . Hence, the eigenvalues/eigenfunctions should be w.r.t the uniform distribution. The bounds given in Seeger et al. (2008) are for the uniform distribution for the Mate\u0301rn kernel and a Gaussian Distribution for the Squared Exponential Kernel. For the latter case, Srinivas et al. (2010) argue that the uniform distribution still satisfies the required tail constraints and therefore the bounds would only differ up to constants.\nB.2. Rates on Add-GP-UCB\nOur analysis in this section draws ideas from Srinivas et al. (2010). We will try our best to stick to their same notation. However, unlike them we also handle the case where the acquisition function is optimised within some error. In the ensuing discussion, we will use x\u0303t = \u22c3 j x\u0303 (j) t to denote the true maximiser of \u03d5\u0303t \u2013 i.e. x\u0303 (j) t = argmaxz\u2208X (j) \u03d5\u0303 (j) t (z).\nxt = \u22c3 j x (j) t denotes the point chosen by Add-GP-UCB at the tth iteration. Recall that xt is \u03b60t\u22121/2\u2013optimal; I.e. \u03d5\u0303t(x\u0303t)\u2212 \u03d5\u0303t(xt) \u2264 \u03b60t\u22121/2.\nDenote p = \u2211 j dj . \u03c0t denotes a sequence such that \u2211 t \u03c0 \u22121 t = 1. For e.g. when we use \u03c0t = \u03c0\n2t2/6 below, we obtain the rates in Theorem 5.\nIn what follows, we will construct discretisations \u2126(j) on each group X (j) for the sake of analysis. Let \u03c9j = |\u2126(j)| and \u03c9m = maxj \u03c9j . The discretisation of the individual groups induces a discretisation \u2126 on X itself, \u2126 = {x = \u22c3 j x (j) : x(j) \u2208 \u2126(j), j = 1, . . . ,M}. Let \u03c9 = |\u2126| = \u220f j \u03c9j . We first establish the following two lemmas before we prove Theorem 5.\nLemma 10. Pick \u03b4 \u2208 (0, 1) and set \u03b2t = 2 log(\u03c9mM\u03c0t/\u03b4). Then with probability > 1\u2212 \u03b4,\n\u2200t \u2265 1,\u2200x \u2208 \u2126, |f(x)\u2212 \u00b5t\u22121(x)| \u2264 \u03b21/2t M\u2211 j=1 \u03c3 (j) t\u22121(x (j)).\nProof. Conditioned on Dt\u22121, at any given x and t we have f(x(j)) \u223c N (\u00b5(j)t\u22121(x(j)), \u03c3 (j) t\u22121j), \u2200j = 1, . . .M . Using the tail bound, P(z > M) \u2264 12e \u2212M2/2 for z \u223c N (0, 1) we have with probability > 1\u2212 \u03b4/\u03c9M\u03c0t,\n|f (j)(x(j))\u2212 \u00b5(j)t\u22121(x(j))| \u03c3\n(j) t\u22121(x\n(j)) > \u03b2\n1/2 t \u2264 e\u2212\u03b2t/2 =\n\u03b4\n\u03c9mM\u03c0t .\nBy using a union bound \u03c9j \u2264 \u03c9m times over all x(j) \u2208 \u2126(j) and then M times over all discretisations the above holds with probability > 1 \u2212 \u03b4/\u03c0t for all j = 1, . . . ,M and x(j) \u2208 \u2126(j). Therefore, we have |f(x) \u2212 \u00b5t\u22121(x)| \u2264 |f(x(j)) \u2212 \u00b5\n(j) t\u22121(x (j))| \u2264 \u03b21/2t \u2211 j \u03c3 (j) t\u22121(x (j)) for all x \u2208 \u2126. Now using the union bound on all t yields the result.\nLemma 11. The posterior mean \u00b5t\u22121 for a GP whose kernel \u03ba(\u00b7, x) is L-Lipschitz satisfies, P ( \u2200t \u2265 1 |\u00b5t\u22121(x)\u2212 \u00b5t\u22121(x\u2032)| \u2264 ( f(x\u2217) + \u03b7 \u221a 2 log(\u03c0t/2\u03b4) ) L\u03b7\u22122t\u2016x\u2212 x\u2032\u20162 ) \u2265 1\u2212 \u03b4.\nProof. Note that for given t, P ( yt < f(x\u2217) + \u03b7 \u221a 2 log(\u03c0t/2\u03b4) ) \u2264 P ( t/\u03b7 < \u221a 2 log(\u03c0t/2\u03b4) ) \u2264 \u03b4/\u03c0t.\nTherefore the statement is true with probability > 1 \u2212 \u03b4 for all t. Further, \u2206 \u03b72I implies \u2016\u2206\u22121\u2016op \u2264 \u03b7\u22122 and |k(x, z)\u2212 k(x\u2032, z)| \u2264 L\u2016x\u2212 x\u2032\u2016. Therefore\n|\u00b5t\u22121(x)\u2212 \u00b5t\u22121(x\u2032)| = |Y >t\u22121\u2206\u22121(k(x,XT )\u2212 k(x\u2032, XT )| \u2264 \u2016Yt\u22121\u20162\u2016\u2206\u22121\u2016op\u2016k(x,Xt\u22121)\u2212 k(x\u2032, Xt\u22121)\u20162 \u2264 ( f(x\u2217) + \u03b7 \u221a 2 log(\u03c0t/2\u03b4) ) L\u03b7\u22122(t\u2212 1)\u2016x\u2212 x\u2032\u20162.\nB.2.1. PROOF OF THEOREM 5\nProof. First note that by Assumption 2 and the union bound we have, P(\u2200i supx(j)\u2208X (j) |\u2202f (j)(x(j))/\u2202x (j) i | > J) \u2264 diae \u2212(J/b)2 . Since, \u2202f(x)/\u2202x(j)i = \u2202f (j)(x(j))/\u2202x (j) i , we have,\nP ( \u2200i = 1, . . . , D sup\nx\u2208X \u2223\u2223\u2223\u2202f(x) \u2202xi \u2223\u2223\u2223 > J) \u2264 pae\u2212(J/b)2 . By setting \u03b4/3 = pae\u2212J 2/b2 we have with probability > 1\u2212 \u03b4/3,\n\u2200x, x\u2032 \u2208 X , |f(x)\u2212 f(x\u2032)| \u2264 b \u221a log(3ap/\u03b4)\u2016x\u2212 x\u2032\u20161. (10)\nNow, we construct a sequence of discretisations \u2126(j)t satisfying \u2016x(j) \u2212 [x(j)]t]\u20161 \u2264 dj/\u03c4t \u2200x(j) \u2208 \u2126 (j) t . Here, [x (j)]t is the closest point to x(j) in \u2126(j)t in an L2 sense. A sufficient discretisation is a grid with \u03c4t uniformly spaced points. Then it follows that for all x \u2208 \u2126t, \u2016x \u2212 [x]t\u20161 \u2264 p/\u03c4t. Here \u2126t is the discretisation induced on X by the \u2126(j)t \u2019s and [x]t is the closest point to x in \u2126t. Note that \u2016x(j) \u2212 [x(j)]t\u20162 \u2264 \u221a dj/\u03c4t \u2200x(j) \u2208 \u2126(j) and \u2016x \u2212 [x]t\u20162 \u2264 \u221a p/\u03c4t. We will set \u03c4t = pt3\u2013therefore, \u03c9tj \u2264 (pt3)d \u2206 = \u03c9mt. When combining this with (10), we get that with probability > 1 \u2212 \u03b4/3,\n|f(x)\u2212 f([x])| \u2264 b \u221a\nlog(3ap/\u03b4)/t3. By our choice of \u03b2t and using Lemma 10 the following is true for all t \u2265 1 and for all x \u2208 X with probability > 1\u2212 2\u03b4/3,\n|f(x)\u2212 \u00b5t\u22121([x]t)| \u2264 |f(x)\u2212 f([x]t)|+ |f([x]t)\u2212 \u00b5t\u22121([x]t)| \u2264 b \u221a log(3ap/\u03b4)\nt2 + \u03b2\n1/2 t M\u2211 j=1 \u03c3 (j) t\u22121([x (j)]t). (11)\nBy Lemma 11 with probability > 1\u2212 \u03b4/3 we have, \u2200x \u2208 X , |\u00b5t\u22121(x)\u2212 \u00b5t\u22121([x]t)| \u2264 L ( f(x\u2217) + \u03b7 \u221a 2 log(3\u03c0t/2\u03b4) ) \u221a p\u03b72t2 . (12)\nWe use the above results to obtain the following bound on the instantaneous regret rt which holds with probability > 1\u2212 \u03b4 for all t \u2265 1,\nrt = f(x\u2217)\u2212 f(xt)\n\u2264 \u00b5t\u22121([x\u2217]t) + \u03b21/2t M\u2211 j=1 \u03c3 (j) t\u22121([x (j) \u2217 ]t)\u2212 \u00b5t\u22121([xt]t) + \u03b21/2t M\u2211 j=1 \u03c3 (j) t\u22121([x (j) t ]t) +\n2b \u221a log(3ap/\u03b4)\nt3\n\u2264 2b \u221a log(3ap/\u03b4)\nt3 + \u03b60\u221a t + \u03b2 1/2 t  M\u2211 j=1 \u03c3 (j) t\u22121(x (j) t ) + M\u2211 j=1 \u03c3 (j) t\u22121([x (j) t ]t) + \u00b5t\u22121(xt)\u2212 \u00b5t\u22121([xt]t) \u2264 2b \u221a log(3ap/\u03b4) t3 + L ( f(x\u2217) + \u03b7 \u221a 2 log(\u03c0t/2\u03b4) ) \u221a p\u03b72t2 + \u03b60\u221a t + \u03b2 1/2 t  M\u2211 j=1 \u03c3 (j) t\u22121(x (j) t ) + M\u2211 j=1 \u03c3 (j) t\u22121([x (j) t ]t)\n . (13) In the first step we have applied Equation (11) at x\u2217 and xt. In the second step we have used the fact that \u03d5\u0303t([x\u2217]t) \u2264 \u03d5\u0303t(x\u0303t) \u2264 \u03d5\u0303t(xt) + \u03b60t\u22121/2. In the third step we have used Equation (12).\nFor any x \u2208 X we can bound \u03c3t(x)2 as follows,\n\u03c3t(x) 2 = \u03b72\u03b7\u22122\u03c3t(x) 2 \u2264 1 log(1 + \u03b7\u22122) log ( 1 + \u03b7\u22122\u03c3t(x) 2 ) .\nHere we have used the fact that u2 \u2264 v2 log(1 + u2)/ log(1 + v2) for u \u2264 v and \u03c3t(x)2 \u2264 \u03ba(x, x) = 1. Write C1 = log\n\u22121(1 + \u03b7\u22122). By using Jensen\u2019s inequality and Definition 3 for any set of T points {x1, x2, . . . xT } \u2282 X , T\u2211 t=1 M\u2211 j=1 \u03c3 (j) t (x (j)) 2 \u2264MT T\u2211 t=1 M\u2211 j=1 \u03c3 (j) t (x (j)) 2 \u2264 C1MT T\u2211 t=1 log ( 1 + \u03b7\u22122\u03c3t(x) 2 ) \u2264 2C1MT\u03b3T . (14)\nFinally we can bound the cumulative regret with probability > 1\u2212 \u03b4 for all T \u2265 1 by,\nRT = T\u2211 t=1 rt \u2264 C2(a, b,D, L, \u03b4) + \u03b60 T\u2211 t=1 t\u22121/2 + \u03b2 1/2 T  T\u2211 t=1 M\u2211 j=1 \u03c3 (j) t\u22121(x (j) t ) + T\u2211 t=1 M\u2211 j=1 \u03c3 (j) t\u22121([x (j) t ]t)  \u2264 C2(a, b,D, L, \u03b4) + 2\u03b60 \u221a T + \u221a 8C1\u03b2TMT\u03b3T .\nwhere we have used the summability of the first two terms in Equation (13). Here, for \u03b4 < 0.8, the constant C2 is given by,\nC2 \u2265 b \u221a log(3ap/\u03b4) + \u03c02Lf(x\u2217)\n6 \u221a p\u03b72 + L\u03c03/2\u221a 12p\u03b4\u03b7 ."}], "references": [{"title": "Using Confidence Bounds for Exploitationexploration Trade-offs", "author": ["Auer", "Peter"], "venue": "J. Mach. Learn. Res.,", "citeRegEx": "Auer and Peter.,? \\Q2003\\E", "shortCiteRegEx": "Auer and Peter.", "year": 2003}, {"title": "Batch Bayesian Optimization via Simulation Matching", "author": ["Azimi", "Javad", "Fern", "Alan", "Xiaoli Z"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Azimi et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Azimi et al\\.", "year": 2010}, {"title": "Algorithms for Hyper-Parameter Optimization", "author": ["Bergstra", "James S", "Bardenet", "R\u00e9mi", "Bengio", "Yoshua", "K\u00e9gl", "Bal\u00e1zs"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Bergstra et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Bergstra et al\\.", "year": 2011}, {"title": "A Tutorial on Bayesian Optimization of Expensive Cost Functions, with Application to Active User Modeling and Hierarchical Reinforcement Learning", "author": ["Brochu", "Eric", "Cora", "Vlad M", "de Freitas", "Nando"], "venue": null, "citeRegEx": "Brochu et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Brochu et al\\.", "year": 2010}, {"title": "Convergence Rates of Efficient Global Optimization Algorithms", "author": ["Bull", "Adam D"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Bull and D.,? \\Q2011\\E", "shortCiteRegEx": "Bull and D.", "year": 2011}, {"title": "Joint Optimization and Variable Selection of High-dimensional Gaussian Processes", "author": ["Chen", "Bo", "Castro", "Rui", "Krause", "Andreas"], "venue": "In Int\u2019l Conference on Machine Learning,", "citeRegEx": "Chen et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Chen et al\\.", "year": 2012}, {"title": "Exponential Regret Bounds for Gaussian Process Bandits with Deterministic Observations", "author": ["de Freitas", "Nando", "Smola", "Alex J", "Zoghi", "Masrour"], "venue": "In International Conference on Machine Learning,", "citeRegEx": "Freitas et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Freitas et al\\.", "year": 2012}, {"title": "Learning Where to Attend with Deep Architectures for Image Tracking", "author": ["Denil", "Misha", "Bazzani", "Loris", "Larochelle", "Hugo", "de Freitas", "Nando"], "venue": "Neural Comput.,", "citeRegEx": "Denil et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Denil et al\\.", "year": 2012}, {"title": "High-Dimensional Gaussian Process Bandits", "author": ["Djolonga", "Josip", "Krause", "Andreas", "Cevher", "Volkan"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Djolonga et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Djolonga et al\\.", "year": 2013}, {"title": "Additive gaussian processes", "author": ["Duvenaud", "David K", "Nickisch", "Hannes", "Rasmussen", "Carl Edward"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Duvenaud et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Duvenaud et al\\.", "year": 2011}, {"title": "Posterior consistency of Gaussian process prior for nonparametric binary regression", "author": ["Ghosal", "Subhashis", "Roy", "Anindya"], "venue": "Annals of Statistics,", "citeRegEx": "Ghosal et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Ghosal et al\\.", "year": 2006}, {"title": "Bayesian Optimization for Synthetic Gene Design", "author": ["Gonzalez", "Javier", "Longworth", "Joseph", "James", "David", "Lawrence", "Neil"], "venue": "In NIPS Workshop on Bayesian Optimization in Academia and Industry,", "citeRegEx": "Gonzalez et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Gonzalez et al\\.", "year": 2014}, {"title": "A Distribution Free Theory of Nonparametric Regression", "author": ["Gy\u00f6rfi", "L\u00e1szl\u00f3", "Kohler", "Micael", "Krzyzak", "Adam", "Walk", "Harro"], "venue": "Springer Series in Statistics,", "citeRegEx": "Gy\u00f6rfi et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Gy\u00f6rfi et al\\.", "year": 2002}, {"title": "Generalized Additive Models", "author": ["T.J. Hastie", "R.J. Tibshirani"], "venue": null, "citeRegEx": "Hastie and Tibshirani,? \\Q1990\\E", "shortCiteRegEx": "Hastie and Tibshirani", "year": 1990}, {"title": "Portfolio Allocation for Bayesian Optimization", "author": ["Hoffman", "Matthew D", "Brochu", "Eric", "de Freitas", "Nando"], "venue": "In Uncertainty in Artificial Intelligence,", "citeRegEx": "Hoffman et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Hoffman et al\\.", "year": 2011}, {"title": "Automated Antenna Design with Evolutionary Algorithms", "author": ["G.S. Hornby", "A. Globus", "D.S. Linden", "J.D. Lohn"], "venue": "American Institute of Aeronautics and Astronautics,", "citeRegEx": "Hornby et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Hornby et al\\.", "year": 2006}, {"title": "Lipschitzian Optimization Without the Lipschitz Constant", "author": ["D.R. Jones", "C.D. Perttunen", "B.E. Stuckman"], "venue": "J. Optim. Theory Appl.,", "citeRegEx": "Jones et al\\.,? \\Q1993\\E", "shortCiteRegEx": "Jones et al\\.", "year": 1993}, {"title": "Efficient global optimization of expensive black-box functions", "author": ["Jones", "Donald R", "Schonlau", "Matthias", "Welch", "William J"], "venue": "J. of Global Optimization,", "citeRegEx": "Jones et al\\.,? \\Q1998\\E", "shortCiteRegEx": "Jones et al\\.", "year": 1998}, {"title": "Bayesian Active Learning for Posterior Estimation", "author": ["Kandasamy", "Kirthevasan", "Schneider", "Jeff", "P\u00f3czos", "Barnab\u00e1s"], "venue": "In International Joint Conference on Artificial Intelligence,", "citeRegEx": "Kandasamy et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Kandasamy et al\\.", "year": 2015}, {"title": "Automatic gait optimization with gaussian process regression", "author": ["Lizotte", "Daniel", "Wang", "Tao", "Bowling", "Michael", "Schuurmans", "Dale"], "venue": "In in Proc. of IJCAI,", "citeRegEx": "Lizotte et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Lizotte et al\\.", "year": 2007}, {"title": "Active Pointillistic Pattern Search", "author": ["Ma", "Yifei", "Sutherland", "Dougal J", "Garnett", "Roman", "Schneider", "Jeff G"], "venue": "In International Conference on Artificial Intelligence and Statistics, AISTATS,", "citeRegEx": "Ma et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Ma et al\\.", "year": 2015}, {"title": "Adaptive MCMC with Bayesian Optimization", "author": ["Mahendran", "Nimalan", "Wang", "Ziyu", "Hamze", "Firas", "de Freitas", "Nando"], "venue": "In Artificial Intelligence and Statistics,", "citeRegEx": "Mahendran et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Mahendran et al\\.", "year": 2012}, {"title": "Active Policy Learning for Robot Planning and Exploration under Uncertainty", "author": ["R. Martinez-Cantin", "N. de Freitas", "A. Doucet", "J. Castellanos"], "venue": "In Proceedings of Robotics: Science and Systems,", "citeRegEx": "Martinez.Cantin et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Martinez.Cantin et al\\.", "year": 2007}, {"title": "Bayesian approach to global optimization and application to multiobjective and constrained problems", "author": ["J.B. Mockus", "L.J. Mockus"], "venue": "Journal of Optimization Theory and Applications,", "citeRegEx": "Mockus and Mockus,? \\Q1991\\E", "shortCiteRegEx": "Mockus and Mockus", "year": 1991}, {"title": "Application of Bayesian approach to numerical methods of global and stochastic optimization", "author": ["Mockus", "Jonas"], "venue": "Journal of Global Optimization,", "citeRegEx": "Mockus and Jonas.,? \\Q1994\\E", "shortCiteRegEx": "Mockus and Jonas.", "year": 1994}, {"title": "Active Learning of Model Evidence Using Bayesian Quadrature", "author": ["M. Osborne", "D. Duvenaud", "R. Garnett", "C. Rasmussen", "S. Roberts", "Z. Ghahramani"], "venue": "In Neural Information Processing Systems (NIPS),", "citeRegEx": "Osborne et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Osborne et al\\.", "year": 2012}, {"title": "A Bayesian model selection analysis of WMAP3", "author": ["Parkinson", "David", "Mukherjee", "Pia", "Liddle", "Andrew R"], "venue": "Physical Review,", "citeRegEx": "Parkinson et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Parkinson et al\\.", "year": 2006}, {"title": "Gaussian Processes for Machine Learning. Adaptative computation and machine learning series", "author": ["C.E. Rasmussen", "C.K.I. Williams"], "venue": null, "citeRegEx": "Rasmussen and Williams,? \\Q2006\\E", "shortCiteRegEx": "Rasmussen and Williams", "year": 2006}, {"title": "Sparse Additive Models", "author": ["Ravikumar", "Pradeep", "Lafferty", "John", "Liu", "Han", "Wasserman", "Larry"], "venue": "Journal of the Royal Statistical Society: Series B (Statistical Methodology),", "citeRegEx": "Ravikumar et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Ravikumar et al\\.", "year": 2009}, {"title": "Information Consistency of Nonparametric Gaussian Process Methods", "author": ["Seeger", "MW", "Kakade", "SM", "Foster", "DP"], "venue": "IEEE Transactions on Information Theory,", "citeRegEx": "Seeger et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Seeger et al\\.", "year": 2008}, {"title": "Practical Bayesian Optimization of Machine Learning Algorithms", "author": ["Snoek", "Jasper", "Larochelle", "Hugo", "Adams", "Ryan P"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Snoek et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Snoek et al\\.", "year": 2012}, {"title": "Gaussian Process Optimization in the Bandit Setting: No Regret and Experimental Design", "author": ["Srinivas", "Niranjan", "Krause", "Andreas", "Kakade", "Sham", "Seeger", "Matthias"], "venue": "In International Conference on Machine Learning,", "citeRegEx": "Srinivas et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Srinivas et al\\.", "year": 2010}, {"title": "Cosmological Constraints from the SDSS Luminous Red Galaxies", "author": ["M. Tegmark et al"], "venue": "Physical Review,", "citeRegEx": "al,? \\Q2006\\E", "shortCiteRegEx": "al", "year": 2006}, {"title": "On the Likelihood that one Unknown Probability Exceeds", "author": ["W.R. Thompson"], "venue": "Another in View of the Evidence of Two Samples. Biometrika,", "citeRegEx": "Thompson,? \\Q1933\\E", "shortCiteRegEx": "Thompson", "year": 1933}, {"title": "Rapid Object Detection using a Boosted Cascade of Simple Features", "author": ["Viola", "Paul A", "Jones", "Michael J"], "venue": "In Computer Vision and Pattern Recognition,", "citeRegEx": "Viola et al\\.,? \\Q2001\\E", "shortCiteRegEx": "Viola et al\\.", "year": 2001}, {"title": "Bayesian Optimization in High Dimensions via Random Embeddings", "author": ["Wang", "Ziyu", "Zoghi", "Masrour", "Hutter", "Frank", "Matheson", "David", "de Freitas", "Nando"], "venue": "In International Joint Conference on Artificial Intelligence,", "citeRegEx": "Wang et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Wang et al\\.", "year": 2013}, {"title": "Making a Science of Model Search: Hyperparameter Optimization in Hundreds of Dimensions for Vision Architectures", "author": ["Yamins", "Daniel", "Tax", "David", "Bergstra", "James S"], "venue": "In International Conference on Machine Learning,", "citeRegEx": "Yamins et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Yamins et al\\.", "year": 2013}, {"title": "\u03b7\u22122) and C2 is a constant depending on a, b, D, \u03b4, L and \u03b7. Proof. Srinivas et al. (2010) bound the regret for exact maximisation of the GP-UCB acquisition \u03c6t. By following an analysis similar to our proof of Theorem", "author": ["T + C"], "venue": null, "citeRegEx": "C2.,? \\Q2010\\E", "shortCiteRegEx": "C2.", "year": 2010}, {"title": "The eigenvalues and eigenfunctions for the kernel are defined with respect to a base distribution on X . In the development of Theorem 8, Srinivas et al. (2010) draw nT samples from the uniform distribution on", "author": ["Seeger"], "venue": "X . Hence,", "citeRegEx": "Seeger,? \\Q2008\\E", "shortCiteRegEx": "Seeger", "year": 2008}, {"title": "argue that the uniform distribution still satisfies the required tail constraints and therefore", "author": ["case", "Srinivas"], "venue": null, "citeRegEx": "case and Srinivas,? \\Q2010\\E", "shortCiteRegEx": "case and Srinivas", "year": 2010}], "referenceMentions": [{"referenceID": 30, "context": "Gaussian process bandits and Bayesian optimisation (GPB/ BO) have been successfully applied in many applications such as tuning hyperparameters in learning algorithms (Snoek et al., 2012; Bergstra et al., 2011; Mahendran et al., 2012), robotics (Lizotte et al.", "startOffset": 167, "endOffset": 234}, {"referenceID": 2, "context": "Gaussian process bandits and Bayesian optimisation (GPB/ BO) have been successfully applied in many applications such as tuning hyperparameters in learning algorithms (Snoek et al., 2012; Bergstra et al., 2011; Mahendran et al., 2012), robotics (Lizotte et al.", "startOffset": 167, "endOffset": 234}, {"referenceID": 21, "context": "Gaussian process bandits and Bayesian optimisation (GPB/ BO) have been successfully applied in many applications such as tuning hyperparameters in learning algorithms (Snoek et al., 2012; Bergstra et al., 2011; Mahendran et al., 2012), robotics (Lizotte et al.", "startOffset": 167, "endOffset": 234}, {"referenceID": 19, "context": ", 2012), robotics (Lizotte et al., 2007; Martinez-Cantin et al., 2007) and object tracking (Denil et al.", "startOffset": 18, "endOffset": 70}, {"referenceID": 22, "context": ", 2012), robotics (Lizotte et al., 2007; Martinez-Cantin et al., 2007) and object tracking (Denil et al.", "startOffset": 18, "endOffset": 70}, {"referenceID": 7, "context": ", 2007) and object tracking (Denil et al., 2012).", "startOffset": 28, "endOffset": 48}, {"referenceID": 35, "context": "However, all such successes have been in low (typically < 10) dimensions (Wang et al., 2013).", "startOffset": 73, "endOffset": 92}, {"referenceID": 36, "context": "Expensive high dimensional functions occur in several problems in fields such as computer vision (Yamins et al., 2013), antenna design (Hornby et al.", "startOffset": 97, "endOffset": 118}, {"referenceID": 15, "context": ", 2013), antenna design (Hornby et al., 2006), computational astrophysics (Parkinson et al.", "startOffset": 24, "endOffset": 45}, {"referenceID": 26, "context": ", 2006), computational astrophysics (Parkinson et al., 2006) and biology (Gonzalez et al.", "startOffset": 36, "endOffset": 60}, {"referenceID": 11, "context": ", 2006) and biology (Gonzalez et al., 2014).", "startOffset": 20, "endOffset": 43}, {"referenceID": 31, "context": "Even current theoretical results suggest that GPB/ BO is exponentially difficult in high dimensions without further assumptions (Srinivas et al., 2010; Bull, 2011).", "startOffset": 128, "endOffset": 163}, {"referenceID": 12, "context": "Nonparametric regression is inherently difficult in high dimensions with known lower bounds depending exponentially in dimension (Gy\u00f6rfi et al., 2002).", "startOffset": 129, "endOffset": 150}, {"referenceID": 25, "context": "GPB/ BO methods follow a family of GP based active learning methods which select the next experiment based on the posterior (Osborne et al., 2012; Ma et al., 2015; Kandasamy et al., 2015).", "startOffset": 124, "endOffset": 187}, {"referenceID": 20, "context": "GPB/ BO methods follow a family of GP based active learning methods which select the next experiment based on the posterior (Osborne et al., 2012; Ma et al., 2015; Kandasamy et al., 2015).", "startOffset": 124, "endOffset": 187}, {"referenceID": 18, "context": "GPB/ BO methods follow a family of GP based active learning methods which select the next experiment based on the posterior (Osborne et al., 2012; Ma et al., 2015; Kandasamy et al., 2015).", "startOffset": 124, "endOffset": 187}, {"referenceID": 17, "context": "In the GPB/ BO setting, common acquisition functions include Expected improvement (Mockus, 1994), probability of improvement (Jones et al., 1998), Thompson sampling (Thompson, 1933) and upper confidence bound (Auer, 2003).", "startOffset": 125, "endOffset": 145}, {"referenceID": 33, "context": ", 1998), Thompson sampling (Thompson, 1933) and upper confidence bound (Auer, 2003).", "startOffset": 27, "endOffset": 43}, {"referenceID": 14, "context": "Some literature studies variants, such as combining several acquisition functions (Hoffman et al., 2011) and querying in batches (Azimi et al.", "startOffset": 82, "endOffset": 104}, {"referenceID": 1, "context": ", 2011) and querying in batches (Azimi et al., 2010).", "startOffset": 32, "endOffset": 52}, {"referenceID": 13, "context": "In the GPB/ BO setting, common acquisition functions include Expected improvement (Mockus, 1994), probability of improvement (Jones et al., 1998), Thompson sampling (Thompson, 1933) and upper confidence bound (Auer, 2003). Of particular interest to us, is the Gaussian process upper confidence bound (GPUCB). It was first proposed and analysed in the noisy setting by Srinivas et al. (2010) and extended to the noiseless case by de Freitas et al.", "startOffset": 126, "endOffset": 391}, {"referenceID": 5, "context": "(2010) and extended to the noiseless case by de Freitas et al. (2012). Some literature studies variants, such as combining several acquisition functions (Hoffman et al.", "startOffset": 48, "endOffset": 70}, {"referenceID": 5, "context": "To our knowledge, most literature for GPB/ BO in high dimensions are in the setting where the function varies only along a very low dimensional subspace (Chen et al., 2012; Wang et al., 2013; Djolonga et al., 2013).", "startOffset": 153, "endOffset": 214}, {"referenceID": 35, "context": "To our knowledge, most literature for GPB/ BO in high dimensions are in the setting where the function varies only along a very low dimensional subspace (Chen et al., 2012; Wang et al., 2013; Djolonga et al., 2013).", "startOffset": 153, "endOffset": 214}, {"referenceID": 8, "context": "To our knowledge, most literature for GPB/ BO in high dimensions are in the setting where the function varies only along a very low dimensional subspace (Chen et al., 2012; Wang et al., 2013; Djolonga et al., 2013).", "startOffset": 153, "endOffset": 214}, {"referenceID": 5, "context": "general than the setting in Chen et al. (2012). Even though it does not contain the settings in Djolonga et al.", "startOffset": 28, "endOffset": 47}, {"referenceID": 5, "context": "general than the setting in Chen et al. (2012). Even though it does not contain the settings in Djolonga et al. (2013); Wang et al.", "startOffset": 28, "endOffset": 119}, {"referenceID": 5, "context": "general than the setting in Chen et al. (2012). Even though it does not contain the settings in Djolonga et al. (2013); Wang et al. (2013), unlike them, we still allow the function to vary along the entire domain.", "startOffset": 28, "endOffset": 139}, {"referenceID": 30, "context": "Using an additive structure is standard in high dimensional regression literature both in the GP framework and otherwise. Hastie & Tibshirani (1990); Ravikumar et al.", "startOffset": 57, "endOffset": 149}, {"referenceID": 27, "context": "Hastie & Tibshirani (1990); Ravikumar et al. (2009) treat the function as a sum of one dimensional components.", "startOffset": 28, "endOffset": 52}, {"referenceID": 9, "context": "Duvenaud et al. (2011) assume a sum of functions of all combinations of lower dimensional coordinates.", "startOffset": 0, "endOffset": 23}, {"referenceID": 3, "context": "Common techniques to maximise \u03c6t include grid search, Monte Carlo and multistart methods (Brochu et al., 2010).", "startOffset": 89, "endOffset": 110}, {"referenceID": 3, "context": "Common techniques to maximise \u03c6t include grid search, Monte Carlo and multistart methods (Brochu et al., 2010). In our work we use the Dividing Rectangles (DiRect) algorithm of Jones et al. (1993). While these methods are efficient in low dimensions they require exponential computation in high dimensions.", "startOffset": 90, "endOffset": 197}, {"referenceID": 31, "context": "Following Srinivas et al. (2010), we first bound the statistical difficulty of the problem as determined by the kernel.", "startOffset": 10, "endOffset": 33}, {"referenceID": 31, "context": "Srinivas et al. (2010) showed that the statistical difficulty of GPB/ BO is determined by the Maximum Information Gain as defined below.", "startOffset": 0, "endOffset": 23}, {"referenceID": 31, "context": "In contrast, for a D order kernel this is exponential (Srinivas et al., 2010).", "startOffset": 54, "endOffset": 77}, {"referenceID": 29, "context": "We use bounds on the eigenvalues of the SE and Mat\u00e9rn kernels from Seeger et al. (2008) and a result from Srinivas et al.", "startOffset": 67, "endOffset": 88}, {"referenceID": 29, "context": "We use bounds on the eigenvalues of the SE and Mat\u00e9rn kernels from Seeger et al. (2008) and a result from Srinivas et al. (2010) which bounds the information gain via the eigendecay of the kernel.", "startOffset": 67, "endOffset": 129}, {"referenceID": 31, "context": "Part of our proof uses ideas from Srinivas et al. (2010). We show that \u2211 j \u03b2t\u03c3 (j) t\u22121(\u00b7) forms a credible interval for f(\u00b7) about the posterior mean \u03bct(\u00b7) for an additive kernel in Add-GP-UCB.", "startOffset": 34, "endOffset": 57}, {"referenceID": 9, "context": "One could consider alternative lower order kernels \u2013 one candidate is the sum of all possible d order kernels (Duvenaud et al., 2011).", "startOffset": 110, "endOffset": 133}, {"referenceID": 31, "context": "Choice of \u03b2t: \u03b2t as specified by Theorems 5, usually tends to be conservative in practice (Srinivas et al., 2010).", "startOffset": 90, "endOffset": 113}, {"referenceID": 32, "context": "Data dependent prior: Our analysis assumes that we know the GP kernel of the prior. In reality this is rarely the case. In our experiments, we choose the hyperparameters of the kernel by maximising the GP marginal likelihood (Rasmussen & Williams, 2006) every Ncyc iterations. Initialisation: Marginal likelihood based kernel tuning can be unreliable with few data points. This is a problem in the first few iterations. Following the recommendations in Bull (2011) we initialise Add-GP-UCB (and GP-UCB) using Ninit points selected uniformly at random.", "startOffset": 28, "endOffset": 465}, {"referenceID": 3, "context": "Following, Brochu et al. (2010) we use DiRect to maximise \u03c6t, \u03c6\u0303t.", "startOffset": 11, "endOffset": 32}, {"referenceID": 3, "context": "Following, Brochu et al. (2010) we use DiRect to maximise \u03c6t, \u03c6\u0303t. We compare Add-GP-UCB against GP-UCB, random querying (RAND) and DiRect3. On the real datasets we also compare it to the Expected Improvement (GP-EI) acquisition function which is popular in BO applications and the method of Wang et al. (2013) which uses a random projection before applying BO (REMBO).", "startOffset": 11, "endOffset": 311}, {"referenceID": 32, "context": "Here we used Galaxy data from the Sloan Digital Sky Survey (SDSS). The task is to find the maximum likelihood estimators for a simulation based astrophysical likelihood model. Data and software for computing the likelihood are taken from Tegmark et al (2006). The software itself takes in only 9 parameters but we augment this to 20 dimensions to emulate the fact that in practical astrophysical problems we may not know the true parameters on which the problem is dependent.", "startOffset": 14, "endOffset": 259}], "year": 2016, "abstractText": "Bayesian Optimisation (BO) is a technique used in optimising a D-dimensional function which is typically expensive to evaluate. While there have been many successes for BO in low dimensions, scaling it to high dimensions has been notoriously difficult. Existing literature on the topic are under very restrictive settings. In this paper, we identify two key challenges in this endeavour. We tackle these challenges by assuming an additive structure for the function. This setting is substantially more expressive and contains a richer class of functions than previous work. We prove that, for additive functions the regret has only linear dependence on D even though the function depends on all D dimensions. We also demonstrate several other statistical and computational benefits in our framework. Via synthetic examples, a scientific simulation and a face detection problem we demonstrate that our method outperforms naive BO on additive functions and on several examples where the function is not additive.", "creator": "LaTeX with hyperref package"}}}