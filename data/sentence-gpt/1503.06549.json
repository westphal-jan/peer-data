{"id": "1503.06549", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "23-Mar-2015", "title": "Optimum Reject Options for Prototype-based Classification", "abstract": "We analyse optimum reject strategies for prototype-based classifiers and real-valued rejection measures, using the distance of a data point to the closest prototype or probabilistic counterparts. We compare reject schemes with global thresholds, and local thresholds for the Voronoi cells of the classifier. For the latter, we develop a polynomial-time algorithm to compute optimum thresholds based on a dynamic programming scheme, and we propose an intuitive linear time, memory efficient approximation thereof with competitive accuracy. Evaluating the performance in various benchmarks, we conclude that local reject options are beneficial in particular for simple prototype-based classifiers, while the improvement is less pronounced for advanced models. For the latter, an accuracy-reject curve which is comparable to support vector machine classifiers with state of the art reject options can be reached.\n\n\n\n\n\n\n\n\nThe results are presented in the second paper. In other words, in the first paper, we use a nonlinear time that is also comparable to the previous paper. In other words, it is possible to achieve a \"supervised\" time by modeling a model of the state of the game, for example, a vector of a random state with a set of parameters that can be manipulated by the user to reduce the probability that the model will change after the implementation of a model. We also use a nonlinear time for simulation of the state of a game.\n\nWe define the nonlinear time of a test, which is the time of the simulation, which is a state where the system is continuously active. In this case, we define the nonlinear time of a test, which is a state where the system is continuously active. In this case, the model of the state of the game is constant with the state of a test. In this case, we define the nonlinear time of a test.\nThe game is not currently an accurate simulation, but it is a good model to work with. The game's real-valued state can be derived from a set of parameters which can be manipulated in this manner. In this case, we define the nonlinear time of a test, which is a state where the system is continuously active. In this case, we define the nonlinear time of a test.\nWe describe the nonlinear time of a test. In the following paper, we use a nonlinear time of a test. In this case, we define the nonlinear time of a test. In this case, we define the nonlinear time of a test. In", "histories": [["v1", "Mon, 23 Mar 2015 08:19:17 GMT  (709kb,D)", "http://arxiv.org/abs/1503.06549v1", "19 pages"]], "COMMENTS": "19 pages", "reviews": [], "SUBJECTS": "cs.LG", "authors": ["lydia fischer", "barbara hammer", "heiko wersing"], "accepted": false, "id": "1503.06549"}, "pdf": {"name": "1503.06549.pdf", "metadata": {"source": "CRF", "title": "Optimum Reject Options for Prototype-based Classification", "authors": ["Lydia Fischer", "Barbara Hammer", "Heiko Wersing"], "emails": [], "sections": [{"heading": null, "text": "Keywords: classification, prototype-based, distance-based, reject option, local strategies"}, {"heading": "1 Introduction", "text": ""}, {"heading": "1.1 Motivation", "text": "Classification constitutes one of the standard application scenarios for machine learning techniques: Its application ranges from automated digit recognition up to fraud detection, and numerous machine learning models are readily available for this task [9]. Often, besides the overall classification accuracy, the flexibility of the classification model to handle uncertain predictions plays an important role. Techniques which provide a level of certainty together with the predicted class label can trade classification security for a partial prediction of\n\u2217L. Fischer acknowledges funding by the CoR-Lab Research Institute for Cognition and Robotics and gratefully acknowledges the financial support from the Honda Research Institute Europe. B. Hammer gratefully acknowledges funding by the CITEC center of excellence.\nthe labels; in the latter case, data for which the prediction is insecure are rejected. In particular applications which require a life long learning or an adaptation to changing conditions benefit from such flexible classification models [32]. Moreover, in safety critical areas such as driver assistance systems, health care, or biomedical data analysis, the information about the certainty of the classification is almost as important as the class label itself. Further tests or expert opinions can be consulted for uncertain classification to avoid critical effects of a misclassification for instance in health care. For driver assistance systems, a high degree of uncertainty can result in turning off the assistance system and passing the responsibility back to the human driver. In all settings, the possibility of a machine learning classifier to reject a classification in case of a low classification confidence is crucial.\nReject options have been pioneered by the formal framework as investigated in the approach [12]: If the costs for a misclassification versus a reject are known, one can design an optimum reject threshold based on the probability of misclassification. In practice, however, the exact probability of a misclassification is generally unknown. Hence further research addresses the question whether reject options can be based on plugin rules where only empirical estimates of the misclassification probability are used [27]. Still, these formalisations rely on consistent probability estimates, which are often not present for given classifiers. Further, rejection and misclassification costs need to be known and constant, which is not necessarily the case in particular for online settings. Thus, these settings deal with an idealised modelling and are not necessarily applicable for efficient, possibly deterministic classifiers in complex scenarios.\nSome machine learning classifiers allow an intuitive incorporation of reject options. Naturally, probabilistic classifiers can directly be plugged into the framework as\nar X\niv :1\n50 3.\n06 54\n9v 1\n[ cs\n.L G\n] 2\n3 M\nar 2\n01 5\nanalysed in [27]. In particular, probabilistic classifiers provide confidence values for which the given scaling is meaningful, provided the probability estimation is correct. The latter is often not the case since the model assumptions need not hold, the model often relies on simplified assumptions, or model priors are chosen based on computational feasibility rather than the (unknown) underlying truth. Further, the inference of exact probabilistic models is not always feasible, depending on the type and size of data and the available ground truth.\nOne principled alternative to enhance given classifiers by confidence values is offered by bootstrapping [9]. This, however, requires repeated training with the available training data, such that it displays a high computational and memory complexity. Further, it is not applicable for online settings where data are not necessarily independent and identically distributed. For online learning, the theory of conformal prediction has caused quite some interest recently [53, 45]. The formalism is based on a so called non-conformity measure; having chosen a suitable criterion, it provides a statistically well founded theory to estimate the confidence of a classification in online settings, where data have to fulfil the weaker property of interchangeability only rather than being i. i. d., see [53, 45]. In practice, however, the choice of the non-conformity measure is very critical and suboptimal choices do not lead to meaningful results. Further, the original approach is very time consuming since it requires the re-training of the model in a leaveone-out fashion. Albeit efficient approximations exist for some classifiers such as prototype-based models, the formal guarantees usually do no longer hold for the latter [55].\nThere have been attempts to accompany powerful deterministic classifiers by efficient ways of confidence estimation. One popular example is given for the support vector machine (SVM), see the approach [36] for two-class classification and the work [54] for extensions towards multiple classes. These techniques are implemented e. g. in the popular LIBSVM [11]. In this article, we are interested in an alternative classification paradigm: Prototype-based models which represent classes in terms of typical representatives and thus allow a direct inspection of the classifier. This feature has contributed to an increasing popularity of these models in particular in the biomedical domain, see e. g. [7, 1, 29, 2], by offering an elegant representation which lends itself to model interpretability in a natural way [52, 22, 38]. Further, the representation of models in terms of few representative prototypes has proved useful when dealing\nwith online scenarios or big data sets [24, 31, 32]. While some approaches exist to accompany nearest neighbour based classification or Gaussian mixture models (GMM) by confidence estimations [50, 28], first reject options for discriminative prototype-based methods such as learning vector quantisation have only recently been proposed [19, 21]. In this article, we will built on the insights as gained in the recent approaches [19, 21], and we will investigate how to optimally set the thresholds within intuitive reject schemes for prototype-based techniques.\nWhile the threshold selection strategies which we will investigate can be used for any prototype-based classification scheme, we will focus on the popular supervised classification technique learning vector quantisation (LVQ) and its recent more fundamental mathematical derivatives [33, 43, 40, 42]. LVQ constitutes a powerful and efficient method for multi-class classification tasks which, due to its simple representation of models in terms of prototypes, is particularly suited for interpretability, online scenarios or life long learning [32]. While classical LVQ models mostly rely on heuristics, modern variants are based on cost-functions such as generalized LVQ (GLVQ) [39], or the full probabilistic model robust soft LVQ (RSLVQ) [43]. LVQ classifiers can be accompanied by strong guarantees concerning their generalization performance and learning dynamics [40, 6]. One particular success story links LVQ classifiers to metric learners: These enrich the classifier by feature weighting terms which opens the way towards a more flexible classification scheme, increased model interpretability, and even a simultaneous visualisation of the classifier [40, 42, 5]. Further, recent LVQ variants address the setting of complex, possibly non-euclidean data which are described by pairwise similarities or dissimilarities only [25]. Apart from the probabilistic model RSLVQ, these classifiers are often deterministic and do not provide a confidence of the classification. Further, also for RSLVQ, the correctness of the probability estimate is not clear since the model is not designed in order to correctly model the data probability but the conditional label probability only [6, 21].\nIn this contribution, building on the results as recently published in [19] which proposes different real-valued certainty measures suitable for an integration in a reject option, we investigate how to devise optimum reject strategies for LVQ type classifiers, putting a particular emphasis on the choice of the threshold for a reject. In particular, we are interested in efficient, onlinecomputable reject options for LVQ classifiers and their behaviour in comparison to mathematically well founded\nstatistical models and the SVM [10, 14]. We will compare reject strategies based on one global reject threshold, and local reject thresholds which take into account the Voronoi tessellation of the space induced by the prototypes. For the latter, we present an optimum computation scheme how to set the threshold for the different Voronoi cells, and we also propose a time and memory efficient approximation thereof which lends itself to online scenarios. We evaluate the techniques extensively using different benchmark data and different types of LVQ classifiers, also providing a comparison to classification with rejection based on SVM. Further, we demonstrate the suitability of the devised technique for a real life example from a medical domain.\nThis contribution is structured as follows: In section 1.2 we give an overview about existing methods to enhance classifiers by reject options. Afterwards in section 2 we explain the LVQ training algorithms that we use in our experiments and introduce in section 3 the basic schemes how to reject based on global or local thresholds. Thereby, we develop a polynomial time scheme based on dynamic programming (DP), that allows an optimum choice of local thresholds, as well as a time and memory efficient greedy approximation thereof. Further, we present in section 3.1 suitable certainty measures that can be plugged into these reject schemes. In the experiments section 5, we test the techniques using different benchmarks and LVQ learning schemes. We illustrate the suitability of the methods, whereby we put a particular emphasis on the comparison of local versus global reject schemes, the comparison of an optimum computation of local thresholds by means of DP versus an efficient greedy scheme, and a comparison of the proposed reject schemes for highly flexible LVQ classifiers with state of the art reject options which accompany an SVM. For all experiments, evaluation will rely on the full accuracy-reject curve as proposed in the approach [34]."}, {"heading": "1.2 Related Work", "text": "The following section summarises the state of the art for reject options and accompanying certainty measures in supervised learning. The approach [50] highlights two main reasons for rejection:\n\u2022 Ambiguity: It is not clear how to classify the data point, e. g. the point is close to at least one decision boundary, or it lies in a region where at least two classes are overlapping.\n\u2022 Outliers: The data point is dissimilar to any already seen data point, e. g. it is caused by noise or it is an instance of a yet unseen class or cluster.\nThere exist several approaches which explicitly address one of these reasons or a combination of both. Mostly, reject options are based on a measure which provides a certainty value about whether a given data point is correctly classified. In the following, we distinguish measures which are based on heuristics and approaches which are based on estimates of misclassification probabilities or confidences. We primarily focus on techniques which have been proposed for distance-based classifiers and similar due to their similarity to LVQ techniques.\nHeuristic Measures: For k-nearest neighbour (k-NN) [15] approaches a variety of simple certainty measures exist using a neighbourhood of a given data point [16, 28]. These measures rely on the correlation of the label of the data point and its neighbours (cp. Fig. 1). In these approaches, several different\nrealisations and combinations of the counting have been compared, leading to the result that an ensemble measure largely rises the stability of the single measures. The approach [48] focusses on effective outlier detection, relying on the distances of a new data point from elements of a randomly chosen subset of the given data. An outlier score is then given by the smallest distance. The resulting method outperforms state of the art approaches such as proposed in [37] in efficiency and accuracy.\nSousa & Cardoso [46] introduce a reject option which identifies ambiguous regions in binary classifications. Their approach is based on a data replication method. An advantage of the proposed strategy is given by the fact that no reject threshold has to be set externally, rather the technique itself provides a suitable cutoff.\nThe approach [47] addresses different neural network architectures including multi-layer perceptrons, learning vector quantisation, and probabilistic neural networks. Here an effectiveness function is introduced taking different costs for rejection and classification errors into account, very similar to the loss function as considered in [12, 27]. Then, different rejection measures based on the activation of the output neurons are investigated.\nA very popular approach to turn the activity provided by a binary SVM into an approximation of a classification confidence measure has been proposed by Platt [36]. The certainty measure is based on the distance of a data point to the decision border, i. e. the activation of an SVM classifier. By means of\na non-linear sigmoidal function, the distance is transformed to a confidence value. Thereby, the parameters of the sigmoidal are fitted on the given training data (Fig. 2). A transfer of this method for multi-class tasks is provided by Wu et al. [54] and it is implemented in the popular LIBSVM toolbox [11].\nProbabilistic Measures: There exist several approaches which more closely rely on an explicit probabilistic modelling of the data. As already mentioned, the approach [12] investigates optimum reject options provided the true probability density function is known. This rule can therefore serve as a baseline provided this ground truth is available. In the limit case, this reject strategy provides a bound for any other measure in the sense of the error-reject trade-of, as proved in [26]. Hansen et al. also extent Chows\u2019s rule [12] to near optimal classifiers on finite data sets, and they introduce a general scaling to compare error-reject curves of several independent experiments even with different classifiers or data sets. The work as presented in [23] also directly builds on [12] and more closely investigates the decomposition of data into different regions as concerns the given classes and potential errors. They propose a strategy which is based on class related thresholds for more flexibility and better results in practice. The setting that reliable class probabilities are unavailable and only empirical estimations thereof are available, is addressed in the approach [27].\nDue to this theoretical background, many approaches follow the roadmap to empirically estimate the data distribution first. Often, GMMs are used for this purpose [17, 50]. Devarakota et al. [17] extend a GMM to estimate the insecurity of a particular class membership for novel, previously unseen patterns of a new class; this estimation can yield to a reliable outlier reject option.\nVailaya & Jain [50] investigate the suitability of GMMs for both, rejection of outliers and ambiguous data. In particular, they propose an efficient strategy how to determine suitable reject thresholds in these cases. The reliable estimation of GMMs is particularly problematic for high dimensional data. Therefore, Ishidera et al. [30] propose a suitable approximation of the probability density function for high dimensionality, which is based on a low dimensional projection of the data.\nThese approaches while providing baselines against which to compare, do not address our setting of prototype-based multi-class classifiers. We will rely on two ingredients for an efficient reject option: (I) A suitable real-valued certainty measure [19, 20] and (II) A suitable definition of how to set a threshold for rejection. In most classical reject schemes as summarised above, one global threshold value is taken, and an optimum value depends on the respective costs of misclassification versus reject. This, however, relies on the assumption of a suitable global scaling of the underlying certainty measure, an assumption which is usually not met in a given setting. Therefore, we will focus on possibilities how to define optimum local thresholds, which release the burden of a globally appropriate scaling of the underlying certainty measure. In particular, we will propose efficient schemes how to optimise local thresholds which are attached to the Voronoi cells given by the prototype-based model.\nFirst we introduce prototype-based classifiers and the most relevant training schemes used in the following."}, {"heading": "2 Prototype-based Classifiers", "text": "A prototype-based classifier is characterised by a set W of \u03be prototypes (w j,c(w j))\u2208RM\u00d7{1, . . . ,Z}, whereby every prototype w is equipped with a class label c(w). Classification takes place by a winner takes all rule (WTA): Given a data point x, its label becomes the label of the closest prototype\nc(x) = c(wl) with l = arg min w j\u2208W d(w j,x) (1)\nwhere d is a distance measure; a common choice for d is the Euclidean distance. The closest prototype wl , the winner, is called the best matching unit. Note that prototype-based models are very similar to k-NN classifiers [15] which stores all training data points as prototypes and predict a label according to the closest (k = 1) or the k closest data points. In contrast, prototype-based\ntraining models aim at a sparser representation of data by a predefined number of prototypes. By means of the WTA rule, a prototype-based classifier decomposes the data into Voronoi cells or receptive fields\nVj = {x|d(w j,x)\u2264 d(wk,x),\u2200k 6= j}, j = 1, . . . ,\u03be ; (2) and it defines a constant classification on any Voronoi cell given by the label of its representative prototype.\nPrototype locations are usually learned based on given data. Assume a training data set X is given with N data points (xi,yi) \u2208 RM \u00d7{1, . . . ,Z}. Z states the number of different classes. The goal is to find prototype locations such that the induced classification of the data is as accurate as possible. Classical training techniques are often based on heuristics such as the Hebbian learning paradigm [33], yielding surprisingly good results in typical model situations, see [6]. More recent training schemes usually rely on a suitable cost function, including generalised LVQ (GLVQ) [39], its extension to an adaptive matrix: generalized matrix LVQ (GMLVQ) [40], its local version (LGMLVQ) [40] with local adaptive metrics, and statistical counterparts referred to as robust soft LVQ (RSLVQ) [43]. We will focus on GLVQ and its matrix version as a particularly efficient and powerful scheme, as well as RSLVQ as a full probabilistic model for which an explicit certainty value is directly available.\nGMLVQ: The Generalized Matrix Learning Vector Quantization [40] performs a stochastic gradient decent on the cost function in [39] with a more general metric d\u039b than the standard Euclidean one. This cost function is a differentiable function which strongly correlates to the (discrete) classification error:\nEGMLVQ = N\n\u2211 i=1\n\u03a6 (\nd+\u039b \u2212d\u2212\u039b d+\u039b +d \u2212 \u039b\n) . (3)\nHere, the metric d\u039b is defined as general quadratic form\nd\u039b(w,x) = (x\u2212w)T \u039b(x\u2212w) (4)\nwith a semi positive definite matrix \u039b. The value d+\u039b = d\u039b(w j,xi) is the distance of a data point xi to the closest prototype w j belonging to the same class and d\u2212\u039b = d\u039b(wk,xi) is the distance of a data point xi to the closest prototype wk belonging to a different class. \u03a6 is a monotonically increasing function, e. g. the identity or the logistic function. The summands in this cost function are negative if and only if the classification\nof the corresponding point is correct, hence the costs correlate to the overall error and optimise the so-called hypothesis margin of the classifier [40]. Note that the value (d+\u039b \u2212 d\u2212\u039b )/(d+\u039b + d\u2212\u039b ) is in between (\u22121,0] for points xi which are in the Voronoi cell of the prototype w j corresponding to d+\u039b . A value close to \u22121 indicates that the data point xi is very close to the prototype and the classification is very certain, while a value close to 0 refers to points at the class boundary or outliers.\nGMLVQ training is derived from these costs (3) by a stochastic gradient descent with respect to the prototype locations and the metric parameters \u039b. Thereby, either a global matrix \u039b is used, or local matrices \u039b j are adapted which induce the distance value for the Voronoi cell of prototypes w j only:\nd\u039b j(w j,x) = (x\u2212w j)T \u039b j(x\u2212w j) . (5)\nThe algorithm which refers to these local metrics (5) is called local GMLVQ (LGMLVQ) [40].\nRSLVQ: The objective function of Robust Soft Learning Vector Quantization [43] corresponds to a statistical modelling of the setting. It relies on the assumption that data points are generated by a GMM. The probability of mixture component j generating data point x is\np(x| j) = 1 (2\u03c0\u03c32j )M/2\n\u00b7 exp ( \u2212d(w j,x)\n2\u03c32j ) This induces the mixture model\np(x|W ) = \u2211 1\u2264 j\u2264\u03be P( j) \u00b7 p(x| j)\nwhich describes the probability of having observed the (unlabelled) data. The priors sum to one \u2211 j P( j) = 1. Label information is incorporated into the model by enhancing every mixture component (i. e. every prototype) with a class label. Then the probability of having observed the labelled data is given by\np(x,y|W ) = \u2211 j:c(w j)=y P( j) \u00b7 p(x| j).\nThe objective function of RSLVQ is defined as the log likelihood ratio of the observed data\nlogL := \u2211 1\u2264i\u2264N\nlog p(xi,yi|W )\np(xi|W )\nwhich corresponds to the optimisation of the likelihood of the observed class labels assuming an underlying\nmixture model and independence of the data. Training optimises these costs by means of a gradient ascend with respect to the prototype locations. The bandwidth \u03c3 j is typically set identically for all mixture components, and it is treated as a meta-parameter. There exist schemes which also adapt the bandwidth [41, 44]."}, {"heading": "3 Rejection Strategies", "text": "We are interested in rejection strategies for prototypebased classifiers or similar models that rely on two main ingredients:\n1. A certainty measure which assigns a degree of certainty r(x) to every data point x indicating the certainty of the predicted class label,\n2. and a strategy how to reject a classification based on the certainty value; suitable reject strategies have to take into account that r(x) is not necessarily scaled in an easily interpretable or uniform way. This means, the exact value r(x) does not necessarily coincide with the statistical confidence (which would be uniformly scaled in [0,1]), and the scaling of the value r(x) might even change depending on the location of the data point x.\nFirst, we shortly review suitable certainty measures r(x) before discussing optimum reject strategies based thereon."}, {"heading": "3.1 Certainty Measures", "text": "In the recent approaches [19, 20] several certainty measures have been proposed and evaluated for prototypebased classification. We will use three measures which scored best in the experiments as presented in [19, 20]:\nBayesian Confidence Value: Chow analysed the error-reject trade-off of Bayes classification. He introduced an optimal certainty measure in the sense of errorreject trade-off [12]. The certainty value for a data point x in case of a Bayes classifier is defined as:\nr(x) = Bayes(x) := max 1\u2264 j\u2264Z P( j|x) (6)\nwhere P( j|x) is the known probability of class j for a given data point x (Fig. 3, left). This value can be interpreted as follows: If the highest probability for any class with given x is lower than a defined threshold \u03b8\nthe probability of making a mistake is relatively high. Classification of such data is insecure according to the chosen \u03b8 . For a binary problem the Bayes reject rule (6) defines an interval around the decision border.\nEmpirical Estimation of the Bayesian Probability: Probabilistic models like the RSLVQ model provide explicit estimations of the probability of class j given a data point x. We refer to these empirical estimates as P\u0302( j|x) and they induce a certainty measure of the form\nr(x) = Conf(x) =: max 1\u2264 j\u2264Z P\u0302( j|x) . (7)\nAn exemplary result of this measure shows Fig. 3 (right).\nRelative Similarity: The relative similarity (RelSim) has been proposed as a certainty measure closely related to the GMLVQ cost function (3), see [39, 19]. It relies on the normalised distance of a data point x to the closest prototype d+ and the distance of x to a closest prototype of a different class d\u2212 (Fig. 4):\nr(x) = RelSim(x) = d\u2212\u2212d+ d\u2212+d+\n(8)\nwhereby d is the distance measure of the used algorithm (d\u039b (4) or d\u039b j (5)). Note that the prototype which\nbelongs to d+ also defines the class label of x. The certainty measure RelSim ranges in the interval [0,1) where values near 1 indicate a certain classification and values near 0 are an indicator for very uncertain class labels.\nThe values d+ and d\u2212 are calculated within GLVQ training schemes, hence no additional computational costs are caused by this certainty measure for training set data. Furthermore RelSim (8) depends on the stored prototypes W only. Therefore no additional storage is needed when computing the certainty of a new unlabelled data point x. Figure 5 shows the contour lines of RelSim (8) for an artificial five class problem with trained prototypes by the GMLVQ without metric adaptation, i. e. \u039bii = 1 and \u039bi j = 0, i 6= j. The certainty values near the class borders are low, hence the measure correctly identifies ambiguous classifications. In addition, the contour lines have a circular shape, such that the certainty measure also correctly identifies outliers which have a large distance from the learned prototypes."}, {"heading": "3.2 Global Reject Option", "text": "A global reject option extends a certainty measure by a global threshold for the whole input space. Assume that\nr(x) : RM \u2192 R, x 7\u2192 r(x) (9)\nrefers to a certainty measure where a higher value indicates higher certainty. Given a real-valued threshold \u03b8 \u2208 R, a data point x is rejected if and only if\nr(x)< \u03b8 . (10)\nAn example of this rejection strategy is shown in Fig. 6. The reject option operates optimally if only\nlabelling errors are rejected. In general this is not the case and a reject measure leads to the rejection of a few correctly classified data points together with errors. For optimum rejects, the number of false rejects should be as small as possible, while rejecting as many as possible true rejects."}, {"heading": "3.3 Local Reject Option", "text": "Global reject options rely on the assumption that the scaling of the certainty measure r(x) is the same for all inputs x. This assumption can be weakened by introducing local threshold strategies. A local threshold strategy relies on a partitioning of the input space into several regions and a different choice of the reject threshold for every region; this way, it enables a finer control of rejection [50, 18]. Following the suggestion in [50], we use the natural decomposition of the input space into the Voronoi-cells Vj as introduced in Eq. (2). A separate threshold \u03b8 j \u2208 R is chosen for every Voronoi cell, and the reject option is given by a threshold vector \u03b8 = (\u03b81, . . . ,\u03b8\u03be ) of the dimension \u03be equal to the number of Voronoi cells Vj. A data point x is rejected iff\nr(x)< \u03b8 j where x \u2208Vj .\nThis means the threshold \u03b8 j determines the behaviour for the region Vj only. In the case of one prototype per class local thresholds realise a class-wise reject option. For the example in Fig. 6 a local rejection would lead to a three-dimensional threshold vector \u03b8 = (\u03b81,\u03b82,\u03b83)."}, {"heading": "4 Optimum Choices of Reject Thresholds", "text": "We consider ways how to set a threshold (threshold vector) optimally for a given classifier. Note that rejection\nrefers to a multi-objective: A threshold \u03b8 (a threshold vector \u03b8 ) should be chosen in such a way that the rejection of errors is maximised, while the rejection of correctly classified data points is minimised. To formalise this fact, and a corresponding evaluation criterion, we explain some terms which we will use later on, first.\nAssume a given data set X (|X | = N) with labelled data for evaluation. Applying a classification algorithm, this set decomposes into a set of correctly classified data points L and a set of wrongly classified data points (errors) E, i. e. X = L\u222aE. An optimum reject would reject all points E, while classifying all points L. Naturally, this is usually not possible using a local or global reject option. Using a global (local) reject option by applying a threshold \u03b8 (threshold vector \u03b8 ), the data set X decomposes into a set of rejected data points X\u03b8 and a set of data points remaining in the system X\u03b8 , i. e. X = X\u03b8 \u222aX\u03b8 . We refer to data points\nL\u03b8 = X\u03b8 \u2229L\nas false rejects because the rejection of correctly classified data points is undesired. The rejection of errors\nE\u03b8 = X\u03b8 \u2229E\nis desired therefore we call them true rejects. Obviously, we can decompose X\u03b8 = E\u03b8 \u222aL\u03b8 .\nFor an evaluation, we want to report the accuracy of the obtained classifier, taking the rejected points into account. This multi-objective can be evaluated by a reference to the so-called accuracy reject curve (ARC) [34]. For a given threshold \u03b8 (threshold vector \u03b8 ), this counts the accuracy of the classified points\nta(\u03b8) := (|L|\u2212 |L\u03b8 |)/|X\u03b8 | (11)\nversus the ratio of the classified points\ntc(\u03b8) := |X\u03b8 |/|X | . (12)\nThese two measures quantify contradictory objectives with limits ta(\u03b8) = 1 and tc(\u03b8) = 0 for large \u03b8 (all points are rejected) and ta(\u03b8) = |L|/|X | and tc(\u03b8) = 1 for small \u03b8 (all points are classified, the accuracy equals the accuracy of the given classifier for the full data set). We are interested in thresholds, such that the value ta is maximised, and tc is minimised. Hence, not all possible thresholds and corresponding pairs (ta(\u03b8), tc(\u03b8)) are of interest, but optimum choices only, which correspond to the so-called Pareto front. Note that pairs\n(|L\u03b8 |, |E\u03b8 |) uniquely correspond to pairs (ta(\u03b8), tc(\u03b8)) and vice versa.\nEvery threshold uniquely induces a pair (|L\u03b8 |, |E\u03b8 |) and a pair (ta(\u03b8), tc(\u03b8)). We say that \u03b8 \u2032 dominates the choice \u03b8 if |L\u03b8 \u2032 | \u2264 |L\u03b8 | and |E\u03b8 \u2032 | \u2265 |E\u03b8 | and for at least one term, inequality holds. We aim at the Pareto front\nP\u03b8 := {(|L\u03b8 |, |E\u03b8 |)| |\u03b8 is not dominated by any \u03b8 \u2032} . (13) Every dominated threshold (threshold vector) corresponds to a sub optimum choice only: We can increase the number of true rejects without increasing the number of false rejects, or, conversely, false rejects can be lowered without lowering true rejects.\nTo evaluate the efficiency of a threshold strategy, it turns out that a slightly different set is more easily accessible. We say that \u03b8 \u2032 dominates \u03b8 with respect to the true rejects if |L\u03b8 \u2032 | = |L\u03b8 | and |E\u03b8 \u2032 | > |E\u03b8 |. This induces the pseudo Pareto front\nP\u0302\u03b8 := {(|L\u03b8 |, |E\u03b8 |)| |\u03b8 is not dominated by any (14)\n\u03b8 \u2032 with respect to the true rejects} .\nObviously, P\u03b8 can easily be computed as the subset of P\u0302\u03b8 by taking the minima over the false rejects. P\u0302\u03b8 has the benefit that it can be understood as a graph where |L\u03b8 | varies in between 0 and |L| and |E\u03b8 | serves as function value. Having computed P\u0302\u03b8 and the corresponding thresholds, we report the efficiency of a rejection strategy by the corresponding ARC curve, i. e. the pairs(ta(\u03b8), tc(\u03b8)): These pairs correspond to a graph, where we report the ratio of classified points (starting from a ratio 1 up to 0) versus the obtained accuracy for the classified points. For good strategies, this graph should be increasing as fast as possible. In the following, we discuss efficient strategies to compute the pseudo Pareto front for global and local reject strategies."}, {"heading": "4.1 Optimum Global Rejection", "text": "For a global reject option, only one parameter \u03b8 is chosen. |L\u03b8 | and |E\u03b8 | are monotonically increasing with increasing \u03b8 , and |X\u03b8 | is decreasing. We can compute thresholds which lead to the pseudo Pareto front and the corresponding pairs (ta(\u03b8), tc(\u03b8)) in time O(N logN) due to the following observation: Consider the rejection measure r(xi) as induced by the certainty function (9) for all points xi \u2208 X and sort the values r(xi1)< .. . < r(xiN ) (see Fig. 7). Additionally Fig. 7 indicates via the symbol\nq j \u2208 {+,\u2212} whether the corresponding point is in L or in E. We assume that the certainty values are not exactly identical, for simplicity; otherwise, we sort the points such that the points in L come first. The following holds:\n\u2022 Every pair (|L\u03b8 |, |E\u03b8 |) \u2208 P\u0302\u03b8 is generated by some \u03b8 = r(xi j) which corresponds to a certainty value in this list or which corresponds to \u221e (i. e. all points are rejected), since values in between do not alter the number of rejected points on X .\n\u2022 Values r(xik) with xik \u2208E are dominated by r(xik+1) (or \u221e for the largest value) with respect to true rejects since the latter threshold accounts for the same number of false rejects, adding one true reject xik .\n\u2022 Contrary, values r(xik) with xik \u2208 L are not dominated with respect to the number of true rejects. Increasing this threshold always increases the number of false rejects by adding xik to the rejected points.\nHence, the pseudo Pareto front is induced by a set of thresholds \u0398 corresponding to correctly classified points:\n\u0398 := {\u03b8 = r(xik) |xik \u2208 L}\u222a{\u221e | if xiN 6\u2208 L} . (15)\nObviously, |\u0398| \u2208 {|L|, |L|+ 1} depending on whether the last point in this list is classified correctly or not. An exemplary setting is depicted in Fig. 7. We refer to the thresholds obtained this way as \u03b8(0), . . . ,\u03b8(|\u0398| \u2212 1) whereby we assume that these values are sorted in ascending order.\nIn addition, we can compute the gain |g(k)| which is obtained when increasing the threshold from \u03b8(k\u22121) to \u03b8(k): For k = 0, . . . , |\u0398|\u22121, the quantity\ng(k) := {xi |\u03b8(k\u22121)\u2264 r(xi)< \u03b8(k),xi \u2208 E} (16)\ndenotes the set of additional true rejects when increasing \u03b8 from \u03b8(k\u22121) to the value \u03b8(k) where we define\n\u03b8(\u22121) := 0. Note that |g(0)| equals the maximum number of true rejects without any false reject. It can easily be computed by one scan through the sorted list of certainty values, see Fig. 7. Obviously, the set\nE\u03b8(k) = \u22c3\n0\u2264i\u2264k g(i), k = 0, . . . , |\u0398|\u22121 (17)\ndescribes true rejects for the choice \u03b8 := \u03b8(k). Note that the loss due to an increase of the threshold from \u03b8(k) to \u03b8(k+1) is always one, by adding exactly one false reject, i. e. |L\u03b8(k)|= k."}, {"heading": "4.2 Optimum Local Rejection", "text": "Finding the pseudo Pareto front for local rejection is more difficult than for a global one because the number of parameters (thresholds) in the optimisation rises from one to \u03be . First, we will derive an optimal solution via dynamic programming (DP) [4, 13]. Secondly, we will introduce a faster greedy solution which provides a good approximation of DP.\nFor every single Voronoi cell Vj, the optimum choice of a threshold and its corresponding pseudo Pareto front is given in exactly the same way as for the global reject option: We sort the certainty values of the points in this Voronoi cell and look for the thresholds induced by correctly classified points (possibly adding \u221e) as depicted in Fig. 7. We use the same notation as for a global reject option, but indicate via an additional index j \u2208 {1, . . . ,\u03be} that these values refer to Voronoi cell Vj: The correctly classified data points in Vj are L j := L\u2229Vj, misclassified points are E j := E \u2229Vj. A threshold \u03b8 j in Vj leads to false and true rejects L\nj \u03b8 j and E j \u03b8 j , respec-\ntively. These rejects accumulate as L\u03b8 = \u222a jL j\u03b8 j and E\u03b8 = \u222a jE j\u03b8 j over the entire classifier, characterising the false and true rejects of the reject strategy with threshold vector \u03b8 . For any separate Voronoi cell, optimum thresholds as concerns the number of true rejects are induced by the certainty values of correctly classified points in this Voronoi cell, possibly adding \u221e. These thresholds are referred to as\n\u0398 j := {\u03b8 j(0), . . . ,\u03b8 j(|\u0398 j|\u22121)} (18)\nequivalent to (15) for Voronoi cell Vj only, where |\u0398 j| \u2208 {|L j|, |L j|+ 1}. These thresholds lead to gains |g j(k)| equivalent to (16) but restricted to Voronoi cell Vj, with true rejects E j\u03b8 j(k) = \u2211i\u2264k g j(i) and false rejects L j \u03b8 j(k) .\nWe are interested in threshold vectors which describe the pseudo Pareto front of the overall strategy, i. e. parameters \u03b8 such that no \u03b8 \u2032 6=\u03b8 exists which dominates \u03b8 with respect to the true rejects. Obviously, the following relation holds: \u03b8 is optimal\u21d2 every \u03b8 j is optimal in Vj. Otherwise, we could easily improve \u03b8 by improving its suboptimal component. The converse is not true: As an example, assume Voronoi cells and thresholds as shown in Table 1. Here, we can compare the threshold vectors (1,1,1) and (0,0,3). While both choices lead to 3 false rejects, the first one encounters 9 true rejects and the second one leads to 25 true rejects. Hence the second vector dominates the first one with respect to true rejects, albeit all threshold components are contained in the pseudo Pareto front of the corresponding Voronoi cell.\nHence we are interested in efficient strategies that compute the set of optimum threshold vectors as combinations of the single values in \u0398 j. There exist at most |\u03981| \u00b7 . . . \u00b7 |\u0398\u03be |= O(|L|\u03be ) different combinations (using the trivial upper bound O(|L j|)\u2264O(|L|) for each |\u0398 j|, we can expect an order O(|L|/\u03be ) provided the Voronoi cells have roughly the same size). While it is possible to test all possibilities provided a low number of prototypes \u03be is present, this number is infeasible if the number of prototypes gets large; this is the case in particular in online schemes or applications for big data. In the following, we propose two alternative methods to compute the Pareto front that are linear with respect to \u03be ."}, {"heading": "4.2.1 Local Threshold Adaptation by DP", "text": "For any number 0\u2264 n\u2264 |L|, 1\u2264 j\u2264 \u03be , 0\u2264 i\u2264 |\u0398 j|\u22121 we define:\nopt(n, j, i) := max\n\u03b8 {|E\u03b8 | | |L\u03b8 |= n,\n\u03b8k \u2208 {\u03b8 j(0), . . . ,\u03b8 j(|\u0398 j|\u22121)}\u2200k < j, \u03b8 j \u2208 {\u03b8 j(0), . . . ,\u03b8 j(i)}, \u03b8k = \u03b8k(0)\u2200k > j} (19)\nThe term opt(n, j, i) measures the maximum number of true rejects that we can obtain with n false rejects, and a threshold vector that is restricted in the sense that the threshold in Voronoi cell j is one of the first i thresholds, it is any threshold value for Voronoi cell k < j, and the threshold for any Voronoi cell k > j is fixed to the first threshold value. For technical reasons, it is useful to extend the index range of the Voronoi cells with 0 that refers to the initial case that all thresholds are set to 0 which serves as an easy initialisation. Since there are no thresholds to pick in Voronoi cell V0, we define |\u03980|= 1, i. e. the index i is the constant 0 in this virtual cell V0.\nFor opt(n, j, i), a few properties hold: First, obviously the pseudo Pareto front can be recovered from the values opt(n,\u03be , |\u0398\u03be | \u2212 1) for n \u2264 |L|, since these parameters correspond to the optimum number of true rejects provided n false rejects and free choice of the thresholds. Hence an efficient computation scheme for the quantities opt(n, j, i) allows to efficiently compute the Pareto front.\nSecond, the decomposition of the optimality terms along the possible threshold values gives rise to the following Bellmann optimality equation:\nopt(n, j, i) = if n = 0 : \u2211\u03bek=1 |E k\u03b8k(0)| if n > 0, j = 0 : \u2212\u221e if n > 0, j > 0, i = 0 : opt(n, j\u22121, |\u0398 j\u22121|\u22121) if 0 < n < i, j > 0 : opt(n, j, i\u22121) if n\u2265 i > 0, j > 0 : max{opt(n, j, i\u22121), opt(n\u2212 i, j\u22121, |\u0398 j\u22121|\u22121)\n+|E j\u03b8 j(i)|\u2212 |E j \u03b8 j(0) |}\n(20) This recursion captures the decomposition of the problem along the Voronoi cells as follows:\n\u2022 In the first case, no false rejects are allowed. Therefore, the gain is characterised by the sum of the gains |E k\u03b8k(0)| over all Voronoi cells; these gains correspond to the minimum thresholds in all Voronoi cells which do not reject a correct point.\n\u2022 In the second case, the number of false rejects has to equal n, but only a trivial threshold with no rejects is allowed. Hence this choice is impossible, reflected in the default value \u2212\u221e.\n\u2022 In the third case, the threshold of Voronoi cell j and all Voronoi cells with index larger than j by definition of opt (19) are clamped to the first one.\nHence, by definition of the quantity opt (19), this is exactly the same as the term opt(n, j\u22121, |\u0398 j\u22121|\u2212 1) where no restriction is posed on Voronoi cells 1 to j\u22121, but thresholds are clamped starting from Voronoi cell j.\n\u2022 In the fourth case, the threshold number i is allowed, but it would account for i false rejects in the Voronoi cell j with only n < i false rejects allowed. Hence we cannot pick number i put a smaller one only.\n\u2022 The fifth case considers the interesting setting where optimality is non-trivial: The choice of threshold number i in Voronoi cell j is possible, but it is unclear whether it is optimum. There are only two possible choices: The first is to take a threshold with smaller index in Voronoi cell j, the second is to choose threshold i in Voronoi cell j. The first choice leads to opt(n, j, i\u22121) true rejects. The second choice has the consequence, that i false rejects occur in Voronoi cell j, hence we are only allowed to reject at most n\u2212 i additional false rejects in Voronoi cells 1 to j\u22121. In turn, however, there are |E j\u03b8 j(i)| true rejects in Voronoi cell j as compared to only |E j\u03b8 j(0)| if we would pick the smallest threshold in this Voronoi cell without false rejects. Hence the optimum number of true rejects which can be achieved in this case decomposes into the optimum opt(n\u2212 i, j\u2212 1, |\u0398 j\u22121|\u2212 1) which picks the best thresholds for Voronoi cells 1 to j\u22121, and keeps all larger ones to the smallest possible value, and the gain |E j\u03b8 j(i)|\u2212 |E j \u03b8 j(0) | which we obtain be-\ncause picking threshold number i instead of the first one in Voronoi cell j.\nThis recursive scheme can be computed by DP, since, in every recursion, the value i or j is decreased, and the recursion does not refer to values with larger indices. An explicit iteration scheme can be structured in three nested loops over n \u2208 {0, . . . , |L|} followed by j \u2208 {1, . . . ,\u03be} followed by i\u2208 {0, . . . , |\u0398 j|\u22121}. Since every evaluation of the equation (20) itself is constant time, this results in a computation scheme with effort O(|L| \u00b7\u03be \u00b7maxk |\u0398k|). Memory efficiency is O(|L| \u00b7maxk |\u0398k|), since the recursion for threshold i in Voronoi cell j refers to the value i\u2212 1 only, or it directly decreases j. Thus a memory matrix of dimensionality O(|L| \u00b7 \u03be ) suffices. This DP scheme yields the optimum achievable values of true rejects; one can easily compute optimum threshold vectors thereof since they correspond to the realisation of\nthe maxima in the recursive scheme. Hence a standard back-tracing scheme on the matrix reveals these vectors. See Algorithm .1 for pseudo code. For memory efficiency we reduce the tensor opt(n, j, i\u2212 1) to a matrix opt(n, j). The value of opt(n, j) denotes the maximum number of true rejects with n false rejects and flexible thresholds in Voronoi cells 1, . . . , j. In this context the vector \u03b8 (n, j) defines the optimal threshold vector for n false rejects and flexible threshold in the Voronoi cells 1, . . . , j whereas the Voronoi cells j+1, . . . ,\u03be are set to the default thresholds (no true reject)."}, {"heading": "4.2.2 Local Threshold Adaptation by an Efficient Greedy Strategy", "text": "Albeit enabling an optimum choice of the local threshold vectors for given data, DP as proposed above (20) is infeasible for large training sets since it scales quadratically with the number of data: The number of thresholds max j |\u0398 j| scales with N, we can expect it is of order O(N/\u03be ). An even more severe bottleneck is the time complexity for DP, which is linear in the number of data points, hence it is not suitable for big data or online schemes. Therefore, we propose a direct greedy approximation scheme which is inspired by the full DP and which yields to an (besides pre-processing) only linear method with excellent performance at the price of possible sub optimality of the solution.\nThe basic idea is to start with the initial setting analogical to opt(0,\u03be , |\u0398\u03be |\u2212 1): All thresholds are set to the first choice \u03b8 j(0), hence no false rejects are present and the number of true rejects can easily be computed. Then, a greedy threshold increase is done until the number of true rejects corresponds to the maximum possible number |E|. While increasing the values, the respective optima are stored; here, we directly compute the ARC, it would easily be possible to compute the number of true and false rejects and the corresponding thresholds, instead.\nThe greedy step proceeds as follows: Starting from n = 0, in each round, the number of false rejects n is increased by one (the default case) or more than one (in case of ties, which particularly happens if the increase of a threshold does not affect the number of true rejects but increases false rejects only). This threshold increase is always done in the Voronoi cell with maximum immediate gain. More precisely:\n\u2022 We consider local gains for each Voronoi cell: These values are the numbers of true rejects gained\nThis procedure is described in detail in Algorithm .2. Thereby, we do not explicitly check whether the considered threshold indices are still in a feasible range; rather, we implicitly assume that the corresponding gain is set to \u2212\u221e if the threshold would be infeasible. The algorithm does not necessarily provide the optimum threshold vectors and hence an approximation to the quasi Pareto front only, but, as we will see in experiments, it is very close to it. Unlike the exact algorithm, it works in O(|L| \u00b7\u03be ) time and O(\u03be ) memory. One example of the algorithmic loops is depicted in Table 2 for the gains as shown in Table 1. The table shows the picked threshold indices of the consecutive iterations of the greedy search."}, {"heading": "5 Experiments", "text": "Having proposed efficient exact and approximate algorithms to determine optimum thresholds, we evaluate the results of the reject options for different data sets. In all cases, we use a 10-fold repeated cross-validation with ten repeats. We evaluate the models obtained by RSLVQ, GMLVQ, and LGMLVQ with one prototype per class. Thereby, we can combine the models with different certainty measures depending on their output: Since RSLVQ provides probability estimates, we can combine it with the certainty measure Conf. In turn, GMLVQ and LGMLVQ lend itself to the certainty measure RelSim which is computed already while training. We compare our results with a standard rejection measure of SVM [36, 54] which is implemented in the LIBSVM toolbox [11].\nFor numerical reasons, we do not display the setting |X\u03b8 | = 0. In Fig. 8 to Fig. 10, we display the ARC averaged over 100 runs per data set and rejection measure. Note that the single curves have different ranges for |X\u03b8 |/|X | corresponding to different thresholds. To ensure a reliable display, we only report those points |X\u03b8 |/|X | for which at least 80 runs deliver a value."}, {"heading": "5.1 Data Sets", "text": "For evaluation, we consider the following data sets:\nGaussian Clusters: This data set contains two artificially generated overlapping 2D Gaussian clusters with means \u00b5x = (\u22124,4.5), \u00b5y = (4,0.5), and standard deviations \u03c3x = (5.2,7.1) and \u03c3y = (2.5,2.1). These points are overlaid with uniform noise.\nPearl Necklace: This data set consists of five artificially generated Gaussian clusters in two dimensions with overlap. Mean values are given by \u00b5yi = 3 \u2200i, \u00b5x = (2,44,85,100,136), standard deviation per dimension is given by \u03c3x = (1,20,0.5,7,11), \u03c3x = \u03c3y.\nImage Segmentation: The image segmentation data set consists of 2310 data points which contain 19 realvalued image descriptors. The data represent small patches from outdoor images with 7 different classes with equal distribution such as grass, cement, etc. [3].\nTecator: The Tecator data set [49] consists of 215 spectra of meat probes. The 100 spectral bands range from 850 nm to 1050 nm. The task is to predict the fat content (high/low) of the probes, which is turned into a balanced two class classification problem.\nHaberman: The Haberman survival data set includes 306 instances of two classes indicating being alive for\nmore than 5 years after breast cancer surgery [3]. One instance represents three features linked to the age, the year, and the number of positive axillary nodes detected.\nCoil: The Columbia Object Image Database Library contains gray scaled images of twenty objects [35]. Each object is rotated in 5\u25e6 steps, resulting in 72 images per object. The data set contains 1440 vectors with 16384 dimensions that are reduced with PCA [51] to 30.\nSince ground truth is available for the first two, artificial data sets, we can use optimum Bayesian decision as a Gold standard for comparison in these two cases."}, {"heading": "5.2 Comparison of DP vs. Greedy Optimization", "text": "First, we evaluate the performance of a greedy optimisation for the computation of local reject thresholds versus an optimum DP scheme. The results are compared in Fig. 8. Since we are interested in the ability of the heuristics to approximate optimum thresholds, ARCs are computed on the training set for which the threshold values are exactly optimized using DP.\nOne can clearly observe that the resulting curves are very similar for the shown data sets and the models provided by GMLVQ as well as LGMLVQ. Only for the Tecator (Haberman) data set the optimum DP solution beats the greedy strategy in a small region, in particular for settings with a large portion of rejected data points (that are usually of less interest in practice since almost all points are rejected in these settings). Results on the other data sets show a similar behaviour.\nHence we can conclude that the greedy optimisation provides near optimal results for realistic settings, while requiring less time and memory complexity. Because of this fact we will use the greedy optimisation for the local reject options in the following analyses."}, {"heading": "5.3 Experiments on Artificial Data", "text": "Thereby, we report the ARC obtained on a hold out test set (which is also not used for threshold optimisation) in order to judge the interesting generalisation error of the classification models with reject option. The data densities for the artificial data sets Gaussian clusters and Pearl necklace are known. Hence we can compare local and global reject options on these data with the optimum Bayes rejection, see Fig. 9. Thereby, RSLVQ is combined with Conf as rejection measure, while RelSim is used for deterministic LVQ models, relying on the insights as gained in the studies [39, 19, 20, 21, 18]. For\nall settings, the performance of the classifier on the test set is depicted, after optimising model parameters and threshold values on the training set. Results of a repeated cross-validation are shown, as specified before.\nGaussian Clusters: For Gaussian clusters, the global and the local rejection ARCs are almost identical for all three models. Therefore, in this setting, it is not necessary to carry out a local strategy, but a computationally more efficient global reject option suffices. Interestingly, reject strategies reach the quality of an optimum Bayesian reject in the relevant regime of up to 25 % rejected data points as can be seen in the left part of the ARCs. RSLVQ, due to its foundation on a probabilistic model, even enables a close to optimum rejection for the full regime, see Fig. 9.\nPearl Necklace: The pearl necklace data set is designed to show the advantage of local rejection as already mentioned before when referring to Fig. 5. Here it turns out that local rejection performs better than global rejection for the models RSLVQ and GMLVQ. As can be seen from Fig. 9, neither RSLVQ nor GMLVQ reach the optimum decision quality, but the ARC curves are greatly improved when using a local instead of a global threshold strategy. This observation can be attributed to the fact that the scaling behaviour of the certainty measure is not the same for the full data space in these settings: RSLVQ is restricted to one global bandwidth, similarly, GMLVQ is restricted to one global quadratic form. This enforces a scaling of the certainty measure which does not scale uniformly with the (varying) certainty as present in the data. In comparison, LGMLVQ is capable of reaching the optimum Bayesian reject boundary for both, local and global reject strategies, caused by the local scaling of the quadratic form in the model. The analysis on these artificial data sets is a first indicator that shows that local reject options can be superior to global ones in particular for simple models. On the other side, there might be a small difference only in between local and global reject options for good models. In all cases, a sufficiently flexible LVQ model together with the proposed reject strategies reaches the quality of an optimum Bayesian reject strategy."}, {"heading": "5.4 Experiments on Benchmarks", "text": "For the benchmark data sets, the underlying density models are unknown, hence we cannot report the result of an optimum Bayes rejection. For these settings, as an alternative, we report the results which are obtained with an SVM and the reject option as introduced in [36, 54].\nFigure 10 displays all results. Tecator: RSLVQ and LGMLVQ provide results which are comparable to the SVM, while GMLVQ leads to worse accuracy. Note, however, the scaling: Also in the latter case, the classification accuracy of the full model is about 92 %, which increases to 94 % when rejecting 10 % of the data. For this regime for GMLVQ, the local threshold strategy is slightly better than a global one.\nImage Segmentation: For this setting, the SVM yields the best classification accuracy of 97 % compared to 95 % for LGMLVQ (and less for the other models). This fact can be explained by the simpler model provided by LVQ techniques as compared to SVM, which can rely on a more complex classification boundary in this setting. Still, the reject strategies for the LVQ models are highly performant: Rejecting 10 % of the data enables an increase of the classification accuracy by 3 % for LGMLVQ. For the simpler models RSLVQ and GMLVQ, again, a benefit of local versus global thresholds can clearly be observed.\nHaberman: For the Haberman data, all LVQ models display the same ARC as SVM models for the interesting regime of at most 25% rejections in the data. For larger reject fractions, deterministic LVQ methods are superior to SVM models and corresponding reject options.\nCoil: The coil data set allows a high classification accuracy reaching 100 %. LVQ models display a slightly smaller accuracy for the full data set due to their simple form, representing the model by few prototypes only. Here, the benefit of reject options is obvious, since it enables to reach 100 % accuracy when rejecting less than\n10 % of the data for GMLVQ (less than 2 % for LGMLVQ). The probabilistic counterpart RSLVQ performs worse, but again, the superiority of local rejects versus global options is clearly apparent for this weaker model.\nBased on these experiments, we conclude the following:\n\u2022 Reject options can greatly enhance the classification performance, provided the classification accuracy is not yet optimum.\n\u2022 Local reject options yield better results than global ones, whereby this effect is stronger for simple models for which the classification accuracy on the full data set is not yet optimum. For more flexible models with excellent classification accuracy for the full data set, this effect is not necessarily given.\n\u2022 LGMLVQ and the proposed reject option is comparable to SVM and the standard reject option for the considered data.\nWe would like to emphasise that the models as provided by LVQ techniques are sparse as compared to the SVM since we use only one prototype per class. Further, the proposed global reject option depends on the prototypes only, while the SVM technique requires a tuning of the non-linearity on the given data [36]."}, {"heading": "5.5 Medical Application", "text": "We conclude with a recent example from the medical domain. The adrenal tumours data [8] contains 147\ndata points composed of 32 steroid marker values. Two classes are present: Patients with benign adrenocortical adenoma (ACA) or malignant carcinoma (ACC). The 32 steroid marker values are measured from urine samples using gas chromatography/mass spectrometry. For further medical details we refer to [8, 2]. The two classes are unbalanced with 102 ACA and 45 ACC data points.\nOur analysis of the data follows the proposed evaluations in [8, 2]: We train a GMLVQ model with one prototype per class. We use the same pre-processing as described in [8, 2]. The data set has 56 missing values (out of 4704). GMLVQ can deal with these values by ignoring them for the distance computation and update, whenever the values are missing. This corresponds to a substitution of the values by the average as provided by the closest prototype. The same treatment of missing values is possible when calculating the RelSim values for rejection. For the evaluation of reject options we split the data into a train set (90%) and a test set (10%). We evaluated the ARC of 1000 random splits of the data and the corresponding GMLVQ models. The averaged ARCs of the tested reject options can be found in Fig. 11. There is nearly no difference between the curves of the global and the local rejection for small rejection rates (up to 10 %). For more than 10 % rejection, the local rejection strategy improves the accuracy more than the global\none. Its ARC is comparable to the ARC associated with SVM rejection computed based on LIBSVM [11]. This can be attributed to the fact that the scaling of RelSim is not uniform as compared to the inherent scaling of the data in this regime. For SVM, missing value imputation has to be done; here we replace the missing values by\nthe class conditional means, following the suggestion in [8]. On average, the SVM models leads to 31 support vectors whereas the GMLVQ models only contains 2 prototypes. Further, the GMLVQ model provides insight into potentially relevant biomarkers and prototypical representatives of the classes, as has been detailed in the publication [2]. The suggested biomarkers, in particular, have been linked with biomedical insight [2]. As a conclusion, the GMLVQ model together with the proposed reject scheme offers a reliable and compact model for this medical application."}, {"heading": "6 Conclusion", "text": "In this article, we introduced reject strategies for prototype-based classifiers and extensively evaluated the proposed methods for diverse data sets, thereby comparing to state of the art reject options as present for SVM. In particular, we introduced global and local reject strategies and addressed the problem of their efficient computation. We introduced two algorithms to derive optimum local reject thresholds: (i) An optimum technique based on dynamic programming (DP) and (ii) a fast greedy approximation. While the first is provably optimum, the latter is based on heuristics. However, we showed that\nthe results of both solutions are very similar such that the fast greedy solution instead of the more complex solution via DP seems a reasonable choice. Its memory complexity is only linear with respect to the number of data, while DP requires quadratic time, and its memory complexity is constant as concerns the number of data, while DPs memory size depends linearly on the number of data points.\nWhen investigating these techniques for diverse reallife data sets, the benefit of local strategies becomes apparent in particular for simple prototype-based models. The effect is less pronounced for more complex models that involve local metric learning like LGMLVQ. Interestingly, the proposed reject strategies in combination with the very intuitive deterministic method LGMLVQ lead to results which are comparable to SVM and corresponding reject options. Thereby, the LVQ techniques base the reject on their distance to few prototypes only, hence they open the way towards efficient techniques for online scenarios.\nSo far, the reject strategies have been designed and evaluated for offline training scenarios only, disregarding the possibility of trends present in life long learning scenarios, or its coupling to possibly varying costs for rejects versus errors. We will analyse in future work how to extend the proposed methods to online scenarios and life long learning, where according thresholds are picked automatically based on the proposed results in this article."}, {"heading": "Acknowledgment", "text": "The authors would like to thank Stephan Hasler for the initial idea of the greedy optimisation of local thresholds and very helpful discussions thereon. The authors would like to thank Wiebke Arlt and Michael Biehl for providing the adrenal tumour data and their support in related questions."}], "references": [{"title": "Assessment of acrosome state in boar spermatozoa heads using n-contours descriptor and RLVQ", "author": ["E. Alegre", "M. Biehl", "N. Petkov", "L. Sanchez"], "venue": "Computer Methods and Programs in Biomedicine, 111(3):525 \u2013 536", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2013}, {"title": "Urine steroid metabolomics as a biomarker  tool for detecting malignancy in adrenal tumors", "author": ["W. Arlt", "M. Biehl", "A.E. Taylor", "S. Hahner", "R. Libe", "B.A. Hughes", "P. Schneider", "D.J. Smith", "H. Stiekema", "N. Krone", "E. Porfiri", "G. Opocher", "J. Bertherat", "F. Mantero", "B. Allolio", "M. Terzolo", "P. Nightingale", "C.H.L. Shackleton", "X. Bertagna", "M. Fassnacht", "P.M. Stewart"], "venue": "Journal of Clinical Endocrinology and Metabolism, 96:3775\u20133784", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2011}, {"title": "Dynamic Programming", "author": ["R. Bellman"], "venue": "Princeton University Press", "citeRegEx": "4", "shortCiteRegEx": null, "year": 1957}, {"title": "Analysis of Flow Cytometry Data by Matrix Relevance Learning Vector Quantization", "author": ["M. Biehl", "K. Bunte", "P. Schneider"], "venue": "PLoS ONE, 8(3):e59401", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2013}, {"title": "Dynamics and Generalization Ability of LVQ Algorithms", "author": ["M. Biehl", "A. Ghosh", "B. Hammer"], "venue": "The Journal of Machine Learning Research, 8:323\u2013360", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2007}, {"title": "Inter-species prediction of protein phosphorylation in the sbv IMPROVER species translation challenge", "author": ["M. Biehl", "P. Sadowski", "G. Bhanot", "E. Bilal", "A. Dayarian", "P. Meyer", "R. Norel", "K. Rhrissorrakrai", "M.D. Zeller", "S. Hormoz"], "venue": "Bioinformatics, 31(4):453\u2013461", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2015}, {"title": "Matrix Relevance LVQ in Steroid Metabolomics Based Classification of Adrenal Tumors", "author": ["M. Biehl", "P. Schneider", "D. Smith", "H. Stiekema", "A. Taylor", "B. Hughes", "C. Shackleton", "P. Stewart", "W. Arlt"], "venue": "20th European Symposium on Artificial Neural Networks (ESANN), pages 423\u2013428", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2012}, {"title": "Pattern Recognition and Machine Learning", "author": ["C.M. Bishop"], "venue": "Springer", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2006}, {"title": "A Training Algorithm for Optimal Margin Classifiers", "author": ["B.E. Boser", "I. Guyon", "V. Vapnik"], "venue": "Proceedings of the Fifth Annual ACM Conf. on Computational Learning Theory (COLT), pages 144\u2013152", "citeRegEx": "10", "shortCiteRegEx": null, "year": 1992}, {"title": "LIBSVM: A library for support vector machines", "author": ["C.-C. Chang", "C.-J. Lin"], "venue": "ACM Transactions on Intelligent Systems and Technology, 2:27:1\u201327:27", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2011}, {"title": "On Optimum Recognition Error and Reject Tradeoff", "author": ["C.K. Chow"], "venue": "IEEE Transactions in Information Theory, volume 16(1), pages 41\u201346. IEEE Transactions in Information Theory", "citeRegEx": "12", "shortCiteRegEx": null, "year": 1970}, {"title": "Introduction to Algorithms", "author": ["T.H. Cormen", "C.E. Leiserson", "R.L. Rivest", "C. Stein"], "venue": "Second Edition. The MIT Press and McGraw-Hill Book Company", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2001}, {"title": "Support-Vector Networks", "author": ["C. Cortes", "V. Vapnik"], "venue": "Machine Learning, 20(3):273\u2013297", "citeRegEx": "14", "shortCiteRegEx": null, "year": 1995}, {"title": "Nearest neighbor pattern classification", "author": ["T.M. Cover", "P.E. Hart"], "venue": "IEEE Trans. on Information Theory, 13(1):21\u201327", "citeRegEx": "15", "shortCiteRegEx": null, "year": 1967}, {"title": "Generating Estimates of Classification Confidence for a Casebased Spam Filter", "author": ["S.J. Delany", "P. Cunningham", "D. Doyle", "A. Zamolotskikh"], "venue": "Proceedings of the 6th international conference on Case-Based Reasoning Research and Development, ICCBR\u201905, pages 177\u2013190, Berlin, Heidelberg", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2005}, {"title": "Confidence Estimation in Classification Decision: A Method for Detecting Unseen Patterns", "author": ["P.R. Devarakota", "B. Mirbach", "B. Ottersten"], "venue": "International Conference on Advances in Pattern Recognition ", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2007}, {"title": "Local Rejection Strategies for Learning Vector Quantization", "author": ["L. Fischer", "B. Hammer", "H. Wersing"], "venue": "Artificial Neural Networks and Machine Learning (ICANN), pages 563\u2013570", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2014}, {"title": "Rejection Strategies for Learning Vector Quantization", "author": ["L. Fischer", "B. Hammer", "H. Wersing"], "venue": "22nd European Symposium on Artificial Neural Networks (ESANN), pages 41\u201346", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2014}, {"title": "and H", "author": ["L. Fischer", "B. Hammer"], "venue": "Wersing. Efficient Rejection Strategies for Prototype-based Classification", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2014}, {"title": "Rejection Strategies for Learning Vector Quantization \u2013 A Comparison of Probabilistic and Deterministic Approaches", "author": ["L. Fischer", "D. Nebel", "T. Villmann", "B. Hammer", "H. Wersing"], "venue": "T. Villmann, F.-M. Schleif, M. Kaden, and M. Lange, editors, Advances in Self-Organizing Maps and Learning Vector Quantization, volume 295 of Advances in Intelligent Systems and Computing, pages 109\u2013118. Springer International Publishing", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2014}, {"title": "Comprehensible Classification Models: A Position Paper", "author": ["A.A. Freitas"], "venue": "SIGKDD Exploration Newsletter, 15(1):1\u201310", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2014}, {"title": "Reject option with multiple thresholds", "author": ["G. Fumera", "F. Roli", "G. Giacinto"], "venue": "Pattern Recognit., 33(12):2099\u20132101", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2000}, {"title": "Learning and modeling big data", "author": ["B. Hammer", "H. He", "T. Martinetz"], "venue": "22th European Symposium on Artificial Neural Networks (ESANN), pages 343\u2013352", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2014}, {"title": "Learning vector quantization for (dis-)similarities", "author": ["B. Hammer", "D. Hofmann", "F.-M. Schleif", "X. Zhu"], "venue": "Neurocomputing, 131:43\u201351", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2014}, {"title": "The Error-Reject Tradeoff", "author": ["L.K. Hansen", "C. Liisberg", "P. Salomon"], "venue": "Technical report, Electronics Institute, Technical University of Denmark, Lyngby, Denmark", "citeRegEx": "26", "shortCiteRegEx": null, "year": 1994}, {"title": "Classification with reject option", "author": ["R. Herbei", "M.H. Wegkamp"], "venue": "Canadian Journal of Statistics, 34(4):709\u2013721", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2006}, {"title": "Sampling with confidence: Using k-NN confidence measures in active learning", "author": ["R. Hu", "S.J. Delany", "B.M. Namee"], "venue": "Proceedings of the UKDS Workshop at 8th International Conference on Case-based Reasoning, ICCBR\u201909, pages 181\u2013192", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2009}, {"title": "Texture Feature Ranking with Relevance Learning to Classify Interstitial Lung Disease Patterns", "author": ["M.B. Huber", "K. Bunte", "M.B. Nagarajan", "M. Biehl", "L.A. Ray", "A. Wism\u00fcller"], "venue": "Artificial Intelligence in Medicine, 56(2):91 \u2013 97", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2012}, {"title": "A confidence value estimation method for handwritten Kanji character recognition and its application to candidate reduction", "author": ["E. Ishidera", "D. Nishiwaki", "A. Sato"], "venue": "International Journal on Document Analysis and Recognition, 6(4):263\u2013270", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2004}, {"title": "Incremental GRLVQ: Learning Relevant Features for 3D Object Recognition", "author": ["T.C. Kietzmann", "S. Lange", "M. Riedmiller"], "venue": "Neurocomputing, pages 2868\u20132879", "citeRegEx": "31", "shortCiteRegEx": null, "year": 2008}, {"title": "A Life- Long Learning Vector Quantization Approach for Interactive Learning of Multiple Categories", "author": ["S. Kirstein", "H. Wersing", "H.-M. Gross", "E. K\u00f6rner"], "venue": "Neural Networks, 28:90\u2013105", "citeRegEx": "32", "shortCiteRegEx": null, "year": 2012}, {"title": "Self-Organization and Associative Memory", "author": ["T. Kohonen"], "venue": "Springer Series in Information Sciences, Springer-Verlag, third edition", "citeRegEx": "33", "shortCiteRegEx": null, "year": 1989}, {"title": "Accuracy- Rejection Curves (ARCs) for Comparing Classification Methods with a Reject Option", "author": ["M.S.A. Nadeem", "J.-D. Zucker", "B. Hanczar"], "venue": "Workshop on Machine Learning in Systems Biology (MLSB), pages 65\u201381", "citeRegEx": "34", "shortCiteRegEx": null, "year": 2010}, {"title": "Columbia Object Image Library (COIL-20)", "author": ["S.A. Nene", "S.K. Nayar", "H. Murase"], "venue": "Technical Report CUCS-005-96,", "citeRegEx": "35", "shortCiteRegEx": "35", "year": 1996}, {"title": "Probabilistic Outputs for Support Vector Machines and Comparisons to Regularized Likelihood Methods. In Advances in Large Margin Classifiers, pages 61\u201374", "author": ["J.C. Platt"], "venue": null, "citeRegEx": "36", "shortCiteRegEx": "36", "year": 1999}, {"title": "Efficient Algorithms for Mining Outliers from Large Data Sets", "author": ["S. Ramaswamy", "R. Rastogi", "K. Shim"], "venue": "SIGMOD International Conference on Management of Data, pages 427\u2013438", "citeRegEx": "37", "shortCiteRegEx": null, "year": 2000}, {"title": "Machine learning for science and society", "author": ["C. Rudin", "K.L. Wagstaff"], "venue": "Machine Learning, 95(1):1\u20139", "citeRegEx": "38", "shortCiteRegEx": null, "year": 2014}, {"title": "Generalized Learning Vector Quantization", "author": ["A. Sato", "K. Yamada"], "venue": "Adv. in Neural Inf. Proc. Syst., volume 7, pages 423\u2013429", "citeRegEx": "39", "shortCiteRegEx": null, "year": 1995}, {"title": "Adaptive Relevance Matrices in Learning Vector Quantization", "author": ["P. Schneider", "M. Biehl", "B. Hammer"], "venue": "Neural Computation, 21(12):3532\u20133561", "citeRegEx": "40", "shortCiteRegEx": null, "year": 2009}, {"title": "Hyperparameter learning in probabilistic prototype-based models", "author": ["P. Schneider", "M. Biehl", "B. Hammer"], "venue": "Neurocomputing, 73(7-9):1117\u20131124", "citeRegEx": "41", "shortCiteRegEx": null, "year": 2010}, {"title": "Regularization in Matrix Relevance Learning", "author": ["P. Schneider", "K. Bunte", "H. Stiekema", "B. Hammer", "T. Villmann", "M. Biehl"], "venue": "IEEE Transactions on Neural Networks, 21(5):831\u2013840", "citeRegEx": "42", "shortCiteRegEx": null, "year": 2010}, {"title": "Soft Learning Vector Quantization", "author": ["S. Seo", "K. Obermayer"], "venue": "Neural Computation, 15(7):1589\u20131604", "citeRegEx": "43", "shortCiteRegEx": null, "year": 2003}, {"title": "Dynamic Hyperparameter Scaling Method for LVQ Algorithms", "author": ["S. Seo", "K. Obermayer"], "venue": "International Joint Conference on Neural Networks (IJCNN), pages 3196\u20133203", "citeRegEx": "44", "shortCiteRegEx": null, "year": 2006}, {"title": "A Tutorial on Conformal Prediction", "author": ["G. Shafer", "V. Vovk"], "venue": "Journal of Machine Learning Research, 9:371\u2013421", "citeRegEx": "45", "shortCiteRegEx": null, "year": 2008}, {"title": "The Data Replication Method for the Classification with Reject Option", "author": ["R. Sousa", "J.S. Cardoso"], "venue": "AI Communications, 26(3):281\u2013302", "citeRegEx": "46", "shortCiteRegEx": null, "year": 2013}, {"title": "To Reject or Not to Reject: That is the Question-An Answer in Case of Neural Classifiers", "author": ["C.D. Stefano", "C. Sansone", "M. Vento"], "venue": "IEEE Transactions on Systems, Man, and Cybernetics, Part C, 30(1):84\u201394", "citeRegEx": "47", "shortCiteRegEx": null, "year": 2000}, {"title": "Rapid Distance-Based Outlier Detection via Sampling", "author": ["M. Sugiyama", "K.M. Borgwardt"], "venue": "Neural Information Processing Systems (NIPS), pages 467\u2013475", "citeRegEx": "48", "shortCiteRegEx": null, "year": 2013}, {"title": "Tecator data set", "author": ["H.H. Thodberg"], "venue": "contained in StatLib Datasets Archive", "citeRegEx": "49", "shortCiteRegEx": null, "year": 1995}, {"title": "Reject Option for VQ-Based Bayesian Classification", "author": ["A. Vailaya", "A.K. Jain"], "venue": "International Conference on Pattern Recognition (ICPR), pages 2048\u20132051", "citeRegEx": "50", "shortCiteRegEx": null, "year": 2000}, {"title": "Matlab Toolbox for Dimensionality Reduction", "author": ["L.J.P. van der Maaten"], "venue": null, "citeRegEx": "51", "shortCiteRegEx": "51", "year": 2013}, {"title": "Making machine learning models interpretable", "author": ["A. Vellido", "J. Martin-Guerrero", "P. Lisboa"], "venue": "Proceedings of the European Symposium on Artificial Neural Networks, Computational Intelligence and Machine Learning (ESANN), pages 163\u2013172", "citeRegEx": "52", "shortCiteRegEx": null, "year": 2012}, {"title": "Algorithmic Learning in a Random World", "author": ["V. Vovk", "A. Gammerman", "G. Shafer"], "venue": "Springer, New York", "citeRegEx": "53", "shortCiteRegEx": null, "year": 2005}, {"title": "Probability Estimates for Multi-class Classification by Pairwise Coupling", "author": ["T.-F. Wu", "C.-J. Lin", "R.C. Weng"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "54", "shortCiteRegEx": "54", "year": 2004}, {"title": "Adaptive conformal semisupervised vector quantization for dissimilarity data", "author": ["X. Zhu", "F.-M. Schleif", "B. Hammer"], "venue": "Pattern Recognition Letters, 49", "citeRegEx": "55", "shortCiteRegEx": null, "year": 2014}], "referenceMentions": [{"referenceID": 7, "context": "Classification constitutes one of the standard application scenarios for machine learning techniques: Its application ranges from automated digit recognition up to fraud detection, and numerous machine learning models are readily available for this task [9].", "startOffset": 254, "endOffset": 257}, {"referenceID": 30, "context": "In particular applications which require a life long learning or an adaptation to changing conditions benefit from such flexible classification models [32].", "startOffset": 151, "endOffset": 155}, {"referenceID": 10, "context": "Reject options have been pioneered by the formal framework as investigated in the approach [12]: If the costs for a misclassification versus a reject are known, one can design an optimum reject threshold based on the probability of misclassification.", "startOffset": 91, "endOffset": 95}, {"referenceID": 25, "context": "Hence further research addresses the question whether reject options can be based on plugin rules where only empirical estimates of the misclassification probability are used [27].", "startOffset": 175, "endOffset": 179}, {"referenceID": 25, "context": "analysed in [27].", "startOffset": 12, "endOffset": 16}, {"referenceID": 7, "context": "One principled alternative to enhance given classifiers by confidence values is offered by bootstrapping [9].", "startOffset": 105, "endOffset": 108}, {"referenceID": 51, "context": "For online learning, the theory of conformal prediction has caused quite some interest recently [53, 45].", "startOffset": 96, "endOffset": 104}, {"referenceID": 43, "context": "For online learning, the theory of conformal prediction has caused quite some interest recently [53, 45].", "startOffset": 96, "endOffset": 104}, {"referenceID": 51, "context": ", see [53, 45].", "startOffset": 6, "endOffset": 14}, {"referenceID": 43, "context": ", see [53, 45].", "startOffset": 6, "endOffset": 14}, {"referenceID": 53, "context": "[55].", "startOffset": 0, "endOffset": 4}, {"referenceID": 34, "context": "One popular example is given for the support vector machine (SVM), see the approach [36] for two-class classification and the work [54] for extensions towards multiple classes.", "startOffset": 84, "endOffset": 88}, {"referenceID": 52, "context": "One popular example is given for the support vector machine (SVM), see the approach [36] for two-class classification and the work [54] for extensions towards multiple classes.", "startOffset": 131, "endOffset": 135}, {"referenceID": 9, "context": "in the popular LIBSVM [11].", "startOffset": 22, "endOffset": 26}, {"referenceID": 5, "context": "[7, 1, 29, 2], by offering an elegant representation which lends itself to model interpretability in a natural way [52, 22, 38].", "startOffset": 0, "endOffset": 13}, {"referenceID": 0, "context": "[7, 1, 29, 2], by offering an elegant representation which lends itself to model interpretability in a natural way [52, 22, 38].", "startOffset": 0, "endOffset": 13}, {"referenceID": 27, "context": "[7, 1, 29, 2], by offering an elegant representation which lends itself to model interpretability in a natural way [52, 22, 38].", "startOffset": 0, "endOffset": 13}, {"referenceID": 1, "context": "[7, 1, 29, 2], by offering an elegant representation which lends itself to model interpretability in a natural way [52, 22, 38].", "startOffset": 0, "endOffset": 13}, {"referenceID": 50, "context": "[7, 1, 29, 2], by offering an elegant representation which lends itself to model interpretability in a natural way [52, 22, 38].", "startOffset": 115, "endOffset": 127}, {"referenceID": 20, "context": "[7, 1, 29, 2], by offering an elegant representation which lends itself to model interpretability in a natural way [52, 22, 38].", "startOffset": 115, "endOffset": 127}, {"referenceID": 36, "context": "[7, 1, 29, 2], by offering an elegant representation which lends itself to model interpretability in a natural way [52, 22, 38].", "startOffset": 115, "endOffset": 127}, {"referenceID": 22, "context": "Further, the representation of models in terms of few representative prototypes has proved useful when dealing with online scenarios or big data sets [24, 31, 32].", "startOffset": 150, "endOffset": 162}, {"referenceID": 29, "context": "Further, the representation of models in terms of few representative prototypes has proved useful when dealing with online scenarios or big data sets [24, 31, 32].", "startOffset": 150, "endOffset": 162}, {"referenceID": 30, "context": "Further, the representation of models in terms of few representative prototypes has proved useful when dealing with online scenarios or big data sets [24, 31, 32].", "startOffset": 150, "endOffset": 162}, {"referenceID": 48, "context": "While some approaches exist to accompany nearest neighbour based classification or Gaussian mixture models (GMM) by confidence estimations [50, 28], first reject options for discriminative prototype-based methods such as learning vector quantisation have only recently been proposed [19, 21].", "startOffset": 139, "endOffset": 147}, {"referenceID": 26, "context": "While some approaches exist to accompany nearest neighbour based classification or Gaussian mixture models (GMM) by confidence estimations [50, 28], first reject options for discriminative prototype-based methods such as learning vector quantisation have only recently been proposed [19, 21].", "startOffset": 139, "endOffset": 147}, {"referenceID": 17, "context": "While some approaches exist to accompany nearest neighbour based classification or Gaussian mixture models (GMM) by confidence estimations [50, 28], first reject options for discriminative prototype-based methods such as learning vector quantisation have only recently been proposed [19, 21].", "startOffset": 283, "endOffset": 291}, {"referenceID": 19, "context": "While some approaches exist to accompany nearest neighbour based classification or Gaussian mixture models (GMM) by confidence estimations [50, 28], first reject options for discriminative prototype-based methods such as learning vector quantisation have only recently been proposed [19, 21].", "startOffset": 283, "endOffset": 291}, {"referenceID": 17, "context": "In this article, we will built on the insights as gained in the recent approaches [19, 21], and we will investigate how to optimally set the thresholds within intuitive reject schemes for prototype-based techniques.", "startOffset": 82, "endOffset": 90}, {"referenceID": 19, "context": "In this article, we will built on the insights as gained in the recent approaches [19, 21], and we will investigate how to optimally set the thresholds within intuitive reject schemes for prototype-based techniques.", "startOffset": 82, "endOffset": 90}, {"referenceID": 31, "context": "While the threshold selection strategies which we will investigate can be used for any prototype-based classification scheme, we will focus on the popular supervised classification technique learning vector quantisation (LVQ) and its recent more fundamental mathematical derivatives [33, 43, 40, 42].", "startOffset": 283, "endOffset": 299}, {"referenceID": 41, "context": "While the threshold selection strategies which we will investigate can be used for any prototype-based classification scheme, we will focus on the popular supervised classification technique learning vector quantisation (LVQ) and its recent more fundamental mathematical derivatives [33, 43, 40, 42].", "startOffset": 283, "endOffset": 299}, {"referenceID": 38, "context": "While the threshold selection strategies which we will investigate can be used for any prototype-based classification scheme, we will focus on the popular supervised classification technique learning vector quantisation (LVQ) and its recent more fundamental mathematical derivatives [33, 43, 40, 42].", "startOffset": 283, "endOffset": 299}, {"referenceID": 40, "context": "While the threshold selection strategies which we will investigate can be used for any prototype-based classification scheme, we will focus on the popular supervised classification technique learning vector quantisation (LVQ) and its recent more fundamental mathematical derivatives [33, 43, 40, 42].", "startOffset": 283, "endOffset": 299}, {"referenceID": 30, "context": "LVQ constitutes a powerful and efficient method for multi-class classification tasks which, due to its simple representation of models in terms of prototypes, is particularly suited for interpretability, online scenarios or life long learning [32].", "startOffset": 243, "endOffset": 247}, {"referenceID": 37, "context": "While classical LVQ models mostly rely on heuristics, modern variants are based on cost-functions such as generalized LVQ (GLVQ) [39], or the full probabilistic model robust soft LVQ (RSLVQ) [43].", "startOffset": 129, "endOffset": 133}, {"referenceID": 41, "context": "While classical LVQ models mostly rely on heuristics, modern variants are based on cost-functions such as generalized LVQ (GLVQ) [39], or the full probabilistic model robust soft LVQ (RSLVQ) [43].", "startOffset": 191, "endOffset": 195}, {"referenceID": 38, "context": "LVQ classifiers can be accompanied by strong guarantees concerning their generalization performance and learning dynamics [40, 6].", "startOffset": 122, "endOffset": 129}, {"referenceID": 4, "context": "LVQ classifiers can be accompanied by strong guarantees concerning their generalization performance and learning dynamics [40, 6].", "startOffset": 122, "endOffset": 129}, {"referenceID": 38, "context": "One particular success story links LVQ classifiers to metric learners: These enrich the classifier by feature weighting terms which opens the way towards a more flexible classification scheme, increased model interpretability, and even a simultaneous visualisation of the classifier [40, 42, 5].", "startOffset": 283, "endOffset": 294}, {"referenceID": 40, "context": "One particular success story links LVQ classifiers to metric learners: These enrich the classifier by feature weighting terms which opens the way towards a more flexible classification scheme, increased model interpretability, and even a simultaneous visualisation of the classifier [40, 42, 5].", "startOffset": 283, "endOffset": 294}, {"referenceID": 3, "context": "One particular success story links LVQ classifiers to metric learners: These enrich the classifier by feature weighting terms which opens the way towards a more flexible classification scheme, increased model interpretability, and even a simultaneous visualisation of the classifier [40, 42, 5].", "startOffset": 283, "endOffset": 294}, {"referenceID": 23, "context": "dress the setting of complex, possibly non-euclidean data which are described by pairwise similarities or dissimilarities only [25].", "startOffset": 127, "endOffset": 131}, {"referenceID": 4, "context": "Further, also for RSLVQ, the correctness of the probability estimate is not clear since the model is not designed in order to correctly model the data probability but the conditional label probability only [6, 21].", "startOffset": 206, "endOffset": 213}, {"referenceID": 19, "context": "Further, also for RSLVQ, the correctness of the probability estimate is not clear since the model is not designed in order to correctly model the data probability but the conditional label probability only [6, 21].", "startOffset": 206, "endOffset": 213}, {"referenceID": 17, "context": "In this contribution, building on the results as recently published in [19] which proposes different real-valued certainty measures suitable for an integration in a reject option, we investigate how to devise optimum reject strategies for LVQ type classifiers, putting a particular emphasis on the choice of the threshold for a reject.", "startOffset": 71, "endOffset": 75}, {"referenceID": 8, "context": "statistical models and the SVM [10, 14].", "startOffset": 31, "endOffset": 39}, {"referenceID": 12, "context": "statistical models and the SVM [10, 14].", "startOffset": 31, "endOffset": 39}, {"referenceID": 32, "context": "For all experiments, evaluation will rely on the full accuracy-reject curve as proposed in the approach [34].", "startOffset": 104, "endOffset": 108}, {"referenceID": 48, "context": "The approach [50] highlights two main reasons for rejection:", "startOffset": 13, "endOffset": 17}, {"referenceID": 13, "context": "Heuristic Measures: For k-nearest neighbour (k-NN) [15] approaches a variety of simple certainty measures exist using a neighbourhood of a given data point [16, 28].", "startOffset": 51, "endOffset": 55}, {"referenceID": 14, "context": "Heuristic Measures: For k-nearest neighbour (k-NN) [15] approaches a variety of simple certainty measures exist using a neighbourhood of a given data point [16, 28].", "startOffset": 156, "endOffset": 164}, {"referenceID": 26, "context": "Heuristic Measures: For k-nearest neighbour (k-NN) [15] approaches a variety of simple certainty measures exist using a neighbourhood of a given data point [16, 28].", "startOffset": 156, "endOffset": 164}, {"referenceID": 46, "context": "The approach [48] focusses on effective outlier detection, relying on the distances of a new data point from elements of a randomly chosen subset of the given data.", "startOffset": 13, "endOffset": 17}, {"referenceID": 35, "context": "The resulting method outperforms state of the art approaches such as proposed in [37] in efficiency and accuracy.", "startOffset": 81, "endOffset": 85}, {"referenceID": 44, "context": "Sousa & Cardoso [46] introduce a reject option which identifies ambiguous regions in binary classifications.", "startOffset": 16, "endOffset": 20}, {"referenceID": 45, "context": "The approach [47] addresses different neural network architectures including multi-layer perceptrons, learning vector quantisation, and probabilistic neural networks.", "startOffset": 13, "endOffset": 17}, {"referenceID": 10, "context": "Here an effectiveness function is introduced taking different costs for rejection and classification errors into account, very similar to the loss function as considered in [12, 27].", "startOffset": 173, "endOffset": 181}, {"referenceID": 25, "context": "Here an effectiveness function is introduced taking different costs for rejection and classification errors into account, very similar to the loss function as considered in [12, 27].", "startOffset": 173, "endOffset": 181}, {"referenceID": 34, "context": "A very popular approach to turn the activity provided by a binary SVM into an approximation of a classification confidence measure has been proposed by Platt [36].", "startOffset": 158, "endOffset": 162}, {"referenceID": 52, "context": "[54] and it is implemented in the popular LIBSVM toolbox [11].", "startOffset": 0, "endOffset": 4}, {"referenceID": 9, "context": "[54] and it is implemented in the popular LIBSVM toolbox [11].", "startOffset": 57, "endOffset": 61}, {"referenceID": 10, "context": "As already mentioned, the approach [12] investigates optimum reject options provided the true probability density function is known.", "startOffset": 35, "endOffset": 39}, {"referenceID": 24, "context": "In the limit case, this reject strategy provides a bound for any other measure in the sense of the error-reject trade-of, as proved in [26].", "startOffset": 135, "endOffset": 139}, {"referenceID": 10, "context": "also extent Chows\u2019s rule [12] to near optimal classifiers on finite data sets, and they introduce a general scaling to compare error-reject curves of several independent experiments even with different classifiers or data sets.", "startOffset": 25, "endOffset": 29}, {"referenceID": 21, "context": "The work as presented in [23] also directly builds on [12] and more closely investigates the decomposition of data into different regions as concerns the given classes and potential errors.", "startOffset": 25, "endOffset": 29}, {"referenceID": 10, "context": "The work as presented in [23] also directly builds on [12] and more closely investigates the decomposition of data into different regions as concerns the given classes and potential errors.", "startOffset": 54, "endOffset": 58}, {"referenceID": 25, "context": "The setting that reliable class probabilities are unavailable and only empirical estimations thereof are available, is addressed in the approach [27].", "startOffset": 145, "endOffset": 149}, {"referenceID": 15, "context": "Often, GMMs are used for this purpose [17, 50].", "startOffset": 38, "endOffset": 46}, {"referenceID": 48, "context": "Often, GMMs are used for this purpose [17, 50].", "startOffset": 38, "endOffset": 46}, {"referenceID": 15, "context": "[17] extend a GMM to estimate the insecurity of a particular class membership for novel, previously unseen patterns of a new class; this estimation can yield to a reliable outlier reject option.", "startOffset": 0, "endOffset": 4}, {"referenceID": 48, "context": "Vailaya & Jain [50] investigate the suitability of GMMs for both, rejection of outliers and ambiguous data.", "startOffset": 15, "endOffset": 19}, {"referenceID": 28, "context": "[30] propose a suitable approximation of the probability density function for high dimensionality, which is based on a low dimensional projection of the data.", "startOffset": 0, "endOffset": 4}, {"referenceID": 17, "context": "We will rely on two ingredients for an efficient reject option: (I) A suitable real-valued certainty measure [19, 20] and (II) A suitable definition of how to set a threshold for rejection.", "startOffset": 109, "endOffset": 117}, {"referenceID": 18, "context": "We will rely on two ingredients for an efficient reject option: (I) A suitable real-valued certainty measure [19, 20] and (II) A suitable definition of how to set a threshold for rejection.", "startOffset": 109, "endOffset": 117}, {"referenceID": 13, "context": "Note that prototype-based models are very similar to k-NN classifiers [15] which stores all training data points as prototypes and predict a label according to the closest (k = 1) or the k closest data points.", "startOffset": 70, "endOffset": 74}, {"referenceID": 31, "context": "Classical training techniques are often based on heuristics such as the Hebbian learning paradigm [33], yielding surprisingly good results in typical model situations, see [6].", "startOffset": 98, "endOffset": 102}, {"referenceID": 4, "context": "Classical training techniques are often based on heuristics such as the Hebbian learning paradigm [33], yielding surprisingly good results in typical model situations, see [6].", "startOffset": 172, "endOffset": 175}, {"referenceID": 37, "context": "More recent training schemes usually rely on a suitable cost function, including generalised LVQ (GLVQ) [39], its extension to an adaptive matrix: generalized matrix LVQ (GMLVQ) [40], its local version (LGMLVQ) [40] with local adaptive metrics, and statistical counterparts referred to as robust soft LVQ (RSLVQ) [43].", "startOffset": 104, "endOffset": 108}, {"referenceID": 38, "context": "More recent training schemes usually rely on a suitable cost function, including generalised LVQ (GLVQ) [39], its extension to an adaptive matrix: generalized matrix LVQ (GMLVQ) [40], its local version (LGMLVQ) [40] with local adaptive metrics, and statistical counterparts referred to as robust soft LVQ (RSLVQ) [43].", "startOffset": 178, "endOffset": 182}, {"referenceID": 38, "context": "More recent training schemes usually rely on a suitable cost function, including generalised LVQ (GLVQ) [39], its extension to an adaptive matrix: generalized matrix LVQ (GMLVQ) [40], its local version (LGMLVQ) [40] with local adaptive metrics, and statistical counterparts referred to as robust soft LVQ (RSLVQ) [43].", "startOffset": 211, "endOffset": 215}, {"referenceID": 41, "context": "More recent training schemes usually rely on a suitable cost function, including generalised LVQ (GLVQ) [39], its extension to an adaptive matrix: generalized matrix LVQ (GMLVQ) [40], its local version (LGMLVQ) [40] with local adaptive metrics, and statistical counterparts referred to as robust soft LVQ (RSLVQ) [43].", "startOffset": 313, "endOffset": 317}, {"referenceID": 38, "context": "GMLVQ: The Generalized Matrix Learning Vector Quantization [40] performs a stochastic gradient decent on the cost function in [39] with a more general metric d\u039b than the standard Euclidean one.", "startOffset": 59, "endOffset": 63}, {"referenceID": 37, "context": "GMLVQ: The Generalized Matrix Learning Vector Quantization [40] performs a stochastic gradient decent on the cost function in [39] with a more general metric d\u039b than the standard Euclidean one.", "startOffset": 126, "endOffset": 130}, {"referenceID": 38, "context": "The summands in this cost function are negative if and only if the classification of the corresponding point is correct, hence the costs correlate to the overall error and optimise the so-called hypothesis margin of the classifier [40].", "startOffset": 231, "endOffset": 235}, {"referenceID": 38, "context": "The algorithm which refers to these local metrics (5) is called local GMLVQ (LGMLVQ) [40].", "startOffset": 85, "endOffset": 89}, {"referenceID": 41, "context": "RSLVQ: The objective function of Robust Soft Learning Vector Quantization [43] corresponds to a statistical modelling of the setting.", "startOffset": 74, "endOffset": 78}, {"referenceID": 39, "context": "There exist schemes which also adapt the bandwidth [41, 44].", "startOffset": 51, "endOffset": 59}, {"referenceID": 42, "context": "There exist schemes which also adapt the bandwidth [41, 44].", "startOffset": 51, "endOffset": 59}, {"referenceID": 0, "context": "This means, the exact value r(x) does not necessarily coincide with the statistical confidence (which would be uniformly scaled in [0,1]), and the scaling of the value r(x) might even change depending on the location of the data point x.", "startOffset": 131, "endOffset": 136}, {"referenceID": 17, "context": "In the recent approaches [19, 20] several certainty measures have been proposed and evaluated for prototypebased classification.", "startOffset": 25, "endOffset": 33}, {"referenceID": 18, "context": "In the recent approaches [19, 20] several certainty measures have been proposed and evaluated for prototypebased classification.", "startOffset": 25, "endOffset": 33}, {"referenceID": 17, "context": "We will use three measures which scored best in the experiments as presented in [19, 20]:", "startOffset": 80, "endOffset": 88}, {"referenceID": 18, "context": "We will use three measures which scored best in the experiments as presented in [19, 20]:", "startOffset": 80, "endOffset": 88}, {"referenceID": 10, "context": "He introduced an optimal certainty measure in the sense of errorreject trade-off [12].", "startOffset": 81, "endOffset": 85}, {"referenceID": 16, "context": "3: [18] Artificial five class data set with the contour lines of Bayes (6) (left side) and the contour lines of Conf (7) with respect to a RSLVQ model (right side, black squares are prototypes).", "startOffset": 3, "endOffset": 7}, {"referenceID": 37, "context": "Relative Similarity: The relative similarity (RelSim) has been proposed as a certainty measure closely related to the GMLVQ cost function (3), see [39, 19].", "startOffset": 147, "endOffset": 155}, {"referenceID": 17, "context": "Relative Similarity: The relative similarity (RelSim) has been proposed as a certainty measure closely related to the GMLVQ cost function (3), see [39, 19].", "startOffset": 147, "endOffset": 155}, {"referenceID": 16, "context": "5: [18] Artificial five class data set with prototypes trained by GMLVQ (black squares) without metric adaptation.", "startOffset": 3, "endOffset": 7}, {"referenceID": 48, "context": "A local threshold strategy relies on a partitioning of the input space into several regions and a different choice of the reject threshold for every region; this way, it enables a finer control of rejection [50, 18].", "startOffset": 207, "endOffset": 215}, {"referenceID": 16, "context": "A local threshold strategy relies on a partitioning of the input space into several regions and a different choice of the reject threshold for every region; this way, it enables a finer control of rejection [50, 18].", "startOffset": 207, "endOffset": 215}, {"referenceID": 48, "context": "Following the suggestion in [50], we use the natural decomposition of the input space into the Voronoi-cells Vj as introduced in Eq.", "startOffset": 28, "endOffset": 32}, {"referenceID": 32, "context": "This multi-objective can be evaluated by a reference to the so-called accuracy reject curve (ARC) [34].", "startOffset": 98, "endOffset": 102}, {"referenceID": 2, "context": "First, we will derive an optimal solution via dynamic programming (DP) [4, 13].", "startOffset": 71, "endOffset": 78}, {"referenceID": 11, "context": "First, we will derive an optimal solution via dynamic programming (DP) [4, 13].", "startOffset": 71, "endOffset": 78}, {"referenceID": 34, "context": "We compare our results with a standard rejection measure of SVM [36, 54] which is implemented in the LIBSVM toolbox [11].", "startOffset": 64, "endOffset": 72}, {"referenceID": 52, "context": "We compare our results with a standard rejection measure of SVM [36, 54] which is implemented in the LIBSVM toolbox [11].", "startOffset": 64, "endOffset": 72}, {"referenceID": 9, "context": "We compare our results with a standard rejection measure of SVM [36, 54] which is implemented in the LIBSVM toolbox [11].", "startOffset": 116, "endOffset": 120}, {"referenceID": 47, "context": "Tecator: The Tecator data set [49] consists of 215 spectra of meat probes.", "startOffset": 30, "endOffset": 34}, {"referenceID": 33, "context": "Coil: The Columbia Object Image Database Library contains gray scaled images of twenty objects [35].", "startOffset": 95, "endOffset": 99}, {"referenceID": 49, "context": "The data set contains 1440 vectors with 16384 dimensions that are reduced with PCA [51] to 30.", "startOffset": 83, "endOffset": 87}, {"referenceID": 37, "context": "Thereby, RSLVQ is combined with Conf as rejection measure, while RelSim is used for deterministic LVQ models, relying on the insights as gained in the studies [39, 19, 20, 21, 18].", "startOffset": 159, "endOffset": 179}, {"referenceID": 17, "context": "Thereby, RSLVQ is combined with Conf as rejection measure, while RelSim is used for deterministic LVQ models, relying on the insights as gained in the studies [39, 19, 20, 21, 18].", "startOffset": 159, "endOffset": 179}, {"referenceID": 18, "context": "Thereby, RSLVQ is combined with Conf as rejection measure, while RelSim is used for deterministic LVQ models, relying on the insights as gained in the studies [39, 19, 20, 21, 18].", "startOffset": 159, "endOffset": 179}, {"referenceID": 19, "context": "Thereby, RSLVQ is combined with Conf as rejection measure, while RelSim is used for deterministic LVQ models, relying on the insights as gained in the studies [39, 19, 20, 21, 18].", "startOffset": 159, "endOffset": 179}, {"referenceID": 16, "context": "Thereby, RSLVQ is combined with Conf as rejection measure, while RelSim is used for deterministic LVQ models, relying on the insights as gained in the studies [39, 19, 20, 21, 18].", "startOffset": 159, "endOffset": 179}, {"referenceID": 34, "context": "For these settings, as an alternative, we report the results which are obtained with an SVM and the reject option as introduced in [36, 54].", "startOffset": 131, "endOffset": 139}, {"referenceID": 52, "context": "For these settings, as an alternative, we report the results which are obtained with an SVM and the reject option as introduced in [36, 54].", "startOffset": 131, "endOffset": 139}, {"referenceID": 34, "context": "Further, the proposed global reject option depends on the prototypes only, while the SVM technique requires a tuning of the non-linearity on the given data [36].", "startOffset": 156, "endOffset": 160}, {"referenceID": 6, "context": "The adrenal tumours data [8] contains 147", "startOffset": 25, "endOffset": 28}, {"referenceID": 6, "context": "For further medical details we refer to [8, 2].", "startOffset": 40, "endOffset": 46}, {"referenceID": 1, "context": "For further medical details we refer to [8, 2].", "startOffset": 40, "endOffset": 46}, {"referenceID": 6, "context": "uations in [8, 2]: We train a GMLVQ model with one prototype per class.", "startOffset": 11, "endOffset": 17}, {"referenceID": 1, "context": "uations in [8, 2]: We train a GMLVQ model with one prototype per class.", "startOffset": 11, "endOffset": 17}, {"referenceID": 6, "context": "We use the same pre-processing as described in [8, 2].", "startOffset": 47, "endOffset": 53}, {"referenceID": 1, "context": "We use the same pre-processing as described in [8, 2].", "startOffset": 47, "endOffset": 53}, {"referenceID": 9, "context": "Its ARC is comparable to the ARC associated with SVM rejection computed based on LIBSVM [11].", "startOffset": 88, "endOffset": 92}, {"referenceID": 6, "context": "the class conditional means, following the suggestion in [8].", "startOffset": 57, "endOffset": 60}, {"referenceID": 1, "context": "Further, the GMLVQ model provides insight into potentially relevant biomarkers and prototypical representatives of the classes, as has been detailed in the publication [2].", "startOffset": 168, "endOffset": 171}, {"referenceID": 1, "context": "The suggested biomarkers, in particular, have been linked with biomedical insight [2].", "startOffset": 82, "endOffset": 85}], "year": 2015, "abstractText": "We analyse optimum reject strategies for prototype-based classifiers and real-valued rejection measures, using the distance of a data point to the closest prototype or probabilistic counterparts. We compare reject schemes with global thresholds, and local thresholds for the Voronoi cells of the classifier. For the latter, we develop a polynomial-time algorithm to compute optimum thresholds based on a dynamic programming scheme, and we propose an intuitive linear time, memory efficient approximation thereof with competitive accuracy. Evaluating the performance in various benchmarks, we conclude that local reject options are beneficial in particular for simple prototype-based classifiers, while the improvement is less pronounced for advanced models. For the latter, an accuracy-reject curve which is comparable to support vector machine classifiers with state of the art reject options can be reached.", "creator": "LaTeX with hyperref package"}}}