{"id": "1505.01576", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "7-May-2015", "title": "Learning and Optimization with Submodular Functions", "abstract": "In many naturally occurring optimization problems one needs to ensure that the definition of the optimization problem lends itself to solutions that are tractable to compute. In cases where exact solutions cannot be computed tractably, it is beneficial to have strong guarantees on the tractable approximate solutions. In order operate under these criterion most optimization problems are cast under the umbrella of convexity or submodularity. In this report we will study design and optimization over a common class of functions called submodular functions. Set functions, and specifically submodular set functions, characterize a wide variety of naturally occurring optimization problems, and the property of submodularity of set functions has deep theoretical consequences with wide ranging applications. Informally, the property of submodularity of set functions concerns the intuitive \"principle of diminishing returns. This property states that adding an element to a smaller set has more value than adding it to a larger set. Common examples of submodular monotone functions are entropies, concave functions of cardinality, and matroid rank functions; non-monotone examples include graph cuts, network flows, and mutual information. These submodular functions, for example, are often called interlinear functions, but are not the same as the non-monotone functions. However, the submodular submodular function is typically an algebraic structure that is commonly used in most optimization problems. In the example above, a particular non-monotone function is termed an \"infinite\" monotone function. It is also considered an integral algebraic structure, with an inherent equivalency between the type of the two. In a more general definition of non-monotone functions, an infinite function can be called an uninefficient \"uninefficient\" monotone function, i.e., the \"precise\" monotone function. In contrast, a non-monotone function can be called a non-linear function. The following code describes the types of non-monotone functions, including set function types, and non-linear ones:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "histories": [["v1", "Thu, 7 May 2015 04:04:02 GMT  (271kb,D)", "http://arxiv.org/abs/1505.01576v1", "Tech Report - USC Computer Science CS-599, Convex and Combinatorial Optimization"]], "COMMENTS": "Tech Report - USC Computer Science CS-599, Convex and Combinatorial Optimization", "reviews": [], "SUBJECTS": "cs.LG", "authors": ["bharath sankaran", "marjan ghazvininejad", "xinran he", "david kale", "liron cohen"], "accepted": false, "id": "1505.01576"}, "pdf": {"name": "1505.01576.pdf", "metadata": {"source": "CRF", "title": "Learning and Optimization with Submodular Functions", "authors": ["Bharath Sankaran", "Marjan Ghazvininejad", "Xinran He", "David Kale", "Liron Cohen"], "emails": ["bsankara@usc.edu", "mghazvin@usc.edu", "xinranhe@usc.edu", "dkale@usc.edu", "lironcoh@usc.edu"], "sections": [{"heading": null, "text": "Learning and Optimization with Submodular Functions\nBharath Sankaran, Marjan Ghazvininejad, Xinran He, David Kale, Liron Cohen Department of Computer Science University of Southern California\nLos Angeles, CA 90034 {bsankara,mghazvin,xinranhe,dkale,lironcoh}@usc.edu"}, {"heading": "1 Motivation", "text": "In many naturally occurring optimization problems one needs to ensure that the definition of the optimization problem lends itself to solutions that are tractable to compute. In cases where exact solutions cannot be computed tractably, it is beneficial to have strong guarantees on the tractable approximate solutions. In order operate under these criterion most optimization problems are cast under the umbrella of convexity or submodularity. In this report we will study design and optimization over a common class of functions called submodular functions.\nSet functions, and specifically submodular set functions, characterize a wide variety of naturally occurring optimization problems, and the property of submodularity of set functions has deep theoretical consequences with wide ranging applications. Informally, the property of submodularity of set functions concerns the intuitive principle of diminishing returns. This property states that adding an element to a smaller set has more value than adding it to a larger set. Common examples of submodular monotone functions are entropies, concave functions of cardinality, and matroid rank functions; non-monotone examples include graph cuts, network flows, and mutual information.\nIn this paper we will review the formal definition of submodularity; the optimization of submodular functions, both maximization and minimization; and finally discuss some applications in relation to learning and reasoning using submodular functions."}, {"heading": "2 What is Submodularity: Formal Definition", "text": "We define submodularity as the property of set functions f : 2V \u2192 R, which assign to each subset S \u2286 V a value f(S). Here V is a finite set called the ground set. We also assume that f(\u2205) = 0.\nDefinition 1 A set function f : 2V \u2192 R is called submodular if it satisfies f(X) + f(Y ) \u2265 f(X \u222a U) + f(X \u2229 Y ) \u2200 X,Y \u2286 V\nThe function f lends itself to different forms in different application domains. In a machine learning context f could be a function that evaluates information of a given set, i.e entropy. Using this notion, we can easily introduce the property of diminishing returns by using an equivalent definition for submodularity.\nDefinition 2 A set function f : 2V \u2192 R is called submodular if it satisfies X \u2192 f(X \u222a k)\u2212 f(X) is non-increasing\nf(X \u222a k)\u2212 f(X) \u2265 f(Y \u222a k) + f(Y ) \u2200 X \u2282 Y \u2200k /\u2208 X\nFinally, a set function f is called supermodular if \u2212f is submodular, and if f is both sub- and supermodular then the function is called a modular function."}, {"heading": "2.1 Notation I", "text": "In this section we will introduce some notation that we will consistently maintain through the course of this document, unless specified. The ground set over which the submodular functions are defined will be denoted by\nar X\niv :1\n50 5.\n01 57\n6v 1\n[ cs\n.L G\n] 7\nM ay\n2 01\n5\nV with cardinality n. For a vector x \u2208 RV and a subset Y \u2286 V we define x(Y ) = \u2211 u\u2208Y x(u). We can naturally extend this definition to capture the positve and negative parts of the vector x as x+ \u2208 RV and x\u2212 \u2208 RV , where x+(u) = max{x(u), 0} and x\u2212(u) = min{x(u), 0}. For a submodular function f we define a polyhedral convex set P (f) called the submodular polyhedron:\nP (f) = {x \u2208 RV | x(S) \u2264 f(S) \u2200S \u2286 V }\nThe face of P (f) for which x(V ) = f(V ) which defines the base polyhedron:\nB(f) = {x \u2208 P (f) | x(V ) = f(V )}\nThe elements of B(f) are bases of the set V or the polyhedron P (V )."}, {"heading": "2.2 Properties of Submodular Functions", "text": "The basic properties of submodular functions are enumerated below. These properties will help us recast many of our optimization objectives as submodular optimization problems.\n\u2022 Lemma 2.1 (Closedness Properties): Submodular functions are closed under nonnegative linear combinations, i.e if {f1, f2, ..., fk} are submodular then the function g(X) = k\u2211 i=1 \u03b1ifi(X) is submodular \u2200\u03b1i \u2265 0.\nCorollary 1.1: The sum of a modular and submodular function is a submodular function.\nCorollary 1.2: (Restriction / marginalization): if Y \u2282 V , then X \u2192 f(X \u2229 Y ) is submodular on V and Y .\nCorollary 1.3: (Contraction / conditioning): If X \u2286 Y and f is submodular, then g(X) = f(Y \\ X) is submodular. Equivalently if Y \u2282 V , then X \u2192 f(X \u222a Y )\u2212 f(Y ) is submodular on V and V \\ Y\n\u2022 Lemma 2.2 (Partial Minimization): Monotone submodular functions remain submodular under truncation, i.e if f(X) is submodular then g(X) := min{f(X), c} for any constant c is submodular.\nNote: This property is not necessarily preserved for max or min for two submodular functions.\n\u2022 Lemma 2.3 (Cardinality Based Functions) If f(X) is a submodular function, then g(X) = \u03c6(f(X)) is also submodular if \u03c6() is a concave function.\n\u2022 Lemma 2.4 (Lova\u0301sz Extension) A function f is submodular function, iff its Lova\u0301sz Extension f\u0302 is convex, where\nf\u0302(c) = max{cTx | x(U) \u2264 f(U) \u2200 U \u2286 V and c \u2208 [0, 1]n}"}, {"heading": "3 Submodular Optimization", "text": "Submodular functions have many interesting connections with convex and concave functions as demonstrated by Lemma 3. Just as minimization of convex functions can be done efficiently, unconstrained submodular minimization is also possible in strongly polynomial time. Submodular function maximization in contrast is a NP hard combinatorial optimization problem, but approximate solutions can be found with guarantees. In fact a simple greedy solution method obtains a (1\u22121/e) approximation, given that we are maximizing a non-decreasing submodular function under matroid constraints."}, {"heading": "3.1 Submodular Function Minimization", "text": "Submodular function minimization can be divided into two categories, exact and approximate algorithms. Exact algorithms obtain global minimizers for a problem whereas approximate algorithms only achieve an approximate\nsolution i.e for a set X the solution f(X) \u2212 min Y\u2282V f(Y ) \u2264 , where is as small as possible. If is less than the minimum absolute difference between non equal values of f , the solution computed corresponds to the exact solution.\nAn important practical aspect of submodular function minimization is that most algorithms come with online approximation guarantees due to a duality relationship, which we will detail in the following subsections."}, {"heading": "3.1.1 Submodular Function Minimizers", "text": "For the lemmas stated below, we consider f to be a submodular function where {f : 2V \u2192 R | f(\u2205) = 0}.\n\u2022 Lemma 3.1 (Lattice of minimizers for submodular functions): The set of minimizers of f is a lattice, i.e if X and Y are minimizers then X \u222a Y and X \u2229 Y are also minimizers. This is evident from Definition 1 and Lemma 1.1\n\u2022 Lemma 3.2 (Diminishing return property of minimizers of submodular functions): The set X \u2282 V is a minimizer of f on 2V iff X is a minimizer of 2X \u2192 R defined as Y \u2282 X \u2192 f(Y ) and if \u2205 is a minimizer of the function from 2V \\X \u2192 R then it is defined as Y \u2282 V \\X \u2192 f(Y \u222aX)\u2212 f(X) . This can be easily shown from Definition 1.\nCorollary 6.1 : (Norm Characterization): Suppose x\u0302 is a minimizer of\nmin x \u2016x\u201622 subject to x \u2208 B(f)\nThen a minimizer A for f can be obtained as follows:\nA = {u \u2208 V | x\u0302(u) \u2264 0}\n\u2022 Lemma 3.3 (Dual of minimization of submodular functions):\nmin X\u2282V f(X) = max x\u2208B(f) x\u2212(V ) = f(V )\u2212 min x\u2208B(f) \u2016x\u2016\nAs mentioned in Section 2.1 (x\u2212)k = min{xk, 0} \u2200k \u2208 V . If X \u2282 V and x \u2208 B(f), we have f(X) \u2265 x\u2212(V ) with equality iff {x < 0} \u2282 X \u2282 {x \u2264 0} and x(X) = f(X).\nmin X\u2282V f(X) = max x\u2208P (f),x\u22640 x(V )\nAgain if X \u2282 V and x \u2208 P (f) | x \u2264 0, then f(X) \u2265 x(V ) iff {x \u2264 0} \u2282 X and s(X) = f(x)."}, {"heading": "3.1.2 Minimum Norm Point Algorithm", "text": "As an example of Submodular function minimization we present the minimum norm point algorithm. A non combinatorial approach proposed by Fujishige [1] is based on the norm characterization of the minima of f shown in Lemma 2.2. Fujishige uses Wolfe\u2019s algorithm [2] which was developed to minimize the L2 norm of a vector in a convex hull of a finite set of points P \u2208 Rn. This method maintains the vector x as a convex combination of points S and iterates over the following steps:\n1. A new point from P with a norm with respect to x is added to to set S.\n2. A point with the minimum norm x is computed in the affine hull of S.\n3. The minimum norm point x is projected onto the convex hull of S.\nIn the case of submodular functions, one needs to search through the set of all bases P which is exponential in size. This issue is circumvented by using Edmonds Greedy Algorithm [3].\nAlgorithm 1 Minimum Norm Point Algorithm 1: Initialization: x\u2190 extreme base generated using arbitrary ordering, S \u2190 {x} 2: loop 3: Selection of new base using Edmonds Greedy Algorithm: y\u2032 \u2190 argmin\ny xT y \u2200y \u2208 B(f)\n4: if xT y\u2032 = xTx then 5: return x 6: else 7: S \u2190 S \u222a {y\u2032} 8: Minimization over affine hull of S: z \u2190 argmin\ny \u2016y\u201622 where y \u2208 S\n9: Projection on to convex hull of S: 10: while z /\u2208 relint(conv(S)) do 11: z \u2190 intersection of [z, x] and S 12: S \u2190 face of S intersected by [z, x] 13: x\u2190 Z"}, {"heading": "3.2 Submodular Function Maximization", "text": "Problems for the form max X\u2282V f(X) for any submodular function f occurs in various applications. Problems of these kind are known to be NP-Hard. Feige and Mirrokni [4] showed that maximizing for non-negative submodular functions a random subset achieves at least 1/4th the optimal value and local search techniques achieve at least a 1/2. Though these problems are NP-Hard, a (1\u2212 1/e) approximation can be obtained when maximizing a non-decreasing submodular function under matroid constraints. The solution to the arbritary matroid constraint was shown more recently by Vondrak et al [5]. The initial result of an (1\u2212 1/e) approximation was shown by Nemhauser [6] in the 70s, but the result was only applicable to uniform matroid (cardinality) constraints. The solution to the uniform matroid contraint consists of a simple greedy algorithm that has implication in online learning and adaptive submodularity.\n\u2022 Lemma 3.4 Local minima for submodular function minimization: Given a submodular function {f : 2V \u2192 R | f(\u2205) = 0} andX \u2282 V such that \u2200k \u2208 X , f(X \\{k}) \u2264 f(X) and \u2200k \u2208 V \\X, f(X \u222a {k}) \u2264 f(X) holds true.\nThen, \u2200Y \u2282 X and \u2200Y \u2283 X , f(Y ) \u2264 f(X)"}, {"heading": "3.2.1 Greedy Algorithm for Monotone Submodular Function Maximization with Uniform Matroid Constraints", "text": "Maximization for arbitary constraints can be achieved using Vondrak\u2019s algorithm. In this document we\u2019ll focus on the greedy algorithm as it has implications in the online learning domain. Note: Maximization can also be formulated using the base polyhedron given we have f and its lova\u0301sz extension f\u0302 . In this case maximization is equivalent to finding the maximum l1-norm point in the base polyhedron. See [7] for more details. For monotone submodular maximization subject to uniform matroid constraints, we need to find a set X\u2217 \u2286 V such that\nX\u2217 = argmax \u2016X\u2016\u2264n f(X)\nwhere n is the cardinality (uniform matroid) constraint. Though this problem is NP-hard we can get an approximate solution with an approximation of (1\u22121/e) of the optimal solution. The algorithm for obtaining this solution is shown in Algorithm 2.\nAlgorithm 2 Greedy Algorithm 1: Initialization: Start with X = \u2205 2: for i = 1 to n do 3: y\u2032 := argmax\ny f(X \u222a y)\n4: X := X \u222a y\u2032"}, {"heading": "3.3 Adaptive Submodularity", "text": "The process of adaptively making decisions with uncertain outcomes is fundamental to many problems with partial observability. In such situations the decision maker needs to make a sequence of decisions by accounting for past observations and adapting accordingly. It has been shown by Golovin and Krause [8] that if a problem is adaptively submodular, then an adaptive greedy algorithm is guaranteed to obtain near optimal solutions. For clarity in the discussion of the Applications section, we introduce the notion of adaptive submodularity and adaptive monotonicity in this section."}, {"heading": "3.3.1 Preliminaries and Notation II", "text": "Let V be the ground set. Assuming each item of the set x \u2208 V can take a number of states from a set of possible states O, we represent item states as \u03c6 : V \u2192 O which is a function that gives the realization of the states of all items in the ground set. Hence \u03c6(x) is the state of x under the realization \u03c6. Now consider a random realization characterized by the random variable \u03a6. Then we can assume a prior probability distribution over realizations as p(\u03c6) := P[\u03a6 = \u03c6]. In cases where we observe only one realization \u03a6(x) at a time, as we pick an item x \u2208 V at a time; we can represent our observations so far with a partial realization \u03c7, i.e a function of a subset of V and its observed states. Hence \u03c7 \u2286 V \u00d7 O is {(x, o) : \u03c7(x) = o}. Here we denote the domain of \u03c7, i.e the set of items observed in \u03c7 as dom(\u03c7) = {x : \u2203o.(x, o) \u2208 \u03c7}. When a partial realization \u03c7 is equal everywhere with \u03c6 in the dom(\u03c7), they are consistent \u03c6 \u223c \u03c7. This implies that all the items observed with specific states in \u03c7 have also been observed with the same states in \u03c6. Now we extend this notion to subsets by saying if \u03c7 and \u03c7\u2032 are consistent with \u03c6 and dom(\u03c7) \u2286 dom(\u03c7\u2032), then \u03c7 is a subrealization of \u03c7\u2032. In a Partially Observable Markov Decision Problem (POMDP) sense, partial realization encompasses the POMDP belief states. These determine our posterior belief given the effect of all our actions and observations.\np(\u03c6 | \u03c7) := P[\u03a6 = \u03c6|\u03a6 \u223c \u03c7]\nDefinition 3 (Conditional Expected Marginal Benefit): Given a partial realization \u03c7 and a item x, the conditional expected marginal belief of x conditioned on having already observed \u03c7 is denoted by \u03b4(x | \u03c7)\n\u03b4(x | \u03c7) = E[f(dom(\u03c7) \u222a {x},\u03a6)\u2212 f(dom(\u03c7),\u03a6) | \u03a6 \u223c \u03c7]\nDefinition 4 (Adaptive Monotonicity): A function f : 2V \u00d7 OV \u2192 <+ is adaptive monotone with respect to the distribution p(\u03c6) if the conditional expected marginal benefit of any item x is non-negative, i.e \u2200\u03c7 with P[\u03a6 \u223c \u03c7] \u2265 0 and all x \u2208 V\n\u03b4(x | \u03c7) \u2265 0\nDefinition 5 (Adaptive Submodularity): A function f : 2V \u00d7 OV \u2192 <+ is adaptive submodular with respect to the distribution p(\u03c6) if the conditional expected marginal benefit of any fixed item does not increase as more items are selected and their states are observed, i.e if f is adaptively submodular w.r.t to p(\u03c6) if \u2200 \u03c7 and \u03c7\u2032 where \u03c7 is a subrealization of \u03c7\u2032 and all x \u2208 V \\ dom(\u03c7\u2032) , the following condition holds true:\n\u03b4(x | \u03c7) \u2265 \u03b4(x | \u03c7\u2032) Given these definitions we can now use the greedy algorithm defined in Algorithm 3 to give an \u03b1 approximation to the best greedy solution for online maximization problems of adaptively montone submodular functions. This means we find an x\u2032 such that\n\u03b4(x\u2032 | \u03c7) \u2265 1 \u03b1 \u03b4(x | \u03c7)\nThe budget for these maximization problems OR the number of rounds we\u2019d like to maximize is similar to the cardinality constraint of submodular problems."}, {"heading": "4 Applications", "text": ""}, {"heading": "4.1 Feature Selection", "text": "In machine learning and statistics, feature selection is one of the most important concepts. The aim of this process is to select a subset of relevant features for use in model construction and parameter fitting. In real world problems, we often\nAlgorithm 3 \u03b1-Approximate Greedy Adaptive Algorithm 1: Input: Budget n, ground set V , p(\u03c6) and function f 2: Output: X \u2282 V where \u2016X\u2016 = n 3: Initialize: X \u2190 \u2205 and \u03c7\u2190 \u2205 4: for i = 1 to n do 5: \u2200x \u2208 V \\X; Evaluate \u03b4(x | \u03c7) = E[f(dom(\u03c7) \u222a {x},\u03a6)\u2212 f(dom(\u03c7),\u03a6) | \u03a6 \u223c \u03c7] 6: x\u2217 = argmax\nx \u03b4(x | \u03c7)\n7: X \u2190 X \u222a x\u2217 8: Observe :\u03a6(x\u2217); Update: \u03c7\u2190 \u03c7 \u222a x\u2217,\u03a6(x\u2217)\nbegin learning with a large number of candidate features that may be redundant, irrelevant, or noisy. Such features needlessly increase the complexity of our models and may lead to overfitting and poor generalization to previously unseen data. By pruning out redundant or irrelevant features, we can gain:\n\u2022 improved model interpretability \u2022 increased computational efficiency, particularly during parameter fitting and prediction \u2022 enhanced generalization of the model by reducing overfitting\nIn feature selection, we search among features and choose the ones that are, in a broad sense, most informative or useful. This definition can be interpreted as an optimization problem for choosing a subset of features which maximize the mutual information between features and labeling function.\nHence, if V indicates the set of all features and a binary vector S indicating the chosen feature set, and xS the real valued vector of feature values for features in S, then assuming that ||S||1 \u2264 b, we can write the problem as:\nmaxsI(y;xs)\nwhere y is the labeling function."}, {"heading": "4.1.1 Submodularity", "text": "We will now show that this is submodular. Suppose A \u2282 B \u2282 S and m 6\u2208 B. We can show that\nI(y;xA \u222a xm)\u2212 I(y;xA) \u2265 I(y;xB \u222a xm)\u2212 I(y;xB) \u21d4 H(y|xA)\u2212H(y|xA, xm) \u2265 H(y|xB)\u2212H(y|xB , xm) (1)\nwe can write H(y|xA)\u2212H(y|xA, xm)\n= H(y|xA) +H(xm|xA)\u2212H(y, xm|xA) = H(y|xA) +H(xm|xA)\u2212H(y|xA)\u2212H(xm|xA, y) = H(xm|xA)\u2212H(xm|xA, y) (2)\nBy substituting into equation 1, we can see that there are cases where this problem is not submodular. Here we give the necessary conditions for submodularity:\n\u2022 Lemma 4.1 If xi\u2019s are all conditionally independent given y, then the function is submodular [9].\nThis constraint is met in many practical machine learning problems. If the xi\u2019s are all conditionally independent given y, then equation 2 can be written as\nH(y|xA)\u2212H(y|xA, xm) = H(xm|xA)\u2212H(xm|xA, y) and if we substitute this in equation 1, then it follows that\nI(y;xA \u222a xm)\u2212 I(y;xA) \u2265 I(y;xB \u222a xm)\u2212 I(y;xB) \u21d4 H(xm|xA) \u2265 H(xm|xB)\nHence, the problem of feature selection can be written as a maximization of a submodular function.[10]"}, {"heading": "4.2 MAP Inference", "text": "In this section we will specifically look at the problem of Maximum a posteriori inference on graphs. To analyze the algorithms in greater detail, we would like to introduce a few preliminary notions, including the concept of Polymatroids."}, {"heading": "4.2.1 Polymatroids", "text": "The notion of submodularity was first studied in the context of matroids. A set system (V,F) is defined by a ground set V and a family of subsets F \u2286 2V . Such a system is a matroid if\n\u2022 \u2205 \u2208 F \u2022 if X \u2286 Y \u2208 F then X \u2208 F \u2022 if X,Y \u2208 F and \u2016X\u2016 > \u2016Y \u2016 \u2203e \u2208 X \\ Y such that Y + e \u2208 F\nNow we define a function \u03c1 called a rank function, which assigns a natural number to each subset of V . This rank function is analagous to rank functions of matrices, in fact a matroid which is the set of linearly independent columns of a matrix A is called a metric matroid. We define our matroid rank function \u03c1 as follows\n\u03c1(X) = max{\u2016F\u2016 | F \u2208 F , F \u2286 X} If \u03c1 is a rank function of a matroid (V,F) then the following properties hold:\n\u2022 \u03c1(X) \u2264 \u2016X\u2016 \u2200X \u2286 Y \u2022 \u03c1 is non decreasing: if X \u2286 Y \u2286 V then \u03c1(X) \u2264 \u03c1(Y ) \u2022 \u03c1 is submodular\nIf a set function \u03c1 satisfies the above properties for a ground set V then the resulting structure (V, \u03c1) is called a polymatroid. Similarly if (V, \u03c1) is a polymatroid, then the family of subsets\nF = {F \u2286 V | \u03c1(F ) = \u2016F\u2016} defines a matroid (V,F)."}, {"heading": "4.2.2 Cuts in Graphs, Energy Minimization and MAP Inference", "text": "Consider a directed graphG = (V,A,W ) with positive edge weights w : A\u2192 R+. We can define a positive directed cut for a given set of vertices S \u2286 V as the set of edges starting in S and ending in V \\ S : \u03b4+(S) = {(i, j) \u2208 A | i \u2208 S, j \u2208 V \\ S}, Similarly a negative directed cut is \u03b4\u2212(S) = {(i, j) \u2208 A | i \u2208 S, j \u2208 V \\ S}. Finally the cut \u03b4(S) = \u03b4+ \u222a \u03b4\u2212, this for an undirected graph would be the set of edges with exactly one end in S. Hence we can define the weight of a cut as\nf+ = \u2211\ne\u2208\u03b4+(S)\nw(e), f\u2212 = \u2211\ne\u2208\u03b4\u2212(S)\nw(e), f = \u2211\ne\u2208\u03b4+(S)\nw(e)\nGiven these cut functions one can note that these cut functions are submodular.\n\u2022 Lemma 4.2 The cut functions f+, f\u2212 and f are submodular Proof : For the function f , suppose X,Y \u2282 V then,\nf(X) + f(Y )\u2212 f(X \u222a Y )\u2212 f(X \u2229 Y ) = \u2211\ni\u2208{X\\Y },j\u2208{Y \\X}\nw(i, j) + \u2211\ni\u2208{X\\Y },j\u2208{Y \\X}\nw(j, i)\nfrom the non-negativity of edge weights we can quickly conclude the above function is submodular. Similarly submodularity can be proved for f+ and f\u2212.\nNow in order to formalize our notion of Maximum a posteriori estimation as a submodular function minimization problem, we introduce the following notation. Consider the function E : {0, 1}n \u2192 R defined over binary variables X = {x1, ..., xn}. Such functions are called regular functions [11]. We can define an equivalent set function E\u0302\nE\u0302(S) = E(x) where xi = 1 if and only if i \u2208 S\nWe define the class F2 to be functions that can be written as a sum of functions of up to two binary variables at a time. E(x1, ....xn) = \u2211 i Ei(xi) + \u2211 i<j Ei,j(xi, xj)\nThe regularity of the binary function from F2 translates to submodularity of the equivalent set function. Given an input set of nodes P in a graph G and a set of labels L, the labeling l (which is a mapping from P to L) can be deduced by minimizing some energy function. In graph based energy minimization problems in computer vision and machine learning, the standard form of the energy function used is as follows\nE(l) = \u2211 p\u2208P Dp(lp) + \u2211 p,q\u2208N Vp,q(lp, lq)\nwhere N \u2282 P \u00d7 P is a neighbourhood set of nodes. Dp is a cost function derived from assigning label lp to node p. Vp,q is the cost of assigning labels lp, lq to adjacent nodes p, q. If V is a non-convex function of \u2016lp \u2212 lq\u2016 which accounts for border labeling, the energy function E(l) is called a discontinuity preserving energy function. This label assignment problem is similar to the graph cut problem, as the labeling function is submodular in the context of the regular functions defined earlier. Minimizing this energy function E is equivalent to finding the minimum cut of the graph G. However one should note that the solution depends on the exact form of the function V and it cannot be convex as it leads to oversmoothing of borders. In the case when V (lp, lq) = T [lp 6= lq], where T is the indicator function. This smoothness term is called the Potts Model. The solution shown above can readilyb e extended to more than two labels, or beyond the binary problem. We use the binary problem to motivate the result shown above. This result is widely used in computer vision in the domains of image segmentation, stereo correspondence and multicamera image reconstruction. Another widely used application of this approach is to find the Maximum a posteriori estimate of a Markov Random Field [12].\nConsider a set of random variables X = {X1, ...., Xn} defined on a set S such that the variable Xi can take the value xi from the set L = {l1, ...ln}. Then X can be defined as a Markov Random field with respect to the neighbourhood set N = {Ni | i \u2208 S} iff, the positivity property P (x) > 0 and the Markovian property P (xi | xS\\i) = P (xi | xNi) \u2200i \u2208 S. Here P (x) = P (X = x), P (xi) = P (Xi = xi) and finally P (X1 = x1, ..., Xn = xn) = (X = x) where x = {xi | i \u2208 S} is a realization of the field. Given these definitions the MAP estimate of the MRF can be formulated as an energy minimization problem, where energy corresponding to a realization of x (configuration of the field) is given by the negative log likelihood of the joint posterior probability of the MRF \u03c6(x) = \u2212logP (x | D) Hence the corresponding energy function for the Potts model becomes\nE(x) = \u2211 i\u2208S \u03c6(D|xi) + \u2211 j\u2208Ni \u03c8(xi, xj)  where \u03c6(D|xi) = \u2212logP (i \u2208 S) and\n\u03c8(xi, xj) = { Kij if xi 6= xj 0 if xi = xj\nHere Kij is some penalty cost which makes \u03c8(xi, xj) non convex.\nFinally we can conclude that the energy minimization problem solved by min-cut, max flow which yields the minimum energy solution is equivalent to finding the maximium a posteriori solution of a Markov Random Field."}, {"heading": "4.3 Active Learning", "text": ""}, {"heading": "4.3.1 Supervised learning theory", "text": "In classic supervised machine learning, the learning algorithm (or learner) is given the task of finding a response function f : X 7\u2192 Y that predicts as accurately as possible the output response Y \u2208 Y for a given input observation X \u2208 X [13]. Responses take a variety of forms. In classification, this may be a label from a discrete set of choices Y = {1, 2, . . . }, while in regression it may be continuous. One of the most common tasks\nis binary classification, in which Y = \u00b11. We have some unknown underlying distribution D over the space of observations and responses X \u00d7 Y , so that observation-response pairs are sampled according to (X,Y ) \u223c D. The learner chooses from candidate functions or hypotheses in a hypothesis space H with the goal of minimizing the expected error or risk D(h) = E(X,Y )\u223cD[err(h(X), Y )]. In other words, the learner\u2019s goal is to find h\u2217 that minimizes the risk: h\u2217 = arg maxh\u2208H D(h). For standard classification tasks, the error function is simply the indicator function of a mistake 1{h(X) 6= Y }, and so the risk is simply the probability of a mistake (h) = E(X,Y )\u223cD[1{h(X) 6= Y }] = Pr{h(X) 6= Y }. For continuous response functions and multiclass classification where order matters, there are a wide choice of more complex error functions.\nOf course, in practice D is unknown and so it is impossible to directly minimize the risk. Instead, the learner is provided with \u201csupervision\u201d in the form of a finite sample of observation-response pairs, i.e., a labeled training data set S = {Xi, Yi}i=1,...,n where |S| = n. The learner can then approximate D using S and minimize the empirical error over S:\n\u0302S(h) = E(X,Y )\u2208S [err(h(X), Y )] = 1\nn n\u2211 i=1 err(h(Xi), Yi)\nNote that this definition of empirical risk assumes that samples (X,Y ) are identically independently distributed (IID), a fairly common assumption in supervised machine learning. In the empirical risk minimization (ERM) paradigm, the learner assumes that the sample S is sufficiently representative of D such that choosing h\u0302 = arg maxh\u2208H \u0302S will yield a hypothesis h\u0302 that will also have a relatively low risk D(h\u0302) [14]. A well known theoretical result for classification that comes from Vapnik tells us if we want to learn a \u201cgood\u201d classifier from a hypothesis class H, then we need roughly |S| = O\u0303 ( d/\u03b52 log(1/\u03b4) ) points in our training sample [15]. Here \u03b5 is the maximum deviation that\nwe will tolerate between the true risks of h\u0302 and optimal h\u2217 and \u03b4 is the probability with which we are willing to let this happen (i.e., we want | (h\u0302)\u2212 (h\u2217)| \u2264 \u03b5 to hold with probability 1\u2212 \u03b4). Informally, d represents the \u201csize\u201d of our hypothesis class; formally, it is the VC dimension. A useful rule of thumb is that for most useful hypothesis classes, the VC dimension scales linearly with the number of parameters and so the number of training samples needed scales linearly with \u201ccomplexity\u201d of the model.\nIt is important to distinguish two cases of supervised learning, based on realizability. When the problem is realizable, then there exists some hypothesis h \u2208 H that can perfectly predict the response for every point (i.e., err(h\u2217) = 0); in binary classification, this corresponds to the problem being \u201cseparable\u201d by a hypothesis in H. When err(h) > 0, the problem is not realizable [16]. The presence of label noise, where the same point may receive different responses, further complicates this picture. If a training sample S contains noisy labels (perhaps due to error), this may mislead the ERM. If the true data distribution allows points to have different labels (i.e., our true labeling function is stochastic), then at best we may only be able to model P (Y |X), rather than make perfect predictions."}, {"heading": "4.3.2 Selective sampling as a submodular problem", "text": "Imagine the following problem, which we will call the selective sampling on a budget problem: given a large, fully labeled finite sample S, we will \u201cpurchase\u201d a subset L \u2286 S (where |L| |S| because our \u201ccost\u201d scales with |L|) and train h\u0304 = arg maxh\u2208H \u0302L(h) with the goal of minimizing D(h\u0304). We are given full access to S until we make our purchase decision, at which point we can use only L to choose our final hypothesis (i.e., we must \u201cforget\u201d everything we know about S\\L). This can be thought of as choosing the smallest possible representative subsampleL. Intuitively, it is similar to a set cover problem: we want to pose queries that \u201ccover\u201d (i.e., eliminate) as many false hypotheses (inconsistent with our labeled data set) as possible. This problem clearly has submodular structure.\nLemma 4.3 The selective sampling on a budget problem is submodular and monotone decreasing.\nProof 4.4 We provide a non-rigorous justification. First, for labeled subsample A, define a hypothesis set HA \u2286 H that contains all hypotheses fromH that are consistent with the labeled points inA: HA = {h : \u0302A(h) = 0\u2227h \u2208 H}. Now define a function f(A) = 1\u2212 |HA|/|H|, i.e., maps A to the value of 1 minus probability mass (under a uniform prior) of its consistent hypothesis set. Now consider labeled subsamples B and B\u2032 such that B \u2286 B\u2032 \u2286 S and arbitrary point X 6\u2208 B, 6\u2208 B\u2032. The key insight here is that as we add labeled points to our subsamples, we can only remove hypotheses from our current hypothesis space; once a hypothesis has been removed, it cannot be re-added.\nf is monotone increasing: Suppose that hypothesis h \u2208 HB\u2032 . This means that it is consistent with every labeled point in B\u2032. Because B \u2286 B\u2032, h must also be consistent with every point in B and so h \u2208 HB. Therefore,HB\u2032 \u2286 HB and so\n|HB\u2032 | \u2264 |HB| |HB\u2032 |/|H| \u2264 |HB|/|H|\n1\u2212 |HB\u2032 |/|H| \u2265 1\u2212 |HB|/|H| f(B\u2032) \u2265 f(B)\nwhenever B \u2286 B\u2032. f is submodular: Now suppose that adding point X to B\u2032 removes h from HB\u2032 , i.e., h \u2208 HB\u2032 \\ HB\u2032\u222a{X}. Because HB\u2032 \u2286 HB whenever B \u2286 B\u2032, it must also be the case that HB\u2032\u222a{X} \u2286 HB\u222a{X} and so h \u2208 HB \\ HB\u222a{X}. Thus, if adding X to B\u2032 removes m hypotheses fromHB\u2032 , then adding X to B must remove n \u2265 m hypotheses fromHB:\nm \u2264 n |HB\u2032 | \u2212 |HB\u2032 |+m \u2264 |HB| \u2212 |HB|+ n\n|HB\u2032 |/|H| \u2212 (|HB\u2032 | \u2212m)/|H| \u2264 |HB|/|H| \u2212 (|HB| \u2212 n)/|H| \u22121 + |HB\u2032 |/|H|+ 1\u2212 (|HB\u2032 | \u2212m)/|H| \u2264 \u22121 + |HB|/|H|+ 1\u2212 (|HB| \u2212 n)/|H| 1\u2212 (|HB\u2032 | \u2212m)/|H| \u2212 (1\u2212 |HB\u2032 |/|H|) \u2264 1\u2212 (|HB| \u2212 n)/|H| \u2212 (1\u2212 |HB|/|H|)\nf(B\u2032 \u222a {X})\u2212 f(B\u2032) \u2264 f(B \u222a {X})\u2212 f(B)\nwhenever B \u2286 B\u2032.\nThis is intuitive. IfH\u2032 \u2286 H contains all hypotheses inH that are inconsistent with X\u2019s label, then clearlyHB\u2032 \u2286 HB implies thatHB\u2032 \\ C \u2286 HB \\ C. This result may not seem terribly exciting, but what it does suggest is that we can solve the selective sampling on a budget problem using a greedy approach: on the tth iteration, choose the X that eliminates the largest number of inconsistent hypotheses from our currentHB:\n(X,Y )t = arg max (X,Y )\u2208S\\Bt \u2223\u2223\u2223\u2223\u2223\u2223 \u2211\nh\u2208HBt\n1{h(X) 6= Y } \u2223\u2223\u2223\u2223\u2223\u2223"}, {"heading": "4.3.3 Greedy active learning is adaptive submodular", "text": "Now imagine a variation of the above selective sampling problem where we do not have access to the label of X \u2208 S until we \u201cpurchase\u201d it. Here we might use active learning. Active learning is a variation of the supervised learning paradigm where the learner does not receive access to a fully labeled data sample S upfront. Rather it has access to an unlabeled data sample U = {(X, ?)}, as well as an oracle that the learner can query for the response (or label) of an observation, Y = or(X) [16]. The active learner is given agency to choose which individual samples to label, but each query has a cost c and the learner has only a limited budget to spend on labeling data. Similar to the selective sampling scenario described above, the active learner has dual goals: to choose simultaneously a labeled subset of observations L \u2286 U and a hypothesis h\u0304 = arg minh\u2208H \u0302L(h) (i.e., h\u0304 is the ERM for L) that will yield the best possible predictive performance (i.e., lowest risk D(h\u0304)).\nWhen evaluating active learning algorithms, we are concerned primarily with two performance properties: the quality (in terms of risk) of the hypotheses they produce and their query efficiency. Intuitively, a good active learner will use a very small number of label queries to produce a hypothesis with very small predictive error. More formally, we are interested in (1) how the error of the hypothesis produced by an active learner that chooses labeled subsample L compares with that of the hypothesis that we could learn from a fully labeled sample S where L \u2286 S; and (2) how many label queries must be made to achieve a certain level of performance, which we call label complexity and express in Big-Oh notation. An ideal active learner will compete with fully supervised learning with |L| |S|. More realistically, we hope to at least place an upper bound on the error of active learning that is within a constant (multiplicative or additive) factor of the error of fully labeled supervised learning.\nIt is not hard to design greedy approaches to active learning, but two questions arise: first, are there greedy active learning algorithms that have sound theoretical guarantees about error and label complexity; and second, can we show that such algorithms are in fact specific cases of more general approaches based on submodularity? The answer to\nboth of these questions is, in fact, yes [17]. Let Lt be the set of labeled data points after t queries (and recall that HLt is the set of hypotheses fromH consistent with the labeled data in Lt). For the next (t+ 1) label query, we want to choose the unlabeled point that provokes the greatest disagreement between hypotheses in HLt .The maximum disagreement occurs when half of the hypotheses predict one label and the rest the other. Equivalently, this minimizes the absolute value of the sum of all predicted labels: |\u2211h\u2208HLt h(x)| (when using \u00b11 labels). Following this query policy, we hope to cut the tth hypothesis space roughly in half with query t+ 1 and achieve a label complexity that is roughly O(log(d/\u03b5)) for d the size (e.g., VC dimension) of the hypothesis space and deviation bound \u03b5. [17] shows that in the worst case, this strategy may have to query every single label; indeed, for certain pathological cases, even the optimal query strategy will need to query every label. However, the average case analysis is much more promising. On average, the greedy strategy\u2019s label complexity is at most O\u0303(log d) times larger that that of the optimal policy, as we show below in Theorem 4.5, which rephrases Claim 4 and Theorem 3 from [17]:\nTheorem 4.5 (Dasgupta [17]) Suppose the optimal query policy requiresM labels in expectation for target hypotheses chosen uniformly from hypothesis class H of (VC) dimension d \u2265 ee \u2248 16. Then the expected number of labels queried by the greedy strategy is at least M log dlog log d and at most 4M log d.\nAs [17] points out, the lower bound is a bit depressing, but we derive some comfort from the fact that the upper bound matches the lower bound within a multiplicative factor. We can extend this analysis to a Bayesian framework where we have a nonuniform prior distribution over hypotheses \u03c0(h). In this setting, we seek a label query that will divide the probability mass over hypotheses (rather than the hypothesis space itself) in half. We do this by minimizing the absolute value of the sum of predictions weighted by the prior probabilities of the hypotheses making them: |\u2211h\u2208Ht \u03c0(x)h(x)|. In this case, the d term in the lower and upper bounds is replaced with minh\u2208H \u03c0(h). In [8], the authors show that the hypothesis space reduction problem is adaptive submodular, specifically an example of an adaptive stochastic coverage problem. Here our ground set is the set of all points V = {x : x \u2208 U}, and each point has an unobserved stateO = {y : y \u2208 Y} = {\u00b11} where \u03a6(x) = y for the pair (x, y) and for a given hypothesis h \u2208 H, \u03a6h(x) = h(x). The set of labeled points Lt forms a consistent partial realization \u03c7t at iteration t. Then we can define a function that takes as input an element subset V \u2032 and a realization function \u03a6\u2032 and maps it to a real number in the interval [0, 1]:\nf(V \u2032,\u03a6\u2032) = f\u0302(H = {h : h(x) = \u03a6\u2032(x) for all x \u2208 V \u2032}) = 1\u2212 \u2211 h\u2208H \u03c0(h)\nSo for a labeled subset Lt, f(Vt,\u03a6t) = f\u0302(Lt), where Vt = {x : (x, y) \u2208 Lt} and \u03a6t(x) = \u03a8t(x) = y for (x, y) \u2208 Lt. This function is adaptively submodular, as shown in Lemma 4.6, adapted from [8]:\nLemma 4.6 (Golovin and Krause [8]) The hypothesis space reduction problem is adaptive submodular and adaptive monotone.\nThe proof of monotonicity follows along lines similar to the one used in Theorem 4.3: basically, querying a label can only remove hypotheses, and hypothesis probabilities are nonzero, so removing one can only reduce the value of f . The proof of submodularity is more subtle, though it rests on the same intuition as that of monotonicity and involves comparing the conditional expected marginal benefits, as described in. Interestingly, this angle yields a slightly more optimistic average case analysis than that given in Theorem 4.5 above, removing the constant multiplier from the upper bound. We give it below in Theorem 4.7, adapted from [8]:\nTheorem 4.7 (Golovin and Krause [8]) Suppose the optimal query policy requires M labels in expectation for target hypotheses chosen using distribution \u03c0 from hypothesis class H. Then the expected number of labels queried by the greedy strategy is at most M ( log (\n1 minh\u2208H \u03c0(h)\n) + 1 ) ."}, {"heading": "4.3.4 New directions", "text": "This is a wonderful example of cross fertilization between research in computer science theory and optimization and learning theory. Working on submodularity and adaptive submodularity, computer scientists were able to rediscover and generalize previously published results from machine learning, improving an upper bound along the way. More\nimportant, they provided new and useful insights into the problem, relating it to other problems (which we did not discuss in this section) and paving the way to new discoveries. Recently, there has been an explosion of similar work, much of it published in 2013. [18] describe a framework for performing distributed submodular maximization in a shared-nothing (MapReduce) storage setting and using it to choose a representative subsample of a massive data set for learning (similar to our selective sampling on a budget problem). [19] describe a greedy batch-mode active learning algorithm that queries labels in batches of size k > 1 and show that this approach is competitive not only with optimal batch-more active learning but also with more traditional greedy active learning. There are a variety of other papers pushing the boundary in this area [20] [21] [22] [23].\nThere are two lines of work that seem conspicuously absent (at least, based on our admittedly myopic literature review): (1) applications of submodularity to streaming active learning; and (2) \u201caggressive\u201d active learning in the nonrealizable case. The former involves active learning when we do not have access to the entirety of U at the start of the learning process. Rather, we receive one data point at a time in an online fashion and must make a query decision for point Xt based only on the samples Ut that we\u2019ve seen so far. The above greedy algorithm and analysis require that we be able to choose a point Xt = arg minX\u2208U\\Lt\n\u2223\u2223\u2223\u2211h\u2208HLt \u03c0(h)h(X)\u2223\u2223\u2223. We cannot, of course, do this in the streaming setting. Nonetheless, intuition suggests that we may be able to extend the adaptive submodularity framework (or some related idea) to this setting.\nAggressive active learning in the non-realizable case is a wide open problem, at least as of [16]. Informally, aggressive active learners, which include greedy active learners, are those that attempt to make the \u201cmost informative\u201d label query at each step. In the realizable case, it is possible to develop aggressive algorithms that are statistically consistent (will discover the optimal hypothesis with enough queries) and have sound theoretical guarantees for label complexity. However, these guarantees go out the window with realizability. Perhaps some form of submodularity may help here, but at first blush, it looks as though the nonrealizable case will not satisfy the assumptions necessary for adaptive submodularity. We do have a variety of mellow active learners, which seek any informative label query, that are label efficient and statistically consistent [24] [16]. It would be interesting to develop a new analysis of these algorithms in terms of submodularity and then to see if this analysis perhaps provides a bridge between mellow and aggressive active learning."}, {"heading": "5 Submodularity in Weighted Constraint Reasoning", "text": "Many application require efficient representation and reasoning about factors like fuzziness, probabilities, preferences, and/or costs. Various extensions to the basic framework of Constraint Satisfaction Problems (CSPs) [25] have been introduced to incorporate and reason about such \u201csoft\u201d constraints. These include variants like fuzzy-CSPs, probabilisticCSPs, and Weighted-CSPs (WCSPs). A WCSP is an optimization version of a CSP in which the constraints are no longer \u201chard,\u201d but are extended by associating (non-negative) costs with the tuples. The goal is to find an assignment of values to all variables from their respective domains such that the total cost is minimized.\nFor simplicity, we restrict ourselves to Boolean WCSPs. Note that this class can be used to model important combinatorial problems such as representing and reasoning about user preferences [26], over-subscription planning with goal preferences [27], combinatorial auctions [28], and bioinformatics [29], energy minimization problems in probabilistic settings, computer vision, Markov Random Fields [30], etc. In addition, many real-world domains exhibit submodularity in the cost structure that is worth exploiting for computational benefits. In what follows, we define a class of submodular constraints over Boolean domains and give a polynomial-time algorithm for solving instances from this class."}, {"heading": "5.1 Weighted Constraint Satisfaction Problems", "text": "Formally, a WCSP is defined by a triplet \u3008X ,D, C\u3009 where X = {X1, X2 . . . XN} is a set of variables, and C = {C1, C2 . . . CM} is a set of weighted constraints on subsets of the variables. Each variable Xi is associated with a discrete-valued domain Di \u2208 D, and each constraint Ci is defined on a certain subset Si \u2286 X of the variables. Si is referred to as the scope of Ci; and Ci specifies a non-negative cost for every possible combination of values to the variables in Si. The arity of the constraint Ci is equal to |Si|. An optimal solution is an assignment of values to all variables (from their respective domains) so that the sum of the costs (as specified locally by each weighted constraint) is minimized. In a Boolean WCSP, the size of any variable\u2019s domain is 2 (that is, Di = {0, 1} for all i). Boolean WCSPs are representationally as powerful as WCSPs; and it is well known that optimally solving Boolean WCSPs is NP-hard in general [25]. The constraint graph associated with a WCSP instance is an undirected graph where a node represents a variable and an edge (Xi, Xj) exists if and only if Xi and Xj appear together in some constraint."}, {"heading": "5.2 Submodular Constraints", "text": "Submodular constraints over Boolean domains correspond directly to submodular set functions. A set function \u03c8 : 2V \u2192 Q defined on all subsets of a set V is submodular if and only if, for all subsets S, T \u2286 V , we have \u03c8(S \u222a T ) + \u03c8(S \u2229 T ) \u2264 \u03c8(S) + \u03c8(T ). A submodular constraint is a weighted constraint with a submodular cost function. Here, the correspondence is in light of the observation that any subset S can be interpreted as specifying the Boolean variables in V that are set to 1. Boolean WCSPs with submodular constraints are known to be tractable [31]. However, the general algorithm for solving Boolean WCSPs with submodular constraints has a time complexity of O(N6), which is not very practical. Specific classes of submodular constraints have been shown to be related to graph cuts, and are therefore solvable more efficiently [31]."}, {"heading": "5.3 Lifted Graphical Representations for Weighted Constraints", "text": "Constraint Composite Graphs (CCGs) are combinatorial structures associated with optimization problems posed as WCSPs. They provide a unifying framework for exploiting both the graphical structure of the variable interactions as well as the numerical structure of the weighted constraints [32]. We reformulate WCSPs as minimum weighted vertex cover problems to construct simple bipartite graph representations for important classes of submodular constraints, thereby translating them into max-flow problems on bipartite graphs.\nThe concept of the minimum weighted VC1 on a given undirected graph G = \u3008V,E\u3009 can be extended to the notion of projecting minimum weighted VCs onto a given IS2 U \u2286 V . The input to such a projection is the graph G as well as an identified IS U = {u1, u2 . . . uk}. The output is a table of 2k numbers. Each entry in this table corresponds to a k-bit vector. We say that a k-bit vector imposes the following restrictions: if the ith bit is 0 (1), the node ui is necessarily excluded (included) from the minimum weighted VC. The value of an entry is the weight of the minimum weighted VC conditioned on the restrictions imposed by it. Figure 1 presents a simple example.\nThe aformentioned table can be viewed as a weighted constraint over |U | Boolean variables. Conversely, given a (Boolean) weighted constraint, we can think about designing a \u201clifted\u201d representation for it so as to be able to view it as the projection of a minimum weighted VC problem in some node-weighted undirected graph. This idea was first discussed in [33]. The benefit of constructing these graphical representations for individual constraints lies in the fact that the \u201clifted\u201d graphical representation for the entire WCSP can be obtained simply by \u201cmerging3\u201d them. This \u201cmerged\u201d graph is referred to as the CCG associated with the WCSP. Computing the minimum weighted VC for the CCG yields a solution for the WCSP; namely, if Xi is in the minimum weighted VC, then it is assigned the value 1 in the WCSP, else it is assigned the value 0 in the WCSP. Figure 1 shows an example WCSP and its CCG.\nAny given weighted constraint on Boolean variables can be represented graphically using a tripartite graph, which can be constructed in polynomial time [32]. In many cases, the lifted graphical representations even turn out to be only bipartite. Since the resulting CCG is also bipartite if each of the individual graphical representations are bipartite, the tractability of the language LBooleanbipartite - the language of all Boolean weighted constraints with a bipartite graphical representation - is readily established. This is because solving minimum weighted VC problems on bipartite graphs is reducible to max-flow problems, and can therefore be solved efficiently in polynomial time.\n1A vertex cover (VC) is a set of nodes S such that every edge has at least one end point in S. 2U is an independent set (IS) of a graph if and only if no two nodes in U are connected by an edge. 3nodes that represent the same variable are simply \u201cmerged\u201d - along with their edges - and every \u201ccomposite\u201d node is given a\nweight equal to the sum of the individual weights of the merged nodes.\n(w1 \u2212 w2)Xi \u2212w(XiXj) \u2212w(XiXjXk) \u2212w(1\u2212Xi)(1\u2212Xj)(1\u2212Xk)w(XiXjXk)\nFinally, Boolean weighted constraints can be represented as multivariate polynomials on the variables participating in that constraint [31, 32]. The coefficients of the polynomial can be computed with a standard Gaussian Elimination procedure for solving systems of linear equations. The linear equations themselves arise from substituting different combinations of values to the variables, and equating them to the corresponding entries in the weighted constraint. One way to build the CCG of a given weighted constraint is: (a) build the graphical representations for each of the individual terms in the multivariate polynomial; and (b) \u201cmerge\u201d these graphical representations [32]."}, {"heading": "5.4 Submodular Constraints with bounded arity", "text": "The focus of [34] is on bounded arity submodular constraints (that is, submodular constraints with arity at most K, for some constant K) and providing asymptotically improved algorithms for solving them. The reason these submodular constraints can be solved more efficiently is because the underlying max-flow problems are staged on bipartite graphs. For Boolean WCSPs with arity at most K, the bipartite CCG has N nodes in one partition, at most 2KM nodes in the other partition, and at most K2KM edges. For K bounded by a constant, this results in a time complexity of O(NM logM). This significantly improves on the O((N + M)3) time complexity of the algorithm provided by [31].4 Figure 3 shows the lifted graphical representation for all possible terms of a constraint of arity 3.\n4For arity K, M could be as large as ( N K ) ."}, {"heading": "5.5 Social Influence", "text": "With the increasing popularity of online social network websites and apps, such as Facebook and Twitter, social networks now play a fundamental role as medium for people to share, exchange, and obtain new ideas and information. Modeling, utilizing, and understanding social influence has become \u201chot topic\u201d in computer science, machine learning, and computational social science [35, 36, 37, 38, 39, 40, 41, 42]. It turns out that submodular functions and especially submodular function maximization play fundamental roles in solving algorithmic questions associated with social influence. In this section, we mainly focus on using submodular function maximization techniques to solve two problems related to social influence, namely influence maximization [36] and network inference [35]."}, {"heading": "5.5.1 Influence Maximization", "text": "Assume that now a company wants to promote its new product among the individuals in a social network (real or virtual). The company has a limited budget to give free samples of their new product to the users in the social network. A natural question to ask is to which set of users should the company give the free sample products, such that the overall adoption of the new product can be maximized. The question is exactly the influence maximization problem, namely selecting a small set of seed nodes in a social network such that its overall influence coverage is maximized under a certain diffusion model.\nAmong the many diffusion models, the Independent Cascade (IC) model and Linear Threshold (LT) are used widely in the study of influence maximization [36]. Both IC and LT models are stochastic models characterizing how influence propagates throughout the network, starting from the initial seed notes.\nFor influence maximization, the objective function \u03c3(S), where S is the initial seed set, is the expected number of activated nodes under the diffusion model. The problem is simply to maximize \u03c3(S) subject to the cardinality constraint |S| \u2264 k. It has been shown that the influence maximization problem under both IC model and LT model is NP-hard [36]. However, by the following theorems the problem allows efficient approximation algorithm.\nTheorem 5.1 (Kempe et al. [36]) The objective function of influence maximization problem under both IC and LT model is non-negative, monotone and submodular.\nBy the classic greedy algorithm for monotone submodular function maximization, a 1\u2212 1/e approximation guarantee can be achieved. The proof of the theorem is by the fact that conic combination of submodular functions is also submodular. The objective function is a expectation and can be written as\n\u03c3(S) = \u2211\noutcomeX\nProb[X]\u03c3(S|X),\nwhere X is any realization of the stochastic diffusion process. A reachability argument for both IC model and LT model can be used to show that \u03c3(S|X) is submodular under any X . Though the greedy algorithm can solve the problem approximately in polynomial time, its key step, i.e., evaluation of the marginal gain \u03c3(S \u222a {u}) \u2212 \u03c3(S), can take a long time for large networks. Many papers have been published on how to improve the efficiency of the algorithm [43, 44, 45, 46, 47], such as by lazy evaluation [44, 45], or by approximate evaluation of the marginal gain [43, 46, 47] .\nA more general result on Generalized Linear Threshold models has been proved generalizing the results for the IC and LT models in [48]. The proof uses a sophisticated stage-wise coupling argument to show that submodularity applies. The idea of the proof is to add the initial seeds and propagate the influence stage by stage. The key component in the proof is the anti-sense coupling used in the last stage.\nA extension to influence maximization that draws much attention recently is to solve this problem under the competitive influence. Competitive influence implies that two or multiple competitive products, or ideas are propagating simultaneously in the social network. The influence maximization problem naturally extends to maximizing one\u2019s own influence [38, 39, 40] or minimizing the influence of the competitors [41, 42] given the choices of the initial seeds of the competitors. For example, on the maximization side, [49] study the influence maximization when a user can dislike the product and propagate bad news about it. On the minimization side, [50] study the idea of influence blocking maximization, which focuses on selecting seeds to block the propagation of rumors. Both approaches solve the optimization problem by showing the objective function is monotone and submodular. The proof technique is similar to that in [36]. However, their arguments are much more complicated due to the interaction of competitive diffusion."}, {"heading": "5.5.2 Network Inference", "text": "The influence maximization problem takes as its input a social network structure with the strength of influence on each edge. However, in most cases, the underlying network that enables the diffusion is hidden (e.g., networks on who influenced whom). The most common observations of information diffusion are only the activation time for individual in social network (e.g., the time stamps of when a person posted a blog containing certain information or retweeted another user\u2019s tweet, when a user bought a certain product in viral marketing applications, etc.). The network inference problem focuses on discovering the diffusion network from the observed cascades occurring among the individuals in a social network. Existing approaches to this problem solve a maximum likelihood estimation problem with respect to the network structure under certain diffusion models [35, 37, 51, 52]. It turns out that the likelihood function of this problem can be approximated with a submodular function. Thus, submodular function maximization can be used to solve this problem [35, 37].\nThe extended IC model is used as the diffusion model in [35, 37]. In the extended IC model, each edge is associated with an activation probability. Moreover, each activation has time delay. For example, if node v is activated at time tv and the activation attempt to v\u2019s neighbour u succeeds. Then u with become activated at time tu + \u2206t, where \u2206t is the time delay. In the model, the delay time satisfies exponential distribution or power law distribution, namely\nPd(\u2206t) \u221d e\u2212 \u2206t \u03b1 or Pd(\u2206t) \u221d\n1\n\u2206t\u03b1\nThen according to the model, if v which is activated at time tv and v succeeds in activating node u which becomes activated at time tu. Then the probability this activation occurs is:\nPc(v, u) = Pd(tu \u2212 tv)pvu Also the model assumes that influence can only propagate forward in time, which means Pc(v, u) = 0 if tv > tu. Then if the pattern of cascade c forms a tree T , the probability that the cascade is observed given the tree is\nP (c|T ) = \u220f\n(i,j)\u2208T\nPc(i, j)\nIn addition, if we assume the who-infect-who relation forms a tree pattern (one is only activated by one person). Then given a certain G, the probability we observe the cascade c would be\nP (c|G) = \u2211\nT\u2208T (G)\nP (c|T )P (T |G) \u221d \u2211\nT\u2208T (G) \u220f (i,j)\u2208T Pc(i, j)\nwhere T (G) is all directed spanning tree on G. Therefore, if we have observed a set of cascades C = {c1, c2, . . .}, The probability of observing all these cascades is\nP (C|G) = \u220f c\u2208C P (c|G).\nUnder this configuration, the network inference problem is to find an graph G\u0302 = (V, E\u0302) with less than k edges such that\nG\u0302 = arg max |E|\u2264k\nP (C|G)\nIn the objective function, we sum over all spanning trees of the graph G, which is super-exponential. In order to make this computation feasible, we instead solve an approximation in which only the spanning tree with the maximal likelihood is considered, namely\nP (C|G) = \u220f c\u2208C max T\u2208T (G) P (c|T ) = \u220f c\u2208C max T\u2208T (G) \u220f (i,j)\u2208T Pc(i, j)\nThen we define Fc(G) as the difference between the log likelihood of cascade c over graph G and empty graph K\u0304.\nFc(G) = max T\u2208T (G) logP (c|T )\u2212 max T\u2208T (K\u0304) logP (c|T )\nand take sum over all the cascades, we have\nFC(G) = \u2211 c\u2208C Fc(G)\nK\u0304 is a graph with all the nodes in G and also a extra node m. The only edges in K\u0304 are the edges from m to every other nodes with activation probability \u03b5 and delay 0. The extra node represents the external influence. Then the optimization problem can be rewritten as\nG\u2217 = arg max |E|\u2264k FC(G) (3)\n[35] proved that this objective function is monotone and submodular. Therefore, a greedy algorithm can achieve 1\u2212 1e approximation for solving it. This approach was later improved by by the MultiTree algorithm in [37], where the the matrix tree theorem is used to calculated the exact summation over all possible spanning trees, rather than using the maximum spanning tree approximation.\nIn a on-going project by Xinran He with Prof. Yan Liu, we are experimenting with using Maximum a Posteriori inference to solve the network inference problem. The previous approaches assume no prior knowledge about the structure of the inferred graph. However, it has been shown repeatedly that social networks have many unique properties, including heavy-tail degree distribution, small diameter, community structure, and so on. We propose a social network generative model over the diffusion network as a prior to incorporate the prior knowledge about network structure. Our current choice is the Kronecker graphs model [53, 54]. The Kronecker graphs model is a parametric model which can provide a probability for the existence of each edge in the social network. The existence of each edge is considered independent under this model. Using this model as a prior, we can change the objective function FC(G) in Equation 3 to\nF \u2032C(G) = FC(G) + \u2211 e\u2208E (logProb[e exists]\u2212 logProb[e not exists]).\nAfter adding a modular function to a submodular function, the resulted F \u2032C(G) is still submodular, however it may not necessary be monotone any more. As a result, the simple greedy algorithm can not be used to solve this problem. Instead, we can use the algorithm proposed in [55] with a 1/2 + o(1) approximation guarantee."}], "references": [{"title": "Lexicographically optimal base of a polymatroid with respect to a weight vector", "author": ["S. Fujishige"], "venue": "Mathematics of Operations Research, vol. 5, no. 2, pp. 186\u2013196, 1980. [Online]. Available: http: //pubsonline.informs.org/doi/abs/10.1287/moor.5.2.186", "citeRegEx": "1", "shortCiteRegEx": null, "year": 1980}, {"title": "Finding the nearest point in a polytope", "author": ["P. Wolfe"], "venue": "Mathematical Programming, vol. 11, no. 1, pp. 128\u2013149, 1976. [Online]. Available: http://dx.doi.org/10.1007/BF01580381", "citeRegEx": "2", "shortCiteRegEx": null, "year": 1976}, {"title": "Submodular functions, matroids, and certain polyhedra", "author": ["J. Edmonds"], "venue": "Combinatorial Optimization Eureka, You Shrink!, ser. Lecture Notes in Computer Science, M. Jnger, G. Reinelt, and G. Rinaldi, Eds. Springer Berlin Heidelberg, 2003, vol. 2570, pp. 11\u201326.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2003}, {"title": "Maximizing non-monotone submodular functions", "author": ["U. Feige", "V.S. Mirrokni"], "venue": "In Proceedings of 48th Annual IEEE Symposium on Foundations of Computer Science (FOCS, 2007, p. 2007.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2007}, {"title": "Optimal approximation for the submodular welfare problem in the value oracle model", "author": ["J. Vondrak"], "venue": "Proceedings of the 40th Annual ACM Symposium on Theory of Computing, ser. STOC \u201908. New York, NY, USA: ACM, 2008, pp. 67\u201374. [Online]. Available: http://doi.acm.org/10.1145/1374376.1374389", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2008}, {"title": "Best algorithms for approximating the maximum of a submodular set function", "author": ["G.L. Nemhauser", "L.A. Wolsey"], "venue": "Mathematics of Operations Research, vol. 3, no. 3, pp. 177\u2013188, 1978. [Online]. Available: http://pubsonline.informs.org/doi/abs/10.1287/moor.3.3.177", "citeRegEx": "6", "shortCiteRegEx": null, "year": 1978}, {"title": "Learning with submodular functions: A convex optimization perspective", "author": ["F. Bach"], "venue": "To appear in Foundations and Trends in Machine Learning, 2013.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2013}, {"title": "Adaptive submodularity: A new approach to active learning and stochastic optimization", "author": ["D. Golovin", "A. Krause"], "venue": "COLT, 2010, pp. 333\u2013345.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2010}, {"title": "Near-optimal nonmyopic value of information in graphical models", "author": ["A. Krause", "C.E. Guestrin"], "venue": "arXiv preprint arXiv:1207.1394, 2012.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2012}, {"title": "What energy functions can be minimized via graph cuts", "author": ["V. Kolmogorov", "R. Zabih"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 26, pp. 65\u201381, 2004. 17", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2004}, {"title": "Efficiently solving dynamic markov random fields using graph cuts", "author": ["P. Kohli", "P.H.S. Torr"], "venue": "Computer Vision, 2005. ICCV 2005. Tenth IEEE International Conference on, vol. 2, 2005, pp. 922\u2013929 Vol. 2.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2005}, {"title": "Foundations of Machine Learning", "author": ["M. Mohri", "A. Rostamizadeh", "A. Talwalkar"], "venue": null, "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2012}, {"title": "The Nature of Statistical Learning Theory", "author": ["V.N. Vapnik"], "venue": null, "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2000}, {"title": "An overview of statistical learning theory", "author": ["V. Vapnik"], "venue": "Neural Networks, IEEE Transactions on, vol. 10, no. 5, pp. 988\u2013999, 1999.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 1999}, {"title": "Two faces of active learning", "author": ["S. Dasgupta"], "venue": "Theor. Comput. Sci., vol. 412, no. 19, pp. 1767\u20131781, Apr. 2011. [Online]. Available: http://dx.doi.org/10.1016/j.tcs.2010.12.054", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2011}, {"title": "Analysis of a greedy active learning strategy", "author": ["\u2014\u2014"], "venue": "NIPS, 2004. [Online]. Available: http: //dblp.uni-trier.de/db/conf/nips/nips2004.html#Dasgupta04", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2004}, {"title": "Distributed submodular maximization: Identifying representative elements in massive data", "author": ["B. Mirzasoleiman", "A. Karbasi", "R. Sarkar", "A. Krause"], "venue": "To appear in Neural Information Processing Systems (NIPS), 2013.", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2013}, {"title": "Near-optimal batch mode active learning and adaptive submodular optimization", "author": ["Y. Chen", "A. Krause"], "venue": "International Conference on Machine Learning (ICML), 2013.", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2013}, {"title": "Adaptive submodularity: Theory and applications in active learning and stochastic optimization", "author": ["D. Golovin", "A. Krause"], "venue": "J. Artif. Intell. Res. (JAIR), vol. 42, pp. 427\u2013486, 2011.", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2011}, {"title": "Near-optimal bayesian active learning with noisy observations", "author": ["D. Golovin", "A. Krause", "D. Ray"], "venue": "Proc. Neural Information Processing Systems (NIPS), December 2010.", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2010}, {"title": "Active learning for multi-criterion optimization", "author": ["M. Zuluaga", "A. Krause", "G. Sergent", "M. P\u00fcschel"], "venue": "International Conference on Machine Learning (ICML), 2013.", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2013}, {"title": "Active classification: Theory and application to underwater inspection", "author": ["G.A. Hollinger", "U. Mitra", "G.S. Sukhatme"], "venue": "CoRR, vol. abs/1106.5829, 2011. [Online]. Available: http://dblp.uni-trier.de/db/journals/corr/ corr1106.html", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2011}, {"title": "Agnostic Active Learning Without Constraints", "author": ["A. Beygelzimer", "J. Langford", "D. Hsu", "Z. Tong"], "venue": "Advances in Neural Information Processing Systems 23, 2011, pp. 199\u2013207.", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2011}, {"title": "Constraint Processing, ser", "author": ["R. Dechter"], "venue": "The Morgan Kaufmann Series in Artificial Intelligence. Elsevier Science,", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2003}, {"title": "CP-nets: A tool for representing and reasoning with conditional ceteris paribus preference statements", "author": ["C. Boutilier", "R.I. Brafman", "C. Domshlak", "H.H. Hoos", "D. Poole"], "venue": "Journal of Artificial Intelligence Research, vol. 21, pp. 135\u2013191, 2004.", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2004}, {"title": "Planning with goal utility dependencies", "author": ["M.B. Do", "J. Benton", "M. Van Den Briel", "S. Kambhampati"], "venue": "Proceedings of the 20th International Joint Conference on Artificial Intelligence, 2007, pp. 1872\u20131878. [Online]. Available: http://dl.acm.org/citation.cfm?id=1625275.1625578", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2007}, {"title": "Algorithm for optimal winner determination in combinatorial auctions", "author": ["T. Sandholm"], "venue": "Artificial Intelligence, vol. 135, no. 1-2, pp. 1\u201354, Feb. 2002. [Online]. Available: http://dx.doi.org/10.1016/S0004-3702(01)00159-X", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2002}, {"title": "Mendelian error detection in complex pedigrees using weighted constraint satisfaction techniques", "author": ["M. Sanchez", "S. de Givry", "T. Schiex"], "venue": "Proceedings of the 2007 conference on Artificial Intelligence Research and Development. Amsterdam, The Netherlands, The Netherlands: IOS Press, 2007, pp. 29\u201337. [Online]. Available: http://dl.acm.org/citation.cfm?id=1566803.1566811", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2007}, {"title": "Primal-dual algorithm for convex Markov random fields", "author": ["V. Kolmogorov"], "venue": "Microsoft Research, Tech. Rep. MSR-TR-2005-117, Sept. 2005. [Online]. Available: ftp://ftp.research.microsoft.com/pub/tr/TR-2005-117.pdf", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2005}, {"title": "Classes of submodular constraints expressible by graph cuts", "author": ["S. Zivny", "P. Jeavons"], "venue": "Proceedings of the International Conference on Principles and Practice of Constraint Programming, 2008, pp. 112\u2013127.", "citeRegEx": "31", "shortCiteRegEx": null, "year": 2008}, {"title": "A framework for hybrid tractability results in boolean weighted constraint satisfaction problems", "author": ["T.K.S. Kumar"], "venue": "Proceedings of the 14th International Conference on Principles and Practice of Constraint Programming, 2008, pp. 282\u2013297. [Online]. Available: http://dx.doi.org/10.1007/978-3-540-85958-1 19", "citeRegEx": "32", "shortCiteRegEx": null, "year": 2008}, {"title": "Lifting techniques for weighted constraint satisfaction problems", "author": ["\u2014\u2014"], "venue": "Proceedings of the International Symposium on Artificial Intelligence and Mathematics, 2008.", "citeRegEx": "33", "shortCiteRegEx": null, "year": 2008}, {"title": "Submodular constraints and planar constraint networks: New results", "author": ["T.K.S. Kumar", "L. Cohen", "S. Koenig"], "venue": "Symposium on Abstraction, Reformulation and Approximation, 2013. 18", "citeRegEx": "34", "shortCiteRegEx": null, "year": 2013}, {"title": "Inferring networks of diffusion and influence", "author": ["M. Gomez Rodriguez", "J. Leskovec", "A. Krause"], "venue": "Proceedings of the 16th ACM SIGKDD international conference on Knowledge discovery and data mining, ser. KDD \u201910, 2010, pp. 1019\u20131028.", "citeRegEx": "35", "shortCiteRegEx": null, "year": 2010}, {"title": "Maximizing the spread of influence through a social network", "author": ["D. Kempe", "J. Kleinberg", "E. Tardos"], "venue": "Proceedings of the ninth ACM SIGKDD international conference on Knowledge discovery and data mining, ser. KDD \u201903, 2003, pp. 137\u2013146.", "citeRegEx": "36", "shortCiteRegEx": null, "year": 2003}, {"title": "Submodular inference of diffusion networks from multiple trees", "author": ["M. Gomez-Rodriguez", "B. Sch\u00f6lkopf"], "venue": "CoRR, vol. abs/1205.1671, 2012.", "citeRegEx": "37", "shortCiteRegEx": null, "year": 2012}, {"title": "Competitive influence maximization in social networks", "author": ["S. Bharathi", "D. Kempe", "M. Salek"], "venue": "Proceedings of the 3rd international conference on Internet and network economics, ser. WINE\u201907, 2007, pp. 306\u2013311.", "citeRegEx": "38", "shortCiteRegEx": null, "year": 2007}, {"title": "Threshold models for competitive influence in social networks", "author": ["A. Borodin", "Y. Filmus", "J. Oren"], "venue": "Internet and Network Economics, ser. WINE\u201910, 2010, pp. 539\u2013550.", "citeRegEx": "39", "shortCiteRegEx": null, "year": 2010}, {"title": "Influence maximization in social networks when negative opinions may emerge and propagate", "author": ["W. Chen", "A. Collins", "R. Cummings", "T. Ke", "Z. Liu", "D. Rincon", "X. Sun", "Y. Wang", "W. Wei", "Y. Yuan"], "venue": "Proceedings of the 11th SIAM International Conference on Data Mining, ser. SDM\u201911, 2011, pp. 379\u2013390.", "citeRegEx": "40", "shortCiteRegEx": null, "year": 2011}, {"title": "Influence blocking maximization in social networks under the competitive linear threshold model", "author": ["X. He", "G. Song", "W. Chen", "Q. Jiang"], "venue": "Proceedings of the 12th SIAM International Conference on Data Mining, ser. SDM\u201912, 2012.", "citeRegEx": "41", "shortCiteRegEx": null, "year": 2012}, {"title": "Limiting the spread of misinformation in social networks", "author": ["C. Budak", "D. Agrawal", "A. El Abbadi"], "venue": "Proceedings of the 20th international conference on World wide web, ser. WWW \u201911, 2011, pp. 665\u2013674.", "citeRegEx": "42", "shortCiteRegEx": null, "year": 2011}, {"title": "Scalable influence maximization for prevalent viral marketing in large-scale social networks", "author": ["W. Chen", "C. Wang", "Y. Wang"], "venue": "Proceedings of the 16th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, ser. KDD \u201910, 2010, pp. 1029\u20131038.", "citeRegEx": "43", "shortCiteRegEx": null, "year": 2010}, {"title": "Cost-effective outbreak detection in networks", "author": ["J. Leskovec", "A. Krause", "C. Guestrin", "C. Faloutsos", "J. VanBriesen", "N. Glance"], "venue": "Proceedings of the 13th ACM SIGKDD international conference on Knowledge discovery and data mining, ser. KDD \u201907, 2007, pp. 420\u2013429.", "citeRegEx": "44", "shortCiteRegEx": null, "year": 2007}, {"title": "Celf++: optimizing the greedy algorithm for influence maximization in social networks", "author": ["A. Goyal", "W. Lu", "L.V. Lakshmanan"], "venue": "Proceedings of the 20th international conference companion on World wide web, ser. WWW \u201911, 2011, pp. 47\u201348.", "citeRegEx": "45", "shortCiteRegEx": null, "year": 2011}, {"title": "Scalable influence maximization in social networks under the linear threshold model", "author": ["W. Chen", "Y. Yuan", "L. Zhang"], "venue": "ICDM, 2010, pp. 88\u201397.", "citeRegEx": "46", "shortCiteRegEx": null, "year": 2010}, {"title": "Scalable influence maximization for prevalent viral marketing in large-scale social networks", "author": ["W. Chen", "C. Wang", "Y. Wang"], "venue": "Proceedings of the 16th ACM SIGKDD international conference on Knowledge discovery and data mining, ser. KDD \u201910, 2010, pp. 1029\u20131038.", "citeRegEx": "47", "shortCiteRegEx": null, "year": 2010}, {"title": "On the submodularity of influence in social networks", "author": ["E. Mossel", "S. Roch"], "venue": "Proceedings of the Thirtyninth Annual ACM Symposium on Theory of Computing, ser. STOC \u201907, 2007, pp. 128\u2013134.", "citeRegEx": "48", "shortCiteRegEx": null, "year": 2007}, {"title": "Influence maximization in social networks when negative opinions may emerge and propagate.", "author": ["W. Chen", "A. Collins", "R. Cummings", "T. Ke", "Z. Liu", "D. Rincn", "X. Sun", "Y. Wang", "W. Wei", "Y. Yuan"], "venue": "in SDM,", "citeRegEx": "49", "shortCiteRegEx": "49", "year": 2011}, {"title": "Influence blocking maximization in social networks under the competitive linear threshold model", "author": ["X. He", "G. Song", "W. Chen", "Q. Jiang"], "venue": "Proceedings of the 12th SIAM International Conference on Data Mining, 2012.", "citeRegEx": "50", "shortCiteRegEx": null, "year": 2012}, {"title": "On the convexity of latent social network inference", "author": ["S.A. Myers", "J. Leskovec"], "venue": "NIPS, 2010, pp. 1741\u2013 1749.", "citeRegEx": "52", "shortCiteRegEx": null, "year": 2010}, {"title": "Kronecker graphs: An approach to modeling networks", "author": ["J. Leskovec", "D. Chakrabarti", "J. Kleinberg", "C. Faloutsos", "Z. Ghahramani"], "venue": "J. Mach. Learn. Res., vol. 11, pp. 985\u20131042, Mar. 2010.", "citeRegEx": "53", "shortCiteRegEx": null, "year": 2010}, {"title": "The network completion problem: Inferring missing nodes and edges in networks", "author": ["M. Kim", "J. Leskovec"], "venue": "SDM, 2011.", "citeRegEx": "54", "shortCiteRegEx": null, "year": 2011}, {"title": "A unified continuous greedy algorithm for submodular maximization.", "author": ["M. Feldman", "J. Naor", "R. Schwartz"], "venue": "in FOCS,", "citeRegEx": "55", "shortCiteRegEx": "55", "year": 2011}, {"title": "Active sequential hypothesis testing", "author": ["M. Naghshvar", "T. Javidi"], "venue": "IEEE Transactions on Information Theory (to appear), March 2012.", "citeRegEx": "56", "shortCiteRegEx": null, "year": 2012}, {"title": "Submodular function minimization", "author": ["A. Toshev"], "venue": "WPE II Document, University of Pennsylvania, 2010.", "citeRegEx": "57", "shortCiteRegEx": null, "year": 2010}, {"title": "Approximation algorithms for NP-complete problems on planar graphs", "author": ["B.S. Baker"], "venue": "Journal of the ACM, vol. 41, no. 1, pp. 153\u2013180, Jan. 1994. [Online]. Available: http://doi.acm.org/10.1145/174644.174650", "citeRegEx": "58", "shortCiteRegEx": null, "year": 1994}, {"title": "Electrical flows, Laplacian systems, and faster approximation of maximum flow in undirected graphs", "author": ["P. Christiano", "J.A. Kelner", "A. Madry", "D.A. Spielman", "S.-H. Teng"], "venue": "Proceedings of the 43rd Annual ACM Symposium on Theory of Computing. ACM, 2011, pp. 273\u2013282. [Online]. Available: http://doi.acm.org/10.1145/1993636.1993674", "citeRegEx": "59", "shortCiteRegEx": null, "year": 2011}, {"title": "An o(n log n) algorithm for maximum st-flow in a directed planar graph", "author": ["G. Borradaile", "P. Klein"], "venue": "Journal of the ACM, vol. 56, no. 2, pp. 9:1\u20139:30, Apr. 2009. [Online]. Available: http: //doi.acm.org/10.1145/1502793.1502798", "citeRegEx": "60", "shortCiteRegEx": null, "year": 2009}, {"title": "Max flows in O(nm) time, or better", "author": ["J.B. Orlin"], "venue": "ACM Symposium on the Theory of Computing, 2013, pp. 765\u2013774.", "citeRegEx": "62", "shortCiteRegEx": null, "year": 2013}, {"title": "Tutorial on submodularity in machine learning and computer vision", "author": ["S. Jegelka", "A. Krause"], "venue": "no. http://submodularity.org/submodularity-2012.pdf, 2012. [Online]. Available: http://submodularity.org/ submodularity-2012.pdf", "citeRegEx": "63", "shortCiteRegEx": null, "year": 2012}, {"title": "Improved algorithms for bipartite network flow", "author": ["O.J.B.R.K. Ahuja", "S. Clifford", "R.E. Tarjan"], "venue": "SIAM Journal on Computing, vol. 23, no. 5, pp. 906\u2013933, Oct. 1994. [Online]. Available: http://dx.doi.org/10.1137/S0097539791199334", "citeRegEx": "64", "shortCiteRegEx": null, "year": 1994}, {"title": "Near-optimal sensor placements in gaussian processes: Theory, efficient algorithms and empirical studies", "author": ["A. Krause", "A. Singh", "C. Guestrin"], "venue": "Journal of Machine Learning Research, vol. 9, pp. 235\u2013284, February 2008. 20", "citeRegEx": "65", "shortCiteRegEx": null, "year": 2008}], "referenceMentions": [{"referenceID": 0, "context": "4 (Lov\u00e1sz Extension) A function f is submodular function, iff its Lov\u00e1sz Extension f\u0302 is convex, where f\u0302(c) = max{cx | x(U) \u2264 f(U) \u2200 U \u2286 V and c \u2208 [0, 1]}", "startOffset": 148, "endOffset": 154}, {"referenceID": 0, "context": "A non combinatorial approach proposed by Fujishige [1] is based on the norm characterization of the minima of f shown in Lemma 2.", "startOffset": 51, "endOffset": 54}, {"referenceID": 1, "context": "Fujishige uses Wolfe\u2019s algorithm [2] which was developed to minimize the L2 norm of a vector in a convex hull of a finite set of points P \u2208 R.", "startOffset": 33, "endOffset": 36}, {"referenceID": 2, "context": "This issue is circumvented by using Edmonds Greedy Algorithm [3].", "startOffset": 61, "endOffset": 64}, {"referenceID": 3, "context": "Feige and Mirrokni [4] showed that maximizing for non-negative submodular functions a random subset achieves at least 1/4th the optimal value and local search techniques achieve at least a 1/2.", "startOffset": 19, "endOffset": 22}, {"referenceID": 4, "context": "The solution to the arbritary matroid constraint was shown more recently by Vondrak et al [5].", "startOffset": 90, "endOffset": 93}, {"referenceID": 5, "context": "The initial result of an (1\u2212 1/e) approximation was shown by Nemhauser [6] in the 70s, but the result was only applicable to uniform matroid (cardinality) constraints.", "startOffset": 71, "endOffset": 74}, {"referenceID": 6, "context": "See [7] for more details.", "startOffset": 4, "endOffset": 7}, {"referenceID": 7, "context": "It has been shown by Golovin and Krause [8] that if a problem is adaptively submodular, then an adaptive greedy algorithm is guaranteed to obtain near optimal solutions.", "startOffset": 40, "endOffset": 43}, {"referenceID": 8, "context": "1 If xi\u2019s are all conditionally independent given y, then the function is submodular [9].", "startOffset": 85, "endOffset": 88}, {"referenceID": 9, "context": "Such functions are called regular functions [11].", "startOffset": 44, "endOffset": 48}, {"referenceID": 10, "context": "Another widely used application of this approach is to find the Maximum a posteriori estimate of a Markov Random Field [12].", "startOffset": 119, "endOffset": 123}, {"referenceID": 11, "context": "1 Supervised learning theory In classic supervised machine learning, the learning algorithm (or learner) is given the task of finding a response function f : X 7\u2192 Y that predicts as accurately as possible the output response Y \u2208 Y for a given input observation X \u2208 X [13].", "startOffset": 267, "endOffset": 271}, {"referenceID": 12, "context": "In the empirical risk minimization (ERM) paradigm, the learner assumes that the sample S is sufficiently representative of D such that choosing \u0125 = arg maxh\u2208H \u000f\u0302S will yield a hypothesis \u0125 that will also have a relatively low risk D(\u0125) [14].", "startOffset": 236, "endOffset": 240}, {"referenceID": 13, "context": "A well known theoretical result for classification that comes from Vapnik tells us if we want to learn a \u201cgood\u201d classifier from a hypothesis class H, then we need roughly |S| = \u00d5 ( d/\u03b5 log(1/\u03b4) ) points in our training sample [15].", "startOffset": 226, "endOffset": 230}, {"referenceID": 14, "context": "When err(h) > 0, the problem is not realizable [16].", "startOffset": 47, "endOffset": 51}, {"referenceID": 14, "context": "Rather it has access to an unlabeled data sample U = {(X, ?)}, as well as an oracle that the learner can query for the response (or label) of an observation, Y = or(X) [16].", "startOffset": 168, "endOffset": 172}, {"referenceID": 15, "context": "both of these questions is, in fact, yes [17].", "startOffset": 41, "endOffset": 45}, {"referenceID": 15, "context": "[17] shows that in the worst case, this strategy may have to query every single label; indeed, for certain pathological cases, even the optimal query strategy will need to query every label.", "startOffset": 0, "endOffset": 4}, {"referenceID": 15, "context": "5, which rephrases Claim 4 and Theorem 3 from [17]:", "startOffset": 46, "endOffset": 50}, {"referenceID": 15, "context": "5 (Dasgupta [17]) Suppose the optimal query policy requiresM labels in expectation for target hypotheses chosen uniformly from hypothesis class H of (VC) dimension d \u2265 e \u2248 16.", "startOffset": 12, "endOffset": 16}, {"referenceID": 15, "context": "As [17] points out, the lower bound is a bit depressing, but we derive some comfort from the fact that the upper bound matches the lower bound within a multiplicative factor.", "startOffset": 3, "endOffset": 7}, {"referenceID": 7, "context": "In [8], the authors show that the hypothesis space reduction problem is adaptive submodular, specifically an example of an adaptive stochastic coverage problem.", "startOffset": 3, "endOffset": 6}, {"referenceID": 0, "context": "Then we can define a function that takes as input an element subset V \u2032 and a realization function \u03a6\u2032 and maps it to a real number in the interval [0, 1]: f(V \u2032,\u03a6\u2032) = f\u0302(H = {h : h(x) = \u03a6\u2032(x) for all x \u2208 V \u2032}) = 1\u2212 \u2211", "startOffset": 147, "endOffset": 153}, {"referenceID": 7, "context": "6, adapted from [8]:", "startOffset": 16, "endOffset": 19}, {"referenceID": 7, "context": "6 (Golovin and Krause [8]) The hypothesis space reduction problem is adaptive submodular and adaptive monotone.", "startOffset": 22, "endOffset": 25}, {"referenceID": 7, "context": "7, adapted from [8]:", "startOffset": 16, "endOffset": 19}, {"referenceID": 7, "context": "7 (Golovin and Krause [8]) Suppose the optimal query policy requires M labels in expectation for target hypotheses chosen using distribution \u03c0 from hypothesis class H.", "startOffset": 22, "endOffset": 25}, {"referenceID": 16, "context": "[18] describe a framework for performing distributed submodular maximization in a shared-nothing (MapReduce) storage setting and using it to choose a representative subsample of a massive data set for learning (similar to our selective sampling on a budget problem).", "startOffset": 0, "endOffset": 4}, {"referenceID": 17, "context": "[19] describe a greedy batch-mode active learning algorithm that queries labels in batches of size k > 1 and show that this approach is competitive not only with optimal batch-more active learning but also with more traditional greedy active learning.", "startOffset": 0, "endOffset": 4}, {"referenceID": 18, "context": "There are a variety of other papers pushing the boundary in this area [20] [21] [22] [23].", "startOffset": 70, "endOffset": 74}, {"referenceID": 19, "context": "There are a variety of other papers pushing the boundary in this area [20] [21] [22] [23].", "startOffset": 75, "endOffset": 79}, {"referenceID": 20, "context": "There are a variety of other papers pushing the boundary in this area [20] [21] [22] [23].", "startOffset": 80, "endOffset": 84}, {"referenceID": 21, "context": "There are a variety of other papers pushing the boundary in this area [20] [21] [22] [23].", "startOffset": 85, "endOffset": 89}, {"referenceID": 14, "context": "Aggressive active learning in the non-realizable case is a wide open problem, at least as of [16].", "startOffset": 93, "endOffset": 97}, {"referenceID": 22, "context": "We do have a variety of mellow active learners, which seek any informative label query, that are label efficient and statistically consistent [24] [16].", "startOffset": 142, "endOffset": 146}, {"referenceID": 14, "context": "We do have a variety of mellow active learners, which seek any informative label query, that are label efficient and statistically consistent [24] [16].", "startOffset": 147, "endOffset": 151}, {"referenceID": 23, "context": "Various extensions to the basic framework of Constraint Satisfaction Problems (CSPs) [25] have been introduced to incorporate and reason about such \u201csoft\u201d constraints.", "startOffset": 85, "endOffset": 89}, {"referenceID": 24, "context": "Note that this class can be used to model important combinatorial problems such as representing and reasoning about user preferences [26], over-subscription planning with goal preferences [27], combinatorial auctions [28], and bioinformatics [29], energy minimization problems in probabilistic settings, computer vision, Markov Random Fields [30], etc.", "startOffset": 133, "endOffset": 137}, {"referenceID": 25, "context": "Note that this class can be used to model important combinatorial problems such as representing and reasoning about user preferences [26], over-subscription planning with goal preferences [27], combinatorial auctions [28], and bioinformatics [29], energy minimization problems in probabilistic settings, computer vision, Markov Random Fields [30], etc.", "startOffset": 188, "endOffset": 192}, {"referenceID": 26, "context": "Note that this class can be used to model important combinatorial problems such as representing and reasoning about user preferences [26], over-subscription planning with goal preferences [27], combinatorial auctions [28], and bioinformatics [29], energy minimization problems in probabilistic settings, computer vision, Markov Random Fields [30], etc.", "startOffset": 217, "endOffset": 221}, {"referenceID": 27, "context": "Note that this class can be used to model important combinatorial problems such as representing and reasoning about user preferences [26], over-subscription planning with goal preferences [27], combinatorial auctions [28], and bioinformatics [29], energy minimization problems in probabilistic settings, computer vision, Markov Random Fields [30], etc.", "startOffset": 242, "endOffset": 246}, {"referenceID": 28, "context": "Note that this class can be used to model important combinatorial problems such as representing and reasoning about user preferences [26], over-subscription planning with goal preferences [27], combinatorial auctions [28], and bioinformatics [29], energy minimization problems in probabilistic settings, computer vision, Markov Random Fields [30], etc.", "startOffset": 342, "endOffset": 346}, {"referenceID": 23, "context": "Boolean WCSPs are representationally as powerful as WCSPs; and it is well known that optimally solving Boolean WCSPs is NP-hard in general [25].", "startOffset": 139, "endOffset": 143}, {"referenceID": 29, "context": "Boolean WCSPs with submodular constraints are known to be tractable [31].", "startOffset": 68, "endOffset": 72}, {"referenceID": 29, "context": "Specific classes of submodular constraints have been shown to be related to graph cuts, and are therefore solvable more efficiently [31].", "startOffset": 132, "endOffset": 136}, {"referenceID": 30, "context": "They provide a unifying framework for exploiting both the graphical structure of the variable interactions as well as the numerical structure of the weighted constraints [32].", "startOffset": 170, "endOffset": 174}, {"referenceID": 31, "context": "This idea was first discussed in [33].", "startOffset": 33, "endOffset": 37}, {"referenceID": 30, "context": "Any given weighted constraint on Boolean variables can be represented graphically using a tripartite graph, which can be constructed in polynomial time [32].", "startOffset": 152, "endOffset": 156}, {"referenceID": 29, "context": "Finally, Boolean weighted constraints can be represented as multivariate polynomials on the variables participating in that constraint [31, 32].", "startOffset": 135, "endOffset": 143}, {"referenceID": 30, "context": "Finally, Boolean weighted constraints can be represented as multivariate polynomials on the variables participating in that constraint [31, 32].", "startOffset": 135, "endOffset": 143}, {"referenceID": 30, "context": "One way to build the CCG of a given weighted constraint is: (a) build the graphical representations for each of the individual terms in the multivariate polynomial; and (b) \u201cmerge\u201d these graphical representations [32].", "startOffset": 213, "endOffset": 217}, {"referenceID": 32, "context": "The focus of [34] is on bounded arity submodular constraints (that is, submodular constraints with arity at most K, for some constant K) and providing asymptotically improved algorithms for solving them.", "startOffset": 13, "endOffset": 17}, {"referenceID": 29, "context": "This significantly improves on the O((N + M)) time complexity of the algorithm provided by [31].", "startOffset": 91, "endOffset": 95}, {"referenceID": 33, "context": "Modeling, utilizing, and understanding social influence has become \u201chot topic\u201d in computer science, machine learning, and computational social science [35, 36, 37, 38, 39, 40, 41, 42].", "startOffset": 151, "endOffset": 183}, {"referenceID": 34, "context": "Modeling, utilizing, and understanding social influence has become \u201chot topic\u201d in computer science, machine learning, and computational social science [35, 36, 37, 38, 39, 40, 41, 42].", "startOffset": 151, "endOffset": 183}, {"referenceID": 35, "context": "Modeling, utilizing, and understanding social influence has become \u201chot topic\u201d in computer science, machine learning, and computational social science [35, 36, 37, 38, 39, 40, 41, 42].", "startOffset": 151, "endOffset": 183}, {"referenceID": 36, "context": "Modeling, utilizing, and understanding social influence has become \u201chot topic\u201d in computer science, machine learning, and computational social science [35, 36, 37, 38, 39, 40, 41, 42].", "startOffset": 151, "endOffset": 183}, {"referenceID": 37, "context": "Modeling, utilizing, and understanding social influence has become \u201chot topic\u201d in computer science, machine learning, and computational social science [35, 36, 37, 38, 39, 40, 41, 42].", "startOffset": 151, "endOffset": 183}, {"referenceID": 38, "context": "Modeling, utilizing, and understanding social influence has become \u201chot topic\u201d in computer science, machine learning, and computational social science [35, 36, 37, 38, 39, 40, 41, 42].", "startOffset": 151, "endOffset": 183}, {"referenceID": 39, "context": "Modeling, utilizing, and understanding social influence has become \u201chot topic\u201d in computer science, machine learning, and computational social science [35, 36, 37, 38, 39, 40, 41, 42].", "startOffset": 151, "endOffset": 183}, {"referenceID": 40, "context": "Modeling, utilizing, and understanding social influence has become \u201chot topic\u201d in computer science, machine learning, and computational social science [35, 36, 37, 38, 39, 40, 41, 42].", "startOffset": 151, "endOffset": 183}, {"referenceID": 34, "context": "In this section, we mainly focus on using submodular function maximization techniques to solve two problems related to social influence, namely influence maximization [36] and network inference [35].", "startOffset": 167, "endOffset": 171}, {"referenceID": 33, "context": "In this section, we mainly focus on using submodular function maximization techniques to solve two problems related to social influence, namely influence maximization [36] and network inference [35].", "startOffset": 194, "endOffset": 198}, {"referenceID": 34, "context": "Among the many diffusion models, the Independent Cascade (IC) model and Linear Threshold (LT) are used widely in the study of influence maximization [36].", "startOffset": 149, "endOffset": 153}, {"referenceID": 34, "context": "It has been shown that the influence maximization problem under both IC model and LT model is NP-hard [36].", "startOffset": 102, "endOffset": 106}, {"referenceID": 34, "context": "[36]) The objective function of influence maximization problem under both IC and LT model is non-negative, monotone and submodular.", "startOffset": 0, "endOffset": 4}, {"referenceID": 41, "context": "Many papers have been published on how to improve the efficiency of the algorithm [43, 44, 45, 46, 47], such as by lazy evaluation [44, 45], or by approximate evaluation of the marginal gain [43, 46, 47] .", "startOffset": 82, "endOffset": 102}, {"referenceID": 42, "context": "Many papers have been published on how to improve the efficiency of the algorithm [43, 44, 45, 46, 47], such as by lazy evaluation [44, 45], or by approximate evaluation of the marginal gain [43, 46, 47] .", "startOffset": 82, "endOffset": 102}, {"referenceID": 43, "context": "Many papers have been published on how to improve the efficiency of the algorithm [43, 44, 45, 46, 47], such as by lazy evaluation [44, 45], or by approximate evaluation of the marginal gain [43, 46, 47] .", "startOffset": 82, "endOffset": 102}, {"referenceID": 44, "context": "Many papers have been published on how to improve the efficiency of the algorithm [43, 44, 45, 46, 47], such as by lazy evaluation [44, 45], or by approximate evaluation of the marginal gain [43, 46, 47] .", "startOffset": 82, "endOffset": 102}, {"referenceID": 45, "context": "Many papers have been published on how to improve the efficiency of the algorithm [43, 44, 45, 46, 47], such as by lazy evaluation [44, 45], or by approximate evaluation of the marginal gain [43, 46, 47] .", "startOffset": 82, "endOffset": 102}, {"referenceID": 42, "context": "Many papers have been published on how to improve the efficiency of the algorithm [43, 44, 45, 46, 47], such as by lazy evaluation [44, 45], or by approximate evaluation of the marginal gain [43, 46, 47] .", "startOffset": 131, "endOffset": 139}, {"referenceID": 43, "context": "Many papers have been published on how to improve the efficiency of the algorithm [43, 44, 45, 46, 47], such as by lazy evaluation [44, 45], or by approximate evaluation of the marginal gain [43, 46, 47] .", "startOffset": 131, "endOffset": 139}, {"referenceID": 41, "context": "Many papers have been published on how to improve the efficiency of the algorithm [43, 44, 45, 46, 47], such as by lazy evaluation [44, 45], or by approximate evaluation of the marginal gain [43, 46, 47] .", "startOffset": 191, "endOffset": 203}, {"referenceID": 44, "context": "Many papers have been published on how to improve the efficiency of the algorithm [43, 44, 45, 46, 47], such as by lazy evaluation [44, 45], or by approximate evaluation of the marginal gain [43, 46, 47] .", "startOffset": 191, "endOffset": 203}, {"referenceID": 45, "context": "Many papers have been published on how to improve the efficiency of the algorithm [43, 44, 45, 46, 47], such as by lazy evaluation [44, 45], or by approximate evaluation of the marginal gain [43, 46, 47] .", "startOffset": 191, "endOffset": 203}, {"referenceID": 46, "context": "A more general result on Generalized Linear Threshold models has been proved generalizing the results for the IC and LT models in [48].", "startOffset": 130, "endOffset": 134}, {"referenceID": 36, "context": "The influence maximization problem naturally extends to maximizing one\u2019s own influence [38, 39, 40] or minimizing the influence of the competitors [41, 42] given the choices of the initial seeds of the competitors.", "startOffset": 87, "endOffset": 99}, {"referenceID": 37, "context": "The influence maximization problem naturally extends to maximizing one\u2019s own influence [38, 39, 40] or minimizing the influence of the competitors [41, 42] given the choices of the initial seeds of the competitors.", "startOffset": 87, "endOffset": 99}, {"referenceID": 38, "context": "The influence maximization problem naturally extends to maximizing one\u2019s own influence [38, 39, 40] or minimizing the influence of the competitors [41, 42] given the choices of the initial seeds of the competitors.", "startOffset": 87, "endOffset": 99}, {"referenceID": 39, "context": "The influence maximization problem naturally extends to maximizing one\u2019s own influence [38, 39, 40] or minimizing the influence of the competitors [41, 42] given the choices of the initial seeds of the competitors.", "startOffset": 147, "endOffset": 155}, {"referenceID": 40, "context": "The influence maximization problem naturally extends to maximizing one\u2019s own influence [38, 39, 40] or minimizing the influence of the competitors [41, 42] given the choices of the initial seeds of the competitors.", "startOffset": 147, "endOffset": 155}, {"referenceID": 47, "context": "For example, on the maximization side, [49] study the influence maximization when a user can dislike the product and propagate bad news about it.", "startOffset": 39, "endOffset": 43}, {"referenceID": 48, "context": "On the minimization side, [50] study the idea of influence blocking maximization, which focuses on selecting seeds to block the propagation of rumors.", "startOffset": 26, "endOffset": 30}, {"referenceID": 34, "context": "The proof technique is similar to that in [36].", "startOffset": 42, "endOffset": 46}, {"referenceID": 33, "context": "Existing approaches to this problem solve a maximum likelihood estimation problem with respect to the network structure under certain diffusion models [35, 37, 51, 52].", "startOffset": 151, "endOffset": 167}, {"referenceID": 35, "context": "Existing approaches to this problem solve a maximum likelihood estimation problem with respect to the network structure under certain diffusion models [35, 37, 51, 52].", "startOffset": 151, "endOffset": 167}, {"referenceID": 49, "context": "Existing approaches to this problem solve a maximum likelihood estimation problem with respect to the network structure under certain diffusion models [35, 37, 51, 52].", "startOffset": 151, "endOffset": 167}, {"referenceID": 33, "context": "Thus, submodular function maximization can be used to solve this problem [35, 37].", "startOffset": 73, "endOffset": 81}, {"referenceID": 35, "context": "Thus, submodular function maximization can be used to solve this problem [35, 37].", "startOffset": 73, "endOffset": 81}, {"referenceID": 33, "context": "The extended IC model is used as the diffusion model in [35, 37].", "startOffset": 56, "endOffset": 64}, {"referenceID": 35, "context": "The extended IC model is used as the diffusion model in [35, 37].", "startOffset": 56, "endOffset": 64}, {"referenceID": 33, "context": "[35] proved that this objective function is monotone and submodular.", "startOffset": 0, "endOffset": 4}, {"referenceID": 35, "context": "This approach was later improved by by the MultiTree algorithm in [37], where the the matrix tree theorem is used to calculated the exact summation over all possible spanning trees, rather than using the maximum spanning tree approximation.", "startOffset": 66, "endOffset": 70}, {"referenceID": 50, "context": "Our current choice is the Kronecker graphs model [53, 54].", "startOffset": 49, "endOffset": 57}, {"referenceID": 51, "context": "Our current choice is the Kronecker graphs model [53, 54].", "startOffset": 49, "endOffset": 57}], "year": 2015, "abstractText": "In many naturally occurring optimization problems one needs to ensure that the definition of the optimization problem lends itself to solutions that are tractable to compute. In cases where exact solutions cannot be computed tractably, it is beneficial to have strong guarantees on the tractable approximate solutions. In order operate under these criterion most optimization problems are cast under the umbrella of convexity or submodularity. In this report we will study design and optimization over a common class of functions called submodular functions.", "creator": "LaTeX with hyperref package"}}}