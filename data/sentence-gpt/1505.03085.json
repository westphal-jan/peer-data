{"id": "1505.03085", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "12-May-2015", "title": "Indonesian Social Media Sentiment Analysis With Sarcasm Detection", "abstract": "Sarcasm is considered one of the most difficult problem in sentiment analysis. In our ob-servation on Indonesian social media, for cer-tain topics, people tend to criticize something using sarcasm. Here, we proposed two additional features to detect sarcasm after a common sentiment analysis is conducted. The features are the negativity information and the number of interjection words. We also employed translated SentiWordNet in the sentiment classification. All the classifications were conducted with machine learning algorithms. The experimental results showed that the additional features are quite effective in the sarcasm detection. This finding was reinforced by the fact that the type of sentiment information found in a person is considered so, in this case, more accurate than they may seem. Also, we observed the tendency for users to react to other words as well as a negative impression. We believe that the more we do, the more likely the more the results will be of sarcasm. Thus, the more we say on sarcasm, the more it will be of a good opinion to express sarcasm in a different language.\n\n\n\n\n\n\n\n", "histories": [["v1", "Tue, 12 May 2015 16:45:52 GMT  (419kb)", "http://arxiv.org/abs/1505.03085v1", "4 pages; 3 figures"]], "COMMENTS": "4 pages; 3 figures", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["edwin lunando", "ayu purwarianti"], "accepted": false, "id": "1505.03085"}, "pdf": {"name": "1505.03085.pdf", "metadata": {"source": "CRF", "title": "Indonesian Social Media Sentiment Analysis with Sarcasm Detection", "authors": ["Edwin Lunando", "Ayu Purwarianti"], "emails": ["edwinlunando@gmail.com", "ayu@stei.itb.ac.id"], "sections": [{"heading": null, "text": "in sentiment analysis. In our ob-servation on Indonesian social media, for cer-tain topics, people tend to criticize something using sarcasm. Here, we proposed two additional features to detect sarcasm after a common sentiment analysis is conducted. The features are the negativity information and the number of interjection words. We also employed translated SentiWordNet in the sentiment classification. All the classifications were conducted with machine learning algorithms. The experimental results showed that the additional features are quite effective in the sarcasm detection.\nKeywords\u2014 Sentimen analysis, sarcasm, classification, SentiWordNet\nI. INTRODUCTION\nRecently, the topic of sentiment analysis, automatic classification of the opinion or sentiment conveyed by a text towards a subject, is highly researched. There are a lot of researches in this area which improves the technique in building a sentiment analysis system. Meanwhile, in the bussiness application industry, sentiment analysis application has been used comprehensively to give more information about the user insight about one topic to help them while making decision. Despite the high usage of the sentiment analysis application, there are still rooms for improvements. One of the problems that still become a challenge in sentiment analysis is sarcasm.\nSarcasm is using irony to mock or convey contempt. Sarcasm tranforms the polarity of the text into its opposite while, the text itself looked like the original sentiment. From our observation from 100 microblogging text with simple conversation topics such as food, life, and health, we found that sarcasm text is very rare. There were only 2 from 100 texts that contain sarcasm. But for sensitive topics such as government, brand, or politic, the quantity is greatly rose. There were 18 texts out of 100 texts containing sarcasm.\nSarcasm or irony is an old and well researched phenomenon in the field of linguistic and psychology [1]. Unfortunately, in the field of text mining or more specifically: sentiment analysis, detecting sarcasm automatically is still considered a difficult problem because lexical features do not give enough information to detect sarcasm. One approach to solve this problem was by employing lexical features such as unigram and pragmatic factors such as smileys or emoticons [5]. An\ninteresting analysis from the field of lingustic tells us that lexical factors like presence of adjectives and adverbs, presence of interjections, and use of punctuations play a quite significant role in sarcasm[4]\nIn the basic sentiment analysis, many researches employed machine learning techniques such as Na\u00efve Bayes, Maximum Entropy, and Support Vector machine because these algorithms are tend to outperform the other algorithm in the context of text classification [2][3][7]. Other than that, there is also a lexical resource, SentiWordNet [6], developed as a resource of word with sentiment score. These two techniques are also employed in our sentiment analysis system of Indonesian social media. This is different with other researches on sentiment analysis of Indonesian social media [2][3] which didn\u2019t address the sarcasm detection and didn\u2019t employ sentiment score in the SentiWordNet."}, {"heading": "II. SENTIMENT ANALYSIS WITH SARCASM CLASSIFICATION", "text": "An easy way to comply with the conference paper formatting requirements is to use this document as a template and simply type your text into it.\nSimilar with other sentiment analysis system, our sentiment classification system consists of preprocessing, fitur extraction and classification. The system architecture is as shown in Fig 1."}, {"heading": "A. Preprocessing component", "text": "The preprocessing aims to minimize the vocabulary of terms used in the text message. In Indonesian text message of social media such as twitter or facebook, people tend to use slank words than the formal one such as using numeric to replace alphabet, repeating vocal characters, and using common informal words to replace the formal words [2]. To process such words, we employed the preprocessing such as follow:\n1. Converse numeric character into alphabet, such as \u201cga2l\u201d into \u201cgagal\u201d (fail) 2. Remove vocal repetition, such as \u201ccemunguuuudh\u201d into \u201ccemungudh\u201d 3. Translate informal words into formal words using dictionary, such as \u201ccemungudh\u201d into \u201csemangat\u201d\n(high spirit).\nHere, even though some informal wordsare mispelled from formal words, but some other are completely different lexical than the formal words, therefore the strategy is to build a dictionary and use it to translate informal words into formal words."}, {"heading": "B. Feature extraction component", "text": "In the feature extraction, there are several features taken\nfrom the preprocessed text:\n1. Unigram We analyzed that unigram is more suitable for Indonesian social media text since the grammars used in Indonesian social media texts are various and informal.The unigram taken from the text is only the term that exists in our translated SentiWordNet. We translated English SentiWordNet into Indonesian using an available statistical machine translation (Google). In the translation, one Indonesian word with more than one English translation is given the average score of all the English translations.\nFor text \u201cPasangan Rieke dan Teten cocok untuk memajukan Jawa Barat!\u201d (Rieke and Teten are suitable to bring forward West Java!), the unigram features are taken for \u201ccocok\u201d (suitable) and \u201cmemajukan\u201d (bring forward) which gives SentiWordNet score of 0.5 and 0.375.\nThere are several phenomena in using unigram: a. Negation Negation words (such as \u201cno\u201d or \u201cnot\u201d) tend to change sentiment score of a certain word. For example, in the text \u201cTelevisi jaman sekarang tidak begitu bagus karena mahal\u201d (nowadays televisions are notgood because they are expensive), the sentiment word \u201cbagus\u201d (good) is changed into negative because it is preceeded by a negation word (\u201ctidak\u201d or \u201cnot\u201d). The negation words usually reside before the sentiment word and it can be located two or three words away from the sentiment word. We handled this by multiplying the score of sentiment word closest to the negation word by 1.\nb. Word context One word sentiment may change depends on its word context. For example, the word \u201cmahasiswa\u201d (student) is basically a neutral word but if this word is preceeded by \u201charga\u201d (price) which makes it into \u201charga mahasiswa\u201d (low price) then the word becomes a possitive word. To handle this problem, we used a special list of word such as used in [2].\nc. Affix Word with different affix may have different sentiment. For example \u201cmurah\u201d (low) has a possitive sentiment, while \u201cmurahan\u201d (twopenny) has a negative sentiment. Since not all suffix \u201can\u201d have negative sentiment, we handled this problem by using a list of word such as used in [2].\n2. Negativity This feature represents the percentage of the negative sentiment in the topic of the text message. This feature is intended to catch global information. It gives information about the real sentiment of a certain topic. In order to get this feature, the topic of the text message should be extracted first. In this research, we did the topic extraction manually.\nFor example, in a topic about Indonesian singer, \u201cRhoma Irama wants to be Indonesia\u2019s President\u201d has 80% negative sentiment. Then, the negativity value is 80% or 0.8.\n3. Number of interjection words This feature shows the number of interjection words from the text message. Example of interjection words are \u201caha\u201d, \u201cbah\u201d, \u201cnah\u201d, \u201cwew\u201d, \u201cwow\u201d, \u201cyay\u201d, \u201cuh\u201d, etc. We employ this feature based on our observation that among 100 sarcasm text, there are 20 text with interjection words. Below are the examples of sarcasm text with interjection.\n\u201cWow kk wow. hebat banget rhoma irama berani nyapres\u201d\n\u201cjir, Polri Indonesia makin jago aja. Kapolda sendiri buron gitu.\u201d\n\u201cwah\u2026 cantik sekali cara telkomsel melayani pelanggannya, dikacangin coy.\u201d\n4. Question word This feature is used to classify neutral text. By detecting the question word like \u201cwho\u201d, \u201cwhat\u201d, \u201cwhen\u201d, \u201chow\u201d, \u201cwhere\u201d, and \u201cwhy\u201d it will show that the text has no sentiment value. Almost all text with question words are classified into neutral text. This feature wotks like boolean value. If there are question word at a text, this feature will get \u201ctrue\u201d and vice versa."}, {"heading": "C. Classification component", "text": "In the classification component, there are two classification steps. The first classification is to classify each text into three sentiment classes: possitive, negative and neutral. The second classification is to classify the sarcasm of the possitive text. The flow is as shown in Fig 2.\nAll the classifications are conducted using several machine learning algorithms such as Na\u00efve Bayes, Maximum Entropy, and Support Vector Machine. These algorithms were chosen because they have shown good accuracy in many text classification task [7].\nIn the first classification, the feature is the unigram, while in the second classification, the features are unigram, negativity and the number of interjection words.\nFig 3 describe one of the classification method in sentiment analysis. Rather than directly classify a text into three classes, at first, this method classify a text into opinion and neutral text. After that, the opinion text will be classified into positive or negative class. [3] has tried to use this method, but they haven\u2019t compare those two methods."}, {"heading": "III. EXPERIMENTS", "text": ""}, {"heading": "A. Experimental data", "text": "The data used in the experiment was gathered manually from Twitter. The size of training data is 980 which consist of 502 neutral texts, 250 possitive texts and 228 negative texts. The size of testing data is 300 which consist of 200 neutral texts, 60 possitive texts and 40 negative texts. The training and testing data were collected from various topics such as politic, food, movie, and public figure.\nIn order to get the list of the negativity value, we generated it by using the search API from Twitter. We gathered 100 tweets from each topic and labeled the sentiment manually to get the number of positive and negative tweets."}, {"heading": "B. Experimental result and analysis", "text": "There were three experiments conducted. The first experiment is on the first classification step, and the second experiment is on the second classification step(classification method), and the third classification is on the third classification step(sarcasm classification).\n1) Experiments on Sentiment Score\nAs the first experiment, we evaluated the usage of the translated SentiWordNet in the first classification type which classify each text into 3 classes: possitive, negative and neutral. We compared two things in the experiment: using only the lexical of sentiment word; and using the score of the sentiment word.\nThe experimental results on Table 1 strengthened other research results on the usage of SentiWordNet which showed that using sentiment score in the classification gave higher accuracy than only using the lexical words. The sentiment score can differentiate the word with low score of certain sentiment and the word with high score of sentiment. By using sentiment score, word with low sentiment score might have been ignored and give result of neutral or opposite class, while for the lexical value, word listed in the vocabulary can\u2019t be ignored and may give incorrect result.\nFor example, in the text \u201cBerlibur di Hanoi Vietnam juga bisa menjadi liburan yang berbeda saat Tahun Baru Cina nanti Travelers\u201d(Vacation at Hanoi, Vietnam can be a different vacation while Chinese New Year), the word \u201cbisa\u201d (can) has a sentiment score of 0.125 which shows a low possitiove sentiment. By using the sentiment score and term weight, the word \u201cbisa\u201d is ignored and it gives the neutral sentiment, which is a correct one. But, by using only the lexical value, the word \u201cbisa\u201d can\u2019t be ignored and it gives the possitive sentiment, which is an incorrect result.\n2) Experiments on classification method:\nThe second experiment evaluated the direct and leveled method in sentimen classification. Both of the classifcation use the sentiment score feature as one of the base feature. The results in Table 2 showed that direct classification gave higher accuracy than leveled method. Both of the methods use the same feature. Here are the list of the feature that used by both method:\n1. Unigram 2. Sentimen Score 3. Question words.\nable 2 shows that the leveled method give lower result in sentiment classification. If we break down the classfication, the positive and negative classification give more than 95% accuracy. The problem lies in the opinion and neutral\nclassification that only give 78% accuracy. In order to improre the accuracy, more feature to detect neutral text is required.\n3) Experiments on sarcasm detection.\nThe third experiment evaluated the additional features of negativity and interjection number in the sarcasm classification accuracy. The results in Table 3 showed that the additional features are effective in sarcasm detection.\ntend to write their critics using sarcasm. As for the low accuracy, we found that there are many sarcasm texts have no global topic. For example, in the text \u201cMen, lu ganteng banget kalo pake dress. :p\u201d (Man, you are so handsome using dress). Here, the text topic is not widely known, thus, the negativity feature is useless."}, {"heading": "IV. CONCLUSIONS", "text": "We have shown that the additional features for detecting sarcasm are quite effective since it increased the accuracy of 6%. Based on our observation of the sarcasm data, we added the features of negativity and number of interjection words. The negativity feature tried to catch the global sentiment value, while the interjection feature represents the lexical phenomena of the text message. In our next research, we will evaluate the method to detect the sarcasm text without global topic and adding some new features to leveled classication to improve the result."}], "references": [{"title": "Sentiment Classification for Indonesian Messages in Social Media", "author": ["A.R. Naradhipa", "A. Purwarianti"], "venue": "International Conference on Electrical Engineering and Informatics (ICEEI). Bandung. Indonesia", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2011}, {"title": "Sistem Analisis Opini Microblogging Berbahasa Indonesia", "author": ["Harlili", "Wibisono", "Yudi"], "venue": "Konferensi Nasional Sistem Informasi. Bali. Indonesia", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2012}, {"title": "Lexical Influences on the Perception of Sarcasm", "author": ["Kreuz", "R. J", "G.M. Caucci"], "venue": "Proceedings of the Workshop on Computational Approaches to Figurative Language", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2007}, {"title": "Identifying Sarcasm in Twitter: a closer look", "author": ["R. Gonzales-Ibanez", "S. Muresan", "Wacholder N"], "venue": "Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2011}, {"title": "SentiWordNet 3.0: An Enhanced Lexical Resource for Sentiment Analysis and Opinion Mining", "author": ["S. Baccianella", "A. Esuli", "Sebastiani"], "venue": "Proceedings of LREC-2010", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2010}, {"title": "Thumb\u2019s up? Sentiment Classification using machine learning Techniques", "author": ["Pang", "Bo", "L. Lee", "Vaithyanathan"], "venue": "Proceeding of the 7 Conference on Empirical Methods in Natural Language Processing (EMNLP-02)", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2002}], "referenceMentions": [{"referenceID": 3, "context": "One approach to solve this problem was by employing lexical features such as unigram and pragmatic factors such as smileys or emoticons [5].", "startOffset": 136, "endOffset": 139}, {"referenceID": 2, "context": "An interesting analysis from the field of lingustic tells us that lexical factors like presence of adjectives and adverbs, presence of interjections, and use of punctuations play a quite significant role in sarcasm[4] In the basic sentiment analysis, many researches employed machine learning techniques such as Na\u00efve Bayes, Maximum Entropy, and Support Vector machine because these algorithms are tend to outperform the other algorithm in the context of text classification [2][3][7].", "startOffset": 214, "endOffset": 217}, {"referenceID": 0, "context": "An interesting analysis from the field of lingustic tells us that lexical factors like presence of adjectives and adverbs, presence of interjections, and use of punctuations play a quite significant role in sarcasm[4] In the basic sentiment analysis, many researches employed machine learning techniques such as Na\u00efve Bayes, Maximum Entropy, and Support Vector machine because these algorithms are tend to outperform the other algorithm in the context of text classification [2][3][7].", "startOffset": 475, "endOffset": 478}, {"referenceID": 1, "context": "An interesting analysis from the field of lingustic tells us that lexical factors like presence of adjectives and adverbs, presence of interjections, and use of punctuations play a quite significant role in sarcasm[4] In the basic sentiment analysis, many researches employed machine learning techniques such as Na\u00efve Bayes, Maximum Entropy, and Support Vector machine because these algorithms are tend to outperform the other algorithm in the context of text classification [2][3][7].", "startOffset": 478, "endOffset": 481}, {"referenceID": 5, "context": "An interesting analysis from the field of lingustic tells us that lexical factors like presence of adjectives and adverbs, presence of interjections, and use of punctuations play a quite significant role in sarcasm[4] In the basic sentiment analysis, many researches employed machine learning techniques such as Na\u00efve Bayes, Maximum Entropy, and Support Vector machine because these algorithms are tend to outperform the other algorithm in the context of text classification [2][3][7].", "startOffset": 481, "endOffset": 484}, {"referenceID": 4, "context": "Other than that, there is also a lexical resource, SentiWordNet [6], developed as a resource of word with sentiment score.", "startOffset": 64, "endOffset": 67}, {"referenceID": 0, "context": "This is different with other researches on sentiment analysis of Indonesian social media [2][3] which didn\u2019t address the sarcasm detection and didn\u2019t employ sentiment score in the SentiWordNet.", "startOffset": 89, "endOffset": 92}, {"referenceID": 1, "context": "This is different with other researches on sentiment analysis of Indonesian social media [2][3] which didn\u2019t address the sarcasm detection and didn\u2019t employ sentiment score in the SentiWordNet.", "startOffset": 92, "endOffset": 95}, {"referenceID": 0, "context": "In Indonesian text message of social media such as twitter or facebook, people tend to use slank words than the formal one such as using numeric to replace alphabet, repeating vocal characters, and using common informal words to replace the formal words [2].", "startOffset": 254, "endOffset": 257}, {"referenceID": 0, "context": "To handle this problem, we used a special list of word such as used in [2].", "startOffset": 71, "endOffset": 74}, {"referenceID": 0, "context": "Since not all suffix \u201can\u201d have negative sentiment, we handled this problem by using a list of word such as used in [2].", "startOffset": 115, "endOffset": 118}, {"referenceID": 5, "context": "These algorithms were chosen because they have shown good accuracy in many text classification task [7].", "startOffset": 100, "endOffset": 103}, {"referenceID": 1, "context": "[3] has tried to use this method, but they haven\u2019t compare those two methods.", "startOffset": 0, "endOffset": 3}], "year": 2013, "abstractText": "Sarcasm is considered one of the most difficult problem in sentiment analysis. In our ob-servation on Indonesian social media, for cer-tain topics, people tend to criticize something using sarcasm. Here, we proposed two additional features to detect sarcasm after a common sentiment analysis is conducted. The features are the negativity information and the number of interjection words. We also employed translated SentiWordNet in the sentiment classification. All the classifications were conducted with machine learning algorithms. The experimental results showed that the additional features are quite effective in the sarcasm detection. Keywords\u2014 Sentimen analysis, sarcasm, classification,", "creator": "Microsoft\u00ae Word 2013"}}}