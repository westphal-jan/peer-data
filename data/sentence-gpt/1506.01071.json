{"id": "1506.01071", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "2-Jun-2015", "title": "Fast Generation of Best Interval Patterns for Nonmonotonic Constraints", "abstract": "In pattern mining, the main challenge is the exponential explosion of the set of patterns. Typically, to solve this problem, a constraint for pattern selection is introduced. One of the first constraints proposed in pattern mining is support (frequency) of a pattern in a dataset (one row or two rows). The same constraints are required in many models. In particular, a linear sequence of sets is required in a set of algorithms to make a selection of the most desirable elements. In the following example, a model using a sparse-bound list of elements is necessary to make a selection of the most desirable elements. In the above example, an inverse-deep linear sequence is required to make a collection of elements in a sparse-bound list of elements.\n\n\n\nThe first constraint for the data set in the model is a pair of sets. In the following example, the two sets of two rows correspond to the list of elements in a list of elements in a set of algorithms, as the input input is a list of elements in a set of algorithms. In the following example, an inverse-deep linear sequence is required to make a collection of elements in a set of algorithms, as the input is a list of elements in a set of algorithms. In the following example, an inverse-deep linear sequence is required to make a collection of elements in a set of algorithms, as the input is a list of elements in a set of algorithms. In the following example, the two sets of two rows correspond to the list of elements in a set of algorithms, as the input is a list of elements in a set of algorithms. In the following example, the two sets of two rows correspond to the list of elements in a set of algorithms. In the following example, the two sets of two rows correspond to the list of elements in a set of algorithms. In the following example, the two sets of two rows correspond to the list of elements in a set of algorithms. In the following example, the two sets of two rows correspond to the list of elements in a set of algorithms. In the following example, the two sets of two rows correspond to the list of elements in a set of algorithms. In the following example, the two sets of two rows correspond to the list of elements in a set of algorithms. In the following example, the two sets of two rows correspond to the list of elements in a set of algorithms. In the following example, the two sets of two rows correspond to the list of elements in a set of algorithms. In the", "histories": [["v1", "Tue, 2 Jun 2015 21:32:14 GMT  (52kb)", "https://arxiv.org/abs/1506.01071v1", "18 pages; 2 figures; 2 tables; 1 algorithm; PKDD 2015 Conference Scientific Track"], ["v2", "Tue, 16 Jun 2015 15:31:19 GMT  (52kb)", "http://arxiv.org/abs/1506.01071v2", "18 pages; 2 figures; 2 tables; 1 algorithm; PKDD 2015 Conference Scientific Track"]], "COMMENTS": "18 pages; 2 figures; 2 tables; 1 algorithm; PKDD 2015 Conference Scientific Track", "reviews": [], "SUBJECTS": "cs.AI cs.DS", "authors": ["aleksey buzmakov", "sergei o kuznetsov", "amedeo napoli"], "accepted": false, "id": "1506.01071"}, "pdf": {"name": "1506.01071.pdf", "metadata": {"source": "CRF", "title": null, "authors": ["Aleksey Buzmakov", "Sergei O. Kuznetsov", "Amedeo Napoli"], "emails": ["aleksey.buzmakov@inria.fr,", "skuznetsov@hse.ru,", "amedeo.napoli@loria.fr"], "sections": [{"heading": null, "text": "ar X\niv :1\n50 6.\n01 07\n1v 2"}, {"heading": "1 Introduction", "text": "Interestingness measures were proposed to overcome the problem of combinatorial explosion of the number of valid patterns that can be discovered in a dataset [18]. For example, pattern support, i.e., the number of objects covered by the pattern, is one of the most famous measures of pattern quality.\n\u2217The final publication is available at link.springer.com\nIn particular, support satisfies the property of anti-monotonicity (aka \u201ca priori principle\u201d), i.e., the larger the pattern is the smaller the support is [12, 1]. Many other measures can be mentioned such as utility constraint [24], pattern stability [10, 15], pattern leverage [19], margin closeness [13], MCCS [16], cosine interest [4], pattern robustness [17], etc.\nSome of these measures (e.g., support, robustness for generators [17], or upper bound constraint of MCCS [16]) are \u201cglobally anti-monotonic\u201d, i.e., for any two patterns X \u2291 Y we have M(X) \u2265 M(Y ), where M is a measure and \u2291 denotes the (subsumption) order relation on patterns. When a measure is anti-monotonic, it is relatively easy to find patterns whose measure is higher than a certain threshold (e.g., patterns with a support higher than a threshold). In contrast some other measures are called \u201clocally anti-monotonic\u201d, i.e., for any pattern X there is an immediate subpattern Y \u227a X such that M(Y ) \u2265 M(X). Then the right strategy should be selected for traversing the search space, e.g., a pattern Y should be extended only to patterns X such that M(Y ) \u2265 M(X). For example, for \u201clocally anti-monotonic\u201d cosine interest [4], the extension of a pattern Y consists in adding only attributes with a smaller support than any attribute from Y . The most difficult case for selecting valid patterns occurs when a measure is not locally anti-monotonic. Then, valid patterns can be retained by postfiltering, i.e., finding a (large set of) patterns satisfying an antimonotone constraint and filtering them w.r.t. the chosen nonmonotonic measure (i.e., neither monotonic nor anti-monotonic) [15, 13, 17], or using heuristics such as leap search [22] or low probability of finding interesting patterns in the current branch [19].\nMost of the measures are only applicable to one type of patterns, e.g., pattern leverage or cosine interest can be applied only to binary data since their definitions involve single attributes. \u201cPattern independent measures\u201d usually relies on support of the pattern and/or on support of other patterns from the search space. In particular, support, stability [10], margin-closeness [13] and robustness [17] are pattern independent measures. In this paper we work with interval tuple data, where only pattern independent measures as well as specific measures for interval tuples can be applied. In addition, given a measure, it can be difficult to define a good threshold. Thus various approaches for finding top-K patterns were introduced [7, 21, 20], with the basic idea to automatically adjust the threshold for a measure M.\nIn this paper we introduce a new algorithm \u03b8-\u03a3\u03bf\u03c6\u03b9\u03b1, i.e., Sofia, for \u201cSearching for Optimal Formal Intents Algorithm\u201d for a interestingness threshold \u03b8, for extracting the best patterns of a kind, e.g., itemsets, interval tuples, strings, graph patterns, etc. \u03b8-\u03a3\u03bf\u03c6\u03b9\u03b1 algorithm is applicable to a class of measures called \u201cprojection-antimonotonic measures\u201d or more precisely \u201cmeasures antimonotonic w.r.t. a chain of projections\u201d. This class includes globally antimonotonic measures such as support, locally anti-monotonic measures such as cosine interest and some of the nonmonotonic measures such as stability or robustness of closed patterns. The main novelty of this paper is \u03b8-\u03a3\u03bf\u03c6\u03b9\u03b1, a new efficient algorithm for finding best patterns of different kinds w.r.t. projectionantimonotonic measures which constitutes a rather large class of measures.\nThe remaining of the paper is organized as follows. The formalization of the current approach is based on Formal Concept Analysis (FCA) [6] and pattern structures [5] which are introduced in Section 2. Then, \u03b8-\u03a3\u03bf\u03c6\u03b9\u03b1 algorithm is detailed in Section 3 first for an arbitrary measure and second for the \u2206-measure. Experiments and a discussion are proposed in Section 4, before conclusion."}, {"heading": "2 Data Model", "text": ""}, {"heading": "2.1 FCA and Pattern structures", "text": "Formal Concept Analysis (FCA) is a formalism for knowledge discovery and data mining thanks to the design of concept lattices [6]. It is also convenient for describing models of itemset mining, and, since [14], lattices of closed itemsets (i.e., concept lattices) and closed descriptions are used for concise representation of association rules. For more complex data such as sequences and graphs one can use an extension of the basic model, called pattern structures [5]. With pattern structures it is possible to define closed descriptions and to give a concise representation of association rules for different descriptions with a natural order (such as subgraph isomorphism order) [11, 8].\nA pattern structure is a triple (G, (D,\u2293), \u03b4), where G is a set of objects, (D,\u2293) is a complete meet-semilattice of descriptions and \u03b4 : G \u2192 D maps an object to a description.\nThe intersection \u2293 gives the similarity of two descriptions. Standard FCA can be presented in terms of a pattern structure. A formal context (G,M, I), where G is a set of objects, M is a set of attributes and I \u2286 G\u00d7M an incidence relation giving information about attributes related to objects, is represented as a pattern structure (G, (\u2118(M),\u2229), \u03b4), where (\u2118(M),\u2229) is a semilattice of subsets of M with \u2229 being the set-theoretical intersection. If x = {a, b, c} and y = {a, c, d}, then x \u2293 y = x \u2229 y = {a, c}. The mapping \u03b4 : G\u2192 \u2118(M) is given by \u03b4(g) = {m \u2208 M | (g,m) \u2208 I} and returns the description of a given object as a set of attributes.\nThe following mappings or diamond operators give a Galois connection between the powerset of objects and descriptions:\nA\u22c4 := l\ng\u2208A\n\u03b4(g), for A \u2286 G\nd\u22c4 := {g \u2208 G | d \u2291 \u03b4(g)}, for d \u2208 D\nGiven a subset of objects A, A\u22c4 returns the description which is common to all objects in A. Given a description d, d\u22c4 is the set of all objects whose description subsumes d. A partial order \u2291 (subsumption) on descriptions from D is defined w.r.t. the similarity operation \u2293: c \u2291 d \u21d4 c \u2293 d = c, and c is subsumed by d.\nA pattern concept of a pattern structure (G, (D,\u2293), \u03b4) is a pair (A, d), where A \u2286 G, called pattern extent and d \u2208 D, called pattern intent, such that A\u22c4 = d and d\u22c4 = A. A pattern extent is a closed set of objects, and a pattern intent is\na closed description, e.g., a closed itemset when descriptions are given as sets of items (attributes). As shown in [11], descriptions closed in terms of counting inference (which is a standard data mining approach), such as closed graphs [23], are elements of pattern intents.\nA pattern extent corresponds to the maximal set of objects A whose descriptions subsume the description d, where d is the maximal common description for objects in A. The set of all pattern concepts is partially ordered w.r.t. inclusion on extents, i.e., (A1, d1) \u2264 (A2, d2) iff A1 \u2286 A2 (or, equivalently, d2 \u2291 d1), making a lattice, called pattern lattice."}, {"heading": "2.2 Interval pattern structure", "text": "A possible instantiation of pattern structures is interval pattern structures introduced to support efficient processing of numerical data without binarization [8]. Given k numerical or interval attributes whose values are of the form [a, b], where a, b \u2208 R, the language of a pattern space is given by tuples of intervals of size k. For simplicity, we denote intervals of the form [a, a] by a.\nFigure 1a exemplifies an interval dataset. It contains 6 objects and 2 attributes. An interval as a value of an attribute corresponds to an uncertainty in the value of the attribute. For example, the value of m1 for g2 is known exactly, while the value of m2 is lying in [1, 2]. Given this intuition for intervals it is natural to define similarity of two intervals as their convex hull, since by adding new objects one increases the uncertainty. For example, for g1 the value of m1 is 0, while for g6 it is 1, thus given the set {g1, g6}, the uncertainty of m1 in this set is [0, 1], i.e., the similarity of g1 and g6 w.r.t. m1 is [0, 1]. More formally, given two intervals [a, b] and [c, d], the similarity of these two intervals is given by [a, b] \u2293 [c, d] = [min(a, c),max(b, d)]. Given a tuple of intervals, the similarity is computed component-wise. For example, g\u22c41 \u2293 g \u22c4 6 = \u3008[0, 1]; [0, 2]\u3009. Reciprocally, \u3008[0, 1]; [0, 2]\u3009 = {g1, g2, \u00b7 \u00b7 \u00b7 , g6}. The resulting concept lattice is shown in Figure 1b. Concept extents are shown by indices of objects, intents are given in angle brackets, the numbers on edges and on concepts are related to interestingness of concepts and will be described in the next subsection."}, {"heading": "2.3 Stability index of a concept", "text": "For real datasets, the number of patterns can be very large, even computing the number of closed patterns is a #P-complete problem [9]. Different measures were tested for selecting most interesting patterns, such as stability [10]. Stability measures the independence of a concept intent w.r.t. randomness in data.\nGiven a concept C, concept stability Stab(C) is the relative number of subsets of the concept extent (denoted by Ext(C)), whose descriptions, i.e., the result of (\u00b7)\u22c4 is equal to the concept intent (denoted by Int(C)).\nStab(C) := |{s \u2208 \u2118(Ext(C)) | s\u22c4 = Int(C)}|\n|\u2118(Ext(C))| (1)\nHere \u2118(P ) is the powerset of P . The larger the stability, the more objects can be deleted from the context without affecting the intent of the concept, i.e., the intent of the most stable concepts is likely to be a characteristic pattern of a given phenomenon and not an artifact of a dataset.\nWe say that a concept is stable if its stability is higher than a given threshold \u03b8; a pattern p is stable if there is a concept in the lattice with p as the intent and the concept is stable.\nExample 1 Figure 1b shows a lattice for the context in Figure 1a. Concept extents are given by their indices, i.e., {g1, g2} is given by 12. The extent of the highlighted concept C is Ext(C) = {g2, g3, g4}, thus, its powerset contains 23 elements. Descriptions of 2 subsets of Ext(C) ({g4} and \u2205) are different from the intent of C, Int(C) = {m3}, while all other subsets of Ext(C) have a common set of attributes equal to \u30080; [1, 2]\u3009. So, Stab(C) = 2 3\u22122 23 = 0.75. Stability of other concepts is shown in brackets. It should be noticed that stability of all comparable patterns for Int(C) in the lattice is smaller than the stability of C, which highlights the nonmonotonicity of stability.\nConcept stability is closely related to the robustness of a closed pattern [17]. Indeed, robustness is the probability of a closed pattern to be found in a subset of the dataset. To define this probability, the authors define a weight for every subset given as a probability of obtaining this subset by removing objects from the dataset, where every object is removed with probability \u03b1, e.g., given a subset of objects X \u2286 G, the probability of the induced subset is given by p(D\u03b1 = (X, (D,\u2293), \u03b4)) = \u03b1|X|(1 \u2212 \u03b1)|G\\X|. Stability in this case is the robustness of closed pattern if the weights of subsets of the dataset are equal to 2\u2212|G|.\nThe problem of computing concept stability is #P-complete [10]. A fast computable stability estimate was proposed in [3], where it was shown that this estimate ranks concepts almost in the same way as stability does. In particular,\nStab(C) \u2264 1 \u2212 2\u2212\u2206(C), where \u2206(C) = min D\u2264C |Ext(C) \\ Ext(D)|, i.e., the minimal difference in supports between concept C and all its nearest subconcepts. For a threshold \u03b8, patterns p with \u2206(p) \u2265 \u03b8 are called \u0394-stable patterns.\nExample 2 Consider the example in Figure 1. Every edge in the figure is labeled with the difference in support between the concepts this edge connects. Thus, \u0394 of a pattern is the minimum label of the edges going down from the concept. The value \u2206(({g2, g3, g4}; \u30080; [1, 2]\u3009)) is equal to 2. Another example is \u2206((G; \u3008[0, 1]; [0, 2]\u3009)) = 2. For this example we can also see that \u0394-measure is not anti-monotonic either.\n\u0394-measure is related to the work of margin-closeness of an itemset [13]. In this work, given a set of patterns, e.g., frequent closed patterns, the authors rank them by the minimal distance in their support to the closest superpattern divided over the support of the pattern. In our case, the minimal distance is exactly the \u0394-measure of the pattern.\nStability and\u0394-measure are not anti-monotonic but rather projection-antimonotonic. Patterns w.r.t. such kind of measures can be mined by a specialized algorithm introduced in Section 3. But before we should introduce projections of pattern structures in order to properly define projection-antimonotonicity and the algorithm."}, {"heading": "2.4 Projections of Pattern Structures", "text": "The approach proposed in this paper is based on projections introduced for reducing complexity of computing pattern lattices [5].\nA projection \u03c8 : D \u2192 D is an \u201cinterior operator\u201d, i.e., it is (1) monotonic (x \u2291 y \u21d2 \u03c8(x) \u2291 \u03c8(y)), (2) contractive (\u03c8(x) \u2291 x) and (3) idempotent (\u03c8(\u03c8(x)) = \u03c8(x)). A projected pattern structure \u03c8((G, (D,\u2293), \u03b4)) is a pattern structure (G, (D\u03c8,\u2293\u03c8), \u03c8 \u25e6 \u03b4), where D\u03c8 = \u03c8(D) = {d \u2208 D | \u2203d\u2217 \u2208 D : \u03c8(d\u2217) = d} and \u2200x, y \u2208 D, x \u2293\u03c8 y := \u03c8(x \u2293 y).\nExample 3 Consider the example in Figure 1. If we remove a column corresponding to an attribute, e.g., the attribute m2, from the context in Figure 1a, we define a projection, given by \u03c8(\u3008[a, b]; [c, d]\u3009) = \u3008[a, b]; [\u2212\u221e,+\u221e]\u3009, meaning that no value of m2 is taken into account.\nGiven a projection \u03c8 we call \u03c8(D) = {d \u2208 D | \u03c8(d) = d} the fixed set of \u03c8. Note that, if \u03c8(d) 6= d, then there is no other d\u0303 such that \u03c8(d\u0303) = d because of idempotency of projections. Hence, any element outside the fixed set of the projection \u03c8 is pruned from the description space. Given the notion of a fixed set we can define a partial order on projections.\nDefinition 1 Given a pattern structure P = (G, (D,\u2293), \u03b4) and two projections \u03c81 and \u03c82, we say that \u03c81 is simpler than \u03c82 (\u03c82 is more detailed than \u03c81), denoted by \u03c81 < \u03c82, if \u03c81(D) \u2282 \u03c82(D), i.e., \u03c81 prunes more descriptions than \u03c82.\nOur algorithm is based on this order on projections. The simpler a projection \u03c8 is, the less patterns we can find in \u03c8(P), and the less computational efforts one should take. Thus, we compute a set of patterns for a simpler projection, then we remove unpromising patterns and extend our pattern structure and the found patterns to a more detailed projection. This allows us to reduce the size of patterns within a simpler projection in order to reduce the computational complexity of more detailed projection."}, {"heading": "2.5 Projections of Interval Pattern Structures", "text": "Let us first consider interval pattern structures with only one attributem. Let us denote byW = {w1, \u00b7 \u00b7 \u00b7 , w|W |} all possible values of the left and right endpoints of the intervals corresponding to the attribute in a dataset, so that w1 < w2 < \u00b7 \u00b7 \u00b7 < w|W |. By reducing the setW of possible values for the left or the right end of the interval we define a projection. For example, if {w1} is the only possible value for the left endpoint of an interval and {w|W |} is the only possible value of the right endpoint of an interval, then all interval patterns are projected to [w1, w|W |]. Let us consider this in more detail.\nLet two sets L,R \u2282 W such that w1 \u2208 L and w|W | \u2208 R be constraints on possible values on the left and right endpoints of an interval, respectively. Then a projection is defined as follows:\n\u03c8m[L,R]([a, b]) = [max{l \u2208 L|l \u2264 a},min{r \u2208 R|r \u2265 b}] . (2)\nRequiring that w1 \u2208 L and w|W | \u2208 R we ensure that the sets used for minimal and maximal functions are not empty. It is not hard to see that (2) is a projection. The projections given by (2) are ordered w.r.t. simplicity (Definition 1). Indeed, given L1 \u2286 L and R1 \u2286 R, we have \u03c8m[L1,R1] < \u03c8m[L,R], because of inclusion of fixed sets. Let us notice that a projection \u03c8m[W,W ] does not modify the lattice of concepts for the current dataset, since any interval for the value set W is possible. We also notice that a projection \u03c8m[L,R] is defined for one interval, while we can combine the projections for different attributes in a tuple to a single projection for the whole tuple \u03c8m1[L1,R1]m2[L2,R2]....\nExample 4 Consider example in Figure 1. Let us consider a projection\n\u03c8m1[{0,1},{1}]m2[{0,2},{0,2}].\nThe fixed set of this projection consists of {[0, 1], 1}\u00d7 {0, 2, [0, 2]}, i.e., 6 intervals. Let us find the projection of (g2)\n\u22c4 = \u30080; [1, 2]\u3009 in a component-wise way: \u03c8m1[{0,1},{1}](0) = [0, 1], since 0 is allowed on the left endpoint of an interval but not allowed to be on the right endpoint of an interval; \u03c8m2[{0,2},{0,2}]([1, 2]) = [0, 2] since 1 is not allowed on the left endpoint of an interval. Thus,\n\u03c8m1[{0,1},{1}]m2[{0,2},{0,2}](\u30080; [1, 2]\u3009) = \u3008[0, 1]; [0, 2]\u3009 .\nThe lattice corresponding to this projection is shown in Figure 2."}, {"heading": "3 \u03b8-\u03a3\u03bf\u03c6\u03b9\u03b1 Algorithm", "text": ""}, {"heading": "3.1 Anti-monotonicity w.r.t. a Projection", "text": "Our algorithm is based on the projection-antimonotonicity, a new idea introduced in this paper. Many interestingness measures for patterns, e.g., stability, are not (anti-)monotonic w.r.t. subsumption order on patterns. A measure M is called anti-monotonic, if for two patterns q \u2291 p, M(q) \u2265 M(p). For instance, support is a anti-monotonic measure w.r.t. pattern order and it allows for efficient generation of patterns with support larger than a threshold [1, 12, 14]. The projection-antimonotonicity is a generalization of standard anti-monotonicity and allows for efficient work with a larger set of interestingness measures.\nDefinition 2 Given a pattern structure P and a projection \u03c8, a measure M is called anti-monotonic w.r.t. the projection \u03c8, if\n(\u2200p \u2208 \u03c8(P))(\u2200q \u2208 P, \u03c8(q) = p) M\u03c8(p) \u2265 M(q), (3)\nwhere M\u03c8(p) is the measure M of a pattern p computed in \u03c8(P).\nHere, for any pattern p of a projected pattern structure we check that a preimage q of p for \u03c8 has a measure smaller than the measure of p. It should be noticed that a measure M for a pattern p can yield different values if M is computed in P or in \u03c8(P). Thus we use the notation M\u03c8 for the measure M computed in \u03c8(P). The property of a measure given in Definition 2 is called projection-antimonotonicity.\nIt should be noticed that classical anti-monotonic measures are projectionantimonotonic for any projection. Indeed, because of contractivity of \u03c8 (\u03c8(p) \u2291 p), for any anti-monotonic measure one has M(\u03c8(p)) \u2265 M(p). This definition covers also the cases where a measure M is only locally anti-monotonic, i.e., given a pattern p there is an immediate subpattern q \u227a p such that M(q) \u2265 M(p), see e.g., the cosine interest of an itemset, which is only locally antimonotonic [4]. Moreover, this definition covers also some measures that are not locally anti-monotonic. As we mentioned in Examples 1 and 2 stability and \u0394measure are not locally anti-monotonic. However, it can be shown that they are anti-monotonic w.r.t. any projection [2]. Moreover, following the same strategy\none can prove that robustness of closed patterns from [17] is also anti-monotonic w.r.t. any projection. In particular, the robustness of closed patterns defines a anti-monotonic constraint w.r.t. any projection.\nThus, given a measure M anti-monotonic w.r.t. a projection \u03c8, if p is a pattern such that M\u03c8(p) < \u03b8, then M(q) < \u03b8 for any preimage q of p for \u03c8. Hence, if, given a pattern p of \u03c8(P), one can find all patterns q of P such that \u03c8(q) = p, it is possible to first find all patterns of \u03c8(P) and then to filter them w.r.t. M\u03c8 and a threshold, and finally to compute the preimages of filtered patterns. It allows one to cut earlier unpromising branches of the search space or adjust a threshold for finding only a limited number of best patterns."}, {"heading": "3.2 Anti-monotonicity w.r.t. a Chain of Projections", "text": "However, given just one projection, it can be hard to efficiently discover the patterns, because the projection is either hard to compute or the number of unpromising patterns that can be pruned is not high. Hence we introduce a chain of projections \u03c80 < \u03c81 < \u00b7 \u00b7 \u00b7 < \u03c8k = 1, where a pattern lattice for \u03c80(P) can be easily computed and 1 is the identity projection, i.e., (\u2200x)1(x) = x. For example, to find frequent itemsets, we typically search for small frequent itemsets and then extend them to larger ones. This corresponds to extension to a more detailed projection.\nDefinition 3 Given a pattern structure P and a chain of projections \u03c80 < \u03c81 < \u00b7 \u00b7 \u00b7 < \u03c8k = 1, a measure M is called anti-monotonic w.r.t. the chain of projections if M is anti-monotonic w.r.t. all \u03c8i for 0 \u2264 i \u2264 k.\nExample 5 Let us construct a chain of projections satisfying (2) for the example in Figure 1. The value set for the first attribute is W1 = {0, 1} and the value set for the second is W2 = {0, 1, 2}. Let us start the chain from a projection \u03c80 = \u03c8m1[{0},{1}]m2[{0},{2}]. This projection allows only for one pattern \u3008[0, 1]; [0, 2]\u3009, i.e., the concept lattice is easily found. Then we increase the complexity of a projection by allowing more patterns. For example, we can enrich the first component of a tuple without affecting the second one, i.e., a projection \u03c81 = \u03c8m1[{0,1},{0,1}]m2[{0},{2}]. This projection allows for 3 patterns, i.e., any possible interval of the first component and only one interval [0,2] for the second component. Let us notice that it is not hard to find preimages for \u03c80 in \u03c81(D). Indeed, for any pattern p from \u03c80(D) one should just modify either the left side of the first interval of p by one value, or the right side of the first interval of p.\nThen we can introduce a projection that slightly enrich the second component of a tuple, e.g., \u03c82 = \u03c8m1[{0,1},{0,1}]m2[{0,1},{1,2}] and finally we have \u03c83 = \u03c8m1[W1,W1]m2[W2,W2]. Finding preimages in this chain is not a hard problem, since on every set we can only slightly change left and/or right side of the second interval in a tuple. Thus, starting from a simple projection and making transitions from one projection to another, we can cut unpromising branches and efficiently find the set of interesting patterns."}, {"heading": "3.3 Algorithms", "text": "Data: A pattern structure P, a chain of projections \u03a8 = {\u03c80, \u03c81, \u00b7 \u00b7 \u00b7 , \u03c8k}, a measure M anti-monotonic for the chain \u03a8, and a threshold \u03b8 for M.\n1 Function ExtendProjection(i, \u03b8, Pi\u22121) Data: i is the projection number to which we should extend\n(0 < i \u2264 k), \u03b8 is a threshold value for M, and Pi\u22121 is the set of patterns for the projection \u03c8i\u22121.\nResult: The set Pi of all patterns with the value of measure M higher than the threshold \u03b8 for \u03c8i.\n2 Pi \u2190\u2212 \u2205; 3 /* Put all preimages in \u03c8i(P) for any pattern p */ 4 foreach p \u2208 Pi\u22121 do 5 Pi \u2190\u2212 Pi \u222a Preimages(i,p) 6 /* Filter patterns in Pi to have a value of M higher than\n\u03b8 */\n7 foreach p \u2208 Pi do 8 if M\u03c8i(p) \u2264 \u03b8 then 9 Pi \u2190\u2212 Pi \\ {p}\n10 Function Algorithm \u03b8-\u03a3\u03bf\u03c6\u03b9\u03b1 Result: The set P of all patterns with a value of M higher than the threshold \u03b8 for P. 11 /* Find all patterns in \u03c80(P) with a value of M higher\nthan \u03b8 */\n12 P \u2190\u2212 FindPatterns(\u03b8, \u03c80); 13 /* Run through out the chain \u03a8 and find the patterns for \u03c8i(P) */ 14 foreach 0 < i \u2264 k do 15 P \u2190\u2212 ExtendProjection(i, \u03b8,P);\nAlgorithm 1: The \u03b8-\u03a3\u03bf\u03c6\u03b9\u03b1 algorithm for finding patterns in P with a value of a measure M higher than a threshold \u03b8.\nGiven a measure anti-monotonic w.r.t. a chain of projections, if we are able to find all preimages of any element in the fixed set of \u03c8i that belong to a fixed set of \u03c8i+1, then we can find all patterns of P with a value of M higher than a given threshold \u03b8. We call this algorithm \u03b8-\u03a3\u03bf\u03c6\u03b9\u03b1 and its pseudocode is given in Algorithm 1. In lines 11-12 we find all patterns for \u03c80(P) satisfying the constraint that a value of M is higher than a threshold. Then in lines 13- 15 we iteratively extend projections from simpler to more detailed ones. The extension is done by constructing the set Pi of preimages of the set Pi\u22121 (lines 2-5) and then by removing the patterns that do not satisfy the constraint from Pi (lines 6-9).\nThe algorithm is sound and complete, since first, a pattern p is included\ninto the set of preimages of p (\u03c8(p) = p) and second, if we remove a pattern p from the set P , then the value M(p) < \u03b8 and, hence, the measure value of any preimage of p is less than \u03b8 by the projection-antimonotonicity of M. The worst case time complexity of \u03b8-\u03a3\u03bf\u03c6\u03b9\u03b1 algorithm is\nT(\u03b8-\u03a3\u03bf\u03c6\u03b9\u03b1) = T(FindPatterns(\u03c80))+\n+ k \u00b7 max 0<i\u2264k |Pi| \u00b7 (T(Preimages) + T(M)), (4)\nwhere k is the number of projections in the chain, T(X ) is time for computing operation X . Since projection \u03c80 can be chosen to be very simple, in a typical case the complexity of FindPatterns(\u03b8, \u03c80) can be low or even constant. The complexities of Preimages and M depend on the measure, the chain of projections, and the kind of patterns. In many cases max\n0<i\u2264k |Pi| can be exponential in\nthe size of the input, because the number of patterns can be exponential. It can be a difficult task to define the threshold \u03b8 such that the maximal cardinality of Pi is not larger than a given number. This can be solved by an automatically adjustment of the threshold \u03b8, which is not discussed here."}, {"heading": "3.4 \u03b8-\u03a3\u03bf\u03c6\u03b9\u03b1 Algorithm for Interval Tuple Data", "text": "In this subsection we consider a pattern structure K = (G, (DI ,\u2293), \u03b4), where DI is a semilattice of interval tuple descriptions. We say that every component of a tuple p corresponds to an attribute m \u2208 M , where M is the set of interval attributes. Thus, the size of any tuple in DI is |M |, and for any attribute m \u2208M we can denote the corresponding interval by m(p). We also denote the value set of m by Wm. Since the set Wm is totally ordered we also denote by W (j) m and W (\u2212j) m the sets containing the first j (smallest) elements and the last j (largest) elements from Wm, respectively. A projection chain for interval tuple data is formed in the same way as discussed in Example 5. We start from the projection containing only one pattern corresponding to the largest interval in each component, i.e., for an attribute m the projection is of the form \u03c8m[W (1) m ,W (\u22121) m ]. Then to pass to a next projection, we select the attribute m, and for this attribute we extend the projection from \u03c8m[W (j) m ,W (\u2212j) m ] to \u03c8m[W (j+1) m ,W (\u2212j\u22121) m ]. Thus, there are k = max m\u2208M |Wm| \u00b7 |M | projections.\nFinding preimages in this case is not hard, since to make a projection more detailed one should just extend the corresponding interval in left and/or on right end of the interval, i.e., there are only 4 possible preimages for a pattern when passing from one projection to another in this chain. Thus, we have proved the following\nProposition 1 The worst case complexity for \u03b8-\u03a3\u03bf\u03c6\u03b9\u03b1 algorithm for interval tuple data is\nT(\u03b8-\u03a3\u03bf\u03c6\u03b9\u03b1 intervals ) = max m\u2208M |Wm| \u00b7 |M | \u00b7 max 0<i\u2264k |Pi| \u00b7 T(M). (5)\n."}, {"heading": "3.5 \u03b8-\u03a3\u03bf\u03c6\u03b9\u03b1 Algorithm for Closed Patterns", "text": "Closed frequent itemsets are widely used as a condensed representation of all frequent itemsets since [14]. Here we show how we can adapt the algorithm for closed patterns. A closed pattern in \u03c8i\u22121(P) is not necessarily closed in \u03c8i(P). However, the extents of \u03c8(P) are extents of P [5]. Thus, we associate the closed patterns with extents and then work with extents instead of patterns, i.e., a pattern structure P = (G, (D,\u2293), \u03b4) is transformed into PC = (G, (DC ,\u2293C), \u03b4C), where DC = 2\nG. Moreover, for all x, y \u2208 DC we have x\u2293C y = (x\u22c4\u2293y\u22c4)\u22c4, where diamond operator is computed in P and \u03b4C(g \u2208 G) = {g}. Hence, every pattern p in DC corresponds to a closed pattern p\n\u22c4 in D. A projection \u03c8 of P induces a projection \u03c8C of PC , given by \u03c8C(X \u2286 G) = \u03c8(X\u22c4)\u22c4 with (\u00b7)\u22c4 for P."}, {"heading": "3.6 \u0394-measure and \u03b8-\u03a3\u03bf\u03c6\u03b9\u03b1 Algorithm", "text": "In this subsection we show that \u0394-measure is anti-monotonic for any projection; it is a stronger condition than the one required by Definition 3. \u0394-measure works for closed patterns, and, hence, we identify every description by its extent (Subsection 3.5).\nProposition 2 \u2206 is anti-monotonic for any projection \u03c8.\nProof. By properties of a projection, an extent of \u03c8(P) is an extent of P [5]. Let us consider an extent E and an extent of its descendant in \u03c8(P). Let us suppose that Ep is a preimage of E for the projection \u03c8. Since Ec and Ep are extents in P, the set Ecp = Ec \u2229 Ep is an extent in P (the intersection of two closed sets is a closed set). Since Ep is a preimage of E, then Ep 6\u2264 Ec (otherwise, Ep is a preimage of Ec and not of E). Then, Ecp 6= Ep and Ecp \u2264 Ep. Hence, \u2206(Ep) \u2264 |Ep\\Ecp| \u2264 |E \\Ec|. So, given a preimage Ep of E, (\u2200Ec \u2286 E)\u2206(Ep) \u2264 |E \\Ec|, i.e., \u2206(Ep) \u2264 \u2206(E). Thus, we can use \u0394-measure in combination with \u03b8-\u03a3\u03bf\u03c6\u03b9\u03b1."}, {"heading": "3.7 Example of \u0394-Stable Patterns in Interval Tuple Data", "text": "Let us consider the example in Figure 1 and show how we can find all \u0394-stable patterns with a threshold \u03b8 = 2. The chain of projections for this example is given in Example 5, it contains 4 projections:\n\u03c80 = \u03c8m1[{0},{1}]m2[{0},{2}] \u03c81 = \u03c8m1[{0,1},{0,1}]m2[{0},{2}] \u03c82 = \u03c8m1[{0,1},{0,1}]m2[{0,1},{1,2}] \u03c83 = \u03c8m1[{0,1},{0,1}]m2[{0,1,2},{0,1,2}]\nSince we are looking for closed patterns, every pattern can be identified by its extent. In Table 1 all patterns are given by their extents, i.e., by elements of DC . For every pattern \u0394-measure is shown for every \u03c8i. A cell is shown in grey if the pattern is no more considered (the value of \u0394 less than 2). A cell has a dash \u201c\u2013\u201d, if a pattern in the row has not been generated for this projection.\nFor the example in Figure 1 the global process is as follows. At the beginning \u03c80(DI) contains only one element corresponding to pattern extent 123456 (a short cut for {g1, g2, g3, g4, g5, g6}) with a description \u3008[0, 1]; [0, 2]\u3009. Then, in \u03c81(G, (DI ,\u2293), \u03b4) possible preimages of 123456 are patterns with descriptions \u30080; [0, 2]\u3009 and \u30081; [0, 2]\u3009 given by pattern extents 1234 and 56, respectively. Then we continue with these three patterns which are all \u0394-stable for the moment. The pattern extents 123456 and 56 have no preimages for the transition \u03c81 \u2192 \u03c82, while the pattern extent 1234 has two preimages with descriptions \u30080; [0, 1]\u3009 and \u30080; [1, 2]\u3009 for this projection, which correspond to pattern extents 1 and 234. The first one is not \u0394-stable and thus is no more considered. Moreover, the pattern extent 1234 is not \u0394-stable (because of 234) and should also be removed. Finally, in transition \u03c82 \u2192 \u03c83 only extent-pattern 234 has a preimage, a pattern extent 4, which is not \u0394-stable. In such a way, we have started from a very simple projection \u03c80 and achieved the projection \u03c83 that gives us the \u0394-stable patterns of the target pattern structure."}, {"heading": "4 Experiments and Discussion", "text": "In this section we compare our approach to approaches based on postfiltering. Indeed, there is no approach that can directly mine stable-like pattern, e.g., stable, \u0394-stable or robust patterns. The known approaches use postfiltering to mine such kind of patterns [15, 13, 2, 17]. Recently it was also shown that it is more efficient to mine interval tuple data without binarization [8]. In their paper the authors introduce algorithm MinIntChange for working directly with interval tuple data. Thus we compare \u03b8-\u03a3\u03bf\u03c6\u03b9\u03b1 and MinIntChange for finding \u0394-stable patterns. We find \u0394-stable concepts with \u03b8-\u03a3\u03bf\u03c6\u03b9\u03b1 and then adjust frequency threshold \u03b8 such that all \u0394-stable patterns are among the frequent ones.\nThe experiments are carried out on an \u201cIntel(R) Core(TM) i7-2600 CPU @ 3.40GHz\u201d computer with 8Gb of memory under Ubuntu 14.04 operating system. The algorithms are not parallelized and are coded in C++."}, {"heading": "4.1 Dataset Simplification", "text": "For interval tuple data stable patterns can be very deep in the search space, such that neither of the algorithms can find them quickly. Thus, we join some similar values for every attribute in an interval in the following way. Given a threshold 0 < \u03b2, two consequent numbers wi and wi+1 from a value set W are joined in the same interval if wi+1 \u2212 wi < \u03b2. In order to properly set the threshold \u03b2, we use another threshold 0 < \u03b3 < 1, which is much easier to set.\nIf we assume that the values of the attributem are distributed around several states with centers w\u03031, \u00b7 \u00b7 \u00b7 , w\u0303l, then it is natural to think that the difference between the closest centers abs(w\u0303i \u2212 w\u0303i\u00b11) are much larger than the difference between the closest values. Ordering all values in the increasing order and finding the maximal difference \u03b4max can give us an idea of typical distance between the states in the data. Thus, \u03b3 is defined as a proportion of this distance that should be considered as a distance between states, i.e., we put \u03b2 = \u03b3 \u00b7 \u03b4max. If the distance between closest values in W are always the same, then even \u03b3 = 0.99 does not join values in intervals. However, if there are two states and the values are distributed very closely to one of these two states, then even \u03b3 = 0.01 can join values into one of two intervals corresponding to the states."}, {"heading": "4.2 Datasets", "text": "We take several datasets from the Bilkent University database 1. The datasets are summarized in Table 2. The names of datasets are given by standard abbreviations used in the database of Bilkent University. For every dataset we provide the number of objects and attributes and the threshold \u03b3 for which the experiments are carried out. For example, database EM has 61 objects, 9 numeric attributes, and the threshold \u03b3 is set to 0.3. Categorical attributes and rows with missing values, if any, are removed from the datasets."}, {"heading": "4.3 Experiments", "text": "In Table 2 we show the computation time for finding the best \u0394-stable pattern (or patterns if they have the same value for \u0394-measure) for \u03b8-\u03a3\u03bf\u03c6\u03b9\u03b1 and for MinIntChange. The last algorithm is abbreviated as MIC. Since MinIntChange algorithm sometimes produces too many patterns, i.e., we do not have enough memory in our computer to check all of them, we interrupt the procedure and show the corresponding time in grey. We also show the number of the best patterns and the corresponding threshold \u2206. The support threshold \u03b8 for finding the best \u0394-stable patterns is also shown. For example, dataset CN contains 5362 best \u0394-stable patterns, all having a \u0394 of 2. To find all these patterns with a postfiltering, we should mine frequent patterns with a support threshold lower than 30 or 30105 = 30%. \u03b8-\u03a3\u03bf\u03c6\u03b9\u03b1 computes all these patterns in 2.4 seconds, while\n1http://funapp.cs.bilkent.edu.tr/DataSets/\nMinIntChange requires at least 28 seconds and the procedure was interrupted without continuation.\nAs we can see, \u03b8-\u03a3\u03bf\u03c6\u03b9\u03b1 is significantly faster than MinIntChange in all datasets. In the two datasets CA and PT, MinIntChange was stopped before computing all patterns and the runtime did not exceed the runtime of \u03b8-\u03a3\u03bf\u03c6\u03b9\u03b1. However, in both cases, MinIntChange achieved less than 10% of the required operations."}, {"heading": "5 Conclusion", "text": "In this paper we have introduced a new class of interestingness measures that are anti-monotonic w.r.t. a chain of projections. We have designed a new algorithm, called \u03b8-\u03a3\u03bf\u03c6\u03b9\u03b1, which is able to efficiently find the best patterns w.r.t. such interestingness measures for interval tuple data. The experiments reported in the paper are the witness of the efficiency of the \u03b8-\u03a3\u03bf\u03c6\u03b9\u03b1 algorithms compared to indirect approaches based on postfiltering. Many future research directions are possible. Different measures should be studied in combination with \u03b8-\u03a3\u03bf\u03c6\u03b9\u03b1. One of them is robustness, which is very close to stability and can be applied to nonbinary data. Moreover, the choice of a projection chain is not a simple one and can affect the algorithm efficiency. Thus, a deep study of suitable projection chains should be carried out.\nAcknowledgments: this research was supported by the Basic Research Program at\nthe National Research University Higher School of Economics (Moscow, Russia) and by the BioIntelligence project (France)."}], "references": [{"title": "Fast algorithms for mining association rules", "author": ["Rakesh Agrawal", "Ramakrishnan Srikant", "Others"], "venue": "In Proc. 20th int. conf. very large data bases, VLDB,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 1994}, {"title": "On Projections of Sequential Pattern Structures (with an application on care trajectories)", "author": ["Aleksey Buzmakov", "Elias Egho", "Nicolas Jay", "Sergei O. Kuznetsov", "Amedeo Napoli", "Chedy R\u00e4\u0131ssi"], "venue": "In Proc. 10th Int. Conf. Concept Lattices Their Appl.,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2013}, {"title": "Scalable Estimates of Concept Stability", "author": ["Aleksey Buzmakov", "Sergei O. Kuznetsov", "Amedeo Napoli"], "venue": "Form. Concept Anal.,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2014}, {"title": "Scaling up cosine interesting pattern discovery: A depth-first method", "author": ["Jie Cao", "Zhiang Wu", "Junjie Wu"], "venue": "Inf. Sci. (Ny).,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2014}, {"title": "Pattern Structures and Their Projections", "author": ["Bernhard Ganter", "Sergei O. Kuznetsov"], "venue": "Concept. Struct. Broadening Base,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2001}, {"title": "Formal Concept Analysis: Mathematical Foundations", "author": ["Bernhard Ganter", "Rudolf Wille"], "venue": "Springer, 1st edition,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 1999}, {"title": "Mining top-k frequent closed patterns without minimum support", "author": ["Jiawei Han", "Jianyong Wang", "Ying Lu", "P Tzvetkov"], "venue": "In Data Mining,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2002}, {"title": "Revisiting Numerical Pattern Mining with Formal Concept Analysis", "author": ["Mehdi Kaytoue", "Sergei O. Kuznetsov", "Amedeo Napoli"], "venue": "IJCAI", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2011}, {"title": "On Computing the Size of a Lattice and Related Decision Problems", "author": ["Sergei O. Kuznetsov"], "venue": null, "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2001}, {"title": "On stability of a formal concept", "author": ["Sergei O. Kuznetsov"], "venue": "Ann. Math. Artif. Intell.,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2007}, {"title": "Learning Closed Sets of Labeled Graphs for Chemical Applications", "author": ["Sergei O. Kuznetsov", "Mikhail V. Samokhin"], "venue": "Inductive Log. Program. SE - 12,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2005}, {"title": "Efficient Algorithms for Discovering Association Rules", "author": ["Heikki Mannila", "Hannu Toivonen", "A Inkeri Verkamo"], "venue": "In Knowl. Discov. Data Min.,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 1994}, {"title": "Efficient mining of all margin-closed itemsets with applications in temporal knowledge discovery and classification by compression", "author": ["Fabian Moerchen", "Michael Thies", "Alfred Ultsch"], "venue": "Knowl. Inf. Syst.,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2011}, {"title": "Efficient Mining of Association Rules Using Closed Itemset Lattices", "author": ["Nicolas Pasquier", "Yves Bastide", "Rafik Taouil", "Lotfi Lakhal"], "venue": "Inf. Syst.,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 1999}, {"title": "On succinct representation of knowledge community taxonomies with formal concept analysis", "author": ["Camille Roth", "Sergei A. Obiedkov", "Derrick G. Kourie"], "venue": "Int. J. Found. Comput. Sci.,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2008}, {"title": "Interesting pattern mining in multi-relational data", "author": ["Eirini Spyropoulou", "Tijl De Bie", "Mario Boley"], "venue": "Data Min. Knowl. Discov.,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2013}, {"title": "Finding Robust Itemsets under Subsampling", "author": ["Nikolaj Tatti", "Fabian Moerchen", "Toon Calders"], "venue": "ACM Trans. Database Syst.,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2014}, {"title": "Interesting Patterns", "author": ["Jilles Vreeken", "Nikolaj Tatti"], "venue": "Freq. Pattern Min.,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2014}, {"title": "Self-sufficient itemsets", "author": ["Geoffrey I. Webb"], "venue": "ACM Trans. Knowl. Discov. Data,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2010}, {"title": "Filtered-top-k association discovery", "author": ["Geoffrey I. Webb"], "venue": "Wiley Interdiscip. Rev. Data Min. Knowl. Discov.,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2011}, {"title": "Extracting redundancy-aware top-k patterns", "author": ["Dong Xin", "Hong Cheng", "Xifeng Yan", "Jiawei Han"], "venue": "In Proc. 12th ACM SIGKDD Int. Conf. Knowl. Discov. data Min. - KDD", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2006}, {"title": "Mining significant graph patterns by leap search", "author": ["Xifeng Yan", "Hong Cheng", "Jiawei Han", "Philip S. Yu"], "venue": "In Proc. 2008 ACM SIGMOD Int. Conf. Manag. data - SIGMOD", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2008}, {"title": "CloSpan: Mining Closed Sequential Patterns in Large Databases", "author": ["Xifeng Yan", "Jiawei Han", "Ramin Afshar"], "venue": "In Proc. SIAM Int\u2019l Conf. Data Min.,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2003}, {"title": "Mining itemset utilities from transaction databases", "author": ["Hong Yao", "Howard J Hamilton"], "venue": "Data Knowl. Eng.,", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2006}], "referenceMentions": [{"referenceID": 17, "context": "Interestingness measures were proposed to overcome the problem of combinatorial explosion of the number of valid patterns that can be discovered in a dataset [18].", "startOffset": 158, "endOffset": 162}, {"referenceID": 11, "context": ", the larger the pattern is the smaller the support is [12, 1].", "startOffset": 55, "endOffset": 62}, {"referenceID": 0, "context": ", the larger the pattern is the smaller the support is [12, 1].", "startOffset": 55, "endOffset": 62}, {"referenceID": 23, "context": "Many other measures can be mentioned such as utility constraint [24], pattern stability [10, 15], pattern leverage [19], margin closeness [13], MCCS [16], cosine interest [4], pattern robustness [17], etc.", "startOffset": 64, "endOffset": 68}, {"referenceID": 9, "context": "Many other measures can be mentioned such as utility constraint [24], pattern stability [10, 15], pattern leverage [19], margin closeness [13], MCCS [16], cosine interest [4], pattern robustness [17], etc.", "startOffset": 88, "endOffset": 96}, {"referenceID": 14, "context": "Many other measures can be mentioned such as utility constraint [24], pattern stability [10, 15], pattern leverage [19], margin closeness [13], MCCS [16], cosine interest [4], pattern robustness [17], etc.", "startOffset": 88, "endOffset": 96}, {"referenceID": 18, "context": "Many other measures can be mentioned such as utility constraint [24], pattern stability [10, 15], pattern leverage [19], margin closeness [13], MCCS [16], cosine interest [4], pattern robustness [17], etc.", "startOffset": 115, "endOffset": 119}, {"referenceID": 12, "context": "Many other measures can be mentioned such as utility constraint [24], pattern stability [10, 15], pattern leverage [19], margin closeness [13], MCCS [16], cosine interest [4], pattern robustness [17], etc.", "startOffset": 138, "endOffset": 142}, {"referenceID": 15, "context": "Many other measures can be mentioned such as utility constraint [24], pattern stability [10, 15], pattern leverage [19], margin closeness [13], MCCS [16], cosine interest [4], pattern robustness [17], etc.", "startOffset": 149, "endOffset": 153}, {"referenceID": 3, "context": "Many other measures can be mentioned such as utility constraint [24], pattern stability [10, 15], pattern leverage [19], margin closeness [13], MCCS [16], cosine interest [4], pattern robustness [17], etc.", "startOffset": 171, "endOffset": 174}, {"referenceID": 16, "context": "Many other measures can be mentioned such as utility constraint [24], pattern stability [10, 15], pattern leverage [19], margin closeness [13], MCCS [16], cosine interest [4], pattern robustness [17], etc.", "startOffset": 195, "endOffset": 199}, {"referenceID": 16, "context": ", support, robustness for generators [17], or upper bound constraint of MCCS [16]) are \u201cglobally anti-monotonic\u201d, i.", "startOffset": 37, "endOffset": 41}, {"referenceID": 15, "context": ", support, robustness for generators [17], or upper bound constraint of MCCS [16]) are \u201cglobally anti-monotonic\u201d, i.", "startOffset": 77, "endOffset": 81}, {"referenceID": 3, "context": "For example, for \u201clocally anti-monotonic\u201d cosine interest [4], the extension of a pattern Y consists in adding only attributes with a smaller support than any attribute from Y .", "startOffset": 58, "endOffset": 61}, {"referenceID": 14, "context": ", neither monotonic nor anti-monotonic) [15, 13, 17], or using heuristics such as leap search [22] or low probability of finding interesting patterns in the current branch [19].", "startOffset": 40, "endOffset": 52}, {"referenceID": 12, "context": ", neither monotonic nor anti-monotonic) [15, 13, 17], or using heuristics such as leap search [22] or low probability of finding interesting patterns in the current branch [19].", "startOffset": 40, "endOffset": 52}, {"referenceID": 16, "context": ", neither monotonic nor anti-monotonic) [15, 13, 17], or using heuristics such as leap search [22] or low probability of finding interesting patterns in the current branch [19].", "startOffset": 40, "endOffset": 52}, {"referenceID": 21, "context": ", neither monotonic nor anti-monotonic) [15, 13, 17], or using heuristics such as leap search [22] or low probability of finding interesting patterns in the current branch [19].", "startOffset": 94, "endOffset": 98}, {"referenceID": 18, "context": ", neither monotonic nor anti-monotonic) [15, 13, 17], or using heuristics such as leap search [22] or low probability of finding interesting patterns in the current branch [19].", "startOffset": 172, "endOffset": 176}, {"referenceID": 9, "context": "In particular, support, stability [10], margin-closeness [13] and robustness [17] are pattern independent measures.", "startOffset": 34, "endOffset": 38}, {"referenceID": 12, "context": "In particular, support, stability [10], margin-closeness [13] and robustness [17] are pattern independent measures.", "startOffset": 57, "endOffset": 61}, {"referenceID": 16, "context": "In particular, support, stability [10], margin-closeness [13] and robustness [17] are pattern independent measures.", "startOffset": 77, "endOffset": 81}, {"referenceID": 6, "context": "Thus various approaches for finding top-K patterns were introduced [7, 21, 20], with the basic idea to automatically adjust the threshold for a measure M.", "startOffset": 67, "endOffset": 78}, {"referenceID": 20, "context": "Thus various approaches for finding top-K patterns were introduced [7, 21, 20], with the basic idea to automatically adjust the threshold for a measure M.", "startOffset": 67, "endOffset": 78}, {"referenceID": 19, "context": "Thus various approaches for finding top-K patterns were introduced [7, 21, 20], with the basic idea to automatically adjust the threshold for a measure M.", "startOffset": 67, "endOffset": 78}, {"referenceID": 5, "context": "The formalization of the current approach is based on Formal Concept Analysis (FCA) [6] and pattern structures [5] which are introduced in Section 2.", "startOffset": 84, "endOffset": 87}, {"referenceID": 4, "context": "The formalization of the current approach is based on Formal Concept Analysis (FCA) [6] and pattern structures [5] which are introduced in Section 2.", "startOffset": 111, "endOffset": 114}, {"referenceID": 5, "context": "Formal Concept Analysis (FCA) is a formalism for knowledge discovery and data mining thanks to the design of concept lattices [6].", "startOffset": 126, "endOffset": 129}, {"referenceID": 13, "context": "It is also convenient for describing models of itemset mining, and, since [14], lattices of closed itemsets (i.", "startOffset": 74, "endOffset": 78}, {"referenceID": 4, "context": "For more complex data such as sequences and graphs one can use an extension of the basic model, called pattern structures [5].", "startOffset": 122, "endOffset": 125}, {"referenceID": 10, "context": "With pattern structures it is possible to define closed descriptions and to give a concise representation of association rules for different descriptions with a natural order (such as subgraph isomorphism order) [11, 8].", "startOffset": 212, "endOffset": 219}, {"referenceID": 7, "context": "With pattern structures it is possible to define closed descriptions and to give a concise representation of association rules for different descriptions with a natural order (such as subgraph isomorphism order) [11, 8].", "startOffset": 212, "endOffset": 219}, {"referenceID": 10, "context": "As shown in [11], descriptions closed in terms of counting inference (which is a standard data mining approach), such as closed graphs [23], are elements of pattern intents.", "startOffset": 12, "endOffset": 16}, {"referenceID": 22, "context": "As shown in [11], descriptions closed in terms of counting inference (which is a standard data mining approach), such as closed graphs [23], are elements of pattern intents.", "startOffset": 135, "endOffset": 139}, {"referenceID": 7, "context": "A possible instantiation of pattern structures is interval pattern structures introduced to support efficient processing of numerical data without binarization [8].", "startOffset": 160, "endOffset": 163}, {"referenceID": 0, "context": "For example, the value of m1 for g2 is known exactly, while the value of m2 is lying in [1, 2].", "startOffset": 88, "endOffset": 94}, {"referenceID": 1, "context": "For example, the value of m1 for g2 is known exactly, while the value of m2 is lying in [1, 2].", "startOffset": 88, "endOffset": 94}, {"referenceID": 0, "context": "For example, for g1 the value of m1 is 0, while for g6 it is 1, thus given the set {g1, g6}, the uncertainty of m1 in this set is [0, 1], i.", "startOffset": 130, "endOffset": 136}, {"referenceID": 0, "context": "m1 is [0, 1].", "startOffset": 6, "endOffset": 12}, {"referenceID": 0, "context": "For example, g 1 \u2293 g \u22c4 6 = \u3008[0, 1]; [0, 2]\u3009.", "startOffset": 28, "endOffset": 34}, {"referenceID": 1, "context": "For example, g 1 \u2293 g \u22c4 6 = \u3008[0, 1]; [0, 2]\u3009.", "startOffset": 36, "endOffset": 42}, {"referenceID": 0, "context": "Reciprocally, \u3008[0, 1]; [0, 2]\u3009 = {g1, g2, \u00b7 \u00b7 \u00b7 , g6}.", "startOffset": 15, "endOffset": 21}, {"referenceID": 1, "context": "Reciprocally, \u3008[0, 1]; [0, 2]\u3009 = {g1, g2, \u00b7 \u00b7 \u00b7 , g6}.", "startOffset": 23, "endOffset": 29}, {"referenceID": 8, "context": "For real datasets, the number of patterns can be very large, even computing the number of closed patterns is a #P-complete problem [9].", "startOffset": 131, "endOffset": 134}, {"referenceID": 9, "context": "Different measures were tested for selecting most interesting patterns, such as stability [10].", "startOffset": 90, "endOffset": 94}, {"referenceID": 0, "context": "m1 m2 g1 0 0 g2 0 [1, 2] g3 0 [1, 2] g4 0 2 g5 1 [0, 2] g6 1 [0, 2]", "startOffset": 18, "endOffset": 24}, {"referenceID": 1, "context": "m1 m2 g1 0 0 g2 0 [1, 2] g3 0 [1, 2] g4 0 2 g5 1 [0, 2] g6 1 [0, 2]", "startOffset": 18, "endOffset": 24}, {"referenceID": 0, "context": "m1 m2 g1 0 0 g2 0 [1, 2] g3 0 [1, 2] g4 0 2 g5 1 [0, 2] g6 1 [0, 2]", "startOffset": 30, "endOffset": 36}, {"referenceID": 1, "context": "m1 m2 g1 0 0 g2 0 [1, 2] g3 0 [1, 2] g4 0 2 g5 1 [0, 2] g6 1 [0, 2]", "startOffset": 30, "endOffset": 36}, {"referenceID": 1, "context": "m1 m2 g1 0 0 g2 0 [1, 2] g3 0 [1, 2] g4 0 2 g5 1 [0, 2] g6 1 [0, 2]", "startOffset": 49, "endOffset": 55}, {"referenceID": 1, "context": "m1 m2 g1 0 0 g2 0 [1, 2] g3 0 [1, 2] g4 0 2 g5 1 [0, 2] g6 1 [0, 2]", "startOffset": 61, "endOffset": 67}, {"referenceID": 0, "context": "(\u2205;\u22a4)[1] (4; \u30080; 2\u3009)[0.", "startOffset": 5, "endOffset": 8}, {"referenceID": 0, "context": "1 (234; \u30080; [1, 2]\u3009)[0.", "startOffset": 12, "endOffset": 18}, {"referenceID": 1, "context": "1 (234; \u30080; [1, 2]\u3009)[0.", "startOffset": 12, "endOffset": 18}, {"referenceID": 1, "context": "2 (1234; \u30080; [0, 2]\u3009)[0.", "startOffset": 13, "endOffset": 19}, {"referenceID": 1, "context": "3 (56; \u30081; [0, 2]\u3009)[0.", "startOffset": 11, "endOffset": 17}, {"referenceID": 0, "context": "2 (123456; \u3008[0, 1]; [0, 2]\u3009)[0.", "startOffset": 12, "endOffset": 18}, {"referenceID": 1, "context": "2 (123456; \u3008[0, 1]; [0, 2]\u3009)[0.", "startOffset": 20, "endOffset": 26}, {"referenceID": 0, "context": "Descriptions of 2 subsets of Ext(C) ({g4} and \u2205) are different from the intent of C, Int(C) = {m3}, while all other subsets of Ext(C) have a common set of attributes equal to \u30080; [1, 2]\u3009.", "startOffset": 179, "endOffset": 185}, {"referenceID": 1, "context": "Descriptions of 2 subsets of Ext(C) ({g4} and \u2205) are different from the intent of C, Int(C) = {m3}, while all other subsets of Ext(C) have a common set of attributes equal to \u30080; [1, 2]\u3009.", "startOffset": 179, "endOffset": 185}, {"referenceID": 16, "context": "Concept stability is closely related to the robustness of a closed pattern [17].", "startOffset": 75, "endOffset": 79}, {"referenceID": 9, "context": "The problem of computing concept stability is #P-complete [10].", "startOffset": 58, "endOffset": 62}, {"referenceID": 2, "context": "A fast computable stability estimate was proposed in [3], where it was shown that this estimate ranks concepts almost in the same way as stability does.", "startOffset": 53, "endOffset": 56}, {"referenceID": 0, "context": "The value \u2206(({g2, g3, g4}; \u30080; [1, 2]\u3009)) is equal to 2.", "startOffset": 31, "endOffset": 37}, {"referenceID": 1, "context": "The value \u2206(({g2, g3, g4}; \u30080; [1, 2]\u3009)) is equal to 2.", "startOffset": 31, "endOffset": 37}, {"referenceID": 0, "context": "Another example is \u2206((G; \u3008[0, 1]; [0, 2]\u3009)) = 2.", "startOffset": 26, "endOffset": 32}, {"referenceID": 1, "context": "Another example is \u2206((G; \u3008[0, 1]; [0, 2]\u3009)) = 2.", "startOffset": 34, "endOffset": 40}, {"referenceID": 12, "context": "\u0394-measure is related to the work of margin-closeness of an itemset [13].", "startOffset": 67, "endOffset": 71}, {"referenceID": 4, "context": "The approach proposed in this paper is based on projections introduced for reducing complexity of computing pattern lattices [5].", "startOffset": 125, "endOffset": 128}, {"referenceID": 0, "context": "The fixed set of this projection consists of {[0, 1], 1}\u00d7 {0, 2, [0, 2]}, i.", "startOffset": 46, "endOffset": 52}, {"referenceID": 1, "context": "The fixed set of this projection consists of {[0, 1], 1}\u00d7 {0, 2, [0, 2]}, i.", "startOffset": 65, "endOffset": 71}, {"referenceID": 0, "context": "Let us find the projection of (g2) \u22c4 = \u30080; [1, 2]\u3009 in a component-wise way: \u03c8m1[{0,1},{1}](0) = [0, 1], since 0 is allowed on the left endpoint of an interval but not allowed to be on the right endpoint of an interval; \u03c8m2[{0,2},{0,2}]([1, 2]) = [0, 2] since 1 is not allowed on the left endpoint of an interval.", "startOffset": 43, "endOffset": 49}, {"referenceID": 1, "context": "Let us find the projection of (g2) \u22c4 = \u30080; [1, 2]\u3009 in a component-wise way: \u03c8m1[{0,1},{1}](0) = [0, 1], since 0 is allowed on the left endpoint of an interval but not allowed to be on the right endpoint of an interval; \u03c8m2[{0,2},{0,2}]([1, 2]) = [0, 2] since 1 is not allowed on the left endpoint of an interval.", "startOffset": 43, "endOffset": 49}, {"referenceID": 0, "context": "Let us find the projection of (g2) \u22c4 = \u30080; [1, 2]\u3009 in a component-wise way: \u03c8m1[{0,1},{1}](0) = [0, 1], since 0 is allowed on the left endpoint of an interval but not allowed to be on the right endpoint of an interval; \u03c8m2[{0,2},{0,2}]([1, 2]) = [0, 2] since 1 is not allowed on the left endpoint of an interval.", "startOffset": 96, "endOffset": 102}, {"referenceID": 0, "context": "Let us find the projection of (g2) \u22c4 = \u30080; [1, 2]\u3009 in a component-wise way: \u03c8m1[{0,1},{1}](0) = [0, 1], since 0 is allowed on the left endpoint of an interval but not allowed to be on the right endpoint of an interval; \u03c8m2[{0,2},{0,2}]([1, 2]) = [0, 2] since 1 is not allowed on the left endpoint of an interval.", "startOffset": 236, "endOffset": 242}, {"referenceID": 1, "context": "Let us find the projection of (g2) \u22c4 = \u30080; [1, 2]\u3009 in a component-wise way: \u03c8m1[{0,1},{1}](0) = [0, 1], since 0 is allowed on the left endpoint of an interval but not allowed to be on the right endpoint of an interval; \u03c8m2[{0,2},{0,2}]([1, 2]) = [0, 2] since 1 is not allowed on the left endpoint of an interval.", "startOffset": 236, "endOffset": 242}, {"referenceID": 1, "context": "Let us find the projection of (g2) \u22c4 = \u30080; [1, 2]\u3009 in a component-wise way: \u03c8m1[{0,1},{1}](0) = [0, 1], since 0 is allowed on the left endpoint of an interval but not allowed to be on the right endpoint of an interval; \u03c8m2[{0,2},{0,2}]([1, 2]) = [0, 2] since 1 is not allowed on the left endpoint of an interval.", "startOffset": 246, "endOffset": 252}, {"referenceID": 0, "context": "\u03c8m1[{0,1},{1}]m2[{0,2},{0,2}](\u30080; [1, 2]\u3009) = \u3008[0, 1]; [0, 2]\u3009 .", "startOffset": 34, "endOffset": 40}, {"referenceID": 1, "context": "\u03c8m1[{0,1},{1}]m2[{0,2},{0,2}](\u30080; [1, 2]\u3009) = \u3008[0, 1]; [0, 2]\u3009 .", "startOffset": 34, "endOffset": 40}, {"referenceID": 0, "context": "\u03c8m1[{0,1},{1}]m2[{0,2},{0,2}](\u30080; [1, 2]\u3009) = \u3008[0, 1]; [0, 2]\u3009 .", "startOffset": 46, "endOffset": 52}, {"referenceID": 1, "context": "\u03c8m1[{0,1},{1}]m2[{0,2},{0,2}](\u30080; [1, 2]\u3009) = \u3008[0, 1]; [0, 2]\u3009 .", "startOffset": 54, "endOffset": 60}, {"referenceID": 0, "context": "(\u2205;\u22a4) (4; \u3008[0, 1]; 2\u3009) (1; \u3008[0, 1]; 0\u3009) (56; \u30081; [0, 2]\u3009) (123456; \u3008[0, 1]; [0, 2]\u3009)", "startOffset": 11, "endOffset": 17}, {"referenceID": 0, "context": "(\u2205;\u22a4) (4; \u3008[0, 1]; 2\u3009) (1; \u3008[0, 1]; 0\u3009) (56; \u30081; [0, 2]\u3009) (123456; \u3008[0, 1]; [0, 2]\u3009)", "startOffset": 28, "endOffset": 34}, {"referenceID": 1, "context": "(\u2205;\u22a4) (4; \u3008[0, 1]; 2\u3009) (1; \u3008[0, 1]; 0\u3009) (56; \u30081; [0, 2]\u3009) (123456; \u3008[0, 1]; [0, 2]\u3009)", "startOffset": 49, "endOffset": 55}, {"referenceID": 0, "context": "(\u2205;\u22a4) (4; \u3008[0, 1]; 2\u3009) (1; \u3008[0, 1]; 0\u3009) (56; \u30081; [0, 2]\u3009) (123456; \u3008[0, 1]; [0, 2]\u3009)", "startOffset": 68, "endOffset": 74}, {"referenceID": 1, "context": "(\u2205;\u22a4) (4; \u3008[0, 1]; 2\u3009) (1; \u3008[0, 1]; 0\u3009) (56; \u30081; [0, 2]\u3009) (123456; \u3008[0, 1]; [0, 2]\u3009)", "startOffset": 76, "endOffset": 82}, {"referenceID": 0, "context": "pattern order and it allows for efficient generation of patterns with support larger than a threshold [1, 12, 14].", "startOffset": 102, "endOffset": 113}, {"referenceID": 11, "context": "pattern order and it allows for efficient generation of patterns with support larger than a threshold [1, 12, 14].", "startOffset": 102, "endOffset": 113}, {"referenceID": 13, "context": "pattern order and it allows for efficient generation of patterns with support larger than a threshold [1, 12, 14].", "startOffset": 102, "endOffset": 113}, {"referenceID": 3, "context": ", the cosine interest of an itemset, which is only locally antimonotonic [4].", "startOffset": 73, "endOffset": 76}, {"referenceID": 1, "context": "any projection [2].", "startOffset": 15, "endOffset": 18}, {"referenceID": 16, "context": "one can prove that robustness of closed patterns from [17] is also anti-monotonic w.", "startOffset": 54, "endOffset": 58}, {"referenceID": 0, "context": "This projection allows only for one pattern \u3008[0, 1]; [0, 2]\u3009, i.", "startOffset": 45, "endOffset": 51}, {"referenceID": 1, "context": "This projection allows only for one pattern \u3008[0, 1]; [0, 2]\u3009, i.", "startOffset": 53, "endOffset": 59}, {"referenceID": 1, "context": ", any possible interval of the first component and only one interval [0,2] for the second component.", "startOffset": 69, "endOffset": 74}, {"referenceID": 13, "context": "Closed frequent itemsets are widely used as a condensed representation of all frequent itemsets since [14].", "startOffset": 102, "endOffset": 106}, {"referenceID": 4, "context": "However, the extents of \u03c8(P) are extents of P [5].", "startOffset": 46, "endOffset": 49}, {"referenceID": 4, "context": "By properties of a projection, an extent of \u03c8(P) is an extent of P [5].", "startOffset": 67, "endOffset": 70}, {"referenceID": 0, "context": "At the beginning \u03c80(DI) contains only one element corresponding to pattern extent 123456 (a short cut for {g1, g2, g3, g4, g5, g6}) with a description \u3008[0, 1]; [0, 2]\u3009.", "startOffset": 152, "endOffset": 158}, {"referenceID": 1, "context": "At the beginning \u03c80(DI) contains only one element corresponding to pattern extent 123456 (a short cut for {g1, g2, g3, g4, g5, g6}) with a description \u3008[0, 1]; [0, 2]\u3009.", "startOffset": 160, "endOffset": 166}, {"referenceID": 1, "context": "Then, in \u03c81(G, (DI ,\u2293), \u03b4) possible preimages of 123456 are patterns with descriptions \u30080; [0, 2]\u3009 and \u30081; [0, 2]\u3009 given by pattern extents 1234 and 56, respectively.", "startOffset": 91, "endOffset": 97}, {"referenceID": 1, "context": "Then, in \u03c81(G, (DI ,\u2293), \u03b4) possible preimages of 123456 are patterns with descriptions \u30080; [0, 2]\u3009 and \u30081; [0, 2]\u3009 given by pattern extents 1234 and 56, respectively.", "startOffset": 107, "endOffset": 113}, {"referenceID": 0, "context": "The pattern extents 123456 and 56 have no preimages for the transition \u03c81 \u2192 \u03c82, while the pattern extent 1234 has two preimages with descriptions \u30080; [0, 1]\u3009 and \u30080; [1, 2]\u3009 for this projection, which correspond to pattern extents 1 and 234.", "startOffset": 150, "endOffset": 156}, {"referenceID": 0, "context": "The pattern extents 123456 and 56 have no preimages for the transition \u03c81 \u2192 \u03c82, while the pattern extent 1234 has two preimages with descriptions \u30080; [0, 1]\u3009 and \u30080; [1, 2]\u3009 for this projection, which correspond to pattern extents 1 and 234.", "startOffset": 166, "endOffset": 172}, {"referenceID": 1, "context": "The pattern extents 123456 and 56 have no preimages for the transition \u03c81 \u2192 \u03c82, while the pattern extent 1234 has two preimages with descriptions \u30080; [0, 1]\u3009 and \u30080; [1, 2]\u3009 for this projection, which correspond to pattern extents 1 and 234.", "startOffset": 166, "endOffset": 172}, {"referenceID": 14, "context": "The known approaches use postfiltering to mine such kind of patterns [15, 13, 2, 17].", "startOffset": 69, "endOffset": 84}, {"referenceID": 12, "context": "The known approaches use postfiltering to mine such kind of patterns [15, 13, 2, 17].", "startOffset": 69, "endOffset": 84}, {"referenceID": 1, "context": "The known approaches use postfiltering to mine such kind of patterns [15, 13, 2, 17].", "startOffset": 69, "endOffset": 84}, {"referenceID": 16, "context": "The known approaches use postfiltering to mine such kind of patterns [15, 13, 2, 17].", "startOffset": 69, "endOffset": 84}, {"referenceID": 7, "context": "Recently it was also shown that it is more efficient to mine interval tuple data without binarization [8].", "startOffset": 102, "endOffset": 105}], "year": 2015, "abstractText": "In pattern mining, the main challenge is the exponential explosion of the set of patterns. Typically, to solve this problem, a constraint for pattern selection is introduced. One of the first constraints proposed in pattern mining is support (frequency) of a pattern in a dataset. Frequency is an anti-monotonic function, i.e., given an infrequent pattern, all its superpatterns are not frequent. However, many other constraints for pattern selection are not (anti-)monotonic, which makes it difficult to generate patterns satisfying these constraints. In this paper we introduce the notion of projection-antimonotonicity and \u03b8-\u03a3\u03bf\u03c6\u03b9\u03b1 algorithm that allows efficient generation of the best patterns for some nonmonotonic constraints. In this paper we consider stability and \u0394-measure, which are nonmonotonic constraints, and apply them to interval tuple datasets. In the experiments, we compute best interval tuple patterns w.r.t. these measures and show the advantage of our approach over postfiltering approaches.", "creator": "LaTeX with hyperref package"}}}