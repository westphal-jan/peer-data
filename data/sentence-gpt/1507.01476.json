{"id": "1507.01476", "review": {"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "6-Jul-2015", "title": "Semi-Proximal Mirror-Prox for Nonsmooth Composite Minimization", "abstract": "We propose a new first-order optimisation algorithm to solve high-dimensional non-smooth composite minimisation problems. Typical examples of such problems have an objective that decomposes into a non-smooth empirical risk part and a non-smooth regularisation penalty. The proposed algorithm, called Semi-Proximal Mirror-Prox, leverages the Fenchel-type representation of one part of the objective while handling the other part of the objective via linear minimization over the domain-specific domain-specific domain-specific domain-specific domain-specific domain-specific domain-specific domain-specific domain-specific domain-specific domain-specific domain-specific domain-specific domain-specific domain-specific domain-specific domain-specific domain-specific domain-specific domain-specific domain-specific domain-specific domain-specific domain-specific domain-specific domain-specific domain-specific domain-specific domain-specific domain-specific domain-specific domain-specific domain-specific domain-specific domain-specific domain-specific domain-specific domain-specific domain-specific domain-specific domain-specific domain-specific domain-specific domain-specific domain-specific domain-specific domain-specific domain-specific domain-specific domain-specific domain-specific domain-specific domain-specific domain-specific domain-specific domain-specific domain-specific domain-specific domain-specific domain-specific domain-specific domain-specific domain-specific domain-specific domain-specific domain-specific domain-specific domain-specific domain-specific domain-specific domain-specific domain-specific domain-specific domain-specific domain-specific domain-specific domain-specific domain-specific domain-specific domain-specific domain-specific domain-specific domain-specific domain-specific domain-specific domain-specific domain-specific domain-specific domain-specific domain-specific domain-specific domain-specific domain-specific domain-specific domain-specific domain-specific domain-specific domain-specific domain-specific domain-specific domain-specific domain-specific domain-specific domain-specific domain-specific domain-specific domain-specific domain-specific domain-specific domain-specific domain-specific domain-specific domain-specific domain-specific domain-specific domain-specific domain-specific domain-specific domain-specific domain-specific domain-specific domain-specific domain-specific domain-specific domain-specific domain-specific domain-specific domain-specific domain-specific domain-specific domain-specific domain-specific domain-specific domain-specific domain-specific domain-specific domain-specific domain-specific domain", "histories": [["v1", "Mon, 6 Jul 2015 14:21:21 GMT  (110kb,D)", "http://arxiv.org/abs/1507.01476v1", null]], "reviews": [], "SUBJECTS": "math.OC cs.LG", "authors": ["niao he", "za\u00efd harchaoui"], "accepted": true, "id": "1507.01476"}, "pdf": {"name": "1507.01476.pdf", "metadata": {"source": "CRF", "title": null, "authors": ["Zaid Harchaoui"], "emails": ["nhe6@gatech.edu", "zaid.harchaoui@inria.fr"], "sections": [{"heading": "1 Introduction", "text": "A wide range of machine learning and signal processing problems can be formulated as the minimization of a composite objective:\nmin x\u2208X\nF (x) := f(x) + \u2016Bx\u2016 (1)\nwhere X is closed and convex, f is convex and can be either smooth, or nonsmooth yet enjoys a particular structure. The term \u2016Bx\u2016 defines a regularization penalty through a norm \u2016 \u00b7 \u2016, and x 7\u2192 Bx a linear mapping on a closed convex set X. The function f usually corresponds to an empirical risk, that is an empirical average of a possibly non-smooth loss function evaluated on a set of data-points, while x encodes the learning parameters. All in all, the objective F has a doubly non-smooth structure.\nIn many situations, the objective function F of interest enjoys a favorable structure, namely a so-called Fenchel-type representation [7, 12, 14]:\nf(x) = max z\u2208Z\n{\u3008x,Az\u3009 \u2212 \u03c8(z)} (2)\nwhere Z is convex compact subset of a Euclidean space, and \u03c8(\u00b7) is a convex function. Sec. 4 will give several examples of such situations. Fenchel-type representations can then be leveraged to use first-order optimisation algorithms.\n\u2217The authors would like to thank Anatoli Juditsky and Arkadi Nemirovski for fruitful discussions. This work was supported by the NSF Grant CMMI-1232623, the LabEx Persyval-Lab (ANR-11-LABX-0025), the project Titan (CNRS-Mastodons), the project Macaron (ANR-14-CE23-0003-01), the MSR-Inria joint centre, and the Moore-Sloan Data Science Environment at NYU.\nar X\niv :1\n50 7.\n01 47\n6v 1\n[ m\nat h.\nO C\n] 6\nJ ul\nA simple first option to minimise F is using the so-called Nesterov smoothing technique [21] along with a proximal gradient algorithm [23], assuming that the proximal operator associated with X is computationally tractable and cheap to compute. However, this is certainly not the case when considering problems with norms acting in the spectral domain of high-dimensional matrices, such as the matrix nuclear-norm [13] and structured extensions thereof [6, 2]. In the latter situation, another option is to use a smoothing technique now with a conditional gradient or Frank-Wolfe algorithm to minimize F , assuming that a a linear minimization oracle associated with X is cheaper to compute than the proximal operator [7, 15, 24]. Neither option takes advantage of the composite structure of the objective (1) or handles the case when the linear mapping B is nontrivial.\nContributions Our goal in this paper is to propose a new first-order optimization algorithm, called SemiProximal Mirror-Prox , designed to solve the difficult non-smooth composite optimisation problem (1), which does not require the exact computation of proximal operators. Instead, the Semi-Proximal Mirror-Prox relies upon i) Fenchel-type representability of f ; ii) Linear minimization oracle associated with \u2016\u00b7\u2016 in the domain X. While the Fenchel-type representability of f allows to cure the non-smoothness of f , the linear minimisation over the domain X allows to tackle the non-smooth regularisation penalty \u2016 \u00b7 \u2016. We establish the theoretical convergence rate of Semi-Proximal Mirror-Prox, which exhibits the optimal complexity bounds, i.e. O(1/ 2), for the number of calls to linear minimization oracle. Furthermore, Semi-Proximal Mirror-Prox generalizes previously proposed approaches and improves upon them in special cases:\n1. Case B \u2261 0: Semi-Proximal Mirror-Prox does not require assumptions on favorable geometry of dual domains Z or simplicity of \u03c8(\u00b7) in (2).\n2. Case B = I: Semi-Proximal Mirror-Prox is competitive with previously proposed approaches [16, 24] based on smoothing techniques.\n3. Case of non-trivial B: Semi-Proximal Mirror-Prox is the first proximal-free or conditional-gradient-type optimization algorithm for (1).\nRelated work The Semi-Proximal Mirror-Prox algorithm belongs the family of conditional gradient algorithms, whose most basic instance is the Frank-Wolfe algorithm for constrained smooth optimization using a linear minimization oracle; see [13, 1, 4]. Recently, in [7, 14], the authors consider constrained non-smooth optimisation when the domain Z has a \u201cfavorable geometry\u201d, i.e. the domain is amenable to linear minimisation (favorable geometry), and establish a complexity bound with O(1/ 2) calls to the linear minimization oracle. Recently, in [16], a method called conditional gradient sliding is proposed to solve similar problems, using a smoothing technique, with a complexity bound in O(1/ 2) for the calls to the linear minimization oracle (LMO) and additionally a O(1/ ) bound for the linear operator evaluations. Actually, this O(1/ 2) bound for the LMO complexity can be shown to be indeed optimal for conditional-gradient-type or LMO-based algorithms, when solving general1 non-smooth convex problems [15].\nHowever, these previous approaches are appropriate for objective with a non-composite structure. When applied to our problem (1), the smoothing would be applied to the objective taken as a whole, ignoring its composite structure. Conditional-gradient-type algorithms were recently proposed for composite objectives [8, 10, 26, 24, 17], but cannot be applied for our problem. In [10], f is smooth and B is identity matrix, whereas in [24], f is non-smooth and B is also the identity matrix. The proposed Semi-Proximal MirrorProx can be seen as a blend of the successful components resp. of the Composite Conditional Gradient algorithm [10] and the Composite Mirror-Prox [12], that enjoys the optimal complexity bound O(1/ 2) on the total number of LMO calls, yet solves a broader class of convex problems than previously considered.\n1Related research extended such approaches to stochastic or online settings [11, 9, 16]; such settings are beyond the scope of this work.\nOutline The paper is organized as follows. In Section 2, we describe the norm-regularized nonsmooth problem of interest and illustrate it with several examples. In Section 3, we present the conditional gradient type method based on an inexact Mirror-Prox framework for structured variational inequalities. In Section 4, we present promising experimental results showing the interest of the approach in comparison to competing methods, resp. on a collaborative filtering for movie recommendation and link prediction for social network analysis applications."}, {"heading": "2 Framework and assumptions", "text": "We present here our theoretical framework, which hinges upon a smooth convex-concave saddle point reformulation of the norm-regularized non-smooth minimization (3). We shall use the following notations throughout the paper. For a given norm \u2016 \u00b7 \u2016, we define the dual norm as \u2016s\u2016\u2217 = max\u2016x\u2016\u22641\u3008s, x\u3009. For any x \u2208 Rm\u00d7n, \u2016x\u20162 = \u2016x\u2016F = ( \u2211m i=1 \u2211n j=1 |xij |2)1/2.\nProblem We consider the composite minimization problem\nOpt = min x\u2208X\nf(x) + \u2016Bx\u2016 (3)\nwhere X is a closed convex set in the Euclidean space Ex; x 7\u2192 Bx is a linear mapping from X to Y (\u2283 BX), where Y is a closed convex set in the Euclidean space Ey. We make two important assumptions on the function f and the norm \u2016 \u00b7 \u2016 defining the regularization penalty, explained below.\nFenchel-type Representation The non-smoothness of f can be challenging to tackle. However, in many cases of interest, the function f enjoys a favorable structure that allows to tackle it with smoothing techniques. We assume that the norm f(x) is a non-smooth convex function given by\nf(x) = max z\u2208Z \u03a6(x, z) (4)\na where \u03a6(x, z) is a smooth convex-concave function and Z is a convex and compact set in the Euclidean space Ez. Such representation was introduced and developed in [7, 12, 14], for the purpose of non-smooth optimisation. Fenchel-type representability can be interpreted as a general form of the smoothing-favorable structure of non-smooth functions used in the Nesterov smoothing technique [21]. Representations of this type are readily available for a wide family of \u201cwell-structured\u201d nonsmooth functions f ; see Sec. 4 for examples.\nComposite Linear Minimization Oracle Proximal-gradient-type algorithms require the computation of a proximal operator at each iteration, i.e.\nmin y\u2208Y\n{ 1\n2 \u2016y\u201622 + \u3008\u03b7, y\u3009+ \u03b1\u2016y\u2016\n} . (5)\nFor several cases of interest, described below, the computation of the proximal operator can be expensive or intractable. A classical example is the nuclear norm, whose proximal operator boils down to singular value thresholding, therefore requiring a full singular value decomposition. In contrast to the proximal operator, the linear minimization oracle can much cheaper. The linear minimization oracle (LMO) is a routine which, given an input \u03b1 > 0 and \u03b7 \u2208 Ey, returns a point\nmin y\u2208Y\n{\u3008\u03b7, y\u3009+ \u03b1\u2016y\u2016} (6)\nIn the case of the nuclear-norm, the LMO only requires the computation of the top pair of eigenvectors/eigenvalues, which is an order of magnitude fast in time-complexity.\nSaddle Point Reformulation. The crux of our approach is a smooth convex-concave saddle point reformulation of (3). After massaging the saddle-point reformulation, we consider the variational inequality associated with the obtained saddle-point problem. For a constrained smooth optimisation problem, the corresponding variational inequality provides the sufficient and necessary condition for an optimal solution to the problem [3, 4]. For non-smooth optimization problems, the corresponding variational inequality is directly related to the accuracy certificate used to guarantee the accuracy of a solution to the optimisation problem; see Sec. 2.1 in [12] and [19]. We shall present then an algorithm to solve the variational inequality established below, that leverages its particular structure.\nAssuming that f admits a Fenchel-type representation (4), we rewrite (3) in epigraph form\nmin x\u2208X,y\u2208Y,\u03c4\u2265\u2016y\u2016 max z\u2208Z\n{\u03a6(x, z) + \u03c4 : y = Bx} ,\nwhich, with a properly selected \u03c1 > 0, can be further approximated by\nO\u0302pt = min x\u2208X,y\u2208Y,\u03c4\u2265\u2016y\u2016 max z\u2208Z\n{\u03a6(x, z) + \u03c4 + \u03c1\u2016y \u2212 Bx\u20162} (7)\n= min x\u2208X,y\u2208Y,\u03c4\u2265\u2016y\u2016 max z\u2208Z,\u2016w\u20162\u22641\n{\u03a6(x, z) + \u03c4 + \u03c1\u3008y \u2212 Bx,w\u3009} . (8)\nIn fact, when \u03c1 is large enough one can always guarantee O\u0302pt = Opt. It is indeed sufficient to set \u03c1 as the Lipschitz constant of \u2016 \u00b7 \u2016 with respect to \u2016 \u00b7 \u20162.\nIntroduce the variables u := [x, y; z, w] and v := \u03c4 . The variational inequality associated with the above saddle point problem is fully described by the domain\nX+ = {x+ = [u; v] : x \u2208 X, y \u2208 Y, z \u2208 Z, \u2016w\u20162 \u2264 1, \u03c4 \u2265 \u2016y\u2016}\nand the monotone vector field F (x+ = [u; v]) = [Fu(u);Fv] ,\nwhere\nFu u =  x y z w   =  \u2207x\u03a6(x, z)\u2212 \u03c1BTw \u03c1w \u2212\u2207z\u03a6(x, z) \u03c1(Bx\u2212 y)  , Fv(v = \u03c4) = 1. In the next section, we present an efficient algorithm to solve this type of variational inequality, which enjoys a particular structure; we call such an inequality semi-structured."}, {"heading": "3 Semi-Proximal Mirror-Prox for Semi-structured Variational In-", "text": "equalities\nSemi-structured variational inequalities (Semi-VI) enjoy a particular product structure, that allows to get the best of two worlds, namely the proximal setup (where the proximal operator can be computed) and the LMO setup (where the linear minimization oracle can be computed). Basically, the domain X is decomposed as a Cartesian product over two sets X = X1 \u00d7X2, such that X1 admits a proximal-mapping while X2 admits a linear minimization oracle. We now describe the main theoretical and algorithmic components of the SemiProximal Mirror-Prox algorithm, resp. in Sec. 3.1 and in Sec. 3.2, and finally describe the overall algorithm in Sec. 3.3."}, {"heading": "3.1 Composite Mirror-Prox with Inexact Prox-mappings", "text": "We first present a new algorithm, which can be seen as an extension of the composite Mirror Prox algorithm, denoted CMP for brevity, that allows inexact computation of the Prox-mappings, and can solve a broad class of variational inequalites. The original Mirror Prox algorithm was introduced in [18], and was extended to composite minimization in [12] assuming exact computations of Prox-mappings.\nStructured Variational Inequalities. We consider the variational inequality VI(X,F ):\nFind x\u2217 \u2208 X : \u3008F (x), x\u2212 x\u2217\u3009 \u2265 0,\u2200x \u2208 X\nwith domain X and operator F that satisfy the assumptions (A.1)\u2013(A.4) below.\n(A.1) Set X \u2282 Eu \u00d7 Ev is closed convex and its projection PX = {u : x = [u; v] \u2208 X} \u2282 U , where U is convex and closed, Eu, Ev are Euclidean spaces;\n(A.2) The function \u03c9(\u00b7) : U \u2192 R is continuously differentiable and also 1-strongly convex w.r.t. some norm2 \u2016 \u00b7 \u2016. This defines the Bregman distance\nVu(u \u2032) = \u03c9(u\u2032)\u2212 \u03c9(u)\u2212 \u3008\u03c9\u2032(u), u\u2032 \u2212 u\u3009 \u2265 1\n2 \u2016u\u2032 \u2212 u\u20162 .\n(A.3) The operator F (x = [u, v]) : X \u2192 Eu \u00d7 Ev is monotone and of form F (u, v) = [Fu(u);Fv] with Fv \u2208 Ev being a constant and Fu(u) \u2208 Eu satisfying the condition\n\u2200u, u\u2032 \u2208 U : \u2016Fu(u)\u2212 Fu(u\u2032)\u2016\u2217 \u2264 L\u2016u\u2212 u\u2032\u2016+M\nfor some L <\u221e,M <\u221e;\n(A.4) The linear form \u3008Fv, v\u3009 of [u; v] \u2208 Eu \u00d7 Ev is bounded from below on X and is coercive on X w.r.t. v: whenever [ut; vt] \u2208 X, t = 1, 2, ... is a sequence such that {ut}\u221et=1 is bounded and \u2016vt\u20162 \u2192 \u221e as t\u2192\u221e, we have \u3008Fv, vt\u3009 \u2192 \u221e, t\u2192\u221e.\n-Prox-mapping In the Composite Mirror Prox with exact Prox-mappings [12], the quality of an iterate, in the course of the algorithm, is measured through the so-called dual gap function\nVI(x \u2223\u2223X,F ) = sup\ny\u2208X \u3008F (y), x\u2212 y\u3009 .\nWe give in Appendix A a refresher on dual gap functions, for the reader\u2019s convenience. We shall establish the complexity bounds in terms this dual gap function for our algorithm, which directly provides an accuracy certificate along the iterations. However, we first need to define what we mean by an inexact prox-mapping. Inexact proximal mapping were recently considered in the context of accelerated proximal gradient algorithms [25]. The definition we give below is more general, allowing for non-Euclidean proximal-mappings.\nWe introduce here the notion of -prox-mapping ( \u2265 0). For \u03be = [\u03b7; \u03b6] \u2208 Eu\u00d7Ev and x = [u; v] \u2208 X, let us define the subset P x(\u03be) of X as\nP x(\u03be) = {x\u0302 = [u\u0302; v\u0302] \u2208 X : \u3008\u03b7 + \u03c9\u2032(u\u0302)\u2212 \u03c9\u2032(u), u\u0302\u2212 s\u3009+ \u3008\u03b6, v\u0302 \u2212 w\u3009 \u2264 \u2200[s;w] \u2208 X}.\nWhen = 0, this reduces to the exact prox-mapping, in the usual setting, that is\nPx(\u03be) = Argmin [s;w]\u2208X\n{\u3008\u03b7, s\u3009+ \u3008\u03b6, w\u3009+ Vu(s)} .\nWhen > 0, this yields our definition of an inexact prox-mapping, with inexactness parameter . Note that for any \u2265 0, the set P x(\u03be = [\u03b7; \u03b3Fv]) is well defined whenever \u03b3 > 0. The Composite Mirror-Prox with Inexact Prox-mappings is outlined in Algorithm 1.\n2There is a slight abuse of notation here. The norm here is not the same as the one in problem (3)\nAlgorithm 1 Composite Mirror Prox Algorithm (CMP) for VI(X,F )\nInput: stepsizes \u03b3t > 0, inexactness t \u2265 0, t = 1, 2, . . . Initialize x1 = [u1; v1] \u2208 X for t = 1, 2, . . . , T do\nyt := [u\u0302t; v\u0302t] \u2208 P txt (\u03b3tF (x t)) = P txt (\u03b3t[Fu(u t);Fv]) xt+1 := [ut+1; vt+1] \u2208 P txt (\u03b3tF (y t)) = P txt (\u03b3t[Fu(u\u0302 t);Fv])\n(9)\nend for Output: xT := [u\u0304T ; v\u0304T ] = ( \u2211T t=1 \u03b3t) \u22121\u2211T t=1 \u03b3ty t\nNote that this composite version of Mirror Prox algorithm works essentially as if there were no vcomponent at all. Therefore, the proposed algorithm is a not-trivial extension of the Composite Mirror-Prox with exact prox-mappings, both from a theoretical and algorithmic point of views. We establish below the theoretical convergence rate; see Appendix for the proof.\nTheorem 3.1. Assume that the sequence of step-sizes (\u03b3t) in the CMP algorithm satisfy\n\u03c3t := \u03b3t\u3008Fu(u\u0302t)\u2212 Fu(ut), u\u0302t \u2212 ut+1\u3009 \u2212 Vu\u0302t(ut+1)\u2212 Vut(u\u0302t) \u2264 \u03b32tM2 , t = 1, 2, . . . , T . (10)\nThen, denoting \u0398[X] = sup[u;v]\u2208X Vu1(u), for a sequence of inexact prox-mappings with inexactness t \u2265 0, we have\nVI(x\u0304T \u2223\u2223X,F ) := sup\nx\u2208X \u3008F (x), x\u0304T \u2212 x\u3009 \u2264\n\u0398[X] +M2 \u2211T t=1\u03b3 2 t + 2 \u2211T t=1 t\u2211T\nt=1 \u03b3t . (11)\nRemarks Note that the assumption on the sequence of step-sizes (\u03b3t) is clearly satisfied when \u03b3t \u2264 ( \u221a 2L)\u22121. When M = 0, it is satisfied as long as \u03b3t \u2264 L\u22121.\nCorollary 3.1. Assume further that X = X1 \u00d7X2, and let F be the monotone vector field associated with the saddle point problem\nSadVal = min x1\u2208X1 max x2\u2208X2\n\u03a6(x1, x2), (12)\ntwo induced convex optimization problems Opt(P ) = minx1\u2208X1 [ \u03a6(x1) = supx2\u2208X2 \u03a6(x 1, x2) ]\n(P ) Opt(D) = maxx2\u2208X2 [ \u03a6(x2) = infx1\u2208X1 \u03a6(x 1, x2) ] (D) (13)\nwith convex-concave locally Lipschitz continuous cost function \u03a6. In addition, assuming that problem (P ) in (13) is solvable with optimal solution x1\u2217 and denoting by x\u0304 1 T the projection of x\u0304T \u2208 X = X1 \u00d7X2 onto X1, we have\n\u03a6(x\u03041T )\u2212Opt(P ) \u2264 [\u2211T\nt=1 \u03b3t\n]\u22121 [ \u0398[{x1\u2217} \u00d7X2] +M2 \u2211T t=1 \u03b32t + 2 \u2211T t=1 t ] . (14)\nThe theoretical convergence rate established in Theorem 3.1 and Corollary 3.1 generalizes the previous result established in Corollary 3.1 in [12] for CMP with exact prox-mappings. Indeed, when exact proxmappings are used, we recover the result of [12]. When inexact prox-mappings are used, the errors due to the inexactness of the prox-mappings accumulates and is reflected in the bound (34) and (14)."}, {"heading": "3.2 Composite Conditional Gradient", "text": "We now turn to a variant of the composite conditional gradient algorithm, denoted CCG, tailored for a particular class of problems, which we call smooth semi-linear problems. The composite conditional gradient algorithm was introduced in [10]. We present an extension here which will turn to be especially tailored for sub-problems that will be solved in Sec. 3.3.\nMinimizing Smooth Semi-linear Problems. We consider the smooth semi-linear problem\nmin x=[u;v]\u2208X\n{ \u03c6+(u, v) = \u03c6(u) + \u3008\u03b8, v\u3009 } (15)\nrepresented by the pair (X;\u03c6+) such that the following assumptions are satisfied. We assume that\ni) X \u2282 Eu \u00d7 Ev is closed convex and its projection PX \u2282 U , where U is convex and compact;\nii) \u03c6(u) : U \u2192 R be a convex continuously differentiable function, and there exists 1 < \u03ba \u2264 2 and L < \u221e such that\n\u03c6(u\u2032) \u2264 \u03c6(u) + \u3008\u2207\u03c6(u), u\u2032 \u2212 u\u3009+ L0 \u03ba \u2016u\u2032 \u2212 u\u2016\u03ba \u2200u, u\u2032 \u2208 U ; (16)\niii) \u03b8 \u2208 Ev be such that every linear function on Eu \u00d7 Ev of the form\n[u; v] 7\u2192 \u3008\u03b7, u\u3009+ \u3008\u03b8, v\u3009 (17)\nwith \u03b7 \u2208 Eu attains its minimum on X at some point x[\u03b7] = [u[\u03b7]; v[\u03b7]]; we have at our disposal a Composite Linear Minimization Oracle (LMO) which, given on input \u03b7 \u2208 Eu, returns x[\u03b7].\nAlgorithm 2 Composite Conditional Gradient Algorithm CCG(X,\u03c6(\u00b7), \u03b8; ) Input: accuracy > 0 and \u03b3t = 2/(t+ 1), t = 1, 2, . . . Initialize x1 = [u1; v1] \u2208 X and for t = 1, 2, . . . do\nCompute \u03b4t = \u3008gt, ut \u2212 ut[gt]\u3009+ \u3008\u03b8, vt \u2212 vt[gt]\u3009, where gt = \u2207\u03c6(ut); if \u03b4t \u2264 then\nReturn xt = [ut; vt] else\nUpdate xt+1 = [ut+1; vt+1] \u2208 X such that \u03c6+(xt+1) \u2264 \u03c6+ (xt + \u03b3t(xt[gt]\u2212 xt)) end if\nend for\nThe algorithm is outlined in Algorithm 2. Note that CCG works essentially as if there were no vcomponent at all. The CCG algorithm enjoys a convergence rate in O(t\u2212(\u03ba\u22121)) in the evaluations of the function \u03c6+, and the accuracy certificates (\u03b4t) enjoy the same rate O(t\n\u2212(\u03ba\u22121)) as well, for solving problems of type (15). See Appendix for details and the proof.\nProposition 3.1. Denote D the \u2016 \u00b7 \u2016-diameter of U . When solving problems of type (15), the sequence of iterates (xt) of CCG satisfies\nt := \u03c6 +(xt)\u2212min x\u2208X \u03c6+(x) \u2264 2L0D\n\u03ba\n\u03ba(3\u2212 \u03ba)\n( 2\nt+ 1\n)\u03ba\u22121 , t \u2265 2 (18)\nIn addition, the accuracy certificates (\u03b4t) satisfy\nmin 1\u2264s\u2264t\n\u03b4s \u2264 O(1)L0D\u03ba ( 2\nt+ 1\n)\u03ba\u22121 , t \u2265 2. (19)"}, {"heading": "3.3 Semi-Proximal Mirror-Prox for Semi-structured Variational Inequality", "text": "We now give the full description of a special class of variational inequalities, called semi-structured variational inequalities. This family of problems encompasses both cases that we discussed so far in Section 3.1 and 3.2. But most importantly, it also covers many other problems that do not fall into these two regimes and in particular, our essential problem of interest (3).\nSemi-structured Variational Inequalities. The class of semi-structured variational inequalities allows to go beyond Assumptions (A.1) \u2212 (A.4), by assuming more structure. This structure is consistent with what we call a semi-proximal setup, which encompasses both the regular proximal setup and the regular linear minimization setup as special cases. Indeed, we consider a class of variational inequality VI(X,F ) that satisfies, in addition to Assumptions (A.1)\u2212 (A.4), the following assumptions:\n(S.1) Proximal setup for X: we assume that Eu = Eu1\u00d7Eu2 , Ev = Ev1\u00d7Ev2 , and U \u2282 U1\u00d7U2, X = X1\u00d7X2 with Xi \u2208 Eui\u00d7Evi and PiX = {ui : [ui; vi] \u2208 Xi} \u2282 Ui for i = 1, 2, where U1 is convex and closed, U2 is convex and compact. We also assume that \u03c9(u) = \u03c91(u1) + \u03c92(u2) and \u2016u\u2016 = \u2016u1\u2016Eu1 + \u2016u2\u2016Eu2 , with \u03c92(\u00b7) : U2 \u2192 R continuously differentiable such that\n\u03c92(u \u2032 2) \u2264 \u03c92(u2) + \u3008\u2207\u03c92(u2), u\u20322 \u2212 u2\u3009+ L0 \u03ba \u2016u\u20322 \u2212 u2\u2016\u03baEu2 ,\u2200u2, u \u2032 2 \u2208 U2;\nfor a particular 1 < \u03ba \u2264 2 and L0 < \u221e. Furthermore, we assume that the \u2016 \u00b7 \u2016Eu2 -diameter of U2 is bounded by some D > 0..\n(S.2) Proximal mapping on X1: we assume that for any \u03b71 \u2208 Eu1 and \u03b1 > 0, we have at disposal easy-tocompute prox-mappings of the form,\nProx\u03c91(\u03b71, \u03b1) := min x1=[u1;v1]\u2208X1 {\u03c91(u1) + \u3008\u03b71, u1\u3009+ \u03b1\u3008Fv1 , v1\u3009} .\n(S.3) Linear minimization on X2: we assume that we we have at our disposal Composite Linear Minimization Oracle (LMO), which given any input \u03b72 \u2208 Eu2 and \u03b1 > 0, returns an optimal solution to the minimization problem with linear form, that is,\nLMO(\u03b72, \u03b1) := min x2=[u2;v2]\u2208X2 {\u3008\u03b72, u2\u3009+ \u03b1\u3008Fv2 , v2\u3009} .\nSemi-proximal setup We denote such problems as Semi-VI(X,F ). On the one hand, when U2 is a singleton, we get the full-proximal setup. On the other hand, when U1 is a singleton, we get the full linearminimization-oracle setup (full LMO setup). In the gray zone in between, we get the semi-proximal setup.\nThe Semi-Proximal Mirror-Prox algorithm. We finally present here our main contribution, the SemiProximal Mirror-Prox algorithm, which solves the semi-structured variational inequality under (A.1)\u2212(A.4) and (S.1) \u2212 (S.3). The Semi-Proximal Mirror-Prox algorithm blends both CMP and CCG. Basically, for sub-domain X2 given by LMO, instead of computing exactly the prox-mapping, we mimick inexactly the prox-mapping via a conditional gradient algorithm in the composite Mirror Prox algorithm. For the subdomain X1, we compute the prox-mapping as it is.\nCourse of the Semi-Proximal Mirror-Prox algorithm Basically, at step t, we first update yt1 = [u\u0302 t 1; v\u0302 t 1] by computing the exact prox-mapping and update yt2 = [u\u0302 t 2; v\u0302 t 2] by running the composite conditional gradient algorithm to problem (15) specifically with\nX = X2, \u03c6(\u00b7) = \u03c92(\u00b7) + \u3008\u03b3tFu2(ut2)\u2212 \u03c9\u20322(ut2), \u00b7\u3009, and \u03b8 = \u03b3tFv2 ,\nuntil \u03b4(yt2) = maxy2\u2208X2\u3008\u2207\u03c6+(yt2), yt2 \u2212 y2\u3009 \u2264 t. We then update xt+11 = [u t+1 1 ; v t+1 1 ] and x t+1 2 = [u t+1 2 ; v t+1 2 ] similarly except this time taking the value of the operator at point yt. Combining the results in Theorem 3.1 and Proposition 3.1, we arrive at the following complexity bound.\nAlgorithm 3 Semi-Proximal Mirror-Prox Algorithm for Semi-VI(X,F )\nInput: stepsizes \u03b3t > 0, accuracies t \u2265 0, t = 1, 2, . . . [1] Initialize x1 = [x11;x 1 2] \u2208 X, where x11 = [u11; v11 ];x12 = [u12, ; v12 ]. for t = 1, 2, . . . , T do [2] Compute yt = [yt1; y t 2] that\nyt1 := [u\u0302 t 1; v\u0302 t 1] = Prox\u03c91(\u03b3tFu1(u t 1)\u2212 \u03c9\u20321(ut1), \u03b3t) yt2 := [u\u0302 t 2; v\u0302 t 2] = CCG(X2, \u03c92(\u00b7) + \u3008\u03b3tFu2(ut2)\u2212 \u03c9\u20322(ut2), \u00b7\u3009, \u03b3tFv2 ; t)\n[3] Compute xt+1 = [xt+11 ;x t+1 2 ] that\nxt+11 := [u t+1 1 ; v t+1 1 ] = Prox\u03c91(\u03b3tFu1(u\u0302 t 1)\u2212 \u03c9\u20321(ut1), \u03b3t) xt+12 := [u t+1 2 ; v t+1 2 ] = CCG(X2, \u03c92(\u00b7) + \u3008\u03b3tFu2(u\u0302t2)\u2212 \u03c9\u20322(ut2), \u00b7\u3009, \u03b3tFv2 ; t)\nend for Output: xT := [u\u0304T ; v\u0304T ] = ( \u2211T t=1 \u03b3t) \u22121\u2211T t=1 \u03b3ty t\nProposition 3.2. Under the assumption (A.1) \u2212 (A.4) and (S.1) \u2212 (S.3) with M = 0, for the outlined algorithm to return an -solution to the variational inequality V I(X,F ), the total number of Mirror Prox steps required does not exceed\nTotal number of steps = O\n( L\u0398[X] ) and the total number of calls to the Linear Minimization Oracle does not exceed\nN = O(1) ( L0L \u03baD\u03ba\n\u03ba\n) 1 \u03ba\u22121\n\u0398[X].\nIn particular, if we use Euclidean proximal setup on U2 with \u03c92(\u00b7) = 12\u2016x2\u2016 2, which leads to \u03ba = 2 and L0 = 1, then the number of LMO calls does not exceed N = O(1) ( L2D2(\u0398[X1] +D 2 ) / 2.\nDiscussion The proposed Semi-Proximal Mirror-Prox algorithm enjoys the optimal complexity bounds, i.e. O(1/ 2), in the number of calls to LMO; see [15] for the optimal complexity bounds for general nonsmooth optimisation with LMO. Furthermore, Semi-Proximal Mirror-Prox generalizes previously proposed approaches and improves upon them in special cases of problem (3); see Appendix."}, {"heading": "4 Experiments", "text": "We present here illustrations of the proposed approach. We report the experimental results obtained with the proposed Semi-Proximal Mirror-Prox, denoted Semi-MP here, and state-of-the-art competing optimization algorithms. We consider three different models, all with a non-smooth loss function and a nuclear-norm regularization penalty: i) matrix completion with `2 data fidelity term; ii) robust collaborative filtering for movie recommendation; iii) link prediction for social network analysis. For i) & ii), we compare to two competing approaches: a) smoothing conditional gradient proposed in [24] (denoted Smooth-CG); b) smoothing proximal gradient ([20, 6]) equipped semi-proximal setup (Semi-SPG). For iii), we compare to Semi-LPADMM, using [22], and solving proximal mapping through conditional gradient routines. Additional experiments and implementation details are given in Appendix E.\nMatrix completion on synthetic data We consider the matrix completion problem, with a nuclearnorm regularisation penalty and an `2 data-fidelity term. We first investigate the convergence patterns of our Semi-MP and Semi-SPG under two different strategies of the inexactness, a) fixed inner CG steps and\nb) decaying t = c/t as the theory suggested. The plots in Fig. 3 indicate that using the second strategy with O(1/t) decaying inexactness provides better and more reliable performance than using fixed number of inner steps. Similar trends are observed for the Semi-SPG. One can see that these two algorithms based on inexact proximal mappings are notably faster than applying conditional gradient on the smoothed problem.\nRobust collaborative filtering We consider the collaborative filtering problem, with a nuclear-norm regularisation penalty and an `1-loss function. We run the above three algorithms on the the small and medium MovieLens datasets. The small-size dataset consists of 943 users and 1682 movies with about 100K ratings, while the medium-size dataset consists of 3952 users and 6040 movies with about 1M ratings. We follow [24] to set the regularisation parameters. In Fig. 2, we can see that Semi-MP clearly outperforms Smooth-CG, while it is competitive with Semi-SPG.\nLink prediction We consider now the link prediction problem, where the objective consists a hinge-loss for the empirical risk part and multiple regularization penalties, namely the `1-norm and the nuclear-norm. For this example, applying the Smooth-CG or Semi-SPG would require two smooth approximations, one for hinge loss term and one for `1 norm term. Therefore, we consider another alternative approach, Semi-LPADMM, where we apply the linearized preconditioned ADMM algorithm [22] by solving proximal mapping through conditional gradient routines. Up to our knowledge, ADMM with early stopping is not fully theoretically analysed in literature. However, from an intuitive point of view, as long as the accumulated error is controlled sufficiently, such variant of ADMM should converge.\nWe conduct experiments on a binary social graph data set called Wikivote, which consists of 7118 nodes and 103,747 edges. Since the computation cost of these two algorithms mainly come from the LMO calls, we present in below the performance in terms of number of LMO calls. For the first set of experiments, we select top 1024 highest degree users from Wikivote and run the two algorithms on this small dataset with different strategies for the inner LMO calls.\nIn Fig. 2, we observe that the Semi-MP is less sensitive to the inner accuracies of prox-mappings compared to the ADMM variant, which sometimes stops progressing if the prox-mapping of early iterations are not solved with sufficient accuracy. The results on the full dataset corroborate the fact that Semi-MP outperforms the semi-proximal variant of the ADMM algorithm."}, {"heading": "A Preliminaries: Variational Inequalities and Accuracy Certifi-", "text": "cates\nFor the reader\u2019s convenience, we recall here the relationship between variational inequalities, accuracy certificates, and execution protocols, for non-smooth optimization algorithms. The exposition below is directly taken from [12], and recalled here for the reader\u2019s convenience.\nExecution protocols and accuracy certificates. Let X be a nonempty closed convex set in a Euclidean space E and F (x) : X \u2192 E be a vector field.\nSuppose that we process (X,F ) by an algorithm which generates a sequence of search points xt \u2208 X, t = 1, 2, ..., and computes the vectors F (xt), so that after t steps we have at our disposal t-step execution protocol It = {x\u03c4 , F (x\u03c4 )}t\u03c4=1. By definition, an accuracy certificate for this protocol is simply a collection \u03bbt = {\u03bbt\u03c4}t\u03c4=1 of nonnegative reals summing up to 1. We associate with the protocol It and accuracy certificate \u03bbt two quantities as follows:\n\u2022 Approximate solution xt(It, \u03bbt) := \u2211t \u03c4=1 \u03bb t \u03c4x\u03c4 , which is a point of X;\n\u2022 Resolution Res(X \u2032 \u2223\u2223It, \u03bbt) on a subset X \u2032 6= \u2205 of X given by\nRes(X \u2032 \u2223\u2223It, \u03bbt) = sup\nx\u2208X\u2032 t\u2211 \u03c4=1 \u03bbt\u03c4 \u3008F (x\u03c4 ), x\u03c4 \u2212 x\u3009. (20)\nThe role of those notions for non-smooth optimization is explained below.\nVariational inequalities. Assume that F is monotone, i.e.,VI(X,F)\n\u3008F (x)\u2212 F (y), x\u2212 y\u3009 \u2265 0, \u2200x, y \u2208 X . (21)\nOur goal is to approximate a weak solution to the variational inequality (v.i.) VI(X,F ) associated with (X,F ). A weak solution is defined as a point x\u2217 \u2208 X such that\n\u3008F (y), y \u2212 x\u2217\u3009 \u2265 0 \u2200y \u2208 X. (22)\nA natural (in)accuracy measure of a candidate weak solution x \u2208 X to VI(X,F ) is the dual gap function VI(x \u2223\u2223X,F ) = sup\ny\u2208X \u3008F (y), x\u2212 y\u3009 (23)\nThis inaccuracy is a convex nonnegative function which vanishes exactly at the set of weak solutions to the VI(X,F ).\nProposition A.1. For every t, every execution protocol It = {x\u03c4 \u2208 X,F (x\u03c4 )}t\u03c4=1 and every accuracy certificate \u03bbt one has xt := xt(It, \u03bbt) \u2208 X. Besides this, assuming F monotone, for every closed convex set X \u2032 \u2282 X such that xt \u2208 X \u2032 one has\nVI(x t \u2223\u2223X \u2032, F ) \u2264 Res(X \u2032\u2223\u2223It, \u03bbt). (24)\nProof. Indeed, xt is a convex combination of the points x\u03c4 \u2208 X with coefficients \u03bbt\u03c4 , whence xt \u2208 X. With X \u2032 as in the premise of Proposition, we have\n\u2200y \u2208 X \u2032 : \u3008F (y), xt \u2212 y\u3009 = t\u2211\n\u03c4=1\n\u03bbt\u03c4 \u3008F (y), x\u03c4 \u2212 y\u3009 \u2264 t\u2211\n\u03c4=1\n\u03bbt\u03c4 \u3008F (x\u03c4 ), x\u03c4 \u2212 y\u3009 \u2264 Res(X \u2032 \u2223\u2223It, \u03bbt),\nwhere the first \u2264 is due to monotonicity of F .\nConvex-concave saddle point problems. Now let X = X1 \u00d7X2, where Xi is a closed convex subset in Euclidean space Ei, i = 1, 2, and E = E1 \u00d7 E2, and let \u03a6(x1, x2) : X1 \u00d7X2 \u2192 R be a locally Lipschitz continuous function which is convex in x1 \u2208 X1 and concave in x2 \u2208 X2. X1, X2,\u03a6 give rise to the saddle point problem\nSadVal = min x1\u2208X1 max x2\u2208X2\n\u03a6(x1, x2), (25)\ntwo induced convex optimization problems\nOpt(P ) = min x1\u2208X1\n[ \u03a6(x1) = sup\nx2\u2208X2 \u03a6(x1, x2)\n] (P )\nOpt(D) = max x2\u2208X2\n[ \u03a6(x2) = inf\nx1\u2208X1 \u03a6(x1, x2)\n] (D)\n(26)\nand a vector field F (x1, x2) = [F1(x 1, x2);F2(x 1, x2)] specified (in general, non-uniquely) by the relations\n\u2200(x1, x2) \u2208 X1 \u00d7X2 : F1(x1, x2) \u2208 \u2202x1\u03a6(x1, x2), F2(x1, x2) \u2208 \u2202x2 [\u2212\u03a6(x1, x2)].\nIt is well known that F is monotone on X, and that weak solutions to the VI(X,F ) are exactly the saddle points of \u03a6 on X1\u00d7X2. These saddle points exist if and only if (P ) and (D) are solvable with equal optimal values, in which case the saddle points are exactly the pairs (x1\u2217, x 2 \u2217) comprised by optimal solutions to (P ) and (D). In general, Opt(P ) \u2265 Opt(D), with equality definitely taking place when at least one of the sets X1, X2 is bounded; if both are bounded, saddle points do exist. To avoid unnecessary complications, from now on, when speaking about a convex-concave saddle point problem, we assume that the problem is proper, meaning that Opt(P ) and Opt(D) are reals; this definitely is the case when X is bounded.\nA natural (in)accuracy measure for a candidate x = [x1;x2] \u2208 X1 \u00d7X2 to the role of a saddle point of \u03a6 is the quantity\nSad(x \u2223\u2223X1, X2,\u03a6) = \u03a6(x1)\u2212 \u03a6(x2)\n= [\u03a6(x1)\u2212Opt(P )] + [Opt(D)\u2212 \u03a6(x2)] + [Opt(P )\u2212Opt(D)]\ufe38 \ufe37\ufe37 \ufe38 \u22650\n(27)\nThis inaccuracy is nonnegative and is the sum of the duality gap Opt(P )\u2212Opt(D) (always nonnegative and vanishing when one of the sets X1, X2 is bounded) and the inaccuracies, in terms of respective objectives, of x1 as a candidate solution to (P ) and x2 as a candidate solution to (D).\nThe role of accuracy certificates in convex-concave saddle point problems stems from the following observation:\nProposition A.2. Let X1, X2 be nonempty closed convex sets, \u03a6 : X := X1\u00d7X2 \u2192 R be a locally Lipschitz continuous convex-concave function, and F be the associated monotone vector field on X.\nLet It = {x\u03c4 = [x1\u03c4 ;x2\u03c4 ] \u2208 X,F (x\u03c4 )}t\u03c4=1 be a t-step execution protocol associated with (X,F ) and \u03bbt = {\u03bbt\u03c4}t\u03c4=1 be an associated accuracy certificate. Then xt := xt(It, \u03bbt) = [x1,t;x2,t] \u2208 X.\nAssume, further, that X \u20321 \u2282 X1 and X \u20322 \u2282 X2 are closed convex sets such that\nxt \u2208 X \u2032 := X \u20321 \u00d7X \u20322. (28)\nThen Sad(x t \u2223\u2223X \u20321, X \u20322,\u03a6) = sup\nx2\u2208X\u20322 \u03a6(x1,t, x2)\u2212 inf x1\u2208X\u20321 \u03a6(x1, x2,t) \u2264 Res(X \u2032 \u2223\u2223It, \u03bbt). (29)"}, {"heading": "In addition, setting \u03a6\u0303(x1) = supx2\u2208X\u20322 \u03a6(x", "text": "1, x2), for every x\u03041 \u2208 X \u20321 we have\n\u03a6\u0303(x1,t)\u2212 \u03a6\u0303(x\u03041) \u2264 \u03a6\u0303(x1,t)\u2212 \u03a6(x\u03041, x2,t) \u2264 Res({x\u03041} \u00d7X \u20322 \u2223\u2223It, \u03bbt). (30)\nIn particular, when the problem Opt = minx1\u2208X\u20321 \u03a6\u0303(x 1) is solvable with an optimal solution x1\u2217, we have\n\u03a6\u0303(x1,t)\u2212Opt \u2264 Res({x1\u2217} \u00d7X \u20322 \u2223\u2223It, \u03bbt). (31)\nProof. The inclusion xt \u2208 X is clear. For every set Y \u2282 X we have\n\u2200[p; q] \u2208 Y : Res(Y \u2223\u2223It, \u03bbt) \u2265\u2211t\u03c4=1 \u03bbt\u03c4 [\u3008F1(x1\u03c4 ), x1\u03c4 \u2212 p\u3009+ \u3008F2(x2\u03c4 ), x2\u03c4 \u2212 q\u3009] \u2265 \u2211t \u03c4=1 \u03bb t \u03c4 [ [\u03a6(x1\u03c4 , x 2 \u03c4 )\u2212 \u03a6(p, x2\u03c4 )] + [\u03a6(x1\u03c4 , q)\u2212 \u03a6(x1\u03c4 , x2\u03c4 )]\n] [by the origin of F and since \u03a6 is convex-concave]\n= \u2211t \u03c4=1 \u03bb t \u03c4 [ \u03a6(x1\u03c4 , q)\u2212 \u03a6(p, x2\u03c4 ) ] \u2265 \u03a6(x1,t, q)\u2212 \u03a6(p, x2,t)\n[by origin of xt and since \u03a6 is convex-concave]\nThus, for every Y \u2282 X we have\nsup [p;q]\u2208Y\n[ \u03a6(x1,t, q)\u2212 \u03a6(p, x2,t) ] \u2264 Res(Y \u2223\u2223It, \u03bbt). (32) Now assume that Condition (28) is satisfied. Setting Y = X \u2032 := X \u20321 \u00d7X \u20322, and recalling what Sad is, (32) yields (29). With Y = {x\u03041}\u00d7X \u20322 (32) yields the second inequality in (30); the first inequality in (30) is clear since x2,t \u2208 X \u20322."}, {"heading": "B Theoretical analysis of composite Mirror Prox with inexact", "text": "proximal mappings\nWe restate the Theorem 3.1 below and the proof below. The theoretical convergence rate established in Theorem 3.1 and Corollary 3.1 extends the previous result established in Corollary 3.1 in [12] for CMP with exact prox-mappings. Indeed, when exact prox-mappings are used, we recover the result of [12]. When inexact prox-mappings are used, the errors due to the inexactness of the prox-mappings accumulates and is reflected in the bound (34) and (14).\nTheorem 3.1. Assume that the sequence of step-sizes (\u03b3t) in the CMP algorithm satisfy\n\u03c3t := \u03b3t\u3008Fu(u\u0302t)\u2212 Fu(ut), u\u0302t \u2212 ut+1\u3009 \u2212 Vu\u0302t(ut+1)\u2212 Vut(u\u0302t) \u2264 \u03b32tM2 , t = 1, 2, . . . , T . (33)\nThen, denoting \u0398[X] = sup[u;v]\u2208X Vu1(u), for a sequence of inexact prox-mappings with inexactness t \u2265 0, we have\nVI(x\u0304T \u2223\u2223X,F ) := sup\nx\u2208X \u3008F (x), x\u0304T \u2212 x\u3009 \u2264\n\u0398[X] +M2 \u2211T t=1\u03b3 2 t + 2 \u2211T t=1 t\u2211T\nt=1 \u03b3t . (34)\nRemarks Note that the assumption on the sequence of step-sizes (\u03b3t) is clearly satisfied when \u03b3t \u2264 ( \u221a 2L)\u22121. When M = 0, it is satisfied as long as \u03b3t \u2264 L\u22121.\nProof. The proofs builds upon and extends the proof in [12]. For all u, u\u2032, w \u2208 U , we have the well-known identity\n\u3008V \u2032u(u\u2032), w \u2212 u\u2032\u3009 = Vu(w)\u2212 Vu\u2032(w)\u2212 Vu(u\u2032). (35)\nIndeed, the right hand side writes as\n[\u03c9(w)\u2212 \u03c9(u)\u2212 \u3008\u03c9\u2032(u), w \u2212 u\u3009]\u2212 [\u03c9(w)\u2212 \u03c9(u\u2032)\u2212 \u3008\u03c9\u2032(u\u2032), w \u2212 u\u2032\u3009]\u2212 [\u03c9(u\u2032)\u2212 \u03c9(u)\u2212 \u3008\u03c9\u2032(u), u\u2032 \u2212 u\u3009] = \u3008\u03c9\u2032(u), u\u2212 w\u3009+ \u3008\u03c9\u2032(u), u\u2032 \u2212 u\u3009+ \u3008\u03c9\u2032(u\u2032), w \u2212 u\u2032\u3009 = \u3008\u03c9\u2032(u\u2032)\u2212 \u03c9\u2032(u), w \u2212 u\u2032\u3009 = \u3008V \u2032u(u\u2032), w \u2212 u\u2032\u3009.\nFor x = [u; v] \u2208 X, \u03be = [\u03b7; \u03b6], \u2265 0, let [u\u2032; v\u2032] \u2208 P x(\u03be). By definition, for all [s;w] \u2208 X, the inequality holds\n\u3008\u03b7 + V \u2032u(u\u2032), u\u2032 \u2212 s\u3009+ \u3008\u03b6, v\u2032 \u2212 w\u3009 \u2264 ,\nwhich by (35) implies that\n\u3008\u03b7, u\u2032 \u2212 s\u3009+ \u3008\u03b6, v\u2032 \u2212 w\u3009 \u2264 \u3008V \u2032u(u\u2032), s\u2212 u\u2032\u3009+ = Vu(s)\u2212 Vu\u2032(s)\u2212 Vu(u\u2032) + . (36)\nWhen applying (36) with = t, [u; v] = [u t; vt] = xt, \u03be = \u03b3tF (x t) = [\u03b3tFu(u t); \u03b3tFv], [u \u2032; v\u2032] = [u\u0302t; v\u0302t] = yt, and [s;w] = [ut+1; vt+1] = xt+1 we obtain\n\u03b3t[\u3008Fu(ut), u\u0302t \u2212 ut+1\u3009+ \u3008Fv, v\u0302t \u2212 vt+1\u3009] \u2264 Vut(ut+1)\u2212 Vu\u0302t(ut+1)\u2212 Vut(u\u0302t) + t ; (37)\nand applying (36) with = t, [u; v] = x t, \u03be = \u03b3tF (y t), [u\u2032; v\u2032] = xt+1, and [s;w] = z \u2208 X we get\n\u03b3t[\u3008Fu(u\u0302t), ut+1 \u2212 s\u3009+ \u3008Fv, vt+1 \u2212 w\u3009] \u2264 Vut(s)\u2212 Vut+1(s)\u2212 Vut(ut+1) + t . (38)\nAdding (38) to (37), we obtain for every z = [s;w] \u2208 X\n\u03b3t\u3008F (yt), yt \u2212 z\u3009 = \u03b3t[\u3008Fu(u\u0302t), u\u0302t \u2212 s\u3009+ \u3008Fv, v\u0302t \u2212 w\u3009] \u2264 Vut(s)\u2212 Vut+1(s) + \u03c3t + 2 t , (39)\nwith \u03c3t := \u03b3t\u3008Fu(u\u0302t)\u2212 Fu(ut), u\u0302t \u2212 ut+1\u3009 \u2212 Vu\u0302t(ut+1)\u2212 Vut(u\u0302t) . Due to the strong convexity, with modulus 1, of Vu(\u00b7) w.r.t. \u2016 \u00b7 \u2016, we have for all u, u\u0302\nVu(u\u0302) \u2265 1\n2 \u2016u\u2212 u\u0302\u20162 .\nTherefore,\n\u03c3t \u2264 \u03b3t\u2016Fu(u\u0302t)\u2212 Fu(ut)\u2016\u2217\u2016u\u0302t \u2212 ut+1\u2016 \u2212 12\u2016u\u0302 t \u2212 ut+1\u20162 \u2212 1 2 \u2016ut \u2212 u\u0302t\u20162\n\u2264 1 2 [ \u03b32t \u2016Fu(u\u0302t)\u2212 Fu(ut)\u20162\u2217 \u2212 \u2016ut \u2212 u\u0302t\u20162 ] \u2264 1\n2 [ \u03b32t [M + L\u2016u\u0302t \u2212 ut\u2016]2 \u2212 \u2016ut \u2212 u\u0302t\u20162 ] ,\nwhere the last inequality follows from Assumption A.3. Note that \u03b3tL < 1 implies that\n\u03b32t [M + L\u2016u\u0302t \u2212 ut\u2016]2 \u2212 \u2016u\u0302t \u2212 ut\u20162 \u2264 max r\n[ \u03b32t [M + Lr] 2 \u2212 r2 ] = \u03b32tM 2\n1\u2212 \u03b32tL2 .\nLet us assume that the step-sizes \u03b3t > 0 are chosen so that (33) holds, that is \u03c3t \u2264 \u03b32tM2. It is indeed the case when 0 < \u03b3t \u2264 1\u221a2L ; when M = 0, we can take also \u03b3t \u2264 1 L . Summing up inequalities (39) over t = 1, 2, ..., t, and taking into account that Vut+1(s) \u2265 0, we finally conclude that for all z = [s;w] \u2208 X, T\u2211 t=1 \u03bbtT \u3008F (yt), yt \u2212 z\u3009 \u2264 Vu1(s) +M 2 \u2211T t=1 \u03b3 2 t + 2 \u2211T t=1 t\u2211T t=1 \u03b3t , where \u03bbtT = ( T\u2211 i=1 \u03b3i) \u22121\u03b3t ."}, {"heading": "C Theoretical analysis of composite conditional gradient", "text": "C.1 Convergence rate\nThe CCG algorithm enjoys a convergence rate in O(t\u2212(\u03ba\u22121)) in the evaluations of the function \u03c6+, and the accuracy certificates (\u03b4t) enjoy the same rate O(t \u2212(\u03ba\u22121)) as well, for solving problems of type (15).\nProposition 3.1. Denote D the \u2016 \u00b7 \u2016-diameter of U . When solving problems of type (15), the sequence of iterates (xt) of CCG satisfies\nt := \u03c6 +(xt)\u2212min x\u2208X \u03c6+(x) \u2264 2L0D\n\u03ba\n\u03ba(3\u2212 \u03ba)\n( 2\nt+ 1\n)\u03ba\u22121 , t \u2265 2 (40)\nIn addition, the accuracy certificates (\u03b4t) satisfy\nmin 1\u2264s\u2264t\n\u03b4s \u2264 O(1)L0D\u03ba ( 2\nt+ 1\n)\u03ba\u22121 , t \u2265 2 (41)\nC.2 Proof of Proposition 3.1\n10. The projection of X2 onto Eu2 is contained in U2, whence\n\u2016u2[\u2207\u03c6(us2)]\u2212 us2\u2016 \u2264 D.\nThis observation, due to the structure of \u03c6+, implies that whenever x, x\u2032 \u2208 X and \u03b3 \u2208 [0, 1], we have\n\u03c6+(x+ \u03b3(x+ \u2212 x)) \u2264 \u03c6+(x) + \u03b3\u3008\u2207\u03c6+(x), x\u2032 \u2212 x\u3009+ L0D \u03ba\n\u03ba \u03b3\u03ba. (42)\nSetting xs+ = x s 2 + \u03b3s(x2[\u2207\u03c6(us)]\u2212 xs2) and \u03b3s2/(s+ 1), we have\n\u03b4t+1 \u2264 \u03c6+(xs+)\u2212 min x2\u2208X2 \u03c6+(x2) (43)\n\u2264 \u03b4s + \u03b3s\u3008\u2207\u03c6(xs2), x[\u2207\u03c6+(xs2)]\u2212 x2\u3009+ L0D\n\u03ba\n\u03ba \u03b3\u03bas (44)\n= \u03b4s \u2212 \u03b3s\u2206s + L0D\n\u03ba\n\u03ba \u03b3\u03bas , (45)\nwhence, due to \u2206s \u2265 \u03b4s \u2265 0,\n(i) \u03b4t+1 \u2264 (1\u2212 \u03b3s)\u03b4s + L0D\n\u03ba\n\u03ba \u03b3\u03bas , s = 1, 2, ...,\n(ii) \u03b3\u03c4\u2206\u03c4 \u2264 \u03b4\u03c4 \u2212 \u03b4\u03c4+1 + L0D\n\u03ba\n\u03ba \u03b3\u03ba\u03c4 , \u03c4 = 1, 2, ... (46)\n20. Let us prove (40) by induction on s \u2265 2. By (46.i) and due to \u03b31 = 1 we have \u03b42 \u2264 L0D \u03ba\n\u03ba , whence\n\u03b42 \u2264 2L0D \u03ba \u03ba(3\u2212\u03ba)\u03b3 \u03ba\u22121 2 due to \u03b32 = 2/3 and 1 < \u03ba \u2264 2. Now assume that \u03b4s \u2264 2L0D \u03ba \u03ba(3\u2212\u03ba)\u03b3 \u03ba\u22121 s for some t \u2265 2. Then, invoking (46.i),\n\u03b4s+1 \u2264 2L0D\n\u03ba\n\u03ba(3\u2212 \u03ba) \u03b3\u03ba\u22121s (1\u2212 \u03b3s) +\nL0D \u03ba\n\u03ba \u03b3\u03bas\n\u2264 2L0D \u03ba\n\u03ba(3\u2212 \u03ba)\n[ \u03b3\u03ba\u22121s \u2212\n\u03ba\u2212 1 2 \u03b3\u03bas ] \u2264 2L0D \u03ba\n\u03ba(3\u2212 \u03ba) 2\u03ba\u22121\n[ (t+ 1)1\u2212\u03ba + (1\u2212 \u03ba)(t+ 1)\u2212\u03ba ] Therefore, by convexity of (t+ 1)1\u2212\u03ba in t\n\u03b4s+1 \u2264 2L0D\n\u03ba\n\u03ba(3\u2212 \u03ba) 2\u03ba\u22121(t+ 2)1\u2212\u03ba =\n2L0D \u03ba\n\u03ba(3\u2212 \u03ba) \u03b3\u03ba\u22121t+1\nThe induction is completed.\n30. To prove (41), given s \u2265 2, let s\u2212 = Ceil(max[2, s/2]). Summing up inequalities (46.ii) over s\u2212 \u2264 \u03c4 \u2264 s, we get (\nmin \u03c4\u2264s \u2206\u03c4 ) \u2211s \u03c4=s\u2212 \u03b3\u03c4 \u2264 s\u2211\n\u03c4=s\u2212\n\u03b3\u03c4\u2206\u03c4 \u2264 \u03b4s\u2212 \u2212 \u03b4s+1 + L0D\n\u03ba\n2 \u2211s \u03c4=s\u2212 \u03b3\u03ba\u03c4 \u2264 O(1)L0D\u03ba\u03b3\u03ba\u22121s\nand \u2211s \u03c4=s\u2212 \u03b3\u03c4 \u2265 O(1), and (41) follows."}, {"heading": "D Semi-Proximal Mirror-Prox", "text": "D.1 Theoretical analysis for Semi-Proximal Mirror-Prox\nWe first restate Proposition 3.2 and provide the proof below.\nProposition 3.2. Under the assumption (A.1) \u2212 (A.4) and (S.1) \u2212 (S.3) with M = 0, for the outlined algorithm to return an -solution to the variational inequality V I(X,F ), the total number of Mirror Prox\nsteps required does not exceed O ( L\u0398[X] ) , and the total number of calls to the Linear Minimization Oracle\ndoes not exceed\nN = O(1) ( L0L \u03baD\u03ba\n\u03ba\n) 1 \u03ba\u22121\n\u0398[X].\nIn particular, if we use Euclidean proximal setup on U2 with \u03c92(\u00b7) = 12\u2016x2\u2016 2, which leads to \u03ba = 2 and L0 = 1, then the number of LMO calls does not exceed N = O(1) ( L2D2(\u0398[X1] +D 2 ) / 2.\nProof. Let us fix N as the number of Mirror prox steps, and since M = 0, from Theorem 3.1, the efficiency estimate of the variational inequality implies that\nVI(x\u0304 N |X,F ) \u2264\nL(\u0398[X] + 2 \u2211N t=1 t)\nN .\nLet us fix t = 2\u0398[X] N for each t = 1, . . . , N , then from Proposition 3.1, it takes at most s = O(1)(L0D \u03baN\n\u0398[X] ) 1/(\u03ba\u22121) LMO oracles to generate a point such that \u2206s \u2264 t. Moreover, we have\nVI(x\u0304 N |X,F ) \u2264 2L\u0398[X]\nN .\nTherefore, to ensure VI(x\u0304 N |X,F ) \u2264 for a given accuracy > 0, the number of Mirror Prox steps N is at most O(L\u0398[X] ) and the number of LMO calls on X2 needed is at most\nN = O(1) (L0D\u03baN\n\u0398[X]\n)1/(\u03ba\u22121) \u00b7N = O(1) (L0L\u03baD\u03ba \u03ba )1/(\u03ba\u22121) \u0398[X].\nIn particular, if \u03ba = 2 and L0 = 1, this quantity can be reduced to\nN = O(1)L 2D2\u0398[X]\n2 .\nD.2 Discussion of Semi-Proximal Mirror-Prox\nThe proposed Semi-Proximal Mirror-Prox algorithm enjoys the optimal complexity bounds, i.e. O(1/ 2), in the number of calls to linear minimization oracle. Furthermore, Semi-Proximal Mirror-Prox generalizes previously proposed approaches and improves upon them in special cases of problem (3).\nWhen there is no regularisation penalty, Semi-Proximal Mirror-Prox is more general than previous algorithms for solving the corresponding constrained non-smooth optimisation problem. Semi-Proximal MirrorProx does not require assumptions on favorable geometry of dual domains Z or simplicity of \u03c8(\u00b7) in (2). When the regularisation is simply a norm (with no operator in front of the argument), Semi-Proximal Mirror-Prox is competitive with previously proposed approaches [16, 24] based on smoothing techniques.\nWhen the regularisation penalty is non-trivial, Semi-Proximal Mirror-Prox is the first proximal-free or conditional-gradient-type optimization algorithm, up to our knowledge."}, {"heading": "E Numerical experiments and implementation details", "text": "E.1 Matrix completion: `2-fit +nuclear norm\nWe first consider the the following type of matrix completion problem,\nmin x\u2208Rm\u00d7n\n\u2016P\u2126x\u2212 b\u20162 + \u03bb\u2016x\u2016nuc (47)\nwhere \u2016 \u00b7 \u2016nuc stands for the nuclear norm and P\u2126x is the restriction of x onto the cells \u2126.\nCompeting algorithms. We compare the following three candidate algorithms, i) Semi-Proximal MirrorProx (Semi-MP) ; ii) conditional gradient after smoothing (Smooth-CG); iii) inexact accelerate proximal gradient after smoothing (Semi-SPG). We provide below the key steps of each algorithms.\n1. Semi-MP: this is shorted for our Semi-Proximal Mirror-Prox algorithm, we solve the saddle point reformulation given by\nmin x,v:\u2016x\u2016nuc\u2264v max \u2016y\u20162\u22641\n\u3008P\u2126x\u2212 b, y\u3009+ \u03bbv (48)\nwhich is equivalent as to the semi-structured variational inequality Semi-VI (X,F ) with X = {[u = (x; y); v] : \u2016x\u2016nuc \u2264 v, \u2016y\u20162 \u2264 1} and F = [Fu(u);Fv] = [PT\u2126 y; b \u2212 P\u2126x;\u03bb]. The subdomain X1 = {y : \u2016y\u20162 \u2264 1} is given by full-prox setup and the subdomain X2 = {(x; v) : \u2016x\u2016nuc \u2264 v} is given by LMO. By setting both the distance generating functions \u03c9x(x) and \u03c9y(y) as the Euclidean distance, the update of y reduces to a gradient step, and the update of x follows the composite conditional gradient routine over a simple quadratic problem.\n2. Smooth-CG: The algorithm ([24]) directly applies the generalized composite conditional gradient on the following smoothed problem using the Nesterov smoothing technique,\nmin x,v:\u2016x\u2016nuc\u2264v f\u03b3(x) + \u03bbv, where f\u03b3(x) = max \u2016y\u20162\u22641\n{\u3008P\u2126x\u2212 b, y\u3009 \u2212 \u03b3\n2 \u2016y\u201622}. (49)\nUnder the full memory version, the update of x at step t requires computing reoptimization problem\nmin \u03b81,...,\u03b8t\nf\u03b3( t\u2211 i=1 \u03b8iuiv T i ) + \u03bb t\u2211 i=1 \u03b8i (50)\nwhere {ui, vi}ti=1 are the singular vectors collected from the linear minimization oracles. Same as suggested in [24], we use the quasi-Newton solver L-BFGS-B [5] to solve the above re-optimization subproblem. Notice that in this situation, solving (50) can be relatively efficient even for large t since computing the gradient of the objective in (50) does not necessarily need to compute out the full matrix representation of x = \u2211t i=1 \u03b8iuiv T i .\n3. Semi-SPG: The approach is to apply the accelerated proximal gradient to the smoothed composite model as in (49) and approximately solve the proximal mappings via conditional gradient routines. In fact, Semi-SPG can be considered as a direct extension of the conditional gradient sliding to the composite setting. Same as Semi-MP, the update of x is given by the composite conditional gradient routine over a simple quadratic problem and additional interpolation step. Since the Lipschitz constant is not known, the learning rate is selected through backtracking.\nFor Semi-MP and Semi-SPG, we test two different strategies for the inexact prox-mappings, a)fixed inner CG steps and b)decaying t = c/t as the theory suggested. For the sake of simplicity, we generate the synthetic data such that the magnitudes of the constant factors (i.e. Frobenius norm and nuclear norm of optimal solution) are approximately of order 1, which means the convergence rate is dominated mainly by the number of LMO calls. In Fig. 3, we evaluate the optimality gap of these algorithms with different parameters\n(e.g. number of inner steps, scaling factor c, smoothness parameter \u03b3) and compare their performance given the best-tuned parameter. As the plot shows, the Semi-MP algorithm generates a solution with = 10\u22123 accuracy within about 3000 LMO calls, which is not bad at all given the fact that the worst complexity is O(1/ 2). Also, the plots indicate that using the second strategy with O(1/t) decaying inexactness provides better and more reliable performance than using fixed number of inner steps. Similar trends are observed for the Semi-SPG. One can see that these two algorithms based on inexact proximal mappings are notably faster than applying conditional gradient on the smoothed problem. Moreover, since the Smooth-CG requires additional computation and memory cost for the re-optimization procedure, the actual difference in terms of CPU time could be more significant.\nE.2 Robust collaborative fitering: `1-empirical risk +nuclear norm\nWe consider the collaborative filtering problem, with a nuclear-norm regularisation penalty and an `1- empirical risk function:\nmin x\n1 |E| \u2211\n(i,j)\u2208E\n|xij \u2212 bij |+ \u03bb\u2016x\u2016nuc. (51)\nCompeting algorithms. We compare the above three candidate algorithm. The smoothed problem for Semi-SPG and Smooth-CG in this case becomes\nmin x,v:\u2016x\u2016nuc\u2264v f\u03b3(x) + \u03bbv, where f\u03b3(x) = max \u2016y\u2016\u221e\u22641  1|E| \u2211 (i,j)\u2208E (xij \u2212 bij)yij \u2212 \u03b3 2 \u2016y\u201622  . (52) Note that in this case, for Smooth-CG, solving the re-optimization problem in (50) at each iteration requires computing the full matrix representation for the gradient. For large t and large-scale problems, the computation cost for re-optimization is no longer negligible. However, the Semi-MP and Semi-SPG do not suffer from this limitation since the conditional gradient routines are called for simple quadratic subproblems. For this particular example, we implement the Semi-MP slightly different from the above scheme. We solve the following saddle point reformulation with properly selected \u03c1,\nmin x,y,v1,v2:\nv1\u2265\u2016x\u2016nuc,v2\u2265\u2016y\u20161\nmax \u2016w\u20162\u22641\nv2 + \u03bbv1 + \u03c1\u3008Ax\u2212 b\u2212 y, w\u3009 (53)\nwhere we use A to denote the operator 1|E|PE . The semi-structured variational inequality Semi-VI (X,F ) associated with the above saddle point problem is given by X = {[u = (x, y, w); v = (v1.v2)] : \u2016x\u2016nuc \u2264 v1, \u2016y\u20161 \u2264 v2, \u2016w\u20162 \u2264 1} and F = [Fu(u);Fv] = [\u03c1Aw;\u2212\u03c1w; \u03c1(y \u2212 Ax + b);\u03bb; 1]. The subdomain X1 = {(y, w, v2) : \u2016y\u20161 \u2264 v2, \u2016w\u20162 \u2264 1} is given by full-prox setup and the subdomain X2 = {(x; v1) : \u2016x\u2016nuc \u2264 v1} is given by LMO. By setting both the distance generating functions as the Euclidean distance, the update of w reduces to the gradient step, the update of y reduces to the soft-thresholding operator, and the update\nof x is given by the composite conditonal gradient routine. In our experiment, the factor \u03c1 is updated adaptively in such a way that the back-projection step does not increase the objective function value. We set the stepsizes \u03b3t along the iterations using line-search. All in all, the Semi-Proximal Mirror-Prox algorithm (Semi-MP) is fully automatic, and does not require tuning of any parameter.\nWe run the above three algorithms on the the small and medium MovieLens datasets. The small-size dataset consists of 943 users and 1682 movies with about 100K ratings,while the medium-size dataset consists of 3952 users and 6040 movies with about 1M ratings. We follow [24] to set the regularisation parameters. We randomly pick 80% of the entries to build the training dataset, and compute the normalized mean absolute error (NMAE) on the remaining test dataset. For Smooth-CG, we carry out the algorithm with different smoothing parameters, ranging from {1e\u22123, 1e\u22122, 1e\u22121, 1e0} and select the one with the best performance. For the Semi-SPG algorithm, we adopt the best smoothing parameter found in Smooth-CG. We use two different strategies to control the number of LMO calls at each iteration, i.e. the accuracy of the proximal mapping for both Semi-SPG and Semi-MP, which are a) fixed inner CG steps and b) decaying t = c/t as the theory suggested. We report in Fig. 4 and Fig. 5 the performance of each algorithm under different choice of parameters and the overall comparison of objective value and NMAE on test data in Fig. 6.\nIn Fig. 4 and Fig. 5, we can see that using fixed inner CG steps sometimes achieve comparable performance\nas using the decaying epsilon t. In Fig. 6, we can see that Semi-MP clearly outperforms Smooth-CG, while it is competitive with Semi-SPG. In the large-scale setting, Semi-MP achieves better objective as well as test NMAE compared to Smooth-CG.\nE.3 Link prediction: hinge loss + `1-norm + nuclear norm\nWe consider the following model for the link prediction problem,\nmin x\u2208Rm\u00d7n\n1 |E| \u2211\n(i,j)\u2208E\nmax (1\u2212 (bij \u2212 0.5)xij , 0) + \u03bb1\u2016x\u20161 + \u03bb2\u2016x\u2016nuc (54)\nThis example is more complicated than the previous two examples since it has not only one nonsmooth loss function but also two regularization terms. Applying the smoothing-CG or Semi-SPG would require to build two smooth approximations, one for hinge loss term and one for `1 norm term. Therefore, we consider another alternative approach, Semi-LPADMM, where we apply the linearized preconditioned ADMM algorithm by solving proximal mapping through conditional gradient routines. Up to our knowledge, ADMM with early stopping is not well-analyzed in literature, but intuitively as long as the accumulated error is controlled sufficiently, the variant will converge.\nWe conduct experiments on a binary social graph data set called Wikivote, which consists of 7118 nodes and 103,747 edges. Since the computation cost of these two algorithms mainly come from the LMO calls, we present in below the performance in terms of number of LMO calls. For the first set of experiments, we select top 1024 highest degree users from Wikivote and run the two algorithms on this small dataset with different strategies for the inner LMO calls.\nIn Fig. 7, we observe that the Semi-MP is less sensitive to the inner accuracies of prox-mappings compared to the ADMM variant, which sometimes stop progressing if the prox mapping of early iterations are not solved with sufficient accuracy. Another observation is that in this example, the second strategy, which essentially saves the use of LMOs, works better in the long run than using fixed number of LMOs. The results indicate again on the full dataset again indicates that our algorithm performs better than the semi-proximal variant of ADMM algorithm."}], "references": [], "referenceMentions": [], "year": 2015, "abstractText": "We propose a new first-order optimisation algorithm to solve high-dimensional non-smooth composite minimisation problems. Typical examples of such problems have an objective that decomposes into a non-smooth empirical risk part and a non-smooth regularisation penalty. The proposed algorithm, called Semi-Proximal Mirror-Prox, leverages the Fenchel-type representation of one part of the objective while handling the other part of the objective via linear minimization over the domain. The algorithm stands in contrast with more classical proximal gradient algorithms with smoothing, which require the computation of proximal operators at each iteration and can therefore be impractical for high-dimensional problems. We establish the theoretical convergence rate of Semi-Proximal Mirror-Prox, which exhibits the optimal complexity bounds, i.e. O(1/ ), for the number of calls to linear minimization oracle. We present promising experimental results showing the interest of the approach in comparison to competing methods.", "creator": "LaTeX with hyperref package"}}}