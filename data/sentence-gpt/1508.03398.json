{"id": "1508.03398", "review": {"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "14-Aug-2015", "title": "End-to-end Learning of LDA by Mirror-Descent Back Propagation over a Deep Architecture", "abstract": "We develop a fully discriminative learning approach for supervised Latent Dirichlet Allocation (LDA) model, which maximizes the posterior probability of the prediction variable given the input document. Different from traditional variational learning or Gibbs sampling approaches, the proposed learning method applies (i) the mirror descent algorithm for exact maximum a posterior inference and (ii) back propagation with stochastic gradient descent for model parameter estimation, leading to scalable learning of the model in an end-to-end discriminative manner. As a byproduct, we also apply this technique to develop a new learning method for the traditional unsupervised LDA model for the estimation of a posterior probability of the prediction variable.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "histories": [["v1", "Fri, 14 Aug 2015 01:32:27 GMT  (765kb,D)", "http://arxiv.org/abs/1508.03398v1", "20 pages, 5 figures"], ["v2", "Sun, 1 Nov 2015 08:11:14 GMT  (540kb,D)", "http://arxiv.org/abs/1508.03398v2", "Proc. NIPS 2015"]], "COMMENTS": "20 pages, 5 figures", "reviews": [], "SUBJECTS": "cs.LG", "authors": ["jianshu chen", "ji he", "yelong shen", "lin xiao", "xiaodong he", "jianfeng gao", "xinying song", "li deng"], "accepted": true, "id": "1508.03398"}, "pdf": {"name": "1508.03398.pdf", "metadata": {"source": "CRF", "title": "End-to-end Learning of Latent Dirichlet Allocation by Mirror-Descent Back Propagation", "authors": ["Jianshu Chen", "Ji He", "Yelong Shen", "Lin Xiao", "Xiaodong He", "Jianfeng Gao", "Xinying Song", "Li Deng"], "emails": ["jianshuc@microsoft.com", "yeshen@microsoft.com", "lin.xiao@microsoft.com", "xiaohe@microsoft.com", "jfgao@microsoft.com", "xinson@microsoft.com", "deng@microsoft.com", "jvking@uw.edu"], "sections": [{"heading": "1 Introduction", "text": "Latent Dirichlet Allocation (LDA) [4], among various forms of topic models, is an important probabilistic generative model for analyzing large collections of text corpora. In LDA, each document is modeled as a collection of words, where each word is assumed to be generated from a certain topic drawn from a topic distribution. The topic distribution can be viewed as a latent representation of the document, which can be used as a feature for prediction purpose (e.g., sentiment analysis). In particular, the inferred topic distribution is fed into a separate classifier or regression model (e.g., logistic regression or linear regression) to perform prediction. Such a separate learning structure usually significantly restricts the performance of the algorithm. For this purpose, various supervised topic models have been proposed to model the documents jointly with the label information. In [3], variational methods was applied to learn a supervised LDA (sLDA) model by maximizing the lower bound of the joint probability of the input data and the labels. The DiscLDA method developed in [11] learns the transformation matrix from the latent topic representation to the output in a discriminative manner, while learning the topic to word distribution in a generative manner similar to the standard LDA. In [21, 22], max margin supervised topic models are developed for classification and regression, which are trained by optimizing the sum of the variational bound for the log marginal likelihood and an additional term that characterizes the prediction margin. These methods successfully incorporate the information from both the input data and the labels, and showed better performance in prediction compared to the vanilla LDA model.\nOne challenge in LDA is that the exact inference is intractable, i.e., the posterior distribution of the topics given the input document cannot be evaluated explicitly. For this reason, various approximate inference methods are proposed, such as variational learning [3,4,21,22] and Gibbs sampling [7,23], for computing the approximate posterior distribution of the topics. In this paper, we will show that,\nar X\niv :1\n50 8.\n03 39\n8v 1\n[ cs\n.L G\n] 1\n4 A\nalthough the full posterior probability of the topic distribution is difficult, its maximum a posteriori (MAP) inference, as a simplified problem, is a convex optimization problem when the Dirichlet parameter satisfies certain conditions, which can be solved efficiently by the mirror descent algorithm (MDA) [1,15,18]. Indeed, Sontag and Roy [16] pointed out that the MAP inference problem of LDA in this situation is polynomial-time and can be solved by an exponentiated gradient method, which shares a same form as our mirror-descent algorithm with constant step-size. Nevertheless, different from [16], which studied the inference problem alone, our focus in this paper is to integrate back propagation with mirror-descent algorithm to perform fully discriminative training of supervised topic models, as we proceed to explain below.\nAmong the aforementioned methods, one training objective of the supervised LDA model is to maximize the joint likelihood of the input and the output variables [3]. Another variant is to maximize the sum of the log likelihood (or its variable bound) and a prediction margin [21\u201323]. Moreover, the DiscLDA optimizes part of the model parameters by maximizing the marginal likelihood of the input variables, and optimizes the other part of the model parameters by maximizing the conditional likelihood. For this reason, DiscLDA is not a fully discriminative training of all the model parameters. In this paper, we propose a fully discriminative training of all the model parameters by maximizing the posterior probability of the output given the input document. We will show that the discriminative training can be performed in a principled manner by naturally integrating the back-propagation with the MDA-based exact MAP inference. Discriminative training of generative model is widely used and usually outperforms standard generative training in prediction tasks [2, 6, 9, 10, 12, 20]. As pointed out in [2,12], discriminative training increases the robustness against the mismatch between the generative model and the real data. To our best knowledge, this paper is the first work to perform a fully end-to-end discriminative training of LDA. Experimental results on two real-world tasks also show the superior performance of discriminative training of LDA models on text analysis.\nIn addition to the aforementioned related studies on unsupervised and supervised LDA models [3,11, 21\u201323], there have been another stream of work that applied empirical risk minimization to graphical models such as Markov Random Field (MRF) and nonnegative matrix factorization (NMF) [8, 17]. Specifically, in [17], an approximate inference algorithm, belief propagation, is used to compute the belief of the output variables, which is further fed into a decoder to produce the prediction. The approximate inference and the decoder are treated as an entire black-box decision rule, which is tuned jointly via back propagation. Our work is different from the above studies in that we use an exact MAP inference based on convex optimization theory motivate the discriminative training from a principled probabilistic framework."}, {"heading": "2 Smoothed Supervised LDA Model", "text": "We consider the smoothed supervised LDA model in Figure 1. Let K be the number of topics, N be the number of words in each document, V be the vocabulary size, and D be the number of documents in the corpus. The generative process of the model in Figure 1 can be described as:\n1. For each document d, choose the topic proportions according to a Dirichlet distribution: \u03b8d \u223c p(\u03b8d|\u03b1) = Dir(\u03b1), where \u03b1 is a K\u00d7 1 vector consisting of nonnegative components.\n2. Draw each column \u03c6k of a V \u00d7K matrix \u03a6 independently from an exchangeable Dirichlet distribution: \u03c6k \u223c Dir(\u03b2) (i.e., \u03a6 \u223c p(\u03a6|\u03b2)), where \u03b2 > 0 is the smoothing parameter.\n3. To generate each word wd,n:\n(a) Choose a topic zd,n \u223c p(zd,n|\u03b8d) = Multinomial(\u03b8d). 1 (b) Choose a word wd,n \u223c p(wd,n|zd,n,\u03a6) = Multinomial(\u03c6zd,n).\n4. Choose the C \u00d7 1 response vector: yd \u223c p(yd|\u03b8, U, \u03b3). (a) In regression, p(yd|\u03b8d, U, \u03b3) = N(U\u03b8d, \u03b3\u22121), where U is a C \u00d7K matrix consisting\nof regression coefficients. (b) In multi-class classification, p(yd|\u03b8d, U, \u03b3) = Multinomial ( \u03c3(\u03b3U\u03b8d) ) , where \u03c3 :\nRC \u2192 RC is a softmax function defined as \u03c3(x)c = e xc\u2211C\nc\u2032=1 e x c\u2032\n, c = 1, . . . , C.\nTherefore, the entire model can be described by the following joint probability\np(\u03a6|\u03b2) D\u220f d=1 [ p(yd|\u03b8d, U, \u03b3) \u00b7 p(\u03b8d|\u03b1) \u00b7 p(wd,1:N |zd,1:N ,\u03a6) \u00b7 p(zd,1:N |\u03b8d)\ufe38 \ufe37\ufe37 \ufe38\n,p(yd,\u03b8d,wd,1:N ,zd,1:N |\u03a6,U,\u03b1,\u03b3)\n] (1)\nwhere wd,1:N and zd,1:N denotes all the words and the associated topics, respectively, in the d-th document. Note that the model in Figure 1 is slightly different from the one proposed in [3], where, in addition to the Dirichlet smoothing part on \u03c6k, the response variable yd in Figure 1 is coupled with \u03b8d instead of zd,1:N as in [3]. Blei and Mcauliffe also pointed out this choice as an alternative in [3]. We will show that this modification will enable us to develop an end-to-end discriminative training with superior prediction performance.\nTo develop a fully discriminative training method for the model parameters \u03a6 and U , we follow the argument in [2,12], which states that the discriminative training is also equivalent to maximizing the joint likelihood of a new model family with an additional set of parameters:\narg max \u03a6,U,\u03a6\u0303 p(\u03a6|\u03b2)p(\u03a6\u0303|\u03b2) D\u220f d=1 p(yd|wd,1:N ,\u03a6, U, \u03b1, \u03b3) D\u220f d=1 p(wd,1:N |\u03a6\u0303, \u03b1) (2)\nwhere p(wd,1:N |\u03a6\u0303, \u03b1) is obtained by marginalizing p(yd, \u03b8d, wd,1:N , zd,1:N |\u03a6, U, \u03b1, \u03b3) in (1) and replace \u03a6 with \u03a6\u0303. The above problem (2) decouples into\narg max \u03a6,U\n[ ln p(\u03a6|\u03b2) + D\u2211 d=1 ln p(yd|wd,1:N ,\u03a6, U, \u03b1, \u03b3) ]\n(3)\narg max \u03a6\u0303\n[ ln p(\u03a6\u0303|\u03b2) + D\u2211 d=1 ln p(wd,1:N |\u03a6\u0303, \u03b1) ]\n(4)\nwhich are the discriminative learning problem of supervised LDA (Eq. (3)), and the unsupervised learning problem of LDA (Eq. (4)), respectively. It was pointed out in [2] that the discriminative training (3) improves performance by compensating for model mismatch, i.e., the differences between the true distribution of the data and the distribution specified by the model. We will show that both problems can be solved in a unified manner using a new MAP inference and back propagation."}, {"heading": "3 Exact MAP Inference", "text": "We first consider the inference problem in the smoothed LDA model. For the supervised case, the main objective is to infer yd given the words wd,1:N in each document d, i.e., computing\np(yd|wd,1:N ,\u03a6, U, \u03b1, \u03b3) = \u222b \u03b8d p(yd|\u03b8d, U, \u03b3)p(\u03b8d|wd,1:N ,\u03a6, \u03b1)d\u03b8d (5)\nwhere the probability p(yd|\u03b8d, U, \u03b3) is known (e.g., multinomial or Gaussian for classification and regression problems \u2014 see Section 2). The main challenge is to evaluate p(\u03b8d|wd,1:N ,\u03a6, \u03b1), i.e., infer the topic proportion given each document, which is also the important inference problem in\n1We will represent all the multinomial variables by a one-hot vector that has a single component equal to one and all other components being zero, where the position of the one is determined by the value of the multinomial variable.\nthe unsupervised LDA model. However, it is well known that the exact evaluation of the posterior probability p(\u03b8d|wd,1:N ,\u03a6, \u03b1) is intractable [3,4,7,11,21\u201323]. For this reason, various approximate inference methods, such as variational inference [3, 4, 11, 21, 22] and Gibbs sampling [7, 23], have been proposed to compute the approximate posterior probability. In this paper, we take an alternative approach for inference; given each document d, we only seek a point (maximum a posterior) estimate of \u03b8d, instead of its full (approximate) posterior probability. The major motivation is that, although the full posterior probability of \u03b8d is difficult, its MAP inference, as a simplified problem, is a convex optimization problem (Section 3.1) and is thus tractable. Furthermore, having the MAP estimate of \u03b8d, we can efficiently infer the prediction variable yd according to the following approximation of p(yd|wd,1:N ,\u03a6, U, \u03b1, \u03b3) from (5):\np(yd|wd,1:N ,\u03a6, U, \u03b1, \u03b3) = E\u03b8d|wd,1:N [p(yd|\u03b8d, U, \u03b3)] \u2248 p(yd|\u03b8\u0302d|wd,1:N , U, \u03b3) (6) where E\u03b8d|wd,1:N [\u00b7] denotes the conditional expectation with respect to \u03b8d given wd,1:N , and the expectation is sampled by the MAP estimate, \u03b8\u0302d|wd,1:N , of \u03b8d given wd,1:N , defined as\n\u03b8\u0302d|wd,1:N = arg max \u03b8d\np(\u03b8d|wd,1:N ,\u03a6, \u03b1, \u03b2) (7)\nThe approximation gets more precise when p(\u03b8d|wd,1:N ,\u03a6, \u03b1, \u03b2) becomes more concentrated around \u03b8\u0302d|wd,1;N . Experimental results on several real datasets (Section 5) show that the approximation (6) provides excellent prediction performance."}, {"heading": "3.1 MAP Inference as a Convex Optimization Problem", "text": "Using the Bayesian rule p(\u03b8d|wd,1:N ,\u03a6, \u03b1) = p(\u03b8d|\u03b1)p(wd,1:N |\u03b8d,\u03a6)/p(wd,1:N |\u03a6, \u03b1) and the fact that p(wd,1:N |\u03a6, \u03b1) is independent of \u03b8d, we obtain the equivalent form of (7) as\n\u03b8\u0302d|wd,1:N = arg max \u03b8d\u2208PK\n[ ln p(\u03b8d|\u03b1) + ln p(wd,1:N |\u03b8d,\u03a6) ] (8)\nwhere PK = {\u03b8 \u2208 RK : \u03b8j \u2265 0, \u2211K j=1 \u03b8j = 1} denotes the (K \u2212 1)-dimensional probability simplex vector, p(\u03b8d|\u03b1) is the Dirichlet distribution described earlier, and p(wd,1:N |\u03b8d,\u03a6) can be computed by integrating p(wd,1:N , zd,1:N |\u03b8d,\u03a6) = \u220fN n=1 p(wd,n|zd,n,\u03a6)p(zd,n|\u03b8d) over zd,1:N , which leads to (derived in Appendix A)\np(wd,1:N |\u03b8d,\u03a6) = V\u220f v=1 ( K\u2211 j=1 \u03b8d,j\u03a6vj )xd,v = p(xd|\u03b8d,\u03a6) (9)\nwhere xd,v denotes the term frequency of the v-th word (in vocabulary) inside the d-th document, and xd denotes the V -dimensional bag-of-words (BoW) vector of the d-th document. Note that p(wd,1:N |\u03b8d,\u03a6) depends on wd,1:N only via the BoW vector xd, which is the sufficient statistics. Therefore, we use p(xd|\u03b8d,\u03a6) and p(wd,1:N |\u03b8d,\u03a6) interchangeably from now on. Substituting the expression of Dirichlet distribution and (9) into (8), we get\n\u03b8\u0302d|wd,1:N = arg max \u03b8d\u2208PK\n[ xTd ln(\u03a6\u03b8d) + (\u03b1\u2212 1)T ln \u03b8d ] = arg min\n\u03b8d\u2208PK\n[ \u2212 xTd ln(\u03a6\u03b8d)\u2212 (\u03b1\u2212 1)T ln \u03b8d ] (10)\nwhere we dropped the terms independent of \u03b8d, and 1 denotes an all-one vector. Note that when each element of \u03b1 is greater than or equal to one, the objective function in (10) is convex and the problem is convex. When \u03b1 is strictly greater than one, the objective function is strictly convex and has a unique solution. In this paper, we will only focus on the regime of \u03b1 being greater than one."}, {"heading": "3.2 Mirror Descent Algorithm for MAP Inference", "text": "An efficient approach to solving the constrained optimization problem (10) is the mirror descent algorithm (MDA) with Bregman divergence chosen to be generalized Kullback-Leibler divergence [1, 15, 18]. Specifically, let f(\u03b8d) denote the cost function in (10), then the MDA updates the MAP estimate of \u03b8d iteratively according to:\n\u03b8d,` = arg min \u03b8d\u2208PK\n[ f(\u03b8d,`\u22121) + [\u2207\u03b8df(\u03b8d,`\u22121)]T (\u03b8d \u2212 \u03b8d,`\u22121) + 1\nTd,` \u03a8(\u03b8d, \u03b8d,`\u22121)\n] (11)\n\u03b8d,` denotes the estimate of \u03b8d,` at the `-th iteration, Td,` denotes the step-size of MDA, and \u03a8(x, y) is the Bregman divergence chosen to be \u03a8(x, y) = xT ln(x/y) \u2212 1Tx + 1T y. The argmin in (11) can be solved in closed-form (see Appendix B) as\n\u03b8d,` = 1\nC\u03b8 \u00b7 \u03b8d,`\u22121 exp\n( Td,` [ \u03a6T\nxd \u03a6\u03b8d,`\u22121 + \u03b1\u2212 1 \u03b8d,`\u22121\n]) , ` = 1, . . . , L, \u03b8d,0 = 1\nK 1 (12)\nwhere C\u03b8 is a normalization factor such that \u03b8d,` adds up to one, denotes Hadamard product, L is the number of MDA iterations, and the divisions in (12) are element-wise operations. Note that the recursion (12) naturally enforces each \u03b8d,` to be on the probability simplex. The MDA step-size Td,` can be either constant, i.e., Td,` = T , or adaptive over iterations and samples, determined by line search (see Appendix C). The computation complexity in (12) is low since most computations are sparse matrix operations. For example, although by itself \u03a6\u03b8d,`\u22121 in (12) is a dense matrix multiplication, we only need to evaluate the elements of \u03a6\u03b8d,`\u22121 at the positions where the corresponding elements of xd are nonzero, because all other elements of xd/\u03a6\u03b8d,`\u22121 is known to be zero. Overall, the computation complexity in each iteration of (12) is O(nTok \u00b7K), where nTok denotes the number of unique tokens in the document. In practice, we only use a small number of iterations, L, in (12) and use \u03b8d,L to approximate \u03b8\u0302d|wd,1:N so that (6) becomes\np(yd|wd,1:N ,\u03a6, U, \u03b1, \u03b3) \u2248 p(yd|\u03b8d,L, U, \u03b3) (13) In summary, the inference of \u03b8d and yd can be implemented by the layered architecture in Figure 2, where the top layer infers yd using (13) and the MDA layers infer \u03b8d iteratively using (12). Figure 2 also implies that the the MDA layers act as a feature extractor by generating the MAP estimate \u03b8d,L for the output layer. Our end-to-end learning strategy developed in the next section jointly learns the model parameter U at the output layer and the model parameter \u03a6 at the feature extractor layers to maximize the posterior of the prediction variable given the input document."}, {"heading": "4 Learning by Mirror-Descent Back Propagation", "text": "We now consider the supervised learning problem (3) and the unsupervised learning problem (4), respectively, using the developed MDA-based MAP inference. We first consider the supervised learning problem. With (13), the discriminative learning problem (3) can be approximated by\narg min \u03a6,U\n[ \u2212 ln p(\u03a6|\u03b2)\u2212\nD\u2211 d=1\nln p(yd|\u03b8d,L, U, \u03b3) ]\n(14)\nwhich can be solved by stochastic gradient descent (SGD). Note that the cost function in (14) depends on U explicitly through p(yd|\u03b8d,L, U, \u03b3), which can be computed directly from its definition in Sec. 2. On the other hand, the cost function in (14) depends on \u03a6 implicitly through \u03b8d,L. From Figure 2, we observe that \u03b8d,L not only depends on \u03a6 explicitly (as indicated in the MDA block on the right-hand side of Figure 2) but also depends on \u03a6 implicitly via \u03b8d,L\u22121, which in turn depends on \u03a6 both explicitly and implicitly (through \u03b8d,L\u22122) and so on. That is, the dependency of\nthe cost function on \u03a6 is in a layered manner. Therefore, we devise a back propagation procedure to efficiently compute its gradient with respect to \u03a6 according to the mirror-descent graph in Figure 2, which back propagate the error signal through the MDA blocks at different layers. The gradient formula and the implementation details of the learning algorithm can be found in Appendices C\u2013D.\nFor the unsupervised learning problem (4), the gradient of ln p(\u03a6\u0303|\u03b2) with respect to \u03a6\u0303 assumes the same form as that of ln p(\u03a6|\u03b2). Moreover, it can be shown that the gradient of ln p(wd,1:N |\u03a6\u0303, \u03b1, \u03b3) with respect \u03a6\u0303 can be expressed as (see Appendix E):\n\u2202 ln p(wd,1:N |\u03a6\u0303, \u03b1) \u2202\u03a6\u0303 = E\u03b8d|xd\n{ \u2202\n\u2202\u03a6\u0303\n[ ln p(xd|\u03b8d, \u03a6\u0303) + ln p(\u03b8d|\u03b1) ]} (15)\nwhere p(xd|\u03b8d, \u03a6\u0303) assumes the same form as (9) except \u03a6 is replaced by \u03a6\u0303. The conditional expectation is evaluated with respect to the posterior probability p(\u03b8d|wd,1:N , \u03a6\u0303, \u03b1), which can be sampled by the MAP estimate of \u03b8d:\n\u2202 ln p(wd,1:N |\u03a6\u0303, \u03b1) \u2202\u03a6\u0303 \u2248 \u2202 \u2202\u03a6\u0303\n[ ln p(xd|\u03b8d,L, \u03a6\u0303) + ln p(\u03b8d,L|\u03b1) ] (16)\nwhere \u03b8d,L is an approximation of \u03b8\u0302d|wd,1:N computed via (12) and Figure 2."}, {"heading": "5 Experiments", "text": ""}, {"heading": "5.1 Description of Datasets and Baselines", "text": "We evaluated our proposed supervised learning (denoted as BP-sLDA) and unsupervised learning (denoted as BP-LDA) methods on two real-world datasets. The first dataset we use is a large-scale dataset built on Amazon movie reviews (AMR) [13]. The data set consists of 7.9 million movie reviews (1.48 billion words) from Amazon, written by 889,176 users, on a total of 253,059 movies. For text preprocessing we removed punctuations and lowercasing capital letters. A vocabulary of size 5,000 is built by selecting the most frequent words. Same as [19], we shifted the review scores so that they have zero mean. The task is formulated as a regression problem, where we seek to predict the rating score using the text of the review.\nSecond, we demonstrate the effectiveness of our algorithm on a multi-domain sentiment (MultiSent) classification task. Sentiment classification system has gained popularity due to their application to multiple text genres, including financial news and product reviews. We use the dataset provided by [5], which contains a total 342,104 product reviews consisting of 25 types of product reviews, such as apparel, electronics, kitchen and housewares. The task is formulated as a binary classification problem to predict the polarity (positive or negative) of each review. Similar to AMR task, we preprocessed the text by removing punctuations and lowercasing capital letters. A vocabulary of size 1,000 is built from the most frequent words.\nWe examined our proposed methods (BP-sLDA and BP-LDA) as well as baselines on both tasks. For BP-sLDA, p(yd|\u03b8d, U, \u03b3) is chosen to be Gaussion on the AMR regression task and multinormial on the MultiSent classification task (see Sec. 2). For BP-LDA, we first train the models in an unsupervised manner, and then generate per-document topic proportion \u03b8d as their features in the inference steps, on top of which we train a linear regression model in AMR regression task and train a logistic regression model in the MultiSent classification task, respectively. The baseline algorithms are implemented either in C++ or Java and our proposed algorithms are implemented in C#.2 We compared our methods to the unsupervised LDA learned by Gibbs sampling (GibbsLDA) [14], logistic/linear regression using raw bag-of-words (BoW), supervised-LDA (sLDA) [3], and MedLDA [21, 22]. Similar to BP-LDA, a separate linear/logistic regression is trained on the features generated by Gibbs-LDA. All the experiments are conducted with 5-fold cross validation."}, {"heading": "5.2 Prediction Performance", "text": "We first evaluate the prediction performance of different models on the AMR regression task. We use the predictive R2 to measure the prediction performance, defined as: pR2 = 1 \u2212 (\u2211d(yod \u2212\n2The code will be released soon.\nyd) 2)/( \u2211 d(y o d \u2212 y\u0304od)2), where yod denotes the label of the d-th document in the heldout (out-offold) set during the 5-fold cross validation, y\u0304od is the mean of all y o d in the heldout set, and yd is the predicted value. We first created a subset by randomly sampling 79K documents (reviews) from the 7.9 million reviews. The pR2 scores of different models with varying number of topics are shown in Figure 3(a). Note that the BP-sLDA model outperforms the other baselines with large margin. Moreover, the unsupervised BP-LDA model outperforms the unsupervised LDA model trained by Gibbs sampling (Gibbs-LDA). We further train our BP-sLDA model on the full 7.9M dataset with 5- fold cross validation and list the pR2 scores in Table 1. We can see that pR2 improves significantly compared to the best results on the 79K dataset shown in Figure 3(a). Moreover, the results in Table 1 also significantly outperform the pR2 scores of Gibbs-sLDA [23], Spectral-sLDA [19], and the Hybrid method (Gibbs-sLDA initialized with Spectral-sLDA) reported in [19], whose pR2 scores are between 0.1 and 0.2 for 5 \u223c 10 topics (and deteriorate when further increasing the topic number). The results therein are obtained on the same full AMR data with same setting as this paper. To further demonstrate the superior performance of BP-sLDA on the large vocabulary scenario, we trained BP-sLDA on the full 7.9M AMR dataset with full vocabulary (701K) and obtain the pR2 scores in Table 2. Note that the results are even significantly better than our results in Table 1.\nNext, we evaluate the performance of our algorithms on the binary classification task of multidomain sentiment analysis. We use the area-under-the-curve (AUC) of the operating curve of probability of correct positive versus probability of false positive as our performance metric. In Figure 3(b), we show the AUC of our methods and the baselines, which also shows that BP-sLDA outperforms other methods and that BP-LDA outperforms the unsupervised Gibbs-LDA model.\nFrom Figure 3, we note that the BP-sLDA model also consistently outperforms the linear regression or logistic regression model on the raw bag-of-words features. In Fig.3b (MultiSent), logistic regression achieves AUC of 90.4%, while BP-sLDA achieves the best AUC of 91.4% with 20 topics, which is about 10% relative improvement over logistic regression. And BP-sLDA significantly outperforms prior-art topic models, which have AUCs less than 80%. This means that our proposed discriminative training method and MDA-based MAP inference together are able to extract useful features from the raw BoW inputs for prediction purpose.\nTable 2: pR2 on full AMR data (7.9M documents and 701K vocabulary size).\nNumber of topics 5 10 20 50 100 Linear regression 0.403 BP-sLDA 0.633 0.677 0.672 0.682 0.684\n2 4 6 8 10 0\n0.1\n0.2\n0.3\n0.4\n0.5\nL\npR 2\nK=5 K=20 K=100\n(a) Number of MDA iterations L\n\u22124 \u22123 \u22122 \u22121 0 0\n0.1\n0.2\n0.3\n0.4\n0.5\nlog10(\u03b1\u22121)\npR 2\nK=5 K=20 K=100\n(b) Dirichlet parameter \u03b1\n\u22125 \u22124 \u22123 \u22122 \u22121 0\n0.1\n0.2\n0.3\n0.4\n0.5\nlog10(\u03b2\u22121)\npR 2\nK=5 K=20 K=100\n(c) Smoothing parameter \u03b2\nFigure 4: Sensitivity of hyper parameters: pR2 score for different L, \u03b1, and \u03b2.\nIn addition, we also conducted a new binary text classification experiment with highly promising results on a large-scale proprietary dataset for business-centric applications (1.2M documents and vocabulary size of 128K). In this new task, BP-sLDA (200 topics) achieves AUC of 92.2% and error rate of 15.2%, while LR has AUC of 90.5% and error rate of 17.1% (11% relative error rate cut). The gain is consistent with what was observed in the other two tasks."}, {"heading": "5.3 Analysis and Discussion", "text": "We now analyze the influence of different hyper parameters on the prediction performance. Note from Figure 3(a) that, when we increase the number of topics, the pR2 score of BP-sLDA first improves and then slightly deteriorates after it goes beyond 20 topics. This is most likely to be caused by overfitting on the small dataset (79K documents), because the BP-sLDA models trained on the full 7.9M dataset produce much higher pR2 scores (Table 1) than that on the 79K dataset and keep improving as the model size (number of topics) increases. Another interesting observation from Figure 3 is that, with limited amount of labeled data, the unsupervised LDA models (BP-LDA and Gibbs-LDA) are less prone to overfitting. Since unlabeled data are widely available, one future work is to combine the supervised and unsupervised parts together to have a semi-supervised LDA models. The framework suggested by [2, 12] could be one potential approach to integrate these two parts together.\nTo further understand the influence of the other hyper-parameters, we plot in Figure 4 the pR2 scores of BP-sLDA on the 79K AMR dataset for different values of L, \u03b1, and \u03b2. The performance is not very sensitive to the number of MDA inference steps L. One explanation for this phenomena is that the mirror-descent back propagation, as an end-to-end training of the prediction output, compensates the imperfection caused by the limited number of inference steps. And, we observe that, by properly tuning the Dirichlet parameter \u03b1 and the smoothing parameter \u03b2, we could further improve the prediction performance of the model. Moreover, although we mainly focus on convex inference under \u03b1 > 1, our algorithm could also handle \u03b1 < 1 case except that, in this case, the inference is no longer convex and hence no global optimal MAP inference is guaranteed as for the methods prior to this work. Table 3 shows the corresponding pR2 scores of BP-sLDA on the 7.9M AMR dataset. Although the results is not as good as the \u03b1 > 1 case in Table 1, they still significantly outperform the baselines."}, {"heading": "5.4 Efficiency in Computation Time", "text": "To compare the efficiency of the algorithms, we show the training time (in hours) of different models on the AMR dataset (79K and 7.9M) in Figure 5, which shows that our algorithm scales well when\nTable 3: pR2 for \u03b1 < 1 case on full AMR data (7.9M documents and 5K vocabulary size).\nNumber of topics 5 10 20 50 100 BP-sLDA (\u03b1 = 0.5) 0.488 0.548 0.575 0.571 0.574 BP-sLDA (\u03b1 = 0.1) 0.441 0.558 0.572 0.569 0.570\n0 20 40 60 80 100 0\n20\n40\n60\n80\n100\n120\nNumber of topics\nTr ai\nni ng\nti m\ne in\nh ou\nrs\nsLDA (79K) BP\u2212sLDA (79K) MedLDA (79K) BP\u2212sLDA (7.9M)\nFigure 5: Training time of different methods (in hours) on the AMR dataset.\nwe increase the model size (number of topics). In addition, it also scales well on the large-scale (7.9M) dataset, which can be completed within reasonable amount of time."}, {"heading": "6 Conclusion", "text": "We have developed novel learning approaches for both supervised and unsupervised LDA models, using exact MAP inference with mirror descent algorithm and back propagation. In particular, the supervised LDA model is trained in an end-to-end fully discriminative manner by maximizing the posterior probability of the prediction variable given input documents. We evaluate the prediction performance of the models on two real-world regression and classification tasks. The results show that the discriminative training approach significantly improves the performance of the supervised LDA model relative to previous learning methods. Moreover, the newly developed inference and learning techniques also improve the performance of the unsupervised LDA model by providing better features for prediction. Future works include (i) exploring other optimization algorithms for the MAP inference problem, such as accelerated mirror descent, and (ii) developing semi-supervised learning of LDA based on the framework suggested by [2, 12]. More importantly, note that the layered architecture in Figure 2 could also be viewed as a deep feedforward neural network with special structures designed from the topic model in Figure 1. This opens up a new direction of combining the strength of both (generative) topic models and neural networks to develop new deep learning models that are scalable, interpretable and having high prediction performance."}, {"heading": "B Derivation of the Recursion for Mirror Descent Algorithm", "text": "First, we rewrite the optimization problem (11) as\nmin \u03b8d\n[\u2207\u03b8df(\u03b8d,`\u22121)]T (\u03b8d \u2212 \u03b8d,`\u22121) + 1\nTd,` \u03a8(\u03b8d, \u03b8d,`\u22121) (19)\ns.t. 1T \u03b8d = 1, \u03b8d 0 (20) where \u03b8d 0 denotes that each element of the vector \u03b8d is greater than or equal to zero. Using the fact that \u03a8(x, y) = xT ln(x/y)\u2212 1Tx + 1T y, the constrained optimization problem (19)\u2013(20) becomes\nmin \u03b8d\n[\u2207\u03b8df(\u03b8d,`\u22121)]T (\u03b8d \u2212 \u03b8d,`\u22121) + 1\nTd,`\n[ \u03b8Td ln\n\u03b8d \u03b8d,`\u22121\n\u2212 1T \u03b8d + 1T \u03b8d,`\u22121 ]\n(21)\ns.t. 1T \u03b8d = 1, \u03b8d 0 (22) Dropping the terms independent of \u03b8d, we can write (21)\u2013(22) as\nmin \u03b8d\n[\u2207\u03b8df(\u03b8d,`\u22121)]T \u03b8d + 1\nTd,`\n[ \u03b8Td ln\n\u03b8d \u03b8d,`\u22121\n\u2212 1T \u03b8d ]\n(23)\ns.t. 1T \u03b8d = 1, \u03b8d 0 (24)\nTo solve (23)\u2013(24), we write its Lagrangian as\nL = [\u2207\u03b8df(\u03b8d,`\u22121)]T \u03b8d + 1\nTd,`\n[ \u03b8Td ln\n\u03b8d \u03b8d,`\u22121\n\u2212 1T \u03b8d ] + \u03bb(1T \u03b8d \u2212 1) (25)\nwhere we relaxed the nonnegative constraint in the above Lagrange multiplier. However, we will show that the solution obtained will automatically be nonnegative mainly because of the logarithm term in the cost function. Taking the derivative of L with respect to \u03b8d and \u03bb and setting them to zero, we have, respectively,\n\u2202L \u2202\u03b8d = \u2207\u03b8df(\u03b8d,`\u22121) + 1 Td,`\n[ ln\n\u03b8d \u03b8d,`\u22121\n] + \u03bb1 = 0\n\u2202L \u2202\u03bb = 1T \u03b8d \u2212 1 = 0\nwhich leads to\n\u03b8d = 1\n\u03bb \u03b8d,`\u22121 exp (\u2212Td,` \u00b7 \u2207\u03b8df(\u03b8d,`\u22121))\n1T \u03b8d = 1\nSolving the above two equations together, we obtain\n\u03b8d = 1\nC\u03b8 \u03b8d,`\u22121 exp (\u2212Td,` \u00b7 \u2207\u03b8df(\u03b8d,`\u22121)) (26)\nwhere C\u03b8 is a normalization factor such that \u03b8d,` adds up to one. Note that the above recursion can always guarantee non-negativity of the entries in the vector \u03b8d,` since we will always initialize the vector in the feasible region. Recall that f(\u03b8d) is the cost function on the right-hand side of (10), which is given by\nf(\u03b8d) = \u2212xTd ln(\u03a6\u03b8d)\u2212 (\u03b1\u2212 1)T ln \u03b8d Therefore, the gradient of f(\u03b8d) can be computed as\n\u2207\u03b8df(\u03b8d) = \u2212 xd \u03a6\u03b8d \u2212 \u03b1\u2212 1 \u03b8d (27)\nSubstituting the above gradient formula into (26), we obtain the desired result in (12).\nC Implementation Details of the BP-sLDA\nIn this section, we describe the implementation details of the mirror-descent back propagation for the end-to-end learning of the supervised LDA model. Specifically, we will describe the details of the inference algorithm, and the model parameter estimation algorithm.\nC.1 Inference algorithm: Mirror Descent\nLet f(\u03b8d) denote the objective function in (12). As we discussed in the paper, we use recursion (12) to iteratively find the MAP estimate of \u03b8d given wd,1:N , which we repeat below:\n\u03b8d,` = 1\nC\u03b8 \u00b7 \u03b8d,`\u22121 exp\n( Td,` [ \u03a6T\nxd \u03a6\u03b8d,`\u22121 + \u03b1\u2212 1 \u03b8d,`\u22121\n]) , ` = 1, . . . , L, \u03b8d,0 = 1\nK 1 (28)\nThe step-size Td,` in mirror descent can be chosen to be either constant, i.e., Td,` = T , or adaptive over iterations ` and documents d. To adaptively determine the step-size, we can use line search procedure. A simple line search can be implemented as follows. For each document d:\n\u2022 Initialization: Td,0 = Td\u22121,L/\u03b7, where 0 < \u03b7 < 1 (e.g., \u03b7 = 0.5). \u2022 Repeat:\n\u2013 Update \u03b8d,` by (28) .\n\u2013 Break if following condition holds:\nf(\u03b8d,`) \u2264 f(\u03b8d,`\u22121) + [\u2207\u03b8df(\u03b8d,`\u22121)]T (\u03b8d,` \u2212 \u03b8d,`\u22121) + 1\n2Td,` \u03a8(\u03b8d,`, \u03b8d,`\u22121)\n(29)\nelse: Td,` \u2190 \u03b7 \u00b7 Td,` Moreover, \u03a8(\u03b8d,`, \u03b8d,`\u22121) can also be replaced by the squared vector 1-norm:\nf(\u03b8d,`) \u2264 f(\u03b8d,`\u22121) + [\u2207\u03b8df(\u03b8d,`\u22121)]T (\u03b8d,` \u2212 \u03b8d,`\u22121) + 1\n2Td,` \u2016\u03b8d,` \u2212 \u03b8d,`\u22121\u201621 (30)\nThe line search approach determines the step-sizes adaptively, automatically stabilizing the algorithm and making inference converge faster.\nC.2 Parameter Estimation: Stochastic Gradient Descent with Back Propagation\nWe first rewrite the training cost (14) as\nJ(U,\u03a6) = D\u2211 d=1 Qd(U,\u03a6) (31)\nwhere Qd(\u00b7) denotes the loss function at the d-th document, defined as\nQd(U,\u03a6) , \u2212 1\nD ln p(\u03a6|\u03b2)\u2212 ln p(yd|\u03b8d,L, U, \u03b3) (32)\nNote that, we do not have constraint on the model parameter U . Therefore, to update U , we can directly use the standard mini-batch stochastic gradient descent algorithm. We randomly sample a mini-batch of documents, and then perform MAP inference of \u03b8d for each document in the minibatch. And then, we compute the stochastic gradient of the loss function for each document, and use the averaged stochastic gradient to update U .\nOn the other hand, each column of the model parameter \u03a6 is constrained to be on a (V \u2212 1)- dimension probability simplex, i.e, each element of \u03a6 has to be nonnegative and each column sum up to one (i.e., \u03a6 is a left-stochastic matrix). For this reason, we need to enforce the constraint on \u03a6. Recalling the definition of the Dirichlet smoothing p(\u03a6|\u03b2), we have\n\u2212 1 D ln p(\u03a6|\u03b2) = \u2212 1 D ln (\u0393(V \u03b2) \u0393(\u03b2)V )K K\u220f j=1 V\u220f v=1 \u03a6\u03b2\u22121vj  = \u2212 1\nD K\u2211 j=1 V\u2211 v=1 (\u03b2 \u2212 1) ln \u03a6vj + C (33)\nObserve that expression (33) provides a natural log barrier for each element of \u03a6 to enforce it to be nonnegative. Therefore, we can relax the nonnegative constraint on the elements of \u03a6 and focus on enforcing the left-stochastic constraint. Let \u03c6j be the j-th column of \u03a6, we use the following algorithm to update the estimate of \u03c6j :\n\u2022 Sample a mini-batch of documents. \u2022 Perform MAP inference of yd and \u03b8d using (12) for each document in the mini-batch. \u2022 Compute the gradient \u2202Qd/\u2202\u03c6j for each document d in the mini-batch and average them:\n\u2206\u03c6j = 1\nDb \u2211 d\u2208Db \u2202Qd \u2202\u03c6j , j = 1, . . . ,K\nwhere \u2202Qd/\u2202\u03c6j is the j-th column of \u2202Qd/\u2202\u03a6, which can be computed according to the formula in Sec. D of this Appendix, Db denotes the set of the documents in the minibatch, and Db is the number of documents in the mini-batch. The gradients are evaluated at \u03c6j,t\u22121, the previous estimate of \u03c6j at time t\u2212 1.\n\u2022 Set initial learning rate: \u00b5\u03c6j = \u00b50, j = 1, . . . ,K. \u2022 For each j = 1, . . . ,K, repeat until all the elements of \u03c6j,t are nonnegative:\n\u2013 Update \u03c6j :\n\u03c6j,t = \u03a0{\u03c6:1T\u03c6=1} ( \u03c6j,t\u22121 \u2212 \u00b5\u03c6j \u00b7\u2206\u03c6j ) (34)\nwhere \u03a0{\u03c6:1T\u03c6=1}(\u00b7) is the Euclidean projection operator onto the affine space: {\u03c6 : 1T\u03c6 = 1}, which can be evaluated efficiently in closed-form:\n\u03a0{\u03c6: 1T\u03c6=1}(x) =\n( I \u2212 11 T\nK\n) x+ 1\nK 1\n\u2013 Shrink the learning rate: \u00b5\u03c6j = \u03b7\u00b5\u03c6j , where 0 < \u03b7 < 1 (e.g., \u03b7 = 0.5).\nIn the above iteration (34), we do not need to recompute the gradient \u2206\u03c6j but just iteratively shrink the learning rates until there is no violation of the nonnegativity constraint. This line search is only used to avoid the stochastic gradient descent from randomly moving \u03c6j into the nonnegative regime, where the log-barrier cannot push \u03c6j back to the positive region. Furthermore, we are allowing different columns of \u03a6 to have different learning rates, which, from our observation in experiments, makes the training algorithm converge much faster than the uniform learning rate over all columns."}, {"heading": "D Gradient Formula of BP-sLDA", "text": "In this section, we give the gradient formula for the supervised learning of BP-sLDA. To this end, we first rewrite the training cost (14) as\nJ(U,\u03a6) = D\u2211 d=1 Qd(U,\u03a6) (35)\nwhere Qd(\u00b7) denotes the loss function at the d-th document, defined as\nQd(U,\u03a6) , \u2212 1\nD ln p(\u03a6|\u03b2)\u2212 ln p(yd|\u03b8d,L, U, \u03b3) (36)\nThe expressions for the two terms in (36) are given by\n\u2212 1 D ln p(\u03a6|\u03b2) = \u2212 1 D ln (\u0393(V \u03b2) \u0393(\u03b2)V )K K\u220f j=1 V\u220f v=1 \u03a6\u03b2\u22121vj  = \u2212 1\nD K\u2211 j=1 V\u2211 v=1 (\u03b2 \u2212 1) ln \u03a6vj + C (37)\n\u2212 ln p(yd|\u03b8d,L, U, \u03b3) =  \u2212 V\u2211 j=1 yd,j ln exp(\u03b3 \u00b7 po,d,j)\u2211V m=1 exp(\u03b3 \u00b7 po,d,m) classification 1\n2\u03b3 \u2016yd \u2212 po,d\u201622 + C regression\n=  \u2212 V\u2211 j=1 yd,j\u03b3 \u00b7 po,d,j + ln V\u2211 m=1 exp(\u03b3 \u00b7 po,d,m) classification 1\n2\u03b3 \u2016yd \u2212 po,d\u201622 + C regression\n(38)\nwhere C in the above expressions denotes a constant term that is independent of U and \u03a6, and\npo,d , U\u03b8d,L (39)\nIn order to apply stochastic gradient descent to minimize (35), it suffices to evaluate the gradient of Qd(U,\u03a6) with respect to U and \u03a6, which we now proceed to derive. Note that the choice of p(yd|\u03b8d,L, U, \u03b3) is not restricted to the above two options in our framework. Other forms could also be used and the corresponding gradient formula could also be derived. However, in this paper, we only list the gradient formula for these two classical choices.\nD.1 Gradient with respect to U\nFirst, we derive the gradient of Qd(\u00b7) with respect U . Note that the only term in (36) depending on U is ln p(yd|\u03b8d,L, U, \u03b3). Therefore, we have \u2202Qd/\u2202U = \u2212\u2202 ln p(yd|\u03b8d,L, U, \u03b3)/\u2202U . Taking the gradient of (38) with respect to U and after some simple algebra, we get\n\u2202Qd \u2202U = { \u2212\u03b3 \u00b7 (yd \u2212 y\u0302d)\u03b8Td,L classification \u2212 1\u03b3 \u00b7 (yd \u2212 y\u0302d)\u03b8Td,L regression\n(40)\nwhere y\u0302d is defined as\ny\u0302d = { \u03c3(\u03b3 \u00b7 po,d) classification po,d regression\nwhere \u03c3(\u00b7) is the soft-max function:\n\u03c3(x) , x\u2211V\nm=1 exp(xm)\nD.2 Gradient with respect to \u03a6\nIn this subsection, we give the final expression for the gradient of Qd with respect to \u03a6. The derivation can be found in Sec. D.3 of this Appendix.\n\u2202Qd \u2202\u03a6 = \u2212 1 D \u00b7 \u03b2 \u2212 1 \u03a6 + L\u2211 `=1 \u2202Qd \u2202\u03a6`\n(41)\nwhere \u2202Qd/\u2202\u03a6` is defined as\n\u2202Qd \u2202\u03a6`\n= Td,` \u00b7 {\nxd \u03a6\u03b8d,`\u22121\n(\u03b8d,` \u03bed,`)T \u2212 [ \u03a6(\u03b8d,` \u03bed,`)\nxd (\u03a6\u03b8d,`\u22121)2\n] \u03b8Td,`\u22121 } (42)\nand \u03bed,` is an intermediate error vector computed from the following backward recursion: \u03bed,`\u22121 = (I\u22121\u03b8Td,`\u22121) { \u03b8d,` \u03bed,` \u03b8d,`\u22121 \u2212Td,` \u00b7 [ \u03a6Tdiag ( xd (\u03a6\u03b8d,`\u22121)2 ) \u03a6+diag ( \u03b1\u2212 1 \u03b82d,`\u22121 )] (\u03b8d,` \u03bed,`) } (43)\nwhich is initialized at\n\u03beL,t = \u2212(I \u2212 1\u03b8Td,L) \u00b7 UT \u00b7 \u03b3(yd \u2212 y\u0302d) (44) In the above back propagation formula, xd and yd are the input bag-of-words vector and the label. The quantities \u03b8d,` and y\u0302d are obtained from the inference step, the MDA step-size Td,` is either set to be a constant (as a hyper-parameters) or determined by line-search in the inference step.\nSimilar to the inference iteration (12), the above gradients can be computed efficiently by exploiting the sparsity of the vector xd. For example, only the elements at the nonzero positions of xd need to be computed for \u03a6\u03b8d,`\u22121 and \u03a6(\u03b8d,` \u03bed,`) since xd\u03a6\u03b8d,`\u22121 and xd (\u03a6\u03b8d,`\u22121)2\nare known to be zero at these positions. Moreover, although (\u03b2\u22121)/\u03a6 is a dense matrix operation, it is the same within one mini-batch and can therefore be computed only once over each mini-batch, which can significantly reduce the amount of computation.\nD.3 Derivation of the gradient with respect to \u03a6\nIn this subsection, we derive the gradient formula for \u03a6. Note from (36) that, there are two terms that depend on \u03a6, and\n\u2202Qd \u2202\u03a6 = \u2202 \u2202\u03a6 ( \u2212 1 D ln p(\u03a6|\u03b2) ) + \u2202 \u2202\u03a6 ( \u2212 ln p(yd|\u03b8d,L, U, \u03b3) ) (45)\nThe first term depends on \u03a6 explicitly and its gradient can be evaluated direct as\n\u2202\n\u2202\u03a6 ( \u2212 1 D ln p(\u03a6|\u03b2) ) = \u2202 \u2202\u03a6 \u2212 1 D K\u2211 j=1 V\u2211 v=1 (\u03b2 \u2212 1) ln \u03a6vj  = \u2212 1\nD \u00b7 \u03b2 \u2212 1 \u03a6 (46)\nThe second term, however, depends on \u03a6 implicitly through \u03b8d,L. From Figure 2, we observe that \u03b8d,L not only depends on \u03a6 explicitly (as indicated in the MDA block on the right-hand side of Figure 2) but also depends on \u03a6 implicitly via \u03b8d,L\u22121, which in turn depends on \u03a6 both explicitly and implicitly (through \u03b8d,L\u22122) and so on. That is, the dependency of the cost function on \u03a6 is in a layered manner. For this reason, we need to apply chain rule to derive the its full gradient with respect to \u03a6, which we describe below.\nFirst, as we discussed above, each MDA block in Figure 2 contains \u03a6, and Qd(U,\u03a6) depends on the \u03a6 appeared at different layers through \u03b8d,L, . . . , \u03b8d,1. If we denote these \u03a6 at different layers as \u03a6L, . . . ,\u03a61, and introduce an auxiliary function Qd(U,\u03a61, . . . ,\u03a6L) to represent an artificial function, \u2212 ln p(yd|\u03b8d,L, U, \u03b3), with this \u201cuntied\u201d \u03a6 across layers in Figure 2, then the original \u2212 ln p(yd|\u03b8d,L, U, \u03b3) with \u201ctied\u201d \u03a6 across layers can be written in the form of Qd(U,\u03a61, . . . ,\u03a6L) as\n\u2212 ln p(yd|\u03b8d,L, U, \u03b3) = Qd(U,\u03a6, . . . ,\u03a6) (47) For this reason, we can express the gradient of \u2212 ln p(yd|\u03b8d,L, U, \u03b3) with respect to \u03a6 as\n\u2202\n\u2202\u03a6\n( \u2212 ln p(yd|\u03b8d,L, U, \u03b3) ) = L\u2211 `=1 \u2202Qd \u2202\u03a6`\n(48)\nwhere \u2202Qd/\u2202\u03a6` denotes the gradient of Q(U,\u03a61, . . . ,\u03a6L) with respect to \u03a6` evaluated at \u03a61 = \u03a62 = \u00b7 \u00b7 \u00b7 = \u03a6L = \u03a6. Therefore, we only need to compute the gradient \u2202Qd/\u2202\u03a6`. For simplicity of notation, we drop the subscript of d in \u03b8d,` and define the following intermediate quantities:\nz` = Td,` \u00b7 [ \u03a6T\nxd \u03a6\u03b8`\u22121 + \u03b1\u2212 1 \u03b8`\u22121 ] p` = \u03b8`\u22121 exp(z`)\nThen the MDA inference recursion (12) can be written in the following equivalent form: z` = Td,` \u00b7 [ \u03a6T\nxd \u03a6\u03b8`\u22121 + \u03b1\u2212 1 \u03b8`\u22121\n] (49)\np` = \u03b8`\u22121 exp(z`) (50) \u03b8` =\np` 1T p`\n(51)\nTo derive the gradient \u2202Qd/\u2202\u03a6`, it suffices to derive \u2202Q\u2202\u03a6`,ji . Note that\n\u2202Qd \u2202\u03a6`,ji = \u2202pT` \u2202\u03a6`,ji \u00b7 \u2202Qd \u2202p` = \u2202pT` \u2202\u03a6`,ji \u00b7 \u03b4` (52)\nwhere\n\u03b4` , \u2202Qd \u2202p`\n(53)\nis an intermediate quantities which follows a backward recursion to be derived later. To proceed, we need to derive \u2202pT` /\u2202\u03a6`,ji:\n\u2202pT` \u2202\u03a6`,ji = \u03b8T`\u22121 \u2202 exp(zT` ) \u2202\u03a6`,ji\n= \u03b8T`\u22121 [ \u2202zT` \u2202\u03a6`,ji \u00b7 diag ( exp(z`) )]\n= \u03b8T`\u22121 [ \u2202zT` \u2202\u03a6`,ji 1 exp(zT` ) ]\n= \u03b8T`\u22121 exp(zT` ) \u2202zT` \u2202\u03a6`,ji\n= pT` \u2202zT` \u2202\u03a6`,ji\n(54)\nThen, we need to derive the expression for \u2202z T l\n\u2202\u03a6`,ji :\n\u2202zT` \u2202\u03a6`,ji\n= Td,` \u00b7 { \u2202\n\u2202\u03a6`,ji\n( xTd\n\u03b8T`\u22121\u03a6 T `\n) \u00b7 \u03a6` +\nxTd \u03b8T`\u22121\u03a6 T ` \u00b7 \u03a6` \u03a6`,ji\n}\n= Td,` \u00b7 { \u2202\n\u2202\u03a6`,ji\n( xTd\n\u03b8T`\u22121\u03a6 T `\n) \u00b7 \u03a6` +\nxTd \u03b8T`\u22121\u03a6 T `\n\u00b7 Eji }\n= Td,` \u00b7 { \u2212\u2202\u03b8 T `\u22121\u03a6 T `\n\u2202\u03a6`,ji \u00b7 diag\n( xd\n(\u03a6`\u03b8`\u22121)2\n) \u00b7 \u03a6` +\nxTd \u03b8T`\u22121\u03a6 T l\n\u00b7 Eji }\n= Td,` \u00b7 { \u2212\u03b8T`\u22121Eij \u00b7 diag ( xd\n(\u03a6`\u03b8`\u22121)2\n) \u00b7 \u03a6` +\nxTd \u03b8T`\u22121\u03a6 T `\n\u00b7 Eji }\n= Td,` \u00b7 { \u2212[\u03b8`\u22121]i [ xd\n(\u03a6`\u03b8`\u22121)2 ] j eTj \u03a6` + [ xd \u03a6`\u03b8`\u22121 ] j eTi } (55)\nwhere ei denotes a one-hot vector with the i-th element being one and all other element equal to zero, and Eji denotes a matrix whose (j, i)-th element is one and all other elements are zero. Substituting the above expression into (54), we obtain\n\u2202pT` \u2202\u03a6`,ji = pT` \u2202zT` \u2202\u03a6`,ji\n= Td,` \u00b7 pT` { \u2212[\u03b8`\u22121]i [ xd\n(\u03a6`\u03b8`\u22121)2 ] j eTj \u03a6` + [ xd \u03a6`\u03b8`\u22121 ] j eTi } (56)\nTherefore,\n\u2202Qd \u2202\u03a6`,ji = \u2202pT` \u2202\u03a6`,ji \u00b7 \u03b4`\n= Td,` \u00b7 p` { \u2212[\u03b8`\u22121]i [ xd\n(\u03a6`\u03b8`\u22121)2 ] j eTj \u03a6` + [ xd \u03a6`\u03b8`\u22121 ] j eTi } \u03b4`\n= Td,` \u00b7 { \u2212[\u03b8`\u22121]i [ xd\n(\u03a6`\u03b8`\u22121)2 ] j ( p` eTj \u03a6` ) \u03b4` + [ xd \u03a6`\u03b8`\u22121 ] j (p` eTi )\u03b4` }\n= Td,` \u00b7 { \u2212[\u03b8`\u22121]i [ xd\n(\u03a6`\u03b8`\u22121)2 ] j ( p` eTj \u03a6` ) \u03b4` + [ xd \u03a6`\u03b8`\u22121 ] j [p`]i \u00b7 [\u03b4`]i }\n= Td,` \u00b7 { \u2212[\u03b8`\u22121]i [ xd\n(\u03a6`\u03b8`\u22121)2 ] j ( eTj \u03a6`diag(p`) ) \u03b4` + [ xd \u03a6`\u03b8`\u22121 ] j [p`]i \u00b7 [\u03b4`]i }\n= Td,` \u00b7 { \u2212[\u03b8l]i [ xd\n(\u03a6`\u03b8`\u22121)2 ] j eTj \u03a6`(pl\u22121 \u03b4`) + [ xd \u03a6`\u03b8`\u22121 ] j [p`]i \u00b7 [\u03b4`]i }\n= Td,` \u00b7 { \u2212[\u03b8`\u22121]i [ xd\n(\u03a6`\u03b8`\u22121)2 ] j [\u03a6`(p` \u03b4`)]j + [ xd \u03a6`\u03b8`\u22121 ] j [p`]i \u00b7 [\u03b4`]i }\n(57)\nWriting the above expressions into matrix form (derivative with respect \u03a6`), we obtain:\n\u2202Qd \u2202\u03a6`\n= Td,` \u00b7 {\nxd \u03a6`\u03b8`\u22121\n(p` \u03b4`)T \u2212 [ \u03a6`(p` \u03b4`)\nxd (\u03a6`\u03b8`\u22121)2\n] \u03b8T`\u22121 } (58)\nNow we need to derive the recursion for computing \u03b4`. By the definition of \u03b4` in (53), we have\n\u03b4`\u22121 , \u2202Qd \u2202p`\u22121\n= \u2202\u03b8T`\u22121 \u2202p`\u22121 \u00b7 \u2202p T ` \u2202\u03b8`\u22121 \u00b7 \u2202Qd \u2202p`\n= \u2202\u03b8T`\u22121 \u2202p`\u22121 \u00b7 \u2202p T ` \u2202\u03b8`\u22121 \u00b7 \u03b4` (59)\nTo continue, we have to evaluate \u2202\u03b8 T `\u22121\n\u2202p`\u22121 and \u2202p\nT `\n\u2202\u03b8`\u22121 . By (49)\u2013(51), we have\n\u2202pT` \u2202\u03b8`\u22121 = \u2202\u03b8T`\u22121 \u2202\u03b8`\u22121 1 exp(zT` ) + 1\u03b8T`\u22121 \u2202 exp(zT` ) \u2202\u03b8`\u22121\n= I [1 exp(zT` )] + 1\u03b8T`\u22121 [ \u2202zT` \u2202\u03b8`\u22121 \u00b7 \u2202e T ` \u2202z` ] = diag ( exp(z`) ) + 1\u03b8T`\u22121 [ \u2202zT` \u2202\u03b8`\u22121 \u00b7 diag ( exp(z`) )]\n= diag ( exp(z`) ) + 1\u03b8T`\u22121 [ \u2202zT` \u2202\u03b8`\u22121 1 exp(zT` ) ]\n= diag ( exp(z`) ) + 1 [ \u03b8T`\u22121 exp(zT` ) ] \u2202z T `\n\u2202\u03b8`\u22121 = diag ( exp(z`) )\n+ 1pT` \u2202zT` \u2202\u03b8`\u22121\n(60)\nTo proceed, we need to derive the expression for \u2202z T `\n\u2202\u03b8`\u22121 :\n\u2202zT` \u2202\u03b8`\u22121\n= Td,` \u00b7 { \u2202\n\u2202\u03b8`\u22121\n( xTd\n\u03b8T`\u22121\u03a6 T `\n) \u03a6` + \u2202\n\u2202\u03b8`\u22121 ( \u03b1\u2212 1 \u03b8`\u22121 )T}\n= Td,` \u00b7 { \u2212\u2202\u03b8 T `\u22121\u03a6 T `\n\u2202\u03b8`\u22121 \u00b7 diag\n( xd\n(\u03a6T` \u03b8`\u22121) 2\n) \u03a6` \u2212 diag ( \u03b1\u2212 1 \u03b82`\u22121 )}\n= Td,` \u00b7 { \u2212\u03a6T` diag ( xd\n(\u03a6T` \u03b8`\u22121) 2\n) \u03a6` \u2212 diag ( \u03b1\u2212 1 \u03b82`\u22121 )} = \u2212Td,` \u00b7 { \u03a6T` diag ( xd\n(\u03a6T` \u03b8`\u22121) 2\n) \u03a6` + diag ( \u03b1\u2212 1 \u03b82`\u22121 )} (61)\nSubstituting the above expression into (60), we get the expression for \u2202p T `\n\u2202\u03b8`\u22121 :\n\u2202pT` \u2202\u03b8`\u22121 = diag\n{ exp ( Td,` [ \u03a6T`\nxd \u03a6`\u03b8`\u22121 + \u03b1\u2212 1 \u03b8`\u22121 ])} \u2212 Td,` \u00b7 (1pT` ) [ \u03a6T` diag ( xd\n(\u03a6`\u03b8`\u22121)2\n) \u03a6` + diag ( \u03b1\u2212 1 \u03b82`\u22121 )] = diag\n( p` \u03b8`\u22121 ) \u2212 Td,` \u00b7 (1pT` ) [ \u03a6T` diag ( xd (\u03a6`\u03b8`\u22121)2 ) \u03a6` + diag ( \u03b1\u2212 1 \u03b82`\u22121 )] = { diag ( 1\n\u03b8`\u22121\n) \u2212 Td,` \u00b7 [ \u03a6T` diag ( xd\n(\u03a6`\u03b8`\u22121)2\n) \u03a6` + diag ( \u03b1\u2212 1 \u03b82`\u22121 )]} diag(p`)\n(62)\nTo complete the derivation of the recursion (59), we need to derive \u2202\u03b8 T `\u22121\n\u2202p`\u22121,t , which is given by\n\u2202\u03b8T`\u22121 \u2202p`\u22121 = \u2202pT`\u22121 \u2202p`\u22121 \u00b7 1 1T p`\u22121 + \u2202 \u2202p`\u22121\n( 1\n1T p`\u22121\n) pT`\u22121 =\nI \u2212 1\u03b8T`\u22121 1T p`\u22121\n(63)\nExpressions (59), (62) and (63) provide the complete backward recursion for \u03b4`, which starts from ` = L and ends at ` = 2. Finally, to initialize this backward recursion, we need to derive the expression for \u03b4L. By its definition, we have\n\u03b4L , \u2202Qd \u2202pL\n= \u2202\u03b8TL \u2202pL \u00b7 \u2202pTo,d \u2202\u03b8L \u00b7 \u2202Qd \u2202po,d\n= \u2202\u03b8TL \u2202pL \u00b7 UT \u00b7 \u2202Qd \u2202po,d\n= 1\n1T pL (I \u2212 1\u03b8TL) \u00b7 UT \u00b7 \u2202Qd \u2202po,d\n(64)\nwhere in the last step we substituted (63). By (47) and(38), we have\n\u2202Qd \u2202po,d = \u2202 \u2202po,d\n( \u2212 ln p(yd|\u03b8d,L, U, \u03b3) ) =\n{ \u2212\u03b3 \u00b7 (yd \u2212 y\u0302d) classification \u2212 1\u03b3 \u00b7 (yd \u2212 y\u0302d) regression\n(65)\nTherefore,\n\u03b4L =  \u2212 1 1T pL (I \u2212 1\u03b8TL) \u00b7 UT \u00b7 \u03b3 \u00b7 (yd \u2212 y\u0302d) classification\n\u2212 1 1T pL (I \u2212 1\u03b8TL) \u00b7 UT \u00b7 1 \u03b3 \u00b7 (yd \u2212 y\u0302d) regression\n(66)\nAs a final remark, we found in practical implementation that p` could be very large while \u03b4` could be small, which leads to potential numerical instability. To address this issue, we introduce the following new variable:\n\u03bed,` , 1 T p` \u00b7 \u03b4` (67)\nThen, the quantities p` and \u03b4` can be replaced with one variable \u03bed,`, and the backward recursion of \u03b4` can also be replaced with the backward recursion of \u03bed,`. With some simple algebra, we obtain the final gradient expression for \u03a6 in Appendix D.2."}, {"heading": "E Gradient Formula of BP-LDA", "text": "The unsupervised learning problem (4) can be rewritten, equivalently, as minimizing the following cost function:\nJ(\u03a6\u0303) = D\u2211 d=1 Qd(\u03a6\u0303) (68)\nwhere Qd(\u03a6\u0303) is the loss function defined as\nQd(\u03a6\u0303) = \u2212 1\nD ln p(\u03a6\u0303|\u03b2)\u2212 ln p(wd,1:N |\u03a6\u0303, \u03b1) (69)\nTaking the gradient of both sides of (69), we obtain\n\u2202Qd\n\u2202\u03a6\u0303 =\n\u2202\n\u2202\u03a6\u0303\n( \u2212 1 D ln p(\u03a6\u0303|\u03b2) ) + \u2202\n\u2202\u03a6\u0303\n( \u2212 ln p(wd,1:N |\u03a6\u0303, \u03b1) ) (70)\nThe first term in (70) has already been derived in (46):\n\u2202 \u2202\u03a6\u0303 ln p(\u03a6\u0303|\u03b2) = \u03b2 \u2212 1 \u03a6\u0303 (71)\nwhere \u03b2\u22121 \u03a6\u0303 denotes elementwise division of the scalar \u03b2 \u2212 1 by the matrix \u03a6\u0303. We now proceed to derive the second term in (70).\n\u2202\n\u2202\u03a6\u0303 ln p(wd,1:N |\u03a6\u0303, \u03b1) =\n1 p(wd,1:N |\u03a6\u0303, \u03b1) \u00b7 \u2202 \u2202\u03a6\u0303 p(wd,1:N |\u03a6\u0303, \u03b1)\n= 1 p(wd,1:N |\u03a6\u0303, \u03b1) \u00b7 \u222b \u03b8d [ \u2202 \u2202\u03a6\u0303 p(wd,1:N , \u03b8d|\u03a6\u0303, \u03b1) ] d\u03b8d\n= 1 p(wd,1:N |\u03a6\u0303, \u03b1) \u00b7 \u222b \u03b8d [ \u2202 \u2202\u03a6\u0303 ln p(wd,1:N , \u03b8d|\u03a6\u0303, \u03b1) ] \u00b7 p(wd,1:N , \u03b8d|\u03a6\u0303, \u03b1)d\u03b8d\n= \u222b \u03b8d [ \u2202 \u2202\u03a6\u0303 ln p(wd,1:N , \u03b8d|\u03a6\u0303, \u03b1) ] \u00b7 p(wd,1:N , \u03b8d|\u03a6\u0303, \u03b1) p(wd,1:N |\u03a6\u0303, \u03b1) d\u03b8d\n= \u222b \u03b8d [ \u2202 \u2202\u03a6\u0303 ln p(wd,1:N , \u03b8d|\u03a6\u0303, \u03b1) ] \u00b7 p(\u03b8d|wd,1:N , \u03a6\u0303, \u03b1)d\u03b8d\n= E\u03b8d|wd,1:N\n[ \u2202\n\u2202\u03a6\u0303 ln p(wd,1:N , \u03b8d|\u03a6\u0303, \u03b1)\n] (72)\nTo continue, we now derive the expression for the gradient inside the expectation term in (72). By (9) and the definition of Dirichlet distribution p(\u03b8d|\u03b1), we can write ln p(wd,1:N , \u03b8d|\u03a6\u0303, \u03b1) as\nln p(wd,1:N , \u03b8d|\u03a6\u0303, \u03b1) = ln p(wd,1:N , \u03b8d|\u03a6\u0303, \u03b1) = ln p(wd,1:N |\u03b8d, \u03a6\u0303) + ln p(\u03b8d|\u03b1)\n= K\u2211 j=1 (\u03b1j \u2212 1) ln \u03b8d,j + ln \u0393 ( K\u2211 j=1 \u03b1j ) \u2212 K\u2211 j=1 ln \u0393(\u03b1j)\n+ V\u2211 v=1 xd,v ln ( K\u2211 j=1 \u03b8d,j\u03a6\u0303vj ) = xTd ln(\u03a6\u0303\u03b8d) + (\u03b1\u2212 1)T ln \u03b8d + ln(1T\u03b1)\u2212 1T ln \u0393(\u03b1) (73)\nTaking the gradient of the above expression with respect to \u03a6\u0303, we obtain the gradient formula."}], "references": [], "referenceMentions": [], "year": 2017, "abstractText": "<lb>We develop a fully discriminative learning approach for supervised Latent Dirich-<lb>let Allocation (LDA) model, which maximizes the posterior probability of the pre-<lb>diction variable given the input document. Different from traditional variational<lb>learning or Gibbs sampling approaches, the proposed learning method applies<lb>(i) the mirror descent algorithm for exact maximum a posterior inference and (ii)<lb>back propagation with stochastic gradient descent for model parameter estimation,<lb>leading to scalable learning of the model in an end-to-end discriminative manner.<lb>As a byproduct, we also apply this technique to develop a new learning method for<lb>the traditional unsupervised LDA model. Experimental results on two real-world<lb>regression and classification tasks show that the proposed methods significantly<lb>outperform the previous supervised/unsupervised LDA learning methods.", "creator": "LaTeX with hyperref package"}}}