{"id": "1508.06191", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "25-Aug-2015", "title": "A Neuro-Fuzzy Method to Improving Backfiring Conversion Ratios", "abstract": "Software project estimation is crucial aspect in delivering software on time and on budget. Software size is an important metric in determining the effort, cost, and productivity. Today, source lines of code and function point are the most used sizing metrics, but there are limitations that apply. Here are a few examples of those limitations.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "histories": [["v1", "Tue, 25 Aug 2015 15:40:44 GMT  (180kb)", "http://arxiv.org/abs/1508.06191v1", "International Conference on Soft Computing, Intelligent System and Information Technology, Bali, Indonesia, pp. 12-17, 2007"]], "COMMENTS": "International Conference on Soft Computing, Intelligent System and Information Technology, Bali, Indonesia, pp. 12-17, 2007", "reviews": [], "SUBJECTS": "cs.SE cs.AI", "authors": ["justin wong", "danny ho", "luiz fernando capretz"], "accepted": false, "id": "1508.06191"}, "pdf": {"name": "1508.06191.pdf", "metadata": {"source": "CRF", "title": "A Neuro-Fuzzy Method to Improving Backfiring Conversion Ratios", "authors": ["Justin Wong", "Danny Ho", "Luiz Fernando Capretz"], "emails": ["jwong343@uwo.ca,", "danny@nfa-estimation.com,", "lcapretz@eng.uwo.ca"], "sections": [{"heading": null, "text": "Software project estimation is crucial aspect in delivering software on time and on budget. Software size is an important metric in determining the effort, cost, and productivity. Today, source lines of code and function point are the most used sizing metrics. Backfiring is a wellknown technique for converting between function points and source lines of code. However when backfiring is used, there is a high margin of error. This study introduces a method to improve the accuracy of backfiring. Intelligent systems have been used in software prediction models to improve performance over traditional techniques. For this reason, a hybrid Neuro-Fuzzy is used because it takes advantages of the neural network\u2019s learning and fuzzy logic\u2019s human-like reasoning. This paper describes an improved backfiring technique which uses Neuro-Fuzzy and compares the new method against the default conversion ratios currently used by software practitioners. Keywords: Backfiring, Software Estimation, Sizing, Function Point, Neuro-Fuzzy\n1. Introduction and Background Software estimation is a delicate activity because it can lead to projects\u2019 success or failure. Underestimation can result in poor quality software because of pressure to complete the project and premature release of the software. Furthermore, underestimation may result in late delivery or even failure because there may be lack of resources or budget to complete the project within the delivery date. Overestimation may result in failure to win bids for client projects. It can also result in allocating too many resources and underused staff [1]. Many software estimation techniques such as Constructive Cost Model (COCOMO) and Function Point Analysis have been developed to tackle these problems [2].\nThe two popular sizing metrics used today are source lines of code (SLOC or LOC) and function points. Jones [3] introduced the concept of backfiring, which converts function points to logical SLOC statements to effectively sized source code. While backfiring is useful and simple, there is a high margin of error in converting SLOC data into function points [3]. Conversion ratios have a range of values, i.e., low, mean, and high; hence, it is difficult to figure out the precise conversion ratio to use for a specific organization.\nNeural networks and fuzzy logic have been applied to software estimation methods to improve the accuracy of existing software sizing methods [4, 5]. The neuro-fuzzy technique, which integrates neural network and fuzzy logic together, has been shown to improve software estimation techniques by calibrating its parameters. Based on the flexibility of the technique, the neuro-fuzzy framework was incorporated to the backfiring technique.\nThe objective of this study is to improve the accuracy of backfiring by creating a neuro-fuzzy function point backfiring (NFFPB) calibration model. The model would be used to size software applications when the programming language and function point are known. It would also be used to provide up-to-date and calibrated conversion ratios to improve performance for specific datasets."}, {"heading": "1.1. SLOC", "text": "SLOC is one of the most popular size metrics used today in industry. SLOC measures the lines of code in software. SLOC is commonly used because it is relatively easy to measure and count. Typically SLOC is used to determine development effort required for software.\nWhile SLOC is popular and simple, there are some shortcomings to the use of SLOC as a size metric. SLOC is not a reliable metric during the software development process because the SLOC often changes from source code being added and removed. Moreover, the level of staff programming skill affects the SLOC produced. For example, an experienced programmer may write less SLOC than a junior programmer. Finally, SLOC is a risky metric if used alone because it is difficult to count an application during development. SLOC counts are more effective when development is completed [6]."}, {"heading": "1.2. Function Point", "text": "First introduced in the 1970s by Albrecht [7], the function point is a unit of measurement for determining the functional size of an information system. Function Point Analysis (FPA) can be used to calculate the size of an application, project development or enhancement project. Calculation of application means the size of an existing application which the functionality available to the end users are measured. For a development project, the measure of the size of the new application being developed is considered based on the requested requirements. Calculating an enhancement project measures a maintenance project of a present application based on all changes, added and removed functions, and the data conversion process [8].\nTo avoid the shortcomings of SLOC, function points are used. However, function points still have their disadvantages. For example, functionality in legacy systems are forgotten, therefore the overall size of the system is underestimated. Moreover, incomplete or informal requirements would result in inconsistent function point counts. Using function point in analogies can result in wrong estimates because a 1000 function point system does not mean it is two times larger than a 500 function point system [6]."}, {"heading": "1.3. Backfiring", "text": "The backfiring technique is a bidirectional mathematical conversion between function point and SLOC. The equation for converting function point to SLOC is defined in (1). In equation (1), FP is the function point input and conversion is the SLOC/FP. Equation (1) can be rearranged to find the number of function points if the SLOC is known.\nConversionFP=SLOC  (1)\nFor the backfiring technique, the conversion ratios or SLOC/FP could be found in a programming table. A programming table is tabulated data of the programming language, language level, and SLOC/FP. A sample programming table is shown in Table 1. The language level, defined by Software Productivity Research (SPR), indicates how powerful the source code language is [9]. For example, Basic Assembler has a language level of 1.0 because it has an average of 320 SLOC/FP. The SLOC/FP decreases as the language level increases, which is shown in Figure 1."}, {"heading": "1.4. Fuzzy Logic", "text": "Fuzzy logic, used to generate a mapping between input and output spaces, is derived from the fuzzy set theory, which uses linguistic terms or a fuzzy set that represents and processes uncertainty. It is made up of membership functions, used to describe linguistic terms such as low, medium and high, with values ranging from 0 to 1."}, {"heading": "1.5. Neural Network", "text": "A neural network is also known as a parallel distribution processing network. Neural network loosely models after the human brain in order to achieve human-like performance and learning. A neural network is made up of a network architecture, activation function, and learning mechanism.\nNeural networks have been applied to enhance traditional software estimation techniques. Aggarwal et al. [10] presented a model using neural networks to improve SLOC estimates when the function point is given as an input. Their estimation model used Bayesian Regularization to train the neural network. They investigated on various training algorithm to find the best results. Furthermore, the network took into account the maximum team size, function point standard and language (3rd generation language and 4th generation language). The shortcoming of the neural network was that it had a black-box design. In addition, the research only took the generation language into account instead of the programming languages. The averages SLOC/FP between the 3rd and 4th generation languages are very large in range. The 3rd generation default language has 80 SLOC/FP, while the 4th generation default language has 20 SLOC/FP."}, {"heading": "1.6. Neuro-Fuzzy Integration", "text": "Neuro-Fuzzy is a term used to refer to a hybrid intelligent system using both neural network and fuzzy logic. Neuro-Fuzzy is used because it takes advantages of the neural network\u2019s learning and fuzzy logic\u2019s human-like reasoning [4].\nHuang et al. [4] introduced a neuro-fuzzy framework and applied it to COCOMO. The neurofuzzy technique showed it could be used to improve software estimation techniques by calibrating its parameters. In this study, it was demonstrated that a neural network could be used to calibrate fuzzy sets to improve performances for many different applications. Based on the flexibility of the technique, the neuro-fuzzy framework was applied to the backfiring technique in this thesis.\nXia [5] proposed a neuro-fuzzy function point model for improving the accuracy of software effort estimates. The model used fuzzy logic for the function type complexities. In addition, a neural network was used to calibrate the complexity to achieve more accurate and current complexity ranges. The neuro-fuzzy function point model was evaluated and found to have an improvement of 22% over the traditional function point complexity values.\n2. Neuro-Fuzzy Backfiring Model The NFFPB model is an approach that calibrates the programming language level to improve backfiring estimations. It uses fuzzy logic to model the programming language level curve by grouping the programming language levels into fuzzy sets. These fuzzy sets become the input programming language level. A neural network is used to calibrate the fuzzy sets' SLOC/FP. The calibrated SLOC/FP replaces the original\nbackfiring conversion ratios. 2.1. Fuzzy Programming Language Level\nThe approach to model the inverse curve was to group the language levels into various fuzzy levels. This was done by grouping all the programming languages together based on similar SLOC/FP. The number of fuzzy level depends on the number of data points available. For example, if there are many points available then more fuzzy levels can be created. Table 2 shows the range of language levels being grouped into a fuzzy level to approximate the curve. The fuzzy levels were obtained based on the programming languages and data points available from ISBSG [11]. The average SLOC/FP was obtained from the average of all the backfiring conversion values within a fuzzy level. Moreover, this average value was used as the initial weight in the neural network and the initial peak of the fuzzy membership functions.\nThe fuzzy levels would change based on the data available. If more programming languages were to become available, more fuzzy levels could be added to model the curve more accurately."}, {"heading": "2.2. Input and Output Membership Functions", "text": "Figure 2 and Figure 3 illustrate the input and output fuzzy membership functions. A triangular function was used for both the input and output membership functions. The peak of the input triangle of each fuzzy level was the programming language level. The average SLOC/FP was the peak of the output membership functions. The peaks were obtained from Table 2."}, {"heading": "2.3. Fuzzy Rules and Inference", "text": "Each fuzzy level was directly referenced to a fuzzy output. For example, f1 referenced o1, f2 referenced o2 and so on. The \u201cAND\u201d and \u201cactivation function\u201d used the minimum function for the rules. For defuzzification, the maximum accumulation method and \u201cCenter of Gravity\u201d method were used."}, {"heading": "2.4. Neural Network", "text": "The neural network was used to calibrate the average source statements per function point for each fuzzy level. Moreover, the input to the neural network was the UFP and the fuzzy language level.\nThe actual SLOC was used only during training. These fuzzy language levels are fed into the network shown in Figure 4, which shows the network\u2019s design. The neural network was designed to be easily interpreted so that it avoids being an obscure \u201cblack-box\u201d model. Furthermore, the network design has been shown by Xia [5] to have improvements in function point estimations.\nThe L1 to Ln were binary fuzzy language level inputs. When a language level was fed into the network, the input was in the form of a matrix and only contains one 1 entry. For example, for language level 4, it would be represented as [0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] based on the proposed fuzzy levels.\nThe weights were initialized initially with the values in Table 2. The step-by-step pseudo-code of how the network is trained is shown below:\n1. Input: UFP, Fuzzy Programming\nLanguage Level (Lx) 2. Input goes through node Z\u2019s activation\nfunction: Prediction= UFP x (Lx x Wx) 3. Get error: Error = Actual - Prediction 4. Propagate error back and adjust weights:\nWx\u2019 = Wx + \u03b7Error 5. If Wx\u2019>max (SLOC/FP for Lx) then Wx\u2019=\nmax (SLOC/FP for Lx). If Wx\u2019<min (SLOC/FP for Lx) then Wx\u2019= min (SLOC/FP for Lx).\n6. Error goal or epochs reached? If Yes END, else go to step 1.\nThere is a constraint to how much a conversion weight can change for each fuzzy level. Each fuzzy level\u2019s input weight is constrained between the lowest and highest conversion value to avoid the SLOC/FP to be calibrated out of the language\u2019s boundaries.\n3. Method of Assesment The Neuro-Fuzzy Function Points Backfiring (NFFPB) model was implemented into a tool used to calibrate the backfiring conversion ratios. The NFFPB model was trained and evaluated with the International Software Benchmarking Standards Group (ISBSG) Release 9 data repository [11]. The NFFPB performance was measured against the Software Productivity Research (SPR) backfiring conversion ratios."}, {"heading": "3.1. Evaluation Criteria", "text": "Magnitude of Relative Error (MRE) is a popular criteria used commonly in industry. In the evaluation, MRE is used to measure the error performance for the calibrated model against the original conversion ratios. While it is popular, Foss et al. [12] showed that when evaluating and comparing prediction models, MRE is not recommended because MRE does not prove that one model is particularly better than another because the results were misleading [13]. MRE favored underestimation and performed worse in small sized projects. The equation is defined in (3).\n  Actual PredictedActual =MRE  (3)\nAnother method that was proposed for evaluating and comparing prediction models was Magnitude of error Relative to the Estimate (MER) [13]. The equation for calculating MER is defined in (4). However, MER favors overestimation because the estimation was a divisor; therefore, larger estimates tend to perform much better than small estimates.\n \nPredicted\nPredictedActual =MER  (4)\nAnother criterion that was used to evaluate the prediction model was Prediction at Level (PRED). MRE less than 25% and 50% was utilized for PRED because other models have used these criteria for evaluation."}, {"heading": "3.2. Experiments", "text": "There were 7 different experiments conducted. In each experiment, the MMRE, MMER, and PRED were compared with the original and calibrated ratios.\nIn experiments 1 and 2, half of the dataset was trained and the rest was used for simulation and evaluation. The data points were selected randomly for each programming language level.\nExperiments 3 and 4 were based on the size of the projects. In experiment 3, the large function point count projects were used for training and the small function point counts were used for simulation. Similarly, experiment 4 used small projects for training and large projects for evaluation.\nExperiments 5, 6, and 7 were based on a larger training set to see if the performance improves. Experiment 5 and 6 used 75% of the dataset for training. In the experiments, the data points were randomly selected for each programming level. In experiment 7, 100% of the dataset was used for training and evaluation."}, {"heading": "4. Results", "text": "The results, in Table 3, have shown from the experiments that the NFFPB model has a satisfactory improvement over the existing backfiring conversion ratios in MMRE and MMER. There was no conclusive evidence that neuro-fuzzy improves PRED because the results had positive, negative, and zero improvement.\nThe improvements were small in experiment 1 and 2 because of the size of the available dataset. Certain programming languages had a low number of training points which resulted in a small calibration. However, regardless of the setback, it was shown in experiments 5, 6, and 7 that there was a larger average MMRE and MMER improvement over the 50% random test results.\nIn experiments 4 and 7, the MMRE improvement was large. MMRE performs better when evaluated with large sized projects because MMRE favors underestimation. In experiment 7, there was a large improvement because the same data points were used for training and evaluation.\nThere were negative improvements in PRED in experiments 4 and 5. The negative PRED\nimprovements indicate that during training some of the accurate project estimates were sacrificed in order to minimize the overall MMER error.\nFigure 5 shows the inverse curve relationship between the calibrated weights from experiment 7 and the language level, which is similar to the curve in Figure 1. Similarly, the calibrated weights from other experiments have a similar curve."}, {"heading": "5. Conclusion", "text": "The conclusions that were drawn from the NFFPB model were that it solved the issues of backfiring conversion and that it reduced the error of the size estimates. The issues with backfiring were that the conversion ratios had a large range and were generic.\nSeven experiments were conducted to compare between NFFPB\u2019s calibrated ratios and SPR\u2019s conversion ratios. Overall, the NFFPB model outperformed SPR\u2019s conversion ratios in MMRE and MMER criteria. However, Neuro-fuzzy did not demonstrate any improvement in PRED.\nThe size of the project data available for evaluation weakened the conclusions being drawn because if more data became available, a larger improvement would show. The small training data hindered the neural network from minimizing errors and the improvements were small because of the biases in the MMRE and MMER criteria. In this study, the model tried to satisfy both criteria, which resulted in only obtaining local minimum error points."}, {"heading": "6. Acknowledgment", "text": "Justin Wong would like to thank his supervisors and referees for their helpful comments. Furthermore, he would also like to thank SPR and ISBSG for providing research data."}, {"heading": "7. References", "text": "[1] Boehm, B., and C. Abts, and S. Chulani.\n(2000). \u201cSoftware Development Cost Estimation Approaches \u2013 A Survey\u201d. Annals of Software Engineering. v 10. pp. 177-205.\n[2] Stutzke, R. D. (2005). Estimating SoftwareIntensive Systems \u2013 Projects, Products, and Processes. Addison-Wesley.\n[3] Jones C. (Nov. 1995). \u201cBackfiring: Converting\nLines of Code to Function Points\u201d. Computer. v 28 (11). pp. 87-88.\n[4] Huang X., and D. Ho, and J. Ren, and L.F.\nCapretz. (Jan. 2006). \u201cA Soft Computing Framework for Software Effort Estimation\u201d. Soft Computing. v 10 (2). pp. 170-177.\n[5] Xia, W. (2005). Calibrating Software Size of\nFunction Points Using Neuro-Fuzzy Technique, University of Western Ontario.\n[6] Galorath D., and M. Evans. (2006). Software\nSizing, Estimation, and Risk Management. Auerbach Publications.\n[7] Albrecht, A.J., and J.E. Jr. Gaffney. (Nov.\n1983). \u201cSoftware Function, Source Lines of Code, and Development Effort Prediction: A Software Science Validation\u201d. IEEE Transactions on Software Engineering. v 9 (6). pp. 639-648.\n[8] Function Point Counting Practices Manual\n4.2.1. (Jan. 2005). International Function Point Users Group. http://www.ifpug.org.\n[9] SPR Programming Languages Table. (2006).\nSoftware Productivity Research Incorporated. http://www.spr.com.\n[10] Aggarwal K. K, and Y. Singh, and P. Chandra,\nM. Puri. (2005). \u201cBayesian Regularization in a Neural Network Model to Estimate Lines of Code Using Function Points\u201d. Journal of Computer Sciences. v 1 (4). pp. 505-509.\n[11] Data CD R9 Demographics. (2004).\nInternational Software Benchmarking Standards Group.\n[12] Foss T., and E. Stensrud, and B. Kitchenham,\nI. Myrtveit. (Nov. 2003). \u201cA Simulation Study of the Model Evaluation Criterion MMRE\u201d, Software Engineering, IEEE Transactions on Software Engineering. v 29 (11). pp. 985-995.\n[13] Kitchenham B.A., and S.G. MacDonell, and\nL.M. Pickad, and M.J. Shepperd. (Jun. 2001). \u201cWhat Accuracy Statistics Really Measure\u201d. IEE Proceedings: Software. v 148 (3). pp. 81- 85."}], "references": [{"title": "Software Development Cost Estimation Approaches \u2013 A Survey", "author": ["B. Boehm", "C. Abts", "S. Chulani"], "venue": "Annals of Software Engineering", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2000}, {"title": "Estimating Software- Intensive Systems \u2013 Projects, Products, and Processes", "author": ["R.D. Stutzke"], "venue": null, "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2005}, {"title": "Backfiring: Converting Lines of Code to Function Points", "author": ["Jones C. (Nov"], "venue": "Computer. v", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 1995}, {"title": "A Soft Computing Framework for Software Effort Estimation", "author": ["Huang X", "D. Ho", "J. Ren", "L.F. Capretz. (Jan"], "venue": "Soft Computing. v", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2006}, {"title": "Calibrating Software Size of Function Points Using Neuro-Fuzzy Technique, University of Western Ontario", "author": ["W. Xia"], "venue": null, "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2005}, {"title": "Software Sizing, Estimation, and Risk Management", "author": ["Galorath D", "M. Evans"], "venue": null, "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2006}, {"title": "Software Function, Source Lines of Code, and Development Effort Prediction: A Software Science Validation", "author": ["A.J. Albrecht", "J.E. Jr. Gaffney. (Nov"], "venue": "IEEE Transactions on Software Engineering. v", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 1983}, {"title": "Bayesian Regularization in a Neural Network Model to Estimate Lines of Code Using Function Points", "author": ["Aggarwal K. K", "Y. Singh", "P. Chandra", "M. Puri"], "venue": "Journal of Computer Sciences", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2005}, {"title": "A Simulation Study of the Model Evaluation Criterion MMRE", "author": ["Foss T", "E. Stensrud", "B. Kitchenham", "I. Myrtveit. (Nov"], "venue": "Software Engineering, IEEE Transactions on Software Engineering. v", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2003}, {"title": "What Accuracy Statistics Really Measure", "author": ["Kitchenham B.A", "S.G. MacDonell", "L.M. Pickad", "M.J. Shepperd"], "venue": "(Jun", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2001}], "referenceMentions": [{"referenceID": 0, "context": "It can also result in allocating too many resources and underused staff [1].", "startOffset": 72, "endOffset": 75}, {"referenceID": 1, "context": "Many software estimation techniques such as Constructive Cost Model (COCOMO) and Function Point Analysis have been developed to tackle these problems [2].", "startOffset": 150, "endOffset": 153}, {"referenceID": 2, "context": "Jones [3] introduced the concept of backfiring, which converts function points to logical SLOC statements to effectively sized source code.", "startOffset": 6, "endOffset": 9}, {"referenceID": 2, "context": "While backfiring is useful and simple, there is a high margin of error in converting SLOC data into function points [3].", "startOffset": 116, "endOffset": 119}, {"referenceID": 3, "context": "Neural networks and fuzzy logic have been applied to software estimation methods to improve the accuracy of existing software sizing methods [4, 5].", "startOffset": 141, "endOffset": 147}, {"referenceID": 4, "context": "Neural networks and fuzzy logic have been applied to software estimation methods to improve the accuracy of existing software sizing methods [4, 5].", "startOffset": 141, "endOffset": 147}, {"referenceID": 5, "context": "SLOC counts are more effective when development is completed [6].", "startOffset": 61, "endOffset": 64}, {"referenceID": 6, "context": "Function Point First introduced in the 1970s by Albrecht [7], the function point is a unit of measurement for determining the functional size of an information system.", "startOffset": 57, "endOffset": 60}, {"referenceID": 5, "context": "Using function point in analogies can result in wrong estimates because a 1000 function point system does not mean it is two times larger than a 500 function point system [6].", "startOffset": 171, "endOffset": 174}, {"referenceID": 7, "context": "[10] presented a model using neural networks to improve SLOC estimates when the function point is given as an input.", "startOffset": 0, "endOffset": 4}, {"referenceID": 3, "context": "Neuro-Fuzzy is used because it takes advantages of the neural network\u2019s learning and fuzzy logic\u2019s human-like reasoning [4].", "startOffset": 120, "endOffset": 123}, {"referenceID": 3, "context": "[4] introduced a neuro-fuzzy framework and applied it to COCOMO.", "startOffset": 0, "endOffset": 3}, {"referenceID": 4, "context": "Xia [5] proposed a neuro-fuzzy function point model for improving the accuracy of software effort estimates.", "startOffset": 4, "endOffset": 7}, {"referenceID": 4, "context": "Furthermore, the network design has been shown by Xia [5] to have improvements in function point estimations.", "startOffset": 54, "endOffset": 57}, {"referenceID": 0, "context": "For example, for language level 4, it would be represented as [0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] based on the proposed fuzzy levels.", "startOffset": 62, "endOffset": 101}, {"referenceID": 8, "context": "[12] showed that when evaluating and comparing prediction models, MRE is not recommended because MRE does not prove that one model is particularly better than another because the results were misleading [13].", "startOffset": 0, "endOffset": 4}, {"referenceID": 9, "context": "[12] showed that when evaluating and comparing prediction models, MRE is not recommended because MRE does not prove that one model is particularly better than another because the results were misleading [13].", "startOffset": 203, "endOffset": 207}, {"referenceID": 9, "context": "Another method that was proposed for evaluating and comparing prediction models was Magnitude of error Relative to the Estimate (MER) [13].", "startOffset": 134, "endOffset": 138}], "year": 2015, "abstractText": "Software project estimation is crucial aspect in delivering software on time and on budget. Software size is an important metric in determining the effort, cost, and productivity. Today, source lines of code and function point are the most used sizing metrics. Backfiring is a wellknown technique for converting between function points and source lines of code. However when backfiring is used, there is a high margin of error. This study introduces a method to improve the accuracy of backfiring. Intelligent systems have been used in software prediction models to improve performance over traditional techniques. For this reason, a hybrid Neuro-Fuzzy is used because it takes advantages of the neural network\u2019s learning and fuzzy logic\u2019s human-like reasoning. This paper describes an improved backfiring technique which uses Neuro-Fuzzy and compares the new method against the default conversion ratios currently used by software practitioners.", "creator": "PScript5.dll Version 5.2.2"}}}