{"id": "1508.06781", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "27-Aug-2015", "title": "Computing Stable Coalitions: Approximation Algorithms for Reward Sharing", "abstract": "Consider a setting where selfish agents are to be assigned to coalitions or projects from a fixed set P. Each project k is characterized by a valuation function; v_k(S) is the value generated by a set S of agents working on project k. We study the following classic problem in this setting: \"how should the agents divide the value that they collectively create?\"\n\n\nThe reason the agent is to be a good at keeping the value of the selected agent (e.g., the one with the highest values) at the lowest. The agents can decide that their prices will be lower, that they should be cheaper or more competitive (e.g., the one with the highest values). In some cases, the agent has to decide that the price that they provide for the agent is higher than the prices that they provide (e.g., the one with the highest values). The agents can choose between either (i) being cheaper or more competitive (e.g., the one with the highest values) or (ii) being more competitive (e.g., the one with the lowest values).\nThe agent has to decide that the prices that they provide will be lower than the prices that they provide (e.g., the one with the lowest values) or (iii) being more competitive (e.g., the one with the highest values) or (iv) being more competitive (e.g., the one with the lowest values) or (v) being more competitive (e.g., the one with the lowest values) or (vi) being more competitive (e.g., the one with the lowest values) or (v) being more competitive (e.g., the one with the lowest values) or (v) being more competitive (e.g., the one with the lowest values) or (v) being more competitive (e.g., the one with the highest values) or (v) being more competitive (e.g., the one with the lowest values) or (v) being more competitive (e.g., the one with the lowest values) or (v) being more competitive (e.g., the one with the lowest values) or (v) being more competitive (e.g., the one with the lowest values) or (v) being more competitive (e.g., the one with the lowest values) or (v) being more competitive (e.g., the one with the highest values) or (v) being more competitive", "histories": [["v1", "Thu, 27 Aug 2015 09:53:40 GMT  (67kb,D)", "http://arxiv.org/abs/1508.06781v1", "Under Review"]], "COMMENTS": "Under Review", "reviews": [], "SUBJECTS": "cs.GT cs.AI", "authors": ["elliot anshelevich", "shreyas sekar"], "accepted": false, "id": "1508.06781"}, "pdf": {"name": "1508.06781.pdf", "metadata": {"source": "CRF", "title": "Computing Stable Coalitions: Approximation Algorithms for Reward Sharing", "authors": ["Elliot Anshelevich", "Shreyas Sekar"], "emails": [], "sections": [{"heading": "1 Introduction", "text": "\u201cHow should a central agency incentivize agents to create high value, and then distribute this value among them in a fair manner?\u201d \u2013 this question forms the central theme of this paper. Formally, we model a set of selfish agents in a combinatorial setting consisting of a set P of projects. Each project k is characterized by a valuation function; vk(S) specifies the welfare generated by a set S of agents working on project k. The problem that we study is the following: compute an assignment of agents to projects to maximize social welfare, and provide rewards or payments to each agent so that no group of agents deviate from the centrally prescribed solution.\nFor example, consider a firm dividing its employees into teams to tackle different projects. If these employees are not provided sufficient remuneration, then some group could break off, and form their own startup to tackle a niche task. Alternatively, one could imagine a funding agency incentivizing researchers to tackle specific problems. More generally, a designer\u2019s goal in such a setting is to delicately balance the twin objectives of optimality and stability : forming a high-quality solution while making sure this solution is stable. A common requirement that binds the two objectives together is budget-balancedness: the payments provided to the agents must add up to the total value of the given solution.\nCooperative Coalition Formation The question of how a group of agents should divide the value they generate has inspired an extensive body of research spanning many fields [7, 28, 32, 38, 40]. The notion of a \u2018fair division\u2019 is perhaps best captured by the Core: a set of payments so that no group of agents would be better off forming a coalition by themselves. Although the\nar X\niv :1\n50 8.\n06 78\n1v 1\n[ cs\n.G T\n] 2\n7 A\nug 2\n01 5\nCore is well understood, implicit in the papers that study this notion is the underlying belief that there are infinite copies of one single project [5,12], which is often not realistic. For example, a tacit assumption is that if the payments provided are \u2018not enough\u2019, then every agent i can break off, and simultaneously generate a value of v(i) by working alone; such a solution does not make sense when the number of projects or possible coalitions is limited. Indeed, models featuring selfish agents choosing from a finite set of distinct strategies are the norm in many real-life phenomena: social or technological coordination [1, 2], opinion formation [13, 21], and party affiliation [6, 8] to name a few.\nThe fundamental premise of this paper is that many coalition formation settings feature multiple non-identical projects, each with its own (subadditive) valuation vk(S). Although our model allows for duplicate projects, the inherently combinatorial nature of our problem makes it significantly different from the classic problem with infinite copies of a single project. For example, in the classic setting with a single valuation v(S), the welfare maximization problem is often trivial (complete partition when v is subadditive), and the stabilizing core payments are exactly the dual variables to the allocation LP [10]. This is not the case in our setting where even the welfare maximization problem is NP-Hard, and known approximation algorithms for this problem use LP-rounding mechanisms, which are hard to reconcile with stability. Given this, our main contribution is a poly-time approximation algorithm that achieves stability without sacrificing too much welfare."}, {"heading": "1.1 The Core", "text": "Given an instance (N ,P, (vk)k\u2208P) with N agents (N ) and m projects, a solution is an allocation S = (S1, . . . , Sm) of agents to projects along with a vector of payments (p\u0304)i\u2208N . With unlimited copies of a project, core stability refers to the inability of any set of agents to form a group on their own and obtain more value than the payments they receive. The stability requirement that we consider is a natural extension of core stability to settings with a finite number of fixed projects. That is, when a set T of agents deviate to project k, they cannot displace the agents already working on that project (Sk). Therefore, the payments of the newly deviated agents (along with the payments of everyone else on that project) must come from the total value generated, vk(Sk \u222a T ). One could also take the Myersonian view [38] that \u2018communication is required for negotiation\u2019 and imagine that all the agents choosing project k (Sk \u222a T ) together collaborate to improve their payments. Formally, we define a solution (S, p\u0304) to be core stable if the following two conditions are satisfied,\n(Stability) No set of agents can deviate to a project and obtain more total value for everyone in that project than their payments, i.e., for every set of agents T and project k, \u2211 i\u2208T\u222aSk p\u0304i \u2265\nvk(T \u222a Sk). (Budget-Balance) The total payments sum up to the social welfare (i.e., total value) of the\nsolution: \u2211 i\u2208N p\u0304i = \u2211 k\u2208P vk(Sk).\nObserve that Stability for T = \u2205 together with budget-balancedness imply that the value created from a project will go to the agents on that project only. Finally, we consider a full-information setting as it is reasonable to expect the central authority to be capable of predicting the value generated when agents work on a project.\n(Example 1) We begin our work with an impossibility result: even for simple instances with two projects and four agents, a core stable solution need not exist. Consider P = {1, 2}, and\ndefine v1(N ) = 4 and v1(S) = 2 otherwise; v2(S) = 1+ for all S \u2286 N . If all agents are assigned to project 1, then in a budget-balanced solution at least one agent has to have a payment of at most 1; such an agent would deviate to project 2. Instead, if some agents are assigned to project 2, then it is not hard to see that they can deviate to project 1 and the total utility goes from 3 + to 4.\nApproximating the Core Our goal is to compute solutions that guarantee a high degree of stability. Motivated by this, we view core stability under the lens of approximation. Specifically, as is standard in cost-sharing literature [29,39], we consider relaxing one of the two requirements for core stability while retaining the other one. First, suppose that we generalize the Stability criterion as follows:\n(\u03b1-Stability) For every set of agents T and every project k, vk(Sk \u222aT ) \u2264 \u03b1 \u2211\ni\u2208Sk\u222aT p\u0304i.\n\u03b1-stability captures the notion of a \u2018switching cost\u2019 and is analogous to an Approximate Equilibrium; in our example, one can imagine that employees do not wish to quit the firm unless the rewards are at least a factor \u03b1 larger. In the identical projects literature, the solution having the smallest value of \u03b1 is known as the Multiplicative Least-Core [10]. Next, suppose that we only relax the budget-balance constraint,\n(\u03b2-Budget Balance) The payments are at most a factor \u03b2 larger than the welfare of the solution.\nThis generalization offers a natural interpretation: the central authority can subsidize the agents to ensure high welfare, as is often needed in other settings such as public projects or academic funding [7]. In the literature, this parameter \u03b2 has been referred to as the Cost of Stability [4,35].\nWe do not argue which of these two relaxations is the more natural one: clearly that depends on the setting. Fortunately, it is not difficult to see that these two notions of approximation are equivalent. In other words, every approximately core stable solution with \u03b1-stability can be transformed into a solution with \u03b1-budget balancedness by scaling the payments of every player by a factor \u03b1. Therefore, in the rest of this paper, we will use the term \u03b1-core stable without loss of generality to refer to either of the two relaxations. All our results can be interpreted either as forming fully budget-balanced payments which are \u03b1-stable, or equivalently as fully stable payments which are \u03b1-budget balanced. Finally, the problem that we tackle in this paper can be summarized as follows:\n(Problem Statement) Given an instance with subadditive valuation functions, compute an \u03b1-core stable solution (S, (p\u0304)i\u2208N ) having as small a value of \u03b1 as possible, that approximately maximizes social welfare."}, {"heading": "1.2 Our Contributions", "text": "The problem that we face is one of bi-criteria approximation: to simultaneously optimize both social welfare and the stability factor \u03b1 (\u03b1 = 1 refers to a core stable solution). For the rest of this paper, we will use the notation (\u03b1, c)-Core stable solution to denote an \u03b1-Core solution that is also a c-Approximation to the optimum welfare. The bounds that we derive are quite strong: we are able to approximate both \u03b1 and c simultaneously to be close to the individually\nbest-possible lower bounds. In a purely algorithmic sense, our problem can be viewed as one of designing approximation algorithms that require the additional property of stabilizability.\nMain Result Our main result is the following black-box reduction that reduces the problem of finding an approximately core stable solution to the purely algorithmic problem of welfare maximization,\n(Informal Theorem). For any instance where the projects have subadditive valuations, any LP-based \u03b1-approximation to the optimum social welfare can be transformed in poly-time to a (2\u03b1, 2\u03b1)-core stable solution.\nThe strength of this result lies in its versatility: our algorithm can stabilize any input allocation at the cost of half the welfare. The class of subadditive valuations is extremely general, and includes many well-studied special classes all of which use LP-based algorithms for welfare maximization; one can simply plug-in the value of \u03b1 for the corresponding class to derive an approximately core stable solution. In particular, for general subadditive valuations, one can use the 2-approximation algorithm of Feige [20] and obtain a (4, 4)-Core. As is standard in the literature [18], we assume that our subadditive functions are specified in terms of a demand oracle (see Section 2 for more details). However, even in the absence of a demand oracle, one can obtain a poly-time reduction as long as we are provided an allocation and the optimum dual prices as input.\nFor various sub-classes of subadditive valuations, we obtain stronger results by exploiting special structural properties of those functions. These results are summarized in Table 1. The classes that we study are extremely common and have been the subject of widespread interest in many different domains.\nLower Bounds. All of our results are \u2018almost tight\u2019 with respect to the theoretical lower bounds for both welfare maximization and stability. Even with anonymous functions, a (2\u2212 ) core may not exist; thus our (2, 2)-approximation for this class is tight. For general subadditive functions, one cannot compute better than a 2-approximation to the optimum welfare efficiently, and so our (4, 4) result has only a gap of 2 in both criteria. Finally, for XoS and Submodular functions, we get almost stable solutions ((1+ )-Core) that match the lower bounds for welfare maximization.\nA Fast Algorithm for Anonymous Subadditive Functions We devise a greedy 2-approximation algorithm for anonymous functions that may be of independent algorithmic interest. The only known 2-approximation algorithm even for this special class is the rather complex LP rounding mechanism for general subadditive functions. In contrast, we provide an intuitive greedy algorithm that obtains the same factor, and use the structural properties of our algorithm to prove\nimproved bi-criteria bounds ((2, 2) as opposed to (4, 4)).\nTies to Combinatorial Auctions with Item Bidding We conclude by pointing out a close relationship between our setting and simultaneous auctions where buyers bid on each item separately [9,14,17]. Consider \u2018flipping\u2019 an instance of our problem to obtain the following combinatorial auction: every project k \u2208 P is a buyer with valuation vk, and every i \u2208 N is an item in the market. We prove an equivalence between Core stable solutions in our setting and Pure Nash equilibrium for the corresponding flipped simultaneous second price auction. Adapting our lower bounds to the auction setting, we make a case for Approximate Nash Equilibrium by constructing instances where every exact Nash equilibrium requires buyers to overbid by a factor of O( \u221a N), when they have anonymous subadditive valuations. Finally, we apply our earlier algorithms to efficiently compute approximate equilibria with small over-bidding for two settings, namely, (i) a 12 -optimal, 2-approximate equilibrium when buyers have anonymous subadditive valuations, and (ii) a (1\u2212 1e )-optimal, 1 + -approximate equilibrium for submodular buyers."}, {"heading": "1.3 Related Work", "text": "The core has formed the basis for a staggering body of research in a myriad of domains, and one cannot hope to do justice to this vast literature. Therefore, we only review the work most pertinent to our model. The non-existence of the core in many important settings has prompted researchers to devise several natural relaxations [3,4,41,43]: of these, the Cost of Stability [4,7,35], and the Multiplicative Least-Core [10,42,43] are the solution concepts that are directly analogous to our notion of an \u03b1-core. That said, there are a few overarching differences between our model, and almost all of the papers studying the core and its relatives; (i) Duplicate Projects: In the classic setting, it is assumed that there are infinite copies of one identical project so that different subsets of agents (say S1, S2) working independently on the same project can each generate their full value (v(S1) + v(S2)), and (ii) Superaddivity: In order to stabilize the grand coalition, most papers assume that the valuation is superadditive, which inherently favors cooperation. On the contrary, our setting models multiple dissimilar projects where each project is a fixed resource with a subadditive valuation.\nAlthough cooperative games traditionally do not involve any optimization, a number of papers have studied well-motivated games where the valuation or cost function (c(S)) is derived from an underlying combinatorial optimization problem [15,26,28,34]. For example, in the vertex cover game [15, 19] where each edge is an agent, c(S) is the size of the minimum cover for the edges in S. Such settings are fundamentally different from ours because the hardness arises from the fact that the value of the cost function cannot be obtained precisely. For many such problems, core payments can be computed almost directly using LP Duality [26,28,34].\nIn the cooperative game theory literature, our setting is perhaps closest to the work studying coalitional structures where instead of forming the grand coalition, agents are allowed to arbitrarily partition themselves [4,27] or form overlapping coalitions [12]. This work has yielded some well-motivated extensions of the Core, albeit for settings with duplicate projects. Our work is similar in spirit to games where agents form coalitions to tackle specific tasks, e.g., threshold task games [12] or coalitional skill games [5]. In these games, there is still a single valuation function v(S) which depends on the (set of) task(s) that the agents in S can complete. Once again, the tacit assumption is that there are an infinite number of copies of each task.\nRecently, there has been a lot of interest in designing cost-sharing mechanisms that satisfy strategy-proofness in settings where a service is to be provided to a group of agents who hold private values for the same [16, 37]. In contrast, we look at a full information game where the central agency can exactly estimate the output due to a set of agents working on a project. A powerful relationship between our work and the body of strategy-proof mechanisms was discovered by Moulin [36] who showed that a natural class of \u2018cross-monotonic cost sharing schemes\u2019 can be used to design mechanisms that are both core-stable (CS) and strategy-proof (SP). This has led to the design of beautiful SP+CS mechanisms for several combinatorially motivated problems with a single identical project or service [25, 39]. Finally, we briefly touch upon the large body of literature in non-transferable utility games that (like us) study coalition formation with a finite number of asymmetric projects [2, 11, 13,23]. However, these papers use fixed reward-sharing schemes, and thus do not model the bargaining power of agents that is a key aspect of coalition formation."}, {"heading": "2 Model and Preliminaries", "text": "We consider a transferable-utility coalition formation game with a set P of m projects and a set N of N agents. Each project k \u2208 P is specified by a monotone non-decreasing valuation function vk : 2\nN \u2192 R+ \u222a {0}. A solution consists of an allocation of agents to projects S = (S1, . . . , Sm), and a payment scheme (p\u0304)i\u2208N and is said to be (\u03b1, c)-core stable for \u03b1 \u2265 1, c \u2265 1 if \u2022 The payments are fully budget-balanced, and for every project k, and set T of agents, vk(Sk \u222a T ) \u2264 \u03b1 \u2211 i\u2208Sk\u222aT p\u0304i. An equivalent condition is that the payments are at most a\nfactor \u03b1 times the social welfare of the solution, and we have full stability, i.e., vk(Sk \u222a T ) \u2264\u2211 i\u2208Sk\u222aT p\u0304i. \u2022 The allocation S is a c-approximation to the optimum allocation, i.e., the welfare of the solution S is at least 1c times the optimum welfare.\nThroughout this paper, we will use OPT to denote the welfare maximizing allocation as long as the instance is clear. Given an allocation S = (S1, . . . , Sm), we use SW (S) = \u2211m k=1 vk(Sk) to denote the social welfare of this allocation, and \u03b6(S) to be the set of projects that are empty under S, i.e., k \u2208 \u03b6(S) if Sk = \u2205."}, {"heading": "Comparison to Traditional Models", "text": "We digress briefly to highlight the key differences between our model as defined above and traditional utility-sharing settings found in the literature. Traditionally, a transferable-utility coalition formation game consists of a single valuation function v(S). The objective there is to provide a vector of payments (pi to user i) in order to stabilize some desired solution S = (S1, . . . , Sr)\n1, where the number of coalitions r can be any positive integer. Here, core stability means that for any group of agents T \u2286 N , \u2211i\u2208T pi \u2265 v(T ). Notice from the above definition that (unlike our setting), the same core payments are applicable for every single solution S, i.e., the payments are completely independent of the solution formed.\nA stark contrast to our notion of a stable solution is the implicit assumption that there are an infinite number of copies of a single project (specified by v(S)) available for the agents\n1 Usually, this is the grand coalition but it can also refer to other solutions, for example, the social welfare maximizing solution\nto deviate to. For instance, a necessary condition for core stability is that pi \u2265 v(i) for every agent i; this implies that in theory, each of the N agents could work independently on the same project and generate a total value of \u2211 i v(i) and not v(N). As mentioned in the introduction, such assumptions do not always make sense, and it is reasonable to assume that the value generated depends on which project the agents deviate to, and how many other agents are currently working on that project or resource. Finally, in the traditional model, the minimum core payments (irrespective of the solution) can be obtained directly using the dual of the allocation LP. In contrast, this is not so in our setting due to the presence of slack variables (See Section 3).\nValuation Functions Our main focus in this paper will be on the class of monotone subadditive valuation functions. A valuation function v is said to be subadditive if for any two sets S, T \u2286 N , v(S \u222a T ) \u2264 v(S) + v(T ), and monotone if v(S) \u2264 v(S \u222a T ). The class of subadditive valuations encompasses a number of popular and well-studied classes of valuations, but at the same time is significantly more general than all of these classes. It is worth noting that when there are an unlimited number of allowed groups, subadditive functions are almost trivial to deal with: both the maximum welfare solution and the stabilizing payments are easily computable. For our setting, however, computing OPT becomes NP-Hard, and a fully core-stable solution need not exist. Due to the importance and the natural interpretation of subadditive functions, we believe it is very desirable to understand utility sharing under such valuations; our paper presents the first known results on utility sharing for general subadditive functions. In addition, we are able to show stronger results for the following two sub-classes that are extremely common in the literature.\nSubmodular Valuations For any two sets S, T with T \u2286 S, and any agent i, v(S \u222a {i}) \u2212 v(S) \u2264 v(T \u222a {i})\u2212 v(T ). Fractionally Subadditive (also called \u2018XoS\u2019) Valuations \u2203 a set of additive functions (a1, . . . , ar) such that for any T \u2286 N , v(T ) = maxrj=1 aj(T ). These additive functions are referred to as clauses.\nRecall that an additive function aj has a single value aj(i) for each i \u2208 N so that for a set T of agents, aj(T ) = \u2211 i\u2208T aj(i). The reader is asked to refer to [18, 20, 31, 44] for alternative definitions of the XoS class and an exposition on how both these classes arise naturally in many interesting applications. Anonymous Subadditive Functions In project assignment settings in the literature modeling a number of interesting applications [30, 35], it is reasonable to assume that the value from a project depends only on the number of users working on that project. Mathematically, this idea is captured by anonymous functions: a valuation function is said to be anonymous if for any two subsets S, T with |S| = |T |, we have v(S) = v(T ). One of our main contributions in this paper is a fast algorithm for the computation of Core stable solutions when the projects have anonymous subadditive functions. We remark here that anonymous subadditive functions form an interesting sub-class of subadditive functions that are quite different from submodular and XoS functions.\nDemand Oracles. The standard approach in the literature while dealing with set functions (where the input representation is often exponential in size) is to assume the presence of an\noracle that allows indirect access to the valuation by answering specific types of queries. In particular, when dealing with a subadditive function v, it is typical to assume that we are provided with a demand oracle that when queried with a vector of payments p, returns a set T \u2286 N that maximizes the quantity v(T )\u2212\u2211i\u2208T pi [18]. Demand oracles have natural economic interpretations, e.g., if p represents the vector of potential payments by a firm to its employees, then v(T )\u2212\u2211i\u2208T pi denotes the assignment that maximizes the firm\u2019s revenue or surplus.\nIn this paper, we do not explicitly assume the presence of a demand oracle; our algorithmic constructions are quite robust in that they do not make any demand queries. However, any application of our black-box mechanism requires as input an allocation which approximates OPT, and the optimum dual prices, both of which cannot be computed without demand oracles. For example, it is well-known [18] that one cannot obtain any reasonable approximation algorithm for subadditive functions (better than O( \u221a N)) in the absence of demand queries. That said, for several interesting valuations, these oracles can be constructed efficiently. For example in the case of XoS functions, a demand oracle can be simulated in time polynomial in the number of input clauses. We conclude this discussion by reiterating that demand oracles are an extremely standard tool used in the literature to study combinatorial valuations; almost all of the papers [18,20,25] studying Subadditive or XoS functions take the presence of a demand oracle for granted.\n2.1 Warm-up Result: (1, 2)-Core for Submodular Valuations\nWe begin with an easy result: an algorithm that computes a core stable solution when all projects have submodular valuations, and also retains half the optimum welfare. Although this result is not particularly challenging, it serves as a useful baseline to highlight the challenges involved in computing stable solutions for more general valuations. Later, we show that by sacrificing an amount of stability, one can compute for submodular functions, a solution with a much better social welfare ( ee\u22121 -approximation to OPT).\nClaim 1 We can compute in poly-time a (1, 2)-Core stable solution for any instance with submodular project valuations.\nThe above claim also implies that for every instance with submodular project valuations, there exists a Core stable solution. In contrast, for subadditive valuations, even simple instances (Example 1) do not admit a Core stable solution.\nProof: The proof uses the popular greedy half-approximation algorithm for submodular welfare maximization due to [31]. Initialize the allocation X to be empty. At every stage, add an agent i to project k so that the value vk(Xk \u222a {i}) \u2212 vk(Xk) is maximized. Set i\u2019s final payment p\u0304i to be exactly the above marginal value. Let the final allocation once the algorithm terminates be S, so \u2211 i\u2208Sk p\u0304i = vk(Sk). Consider any group of agents T , and some project k: by the definition of the greedy algorithm, and by submodularity, it is not hard to see that \u2200i \u2208 T , p\u0304i \u2265 vk(Sk \u222a {i}) \u2212 vk(Sk). Therefore, we have that \u2211 i\u2208T p\u0304i \u2265 vk(Sk \u222a T ) \u2212 vk(Sk), and since the payments are clearly budget-balanced, the solution is core-stable.\nChallenges and Techniques for Subadditive Valuations At the heart of finding a Core allocation lies the problem of estimating \u2018how much is an agent worth to a coalition\u2019. Unfortunately, the idea used in Claim 1 does not extend to more general valuations as the marginal value is no longer representative of an agent\u2019s worth. One alternative approach is to use the\ndual variables to tackle this problem: for example, in the classic setting with duplicate projects, every solution S along with the dual prices as payments yields an \u03b1-budget balanced core. Therefore, the challenge there is to bound the factor \u03b1 using the integrality gap. However, this is no longer true in our combinatorial setting as the payments are closely linked to the actual solution formed, and moreover, there is no clear way of dividing the dual variables due to the presence of slack (see LP 1). Our Approach. We attempt to approximately resolve the question of finding each agent\u2019s worth by identifying (for each project) a set of \u201cheavy users\u201d who contribute to half the project\u2019s value. We provide large payments to each heavy user based on her best outside option which are determined using Greedy Matchings. Finally, the dual variables are used only as a \u2018guide\u2019 to ensure that \u2200k \u2208 P, the payment given to the users on that project is at least a good fraction of the value they generate."}, {"heading": "3 Computing Approximately Core Stable Solutions", "text": "In this section, we show our main algorithmic result, namely a black-box mechanism that reduces the problem of finding a core stable solution to the algorithmic problem of subadditive welfare maximization. We use this black-box in conjunction with the algorithm of Feige [20] to obtain a (4, 4)-Core stable solution, i.e., a 4-approximate core that extracts one-fourth of the optimum welfare. Using somewhat different techniques, we form stronger bounds ((2, 2)-Core) for the class of anonymous subadditive functions. Our results for the class of anonymous functions are tight: there are instances where no (2 \u2212 , 2 \u2212 )-core stable solution exists. This indicates that our result for general subadditive valuations is close to tight (up to a factor of two).\nWe begin by stating the following standard linear program relaxation for the problem of computing the welfare maximizing allocation. Although the primal LP contains an exponential number of variables, the dual LP can be solved using the Ellipsoid method where the demand oracle serves as a separation oracle [18]. The best-known approximation algorithms for many popular classes of valuations use LP-based rounding techniques; of particular interest to us is the 2-approximation for Subadditive valuations [20], and ee\u22121 -approximation for XoS valuations [18].\nmax M\u2211 k=1 \u2211 S\u2286N xk(S)vk(S) (D) min N\u2211 i=1 pi + M\u2211 k=1 zk\ns.t. M\u2211 k=1 \u2211 S3i xk(S) \u2264 1 \u2200i \u2208 N s.t. \u2211 i\u2208S\npi + zk \u2265 vk(S) \u2200S, k\u2211 S\u2286N xk(S) \u2264 1, \u2200k \u2208 P pi \u2265 0, \u2200i \u2208 N xk(S) \u2265 0, \u2200S,\u2200k zk \u2265 0, \u2200k \u2208 P\n(1)\nAs long as the instance is clear from the context, we will use (p\u2217, z\u2217) to denote the optimum solution to the Dual LP, referring to p\u2217 as the dual prices, and z\u2217 as the slack. Main Result We are now in a position to show the central result of this paper. The following black-box mechanism assumes as input an LP-based \u03b1-approximate allocation, i.e., an allocation whose social welfare is at most a factor \u03b1 smaller than the value of the LP optimum for that instance. LP-based approximation factors are a staple requirement for black-box mechanisms that\nexplicitly make use of the optimum LP solution [25]. Along these lines, we make the assumption that the optimum dual variables (for the given instance) are available to the algorithm along with an input allocation.\nTheorem 2. Given any \u03b1-approximate solution to the LP optimum, we can construct a (2\u03b1, 2\u03b1)Core Stable Solution in polynomial time as long as the projects have subadditive valuations.\nFor general subadditive functions, the only known poly-time constant-factor approximation is the rather intricate randomized LP rounding scheme proposed in [20]. Using this 2- approximation, we get the following corollary.\nCorollary 3. We can compute in poly-time a (4, 4)-Core stable solution for any instance with subadditive projects.\nWe now prove Theorem 2.\nProof: We provide an algorithm that takes as input an allocation A = (A1, . . . Am) that is an \u03b1-approximation to the LP Optimum and returns a core stable solution S = (S1, . . . , Sm) along with payments (p\u0304)i\u2208N whose welfare is at least half that of A, and such that the total payments are at most 2\u03b1 times the welfare of S.\nRecall that in a core stable solution S, it is necessary that for every project k and set T of agents, vk(Sk \u222a T ) \u2264 \u2211 i\u2208Sk\u222aT p\u0304i. A naive approach is to consider whether the dual payments (price p\u2217i plus the slack z \u2217 k divided equally among Ak) would suffice to enforce core stability to the solution A. Unfortunately, this naive strategy fails because the payments are not enough to prevent the deviation of agents to empty projects. To remedy this, we take the following approach: we implement a matching-based routine that allows us to identify the \u2018light\u2019 and \u2018heavy\u2019 users at each project so that when the light users deviate to the empty projects, there is not much welfare loss (and vice-versa for the heavy users). We assign the light users to these projects, and provide the heavy users with payments that depend on both \u2018the best outside option\u2019 available to them and their contribution to social welfare in order to stabilize them.\nWe begin by defining a simple Greedy Matching with Reserve Prices procedure that will serve as a building block for our main algorithm. The procedure is straightforward so we state it in words here and formally define it in Appendix A.\nAlgorithm 2: \u201cBegin with an input allocation and initial payments. During every iteration, assign an agent i to a currently empty project k, as long as her current payment pi < vk(i), and update her payment to vk(i). Terminate when pi \u2265 vk(i) for each agent i and empty project k.\u201d\nWe begin our analysis of the above procedure with a simple observation: during the course of the algorithm, the payments of the agents are non-decreasing (in fact, in every iteration, the payment of at least one agent strictly increases). Specifically, we are interested in analyzing the solution returned by the algorithm when the input allocation is A, and the input payments are the naive dual payments discussed above. We first describe some notation and then prove some lemmas regarding the solution returned by the algorithm for this input. Recall that for any given solution X, \u03b6(X) denotes the set of empty projects under X.\nWe denote by p0 the marginal contributions given by the optimal dual payment plus the slack divided equally as per A, i.e., if agent i \u2208 Ak, then p0i = p\u2217i + z\u2217k |Ak| . Suppose we run the\nalgorithm on the input (A,p0); let the corresponding output allocation be B, and the payments be pB. Also define for every k \u2208 P \\ \u03b6(A), A+k = Ak \u2229 Bk to be the agents who remained on project k, A\u2212k = Ak \\A+k to be the agents who left project k, and Pk to be the set of projects that the agents in A\u2212k switched to in allocation B. Note that all the projects in Pk will only have one agent each in B due to the definition of the algorithm. We now divide the non-empty projects in A into two categories based on the welfare lost after running the algorithm. Specifically, consider any project k in P \\ \u03b6(A). We refer to k as a good project if the welfare in B due to the agents originally in Ak is at least half their original welfare, and refer to k as a bad project otherwise. That is, k is a good project iff,\nvk(A + k ) + \u2211 l\u2208Pk vl(Bl) \u2265 vk(Ak) 2 .\nThe following lemma which we prove in the Appendix establishes the crucial fact that although bad projects may result in heavy welfare losses, they surprisingly retain at least half the agents originally assigned to them under A. Later, we use this to infer that the agents who deviated from bad projects are \u2018heavy\u2019 users who contribute significantly to the project\u2019s welfare.\nLemma 4. For every bad project k, |A+k | > |A\u2212k |, i.e., more than half the agents in Ak still remain in project k.\nOur next lemma relates the output payments pB to the optimal dual variables.\nLemma 5. For every project k, and every agent i who is allocated to k in B, her payment under pB is not larger than p\u2217i + z\u2217k |Bk| .\nProof: We prove the lemma in two cases. First consider any agent i whose allocation remains the same (say project k) during the entire course of Algorithm 2 for the input (A,p0). Clearly, this agent\u2019s final payment returned by the algorithm pBi is exactly the same as her initial payment p0i = p \u2217 i + z\u2217k |Ak| . However, we know that |A + k | \u2264 Bk. Therefore, pBi = p\u2217i + z\u2217k |Ak| \u2264 p \u2217 i + z\u2217k |Bk| .\nNext, consider an agent i \u2208 Bk whose allocation changed at some point during the course of the algorithm. This means that |Bk| = 1. Then, by definition, her final payment is exactly vk(i), which is not larger than p\u2217i + z \u2217 k by dual feasibility. ut\nMain Algorithm: Phase I While the returned solution B is indeed core stable, its welfare may be poor due to the presence of one or more bad projects. Instead of using solution B, we use its structure as a guide for how to form a high-welfare solution. For good projects, we can put the agents in A+k onto k and the agents in A \u2212 k onto Pk; since these are good projects this is guaranteed to get us half of the welfare vk(Ak), as desired. For bad projects, on the other hand, more than half of the welfare disappeared when we moved agents on A\u2212k away; due to sub-additivity this means that vk(A \u2212 k ) \u2265 vk(Ak) 2 . So instead we will assign agents in A \u2212 k to project k (which is the opposite of what happens in solution B), and put some agents from A+k onto projects Pk. This is Phase I of our main algorithm, defined formally in Appendix A. Payments at the end of Phase I: Suppose that the allocation at the end of the above procedure is S\u2032; let us define the following payment vector p\u2032. For every good project k: for each agent i assigned to l \u2208 k \u222a Pk, her payment is p\u2032i = p\u2217i + z\u2217l |S\u2032l | . For every bad project k, define Dk := S \u2032 k \\ A\u2212k to be the set of dummy agents belonging to that project. Each dummy agent\nreceives exactly p\u2032i = p \u2217 i as payment; every non-dummy agent assigned to a bad project receives p\u2032i = p B i plus the left over slack from that project. For each bad project k, every agent i assigned to some l \u2208 Pk receives a payment of p\u2032i = p\u2217i + z\u2217l . We break the flow of our algorithm and show some properties satisfied by the solution returned by Phase I of our algorithm (S\u2032,p\u2032). Mainly we show that this solution is almost corestable and has desired welfare properties. In Phase II, we once again invoke our Greedy Matching Procedure to ensure core-stability. Recall that every bad project contains at least one dummy agent; all the agents N other than the dummy agents will be referred to as non-dummy agents.\nLemma 6. For every agent i that does not belong to the set of dummy agents, her payment at the end of the first phase (p\u2032i) is at least her payment returned by the call to the Greedy Matching Procedure pBi .\nSpecifically, the above lemma implies that with respect to the non-dummy agents, our solution (S\u2032,p\u2032) retains the \u2018nice\u2019 stability properties guaranteed by the greedy matching procedure.\nCorollary 7. For every empty project k in S\u2032 (i.e., k \u2208 \u03b6(S\u2032)), and every non-dummy agent i, her payment at the end of the first phase is at least her individual valuation for project k, i.e.,\np\u2032i \u2265 vk(i).\nNow that we have a lower bound on the payments returned by the first phase of our algorithm, we show a stricter lemma giving an exact handle on the payments.\nLemma 8. For every non-empty project k /\u2208 \u03b6(S\u2032), the total payment to agents in k at the end of Phase I is exactly \u2211 i\u2208S\u2032k p\u2217i + z \u2217 k.\nOur final lemma shows that the total welfare at the end of the first phase is at least half the welfare of the original input allocation A.\nLemma 9. For every good project k, the welfare due to the agents in k \u222a Pk is at least half of vk(Ak)\n2 . For every bad project k, the welfare due to the non-dummy agents in k, i.e., A \u2212 k is at\nleast half of vk(Ak)2 .\nProof: The first half of the lemma is trivially true because of the definition of good projects and the fact that the allocation of agents to the projects in k \u222a Pk is the same as the allocation returned by the call to Algorithm 2.\nMoving on to bad projects, we know that S\u2032k \u2287 A\u2212k and the agents in A\u2212k are exactly the non-dummy agents in project k. Therefore, we have\nvk(A \u2212 k ) \u2265 vk(Ak)\u2212 vk(A+k ) \u2265 vk(Ak)\u2212\nvk(Ak)\n2 (By the definition of bad projects).\nObserve that by virtue of this lemma, we can immediately obtain that the solution returned by the first phase of our algorithm has half the social welfare of the allocation A. ut"}, {"heading": "Main Algorithm - Phase II", "text": "From the above lemmas, it is not hard to conclude that the solution S\u2032 at the end of Phase I has good social welfare and is resilient against deviations to empty projects as long as we only consider non-dummy agents2. In the second phase of our algorithm, we fix this issue by allowing dummy agents to deviate to empty projects using our Greedy Matching procedure and lower bounding their final payments using the dual variables. We formalize the algorithm for Phase II in the Appendix. Suppose that S is the solution returned by the Greedy Matching Algorithm with input (S\u2032,p\u2032), and p\u0304 is the payment vector where all the agents who deviated from S\u2032 receive as much as their dual variables, and the rest of the agents receive their payment under p\u2032. We now state some simple properties that compare the output of Phase II with its input, and formally prove them in Appendix A.\nClaim 10 The following properties are true:\n1. The set of empty projects in S is a subset of the set of empty projects in S\u2032, i.e., \u03b6(S) \u2286 \u03b6(S\u2032). 2. For all non-dummy agents, their strategies in S\u2032 and S coincide. 3. For every agent i \u2208 N , her payment at the end of Phase II (p\u0304i) is at least her payment at the end of Phase I.\nOur final lemma before showing the main theorem tells us that for every project, the total payment made to agents of that project coincides with the dual payments. The final payments to agents, therefore, are simply a redistribution of the dual payments. We defer its proof to the Appendix.\nLemma 11. For every non-empty project k /\u2208 \u03b6(S), the total payments made to agents in k is exactly \u2211 i\u2208Sk p \u2217 i + z \u2217 k. Moreover, the payment made to any agent i is at least her dual price p \u2217 i .\nThe rest of the theorem follows almost immediately. We begin by showing that the solution (S, (p\u0304)i) is core stable. Consider any project k, and a deviation by some set of agents T to this project. We only have to show that the total payment made to the agents in Sk \u222a T is at least vk(Sk \u222a T ). We proceed in two cases.\nFirst, suppose that Sk = \u2205. Then, we have vk(Sk \u222a T ) \u2264 \u2211 i\u2208Sk\u222aT vk(i) \u2264 \u2211\ni\u2208Sk\u222aT p\u0304i from Subadditivity, and Claim 10 respectively. Claim 10). Now suppose that Sk 6= \u2205. Then, we have\u2211\ni\u2208Sk\u222aT p\u0304i = \u2211 i\u2208Sk p\u0304i + \u2211 i\u2208T p\u0304i \u2265 \u2211 i\u2208Sk p\u2217i + z \u2217 k + \u2211 i\u2208T p\u2217i By Lemma 11\n\u2265 vk(Sk \u222a T ) By dual feasibility\nWe now establish that the social welfare of our solution is at least half the social welfare of the original allocation A. Recall that every non-empty project in A was classified as a good or bad project. For every good project k and its associated projects Pk, the fact that vk(Sk) +\u2211\nl\u2208Pk vl(Sl) \u2265 vk(Ak)/2 follows from Lemma 9 since Sk = S \u2032 k, and Sl = S \u2032 l.\nConsider any bad project k. We know that for every non-dummy agent in S\u2032k, her strategy in S is still project k. Therefore, the welfare due to any bad project is at least the welfare due to the non-dummy agents in that project which by Lemma 9 is at least half of vk(Ak). Finally,\n2 We can also show that the solution is resilient against deviations to non-empty projects, although this is not needed at this time.\nall that remains is to show that the total payments made in (p\u0304)i are at most a factor 2\u03b1 larger than the welfare of the solution.\nFrom Lemma 11, we know that the total payments made to agents at the end of Phase I is at most the value of the Dual Optimum of LP 1, which by Strong Duality is equal to the value of the Primal Optimum. However, we know that the welfare of S is at least half the welfare of A, which by definition is at most a factor \u03b1 away from the LP Optimum. This completes the proof."}, {"heading": "3.1 Anonymous Functions", "text": "Our other main result in this paper is a (2, 2)-Core stable solution for the class of subadditive functions that are anonymous. Recall that for an anonymous valuation v, v(T1) = v(T2) for any |T1| = |T2|. Such functions are frequently assumed in coalition formation and project assignment settings [30]. We begin with some existential lower bounds for approximating the core. From Example (1), we already know that the core may not exist even in simple instances. Extending this example, we show a much stronger set of results.\nClaim 12 (Lower Bounds) There exist instances having only two projects with anonymous subadditive functions such that\n1. For any > 0, no (2\u2212 , c1)-core stable solution exists for any value c1. 2. For any > 0, no (c2, 2\u2212 )-core stable solution exists for any value c2.\n(Proof Sketch) (Part 1) For ease of notation, we show that no (2\u2212 )-budget-balanced core stable solution exists for a given > 0. Consider an instance with N buyers. The valuations for the two projects are v1(S) = N 2 \u2200S \u2282 N , and v1(N ) = N ; v2(S) = 2 \u2200S \u2286 N . Assume by contradiction that there is a (2\u2212 )-core stable solution, then this cannot be achieved when all of the agents are assigned to project 1 because they would each require a payment of 2 to prevent them from deviating to project 2. On the other hand, suppose that some agents are assigned to project 2, then the social welfare of the solution is at most N2 + 2. If these agents cannot deviate to project 1, then, the total payments would have to be at least v1(N ) = N . For a sufficiently large N , we get that the budget-balance is NN/2+2 > 2 \u2212 . The example for Part 2 is provided in the Appendix.\nWe now describe an intuitive 2-approximation algorithm (Algorithm 1) for maximizing welfare that may be of independent interest. To the best of our knowledge, the only previously known approach that achieves a 2-approximation for anonymous subadditive functions is the LP-based rounding algorithm for general subadditive functions [20]. Our result shows that for the special class of anonymous functions, the same approximation factor can be achieved by a much faster, greedy algorithm. In addition, our greedy algorithm also possesses other \u2018nice structural properties\u2019 that may be of use in other settings such as mechanism design [33]. Recall that the quantity v(T |S) refers to v(S \u222a T )\u2212 v(S). Although Algorithm 1 is only an approximation algorithm, the following theorem shows that we can utilize the greedy structure of the allocation and devise payments that ensure core stability. In particular, the solution that we use to construct a (yet to be proved) (2, 2)-core is (S, p\u0304), where S is the allocation returned by the algorithm, and p\u0304i = 2pi is the payment provided to agent i. We remark that the \u2018marginal contributions\u2019 are defined only for the sake\nAlgorithm 1: Greedy 2-Approximation Algorithm for Anonymous Subadditive Functions 1: Initialize the set of unallocated agents U \u2190 N 2: Initialize the current allocation S \u2190 (\u2205, . . . , \u2205) 3: while U 6= \u2205 do 4: Find a set T \u2286 U that maximizes the ratio vk(T |Sk)|T | over all k \u2208 P\n5: Assign the agents in T to the project k that maximizes the above ratio {Sk = Sk \u222a T and U = U \\ T .} 6: For all i \u2208 T , set agent i\u2019s marginal contribution pi = vk(T |Sk)|T | . 7: end while 8: Return the final allocation S.\nof convenience. They do not serve any other purpose. We make the following simple observation regarding the algorithm: the total social welfare of the solution S, SW (S) is exactly equal to the sum of the marginal contributions \u2211 i\u2208N pi.\nTheorem 13. For any instance with anonymous subadditive projects, the allocation S returned by Algorithm 1 along with a payment of p\u0304i = 2pi for every i \u2208 N constitutes a (2, 2)-core stable solution.\nProof: We begin with some basic notation and simple lemmas highlighting the structural properties of our algorithm leading up to the main result. First, note that the total payments are exactly equal to the twice the aggregate marginal contribution, which in turn is equal to twice the social welfare. Therefore, our solution is indeed 2-budget balanced. Now, let us divide the execution of the greedy algorithm into iterations from 1 to r such that in every iteration, the algorithm chooses a set of unallocated agents maximizing the marginal contribution (average increase in welfare). We define Aj to be the set of agents assigned to some project during iteration j \u2264 r. Clearly, all the agents in Aj are allocated to the same project, and have the exact same marginal contribution, and therefore payment. Let us use p(j) to refer to the marginal contribution of the agents in Aj .\nNote that in order to characterize the state of the algorithm during iteration j, it is enough if we express the set of agents assigned to each project, and the set of unallocated agents. Define S (j) k to be the set of agents allocated to project k at the beginning of iteration j (before the agents in Aj are assigned), and U (j) to be the set of unallocated agents during that instant. Suppose that the agents in Aj are assigned to project k, then by definition the following equation must be true,\np(j) = vk(Aj |S(j)k ) |Aj | .\nFinally, given any T \u2286 N , we denote by T>, the ordered set of elements in T in the decreasing order of their payment. We begin with a simple property that links the prices to the welfare of every project.\nProposition 14. In the final allocation S, the social welfare due to every project k equals the total marginal contributions to the agents assigned to that project, i.e.,\u2211\ni\u2208Sk\npi = vk(Sk).\nThe proof follows directly from the definition of the algorithm. Now, we establish that as the algorithm proceeds, the marginal contributions of the agents cannot increase.\nLemma 15. For every i, j with i < j, the marginal of the agents in Ai is not smaller than the marginal of the agents in Aj, i.e., p (1) \u2265 p(2) \u2265 . . . \u2265 p(r).\n(Proof Sketch) Since, the assignment of agents to any one project does not affect the marginal contribution (or average increase in welfare) in other projects, it suffices to prove the lemma for the case when Ai and Aj are assigned to the same project. The rest of the proof involves showing that if the lemma does not hold, then adding Ai \u222aAj instead of Ai in iteration i would have lead to larger average welfare. The full proof is in the Appendix.\nRecall that Proposition 14 equates the marginal contributions to the welfare for every set Sk. The following lemma establishes a relationship between payments and welfare for subsets of Sk. Note that since the payments to the agents are exactly twice their marginal, we can use the payments and marginal contributions interchangeably. Once again, its proof is in Appendix B.\nLemma 16. For every project k, and any given positive integer t \u2264 |Sk|, the total marginal contribution of the t highest paid agents in Sk is at least the value derived due to any set of t agents, i.e., if T denotes the set of t-highest paid agents in Sk, then\u2211\ni\u2208T pi \u2265 vk(T ).\nWe now move on to the most important component of our theorem, which we call the Doubling Lemma. This lemma will serve as the fundamental block required to prove both core stability and the necessary welfare bound. The essence of the lemma is rather simple; it says that if we take some project k and add any arbitrary set of elements T on top of Sk, then the total resulting welfare is no larger than the final payments to the agents in T \u222aSk. We first state the Doubling Lemmma here and then prove that using this lemma as a black-box, we can obtain both our welfare and stability result. The proof of the lemma is deferred to the Appendix.\nLemma 17. (Doubling Lemma) Consider any project k and the set of elements assigned to k in our solution (Sk). Let T be some set of agents such that T \u2229 Sk = \u2205 and |T | > |Sk|. Then, the total payment to the agents in T \u222a Sk is at least vk(Sk \u222a T ), i.e.,\u2211\ni\u2208T\u222aSk\np\u0304i \u2265 vk(Sk \u222a T )."}, {"heading": "Proof of Core stability", "text": "We need to show that our solution (S, (p\u0304)i) is core stable, i.e., for every project k and set of agents T , vk(Sk \u222a T ) \u2264 \u2211 i\u2208Sk\u222aT p\u0304i. Assume by contradiction that \u2203 some project k and some set T that does not satisfy the inequality for stability. We claim that |T | > |Sk|. Lemma 18. If vk(Sk \u222a T ) > \u2211\ni\u2208Sk\u222aT p\u0304i, then there are strictly more agents in the set T than in project k under S, i.e., |T | > |Sk|.\nProof: We know that\nvk(T \u222a Sk) > \u2211\ni\u2208T\u222aSk p\u0304i \u2265 2 \u2211 i\u2208Sk pi = 2vk(Sk).\nLet Q be some arbitrary set of size |T\u222aSk|2 . Applying Proposition 25, we get,\nvk(Q) \u2265 1\n2 vk(T \u222a Sk) > vk(Sk).\nBy monotonicity, it must be that |Q| > |Sk|, and so |T \u222aSk| > 2|Sk| giving us the desired lemma. ut\nSo, Sk and T satisfy the conditions required for the doubling lemma. Applying the lemma, we get \u2211 i\u2208Sk\u222aT p\u0304i \u2265 vk(Sk \u222aT ), which is a contradiction. Therefore, our solution is indeed core stable."}, {"heading": "Welfare Bound", "text": "Suppose that the optimum solution O\u2217 = (O\u22171, . . . , O \u2217 M ) has a social welfare of v(O \u2217). We need to show that the social welfare of our solution v(S) is at least half of v(O\u2217). Recall that our social welfare is exactly equal to half the payments \u2211 i p\u0304i. Therefore, it suffices if we prove that the welfare of the optimal solution v(O\u2217) is not larger than the sum of the payments. Our approach is as follows: we will map every project k to a proxy set Xk \u2286 N so that \u2211 i\u2208Xk p\u0304i \u2265 vk(O \u2217 k). If we ensure that the sets (Xk)k\u2208P are mutually disjoint, we can sum these inequalities up to get our desired welfare bound.\nWe begin by dividing the projects into three categories based on the number of agents assigned to these projects in our solution |Sk| and how this compares to |O\u2217k|, 1. (P1) All projects k satisfying, |O\u2217k| \u2265 |Sk| \u2265 12 |O\u2217k|, 2. (P2) All projects k satisfying |Sk| > |O\u2217k|, 3. (P3) All projects k satisfying |O\u2217k| > 2|Sk|, i.e., in the optimum solution k has more than\ndouble the number of agents assigned to k in our solution.\nWe define the sets Xk as follows: for every project k \u2208 P1, Xk = Sk. For every project k \u2208 P2, Xk is defined as the set of |O\u2217k| agents in Sk with the highest payments as per our solution. Notice that for every k \u2208 P2, there are some \u2018left over\u2019 agents who are not yet assigned to any Xk\u2032 . Let Rem be the union of such leftover agents over all projects in P2.\nFinally, for every project k \u2208 P3, we define Xk to be Sk plus some arbitrarily chosen |O\u2217k|\u2212|Sk| agents from the set Rem. It is not hard to see that we can choose Xk\u2019s for the projects in P3 in such a manner that these sets are all mutually disjoint. Indeed, this is true because\n|Rem|+ \u2211 k\u2208P3 |Sk| \u2265 \u2211 k\u2208P3 |O\u2217k|.\nThe above inequality comes from the fact that |O\u2217k| \u2212 |Xk| summed over all k \u2208 P1 \u222a P2 is a non-negative number. Now all that remains is for us to show that \u2211 i\u2208Xk p\u0304i \u2265 vk(O \u2217 k) for every k. First, look at the projects in P1. We can show that \u2211 i\u2208Xk p\u0304i = 2vk(Sk) \u2265 2. 1 2vk(O \u2217 k), where the last inequality comes from Proposition 25 since Sk has at least half as many agents as O \u2217 k.\nNow, for the projects in P2, we can directly apply Lemma 16 to get \u2211 i\u2208Xk p\u0304i = 2 \u2211\ni\u2208Xk pi \u2265 vk(O \u2217 k).\nFinally, look at the projects in P3. Fix some k \u2208 P3, and define T = Xk\\Sk. Since |Xk| = |O\u2217k|, we immediately get |T | > |Sk| from the definition of P3. Therefore, we can apply the important Doubling Lemma and get the desired result. This completes the proof of our final welfare bound.\nEnvy-Free Payments One interpretation for projects having anonymous valuations is that all the agents possess the same level of skill, and therefore, the value generated from a project depends only on the number of agents assigned to it. In such scenarios, it may be desirable that the payments given to the different agents are \u2018fair\u2019 or envy-free, i.e., all agents assigned to a certain project must receive the same payment. The following theorem (which we formally prove in the Appendix) shows that Algorithm 1 can be used to compute a (2, 2)-approximate core that also satisfies this additional constraint of envy-freeness.\nClaim 19 For any instance where the projects have anonymous subadditive valuations, there exists a (2, 2)-core stable solution such that the payments are envy-free, i.e., all the agents assigned to a single project receive the same payment."}, {"heading": "3.2 Submodular and Fractionally Subadditive (XoS) Valuations", "text": "Submodular and Fractionally Subadditive valuations are arguably the most popular classes of subadditive functions, and we show several interesting and improved results for these sub-classes. For instance, for XoS valuations, we can compute a (1 + )-core using Demand and XoS oracles (see [18] for a treatment of XoS oracles), whereas without these oracles, we can still compute a ( ee\u22121)-core. For submodular valuations, we provide an algorithm to compute a (1 + )-core even without a Demand oracle. All of these solutions retain at least a fraction (1\u2212 1e ) of the optimum welfare, which matches the computational lower bound for both of these classes. We begin with a simple existence result for XoS valuations, that the optimum solution along with payments obtained using a XoS oracle form an exact core stable solution. All the results that we state in this Section, and Section 4 are proved in the Appendix.\nProposition 20. There exists a (1, 1)-core stable solution for every instance where the projects have XoS valuations.\nSince Submodular \u2282 XoS, this result extends to Submodular valuations as well. Unfortunately, it is known that the optimum solution cannot be computed efficiently for either of these classes unless P=NP [18]. However, we show that one can efficiently compute approximately optimal solutions that are almost-(core)-stable.\nTheorem 21. 1. For any instance where the projects have XoS valuations, we can compute (1 + , ee\u22121)-core stable solution using Demand and XoS oracles, and a ( e e\u22121 , e e\u22121)-core stable\nsolution without these oracles. 2. For submodular valuations, we can compute a (1 + , ee\u22121)-core stable solution using only a\nValue oracle.\nNote that for both the classes, a (1 + )-core can be computed in time polynomial in the input, and 1 . We conclude by pointing out that the results above are much better than what could have been obtained by plugging in \u03b1 = ee\u22121 in Theorem 2 for Submodular or XoS valuations."}, {"heading": "4 Relationship to Combinatorial Auctions", "text": "We now change gears and consider the seemingly unrelated problem of Item Bidding Auctions, and establish a surprising equivalence between Core stable solutions and pure Nash equilibrium in Simultaneous Second Price Auctions. Following this, we adapt some of our results specifically for the auction setting and show how to efficiently compute Approximate Nash equilibrium when buyers have anonymous or submodular functions.\nIn recent years, the field of Auction Design has been marked by a paradigm shift towards \u2018simple auctions\u2019; one of the best examples of this is the growing popularity of Simultaneous Combinatorial Auctions [9, 14, 17], where the buyers submit a single bid for each item. The auction mechanism is simple: every buyer submits one bid for each of the N items, the auctioneer then proceeds to run N -parallel single-item auctions (usually first-price or second-price). In the case of Second Price Auctions, each item is awarded to the highest bidder (for that item) who is then charged the bid of the second highest bidder. Each buyer\u2019s utility is her valuation for the bundle she receives minus her total payment.\nWe begin by establishing that for every instance of our utility sharing problem, there is a corresponding combinatorial auction, and vice-versa. Formally, given an instance (N ,P, (v)k\u2208P), we define the following \u2018flipped auction\u2019: there is a set N of N items, and a set P of m buyers. Every buyer k \u2208 P has a valuation function vk for the items. In the simultaneous auction, the strategy of every buyer is a bid vector bk; bk(i) denotes buyer k\u2019s bid for item i \u2208 N . A profile of bid vectors (b1, . . . , bm) along with an allocation is said to be a pure Nash equilibrium of the simultaneous auction if no buyer can unilaterally change her bids and improve her utility at the new allocation.\nOver-Bidding Nash equilibrium in Simultaneous Auctions is often accompanied by a rather strong no-overbidding condition that a player\u2019s aggregate bid for every set S of items is at most her valuation vk(S) for that set. In this paper, we also study the slightly less stringent weak no-overbidding assumption considered in [24] and [22] which states that \u2018a player\u2019s total bid for her winning set is at most her valuation for that set\u2019. The set of equilibrium with no-overbidding is strictly contained in the set of equilibrium with weak no-overbidding. Finally, to model buyers who overbid by small amounts, we focus on the following natural relaxation of no-overbidding known as \u03b3-conservativeness that was defined by Bhawalkar and Roughgarden [9]. Definition 22. (Conservative Bids) [9] For a given buyer k \u2208 P, a bid vector bk is said to be \u03b3-conservative if for all T \u2286 N , we have \u2211i\u2208T bk(i) \u2264 \u03b3 \u00b7 vk(T ). We now state our main equivalence result that is based on a simple black-box transformation to convert a Core stable solution (S, p\u0304) to a profile of bids (bk)k\u2208P that form a Nash Equilibrium: bk(i) = p\u0304i if i \u2208 Sk, and bk(i) = 0 otherwise.\nTheorem 23. Every Core stable solution for a given instance of our game can be transformed into a Pure Nash Equilibrium (with weak no-overbidding) of the corresponding \u2018flipped\u2019 simultaneous second price auction, and vice-versa.\nExistence and Computation of Equilibrium Although simultaneous auctions enjoy several desirable properties like good Price of Anarchy [9, 14], their applicability is limited by both existential and computational barriers. Particularly, while a no over-bidding Nash equilibrium\nalways exists for simple valuations like XoS, it may not be possible to actually compute one [17]. For more general subadditive (and even anonymous) valuations, Nash equilibria without overbidding may not even exist [9], and whether or not they exist cannot be determined without exponential communication [17]. A case for Approximate Equilibrium The exciting connection between Core stable solutions and Nash Equilibrium unfortunately extends to negative results as well. One can extend our lower bound examples (See Appendix) to show that even when all buyers have anonymous subadditive functions, there exist instances where every Nash equilibrium requires O( \u221a N)-conservative bids. The expectation that buyers will overbid by such a large amount appears to be unreasonable. In light of these impossibility results and the known barriers to actually compute a (no-overbidding) equilibrium [17], we argue that in many auctions, it seems reasonable to consider \u03b1-approximate Nash equilibrium that guarantee that buyers\u2019 utilities cannot improve by more than a factor \u03b1 when they change their bids. In the following result, we adapt our previous algorithms to compute approximate equilibria with high social welfare for two useful settings. Moreover, these solutions require small over-bidding, and can be obtained via simple mechanisms, so it seems likely that they would actually arise in practice when pure equilibria either do not exist or require a large amount of overbidding.\nClaim 24 Given a Second Price Simultaneous Combinatorial Auction, we can compute in time polynomial in the input (and 1 for a given > 0)\n1. A 2-approximate Nash equilibrium that extracts half the optimal social welfare as long as the buyers have anonymous subadditive valuations. 2. A (1 + )-approximate Nash equilibrium that is a ee\u22121 -approximation to the optimum welfare when the buyers have submodular valuations.\nThe first solution involves 4-conservative bids, and the second solution involves (1 + )- conservative bids.\nGiven a submodular valuation vk, define vmax = maxi,S vk(i|S). Also, define\u2206 = mini,S vk(i|S) such that vk(i|S) > 0. That is \u2206 is the smallest non-zero increment in utility. Then, the algorithm for Submodular Functions converges in Poly(N,m, 1 , log(\nvmax \u2206 )) time. One can contrast this re-\nsult to an algorithm by [17] that computes an exact Nash equilibrium in pseudo-polynomial time, i.e., O(vmax\u2206 ). On the contrary, we show that we can compute an approximate Nash equilibrium in poly-time (using a PTAS)."}, {"heading": "Conclusion", "text": "We conclude by remarking that despite the large body of work in Simultaneous Auctions, our main results do not follow from any known results in that area, and we hope that our techniques lead to new insights for computing auction equilibria."}, {"heading": "A Appendix: Proofs for Subadditive Valuations", "text": "We begin by formally defining the Greedy Matching Procedure procedure that is the building block of our main algorithm.\nAlgorithm 2: Greedy Matching with Reserve Prices\nInput : Allocation I = (I1, . . . , IM ), Payments p I = (pI1, . . . , p I N ). Output: Allocation O = (O1, . . . , OM ), Payments p O = (pO1 , . . . , p O N ).\n1 Initialize the current allocation S = I, and current payments p = pI . 2 if \u2203 empty project k with Sk = \u2205 and agent i such that vk(i) > pi then 3 Remove agent i from her current project and assign her to the empty project l with the maximum value of vl(i). Update agent i\u2019s payment to pi = vl(i). 4 else 5 return the current allocation S and payments p. 6 end\nLemma 4. For every bad project k, |A+k | > |A\u2212k |, i.e., more than half the agents in Ak still remain in project k.\nProof: We prove this by contradiction. Suppose that for some such k, |A\u2212k | \u2265 |A+k |. Recall that the marginal contributions given to agents in A\u2212k is\u2211\ni\u2208A\u2212k\np\u2217i + |A\u2212k | |Ak| z\u2217k \u2265 \u2211 i\u2208A\u2212k p\u2217i + z\u2217k 2\n(since Ak = A + k \u222aA\u2212k ).\nMoreover, the payments are non-decreasing under Algorithm 2, and agent i \u2208 A\u2212k is transferred from project k to some project l only if vl(i) > p \u2217 i +\nz\u2217k |Ak| . Therefore, we have,\u2211\nl\u2208Pk vl(Bl) > \u2211 i\u2208A\u2212k (p\u2217i + z\u2217k |Ak| ) \u2265 \u2211 i\u2208A\u2212k p\u2217i + z\u2217k 2 .\nNow, p\u2217 and z\u2217 are feasible solutions to the dual LP; this means that \u2211\ni\u2208A\u2212k p\u2217i + z \u2217 k \u2265 vk(A\u2212k ).\nSo, we have,\nvk(A + k ) + \u2211 l\u2208Pk vl(Bl) \u2265 vk(A+k ) + \u2211 i\u2208A\u2212k p\u2217i + z\u2217k 2\n> vk(A + k ) +\n1 2 vk(A \u2212 k )\n\u2265 1 2 (vk(A + k ) + vk(A \u2212 k )) \u2265 1 2 vk(Ak).\nThe last inequality follows from subadditivity and the fact that Ak = A + k \u222a A\u2212k . However, this contradicts the definition of a bad project. So, we must have that |A\u2212k | < |A+k |. ut"}, {"heading": "Main Algorithm - Phase I", "text": "1. Run Algorithm 2 on the allocation A with payments p0. Let the output be B,pB, and define A+k , A \u2212 k , and Pk as mentioned above. 2. (Good Projects) For every good project k \u2208 P \\ \u03b6(A) (a) \u2200i \u2208 A+k , assign them to project k, set p\u2032i = p\u2217i +\nz\u2217k |A+k |\n(b) \u2200i \u2208 A\u2212k , assign them to their project l \u2208 Pk, set p\u2032i = p\u2217i + z\u2217l (c) Denote the resulting sets by S\u2032k and S \u2032 l\n3. (Bad Projects) For every bad project k \u2208 P \\ \u03b6(A) (a) Arbitrarily choose dummy agents Dk \u2282 A+k such that |Dk| = |A+k |\u2212 |A\u2212k | (this is possible\ndue to Lemma 4). (b) Set S\u2032k = A \u2212 k \u222aDk. (c) For i \u2208 A\u2212k , set p\u2032i = pBi + z\u2032k |A\u2212k | where z\u2032k is the leftover slack defined as z \u2217 k\u2212 \u2211 i\u2208A\u2212k (pBi \u2212p\u2217i ).\nFor i \u2208 Dk, set p\u2032i = p\u2217i . (d) Assign the non-dummy agents in A+k arbitrarily to the projects in Pk so that each project\nin Pk gets exactly one agent from (A + k \\Dk). (S\u2032l is defined accordingly for l \u2208 Pk).\n(e) For every l \u2208 Pk: for i \u2208 S\u2032l, set p\u2032i = p\u2217i + z\u2217l .\nLemma 6. For every agent i that does not belong to the set of dummy agents, her payment at the end of the first phase (p\u2032i) is at least her payment returned by the call to the Greedy Matching Procedure pBi .\nProof: For each agent assigned to a good project k and the associated set of agents in Pk, the claim follows almost trivially from Lemma 5 and the definition of the final payment p\u2032i. Moreover, suppose that k is a bad project, then we claim that the leftover slack z\u2032k is non-negative. This is true because \u2211\ni\u2208A\u2212k\npBi = \u2211 l\u2208Pk vl(Bl) < vk(Ak)/2 < vk(A \u2212 k ) \u2264 \u2211 i\u2208A\u2212k p\u2217i + z \u2217 k.\n(The first inequality above is since k is a bad project; the second is due to the fact that vk is subadditive and vk(A + k ) < vk(Ak)/2 since k is a bad project. The last is due to dual feasibility.)\nTherefore, by definition, the payment to a non-dummy agent i assigned to a bad project\np\u2032i = p B i + z\u2032l |A\u2212k | \u2265 pBi . Finally, fix a bad project k and consider the agents assigned to the projects in Pk. We claim that for every l \u2208 Pk, z\u2217l is at least as large as z\u2217k |Ak| . We first show how this claim leads to the desired lemma and then conclude by proving the claim. For any l \u2208 Pk, let S\u2032l be some agent i. Since agent i \u2208 A+k , it remained on the same project k in solution B. This means that her payment as output by the matching procedure is exactly the same as the input payment p\u2217i + z\u2217k |Ak| , which by the above claim is not larger than p \u2217 i + z \u2217 l giving us the desired lemma. (Proof of Claim that z\u2217l \u2265 z\u2217k |Ak|) Suppose that some agent j \u2208 Ak belonged to project l in the solution returned by the matching B. Then, by the monotonicity of payments in Algorithm 2, it must hold that j\u2019s payment at the termination of Algorithm 2, pBj , is at least her initial payment p\u2217j + z\u2217k |Ak| . Applying dual feasibility, we get the desired claim\np\u2217j + z \u2217 l \u2265 vl(j) = pBj \u2265 p\u2217j + z\u2217k |Ak| .\nut Lemma 8. For every non-empty project k /\u2208 \u03b6(S\u2032), the total payment to agents in k at the end of Phase I is exactly \u2211 i\u2208S\u2032k p\u2217i + z \u2217 k.\nProof: First consider any good project k and the associated set of projects in Pk. By definition, for every l \u2208 k \u222aPk, the total payments to the agents in S\u2032l is exactly as given by the lemma. So the proof for good projects and associated projects is trivial. Suppose that k is a bad project, then every l \u2208 Pk contains exactly one agent i whose payment is exactly p\u2217i + z\u2217l . Finally, look at project k and recall that Dk is the set of dummy agents in k. Then, by definition of the payments to the agents in S\u2032k, we have\u2211\ni\u2208S\u2032k\np\u2032i = \u2211\ni\u2208S\u2032k\\Dk\np\u2032i + \u2211 i\u2208Dk p\u2032i = \u2211\ni\u2208S\u2032k\\Dk\np\u2217i + z \u2217 k + \u2211 i\u2208Dk p\u2217i .\nut"}, {"heading": "Main Algorithm - Phase II", "text": "1. Input to this Phase is the output of Phase I: (S\u2032,p\u2032) 2. Run Algorithm 2 with the input (S\u2032,p\u2032) 3. Let the output of Algorithm 2 be (S,ptemp). 4. Construct the final payment vector (p\u0304)i as follows: if agent i belongs to strategy k in both S\nand S\u2032, then set p\u0304i = p temp i . Otherwise if agent i\u2019s strategy in S is k but her strategy is S \u2032 is not k, then set p\u0304i = p \u2217 i + z \u2217 k.\n5. Output the final solution: S, (p\u0304)i.\nWe now prove some simple properties that compare the output of Phase II with its input. Claim 10. The following properties are true:\n1. The set of empty projects in S is a subset of the set of empty projects in S\u2032, i.e., \u03b6(S) \u2286 \u03b6(S\u2032). 2. For all non-dummy agents, their strategies in S\u2032 and S coincide. 3. For every project k that was empty in S\u2032 but not in S, Sk consists of a single dummy agent i. 4. For every agent i \u2208 N , her payment at the end of Phase II (p\u0304i) is at least her payment at the end of Phase I.\nProof: Recall that in every stage of our greedy matching procedure, an agent i is transferred to an empty group (say k) having the largest value of vk(i) as long as it is greater than the agent\u2019s current payment. Consider the execution of the greedy matching procedure in our algorithm\u2019s second phase. We prove by induction that at every stage of this procedure, (i) the set of empty projects is a subset of \u03b6(S), ii) for every non-dummy agent, her strategy remains the same as in S\u2032. Clearly, this is true at the beginning. Moreover, note that every project k /\u2208 \u03b6(S\u2032) contains at least one non-dummy agent under S\u2019.\nSuppose that the two induction hypotheses hold up to some iteration t of the algorithm. Let Pe be the set of empty projects at the end of this iteration, and let p be the payment vector after iteration t. In iteration t + 1, the agent i assigned to an empty project k satisfies pi < vk(i). This implies that i cannot be a non-dummy agent because due to Corollary 7 and\nthe monotonicity of payments, we know that for every non-dummy agent j, pj \u2265 p\u2032j \u2265 vk(i) since k \u2208 \u03b6(S\u2032). Therefore, project k gains a dummy agent in iteration t + 1 and the positions of non-dummy agents remain the same as they were in the previous iteration. Moreover, every non-empty project in S\u2032 still has one non-dummy agent and therefore, remains non-empty. We conclude the proof of Properties (1) and (2). Property (3) is simply a corollary of Property (2).\nFinally, we know by the monotonicity of payments that ptemp \u2265 p\u2032. Moreover, for every agent i whose strategy did not change from S\u2032, her payment remains the same as in ptemp and therefore, the input payments. For any dummy agent (say i) who transferred to an empty project (say k), her final payment is p\u2217i + z \u2217 k which by dual feasibility is not smaller than p temp i = vk(i) which in turn is larger than p\u2032i. Therefore, Property (4) also holds. ut Lemma 11. For every non-empty project k /\u2208 \u03b6(S), the total payments made to agents in k is exactly \u2211 i\u2208Sk p \u2217 i + z \u2217 k. Moreover, the payment made to any agent i is at least her dual price p \u2217 i .\nProof: The proof is rather straightforward and is analogous to Lemma 8. The only change caused by Phase II is in the strategies of dummy agents, and because dummy agents only belong to bad projects, it suffices to show this lemma for bad projects and the projects that newly gained a dummy agent in Phase II, i.e., k \u2208 \u03b6(S\u2032)\\\u03b6(S). For the latter case, the lemma is true trivially due to the definition of Phase II. Now, consider some bad project k, and let X be the set of dummy agents belonging to Sk (ones that did not deviate in the greedy matching procedure). Moreover, for every agent in Sk, her payment is the same as her input payment because these agents did not deviate during the course of the matching procedure. Therefore, the final payments to the agents can be aggregated similar to the method in Lemma 8,\u2211\ni\u2208Sk\np\u0304i = \u2211\ni\u2208Sk\\X\np\u0304i + \u2211 i\u2208X p\u0304i = \u2211 i\u2208Sk p\u2217i + z \u2217 k + \u2211 i\u2208X p\u2217i .\nut"}, {"heading": "B Appendix: Proofs for Anonymous Subadditive Valuations", "text": "We begin with a basic property of anonymous subadditive functions that we require in all of the proofs. In the rest of this paper, the notation v(T |S) refers to v(S \u222a T )\u2212 v(S).\nProposition 25. Let S \u2286 N be some set of agents, and suppose T \u2286 N such that |T | \u2265 |S|2 . Then for an anonymous subadditive function v, we have v(T ) \u2265 v(S)2 .\nThe proof follows from the fact that v(T ) + v(S \\ T ) \u2265 v(S), and |T | \u2265 |S|. Claim 12. (Lower Bounds) There exists instances having only two projects with anonymous subadditive functions such that\n1. For any > 0, no (2\u2212 , c)-core stable solution exists for any value c. 2. For any > 0, no (\u03b1, 2\u2212 )-core stable solution exists for any constant \u03b1.\nProof: (Part 2) Consider an instance with N agents and 2 projects. We choose a large enough N so that the following condition is satisfied N\nN/2+ \u221a N > 2 \u2212 . Now the project valuations are\ndefined as follows:\nv1(S) = N\n2 for S 6= N v2(S) =\n\u221a N \u2200S \u2286 N\nv1(N ) =N,\nThe social welfare is maximized when all agents are allocated to project 1. It is also not hard to see (due to our choice of N) that no other solution has a social welfare that is at most a factor 2 \u2212 away from OPT. Now, using the same reasoning as we did for the previous claim, we can conclude that in order to stabilize the optimum solution, every agent needs a payment of at least \u221a N , and therefore, the total payments have to be at least a factor \u221a N larger than the optimum welfare. ut Lemma 15. For every i, j with i < j, the marginal of the agents in Ai is not smaller than the marginal of the agents in Aj , i.e., p (1) \u2265 p(2) \u2265 . . . \u2265 p(r).\nProof: We argue that it is sufficient if we prove the lemma only for the case where the agents in Ai and Aj are assigned to the same project in S. To see why, suppose that the lemma holds for every such pair, now look at some Ai, Aj with i < j such that the agents in Ai belong to project ki and Aj belong to project kj with ki 6= kj . Next, define i < l \u2264 j to be the smallest index such that the agents in Al are assigned to project kj , the same as the agents in Aj . Note that by definition of l, S (i) kj = S (l) kj\n: the set of agents in project kj are the same before iterations i, and l. This implies that the assignment of the agents in Al to project kj was a possible step for the greedy algorithm for iteration i. However, since the greedy algorithm actually chose Ai \u2192 ki, this means that\np(i) = vki(Ai|S (i) ki ) |Ai| \u2265 vkj (Al|S (l) kj ) |Al| = p(l).\nBut we know that p(l) \u2265 p(j) since the agents in Al and Aj are assigned to the same project. Therefore, it suffices to prove the lemma for the case where the two sets of agents are assigned to the same project, i.e., we need to prove that if the agents in Ai and Aj are assigned to the same project with i < j, then p(i) \u2265 p(j).\nSuppose that the agents in Ai and Aj are both assigned to project k and assume by contradiction that p(j) > p(i). Without loss of generality, we can assume that no agents are assigned to project k in between iterations i and j. Since p(i) < p(j), we have\nvk(Ai|S(i)k ) |Ai| < vk(Aj |S(i)k \u222aAi) |Aj | .\nConsider the set Ai \u222aAj . We have that\nvk(Ai \u222aAj |S(i)k ) |Ai|+ |Aj | = vk(Aj |Ai \u222a S(i)k ) + vk(Ai|S (i) k ) |Aj |+ |Ai| > vk(Ai|S(i)k ) |Ai| .\nThe last inequality follows from the basic algebraic property that a+cb+d > min( a b , c d) as long as ab 6= cd . In other words, the average welfare due to adding the agents in Ai \u222a Aj to project k during the ith iteration is strictly larger than the average welfare due to adding the agents in Ai\nto project k in the same iteration. However, this means that in iteration i, the algorithm would have chosen the agents in Ai \u222aAj and assigned them to to project k instead of the agents in Ai, which is a contradiction. This completes the proof. ut Lemma 16. For every project k, and any given positive integer t \u2264 |Sk|, the total marginal contribution of the t highest paid agents in Sk is at least the value derived due to any set of t agents, i.e., if T denotes the set of t-highest paid agents in Sk, then\u2211\ni\u2208T pi \u2265 vk(T ).\nProof: Define l to be the smallest index such that after the lth iteration, the project k contains at least t agents, i.e., |S(l)k | < t and |S (l+1) k | \u2265 t. Then, from the monotonicity of the marginals (Lemma 15) it is not hard to see that the set T of the t highest paid agents must contain S (l) k and some arbitrary t \u2212 |S(l)k | agents from the set of agents added in lth iteration. Consider the average welfare increase obtained by adding the agents in T \\ S(l)k to project k during iteration l; this cannot be larger than p(l), the actual average welfare obtained by our greedy algorithm in that iteration, i.e.,\np(l) \u2265 vk(T )\u2212 vk(S (l) k )\n|T | \u2212 |S(l)k | .\nTherefore, the total marginal contributions of the t top agents in Sk can be bounded as follows, \u2211\ni\u2208T pi = vk(S\n(l)) k ) + (|T | \u2212 |S (l) k |)p(l) \u2265 vk(T ).\nThe first part of the above inequality comes from the fact that the total payment to the\nagents in S (l) k is exactly vk(S (l) k ). ut Lemma 17. (Doubling Lemma) Consider any project k and the set of elements assigned to k in our solution (Sk). Let T be some set of agents such that T \u2229 Sk = \u2205 and |T | > |Sk|. Then, the total payment to the agents in T \u222a Sk is at least vk(Sk \u222a T ), i.e.,\u2211\ni\u2208T\u222aSk\np\u0304i \u2265 vk(Sk \u222a T ).\nProof: We assume for convenience that both |T | and |Sk| are even. The same proof holds when one or both the sets are odd with a few minor modifications. We introduce some additional notation: recall that T> consists of the elements of T in the decreasing order of their marginal (or payment). We partition T> into two sets T1 and T2 containing the first |T | 2 + |Sk| 2 elements of T>, and the last |T |2 \u2212 |Sk| 2 elements respectively (see Figure 1). Let x be the agent in T2 who was first assigned to some project during the course of our algorithm. By definition, for every i \u2208 T1, pi \u2265 px, and by the monotonicity of the marginals, for every i \u2208 T2, pi \u2264 px.\nThe rest of the proof proceeds as follows, we first establish lower bounds on px and then use the fact that pi \u2265 px for all i \u2208 T1 to show that the payments are large enough. Suppose that agent x was assigned to some project during iteration l of our algorithm. Let Rem be the agents in Sk who were unassigned before the l th iteration, i.e., Rem = Sk \\ S(l)k . Since the\ngreedy algorithm did not choose to assign the agents in T2 \u222aRem to project k during iteration l, this means that the marginal contribution of the agents chosen in iteration l by our algorithm (p(l) = px) is at least the average welfare due to the alternative assignment that was not chosen, i.e.,\npx \u2265 vk(T2 \u222aRem | S(l)k ) |Rem|+ |T2| = vk(Sk \u222a T2)\u2212 vk(S(l)k ) |Rem|+ |T2| .\nSince |Rem| \u2264 |Sk| and |T2| = |T |2 \u2212 |Sk| 2 , we get that |Rem|+|T2| \u2264 12(|T |+|Sk|). Substituting\nthis in the above inequality, and bringing the denominator over to the other side, we obtain\n(|T |+ |Sk|)px \u2265 2(vk(Sk \u222a T2)\u2212 vk(S(l)k )). Look at the set Sk \u222a T2, the cardinality of this set is exactly 12(|T |+ |Sk|). Therefore, from our fundamental Proposition 25, we know that vk(Sk \u222a T2) \u2265 12vk(Sk \u222a T ). Therefore, we get the following final lower bound on px multiplied by |T |+ |Sk|,\n(|T |+ |Sk|)px \u2265 vk(Sk \u222a T )\u2212 2vk(S(l)k ) \u2265 vk(Sk \u222a T )\u2212 2vk(Sk).\nThe last inequality comes from the fact that S (l) k \u2286 Sk. Remember that the final payment to every agent is twice her marginal. Moreover, for every agent in T1, her initial payment is at least px. Now, we can finally prove the desired lemma,\u2211\ni\u2208Sk\u222aT p\u0304i \u2265 2 \u2211 i\u2208Sk pi + 2 \u2211 i\u2208T1 pi\n\u2265 2vk(Sk) + 2|T1|px = 2vk(Sk) + (|T |+ |Sk|)px \u2265 2vk(Sk) + vk(Sk \u222a T )\u2212 2vk(Sk) = vk(Sk \u222a T ).\nut\nFair Payments Given a payment vector p and an allocation S, we say that the payments are fair or envy-free, if for every i, j \u2208 N such that both i and j belong to project k in S, then pi = pj .\nClaim 19. For any instance where the projects have anonymous subadditive valuations, there exists a (2, 2)-core stable solution such that the payments are envy-free, i.e., all the agents assigned to a single project receive the same payment.\nProof: Once again, we run Algorithm 1 to obtain an allocation S, but the payments that we provide are defined as follows: for every agent i \u2208 Sk, her payment is now p(ef)i = 2 vk(Sk) |Sk| . From the proof of Theorem 13, the solution is still a 2-approximation to OPT . Moreover, the payments are clearly 2-budget balanced. It only remains for us to show that no group of agents T can deviate to any project k and collectively improve their utility. Instead of proving this from scratch, we piggyback on the proof of Theorem 13 and reduce our stability condition to that of the Theorem. More specifically, suppose that (p\u0304)i\u2208N denotes the payment vector used in Theorem 13. Then we show that as long as the solution (S, (p\u0304)i) is a 2-core, so is the envyfree solution (S,p(ef)). The following lemma is the basic building block that facilitates this reduction.\nLemma 26. For a given project k, and any positive integer t \u2264 |Sk|, let T denote the set of t agents in Sk with the smallest payments according to (p\u0304)i\u2208N , i.e., for any i \u2208 T , and any j \u2208 Sk \\ T , p\u0304j \u2265 p\u0304i. Then, \u2211\ni\u2208T p\u0304i \u2264 \u2211 i\u2208T p (ef) i = 2t vk(Sk) |Sk| .\nProof: Assume by contradiction that the above inequality is false, i.e., \u2211\ni\u2208T p\u0304i > 2t vk(Sk) |Sk| . Then,\nthere must exist at least one agent i \u2208 T whose payment p\u0304i is strictly larger than 2vk(Sk)|Sk| . This implies that for every agent j in Sk \\ T , her payment is also strictly larger than the above quantity. Therefore, we have\n\u2211 i\u2208Sk p\u0304i = \u2211 i\u2208T p\u0304i + \u2211 i/\u2208T p\u0304i > 2t vk(Sk) |Sk| + 2(|Sk| \u2212 t) vk(Sk) |Sk| .\nHowever, this is a contradiction since we know that \u2211\ni\u2208Sk p\u0304i = 2vk(Sk). ut Now, we are ready to show that for every project k, and every group T , \u2211 i\u2208T\u222aSk p (ef) i \u2265 vk(T \u222aSk). Without loss of generality, we can assume that from every project l only the members with the lowest payments under the solution (p\u0304)i\u2208N deviate. That is, suppose that T consists of some t members originally in project l, then we can assume that these coincide with the t members of Sl who had the lowest payments in (p\u0304)i\u2208N . Now, from Lemma 26, we know that\n\u2211 i\u2208T p (ef) i = \u2211 l\u2208P \u2211 i\u2208T\u2229Sl p (ef) i \u2265 \u2211 l\u2208P \u2211 i\u2208T\u2229Sl p\u0304i = \u2211 i\u2208T p\u0304i.\nSince \u2211 i\u2208Sk p\u0304i = \u2211 i\u2208Sk p (ef) i = 2vk(Sk), this means that \u2211 i\u2208T\u222aSk p (ef) i \u2265 \u2211 i\u2208T\u222aSk p\u0304i. How-\never, from the proof of Theorem 13, we know that \u2211\ni\u2208T\u222aSk p\u0304i \u2265 vk(T \u222aSk). This completes the proof."}, {"heading": "C Appendix: Proofs for Submodular and Fractionally Subadditive Valuations", "text": ""}, {"heading": "XoS Oracles", "text": "One of our results for this section requires access to an XoS oracle [18], which when queried with a XoS valuation vk and a set Sk returns the XoS clause a (l) k that maximizes a (l) k (Sk). In addition, we also assume the presence of a Demand Oracle for each function. For any XoS function, both of these oracles can be implemented in time polynomial in the size of the input (number agents, number of independent clauses).\nProposition 20. There exists a (1, 1)-core stable solution for every instance where the projects have XoS valuations.\nSince Submodular functions are contained in the XoS class, this result extends to Submodular valuations as well.\nProof: The proof is simple: let O = (O1, . . . , Om) be the welfare maximizing solution. We define the following procedure to award payments to each agent: for each project k, invoke the XoS oracle for vk, Ok and suppose that the returned additive clause is a (l) k . For every i \u2208 Sk, her payment is exactly p\u0304i = a (l) k . Notice that by definition of the XoS class, for every project k, and\nset T \u2286 Sk, a(l)k (T ) = \u2211\ni\u2208T p\u0304i \u2264 vk(T ). We now claim that these payments along with the allocation O form a core stable solution. Clearly the solution is budget-balanced, so we only need to show that no group of agents can deviate. Assume to the contrary, and suppose that some set T of agents can deviate to project k and collectively improve their utility. Let O\u2032 be the allocation obtained from O by the deviation of the agents in T to project k. Then, we show that the social welfare of O\u2032 must be strictly larger than the social welfare of O, which is a contradiction, i.e.,\nSW (O\u2032) = vk(Sk \u222a T ) + \u2211 l 6=k vl(O \u2032 l)\n> \u2211\ni\u2208Sk\u222aT p\u0304i + \u2211 l 6=k \u2211 i\u2208Sl\\T p\u0304i = \u2211 i\u2208N p\u0304i = SW (O \u2217).\nTheorem 21.\n1. For any instance where the projects have XoS valuations, we can compute (1 + , ee\u22121)-core stable solution using Demand and XoS oracles, and a ( ee\u22121 , e e\u22121)-core stable solution without\nthese oracles.\n2. For submodular valuations, we can compute a (1 + , ee\u22121)-core stable solution using only a Value oracle.\nProof:\n(Part 1.1) Xos Valuations with Demand, Xos Oracles\nWe begin with some additional notation. Given an allocation X, we define the \u2018XoS price\u2019 of every agent i, pi(X) as follows: suppose that i \u2208 Xk, then use the XoS oracle and obtain the maximizing additive clause a\n(l) k for Xk. Set pi(X) = a (l) k (i), i.e., the value of agent i in the\nadditive valuation that obtains the maximum value for the allocation Xk. It is not hard to see that for every project, the sum of XoS prices of the agents assigned to that project is exactly the welfare due to that project, i.e., \u2200k \u2208 P,\u2211\ni\u2208Xk\npi(X) = a (l) k (Xk) = vk(Xk).\nThe algorithm that we present is quite intuitive and based on a best response approach using the social welfare as a potential function.\n1. Initialize the input allocation A to be the ee\u22121 \u2248 1.58 approximation to OPT obtained using the Algorithm of [18]. 2. Let pi(A) denote the XoS price of every agent i for the allocation A. 3. Define the current allocation X = A, and current payments pi = pi(A) + N SW (A). 4. Perform a best-response step, i.e., allow a set T of agents to deviate to project k if we can simultaneously improve all of their payments, i.e., if vk(T |Xk) > \u2211 i\u2208T pi. 5. Update the current allocation X, and the current payments to be pi = pi(X) + N SW (X). 6. When no such deviation is possible, return the allocation S = X, and the final payments (p\u0304)i\u2208N = p.\nWe need to show the following: (i) for a given > 0, the algorithm converges after making a polynomial number of queries to the Demand and XoS oracles, (ii) the solution returned has at least the welfare of the initial allocation A, (iii) the solution is (1 + )-Core stable.\nWe begin with an easy observation: after every iteration of our algorithm, the total payment made to all the agents is at most a factor (1+ ) times the current social welfare. This is because the payment to every agent is her XoS price plus N times the current welfare; since there are a total of N agents we get that the total payments is the aggregate XoS price plus times the social welfare. Our next claim is that in every iteration, our algorithm makes at most m calls to the XoS oracle and to the Demand oracle. Observe that we require the XoS oracle only when we choose payments for the agents (invoke the XoS prices), the demand oracle is only required for identifying a best-response step in our algorithm (Step (5)). In order to find the XoS prices, it suffices if we invoke the XoS oracle once for each every project k, given the allocation Xk. Next, in order to check for a best-response step, we need to see if \u2203 k, T such that vk(T |Xk) > \u2211 i\u2208T pi. This can be done using the demand oracle for project k using the price vector p, and the reduced valuation function vk(.|Xk). Therefore, in order to determine whether there exists a best-response step, we need to call the Demand oracle at most m times, once for each project. This completes the proof of the claim.\nNow that we know that our algorithm makes at most m calls to each of the oracles in each iteration, if we can prove that our algorithm converges after a polynomial number of iterations, then the total number of queries to the oracles is also polynomially bounded. In order to show this, we first prove a more fundamental lemma that gives a lower bound on the increase in social welfare during each iteration.\nLemma 27. In every iteration, the social welfare of the current allocation increases strictly by at least a fraction N of current social welfare.\nThat is, suppose that during some iteration, the initial allocation was X1, and the allocation after the best-response was X2, then SW (X2) > SW (X1)(1 + N ).\nProof: Suppose that during this allocation, some set T of agents deviate to project k. Let the initial payments of all the agents (before the deviation) be p. We also know by definition of the best-response step that vk(T |X1k) > \u2211 i\u2208T pi. Moreover, it is not hard to see that (initially) for\nevery project l, the payments are at most the welfare due to the project plus a markup, i.e.,\u2211 i\u2208X1l pi = vl(X 1 l ) + |X1l | N SW (X1).\nOur next observation establishes a relationship between the welfare of any project l after the best-response step, and the initial set of prices. We know that for all l \u2208 P with l 6= k, X2l \u2286 X1l . Then, we show that:\nvl(X 2 l ) \u2265 \u2211 i\u2208X2l (pi \u2212 N SW (X1)).\nTo see why the above inequality is true, suppose that for a given project l 6= k, r1 and r2 are the maximizing clauses for the assignments X1l and X 2 l respectively. The above inequality follows from the fact that vl(X 2 l ) = a r2 l (X 2 l ) \u2265 ar1l (X2l ). The final term is exactly the initial XoS prices of the agents in X2l , which is pi \u2212 N SW (X1) for every agent i. Now we are in a position to show our desired result,\nSW (X2) = vk(X 2 k) + \u2211 l 6=k vl(X 2 l )\n\u2265 [ vk(X 1 k) + vk(T |X1k) ] + \u2211 l 6=k \u2211 i\u2208X2l (pi \u2212 N SW (X1))\n> vk(X 1 k) + \u2211 i\u2208T pi + \u2211 l 6=k \u2211 i\u2208X2l (pi \u2212 N SW (X1)).\nNow we can rearrange the above inequality by assigning every agent i \u2208 T to the project that i belonged to in X1, and then rewriting pi for these agents as pi\u2212 N SW (X1)+ N SW (X1). This gives us,\nSW (X2) > vk(X 1 k) + \u2211 l 6=k \u2211 i\u2208X1l (pi \u2212 N SW (X1)) + N |T |SW (X1)\n\u2265 vk(X1k) + \u2211 l 6=k vl(X 1 l ) + N SW (X1)\n= SW (X1) + N SW (X1).\nThis completes the proof of the lemma. ut Now, we can use the above lemma to prove the main theorem. We begin by showing that our algorithm converges after a polynomial number of iterations. Clearly, the social welfare of the current allocation is non-decreasing throughout our algorithm, and therefore bounded from\nbelow by SW (A). This means that in every iteration, the increase in welfare is strictly larger than N SW (A). But we also know that e e\u22121SW (A) \u2265 SW (OPT ). Therefore, we can bound the number of iterations of our algorithm by the total possible increase in welfare divided by the increase in welfare in each iteration,\nSW (OPT )\u2212 SW (A) N SW (A) \u2264 N (e\u2212 1) .\nTherefore, our algorithm converges after a polynomial number of calls to the Demand and XoS Oracles. The final welfare, as per Lemma 27 is at least the initial welfare, i.e., SW (A). Core stability follows by definition of the best-response phase because if there existed a set T , and a project k, such that vk(T |Sk) > \u2211 i\u2208T p\u0304i, then our algorithm would not have terminated.\nTogether with the fact that \u2211 i\u2208Sk p\u0304i \u2265 vk(Sk), we get that \u2211\ni\u2208T\u222aSk p\u0304i \u2265 vk(T |Sk) + vk(Sk) = vk(T \u222a Sk), as desired. Finally, the payments are (1 + )-budget balanced:\u2211\ni\u2208N p\u0304i = \u2211 k\u2208P (vk(Sk) + |Sk| N SW (S)) = SW (S) + SW (S)\n(Part 1.2) XoS Valuations without the Oracles\nWe actually show a much stronger result here, namely that given a \u03b1-approximation to the LP optimum, we can obtain a (\u03b1, \u03b1)-Core stable solution. Plugging in \u03b1 = ee\u22121 for fractionally subadditive functions, we get the desired result. Note that a (\u03b1, \u03b1)-core result is strictly better than our (2\u03b1, 2\u03b1) result for general subadditive functions.\nWe only sketch the key features of this proof since the approach is very similar to our algorithm for general subadditive functions as described in Theorem 2. Suppose that the input allocation is A, and the optimum dual prices are p\u2217, z\u2217 as usual. Given any allocation X, define margi(X) to be agent i\u2019s marginal contribution to her project, i.e., suppose that agent i \u2208 Xk, then define margi(X) = vk(Xk) \u2212 vk(Xk \u2212 {i}). Now, our algorithm for this theorem involves the following adaptation of the Greedy Matching procedure described in the proof of Theorem 2. Recall that for any allocation X, \u03b6(X) gives the set of empty projects under that allocation.\n1. Let the current allocation X be initialized to A. 2. Allow a single agent i to deviate to some empty project k \u2208 \u03b6(X) as long as this leads to a\nstrict increase in social welfare, i.e, vk(i) > margi(X). 3. Update the current allocation X and repeat Step (2) until no agent wants to deviate. 4. Output S to be the (final) current allocation.\nClearly, it is not hard to see that the welfare of the final allocation is not smaller than the welfare of the initial allocation A. Moreover, the above algorithm must converge in time Poly(N,m). The crux of the proof lies in the following slightly intricate payment scheme,\n\u2022 Define for every project k, high value users (SHk ) and low value users (SLk ) as follows, SHk = {i \u2208 Sk|margi(S) > p\u2217i } , SLk = Sk \\ SHk .\n\u2022 Define for every project k, the residual slack zk as follows, zk = \u2211 i\u2208SHk p\u2217i + z \u2217 k \u2212 \u2211 i\u2208SHk margi(S).\n\u2022 For every project k, and every low value agent i \u2208 Sk, let her final payment be p\u0304i = p\u2217i . \u2022 For every project k, and every high value agent i \u2208 Sk, let her final payment be p\u0304i = margi(S) +\nzk |SHk | .\nThe following is the crucial lemma that helps us show core stability.\nLemma 28. For every agent i, her payment is at least her marginal value. Moreover, the total payment to the members of any project k is exactly \u2211 i\u2208Sk p \u2217 i + z \u2217 k.\nProof: Let us begin with the first part of the lemma, this is clearly true for low value agents by definition. Therefore, we only need to focus on the high value agents. Since every high value agent\u2019s payment is her marginal value plus some fraction of the residual slack, it is enough if we show that for every project k, the residual slack is positive. We use the following property of XoS functions: given assignment Sk, let l be the clause that maximizes a (l) k (Sk), then, margi(S) = vk(Sk)\u2212 vk(Sk\u2212{i}) \u2264 a(l)k (Sk)\u2212 a (l) k (Sk\u2212{i}) = a (l) k (i). Now we can prove the first part of the lemma,\nzk = \u2211 i\u2208SHk p\u2217i + z \u2217 k \u2212 \u2211 i\u2208SHk margi(S)\n\u2265 vk(SHk )\u2212 \u2211 i\u2208SHk a (l) k (i) \u2265 vk(SHk )\u2212 vk(SHk ) = 0.\nThis completes the first part of the lemma. The second part follows from definition of the payments. ut\nNow the rest of the proof follows in the same fashion as that of Theorem 2. Clearly, the final payments are exactly equal to the value of the Dual Optimum which is a factor \u03b1 larger than the welfare of the current solution. In order to show that no group of agents T can deviate to any project for subadditive valuations (remember that XoS is a sub-class of subadditive valuations), it is enough to show the following (See proof of Theorem 2) (i) every agent i\u2019s payment is at least p\u2217i , (ii) for every project k, the total payment of the members of that project is at least \u2211 i\u2208Sk p \u2217 i + z \u2217 k, (iii) if k is an empty project, then for any agent i, p\u0304i \u2265 vk(i). (i) and (ii) guarantee that any deviation to a non-empty project k will not occur due to dual feasibility, and (iii) together with subadditivity guarantees that no set benefits from deviating to an empty project. The first two requirements follow immediately from the definition of the payments and the above Lemma. For the third requirement, observe that at the end of the payment algorithm defined above, margi(S) \u2265 vk(i) for k \u2208 \u03b6(S). Therefore, as per Lemma 28, p\u0304i \u2265 margi(S) \u2265 vk(i). This completes the proof.\n(Part 2) Submodular Functions with only Value Queries\nThe algorithm is exactly the same as in the proof for XoS functions in Part 1.1; recall that submodular functions are a strict sub-class of XoS functions. The key difference here is that we can eliminate the dependence on both Demand and XoS oracles using the nice properties of Submodular functions. First, note that we use the XoS oracle to find the corresponding additive\nclause for a given valuation function vk(Sk). It is known that one can implement XoS queries in polynomial time for Submodular functions using a simple Greedy Approach as in Claim 1.\nMore specifically, given a submodular function vk, and a corresponding set Sk, the goal of an XoS oracle query is to obtain an additive function a such that vk(Sk) = a(Sk) and for all T \u2286 Sk, vk(T ) \u2265 a(T ). It is not hard to see that this gives us the XoS clause which is maximum at Sk without loss of generality. For submodular functions, we can compute the XoS prices as follows: (i) order the elements of Sk in some arbitrary order, (ii) add the elements of Sk to vk(\u2205) one after the other in the predetermined order, (iii) agent i\u2019s XoS price is the marginal cost of adding her to the set, i.e., if Ai is the set of elements before i in the predetermined order, then agent i\u2019s XoS price is vk(Ai \u222a {i}) \u2212 vk(Ai). These prices give us the additive function a, as desired.\nNow, we move on to Demand Oracles whose main purpose is to identify in every iteration, a project k, and a set T such that vk(T |Xk) > \u2211 i\u2208T pi, where Xk is the set of agents currently assigned to that project. For submodular functions, instead of looking at group deviations to a project, it suffices if we look at individual deviations. More specifically, our claim is the following: if \u2203T satisfying vk(T |Xk) > \u2211 i\u2208T pi, then there exists at least one agent i \u2208 T satisfying vk(Xk \u222a {i})\u2212 vk(Xk) > pi. This follows almost directly from submodularity,\u2211 i\u2208T pi < vk(T |Xk) < \u2211 i\u2208T vk(Xk \u222a {i})\u2212 vk(Xk).\nTherefore, our claim must be true for at least one such agent. The claim has the following implication: the best-response algorithm for Submodular functions can be obtained from the B-R algorithm for XoS valuations in Part 1.1 by changing step (4) to \u201callow a single i to deviate to project k as long as vk(Xk \u222a {i}) \u2212 vk(Xk) > pi\u201d. Whether or not such a deviation exists can be found using O(Nm) value queries. Finally, we remark that a ee\u22121 -approximation to OPT that we use as an input to the algorithm can be computed for submodular functions using only Value Queries [45].\nThe rest of the proof follows."}, {"heading": "D Appendix: Proofs from Section 4", "text": "Theorem 23. Every Core stable solution for a given instance of our utility sharing game can be transformed into a Pure Nash Equilibrium (with weak no-overbidding) of the corresponding \u2018flipped\u2019 simultaneous second price auction, and vice-versa.\nProof: Suppose that we are given an instance (N ,P, (v)k\u2208P) of our combinatorial utility sharing game along with a core stable solution (S, (p\u0304)i\u2208N ). We construct a bid profile b = (b1, . . . , bm) for the flipped combinatorial auction that in combination with the allocation S, and the corresponding second-price payments constitutes a Pure Nash equilibrium with no weak-overbidding. Our construction is simple, for every buyer k \u2208 P, and item i \u2208 N : bk(i) = p\u0304i if i \u2208 Sk and bk(i) = 0 otherwise. Notice that for every item, only one buyer (the winning buyer) has a positive bid, therefore, the corresponding auction mechanism will output S as the winning allocation along with zero payments. Therefore, every every buyer k\u2019s utility is exactly vk(Sk).\nIn order to show that this is a pure Nash equilibrium, it is enough to prove for a fixed buyer k, and for any alternative bid vector b\u2032k, buyer k\u2019s utility cannot strictly improve at her new bid\nwhen all the other buyers bid according to the constructed profile. Suppose that at the new bid vector, player k wins the set S\u2032k of items and define T = S \u2032 k \\ Sk. Then, for every item i \u2208 T , buyer k has to pay exactly p\u0304i (the bid of the second highest bidder) in the new auction solution. Therefore, player k\u2019s new utility is\nuk(b \u2032 k, b\u2212k) = vk(S \u2032 k)\u2212 \u2211 i\u2208T p\u0304i \u2264 vk(Sk \u222a T )\u2212 \u2211 i\u2208T p\u0304i.\nNow upon applying the core stability requirement for the empty set, we get vk(Sk) \u2264\u2211 i\u2208Sk p\u0304i. This condition must be true for every project l \u2208 P. Moreover, this condition in com-\nbination with budget-balance indicates that for project k (and every other project), vk(Sk) =\u2211 i\u2208Sk p\u0304i. Now, we can bound the player\u2019s new utility using core-stability as\nvk(Sk \u222a T )\u2212 \u2211 i\u2208T p\u0304i \u2264 \u2211 i\u2208Sk p\u0304i = vk(Sk).\nThe last quantity is player k\u2019s original utility, and therefore this deviation cannot strictly benefit the player. Notice that this also implies the no weak-overbidding condition.\nNow, for the other direction, suppose that we are given a winning allocation S along with a bid profile b that together forms a Nash Equilibrium (the second-price payments P are implicit in the bid). Construct the following payment vector: for every item i \u2208 N , pi = maxk\u2208P bk(i), i.e., the highest bid for that item. Consider any player k, and a set of items T outside of her current allocation. In order to win these items as well as the items she received in S, player k must bid at least pi + for every i \u2208 T without changing her bids for the items in Sk. Let b\u2032k be the modified bid vector reflecting these increased bids for the items in T . However, since this is a Nash equilibrium, the utility of the player under the modified bid vector cannot be larger than her original utility, i.e.,\nuk(b \u2032 k, b\u2212k) = vk(Sk \u222a T )\u2212 P (Sk)\u2212 \u2211 i\u2208T pi\n\u2264 uk(b) = vk(Sk)\u2212 P (Sk).\nTherefore, we have for every buyer k, and every set of items T , vk(Sk\u222aT )\u2212 \u2211\ni\u2208T pi \u2264 vk(Sk). Due to the weak no-overbidding assumption, we know that for each k, \u2211 i\u2208Sk pi \u2264 vk(Sk). We now set\nthe final payments p\u0304i by increasing the payments pi arbitrarily for each k until \u2211\ni\u2208Sk p\u0304i = vk(Sk). These payments are clearly budget-balanced. Moreover, since we only increased the payments, we still have that for every buyer k, and every set of items T , vk(Sk\u222aT )\u2212vk(Sk) \u2264 \u2211 i\u2208T p\u0304i. From this inequality, it is easy to see that the solution S along with the payments (p\u0304)i\u2208N constitutes a core-stable solution. This solution retains the welfare of the original Nash equilibrium.\nInstance where every Nash Equilibrium requires a large amount of overbidding\nThe example that we use here is the same as the instance for Part (2) of Claim 12. Consider an auction with just two buyers having the following anonymous subadditive valuations: v1(S) = N 2 for S 6= N , v1(N ) = N ; and v2(S) = \u221a N \u2200S \u2286 N . We show that in any Pure Nash\nEquilibrium (b1, b2) and S, at least one buyer has to over-bid by a factor O( \u221a N). First, consider\nany Nash equilibrium where buyer 1 wins all of the items. Then, it is not hard to see that b1(i) \u2265 \u221a N for every i \u2208 N or else buyer 2 can bid for i (b\u20322(i) = \u221a N), win the item and\nstrictly improve her utility. Therefore, we have b1(N ) \u2265 \u221a N \u00d7N = \u221a Nv1(N ), which gives us the amount by which buyer 1 overbids.\nNext, suppose that in a Nash Equilibrium of this auction, buyer 2 receives some (S2) but not all the items. Then, buyer 1\u2019s utility is v1(S1)\u2212 b2(S1) = N2 \u2212 b2(S1). Now what if buyer 1 modifies her bids in order to win all the items in N and pays b2(N ) for the same? Such a deviation cannot improve her utility, i.e., N \u2212 b2(N ) \u2264 N2 \u2212 b2(S1). Simplifying this, we get b2(S2) \u2265 N2 . Since v2(S2) = \u221a N , we get that the amount of over-bidding by buyer 2 is N\n2 \u221a N = \u221a N 2 . It is not\nhard to see that this must be the case even when buyer 2 wins all of the items in N .\nClaim 24. Given a Second Price Simultaneous Combinatorial Auction with Item Bidding, we can compute\n1. A 2-approximate Nash Equilibrium that extracts half the optimal social welfare as long as the buyers have anonymous subadditive valuations. 2. A 1 + -approximate Nash equilibrium that is a ee\u22121 -approximation to the optimum welfare when the buyers have submodular valuations.\nThe first solution involves 4-conservative bids, and the second solution involves (1 + )- conservative bids.\nProof: (Proof of Statement 1) Once again, we turn to our greedy algorithm (Algorithm 1). Consider the solution S returned by our greedy algorithm and envy-free payments (p(ef))i\u2208N as per Claim 19. Convert the payments into a bid profile b using the transformation mechanism described in the proof of Theorem 23. Clearly, the solution has the some social welfare as the original allocation, so we only need to prove stability and quantify the level of over-bidding. As with the proof of Theorem 23, suppose that some buyer k changes his bids so that his new winning set is S\u2032k and T = S \u2032 k \\ Sk. Then we have that the player\u2019s new utility is at most\nvk(Sk \u222a T )\u2212 \u2211 i\u2208T p\u0304i \u2264 \u2211 i\u2208Sk p\u0304i = 2vk(Sk)\nTherefore, the player\u2019s new utility is at most twice her original utility, and therefore, the solution is a 2-approximate Nash Equilibrium. Now, it only remains for us to prove that the bid vector is 4-conservative for every buyer k.\nConsider some k \u2208 P, it suffices to show that \u2211i\u2208T bk(i) \u2264 4vk(T ) holds only for the case when T is subset of Sk. This is because the player\u2019s bid is zero for every item outside of her winning set. Suppose that |T | = t, and let r be a non-negative integer satisfying, 2rt \u2264 |Sk| \u2264 2r+1t. We know that player k\u2019s bid for every item in Sk is exactly\n2vk(SK) |Sk| . Abusing notation,\nwe denote by vk(2 rt) the value of any set of size 2rt. Now, from a repeated application of the Fundamental Proposition for Anonymous Functions (Proposition 25), we get\nvk(T ) \u2265 vk(2\nrt)\n2r .\nNow we are ready for the final leg of our proof.\u2211 i\u2208T bk(i) = 2vk(Sk) |Sk| t\n\u2264 2vk(Sk)t 2rt = 2 vk(Sk) 2r \u2264 22vk(2 rt)\n2r (From Proposition 25)\n\u2264 4vk(T )2 r\n2r = 4vk(T )\n(Proof of Statement 2) One could be tempted to claim that the Algorithm in Theorem 21 yields a 1 + -approximate equilibrium (even for XoS valuations), and indeed it does. Unfortunately, in the final payments, every agent is provided her XoS clause price along with an additive mark-up of SW (S). Therefore, the level of multiplicative over-bidding (as measured by \u03b3-conservativeness) for this solution could be quite large. However, we only need to make a few high-level modifications to the Algorithm for Submodular valuations in Theorem 21 that will allow us to improve the conservativeness while retaining the approximation factor.\nThe key step in this modified algorithm is how we price items (using the XoS prices) in Step (5) of the algorithm. In particular, the property that we require from the pricing mechanism is the following: after any best-response move that leads to a strict improvement of the social welfare, the price of any given item cannot decrease. A simple pricing mechanism for Submodular functions that achieves this property was described in [17], the reader is asked for refer to Claim 2.5 of that paper for the exact construction. At a high level, the pricing mechanism works as follows: in every iteration, every buyer maintains an ordering on the item set, which is dynamically updated. Suppose that for a given item i assigned to buyer k at some instance, Ai denotes the set of items before i in buyer k\u2019s ordering. Then, the price of item i is exactly vk({i} |Ai).\nWe simply use the above mechanism as a black-box here. Now, we are in a position to describe our modified algorithm: in every round we maintain a single price (or payment) for each item. At the end, we derive bids for the players using the same idea as in Theorem 23.\n1. Initialize the input allocation A to be the ee\u22121 \u2248 1.58 approximation to OPT obtained using the Algorithm of [45]. 2. Let pi(A) denote the Submodular price of every item i for the allocation A obtained using the mechanism of [17]. 3. Define the current allocation X = A, and current payment pi = pi(A)(1 + ). 4. Perform a best-response step, i.e., allow an item i to deviate to project k as long as vk(i|Xk) > pi. 5. Update the current allocation X, and let pi(X) be the current submodular prices obtained using the mechanism of [17]. Then, every agent i\u2019s payment is pi = pi(X)(1 + ). 6. When no such deviation is possible, return the allocation S = X, and the final payments (p\u0304)i\u2208N = p.\nWe first argue for core-stability before showing the properties of the approximate Nash equilibrium. Clearly, the solution returned is (approximately) core-stable, and has a social welfare that is at least a ee\u22121 -approx to OPT (since the best-response is welfare increasing). We now\nshow bounds on the running time. Notice that in every round, the price of at least one item is increasing by a multiplicative factor of 1 + , i.e., i deviates to project k because vk(i|Xk) > pi, then her price becomes vk(i|Xk)(1 + ).\nGiven this, it is not hard to see that the algorithm proceeds for at most O(Nlog(1+ )( vmax \u2206 )) since no agent\u2019s price can be strictly larger than vmax by definition. We need not worry about agents whose initial payment is zero; either their final payment is still zero or their payment (during some iteration) increases up to \u2206, and then multplicatively increases in each subsequent round where it deviates. Moreover, since log(1+ )( vmax \u2206 ) = O( 1 log( vmax \u2206 )), we get the desired run time. Now, let use the black-box mechanism of Theorem 21 to convert payments to bids. We first show that the solution is a (1+ )-approximate Nash equilibrium. Observe that for every project k, \u2211 i\u2208Sk bk(i) = \u2211\ni\u2208Sk p\u0304i = (1 + )vk(Sk). Now suppose that buyer k modifies her bid, receives an additional set T of items, then her new utility is\nvk(Sk \u222a T )\u2212 \u2211 i\u2208T p\u0304i \u2264 \u2211 i\u2208Sk p\u0304i = (1 + )vk(Sk),\nwhere vk(Sk) is her old utility. Therefore, the solution is a (1 + )-approximate equilibrium. Next, we prove that the bids are (1+ )-conservative. Recall that (as per the pricing mechanism) for every project k, there exists an ordering of agents (Ok) so that each agent\u2019s (final) price is (1 + )-times her marginal price when adding agents according to that order. In order to show that the bids are conservative, consider any set T \u2286 Sk. We argue that\u2211\ni\u2208T bk(i) = \u2211 i\u2208T p\u0304i \u2264 (1 + )vk(T ).\nIndeed, consider the item i in T who appears first in Ok. Clearly its payment is at most vk(i) by submodularity (since it may not be the first item in Ok). This argument can be repeated for every agent recursively. Therefore, in the solution that we obtain, the Nash Equilibrium has (1 + )-conservative bids."}], "references": [{"title": "Approximate equilibrium and incentivizing social coordination", "author": ["Elliot Anshelevich", "Shreyas Sekar"], "venue": "In Proceedings of the Twenty-Eighth AAAI Conference on Artificial Intelligence, July", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2014}, {"title": "Dynamics of profit-sharing games", "author": ["John Augustine", "Ning Chen", "Edith Elkind", "Angelo Fanelli", "Nick Gravin", "Dmitry Shiryaev"], "venue": "Internet Mathematics,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2015}, {"title": "The bargaining set for cooperative games", "author": ["Robert J Aumann", "Michael Maschler"], "venue": "Advances in game theory,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 1964}, {"title": "The cost of stability in coalitional games", "author": ["Yoram Bachrach", "Edith Elkind", "Reshef Meir", "Dmitrii V. Pasechnik", "Michael Zuckerman", "J\u00f6rg Rothe", "Jeffrey S. Rosenschein"], "venue": "In Algorithmic Game Theory, Second International Symposium,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2009}, {"title": "Computing cooperative solution concepts in coalitional skill games", "author": ["Yoram Bachrach", "David C. Parkes", "Jeffrey S. Rosenschein"], "venue": "Artif. Intell.,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2013}, {"title": "Improved equilibria via public service advertising", "author": ["Maria-Florina Balcan", "Avrim Blum", "Yishay Mansour"], "venue": "In Proceedings of the Twentieth Annual ACM-SIAM Symposium on Discrete Algorithms,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2009}, {"title": "Core extensions for non-balanced tu-games", "author": ["Camelia Bejan", "Juan Camilo G\u00f3mez"], "venue": "Int. J. Game Theory,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2009}, {"title": "Approximating pure nash equilibrium in cut, party affiliation, and satisfiability games", "author": ["Anand Bhalgat", "Tanmoy Chakraborty", "Sanjeev Khanna"], "venue": "In Proceedings 11th ACM Conference on Electronic Commerce (EC-2010),", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2010}, {"title": "Welfare guarantees for combinatorial auctions with item bidding", "author": ["Kshipra Bhawalkar", "Tim Roughgarden"], "venue": "In Proceedings of the Twenty-Second Annual ACM-SIAM Symposium on Discrete Algorithms,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2011}, {"title": "Coalition games on interaction graphs: A horticultural perspective", "author": ["Nicolas Bousquet", "Zhentao Li", "Adrian Vetta"], "venue": "In Proceedings of the Sixteenth ACM Conference on Economics and Computation, EC", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2015}, {"title": "Coalitional affinity games and the stability gap", "author": ["Simina Br\u00e2nzei", "Kate Larson"], "venue": "IJCAI", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2009}, {"title": "Cooperative games with overlapping coalitions", "author": ["Georgios Chalkiadakis", "Edith Elkind", "Evangelos Markakis", "Maria Polukarov", "Nick R. Jennings"], "venue": "J. Artif. Intell. Res. (JAIR),", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2010}, {"title": "On discrete preferences and coordination", "author": ["Flavio Chierichetti", "Jon M. Kleinberg", "Sigal Oren"], "venue": "In ACM Conference on Electronic Commerce, EC \u201913,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2013}, {"title": "Bayesian combinatorial auctions. In Automata, Languages and Programming, 35th International Colloquium, ICALP 2008, Reykjavik, Iceland", "author": ["George Christodoulou", "Annam\u00e1ria Kov\u00e1cs", "Michael Schapira"], "venue": "July 7-11,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2008}, {"title": "Algorithmic aspects of the core of combinatorial optimization games", "author": ["Xiaotie Deng", "Toshihide Ibaraki", "Hiroshi Nagamochi"], "venue": "Mathematics of Operations Research,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 1999}, {"title": "Strategyproof cost-sharing mechanisms for set cover and facility location games", "author": ["Nikhil R. Devanur", "Milena Mihail", "Vijay V. Vazirani"], "venue": "Decision Support Systems,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2005}, {"title": "On the complexity of computing an equilibrium in combinatorial auctions", "author": ["Shahar Dobzinski", "Hu Fu", "Robert D. Kleinberg"], "venue": "In Proceedings of the Twenty-Sixth Annual ACM-SIAM Symposium on Discrete Algorithms,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2015}, {"title": "Approximation algorithms for combinatorial auctions with complement-free", "author": ["Shahar Dobzinski", "Noam Nisan", "Michael Schapira"], "venue": "bidders. Math. Oper. Res.,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2010}, {"title": "Core stability of vertex cover games", "author": ["Qizhi Fang", "Liang Kong", "Jia Zhao"], "venue": "Internet Mathematics,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2008}, {"title": "On maximizing welfare when utility functions are subadditive", "author": ["Uriel Feige"], "venue": "SIAM J. Comput.,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2009}, {"title": "A unified framework for strong price of anarchy in clustering games. In Automata, Languages, and Programming - 42nd International Colloquium, ICALP 2015, Kyoto, Japan", "author": ["Michal Feldman", "Ophir Friedler"], "venue": "July 6-10,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2015}, {"title": "Simultaneous auctions are (almost) efficient", "author": ["Michal Feldman", "Hu Fu", "Nick Gravin", "Brendan Lucier"], "venue": "In Symposium on Theory of Computing Conference,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2013}, {"title": "Hedonic clustering games", "author": ["Moran Feldman", "Liane Lewin-Eytan", "Joseph Naor"], "venue": "In 24th ACM Symposium on Parallelism in Algorithms and Architectures, SPAA \u201912,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2012}, {"title": "Conditional equilibrium outcomes via ascending price processes with applications to combinatorial auctions with item bidding", "author": ["Hu Fu", "Robert Kleinberg", "Ron Lavi"], "venue": "In ACM Conference on Electronic Commerce, EC \u201912,", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2012}, {"title": "Black-box reductions for cost-sharing mechanism design", "author": ["Konstantinos Georgiou", "Chaitanya Swamy"], "venue": "Games and Economic Behavior,", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2013}, {"title": "Cooperative facility location games", "author": ["Michel X Goemans", "Martin Skutella"], "venue": "Journal of Algorithms,", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2004}, {"title": "On the complexity of the core over coalition structures", "author": ["Gianluigi Greco", "Enrico Malizia", "Luigi Palopoli", "Francesco Scarcello"], "venue": "IJCAI", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2011}, {"title": "Strategic cooperation in cost sharing games", "author": ["Martin Hoefer"], "venue": "Int. J. Game Theory,", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 2013}, {"title": "Limitations of cross-monotonic cost-sharing schemes", "author": ["Nicole Immorlica", "Mohammad Mahdian", "Vahab S. Mirrokni"], "venue": "ACM Transactions on Algorithms,", "citeRegEx": "29", "shortCiteRegEx": "29", "year": 2008}, {"title": "Mechanisms for (mis)allocating scientific credit", "author": ["Jon M. Kleinberg", "Sigal Oren"], "venue": "In Proceedings of the 43rd ACM Symposium on Theory of Computing,", "citeRegEx": "30", "shortCiteRegEx": "30", "year": 2011}, {"title": "Combinatorial auctions with decreasing marginal utilities", "author": ["Benny Lehmann", "Daniel J. Lehmann", "Noam Nisan"], "venue": "Games and Economic Behavior,", "citeRegEx": "31", "shortCiteRegEx": "31", "year": 2006}, {"title": "Bitcoin mining pools: A cooperative game theoretic analysis", "author": ["Yoad Lewenberg", "Yoram Bachrach", "Yonatan Sompolinsky", "Aviv Zohar", "Jeffrey S. Rosenschein"], "venue": "In Proceedings of the 2015 International Conference on Autonomous Agents and Multiagent Systems,", "citeRegEx": "32", "shortCiteRegEx": "32", "year": 2015}, {"title": "Price of anarchy for greedy auctions", "author": ["Brendan Lucier", "Allan Borodin"], "venue": "In Proceedings of the Twenty-First Annual ACM-SIAM Symposium on Discrete Algorithms,", "citeRegEx": "33", "shortCiteRegEx": "33", "year": 2010}, {"title": "On the core of the multicommodity flow game", "author": ["Evangelos Markakis", "Amin Saberi"], "venue": "Decision support systems,", "citeRegEx": "34", "shortCiteRegEx": "34", "year": 2005}, {"title": "Minimal subsidies in expense sharing games", "author": ["Reshef Meir", "Yoram Bachrach", "Jeffrey S. Rosenschein"], "venue": "In Algorithmic Game Theory - Third International Symposium,", "citeRegEx": "35", "shortCiteRegEx": "35", "year": 2010}, {"title": "Incremental cost sharing: Characterization by coalition strategy-proofness", "author": ["Herv\u00e9 Moulin"], "venue": "Social Choice and Welfare,", "citeRegEx": "36", "shortCiteRegEx": "36", "year": 1999}, {"title": "Strategyproof sharing of submodular costs: budget balance versus efficiency", "author": ["Herv\u00e9 Moulin", "Scott Shenker"], "venue": "Economic Theory,", "citeRegEx": "37", "shortCiteRegEx": "37", "year": 2001}, {"title": "Graphs and cooperation in games", "author": ["Roger B Myerson"], "venue": "Mathematics of operations research,", "citeRegEx": "38", "shortCiteRegEx": "38", "year": 1977}, {"title": "Quantifying inefficiency in cost-sharing mechanisms", "author": ["Tim Roughgarden", "Mukund Sundararajan"], "venue": "J. ACM,", "citeRegEx": "39", "shortCiteRegEx": "39", "year": 2009}, {"title": "Coalitional game theory for communication networks", "author": ["Walid Saad", "Zhu Han", "M\u00e9rouane Debbah", "Are Hj\u00f8rungnes", "Tamer Ba\u015far"], "venue": "Signal Processing Magazine, IEEE,", "citeRegEx": "40", "shortCiteRegEx": "40", "year": 2009}, {"title": "The nucleolus of a characteristic function game", "author": ["David Schmeidler"], "venue": "SIAM Journal on applied mathematics,", "citeRegEx": "41", "shortCiteRegEx": "41", "year": 1969}, {"title": "Approximating the least core value and least core of cooperative games with supermodular costs", "author": ["Andreas S. Schulz", "Nelson A. Uhan"], "venue": "Discrete Optimization,", "citeRegEx": "42", "shortCiteRegEx": "42", "year": 2013}, {"title": "Quasi-cores in a monetary economy with nonconvex preferences", "author": ["Lloyd S Shapley", "Martin Shubik"], "venue": "Econometrica: Journal of the Econometric Society,", "citeRegEx": "43", "shortCiteRegEx": "43", "year": 1966}, {"title": "Submodularity in combinatorial optimization", "author": ["Jan Vondr\u00e1k"], "venue": "PhD thesis, Citeseer,", "citeRegEx": "44", "shortCiteRegEx": "44", "year": 2007}], "referenceMentions": [{"referenceID": 6, "context": "Cooperative Coalition Formation The question of how a group of agents should divide the value they generate has inspired an extensive body of research spanning many fields [7, 28, 32, 38, 40].", "startOffset": 172, "endOffset": 191}, {"referenceID": 27, "context": "Cooperative Coalition Formation The question of how a group of agents should divide the value they generate has inspired an extensive body of research spanning many fields [7, 28, 32, 38, 40].", "startOffset": 172, "endOffset": 191}, {"referenceID": 31, "context": "Cooperative Coalition Formation The question of how a group of agents should divide the value they generate has inspired an extensive body of research spanning many fields [7, 28, 32, 38, 40].", "startOffset": 172, "endOffset": 191}, {"referenceID": 37, "context": "Cooperative Coalition Formation The question of how a group of agents should divide the value they generate has inspired an extensive body of research spanning many fields [7, 28, 32, 38, 40].", "startOffset": 172, "endOffset": 191}, {"referenceID": 39, "context": "Cooperative Coalition Formation The question of how a group of agents should divide the value they generate has inspired an extensive body of research spanning many fields [7, 28, 32, 38, 40].", "startOffset": 172, "endOffset": 191}, {"referenceID": 4, "context": "Core is well understood, implicit in the papers that study this notion is the underlying belief that there are infinite copies of one single project [5,12], which is often not realistic.", "startOffset": 149, "endOffset": 155}, {"referenceID": 11, "context": "Core is well understood, implicit in the papers that study this notion is the underlying belief that there are infinite copies of one single project [5,12], which is often not realistic.", "startOffset": 149, "endOffset": 155}, {"referenceID": 0, "context": "Indeed, models featuring selfish agents choosing from a finite set of distinct strategies are the norm in many real-life phenomena: social or technological coordination [1, 2], opinion formation [13, 21], and party affiliation [6, 8] to name a few.", "startOffset": 169, "endOffset": 175}, {"referenceID": 1, "context": "Indeed, models featuring selfish agents choosing from a finite set of distinct strategies are the norm in many real-life phenomena: social or technological coordination [1, 2], opinion formation [13, 21], and party affiliation [6, 8] to name a few.", "startOffset": 169, "endOffset": 175}, {"referenceID": 12, "context": "Indeed, models featuring selfish agents choosing from a finite set of distinct strategies are the norm in many real-life phenomena: social or technological coordination [1, 2], opinion formation [13, 21], and party affiliation [6, 8] to name a few.", "startOffset": 195, "endOffset": 203}, {"referenceID": 20, "context": "Indeed, models featuring selfish agents choosing from a finite set of distinct strategies are the norm in many real-life phenomena: social or technological coordination [1, 2], opinion formation [13, 21], and party affiliation [6, 8] to name a few.", "startOffset": 195, "endOffset": 203}, {"referenceID": 5, "context": "Indeed, models featuring selfish agents choosing from a finite set of distinct strategies are the norm in many real-life phenomena: social or technological coordination [1, 2], opinion formation [13, 21], and party affiliation [6, 8] to name a few.", "startOffset": 227, "endOffset": 233}, {"referenceID": 7, "context": "Indeed, models featuring selfish agents choosing from a finite set of distinct strategies are the norm in many real-life phenomena: social or technological coordination [1, 2], opinion formation [13, 21], and party affiliation [6, 8] to name a few.", "startOffset": 227, "endOffset": 233}, {"referenceID": 9, "context": "For example, in the classic setting with a single valuation v(S), the welfare maximization problem is often trivial (complete partition when v is subadditive), and the stabilizing core payments are exactly the dual variables to the allocation LP [10].", "startOffset": 246, "endOffset": 250}, {"referenceID": 37, "context": "One could also take the Myersonian view [38] that \u2018communication is required for negotiation\u2019 and imagine that all the agents choosing project k (Sk \u222a T ) together collaborate to improve their payments.", "startOffset": 40, "endOffset": 44}, {"referenceID": 28, "context": "Specifically, as is standard in cost-sharing literature [29,39], we consider relaxing one of the two requirements for core stability while retaining the other one.", "startOffset": 56, "endOffset": 63}, {"referenceID": 38, "context": "Specifically, as is standard in cost-sharing literature [29,39], we consider relaxing one of the two requirements for core stability while retaining the other one.", "startOffset": 56, "endOffset": 63}, {"referenceID": 9, "context": "In the identical projects literature, the solution having the smallest value of \u03b1 is known as the Multiplicative Least-Core [10].", "startOffset": 124, "endOffset": 128}, {"referenceID": 6, "context": "This generalization offers a natural interpretation: the central authority can subsidize the agents to ensure high welfare, as is often needed in other settings such as public projects or academic funding [7].", "startOffset": 205, "endOffset": 208}, {"referenceID": 3, "context": "In the literature, this parameter \u03b2 has been referred to as the Cost of Stability [4,35].", "startOffset": 82, "endOffset": 88}, {"referenceID": 34, "context": "In the literature, this parameter \u03b2 has been referred to as the Cost of Stability [4,35].", "startOffset": 82, "endOffset": 88}, {"referenceID": 19, "context": "In particular, for general subadditive valuations, one can use the 2-approximation algorithm of Feige [20] and obtain a (4, 4)-Core.", "startOffset": 102, "endOffset": 106}, {"referenceID": 17, "context": "As is standard in the literature [18], we assume that our subadditive functions are specified in terms of a demand oracle (see Section 2 for more details).", "startOffset": 33, "endOffset": 37}, {"referenceID": 19, "context": "Valuation Function Class Our Results: (\u03b1, c)-Core Lower Bound for c Subadditive (4, 4) 2 [20] Anonymous Subadditive (2, 2) 2 [20] Fractionally Subadditive (XoS) (1 + , e e\u22121 ) e e\u22121 [18] Submodular (1 + , e e\u22121 ) and (1, 2) e e\u22121 [45]", "startOffset": 89, "endOffset": 93}, {"referenceID": 19, "context": "Valuation Function Class Our Results: (\u03b1, c)-Core Lower Bound for c Subadditive (4, 4) 2 [20] Anonymous Subadditive (2, 2) 2 [20] Fractionally Subadditive (XoS) (1 + , e e\u22121 ) e e\u22121 [18] Submodular (1 + , e e\u22121 ) and (1, 2) e e\u22121 [45]", "startOffset": 125, "endOffset": 129}, {"referenceID": 17, "context": "Valuation Function Class Our Results: (\u03b1, c)-Core Lower Bound for c Subadditive (4, 4) 2 [20] Anonymous Subadditive (2, 2) 2 [20] Fractionally Subadditive (XoS) (1 + , e e\u22121 ) e e\u22121 [18] Submodular (1 + , e e\u22121 ) and (1, 2) e e\u22121 [45]", "startOffset": 182, "endOffset": 186}, {"referenceID": 8, "context": "Ties to Combinatorial Auctions with Item Bidding We conclude by pointing out a close relationship between our setting and simultaneous auctions where buyers bid on each item separately [9,14,17].", "startOffset": 185, "endOffset": 194}, {"referenceID": 13, "context": "Ties to Combinatorial Auctions with Item Bidding We conclude by pointing out a close relationship between our setting and simultaneous auctions where buyers bid on each item separately [9,14,17].", "startOffset": 185, "endOffset": 194}, {"referenceID": 16, "context": "Ties to Combinatorial Auctions with Item Bidding We conclude by pointing out a close relationship between our setting and simultaneous auctions where buyers bid on each item separately [9,14,17].", "startOffset": 185, "endOffset": 194}, {"referenceID": 2, "context": "The non-existence of the core in many important settings has prompted researchers to devise several natural relaxations [3,4,41,43]: of these, the Cost of Stability [4,7,35], and the Multiplicative Least-Core [10,42,43] are the solution concepts that are directly analogous to our notion of an \u03b1-core.", "startOffset": 120, "endOffset": 131}, {"referenceID": 3, "context": "The non-existence of the core in many important settings has prompted researchers to devise several natural relaxations [3,4,41,43]: of these, the Cost of Stability [4,7,35], and the Multiplicative Least-Core [10,42,43] are the solution concepts that are directly analogous to our notion of an \u03b1-core.", "startOffset": 120, "endOffset": 131}, {"referenceID": 40, "context": "The non-existence of the core in many important settings has prompted researchers to devise several natural relaxations [3,4,41,43]: of these, the Cost of Stability [4,7,35], and the Multiplicative Least-Core [10,42,43] are the solution concepts that are directly analogous to our notion of an \u03b1-core.", "startOffset": 120, "endOffset": 131}, {"referenceID": 42, "context": "The non-existence of the core in many important settings has prompted researchers to devise several natural relaxations [3,4,41,43]: of these, the Cost of Stability [4,7,35], and the Multiplicative Least-Core [10,42,43] are the solution concepts that are directly analogous to our notion of an \u03b1-core.", "startOffset": 120, "endOffset": 131}, {"referenceID": 3, "context": "The non-existence of the core in many important settings has prompted researchers to devise several natural relaxations [3,4,41,43]: of these, the Cost of Stability [4,7,35], and the Multiplicative Least-Core [10,42,43] are the solution concepts that are directly analogous to our notion of an \u03b1-core.", "startOffset": 165, "endOffset": 173}, {"referenceID": 6, "context": "The non-existence of the core in many important settings has prompted researchers to devise several natural relaxations [3,4,41,43]: of these, the Cost of Stability [4,7,35], and the Multiplicative Least-Core [10,42,43] are the solution concepts that are directly analogous to our notion of an \u03b1-core.", "startOffset": 165, "endOffset": 173}, {"referenceID": 34, "context": "The non-existence of the core in many important settings has prompted researchers to devise several natural relaxations [3,4,41,43]: of these, the Cost of Stability [4,7,35], and the Multiplicative Least-Core [10,42,43] are the solution concepts that are directly analogous to our notion of an \u03b1-core.", "startOffset": 165, "endOffset": 173}, {"referenceID": 9, "context": "The non-existence of the core in many important settings has prompted researchers to devise several natural relaxations [3,4,41,43]: of these, the Cost of Stability [4,7,35], and the Multiplicative Least-Core [10,42,43] are the solution concepts that are directly analogous to our notion of an \u03b1-core.", "startOffset": 209, "endOffset": 219}, {"referenceID": 41, "context": "The non-existence of the core in many important settings has prompted researchers to devise several natural relaxations [3,4,41,43]: of these, the Cost of Stability [4,7,35], and the Multiplicative Least-Core [10,42,43] are the solution concepts that are directly analogous to our notion of an \u03b1-core.", "startOffset": 209, "endOffset": 219}, {"referenceID": 42, "context": "The non-existence of the core in many important settings has prompted researchers to devise several natural relaxations [3,4,41,43]: of these, the Cost of Stability [4,7,35], and the Multiplicative Least-Core [10,42,43] are the solution concepts that are directly analogous to our notion of an \u03b1-core.", "startOffset": 209, "endOffset": 219}, {"referenceID": 14, "context": "Although cooperative games traditionally do not involve any optimization, a number of papers have studied well-motivated games where the valuation or cost function (c(S)) is derived from an underlying combinatorial optimization problem [15,26,28,34].", "startOffset": 236, "endOffset": 249}, {"referenceID": 25, "context": "Although cooperative games traditionally do not involve any optimization, a number of papers have studied well-motivated games where the valuation or cost function (c(S)) is derived from an underlying combinatorial optimization problem [15,26,28,34].", "startOffset": 236, "endOffset": 249}, {"referenceID": 27, "context": "Although cooperative games traditionally do not involve any optimization, a number of papers have studied well-motivated games where the valuation or cost function (c(S)) is derived from an underlying combinatorial optimization problem [15,26,28,34].", "startOffset": 236, "endOffset": 249}, {"referenceID": 33, "context": "Although cooperative games traditionally do not involve any optimization, a number of papers have studied well-motivated games where the valuation or cost function (c(S)) is derived from an underlying combinatorial optimization problem [15,26,28,34].", "startOffset": 236, "endOffset": 249}, {"referenceID": 14, "context": "For example, in the vertex cover game [15, 19] where each edge is an agent, c(S) is the size of the minimum cover for the edges in S.", "startOffset": 38, "endOffset": 46}, {"referenceID": 18, "context": "For example, in the vertex cover game [15, 19] where each edge is an agent, c(S) is the size of the minimum cover for the edges in S.", "startOffset": 38, "endOffset": 46}, {"referenceID": 25, "context": "For many such problems, core payments can be computed almost directly using LP Duality [26,28,34].", "startOffset": 87, "endOffset": 97}, {"referenceID": 27, "context": "For many such problems, core payments can be computed almost directly using LP Duality [26,28,34].", "startOffset": 87, "endOffset": 97}, {"referenceID": 33, "context": "For many such problems, core payments can be computed almost directly using LP Duality [26,28,34].", "startOffset": 87, "endOffset": 97}, {"referenceID": 3, "context": "In the cooperative game theory literature, our setting is perhaps closest to the work studying coalitional structures where instead of forming the grand coalition, agents are allowed to arbitrarily partition themselves [4,27] or form overlapping coalitions [12].", "startOffset": 219, "endOffset": 225}, {"referenceID": 26, "context": "In the cooperative game theory literature, our setting is perhaps closest to the work studying coalitional structures where instead of forming the grand coalition, agents are allowed to arbitrarily partition themselves [4,27] or form overlapping coalitions [12].", "startOffset": 219, "endOffset": 225}, {"referenceID": 11, "context": "In the cooperative game theory literature, our setting is perhaps closest to the work studying coalitional structures where instead of forming the grand coalition, agents are allowed to arbitrarily partition themselves [4,27] or form overlapping coalitions [12].", "startOffset": 257, "endOffset": 261}, {"referenceID": 11, "context": ", threshold task games [12] or coalitional skill games [5].", "startOffset": 23, "endOffset": 27}, {"referenceID": 4, "context": ", threshold task games [12] or coalitional skill games [5].", "startOffset": 55, "endOffset": 58}, {"referenceID": 15, "context": "Recently, there has been a lot of interest in designing cost-sharing mechanisms that satisfy strategy-proofness in settings where a service is to be provided to a group of agents who hold private values for the same [16, 37].", "startOffset": 216, "endOffset": 224}, {"referenceID": 36, "context": "Recently, there has been a lot of interest in designing cost-sharing mechanisms that satisfy strategy-proofness in settings where a service is to be provided to a group of agents who hold private values for the same [16, 37].", "startOffset": 216, "endOffset": 224}, {"referenceID": 35, "context": "A powerful relationship between our work and the body of strategy-proof mechanisms was discovered by Moulin [36] who showed that a natural class of \u2018cross-monotonic cost sharing schemes\u2019 can be used to design mechanisms that are both core-stable (CS) and strategy-proof (SP).", "startOffset": 108, "endOffset": 112}, {"referenceID": 24, "context": "This has led to the design of beautiful SP+CS mechanisms for several combinatorially motivated problems with a single identical project or service [25, 39].", "startOffset": 147, "endOffset": 155}, {"referenceID": 38, "context": "This has led to the design of beautiful SP+CS mechanisms for several combinatorially motivated problems with a single identical project or service [25, 39].", "startOffset": 147, "endOffset": 155}, {"referenceID": 1, "context": "Finally, we briefly touch upon the large body of literature in non-transferable utility games that (like us) study coalition formation with a finite number of asymmetric projects [2, 11, 13,23].", "startOffset": 179, "endOffset": 193}, {"referenceID": 10, "context": "Finally, we briefly touch upon the large body of literature in non-transferable utility games that (like us) study coalition formation with a finite number of asymmetric projects [2, 11, 13,23].", "startOffset": 179, "endOffset": 193}, {"referenceID": 12, "context": "Finally, we briefly touch upon the large body of literature in non-transferable utility games that (like us) study coalition formation with a finite number of asymmetric projects [2, 11, 13,23].", "startOffset": 179, "endOffset": 193}, {"referenceID": 22, "context": "Finally, we briefly touch upon the large body of literature in non-transferable utility games that (like us) study coalition formation with a finite number of asymmetric projects [2, 11, 13,23].", "startOffset": 179, "endOffset": 193}, {"referenceID": 17, "context": "The reader is asked to refer to [18, 20, 31, 44] for alternative definitions of the XoS class and an exposition on how both these classes arise naturally in many interesting applications.", "startOffset": 32, "endOffset": 48}, {"referenceID": 19, "context": "The reader is asked to refer to [18, 20, 31, 44] for alternative definitions of the XoS class and an exposition on how both these classes arise naturally in many interesting applications.", "startOffset": 32, "endOffset": 48}, {"referenceID": 30, "context": "The reader is asked to refer to [18, 20, 31, 44] for alternative definitions of the XoS class and an exposition on how both these classes arise naturally in many interesting applications.", "startOffset": 32, "endOffset": 48}, {"referenceID": 43, "context": "The reader is asked to refer to [18, 20, 31, 44] for alternative definitions of the XoS class and an exposition on how both these classes arise naturally in many interesting applications.", "startOffset": 32, "endOffset": 48}, {"referenceID": 29, "context": "Anonymous Subadditive Functions In project assignment settings in the literature modeling a number of interesting applications [30, 35], it is reasonable to assume that the value from a project depends only on the number of users working on that project.", "startOffset": 127, "endOffset": 135}, {"referenceID": 34, "context": "Anonymous Subadditive Functions In project assignment settings in the literature modeling a number of interesting applications [30, 35], it is reasonable to assume that the value from a project depends only on the number of users working on that project.", "startOffset": 127, "endOffset": 135}, {"referenceID": 17, "context": "In particular, when dealing with a subadditive function v, it is typical to assume that we are provided with a demand oracle that when queried with a vector of payments p, returns a set T \u2286 N that maximizes the quantity v(T )\u2212\u2211i\u2208T pi [18].", "startOffset": 234, "endOffset": 238}, {"referenceID": 17, "context": "For example, it is well-known [18] that one cannot obtain any reasonable approximation algorithm for subadditive functions (better than O( \u221a N)) in the absence of demand queries.", "startOffset": 30, "endOffset": 34}, {"referenceID": 17, "context": "We conclude this discussion by reiterating that demand oracles are an extremely standard tool used in the literature to study combinatorial valuations; almost all of the papers [18,20,25] studying Subadditive or XoS functions take the presence of a demand oracle for granted.", "startOffset": 177, "endOffset": 187}, {"referenceID": 19, "context": "We conclude this discussion by reiterating that demand oracles are an extremely standard tool used in the literature to study combinatorial valuations; almost all of the papers [18,20,25] studying Subadditive or XoS functions take the presence of a demand oracle for granted.", "startOffset": 177, "endOffset": 187}, {"referenceID": 24, "context": "We conclude this discussion by reiterating that demand oracles are an extremely standard tool used in the literature to study combinatorial valuations; almost all of the papers [18,20,25] studying Subadditive or XoS functions take the presence of a demand oracle for granted.", "startOffset": 177, "endOffset": 187}, {"referenceID": 30, "context": "Proof: The proof uses the popular greedy half-approximation algorithm for submodular welfare maximization due to [31].", "startOffset": 113, "endOffset": 117}, {"referenceID": 19, "context": "We use this black-box in conjunction with the algorithm of Feige [20] to obtain a (4, 4)-Core stable solution, i.", "startOffset": 65, "endOffset": 69}, {"referenceID": 17, "context": "Although the primal LP contains an exponential number of variables, the dual LP can be solved using the Ellipsoid method where the demand oracle serves as a separation oracle [18].", "startOffset": 175, "endOffset": 179}, {"referenceID": 19, "context": "The best-known approximation algorithms for many popular classes of valuations use LP-based rounding techniques; of particular interest to us is the 2-approximation for Subadditive valuations [20], and e e\u22121 -approximation for XoS valuations [18].", "startOffset": 192, "endOffset": 196}, {"referenceID": 17, "context": "The best-known approximation algorithms for many popular classes of valuations use LP-based rounding techniques; of particular interest to us is the 2-approximation for Subadditive valuations [20], and e e\u22121 -approximation for XoS valuations [18].", "startOffset": 242, "endOffset": 246}, {"referenceID": 24, "context": "explicitly make use of the optimum LP solution [25].", "startOffset": 47, "endOffset": 51}, {"referenceID": 19, "context": "For general subadditive functions, the only known poly-time constant-factor approximation is the rather intricate randomized LP rounding scheme proposed in [20].", "startOffset": 156, "endOffset": 160}, {"referenceID": 29, "context": "Such functions are frequently assumed in coalition formation and project assignment settings [30].", "startOffset": 93, "endOffset": 97}, {"referenceID": 19, "context": "To the best of our knowledge, the only previously known approach that achieves a 2-approximation for anonymous subadditive functions is the LP-based rounding algorithm for general subadditive functions [20].", "startOffset": 202, "endOffset": 206}, {"referenceID": 32, "context": "In addition, our greedy algorithm also possesses other \u2018nice structural properties\u2019 that may be of use in other settings such as mechanism design [33].", "startOffset": 146, "endOffset": 150}, {"referenceID": 17, "context": "For instance, for XoS valuations, we can compute a (1 + )-core using Demand and XoS oracles (see [18] for a treatment of XoS oracles), whereas without these oracles, we can still compute a ( e e\u22121)-core.", "startOffset": 97, "endOffset": 101}, {"referenceID": 17, "context": "Unfortunately, it is known that the optimum solution cannot be computed efficiently for either of these classes unless P=NP [18].", "startOffset": 124, "endOffset": 128}, {"referenceID": 8, "context": "In recent years, the field of Auction Design has been marked by a paradigm shift towards \u2018simple auctions\u2019; one of the best examples of this is the growing popularity of Simultaneous Combinatorial Auctions [9, 14, 17], where the buyers submit a single bid for each item.", "startOffset": 206, "endOffset": 217}, {"referenceID": 13, "context": "In recent years, the field of Auction Design has been marked by a paradigm shift towards \u2018simple auctions\u2019; one of the best examples of this is the growing popularity of Simultaneous Combinatorial Auctions [9, 14, 17], where the buyers submit a single bid for each item.", "startOffset": 206, "endOffset": 217}, {"referenceID": 16, "context": "In recent years, the field of Auction Design has been marked by a paradigm shift towards \u2018simple auctions\u2019; one of the best examples of this is the growing popularity of Simultaneous Combinatorial Auctions [9, 14, 17], where the buyers submit a single bid for each item.", "startOffset": 206, "endOffset": 217}, {"referenceID": 23, "context": "In this paper, we also study the slightly less stringent weak no-overbidding assumption considered in [24] and [22] which states that \u2018a player\u2019s total bid for her winning set is at most her valuation for that set\u2019.", "startOffset": 102, "endOffset": 106}, {"referenceID": 21, "context": "In this paper, we also study the slightly less stringent weak no-overbidding assumption considered in [24] and [22] which states that \u2018a player\u2019s total bid for her winning set is at most her valuation for that set\u2019.", "startOffset": 111, "endOffset": 115}, {"referenceID": 8, "context": "Finally, to model buyers who overbid by small amounts, we focus on the following natural relaxation of no-overbidding known as \u03b3-conservativeness that was defined by Bhawalkar and Roughgarden [9].", "startOffset": 192, "endOffset": 195}, {"referenceID": 8, "context": "(Conservative Bids) [9] For a given buyer k \u2208 P, a bid vector bk is said to be \u03b3-conservative if for all T \u2286 N , we have \u2211i\u2208T bk(i) \u2264 \u03b3 \u00b7 vk(T ).", "startOffset": 20, "endOffset": 23}, {"referenceID": 8, "context": "Existence and Computation of Equilibrium Although simultaneous auctions enjoy several desirable properties like good Price of Anarchy [9, 14], their applicability is limited by both existential and computational barriers.", "startOffset": 134, "endOffset": 141}, {"referenceID": 13, "context": "Existence and Computation of Equilibrium Although simultaneous auctions enjoy several desirable properties like good Price of Anarchy [9, 14], their applicability is limited by both existential and computational barriers.", "startOffset": 134, "endOffset": 141}, {"referenceID": 16, "context": "always exists for simple valuations like XoS, it may not be possible to actually compute one [17].", "startOffset": 93, "endOffset": 97}, {"referenceID": 8, "context": "For more general subadditive (and even anonymous) valuations, Nash equilibria without overbidding may not even exist [9], and whether or not they exist cannot be determined without exponential communication [17].", "startOffset": 117, "endOffset": 120}, {"referenceID": 16, "context": "For more general subadditive (and even anonymous) valuations, Nash equilibria without overbidding may not even exist [9], and whether or not they exist cannot be determined without exponential communication [17].", "startOffset": 207, "endOffset": 211}, {"referenceID": 16, "context": "In light of these impossibility results and the known barriers to actually compute a (no-overbidding) equilibrium [17], we argue that in many auctions, it seems reasonable to consider \u03b1-approximate Nash equilibrium that guarantee that buyers\u2019 utilities cannot improve by more than a factor \u03b1 when they change their bids.", "startOffset": 114, "endOffset": 118}, {"referenceID": 16, "context": "One can contrast this result to an algorithm by [17] that computes an exact Nash equilibrium in pseudo-polynomial time, i.", "startOffset": 48, "endOffset": 52}], "year": 2015, "abstractText": "Consider a setting where selfish agents are to be assigned to coalitions or projects from a set P. Each project k \u2208 P is characterized by a valuation function; vk(S) is the value generated by a set S of agents working on project k. We study the following classic problem in this setting: \u201chow should the agents divide the value that they collectively create?\u201d. One traditional approach in cooperative game theory is to study core stability with the implicit assumption that there are infinite copies of one project, and agents can partition themselves into any number of coalitions. In contrast, we consider a model with a finite number of non-identical projects; this makes computing both high-welfare solutions and core payments highly non-trivial. The main contribution of this paper is a black-box mechanism that reduces the problem of computing a near-optimal core stable solution to the purely algorithmic problem of welfare maximization; we apply this to compute an approximately core stable solution that extracts one-fourth of the optimal social welfare for the class of subadditive valuations. We also show much stronger results for several popular sub-classes: anonymous, fractionally subadditive, and submodular valuations, as well as provide new approximation algorithms for welfare maximization with anonymous functions. Finally, we establish a connection between our setting and the well-studied simultaneous auctions with item bidding; we adapt our results to compute approximate pure Nash equilibria for these auctions.", "creator": "LaTeX with hyperref package"}}}