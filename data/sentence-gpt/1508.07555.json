{"id": "1508.07555", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "30-Aug-2015", "title": "An Event Network for Exploring Open Information", "abstract": "In this paper, an event network is presented for exploring open information, where linguistic units about an event are organized for analysing. The process is divided into three steps: document event detection, event network construction and event network analysis. First, by implementing event detection or tracking, documents are retrospectively (or on-line) organized into document events. Secondly, for each of the document event, linguistic units are extracted and combined into event networks. Thirdly, various analytic methods are proposed for event network analysis. In our application methodologies are presented for exploring open information. For example, we are able to generate a document of an event to analyze. First, we consider a given event network for analyzing. Second, we consider an event network for analyzing. Thirdly, we consider the same event network for analyzing. Fourth, we consider the same event network for analyzing. Finally, in our model we use the word \u200d\u200f\u200f\u200f\u200f\u200f\u200f\u200f\u200f\u200f\u200f\u200f\u200f\u200f\u200f\u200f\u200f\u200f\u200f\u200f\u200f\u200f\u200f\u200f\u200f\u200f\u200f\u200f\u200f\u200f\u200f\u200f\u200f\u200f\u200f\u200f\u200f\u200f\u200f\u200f\u200f\u200f\u200f\u200f\u200f\u200f\u200f\u200f\u200f\u200f\u200f\u200f\u200f\u200f\u200f\u200f\u200f\u200f\u200f\u200f\u200f\u200f\u200f\u200f\u200f\u200f\u200f\u200f\u200f\u200f\u200f\u200f\u200f\u200f\u200f\u200f\u200f\u200f\u200f\u200f\u200f\u200f\u200f\u200f\u200f\u200f\u200f\u200f\u200f\u200f\u200f\u200f\u200f\u200f\u200f\u200f\u200f\u200f\u200f\u200f\u200f\u200f\u200f\u200f\u200f\u200f\u200f\u200f\u200f\u200f\u200f\u200f\u200f\u200f\u200f\u200f\u200f\u200f\u200f\u200f\u200f\u200f\u200f\u200f\u200f\u200f\u200f\u200f\u200f\u200f\u200f\u200f\u200f\u200f\u200f\u200f\u200f\u200f\u200f\u200f\u200f\u200f\u200f\u200f\u200f\u200f\u200f\u200f\u200f\u200f\u200f\u200f\u200f\u200f\u200f\u200f\u200f\u200f\u200f\u200f\u200f\u200f\u200f\u200f\ufffd", "histories": [["v1", "Sun, 30 Aug 2015 11:22:38 GMT  (639kb)", "http://arxiv.org/abs/1508.07555v1", null]], "reviews": [], "SUBJECTS": "cs.CL", "authors": ["yanping chen"], "accepted": false, "id": "1508.07555"}, "pdf": {"name": "1508.07555.pdf", "metadata": {"source": "CRF", "title": "An Event Network for Exploring Open Information", "authors": ["Yanping Chen"], "emails": ["ypench@gmail.com"], "sections": [{"heading": null, "text": "ar X\niv :1\n50 8.\n07 55\n5v 1\n[ cs\n.C L\n] 3\n0 A\nug 2"}, {"heading": "1 Introduction", "text": "Exploring information in open fields is a crucial and challenging task for human beings in the age characterized by flooding of information. Gigantic volumes of data spring up all over the world. This information is availably for us by connecting into the Internet. Events (e.g. the Ebola virus, the Islamic state) outbroken far away from us may affect our ordinary life. We no longer turn a blind eye to world events, that we are getting involved. We not only consume information, but also produce it. Social media (e.g., Twitter) makes us easily and freely express opinions. Millions of comments spread over the Internet, affecting the trend of public opinions. Accessing this information is beneficial for our decision-makings. Commonly, Information Retrieval (IR) and Information Extraction (IE) provide helpful solutions for us to handle the surge of information.\nWhen exploring information, event oriented techniques provide effective approaches to understand who, where, when and what happened. Output of event detection in IR is series (or clusters) of documents, referred as document events in this paper. The problem with IR systems is that, they only retrieve subject-documents, but no content of documents is identified. Users are required to skim through returned documents. Events of IE are templates with slots to be filled, referred to as template events. Template event recognition extracts structured data from semi-structured or unstructured data. It is expected that the result is used to populate a knowledge base directly. The main problem for template event recognition is that it suffers from poor performance, especially in an open field, where heterogeneous resources, noise and fragmental data are processed.\nIn open fields, there are knowledge bases automatically constructed to support information exploring. Many of them are constructed from semi-structured database (e.g. Wikipedia, WordNet) or under human supervision (collaboratively). Therefore, a better consistency is expected. They are widely used as external knowledge for semisupervised methods. Because semi-structured data or human labor are required, when a\nnews is broken in open fields automatically handling this information in real time is difficult. Furthermore, many systems automatically organize extracted linguistic units into a graph-based representation. These systems generally lead to a complex network with thousands of nodes or edges. Rare analysis was conducted to show underlying structures of events. Generally, output generated by IE systems is error-prone, redundant and incompatible information makes it contradictory. In this paper, analyses of event network are emphasized. Contributions of this paper include,\n1. An event network framework is proposed, which provides an event oriented information exploring and supports various analyses. 2. Two novel analytic methods (PLT analysis and action analysis) are discussed for event oriented information exploring.\nThe rest of this paper is organized as follows. Section 2 introduces related work. Motivations and definitions about the event network are presented in Section 3. Section 4 discusses our method to construct event networks. Section 5 demonstrates applications of event network. Section 6 gives conclusions."}, {"heading": "2 Related Work", "text": "Organizing linguistic units as networks or graphs shows an increased interest in NLP. These representations can be roughly divided into three paradigms: logic based semantic network (e.g. Ontology), scalable knowledge database (e.g. Freebase) and semantic network constructed from open information extraction.\nLogic based semantic network refers to networks constructed with human labor. They mainly focus on a closed domain. For example, conceptual graph represents logic as a graph representation (Sowa, 1984). These networks support logic operators, can map questions and assertions from natural language to a relational database. Logic based semantic networks are constructed by domain experts and used as domainspecific ontologies (e.g., WordNet, Cyc, etc.). Commonly, they support inferences developed in knowledge representation. In this paradigm, conflicting and contradictory are not allowed. Therefore, in open fields it is difficult to apply.\nIn the second paradigm, logic based semantic network is extended into open fields. Large knowledge databases such as Yago (Suchanek et al., 2007), Freebase (Bollacker et al., 2008) are constructed, representing large knowledge in formalized forms. These representations merge diverse and heterogeneous data with high scalability, providing a unified framework for organizing information. Instead of rigid definitions, these networks have no canonical view of data. They use a loose representation to support scalability and extensibility. Many of them are constructed by merging ontologies (e.g. WordNet, OpenCyc) or extracted from semi-structured database (e.g. Wikipedia). To construct logic based semantic network, commonly, direct or indirect human interventions are involved (e.g. collaborative methods or searching logs).\nInstead of aiming at semi-structured data, the third paradigm explores information in an open and dynamic field (mainly focusing on unstructured data). In this paradigm, weak supervision (Mintz et al., 2009; Xu and Zhao, 2014) and bootstrapping methods (Agichtein and Gravano, 2000; Kozareva and Hovy, 2010; McIntosh et al., 2011;\nWeld et al., 2009) are employed. Scalable knowledge databases are used to guide the process, e.g., TEXTRUNNER (Banko et al., 2007), KNOWITALL (Etzioni et al., 2005, 2011), WOE (Hoffmann et al., 2010) and StatSnowBall (Zhu et al., 2009). Commonly, in these systems, nodes are named entities and edges are relations between them. All extracted results are combined into a large network. It often generate a network containing more than thousands of nodes and edges.\nThe notion of event is widely used for exploring information. Piskorski et al. (2011) presents an on-line news event extraction system. Each event is defined as a frame with slots filled by information extracted from clustered documents, where the pattern matching method is used. Ramakrishnan et al. (2014) proposes an EMBERS system encoding events as frames. It is used to forecast \u201ccivil unrest\u201d events in open fields. TwiCal extracts open-domain events from Twitter (Ritter et al., 2012), where events are identified by named entities. In the same data set, ET represents events as clusters of keywords (Parikh and Karlapalem, 2013). Kuzey et al. (2014) uses events itself as nodes of network. They cluster documents into a hierarchical representation, where notes are events and edges link the same event in chronological order. Angel et al. (2012) constructs an entity network from social media by the streaming edge weight method. They mine dense subgraphs of network for identifying realtime stories. Das Sarma et al. (2011) provides an event discovery method based on entity dynamic relation graphs, which are constructed by co-occurrences of entities constrained in documents."}, {"heading": "3 Motivation and Definition", "text": "Methodologies to organize linguistic units into networks or graphs show an increased interest in NLP. They provide novel solutions for many NLP tasks and support human oriented information exploring. Representing linguistic units as a graph enables topological analyses developed in fields such as: social network and complex network.\nIn open fields, these representations are mainly constructed by techniques developed under information extraction or text understanding. Information extraction aims at extracting linguistic units with concrete concepts or functions. It is seen as a tradeoff between information retrieval and text understanding, where text understanding tries to capture all information in a document. Text understanding may lead to worsen performance caused by applied techniques (Hobbs and Riloff, 2010). On the other hand, information extraction extracts targeted units and ignores uninterested.\nDue to extracting challenges in open fields, instead of extracting information in a monolithic process, we divide the task into three steps: document event detection, event network construction and event network analysis. In the first step, by implementing document event detection and tracking, documents are organized into document events. Most of irrelevant or uninterested information is filtered. Then, in the second step, IE techniques are employed to extract linguistic units and organized into event networks. Techniques with higher performance are highlighted. For example, instead of extracting named entities as nodes, entity mentions are used. Where coreference resolution are required to group entity mentions into named entities, which is error-prone. In the last step, because topological information is available, structural information between lin-\nguistic units can be used to modify the network quality. Then, network or graph based analytic methods can be used, and it is convenient for visualization.\nIn this domain, many systems combine extracted results into a complex network, which not doing much help for analysing information. Furthermore, redundant and incompatible information makes it contradictory and misunderstanding. In our application, we emphasize methodologies conducted for event network analysis. Advantages of the event network include: first, after document event detection, information extraction in each document event can be independently implemented. Therefore, the effect of noise and heterogeneous data on information extraction can be reduced. Secondly, crossing document information enables discovery of potential relations between documents. Thirdly, event network provides a structured data representation for exploring open information, topological methods, e.g., social network or complex network, can be introduced for event network analysis.\nFor convenience to discuss event network analysis, we define nodes and edges of event network as frames with slots. These information is also expected to support human oriented information exploring.\nLet D={d1, \u00b7 \u00b7 \u00b7 , dL} be a document set, di denotes a document. A document event Ek is a subset of D . For all di, dj \u2208 Ek, similarity function Similarity(di, dj) satisfy a predefined condition (e.g. a threshold). All document events in D are denoted as E ={E1, \u00b7 \u00b7 \u00b7 , EK}. The constraint that E is a partition of D is not necessary, because some documents in D can be filtered, or fuzzy partitioning techniques can be used, which enable a document belonging to more than one document event.\nAn event network on document event Ek is represented as a graph Nk={Vk, Ek}, where Vk={vk1, \u00b7 \u00b7 \u00b7 , vkN} and Ek={ek1, \u00b7 \u00b7 \u00b7 , ekM} are vertex set and edge set. Both vertices and edges are frames defined as follows.\nvertex := {key, name, type, weight, info}\nedge := {type, v-1, v-2, weight, info}\nwhere vertex frame defines nodes of event network. Slot \u201cname\u201d refers to entity mentions occurred in a document event. Each vertex is identified by an integer value \u201ckey\u201d. Slot \u201ctype\u201d represents categories of vertices (e.g. Person, Organization and Location). Slot \u201cweight\u201d is the likelihood of \u201cname\u201d to be \u201ctype\u201d. Traditionally, this value is given by a classifier when extracting this frame. Depending on real applications, \u201cweight\u201d can be used to filter an event network. An edge frame denotes a relation between two vertexes. Slots \u201cv-1\u201d and \u201cv-2\u201d are keys of vertices in an edge, used to identify vertices linked by edges. Edge types are referred by \u201ctype\u201d (e.g. Part-whole, Personal-Social). In both frames, slot \u201cinfo\u201d contains information about the frames, where entity mentions or entity relations occurred, e.g., sentences, documents or timestamps. These information support event network analyses (e.g. coreference resolution, statistical relational learning or manually exploring). If they are empty, these values are null."}, {"heading": "4 Implementation", "text": "This section discusses our method to construct event networks, which are used to show methodologies discussed in Section 5."}, {"heading": "4.1 Data Sets", "text": "We use the ACE 2005 Chinese corpus. It contains 633 documents annotated with 15,264 entities and 33,932 entity mentions1. 7 entity types (e.g. person, organization, etc.) and 44 entity subtypes are defined. The corpus also annotated with 6 major relation types and 18 relation subtypes. Each relation instance has two named entities as arguments. There are 9,244 relation mentions are collected as positive instances.\nThe ACE 2005 Chinese corpus is used to train named entity and relation classifiers. In order to show our method in an open field, we also use the Chinese Gigaword Fifth Edition corpus. The Peoples Daily source is used, which contain 145,001 newswire texts covering the period from November 2006 through December 2010."}, {"heading": "4.2 Events Detection", "text": "The purpose of document event detection is to cluster documents into events. We use LDA toolkit provided by Phan and Nguyen (2007) to implement this task. In LDA model, a corpus is first represented as a matrix, where each column refers to a document vector, and each row represents distribution of a term in documents. Then LDA maps documents from a term space into a topic space. Topics are hidden variables.\nBecause we focus on newswire texts, where short texts are commonly used. We use Omni-word feature proposed by Chen et al. (2014), which takes every potential word as terms of documents. It is a subset of n-Gram feature. In the pretreatment process, we remove high and low frequency words2 in an employed lexicon. Words with frequencies lower than 10 are also removed. To train an LDA model, hyper-parameters are required. The topic number is set as 25. Other parameters use default settings.\nThe toolkit generates several outputs. The word-topic distributions are more favourable to us, which give distributions of terms in a topic space. We use topics as centroids of document clusters in a term space. When clustering documents, a documents belonging to an event is judged by the nearest Euler Distance of the document and centroids. The top 100 most likely words per each topic are used to represent an event.\nIt is recognized that documents discussing the same event tend to be temporal proximity, and a time gap between bursts of similar documents may indicate different events (Yang et al., 1999). Therefore, timestamps are used to partition the newswire texts. In our experiment, the time step is set as 5 months. Then, the Chinese Gigaword corpus is divided into 10 parts. Each part contains 5 months newswire texts. Because hierarchical representation can give a multi-granularity review when exploring open information and reduce the travel cost. In each time step, instead of using retrospective methods to give a flat partition of documents, we organize them into a hierarchical representation. Documents of each time step are clustered into 25 events by the LDA toolkit. Each event is further clustered into sub-events by the same approach. If an event contains documents less than ten, the process to find its sub-events is skipped. Therefore, in each time step, 25 events and at most 25\u00d7 25 sub-events are detected.\n1 An entity mention is a reference to an entity. 2 The ratio is 5% for each."}, {"heading": "4.3 Named Entity Recognizing", "text": "In this step, it is free to use any named entity recognition methods. In our application, we use a Boundary Assembling (BA) method to implement the named entity recognition task. The notion of BA method is that, instead of recognizing entity mentions in a unitary style, it first detects boundaries of entity mention, then assembles detected boundaries into entity mention candidates. Each candidate is further assessed by a classifier.\nIn our work, we recognize three types of named entity: \u201cPER\u201d (Person), \u201cLOC\u201d (Location) and \u201cORG\u201d (Organization). In order to filter noise, recognized named entities with Chinese characters less than two and more than six are discarded."}, {"heading": "4.4 Relation Recognizing", "text": "To recognize relations between named entities, we adopt the method proposed in Chen et al. (2014), where an Omni-word feature and a soft constraint method is proposed for Chinese relation extraction. The Omni-word feature uses every potential word in a relation mention as lexical features. Then for each employed atomic feature, an appropriate constraint condition is selected to combine them with additional information to maximize the classification determination.\nWith our employed three entity types, five relation types annotated in the ACE corpus are recognized: \u201cPER-SOC\u201d, \u201cGEN-AFF\u201d, \u201cORG-AFF\u201d, \u201cPART-WHOLE\u201d and \u201cPHYS\u201d. Sentences with more than ten entities are ignored, because extracting relations in a long sentence is error-prone."}, {"heading": "4.5 Merging and Visualizing", "text": "As approaches discussed above, the result about recognized document events, named entities and relations are listed in Table 1.\nIn the follows, in order to conduct event network analysis, we use the igraph toolkit provide by Csardi and Nepusz (2006), representing extracted entity mentions and relations as a graph. A network analysis toolkit (Pajek) provided by Batagelj and Mrvar (1998) is used for visualization."}, {"heading": "5 Application", "text": "In our work, we emphasize analyses of event networks. After event networks were constructed, techniques such as social network, complex network can be employed to analyse event networks. For example, setting a person name as a central entity, we can navigate entities around it. Filtering irrelevant information, we can show character relationships in an event. Using the \u201cPART-WHOLE\u201d relations, multi-granularity visualization can be supported. Because event networks have a graph representation, topological information is available. Therefore, various approaches (e.g., statistical relational learning) can be used to improve the network quality. Furthermore, event networks support human oriented information exploring. When human exploring open information, manual interventions can be used to modify the quality of event networks.\nIn this section, we choose a document event in time step 0 as an example, which contain 1,041 documents. There are 42,436 named entities and 6,272 relations occurred. The most likely words in it are \u201c\u88ad\u51fb,\u5317\u7ea6,\u53d1\u8a00\u4eba,\u51b2\u7a81,\u9632\u5fa1, etc.\u201d (Assault, NATO, Spokesman, Conflict, Defence, etc.). It indicates that the concern of this event is military affairs. Extracted named entities and relations are organized in Figure 1, where there are 252 nodes and 571 edges are merged. Nodes in Red, Yellow and Blue colors represent Person, Organization and Location respectively. Each edge is labelled by the relation type.\nTo explore open information, many systems dynamically organize linguistic units into a complex network. Heterogeneous resources and unreliable information make the network chaotic and misunderstanding. As Figure 1 showing, a complex network makes it difficult to understand. In the following, based on the event network, we give four methodologies to explore open information: Information Filtering, PLT Analysis, Action Analysis and Social Network Analysis."}, {"heading": "5.1 Information Filtering", "text": "The simplest way to analyse event network is to filter information that is irrelevant or uninterested. In Figure 2(a), only person names and \u201cPER-SOC\u201d relations are remained to show character relationships in an event network.\n(a) Information Filtering (b) PLA Analysis\nThis example can be formalized as: Let N be an event network. The filtered event network N \u2032={V \u2032, E\u2032} is a subgraph of N , such that N \u2032 \u2282 N . And N \u2032 satisfies \u2200v \u2208 V \u2032(v.type = PER) \u2227 \u2200e \u2208 E\u2032(e.type = PER-SOC).\nUsing information contained in vertex frames and edge frames, information filtering can provide effective approaches for exploring open information. For example, in vertex frames and edge frames, we may require that the value in weight slots is greater than a predefined threshold. Utilizing information in info slots, we can collect named entities occurred in specified periods or areas. For a central figure, we can see directly connected named entities and relations between them."}, {"heading": "5.2 PLT Analysis", "text": "Person-Location-Time (PLT) analysis tries to find relations between persons and locations in a period of time. It can be used to track a person, find trajectories of targeted entities. Person, Location are extracted by named entity recognition methods. While the T ime is different. Two kinds of T ime are distinguished in a document: implicit temporal information and explicit temporal information. Implicit temporal information is part of the document\u2019s content indicating the creation, development, termination of an event. It is also seen as a named entity type in some researches. Extracting this information needs information extraction or text understanding techniques. In many applications, it is ignored. Generally, in open fields, all documents have explicit temporal information, which includes the creation, modification and transmission timestamps of documents. They are meta-data spread with documents. In our paper, because we focus on newswire texts, where the explicit temporal information of documents is released together. Therefore, we use the explicit temporal information for PLT analysis.\nThis process can be formalized by introducing an attribute time in the info slot. Let N be an event network, times represent timestamps and person is a person name. N \u2032={V \u2032, E\u2032} is the result of PLT analysis based on N , where \u2200e \u2208 E\u2032(e.type = PHYS \u2227 (e.v-1 = person \u2228 e.v-2 = person)). In other words, all relation type in E\u2032 is \u201cPHYS\u201d, and take the same entity mention person as an argument. Replacing all person by corresponding times, we get a graph with nodes referred to timestamps and locations. An example is shown in Figure 2(b).\nIn this example, we track Mao Zedong (\u201c\u6bdb\u6cfd\u4e1c\u201d)3 in the whole Gigaword corpus, collect all recognized \u201cPHYS\u201d relation instances which have Mao Zedong as an argument. In the result, there are 142 \u201cPHYS\u201d relation mentions, which take Mao Zedong (or Chairman Mao) as arguments. Then we replace Mao Zedong (or Chairman Mao) by the explicit temporal information of newswire texts. In Figure 2(b)4, nodes in green color are timestamps, and blue nodes are locations. Each green node means that Mao Zedong occurred with the connected locations at that time."}, {"heading": "5.3 Action Analysis", "text": "Recognizing an \u201cevent\u201d under the ACE definition is difficult, where event triggers, participant roles, properties and attributes should be identified (Doddington et al., 2004). It received an ACE value score only 30% in Ahn (2006). In an open field, it will come to worse performance. In many researches, co-occurrence information (e.g. co-citation, co-word, co-link, etc.) between terms is used to explore and understand structures in the underlying document sets, e.g., Leydesdorff and Vaughan (2006). In our application, instead of the definition in ACE, we present the action analysis.\nIn action analysis, we focus on detecting whether or not a special action is mentioned in a sentence. Therefore, we conduct the \u201csentence classification\u201d task, classing each sentence by a classifier trained on the ACE annotated event mentions. In our application, we monitor the \u201cConflict\u201d ACE event type, which has two substype: Attack and Demonstrate (Doddington et al., 2004). The ACE corpus, which annotates 596 \u201cConflict\u201d events, is employed for training and testing. We implement the 5-fold cross validation, and the P/R/F (Precision/Recall/F-score) measurement. F-score is computed by (2 \u00d7 P \u00d7 R)/(P + R). In order to perform a two-class classification, we generate negative instances by segmenting the corpus into sentences, discarding annotated ACE event mentions, and filtering sentences without event triggers of \u201cConflict\u201d ACE events. Then, 1,589 sentences are collected as negative instances. We only use Omniwords features in sentences for classification. The performance is shown in Row 1 of Table 2, where Only the performance about \u201cConflict\u201d is listed.\nIn an open field with massive data, the precision is more emphasized. Therefore, we label an instance as a \u201cConflict\u201d action only when the employed classifier (maximum entropy) output a predicted value equals 1 5. The performance is shown in Row 2 of\n3 The leader of the Communist Party of Chinese. 4 Because the original graph is more complex (55 nodes and 142 edges), in this place, only part\nof it is given. 5 The default value is 0.5 in two-class classification.\nTable 2. We use this setting to train a classifier and predict every sentence in document events. Entity co-occurrences in each \u201cConflict\u201d sentence are calculated. The result is shown in Figure 2(c).\n(c) Action Analysis (d) Social Network Analysis\nFigure 2(c) shows the result about the employed event. Edges in this example indicate co-occurrence relations between entities. In this event, there are 12,076 sentences containing at least two entities,where 836 sentences have the \u201cConflict\u201d action with value 1 outputted by the classifier. Among them, 3,221 entities co-occurred. In order to make the result more comprehensible, edges with co-occurrence frequencies less than 12 are erased. Finally, a network with 25 entities is generated. In this example, entities (e.g., \u201c\u54c8\u9a6c\u65af\u201d (Hamas), \u201c\u52a0\u6c99\u5317\u90e8\u201d (the Gaza Strip), \u201c\u963f\u5bcc\u6c57\u201d (Afghanistan), \u201c\u7f8e \u519b\u201d (U.S. forces)) and the edges between them surely show meaningful information."}, {"heading": "5.4 Social Network Analysis", "text": "Techniques (e.g., Short Path, Cohesive Subgroup, Center, etc.) proposed in social network mainly implemented on a network constructed by domain experts. A precise network is required to discover the underlying structure of social network. Because event networks are automatically extracted. They are error-prone. Therefore, for some of these techniques, it is difficult to get a reliable output. However, some results generated by social network also show meaningful information for us. In Figure 2(d), an example is given.\nData in this example comes from results of Information Filtering and PLT analysis. The left of Figure 2(d) seeks a short path between \u201c\u5361\u5c14\u624e\u4f0a\u201d (Hamid Karzai) and \u201c\u56fd\u52a1\u537f\u201d (the Secretary of State). They are connected by \u201cPER-SOC\u201d relations. On the right, \u201cMao Zedong\u201d is set as the central figure to show directly collected locations, e.g., \u201c\u4e95\u5188\u5c71\u201d (Jinggangshan)."}, {"heading": "6 Conclusion and Future Work", "text": "Event network is a framework for exploring open information. In this paper, based on the employed data set, we show applications of event network for information analyses. In future work, based on event network, more analyses can be developed to support exploring open information."}], "references": [{"title": "Snowball: Extracting relations from large plaintext collections", "author": ["Eugene Agichtein", "Luis Gravano"], "venue": "In Proceedings of DL", "citeRegEx": "Agichtein and Gravano.,? \\Q2000\\E", "shortCiteRegEx": "Agichtein and Gravano.", "year": 2000}, {"title": "The stages of event extraction", "author": ["David Ahn"], "venue": "In Proceedings of the Workshop on Annotating and Reasoning about Time and Events,", "citeRegEx": "Ahn.,? \\Q2006\\E", "shortCiteRegEx": "Ahn.", "year": 2006}, {"title": "Dense subgraph maintenance under streaming edge weight updates for real-time story identification", "author": ["Albert Angel", "Nikos Sarkas", "Nick Koudas", "Divesh Srivastava"], "venue": null, "citeRegEx": "Angel et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Angel et al\\.", "year": 2012}, {"title": "Open information extraction for the web", "author": ["Michele Banko", "Michael J Cafarella", "Stephen Soderland", "Matthew Broadhead", "Oren Etzioni"], "venue": "In Proceedings of IJCAI \u201907,", "citeRegEx": "Banko et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Banko et al\\.", "year": 2007}, {"title": "Pajek-program for large network", "author": ["Vladimir Batagelj", "Andrej Mrvar"], "venue": "analysis. Connections,", "citeRegEx": "Batagelj and Mrvar.,? \\Q1998\\E", "shortCiteRegEx": "Batagelj and Mrvar.", "year": 1998}, {"title": "Freebase: a collaboratively created graph database for structuring human knowledge", "author": ["Kurt Bollacker", "Colin Evans", "Praveen Paritosh", "Tim Sturge", "Jamie Taylor"], "venue": "In Proceedings of SIGMOD", "citeRegEx": "Bollacker et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Bollacker et al\\.", "year": 2008}, {"title": "Omni-word Feature and Soft Constraint for Chinese Relation Extraction", "author": ["Yanping Chen", "Qinghua Zheng", "Wei Zhang"], "venue": "In Proceedings of ACL\u201914,", "citeRegEx": "Chen et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Chen et al\\.", "year": 2014}, {"title": "The igraph software package for complex network research", "author": ["Gabor Csardi", "Tamas Nepusz"], "venue": "IJ COMP SYS,", "citeRegEx": "Csardi and Nepusz.,? \\Q2006\\E", "shortCiteRegEx": "Csardi and Nepusz.", "year": 2006}, {"title": "Dynamic relationship and event discovery", "author": ["Anish Das Sarma", "Alpa Jain", "Cong Yu"], "venue": "In Proceedings of WSDM", "citeRegEx": "Sarma et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Sarma et al\\.", "year": 2011}, {"title": "The automatic content extraction (ACE) program\u2013tasks, data, and evaluation", "author": ["G. Doddington", "A. Mitchell", "M. Przybocki", "L. Ramshaw", "S. Strassel", "R. Weischedel"], "venue": "In Proceedings of LREC \u201904,", "citeRegEx": "Doddington et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Doddington et al\\.", "year": 2004}, {"title": "Unsupervised named-entity extraction from the web: An experimental study", "author": ["O. Etzioni", "M. Cafarella", "D. Downey", "A.M. Popescu", "T. Shaked", "S. Soderland", "D.S. Weld", "A. Yates"], "venue": null, "citeRegEx": "Etzioni et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Etzioni et al\\.", "year": 2005}, {"title": "Open Information Extraction: The Second Generation", "author": ["Oren Etzioni", "Anthony Fader", "Janara Christensen", "Stephen Soderland", "Mausam Mausam"], "venue": "In Proceedings of IJCAI \u201911,", "citeRegEx": "Etzioni et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Etzioni et al\\.", "year": 2011}, {"title": "Information extraction", "author": ["Jerry R Hobbs", "Ellen Riloff"], "venue": "Handbook of natural language processing,", "citeRegEx": "Hobbs and Riloff.,? \\Q2010\\E", "shortCiteRegEx": "Hobbs and Riloff.", "year": 2010}, {"title": "Learning 5000 relational extractors", "author": ["R. Hoffmann", "C. Zhang", "D.S. Weld"], "venue": "In Proceedings of ACL \u201910,", "citeRegEx": "Hoffmann et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Hoffmann et al\\.", "year": 2010}, {"title": "Learning arguments and supertypes of semantic relations using recursive patterns", "author": ["Zornitsa Kozareva", "Eduard Hovy"], "venue": "In Proceedings of ACL\u201910,", "citeRegEx": "Kozareva and Hovy.,? \\Q2010\\E", "shortCiteRegEx": "Kozareva and Hovy.", "year": 2010}, {"title": "A Fresh Look on Knowledge Bases: Distilling Named Events from News", "author": ["Erdal Kuzey", "Jilles Vreeken", "Gerhard Weikum"], "venue": "In Proceedings of CIKM", "citeRegEx": "Kuzey et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Kuzey et al\\.", "year": 2014}, {"title": "Co-occurrence matrices and their applications in information science: Extending ACA to the Web environment", "author": ["Loet Leydesdorff", "Liwen Vaughan"], "venue": null, "citeRegEx": "Leydesdorff and Vaughan.,? \\Q2006\\E", "shortCiteRegEx": "Leydesdorff and Vaughan.", "year": 2006}, {"title": "Relation Guided Bootstrapping of Semantic Lexicons", "author": ["Tara McIntosh", "Lars Yencken", "James R Curran", "Timothy Baldwin"], "venue": "In Proceedings of ACL", "citeRegEx": "McIntosh et al\\.,? \\Q2011\\E", "shortCiteRegEx": "McIntosh et al\\.", "year": 2011}, {"title": "Distant supervision for relation extraction without labeled data", "author": ["Mike Mintz", "Steven Bills", "Rion Snow", "Dan Jurafsky"], "venue": "In Proceedings of ACL", "citeRegEx": "Mintz et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Mintz et al\\.", "year": 2009}, {"title": "Et: events from tweets", "author": ["Ruchi Parikh", "Kamalakar Karlapalem"], "venue": "In Proceedings WWW", "citeRegEx": "Parikh and Karlapalem.,? \\Q2013\\E", "shortCiteRegEx": "Parikh and Karlapalem.", "year": 2013}, {"title": "Gibbslda++: Ac/c++ implementation of latent dirichlet allocation", "author": ["Xuan-Hieu Phan", "Cam-Tu Nguyen"], "venue": null, "citeRegEx": "Phan and Nguyen.,? \\Q2007\\E", "shortCiteRegEx": "Phan and Nguyen.", "year": 2007}, {"title": "Online news event extraction for global crisis surveillance", "author": ["Jakub Piskorski", "Hristo Tanev", "Martin Atkinson", "Eric Van Der Goot", "Vanni Zavarella"], "venue": "In TCCI,", "citeRegEx": "Piskorski et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Piskorski et al\\.", "year": 2011}, {"title": "Beating the news\u2019 with EMBERS: Forecasting Civil Unrest using Open Source Indicators", "author": ["Naren Ramakrishnan", "Patrick Butler", "Sathappan Muthiah", "Nathan Self"], "venue": "In Proceedings SIGKDD", "citeRegEx": "Ramakrishnan et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Ramakrishnan et al\\.", "year": 2014}, {"title": "Open domain event extraction from twitter", "author": ["Alan Ritter", "Oren Etzioni", "Sam Clark"], "venue": "In Proceedings of SIGKDD", "citeRegEx": "Ritter et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Ritter et al\\.", "year": 2012}, {"title": "Conceptual structures: information processing in mind and machine", "author": ["John F Sowa"], "venue": null, "citeRegEx": "Sowa.,? \\Q1984\\E", "shortCiteRegEx": "Sowa.", "year": 1984}, {"title": "Yago: a core of semantic knowledge", "author": ["Fabian M Suchanek", "Gjergji Kasneci", "Gerhard Weikum"], "venue": "In Proceedings of WWW", "citeRegEx": "Suchanek et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Suchanek et al\\.", "year": 2007}, {"title": "Using wikipedia to bootstrap open information extraction", "author": ["Daniel S Weld", "Raphael Hoffmann", "Fei Wu"], "venue": "ACM SIGMOD Record,", "citeRegEx": "Weld et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Weld et al\\.", "year": 2009}, {"title": "Exploring Fine-grained Entity Type Constraints for Distantly Supervised Relation Extraction", "author": ["Yang Liu Kang Liu Liheng Xu", "Jun Zhao"], "venue": null, "citeRegEx": "Xu and Zhao.,? \\Q2014\\E", "shortCiteRegEx": "Xu and Zhao.", "year": 2014}, {"title": "Learning approaches for detecting and tracking news events", "author": ["Yiming Yang", "Jaime G Carbonell", "Ralf D Brown", "Thomas Pierce", "Brian T Archibald", "Xin Liu"], "venue": "IEEE INTELL SYST,", "citeRegEx": "Yang et al\\.,? \\Q1999\\E", "shortCiteRegEx": "Yang et al\\.", "year": 1999}, {"title": "StatSnowball: a statistical approach to extracting entity relationships", "author": ["Jun Zhu", "Zaiqing Nie", "Xiaojiang Liu", "Bo Zhang", "Ji-Rong Wen"], "venue": "In Proceedings of WWW", "citeRegEx": "Zhu et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Zhu et al\\.", "year": 2009}], "referenceMentions": [{"referenceID": 24, "context": "For example, conceptual graph represents logic as a graph representation (Sowa, 1984).", "startOffset": 73, "endOffset": 85}, {"referenceID": 25, "context": "Large knowledge databases such as Yago (Suchanek et al., 2007), Freebase (Bollacker et al.", "startOffset": 39, "endOffset": 62}, {"referenceID": 5, "context": ", 2007), Freebase (Bollacker et al., 2008) are constructed, representing large knowledge in formalized forms.", "startOffset": 18, "endOffset": 42}, {"referenceID": 18, "context": "In this paradigm, weak supervision (Mintz et al., 2009; Xu and Zhao, 2014) and bootstrapping methods (Agichtein and Gravano, 2000; Kozareva and Hovy, 2010; McIntosh et al.", "startOffset": 35, "endOffset": 74}, {"referenceID": 27, "context": "In this paradigm, weak supervision (Mintz et al., 2009; Xu and Zhao, 2014) and bootstrapping methods (Agichtein and Gravano, 2000; Kozareva and Hovy, 2010; McIntosh et al.", "startOffset": 35, "endOffset": 74}, {"referenceID": 3, "context": ", TEXTRUNNER (Banko et al., 2007), KNOWITALL (Etzioni et al.", "startOffset": 13, "endOffset": 33}, {"referenceID": 13, "context": ", 2005, 2011), WOE (Hoffmann et al., 2010) and StatSnowBall (Zhu et al.", "startOffset": 19, "endOffset": 42}, {"referenceID": 29, "context": ", 2010) and StatSnowBall (Zhu et al., 2009).", "startOffset": 25, "endOffset": 43}, {"referenceID": 23, "context": "TwiCal extracts open-domain events from Twitter (Ritter et al., 2012), where events are identified by named entities.", "startOffset": 48, "endOffset": 69}, {"referenceID": 19, "context": "In the same data set, ET represents events as clusters of keywords (Parikh and Karlapalem, 2013).", "startOffset": 67, "endOffset": 96}, {"referenceID": 17, "context": "Piskorski et al. (2011) presents an on-line news event extraction system.", "startOffset": 0, "endOffset": 24}, {"referenceID": 17, "context": "Piskorski et al. (2011) presents an on-line news event extraction system. Each event is defined as a frame with slots filled by information extracted from clustered documents, where the pattern matching method is used. Ramakrishnan et al. (2014) proposes an EMBERS system encoding events as frames.", "startOffset": 0, "endOffset": 246}, {"referenceID": 13, "context": "Kuzey et al. (2014) uses events itself as nodes of network.", "startOffset": 0, "endOffset": 20}, {"referenceID": 2, "context": "Angel et al. (2012) constructs an entity network from social media by the streaming edge weight method.", "startOffset": 0, "endOffset": 20}, {"referenceID": 2, "context": "Angel et al. (2012) constructs an entity network from social media by the streaming edge weight method. They mine dense subgraphs of network for identifying realtime stories. Das Sarma et al. (2011) provides an event discovery method based on entity dynamic relation graphs, which are constructed by co-occurrences of entities constrained in documents.", "startOffset": 0, "endOffset": 199}, {"referenceID": 12, "context": "Text understanding may lead to worsen performance caused by applied techniques (Hobbs and Riloff, 2010).", "startOffset": 79, "endOffset": 103}, {"referenceID": 20, "context": "We use LDA toolkit provided by Phan and Nguyen (2007) to implement this task.", "startOffset": 31, "endOffset": 54}, {"referenceID": 6, "context": "We use Omni-word feature proposed by Chen et al. (2014), which takes every potential word as terms of documents.", "startOffset": 37, "endOffset": 56}, {"referenceID": 28, "context": "It is recognized that documents discussing the same event tend to be temporal proximity, and a time gap between bursts of similar documents may indicate different events (Yang et al., 1999).", "startOffset": 170, "endOffset": 189}, {"referenceID": 6, "context": "To recognize relations between named entities, we adopt the method proposed in Chen et al. (2014), where an Omni-word feature and a soft constraint method is proposed for Chinese relation extraction.", "startOffset": 79, "endOffset": 98}, {"referenceID": 6, "context": "In the follows, in order to conduct event network analysis, we use the igraph toolkit provide by Csardi and Nepusz (2006), representing extracted entity mentions and relations as a graph.", "startOffset": 97, "endOffset": 122}, {"referenceID": 4, "context": "A network analysis toolkit (Pajek) provided by Batagelj and Mrvar (1998) is used for visualization.", "startOffset": 47, "endOffset": 73}, {"referenceID": 9, "context": "Recognizing an \u201cevent\u201d under the ACE definition is difficult, where event triggers, participant roles, properties and attributes should be identified (Doddington et al., 2004).", "startOffset": 150, "endOffset": 175}, {"referenceID": 9, "context": "In our application, we monitor the \u201cConflict\u201d ACE event type, which has two substype: Attack and Demonstrate (Doddington et al., 2004).", "startOffset": 109, "endOffset": 134}, {"referenceID": 1, "context": "It received an ACE value score only 30% in Ahn (2006). In an open field, it will come to worse performance.", "startOffset": 43, "endOffset": 54}, {"referenceID": 1, "context": "It received an ACE value score only 30% in Ahn (2006). In an open field, it will come to worse performance. In many researches, co-occurrence information (e.g. co-citation, co-word, co-link, etc.) between terms is used to explore and understand structures in the underlying document sets, e.g., Leydesdorff and Vaughan (2006). In our application, instead of the definition in ACE, we present the action analysis.", "startOffset": 43, "endOffset": 326}], "year": 2015, "abstractText": "In this paper, an event network is presented for exploring open information, where linguistic units about an event are organized for analysing. The process is divided into three steps: document event detection, event network construction and event network analysis. First, by implementing event detection or tracking, documents are retrospectively (or on-line) organized into document events. Secondly, for each of the document event, linguistic units are extracted and combined into event networks. Thirdly, various analytic methods are proposed for event network analysis. In our application methodologies are presented for exploring open information.", "creator": "LaTeX with hyperref package"}}}