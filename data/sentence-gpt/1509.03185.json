{"id": "1509.03185", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "10-Sep-2015", "title": "Use it or Lose it: Selective Memory and Forgetting in a Perpetual Learning Machine", "abstract": "In a recent article we described a new type of deep neural network - a Perpetual Learning Machine (PLM) - which is capable of learning 'on the fly' like a brain by existing in a state of Perpetual Stochastic Gradient Descent (PSGD). Here, by simulating the process of practice, we demonstrate both selective memory and selective forgetting when we introduce statistical recall biases during PSGD. Frequently recalled memories are remembered, whilst memories recalled rarely are forgotten. The present paper illustrates the ability of these memories to improve neural networks in the context of the current state of Perpetual Stochastic Gradient Descent. We also demonstrate the capability of memory-enhancing memory-enhancing memory-enhancing memory-enhancing memory-enhancing memory-enhancing memory-enhancing memory-enhancing memory-enhancing memory-enhancing memory-enhancing memory-enhancing memory-enhancing memory-enhancing memory-enhancing memory-enhancing memory-enhancing memory-enhancing memory-enhancing memory-enhancing memory-enhancing memory-enhancing memory-enhancing memory-enhancing memory-enhancing memory-enhancing memory-enhancing memory-enhancing memory-enhancing memory-enhancing memory-enhancing memory-enhancing memory-enhancing memory-enhancing memory-enhancing memory-enhancing memory-enhancing memory-enhancing memory-enhancing memory-enhancing memory-enhancing memory-enhancing memory-enhancing memory-enhancing memory-enhancing memory-enhancing memory-enhancing memory-enhancing memory-enhancing memory-enhancing memory-enhancing memory-enhancing memory-enhancing memory-enhancing memory-enhancing memory-enhancing memory-enhancing memory-enhancing memory-enhancing memory-enhancing memory-enhancing memory-enhancing memory-enhancing memory-enhancing memory-enhancing memory-enhancing memory-enhancing memory-enhancing memory-enhancing memory-enhancing memory-enhancing memory-enhancing memory-enhancing memory-enhancing memory-enhancing memory-enhancing memory-enhancing memory-enhancing memory-enhancing memory-enhancing memory-enhancing memory-enhancing memory-enhancing memory-enhancing memory-enhancing memory-enhancing memory-enhancing memory-enhancing memory-enhancing memory-enhancing memory-enhancing memory-enhancing memory-enhancing memory-", "histories": [["v1", "Thu, 10 Sep 2015 15:12:00 GMT  (316kb)", "http://arxiv.org/abs/1509.03185v1", "arXiv admin note: substantial text overlap witharXiv:1509.00913"]], "COMMENTS": "arXiv admin note: substantial text overlap witharXiv:1509.00913", "reviews": [], "SUBJECTS": "cs.LG", "authors": ["andrew j r simpson"], "accepted": false, "id": "1509.03185"}, "pdf": {"name": "1509.03185.pdf", "metadata": {"source": "CRF", "title": "Use it or Lose it: Selective Memory and Forgetting in a Perpetual Learning Machine", "authors": ["Andrew J.R. Simpson"], "emails": ["Andrew.Simpson@Surrey.ac.uk"], "sections": [{"heading": null, "text": "neural network\u2013 a Perpetual Learning Machine (PLM) \u2013 which is capable of learning \u2018on the fly\u2019 like a brain by existing in a state of Perpetual Stochastic Gradient Descent (PSGD). Here, by simulating the process of practice, we demonstrate both selective memory and selective forgetting when we introduce statistical recall biases during PSGD. Frequently recalled memories are remembered, whilst memories recalled rarely are forgotten. This results in a \u2018use it or lose it\u2019 stimulus driven memory process that is similar to human memory.\nIndex terms\u2014Perpetual Learning Machine, Perpetual Stochastic Gradient Descent, self-supervised learning, parallel dither, forgetting.\nI. INTRODUCTION\nDeep neural networks (DNN) have long aimed at replicating human intelligence but still fail to capture some important features: DNN do not learn \u2018on the fly\u2019, do feature emergent memory and they do not forget. To account for emergent memory, we recently introduced a new type of DNN \u2013 a Perpetual Learning Machine (PLM) \u2013 which is capable of on-the-fly learning [1]. The PLM exists in a state of Perpetual Stochastic Gradient Descent (PSGD) and provides a unified architecture for learning and memory represented within the weights of the model.\nA remaining key difference between machine learning and human learning is the concept of practice. The maxim \u2018use it or lose it\u2019 invokes the role of practice in human learning and memory \u2013 what we do not practice we forget. Furthermore, memory is cumulative with practice \u2013 what we practice most, we remember best. Therefore, both learning and forgetting are selective processes and practice is the selection mechanism. This selectivity is not captured by either the standard DNN or the PLM, both of which essentially converge upon a uniform state of learning across whatever set of memorable data or classes. To restate, the concept of practice combines both learning and statistics \u2013 what we learn frequently, we memorise. Thus, since learning results in memory in the PLM, we may hypothesise that a combination of frequentist statistics and learning will result in selective learning and selective forgetting in the PLM.\nIn this article, we demonstrate that both learning and memory in a PLM may be biased by recall statistics during PSGD. Elements of the dataset which are statistically prioritised (commonly recalled) assimilate more rapidly and\nare remembered best during perpetual memory. Elements of the dataset not prioritised (rarely recalled) are forgotten.\nII. METHOD\nWe chose the well-known MNIST hand-written digit dataset [2]. First, we unpacked the images of 28x28 pixels into vectors of length 784. Example digits are given in Fig. 1. Pixel intensities were normalized to zero mean.\nOur PLM [1] involves two DNNs, one for storage and the other for recall. The storage DNN learns the classes of some training images. The recall DNN learns to synthesise the same images from the same classes. Together, the two networks hold, encoded, the training set. We then place these pair of DNNs in a self-supervised and homeostatic state of Perpetual Stochastic Gradient Descent (PSGD). During each step of PSGD, a random class is chosen and an image synthesised from the recall DNN. This randomly synthesised image is then used in combination with the random class to train both DNNs via non-batch SGD. I.e., the PSGD is driven by training data that is synthesised from memory according to random classes. In this article, we bias the statistics of this random perpetuation such that certain elements are learned more frequently than others. This allows us to measure the\neffect of this frequentist-statistical bias in terms of learning and memory.\nPerpetual Memory. We required our PLM to learn to identify a collection of images. We took the first 75 of the MNIST digits and assigned each to an arbitrary class (this is arbitrary associative learning). This gave 75 unique classes,\neach associated with a single, specific digit. The task of the model was to recognise the images and assign to them the correct (arbitrary) classes. We split the 75 digits randomly into three groups of equal size (25). We assigned each with a different probability of being selected during PSGD.\nStorage and Recall. We instantiated two DNN; the storage DNN was a typical classifier of size 784x100x75, with the softmax output layer corresponding to the 75-way classification problem. The storage DNN took images as input and produced classes as output. The recall DNN was of size 75x100x784, took classes as input and synthesised the training images at output. Both DNNs used biased sigmoids [3] throughout (with zero bias in the output layer).\nSelective learning. For the selective learning experiment, the storage DNN was trained using the 75 image classes. Each step of non-batch SGD training featured only a single class (i.e., SGD training was not batch averaged). The class was randomly chosen according to the statistical biases of the groups; group 1 was chosen with 80% probability, group 2 was chosen with 15% probability and group 3 was chosen with 5% probability. Training was performed (regularised) using parallel (100x) dither w/ dropout [as in 1,4,5].\nSelective forgetting. In the selective forgetting experiment, both storage and recall DNNs were independently trained (from random starting weights) on the entire 75 image classes without any statistical biases (i.e., non-batch SGD) for 100 full-sweep iterations. Classification error converged at 0.04% for the storage DNN, and at 0.04% for the storage DNN fed with the output of the recall DNN charged with synthesising the images of the respective test classes. Hence, the recall was suitably robust and was more or less visually indistinguishable from the original training images. Fig. 1 plots some example digits recalled (synthesised) using the recall DNN.\nPerpetual Stochastic Gradient Descent. Once the storage and recall DNNs were trained, the training images were discarded and the pair of models were subjected to PSGD (Fig. 2). The random selection of classes during PSGD was subject to the statistical biases of the three groups; group 1 was selected with 99% probability, group 2 was selected with 1% probability and group 3 was not selected at all (0% probability). Next, using this selectively biased random class, a respective image was synthesised using the recall DNN. This synthetic image was then combined with the random class and used together to train both DNNs in parallel (via non-batch SGD [1,5]). I.e., given the random seed, the recall DNN synthesised \u2013 from memory \u2013 the relevant training image and used it for self-supervision. This step of non-batch SGD also employed parallel dither w/dropout (100x). As in [1,4,5], all dither was random noise of zero mean and unit scale and dropout [6,5] was 50%.\nIn both experiments (selective learning and selective forgetting), classification accuracy of the storage DNN was tested at each iteration of PSGD. Each subgroup (of 25 image classes) was tested separately. This gave three dynamic measures of memory and recall that could be plotted as a function of time (iterations).\nIII. RESULTS\nFig. 3a plots the recall accuracy (classification error rate) of the storage DNN, trained from scratch, as a function of PSGD iterations for the various groups. The group selected with 80%\nprobability was learned fastest and the groups at 15% and 5% were learned proportionally more slowly. Hence, it is possible to introduce a selective bias to the learning phase such that commonly occuring elements are learned more quickly.\nFig. 3b plots the recall accuracy of the storage DNN, as a function of PSGD iterations, from the starting point of being fully trained using SGD and without any statistical biases. I.e., here, we start from the position of having memorised the whole dataset. The 99% recall group shows solid homeostasis throughout and does not deviate from zero error. Both the 1% and the 0% groups begin to increase in error (i.e., be forgotten) immediately but the 1% group recovers and reaches homeostasis at a relatively high level of error, while the 0% group continues to be increasingly forgotten without any signs of levelling off. Thus, during PSGD, the memory of the most probable image classes was maintained perfectly, whilst the less probable image classes were forgotten to a degree that was determined by their frequency of recall.\nIV. DISCUSSION AND CONCLUSION\nBy introducing selective statistical biases into the paths of PSGD, we have demonstrated both selective memory and selective forgetting in a Perpetual Learning Machine. We have equated learning with stochastic gradient descent, we have equated frequentist statistics with practice, and we have equated the emergent and selective result on perpetual memory with forgetting. Hence, it seems possible that a similar principle may be responsible for forgetting within the brain.\nACKNOWLEDGMENT\nAJRS did this work on the weekends and was supported by his wife and children.\nREFERENCES [1] Simpson AJR (2015) \u201cOn-the-Fly Learning in a Perpetual Learning\nMachine\u201d, arxiv.org abs/1509.00913. [2] LeCun Y, Bottou L, Bengio Y, Haffner P (1998) \u201cGradient-based\nlearning applied to document recognition\u201d, Proc. IEEE 86: 2278\u20132324. [3] Simpson AJR (2015) \u201cAbstract Learning via Demodulation in a Deep\nNeural Network\u201d, arxiv.org abs/1502.04042.\n[4] Simpson AJR (2015) \u201cDither is Better than Dropout for Regularising Deep Neural Networks\u201d, arxiv.org abs/1508.04826. [5] Simpson AJR (2015) \u201cParallel Dither and Dropout for Regularising Deep Neural Networks\u201d, arxiv.org abs/1508.07130. [6] Hinton GE, Srivastava N, Krizhevsky A, Sutskever I, Salakhutdinov R (2012) \u201cImproving neural networks by preventing co-adaptation of feature detectors\u201d, The Computing Research Repository (CoRR), abs/1207.0580."}], "references": [{"title": "On-the-Fly Learning in a Perpetual Learning Machine\u201d, arxiv.org abs/1509.00913", "author": ["AJR Simpson"], "venue": null, "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2015}, {"title": "Gradient-based learning applied to document recognition", "author": ["Y LeCun", "L Bottou", "Y Bengio", "P Haffner"], "venue": "Proc. IEEE", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 1998}, {"title": "Abstract Learning via Demodulation in a Deep Neural Network\u201d, arxiv.org abs/1502.04042", "author": ["AJR Simpson"], "venue": null, "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2015}, {"title": "Dither is Better than Dropout for Regularising Deep Neural Networks\u201d, arxiv.org abs/1508.04826", "author": ["AJR Simpson"], "venue": null, "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2015}, {"title": "Parallel Dither and Dropout for Regularising Deep Neural Networks\u201d, arxiv.org abs/1508.07130", "author": ["AJR Simpson"], "venue": null, "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2015}, {"title": "Improving neural networks by preventing co-adaptation of feature detectors\u201d, The Computing Research Repository (CoRR), abs/1207.0580", "author": ["GE Hinton", "N Srivastava", "A Krizhevsky", "I Sutskever", "R Salakhutdinov"], "venue": null, "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2012}], "referenceMentions": [{"referenceID": 0, "context": "To account for emergent memory, we recently introduced a new type of DNN \u2013 a Perpetual Learning Machine (PLM) \u2013 which is capable of on-the-fly learning [1].", "startOffset": 152, "endOffset": 155}, {"referenceID": 1, "context": "We chose the well-known MNIST hand-written digit dataset [2].", "startOffset": 57, "endOffset": 60}, {"referenceID": 0, "context": "Our PLM [1] involves two DNNs, one for storage and the other for recall.", "startOffset": 8, "endOffset": 11}, {"referenceID": 2, "context": "Both DNNs used biased sigmoids [3] throughout (with zero bias in the output layer).", "startOffset": 31, "endOffset": 34}, {"referenceID": 0, "context": "This synthetic image was then combined with the random class and used together to train both DNNs in parallel (via non-batch SGD [1,5]).", "startOffset": 129, "endOffset": 134}, {"referenceID": 4, "context": "This synthetic image was then combined with the random class and used together to train both DNNs in parallel (via non-batch SGD [1,5]).", "startOffset": 129, "endOffset": 134}, {"referenceID": 0, "context": "As in [1,4,5], all dither was random noise of zero mean and unit", "startOffset": 6, "endOffset": 13}, {"referenceID": 3, "context": "As in [1,4,5], all dither was random noise of zero mean and unit", "startOffset": 6, "endOffset": 13}, {"referenceID": 4, "context": "As in [1,4,5], all dither was random noise of zero mean and unit", "startOffset": 6, "endOffset": 13}, {"referenceID": 5, "context": "scale and dropout [6,5] was 50%.", "startOffset": 18, "endOffset": 23}, {"referenceID": 4, "context": "scale and dropout [6,5] was 50%.", "startOffset": 18, "endOffset": 23}], "year": 2015, "abstractText": "In a recent article we described a new type of deep neural network\u2013 a Perpetual Learning Machine (PLM) \u2013 which is capable of learning \u2018on the fly\u2019 like a brain by existing in a state of Perpetual Stochastic Gradient Descent (PSGD). Here, by simulating the process of practice, we demonstrate both selective memory and selective forgetting when we introduce statistical recall biases during PSGD. Frequently recalled memories are remembered, whilst memories recalled rarely are forgotten. This results in a \u2018use it or lose it\u2019 stimulus driven memory process that is similar to human memory.", "creator": "PDFCreator Version 1.7.1"}}}