{"id": "1509.05437", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "17-Sep-2015", "title": "Class Association Rules Mining based Rough Set Method", "abstract": "This paper investigates the mining of class association rules with rough set approach. In data mining, an association occurs between two set of elements when one element set happen together with another. A class association rule set (CARs) is a subset of association rules with classes specified as their consequences for class association rules, as opposed to a single set of elements, or classes specified in other contexts: the principal example of a class association rule that uses all of the above elements to control class association rules (as in this example). One example of a class association rule that uses all of the above elements to control class association rules is one that uses the principal example of a class association rule that uses all of the above elements to control class association rules (as in this example).\n\n\n\n\nThe principal example of a class association rule that uses all of the above elements to control class association rules (as in this example). A group consists of 2 members of the same class, and all of the above elements are bound to one another.\nThe principal example of a class association rule that uses all of the above elements to control class association rules (as in this example). A group consists of 2 members of the same class, and all of the above elements are bound to one another.\nThe principal example of a class association rule that uses all of the above elements to control class association rules (as in this example). A group consists of 2 members of the same class, and all of the above elements are bound to one another.\nThe principal example of a class association rule that uses all of the above elements to control class association rules (as in this example). A group consists of 2 members of the same class, and all of the above elements are bound to one another.\nA class association rule that uses all of the above elements to control class association rules (as in this example). A group consists of 2 members of the same class, and all of the above elements are bound to one another.\nEach of the above elements has a binding legal form: the principal example of a class association rule (as in this example). The principal example of a class association rule that uses all of the above elements to control class association rules (as in this example). A group consists of 2 members of the same class, and all of the above elements are bound to one another.\nEach of the above elements has a binding legal form: the principal example of a class association rule (as in this example). The principal example of a class association rule that", "histories": [["v1", "Thu, 17 Sep 2015 20:42:19 GMT  (207kb)", "http://arxiv.org/abs/1509.05437v1", "10 pages, 2 figures"]], "COMMENTS": "10 pages, 2 figures", "reviews": [], "SUBJECTS": "cs.DB cs.AI", "authors": ["thabet slimani"], "accepted": false, "id": "1509.05437"}, "pdf": {"name": "1509.05437.pdf", "metadata": {"source": "CRF", "title": "Class Association Rules Mining based Rough Set Method", "authors": ["Thabet Slimani"], "emails": ["thabet.slimani@gmail.com"], "sections": [{"heading": null, "text": "data mining, an association occurs between two set of elements when one element set happen together with another. A class association rule set (CARs) is a subset of association rules with classes specified as their consequences. We present an efficient algorithm for mining the finest class rule set inspired form Apriori algorithm, where the support and confidence are computed based on the elementary set of lower approximation included in the property of rough set theory. Our proposed approach has been shown very effective, where the rough set approach for class association discovery is much simpler than the classic association method.\nData Mining, RST, CAR, ARM, NAR, Bitmap, class association rules, Rough Set Theory\nI. INTRODUCTION\nata Mining (DM) is a modern area of research very useful in computer science. The objective of DM is to extract various models of interesting, hidden, and potentially useful knowledge from databases, where the\nvolume of collected data is huge. Knowledge exploited by data mining can be represented as rules, customs, patterns, trends, etc. DM [1] is a prominent tool which encloses several techniques: Association, Clustering, Classification and Deviation. Association rule mining (ARM) [2] is defined to extract the important correlation and relation included in large amount of data. Association rule mining aims to find interesting relationships from the data in the form of rules. ARM, are originally applied on market basket analysis seeking to study the buying habits of customers [3]. Interesting association rules discovery can be used to help the decision making process. As a formal definition, an association rule is a relation in the form of implication A B between two disjunctive sets of items A and B. A typical example of an association rule on \"market basket data\" is that \"80% of customers who purchase spaghetti also purchase sauces \". Two quality measurements characterize each rule, support and confidence. The expression if A then B (A B) is a regular association rule for attribute sets A and B (with some confidence). Consequently, an association rule A B is regular means that if A maximally then B maximally [4]. More deeply, the rule A B has confidence CF if CF% of transactions in the set of transactions D that contains A also\ncontains B. The rule A B has support SP if SP% of transactions in D contains A B. To find regular association rules is a problem to find all association rules having a support and a confidence greater than the threshold of minimum support specified by an expert (called MinS) and threshold of minimum confidence (called MinC ) respectively. Additionally, ARM can be exploited in information retrieval where there exist a need to identify association between keywords. Different types of association rules can be enumerated: rules-based types of values handled, rules-based levels of abstraction handled and rules-based dimensions of data involved. The first type can be classified into Boolean or quantitative association rules and the second type can be classified into single-level and multi-level association rules. In multidimensional database, ARM can be classified into single dimensional association rules (SDAR) and multidimensional association rules (MDAR). A single distinct predicate with multiple occurrences is referred to us as SDAR where transactional data is used. The terminology of single dimensional is used to consider each distinct predicate in the rule as a dimension. More specifically, items in a rule are assumed to belong to the same transaction. For instance, in market basket analysis, the SDAR representation of the Boolean association rule \u201cdiapers \u21d2 beer\u201d can be written as follows [5]:\nD\nFigure1: Association Rule Mining Types Tree"}, {"heading": "R1: buys(x, \"diapers\") \u21d2 buys(x, \"beer\") [10% (supp), 70% (conf)].", "text": "The MDAR representation uses relational data where an Attribute X in a rule is assumed to have value x, attribute Y has the value y and attribute Z has the value z in the same tuple. For instance, in market basket analysis, with the same example of the SDAR representation, it considers items in the rule varies from two to more dimensions or predicates, e.g. \"buys\", \" transaction_time\", \"customer_category\". For instance, R2 is an example of MDAR: R2: Age(A,\u201d20..29\u201d) \u2227 income(A,\u201d60K..80K\u201d) \u21d2 buys(A, High Resolution TV) The Rules that concern associations between the presence or absence of items are Boolean rules: For e.g. \"buys an item A\" or \"does not buy an item A\" (e.g. R3)"}, {"heading": "R3: buys(x, \"A\") ^ buys(x, \"B\") \u21d2buys(x, \"C\") [0.2%, 60%]", "text": "The rules that concern associations between quantitative items or attributes are quantitative rules. For instance, R4 is an example of quantitative association rules:"}, {"heading": "R4: age(x, \"20..29\") ^ income(x, \"18..38K) \u21d2 buys(x, \"PC\") [1%, 80%]", "text": "Rough set theory can be used for data mining when the available information is insufficient to determine the exact value of a given set, based on lower and upper approximations for the representation of a concerned set [6]. By using this theory, it is possible to extract rules that are similar to normal associations. However, we investigate the rough set approach to discover class association rules and we show that this approach is simpler than the classic association method. The paper is structured as follows: Section 2 describes ARM background which explains data preparation for further process with rough set approach. Additionally, it discusses the meaning of itemset, support and confidence of rule, how to transform relational schema into bitmap table and the meaning of class association rules. Section 3, presents the rough set model and its applications. Section 4 discusses how to apply RST to class association rules, how to represent data with RST and the algorithm C_Apriori adopted for CAR mining. Finally, section 5 concludes the paper.\nII. BACKGROUND\nAgrawal et al. [3] is the first author that introduces Association Rule Mining that begins a well-known data mining research field. The main idea is to extract common model of mined knowledge under format of Association Rules set (ARs) based on data stored in transactional database D. Let I = {i1, i2, \u2026, in\u20131, in} be a set of items or database attributes, and T = {t1, t2, \u2026, tm\u20131, tm} be a set of transactions or database records, T describe D, where each tj \u2208 T includes the items in the set I\u2032 \u2286I.\nARM\nRules-based dimension Rules-based levels of abstraction Rules-based types of values\nBoolean\nQuantitative\nSinglelevel\nMultilevel\nSDAR\nMDAR\nThe implication of co-occurring relationship between two sets of items in D is what it defines an association rule. However, an association rule is expressed in the form of the implication: \u201cantecedent (A) \u21d2 consequent (B)\u201d, where A, B \u2286 I and A \u2229 B=\u00d8. There are two ways to measure the usefulness of an association rule: objective and subjective measures. Objective measures involve two threshold values that are commonly used in ARM to measure the significance of an association rule: Support: An itemset is formed by a set of items S. The proportion of transactions T\u2019 in T for which S\n\u2286 T is the support of S. The rule R (A B) occurs with support s if s% of transaction in D contains A B. The rule that have a support s greater than a user-supplied support threshold (\u03c3) is defined to be significant (have minimum support).\nConfidence: It is based on a user-supplied confidence threshold \u03b1, and aims to discover how \u201cstrongly\u201d a rule antecedent A implies another rule consequent B. The association rule A B occurs with confidence c if c% of the transactions in D containing A also contains B. The association rule A B is said to be valid if the support for the A and B co-occurrence exceeds \u03c3, and the confidence of this association rule exceeds \u03b1.\nThe support is computed as follows:\nS(A \u222a B) = |A \u222a B| / |T | (1)\nWhere |A \u222a B| is the transactions number containing the set A \u222a B in T, and |T | is the cardinality of the set T. The confidence is computed as follows:\nC(A \u21d2 B) = S(A \u222a B) / S(A) (2)\nApriori algorithm is mainly the well-known ARM algorithm, developed by Agrawal and Srikant [3], which represents the basis of various subsequent ARM algorithms."}, {"heading": "A. Relation Table Types", "text": "Generally, the process of association rules discovery uses a single table (relation) as a source of data that represents relations between items. Formally, a relation is a relational table R that includes a set of tuples (t1,t2,\u2026ti,\u2026tn), where ti represents the i-th tuple. A relation R can be either accompanied with binary domain or no-binary attributes. As an example of a relation RL1 with binary attributes: the presence of a computer item in a transaction or its absence represents its domain {sold, not sold}. An attribute Aj is non-binary domain is\nrepresented by j items and binary vectors such that n is the number of attributes of the non-binary domain. For example, for the better representation of a customer wealth level, we associate to the attribute\n\u201cincome\u201d the domain constituted by 3 (j=3) items {high, medium, low} defined as follows: a1 = {\u201chigh income\"}, a2 = {\u201cmiddle income\"} and a3 ={\u201clow income\u201d}."}, {"heading": "B. Bitmap Representation", "text": "A relation or table uses as data source for ARM approach, some attributes are measurable with discrete variable as some numerical or textual values on behalf of some range. However, the form of original data representation could be changed exactly so that, each attribute in the new Bitmap table is an exact value of one item in original table, and each attribute value should be 1 or 0, expressing if it exist there is a \u20181\u2019, otherwise a \u20180\u2019 in the bitmap table[7]. Let be the example of table 3 where attributes representing data are {X}, {Y} and {Z}. The attribute X has two values {A and B} = {Account debited, Account credited}, the attribute Y has three values {C, D and E} = {low income, high income, middle income} and the attribute Z has two values {F, G} = {according loan, not according loan}. There are 7 items for the resultant Bitmap table {A, B, C, D, E, F and G}.\nTABLE III\nThe conversion of original relation data as Bitmap table is figured in table 4 as follows:\nTABLE IV"}, {"heading": "C. Class Association Rules (CARs)", "text": "Let be T a set of n transactions. Each transaction us labelled by a class y. The set of all items in T is labelled by\nand the set of class labels is labelled by Y where I Y=\u00d8. A class association rule (CAR) is an implication of\nthe form: A B where A The following table give a comparison between normal association rules (NAR), denoted above by ARM, and class association rules (CAR):\nTABLE V\nMining CARs is an objective to generate the complete set of CARs satisfying a user-specified minimum support and minimum confidence constraint.\nIII. ROUGH SET\nRough set theory (RST) is a useful mathematical method that deals with inconsistency problems developed by Pawlak in 1982 [8]. RST is defined as an extension of the conventional set theory that supports approximations in decision Making [8]. The rough set is the approximation of a vague concept (set) by a pair of fixed concepts classifying a specified domain into disjoint categories named lower and upper approximations. The lower approximation describes the domain objects which are known with certainty to belong to the subset of interest, whereas the upper approximation describes the objects which possibly belong to the subset. The theory of rough sets is described formally in the work of [8][9]. The concept of RST is described as follows:\nLet be the universe a finite set of objects for that any subset A of the universe is called a concept\nin and representing each knowledge by any family of concepts contained in . The family of classifications\nover the universe refers the knowledge base over . The formal foundation of RST is based on the fact to consider the \u201cuniverse\u201d as a finite set. In database systems, the meaningfulness of updating sets (insert, delete and join) is interesting in several database applications.\nMore formally, let be R an equivalence relation over such that R A\u00d7A, then the following properties should be considered: R is reflexive: aRa, R is symmetric: if aRb then bRa R is transitive (if aRb and bRc then aRc)\n/R denotes the family of equivalence classes of R and aR denotes the category in R that contains an element a\nincluded in Let be KB=( denotes the knowledge base and B a non empty subset of the set A of all attributes, then the equivalence relation R(B) is called the indiscernibility relation over B representing a binary\nrelation on defined for x,y . Because, information table (relational data) contains attributes and domains, a set Va is associated to every attribute a \u2208 A (its values) and called the domain of a.\nAny subset B of A determines a binary relation R(B) on and is defined as follows: xR(B)y if and only if a(x)=a(y) for each a \u2208 A , where a(x) indicates the attribute value a for element x. Complementary mathematical properties have been explored by the current research in RST. As instance, after studying the ordered set of rough set theory, the author in [10] shows that the relations are not essentially reflexive, symmetric or transitive."}, {"heading": "A. Approximations", "text": "As defined before, as starting point of RST, the indiscernibility relation is intended to express the fact that due to the lack of knowledge, but it is unable to distinguish some objects employing the available information. RST includes another important concept which is Approximations. Approximation is also associated with the meaning of the approximations of topological operations [11]. The types of approximations exploited in Rough Sets Theory are described below:\n1. Lower Approximation (B*): The description of the domain object known with certainty to belong to the subset of interest defines the lower approximation (LA). Additionally, the LA Set (B*) of a set X regarding to R is the set containing all the objects, which surely can be classified with X regarding R. 2. Upper Approximation (B*): The objects that possibly belong to the subset of interest define the upper approximation (UA). Moreover, the UA Set (B*) of a set X with regard to R is the set containing all the objects that, possibly, can be classified with X regarding R. 3. Boundary Region (BR): The set of all the objects, contained in a set X with regard to R, which cannot be classified neither as X nor -X regarding R is the definition of BR.\nBR is a crisp set (exact in relation to R), if the BR is a set X =\u2205 (Empty); otherwise BR is a rough set = B* - B*, if the boundary region is a set X \u2260 \u2205. More formally, let a set X \u2286 , B be an equivalence\nrelation and a knowledge base K = ( ,B). Two subsets can be associated:\n1. B-lower: B*= \u222a {Y \u2208 /B : Y \u2286 X} 2. B-upper: B*= \u222a {Y \u2208 /B : Y \u2229 X \u2260 \u2205}\nSimilarly, POS(B), BN(B) and NEG(B) are defined below [8]. 3. POS(B) = B*\u21d2 certainly member of X 4. NEG(B) = \u2013B* \u21d2 certainly non-member of X 5. BR(B) = B* - B* \u21d2 possibly member of X.\nFig1: B-approximation sets and B-regions Definition"}, {"heading": "B. RST Applications", "text": "Several properties of RST that make the theory an evident choice for use to deal with real problems: a brief overview of some of the many applications of rough set is presented in the following section: Pattern Recognition: As an application of pattern recognition, Mrozek and Cyran [12] proposed, in\n2001, a hybrid method of automatic diffraction pattern recognition based on RST and Neural Network. This new method uses RST to define the objective function and stochastic evolutionary algorithm for space search of a feature extractor. The neural networks are used for uncertain systems modeling. Acoustical analysis: An application based on the RST is used to induce generalized rules describing the relationship between acoustical parameters of concert halls and sound processing algorithms is described in the work of Kotek in 1999 [13]. Classification of spatial and meteorological pattern: the current sunspot recognition and classification systems are manual and if successfully learned by a machine, the labor intensive processes begin automated. The approach proposed in [14] by Nguyen et al. in 2005 employs a hierarchical rough set based learning method for sunspot classification. The aim of this system is to learn the modified Zurich classification scheme adopting rough set-based decision tree induction. The evaluation of the proposed system based on sunspots extracted from satellite images, presents promising results. Another work adopting RST approach is developed by Shen&Jensen in 2007 [15] to classify a number of meteorological storm events. Intelligent control systems: The intelligent control system especially when incorporated with fuzzy theory is an important application field of rough set theory [16].\nIV. RST APPLIED TO CAR\nA. Data representation with RST\nThe format, often, used to present data is table format, where each column indicates an attribute and each row indicates an object of interest and each entry of the table contains an attribute value. Such tables are composed of information systems, attribute-value tables and information tables. In this paper, we will adopt the\nB*\nB*\nNEG(B)\nBR(B)\nPOS(B)\ninformation table format, where the columns represent variables and rows represents cases (objects). All variables in information tables are called attributes. The main problems that can be undertaken by the use of RST are the following:\nA set of object can be characterized in terms of attribute values. It is possible to find association rules between items in Y and I. Generation of association rules\nAn example of information table is presented in Table 5 with two classes Y={Sport and Education} and seven text documents. Each document is a transaction and consists of a set of keywords. Additionally, each transaction is labelled with a topic class in Y. The set of keywords is denoted by the items in I={Student, Teach, School, City, Game, Baseball, Basketball, Team, Coach, Player, Spectator}.\nTABLE VI Example of illustrative data set containing documents and their classes.\nThe set represents all the possible cases, the set of all attributes denoted by A, and the set of all attribute\nvalues denoted by V. An information table defines an information function I: \u00d7 A \u2192 V.\nPawlak have presented a formal definition of a decision table, in 1982. A decision table is a system S= ( , A, V, f) where:\nAn attribute-value is denoted by the pair = (a, v) where a\u2208 A, v\u2208 V. [ ] denotes a block, including the set of\nall cases in where each attribute a has a value v. In ARM approach, the support measure of an attribute, compute the existence of an attribute in a specified row, then the support of an attribute-value pair is obtained by\nthe cardinality of [ ] and denoted by |[ ]|. Based on the example in the Table 6, blocks and their related support are defined as follows:\n[ ]1: [{Student}] = {1, 2}, and support([ ]1)=2\n[ ]2:[ {School}] = {1,2,3}, and support([ ]2)=3\n[ ]3:[ {Spectator}] = {5}, and support([ ]3)=1\n[ ]4:[ {Basketball}] = {4, 5, 7}, and support ([ ]4)=3\n[ ]5=[{Game}] = {3,6, 7}, and support ([ ]5)=3\n[ ]6=[ {Baseball}] = {4,6}, and support ([ ]6)=2\n[ ]7=[{Student, School}] = {1, 2}, and support([ ]7)=2\n[ ]8=[{Team}] = {6, 7}, and support([ ]8)=2\nDoc\nid Transaction Class\n1 Student, Teach, School Education\n2 Student, School Education 3 Teach, School, City, Game Education 4 Baseball, Basketball Sport 5 Basketball, Player, Spectator Sport 6 Baseball, Coach, Game, Team Sport 7 Basketball, Team, City, Game Sport\nLet be x\u2208 and B \u2286 A. We denote the elementary set of B containing x by [x]B, represented by the following\nset:\nLet be the subset of containing all cases from that are indistinguishable from x while using all attributes from B the elementary sets. Elementary sets are called information granules in the terminology of soft computing. Element sets are blocks of attribute-value pairs represented by that specific attribute, while subset B is limited to a single attribute, Consequently, [{Game}]={3,6,7} [{Player}]={ 5} To combine two attribute-values, for example, the elementary set of B with two attributes is defined as follows:\n{[ ]1 [ ]2}=[{Student, School}]={1,2}, and support ([ ]1 [ ]2)=2\n{[ ]5, [ ]8}=[{Game,Team}]={6,7}, and support ([ ]5 [ ]8)=2\nB. Class association rules Algorithm\nB.1. Class association rules between items\nCARs can be mined directly in a single step, unlike the normal association rules. The aim is to find all rules\nhaving a support greater than minsupp, and for that reason a rule is of the form: (i, y) where i (set of items)\nand y (a class label). The support and the confidence of a class association rules are denoted, respectively, by S and C as follows:\nS\nWhere B* is the upper approximation in term of rough set theory representing the items in the condition of the\nrule and the number of the items i occurring in conjunction with a label y across the\ntransactions in the table and indicates the number of all the transactions in the table.\nC\nWhere denotes the number of the items i in the condition of the association occurring across the\ntransactions in the table. Let be a class association rule defined as follows: CR={Student, School Education}. The elementary set of B in the condition of the rule contains two attributes and is defined as follows:\n{condSet}={[ ]c}=[{Student, School}]={1,2}, and support ([ ]c)=2\n{decSet}={ [ ]d}=[{education}]={1,2,3} and support { [ ]d}=3\nSupport of CR= support {condSet decSet} =support{[ ]c,[ ]d}=support{1,2}=2\nThen the support of (CR) is 2/7=28%.\nThe confidence of CR is the S(CR)/support ([ ]c)=2/2=1. However, as these explained by the previous examples, the rough set approach to discover CAR is much simpler than the normal association method presented in the beginning of this paper.\nB.2. CAR mining Algorithm\nThe algorithm generating class association rules is denoted by C_Apripori which is based on Apriori algorithm. C_Apriori generates all the frequent rules making multiple passes over data resembling the Apriori algorithm. In the first pass, it counts the support of each 1-ruleitem (containing one item in its condition set). The set of all ruleitems (1-candidate) is denoted by the following expression:\nC0={({i},y)|i and y }\nAlgorithm C_Apriori\n1 Discretization of data, k=0; 2 Ckinit ( ) ; //first pass over database 3 Fk{f|f C0, f.support minsupp}; 4 CRk{f|f Fk , f.confidence minconf} ; k++ 5 for (i=k ; Fk-1 ; i++) do 6 CiCAcandidate-gen(Fi-1); 7 for each transaction t do\n8 for each c Ci do 9 if (c.Condset is included in t) then 10 c.condsupport++ 11 if(t.class=c.class) then 12 CRi.support++ 13 endfor"}, {"heading": "14 endfor", "text": "15 Fi{c Ci|c.support minsupp} ; 16 CAi{f|f F, f.support minconf} ; 17 endfor 18 return CA iCAi The instruction in line 3 indicates whether the candidate 1-ruleitems are frequent or no and we generate 1- condition CR (rule with unique condition) from the identified 1-ruleitem. In the next pass i, the algorithm C_Apriori starts with the beginning set of (i-1)-ruleitems established as frequent in the (i-1)-pass, and uses this beginning set to generate other new frequent k-ruleitems (Ci in line 6). The support counted for both the condition rule and the rule are updated continuously during the scan of the data for each i-ruleitem. The objective behind the overall data scan is to find which of the actually frequent candidate k-ruleitem in Ci (line 15). And finally, in line 16, the C_Apriori algorithm generates i-condition CA (class association rules with i conditions). The CAcandidate-gen is very similar function to the candidtae-gen function in the Apriori algorithm. The unique difference is that in CAcandidate-gen ruleitems joins the condition sets aiming to join the ruleitems with same class.\nV. CONCLUSION\nThis paper proposes an approach based RST for class association rule mining. Mining class association rules with the proposed C_Apriori algorithm is easy and efficient. It computes the support and the confidence in a similar manner to the elementary set of lower approximation included in the RST approach. C_Apriori is more easily compared to the classic Apriori algorithm, where the process of frequent itemsets searching based on the concept of equivalence class is very simple. In future we will investigate the Bitmap structure to convert dataset to structured data where items are denoted by binary representation, and each line (transaction) is converted to a binary number.\nREFERENCES\n[1] K. J. Cios, W. Pedrycz, R.W. Swiniarski, & L.A. Kurgan. Data mining: A knowledge discovery approach. New York, NY: Springer. [2] X. Liu, K. Zhai, & W. Zhai. An improved association rules mining method. Expert Systems with Applications, 39(1), 1362\u20131374.\ndoi:10.1016/j. eswa.2012.\n[3] R.Agrawal, R. Imielinski & A.Swami. Mining associations between sets of items in massive databases. In Proceedings of the ACM\nSIGMOD Conference on Management of Data, Washington, DC (pp. 207-216), 1993.\n[4] R Feldman, Y. Aumann, A. Amir, A. Zilberstain, W. Kloesgen, Y.Ben-Yehuda. Maximal association rules: a new tool for mining for\nkeyword cooccurrences in document collection, in Proceedings of the 3rd International Conference on Knowledge Discovery (KDD 1997), pp.167-170, 1997.\n[5] J. Han, K.Micheline, Data Mining: Concepts and Techniques, the Morgan Kaufmann Series, 2001. [6] S.Thabet. International journal of Computer Science & Network Solutions. 1(3), pp. 1-10, 2013. [7] M.Jurgens, and H.J.Lenz. Tree Based Indexes Versus Bitmap Indexes: A Performance Study. International Journal of Cooperative\nInformation Systems, 10, pp.355\u2013376, 2001.\n[8] Z.Pawlak. \u201cRough Sets\u201d, International Journal of. Computer and Information Sciences, Vol.11, 341-356, 1982. [9] J.Komorowski, L.Polkowski, A.Skowron. Rough sets: A tutorial, in: S.K. Pal, A. Skowron (Eds.), Rough Fuzzy Hybridization \u2014 A\nNew Trend in Decision Making, Springer, pp. 3-98, 1999.\n[10] J.Jarvinen. The ordered set of rough sets, in: S. Tsumoto, et al. (Eds.), RSCTC, in: Proceedings LNAI, vol. 3066, Springer, pp. 49-58,\n2004.\n[11] C.Wu, Y.Yue, M.Li & O.Adjei. . The Rough Set Theory and Applications, Engineering Computations, Vol. 21, No. 5, pp.488-511,\nISSN 0264-4401, 2004.\n[12] A.Mrozek, K. Cyran. Rough Set in Hybrid Methods for Pattern Recognition, International Journal of Intelligence Systems, Vol. 16.\nNo. 2, Feb. pp.149-168, ISSN 0884-8173, 2001.\n[13] B. Kostek. Assessment of Concert Hall Acoustics using Rough Set and Fuzzy Set pproach, In: Rough Fuzzy Hybridization: A New\nTrend in Decision-Making, Pal, S. & Skowron, A. (Ed.), pp. 381-396, Springer-Verlag Co., ISBN 981-4021-00-8, Secaucus-USA,\n1999.\n[14] S.H. Nguyen, T.T.Nguyen & H.S. Nguyen. Rough Set Approach to Sunspot Classification Problem, Proceedings of the 2005\nInternational Conference on Rough Sets, Fuzzy Sets, Data Mining and Granular Computing - Lecture Notes in Artificial Intelligence 3642, 2005, pp. 263\u2013272, ISBN 978-3-540-28653-0, Regina-Canada, Aug. 31-Sept. 3, Springer, Secaucus-USA, 2005. [15] Q. Shen & R.Jensen. Rough Sets, Their Extensions and Applications, International Journal of Automation and Computing, Vol. 4, No.\n3, pp. 217-228, ISSN 1476-8186, 2007\n[16] G. Xie, F.Wang. & K.Xie. RST-Based System Design of Hybrid Intelligent Control, Proceedings of the 2004 IEEE International\nConference on Systems, Man and Cybernetics, pp. 5800-5805, ISBN 0-7803-8566-7, The Hague-The Netherlands, Oct. 10-13, IEEE Press, New Jersey-USA, 2004.\nAUTHOR PROFILE\nDr. Thabet Slimani got a PhD in Computer Science (2011) from the University of Tunisia. He is currently an Assistant Professor of Information Technology at the Department of Computer Science of Taif University at Saudia Arabia, where he is involved both in research and teaching activities. His research interests are mainly related to Semantic Web, Data Mining, Business Intelligence, Knowledge Management and recently Web services. Dr.Thabet is the author of some programming books and has published his research through international conferences, chapter in books and peer reviewed journals. He also serves as a reviewer for some conferences and journals."}], "references": [{"title": "An improved association rules mining method", "author": ["X. Liu", "K. Zhai", "W. Zhai"], "venue": "Expert Systems with Applications,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2012}, {"title": "Mining associations between sets of items in massive databases", "author": ["R.Agrawal", "R. Imielinski", "A.Swami"], "venue": "In Proceedings of the ACM SIGMOD Conference on Management of Data,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 1993}, {"title": "Maximal association rules: a new tool for mining for keyword cooccurrences in document collection", "author": ["R Feldman", "Y. Aumann", "A. Amir", "A. Zilberstain", "W. Kloesgen", "Y.Ben-Yehuda"], "venue": "Proceedings of the 3rd International Conference on Knowledge Discovery (KDD 1997),", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 1997}, {"title": "K.Micheline, Data Mining: Concepts and Techniques, the Morgan", "author": ["J. Han"], "venue": null, "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2001}, {"title": "Rough Set in Hybrid Methods for Pattern Recognition, International", "author": ["A.Mrozek", "K. Cyran"], "venue": "Journal of Intelligence Systems,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2001}, {"title": "Assessment of Concert Hall Acoustics using Rough Set and Fuzzy Set pproach, In: Rough Fuzzy Hybridization: A New Trend in Decision-Making", "author": ["B. Kostek"], "venue": "Secaucus-USA,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 1999}, {"title": "Rough Set Approach to Sunspot Classification Problem, Proceedings of the 2005 International Conference on Rough Sets, Fuzzy Sets, Data Mining and Granular Computing ", "author": ["S.H. Nguyen", "T.T.Nguyen", "H.S. Nguyen"], "venue": "Lecture Notes in Artificial Intelligence", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2005}, {"title": "Rough Sets, Their Extensions and Applications, International", "author": ["Q. Shen", "R.Jensen"], "venue": "Journal of Automation and Computing,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2007}, {"title": "AUTHOR PROFILE Dr. Thabet Slimani got a PhD in Computer Science (2011) from the University of Tunisia. He is currently an Assistant Professor of Information Technology at the Department of Computer Science of Taif University at Saudia Arabia, where he is involved both in research and teaching activities. His research interests are mainly related to Semantic Web, Data Mining, Business Intelligence, Knowledge Management and recently Web services. Dr.Thabet is the author of some programming books", "author": ["G. Xie", "F.Wang"], "venue": "K.Xie. RST-Based System Design of Hybrid Intelligent Control,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2004}], "referenceMentions": [{"referenceID": 0, "context": "Association rule mining (ARM) [2] is defined to extract the important correlation and relation included in large amount of data.", "startOffset": 30, "endOffset": 33}, {"referenceID": 1, "context": "ARM, are originally applied on market basket analysis seeking to study the buying habits of customers [3].", "startOffset": 102, "endOffset": 105}, {"referenceID": 2, "context": "Consequently, an association rule A B is regular means that if A maximally then B maximally [4].", "startOffset": 92, "endOffset": 95}, {"referenceID": 3, "context": "For instance, in market basket analysis, the SDAR representation of the Boolean association rule \u201cdiapers \u21d2 beer\u201d can be written as follows [5]: D", "startOffset": 140, "endOffset": 143}, {"referenceID": 1, "context": "[3] is the first author that introduces Association Rule Mining that begins a well-known data mining research field.", "startOffset": 0, "endOffset": 3}, {"referenceID": 1, "context": "Apriori algorithm is mainly the well-known ARM algorithm, developed by Agrawal and Srikant [3], which represents the basis of various subsequent ARM algorithms.", "startOffset": 91, "endOffset": 94}, {"referenceID": 4, "context": "Several properties of RST that make the theory an evident choice for use to deal with real problems: a brief overview of some of the many applications of rough set is presented in the following section: Pattern Recognition: As an application of pattern recognition, Mrozek and Cyran [12] proposed, in 2001, a hybrid method of automatic diffraction pattern recognition based on RST and Neural Network.", "startOffset": 283, "endOffset": 287}, {"referenceID": 5, "context": "Acoustical analysis: An application based on the RST is used to induce generalized rules describing the relationship between acoustical parameters of concert halls and sound processing algorithms is described in the work of Kotek in 1999 [13].", "startOffset": 238, "endOffset": 242}, {"referenceID": 6, "context": "The approach proposed in [14] by Nguyen et al.", "startOffset": 25, "endOffset": 29}, {"referenceID": 7, "context": "Another work adopting RST approach is developed by Shen&Jensen in 2007 [15] to classify a number of meteorological storm events.", "startOffset": 71, "endOffset": 75}, {"referenceID": 8, "context": "Intelligent control systems: The intelligent control system especially when incorporated with fuzzy theory is an important application field of rough set theory [16].", "startOffset": 161, "endOffset": 165}], "year": 2015, "abstractText": "This paper investigates the mining of class association rules with rough set approach. In data mining, an association occurs between two set of elements when one element set happen together with another. A class association rule set (CARs) is a subset of association rules with classes specified as their consequences. We present an efficient algorithm for mining the finest class rule set inspired form Apriori algorithm, where the support and confidence are computed based on the elementary set of lower approximation included in the property of rough set theory. Our proposed approach has been shown very effective, where the rough set approach for class association discovery is much simpler than the classic association method. Data Mining, RST, CAR, ARM, NAR, Bitmap, class association rules, Rough Set Theory", "creator": "PScript5.dll Version 5.2.2"}}}