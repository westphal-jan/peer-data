{"id": "1510.06153", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "21-Oct-2015", "title": "Creating Scalable and Interactive Web Applications Using High Performance Latent Variable Models", "abstract": "In this project we outline a modularized, scalable system for comparing Amazon products in an interactive and informative way using efficient latent variable models and dynamic visualization. We demonstrate how our system can build on the structure and rich review information of Amazon products in order to provide a fast, multifaceted, and intuitive comparison. By providing a condensed per-topic comparison visualization to the user, we are able to display aggregate information from the entire set of reviews while providing an interface that is at least as compact as the \"most helpful reviews\" currently displayed by Amazon, yet far more informative than those that were offered in previous reviews.\n\n\n\nAs the list of review criteria and our complete list of reviews for Amazon products can be viewed in the following steps.\n1. Complete Amazon Product List (EASL)\n2. Test Amazon Product List (EASL)\n3. Select Amazon Product List (EASL)\n4. Select Amazon Product List (EASL)\n5. Select Amazon Product List (EASL)\n6. Select Amazon Product List (EASL)\n7. Select Amazon Product List (EASL)\n8. Test Amazon Product List (EASL)\n9. Select Amazon Product List (EASL)\n10. Select Amazon Product List (EASL)\n11. Select Amazon Product List (EASL)\n12. Select Amazon Product List (EASL)\n13. Select Amazon Product List (EASL)\n14. Select Amazon Product List (EASL)\n15. Select Amazon Product List (EASL)\n16. Select Amazon Product List (EASL)\n17. Select Amazon Product List (EASL)\n18. Select Amazon Product List (EASL)\n19. Select Amazon Product List (EASL)\n20. Select Amazon Product List (EASL)\n21. Select Amazon Product List (EASL)\n22. Select Amazon Product List (EASL)\n23. Select Amazon Product List (EASL)\n24. Select Amazon Product List (EASL)\n25. Select Amazon Product List (EASL)\n26. Select Amazon Product List (EASL)\n27. Select Amazon Product List (EASL)\n28. Select Amazon Product List (EASL)\n29. Select Amazon Product List (EASL)\n30. Select Amazon Product List (EASL)\n31", "histories": [["v1", "Wed, 21 Oct 2015 07:29:23 GMT  (1739kb,D)", "http://arxiv.org/abs/1510.06153v1", null]], "reviews": [], "SUBJECTS": "cs.AI cs.IR", "authors": ["aaron q li", "yuntian deng", "kublai jing", "joseph w robinson"], "accepted": false, "id": "1510.06153"}, "pdf": {"name": "1510.06153.pdf", "metadata": {"source": "CRF", "title": "Creating Scalable and Interactive Web Applications Using High Performance Latent Variable Models", "authors": ["Aaron Q Li", "Yuntian Deng"], "emails": ["aaron@potatos.io", "yuntiand@cs.cmu.edu", "hjing@andrew.cmu.edu", "jwrobins@andrew.cmu.edu"], "sections": [{"heading": null, "text": "In this project we outline a modularized, scalable system for comparing Amazon products in an interactive and informative way using efficient latent variable models and dynamic visualization. We demonstrate how our system can build on the structure and rich review information of Amazon products in order to provide a fast, multifaceted, and intuitive comparison. By providing a condensed per-topic comparison visualization to the user, we are able to display aggregate information from the entire set of reviews while providing an interface that is at least as compact as the \u201cmost helpful reviews\u201d currently displayed by Amazon, yet far more informative."}, {"heading": "1 Introduction", "text": "Latent variable models are a highly versatile tool for inferring the structures and hierarchies from unstructured data. Typical use cases of latent variable models include learning topics from documents, building user profiles, predicting user behavior, and generating hierarchies of class labels.\nAlthough latent variable models are arguably some of the most powerful tools in machine learning, they are often overlooked and underutilized in practice. Using latent variable models has many challenges in real world settings: models are slow to compute, hardly scalable, and results are noisy and hard to visualize. While prior work in [1, 4, 19, 3, 20, 2] has addressed challenges in computational speed and scalability and systems such as [5, 21, 6] have been proposed to visualize topic modeling results, there is yet a system that combines these components and presents the results to end users in an intuitive, effective, and meaningful way.\nIn this paper, we present the architecture of a modularized distributed system built on top of latent variable models that is able to process, analyze, and intuitively visualize large volumes of Amazon product reviews. We show a fully-featured demo using a completed prototype, and present the results with two case studies.\nar X\niv :1\n51 0.\n06 15\n3v 1\n[ cs"}, {"heading": "2 Background", "text": ""}, {"heading": "2.1 Current Amazon System", "text": "The current Amazon system for presenting reviews to a potential customer consists of three distinct views: customer quotes, most helpful reviews, and the full review list. Below, we describe each of these in detail and outline the deficiencies that our system intends to resolve."}, {"heading": "2.1.1 Quotes", "text": "The quotes view provides a quick overview of a product and consists of three single-sentence quotations extracted from user reviews that are intended to capture sentiment about different aspects of a product in a concise and user-friendly way. As an example, the Macally Power Adapter quotes in Figure 1 display customer sentiment about the product\u2019s cord length and durability, a possibly annoying indicator light, and low cost relative to the brand-name alternative. While these quotes do provide insight into a product, a severe limitation is that they only represent the reviews of a few representatives. Regardless of how these representatives are chosen, their usefulness will always be limited by their inability to convey aggregate information on user sentiment towards different features of a product. We do, however, note the conciseness and simplicity of this representation. In designing our alternative system we attempt to retain as much of this simplicity as possible while improving information content."}, {"heading": "2.1.2 Most Helpful Reviews", "text": "The most helpful reviews section, displayed on the Amazon website above the full review list, provides the \u201cmost helpful\u201d high and low rating reviews in a comparison-oriented view. An example of this is provided in Figure 2, again using the Macally power adapter. With this view, users can see two contrasting product experiences that have been deemed legitimate by other customers. One benefit of this is noise-reduction via user helpfulness feedback. However, these \u201cmost helpful reviews\u201d can often be quite long and may only capture a few facets of the product. On top of this, helpfulness votes are strongly biased by a review\u2019s first vote \u2013 a review that quickly gets a helpful vote is much more likely to get additional positive votes, and vice versa. In our system, we hope to address these problems by placing substantially less weight on helpfulness ratings when presenting information while simultaneously capturing a larger set of product facets and reducing the amount of textual content that needs to be read."}, {"heading": "2.1.3 Full Review List", "text": "The full review list in helpfulness-sorted order is provided as a final source of reference. As there are hundreds of reviews for even moderately popular products, it is generally infeasible for a potential customer to examine this entire list. However, this view does provide the informational completeness that the previous two views lack. Our proposed system is designed to retain this completeness while simultaneously improving individual review search and allowing for multiple sorted review lists based on different aspects of a product that the user may be interested in."}, {"heading": "2.2 Latent Variable Models", "text": "Many potentially suitable latent variable models exist for the task of analyzing Amazon reviews, such as unsupervised models described in [8, 9, 12, 13, 17], supervised models in [10, 11], and hierarchical models in [15, 16, 22, 23]. However, few of them have been designed with efficient inference and sampling procedures, such as [14, 1, 2, 18, 20, 24, 25]. For practical reasons, we only illustrate how our system works with latent variable models accompanied with efficient samplers, such as those introduced in [1, 20]."}, {"heading": "2.2.1 Latent Dirichlet Allocation", "text": "Our prototype makes use of Latent Dirichlet Allocation (LDA) [13], a widely used topic model in which one assumes that documents are generated from mixture distributions of language models associated with individual topics. That is, the documents are generated by the latent variable model below:\nFor each document d draw a topic distribution \u03b8d from a Dirichlet distribution with parameter \u03b1\n\u03b8d \u223c Dir(\u03b1) (1) For each topic t draw a word distribution from a Dirichlet distribution with parameter \u03b2\n\u03c8t \u223c Dir(\u03b2) (2) For each word i \u2208 {1...nd} in document d draw a topic from the multinomial \u03b8d via\nzdi \u223cMult(\u03b8d) (3) Draw a word from the multinomial \u03c8zdi via\nwdi \u223cMult(\u03c8zdi) (4) The Dirichlet-multinomial design in this model makes it simple to do inference due to distribution conjugacy \u2013 we can integrate out the multinomial parameters \u03b8d and \u03c8k, thus allowing one to express p(w, z|\u03b1, \u03b2, nd) in a closed-form [20]. This yields a Gibbs sampler for drawing p(zdi|rest) efficiently. The conditional probability is given by\np(zdi|rest) \u221d (n\u2212ditd + \u03b1t)(n \u2212di tw + \u03b2w)\nn\u2212dit + \u03b2\u0304 (5)\nHere the count variables ntd, ntw and nt denote the number of occurrences of a particular (topic,document) and (topic,word) pair, or of a particular topic, respectively. Moreover, the superscript .\u2212di denotes count when ignoring the pair (zdi, wdi). For instance, n\u2212ditw is obtained when ignoring the (topic,word) combination at position (d, i). Finally, \u03b2\u0304 := \u2211 w \u03b2w denotes the joint normalization.\nSampling from (5) requires O(k) time since we have k nonzero terms in a sum that need to be normalized. In large datasets where the number of topics may be large, this is computationally costly.\nHowever, there are many approaches for substantially accelerating sampling speed by exploiting the topic sparsity to reduce time complexity to O(kd + kw) [20] and further to O(kd) [1], where O(kd) denotes the number of topics instantiated in a document and O(kw) denotes the number of topics instantiated for a word across all documents."}, {"heading": "3 Proposed System", "text": "We propose a system that is capable of handling concurrent requests of product names from many users, analyzing relevant reviews by efficiently sampling from latent variable models, and displaying the streamlined updates from the models in real-time.\n3.1 Architecture\nFigure 3 shows the architectural design of our proposed system. In this design, almost every component is asynchronous and stateless. Furthermore, many tasks can be performed in a distributed fashion in order to balance computational costs."}, {"heading": "3.1.1 Components", "text": "The major components of our system are the distributed web servers, asynchronous task dispatcher, data warehouse, search engine, text pre-processing engine, modularized concurrent topic modeling engine, update pool, and quality evaluator.\nThe workflow of the system is as follows: After a query is accepted by one of the web servers, a request is dispatched to the review search engine. The search engine determines if pre-processed results already exist in the data warehouse, and if not, how much further pre-processing is required. Requests of pre-processing tasks are created and dispatched to the text processing engine, where background workers are constantly pre-processing fresh reviews while assigning highest priority to new requests from the search engine. When pre-processed data is ready, the results are dispatched to the concurrent topic modeling engine. Multiple topic modeling instances are created at the same time, each emitting updates every few Gibbs sampling iterations to a pool where the results are\nfurther evaluated for quality. After evaluation, the best result is selected and sent back to the asynchronous task dispatcher, where it is later routed back to the initial web server. The web server then packages the result and returns it for presentation to the end user."}, {"heading": "3.1.2 Distributed Computing", "text": "Our use of multiple samplers begs the following question: What is the best way to efficiently evaluate the quality of model results? The most popular two evaluation metrics, log likelihood and perplexity, both have their own merits. Compared to log likelihood, perplexity is typically regarded as a more accurate metric when the amount of test data is large, but is much slower to evaluate. In our system, we chose to use log-likelihood as the primary measure of quality for the following reasons:\n\u2022 The number of reviews can be very limited for some products. Computing perplexity on insufficient test data may yield inaccurate evaluation of quality.\n\u2022 There is almost zero overhead for computing log-likelihood."}, {"heading": "3.2 Towards Large Scale", "text": "The modularized and stateless design allows for easier scalability towards large scale processing. For example, Cassandra for data storage, Play! for distributed web servers, Parameter Server for topic modeling engines, and UIMA for pre-processing can all be swapped into our system in order to scale up with minimal modifications to other modules."}, {"heading": "3.3 Visual Design", "text": "To visualize the thousands to millions of parameters estimated by latent variable models, we design an intuitive visualization framework that is most suitable for topic models. We analyze the meaning and structure of the statistical models, their sparsity properties and interconnections, and how they can be mapped onto a two dimensional Euclidean space. We additionally divide presentable information into a hierarchy in which a subset of information is available to the user at each level."}, {"heading": "4 Implementation", "text": "Our prototype system uses the Electronics category from the SNAP Amazon reviews dataset [7], a subset that consists of approximately 1 million reviews and 76,000 products. The primary components of our system \u2013 pre-processing, database, modeling, and visualization \u2013 are described below."}, {"heading": "4.1 Pre-Processing & NLP", "text": "Our pre-processing pipeline is built primarily on Stanford CoreNLP, a robust and highly modular package that has been shown to provide state-of-the-art performance on a variety of tasks. Using CoreNLP, we transform raw review text into a lemmatized token form augmented with part-ofspeech. Ratings are used in place of sentiment to allow for a more intuitive per-topic rating and to reduce computation time. On our machine, we found that pre-processing time increased from 4.1ms to 706ms per review when sentiment analysis was added, making real-time sentiment computation with CoreNLP infeasible. Similarly, our original intension was to include named-entity recognition in our pre-processing pipeline. Our tests found that Stanford\u2019s implementation of this is far too slow \u2013 on our machine, adding named-entity recognition resulted in an increase in average review pre-processing time from 4.1ms to 93.6ms.\nWhile CoreNLP is used for base pre-processing, we defer stop word removal and instead filter out these words in real-time. This provides greater system flexibility and allows us to adjust stop word lists within seconds. From our tests, we found that filtering out tokens corresponding to words in a product\u2019s name resulted in substantially better and more visualizable topics. We also invested in augmenting MALLET\u2019s standard stop word list with many Amazon-specific stop words, such as \u201creview\u201d and \u201cstar\u201d."}, {"heading": "4.2 Database", "text": "We use high memory instances on Google Cloud Engine (GCE) for our review data warehouse. NoSQL databases [27, 28] such as Cassandra [29] are ideal candidates for our setting as we require a high degree of concurrency and high availability, but relatively low demand for consistency. For the prototype system, a relational database is chosen to accomplish this task due to its simplicity and better performance on a relatively low volume of data. To reduce overhead, the same database is used as a cache for pre-processed data. A background task runs continuously to pre-process fresh reviews, giving priority to reviews of products being currently queried.\nThere are a few challenges in using a database for such a system. For instance, when a query is accepted, the system has to quickly determine if pre-processed reviews are available in the cache. If only part of the relevant reviews are cached, the fastest strategy to produce a reasonable response is to return the processed reviews and have the requester process the reviews not yet in the cache, then insert the processed results asynchronously as soon as they are available. When multiple queries are being processed concurrently, the chance that multiple on-demand pre-processing requests point to the same unprocessed review cannot be neglected. In this case, the same unprocessed review may be processed multiple times by different threads, incurring both computational overhead and potential risks of cache deadlock and duplication. One solution to this problem is to employ a scheduler to manage processing and updating, avoiding duplicate processing through the use of efficient hashing."}, {"heading": "4.3 Topic Modeling", "text": "We use a customized version of the open-source MAchine Learning LanguagE Toolkit (MALLET) [26] as our modeling base. By generating a topic model from each product in a comparison in parallel, we achieve a significant speedup compared to MALLET\u2019s single threaded mode and substantially less overhead compared to MALLET\u2019s multithreaded mode. Our system is flexible with respect to the number of topics k in that any number of topics can always be reduced to a core set for presentation to the user.\nSince MALLET\u2019s implementation of LDA uses Gibbs sampling, we continue sampling until relative convergence. We empirically determine the number of iterations for producing good results. In addition, we perform alpha/beta optimization every 100 iterations. We estimate review-topic and word-topic distributions, which we then feed into our model summarization engine. Our modified version of MALLET allows us to compute and emit intermediate summaries after the 10th iteration of sampling and again every 2 seconds until sampling is complete. This gives the user immediate feedback and allows us to provide improved results as they become available.\nFrom our topic model and reviews, we summarize each product with its topics and review summaries. Each topic structure contains a probability, list of augmented lemmas, rating, nearest topic and distance to that topic for the comparison product, and a representative review. Probabilities represent the overall topic distribution for the model generated from a product\u2019s reviews, which we use as our metric for topic relevance when presenting results to the end user. Each augmented lemma consists of the lemma text and both normalized and unnormalized word-topic weights. To compute nearest topics, we chose to use the Hellinger distance metric between normalized word-topic weights. Per-topic ratings Rt are estimated as Ed\u223c\u03b8\u00b7,t [r(d)]. The top review d\u2217 for each topic t is found by maximizing the following metric over d:\n\u03b8d,t\n\u2016r(d)\u2212Rt\u2016 \u2212 1101(h+(d)\u2212 h\u2212(d) > 0) + 1 (6)\nHere, h+(d), h\u2212(d) refer to the helpfulness and unhelpfulness votes for review d, respectively. This metric was designed to address several problems that arise when using \u03b8 alone. Namely, we add a slight preference towards reviews that were voted to be helpful in order to avoid poor-quality representatives. We also bias our metric towards reviews in which the user rated the product similarly to the topic\u2019s aggregate rating, reducing user confusion and the frequency of unexpected results; a user browsing a 1-star topic does not expect to see a 5-star representative review praising the product. From our experiments, we found this metric to produce good results and have subjectively found it to offer more informative and intuitive representatives compared to the pure probability-based baseline. We also experimented with weighted n-gram topic visualization as an alternative to singular lemmas,\nhowever we found that single words resulted in simpler and more easily interpretable word clouds than n-grams.\nAs previously mentioned, our backend system also computes review summaries. The fields of this structure \u2013 user id, profile name, helpful votes, unhelpful votes, rating, time, summary, and \u03b8 probabilities \u2013 are self-explanatory. A key thing to note is our exclusion of the full review text. By doing this, we substantially reduce bandwidth costs and response time while allowing for later querying of individual reviews when requested."}, {"heading": "4.4 Visualization", "text": "To achieve satisfactory performance, we made use of multiple rendering buffers and an advanced object management framework. The geometry of each data point is computed in real-time. Review contents are pulled from servers on-demand to minimize traffic. We additionally made use of many invisible techniques to minimize traffic, computation, and rendering efforts in order to maintain a smooth user experience."}, {"heading": "5 Results", "text": "Our final prototype allows a user to query product reviews using an intuitive web interface and visualize initial results in under 3 seconds in the majority of instances. The interface allows for easy topic rating visualization with the ability to quickly select individual reviews. Selecting a topic brings up a side panel containing a topic-specific product comparison along with topic-sorted review summaries. Further details are available in the case studies below."}, {"heading": "5.1 Case Studies", "text": "Below, we provide two product comparison case studies to demonstrate the utility and simplicity of our system. In the first, we compare the Macally PS-AC4 AC Power Adapter for Apple G4 to the Apple USB Power Adapter for iPod (White). We then repeat this analysis with a separate case consisting of two cameras, the Canon Digital Rebel XT 8MP Digital SLR Camera with EF-S 18- 55mm f3.5-5.6 Lens (Black) and the Sony Cybershot DSC-T1 5MP Digital Camera with 3x Optical Zoom."}, {"heading": "5.1.1 Power Adapters", "text": "Figure 4 shows the interface a user of our system would see when comparing the two power adapters, using the Macally adapter as the reference product. On our machine, an initial view was available in approximately 2 seconds with updates continuing for a few seconds afterwards.\nFrom the word clouds, we immediately see that customers tend to think highly of the Macally adapter\u2019s power cord, giving the topic high weight and an associated rating of 4.1. In contrast, we see 2.5 stars attributed to a topic dominated by \u201cwork\u201d, \u201ccomputer\u201d, and \u201cbattery\u201d. Clicking on this topic circle brings up the panel on the right, where we quickly learn that this product has a tendency to die after a few months and intermittently not work, failing to charge the the customer\u2019s computer."}, {"heading": "5.1.2 Cameras", "text": "Figure 5 shows the side panel displayed for a single topic in the Sony-Canon camera comparison. As we can see, the Sony camera (left column) has potential red-eye and flash problems, whereas the nearest topic from the Canon model suggests higher design and picture quality. The relatively high similarity (37%) of these topics suggests that the two do indeed describe the same facet of the cameras. Looking at the top topic reviews for the Sony camera, we see concerns about indoor picture quality compared to the Canon. As such, users whose primary concern is picture quality can quickly see that the Canon is generally regarded as superior in this area. However, cost conscious users that require a cheaper and more compact device can also benefit from this interface by learning that the Sony camera\u2019s problems tend to stem from picture quality issues rather than device failures."}, {"heading": "6 Future Work", "text": "For future work, we wish to improve the scalability and performance of our system. In terms of modeling performance, replacing MALLET with higher performing implementations based on ideas described in [1, 2, 4] would reduce sampling time and allow our system to scale to a larger number of users. We also expect future project iterations to use a continuously updating, crawler-based system in order to provide more up-to-date information and allow us to pre-process new data as it occurs.\nWe also plan to explore alternative topic distance metrics. Compared to our limited Hellinger distance metric, we suspect that including part-of-speech information will lead to better pairings. Specifically, we plan to experiment with computing distances on nouns only, allowing sentiment (typically manifested in adjective use) to arise naturally. Related part-of-speech experiments may also prove useful.\nA known deficiency of topic models is the presence of noisy topics. Paralleling our use of per-topic customer ratings, we plan to explore per-topic helpfulness ratings based on our intuition that noisy and less informative topics would receive a higher proportion of weighted unhelpful votes and can therefore be automatically pruned out."}], "references": [{"title": "Parameter Server for Distributed Machine Learning", "author": ["Mu Li", "Li Zhou", "Zichao Yang", "Aaron Q Li", "Fei Xia", "David G Anderson", "Alexander J Smola"], "venue": "NIPS Big Learning Workshop", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2013}, {"title": "High Performance Latent Variable Models WWW 2015", "author": ["Aaron Q Li", "Amr Ahmed", "Mu Li", "Vanja Josifovski", "Alexander J Smola"], "venue": null, "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2015}, {"title": "Krevl, SNAP Large Network Dataset Collection 2014 http: //snap.stanford.edu/data/web-Amazon-links.html", "author": ["Jure Leskovec", "Andrej"], "venue": null, "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2014}, {"title": "Integrating Document Clustering and Topic Modeling UAI", "author": ["Pengxiao Xie", "Eric P. Xing"], "venue": null, "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2013}, {"title": "Mining and summarizing customer reviews KDD", "author": ["Hu", "Minqing", "Bing Liu"], "venue": null, "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2004}, {"title": "Jointly Modeling Aspects, Ratings and Sentiments for Movie Recommendation (JMARS) KDD2014", "author": ["Qiming Diao"], "venue": null, "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2014}, {"title": "A Joint Model of Text and Aspect Ratings for Sentiment Summarization", "author": ["Titov", "Ivan", "Ryan T. McDonald"], "venue": null, "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2008}, {"title": "Latent Dirichlet allocation", "author": ["D. Blei", "A. Ng", "M. Jordan"], "venue": "JMLR, 3:993\u20131022, Jan.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2003}, {"title": "A Collapsed Variational Bayesian Inference Algorithm for Latent Dirichlet Allocation NIPS2007", "author": ["Y.W. Teh", "D. Newman", "M. Welling"], "venue": null, "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2007}, {"title": "Mixed Membership Stochastic Blockmodels", "author": ["E.M. Airoldi", "D. Blei", "S. Fienberg", "E.P. Xing"], "venue": null, "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2008}, {"title": "An architecture for parallel topic models", "author": ["A.J. Smola", "S. Narayanamurthy"], "venue": "PVLDB", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2010}, {"title": "Efficient methods for topic model inference on streaming document collections", "author": ["L. Yao", "D. Mimno", "A. McCallum"], "venue": null, "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2009}, {"title": "Interpretation and Trust: Designing Model- Driven Visualizations for Text Analysis", "author": ["J. Chuang", "D. Ramage", "C.D. Manning", "J. Heer"], "venue": null, "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2012}, {"title": "Hierarchical dirichlet processes", "author": ["Y. Teh", "M. Jordan", "M. Beal", "D. Blei"], "venue": "JASA, 101(576):1566\u20131581,", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2006}, {"title": "Differential topic models", "author": ["C. Chen", "W. Buntine", "N. Ding", "L. Xie", "L. Du"], "venue": "IEEE Pattern Analysis and Machine Intelligence,", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2014}, {"title": "A bayesian review of the poisson-dirichlet", "author": ["W. Buntine", "M. Hutter"], "venue": null, "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2010}, {"title": "Sampling table configurations for the hierarchical poissondirichlet process", "author": ["C. Chen", "L. Du", "W. Buntine"], "venue": "ECML, pages 296\u2013311,", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2011}, {"title": "MALLET: A Machine Learning for Language Toolkit", "author": ["Andrew Kachites McCallum"], "venue": null, "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2002}, {"title": "Scalable SQL and NoSQL Data Stores", "author": ["Rick Cattell"], "venue": "ACM SIGMOD Record,", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2011}, {"title": "Bigtable: A distributed storage system for structured data", "author": ["Fay Chang", "Jeffrey Dean", "Sanjay Ghemawat", "Wilson C Hsieh", "Deborah A Wallach", "Mike Burrows", "Tushar Chandra", "Andrew Fikes", "Robert E Gruber"], "venue": "ACM Transactions on Computer Systems (TOCS),", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 2008}, {"title": "Cassandra: A Decentralized Structured Storage System", "author": ["Avinash Lakshman", "Prashant Malik"], "venue": "ACM SIGOPS Operating Systems Review,", "citeRegEx": "29", "shortCiteRegEx": "29", "year": 2010}], "referenceMentions": [{"referenceID": 1, "context": "While prior work in [1, 4, 19, 3, 20, 2] has addressed challenges in computational speed and scalability and systems such as [5, 21, 6] have been proposed to visualize topic modeling results, there is yet a system that combines these components and presents the results to end users in an intuitive, effective, and meaningful way.", "startOffset": 20, "endOffset": 40}, {"referenceID": 10, "context": "While prior work in [1, 4, 19, 3, 20, 2] has addressed challenges in computational speed and scalability and systems such as [5, 21, 6] have been proposed to visualize topic modeling results, there is yet a system that combines these components and presents the results to end users in an intuitive, effective, and meaningful way.", "startOffset": 20, "endOffset": 40}, {"referenceID": 0, "context": "While prior work in [1, 4, 19, 3, 20, 2] has addressed challenges in computational speed and scalability and systems such as [5, 21, 6] have been proposed to visualize topic modeling results, there is yet a system that combines these components and presents the results to end users in an intuitive, effective, and meaningful way.", "startOffset": 20, "endOffset": 40}, {"referenceID": 11, "context": "While prior work in [1, 4, 19, 3, 20, 2] has addressed challenges in computational speed and scalability and systems such as [5, 21, 6] have been proposed to visualize topic modeling results, there is yet a system that combines these components and presents the results to end users in an intuitive, effective, and meaningful way.", "startOffset": 20, "endOffset": 40}, {"referenceID": 12, "context": "While prior work in [1, 4, 19, 3, 20, 2] has addressed challenges in computational speed and scalability and systems such as [5, 21, 6] have been proposed to visualize topic modeling results, there is yet a system that combines these components and presents the results to end users in an intuitive, effective, and meaningful way.", "startOffset": 125, "endOffset": 135}, {"referenceID": 3, "context": "Many potentially suitable latent variable models exist for the task of analyzing Amazon reviews, such as unsupervised models described in [8, 9, 12, 13, 17], supervised models in [10, 11], and hierarchical models in [15, 16, 22, 23].", "startOffset": 138, "endOffset": 156}, {"referenceID": 4, "context": "Many potentially suitable latent variable models exist for the task of analyzing Amazon reviews, such as unsupervised models described in [8, 9, 12, 13, 17], supervised models in [10, 11], and hierarchical models in [15, 16, 22, 23].", "startOffset": 138, "endOffset": 156}, {"referenceID": 6, "context": "Many potentially suitable latent variable models exist for the task of analyzing Amazon reviews, such as unsupervised models described in [8, 9, 12, 13, 17], supervised models in [10, 11], and hierarchical models in [15, 16, 22, 23].", "startOffset": 138, "endOffset": 156}, {"referenceID": 7, "context": "Many potentially suitable latent variable models exist for the task of analyzing Amazon reviews, such as unsupervised models described in [8, 9, 12, 13, 17], supervised models in [10, 11], and hierarchical models in [15, 16, 22, 23].", "startOffset": 138, "endOffset": 156}, {"referenceID": 9, "context": "Many potentially suitable latent variable models exist for the task of analyzing Amazon reviews, such as unsupervised models described in [8, 9, 12, 13, 17], supervised models in [10, 11], and hierarchical models in [15, 16, 22, 23].", "startOffset": 138, "endOffset": 156}, {"referenceID": 5, "context": "Many potentially suitable latent variable models exist for the task of analyzing Amazon reviews, such as unsupervised models described in [8, 9, 12, 13, 17], supervised models in [10, 11], and hierarchical models in [15, 16, 22, 23].", "startOffset": 179, "endOffset": 187}, {"referenceID": 13, "context": "Many potentially suitable latent variable models exist for the task of analyzing Amazon reviews, such as unsupervised models described in [8, 9, 12, 13, 17], supervised models in [10, 11], and hierarchical models in [15, 16, 22, 23].", "startOffset": 216, "endOffset": 232}, {"referenceID": 14, "context": "Many potentially suitable latent variable models exist for the task of analyzing Amazon reviews, such as unsupervised models described in [8, 9, 12, 13, 17], supervised models in [10, 11], and hierarchical models in [15, 16, 22, 23].", "startOffset": 216, "endOffset": 232}, {"referenceID": 8, "context": "However, few of them have been designed with efficient inference and sampling procedures, such as [14, 1, 2, 18, 20, 24, 25].", "startOffset": 98, "endOffset": 124}, {"referenceID": 11, "context": "However, few of them have been designed with efficient inference and sampling procedures, such as [14, 1, 2, 18, 20, 24, 25].", "startOffset": 98, "endOffset": 124}, {"referenceID": 15, "context": "However, few of them have been designed with efficient inference and sampling procedures, such as [14, 1, 2, 18, 20, 24, 25].", "startOffset": 98, "endOffset": 124}, {"referenceID": 16, "context": "However, few of them have been designed with efficient inference and sampling procedures, such as [14, 1, 2, 18, 20, 24, 25].", "startOffset": 98, "endOffset": 124}, {"referenceID": 11, "context": "For practical reasons, we only illustrate how our system works with latent variable models accompanied with efficient samplers, such as those introduced in [1, 20].", "startOffset": 156, "endOffset": 163}, {"referenceID": 7, "context": "Our prototype makes use of Latent Dirichlet Allocation (LDA) [13], a widely used topic model in which one assumes that documents are generated from mixture distributions of language models associated with individual topics.", "startOffset": 61, "endOffset": 65}, {"referenceID": 11, "context": "nd} in document d draw a topic from the multinomial \u03b8d via zdi \u223cMult(\u03b8d) (3) Draw a word from the multinomial \u03c8zdi via wdi \u223cMult(\u03c8zdi) (4) The Dirichlet-multinomial design in this model makes it simple to do inference due to distribution conjugacy \u2013 we can integrate out the multinomial parameters \u03b8d and \u03c8k, thus allowing one to express p(w, z|\u03b1, \u03b2, nd) in a closed-form [20].", "startOffset": 372, "endOffset": 376}, {"referenceID": 11, "context": "However, there are many approaches for substantially accelerating sampling speed by exploiting the topic sparsity to reduce time complexity to O(kd + kw) [20] and further to O(kd) [1], where O(kd) denotes the number of topics instantiated in a document and O(kw) denotes the number of topics instantiated for a word across all documents.", "startOffset": 154, "endOffset": 158}, {"referenceID": 2, "context": "Our prototype system uses the Electronics category from the SNAP Amazon reviews dataset [7], a subset that consists of approximately 1 million reviews and 76,000 products.", "startOffset": 88, "endOffset": 91}, {"referenceID": 18, "context": "NoSQL databases [27, 28] such as Cassandra [29] are ideal candidates for our setting as we require a high degree of concurrency and high availability, but relatively low demand for consistency.", "startOffset": 16, "endOffset": 24}, {"referenceID": 19, "context": "NoSQL databases [27, 28] such as Cassandra [29] are ideal candidates for our setting as we require a high degree of concurrency and high availability, but relatively low demand for consistency.", "startOffset": 16, "endOffset": 24}, {"referenceID": 20, "context": "NoSQL databases [27, 28] such as Cassandra [29] are ideal candidates for our setting as we require a high degree of concurrency and high availability, but relatively low demand for consistency.", "startOffset": 43, "endOffset": 47}, {"referenceID": 17, "context": "We use a customized version of the open-source MAchine Learning LanguagE Toolkit (MALLET) [26] as our modeling base.", "startOffset": 90, "endOffset": 94}, {"referenceID": 1, "context": "In terms of modeling performance, replacing MALLET with higher performing implementations based on ideas described in [1, 2, 4] would reduce sampling time and allow our system to scale to a larger number of users.", "startOffset": 118, "endOffset": 127}], "year": 2015, "abstractText": "In this project we outline a modularized, scalable system for comparing Amazon products in an interactive and informative way using efficient latent variable models and dynamic visualization. We demonstrate how our system can build on the structure and rich review information of Amazon products in order to provide a fast, multifaceted, and intuitive comparison. By providing a condensed per-topic comparison visualization to the user, we are able to display aggregate information from the entire set of reviews while providing an interface that is at least as compact as the \u201cmost helpful reviews\u201d currently displayed by Amazon, yet far more informative.", "creator": "LaTeX with hyperref package"}}}