{"id": "1510.08692", "review": {"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "29-Oct-2015", "title": "Covariance-Controlled Adaptive Langevin Thermostat for Large-Scale Bayesian Sampling", "abstract": "Monte Carlo sampling for Bayesian posterior inference is a common approach used in machine learning. The Markov Chain Monte Carlo procedures that are used are often discrete-time analogues of associated stochastic differential equations (SDEs). These SDEs are guaranteed to leave invariant the required posterior distribution for the top two Bayesian distributions. However, some of the SDEs are not necessarily additive, even with an optimization of the top two. A recent example of a Monte Carlo algorithm in which it is possible to apply Bayesian Monte Carlo models (e.g., Biorgian, SDEs, etc.), would appear to show that Bayesian posterior probability distributions are constrained by the fact that all of the features of the underlying machine learning algorithm are in fact covariate. The Bayesian SDEs also allow for a general equilibrium between the distributions of probability distributions, and the general equilibrium between distributions in order to maintain a general equilibrium in this area.\n\n\n\nBayesian Bayesian Bayesian Bayesian Bayesian Bayesian Bayesian Bayesian Bayesian Bayesian Bayesian Bayesian Bayesian Bayesian Bayesian Bayesian Bayesian Bayesian Bayesian Bayesian Bayesian Bayesian Bayesian Bayesian Bayesian Bayesian Bayesian Bayesian Bayesian Bayesian Bayesian Bayesian Bayesian Bayesian Bayesian Bayesian Bayesian Bayesian Bayesian Bayesian Bayesian Bayesian Bayesian Bayesian Bayesian Bayesian Bayesian Bayesian Bayesian Bayesian Bayesian Bayesian Bayesian Bayesian Bayesian Bayesian Bayesian Bayesian Bayesian Bayesian Bayesian Bayesian Bayesian Bayesian Bayesian Bayesian Bayesian Bayesian Bayesian Bayesian Bayesian Bayesian Bayesian Bayesian Bayesian Bayesian Bayesian Bayesian Bayesian Bayesian Bayesian Bayesian Bayesian Bayesian Bayesian Bayesian Bayesian Bayesian Bayesian Bayesian Bayesian Bayesian Bayesian Bayesian Bayesian Bayesian Bayesian Bayesian Bayesian Bayesian Bayesian Bayesian Bayesian Bayesian Bayesian Bayesian Bayesian Bayesian Bayesian Bayesian Bayesian Bayesian Bayesian Bayesian Bayesian Bayesian Bayesian Bayesian Bayesian Bayesian Bayesian Bayesian Bayesian Bayesian Bayesian Bayesian Bayesian Bayesian Bayesian Bayesian Bayesian Bayesian Bayesian Bayesian Bayesian Bayesian Bayesian Bayesian Bayesian Bayesian Bayesian Bayesian Bayesian Bayesian Bayesian Bayesian Bayesian Bayesian Bayesian Bayesian Bayesian Bayesian Bayesian Bayesian Bayesian Bayesian Bay", "histories": [["v1", "Thu, 29 Oct 2015 13:57:11 GMT  (64kb)", "http://arxiv.org/abs/1510.08692v1", "Advances in Neural Information Processing Systems (NIPS), 2015"]], "COMMENTS": "Advances in Neural Information Processing Systems (NIPS), 2015", "reviews": [], "SUBJECTS": "stat.ML cs.LG", "authors": ["xiaocheng shang", "zhanxing zhu", "benedict j leimkuhler", "amos j storkey"], "accepted": true, "id": "1510.08692"}, "pdf": {"name": "1510.08692.pdf", "metadata": {"source": "CRF", "title": "Covariance-Controlled Adaptive Langevin Thermostat for Large-Scale Bayesian Sampling", "authors": ["Xiaocheng Shang", "Zhanxing Zhu", "Benedict Leimkuhler", "Amos J. Storkey"], "emails": ["(x.shang@ed.ac.uk).", "b.leimkuhler@ed.ac.uk", "(zhanxing.zhu@ed.ac.uk).", "a.storkey@ed.ac.uk"], "sections": [{"heading": null, "text": "ar X\niv :1\n51 0.\n08 69\n2v 1\n[ st\nat .M\nL ]\n2 9"}, {"heading": "1 Introduction", "text": "In machine learning applications, direct sampling with the entire large-scale dataset is computationally infeasible. For instance, standard Markov Chain Monte Carlo (MCMC) methods [16], as well as typical Hybrid Monte Carlo (HMC) methods [3, 6, 9], require the calculation of the acceptance probability and the creation of informed proposals based on the whole dataset.\nIn order to improve computational efficiency, a number of stochastic gradient methods [4, 5, 20, 21] have been proposed in the setting of Bayesian sampling based on random (and much smaller) subsets to approximate the likelihood of the whole dataset, thus substantially reducing the computational cost in practice. Welling and Teh proposed the so-called\n\u2217School of Mathematics and Maxwell Institute for Mathematical Sciences, University of Edinburgh, EH9 3FD, UK (x.shang@ed.ac.uk).\n\u2020b.leimkuhler@ed.ac.uk \u2021Institute of Adaptive Neural Computation, School of Informatics, University of Edinburgh, EH8 9AB, UK\n(zhanxing.zhu@ed.ac.uk). \u00a7a.storkey@ed.ac.uk \u00b6Address in common for the first and third authors. \u2016Address in common for the second and fourth authors.\n\u2217\u2217The first and second authors contributed equally, and the listed author order was decided by lot.\nStochastic Gradient Langevin Dynamics (SGLD) [21], combining the ideas of stochastic optimization [18] and traditional Brownian dynamics, with a sequence of stepsizes decreasing to zero. A fixed stepsize is often adopted in practice which is the choice in this article as in Vollmer et al. [20], where a modified SGLD (mSGLD) was also introduced that was designed to reduce sampling bias.\nSGLD generates samples from first order Brownian dynamics, and thus, with a fixed timestep, one can show that it is unable to dissipate excess noise in gradient approximations while maintaining the desired invariant distribution [4]. A Stochastic Gradient Hamiltonian Monte Carlo (SGHMC) method was proposed by Chen et al. [4], which relies on second order Langevin dynamics and incorporates a parameter-dependent diffusion matrix that is intended to effectively offset the stochastic perturbation of the gradient. However, it is difficult to accommodate the additional diffusion term in practice. Moreover, as pointed out in [5] poor estimation of it may have a significant adverse influence on the sampling of the target distribution; for example the effective system temperature may be altered.\nThe \u201cthermostat\u201d idea, which is widely used in molecular dynamics [7, 13], was recently adopted in the Stochastic Gradient Nose\u0301-Hoover Thermostat (SGNHT) by Ding et al. [5] in order to adjust the kinetic energy during simulation in such a way that the canonical ensemble is preserved (i.e. so that a prescribed constant temperature distribution is maintained). In fact, the SGNHT method is essentially equivalent to the Adaptive Langevin (Ad-Langevin) thermostat proposed earlier by Jones and Leimkuhler [10] in the molecular dynamics setting (see [15] for discussion).\nDespite the substantial interest generated by these methods, the mathematical foundation for stochastic gradient methods has been incomplete. The underlying dynamics of the SGNHT [5] was taken up by Leimkuhler and Shang [15], together with the design of discretization schemes with high effective order of accuracy. SGNHT methods are designed based on the assumption of constant noise variance. In this article, we propose a Covariance-Controlled Adaptive Langevin (CCAdL) thermostat, that can handle parameter-dependent noise, improving both robustness and reliability in practice, and which can effectively speed up the convergence to the desired invariant distribution in large-scale machine learning applications.\nThe rest of the article is organized as follows. In Section 2, we describe the setting of Bayesian sampling with noisy gradients and briefly review existing techniques. In Section 3, we construct the novel Covariance-Controlled Adaptive Langevin (CCAdL) method that can effectively dissipate parameter-dependent noise while maintaining the correct distribution. Various numerical experiments are performed in Section 4 to verify the usefulness of CCAdL in a wide range of large-scale machine learning applications. Finally, we summarize our findings in Section 5."}, {"heading": "2 Bayesian Sampling with Noisy Gradients", "text": "In the typical setting of Bayesian sampling [3, 19], one is interested in drawing states from a posterior distribution defined as\n\u03c0(\u03b8|X) \u221d \u03c0(X|\u03b8)\u03c0(\u03b8) , (1)\nwhere \u03b8 \u2208 RNd is the parameter vector of interest, X denotes the entire dataset, and, \u03c0(X|\u03b8) and \u03c0(\u03b8) are the likelihood and prior distributions, respectively. We introduce a potential\nenergy function U(\u03b8) by defining \u03c0(\u03b8|X) \u221d exp(\u2212\u03b2U(\u03b8)), where \u03b2 is a positive parameter and can be interpreted as being proportional to the reciprocal temperature in an associated physical system, i.e. \u03b2\u22121 = kBT (kB is the Boltzmann constant and T is temperature). In practice, \u03b2 is often set to be unity for notational simplicity. Taking the logarithm of (1) yields\nU(\u03b8) = \u2212 log \u03c0(X|\u03b8)\u2212 log \u03c0(\u03b8) . (2) Assuming the data are independent and identically distributed (i.i.d.), the logarithm of the likelihood can be calculated as\nlog \u03c0(X|\u03b8) = N \u2211\ni=1\nlog \u03c0(xi|\u03b8) , (3)\nwhere N is the size of the entire dataset. However, as already mentioned, it is computationally infeasible to deal with the entire large-scale dataset at each timestep as would typically be required in MCMC and HMC methods. Instead, in order to improve the efficiency, a random (and much smaller, n \u226a N) subset is preferred in stochastic gradient methods, in which the likelihood of the dataset for given parameters is approximated as\nlog \u03c0(X|\u03b8) \u2248 N n\nn \u2211\ni=1\nlog \u03c0(xri |\u03b8) , (4)\nwhere {xri}ni=1 represents a random subset of X. Thus, the \u201cnoisy\u201d potential energy can be written as\nU\u0303(\u03b8) = \u2212N n\nn \u2211\ni=1\nlog \u03c0(xri |\u03b8)\u2212 log \u03c0(\u03b8) , (5)\nwhere the negative gradient of the potential is referred to as the \u201cnoisy\u201d force, i.e. F\u0303(\u03b8) = \u2212\u2207U\u0303(\u03b8).\nOur goal is to correctly sample the Gibbs distribution \u03c1(\u03b8) \u221d exp(\u2212\u03b2U(\u03b8)) (1). As in [4,5], the gradient noise is assumed to be Gaussian with mean zero and unknown variance, in which case one may rewrite the noisy force as\nF\u0303(\u03b8) = \u2212\u2207U(\u03b8) + \u221a \u03a3(\u03b8)M1/2R , (6)\nwhere M typically is a diagonal matrix, \u03a3(\u03b8) represents the covariance matrix of the noise and R is a vector of i.i.d. standard normal random variables. Note that \u221a\n\u03a3(\u03b8)M1/2R here is actually equivalent to N (0,\u03a3(\u03b8)M).\nIn a typical setting of numerical integration with associated stepsize h, one has\nhF\u0303(\u03b8) = h ( \u2212\u2207U(\u03b8) + \u221a \u03a3(\u03b8)M1/2R ) = \u2212h\u2207U(\u03b8) + \u221a h ( \u221a h\u03a3(\u03b8) ) M1/2R , (7)\nand therefore, assuming a constant covariance matrix (i.e. \u03a3 = \u03c32I, where I is the identity matrix), the SGNHT method by Ding et al. [5], has the following underlying dynamics, written as a standard Ito\u0304 stochastic differential equation (SDE) system [15]:\nd\u03b8 = M\u22121pdt , dp = \u2212\u2207U(\u03b8)dt+ \u03c3 \u221a hM1/2dW\u2212 \u03bepdt+ \u221a 2A\u03b2\u22121M1/2dWA , d\u03be = \u00b5\u22121 [ pTM\u22121p\u2212NdkBT ] dt ,\n(8)\nwhere, colloquially, dW and dWA, respectively, represent vectors of independent Wiener increments; and are often informally denoted by N (0,dtI) [4]. The coefficient \u221a\n2A\u03b2\u22121M1/2, represents the strength of artificial noise added into the system to improve ergodicity, and A, which can be termed as \u201ceffective friction\u201d, is a positive parameter and proportional to the variance of the noise. The auxiliary variable \u03be \u2208 R is governed by a Nose\u0301-Hoover device [8,17] via a negative feedback mechanism, i.e. when the instantaneous temperature (average kinetic energy per degree of freedom) calculated as\nkBT = pTM\u22121p\nNd (9)\nis below the target temperature, the \u201cdynamical friction\u201d \u03be would decrease allowing an increase of temperature, while \u03be would increase when the temperature is above the target. \u00b5 is a coupling parameter which is referred to as the \u201cthermal mass\u201d in the molecular dynamics setting. Proposition 1: (See Jones and Leimkuhler [10]) The SGNHT method (8) preserves the modified Gibbs (stationary) distribution\n\u03c1\u0303\u03b2(\u03b8,p, \u03be) = 1\nZ exp (\u2212\u03b2H(\u03b8,p)) exp\n(\n\u2212\u03b2\u00b5 2 (\u03be \u2212 \u03be\u0304)2\n)\n, (10)\nwhere Z is the normalizing constant, H(\u03b8,p) = pTM\u22121p/2 + U(\u03b8) is the Hamiltonian, and\n\u03be\u0304 = A+ \u03b2h\u03c32\n2 . (11)\nProposition 1 tells us that the SGNHT method can adaptively dissipate excess noise pumped into the system while maintaining the correct distribution. The variance of the gradient noise, \u03c32, does not need to be known a priori. As long as \u03c32 is constant, the auxiliary variable \u03be will be able to automatically find its mean value \u03be\u0304 on the fly. However, with a parameter-dependent covariance matrix \u03a3(\u03b8), the SGNHT method (8) would not produce the required target distribution (10).\nDing et al. [5] claimed that it is reasonable to assume the covariance matrix \u03a3(\u03b8) is constant when the size of the dataset, N , is large, in which case the variance of the posterior of \u03b8 is small. The magnitude of the posterior variance does not actually relate to the constancy of the \u03a3, however, in general \u03a3 is not constant. Simply assuming the non-constancy of the \u03a3 can have a significant impact on the performance of the method (most notably the stability measured by the largest usable stepsize). Therefore, it is essential to have an approach that can handle parameter-dependent noise. In the following section we propose a covariance-controlled thermostat that can effectively dissipate parameter-dependent noise while maintaining the target stationary distribution."}, {"heading": "3 Covariance-Controlled Adaptive Langevin Thermostat", "text": "As mentioned in the previous section, the SGNHT method (8) can only dissipate noise with a constant covariance matrix. When the covariance matrix becomes parameter-dependent, in general a parameter-dependent covariance matrix does not imply the required \u201cthermal\nequilibrium\u201d, i.e. the system cannot be expected to converge to the desired invariant distribution (10), typically resulting in poor estimation of functions of parameters of interest. In fact, in that case it is not clear whether or not there exists an invariant distribution at all.\nIn order to construct a stochastic-dynamical system that preserves the canonical distribution, we suggest adding a suitable damping (viscous) term to effectively dissipate the parameter-dependent gradient noise. To this end, we propose the following CovarianceControlled Adaptive Langevin (CCAdL) thermostat\nd\u03b8 = M\u22121pdt ,\ndp = \u2212\u2207U(\u03b8)dt+ \u221a h\u03a3(\u03b8)M1/2dW\u2212 (h/2)\u03b2\u03a3(\u03b8)pdt \u2212 \u03bepdt+ \u221a 2A\u03b2\u22121M1/2dWA , d\u03be = \u00b5\u22121 [ pTM\u22121p\u2212NdkBT ]\ndt . (12)\nProposition 2: The CCAdL thermostat (12) preserves the modified Gibbs (stationary) distribution\n\u03c1\u0302\u03b2(\u03b8,p, \u03be) = 1\nZ exp (\u2212\u03b2H(\u03b8,p)) exp\n(\n\u2212\u03b2\u00b5 2 (\u03be \u2212A)2\n)\n. (13)\nProof: The Fokker-Planck equation corresponding to (12) is\n\u03c1t = L\u2020\u03c1 := \u2212M\u22121p \u00b7 \u2207\u03b8\u03c1+\u2207U(\u03b8) \u00b7 \u2207p\u03c1+ (h/2)\u2207p \u00b7 (\u03a3(\u03b8)M\u2207p\u03c1) + (h/2)\u03b2\u2207p \u00b7 (\u03a3(\u03b8)p\u03c1) + \u03be\u2207p \u00b7 (p\u03c1) +A\u03b2\u22121\u2207p \u00b7 (M\u2207p\u03c1)\u2212 \u00b5\u22121 [ pTM\u22121p\u2212NdkBT ] \u2207\u03be\u03c1 .\nJust insert \u03c1\u0302\u03b2 (13) into the Fokker-Planck operator L\u2020 to see that it vanishes. \u2737. The incorporation of the parameter-dependent covariance matrix \u03a3(\u03b8) in (12) is intended to offset the covariance matrix coming from the gradient approximation. However, in practice, one does not know \u03a3(\u03b8) a priori. Thus instead one must estimate \u03a3(\u03b8) during the simulation, a task which will be addressed in Section 3.1. This procedure is related to the method used in the SGHMC method proposed by Chen et al. [4], which uses dynamics of the following form:\nd\u03b8 = M\u22121pdt , dp = \u2212\u2207U(\u03b8)dt+ \u221a h\u03a3(\u03b8)M1/2dW\u2212Apdt+ \u221a 2\u03b2\u22121 (AI\u2212 h\u03a3(\u03b8)/2)M1/2dWA . (14)\nIt can be shown that the SGHMC method preserves the Gibbs canonical distribution\n\u03c1\u03b2(\u03b8,p) = Z \u22121 exp (\u2212\u03b2H(\u03b8,p)) . (15)\nAlthough both CCAdL (12) and SGHMC (14) preserve their respective invariant distributions, let us note several advantages of the former over the latter in practice:\n(i) CCAdL and SGHMC both require estimation of the covariance matrix \u03a3(\u03b8) during simulation, which can be costly in high dimension. In numerical experiments, we have found that simply using the diagonal of the covariance matrix, at significantly reduced computational cost, works quite well in CCAdL. By contrast, it is difficult to find a suitable value of the parameter A in SGHMC since one has to make sure the matrix AI \u2212 h\u03a3(\u03b8)/2 is positive semi-definite. One may attempt to use a large value of the \u201ceffective friction\u201d A and/or a small stepsize h. However, too-large a friction would essentially reduce SGHMC to SGLD, which is not desirable, as pointed out in [4], while extremely small stepsize would significantly impact the computational efficiency.\n(ii) Estimation of the covariance matrix \u03a3(\u03b8) unavoidably introduces additional noise in both CCAdL and SGHMC. Nonetheless, CCAdL can still effectively control the system temperature (i.e. maintaining the correct distribution of the momenta) due to the use of the stabilizing Nose\u0301-Hoover control, while in SGHMC poor estimation of the covariance matrix may lead to significant deviations of the system temperature (as well as the distribution of the momenta), resulting in poor sampling of the parameters of interest."}, {"heading": "3.1 Covariance Estimation of Noisy Gradients", "text": "Under the assumption that the noise of the stochastic gradient follows a normal distribution, we apply a similar method to that of [2] to estimate the covariance matrix associated with the noisy gradient. If we let g(\u03b8;x) = \u2207\u03b8 log \u03c0(x|\u03b8) and assume that the size of subset n is large enough for the central limit theorem to hold, we have\n1\nn\nn \u2211\ni=1\ng(\u03b8t;xri) \u223c N ( Ex[g(\u03b8t;x)], 1\nn It\n)\n, (16)\nwhere It = Cov[g(\u03b8t;x)] is the covariance of the gradient at \u03b8t. Given that the noisy (stochastic) gradient based on current subset\u2207U\u0303(\u03b8t) = \u2212Nn \u2211n i=1 g(\u03b8t;xri)\u2212\u2207 log \u03c0(\u03b8t), and the clean (full) gradient \u2207U(\u03b8t) = \u2212 \u2211N\ni=1 g(\u03b8t;xi) \u2212\u2207 log \u03c0(\u03b8t), we have Ex[\u2207U\u0303(\u03b8t)] = Ex[\u2207U(\u03b8t)], and thus\n\u2207U\u0303(\u03b8t) = \u2207U(\u03b8t) +N ( 0, N2\nn It\n)\n, (17)\ni.e. \u03a3(\u03b8t) = N 2It/n. Assuming \u03b8t does not change dramatically over time, we use the moving average update to estimate It,\nI\u0302t = (1\u2212 \u03bat)I\u0302t\u22121 + \u03batV(\u03b8t) , (18)\nwhere \u03bat = 1/t, and\nV(\u03b8t) = 1 n\u2212 1 n \u2211\ni=1\n(g(\u03b8t;xri)\u2212 g\u0304(\u03b8t)) (g(\u03b8t;xri)\u2212 g\u0304(\u03b8t))T (19)\nis the empirical covariance of gradient. g\u0304(\u03b8t) represents the mean gradient of the log likelihood computed from a subset. As proved in [2], this estimator has a convergence order of O(1/N).\nAs already mentioned, estimating the full covariance matrix is computationally infeasible in high dimension. However, we have found that employing a diagonal approximation of the covariance matrix (i.e. only estimating the variance along each dimension of the noisy gradient), works quite well in practice, as demonstrated in Section 4.\nThe procedure of the CCAdL method is summarized in Algorithm 1, where we simply used M = I, \u03b2 = 1, and \u00b5 = Nd in order to be consistent with the original implementation of SGNHT [5].\nNote that this is a simple, first order (in terms of the stepsize) algorithm. A recent article [15] has introduced higher order of accuracy schemes which can improve accuracy, but our interest here is in the direct comparison of the underlying machinery of SGHMC, SGNHT, and CCAdL, so we avoid further modifications and enhancements related to timestepping at this stage.\nAlgorithm 1 Covariance-Controlled Adaptive Langevin (CCAdL)\n1: Input: h, A, {\u03bat}T\u0302t=1. 2: Initialize \u03b80, p0, I0, and \u03be0 = A. 3: for t = 1, 2, . . . , T\u0302 do 4: \u03b8t = \u03b8t\u22121 + pt\u22121h; 5: Estimate I\u0302t using Eq. (18); 6: pt = pt\u22121 \u2212\u2207U\u0303(\u03b8t)h\u2212 h2 N 2 n I\u0302tpt\u22121h\u2212 \u03bet\u22121pt\u22121h+ \u221a 2AhN (0, 1); 7: \u03bet = \u03bet\u22121 + ( pTt pt/Nd \u2212 1 )\nh; 8: end for\nIn the following section, we compare the newly-established CCAdL method with SGHMC and SGNHT on various machine learning tasks to demonstrate the benefits of CCAdL in Bayesian sampling with a noisy gradient."}, {"heading": "4 Numerical Experiments", "text": ""}, {"heading": "4.1 Bayesian Inference for Gaussian Distribution", "text": "We first compare the performance of the newly-established CCAdL method with SGHMC and SGNHT for a simple task using synthetic data, i.e. Bayesian inference of both the mean and variance of a one-dimensional normal distribution. We apply the same experimental setting as in [5]. We generated N = 100 samples from the standard normal distributionN (0, 1). We used the likelihood function ofN (xi|\u00b5, \u03b3\u22121) and assigned Normal-Gamma distribution as their prior distribution, i.e. \u00b5, \u03b3 \u223c N (\u00b5|0, \u03b3)Gam(\u03b3|1, 1). Then the corresponding posterior distribution is another Normal-Gamma distribution, i.e. (\u00b5, \u03b3)|X \u223c N (\u00b5|\u00b5N , (\u03baN\u03b3)\u22121)Gam(\u03b3|\u03b1N , \u03b2N ), with\n\u00b5N = N x\u0304\nN + 1 , \u03baN = 1 +N , \u03b1N = 1 +\nN\n2 , \u03b2N = 1 +\nN \u2211\ni=1\n(xi \u2212 x\u0304)2 2 + N x\u03042 2(1 +N) ,\nwhere x\u0304 = \u2211N\ni=1 xi/N . A random subset of size n = 10 was selected at each timestep to approximate the full gradient, resulting in the following stochastic gradients,\n\u2207\u00b5U\u0303 = (N + 1)\u00b5\u03b3 \u2212 \u03b3N\nn\nn \u2211\ni=1\nxri , \u2207\u03b3U\u0303 = 1\u2212 N + 1\n2\u03b3 +\n\u00b52\n2 +\nN\n2n\nn \u2211\ni=1\n(xri \u2212 \u00b5)2 .\nIt can be seen that the variance of the stochastic gradient noise is no longer constant and actually depends on the size of the subset, n, and the values of \u00b5 and \u03b3 in each iteration. This directly violates the constant noise variance assumption of SGNHT [5], while CCAdL adjusts to the varying noise variance.\nThe marginal distributions of \u00b5 and \u03b3 obtained from various methods with different combinations of h and A were compared and plotted in Figure 1, with Table 1 consisting of the corresponding root mean square error (RMSE) of the distribution and autocorrelation time from 106 samples. In most of the cases, both SGNHT and CCAdL easily outperform the SGHMC method possibly due to the presence of the Nose\u0301-Hoover device, with SGHMC only\nshowing superiority with small values of h and large value of A, neither of which is desirable in practice as discussed in Section 3. Between SGNHT and the newly-proposed CCAdL method, the latter achieves better performance in each of the cases investigated, highlighting the importance of the covariance control with parameter-dependent noise."}, {"heading": "4.2 Large-scale Bayesian Logistic Regression", "text": "We then consider a Bayesian logistic regression model trained on the benchmark MNIST dataset for binary classification of digits 7 and 9 using 12, 214 training data points, with a test set of size 2037. A 100-dimensional random projection of the original features was used. We used the likelihood function of \u03c0 (\n{xi, yi}Ni=1|w ) \u221d \u220fNi=1 1/ ( 1 + exp(\u2212yiwTxi) )\n, and the prior distribution of \u03c0(w) \u221d exp(\u2212wTw/2), respectively. A subset of size n = 500 was used at each timestep. Since the dimensionality of this problem is not that high, a full covariance estimation was used for CCAdL.\nWe investigate the convergence speed of each method through measuring test log likelihood using posterior mean against the number of passes over the entire dataset, see Figure 2 (top row). CCAdL displays significant improvements over SGHMC and SGNHT with different values of h and A: (1) CCAdL converges much faster than the other two, which also indicates its faster mixing speed and shorter burn-in period; (2) CCAdL shows robustness in different values of the \u201ceffective friction\u201d A, with SGHMC and SGNHT relying on a relative large value of A (especially the SGHMC method) which is intended to dominate the gradient noise.\nTo compare the sample quality obtained from each method, Figure 2 (bottom row) plots the two-dimensional marginal posterior distribution in randomly-selected dimensions of 2 and 5 based on 106 samples from each method after the burn-in period (i.e. we start to collect samples when the test log likelihood stabilizes). The true (reference) distribution was obtained by a sufficiently long run of standard HMC. We implemented 10 runs of standard HMC and found there was no variation between these runs, which guarantees its qualification as the true (reference) distribution. Again, CCAdL shows much better performance than SGHMC and SGNHT. Note that the SGHMC does not even fit in the region of the plot, and in fact it shows significant deviation even in the estimation of the mean."}, {"heading": "4.3 Discriminative Restricted Boltzmann Machine (DRBM)", "text": "DRBM [11] is a self-contained non-linear classifier, and the gradient of its discriminative objective can be explicitly computed. Due to the limited space, we refer the readers to [11] for more details. We trained a DRBM on different large-scale multi-class datasets from LIBSVM\u2217 dataset collection, including connect-4, letter, and SensIT Vehicle acoustic. The detailed information of these datasets are presented in Table 2.\n\u2217http://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/multiclass.html\nWe selected the number of hidden units using cross-validation to achieve their best results. Since the dimension of parameters, Nd, is relatively high, we only used diagonal covariance matrix estimation for CCAdL to significantly reduce the computational cost, i.e. only estimating the variance along each dimension. The size of the subset was chosen as 500\u20131000 to obtain a reasonable variance estimation. For each dataset, we chose the first 20% of the total number of passes over the entire dataset as the burn-in period, and collected the remaining samples for prediction.\nThe error rate computed by various methods on the test set using posterior mean against number of passes over entire dataset was plotted in Figure 3. It can be observed that SGHMC and SGNHT only work well with a large value of the effective friction A, which corresponds to a strong random walk effect and thus slows down the convergence. On the contrary, CCAdL works reliably (much better than the other two) in a wide range of A, and more importantly in the large stepsize regime, which speeds up the convergence rate in relation to the computational work performed. It can be easily seen that the performance of SGHMC heavily relies on using a small value of h and large value of A, which significantly limits its usefulness in practice."}, {"heading": "5 Conclusions and Future Work", "text": "In this article, we have proposed a novel Covariance-Controlled Adaptive Langevin (CCAdL) formulation that can effectively dissipate parameter-dependent noise while maintaining a desirable invariant distribution. CCAdL combines ideas of SGHMC and SGNHT from the literature, but achieves significant improvements over each of these methods in practice. The additional error introduced by covariance estimation is expected to be small in a relative sense, i.e. substantially smaller than the error arising from the noisy gradient. Our findings have been verified in large-scale machine learning applications. In particular, we have consistently observed that SGHMC relies on a small stepsize h and large friction A, which significantly reduces its usefulness in practice as discussed. The techniques presented in this article could be of use in the more general setting of large-scale Bayesian sampling and optimization, which we leave for future work.\nA naive nonsymmetric splitting method has been applied for CCAdL for fair comparison in this article. However, we point out that optimal design of splitting methods in ergodic SDE systems has been explored recently in the mathematics community [1, 13, 14]. Moreover, it has been shown in [15] that a certain type of symmetric splitting method for the AdLangevin/SGNHT method with a clean (full) gradient inherits the superconvergence property (i.e. fourth order convergence to the invariant distribution for configurational quantities) recently demonstrated in the setting of Langevin dynamics [12,14]. We leave further exploration of this direction in the context of noisy gradients for future work."}, {"heading": "Acknowledgements", "text": "XS and ZZ gratefully acknowledge the financial support from the University of Edinburgh and China Scholarship Council."}], "references": [{"title": "Long time accuracy of Lie-Trotter splitting methods for Langevin dynamics", "author": ["A. Abdulle", "G. Vilmart", "K.C. Zygalakis"], "venue": "SIAM Journal on Numerical Analysis,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2015}, {"title": "Bayesian posterior sampling via stochastic gradient Fisher scoring", "author": ["S. Ahn", "A. Korattikara", "M. Welling"], "venue": "In Proceedings of the 29th International Conference on Machine Learning,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2012}, {"title": "Handbook of Markov Chain Monte Carlo", "author": ["S. Brooks", "A. Gelman", "G. Jones", "X.-L. Meng"], "venue": null, "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2011}, {"title": "Stochastic gradient Hamiltonian Monte Carlo", "author": ["T. Chen", "E.B. Fox", "C. Guestrin"], "venue": "In Proceedings of the 31st International Conference on Machine Learning,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2014}, {"title": "Bayesian sampling using stochastic gradient thermostats", "author": ["N. Ding", "Y. Fang", "R. Babbush", "C. Chen", "R.D. Skeel", "H. Neven"], "venue": "In Advances in Neural Information Processing Systems", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2014}, {"title": "Hybrid Monte Carlo", "author": ["S. Duane", "A.D. Kennedy", "B.J. Pendleton", "D. Roweth"], "venue": "Physics Letters B,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 1987}, {"title": "Understanding Molecular Simulation: From Algorithms to Applications, Second Edition", "author": ["D. Frenkel", "B. Smit"], "venue": null, "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2001}, {"title": "Computational Statistical Mechanics, Studies in Modern Thermodynamics", "author": ["W.G. Hoover"], "venue": "Elsevier Science,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 1991}, {"title": "A generalized guided Monte Carlo algorithm", "author": ["A.M. Horowitz"], "venue": "Physics Letters B,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 1991}, {"title": "Adaptive stochastic methods for sampling driven molecular systems", "author": ["A. Jones", "B. Leimkuhler"], "venue": "The Journal of Chemical Physics,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2011}, {"title": "Classification using discriminative restricted Boltzmann machines", "author": ["H. Larochelle", "Y. Bengio"], "venue": "In Proceedings of the 25th International Conference on Machine Learning,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2008}, {"title": "Rational construction of stochastic numerical methods for molecular sampling", "author": ["B. Leimkuhler", "C. Matthews"], "venue": "Applied Mathematics Research eXpress,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2013}, {"title": "Molecular Dynamics: With Deterministic and Stochastic Numerical Methods", "author": ["B. Leimkuhler", "C. Matthews"], "venue": null, "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2015}, {"title": "The computation of averages from equilibrium and nonequilibrium Langevin molecular dynamics", "author": ["B. Leimkuhler", "C. Matthews", "G. Stoltz"], "venue": "IMA Journal of Numerical Analysis,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2015}, {"title": "Adaptive thermostats for noisy gradient systems", "author": ["B. Leimkuhler", "X. Shang"], "venue": "arXiv preprint arXiv:1505.06889,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2015}, {"title": "Equation of state calculations by fast computing machines", "author": ["N. Metropolis", "A.W. Rosenbluth", "M.N. Rosenbluth", "A.H. Teller", "E. Teller"], "venue": "The Journal of Chemical Physics,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 1953}, {"title": "A unified formulation of the constant temperature molecular dynamics methods", "author": ["S. Nos\u00e9"], "venue": "The Journal of Chemical Physics,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 1984}, {"title": "A stochastic approximation method", "author": ["H. Robbins", "S. Monro"], "venue": "Annals of Mathematical Statistics,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 1951}, {"title": "Monte Carlo Statistical Methods, Second Edition", "author": ["C. Robert", "G. Casella"], "venue": null, "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2004}, {"title": "Non-) asymptotic properties of stochastic gradient Langevin dynamics", "author": ["S.J. Vollmer", "K.C. Zygalakis", "Y.W. Teh"], "venue": "arXiv preprint arXiv:1501.00438,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2015}, {"title": "Bayesian learning via stochastic gradient Langevin dynamics", "author": ["M. Welling", "Y.W. Teh"], "venue": "In Proceedings of the 28th International Conference on Machine Learning,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2011}], "referenceMentions": [{"referenceID": 15, "context": "For instance, standard Markov Chain Monte Carlo (MCMC) methods [16], as well as typical Hybrid Monte Carlo (HMC) methods [3, 6, 9], require the calculation of the acceptance probability and the creation of informed proposals based on the whole dataset.", "startOffset": 63, "endOffset": 67}, {"referenceID": 2, "context": "For instance, standard Markov Chain Monte Carlo (MCMC) methods [16], as well as typical Hybrid Monte Carlo (HMC) methods [3, 6, 9], require the calculation of the acceptance probability and the creation of informed proposals based on the whole dataset.", "startOffset": 121, "endOffset": 130}, {"referenceID": 5, "context": "For instance, standard Markov Chain Monte Carlo (MCMC) methods [16], as well as typical Hybrid Monte Carlo (HMC) methods [3, 6, 9], require the calculation of the acceptance probability and the creation of informed proposals based on the whole dataset.", "startOffset": 121, "endOffset": 130}, {"referenceID": 8, "context": "For instance, standard Markov Chain Monte Carlo (MCMC) methods [16], as well as typical Hybrid Monte Carlo (HMC) methods [3, 6, 9], require the calculation of the acceptance probability and the creation of informed proposals based on the whole dataset.", "startOffset": 121, "endOffset": 130}, {"referenceID": 3, "context": "In order to improve computational efficiency, a number of stochastic gradient methods [4, 5, 20, 21] have been proposed in the setting of Bayesian sampling based on random (and much smaller) subsets to approximate the likelihood of the whole dataset, thus substantially reducing the computational cost in practice.", "startOffset": 86, "endOffset": 100}, {"referenceID": 4, "context": "In order to improve computational efficiency, a number of stochastic gradient methods [4, 5, 20, 21] have been proposed in the setting of Bayesian sampling based on random (and much smaller) subsets to approximate the likelihood of the whole dataset, thus substantially reducing the computational cost in practice.", "startOffset": 86, "endOffset": 100}, {"referenceID": 19, "context": "In order to improve computational efficiency, a number of stochastic gradient methods [4, 5, 20, 21] have been proposed in the setting of Bayesian sampling based on random (and much smaller) subsets to approximate the likelihood of the whole dataset, thus substantially reducing the computational cost in practice.", "startOffset": 86, "endOffset": 100}, {"referenceID": 20, "context": "In order to improve computational efficiency, a number of stochastic gradient methods [4, 5, 20, 21] have been proposed in the setting of Bayesian sampling based on random (and much smaller) subsets to approximate the likelihood of the whole dataset, thus substantially reducing the computational cost in practice.", "startOffset": 86, "endOffset": 100}, {"referenceID": 20, "context": "Stochastic Gradient Langevin Dynamics (SGLD) [21], combining the ideas of stochastic optimization [18] and traditional Brownian dynamics, with a sequence of stepsizes decreasing to zero.", "startOffset": 45, "endOffset": 49}, {"referenceID": 17, "context": "Stochastic Gradient Langevin Dynamics (SGLD) [21], combining the ideas of stochastic optimization [18] and traditional Brownian dynamics, with a sequence of stepsizes decreasing to zero.", "startOffset": 98, "endOffset": 102}, {"referenceID": 19, "context": "[20], where a modified SGLD (mSGLD) was also introduced that was designed to reduce sampling bias.", "startOffset": 0, "endOffset": 4}, {"referenceID": 3, "context": "SGLD generates samples from first order Brownian dynamics, and thus, with a fixed timestep, one can show that it is unable to dissipate excess noise in gradient approximations while maintaining the desired invariant distribution [4].", "startOffset": 229, "endOffset": 232}, {"referenceID": 3, "context": "[4], which relies on second order Langevin dynamics and incorporates a parameter-dependent diffusion matrix that is intended to effectively offset the stochastic perturbation of the gradient.", "startOffset": 0, "endOffset": 3}, {"referenceID": 4, "context": "Moreover, as pointed out in [5] poor estimation of it may have a significant adverse influence on the sampling of the target distribution; for example the effective system temperature may be altered.", "startOffset": 28, "endOffset": 31}, {"referenceID": 6, "context": "The \u201cthermostat\u201d idea, which is widely used in molecular dynamics [7, 13], was recently adopted in the Stochastic Gradient Nos\u00e9-Hoover Thermostat (SGNHT) by Ding et al.", "startOffset": 66, "endOffset": 73}, {"referenceID": 12, "context": "The \u201cthermostat\u201d idea, which is widely used in molecular dynamics [7, 13], was recently adopted in the Stochastic Gradient Nos\u00e9-Hoover Thermostat (SGNHT) by Ding et al.", "startOffset": 66, "endOffset": 73}, {"referenceID": 4, "context": "[5] in order to adjust the kinetic energy during simulation in such a way that the canonical ensemble is preserved (i.", "startOffset": 0, "endOffset": 3}, {"referenceID": 9, "context": "In fact, the SGNHT method is essentially equivalent to the Adaptive Langevin (Ad-Langevin) thermostat proposed earlier by Jones and Leimkuhler [10] in the molecular dynamics setting (see [15] for discussion).", "startOffset": 143, "endOffset": 147}, {"referenceID": 14, "context": "In fact, the SGNHT method is essentially equivalent to the Adaptive Langevin (Ad-Langevin) thermostat proposed earlier by Jones and Leimkuhler [10] in the molecular dynamics setting (see [15] for discussion).", "startOffset": 187, "endOffset": 191}, {"referenceID": 4, "context": "The underlying dynamics of the SGNHT [5] was taken up by Leimkuhler and Shang [15], together with the design of discretization schemes with high effective order of accuracy.", "startOffset": 37, "endOffset": 40}, {"referenceID": 14, "context": "The underlying dynamics of the SGNHT [5] was taken up by Leimkuhler and Shang [15], together with the design of discretization schemes with high effective order of accuracy.", "startOffset": 78, "endOffset": 82}, {"referenceID": 2, "context": "2 Bayesian Sampling with Noisy Gradients In the typical setting of Bayesian sampling [3, 19], one is interested in drawing states from a posterior distribution defined as \u03c0(\u03b8|X) \u221d \u03c0(X|\u03b8)\u03c0(\u03b8) , (1) where \u03b8 \u2208 RNd is the parameter vector of interest, X denotes the entire dataset, and, \u03c0(X|\u03b8) and \u03c0(\u03b8) are the likelihood and prior distributions, respectively.", "startOffset": 85, "endOffset": 92}, {"referenceID": 18, "context": "2 Bayesian Sampling with Noisy Gradients In the typical setting of Bayesian sampling [3, 19], one is interested in drawing states from a posterior distribution defined as \u03c0(\u03b8|X) \u221d \u03c0(X|\u03b8)\u03c0(\u03b8) , (1) where \u03b8 \u2208 RNd is the parameter vector of interest, X denotes the entire dataset, and, \u03c0(X|\u03b8) and \u03c0(\u03b8) are the likelihood and prior distributions, respectively.", "startOffset": 85, "endOffset": 92}, {"referenceID": 3, "context": "As in [4,5], the gradient noise is assumed to be Gaussian with mean zero and unknown variance, in which case one may rewrite the noisy force as F\u0303(\u03b8) = \u2212\u2207U(\u03b8) + \u221a \u03a3(\u03b8)MR , (6) where M typically is a diagonal matrix, \u03a3(\u03b8) represents the covariance matrix of the noise and R is a vector of i.", "startOffset": 6, "endOffset": 11}, {"referenceID": 4, "context": "As in [4,5], the gradient noise is assumed to be Gaussian with mean zero and unknown variance, in which case one may rewrite the noisy force as F\u0303(\u03b8) = \u2212\u2207U(\u03b8) + \u221a \u03a3(\u03b8)MR , (6) where M typically is a diagonal matrix, \u03a3(\u03b8) represents the covariance matrix of the noise and R is a vector of i.", "startOffset": 6, "endOffset": 11}, {"referenceID": 4, "context": "[5], has the following underlying dynamics, written as a standard It\u014d stochastic differential equation (SDE) system [15]: d\u03b8 = Mpdt , dp = \u2212\u2207U(\u03b8)dt+ \u03c3 \u221a hMdW\u2212 \u03bepdt+ \u221a", "startOffset": 0, "endOffset": 3}, {"referenceID": 14, "context": "[5], has the following underlying dynamics, written as a standard It\u014d stochastic differential equation (SDE) system [15]: d\u03b8 = Mpdt , dp = \u2212\u2207U(\u03b8)dt+ \u03c3 \u221a hMdW\u2212 \u03bepdt+ \u221a", "startOffset": 116, "endOffset": 120}, {"referenceID": 3, "context": "where, colloquially, dW and dWA, respectively, represent vectors of independent Wiener increments; and are often informally denoted by N (0,dtI) [4].", "startOffset": 145, "endOffset": 148}, {"referenceID": 7, "context": "The auxiliary variable \u03be \u2208 R is governed by a Nos\u00e9-Hoover device [8,17] via a negative feedback mechanism, i.", "startOffset": 65, "endOffset": 71}, {"referenceID": 16, "context": "The auxiliary variable \u03be \u2208 R is governed by a Nos\u00e9-Hoover device [8,17] via a negative feedback mechanism, i.", "startOffset": 65, "endOffset": 71}, {"referenceID": 9, "context": "Proposition 1: (See Jones and Leimkuhler [10]) The SGNHT method (8) preserves the modified Gibbs (stationary) distribution", "startOffset": 41, "endOffset": 45}, {"referenceID": 4, "context": "[5] claimed that it is reasonable to assume the covariance matrix \u03a3(\u03b8) is constant when the size of the dataset, N , is large, in which case the variance of the posterior of \u03b8 is small.", "startOffset": 0, "endOffset": 3}, {"referenceID": 3, "context": "[4], which uses dynamics of the following form: d\u03b8 = Mpdt , dp = \u2212\u2207U(\u03b8)dt+ \u221a h\u03a3(\u03b8)MdW\u2212Apdt+ \u221a 2\u03b2\u22121 (AI\u2212 h\u03a3(\u03b8)/2)MdWA .", "startOffset": 0, "endOffset": 3}, {"referenceID": 3, "context": "However, too-large a friction would essentially reduce SGHMC to SGLD, which is not desirable, as pointed out in [4], while extremely small stepsize would significantly impact the computational efficiency.", "startOffset": 112, "endOffset": 115}, {"referenceID": 1, "context": "1 Covariance Estimation of Noisy Gradients Under the assumption that the noise of the stochastic gradient follows a normal distribution, we apply a similar method to that of [2] to estimate the covariance matrix associated with the noisy gradient.", "startOffset": 174, "endOffset": 177}, {"referenceID": 1, "context": "As proved in [2], this estimator has a convergence order of O(1/N).", "startOffset": 13, "endOffset": 16}, {"referenceID": 4, "context": "The procedure of the CCAdL method is summarized in Algorithm 1, where we simply used M = I, \u03b2 = 1, and \u03bc = Nd in order to be consistent with the original implementation of SGNHT [5].", "startOffset": 178, "endOffset": 181}, {"referenceID": 14, "context": "A recent article [15] has introduced higher order of accuracy schemes which can improve accuracy, but our interest here is in the direct comparison of the underlying machinery of SGHMC, SGNHT, and CCAdL, so we avoid further modifications and enhancements related to timestepping at this stage.", "startOffset": 17, "endOffset": 21}, {"referenceID": 4, "context": "We apply the same experimental setting as in [5].", "startOffset": 45, "endOffset": 48}, {"referenceID": 4, "context": "This directly violates the constant noise variance assumption of SGNHT [5], while CCAdL adjusts to the varying noise variance.", "startOffset": 71, "endOffset": 74}, {"referenceID": 10, "context": "3 Discriminative Restricted Boltzmann Machine (DRBM) DRBM [11] is a self-contained non-linear classifier, and the gradient of its discriminative objective can be explicitly computed.", "startOffset": 58, "endOffset": 62}, {"referenceID": 10, "context": "Due to the limited space, we refer the readers to [11] for more details.", "startOffset": 50, "endOffset": 54}, {"referenceID": 0, "context": "However, we point out that optimal design of splitting methods in ergodic SDE systems has been explored recently in the mathematics community [1, 13, 14].", "startOffset": 142, "endOffset": 153}, {"referenceID": 12, "context": "However, we point out that optimal design of splitting methods in ergodic SDE systems has been explored recently in the mathematics community [1, 13, 14].", "startOffset": 142, "endOffset": 153}, {"referenceID": 13, "context": "However, we point out that optimal design of splitting methods in ergodic SDE systems has been explored recently in the mathematics community [1, 13, 14].", "startOffset": 142, "endOffset": 153}, {"referenceID": 14, "context": "Moreover, it has been shown in [15] that a certain type of symmetric splitting method for the AdLangevin/SGNHT method with a clean (full) gradient inherits the superconvergence property (i.", "startOffset": 31, "endOffset": 35}, {"referenceID": 11, "context": "fourth order convergence to the invariant distribution for configurational quantities) recently demonstrated in the setting of Langevin dynamics [12,14].", "startOffset": 145, "endOffset": 152}, {"referenceID": 13, "context": "fourth order convergence to the invariant distribution for configurational quantities) recently demonstrated in the setting of Langevin dynamics [12,14].", "startOffset": 145, "endOffset": 152}], "year": 2015, "abstractText": "Monte Carlo sampling for Bayesian posterior inference is a common approach used in machine learning. The Markov Chain Monte Carlo procedures that are used are often discrete-time analogues of associated stochastic differential equations (SDEs). These SDEs are guaranteed to leave invariant the required posterior distribution. An area of current research addresses the computational benefits of stochastic gradient methods in this setting. Existing techniques rely on estimating the variance or covariance of the subsampling error, and typically assume constant variance. In this article, we propose a covariance-controlled adaptive Langevin thermostat that can effectively dissipate parameter-dependent noise while maintaining a desired target distribution. The proposed method achieves a substantial speedup over popular alternative schemes for large-scale machine learning applications.", "creator": "LaTeX with hyperref package"}}}