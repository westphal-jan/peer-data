{"id": "1511.02290", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "7-Nov-2015", "title": "Combining Privileged Information to Improve Context-Aware Recommender Systems", "abstract": "A recommender system is an information filtering technology which can be used to predict preference ratings of items (products, services, movies, etc) and/or to output a ranking of items that are likely to be of interest to the user. Context-aware recommender systems (CARS) learn and predict the tastes and preferences of users by incorporating available contextual information in the recommendation process. One of the major challenges in context-aware recommender systems research is the lack of automatic methods to obtain contextual information for these systems. Therefore, it is important to evaluate the importance of user-level data to the recommender system for the purposes of predicting preference ratings for products and services.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "histories": [["v1", "Sat, 7 Nov 2015 03:04:02 GMT  (180kb,D)", "http://arxiv.org/abs/1511.02290v1", null]], "reviews": [], "SUBJECTS": "cs.IR cs.AI", "authors": ["camila v sundermann", "marcos a domingues", "ricardo m marcacini", "solange o rezende"], "accepted": false, "id": "1511.02290"}, "pdf": {"name": "1511.02290.pdf", "metadata": {"source": "CRF", "title": "Combining Privileged Information to Improve Context-Aware Recommender Systems", "authors": ["Camila V. Sundermann", "Marcos A. Domingues", "Ricardo M. Marcacini", "Solange O. Rezende"], "emails": ["solange}@icmc.usp.br", "ricardo.marcacini@ufms.br"], "sections": [{"heading": null, "text": "Keywords\u2014Contextual Information; Context-Aware Recommender Systems; Text Mining; Topic Hierarchy; Named Entities; Domain Terms\nI. INTRODUCTION\nA recommender system is an information filtering technology which can be used to predict preference ratings of items (products, services, movies, etc) and/or to output a ranking of items that are likely to be of interest to the user [21]. This kind of system has emerged in order to reduce the difficulty of users to choose the product or service that most meets their needs. Many areas have been using recommender systems, mainly some web sites, like Amazon1, Netflix2 and Last.fm3.\nRecommender systems usually use web access logs which represent the interaction activity between users and items. Traditional recommender systems consider only the two entities,\n1http://www.amazon.com 2http://www.netflix.com 3http://www.last.fm\nitems and users, to build the recommendation model. However, the use of contextual information can improve the recommendation process in some cases [2], [12]. The researchers that already investigated the use of context discovered that the quality of recommendations increases when additional information, like time, place, and so on, is used.\nThe concept context can assume different definitions. In this paper we consider that context is any information that can be used to characterize the situation of an entity [11]. An example of application in which to consider contextual information can be important is movie recommendation. An user can prefer watch a love story with his girlfriend on Saturday night and a comedy with his friends during the week. So an online video store can recommend the movie that more corresponds to the users context.\nAlthough the proven importance of the use of contextual information in the recommendation process, there is still a lack of automatic methods to obtain such information. In a contextaware recommender system is possible to consider the context of the user or the context of the item. In this work we focus on the context extracted for the items (in our case, web pages).\nThe contextual information can be represented and structured in various ways. A form of organizing this information is using hierarchical structures. In [2] and [20], the researchers represented the context as trees. Given this possibility of hierarchical organization of context, we have been using topic hierarchies as a way to organize and extract the context of the textual content of web pages [13], [24].\nMost of the methods in the literature to build topic hierarchies represent the texts as a traditional bag-of-words, i.e., these methods consider the terms of texts as a disordered set of words. In [13], we constructed topic hierarchies of web pages by using traditional bag-of-words, and the extracted topics were used as context of these pages in context-aware recommender systems. However, Marcacini and Rezende [17] proposed a method, called LUPI-based Incremental Hierarchical Clustering (LIHC) to construct topic hierarchies that uses besides the bag-of-words (technical information), also the privileged information, which is a more valuable kind of information extracted from texts. In [24], we constructed topic\nar X\niv :1\n51 1.\n02 29\n0v 1\n[ cs\n.I R\n] 7\nN ov\n2 01\n5\nhierarchies of the web pages using the method LIHC. We considered the bag-of-words and the named entities, extracted from the web pages, as privileged information, and we used the topics as the contextual information of the web pages in context-aware recommender systems. However, named entities are one of the various types of information that can be considered as privileged information.\nThe original LIHC method used only one type of privileged information to construct the topic hierarchies, in other words, it did not work with more than a kind of privileged information at the same time. In this paper we extend the method LIHC to be able to work with two kinds of privileged information, i.e., to construct topic hierarchies using besides the technical information, also other two kinds of information (privileged information). So, we propose to use topic hierarchies constructed by using three kinds of information: bag-of-words (technical information), named entities (privileged information I) and domain terms (privileged information II). The aim of this work is to combine this information and evaluate the impact of the use of the topics extracted from this combination as contextual information in context-aware recommender systems.\nThis paper is structured as follows: in Section II, we report the related work. In Section III, we present our proposal. We evaluate our proposal in Section IV. And, finally, in Section V, we present conclusion and future work."}, {"heading": "II. RELATED WORK", "text": "There are three different ways to acquire contextual information: explicitly, implicitly and inferred [3]. The explicit acquisition methods collect the contextual information through direct questions to the users. The implicit acquisition methods get contextual information directly from Web data or environment. The inference methods obtain contextual information using data an text mining techniques. In this paper, we infer context from web pages using text mining techniques. Following, some related works are presented.\nIn [16], Li et al. proposed methods to extract contextual information from online reviews. They investigated available restaurant review data and four types of contextual information for a meal: the company (if the meal involved multiple people), occasion (for which occasions is the event), time (what time of the day) and location (in which city the event took place). They developed their algorithms by using existing natural language processing tools such as GATE tool4. Hariri et al. [14] introduced a context-aware recommendation system that obtains contextual information by mining hotel reviews made by users, and combine them with user\u2019s rating historic to calculate a utility function over a set of items. They used a hotel review dataset from \u201cTrip Advisor website\u201d5.\nThe methods proposed by Li et al. [16] and Hariri et al. [14] assume there are explicit contextual information in reviews, and such information is obtained for each review by mapping it to the labels. Therefore, they use supervised methods to learn the labels. The advantage of our proposal is that it exploits unsupervised methods to learn topic hierarchies. Therefore, it does not need a mapping between reviews and labels.\n4http://gate.ac.uk 5http://www.tripadvisor.com\nAciar [1] proposed a technique to detect sentences of reviews with contextual information. She applied text mining tools to define sets of rules for identifying such sentences with context. In her work the phrases are classified into two categories: \u201cContextual\u201d and \u201cPreferences\u201d. The category \u201cContextual\u201d groups phrases that present information on the context in which the review was written. The category \u201cPreferences\u201d groups phrases that present information about the features that consumers evaluated.\nOur work differs from the Aciar\u2019s method since it is capable of using more text mining techniques, and these techniques are unsupervised, to extract contextual information. Aciar uses supervised techniques and conduct the evaluation of her method by using a case study, i.e., she does not compare her method results against other methods in the literature. Besides, she does not discuss the use of the extracted information in the recommendation process.\nHo et al. [15] proposed an approach to mine future spatiotemporal events from news articles, and thus provide information for location-aware recommendation systems. A future event consists of its geographic location, temporal pattern, sentiment variable, news title, key phrase, and news article URL. Besides that, their method is unsupervised and also extracts topics.\nIn [15], the contextual information that Ho et al. extracted are related to time and local. The information of time is extracted from the timestamp of the article publication. To extract information of local, they also used named entity recognition. However, they did not evaluate the impact of the contextual information that they extracted in the recommender systems. The authors only presented some results about the evaluation of the context extraction process.\nBauman and Tuzhilin [4] presented a method to find relevant contextual information from reviews of users. In this method, the reviews are classified as \u201cspecific\u201d and \u201cgeneric\u201d. They found that contextual information is contained mainly in the specific reviews, which are those that describe specific visits of a user to an establishment. Therefore, the context is extracted from the \u201cspecific\u201d reviews by means of two methods: \u201cword-based\u201d and \u201cLDA-based\u201d.\nIn [4], Bauman and Tuzhilin consider that the contextual information is not known a priori. Besides that, their method is unsupervised and also extracts topics. Our method differs from theirs since it extracts topics using also privileged information, which enrich the contextual information.\nOur method has many advantages over the other ones proposed in the literature. In general, it does not need previous information (for example, labels). It uses unsupervised methods and combines technical information with privileged information, which enriches the contextual information. Additionally, the context extracted is about the item (web pages) and not the user. Finally, our results, presented in Section IV, demonstrate that our contextual information is able to improve the quality of recommendations."}, {"heading": "III. OUR PROPOSAL", "text": "As already stated, the term context can assume many definitions depending on what area it is being treated in. We consider\nthe definition given by Dey [11] that says: \u201cContext is any definition that can be used to characterize the situation of an entity\u201d. In our work the entities are web pages (items). Besides the definition, the contextual information can be represented using many structures. Some researchers treat the context as a hierarchical structure and represent it using trees. For example, Panniello and Gorgoglione [20] represent the attribute \u201cperiod of year\u201d as a tree like illustrated in Figure 1.\nThe idea of this research is representing the contextual information using a hierarchical structure called topic hierarchy. Topic hierarchies organize texts into groups and subgroups, and for each group, topics are extracted to represent the main issue of the group. Constructing a topic hierarchy of the items in a recommender system means grouping them by context, i.e., the topics extracted for each group represent the context of the group. Items of a same group are in the same context. We construct topic hierarchies by using the textual content of the web pages, and use the topics as contextual information in context-aware recommender systems.\nTopics hierarchies can be constructed using hierarchical clustering. Traditional methods represent the textual collection as a bag-of-words [22], also known as technical information [25]. However, we can extract concepts from the texts that are not represented in a simple bag-of-words. Named entities and domain terms are good examples of concepts that may be formed by a word or by more than a word and that are identified and extracted by using more advanced text preprocessing techniques. Thus, these two kinds of information, named entity and domain term, are considered in this paper as privileged information.\nThe term Named Entity was born in the Message Understanding Conferences (MUC) and includes names of people, organizations and locations, besides numeric expressions like time, date, money and percent expressions [23]. The named entity recognition is a task that involves identifying words or expressions that belong to categories of named entities [19]. For example, in the sentence: \u201cAna Maria works at Petrobras, in Brazil, since 1989\u201d. \u201cAna Maria\u201d is recognized as a person, \u201cPetrobras\u201d as an organization, \u201cBrazil\u201d as a location and \u201c1989\u201d as a date.\nDespite the importance of term extraction task, there is still no consensus on the formal definition of what the \u201cterm\u201d is. A definition widely accepted of term is given by Cabre\u0301 and Vivaldi [6], which is: \u201cterminological unit obtained from specialized domain\u201d. In most researches found in literature, the authors state that terms are generally nominal units, since they describe concepts. For example, in the Ecologic domain, the\nterms \u201cclimate\u201d, \u201cplant\u201d, \u201cAtlantic forest\u201d and \u201csoil moisture\u201d are examples of domain terms [8]. The terms are used in applications such as information retrieval, information extraction and summarization.\nIn our proposal, we instantiate the LUPI-based Incremental Hierarchical Clustering (LIHC) method [17] to construct topic hierarchies using one type of privileged information and technical information. Let Dpri = {dp1, . . . , dpm} and Dtec = {dt1, . . . , dtm, dtm+1, . . . , dn} the sets of documents represented by the privileged information (totaling m documents) and with technical information (totaling n documents), respectively, where dp \u2208 Dp and dt \u2208 Dt. Note that the number of documents represented by the privileged information, in general, is smaller than the number of documents represented by technical information, i.e, m \u2264 n. This is due to the fact that a significant number of documents do not contain features extracted from privileged information (e.g., named entities and domain terms).\nThe subset of documents that contain the privileged information and technical information, Y = {(dt1, d p 1), . . . , (d t m, d p m)}, is used for learning the initial clustering model. In this case, various clustering algorithms are run (or repeated runs of the same algorithm with different parameter values) to obtain several clusters from the subset Y . To aggregate the generated clusters, the LIHC method obtains two co-association matrices M t(i, j) and Mp(i, j) which represent, respectively, the technical information (bag-of-words) clustering model and privileged information clustering model. The combination of these two clustering models is performed by using a consensual co-association matrix:\nMF (i, j) = (1\u2212 \u03b1)M t(i, j) + \u03b1Mp(i, j), (1)\nfor all items i and j. In this case, the parameter \u03b1 is a combination factor (0 \u2264 \u03b1 \u2264 1) that indicates the importance of the privileged information space in the final co-association matrix. The initial model of the LIHC method is obtained by applying any hierarchical clustering algorithm from the matrix MF . The remaining text documents, i.e., the documents without privileged information, are inserted incrementally into hierarchical clustering by using the nearest neighbor technique. For the construction of topic hierarchies, the topic extraction is based on selection of the most frequent terms of each cluster.\nIn [24], we constructed topic hierarchies of the web pages by using the method LIHC and considering as privileged information only named entities. In this paper, we construct topic hierarchies by combining named entities and domain terms as privileged information, varying the weight of each type of information. To incorporate the two types of privileged information, the method LIHC was extended as follows.\nFirst, Dpri is divided into two sets Dne (the set of the privileged information I named entities) and Ddt (the set of the privileged information II domain terms). Let Dne = {dne1 , . . . , dner } be the set of documents with named entities (totaling r documents) and Ddt = {ddt1 , . . . , ddts } be the set of documents with domain terms (totaling s documents). Similarly, the matrix Mp(i, j) is divided into two matrices Mne (the named entities clustering model) and Mdt (the domain terms clustering model). The combination of the three\nclustering models (M t, Mne and Mdt) is performed by using the follow consensual co-association matrix:\nMnf (i, j) = (1\u2212\u03b1)M t(i, j)+\u03b2Mne(i, j)+\u03b8Mdt(i, j), (2)\nwhere, \u03b2 and \u03b8 indicate the importance of the named entities and domain terms, respectively, in the final co-association matrix, and \u03b2 + \u03b8 = \u03b1. In the next section, we empirically evaluate our proposal by using different values of \u03b1, \u03b2 and \u03b8 to construct the topic hierarchies."}, {"heading": "IV. EMPIRICAL EVALUATION", "text": "The aim of our work is to study the impact of the context, extracted by our method, in context-aware recommender systems. So, the empirical evaluation consists of comparing the results of the algorithms C. Reduction [2], DaVI-BEST [12], Weight PoF and Filter PoF [20], all them using our contextual information, against the uncontextual algorithm Item-Based Collaborative Filtering (IBCF) [10]. In this way, we compared the quality of the recommendations generated by using our context against the quality of the recommendations generated without using contextual information. In this section, we present the necessary details to understand our experiments: data set, baseline, context-aware recommender algorithms, experimental setup, evaluation measure and the results."}, {"heading": "A. Data Set", "text": "In the experiments we used a data set from a Portuguese website about agribusiness that consists of 4,659 users, 15,037 accesses and 1,543 web pages written in Portuguese language. To construct the topic hierarchies for these web pages, we used the textual content of the pages, eliminating header, footer and everything that do not pertaining to the main textual content.\nWe preprocessed the texts executing traditional text preprocessing tasks: stopword removal and stemming. The representations or \u201cterm value matrix\u201d were constructed using the term weighting measure TF-IDF (term frequency-inverse document frequency). Three representations were constructed: the traditional bag-of-words representation (technical information), the named entities representation (privileged information I) and the domain terms representation (privileged information II). We defined the weights testing different combinations of the two kinds of privileged information. The weights are shown in Table I.\nWe extracted the topics from the topic hierarchies considering three configurations {50, 100}, {15, 20} and {2, 7}. In this configuration {x, y}, that represents the granularity level, the parameter x identifies the minimum number of items allowed in the topic, while the parameter y identifies the maximum number of items per topic. Topics with more items associated to them mean topics more generic, while topics with fewer items associated to them mean topics more specific. So, the topics extracted by the configuration {50, 100} are more generic and the topics extracted by the configuration {2, 7} are more specific. The configuration {15, 20} are between the two others, and it was chosen because, in previous experiments, we obtained good results using this granularity level. Besides that, the more generic configuration extracts a lower number of topics, while the more specific configuration extracts a higher number of topics. Therefore, using this configuration\nwe can analyses if the number of topics extracted or the granularity level of this topics influences the quality of the recommendations. In Table II, we can see the number of topics extracted using each configuration."}, {"heading": "B. Supporting Tools and Methods", "text": "In the experiments we used JPretext6 and LIHC7 for the pre-processing and the hierarchical clustering of the items. These two tools are part of Torch [18], that is a set of tools developed to support text clustering and construction of topic hierarchies. JPretext transforms the collection of texts in a \u201cterm value matrix\u201d and LIHC tool implements the LUPIbased Incremental Hierarchical Clustering method.\nThe named entity recognition was performed by using REMBRANDT [7], a system that recognizes classes of named entities, like things, location, organization, people and others, in texts written in Portuguese. REMBRANDT uses Wikipedia8 as knowledge base for the classification of the entities.\n6http://sites.labic.icmc.usp.br/torch/msd2011/jpretext 7 http://sites.labic.icmc.usp.br/torch/doceng2013 8https://www.wikipedia.org\nLastly, for the domain term extraction we used the method MATE-ML (Automatic Term Extraction based on Machine Learning) [9], [8]. This method uses machine learning incorporating rich features of candidate terms. The steps of MATEML are: 1) Text Pre-Processing; 2) Extraction of linguistic, statistic and hybrid features; 3) Application of filters; and 4) Generation of inductive models based on machine learning."}, {"heading": "C. Baseline", "text": "In this paper we considered the un-contextual algorithm Item-Based Collaborative Filtering (IBCF) [10] as baseline. Let m be the number of users U = {u1, u2, ..., um} and n the number of items that can be recommended I = {i1, i2, ..., in}. An item-based collaborative filtering model M is a matrix representing the similarities among all pairs of items, according to a similarity measure. We used the cosine angle similarity measure, defined as:\nsim(i1, i2) = cos( \u2212\u2192 i1 , \u2212\u2192 i2 ) =\n\u2212\u2192 i1 \u00b7 \u2212\u2192 i2\n\u2016\u2212\u2192i1 \u2016 \u2217 \u2016 \u2212\u2192 i2 \u2016\n, (3)\nwhere \u2212\u2192 i1 and \u2212\u2192 i2 are rating vectors and the operator \u201c\u00b7\u201d denotes the dot-product of the two vectors. In our case, as we are dealing only with implicit feedback, the rating vectors are binary. The value 1 means that the user accessed the respective item, whereas the value 0 is the opposite.\nGiven an active user ua and his set of observable items O \u2286 I , the N recommendations are generated as follows. First, we identify the set of candidate items for recommendation R by selecting from the model all items i /\u2208 O. Then, for each candidate item r \u2208 R, we calculate its recommendation score as:\nscore(ua, O, r) = \u2211 i\u2208Kr\u2229O sim(r, i)\u2211 i\u2208Kr sim(r, i) , (4)\nwhere Kr is the set of the k most similar items to the candidate item r. The N candidate items with the highest values of score are recommended to the user ua.\nAll the context-aware recommendation algorithms used in this work are based on the Item-Based Collaborative Filtering. They are presented in the next section."}, {"heading": "D. Context-Aware Recommender Systems", "text": "Context-aware recommender systems (CARS) learn and predict the tastes and preferences of users by incorporating available contextual information in the recommendation process. According to Adomavicius and Tuzhilin [3], contextual information can be applied at various stages of the recommendation process. Following this criterion, these systems can be divided into three categories: contextual pre-filtering, contextual modeling and contextual post-filtering.\nIn this work, we evaluate the effects of using the contextual information, obtained from topic hierarchies, in four different context-aware recommender systems:\n\u2022 C. Reduction [2] (Pre-filtering approach): in pre-filtering approaches the contextual information is used as a label for filtering out those data that do not correspond to the specified contextual information. The remaining data that\npassed the filter (contextualized data) is used to generate the model. C. Reduction uses the contextual information as label to segment the data. A recommendation method is run for each contextual segment to determine which segment outperforms the traditional un-contextual recommendation model. The best contextual model is chosen to make the recommendation. Here the best model is the one that has the highest F1 measure. \u2022 DaVI-BEST [12] (Contextual modeling approach): in this approach the context is used in the recommendation model, i.e., the contextual information is part of the model together with user and item data. DaVI-BEST considers the contextual information as virtual items, using them along with the actual items in the recommendation model. All contextual information are evaluated and it is selected the dimension which better outperforms the traditional un-contextual recommendation model to make contextual recommendations. \u2022 Weight PoF and Filter PoF [20] (Contextual postfiltering approaches): these approaches use the contextual information to reorder and filter out the recommendation, respectively. Firstly, they apply the traditional algorithm to build the un-contextual recommendation model, ignoring the contextual information. Then, the probability of users to access the items given the right context is calculated. This probability is multiplied by scores of items to reorder the recommendations (Weight PoF) or is used as a threshold to filter them (Filter PoF)."}, {"heading": "E. Experimental Setup and Evaluation Measures", "text": "The protocol considered in this paper to measure the predictive ability of the recommender systems is the All But One protocol [5] with 10-fold cross validation, i.e., the set of documents is partitioned into 10 subsets. For each fold we use n\u22121 of these subsets for training and the rest for testing. The training set Tr is used to build the recommendation model. For each user in the test set Te, an item is hidden as a singleton set H . The remaining items represent the set of observable items O, that is used in the recommendation. Then, we compute Mean Average Precision (MAP@N ), where N equals 5 and 10 recommendations. For each configuration and measure, the 10-fold values are summarized by using mean and standard deviation. To compare two recommendation algorithms, we applied the two-sided paired t-test with a 95% confidence level.\nIn our empirical evaluation, we used the 4 most similar items to make the recommendations and 0.1 as a threshold in Filter PoF to filter out the recommendations, since these values provided the best results for this experiment."}, {"heading": "F. Results", "text": "In Table III, we show the results of our ranking evaluation by means of MAP@N . The results are obtained at four values of the combination factor (\u03b1 = 0.3, \u03b1 = 0.5, \u03b1 = 0.7 and \u03b1 = 1) and at three granularity levels, as described in Section IV-A. For each value of combination factor we also have the weights of each type of privileged information. To facilitate the understanding of the results, we mentioned the weight of technical information as BOW, the weight of the named entities as NE and the weight of domain terms as DT.\nThe presented results are for the three context-aware recommendation algorithms (C. Reduction, Weight PoF and Filter PoF), and also for the baseline IBCF. The DaVI-BEST results are not presented because they are equivalent to the IBCF results. So, there is no improvement by using this algorithm and the contextual information extracted with our proposal.\nThe analysis of the results can be divided into 3 questions: 1) What is the algorithm with the best results?; 2) What is the granularity with the best results?; and 3) What is the value of combination factor with the best results?\nAnswering the first question, we can observe that the algorithm Weight PoF presented the best results. This algorithm was also better than the baseline with statistical significance in all the experiments. For the second question, each algorithm\nwas better at different granularity levels. The C. Reduction and Weight PoF algorithms presented the best results at configuration {15, 20}, while the Filter PoF algorithm presented the best results at configuration {2, 7} (topics more specifics). The topics extracted by the configuration {50, 100} presented values of MAP not as high as for the others configurations, which shows that it is better to consider more specific topics and in larger amount.\nAnalyzing the values of combination factor, to answer the third question, C. Reduction and Weight PoF presented the best results for combination factor \u03b1 = 0.3, (BOW = 70% - EN = 20% - DT = 10%) and (BOW = 70%, EN = 10%, DT = 20%) respectively, and Filter PoF for combination factor \u03b1 = 0.5 (BOW = 50% - EN = 25% - DT = 25%).\nIn the graphic of Figure 2, we can analyze the best results of our experiments, i.e., the results for \u03b1 = 0.3 (BOW = 70%, EN = 10% and DT = 20%). The x-axis represents the granularities levels while the y-axis represents the values of MAP@10. Each line of the graphic is a recommender algorithm. It is evident that the three context-aware algorithms presented better results than the baseline IBCF, only Filter PoF presented a lower value of MAP at the granularity {50, 100}. At the granularity {2, 7}, this same algorithm presented better results than the others algorithms, what shows that this algorithm presents high values of MAP when topics more specifics are used. The algorithms Weight PoF and Filter PoF presented the best values of MAP at the granularity {15, 20}, being the Weight PoF the best of them."}, {"heading": "V. CONCLUSION", "text": "In this paper, we proposed to use contextual information from topic hierarchies, constructed by LIHC method, to improve the accuracy of context-aware recommender systems. The topic hierarchies was constructed considering traditional bag-of-words (technical information), and the combination of named entities (privileged information I) and domains terms (privileged information II). The empirical evaluation showed that by using topics from the topic hierarchies with combined privileged information as contextual information, contextaware recommender systems can provide better recommendations. The contextual information obtained from the three topic hierarchies improved the recommendations in 3 out of 4 recommender systems evaluated in this paper: C. Reduction, Weight PoF and Filter PoF (in most of the experiments).\nAs future work, we will finish some experiments in which we are comparing the combined use of the two types of privileged information against the results of our previous studies using named entities and domain terms separately. Additionally, we will also compare our proposal against other baselines proposed in the literature."}, {"heading": "ACKNOWLEDGMENT", "text": "The authors would like to thank FAPESP (grant #2010/20564-8, #2012/13830-9, and #2013/16039-3, Sa\u0303o Paulo Research Foundation (FAPESP)) and CAPES/Brazil for financial support."}], "references": [{"title": "Mining context information from consumer\u2019s reviews", "author": ["S. Aciar"], "venue": "CARS\u201910: Proceedings of the 2nd Workshop on Context-Aware Recommender Systems", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2010}, {"title": "Incorporating Contextual Information in Recommender Systems Using a Multidimensional Approach", "author": ["G. Adomavicius", "R. Sankaranarayanan", "S. Sen", "A. Tuzhilin"], "venue": "ACM Trans. Inf. Syst., 23(1):103\u2013145", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2005}, {"title": "Context-Aware Recommender Systems", "author": ["G. Adomavicius", "A. Tuzhilin"], "venue": "Recommender Systems Handbook, pages 217\u2013253. Springer", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2011}, {"title": "Discovering Contextual Information from User Reviews for Recommendation Purposes", "author": ["K. Bauman", "A. Tuzhilin"], "venue": "CBRecSys \u201914: Proceedings of Workshop on New Trends in Content-based Recommender Systems, pages 2\u20139", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2014}, {"title": "Empirical Analysis of Predictive Algorithms for Collaborative Filtering", "author": ["J.S. Breese", "D. Heckerman", "C. Kadie"], "venue": "Proc. of the Fourteenth Conference on Uncertainty in Artificial Intelligence, pages 43\u201352", "citeRegEx": "5", "shortCiteRegEx": null, "year": 1998}, {"title": "Automatic term detection: a reviw of current systems", "author": ["M.T. Cabr\u00e9", "R.E.J. Vivaldi"], "venue": "D. Bourigault, C. Jacquemin, and M.-C. L\u2019Homme, editors, Advances in Computational Terminology, pages 53\u201388. John Benjamins, Amsterdam / Philadelphia", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2001}, {"title": "REMBRANDT - Reconhecimento de Entidades Mencionadas Baseado em Relaes e ANlise Detalhada do Texto", "author": ["N. Cardoso"], "venue": "Desafios na avaliao conjunta do reconhecimento de entidades mencionadas: O Segundo HAREM, pages 195\u2013211. Linguateca", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2008}, {"title": "Extra\u00e7\u00e3o autom\u00e1tica de termos simples baseada em aprendizado de m\u00e1quina", "author": ["M.S. Conrado"], "venue": "PhD thesis, Instituto de Ci\u00eancias Matem\u00e1ticas e de Computa\u00e7\u00e3o - Universidade de S\u00e3o Paulo - USP", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2014}, {"title": "A Machine Learning Approach to Automatic Term Extraction using a Rich Feature Set. In NAACL-HLT-SRW \u201913: Proceedings of the Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies ", "author": ["M.S. Conrado", "T.A.S. Pardo", "S.O. Rezende"], "venue": "Student Research Workshop,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2013}, {"title": "Item-based top-N Recommendation Algorithms", "author": ["M. Deshpande", "G. Karypis"], "venue": "ACM Trans. Inf. Syst., 22(1):143\u2013177", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2004}, {"title": "Understanding and Using Context", "author": ["A.K. Dey"], "venue": "Personal and Ubiquitous Computing, 5(1):4\u20137", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2001}, {"title": "Dimensions As Virtual Items: Improving the Predictive Ability of top-N Recommender Systems", "author": ["M.A. Domingues", "A.M. Jorge", "C. Soares"], "venue": "Inf. Process. Manage., 49(3):698\u2013720", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2013}, {"title": "Using contextual information from topic hierarchies to improve context-aware recommender systems", "author": ["M.A. Domingues", "M.G. Manzato", "R.M. Marcacini", "C.V. Sundermann", "S.O. Rezende"], "venue": "In ICPR \u201914: Proceedings of the 22nd International Conference on Pattern Recognition,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2014}, {"title": "Context-Aware Recommendation Based on Review Mining", "author": ["N. Hariri", "B. Mobasher", "R. Burke", "Y. Zheng"], "venue": "Proc. of the 9th Workshop On Intelligent Techniques for Web Personalization and Recommender Systems, pages 30\u201336", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2011}, {"title": "Mining Future Spatiotemporal Events and Their Sentiment from Online News Articles for Location-aware Recommendation System", "author": ["S.-S. Ho", "M. Lieberman", "P. Wang", "H. Samet"], "venue": "Proc. of the First ACM SIGSPATIAL International Workshop on Mobile Geographic Information Systems, pages 25\u201332", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2012}, {"title": "Contextual Recommendation Based on Text Mining", "author": ["Y. Li", "J. Nie", "Y. Zhang"], "venue": "Proc. of the 23rd International Conference on Computational Linguistics: Posters, pages 692\u2013700", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2010}, {"title": "Incremental Hierarchical Text Clustering with Privileged Information", "author": ["R. Marcacini", "S.O. Rezende"], "venue": "Proc. of the 2013 ACM Symposium on Document Engineering", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2013}, {"title": "Torch: a tool for building topic hierarchies from growing text collections", "author": ["R.M. Marcacini", "S.O. Rezende"], "venue": "IX Workshop on Tools and Applications. In 8th Brazilian Symposium on Multimedia and the Web", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2010}, {"title": "Named Entity Recognition without Gazetteers", "author": ["A. Mikheev", "M. Moens", "C. Grover"], "venue": "Proc. of the Ninth Conference on European Chapter of the Association for Computational Linguistics, pages 1\u20138", "citeRegEx": "19", "shortCiteRegEx": null, "year": 1999}, {"title": "Incorporating Context into Recommender Systems: An Empirical Comparison of Context-based Approaches", "author": ["U. Panniello", "M. Gorgoglione"], "venue": "Eletronic Commerce Research, 12(1):1\u201330", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2012}, {"title": "editors", "author": ["F. Ricci", "L. Rokach", "B. Shapira", "P.B. Kantor"], "venue": "Recommender System Handbook. Springer", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2011}, {"title": "Introduction to Modern Information Retrieval", "author": ["G. Salton", "M.J. McGill"], "venue": "McGraw-Hill, Inc.", "citeRegEx": "22", "shortCiteRegEx": null, "year": 1983}, {"title": "Named Entity: History and Future", "author": ["S. Sekine"], "venue": null, "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2004}, {"title": "Using topic hierarchies with privileged information to improve context-aware recommender systems", "author": ["C.V. Sundermann", "M.A. Domingues", "R.M. Marcacini", "S.O. Rezende"], "venue": "BRACIS", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2014}, {"title": "A new learning paradigm: Learning using privileged information", "author": ["V. Vapnik", "A. Vashist"], "venue": "Neural Networks, 22:544 \u2013 557", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2009}], "referenceMentions": [{"referenceID": 20, "context": "A recommender system is an information filtering technology which can be used to predict preference ratings of items (products, services, movies, etc) and/or to output a ranking of items that are likely to be of interest to the user [21].", "startOffset": 233, "endOffset": 237}, {"referenceID": 1, "context": "However, the use of contextual information can improve the recommendation process in some cases [2], [12].", "startOffset": 96, "endOffset": 99}, {"referenceID": 11, "context": "However, the use of contextual information can improve the recommendation process in some cases [2], [12].", "startOffset": 101, "endOffset": 105}, {"referenceID": 10, "context": "In this paper we consider that context is any information that can be used to characterize the situation of an entity [11].", "startOffset": 118, "endOffset": 122}, {"referenceID": 1, "context": "In [2] and [20], the researchers represented the context as trees.", "startOffset": 3, "endOffset": 6}, {"referenceID": 19, "context": "In [2] and [20], the researchers represented the context as trees.", "startOffset": 11, "endOffset": 15}, {"referenceID": 12, "context": "Given this possibility of hierarchical organization of context, we have been using topic hierarchies as a way to organize and extract the context of the textual content of web pages [13], [24].", "startOffset": 182, "endOffset": 186}, {"referenceID": 23, "context": "Given this possibility of hierarchical organization of context, we have been using topic hierarchies as a way to organize and extract the context of the textual content of web pages [13], [24].", "startOffset": 188, "endOffset": 192}, {"referenceID": 12, "context": "In [13], we constructed topic hierarchies of web pages by using traditional bag-of-words, and the extracted topics were used as context of these pages in context-aware recommender systems.", "startOffset": 3, "endOffset": 7}, {"referenceID": 16, "context": "However, Marcacini and Rezende [17] proposed a method, called LUPI-based Incremental Hierarchical Clustering (LIHC) to construct topic hierarchies that uses besides the bag-of-words (technical information), also the privileged information, which is a more valuable kind of information extracted from texts.", "startOffset": 31, "endOffset": 35}, {"referenceID": 23, "context": "In [24], we constructed topic ar X iv :1 51 1.", "startOffset": 3, "endOffset": 7}, {"referenceID": 2, "context": "There are three different ways to acquire contextual information: explicitly, implicitly and inferred [3].", "startOffset": 102, "endOffset": 105}, {"referenceID": 15, "context": "In [16], Li et al.", "startOffset": 3, "endOffset": 7}, {"referenceID": 13, "context": "[14] introduced a context-aware recommendation system that obtains contextual information by mining hotel reviews made by users, and combine them with user\u2019s rating historic to calculate a utility function over a set of items.", "startOffset": 0, "endOffset": 4}, {"referenceID": 15, "context": "[16] and Hariri et al.", "startOffset": 0, "endOffset": 4}, {"referenceID": 13, "context": "[14] assume there are explicit contextual information in reviews, and such information is obtained for each review by mapping it to the labels.", "startOffset": 0, "endOffset": 4}, {"referenceID": 0, "context": "com Aciar [1] proposed a technique to detect sentences of reviews with contextual information.", "startOffset": 10, "endOffset": 13}, {"referenceID": 14, "context": "[15] proposed an approach to mine future spatiotemporal events from news articles, and thus provide information for location-aware recommendation systems.", "startOffset": 0, "endOffset": 4}, {"referenceID": 14, "context": "In [15], the contextual information that Ho et al.", "startOffset": 3, "endOffset": 7}, {"referenceID": 3, "context": "Bauman and Tuzhilin [4] presented a method to find relevant contextual information from reviews of users.", "startOffset": 20, "endOffset": 23}, {"referenceID": 3, "context": "In [4], Bauman and Tuzhilin consider that the contextual information is not known a priori.", "startOffset": 3, "endOffset": 6}, {"referenceID": 10, "context": "the definition given by Dey [11] that says: \u201cContext is any definition that can be used to characterize the situation of an entity\u201d.", "startOffset": 28, "endOffset": 32}, {"referenceID": 19, "context": "For example, Panniello and Gorgoglione [20] represent the attribute \u201cperiod of year\u201d as a tree like illustrated in Figure 1.", "startOffset": 39, "endOffset": 43}, {"referenceID": 19, "context": "1: Hierarchical structure of the contextual attribute \u201cperiod of the year\u201d [20].", "startOffset": 75, "endOffset": 79}, {"referenceID": 21, "context": "Traditional methods represent the textual collection as a bag-of-words [22], also known as technical information [25].", "startOffset": 71, "endOffset": 75}, {"referenceID": 24, "context": "Traditional methods represent the textual collection as a bag-of-words [22], also known as technical information [25].", "startOffset": 113, "endOffset": 117}, {"referenceID": 22, "context": "The term Named Entity was born in the Message Understanding Conferences (MUC) and includes names of people, organizations and locations, besides numeric expressions like time, date, money and percent expressions [23].", "startOffset": 212, "endOffset": 216}, {"referenceID": 18, "context": "The named entity recognition is a task that involves identifying words or expressions that belong to categories of named entities [19].", "startOffset": 130, "endOffset": 134}, {"referenceID": 5, "context": "A definition widely accepted of term is given by Cabr\u00e9 and Vivaldi [6], which is: \u201cterminological unit obtained from specialized domain\u201d.", "startOffset": 67, "endOffset": 70}, {"referenceID": 7, "context": "For example, in the Ecologic domain, the terms \u201cclimate\u201d, \u201cplant\u201d, \u201cAtlantic forest\u201d and \u201csoil moisture\u201d are examples of domain terms [8].", "startOffset": 134, "endOffset": 137}, {"referenceID": 16, "context": "In our proposal, we instantiate the LUPI-based Incremental Hierarchical Clustering (LIHC) method [17] to construct topic hierarchies using one type of privileged information and technical information.", "startOffset": 97, "endOffset": 101}, {"referenceID": 23, "context": "In [24], we constructed topic hierarchies of the web pages by using the method LIHC and considering as privileged information only named entities.", "startOffset": 3, "endOffset": 7}, {"referenceID": 1, "context": "Reduction [2], DaVI-BEST [12], Weight PoF and Filter PoF [20], all them using our contextual information, against the uncontextual algorithm Item-Based Collaborative Filtering (IBCF) [10].", "startOffset": 10, "endOffset": 13}, {"referenceID": 11, "context": "Reduction [2], DaVI-BEST [12], Weight PoF and Filter PoF [20], all them using our contextual information, against the uncontextual algorithm Item-Based Collaborative Filtering (IBCF) [10].", "startOffset": 25, "endOffset": 29}, {"referenceID": 19, "context": "Reduction [2], DaVI-BEST [12], Weight PoF and Filter PoF [20], all them using our contextual information, against the uncontextual algorithm Item-Based Collaborative Filtering (IBCF) [10].", "startOffset": 57, "endOffset": 61}, {"referenceID": 9, "context": "Reduction [2], DaVI-BEST [12], Weight PoF and Filter PoF [20], all them using our contextual information, against the uncontextual algorithm Item-Based Collaborative Filtering (IBCF) [10].", "startOffset": 183, "endOffset": 187}, {"referenceID": 17, "context": "These two tools are part of Torch [18], that is a set of tools developed to support text clustering and construction of topic hierarchies.", "startOffset": 34, "endOffset": 38}, {"referenceID": 6, "context": "The named entity recognition was performed by using REMBRANDT [7], a system that recognizes classes of named entities, like things, location, organization, people and others, in texts written in Portuguese.", "startOffset": 62, "endOffset": 65}, {"referenceID": 8, "context": "Lastly, for the domain term extraction we used the method MATE-ML (Automatic Term Extraction based on Machine Learning) [9], [8].", "startOffset": 120, "endOffset": 123}, {"referenceID": 7, "context": "Lastly, for the domain term extraction we used the method MATE-ML (Automatic Term Extraction based on Machine Learning) [9], [8].", "startOffset": 125, "endOffset": 128}, {"referenceID": 9, "context": "In this paper we considered the un-contextual algorithm Item-Based Collaborative Filtering (IBCF) [10] as baseline.", "startOffset": 98, "endOffset": 102}, {"referenceID": 2, "context": "According to Adomavicius and Tuzhilin [3], contextual information can be applied at various stages of the recommendation process.", "startOffset": 38, "endOffset": 41}, {"referenceID": 1, "context": "Reduction [2] (Pre-filtering approach): in pre-filtering approaches the contextual information is used as a label for filtering out those data that do not correspond to the specified contextual information.", "startOffset": 10, "endOffset": 13}, {"referenceID": 11, "context": "\u2022 DaVI-BEST [12] (Contextual modeling approach): in this approach the context is used in the recommendation model, i.", "startOffset": 12, "endOffset": 16}, {"referenceID": 19, "context": "\u2022 Weight PoF and Filter PoF [20] (Contextual postfiltering approaches): these approaches use the contextual information to reorder and filter out the recommendation, respectively.", "startOffset": 28, "endOffset": 32}, {"referenceID": 4, "context": "The protocol considered in this paper to measure the predictive ability of the recommender systems is the All But One protocol [5] with 10-fold cross validation, i.", "startOffset": 127, "endOffset": 130}], "year": 2015, "abstractText": "A recommender system is an information filtering technology which can be used to predict preference ratings of items (products, services, movies, etc) and/or to output a ranking of items that are likely to be of interest to the user. Context-aware recommender systems (CARS) learn and predict the tastes and preferences of users by incorporating available contextual information in the recommendation process. One of the major challenges in context-aware recommender systems research is the lack of automatic methods to obtain contextual information for these systems. Considering this scenario, in this paper, we propose to use contextual information from topic hierarchies of the items (web pages) to improve the performance of context-aware recommender systems. The topic hierarchies are constructed by an extension of the LUPI-based Incremental Hierarchical Clustering method that considers three types of information: traditional bag-of-words (technical information), and the combination of named entities (privileged information I) with domain terms (privileged information II). We evaluated the contextual information in four context-aware recommender systems. Different weights were assigned to each type of information. The empirical results demonstrated that topic hierarchies with the combination of the two kinds of privileged information can provide better recommendations. Keywords\u2014Contextual Information; Context-Aware Recommender Systems; Text Mining; Topic Hierarchy; Named Entities; Domain Terms", "creator": "LaTeX with hyperref package"}}}