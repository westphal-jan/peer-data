{"id": "1511.05389", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "17-Nov-2015", "title": "Learning to retrieve out-of-vocabulary words in speech recognition", "abstract": "Many Proper Names (PNs) are Out-Of-Vocabulary (OOV) words for speech recognition systems used to process diachronic audio data. To help recovery of the PNs missed by the system, relevant OOV PNs can be retrieved out of the many OOVs by exploiting semantic context of the spoken content. In this paper, we propose two neural network models targeted to retrieve OOV PNs relevant to an audio document: (a) Document level Continuous Bag of Words (D-CBOW), (b) Document level Continuous Bag of Weighted Words (D-CBOW2) or (c) Document level Continuous Bag of Weighted Words (D-CBOW3). D-CBOW and D-CBOW were used to retrieve the contents of a document. (b) Document level Continuous Bag of Weighted Words (D-CBOW4), (c) Document level Continuous Bag of Weighted Words (D-CBOW5) or (d) Document level Continuous Bag of Weighted Words (D-CBOW6). The three neural networks identified as DNFS, D-CBOW1, and D-CBOW2 were used for the analysis of semantic context of this document.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "histories": [["v1", "Tue, 17 Nov 2015 13:18:07 GMT  (365kb,D)", "https://arxiv.org/abs/1511.05389v1", "Under review as a conference paper at ICLR 2016"], ["v2", "Fri, 4 Dec 2015 09:39:29 GMT  (397kb,D)", "http://arxiv.org/abs/1511.05389v2", "Under review as a conference paper at ICLR 2016; updated references, added appendix discussing more results"], ["v3", "Thu, 7 Jan 2016 19:32:55 GMT  (454kb,D)", "http://arxiv.org/abs/1511.05389v3", "Under review as a conference paper at ICLR 2016; updated references, added appendix discussing more results, added more discussion, replaced simple phone search results with KWS results"], ["v4", "Tue, 1 Mar 2016 14:03:44 GMT  (450kb,D)", "http://arxiv.org/abs/1511.05389v4", "Updated references, added appendix discussing more results; added more discussion, replaced simple phone search results with KWS results; added KWS results for both training phase, probably last update"]], "COMMENTS": "Under review as a conference paper at ICLR 2016", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["imran sheikh", "irina illina", "dominique fohr", "georges linar\\`es"], "accepted": false, "id": "1511.05389"}, "pdf": {"name": "1511.05389.pdf", "metadata": {"source": "CRF", "title": null, "authors": ["Imran Sheikh", "Irina Illina", "Dominique Fohr"], "emails": ["dominique.fohr}@loria.fr", "georges.linares@univ-avignon.fr"], "sections": [{"heading": null, "text": "Many Proper Names (PNs) are Out-Of-Vocabulary (OOV) words for speech recognition systems used to process diachronic audio data. To help recovery of the PNs missed by the system, relevant OOV PNs can be retrieved out of the many OOVs by exploiting semantic context of the spoken content. In this paper, we propose two neural network models targeted to retrieve OOV PNs relevant to an audio document: (a) Document level Continuous Bag of Words (D-CBOW), (b) Document level Continuous Bag of Weighted Words (D-CBOW2). Both these models take document words as input and learn with an objective to maximise the retrieval of co-occurring OOV PNs. With the D-CBOW2 model we propose a new approach in which the input embedding layer is augmented with a context anchor layer. This layer learns to assign importance to input words and has the ability to capture (task specific) key-words in a bag-of-words neural network model. With experiments on French broadcast news videos we show that these two models outperform the baseline methods based on raw embeddings from LDA, Skip-gram and Paragraph Vectors. Combining the D-CBOW and D-CBOW2 models gives faster convergence during training."}, {"heading": "1 INTRODUCTION", "text": "Large Vocabulary Continuous Speech Recognition (LVCSR) based automatic audio indexing approaches allow search, navigation, browsing and structuring of large audio-video datasets based on spoken content (Alberti et al., 2009; Seide et al., 2008), as opposed to phonetic audio mining approaches which mostly serve user query based audio document retrieval from relatively smaller databases (Bhatt & Kankanhalli, 2011). However, LVCSR processing of diachronic audio data, and specifically broadcast audio news, can be challenging due to the variations in linguistic content and vocabulary. Thus leading to Out-Of-Vocabulary (OOV) words for LVCSR. Even if good amount of training data is available, appending the LVCSR vocabulary and updating the Language Model (LM) is not always a feasible solution (Qin, 2013). Proper Names (PNs), which are important indexes for audio-video, have been found to be a major percentage of OOV words. In this paper, we focus on the problem of retrieval of OOV PNs relevant to an audio document.\nTo retrieve OOV PNs relevant to an audio document we rely on semantic context. In training phase, diachronic text news with new (i.e., OOV) PNs are collected from the internet. These set of text documents, referred as diachronic text corpus, is used to learn a context vector space which captures relationship between the In-Vocabulary (IV) words & PNs and the OOV PNs. During test, the LVCSR hypothesis of the audio document is projected into the context space and then relevant OOV PNs are inferred. Recently it has been shown in Sheikh et al. (2015b) that Latent Dirichlet Allocation\nar X\niv :1\n51 1.\n05 38\n9v 4\n[ cs\n.C L\n] 1\nM ar\n(LDA) based topic space can perform with a good recall rate for retrieval of the target OOV PNs1. In LDA, word and topic representations are constructed by counting word co-occurrences. Alternative methods to learn word and context representations (Mikolov et al., 2013; Pennington et al., 2014), based on predicting the context in which words appear, have become popular. These representations, also called embeddings, have been shown to perform effectively when applied as pre-trained features in a range of applications and tasks (Baroni et al., 2014).\nIn this paper, we propose two models targeted to retrieve OOV PNs relevant to an audio document: (a) Document level Continuous Bag of Words (D-CBOW) context model (b) Document level Continuous Bag of Weighted Words (D-CBOW2) context model. Both these models use pre-trained Skip-gram word embeddings (Mikolov et al., 2013) for IV words & PNs and learn with an objective to maximise the retrieval of the target OOV PNs in the document. The D-CBOW model gives equal importance to all the input terms (IV words & PNs) co-occurring with the OOV PN in the document. In the D-CBOW2 model, we propose to augment the input embedding layer with a context anchor layer which learns to assign importance to input words/features. This mechanism has the ability to capture (task specific) key-words/key-features in a bag-of-words neural network model. With experiments on French broadcast news videos, we show that these two models outperform the baseline methods based on raw embeddings from LDA, Skip-gram and Paragraph Vectors (Le & Mikolov, 2014). Additionally, D-CBOW2+ model, which combines the context vectors from the D-CBOW and D-CBOW2 models, gives faster convergence during training."}, {"heading": "1.1 RELATED WORK", "text": "OOV word recovery and vocabulary selection in LVCSR have traditionally relied on web search and selection methods based on frequency/recency of words (Sheikh et al., 2015b). The task of retrieval of OOV and PNs relevant to an audio document has been presented previously. Bigot et al. (2013); Senay et al. (2013) use one LDA/LSA context model per PN which restricts the approach to frequent PNs. Sheikh et al. (2015b;a) presented methods based on probabilistic topic models and addressed the problems in ranking PNs arising due to bias in the probabilistic topic models. These methods readily apply to audio documents with single or coherent events. Fohr & Illina (2015) applied word embeddings to audio documents with multiple events appearing one after another. As compared to these works we propose new models D-CBOW, D-CBOW2 and D-CBOW2+ trained to maximise the performance of retrieval of OOV PNs for audio documents with single/coherent events.\nDifferent extensions and variations in the Log-bilinear (LBL) model and specifically the CBOW/Skip-gram architecture (Mikolov et al., 2013) have been proposed for different tasks (Le & Mikolov, 2014; Ling et al., 2015; Niu & Dai, 2015; Qiu et al., 2014; Levy & Goldberg, 2014; Chen et al., 2014). For our task we propose document level bag-of-words architectures mainly because they are suitable to process LVCSR transcriptions of audio documents, which are firstly prone to noise due to word errors and secondly have no direct information about position of OOVs. Our novel contribution is the context anchor layer which learns to assign importance to input words and has the ability to capture (task specific) key-words in a bag-of-words neural network model. The context anchor layer is inspired by the attention mechanism presented in Bahdanau et al. (2014). Increasing importance of words in classical bag-of-words model of text has been discussed in Islam et al. (2015) for the task of text relatedness. The Deep Structured Semantic Model (DSSM) with convolutional-pooling structures presented in Gao et al. (2014) has been shown to capture keywords in text documents."}, {"heading": "2 METHODS TO REPRESENT AND RETRIEVE OOV PROPER NAMES", "text": "As mentioned, our task is to retrieve OOV PNs relevant to an audio document. To achieve this we aim to learn a context vector space which captures relationship between the In-Vocabulary (IV) words & PNs and the OOV PNs, using a diachronic text corpus from the internet. During test, the LVCSR hypothesis of the audio document is projected into the context space to infer relevant OOV PNs. In this section we first briefly present the baseline method based on LDA, originally\n1For a given audio documents several OOV PNs can be relevant, but only few of them are actually present in the audio document. We refer to the actual OOV PNs present in the audio document as target OOV PNs\nproposed in Sheikh et al. (2015b). Then we present an extension of this method to raw Skip-gram and Paragraph Vector embeddings. Followed by the two proposed models, D-CBOW and D-CBOW2."}, {"heading": "2.1 TOPIC SPACE REPRESENTATION BASED ON LDA", "text": "LDA topics are trained on the diachronic text corpus of (D) documents. Topic vocabulary size (N ), the number of topics (T ) and Dirichlet priors (\u03b1, \u03b2) are first chosen. Topic model parameters \u03b8 and \u03c6 are then estimated using Gibbs sampling algorithm (Griffiths & Steyvers, 2004). \u03b8 = [\u03b8dt]D\u00d7T is the topic distribution for each document d, and \u03c6 = [\u03c6vt]N\u00d7T is the topic distribution to words from the vocabulary, both across T topics. Let us denote the LVCSR word hypothesis by h and OOV PNs in diachronic corpus (and topic model vocabulary) by v\u0303i. The latent topic mixture of h, i.e. p(t|h), is inferred by sampling the topic assignments for words in h using the word-topic distribution \u03c6 learned during training. Given p(v\u0303i|t) from \u03c6, the likelihood of an OOV PN (v\u0303i) in the diachronic corpus is calculated as:\np(v\u0303i|h) = T\u2211\nt=1\np(v\u0303i|t) p(t|h) (1)\nTo retrieve OOV PNs we calculate p(v\u0303i|h) for each v\u0303i and then use it as a score to rank OOV PNs relevant to h."}, {"heading": "2.2 RAW WORD EMBEDDINGS FROM PARAGRAPH VECTOR AND SKIP-GRAM MODELS", "text": "Le & Mikolov (2014) proposed Paragraph Vector - a distributed model to represent sentences, paragraphs and documents. For our task, this model can represent test documents and OOV PNs in a common vector space and we study its performance to retrieve relevant OOV PNs. The K dimensional vector representation of the LVCSR hypothesis of the audio document (h) is compared with the embeddings (v\u0303i) for each of the OOV PNs to calculate a score as follows:\ns \u2248 max i {CosSim(h, v\u0303i)} (2)\nwhere CosSim(\u00b7, \u00b7) is the cosine similarity measure. The score s is used to rank and retrieve OOV PNs relevant to test document.\nWe also examine a simple alternative to Paragraph Vectors. In this method, during training Skipgram word embeddings2 are learned for all the words in the diachronic corpus. Given these word embeddings and their linearity property, we obtain a representation for a test document by taking an average over all the vocabulary words in the document. This document representation is referred to as AverageVec. With the AverageVec test document representation (h) and the Skip-gram embeddings of the OOV PNs (v\u0303i), the OOV PNs relevant to the test documents can be retrieved using Equation 2."}, {"heading": "2.3 LEARNING OOV CONTEXT TO MAXIMISE RETRIEVAL PERFORMANCE", "text": "We propose two models targeted to retrieve OOV PNs relevant to an audio document. These models operate at document level and learn with an objective to maximise the retrieval of the target OOV PNs in the document. We choose document level input as it is suitable to process LVCSR transcriptions of audio documents, which are prone to noise due to word errors and have no direct information about position of OOVs."}, {"heading": "2.3.1 DOCUMENT LEVEL CONTINUOUS BAG OF WORDS (D-CBOW) CONTEXT MODEL", "text": "Figure 1 depicts a forward pass of the proposed D-CBOW model. The D-CBOW model takes at input all the IV words & PNs in a document. The context vector (cd) for an input document (d) is obtained using the matrix-vector product between the input word embedding matrix W IV and the input document vector. During training, the co-occurring OOV PNs in the document are set at the output. (The cost function used to train the network shares similarity with that of CBOW model\n2Word embeddings from Skip-gram model give better performance than those from the CBOW model proposed in the original work Mikolov et al. (2013).\noriginally proposed in Mikolov et al. (2013), we refer the interested readers to Rong (2014).) During test, the softmax probabilities at the output are used as scores to rank and retrieve the OOV PNs.\nTo train the D-CBOW model we first learn Skip-gram embeddings for the IV words & PNs. The W IV parameter in the model is set with these embeddings. In the first training phase, only the WOOV , bOOV parameters are trained (until convergence on the validation set), keeping the W IV parameter fixed. After this first training phase, all the model parameters (W IV ,WOOV , bOOV ) are trained and updated in the second training phase. In our experiments we observed that the model trained with all the network parameters learned in a single training phase gives lower retrieval performance compared to the model trained in two phase training."}, {"heading": "2.3.2 DOCUMENT LEVEL CONTINUOUS BAG OF WEIGHTED WORDS (D-CBOW2) CONTEXT MODEL", "text": "Figure 2 depicts a forward pass of the proposed D-CBOW2 model. Like the D-CBOW model, the D-CBOW2 model also takes at input all the IV words and PNs in a document. During training the cooccurring OOV PNs in the document are set at the output and during test the softmax probabilities\nat the output are used as scores to rank the OOV PNs. While the D-CBOW model gives equal importance to the input embeddings, the D-CBOW2 model learns to assign importance to input embeddings. To achieve this it has a context anchor vector which itself is learned during training. The importance weight (\u03c9j) for the jth input embedding (wIVj ) is calculated as:\n\u03b4j = prod(w IV j , C A) \u03c9j = exp(\u03b4j)\u2211 j exp(\u03b4j)\n(3)\nwhere CA denotes the context anchor and prod(\u00b7, \u00b7) is a matrix product (a matrix-vector product in this case). Given the importance weights, the context vector (cd) for an input document (d) is calculated as a weighted sum of the input embeddings as follows:\ncd = Nd\u2211 j \u03c9j w IV j (4)\nThe steps to train the network are similar to D-CBOW. The W IV parameter in the model is set with Skip-gram embeddings. In the first training phase, the WOOV , bOOV , CA parameters are trained, keeping the W IV parameter fixed. After this first training phase, all the model parameters (W IV ,WOOV , bOOV , CA) are trained and updated in the second training phase."}, {"heading": "3 EXPERIMENTS AND RESULTS", "text": ""}, {"heading": "3.1 EXPERIMENT CORPUS", "text": "Table 1 presents realistic broadcast news diachronic datasets which will be used as the train, validation and test sets in our study. These datasets also highlight the motivation for handling OOV PNs. The datasets are collected from two different sources: (a) French newspaper L\u2019Express (http://www.lexpress.fr/) (b) French website of the Euronews (http://fr.euronews.com/) television channel. The L\u2019Express dataset contains text news whereas the Euronews dataset contains text news as well news videos and their text transcriptions. In our study the L\u2019Express dataset will be used as diachronic corpus to train context/topic models, in order to infer the OOV PNs relevant to Euronews videos. Euronews text documents, denoted as \u2019validation\u2019 in Table 1, are used as a validation set in our experiments.\nTreeTagger (Schmid, 2014) is used to automatically tag PNs in the text. The words and PNs which occur in the lexicon of our Automatic News Transcription System (ANTS)(Illina et al., 2004) are tagged as IV and remaining PNs are tagged as OOV. ANTS lexicon is based on news articles until 2008 from French newspaper LeMonde and contains about 123K unique words. As shown in the Table 1, 72% of OOV words in Euronews video dataset are PNs and about 64% of the videos contain OOV PNs. The total number of OOV PNs to be retrieved for the Euronews videos, obtained by counting unique OOV PNs per video, is 4694. Out of 4694, up to 2010 (42%) OOV PNs can be retrieved with the training (L\u2019Express) diachronic corpus. As shown in the Table 1 the training corpus has 9.3K new (OOV) PNs to learn. This number and the target OOV PN coverage can be increased by augmenting text documents from additional sources (Sheikh et al., 2016), for instance from other news websites. However this is not the focus of our study in this paper."}, {"heading": "3.2 EXPERIMENT SETUP", "text": "The ANTS (Illina et al., 2004) LVCSR system is used to perform automatic segmentation and speech-to-text transcription of the test set (Euronews) audio news. The automatic transcriptions of the test audio news obtained by ANTS have an average Word Error Rate (WER) of 40% as compared to the reference transcriptions available from Euronews.\nFor training the context/topic models, diachronic corpus words are lemmatised and filtered by removing PNs and non PN words occurring less than 3 times. Additionally a stop-list of common French words and non content words is used. Moreover, a POS based filter is employed to choose words tagged as PN, noun, adjective, verb and acronym. PNs not present in the ANTS LVCSR\nlexicon and are tagged as OOV PNs. The context and topic models are trained with this filtered vocabulary. For comparison, the number of LDA topics and the dimensionality of the different neural context models are chosen to be equal and set to 100. A window size of 15 is chosen for training the Skip-gram embeddings. This selection is based on performance on the validation set.\nOur baseline methods, discussed in Section 2.1 and Section 2.2, are denoted as LDA, Doc2Vec (for Paragraph Vector method), AverageVec. Our proposed models, discussed in Section 2.3.1 and Section 2.3.2, are denoted as D-CBOW and D-CBOW2. Additionally we present the results of our experiments with a combination of the D-CBOW and D-CBOW2 models. We denote it as DCBOW2+. In D-CBOW2+ model the bag-of-words and the bag-of-weighted-words context vectors are concatenated together."}, {"heading": "3.3 TRAINING THE D-CBOW GROUP OF MODELS", "text": "As discussed in Section 2.3.1 and Section 2.3.2, the D-CBOW and D-CBOW2 models are trained in two phases. The D-CBOW2+ model is also trained in two phases. To control the training of the D-CBOW, D-CBOW2 and D-CBOW2+ models an early stopping criterion (Bengio, 2012) based on the validation set error is used. Early stopping is applied in both the first and the second training phases. The patience limits in early stopping are different for the two training phases. Figure 3 shows a graph of validation set errors, of the D-CBOW, D-CBOW2 and D-CBOW2+ models, as the training progresses. It must be noted that this error is like a classification error and a measure of whether an OOV PN in the validation set document is given the highest output probability or not. The actual performance measures used to evaluate our OOV PN retrieval task are different and discussed in the next section. The classification error is shown as it is easier to analyse and visualise the training of the models. For instance it can be observed in Figure 3 that the D-CBOW2+ model gives a faster convergence compared to the D-CBOW and D-CBOW2 models. We analyse the retrieval performance and the training convergence of these models in detail in Section 4.2."}, {"heading": "3.4 OOV PN RETRIEVAL PERFORMANCE", "text": "Figure 4 and Figure 5 show the Recall and Mean Average Precision (MAP) (Manning et al., 2008) performance of retrieval of OOV PNs, for models discussed in Section 2. Figure 4 depicts the performance of D-CBOW, D-CBOW2 and D-CBOW2+ after the end of first training phase, whereas\nFigure 5 depicts the performance after the end of second training phase. The graphs shown are for the reference transcriptions (left) and the LVCSR transcriptions (right) of the Euronews test set audio. The X-axis represents the number of OOV PNs selected from the diachronic corpus i.e. the \u2019N\u2019 in the top-N retrieved results. Y-axis represents recall (top) and MAP (bottom) of the target OOV PNs."}, {"heading": "4 DISCUSSION", "text": ""}, {"heading": "4.1 A NOTE ON RECALL AND MAP", "text": "It is necessary to understand the importance and differences for the recall and MAP curves. After retrieval of the relevant OOV PNs, the top-N relevant OOV PNs are to be used for recovery/recognition of the target OOV PNs. To recover the target OOV PNs one can use phone matching (Pan et al., 2005), or additional speech recognition pass (Fohr & Illina, 2015; Oger et al., 2008)); or spotting PNs in speech (Parada et al., 2010; Chen et al., 2013). In each of these approaches, the retrieval ranks/scores may or may not be used. This is where the recall and MAP curves make a difference. The recall value at an operating point (N in the top-N choice) is not sensitive to the rank of the retrieved OOV PNs whereas the MAP value, by definition, takes into account the retrieval ranks. For instance if we take top 5% (top 465 retrieved OOV PNs3) of the retrieved OOV PNs almost all the methods will have same recall, but the MAP will have differences. In Section 4.4 we try to analyse the effect of the recall and MAP of the retrieval task on recovery of the target OOV PNs. To recover the target OOV PNs in the audio documents we perform a keyword search on the LVCSR lattices using the approach proposed by Chen et al. (2013). This is a quick and simple approach to evaluate the retrieved list of top-N OOV PNs.\n35% of 9.3K. This might appear as a small number but it must be noted that as we increase the diachronic corpora to increase coverage of target OOV PNs this number will also multiply (Sheikh et al., 2016)."}, {"heading": "4.2 COMPARISON OF RETRIEVAL PERFORMANCE", "text": "Among the baseline methods, LDA based method performs better than the methods based on AverageVec and Doc2Vec embeddings4. AverageVec performs better than Doc2Vec, specially for LVCSR transcriptions. The proposed D-CBOW and D-CBOW2+ models clearly outperform the baseline methods, both for reference and LVCSR transcriptions. Performance of D-CBOW2+ is similar to that of D-CBOW, but as mentioned earlier D-CBOW2+ has faster convergence during training. The D-CBOW2 model also outperforms the baseline methods for reference transcriptions. For LVCSR transcriptions its performance is affected due to LVCSR errors in important keywords. We discuss more about this in Section 4.3.\nHere we will try to discuss why and when D-CBOW2 and D-CBOW2+ models do not outperform the D-CBOW model. First we can observe from Figure 3 that the second training phase helps only the D-CBOW model. For D-CBOW2 model it causes the validation error to increase after a few epochs and for the D-CBOW2+ model the validation error is kind of oscillating; and thus the second training phase makes a quick early stop for both these models. We believe that this problem of convergence during the second training phase of D-CBOW2 and D-CBOW2+ models is because both the input embeddings and the context anchor vector (applied to the input embeddings to obtain importance weights) are being updated during the subsequent training min-batches. We believe that this takes the D-CBOW2 and D-CBOW2+ models away from convergence. Currently we are working on addressing this problem. Note that during the first training phase of D-CBOW2 and D-CBOW2+, only the context anchor vector is trained/updated at the input side. We find that DCBOW2 model stops at a higher validation error even in the first training phase as it is constrained to classify OOV PNs based on handful of words (few words assigned high importance weights, remaining close to zero). D-CBOW2+ model on the other hand uses average of input words as well as the specific words assigned higher importance. This combination at the input side gives a faster convergence in the first training phase (majority of the training time), even though the model parameters (output layer) are doubled in size.\nWe can see the effect of this even on the retrieval performance. We have shown the Recall and MAP performance at the end of first training phase in Figure 4. For better clarity we have also shown the difference in the Recall and MAP performances between the second and the first training phases in Figure 7 in Appendix A. Firstly, it is interesting to note from Figure 4 that at the end of first training phase the D-CBOW2+ performs better than the D-CBOW model, and the D-CBOW2 model is not far from D-CBOW as after second training phase. Secondly, even the differences between performance of the LVCSR and reference transcriptions, for proposed models, is relatively less (about 0.5 to 0.6 MAP) as compared to that at the end of second training phase (about 0.5 to 1.0 MAP). Further from the Figure 7 we can observe that the second training phase improves the Recall and MAP for D-CBOW and this improvement is more for the reference transcriptions. For D-CBOW2 improvements are seen in the reference transcriptions but these come at the cost of degradation in the Recall and MAP for LVCSR transcriptions. In case of D-CBOW2+, there are only small improvements for (both) reference and LVCSR transcriptions, again suggesting that the second training phase is not working with importance based models."}, {"heading": "4.3 KEYWORD IMPORTANCE BY D-CBOW2 MODEL", "text": "In Table 2, we demonstrate the ability of the D-CBOW2 model to give importance to keywords in the input document in order to infer the target OOV PN. We have listed four Euronews video examples. The first column lists the target OOV PNs present in these videos. The words given importance by the D-CBOW2 models (importance weight more than 0.1 as calculated by Equation 3), from corresponding input reference and manual transcriptions are shown in second and fifth column respectively. For comparison the ranks given by the D-CBOW2 and D-CBOW models are also shown. It can be seen that in the first two examples the D-CBOW2 model extracts relevant keywords and gives similar ranks as D-CBOW model. In the third example, the ranks given by D-CBOW2 models are better than that of D-CBOW as the context, influenced by the keywords, is more focused. But relying on few words can cause degradation when (a) the LVCSR transcription loses some of the interesting words and (b) the target OOV PNs cannot be discriminated with the available interesting words. This can be seen in the fourth example, where words kiev and parti\n4It is also interesting to note that the LDA based method shows least degradation due to LVCSR errors.\nwere mis-recognised during LVCSR transcription. And even though the word cfa, in the LVCSR transcription, is a good descriptor of the topic of the input document it does lead to good ranks as it is not close to the target OOV PNs in the learned space. The DCBOW model on the other hand takes a decision based on average of the words in the LVCSR transcription and thus gets relatively better ranks."}, {"heading": "4.4 RECOVERY OF TARGET OOV PNS WITH AUTOMATIC KEYWORD SEARCH (KWS)", "text": "The recovery of the target OOV PNs in a diachronic audio is done in two steps. First, a list of relevant OOV PNs is retrieved with the models presented in this paper. In the second step, an automatic Keyword Search (KWS) is performed, for each OOV PN in the list of relevant OOV PNs, on the entire LVCSR lattice of the audio file. For this KWS we employ the approach proposed by Chen et al. (2013), which enables searching of OOV words (in their phonetic form) in an LVCSR\nlattice. The OOV PN recovery performance is evaluated in terms of F1-score, calculated as:\nF1 = 2 \u2217 precision \u2217 recall precision+ recall\n= 2 \u2217 tp\n2 \u2217 tp+ fp+ fn\n(5)\nwhere tp, fp, fn stand for number of true positive, false positive and false negative OOV PNs respectively. (Note that the precision and recall here correspond to the phonetic search and are different from those of the retrieval task discussed previously.)\nFigure 6 shows the F1-scores for recovery of the target OOV PNs. For comparison of performance of D-CBOW, D-CBOW2 and D-CBOW2+ models, the F1-scores obtained with the OOV PN lists after the first and the second training phase are shown. Among the baseline models, F1-scores for only LDA based approach is shown because LDA performs the best. The X-axis represents the number of top-N relevant OOV PNs selected for keyword search. The keyword search algorithm has a matching score threshold which controls the operating characteristics (and hence recall/precision and F1-score) of the phonetic search. We show the best F1-scores corresponding to top-N OOV PN lists of different sizes (N). The F1-scores are shown only until top-512 OOV PNs because beyond this there is no significant difference in the F1-scores of the different retrieval methods. Overall we can observe that, better the Recall and MAP of OOV PN retrieval the better is the F-1 score. F1-scores are best for the list of OOV PNs retrieved by the proposed models D-CBOW and DCBOW2+. They obtain the best F1-score of about 0.34 with the top-8 retrieved OOV PNs. At this F1-score the recall and precision for OOV recovery with D-CBOW is 0.30 and 0.38 respectively. Similarly for D-CBOW2+ it is 0.29 and 0.42 respectively"}, {"heading": "ACKNOWLEDGMENTS", "text": "This work is funded by the ContNomina project supported by the French National Research Agency (ANR) under contract ANR-12-BS02-0009. The KWS experiments presented in this paper were carried out using the Grid\u20195000 testbed, supported by a scientific interest group hosted by Inria and including CNRS, RENATER and several Universities as well as other organizations (see https://www.grid5000.fr)."}, {"heading": "APPENDIX A DIFFERENCE IN OOV PN RETRIEVAL PERFORMANCE", "text": "OBTAINED AFTER THE FIRST AND THE SECOND TRAINING PHASE"}], "references": [{"title": "An audio indexing system for election video material", "author": ["C Alberti"], "venue": "In Acoustics, Speech and Signal Processing,", "citeRegEx": "Alberti,? \\Q2009\\E", "shortCiteRegEx": "Alberti", "year": 2009}, {"title": "Neural machine translation by jointly learning to align and translate", "author": ["Bahdanau", "Dzmitry", "Cho", "Kyunghyun", "Bengio", "Yoshua"], "venue": "arXiv preprint arXiv:1409.0473,", "citeRegEx": "Bahdanau et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Bahdanau et al\\.", "year": 2014}, {"title": "Don\u2019t count, predict! a systematic comparison of context-counting vs. context-predicting semantic vectors. In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "author": ["Baroni", "Marco", "Dinu", "Georgiana", "Kruszewski", "Germ\u00e1n"], "venue": null, "citeRegEx": "Baroni et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Baroni et al\\.", "year": 2014}, {"title": "Practical recommendations for gradient-based training of deep architectures", "author": ["Bengio", "Yoshua"], "venue": "CoRR, abs/1206.5533,", "citeRegEx": "Bengio and Yoshua.,? \\Q2012\\E", "shortCiteRegEx": "Bengio and Yoshua.", "year": 2012}, {"title": "Multimedia data mining: state of the art and challenges", "author": ["Bhatt", "Chidansh Amitkumar", "Kankanhalli", "Mohan S"], "venue": "Multimedia Tools and Applications,", "citeRegEx": "Bhatt et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Bhatt et al\\.", "year": 2011}, {"title": "Person name recognition in ASR outputs using continuous context models", "author": ["Bigot", "Benjamin", "Senay", "Gr\u00e9gory", "Linar\u00e8s", "Georges", "Fredouille", "Corinne", "Dufour", "Richard"], "venue": "In Acoustics, Speech and Signal Processing,", "citeRegEx": "Bigot et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Bigot et al\\.", "year": 2013}, {"title": "Quantifying the value of pronunciation lexicons for keyword search in lowresource languages", "author": ["Chen", "Guoguo", "S. Khudanpur", "D. Povey", "J. Trmal", "D. Yarowsky", "O. Yilmaz"], "venue": "In IEEE International Conference on Acoustics, Speech and Signal Processing,", "citeRegEx": "Chen et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Chen et al\\.", "year": 2013}, {"title": "A unified model for word sense representation and disambiguation", "author": ["Chen", "Xinxiong", "Liu", "Zhiyuan", "Sun", "Maosong"], "venue": "In Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP),", "citeRegEx": "Chen et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Chen et al\\.", "year": 2014}, {"title": "Continuous word representation using neural networks for proper name retrieval from diachronic documents", "author": ["Fohr", "Dominique", "Illina", "Irina"], "venue": "In 16th Annual Conference of the International Speech Communication Association (INTERSPEECH),", "citeRegEx": "Fohr et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Fohr et al\\.", "year": 2015}, {"title": "Modeling interestingness with deep neural networks", "author": ["Gao", "Jianfeng", "Pantel", "Patrick", "Gamon", "Michael", "He", "Xiaodong", "Deng", "Li", "Shen", "Yelong"], "venue": "In Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing,", "citeRegEx": "Gao et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Gao et al\\.", "year": 2014}, {"title": "Finding scientific topics", "author": ["Griffiths", "Thomas L", "Steyvers", "Mark"], "venue": "Proceedings of the National Academy of Sciences,", "citeRegEx": "Griffiths et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Griffiths et al\\.", "year": 2004}, {"title": "The Automatic News Transcription System: ANTS some Real Time experiments", "author": ["Illina", "Irina", "Fohr", "Dominique", "Mella", "Odile", "Cerisara", "Christophe"], "venue": "In 8th International Conference on Spoken Language Processing (INTERSPEECH\u20192004 - ICSLP),", "citeRegEx": "Illina et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Illina et al\\.", "year": 2004}, {"title": "Do important words in bag-of-words model of text relatedness help? In Text, Speech, and Dialogue, volume", "author": ["Islam", "Aminul", "Milios", "Evangelos", "Keelj", "Vlado"], "venue": "Lecture Notes in Computer Science,", "citeRegEx": "Islam et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Islam et al\\.", "year": 2015}, {"title": "Distributed representations of sentences and documents", "author": ["Le", "Quoc", "Mikolov", "Tomas"], "venue": "In Proceedings of the 31st International Conference on Machine Learning", "citeRegEx": "Le et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Le et al\\.", "year": 2014}, {"title": "Combined low level and high level features for out-of-vocabulary word detection", "author": ["Lecouteux", "Benjamin", "Linar\u00e8s", "Georges", "Favre", "Benoit"], "venue": "In 10th Annual Conference of the International Speech Communication Association (INTERSPEECH),", "citeRegEx": "Lecouteux et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Lecouteux et al\\.", "year": 2009}, {"title": "Dependencybased word embeddings", "author": ["Levy", "Omer", "Goldberg", "Yoav"], "venue": "In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics,", "citeRegEx": "Levy et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Levy et al\\.", "year": 2014}, {"title": "Two/too simple adaptations of word2vec for syntax problems", "author": ["Ling", "Wang", "Dyer", "Chris", "Black", "Alan", "Trancoso", "Isabel"], "venue": "Proceedings of the North American Chapter of the Association for Computational Linguistics (NAACL),", "citeRegEx": "Ling et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Ling et al\\.", "year": 2015}, {"title": "Introduction to Information Retrieval", "author": ["Manning", "Christopher D", "Raghavan", "Prabhakar", "Sch\u00fctze", "Hinrich"], "venue": null, "citeRegEx": "Manning et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Manning et al\\.", "year": 2008}, {"title": "Distributed representations of words and phrases and their compositionality", "author": ["Mikolov", "Tomas", "Sutskever", "Ilya", "Chen", "Kai", "Corrado", "Greg S", "Dean", "Jeff"], "venue": "In Advances in Neural Information Processing Systems", "citeRegEx": "Mikolov et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Mikolov et al\\.", "year": 2013}, {"title": "A guided tour to approximate string matching", "author": ["Navarro", "Gonzalo"], "venue": "ACM Comput. Surv.,", "citeRegEx": "Navarro and Gonzalo.,? \\Q2001\\E", "shortCiteRegEx": "Navarro and Gonzalo.", "year": 2001}, {"title": "Topic2vec: Learning distributed representations of topics", "author": ["Niu", "Li-Qiang", "Dai", "Xin-Yu"], "venue": "CoRR, abs/1506.08422,", "citeRegEx": "Niu et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Niu et al\\.", "year": 2015}, {"title": "On-demand new word learning using world wide web", "author": ["Oger", "Stanislas", "Linar\u00e8s", "Georges", "B\u00e9chet", "Fr\u00e9d\u00e9ric", "Nocera", "Pascal"], "venue": "In IEEE International Conference on Acoustics, Speech and Signal Processing,", "citeRegEx": "Oger et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Oger et al\\.", "year": 2008}, {"title": "Named entity recognition from spoken documents using global evidences and external knowledge sources with applications on mandarin chinese", "author": ["Pan", "Yi-Cheng", "Liu", "Yu-Ying", "Lee", "Lin-Shan"], "venue": "In IEEE Workshop on Automatic Speech Recognition and Understanding,", "citeRegEx": "Pan et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Pan et al\\.", "year": 2005}, {"title": "A spoken term detection framework for recovering out-of-vocabulary words using the web", "author": ["Parada", "Carolina", "Sethy", "Abhinav", "Dredze", "Mark", "Jelinek", "Frederick"], "venue": "In 11th Annual Conference of the International Speech Communication Association (INTERSPEECH),", "citeRegEx": "Parada et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Parada et al\\.", "year": 2010}, {"title": "Glove: Global vectors for word representation", "author": ["Pennington", "Jeffrey", "Socher", "Richard", "Manning", "Christopher"], "venue": "In Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP),", "citeRegEx": "Pennington et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Pennington et al\\.", "year": 2014}, {"title": "Learning Out-of-Vocabulary Words in Automatic Speech Recognition", "author": ["Qin", "Long"], "venue": "PhD thesis,", "citeRegEx": "Qin and Long.,? \\Q2013\\E", "shortCiteRegEx": "Qin and Long.", "year": 2013}, {"title": "Learning word representation considering proximity and ambiguity", "author": ["Qiu", "Lin", "Cao", "Yong", "Nie", "Zaiqing", "Yu", "Rui"], "venue": "In Proceedings of the Twenty-Eighth AAAI Conference on Artificial Intelligence, July", "citeRegEx": "Qiu et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Qiu et al\\.", "year": 2014}, {"title": "word2vec parameter learning explained", "author": ["Rong", "Xin"], "venue": "CoRR, abs/1411.2738,", "citeRegEx": "Rong and Xin.,? \\Q2014\\E", "shortCiteRegEx": "Rong and Xin.", "year": 2014}, {"title": "TreeTagger: A part-of-speech tagger and lemmatizer for several languages", "author": ["Schmid", "Helmut"], "venue": null, "citeRegEx": "Schmid and Helmut.,? \\Q2014\\E", "shortCiteRegEx": "Schmid and Helmut.", "year": 2014}, {"title": "Word-lattice based spoken-document indexing with standard text indexers", "author": ["F. Seide", "K. Thambiratnam", "R.P. Yu"], "venue": "In IEEE Spoken Language Technology Workshop,", "citeRegEx": "Seide et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Seide et al\\.", "year": 2008}, {"title": "Person name spotting by combining acoustic matching and LDA topic models", "author": ["Senay", "Gr\u00e9gory", "Bigot", "Benjamin", "Dufour", "Richard", "Linar\u00e8s", "Georges", "Fredouille", "Corinne"], "venue": "In 14th Annual Conference of the International Speech Communication Association (INTERSPEECH),", "citeRegEx": "Senay et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Senay et al\\.", "year": 2013}, {"title": "Study of entity-topic models for OOV proper name retrieval", "author": ["Sheikh", "Imran", "Illina", "Irina", "Fohr", "Dominique"], "venue": "In 16th Annual Conference of the International Speech Communication Association (INTERSPEECH),", "citeRegEx": "Sheikh et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Sheikh et al\\.", "year": 2015}, {"title": "OOV proper name retrieval using topic and lexical context models", "author": ["Sheikh", "Imran", "Illina", "Irina", "Fohr", "Dominique", "Linar\u00e8s", "Georges"], "venue": "In IEEE International Conference on Acoustics, Speech and Signal Processing,", "citeRegEx": "Sheikh et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Sheikh et al\\.", "year": 2015}, {"title": "How diachronic text corpora affect context based retrieval of oov proper names for audio news", "author": ["Sheikh", "Imran", "Illina", "Irina", "Fohr", "Dominique"], "venue": "In (submitted to) Language Resources and Evaluation Conference (LREC)", "citeRegEx": "Sheikh et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Sheikh et al\\.", "year": 2016}], "referenceMentions": [{"referenceID": 29, "context": "Large Vocabulary Continuous Speech Recognition (LVCSR) based automatic audio indexing approaches allow search, navigation, browsing and structuring of large audio-video datasets based on spoken content (Alberti et al., 2009; Seide et al., 2008), as opposed to phonetic audio mining approaches which mostly serve user query based audio document retrieval from relatively smaller databases (Bhatt & Kankanhalli, 2011).", "startOffset": 202, "endOffset": 244}, {"referenceID": 0, "context": "Large Vocabulary Continuous Speech Recognition (LVCSR) based automatic audio indexing approaches allow search, navigation, browsing and structuring of large audio-video datasets based on spoken content (Alberti et al., 2009; Seide et al., 2008), as opposed to phonetic audio mining approaches which mostly serve user query based audio document retrieval from relatively smaller databases (Bhatt & Kankanhalli, 2011). However, LVCSR processing of diachronic audio data, and specifically broadcast audio news, can be challenging due to the variations in linguistic content and vocabulary. Thus leading to Out-Of-Vocabulary (OOV) words for LVCSR. Even if good amount of training data is available, appending the LVCSR vocabulary and updating the Language Model (LM) is not always a feasible solution (Qin, 2013). Proper Names (PNs), which are important indexes for audio-video, have been found to be a major percentage of OOV words. In this paper, we focus on the problem of retrieval of OOV PNs relevant to an audio document. To retrieve OOV PNs relevant to an audio document we rely on semantic context. In training phase, diachronic text news with new (i.e., OOV) PNs are collected from the internet. These set of text documents, referred as diachronic text corpus, is used to learn a context vector space which captures relationship between the In-Vocabulary (IV) words & PNs and the OOV PNs. During test, the LVCSR hypothesis of the audio document is projected into the context space and then relevant OOV PNs are inferred. Recently it has been shown in Sheikh et al. (2015b) that Latent Dirichlet Allocation", "startOffset": 203, "endOffset": 1578}, {"referenceID": 18, "context": "Alternative methods to learn word and context representations (Mikolov et al., 2013; Pennington et al., 2014), based on predicting the context in which words appear, have become popular.", "startOffset": 62, "endOffset": 109}, {"referenceID": 24, "context": "Alternative methods to learn word and context representations (Mikolov et al., 2013; Pennington et al., 2014), based on predicting the context in which words appear, have become popular.", "startOffset": 62, "endOffset": 109}, {"referenceID": 2, "context": "These representations, also called embeddings, have been shown to perform effectively when applied as pre-trained features in a range of applications and tasks (Baroni et al., 2014).", "startOffset": 160, "endOffset": 181}, {"referenceID": 18, "context": "Both these models use pre-trained Skip-gram word embeddings (Mikolov et al., 2013) for IV words & PNs and learn with an objective to maximise the retrieval of the target OOV PNs in the document.", "startOffset": 60, "endOffset": 82}, {"referenceID": 18, "context": "Different extensions and variations in the Log-bilinear (LBL) model and specifically the CBOW/Skip-gram architecture (Mikolov et al., 2013) have been proposed for different tasks (Le & Mikolov, 2014; Ling et al.", "startOffset": 117, "endOffset": 139}, {"referenceID": 16, "context": ", 2013) have been proposed for different tasks (Le & Mikolov, 2014; Ling et al., 2015; Niu & Dai, 2015; Qiu et al., 2014; Levy & Goldberg, 2014; Chen et al., 2014).", "startOffset": 47, "endOffset": 163}, {"referenceID": 26, "context": ", 2013) have been proposed for different tasks (Le & Mikolov, 2014; Ling et al., 2015; Niu & Dai, 2015; Qiu et al., 2014; Levy & Goldberg, 2014; Chen et al., 2014).", "startOffset": 47, "endOffset": 163}, {"referenceID": 7, "context": ", 2013) have been proposed for different tasks (Le & Mikolov, 2014; Ling et al., 2015; Niu & Dai, 2015; Qiu et al., 2014; Levy & Goldberg, 2014; Chen et al., 2014).", "startOffset": 47, "endOffset": 163}, {"referenceID": 4, "context": "Bigot et al. (2013); Senay et al.", "startOffset": 0, "endOffset": 20}, {"referenceID": 4, "context": "Bigot et al. (2013); Senay et al. (2013) use one LDA/LSA context model per PN which restricts the approach to frequent PNs.", "startOffset": 0, "endOffset": 41}, {"referenceID": 4, "context": "Bigot et al. (2013); Senay et al. (2013) use one LDA/LSA context model per PN which restricts the approach to frequent PNs. Sheikh et al. (2015b;a) presented methods based on probabilistic topic models and addressed the problems in ranking PNs arising due to bias in the probabilistic topic models. These methods readily apply to audio documents with single or coherent events. Fohr & Illina (2015) applied word embeddings to audio documents with multiple events appearing one after another.", "startOffset": 0, "endOffset": 399}, {"referenceID": 1, "context": "The context anchor layer is inspired by the attention mechanism presented in Bahdanau et al. (2014). Increasing importance of words in classical bag-of-words model of text has been discussed in Islam et al.", "startOffset": 77, "endOffset": 100}, {"referenceID": 1, "context": "The context anchor layer is inspired by the attention mechanism presented in Bahdanau et al. (2014). Increasing importance of words in classical bag-of-words model of text has been discussed in Islam et al. (2015) for the task of text relatedness.", "startOffset": 77, "endOffset": 214}, {"referenceID": 1, "context": "The context anchor layer is inspired by the attention mechanism presented in Bahdanau et al. (2014). Increasing importance of words in classical bag-of-words model of text has been discussed in Islam et al. (2015) for the task of text relatedness. The Deep Structured Semantic Model (DSSM) with convolutional-pooling structures presented in Gao et al. (2014) has been shown to capture keywords in text documents.", "startOffset": 77, "endOffset": 359}, {"referenceID": 31, "context": "proposed in Sheikh et al. (2015b). Then we present an extension of this method to raw Skip-gram and Paragraph Vector embeddings.", "startOffset": 12, "endOffset": 34}, {"referenceID": 18, "context": "(The cost function used to train the network shares similarity with that of CBOW model Word embeddings from Skip-gram model give better performance than those from the CBOW model proposed in the original work Mikolov et al. (2013).", "startOffset": 209, "endOffset": 231}, {"referenceID": 18, "context": "originally proposed in Mikolov et al. (2013), we refer the interested readers to Rong (2014).", "startOffset": 23, "endOffset": 45}, {"referenceID": 18, "context": "originally proposed in Mikolov et al. (2013), we refer the interested readers to Rong (2014).) During test, the softmax probabilities at the output are used as scores to rank and retrieve the OOV PNs.", "startOffset": 23, "endOffset": 93}, {"referenceID": 11, "context": "The words and PNs which occur in the lexicon of our Automatic News Transcription System (ANTS)(Illina et al., 2004) are tagged as IV and remaining PNs are tagged as OOV.", "startOffset": 94, "endOffset": 115}, {"referenceID": 33, "context": "This number and the target OOV PN coverage can be increased by augmenting text documents from additional sources (Sheikh et al., 2016), for instance from other news websites.", "startOffset": 113, "endOffset": 134}, {"referenceID": 11, "context": "The ANTS (Illina et al., 2004) LVCSR system is used to perform automatic segmentation and speech-to-text transcription of the test set (Euronews) audio news.", "startOffset": 9, "endOffset": 30}, {"referenceID": 17, "context": "Figure 4 and Figure 5 show the Recall and Mean Average Precision (MAP) (Manning et al., 2008) performance of retrieval of OOV PNs, for models discussed in Section 2.", "startOffset": 71, "endOffset": 93}, {"referenceID": 22, "context": "To recover the target OOV PNs one can use phone matching (Pan et al., 2005), or additional speech recognition pass (Fohr & Illina, 2015; Oger et al.", "startOffset": 57, "endOffset": 75}, {"referenceID": 21, "context": ", 2005), or additional speech recognition pass (Fohr & Illina, 2015; Oger et al., 2008)); or spotting PNs in speech (Parada et al.", "startOffset": 47, "endOffset": 87}, {"referenceID": 23, "context": ", 2008)); or spotting PNs in speech (Parada et al., 2010; Chen et al., 2013).", "startOffset": 36, "endOffset": 76}, {"referenceID": 6, "context": ", 2008)); or spotting PNs in speech (Parada et al., 2010; Chen et al., 2013).", "startOffset": 36, "endOffset": 76}, {"referenceID": 6, "context": ", 2010; Chen et al., 2013). In each of these approaches, the retrieval ranks/scores may or may not be used. This is where the recall and MAP curves make a difference. The recall value at an operating point (N in the top-N choice) is not sensitive to the rank of the retrieved OOV PNs whereas the MAP value, by definition, takes into account the retrieval ranks. For instance if we take top 5% (top 465 retrieved OOV PNs3) of the retrieved OOV PNs almost all the methods will have same recall, but the MAP will have differences. In Section 4.4 we try to analyse the effect of the recall and MAP of the retrieval task on recovery of the target OOV PNs. To recover the target OOV PNs in the audio documents we perform a keyword search on the LVCSR lattices using the approach proposed by Chen et al. (2013). This is a quick and simple approach to evaluate the retrieved list of top-N OOV PNs.", "startOffset": 8, "endOffset": 804}, {"referenceID": 33, "context": "This might appear as a small number but it must be noted that as we increase the diachronic corpora to increase coverage of target OOV PNs this number will also multiply (Sheikh et al., 2016).", "startOffset": 170, "endOffset": 191}, {"referenceID": 6, "context": "For this KWS we employ the approach proposed by Chen et al. (2013), which enables searching of OOV words (in their phonetic form) in an LVCSR", "startOffset": 48, "endOffset": 67}], "year": 2016, "abstractText": "Many Proper Names (PNs) are Out-Of-Vocabulary (OOV) words for speech recognition systems used to process diachronic audio data. To help recovery of the PNs missed by the system, relevant OOV PNs can be retrieved out of the many OOVs by exploiting semantic context of the spoken content. In this paper, we propose two neural network models targeted to retrieve OOV PNs relevant to an audio document: (a) Document level Continuous Bag of Words (D-CBOW), (b) Document level Continuous Bag of Weighted Words (D-CBOW2). Both these models take document words as input and learn with an objective to maximise the retrieval of co-occurring OOV PNs. With the D-CBOW2 model we propose a new approach in which the input embedding layer is augmented with a context anchor layer. This layer learns to assign importance to input words and has the ability to capture (task specific) key-words in a bag-of-words neural network model. With experiments on French broadcast news videos we show that these two models outperform the baseline methods based on raw embeddings from LDA, Skip-gram and Paragraph Vectors. Combining the D-CBOW and D-CBOW2 models gives faster convergence during training.", "creator": "LaTeX with hyperref package"}}}