{"id": "1511.05488", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "17-Nov-2015", "title": "Active exploration of sensor networks from a robotics perspective", "abstract": "Traditional algorithms for robots who need to integrate into a wireless network often focus on one specific task. In this work we want to develop simple, adaptive and reusable algorithms for real world applications for this scenario. Starting with the most basic task for mobile wireless network nodes, finding the position of another node, we introduce an algorithm able to solve this task. We then show how this algorithm can readily be employed to solve a large number of other related tasks like finding the optimal position to bridge two static network nodes. For this we first introduce a meta-algorithm inspired by autonomous robot learning strategies and the concept of internal models which yields a class of source seeking algorithms for mobile nodes. The effectiveness of this algorithm is demonstrated in real world experiments using a physical mobile robot and standard 802.11 wireless LAN in an office environment. We also discuss the differences to conventional algorithms and give the robotics perspective on this class of algorithms. Then we proceed to show how more complex tasks, which might be encountered by mobile nodes, can be encoded in the same framework and how the introduced algorithm can solve them. These tasks can be direct (cross layer) optimization tasks or can also encode more complex tasks like bridging two network nodes. We choose the bridging scenario as an example, implemented on a real physical robot, and show how the robot can solve it in a real world experiment. The concept of internal models is presented in a practical example: the robot can be configured to be an autonomous robot. If you want to build a robot that can communicate with humans by way of a remote server, you need to install an internet service in the robot which could connect to a server using a wireless router. The robot can also be configured to use wireless remote connections and remote servers and connect to a remote computer via a WiFi router. There are three options to start from: the robot can communicate with humans and get information from a local router. The machine can also be configured to connect to a remote computer via a wireless router. In order to obtain information from a local router, you need to set up a network of network connections, including a high-bandwidth connection. The machine can also be configured to be configured to run a network of network connections as it is connected to an external computer. The robot can be configured to connect to a remote computer via a wireless router. As shown above, the algorithm will perform a task like this: The robot can communicate with humans and get information from a local router. We can also test the algorithm as an example and show how it can be implemented on", "histories": [["v1", "Tue, 17 Nov 2015 17:50:23 GMT  (1485kb,D)", "http://arxiv.org/abs/1511.05488v1", null]], "reviews": [], "SUBJECTS": "cs.RO cs.AI cs.NI", "authors": ["christian blum", "verena v hafner"], "accepted": false, "id": "1511.05488"}, "pdf": {"name": "1511.05488.pdf", "metadata": {"source": "CRF", "title": "Active exploration of sensor networks from a robotics perspective", "authors": ["Christian Blum", "Verena V. Hafner"], "emails": ["blum@informatik.hu-berlin.de"], "sections": [{"heading": null, "text": "Active exploration of sensor networks from a robotics perspective\nChristian Blum and Verena V. Hafner\nAdaptive Systems Group Department of Computer Science\nHumboldt-Universita\u0308t zu Berlin, Germany email: blum@informatik.hu-berlin.de\nTraditional algorithms for robots who need to integrate into a wireless network often focus on one specific task. In this work we want to develop simple, adaptive and reusable algorithms for real world applications for this scenario. Starting with the most basic task for mobile wireless network nodes, finding the position of another node, we introduce an algorithm able to solve this task. We then show how this algorithm can readily be employed to solve a large number of other related tasks like finding the optimal position to bridge two static network nodes. For this we first introduce a meta-algorithm inspired by autonomous robot learning strategies and the concept of internal models which yields a class of source seeking algorithms for mobile nodes. The effectiveness of this algorithm is demonstrated in real world experiments using a physical mobile robot and standard 802.11 wireless LAN in an office environment. We also discuss the differences to conventional algorithms and give the robotics perspective on this class of algorithms. Then we proceed to show how more complex tasks, which might be encountered by mobile nodes, can be encoded in the same framework and how the introduced algorithm can solve them. These tasks can be direct (cross layer) optimization tasks or can also encode more complex tasks like bridging two network nodes. We choose the bridging scenario as an example, implemented on a real physical robot, and show how the robot can solve it in a real world experiment."}, {"heading": "1 Introduction", "text": "Autonomous mobile network nodes are becoming more and more commonplace in the form of robots. Robots turn into mobile network nodes when they need to communicate data with either\nar X\niv :1\n51 1.\n05 48\n8v 1\n[ cs\n.R O\n] 1\n7 N\nov 2\n01 5\nother robots, infrastructure or humans. For example robot swarms often rely on explicit communication between each other and base stations and can even span their own network (Daniel et al., 2010; Hauert et al., 2010) or they want to make use of the sensors of a sensor network or even everyday objects like lighting systems or even a fridge, which become increasingly smarter and networked (Mattern and Floerkemeier, 2010). This also includes semi-autonomous operation of robots like for example in disaster scenarios in a supporting role for firefighters or rescue crews.\nThis means that they have to deal with the issues of signal attenuation, noise and interference, which are all of a spatial nature. A mobile robot can thus also use its mobility to mitigate negative effects in a cross layer fashion. This can in principle encompass everything from bandwidth optimization over energy savings up to interference mitigation.\nWe show one possible way to make use of the robot\u2019s mobility to optimize one network parameter and go on to show how this approach can be extended to all kinds of other criteria or parameters. We do this explicitly from a robotics point of view in order to give some new insights into this cross-cutting issue between networking and robotics."}, {"heading": "1.1 State of the Art", "text": "When dealing with any kind of taxis algorithm, the first question is if (local) position information is available to the agent or not. If there is no position information available, the only possible class of algorithms are stochastic ones similar to the ones employed by nature for example in chemotaxis of bacteria (Berg and Brown, 1972). When using directional antennas, this limitation can be mitigated and simple Braitenberg-style algorithms (Braitenberg, 1986) can find a source. However in this paper we are more interested in algorithms using position information but only measuring scalar samples of the target function1.\nMany algorithms estimate the bearing to sources from measurements by estimating Received Signal Strength Indicator (RSSI) gradients (Dantu et al., 2009; Han et al., 2009) or exploiting the anisotropic radiation profiles of antennas (Derenick et al., 2011). Furthermore, RSSI gradients can be used for frontier exploration of coverage areas (Twigg et al., 2012). These gradients can be estimated either using classical finite difference methods or by for example fitting a plane to local measurements to mitigate noise and using this plane to estimate the gradients (Paul et al., 2011).\nGradient based methods can be proven to converge for the case of signal strength in wireless networks under some constraints (Atanasov et al., 2012; Blum and Hafner, 2014). These methods basically implement gradient descent directly on noisy measurements and need to mitigate local maxima created by small scale fading.\nMore complex models than local linear approximations have been shown to effectively estimate source localization (Fink and Kumar, 2010). This algorithm uses Gaussian process models based on path-loss and attenuation priors. It performs very well in terms of accuracy and statistical efficiency, i.e., the number of samples needed but it unfortunately scales cubic with the number of samples.\nAlso more complex algorithms for source seeking have been presented. For example Wadhwa\n1This allows us to extend the target function to more complex targets, see section 6.\net al. (Wadhwa et al., 2011) present a multi-phase heuristic algorithm to mitigate the effects of very flat gradients far away from the source. This algorithm has only been evaluated in simulation."}, {"heading": "2 Algorithm", "text": "We first present a high-level view of the (meta-) algorithm we designed. This algorithm was designed with the task of finding the source of a wireless signal in mind but can readily be extended to a host of different tasks as will be shown in section 6.\nThe algorithm is presented schematically on a high level of abstraction in algorithm 1. While executing the algorithm, the robot receives a constant and asynchronous stream of messages from its various sensors, of which the current 2D position and the signal strengths of measured packets are used by the algorithm. At the beginning of each iteration of the algorithm, these messages are parsed and the positions interpolated to fit the timestamps of the signal strength measurements. The robot is capable of localizing and navigating autonomously which also means that movements are restricted to legal movements, i.e., ones which are not part of a wall or outside of the known map. For details refer to section 4.1.\nAlgorithm 1: Main Algorithm Input: x,y,r as asynchronous messages Output: move towards source do random movement; while not at source do\nparse messages; if abs(mean RSSI over last second - model prediction at current position) > error threshold then\ndiscard current model; learn new model on all available data;\nif random() > then go with min(dist to goal, step width) towards global minimum of the model; else do random movement;\nThe robot starts the algorithm with a random movement, which corresponds to a flat prior on all possible options. The initial movement is restricted to twice the regular step width and facilitates a first learning of the internal signal strength model (see section 4.2). We chose a constant step width of 1m for all experiments.\nAt the beginning of each iteration, all messages in the buffer are parsed and added to the available dataset. Then the model prediction error at the current location is calculated against the mean signal strength over the last second to mitigate some of the noise. If the prediction error surpasses an error threshold (we used a threshold of 3dB), the current model is discarded and a new model is learnt based on all available data. In principle the model could be discarded\nin every iteration and replaced with a new model based on the latest data but in order to keep computational cost to a minimum, especially for more complex models, we stick to a model as long as its performance does not degrade.\nThe next step implements what is known as the -greedy strategy in reinforcement learning (Sutton and Barto, 1998) and is one of the most simple strategies to balance exploitation and exploration of an agent. The strategy executes the action with the highest reward with a probability of 1 \u2212 and a random action with a probability of . Additionally, we anneal from 1.0 to 0.1 during the first couple of iterations. We chose to anneal = 0.9e\u2212\u03b1n + 0.1 \u221d e\u2212n where n is the number of iterations and \u03b1 such that = 0.5 at n = 5.\nIf a greedy step is selected, a grid search over the current model for all legal positions is performed to locate the global maximum. We chose grid search because the prediction steps of internal models are usually fast enough in relation to movement speeds and model learning to allow for brute force. Any standard optimization method could be used as a drop-in replacement. The robot then moves either directly towards the maximum if it is not further away than the step width or moves one step width towards the maximum. If the step leads to an invalid position, a random search on the line between the current position and the maximum starting at one step width distance is performed. The first valid point on this line that the search finds is chosen, i.e., either directly in front or after the obstacle blocking the step.\nAn -step means a random movement. We chose to implement that random movement in a novelty-driven way choosing only points where the robot has not been before. This is done by checking if a possible random movement is a minimum distance of about the size of the robot away from any points of the past trajectory of the robot and discarding those options. Points outside the known map are also discarded because of practical reasons. A point ~x is chosen randomly under these constraints from a probability distribution P (~x) \u221d e\u2212\u2016~x\u2212~x0\u2016 where ~x0 is the current position of the robot.\nAs for all optimization problems, there is no canonic way to terminate it. The most straightforward options would be a cut-off signal strength, which can be problematic because of noise, a maximum number of iterations or manual stopping, which we used in the experimental examples. The algorithm itself will stop moving the robot once a global maximum of the model has been reached. The algorithm continues and will occasionally lead to -steps which drive the robot away from the maximum. If the predicted maximum is truly a maximum, the algorithm will lead the robot back to this maximum after executing the -step. If however the new measurements collected by this -step contradict the model predictions, the model will be updated and possibly predict a different maximum. Thus global convergence can be assumed.\nIn general the parameters of the algorithm are not critically important for convergence, they mainly balance exploitation against exploration and are thus to some degree purely design choices. We tested different parameter configurations without changing the behaviour of the algorithm fundamentally. We settled on a configuration which worked well with the constraints we had for computational speed, speed of the robot and the test environment."}, {"heading": "3 Internal Model View", "text": "The concept of internal models originates from control theory but has been introduced in the fields of biology (Wolpert et al., 2011; Haruno et al., 1999) as well as in robotics (Demiris and Khadhouri, 2006; Schillaci et al., 2012). Internal models are often used as a representation of sensorimotor skills, and usually consist of a pair of forward model (predictor), which predicts sensory states as a consequence of motor commands performed at a current state, and inverse model (controller), which provides motor commands leading to a desired sensory state. Here we are mainly interested in forward models, which we will call internal models for the sake of simplicity. The inverse models in our case are predefined mappings of positional information, signal strength and steering commands as defined in section 2.\nA prominent hypothesis in Cognitive Robotics and Neuroscience states that situations beyond a certain minimal complexity can only be effectively handled by utilising agent-internal models (internal simulations) (Little and Sommer, 2013). Internal simulations can cope with noise and delay that is inherent in most biological and robotics systems.\nIt has been proposed that internal simulation processes can be behind the capability of anticipating and of recognising others\u2019 actions (Demiris and Khadhouri, 2006; Wolpert et al., 2003; Schillaci et al., 2012). In the context of network robotics, this idea can be mapped to using the internal model of the signal strength of a network node to identify this node.\nInternal models can also be reused since they encode knowledge of the agent. Internal models of the signal strength distribution of two nodes learned while trying to locate both nodes could for example be reused in the task of trying to optimally bridge these two nodes.\nThe concept of internal models is agnostic to the actual representation of the internal model, so representations of varying complexity and statistical power can be used depending on the available resources and prior knowledge. The representations of internal models reach from simple k-Nearest Neighbors over linear models or Multilayer Perceptron (MLP) to Gaussian Process models."}, {"heading": "3.1 Comparison to Gradient Based Algorithms", "text": "Gradient-based methods are based on the implicit Taylor expansion of the underlying signal strength function. Using the gradient means using a local linear approximation of this function, which is fitted every iteration to the current local data. This is usually done directly on noisy data, and under some constraints, convergence for this class of algorithms can be proven (Atanasov et al., 2012; Blum and Hafner, 2014). One precondition for convergence is that local maxima, which can result from small scale fading, have to be mitigated by using more samples for example by fitting a plane to the data instead of directly calculating gradients using finite differences, else the algorithms can get stuck in these maxima. From the internal model point of view, even plain gradient-based methods make use of an (implicit) internal model by this local linear approximation even though no information is propagated from iteration to iteration.\nBy making the choice of the (internal) model explicit and using all the available data, we can directly detect and mitigate local maxima. This also means that we can choose the shortest possible path to the maximum instead of following the gradient. The price for this additional information is additional computational and memory cost which is why we chose to update the\nmodel only when necessary and not every iteration as a gradient-based method would. This is also due to being able to explicitly check model predictions against real measured data.\nAdditionally, the choice of the -greedy strategy guarantees that the robot cannot get stuck in a wrongly perceived local maximum which is mistaken as a global maximum by the internal model. This strategy is a standard strategy employed in the field of reinforcement learning to balance exploration against exploitation (Sutton and Barto, 1998)."}, {"heading": "4 Implementation", "text": ""}, {"heading": "4.1 Hardware and ROS", "text": "We are using a TurtleBot 22 as a mobile base. The algorithm is implemented as a ROS node using a ROS node for capturing and analyzing the packets We are using the ROS navigation stack3 for navigation, localization and path planning using the Microsoft Kinect and odometry. The navigation is facilitated by a pre-learned map using OpenSlam\u2019s Gmapping4 and amcl5.\n2http://turtlebot.com/ 3http://wiki.ros.org/navigation 4http://wiki.ros.org/gmapping 5http://wiki.ros.org/amcl\nAs a medium we are using off-the-shelf usb 802.11 wireless dongles and tcpdump/libpcap6 for capturing packets. For all captured packets sent via the correct MAC-address, RSSI values are extracted from the Radiotap headers. The robot is depicted in fig. 1."}, {"heading": "4.2 Internal Models", "text": "To limit the computational cost of learning an internal model we chose to learn on a maximum of randomly drawn 10, 000 samples from our data. In the experiments we easily exceed 30, 000 samples. In the following two subsections, section 4.2.1 and section 4.2.2, we give a short overview over the two chosen instantiations of internal models and their implementation as learning strategies."}, {"heading": "4.2.1 Local Ridge Regression", "text": "Ridge regression is a linear least squares model with a Tikhonov regularization (Tikhonov, 1943). We use a local version of this by only fitting it to data inside of some radius to have a similar model as used in gradient-based algorithms. We used Ridge regression implemented by scikit-learn (Pedregosa et al., 2011) with a local radius of 5m and regularization parameter \u03b1 = 1.0. No preprocessing of the data was used.\nEven though using this model is similar to the idea of a locally linear Taylor approximation as used in gradient-based methods, it is superior in that it averages over an area, mitigating the effects of small scale fading and noise and in that it is regularized in order to prevent instabilities and overfitting."}, {"heading": "4.2.2 Multilayer Perceptron", "text": "As a second example of an internal model we chose an MLP with two input neurons, a hidden layer of 100 sigmoid neurons and one linear output neuron. All layers also have access to a bias node. Classic backpropagation with a small momentum term7 for three epochs was used for learning. We chose to use a fixed number of epochs to limit computational cost. We are not interested in full convergence and cross-validation since the algorithm checks the predictions of the model against real measured data constantly and re-learns the model if the prediction errors surpass a threshold. The network and learning was implemented using PyBrain (Schaul et al., 2010). We preprocessed the data to remove the mean and scale it to unit variance because those are assumed by our implementation of artificial neural networks."}, {"heading": "5 Experiments", "text": "All experiments are performed in a regular office environment with about 20 different active access points and countless clients in the 2.4GHz band in the test environment. The source node was emitting around 200 dummy packets/s which were then captured by the robot.\n6http://www.tcpdump.org/ 7learning rate 0.01 and momentum 0.1\nWe also did a complete mapping of the experimental area in terms of RSSI using our setup. The resulting hexagonal histogram is depicted in fig. 2. The bins of the histogram are larger than the wavelength of the wireless signal which means that it represents pure path loss and no interference effects such as small scale fading. We measured an average logarithmic Gaussian noise with a standard deviation of 4 dB.\nTo accurately model small scale fading and other interference effects, a very accurate simulation or even the complete solution of Maxwell\u2019s equations is necessary. This is computationally costly and requires accurate knowledge of material properties of walls etc. Effective models on the other hand are cheaper to calculate but only represent an abstract, stochastic model of the environment. Thus we chose to work directly with real world experiments in order not to lose or miss systematic physical effects such as small scale fading.\nSince we performed the experiments during regular office hours, a lot of disturbances such a\npersons walking, opening and closing doors, changing network load etc. affected the measurements and path planning. Additionally, the algorithm itself is stochastic. Thus, a large number of experiments would have to be conducted to gain statistically sound results. We chose to show some typical experiments instead.\nFive typical runs for the two different internal model implementations discussed in section 4.2 are depicted in fig. 3 and fig. 4 respectively. For all experiments the robot starts from the same initial position. The plots show trajectories, points where the model was updated as well as the signal strength as a function of the way travelled8.\nThe trajectories show several distinct variations which can shed some light on how the algorithm works. In the beginning of each experiment the robot does not posses any knowledge about the signal strength distribution and starts with an initial random step. For the next five iterations is higher than 0.5 and since the -steps are novelty driven, the probability of continuing in the same direction as the initial random step is higher than the probability of turning around. Once is approaching its final value of 0.1 and the robot has collected enough samples of the signal strength distribution, it either turns around if it initially went into the wrong direction or it continues on towards the maximum. Once the robot passes the room where the target node is located, it shows a similar behaviour. Either the internal model correctly predicts the position of the target node and the robot directly enters the room or the robot passes by the room but\n8Duration times vary wildly because of the robot stopping for persons, different training times, etc.\nthen turns around after the prediction error of the internal model measured against the collected samples passes the error threshold and the model is updated with new samples.\nConsidering the measurement history of the experiments, it is clear how big of a challenge the task is. Especially far away from the source, the gradients are much smaller than the noise of the measurements. Using finite difference gradient methods would only work for impractically large measurement steps or would lead to very noisy trajectories close to biased random walks. In contrast, both internal models seem to be able to cope with the noise and possible local maxima.\nThe particular choice of the internal model does not seem to make much of a difference though. This may be due to the simple (and convex) nature of the underlying function, which is essentially the path loss function measured and depicted in fig. 2. The choice of a concrete model might be more important when working with more complex target functions as discussed in section 6. In addition to the two exemplary models shown here, we also tried Support Vector Regression, Kernel Ridge Regression, different other configurations of an MLP, k-Nearest Neighbors Regression and Radius Nearest Neighbor Regression. All representations converged albeit with different convergence speeds. We believe that the choice of the meta-algorithm, i.e., constant model validation and novelty driven -greedy search, will lead to convergence of the algorithm as long as the particular model is in principle able to represent the target function."}, {"heading": "6 Extensions", "text": ""}, {"heading": "6.1 Idea und Theory", "text": "The presented algorithm can readily be extended to solve different tasks by noting that in essence it is just maximizing an unknown function with access to point measurements. The most straightforward extensions in the networking context would thus be to replace signal strength with any other interesting metric like for example Packet-Delivery Ratio (PDR) or Bit-Error Rate (BER). These metrics might be more noisy and contain a lot of local minima but the algorithm is able to cope with that by design.\nMore complex tasks can be easily constructed using compound metrics. As an example we consider the task of bridging two network nodes. Practically, this means moving to the point with the maximal but equal signal strength to both nodes. We construct a single metric fulfilling this criteria using the signal strengths of both nodes using a target function f like\nf = \u2212|RSSI1 \u2212 RSSI2| \u2212 |RSSI1 + RSSI2|\nwhere the indices 1 and 2 correspond to both nodes in question. This target function f with toy signal strength path loss functions for both nodes is depicted in fig. 5."}, {"heading": "469108 samples", "text": "The target function shows a clear maximum at exactly the center between the two source positions, so maximising it leads to maximal and equal signal strengths of both nodes.\nThis is only a toy example and other task-specific metrics can be designed making this algorithm very versatile in formulating and solving tasks for mobile nodes in wireless networks. A cross-layer approach would be especially interesting. For more complicated target functions, which are probably also more noisy, more complex internal models can be beneficial."}, {"heading": "6.2 Experiment", "text": "We did exemplary experiments with two nodes and the target function shown above. One of the nodes was the one used for the earlier experiments and the second one was placed in a\ndifferent office. Both nodes were simple USB wireless adapters dongles sending packets. Again, the experiments were conducted during regular office hours. fig. 6 shows the histogram of the measured values over all experiments conducted. As expected the function has one maximum somewhere between both nodes.\nUsing the target function f means that the noise of the measurements of both sources are combined following the law of propagation of uncertainty, which yields for the case of the same but independent noise for both nodes and the use of the target function f twice the noise of a single node, which is around 4 dB. We measured a standard deviation of about 9 arb. unit for our experiments which agrees well with the predicted error.\nThis also means that the magnitude of measured gradients would be less than the noise of the experiment, which means that a gradient descent algorithm would show a behaviour similar to a random walk with drift instead of a noisy gradient descent. Convergence would not be impacted\nby this high error but convergence speed would be low. fig. 7 depicts an exemplary experiment. We used an MLP as the internal model with the same parameters as for the single source experiment but we changed the error threshold to 7 arb. unit to account for the increased noise. The trajectory of the robot converges to the area of the maximum of fig. 6. The experiment was terminated before a stable maximum was reached because we chose to anneal to 0.1 instead of 0.0 which means that no fixed position can be reached by design. The magnitude of the noise can be seen in the measurement log of fig. 7.\nThe behaviour of the algorithm certainly can be improved by tuning parameters but the general idea of testing the internal model predictions against real measurements and refining it when necessary in combination with the -greedy strategy ensures convergence even without optimized parameters and in spite of very noisy measurements."}, {"heading": "7 Conclusions", "text": "In this paper we have introduced a class of algorithms to solve a number of tasks related to network robotics, specifically to autonomous mobile network nodes interacting with a wireless network. Beginning with the most basic task of source seeking, the general algorithm has shown to be effective in real world scenarios by a series of experiments with a real physical robot in an office environment. We then showed how this algorithm can be extended to various other tasks, which can be encountered by a mobile network node, such as maximizing the PDR to a certain target node or bridging two network nodes. For the bridging scenario an exemplary experiment has been conducted successfully.\nFurthermore, we have given insight into the robotics view on the problem and have discussed the relationship to conventional algorithms. We believe that this discussion can further the field of network robotics in an interdisciplinary manner and can also lead to new insights in other related fields."}, {"heading": "Acknowledgments", "text": "We thank everybody who contributed to the success of this project. This includes all members of the Adaptive Systems Group and the DFG graduate research training group METRIK (GRK 1324), which also funds one of the authors."}], "references": [{"title": "Stochastic source seeking in complex environments", "author": ["N. Atanasov", "J. Le Ny", "N. Michael", "G.J. Pappas"], "venue": "Robotics and Automation (ICRA), 2012 IEEE International Conference on, pages 3013\u20133018. IEEE.", "citeRegEx": "Atanasov et al\\.,? 2012", "shortCiteRegEx": "Atanasov et al\\.", "year": 2012}, {"title": "Chemotaxis in escherichia coli analysed by threedimensional tracking", "author": ["H.C. Berg", "D.A. Brown"], "venue": "Nature, 239(5374):500\u2013504. 14", "citeRegEx": "Berg and Brown,? 1972", "shortCiteRegEx": "Berg and Brown", "year": 1972}, {"title": "Gradient-based taxis algorithms for network robotics", "author": ["C. Blum", "V.V. Hafner"], "venue": "arXiv preprint arXiv:1409.7580.", "citeRegEx": "Blum and Hafner,? 2014", "shortCiteRegEx": "Blum and Hafner", "year": 2014}, {"title": "Vehicles: Experiments in synthetic psychology", "author": ["V. Braitenberg"], "venue": "MIT press.", "citeRegEx": "Braitenberg,? 1986", "shortCiteRegEx": "Braitenberg", "year": 1986}, {"title": "A communication aware steering strategy avoiding self-separation of flying robot swarms", "author": ["K. Daniel", "S. Rohde", "N. Goddemeier", "C. Wietfeld"], "venue": "Intelligent Systems (IS), 2010 5th IEEE International Conference, pages 254\u2013259. IEEE.", "citeRegEx": "Daniel et al\\.,? 2010", "shortCiteRegEx": "Daniel et al\\.", "year": 2010}, {"title": "Relative bearing estimation from commodity radios", "author": ["K. Dantu", "P. Goyal", "G. Sukhatme"], "venue": "Robotics and Automation, 2009. ICRA\u201909. IEEE International Conference on, pages 3871\u20133877. IEEE.", "citeRegEx": "Dantu et al\\.,? 2009", "shortCiteRegEx": "Dantu et al\\.", "year": 2009}, {"title": "Hierarchical attentive multiple models for execution and recognition of actions", "author": ["Y. Demiris", "B. Khadhouri"], "venue": "Robotics and autonomous systems, 54(5):361\u2013369.", "citeRegEx": "Demiris and Khadhouri,? 2006", "shortCiteRegEx": "Demiris and Khadhouri", "year": 2006}, {"title": "Localization using ambiguous bearings from radio signal strength", "author": ["J. Derenick", "J. Fink", "V. Kumar"], "venue": "Intelligent Robots and Systems (IROS), 2011 IEEE/RSJ International Conference on, pages 3248\u20133253. IEEE.", "citeRegEx": "Derenick et al\\.,? 2011", "shortCiteRegEx": "Derenick et al\\.", "year": 2011}, {"title": "Online methods for radio signal mapping with mobile robots", "author": ["J. Fink", "V. Kumar"], "venue": "Robotics and Automation (ICRA), 2010 IEEE International Conference on, pages 1940\u20131945. IEEE.", "citeRegEx": "Fink and Kumar,? 2010", "shortCiteRegEx": "Fink and Kumar", "year": 2010}, {"title": "Access point localization using local signal strength gradient", "author": ["D. Han", "D.G. Andersen", "M. Kaminsky", "K. Papagiannaki", "S. Seshan"], "venue": "Passive and Active Network Measurement, pages 99\u2013108.", "citeRegEx": "Han et al\\.,? 2009", "shortCiteRegEx": "Han et al\\.", "year": 2009}, {"title": "Multiple paired forward-inverse models for human motor learning and control", "author": ["M. Haruno", "D.M. Wolpert", "M. Kawato"], "venue": "Advances in neural information processing systems, pages 31\u201337.", "citeRegEx": "Haruno et al\\.,? 1999", "shortCiteRegEx": "Haruno et al\\.", "year": 1999}, {"title": "Communication-based swarming for flying robots", "author": ["S. Hauert", "S. Leven", "Zufferey", "J.-C.", "D. Floreano"], "venue": "International Workshop on Self-Organized Systems, number LISPOSTER-2010-001.", "citeRegEx": "Hauert et al\\.,? 2010", "shortCiteRegEx": "Hauert et al\\.", "year": 2010}, {"title": "Learning and exploration in action-perception loops", "author": ["D.Y. Little", "F.T. Sommer"], "venue": "Frontiers in Neural Circuits, 7(37).", "citeRegEx": "Little and Sommer,? 2013", "shortCiteRegEx": "Little and Sommer", "year": 2013}, {"title": "From the internet of computers to the internet of things", "author": ["F. Mattern", "C. Floerkemeier"], "venue": "From active data management to event-based systems and more, pages 242\u2013259. Springer.", "citeRegEx": "Mattern and Floerkemeier,? 2010", "shortCiteRegEx": "Mattern and Floerkemeier", "year": 2010}, {"title": "Radio signal strength tracking and control for robotic networks", "author": ["L.Y. Paul", "J.N. Twigg", "B.M. Sadler"], "venue": "SPIE Defense, Security, and Sensing, pages 803116\u2013803116.", "citeRegEx": "Paul et al\\.,? 2011", "shortCiteRegEx": "Paul et al\\.", "year": 2011}, {"title": "Scikit-learn: Machine learning in Python", "author": ["F. Pedregosa", "G. Varoquaux", "A. Gramfort", "V. Michel", "B. Thirion", "O. Grisel", "M. Blondel", "P. Prettenhofer", "R. Weiss", "V. Dubourg", "J. Vanderplas", "A. Passos", "D. Cournapeau", "M. Brucher", "M. Perrot", "E. Duchesnay"], "venue": "Journal of Machine Learning Research, 12:2825\u20132830.", "citeRegEx": "Pedregosa et al\\.,? 2011", "shortCiteRegEx": "Pedregosa et al\\.", "year": 2011}, {"title": "PyBrain", "author": ["T. Schaul", "J. Bayer", "D. Wierstra", "Y. Sun", "M. Felder", "F. Sehnke", "T. R\u00fcckstie\u00df", "J. Schmidhuber"], "venue": "Journal of Machine Learning Research, 11:743\u2013746.", "citeRegEx": "Schaul et al\\.,? 2010", "shortCiteRegEx": "Schaul et al\\.", "year": 2010}, {"title": "Internal simulations for behaviour selection and recognition", "author": ["G. Schillaci", "B. Lara", "V.V. Hafner"], "venue": "Salah, A. A., del Solar, J. R., Mericli, C., and Oudeyer, P.-Y., editors, HBU, volume 7559 of Lecture Notes in Computer Science, pages 148\u2013160. Springer.", "citeRegEx": "Schillaci et al\\.,? 2012", "shortCiteRegEx": "Schillaci et al\\.", "year": 2012}, {"title": "Introduction to reinforcement learning", "author": ["R.S. Sutton", "A.G. Barto"], "venue": "MIT Press.", "citeRegEx": "Sutton and Barto,? 1998", "shortCiteRegEx": "Sutton and Barto", "year": 1998}, {"title": "On the stability of inverse problems", "author": ["A.N. Tikhonov"], "venue": "Dokl. Akad. Nauk SSSR, volume 39, pages 195\u2013198.", "citeRegEx": "Tikhonov,? 1943", "shortCiteRegEx": "Tikhonov", "year": 1943}, {"title": "Rss gradient-assisted frontier exploration and radio source localization", "author": ["J.N. Twigg", "J.R. Fink", "P. Yu", "B.M. Sadler"], "venue": "Robotics and Automation (ICRA), 2012 IEEE International Conference on, pages 889\u2013895. IEEE.", "citeRegEx": "Twigg et al\\.,? 2012", "shortCiteRegEx": "Twigg et al\\.", "year": 2012}, {"title": "Following an rf trail to its source", "author": ["A. Wadhwa", "U. Madhow", "J. Hespanha", "B.M. Sadler"], "venue": "Communication, Control, and Computing (Allerton), 2011 49th Annual Allerton Conference on, pages 580\u2013587. IEEE.", "citeRegEx": "Wadhwa et al\\.,? 2011", "shortCiteRegEx": "Wadhwa et al\\.", "year": 2011}, {"title": "Principles of sensorimotor learning", "author": ["D.M. Wolpert", "J. Diedrichsen", "J.R. Flanagan"], "venue": "Nature Reviews Neuroscience, 12(12):739\u2013751.", "citeRegEx": "Wolpert et al\\.,? 2011", "shortCiteRegEx": "Wolpert et al\\.", "year": 2011}, {"title": "A unifying computational framework for motor control and social interaction", "author": ["D.M. Wolpert", "K. Doya", "M. Kawato"], "venue": "Philosophical Transactions of the Royal Society of London. Series B: Biological Sciences, 358(1431):593\u2013602.", "citeRegEx": "Wolpert et al\\.,? 2003", "shortCiteRegEx": "Wolpert et al\\.", "year": 2003}], "referenceMentions": [{"referenceID": 4, "context": "For example robot swarms often rely on explicit communication between each other and base stations and can even span their own network (Daniel et al., 2010; Hauert et al., 2010) or they want to make use of the sensors of a sensor network or even everyday objects like lighting systems or even a fridge, which become increasingly smarter and networked (Mattern and Floerkemeier, 2010).", "startOffset": 135, "endOffset": 177}, {"referenceID": 11, "context": "For example robot swarms often rely on explicit communication between each other and base stations and can even span their own network (Daniel et al., 2010; Hauert et al., 2010) or they want to make use of the sensors of a sensor network or even everyday objects like lighting systems or even a fridge, which become increasingly smarter and networked (Mattern and Floerkemeier, 2010).", "startOffset": 135, "endOffset": 177}, {"referenceID": 13, "context": ", 2010) or they want to make use of the sensors of a sensor network or even everyday objects like lighting systems or even a fridge, which become increasingly smarter and networked (Mattern and Floerkemeier, 2010).", "startOffset": 181, "endOffset": 213}, {"referenceID": 1, "context": "If there is no position information available, the only possible class of algorithms are stochastic ones similar to the ones employed by nature for example in chemotaxis of bacteria (Berg and Brown, 1972).", "startOffset": 182, "endOffset": 204}, {"referenceID": 3, "context": "When using directional antennas, this limitation can be mitigated and simple Braitenberg-style algorithms (Braitenberg, 1986) can find a source.", "startOffset": 106, "endOffset": 125}, {"referenceID": 5, "context": "Many algorithms estimate the bearing to sources from measurements by estimating Received Signal Strength Indicator (RSSI) gradients (Dantu et al., 2009; Han et al., 2009) or exploiting the anisotropic radiation profiles of antennas (Derenick et al.", "startOffset": 132, "endOffset": 170}, {"referenceID": 9, "context": "Many algorithms estimate the bearing to sources from measurements by estimating Received Signal Strength Indicator (RSSI) gradients (Dantu et al., 2009; Han et al., 2009) or exploiting the anisotropic radiation profiles of antennas (Derenick et al.", "startOffset": 132, "endOffset": 170}, {"referenceID": 7, "context": ", 2009) or exploiting the anisotropic radiation profiles of antennas (Derenick et al., 2011).", "startOffset": 69, "endOffset": 92}, {"referenceID": 20, "context": "Furthermore, RSSI gradients can be used for frontier exploration of coverage areas (Twigg et al., 2012).", "startOffset": 83, "endOffset": 103}, {"referenceID": 14, "context": "These gradients can be estimated either using classical finite difference methods or by for example fitting a plane to local measurements to mitigate noise and using this plane to estimate the gradients (Paul et al., 2011).", "startOffset": 203, "endOffset": 222}, {"referenceID": 0, "context": "Gradient based methods can be proven to converge for the case of signal strength in wireless networks under some constraints (Atanasov et al., 2012; Blum and Hafner, 2014).", "startOffset": 125, "endOffset": 171}, {"referenceID": 2, "context": "Gradient based methods can be proven to converge for the case of signal strength in wireless networks under some constraints (Atanasov et al., 2012; Blum and Hafner, 2014).", "startOffset": 125, "endOffset": 171}, {"referenceID": 8, "context": "More complex models than local linear approximations have been shown to effectively estimate source localization (Fink and Kumar, 2010).", "startOffset": 113, "endOffset": 135}, {"referenceID": 21, "context": "(Wadhwa et al., 2011) present a multi-phase heuristic algorithm to mitigate the effects of very flat gradients far away from the source.", "startOffset": 0, "endOffset": 21}, {"referenceID": 18, "context": "The next step implements what is known as the -greedy strategy in reinforcement learning (Sutton and Barto, 1998) and is one of the most simple strategies to balance exploitation and exploration of an agent.", "startOffset": 89, "endOffset": 113}, {"referenceID": 22, "context": "The concept of internal models originates from control theory but has been introduced in the fields of biology (Wolpert et al., 2011; Haruno et al., 1999) as well as in robotics (Demiris and Khadhouri, 2006; Schillaci et al.", "startOffset": 111, "endOffset": 154}, {"referenceID": 10, "context": "The concept of internal models originates from control theory but has been introduced in the fields of biology (Wolpert et al., 2011; Haruno et al., 1999) as well as in robotics (Demiris and Khadhouri, 2006; Schillaci et al.", "startOffset": 111, "endOffset": 154}, {"referenceID": 6, "context": ", 1999) as well as in robotics (Demiris and Khadhouri, 2006; Schillaci et al., 2012).", "startOffset": 31, "endOffset": 84}, {"referenceID": 17, "context": ", 1999) as well as in robotics (Demiris and Khadhouri, 2006; Schillaci et al., 2012).", "startOffset": 31, "endOffset": 84}, {"referenceID": 12, "context": "A prominent hypothesis in Cognitive Robotics and Neuroscience states that situations beyond a certain minimal complexity can only be effectively handled by utilising agent-internal models (internal simulations) (Little and Sommer, 2013).", "startOffset": 211, "endOffset": 236}, {"referenceID": 6, "context": "It has been proposed that internal simulation processes can be behind the capability of anticipating and of recognising others\u2019 actions (Demiris and Khadhouri, 2006; Wolpert et al., 2003; Schillaci et al., 2012).", "startOffset": 136, "endOffset": 211}, {"referenceID": 23, "context": "It has been proposed that internal simulation processes can be behind the capability of anticipating and of recognising others\u2019 actions (Demiris and Khadhouri, 2006; Wolpert et al., 2003; Schillaci et al., 2012).", "startOffset": 136, "endOffset": 211}, {"referenceID": 17, "context": "It has been proposed that internal simulation processes can be behind the capability of anticipating and of recognising others\u2019 actions (Demiris and Khadhouri, 2006; Wolpert et al., 2003; Schillaci et al., 2012).", "startOffset": 136, "endOffset": 211}, {"referenceID": 0, "context": "This is usually done directly on noisy data, and under some constraints, convergence for this class of algorithms can be proven (Atanasov et al., 2012; Blum and Hafner, 2014).", "startOffset": 128, "endOffset": 174}, {"referenceID": 2, "context": "This is usually done directly on noisy data, and under some constraints, convergence for this class of algorithms can be proven (Atanasov et al., 2012; Blum and Hafner, 2014).", "startOffset": 128, "endOffset": 174}, {"referenceID": 18, "context": "This strategy is a standard strategy employed in the field of reinforcement learning to balance exploration against exploitation (Sutton and Barto, 1998).", "startOffset": 129, "endOffset": 153}, {"referenceID": 19, "context": "Ridge regression is a linear least squares model with a Tikhonov regularization (Tikhonov, 1943).", "startOffset": 80, "endOffset": 96}, {"referenceID": 15, "context": "We used Ridge regression implemented by scikit-learn (Pedregosa et al., 2011) with a local radius of 5m and regularization parameter \u03b1 = 1.", "startOffset": 53, "endOffset": 77}, {"referenceID": 16, "context": "The network and learning was implemented using PyBrain (Schaul et al., 2010).", "startOffset": 55, "endOffset": 76}], "year": 2015, "abstractText": "Traditional algorithms for robots who need to integrate into a wireless network often focus on one specific task. In this work we want to develop simple, adaptive and reusable algorithms for real world applications for this scenario. Starting with the most basic task for mobile wireless network nodes, finding the position of another node, we introduce an algorithm able to solve this task. We then show how this algorithm can readily be employed to solve a large number of other related tasks like finding the optimal position to bridge two static network nodes. For this we first introduce a meta-algorithm inspired by autonomous robot learning strategies and the concept of internal models which yields a class of source seeking algorithms for mobile nodes. The effectiveness of this algorithm is demonstrated in real world experiments using a physical mobile robot and standard 802.11 wireless LAN in an office environment. We also discuss the differences to conventional algorithms and give the robotics perspective on this class of algorithms. Then we proceed to show how more complex tasks, which might be encountered by mobile nodes, can be encoded in the same framework and how the introduced algorithm can solve them. These tasks can be direct (cross layer) optimization tasks or can also encode more complex tasks like bridging two network nodes. We choose the bridging scenario as an example, implemented on a real physical robot, and show how the robot can solve it in a real world experiment.", "creator": "LaTeX with hyperref package"}}}