{"id": "1512.04011", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "13-Dec-2015", "title": "L1-Regularized Distributed Optimization: A Communication-Efficient Primal-Dual Framework", "abstract": "Despite the importance of sparsity in many big data applications, there are few existing methods for efficient distributed optimization of sparsely-regularized objectives. In this paper, we present a communication-efficient framework for L1-regularized optimization in distributed environments. By taking a non-traditional view of classical objectives as part of a more general primal-dual setting, we obtain a new class of methods that can be efficiently distributed and is applicable to common L1-regularized regression and classification objectives, such as Lasso, sparse logistic regression, and elastic net regression. We provide convergence guarantees for this framework and demonstrate strong empirical performance as compared to other state-of-the-art methods on several real-world distributed datasets.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "histories": [["v1", "Sun, 13 Dec 2015 06:49:00 GMT  (278kb,D)", "https://arxiv.org/abs/1512.04011v1", null], ["v2", "Thu, 2 Jun 2016 23:45:03 GMT  (422kb,D)", "http://arxiv.org/abs/1512.04011v2", null]], "reviews": [], "SUBJECTS": "cs.LG", "authors": ["virginia smith", "simone forte", "michael i jordan", "martin jaggi"], "accepted": false, "id": "1512.04011"}, "pdf": {"name": "1512.04011.pdf", "metadata": {"source": "CRF", "title": "L1-Regularized Distributed Optimization: A Communication-Efficient Primal-Dual Framework", "authors": ["Virginia Smith", "Simone Forte", "Michael I. Jordan"], "emails": [], "sections": [{"heading": "1 Introduction", "text": "In this paper, we consider standard regularized loss minimization problems, including as our main focus L1-regularized optimization problems of the form\nmin \u03b1\u2208Rn f(A\u03b1) + \u03bb \u2016\u03b1\u20161 ,\nwhere \u03b1 \u2208 Rn is the weight vector, A \u2208 Rd\u00d7n is a given data matrix, and \u03bb is a regularization parameter. This formulation includes many popular L1-regularized classification and regression models, such as Lasso and sparse logistic regression, and is easily extended to other separable regularizers like elastic net. Models of this form are particularly useful in high-dimensional settings because of their tendency to bias learning towards sparse solutions. However, despite their importance, few methods currently exist to efficiently fit such sparsity-inducing models in the distributed environment.\nOne promising distributed method is COCOA+ [12, 17], a recently proposed primal-dual framework that demonstrates competitive performance, provides a flexible communication scheme, and enables the use of off-the-shelf single-machine solvers internally. However, by solving the problem in the dual, COCOA+ (like SDCA, prox-SDCA, and numerous other primal-dual methods [26, 27, 30, 35, 36]) is only equipped to handle strongly convex regularizers, which prevents it from being directly applied to L1-regularized objectives. Moreover, by requiring the data to be distributed by data point rather than by feature, communication can become a prohibitive bottleneck for COCOA+ as the number of features grows large, which is precisely the setting of interest for L1 regularization.\nIn this work, we take a different perspective and propose a framework that can run either in the dual, or on the primal directly. From this change in perspective we derive several new primal-dual distributed optimization methods, in particular for sparsity-inducing regularizers. Our approach uses ideas from COCOA+, though leveraging these ideas in this new setting requires significant theoretical and algorithmic modifications, particularly in handling non-strongly convex regularizers. The proposed primal-dual framework and associated rates are novel contributions even in the non-distributed case.\n\u2020Parts of this work appear in SF\u2019s Master\u2019s Thesis [10].\nar X\niv :1\n51 2.\n04 01\n1v 2\n[ cs\n.L G\n] 2\nJ un"}, {"heading": "1.1 Contributions", "text": "Generalized framework. By building on the COCOA+ framework, PROXCOCOA+ comes with several benefits, including the use of arbitrary local solvers on each machine, and the analysis of and ability to solve subproblems to arbitrary accuracies. However in contrast to COCOA+, we consider a much broader class of optimization problems. This results in a more general framework that: (1) specifically incorporates the case of L1 regularization; (2) allows for the flexibility of distributing the data by either feature or data point; and (3) can be run on either the primal or dual formulation, which we show to have significant theoretical and practical implications.\nAnalysis of non-strongly convex regularizers and losses. We derive convergence rates for the general class of problems considered in this work, leveraging a novel approach in the analysis of primal-dual rates for non-strongly convex regularizers. The proposed technique is a significant improvement over simple smoothing techniques used in, e.g., [22, 27, 35] that enforce strong convexity by adding a small L2 term to the objective. Our results include primal-dual rates and certificates for both strongly convex and non-strongly convex regularizers and losses, and we show how earlier rates of COCOA and COCOA+ can be derived as a special case of our new rates / methods.\nExperimental comparison. The proposed framework yields order-of-magnitude speedups (as much as 50\u00d7 faster) as compared to other state-of-the-art methods for L1-regularized optimization. We demonstrate these performance gains in an extensive experimental comparison on real-world distributed datasets. We additionally show significant improvements over COCOA+ when considering strongly convex objectives. All algorithms for comparison are implemented in Apache Spark and run on Amazon EC2 clusters. Our code is available at: github.com/gingsmith/proxcocoa."}, {"heading": "2 Setup", "text": "A great variety of methods in machine learning and signal processing are posed as the minimization of a weighted sum of two convex functions, where the first term is a convex function of a linear predictor and the second term is a regularizer:\nmin \u03b1\u2208Rn f(A\u03b1) + g(\u03b1) . (A)\nHere \u03b1 \u2208 Rn is the parameter vector, and A := [x1; . . . ;xn] \u2208 Rd\u00d7n is a data matrix with column vectors xi \u2208 Rd, i \u2208 [n] and row vectors yTj \u2208 Rn, j \u2208 [d]. Our central assumption will be that g(\u00b7) is separable, meaning that\ng(\u03b1) = n\u2211 i=1 gi(\u03b1i)\nfor convex functions gi : R\u2192 R. Furthermore, we assume f : Rd \u2192 R is (1/\u03c4)-smooth for \u03c4 > 0. Examples. The above setting encompasses all convex loss functions depending on linear predictors yTj \u03b1, together with most common convex regularizers, including all separable functions, such as L1or general Lp-norms, or the elastic net given by \u03b72 \u2016\u00b7\u20162 + (1\u2212 \u03b7) \u2016\u00b7\u20161. Data partitioning. To map this setup to the distributed environment, we suppose that the dataset A is distributed over K machines according to a partition {Pk}Kk=1 of the columns of A \u2208 Rd\u00d7n. We denote the size of the partition on machine k by nk = |Pk|. For k \u2208 [K] and \u03b1 \u2208 Rn, we define \u03b1[k] \u2208 Rn as the n-vector with elements (\u03b1[k])i := \u03b1i if i \u2208 Pk and (\u03b1[k])i := 0 otherwise."}, {"heading": "3 The PROXCOCOA+ Algorithmic Framework", "text": "The PROXCOCOA+ framework is given in Algorithm 1. This framework builds on the recent COCOA+ framework [12, 17], though with a more general objective, a modified subproblem, and where we allow the method to be applied to either the primal or dual formulation. To distribute the method, we assign each machine to work only on local coordinates of the weight vector \u03b1, and access only data that is stored locally. Machines share state through the vector v := A\u03b1. This vector is communicated at each round after using local solvers in parallel to find (possibly) approximate solutions to the subproblems defined in (2). Solving the primal problem (A) directly with PROXCOCOA+ will result in distributing the data column-wise (by feature), and having the vector v be of length equal to the number of data points. This can greatly reduce communication costs as the number of features grows (see Section 6). Most importantly, the proposed setup will prepare us to handle non-strongly convex regularizers in both theory and practice, as we further explain in the following sections.\nAlgorithm 1 PROXCOCOA+ Distributed Framework for Problem (A)\n1: Input: Data matrix A distributed column-wise according to partition {Pk}Kk=1, aggregation parameter \u03b3\u2208(0, 1], and parameter \u03c3\u2032 for the local subproblems G\u03c3\u2032k (\u2206\u03b1[k];v,\u03b1[k]). Starting point \u03b1(0) := 0 \u2208 Rn, v(0) := 0 \u2208 Rd. 2: for t = 0, 1, 2, . . . do 3: for k \u2208 {1, 2, . . . ,K} in parallel over computers do 4: call local solver, returning a \u0398-approximate solution \u2206\u03b1[k] of the local subproblem (2) 5: update local variables \u03b1(t+1)[k] := \u03b1 (t) [k] + \u03b3\u2206\u03b1[k] 6: return updates to shared state \u2206vk := A\u2206\u03b1[k] 7: end for 8: reduce v(t+1) := v(t) + \u03b3 \u2211K k=1 \u2206vk 9: end for\nData-local quadratic subproblems. For each machine, we define a data-local subproblem of the original optimization problem (A). This simpler problem can be solved on machine k and only requires accessing data which is already available locally, i.e., columns Ai such that i \u2208 Pk. The subproblem depends only on the previous shared vector v := A\u03b1 and the local data:\nmin \u2206\u03b1[k]\u2208Rn\nG\u03c3 \u2032\nk (\u2206\u03b1[k];v,\u03b1[k]) , (1)\nwhere\nG\u03c3 \u2032 k (\u2206\u03b1[k];v,\u03b1[k]) := 1\nK f(v) + wTA\u2206\u03b1[k] +\n\u03c3\u2032\n2\u03c4 \u2225\u2225\u2225A\u2206\u03b1[k]\u2225\u2225\u22252 + \u2211 i\u2208Pk gi(\u03b1i + \u2206\u03b1[k]i) (2)\nwith w := \u2207f(v). We denote the change of local variables \u03b1i for indices i \u2208 Pk as \u2206\u03b1[k]. For a given aggregation parameter \u03b3 \u2208 (0, 1], the subproblem relaxation parameter \u03c3\u2032 will be set as \u03c3\u2032 := \u03b3K, but can also be improved in a data-dependent way as we discuss in Appendix E.\nReusability of existing single-machine solvers. Our local subproblems have the appealing property of being very similar in structure to the global problem (A), with the main difference being that they are defined on a smaller (local) subset of the data. For the user of our framework, this presents a major advantage in that existing single machine-solvers can be directly re-used in our distributed framework (Algorithm 1) by employing them on the subproblems G\u03c3\u2032k . Therefore, problem-specific tuned solvers which have already been developed, along with associated speed improvements (such as multi-core implementations), can be easily leveraged in the distributed setting. We quantify the dependence on local solver performance in more detail in our convergence analysis (Section 4).\nInterpretation. The above definition of the local objective functions G\u03c3\u2032k are such that they closely approximate the global objective in (A) as the \u201clocal\u201d variable \u2206\u03b1[k] varies, which we will see in the analysis (Lemma 8 in the appendix). In fact, if the subproblem were solved exactly, this could be interpreted as a data-dependent, block-separable proximal step, applied to the f part of the objective (A) as follows: K\u2211 k=1 G\u03c3 \u2032 k (\u2206\u03b1[k];v,\u03b1[k]) = L+ f(v) +\u2207f(v)TA\u2206\u03b1 + \u03c3\u2032 2\u03c4 \u2206\u03b1T A T [1]A[1] 0 . . .\n0 AT[K]A[K] \u2206\u03b1 , where L = \u2211 i\u2208[n] gi(\u03b1i + \u2206\u03b1i) .\nHowever, note that in contrast to traditional proximal methods, our algorithm does not assume that the prox subproblems be solved to high accuracy, as we instead allow the use of local solvers of any approximation quality \u0398. This notion is made precise with the following assumption.\nAssumption 1 (\u0398-approximate solution, see [17]). We assume that there exists \u0398 \u2208 [0, 1) such that \u2200k \u2208 [K], the local solver at any outer iteration t produces a (possibly) randomized approximate solution \u2206\u03b1[k], which satisfies\nE [ G\u03c3 \u2032 k (\u2206\u03b1[k];v,\u03b1[k])\u2212 G\u03c3 \u2032 k (\u2206\u03b1 ? [k];v,\u03b1[k]) ] \u2264 \u0398 ( G\u03c3 \u2032 k (0;v,\u03b1[k])\u2212 G\u03c3 \u2032 k (\u2206\u03b1 ? [k];v,\u03b1[k]) ) , (3)\nwhere \u2206\u03b1?[k] \u2208 arg min\n\u2206\u03b1\u2208Rn G\u03c3 \u2032 k (\u2206\u03b1[k];v,\u03b1[k]) \u2200k \u2208 [K] . (4)\nRemark 1. In practice, the time spent solving the local subproblems in parallel should be chosen comparable to the required time of a communication round, for best overall efficiency on a given system. We study this trade-off both in theory (Section 4) and experiments (Section 6)."}, {"heading": "3.1 Primal-Dual Context", "text": "Exploiting primal-dual structure is not a requirement to optimize (A); indeed, we have shown above how to solve this optimization problem directly. However, noting the relationship between primal and dual objectives has many benefits, including computation of the duality gap, which allows us to have a certificate of approximation quality. It is also useful as an analysis tool and helps relate this work to the prior work of [30, 12, 17]. To leverage this structure, starting from our original formulation (A) with objective function D(\u03b1) := f(A\u03b1) + \u2211n i=1 gi(\u03b1i), the dual problem is given by\nmin w\u2208Rd\n[ P(w) := f\u2217(w) + n\u2211 i=1 g\u2217i (\u2212xTi w) ] . (B)\nHere w \u2208 Rd is a weight vector and xi \u2208 Rd are columns of the data matrix A. The functions f\u2217, g\u2217i are the convex conjugates of f, gi in the original problem (A). This duality structure is known as Fenchel-Rockafellar Duality (see [4, Theorem 4.4.2] or a self-contained derivation in the appendix).\nGiven \u03b1 \u2208 Rn in the context of (A), a corresponding primal vector w \u2208 Rd for problem (B) is obtained by: w = w(\u03b1) := \u2207f(A\u03b1) . (5) This mapping is given by the first-order optimality conditions for the f -part of the objective. (Recall that we assumed gi : R\u2192 R are arbitrary closed convex functions, f : Rd \u2192 R is (1/\u03c4)-smooth.) The duality gap, given by: G(\u03b1) := P(w(\u03b1))\u2212 (\u2212D(\u03b1)) (6) acts as a certificate of approximation quality, as the distance to the true optimum P(w?) is always bounded above by the duality gap. A globally defined and finite duality gapG(\u03b1) for any problem (A) can be obtained by bounding the region of interest for the iterates \u03b1. This \u201cLipschitzing\u201d trick will make the conjugates g\u2217i globally defined and Lipschitz [8], as we prove in Section 4.\nPrimal vs. Dual. Previous work of COCOA+ mapped machine learning tasks to P(w) (B), and then solved this problem in the dual. While this can still be accomplished with the machinery of PROXCOCOA+ (see Section F), here our main focus is to instead solve the original objectiveD(\u03b1) (A) directly. This can have a large practical impact for the described applications in the distributed setting, as it implies that we can distribute the data by feature rather than by data point. Further, we will communicate a vector equal in size to the number of data points, as opposed to the number of features. When the number of features is high (as is common in sparsity-inducing models) this can significantly reduce communication and improve overall performance, as we demonstrate in Section 6. Further, it allows us to directly leverage state-of-the-art coordinate-wise primal methods, such as GLMNET [11] and extensions [34, 13]. From a theoretical perspective, solving D(\u03b1) will allow us to consider non-strongly convex regularizers, which were not covered in COCOA+, as we discuss in Section 4."}, {"heading": "4 Convergence Analysis", "text": "In this section we provide convergence rates for the proposed framework, and introduce an important theoretical technique in analyzing non-strongly convex terms in the primal-dual setting. For simplicity of presentation, we assume in the analysis that the data partition is balanced; i.e., nk = n/K for all k. Furthermore, we assume that the columns of A satisfy \u2016xi\u2016 \u2264 1 for all i \u2208 [n]. We present results for the case where \u03b3 := 1 in Algorithm 1, and where the subproblems (2) are defined using the corresponding safe bound \u03c3\u2032 := K. This case delivers the fastest convergence rates in the distributed setting, which in particular don\u2019t degrade as the number of machines K grows and n remains fixed."}, {"heading": "4.1 General Convex gi", "text": "Our first main theorem provides convergence guarantees for objectives with non-strongly convex regularizers, including models such as Lasso and sparse logistic regression. Providing primal-dual\nrates and globally defined primal-dual accuracy certificates requires a theoretical technique that we introduce below, in which we show how to satisfy the following notion of L-bounded support. Definition 1 (L-Bounded Support). A function h has L-bounded support if its effective domain is bounded by L, i.e.,\nh(u) < +\u221e \u21d2 \u2016u\u2016 \u2264 L . (7)\nAs we explain in Section F of the appendix, our assumption of L-bounded support for the gi functions can be interpreted as an assumption that their conjugates are globally L-Lipschitz.\nTheorem 1. Consider Algorithm 1 with \u03b3 := 1, and let \u0398 be the quality of the local solver as in Assumption 1. Let gi have L-bounded support, and f be (1/\u03c4)-smooth. Then after T iterations where\nT \u2265 T0+ max{ \u2308 1\n1\u2212\u0398\n\u2309 , 4L2n2\n\u03c4 G(1\u2212\u0398) } , (8)\nT0 \u2265 t0 + [ 2\n1\u2212\u0398\n( 8L2n2 \u03c4 G \u2212 1 )] + , t0 \u2265 max(0, \u2308 1 (1\u2212\u0398) log ( \u03c4(D(\u03b1(0))\u2212D(\u03b1?)) 2L2Kn )\u2309 ) ,\nwe have that the expected duality gap satisfies\nE[P(w(\u03b1))\u2212 (\u2212D(\u03b1))] \u2264 G , where \u03b1 is the averaged iterate returned by Algorithm 1.\nBounded support modification. Note that the absolute value function gi = | \u00b7 | for L1 regularization does not have L-bounded support, and thus violates the assumptions yielding convergence in Theorem 1. Its dual, the indicator function of the interval, is not defined globally, and thus does not always allow a finite duality gap. To address this, existing approaches typically use a simple smoothing technique as in [22]: by adding a small amount of L2 to the L1-norm, it becomes strongly convex; see, e.g., [27]. This Nesterov smoothing technique is undesirable in practice, as it changes the iterates, the convergence rate, and the tightness of the resulting duality gap. Further, the amount of smoothing can be difficult to tune and can have a large influence on the performance of the method at hand. We show examples of this issue with experiments in Section 6.\nIn contrast, our approach preserves all solutions of the original objective, leaves the iterate sequence unchanged, and allows for direct reusability of existing L1 solvers. It also removes the need for additional parameter tuning. To achieve this, we modify the function | \u00b7 | by imposing an additional weak constraint that is inactive in our region of interest. Formally, we replace gi(\u00b7) = | \u00b7 | by\ng\u0304i(\u03b1) := { |\u03b1| : \u03b1 \u2208 [\u2212B,B] +\u221e : otherwise.\nFor large enough B, this problem yields the same solution as the original L1-regularized objective. Note that this only affects convergence theory, in that it allows us to present a strong primal-dual rate (Theorem 1 for L=B). The modification of gi does not affect the algorithms for the original problems. Whenever a monotone optimizer is used, we will never leave the level set defined by the objective at the starting point. We provide further details on this technique in Section D.3, and illustrate how to leverage it for a variety of applications (see Section C of the appendix and also [8])."}, {"heading": "4.2 Strongly Convex gi", "text": "For the case of strongly convex gi, including elastic net-regularized objectives, we obtain the following faster geometric convergence rate.\nTheorem 2. Consider Algorithm 1 with \u03b3 := 1, and let \u0398 be the quality of the local solver as in Assumption 1. Let gi be \u00b5-strongly convex \u2200i \u2208 [n], and f be (1/\u03c4)-smooth. Then we have that T iterations are sufficient for suboptimality D, with\nT \u2265 1\u03b3(1\u2212\u0398) \u00b5\u03c4+n \u00b5\u03c4 log n D . (9)\nFurthermore, after T iterations with\nT \u2265 1\u03b3(1\u2212\u0398) \u00b5\u03c4+n \u00b5\u03c4 log\n( 1\n\u03b3(1\u2212\u0398) \u00b5\u03c4+n \u00b5\u03c4 n G\n) ,\nE[P(w(\u03b1(T )))\u2212 (\u2212D(\u03b1(T )))] \u2264 G .\nWe provide proofs of both Theorem 1 and Theorem 2 in the appendix (Section E)."}, {"heading": "5 Related Work", "text": "Single-machine coordinate solvers. For strongly convex regularizers, current state-of-the-art for empirical loss minimization is randomized coordinate ascent on the dual (SDCA) [26] and its accelerated variants, e.g., [27]. In contrast to primal stochastic gradient descent (SGD) methods, the SDCA family is often preferred as it is free of learning-rate parameters and has faster (geometric) convergence guarantees. Interestingly, a similar trend in coordinate solvers has been observed in recent Lasso literature, but with the roles of primal and dual reversed. For those problems, coordinate descent methods on the primal have become state-of-the-art, as in GLMNET [11] and extensions [34]; see, e.g., the overview in [33]. However, primal-dual convergence rates for unmodified coordinate algorithms have to our knowledge been obtained only for strongly convex regularizers to date [27, 35].\nConnection to coordinate-wise Newton methods. Coordinate descent on L1-regularized problems (A) with g(\u00b7) = \u03bb\u2016 \u00b7 \u20161 can be interpreted as the iterative minimization of a quadratic approximation of the smooth part of the objective (as in a one-dimensional Newton step), followed by a shrinkage step resulting from the L1 part. In the single-coordinate update case, this is at the core of GLMNET [11, 33], and widely used in, e.g., solvers based on the primal formulation of L1-regularized objectives [25, 34, 3, 9, 28]. When changing more than one coordinate at a time, again employing a quadratic upper bound on the smooth part, this results in a two-loop method as in GLMNET [11] for the special case of logistic regression. This idea is crucial for the distributed setting.\nParallel coordinate descent. Parallel coordinate descent for L1-regularized objectives (with and without using mini-batches) was proposed in [7] (Shotgun) and generalized in [3] , and is among the best performing solvers in the parallel setting. Our framework reduces to Shotgun as a special case when the internal solver is a single coordinate update on the subproblem (2), \u03b3 = 1, and for a suitable \u03c3\u2032. However, Shotgun is not covered by our convergence theory, since it uses a potentially un-safe upper bound \u03b2 instead of \u03c3\u2032, which isn\u2019t guaranteed to satisfy the condition (21). Other parallel coordinate descent methods on the L1-objective have recently been analyzed in [9, 28, 21], but not in the communication-efficient or distributed setting.\nDistributed solvers. The methods most closely related to our approach are distributed variants of GLMNET as in [18]. Inspired by GLMNET and [34], the work of [3, 18] introduced the idea of a block-diagonal Hessian upper approximation in the distributed L1 context. The later work of [29] specialized this approach to sparse logistic regression.\nIf hypothetically each of our quadratic subproblems G\u03c3\u2032k (\u2206\u03b1[k]) as defined in (2) were to be minimized exactly, the resulting steps could be interpreted as block-wise Newton-type steps on each coordinate block k, where the Newton-subproblem is modified to also contain the L1-regularizer [18, 34, 23]. While [18] allows a fixed accuracy for these subproblems\u2014but not arbitrary approximation quality \u0398 as in our framework\u2014the work of [29, 34, 31] assumes that the quadratic subproblems are solved exactly. Therefore, these methods are not able to freely trade off communication and computation. Also, they do not allow the re-use of arbitrary local solvers. On the theoretical side, the rate results provided by [18, 29, 34] are not explicit convergence rates but only asymptotic, as the quadratic upper bounds are not explicitly controlled for safety as with our \u03c3\u2032.\nBatch solvers. ADMM [5], proximal gradient descent, and quasi-Newton methods such as L-BFGS and are also often used in distributed environments because of their relatively low communication requirements. However, they require at least a full (distributed) batch gradient computation at each round, and therefore do not allow the gradual trade-off between communication and computation provided by PROXCOCOA+. The works of [19] and [15] have obtained encouraging results for distributed systems employing coordinate descent variants on L1-problems. The latter approach distributes both columns and rows of the data matrix and can be extended to Lasso. However it only provides asymptotic improvement per step, and no convergence rate. We include experimental comparisons with ADMM, prox-GD, and orthant-wise limited memory quasi-Newton (OWL-QN) [1], an L-BFGS variant that can handle L1 regularization [32], but which has no convergence rate.\nFinally, we note that while the provided convergence rates for PROXCOCOA+ mirror the convergence class of classical batch gradient methods in terms of the number of outer rounds, existing batch proximal gradient methods come with a weaker theory, as they do not allow general inexactness \u0398 for the local subproblem (2). In contrast, our shown convergence rates incorporate this approximation directly, and, moreover, hold for arbitrary local solvers of much cheaper cost than batch methods (where in each round, every machine has to process exactly a full pass through the local data). This\nmakes PROXCOCOA+ more flexible in the distributed setting, as it can adapt to varied communication costs on real systems. We will see in the following section that this flexibility results in significant performance gains over the competing methods."}, {"heading": "6 Experimental Results", "text": "In this section we compare PROXCOCOA+ to numerous state-of-the-art methods for large-scale L1-regularized optimization, including:\n\u2022 MB-SGD: mini-batch stochastic gradient descent with an L1-prox \u2022 PROX-GD: full proximal gradient descent \u2022 OWL-QN: orthant-wise limited quasi-Newton \u2022 ADMM: alternating direction method of multipliers \u2022 MB-CD: mini-batch parallel coordinate descent, incl. SHOTGUN\nThe first three methods are optimized and implemented in Apache Spark\u2019s MLlib (v1.5.0) [20]. We employ coordinate descent as a local solver for PROXCOCOA+, and apply PROXCOCOA+ directly to the primal formulation of Lasso and elastic net, thereby mapping the problem to (A) and solving this objective directly. A comparison with SHOTGUN is provided as an extreme case to highlight the detrimental effects of frequent communication in the distributed environment.\nWe test the performance of each method in large-scale experiments fitting Lasso and elastic net regression models to the datasets shown in Table 1. All code is written in Apache Spark and experiments are run on public cloud Amazon EC2 m3.xlarge machines with one core per machine. For MB-CD, SHOTGUN, and PROXCOCOA+ in the primal, datasets are distributed by feature, whereas for MB-SGD, PROX-GD, OWL-QN, ADMM, and COCOA+ they are distributed by datapoint.\nWe carefully tune each competing method for best performance. ADMM requires the most tuning, both in selecting the penalty parameter \u03c1 and in solving the subproblems. Solving the subproblems to completion for ADMM is prohibitively slow, and we thus use iterations of conjugate gradient and improve performance by allowing early stopping. We also use a varying penalty parameter \u03c1 \u2014 practices described in [5, Sec. 4.3, 3.4.1]. For MB-SGD, we\ntune the step size and mini-batch size parameters. For MB-CD, we scale the updates at each round by \u03b2b for mini-batch size b and \u03b2 \u2208 [1, b], and tune both parameters b and \u03b2. Further implementation details for all methods are given in the appendix (Section G).\nComparison with L1 methods. In analyzing the performance of each algorithm (Figure 1), we measure the improvement to the primal objective given in (A) (D(\u03b1)) in terms of wall-clock time in seconds. We see that both MB-SGD and MB-CD are slow to converge, and come with the additional burden of having to tune extra parameters (though MB-CD makes clear improvements over MB-SGD). As expected, naively distributing SHOTGUN [7] (single coordinate updates per machine) does not perform well, as it is tailored to shared-memory systems and requires communicating too frequently. OWL-QN performs the best of all compared methods, but is still much slower to converge than PROXCOCOA+, converging, e.g., 50\u00d7 more slowly for the webspam dataset. The optimal performance of PROXCOCOA+ is particularly evident in datasets with large numbers of features (e.g., url, kddb, webspam), which are exactly the datasets of interest for L1 regularization.\nResults are shown for regularization parameters \u03bb such that the resulting weight vector \u03b1 is sparse. However, our results are robust to varying values of \u03bb as well as to various problem settings, as we illustrate in Figure 2.\nWe note that in contrast to the compared methods, PROXCOCOA+ comes with the benefit of having only a single parameter to tune: the subproblem approximation quality, \u0398, which can be controlled via the number of local subproblem iterations, H . We further explore the effect of this parameter in Figure 3, and provide a general guideline for choosing it in practice (see Remark 1). In particular, we see that while increasing H always results in better performance in terms of rounds, smaller or larger values of H may result in better performance in terms of wall-clock time, depending on the cost of communication and computation. The flexibility to tuneH is one of the reasons for PROXCOCOA+\u2019s significant performance gains.\nComparison with COCOA+. Finally, we point out several important ways in which PROXCOCOA+ improves upon the COCOA+ framework [17]. First, COCOA+ cannot be in-\ncluded in the set of experiments in Figure 1 because it cannot be directly applied to the Lasso objective (COCOA+ only allows for strongly convex regularizers1). Second, as shown in Figure 4, the performance of COCOA+ degrades drastically when considering datasets with large numbers of features, such as the webspam dataset. One reason for this is that COCOA+ distributes data by data point, which necessitates communicating a vector of length equal to the feature size. When the feature size is large, this can become expensive. The results shown hold despite the fact that we have tuned H (the number of local solver iterations) separately for both PROXCOCOA+ and COCOA+.\nBeyond communication, we also see that COCOA+ is slower to converge as the regularizer becomes less strongly convex (Figure 4a). Indeed, even when the number of features is relatively low such as for the epsilon dataset, we see that the performance of COCOA+ degrades significantly as the regularizer approaches pure L1. In Figure 4, we illustrate this by implementing the Nesterov smoothing technique used in, e.g., [27, 35] \u2014 adding a small amount of strong convexity \u03b4\u2016\u03b1\u201622 to the objective for Lasso regression. We show results for decreasing levels of \u03b4. As \u03b4 decreases, the final sparsity of the problem starts to match that of running pure L1 (Figure 4c), but the performance also degrades (Figure 4b). We note again that through the modification presented in Section 4, we can deliver strong rates without having to make these fundamental alterations to the problem of interest.\n1COCOA+ in [17] is in fact limited to the case where the regularizer is equal to the L2 norm 12\u2016 \u00b7 \u2016 2 2, though\nthe extension to strongly convex regularizers is covered as a special case in our analysis."}, {"heading": "Acknowledgments", "text": "We thank Michael P. Friedlander and Martin Tak\u00e1c\u030c for fruitful discussions."}, {"heading": "Appendix", "text": ""}, {"heading": "A Definitions", "text": "Definition 2 (L-Lipschitz Continuity). A function f : Rd \u2192 R is L-Lipschitz continuous if \u2200a, b \u2208 Rd, we have\n|f(a)\u2212 f(b)| \u2264 L\u2016a\u2212 b\u2016 . (10)\nDefinition\u2019 1 (L-Bounded Support). A function f : Rd \u2192 R has L-bounded support if its effective domain is bounded by L, i.e.,\nf(u) < +\u221e \u21d2 \u2016u\u2016 \u2264 L . (11)\nDefinition 3 (L-Smoothness). A function f : Rd \u2192 R is called L-smooth, for L > 0, if it is differentiable and its derivative is L-Lipschitz continuous, or equivalently\nf(u) \u2264 f(w) + \u3008\u2207f(w),u\u2212w\u3009+ L 2 \u2016u\u2212w\u20162 \u2200u,w \u2208 Rd . (12)\nDefinition 4 (\u00b5-Strong Convexity). A function f : Rd \u2192 R is called \u00b5-strongly convex, for \u00b5 \u2265 0, if f(u) \u2265 f(w) + \u3008\u2207f(w),u\u2212w\u3009+ \u00b5\n2 \u2016u\u2212w\u20162 \u2200u,w \u2208 Rd . (13)\nAnd analogously if the same holds for all subgradients, in the case of a general closed convex function f ."}, {"heading": "B Convex Conjugates", "text": "The convex conjugate of a function f : Rd \u2192 R is defined as f\u2217(v) := max\nu\u2208Rd vTu\u2212 f(u) . (14)\nBelow we list several useful properties of conjugates (see, e.g., [6, Section 3.3.2]):\n\u2022 Double conjugate: (f\u2217)\u2217 = f if f is closed and convex.\n\u2022 Value Scaling: (for \u03b1 > 0) f(v) = \u03b1g(v) \u21d2 f\u2217(w) = \u03b1g\u2217(w/\u03b1) .\n\u2022 Argument Scaling: (for \u03b1 6= 0) f(v) = g(\u03b1v) \u21d2 f\u2217(w) = g\u2217(w/\u03b1) . \u2022 Conjugate of a separable sum: f(v) = \u2211 i \u03c6i(vi) \u21d2 f\u2217(w) = \u2211 i \u03c6 \u2217 i (wi) .\nLemma 3 (Duality between Lipschitzness and L-Bounded Support, [24, Corollary 13.3.3]). Given a proper convex function f , it holds that f is L-Lipschitz if and only if f\u2217 has L-bounded support.\nLemma 4 (Duality between Smoothness and Strong Convexity, [14, Theorem 6]). Given a closed convex function f , it holds that f is \u00b5 strongly convex w.r.t. the norm \u2016 \u00b7 \u2016 if and only if f\u2217 is (1/\u00b5)-smooth w.r.t. the dual norm \u2016 \u00b7 \u2016\u2217."}, {"heading": "C Applications", "text": ""}, {"heading": "C.1 L1 and General Non-Strongly Convex Regularizers", "text": "L1 regularization is obtained in the objective (A) by letting gi(\u00b7) := \u03bb| \u00b7 |. Primal-dual convergence can be obtained by using the modification introduced in Section 4, which will guarantee L-bounded support. Formally, we replace gi(\u00b7) = | \u00b7 | by\ng\u0304(\u03b1) := { |\u03b1| : \u03b1 \u2208 [\u2212B,B] +\u221e : otherwise.\nFor large enough B, this problem yields the same solution as the original L1-objective. We provide a detailed proof and description of this technique in Section D.3. Note that this only affects convergence theory, in that it allows us to present a strong primal-dual rate (Theorem 1 for L=B)."}, {"heading": "C.2 Elastic Net and General Strongly Convex Regularizers", "text": "Another application we can consider is elastic net regularization, \u03b72 \u2016\u03b1\u2016 2 2 + (1\u2212 \u03b7) \u2016\u03b1\u20161, for fixed parameter \u03b7 \u2208 (0, 1], which is obtained by setting gi(\u03b1) := \u03bb [ \u03b7 2\u03b1 2 + (1 \u2212 \u03b7)|\u03b1| ]\nin (A). For the special case \u03b7 = 0, we obtain the L1-norm. For elastic-net-regularized problems of the form (A), Theorem 2 gives a global linear (geometric) convergence rate, since gi is \u03b7-strongly convex. This holds as long as the data-fit function is smooth (see Section C.4), and directly yields a primal-dual algorithm and corresponding rate."}, {"heading": "C.3 Local Solvers for L1 and Elastic Net", "text": "For the L1-regularizer in the primal setting, the local subproblem (2) becomes a simple quadratic problem on the local data, with regularization applied only to local variables \u03b1[k]. Therefore, existing fast L1-solvers for the single-machine case, such as GLMNET variants [11] or BLITZ [13] can be directly applied to each local subproblem G\u03c3\u2032k ( \u00b7 ;v,\u03b1[k]) within Algorithm 1. The sparsity induced on the subproblem solutions of each machine naturally translates into the sparsity of the global solution, since the local variables \u03b1[k] will be concatenated.\nIn terms of the approximation quality parameter \u0398 for the local problems (Assumption 1), we can apply existing recent convergence results from the single machine case. For example, for randomized coordinate descent (as part of GLMNET), [16, Theorem 1] gives a O(1/t) approximation quality for any separable regularizer, including L1 and elastic net; see also [28, 25]."}, {"heading": "C.4 Smooth Data-Fit Functions", "text": "To illustrate the role of f as a smooth data-fit function in this section\u2014contrasting with its role as a regularizer in traditional COCOA+ as we discuss in Section F\u2014we consider the following examples.\nLeast squares loss. Let b \u2208 Rd be labels or response values, and consider the least squares objective f(v) := 12\u2016v \u2212 b\u2016 2 2, which is 1-smooth. We obtain the familiar least-squares regression objective in our optimization problem (A), using f(A\u03b1) := 12\u2016A\u03b1\u2212 b\u2016 2 2 . Observing that the gradient of f is \u2207f(v) = v \u2212 b, the dual-to-primal mapping is given by: w(\u03b1) :=\u2207f(v(\u03b1)) = A\u03b1\u2212 b, which is well known as the residual vector in least-squares regression.\nLogistic regression loss. For classification problems, we consider a logistic regression model with d training examples yj \u2208 Rn for j \u2208 [d] collected as the rows of the data matrix A. For each training example, we are given a binary label, which we collect in the vector b \u2208 {\u22121, 1}d. Formally, the objective is defined as f(v) := \u2211d j=1 log (1 + exp (\u2212bjvj)), which is again a separable function. The classifier loss is given by f(A\u03b1) :=\nd\u2211 j=1 log (1 + exp (\u2212bjyTj \u03b1)) , (15)\nwhere \u03b1 \u2208 Rn is the parameter vector. It is not hard to show that f is 1-smooth if the labels satisfy bj \u2208 [\u22121, 1]; see e.g. Lemma 5 below. The primal-dual mapping w(\u03b1) := \u2207f(v(\u03b1)) = \u2207f(A\u03b1) is given by wj(\u03b1) =\n\u2212bj 1+exp (bjyTj \u03b1) ."}, {"heading": "D Proofs of Primal-Dual Relationship", "text": "In the following subsections we provide derivations of the primal-dual relationship of the general objectives (A) and (B), and then show how to derive this primal-dual setup for various applications."}, {"heading": "D.1 Primal-Dual Relationship", "text": "The relation of our original formulation (A) to its dual formulation (B) is standard in convex analysis, and is a special case of the concept of Fenchel Duality. Using the combination with the linear map A as in our case, the relationship is called Fenchel-Rockafellar Duality, see e.g. [4, Theorem 4.4.2] or [2, Proposition 15.18]. For completeness, we illustrate this correspondence with a self-contained derivation of the duality.\nStarting with the original formulation (A), we introduce a helper variable vector v \u2208 Rd representing v = A\u03b1. Then optimization problem (A) becomes:\nmin \u03b1\u2208Rn f(v) + g(\u03b1) such that v = A\u03b1 . (16)\nIntroducing Lagrange multipliers w \u2208 Rd, the Lagrangian is given by: L(\u03b1,v;w) := f(v) + g(\u03b1) + wT (A\u03b1\u2212 v) .\nThe dual problem of (A) follows by taking the infimum with respect to both \u03b1 and v: inf \u03b1,v L(w,\u03b1,v) = inf v\n{ f(v)\u2212wTv } + inf\n\u03b1\n{ g(\u03b1) + wTA\u03b1 } = \u2212 sup\nv\n{ wTv \u2212 f(v) } \u2212 sup\n\u03b1\n{ (\u2212wTA)\u03b1\u2212 g(\u03b1) } = \u2212f\u2217(w)\u2212 g\u2217(\u2212ATw) . (17)\nWe change signs and turn the maximization of the dual problem (17) into a minimization and thus we arrive at the dual formulation (B) as claimed:\nmin w\u2208Rd\n[ P(w) := f\u2217(w) + g\u2217(\u2212ATw) ] ."}, {"heading": "D.2 Conjugates and Smoothness of f -Functions of Interest", "text": "Lemma 5 (Conjugate and Smoothness of the Logistic Loss). The logistic classifier loss function\nf(A\u03b1) := d\u2211 j=1 log (1 + exp (\u2212bjyTj \u03b1))\n(see also (15) above) is the conjugate of f\u2217, where\nf\u2217(w) := d\u2211 j=1 ( (1 + wjbj) log (1 + wjbj)\u2212 wjbj log (\u2212wjbj) ) , (18)\nwith the box constraint \u2212wjbj \u2208 [0, 1]. Furthermore, f\u2217(w) is 1-strongly convex over its domain if the labels satisfy bj \u2208 [\u22121, 1]. Proof of Lemma 5. By separability of f\u2217, the conjugate of f\u2217(v) = \u2211 j \u03c6 \u2217 j (vj) is f(w) =\u2211\nj \u03c6j(wj). For the losses, the conjugate pairs are \u03c6j(u) = log(1 + exp(\u2212bju)), and \u03c6\u2217j (wj) = \u2212wjbj log(\u2212wjbj) + (1 + wjbj) log(1 + wjbj) with \u2212wjbj \u2208 [0, 1], see e.g. [26, Page 577]. For the strong convexity, we show 1-strong smoothness of the conjugate f(v) :=\u2211d j=1 log (1 + exp (\u2212bjvj)) = \u2211d j=1 h(bjvj), which is an equivalent property, see Lemma 4. Using the second derivative h\u2032\u2032(a) = e \u2212a\n(1+e\u2212a)2 \u2264 1 of the function h(a) = log(1 + e \u2212a), we have that \u22072f(v) = diag ( (h\u2032\u2032(bjvj)b 2 j )j ) = diag ( ( e \u2212bjvj (1+e\u2212bjvj )2 b2j )j ) \u2264 1, so f(v) is 1-smooth w.r.t. the Euclidean norm."}, {"heading": "D.3 Conjugates of Common Regularizers", "text": "Lemma 6 (Conjugate of the Elastic Net Regularizer). For \u03b7 \u2208 (0, 1], the elastic net function gi(\u03b1) := \u03b7 2\u03b1\n2 + (1\u2212 \u03b7)|\u03b1| is the convex conjugate of g\u2217i (x) := 1 2\u03b7 ([ |x| \u2212 (1\u2212 \u03b7) ] + )2 ,\nwhere [.]+ is the positive part operator, [s]+ = s for s > 0, and zero otherwise. Furthermore, this g\u2217 is smooth, i.e. has Lipschitz continuous gradient with constant 1/\u03b7.\nProof. We start by applying the definition of convex conjugate, that is:\ng\u2217(x) = max\u03b1\u2208R [ x\u03b1\u2212 \u03b7\u03b1 2 2 \u2212 (1\u2212 \u03b7)|\u03b1| ] .\nWe now distinguish two cases for the optimal: \u03b1? \u2265 0, \u03b1? < 0. For the first case we get that g\u2217(x) = max\u03b1\u2208R [ x\u03b1\u2212 \u03b7\u03b1 2 2 \u2212 (1\u2212 \u03b7)\u03b1 ] .\nSetting the derivative to 0 we get \u03b1? = x\u2212(1\u2212\u03b7)\u03b7 . To satisfy \u03b1 ? \u2265 0, we must have x \u2265 1 \u2212 \u03b7. Replacing with \u03b1? we thus get: g\u2217(x) = \u03b1?(x\u2212 12\u03b7\u03b1 ? \u2212 (1\u2212 \u03b7)) = \u03b1? ( x\u2212 12 (x\u2212 (1\u2212 \u03b7))\u2212 (1\u2212 \u03b7) ) =\n1 2\u03b1 ? (x\u2212 (1\u2212 \u03b7)) = 12\u03b7 (x\u2212 (1\u2212 \u03b7)) 2 .\nSimilarly we can show that for x \u2264 \u2212(1\u2212 \u03b7) g\u2217(x) = 12\u03b7 (x+ (1\u2212 \u03b7)) 2 . Finally, by the fact that g\u2217(.) is convex, always positive, and g\u2217(\u2212(1 \u2212 \u03b7)) = g\u2217(1 \u2212 \u03b7) = 0, it follows that g\u2217(x) = 0 for every x \u2208 [\u2212(1\u2212 \u03b7), 1\u2212 \u03b7]. For the smoothness properties, we consider the derivative of this function g\u2217(x) and see that g\u2217(x) is smooth, i.e. has Lipschitz continuous gradient with constant 1/\u03b7, assuming \u03b7 > 0.\nContinuous conjugate modification for indicator functions. To apply the theoretical convergence result from Theorem 1 to objectives with L1 norms, we modify the function | \u00b7 | by imposing an additional constraint. Consider replacing gi(\u00b7) = | \u00b7 | by\ng\u0304(\u03b1) := { |\u03b1| : \u03b1 \u2208 [\u2212B,B] +\u221e : otherwise.\nWith this modified L1-regularizer, the optimization problem (A) with regularization parameter \u03bb becomes\nmin \u03b1\u2208Rn f(A\u03b1) + \u03bb n\u2211 i=1 g\u0304(\u03b1i) . (19)\nFor large enough choice of the value B, this problems yields the same solution as the original objective:\nmin \u03b1\u2208Rn\n[ D(\u03b1) := f(A\u03b1) + \u03bb n\u2211 i=1 |\u03b1i| ] . (20)\nAs we can see, the g\u0304 is nothing more than a constrained version of the absolute value to the interval [\u2212B,B]. Therefore by setting B to a large enough value that the interesting values of \u03b1i will never reach, we can have continuous g\u0304\u2217 and at the same time make (19) equivalent to (20).\nFormally, a simple way to obtain a large enough value ofB, so that all solutions of (20) are unaffected is the following. Note that we start the algorithm at \u03b1 = 0. For every solution encountered during the execution of the algorithm, the objective values should never become worse than D(0). In other words, we restrict the D(\u00b7) optimization problem to the level set given by the initial starting value. Formally, this means that for every i, we will always require:\n\u03bb|\u03b1i| \u2264 f(0) = D(0) =\u21d2 |\u03b1i| \u2264 f(0)\n\u03bb .\n(Note that f(\u03b1) \u2265 0 holds without loss of generality). We can thus set the value of B to be f(0)\u03bb .\nLemma 7 (Conjugate of the modified L1-norm). The convex conjugate of g\u0304i as defined above is\ng\u0304\u2217(x) = { 0 : x \u2208 [\u22121, 1] B(|x| \u2212 1) : otherwise,\nand is B-Lipschitz.\nProof. We start by applying the definition of convex conjugate: g\u0304(\u03b1) = sup\nx\u2208R [\u03b1x\u2212 g\u0304\u2217(x)] .\nWe begin by looking at the case in which \u03b1 \u2265 B; in this case it\u2019s easy to see that when x\u2192 +\u221e, we have:\n\u03b1x\u2212B(|x| \u2212 1) = (\u03b1\u2212B)x\u2212B \u2192 +\u221e as \u03b1\u2212B \u2265 0. The case \u03b1 \u2264 \u2212B holds analogously. We\u2019ll now look at the case \u03b1 \u2208 [0, B]; in this case it is clear we must have x? \u2265 0. It also must hold that x? \u2264 1, since\n\u03b1x\u2212B(x\u2212 1) < \u03b1x for every x > 1. Therefore the maximization becomes\ng\u0304(\u03b1) = sup x\u2208[0,1] \u03b1x ,\nwhich has maximum \u03b1 at x = 1. The remaining \u03b1 \u2208 [\u2212B, 0] case follows in similar fashion."}, {"heading": "E Convergence Proofs", "text": "In this section we provide proofs of our main convergence results. The results are motivated by [17], but where we have significantly generalized the problem of interest, and where we derive separate meaning by applying the problem directly to (A). We provide full details of Lemma 8 as a proof of concept, but omit details in later proofs that can be derived using the arguments in [17] or earlier work of [26], and instead outline the proof strategy and highlight sections where the theory deviates."}, {"heading": "E.1 Approximation of D(\u00b7) by the Local Subproblems G\u03c3\u2032k (\u00b7)", "text": "We begin with a definition of the data-dependent aggregation parameter for PROXCOCOA+, \u03c3\u2032, which we will use in the throughout our convergence results. Definition 5 (Data-dependent aggregation parameter). In Algorithm 1, the aggregation parameter \u03b3 controls the level of adding (\u03b3 := 1) versus averaging (\u03b3 := 1K ) of the partial solutions from all machines. For the convergence results discussed below to hold, the subproblem parameter \u03c3\u2032 must be chosen not smaller than\n\u03c3\u2032 \u2265 \u03c3\u2032min := \u03b3 max \u03b1\u2208Rn \u2016A\u03b1\u20162\u2211K k=1 \u2016A\u03b1[k]\u20162 . (21)\nThe simple choice of \u03c3\u2032 := \u03b3K is valid for (21), i.e., \u03b3K \u2265 \u03c3\u2032min . In some cases, it will be possible to give better (data-dependent) choices for \u03c3\u2032, closer to the actual bound given in \u03c3\u2032min.\nOur first lemma in the overall proof of convergence helps to relate change in local subproblems to the global objective D(\u00b7). Lemma 8. For any dual \u03b1,\u2206\u03b1 \u2208 Rn, v = v(\u03b1) := A\u03b1, and real values \u03b3, \u03c3\u2032 satisfying (21), it holds that\nD ( \u03b1 + \u03b3 K\u2211 k=1 \u2206\u03b1[k] ) \u2264 (1\u2212 \u03b3)D(\u03b1) + \u03b3 K\u2211 k=1 G\u03c3 \u2032 k (\u2206\u03b1[k];v,\u03b1[k]) . (22)\nProof. In this proof we follow the line of reasoning in [17, Lemma 4] with a more general (1/\u03c4) smoothness assumption on f(\u00b7). An outer iteration of PROXCOCOA+ performs the following update:\nD(\u03b1 + \u03b3 K\u2211 k=1 \u2206\u03b1[k]) = f(v(\u03b1 + \u03b3 K\u2211 k=1\n\u2206\u03b1[k]))\ufe38 \ufe37\ufe37 \ufe38 A +\nn\u2211 i=1 gi(\u03b1i + \u03b3( K\u2211 k=1\n\u2206\u03b1[k])i)\ufe38 \ufe37\ufe37 \ufe38 B . (23)\nWe bound the terms A and B separately. First we bound A using (1/\u03c4)-smoothness of f : A = f ( v(\u03b1 + \u03b3 K\u2211 k=1 \u2206\u03b1[k]) ) = f ( v(\u03b1) + \u03b3 K\u2211 k=1 v(\u2206\u03b1[k]) )\nsmoothness of f as in (12) \u2264 f(v(\u03b1)) + K\u2211 k=1 \u03b3\u2207f(v(\u03b1))Tv(\u2206\u03b1[k]) + \u03b32 2\u03c4 \u2016 K\u2211 k=1 v(\u03b1[k])\u20162\ndefinition of w as in (5) \u2264 f(v(\u03b1)) + K\u2211 k=1 \u03b3v(\u2206\u03b1[k]) Tw(\u03b1) + \u03b32 2\u03c4 \u2016 K\u2211 k=1 v(\u03b1[k])\u20162\nsafe choice of \u03c3\u2032 as in (21) \u2264 f(v(\u03b1)) + K\u2211 k=1 \u03b3v(\u2206\u03b1[k]) Tw(\u03b1) + 1 2\u03c4 \u03b3\u03c3\u2032 K\u2211 k=1 \u2016v(\u03b1[k])\u20162 .\nNext we use Jensen\u2019s inequality to bound B:\nB = K\u2211 k=1 (\u2211 i\u2208Pk gi(\u03b1i + \u03b3(\u2206\u03b1[k])i) ) = K\u2211 k=1 (\u2211 i\u2208Pk gi((1\u2212 \u03b3)\u03b1i + \u03b3(\u03b1 + \u2206\u03b1[k])i) )\n\u2264 K\u2211 k=1 (\u2211 i\u2208Pk (1\u2212 \u03b3)gi(\u03b1i) + \u03b3gi(\u03b1i + \u2206\u03b1[k]i) ) .\nPlugging A and B back into (23) yields: D ( \u03b1 + \u03b3 K\u2211 k=1 \u2206\u03b1[k] ) \u2264 f(v(\u03b1))\u00b1 \u03b3f(v(\u03b1)) + K\u2211 k=1 \u03b3v(\u2206\u03b1[k]) Tw(\u03b1) + 1 2\u03c4 \u03b3\u03c3\u2032 K\u2211 k=1 \u2016v(\u03b1[k])\u20162\n+ K\u2211 k=1 \u2211 i\u2208Pk (1\u2212 \u03b3)gi(\u03b1i) + \u03b3gi(\u03b1i + \u2206\u03b1[k]i)\n= (1\u2212 \u03b3)f(v(\u03b1)) + K\u2211 k=1 (\u2211 i\u2208Pk (1\u2212 \u03b3)gi(\u03b1i) ) \ufe38 \ufe37\ufe37 \ufe38\n(1\u2212\u03b3)D(\u03b1)\n+ \u03b3 K\u2211 k=1\n( 1\nK f(v(\u03b1)) + v(\u2206\u03b1[k])\nTw(\u03b1) + \u03c3\u2032\n2\u03c4 \u2016v(\u03b1[k])\u20162 + \u2211 i\u2208Pk gi(\u03b1i + \u2206\u03b1[k]i)\n)\n(2) = (1\u2212 \u03b3)D(\u03b1) + \u03b3 K\u2211 k=1 G\u03c3 \u2032 k (\u2206\u03b1[k];v) ,\nwhere the last equality is by the definition of the subproblem objective G\u03c3\u2032k (.) as in (2)."}, {"heading": "E.2 Proof of Main Convergence Result (Theorem 1)", "text": "Before proving the main convergence results, we introduce several useful quantities, including the the following lemma, which characterizes the effect of iterations of Algorithm 1 on the duality gap for any chosen local solver of approximation quality \u0398.\nLemma 9. Let gi be strongly2 convex with convexity parameter \u00b5 \u2265 0 with respect to the norm \u2016 \u00b7 \u2016, \u2200i \u2208 [n]. Then for all iterations t of Algorithm 1 under Assumption 1, and any s \u2208 [0, 1], it holds that\nE[D(\u03b1(t))\u2212D(\u03b1(t+1))] \u2265 \u03b3(1\u2212\u0398) ( sG(\u03b1(t))\u2212 \u03c3 \u2032s2\n2\u03c4 R(t)\n) , (24)\nwhere R(t) := \u2212 \u03c4\u00b5(1\u2212s)\u03c3\u2032s \u2016u (t) \u2212\u03b1(t)\u20162 + \u2211K k=1\u2016A(u(t) \u2212\u03b1(t))[k]\u20162 , (25) for u(t) \u2208 Rn with u\n(t) i \u2208 \u2202g \u2217 i (\u2212xTi w(\u03b1(t))) . (26)\nProof. The line of proof is motivated by [26, Lemma 19] and follows [17, Lemma 5], with a main addition being the extension to our generalized subproblems G\u03c3\u2032k (\u00b7;v,\u03b1[k]) along with the general mappings w(\u03b1) := \u2207f(v(\u03b1)) with v(\u03b1) := A\u03b1.\nFor simplicity, we write \u03b1 instead of \u03b1(t), v instead of v(\u03b1(t)), w instead of w(\u03b1(t)) and u instead of u(t). We can estimate the expected change of the objective D(\u03b1) as follows. Starting from the definition of the update \u03b1(t+1) := \u03b1(t) + \u03b3 \u2211 k \u2206\u03b1[k] from Algorithm 1, we apply Lemma 8, which relates the local approximation G\u03c3\u2032k (\u03b1;v,\u03b1[k]) to the global objective D(\u03b1), and then bound this\n2Note that the case of weakly convex gi(.) is explicitly allowed here as well, as the Lemma holds for the case \u00b5 = 0.\nusing the notion of quality of the local solver (\u0398), as in Assumption 1. This gives us:\nE [ D(\u03b1(t))\u2212D(\u03b1(t+1)) ] = E [ D(\u03b1)\u2212D ( \u03b1 + \u03b3 K\u2211 k=1 \u2206\u03b1[k] )]\n\u2265 \u03b3(1\u2212\u0398) D(\u03b1)\u2212 K\u2211 k=1 G\u03c3 \u2032\nk (\u2206\u03b1 ? [k];v,\u03b1[k])\ufe38 \ufe37\ufe37 \ufe38\nC  . (27) We next upper bound the C term, denoting \u2206\u03b1? = \u2211K k=1 \u2206\u03b1 ? [k]. We first plug in the definition of the objective D in (A) and the local subproblems (2), and then substitute s(ui \u2212 \u03b1i) for \u2206\u03b1?i and apply the \u00b5-strong convexity of the gi terms. This gives us:\nC = n\u2211 i=1 (gi(\u03b1i)\u2212 gi(\u03b1i + \u2206\u03b1?i ))\u2212 (A\u2206\u03b1?)Tw(\u03b1)\u2212 K\u2211 k=1 \u03c3\u2032 2\u03c4 \u2225\u2225\u2225A\u2206\u03b1?[k]\u2225\u2225\u22252 \u2265\nn\u2211 i=1 ( sgi(\u03b1i)\u2212 sgi(ui) + \u00b5 2 (1\u2212 s)s(ui \u2212 \u03b1i)2 ) \u2212A(s(u\u2212\u03b1))Tw(\u03b1)\u2212\nK\u2211 k=1 \u03c3\u2032 2\u03c4 \u2225\u2225\u2225A(s(u\u2212\u03b1)[k])\u2225\u2225\u22252 . (28) From the definition of the primal and dual optimization problems (A) and (B), and definition of convex conjugates, we can write the duality gap as:\nG(\u03b1) := P(w(\u03b1))\u2212 (\u2212D(\u03b1)) (A),(B)= n\u2211 i=1 ( g\u2217i (\u2212xTi w(\u03b1)) + gi(\u03b1i) ) + f\u2217(w(\u03b1)) + f(A\u03b1))\n= n\u2211 i=1 ( g\u2217i (\u2212xTi w(\u03b1)) + gi(\u03b1i) ) + f\u2217(\u2207f(A\u03b1)) + f(A\u03b1)\n= n\u2211 i=1 ( g\u2217i (\u2212xTi w(\u03b1)) + gi(\u03b1i) ) + (A\u03b1)Tw(\u03b1)\n= n\u2211 i=1 ( g\u2217i (\u2212xTi w(\u03b1)) + gi(\u03b1i) + \u03b1ixTi w(\u03b1) ) . (29)\nThe convex conjugate maximal property from (26) implies that gi(ui) = ui(\u2212xTi w(\u03b1))\u2212 g\u2217i (\u2212xTi w(\u03b1)) . (30)\nUsing (30) and (29), we therefore have:\nC (30) \u2265 n\u2211 i=1 ( sgi(\u03b1i)\u2212 sui(\u2212xTi w(\u03b1)) + sg\u2217i (\u2212xTi w(\u03b1)) + \u00b5 2 (1\u2212 s)s(ui \u2212 \u03b1i)2 ) \u2212A(s(u\u2212\u03b1))Tw(\u03b1)\u2212\nK\u2211 k=1 \u03c3\u2032 2\u03c4 \u2225\u2225\u2225A(s(u\u2212\u03b1)[k])\u2225\u2225\u22252 =\nn\u2211 i=1 [ sgi(\u03b1i) + sg \u2217 i (\u2212xTi w(\u03b1)) + sxTi w(\u03b1)\u03b1i ] \u2212 n\u2211 i=1 [ sxTi w(\u03b1)(\u03b1i \u2212 ui)\u2212 \u00b5 2 (1\u2212 s)s(ui \u2212 \u03b1i)2 ] \u2212A(s(u\u2212\u03b1))Tw(\u03b1)\u2212\nK\u2211 k=1 \u03c3\u2032 2\u03c4 \u2225\u2225\u2225A(s(u\u2212\u03b1)[k])\u2225\u2225\u22252 (29) = sG(\u03b1) + \u00b5\n2 (1\u2212 s)s\u2016u\u2212\u03b1\u20162 \u2212 \u03c3\n\u2032s2\n2\u03c4 K\u2211 k=1 \u2016A(u\u2212\u03b1)[k]\u20162 . (31)\nThe claimed improvement bound (24) then follows by plugging (31) into (27).\nThe following Lemma provides a uniform bound on R(t):\nLemma 10. If g\u2217i are L-Lipschitz continuous for all i \u2208 [n], then\n\u2200t : R(t) \u2264 4L2 K\u2211 k=1\n\u03c3knk\ufe38 \ufe37\ufe37 \ufe38 =:\u03c3 , (32)\nwhere\n\u03c3k := max \u03b1[k]\u2208Rn\n\u2016A\u03b1[k]\u20162\n\u2016\u03b1[k]\u20162 . (33)\nProof. [17, Lemma 6]. For general convex functions, the strong convexity parameter is \u00b5 = 0, and hence the definition (25) of the complexity constant R(t) becomes\nR(t) = K\u2211 k=1 \u2016A(u(t) \u2212\u03b1(t))[k]\u20162 (33) \u2264 K\u2211 k=1 \u03c3k\u2016(u(t) \u2212\u03b1(t))[k]\u20162 \u2264 K\u2211 k=1 \u03c3k|Pk|4L2 .\nHere the last inequality follows from in [26, Lemma 21], which shows that for g\u2217i : R \u2192 R being L-Lipschitz, it holds that for any real value a with |a| > L one has that gi(a) = +\u221e.\nRemark 2. [17, Remark 7] If all data points xi are normalized such that \u2016xi\u2016 \u2264 1 \u2200i \u2208 [n], then \u03c3k \u2264 |Pk| = nk. Furthermore, if we assume that the data partition is balanced, i.e., that nk = n/K for all k, then \u03c3 \u2264 n2/K. This can be used to bound the constants R(t), above, as R(t) \u2264 4L 2n2\nK .\nTheorem 11. Consider Algorithm 1, using a local solver of quality \u0398 (See Assumption 1). Let g\u2217i (\u00b7) be L-Lipschitz continuous, and G > 0 be the desired duality gap (and hence an upper-bound on suboptimality D). Then after T iterations, where\nT \u2265 T0 + max{ \u2308 1 \u03b3(1\u2212\u0398) \u2309 , 4L2\u03c3\u03c3\u2032 \u03c4 G\u03b3(1\u2212\u0398) } , (34)\nT0 \u2265 t0 + [ 2 \u03b3(1\u2212\u0398) ( 8L2\u03c3\u03c3\u2032 \u03c4 G \u2212 1 )] + , t0 \u2265 max(0, \u2308 1 \u03b3(1\u2212\u0398) log ( \u03c4(D(\u03b1(0))\u2212D(\u03b1?)) 2L2\u03c3\u03c3\u2032 )\u2309 ) ,\nwe have that the expected duality gap satisfies E[P(w(\u03b1))\u2212 (\u2212D(\u03b1))] \u2264 G\nat the averaged iterate \u03b1 := 1T\u2212T0 \u2211T\u22121 t=T0+1 \u03b1(t) . (35)\nProof. This proof draws from the line of reasoning in [26, Theorem 2] and follows [17, Theorem 8] but for the more general problem setting (A). We begin by estimating the expected change of feasibility for D. We can bound this above by using Lemma 9 and the fact that the P(\u00b7) is always a lower bound for \u2212D(\u00b7), and then applying (32) to find:\nE[D(\u03b1(t+1))\u2212D(\u03b1?)] \u2264 (1\u2212 \u03b3(1\u2212\u0398)s) (D(\u03b1(t))\u2212D(\u03b1?)) + \u03b3(1\u2212\u0398)\u03c3 \u2032s2\n2\u03c4 4L 2\u03c3 . (36)\nUsing (36) recursively we have\nE[D(\u03b1(t))\u2212D(\u03b1?)] \u2264 (1\u2212 \u03b3(1\u2212\u0398)s)t (D(\u03b1(0))\u2212D(\u03b1?)) + s4L 2\u03c3\u03c3\u2032\n2\u03c4 . (37)\nChoosing s = 1 and t = t0 := max{0, d 1\u03b3(1\u2212\u0398) log(2(D(\u03b1 (0))\u2212D(\u03b1?))/(4L2\u03c3\u03c3\u2032))e} will lead to\nE[D(\u03b1(t))\u2212D(\u03b1?)] \u2264 (1\u2212 \u03b3(1\u2212\u0398))t0 (D(\u03b1(0))\u2212D(\u03b1?)) + 4L 2\u03c3\u03c3\u2032\n2\u03c4 \u2264 4L\n2\u03c3\u03c3\u2032 \u03c4 . (38)\nNext, we show inductively that\n\u2200t \u2265 t0 : E[D(\u03b1(t))\u2212D(\u03b1?)] \u2264 4L2\u03c3\u03c3\u2032\n\u03c4(1 + 12\u03b3(1\u2212\u0398)(t\u2212 t0)) . (39)\nClearly, (38) implies that (39) holds for t = t0. Assuming that it holds for any t \u2265 t0, we show that it must also hold for t+ 1. Indeed, using\ns = 1\n1 + 12\u03b3(1\u2212\u0398)(t\u2212 t0) \u2208 [0, 1] , (40)\nwe obtain\nE[D(\u03b1(t+1))\u2212D(\u03b1?)] \u2264 4L 2\u03c3\u03c3\u2032\n\u03c4\n( 1 + 12\u03b3(1\u2212\u0398)(t\u2212 t0)\u2212 1 2\u03b3(1\u2212\u0398)\n(1 + 12\u03b3(1\u2212\u0398)(t\u2212 t0))2 ) \ufe38 \ufe37\ufe37 \ufe38\nD\nby applying the bounds (36) and (39), plugging in the definition of s (40), and simplifying. We upperbound the term D using the fact that geometric mean is less or equal to arithmetic mean:\nD = 1 1 + 12\u03b3(1\u2212\u0398)(t+ 1\u2212 t0) (1 + 12\u03b3(1\u2212\u0398)(t+ 1\u2212 t0))(1 + 1 2\u03b3(1\u2212\u0398)(t\u2212 1\u2212 t0))\n(1 + 12\u03b3(1\u2212\u0398)(t\u2212 t0))2\ufe38 \ufe37\ufe37 \ufe38 \u22641\n\u2264 1 1 + 12\u03b3(1\u2212\u0398)(t+ 1\u2212 t0) ,\nIf \u03b1 is defined as (35), we apply the results of Lemma 9 and Lemma 10 to obtain\nE[G(\u03b1)] = E [ G ( T\u22121\u2211 t=T0 1 T\u2212T0\u03b1 (t) )] \u2264 1T\u2212T0E [ T\u22121\u2211 t=T0 G ( \u03b1(t) )]\n\u2264 1 \u03b3(1\u2212\u0398)s 1 T \u2212 T0 E [ D(\u03b1(T0))\u2212D(\u03b1?) ] + 4L 2\u03c3\u03c3\u2032s 2\u03c4 . (41)\nIf T \u2265 d 1\u03b3(1\u2212\u0398)e+ T0 such that T0 \u2265 t0 we have\nE[G(\u03b1)] (41),(39) \u2264 1 \u03b3(1\u2212\u0398)s 1 T \u2212 T0\n( 4L2\u03c3\u03c3\u2032\n\u03c4(1 + 12\u03b3(1\u2212\u0398)(T0 \u2212 t0))\n) + 4L2\u03c3\u03c3\u2032s\n2\u03c4\n= 4L2\u03c3\u03c3\u2032\n\u03c4\n( 1\n\u03b3(1\u2212\u0398)s 1 T \u2212 T0 1 1 + 12\u03b3(1\u2212\u0398)(T0 \u2212 t0) + s 2\n) . (42)\nChoosing\ns = 1\n(T \u2212 T0)\u03b3(1\u2212\u0398) \u2208 [0, 1] (43)\ngives us\nE[G(\u03b1)] (42),(43) \u2264 4L\n2\u03c3\u03c3\u2032\n\u03c4\n( 1\n1 + 12\u03b3(1\u2212\u0398)(T0 \u2212 t0) +\n1 (T \u2212 T0)\u03b3(1\u2212\u0398) 1 2\n) . (44)\nTo have right hand side of (44) smaller then G it is sufficient to choose T0 and T such that 4L2\u03c3\u03c3\u2032\n\u03c4\n( 1\n1 + 12\u03b3(1\u2212\u0398)(T0 \u2212 t0)\n) \u2264 1\n2 G , (45)\n4L2\u03c3\u03c3\u2032\n\u03c4\n( 1\n(T \u2212 T0)\u03b3(1\u2212\u0398) 1 2\n) \u2264 1\n2 G . (46)\nHence if\nt0 + 2\n\u03b3(1\u2212\u0398)\n( 8L2\u03c3\u03c3\u2032 \u03c4 G \u2212 1 ) \u2264 T0 , and\nT0 + 4L2\u03c3\u03c3\u2032\n\u03c4 G\u03b3(1\u2212\u0398) \u2264 T ,\nthen (45) and (46) are satisfied.\nThe following main theorem simplifies the results of Theorem 11 and is a generalization of [17, Corollary 9] for general f\u2217(\u00b7) functions: Theorem\u2019 1. Consider Algorithm 1 with \u03b3 := 1, using a local solver of quality \u0398 (see Assumption 1). Let g\u2217i (\u00b7) be L-Lipschitz continuous, and assume that the columns of A satisfy \u2016xi\u2016 \u2264 1 \u2200i \u2208 [n]. Let G > 0 be the desired duality gap (and hence an upper-bound on primal sub-optimality). Then\nafter T iterations, where T \u2265 T0 + max{ \u2308 1\n1\u2212\u0398\n\u2309 , 4L2n2\n\u03c4 G(1\u2212\u0398) } , (47)\nT0 \u2265 t0 + [ 2\n1\u2212\u0398\n( 8L2n2 \u03c4 G \u2212 1 )] + ,\nt0 \u2265 max(0, \u2308 1 (1\u2212\u0398) log ( \u03c4(D(\u03b1(0))\u2212D(\u03b1?)) 2L2Kn )\u2309 ) ,\nwe have that the expected duality gap satisfies E[P(w(\u03b1))\u2212 (\u2212D(\u03b1))] \u2264 G\n(where \u03b1 is the averaged iterate returned by Algorithm 1).\nProof. Plug in parameters \u03b3 := 1, \u03c3\u2032 := \u03b3K = K to the results of Theorem 11, and note that for balanced datasets we have \u03c3 \u2264 n 2\nK (see Remark 2). We can further simplify the rate by noting that \u03c4 = 1 for the 1-smooth losses (least squares and logistic) given as examples in this work.\nRemark 3. For pure L1-regularized problems as discussed in Section C.1, we have that the above theorem directly delivers a primal-dual convergence with a sublinear rate. This is because in view of Lemma 7, we know that g\u2217i is B-Lipschitz for the bounded support modification introduced in Section 4."}, {"heading": "E.3 Proof of Convergence Result for Strongly Convex gi", "text": "Our second main theorem follows reasoning in [26] and is a generalization of [17, Corollary 11]. We first introduce a lemma to simplify the proof.\nLemma 12. Assume that gi(0) \u2208 [0, 1] for all i \u2208 [n], then for the zero vector \u03b1(0) := 0 \u2208 Rn, we have\nD(\u03b1(0))\u2212D(\u03b1?) = D(0)\u2212D(\u03b1?) \u2264 n . (48)\nProof. For \u03b1 := 0 \u2208 Rn, we have w(\u03b1) = A\u03b1 = 0 \u2208 Rd. Therefore, since the dual \u2212D(\u00b7) is always a lower bound on the primal P(\u00b7), and by definition of the objective D given in (A),\n0 \u2264 D(\u03b1)\u2212D(\u03b1?) \u2264 P(w(\u03b1))\u2212 (\u2212D(\u03b1)) (A) \u2264 n .\nTheorem 13. Assume that gi are \u00b5-strongly convex \u2200i \u2208 [n]. We define \u03c3max = maxk\u2208[K] \u03c3k. Then after T iterations of Algorithm 1, with\nT \u2265 1\u03b3(1\u2212\u0398) \u00b5\u03c4+\u03c3max\u03c3\n\u2032\n\u00b5\u03c4 log n D ,\nit holds that E[D(\u03b1(T ))\u2212D(\u03b1?)] \u2264 D .\nFurthermore, after T iterations with\nT \u2265 1\u03b3(1\u2212\u0398) \u00b5\u03c4+\u03c3max\u03c3\n\u2032 \u00b5\u03c4 log ( 1 \u03b3(1\u2212\u0398) \u00b5\u03c4+\u03c3max\u03c3 \u2032 \u00b5\u03c4 n G ) ,\nwe have the expected duality gap E[P(w(\u03b1(T )))\u2212 (\u2212D(\u03b1(T )))] \u2264 G .\nProof. Given that gi(.) is \u00b5-strongly convex with respect to the \u2016 \u00b7 \u2016 norm, we can apply (25) and the definition of \u03c3k to find:\nR(t) \u2264 \u2212 \u03c4\u00b5(1\u2212s)\u03c3\u2032s \u2016u (t) \u2212\u03b1(t)\u20162 + \u2211K k=1 \u03c3k\u2016u(t) \u2212\u03b1(t)[k]\u2016 2\n\u2264 ( \u2212 \u03c4\u00b5(1\u2212s)\u03c3\u2032s + \u03c3max ) \u2016u(t) \u2212\u03b1(t)\u20162 , (49)\nwhere \u03c3max = maxk\u2208[K] \u03c3k. If we plug the following value of s\ns = \u03c4\u00b5\n\u03c4\u00b5+ \u03c3max\u03c3\u2032 \u2208 [0, 1] (50)\ninto (49) we obtain that \u2200t : R(t) \u2264 0. Putting the same s into (24) will give us\nE[D(\u03b1(t))\u2212D(\u03b1(t+1))] (24),(50) \u2265 \u03b3(1\u2212\u0398) \u03c4\u00b5 \u03c4\u00b5+ \u03c3max\u03c3\u2032 G(\u03b1(t)) \u2265 \u03b3(1\u2212\u0398) \u03c4\u00b5 \u03c4\u00b5+ \u03c3max\u03c3\u2032 (D(\u03b1(t))\u2212D(\u03b1?)) .\n(51)\nUsing the fact that E[D(\u03b1(t))\u2212D(\u03b1(t+1))] = E[D(\u03b1?)\u2212D(\u03b1(t+1))] +D(\u03b1(t))\u2212D(\u03b1?) we have\nE[D(\u03b1?)\u2212D(\u03b1(t+1))] +D(\u03b1(t))\u2212D(\u03b1?) (51) \u2265 \u03b3(1\u2212\u0398) \u03c4\u00b5\n\u03c4\u00b5+ \u03c3max\u03c3\u2032 (D(\u03b1(t))\u2212D(\u03b1?)) ,\nwhich is equivalent to E[D(\u03b1(t+1))\u2212D(\u03b1?)] \u2264 (\n1\u2212 \u03b3(1\u2212\u0398) \u03c4\u00b5 \u03c4\u00b5+ \u03c3max\u03c3\u2032\n) (D(\u03b1(t))\u2212D(\u03b1?)) . (52)\nTherefore if we denote (t)D = D(\u03b1(t))\u2212D(\u03b1?) we have recursively that E[ (t)D ] (52) \u2264 (\n1\u2212 \u03b3(1\u2212\u0398) \u03c4\u00b5 \u03c4\u00b5+ \u03c3max\u03c3\u2032\n)t (0) D (48) \u2264 (\n1\u2212 \u03b3(1\u2212\u0398) \u03c4\u00b5 \u03c4\u00b5+ \u03c3max\u03c3\u2032\n)t n\n\u2264 exp ( \u2212t\u03b3(1\u2212\u0398) \u03c4\u00b5\n\u03c4\u00b5+ \u03c3max\u03c3\u2032\n) n .\nThe right hand side will be smaller than some D if\nt \u2265 1 \u03b3(1\u2212\u0398)\n\u03c4\u00b5+ \u03c3max\u03c3 \u2032\n\u03c4\u00b5 log\nn D .\nMoreover, to bound the duality gap, we have\n\u03b3(1\u2212\u0398) \u03c4\u00b5 \u03c4\u00b5+ \u03c3max\u03c3\u2032 G(\u03b1(t)) (51) \u2264 E[D(\u03b1(t))\u2212D(\u03b1(t+1))] \u2264 E[D(\u03b1(t))\u2212D(\u03b1?)] .\nThus, G(\u03b1(t)) \u2264 1\u03b3(1\u2212\u0398) \u03c4\u00b5+\u03c3max\u03c3\n\u2032\n\u03c4\u00b5 (t) D . Hence if D \u2264 \u03b3(1\u2212\u0398) \u03c4\u00b5 \u03c4\u00b5+\u03c3max\u03c3\u2032 G then G(\u03b1(t)) \u2264 G. Therefore after\nt \u2265 1 \u03b3(1\u2212\u0398)\n\u03c4\u00b5+ \u03c3max\u03c3 \u2032\n\u03c4\u00b5 log\n( 1\n\u03b3(1\u2212\u0398) \u03c4\u00b5+ \u03c3max\u03c3\n\u2032\n\u03c4\u00b5\nn\nG ) iterations we have obtained a duality gap less than G.\nTheorem\u2019 2. Consider Algorithm 1 with \u03b3 := 1, using a local solver of quality \u0398 (See Assumption 1). Let gi(\u00b7) be \u00b5-strongly convex \u2200i \u2208 [n], and assume that the columns of A satisfy \u2016xi\u2016 \u2264 1 \u2200i \u2208 [n]. Then we have that T iterations are sufficient for suboptimality D, with\nT \u2265 1\u03b3(1\u2212\u0398) \u03c4\u00b5+n \u03c4\u00b5 log n D .\nFurthermore, after T iterations with\nT \u2265 1\u03b3(1\u2212\u0398) \u03c4\u00b5+n \u03c4\u00b5 log\n( 1\n\u03b3(1\u2212\u0398) \u03c4\u00b5+n \u03c4\u00b5 n G\n) ,\nwe have the expected duality gap E[P(w(\u03b1(T )))\u2212D(\u03b1(T ))] \u2264 G .\nProof. Plug in parameters \u03b3 := 1, \u03c3\u2032 := \u03b3K = K to the results of Theorem 13 and note that for balanced datasets we have \u03c3max \u2264 nK (see Remark 2). We can further simplify the rate by noting that \u03c4 = 1 for the 1-smooth losses (least squares and logistic) given as examples in this work.\nRemark 4. For elastic net regularized problems as discussed in Section C.2, we have that the above theorem directly delivers a primal-dual convergence with a geometric rate. This is because in view of Lemma 6, we know that g\u2217i is 1/\u03b7-smooth for any elastic net parameter \u03b7 \u2208 (0, 1]."}, {"heading": "F Recovering COCOA+ as a Special Case", "text": "As a special case, PROXCOCOA+ directly applies to any L2-regularized loss-minimization problem, including those presented in [12, 17]. In this setting, the original machine-learning problem is mapped to what we here refer to as the \u201cdual\u201d problem formulation (B):\nmin w\u2208Rd\n[ P(w) := f\u2217(w) + n\u2211 i=1 g\u2217i (\u2212xTi w) ] ,\nwith f\u2217(\u00b7) = \u03bb2 \u2016 \u00b7 \u2016 2 being the regularizer, and g\u2217i taking the role of loss function, acting on a linear predictor xTi w (recall that xi is a column of the data matrix A). In other words, the PROXCOCOA + algorithm will in this case apply to (A) as the dual of the original input problem (which will be mapped to (B)), as described in [12, 17]. The following remarks show that we recover the linear (geometric) convergence rates for smooth loss functions g\u2217i , and sublinear convergence for Lipschitz losses. Note that this contrasts the discussed applications of PROXCOCOA+ where the g function has the role of the regularizer instead.\nRemark 5. If we view (B) as the primal , restrict f\u2217(\u00b7) := \u03bb2 \u2016 \u00b7\u2016 2 (so that \u03c4 = \u03bb), and let g\u2217i := 1 n` \u2217 i , Theorem 1 recovers as a special case the COCOA+ rates for general L-Lipschitz `\u2217i losses (see [17, Corollary 9]).\nThis follows since g\u2217i is L-Lipschitz if and only if gi has L-bounded support [24, Corollary 13.3.3].\nRemark 6. If we view (B) as the primal , restrict f\u2217(\u00b7) := \u03bb2 \u2016 \u00b7 \u2016 2 (so that \u03c4 = \u03bb), and scale g\u2217i := 1 n` \u2217 i , Theorem 2 recovers as a special case the COCOA\n+ rates for (1/`\u2217i )-smooth losses (see [17, Corollary 11]).\nThis follows since g\u2217i is \u00b5-strongly convex if and only if gi is (1/\u00b5)-smooth [14, Theorem 6].\nRemark 7. Note that the approach of mapping the original objective to (B) does not allow general regularizers such asL1. This is one of the reasons we have proposed swapping the roles of regularizers and losses, and running PROXCOCOA+ on the primal of the original problem instead."}, {"heading": "G Experiment Details", "text": "In this section we provide greater details on the experimental setup and implementations from Section 6. All experiments are run on Amazon EC2 clusters of m3.xlarge machines, with one core per machine. The code for each method is written in Apache Spark, v1.5.0. Our code is open-source and publicly available at: github.com/gingsmith/proxcocoa.\nADMM Alternating Direction Method of Multipliers (ADMM) [5] is a popular method that lends itself naturally to the distributed environment. Implementing ADMM for the problems of interest requires solving a large linear system Cx = d on each machine, where C \u2208 Rn\u00d7n with n scaling beyond 107 for the datasets in Table 1, and with C being possibly dense. It is prohibitively slow to solve this directly on each machine, and we therefore employ the iterative method of conjugate gradient with early stopping (see, e.g., [5, Section 4.3]). We further improve performance by using a varying rather than constant penalty parameter, as suggested in [5, Section 3.4.1].\nMini-batch SGD and Proximal GD Mini-batch SGD is a standard and widely used method for parallel and distributed optimization. We use the optimized code provided in Spark\u2019s machine learning library, MLlib, v1.5.0. We tune both the size of the mini-batch and the SGD step size using grid search. Proximal gradient descent can be seen as a specific setting of mini-batch SGD, where the mini-batch size is equal to the total number of datapoints. We thus also use the implementation in MLlib for prox-GD, and tune the step size parameter using grid search.\nMini-batch CD Mini-batch CD aims to improve mini-batch SGD by employing coordinate descent, which has encouraging theoretical and practical backings [25, 9, 28]. We implement mini-batch CD in Spark and scale the updates made at each round by \u03b2b for mini-batch size b and \u03b2 \u2208 [1, b], tuning both parameters b and \u03b2 via grid search.\nShotgun As a special case of mini-batch CD, Shotgun [7] is a popular method for parallel optimization. Shotgun can be seen an extreme case of mini-batch CD where the mini-batch is set to 1 element per machine, i.e., there is a single update made by each machine per round. We see in the experiments that communicating this frequently becomes prohibitively slow in the distributed environment.\nOWL-QN OWN-QN [32] is a quasi-Newton method optimized in Spark\u2019s spark.ml package. Outer iterations of OWL-QN make significant progress towards convergence, but the iterations themselves can be slow because they require processing the entire dataset. PROXCOCOA+, the mini-batch methods, and ADMM with early stopping all improve on this by allowing the flexibility of only a subset of the dataset to be processed at each iteration. PROXCOCOA+ and ADMM have even greater\nflexibility by allowing internal methods to process the dataset more than once. PROXCOCOA+ makes this approximation quality specific, both in theoretical convergence rates and by providing general guidelines for setting the parameter.\nPROXCOCOA+ We implement PROXCOCOA+ with coordinate descent as a local solver. We note that since the framework and theory allow any internal solver to be used, PROXCOCOA+ could benefit even beyond the results shown, by using existing fast L1-solvers for the single-machine case, such as GLMNET variants [11] or BLITZ [13]. The only parameter necessary to tune for PROXCOCOA+ is the level of approximation quality, which we parameterize in the experiments using H , the number of local iterations of the iterative method run locally. Our theory relates local approximation quality to global convergence, and we provide a guideline for how to choose this value in practice that links the value to the systems environment at hand (Remark 1). We implement COCOA+ as a special case of PROXCOCOA+ for elastic net regularized objectives by mapping the main objective to (B) according to the steps described in Section F, and again use coordinate descent as a local solver."}], "references": [{"title": "Scalable training of L1-regularized log-linear models", "author": ["G. Andrew", "J. Gao"], "venue": "In ICML,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2007}, {"title": "Convex Analysis and Monotone Operator Theory in Hilbert Spaces. CMS Books in Mathematics", "author": ["H.H. Bauschke", "P.L. Combettes"], "venue": null, "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2011}, {"title": "Parallel coordinate descent newton method for efficient g1-regularized minimization", "author": ["Y. Bian"], "venue": "arXiv.org,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2013}, {"title": "Techniques of Variational Analysis and Nonlinear Optimization. Canadian Mathematical Society Books in Math", "author": ["J.M. Borwein", "Q. Zhu"], "venue": null, "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2005}, {"title": "Distributed optimization and statistical learning via the alternating direction method of multipliers", "author": ["S. Boyd"], "venue": "Foundations and Trends in Machine Learning,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2010}, {"title": "Convex Optimization", "author": ["S. Boyd", "L. Vandenberghe"], "venue": null, "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2004}, {"title": "Parallel coordinate descent for l1-regularized loss minimization", "author": ["J.K. Bradley"], "venue": "In ICML,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2011}, {"title": "Primal-Dual Rates and Certificates", "author": ["C. D\u00fcnner"], "venue": "In ICML,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2016}, {"title": "Accelerated, Parallel, and Proximal Coordinate Descent", "author": ["O. Fercoq", "P. Richt\u00e1rik"], "venue": "SIAM Journal on Optimization,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2015}, {"title": "Distributed Optimization for Non-Strongly Convex Regularizers", "author": ["S. Forte"], "venue": "Master\u2019s thesis, ETH Zu\u0308rich,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2015}, {"title": "Regularization paths for generalized linear models via coordinate descent", "author": ["J. Friedman", "T. Hastie", "R. Tibshirani"], "venue": "Journal of Statistical Software,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2010}, {"title": "Communication-efficient distributed dual coordinate ascent", "author": ["M. Jaggi"], "venue": "In NIPS,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2014}, {"title": "Blitz: A Principled Meta-Algorithm for Scaling Sparse Optimization", "author": ["T. Johnson", "C. Guestrin"], "venue": "In ICML,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2015}, {"title": "On the duality of strong convexity and strong smoothness: Learning applications and matrix regularization", "author": ["S.M. Kakade", "S. Shalev-Shwartz", "A. Tewari"], "venue": "Technical report,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2009}, {"title": "Data/feature distributed stochastic coordinate descent for logistic regression", "author": ["Kang"], "venue": "In CIKM,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2014}, {"title": "On the complexity analysis of randomized block-coordinate descent methods", "author": ["Z. Lu", "L. Xiao"], "venue": null, "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2013}, {"title": "Adding vs. averaging in distributed primal-dual optimization", "author": ["C. Ma"], "venue": "In ICML,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2015}, {"title": "A distributed block coordinate descent method for training l1 regularized linear classifiers", "author": ["D. Mahajan", "S.S. Keerthi", "S. Sundararajan"], "venue": null, "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2014}, {"title": "Ad click prediction: a view from the trenches", "author": ["H.B. McMahan"], "venue": "In KDD,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2013}, {"title": "Mllib: Machine learning in apache spark", "author": ["X. Meng"], "venue": "arXiv.org,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2015}, {"title": "Parallel Random Coordinate Descent Method for Composite Minimization: Convergence Analysis and Error Bounds", "author": ["I. Necoara", "D. Clipici"], "venue": "SIAM Journal on Optimization,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2016}, {"title": "Smooth minimization of non-smooth functions", "author": ["Y. Nesterov"], "venue": "Mathematical Programming,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2005}, {"title": "SDNA: Stochastic dual newton ascent for empirical risk", "author": ["Z. Qu"], "venue": "minimization. arXiv.org,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2015}, {"title": "Convex Analysis", "author": ["R.T. Rockafellar"], "venue": null, "citeRegEx": "24", "shortCiteRegEx": "24", "year": 1997}, {"title": "Stochastic methods for l1-regularized loss minimization", "author": ["S. Shalev-Shwartz", "A. Tewari"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2011}, {"title": "Stochastic dual coordinate ascent methods for regularized loss minimization", "author": ["S. Shalev-Shwartz", "T. Zhang"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2013}, {"title": "Accelerated proximal stochastic dual coordinate ascent for regularized loss minimization", "author": ["S. Shalev-Shwartz", "T. Zhang"], "venue": "Mathematical Programming, Series", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2014}, {"title": "On the complexity of parallel coordinate descent", "author": ["R. Tappenden", "P. Richt\u00e1rik"], "venue": "arXiv.org,", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 2015}, {"title": "Distributed coordinate descent for l1-regularized logistic regression", "author": ["I. Trofimov", "A. Genkin"], "venue": "arXiv.org,", "citeRegEx": "29", "shortCiteRegEx": "29", "year": 2014}, {"title": "Trading computation for communication: Distributed stochastic dual coordinate ascent", "author": ["T. Yang"], "venue": "In NIPS,", "citeRegEx": "30", "shortCiteRegEx": "30", "year": 2013}, {"title": "A Dual Augmented Block Minimization Framework for Learning with Limited Memory", "author": ["I.E.-H. Yen", "S.-W. Lin", "S.-D. Lin"], "venue": "In NIPS,", "citeRegEx": "31", "shortCiteRegEx": "31", "year": 2015}, {"title": "A quasi-newton approach to nonsmooth convex optimization problems in machine learning", "author": ["J. Yu", "S. Vishwanathan", "S. G\u00fcnter", "N.N. Schraudolph"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "32", "shortCiteRegEx": "32", "year": 2010}, {"title": "A comparison of optimization methods and software for large-scale l1-regularized linear classification", "author": ["G.-X. Yuan"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "33", "shortCiteRegEx": "33", "year": 2010}, {"title": "An improved glmnet for l1-regularized logistic regression", "author": ["G.-X. Yuan", "C.-H. Ho", "C.-J. Lin"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "34", "shortCiteRegEx": "34", "year": 2012}, {"title": "Stochastic Primal-Dual Coordinate Method for Regularized Empirical Risk Minimization", "author": ["Y. Zhang", "X. Lin"], "venue": "In ICML,", "citeRegEx": "35", "shortCiteRegEx": "35", "year": 2015}], "referenceMentions": [{"referenceID": 11, "context": "One promising distributed method is COCOA+ [12, 17], a recently proposed primal-dual framework that demonstrates competitive performance, provides a flexible communication scheme, and enables the use of off-the-shelf single-machine solvers internally.", "startOffset": 43, "endOffset": 51}, {"referenceID": 16, "context": "One promising distributed method is COCOA+ [12, 17], a recently proposed primal-dual framework that demonstrates competitive performance, provides a flexible communication scheme, and enables the use of off-the-shelf single-machine solvers internally.", "startOffset": 43, "endOffset": 51}, {"referenceID": 25, "context": "However, by solving the problem in the dual, COCOA+ (like SDCA, prox-SDCA, and numerous other primal-dual methods [26, 27, 30, 35, 36]) is only equipped to handle strongly convex regularizers, which prevents it from being directly applied to L1-regularized objectives.", "startOffset": 114, "endOffset": 134}, {"referenceID": 26, "context": "However, by solving the problem in the dual, COCOA+ (like SDCA, prox-SDCA, and numerous other primal-dual methods [26, 27, 30, 35, 36]) is only equipped to handle strongly convex regularizers, which prevents it from being directly applied to L1-regularized objectives.", "startOffset": 114, "endOffset": 134}, {"referenceID": 29, "context": "However, by solving the problem in the dual, COCOA+ (like SDCA, prox-SDCA, and numerous other primal-dual methods [26, 27, 30, 35, 36]) is only equipped to handle strongly convex regularizers, which prevents it from being directly applied to L1-regularized objectives.", "startOffset": 114, "endOffset": 134}, {"referenceID": 34, "context": "However, by solving the problem in the dual, COCOA+ (like SDCA, prox-SDCA, and numerous other primal-dual methods [26, 27, 30, 35, 36]) is only equipped to handle strongly convex regularizers, which prevents it from being directly applied to L1-regularized objectives.", "startOffset": 114, "endOffset": 134}, {"referenceID": 9, "context": "\u2020Parts of this work appear in SF\u2019s Master\u2019s Thesis [10].", "startOffset": 51, "endOffset": 55}, {"referenceID": 21, "context": ", [22, 27, 35] that enforce strong convexity by adding a small L2 term to the objective.", "startOffset": 2, "endOffset": 14}, {"referenceID": 26, "context": ", [22, 27, 35] that enforce strong convexity by adding a small L2 term to the objective.", "startOffset": 2, "endOffset": 14}, {"referenceID": 34, "context": ", [22, 27, 35] that enforce strong convexity by adding a small L2 term to the objective.", "startOffset": 2, "endOffset": 14}, {"referenceID": 11, "context": "This framework builds on the recent COCOA+ framework [12, 17], though with a more general objective, a modified subproblem, and where we allow the method to be applied to either the primal or dual formulation.", "startOffset": 53, "endOffset": 61}, {"referenceID": 16, "context": "This framework builds on the recent COCOA+ framework [12, 17], though with a more general objective, a modified subproblem, and where we allow the method to be applied to either the primal or dual formulation.", "startOffset": 53, "endOffset": 61}, {"referenceID": 0, "context": "k=1 G \u2032 k (\u2206\u03b1[k];v,\u03b1[k]) = L+ f(v) +\u2207f(v)A\u2206\u03b1 + \u03c3\u2032 2\u03c4 \u2206\u03b1 \uf8ef\uf8f0A T [1]A[1] 0 .", "startOffset": 62, "endOffset": 65}, {"referenceID": 0, "context": "k=1 G \u2032 k (\u2206\u03b1[k];v,\u03b1[k]) = L+ f(v) +\u2207f(v)A\u2206\u03b1 + \u03c3\u2032 2\u03c4 \u2206\u03b1 \uf8ef\uf8f0A T [1]A[1] 0 .", "startOffset": 66, "endOffset": 69}, {"referenceID": 16, "context": "Assumption 1 (\u0398-approximate solution, see [17]).", "startOffset": 42, "endOffset": 46}, {"referenceID": 29, "context": "It is also useful as an analysis tool and helps relate this work to the prior work of [30, 12, 17].", "startOffset": 86, "endOffset": 98}, {"referenceID": 11, "context": "It is also useful as an analysis tool and helps relate this work to the prior work of [30, 12, 17].", "startOffset": 86, "endOffset": 98}, {"referenceID": 16, "context": "It is also useful as an analysis tool and helps relate this work to the prior work of [30, 12, 17].", "startOffset": 86, "endOffset": 98}, {"referenceID": 7, "context": "This \u201cLipschitzing\u201d trick will make the conjugates g\u2217 i globally defined and Lipschitz [8], as we prove in Section 4.", "startOffset": 87, "endOffset": 90}, {"referenceID": 10, "context": "Further, it allows us to directly leverage state-of-the-art coordinate-wise primal methods, such as GLMNET [11] and extensions [34, 13].", "startOffset": 107, "endOffset": 111}, {"referenceID": 33, "context": "Further, it allows us to directly leverage state-of-the-art coordinate-wise primal methods, such as GLMNET [11] and extensions [34, 13].", "startOffset": 127, "endOffset": 135}, {"referenceID": 12, "context": "Further, it allows us to directly leverage state-of-the-art coordinate-wise primal methods, such as GLMNET [11] and extensions [34, 13].", "startOffset": 127, "endOffset": 135}, {"referenceID": 21, "context": "To address this, existing approaches typically use a simple smoothing technique as in [22]: by adding a small amount of L2 to the L1-norm, it becomes strongly convex; see, e.", "startOffset": 86, "endOffset": 90}, {"referenceID": 26, "context": ", [27].", "startOffset": 2, "endOffset": 6}, {"referenceID": 7, "context": "3, and illustrate how to leverage it for a variety of applications (see Section C of the appendix and also [8]).", "startOffset": 107, "endOffset": 110}, {"referenceID": 25, "context": "For strongly convex regularizers, current state-of-the-art for empirical loss minimization is randomized coordinate ascent on the dual (SDCA) [26] and its accelerated variants, e.", "startOffset": 142, "endOffset": 146}, {"referenceID": 26, "context": ", [27].", "startOffset": 2, "endOffset": 6}, {"referenceID": 10, "context": "For those problems, coordinate descent methods on the primal have become state-of-the-art, as in GLMNET [11] and extensions [34]; see, e.", "startOffset": 104, "endOffset": 108}, {"referenceID": 33, "context": "For those problems, coordinate descent methods on the primal have become state-of-the-art, as in GLMNET [11] and extensions [34]; see, e.", "startOffset": 124, "endOffset": 128}, {"referenceID": 32, "context": ", the overview in [33].", "startOffset": 18, "endOffset": 22}, {"referenceID": 26, "context": "However, primal-dual convergence rates for unmodified coordinate algorithms have to our knowledge been obtained only for strongly convex regularizers to date [27, 35].", "startOffset": 158, "endOffset": 166}, {"referenceID": 34, "context": "However, primal-dual convergence rates for unmodified coordinate algorithms have to our knowledge been obtained only for strongly convex regularizers to date [27, 35].", "startOffset": 158, "endOffset": 166}, {"referenceID": 10, "context": "In the single-coordinate update case, this is at the core of GLMNET [11, 33], and widely used in, e.", "startOffset": 68, "endOffset": 76}, {"referenceID": 32, "context": "In the single-coordinate update case, this is at the core of GLMNET [11, 33], and widely used in, e.", "startOffset": 68, "endOffset": 76}, {"referenceID": 24, "context": ", solvers based on the primal formulation of L1-regularized objectives [25, 34, 3, 9, 28].", "startOffset": 71, "endOffset": 89}, {"referenceID": 33, "context": ", solvers based on the primal formulation of L1-regularized objectives [25, 34, 3, 9, 28].", "startOffset": 71, "endOffset": 89}, {"referenceID": 2, "context": ", solvers based on the primal formulation of L1-regularized objectives [25, 34, 3, 9, 28].", "startOffset": 71, "endOffset": 89}, {"referenceID": 8, "context": ", solvers based on the primal formulation of L1-regularized objectives [25, 34, 3, 9, 28].", "startOffset": 71, "endOffset": 89}, {"referenceID": 27, "context": ", solvers based on the primal formulation of L1-regularized objectives [25, 34, 3, 9, 28].", "startOffset": 71, "endOffset": 89}, {"referenceID": 10, "context": "When changing more than one coordinate at a time, again employing a quadratic upper bound on the smooth part, this results in a two-loop method as in GLMNET [11] for the special case of logistic regression.", "startOffset": 157, "endOffset": 161}, {"referenceID": 6, "context": "Parallel coordinate descent for L1-regularized objectives (with and without using mini-batches) was proposed in [7] (Shotgun) and generalized in [3] , and is among the best performing solvers in the parallel setting.", "startOffset": 112, "endOffset": 115}, {"referenceID": 2, "context": "Parallel coordinate descent for L1-regularized objectives (with and without using mini-batches) was proposed in [7] (Shotgun) and generalized in [3] , and is among the best performing solvers in the parallel setting.", "startOffset": 145, "endOffset": 148}, {"referenceID": 8, "context": "Other parallel coordinate descent methods on the L1-objective have recently been analyzed in [9, 28, 21], but not in the communication-efficient or distributed setting.", "startOffset": 93, "endOffset": 104}, {"referenceID": 27, "context": "Other parallel coordinate descent methods on the L1-objective have recently been analyzed in [9, 28, 21], but not in the communication-efficient or distributed setting.", "startOffset": 93, "endOffset": 104}, {"referenceID": 20, "context": "Other parallel coordinate descent methods on the L1-objective have recently been analyzed in [9, 28, 21], but not in the communication-efficient or distributed setting.", "startOffset": 93, "endOffset": 104}, {"referenceID": 17, "context": "The methods most closely related to our approach are distributed variants of GLMNET as in [18].", "startOffset": 90, "endOffset": 94}, {"referenceID": 33, "context": "Inspired by GLMNET and [34], the work of [3, 18] introduced the idea of a block-diagonal Hessian upper approximation in the distributed L1 context.", "startOffset": 23, "endOffset": 27}, {"referenceID": 2, "context": "Inspired by GLMNET and [34], the work of [3, 18] introduced the idea of a block-diagonal Hessian upper approximation in the distributed L1 context.", "startOffset": 41, "endOffset": 48}, {"referenceID": 17, "context": "Inspired by GLMNET and [34], the work of [3, 18] introduced the idea of a block-diagonal Hessian upper approximation in the distributed L1 context.", "startOffset": 41, "endOffset": 48}, {"referenceID": 28, "context": "The later work of [29] specialized this approach to sparse logistic regression.", "startOffset": 18, "endOffset": 22}, {"referenceID": 17, "context": "If hypothetically each of our quadratic subproblems G\u03c3 k (\u2206\u03b1[k]) as defined in (2) were to be minimized exactly, the resulting steps could be interpreted as block-wise Newton-type steps on each coordinate block k, where the Newton-subproblem is modified to also contain the L1-regularizer [18, 34, 23].", "startOffset": 289, "endOffset": 301}, {"referenceID": 33, "context": "If hypothetically each of our quadratic subproblems G\u03c3 k (\u2206\u03b1[k]) as defined in (2) were to be minimized exactly, the resulting steps could be interpreted as block-wise Newton-type steps on each coordinate block k, where the Newton-subproblem is modified to also contain the L1-regularizer [18, 34, 23].", "startOffset": 289, "endOffset": 301}, {"referenceID": 22, "context": "If hypothetically each of our quadratic subproblems G\u03c3 k (\u2206\u03b1[k]) as defined in (2) were to be minimized exactly, the resulting steps could be interpreted as block-wise Newton-type steps on each coordinate block k, where the Newton-subproblem is modified to also contain the L1-regularizer [18, 34, 23].", "startOffset": 289, "endOffset": 301}, {"referenceID": 17, "context": "While [18] allows a fixed accuracy for these subproblems\u2014but not arbitrary approximation quality \u0398 as in our framework\u2014the work of [29, 34, 31] assumes that the quadratic subproblems are solved exactly.", "startOffset": 6, "endOffset": 10}, {"referenceID": 28, "context": "While [18] allows a fixed accuracy for these subproblems\u2014but not arbitrary approximation quality \u0398 as in our framework\u2014the work of [29, 34, 31] assumes that the quadratic subproblems are solved exactly.", "startOffset": 131, "endOffset": 143}, {"referenceID": 33, "context": "While [18] allows a fixed accuracy for these subproblems\u2014but not arbitrary approximation quality \u0398 as in our framework\u2014the work of [29, 34, 31] assumes that the quadratic subproblems are solved exactly.", "startOffset": 131, "endOffset": 143}, {"referenceID": 30, "context": "While [18] allows a fixed accuracy for these subproblems\u2014but not arbitrary approximation quality \u0398 as in our framework\u2014the work of [29, 34, 31] assumes that the quadratic subproblems are solved exactly.", "startOffset": 131, "endOffset": 143}, {"referenceID": 17, "context": "On the theoretical side, the rate results provided by [18, 29, 34] are not explicit convergence rates but only asymptotic, as the quadratic upper bounds are not explicitly controlled for safety as with our \u03c3\u2032.", "startOffset": 54, "endOffset": 66}, {"referenceID": 28, "context": "On the theoretical side, the rate results provided by [18, 29, 34] are not explicit convergence rates but only asymptotic, as the quadratic upper bounds are not explicitly controlled for safety as with our \u03c3\u2032.", "startOffset": 54, "endOffset": 66}, {"referenceID": 33, "context": "On the theoretical side, the rate results provided by [18, 29, 34] are not explicit convergence rates but only asymptotic, as the quadratic upper bounds are not explicitly controlled for safety as with our \u03c3\u2032.", "startOffset": 54, "endOffset": 66}, {"referenceID": 4, "context": "ADMM [5], proximal gradient descent, and quasi-Newton methods such as L-BFGS and are also often used in distributed environments because of their relatively low communication requirements.", "startOffset": 5, "endOffset": 8}, {"referenceID": 18, "context": "The works of [19] and [15] have obtained encouraging results for distributed systems employing coordinate descent variants on L1-problems.", "startOffset": 13, "endOffset": 17}, {"referenceID": 14, "context": "The works of [19] and [15] have obtained encouraging results for distributed systems employing coordinate descent variants on L1-problems.", "startOffset": 22, "endOffset": 26}, {"referenceID": 0, "context": "We include experimental comparisons with ADMM, prox-GD, and orthant-wise limited memory quasi-Newton (OWL-QN) [1], an L-BFGS variant that can handle L1 regularization [32], but which has no convergence rate.", "startOffset": 110, "endOffset": 113}, {"referenceID": 31, "context": "We include experimental comparisons with ADMM, prox-GD, and orthant-wise limited memory quasi-Newton (OWL-QN) [1], an L-BFGS variant that can handle L1 regularization [32], but which has no convergence rate.", "startOffset": 167, "endOffset": 171}, {"referenceID": 19, "context": "0) [20].", "startOffset": 3, "endOffset": 7}, {"referenceID": 6, "context": "As expected, naively distributing SHOTGUN [7] (single coordinate updates per machine) does not perform well, as it is tailored to shared-memory systems and requires communicating too frequently.", "startOffset": 42, "endOffset": 45}, {"referenceID": 16, "context": "Finally, we point out several important ways in which PROXCOCOA+ improves upon the COCOA+ framework [17].", "startOffset": 100, "endOffset": 104}, {"referenceID": 26, "context": ", [27, 35] \u2014 adding a small amount of strong convexity \u03b4\u2016\u03b1\u20162 to the objective for Lasso regression.", "startOffset": 2, "endOffset": 10}, {"referenceID": 34, "context": ", [27, 35] \u2014 adding a small amount of strong convexity \u03b4\u2016\u03b1\u20162 to the objective for Lasso regression.", "startOffset": 2, "endOffset": 10}, {"referenceID": 16, "context": "1COCOA+ in [17] is in fact limited to the case where the regularizer is equal to the L2 norm 12\u2016 \u00b7 \u2016 2 2, though the extension to strongly convex regularizers is covered as a special case in our analysis.", "startOffset": 11, "endOffset": 15}, {"referenceID": 0, "context": "References [1] G.", "startOffset": 11, "endOffset": 14}, {"referenceID": 1, "context": "[2] H.", "startOffset": 0, "endOffset": 3}, {"referenceID": 2, "context": "[3] Y.", "startOffset": 0, "endOffset": 3}, {"referenceID": 3, "context": "[4] J.", "startOffset": 0, "endOffset": 3}, {"referenceID": 4, "context": "[5] S.", "startOffset": 0, "endOffset": 3}, {"referenceID": 5, "context": "[6] S.", "startOffset": 0, "endOffset": 3}, {"referenceID": 6, "context": "[7] J.", "startOffset": 0, "endOffset": 3}, {"referenceID": 7, "context": "[8] C.", "startOffset": 0, "endOffset": 3}, {"referenceID": 8, "context": "[9] O.", "startOffset": 0, "endOffset": 3}, {"referenceID": 9, "context": "[10] S.", "startOffset": 0, "endOffset": 4}, {"referenceID": 10, "context": "[11] J.", "startOffset": 0, "endOffset": 4}, {"referenceID": 11, "context": "[12] M.", "startOffset": 0, "endOffset": 4}, {"referenceID": 12, "context": "[13] T.", "startOffset": 0, "endOffset": 4}, {"referenceID": 13, "context": "[14] S.", "startOffset": 0, "endOffset": 4}, {"referenceID": 14, "context": "[15] Kang et al.", "startOffset": 0, "endOffset": 4}, {"referenceID": 15, "context": "[16] Z.", "startOffset": 0, "endOffset": 4}, {"referenceID": 16, "context": "[17] C.", "startOffset": 0, "endOffset": 4}, {"referenceID": 17, "context": "[18] D.", "startOffset": 0, "endOffset": 4}, {"referenceID": 18, "context": "[19] H.", "startOffset": 0, "endOffset": 4}, {"referenceID": 19, "context": "[20] X.", "startOffset": 0, "endOffset": 4}, {"referenceID": 20, "context": "[21] I.", "startOffset": 0, "endOffset": 4}, {"referenceID": 21, "context": "[22] Y.", "startOffset": 0, "endOffset": 4}, {"referenceID": 22, "context": "[23] Z.", "startOffset": 0, "endOffset": 4}, {"referenceID": 23, "context": "[24] R.", "startOffset": 0, "endOffset": 4}, {"referenceID": 24, "context": "[25] S.", "startOffset": 0, "endOffset": 4}, {"referenceID": 25, "context": "[26] S.", "startOffset": 0, "endOffset": 4}, {"referenceID": 26, "context": "[27] S.", "startOffset": 0, "endOffset": 4}, {"referenceID": 27, "context": "[28] R.", "startOffset": 0, "endOffset": 4}, {"referenceID": 28, "context": "[29] I.", "startOffset": 0, "endOffset": 4}, {"referenceID": 29, "context": "[30] T.", "startOffset": 0, "endOffset": 4}, {"referenceID": 30, "context": "[31] I.", "startOffset": 0, "endOffset": 4}, {"referenceID": 31, "context": "[32] J.", "startOffset": 0, "endOffset": 4}, {"referenceID": 32, "context": "[33] G.", "startOffset": 0, "endOffset": 4}, {"referenceID": 33, "context": "[34] G.", "startOffset": 0, "endOffset": 4}, {"referenceID": 34, "context": "[35] Y.", "startOffset": 0, "endOffset": 4}, {"referenceID": 10, "context": "Therefore, existing fast L1-solvers for the single-machine case, such as GLMNET variants [11] or BLITZ [13] can be directly applied to each local subproblem G\u03c3 k ( \u00b7 ;v,\u03b1[k]) within Algorithm 1.", "startOffset": 89, "endOffset": 93}, {"referenceID": 12, "context": "Therefore, existing fast L1-solvers for the single-machine case, such as GLMNET variants [11] or BLITZ [13] can be directly applied to each local subproblem G\u03c3 k ( \u00b7 ;v,\u03b1[k]) within Algorithm 1.", "startOffset": 103, "endOffset": 107}, {"referenceID": 27, "context": "For example, for randomized coordinate descent (as part of GLMNET), [16, Theorem 1] gives a O(1/t) approximation quality for any separable regularizer, including L1 and elastic net; see also [28, 25].", "startOffset": 191, "endOffset": 199}, {"referenceID": 24, "context": "For example, for randomized coordinate descent (as part of GLMNET), [16, Theorem 1] gives a O(1/t) approximation quality for any separable regularizer, including L1 and elastic net; see also [28, 25].", "startOffset": 191, "endOffset": 199}, {"referenceID": 0, "context": "with the box constraint \u2212wjbj \u2208 [0, 1].", "startOffset": 32, "endOffset": 38}, {"referenceID": 0, "context": "For the losses, the conjugate pairs are \u03c6j(u) = log(1 + exp(\u2212bju)), and \u03c6j (wj) = \u2212wjbj log(\u2212wjbj) + (1 + wjbj) log(1 + wjbj) with \u2212wjbj \u2208 [0, 1], see e.", "startOffset": 139, "endOffset": 145}, {"referenceID": 0, "context": "\u1e21(\u03b1) = sup x\u2208[0,1] \u03b1x ,", "startOffset": 13, "endOffset": 18}, {"referenceID": 16, "context": "The results are motivated by [17], but where we have significantly generalized the problem of interest, and where we derive separate meaning by applying the problem directly to (A).", "startOffset": 29, "endOffset": 33}, {"referenceID": 16, "context": "We provide full details of Lemma 8 as a proof of concept, but omit details in later proofs that can be derived using the arguments in [17] or earlier work of [26], and instead outline the proof strategy and highlight sections where the theory deviates.", "startOffset": 134, "endOffset": 138}, {"referenceID": 25, "context": "We provide full details of Lemma 8 as a proof of concept, but omit details in later proofs that can be derived using the arguments in [17] or earlier work of [26], and instead outline the proof strategy and highlight sections where the theory deviates.", "startOffset": 158, "endOffset": 162}, {"referenceID": 0, "context": "Then for all iterations t of Algorithm 1 under Assumption 1, and any s \u2208 [0, 1], it holds that E[D(\u03b1)\u2212D(\u03b1)] \u2265 \u03b3(1\u2212\u0398) ( sG(\u03b1)\u2212 \u03c3 \u2032s2 2\u03c4 R ) , (24) where R := \u2212 \u03c4\u03bc(1\u2212s) \u03c3\u2032s \u2016u (t) \u2212\u03b1\u2016 + \u2211K k=1\u2016A(u \u2212\u03b1)[k]\u2016 , (25) for u \u2208 R with u (t) i \u2208 \u2202g \u2217 i (\u2212xi w(\u03b1)) .", "startOffset": 73, "endOffset": 79}, {"referenceID": 0, "context": "s = 1 1 + 12\u03b3(1\u2212\u0398)(t\u2212 t0) \u2208 [0, 1] , (40)", "startOffset": 28, "endOffset": 34}, {"referenceID": 0, "context": "s = 1 (T \u2212 T0)\u03b3(1\u2212\u0398) \u2208 [0, 1] (43)", "startOffset": 23, "endOffset": 29}, {"referenceID": 25, "context": "Our second main theorem follows reasoning in [26] and is a generalization of [17, Corollary 11].", "startOffset": 45, "endOffset": 49}, {"referenceID": 0, "context": "Assume that gi(0) \u2208 [0, 1] for all i \u2208 [n], then for the zero vector \u03b1 := 0 \u2208 R, we have D(\u03b1)\u2212D(\u03b1) = D(0)\u2212D(\u03b1) \u2264 n .", "startOffset": 20, "endOffset": 26}, {"referenceID": 0, "context": "s = \u03c4\u03bc \u03c4\u03bc+ \u03c3max\u03c3\u2032 \u2208 [0, 1] (50)", "startOffset": 20, "endOffset": 26}, {"referenceID": 11, "context": "F Recovering COCOA+ as a Special Case As a special case, PROXCOCOA+ directly applies to any L2-regularized loss-minimization problem, including those presented in [12, 17].", "startOffset": 163, "endOffset": 171}, {"referenceID": 16, "context": "F Recovering COCOA+ as a Special Case As a special case, PROXCOCOA+ directly applies to any L2-regularized loss-minimization problem, including those presented in [12, 17].", "startOffset": 163, "endOffset": 171}, {"referenceID": 11, "context": "In other words, the PROXCOCOA + algorithm will in this case apply to (A) as the dual of the original input problem (which will be mapped to (B)), as described in [12, 17].", "startOffset": 162, "endOffset": 170}, {"referenceID": 16, "context": "In other words, the PROXCOCOA + algorithm will in this case apply to (A) as the dual of the original input problem (which will be mapped to (B)), as described in [12, 17].", "startOffset": 162, "endOffset": 170}, {"referenceID": 4, "context": "ADMM Alternating Direction Method of Multipliers (ADMM) [5] is a popular method that lends itself naturally to the distributed environment.", "startOffset": 56, "endOffset": 59}, {"referenceID": 24, "context": "Mini-batch CD Mini-batch CD aims to improve mini-batch SGD by employing coordinate descent, which has encouraging theoretical and practical backings [25, 9, 28].", "startOffset": 149, "endOffset": 160}, {"referenceID": 8, "context": "Mini-batch CD Mini-batch CD aims to improve mini-batch SGD by employing coordinate descent, which has encouraging theoretical and practical backings [25, 9, 28].", "startOffset": 149, "endOffset": 160}, {"referenceID": 27, "context": "Mini-batch CD Mini-batch CD aims to improve mini-batch SGD by employing coordinate descent, which has encouraging theoretical and practical backings [25, 9, 28].", "startOffset": 149, "endOffset": 160}, {"referenceID": 6, "context": "Shotgun As a special case of mini-batch CD, Shotgun [7] is a popular method for parallel optimization.", "startOffset": 52, "endOffset": 55}, {"referenceID": 31, "context": "OWL-QN OWN-QN [32] is a quasi-Newton method optimized in Spark\u2019s spark.", "startOffset": 14, "endOffset": 18}, {"referenceID": 10, "context": "We note that since the framework and theory allow any internal solver to be used, PROXCOCOA+ could benefit even beyond the results shown, by using existing fast L1-solvers for the single-machine case, such as GLMNET variants [11] or BLITZ [13].", "startOffset": 225, "endOffset": 229}, {"referenceID": 12, "context": "We note that since the framework and theory allow any internal solver to be used, PROXCOCOA+ could benefit even beyond the results shown, by using existing fast L1-solvers for the single-machine case, such as GLMNET variants [11] or BLITZ [13].", "startOffset": 239, "endOffset": 243}], "year": 2016, "abstractText": "Despite the importance of sparsity in many large-scale applications, there are few methods for distributed optimization of sparsity-inducing objectives. In this paper, we present a communication-efficient framework for L1-regularized optimization in the distributed environment. By viewing classical objectives in a more general primal-dual setting, we develop a new class of methods that can be efficiently distributed and applied to common sparsity-inducing models, such as Lasso, sparse logistic regression, and elastic net-regularized problems. We provide theoretical convergence guarantees for our framework, and demonstrate its efficiency and flexibility with a thorough experimental comparison on Amazon EC2. Our proposed framework yields speedups of up to 50\u00d7 as compared to current state-of-the-art methods for distributed L1-regularized optimization.", "creator": "LaTeX with hyperref package"}}}