{"id": "1601.01974", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "8-Jan-2016", "title": "Scale-Free Online Learning", "abstract": "We design algorithms for online linear optimization that have optimal regret and at the same time do not need to know any upper or lower bounds on the norm of the loss vectors. We achieve adaptiveness to the norms of the loss vectors by scale invariance, i.e. the distribution of the loss vectors by the loss vectors and the likelihood of the return vectors by the negative and negative vector (e.g. loss vectors).\n\n\n\n\n\n\nWe define a procedure called a loss vector. This function can be used to estimate the total potential for the loss vectors from random linear models, but it uses an inverse function called a uniformization. For example, a matrix-to-linearization would produce a linear transformation of the loss vectors from the left to the right and return the value that is the right of the loss vectors from the left to the left, thus providing a \"transverse probability\" of a given model. For example, a matrix-to-linearization would be the same as a regularization (e.g. linear), but a random linearization would be a given uniformization for a given model.\nThe transformation function can also be applied to a random linear matrix, i.e. an approximation for the probability of loss vectors. For instance, a matrix-to-linearization would be a given matrix-to-linearization and a linear transformation for the likelihood of the return vectors by the loss vectors of the correct (i.e. a) and a normalization (i.e. a) loss vectors. The loss vectors of the correct (i.e. a) and a normalization (i.e. a) loss vectors could be used to compute the correct (i.e. a) and a (i.e. a) loss vectors. For example, the following algorithm can compute the probability of loss vectors. For example, a matrices-to-linearization would be a given matrix-to-linearization and a normalization (i.e. a) loss vectors. For example, a matrices-to-linearization would be a given matrix-to-linearization and a normalization (i.e. a) loss vectors.\nIn the previous section, we set a generalization function for the probability of loss vectors. The function is used to estimate the total potential for the loss vectors from random linear models, but it uses an inverse function called a uniformization. For example, a matrix-to-linearization would be a", "histories": [["v1", "Fri, 8 Jan 2016 18:47:18 GMT  (27kb)", "https://arxiv.org/abs/1601.01974v1", "arXiv admin note: text overlap witharXiv:1502.05744"], ["v2", "Wed, 14 Dec 2016 18:32:39 GMT  (27kb)", "http://arxiv.org/abs/1601.01974v2", "arXiv admin note: text overlap witharXiv:1502.05744"]], "COMMENTS": "arXiv admin note: text overlap witharXiv:1502.05744", "reviews": [], "SUBJECTS": "cs.LG", "authors": ["francesco orabona", "d\\'avid p\\'al"], "accepted": false, "id": "1601.01974"}, "pdf": {"name": "1601.01974.pdf", "metadata": {"source": "CRF", "title": "Scale-Free Online Learning", "authors": ["Francesco Orabona", "D\u00e1vid P\u00e1l"], "emails": ["francesco@orabona.com", "dpal@yahoo-inc.com"], "sections": [{"heading": null, "text": "ar X\niv :1\n60 1.\n01 97\n4v 2\n[ cs\n.L G\n] 1\n4 D\nWe design and analyze algorithms for online linear optimization that have optimal regret and at the same time do not need to know any upper or lower bounds on the norm of the loss vectors. Our algorithms are instances of the Follow the Regularized Leader (FTRL) and Mirror Descent (MD) meta-algorithms. We achieve adaptiveness to the norms of the loss vectors by scale invariance, i.e., our algorithms make exactly the same decisions if the sequence of loss vectors is multiplied by any positive constant. The algorithm based on FTRL works for any decision set, bounded or unbounded. For unbounded decisions sets, this is the first adaptive algorithm for online linear optimization with a non-vacuous regret bound. In contrast, we show lower bounds on scale-free algorithms based on MD on unbounded domains."}, {"heading": "1. Introduction", "text": "Online Linear Optimization (OLO) is a problem where an algorithm repeatedly chooses a point wt from a convex decision set K, observes an arbitrary, or even adversarially chosen, loss vector \u2113t and suffers the loss \u3008\u2113t, wt\u3009. The goal of the algorithm is to have a small cumulative loss. The performance of an algorithm is evaluated by the so-called regret, which is the difference of the cumulative losses of the algorithm and of the (hypothetical) strategy that would choose in every round the same best point in hindsight.\nOLO is a fundamental problem in machine learning [2, 3, 4]. Many learning problems can be directly phrased as OLO, e.g., learning with expert advice [5, 6, 7, 8] and online combinatorial optimization [9, 10, 11]. Other problems can be reduced to OLO, e.g., online convex optimization [12], [4, Chapter 2], online\n\u2729A preliminary version of this paper [1] was presented at ALT 2015. \u2217Work done while at Yahoo Research.\n\u2217\u2217Corresponding author Email addresses: francesco@orabona.com (Francesco Orabona), dpal@yahoo-inc.com\n(Da\u0301vid Pa\u0301l)\nPreprint submitted to Elsevier December 15, 2016\nclassification [13, 14] and regression [15], [2, Chapters 11 and 12], multi-armed bandits problems [2, Chapter 6], [16, 17], and batch and stochastic optimization of convex functions [18, 19]. Hence, a result in OLO immediately implies other results in all these domains.\nThe adversarial choice of the loss vectors received by the algorithm is what makes the OLO problem challenging. In particular, if an OLO algorithm commits to an upper bound on the norm of future loss vectors, its regret can be made arbitrarily large through an adversarial strategy that produces loss vectors with norms that exceed the upper bound.\nFor this reason, most of the existing OLO algorithms receive as an input\u2014 or implicitly assume\u2014an upper bound B on the norm of the loss vectors. The input B is often disguised as the learning rate, the regularization parameter, or the parameter of strong convexity of the regularizer. However, these algorithms have two obvious drawbacks.\nFirst, they do not come with any regret guarantee for sequences of loss vectors with norms exceeding B. Second, on sequences of loss vectors with norms bounded by b \u226a B, these algorithms fail to have an optimal regret guarantee that depends on b rather than on B.\n1 Even if, in principle the FTRL-Proximal algorithm can be used with any proximal regularizer, to the best of our knowledge a general way to construct proximal regularizers is not known. The only proximal regularizer we are aware is based on the 2-norm.\n2 These algorithms attempt to produce an invariant sequence of predictions \u3008wt, \u2113t\u3009, rather than a sequence of invariant wt.\nThere is a clear practical need to design algorithms that adapt automatically to the norms of the loss vectors. A natural, yet overlooked, design method to achieve this type of adaptivity is by insisting to have a scale-free algorithm. That is, with the same parameters, the sequence of decisions of the algorithm does not change if the sequence of loss vectors is multiplied by a positive constant. The most important property of scale-free algorithms is that both their loss and their regret scale linearly with the maximum norm of the loss vector appearing in the sequence."}, {"heading": "1.1. Previous results", "text": "The majority of the existing algorithms for OLO are based on two generic algorithms: Follow The Regularizer Leader (FTRL) and Mirror Descent (MD). FTRL dates back to the potential-based forecaster in [2, Chapter 11] and its theory was developed in [28]. The name Follow The Regularized Leader comes from [16]. Independently, the same algorithm was proposed in [29] for convex optimization under the name Dual Averaging and rediscovered in [21] for online convex optimization. Time-varying regularizers were analyzed in [24] and the analysis tightened in [27]. MD was originally proposed in [18] and later analyzed in [30] for convex optimization. In the online learning literature it makes its first appearance, with a different name, in [15].\nBoth FTRL and MD are parametrized by a function called a regularizer. Based on different regularizers different algorithms with different properties can be instantiated. A summary of algorithms for OLO is presented in Table 1. All of them are instances of FTRL or MD.\nScale-free versions of MD include AdaGrad MD [24]. However, the AdaGrad MD algorithm has a non-trivial regret bounds only when the Bregman divergence associated with the regularizer is bounded. In particular, since a bound on the Bregman divergence implies that the decision set is bounded, the regret bound for AdaGrad MD is vacuous for unbounded sets. In fact, as we show in Section 4.1, AdaGrad MD and similar algorithms based on MD incurs \u2126(T ) regret, in the worst case, if the Bregman divergence is not bounded.\nOnly one scale-free algorithm based on FTRL was known. It is the AdaHedge [25] algorithm for learning with expert advice, where the decision set is bounded. An algorithm based on FTRL that is \u201calmost\u201d scale-free isAdaGrad FTRL [24]. This algorithm fail to be scale-free due to \u201coff-by-one\u201d issue; see [23] and the discussion in Section 3. Instead, FTRL-Proximal [22, 23] solves the off-by-one issue, but it requires proximal regularizers. In general, proximal regularizers do not have a simple form and even the simple 2-norm case requires bounded domains to achieve non-vacuous regret.\nFor unbounded decision sets no scale-free algorithm with a non-trivial regret bound was known. Unbounded decision sets are practically important (see, e.g., [31]), since learning of large-scale linear models (e.g., logistic regression) is done by gradient methods that can be reduced to OLO with decision set Rd."}, {"heading": "1.2. Overview of the Results", "text": "We design and analyze two scale-free algorithms: SOLO FTRL and ScaleFree MD. A third one, AdaFTRL, is presented in the Appendix. SOLO FTRL and AdaFTRL are based on FTRL. AdaFTRL is a generalization of AdaHedge [25] to arbitrary strongly convex regularizers. SOLO FTRL can be viewed as the \u201ccorrect\u201d scale-free version of the diagonal version of AdaGrad FTRL [24] generalized to arbitrary strongly convex regularizers. Scale-Free MD is based on MD. It is a generalization of AdaGrad MD [24] to arbitrary strongly convex regularizers. The three algorithms are presented in Sections 3 and 4, and Appendix B, respectively.\nWe prove that the regret of SOLO FTRL and AdaFTRL on bounded do-\nmains after T rounds is bounded by O( \u221a supv\u2208K f(v) \u2211T t=1 \u2016\u2113t\u20162\u2217) where f is a non-negative regularizer that is 1-strongly convex with respect to a norm \u2016\u00b7\u2016 and \u2016\u00b7\u2016\u2217 is its dual norm. For Scale-Free MD, we proveO( \u221a supu,v\u2208K Bf (u, v) \u2211T t=1 \u2016\u2113t\u20162\u2217) where Bf is the Bregman divergence associated with a 1-strongly convex regu-\nlarizer f . In Section 5, we show that the \u221a\u2211T t=1 \u2016\u2113t\u20162\u2217 term in the bounds is\nnecessary by proving a D\u221a 8 \u221a\u2211T t=1 \u2016\u2113t\u20162\u2217 lower bound on the regret of any algorithm for OLO for any decision set with diameter D with respect to the primal norm \u2016 \u00b7 \u2016.\nFor SOLO FTRL, we prove that the regret against a competitor u \u2208 K is at most O(f(u) \u221a\u2211T t=1 \u2016\u2113t\u20162\u2217 + maxt=1,2,...,T \u2016\u2113t\u2016\u2217 \u221a T ). As before, f is a non-negative 1-strongly convex regularizer. This bound is non-trivial for any decision set, bounded or unbounded. The result makes SOLO FTRL the first adaptive algorithm for unbounded decision sets with a non-trivial regret bound.\nAll three algorithms are any-time, i.e., they do not need to know the number of rounds, T , in advance and the regret bounds hold for all T simultaneously.\nOur proof techniques rely on new homogeneous inequalities (Lemmas 3, 7) which might be of independent interest.\nFinally, in Section 4.1, we show negative results for existing popular variants of MD. We show two examples of decision sets and sequences of loss vectors of unit norm on which these variants of MD have \u2126(T ) regret. These results indicate that FTRL is superior to MD in a worst-case sense."}, {"heading": "2. Notation and Preliminaries", "text": "Let V be a finite-dimensional3 real vector space equipped with a norm \u2016 \u00b7 \u2016. We denote by V \u2217 its dual vector space. The bi-linear map associated with (V \u2217, V ) is denoted by \u3008\u00b7, \u00b7\u3009 : V \u2217 \u00d7 V \u2192 R. The dual norm of \u2016 \u00b7 \u2016 is \u2016 \u00b7 \u2016\u2217.\n3Many, but not all, of our results can be extended to more general normed vector spaces.\nIn OLO, in each round t = 1, 2, . . . , the algorithm chooses a point wt in the decision set K \u2286 V and then the algorithm observes a loss vector \u2113t \u2208 V \u2217. The instantaneous loss of the algorithm in round t is \u3008\u2113t, wt\u3009. The cumulative loss of the algorithm after T rounds is \u2211T t=1\u3008\u2113t, wt\u3009. The regret of the algorithm with respect to a point u \u2208 K is\nRegretT (u) =\nT\u2211\nt=1\n\u3008\u2113t, wt\u3009 \u2212 T\u2211\nt=1\n\u3008\u2113t, u\u3009,\nand the regret with respect to the best point is RegretT = supu\u2208K RegretT (u). We assume that K is a non-empty closed convex subset of V . Sometimes we will assume that K is also bounded. We denote by D its diameter with respect to \u2016 \u00b7 \u2016, i.e., D = supu,v\u2208K \u2016u\u2212 v\u2016. If K is unbounded, D = +\u221e."}, {"heading": "2.1. Convex Analysis", "text": "The Bregman divergence of a convex differentiable function f is defined as Bf(u, v) = f(u) \u2212 f(v) \u2212 \u3008\u2207f(v), u \u2212 v\u3009. Note that Bf(u, v) \u2265 0 for any u, v which follows directly from the definition of convexity of f .\nThe Fenchel conjugate of a function f : K \u2192 R is the function f\u2217 : V \u2217 \u2192 R\u222a{+\u221e} defined as f\u2217(\u2113) = supw\u2208K (\u3008\u2113, w\u3009 \u2212 f(w)). The Fenchel conjugate of any function is convex (since it is a supremum of affine functions) and satisfies the Fenchel-Young inequality\n\u2200w \u2208 K, \u2200\u2113 \u2208 V \u2217 f(w) + f\u2217(\u2113) \u2265 \u3008\u2113, w\u3009 .\nMonotonicity of Fenchel conjugates follows easily from the definition: If f, g : K \u2192 R satisfy f(w) \u2264 g(w) for all w \u2208 K then f\u2217(\u2113) \u2265 g\u2217(\u2113) for every \u2113 \u2208 V \u2217.\nGiven \u03bb > 0, a function f : K \u2192 R is called \u03bb-strongly convex with respect to a norm \u2016 \u00b7 \u2016 if and only if, for all x, y \u2208 K,\nf(y) \u2265 f(x) + \u3008\u2207f(x), y \u2212 x\u3009+ \u03bb 2 \u2016x\u2212 y\u20162 ,\nwhere \u2207f(x) is any subgradient of f at the point x. The following proposition relates the range of values of a strongly convex function to the diameter of its domain. The proof can be found in Appendix A.\nProposition 1 (Diameter vs. Range). Let K \u2286 V be a non-empty bounded closed convex set. Let D = supu,v\u2208K \u2016u \u2212 v\u2016 be its diameter with respect to \u2016 \u00b7 \u2016. Let f : K \u2192 R be a non-negative lower semi-continuous function that is 1-strongly convex with respect to \u2016 \u00b7 \u2016. Then, D \u2264 \u221a 8 supv\u2208K f(v).\nFenchel conjugates and strongly convex functions have certain nice properties, which we list in Proposition 2 below.\nAlgorithm 1 FTRL with Varying Regularizer Require: Non-empty closed convex set K \u2286 V 1: Initialize L0 \u2190 0 2: for t = 1, 2, 3, . . . do 3: Choose a regularizer Rt : K \u2192 R 4: wt \u2190 argminw\u2208K (\u3008Lt\u22121, w\u3009+Rt(w)) 5: Predict wt 6: Observe \u2113t \u2208 V \u2217 7: Lt \u2190 Lt\u22121 + \u2113t 8: end for\nProposition 2 (Fenchel Conjugates of Strongly Convex Functions). Let K \u2286 V be a non-empty closed convex set with diameter D := supu,v\u2208K \u2016u\u2212 v\u2016. Let \u03bb > 0, and let f : K \u2192 R be a lower semi-continuous function that is \u03bb-strongly convex with respect to \u2016 \u00b7 \u2016. The Fenchel conjugate of f satisfies:\n1. f\u2217 is finite everywhere and differentiable everywhere. 2. For any \u2113 \u2208 V \u2217, \u2207f\u2217(\u2113) = argminw\u2208K (f(w)\u2212 \u3008\u2113, w\u3009). 3. For any \u2113 \u2208 V \u2217, f\u2217(\u2113) + f(\u2207f\u2217(\u2113)) = \u3008\u2113,\u2207f\u2217(\u2113)\u3009. 4. f\u2217 is 1\u03bb -strongly smooth, i.e., for any x, y \u2208 V \u2217, Bf\u2217(x, y) \u2264 12\u03bb\u2016x\u2212 y\u20162\u2217. 5. f\u2217 has 1\u03bb -Lipschitz continuous gradients, i.e., for any x, y \u2208 V \u2217, \u2016\u2207f\u2217(x)\u2212\n\u2207f\u2217(y)\u2016 \u2264 1\u03bb\u2016x\u2212 y\u2016\u2217. 6. Bf\u2217(x, y) \u2264 D\u2016x\u2212 y\u2016\u2217 for any x, y \u2208 V \u2217. 7. \u2016\u2207f\u2217(x)\u2212\u2207f\u2217(y)\u2016 \u2264 D for any x, y \u2208 V \u2217. 8. For any c > 0, (cf(\u00b7))\u2217 = cf\u2217(\u00b7/c).\nExcept for properties 6 and 7, the proofs can be found in [28]. Property 6 is proven in Appendix A. Property 7 trivially follows from property 2."}, {"heading": "2.2. Generic FTRL with Varying Regularizer", "text": "Two of our scale-free algorithms are instances of FTRL with varying regularizers, presented as Algorithm 1. The algorithm is paramatrized by a sequence {Rt}\u221et=1 of functions Rt : K \u2192 R called regularizers. Each regularizerRt can depend on the past loss vectors \u21131, \u21132, . . . , \u2113t\u22121 in an arbitrary way. The following lemma bounds its regret.\nLemma 1 (Regret of FTRL). If the regularizers R1, R2, . . . chosen by Algorithm 1 are strongly convex and lower semi-continuous, the algorithm\u2019s regret is upper bounded as\nRegretT (u) \u2264 RT+1(u)+R\u22171(0)+ T\u2211\nt=1\nBR\u2217 t (\u2212Lt,\u2212Lt\u22121)\u2212R\u2217t (\u2212Lt)+R\u2217t+1(\u2212Lt) .\nThe proof of the lemma can be found in [27]. For completeness, we include it in Appendix A.\nAlgorithm 2 Mirror Descent with Varying Regularizer Require: Non-empty closed convex set K \u2286 V 1: Choose a regularizer R0 : K \u2192 R 2: w1 \u2190 argminw\u2208K R0(w) 3: for t = 1, 2, 3, . . . do 4: Predict wt 5: Observe \u2113t \u2208 V \u2217 6: Choose a regularizer Rt : K \u2192 R 7: wt+1 \u2190 argminw\u2208K (\u3008\u2113t, w\u3009 + BRt(w,wt)) 8: end for"}, {"heading": "2.3. Generic Mirror Descent with Varying Regularizer", "text": "Mirror Descent (MD) is a generic algorithm similar to FTRL but quite different in the details. The algorithm is stated as Algorithm 2. The algorithm is parametrized by a sequence {Rt}\u221et=0 of convex functions Rt : K \u2192 R called regularizers. Each regularizer Rt can depend on past loss vectors \u21131, \u21132, . . . , \u2113t in an arbitrary way. If Rt is not differentiable,\n4 the Bregman divergence, BRt(u, v) = Rt(u)\u2212Rt(v)\u2212\u3008\u2207Rt(v), u\u2212v\u3009 needs to be defined. This is done by choosing a subgradient map \u2207Rt : K \u2192 V , i.e., a function such that \u2207Rt(w) is a subgradient of Rt at any point w. If Rt is a restriction of a differentiable function R\u2032t, it is convenient to define \u2207Rt(w) = \u2207R\u2032t(w) for all w \u2208 K. The following lemma bounds the regret of MD.\nLemma 2 (Regret of MD). Algorithm 2 satisfies, for any u \u2208 K,\nRegretT (u) \u2264 T\u2211\nt=1\n\u3008\u2113t, wt \u2212 wt+1\u3009 \u2212 BRt(wt+1, wt) + BRt(u,wt)\u2212 BRt(u,wt+1) .\nThe proof of the lemma can be found in [3, 32]. For completeness, we give a proof in Appendix E."}, {"heading": "2.4. Per-Coordinate Learning", "text": "An interesting class of algorithms proposed in [22] and [24] are based on socalled per-coordinate learning rates. As shown in [33], any algorithm for OLO can be used with per-coordinate learning rates as well.\nAbstractly, we assume that the decision set is a Cartesian product K = K1 \u00d7 K2 \u00d7 \u00b7 \u00b7 \u00b7 \u00d7 Kd of a finite number of convex sets. On each factor Kj , j = 1, 2, . . . , d, we can run any OLO algorithm separately and we denote by\n4Note that this can happen even when Rt is a restriction of a differentiable function defined on a superset of K. If K is bounded and closed, Rt fails to be differentiable at the boundary of K. If K is a subset of an affine subspace of a dimension smaller than the dimension of V , then Rt fails to be differentiable everywhere.\nRegret (j) T (uj) its regret with respect to uj \u2208 Kj. The overall regret with respect to any u = (u1, u2, . . . , ud) \u2208 K can be written as\nRegretT (u) =\nd\u2211\nj=1\nRegret (j) T (uj) .\nIf the algorithm for each factor is scale-free, the overall algorithm is clearly scale-free as well. Hence, even if not explicitly mentioned in the text, any algorithm we present can be trivially transformed to a per-coordinate version."}, {"heading": "3. SOLO FTRL", "text": "In this section, we introduce our first scale-free algorithm; it will be based on FTRL. The closest algorithm to a scale-free FTRL in the existing literature is the AdaGrad FTRL algorithm [24]. It uses a regularizer on each coordinate of the form\nRt(w) = R(w)\n\n\u03b4 +\n\u221a\u221a\u221a\u221a t\u22121\u2211\ni=1\n\u2016\u2113i\u20162\u2217\n\n .\nThis kind of regularizer would yield a scale-free algorithm only for \u03b4 = 0. In fact, with this choice of \u03b4 it is easy to see that the predictions wt in line 4 of Algorithm 1 would be independent of the scaling of the \u2113t. Unfortunately, the regret bound in [24] becomes vacuous for such setting in the unbounded case. In fact, it requires \u03b4 to be greater than \u2016\u2113t\u2016\u2217 for all time steps t, requiring knowledge of the future (see Theorem 5 in [24]). In other words, despite of its name, AdaGrad FTRL is not fully adaptive to the norm of the gradient vectors. Similar considerations hold for the FTRL-Proximal in [22, 23]: The scale-free setting of the learning rate is valid only in the bounded case.\nOne simple approach would be to use a doubling trick on \u03b4 in order to estimate on the fly the maximum norm of the losses. Note that a naive strategy would still fail because the initial value of \u03b4 should be data-dependent in order to have a scale-free algorithm. Moreover, we would have to upper bound the regret in all the rounds where the norm of the current loss is bigger than the estimate. Finally, the algorithm would depend on an additional parameter, the \u201cdoubling\u201d power. Hence, even in the case one would prove a regret bound, such strategy would give the feeling that FTRL needs to be \u201cfixed\u201d in order to obtain a scale-free algorithm.\nIn the following, we propose a much simpler and better approach. We propose to use Algorithm 1 with the regularizer\nRt(w) = R(w)\n\u221a\u221a\u221a\u221a t\u22121\u2211\ni=1\n\u2016\u2113i\u20162\u2217 , (1)\nwhere R : K \u2192 R is any strongly convex function. Through a refined analysis, we show that this regularizer suffices to obtain an optimal regret bound for any\ndecision set, bounded or unbounded. We call this variant Scale-free Online Linear Optimization FTRL algorithm (SOLO FTRL). Our main result is Theorem 1 below, which is proven in Section 3.1.\nThe regularizer (1) does not uniquely define the FTRL minimizer wt =\nargminw\u2208K Rt(w) when \u221a\u2211t\u22121\ni=1 \u2016\u2113i\u20162\u2217 is zero. This happens if \u21131, \u21132, . . . , \u2113t\u22121 are all zero (and in particular for t = 1). In that case, we define wt = argminw\u2208K R(w) which is consistent with wt = lima\u21920+ argminw\u2208K aR(w).\nTheorem 1 (Regret of SOLO FTRL). Suppose K \u2286 V is a non-empty closed convex set. Let D = supu,v\u2208K \u2016u \u2212 v\u2016 be its diameter with respect to a norm \u2016 \u00b7 \u2016. Suppose that the regularizer R : K \u2192 R is a non-negative lower semi-continuous function that is \u03bb-strongly convex with respect to \u2016 \u00b7 \u2016. The regret of SOLO FTRL satisfies\nRegretT (u) \u2264 ( R(u) + 2.75\n\u03bb\n) \u221a\u221a\u221a\u221a T\u2211\nt=1\n\u2016\u2113t\u20162\u2217 + 3.5min {\u221a T \u2212 1 \u03bb ,D } max t\u2264T \u2016\u2113t\u2016\u2217 .\nWhen K is unbounded, we pay a penalty that scales as maxt\u2264T \u2016\u2113t\u2016\u2217 \u221a T , that has the same magnitude of the first term in the bound. On the other hand, when K is bounded, the second term is a constant and we can choose the optimal multiple of the regularizer. We choose R(w) = \u03bbf(w) where f is a 1-strongly convex function and optimize \u03bb. The result of the optimization is Corollary 1.\nCorollary 1 (Regret Bound for Bounded Decision Sets). Suppose K \u2286 V is a non-empty bounded closed convex set. Suppose that f : K \u2192 R is a nonnegative lower semi-continuous function that is 1-strongly convex with respect to \u2016 \u00b7 \u2016. SOLO FTRL with regularizer\nR(w) = f(w) \u221a 2.75\u221a\nsupv\u2208K f(v) satisfies RegretT \u2264 13.3 \u221a\u221a\u221a\u221asup v\u2208K f(v) T\u2211\nt=1\n\u2016\u2113t\u20162\u2217 .\nProof. Let S = supv\u2208K f(v). Theorem 1 applied to the regularizer R(w) = c\u221a S f(w), together with Proposition 1 and a crude bound maxt=1,2,...,T \u2016\u2113t\u2016\u2217 \u2264\u221a\u2211T t=1 \u2016\u2113t\u20162\u2217, give\nRegretT \u2264 ( c+ 2.75\nc + 3.5\n\u221a 8 ) \u221a\u221a\u221a\u221aS T\u2211\nt=1\n\u2016\u2113t\u20162\u2217 .\nWe choose c by minimizing g(c) = c+ 2.75c +3.5 \u221a 8. Clearly, g(c) has minimum\nat c = \u221a 2.75 and has minimal value g( \u221a 2.75) = 2 \u221a 2.75 + 3.5 \u221a 8 \u2264 13.3.\n3.1. Proof of Regret Bound for SOLO FTRL\nThe proof of Theorem 1 relies on an inequality (Lemma 3). Related and weaker inequalities, like Lemma 4, were proved in [34] and [35]. The main property of this inequality is that on the right-hand side C does not multiply the \u221a\u2211T\nt=1 a 2 t term.\nLemma 3 (Useful Inequality). Let C, a1, a2, . . . , aT \u2265 0. Then,\nT\u2211\nt=1\nmin   \na2t\u221a\u2211t\u22121 i=1 a 2 i , Cat\n   \u2264 3.5C maxt=1,2,...,T at + 3.5 \u221a\u221a\u221a\u221a T\u2211\nt=1\na2t .\nProof. Without loss of generality, we can assume that at > 0 for all t. Since otherwise we can remove all at = 0 without affecting either side of the inequality. Let Mt = max{a1, a2, . . . , at} and M0 = 0. We prove that for any \u03b1 > 1\nmin\n   a2t\u221a\u2211t\u22121 i=1 a 2 i , Cat    \u2264 2 \u221a 1 + \u03b12   \u221a\u221a\u221a\u221a t\u2211 i=1 a2i \u2212 \u221a\u221a\u221a\u221a t\u22121\u2211 i=1 a2i  +C\u03b1(Mt \u2212Mt\u22121) \u03b1\u2212 1\nfrom which the inequality follows by summing over t = 1, 2, . . . , T and choosing \u03b1 = \u221a 2. The inequality follows by case analysis. If a2t \u2264 \u03b12 \u2211t\u22121 i=1 a 2 i , we have\nmin   \na2t\u221a\u2211t\u22121 i=1 a 2 i , Cat\n   \u2264\na2t\u221a\u2211t\u22121 i=1 a 2 i = a2t\u221a\n1 1+\u03b12\n( \u03b12 \u2211t\u22121 i=1 a 2 i + \u2211t\u22121 i=1 a 2 i )\n\u2264 a 2 t \u221a 1 + \u03b12\u221a\na2t + \u2211t\u22121 i=1 a 2 i = a2t \u221a 1 + \u03b12\u221a\u2211t i=1 a 2 i \u2264 2 \u221a 1 + \u03b12\n\n\n\u221a\u221a\u221a\u221a t\u2211\ni=1\na2i \u2212\n\u221a\u221a\u221a\u221a t\u22121\u2211\ni=1\na2i\n\n\nwhere we have used x2/ \u221a x2 + y2 \u2264 2( \u221a x2 + y2 \u2212 \u221a y2) in the last step. On the other hand, if a2t > \u03b1 2 \u2211t\u22121 t=1 a 2 i , we have\nmin\n   a2t\u221a\u2211t\u22121 i=1 a 2 i , Cat    \u2264 Cat = C \u03b1at \u2212 at \u03b1\u2212 1 \u2264 C \u03b1\u2212 1  \u03b1at \u2212 \u03b1 \u221a\u221a\u221a\u221a t\u22121\u2211 i=1 a2i  \n= C\u03b1\n\u03b1\u2212 1\n at \u2212 \u221a\u221a\u221a\u221a t\u22121\u2211\ni=1\na2i\n  \u2264 C\u03b1\n\u03b1\u2212 1 (at \u2212Mt\u22121) = C\u03b1 \u03b1\u2212 1 (Mt \u2212Mt\u22121)\nwhere we have used that at = Mt and \u221a\u2211t\u22121 i=1 a 2 i \u2265 Mt\u22121.\nLemma 4 ([34, Lemma 3.5]). Let a1, a2, . . . , aT be non-negative real numbers. If a1 > 0 then,\nT\u2211\nt=1 at\u221a\u2211t i=1 ai \u2264 2\n\u221a\u221a\u221a\u221a T\u2211\nt=1\nat .\nFor completeness, a proof of Lemma 4 is in Appendix D.\nProof (Proof of Theorem 1). Let \u03b7t = 1\u221a\u2211\nt\u22121 i=1 \u2016\u2113i\u20162\u2217\n, henceRt(w) = 1 \u03b7t R(w).\nWe assume without loss of generality that \u2016\u2113t\u2016\u2217 > 0 for all t, since otherwise we can remove all rounds t where \u2113t = 0 without affecting the regret and the predictions of the algorithm on the remaining rounds. By Lemma 1,\nRegretT (u) \u2264 1\n\u03b7T+1 R(u) +\nT\u2211\nt=1\n( BR\u2217 t (\u2212Lt,\u2212Lt\u22121)\u2212R\u2217t (\u2212Lt) +R\u2217t+1(\u2212Lt) ) .\nWe upper bound the terms of the sum in two different ways. First, by Proposition 2, we have\nBR\u2217 t (\u2212Lt,\u2212Lt\u22121)\u2212R\u2217t (\u2212Lt) +R\u2217t+1(\u2212Lt) \u2264 BR\u2217t (\u2212Lt,\u2212Lt\u22121) \u2264 \u03b7t\u2016\u2113t\u20162\u2217 2\u03bb .\nSecond, we have\nBR\u2217 t (\u2212Lt,\u2212Lt\u22121)\u2212R\u2217t (\u2212Lt) +R\u2217t+1(\u2212Lt) = BR\u2217 t+1 (\u2212Lt,\u2212Lt\u22121) +R\u2217t+1(\u2212Lt\u22121)\u2212R\u2217t (\u2212Lt\u22121)\n+ \u3008\u2207R\u2217t (\u2212Lt\u22121)\u2212\u2207R\u2217t+1(\u2212Lt\u22121), \u2113t\u3009\n\u2264 \u03b7t+1\u2016\u2113t\u2016 2 \u2217\n2\u03bb + \u2016\u2207R\u2217t (\u2212Lt\u22121)\u2212\u2207R\u2217t+1(\u2212Lt\u22121)\u2016 \u00b7 \u2016\u2113t\u2016\u2217\n= \u03b7t+1\u2016\u2113t\u20162\u2217\n2\u03bb + \u2016\u2207R\u2217(\u2212\u03b7tLt\u22121)\u2212\u2207R\u2217(\u2212\u03b7t+1Lt\u22121)\u2016 \u00b7 \u2016\u2113t\u2016\u2217\n\u2264 \u03b7t+1\u2016\u2113t\u2016 2 \u2217\n2\u03bb +min\n{ 1\n\u03bb \u2016Lt\u22121\u2016\u2217 (\u03b7t \u2212 \u03b7t+1) , D\n} \u2016\u2113t\u2016\u2217 ,\nwhere in the first inequality we have used the fact thatR\u2217t+1(\u2212Lt\u22121) \u2264 R\u2217t (\u2212Lt\u22121), Ho\u0308lder\u2019s inequality, and Proposition 2. In the second inequality we have used properties 5 and 7 of Proposition 2. Using the definition of \u03b7t+1 we have\n\u2016Lt\u22121\u2016\u2217(\u03b7t \u2212 \u03b7t+1) \u03bb \u2264 \u2016Lt\u22121\u2016\u2217 \u03bb \u221a\u2211t\u22121 i=1 \u2016\u2113i\u20162\u2217 \u2264\n\u2211t\u22121 i=1 \u2016\u2113i\u2016\u2217\n\u03bb \u221a\u2211t\u22121 i=1 \u2016\u2113i\u20162\u2217 \u2264\n\u221a t\u2212 1 \u03bb \u2264 \u221a T \u2212 1 \u03bb .\nDenoting by H = min {\u221a\nT\u22121 \u03bb , D\n} we have\nRegretT (u) \u2264 1\n\u03b7T+1 R(u) +\nT\u2211\nt=1\nmin { \u03b7t\u2016\u2113t\u20162\u2217 2\u03bb , H\u2016\u2113t\u2016\u2217 + \u03b7t+1\u2016\u2113t\u20162\u2217 2\u03bb }\n\u2264 1 \u03b7T+1 R(u) + 1 2\u03bb\nT\u2211\nt=1\n\u03b7t+1\u2016\u2113t\u20162\u2217 + 1\n2\u03bb\nT\u2211\nt=1\nmin { \u03b7t\u2016\u2113t\u20162\u2217, 2\u03bbH\u2016\u2113t\u2016\u2217 }\n= 1\n\u03b7T+1 R(u) +\n1\n2\u03bb\nT\u2211\nt=1 \u2016\u2113t\u20162\u2217\u221a\u2211t i=1 \u2016\u2113i\u20162\u2217 + 1 2\u03bb\nT\u2211\nt=1\nmin\n   \u2016\u2113t\u20162\u2217\u221a\u2211t\u22121 i=1 \u2016\u2113i\u20162\u2217 , 2\u03bbH\u2016\u2113t\u2016\u2217    .\nWe bound each of the three terms separately. By definition of \u03b7T+1, the first\nterm is 1\u03b7T+1R(u) = R(u) \u221a\u2211T t=1 \u2016\u2113t\u20162\u2217. We upper bound the second term using Lemma 4 as\n1\n2\u03bb\nT\u2211\nt=1 \u2016\u2113t\u20162\u2217\u221a\u2211t i=1 \u2016\u2113i\u20162\u2217 \u2264 1 \u03bb\n\u221a\u221a\u221a\u221a T\u2211\nt=1\n\u2016\u2113t\u20162\u2217 .\nFinally, by Lemma 3 we upper bound the third term as\n1\n2\u03bb\nT\u2211\nt=1\nmin   \n\u2016\u2113t\u20162\u2217\u221a\u2211t\u22121 i=1 \u2016\u2113i\u20162\u2217 , 2\u03bb\u2016\u2113t\u2016\u2217H\n   \u2264 3.5Hmaxt\u2264T \u2016\u2113t\u2016\u2217 + 1.75 \u03bb \u221a\u221a\u221a\u221a T\u2211\nt=1\n\u2016\u2113t\u20162\u2217 .\nPutting everything together gives the stated bound."}, {"heading": "4. Scale-Free Mirror Descent", "text": "In this section, we analyze scale-free version of Mirror Descent. Our algorithm uses the regularizer\nRt(w) = R(w)\n\u221a\u221a\u221a\u221a t\u2211\ni=1\n\u2016\u2113i\u20162\u2217 , (2)\nwhere R : K \u2192 R an arbitrary strongly convex function. As for SOLO FTRL, it is easy to see that such regularizer gives rise to predictions wt that are scalefree. We call the resulting algorithm Scale-Free MD. Similar to SOLO FTRL, the regularizer (2) does not uniquely define the MD minimizer wt+1 =\nargminw\u2208K (\u3008\u2113t, w\u3009 + BRt(w,wt)) when \u221a\u2211t\ni=1 \u2016\u2113i\u20162\u2217 is zero. This happens when the loss vectors \u21131, \u21132, . . . , \u2113t are all zero. In this case, we define wt+1 = argminw\u2208K R(w) which agrees with wt+1 = lima\u21920+ argminw\u2208K aBR(w,wt). Similarly, w1 = argminw\u2208K R(w).\nPer-coordinate version of Scale-Free MD with regularizer R(w) = 12\u2016w\u2016 2 2 is exactly the same algorithm as the diagonal version of AdaGrad MD [24]. The theorem below upper bounds the regret of Scale-Free MD (see also [24, 32, 36]). The proof is in Appendix E.\nTheorem 2 (Regret of Scale-Free Mirror Descent). Suppose K \u2286 V is a non-empty closed convex set. Suppose that R : K \u2192 R is a \u03bb-strongly convex function with respect to a norm \u2016 \u00b7 \u2016. Scale-Free MD with regularizer R satisfies for any u \u2208 K,\nRegretT (u) \u2264 ( 1\n\u03bb + sup v\u2208K BR(u, v)\n) \u221a\u221a\u221a\u221a T\u2211\nt=1\n\u2016\u2113t\u20162\u2217 .\nWe choose the regularizer R(w) = \u03bbf(w) where f is a 1-strongly convex function and optimize \u03bb. The result is the following Corollary. Its proof is trivial.\nCorollary 2 (Regret of Scale-Free Mirror Descent). Suppose K \u2286 V is a non-empty bounded closed convex set. Suppose that f : K \u2192 R is a 1-strongly convex function with respect to a norm \u2016 \u00b7 \u2016. Scale-Free MD with regularizer\nR(w) = f(w)\u221a\nsup u,v\u2208K\nBf (u, v) satisfies RegretT \u2264 2 \u221a\u221a\u221a\u221a sup u,v\u2208K Bf(u, v) T\u2211 t=1 \u2016\u2113t\u20162\u2217 .\nThe regret bound for Scale-Free MD in the Corollary 2 depends on supu,v\u2208K Bf(u, v). In contrast, the regret bound for SOLO FTRL in Corollary 1 depend on supu\u2208K f(u). Similarly, the regret bound in Theorem 2 for Scale-Free MD depends on supv\u2208K BR(u, v) and the regret bounds in Theorem 1 for SOLO FTRL depend on R(u). It is not hard to show that\n\u2200u \u2208 K R(u) \u2264 sup v\u2208K BR(u, v) , (3)\nprovided that at the minimizer v\u2217 = argminv\u2208K R(v) both R(v \u2217) and \u2207R(v\u2217) are zero. Indeed, in that case, R(u) = BR(u, v\u2217) \u2264 supv\u2208K BR(u, v). The assumption R(v\u2217) = 0 and \u2207R(v\u2217) = 0 are easy to achieve by adding an affine function to the regularizer:\nR\u2032(u) = R(u)\u2212 \u3008\u2207R(v\u2217), u\u2212 v\u2217\u3009 \u2212R(v\u2217) .\nThe regularizer R\u2032 has the same parameter of strong convexity as R, the associated Bregman divergences BR\u2032 and BR are equal, R\u2032 and R have the same minimizer v\u2217, and R\u2032(v\u2217) and \u2207R\u2032(v\u2217) are both zero.\nThus, inequality (3) implies that\u2014ignoring constant factors\u2014the regret bound for Scale-Free MD is inferior to the regret bound for SOLO FTRL. In fact, it is not hard to come up with examples where R(u) is finite whereas supv\u2208K BR(u, v) is infinite. We mention two such examples. The first example is R(w) = 12\u2016w\u201622 defined on the whole space V , where for any u \u2208 V , R(u) is a finite value but supv\u2208K BR(u, v) = supv\u2208V 12\u2016u\u2212v\u201622 = +\u221e. The second example is the shifted negative entropy regularizer R(w) = ln(d)+ \u2211d j=1 wj lnwj defined\non the d-dimensional probability simplex K = {w \u2208 Rd : wj \u2265 0, \u2211d\nj=1 wj = 1}, where for any u \u2208 K, R(u) is finite and in fact lies in the interval [0, lnd] but supv\u2208K BR(u, v) = supv\u2208K \u2211d j=1 uj ln(uj/vj) = +\u221e. We revisit these examples in the following subsection."}, {"heading": "4.1. Lower Bounds for Scale-Free Mirror Descent", "text": "The bounds in Theorem 2 and Corollary 2 are vacuous when BR(u, v) is not bounded. One might wonder if the assumption that BR(u, v) is bounded is necessary in order for Scale-Free MD to have a sublinear regret. We show necessity of this assumption on two counter-examples. In these counterexamples, we consider strongly convex regularizers R such that BR(u, v) is not bounded and we construct sequences of loss vectors \u21131, \u21132, . . . , \u2113T such that \u2016\u21131\u2016\u2217 = \u2016\u21132\u2016\u2217 = \u00b7 \u00b7 \u00b7 = \u2016\u2113T\u2016\u2217 = 1 and Scale-Free MD has regret \u2126(T ) or worse.\nThe first counter-example is stated as Theorem 3 below; our proof is in Appendix E. The decision set is the whole space K = V and the regularizer is R(w) = 12\u2016w\u201622. Note that R(w) is 1-strongly convex with respect to \u2016 \u00b7 \u20162 and the dual norm of \u2016 \u00b7 \u20162 is \u2016 \u00b7 \u20162. The corresponding Bregman divergence is BR(u, v) = 12\u2016u\u2212 v\u201622. The counter-example constructs a sequence of unit-norm loss vectors in the onedimensional subspace spanned by the first vector of the standard orthnormal basis. On such a sequence, both versions of AdaGrad MD as well as Scale-Free MD are identical to gradient descent with step size 1/ \u221a t, i.e., they are identical Zinkevich\u2019s Generalized Infinitesimal Gradient Ascent (GIGA) algorithm [20]. Hence the lower bound applies to all these algorithms.\nTheorem 3 (First Counter-Example). Suppose K = V . For any T \u2265 42, there exists a sequence of loss vectors \u21131, \u21132, . . . , \u2113T \u2208 V \u2217 such that \u2016\u21131\u20162 = \u2016\u21132\u20162 = \u00b7 \u00b7 \u00b7 = \u2016\u2113T\u20162 = 1 and Scale-Free MD with regularizer R(w) = 12\u2016w\u201622, GIGA, and both versions of AdaGrad MD satisfy\nRegretT (0) \u2265 T 3/2\n20 .\nThe second counter-example is stated as Theorem 4 below; our proof is in Appendix E. The decision set is the d-dimensional probability simplex K = {w \u2208 Rd : wj \u2265 0, \u2211d j=1 wj = 1} and the regularizer is the negative entropy R(w) = \u2211d\nj=1 wj lnwj . Negative entropy is 1-strongly convex with respect to \u2016\u00b7\u20161 and the dual norm of \u2016\u00b7\u20161 is \u2016 \u00b7 \u2016\u221e. The corresponding Bregman divergence is the Kullback-Leibler divergence BR(u, v) = \u2211d j=1 uj ln(uj/vj). Note that despite that negative entropy is upper- and lower-bounded, Kullback-Leibler divergence can be arbitrarily large.\nTheorem 4 (Second Counter-Example). Let d \u2265 2, let V = Rd, and let K = {w \u2208 V : wj \u2265 0, \u2211d j=1 wj = 1} be the d-dimensional probability simplex. For any T \u2265 120, there exists a sequence of loss vectors \u21131, \u21132, . . . , \u2113T \u2208 V \u2217 such\nthat \u2016\u21131\u2016\u221e = \u2016\u21132\u2016\u221e = \u00b7 \u00b7 \u00b7 = \u2016\u2113T \u2016\u221e = 1 and Scale-Free MD with regularizer R(w) = \u2211d j=1 wj lnwj satisfies\nRegretT \u2265 T\n6 ."}, {"heading": "5. Lower Bound", "text": "We show a lower bound on the worst-case regret of any algorithm for OLO. The proof, presented in Appendix F, is a standard probabilistic argument.\nTheorem 5 (Lower Bound). Let K \u2286 V be any non-empty bounded closed convex subset. Let D = supu,v\u2208K \u2016u \u2212 v\u2016 be the diameter of K. Let A be any (possibly randomized) algorithm for OLO on K. Let T be any non-negative integer and let a1, a2, . . . , aT be any non-negative real numbers. There exists a sequence of vectors \u21131, \u21132, . . . , \u2113T in the dual vector space V\n\u2217 such that \u2016\u21131\u2016\u2217 = a1, \u2016\u21132\u2016\u2217 = a2, . . . , \u2016\u2113T \u2016\u2217 = aT and the regret of algorithm A satisfies\nRegretT \u2265 D\u221a 8\n\u221a\u221a\u221a\u221a T\u2211\nt=1\n\u2016\u2113t\u20162\u2217 . (4)\nThe upper bounds on the regret, which we have proved for our algorithms, have the same dependency on the norms of the loss vectors. However, a gap remains between the lower bound and the upper bounds.\nThe upper bound on regret of SOLO FTRL is of the formO( \u221a supv\u2208K f(v) \u2211T t=1 \u2016\u2113t\u20162\u2217)\nwhere f is any 1-strongly convex function with respect to \u2016 \u00b7 \u2016. The same upper bound is also achieved by FTRL with a constant learning rate when \u2211T t=1 \u2016\u2113t\u20162\u2217\nis known upfront [4, Chapter 2]. The lower bound is \u2126(D \u221a\u2211T\nt=1 \u2016\u2113t\u20162\u2217). The gap between D and \u221a supv\u2208K f(v) can be substantial. For example,\nif K is the probability simplex in Rd and f(w) = ln(d) + \u2211d\nj=1 wj lnwj is the shifted negative entropy, the \u2016 \u00b7 \u20161-diameter of K is 2, f is non-negative and 1-strongly convex with respect to \u2016 \u00b7 \u20161, but supv\u2208K f(v) = ln(d). On the other hand, if the norm \u2016 \u00b7 \u20162 = \u221a \u3008\u00b7, \u00b7\u3009 arises from an inner product \u3008\u00b7, \u00b7\u3009, the lower bound matches the upper bounds within a constant factor. The reason is that for any K with \u2016 \u00b7 \u20162-diameter D, the function f(w) = 12\u2016w\u2212w0\u201622, where w0 is an arbitrary point in K, is 1-strongly convex with respect to \u2016 \u00b7 \u20162 and satisfies that \u221a supv\u2208K f(v) \u2264 D. This leads to the following open problem (posed also in [37]):\nGiven a bounded convex set K and a norm \u2016 \u00b7 \u2016, construct a nonnegative function f : K \u2192 R that is 1-strongly convex with respect to \u2016 \u00b7 \u2016 and minimizes supv\u2208K f(v).\nAs shown in [38], the existence of f with small supv\u2208K f(v) is equivalent to the\nexistence of an algorithm for OLO with O\u0303( \u221a T supv\u2208K f(v)) regret assuming \u2016\u2113t\u2016\u2217 \u2264 1. The O\u0303 notation hides a polylogarithmic factor in T ."}, {"heading": "6. Conclusions", "text": "We have investigated scale-free algorithms for online linear optimization and we have shown that the scale-free property leads to algorithms which have optimal regret and do not need to know or assume anything about the sequence of loss vectors. In particular, the algorithms do not assume any upper or lower bounds on the norms of the loss vectors or the number of rounds.\nWe have designed a scale-free algorithm based on Follow The Regularizer Leader. Its regret with respect to any competitor u is\nO  f(u) \u221a\u221a\u221a\u221a T\u2211\nt=1\n\u2016\u2113t\u20162\u2217 +min{ \u221a T ,D} max\nt=1,2,...,T \u2016\u2113t\u2016\u2217\n  ,\nwhere f is any non-negative 1-strongly convex function defined on the decision set and D is the diameter of the decision set. The result makes sense even when the decision set is unbounded.\nA similar, but weaker result holds for a scale-free algorithm based onMirror Descent. However, we have also shown this algorithm to be strictly weaker than algorithms based on Follow The Regularizer Leader. Namely, we gave examples of regularizers for which the scale-free version of Mirror Descent has \u2126(T ) regret or worse.\nWe have proved an D\u221a 8 \u221a\u2211T t=1 \u2016\u2113\u20162\u2217 lower bound on the regret of any algorithm for any decision set with diameter D. Notice that with the regularizer f(u) = 12\u2016u\u201622 the regret of SOLO FTRL depends quadratically on the norm of the competitor \u2016u\u20162. There exist nonscale-free algorithms [39, 40, 41, 42, 43, 44] that have only a O(\u2016u\u20162 \u221a log \u2016u\u20162) or O(\u2016u\u20162 log \u2016u\u20162) dependency. These algorithms assume an a priori bound on the norm of the loss vectors. Recently, an algorithm that adapts to norms of loss vectors and has a O(\u2016u\u20162 log \u2016u\u20162) dependency was proposed [45]. However, the trade-off between the dependency on \u2016u\u20162 and the adaptivity to the norms of the loss vectors still remains to be explored."}, {"heading": "Acknowledgments", "text": "We thank an anonymous reviewer for suggesting a simpler proof of Lemma 7."}, {"heading": "Appendix A. Proofs for Preliminaries", "text": "Proof (Proof of Proposition 1). Let S = supu\u2208K f(u) and v \u2217 = argminv\u2208K f(v). The minimizer v\u2217 is guaranteed to exist by lower semi-continuity of f and compactness of K. The optimality condition for v\u2217 and 1-strong convexity of f imply that for any u \u2208 K,\nS \u2265 f(u)\u2212 f(v\u2217) \u2265 f(u)\u2212 f(v\u2217)\u2212 \u3008\u2207f(v\u2217), u\u2212 v\u2217\u3009 \u2265 1 2 \u2016u\u2212 v\u2217\u20162 .\nIn other words, \u2016u\u2212 v\u2217\u2016 \u2264 \u221a 2S. By the triangle inequality,\nD = sup u,v\u2208K \u2016u\u2212 v\u2016 \u2264 sup u,v\u2208K\n(\u2016u\u2212 v\u2217\u2016+ \u2016v\u2217 \u2212 v\u2016) \u2264 2 \u221a 2S = \u221a 8S .\nProof (Proof of Property 6 of Proposition 2). To bound Bf\u2217(x, y) we add a non-negative divergence term Bf\u2217(y, x).\nBf\u2217(x, y) \u2264 Bf\u2217(x, y) + Bf\u2217(y, x) = \u3008x\u2212 y,\u2207f\u2217(x) \u2212\u2207f\u2217(y)\u3009 \u2264 \u2016x\u2212 y\u2016\u2217 \u00b7 \u2016\u2207f\u2217(x) \u2212\u2207f\u2217(y)\u2016 \u2264 D\u2016x\u2212 y\u2016\u2217 ,\nwhere we have used Ho\u0308lder\u2019s inequality and property 7 of the Proposition.\nProof (Proof of Lemma 1). By the Fenchel-Young inequality,\nT\u2211\nt=1\n( R\u2217t+1(\u2212Lt)\u2212R\u2217t (\u2212Lt\u22121) ) = R\u2217T+1(\u2212LT )\u2212R\u22171(0)\n\u2265 \u2212\u3008LT , u\u3009 \u2212RT+1(u)\u2212R\u22171(0) = \u2212RT+1(u)\u2212R\u22171(0)\u2212 T\u2211\nt=1\n\u3008\u2113t, u\u3009 .\nWe add \u2211T\nt=1\u3008\u2113t, wt\u3009 to both sides and we obtain RegretT (u) on the right side. After rearrangement of the terms, we get an upper bound on the regret:\nRegretT (u) =\nT\u2211\nt=1\n\u3008\u2113t, wt\u3009 \u2212 T\u2211\nt=1\n\u3008\u2113t, u\u3009\n\u2264 RT+1(u) +R\u22171(0) + T\u2211\nt=1\n( R\u2217t+1(\u2212Lt)\u2212R\u2217t (\u2212Lt\u22121) + \u3008\u2113t, wt\u3009 ) .\nBy Proposition 2, property 2, we have wt = \u2207R\u2217t (\u2212Lt\u22121) and therefore we can rewrite the sum in last expression as\nT\u2211\nt=1\nR\u2217t+1(\u2212Lt)\u2212R\u2217t (\u2212Lt\u22121) + \u3008\u2113t, wt\u3009\n=\nT\u2211\nt=1\nR\u2217t+1(\u2212Lt)\u2212R\u2217t (\u2212Lt\u22121) + \u3008\u2113t,\u2207R\u2217t (\u2212Lt\u22121)\u3009\n= T\u2211\nt=1\nR\u2217t (\u2212Lt)\u2212R\u2217t (\u2212Lt\u22121) + \u3008\u2113t,\u2207R\u2217t (\u2212Lt\u22121)\u3009 \u2212R\u2217t (\u2212Lt) +R\u2217t+1(\u2212Lt)\n=\nT\u2211\nt=1\nBR\u2217 t (\u2212Lt,\u2212Lt\u22121)\u2212R\u2217t (\u2212Lt) +R\u2217t+1(\u2212Lt) .\nThis finishes the proof."}, {"heading": "Appendix B. AdaFTRL", "text": "In this section, we show that it is possible to derive a scale-free algorithm different from SOLO FTRL. We generalize the AdaHedge algorithm [25] to the OLO setting, showing that it retains its scale-free property. We call the resulting algorithm AdaFTRL. The analysis is very general and based on general properties of strongly convex functions, rather than specific properties of the entropic regularizer as in the original analysis of AdaHedge.\nAssume that K is bounded and that R : K \u2192 R is a strongly convex lower semi-continuous function bounded from above. We instantiate Algorithm 1 with\nthe sequence of regularizers\nRt(w) = \u2206t\u22121R(w) where \u2206t = t\u2211\ni=1\n\u2206i\u22121BR\u2217 ( \u2212 Li \u2206i\u22121 ,\u2212Li\u22121 \u2206i\u22121 ) . (B.1)\nThe sequence {\u2206t}\u221et=0 is non-negative and non-decreasing. Also, \u2206t as a function of \u21131, \u21132, . . . , \u2113t is positive homogeneous of degree one, making the algorithm scale-free.\nIf \u2206i\u22121 = 0, we define \u2206i\u22121BR\u2217( \u2212Li\u2206i\u22121 , \u2212Li\u22121 \u2206i\u22121 ) as lima\u21920+ aBR\u2217(\u2212Lia , \u2212Li\u22121 a ) which always exists and is finite; see Lemma 9 in Appendix C. Similarly, when \u2206t\u22121 = 0, we define wt = argminw\u2208K\u3008Lt\u22121, w\u3009 where ties among minimizers are broken by taking the one with the smallest value of R(w), which is unique due to strong convexity. As we show in Lemma 8 in Appendix C, this is the same as wt = lima\u21920+ argminw\u2208K(\u3008Lt\u22121, w\u3009+ aR(w)).\nOur main result is an O( \u221a\u2211T\nt=1 \u2016\u2113t\u20162\u2217) upper bound on the regret of the algorithm after T rounds, without the need to know beforehand an upper bound on \u2016\u2113t\u2016\u2217. We prove the theorem in Appendix B.1.\nTheorem 6 (Regret Bound). Suppose K \u2286 V is a non-empty bounded closed convex set. Let D = supx,y\u2208K \u2016x \u2212 y\u2016 be its diameter with respect to a norm \u2016 \u00b7 \u2016. Suppose that the regularizer R : K \u2192 R is a non-negative lower semicontinuous function that is \u03bb-strongly convex with respect to \u2016 \u00b7\u2016 and is bounded from above. The regret of AdaFTRL satisfies\nRegretT (u) \u2264 \u221a 3max { D,\n1\u221a 2\u03bb\n} \u221a\u221a\u221a\u221a T\u2211\nt=1\n\u2016\u2113t\u20162\u2217 (1 +R(u)) .\nThe regret bound can be optimized by choosing the optimal multiple of the regularizer. Namely, we choose regularizer of the form \u03bbf(w) where f(w) is 1-strongly convex and optimize over \u03bb. The result of the optimization is the following corollary.\nCorollary 3 (Regret Bound). Suppose K \u2286 V is a non-empty bounded closed convex set. Suppose f : K \u2192 R is a non-negative lower semi-continuous function that is 1-strongly convex with respect to \u2016 \u00b7 \u2016 and is bounded from above. The regret of AdaFTRL with regularizer\nR(w) = f(w)\n16 \u00b7 supv\u2208K f(v) satisfies RegretT \u2264 5.3 \u221a\u221a\u221a\u221asup v\u2208K f(v) T\u2211\nt=1\n\u2016\u2113t\u20162\u2217 .\nProof. Let S = supv\u2208K f(v). Theorem 6 applied to the regularizer R(w) = c S f(w) and Proposition 1 gives\nRegretT \u2264 \u221a 3(1 + c)max {\u221a 8,\n1\u221a 2c\n} \u221a\u221a\u221a\u221aS T\u2211\nt=1\n\u2016\u2113t\u20162\u2217 .\nIt remains to find the minimum of g(c) = \u221a 3(1 + c)max{ \u221a 8, 1/ \u221a 2c}. The function g is strictly convex on (0,\u221e) and has minimum at c = 1/16 and g( 116 ) = \u221a 3(1 + 116 ) \u221a 8 \u2264 5.3.\nAppendix B.1. Proof of Regret Bound for AdaFTRL Lemma 5 (Initial Regret Bound). AdaFTRL satisfies, for any u \u2208 K and any T \u2265 0, RegretT (u) \u2264 (1 +R(u))\u2206T . Proof. Recall from (B.1) that Rt(w) = \u2206t\u22121R(w). Since R is non-negative, {Rt}\u221et=1 is non-decreasing. Hence, R\u2217t (\u2113) \u2265 R\u2217t+1(\u2113) for every \u2113 \u2208 V \u2217 and thus R\u2217t (\u2212Lt)\u2212R\u2217t+1(\u2212Lt) \u2265 0. So, by Lemma 1,\nRegretT (u) \u2264 RT+1(u) +R\u22171(0) + T\u2211\nt=1\nBR\u2217 t (\u2212Lt,\u2212Lt\u22121) . (B.2)\nTechnically, (B.2) is not justified since Rt might not be strongly convex. This happens when \u2206t\u22121 = 0. In order to justify (B.2), we consider a different algorithm that initializes \u22060 = \u01eb where \u01eb > 0; that ensures that \u2206t\u22121 > 0 and Rt is strongly convex. Applying Lemma 1 and then taking limit \u01eb \u2192 0, yields (B.2).\nSince, BR\u2217 t (u, v) = \u2206t\u22121BR\u2217( u\u2206t\u22121 , v \u2206t\u22121 ) by definition of Bregman diver-\ngence and property 8 of Proposition 2, we have \u2211T\nt=1 BR\u2217t (\u2212Lt,\u2212Lt\u22121) = \u2206T . Lemma 6 (Recurrence). Let D = supu,v\u2208K \u2016u \u2212 v\u2016 be the diameter of K. The sequence {\u2206t}\u221et=1 generated by AdaFTRL satisfies for any t \u2265 1,\n\u2206t \u2264 \u2206t\u22121 +min { D\u2016\u2113t\u2016\u2217,\n\u2016\u2113t\u20162\u2217 2\u03bb\u2206t\u22121\n} .\nProof. By definition, \u2206t satisfies the recurrence\n\u2206t = \u2206t\u22121 +\u2206t\u22121BR\u2217 ( \u2212 Lt \u2206t\u22121 ,\u2212Lt\u22121 \u2206t\u22121 ) .\nUsing parts 4 and 6 of Proposition 2, we can upper bound BR\u2217 ( \u2212 Lt\u2206t\u22121 ,\u2212 Lt\u22121 \u2206t\u22121 ) with two different quantities. Taking the minimum of the two quantities finishes the proof.\nThe recurrence of Lemma 6 can be simplified. Defining\nat = \u2016\u2113t\u2016\u2217max { D,\n1\u221a 2\u03bb\n} ,\nwe get a recurrence\n\u2206t \u2264 \u2206t\u22121 +min { at,\na2t \u2206t\u22121\n} .\nThe next lemma solves this recurrence, by giving an explicit upper bound on \u2206T in terms of a1, a2, . . . , aT .\nLemma 7 (Solution of the Recurrence). Let {at}\u221et=1 be any sequence of non-negative real numbers. Suppose that {\u2206t}\u221et=0 is a sequence of non-negative real numbers satisfying\n\u22060 = 0 and \u2206t \u2264 \u2206t\u22121 +min { at,\na2t \u2206t\u22121\n} for any t \u2265 1 .\nThen, for any T \u2265 0,\n\u2206T \u2264 \u221a\u221a\u221a\u221a3 T\u2211\nt=1\na2t .\nProof. Observe that\n\u22062T = T\u2211\nt=1\n\u22062t \u2212\u22062t\u22121 = T\u2211\nt=1\n(\u2206t \u2212\u2206t\u22121)2 + 2(\u2206t \u2212\u2206t\u22121)\u2206t\u22121 .\nWe bound each term in the sum separately. The left term of the minimum inequality in the definition of \u2206t gives\n(\u2206t \u2212\u2206t\u22121)2 \u2264 a2t ,\nwhile the right term gives\n2(\u2206t \u2212\u2206t\u22121)\u2206t\u22121 \u2264 2a2t .\nSo, we conclude\n\u22062T \u2264 3 T\u2211\nt=1\na2t .\nTheorem 6 follows from Lemmas 5, 6 and 7."}, {"heading": "Appendix C. Limits", "text": "In this section, we show that prediction of AdaFTRL is correctly defined when the regularizer is multiplied by zero.\nLemma 8 (Prediction for Zero Regularizer). Let K be non-empty bounded closed convex subset of a finite dimensional normed real vector space (V, \u2016 \u00b7 \u2016). Let R : K \u2192 R be strictly convex and lower semi-continuous, and let L \u2208 V \u2217. The limit\nlim \u03b7\u2192+\u221e argmin w\u2208K\n( \u3008L,w\u3009+ 1\n\u03b7 R(w)\n) (C.1)\nexists and it is equal to the unique minimizer of R(w) over the set (of minimizers) {\nw \u2208 K : \u3008L,w\u3009 = inf v\u2208K\n\u3008L, v\u3009 } .\nBefore we give the proof, we illustrate the lemma on a simple example. Let K = [\u22121, 1]2 be a closed square in R2 and let R(w) = \u2016w\u201622. Let L = (1, 0). The minimizers are\nargmin w\u2208K\n\u3008L,w\u3009 = {(\u22121, y) : y \u2208 [\u22121, 1]} .\nThe minimizer with the smallest value of R(w) is (\u22121, 0). Hence the lemma implies that\nlim \u03b7\u2192+\u221e argmin w\u2208K\n( \u3008L,w\u3009+ 1\n\u03b7 \u2016w\u201622\n) = (\u22121, 0) .\nProof (Proof of Lemma 8). Without loss of generality, we can assume that R(w) is non-negative for any w \u2208 K. For otherwise, we can replace R(w) with R\u2032(w) = R(w)\u2212 infv\u2208K R(v).\nSince K is a non-empty bounded closed convex subset of a finite dimensional normed vector space, it is compact and r\u2217 = minw\u2208K\u3008L,w\u3009 exists and is attained at some w \u2208 K. Consider the hyperplane\nH = {w \u2208 V : \u3008L,w\u3009 = r\u2217} .\nThe intersection H \u2229K is a non-empty compact convex set. Let\nv\u2217 = argmin v\u2208K\u2229H R(v) .\nThe existence of v\u2217 follows from compactness ofH\u2229K and lower semi-continuity of R(v). Uniqueness of v\u2217 follows from strict convexity of R(v). We show that the limit (C.1) equals v\u2217.\nBy the definition of H ,\nv\u2217 \u2208 argmin w\u2208K \u3008L,w\u3009 . (C.2)\nLet S = {w \u2208 K : R(w) \u2264 R(v\u2217)}. Since R(w) is lower semi-continuous S is closed. Since R(w) is strictly convex, S \u2229H = {v\u2217}.\nFor any \u03b7 > 0, let\nw(\u03b7) = argmin w\u2208K\n( \u3008L,w\u3009+ 1\n\u03b7 R(w)\u3009\n) .\nWe prove that w(\u03b7) \u2208 S. Indeed, by optimality of v\u2217 and w(\u03b7),\n1 \u03b7 R(w(\u03b7)) + \u3008L,w(\u03b7)\u3009 \u2264 1 \u03b7 R(v\u2217) + \u3008L, v\u2217\u3009 \u2264 1 \u03b7 R(v\u2217) + \u3008L,w(\u03b7)\u3009\nand hence R(w(\u03b7)) \u2264 R(v\u2217). By non-negativity of R and optimality of w(\u03b7) we have\n\u3008L,w(\u03b7)\u3009 \u2264 \u3008L,w(\u03b7)\u3009 + 1 \u03b7 R(w(\u03b7)) \u2264 \u3008L, v\u2217\u3009+ 1 \u03b7 R(v\u2217) .\nTaking the limit \u03b7 \u2192 +\u221e, we see that\nlim \u03b7\u2192+\u221e \u3008L,w(\u03b7)\u3009 \u2264 lim \u03b7\u2192+\u221e\n( \u3008L, v\u2217\u3009+ 1\n\u03b7 R(v\u2217)\n) = \u3008L, v\u2217\u3009 .\nFrom (C.2) we have \u3008L, v\u2217\u3009 \u2264 \u3008L,w\u3009 for any w, and therefore\nlim \u03b7\u2192+\u221e\n\u3008L,w(\u03b7)\u3009 = \u3008L, v\u2217\u3009 . (C.3)\nConsider any sequence {\u03b7t}\u221et=1 of positive numbers approaching +\u221e. Since K is compact, w(\u03b7t) has a convergent subsequence. Thus {w(\u03b7t)}\u221et=1 has at least one accumulation point; let w\u2217 be any of them. We will show that w\u2217 = v\u2217.\nConsider a subsequence {\u03bet}\u221et=1 of {\u03b7t}\u221et=1 such that limt\u2192\u221e w(\u03bet) = w\u2217. Since w(\u03bet) \u2208 S and S is closed, w\u2217 \u2208 S. From (C.3) we have \u3008L,w\u2217\u3009 = \u3008L, v\u2217\u3009 and hence w\u2217 \u2208 H . Thus w\u2217 \u2208 S \u2229H . Since v\u2217 is the only point in S \u2229H we must have w\u2217 = v\u2217.\nLemma 9 (Limit of Bregman Divergence). Let K be a non-empty bounded closed convex subset of a finite dimensional normed real vector space (V, \u2016 \u00b7 \u2016). Let R : K \u2192 R be a strongly convex lower semi-continuous function bounded from above. Then, for any x, y \u2208 V \u2217,\nlim a\u21920+\naBR\u2217(x/a, y/a) = \u3008x, u \u2212 v\u3009\nwhere\nu = lim a\u21920+ argmin w\u2208K (aR(w)\u2212 \u3008x,w\u3009) and v = lim a\u21920+ argmin w\u2208K (aR(w) \u2212 \u3008y, w\u3009) .\nProof. Using property 3 of Proposition 2 we can write the divergence\naBR\u2217(x/a, y/a) = aR\u2217(x/a)\u2212 aR\u2217(y/a)\u2212 \u3008x\u2212 y,\u2207R\u2217(y/a)\u3009 = a [\u3008x/a,\u2207R\u2217(x/a)\u3009 \u2212R(\u2207R\u2217(x/a))]\n\u2212 a [\u3008y/a,\u2207R\u2217(y/a)\u3009 \u2212R(\u2207R\u2217(y/a))]\u2212 \u3008x\u2212 y,\u2207R\u2217(y/a)\u3009 = \u3008x,\u2207R\u2217(x/a)\u2212\u2207R\u2217(y/a)\u3009 \u2212 aR(\u2207R\u2217(x/a)) + aR(\u2207R\u2217(y/a)) .\nProperty 2 of Proposition 2 implies that\nu = lim a\u21920+ \u2207R\u2217(x/a) = lim a\u21920+ argmin w\u2208K (aR(w) \u2212 \u3008x,w\u3009) ,\nv = lim a\u21920+ \u2207R\u2217(y/a) = lim a\u21920+ argmin w\u2208K (aR(w) \u2212 \u3008y, w\u3009) .\nThe limits on the right exist according to Lemma 8. They are simply the minimizers u = argminw\u2208K \u2212\u3008x,w\u3009 and v = argminw\u2208K \u2212\u3008y, w\u3009 where ties in argmin are broken according to smaller value of R(w).\nBy assumption R(w) is upper bounded. It is also lower bounded, since it is defined on a compact set and it is lower semi-continuous. Thus,\nlim a\u21920+\naBR\u2217(x/a, y/a)\n= lim a\u21920+\n\u3008x,\u2207R\u2217(x/a)\u2212\u2207R\u2217(y/a)\u3009 \u2212 aR(\u2207R\u2217(x/a)) + aR(\u2207R\u2217(y/a))\n= lim a\u21920+\n\u3008x,\u2207R\u2217(x/a)\u2212\u2207R\u2217(y/a)\u3009 = \u3008x, u\u2212 v\u3009 ."}, {"heading": "Appendix D. Proofs for SOLO FTRL", "text": "Proof (Proof of Lemma 4). We use the inequality x/ \u221a x+ y \u2264 2(\u221ax+ y\u2212\u221a\ny) which holds for non-negative x, y that are not both zero. Substituting\nx = at and y = \u2211t\u22121 i=1 ai, we get that for any t \u2265 1,\nat\u221a\u2211t i=1 ai \u2264 2\n\u221a\u221a\u221a\u221a t\u2211\ni=1\nai \u2212 2\n\u221a\u221a\u221a\u221a t\u22121\u2211\ni=1\nai .\nSumming the above inequality over all t = 1, 2, . . . , T , the right side telescopes\nto 2 \u221a\u2211T t=1 at."}, {"heading": "Appendix E. Proofs for Scale-Free Mirror Descent", "text": "Proof (Proof of Lemma 2). Let\n\u03a8t+1(w) = \u3008\u2113t, w\u3009+ BRt(w,wt) = \u3008\u2113t, w\u3009+Rt(w) \u2212Rt(wt)\u2212 \u3008\u2207Rt(wt), w \u2212 wt\u3009 .\nThen, wt+1 = argminw\u2208K \u03a8t+1(w). Note that \u2207\u03a8t+1(w) = \u2113t + \u2207Rt(w) \u2212 \u2207Rt(wt). The optimality condition for wt+1 states that \u3008\u2207\u03a8t+1(wt+1), u \u2212 wt+1\u3009 \u2265 0 for all u \u2208 K. Written explicitly,\n\u3008\u2113t +\u2207Rt(wt+1)\u2212\u2207Rt(wt), u\u2212 wt+1\u3009 \u2265 0 .\nAdding \u3008\u2113t, wt+1 \u2212 wt\u3009 to both sides and rearranging, we have\n\u3008\u2113t, wt \u2212 u\u3009 \u2264 \u3008\u2207Rt(wt+1)\u2212\u2207Rt(wt), u\u2212 wt+1\u3009+ \u3008\u2113t, wt \u2212 wt+1\u3009 = \u3008\u2113t, wt \u2212 wt+1\u3009 \u2212 BRt(wt+1, wt) + BRt(u,wt)\u2212 BRt(u,wt+1) .\nThe last equality follows by from definition of Bregman divergence. Summation over all t = 1, 2, . . . , T gives the final regret bound.\nProof (Proof of Theorem 2). Let \u03b7t = 1\u221a\u2211\nt i=1 \u2016\u2113i\u20162\u2217 . We define \u03b70 = +\u221e and 1/\u03b70 = 0. Hence Rt(w) =\n1 \u03b7t R(w). Since Rt is \u03bb \u03b7t -strongly convex, we have\n\u3008\u2113t, wt \u2212 wt+1\u3009 \u2212 BRt(wt+1, wt) \u2264 \u2016\u2113t\u2016\u2217 \u00b7 \u2016wt \u2212 wt+1\u2016 \u2212 \u03bb\n2\u03b7t \u2016wt \u2212 wt+1\u20162\n\u2264 max z\u2208R\n( \u2016\u2113t\u2016\u2217z \u2212 \u03bb 2\u03b7t z2 )\n= \u03b7t 2\u03bb \u2016\u2113t\u20162\u2217 .\nCombining the last inequality with Lemma 2, we have\nRegretT (u) \u2264 T\u2211\nt=1\n\u03b7t 2\u03bb\n\u2016\u2113t\u20162\u2217 + T\u2211\nt=1\n[BRt(u,wt)\u2212 BRt(u,wt+1)] .\nSince Rt(w) = 1 \u03b7t R(w), we have\nRegretT (u) \u2264 1\n2\u03bb\nT\u2211\nt=1\n\u03b7t\u2016\u2113t\u20162\u2217 + T\u2211\nt=1\n1 \u03b7t [BR(u,wt)\u2212 BR(u,wt+1)]\n\u2264 1 2\u03bb\nT\u2211\nt=1\n\u03b7t\u2016\u2113t\u20162\u2217 + T\u2211\nt=1\nBR(u,wt) ( 1\n\u03b7t \u2212 1 \u03b7t\u22121\n)\n\u2264 1 2\u03bb\nT\u2211\nt=1 \u2016\u2113t\u20162\u2217\u221a\u2211t i=1 \u2016\u2113i\u20162\u2217 + sup v\u2208K BR(u, v) T\u2211 t=1\n( 1\n\u03b7t \u2212 1 \u03b7t\u22121\n)\n\u2264 1 \u03bb\n\u221a\u221a\u221a\u221a T\u2211\nt=1\n\u2016\u2113t\u20162\u2217 + sup v\u2208K BR(u, v)\n\u221a\u221a\u221a\u221a T\u2211\nt=1\n\u2016\u2113t\u20162\u2217 (By Lemma 4)\n=\n( 1\n\u03bb + sup v\u2208K BR(u, v)\n) \u221a\u221a\u221a\u221a T\u2211\nt=1\n\u2016\u2113t\u20162\u2217 .\nProof (Proof of Theorem 3). We assume d = 1. For d \u2265 2, we simply embed the one-dimensional loss vectors into the first coordinate of Rd. Consider the sequence\n(\u21131, \u21132, . . . , \u2113T ) = (\u22121,\u22121, . . . ,\u22121\ufe38 \ufe37\ufe37 \ufe38 \u2308T/2\u2309 ,+1,+1, . . . ,+1\ufe38 \ufe37\ufe37 \ufe38 \u230aT/2\u230b ) .\nThe first half consists of \u22121\u2019s, the second of +1\u2019s. For t \u2264 \u2308T/2\u2309\nwt+1 = wt + 1\u221a t .\nUnrolling the recurrence and using w1 = 0 we get\nwt = t\u22121\u2211\ni=1\n1\u221a i\n(for t \u2264 \u2308T/2\u2309+ 1) .\nOn the other hand, for t \u2265 \u2308T/2\u2309+ 1, we have\nwt+1 = wt \u2212 1\u221a t .\nUnrolling the recurrence up to w\u2308T/2\u2309+1 we get\nwt = w\u2308T/2\u2309+1 \u2212 t\u22121\u2211\ni=\u2308T/2\u2309+1\n1\u221a i =\n\u2308T/2\u2309\u2211\ni=1\n1\u221a i \u2212\nt\u22121\u2211\ni=\u2308T/2\u2309+1\n1\u221a i\n(for t \u2265 \u2308T/2\u2309+ 1) .\nWe are ready to lower bound the regret.\nRegretT (0) =\nT\u2211\nt=1\n\u2113twt\n= \u2212 \u2308T/2\u2309\u2211\nt=1\nwt +\nT\u2211\nt=\u2308T/2\u2309+1 wt\n= \u2212 \u2308T/2\u2309\u2211\nt=1\nt\u22121\u2211\ni=1\n1\u221a i +\nT\u2211\nt=\u2308T/2\u2309+1\n  \u2308T/2\u2309\u2211\ni=1\n1\u221a i\n\u2212 t\u22121\u2211\ni=\u2308T/2\u2309+1\n1\u221a i\n\n\n= \u2212 \u2308T/2\u2309\u2211\ni=1\n\u2308T/2\u2309 \u2212 i\u221a i\n+ \u230aT/2\u230b \u2308T/2\u2309\u2211\ni=1\n1\u221a i\n\u2212 T\u2211\ni=\u2308T/2\u2309+1\nT \u2212 i\u221a i\n= \u2212 \u2308T/2\u2309\u2211\ni=1\n\u2308T/2\u2309 \u2212 \u230aT/2\u230b\u221a i +\nT\u2211\ni=1\n\u221a i \u2212 T T\u2211\ni=\u2308T/2\u2309+1\n1\u221a i\n\u2265 \u2212 \u2308T/2\u2309\u2211\ni=1\n1\u221a i +\nT\u2211\ni=1\n\u221a i \u2212 T T\u2211\ni=\u2308T/2\u2309+1\n1\u221a i\n\u2265 \u22121\u2212 \u222b \u2308T/2\u2309\ni=1\n1\u221a x dx +\n\u222b T\n0\n\u221a x dx \u2212 T\n\u222b T\n\u2308T/2\u2309\n1\u221a x dx\n= \u22121\u2212 2 (\u221a \u2308T/2\u2309 \u2212 1 ) + 2\n3 T 3/2 \u2212 2T\n(\u221a T \u2212 \u221a \u2308T/2\u2309 )\n\u2265 1\u2212 2 \u221a \u2308T/2\u2309+\n( 2\n3 \u2212 2 +\n\u221a 2 ) T 3/2 .\nThe last expression is \u2126(T 3/2) with dominant term (23\u22122+ \u221a 2)T 3/2 \u2248 0.08\u00b7T 3/2. For any T \u2265 42, the expression is lower bounded by 120T 3/2.\nProof (Proof of Theorem 4). Let e1, e2, . . . , ed be the standard orthnormal basis of Rd. Consider the sequence of loss vectors\n(\u21131, \u21132, . . . , \u2113T ) = (\u2212e1,\u2212e1, . . . ,\u2212e1\ufe38 \ufe37\ufe37 \ufe38 \u2308T/3\u2309 ,\u2212e2,\u2212e2, . . . ,\u2212e2\ufe38 \ufe37\ufe37 \ufe38 \u230a2T/3\u230b ) .\nFirst, for any t \u2265 \u2308T/3\u2309+ 1,\nwt,1 wt,2\n= exp(\u2212\u2211t\u22121i=1 \u2113i,1/ \u221a i)\nexp(\u2212 \u2211t\u22121 i=1 \u2113i,2/ \u221a i)\n= exp(\n\u2211\u2308T/3\u2309 i=1 1/ \u221a i)\nexp( \u2211t i=\u2308T/3\u2309+1 1/ \u221a i)\n\u2265 exp( \u2211\u2308T/3\u2309 i=1 1/ \u221a i)\nexp( \u2211T i=\u2308T/3\u2309+1 1/ \u221a i)\n= exp\n  \u2308T/3\u2309\u2211\ni=1\n1\u221a i\n\u2212 T\u2211\ni=\u2308T/3\u2309+1 1/\n\u221a i\n\n\n\u2265 exp (\u222b \u2308T/3\u2309+1\n1\ndx\u221a x\n\u2212 \u222b T\n\u2308T/3\u2309\ndx\u221a x\n)\n= exp ( 2 \u221a \u2308T/3\u2309+ 1\u2212 2\u2212 (2 \u221a T \u2212 2 \u221a \u2308T/3\u2309) ) \u2265 exp ((\n4\u221a 3 \u2212 2\n)\u221a T \u2212 2 )\n\u2265 4 ,\nwhere the last inequality follows from the fact that exp ((\n4\u221a 3 \u2212 2\n)\u221a T \u2212 2 ) is\nan increasing function of T and the inequality can be easily verified for T = 120. Since wt,1 + wt,1 \u2264 1 and wt,1 \u2265 0 and wt,2 \u2265 0, the inequality wt,1/wt,2 \u2265 4 implies that\nwt,2 \u2264 1\n5 (for any t \u2265 \u2308T/3\u2309+ 1) .\nNow, we lower bound the regret. Since T \u2265 120,\nRegretT \u2265 RegretT (e2)\n= T\u2211\nt=1\n\u3008\u2113t, wt\u3009 \u2212 T\u2211\nt=1\n\u3008\u2113t, e2\u3009\n= \u2212 \u2308T/3\u2309\u2211\nt=1\nwt,1 \u2212 T\u2211\nt=\u2308T/3\u2309+1 wt,2 + \u230a2T/3\u230b\n\u2265 \u2212\u2308T/3\u2309 \u2212 1 5 \u230a2T/3\u230b+ \u230a2T/3\u230b \u2265 \u2212T/3\u2212 1\u2212 2T/15 + 2T/3\u2212 1 = T/5\u2212 2 \u2265 T/6 ."}, {"heading": "Appendix F. Lower Bound Proof", "text": "Proof (Proof of Theorem 5). Pick x, y \u2208 K such that \u2016x\u2212 y\u2016 = D. This is possible sinceK is compact. Since \u2016x\u2212y\u2016 = sup{\u3008\u2113, x\u2212y\u3009 : \u2113 \u2208 V \u2217, \u2016\u2113\u2016\u2217 = 1} and the set {\u2113 \u2208 V \u2217 : \u2016\u2113\u2016\u2217 = 1} is compact, there exists \u2113 \u2208 V \u2217 such that\n\u2016\u2113\u2016\u2217 = 1 and \u3008\u2113, x\u2212 y\u3009 = \u2016x\u2212 y\u2016 = D .\nLet Z1, Z2, . . . , ZT be i.i.d. Rademacher variables, that is, Pr[Zt = +1] = Pr[Zt = \u22121] = 1/2. Let \u2113t = Ztat\u2113. Clearly, \u2016\u2113t\u2016\u2217 = at. The lemma will be proved if we show that (4) holds with positive probability. We show a stronger statement that the inequality holds in expectation, i.e., E[RegretT ] \u2265 D\u221a 8 \u221a\u2211T t=1 a 2 t . Indeed,\nE [RegretT ] \u2265 E [ T\u2211\nt=1\n\u3008\u2113t, wt\u3009 ] \u2212E [ min\nu\u2208{x,y}\nT\u2211\nt=1\n\u3008\u2113t, u\u3009 ]\n= E\n[ T\u2211\nt=1\nZtat\u3008\u2113, wt\u3009 ] +E [ max\nu\u2208{x,y}\nT\u2211\nt=1\n\u2212Ztat\u3008\u2113, u\u3009 ]\n= E [ max\nu\u2208{x,y}\nT\u2211\nt=1\n\u2212Ztat\u3008\u2113, u\u3009 ]\n= E [ max\nu\u2208{x,y}\nT\u2211\nt=1\nZtat\u3008\u2113, u\u3009 ]\n= 1\n2 E\n[ T\u2211\nt=1\nZtat\u3008\u2113, x+ y\u3009 ] + 1\n2 E [\u2223\u2223\u2223\u2223\u2223 T\u2211\nt=1\nZtat\u3008\u2113, x\u2212 y\u3009 \u2223\u2223\u2223\u2223\u2223 ]\n= D\n2 E [\u2223\u2223\u2223\u2223\u2223 T\u2211\nt=1\nZtat \u2223\u2223\u2223\u2223\u2223 ]\n\u2265 D\u221a 8\n\u221a\u221a\u221a\u221a T\u2211\nt=1\na2t ,\nwhere we used that E[Zt] = 0, the fact that distributions of Zt and \u2212Zt are the same, the formula max{a, b} = (a+ b)/2 + |a\u2212 b|/2, and Khinchin\u2019s inequality in the last step (Lemma A.9 in [2])."}], "references": [], "referenceMentions": [], "year": 2016, "abstractText": "<lb>We design and analyze algorithms for online linear optimization that have opti-<lb>mal regret and at the same time do not need to know any upper or lower bounds<lb>on the norm of the loss vectors. Our algorithms are instances of the Follow the<lb>Regularized Leader (FTRL) and Mirror Descent (MD) meta-algorithms. We<lb>achieve adaptiveness to the norms of the loss vectors by scale invariance, i.e.,<lb>our algorithms make exactly the same decisions if the sequence of loss vectors is<lb>multiplied by any positive constant. The algorithm based on FTRL works for<lb>any decision set, bounded or unbounded. For unbounded decisions sets, this is<lb>the first adaptive algorithm for online linear optimization with a non-vacuous<lb>regret bound. In contrast, we show lower bounds on scale-free algorithms based<lb>on MD on unbounded domains.", "creator": "LaTeX with hyperref package"}}}