{"id": "1601.06579", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "25-Jan-2016", "title": "A Kernel Independence Test for Geographical Language Variation", "abstract": "Quantifying the degree of spatial dependence for linguistic variables is a key task for analyzing dialectal variation. However, existing approaches have important drawbacks. First, they make unjustified assumptions about the nature of spatial variation: some assume that the geographical distribution of linguistic variables is Gaussian, while others assume that linguistic variation is aligned to pre-defined geopolitical units such as states or counties. The results of these tests demonstrate that linguistic variables are indeed Gaussian.\n\n\n\nThe current problem with this problem is that linguistic variables are Gaussian. If an arbitrary group of variables is Gaussian, it is not Gaussian, and thus the only group of variables that represent Gaussian can be Gaussian, although one can argue that the statistical validity of the tests is much less likely to be accurate. However, while the statistical validity of these tests is likely to be weak, it is likely to be less than 1 percent, since it can be found to be much weaker than the general statistical validity of the tests.\nTherefore, it seems reasonable to conclude that the Gaussian-correcting method has a very small effect on the accuracy of the tests in general and does not prove that statistical validity has much to do with the Gaussian-correcting method.\nFor example, the study of linguistic variables was conducted with two different populations: the second group consisted of people who were not familiar with English or French but who had recently settled into Western Europe. The third group consisted of people who are not familiar with Russian or any other dialect. As a result, the results of this test for linguistic variables are not comparable to the results of the results of the previous tests (see supplementary sources). Therefore, the results of this test are not consistent with the results of the earlier studies (see supplementary sources).\nGiven that the analysis of linguistic variables has been conducted using multiple groups of variables (for example, the previous tests (see supplementary sources) and with multiple different groups, we are not able to test whether the general statistical validity of the tests with different groups has changed significantly in recent years (for example, the original tests (see supplementary sources) and between the two groups after which the standard deviation for a particular class of variables remained stable (for example, the original tests (see supplementary sources) and between the two groups after which the standard deviation for a particular class of variables remained stable.\nFurthermore, the results of the previous tests (and the results of the previous test for a particular class of variables) are not consistent with the results of the previous tests (and", "histories": [["v1", "Mon, 25 Jan 2016 12:45:59 GMT  (4262kb,D)", "http://arxiv.org/abs/1601.06579v1", "In submission. 22 pages"], ["v2", "Mon, 29 Aug 2016 13:16:42 GMT  (4739kb,D)", "http://arxiv.org/abs/1601.06579v2", "In submission. 26 pages"]], "COMMENTS": "In submission. 22 pages", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["dong nguyen", "jacob eisenstein"], "accepted": false, "id": "1601.06579"}, "pdf": {"name": "1601.06579.pdf", "metadata": {"source": "CRF", "title": "A Kernel Independence Test for Geographical Language Variation", "authors": ["Dong Nguyen", "Jacob Eisenstein"], "emails": [], "sections": [{"heading": "A Kernel Independence Test for Geographical", "text": "Language Variation\nDong Nguyen University of Twente\nJacob Eisenstein Georgia Institute of Technology\nQuantifying the degree of spatial dependence for linguistic variables is a key task for analyzing dialectal variation. However, existing approaches have important drawbacks. First, they make unjustified assumptions about the nature of spatial variation: some assume that the geographical distribution of linguistic variables is Gaussian, while others assume that linguistic variation is aligned to pre-defined geopolitical units such as states or counties. Second, they are not applicable to all types of linguistic data: some approaches apply only to frequencies, others to boolean indicators of whether a linguistic variable is present. We present a new method for measuring geographical language variation, which solves both of these problems. Our approach builds on reproducing kernel Hilbert space (RKHS) representations for nonparametric statistics, and takes the form of a test statistic that is computed from pairs of individual geotagged observations without aggregation into predefined geographical bins. We compare this test with prior work using synthetic data as well as a diverse set of real datasets: a corpus of Dutch tweets, a Dutch syntactic atlas, and a dataset of letters to the editor in North American newspapers. Our proposed test is shown to support robust inferences across a broad range of scenarios and types of data."}, {"heading": "1. Introduction", "text": "Figure 1 shows the geographical location of 1000 Twitter posts containing the word hella, an intensifier used in expressions like I got hella studying to do and my eyes got hella big [10]. While the word appears in major population centers throughout the United States, the map suggests that it enjoys a particularly high level of popularity on the west coast, in the area around San Francisco. But does this represent a real geographical difference in American English, or is it the result of chance fluctuation in a finite dataset?\nRegional variation of language has been extensively studied in sociolinguistics and dialectology [5, 15, 16, 21, 25, 32]. A common approach involves mapping the geographic distribution of a linguistic variable (e.g., the choice of soda, pop, or coke to refer to a soft drink) and identifying boundaries between regions based on the data. The identification of linguistic variables that exhibit regional variation is therefore the first step in many studies of regional dialects. Traditionally, this step has been based on the manual judgment of the researcher; depending on the quality of the researcher\u2019s intuitions, the most interesting or important variables might be missed.\nThe increasing amount of data available to study dialectal variation suggests a turn towards data-driven alternatives for variable selection. For example, researchers can mine social media data such as Twitter [8, 9] or product reviews [20] to identify and test thousands of dialectal variables. Despite the large scale of available data, the well-known \u201clong tail\u201d phenomenon of language ensures that there will be many potential variables with low counts. A statistical metric for comparing the strength of geographical associations across potential linguistic variables would allow linguists to\n\u00a9 2016 Association for Computational Linguistics\nar X\niv :1\n60 1.\n06 57\n9v 1\n[ cs\n.C L\n] 2\n5 Ja\nn 20\n16\ndetermine whether finite geographical samples \u2014 such as the one shown in Figure 1 \u2014 reveal a statistically meaningful association.\nThe use of statistical methods to analyze spatial dependence has been only lightly studied in sociolinguistics and dialectology. Relevant methods tend to employ classical statistics such as Moran\u2019s I [e.g., 15], Point Pattern Analysis [e.g., 21] and the Mantel Test [e.g., 28]. We review these approaches in section 2. In general, they suffer from two main weaknesses: they make unjustified assumptions about the nature of spatial variation, and they are applicable to only some forms of linguistic data. We now review these challenges in detail.\nAssumptions about spatial variation. Several existing methods assume that linguistic variation is aligned to pre-defined geopolitical units such as states or counties. For example, Moran\u2019s I is designed for comparing frequencies in data that has been geographically aggregated by bins, such as metropolitan statistical areas [15], cities [16, 17] and counties [32]. Computational linguistic studies make similar assumptions, relying on politicallydefined units [20], geodesic grids [34], KD-trees [27], Gaussians [9], and mixtures of Gaussians [19]. All such approaches sacrifice statistical power because linguistic \u201cisoglosses\u201d (the technical term for the geographical boundaries between linguistic features) need not align with politically-defined geographical units [25]. Depending on the definition of the geographical units, they may have dramatically varying populations; in low-populations units, frequency statistics may suffer from high variance, leading to inferential errors. While the Mantel Test does not employ geographic binning, it is a correlation-based statistic that assumes a linear relationship between geographical similarity and linguistic similarity. This assumption of linearity is refuted by both theoretical and empirical dialectological evidence [24], and will therefore limit the statistical power of both the Mantel Test and Moran\u2019s I.\nLack of applicability. A second problem with existing approaches is that they are not applicable to all types of linguistic data. For example, Moran\u2019s I is designed for datasets in which each geographical region is associated with a single frequency parameter, capturing the likelihood of one or another linguistic form; it is not even applicable to data in linguistic variables with three or more possible forms (e.g., soda/pop/coke). Conversely, in its original form, Point Pattern Analysis [21] is suitable only for binary or category data.\nOur approach. To address these limitations, we propose a new test statistic that builds on a rich and growing literature on kernel-based methods for non-parametric statistics [29]. In these methods, probability distributions, such as the distribution over geographical locations for each linguistic variable, are embedded in a Reproducing Kernel Hilbert space (RKHS). Specifically, we employ the Hilbert-Schmidt Independence Criterion [HSIC; 14], which can be seen as capturing covariance in a high-dimensional feature space. HSIC can be applied to both frequency and categorical data, requires no binning and makes no parametric assumptions about the form which spatial dependence will take. Because the approach is based on kernel similarity, it can be applied to any form of linguistic data, as long as an appropriate kernel function can be constructed.\nTo validate this approach, we compare it against three alternative spatial statistics: Moran\u2019s I, the Mantel test, and Point Pattern Analysis (PPA). For a controlled comparison, we use synthetic data to simulate different types of regional variation, and different types of linguistic data. This allows us to measure the capability of each approach to recover true geo-linguistic associations, and to avoid Type I errors even in noisy and sparse data. Next, we apply these approaches to three real linguistic datasets: a corpus of Dutch tweets, a Dutch syntactic atlas and letters to the editor in North American newspapers.\nTo summarize, the contributions of this article are:\n\u2022 We show how the recently-introduced HSIC test statistic can be applied to linguistic data. HSIC is a non-parametric test statistic, which can handle both frequency and categorical data, requires no discretization of geographic data, and is capable of detecting nonlinear geo-linguistic associations (section 2).\n\u2022 We use synthetic data to compare the power and calibration of HSIC against three alternatives: Moran\u2019s I, the Mantel Test, and Point Pattern Analysis (section 3).\n\u2022 We apply these methods to analyze dialectal variation in three empirical datasets, in both English and Dutch, across a variety of registers (section 4)."}, {"heading": "2. Methods", "text": "This section describes four methods for quantifying the degree of spatial dependence in an observed signal. The first three methods are included because they are used in linguistic papers on dialect: Moran\u2019s I [15], Point Pattern Analysis [21] and the Mantel test [28]. After describing these methods, we present the Hilbert-Schmidt Independence Criterion (HSIC), a kernel-based nonparametric statistic for measuring cross-covariance [14]. To our knowledge, this statistic has not previously been used in combination with linguistic data.\nWe define a consistent notation across methods. Let xi represent a scalar linguistic observation for unit i \u2208 {1 . . . n} (typically, the presence or frequency of a linguistic variable), and let yi represent a corresponding geolocation. For convenience, we define dij as the spatial distance between yi and yj . Suppose we have n observations, so that the data D = {(x1, y1), (x2, y2), . . . , (xn, yn)}. Our goal is to test the strength of association between X and Y , with a null hypothesis that there is no association."}, {"heading": "2.1 Moran\u2019s I", "text": "Grieve et al. [15] introduced the use of Moran\u2019s I [6, 22] in the study of dialectal variation. To define the statistic, let W = {wij}i,j\u2208{1...N} represent a spatial neighborhood matrix, such that larger values ofwij indicate greater proximity, andwii = 0. In their application of Moran\u2019s I to a corpus of letters-to-the-editor, Grieve et al. define W as,\nwij = { 1, dij < \u03c4, i 6= j 0, dij \u2265 \u03c4, or i = j\n(1)\nwhere \u03c4 is some critical threshold. Intuitively, the goal of Moran\u2019s I is to quantify whether observations xi and xj are more similar when wij = 1 than when wij = 0.\nMoran\u2019s I is based on a hypothesized autoregressive process X = \u03c1WX + , where X is a vector of the linguistic observations x1, . . . xn, and is a vector of uncorrelated noise. Since X and W are given, the estimation problem is to find \u03c1 so as to minimize the magnitude of . To take a probabilistic interpretation, it is typical to assume that consists of independent and identically-distributed (IID) normal random variables with zero mean [26]. Under the null hypothesis, we would have \u03c1 = 0, indicating that there is no spatial dependence between the observations in X . Because \u03c1 is difficult to estimate exactly [26], Moran\u2019s I is used as an approximation. It is computed as,\nI = n\u2211n\ni (xi \u2212 x)2\n\u2211n i \u2211n j wij(xi \u2212 x)(xj \u2212 x)\u2211n\ni \u2211n j wij\n, (2)\nwhere x = 1n \u2211 i xi. The ratio on the left is the inverse of the variance of X ; the ratio on the right corresponds to the covariance between points i and j that are spatially similar. Thus, the statistic rescales a spatially-reweighted covariance (the ratio on the right of Equation 2) by the overall variance (the ratio on the left of Equation 2), giving an estimate of the overall spatial dependence of X . A compact alternative notation is to rewrite the statistic in terms of the matrix of residuals R = {ri}i\u22081...n, where ri = xi \u2212 x. This yields the form I = R\n>WR R>R , with R> indicating the transpose of the column vector R. Moran\u2019s I values often lie between \u22121 and 1, but the exact range depends on the weight matrix W , and is theoretically unbounded [7].\nIn hypothesis testing, our goal is to determine the p-value representing the likelihood that a value of Moran\u2019s I at least as extreme as the observed value would arise by chance under the null hypothesis. The expected value of Moran\u2019s I in the case of no spatial dependence is \u2212 1n\u22121 . Grieve et al. compute p-values from a closed-form approximation of the variance under the null hypothesis of total randomization. A nonparametric alternative is to perform a permutation test, calculating the empirical p-value by comparing the observed test statistic against the values that arise across multiple random permutations of the original data.\nIn the study of dialect, X typically represents the frequency or presence of some linguistic variable, such as the use of soda versus pop. We are unaware of applications of Moran\u2019s I to variables with more than two possibilities (e.g., soda, pop, coke), and it is not clear how this would be computed. A key question for the use of Moran\u2019s I is the definition of the spatial neighborhood matrix W . As noted above, Grieve et al. set wij = 1 if the distance is below some threshold \u03c4 . In Section 3, we use synthetic data to test the sensitivity of Moran\u2019s I to the value of this parameter, and evaluate heuristics that have been proposed in prior work."}, {"heading": "2.2 Point Pattern Analysis (PPA)", "text": "One way to avoid defining a threshold for the spatial adjacency matrix W is to use Delaunay triangulation, a technique for automatically producing a mesh of triangles over a set of points. A property of Delaunay triangulation is that points tend to be connected to their closest neighbors, regardless of how distant or near those neighbors are: in high-density regions, the edges will tend to be short, while in low-density regions, the edges will be long. The method is therefore arguably more suitable to data in which the density of observations is highly variable \u2014 for example, between denselypopulated cities and sparse-populated hinterlands.\nLee and Kretzschmar [21] apply Delaunay triangulation to the analysis of a set of dialect interviews, in the framework of Point Pattern Analysis (PPA).1 Here, each observation is assumed to be binary, xi \u2208 {0, 1}; the Delaunay triangulation can again be represented with a matrix W , where wij = 1 whenever points i and j are connected in the triangulation. We can then compute the number of \u201cagreements\u201d between linked points,\nnum-agree = n\u2211 i n\u2211 j wij(xixj + (1\u2212 xi)(1\u2212 xj)) (3)\n=X>WX + (1\u2212X)>W (1\u2212X), (4)\nwith X> indicating the transpose of the column vector X . Note the similarity to the numerator of Moran\u2019s I, which can be written as R>WR.\nTo evaluate the statistical significance of this statistic, we must also compute the expected number of agreements under the null hypothesis. The likelihood of any two randomly chosen points having xi = xj = 1 is x2, and the likelihood of their having the value xi = xj = 0 is (1\u2212 x)2, where x is again the empirical mean, x = 1n \u2211 i xi. Since\nthe total number of linked points is \u2211 ij wij , the expected number of agreements is given by:\nE[num-agree] = (x2 + (1\u2212 x)2) n\u2211 i n\u2211 j wij , (5)\nThe variance of the number of agreements under the null hypothesis can also be obtained in closed form, enabling the computation of a z-statistic and p-value for the null hypothesis of total randomization.\nBecause PPA is based on counts of agreements, it requires that each xi is a categorical variable \u2014 possibly non-binary \u2014 rather than a frequency. In this sense, it is the inverse of Moran\u2019s I, which can be applied to frequencies, but not to non-binary variables. Thus, PPA is best suited to cases where observations correspond to individual utterances (e.g., Twitter data, dialect interviews), rather than cases where observations correspond to longer texts (e.g., newspaper corpora).\n1 Note that this procedure could in principle be used to construct W for Moran\u2019s I, but we are unaware of this being tried in any previous work on dialect analysis."}, {"heading": "2.3 The Mantel Test", "text": "Moran\u2019s I and Point Pattern Analysis are both asymmetric in their treatment of the geographical and linguistic variables \u2014 they measure similarity on the linguistic variable between all points that are sufficiently close in space. The Mantel test takes a more symmetric approach, and can in principle be used to measure the dependence between any two arbitrary signals. Let us compute distances for each pair of linguistic variables, dx(xi, xj), and each pair of spatial locations, dy(yi, yj), forming a pair of distance matrices Dx and Dy . The Mantel test then measures the element-wise correlation (usually, the Pearson correlation) between these two matrices. Scherrer [28] used the Mantel test to correlate linguistic distance with geographical distance, and Gooskens and Heeringa [13] correlated perceptual distance with linguistic distance.2\nAs usual, the goal of hypothesis testing is to determine the likelihood that the observed test statistic \u2014 in this case, the correlation between Dx and Dy \u2014 could have arisen by chance. To assess the distribution of correlations under the null hypothesis, we randomly permute the rows or columns of one of the matrices repeatedly. If the correlation between the unpermutedDx andDy is consistently higher than the correlations under permutation, then the null hypothesis is unlikely to hold.\nA design question for the Mantel test is the choice of the distance functions for X and Y . For spatial locations, we compute the distance matrix based on the Euclidean distance between each pair of points. For binary or categorical linguistic data, the entries of the linguistic distances matrix are set to 0 if xi = xj , and 1 otherwise. For linguistic frequency data, we use the absolute difference between the frequency values.\nThe Mantel test is more flexible than Moran\u2019s I or Point Pattern Analysis: it is applicable to binary, categorical, and frequency data, and does not require the specification of a geographical distance threshold. However, by focusing on correlations between similarities, it makes an implicit parametric assumption: in the ideal case of perfect correlation, twice as much geographical distance should imply twice as much as linguistic distance. Yet a range of dialectometric studies have found that linguistic differences increase sublinearly with geographical distance, a phenomenon that Nerbonne has dubbed \u201cSeguy\u2019s law\u201d [24]. On this view, the parametric assumption of linear dependence between geographical and linguistic distance is incorrect. A second concern is that human settlement patterns are highly variable, so that a distance of, say, 100 kilometers may be far more linguistically meaningful in a densely-populated urban area like New England than it would be in a more sparsely-populated region like the American West. If the assumptions underlying Mantel\u2019s test \u2014 linearity and homogeneity \u2014 are incorrect, then the test will be underpowered, failing to detect meaningful relationships in the data."}, {"heading": "2.4 Hilbert-Schmidt Independence Criterion (HSIC)", "text": "The discussion of existing tests for spatial dependence has helped to identify some desiderata. The ideal test would be applicable across many kind of linguistic data, including both binary and categorical variables, and both frequencies and discrete observations. The Mantel test solves these problems, but makes unsupported parametric\n2 The Mantel test has also been applied to non-human dialect analysis, revealing regional differences in the call structures of Amazonian parrots by computing a linguistic distance matrix Dx directly from spectral measurements [35].\nassumptions about the nature of the relationship between linguistic and spatial distance. Rather than measuring the correlation of linguistic variables with a single, thresholded distance function (as in Moran\u2019s I and PPA) or a single correlation matrix (as in the Mantel test), we might prefer to model non-linear relationships, perhaps by considering higher-order moments (x2, x3, . . .) or other transformations of the spatial distances.\nBoth of these problems can be solved through the use of Reproducing Kernel Hilbert Spaces (RKHS), a family of techniques from non-parametric statistics, capable of capturing arbitrary statistical dependencies [14]. Specifically, the Hilbert-Schmidt Independence Criterion (HSIC) provides a robust test for statistical dependence of two signals, which is simple to implement, and involves only a single tunable parameter.\nAt the core of RKHS-based techniques is the kernel function on pairs of instances. Let k(xi, xj) : X \u00d7 X \u2192 R+ represent a function from pairs (xi, xj) to non-negative real numbers; let us also assume that k(xi, xj) = k(xj , xi), so that k can be thought of as a measure of similarity. Now suppose we have a set of inputs {xi}i\u2208{1...n}, and we construct a matrix K, such that Ki,j = k(xi, xj), known as the Gram matrix. For appropriately chosen kernel functions,3 Mercer\u2019s theorem guarantees that there exists some feature function \u03c6(x) : X \u2192 RD such that k(xi,xj) = \u03c6(xi)>\u03c6(xj). The dimension D of the feature function may be very large, even infinite; for example, the feature function may correspond to an infinite series, [x, x2, x3, . . .]. Nonetheless, by working with the kernels (rather than directly with the feature functions), we can compute the inner product (and therefore the covariance) directly from the kernel function.\nTo make things more concrete, let us define the spatial kernel function k\u03b3(yi, yj) = e\u2212\u03b3d\n2 ij , where d2ij is the squared Euclidean distance between yi and yj , and \u03b3 is a parameter of the kernel function. Similarly, for linguistic frequency data, let `\u03b9(xi, xj) = e\u2212\u03b9(xi\u2212xj) 2 . This linguistic kernel function is suitable for continuous data, such as values of acoustic variables, and can also capture difference in frequencies of a binary linguistic variable. These exponentially decaying kernel functions are known as radial basis functions (RBFs), and are guaranteed to be symmetric and positive definite, satisfying the conditions of Mercer\u2019s theorem. The RBF kernel corresponds to a inner product between infinite-dimensional feature vectors \u03c6 [23]. Thus, although the RBF kernel function is based on distances, the resulting feature map includes non-linear transformations of these distances, and therefore the approach is not equivalent to simply correlating linguistic and geographical distances. In the case of binary and categorical data, we use a Delta kernel, where `\u03b9(xi, xj) = 1 if xi = xj and 0 otherwise. The Delta kernel has been used successfully in combination with HSIC for high-dimensional feature selection [30, 36].\nNow, if we compute the kernel functions over all pairs of observations, we obtain the Gram matrices K and L, where Kij = k(yi, yj) and Lij = `(xi, xj), eliding the parameters \u03b3 and \u03b9 for clarity. The Hilbert-Schmidt Independence Criterion (HSIC) is a nonparametric measure of the dependence between X and Y [14], and an empirical estimator is given by,\nHSIC(x, y) = trKHLH\nn2 , (6)\n3 Specifically, we require that K is symmetric, meaning that Kij = Kji for all i and j, and positive definite, meaning that a>Ka > 0 for all vectors a. One test for positive definiteness is that the eigenvalues of K must all be positive.\nwhere tr indicates the matrix trace, trA = \u2211 iAii and,\nHij = { 1\u2212 1/n, i = j \u22121/n, i 6= j.\n(7)\nWith this definition of H , we have,\n(KH)ij =k(yi, yj)\u2212 1\nn \u2211 j\u2032 k(yi, yj\u2032) (8)\n(LH)ij =`(xi, xj)\u2212 1\nn \u2211 j\u2032 `(xi, xj\u2032). (9)\nThese two terms can therefore be seen as mean-centered Gram matrices. By computing the trace of their matrix product, we obtain a cross-covariance between the Gram matrices. If the two data sources are independent, the expectation of this cross-covariance is zero.\nAn important implementation detail is that the size of each Gram matrix is the square of the number of observations, which for large data will be too expensive to compute. Following Gretton et al. [14], we employ a low-rank approximation to each Gram matrix, using the incomplete Cholesky decomposition [1]. Specifically, we approximate the symmetric matrices K and L as low-rank products, K \u2248 AAT and L \u2248 BBT , where A \u2208 Rn\u00d7rA andB \u2208 Rn\u00d7rB . The approximation quality is determined by the parameters rA and rB , which are set to ensure that the magnitudes of the residuals K \u2212AAT and L\u2212BBT are below a predefined threshold. HSIC may then be approximated as:\nHSIC(x, y) = trKHLH\nn2 , (10)\n\u2248 tr(AA T )H(BBT )H\nn2 , (11)\n= tr(BT (HA))(BT (HA))T\nn2 (12)\nwhere the matrix product HA can be computed without explicitly forming the n\u00d7 n matrix H , due to its simple structure.\nThe HSIC has several advantages. It can be computed for either frequency or count data, as long as an appropriate kernel function can be defined. It offers a parallel treatment of X and Y , thereby avoiding the use of arbitrary thresholds in the construction of a spatial neighborhood matrix W . A potential concern is the selection of the kernel bandwidth parameters \u03b3 and \u03b9. We will test the sensitivity to these parameters in the next section, and demonstrate a simple heuristic that works well in practice.4\n4 Flaxman recently proposed a \u201ckernelized Mantel test\u201d, in which correlations are taken between kernel similarities rather than distances [11]. The resulting test statistic is similar, but not identical to HSIC. Specifically, while HSIC centers the kernel matrix against the local mean kernel similarities for each point, the kernelized Mantel test centers against the global mean kernel similarity. This makes the test more sensitive to distant outliers. We implemented the kernelized Mantel test, and found its performance to be"}, {"heading": "2.5 Computing Significance Tests", "text": "HSIC and the Mantel test are applicable to all types of data, but Moran\u2019s I is not applicable to categorical data and PPA is not applicable to frequency data. For all approaches, a one-tailed significance test is appropriate, since in nearly all conceivable dialectological scenarios we are testing only for the possibility of a higher clustering in geographical space than chance; however, the generalization to two-tailed tests is trivial. For some methods, it is possible to calculate the variance of the test statistic in closed form. However, for consistency, we employ a permutation approach to characterize the null distribution over the test statistic values. We permute the linguistic data x, breaking any link between geography and the language data, and then compute the test statistics for many such permutations."}, {"heading": "3. Synthetic Data", "text": "Real linguistic datasets lack ground truth about which features are geographically distinct, making it impossible to use such data to quantitatively evaluate the proposed approaches. We therefore use synthetic data to compare the power and sensitivity of the various approaches described in the previous section. Our main goals are: (1) to calibrate the p-values produced by each approach in the event that the null hypothesis is true, using completely randomized data; (2) to test the ability of each approach to capture spatial dependence, particularly under conditions in which the spatial dependence is obscured by noise."}, {"heading": "3.1 Data Generation", "text": "To ensure the verisimilitude of our synthetic data, we target the scenario of geo-tagged tweets in the Netherlands. For each municipality i, we stochastically determine the number and location of the tweets as follows:\nNumber of data points For each municipality, the number of tweets ni is chosen to be proportional to the population, as estimated by Statistics Netherlands (CBS). Specifically, we draw n\u0303i \u223c Poisson(\u00b5obs \u2217 populationi) and then set ni = n\u0303i + 1, ensuring that each municipality has at least one data point. The parameter \u00b5obs controls the frequency of the linguistic variable. For example, a common orthographic variable (e.g., \u201cg-deletion\u201d) might have a high value of \u00b5obs, while a rare lexical variable (e.g., soda versus pop) might have a much lower value. Note that \u00b5obs is shared across all municipalities. Locations Next, for each tweet t, we determine the location yt by sampling without replacement from the set of real tweet locations in municipality i (the dataset is described in section 4.3). This ensures that the distribution of geo-locations in the synthetic data matches the real geographical distribution of tweets, rather than drawing from a parametric distribution which may not match the complexity of true geographical population distributions. Each location is represented as a latitude and longitude pair.\nsimilar to the classical Mantel test, with lower statistical power than HSIC. Flaxman made similar observations in his analysis of the spatiotemporal distribution of crime events.\nFor each variable, each municipality is assigned a frequency vector \u03b8i, indicating the relative frequency of each variable form: e.g., 70% soda, 30% pop. We discuss methods for setting \u03b8i below, which enable the simulation of a range of dialectal phenomena.\nWe simulate both counts data and frequency data. In counts data \u2014 such as geotagged tweets \u2014 the data points in each instance in municipality i are drawn from a binomial or multinomial distribution with parameter \u03b8i. In frequency data, we observe only the relatively frequency of each variable form for each municipality. In this case, we draw the frequency from a Dirichlet distribution with expected value equal to \u03b8i, drawing \u03c6t \u223c Dirichlet(s\u03b8i), where the scale parameter s controls the variance within each municipality."}, {"heading": "3.2 Calibration", "text": "Our first use of synthetic data is to examine the p-values obtained from each method when the null hypothesis is true \u2014 that is, when there is no geographical variation in the data. The p-value corresponds to the likelihood of seeing a test statistic at least as extreme as the observed value, under the null hypothesis. Thus, if we repeatedly generate data under the null hypothesis, a well-calibrated test will return a distribution of p-values that is uniform in the interval [0, 1]: for example, we expect to observe p < .05 in exactly 5% of cases, corresponding to the allowed rate of Type I errors (incorrect rejection of the null hypothesis) at the threshold \u03b1 = 0.05.\nTo measure the calibration of each of the proposed tests, we generate 1000 random datasets using the procedure described above, and then compute the p-values under each test. In these random datasets, the relative frequency parameters \u03b8i are the same for all municipalities, which is the null hypothesis of complete randomization. To generate the binary and categorical data, we use \u00b5obs = 10\u22125, meaning that the expected number of observations is one per hundred thousand individuals in the municipality or province; for comparison, this corresponds roughly to the tweet frequency of the lengthened spelling hellla in the 2009-2012 Twitter dataset gathered by Eisenstein et al [10].\nTo visualize the calibration of each test, we use quantile-quantile (Q-Q) plots, comparing the obtained p-values with a uniform distribution. A well-calibrated test should give a straight line from the origin to (1, 1). Figure 3 shows the Q-Q plots obtained from each method on each relevant type of data (recall that not all methods can be applied to all types of data, as described in the previous section).\nHSIC and Moran\u2019s I each have tuning parameters that control the behavior of the test: the kernel bandwidth in HSIC and the distance cutoff in Moran\u2019s I. A simple heuristic is to use the median Euclidian distance d: in Moran\u2019s I, we use d as the distance threshold for constructing the neighborhood matrixW ; in HSIC, we use 1\nd 2 as the kernel\nbandwidth parameter. Figure 3 shows that by basing these parameters on the median distance between pairs of points, we get well-calibrated results. However, some prior work takes an alternative approach, sweeping over parameter values to obtain the most significant results [15]. In our experiments we sweep across the distance cutoff for Moran\u2019s I, and the bandwidth for the spatial distances in HSIC. This badly distorts the calibration, particularly for Moran\u2019s I, meaning that the resulting p-values are not reliable. This is most severe for Moran\u2019s I on the municipality level, reaching type I error rates of 11.7% (binary data) and 14.3% (frequency data) when the significance threshold \u03b1 is set to 5%. Given that such parameter sweeps are explicitly designed to maximize the number of positive test results \u2014 and not the overall calibration of the test \u2014 this is unsurprising. We therefore avoid parameter sweeps in the remainder of this article, and rely instead on median distance as a simple heuristic alternative."}, {"heading": "3.3 Power", "text": "Next, we consider synthetic data in which there is geographical variation by construction. We assess the power of each approach by computing the fraction of simulations for which the approaches correctly rejected the null hypothesis of no spatial dependence, given a significance threshold of \u03b1 = 0.05. We again use the Netherlands as the stage for all simulations, and consider two types of geographical variation.\nLinear variation We generate data such that the frequency of a linguistic variant increases linearly through space, as in a dialect continuum [18]. In most of the synthetic data experiments below, we average across a range of angles, from 0\u25e6\nto 357\u25e6 with step sizes of 3\u25e6, yielding 120 distinct angles in total. Each angle aligns differently with the population distribution of the Netherlands, so we also assess sensitivity of each method to the angle itself.\nCenters Second, we consider a setting in which variation is based on one or more geographical centers. In this setting, all cities within some specified range of the center\n(or one of the centers) have some maximal frequency value \u03b8i; in other cities, this value decreases as distance from the nearest center grows. This corresponds to the dialectological scenario in which a variable form is centered on one specific city, as in, say, the association of the word hella with the San Francisco metropolitan area. We average across twenty five possible centers: the capitals of each of the twelve provinces of the Netherlands; the national capital of the Netherlands (Amsterdam); the two most populous cities in each of the twelve provinces. For each setting, we randomly generate synthetic data four times, resulting in a total of 100 synthetic datasets for this condition.\nParameter settings. We use these data generation scenarios to test the sensitivity of HSIC and Moran\u2019s I to their hyperparameters, by varying the kernel bandwidths in HSIC (Figures 4a and 4b) and the distance threshold in Moran\u2019s I (Figures 4c and 4d). The sensitivity of HSIC to the bandwidth value decreases as the number of data points increases (as governed by \u00b5obs), especially in the case of linear variation. The sensitivity of Moran\u2019s I to the distance cutoff value decreases with the amount of data in the case of linear variation, but in the case of center-based variation, Moran\u2019s I becomes more sensitive to this parameter as there is more data. For both methods, the same trends regarding the best performing parameters can be observed. In the case of linear variation, larger cutoffs and bandwidths perform best, but in the case of variation based on centers, smaller cutoffs and bandwidths lead to higher power. Overall, there is no single best parameter setting, but the median heuristics perform reasonably well for both types of variation.\nAngle of linear variation. We simulate dialect continua by varying the frequency of linguistic variables linearly through space. Due to the heterogeneity of population density,\ndifferent spatial angles will have very different properties: for example, one choice of angle would imply a continuum cutting through several major cities, while another choice might imply a rural-urban distinction. Figure 5 shows the power of the methods on binary data (there are two variant forms, and each instance contains exactly one of them), in which we vary the angle of the continuum. HSIC is insensitive to the angle of variation, demonstrating the advantage of this kernel nonparametric method. Moran\u2019s I is relatively robust, while Point Pattern Analysis (PPA) performs poorly across the entire range of settings. The Mantel test is remarkably sensitive to the angle of variation, attaining nearly zero power for some scenarios of linear variation. This is caused by the complex interaction between the underlying linguistic phenomenon and the east-west variation of the population density of the Netherlands. For example, when the dialect continuum is simulated at an angle of 105 degrees, the south east of the Netherlands has a higher usage of the variable, but this is only a very small region due to the shape of the country. The Mantel test apparently has great difficulty in detecting geographical variation in such cases.\nOutliers. In the frequency-based synthetic data, each instance uses each variable form with some continuous frequency \u2014 this is based on the scenario of letters-to-the-editors of regional newspapers, as explored in prior work [15]. We test the robustness of each approach by introducing outliers: randomly selected individuals whose variable frequencies are replaced at random with extreme values of either 0 or 1. As shown in Figure 6, HSIC is the most robust against outliers, while the performance of Moran\u2019s I is the most affected by outliers (recall that PPA applies only to discrete observations, so it cannot be compared on this measure).\nOverall. We now compare the methods by averaging across various settings simulating linear variation (Figure 7) and variation based on centers (Figure 8). To generate the categorical data, we vary \u00b5obs in our experiments, with a higher \u00b5obs resulting in more tweets and consequently less variation on the municipality level. As expected, the power of the approaches increases as \u00b5obs increases in the experiments on the categorical data, and the power of the approaches decreases as \u03c3 increases in the experiments on the frequency data. The experiments on the binary and categorical data show the same trends: HSIC performs the best across all settings. PPA does well when the variation is based on centers, and Moran\u2019s I does best when the variation is linear. Moran\u2019s I performs best on the frequency data, especially in the case of variation based on centers."}, {"heading": "3.4 Summary", "text": "In this section, we evaluated each statistical test for geographical language variation on a battery of synthetic data. HSIC and the Mantel test are the only approaches applicable to all data types (binary, categorical and frequency data). Overall, HSIC is more effective than the Mantel test, which is much more sensitive to the specifics of the synthetic data scenario, such as the angle of the dialect continuum. HSIC is robust against outliers, and performs particularly well when the number of data points increases and it is robust against outliers. PPA is suitable for capturing non-linear variation, but its power is low compared to other approaches in situations of linear variation. On the other hand, Moran\u2019s I performs well on binary data with linear variation, but its power is low in situations of variation based on centers. In our experiments on frequency data, where the other approaches also directly deal with frequency values, Moran\u2019s I performed well."}, {"heading": "4. Empirical Data", "text": "We now assess the spatial dependence of linguistic variables on three real linguistic datasets: letters to the editor (English), syntactic atlas of the Dutch dialects, and Dutch geotagged tweets. To account for multiple hypothesis testing, we use the BenjaminiHochberg false discovery rate procedure to adjust the p-values [4]."}, {"heading": "4.1 Letters to the Editor", "text": "In their application of Moran\u2019s I to English dialects in the United States, Grieve et al. compile a corpus of letters-to-the-editors of newspapers to measure the presence of dialect variables in text. To compute the frequency of the lexical variables, letters are aggregated to core-based statistical areas (CBSA), which are defined by the United States to capture the geographical region around an urban core. The frequency of 40 manually selected lexical variables is computed for each of 206 cities.\nWe use the Mantel test, HSIC, and Moran\u2019s I to assess the spatial dependence of variables in this dataset. PPA was excluded from the analysis, because it is not suitable for frequency data. We verified our implementation of Moran\u2019s I by following the approach taken by Grieve et al.: we computed Moran\u2019s I for cutoffs in the range of 200 to 1000 miles and selected the cutoff that yielded the lowest p-value. The obtained cutoffs and test statistics closely followed the values reported in the analysis by Grieve et al., with slight deviations possibly due to our use of a permutation test rather than a closedform approximation to compute the p-values.\nAfter adjusting the p-values using the false discovery rate (FDR) procedure, a 500- mile cutoff results in three significant linguistic variables.5 However, recall that the approach of selecting parameters by maximizing the number of positive test results tends to produce a large number of Type I errors. When setting the distance cutoff to the median distance between data points, none of the linguistic variables were found to have a significant geographical association. Similarly, HSIC and the Mantel test also found no significant associations after adjusting for multiple comparisons. Figure 9 shows the proportion of significant variables according to Moran\u2019s I based on different thresholds. The numbers vary considerably depending on the threshold. The figure also suggests that the median distance (921 miles) may not be a suitable threshold for this dataset.\n5 Grieve et al. report five significant variables. In our analysis, there are two variables with FDR-adjusted p-values of 0.0559"}, {"heading": "4.2 Syntactic Atlas of the Dutch Dialects (SAND)", "text": "SAND [2, 3] is an online electronic atlas that maps syntactic variation of Dutch varieties in the Netherlands, Belgium, and France.6 The data was collected between the years of 2000 and 2005. SAND has been used to measure the distances between dialects, and to discover dialect regions [31, 33].\nIn our experiments, we consider only locations within the Netherlands (157 locations). The number of variants per linguistic variable ranges from one (due to our restriction to the Netherlands) to eleven. We do not include Moran\u2019s I in our experiments, since it is not applicable to linguistic variables with more than two variants. We apply the remaining methods to all linguistic variables with twenty or more data points and at least two variants, resulting in a total of 143 variables.\nTable 1 lists the 10 variables with the highest HSIC values. Statistical significance at a level of \u03b1 = 0.05 is detected for 65.0% of the linguistic variables using HSIC, 78.3% when using PPA, and 52.4% when using the Mantel test. The three methods agree on 99 out of the 143 variables, and HSIC and PPA agree on 118 variables. Based on manual inspection, it seems that the non-linearity of the geographical patterns may have caused difficulties for the Mantel test. For example, Figure 10 is an example of a variable where HSIC and PPA both had an adjusted p-value < .05, but the Mantel test did not detect a significant pattern. Note the uneven dispersion of the data points and the clusters of subject relatives (purple data points) in both the north and south of the Netherlands, which does not match the linearity assumption employed by the Mantel Test.\n6 http://www.meertens.knaw.nl/sand/\nLinguistic variables Description N Moran\u2019s I HSIC Mantel PPA\nFriet / patat french fries 842 0.0004 0.0002 0.0003 0.0003 Proficiat / gefeliciteerd congratulations 14,474 0.0004 0.0002 0.0080 0.0003 Iedereen / een ieder everyone 13,009 0.8542 0.0002 0.8769 0.0432 Doei / aju bye 4,427 0.7163 0.0050 0.2570 0.3868 Efkes / eventjes for a little while 969 0.0036 0.0002 0.0003 0.0003 Naar huis / naar huus to home 3, 942 0.8542 0.1090 0.1245 0.9426 Niet meer / nie meer not anymore 11,596 0.0793 0.0002 0.5590 0.0329 Of niet / of nie or not 1,882 0.8357 0.1010 0.4191 0.9426 -oa- / -ao- e.g., jao versus joa 754 0.0004 0.0002 0.0003 0.0003 Even weer / weer even for a little while again 921 0.0004 0.0002 0.0003 0.0003 Have + participle e.g., heb gedaan (\u2018have done\u2019)\nvs. gedaan heb (\u2018done have\u2019) 1,122 0.8587 0.2849 0.6668 0.0255\nBe + participle e.g., ben geweest (\u2018have been\u2019) vs. geweest ben (\u2018been have\u2019)\n1,597 0.0793 0.2849 0.7862 0.0051\nSpijkerbroek / jeans jeans 1,170 0.7796 0.0002 0.0080 0.0003 Doei/ houdoe bye 4,491 0.5016 0.0002 0.6668 0.0047 Bellen / telefoneren to call by telephone 4,689 0.2730 0.0003 0.9781 0.5941\nTable 2: Twitter results. The p-values were calculated using 10,000 permutations and corrected for multiple comparisons."}, {"heading": "4.3 Twitter", "text": "Our Twitter dataset consists of 4,039,786 geotagged tweets from the Netherlands, written between January 1, 2015 and October 31, 2015. We manually selected a set of linguistic variables (Table 2), covering examples of lexical variation (e.g., two different words for referring to french fries), phonological variation (e.g., t-deletion), and syntactic variation (e.g., heb gedaan (\u2018have done\u2019) vs. gedaan heb (\u2018done have\u2019)). We are not aware of any previous work on dialectal variation in the Netherlands that uses spatial dependency testing on Twitter data. The number of tweets per municipality varies dramatically, and for the less frequent linguistic variables there are no tweets at all in some municipalities. In our computation of Moran\u2019s I, we only include municipalities with at least one tweet.\nTable 2 shows the output of each statistical test for this data. Some of these linguistic variables exhibit strong spatial variation, and are identified as statistically significant by all approaches. An example is the different ways of referring to french fries (friet versus patat, Figure 11a), where the figure shows a striking difference between the south and the north of the Netherlands. Another example is Figure 11b , which shows two different ways of saying \u2018for a little while\u2019 (efkes versus eventjes). The less common form, efkes is mostly used in Friesland, a province in the north of the Netherlands.\nExamples of linguistic variables where the approaches disagree are shown in Figure 12. The first case (Figure 12a) is an example of lexical variation, with two different ways of saying bye in the Netherlands. A commonly used form is doei, while houdoe is known to be specific to North-Brabant, a Dutch province in the south of the Netherlands. HSIC and PPA both detect a significant pattern, but Moran\u2019s I and the Mantel test do not. The trend is less strong than in the previous examples, but the figure does suggest a higher usage of houdoe in the south of the Netherlands.\nAnother example is t-deletion for a specific phrase (niet meer versus nie meer), as shown in Figure 12b. Previous dialect research has found that geography is the most important external factor for t-deletion in the Netherlands [12]. Both HSIC and PPA report an FDR-adjusted p < .05, while for Moran\u2019s I, the geographical association does not reach the threshold of significance.\nWe also present preliminary results on using HSIC as an exploratory tool on the same Twitter corpus. To focus on active users who are most likely tweeting on a personal basis, we exclude users with 1000 or more followers and users who have fewer than 50 tweets, resulting in 8,333 users. We exclude infrequent words (used by fewer than 100 users) and very frequent words (used by 1000 users or more), resulting in a total of 5,183 words. We represent the usage of a word by each author as a binary variable, and use HSIC to compute the level of spatial dependence for each word.\nThe top 10 words with the highest HSIC scores are groningen (city), zwolle (city), eindhoven (city) arnhem (city), breda (city), enschede (city), nijmegen (city), leiden (city), twente (region) and delft (city). While these words do not reflect dialectal variation as it is normally construed, we expect their distribution to be heavily influenced by geography. Manual inspection also revealed that many English words are highly ranked in the list (e.g., his, very); as English speakers are more likely to visit tourist and commercial centers, it is unsurprising that these words should show a strong geographical association. The first non-topical word occurs on rank 34 in the list and is proficiat, which is one of\nthe words we included in our analysis in Table 2. This replication of prior dialectological knowledge validates the usage of HSIC as an exploratory tool. Two other highly ranked words (ranks 60 and 71), which are less well-known, are shown in Figure 13. Joh (Figure 13a) is an interjection and is used less in the southern part of the Netherlands, while dadelijk (\u2018immediately\u2019/\u2018just a second\u2019, Figure 13b) is used more in the southern part of the Netherlands. The identification of these words speaks to the potential of HSIC to guide the study of dialect by revealing geographically-associated terms."}, {"heading": "5. Conclusion", "text": "We have reviewed four methods for quantifying the spatial dependence of linguistic variables: Moran\u2019s I, which is perhaps the best-known in sociolinguistics and dialectology; PPA; the Mantel test; and the Hilbert-Schmidt Independent Criterion (HSIC). Of these methods, only the Mantel test and HSIC can be applied to the full range of linguistic data: binary and multiway counts, as well as frequencies. The Mantel test assumes a linear relationship between geographical and linguistic distance, making it underpowered in cases where population density interacts with linguistic variation. This means that the effectiveness of the Mantel test will depend on where the variable happens to be centered, or how a dialect continuum aligns with population density; HSIC is more stable in the face of both of these factors. PPA and Moran\u2019s I each perform well in some situations, and poorly in others. Moran\u2019s I is found to be relatively sensitive to the distance cutoff parameter, and PPA struggles with dialect continuum scenarios. HSIC is the least sensitive to \u201coutlier\u201d individuals. Overall, we find that HSIC, while not the most powerful test in every scenario, offers the broadest applicability and the least potential for catastrophic failure of any of the proposed approaches.\nWe then showed how to apply these tests to a diverse range of real datasets: frequency observations in letters to the editor, binary observations in a dialect atlas, and binary observations in social media. We find that previous results on newspaper data were dependent on the procedure of selecting the geographical distance cutoff to maximize the number of positive test results; using all other test procedures, the significance of these results disappears. On the dialect atlas, we find that the fraction of statistically significant variables ranges from 55.2% to 78.3% depending on the statistical approach. On the social media data, we obtain largely similar results from the four dif-\nferent tests, but HSIC detects the largest number of significant associations, identifying cases in which geography and population density were closely intertwined.\nMore broadly, this work proposes a somewhat unusual relationship between computation and linguistics: rather than using linguistics as guidance for developing new natural language processing algorithms or for producing new labeled training sets, we use computation as a tool for exploring and testing linguistic hypotheses in large corpora of unannotated text. The resulting method, which builds on the well-understood mathematics of kernel support vector machines, is more broadly applicable and robust than traditional parametric statistical techniques. With the rapidly increasing scale of linguistically-relevant data, we believe there will be many more opportunities to apply computation in this way."}, {"heading": "Acknowledgments", "text": "Thanks to Jack Grieve for sharing the corpus of dialect variables from Letters to the Editor in North American newspapers, Arthur Gretton for advice about how best to use HSIC, Erik Tjong Kim Sang for help on using the SAND data, the DB group of the University of Twente for sharing the Dutch geotagged tweets, and Leonie Cornips and Sjef Barbiers for advice on selecting the Dutch linguistic variables. The first author was supported by the Netherlands Organization for Scientific Research (NWO), grant 640.005.002 (FACT). The second author was supported by National Science Foundation award RI-1452443, and by the Air Force Office of Scientific Research."}], "references": [{"title": "Kernel independent component analysis", "author": ["Francis R. Bach", "Michael I. Jordan"], "venue": "The Journal of Machine Learning Research,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2002}, {"title": "Syntactic Atlas of the Dutch Dialects: Volume I", "author": ["Sief Barbiers", "Hans Bennis", "Gunther De Vogelaer", "Magda Devos", "Margreet van der Ham", "Irene Haslinger", "Marjo van Koppen", "Jeroen Van Craenenbroeck", "Vicky Van den Heede"], "venue": null, "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2005}, {"title": "Syntactic Atlas of the Dutch Dialects: Volume II", "author": ["Sjef Barbiers", "Johan van der Auwera", "Hans Bennis", "Eefje Boef", "Gunther De Vogelaer", "Margreet van der Ham"], "venue": null, "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2009}, {"title": "Controlling the false discovery rate: A practical and powerful approach to multiple testing", "author": ["Yoav Benjamini", "Yosef Hochberg"], "venue": "Journal of the Royal Statistical Society. Series B (Methodological),", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 1995}, {"title": "Spatial processes: models & applications, volume 44", "author": ["Andrew D. Cliff", "J. Keith Ord"], "venue": "Pion London,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 1981}, {"title": "On extreme values of Moran\u2019s I and Geary\u2019s", "author": ["P. de Jong", "C. Sprenger", "F. van Veen"], "venue": "c. Geographical Analysis,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 1984}, {"title": "Mapping dialectal variation by querying social media", "author": ["Gabriel Doyle"], "venue": "In Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2014}, {"title": "A latent variable model for geographic lexical variation", "author": ["Jacob Eisenstein", "Brendan O\u2019Connor", "Noah A. Smith", "Eric P. Xing"], "venue": "In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2010}, {"title": "Diffusion of lexical change in social media", "author": ["Jacob Eisenstein", "Brendan O\u2019Connor", "Noah A. Smith", "Eric P. Xing"], "venue": "PLoS ONE,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2014}, {"title": "Machine Learning in Space and Time", "author": ["Seth R. Flaxman"], "venue": "PhD thesis,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2015}, {"title": "T-deletie in Nederlandse dialecten; kwantitatieve analyse van structurele, ruimtelijke en temporele variatie", "author": ["Ton Goeman"], "venue": "PhD thesis,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 1999}, {"title": "The relative contribution of pronunciational, lexical, and prosodic differences to the perceived distances between norwegian dialects", "author": ["Charlotte Gooskens", "Wilbert Heeringa"], "venue": "Literary and Linguistic Computing,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2006}, {"title": "Measuring statistical dependence with Hilbert-Schmidt norms", "author": ["Arthur Gretton", "Olivier Bousquet", "Alex Smola", "Bernhard Sch\u00f6lkopf"], "venue": "Algorithmic Learning Theory,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2005}, {"title": "A statistical method for the identification and aggregation of regional linguistic variation", "author": ["Jack Grieve", "Dirk Speelman", "Dirk Geeraerts"], "venue": "Language Variation and Change,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2011}, {"title": "A multivariate spatial analysis of vowel formants in American English", "author": ["Jack Grieve", "Dirk Speelman", "Dirk Geeraerts"], "venue": "Journal of Linguistic Geography, 1:31\u201351,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2013}, {"title": "Geolocation prediction in social media data by finding location indicative words", "author": ["Bo Han", "Paul Cook", "Timothy Baldwin"], "venue": "In Proceedings of COLING,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2012}, {"title": "Dialect areas and dialect continua", "author": ["Wilbert Heeringa", "John Nerbonne"], "venue": "Language Variation and Change,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2001}, {"title": "Discovering geographical topics in the twitter stream", "author": ["Liangjie Hong", "Amr Ahmed", "Siva Gurumurthy", "Alexander J Smola", "Kostas Tsioutsiouliklis"], "venue": "In Proceedings of the 21st international conference on World Wide Web,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2012}, {"title": "User review sites as a resource for large-scale sociolinguistic studies", "author": ["Dirk Hovy", "Anders Johannsen", "Anders S\u00f8gaard"], "venue": "In Proceedings of the 24th International Conference on World Wide Web,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2015}, {"title": "Spatial analysis of linguistic data with gis functions", "author": ["Jay Lee", "William A. Kretzschmar"], "venue": "International Journal of Geographical Information Science,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 1993}, {"title": "Machine Learning: A Probabilistic Perspective", "author": ["Kevin P. Murphy"], "venue": null, "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2012}, {"title": "Measuring the diffusion of linguistic change", "author": ["John Nerbonne"], "venue": "Philosophical Transactions of the Royal Society B: Biological Sciences,", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2010}, {"title": "Estimation methods for models of spatial interaction", "author": ["Keith Ord"], "venue": "Journal of the American Statistical Association,", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 1975}, {"title": "Supervised text-based geolocation using language models on an adaptive grid", "author": ["Stephen Roller", "Michael Speriosu", "Sarat Rallapalli", "Benjamin Wing", "Jason Baldridge"], "venue": "In Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning,", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2012}, {"title": "Recovering dialect geography from an unaligned comparable corpus", "author": ["Yves Scherrer"], "venue": "In Proceedings of the EACL 2012 Joint Workshop of LINGVIS & UNCLH,", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 2012}, {"title": "Kernel methods for pattern analysis", "author": ["John Shawe-Taylor", "Nello Cristianini"], "venue": null, "citeRegEx": "29", "shortCiteRegEx": "29", "year": 2004}, {"title": "Feature selection via dependence maximization", "author": ["Le Song", "Alex Smola", "Arthur Gretton", "Justin Bedo", "Karsten Borgwardt"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "30", "shortCiteRegEx": "30", "year": 2012}, {"title": "Measuring syntactic variation in Dutch dialects", "author": ["Marco Ren\u00e9 Spruit"], "venue": "Literary and Linguistic Computing,", "citeRegEx": "31", "shortCiteRegEx": "31", "year": 2006}, {"title": "Grammatical variation in British English dialects: a study in corpus-based dialectometry", "author": ["Benedikt Szmrecsanyi"], "venue": null, "citeRegEx": "32", "shortCiteRegEx": "32", "year": 2012}, {"title": "Discovering Dialect Regions in Syntactic Dialect Data", "author": ["Erik Tjong Kim Sang"], "venue": "In Workshop European Dialect Syntax VIII - Edisyn", "citeRegEx": "33", "shortCiteRegEx": "33", "year": 2015}, {"title": "Simple supervised document geolocation with geodesic grids", "author": ["Benjamin Wing", "Jason Baldridge"], "venue": "In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies,", "citeRegEx": "34", "shortCiteRegEx": "34", "year": 2011}, {"title": "Regional dialects in the contact call of a parrot", "author": ["Timothy F. Wright"], "venue": "Proceedings of the Royal Society of London B: Biological Sciences,", "citeRegEx": "35", "shortCiteRegEx": "35", "year": 1996}, {"title": "High-dimensional feature selection by feature-wise kernelized lasso", "author": ["Makoto Yamada", "Wittawat Jitkrittum", "Leonid Sigal", "Eric P Xing", "Masashi Sugiyama"], "venue": "Neural computation,", "citeRegEx": "36", "shortCiteRegEx": "36", "year": 2014}], "referenceMentions": [{"referenceID": 8, "context": "Figure 1 shows the geographical location of 1000 Twitter posts containing the word hella, an intensifier used in expressions like I got hella studying to do and my eyes got hella big [10].", "startOffset": 183, "endOffset": 187}, {"referenceID": 13, "context": "But does this represent a real geographical difference in American English, or is it the result of chance fluctuation in a finite dataset? Regional variation of language has been extensively studied in sociolinguistics and dialectology [5, 15, 16, 21, 25, 32].", "startOffset": 236, "endOffset": 259}, {"referenceID": 14, "context": "But does this represent a real geographical difference in American English, or is it the result of chance fluctuation in a finite dataset? Regional variation of language has been extensively studied in sociolinguistics and dialectology [5, 15, 16, 21, 25, 32].", "startOffset": 236, "endOffset": 259}, {"referenceID": 19, "context": "But does this represent a real geographical difference in American English, or is it the result of chance fluctuation in a finite dataset? Regional variation of language has been extensively studied in sociolinguistics and dialectology [5, 15, 16, 21, 25, 32].", "startOffset": 236, "endOffset": 259}, {"referenceID": 28, "context": "But does this represent a real geographical difference in American English, or is it the result of chance fluctuation in a finite dataset? Regional variation of language has been extensively studied in sociolinguistics and dialectology [5, 15, 16, 21, 25, 32].", "startOffset": 236, "endOffset": 259}, {"referenceID": 6, "context": "For example, researchers can mine social media data such as Twitter [8, 9] or product reviews [20] to identify and test thousands of dialectal variables.", "startOffset": 68, "endOffset": 74}, {"referenceID": 7, "context": "For example, researchers can mine social media data such as Twitter [8, 9] or product reviews [20] to identify and test thousands of dialectal variables.", "startOffset": 68, "endOffset": 74}, {"referenceID": 18, "context": "For example, researchers can mine social media data such as Twitter [8, 9] or product reviews [20] to identify and test thousands of dialectal variables.", "startOffset": 94, "endOffset": 98}, {"referenceID": 13, "context": "For example, Moran\u2019s I is designed for comparing frequencies in data that has been geographically aggregated by bins, such as metropolitan statistical areas [15], cities [16, 17] and counties [32].", "startOffset": 157, "endOffset": 161}, {"referenceID": 14, "context": "For example, Moran\u2019s I is designed for comparing frequencies in data that has been geographically aggregated by bins, such as metropolitan statistical areas [15], cities [16, 17] and counties [32].", "startOffset": 170, "endOffset": 178}, {"referenceID": 15, "context": "For example, Moran\u2019s I is designed for comparing frequencies in data that has been geographically aggregated by bins, such as metropolitan statistical areas [15], cities [16, 17] and counties [32].", "startOffset": 170, "endOffset": 178}, {"referenceID": 28, "context": "For example, Moran\u2019s I is designed for comparing frequencies in data that has been geographically aggregated by bins, such as metropolitan statistical areas [15], cities [16, 17] and counties [32].", "startOffset": 192, "endOffset": 196}, {"referenceID": 18, "context": "Computational linguistic studies make similar assumptions, relying on politicallydefined units [20], geodesic grids [34], KD-trees [27], Gaussians [9], and mixtures of Gaussians [19].", "startOffset": 95, "endOffset": 99}, {"referenceID": 30, "context": "Computational linguistic studies make similar assumptions, relying on politicallydefined units [20], geodesic grids [34], KD-trees [27], Gaussians [9], and mixtures of Gaussians [19].", "startOffset": 116, "endOffset": 120}, {"referenceID": 23, "context": "Computational linguistic studies make similar assumptions, relying on politicallydefined units [20], geodesic grids [34], KD-trees [27], Gaussians [9], and mixtures of Gaussians [19].", "startOffset": 131, "endOffset": 135}, {"referenceID": 7, "context": "Computational linguistic studies make similar assumptions, relying on politicallydefined units [20], geodesic grids [34], KD-trees [27], Gaussians [9], and mixtures of Gaussians [19].", "startOffset": 147, "endOffset": 150}, {"referenceID": 17, "context": "Computational linguistic studies make similar assumptions, relying on politicallydefined units [20], geodesic grids [34], KD-trees [27], Gaussians [9], and mixtures of Gaussians [19].", "startOffset": 178, "endOffset": 182}, {"referenceID": 21, "context": "This assumption of linearity is refuted by both theoretical and empirical dialectological evidence [24], and will therefore limit the statistical power of both the Mantel Test and Moran\u2019s I.", "startOffset": 99, "endOffset": 103}, {"referenceID": 19, "context": "Conversely, in its original form, Point Pattern Analysis [21] is suitable only for binary or category data.", "startOffset": 57, "endOffset": 61}, {"referenceID": 25, "context": "To address these limitations, we propose a new test statistic that builds on a rich and growing literature on kernel-based methods for non-parametric statistics [29].", "startOffset": 161, "endOffset": 165}, {"referenceID": 13, "context": "The first three methods are included because they are used in linguistic papers on dialect: Moran\u2019s I [15], Point Pattern Analysis [21] and the Mantel test [28].", "startOffset": 102, "endOffset": 106}, {"referenceID": 19, "context": "The first three methods are included because they are used in linguistic papers on dialect: Moran\u2019s I [15], Point Pattern Analysis [21] and the Mantel test [28].", "startOffset": 131, "endOffset": 135}, {"referenceID": 24, "context": "The first three methods are included because they are used in linguistic papers on dialect: Moran\u2019s I [15], Point Pattern Analysis [21] and the Mantel test [28].", "startOffset": 156, "endOffset": 160}, {"referenceID": 12, "context": "After describing these methods, we present the Hilbert-Schmidt Independence Criterion (HSIC), a kernel-based nonparametric statistic for measuring cross-covariance [14].", "startOffset": 164, "endOffset": 168}, {"referenceID": 13, "context": "[15] introduced the use of Moran\u2019s I [6, 22] in the study of dialectal variation.", "startOffset": 0, "endOffset": 4}, {"referenceID": 4, "context": "[15] introduced the use of Moran\u2019s I [6, 22] in the study of dialectal variation.", "startOffset": 37, "endOffset": 44}, {"referenceID": 22, "context": "To take a probabilistic interpretation, it is typical to assume that consists of independent and identically-distributed (IID) normal random variables with zero mean [26].", "startOffset": 166, "endOffset": 170}, {"referenceID": 22, "context": "Because \u03c1 is difficult to estimate exactly [26], Moran\u2019s I is used as an approximation.", "startOffset": 43, "endOffset": 47}, {"referenceID": 5, "context": "Moran\u2019s I values often lie between \u22121 and 1, but the exact range depends on the weight matrix W , and is theoretically unbounded [7].", "startOffset": 129, "endOffset": 132}, {"referenceID": 19, "context": "Lee and Kretzschmar [21] apply Delaunay triangulation to the analysis of a set of dialect interviews, in the framework of Point Pattern Analysis (PPA).", "startOffset": 20, "endOffset": 24}, {"referenceID": 24, "context": "Scherrer [28] used the Mantel test to correlate linguistic distance with geographical distance, and Gooskens and Heeringa [13] correlated perceptual distance with linguistic distance.", "startOffset": 9, "endOffset": 13}, {"referenceID": 11, "context": "Scherrer [28] used the Mantel test to correlate linguistic distance with geographical distance, and Gooskens and Heeringa [13] correlated perceptual distance with linguistic distance.", "startOffset": 122, "endOffset": 126}, {"referenceID": 21, "context": "Yet a range of dialectometric studies have found that linguistic differences increase sublinearly with geographical distance, a phenomenon that Nerbonne has dubbed \u201cSeguy\u2019s law\u201d [24].", "startOffset": 178, "endOffset": 182}, {"referenceID": 31, "context": "2 The Mantel test has also been applied to non-human dialect analysis, revealing regional differences in the call structures of Amazonian parrots by computing a linguistic distance matrix Dx directly from spectral measurements [35].", "startOffset": 227, "endOffset": 231}, {"referenceID": 12, "context": "Both of these problems can be solved through the use of Reproducing Kernel Hilbert Spaces (RKHS), a family of techniques from non-parametric statistics, capable of capturing arbitrary statistical dependencies [14].", "startOffset": 209, "endOffset": 213}, {"referenceID": 20, "context": "The RBF kernel corresponds to a inner product between infinite-dimensional feature vectors \u03c6 [23].", "startOffset": 93, "endOffset": 97}, {"referenceID": 26, "context": "The Delta kernel has been used successfully in combination with HSIC for high-dimensional feature selection [30, 36].", "startOffset": 108, "endOffset": 116}, {"referenceID": 32, "context": "The Delta kernel has been used successfully in combination with HSIC for high-dimensional feature selection [30, 36].", "startOffset": 108, "endOffset": 116}, {"referenceID": 12, "context": "The Hilbert-Schmidt Independence Criterion (HSIC) is a nonparametric measure of the dependence between X and Y [14], and an empirical estimator is given by,", "startOffset": 111, "endOffset": 115}, {"referenceID": 12, "context": "[14], we employ a low-rank approximation to each Gram matrix, using the incomplete Cholesky decomposition [1].", "startOffset": 0, "endOffset": 4}, {"referenceID": 0, "context": "[14], we employ a low-rank approximation to each Gram matrix, using the incomplete Cholesky decomposition [1].", "startOffset": 106, "endOffset": 109}, {"referenceID": 9, "context": "4 Flaxman recently proposed a \u201ckernelized Mantel test\u201d, in which correlations are taken between kernel similarities rather than distances [11].", "startOffset": 138, "endOffset": 142}, {"referenceID": 0, "context": "Thus, if we repeatedly generate data under the null hypothesis, a well-calibrated test will return a distribution of p-values that is uniform in the interval [0, 1]: for example, we expect to observe p < .", "startOffset": 158, "endOffset": 164}, {"referenceID": 8, "context": "To generate the binary and categorical data, we use \u03bcobs = 10\u22125, meaning that the expected number of observations is one per hundred thousand individuals in the municipality or province; for comparison, this corresponds roughly to the tweet frequency of the lengthened spelling hellla in the 2009-2012 Twitter dataset gathered by Eisenstein et al [10].", "startOffset": 347, "endOffset": 351}, {"referenceID": 0, "context": "The xaxis shows the corresponding quantile for a uniform distribution on the range [0,1].", "startOffset": 83, "endOffset": 88}, {"referenceID": 13, "context": "However, some prior work takes an alternative approach, sweeping over parameter values to obtain the most significant results [15].", "startOffset": 126, "endOffset": 130}, {"referenceID": 16, "context": "Linear variation We generate data such that the frequency of a linguistic variant increases linearly through space, as in a dialect continuum [18].", "startOffset": 142, "endOffset": 146}, {"referenceID": 13, "context": "In the frequency-based synthetic data, each instance uses each variable form with some continuous frequency \u2014 this is based on the scenario of letters-to-the-editors of regional newspapers, as explored in prior work [15].", "startOffset": 216, "endOffset": 220}, {"referenceID": 3, "context": "To account for multiple hypothesis testing, we use the BenjaminiHochberg false discovery rate procedure to adjust the p-values [4].", "startOffset": 127, "endOffset": 130}, {"referenceID": 1, "context": "SAND [2, 3] is an online electronic atlas that maps syntactic variation of Dutch varieties in the Netherlands, Belgium, and France.", "startOffset": 5, "endOffset": 11}, {"referenceID": 2, "context": "SAND [2, 3] is an online electronic atlas that maps syntactic variation of Dutch varieties in the Netherlands, Belgium, and France.", "startOffset": 5, "endOffset": 11}, {"referenceID": 27, "context": "SAND has been used to measure the distances between dialects, and to discover dialect regions [31, 33].", "startOffset": 94, "endOffset": 102}, {"referenceID": 29, "context": "SAND has been used to measure the distances between dialects, and to discover dialect regions [31, 33].", "startOffset": 94, "endOffset": 102}, {"referenceID": 10, "context": "Previous dialect research has found that geography is the most important external factor for t-deletion in the Netherlands [12].", "startOffset": 123, "endOffset": 127}], "year": 2017, "abstractText": "Quantifying the degree of spatial dependence for linguistic variables is a key task for analyzing dialectal variation. However, existing approaches have important drawbacks. First, they make unjustified assumptions about the nature of spatial variation: some assume that the geographical distribution of linguistic variables is Gaussian, while others assume that linguistic variation is aligned to pre-defined geopolitical units such as states or counties. Second, they are not applicable to all types of linguistic data: some approaches apply only to frequencies, others to boolean indicators of whether a linguistic variable is present. We present a new method for measuring geographical language variation, which solves both of these problems. Our approach builds on reproducing kernel Hilbert space (RKHS) representations for nonparametric statistics, and takes the form of a test statistic that is computed from pairs of individual geotagged observations without aggregation into predefined geographical bins. We compare this test with prior work using synthetic data as well as a diverse set of real datasets: a corpus of Dutch tweets, a Dutch syntactic atlas, and a dataset of letters to the editor in North American newspapers. Our proposed test is shown to support robust inferences across a broad range of scenarios and types of data.", "creator": "LaTeX with hyperref package"}}}