{"id": "1601.06763", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "25-Jan-2016", "title": "Emerging Dimension Weights in a Conceptual Spaces Model of Concept Combination", "abstract": "We investigate the generation of new concepts from combinations of properties as an artificial language develops. To do so, we have developed a new framework for conjunctive concept combination. This framework gives a semantic grounding to the weighted sum approach to concept combination seen in the literature. We implement the framework in a multi-agent simulation of language evolution and show that shared combination weights emerge. The expected value and the variance of these weights across agents may be predicted from the distribution of elements in the conceptual space, as determined by the underlying environment, together with the rate at which agents adopt others' concepts. When this rate is smaller, the agents are able to converge to weights with lower variance. However, the time taken to converge to a steady state distribution of weights is longer. We provide a framework for these insights. The combined weight of agent properties of the conceptual space can be calculated with probability and covariance variables, which allows the simulation to take a much longer time. We estimate the expected value of a combination between a pair of two different inputs and a single pair of pairs of two different inputs. These include a simple model, which uses the same parameters to calculate their variance. The model's initial values can be calculated by dividing the expected value and the model's covariance (which is determined by the model's covariance) to make it a general concept.\n\n\n\n\nThe model's covariance is an estimate of the variance of the two inputs. The model's covariance estimates of the variance of the two inputs. The model's covariance estimates of the variance of the two inputs. The model's covariance estimates of the variance of the two inputs. The model's covariance estimates of the variance of the two inputs. The model's covariance estimates of the variance of the two inputs. The model's covariance estimates of the variance of the two inputs. The model's covariance estimates of the variance of the two inputs. The model's covariance estimates of the variance of the two inputs. The model's covariance estimates of the variance of the two inputs.\n\nThe model's covariance estimates of the variance of the two inputs. The model's covariance estimates of the variance of the two inputs. The model's covariance estimates of the variance of the two inputs. The model's covariance estimates of the variance of the two inputs.\nThe model's covariance estimates of the variance of the two inputs. The model's covariance estimates of the variance of the two inputs. The model's covariance estimates of the", "histories": [["v1", "Mon, 25 Jan 2016 20:40:55 GMT  (157kb,D)", "http://arxiv.org/abs/1601.06763v1", "AISB 2014, updated to include references to previous work"]], "COMMENTS": "AISB 2014, updated to include references to previous work", "reviews": [], "SUBJECTS": "cs.AI cs.CL cs.MA", "authors": ["martha lewis", "jonathan lawry"], "accepted": false, "id": "1601.06763"}, "pdf": {"name": "1601.06763.pdf", "metadata": {"source": "CRF", "title": "Emerging Dimension Weights in a Conceptual Spaces Model of Concept Combination", "authors": ["Martha Lewis", "Jonathan Lawry"], "emails": ["martha.lewis@bristol.ac.uk,", "j.lawry@bristol.ac.uk"], "sections": [{"heading": "1 INTRODUCTION", "text": "Humans are skilled at making sense of novel combinations of concepts, so to create artificial languages for implementation in AI systems, we must model this ability. Standard approaches to combining concepts, e.g. fuzzy set theory, have been shown to be inadequate [11]. Concepts formed through the combination of properties frequently have \u2018emergent attributes\u2019 [3] which cannot be explicated by decomposing the label into its constituent parts. We have developed a model of concept combination within the label semantics framework as given in [8, 10]. The model is inspired by and reflects results in [3], in which membership in a compound concept can be rendered as the weighted sum of memberships in individual concepts, however, it can also account for emergent attributes, where e.g. importance in a conjunctive concept is greater than the importance of an attribute in the constituent concepts. We implement a simple version of this model in a multi-agent simulation of language users, and show that the agents converge to shared combination weights, allowing effective communication. These weights are determined by the distribution of objects in the agents\u2019 conceptual space. This provides a theoretical grounding to the proposal seen in the literature [2, 3, 6, 16] that complex concepts can be characterised as weighted sums of attributes. Further, it relates the weights in the combined concept to the external world. In this paper, we firstly summarise the theoretical framework we use (section 2), and in section 3 give a brief account of our model of concept combination. In section 4, we implement a simple version of our model in a multi-agent simulation of a community of language users in order to examine whether an how such a community is able to converge to shared combination weights. We give simulation methods and results, and analyse the behaviour of the\n1 University of Bristol, England, email: martha.lewis@bristol.ac.uk, j.lawry@bristol.ac.uk\nagents. Finally, section 5 discusses our results and gives an indication of future work."}, {"heading": "2 BACKGROUND", "text": "We model concepts within the label semantics framework [7, 8], combined with prototype theory [12] and the conceptual spaces model of concepts [2]. Prototype theory offers an alternative to the classical theory of concepts, basing categorization on proximity to a prototype. This approach is based on experimental results where human subjects were found to view membership in a concept as a matter of degree, with some objects having higher membership than others [12]. Fuzzy set theory [15], in which an object x has a graded membership \u00b5L(x) in a concept L, was proposed as a formalism for prototype theory. However, numerous objections to its suitability have been made [4, 3, 5, 11, 13].\nConceptual spaces theory renders concepts as convex regions of a conceptual space - a geometrical structure with quality dimensions and a distance metric. Examples are: the RGB colour cube, pictured in figure 1; physical dimensions of height, breadth and depth; or the taste tetrahedron. Since concepts are convex regions of such spaces, the centroid of such a region can naturally be viewed as the prototype of the concept.\nLabel semantics proposes that agents use a set of labels LA = {L1, ..., Ln} to describe a conceptual space \u2126 with distance metric d(x, x\u2032). Labels Li are associated with prototypes Pi \u2286 \u2126 and uncertain thresholds \u03b5i, drawn from probability distributions \u03b4\u03b5i . The threshold \u03b5i captures the notion that an element x \u2208 \u2126 is sufficiently close to Pi to be labelled Li. The membership of an object x in a concept Li is quantified by \u00b5Li(x), given by\nar X\niv :1\n60 1.\n06 76\n3v 1\n[ cs\n.A I]\n2 5\nJa n\n20 16\n\u00b5Li(x) = P (d(x, Pi) \u2264 \u03b5i) = \u222b \u221e d(x,Pi) \u03b4\u03b5i(\u03b5i)d\u03b5i\nLabels can then be described as Li =<Pi, d(x, x\u2032), \u03b4\u03b5i >. We illustrate this idea in figure 2."}, {"heading": "3 A HIERARCHICAL MODEL OF CONCEPT COMPOSITION", "text": "Experiments in the psychological literature propose that human concept combination can in many cases be modelled as a weighted sum of attributes such as \u2018has feathers\u2019, \u2018has a beak\u2019 (for the concept \u2018Bird\u2019) [3]. These attributes differ from quality dimensions in conceptual spaces: they tend to be binary, complex, and multidimensional in themselves. We therefore view each attribute as a label in a continuous conceptual space \u2126i and combine these labels in a binary conceptual space {0, 1}n illustrated in figure 3. In this binary conceptual space, a conjunction of such labels \u03b1 = \u2227n i=1\u00b1Li maps to a binary vector ~y\u03b1 taking value 1 for positive labels Li and 0 for negated labels \u00acLi (figure 4).\nWe treat membership in \u03b1 in the binary conceptual space within the label semantics framework. So \u03b1 is described in the binary space by \u03b1\u0303 =<~y\u03b1, d(~y, ~y\u2032), \u03b4> as before, and \u00b5\u03b1(y) = \u222b\u221e d(y,y\u03b1)\n\u03b4\u03b5(\u03b5)d\u03b5. Since the dimensions of the space are weighted, some are considered more important than others. The presence or absence of some attributes may be relaxed. For example, \u2018Bird\u2019 might be characterised by (among others) the attributes \u2018has feathers\u2019, \u2018has wings\u2019, \u2018flies\u2019.\nThe attributes \u2018has wings\u2019 and \u2018has feathers\u2019 should be given more importance than \u2018flies\u2019. This is because various species of birds do not fly, so this attribute may be relaxed whilst still allowing something to be categorised as a bird. The effect this has is to create elliptical regions of the conceptual space, as illustrated in figure 5.\nThe distance metric between two vectors ~y, ~y\u2032 in the binary space {0, 1}n is written H~\u03bb(~y, ~y\n\u2032) and defined as a weighted city block metric.\nThen, under certain constraints, membership in the combined concept \u03b1 = \u2227n i=1\u00b1Li is equal to the weighted sum of membership in each of the Li. This is stated in the following theorem:\nTheorem 1 (Compound Concepts). Let Li be attributes described by membership functions \u00b5Li(xi) in conceptual spaces \u2126i. Let \u03b1 be a conjunction of such attributes (or their negation): \u03b1 = \u2227n i=1\u00b1Li. If we combine these labels in a binary space {0, 1}n with \u03b1\u0303 =< ~y\u03b1, H~\u03bb, U(0, \u03bbT )> where \u03bbT = \u2211n i=1 \u03bbi, then we may calculate the membership in \u03b1 in the space \u21261 \u00d7 ...\u00d7 \u2126n by:\n\u00b5\u03b1(~x) = n\u2211 i=1 \u03bbi \u03bbT \u00b5\u00b1Li(xi)\nwhere ~x \u2208 \u21261 \u00d7 ...\u00d7 \u2126n, xi \u2208 \u2126i.\nWe may further combine such compound concepts \u03b8, \u03d5 in a higher level binary space. Then, again under certain constraints, \u03b8\u0303 \u2022 \u03d5\u0303 can be expressed in the continuous space as a weighted sum of \u03b8 and \u03d5.\nTheorem 2 (Conjunction of Compound Concepts). Let \u03b8\u0303 \u2022 \u03d5\u0303 =< {(1, 1)}, H~w, \u03b4 >, where \u03b8 and \u03d5 are compound concepts as de-\nscribed in theorem 1, so that \u03b8 is characterised by membership function \u00b5\u03b8(~x) = \u2211n i=1\n\u03bb\u03b8i \u03bb\u03b8T \u00b5\u00b1Li(xi) for ~x \u2208 \u21261 \u00d7 ...\u00d7\u2126n, xi \u2208 \u2126i, and \u03d5 is similarly characterised. Then\n\u00b5\u03b8\u0303\u2022\u03d5\u0303(~x) = n\u2211 i=1 ( w1\u03bb\u03d5T \u03bb\u03b8i + w2\u03bb\u03b8T \u03bb\u03d5i wT\u03bb\u03b8T \u03bb\u03d5T )\u00b5\u00b1Li(~x)\nwhere ~x \u2208 \u21261 \u00d7 ...\u00d7 \u2126n, xi \u2208 \u2126i.\nThese results show that under the constraint \u03b5 \u223c U(0, \u03bbT ), combining labels in a weighted binary conceptual space leads naturally to the creation of compound concepts as weighted sums of individual labels, reflecting results in [3]. An important aspect of these results is that non-compositional phenomena are seen, such as emergent attributes. These are attributes that become more important in the conjunction of two concepts than in either of the constituent concepts. A specific example seen in [3] is that the attribute\u2018talks\u2019 becomes more important in the conjunction \u2018Birds that are Pets\u2019 than in either \u2018Birds\u2019 or \u2018Pets\u2019. Relaxing the constraint \u03b5 \u223c U(0, \u03bbT ) allows us to account for phenomena such as emergent attributes and overextension of concepts. In the current paper, however, we concentrate on a simple weighted sum combination and examine the properties of this type of combination in multi-agent simulations."}, {"heading": "4 CONVERGENCE OF DIMENSION WEIGHTS ACROSS A POPULATION", "text": "We implement a simple version of the hierarchical model of concept combination in a multi-agent simulation of agents playing a series of language games, similar to those used in [14]. We investigate how agents using compound concepts \u03b1 in a conceptual space converge to a shared weighting of the constituent concepts Li. Agents do indeed converge to a shared weighting, which is dependent on the distribution of objects in the environment and also on the rate at which they move towards other agents\u2019 concepts. Section 4.1 describes the methods and simulation set-up. Section 4.2 gives simulation results, and section 4.3 gives an analysis of the results."}, {"heading": "4.1 Methods", "text": "Consider agents each with labels L1 =< P1, d(x, y), \u03b41 >\u2208 \u21261, L2 =< P2, d(x, y), \u03b42 >\u2208 \u21262. We assume that agents combine these two labels as in section 3 - i.e., in a binary space {0, 1}2 with weight vector ~\u03bb = (\u03bb1, \u03bb2)> and where the threshold in the binary space \u03b5 has distribution \u03b4 = U(0, \u03bbT ), where \u03bbT = \u03bb1 + \u03bb2. Then, membership in the conjunction L1 \u2227L2 in the space \u21261 \u00d7\u21262 may be calculated as a weighted sum of membership in the individual spaces. W.l.o.g. we assume that \u03bbT = 1. We therefore have \u00b5L1\u2227L2(~x) = \u03bb\u00b5L1(x1) + (1\u2212 \u03bb)\u00b5L2(x2).\nTo investigate how these weights are to be determined, we run simulations in which agents with equal labels but randomly initiated weights engage in a series of dialogues about elements in the conceptual space, adjusting their weights after each dialogue is completed."}, {"heading": "4.1.1 Assertion algorithm", "text": "Agents are equipped with shared labels L1 \u2208 \u21261 = [0, 1] and L2 \u2208 \u21262 = [0, 1], and a weight \u03bb. At each timestep agents are paired into speaker and listener agents. Each pair of agents is shown an element\nx \u2208 \u21261 \u00d7 \u21262 = [0, 1]2. The speaker agent asserts one of\n\u03b11 = L1 \u2227 L2 \u03b12 = L1 \u2227 \u00acL2 \u03b13 = \u00acL1 \u2227 L2 \u03b14 = \u00acL1 \u2227 \u00acL2\nwhere the membership in the compound concept is determined by the weighted sum of the memberships in the constituent concepts.\n\u00b5\u03b11(x) = \u03bb\u00b5L1(x1) + (1\u2212 \u03bb)\u00b5L2(x2) \u00b5\u03b12(x) = \u03bb\u00b5L1(x1) + (1\u2212 \u03bb)(1\u2212 \u00b5L2(x2)) \u00b5\u03b13(x) = \u03bb(1\u2212 \u00b5L1(x1)) + (1\u2212 \u03bb)\u00b5L2(x2) \u00b5\u03b14(x) = \u03bb(1\u2212 \u00b5L1(x1)) + (1\u2212 \u03bb)(1\u2212 \u00b5L2(x2))\nThe concept \u03b1i asserted is that for which \u00b5\u03b1i(x) is maximal. Note that this implies that if \u03b1i asserted then \u00b5\u03b1i(x) \u2265 0.5."}, {"heading": "4.1.2 Updating algorithm", "text": "We compare two different updating algorithms. The first implements the idea that the listener agent updates its concepts when the agent\u2019s belief in the appropriateness of a compound label, \u00b5\u03b1i(x), is less than the reliability of the speaker as measured by a weightw \u2208 [0, 1]. So if \u00b5\u03b1i(x) \u2264 w the listener agent updates its label set.\nThe update consists in moving the dimension weight \u03bb towards the value A which satisfies \u00b5\u03b8(x) = w, where\nA = w \u2212 \u00b5L2(x2)\n\u00b5\u00b1L1(x1)\u2212 \u00b5\u00b1L2(x2)\nHowever, it is possible for A < 0 or A > 1, in which cases we set A = 0 or A = 1, giving us:\nA =  1 if w\u2212\u00b5L2 (x2) \u00b5\u00b1L1 (x1)\u2212\u00b5\u00b1L2 (x2) > 1 0 if w\u2212\u00b5L2 (x2) \u00b5\u00b1L1 (x1)\u2212\u00b5\u00b1L2 (x2) < 0\nw\u2212\u00b5L2 (x2) \u00b5\u00b1L1 (x1)\u2212\u00b5\u00b1L2 (x2)\notherwise\nThe listener agent updates the weight \u03bb to \u03bb\u2032 by:\n\u03bb\u2032 = \u03bb+ h(A\u2212 \u03bb)\nWe measure the convergence between \u03bbi across the agents as the standard deviation (SD) of the \u03bbi.\nWe also introduce a second updating algorithm. This is similar to the first with the exception that the criterion for updating is that \u00b5\u03b1i(~x) 6= w. This means that if an agent with low reliability makes an assertion, the listener agent shifts the dimension weight \u03bb to reduce the appropriateness of the assertion \u03b1i."}, {"heading": "4.1.3 Simulation Details", "text": "Agents have labelsL1 = L2 =<1, d, U [0, 1]>, where d is Euclidean distance, to describe the conceptual space \u2126 = \u21261\u00d7\u21262 = [0, 1]2. In this case, we have \u00b5Li(x) = xi. Simulations are run with 10 agents for 2, 000 timesteps with increment h = 10\u22123 unless otherwise indicated. At each timestep, each agent talks to every other agent, in a randomised order. Simulation results are averaged across 25 runs.\nParameters varied are the distribution of elements within the conceptual space and the reliability of the agents. So, for example, one simulation might include elements sampled uniformly across the whole conceptual space, whereas another might include elements sampled uniformly from one half of the space. This difference in distribution leads to differences in the combination weights."}, {"heading": "4.2 Simulation Results", "text": ""}, {"heading": "4.2.1 Updating model 1: \u00b5\u03b1i(~x) < w", "text": "Within this updating model, the listener agent updates only when \u00b5\u03b1i(~x) < w. We find that when the agent reliabilityw > 0.5, agents are able to converge to a shared weight \u03bb. The weight to which agents converge is dependent on the distribution of objects in the environment, and the reliability w of the agents. When w = 1 for all agents, and x1 \u223c U [0, 1], x2 \u223c U [0, 0.5], so that elements are encountered within half of the total space \u2126 = [0, 1]2, the agents converge to a value of \u03bb = 0.5, as seen in figure ??.\nze When the distribution of elements in the environment is changed, \u03bb may converge to a different value. For example, changing the distribution of the elements in the space to x1 \u223c U [0.25, 0.75], x2 \u223c U [0, 0.5], with w = 1 for all agents, results in a final value of \u03bb = 0.25, illustrated in figure 6.\nThe final value of \u03bbmay also be dependent on the reliability of the agents as parameterised by w. For some distributions, the value of w does not affect the value of \u03bb to which agents converge. In others, the value of w alters the weighting \u03bb. This is illustrated in figure 7."}, {"heading": "4.2.2 Updating model 2: \u00b5\u03b1i(~x) 6= w", "text": "We also introduce a second updating model, in which the listener agent updates whenever \u00b5\u03b1i(~x) 6= w. Although this model is slightly less realistic, it is more amenable to analysis, and so we use this as a starting point for the analysis of these systems. Again, each set of simulations is run 25 times and results are averaged. Figure 8 compares the results of simulations run using the two different assertion models, where x1 \u223c U [0.25, 0.75], x2 \u223c U [0, 0.5].\nWhen the updating condition requires that \u00b5\u03b1i(~x) 6= w, agents converge to a shared weight \u03bb even when their reliability w \u2264 0.5. However, the values of \u03bb to which agents converge are not the same as those converged to under the first assertion algorithm.\nThese results show that the combination weights that the agents converge to are dependent on firstly the distribution of elements in the conceptual space, as determined by the environment, and secondly the reliability of the agents in the space. We go on to give an analysis of these results, and to prove some results relating the values of the final weights to the distribution of objects within the conceptual space."}, {"heading": "4.3 Analysis", "text": "We wish to analyse the results seen in section 4.2 in order to predict the value to which \u03bb will converge and also the extent to which it will converge across agents as measured by the standard deviation of the \u03bbi across agents. To do so, we start with some analysis of the particular space and labels we have used before giving some more general results.\nWithin the results in section 4.2, agents have labels L1 = L2 =< 1, U [0, 1] > to describe the conceptual space \u2126 = [0, 1]2. In this case, we have \u00b5Li(x) = xi. Each assertion \u03b1i is made exactly when each component \u00b5\u00b1L1(x) > 0.5, \u00b5\u00b1L2(x) > 0.5 (since otherwise\nanother \u03b1j would be maximal). We can therefore split up the conceptual space into quadrants corresponding to where each \u03b1i is asserted, displayed in figure 9. Each quadrant where \u03b1i is asserted is called Ri.\n0 0.2 0.4 x1\n0.6 0.8 1 0\n0.2\n0.4 x2\n0.6\n0.8\n1\nR3 R1\nR4 R2\nFigure 9: Each assertion \u03b1i is made when ~x = (x1, x2) falls in Ri\nTo investigate the value to which the \u03bbi converge, we look at the quantity (A \u2212 \u03bb). If (A \u2212 \u03bb) is positive, \u03bb will increase, and if it is negative, \u03bb will decrease. We therefore look at the circumstances that lead to \u03bb increasing or decreasing. We do this on a case by case basis depending on which assertion is being made.\nCase: \u03b11 is asserted\nWhen \u03b11 is asserted, \u00b5L1(x1) = x1 > 0.5, \u00b5L2(x2) = x2 > 0.5. We wish to know when A > \u03bb\nA = w \u2212 \u00b5L2(x2)\n\u00b5L1(x1)\u2212 \u00b5L2(x2) = w \u2212 x2 x1 \u2212 x2 \u2265 \u03bb\n\u03bb is updated when \u00b5\u03b11 = \u03bbx1 + (1\u2212 \u03bb)x2 < w, i.e. when\nw \u2212 x2 \u2265 \u03bb(x1 \u2212 x2)\nThen if (x1 \u2212 x2) > 0 then A \u2265 \u03bb, and the update is a positive increment. Otherwise the reverse holds, i.e. A \u2264 \u03bb and the update is a negative increment.\nCase: \u03b12 is asserted\nWhen \u03b12 is asserted, \u03bb is updated when \u00b5\u03b12 = \u03bbx1 + (1\u2212 \u03bb)(1\u2212 x2) < w, i.e. when\nw \u2212 (1\u2212 x2) \u2265 \u03bb(x1 + x2 \u2212 1)\nThen if (x1 + x2 \u2212 1) > 0, A \u2265 \u03bb, and the update is a positive increment. Otherwise the reverse holds, i.e. A \u2264 \u03bb and the update is a negative increment.\nCase: \u03b13 is asserted\nWhen \u03b13 is asserted, \u03bb is updated when \u00b5\u03b13(~x) = \u03bb(1\u2212x1)+(1\u2212 \u03bb)x2 < w, i.e. when\nw \u2212 x2 \u2265 \u03bb(1\u2212 x1 \u2212 x2)\nThen if (1 \u2212 x1 \u2212 x2) > 0, A \u2265 \u03bb, and the update is a positive increment. Otherwise the reverse holds, i.e. A \u2264 \u03bb and the update is a negative increment.\nCase: \u03b14 is asserted\nWhen \u03b14 is asserted, \u03bb is updated when \u00b5\u03b14(~x) = \u03bb(1\u2212x1)+(1\u2212 \u03bb)(1\u2212 x2) < w, i.e. when\nw \u2212 (1\u2212 x2) \u2265 \u03bb(x2 \u2212 x1)\nThen if (x2 \u2212 x1) > 0, A \u2265 \u03bb, and the update is a positive increment. Otherwise the reverse holds, i.e. A \u2264 \u03bb and the update is a negative increment.\nEach of these cases can be represented graphically, since the conditions are determined by the lines x1 = x2 and x1 = 1 \u2212 x2. This is illustrated in figure 10. We call areas of the space where a positive update is made positive regions and areas of the space where negative updates are made negative regions.\n0 0.2 0.4 x1\n0.6 0.8 1 0\n0.2\n0.4 x2\n0.6\n0.8\n1\n--\n- -\n+\n+\n+\n+\nFigure 10: The type of update made when ~x = (x1, x2) falls in each area of the space\nWe can now prove some results concerning the final value of \u03bb across the population of agents.\nTheorem 3. Suppose that agents have labels L1 = L2 =< 1, U(0, 1) > and all agents have weight 1. Agents update their concepts according to the language game described using updating model 1. Suppose that there is a probability p+ of ~x falling in a positive region and probability p\u2212 = 1 \u2212 p+ of ~x falling in a negative region. Then the expected value of \u03bb converges to p+\nProof. Whenever ~x falls in the positive region, A \u2265 1 and hence we set A = 1. For example, suppose ~x \u2208 R1. Then\nA = 1\u2212 x2 x1 \u2212 x2\nNow 1\u2212x2 \u2265 0 so the sign ofA is determined by x1\u2212x2. If ~x falls in the positive quadrant then x1 > x2 so\nA = 1\u2212 x2 x1 \u2212 x2 \u2265 1"}, {"heading": "So A = 1 and the update is \u03bbn+1 = \u03bbn + h(1\u2212 \u03bbn)", "text": "If ~x falls in the negative quadrant then x1 < x2 so\nA = 1\u2212 x2 x1 \u2212 x2 \u2264 0\nSo A = 0 and the update is \u03bbn+1 = \u03bbn \u2212 h\u03bbn. Similar arguments can be made for the other quadrants, giving us the following updating rule:\n\u03bbt+1 =\n{ \u03bbt(1\u2212 h) if ~x \u2208 R\u2212\n\u03bbt(1\u2212 h) + h if ~x \u2208 R+\nThen consider the behaviour of the expected value of \u03bb over time:\nE(\u03bbt+1) = E(\u03bbt+1|~x \u2208 R+)p+ + E(\u03bbt+1|~x \u2208 R\u2212)p\u2212\n= E(\u03bbt(1\u2212 h) + h|~x \u2208 R+)p+\n+ E(\u03bbt(1\u2212 h)|~x \u2208 R\u2212)p\u2212\n= (1\u2212 h)E(\u03bbt) + p+h\nAs t\u2192\u221e, we have\nE(\u03bb) = E(\u03bb)(1\u2212 h) + p+h = p+\nWe have therefore related the value of \u03bb to which agents converge to the distribution of elements ~x in the conceptual space \u2126.\nTheorem 4. Suppose agents are equipped with labels L1, L2 and combine and update these label according to the language game described. Then the expected value of \u03bb, E(\u03bb) = E(A).\nProof. To obtain E(\u03bb), consider:\n\u03bbt+1 = \u03bbt(1\u2212 h) + hA\nE(\u03bbt+1) = E(\u03bbt(1\u2212 h) + hA) = (1\u2212 h)E(\u03bbt) + hE(A)\nThen as t\u2192\u221e, we have\nE(\u03bb) = E(\u03bb)(1\u2212 h) + hE(A) = E(A)\nThis result shows that the weighting given to the compound concepts \u03b1i may be directly predicted from the distribution of elements in the conceptual space and the membership functions used to categorise the constituent labels Lj .\nIf we consider updating model 2, where agents update whenever \u00b5\u03b1i(~x) 6= w, we may also obtain an expression for the variance of the \u03bbi across agents.\nTheorem 5. Suppose agents have labels L1, L2 and that agents update according to updating model 2: \u00b5\u03b1i(~x) 6= w. Then the variance of the \u03bb across agents is V ar(\u03bb) = h\n2\u2212hV ar(A)\nProof. We obtain V ar(\u03bb) by firstly calculating E(\u03bb2):\nE(\u03bb2t+1) = E((\u03bbt(1\u2212 h) + hA)2)\n= E((1\u2212 h)2\u03bb2t + 2h(1\u2212 h)\u03bbtA+ h2A2))\n= (1\u2212 h)2E(\u03bb2t ) + 2h(1\u2212 h)E(\u03bbt)E(A) + h2E(A2)\nWe may then calculate\nV ar(\u03bbt+1) = E(\u03bb 2 t+1)\u2212 (E(\u03bbt+1))2\n= (1\u2212 h)2E(\u03bb2t ) + 2h(1\u2212 h)E(\u03bbt)E(A)\n+ h2E(A2)\u2212 (E(\u03bb)(1\u2212 h) + hE(A))2\n= (1\u2212 h)2E(\u03bb2t ) + 2h(1\u2212 h)E(\u03bbt)E(A)\n+ h2E(A2)\u2212 (1\u2212 h)2(E(\u03bbt))2\n\u2212 2h(1\u2212 h)E(\u03bbt)E(A)\u2212 h2(E(A))2\n= (1\u2212 h)2V ar(\u03bbt)\u2212 h2V ar(A)\nAs t\u2192\u221e, we have\nV ar(\u03bb) = (1\u2212 h)2V ar(\u03bb)\u2212 h2V ar(A)\n= h\n2\u2212 hV ar(A)\nWe can further examine how quickly the mean and variance of \u03bbi approach that ofA. We obtain an expression forE(\u03bbt) and V ar(\u03bbt) in terms of t and solve. The speed at which the \u03bbi converge to the resting state is dependent on h.\nTheorem 6. Suppose agents are equipped with labels L1, L2 and combine and update these label according to the language game described, using updating model 2. Then the number of timesteps until |E(\u03bbt) \u2212 E(A)| \u2264 for some small is t \u2265 (log( ) \u2212 log(|E(\u03bb0) \u2212 E(A)|))/ log(1 \u2212 h), and the number of timesteps until |V ar(\u03bbt)\u2212 h2\u2212hV ar(A)| \u2264 is\nt \u2265 (log( )\u2212 log(|V ar(\u03bb0)\u2212 h2\u2212hV ar(A)|))\n2 log(1\u2212 h)\nProof. We firstly obtain an expression for E(\u03bbt) in terms of t, h, E(A) and E(\u03bb0)\nE(\u03bbt) = E(\u03bbt\u22121)(1\u2212 h) + hE(A)\n= E(\u03bb0)(1\u2212 h)t + E(A) t\u2211\nk=1\n(h(1\u2212 h)t\u22121)\n= E(\u03bb0)(1\u2212 h)t + E(A)(1\u2212 (1\u2212 h)t)\nNow, consider\n\u2265 |E(\u03bbt)\u2212 E(A)| = |E(\u03bb0)\u2212 E(A)|(1\u2212 h)t\nt \u2265 (log( )\u2212 log(|E(\u03bb0)\u2212 E(A)|))/ log(1\u2212 h)\nTo calculate the number of timesteps needed until V ar(\u03bb) has reached its resting state, we again obtain an expression for V ar(\u03bbt) in terms of t, h, V ar(A) and V ar(\u03bb0).\nV ar\u03bbt = (1\u2212 h)2V ar(\u03bb(t\u2212 1))\u2212 h2V ar(A)\n= V ar(\u03bb0)(1\u2212 h)2t + V ar(A) t\u2211\nk=1\nh2(1\u2212 h)2t\n= V ar(\u03bb0)(1\u2212 h)2t + h\n2\u2212 hV ar(A)(1\u2212 (1\u2212 h) 2t)\nAgain, consider\n\u2265 |V ar(\u03bbt)\u2212 h\n2\u2212 hV ar(A)|\n= |V ar(\u03bb0)\u2212 h\n2\u2212 hV ar(A)|(1\u2212 h) 2t\nt \u2265 (log( )\u2212 log(|V ar(\u03bb0)\u2212 h2\u2212hV ar(A)|))\n2 log(1\u2212 h)\nTo illustrate these results, we ran simulations of the language game with 1000 agents each with L1 = L2 =<1, U(0, 1)>, w = 1, x1 \u223c U [0.25, 0.75], x2 \u223c U [0, 0.5], and h \u2208 {10\u22122, 10\u22123, 10\u22124, 10\u22125}. Figure 11 shows the values ofE(\u03bbt) over time obtained from simulations, together with the predicted value of E(\u03bbt) and also the resting state E(\u03bb).\nFigure 12 shows the values of V ar(\u03bbt) over time obtained from simulations, together with the predicted value of V ar(\u03bbt) and also the resting state V ar(\u03bb).\nThese results illustrate that the rate at which agents converge to the resting state is dependent on the value h by which agents adopt others agents\u2019 viewpoints. Larger values of h allow faster convergence to the resting state, however that resting state will have a larger variance when h is larger."}, {"heading": "5 DISCUSSION", "text": "Characterising concepts as a weighted sum of attributes is seen throughout the literature [2, 3, 6, 16]. However, this has been proposed in an ad hoc fashion, and many concepts do not adhere to this formulation. Further, no mechanism for determining the weights has been proposed. We have developed a hierarchical model of concept combination from which the characterisation of concepts as a weighted sum of attributes arises naturally, summarised in section 2. We have implemented a simple version of this model within the language game framework in which agents make assertions that consist of a weighted sum of two constituent concepts. We have shown that within a multi-agent simulation of a community of such language users agents can converge to shared weightings (section 4.2). The weights \u03bbi to which the community of agents converge are related to the distribution of elements xj in the conceptual space, the membership functions \u00b5Lj (xj) used for the constituent concepts, and the reliability w of the agents. We have derived explicit expressions re-\nlating the mean of the final weights \u03bbi across all agents to the distribution of the xj , \u00b5Lj (xj), and w. In a modified updating model that is more amenable to analysis, we have derived expressions for the variance of the \u03bbi in terms of xj , \u00b5Lj (xj), w and also h, the rate at which agents adopt other agents\u2019 concepts. When h is small, i.e. agents are slower to adopt others\u2019 concepts, the variance of the \u03bbi is smaller, perhaps indicating that more robust concepts are formed. We have also derived expressions for the speed at which the resting distribution of the \u03bbi are approached, dependent on the value of h (section 4.3). The results from this model indicate how weightings in a weighted sum of concepts can be related to the elements encountered in a conceptual space.\nThis model is of course extremely simple, and numerous extensions are ongoing. The use of more complex labels Li is under investigation, with labels being extended to multiple dimensions. We are also developing the updating algorithm in order to combine more than two labels and to include noise in agents\u2019 labels. In previous work [1, 9], the agents in the simulations have had varying reliability w, which could be incorporated into these simulations. Future work will also incorporate the theoretical aspects alluded to in section 2 that account for non-compositional properties such as emergent attributes."}, {"heading": "ACKNOWLEDGEMENTS", "text": "Martha Lewis gratefully acknowledges support from EPSRC Grant No. EP/E501214/1"}], "references": [{"title": "Language games with vague categories and negations", "author": ["Henrietta Eyre", "Jonathan Lawry"], "venue": "Adaptive Behavior,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2014}, {"title": "Conceptual spaces: The geometry of thought", "author": ["P. G\u00e4rdenfors"], "venue": "The MIT Press", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2004}, {"title": "Inheritance of attributes in natural concept conjunctions", "author": ["J. Hampton"], "venue": "Memory & Cognition, 15(1), 55\u201371, ", "citeRegEx": "3", "shortCiteRegEx": null, "year": 1987}, {"title": "Conceptual combinations and fuzzy logic", "author": ["J. Hampton"], "venue": "Concepts and Fuzzy Logic, eds., R. Belohlavek and G. J. Klir, The MIT Press, ", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2011}, {"title": "Prototype theory and compositionality", "author": ["H. Kamp", "B. Partee"], "venue": "Cognition, 57(2), 129\u2013191, ", "citeRegEx": "5", "shortCiteRegEx": null, "year": 1995}, {"title": "Hedges: A study in meaning criteria and the logic of fuzzy concepts", "author": ["G. Lakoff"], "venue": "Journal of philosophical logic, 2(4), 458\u2013508, ", "citeRegEx": "6", "shortCiteRegEx": null, "year": 1973}, {"title": "A framework for linguistic modelling", "author": ["J. Lawry"], "venue": "Artificial Intelligence, 155(1-2), 1\u201339, ", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2004}, {"title": "Uncertainty modelling for vague concepts: A prototype theory approach", "author": ["J. Lawry", "Y. Tang"], "venue": "Artificial Intelligence, 173(18), 1539\u2013 1558, ", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2009}, {"title": "The utility of hedged assertions in the emergence of shared categorical labels", "author": ["Martha Lewis", "Jonathan Lawry"], "venue": "Proceedings of the AISB Convention", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2013}, {"title": "On the adequacy of prototype theory as a theory of concepts", "author": ["D.N. Osherson", "E.E. Smith"], "venue": "Cognition, 9(1), 35\u201358, ", "citeRegEx": "11", "shortCiteRegEx": null, "year": 1981}, {"title": "Cognitive representations of semantic categories.", "author": ["E. Rosch"], "venue": "Journal of Experimental Psychology: General,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 1975}, {"title": "Conceptual combination with prototype concepts", "author": ["E.E. Smith", "D.N. Osherson"], "venue": "Cognitive Science, 8(4), 337\u2013361, ", "citeRegEx": "13", "shortCiteRegEx": null, "year": 1984}, {"title": "Coordinating perceptually grounded categories through language: A case study for colour", "author": ["Luc Steels", "Tony Belpaeme"], "venue": "Behavioral and brain sciences,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2005}, {"title": "Fuzzy sets", "author": ["L.A. Zadeh"], "venue": "Information and Control, 8(3), 338\u2013353, ", "citeRegEx": "15", "shortCiteRegEx": null, "year": 1965}, {"title": "A fuzzy-set-theoretic interpretation of linguistic hedges", "author": ["L.A. Zadeh"], "venue": "Journal of Cybernetics, ", "citeRegEx": "16", "shortCiteRegEx": null, "year": 1972}], "referenceMentions": [{"referenceID": 9, "context": "fuzzy set theory, have been shown to be inadequate [11].", "startOffset": 51, "endOffset": 55}, {"referenceID": 2, "context": "Concepts formed through the combination of properties frequently have \u2018emergent attributes\u2019 [3] which cannot be explicated by decomposing the label into its constituent parts.", "startOffset": 92, "endOffset": 95}, {"referenceID": 7, "context": "We have developed a model of concept combination within the label semantics framework as given in [8, 10].", "startOffset": 98, "endOffset": 105}, {"referenceID": 2, "context": "The model is inspired by and reflects results in [3], in which membership in a compound concept can be rendered as the weighted sum of memberships in individual concepts, however, it can also account for emergent attributes, where e.", "startOffset": 49, "endOffset": 52}, {"referenceID": 1, "context": "This provides a theoretical grounding to the proposal seen in the literature [2, 3, 6, 16] that complex concepts can be characterised as weighted sums of attributes.", "startOffset": 77, "endOffset": 90}, {"referenceID": 2, "context": "This provides a theoretical grounding to the proposal seen in the literature [2, 3, 6, 16] that complex concepts can be characterised as weighted sums of attributes.", "startOffset": 77, "endOffset": 90}, {"referenceID": 5, "context": "This provides a theoretical grounding to the proposal seen in the literature [2, 3, 6, 16] that complex concepts can be characterised as weighted sums of attributes.", "startOffset": 77, "endOffset": 90}, {"referenceID": 14, "context": "This provides a theoretical grounding to the proposal seen in the literature [2, 3, 6, 16] that complex concepts can be characterised as weighted sums of attributes.", "startOffset": 77, "endOffset": 90}, {"referenceID": 6, "context": "We model concepts within the label semantics framework [7, 8], combined with prototype theory [12] and the conceptual spaces model of concepts [2].", "startOffset": 55, "endOffset": 61}, {"referenceID": 7, "context": "We model concepts within the label semantics framework [7, 8], combined with prototype theory [12] and the conceptual spaces model of concepts [2].", "startOffset": 55, "endOffset": 61}, {"referenceID": 10, "context": "We model concepts within the label semantics framework [7, 8], combined with prototype theory [12] and the conceptual spaces model of concepts [2].", "startOffset": 94, "endOffset": 98}, {"referenceID": 1, "context": "We model concepts within the label semantics framework [7, 8], combined with prototype theory [12] and the conceptual spaces model of concepts [2].", "startOffset": 143, "endOffset": 146}, {"referenceID": 10, "context": "This approach is based on experimental results where human subjects were found to view membership in a concept as a matter of degree, with some objects having higher membership than others [12].", "startOffset": 189, "endOffset": 193}, {"referenceID": 13, "context": "Fuzzy set theory [15], in which an object x has a graded membership \u03bcL(x) in a concept L, was proposed as a formalism for prototype theory.", "startOffset": 17, "endOffset": 21}, {"referenceID": 3, "context": "However, numerous objections to its suitability have been made [4, 3, 5, 11, 13].", "startOffset": 63, "endOffset": 80}, {"referenceID": 2, "context": "However, numerous objections to its suitability have been made [4, 3, 5, 11, 13].", "startOffset": 63, "endOffset": 80}, {"referenceID": 4, "context": "However, numerous objections to its suitability have been made [4, 3, 5, 11, 13].", "startOffset": 63, "endOffset": 80}, {"referenceID": 9, "context": "However, numerous objections to its suitability have been made [4, 3, 5, 11, 13].", "startOffset": 63, "endOffset": 80}, {"referenceID": 11, "context": "However, numerous objections to its suitability have been made [4, 3, 5, 11, 13].", "startOffset": 63, "endOffset": 80}, {"referenceID": 2, "context": "3 A HIERARCHICAL MODEL OF CONCEPT COMPOSITION Experiments in the psychological literature propose that human concept combination can in many cases be modelled as a weighted sum of attributes such as \u2018has feathers\u2019, \u2018has a beak\u2019 (for the concept \u2018Bird\u2019) [3].", "startOffset": 253, "endOffset": 256}, {"referenceID": 2, "context": "These results show that under the constraint \u03b5 \u223c U(0, \u03bbT ), combining labels in a weighted binary conceptual space leads naturally to the creation of compound concepts as weighted sums of individual labels, reflecting results in [3].", "startOffset": 229, "endOffset": 232}, {"referenceID": 2, "context": "A specific example seen in [3] is that the attribute\u2018talks\u2019 becomes more important in the conjunction \u2018Birds that are Pets\u2019 than in either \u2018Birds\u2019 or \u2018Pets\u2019.", "startOffset": 27, "endOffset": 30}, {"referenceID": 12, "context": "We implement a simple version of the hierarchical model of concept combination in a multi-agent simulation of agents playing a series of language games, similar to those used in [14].", "startOffset": 178, "endOffset": 182}, {"referenceID": 0, "context": "1 Assertion algorithm Agents are equipped with shared labels L1 \u2208 \u03a91 = [0, 1] and L2 \u2208 \u03a92 = [0, 1], and a weight \u03bb.", "startOffset": 71, "endOffset": 77}, {"referenceID": 0, "context": "1 Assertion algorithm Agents are equipped with shared labels L1 \u2208 \u03a91 = [0, 1] and L2 \u2208 \u03a92 = [0, 1], and a weight \u03bb.", "startOffset": 92, "endOffset": 98}, {"referenceID": 0, "context": "Each pair of agents is shown an element x \u2208 \u03a91 \u00d7 \u03a92 = [0, 1].", "startOffset": 54, "endOffset": 60}, {"referenceID": 0, "context": "The first implements the idea that the listener agent updates its concepts when the agent\u2019s belief in the appropriateness of a compound label, \u03bc\u03b1i(x), is less than the reliability of the speaker as measured by a weightw \u2208 [0, 1].", "startOffset": 222, "endOffset": 228}, {"referenceID": 0, "context": "3 Simulation Details Agents have labelsL1 = L2 =<1, d, U [0, 1]>, where d is Euclidean distance, to describe the conceptual space \u03a9 = \u03a91\u00d7\u03a92 = [0, 1].", "startOffset": 57, "endOffset": 63}, {"referenceID": 0, "context": "3 Simulation Details Agents have labelsL1 = L2 =<1, d, U [0, 1]>, where d is Euclidean distance, to describe the conceptual space \u03a9 = \u03a91\u00d7\u03a92 = [0, 1].", "startOffset": 142, "endOffset": 148}, {"referenceID": 0, "context": "When w = 1 for all agents, and x1 \u223c U [0, 1], x2 \u223c U [0, 0.", "startOffset": 38, "endOffset": 44}, {"referenceID": 0, "context": "5], so that elements are encountered within half of the total space \u03a9 = [0, 1], the agents converge to a value of \u03bb = 0.", "startOffset": 72, "endOffset": 78}, {"referenceID": 0, "context": "(a) x1 \u223c U [0, 1], x2 \u223c U [0, 0.", "startOffset": 11, "endOffset": 17}, {"referenceID": 0, "context": "For x1 \u223c U [0, 1], x2 \u223c U [0, 0.", "startOffset": 11, "endOffset": 17}, {"referenceID": 0, "context": "2, agents have labels L1 = L2 =< 1, U [0, 1] > to describe the conceptual space \u03a9 = [0, 1].", "startOffset": 38, "endOffset": 44}, {"referenceID": 0, "context": "2, agents have labels L1 = L2 =< 1, U [0, 1] > to describe the conceptual space \u03a9 = [0, 1].", "startOffset": 84, "endOffset": 90}, {"referenceID": 1, "context": "Characterising concepts as a weighted sum of attributes is seen throughout the literature [2, 3, 6, 16].", "startOffset": 90, "endOffset": 103}, {"referenceID": 2, "context": "Characterising concepts as a weighted sum of attributes is seen throughout the literature [2, 3, 6, 16].", "startOffset": 90, "endOffset": 103}, {"referenceID": 5, "context": "Characterising concepts as a weighted sum of attributes is seen throughout the literature [2, 3, 6, 16].", "startOffset": 90, "endOffset": 103}, {"referenceID": 14, "context": "Characterising concepts as a weighted sum of attributes is seen throughout the literature [2, 3, 6, 16].", "startOffset": 90, "endOffset": 103}, {"referenceID": 0, "context": "In previous work [1, 9], the agents in the simulations have had varying reliability w, which could be incorporated into these simulations.", "startOffset": 17, "endOffset": 23}, {"referenceID": 8, "context": "In previous work [1, 9], the agents in the simulations have had varying reliability w, which could be incorporated into these simulations.", "startOffset": 17, "endOffset": 23}], "year": 2016, "abstractText": "We investigate the generation of new concepts from combinations of properties as an artificial language develops. To do so, we have developed a new framework for conjunctive concept combination. This framework gives a semantic grounding to the weighted sum approach to concept combination seen in the literature. We implement the framework in a multi-agent simulation of language evolution and show that shared combination weights emerge. The expected value and the variance of these weights across agents may be predicted from the distribution of elements in the conceptual space, as determined by the underlying environment, together with the rate at which agents adopt others\u2019 concepts. When this rate is smaller, the agents are able to converge to weights with lower variance. However, the time taken to converge to a steady state distribution of weights is longer.", "creator": "LaTeX with hyperref package"}}}