{"id": "1602.01428", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "3-Feb-2016", "title": "\"Draw My Topics\": Find Desired Topics fast from large scale of Corpus", "abstract": "We develop the \"Draw My Topics\" toolkit, which provides a fast way to incorporate social scientists' interest into standard topic modelling. Instead of using raw corpus with primitive processing as input, an algorithm based on Vector Space Model and Conditional Entropy are used to connect social scientists' willingness and unsupervised topic models' output. Space for users' adjustment on specific corpus of their interest is also accommodated by the model-level model-level model, which allows users to choose the number of subjects to explore in a range of settings. The toolkit can be downloaded here.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "histories": [["v1", "Wed, 3 Feb 2016 19:44:37 GMT  (550kb)", "http://arxiv.org/abs/1602.01428v1", null]], "reviews": [], "SUBJECTS": "cs.CL cs.IR", "authors": ["jason dou", "ni sun", "xiaojun zou"], "accepted": false, "id": "1602.01428"}, "pdf": {"name": "1602.01428.pdf", "metadata": {"source": "CRF", "title": "\u201cDraw My-Topics\u201d Toolkit: Draw Desired Topics Fast from Large Volume of Corpus", "authors": ["Jason Xiaotian Dou", "Ni Sun", "Xiaojun Zou"], "emails": [], "sections": [{"heading": null, "text": "We develop the \u201cDraw My-Topics\u201d Toolkit, which provides a fast way to incorporate social scientists\u2019 concerns and interests into the standard topic model. Instead of using raw corpus with primitive processing as input, an algorithm based on Vector Space Model and Conditional Entropy are used to connect social scientists\u2019 subjective want and the unsupervised topic models\u2019 output. Space for users\u2019 adjustment on specific corpus of their interest is accommodated in our algorithm. We demonstrate the toolkit\u2019s use on the Diachronic People\u2019s Daily Corpus in Chinese. Several interesting \u201ccentral words\u201d like \u201cEnlai Zhou\u201d (First PRC premier minister) and \u201cCultural Revolution\u201d which may be interested of social scientists from different disciplines and the original corpus are used as input of our toolkit, then the most related topics are present efficiently for further research purpose."}, {"heading": "1 Introduction", "text": "Probabilistic topic models, such as Probabilistic Latent Semantic Analysis (PLSA) and Latent Dirichlet Allocation (Blei, Ng and Jordan, 2003), are widely used as common tools to assist social scientists\u2019 understanding large, unstructured collections of documents. The value of topic models is being recognized by social scientists as a tool for large document-summary and abstraction for economically and politically interesting facts such as Chinese Censorship (Grimmer and Stewart, 2013; King, Robert and Pan, 2013; Tingley, 2013; Bamman, Connor and Smith, 2012).\nSocial scientists often start with off-the-shelf implementations of topic modeling which are widely available on the Internet. Then a variety of post-hoc evaluation of the implementation\u2019s output, including topic prevalence and\ntopic variation can be conducted. However, due to topic models are mainly unsupervised method. In this case, social scientists often have little to do with the topic generation process. So many unrelated topics may show up, but they are not of the social scientists\u2019 interest. There are already considerable terrific works on better connecting social scientists with topic modeling. Kim, Zhai and Diermeier (2013) connected topic modeling with time-series feedback, Roberts, Stewart, Tingley and Airoldi (2013) developed \u201cStructural Topic Model\u201d to incorporate corpus observed metadata into standard topic model. Hall, Wallach, Mimno and McCallum (2009) accommodated outside information by optimize the hyper parameters of LDA. Hall, Jurafsky and Manning (2008) hand selected seed-word by adding number of pseudo-counts to the topic related words that they are especially interested in. We develop the \u201cDraw Related-Topics\u201d toolkit to help social scientists and other topic model users to get desired topics in a more direct way. The central idea is that users define their interesting topics by a \u201ccentral word\u201d, and then we extract this word (topic)\u2019s relatively small context rather than the huge volume of raw corpus as topic model\u2019s input. Based on \u201cSpatial Locality Principle\u201d, this allows us to draw central word\u2019s related topic prevalence and related topics much easier than searching for the whole corpus purposely. To define and find the \u201crelated context\u201d, we propose a two \u2013step approach. First, to find the \u201ccentral word\u2019s top twenty similar words by Vector Space Model (Salton, Wong and Yang, 1975) and Conditional Entropy (Cover, Thomas M, 1991). These form the similar word set. Second, extract adjacent context of the similar word set to form the whole related context. Furthermore, users can adjust the two approaches by their subjective judgment (in\nother words, social science sense/knowledge) according to their own corpus\u2019 part-of speech-tagging statistics to get more desirable results. After describing the method, we demonstrate the use of \u201cDraw RelatedTopics\u201d toolkit by analyzing several interesting words on the diachronic \u201cPeople\u2019s Daily\u201d corpus in Chinese."}, {"heading": "2 The Two-Step Approach", "text": "The input of our \u201cDraw My-Topics\u201d Toolkit is interesting words defined by users (target at social scientists mainly) and large volume of corpus. The output is \u201ccentral word\u201d related topics content and topic prevalence. Also, users can adjust the output by their domain knowledge and intuitions by flexible parameters we provide.\n2.1\nIn the first step, we calculate top three hundred similar words of each given \u201cCentral Word\u201d by vector space model and conditional entropy. Vector space model is an algebraic model for representing text documents as vectors of identifiers. In our case, each word is treated as a vector in the space. The similarity degree of different words is calculated by the cosine of the angle between different vectors of words. The entry of word vector is point-to-point mutual information. Then to calculate mutual information, decision on length of information window gets crucial and subtle. We do this based on \u201camount of information\u201d of each window, which is calculated as conditional entropy. !!!!!!!!!!\nInformation! = !\u2212!log(Pr(X, Y)!/!Pr(Y)) In it Y denotes the target word and X denotes words in nearby context. For four part-of-speech tagging types, we set four different information thresholds as the following based on sampling, observation, and statistics:\nThis information threshold table for similarity degree calculation can also be determined by toolkit users themselves since \u201csimilar\u201d is quite a subjective measure from different disciplines\u2019 perspective. For example, \u201cdemand\u201d may be\n\u201csimilar\u201d to \u201csupply\u201d from an economist\u2019s view while political scientist may think \u201cdemand\u201d is related to \u201cpower\u201d. Some of the similarity calculation results based on Chinese diachronic corpus of \u201cPeople\u2019s Daily\u201d are presented below.\nIn the second step, we apply a straightforward method to summarize related corpus from the original one based on similarity words result from first step. We go through the People\u2019s Daily Corpus year by year. For every line of one year, draw it down if the line contains any of the similar words of given target word. All these lines constitute our related corpus. In our \u201cPeople\u2019s Daily Corpus\u201d, every line is a separate news piece, so this method take the completeness of news well. Drawback of this kind of summary is obvious: we reduce corpus size as input of topic model at the risk of neglect precious information related to our target word in the abandoned corpus. Figure 1 shows part of related corpus we draw for central word \u201cEnlai Zhou\u201d( /n), who is PRC\u2019s first premier minister.\n/n /t /n /t /n /m /q /f /n /g /n /n /n /n /v /m /q /v /g /g /m /u /b /n /d /v /u /a /u /n /v /s /v /v /n /v /n /s /t /v /s /u /n /d /v /n /s /d /v /v /n /u /v /m /u /n /n /v /v /v /w /p /n /v /v /v /a /u /n /n /m /n /d /v /v /n /m /q /v /m /q /w /v /v /v /n /v /n /n /v /u /n /c /n /d /v /w /d /d /v /v /d /v /n /s /v /n /v /m /n /n /a /u /n /n /w /n /w /n /p /n /v /n /n /v\n/n /n /n /v /m /q /v /n /v /r"}, {"heading": "3 Experimental Results and Online Visualization", "text": "In this part, we first demonstrate how the \u201cDraw My-Topics\u201d Toolkit can effectively condense corpus size, then we show the topics draw from the condensed corpus, finally, we show our online visualization platform. Online service and downloadable package will all be provided soon. In the following table, four interesting words (\n, Enlai Zhou; , Peking University; economy; , Chinese God) and the whole year 1957\u2019s corpus of People\u2019s Daily are used as input of our toolkit, we can see that size of related corpus decrease significantly in the four cases.\nBut our goal is topic prevalence and topic content; will the condensed corpus work well? Here are the results in Table 4. Stop words are removed from the corpus to distinguish the four topics.\nFor the convenience of users to use our toolkit and other \u201cproducts\u201d, we are also building an online visualization platform based on the diachronic corpus of \u201cPeople\u2019s Daily\u201d. Functions include plot of fifty-year word frequency distribution as showed in Figure 2 and ten years\u2019 similarity degree variation of given word as showed\nin Figure 3. A dynamic visualization of our toolkit\u2019s application will be implemented on the platform soon."}, {"heading": "4 Conclusion and Future Work", "text": "We have developed the \u201cDraw My-Topics\u201d Toolkit for social scientists to incorporate their concerns and interests when using standard topic model. The main method is to use word similarity calculation based on Vector Space Model and Conditional Entropy to \u201ccondense\u201d original corpus. The condensed size is also helpful when facing large scale of corpora, where Topic Model training time can be a bottleneck. Space for social scientists to incorporate their own judgments is also provided. An online visualization platform and downloadable package will be released soon. We are improving this work from two aspects, calculation and evaluation. In the calculation part, we hope to incorporate the diachronic ontology we build on \u201cPeople\u2019s Daily\u201d (Shaoda He, et al. 2013) to improve quality of condensed corpus. Evaluation of topic modeling is quite an open question. Chang, Boyd-Graber, Gerrish, Wang and Blei (2013) use human judgments including user studies to examine the topics. In our case, we hope to use the user feedback of our toolkit to design new feasible methods."}, {"heading": "Acknowledgements", "text": "Thanks to Noah Smith, Gary King, Brandon Stewart, Shuo Chen, Xun Pang, David Hall and Sebastian Benthall for enlightening suggestions, comments and guide; and also to my Undergraduate Research advisor, Professor Junfeng Hu. It is his guide, dedication and encouragement that make me fall in love with research and finish my first paper as this. \u201cNational Innovation Plan for Undergraduate\u201d, Ministry of Education of China supports this work."}], "references": [{"title": "The structural topic", "author": ["Roberts", "Margaret"], "venue": null, "citeRegEx": "Roberts and Margaret,? \\Q2013\\E", "shortCiteRegEx": "Roberts and Margaret", "year": 2013}, {"title": "Construction of Diachronic Ontologies from People\u2019s Daily of Fifty Years", "author": ["Shaoda He", "Xiaojun Zou", "Liumingjing Xiao", "Junfeng Hu."], "venue": "LREC", "citeRegEx": "He et al\\.,? 2014", "shortCiteRegEx": "He et al\\.", "year": 2014}, {"title": "Rethinking LDA: Why Priors Matter", "author": ["Wallach", "Hanna M", "David M. Mimno", "Andrew McCallum"], "venue": "NIPS. Vol", "citeRegEx": "Wallach et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Wallach et al\\.", "year": 2009}, {"title": "Diachronic Corpus Based Word Semantic Variation and Change Mining", "author": ["X. Zou", "N. Sun", "H. Zhang", "J. Hu"], "venue": "Language Processing and Intelligent Information Systems, pages 145-150.", "citeRegEx": "Zou et al\\.,? 2013", "shortCiteRegEx": "Zou et al\\.", "year": 2013}], "referenceMentions": [], "year": 2014, "abstractText": "We develop the \u201cDraw My-Topics\u201d Toolkit, which provides a fast way to incorporate social scientists\u2019 concerns and interests into the standard topic model. Instead of using raw corpus with primitive processing as input, an algorithm based on Vector Space Model and Conditional Entropy are used to connect social scientists\u2019 subjective want and the unsupervised topic models\u2019 output. Space for users\u2019 adjustment on specific corpus of their interest is accommodated in our algorithm. We demonstrate the toolkit\u2019s use on the Diachronic People\u2019s Daily Corpus in Chinese. Several interesting \u201ccentral words\u201d like \u201cEnlai Zhou\u201d (First PRC premier minister) and \u201cCultural Revolution\u201d which may be interested of social scientists from different disciplines and the original corpus are used as input of our toolkit, then the most related topics are present efficiently for further research purpose.", "creator": "Word"}}}