{"id": "1602.01718", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "4-Feb-2016", "title": "Formal Verification of Autonomous Vehicle Platooning", "abstract": "The coordination of multiple autonomous vehicles into convoys or platoons is expected on our highways in the near future. However, before such platoons can be deployed, the new autonomous behaviors of the vehicles in these platoons must be certified. An appropriate representation for vehicle platooning is as a multi-agent system in which each agent captures the \"autonomous decisions\" carried out by each vehicle.\n\n\n\nThe next step in these two tasks is to enable the public to access information on the vehicles, without any additional constraints.\nThe vehicle platooning, along with all the other \"autonomous decisions\" carried out by the vehicles, will also provide the potential to facilitate the coordination of the actions of these vehicles.\nIn an effort to achieve this objective, the vehicles will be placed under autonomous control.\nThe next step will be the introduction of the autonomous vehicles in public transportation.\nThe goal is to provide the public with a better understanding of the different types of vehicles that can be used in and around the country.", "histories": [["v1", "Thu, 4 Feb 2016 15:50:22 GMT  (923kb,D)", "http://arxiv.org/abs/1602.01718v1", null]], "reviews": [], "SUBJECTS": "cs.AI cs.SE", "authors": ["maryam kamali", "louise a dennis", "owen mcaree", "michael fisher", "sandor m veres"], "accepted": false, "id": "1602.01718"}, "pdf": {"name": "1602.01718.pdf", "metadata": {"source": "CRF", "title": "Formal Verification of Autonomous Vehicle Platooning", "authors": ["Maryam Kamali", "Louise A. Dennis", "Owen McAree", "Michael Fisher", "Sandor M. Veres"], "emails": [], "sections": [{"heading": null, "text": "expected on our highways in the near future. However, before such platoons can be deployed, the new autonomous behaviours of the vehicles in these platoons must be certified. An appropriate representation for vehicle platooning is as a multiagent system in which each agent captures the \u201cautonomous decisions\u201d carried out by each vehicle. In order to ensure that these autonomous decision-making agents in vehicle platoons never violate safety requirements, we use formal verification. However, as the formal verification technique used to verify the agent code does not scale to the full system and as the global verification technique does not capture the essential verification of autonomous behaviour, we use a combination of the two approaches. This mixed strategy allows us to verify safety requirements not only of a model of the system, but of the actual agent code used to program the autonomous vehicles."}, {"heading": "1 Introduction", "text": "While \u201cdriverless cars\u201d regularly appear in the media, they are neither \u201cdriverless\u201d nor fully autonomous. Legal constraints ensure that there must always be a responsible human in the vehicle. However, although fully autonomous road vehicles remain futuristic, the automotive industry is working on what are variously called \u201croad trains\u201d, \u201ccar convoys\u201d or \u201cvehicle platoons\u201d. Here, each vehicle autonomously follows the one in front of it on the road, with the front vehicle in the platoon/convoy/train being driven manually. This technology is being introduced by the automotive industry in order to improve both the safety and efficiency of vehicles on very congested roads [18]. It is especially useful if the vehicles are trucks/lorries and if the road is a multi-lane highway.\nIn these platoons, each vehicle clearly needs to communicate with others, at least with the one immediately in front and the one immediately behind. Vehicle-to-vehicle\nar X\niv :1\n60 2.\n01 71\n8v 1\n[ cs\n.A I]\n(V2V) communication is used at a lower (continuous control system) level to adjust each vehicle\u2019s position in the lanes and the spacing between the vehicles. V2V is also used at higher levels, for example to communicate joining requests, leaving requests, or commands dissolving the platoon. So a traditional approach is to implement the software for each vehicle in terms of hybrid (and hierarchical) control systems and to analyse this using hybrid systems techniques.\nHowever, as the behaviours and requirements of these automotive platoons become more complex there is a move towards much greater autonomy within each vehicle. Although the human in the vehicle is still responsible, the autonomous control deals with much of the complex negotiation to allow other vehicles to leave and join, etc. Traditional approaches involve hybrid automata [12] in which the continuous aspects are encapsulated within discrete states, while discrete behaviours are expressed as transitions between these states. A drawback of combining discrete decision-making and continuous control within a hybrid automaton is that it is difficult to separate the two (high-level decision-making and continuous control) concerns. In addition, the representation of the high-level decision-making can become unnecessarily complex.\nAs is increasingly common within autonomous systems, we use a hybrid autonomous systems architecture where not only is the discrete decision-making component separated from the continuous control system, but the behaviour of the discrete part is described in much more detail. In particular, the agent paradigm is used [26]. This style of architecture, using the agent paradigm, not only improves the system design from an engineering perspective but also facilitates the system analysis and verification. Indeed, we use this architecture for actually implementing automotive platoons, and we here aim to analyse the system by verification.\nSafety certification is an inevitable concern in the development of more autonomous road vehicles, and verifying the safety and reliability of automotive platooning is currently one of the main challenges faced by the automotive industry. The verification of such systems is challenging due to their complex and hybrid nature. Separating discrete and continuous concerns, as above, potentially allows us to reason about the decision-making components in isolation and ensure that no decision-making component ever deliberately chooses an unsafe state. However, the use of the \u2018agent\u2019 concept alone is not enough for our purposes, since this can still make its autonomous decisions in an \u2018opaque\u2019 way. In order to be able to reason about, and formally verify, the choices the system makes, we need a rational agent [27]. This not only makes decisions, but has explicit representations of the reasons for making them, allowing us to describe not only what the autonomous system chooses to do, but why it makes particular choices [10].\nThe Belief-Desire-Intention (BDI) model is one of the most widely used conceptual models not only for describing rational agents but for actually implementing them [20]. A BDI-style agent is characterised by its beliefs, desires and intentions: beliefs represent the agent\u2019s views about the world; desires represent the objectives to be accomplished; while intentions are the set of tasks currently undertaken by the agent to achieve its desires. A BDI-style agent has a set of plans, determining how an agent acts based on its beliefs and goals, and an event queue where events (perceptions from the environment and internal subgoals) are stored. In this paper, we use the GWENDOLEN programming language [4], developed for verifiable BDI-style programming,\nto implement agent-based decision-making for an automotive platoon. This captures the high-level, autonomous decision-making within each vehicle.\nAs part of safety certification, we need to verify the agent decisions, especially in combination with the other vehicles. An autonomous rational agent makes decisions about what actions to perform, etc, based on the beliefs, goals and intentions that the agent holds at that time. We use a model-checking approach to demonstrate that the rational agent always behaves in line with the platoon requirements and never deliberately chooses options that end up in unsafe states. We verify properties of the rational agent code using the AJPF model-checker [7], one of the very few model-checkers able to cope with complex properties of BDI agents. Unfortunately, there are two drawbacks to using AJPF: currently, AJPF does not support verification of timed behaviours; and AJPF is resource heavy and cannot be used to verify the whole system. Consequently, in this paper, we use a combined methodology for the verification of automotive platooning. To evaluate timing behaviour, we use a timed-automata abstraction and verify the system using the Uppaal model-checker; to evaluate autonomous decisions, we apply AJPF to the individual agents together with an abstraction of the other vehicles/agents. Furthermore, we describe how these two approaches to modeling, i.e. BDI models and timed-automata, can be combined to provide an appropriate basis for verifying the behaviour of both individual agents and the whole system.\nThe remainder of the paper is organised as follows. In Section 2 the automotive platoon and platoon requirements are presented. In Section 3 the hybrid agent architecture and the agent-based decision-making for automotive platoon are described. In Section 4 the analysis and verification of an automotive platoon is considered. Finally, in Section 5, concluding remarks are provided and future work is discussed."}, {"heading": "2 Automotive Platoons", "text": "An automotive platoon, enabling road vehicles to travel as a group, is led by a vehicle which is driven by a professional driver [21, 22, 25]. The following vehicles, i.e, members of the platoon, are controlled autonomously. These vehicles, equipped with low-level longitudinal (controlling speed) and lateral (controlling steering) control systems, travel in a platoon with pre-defined gaps between them. In addition, V2V communication also connects the vehicles at an agent level. The lead vehicle, via its agent, effectively carries out coordination over the platoon: setting parameters, creating certificates of joining and leaving, etc. Each individual vehicle observes its environment and follows incoming commands from the lead agent. In what follows, we outline the set of high-level automotive platoon concepts and procedures including how to join and leave a platoon [2]. In addition, the initial requirements on these procedures for the development of safe and reliable platooning are explained. From these we derive the formal properties to be verified."}, {"heading": "2.1 Joining the Platoon", "text": "A vehicle can join a platoon either at the end or in the middle with different control strategies being used. The joining procedure is as follows:\n\u2022 a non-member vehicle sends a joining request to the platoon leader, expressing the intended position in the platoon;\n\u2022 if the vehicle has requested to join from the rear, the leader sends back an agreement provided the maximum platoon length has not been reached and the platoon is currently in normal operation;\n\u2022 if the vehicle requests to join in front of (for example) vehicle X and the maximum platoon length has not been reached, the leader sends an \u201cincrease space\u201d command to vehicle X, and when the leader is informed that enough spacing has been created (approx. 17 metres), it sends back an agreement to the joining vehicle;\n\u2022 upon receipt of an agreement, the joining vehicle changes its lane (changing lane is a manual procedure which is performed by a driver);\n\u2022 once the vehicle is in the correct lane, its automatic speed controller is enabled and it approaches the preceding vehicle;\n\u2022 when the vehicle is close enough to the preceding vehicle (less than 20 metres), its automatic steering controller is enabled and it sends an acknowledgement to the leader; and, finally\n\u2022 the leader sends a \u201cdecrease space\u201d command to vehicle X, and when the leader is informed that spacing has been back to normal (approximately 5 metres), it replies to the acknowledgement.\nIn order to ensure a safe joining operation, the following requirements should be preserved within the agent-based decision-making components of automotive platoon.\n1. A vehicle must only initiate joining a platoon, i.e., changing lane, once it has received confirmation from the leader.\n2. Before autonomous control is enabled, a joining vehicle must approach the preceding vehicle, in the correct lane.\n3. Automatic steering controller must only be enabled once the joining vehicle is sufficiently close to the preceding vehicle."}, {"heading": "2.2 Leaving the Platoon", "text": "A vehicle can request to leave platoon at any time. The leaving procedure is:\n\u2022 a platoon member sends a leaving request to the leader and waits for authorisation;\n\u2022 upon receipt of \u2018leave\u2019 authorisation, the vehicle increases its space from the preceding vehicle;\n\u2022 when maximum spacing has been achieved, the vehicle switches both its speed and steering controller to \u2018manual\u2019 and changes its lane; and, finally\n\u2022 the vehicle sends an acknowledgement to the leader.\nThe two following requirements are necessary in order to meet with the agent-based decision-making components of automotive platoon.\n1. Except in emergency cases, a vehicle must not leave the platoon without authorisation from the leader.\n2. When authorised to leave, autonomous control should not be disabled until the maximum allowable platoon spacing has been achieved."}, {"heading": "3 Agent-based Development of Automotive Platoon", "text": "We employ a hybrid agent architecture based on [5] for each vehicle:\nAutomotive Simulation Environment\nPhysical Engine\n[ MATLAB/ Simulink ]\nAbstraction Agent\nDecision Making Agent\n[ TORCS ] [ MATLAB/Simulink ] [ Gwendolen ] [ Gwendolen ]\nReal-time continuous control of the vehicle is managed by feedback controllers, implemented in MATLAB, and observing the environment through its sensory input. This is called the Physical Engine. The Physical Engine, in turn, communicates with an Abstraction Agent that extracts discrete information from streams of continuous data and passes this on a Decision-Making Agent. The Decision-Making Agent is a rational agent which directs the Physical Engine by passing it instructions through the Abstraction Agent. Instructions from the Decision-Making Agent to the Abstraction Agent are interpreted into meaningful instructions for Physical Engine.\nTo provide the complex environment necessary for effective simulation and testing, we use an automotive simulator, TORCS [23], to implement the environment component of the architecture. The Physical Engine is implemented in MATLAB, while both Abstraction and Decision-Making Agents are programmed in the GWENDOLEN programming language. An interface between TORCS and MATLAB/Simulink has been developed that provides a means to control vehicles from MATLAB and Simulink.\nListing 1 shows some of the GWENDOLEN code from the Decision-Making Agent for the joining procedure for follower vehicle. The GWENDOLEN syntax that is needed for this example is summarised in Fig. 1. Essentially, GWENDOLEN is an extension of Prolog-style declarative programming, incorporating explicit representations of goals, beliefs, and plans. For example, the first plan in Listing 1 (Line 7-12) denotes that once the follower agent sets a goal to join the platoon, it sends a request to the leader and waits for an agreement belief to become true. The changing lane plan in Listing 1 (Line 14-19) can be executed if and only if the follower agent has the agreement belief. In each iteration, the follower agent then selects plan based on its goals and beliefs.\nA GWENDOLEN agent can also perform deductive reasoning on its beliefs, expressed through its reasoning rules. In the \u2018joining\u2019 scenario, the follower agent deduces that its goal to join the platoon has been achieved if it believes all the prescribed joining steps have been performed. This is represented by the platoon-ok belief.\nEssentially, the decision-making agent\u2019s activity proceeds in sequence: the follower has a goal to successfully join the platoon; it initiates changing lane, if it believes it has received an agreement from the leader; and the follower achieves the joining goal if it believes it is in right lane and the automatic speed and steering controller are enabled. Changing lane is performed manually by a driver and as long as the speed and steering controllers are not switched to automatic, driver needs to control speed and steering.\n1 2Reason ing Rules 3j o i n i n g (X, Y):\u2212 name (X) , p l a t o o n\u2212ok 4 5P l a n s 6+! j o i n i n g (X, Y) [ a c h i e v e ] : {B name (X) , ~B j o i n _ a g r e e m e n t (X, Y) } 7<\u2212 +! s p e e d _ c o n t r ( 0 ) [ pe r fo rm ] , +! s t e e r i n g _ c o n t r ( 0 ) [ pe r fo rm ] , 8. send ( l e a d e r , : t e l l , j o i n _ r e q (X, Y) ) , \u2217 j o i n _ a g r e e m e n t (X, Y ) ; 9 10+! j o i n i n g (X, Y) [ a c h i e v e ] : {B name (X) , B j o i n _ a g r e e m e n t (X, Y) , 11~B changed_ lane , ~G s e t _ s p a c i n g ( Z ) [ a c h i e v e ] } 12<\u2212 +! s p e e d _ c o n t r ( 0 ) [ pe r fo rm ] , +! s t e e r i n g _ c o n t r ( 0 ) [ pe r fo rm ] , 13p e r f ( c h a n g i n g _ l a n e ( 1 ) ) , \u2217 c h a n g e d _ l a n e ; 14 15+! j o i n i n g (X, Y) [ a c h i e v e ] : {B name (X) , B j o i n _ a g r e e m e n t (X, Y) , 16B changed_ lane , ~B s p e e d _ c o n t r , ~ B s t e e r i n g _ c o n t r , 17~B c l o s i n g _ e n o u g h , ~G s e t _ s p a c i n g ( Z ) [ a c h i e v e ] } 18<\u2212 +! s p e e d _ c o n t r ( 1 ) [ pe r fo rm ] , \u2217 j o i n i n g _ d i s t a n c e ; 19 20+! j o i n i n g (X, Y) [ a c h i e v e ] : {B name (X) , B j o i n _ a g r e e m e n t (X, Y) , 21B changed_ lane , B s p e e d _ c o n t r , ~B s t e e r i n g _ c o n t r , 22B c l o s i n g _ e n o u g h , ~G s e t _ s p a c i n g ( Z ) [ a c h i e v e ] } 23<\u2212 +! s t e e r i n g _ c o n t r ( 1 ) [ pe r fo rm ] ; 24 25+! j o i n i n g (X, Y) [ a c h i e v e ] : {B name (X) , B j o i n _ a g r e e m e n t (X, Y) , 26B changed_ lane , ~B speed_co n t , ~B s t e e r i n g _ c o n t r , 27B c l o s i n g _ e n o u g h , ~G s e t _ s p a c i n g ( Z ) [ a c h i e v e ] } 28<\u2212 +! s p e e d _ c o n t r ( 1 ) [ pe r fo rm ] , +! s t e e r i n g _ c o n t r ( 1 ) [ pe r fo rm ] ; 29 30+! j o i n i n g (X, Y) [ a c h i e v e ] : {B name (X) , B j o i n _ a g r e e m e n t (X, Y) , 31B changed_ lane , B s p e e d _ c o n t r , B s t e e r i n g _ c o n t r , 32B c l o s i n g _ e n o u g h , ~B platoon_m , ~G s e t _ s p a c i n g ( Z ) [ a c h i e v e ] } 33<\u2212 . send ( l e a d e r , : t e l l , message (X, j o i n e d _ s u c c ) ,\u2217 platoon_m , p l a t o o n\u2212ok ;\nListing 1: A Follower Vehicle\u2019s code\nJoining the platoon is described in GWENDOLEN as an \u2018achievement\u2019 goal, meaning that the agent continuously attempts the plans given in Listing 1 until it believes that platoon-ok is true. This belief, platoon-ok, denotes that not only is the vehicle in the right lane but that its automatic controllers are enabled. It also determines that the leader has received an acknowledgement from the vehicle, confirming it has successfully joined the platoon. Subsequently, the agent deduces from its reasoning rule (Line 2) that the joining goal has indeed been achieved."}, {"heading": "4 Verification", "text": ""}, {"heading": "4.1 Verification Methodology", "text": "We can visualise the overall system as:\nComms AgentComms AgentComms Agent\nThe agent is a GWENDOLEN program, the Comms component is a simple transfer protocol, and the vehicle represents the particular vehicular system that we interact with. This is typically an automotive control system together with environmental interactions, and we have validated this both in simulation (using the TORCS automotive simulation) and in physical vehicles (using Jaguar outdoor rover vehicles).\nLimits to Modelling/Verification. We are not going to formally verify the vehicular control systems, and leave this to standard mathematical (usually analytic) techniques from the Control Systems field. These control components, for example involving following a prescribed path, avoiding local obstacles, keeping distance from object, etc, are well-established and standard. Instead, we will verify the autonomous decisions the vehicles make, captured within each vehicle\u2019s \u2018agent\u2019 [10]. Each agent represents the autonomous decision-maker within each vehicle and corresponds, in part, to the human driver\u2019s decisions. These decisions involve deciding where to go, when to turn, when to stop, what to do in unexpected situations, etc. In the case of autonomous vehicle convoys/platoons, the agent\u2019s (and, hence, the vehicle\u2019s) decisions concern when to join the convoy, when to leave, what to do in an emergency, etc.\nSo, we begin by abstracting from all the vehicle control systems and environmental interactions, representing these by one (potentially complex, depending on the vehicle/environment interactions) automaton. We also use an automaton to describe the simple transfer protocol that the vehicles use for their communication. In both these cases we will use Timed Automata [1]. Simplified, our architecture is:\nCommunications Agent Program\nCommunications\nVehicle Control and Environment\nAgent Program\nCommunications\nVehicle Control and Environment\nwhich, at least in principle, leads to an overarching formal model:\nTimed Automaton AgentAutomaton\nTimed Automaton\nTimed Automaton\nAgent Automaton\nTimed Automaton\nTimed Automaton\nIn describing agent behaviour, the agent automaton comprises added (modal) dimensions of (at least) belief and intention. Thus, the formal structures that allow us to fully represent all the system above are quite complex, combining timed relations as well as relations for each of the belief and intention dimensions [1, 19]. We will not describe this formal model in detail but just note that it is a fusion [9, 11, 16] of timed and BDI structures, \u3008L,A,C, E , inv,RB , RI , l\u3009, where: L is a finite set of locations; A is a finite set of actions; C is a finite set of clocks; E \u2286 L \u00d7 \u03a8(C) \u00d7 A \u00d7 2C \u00d7 L is a set of (timed) edges between locations; inv : L \u2192 \u03a8(C) is a function associating each location with some clock constraint in \u03a8(C); RB : Ag \u2192 (L \u00d7 L), where Ag is the set of \u2018agents\u2019 and RB(a) provides the belief relation (corresponding to KD45 modal logic) for agent a between locations; RI : Ag \u2192 (L \u00d7 L), where RB(c) provides the intention relation (KD) for agent c between locations; and l : L \u2192 2AP is a labelling function essentially capturing those propositions true at each location (AP is a set of atomic propositions).\nThe logic then interpreted over such structures combines [11] the syntax of timed temporal logic, for example\u2666\u22645finish , and the syntax of modal logics of belief, desire and intention, for example Bxstarted (i.e. \u201cagent x believes that started is true\u201d).\nIn principle, though very complex, we could provide all our convoy requirements in such a logic, build structures of the above form for our convoy implementation, and then develop a model-checking approach for this combination [15]. However, there are several reasons we choose to abstract and separate the timed/agent strands, as follows. \u2022 For certification it is important that we verify the actual agent program used\nin each vehicle, not a derived model of this. Consequently, we utilise a program model checking [24] approach to assess the correctness of each agent program. For this formal verification of the agent\u2019s autonomous decisions, we use AJPF [7], an extension of the Java PathFinder (JPF) program model checker [14] for GWENDOLEN that allows verification of belief/intention properties.\n\u2022 We do not have the detailed implementations of all the communications protocol, the vehicular control, and environmental interaction, and so use an abstract, formal model to describe these, rather than actual code.\n\u2022 JPF is an explicit-state program-checker and is relatively slow; AJPF builds a BDI programming layer on top of JPF and is at least an order of magnitude slower. Consequently, AJPF cannot realistically be used for verification of the whole system. In addition, as AJPF does not yet have real-time capabilities, then verifying timing aspects within AJPF is difficult.\nWhile these appear problematic, there are several useful simplifications in our context:\n\u2022 When verifying autonomous behaviour, the formal verification we carry out concerns the interaction of beliefs, intentions, etc, within each agent. These do not extend between agents and so, checking of beliefs, intentions, etc, can be localised within each agent.\n\u2022 In the requirements to be checked, the timed and BDI formulae are quite separate, i.e. \u2666\u22645finish \u2227 Bxstarted but never \u2666\u22645Bxstarted or Bx\u2666\u22645finish . As the overall logic is a fusion, and since there are no explicit timing constraints within an agent program (agents have fast internal computation), then this allows us to deal with the dimensions separately.\nSo, given an overall system, S, over which we wish to check \u03d5, then we reduce S |= \u03d5 to two problems:\n1. for each individual agent, Ai, within S, verify the agent properties from \u03d5, i.e. \u03d5a, on the agent within an untimed environment (an over-approximation); and\n2. verify the timing properties from \u03d5 i.e. \u03d5t, on the whole system where the agent program is replaced by an untimed automaton describing solely its input-output behaviour (abstracting from internal BDI reasoning).\nWe explain both of these in more detail, before giving the relevant theorems.\nTimed Automaton\u2212\u2192Untimed Automaton. This is achieved by the over-approximation as above and then allows us to verify V \u2032i \u2016Comms\u2032\u2016Ai |= \u03d5a using AJPF:\nTimed Automaton: Comms\nAgent Program: Ai\nTimed Automaton:\nVi\nUntimed Automaton: Comms\u2019\nAgent Program: Ai\nUntimed Automaton:\nVi\u2019\nABSTRACT\nNote that going from a timed automaton to an untimed one, for example replacing behaviours such as \u2666\u22643receive by \u2666receive provides this over-approximation. Hence, for example, Comms\u2032 |= \u03d5 implies Comms |= \u03d5, but not necessarily the converse.\nAgent Model \u2212\u2192 Untimed Automaton. This is achieved by extracting a model of the agent program\u2019s behaviour, then removing belief/intention aspects from this:\nTimed Automaton: Comms\nAgent Program: Ai\nTimed Automaton:\nVi\nTimed Automaton: Comms\nUntimed Automaton: Ai\u2019\nTimed Automaton:\nVi\nABSTRACT\nFormal verification using Uppaal is then carried out on the whole system with all agents abstracted in this way.\nWe now prove important properties of these abstractions. For simplicity, we assume that S consists of just two agents/vehicles; this result can then easily be generalised to greater numbers of agents/vehicles.\nTheorem 1. Let S == V1 \u2016 A1 \u2016 Comms12 \u2016 A2 \u2016 V2. If\na) V \u20321 \u2016 A1 \u2016 Comms12\u2032 |= \u03d5a and b) V \u20322 \u2016 A2 \u2016 Comms12\u2032 |= \u03d5a and c) V1 \u2016 A\u20321 \u2016 Comms12 \u2016 A\u20322 \u2016 V2 |= \u03d5t.\nthen S |= \u03d5a \u2227 \u03d5t.\nProof. Since V \u20321 and Comms12 \u2032 are over-approximations, then"}, {"heading": "V \u20321\u2016A1\u2016Comms12\u2032 |= \u03d5a implies V1\u2016A1\u2016Comms12 |= \u03d5a.", "text": "Similarly, (b) gives us V2\u2016A2\u2016Comms12 |= \u03d5a. As the agent properties in \u03d5a are local, we can compose these to give V1\u2016A1\u2016Comms12\u2016A2\u2016V2 |= \u03d5a and so S |= \u03d5a.\nBy (c) we know that V1\u2016A\u20321\u2016Comms12\u2016A\u20322\u2016V2 |= \u03d5t yet, as A1 and A2 have no timed behaviour to begin with, we know thatA\u20321 andA \u2032 2 give us exactly the same timed behaviours. Consequently, V1\u2016A1\u2016Comms12\u2016A2\u2016V2 |= \u03d5t and so S |= \u03d5t. These two together give us S |= \u03d5a \u2227 \u03d5t.\nTheorem 2. If V1\u2016A1\u2016Comms12\u2016A2\u2016V2 |= \u03d5t then V1\u2016A\u20321\u2016Comms12\u2016A\u20322\u2016V2 |= \u03d5t.\nProof. Since the timing behaviour of eachAi is identical to eachA\u2032i then V1\u2016A\u20321\u2016Comms12\u2016A\u20322\u2016V2 and V1\u2016A1\u2016Comms12\u2016A2\u2016V2 are equivalent."}, {"heading": "4.2 Individual Agent Verification using AJPF", "text": "To verify agent properties, we use the AJPF model checker on our agent, written in the GWENDOLEN language, as above. For instance, we verify that:"}, {"heading": "If a vehicle never believes it has received confirmation from the leader,", "text": "then it never initiates joining to the platoon.\nThis safety property corresponds to the first requirement of joining a platoon, as given in Section 2, and can be defined as:\n2 (G f3 platoon_m (f3, f1)\n\u2192\u00acDf3 perf(changing_lane(1)) W Bf3 join_agr (f3, f1)) (1)\nHere Gx y stands for a goal y that agent x tries to achieve, Bx z stands for a belief z of agent x, and Dx k stands for an action k that agent x performs/does. The standard LTL operators, such as 2 meaning \u201calways in the future\u201d and W meaning \u201cunless\u201d, are used. An instance of the above , where the agent never receives a join agreement, is:\n2 (G f3 platoon_m (f3, f1) &\u00acB f3 join_agr (f3, f1)) \u2192 2\u00acD f3 perf(changing_lane(1))\n(2)\nTo be able to check such a property, incoming perceptions/communications should be provided. We supply two automata: Comm\u2032, representing communication to/from the other agents; and V \u2032i , representing vehicle responses to agent actions. Under this configuration, we were able to carry out the agent verification in around 12 hours.\nWe have verified a range of safety and liveness properties and we provide some joining/leaving examples below. Note that the following properties can also be similarly expressed in terms of the weak until operator, W ; however, we denote a particular instance of these properties for the sake of brevity."}, {"heading": "If a vehicle ever sends a \u2018join\u2019 request to the leader and eventually receives the join agreement and it is not already in the correct lane, it initiates \u2018joining\u2019 the platoon by performing \u201cchanging lane\u201d.", "text": "( G f3 platoon_m (f3, f1) & \u00acB f3 changed_lane & 2 ItD f3send(leader, tell, message(f3, 1, f1))\u2192 \u2666 B f3 join_agr (f3, f1)) \u2192 \u2666 D f3 perf(changing_lane(1)) (3)\nProperty 3 is a liveness property ensuring that eventually (using the LTL \u2666 operator) the joining procedure initiates the changing lane control system once its condition is fulfilled. Similarly, we can verify other properties to show progress such as eventually the speed and steering controllers are switched to automatic if pre-conditions hold. Other verified properties ensuring safe operation of the platoon are as follows."}, {"heading": "If a vehicle never believes it has changed its lane, then it never switches to the automatic speed controller.", "text": "2 ( G f3 platoon_m (f3, f1) & \u00acB f3 changed_lane ) \u2192 2 \u00acD f3 perf(speed_controller(1))\n(4)"}, {"heading": "If a vehicle never believes it has received a confirmation from the leader, then it never switches to the automatic speed controller.", "text": "2 ( G f3 platoon_m (f3, f1) & \u00acB f3 join_agr (f3, f1) ) \u2192 2 \u00acD f3 perf(speed_controller(1))\n(5)"}, {"heading": "If a vehicle never believes it is sufficiently close to the preceding vehicle, it never switches to the automatic steering controller.", "text": "2 ( G f3 platoon_m (f3, f1) & \u00acB f3 joining_distance ) \u2192 2 \u00acD f3 perf(steering_controller(1))\n(6)"}, {"heading": "If a vehicle never believes it has received a confirmation from the leader to leave the platoon, i.e., increasing spacing has been achieved, then it never disables its autonomous control.", "text": "Note that the leader sends back the \u2018leave\u2019 agreement to follower3 if, and only if, it received an acknowledgement from follower3 showing that spacing has been increased.\n2 (G f3 leave_platoon & \u00acB f3 leave_agr (f3)) \u2192 2 \u00acD f3 perf(speed_controller(0))\n(7)\nIt is important to recall that perceptions and communications coming in to the agent are represented as internal beliefs. Hence the proliferation of belief operators. The AJPF program model checker explores all possible combinations of shared beliefs and messages and so, even with the relatively low number of perceptions above, the combinatorial explosion associated with exploring all possibilities is very significant. Therefore, verifying the whole multi-agent platooning system using AJPF is infeasible.\nTo verify the global properties of multi-agent platooning, we use a complementary approach. We manually generate a model of the whole system as timed-automata and use the Uppaal model checker to establish the (timed) correctness of multi-agent platooning. In the following, we review the relevant timed-automata and highlight some of the global safety properties of vehicle platooning that have been verified using Uppaal."}, {"heading": "4.3 Timed Automata Model of Automotive Platoons", "text": "We model vehicle platooning in Uppaal as a parallel composition of identical processes describing the behaviour of each individual vehicle in the platoon along with an extra process describing the behaviour of the platoon leader (the leader automaton). Each of these vehicle processes is a parallel composition of two timed automata, vehicle and\nagent. The agent automaton, in turn, comprises both Comms and A\u2032i components, as given in Section 4.1 .\nThe vehicle automaton supplies incoming perceptions for the agent automaton. It describes the sensor models and action execution. The vehicle automaton receives, and responds to, the action commands of the corresponding agent through three pairs of binary channels modelling change-lane, set-space and join-distance commands and responses. To model timing behaviour, we define a clock for the vehicle automaton which models the time assessments for \u201cchanging lane\u201d, \u201csetting space\u201d and \u201cjoining distance\u201d actions. Based on engineers\u2019 study, actions change-lane, set-space and joindistance take 20\u00b1 5, 10\u00b1 5 and 10\u00b1 5 seconds, respectively.\nThe agent automaton models an abstracted version of the GWENDOLEN agent by excluding all internal computations of the agent. The overall structure of an agent consists of 5 regions, shown in Fig. 2. If the automaton is in the IDLE region, which consists of only one location, then the agent does not perform any action at that moment. The regions JOIN, LEAVE, SET-SPACE and SW-STEERING represent the sequence of necessary communications with other agents (and the vehicle) in order to achieve the agent\u2019s goals. If a vehicle is part of the platoon it can leave the platoon or receive messages from the leader to set spacing or switch steering controller. If a vehicle is not part of the platoon, it can only join the platoon. Each agent automaton contains two binary channels join-r[i][0] and leave-r[i][0] to model the unicast sending of \u2018join\u2019 and \u2018leave\u2019 requests to the leader and two binary channels joined-suc[i][0] and leftsuc[i][0] to model the unicast sending of \u2018join\u2019 and \u2018leave\u2019 acknowledgements to the leader. These channels are used to model the message passing between the following agents and the leader, modelled in decision-making agent (Section. 3). Furthermore, each agent automaton also contains channels to send commands to its vehicle and receive acknowledgements from its vehicle. The agent automaton has a clock processtime that is used to model the time consumption for achieving goals.\nNext, we define a leader automaton to model the external behaviour of the leader agent (Fig. 3), where the coordination between agents is handled through unicast synchronisation channels. Upon receipt of a joining request, i.e., join-r[i][0]!, it sends a \u201cset spacing\u201d command to the preceding agent where the requested agent wants to be placed. The leader sends a joining agreement, i.e., join-agr-c[0][i]?, to the requested agent, if it has successfully set spacing between the two vehicles where the requested vehicle will be placed. Follower i synchronises with the leader via join-agr-c channel. Then the leader waits for an acknowledgement from the requested agent. It waits for at most the upper bound time for setting space, changing lane and getting close enough to the front vehicle. Upon receipt of the acknowledgement, the leader sends a confirmation to the agent and a \u201cset spacing\u201d command to the preceding agent to decrease its space with the front vehicle to complete the joining procedure. If it does not receive the acknowledgement in time, it sends a \u201cset spacing\u201d command to the preceding agent to decrease its space and waits for a spacing acknowledgement then goes back to the idle location, ready for the next request. The leader communicates with the agents through synchronisation channels. It passes messages to the follower through channels dedicated to the agreements, setting space and switching steering controller. For simplicity, we assume the leader handles only one request at any time."}, {"heading": "4.4 Multi-agent Platooning Verification using Uppaal", "text": "Now we have timed automata representations of the platoon, we can carry out verification of their properties using Uppaal. For simplicity, we analyse the global and timing properties of a multi-agent platoon composed simply of a leader and three vehicles (with three corresponding) agents. We assume vehicles can always set spacing and joining distance in time, i.e., 10 \u00b1 5, but can fail to change lane in time, i.e., less than 20 + 5. In the following, we first give examples of global properties involving the coordination between the leader and the followers. Second, we evaluate timing requirements: the safe lower and upper bounds for joining and leaving activities. We observed that the verification of these properties took less than 3 seconds using Uppaal.\nIf an agent ever receives a joining agreement from the leader, then the preceding agent has increased its space to its front agent. This property is formulated for agent a3 as follows (A represents \u201con all paths\u201d):\nA2 ((a3.rdy_ch_lane && l.joining_vehicle.front == 2) imply ( a2.incr_spacing && a2.spacing_done))\n(8)\nwhere a3 is the agent which is in the rdy_ch_lane location, i.e, the agent has received a joining agreement, variable joining_vehicle.front indicates the identification of the preceding agent, flag a2.incr_spacing models that the preceding agent has received an \u201cincrease space\u201d command from the leader and, finally, flag a2.spacing_done models whether agent a2 has successfully increased its space. We can also verify this property for agents a2 and a4. Property 8 is a safety requirement ensuring that a vehicle initiates\n\u201cchanging lane\u201d only if sufficient spacing is provided. The next property of interest is whether a joining request always ends up increasing space of the preceding vehicle. To express this property, we use the leads to property form, written \u03d5 \u03c8. It states that whenever \u03d5 is satisfied, then eventually \u03c8 will be satisfied. Such properties are written as \u03d5 99K \u03c8 in Uppaal. We verify the property (9) to show that whenever agent a3 is in the wait_ j_ agr location, i.e., has sent a joining request, and agent a2 is the preceding vehicle in the platoon, then eventually a3 will receive an increasing space command and will perform the action.\n(a3.wait_j_agr && l.joining_vehicle.front == 2) 99K ( a2.incr_spacing && a2.spacing_done)\n(9)\nTo ensure that the spacing always decreases after a joining procedure, i.e., platoon returns back to a normal state, we verify that if ever the leader receives a joining request, it eventually sends a decreasing space command to the preceding agent unless the joined agent is the final one in the platoon.\nA2 ((a3.join_completed && l.joining_vehicle.front == 2) imply ( !a2.incr_spacing && a2.spacing_done))\n(10)\nGiven the required time for a vehicle to carry out \u201cset spacing\u201d, \u201cjoining distance\u201d and \u201cchanging lane\u201d tasks, we are interested in verifying if an agent accomplishes joining the platoon within an expected interval: waiting time for agreement + changing lane + joining distance + waiting time for leader confirmation, represented in Property 11.\nA2 (a2.join_completed imply (a2.process_time \u2265 50 && a2.process_time \u2264 90))\n(11)\nSimilarly, we check if an agent leaves a platoon within an expected interval: waiting time for agreement + changing lane + waiting time for leader confirmation. Waiting time for agreement is equal to the time needed to set space and waiting time for leader confirmation is zero because we assume switching steering controllers is immediate.\nA2 (a2.leave_completed imply (a2.process_time \u2265 30 && a2.process_time \u2264 50))\n(12)"}, {"heading": "5 Concluding Remarks", "text": "The verification of safety considerations for automotive platooning is quite complex and difficult. There are several reasons for this.\n\u2022 These are non-trivial hybrid autonomous systems, with each vehicle mixing feedback controllers and agent decision-making.\n\u2022 There is a strong requirement to verify the actual code used in the implementation, rather than extracting a formal model of the program\u2019s behaviour \u2014 this leads on to program model-checking, which is resource intensive.\n\u2022 There are no other practical systems able to model check temporal and modal properties of complex BDI agents \u2014 thus we are led to AJPF.\n\u2022 AJPF is very resource intensive (as we have seen, 12 hours for some agent properties) and cannot be practically used to verify whole system properties of automotive platooning.\n\u2022 Especially when interacting with real vehicles we need to verify timed properties.\nThus it is perhaps not surprising that such formal verification has never been reported before. Safety verification of platooning in the contorl level was investigated extensively [13, 17]. A combined verification approach for vehicle platooning is proposed in [3] where the system behaviour is specified in CSP and B formal methods. A compositional verification approach for vehicle platooning is introduced in [8] where feedback controllers and agent decision-making are mixed.\nIn order to address all of the above concerns, we have adopted a twin strategy. We use AJPF to verify individual agent properties, given realistic abstractions of environmental interactions. We then abstract from the BDI code and produce an abstract agent automaton suitable for use in Uppaal verification. This then allows us to formally verify platoon requirements and safety considerations, a sample of which we have included.\nIt must be emphasised that the agent code that we verify is actually the code that controls the vehicle both in the TORCS simulation and in the real vehicle that we are developing. Thus, as long as the environmental abstractions are correct, we can be sure of the decisions made by the agent.\nFuture Work. There is clearly much future work to tackle. An obvious one is to continue efforts to improve the efficiency of AJPF.\nMaintaining a safe platoon in case of recoverable latency and dissolving a platoon in the case of unrecoverable latency are two procedures that are not implemented in our verified agent code due to a shortcoming of AJPF. Adding these two procedures to the agent grows the system space to the extent that AJPF fails to verify any property. Thus, we are investigating an agent abstraction at the level of goals, beliefs and intentions in order to use AJPF for verification of more complex agents.\nSince we are concerned with certification of automotive platooning in practice, we are aiming to extract a more comprehensive list of formal properties from official platoon requirement documents. Related to this, we are also in the process of porting the agent architecture on to a real vehicle and so testing the platooning algorithms in physical, as well as just simulation, contexts.\nFinally, an important aspect of our two pronged strategy is to link the models used in Uppaal to the programs that AJPF uses. In this paper we generated the Uppaal models by hand, extracted temporal formulae to capture their (non-timed) behaviour,\nand then verified these temporal formulae on the agent code. This at least shows that the timed automata we built correspond to the agent code execution. We believe that all of this can be automated. In particular, we plan to use the AJPF framework to explore the agent code executions and so automatically build up the automaton that Uppaal can use [6]. This would give a much stronger form of completeness and would improve efficiency."}], "references": [{"title": "Model-Checking in Dense Real-time", "author": ["R. Alur", "C. Courcoubetis", "D. Dill"], "venue": "Information and Computation, 104:2\u201334", "citeRegEx": "1", "shortCiteRegEx": null, "year": 1993}, {"title": "Challenges of Platooning on Public Motorways", "author": ["C. Bergenhem", "Q. Huang", "A. Benmimoun", "T. Robinson"], "venue": "Proc. 17th World Congress on Intelligent Transport Systems, pages 1\u201312", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2010}, {"title": "Using CSP\u2016b Components: Application to a Platoon of Vehicles", "author": ["S. Colin", "A. Lanoix", "O. Kouchnarenko", "J. Souqui\u00e8res"], "venue": "Formal Methods for Industrial Critical Systems, pages 103\u2013118. Springer", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2009}, {"title": "Gwendolen: A BDI Language for Verifiable Agents", "author": ["L.A. Dennis", "B. Farwer"], "venue": "AISB\u201908 Workshop on Logic and the Simulation of Interaction and Reasoning. AISB", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2008}, {"title": "Declarative Abstractions for Agent Based Hybrid Control Systems", "author": ["L.A. Dennis", "M. Fisher", "N.K. Lincoln", "A. Lisitsa", "S.M. Veres"], "venue": "Declarative Agent Languages and Technologies VIII, volume 6619 of LNCS, pages 96\u2013111. Springer", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2011}, {"title": "Two-Stage Agent Program Verification", "author": ["L.A. Dennis", "M. Fisher", "M. Webster"], "venue": "Journal of Logic and Computation", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2015}, {"title": "Model Checking Agent Programming Languages", "author": ["L.A. Dennis", "M. Fisher", "M.P. Webster", "R.H. Bordini"], "venue": "Automated Software Engineering, 19(1):5\u201363", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2012}, {"title": "Compositional Verification for Reactive Multi-Agent Systems Applied to Platoon non Collision Verification", "author": ["M. El-Zaher", "J.-M. Contet", "P. Gruer", "F. Gechter", "A. Koukam"], "venue": "Stud. Inform. Univ., 10(3):119\u2013141", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2012}, {"title": "Combining Temporal Logic Systems", "author": ["M. Finger", "D.M. Gabbay"], "venue": "Notre Dame Journal of Formal Logic, 37(2):204\u2013232", "citeRegEx": "9", "shortCiteRegEx": null, "year": 1996}, {"title": "Verifying Autonomous Systems", "author": ["M. Fisher", "L.A. Dennis", "M. Webster"], "venue": "ACM Communications, 56(9):84\u201393", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2013}, {"title": "Many-Dimensional Modal Logics: Theory and Applications", "author": ["D. Gabbay", "A. Kurucz", "F. Wolter", "M. Zakharyaschev"], "venue": "Number 148 in Studies in Logic and the Foundations of Mathematics. Elsevier Science", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2003}, {"title": "The Theory of Hybrid Automata", "author": ["T.A. Henzinger"], "venue": "Proc. 11th IEEE Symposium on Logic in Computer Science, pages 278\u2013. IEEE Computer Society", "citeRegEx": "12", "shortCiteRegEx": null, "year": 1996}, {"title": "Proving Safety of Traffic Manoeuvres on Country Roads", "author": ["M. Hilscher", "S. Linker", "E.-R. Olderog"], "venue": "Z. Liu, J. Woodcock, and H. Zhu, editors, Theories of Programming and Formal Methods, volume 8051 of LNCS, pages 196\u2013212. Springer", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2013}, {"title": "Combined Model Checking for Temporal", "author": ["S. Konur", "M. Fisher", "S. Schewe"], "venue": "Probabilistic, and Real-time Logics. Theoretical Computer Science, 503:61\u201388", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2013}, {"title": "Combining Modal Logics", "author": ["A. Kurucz"], "venue": "J. van Benthem, P. Blackburn, and F. Wolter, editors, Handbook of Modal Logic, volume 3 of Studies in Logic and Practical Reasoning, pages 869\u2013924. Elsevier", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2007}, {"title": "Verified Hybrid Controllers for Automated Vehicles", "author": ["J. Lygeros", "D. Godbole", "S. Sastry"], "venue": "IEEE Trans. Automatic Control,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 1998}, {"title": "Decision Procedures for Propositional Linear-Time Belief-Desire- Intention Logics", "author": ["A.S. Rao"], "venue": "Journal of Logic and Computation, 8(3):293\u2013342", "citeRegEx": "19", "shortCiteRegEx": null, "year": 1998}, {"title": "An Abstract Architecture for Rational Agents", "author": ["A.S. Rao", "M.P. Georgeff"], "venue": "Proc. 3rd International Conference on Principles of Knowledge Representation and Reasoning (KR), pages 439\u2013449", "citeRegEx": "20", "shortCiteRegEx": null, "year": 1992}, {"title": "PATH at 20 - History and Major Milestones", "author": ["S.E. Shladover"], "venue": "IEEE Transactions on Intelligent Transportation Systems, 8(4):584\u2013592", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2007}, {"title": "Model Checking Programs", "author": ["W. Visser", "K. Havelund", "G. Brat", "S. Park", "F. Lerda"], "venue": "Automated Software Eng.,", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2003}, {"title": "KONVOI: Electronically coupled truck convoys", "author": ["M. Wille", "M. R\u00f6wenstrunk", "G. Debus"], "venue": "Human Factors for Assistance and Automation, pages 243\u2013 256", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2008}, {"title": "An Introduction to Multiagent Systems", "author": ["M. Wooldridge"], "venue": "John Wiley & Sons", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2002}, {"title": "Foundations of Rational Agency", "author": ["M. Wooldridge", "A. Rao", "editors"], "venue": "Applied Logic Series. Kluwer Academic Publishers,", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 1999}], "referenceMentions": [{"referenceID": 11, "context": "Traditional approaches involve hybrid automata [12] in which the continuous aspects are encapsulated within discrete states, while discrete behaviours are expressed as transitions between these states.", "startOffset": 47, "endOffset": 51}, {"referenceID": 21, "context": "In particular, the agent paradigm is used [26].", "startOffset": 42, "endOffset": 46}, {"referenceID": 22, "context": "In order to be able to reason about, and formally verify, the choices the system makes, we need a rational agent [27].", "startOffset": 113, "endOffset": 117}, {"referenceID": 9, "context": "This not only makes decisions, but has explicit representations of the reasons for making them, allowing us to describe not only what the autonomous system chooses to do, but why it makes particular choices [10].", "startOffset": 207, "endOffset": 211}, {"referenceID": 17, "context": "The Belief-Desire-Intention (BDI) model is one of the most widely used conceptual models not only for describing rational agents but for actually implementing them [20].", "startOffset": 164, "endOffset": 168}, {"referenceID": 3, "context": "In this paper, we use the GWENDOLEN programming language [4], developed for verifiable BDI-style programming,", "startOffset": 57, "endOffset": 60}, {"referenceID": 6, "context": "We verify properties of the rational agent code using the AJPF model-checker [7], one of the very few model-checkers able to cope with complex properties of BDI agents.", "startOffset": 77, "endOffset": 80}, {"referenceID": 18, "context": "An automotive platoon, enabling road vehicles to travel as a group, is led by a vehicle which is driven by a professional driver [21, 22, 25].", "startOffset": 129, "endOffset": 141}, {"referenceID": 20, "context": "An automotive platoon, enabling road vehicles to travel as a group, is led by a vehicle which is driven by a professional driver [21, 22, 25].", "startOffset": 129, "endOffset": 141}, {"referenceID": 1, "context": "In what follows, we outline the set of high-level automotive platoon concepts and procedures including how to join and leave a platoon [2].", "startOffset": 135, "endOffset": 138}, {"referenceID": 4, "context": "We employ a hybrid agent architecture based on [5] for each vehicle:", "startOffset": 47, "endOffset": 50}, {"referenceID": 3, "context": "Figure 1: GWENDOLEN [4] Syntax", "startOffset": 20, "endOffset": 23}, {"referenceID": 9, "context": "Instead, we will verify the autonomous decisions the vehicles make, captured within each vehicle\u2019s \u2018agent\u2019 [10].", "startOffset": 107, "endOffset": 111}, {"referenceID": 0, "context": "In both these cases we will use Timed Automata [1].", "startOffset": 47, "endOffset": 50}, {"referenceID": 0, "context": "Thus, the formal structures that allow us to fully represent all the system above are quite complex, combining timed relations as well as relations for each of the belief and intention dimensions [1, 19].", "startOffset": 196, "endOffset": 203}, {"referenceID": 16, "context": "Thus, the formal structures that allow us to fully represent all the system above are quite complex, combining timed relations as well as relations for each of the belief and intention dimensions [1, 19].", "startOffset": 196, "endOffset": 203}, {"referenceID": 8, "context": "We will not describe this formal model in detail but just note that it is a fusion [9, 11, 16] of timed and BDI structures, \u3008L,A,C, E , inv,RB , RI , l\u3009, where: L is a finite set of locations; A is a finite set of actions; C is a finite set of clocks; E \u2286 L \u00d7 \u03a8(C) \u00d7 A \u00d7 2 \u00d7 L is a set of (timed) edges between locations; inv : L \u2192 \u03a8(C) is a function associating each location with some clock constraint in \u03a8(C); RB : Ag \u2192 (L \u00d7 L), where Ag is the set of \u2018agents\u2019 and RB(a) provides the belief relation (corresponding to KD45 modal logic) for agent a between locations; RI : Ag \u2192 (L \u00d7 L), where RB(c) provides the intention relation (KD) for agent c between locations; and l : L \u2192 2 is a labelling function essentially capturing those propositions true at each location (AP is a set of atomic propositions).", "startOffset": 83, "endOffset": 94}, {"referenceID": 10, "context": "We will not describe this formal model in detail but just note that it is a fusion [9, 11, 16] of timed and BDI structures, \u3008L,A,C, E , inv,RB , RI , l\u3009, where: L is a finite set of locations; A is a finite set of actions; C is a finite set of clocks; E \u2286 L \u00d7 \u03a8(C) \u00d7 A \u00d7 2 \u00d7 L is a set of (timed) edges between locations; inv : L \u2192 \u03a8(C) is a function associating each location with some clock constraint in \u03a8(C); RB : Ag \u2192 (L \u00d7 L), where Ag is the set of \u2018agents\u2019 and RB(a) provides the belief relation (corresponding to KD45 modal logic) for agent a between locations; RI : Ag \u2192 (L \u00d7 L), where RB(c) provides the intention relation (KD) for agent c between locations; and l : L \u2192 2 is a labelling function essentially capturing those propositions true at each location (AP is a set of atomic propositions).", "startOffset": 83, "endOffset": 94}, {"referenceID": 14, "context": "We will not describe this formal model in detail but just note that it is a fusion [9, 11, 16] of timed and BDI structures, \u3008L,A,C, E , inv,RB , RI , l\u3009, where: L is a finite set of locations; A is a finite set of actions; C is a finite set of clocks; E \u2286 L \u00d7 \u03a8(C) \u00d7 A \u00d7 2 \u00d7 L is a set of (timed) edges between locations; inv : L \u2192 \u03a8(C) is a function associating each location with some clock constraint in \u03a8(C); RB : Ag \u2192 (L \u00d7 L), where Ag is the set of \u2018agents\u2019 and RB(a) provides the belief relation (corresponding to KD45 modal logic) for agent a between locations; RI : Ag \u2192 (L \u00d7 L), where RB(c) provides the intention relation (KD) for agent c between locations; and l : L \u2192 2 is a labelling function essentially capturing those propositions true at each location (AP is a set of atomic propositions).", "startOffset": 83, "endOffset": 94}, {"referenceID": 10, "context": "The logic then interpreted over such structures combines [11] the syntax of timed temporal logic, for example\u2666\u22645finish , and the syntax of modal logics of belief, desire and intention, for example Bxstarted (i.", "startOffset": 57, "endOffset": 61}, {"referenceID": 13, "context": "In principle, though very complex, we could provide all our convoy requirements in such a logic, build structures of the above form for our convoy implementation, and then develop a model-checking approach for this combination [15].", "startOffset": 227, "endOffset": 231}, {"referenceID": 19, "context": "Consequently, we utilise a program model checking [24] approach to assess the correctness of each agent program.", "startOffset": 50, "endOffset": 54}, {"referenceID": 6, "context": "For this formal verification of the agent\u2019s autonomous decisions, we use AJPF [7], an extension of the Java PathFinder (JPF) program model checker [14] for GWENDOLEN that allows verification of belief/intention properties.", "startOffset": 78, "endOffset": 81}, {"referenceID": 12, "context": "Safety verification of platooning in the contorl level was investigated extensively [13, 17].", "startOffset": 84, "endOffset": 92}, {"referenceID": 15, "context": "Safety verification of platooning in the contorl level was investigated extensively [13, 17].", "startOffset": 84, "endOffset": 92}, {"referenceID": 2, "context": "A combined verification approach for vehicle platooning is proposed in [3] where the system behaviour is specified in CSP and B formal methods.", "startOffset": 71, "endOffset": 74}, {"referenceID": 7, "context": "A compositional verification approach for vehicle platooning is introduced in [8] where feedback controllers and agent decision-making are mixed.", "startOffset": 78, "endOffset": 81}, {"referenceID": 5, "context": "In particular, we plan to use the AJPF framework to explore the agent code executions and so automatically build up the automaton that Uppaal can use [6].", "startOffset": 150, "endOffset": 153}], "year": 2016, "abstractText": "The coordination of multiple autonomous vehicles into convoys or platoons is expected on our highways in the near future. However, before such platoons can be deployed, the new autonomous behaviours of the vehicles in these platoons must be certified. An appropriate representation for vehicle platooning is as a multiagent system in which each agent captures the \u201cautonomous decisions\u201d carried out by each vehicle. In order to ensure that these autonomous decision-making agents in vehicle platoons never violate safety requirements, we use formal verification. However, as the formal verification technique used to verify the agent code does not scale to the full system and as the global verification technique does not capture the essential verification of autonomous behaviour, we use a combination of the two approaches. This mixed strategy allows us to verify safety requirements not only of a model of the system, but of the actual agent code used to program the autonomous vehicles.", "creator": "LaTeX with hyperref package"}}}