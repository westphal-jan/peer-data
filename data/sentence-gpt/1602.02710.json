{"id": "1602.02710", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "5-Feb-2016", "title": "Strategic disclosure of opinions on a social network", "abstract": "We study the strategic aspects of social influence in a society of agents linked by a trust network, introducing a new class of games called games of influence. A game of influence is an infinite repeated game with incomplete information in which, at each stage of interaction, an agent can make her opinions visible (public) or invisible (private) in order to influence other agents' opinions. The influence process is mediated by a trust network, as we assume that the opinion of a given agent is only affected by the opinions of those agents that she considers trustworthy (i.e., trustworthy). This trust network is one of the most powerful components of the social system. By examining the effects of a trust network, the authors show that many social agents are able to exert political influence in a society, with little or no change. The trust network may be the most powerful of all forms of communication, and, therefore, the most powerful of all social agents.\n\n\n\nThe authors propose that the influence process, a multilingual network, is a necessary way of learning how to use information to influence decisions and decisions. Using a trust network, a person can learn how to act in a socially acceptable way, and learn the skills to follow their goals in a society that rewards them. The trust network provides information about the individual who makes decisions and what decisions they make, how to act in a society that rewards them, and how to respond to an event. The trust network, as shown in the game, is the same as that of a trust network, and it contains information that is needed to influence the decisions made by other members of the system. The trust network may have an impact on decisions made by other members of the system, but also on their interactions with others who share their opinions and beliefs. By using a trust network, a person may have a real, honest understanding of the values and concerns of the system and to interact with it with others with their opinions. In contrast, in the game, an individual may have a real, honest understanding of the value and concerns of the system and to interact with it with others with their opinions. This knowledge could be transmitted through the use of the trust network to influence decisions and decisions.\nIn an interview with Wissenbaum, he explained how he hopes to use a trust network for education, but, \"what I'm saying is that the network is a form of communication. There are many aspects to the system that we can think about.\" He is also interested in improving social awareness and social interaction. The", "histories": [["v1", "Fri, 5 Feb 2016 14:10:44 GMT  (29kb)", "http://arxiv.org/abs/1602.02710v1", null]], "reviews": [], "SUBJECTS": "cs.GT cs.AI", "authors": ["umberto grandi", "emiliano lorini", "laurent perrussel"], "accepted": false, "id": "1602.02710"}, "pdf": {"name": "1602.02710.pdf", "metadata": {"source": "CRF", "title": "Strategic disclosure of opinions on a social network", "authors": ["Umberto Grandi", "Emiliano Lorini"], "emails": [], "sections": [{"heading": null, "text": "ar X\niv :1\n60 2.\n02 71\n0v 1\n[ cs\n.G T"}, {"heading": "1 Introduction", "text": "At the micro-level, social influence can be conceived as a process where an agent forms her opinion on the basis of the opinions expressed by other agents in the society. Social influence depends on trust since an agent can be influenced by another agent, so that her opinions are affected by the expressed opinions of the other, only if she trusts her. At the macro-level, social influence is the basic mechanism driving the diffusion of opinions in human societies: certain agents in the society influence other agents in the society towards a given view, and these agents, in turn, influence other agents to acquire the same view, and so on. In other words, social influence can be seen as the driving force of opinion diffusion in human and human-like agent societies. This view is resonant of existing studies in social sciences and social psychology which\n\u2217This work was partially supported by Labex CIMI (ANR-11-LABX-0040-CIMI), within the program ANR-11-IDEX-0002-02.\nemphasize the role of interpersonal processes in how people construe and form their perceptions, judgments, and impressions (see, e.g., [1, 9, 15]).\nRecent work in multi-agent systems [18, 12] proposed a formal model of opinion diffusion that combined methods and techniques from social network analysis with methods and techniques from belief merging and judgment aggregation. The two models aim at studying how opinions of agents on a given set of issues evolve over time due to the influence of other agents in the population. The basic component of these models is the trust network, as it is assumed that the opinions of a certain agent are affected only by the opinions of the agents that she trusts (i.e., the agents in the trust network that are directly linked to her). Specifically, the opinions of a certain agent at a given time are the result of aggregating the opinions of the trustworthy agents at the previous time.\nIn this work we build on these models to look at social influence from a strategic perspective. We do so by introducing a new class of games, called games of influence. Specifically, a game of influence is an infinite repeated game with incomplete information in which, at each stage of interaction, an agent can make her opinions visible (public) or invisible (private) to the other agents. Incompleteness of information is determined by the fact that an agent has uncertainty about the private opinions of the other agents, as she cannot see them. At each stage of the game, every agent is influenced by the public opinions of the agents she trusts (i.e., her neighbors in the trust network) and changes her opinions on the basis of the aggregation criterion she uses.\nFollowing the representation of agents\u2019 motivations given in [14], in a game of influence each agent is identified with the goal that she wants to achieve. This goal is represented by a formula of a variant of linear temporal logic (LTL), in which we can express properties about agents\u2019 present and future opinions. For example, an agent might have the achievement goal that at some point in the future there will be consensus about a certain proposition p (i.e., either everybody has the opinion that p is true or everybody has the opinion that p is false), or the maintenance goal that two different agents will always have the same opinion about p.\nGames of influence provide a simple abstraction to explore the effects of the trust network structure on the agents\u2019 behaviour. We consider solution concepts from gametheory such as Nash equilibrium, weak dominance and winning strategies. For instance, in the context of games of influence, we can study how the relative position of an agent in the trust network determines her influencing power, that is, her capacity to influence opinions of other agents, no matter what the others decide to do (which corresponds to the concept of uniform strategy). Moreover, in games of influence one can study how the structure of the trust network determines existence of Nash equilibria, depending on the form of the agents\u2019 goals. For instance, we will show that if the trust network is fully connected and every agent wants to reach a consensus about a certain proposition p, then there always exists a least one Nash equilibrium.\nRelated work and paper outline\nApart from the above mentioned work on opinion diffusion via judgment aggregation [12] and belief merging [18], there is a vast interest in providing formal models of social influence. The most relevant is probably the work of Gosh and Vela\u0301zquez-\nQuesada [10], which does not however consider strategic aspects in their preference update model. The Facebook logic introduced by Seligman et al. [19] is also relevant, and motivated our effort in Section 4 to get rid of epistemic operators in the goal language. The difference between private and public information is reminiscent of the work of Christoff and Hansen [6, 7], which also does not focus on strategic aspects. A related problem to opinion diffusion is that of information cascades and knowledge diffusion, which has been given formal treatment in a logical settings [16, 2]. Finally, our work is greatly indebted to the work of [14], since an influence game can be considered as a variation of an iterated boolean game in which individuals do not have direct power on all the variables \u2013 there can be several individuals influencing another one \u2013 but concurrently participate in its change. Finally, [20] recently presented an extension of iterated boolean games with a social network structure in which agents choose actions depending on the actions of those in their neighbourhood.\nThe paper is organized as follows. Section 2 presents the basic definition of private and public opinions, as well as our model of opinion diffusion. In Section 3 we present our language for goals based on an epistemic version of LTL, and we show that both the model-checking problem remains in PSPACE (as for LTL), by showing a reduction of the epistemic operator. Section 4 introduces the definition of influence games, and presents the main results about the effects of the network structure on solution concepts such as Nash equilibria and winning strategy, and on the complexity of checking that a given profile of strategies is a Nash equilibrium. Section 5 concludes the paper."}, {"heading": "2 Opinion diffusion", "text": "In this section we present the model of opinion diffusion which is the starting point of our analysis. We generalise the model of propositional opinion diffusion introduced in related work [12] by separating private and public opinions, and adapting the notion of diffusion through aggregation to this more complex setting."}, {"heading": "2.1 Private and public opinions", "text": "Let I = {p1, . . . , pm} be a finite set of propositions or issues and let N = {1, . . . , n} be a finite set of individuals or agents. Agents have opinions about all issues in I in the form of a propositional evaluations, or, equivalently, a vector of 0s and 1s:\nDefinition 1 (private opinion). The private opinion of agent i is a function Bi : I \u2192 {1, 0} where Bi(p) = 1 and Bi(p) = 0 express, respectively, the agent\u2019s opinion that p is true and the agent\u2019s opinion that p is false.\nFor every J \u2286 N , we denote with BJ = \u03a0i\u2208JBi the set of all tuples of opinions of the agents in J . Elements of BJ are denoted by BJ . For notational convenience, we write B instead of BN , and Bi instead of B{i}.\nLet B = (B1, . . . , Bn) denote the profile composed by the individual opinion of each agent. Propositional evaluations can be used to represent ballots in a multiple referendum, expressions of preference over alternatives, or value judgements over correlated issues (see, e.g., [5, 11]). Depending on the application at hand, an integrity\nconstraint can be introduced to model the propositional correlation among issues. For the sake of simplicity in this paper we do not assume any correlation among the issues, but the setting can easily be adapted to this more general framework.\nWe also assume that each agent has the possibility of declaring or hiding her private opinion on each of the issues.\nDefinition 2 (visibility function). The visibility function of agent i is a map Vi : I \u2192 {1, 0} where Vi(p) = 1 and Vi(p) = 0 express, respectively, the fact that agent i\u2019s opinion on p is visible and the fact that agent i\u2019s opinion on p is hidden.\nWe denote with V = (V1, . . . , Vn) the profile composed of the agents\u2019 visibility functions. By combining the private opinion with the visibility function of an agent we can build her public opinion as a three-valued function on the set of issues.\nDefinition 3 (public opinion). Let Bi be agent i\u2019s opinion and Vi her visibility function. The public opinion induced by Bi and Vi is a function Pi : I \u2192 {1, 0, ?} such that\nPi(p) =\n{ Bi(p) if Vi(p) = 1\n? if Vi(p) = 0\nFor every J \u2286 N , we denote with PJ = \u03a0i\u2208JPi the set of all tuples of public opinions of the agents in J . Elements of PJ are denoted by PJ . For notational convenience, we write P instead of PN , and Pi instead of P{i}.\nOnce more, P = (P1, . . . , Pn) denotes the profile of public opinions of all the agents in N . Pi is aimed at capturing the public expression of i\u2019s view about the issues in I. Observe that an agent can only hide or declare her opinion about a given issue, but is not allowed to lie. Relaxing this assumption would actually represent an interesting direction for future work."}, {"heading": "2.2 Information states", "text": "The information contained in a profile of public opinions can also be modelled using a state-based representation and an indistinguishability relation, in line with the existing work on interpreted systems (see, e.g., [8]). States will form the building blocks of our model of strategic reasoning in opinion dynamics.\nDefinition 4 (state). A state is a tuple S = (B,V ) where B is a profile of private opinions and V is a profile of visibility functions. The set of all states is denoted by S.\nThe following definition formalises the uncertainty between states induced by the visibility functions. The idea is that an agent cannot distinguish between two states if and only if both the agent\u2019s individual opinion and the other agents\u2019 public opinions are the same according to the two states.\nDefinition 5 (Indistinguishability). Let S, S\u2032 \u2208 S be two states. We say that agent i cannot distinguish between them, denoted by S \u223ci S\u2032, if and only if:\n\u2022 Bi = B\u2032i,\n\u2022 V = V \u2032 and\n\u2022 for all j \u2208 N \\ {i} and for all p \u2208 I, if Vj(p) = 1 then Bj(p) = B\u2032j(p).\nLet S\u223ci = {S\u2032 \u2208 S | S \u223ci S\u2032} be the set of states that agent i cannot distinguish from S. Clearly \u223ci is an equivalence relation. In what follows we will often use public states to represent the equivalence class of a state. Observe however that this is a too coarse representation, since each of the agents knows her own belief.\nExample 1. Let there be three agents i, j and k, and one issue p. Assume that agents j and k consider p as true as private opinion while i private opinion is p = 0. Suppose also that agents i and j make their opinion public while agent k does not. From the perspective of agent i, the two states S0 = ((0, 1, 0), (1, 1, 0)) and S1 = ((0, 1, 1), (1, 1, 0)) are indistinguishable, representing the two possible opinions of agent k who is hiding it. Figure 1 represents the perspective of agent i."}, {"heading": "2.3 Opinion diffusion through aggregation", "text": "In this section we define the influence process that is at the heart of our model. Our definition is a generalisation of the model by [12].\nFirst, we assume that individuals are connected by an influence network which we model as a directed graph:\nDefinition 6 (influence network). An influence network is a directed irreflexive graph E \u2286 N \u00d7N . We interpret (i, j) \u2208 E as \u201cagent j is influenced by agent i\u201d.\nWe also refer to E as the influence graph and to individuals in N as the nodes of the graph. Let Inf (j) = {i \u2208 N | (i, j) \u2208 E} be the set of influencers of agent j in the network E. Given a state S, this definition can be refined by considering the set Inf S(i, p) = {j \u2208 N | (j, i) \u2208 E and Pj(p) 6= ?} to be the subset of influencers that are actually expressing their private opinion about issue p. Clearly, Inf S(i, p) \u2286 Inf (i) for all p and S.\nExample 2. Figure 2 represents a basic influence network where some agent i is influenced by two agents j and k. The set Inf (i) = {j, k}, and, using the notation in the previous example, the set Inf S0(i, p) = Inf S1(i, p) = {j}.\ni kj\nFigure 2: i influences by j and k.\nGiven a profile of public opinions and an influence network E, we model the process of opinion diffusion by means of an aggregation function, which shapes the private opinion of an agent by taking into consideration the public opinions of her influencers.\nDefinition 7 (Aggregation procedure). An aggregation procedure for agent i is a class of functions\nFi : B \u00d7 PJ \u2212\u2192 B for each J \u2286 N \\ {i}\nthat maps agent i\u2019s individual opinion and the public opinions of a set of agents J to agent i\u2019s individual opinion.\nAggregation functions are used to construct the new private opinion of an agent in the dynamic process of opinion diffusion. Thus, Fi(Bi,P Inf (i)) represents the private opinion of agent i updated with the public opinions received by its influencers.\nA number of aggregation procedures have been considered in the literature on judgment aggregation and can be adapted to our setting. Notable examples are quota rules, where an agent changes her opinion if the amount of people disagreeing with her is superior of a given quota (the majority rule is such an example). These aggregation procedures give rise to the class of threshold models studied in the literature on opinion diffusion [13, 17].\nFor the sake of simplicity in this paper we consider that all agents use the following aggregation procedure:\nDefinition 8. Let S = (B,V ) be a state and P the corresponding profile of public opinions. The unanimous issue-by-issue aggregation procedure is defined as follows:\nFUi (Bi,P )(p) =    Bi(p) if Inf S(i, p) = \u2205 x \u2208 {0, 1} if Pj(p) = x \u2200j \u2208 Inf S(i, p)\nBi(p) otherwise\nThat is, an individual will change her private opinion about issue p if and only if all her influencers that are expressing their opinion publicly are unanimous in disagreeing with her own one."}, {"heading": "2.4 Strategic actions and state transitions", "text": "Showing or hiding information is a key action in the model of opinion diffusion defined above. The dynamic of opinion is rooted in two dimensions: the influence network and the visibility function. At each time step, by hiding or revealing their opinions, agents influence other agents opinions. We assume that agents can make their opinions visible or invisible by specific actions of type reveal(p) (i.e., action of making the opinion\nabout p visible) and hide(p) (i.e., action of hiding the opinion about p). The action of doing nothing is denoted by skip. Let therefore\nA ={reveal(p) : p \u2208 I} \u222a {hide(p) : p \u2208 I} \u222a {skip}\nbe the set of all individual actions and J = An the set of all joint actions. Elements of J are denoted by a = (a1, . . . , an).\nEach joint action a induces a transition function between states. This function is deterministic and is defined as follows:\nDefinition 9 (transition function). The transition function succ : S \u00d7 J \u2212\u2192 S associates to each state S and joint action a a new state S\u2032 = (B\u2032,V \u2032) where, for all i \u2208 N :\n\u2022 V \u2032i (p) =    1 if ai = reveal(p) or 0 if ai = hide(p) or\nVi(p) if ai = skip\n\u2022 B\u2032i = F U i (Bi,P \u2032 Inf (i))\nWhere P \u2032 is the public profile obtained from private profile B and visibility functions V \u2032.\nBy a slight abuse of notation we denote with a(S) the state succ(S,a) obtained from S and a by applying the transition function. Observe that in our definition of transition function we are assuming that the influence process occurs after that the actions have modified the visibility of the agents\u2019 opinions. Specifically, first, actions have consequences on the visibility of the agents\u2019 opinions, then, each agent modifies her private opinions on the basis of those opinions of other agents that have become public.\nWe are now ready to define the concept of history, describing the temporal aspect of agents\u2019 opinion dynamic:\nDefinition 10 (history). Given a set of issues I, a set of agents N , and aggregation procedures Fi over a network E, an history is an infinite sequence of states H = (H0, H1, . . .). such that for all t \u2208 N there exists a joint action at \u2208 J such that Ht+1 = at(Hn).\nLet H = (H0, H1, . . .) be an history. For notational convenience, for any i \u2208 N and for any t \u2208 N, we denote with HBi,t agent i\u2019s private opinion in state Ht and with HVi,t agent i\u2019s visibility function in state Ht.\nThe set of all histories is denoted by H. Observe that our definition restricts the set of all possible histories to those that corresponds to a run of the influence dynamic described above.\nExample 3. Let us reconsider the two previous examples, with initial state H0 = S0. Consider now the following joint actions a0 = (skip, skip, reveal(p)) and a1 = (skip, hide(p), skip): agent k reveals her opinion, and at the next step j hides her\nopinion about p. If we assume that all individuals are using the unanimous aggregation procedure then Figure 3 shows the two states H1 and H2 constructed by applying the two joint actions from state S0. In state H1, agent i\u2019s private opinion about p has changed, i.e., HBi,1(p) = 1 as all her influencers are publicly unanimous about p. At the next step, instead, no opinion is updated."}, {"heading": "3 Temporal and Epistemic Goals", "text": "As agents can hide or reveal their opinions, the strategic dimension of opinion diffusion is immediate: by revealing/hiding her opinion, an agent influences other agents. Influence is actually guided by some underlying goals. An agent reveals/hides her opinion only if she wants to influence some other agents: she aims at changing individual opinions. Temporal dimension is immediate as the dynamics of opinion has to be considered. Following [14], we define a language to express individual epistemic goals about the state of the individual opinions."}, {"heading": "3.1 Epistemic temporal logic of influence", "text": "Let us introduce a logical language based on a combination of simple version of multiagent epistemic logic and linear temporal logic (LTL) that can be interpreted over histories. In line with our framework, term epistemic state should be interpreted as private opinion. Goals in our perspective consists of targeting an epistemic state: typically \u2018\u2019agent i wants that agent j has private opinion \u03d5 in the future\u201d. The proposed language does not allow the temporal operator to be in the scope of a knowledge operator, obtaining a simpler language and a reduction that allows us to stay in the same complexity class as LTL.\nWe call ELTL\u2013I this logic, from epistemic linear temporal logic of influence. Its language, denoted by LELTL\u2013I, is defined by the following BNF:\n\u03b1 ::= op(i, p) | vis(i, p) | \u00ac\u03b1 | \u03b11 \u2227 \u03b12 | Ki\u03b1 \u03d5 ::= \u03b1 | \u00ac\u03d5 | \u03d51 \u2227 \u03d52 | X\u03d5 | \u03d51U\u03d52\nwhere i ranges over N and p ranges over I. op(i, p) has to be read \u201cagent i\u2019s opinion is that p is true\u201d while \u00acop(i, p) has to be read \u201cagent i\u2019s opinion is that p is not true\u201d (since we assume that agents have binary opinions). vis(i, p) has to be read \u201cagent i\u2019s opinion about p is visible\u201d. Finally, Ki\u03b1 has to be read \u201cagent i knows that \u03b1 is true\u201d.\nX\u03d5 and U are the standard LTL operators \u2018next\u2019 and \u2018until\u2019. In particular, X\u03d5 has to be read \u201c\u03d5 is going to be true in the next state\u201d and \u03d51U\u03d52 has to be read \u201c\u03d51 will\nbe true until \u03d52 is true\u201d. As usual, we can define the temporal operators \u2018henceforth\u2019 (G) and \u2018eventually\u2019 (F) by means of the \u2018until\u2019 operator:\nG\u03d5 =def \u00ac(\u22a4U\u00ac\u03d5)\nF\u03d5 =def \u00acG\u00ac\u03d5\nThe interpretation of LELTL\u2013I-formulas relative to histories is defined as follows.\nDefinition 11 (Truth conditions). Let \u03d5 be a LELTL\u2013I-formula, let H be a history and let k \u2208 N. Then:\nH, k |= op(i, p) \u21d4 HBi,k(p) = 1\nH, k |= vis(i, p) \u21d4 HVi,k(p) = 1\nH, k |= Ki\u03b1 \u21d4 \u2200H \u2032 \u2208 H : if H(k) \u223ci H \u2032(k) then\nH \u2032, k |= \u03b1\nH, k |= \u00ac\u03d5 \u21d4 H, k 6|= \u03d5\nH, k |= \u03d51 \u2227 \u03d52 \u21d4 H, k |= \u03d51 and H, k |= \u03d52 H, k |= X\u03d5 \u21d4 H, k + 1 |= \u03d5\nH, k |= \u03d51U\u03d52 \u21d4 \u2203k \u2032 \u2208 N : (k \u2264 k\u2032 and H, k\u2032 |= \u03d52 and\n\u2200k\u2032\u2032 \u2208 N : if k \u2264 k\u2032\u2032 < k\u2032 then H, k\u2032\u2032 |= \u03d51)\nThe operator Ki is rather peculiar, and should not be interpreted as a classical individual epistemic operator. It mixes public and private opinions of our model. Operator Ki reading is rather \u201dagent i is uncertain about other agents private opinion as this opinion is not visible\u201d and Ki\u03b1 stands for agent i knows \u03b1 despite this uncertainty.\nThe following proposition shows thatKi could also be formulated in terms of equivalence between histories rather than in terms of equivalence between states. Its proof is immediate from our definitions.\nProposition 1. Let H \u2208 H and k \u2208 N. Then\nH, k |= Ki\u03b1 iff \u2200H \u2032 \u2208 H : if H \u223ci H \u2032 then H \u2032, k |= \u03b1\nwhere H \u223ci H \u2032 iff H(h) \u223ci H \u2032(h) for all h \u2208 N.\nExample 4. Consider Figure 3, the following statement expresses that in state H0, it is the case that in the future agent k knows agent i public opinion about p (as H\u223ck1 = {H1}):\nH, 0 |= F(Kk(op(i, p) \u2227 vis(i, p)))\nThis example also shows how each ELTL\u2013I statements can be used for representing individual goals. Hence, gathering individual goals lead to the construction of a boolean game. Before detailing this aspect we conclude the section by exhibiting the key results about model checking for the ELTL\u2013I logic."}, {"heading": "3.2 Model checking", "text": "The aim of this section is to show that model checking for ELTL\u2013I is as hard as model checking for LTL. Recall that epistemic temporal logic has very high complexity [8]. We do so by reducing formulas containing an epistemic modality to propositional ones.\nLemma 5. The following formulas are valid in ELTL\u2013I: (i) Kiop(i, p) \u2194 op(i, p) (ii) Kiop(j, p) \u2194 (op(j, p) \u2227 vis(j, p)) if i 6= j (iii) Kivis(j, p) \u2194 vis(j, p) for all j (iv) Ki\u00acop(i, p) \u2194 \u00acop(i, p) (v) Ki\u00acop(j, p) \u2194 (\u00acop(j, p) \u2227 vis(j, p)) if i 6= j (vi) Ki\u00acvis(j, p) \u2194 \u00acvis(j, p) for all j\nsketch. Straightforward from Definition 5 and the interpretation of the Kip operator. To show the right-to-left direction of (ii) and (v), suppose that op(j, p) is true at every indistinguishable state for \u223ci, i.e., that Kiop(j, p) is true. This implies that op(j, p) is true in the current state. Moreover, if vis(j, p) is false, then by Definition 5 there would be an indistinguishable state in which op(j, p) is false, contradicting the hypothesis.\nWe now show two distribution laws for the operator Ki with respect to conjunction and negation:\nLemma 6. The following formulas are valid in ELTL\u2013I: (i) Ki(\u03b11 \u2227 \u03b12) \u2194 (Ki\u03b11 \u2227 Ki\u03b12) for all \u03b11 and \u03b12; (ii) Ki(\u03b11 \u2228 \u03b12) \u2194 (Ki\u03b11 \u2228 Ki\u03b12) when \u03b11 and \u03b12 do not contain any occurrence\nof the modality Kj for any j.\nsketch. (i) and the right-to-left directions of (ii) are standard consequences of interpreting Kip over equivalence relations. We now prove the left-to-right direction of (ii) by induction on the construction of a propositional formula.\nAssume some historyH and state S and suppose that the left part holds. This means that in all states \u2208 S\u223ci , either \u03b11 or \u03b12 is true. If both statements contains vis(j, p) or \u00acvis(j, p) then Definition 5 entails that right-to-left direction hold, since either\u03b11 holds in all states \u2208 S\u223ci or \u03b12 holds in all states \u2208 S\u223ci . If \u03b11 (respectively \u03b12) contains some statement op(i, p), then the right-to-left direction holds as \u03b11 either holds in all states \u2208 S\u223ci or is false in all states. If it does not hold then \u03b12 is considered in a similar way to \u03b11. Now suppose that \u03b11 and \u03b12 only contain statements of the form op(j, p) s.t. it is always the case that j 6= i. Then there must exist j, p such that vis(j, p) = 1. Otherwise, there exists a state S\u2032 \u2208 S\u223ci such that neither \u03b11 or \u03b12 hold (as all possible indistinguishable states must be considered). In conclusion, the right-to-left direction holds as either \u03b11 (respectively \u03b12) either holds in all states \u2208 S\u223ci or it does not hold in all states.\nFinally, we reduce the nesting of the Kip operator:\nLemma 7. The following formulas are valid in ELTL\u2013I: (i) KiKi\u03b1 \u2194 Ki\u03b1\n(ii) KiKjKi\u03b1 \u2194 KjKi\u03b1 for all i 6= j, when \u03b1 do not contain any occurrence of the modality Kj for any j.\nsketch. The proof of (i) is a standard consequence of using equivalence relations. To prove (ii), let \u03b1 be a propositional formula. Put first \u03b1 in CNF and then distribute by Lemma 6 the modalities over conjunction. We now prove that KiKjKi\u2113 \u2194 KjKi\u2113 where \u2113 is a literal. If \u2113 = (\u00ac)vis(j, p), then by Lemma 5 both sides of the equivalence reduce to (\u00ac)vis(j, p). Suppose that \u2113 = (\u00ac)op(k, p) for some k \u2208 N . If k 6= i, j then by Lemma 5 we can reduce Ki\u2113 to \u2113 \u2227 vis(k, p), and then it is straightforward to conclude by observing that Ki\u2113 \u2227 vis(k, p) \u2194 \u2113 \u2227 vis(k, p) \u2227 vis(k, p) which in turn is equivalent to \u2113 \u2227 vis(k, p). The case of k = i and k = j is similar.\nWe are now ready to present an algorithm to translate a formula of ELTL\u2013I into an equivalent one without any occurrence of the Ki operator. Let an epistemic literal be a formula of the form (\u00ac)Ki\u2113 for i \u2208 N and propositional literal \u2113.\nInput: a formula \u03d5 \u2208 LELTL\u2013I Output: a formula red(\u03d5) \u2208 LELTL\u2013I with no epistemic operators\nwhile there is an epistemic operator in \u03d5 outside an epistemic literal do 1. choose a subformula Ki\u03b1 of \u03d5 such that \u03b1 is without epistemic operators and is not a propositional literal; 2. put \u03b1 in negated normal form (NNF); 3. distribute Ki over \u2227 and \u2228 ; end 4. Reduce the depth modalities with Lemma 7; 5. Reduce the atoms with Lemma 5 ;\nAlgorithm 1: Reduction of the epistemic operator\nThe following proposition guarantees that the translation defined is also polynomial.\nLemma 8. Algorithm 1 terminates, red(\u03d5) is polynomial in the size of \u03d5, does not contain epistemic operators, and is equivalent to \u03d5.\nProof. Lines 3, 4 and 5 apply equivalences that are valid by Lemmas 5, 6 and 7 and the fact that the following rule of replacement of equivalents is admissible in ELTL\u2013I:\n\u03c81 \u2194 \u03c82 \u03d5 \u2194 \u03d5[\u03c81/\u03c82]\nThe negated normal form of a propositional formula (treating epistemic literals as propositional literals) is constructed by propositional equivalence and is polynomial in the size of the initial formula. Finally, since the modal depth is limited by Lemma 7 to |N |, we add a maximum of |N | extra variables of the form vis(j, p) for some j and some p to the translation of each epistemic literal.\nUsing Lemma 8, we are able to polynomially reduce every formula of the ELTL\u2013I to an equivalent formula of the fragment LTL\u2013I whose language LLTL\u2013I is defined by the following BNF:\n\u03d5 ::= op(i, p) | vis(i, p) | \u00ac\u03d5 | \u03d51 \u2227 \u03d52 | X\u03d5 | \u03d51U\u03d52\nwhere i ranges over N and p ranges over I. We first show the following:\nProposition 2. The model checking problem of LTL\u2013I is PSPACE-complete.\nProof. To verify membership it is sufficient to note that LTL\u2013I is a special instance of LTL built out of the finite set of atomic propositions {op(i, p) : i \u2208 N and p \u2208 I} \u222a {vis(i, p) : i \u2208 N and p \u2208 I} and interpreted over a subset of the set of all possible histories for this language. Since the model checking problem for LTL is in PSPACE [21], the model checking problem for LTL\u2013I should also be in PSPACE.\nTo check that model checking of LTL\u2013I is PSPACE-hard we are going to consider the following fragment of LLTL\u2013I:\n\u03d5 ::= vis(i, p) | \u00ac\u03d5 | \u03d51 \u2227 \u03d52 | X\u03d5 | \u03d51U\u03d52\nwhere i ranges over N and p ranges over I. It is straightforward to check that the set of histories H includes all possible interpretations for this language which is nothing but the LTL language built out of the finite set of atomic propositions {vis(i, p) : i \u2208 N and p \u2208 I}. Since the model checking for LTL is is known to be PSPACE-hard [21], it follows that the model checking for LTL\u2013I is PSPACE-hard too.\nWe can now state the following theorem about complexity of model checking for ELTL\u2013I.\nTheorem 1. The model checking problem of ELTL\u2013I is PSPACE-complete.\nProof. By Proposition 2 we know that model checking for LTL\u2013I is PSPACE-complete. Every formula of ELTL\u2013I can be reduced to an equivalent formula of polynomial size in LTL\u2013I by Lemma 8, showing membership in PSPACE of model checking for ELTL\u2013I. Since LTL\u2013I is a sublogic of ELTL\u2013I we also obtain PSPACE-hardness."}, {"heading": "4 Games of influence", "text": "We are now ready to put together all the definitions introduced in the previous sections and give the following definition:\nDefinition 12 (Influence game). An influence game is a tuple IG = (N , I, E, Fi, S0, \u03b31, . . . , \u03b3n) where N , I, E and S0 are, respectively, a set of agents, a set of issues, an influence network, and an initial state, Fi are aggregation procedures, one for each agent, and \u03b3i \u2208 LELTL\u2013I is agent i\u2019s goal."}, {"heading": "4.1 Strategies", "text": "The following definition introduces the concept of strategy. The standard definition would call for a function that assigns in each point in time an action to each player. We choose to study simpler state-based strategies:\nDefinition 13 (strategy). A strategy for player i is a function that associates an action to every information state, i.e., Qi : S \u2192 A such that Qi(S) = Qi(S\u2032) whenever S \u223ci S\u2032. A strategy profile is a tuple Q = (Q1, . . . ,Qn).\nFor notational convenience, we interchangeably use Q to denote a strategy profile (Q1, . . . ,Qn) and the function Q : S \u2212\u2192 J such that Q(S) = a if and only if Qi(S) = ai, for all S \u2208 S and i \u2208 N . As the following definition highlights, every strategy profile Q combined with an initial state S0 induces a history:\nDefinition 14 (Induced history). Let S0 be an initial state and let Q be a strategy profile. The history HS0,Q \u2208 H induced by them is defined as follows:\nH0(S0,Q) = S0\nHn+1(S0,Q) = succ(Sn,Q(Sn)) for all n \u2208 N"}, {"heading": "4.2 Solution concepts", "text": "We start with the concept of winning uniform strategy. Intuitively speaking, Qi is a winning uniform strategy for player i if and only if i knows that, by playing this strategy, she will achieve her goal no matter what the other players will decide to do.\nDefinition 15 (Winning strategy). Let IG be an influence game and let Qi be a strategy for player i. We say that Qi is a winning strategy for player i if and only if\nHS0,(Qi,Q\u2212i) |= \u03b3i (1)\nfor all profiles Q\u2212i of strategies of players other than i. A winning strategy is called uniform if (1) is true for all states S \u2208 S\u223ci0 .\nObserve that a winning strategy is not necessarily winning uniform, as the private state of an agent is not necessarily accessible to the other players.\nExample 9. Let Ann, Bob and Jesse be three agents. Let p be an issue, and suppose that BAnn(p) = 1, BBob(p) = 0, BJesse(p) = 0. Ann influences Bob and Jesse, while Bob influences Jesse as shown in the following picture:\nAnn\nBob\nJesse\nSuppose that the goal of Ann is FGop(Jesse, p). Her winning (uniform) strategy is reveal(p) in all states: Bob will be influenced to believe p in the second stage, and subsequently Jesse will also do so, since her influencers are unanimous (even if Bob plays hide(p)).\nAs we will show in the following section, the concept of winning strategy is too strong for our setting. Let us then define the less demanding notion of weak dominance:\nDefinition 16. Let IG be an influence game and let Qi be a strategy for player i. We say that Qi is a weakly dominant strategy for player i and initial state S0 if and only if for all profiles Q\u2212i of strategies of players other than i and for all strategies Q \u2032 i we have:\nHS0,(Q\u2032i,Q\u2212i) |= \u03b3i \u21d2 HS0,(Qi,Q\u2212i) |= \u03b3i (2)\nA weakly dominant strategy is called uniform if (2) is true for all initial states S \u2208 S i0 .\nExample 10. Let us go back to the previous example and suppose now that Ann still believes p, but does not influence Jesse any longer. In this case, Ann does not have a winning strategy: if neither Bob nor Jesse do not believe p, it is sufficient for Bob to play reveal(p) to make sure that she will never satisfy her goal. However, the strategy reveal(p) is a weakly dominant strategy for Ann.\nNow let us consider the following concept of best response. Intuitively speaking, Qi is a best response to Q\u2212i if and only if player i knows that the worst she could possibly get by playing Qi, when the others play Q\u2212i, is better or equal to the worst she could possibly get by playing a strategy different from Qi.\nDefinition 17 (Best response). Let IG be an influence game, let Qi \u2208 Qi and let Q\u2212i \u2208 Q\u2212i. We say that Qi is a best response to Q\u2212i wrt. initial state S0 if and only if for all Q \u2032i \u2208 Qi:\n(\u2200S \u2208 S\u223ci0 (HS,(Qi,Q\u2212i) |= \u03b3i) or\n(\u2203S, S\u2032 \u2208 S\u223ci0 HS,(Qi,Q\u2212i) 6|= \u03b3i and HS\u2032,(Q\u2032i,Q\u2212i) 6|= \u03b3i))\nIf we rephrase this definition through some utility notion, then we can consider a fictitious utility Ui(S) = 1 for states S that satisfy the goal of agent i, and Ui(S) = 0 for states where the goal is not satisfied. In that case, our definition of best response corresponds to minS\u2208S\u223ci\n0 Ui(HS,(Qi,Q\u2212i)) \u2265 minS\u2208S\u223ci0 Ui(HS,(Q \u2032 i ,Q \u2212i )). This defi-\nnition is justified on the basis of the prudential criterion according to which, if an agent does not have a probability distribution over the set of possible states, she should focus on the worst possible outcome and choose the action whose worst possible outcome is at least as good as the worst possible outcome of any other actions (see, e.g., [22, 3, 4]).\nDefinition 17 allow us to define the concept of Nash equilibrium for games with incomplete information such as influence games:\nDefinition 18 (Nash equilibrium). Let IG be an influence game and let Q be a strategy profile. Q is a Nash equilibrium if and only if, for all i \u2208 N , Qi is a best response to Q\u2212i."}, {"heading": "4.3 Influence network and solution concepts", "text": "In this section we show some preliminary results about the interplay between the network structure and the existence of solutions concepts. In what follows we only consider influence games where the aggregation function is the unanimous one (see Definition 8). In the interest of space, most proofs will only be sketched. Let us first give the following:\nDefinition 19. A goal \u03b3 is coherent with an initial state S0 in game IG if and only if there exists a strategy profile Q inducing history H such that HS0,Q |= \u03b3.\nClearly, if \u03b3i is not coherent with initial state S0, then all strategies for player i are equivalent. The following lemma shows that visibility goals cannot be enforced by means of a winning strategy:\nProposition 3. If \u03b3i entails one formula of the form vis(j, p), Kjop(i, p), or Xvis(j, p) for j 6= i, with belief and visibility atoms eventually negated, then i does not have a winning strategy.\nTo see this, consider that if an individual goal \u03b3i concerns the visibility of another agent about a given issue p, then this second agent can always respond hide(p) and make sure that \u03b3i is false.\nLet us now introduce a simpler language for goals, in order to study the limitations of considering winning strategies in this setting. Let LTL\u2013IJ be the language of future goals about a subset of agent J \u2286 N , which focuses on the future opinions of agents in J without considering the visibility. This language is defined by the following BNF:\n\u03b1 ::= op(j, p) | \u00acop(j, p) | \u03b1 \u2227 \u03b1 \u03d5 ::= X\u03b1 | X\u03d5 | G\u03d5 | F\u03d5\nwhere j \u2208 J and p ranges over I. Let us introduce some further notation. If i, j \u2208 N we say that i controls j if either Inf (j) = {j}, or for all paths l1, . . . , ln such that (li, li+1) \u2208 E, l1 = i and ln = j, we have that i controls each lk. We can now prove the following:\nProposition 4. If \u03b3i \u2208 LTL\u2013IJ then i has a winning strategy for all initial states S0 if and only if i controls j for all j \u2208 J .\nProof. One direction is easier: if i controls agent j, then her winning strategy is to always play reveal(p) in case her goal is consistent with her opinion, e.g. if her goal is op(j, p) and HBi,0(p) = 1. Otherwise always playing hide(p) guarantees that her goal will be satisfied. Note that the consistency of \u03b3i is crucial here.\nFor the other direction, consider a network in which j has more than one influencer, say k, which is however not controlled by i. A simple case study shows that there always exists an initial state in which i does not have a winning strategy. For instance, if \u03b3i = Xop(j, p), then in an initial state in which Bj(p) = 0 it is sufficient for agent k to play reveal(p) to make sure that agent j never updates her belief, and hence that \u03b3i will not be satisfied.\nProposition 4 shows that the concept of winning strategy is too strong in influence games, as it can only be applied in situations in which an agent has exclusive control over the opinion of another.\nLet us now focus on a particular influence game, in which the agents\u2019 goal is to reach a consensus about p. That is, each agent i adopts the following goal:\n\u03b3+i =def FX\n \u2227\nj 6=i\nop(j, p)   \u03b3\u2212i =def FX  \u2227\nj 6=i\n\u00acop(j, p)\n \nConsensus means that the conjunction of each individual goal leads to a state where all agents have p as opinion.\nTheorem 2. If all agent i has the goal of consensus represented by \u03b3+i (respectively \u03b3\u2212i ), and the network E is fully connected, then for any initial state S0 there always exists a Nash equilibrium Q\u0302 such that H\nS0,Q\u0302 |= \u2227 i\u2208N \u03b3 + i (respectively, \u03b3 \u2212 i ). Moreover,\neach strategy is weakly dominant.\nProof. Take an initial state S0 = (B,V ), and assume that all individuals have goal \u03b3+i . Consider the four possible states about p for agent i: either p is true or false, and p is visible or not. Assume Bi(p) = 1, then, regardless of visibility, we show that strategy reveal(p) is weakly dominant. For all S \u2208 S\u223ci0 , either HS,(reveal(p),Q\u2212i) |= \u2227 j 6=i op(j, p) or HS,(reveal(p),Q\u2212i) 6|= \u2227 j 6=i op(j, p); for that\nformer case, definition of unanimity entails that HS,(skip,Q\u2212i) 6|= \u2227\nj 6=i op(j, p) and HS,(hide(p),Q\u2212i) 6|= \u2227 j 6=i op(j, p). In a similar way, we can show that strategy hide(p) is a best response to any strategy Q\u2212i if Bi(p) = 0. We then built up a strategy profile Q\u0302 w.r.t. Bi: Qi = reveal(p) if Bi(p) = 1 otherwise Qi = hide(p), this strategy profile is a Nash equilibrium in weakly dominant strategies.\nObserve that if the network E is not fully connected this result does not hold since, for instance, the opinion of an isolated agent cannot be changed. Let us now focus on specific shapes of the influence graph where weakly dominant strategy exists. Those strategies concern the sources the agents who have no influencers. Theorem 3. If E is acyclic, I\u2217 is the set of sources, and S0 is coherent with \u2227\ni\u2217\u2208I\u2217 \u03b3i, and each source influences only one individual, then for all i\u2217 there exists a weakly dominant strategy. sketch. If \u2227\ni\u2217\u2208I\u2217 \u03b3i\u2217 is coherent with S0 then there exists some induced history H by some strategy Qc such that HS0,Qc |= \u2227 i\u2217\u2208I\u2217 \u03b3i\u2217 . Consider a source i\n\u2217 and its goal \u03b3i\u2217 . Subformulas of its goal refer to agents that it directly influences or not. In the latter case all the strategies of the source will be equivalent (hence weak-dominant). If they talk about the (only) individuals that is influenced by the source, then by the monotonicity of the aggregation procedure it is weakly dominant to play reveal(p) if the source goal is coherent with the source\u2019s belief. And hide(p) otherwise. (A case study is required to obtain the full proof).\nThis result, once more, shows the difficulty of playing an influence game. It is actually possible to exhibit examples of acyclic influence graphs with sources influencing multiple agents where no weakly dominant strategies exist for these sources."}, {"heading": "4.4 Computational complexity", "text": "In this section we exemplify the use of ELTL\u2013I and the complexity results presented in Section 3 for the computation of strategic aspects of influence games. We do so by providing a PSPACE algorithm to decide whether a strategy profile is a Nash equilibrium.\nLet MEMBERSHIP(F) be the following problem: given as input a set of individuals N , issues I, goals \u03b3i for i \u2208 N \u2013 which together with F form an influence game IG \u2013 and a strategy profile Q, we want to know whether Q is a Nash equilibrium of IG .\nThe algorithm presented in [14] in the setting of iterated boolean games cannot be directly applied to our setting for two reasons. First, our histories are generated by means of an aggregation function F that models the diffusion of opinions \u2013 i.e., agents have a concurrent control on a set of propositional variables. Second, not all conceivable strategies are available to players, as we focus on state-based strategies.\nWe therefore begin by translating a state-based strategy in ELTL\u2013I. Clearly, a conjunction of literals \u03b1(S) can be defined to uniquely identify a state S: \u03b1(S) will specify the private opinion of all individuals and their visibility function. Given action a, let\n\u03b2i(a) =    Xvis(i, p) if a = reveal(p) X\u00acvis(i, p) if a = hide(p)\n\u22a4 if a = skip\nWe can now associate a ELTL\u2013I formula to each strategy Qi:\n\u03c4i(Qi) =def \u2227\nS\u2208S\n\u03b1(S) \u2192 \u03b2i(Qi(S))\nIf Q is a strategy profile, let \u03c4(Q) = \u2227\ni\u2208N \u03c4i(Qi). We now need to encode the aggregation function into a formula as well. Recall the unanimous issue-by-issue aggregation function of Definition 8 and consider the following formulas unan(i, p):\nX op(i, p) \u2194 ([ \u2227\nj\u2208Inf (i)\nX\u00acvis(j, p) \u2227 op(i, p) ] \u2228\n[ \u2228\nj\u2208Inf (i)\nX vis(j, p) \u2227 \u2227\nj\u2208Inf (i)\n(X vis(j, p) \u2192 op(j, p)) ] \u2228\n[ \u2228\nj,z\u2208Inf (i):\n(X vis(j, p) \u2227 X vis(z, p)\u2227\nop(j, p) \u2227 \u00acop(j, p)) \u2227 op(i, p) ])\nas well as the following formula unan(i,\u00acp):\nX \u00acop(i, p) \u2194 ([ \u2227\nj\u2208Inf (i)\nX\u00acvis(j, p) \u2227 \u00acop(i, p) ] \u2228\n[ \u2228\nj\u2208Inf (i)\nX vis(j, p) \u2227 \u2227\nj\u2208Inf (i)\n(X vis(j, p) \u2192 \u00acop(j, p)) ] \u2228\n[ \u2228\nj,z\u2208Inf (i):\n(X vis(j, p) \u2227 X vis(z, p)\u2227\n\u00acop(j, p) \u2227 op(j, p)) \u2227 \u00acop(i, p) ])\nThis formula ensures that if the influencers of agent i are unanimous, then agent i\u2019s opinion should be defined according to the three cases described in Definition 8. Recall that, while actions take one time unit to be effectuated (hence the X operator in front of vis(j, p)), the diffusion of opinions is simultaneous. Let now:\n\u03c4(FUi ) =def \u2227\n{i\u2208N|Inf (i) 6=\u2205}\n\u2227\n{p\u2208I}\n(unan(i, p) \u2227 unan(i,\u00acp))\nThis formula encodes the transition process defined by the opinion diffusion. \u03c4(FUi ) is polynomial in both the number of individuals and the number of issues (in the worst case it is quadratic in n and linear in m). We are now ready to prove the following result:\nTheorem 4. MEMBERSHIP(FUi ) is in PSPACE.\nProof. Let Q be a strategy profile for game IG . The following algorithm can be used to check whether Q is a Nash equilibrium. For all individuals i \u2208 N , we first check the following entailment:\n\u03c4(Q) \u2227 \u03c4(Fi) |=LTL red(\u03b3i)\nin the language of LTL built out the set of atomic propositions {op(i, p) : i \u2208 N and p \u2208 I} \u222a {vis(i, p) : i \u2208 N and p \u2208 I}, where red(\u03b3i) is defined as in Algorithm 1 in Section 3.2.\nIf this is not the case, we consider all the possible strategies Q\u2032i 6= Qi for agent i \u2013 there are exponentially many, but each one can be specified in space polynomial in the size of the input \u2013 and check the following entailment:\n\u03c4(Q\u2212i, Qi) \u2227 \u03c4(Fi) |=LTL red(\u03b3i)\nIf the answer is positive we output NO, otherwise we proceed until all strategies and all individuals have been considered. The entailment for LTL can be reduced to the problem of checking validity in LTL. Indeed, the following equivalence holds:\n\u03c8 |=LTL \u03d5 iff |=LTL G\u03c8 \u2192 \u03d5\nSince the problem of checking validity in LTL can be solved in PSPACE [21], we obtain the desired upper bound.\nWe conjecture that the problem is also PSPACE-complete, as a reduction in line with the one by [14] is likely to be obtained.\nObserve that Theorem 4 can easily be generalised to all aggregation procedures that can be axiomatised by means of polynomially many ELTL\u2013I formulas \u2013 with the eventual use of Lemma 8 to translate ELTL\u2013I-formulas in LTL. This is not the case for all aggregation procedures: the majority rule \u2013 i.e., the rule that updates the opinion of an individual to copy that of the majority of its influencers \u2013 would for instance require an exponential number of formulas, one for each subset of influencers that forms a relative majority. The study of the axiomatisation of aggregation procedures for opinion diffusion constitutes a promising direction for future work."}, {"heading": "5 Conclusions and future work", "text": "In this paper we proposed a model, inspired from related work on iterated boolean games [14], that allows us to explore some basic aspects of strategic reasoning in social influence. We grounded our model on related work [18, 12], which modelled the process of social influence by means of aggregation procedures from either judgment aggregation or belief merging, and we augmented it with the introduction of a simple logical language for the expression of temporal and epistemic goals. This allowed us to inquire into the multiple aspects of the relation between the structure of the influence network, and the existence of well-known game-theoretic solution concepts. Moreover, we were able to show that model checking for our language, as well as the problem of checking whether a given profile is a Nash equilibrium, is in PSPACE, hence no harder than the linear temporal logic on which our language is based.\nThere are multiple directions in which this work can be expanded. First, the introduction of extra actions to add or sever trust links may add an important dynamic aspect to the network structure. Second, we may allow agents to lie about their private preferences, hence providing them with more strategies to attain their goals. Third, to develop our framework to its full generality we could introduce integrity constraints among the issues at hand. In all these cases, a deeper study of the interconnection between the network structure and the strategies played by the agents of extreme interest, and has the potential to unveil general insights about the problem of social influence."}], "references": [{"title": "Studies of independence and conformity: a minority of one against a unanimous majority", "author": ["S.E. Asch"], "venue": "Psychological Monographs, 70(9)", "citeRegEx": "1", "shortCiteRegEx": null, "year": 1956}, {"title": "Logical models of informational cascades", "author": ["A. Baltag", "Z. Christoff", "J. Hansen", "S. Smets"], "venue": "Studies in Logic, 47:405\u2013432", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2013}, {"title": "Toward a logic for qualitative decision theory", "author": ["C. Boutilier"], "venue": "Proceedings of the 4th International Conference on Principles of Knowledge Representation and Reasoning ", "citeRegEx": "3", "shortCiteRegEx": null, "year": 1994}, {"title": "An axiomatic treatment of three qualitative decision criteria", "author": ["R. Brafman", "M. Tennenholtz"], "venue": "Journal of the ACM, 47:452\u2013482", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2000}, {"title": "On complexity of lobbying in multiple referenda", "author": ["R. Christian", "M. Fellows", "F. Rosamond", "A. Slinko"], "venue": "Review of Economic Design, 11(3):217\u2013224", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2007}, {"title": "A logic for diffusion in social networks", "author": ["Z. Christoff", "J.U. Hansen"], "venue": "Journal of Applied Logic, 13(1):48 \u2013 77", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2015}, {"title": "Reflecting on social influence in networks", "author": ["Z. Christoff", "J.U. Hansen", "C. Proietti"], "venue": "Proceedings of the Information Dynamics in Artificial Societies Workshop ", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2014}, {"title": "Reasoning About Knowledge", "author": ["R. Fagin", "J. Halpern", "Y. Moses", "M. Vardi"], "venue": "MIT Press", "citeRegEx": "8", "shortCiteRegEx": null, "year": 1995}, {"title": "Informal social communication", "author": ["L. Festinger"], "venue": "Psychological Review, 57(5):271\u2013 282", "citeRegEx": "9", "shortCiteRegEx": null, "year": 1950}, {"title": "Agreeing to agree: Reaching unanimity via preference dynamics based on reliable agents", "author": ["S. Ghosh", "F.R. Vel\u00e1zquez-Quesada"], "venue": "Proceedings of the 14th International Joint Conference on Autonomous Agents and Multiagent Systems ", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2015}, {"title": "Binary aggregation with integrity constraints", "author": ["U. Grandi", "U. Endriss"], "venue": "Proceedings of the 22nd International Joint Conference on Artificial Intelligence ", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2011}, {"title": "Propositional opinion diffusion", "author": ["U. Grandi", "E. Lorini", "L. Perrussel"], "venue": "Proceedings of the 14th International Joint Conference on Autonomous Agents and Multiagent Systems ", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2015}, {"title": "Threshold models of collective behavior", "author": ["M. Granovetter"], "venue": "American Journal of Sociology, 83(6):1420\u20131443", "citeRegEx": "13", "shortCiteRegEx": null, "year": 1978}, {"title": "Iterated boolean games", "author": ["J. Gutierrez", "P. Harrenstein", "M. Wooldridge"], "venue": "Information and Computation, 242:53\u201379", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2015}, {"title": "Studies in social influence", "author": ["S. Moscovici", "B. Personnaz"], "venue": "Journal of Experimental Social Psychology, 16:270\u2013282", "citeRegEx": "15", "shortCiteRegEx": null, "year": 1980}, {"title": "A logic for knowledge flow in social networks", "author": ["J. Ruan", "M. Thielscher"], "venue": "24th Australasian AI Joint Conference", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2011}, {"title": "Micromotives and macrobehavior", "author": ["T. Schelling"], "venue": "Norton", "citeRegEx": "17", "shortCiteRegEx": null, "year": 1978}, {"title": "Belief revision games", "author": ["N. Schwind", "K. Inoue", "G. Bourgne", "S. Konieczny", "P. Marquis"], "venue": "Proceedings of the Twenty-Ninth AAAI Conference on Artificial Intelligence ", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2015}, {"title": "Facebook and the epistemic logic of friendship", "author": ["J. Seligman", "F. Liu", "P. Girard"], "venue": "Proceedings of the 14th Conference on Theoretical Aspects of Rationality and Knowledge ", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2013}, {"title": "Boolean network games and iterated boolean games", "author": ["J. Seligman", "D. Thompson"], "venue": "Proceedings of the 5th International Workshop on Logic, Rationality and Interaction ", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2015}, {"title": "The complexity of propositional linear temporal logics", "author": ["A.P. Sistla", "E.M. Clarke"], "venue": "Journal of the Association of Computing Machinery, 32(3):733\u2013749", "citeRegEx": "21", "shortCiteRegEx": null, "year": 1985}, {"title": "Statistical Decision Functions", "author": ["A. Wald"], "venue": "Wiley", "citeRegEx": "22", "shortCiteRegEx": null, "year": 1950}], "referenceMentions": [{"referenceID": 0, "context": ", [1, 9, 15]).", "startOffset": 2, "endOffset": 12}, {"referenceID": 8, "context": ", [1, 9, 15]).", "startOffset": 2, "endOffset": 12}, {"referenceID": 14, "context": ", [1, 9, 15]).", "startOffset": 2, "endOffset": 12}, {"referenceID": 17, "context": "Recent work in multi-agent systems [18, 12] proposed a formal model of opinion diffusion that combined methods and techniques from social network analysis with methods and techniques from belief merging and judgment aggregation.", "startOffset": 35, "endOffset": 43}, {"referenceID": 11, "context": "Recent work in multi-agent systems [18, 12] proposed a formal model of opinion diffusion that combined methods and techniques from social network analysis with methods and techniques from belief merging and judgment aggregation.", "startOffset": 35, "endOffset": 43}, {"referenceID": 13, "context": "Following the representation of agents\u2019 motivations given in [14], in a game of influence each agent is identified with the goal that she wants to achieve.", "startOffset": 61, "endOffset": 65}, {"referenceID": 11, "context": "Apart from the above mentioned work on opinion diffusion via judgment aggregation [12] and belief merging [18], there is a vast interest in providing formal models of social influence.", "startOffset": 82, "endOffset": 86}, {"referenceID": 17, "context": "Apart from the above mentioned work on opinion diffusion via judgment aggregation [12] and belief merging [18], there is a vast interest in providing formal models of social influence.", "startOffset": 106, "endOffset": 110}, {"referenceID": 9, "context": "Quesada [10], which does not however consider strategic aspects in their preference update model.", "startOffset": 8, "endOffset": 12}, {"referenceID": 18, "context": "[19] is also relevant, and motivated our effort in Section 4 to get rid of epistemic operators in the goal language.", "startOffset": 0, "endOffset": 4}, {"referenceID": 5, "context": "The difference between private and public information is reminiscent of the work of Christoff and Hansen [6, 7], which also does not focus on strategic aspects.", "startOffset": 105, "endOffset": 111}, {"referenceID": 6, "context": "The difference between private and public information is reminiscent of the work of Christoff and Hansen [6, 7], which also does not focus on strategic aspects.", "startOffset": 105, "endOffset": 111}, {"referenceID": 15, "context": "A related problem to opinion diffusion is that of information cascades and knowledge diffusion, which has been given formal treatment in a logical settings [16, 2].", "startOffset": 156, "endOffset": 163}, {"referenceID": 1, "context": "A related problem to opinion diffusion is that of information cascades and knowledge diffusion, which has been given formal treatment in a logical settings [16, 2].", "startOffset": 156, "endOffset": 163}, {"referenceID": 13, "context": "Finally, our work is greatly indebted to the work of [14], since an influence game can be considered as a variation of an iterated boolean game in which individuals do not have direct power on all the variables \u2013 there can be several individuals influencing another one \u2013 but concurrently participate in its change.", "startOffset": 53, "endOffset": 57}, {"referenceID": 19, "context": "Finally, [20] recently presented an extension of iterated boolean games with a social network structure in which agents choose actions depending on the actions of those in their neighbourhood.", "startOffset": 9, "endOffset": 13}, {"referenceID": 11, "context": "We generalise the model of propositional opinion diffusion introduced in related work [12] by separating private and public opinions, and adapting the notion of diffusion through aggregation to this more complex setting.", "startOffset": 86, "endOffset": 90}, {"referenceID": 4, "context": ", [5, 11]).", "startOffset": 2, "endOffset": 9}, {"referenceID": 10, "context": ", [5, 11]).", "startOffset": 2, "endOffset": 9}, {"referenceID": 7, "context": ", [8]).", "startOffset": 2, "endOffset": 5}, {"referenceID": 11, "context": "Our definition is a generalisation of the model by [12].", "startOffset": 51, "endOffset": 55}, {"referenceID": 12, "context": "These aggregation procedures give rise to the class of threshold models studied in the literature on opinion diffusion [13, 17].", "startOffset": 119, "endOffset": 127}, {"referenceID": 16, "context": "These aggregation procedures give rise to the class of threshold models studied in the literature on opinion diffusion [13, 17].", "startOffset": 119, "endOffset": 127}, {"referenceID": 13, "context": "Following [14], we define a language to express individual epistemic goals about the state of the individual opinions.", "startOffset": 10, "endOffset": 14}, {"referenceID": 7, "context": "Recall that epistemic temporal logic has very high complexity [8].", "startOffset": 62, "endOffset": 65}, {"referenceID": 20, "context": "Since the model checking problem for LTL is in PSPACE [21], the model checking problem for LTL\u2013I should also be in PSPACE.", "startOffset": 54, "endOffset": 58}, {"referenceID": 20, "context": "Since the model checking for LTL is is known to be PSPACE-hard [21], it follows that the model checking for LTL\u2013I is PSPACE-hard too.", "startOffset": 63, "endOffset": 67}, {"referenceID": 21, "context": ", [22, 3, 4]).", "startOffset": 2, "endOffset": 12}, {"referenceID": 2, "context": ", [22, 3, 4]).", "startOffset": 2, "endOffset": 12}, {"referenceID": 3, "context": ", [22, 3, 4]).", "startOffset": 2, "endOffset": 12}, {"referenceID": 13, "context": "The algorithm presented in [14] in the setting of iterated boolean games cannot be directly applied to our setting for two reasons.", "startOffset": 27, "endOffset": 31}, {"referenceID": 20, "context": "\u03c8 |=LTL \u03c6 iff |=LTL G\u03c8 \u2192 \u03c6 Since the problem of checking validity in LTL can be solved in PSPACE [21], we obtain the desired upper bound.", "startOffset": 97, "endOffset": 101}, {"referenceID": 13, "context": "We conjecture that the problem is also PSPACE-complete, as a reduction in line with the one by [14] is likely to be obtained.", "startOffset": 95, "endOffset": 99}, {"referenceID": 13, "context": "In this paper we proposed a model, inspired from related work on iterated boolean games [14], that allows us to explore some basic aspects of strategic reasoning in social influence.", "startOffset": 88, "endOffset": 92}, {"referenceID": 17, "context": "We grounded our model on related work [18, 12], which modelled the process of social influence by means of aggregation procedures from either judgment aggregation or belief merging, and we augmented it with the introduction of a simple logical language for the expression of temporal and epistemic goals.", "startOffset": 38, "endOffset": 46}, {"referenceID": 11, "context": "We grounded our model on related work [18, 12], which modelled the process of social influence by means of aggregation procedures from either judgment aggregation or belief merging, and we augmented it with the introduction of a simple logical language for the expression of temporal and epistemic goals.", "startOffset": 38, "endOffset": 46}], "year": 2016, "abstractText": "We study the strategic aspects of social influence in a society of agents linked by a trust network, introducing a new class of games called games of influence. A game of influence is an infinite repeated game with incomplete information in which, at each stage of interaction, an agent can make her opinions visible (public) or invisible (private) in order to influence other agents\u2019 opinions. The influence process is mediated by a trust network, as we assume that the opinion of a given agent is only affected by the opinions of those agents that she considers trustworthy (i.e., the agents in the trust network that are directly linked to her). Each agent is endowed with a goal, expressed in a suitable temporal language inspired from linear temporal logic (LTL). We show that games of influence provide a simple abstraction to explore the effects of the trust network structure on the agents\u2019 behaviour, by considering solution concepts from game-theory such as Nash equilibrium, weak dominance and winning strategies.", "creator": "LaTeX with hyperref package"}}}