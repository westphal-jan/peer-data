{"id": "1602.03291", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "10-Feb-2016", "title": "Feature Based Task Recommendation in Crowdsourcing with Implicit Observations", "abstract": "Existing research in crowdsourcing has investigated how to recommend tasks to workers based on which task the workers have already completed, referred to as {\\em implicit feedback}. We, on the other hand, investigate the task recommendation problem, where we leverage both implicit feedback and explicit features of the task. We assume that we are given a set of workers, a set of tasks, interactions (such as the number of times a worker has completed a particular task), and the presence of explicit features of each task (such as, task location). We intend to recommend tasks to the workers by exploiting the implicit interactions, and the presence or absence of explicit features in the tasks. We formalize the problem as an optimization problem, propose two alternative problem formulations and respective solutions that exploit implicit feedback, explicit features, as well as similarity between the tasks. We compare the efficacy of our proposed solutions against multiple state-of-the-art techniques using two large scale real world datasets.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "histories": [["v1", "Wed, 10 Feb 2016 08:06:32 GMT  (178kb,D)", "https://arxiv.org/abs/1602.03291v1", null], ["v2", "Wed, 7 Sep 2016 05:13:51 GMT  (690kb,D)", "http://arxiv.org/abs/1602.03291v2", null]], "reviews": [], "SUBJECTS": "cs.AI cs.HC", "authors": ["habibur rahman", "lucas joppa", "senjuti basu roy"], "accepted": false, "id": "1602.03291"}, "pdf": {"name": "1602.03291.pdf", "metadata": {"source": "CRF", "title": "Feature Based Task Recommendation in Crowdsourcing with Implicit Observations", "authors": ["Habibur Rahman", "Lucas Joppa", "Senjuti Basu Roy"], "emails": ["habibur.rahman@mavs.uta.edu", "ljoppa@microsoft.com", "senjutib@njit.edu"], "sections": [{"heading": "Introduction", "text": "Crowdsourcing platforms, such as Amazon\u2019s Mechanical Turk or Crowdflower, have recently gained immense popularity due to their elegant framework, where a task requester can get work done by numerous virtual workers for very low compensation. One common problem in these platforms is that workers have to suffer huge latency to find suitable tasks, which creates dissatisfaction and eventually leads to the abandonment of the platform. Task recommendation problems are studied in the crowdsourcing context, where the objective is to recommend a set of tasks to each worker such that these tasks are best suited for the workers (Geiger and others 2014; Yuen and others 2012). In this work, we aim at leveraging the task completion history of the workers (referred to as implicit feedback) and augment that with explicit task characteristics or features to recommend tasks to the workers. Our focus of investigation is limited to citizen science crowdsourcing applications where the importance of effective task recommendation is pivotal (Xue and others 2013). We focus on the crowdsourcing of biodiversity observations, where volunteer visit sites, observe species, and report their findings via web applications. Currently, a volunteer, upon identifying a species, uploads information into the server specifying the details of the identification. A common problem which frequently occurs in this scenario is incorrect identification. A reliable task recommender system\nCopyright c\u00a9 2016, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.\ncan alleviate the problem. If we have historical data on how many tasks a volunteer has successfully performed and those observations are on what species and from which locations, then we can lower the risk in incorrect identification by asking volunteers to identify species they have prior experience with."}, {"heading": "Methodologies", "text": "Notations: W = \u3008w1, w2, w3 . . . wnw\u3009 and T = \u3008t1, t2, t3, . . . tnt\u3009 represents the set of workers and tasks respectively. The relationship between workers and tasks is represented by matrix Cnw\u00d7nt , where cwi represents the number of times worker w has completed task i. The preference matrix P is a boolean version of C, such that pwi = 1, if cwi \u2265 1, otherwise pwi = 0. Ynt\u00d7nl represents the explicit task feature matrix, where yil \u2208 {0, 1} denotes the absence or presence of feature l for task i. Worker feature preference matrix is denoted as Xnw\u00d7nl . Additionally, Unw\u00d7nf and Vnt\u00d7nf are the two latent factor matrices, where U is for the workers and V is for the tasks.\nFormulation 1 - Feature Preference Model: We assume that the reason that a particular worker has completed a particular task is because the worker has a hidden preference over the task features which we want to uncover. As an example, if locations are used as task features, we can learn the preference of workers for different location, which can be used for recommend new task to workers. Based on the explicit knowledge of task feature matrix Y and worker task completion matrix we learn the preference of each worker in the feature space or X . Formally, we want to minimize the following objective function.\nM = \u2211 w,i qwi(pwi \u2212 xwyi)2 + \u03bb(\u2016X\u20162) (1)\nX \u2265 0 (2) qwi = 1 + \u03b1\u00d7 cwi (3)\nHere, qwi is designed such that, the weight of positive signals is amplified. Q denotes the matrix representing the values of qwi for all workers and tasks. If a particular observation has high confidence the system will choose xw such that xwyi becomes close to 1. \u03b1 is set to a positive value indicating the confidence for the positive signals over negative signals. By solving M , we get the solution for user\nar X\niv :1\n60 2.\n03 29\n1v 2\n[ cs\n.A I]\n7 S\nep 2\n01 6\nvector, xw = (Y tQwY + \u03bbI)\u22121Y tQwPw. Due to the nonnegativity constratint ofX , we solve the following optimization problem as \u2016(Y tQwY +\u03bbI)xw\u2212Y tQwPw\u20162. We refer to our algorithm as Feat-Based-NNLS or Feature Based Non-Negative-Least Square.\nFormulation 2: Latent Factor Model: We consider the following objective function for task recommendation -\n(4)\nM = \u2211 w,i qwi(pwi \u2212 uwvi)2\n+ \u03bb(\u2016U\u20162 + \u2016V \u20162 \u2212 \u2211 i,i\u2032 vtiv \u2032 iSim(i, i \u2032))\nHere, the goal is to find U and V such that it minimizes the error, where \u03bb is the regularization parameter. For any new task, the predicted recommendation score is calculated by multiplying Uw with Vi. To incorporate the task similarity into the latent factor based formulation, we add a penalty term in the equation. Our intuition is that if the similarity between any two tasks is high, then they should also be similar in the latent factor space. Our notion of task similarity is defined as sim(ti, tj) = 1\n1+e\u2212Y t i Yj . The analytical solution for U and V is given below.\nuw = (V tQuV + \u03bbI)\u22121V tQwPw (5)\nvi = (U tQiU + \u03bbI)\u22121(U tQiPi + \u03bb \u2217 0.5 \u2217 nt\u2211 i\u2032=1 Sim(i, i\u2032)v\u2032i)\n(6)\nWe solve the optimization problem by alternating and fixing U and V . This method is referred to as Implicit Factorization with Task Similarity or IFTS."}, {"heading": "Experiments", "text": "Dataset: We collected data from a popular citizen science platform named Ebird 1. Ebird is a popular citizen science platform for bird observations. We crawled all the observations from year 2012 and randomly choose a set of 5000 workers for our experiments leading to 1767 tasks with a total number of 2.5 million observations. We used 294 locations as task features.Evaluation: We evaluate our methods using a hold out test set. We randomly choose 90% of our data as the training set and remaining 10% as the test set which gives us the ground truth. All the results are an average of three runs.\nImplemented Baseline Algorithms: i)Implicit-ALS-Neg: This algorithm is implemented according to (Lin and others 2014).The algorithm uses alternating least square method considering negative signals. If a worker has not completed a task then the total number of times that task has been completed by other users is considered as the weight of the negative signal. ii) Feature-Based-Reg: We assume that the task-feature matrix V is given to us. We solve the regularized regression (Wu and others 2006) problem (Cij \u2212xiyj)2+\u03bb\u2016X\u20162 to find X .\n1Ebird.org\n0\n0.1\n0.2\n0.3\n0 0.2 0.4 0.6 0.8 1\nPr ec is io n\nRecall\nFeature-Based-NNLS\nFeature-Based-Regression\nImplicit-ALS-Negative\nIFTS\nFigure 1: PR Curve\nAlgorithm MPR Impl-ALS-Neg 17.3 Feat-Based-Reg 13.706 Feat-Based-NNLS 5.68 IFTS 6.87\nTable 1: MPR\nEvaluation Metrics: We use Mean Percentile Ranking(MPR) proposed by (Hu and others 2008) for evaluating implicit feedback. The mathematical formula to calculate MPR is \u2211 ij cij\u03c1ij\u2211\nij cij . \u03c1ij is the percentile ranking of\nthe task j for worker i. Our recommendation is based on the estimated Worker-Task Preference matrix, P\u0302 . For Feat-Based-NNLS, P\u0302 = XY , where X is WorkerFeature matrix and Y is Task-Feature matrix. For IFTS, P\u0302 = UV . We experimented with different values of \u03b1 and choose \u03b1 = 50. We also use Precision Recall curve as our second evaluation method. In this method, we want to evaluate our method based on how many task in the test set we can correctly predict by taking only (t%) of the top-tasks. We vary t (in an increment of 1%) in a continuous manner and obtain PR curve.\nSummary of Results: The objective of our empirical study is to see how effective our proposed task recommendation models are in comparison with the baseline models. Our proposed algorithm Feature-Based-NNLS convincingly outperforms the baseline algorithms in both MPR and PR-Curve. The reason behind the worse performance of Implicit-ALS-Negative is that the worker does not choose tasks from a list of available task list, so a task that hasn\u2019t been attempted by the user really has no preference rather than \u201cnegative preference\u201d. IFTS also performs reasonably well compare to other methods."}, {"heading": "Related Work", "text": "Task recommendation with explicit observation is studied in (Yuen and others 2012). We are the first to treat workertask completion history as implicit observations and incorporate task feature information for recommendation. Works in recommender systems such as (Forbes and Zhu 2011; Nguyen and Zhu 2013; Koren 2008) mostly rely on explicit feedback or content based feedback, whereas our model relies on implicit feedback. This precludes direct adaptation of their techniques."}, {"heading": "Conclusion and Future Work", "text": "We initiate the study of the task recommendation problem in citizen science based crowdsourcing applications, considering both implicit feedback and explicit features. We formalize two optimization problems and present preliminary results. As ongoing research, we are investigating our method\u2019s validity on other datasets, as well as the generality of our proposed solution outside citizen science applications."}], "references": [{"title": "Content-boosted matrix factorization for recommender systems: experiments with recipe recommendation", "author": ["Forbes", "P. Zhu 2011] Forbes", "M. Zhu"], "venue": "In Proceedings of the fifth ACM conference on Recommender systems,", "citeRegEx": "Forbes et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Forbes et al\\.", "year": 2011}, {"title": "Personalized task recommendation in crowdsourcing information systemscurrent state of the art", "author": ["D Geiger"], "venue": "Decision Support Systems", "citeRegEx": "Geiger,? \\Q2014\\E", "shortCiteRegEx": "Geiger", "year": 2014}, {"title": "Collaborative filtering for implicit feedback datasets", "author": ["Y Hu"], "venue": "In ICDM", "citeRegEx": "Hu,? \\Q2008\\E", "shortCiteRegEx": "Hu", "year": 2008}, {"title": "Signals in the silence: Models of implicit feedback in a recommendation system for crowdsourcing", "author": ["Lin", "C. H"], "venue": null, "citeRegEx": "Lin and H,? \\Q2014\\E", "shortCiteRegEx": "Lin and H", "year": 2014}, {"title": "Content-boosted matrix factorization techniques for recommender systems. Statistical Analysis and Data Mining: The ASA Data Science Journal 6(4):286\u2013301", "author": ["Nguyen", "J. Zhu 2013] Nguyen", "M. Zhu"], "venue": null, "citeRegEx": "Nguyen et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Nguyen et al\\.", "year": 2013}, {"title": "Learning rates of least-square regularized regression", "author": ["Wu", "Q others 2006] Wu"], "venue": "Foundations of Computational Mathematics", "citeRegEx": "Wu and Wu,? \\Q2006\\E", "shortCiteRegEx": "Wu and Wu", "year": 2006}, {"title": "Improving your chances: Boosting citizen science discovery", "author": ["Xue", "Y others 2013] Xue"], "venue": "In First AAAI Conference on Human Computation and Crowdsourcing", "citeRegEx": "Xue and Xue,? \\Q2013\\E", "shortCiteRegEx": "Xue and Xue", "year": 2013}, {"title": "Taskrec: probabilistic matrix factorization in task recommendation in crowdsourcing systems", "author": ["Yuen", "others 2012] Yuen", "M.-C"], "venue": "In Neural Information Processing", "citeRegEx": "Yuen et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Yuen et al\\.", "year": 2012}], "referenceMentions": [], "year": 2016, "abstractText": "We initiate the study of task recommendation problem for citizen science crowdsourcing platforms, where we leverage both implicit feedback and explicit features of the tasks. We assume that we are given a set of workers, a set of tasks, interactions (such as the number of times a worker has completed a particular task), and the presence of explicit features of each task (such as, task location). We intend to recommend tasks to the workers by exploiting implicit interactions, and the presence or absence of explicit features in the tasks. We present two alternative optimization problems,and propose respective solutions. We compare our solutions against multiple state-of-the-art techniques using a real world large citizen science dataset.", "creator": "LaTeX with hyperref package"}}}