{"id": "1602.06818", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "22-Feb-2016", "title": "Graph Regularized Low Rank Representation for Aerosol Optical Depth Retrieval", "abstract": "In this paper, we propose a novel data-driven regression model for aerosol optical depth (AOD) retrieval. First, we adopt a low rank representation (LRR) model to learn a powerful representation of the spectral response. Then, graph regularization is incorporated into the LRR model to capture the local structure information and the nonlinear property of the remote-sensing data collection. Second, we study the correlation between the observed response and the observed response, and provide a model for the relative stability of the spectral response and a model for the local distribution of the spectral response.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "histories": [["v1", "Mon, 22 Feb 2016 15:31:19 GMT  (2785kb)", "https://arxiv.org/abs/1602.06818v1", "16 pages, 6 figures"], ["v2", "Mon, 7 Mar 2016 16:03:39 GMT  (2283kb)", "http://arxiv.org/abs/1602.06818v2", "16 pages, 6 figures"]], "COMMENTS": "16 pages, 6 figures", "reviews": [], "SUBJECTS": "cs.LG", "authors": ["yubao sun", "renlong hang", "qingshan liu", "fuping zhu", "hucheng pei"], "accepted": false, "id": "1602.06818"}, "pdf": {"name": "1602.06818.pdf", "metadata": {"source": "CRF", "title": "Graph Regularized Low Rank Representation for Aerosol Optical Depth Retrieval", "authors": ["Yubao Sun", "Renlong Hang", "Qingshan Liu", "Fuping Zhu", "Hucheng Pei"], "emails": ["sunyb@nuist.edu.cn;", "hang@163.com;", "qsliu@nuist.edu.cn)."], "sections": [{"heading": null, "text": "ar X\niv :1\n60 2.\n06 81\n8v 2\n[ cs\n.L G\n] 7\nM ar\n2 01\n6 1\nIn this paper, we propose a novel data-driven regression model for aerosol optical depth (AOD) retrieval. First, we adopt a low rank representation (LRR) model to learn a powerful representation of the spectral response. Then, graph regularization is incorporated into the LRR model to capture the local structure information and the nonlinear property of the remote-sensing data. Since it is easy to acquire the rich satellite-retrieval results, we use them as a baseline to construct the graph. Finally, the learned feature representation is feeded into support vector machine (SVM) to retrieve AOD. Experiments are conducted on two widely used data sets acquired by different sensors, and the experimental results show that the proposed method can achieve superior performance compared to the physical models and other state-of-the-art empirical models.\nKeywords\nAerosol optical depth (AOD), physical model, empirical model, low rank representation (LRR), graph regular-\nization, support vector machine (SVM).\nI. INTRODUCTION\nAerosols are small solid and liquid particles suspended in the atmosphere. They can scatter and absorb solar radiance, and modify microphysical and radiative properties of cloud [1]. An important metric of aerosols\u2019 concentration in the atmosphere is aerosol optical depth (AOD), which measures the amount of depletion that a beam of solar radiation undergoes as it passes through the atmosphere. AOD has become a major atmospheric data product derived from various earth observation satellites, such as the Moderate Resolution Imaging Spectroradiometer (MODIS) [2], the Multiangle Imaging Spectro-Radiometer (MISR)\nY. Sun, R. Hang and Q. Liu are with the Jiangsu Key Laboratory of Big Data Analysis Technology, the School of Information and Control, Nanjing University of Information Science and Technology, Nanjing 210044, China (e-mail: sunyb@nuist.edu.cn; renlong hang@163.com; qsliu@nuist.edu.cn).\nF. Zhu and H. Pei are with Beijing Electro-Mechanical Engineering Institute, Beijing 100083, China. Corresponding author: Qingshan Liu\n2 [3], etc. These remote sensing satellites obtain geolocated and calibrated radiances, and then retrieval algorithms are used to derive the corresponding AOD values.\nMost of the current operating satellite-retrieval algorithms are based on physical models [4][5][6]. These models need to take into account numerous physical variables affecting the radiometric characteristics of remote sensing data, such as atmospheric conditions, solar azimuth and zenith angles, sensor azimuth and zenith angles, etc. Complex mathematical formulations are set up to represent the relationships between these variables according to radiation transfer equation. To simplify the radiative transfer calculations, a lookup table (LUT) is used to simulate the radiative properties of the atmosphere calculated for expected aerosol types at particular wavelengths, angles and aerosol loading. Spectral reflectance from the LUT is then compared with the satellite-observation value to find the best match, and the corresponding AOT is the final retrieval result. However, due to the complex Earth-atmosphere interaction, it is difficult to consider all related physical variables and to accurately formulate their relationships. Besides, searching LUT is very time consuming.\nAn efficient alternative is empirical models [7][8]. These models can be considered as data-driven regression approaches. First, using the collocated satellite and ground-based observations to train a regression model. Then, the trained model is used to predict AOD for satellite observations without ground-truth. Among these models, neural networks (NN) [8][9] and support vector machines (SVMs) [7][10] are two popular methods, because they can approximate the complex non-linear relationships between satellite-based observations and ground-based observations. In contrast to physical models, empirical models don\u2019t make a prior assumptions on variable relations or rigid functional forms, they directly rely on the available data. In addition, they are computationally less expensive, flexible to different retrieval scenarios and more accurate than the physical models, if sufficient amounts of training data are available. However, in previous works, most empirical models directly exploit a part of or the whole spectral values as features. Since remotesensing data often suffer from various annoying degradations, e.g., noise contamination, stripe corruption, and missing data, due to the sensor, photon effects, and calibration error [11][12], directly using such\n3 corrupted data without any preprocessing may degrade the performance of empirical models.\nIn this paper, we propose a graph regularized low rank representation model to address the above issues. Low rank representation (LRR), which was successfully employed in natural image denoising [13][14], has shown its potential in remote-sensing data analysis [15]. By stacking the remote-sensing data into a 2-D matrix, it should be low rank due to the high correlations of the spectral information. Moreover, as discussed in [16], the rank of the matrix constructed by remote-sensing data is bounded by the small number of pure spectral endmembers. We therefore propose to employ LRR to learn a new feature representation for the remote-sensing data. Besides, due to the effects of multipath scattering, variations in sun-canopy-sensor geometry, nonhomogeneous composition of pixels, and attenuating properties of media, remote-sensing data are often nonlinearly distributed [17]. To preserve such nonlinear structure, motivated by [18][19][20], graph regularization is incorporated into the LRR model. Nowadays, it is easy to acquire the rich satellite-retrieval results based on physical models. Many researchers attempted to employ such information as features for regression models [7][9][21]. Different from them, we use the satellite-retrieval results as a baseline to construct the graph. This prior information can make the proposed model combine the merits of physical models and regression models to some extent.\nThe rest of this paper is outlined as follows. Section II introduces the proposed method in detail. Section\nIII presents the data sets used and the experimental results, followed by the conclusion in Section IV.\nII. METHODOLOGY"}, {"heading": "A. Representation model", "text": "Assume the remote-sensing data can be represented as a two-dimensional matrix X = [x1, \u00b7 \u00b7 \u00b7 ,xi, \u00b7 \u00b7 \u00b7 ,xn] \u2208\nRd\u00d7n by stacking the pixels in the original d\u2212dimensional spectral feature space as the columns. Since the remote-sensing data are often corrupted by noise in the acquisition process, X can be written as X = X0+E, where X0 \u2208 Rd\u00d7n is the ideal clean data, E \u2208 Rd\u00d7n is the noise or outlier. Each pixel of X0 can be represented by a linear combination of the bases in a \u2018dictionary\u2019 A = [a1, a2, \u00b7 \u00b7 \u00b7 , am] \u2208 Rd\u00d7m.\n4\nSo we have X = AZ + E, where Z = [z1, \u00b7 \u00b7 \u00b7 , zi, \u00b7 \u00b7 \u00b7 , zn] \u2208 Rm\u00d7n is the coefficient matrix and each zi corresponds to the new characterization of xi. The dictionary is often overcomplete, and the clean remotesensing data often lie in a low rank feature space [16]. Thus, we can use an alternative scheme of A = X as in [13][22], and the purpose becomes to search for the lowest rank solution of Z by\nmin Z,E \u2016Z\u2016\u2217 + \u03bb\u2016E\u20162,1,\ns.t. X = XZ+ E,\n(1)\nwhere \u2016 \u00b7 \u2016\u2217 denotes the nuclear norm of a matrix, and E represents the sparse noise, which is measured by l2,1 norm, i.e., \u2016E\u20162,1 = \u2211n\nj=1\n\u221a\n\u2211d\ni=1(Eij) 2 as in [14]. \u03bb > 0 is a balance parameter. This is a popular\nLRR model. It was demonstrated that LRR is capable of capturing the global structure of the data as well as robust to noise [22].\nHowever, as discussed in [23], nonlinearities often exist in remote-sensing data due to the effects of many factors. Taking MISR remote-sensing data as an example in Fig. 1. Fig. 1(a) shows a three-dimensional map by choosing three spectral bands in MISR. Obviously, this data is nonlinear distribution, which can also be demonstrated from its two-dimensional map. Recently, nonlinear manifold learning has been proved\n5 to be a successful method to capture such nonlinearity [24][25]. Inspired by the idea, we propose a graph regularization based LRR model to preserve the local neighboring relations among the data. Thus, the objective function in Eq. (1) can be reformulated as\nmin Z,E\n\u2016Z\u2016\u2217 + \u03bb\u2016E\u20162,1 + \u03b2\n2 tr(ZLZ\u22a4),\ns.t. X = XZ+ E.\n(2)\nThe term of Tr(ZLZ\u22a4) is the graph regularization term, which is derived as follows:\nmin Z\nn \u2211\ni=1\nn \u2211\nj=1\n\u2016zi \u2212 zj\u2016 2wij\n= min Z\nTr(Z(D\u2212W)Z\u22a4),\n=min Z\nTr(ZLZ\u22a4),\n(3)\nwhere W is an affinity matrix, D is a diagonal matrix whose elements equal to the sum of rows or columns of W, i.e., Dii = \u2211n j=1wij , and L = D\u2212W is the graph Laplacian matrix.\nAn intuitive motivation behind Eq. (3) is that if two pixels are close, their new representations are also close to each other [26]. As we all know, it is easy to acquire the rich satellite-retrieval results, we therefore use them as a baseline to construct the graph. Assume that the satellite-retrieval results of two pixels xi and xj are yi and yj , respectively, each element wij of W can be calculated as\nwij =\n       e\u2212 (yi\u2212yj) 2 2\u03c32 , if yi \u2208 Nk(yj) or yj \u2208 Nk(yi), 0, otherwise, (4)\nwhere Nk(yj) denotes the set of k-nearest neighbors of yj , and \u03c3 refers to the parameter of the Heat kernel. This weight setting promotes our model to be consistent with the satellite-retrieval results, which can inherit the merits of both physical model and regression model.\n6"}, {"heading": "B. Optimization algorithm", "text": "The objective function Eq. (2) of the graph regularized LRR is non-convex, thus jointly optimizing Z and E is extremely difficult. As in [27][28], we adopt the linearized Alternating Direction Method of Multipliers (ADMM) algorithm to optimize it. We first convert (2) to the following equivalent problem:\nmin Z,E,J\n\u2016J\u2016\u2217 + \u03bb\u2016E\u20162,1 + \u03b2\n2 tr(ZLZ\u22a4),\ns.t. X = XZ+ E, Z = J,\n(5)\nwhich can be changed to the Augmented Lagrange Multiplier (ALM) problem:\nmin Z,E,J\n\u2016J\u2016\u2217 + \u03bb\u2016E\u20162,1 + \u03b2\n2 tr(ZLZ\u22a4) + \u3008Y1,Z\u2212 J\u3009+\n\u3008Y2,XZ+ E\u2212X\u3009+ \u00b5\n2 \u2016XZ+ E\u2212X\u20162F +\n\u00b5 2 \u2016Z\u2212 J\u20162F ,\n(6)\nwhere Y1, Y2 are Lagrange multipliers, \u00b5 > 0 is a penalty parameter, and \u2016 \u00b7 \u2016F denotes the Frobenius norm. Eq. (6) can be rewritten as\nmin Z,E,J\n\u2016J\u2016\u2217 + \u03bb\u2016E\u20162,1 + \u03b2\n2 tr(ZLZ\u22a4) +\n\u00b5 2 \u2016XZ+ E\u2212X+ Y2 \u00b5 \u20162F + \u00b5 2 \u2016Z\u2212 J+ Y1 \u00b5 \u20162F . (7)\nFollowing the iterative optimization method in [13], we divide Eq. (7) into three sub-problems: optimizing J while fixing Z and E, optimizing E while fixing J and Z, and optimizing Z while fixing J and E.\nFixing Z and E to optimize J, Eq. (7) is simplified to\nmin J\n\u2016J\u2016\u2217 + \u00b5\n2 \u2016J\u2212 (Z+\nY1\n\u00b5 )\u20162F . (8)\nAccording to [29] [30], singular value thresholding operator is used to solve Eq. (8).\nFixing J and Z to optimize E, Eq. (7) is reduced to\nmin E\n\u03bb\u2016E\u20162,1 + \u00b5\n2 \u2016E\u2212 (X\u2212XZ\u2212\nY2\n\u00b5 )\u20162F . (9)\n7 According to the Lemma 3.2 in [13], if the optimal solution is E\u2217, the i\u2212 th column of E\u2217 is:\nE\u2217(:, i) =\n       \u2016qi\u2016\u2212 \u03bb \u00b5 \u2016qi\u2016 qi, if \u03bb\u00b5 < \u2016qi\u2016, 0, otherwise. (10)\nwhere qi is the i\u2212 th column vector of matrix X\u2212XZ\u2212 Y2\u00b5 .\nFixing J and E to optimize Z, Eq. (7) is simplified to\nmin Z\n\u03b2 2 tr(ZLZ\u22a4) + \u00b5 2 \u2016XZ+ E\u2212X+ Y2 \u00b5 \u20162F + \u00b5 2 \u2016Z\u2212 J+ Y1 \u00b5 \u20162F . (11)\nWe adopt a linearization strategy to optimize Eq. (11). In specific, \u00b5 2 \u2016XZ+ E\u2212X + Y2 \u00b5 \u20162F is linearly approximated into the following formula by using second-order Taylor expansion around point Zk:\n\u00b5 2 \u2016XZ+ E\u2212X+ Y2 \u00b5 \u20162F \u2248 \u3008\u00b5A \u22a4(XZk + E\u2212X+ Y2 \u00b5 ),Z\u2212 Zk\u3009+ \u00b5\u2016A\u20162F 2 \u2016Z\u2212 Zk\u2016 2 F . (12)\nThen, substitute (12) for \u00b5 2 \u2016XZ+ E\u2212X+ Y2 \u00b5 \u20162F and Eq. (11) is written as follows:\nmin Z\n\u03b2 2 tr(ZLZ\u22a4) + \u00b5\u2016X\u20162F 2 \u2016Z\u2212 (Zk \u2212 X\u22a4(XZk + E\u2212X+ Y2 \u00b5 ) \u2016X\u20162F )\u20162F + \u00b5 2 \u2016Z\u2212 J+ Y1 \u00b5 \u20162F . (13)\nFinally, we can achieve the optimal Z by setting the derivative of Eq. (13) with respect to Z to zero:\nZ = [\u00b5\u2016X\u20162FZk \u2212 \u00b5X \u22a4XZk \u2212 \u00b5X \u22a4E+ \u00b5X\u22a4X\u2212X\u22a4Y2 + \u00b5J\u2212Y1](\u03b2L+ \u00b5(\u2016X\u2016 2 F + 1)I) \u22121. (14)\nThe detailed optimization algorithm is summarized in Algorithm 1.\n8 Algorithm 1: The proposed optimization algorithm for graph regularized LRR by linearized ADMM Input: Data matrix X, parameter \u03bb and \u03b2. Initialize: Z = J = 0, E = 0, Y1 = 0, Y2 = 0, \u00b5 = 10\u22126, max\u00b5 = 1011, \u03c1 = 1.1, \u03b5 = 10\u221211, Zk = 0. Output: Lowest rank representation Z.\n1 for each iteration do 2 Fix Z, E and update J: J = argmin \u2016J\u2016\u2217 + \u00b5 2 \u2016J\u2212 (Z+ Y1 \u00b5 )\u20162F . 3 Fix J, Z and update E: E = argmin \u03bb\u2016E\u20162,1 + \u00b5 2 \u2016E\u2212 (X\u2212XZ\u2212 Y2 \u00b5 )\u20162F . 4 Fix J, E and update Z: Z = [\u00b5\u2016X\u20162FZk \u2212 \u00b5X \u22a4XZk \u2212 \u00b5X \u22a4E+ \u00b5X\u22a4X\u2212X\u22a4Y2 + \u00b5J\u2212Y1](\u03b2L+ \u00b5(\u2016X\u2016 2 F + 1)I) \u22121. 5 Update the multipliers: Y1 = Y1 + \u00b5(Z\u2212 J); Y2 = Y2 + \u00b5(XZ+ E\u2212X). 6 Update the parameters: \u00b5 = min(\u03c1\u00b5,max\u00b5); Zk = Z. 7 Check the convergence conditions: \u2016X\u2212XZ\u2212E\u2016\u221e < \u03b5 and \u2016Z\u2212 J\u2016\u221e < \u03b5.\nIII. EXPERIMENTS"}, {"heading": "A. Data Sets", "text": "As in [8][9][10], we use Level 2.0 AERONET retrievals as the target values for regression models. AERONET is a global network of about 250 ground-based instruments that observe aerosols [31]. Most of these stations measure AOD in different spectral bands centered around the nominal wavelengths of 340, 380, 440, 670 nm, and others [32]. To facilitate inter-comparisons with other instruments, these data are interpolated to 550 nm using the quadratic fit on log-log scale from all wavelengths, at a particular location and time [2]. Besides using the AOT values at 550 nm as ground-truth of regression problems, the following two sensors\u2019 spectral values along all the bands are used as features (inputs).\nThe first is the Moderate Resolution Imaging Spectroradiometer (MODIS) data. MODIS is a key instrument aboard the TERRA satellite for the collection of aerosol and cloud information. It has a swath width of 2330 km, and achieves a global coverage in about two days. The MODIS instrument has a single camera observing the top-of-the-atmosphere reflectance over 36 spectral bands between 410 nm and 14 \u00b5m at three different spatial resolutions (250 m, 500 m, 1 km) [33]. We obtain the MODIS Level-1B calibrated radiance product MOD021KM with spatial resolution of 1 km, covering the Beijing AERONET location between January 2002 and December 2014. Over the same spatial and temporal range, we obtain the Level-2 aerosol-retrieval product MOD04 (Collection 6, QA>1) with a spatial resolution of 10 km,\n9 and geolocation product MOD03 with 1 km resolution. MOD04 product is used as a baseline to verify the effectiveness of regression models. Thereafter, Level 2.0 AERONET data are collocated in space and time with the MODIS data. The detailed process can be found in [9]. We obtain a total of 843 spatially and temporally collocated observations from MODIS and AERONET.\nThe second is Multi-angle Imaging SpectroRadiometer (MISR) data. MISR is one of the five instruments mounted on Terra spacecraft. The spacecraft flies in a sun-synchronous 705 km descending polar orbit, so that it crosses the equator always at 10:30 am local time. The MISR instrument consists of nine pushbroom cameras arranged in different view angles relative to the earth\u2019s surface. Each camera uses four ChargeCoupled Device (CCD) line arrays in a single focal plane. The line arrays cover 360 km wide swath and provide four spectral bands in Blue, Green, Red and Near Infrared (NIR) that are centered at 443, 555, 670 and 865 nm, respectively. The resolution of all the four bands in nadir view and the red band at all the nine angles is 275 m and the resolution of the other bands is 1.1 km. We download 1045 collocated MISR and AERONET data from MAPSS [32], covering the whole 23 stations at all available time in China."}, {"heading": "B. Experimental Setup", "text": "To demonstrate the superiority of the proposed graph regularized LRR model, the new representation is feeded into the subsequent regression model SVM. For simplicity, we name it GLRR+SVM, which is compared with the following six retrieval models: 1) the operating satellite-retrieval algorithms by physical models; 2) the ordinary least square regression (OLS); 3) ridge regression (RR); 4) NN; 5) SVM; 6) the classical LRR with SVM regressor (LRR+SVM). For NN, the optimal number of hidden nodes is chosen from [2, 50] in steps of 5 via a 5-fold cross validation. For SVM, we adopt the Gaussian kernel since it usually achieves the best results compared to other kernels. The optimal variance parameter \u03b3 for the Gaussian kernel and the regularization parameter C in SVM are both selected from {10\u22123, 10\u22122, \u00b7 \u00b7 \u00b7 , 103}. Besides, there are two regularization parameters \u03bb and \u03b2 for the graph regularized LRR model, which are also chosen by a 5-fold cross validation from the given set {10\u22123, 10\u22122, \u00b7 \u00b7 \u00b7 , 103}. In all the experiments, we randomly divide the whole data into the training set and the testing set according to some percentages. The\n10\ntraining set is used to train the regression based retrieval models, while the testing set is used to evaluate their performances. In order to reduce the effects of random selection, all the algorithms are repeated ten times and the average performances are reported. Without loss of generality, we use two mainstream evaluation metrics: the root-mean-square error (RMSE) to evaluate the accuracy of the estimations, and Pearson\u2019s correlation coefficient R to evaluate the goodness of fit."}, {"heading": "C. Results and Discussion", "text": "For the MODIS data set, the average RMSE values and the standard deviations achieved by seven different models from ten experiments are demonstrated in Fig. 2, where the smaller values correspond to the better performances. Several conclusions can be observed from this figure. First, in Fig. 2(a), it can be seen that given enough training samples, the regression models achieve higher performance than the physical model. Second, SVM yields the best performance in the four regression models, because it can well solve the case with small numbers of training samples. Third, in Fig. 2(b), the performance of LRR+SVM is a little better than SVM especially when the percentage of training samples is more than 70%. This indicates that LRR is able to learn a better representation from the corrupted observation data compared to the pure\n11\nspectral response values. More importantly, GLRR+SVM further improves the performance as compared to LRR+SVM, because it can capture the local structure information and the nonlinear property of MODIS data. The last but not the least, a deficiency of regression models can be observed in Fig. 2(a). Specifically, when the percentage of training samples is 10%, the physical model is better than all of the regression\n12\nmodels. However, when the percentage of training samples is more than 20%, the best regression model SVM yields higher performance than the physical model. This indicates that the regression models heavily rely on the number of training samples while the physical model is stable. The above conclusions can also be verified from another evaluation indicator R in Fig. 3. Different from Fig. 2, here, the larger values denote the better performances. In particular, SVM obtains the best results compared to OLS, RR and NN. With a learned representation, LRR+SVM improves the performance of SVM. Besides, GLRR+SVM is capable of boosting the results of LRR+SVM by adding a graph regularization into the original LRR.\nFor the MISR data set, Fig. 4 and Fig. 5 show the average performances and deviations of seven different models from ten experiments. From these figures, we can observe that the performances of the regression models are better than that of the physical model. In particular, SVM is superior to OLS, RR and NN. GLRR+SVM and LRR+SVM are both better than SVM, because they can learn an effective representation rather than directly using the corrupted spectral values. More importantly, when graph regularization based on the physical retrieval results is incorporated into the LRR model, the performance can be further boosted especially when the number of training samples is less than 70%, which certify the effectiveness of GLRR+SVM.\n13"}, {"heading": "D. Parameter Analysis", "text": "There are two important regularization parameters \u03bb and \u03b2 in the proposed method. The first one is used to balance the effects of low rank property and noise component, and the second one is utilized to balance the information from empirical model and physical model. Fig. 6 demonstrates the 3-D diagram of RMSE against them on MODIS and MISR data sets. From Fig. 6(a), we can observe that as \u03bb and \u03b2 increase, the corresponding RMSE firstly increases and then decreases, and achieves the maximal value at \u03bb = 1 and \u03b2 = 10\u22121. Similar results can be seen from Fig. 6(b), and the maximal value appears when \u03bb = \u03b2 = 10."}, {"heading": "IV. CONCLUSION", "text": "This paper proposed a graph regularized low rank representation (LRR) model to learn an effective feature representation for aerosol optical depth (AOD) retrieval. Based on the observation that remote-sensing data often lie in a low rank subspace, LRR was naturally used to uncover the intrinsic data structure from corrupted or noisy observations. Additionally, to preserve the nonlinear structure in remote-sensing data, graph regularization was added to the LRR model. It is well known that the current operating satellites can generate AOD values by physical models. Thus, the proposed graph model was constructed based on such rich information. By conducting experiments on two data sets collected by different instruments\n14\n(MODIS and MISR), we compared the proposed method with the physical models and the other state-ofthe-art empirical models. The experimental results indicate that the learned representation can improve the retrieval performance."}], "references": [{"title": "A satellite view of aerosols in the climate system,", "author": ["Yoram J Kaufman", "Didier Tanr\u00e9", "Olivier Boucher"], "venue": "Nature, vol. 419,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2002}, {"title": "The modis aerosol algorithm, products, and validation,", "author": ["Lorraine A Remer", "YJ Kaufman", "D Tanr\u00e9", "S Mattoo", "DA Chu", "J Vanderlei Martins", "R-R Li", "C Ichoku", "RC Levy", "RG Kleidman"], "venue": "Journal of the atmospheric sciences,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2005}, {"title": "Multiangle imaging spectroradiometer (misr) global aerosol optical depth validation based on 2 years of coincident aerosol robotic network (aeronet) observations,", "author": ["Ralph A Kahn", "Barbara J Gaitley", "John V Martonchik", "David J Diner", "Kathleen A Crean", "Brent Holben"], "venue": "Journal of Geophysical Research: Atmospheres (1984\u20132012),", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2005}, {"title": "and BN Holben", "author": ["YJ Kaufman", "D Tanr\u00e9", "L Ao Remer", "EF Vermote", "A Chu"], "venue": "\u201cOperational remote sensing of tropospheric aerosol over land from eos moderate resolution imaging spectroradiometer,\u201d Journal of Geophysical Research: Atmospheres ", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2012}, {"title": "Techniques for the retrieval of aerosol properties over land and ocean using multiangle imaging,", "author": ["John V Martonchik", "David J Diner", "Ralph Kahn", "Thomas P Ackerman", "Michel M Verstraete", "Bernard Pinty", "Howard R Gordon"], "venue": "IEEE Transactions on Geoscience and Remote Sensing,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 1998}, {"title": "Second-generation operational algorithm: Retrieval of aerosol properties over land from inversion of moderate resolution imaging spectroradiometer spectral reflectance,", "author": ["Robert C Levy", "Lorraine A Remer", "Shana Mattoo", "Eric F Vermote", "Yoram J Kaufman"], "venue": "Journal of Geophysical Research: Atmospheres (1984\u20132012),", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2007}, {"title": "Uncertainty analysis of neural-network-based aerosol retrieval,", "author": ["Kosta Ristovski", "Slobodan Vucetic", "Zoran Obradovic"], "venue": "IEEE Transactions on Geoscience and Remote Sensing,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2012}, {"title": "A data-mining approach for the validation of aerosol retrievals,", "author": ["Slobodan Vucetic", "Bo Han", "Wen Mi", "Zhanquing Li", "Zoran Obradovic"], "venue": "IEEE Geoscience and Remote Sensing Letters,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2008}, {"title": "and S Paradise", "author": ["DJ Lary", "LA Remer", "D MacNeill", "B Roscoe"], "venue": "\u201cMachine learning and bias correction of modis aerosol optical depth,\u201d IEEE Geoscience and Remote Sensing Letters, vol. 6, no. 4, pp. 694\u2013698", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2009}, {"title": "Nonwhite noise reduction in hyperspectral images,", "author": ["Xuefeng Liu", "Salah Bourennane", "Caroline Fossati"], "venue": "IEEE Geoscience and Remote Sensing Letters,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2012}, {"title": "A super-resolution reconstruction algorithm for hyperspectral images,", "author": ["Hongyan Zhang", "Liangpei Zhang", "Huanfeng Shen"], "venue": "Signal Processing,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2012}, {"title": "Robust subspace segmentation by low-rank representation,", "author": ["Guangcan Liu", "Zhouchen Lin", "Yong Yu"], "venue": "Proceedings of the international conference on machine learning,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2010}, {"title": "Robust recovery of subspace structures by low-rank representation,", "author": ["Guangcan Liu", "Zhouchen Lin", "Shuicheng Yan", "Ju Sun", "Yong Yu", "Yi Ma"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2013}, {"title": "Hyperspectral image restoration using low-rank matrix recovery,", "author": ["Hongyan Zhang", "Wei He", "Liangpei Zhang", "Huanfeng Shen", "Qiangqiang Yuan"], "venue": "IEEE Transactions on Geoscience and Remote Sensing,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2014}, {"title": "Sparcs: Recovering low-rank and sparse matrices from compressive measurements,", "author": ["Andrew E Waters", "Aswin C Sankaranarayanan", "Richard Baraniuk"], "venue": "Advances in neural information processing systems,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2011}, {"title": "A Fusina, \u201cExploiting manifold geometry in hyperspectral imagery,", "author": ["Charles M Bachmann", "Thomas L Ainsworth", "Robert"], "venue": "IEEE Transactions on Geoscience and Remote Sensing,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2005}, {"title": "Graph regularized sparse coding for image representation,", "author": ["Miao Zheng", "Jiajun Bu", "Chun Chen", "Can Wang", "Lijun Zhang", "Guang Qiu", "Deng Cai"], "venue": "IEEE Transactions on Image Processing, vol. 20,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2011}, {"title": "Laplacian sparse coding, hypergraph laplacian sparse coding, and applications,", "author": ["Shenghua Gao", "Ivor Wai-Hung Tsang", "Liang-Tien Chia"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2013}, {"title": "Graph regularized nonnegative matrix factorization for data representation,", "author": ["Deng Cai", "Xiaofei He", "Jiawei Han", "Thomas S Huang"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2011}, {"title": "Global bias adjustment for modis aerosol optical thickness using neural network,", "author": ["Arif Albayrak", "Jennifer Wei", "Maksym Petrenko", "Christopher Lynnes", "Robert C Levy"], "venue": "Journal of Applied Remote Sensing,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2013}, {"title": "Latent low-rank representation for subspace segmentation and feature extraction,", "author": ["Guangcan Liu", "Shuicheng Yan"], "venue": "IEEE International Conference on Computer Vision. IEEE,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2011}, {"title": "Manifold-learning-based feature extraction for classification of hyperspectral data: a review of advances in manifold learning,", "author": ["Dalton Lunga", "Santasriya Prasad", "Melba M Crawford", "Ozan Ersoy"], "venue": "IEEE Signal Processing Magazine, vol. 31,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2014}, {"title": "Locality-preserving dimensionality reduction and classification for hyperspectral image analysis,", "author": ["Wei Li", "Saurabh Prasad", "James E Fowler", "Lori Mann Bruce"], "venue": "IEEE Transactions on Geoscience and Remote Sensing,", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2012}, {"title": "Laplacian eigenmaps and spectral techniques for embedding and clustering.,", "author": ["Mikhail Belkin", "Partha Niyogi"], "venue": "Advances in neural  16 information processing systems,", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2001}, {"title": "Linearized alternating direction method with adaptive penalty for low-rank representation,", "author": ["Zhouchen Lin", "Risheng Liu", "Zhixun Su"], "venue": "Advances in neural information processing systems,", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2011}, {"title": "Linearized augmented lagrangian and alternating direction methods for nuclear norm minimization,", "author": ["Junfeng Yang", "Xiaoming Yuan"], "venue": "Mathematics of Computation,", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 2013}, {"title": "The augmented lagrange multiplier method for exact recovery of corrupted low-rank matrices,", "author": ["Zhouchen Lin", "Minming Chen", "Yi Ma"], "venue": "arXiv preprint arXiv:1009.5055,", "citeRegEx": "29", "shortCiteRegEx": "29", "year": 2010}, {"title": "A singular value thresholding algorithm for matrix completion,", "author": ["Jian-Feng Cai", "Emmanuel J Cand\u00e8s", "Zuowei Shen"], "venue": "SIAM Journal on Optimization,", "citeRegEx": "30", "shortCiteRegEx": "30", "year": 2010}, {"title": "T Nakajima", "author": ["BN Holben", "TF Eck", "I Slutsker", "D Tanre", "JP Buis", "A Setzer", "E Vermote", "JA Reagan", "YJ Kaufman"], "venue": "et al., \u201cAeronet\u0142a federated instrument network and data archive for aerosol characterization,\u201d Remote sensing of environment, vol. 66, no. 1, pp. 1\u201316", "citeRegEx": "31", "shortCiteRegEx": null, "year": 1998}, {"title": "and G Leptoukh", "author": ["M Petrenko", "C Ichoku"], "venue": "\u201cMulti-sensor aerosol products sampling system (mapss),\u201d Atmospheric Measurement Techniques, vol. 5, no. 5, pp. 913\u2013926", "citeRegEx": "32", "shortCiteRegEx": null, "year": 2012}], "referenceMentions": [{"referenceID": 0, "context": "They can scatter and absorb solar radiance, and modify microphysical and radiative properties of cloud [1].", "startOffset": 103, "endOffset": 106}, {"referenceID": 1, "context": "AOD has become a major atmospheric data product derived from various earth observation satellites, such as the Moderate Resolution Imaging Spectroradiometer (MODIS) [2], the Multiangle Imaging Spectro-Radiometer (MISR) Y.", "startOffset": 165, "endOffset": 168}, {"referenceID": 2, "context": "[3], etc.", "startOffset": 0, "endOffset": 3}, {"referenceID": 3, "context": "Most of the current operating satellite-retrieval algorithms are based on physical models [4][5][6].", "startOffset": 90, "endOffset": 93}, {"referenceID": 4, "context": "Most of the current operating satellite-retrieval algorithms are based on physical models [4][5][6].", "startOffset": 93, "endOffset": 96}, {"referenceID": 5, "context": "Most of the current operating satellite-retrieval algorithms are based on physical models [4][5][6].", "startOffset": 96, "endOffset": 99}, {"referenceID": 6, "context": "An efficient alternative is empirical models [7][8].", "startOffset": 48, "endOffset": 51}, {"referenceID": 6, "context": "Among these models, neural networks (NN) [8][9] and support vector machines (SVMs) [7][10] are two popular methods, because they can approximate the complex non-linear relationships between satellite-based observations and ground-based observations.", "startOffset": 41, "endOffset": 44}, {"referenceID": 7, "context": "Among these models, neural networks (NN) [8][9] and support vector machines (SVMs) [7][10] are two popular methods, because they can approximate the complex non-linear relationships between satellite-based observations and ground-based observations.", "startOffset": 44, "endOffset": 47}, {"referenceID": 8, "context": "Among these models, neural networks (NN) [8][9] and support vector machines (SVMs) [7][10] are two popular methods, because they can approximate the complex non-linear relationships between satellite-based observations and ground-based observations.", "startOffset": 86, "endOffset": 90}, {"referenceID": 9, "context": ", noise contamination, stripe corruption, and missing data, due to the sensor, photon effects, and calibration error [11][12], directly using such", "startOffset": 117, "endOffset": 121}, {"referenceID": 10, "context": ", noise contamination, stripe corruption, and missing data, due to the sensor, photon effects, and calibration error [11][12], directly using such", "startOffset": 121, "endOffset": 125}, {"referenceID": 11, "context": "Low rank representation (LRR), which was successfully employed in natural image denoising [13][14], has shown its potential in remote-sensing data analysis [15].", "startOffset": 90, "endOffset": 94}, {"referenceID": 12, "context": "Low rank representation (LRR), which was successfully employed in natural image denoising [13][14], has shown its potential in remote-sensing data analysis [15].", "startOffset": 94, "endOffset": 98}, {"referenceID": 13, "context": "Low rank representation (LRR), which was successfully employed in natural image denoising [13][14], has shown its potential in remote-sensing data analysis [15].", "startOffset": 156, "endOffset": 160}, {"referenceID": 14, "context": "Moreover, as discussed in [16], the rank of the matrix constructed by remote-sensing data is bounded by the small number of pure spectral endmembers.", "startOffset": 26, "endOffset": 30}, {"referenceID": 15, "context": "Besides, due to the effects of multipath scattering, variations in sun-canopy-sensor geometry, nonhomogeneous composition of pixels, and attenuating properties of media, remote-sensing data are often nonlinearly distributed [17].", "startOffset": 224, "endOffset": 228}, {"referenceID": 16, "context": "To preserve such nonlinear structure, motivated by [18][19][20], graph regularization is incorporated into the LRR model.", "startOffset": 51, "endOffset": 55}, {"referenceID": 17, "context": "To preserve such nonlinear structure, motivated by [18][19][20], graph regularization is incorporated into the LRR model.", "startOffset": 55, "endOffset": 59}, {"referenceID": 18, "context": "To preserve such nonlinear structure, motivated by [18][19][20], graph regularization is incorporated into the LRR model.", "startOffset": 59, "endOffset": 63}, {"referenceID": 7, "context": "Many researchers attempted to employ such information as features for regression models [7][9][21].", "startOffset": 91, "endOffset": 94}, {"referenceID": 19, "context": "Many researchers attempted to employ such information as features for regression models [7][9][21].", "startOffset": 94, "endOffset": 98}, {"referenceID": 14, "context": "The dictionary is often overcomplete, and the clean remotesensing data often lie in a low rank feature space [16].", "startOffset": 109, "endOffset": 113}, {"referenceID": 11, "context": "Thus, we can use an alternative scheme of A = X as in [13][22], and the purpose becomes to search for the lowest rank solution of Z by", "startOffset": 54, "endOffset": 58}, {"referenceID": 20, "context": "Thus, we can use an alternative scheme of A = X as in [13][22], and the purpose becomes to search for the lowest rank solution of Z by", "startOffset": 58, "endOffset": 62}, {"referenceID": 12, "context": "\u2211d i=1(Eij) 2 as in [14].", "startOffset": 20, "endOffset": 24}, {"referenceID": 20, "context": "It was demonstrated that LRR is capable of capturing the global structure of the data as well as robust to noise [22].", "startOffset": 113, "endOffset": 117}, {"referenceID": 21, "context": "However, as discussed in [23], nonlinearities often exist in remote-sensing data due to the effects of many factors.", "startOffset": 25, "endOffset": 29}, {"referenceID": 22, "context": "to be a successful method to capture such nonlinearity [24][25].", "startOffset": 59, "endOffset": 63}, {"referenceID": 23, "context": "(3) is that if two pixels are close, their new representations are also close to each other [26].", "startOffset": 92, "endOffset": 96}, {"referenceID": 24, "context": "As in [27][28], we adopt the linearized Alternating Direction Method of Multipliers (ADMM) algorithm to optimize it.", "startOffset": 6, "endOffset": 10}, {"referenceID": 25, "context": "As in [27][28], we adopt the linearized Alternating Direction Method of Multipliers (ADMM) algorithm to optimize it.", "startOffset": 10, "endOffset": 14}, {"referenceID": 11, "context": "Following the iterative optimization method in [13], we divide Eq.", "startOffset": 47, "endOffset": 51}, {"referenceID": 26, "context": "According to [29] [30], singular value thresholding operator is used to solve Eq.", "startOffset": 13, "endOffset": 17}, {"referenceID": 27, "context": "According to [29] [30], singular value thresholding operator is used to solve Eq.", "startOffset": 18, "endOffset": 22}, {"referenceID": 11, "context": "2 in [13], if the optimal solution is E, the i\u2212 th column of E is:", "startOffset": 5, "endOffset": 9}, {"referenceID": 6, "context": "Data Sets As in [8][9][10], we use Level 2.", "startOffset": 16, "endOffset": 19}, {"referenceID": 7, "context": "Data Sets As in [8][9][10], we use Level 2.", "startOffset": 19, "endOffset": 22}, {"referenceID": 8, "context": "Data Sets As in [8][9][10], we use Level 2.", "startOffset": 22, "endOffset": 26}, {"referenceID": 28, "context": "AERONET is a global network of about 250 ground-based instruments that observe aerosols [31].", "startOffset": 88, "endOffset": 92}, {"referenceID": 29, "context": "Most of these stations measure AOD in different spectral bands centered around the nominal wavelengths of 340, 380, 440, 670 nm, and others [32].", "startOffset": 140, "endOffset": 144}, {"referenceID": 1, "context": "To facilitate inter-comparisons with other instruments, these data are interpolated to 550 nm using the quadratic fit on log-log scale from all wavelengths, at a particular location and time [2].", "startOffset": 191, "endOffset": 194}, {"referenceID": 7, "context": "The detailed process can be found in [9].", "startOffset": 37, "endOffset": 40}, {"referenceID": 29, "context": "We download 1045 collocated MISR and AERONET data from MAPSS [32], covering the whole 23 stations at all available time in China.", "startOffset": 61, "endOffset": 65}, {"referenceID": 1, "context": "For NN, the optimal number of hidden nodes is chosen from [2, 50] in steps of 5 via a 5-fold cross validation.", "startOffset": 58, "endOffset": 65}], "year": 2016, "abstractText": "In this paper, we propose a novel data-driven regression model for aerosol optical depth (AOD) retrieval. First, we adopt a low rank representation (LRR) model to learn a powerful representation of the spectral response. Then, graph regularization is incorporated into the LRR model to capture the local structure information and the nonlinear property of the remote-sensing data. Since it is easy to acquire the rich satellite-retrieval results, we use them as a baseline to construct the graph. Finally, the learned feature representation is feeded into support vector machine (SVM) to retrieve AOD. Experiments are conducted on two widely used data sets acquired by different sensors, and the experimental results show that the proposed method can achieve superior performance compared to the physical models and other state-of-the-art empirical models.", "creator": "LaTeX with hyperref package"}}}