{"id": "1603.00260", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "1-Mar-2016", "title": "Event Search and Analytics: Detecting Events in Semantically Annotated Corpora for Search and Analytics", "abstract": "In this article, I present the questions that I seek to answer in my PhD research. I posit to analyze natural language text with the help of semantic annotations and mine important events for navigating large text corpora. Semantic annotations such as named entities, geographic locations, and temporal expressions can help us mine events from the given corpora. These events thus provide us with useful means to discover the locked knowledge in them. I pose three problems that can help unlock this knowledge vault in semantically annotated text corpora: i. identifying important events; ii. semantic search; and iii. event analytics.\n\n\n\nIn a particular case of the search for important events, we should use semantic search to uncover key events, such as the following:\n\u2013 The name of the event used; and iii. event analytics.\nThe most powerful and powerful semantic search engine (Hadoop) can perform this feature on any of the following:\n\u2013 The name of the event used; and iii. event analytics.\nEach search query can be performed in this way by adding the following tag:\n\u2013 The name of the event used; and iii. event analytics.\nThe following list of the most powerful semantic search engines (Hadoop) can be run by using the following command:\n\u2013 The name of the event used; and iii. event analytics.\nThe following list of the most powerful semantic search engines (Hadoop) can be run by using the following command:\n\u2013 The name of the event used; and ii. event analytics.\nThese are a number of useful events I can explore in this section, and can be accessed by using the following command:\n\u2013 The name of the event used; and ii. event analytics.\nThese are a number of useful events I can explore in this section, and can be accessed by using the following command:\n\u2013 The name of the event used; and iii. event analytics.\nThese are a number of useful events I can explore in this section, and can be accessed by using the following command:\n\u2013 The name of the event used; and iii. event analytics.\nThese are a number of useful events I can explore in this section, and can be accessed by using the following command:\n\u2013 The name of the event used; and ii. event analytics.\nThese are a number of useful events I can explore in this section, and can be accessed by using the following command:\n\u2013 The name of the event used; and ii.", "histories": [["v1", "Tue, 1 Mar 2016 13:14:33 GMT  (89kb,D)", "http://arxiv.org/abs/1603.00260v1", "Extended research report of an extended abstract published at WSDM 2016 Doctoral Consortium. in WSDM 2016 Proceedings of the Ninth ACM International Conference on Web Search and Data Mining"]], "COMMENTS": "Extended research report of an extended abstract published at WSDM 2016 Doctoral Consortium. in WSDM 2016 Proceedings of the Ninth ACM International Conference on Web Search and Data Mining", "reviews": [], "SUBJECTS": "cs.IR cs.CL", "authors": ["dhruv gupta"], "accepted": false, "id": "1603.00260"}, "pdf": {"name": "1603.00260.pdf", "metadata": {"source": "CRF", "title": "Event Search and Analytics Detecting Events in Semantically Annotated Corpora for Search & Analytics", "authors": ["Dhruv Gupta"], "emails": ["dhgupta@mpi-inf.mpg.de"], "sections": [{"heading": null, "text": "Keywords Information Retrieval; Text Analytics; Text Summarization; Semantic Annotations; Diversity & Novelty; Semantic Search"}, {"heading": "1. INTRODUCTION", "text": "Information retrieval systems have largely relied on word statistics in text corpora to satisfy information needs of users by retrieving documents with high relevance for a given keyword query. In my PhD research I hypothesize that information needs of users can be satisfied to a greater extent by using events as a means of navigating text corpora. Events in our context would be an act performed by certain actor(s) at a specific location during a specific time interval. An example would be : Usain Bolt won the gold medal at the 2008 summer Olympics in Bejing. With the availability of annotators that can provide us with accurate semantic annotations in form of named entities, geographic locations, and temporal expressions; we can leverage the growing number of knowledge resources such as Wikipedia [37] and ontologies such as Freebase [12] to understand natural language text and mine important events. Formally the central hypothesis can be stated as follows:\nCentral Hypothesis Given text corpora with semantic annotations; traditional information retrieval models can be improved by utilizing knowledge about events and using events as proxies for information need.\nAs a toy example consider the following text snippet 1\nwith demonstrative semantic annotations in Figure 1 :\nIn the text snippet (Figure 1), we obtain the named entity Usain Bolt whose mention has been identified and disambiguated to point to an external knowledge source. Also identified is a geographical location - Beijing, which is disambiguated and resolved to its geographical coordinates. Likewise the temporal expression 2008 has also been resolved to time range. Having these semantic annotations we can now devise algorithms that can deduce that the event is that of Usain Bolt winning Olympic competition in Beijing, China.\nThe goal of the proposed research is to leverage the semantic annotations for mining important events and use them to navigate text corpora. The research will find application in many domains of research such as digital humanities, in which social scientists are interested in computational history in large digital-born text collections. Anthropologists are interested in cultural and linguistic shifts that occur in such collections. Collectively we can allow computational culturomics [24] on corpora to study cultural trends. Events can also be used to link information in multiple and diverse text collections. In short, important events provide a way to create a gist from semantically annotated corpora, which otherwise is not possible through manual human effort.\nOutline. The article consists of:\n\u2022 a literature survey (Section 2);\n\u2022 an overview of the research problems (Section 3);\n\u2022 available corpora, test sources and evaluation measures for research (Section 5);\n\u2022 discussion of few open technical problems (Section 6). 1 http://www.bbc.com/sport/0/athletics/34032366\nar X\niv :1\n60 3.\n00 26\n0v 1\n[ cs\n.I R\n] 1\nM ar\n2 01\n6"}, {"heading": "2. RELATED WORK", "text": "In this section I discuss the progress already made in the area of analyzing different semantic annotations in isolation as well as in conjunction for some of the problems proposed.\nTemporal Information Retrieval and Extraction. Researchers have considered only temporal annotations in text corpora to improve retrieval effectiveness by analyzing the time sensitivity of keyword queries and incorporating the time dimension in retrieval models. Some methods of analysis of time-sensitive queries rely on publication dates of documents [21, 22], while others also look at the temporal expressions in document contents [15]. Several works also take into account the time dimension for re-ranking documents [10] and diversifying them along time [11, 25]. One of the seminal works in extracting temporal events was by Ling and Weld [23]. They outline a probabilistic model to solve the problem of extracting relations from text with temporal constraints.\nImportant Events in Annotated Corpora. One of the most important seminal works in identifying existing and emerging events were the various tasks in Topic Detection and Tracking (TDT) [7]. The TDT program aimed to \u201csearch, organize and structure\u201d broadcast news media from multiple sources. The five tasks laid within the ambit of TDT where topic tracking, link detection, topic detection, first story detection, and story segmentation. The task of topic tracking required to build a system to detect on topic stories from an evaluation corpus after being trained on a set on topic stories. The link detection task involved answering a boolean query to whether two given stories are related by a common topic. The topic detection task comprised of declaring new topics from incoming stories which had not been presented to the system. First story detection was another boolean decision task of determining whether the given story is a seed story (first-story) to create a new topic cluster. Story segmentation task required segmentation of an incoming stream of text into stories.\nFocusing specifically on extracting and summarizing events in the future, Jatowt and Yeung [20] present a model-based clustering algorithm. The clustering considers both textual and temporal similarities. For computing temporal similarity, the authors model time as a probability distribution by utilizing different family of distributions based on whether its is singular time point, starting date or and ending date. The similarity is then computed using KL-divergence.\nRadinsky et al. [26] present an algorithm Pundit, which based on the past events in text is able to predict a future event given a query to the system. The events are represented as multidimensional attributes such as time, geographic location and participating entities. The algorithm derives these events from external text collection and builds an abstraction tree, which is the result from hierarchical agglomerative clustering. In order to predict the future Pundit is trained to select the most similar cluster from the abstraction tree and produce an event representation.\nThe work by Yeung and Jatowt [38] tackles the problem of analysis of historical events in multiple large document collections. They utilize latent Dirichlet allocation to identify topic distributions along time. Thereafter they perform analytics to answer questions such as i. significant years and topics, ii. triggers that caused remembrance of the past and iii. historical similarity of countries.\nMost recently, Abujabal and Berberich [5] present a system which identifies important events in text collections by counting frequent itemsets of sentences containing named entities and temporal expressions. For evaluation they resort to Wikipedia\u2019s event directory as a ground truth.\nSemantic Search. Summarizing text collections in a timeline visualization is a natural choice. Swan and Allan [31] present an approach for producing a timeline that depicts most important topics and events closely modeled on the Topic Detection and Tracking task. The algorithms analyzes features based on named entities and noun phrases. The analysis involves construction of 2 \u00d7 2 contingency table on presence or absence of features, and subsequent measurement of \u03c72 statistic for measuring significance of cooccurrence of a pair of features.\nThe seminal work by Baeza-Yates [8] proposed a future retrieval (FR) system. The FR system considers both text and temporal expressions to identify future events that might be relevant to an input query. Baeza-Yates outlined the components of a FR system to be composed of an information extraction (IE) module, information retrieval (IR) module, and a text mining (TM) module. The IE module would act as a temporal annotator; identify temporal expressions and normalize them. The IR system is designed to incorporate the time dimension in an index; thus retrieving documents with text and time similarity. The TM module would identify the most relevant topics given a time period. He presented a retrieval model, in which each document consists of a multiple temporal events. A temporal event consists of a time segment and its associated likelihood of occurring. The score of the document is thus obtained by its textual similarity and the maximum likelihood of all the temporal events in that document.\nBast and Buchhold [9] outline a joint index structure over ontologies and text. Which allows for fast semantic search and provide context sensitive auto-complete suggestions.\nEvents as a means of search document collections has also been explored by Stro\u0308tgen and Gertz [28]. Events were modeled by the geographic location and time of their occurrence. For temporal queries expressed in simple natural language they outline an extended Backus-Naur form (EBNF) language that incorporates time intervals with standard boolean operations. Geographical queries are also modeled as EBNF language, however the input for them is a minimum bounding rectangle (MBR). Using this multidimensional querying model the user is able to visualize search results in form of events; which are additionally represented on a map.\nGiving special attention to geographical information retrieval, Samet et al. [27] present a system NewsStand, that is able to resolve and pinpoint a news article based on the geographic information present in its content. They discuss various methods for toponymn resolution, which is in essence disambiguating the geographic location based on its surface form in the news content. The system involves a streaming clustering algorithm that can keep track of emerging news in new locations and present them in a map-based interface.\nEvent Analytics. By disambiguating and linking named entities to ontologies, Hoffart et al. [17, 18] provide a framework for semantic search and performing analytics on them. They provide features for giving auto-complete suggestions in the form of similar entities for the input named-entity. In [17] they provide analytics that leverage accurate entity\ncounts and provide entity co-occurrence statistics which is helpful in analyzing semantically similar named-entities."}, {"heading": "3. RESEARCH OBJECTIVES", "text": "Given the text corpora with semantic annotations, I describe three important research problems in this section: i. identifying important events; ii. using identified events for improving retrieval effectiveness; and iii. using identified events for analytics."}, {"heading": "3.1 Notation", "text": "Let us consider multiple corpora for the purpose of analysis. This allows us to capture frequently occurring events as well as link similar events across corpus. Given corpora\nD = N\u22c3 k=1 Dk,\nwhere each document d \u2208 D consists of word sequence x at appropriate granularity (e.g. paragraph or sentence):\nd = n\u22c3 i=1 xi.\nFurther each x \u2208 d contains semantic annotations in form of i. named entities (e), ii. geographical location (g), and iii. temporal expressions (t). Additionally x also consists of the a bag of wordsW drawn from a vocabulary V. Formally represented as:\nx = \u3008E , g, t,W\u3009"}, {"heading": "3.2 Problem Definition", "text": "The objective is to design a family of algorithms:\nEvent*(X,Q, \u03b1) where X = \u22c3 x, Q represents an input query and \u03b1 \u2208 Rm, where \u03b1 is set of parameters. The input query Q can be a combination of following input components: i. keyword query q, ii. time qtime, iii. geographical location qgeo, and iv. named entity qentity.\nGiven the input, we need to design the algorithms Event* according to the different problems. We discuss the design objectives for the three different purposes in this section.\nIdentifying Important Events. Events are the proposed building blocks for further text analysis. An event in our context is defined to be an activity or an act involving named entities that happens in a specific geographical location anchored to a specific time interval. Mathematically, given a multidimensional query :\nQ = \u3008q, qtime, qgeo, gentity\u3009,\nand a subset of highly relevant documents R \u2286 D, the algorithm for this purpose EventDetect should produce a set of ordered events :\nC = {c1, c2, . . . , ck},\nwhere, c = \u3008E , g, t,W\u3009. The event c is hence described by the participating named entities E , its location g, its time of occurrence t, and frequently occurring contextual terms around these semantic annotationsW. This requires proposing a probability mass function, P (C, R), using which we can impose a total order on C.\nAs an example consider the keyword-only query summer olympics to the processed corpora of news articles. The designed algorithm shall then identify the important events as in Figure 2.\nDiversifying and Summarizing Search Results are retrieval tasks that try to address the information need underlying an ambiguous query at different levels of textual granularity. Each task tries to maximize the coverage of different information needs underlying the given ambiguous query. As information intents, we propose to use the mined set of events. Accomplishing these tasks would allow for automatic creation of event timelines or entity biographies. We briefly discuss an intuition of achieving the same.\nWhen diversifying search results we would like to present users with documents such that the user finds at least one document that satisfies her information intent. For this we need to devise an algorithm EventDiverse which considers as an input Q and R \u2286 D. As an output it returns a set of documents S \u2282 R which cover all events in C.\nSummarizing search results would require us to construct an algorithm EventSummary to piece together, sentences S\u0302 = \u22c3 x, such that the text summary covers all events in C.\nSemantic Search and Analytics. The mined set of events can further be utilized for search and analytics. For this purpose we can utilize inherent hierarchy in the semantic annotations. For example a given year 2015 can be broken down to different months and subsequently days in those months. Similarly, we can utilize the type hierarchies in named entities. Such as Usain Bolt and Justin Gatlin are subtypes of Athletes. This can jointly be modeled by using the concept of a data cube [16] as shown in Figure 3.\nFormally, given a query Q, the objective would to first model the mined set of events as a data cube and subsequently provide data cube operations [16]:\n\u2022 roll (\u00a9), \u2022 slice ( ), \u2022 dice (\u2295), \u2022 drill up (4), \u2022 drill down (5).\nAs a concrete example consider the query all races won during 2008 by usain bolt in china. To produce an appropriate result the sequence of operations would be: first a slice on the entity Usain Bolt; second dice on China; and finally drill up to year 2008 (see Figure 4)."}, {"heading": "4. DATA", "text": "Corpora. There are several readily available massive data sets. They are available from news corporation such as the New York Times [4], English Gigaword [3]. These corpora have the benefit of being available with reliable publication dates and grammatically well-formed text. On larger scale are Web collections such as ClueWeb\u201909 [1]/\u201912 [2], which are not always accompanied by reliable creation dates and many are ill-formed documents.\nSemantic Annotations. The text corpora next need to be annotated for text mining. I explain how to obtain the different semantic annotations in the following paragraphs.\nNamed Entities. For disambiguating and linking named entities in text to an external knowledge source such as Wikipedia [37] or an ontology such as YAGO [30] or Freebase [12]; I use the AIDA system [19]. The AIDA system does named entity disambiguation and linking by leveraging contexts extracted from ontologies such as YAGO. For Web collections such ClueWeb\u201909/\u201912 the entity disambiguation and linking has been released as facc1 : Freebase annotation of ClueWeb Corpora [14].\nGeographical Locations can be obtained by utilizing geographic named entities such as those known to be cities, countries, or continents. Geographical relations stored in an ontology can be used to resolve these locations to its geographical coordinates. Having obtained a set of coordinates, we can subsequently construct a geographical representation such as a minimum bounding rectangle over the coordinates.\nTemporal Expressions, both implicit and explicit, can be extracted and normalized from text by using temporal taggers such as HeidelTime [29] or SUTime [13]."}, {"heading": "5. EVALUATION", "text": "To test our approach we need to construct query sets that contain an event description associated with the query; along with participating named entities, geographical locations where the event took place and relevant time interval associated with it. I describe a tentative approach to achieve this here.\nTest Data. To evaluate the correctness of the various algorithms, I plan to use reliable encyclopedic resources on the Web such as Wikipedia [37] or other curated knowledge sources. For an objective evaluation, I propose the following different sources depending on the algorithm under evaluation.\n\u2022 Identify important events\n\u2013 Events in a particular year/decade etc. pages available on Wikipedia [33].\n\u2013 Testing of past events can be done by extracting important topics from Category pages on various historical topics on Wikipedia [35].\n\u2013 Events in the future can be evaluated by using important infrastructure projects, engineering projects etc. These can be extracted from Wikipedia and other sources on the Internet.\n\u2013 Current events extracted from Wikipedia [36].\n\u2013 Alternatively, we can manually construct a list of prominent events and extract relevant information such as named entities, geographical location, and time from ontologies such as: YAGO [30], Freebase [12], etc.\n\u2022 Diversifying and summarizing search events\n\u2013 Biographies of eminent personalities, for example United States presidents [32].\n\u2013 Historical timelines of various countries, for example for India [34].\nStructure. Each event in our test bed is then composed of a fact with an accompanying query. Formally, a fact in our testbed is a 4-tuple extracted from one of the aforementioned sources:\n\u3008q, E , g, t,W\u3009\nwhere q consists of keyword query describing the event, E is a bag of participating entities, g is the geographic location, t is the time of its occurrence, and W are important terms describing the event.\nMetrics. Based on the structure of the testbed of events, metrics such as precision, recall and F1 can be utilized to measure the effectiveness of the algorithms for detecting important events in semantically annotated corpora. How effectively the algorithm diversifies documents along multiple dimensions can be evaluated by metrics such as \u03b1-nDCG [6]. Quality of summaries can be measured by an automatic evaluation metric called Rouge [39]."}, {"heading": "6. DISCUSSION", "text": "I briefly present some open technical challenges that I will address along with the research objectives in my PhD dissertation.\nMathematical Models. One key aspect that occurs in the design of the algorithms is that of computational models for named entities, geographical locations and temporal expressions. What would be the most descriptive mathematical models for each of these semantic annotations?\nSimilarity Functions. Given a pair of named entities, geographical locations or temporal expressions; how can we efficiently compute the similarity between the same type of annotations?\nEfficiency & Scalability. Identifying data structures for indexing corpora along with their semantic annotations, such that their asymptotic run times scale linearly with the size of the corpora.\nEvaluation. Since evaluation of the solutions outlined are very subjective in nature; what are other reliable sources of objective ground truth ? What other metrics can be employed to test the effectiveness of our methods ?"}, {"heading": "7. CONCLUSION", "text": "In this article I laid out an outline of the research work that I envisage to carry out for my PhD dissertation. The research would in its culmination provide us methods to computationally extract world history as sequence of temporally ordered events and portray future events to take place from semantically annotated corpora. The research would also provide ways to perform semantic search and large scale event analytics on these annotated corpora. I further described already available resources that can be utilized for carrying out the research; test cases that can be built from encyclopedic resources on the Internet; and the metrics that can be utilized for evaluation."}, {"heading": "8. REFERENCES", "text": "[1] Clueweb\u201909. [Online; accessed 26-August-2015] http://www.lemurproject.org/clueweb09.php/. [2] Clueweb\u201912. [Online; accessed 26-August-2015] http://www.lemurproject.org/clueweb12.php/. [3] English gigaword. [Online; accessed 26-August-2015] https://catalog.ldc.upenn.edu/LDC2003T05. [4] New york times anotated corpus. [Online; accessed 26-August-2015] https://catalog.ldc.upenn.edu/LDC2008T19. [5] Abujabal A. and Berberich K. Important events in the past, present, and future. WWW\u201915 Companion Volume. [6] Agrawal R. et al. Diversifying search results. WSDM\u201909. [7] Allan J., editor. Topic Detection and Tracking:\nEvent-based Information Organization. Kluwer Academic Publishers, Norwell, MA, USA, 2002. [8] Baeza-Yates R. Searching the future. SIGIR\u201905 Workshop MF/IR. [9] Bast H. and Buchhold B. An index for efficient semantic full-text search. CIKM\u201913.\n[10] Berberich K. et al. A language modeling approach for temporal information needs. ECIR\u201910. [11] Berberich K. and Bedathur S. Temporal diversification of search results. TAIA\u201913. [12] Bollacker K. et al. Freebase: A collaboratively created graph database for structuring human knowledge. SIGMOD\u201908.\n[13] Chang A. X. and Manning C. D. SUTIME: A library for recognizing and normalizing time expressions. LREC\u201912. [14] Ringgaard M. et al. Facc1: Freebase annotation of clueweb corpora, version 1 (release date 2013-06-26, format version 1, correction level 0), June 2013. http://lemurproject.org/clueweb12/. [15] Gupta D. and Berberich K. Temporal query classification at different granularities. SPIRE\u201915. [16] Han J. et al. Data Mining: Concepts and Techniques. Morgan Kaufmann Publishers Inc., San Francisco, CA, USA, 3rd edition, 2011. [17] Hoffart J. et al. AESTHETICS: analytics with strings, things, and cats. CIKM\u201914. [18] Hoffart J. et al. STICS: searching with strings, things, and cats. SIGIR\u201914. [19] Hoffart J. et al. Robust disambiguation of named entities in text. EMNLP\u201911. [20] Jatowt A. and Yeung C. A. Extracting collective expectations about the future from large text collections. CIKM\u201911. [21] Jones R. and Diaz F. Temporal profiles of queries. ACM Trans. Inf. Syst., 25(3), July 2007. [22] Kanhabua N. and N\u00f8rv\u030aag K. Determining time of queries for re-ranking search results. ECDL\u201910. [23] Ling X. and Weld D. S. Temporal information extraction. AAAI\u201910. [24] Michel J. B. et al. Quantitative analysis of culture using millions of digitized books. Science\u201910. [25] Nguyen T. N. and Kanhabua N. Leveraging dynamic query subtopics for time-aware search result diversification. ECIR\u201914. [26] Radinsky K. et al. Learning to predict from textual data. J. Artif. Intell. Res. (JAIR), 45:641\u2013684, 2012. [27] Samet H. et al. Reading news with maps by exploiting spatial synonyms. Commun. ACM, 57(10):64\u201377, 2014. [28] Stro\u0308tgen J. and Gertz M. Event-centric search and exploration in document collections. JCDL\u201912. [29] Stro\u0308tgen J. and Gertz M. Multilingual and cross-domain temporal tagging. Language Resources and Evaluation, 47(2):269\u2013298, 2013. [30] Suchanek F. M. et al. Yago: A large ontology from wikipedia and wordnet. Web Semant., 6(3):203\u2013217, September 2008. [31] Swan R. C. and Allan J. Automatic generation of overview timelines. SIGIR\u201900. [32] Wikipedia. List of presidents of the united states \u2014 Wikipedia, the free encyclopedia, 2015. [Online; accessed 26-August-2015]https://en.wikipedia.org/wiki/List_of_ Presidents_of_the_United_States. [33] Wikipedia. List of years \u2014 Wikipedia, the free encyclopedia, 2015. [Online; accessed 26-August2015]https://en.wikipedia.org/wiki/List_of_years. [34] Wikipedia. List of years in india \u2014 Wikipedia, the free encyclopedia, 2015. [Online; accessed 26-August-2015] https: //en.wikipedia.org/wiki/List_of_years_in_India. [35] Wikipedia. Portal:contents/history and events \u2014 Wikipedia, the free encyclopedia, 2015. [Online; accessed 26-August-2015]https://en.wikipedia.org/wiki/Portal: Contents/History_and_events. [36] Wikipedia. Portal:current events \u2014 Wikipedia, the free encyclopedia, 2015. [Online; accessed 26-August-2015]https://en.wikipedia.org/wiki/Portal: Contents/History_and_events. [37] Wikipedia. Wikipedia, the free encyclopedia, 2015. [Online; accessed 26-August-2015]http://en.wikipedia.org/. [38] Yeung C. A. and Jatowt A. Studying how the past is remembered: towards computational history through large scale text mining. CIKM\u201911. [39] Lin C. Y. Rouge: a package for automatic evaluation of summaries. ACL-04 workshop."}], "references": [{"title": "Topic Detection and Tracking: Event-based Information Organization", "author": ["Allan J", "editor"], "venue": null, "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2002}, {"title": "Facc1: Freebase annotation of clueweb corpora, version 1 (release date 2013-06-26, format version 1, correction level", "author": ["M Ringgaard"], "venue": null, "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2013}, {"title": "Data Mining: Concepts and Techniques", "author": ["J Han"], "venue": null, "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2011}, {"title": "Temporal profiles of queries", "author": ["R. Jones", "F. Diaz"], "venue": "ACM Trans. Inf. Syst.,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2007}, {"title": "Learning to predict from textual data", "author": ["K Radinsky"], "venue": "J. Artif. Intell. Res. (JAIR),", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2012}, {"title": "Reading news with maps by exploiting spatial synonyms", "author": ["H Samet"], "venue": "Commun. ACM,", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2014}, {"title": "Multilingual and cross-domain temporal tagging", "author": ["J. Str\u00f6tgen", "M. Gertz"], "venue": "Language Resources and Evaluation,", "citeRegEx": "29", "shortCiteRegEx": "29", "year": 2013}, {"title": "Yago: A large ontology from wikipedia and wordnet", "author": ["M Suchanek F"], "venue": "Web Semant.,", "citeRegEx": "30", "shortCiteRegEx": "30", "year": 2008}], "referenceMentions": [{"referenceID": 3, "context": "Some methods of analysis of time-sensitive queries rely on publication dates of documents [21, 22], while others also look at the temporal expressions in document contents [15].", "startOffset": 90, "endOffset": 98}, {"referenceID": 0, "context": "One of the most important seminal works in identifying existing and emerging events were the various tasks in Topic Detection and Tracking (TDT) [7].", "startOffset": 145, "endOffset": 148}, {"referenceID": 4, "context": "[26] present an algorithm Pundit, which based on the past events in text is able to predict a future event given a query to the system.", "startOffset": 0, "endOffset": 4}, {"referenceID": 5, "context": "[27] present a system NewsStand, that is able to resolve and pinpoint a news article based on the geographic information present in its content.", "startOffset": 0, "endOffset": 4}, {"referenceID": 2, "context": "This can jointly be modeled by using the concept of a data cube [16] as shown in Figure 3.", "startOffset": 64, "endOffset": 68}, {"referenceID": 2, "context": "Formally, given a query Q, the objective would to first model the mined set of events as a data cube and subsequently provide data cube operations [16]:", "startOffset": 147, "endOffset": 151}, {"referenceID": 7, "context": "For disambiguating and linking named entities in text to an external knowledge source such as Wikipedia [37] or an ontology such as YAGO [30] or Freebase [12]; I use the AIDA system [19].", "startOffset": 137, "endOffset": 141}, {"referenceID": 1, "context": "For Web collections such ClueWeb\u201909/\u201912 the entity disambiguation and linking has been released as facc1 : Freebase annotation of ClueWeb Corpora [14].", "startOffset": 146, "endOffset": 150}, {"referenceID": 6, "context": "Temporal Expressions, both implicit and explicit, can be extracted and normalized from text by using temporal taggers such as HeidelTime [29] or SUTime [13].", "startOffset": 137, "endOffset": 141}, {"referenceID": 7, "context": "\u2013 Alternatively, we can manually construct a list of prominent events and extract relevant information such as named entities, geographical location, and time from ontologies such as: YAGO [30], Freebase [12], etc.", "startOffset": 189, "endOffset": 193}], "year": 2016, "abstractText": "In this article, I present the questions that I seek to answer in my PhD research. I posit to analyze natural language text with the help of semantic annotations and mine important events for navigating large text corpora. Semantic annotations such as named entities, geographic locations, and temporal expressions can help us mine events from the given corpora. These events thus provide us with useful means to discover the locked knowledge in them. I pose three problems that can help unlock this knowledge vault in semantically annotated text corpora: i. identifying important events; ii. semantic search; and iii. event analytics.", "creator": "LaTeX with hyperref package"}}}