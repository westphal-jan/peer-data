{"id": "1603.02010", "review": {"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "7-Mar-2016", "title": "Differentially Private Policy Evaluation", "abstract": "We present the first differentially private algorithms for reinforcement learning, which apply to the task of evaluating a fixed policy. We establish two approaches for achieving differential privacy, provide a theoretical analysis of the privacy and utility of the two algorithms, and show promising results on simple empirical examples. In the next two years we will expand our approach to identifying and treating adversarial information. In the next two years we will introduce two more approaches to the problem of estimating the privacy of the public sector, namely the problem of comparing the public sector with private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private sector private", "histories": [["v1", "Mon, 7 Mar 2016 11:23:57 GMT  (174kb,D)", "http://arxiv.org/abs/1603.02010v1", null]], "reviews": [], "SUBJECTS": "cs.LG stat.ML", "authors": ["borja balle", "maziar gomrokchi", "doina precup"], "accepted": true, "id": "1603.02010"}, "pdf": {"name": "1603.02010.pdf", "metadata": {"source": "CRF", "title": "Differentially Private Policy Evaluation\u2217", "authors": ["Borja Balle", "Maziar Gomrokchi", "Doina Precup"], "emails": ["b.deballepigem@lancaster.ac.uk"], "sections": [{"heading": "1 Introduction", "text": "Learning how to make decisions under uncertainty is becoming paramount in many practical applications, such as medical treatment design, energy management, adaptive user interfaces, recommender systems etc. Reinforcement learning [Sutton and Barto, 1998] provides a variety of algorithms capable of handling such tasks. However, in many practical applications, aside from obtaining good predictive performance, one might also require that the data used to learn the predictor be kept confidential. This is especially true in medical applications, where patient confidentiality is very important, and in other applications which are user-centric (such as recommender systems). Differential privacy (DP) [Dwork, 2006] is a very active research area, originating from cryptography, but which has now been embraced by the machine learning community. DP is a formal model of privacy used to design mechanisms that reduce the amount of information leaked by the result of queries to a database containing sensitive information about multiple users [Dwork, 2006]. Many supervised learning algorithms have differentially private versions, including logistic regression [Chaudhuri and Monteleoni, 2009, Chaudhuri et al., 2011], support vector machines [Chaudhuri et al., 2011, Rubinstein et al., 2012, Jain and Thakurta, 2013], and the lasso [Thakurta and Smith, 2013]. However, differential privacy for reinforcement learning tasks has not been tackled yet, except for the simpler case of bandit problems [Smith and Thakurta, 2013, Mishra and Thakurta, 2015, Tossou and Dimitrakakis, 2016].\nIn this paper, we tackle differential privacy for reinforcement learning algorithms for the full Markov Decision Process (MDP) setting. We develop differentially private algorithms for the problem of policy evaluation, in which a given way of behaving has to be evaluated quantitatively. We start with the batch, first-visit Monte Carlo approach to policy evaluation, which is well understood and closest to regression algorithms, and provide two differentially private versions, which come with formal privacy proofs as well as guarantees on the quality of the solution obtained. Both\n\u2217Corresponding e-mail: b.deballepigem@lancaster.ac.uk\nar X\niv :1\n60 3.\n02 01\n0v 1\n[ cs\n.L G\n] 7\nM ar\n2 01\nalgorithms work by injecting Gaussian noise into the parameters vector for the value functions, but they differ in the definition of the noise amount. Our privacy analysis techniques are related to previous output perturbation for empirical risk minimization (ERM), but there are some domain specific challenges that need to be addressed. Our utility analysis identifies parameters of the MDP that control how easy it is to maintain privacy in each case. The theoretical utility analysis, as well as some illustrative experiments, show that the accuracy of the private algorithms does not suffer (compared to usual Monte Carlo) when the data set is large.\nThe rest of the paper is organized as follows. In Sec. 2 we provide background notation and results on differential privacy and Monte Carlo methods for policy evaluation. Sec. 3 presents our proposed algorithms. The privacy analysis and the utility analysis are outlined in Sec. 4 and Sec. 5 respectively. Detailed proofs for both of these sections are given in the Supplementary Material. In Sec. 6 we provide empirical illustrations of the scaling behaviour of the proposal algorithms, using synthetic MDPs, which try to mimic characteristics of real applications. Finally, we conclude in Sec. 7 with a discussion of related work and avenues for future work."}, {"heading": "2 Background", "text": "In this section we provide background on differential privacy and policy evaluation from Monte Carlo estimates."}, {"heading": "2.1 Differential Privacy", "text": "DP takes a user-centric approach, by providing privacy guarantees based on the difference of the outputs of a learning algorithm trained on two databases differing in a single user. The central goal is to bound the loss in privacy that a user can suffer when the result of an analysis on a database with her data is made public. This can incentivize users to participate in studies using sensitive data, e.g. mining of medical records. In the context of machine learning, differentially private algorithms are useful because they allow learning models in such a way that their parameters do not reveal information about the training data [McSherry and Talwar, 2007]. For example, one can think of using historical medical records to learn prognostic and diagnostic models which can then be shared between multiple health service providers without compromising the privacy of the patients whose data was used to train the model.\nTo formalize the above discussion, let X be an input space and Y an output space. Suppose A is a randomized algorithm that takes as input a tuple X = (x1, . . . , xm) of elements from X for some m \u2265 1 and outputs a (random) element A(X) of Y. We interpret X \u2208 Xm as a dataset containing data from m individuals and define its neighbouring datasets as those that differ from X in their last1 element: X \u2032 = (x1, . . . , xm\u22121, x \u2032 m) with xm 6= x\u2032m. We denote this (symmetric) relation by X ' X \u2032. A is (\u03b5, \u03b4)-differentially private for some \u03b5, \u03b4 > 0 if for every m \u2265 1, every pair of datasets X,X \u2032 \u2208 Xm, X ' X \u2032, and every measurable set \u2126 \u2286 Y we have\nP[A(X) \u2208 \u2126] \u2264 e\u03b5P[A(X \u2032) \u2208 \u2126] + \u03b4 . (1) 1Formally, we should define neighbouring datasets as those which differ in one element, not necessarily the last. But we are implicitly assuming here that the order of the elements in X does not affect the distribution of A(X), so we can assume without loss of generality that the difference between neighbouring datasets is always in the last element.\nThis definition means that the distribution over possible outputs of A on inputs X and X \u2032 is very similar, so revealing this output leaks almost no information on whether xm or x \u2032 m was in the dataset. A simple way to design a DP algorithm for a given function f : Xm \u2192 Y is the output perturbation mechanism, which releases A(X) = f(X) + \u03b7, where \u03b7 is noise sampled from a properly calibrated distribution. For real outputs Y = Rd, the Laplace (resp. Gaussian) mechanism (see e.g. Dwork and Roth [2014]) samples each component of the noise \u03b7 = (\u03b71, . . . , \u03b7d) i.i.d. from a Laplace (resp. Gaussian) distribution with standard deviation O(GS1(f)/\u03b5) (resp. O(GS2(f) ln(1/\u03b4)/\u03b5)), where GSp(f) is the global sensitivity of f given by\nGSp(f) = sup X,X\u2032\u2208Xm,X'X\u2032\n\u2016f(X)\u2212 f(X \u2032)\u2016p .\nCalibrating noise to the global sensitivity is a worst-case approach that requires taking the supremum over all possible pairs of neighbouring datasets, and in general does not account for the fact that in some datasets privacy can be achieved with substantially smaller perturbations. In fact, for many applications (like the one we consider in this paper) the global sensitivity is too large to provide useful mechanisms. Ideally one would like to add perturbations proportional to the potential changes around the input dataset X, as measured, for example by the local sensitivity LSp(f,X) = supX\u2032'X \u2016f(X)\u2212 f(X \u2032)\u2016p. Nissim et al. [2007] showed that approaches based on LSp do not lead to differentially private algorithms, and then proposed an alternative framework for DP mechanisms with data-dependent perturbations based on the idea of smoothed sensitivity. This is the approach we use in this paper; see Section 4 for further details."}, {"heading": "2.2 Policy Evaluation", "text": "Policy evaluation is the problem of obtaining (an approximation to) the value function of a Markov reward process defined by an MDP M and a policy \u03c0 [Sutton and Barto, 1998, Szepesva\u0301ri, 2010]. In many cases of interest M is unknown but we have access to trajectories containing state transitions and immediate rewards sampled from \u03c0. When the state space of M is relatively small, tabular methods that represent the value of each state can be used individually. However, in problems with large (or even continuous) state spaces, parametric representations for the value function are typically needed in order to defeat the curse of dimensionality and exploit the fact that similar states will have similar values. In this paper we focus on policy evaluation with linear function approximation in the batch case, where we have access to a set of trajectories sampled from the policy of interest.\nLet M be an MDP over a finite state space S with N = |S| and \u03c0 a policy on M . Given an initial state s0 \u2208 S, the interaction of \u03c0 with M is described by a sequence ((st, at, rt))t\u22650 of state\u2013action\u2013reward triplets. Suppose 0 < \u03b3 < 1 is the discount factor of M . The value function V \u03c0 : S \u2192 R of \u03c0 assigns to each state the expected discounted cumulative reward obtained by a trajectory following policy \u03c0 from that state:\nV \u03c0(s) = EM,\u03c0 [\u2211 t\u22650 \u03b3 trt \u2223\u2223\u2223 s0 = s ] . (2) The value function can be considered a vector V \u03c0 \u2208 RS . We make the usual assumption that any reward r generated by M is bounded: 0 \u2264 r \u2264 Rmax, so 0 \u2264 V \u03c0(s) \u2264 Rmax/(1\u2212 \u03b3) for all s \u2208 S.\nLet \u03a6 \u2208 RS\u00d7d be a feature representation that associates each state s \u2208 S to a d-dimensional feature vector \u03c6>s = \u03a6(s, :) \u2208 Rd. The goal is to find a parameter vector \u03b8 \u2208 Rd such that V\u0302 \u03c0 = \u03a6\u03b8 is a good approximation to V \u03c0. To do so, we assume that we have access to a collection X = (x1, . . . , xm) of finite trajectories sampled from M by \u03c0, where each xi is a sequence of states, actions and rewards.\nWe will use a Monte Carlo approach, in which the returns of the trajectories in X are used as regression targets to fit the parameters in V\u0302 \u03c0 via a least squares approach [Sutton and Barto, 1998]. In particular, we consider first-visit Monte Carlo estimates obtained as follows. Suppose x = ((s1, a1, r1), . . . , (sT , aT , rT )) is a trajectory that visits s and ix,s is the time of the first visit to s; that is, six,s = s, and st 6= s for all t < ix,s. The return collected from this first visit is given by\nFx,s = T\u2211\nt=ix,s\nrt\u03b3 t\u2212ix,s = T\u2212ix,s\u2211 t=0 rt+ix,s\u03b3 t ,\nand provides an unbiased estimate of V \u03c0(s). For convenience, when state s is not visited by trajectory x we assume Fx,s = 0.\nGiven the returns from all first visits corresponding to a dataset X with m trajectories, we can find a parameter vector for the estimator V\u0302 \u03c0 by solving the optimization problem argmin\u03b8 JX(\u03b8), where\nJX(\u03b8) = 1\nm m\u2211 i=1 \u2211 s\u2208Sxi \u03c1s(Fxi,s \u2212 \u03c6>s \u03b8)2 , (3)\nand Sx is the set of states visited by trajectory x. The regression weights 0 \u2264 \u03c1s \u2264 1 are given as an input to the problem and capture the user\u2019s believe that some states are more relevant than others. It is obvious that JX(\u03b8) is a convex function of \u03b8. However, in general it is not strongly convex and therefore the optimum of argmin\u03b8 JX(\u03b8) is not necessarily unique. On the other hand, it is known that differential privacy is tightly related to certain notions of stability [Thakurta and Smith, 2013], and optimization problems with non-unique solutions generally pose a problem to stability. In order to avoid this problem, the private policy evaluation algorithms that we propose in Section 3 are based on optimizing slightly modified versions of JX(\u03b8) which promote stability in their solutions. Note that the notions of stability related to DP are for worst-case situations: that is, they need to hold for every possible pair of neighbouring input dataset X ' X \u2032, regardless of any generative model assumed for the trajectories in those datasets. In particular, these stability considerations are not directly related to the variance of the estimates in V\u0302 \u03c0.\nWe end this section with a discussion of the main obstruction to stability, i.e. the cases where argmin\u03b8 JX(\u03b8) fails to have a unique solution. Given a dataset X with m trajectories we define a vector FX \u2208 RS containing the average first visit returns from all trajectories in X that visit a particular state. In particular, if Xs represents the multiset of trajectories from X that visit state s at some point, then we have\nFX(s) = FX,s = 1 |Xs| \u2211 x\u2208Xs Fx,s . (4)\nIf s is not visited by any trajectory in X we set FX,s = 0. To simplify notation, let FX \u2208 RS be the vector collecting all these estimates. We also define a diagonal matrix \u0393X \u2208 RS\u00d7S with entries given by the product of the regression weight on each state and the fraction of trajectories in X\nvisiting that state: \u0393X(s, s) = \u03c1s|Xs|/m. Solving for \u03b8 in \u2207\u03b8JX(\u03b8) = 0, it is easy to see that any optimal \u03b8X \u2208 argmin\u03b8 JX(\u03b8) must satisfy\n\u03a6>\u0393X\u03a6\u03b8X = \u03a6 >\u0393XFX . (5)\nThus, this optimization has a unique solution if and only if the matrix \u03a6>\u0393X\u03a6 is invertible. Since it is easy to find neighbouring datasets X ' X \u2032 where at most one of \u03a6>\u0393X\u03a6 and \u03a6>\u0393X\u2032\u03a6 is invertible, optimizing JX(\u03b8) directly poses a problem to the design differentially private policy evaluation algorithms with small perturbations. Next we present two DP algorithm based on stable policy evaluation algorithms."}, {"heading": "3 Private First-Visit Monte Carlo Algorithms", "text": "In this section we give the details of two differentially private policy evaluation algorithms based on first-visit Monte Carlo estimates. Each of these algorithms corresponds to a different stable version of the minimization argmin\u03b8 JX(\u03b8) described in previous section. A formal privacy analysis of these algorithms is given in Section 4. Bounds showing how the privacy requirement affects the utility of the value estimates are presented in Section 5."}, {"heading": "3.1 Algorithm DP-LSW", "text": "One way to make the optimization argmin\u03b8 JX(\u03b8) more stable to changes in the dataset X is to consider a similar least-squares optimization where the optimization weights do not change with X, and guarantee that the optimization problem is always strongly convex. Thus, we consider a new objective function given in terms of a new set of positive regression weights ws > 0. Let \u0393 \u2208 RS\u00d7S be a diagonal matrix with \u0393(s, s) = ws. We define the objective function as:\nJwX(\u03b8) = \u2211 s\u2208S ws(FX,s \u2212 \u03c6>s \u03b8)2 = \u2016FX \u2212 \u03a6\u03b8\u201622,\u0393 , (6)\nwhere \u2016v\u201622,\u0393 = \u2016\u03931/2v\u201622 = v>\u0393v is the weighted L2 norm. To see the relation between the optimizations over JX and J w X , note that equating the gradient of J w X(\u03b8) to 0 we see that a minimum \u03b8wX \u2208 argmin\u03b8 JwX(\u03b8) must satisfy \u03a6>\u0393\u03a6\u03b8wX = \u03a6 >\u0393FX . (7) Thus, the optimization problem is well-posed whenever \u03a6>\u0393\u03a6 is invertible, which henceforth will be our working assumption. Note that this is a mild assumption, since it is satisfied by choosing a feature matrix \u03a6 with full column rank. Under this assumption we have:\n\u03b8wX = ( \u03a6>\u0393\u03a6 )\u22121 \u03a6>\u0393FX = ( \u03931/2\u03a6 )\u2020 \u03931/2FX , (8)\nwhere M \u2020 denotes the Moore\u2013Penrose pseudo-inverse. The difference between optimizing JX(\u03b8) or JwX(\u03b8) is reflected in the differences between (5) and (7). In particular, if the trajectories in X are i.i.d. and ps denotes the probability that state s is visited by a trajectory in X, then taking ws = EX [\u03c1s|Xs|/m] = \u03c1sps yields a loss function JwX(\u03b8) that captures the effect of each state s in JX(\u03b8) in the asymptotic regime m \u2192 \u221e. However, we note that knowledge of these visit probabilities is not required for running our algorithm or for our analysis.\nOur first DP algorithm for policy evaluation applies a carefully calibrated output perturbation mechanism to the solution \u03b8wX of argmin\u03b8 J w X(\u03b8). We call this algorithm DP-LSW, and its full pseudo-code is given in Algorithm 1. It receives as input the dataset X, the regression weights w, the feature representation \u03a6, and the MDP parameters Rmax and \u03b3. Additionally, the algorithm is parametrized by the privacy parameters \u03b5 and \u03b4. Its output is the result of adding a random vector \u03b7 drawn from a multivariate Gaussian distribution N (0, \u03c32XI) to the parameter vector \u03b8wX . In order to compute the variance of \u03b7 the algorithm needs to solve the discrete optimization problem \u03c8wX = max0\u2264k\u2264KX e\n\u2212k\u03b2\u03d5wX(k), where KX = maxs\u2208S |Xs|, \u03b2 is a parameter computed in the algorithm, and \u03d5wX(k) is given by the following expression:\n\u03d5wX(k) = \u2211 s\u2208S ws max{|Xs| \u2212 k, 1}2 . (9)\nNote that \u03c8wX can be computed in time O(KXN).\nAlgorithm 1: DP-LSW\nInput: X, \u03a6, \u03b3, Rmax, w, \u03b5, \u03b4 Output: \u03b8\u0302wX Compute \u03b8wX ; // cf. (8)\nLet \u03b1\u2190 5 \u221a 2 ln(2/\u03b4)\n\u03b5 and \u03b2 \u2190 \u03b5 4(d+ln(2/\u03b4)) ;\nLet \u03c8wX \u2190 max0\u2264k\u2264KX e\u2212k\u03b2\u03d5wX(k) ; // cf. (9) Let \u03c3X \u2190 \u03b1Rmax\u2016(\u0393 1/2\u03a6)\u2020\u2016 1\u2212\u03b3 \u221a \u03c8wX ; Sample a d-dimensional vector \u03b7 \u223c N (0, \u03c32XI); Return \u03b8\u0302wX = \u03b8 w X + \u03b7;\nThe variance of the noise in DP-LSW is proportional to the upper bound Rmax/(1\u2212 \u03b3) on the return from any state. This bound might be excessively pessimistic in some applications, leading to unnecessary large perturbation of the solution \u03b8wX . Fortunately, it is possible to replace the term Rmax/(1\u2212 \u03b3) with any smaller upper bound Fmax on the returns generated by the target MDP on any state. In practice this leads to more useful algorithms, but it is important to keep in mind that for the privacy guarantees to remain unaffected, one needs to assume that Fmax is a publicly known quantity (i.e. it is not based on an estimate made from private data). These same considerations apply to the algorithm in the next section."}, {"heading": "3.2 Algorithm DP-LSL", "text": "The second DP algorithm for policy evaluation we propose is also an output perturbation mechanism. It differs from DP-LSW in they way stability of the unperturbed solutions is promoted. In this case, we choose to optimize a regularized version of JX(\u03b8). In particular, we consider the objective function J\u03bbX(\u03b8) obtained by adding a ridge penalty to the least-squares loss from (3):\nJ\u03bbX(\u03b8) = JX(\u03b8) + \u03bb\n2m \u2016\u03b8\u201622 , (10)\nwhere \u03bb > 0 is a regularization parameter. The introduction of the ridge penalty makes the objective function J\u03bbX(\u03b8) strongly convex, and thus ensures the existence of a unique solution\n\u03b8\u03bbX = argmin\u03b8 J \u03bb X(\u03b8), which can be obtained in closed-form as:\n\u03b8\u03bbX = ( \u03a6>\u0393X\u03a6 + \u03bb\n2m I\n)\u22121 \u03a6>\u0393XFX . (11)\nHere \u0393X is defined as in Section 2.2. We call DP-LSL the algorithm obtained by applying an output perturbation mechanism to the minimizer of J\u03bbX(\u03b8); the full pseudo-code is given in Algorithm 2. It receives as input the privacy parameters \u03b5 and \u03b4, a dataset of trajectories X, the regression weights \u03c1, the feature representation \u03a6, a regularization parameter \u03bb > \u2016\u03a6\u20162\u2016\u03c1\u2016\u221e, and the MDP parameters Rmax and \u03b3. After computing the solution \u03b8\u03bbX to argmin\u03b8 J \u03bb X(\u03b8), the algorithm outputs \u03b8\u0302 \u03bb X = \u03b8 \u03bb X + \u03b7, where \u03b7 is a d-dimensional noise vector drawn from N (0, \u03c32XI). The variance of \u03b7 is obtained by solving a discrete optimization problem (different from the one in DP-LSW). Let c\u03bb = \u2016\u03a6\u2016\u2016\u03c1\u2016\u221e/ \u221a 2\u03bb and for k \u2265 0, define \u03d5\u03bbX(k) as: c\u03bb\u221a\u2211 s \u03c1s min{|Xs|+ k,m}+ \u2016\u03c1\u20162\n2 . (12) Then DP-LSL computes \u03c8\u03bbX = max0\u2264k\u2264m e \u2212k\u03b2\u03d5\u03bbX(k), which can be done in time O(mN).\nAlgorithm 2: DP-LSL\nInput: X, \u03a6, \u03b3, Rmax, \u03c1, \u03bb, \u03b5, \u03b4 Output: \u03b8\u0302\u03bbX Compute \u03b8\u03bbX ; // cf. (11)\nLet \u03b1\u2190 5 \u221a 2 ln(2/\u03b4)\n\u03b5 and \u03b2 \u2190 \u03b5 4(d+ln(2/\u03b4)) ;\nLet \u03c8\u03bbX \u2190 max0\u2264k\u2264m e\u2212k\u03b2\u03d5\u03bbX(k) ; // cf. (12) Let \u03c3X \u2190 2\u03b1Rmax\u2016\u03a6\u2016(1\u2212\u03b3)(\u03bb\u2212\u2016\u03a6\u20162\u2016\u03c1\u2016\u221e) \u221a \u03c8\u03bbX ; Sample a d-dimensional vector \u03b7 \u223c N (0, \u03c32XI); Return \u03b8\u0302\u03bbX = \u03b8 \u03bb X + \u03b7;"}, {"heading": "4 Privacy Analysis", "text": "This section provides a formal privacy analysis for DP-LSW and DP-LSL and shows that both algorithms are (\u03b5, \u03b4)-differentially private. We use the smooth sensitivity framework of [Nissim et al., 2007, 2011], which provides tools for the design of DP mechanisms with data-dependent output perturbations. We rely on the following lemma, which provides sufficient conditions for calibrating Gaussian output perturbation mechanisms with variance proportional to smooth upper bounds of the local sensitivity.\nLemma 1 (Nissim et al. [2011]). Let A be an algorithm that on input X computes a vector \u00b5X \u2208 Rd deterministically and then outputs ZX \u223c N (\u00b5X , \u03c32XI), where \u03c32X is a variance that depends on X. Let \u03b1 = \u03b1(\u03b5, \u03b4) = 5 \u221a 2 ln(2/\u03b4)/\u03b5 and \u03b2 = \u03b2(\u03b5, \u03b4, d) = \u03b5/(4d + 4 ln(2/\u03b4)). Suppose \u03b5 and \u03b4 are such that the following are satisfied for every pair of neighbouring datasets X ' X \u2032: (a) \u03c3X \u2265 \u03b1\u2016\u00b5X \u2212 \u00b5X\u2032\u20162, and (b) | ln(\u03c32X)\u2212 ln(\u03c32X\u2032)| \u2264 \u03b2. Then A is (\u03b5, \u03b4)-differentially private.\nCondition (a) says we need variance at least proportional to the local sensitivity LS2(f,X). Condition (b) asks that the variance does not change too fast between neighbouring datasets, by imposing the constraint \u03c32X/\u03c3 2 X\u2032 \u2264 e\u03b2. This is precisely the spirit of the smoothed sensitivity principle: calibrate the noise to a smooth upper bound of the local sensitivity. We acknowledge Lemma 1 is only available in pre-print form, and thus provide an elementary proof in Appendix A for completeness. The remaining proofs from this section are presented Appendices B and C."}, {"heading": "4.1 Privacy Analysis of DP-LSW", "text": "We start by providing an upper bound on the norm \u2016\u03b8wX \u2212 \u03b8wX\u2032\u20162 for any two neighbouring datasets X ' X \u2032. Using (8) it is immediate that:\n\u2016\u03b8wX \u2212 \u03b8wX\u2032\u20162 \u2264 \u2016(\u03931/2\u03a6)\u2020\u2016\u2016FX \u2212 FX\u2032\u20162,\u0393 . (13)\nThus, we need to bound \u2016FX \u2212 FX\u2032\u20162,\u0393.\nLemma 2. Let X ' X \u2032 be two neighbouring datasets of m trajectories with X = (x1, . . . , xm\u22121, x) and X \u2032 = (x1, . . . , xm\u22121, x\n\u2032). Let X\u25e6 = (x1, . . . , xm\u22121). Let Sx (resp. Sx\u2032) denote the set of states visited by x (resp. x\u2032). Then we have\n\u2016FX \u2212 FX\u2032\u20162,\u0393 \u2264 Rmax 1\u2212 \u03b3 \u221a \u2211 s\u2208Sx\u222aSx\u2032 ws (|X\u25e6s |+ 1)2 .\nSince the condition in Lemma 1 needs to hold for any dataset X \u2032 neighbouring X, we take the supremum of the bound above over all neighbours., which yields the following corollary.\nCorollary 3. If X is a dataset of trajectories, then the following holds for every neighbouring dataset X \u2032 ' X:\n\u2016FX \u2212 FX\u2032\u20162,\u0393 \u2264 Rmax 1\u2212 \u03b3 \u221a\u2211 s\u2208S ws max{|Xs|, 1}2 .\nUsing this result we see that in order to satisfy item (a) of Lemma 1 we can choose a noise variance satisfying:\n\u03c3X \u2265 \u03b1Rmax\u2016(\u03931/2\u03a6)\u2020\u2016\n1\u2212 \u03b3\n\u221a\u2211 s\u2208S ws max{|Xs|, 1}2 , (14)\nwhere only the last multiplicative term depends on the dataset X, and the rest can be regarded as a constant that depends on parameters of the problem which are either public or chosen by the user, and will not change for a neighbouring dataset X \u2032. Thus, we are left with a lower bound expressible as \u03c3X \u2265 C \u221a \u03d5wX , where \u03d5 w X = \u2211 s(ws/max{|Xs|, 1}2) only depends on the dataset X through its signature \u3008X\u3009 \u2208 NS given by the number of times each state appears in the trajectories of X: \u3008X\u3009(s) = |Xs|. Accordingly, we write \u03d5wX = \u03d5w(\u3008X\u3009), where \u03d5w : NS \u2192 R is the function\n\u03d5w(v) = \u2211 s ws max{vs, 1}2 . (15)\nThe signatures of two neighbouring datasets X ' X \u2032 satisfy \u2016\u3008X\u3009 \u2212 \u3008X \u2032\u3009\u2016\u221e \u2264 1 because replacing a single trajectory can only change by one the number of first visits to any particular\nstate. Thus, assuming we have a function \u03c8 : NS \u2192 R satisfying \u03c8w(v) \u2265 \u03d5w(v) and | ln(\u03c8w(v))\u2212 ln(\u03c8w(v\u2032))| \u2264 \u03b2 for all v, v\u2032 \u2208 NS with \u2016v\u2212v\u2032\u2016\u221e \u2264 1, we can take \u03c3X = C \u221a \u03c8w(\u3008X\u3009). This variance clearly satisfies the conditions of Lemma 1 since\n| ln(\u03c32X)\u2212 ln(\u03c32X\u2032)| = | ln(\u03c8w(\u3008X\u3009))\u2212 ln(\u03c8w(\u3008X \u2032\u3009))| \u2264 \u03b2 .\nThe function \u03c8w is known as a \u03b2-smooth upper bound of \u03d5w, and the following result provides a tool for constructing such functions.\nLemma 4 (Nissim et al. [2007]). Let \u03d5 : NS \u2192 R. For any k \u2265 0 let \u03d5k(v) = max\u2016v\u2212v\u2032\u2016\u221e\u2264k \u03d5(v\u2032). Given \u03b2 > 0, the smallest \u03b2-smooth upper bound of \u03d5 is the function\n\u03c8(v) = sup k\u22650\n( e\u2212k\u03b2\u03d5k(v) ) . (16)\nFor some functions \u03d5, the upper bound \u03c8 can be hard to compute or even approximate [Nissim et al., 2007]. Fortunately, in our case a simple inspection of (15) reveals that \u03d5wk (v) is easy to compute. In particular, the following lemma implies that \u03c8w(v) can be obtained in time O(N\u2016v\u2016\u221e).\nLemma 5. The following holds for every v \u2208 NS : \u03d5wk (v) = \u2211 s\u2208S ws max{vs \u2212 k, 1}2 .\nFurthermore, for every k \u2265 \u2016v\u2016\u221e \u2212 1 we have \u03d5wk (v) = \u2211 sws.\nCombining the last two lemmas, we see that the quantity \u03c8wX computed in DP-LSW is in fact a \u03b2-smooth upper bound to \u03d5wX . Because the variance \u03c3X used in DP-LSW can be obtained by plugging this upper bound into (14), the two conditions of Lemma 1 are satisfied. This completes the proof of the main result of this section:\nTheorem 6. Algorithm DP-LSW is (\u03b5, \u03b4)-differentially private.\nBefore proceeding to the next privacy analysis, note that Corollary 3 is the reason why a mechanism with output perturbations proportional to the global sensitivity is not sufficient in this case. The bound there says that if in the worst case we can find datasets of an arbitrary size m where some states are visited few (or zero) times, then the global sensitivity will not vanish as m\u2192\u221e. Hence, the utility of such algorithm would not improve with the size of the dataset. The smoothed sensitivity approach works around this problem by adding large noise to these datasets, but adding much less noise to datasets where each state appears a sufficient number of times. Corollary 3 also provides the basis for efficiently computing smooth upper bounds to the local sensitivity. In principle, condition (b) in Lemma 1 refers to any dataset neighbouring X, of which there are uncountably many because we consider real rewards. Bounding the local sensitivity in terms of the signature reduces this to finitely many \u201cclasses\u201d of neighbours, and the form of the bound in Corollary 3 makes it possible to apply Lemma 4 efficiently."}, {"heading": "4.2 Privacy Analysis of DP-LSL", "text": "The proof that DP-LSL is differentially private follows the same strategy as for DP-LSW. We start with a lemma that bounds the local sensitivity of \u03b8\u03bbX for pairs of neighbouring datasets X ' X \u2032. We use the notation Is\u2208x for an indicator variable that is equal to one when state s is visited within trajectory x.\nLemma 7. Let X ' X \u2032 be two neighbouring datasets of m trajectories with X = (x1, . . . , xm\u22121, x) and X \u2032 = (x1, . . . , xm\u22121, x\n\u2032). Let Fx \u2208 RS (resp. Fx\u2032 \u2208 RS) be the vector given by Fx(s) = Fx,s (resp. Fx\u2032(s) = Fx\u2032,s). Define diagonal matrices \u0393\u03c1,\u2206x,x\u2032 \u2208 RS\u00d7S given by \u0393\u03c1(s, s) = \u03c1s and \u2206x,x\u2032(s, s) = Is\u2208x \u2212 Is\u2208x\u2032. If the regularization parameter satisfies \u03bb > \u2016\u03a6>\u2206x,x\u2032\u0393\u03c1\u03a6\u2016, then:\n\u2016\u03b8\u03bbX \u2212 \u03b8\u03bbX\u2032\u20162 2 \u2264\n\u2225\u2225\u2225(\u2206x,x\u2032\u03a6\u03b8\u03bbX \u2212 Fx + Fx\u2032)> \u0393\u03c1\u03a6\u2225\u2225\u2225 2\n\u03bb\u2212 \u2016\u03a6>\u2206x,x\u2032\u0393\u03c1\u03a6\u2016 .\nAs before, we need to consider the supremum of the bound over all possible neighbours X \u2032 of X. In particular, we would like to get a bound whose only dependence on the dataset X is through the signature \u3008X\u3009. This is the purpose of the following corollary:\nCorollary 8. Let X be a dataset of trajectories and suppose \u03bb > \u2016\u03a6\u20162\u2016\u03c1\u2016\u221e. Then the following holds for every neighbouring dataset X \u2032 ' X:\n\u2016\u03b8\u03bbX \u2212 \u03b8\u03bbX\u2032\u20162 \u2264 2Rmax\u2016\u03a6\u2016\n(1\u2212 \u03b3)(\u03bb\u2212 \u2016\u03a6\u20162\u2016\u03c1\u2016\u221e)\n\u221a \u03d5\u03bbX ,\nwhere\n\u03d5\u03bbX = \u2016\u03a6\u2016\u2016\u03c1\u2016\u221e\u221a 2\u03bb \u221a\u2211 s\u2208S \u03c1s|Xs|+ \u2016\u03c1\u20162 2 . By the same reasoning of Section 4.1, as long as the regularization parameter is larger than \u2016\u03a6\u20162\u2016\u03c1\u2016\u221e, a differentially private algorithm can be obtained by adding to \u03b8\u03bbX a Gaussian perturbation with a variance satisfying\n\u03c3X \u2265 2\u03b1Rmax\u2016\u03a6\u2016\n(1\u2212 \u03b3)(\u03bb\u2212 \u2016\u03a6\u20162\u2016\u03c1\u2016\u221e)\n\u221a \u03d5\u03bbX\nand the second condition of Lemma 1. This second requirement can be achieved by computing a \u03b2-smooth upper bound of the function \u03d5\u03bb : NS \u2192 R given by\n\u03d5\u03bb(v) = \u2016\u03a6\u2016\u2016\u03c1\u2016\u221e\u221a 2\u03bb \u221a\u2211 s\u2208S \u03c1s max{vs,m}+ \u2016\u03c1\u20162 2 . When going from \u03d5\u03bbX to \u03d5\n\u03bb(v) we substituted |Xs| by max{vs,m} to reflect the fact that any state cannot be visited by more than m trajectories in a dataset X of size m. It turns out that in this case the function \u03d5\u03bbk(v) = max\u2016v\u2212v\u2032\u2016\u221e\u2264k \u03d5 \u03bb(v\u2032) arising in Lemma 4 is also easy to compute. Lemma 9. For every v \u2208 NS , \u03d5\u03bbk(v) is equal to:\u2016\u03a6\u2016\u2016\u03c1\u2016\u221e\u221a 2\u03bb \u221a\u2211 s\u2208S \u03c1s max{vs + k,m}+ \u2016\u03c1\u20162\n2 . Furthermore, for every k \u2265 m\u2212mins vs we have \u03d5\u03bbk(v) = ( \u2016\u03a6\u2016\u2016\u03c1\u2016\u221e \u221a m\u221a\n2\u03bb\n\u221a\u2211 s\u2208S \u03c1s + \u2016\u03c1\u20162 )2 .\nFinally, in view of Lemma 4, Corollary 8, and Lemma 9, the variance of the noise perturbation in DP-LSL satisfies the conditions of Lemma 1, so we have proved the following.\nTheorem 10. Algorithm DP-LSL is (\u03b5, \u03b4)-differentially private."}, {"heading": "5 Utility Analysis", "text": "Because the promise of differential privacy has to hold for any possible pair of neighbouring datasets X ' X \u2032, the analysis in previous section does not assume any generative model for the input dataset X. However, in practical applications we expect X = (x1, . . . , xm) to contain multiple trajectories sampled from the same policy on the same MDP. The purpose of this section is to show that when the trajectories xi are i.i.d. the utility of our differentially private algorithms increases asm\u2192\u221e. In other words, when the input dataset grows, the amount of noise added by our algorithms decreases, thus leading to more accurate estimates of the value function. This matches the intuition that when outputting a fixed number of parameters, using data from more users to estimate these parameters leads to a smaller individual contributions from each user, and makes the privacy constraint easier to satisfy.\nTo measure the utility of our DP algorithms we shall bound the difference in empirical risk between the private and non-private parameters learned from a given dataset. That is, we want to show that the quantity EX,\u03b7[J\u2022X(\u03b8\u0302\u2022X) \u2212 J\u2022X(\u03b8\u2022X)] vanishes as |X| = m \u2192 \u221e, for both \u2022 = w and \u2022 = \u03bb. The first theorem bounds the expected empirical excess risk of DP-LSW. The bound contains two terms: one vanishes as m \u2192 \u221e, and the other reflects the fact that states which are never visited pose a problem to stability. The proof is deferred to Appendix D.\nTheorem 11. Let S0 = {s \u2208 S|ps = 0} and S+ = S \\S0. Let C = \u03b1Rmax\u2016(\u03931/2\u03a6)\u2020\u2016\u2016\u03931/2\u03a6\u2016F /(1\u2212 \u03b3). Suppose \u03b2 \u2264 1/2. Then EX,\u03b7[JwX(\u03b8\u0302wX)\u2212 JwX(\u03b8wX)] is upper bounded by:\nC2 \u2211 s\u2208S0 ws + 6 \u2211 s\u2208S+ ws ( 1 p2sm 2 + \u03b22 ( 1\u2212 \u03b2ps 2 )m) . Note the above bound depends on the dimension d through \u03b2 and \u2016\u03931/2\u03a6\u2016F . In terms of the size of the dataset, we can get excess risk bounds that decreases quadratically with m by assuming that either all states are visited with non-zero probability or the user sets the regression weights so that such states do not contribute to \u03b8wX .\nCorollary 12. If ws = 0 for all s \u2208 S0, then EX,\u03b7[JwX(\u03b8\u0302wX)\u2212 JwX(\u03b8wX)] = O(1/m2).\nA similar theorem can be proved for DP-LSL. However, in this case the statement of the bound is complicated by the appearance of co-occurrence probabilities of the form Px[s \u2208 x \u2227 s\u2032 \u2208 x] and Px[s \u2208 x \u2227 s\u2032 /\u2208 x]. Here we only state the main corollary of our result; the full statement and the corresponding proofs are presented in Appendix E. This corollary is obtained by assuming the regularization parameter is allowed to grow with m, and stresses the tensions in selecting an adequate regularization schedule.\nCorollary 13. Suppose \u03bb = \u03c9(1) with respect to m. Then we have EX,\u03b7[J\u03bbX(\u03b8\u0302\u03bbX) \u2212 J\u03bbX(\u03b8\u03bbX)] = O(1/\u03bbm+ 1/\u03bb2 +m/\u03bb3).\nNote that taking \u03bb = \u0398(m) we get a bound on the excess risk of order O(1/m2). However, if we want the regularization term in J\u03bbX(\u03b8) to vanish as m \u2192 \u221e we need \u03bb = o(m). We shall see importance of this trade-off in our experiments."}, {"heading": "6 Experiments", "text": "In this section we illustrate the behaviour of the proposed algorithms on synthetic examples. The domain we use consists of a chain of N states, where in each state the agent has some probability p of staying and probability (1 \u2212 p) of advancing to its right. There is a reward of 1 when the agent reaches the final, absorbing state, and 0 for all other states. While this is a toy example, it illustrates the typical case of policy evaluation in the medical domain, where patients tend to progress through stages of recovery at different speeds, and past states are not typically revisited (partly because in the medical domain, states contain historic information about past treatments). Trajectories are drawn by starting in an initial state distribution and generating state-action-reward transitions according to the described probabilities until the absorbing state is reached. Trajectories are harvested in a batch, and the same batches are processed by all algorithms.\nWe experiment with both a tabular representation of the value function, as well as with function approximation. In the latter case, we simply aggregate pairs of adjacent states, which are hence forced to take the same value. We compared the proposed private algorithms DP-LSW and DPLSL with their non-private equivalents LSW and LSL. The performance measure used is average root mean squared error over the state space. The error is obtained by comparing the state values estimated by the learning algorithms against the exact values obtained by exact, tabular dynamic programming. Standard errors computed over 20 independent runs are included.\nThe main results are summarized in Fig. 1, for an environment with N = 40 states, p = 0.5, discount \u03b3 = 0.99, and for the DP algorithms, \u03b5 = 0.1 and \u03b4 = 0.1. In general, these constants should be chosen depending on the privacy constraints of the domain. Our theoretical results explain the expected effect of these choices on the privacy-utility trade-off so we do not provide extensive experiments with different values.\nThe left plot in Fig. 1 compares the non-private LSL and LSW versions of Monte Carlo evaluation, in the tabular and function approximation case. As can be seen, both algorithms are very stable and converge to the same solution, but LSW converges faster. The second plot compares the performance of all algorithms in the tabular case, over a range of regularization parameters, for two different batch sizes. The third plot compares the expected RMSE of the algorithms when run with state aggregation, as a function of batch size. As can be seen, the DP algorithms converge to the same solutions as the non-private corresponding versions for large enough batch sizes. Interestingly, the two proposed approaches serve different needs. The LSL algorithms work better with small batches of data, whereas the LSW approach is preferable with large batches. From an empirical point of view, the trade-off between accuracy and privacy in the DP-LSL algorithm should be done by setting a regularization schedule proportional to \u221a m. While the theory suggests it is not the\nbest schedule in terms of excess empirical risk, it achieves the best overall accuracy. Finally, the last figure shows excess empirical risk as a function of the batch size. Interestingly, more aggressive function approximation helps both differentially private algorithms converge faster. This is intuitive, since using the same data to estimate fewer parameters means the effect of each individual trajectory is already obscured by the function approximation. Decreasing the number of parameters of the function approximator, d, increases \u03b2, which lowers the smooth sensitivity bounds. In medical applications, one expects to have many attributes measured about patients, and to need aggressive function approximation in order to provide generalization. This result tells us that differentially private algorithms should be favoured in this case as well.\nOverall, the empirical results are very promising, showing that especially as batch size increases, the noise introduced by the DP mechanism decreases rapidly, and these algorithms provide the same performance but with the additional privacy guarantees."}, {"heading": "7 Conclusion", "text": "We present the first differentially private algorithms for policy evaluation in the full MDP setting. Our algorithms are built on top of established Monte Carlo methods, and come with utility guarantees showing that the cost of privacy diminishes as training batches get larger. The smoothed sensitivity framework is a key component of our analyses, which differ from previous works on DP mechanisms for ERM and bandits problems in two substantial ways. The first, we consider optimizations with non-Lipschitz loss functions, which prevents us from using most of the established techniques for analyzing privacy and utility in ERM algorithms and complicates some parts of our analysis. In particular, we cannot leverage the tight utility analysis of [Jain and Thakurta, 2014] to get dimension independent bounds. Second, and more importantly, the natural model of neighbouring datasets for policy evaluation involves replacing a whole trajectory. This implies that neighbouring datasets can differ in multiple regression targets, which is quite different from the usual supervised learning approach where neighbouring datasets can only change a single regression target. Our approach is also different from the on-line learning and bandits setting, where there is a single stream of experience and neighbouring datasets differ in one element of the stream. Note that this setting cannot be used naturally in the full MDP setup, because successive observations in a single stream are inherently correlated.\nIn future work we plan to extend our techniques in two directions. First, we would like to design DP policy evaluation methods based on temporal-difference learning [Sutton, 1988]. Secondly, we will tackle the control case, where policy evaluation is often used as a sub-routine, e.g. as in actorcritic methods. We also plan to evaluate the current algorithms on patient data from an ongoing clinical study (in which case, errors cannot be estimated precisely, because the right answer is not known)."}, {"heading": "A Smoothed Gaussian Perturbation", "text": "A proof of Lemma 1 in the paper can be found in the pre-print Nissim et al. [2011]. For the sake of completeness, we provide here an elementary proof (albeit with slightly worse constants). In particular, we are going to prove the following.\nLemma 14. Let A be an algorithm that on input X computes a vector \u00b5X \u2208 Rd deterministically and then outputs ZX \u223c N (\u00b5X , \u03c32XI), where \u03c32X is a variance that depends on X. Let \u03b1 = \u03b1(\u03b5, \u03b4) = 15 \u221a 2 ln(4/\u03b4)/\u03b5 and \u03b2 = \u03b2(\u03b5, \u03b4, d) = (2 ln 2)\u03b5/5( \u221a d + \u221a 2 ln(4/\u03b4))2. Suppose that \u03b5 \u2264 5, \u03b4 and d are such \u03b2 \u2264 ln 2, and the following are satisfied for every pair of neighbouring datasets X ' X \u2032:\n1. \u03c3X \u2265 \u03b1\u2016\u00b5X \u2212 \u00b5X\u2032\u20162,\n2. | ln(\u03c32X)\u2212 ln(\u03c32X\u2032)| \u2264 \u03b2.\nThen A is (\u03b5, \u03b4)-differentially private.\nWe start with a simple characterization of (\u03b5, \u03b4)-differential privacy that will be useful for our proof.\nLemma 15. Let A(X) = \u03b8X \u2208 Rd be the output of a randomized algorithm on input X. Write f\u03b8X (\u03b8) for the probability density of the output of A on input X. Suppose that for every pair of neighbouring datasets X ' X \u2032 there exists a measurable set \u0398X,X\u2032 \u2282 Rd such that the following are satisfied:\n1. P[\u03b8X /\u2208 \u0398X,X\u2032 ] \u2264 \u03b4;\n2. for all \u03b8 \u2208 \u0398X,X\u2032 we have f\u03b8X (\u03b8) \u2264 e\u03b5f\u03b8X\u2032 (\u03b8).\nThen A is (\u03b5, \u03b4)-differentially private.\nProof. Fix a pair of neighbouring datasets X ' X \u2032 and let E \u2286 Rd be any measurable set. Let \u0398X,X\u2032 be as in the statement and write \u0398 c X,X\u2032 = R\nd \\\u0398X,X\u2032 . Using the assumptions on \u0398X,X\u2032 we see that\nP[\u03b8X \u2208 E] = P[\u03b8X \u2208 E \u2229\u0398X,X\u2032 ] + P[\u03b8X \u2208 E \u2229\u0398cX,X\u2032 ] \u2264 e\u03b5P[\u03b8X\u2032 \u2208 E \u2229\u0398X,X\u2032 ] + \u03b4 \u2264 e\u03b5P[\u03b8X\u2032 \u2208 E] + \u03b4 .\nNow we proceed with the proof of Lemma 14. Let X ' X \u2032 be two neighbouring datasets and let us write Z1 = ZX and Z2 = ZX\u2032 for simplicity. Thus, for i = 1, 2 we have that Zi \u223c N (\u00b5i, \u03c32i I) are d-dimensional independent Gaussian random variables whose means and variances satisfy the assumptions of Lemma 14 for some \u03b5, \u03b4 > 0. The density function of Zi is denoted by fZi(z). In order to be able to apply Lemma 15 we want to show that the privacy loss between Z1 and Z2 defined as\nL(z) = ln fZ1(z)\nfZ2(z) (17)\nis bounded by \u03b5 for all z \u2208 \u2126, where \u2126 \u2282 Rd is an event with probability at least 1\u2212 \u03b4 under Z1. We can start by identifying a candidate \u2126. Since \u2126 has to have high probability w.r.t. Z1, it should contain \u00b51 because a ball around the mean is the event with the highest probability under\na spherical Gaussian distribution (among those with the same Lebesgue measure). For technical reasons, instead of a ball we will take a slightly more complicated region, which for now we will parametrize by two quantities a, b > 0. The definition of this region will depend on the difference of means \u2206 = \u00b52 \u2212 \u00b51:\n\u2126 = \u2126a \u2229 \u2126b = {z + \u00b51 \u2208 Rd | | \u3008z,\u2206\u3009 | \u2264 a} \u2229 {z + \u00b51 \u2208 Rd | \u2016z\u2016 \u2264 b} . (18)\nWe need to choose a and b such that the probability P[Z1 /\u2208 \u2126] \u2264 \u03b4, and for that we shall combine two different tail bounds. On the one hand, note that Z = \u3008Z1 \u2212 \u00b51,\u2206\u3009 /(\u03c31\u2016\u2206\u2016) \u223c N (0, 1) is a one dimensional standard Gaussian random variable and recall that for any t \u2265 0:\nP[|Z| > t] \u2264 2e\u2212t2/2 . (19)\nOn the other hand, X = \u2016Z1 \u2212 \u00b51\u20162/\u03c321 \u223c \u03c72d follows a chi-squared distribution with d degrees of freedom, for which is known Laurent and Massart [2000] that for all t \u2265 0:\nP[X > d+ 2 \u221a dt+ 2t] \u2264 e\u2212t . (20)\nTo make our choices for a and b we can take them such that P[Z1 /\u2208 \u2126a],P[Z1 /\u2208 \u2126b] \u2264 \u03b4/2, since then by a union bound we will get\nP[Z1 /\u2208 \u2126] \u2264 P[Z1 /\u2208 \u2126A] + P[Z1 /\u2208 \u2126B] \u2264 \u03b4 . (21) Since Z satisfies |Z| \u2264 \u221a 2 ln(4/\u03b4) with probability at least 1\u2212 \u03b4/2, we can take\na = \u03c31\u2016\u2206\u2016 \u221a 2 ln 4\n\u03b4 = \u03c31\u2016\u2206\u2016C\u03b4 . (22)\nFor X we have that d+2 \u221a d ln(2/\u03b4)+2 ln(2/\u03b4) \u2264 d+2 \u221a 2d ln(2/\u03b4)+2 ln(2/\u03b4) = ( \u221a d+ \u221a\n2 ln(2/\u03b4))2. Hence, we choose\nb = \u03c31( \u221a d+ \u221a 2 ln(2/\u03b4)) = \u03c31D\u03b4 . (23)\nFixing this choice of \u2126, we now proceed to see under what conditions on \u03c31 and \u03c32 we can get L(z) \u2264 \u03b5 for all z \u2208 \u2126. We start by expanding the definition of L(z) to get\nL(z) = d 2 ln \u03c322 \u03c321 + \u2016\u00b52 \u2212 z\u20162 2\u03c322 \u2212 \u2016\u00b51 \u2212 z\u2016 2 2\u03c321 . (24)\nThe easiest thing to do is to separate this quantity into several parts and insist on each part being at most a fraction of \u03b5. To simplify calculations we will just require that each part is at most = \u03b5/5. This reasoning applied to the first term shows that we must satisfy\n\u03c322 \u03c321 \u2264 e2 /d . (25)\nNote that this becomes more restrictive as \u2248 0 or d\u2192\u221e, in which case we have e /d \u2248 1. Next we look at the second part and write z = z\u2032 + \u00b51 because this is the form of the vectors in \u2126. With some algebra we get:\n\u2016\u00b52 \u2212 (z\u2032 + \u00b51)\u20162 2\u03c322 \u2212 \u2016\u00b51 \u2212 (z \u2032 + \u00b51)\u20162 2\u03c321 = \u2016\u2206\u20162 + \u2016z\u2032\u20162 \u2212 2 \u3008z\u2032,\u2206\u3009 2\u03c322 \u2212 \u2016z \u2032\u20162 2\u03c321 . (26)\nTo further decompose this quantity we write z\u2032 \u2208 Rd as z\u2032 = zp + zo, where zp = \u2206 \u3008z\u2032,\u2206\u3009 /\u2016\u2206\u20162 is the orthogonal projection of z onto the line spanned by the vector \u2206, and zo is the corresponding orthogonal complement. Pythagora\u2019s Theorem implies \u2016z\u2032\u20162 = \u2016zp\u20162 + \u2016zo\u20162, and the RHS in the above expression is equal to\n\u2016\u2206\u20162 2\u03c322 \u2212 \u3008z \u2032,\u2206\u3009 \u03c322 + | \u3008z\u2032,\u2206\u3009 |2 2\u2016\u2206\u20162\n( 1\n\u03c322 \u2212 1 \u03c321\n) + \u2016zo\u20162\n2\n( 1\n\u03c322 \u2212 1 \u03c321\n) . (27)\nNow note that the last two terms can be upper bounded by zero if \u03c31 \u2264 \u03c32, but need to be taken into account otherwise. Furthermore, if it were the case that \u03c31 \u03c32 \u2248 0, then these terms could grow unboundedly. Thus we shall require that a bound of the form\n\u03c321 \u03c322 \u2264 \u03b3 , (28)\nholds for some \u03b3 \u2265 1 to be specified later. Nonetheless, we observe that under this assumption\n1 \u03c322 \u2212 1 \u03c321 \u2264 \u03b3 \u2212 1 \u03c321 . (29)\nFurthermore, z \u2208 \u2126 implies \u2016zo\u20162 \u2264 \u2016z\u2032\u20162 = \u2016z \u2212 \u00b51\u2016 \u2264 b2 and | \u3008z\u2032,\u2206\u3009 |2 = | \u3008z \u2212 \u00b51,\u2206\u3009 |2 \u2264 a2. Thus we see that\n| \u3008z\u2032,\u2206\u3009 |2\n2\u2016\u2206\u20162\n( 1\n\u03c322 \u2212 1 \u03c321\n) \u2264 C2\u03b4 (\u03b3 \u2212 1)\n2 , (30)\nand \u2016zo\u20162\n2\n( 1\n\u03c322 \u2212 1 \u03c321\n) \u2264 D2\u03b4 (\u03b3 \u2212 1)\n2 . (31)\nBy requiring that each of these bounds is at most we obtain the following constraint for \u03b3:\n\u03b3 \u2264 1 + 2 max{C2\u03b4 , D2\u03b4} , (32)\nwhich can be satisfied by taking, for example:\n\u03b3 = 1 + 2 (\u221a d+ \u221a 2 ln(4/\u03b4) )2 . (33)\nNote that for fixed \u03b4, small and/or large d this choice of \u03b3 will make (28) behave much like the bound (25) we assumed above for \u03c322/\u03c3 2 1. In fact, using that 1 + x \u2265 ex ln 2 for all 0 \u2264 x \u2264 1 we see\nthat (28) can be satisfied if 2 /( \u221a d+ \u221a 2 ln(4/\u03b4))2 \u2264 1 and\n\u03c321 \u03c322 \u2264 exp  (2 ln 2) (\u221a d+ \u221a 2 ln(4/\u03b4) )2  . (34)\nFrom here it is immediate to see that if the second condition | ln(\u03c321)\u2212 ln(\u03c322)| \u2264 \u03b2 in Lemma 14 is satisfied, then (25) and (34) are both satisfied.\nThe missing ingredient to show that L(z) \u2264 \u03b5 for all z \u2208 \u2126 is an absolute lower bound on \u03c31. This will follow from bounding the remaining terms in L(z) as follows:\n\u2016\u2206\u20162 2\u03c322 \u2212 \u3008z \u2032,\u2206\u3009 \u03c322 \u2264 \u2016\u2206\u2016 2 + 2\u03c31\u2016\u2206\u2016C\u03b4 2\u03c322 (35)\n\u2264 \u03b3 2 \u2016\u2206\u20162 + 2\u03c31\u2016\u2206\u2016C\u03b4 \u03c321\n(36)\n\u2264 3 2 \u2016\u2206\u20162 + 2\u03c31\u2016\u2206\u2016C\u03b4 \u03c321\n(37)\n= 3\u2016\u2206\u20162\n2\u03c321 + 3\u2016\u2206\u2016C\u03b4 \u03c31 , (38)\nwhere we used that \u2264 1 implies \u03b3 \u2264 3. If we require each of these two terms to be at most , we obtain the constraint:\n\u03c31 \u2265 \u2016\u2206\u2016max\n{\u221a 3\n2 , 3C\u03b4\n} = 3\u2016\u2206\u2016C\u03b4 . (39)\nTo conclude the proof just note that the above bound can be rewritten as \u03c31 \u2265 \u03b1\u2016\u2206\u2016, which is precisely the first condition in Lemma 14."}, {"heading": "B Privacy Analysis of DP-LSW", "text": "Lemma 16. Let X ' X \u2032 be two neighbouring datasets of m trajectories with X = (x1, . . . , xm\u22121, x) and X \u2032 = (x1, . . . , xm\u22121, x\n\u2032). Let X\u25e6 = (x1, . . . , xm\u22121). Let Sx (resp. Sx\u2032) denote the set of states visited by x (resp. x\u2032). Then we have\n\u2016FX \u2212 FX\u2032\u20162,\u0393 \u2264 Rmax 1\u2212 \u03b3 \u221a \u2211 s\u2208Sx\u222aSx\u2032 ws (|X\u25e6s |+ 1)2 .\nProof. We start by noting that if s \u2208 S \\ (Sx \u222a Sx\u2032), then FX,s = FX\u2032,s. In the case s \u2208 Sx \u222a Sx\u2032 we can write FX,s = (|X\u25e6s |FX\u25e6,s + Fx,s)/(|X\u25e6s |+ 1). Using a symmetric expression for FX\u2032,s we see that in this case\n|FX,s \u2212 FX\u2032,s| = 1\n|X\u25e6s |+ 1 |Fx,s \u2212 Fx\u2032,s| \u2264\n1\n|X\u25e6s |+ 1 max{Fx,s, Fx\u2032,s} \u2264\n1 |X\u25e6s |+ 1 Rmax 1\u2212 \u03b3 ,\nwhere we used that 0 \u2264 Fx,s \u2264 Rmax/(1 \u2212 \u03b3) for all s and x. When s \u2208 Sx \\ Sx\u2032 we can use the same expression as before for FX,s and write FX\u2032,s = FX\u25e6,s. A similar argument as in the previous case then yields\n|FX,s \u2212 FX\u2032,s| = 1\n|X\u25e6s |+ 1 |Fx,s \u2212 FX\u25e6,s| \u2264\n1 |X\u25e6s |+ 1 Rmax 1\u2212 \u03b3 .\nNote the same bound also holds for the case s \u2208 Sx\u2032 \\Sx. Finally, since we have seen that the same bound holds for all s \u2208 Sx \u222a Sx\u2032 , we obtain\u2211\ns\u2208S ws(FX,s \u2212 FX\u2032,s)2 \u2264\nR2max (1\u2212 \u03b3)2 \u2211 s\u2208Sx\u222aSx\u2032 ws (|X\u25e6s |+ 1)2 ,\nwhich yields the desired bound.\nCorollary 17. If X is a dataset of trajectories, then the following holds for every neighbouring dataset X \u2032 ' X:\n\u2016FX \u2212 FX\u2032\u20162,\u0393 \u2264 Rmax 1\u2212 \u03b3 \u221a\u2211 s\u2208S ws max{|Xs|, 1}2 .\nProof. Using the notation from Lemma 16 we observe that |Xs| = |X\u25e6s |+1 if s \u2208 Sx, and |Xs| = |X\u25e6s | if s /\u2208 Sx. Therefore, the following holds for any trajectories x, x\u2032:\u2211 s\u2208Sx\u222aSx\u2032 ws (|X\u25e6s |+ 1)2 \u2264 \u2211 s\u2208S ws (|X\u25e6s |+ 1)2 = \u2211 s\u2208Sx ws |Xs|2 + \u2211 s\u2208S\\Sx ws (|Xs|+ 1)2 \u2264 \u2211 s\u2208SX ws |Xs|2 + \u2211 s\u2208S\\SX ws ,\nwhere SX denotes the set of states visited by at least one trajectory from X. Since s /\u2208 SX implies |Xs| = 0, we can plug this bound into the result of Lemma 16 as follows:\n\u2016FX \u2212 FX\u2032\u20162,\u0393 \u2264 Rmax 1\u2212 \u03b3 \u221a\u2211 s\u2208SX ws |Xs|2 + \u2211 s\u2208S\\SX ws = Rmax 1\u2212 \u03b3 \u221a\u2211 s\u2208S ws max{|Xs|, 1}2 .\nLemma 18. The following holds for every v \u2208 NS :\n\u03d5wk (v) = \u2211 s\u2208S ws max{vs \u2212 k, 1}2 .\nFurthermore, for every k \u2265 \u2016v\u2016\u221e \u2212 1 we have \u03d5wk (v) = \u2211 sws.\nProof. Recall that \u03d5wk (v) = max\u2016v\u2032\u2212v\u2016\u221e\u2264k \u03d5 w(v\u2032) with \u03d5w(v) = \u2211 sws/max{vs, 1}2 and observe the result follows immediately because\n\u03d5wk (v) = \u2211 s\u2208S ws min\u2212k\u2264l\u2264k max{vs + l, 1}2 = \u2211 s\u2208S ws max{vs \u2212 k, 1}2 ."}, {"heading": "C Privacy Analysis of DP-LSL", "text": "Lemma 19. Let X ' X \u2032 be two neighbouring datasets of m trajectories with X = (x1, . . . , xm\u22121, x) and X \u2032 = (x1, . . . , xm\u22121, x\n\u2032). Let Fx \u2208 RS (resp. Fx\u2032 \u2208 RS) be the vector given by Fx(s) = Fx,s (resp. Fx\u2032(s) = Fx\u2032,s). Define the diagonal matrices \u0393\u03c1,\u2206x,x\u2032 \u2208 RS\u00d7S given by \u0393\u03c1(s, s) = \u03c1s and \u2206x,x\u2032(s, s) = Is\u2208x \u2212 Is\u2208x\u2032. If the regularization parameter satisfies \u03bb > \u2016\u03a6>\u2206x,x\u2032\u0393\u03c1\u03a6\u2016, then the following holds:\n\u2016\u03b8\u03bbX \u2212 \u03b8\u03bbX\u2032\u20162 2 \u2264\n\u2225\u2225\u2225(\u2206x,x\u2032\u03a6\u03b8\u03bbX \u2212 Fx + Fx\u2032)> \u0393\u03c1\u03a6\u2225\u2225\u2225 2\n\u03bb\u2212 \u2016\u03a6>\u2206x,x\u2032\u0393\u03c1\u03a6\u2016 . (40)\nProof. In order to simplify our notation we write \u03b8\u0304 = \u03b8\u03bbX and \u03b8\u0304 \u2032 = \u03b8\u03bbX\u2032 for the rest of the proof. Given a trajectory x and a vector \u03b8 \u2208 Rd we shall also write `(x, \u03b8) = \u2211\ns\u2208Sx \u03c1s(Fx,s \u2212 \u03c6 > s \u03b8) 2 so\nthat JX(\u03b8) = 1 m \u2211m i=1 `(xi, \u03b8). Now we proceed with the proof.\nLet us start by noting that because J\u03bbX(\u03b8) is \u03bb/m-strongly convex, we have J \u03bb X(\u03b81)\u2212 J\u03bbX(\u03b82) \u2265\n\u3008\u2207J\u03bbX(\u03b82), \u03b81\u2212\u03b82\u3009+ \u03bb 2m\u2016\u03b81\u2212\u03b82\u2016 2 2 for any \u03b81, \u03b82 \u2208 Rd. Thus, using that optimality implies \u2207J\u03bbX(\u03b8\u0304) =\n\u2207J\u03bbX\u2032(\u03b8\u0304\u2032) = 0, we get\n\u03bb m \u2016\u03b8\u0304 \u2212 \u03b8\u0304\u2032\u201622 \u2264 J\u03bbX(\u03b8\u0304\u2032)\u2212 J\u03bbX(\u03b8\u0304) + J\u03bbX\u2032(\u03b8\u0304)\u2212 J\u03bbX\u2032(\u03b8\u0304\u2032)\n= JX(\u03b8\u0304 \u2032)\u2212 JX(\u03b8\u0304) + JX\u2032(\u03b8\u0304)\u2212 JX\u2032(\u03b8\u0304\u2032) = 1\nm\n( `(x, \u03b8\u0304\u2032)\u2212 `(x, \u03b8\u0304) + `(x\u2032, \u03b8\u0304)\u2212 `(x\u2032, \u03b8\u0304\u2032) ) ,\nwhere the equalities follows from definitions of X, X \u2032, J\u03bbX and JX . If we now expand the definition of `(x, \u03b8) we see that\n`(x, \u03b8\u0304\u2032)\u2212 `(x, \u03b8\u0304) = \u2211 s\u2208Sx \u03c1s ( (\u03c6>s \u03b8\u0304 \u2032)2 \u2212 (\u03c6>s \u03b8\u0304)2 \u2212 2Fx,s\u03c6>s (\u03b8\u0304\u2032 \u2212 \u03b8\u0304) ) ,\n`(x\u2032, \u03b8\u0304)\u2212 `(x\u2032, \u03b8\u0304\u2032) = \u2211 s\u2208Sx\u2032 \u03c1s ( (\u03c6>s \u03b8\u0304) 2 \u2212 (\u03c6>s \u03b8\u0304\u2032)2 \u2212 2Fx\u2032,s\u03c6>s (\u03b8\u0304 \u2212 \u03b8\u0304\u2032) ) .\nUsing the identity (\u03c6>s \u03b8\u0304 \u2032)2\u2212 (\u03c6>s \u03b8\u0304)2 = (\u03b8\u0304\u2032+ \u03b8\u0304)>\u03c6s\u03c6>s (\u03b8\u0304\u2032\u2212 \u03b8\u0304), we rewrite `(x, \u03b8\u0304\u2032)\u2212 `(x, \u03b8\u0304) + `(x\u2032, \u03b8\u0304)\u2212 `(x\u2032, \u03b8\u0304\u2032) as \u2211 s\u2208S \u03c1s [ (Is\u2208x \u2212 Is\u2208x\u2032)(\u03b8\u0304\u2032 + \u03b8\u0304)>\u03c6s\u03c6>s \u2212 2(Fx,s \u2212 Fx\u2032,s)\u03c6>s ] (\u03b8\u0304\u2032 \u2212 \u03b8\u0304) , (41)\nwhere we implicitly used that Fx,s = 0 whenever s /\u2208 x. Finally, using the definitions in the statement we can rearrange the above expression to show that\n\u03bb m \u2016\u03b8\u0304 \u2212 \u03b8\u0304\u2032\u201622 \u2264 1 m\n( (\u03b8\u0304\u2032 + \u03b8\u0304)>\u03a6>\u2206x,x\u2032 \u2212 2(Fx \u2212 Fx\u2032)> ) \u0393\u03c1\u03a6(\u03b8\u0304 \u2032 \u2212 \u03b8\u0304)\n= 2\nm\n( \u03b8\u0304>\u03a6>\u2206x,x\u2032 \u2212 (Fx \u2212 Fx\u2032)> ) \u0393\u03c1\u03a6(\u03b8\u0304\n\u2032 \u2212 \u03b8\u0304) + 1 m (\u03b8\u0304\u2032 \u2212 \u03b8\u0304)>\u03a6>\u2206x,x\u2032\u0393\u03c1\u03a6(\u03b8\u0304\u2032 \u2212 \u03b8\u0304)\n\u2264 2 m \u2016 ( \u03b8\u0304>\u03a6>\u2206x,x\u2032 \u2212 (Fx \u2212 Fx\u2032)> ) \u0393\u03c1\u03a6\u20162\u2016\u03b8\u0304\u2032 \u2212 \u03b8\u0304\u20162 + 1 m \u2016\u03a6>\u2206x,x\u2032\u0393\u03c1\u03a6\u2016\u2016\u03b8\u0304\u2032 \u2212 \u03b8\u0304\u201622 ,\nwhere we used the Cauchy\u2013Schwartz inequality and the definition of operator norm. The result now follows by solving for \u2016\u03b8\u0304 \u2212 \u03b8\u0304\u2032\u20162 in the above inequality.\nCorollary 20. Let X be a dataset of trajectories and suppose \u03bb > \u2016\u03a6\u20162\u2016\u03c1\u2016\u221e. Then the following holds for any neighbouring dataset X \u2032 ' X:\n\u2016\u03b8\u03bbX \u2212 \u03b8\u03bbX\u2032\u20162 \u2264 2Rmax\u2016\u03a6\u2016\n(1\u2212 \u03b3)(\u03bb\u2212 \u2016\u03a6\u20162\u2016\u03c1\u2016\u221e)\n\u221a \u03d5\u03bbX ,\nwhere\n\u03d5\u03bbX = \u2016\u03a6\u2016\u2016\u03c1\u2016\u221e\u221a 2\u03bb \u221a\u2211 s\u2208S \u03c1s|Xs|+ \u2016\u03c1\u20162 2 . Proof. We start by noting that \u2016\u2206x,x\u2032\u2016 \u2264 1 and \u2016\u0393\u03c1\u2016 = \u2016\u03c1\u2016\u221e, hence submultiplicativity of matrix operator norms yields \u2016\u03a6>\u2206x,x\u2032\u0393\u03c1\u03a6\u2016 \u2264 \u2016\u03a6\u20162\u2016\u03c1\u2016\u221e. On the other hand, for the numerator in (40) we have \u2225\u2225\u2225\u2225(\u2206x,x\u2032\u03a6\u03b8\u03bbX \u2212 Fx + Fx\u2032)> \u0393\u03c1\u03a6\u2225\u2225\u2225\u2225\n2\n\u2264 ( \u2016\u03b8\u03bbX\u20162\u2016\u03a6\u2016\u2016\u03c1\u2016\u221e + \u2016(Fx \u2212 Fx\u2032)>\u0393\u03c1\u20162 ) \u2016\u03a6\u2016 . (42)\nBounding the individual entries in Fx and Fx\u2032 by Rmax/(1 \u2212 \u03b3) we get \u2016(Fx \u2212 Fx\u2032)>\u0393\u03c1\u20162 \u2264 Rmax\u2016\u03c1\u20162/(1 \u2212 \u03b3). The last step is to bound the norm \u2016\u03b8\u03bbX\u20162, for which we use the closed-form solution to argmin\u03b8 J \u03bb X(\u03b8) given in the paper and write:\n\u2016\u03b8\u03bbX\u20162 \u2264 \u2225\u2225\u2225\u2225(\u03a6>\u0393X\u03a6 + \u03bb2mI)\u22121\u03a6>\u03931/2X \u2225\u2225\u2225\u2225 \u2016FX\u20162,\u0393X \u2264 \u2225\u2225\u2225\u2225(\u03a6>\u0393X\u03a6 + \u03bb2mI)\u22121\u03a6>\u03931/2X \u2225\u2225\u2225\u2225 ( Rmax 1\u2212 \u03b3 \u221a\u2211 s\u2208S \u03c1s|Xs| m ) .\nTo bound the last remaining norm let use write U\u03a3V > for the SVD of \u0393 1/2 X \u03a6, where V \u2208 Rd\u00d7d with V >V = V V > = I. With this we can write:\n(\u03a6>\u0393X\u03a6 + \u03bb 2m I)\u22121\u03a6>\u0393 1/2 X = V\n( \u03a32 + \u03bb\n2m I\n)\u22121 \u03a3U> . (43)\nNow we use that \u2016U\u2016 = \u2016V \u2016 = 1 and x/(x2 + a) \u2264 1/(2 \u221a a) for any x \u2265 0 to get \u2016V (\u03a32 + (\u03bb/2m)I)\u22121\u03a3U>\u2016 \u2264 \u221a m/2\u03bb. Thus we get a bound for \u2016\u03b8\u03bbX\u20162 that when plugged into (42) yields the desired result.\nLemma 21. The following holds for every v \u2208 NS :\n\u03d5\u03bbk(v) = \u2016\u03a6\u2016\u2016\u03c1\u2016\u221e\u221a 2\u03bb \u221a\u2211 s\u2208S \u03c1s max{vs + k,m}+ \u2016\u03c1\u20162 2 . Furthermore, for every k \u2265 m\u2212mins vs we have \u03d5\u03bbk(v) = ( \u2016\u03a6\u2016\u2016\u03c1\u2016\u221e \u221a m\u221a\n2\u03bb\n\u221a\u2211 s\u2208S \u03c1s + \u2016\u03c1\u20162 )2 .\nProof. The proof is similar to that of Lemma 18 and is omitted."}, {"heading": "D Utility Analysis of DP-LSW", "text": "The goal of this section is to show that as the size m of the dataset X grows, the differentially private solution \u03b8wX provided by algorithm DP-LSW is not much worse than the one obtained by directly minimizing JwX(\u03b8). In other words, for large datasets the noise introduced by the privacy constraint is negligible. We do so by proving a O(1/m2) bound for the expected empirical excess risk given by EX,\u03b7[JwX(\u03b8\u0302wX)\u2212 JwX(\u03b8wX)]. Our analysis starts with a lemma that leverages the law of total expectation in order to reduce the bound to a quantity that only depends on EX [\u03c32X ].\nLemma 22. EX,\u03b7[JwX(\u03b8\u0302wX)\u2212 JwX(\u03b8wX)] = \u2016\u03931/2\u03a6\u20162FEX [\u03c32X ] . (44)\nProof. By the law of total expectation it is enough to show that\nE\u03b7[JwX(\u03b8\u0302wX)\u2212 JwX(\u03b8wX)|X] = \u03c32X\u2016\u03931/2\u03a6\u20162F . (45)\nLet X be an arbitrary dataset. Expanding the definition of JwX(\u03b8) we have that for any \u03b8 \u2208 Rd\nJwX(\u03b8) = F > X\u0393FX + \u03b8 >\u03a6>\u0393\u03a6\u03b8 \u2212 2F>X\u0393\u03a6\u03b8 . (46)\nOn the other hand, since \u2207\u03b8JwX(\u03b8wX) = 0, we have \u03b8wX >\u03a6>\u0393\u03a6 = F>X\u0393\u03a6. Thus, using the definition \u03b8\u0302wX = \u03b8 w X + \u03b7, a simple algebraic calculation yields\nJwX(\u03b8\u0302 w X)\u2212 JwX(\u03b8wX) = \u03b7>\u03a6>\u0393\u03a6\u03b7 \u2212 F>X\u0393\u03a6\u03b7 \u2212 \u03b7>\u03a6>\u0393\u03a6\u03b8wX . (47)\nFinally, taking the expectation over \u03b7 \u223c N (0, \u03c32XI) of the above expression we get\nE\u03b7[JwX(\u03b8\u0302wX)\u2212 JwX(\u03b8wX)] = E\u03b7[\u03b7>\u03a6>\u0393\u03a6\u03b7] = \u03c32X Tr(\u03a6>\u0393\u03a6) = \u03c32X\u2016\u03931/2\u03a6\u20162F . (48)\nIn order to bound EX [\u03c32X ] we recall the variance has the form \u03c32X = C2\u03c8wX , where C is a constant independent of X and\n\u03c8wX = max k\u22650 e\u2212k\u03b2 \u2211 s\u2208S ws max{|Xs| \u2212 k, 1}2 \u2264 \u2211 s ws ( max k\u22650\ne\u2212k\u03b2\nmax{|Xs| \u2212 k, 1}2\n) . (49)\nThus, we can bound EX [\u03c32X ] = C2EX [\u03c8wX ] by providing a bound for the expectation of each individual maximum in (49). The two following technical lemmas will prove useful.\nLemma 23. Let b > 0 and a \u2265 1. Then the following holds:\nmax 0\u2264x\u2264a\u22121\ne\u2212bx\n(a\u2212 x)2 =  1 a2\nb < 2/a\ne1\u2212ab b > 2 e2\n4 b 2e\u2212ab otherwise\n(50)\nProof. The result follows from a simple calculation.\nLemma 24. Suppose Bm,p is a binomial random variable with m trials and success probability p. Then the following hold:\nE [\n1\nBm,p + 1\n] = 1\u2212 (1\u2212 p)m+1\np(m+ 1) , E [ 1\nB2m,p IBm,p\u22651 ] \u2264 6 p(m+ 1) ( 1\u2212 (1\u2212 p)m+2 p(m+ 2) \u2212 (1\u2212 p)m+1 \u2212 p(m+ 1) 2 (1\u2212 p)m ) .\nProof. The first expectation is a classical exercise in probability textbooks. The second one can be\nproved as follows: E [ 1\nB2m,p IBm,p\u22651\n] = m\u2211 k=1 1 k2 ( m k ) pk(1\u2212 p)m\u2212k\n\u2264 6 m\u2211 k=1\n1\n(k + 1)(k + 2)\n( m\nk\n) pk(1\u2212 p)m\u2212k\n= 6\np(m+ 1) m\u2211 k=1 1 k + 2\n(m+ 1)!\n(k + 1)!(m\u2212 k)! pk+1(1\u2212 p)m\u2212k\n= 6\np(m+ 1) m\u2211 k=1 1 k + 2 P[Bm+1,p = k + 1]\n= 6\np(m+ 1) m+1\u2211 j=2 1 j + 1 P[Bm+1,p = j]\n= 6\np(m+ 1)\n( E [\n1\nBm+1,p + 1\n] \u2212 P[Bm+1,p = 0]\u2212 1\n2 P[Bm+1,p = 1] ) = 6\np(m+ 1)\n( 1\u2212 (1\u2212 p)m+2\np(m+ 2) \u2212 (1\u2212 p)m+1 \u2212 p(m+ 1) 2 (1\u2212 p)m\n) ,\nwhere we used the first equation in the last step, and the bound (k+ 1)(k+ 2)/k2 \u2264 6 for k \u2265 1 in the first inequality.\nRecall that ps denotes the probability that a trajectory from X visits states s. Because these trajectories are i.i.d. we have that |Xs| = Bm,ps is a binomial random variable. Therefore, we can combine the last two lemmas to prove the following.\nLemma 25. Suppose \u03b2 \u2264 2. Then we have:\nEX [ max k\u22650\ne\u2212k\u03b2\nmax{|Xs| \u2212 k, 1}2\n] \u2264 { 6 p2s(m+1)(m+2) + e 2\u03b22 4 (1\u2212 (1\u2212 e \u2212\u03b2)ps) m ps > 0 ,\n1 ps = 0 . (51)\nProof. Note in the first place that Lemma 23 implies\nmax k\u22650\ne\u2212k\u03b2\nmax{|Xs| \u2212 k, 1}2 = I|Xs|=0 + I1\u2264|Xs|<2/\u03b2\n1\n|Xs|2 + I|Xs|\u22652/\u03b2\ne2\n4 \u03b22e\u2212\u03b2|Xs| , (52)\nwhere we used that in the case |Xs| = 0 the maximum is 1. If ps = 0, then obviously |Xs| = 0 almost surely and the expectation of (52) equals 1. On the other hand, when ps > 0 we use the linearity of expectation and bound each term separately. Clearly, EX [I|Xs|=0] = PX [Bm,ps = 0] = (1\u2212 ps)m. On the other hand, by looking up the moment generating function of a binomial distribution we have\nEX [I|Xs|\u22652/\u03b2 e2 4 \u03b22e\u2212\u03b2|Xs|] \u2264 e 2 4 \u03b22EX [e\u2212\u03b2|Xs|] = e2 4 \u03b22(1\u2212 (1\u2212 e\u2212\u03b2)ps)m . (53)\nThe remaining term is bounded by EX [ I1\u2264|Xs|<2/\u03b2 1\n|Xs|2\n] \u2264 EX [ I1\u2264|Xs| 1\n|Xs|2\n] . (54)\nTherefore, applying Lemma 24 and upper bounding some negative terms by zero, we get EX [ max k\u22650 e\u2212k\u03b2 max{|Xs| \u2212 k, 1}2 ] \u2264 6 p2s(m+ 1)(m+ 2) + e2\u03b22 4 (1\u2212 (1\u2212 e\u2212\u03b2)ps)m . (55)\nNow we can combine Lemmas 22 and 25 using Equation 49 to get our final result.\nTheorem 26. Let S0 = {s \u2208 S|ps = 0} and S+ = S \\S0. Let C = \u03b1Rmax\u2016(\u03931/2\u03a6)\u2020\u2016\u2016\u03931/2\u03a6\u2016F /(1\u2212 \u03b3). Suppose \u03b2 \u2264 2. Then we have the following:\nEX,\u03b7[JwX(\u03b8\u0302wX)\u2212JwX(\u03b8wX)] \u2264 C2 \u2211 s\u2208S0 ws + \u2211 s\u2208S+ ws ( 6 p2s(m+ 1)(m+ 2) + e2\u03b22 4 (1\u2212 (1\u2212 e\u2212\u03b2)ps)m ) . The following version is the one given in the paper for reasons of space. It is easily obtained by noting that e2/4 \u2264 6, m2 \u2264 (m+ 1)(m+ 2), and when \u03b2 \u2264 1/2 then 1\u2212 (1\u2212 e\u2212\u03b2)ps \u2264 1\u2212 \u03b2ps/2.\nCorollary 27. Let S0 = {s \u2208 S|ps = 0} and S+ = S\\S0. Let C = \u03b1Rmax\u2016(\u03931/2\u03a6)\u2020\u2016\u2016\u03931/2\u03a6\u2016F /(1\u2212 \u03b3). Suppose \u03b2 \u2264 1/2. Then EX,\u03b7[JwX(\u03b8\u0302wX)\u2212 JwX(\u03b8wX)] is upper bounded by:\nC2 \u2211 s\u2208S0 ws + 6 \u2211 s\u2208S+ ws ( 1 p2sm 2 + \u03b22 ( 1\u2212 \u03b2ps 2 )m) . The following is an immediate consequence of these results.\nCorollary 28. If ws = 0 for all s \u2208 S0, then EX,\u03b7[JwX(\u03b8\u0302wX)\u2212 JwX(\u03b8wX)] = O(1/m2)."}, {"heading": "E Utility Analysis of DP-LSL", "text": "The analysis in this section follows a scheme similar to the previous one. We start by taking the expectation of the excess empirical risk with respect to the Gaussian perturbation \u03b7.\nLemma 29.\nEX,\u03b7[J\u03bbX(\u03b8\u0302\u03bbX)\u2212 J\u03bbX(\u03b8\u03bbX)] = EX\n[( \u03bbd\n2m +\n1\nm \u2211 s\u2208S \u03c1s\u2016\u03c6s\u201622|Xs| ) \u03c32X ] . (56)\nProof. Let X be an arbitrary dataset with m trajectories. Recalling that \u03b8\u0302\u03bbX = \u03b8 \u03bb X + \u03b7 we get:\nJ\u03bbX(\u03b8\u0302 \u03bb X)\u2212 J\u03bbX(\u03b8\u03bbX) =\n1\nm m\u2211 i=1 \u2211 s\u2208Sxi \u03c1s ( (\u03c6>s \u03b8\u0302 \u03bb X) 2 \u2212 (\u03c6>s \u03b8\u03bbX)2 \u2212 2Fxi,s\u03c6>s \u03b7 ) + \u03bb 2m ( \u2016\u03b8\u0302\u03bbX\u201622 \u2212 \u2016\u03b8\u03bbX\u201622 )\n= 1\nm m\u2211 i=1 \u2211 s\u2208Sxi \u03c1s ( \u03b7>\u03c6s\u03c6 > s \u03b7 + 2\u03b7 >\u03c6s\u03c6 > s \u03b8 \u03bb X \u2212 2Fxi,s\u03c6>s \u03b7 ) + \u03bb 2m ( \u2016\u03b7\u201622 + 2\u03b7>\u03b8\u03bbX ) .\nTaking the expectation over \u03b7 \u223c N (0, \u03c32XI) in the above expression we get\nE\u03b7[J\u03bbX(\u03b8\u0302\u03bbX)\u2212 J\u03bbX(\u03b8\u03bbX)] = 1\nm m\u2211 i=1 \u2211 s\u2208Sxi \u03c1s Tr(\u03c6s\u03c6 > s )\u03c3 2 X + \u03bb 2m d\u03c32X .\nThe result now follows from noting that \u2211m\ni=1 \u2211 s\u2208Sxi \u03c1s Tr(\u03c6s\u03c6 > s ) = \u2211 s\u2208S \u03c1s\u2016\u03c6s\u201622|Xs|.\nIn order to bound the expression given by previous lemma we will expand the definition of \u03c3X =\nC\u03bb \u221a \u03c8\u03bbX , with C\u03bb = 2Rmax\u2016\u03a6\u2016/(1 \u2212 \u03b3)(\u03bb \u2212 \u2016\u03a6\u20162\u2016\u03c1\u2016\u221e), and note that using the straightforward bound (a+ b)2 \u2264 2a2 + 2b2 we have:\n\u03c8\u03bbX = max k\u22650 e\u2212k\u03b2 \u2016\u03c1\u20162 + \u2016\u03a6\u2016\u2016\u03c1\u2016\u221e\u221a 2\u03bb \u221a\u2211 s\u2208S \u03c1s min{|Xs|+ k,m} 2\n\u2264 2\u2016\u03c1\u201622 + \u2016\u03a6\u20162\u2016\u03c1\u20162\u221e\n\u03bb\n\u2211 s\u2208S \u03c1s max k\u22650 ( e\u22122k\u03b2 min{|Xs|+ k,m} ) .\nThe following lemma can be used to bound the maximums inside this sum.\nLemma 30. Suppose a \u2265 0 and b > 0. Then the following holds:\nmax 0\u2264x\u2264m\u2212a\ne\u22122bx(a+ x) =  a b < a/2 me\u22122b(m\u2212a) b > m/2 1\n2ebe 2ab otherwise\n(57)\nAssuming we have 2\u03b2 < 1 \u2264 m, previous lemma yields:\nmax k\u22650\n( e\u22122k\u03b2 min{|Xs|+ k,m} ) = |Xs|I|Xs|>2\u03b2 + 1\n2e\u03b2 e2\u03b2|Xs|I|Xs|\u22642\u03b2 \u2264 |Xs|+\n1\n2e\u03b2 I|Xs|=0 . (58)\nWhen taking the expectation of the upper bound for (56) obtained by plugging in (58), several quantities involving products of correlated binomial random variables will appear. Next lemma gives expressions for all these expectations.\nLemma 31. Recall that ps = P[s \u2208 x] and |Xs| is a binomial random variable with m trials and success probability ps. Define ps,s\u2032 = P[s \u2208 x\u2227 s\u2032 \u2208 x] and p\u0304s,s\u2032 = P[s \u2208 x\u2227 s\u2032 /\u2208 x] for any s, s\u2032 \u2208 S. Then we have the following:\n1. E[|Xs|] = mps,\n2. E[I|Xs|=0] = (1\u2212 ps)m,\n3. E[|Xs|2] = m2p2s +m(ps \u2212 p2s),\n4. E[|Xs||Xs\u2032 |] = m(m\u2212 1)psps\u2032 +mps,s\u2032,\n5. E[|Xs|I|Xs\u2032 |=0] = mp\u0304s,s\u2032(1\u2212 ps\u2032) m\u22121.\nProof. All equations follow from straightforward calculations.\nTheorem 32. Suppose \u03b2 < 1/2 and \u03bb > \u2016\u03a6\u20162\u2016\u03c1\u2016\u221e. Let C\u03bb = 2\u03b1Rmax\u2016\u03a6\u2016/(1\u2212\u03b3)(\u03bb\u2212\u2016\u03a6\u20162\u2016\u03c1\u2016\u221e). Then we have\nEX,\u03b7[J\u03bbX(\u03b8\u0302\u03bbX)\u2212 J\u03bbX(\u03b8\u03bbX)] \u2264 C2\u03bb {\u2211 s\u2208S \u03c1sps ( d\u2016\u03a6\u20162\u2016\u03c1\u20162\u221e 2 + 2\u2016\u03c1\u201622\u2016\u03c6s\u201622 ) + \u03bb\nm d\u2016\u03c1\u201622 +\n1\nm d\u2016\u03a6\u20162\u2016\u03c1\u20162\u221e 4e\u03b2 \u2211 s\u2208S \u03c1s(1\u2212 ps)m + m \u03bb \u2016\u03a6\u20162\u2016\u03c1\u20162\u221e \u2211 s,s\u2032\u2208S \u03c1s\u03c1s\u2032psps\u2032\u2016\u03c6s\u201622\n+ 1\n\u03bb \u2016\u03a6\u20162\u2016\u03c1\u20162\u221e \u2211 s\u2208S \u03c12s\u2016\u03c6s\u201622(ps \u2212 p2s) + \u2211 s,s\u2032\u2208S s 6=s\u2032 \u03c1s\u03c1s\u2032\u2016\u03c6s\u201622 ( ps,s\u2032 \u2212 psps\u2032 + 1 2e\u03b2 p\u0304s,s\u2032(1\u2212 ps\u2032)m\u22121 )  .\nProof. Combining Lemma 29 with (58) and the definition of \u03c32X yields the following upper bound for EX,\u03b7[J\u03bbX(\u03b8\u0302\u03bbX)\u2212 J\u03bbX(\u03b8\u03bbX)]:\nC2\u03bbEX\n[( \u03bbd\n2m +\n1\nm \u2211 s\u2208S \u03c1s\u2016\u03c6s\u201622|Xs| )( 2\u2016\u03c1\u201622 + \u2016\u03a6\u20162\u2016\u03c1\u20162\u221e \u03bb \u2211 s\u2208S \u03c1s ( |Xs|+ 1 2e\u03b2 I|Xs|=0 ))] .\nTerms that do not involve products of the form |Xs||Xs\u2032 | or |Xs|I|Xs\u2032 |=0 can be straightforwardly reduced to linear combinations of expectations in Lemma 31. The remaining term yields the following:\nEX  \u2211 s,s\u2032\u2208S \u03c1s\u03c1s\u2032\u2016\u03c6s\u201622|Xs| ( |Xs\u2032 |+ 1 2e\u03b2 I|Xs\u2032 |=0 ) = \u2211 s\u2208S \u03c12s\u2016\u03c6s\u201622EX [ |Xs| ( |Xs|+ 1 2e\u03b2 I|Xs|=0\n)] + \u2211 s,s\u2032\u2208S s 6=s\u2032 \u03c1s\u03c1s\u2032\u2016\u03c6s\u201622EX [ |Xs| ( |Xs\u2032 |+ 1 2e\u03b2 I|Xs\u2032 |=0 )]\n= \u2211 s\u2208S \u03c12s\u2016\u03c6s\u201622 ( m2p2s +m(ps \u2212 p2s) ) + \u2211 s,s\u2032\u2208S s6=s\u2032 \u03c1s\u03c1s\u2032\u2016\u03c6s\u201622 ( m(m\u2212 1)psps\u2032 +mps,s\u2032 + 1 2e\u03b2 mp\u0304s,s\u2032(1\u2212 ps\u2032)m\u22121 ) ,\nwhere we used Lemma 31 again. Thus we get:\nEX,\u03b7[J\u03bbX(\u03b8\u0302\u03bbX)\u2212 J\u03bbX(\u03b8\u03bbX)] \u2264 C2\u03bb { \u03bbd\u2016\u03c1\u201622 m + d\u2016\u03a6\u20162\u2016\u03c1\u20162\u221e 2m \u2211 s\u2208S \u03c1s ( mps + 1 2e\u03b2 (1\u2212 ps)m ) +\n2\u2016\u03c1\u201622 m \u2211 s\u2208S \u03c1sps\u2016\u03c6s\u201622m+ \u2016\u03a6\u20162\u2016\u03c1\u20162\u221e \u03bbm \u2211 s\u2208S \u03c12s\u2016\u03c6s\u201622 ( m2p2s +m(ps \u2212 p2s) )\n+ \u2016\u03a6\u20162\u2016\u03c1\u20162\u221e\n\u03bbm\n\u2211 s,s\u2032\u2208S s 6=s\u2032 \u03c1s\u03c1s\u2032\u2016\u03c6s\u201622 ( m(m\u2212 1)psps\u2032 +mps,s\u2032 + 1 2e\u03b2 mp\u0304s,s\u2032(1\u2212 ps\u2032)m\u22121 ) The final result is obtained by grouping the terms in this expression by their dependence in \u03bb and m.\nNote that if we take \u03bb = \u03c9(1) with respect to m in the above theorem, then C\u03bb = O(1/\u03bb) and we get the following corollary.\nCorollary 33. Suppose \u03bb = \u03c9(1) with respect to m. Then we have EX,\u03b7[J\u03bbX(\u03b8\u0302\u03bbX)\u2212 J\u03bbX(\u03b8\u03bbX)] = O ( 1\n\u03bbm +\n1 \u03bb2 + m \u03bb3\n) . (59)"}], "references": [{"title": "Privacy-preserving logistic regression", "author": ["Kamalika Chaudhuri", "Claire Monteleoni"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Chaudhuri and Monteleoni.,? \\Q2009\\E", "shortCiteRegEx": "Chaudhuri and Monteleoni.", "year": 2009}, {"title": "Differentially private empirical risk", "author": ["Kamalika Chaudhuri", "Claire Monteleoni", "Anand D Sarwate"], "venue": "minimization. volume 12. JMLR. org,", "citeRegEx": "Chaudhuri et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Chaudhuri et al\\.", "year": 2011}, {"title": "Differential privacy. In Proceedings of the 33rd international conference on Automata, Languages and Programming-Volume Part II, pages", "author": ["Cynthia Dwork"], "venue": null, "citeRegEx": "Dwork.,? \\Q2006\\E", "shortCiteRegEx": "Dwork.", "year": 2006}, {"title": "The algorithmic foundations of differential privacy", "author": ["Cynthia Dwork", "Aaron Roth"], "venue": "Foundations and Trends in Theoretical Computer Science,", "citeRegEx": "Dwork and Roth.,? \\Q2014\\E", "shortCiteRegEx": "Dwork and Roth.", "year": 2014}, {"title": "Differentially private learning with kernels", "author": ["Prateek Jain", "Abhradeep Thakurta"], "venue": "In Proceedings of the 30th International Conference on Machine Learning", "citeRegEx": "Jain and Thakurta.,? \\Q2013\\E", "shortCiteRegEx": "Jain and Thakurta.", "year": 2013}, {"title": "near) dimension independent risk bounds for differentially private learning", "author": ["Prateek Jain", "Abhradeep Guha Thakurta"], "venue": "In Proceedings of The 31st International Conference on Machine Learning,", "citeRegEx": "Jain and Thakurta.,? \\Q2014\\E", "shortCiteRegEx": "Jain and Thakurta.", "year": 2014}, {"title": "Adaptive estimation of a quadratic functional by model selection", "author": ["Beatrice Laurent", "Pascal Massart"], "venue": "Annals of Statistics,", "citeRegEx": "Laurent and Massart.,? \\Q2000\\E", "shortCiteRegEx": "Laurent and Massart.", "year": 2000}, {"title": "Mechanism design via differential privacy", "author": ["Frank McSherry", "Kunal Talwar"], "venue": "In Foundations of Computer Science,", "citeRegEx": "McSherry and Talwar.,? \\Q2007\\E", "shortCiteRegEx": "McSherry and Talwar.", "year": 2007}, {"title": "Nearly optimal differentially private stochastic multi-arm bandits", "author": ["Nikita Mishra", "Abhradeep Thakurta"], "venue": "In UAI,", "citeRegEx": "Mishra and Thakurta.,? \\Q2015\\E", "shortCiteRegEx": "Mishra and Thakurta.", "year": 2015}, {"title": "Smooth sensitivity and sampling in private data analysis", "author": ["Kobbi Nissim", "Sofya Raskhodnikova", "Adam Smith"], "venue": "In Proceedings of the thirty-ninth annual ACM symposium on Theory of computing,", "citeRegEx": "Nissim et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Nissim et al\\.", "year": 2007}, {"title": "Smooth sensitivity and sampling in private data", "author": ["Kobbi Nissim", "Sofya Raskhodnikova", "Adam Smith"], "venue": "Journal of Privacy and Confidentiality,", "citeRegEx": "Nissim et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Nissim et al\\.", "year": 2011}, {"title": "Nearly optimal algorithms for private online learning in full-information and bandit settings", "author": ["Adam Smith", "Abhradeep Thakurta"], "venue": "In NIPS,", "citeRegEx": "Smith and Thakurta.,? \\Q2013\\E", "shortCiteRegEx": "Smith and Thakurta.", "year": 2013}, {"title": "Learning to predict by the methods of temporal differences", "author": ["Richard S. Sutton"], "venue": "Machine Learning,", "citeRegEx": "Sutton.,? \\Q1988\\E", "shortCiteRegEx": "Sutton.", "year": 1988}, {"title": "Reinforcement learning: An introduction", "author": ["Richard S Sutton", "Andrew G Barto"], "venue": "MIT press,", "citeRegEx": "Sutton and Barto.,? \\Q1998\\E", "shortCiteRegEx": "Sutton and Barto.", "year": 1998}, {"title": "Algorithms for reinforcement learning", "author": ["Csaba Szepesv\u00e1ri"], "venue": null, "citeRegEx": "Szepesv\u00e1ri.,? \\Q2010\\E", "shortCiteRegEx": "Szepesv\u00e1ri.", "year": 2010}, {"title": "Differentially private feature selection via stability arguments, and the robustness of the lasso", "author": ["Abhradeep Guha Thakurta", "Adam Smith"], "venue": "In Conference on Learning Theory,", "citeRegEx": "Thakurta and Smith.,? \\Q2013\\E", "shortCiteRegEx": "Thakurta and Smith.", "year": 2013}, {"title": "Algorithms for differentially private multi-armed bandits", "author": ["Aristide C.Y. Tossou", "Christos Dimitrakakis"], "venue": "In International Conference on Artificial Intelligence", "citeRegEx": "Tossou and Dimitrakakis.,? \\Q2016\\E", "shortCiteRegEx": "Tossou and Dimitrakakis.", "year": 2016}], "referenceMentions": [{"referenceID": 13, "context": "Reinforcement learning [Sutton and Barto, 1998] provides a variety of algorithms capable of handling such tasks.", "startOffset": 23, "endOffset": 47}, {"referenceID": 2, "context": "Differential privacy (DP) [Dwork, 2006] is a very active research area, originating from cryptography, but which has now been embraced by the machine learning community.", "startOffset": 26, "endOffset": 39}, {"referenceID": 2, "context": "DP is a formal model of privacy used to design mechanisms that reduce the amount of information leaked by the result of queries to a database containing sensitive information about multiple users [Dwork, 2006].", "startOffset": 196, "endOffset": 209}, {"referenceID": 15, "context": ", 2012, Jain and Thakurta, 2013], and the lasso [Thakurta and Smith, 2013].", "startOffset": 48, "endOffset": 74}, {"referenceID": 7, "context": "In the context of machine learning, differentially private algorithms are useful because they allow learning models in such a way that their parameters do not reveal information about the training data [McSherry and Talwar, 2007].", "startOffset": 202, "endOffset": 229}, {"referenceID": 2, "context": "Dwork and Roth [2014]) samples each component of the noise \u03b7 = (\u03b71, .", "startOffset": 0, "endOffset": 22}, {"referenceID": 9, "context": "Nissim et al. [2007] showed that approaches based on LSp do not lead to differentially private algorithms, and then proposed an alternative framework for DP mechanisms with data-dependent perturbations based on the idea of smoothed sensitivity.", "startOffset": 0, "endOffset": 21}, {"referenceID": 13, "context": "We will use a Monte Carlo approach, in which the returns of the trajectories in X are used as regression targets to fit the parameters in V\u0302 \u03c0 via a least squares approach [Sutton and Barto, 1998].", "startOffset": 172, "endOffset": 196}, {"referenceID": 15, "context": "On the other hand, it is known that differential privacy is tightly related to certain notions of stability [Thakurta and Smith, 2013], and optimization problems with non-unique solutions generally pose a problem to stability.", "startOffset": 108, "endOffset": 134}, {"referenceID": 9, "context": "We use the smooth sensitivity framework of [Nissim et al., 2007, 2011], which provides tools for the design of DP mechanisms with data-dependent output perturbations. We rely on the following lemma, which provides sufficient conditions for calibrating Gaussian output perturbation mechanisms with variance proportional to smooth upper bounds of the local sensitivity. Lemma 1 (Nissim et al. [2011]).", "startOffset": 44, "endOffset": 398}, {"referenceID": 9, "context": "Lemma 4 (Nissim et al. [2007]).", "startOffset": 9, "endOffset": 30}, {"referenceID": 9, "context": "For some functions \u03c6, the upper bound \u03c8 can be hard to compute or even approximate [Nissim et al., 2007].", "startOffset": 83, "endOffset": 104}, {"referenceID": 5, "context": "In particular, we cannot leverage the tight utility analysis of [Jain and Thakurta, 2014] to get dimension independent bounds.", "startOffset": 64, "endOffset": 89}, {"referenceID": 12, "context": "First, we would like to design DP policy evaluation methods based on temporal-difference learning [Sutton, 1988].", "startOffset": 98, "endOffset": 112}, {"referenceID": 9, "context": "A proof of Lemma 1 in the paper can be found in the pre-print Nissim et al. [2011]. For the sake of completeness, we provide here an elementary proof (albeit with slightly worse constants).", "startOffset": 62, "endOffset": 83}, {"referenceID": 6, "context": "On the other hand, X = \u2016Z1 \u2212 \u03bc1\u2016/\u03c3 1 \u223c \u03c7d follows a chi-squared distribution with d degrees of freedom, for which is known Laurent and Massart [2000] that for all t \u2265 0: P[X > d+ 2 \u221a dt+ 2t] \u2264 e\u2212t .", "startOffset": 123, "endOffset": 150}], "year": 2016, "abstractText": "We present the first differentially private algorithms for reinforcement learning, which apply to the task of evaluating a fixed policy. We establish two approaches for achieving differential privacy, provide a theoretical analysis of the privacy and utility of the two algorithms, and show promising results on simple empirical examples.", "creator": "LaTeX with hyperref package"}}}