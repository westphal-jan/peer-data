{"id": "1603.03703", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "11-Mar-2016", "title": "Searching for Topological Symmetry in Data Haystack", "abstract": "Finding interesting symmetrical topological structures in high-dimensional systems is an important problem in statistical machine learning. Limited amount of available high-dimensional data and its sensitivity to noise pose computational challenges to find symmetry. Our paper presents a new method to find local symmetries in a low-dimensional 2-D grid structure which is embedded in high-dimensional structure. To compute the symmetry in a grid structure, we introduce three legal grid moves (i) Commutation (ii) Cyclic Permutation (iii) Stabilization on sets of local grid squares, grid blocks. The three grid moves are legal transformations as they preserve the statistical distribution of hamming distances in each grid block. We propose and coin the term of grid symmetry of data on the 2-D data grid as the invariance of statistical distributions of hamming distance are preserved after a sequence of grid moves. We have computed and analyzed the grid symmetry of data on multivariate Gaussian distributions and Gamma distributions with noise. Our algorithm was adapted for several reasons in order to maximize the efficiency of the algorithm.\n\n\n\n\n\nThe two-dimensional grid structure of a high-dimensional grid is a mathematical mechanism for finding a mathematical consistency. The number of squares per grid is given by the number of squares per grid. These numbers are multiplied by a ratio of the two-dimensional scale. A linear distribution of squares per grid is determined by the square root of the number of squares per grid. In order to solve this problem, we first define a linear, Gaussian derivative that is, at an exponential level, the shortest, shortest, and fastest.\n\nIn this case the shortest is the shortest. For the longest, there is a finite number of square root square root square root square root squares per grid. The shortest is the shortest. For the longest, there is a finite number of square root square root square root square root square root square root square root square root square root square root square root square root square root square root square root square root square root square root square root square root square root square root square root square root square root square root square root square root square root square root square root square root square root square root square root square root square root square root square root square root square root square root square root square root square root square root square root square root square root square root square root square root square root square root square root square root square root square root square root square root square root square root square root square root square root square root square root square root square", "histories": [["v1", "Fri, 11 Mar 2016 17:47:00 GMT  (1075kb)", "http://arxiv.org/abs/1603.03703v1", null]], "reviews": [], "SUBJECTS": "cs.LG", "authors": ["kallol roy", "anh tong", "jaesik choi"], "accepted": false, "id": "1603.03703"}, "pdf": {"name": "1603.03703.pdf", "metadata": {"source": "CRF", "title": null, "authors": [], "emails": [], "sections": [{"heading": null, "text": "ar X\niv :1\n60 3.\n03 70\n3v 1\n[ cs\n.L G\n] 1\n1 M\nar 2\nFinding interesting symmetrical topological structures in high-dimensional systems is an important problem in statistical machine learning. Limited amount of available high-dimensional data and its sensitivity to noise pose computational challenges to find symmetry. Our paper presents a new method to find local symmetries in a low-dimensional 2-D grid structure which is embedded in high-dimensional structure. To compute the symmetry in a grid structure, we introduce three legal grid moves (i) Commutation (ii) Cyclic Permutation (iii) Stabilization on sets of local grid squares, grid blocks. The three grid moves are legal transformations as they preserve the statistical distribution of hamming distances in each grid block. We propose and coin the term of grid symmetry of data on the 2-D data grid as the invariance of statistical distributions of hamming distance are preserved after a sequence of grid moves. We have computed and analyzed the grid symmetry of data on multivariate Gaussian distributions and Gamma distributions with noise."}, {"heading": "1 Introduction", "text": "The current hurdle in big data is to develop machine learning representations which can extract meaningful features. The principle of symmetry plays a natural foundation in the development of such a learning representation by getting rid of unimportant variations, while making the important ones easy to detect. Exploiting symmetries reduces computational complexity and leads to the development of new generalizations of learning algorithms and provides a new approach in deep symmetry networks [Gens and Domingos, 2014; Badrinarayanan et al., 2015]. There is recent interest in exploiting cyclic symmetry in convolution neural network architectures[Dieleman et al.,\n2016; Dieleman et al., 2015]. Encoding these properties in networks by using the transnational equivariance allows the model for parameter budgeting efficiently.\nSearching for symmetry in high-dimensional objects under certain low complexity constraints though possible is a computationally challenging task. Symmetry based machine learning are broadly classified as (1) Exchangeable variable models [Niepert and Domingos, 2014] (2) Deep Symmetry Networks (3) Symmetry based semantic parsing [Poon and Domingos, 2009].\nOne way to solve this problem is to use a topologypreserving dimensionality reduction method, and then search for symmetrical structures. High-dimensional models with low-dimensional structures of patterns or symmetry are ubiquitous. Extracting low-dimensional structures in high-dimensional models have widespread uses in various disciplines including neuroscience, economics, and genetics. Our work is inspired by the Noether\u2019s Theorem of unification symmetry and conservation in theoretical physics [Schwarzbach and Kosmann-Schwarzbach, 2010]. This paper presents a novel method of searching symmetry on 2\u2212D grid space, where the Betti number, an important topological property in persistent homology, is computed (or efficiently approximated). We define three grid moves (i) Commutation (ii) Cyclic Permutation (iii) Stabilization on grid blocks, consisting of a finite number of local grid squares. Our algorithm finds symmetry in each grid block after a finite sequence of grid moves. We prove the upper bound of the Hamming distance H(n) is bounded. We have used the metric of Hamming distance as measure of randomness in the search of symmetry. The randomness may come from the added noise in the signal data or inherently embedded in the data. Our proposed method of topological data processing is immune the to effect of noise for most cases and is used for searching the local symmetry. Our method of estimating the upper bound of the Hamming distance H(n) can be useful in detecting the phase change in data, which have profound implications in security, finance, and other areas.\nThe organization of the paper is as follows: Section 2\ngives a quick introduction to Low-Dimensional Topological Models, Subsection 2 will introduce the newly construct of Grid Diagrams perspective, Section 3 will explain our method of searching symmetry, Section 4 explain our newly proposed Ising model of data, Section 5 explains the related work, Section 6 presents our experimental results and Section 7 concludes the paper. We have used the following important notations in our paper\nNotations\n(1) \u03b2 Betti number (2) H Hamming distance (3) g Small square grid (4) G 2D Grid (5) l Dimension of small grid (6) H Hamiltonian (7) \u03c3 Configuration (8) Jg1,g2 Grid interaction parameter (9) \u0393(l) Scaling invariant parameter (10) T1,T2,T3 Commutation, Cyclic Permutation, Stabilization"}, {"heading": "2 Low-Dimensional Topological Models", "text": "Our Algorithm of finding the symmetry in Data uses the topological features to search the local symmetry. Our method is of general nature and features other than the topological ones can be extended in it. We encode our Data space as a topological space, because of its highdimensional features (symmetry and connectivity) can be inferred from its low-dimensional, local representations as in [Chen and Rong, 2010; Edelsbrunner, 2007; Carlsson, 2014].\nTopological Invariants on Data Manifolds\nComputing topological invariants in low-dimensional space is used for exploring the symmetry in data space in our paper. Homology groups are increasingly used in computing the invariants as their computations are more feasible and provide the important information about the shape of the object. The homology groups for the 2\u2212D object are computed efficiently by the digitization [Evako, 2006; Chen and Rong, 2010; Chen, 2004]. Digital topology allows discretizing data object by integrating the geometric and topological constraints. The digital model of a 2\u2212dimensional continuous object is called a digital 2\u2212surface. The intrinsic topology of the object is used without referring to an embedding space. A set D is defined as a 2\u2212cell if it is homeomorphic to a closed unit square, similarly, a set D is a 1\u2212cell if it is homeomorphic to a closed unit segment and a set D is a circle(or 1\u2212sphere) if it is homeomorphic to a unit circle. The interior and the boundary of an n\u2212cell D, are denoted as IntD and \u2202D with\nthe following boundary condition\nD = IntD\u222a\u2202D (1)\nIntuitively we can visualize the boundary of a 1\u2212 cell has two endpoints, the boundary of a 2\u2212cell is a circle. For the sake of completeness, we define 0\u2212cell as a single point for which \u2202D = /0. The following properties hold for digital topology \u2022 For a circle C and a 1\u2212cell D contained in C the set C\u2212 IntD is a 1\u2212cell. \u2022 If 1\u2212cells C1 and C2 are such that C1\u2229C2 = \u2202C1\u2229\u2202C2 = v holds, then C1 \u222aC2 = E is a 1\u2212cell. \u2022 For 2\u2212cells D1 and D2 such that D1\u2229D2 = \u2202D1\u2229\u2202D2 = C is a 1\u2212cell holds, then D1 \u222aD2 = B is a 2\u2212 cell. \u2022 An (i+ 1)\u2212cell can be formed by two disjoint i\u2212cells that are parallel \u2022 An i\u2212cell and it\u2019s parallel move form an (i+ 1)\u2212cell. We now formally define the Digital Surface as\nDefinition (Digital Surface). A digital surface is the set of surface points each of which has two adjacent components not in the surface in its neighborhood\nIn 2\u2212D space, algorithms to compute Betti numbers are of complexity O(n log2 n) or O(n log3 n). Our paper use the properties of manifolds in 2\u2212D digital spaces for the computation of topological invariants. We formally define digital manifold as\nDefinition (Digital Manifold). A connected subset S in digital space \u2211 is a i\u2212D digital manifold if \u2022 Any two i\u2212cells are (i\u2212 1) connected in S \u2022 Every (i-1)cell in S has only one or two parallel-moves in S \u2022 S does not contain any (i+ 1)\u2212cell\nWe represent a compact 3\u2212dimensional manifold in R3 by a surface. Then the homology group is expressed in terms of its boundary surface. The Betti numbers related to homology groups are used in topological classification. For a k\u2212 manifold, homology group Hi, i = 0, \u00b7 \u00b7 \u00b7 ,k, indicates the number of holes in each i\u2212skeleton of the manifold. For a topological space M, its homology groups, Hi(M) are certain measures of i\u2212dimensional holes in M.\nDefinition (Betti number). The Betti number \u03b2 is formally defined as the rank of the quotient group as\n\u03b2 = rankHi(M) (2)\nIn our algorithm we use the statistical distribution of Betti number \u03b2 in each small grid square of length l for computing of local symmetry.\nGrid Diagrams for Low-Dimensional Topology\nA grid diagram is defined as a two dimensional square grid such that each square inside the grid is filled with symbols x, o or is left blank, with the constraint such that every column and every row has exactly one x and one o. The symbols x and o are abstract decorations that fill the small grid square.\nThe grid number for the grid diagram is the number of columns (or rows). The grid diagram is associated with an equivalent knot by joining the x and o symbols in each column and row by a straight line with the convention of vertical lines crosses over the horizontal lines (as shown by the dotted red lines in Figure 1). These lines joining the symbols x and o form the strands of the knot and removing the grid give us the planar projection of the knot (trivial knot in our example) as shown in Figure 1 [Manolescu, 2012; Ozsv\u00e1th et al., 2015; Sarkar, 2010]. Grid diagrams are extensively used recently because of the use the grids gives a combinatorial definition of knot Floer homology [Sarkar and Wang, 2010].\nThree grid moves (explained in Section 3) to relate the grid diagrams are (1) Commutation (T1) (2) Cyclic Permutations (T2) (3) Stabilization (T3) [Manolescu, 2012; Ozsv\u00e1th et al., 2015; Sarkar, 2010]. These grid moves are analogous to Reidemeister moves for knot diagrams. The grid moves are used to generate equivalent relations. Theorem 1 explains that a sequence of grid moves gives the invariant knots. A knot invariant is defined in the form of a polynomial such as the Alexander polynomial, Conway polynomial, HOMFLY polynomial, Jones polynomial etc.\nTheorem 1. [Reidemeister, 1932] G1 is a grid diagram with its equivalent knot K1 and grid diagram G2 with its equivalent knot K2. K1 and K2 are equivalent knots if and only if there exists a sequence of commutation, stabilization and cyclic permutation grid moves transform G1 to G2.\nOur goal in this paper is to define the symmetrical invariance in grid diagrams under uncertainty. For searching the local symmetry we have moved away from generating knots from the planar grid diagrams and instead use the distribution of hamming distance among the grid blocks explained in Section 3. A finite sequence of operations T comprising of Commutation, Cyclic Permutation, Stabilization in a defined order is\nT = T a1 \u25e6T b 2 \u25e6T c 3 (3)\nwhere a,b,c \u2208 R. The stabilization operations T3 of kink addition and kink subtraction occur in pairs to maintain the constant grid number."}, {"heading": "3 Searching Symmetry with Uncertainty", "text": "Inference in high dimensional data is challenge because of the curse of dimensionality. Thus, high dimensional data are usually converted to low-dimensional codes by (1) Neural Networks [Hinton and Salakhutdinov, 2006]; (2) Nonlinear dimension reduction [Tenenbaum et al., 2000; Lee and Verleysen, 2007]; and (3) Topological and Geometric methods [Wang, 2012].\nIn this paper, we propose a new form of symmetry termed a grid symmetry with the following hypothesis.\nHypothesis 2 (Invariance of Symmetric Probability). The symmetry on a grid is represented by Commutation, Cyclic Permutation and Stabilization. The statistical distribution of the Betti numbers remains conserved during the above defined legal transformations.\nSymmetry of a geometric object comes with the concept of automorphisms. Legal transformations allowed for grid diagrams are 1 Commutation (2) Cyclic Permutations (3) Stabilization defined as in [Ozsv\u00e1th et al., 2015; Manolescu, 2012; Sarkar and Wang, 2010; Sarkar, 2010; Ozs, 2004; Hedden, 2008; Reidemeister, 1932]. Commutation: Commutation is defined as an interchange of two consecutive rows or columns of a grid diagram. The commutation is permitted only between rows or columns those are non-nested.\nCyclic Permutation: Cyclic permutation preserves the grid number and is defined as the removal of an outer row/column and replacing it to the opposite side of the grid.\nStabilization: Stabilization is performed by kink addition or removal and thus does not preserve the grid number. A\nkink is added either to the right or left of a column or above or below of a row. Adding a kink to a column c is done by inserting an empty row between the symbols x and o of the column c. Then an empty column is inserted either to the right or left of column c. We then move the either symbol x or o to the adjacent grid square in the added column. We then complete the added row and column with the symbols x and o appropriately. To add a kink to a row, we have to swap the row and column operations. To remove a kink (grid number decreases by 1), we follow the instructions in reverse order.\nAfter projecting the high dimensional data to our 2D grid space, we compute the Betti number \u03b2 in each small grid square of length l. We compute only a particular order of Betti number \u03b2k for a fixed k and mark the grid square with the Betti number if \u03b2k 6= 0 and leave the grid square empty if \u03b2k = 0. For example we fill up the small grid square if the number of holes in it is at least 1 i.e \u03b22 6= 0 and leave the grid square empty when \u03b22 = 0. We have used the symbol \u03b2 to represent \u03b2k for fixed k. We introduce this binary topological marking to get the sparse representation. For sufficiently sparse data we get a grid diagram where most of small grid squares are left empty and others are marked with \u03b2 . This binary marking makes our model consistent with the grid homology for the studying of invariance of knots. Here, the difference is that we investigate the invariance of the probabilistic distribution of Betti numbers using the metric of Hamming distance.\nAfter the marking of the grid squares, we randomly sample a square grid block of size l consisting of n2 small grid squares and apply a finite sequence of operations T defined in Equation 8 on the sampled grid block as shown in Figure 6. The small grid squares colored red and green as illustrated in Figure 6 are of dimension l. The sampled grid block ABCD on which the sequence of operations T are applied is shown as shaded grey in Figure 6. The sequence of finite operations changes the arrangements of Betti numbers in the sampled grid block denoted as H in Figure 6. The grid squares which were not marked with Betti number \u03b2 before the transformation T may now be marked or filled with Betti number \u03b2 . This means to say that the position arrangements of Betti number \u03b2 .\nWe now introduce the concept of symmetry as the amount of reshuffling happen because of the application of Transformation operation T . We have used the metric of Hamming distance Hx to capture the degree of reshuffling. We have moved away from the elementary concept of mirror symmetry and introduced the concept of Grid Symmetry. Our grid symmetry is with the respect to a particular feature of the data like distribution of holes, connected components etc. We have particularly used the topological features as it is more robust to noise. Our method is quite general and can be extended to other features of the data. To compute the Hamming distance, we have used the following notations\n1. Each small grid square at location i and j is marked as (i, j).\n2. |(i,j)| represents the occupation of the small grid square with the Betti number (\u03b2 6= 0) and is defined formally as,\n|(i, j)|=\n{\n1 if the grid square is occupied 0 if the grid square is not occupied\n3. The Hamming distance Hi, j computed along each row is given by\nHi, j = |(i, j)|\u2295 |(i, j \u2032 )|,\nwhere the interchange of two consecutive columns T = T1 is given by \u03c0( j) = j \u2032 , and pasting the outermost column before the first T = T2 is given \u03c0(1) = j \u2032 for. \u03c0 is the permutation operator. Here T1 and T2 are commutation and cyclic permutations as defined in the Section 2.\n4. The Hamming distance computed over the sampled grid block H(n) is given by,\nH(n) = n\n\u2211 i=1\n|(i, j)|\u2295 |(i, j \u2032 )|, (4)\nwhere n is the grid number of the sampled block and \u2295 denotes the mod 2 operations.\nIntuitively the Hamming distance H(n) denotes the positional changes of the Betti number \u03b2 after the finite sequence of operations. We now formally define the symmetric distribution of Betti numbers in our grid diagram context as the change positional changes of Betti number in small grid squares as shown Figure 5. The Figure 5 shows the Hamming distance after the applications of operations. The original grid block containing a particular configurations \u03c3 of Betti number \u03b2 changes the number of positional distribution after the application of T2 as 12. So the hamming distance between the two configurations is\n12. After the operation of T2 again the Hamming distance decreases to 6, then after application of the operation T1 the hamming distance increases to 14 and lastly after the operation of T1 again the Hamming distance falls back to 6. The oscillating nature of Hamming distance H is upper bounded proved in our paper in the Section 4.\nDefinition (Symmetric Distribution). The probability distribution over Betti numbers \u03b2 on a local grid block of size n is symmetric, if the Hamming distance Hi, j computed over the grid block (Equation (4)) is bounded by \u03b7 after a finite sequence of operations T ,\nH(n)\u2264 \u03b7(n, l) (5)\nwhere \u03b7(n, l) is a integer parameter of choice and it depends on grid number of the sampled block and the grid parameter l.\nThe conditional probability Pr(H \u2264 \u03b7) is computed as\nPr(H \u2264 \u03b7) = Pr(\u03c3 |H \u2264 \u03b7)Pr(\u03c3) (6)\nFor the case of Cyclic Permutation operation, it is intuitive to see the local symmetry axis passing through the middle of the sampled grid block if the H(n) = 0. The value of H(n) gives us the sense of symmetry. More the value of H(n) less will be the symmetry of the sampled grid block. Next, we prove the upper bound of the Hamming distance H(n) is bounded.\nFor our proof of bounded upper bound of Hamming distance, we assume some known discrete distribution of Betti number \u03b2 on the small grid square i.e the probability distribution f\u03b2 (i, j) of \u03b2 on the grid square (i, j) follows some distributions. This approximation is valid as the real world\ndata lies in between truly random distribution and a probability distribution.\nTo simplify the notations, we denote x = {(i, j), l} and the probability density function f\u03b2 = f\u03b2 (x). From hence onward we also denote f\u03b2 (x) as f (x). Thus f\u03b2 (x) defines the probability that the grid square (i, j) will be occupied by \u03b2 . Note that, f\u03b2 (x) is a multivariate function [Holtz, 2008; Garcke and Pf\u00fclger, 2014]. In the proof, we have used 2 dimensions as (1) position of the grid square (2) size of the small grid square l."}, {"heading": "4 The Ising Model on a 2-D Grid", "text": "We formally propose a new Ising model of Data and compute the statistical distribution of the Betti numbers. Our modeling of data on a 2\u2212D grid surface and digitization of Betti numbers are analogous to the spin configuration as in the Quantum Ising Model. We draw those parallels from the physical Ising model [Chakrabarti et al., 1996; Grimmett, 2010] and propose an analogous Data Ising Model. We then compute a probabilistic distribution of configurations Betti numbers on the grid. This allows us to find the symmetric distribution for the sampled grid after the finite sequence of operations of commutation, cyclic permutation and stabilization. We introduce the following notations.\nWe denote the 2\u2212D planar grid G = (g,N), where g is the small grid square and N is the set of neighboring grid squares as shown in Figure 7. The small red square grid is surrounded by the set N of four green squares grid as shown in Figure 7. To each small square grid g \u2208 G, we associate a number 1 or 0 analogous to quantum spin as in Quantum Ising Model with the local two-dimensional Hilbert space C2 [Grimmett, 2010; Chakrabarti et al., 1996]. We associate each small grid square g with 1 if the Betti number computed on it is not equal to 0, and leave the grid square g vacant(as in our model) or mark it with 0. This marking leaves us the planar grid as a block spin configuration. This allows us to write the configuration space for our planar grid as the tensor product of the grid states (1) and 0 as explained before.\nThe configuration space H for the planar 2\u2212D planar grid is expressed as\nH = \u2297\ng\u2208G\nC (7)\nfor the local Hilbert space C. The eigenvectors for the Hilbert space C2 are e1 = ( 1 0 )T , e2 = ( 0 1 )T of the matrix \u03c3 (3)g = (\n1 0 0 \u22121\n)\nat the small grid site g,\nwith eigenvalues \u00b11. The other two matrices are \u03c3 (1)g = (\n1 0 0 \u22121\n) , \u03c3 (2)g = ( 1 0 0 \u22121 ) . We the propose the opera-\ntor H for our 2\u2212D planar grid analogous to the Hamiltonian concept as\nH =\u2212 \u2211 g1,g2\u2208G Jg1,g2\u03c3 (3) g1 \u03c3 (3) g2 \u2212\u0393 \u2211 g\u2208G \u03c31g (8)\nwhere g1 and g2 are neighboring small grid squares as shown in Figure 7.\nThe parameter Jg1,g2 is defined as the interaction strength between the small grid squares g1 and g2. The parameter Jg1,g2 is critically dependent on the boundaries \u2202g1 \u2202g2 and grid length l. The interaction parameter indicates the continuity of data manifold. The parameter \u0393 in our model denotes the rate of change hierarchical continuity of across the data manifold. The is hierarchical scaling variance parameter \u0393(l) is a function of the dimension of small grid square l.\nThe probability for a configuration \u03c3 of Betti numbers in our 2\u2212D planar grid G based on our data based Ising model is\nPG(\u03c3) = 1\nZG e\u2212\u03c4H(\u03c3 ) (9)\nwhere \u03c4 is a parameter. The normalization constant is for all possible configurations \u03c3 is given by\nZG = \u2211e\u2212\u03c4H(\u03c3 ) (10) The expected value for a function < f (\u03c3) > of configurations is\n< f (\u03c3) >= \u2211 \u03c3 f (\u03c3)PG(\u03c3) (11)\nWe compute the expected value H(\u03c3) of the number of using our proposed Data Ising Model\n< H(\u03c3)>= \u2211 \u03c3 H(\u03c3)PG(\u03c3) (12)\nRemark (Symmetric Distributions: Trivial Cases). Given a grid block, when either P(|(i, j)|) = 1 \u2200i, j or P(|(i, j)|) = 0 \u2200i, j, the Hamming distance is 0 after any sequence of legal grid moves.\nRemark (The Bernoulli Distribution of the Betti Numbers). Given a grid block of size n, when the distribution\nof the Betti numbers in each grid square independently follows the Bernoulli distribution with a parameter p, the expected Hamming Distance after a sequence of grid moves is 2n2 p(1\u2212 p).\nTheorem 3 (Bounded Hamming Distance between Symmetric Grid). When Commutation, Cyclic Permutation and Stabilization are allowed grid moves in a grid block, the statistical distribution measured by Hamming distance H(n) remains bounded after a sequence of grid moves.\nProof. Let \u2126 \u2286 R be a set and a d(= 2) dimensional product measure defined on Borel subsets of \u21262 using dimension-wise decomposition approximations as\nd(x) = \u220fd\u00b5 j(x j) = d\u00b51(x1) \u00b7d\u00b52(x2), (13) where x = (x1,x2) and \u00b5 j ( j = 1, \u00b7 \u00b7 \u00b7 ,d) are probability measures on Borel subsets of \u2126. Here x1 = (i, j), x2 = l\nLet V (2) is the Hilbert space of all functions. We define f (x) as a multivariate density function defined as\nf : \u21262 \u2192 [0,1]. (14)\nFor a subset u \u2286 D , where D = {1,2}, the measure \u00b5 induces projection functions Pu : V (2) \u2192V (|u|) by\nPu f (xu) := \u222b\n\u2126d\u2212||u| f (x)d\u00b5D\\u(x) (15)\nHere xu denotes the |u|\u2212dimensional vector and d\u00b5D\\u(x) := \u220f j/\u2208u d\u00b5 j(x j).\nFor u = /0 the projection function is given as\nP/0 f (x /0) = \u222b\n\u21262 f (x)d\u00b5(x) =: A (16)\nf \u2208V (2) is then decomposed using dimension-wise decomposition and as\nf (x) = \u2211 u\u2286D fu(xu) (17)\nwith the orthogonality conditions\n( fu, fu) = 0, u 6= v (18)\nThe fu are computed recursively as\nfu(xu) = Pu f (xu)\u2212 \u2211 v\u2282u fv(xv) (19)\nUsing the classical ANOVA Decomposition and orthogonality condition we write the variance \u03c3( f )2 as\n\u03c32( f ) = \u222b\n\u2126d ( f (x)\u2212A)2d(x)\n= \u2211 u\u2286D , u6= /0\n\u03c32( fu) (20)\nwhere \u03c32( fu) denotes the variance of fu.\nNow we compute the probability of Hamming distance H = m for a grid block consisting of n2 grid squares as\nPr[H] = Pr[ n\n\u2211 i=1\n|(i, j)|\u2295 |(i, j \u2032 )|]\n\u2264 n\n\u2211 i=1\nPr[|(i, j)|\u2295 |(i, j \u2032 )|]\n(21)\nNow for the case m > n2, Pr[H = m] = 0. To get the tighter upper bound we use the transformation of random variables and write as there exists a map g and g\u221211 as\nH = g1(X) (22)\nX = g\u221211 (H) (23)\nWe prove the the upper bound of Hamming distance after a finite sequence of Chebyshev\u2019s inequality we write\nPr[H > k\u03c7(\u03c3)] = Pr[g1(X)> k\u03c7(\u03c3)]\n\u2264 1 k\u03ba(\u03c3) (24)\nwhere \u03c7(\u03c3) and \u03ba(\u03c3) are functions that depend on the variance of f (x)\nWe have proposed a general Algorithm"}, {"heading": "5 Related Work", "text": "The symmetric features of the data set like rotation symmetry, translation symmetry are used as a feature and used a priory in Bayesian machine learning [Culbertson and Sturtz, 2013] or used in training the convolutional neural network layers [Dieleman et al., 2016; Dieleman et al., 2015]. Analogous to our definitions of symmetric operations of cyclic permutation, commutation and stabilization, [Dieleman et al., 2016] proposes four operations which is inserted in neural network model as layers to model the translation equivariance into rotation equivariance. The notion of equivariance is formally defined as\nDefinition (Equivariant Function). The function f is defined as equivariant for a class of transformations T , if for all transformations T \u2208T of the input x, there exists a corresponding transformation T \u2032 of the output f (x), such that the following condition holds\nf (T(x)) = T \u2032 f (x) (25)\nThe patterns at different spatial positions are encoded similarly in the feature representations by these layers. This allows parameter sharing much more effectively than a fully\nAlgorithm 1 Searching Local Symmetry\nRequire: Marked Grid Diagram 1: procedure HAMMING DISTANCE(Sampled Grid\nBlock) 2: Call Generating Grid Diagram 3: Sample the grid diagram G 4: Call T1, T2, T3 to generate T (G) = T a1 \u25e6T b 2 \u25e6T c 3 5: Apply T (G) on the sampled Grid Block 6: Compute H(n) = \u2211ni=1 |(i, j)|\u2295 |(i, j \u2032 )| 7: if H(n)\u2264 \u03b7 then 8: the sampled grid is symmetric 9: else the sampled grid is not symmetric\n10: end if 11: end procedure\nGenerating Grid Diagram\nRequire: Marking Each Small Grid Square with \u03b2 12: function COMPUTING(Betti Number \u03b2 ) 13: Construct the Grid G of parameters n and l 14: G(i, j) is the position of small grid square at (i, j)\nposition. 15: Construct Simplicial Complex for each G(i, j) 16: Compute the quotient space Hk(X) = ker\u2202k ker\u2202k+1 17: \u03b2 = dim (Hk(X)) 18: Mark G(i, j) with \u03b2 if \u03b2 6= 0 19: Leave G(i, j)e empty if \u03b2 6= 0 20: end function\nCommutation Operation T1 21: procedure COMMUTATION(G) \u22b2 T1 22: c \u2190 1 23: while c \u2264 n\u2212 1 do 24: swap column c and c+ 1 25: c \u2190 c+ 2 26: end while 27: end procedure\nCyclic Permutation T2 28: procedure CYCLIC PERMUTATION(G) \u22b2 T2 29: for c \u2208 1 . . .n do 30: for r \u2208 1 . . .n do 31: if c = 1 then G(c,r) = G(n,r) 32: else G(c,r) = G(c\u2212 1,r) 33: end if 34: end for 35: end for 36: end procedure\nStabilization T3 37: procedure STABILIZATION(G) \u22b2 T3 38: Randomly pick a column c and split it into two 39: insert an empty row and fill the intersections with\ntwo columns with \u03b2 40: end procedure\nconnected neural network under similar conditions. They extended to rotation invariance by introducing the four operations of (1) Slice (2) Roll (3) Pool (4) Stack to build CNNs. The CNNs will detect the cyclic symmetry in the input data by the rotation over the angles k.90o,k \u2208 {0,1,2,3}. They this group of four rotations form a cyclic group of order 4(C4) as a restricted form rotational symmetry called cyclic symmetry. Similarly the dihedral symmetryD4 is defined as a set of total eight possible orientations after the operation of horizontal flipping. [Dieleman et al., 2016] proposes the computation of approximate invariance by the method of data augmentation as presenting the network during training with examples that are randomly perturbed. Given a network with sufficient capacity, it learn invariances."}, {"heading": "6 Experimental Results", "text": "In this section, we setup a grid block with size 1000\u00d71000. We conduct two scenarios of sampling Betti number. In the first case, Betti number positions are sampled inside the grid with by a mixtures two Gaussian distributions N (\u00b51,\u03a31) and N (\u00b52,\u03a32). A 2-dimensional Gamma distribution \u0393(k,\u03b8 ) is chosen to generate Betti number position in the second case. The grid block of sampled Betti number position is divided into subsample grid squares with size 5\u00d7 5. We perform grid moves including commutation, cyclic permutation, stabilization on these local grid squares. After the transformations, the Hamming distances are obtained between the original grid squares and the corresponding transformed grid squares. With this synthetic data, we conduct four types of tests including (a) commutation, (b) cyclic permutation, (c) chain of transformations, and (d) chains of transformation with noise data. The contour line illustrations of results are portrayed in Figure 8 and 9 respectively for the mixture of Gaussian case and Gamma case."}, {"heading": "7 Conclusions", "text": "We have proposed a novel method of finding symmetry termed as grid symmetry in data by developing a new framework of 2\u2212D grid space. We have proposed three fundamental operations of commutation, cyclic permutation and stabilization to determine the symmetry. The methods of statistical topology i.e distribution of Betti number is used as a feature in checking symmetry in data. Our method is particularly helpful Bayesian machine learning where the topological feature(Betti number) is encoded a priory. Our method of spatial distribution of Betti numbers on 2D grid can be encoded in constitutional neural network layers as the property of translation equivariance [Dieleman et al., 2016; Dieleman et al., 2015]. The method of data augmentation as described in [Dieleman et al., 2016] for the training of CNN\u2019s fits particularly well with our approach, as\nthe random perturbations are well described the topological deformations. Our method throws light on the directions of studying the deep machine learning using scale invariants. We have connected our low dimensional topology models with Ising. Modeling invariances in deep learning particularly so in unsupervised learning is an active area of research[Srivastava et al., 2015]. The recent Google\u2019s breakthrough cat neuron paper the authors uses the unshared weights to allow learning of more invariances other than translational invariances[Le et al., 2012]. Our modeling of topological invariances(Betti number) and priors in the data set naturally fits in the scheme. Further our Ising model parameter \u0393(l) captures scaling of invariants asymptotically, as we decrease the dimension of the small grid square l."}], "references": [{"title": "Understanding symmetries in deep networks", "author": ["Vijay Badrinarayanan", "Bamdev Mishra", "Roberto Cipolla"], "venue": "CoRR, abs/1511.01029,", "citeRegEx": "Badrinarayanan et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Badrinarayanan et al\\.", "year": 2015}, {"title": "Topological pattern recognition for point cloud data", "author": ["Gunnar Carlsson"], "venue": "Acta Numerica, 23:289\u2013368,", "citeRegEx": "Carlsson.,? \\Q2014\\E", "shortCiteRegEx": "Carlsson.", "year": 2014}, {"title": "Quantum ising phases and transitions in transverse ising models. Lecture notes in physics: Monographs", "author": ["B.K. Chakrabarti", "A. Dutta", "P. Sen"], "venue": null, "citeRegEx": "Chakrabarti et al\\.,? \\Q1996\\E", "shortCiteRegEx": "Chakrabarti et al\\.", "year": 1996}, {"title": "Digital topological method for computing genus and the betti numbers", "author": ["Li Chen", "Yongwu Rong"], "venue": "Topology and its Applications,", "citeRegEx": "Chen and Rong.,? \\Q1936\\E", "shortCiteRegEx": "Chen and Rong.", "year": 1936}, {"title": "Discrete Surfaces and Manifolds: A Theory of Digital-discrete Geometry and Topology", "author": ["L. Chen"], "venue": "Scientific & Practical Computing,", "citeRegEx": "Chen.,? \\Q2004\\E", "shortCiteRegEx": "Chen.", "year": 2004}, {"title": "Bayesian machine learning via category theory", "author": ["J. Culbertson", "K. Sturtz"], "venue": "ArXiv e-prints,", "citeRegEx": "Culbertson and Sturtz.,? \\Q2013\\E", "shortCiteRegEx": "Culbertson and Sturtz.", "year": 2013}, {"title": "Rotation-invariant convolutional neural networks for galaxy morphology prediction", "author": ["Sander Dieleman", "Kyle Willett", "Joni Dambre"], "venue": "Monthly Notices of the Royal Astronomical Society,", "citeRegEx": "Dieleman et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Dieleman et al\\.", "year": 2015}, {"title": "Exploiting Cyclic Symmetry in Convolutional Neural Networks", "author": ["S. Dieleman", "J. De Fauw", "K. Kavukcuoglu"], "venue": "ArXiv e-prints,", "citeRegEx": "Dieleman et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Dieleman et al\\.", "year": 2016}, {"title": "An introduction to persistent homology", "author": ["Herbert Edelsbrunner"], "venue": "In Proceedings of the 2007 ACM Symposium on Solid and Physical Modeling, Beijing,", "citeRegEx": "Edelsbrunner.,? \\Q2007\\E", "shortCiteRegEx": "Edelsbrunner.", "year": 2007}, {"title": "Topological properties of closed digital spaces: One method of constructing digital models of closed continuous surfaces by using covers", "author": ["Alexander V. Evako"], "venue": "Comput. Vis. Image Underst.,", "citeRegEx": "Evako.,? \\Q2006\\E", "shortCiteRegEx": "Evako.", "year": 2006}, {"title": "Sparse Grids and Applications - Munich", "author": ["Jochen Garcke", "Dirk Pf\u00fclger"], "venue": null, "citeRegEx": "Garcke and Pf\u00fclger.,? \\Q2012\\E", "shortCiteRegEx": "Garcke and Pf\u00fclger.", "year": 2012}, {"title": "Deep symmetry networks", "author": ["Robert Gens", "Pedro M Domingos"], "venue": "Advances in Neural Information Processing Systems", "citeRegEx": "Gens and Domingos.,? \\Q2014\\E", "shortCiteRegEx": "Gens and Domingos.", "year": 2014}, {"title": "Probability on Graphs: Random Processes on Graphs and Lattices. Institute of Mathematical Statistics Textbooks", "author": ["G. Grimmett"], "venue": null, "citeRegEx": "Grimmett.,? \\Q2010\\E", "shortCiteRegEx": "Grimmett.", "year": 2010}, {"title": "An ozsv\u00c3\u0105th\u00e2\u0102\u015eszab\u00c3\u015f floer homology invariant of knots in a contact manifold", "author": ["Matthew Hedden"], "venue": "Advances in Mathematics,", "citeRegEx": "Hedden.,? \\Q2008\\E", "shortCiteRegEx": "Hedden.", "year": 2008}, {"title": "Reducing the dimensionality of data with neural networks", "author": ["G E Hinton", "R R Salakhutdinov"], "venue": "Science,", "citeRegEx": "Hinton and Salakhutdinov.,? \\Q2006\\E", "shortCiteRegEx": "Hinton and Salakhutdinov.", "year": 2006}, {"title": "Sparse Grid Quadrature in High Dimensions with Applications in Finance and Insurance", "author": ["M. Holtz"], "venue": null, "citeRegEx": "Holtz.,? \\Q2008\\E", "shortCiteRegEx": "Holtz.", "year": 2008}, {"title": "Nonlinear Dimensionality Reduction", "author": ["J.A. Lee", "M. Verleysen"], "venue": "Information Science and Statistics. Springer,", "citeRegEx": "Lee and Verleysen.,? \\Q2007\\E", "shortCiteRegEx": "Lee and Verleysen.", "year": 2007}, {"title": "Grid diagrams in Heegaard Floer theory", "author": ["Ciprian Manolescu"], "venue": "European Congress of Mathematics (ECM) ,", "citeRegEx": "Manolescu.,? \\Q2012\\E", "shortCiteRegEx": "Manolescu.", "year": 2012}, {"title": "Exchangeable variable models", "author": ["Mathias Niepert", "Pedro M. Domingos"], "venue": "CoRR, abs/1405.0501,", "citeRegEx": "Niepert and Domingos.,? \\Q2014\\E", "shortCiteRegEx": "Niepert and Domingos.", "year": 2014}, {"title": "Grid Homology for Knots and Links", "author": ["P.S. Ozsv\u00e1th", "A.I. Stipsicz", "Z. Szab\u00f3"], "venue": "Mathematical Surveys and Monographs", "citeRegEx": "Ozsv\u00e1th et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Ozsv\u00e1th et al\\.", "year": 2015}, {"title": "Unsupervised semantic parsing", "author": ["Hoifung Poon", "Pedro M. Domingos"], "venue": "In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing (EMNLP),", "citeRegEx": "Poon and Domingos.,? \\Q2009\\E", "shortCiteRegEx": "Poon and Domingos.", "year": 2009}, {"title": "A combinatorial description of some heegaard floer homologies", "author": ["Sucharit Sarkar", "Jiajun Wang"], "venue": "Annals of Mathematics,", "citeRegEx": "Sarkar and Wang.,? \\Q2010\\E", "shortCiteRegEx": "Sarkar and Wang.", "year": 2010}, {"title": "Grid diagrams and the Ozsvath-Szabo tauinvariant", "author": ["Sucharit Sarkar"], "venue": null, "citeRegEx": "Sarkar.,? \\Q2010\\E", "shortCiteRegEx": "Sarkar.", "year": 2010}, {"title": "The Noether Theorems: Invariance and Conservation Laws in the Twentieth Century. Sources and Studies in the History of Mathematics and Physical Sciences", "author": ["B.E. Schwarzbach", "Y. Kosmann-Schwarzbach"], "venue": null, "citeRegEx": "Schwarzbach and Kosmann.Schwarzbach.,? \\Q2010\\E", "shortCiteRegEx": "Schwarzbach and Kosmann.Schwarzbach.", "year": 2010}, {"title": "Unsupervised Learning of Video Representations using LSTMs", "author": ["N. Srivastava", "E. Mansimov", "R. Salakhutdinov"], "venue": "ArXiv e-prints,", "citeRegEx": "Srivastava et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Srivastava et al\\.", "year": 2015}, {"title": "A Global Geometric Framework for Nonlinear Dimensionality Reduction", "author": ["J.B. Tenenbaum", "V. Silva", "J.C. Langford"], "venue": null, "citeRegEx": "Tenenbaum et al\\.,? \\Q2000\\E", "shortCiteRegEx": "Tenenbaum et al\\.", "year": 2000}, {"title": "Geometric Structure of High-Dimensional Data and Dimensionality Reduction", "author": ["J. Wang"], "venue": null, "citeRegEx": "Wang.,? \\Q2012\\E", "shortCiteRegEx": "Wang.", "year": 2012}], "referenceMentions": [{"referenceID": 11, "context": "Exploiting symmetries reduces computational complexity and leads to the development of new generalizations of learning algorithms and provides a new approach in deep symmetry networks [Gens and Domingos, 2014; Badrinarayanan et al., 2015].", "startOffset": 184, "endOffset": 238}, {"referenceID": 0, "context": "Exploiting symmetries reduces computational complexity and leads to the development of new generalizations of learning algorithms and provides a new approach in deep symmetry networks [Gens and Domingos, 2014; Badrinarayanan et al., 2015].", "startOffset": 184, "endOffset": 238}, {"referenceID": 7, "context": "There is recent interest in exploiting cyclic symmetry in convolution neural network architectures[Dieleman et al., 2016; Dieleman et al., 2015].", "startOffset": 98, "endOffset": 144}, {"referenceID": 6, "context": "There is recent interest in exploiting cyclic symmetry in convolution neural network architectures[Dieleman et al., 2016; Dieleman et al., 2015].", "startOffset": 98, "endOffset": 144}, {"referenceID": 18, "context": "Symmetry based machine learning are broadly classified as (1) Exchangeable variable models [Niepert and Domingos, 2014] (2) Deep Symmetry Networks (3) Symmetry based semantic parsing [Poon and Domingos, 2009].", "startOffset": 91, "endOffset": 119}, {"referenceID": 20, "context": "Symmetry based machine learning are broadly classified as (1) Exchangeable variable models [Niepert and Domingos, 2014] (2) Deep Symmetry Networks (3) Symmetry based semantic parsing [Poon and Domingos, 2009].", "startOffset": 183, "endOffset": 208}, {"referenceID": 23, "context": "Our work is inspired by the Noether\u2019s Theorem of unification symmetry and conservation in theoretical physics [Schwarzbach and Kosmann-Schwarzbach, 2010].", "startOffset": 110, "endOffset": 153}, {"referenceID": 8, "context": "We encode our Data space as a topological space, because of its highdimensional features (symmetry and connectivity) can be inferred from its low-dimensional, local representations as in [Chen and Rong, 2010; Edelsbrunner, 2007; Carlsson, 2014].", "startOffset": 187, "endOffset": 244}, {"referenceID": 1, "context": "We encode our Data space as a topological space, because of its highdimensional features (symmetry and connectivity) can be inferred from its low-dimensional, local representations as in [Chen and Rong, 2010; Edelsbrunner, 2007; Carlsson, 2014].", "startOffset": 187, "endOffset": 244}, {"referenceID": 9, "context": "The homology groups for the 2\u2212D object are computed efficiently by the digitization [Evako, 2006; Chen and Rong, 2010; Chen, 2004].", "startOffset": 84, "endOffset": 130}, {"referenceID": 4, "context": "The homology groups for the 2\u2212D object are computed efficiently by the digitization [Evako, 2006; Chen and Rong, 2010; Chen, 2004].", "startOffset": 84, "endOffset": 130}, {"referenceID": 17, "context": "These lines joining the symbols x and o form the strands of the knot and removing the grid give us the planar projection of the knot (trivial knot in our example) as shown in Figure 1 [Manolescu, 2012; Ozsv\u00e1th et al., 2015; Sarkar, 2010].", "startOffset": 184, "endOffset": 237}, {"referenceID": 19, "context": "These lines joining the symbols x and o form the strands of the knot and removing the grid give us the planar projection of the knot (trivial knot in our example) as shown in Figure 1 [Manolescu, 2012; Ozsv\u00e1th et al., 2015; Sarkar, 2010].", "startOffset": 184, "endOffset": 237}, {"referenceID": 22, "context": "These lines joining the symbols x and o form the strands of the knot and removing the grid give us the planar projection of the knot (trivial knot in our example) as shown in Figure 1 [Manolescu, 2012; Ozsv\u00e1th et al., 2015; Sarkar, 2010].", "startOffset": 184, "endOffset": 237}, {"referenceID": 21, "context": "Grid diagrams are extensively used recently because of the use the grids gives a combinatorial definition of knot Floer homology [Sarkar and Wang, 2010].", "startOffset": 129, "endOffset": 152}, {"referenceID": 17, "context": "Three grid moves (explained in Section 3) to relate the grid diagrams are (1) Commutation (T1) (2) Cyclic Permutations (T2) (3) Stabilization (T3) [Manolescu, 2012; Ozsv\u00e1th et al., 2015; Sarkar, 2010].", "startOffset": 147, "endOffset": 200}, {"referenceID": 19, "context": "Three grid moves (explained in Section 3) to relate the grid diagrams are (1) Commutation (T1) (2) Cyclic Permutations (T2) (3) Stabilization (T3) [Manolescu, 2012; Ozsv\u00e1th et al., 2015; Sarkar, 2010].", "startOffset": 147, "endOffset": 200}, {"referenceID": 22, "context": "Three grid moves (explained in Section 3) to relate the grid diagrams are (1) Commutation (T1) (2) Cyclic Permutations (T2) (3) Stabilization (T3) [Manolescu, 2012; Ozsv\u00e1th et al., 2015; Sarkar, 2010].", "startOffset": 147, "endOffset": 200}, {"referenceID": 14, "context": "Thus, high dimensional data are usually converted to low-dimensional codes by (1) Neural Networks [Hinton and Salakhutdinov, 2006]; (2) Nonlinear dimension reduction [Tenenbaum et al.", "startOffset": 98, "endOffset": 130}, {"referenceID": 25, "context": "Thus, high dimensional data are usually converted to low-dimensional codes by (1) Neural Networks [Hinton and Salakhutdinov, 2006]; (2) Nonlinear dimension reduction [Tenenbaum et al., 2000; Lee and Verleysen, 2007]; and (3) Topological and Geometric methods [Wang, 2012].", "startOffset": 166, "endOffset": 215}, {"referenceID": 16, "context": "Thus, high dimensional data are usually converted to low-dimensional codes by (1) Neural Networks [Hinton and Salakhutdinov, 2006]; (2) Nonlinear dimension reduction [Tenenbaum et al., 2000; Lee and Verleysen, 2007]; and (3) Topological and Geometric methods [Wang, 2012].", "startOffset": 166, "endOffset": 215}, {"referenceID": 26, "context": ", 2000; Lee and Verleysen, 2007]; and (3) Topological and Geometric methods [Wang, 2012].", "startOffset": 76, "endOffset": 88}, {"referenceID": 19, "context": "Legal transformations allowed for grid diagrams are 1 Commutation (2) Cyclic Permutations (3) Stabilization defined as in [Ozsv\u00e1th et al., 2015; Manolescu, 2012; Sarkar and Wang, 2010; Sarkar, 2010; Ozs, 2004; Hedden, 2008; Reidemeister, 1932].", "startOffset": 122, "endOffset": 243}, {"referenceID": 17, "context": "Legal transformations allowed for grid diagrams are 1 Commutation (2) Cyclic Permutations (3) Stabilization defined as in [Ozsv\u00e1th et al., 2015; Manolescu, 2012; Sarkar and Wang, 2010; Sarkar, 2010; Ozs, 2004; Hedden, 2008; Reidemeister, 1932].", "startOffset": 122, "endOffset": 243}, {"referenceID": 21, "context": "Legal transformations allowed for grid diagrams are 1 Commutation (2) Cyclic Permutations (3) Stabilization defined as in [Ozsv\u00e1th et al., 2015; Manolescu, 2012; Sarkar and Wang, 2010; Sarkar, 2010; Ozs, 2004; Hedden, 2008; Reidemeister, 1932].", "startOffset": 122, "endOffset": 243}, {"referenceID": 22, "context": "Legal transformations allowed for grid diagrams are 1 Commutation (2) Cyclic Permutations (3) Stabilization defined as in [Ozsv\u00e1th et al., 2015; Manolescu, 2012; Sarkar and Wang, 2010; Sarkar, 2010; Ozs, 2004; Hedden, 2008; Reidemeister, 1932].", "startOffset": 122, "endOffset": 243}, {"referenceID": 13, "context": "Legal transformations allowed for grid diagrams are 1 Commutation (2) Cyclic Permutations (3) Stabilization defined as in [Ozsv\u00e1th et al., 2015; Manolescu, 2012; Sarkar and Wang, 2010; Sarkar, 2010; Ozs, 2004; Hedden, 2008; Reidemeister, 1932].", "startOffset": 122, "endOffset": 243}, {"referenceID": 15, "context": "Note that, f\u03b2 (x) is a multivariate function [Holtz, 2008; Garcke and Pf\u00fclger, 2014].", "startOffset": 45, "endOffset": 84}, {"referenceID": 2, "context": "We draw those parallels from the physical Ising model [Chakrabarti et al., 1996; Grimmett, 2010] and propose an analogous Data Ising Model.", "startOffset": 54, "endOffset": 96}, {"referenceID": 12, "context": "We draw those parallels from the physical Ising model [Chakrabarti et al., 1996; Grimmett, 2010] and propose an analogous Data Ising Model.", "startOffset": 54, "endOffset": 96}, {"referenceID": 12, "context": "To each small square grid g \u2208 G, we associate a number 1 or 0 analogous to quantum spin as in Quantum Ising Model with the local two-dimensional Hilbert space C2 [Grimmett, 2010; Chakrabarti et al., 1996].", "startOffset": 162, "endOffset": 204}, {"referenceID": 2, "context": "To each small square grid g \u2208 G, we associate a number 1 or 0 analogous to quantum spin as in Quantum Ising Model with the local two-dimensional Hilbert space C2 [Grimmett, 2010; Chakrabarti et al., 1996].", "startOffset": 162, "endOffset": 204}, {"referenceID": 5, "context": "The symmetric features of the data set like rotation symmetry, translation symmetry are used as a feature and used a priory in Bayesian machine learning [Culbertson and Sturtz, 2013] or used in training the convolutional neural network layers [Dieleman et al.", "startOffset": 153, "endOffset": 182}, {"referenceID": 7, "context": "The symmetric features of the data set like rotation symmetry, translation symmetry are used as a feature and used a priory in Bayesian machine learning [Culbertson and Sturtz, 2013] or used in training the convolutional neural network layers [Dieleman et al., 2016; Dieleman et al., 2015].", "startOffset": 243, "endOffset": 289}, {"referenceID": 6, "context": "The symmetric features of the data set like rotation symmetry, translation symmetry are used as a feature and used a priory in Bayesian machine learning [Culbertson and Sturtz, 2013] or used in training the convolutional neural network layers [Dieleman et al., 2016; Dieleman et al., 2015].", "startOffset": 243, "endOffset": 289}, {"referenceID": 7, "context": "Analogous to our definitions of symmetric operations of cyclic permutation, commutation and stabilization, [Dieleman et al., 2016] proposes four operations which is inserted in neural network model as layers to model the translation equivariance into rotation equivariance.", "startOffset": 107, "endOffset": 130}, {"referenceID": 7, "context": "[Dieleman et al., 2016] proposes the computation of approximate invariance by the method of data augmentation as presenting the network during training with examples that are randomly perturbed.", "startOffset": 0, "endOffset": 23}, {"referenceID": 7, "context": "Our method of spatial distribution of Betti numbers on 2D grid can be encoded in constitutional neural network layers as the property of translation equivariance [Dieleman et al., 2016; Dieleman et al., 2015].", "startOffset": 162, "endOffset": 208}, {"referenceID": 6, "context": "Our method of spatial distribution of Betti numbers on 2D grid can be encoded in constitutional neural network layers as the property of translation equivariance [Dieleman et al., 2016; Dieleman et al., 2015].", "startOffset": 162, "endOffset": 208}, {"referenceID": 7, "context": "The method of data augmentation as described in [Dieleman et al., 2016] for the training of CNN\u2019s fits particularly well with our approach, as 40 60 80 100 120 140 160 40 60 80 100 120 140 160", "startOffset": 48, "endOffset": 71}, {"referenceID": 24, "context": "Modeling invariances in deep learning particularly so in unsupervised learning is an active area of research[Srivastava et al., 2015].", "startOffset": 108, "endOffset": 133}], "year": 2016, "abstractText": "Finding interesting symmetrical topological structures in high-dimensional systems is an important problem in statistical machine learning. Limited amount of available high-dimensional data and its sensitivity to noise pose computational challenges to find symmetry. Our paper presents a new method to find local symmetries in a low-dimensional 2-D grid structure which is embedded in high-dimensional structure. To compute the symmetry in a grid structure, we introduce three legal grid moves (i) Commutation (ii) Cyclic Permutation (iii) Stabilization on sets of local grid squares, grid blocks. The three grid moves are legal transformations as they preserve the statistical distribution of hamming distances in each grid block. We propose and coin the term of grid symmetry of data on the 2-D data grid as the invariance of statistical distributions of hamming distance are preserved after a sequence of grid moves. We have computed and analyzed the grid symmetry of data on multivariate Gaussian distributions and Gamma distributions with noise.", "creator": "LaTeX with hyperref package"}}}