{"id": "1603.06155", "review": {"conference": "ACL", "VERSION": "v1", "DATE_OF_SUBMISSION": "19-Mar-2016", "title": "A Persona-Based Neural Conversation Model", "abstract": "We present persona-based models for handling the issue of speaker consistency in neural response generation. A speaker model encodes personas in distributed embeddings that capture individual characteristics such as background information and speaking style. A dyadic speaker-addressee model captures properties of interactions between two interlocutors and allows the speaker-addressee model to distinguish different features in the speech context. The dynamic model also represents the underlying neural process associated with speaker stability, and thus a direct model of how the speaker-addressee model can be used to construct models and predict, in part, how to control and monitor speech and speech. The role of these models in the learning process is unclear, but the overall performance of the speaker-addressee model is similar to that of the dyadic speaker-addressee model and that of the dyadic speaker-addressee model. Moreover, the model model can be used for predicting and managing speech quality.\n\n\n\n\nA speaker model based on a computerized learning model can form an explicit model of the speaker-addressee model, which is typically expressed by a model to determine its performance. A system that can be constructed using a model is capable of creating an explicit model of the speaker-addressee model, which is typically expressed by a model to determine its performance. A system that can be constructed using a model is capable of creating an explicit model of the speaker-addressee model, which is typically expressed by a model to determine its performance. A system that can be constructed using a model is capable of creating an explicit model of the speaker-addressee model, which is typically expressed by a model to determine its performance. A system that can be constructed using a model is capable of creating an explicit model of the speaker-addressee model, which is typically expressed by a model to determine its performance. A system that can be constructed using a model is capable of creating an explicit model of the speaker-addressee model, which is typically expressed by a model to determine its performance. A system that can be constructed using a model is capable of creating an explicit model of the speaker-addressee model, which is typically expressed by a model to determine its performance. A system that can be constructed using a model is capable of creating an explicit model of the speaker-addressee model, which is typically expressed by a model to determine its performance. A system that can be constructed using a model is capable of creating an explicit model of the", "histories": [["v1", "Sat, 19 Mar 2016 23:15:18 GMT  (68kb,D)", "http://arxiv.org/abs/1603.06155v1", "10 pages"], ["v2", "Wed, 8 Jun 2016 17:19:58 GMT  (68kb,D)", "http://arxiv.org/abs/1603.06155v2", "Accepted for publication at ACL 2016"]], "COMMENTS": "10 pages", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["jiwei li", "michel galley", "chris brockett", "georgios p spithourakis", "jianfeng gao", "william b dolan"], "accepted": true, "id": "1603.06155"}, "pdf": {"name": "1603.06155.pdf", "metadata": {"source": "CRF", "title": "A Persona-Based Neural Conversation Model", "authors": ["Jiwei Li", "Michel Galley", "Chris Brockett", "Jianfeng Gao", "Bill Dolan"], "emails": ["jiweil@stanford.edu", "mgalley@microsoft.com", "chrisbkt@microsoft.com", "jfgao@microsoft.com", "billdol@microsoft.com"], "sections": [{"heading": null, "text": "We present persona-based models for handling the issue of speaker consistency in neural response generation. A speaker model encodes personas in distributed embeddings that capture individual characteristics such as background information and speaking style. A dyadic speaker-addressee model captures properties of interactions between two interlocutors. Our models yield qualitative performance improvements in both perplexity and BLEU scores over baseline sequence-to-sequence models, with similar gain in speaker consistency as measured by human judges."}, {"heading": "1 Introduction", "text": "As conversational agents gain traction as user interfaces, there has been growing research interest in training naturalistic conversation systems from large volumes of human-to-human interactions (Ritter et al., 2011; Sordoni et al., 2015; Vinyals and Le, 2015; Li et al., 2015). One major issue for these data-driven systems is their propensity to select the response with greatest likelihood\u2014in effect a consensus response of the humans represented in the trainng data. Outputs are frequently vague or non-committal as discussed in (Li et al., 2015), and when not, they can be wildly inconsistent, as illustrated in Table 1.\nIn this paper, we address the challenge of consistency and how to endow data-driven systems with the coherent \u201cpersona\u201d needed to model human-like behavior, whether as personal assistants, personalized\n* The entirety of this work was conducted at Microsoft.\navatar-like agents, or game characters.1 For present purposes, we will define PERSONA as the character that an artificial agent, as actor, plays or performs during conversational interactions. A persona can be viewed as a composite of elements of identity (background facts or user profile), language behavior, and interaction style. A persona is also adaptive, since an agent may need to present different facets to different human interlocutors depending on the demands of\n1(Vinyals and Le, 2015) suggest that the lack of a coherent personality makes it impossible for current systems to pass the Turing test.\nar X\niv :1\n60 3.\n06 15\n5v 1\n[ cs\n.C L\n] 1\n9 M\nar 2\nthe interaction. Fortunately, sequence-to-sequence (SEQ2SEQ) models of conversation generation (Vinyals and Le, 2015; Li et al., 2015) provide a straightforward mechanism for incorporating personas as embeddings. We therefore explore two persona models, a singlespeaker SPEAKER MODEL and a dyadic SPEAKERADDRESSEE MODEL, within the SEQ2SEQ framework. The Speaker Model integrates a speakerlevel vector representation into the target part of the SEQ2SEQ model. Analogously, the SpeakerAddressee model encodes the interaction patterns of two interlocutors by constructing an interaction representation from their individual embeddings and incorporating it into the SEQ2SEQ model. These persona vectors are trained on human-human conversation data and used at test time to generate personalized responses. Our experiments on an open-domain corpus of Twitter conversations and dialog datasets comprising TV series scripts show that leveraging persona vectors can improve relative performance up to 20% in BLEU score and 12% in perplexity, with a commensurate gain in consistency as judged by human annotators."}, {"heading": "2 Related Work", "text": "This work follows the line of investigation initiated by Ritter et al. (2011) who treat generation of conversational dialog as a statistical machine translation (SMT) problem. Ritter et al. (2011) represents a break with previous and contemporaneous dialog work that relies extensively on hand-coded rules, typically either building statistical models on top of heuristic rules or templates (Levin et al., 2000; Young et al., 2010; Walker et al., 2003; Pieraccini et al., 2009; Wang et al., 2011) or learning generation rules from a minimal set of authored rules or labels (Oh and Rudnicky, 2000; Ratnaparkhi, 2002; Banchs and Li, 2012; Ameixa et al., 2014; Nio et al., 2014; Chen et al., 2013). More recently (Wen et al., 2015) have used a Long Short-Term Memory (LSTM) (Hochreiter and Schmidhuber, 1997) to learn from unaligned data in order to reduce the heuristic space of sentence planning and surface realization.\nThe SMT model proposed by Ritter et al., on the other hand, is end-to-end, purely data-driven, and contains no explicit model of dialog structure; the model learns to converse from human-to-human con-\nversational corpora. Progress in SMT stemming from the use of neural language models (Sutskever et al., 2014; Gao et al., 2014; Bahdanau et al., 2015; Luong et al., 2015) has inspired efforts to extend these neural techniques to SMT-based conversational response generation. Sordoni et al. (2015) augments Ritter et al. (2011) by rescoring outputs using a SEQ2SEQ model conditioned on conversation history. Other researchers have recently used SEQ2SEQ to directly generate responses in an end-to-end fashion without relying on SMT phrase tables (Serban et al., 2015; Shang et al., 2015; Vinyals and Le, 2015). Serban et al. (2015) propose a hierarchical neural model aimed at capturing dependencies over an extended conversation history. Recent work by Li et al. (2015) measures mutual information between message and response in order to reduce the proportion of generic responses typical of SEQ2SEQ systems.\nModeling of users and speakers has been extensively studied within the standard dialog modeling framework (e.g., (Wahlster and Kobsa, 1989; Kobsa, 1990; Schatztnann et al., 2005; Lin and Walker, 2011)). Since generating meaningful responses in a open-domain scenario is intrinsically difficult in conventional dialog systems, existing models often focus on generalizing character style on the basis of qualitative statistical analysis (Walker et al., 2012; Walker et al., 2011). The present work, by contrast, is in the vein of the SEQ2SEQ models of Vinyals and Le (2015) and Li et al. (2015), enriching these models by training persona vectors directly from conversational data and relevant side-information, and incorporating these directly into the decoder."}, {"heading": "3 Sequence-to-Sequence Models", "text": "Given a sequence of inputs X = {x1, x2, ..., xnX}, an LSTM associates each time step with an input gate, a memory gate and an output gate, respectively denoted as it, ft and ot. We distinguish e and h where et denotes the vector for an individual text unit (for example, a word or sentence) at time step t while ht denotes the vector computed by the LSTM model at time t by combining et and ht\u22121. ct is the cell state vector at time t, and \u03c3 denotes the sigmoid function. Then, the vector representation ht for each time step\nt is given by: it ft ot lt  =  \u03c3 \u03c3 \u03c3 tanh W \u00b7 [ ht\u22121est ]\n(1)\nct = ft \u00b7 ct\u22121 + it \u00b7 lt (2) hst = ot \u00b7 tanh(ct) (3)\nwhere Wi, Wf , Wo, Wl \u2208 RK\u00d72K . In SEQ2SEQ generation tasks, each input X is paired with a sequence of outputs to predict: Y = {y1, y2, ..., ynY }. The LSTM defines a distribution over outputs and sequentially predicts tokens using a softmax function:\np(Y |X) = ny\u220f t=1 p(yt|x1, x2, ..., xt, y1, y2, ..., yt\u22121)\n= ny\u220f t=1 exp(f(ht\u22121, eyt))\u2211 y\u2032 exp(f(ht\u22121, ey\u2032))\nwhere f(ht\u22121, eyt) denotes the activation function between ht\u22121 and eyt . Each sentence terminates with a special end-of-sentence symbol EOS. In keeping with common practices, inputs and outputs use different LSTMs with separate parameters to capture different compositional patterns.\nDuring decoding, the algorithm terminates when an EOS token is predicted. At each time step, either a greedy approach or beam search can be adopted for word prediction."}, {"heading": "4 Personalized Response Generation", "text": "Our work introduces two persona-based models: the Speaker Model, which models the personality of the respondent, and the Speaker-Addressee Model which models the way the respondent adapts their speech to a given addressee \u2014 a linguistic phenomenon known as lexical entrainment (Deutsch and Pechmann, 1982)."}, {"heading": "4.1 Notation", "text": "For the response generation task, let M denote the input word sequence (message) M = {m1,m2, ...,mI}. R denotes the word sequence in response to M , where R = {r1, r2, ..., rJ , EOS} and J is the length of the response (terminated by an EOS token). rt denotes a word token that is associated with a K dimensional distinct word embedding et. V is the vocabulary size."}, {"heading": "4.2 Speaker Model", "text": "Our first model is the Speaker Model, which models the respondent alone. This model represents each individual speaker as a vector or embedding, which encodes speaker-specific information (e.g., dialect, register, age, gender, personal information) that influences the content and style of her responses.2\nFigure 1 gives a brief illustration of the Speaker Model. Each speaker i \u2208 [1, N ] is associated with a user-level representation vi \u2208 RK\u00d71. As in standard SEQ2SEQ models, we first encode message S into a vector representation hS using the source LSTM. Then for each step in the target side, hidden units are obtained by combining the representation produced by the target LSTM at the previous time step, the word representations at the current time step, and the speaker embedding vi:\nit ft ot lt\n =  \u03c3 \u03c3 \u03c3\ntanh\nW \u00b7  ht\u22121est\nvi  (4) ct = ft \u00b7 ct\u22121 + it \u00b7 lt (5)\nhst = ot \u00b7 tanh(ct) (6)\nwhere W \u2208 R4K\u00d73K . In this way, speaker information is encoded and injected into the hidden layer at each time step and thus helps predict personalized responses throughout the generation process. The Speaker embedding {vi} is shared across all conversations that involve speaker i. {vi} are learned by back propagating word prediction errors to each neural component during training.\nAnother helpful property of this model is that it helps infer answers to questions even if the evidence is not readily present in the training set. This is important as the training data does not contain explicit information about every attribute of each user (e.g., gender, age, country of residence). The model learns speaker representations based on conversational content produced by different speakers, and speakers producing similar responses tend to have similar embeddings, occupying nearby positions in the vector space. This way, the training data of speakers nearby\n2Note that these attributes are not explicitly annotated, which would be tremendously expensive for our datasets. Instead, our model manages to cluster users along some of these traits (e.g., age, country of residence) based on responses alone.\nin vector space help increase the generalization capability of the speaker model. For example, consider two speakers i and j who sound distinctly British, and who are therefore close in speaker embedding space. Now, suppose that, in the training data, speaker i was asked Where do you live? and responded in the UK. Even if speaker j was never asked the same question, this answer can help influence a good response from speaker j, and this without any explicitly labeled geo-location information."}, {"heading": "4.3 Speaker-Addressee Model", "text": "A natural extension of the Speaker Model is a model that is sensitive to speaker-addressee interaction patterns within the conversation. Indeed, speaking style, register, and content does not only vary with the identity of the speaker, but also with that of the addressee. For example, in scripts for the TV series Friends used in some of our experiments, the character Ross often talks differently to his sister Monica than to Rachel, with whom he is engaged in a on-again off-again relationship throughout the series.\nThe proposed Speaker-Addressee Model operates as follows: We wish to predict how speaker i would respond to a message produced by speaker j. Similarly to the Speaker model, we associate each speaker with a K dimensional speaker-level representation,\nnamely vi for user i and vj for user j. We obtain an interactive representation Vi,j \u2208 RK\u00d71 by linearly combining user vectors vi and vj in an attempt to model the interactive style of user i towards user j,\nVi,j = tanh(W1 \u00b7 vi +W2 \u00b7 v2) (7)\nwhere W1,W2 \u2208 RK\u00d7K . Vi,j is then linearly incorporated into LSTM models at each step in the target:\nit ft ot lt\n =  \u03c3 \u03c3 \u03c3\ntanh\nW \u00b7  ht\u22121est\nVi,j  (8) ct = ft \u00b7 ct\u22121 + it \u00b7 lt (9)\nhst = ot \u00b7 tanh(ct) (10)\nVi,j depends on both speaker and addressee and the same speaker will thus respond differently to a message from different interlocutors. One potential issue with Speaker-Addressee modelling is the difficulty involved in collecting a large-scale training dataset in which each speaker is involved in conversation with a wide variety of people. Like the Speaker Model, however, the Speaker-Addressee Model derives generalization capabilities from speaker embeddings. Even if the two speakers at test time (i and j) were never\ninvolved in the same conversation in the training data, two speakers i\u2032 and j\u2032 who are respectively close in embeddings may have been, and this can help modelling how i should respond to j."}, {"heading": "4.4 Decoding and Reranking", "text": "For decoding, the N-best lists are generated using the decoder with beam sizeB = 200. We set a maximum length of 20 for the generated candidates. Decoding operates as follows: At each time step, we first examine all B \u00d7B possible next-word candidates, and add all hypothesis ending with an EOS token to the N-best list. We then preserve the top-B unfinished hypotheses and move to the next word position.\nTo deal with the issue that SEQ2SEQ models tend to generate generic and commonplace responses such as I don\u2019t know, we follow Li et al. (2015) by reranking the generated N-best list using a scoring function that linearly combines a length penalty and the log likelihood of source given target:\nlog p(R|M, v) + \u03bb log p(M |R) + \u03b3|R| (11)\nwhere p(R|M,v) denotes the probability of the generated response given the message M and the respondent\u2019s speaker ID. |R| denotes the length of the target and \u03b3 denotes the associated penalty weight. We optimize \u03b3 and \u03bb on N-best lists of response candidates generated from the development set using MERT (Och, 2003) by optimizing BLEU. To compute p(M |R), we train an inverse SEQ2SEQ model by swapping messages and responses. We trained standard SEQ2SEQ models for p(M |R) with no speaker information considered."}, {"heading": "5 Datasets", "text": ""}, {"heading": "5.1 Twitter Persona Dataset", "text": "Data Collection Training data for the Speaker Model was extracted from the Twitter FireHose for the six-month period beginning January 1, 2012. We limited the sequences to those where the responders had engaged in at least 60 (and at most 300) conversational interactions during the period, in other words, users who reasonably frequently engaged in conversation. This yielded a set of 74,003 users who took part in a minimum of 60 and a maximum of 164 conversational turns (average: 92.24, median: 90).\nThe dataset extracted using responses by these \u201cconversationalists\u201d contained 24,725,711 3-turn slidingwindow (context-message-response) conversational sequences.\nIn addition, we sampled 12000 3-turn conversations from the same user set from the Twitter FireHose for the three-month period beginning July 1, 2012, and set these aside as development, validation, and test sets (4000 conversational sequences each). Note that development, validation, and test sets for this data are single-reference, which is by by design. Multiple reference responses would typically require acquiring responses from different people, which would confound different personas.\nTraining Protocols We trained four-layer SEQ2SEQ models on the Twitter corpus following the approach of (Sutskever et al., 2014). Details are as follows:\n\u2022 4 layer LSTM models with 1,000 hidden cells for each layer. \u2022 Batch size is set to 128. \u2022 Learning rate is set to 1.0. \u2022 Parameters are initialized by sampling from the\nuniform distribution [\u22120.1, 0.1]. \u2022 Gradients are clipped to avoid gradient explo-\nsion with a threshold of 5. \u2022 Vocabulary size is limited to 50,000. \u2022 Dropout rate is set to 0.2.\nSource and target LSTMs use different sets of parameters. We ran 14 epochs, and training took roughly a month to finish on a Tesla K40 GPU machine.\nAs only speaker IDs of responses were specified when compiling the Twitter dataset, experiments on this dataset were limited to the Speaker Model."}, {"heading": "5.2 Twitter Sordoni Dataset", "text": "The Twitter Persona Dataset was collected for this paper for experiments with speaker ID information. To obtain a point of comparison with prior state-ofthe-art work (Sordoni et al., 2015; Li et al., 2015), we measure our baseline (non-persona) LSTM model against prior work on the dataset of (Sordoni et al., 2015), which we call the Twitter Sordoni Dataset. We only use its test-set portion, which contains responses for 2114 context and messages. It is important to note that the Sordoni dataset offers up to 10 references per message, while the Twitter Persona dataset has only\n1 reference per message. Thus BLEU scores cannot be compared across the two Twitter datasets (BLEU scores on 10 references are generally much higher than with 1 reference). Details of this dataset are in (Sordoni et al., 2015)."}, {"heading": "5.3 Television Series Transcripts", "text": "Data Collection For the dyadic SpeakerAddressee Model we used scripts from the American television comedies Friends3 and The Big Bang Theory,4 available from from Internet Movie Script Database (IMSDb).5 We collected 13 main characters from the two series in a corpus of 69,565 turns. We split the corpus into training/development/testing sets, with development and testing sets each of about 2,000 turns.\nTraining Since the relatively small size of the dataset does not allow for training an open domain dialog model, we adopted a domain adaption strategy where we first trained a standard SEQ2SEQ models using a much larger OpenSubtitles (OSDb) dataset (Tiedemann, 2009), and then adapting the pre-trained model to the TV series dataset.\nThe OSDb dataset is a large, noisy, open-domain dataset containing roughly 60M-70M scripted lines spoken by movie characters. This dataset does not specify which character speaks each subtitle line, which prevents us from inferring speaker turns. Following Vinyals et al. (2015), we make the simplifying assumption that each line of subtitle constitutes a full speaker turn.6 We trained standard SEQ2SEQ models on OSDb dataset, following the protocols already described in Section 5.1. We run 10 iterations over the training set.\nWe initialize word embeddings and LSTM parameters in the Speaker Model and the Speaker-Addressee model using parameters learned from OpenSubtitles datasets. User embeddings are randomly initialized from [\u22120.1, 0.1]. We then ran 5 additional epochs until the perplexity on the development set stabilized.\n3https://en.wikipedia.org/wiki/Friends 4https://en.wikipedia.org/wiki/The_Big_\nBang_Theory 5http://www.imsdb.com 6This introduces a degree of noise as consecutive lines are not necessarily from the same scene or two different speakers."}, {"heading": "6 Experiments", "text": ""}, {"heading": "6.1 Evaluation", "text": "Following (Sordoni et al., 2015; Li et al., 2015) we used BLEU (Papineni et al., 2002) for parameter tuning and evaluation. BLEU has been shown to correlate well with human judgment on the response generation task, as demonstrated in (Galley et al., 2015). Besides BLEU scores, we also report perplexity, which has been widely adopted as an indicator of model capability."}, {"heading": "6.2 Baseline", "text": "Since our main experiments are with a new dataset (the Twitter Persona Dataset), we first show that our LSTM baseline is competitive with the state-of-theart (Li et al., 2015) on an established dataset, the Twitter Sordoni Dataset (Sordoni et al., 2015). Our baseline is simply our implementation of the LSTMMMI of (Li et al., 2015), so results should be relatively close to their reported results. Table 2 summarizes our results against prior work. We see that our system actually does better than (Li et al., 2015), and we attribute the improvement to a larger training corpus, the use of dropout during training, and possibly to the \u201cconversationalist\u201d nature of our corpus."}, {"heading": "6.3 Results", "text": "We first report performance on the Twitter Persona dataset. Perplexity is reported in Table 3. We observe about a 10% decrease in perplexity for the Speaker model over the standard SEQ2SEQ model. In terms of BLEU scores (Table 4), a significant performance boost is observed for the Speaker model over the standard SEQ2SEQ model, yielding an increase of 21% in the maximum likelihood (MLE) setting and 11.7% for mutual information setting (MMI). In line with findings in (Li et al., 2015), we observe a consistent performance boost introduced by the MMI objective function over a standard SEQ2SEQ model based on the MLE objective function. It is worth noting that our persona models are more beneficial to the MLE models than to the MMI models. This result is intuitive as the persona models help make Standard LSTM MLE outputs more informative and less bland, and thus make the use of MMI less critical.\nFor the TV Series dataset, perplexity and BLEU scores are respectively reported in Table 5 and Table 6. As can be seen, the Speaker and SpeakerAddressee models respectively achieve perplexity values of 25.4 and 25.0 on the TV-series dataset, 7.0% and 8.4% percent lower than the correspondent standard SEQ2SEQ models. In terms of BLEU score, we observe a similar performance boost as on the\nTwitter dataset, in which the Speaker model and the Speaker-Addressee model outperform the standard SEQ2SEQ model by 13.7% and 10.6%. By comparing the Speaker-Addressee model against the Speaker model on the TV Series dataset, we do not observe a significant difference. We suspect that this is primarily due to the relatively small size of the dataset where the interactive patterns might not be fully captured. Smaller values of perplexity are observed for the Television Series dataset than the Twitter dataset, the perplexity of which is over 40, presumably due to the more noisy nature of Twitter dialogues."}, {"heading": "6.4 Qualitative Analysis", "text": "Diverse Responses by Different Speakers Table 7 represents responses generated by persona models in response to three different input questions. We randomly selected 10 speakers (without cherry-picking) from the original twitter dataset. We collected their user level representations from a speaker look-up table and integrated them into the decoding models. We can see that the model tends to generate specific responses for different people in response to the factual questions.7\nHuman Evaluation We conducted a human evaluation of outputs from the Speaker Model, using a crowdsourcing service. Since we cannot expect crowdsourced human judges to know or attempt to learn the ground truth of Twitter users who are not well-known public figures, we designed our experiment to evaluate the consistency of outputs associated with the speaker IDs. To this end, we collected 24 pairs of questions for which we would expect responses to be consistent if the persona model is coherent. For example, responses to the questions What\n7There appears to be a population bias in the training set that favors British users.\ncountry do you live in? and What city do you live in? would be considered consistent if the answers were England and London respectively, but not if they were UK and Chicago. Similarly, the responses to Are you vegan or vegetarian? and Do you eat beef? are consistent if the answers generated are vegan and absolutely not, but not if they are vegan and I love beef. We collected the top 20 pairs of outputs provided by the Speaker Model for each question pair (480 response pairs total). We also obtained the cor-\nresponding outputs from the baseline MMI-enhanced SEQ2SEQ system.\nSince our purpose is to measure the gain in consistency over the baseline system, we presented the pairs of answers system-pairwise, i.e., 4 responses, 2 from each system, displayed on the screen, and asked judges to decide which of the two systems was more consistent. The position in which the system pairs were presented on the screen was randomized. Five judges rated each pair. A system was assigned a score 1.0 if it was judged much more consistent than the other, 0.5 if mostly more consistent, zero otherwise. Ties (where the two systems are equally consistent or inconsistent) were discarded. A maximum score of 5.0 was possible. After reweighting for frequency of response pairs, the mean relative consistency rating for the Speaker Model was 1.33 compared to 0.99 for the baseline model, representing a gain in relative consistency of 34.68%. It should be stressed that the latter is a strong baseline, since it represents the consensus of all 70K Twitter users in the dataset. (I\u2019m not pregnant is an excellent consensus answer to the question Are you pregnant?, while I\u2019m pregnant is consistent as a response only in the case of someone who also answers the question Are you a guy or a girl? with something in the vein of I\u2019m a girl.)\nSpeaker Consistency Table 8 illustrates how consistency is an emergent property of two arbitrarily selected users. The model is capable of discovering the relations between different categories of location such as London and the UK, Jakarta and Indonesia. However, the model also makes inconsistent response decisions, generating different answers in the second example in response to questions asking about age or major. Our proposed persona models integrate user embeddings into the LSTM, and thus can be viewed as encapsulating a trade-off between a persona-specific generation model and a general conversational model."}, {"heading": "7 Conclusions", "text": "We have presented two persona-based response generation models for open-domain conversation generation. There are many other aspects of speaker behavior, such as mood and emotion, that we have not attempted to examine here, but these are beyond the scope of the current paper and must be left to\nfuture work. Although the gains presented by our new models are not spectacular, the systems nevertheless outperform our baseline SEQ2SEQ systems in terms of BLEU, perplexity, and human judgments of speaker consistency. We have demonstrated that by encoding personas into distributed representations, we are able to capture certain personal characteristics such as speaking style and background information. In the Speaker-Addressee model, moreover, the evidence suggests that there is benefit in capturing dyadic interactions.\nOur ultimate goal is to be able to take the profile of\nan arbitrary individual whose identity is not known in advance, and generate conversations that accurately emulate that individual\u2019s persona in terms of linguistic response behavior and other salient characteristics. Such a capability will dramatically change the ways in which we interact with dialog agents of all kinds, opening up rich new possibilities for user interfaces. Given a sufficiently large training corpus in which a sufficiently rich variety of speakers is represented, this objective does not seem too far-fetched."}, {"heading": "Acknowledgments", "text": "We thank Dan Jurafsky, Pushmeet Kohli, Chris Quirk, Alan Ritter, and George Spithourakis for helpful discussions about this work."}], "references": [{"title": "Luke, I am your father: dealing with out-of-domain requests by using movies subtitles", "author": ["David Ameixa", "Luisa Coheur", "Pedro Fialho", "Paulo Quaresma."], "venue": "Intelligent Virtual Agents, pages 13\u201321. Springer.", "citeRegEx": "Ameixa et al\\.,? 2014", "shortCiteRegEx": "Ameixa et al\\.", "year": 2014}, {"title": "Neural machine translation by jointly learning to align and translate", "author": ["Dzmitry Bahdanau", "Kyunghyun Cho", "Yoshua Bengio."], "venue": "Proc. of the International Conference on Learning Representations (ICLR).", "citeRegEx": "Bahdanau et al\\.,? 2015", "shortCiteRegEx": "Bahdanau et al\\.", "year": 2015}, {"title": "IRIS: a chatoriented dialogue system based on the vector space model", "author": ["Rafael E Banchs", "Haizhou Li."], "venue": "Proc. of the ACL 2012 System Demonstrations, pages 37\u201342.", "citeRegEx": "Banchs and Li.,? 2012", "shortCiteRegEx": "Banchs and Li.", "year": 2012}, {"title": "An empirical investigation of sparse log-linear models for improved dialogue act classification", "author": ["Yun-Nung Chen", "Wei Yu Wang", "Alexander Rudnicky."], "venue": "Acoustics, Speech and Signal Processing (ICASSP), 2013 IEEE International Conference on, pages 8317\u2013", "citeRegEx": "Chen et al\\.,? 2013", "shortCiteRegEx": "Chen et al\\.", "year": 2013}, {"title": "Social interaction and the development of definite descriptions", "author": ["Werner Deutsch", "Thomas Pechmann."], "venue": "Cognition, 11:159\u2013184.", "citeRegEx": "Deutsch and Pechmann.,? 1982", "shortCiteRegEx": "Deutsch and Pechmann.", "year": 1982}, {"title": "\u2206BLEU: A discriminative metric for generation tasks with intrinsically diverse targets", "author": ["Michel Galley", "Chris Brockett", "Alessandro Sordoni", "Yangfeng Ji", "Michael Auli", "Chris Quirk", "Margaret Mitchell", "Jianfeng Gao", "Bill Dolan."], "venue": "Proc. of ACL-IJCNLP, pages", "citeRegEx": "Galley et al\\.,? 2015", "shortCiteRegEx": "Galley et al\\.", "year": 2015}, {"title": "Learning continuous phrase representations for translation modeling", "author": ["Jianfeng Gao", "Xiaodong He", "Wen-tau Yih", "Li Deng."], "venue": "Proc. of ACL, pages 699\u2013709, Baltimore, Maryland.", "citeRegEx": "Gao et al\\.,? 2014", "shortCiteRegEx": "Gao et al\\.", "year": 2014}, {"title": "Long short-term memory", "author": ["Sepp Hochreiter", "J\u00fcrgen Schmidhuber."], "venue": "Neural computation, 9(8):1735\u2013 1780.", "citeRegEx": "Hochreiter and Schmidhuber.,? 1997", "shortCiteRegEx": "Hochreiter and Schmidhuber.", "year": 1997}, {"title": "User modeling in dialog systems: Potentials and hazards", "author": ["Alfred Kobsa."], "venue": "AI & society, 4(3):214\u2013231.", "citeRegEx": "Kobsa.,? 1990", "shortCiteRegEx": "Kobsa.", "year": 1990}, {"title": "A stochastic model of human-machine interaction for learning dialog strategies", "author": ["Esther Levin", "Roberto Pieraccini", "Wieland Eckert."], "venue": "IEEE Transactions on Speech and Audio Processing, 8(1):11\u201323.", "citeRegEx": "Levin et al\\.,? 2000", "shortCiteRegEx": "Levin et al\\.", "year": 2000}, {"title": "A diversity-promoting objective function for neural conversation models", "author": ["Jiwei Li", "Michel Galley", "Chris Brockett", "Jianfeng Gao", "Bill Dolan."], "venue": "arXiv preprint arXiv:1510.03055.", "citeRegEx": "Li et al\\.,? 2015", "shortCiteRegEx": "Li et al\\.", "year": 2015}, {"title": "All the world\u2019s a stage: Learning character models from film", "author": ["Grace I Lin", "Marilyn A Walker."], "venue": "Proceedings of the Seventh AAAI Conference on Artificial Intelligence and Interactive Digital Entertainment (AIIDE).", "citeRegEx": "Lin and Walker.,? 2011", "shortCiteRegEx": "Lin and Walker.", "year": 2011}, {"title": "Addressing the rare word problem in neural machine translation", "author": ["Thang Luong", "Ilya Sutskever", "Quoc Le", "Oriol Vinyals", "Wojciech Zaremba."], "venue": "Proc. of ACL, pages 11\u201319, Beijing, China, July.", "citeRegEx": "Luong et al\\.,? 2015", "shortCiteRegEx": "Luong et al\\.", "year": 2015}, {"title": "Developing non-goal dialog system based on examples of drama television", "author": ["Lasguido Nio", "Sakriani Sakti", "Graham Neubig", "Tomoki Toda", "Mirna Adriani", "Satoshi Nakamura."], "venue": "Natural Interaction with Robots, Knowbots and Smartphones, pages 355\u2013361. Springer.", "citeRegEx": "Nio et al\\.,? 2014", "shortCiteRegEx": "Nio et al\\.", "year": 2014}, {"title": "Minimum error rate training in statistical machine translation", "author": ["Franz Josef Och."], "venue": "Proceedings of the 41st Annual Meeting of the Association for Computational Linguistics, pages 160\u2013167, Sapporo, Japan, July. Association for Computational Linguistics.", "citeRegEx": "Och.,? 2003", "shortCiteRegEx": "Och.", "year": 2003}, {"title": "Stochastic language generation for spoken dialogue systems", "author": ["Alice H Oh", "Alexander I Rudnicky."], "venue": "Proceedings of the 2000 ANLP/NAACL Workshop on Conversational systems-Volume 3, pages 27\u201332.", "citeRegEx": "Oh and Rudnicky.,? 2000", "shortCiteRegEx": "Oh and Rudnicky.", "year": 2000}, {"title": "BLEU: a method for automatic evaluation of machine translation", "author": ["Kishore Papineni", "Salim Roukos", "Todd Ward", "WeiJing Zhu."], "venue": "Proc. of ACL, pages 311\u2013318.", "citeRegEx": "Papineni et al\\.,? 2002", "shortCiteRegEx": "Papineni et al\\.", "year": 2002}, {"title": "Are we there yet? research in commercial spoken dialog systems", "author": ["Roberto Pieraccini", "David Suendermann", "Krishna Dayanidhi", "Jackson Liscombe."], "venue": "Text, Speech and Dialogue, pages 3\u201313. Springer.", "citeRegEx": "Pieraccini et al\\.,? 2009", "shortCiteRegEx": "Pieraccini et al\\.", "year": 2009}, {"title": "Trainable approaches to surface natural language generation and their application to conversational dialog systems", "author": ["Adwait Ratnaparkhi."], "venue": "Computer Speech & Language, 16(3):435\u2013455.", "citeRegEx": "Ratnaparkhi.,? 2002", "shortCiteRegEx": "Ratnaparkhi.", "year": 2002}, {"title": "Data-driven response generation in social media", "author": ["Alan Ritter", "Colin Cherry", "William B Dolan."], "venue": "Proceedings of the Conference on Empirical Methods in Natural Language Processing, pages 583\u2013593.", "citeRegEx": "Ritter et al\\.,? 2011", "shortCiteRegEx": "Ritter et al\\.", "year": 2011}, {"title": "Effects of the user model on simulation-based learning of dialogue strategies", "author": ["Jost Schatztnann", "Matthew N Stuttle", "Karl Weilhammer", "Steve Young."], "venue": "Automatic Speech Recognition and Understanding, 2005 IEEE Workshop on, pages 220\u2013225.", "citeRegEx": "Schatztnann et al\\.,? 2005", "shortCiteRegEx": "Schatztnann et al\\.", "year": 2005}, {"title": "Building end-to-end dialogue systems using generative hierarchical neural network models", "author": ["Iulian V Serban", "Alessandro Sordoni", "Yoshua Bengio", "Aaron Courville", "Joelle Pineau."], "venue": "Proc. of AAAI.", "citeRegEx": "Serban et al\\.,? 2015", "shortCiteRegEx": "Serban et al\\.", "year": 2015}, {"title": "Neural responding machine for short-text conversation", "author": ["Lifeng Shang", "Zhengdong Lu", "Hang Li."], "venue": "ACL-IJCNLP, pages 1577\u20131586.", "citeRegEx": "Shang et al\\.,? 2015", "shortCiteRegEx": "Shang et al\\.", "year": 2015}, {"title": "A neural network approach to context-sensitive generation of conversational responses", "author": ["Alessandro Sordoni", "Michel Galley", "Michael Auli", "Chris Brockett", "Yangfeng Ji", "Meg Mitchell", "Jian-Yun Nie", "Jianfeng Gao", "Bill Dolan."], "venue": "Proc. of NAACL-HLT.", "citeRegEx": "Sordoni et al\\.,? 2015", "shortCiteRegEx": "Sordoni et al\\.", "year": 2015}, {"title": "Sequence to sequence learning with neural networks", "author": ["Ilya Sutskever", "Oriol Vinyals", "Quoc V Le."], "venue": "Advances in neural information processing systems (NIPS), pages 3104\u20133112.", "citeRegEx": "Sutskever et al\\.,? 2014", "shortCiteRegEx": "Sutskever et al\\.", "year": 2014}, {"title": "News from OPUS \u2013 a collection of multilingual parallel corpora with tools and interfaces", "author": ["J\u00f6rg Tiedemann."], "venue": "Recent advances in natural language processing, volume 5, pages 237\u2013248.", "citeRegEx": "Tiedemann.,? 2009", "shortCiteRegEx": "Tiedemann.", "year": 2009}, {"title": "A neural conversational model", "author": ["Oriol Vinyals", "Quoc Le."], "venue": "Proc. of ICML Deep Learning Workshop.", "citeRegEx": "Vinyals and Le.,? 2015", "shortCiteRegEx": "Vinyals and Le.", "year": 2015}, {"title": "User models in dialog systems", "author": ["Wolfgang Wahlster", "Alfred Kobsa."], "venue": "Springer.", "citeRegEx": "Wahlster and Kobsa.,? 1989", "shortCiteRegEx": "Wahlster and Kobsa.", "year": 1989}, {"title": "A trainable generator for recommendations in multimodal dialog", "author": ["Marilyn A Walker", "Rashmi Prasad", "Amanda Stent."], "venue": "INTERSPEECH.", "citeRegEx": "Walker et al\\.,? 2003", "shortCiteRegEx": "Walker et al\\.", "year": 2003}, {"title": "Perceived or not perceived: Film character models for expressive nlg", "author": ["Marilyn A Walker", "Ricky Grant", "Jennifer Sawyer", "Grace I Lin", "Noah Wardrip-Fruin", "Michael Buell."], "venue": "Interactive Storytelling, pages 109\u2013 121. Springer.", "citeRegEx": "Walker et al\\.,? 2011", "shortCiteRegEx": "Walker et al\\.", "year": 2011}, {"title": "An annotated corpus of film dialogue for learning and characterizing character style", "author": ["Marilyn A Walker", "Grace I Lin", "Jennifer Sawyer."], "venue": "LREC, pages 1373\u20131378.", "citeRegEx": "Walker et al\\.,? 2012", "shortCiteRegEx": "Walker et al\\.", "year": 2012}, {"title": "Improving spoken dialogue understanding using phonetic mixture models", "author": ["William Yang Wang", "Ron Artstein", "Anton Leuski", "David Traum."], "venue": "FLAIRS Conference.", "citeRegEx": "Wang et al\\.,? 2011", "shortCiteRegEx": "Wang et al\\.", "year": 2011}, {"title": "Semantically conditioned LSTM-based natural language generation for spoken dialogue systems", "author": ["Tsung-Hsien Wen", "Milica Gasic", "Nikola Mrk\u0161i\u0107", "Pei-Hao Su", "David Vandyke", "Steve Young."], "venue": "Proc. of EMNLP, pages 1711\u20131721, Lisbon, Portugal, September. Asso-", "citeRegEx": "Wen et al\\.,? 2015", "shortCiteRegEx": "Wen et al\\.", "year": 2015}, {"title": "The hidden information state model: A practical framework for pomdp-based spoken dialogue management", "author": ["Steve Young", "Milica Ga\u0161i\u0107", "Simon Keizer", "Fran\u00e7ois Mairesse", "Jost Schatzmann", "Blaise Thomson", "Kai Yu."], "venue": "Computer Speech & Language, 24(2):150\u2013", "citeRegEx": "Young et al\\.,? 2010", "shortCiteRegEx": "Young et al\\.", "year": 2010}], "referenceMentions": [{"referenceID": 19, "context": "As conversational agents gain traction as user interfaces, there has been growing research interest in training naturalistic conversation systems from large volumes of human-to-human interactions (Ritter et al., 2011; Sordoni et al., 2015; Vinyals and Le, 2015; Li et al., 2015).", "startOffset": 196, "endOffset": 278}, {"referenceID": 23, "context": "As conversational agents gain traction as user interfaces, there has been growing research interest in training naturalistic conversation systems from large volumes of human-to-human interactions (Ritter et al., 2011; Sordoni et al., 2015; Vinyals and Le, 2015; Li et al., 2015).", "startOffset": 196, "endOffset": 278}, {"referenceID": 26, "context": "As conversational agents gain traction as user interfaces, there has been growing research interest in training naturalistic conversation systems from large volumes of human-to-human interactions (Ritter et al., 2011; Sordoni et al., 2015; Vinyals and Le, 2015; Li et al., 2015).", "startOffset": 196, "endOffset": 278}, {"referenceID": 10, "context": "As conversational agents gain traction as user interfaces, there has been growing research interest in training naturalistic conversation systems from large volumes of human-to-human interactions (Ritter et al., 2011; Sordoni et al., 2015; Vinyals and Le, 2015; Li et al., 2015).", "startOffset": 196, "endOffset": 278}, {"referenceID": 10, "context": "Outputs are frequently vague or non-committal as discussed in (Li et al., 2015), and when not, they can be wildly inconsistent, as illustrated in Table 1.", "startOffset": 62, "endOffset": 79}, {"referenceID": 26, "context": "(Vinyals and Le, 2015) suggest that the lack of a coherent personality makes it impossible for current systems to pass the Turing test.", "startOffset": 0, "endOffset": 22}, {"referenceID": 26, "context": "Fortunately, sequence-to-sequence (SEQ2SEQ) models of conversation generation (Vinyals and Le, 2015; Li et al., 2015) provide a straightforward mechanism for incorporating personas as embeddings.", "startOffset": 78, "endOffset": 117}, {"referenceID": 10, "context": "Fortunately, sequence-to-sequence (SEQ2SEQ) models of conversation generation (Vinyals and Le, 2015; Li et al., 2015) provide a straightforward mechanism for incorporating personas as embeddings.", "startOffset": 78, "endOffset": 117}, {"referenceID": 9, "context": "(2011) represents a break with previous and contemporaneous dialog work that relies extensively on hand-coded rules, typically either building statistical models on top of heuristic rules or templates (Levin et al., 2000; Young et al., 2010; Walker et al., 2003; Pieraccini et al., 2009; Wang et al., 2011) or learning generation rules from a minimal set of authored rules or labels (Oh and Rudnicky, 2000; Ratnaparkhi, 2002; Banchs and Li, 2012; Ameixa et al.", "startOffset": 201, "endOffset": 306}, {"referenceID": 33, "context": "(2011) represents a break with previous and contemporaneous dialog work that relies extensively on hand-coded rules, typically either building statistical models on top of heuristic rules or templates (Levin et al., 2000; Young et al., 2010; Walker et al., 2003; Pieraccini et al., 2009; Wang et al., 2011) or learning generation rules from a minimal set of authored rules or labels (Oh and Rudnicky, 2000; Ratnaparkhi, 2002; Banchs and Li, 2012; Ameixa et al.", "startOffset": 201, "endOffset": 306}, {"referenceID": 28, "context": "(2011) represents a break with previous and contemporaneous dialog work that relies extensively on hand-coded rules, typically either building statistical models on top of heuristic rules or templates (Levin et al., 2000; Young et al., 2010; Walker et al., 2003; Pieraccini et al., 2009; Wang et al., 2011) or learning generation rules from a minimal set of authored rules or labels (Oh and Rudnicky, 2000; Ratnaparkhi, 2002; Banchs and Li, 2012; Ameixa et al.", "startOffset": 201, "endOffset": 306}, {"referenceID": 17, "context": "(2011) represents a break with previous and contemporaneous dialog work that relies extensively on hand-coded rules, typically either building statistical models on top of heuristic rules or templates (Levin et al., 2000; Young et al., 2010; Walker et al., 2003; Pieraccini et al., 2009; Wang et al., 2011) or learning generation rules from a minimal set of authored rules or labels (Oh and Rudnicky, 2000; Ratnaparkhi, 2002; Banchs and Li, 2012; Ameixa et al.", "startOffset": 201, "endOffset": 306}, {"referenceID": 31, "context": "(2011) represents a break with previous and contemporaneous dialog work that relies extensively on hand-coded rules, typically either building statistical models on top of heuristic rules or templates (Levin et al., 2000; Young et al., 2010; Walker et al., 2003; Pieraccini et al., 2009; Wang et al., 2011) or learning generation rules from a minimal set of authored rules or labels (Oh and Rudnicky, 2000; Ratnaparkhi, 2002; Banchs and Li, 2012; Ameixa et al.", "startOffset": 201, "endOffset": 306}, {"referenceID": 15, "context": ", 2011) or learning generation rules from a minimal set of authored rules or labels (Oh and Rudnicky, 2000; Ratnaparkhi, 2002; Banchs and Li, 2012; Ameixa et al., 2014; Nio et al., 2014; Chen et al., 2013).", "startOffset": 84, "endOffset": 205}, {"referenceID": 18, "context": ", 2011) or learning generation rules from a minimal set of authored rules or labels (Oh and Rudnicky, 2000; Ratnaparkhi, 2002; Banchs and Li, 2012; Ameixa et al., 2014; Nio et al., 2014; Chen et al., 2013).", "startOffset": 84, "endOffset": 205}, {"referenceID": 2, "context": ", 2011) or learning generation rules from a minimal set of authored rules or labels (Oh and Rudnicky, 2000; Ratnaparkhi, 2002; Banchs and Li, 2012; Ameixa et al., 2014; Nio et al., 2014; Chen et al., 2013).", "startOffset": 84, "endOffset": 205}, {"referenceID": 0, "context": ", 2011) or learning generation rules from a minimal set of authored rules or labels (Oh and Rudnicky, 2000; Ratnaparkhi, 2002; Banchs and Li, 2012; Ameixa et al., 2014; Nio et al., 2014; Chen et al., 2013).", "startOffset": 84, "endOffset": 205}, {"referenceID": 13, "context": ", 2011) or learning generation rules from a minimal set of authored rules or labels (Oh and Rudnicky, 2000; Ratnaparkhi, 2002; Banchs and Li, 2012; Ameixa et al., 2014; Nio et al., 2014; Chen et al., 2013).", "startOffset": 84, "endOffset": 205}, {"referenceID": 3, "context": ", 2011) or learning generation rules from a minimal set of authored rules or labels (Oh and Rudnicky, 2000; Ratnaparkhi, 2002; Banchs and Li, 2012; Ameixa et al., 2014; Nio et al., 2014; Chen et al., 2013).", "startOffset": 84, "endOffset": 205}, {"referenceID": 32, "context": "More recently (Wen et al., 2015) have used a Long Short-Term Memory (LSTM) (Hochreiter and Schmidhuber, 1997) to learn from unaligned data in order to reduce the heuristic space of sentence planning and surface realization.", "startOffset": 14, "endOffset": 32}, {"referenceID": 7, "context": ", 2015) have used a Long Short-Term Memory (LSTM) (Hochreiter and Schmidhuber, 1997) to learn from unaligned data in order to reduce the heuristic space of sentence planning and surface realization.", "startOffset": 50, "endOffset": 84}, {"referenceID": 9, "context": "This work follows the line of investigation initiated by Ritter et al. (2011) who treat generation of conversational dialog as a statistical machine translation (SMT) problem.", "startOffset": 57, "endOffset": 78}, {"referenceID": 9, "context": "This work follows the line of investigation initiated by Ritter et al. (2011) who treat generation of conversational dialog as a statistical machine translation (SMT) problem. Ritter et al. (2011) represents a break with previous and contemporaneous dialog work that relies extensively on hand-coded rules, typically either building statistical models on top of heuristic rules or templates (Levin et al.", "startOffset": 57, "endOffset": 197}, {"referenceID": 24, "context": "Progress in SMT stemming from the use of neural language models (Sutskever et al., 2014; Gao et al., 2014; Bahdanau et al., 2015; Luong et al., 2015) has inspired efforts to extend these neural techniques to SMT-based conversational response generation.", "startOffset": 64, "endOffset": 149}, {"referenceID": 6, "context": "Progress in SMT stemming from the use of neural language models (Sutskever et al., 2014; Gao et al., 2014; Bahdanau et al., 2015; Luong et al., 2015) has inspired efforts to extend these neural techniques to SMT-based conversational response generation.", "startOffset": 64, "endOffset": 149}, {"referenceID": 1, "context": "Progress in SMT stemming from the use of neural language models (Sutskever et al., 2014; Gao et al., 2014; Bahdanau et al., 2015; Luong et al., 2015) has inspired efforts to extend these neural techniques to SMT-based conversational response generation.", "startOffset": 64, "endOffset": 149}, {"referenceID": 12, "context": "Progress in SMT stemming from the use of neural language models (Sutskever et al., 2014; Gao et al., 2014; Bahdanau et al., 2015; Luong et al., 2015) has inspired efforts to extend these neural techniques to SMT-based conversational response generation.", "startOffset": 64, "endOffset": 149}, {"referenceID": 21, "context": "Other researchers have recently used SEQ2SEQ to directly generate responses in an end-to-end fashion without relying on SMT phrase tables (Serban et al., 2015; Shang et al., 2015; Vinyals and Le, 2015).", "startOffset": 138, "endOffset": 201}, {"referenceID": 22, "context": "Other researchers have recently used SEQ2SEQ to directly generate responses in an end-to-end fashion without relying on SMT phrase tables (Serban et al., 2015; Shang et al., 2015; Vinyals and Le, 2015).", "startOffset": 138, "endOffset": 201}, {"referenceID": 26, "context": "Other researchers have recently used SEQ2SEQ to directly generate responses in an end-to-end fashion without relying on SMT phrase tables (Serban et al., 2015; Shang et al., 2015; Vinyals and Le, 2015).", "startOffset": 138, "endOffset": 201}, {"referenceID": 1, "context": ", 2014; Bahdanau et al., 2015; Luong et al., 2015) has inspired efforts to extend these neural techniques to SMT-based conversational response generation. Sordoni et al. (2015) augments Ritter et al.", "startOffset": 8, "endOffset": 177}, {"referenceID": 1, "context": ", 2014; Bahdanau et al., 2015; Luong et al., 2015) has inspired efforts to extend these neural techniques to SMT-based conversational response generation. Sordoni et al. (2015) augments Ritter et al. (2011) by rescoring outputs using a SEQ2SEQ model conditioned on conversation history.", "startOffset": 8, "endOffset": 207}, {"referenceID": 1, "context": ", 2014; Bahdanau et al., 2015; Luong et al., 2015) has inspired efforts to extend these neural techniques to SMT-based conversational response generation. Sordoni et al. (2015) augments Ritter et al. (2011) by rescoring outputs using a SEQ2SEQ model conditioned on conversation history. Other researchers have recently used SEQ2SEQ to directly generate responses in an end-to-end fashion without relying on SMT phrase tables (Serban et al., 2015; Shang et al., 2015; Vinyals and Le, 2015). Serban et al. (2015) propose a hierarchical neural model aimed at capturing dependencies over an extended conversation history.", "startOffset": 8, "endOffset": 511}, {"referenceID": 1, "context": ", 2014; Bahdanau et al., 2015; Luong et al., 2015) has inspired efforts to extend these neural techniques to SMT-based conversational response generation. Sordoni et al. (2015) augments Ritter et al. (2011) by rescoring outputs using a SEQ2SEQ model conditioned on conversation history. Other researchers have recently used SEQ2SEQ to directly generate responses in an end-to-end fashion without relying on SMT phrase tables (Serban et al., 2015; Shang et al., 2015; Vinyals and Le, 2015). Serban et al. (2015) propose a hierarchical neural model aimed at capturing dependencies over an extended conversation history. Recent work by Li et al. (2015) measures mutual information between message and response in order to reduce the proportion of generic responses typical of SEQ2SEQ systems.", "startOffset": 8, "endOffset": 650}, {"referenceID": 27, "context": ", (Wahlster and Kobsa, 1989; Kobsa, 1990; Schatztnann et al., 2005; Lin and Walker, 2011)).", "startOffset": 2, "endOffset": 89}, {"referenceID": 8, "context": ", (Wahlster and Kobsa, 1989; Kobsa, 1990; Schatztnann et al., 2005; Lin and Walker, 2011)).", "startOffset": 2, "endOffset": 89}, {"referenceID": 20, "context": ", (Wahlster and Kobsa, 1989; Kobsa, 1990; Schatztnann et al., 2005; Lin and Walker, 2011)).", "startOffset": 2, "endOffset": 89}, {"referenceID": 11, "context": ", (Wahlster and Kobsa, 1989; Kobsa, 1990; Schatztnann et al., 2005; Lin and Walker, 2011)).", "startOffset": 2, "endOffset": 89}, {"referenceID": 30, "context": "Since generating meaningful responses in a open-domain scenario is intrinsically difficult in conventional dialog systems, existing models often focus on generalizing character style on the basis of qualitative statistical analysis (Walker et al., 2012; Walker et al., 2011).", "startOffset": 232, "endOffset": 274}, {"referenceID": 29, "context": "Since generating meaningful responses in a open-domain scenario is intrinsically difficult in conventional dialog systems, existing models often focus on generalizing character style on the basis of qualitative statistical analysis (Walker et al., 2012; Walker et al., 2011).", "startOffset": 232, "endOffset": 274}, {"referenceID": 8, "context": ", (Wahlster and Kobsa, 1989; Kobsa, 1990; Schatztnann et al., 2005; Lin and Walker, 2011)). Since generating meaningful responses in a open-domain scenario is intrinsically difficult in conventional dialog systems, existing models often focus on generalizing character style on the basis of qualitative statistical analysis (Walker et al., 2012; Walker et al., 2011). The present work, by contrast, is in the vein of the SEQ2SEQ models of Vinyals and Le (2015) and Li et al.", "startOffset": 16, "endOffset": 461}, {"referenceID": 8, "context": ", (Wahlster and Kobsa, 1989; Kobsa, 1990; Schatztnann et al., 2005; Lin and Walker, 2011)). Since generating meaningful responses in a open-domain scenario is intrinsically difficult in conventional dialog systems, existing models often focus on generalizing character style on the basis of qualitative statistical analysis (Walker et al., 2012; Walker et al., 2011). The present work, by contrast, is in the vein of the SEQ2SEQ models of Vinyals and Le (2015) and Li et al. (2015), enriching these models by training persona vectors directly from conversational data and relevant side-information, and incorporating these directly into the decoder.", "startOffset": 16, "endOffset": 482}, {"referenceID": 4, "context": "Our work introduces two persona-based models: the Speaker Model, which models the personality of the respondent, and the Speaker-Addressee Model which models the way the respondent adapts their speech to a given addressee \u2014 a linguistic phenomenon known as lexical entrainment (Deutsch and Pechmann, 1982).", "startOffset": 277, "endOffset": 305}, {"referenceID": 10, "context": "To deal with the issue that SEQ2SEQ models tend to generate generic and commonplace responses such as I don\u2019t know, we follow Li et al. (2015) by reranking the generated N-best list using a scoring function that linearly combines a length penalty and the log likelihood of source given target:", "startOffset": 126, "endOffset": 143}, {"referenceID": 14, "context": "We optimize \u03b3 and \u03bb on N-best lists of response candidates generated from the development set using MERT (Och, 2003) by optimizing BLEU.", "startOffset": 105, "endOffset": 116}, {"referenceID": 24, "context": "Training Protocols We trained four-layer SEQ2SEQ models on the Twitter corpus following the approach of (Sutskever et al., 2014).", "startOffset": 104, "endOffset": 128}, {"referenceID": 23, "context": "To obtain a point of comparison with prior state-ofthe-art work (Sordoni et al., 2015; Li et al., 2015), we measure our baseline (non-persona) LSTM model against prior work on the dataset of (Sordoni et al.", "startOffset": 64, "endOffset": 103}, {"referenceID": 10, "context": "To obtain a point of comparison with prior state-ofthe-art work (Sordoni et al., 2015; Li et al., 2015), we measure our baseline (non-persona) LSTM model against prior work on the dataset of (Sordoni et al.", "startOffset": 64, "endOffset": 103}, {"referenceID": 23, "context": ", 2015), we measure our baseline (non-persona) LSTM model against prior work on the dataset of (Sordoni et al., 2015), which we call the Twitter Sordoni Dataset.", "startOffset": 95, "endOffset": 117}, {"referenceID": 23, "context": "Details of this dataset are in (Sordoni et al., 2015).", "startOffset": 31, "endOffset": 53}, {"referenceID": 25, "context": "Training Since the relatively small size of the dataset does not allow for training an open domain dialog model, we adopted a domain adaption strategy where we first trained a standard SEQ2SEQ models using a much larger OpenSubtitles (OSDb) dataset (Tiedemann, 2009), and then adapting the pre-trained model to the TV series dataset.", "startOffset": 249, "endOffset": 266}, {"referenceID": 19, "context": "MT baseline (Ritter et al., 2011) 3.", "startOffset": 12, "endOffset": 33}, {"referenceID": 10, "context": "Standard LSTM MMI (Li et al., 2015) 5.", "startOffset": 18, "endOffset": 35}, {"referenceID": 19, "context": "We contrast our baseline against an SMT baseline (Ritter et al., 2011), and the best result (Li et al.", "startOffset": 49, "endOffset": 70}, {"referenceID": 10, "context": ", 2011), and the best result (Li et al., 2015) on the established dataset of (Sordoni et al.", "startOffset": 29, "endOffset": 46}, {"referenceID": 23, "context": ", 2015) on the established dataset of (Sordoni et al., 2015).", "startOffset": 38, "endOffset": 60}, {"referenceID": 23, "context": "Following (Sordoni et al., 2015; Li et al., 2015) we used BLEU (Papineni et al.", "startOffset": 10, "endOffset": 49}, {"referenceID": 10, "context": "Following (Sordoni et al., 2015; Li et al., 2015) we used BLEU (Papineni et al.", "startOffset": 10, "endOffset": 49}, {"referenceID": 16, "context": ", 2015) we used BLEU (Papineni et al., 2002) for parameter tuning and evaluation.", "startOffset": 21, "endOffset": 44}, {"referenceID": 5, "context": "BLEU has been shown to correlate well with human judgment on the response generation task, as demonstrated in (Galley et al., 2015).", "startOffset": 110, "endOffset": 131}, {"referenceID": 10, "context": "Since our main experiments are with a new dataset (the Twitter Persona Dataset), we first show that our LSTM baseline is competitive with the state-of-theart (Li et al., 2015) on an established dataset, the Twitter Sordoni Dataset (Sordoni et al.", "startOffset": 158, "endOffset": 175}, {"referenceID": 23, "context": ", 2015) on an established dataset, the Twitter Sordoni Dataset (Sordoni et al., 2015).", "startOffset": 63, "endOffset": 85}, {"referenceID": 10, "context": "Our baseline is simply our implementation of the LSTMMMI of (Li et al., 2015), so results should be relatively close to their reported results.", "startOffset": 60, "endOffset": 77}, {"referenceID": 10, "context": "We see that our system actually does better than (Li et al., 2015), and we attribute the improvement to a larger training corpus, the use of dropout during training, and possibly to the \u201cconversationalist\u201d nature of our corpus.", "startOffset": 49, "endOffset": 66}, {"referenceID": 10, "context": "In line with findings in (Li et al., 2015), we observe a consistent performance boost introduced by the MMI objective function over a standard SEQ2SEQ model based on the MLE objective function.", "startOffset": 25, "endOffset": 42}], "year": 2017, "abstractText": "We present persona-based models for handling the issue of speaker consistency in neural response generation. A speaker model encodes personas in distributed embeddings that capture individual characteristics such as background information and speaking style. A dyadic speaker-addressee model captures properties of interactions between two interlocutors. Our models yield qualitative performance improvements in both perplexity and BLEU scores over baseline sequence-to-sequence models, with similar gain in speaker consistency as measured by human judges.", "creator": "TeX"}}}