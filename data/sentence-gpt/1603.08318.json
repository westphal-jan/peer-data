{"id": "1603.08318", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "28-Mar-2016", "title": "Exclusivity Regularized Machine", "abstract": "It has been recognized that the diversity of base learners is of utmost importance to a good ensemble. This paper defines a novel measurement of diversity, termed as exclusivity. With the designed exclusivity, we further propose an ensemble model, namely Exclusivity Regularized Machine (ERM), to jointly suppress the training error of ensemble and enhance the diversity between bases. The study, which was initiated in collaboration with the College of Science, London and the University of Manchester, uses a technique called \"Rutability Rutability\". This results in a number of findings, including that with the introduction of more training to the ensemble, it has enabled an ensemble to reduce the error and reduce the error by about 1% in the model. The resulting results can be seen as having positive effects on training performance, with an improved training and improved training performance.\n\n\n\nThe purpose of the study is to explore whether this model provides a useful information for evaluating the results of this research. In addition, it is important to acknowledge that the number of different studies has been performed on several different dimensions of performance (ie. the number of members in each case, the length of the training, the degree of time it takes to obtain a consensus estimate), and that this is still relevant as it is not an exhaustive list of subjects. However, the primary issue in this paper is that there are a number of different hypotheses for the role of inclusion in the training. The first one is the role of inclusion in the training. We do not think there is sufficient evidence to establish that this is the primary determinant of the performance of the ensemble in terms of the training, and that in turn, we need to take into account the role of the other variables in the training. Although we have shown that the training may vary in the training phase (e.g., as mentioned in the second part of the paper), that this is not conclusive, it is worth looking into.\nFor example, we have shown that only the first time there were any number of different types of trained members was at least 8,000 minutes (4,400 minutes), but only 1,800 of those participants were. The second is the role of inclusion, which suggests that these individuals have been more active during the training session than the first time, whereas those individuals who had been more active during the training session were more active during the training session. This suggests that the majority of participants in the study had been more active when the training was more than the first time. Therefore, when we look", "histories": [["v1", "Mon, 28 Mar 2016 05:58:15 GMT  (30kb)", "https://arxiv.org/abs/1603.08318v1", null], ["v2", "Mon, 16 May 2016 07:02:05 GMT  (28kb)", "http://arxiv.org/abs/1603.08318v2", null]], "reviews": [], "SUBJECTS": "cs.LG", "authors": ["xiaojie guo"], "accepted": false, "id": "1603.08318"}, "pdf": {"name": "1603.08318.pdf", "metadata": {"source": "CRF", "title": null, "authors": ["Xiaojie Guo"], "emails": ["xj.max.guo@gmail.com"], "sections": [{"heading": null, "text": "ar X\niv :1\n60 3.\n08 31\n8v 2\n[ cs\n.L G\n] 1\n6 M\nay 2"}, {"heading": "1 Introduction", "text": "Classification is a major task in the fields of machine learning and pattern recognition. In binary classification, a hypothesis is constructed from a feasible hypothesis space based on the training set {(xi, yi)} N i=1, where {xi} N i=1 is a set of data points with xi \u2208 R\nd sampled i.i.d. under a distribution from an input subspace, and {yi}Ni=1 with yi \u2208 {\u22121,+1} are their corresponding labels. The obtained hypothesis, also known as classifier, is \u201cgood\u201d when it is able to generalize well the \u201cknowledge\u201d learned from the training data to unseen instances. Multiple-class cases can be analogously accomplished by a group of binary classifiers [1].\nArguably, among existing classifiers, Support Vector Machine (SVM) [2][3] is the most popular one due to its promising performance. In general, the primal SVM can be modeled as follows:\nargmin {w,b}\n\u03a8(w) + \u03bb N \u2211\ni=1\nf(yi, \u03c6(xi) Tw+ b), (1)\nwhere f(\u00b7) is a penalty function, \u03a8(w) performs as a regularizer on the learner w and b is the bias. The function \u03c6(\u00b7) is to map xi from the original D-dimensional feature space to a new M - dimensional one. Moreover, \u03bb is a non-negative coefficient that provides a trade-off between the loss term and the regularizer. If SVM adopts the hinge loss as penalty, the above (1) turns out to be:\nargmin {w,b} \u03a8(w) + \u03bb\nN \u2211\ni=1\n(\n1\u2212 (\u03c6(xi) Tw + b)yi\n)p\n+ , (2)\nwhere the operator (u)+ := max(u, 0) keeps the input scalar u unchanged if u is non-negative, returns zero otherwise, the extension of which to vectors and matrices is simply applied elementwise. Furthermore, p is a constant typically in the range [1, 2] for being meaningful. In practice, p is often selected to be either 1 or 2 for ease of computation, which correspond to \u21131-norm and \u21132-norm loss primal SVMs, respectively. As for the regularization term, \u03a8(w) := 12\u2016w\u2016 2 2 (\u2113\n2 regularizer) and \u03a8(w) := \u2016w\u20161 (\u21131 regularizer) are two classical options.\nAs has been well recognized, a combination of various classifiers can improve predictions. Ensemble approaches, with Boosting [4] and Bagging [5] as representatives, make use of this recognition and achieve strong generalization performance. The generalization error of ensemble mainly depends on two factors, formally expressed as E = E\u0304 \u2212 A\u0304, where E is the mean-square error of the ensemble, E\u0304 represents the average mean-square error of component learners and A\u0304 stands for the average difference (diversity) between the ensemble and the components. Error-Ambiguity decomposition [6], Bias-Variance-Covariance decomposition [7] and Strength-Correlation decomposition [8] all confirm the above principle. This indicates that jointly minimizing the training error and maximizing the diversity of base learners is key to the ensemble performance. Considering the popularity of SVM and the potential of ensemble, it would be interesting and beneficial to equip SVM with ensemble thoughts.\nThis work concentrates on how to train a set of component SVMs and integrate them as an ensemble. More concretely, the contribution of this paper can be summarized as follows: 1) we define a new measurement, namely (relaxed) exclusivity, to manage the diversity between base learners, 2) 2e propose a novel ensemble, called Exclusivity Regularized Machine (ERM), which concerns the training error and the diversity of components simultaneously, and 3) we design an Augmented Lagrange Multiplier based algorithm to efficiently seek the solution of ERM, the global optimality of which is theoretically guaranteed."}, {"heading": "2 Exclusivity Regularized Machine", "text": ""}, {"heading": "2.1 Definition and Formulation", "text": "It is natural to extend the traditional primal SVM (2) to the following ensemble version with C components as:\nargmin {W,b} \u03a8(W) + \u03bb\nC \u2211\nc=1\nN \u2211\ni=1\n(\n1\u2212 (\u03c6(xi) Twc + bc)yi\n)p\n+ , (3)\nwhere W \u2208 RM\u00d7C := [w1,w2, ...,wC ] and b \u2208 RC := [b1, b2, .., bC ]T . Suppose we simply impose 12\u2016W\u2016 2 F or \u2016W\u20161 on W, all the components (and the ensemble) will have no difference with the hypothesis directly calculated from (2) using the same type of regularizer. From this view, \u03a8(W) is critical to achieve the diversity.1\nPrior to introducing our designed regularizer, we first focus on the concept of diversity. Although the diversity has no formal definition so far, the thing in common among studied measurements is that the diversity enforced in a pairwise form between members strikes a good balance between complexity and effectiveness. The evidence includes Q-statistics measure [9], correlation coefficient measure [9], disagreement measure [10], double-fault measure [11], k-statistic measure [12] and mutual angular measure [13, 14, 15]. These measures somehow enhance the diversity, however, most of them are heuristic. One exception is Diversity Regularized Machine [13], which attempts to seek the globally-optimal solution. Unfortunately, it often fails because the condition required for the global optimality, say \u2016wc\u20162 = 1 for all c, is not always satisfied. Further, Li et al. proposed a pruning strategy to improve the performance of DRM [16]. But, DRM requires too much time to converge, which limits its applicability. In this work, we define a new measure of diversity, i.e. (relaxed) exclusivity, as below.\nDefinition 1. (Exclusivity) Exclusivity between two vectors u \u2208 Rm and v \u2208 Rm is defined as X (u,v) := \u2016u \u2299 v\u20160 = \u2211m\ni=1 u(i) \u00b7 v(i) 6= 0, where \u2299 designates the Hadamard product, and \u2016 \u00b7 \u20160 is the \u21130 norm.\nFrom the definition, we can observe that the exclusivity encourages two vectors to be as orthogonal as possible. Due to the non-convexity and discontinuity of \u21130 norm, we have the following relaxed exclusivity.\n1We note that splitting the training data into C sub-sets and training C classifiers separately on the sub-sets would lead to some difference between the components. But, this strategy is not so reliable since if the training data are sufficiently and i.i.d. sampled under a distribution, the difference would be very trivial.\nDefinition 2. (Relaxed Exclusivity) The definition of relaxed exclusivity between u \u2208 Rm and v \u2208 Rm is given as Xr(u,v) := \u2016u \u2299 v\u20161 = \u2211m i=1 |u(i)| \u00b7 |v(i)|, where |u| is the absolute value of u. The relaxation is similar with that of the \u21131 norm to the \u21130 norm.\nIt can be easily verified that \u2016u\u20160 = X (u,1), \u2016u\u20161 = Xr(u,1) and \u2016u\u201622 = Xr(u,u), where 1 \u2208 Rm is the vector with all of its m entries being 1.\nInstead of directly using \u03a8(W) := \u2211\n1\u2264c\u0303 6=c\u2264C Xr(wc,wc\u0303), we employ the following:\n\u03a8(W) := 1\n2 \u2016W\u20162F +\n\u2211\n1\u2264c\u0303 6=c\u2264C\nXr(wc,wc\u0303) = 1\n2\nM \u2211\ni=1\n( C \u2211\nc=1\n|wc(i)|\n)2\n= 1\n2 \u2016WT \u201621,2. (4)\nThe main reasons of bringing 12\u2016W\u2016 2 F into the regularizer are: 1) it essentially enhances the stability of solution, 2) it tends to mitigate the scale issue by penalizing large columns, and 3) as the relaxed exclusivity itself is non-convex, the introduction guarantees the convexity of the regularizer. Finally, the proposed Exclusivity Regularized Machine (ERM) can be written in the following shape:\nmin {wc,bc}\n1 2 \u2016WT \u201621,2 + \u03bb\nC \u2211\nc=1\nN \u2211\ni=1\n(\n1\u2212 (\u03c6(xi) Twc + bc)yi\n)p\n+ . (5)\nIn next sub-section, we will customize an efficient and effective Augmented Lagrangian Multiplier algorithm (ALM) to seek the solution to (5), which has rigorous convergence and global optimality guarantee as well as (quasi) linear complexity (discussed in Sec. 3).\nRemarks As expressed in Eq. 4, we have motivated the \u21131,2 regularizer from a novel perspective. It has been verified that, as one of mixed norms, the \u21131,2 is in nature able to capture some structured sparsity [17]. In general, the regression models using such mixed norms can be solved by a modified FOCUSS algorithm [17]. Zhou et al. [18] introduced the \u21131,2 regularizer into a specific task, i.e. multi-task feature selection, and used the subgradient method to seek the solution of the associated optimization problem. The responsibility of the \u21131,2 regularizer is to enforce the negative correlation among categories [18]. Recently, Kong et al. [19] utilized \u21131,2 norm to bring out sparsity at intra-group level in feature selection, and proposed an effective iteratively re-weighted algorithm to solve the corresponding optimization problem. In this work, besides the view of motivating the \u21131,2 regularizer, its role in our target problem, say constructing an ensemble of SVMs, is also different with the previous work [17, 18, 19]. The functionalities of [18] and [19] are the intra-exclusivity of multiple hypotheses (tasks) and the inter-exclusivity of a single hypothesis respectively, while our principle is the diversity of multiple components of a single ensemble hypothesis."}, {"heading": "2.2 Optimization", "text": "With the trick that 1\u2212(\u03c6(xi)Twc+bc)yi = yiyi\u2212(\u03c6(xi)Twc+bc)yi = yi(yi\u2212(\u03c6(xi)Twc+bc)), we introduce auxiliary variables eci := yi\u2212 (\u03c6(xi)\nTwc + bc). In the sequel, the minimization of (5) can be converted into:\nargmin {W,b}\n1 2 \u2016WT \u201621,2 + \u03bb ( Y \u2299E)p+ s. t. P = W; E = Y \u2212 (X TP+ 1bT ), (6)\nwhere X \u2208 RM\u00d7N := [\u03c6(x1), \u03c6(x2), ..., \u03c6(xN )], ec \u2208 RN := [ec1, e c 2, ..., e c N ] T , E \u2208 RN\u00d7C := [e1, e2, ..., eC ] and y \u2208 RN := [y1, y2, ..., yN ]T . And each column of Y \u2208 RN\u00d7C is y. Please notice that, the constraint P = W is added to make the objective separable and thus solvable by the Augmented Lagrangian Multiplier framework. It is worth mentioning that, thanks to the convexity of each term involved in the objective and the linearity of the constraints, the target problem is convex. The Lagrangian function of (6) can be written in the following form:\nL(W,b,E,P) := 1\n2 \u2016WT \u201621,2 + \u03bb\n(\nY \u2299E)p+ +\u03a6(Q,P\u2212W) + \u03a6(Z,E\u2212Y +X TP+ 1bT ),\n(7) with the definition \u03a6(U,V) := \u00b52 \u2016V\u2016 2 F + \u3008U,V\u3009, where \u3008\u00b7, \u00b7\u3009 represents matrix inner product and \u00b5 is a positive penalty scalar. In addition, Q \u2208 RM\u00d7C and Z \u2208 RN\u00d7C are Lagrangian multipliers. The proposed solver iteratively updates one variable at a time by fixing the others. Below are the solutions to sub-problems.\nW sub-problem With the variables unrelated to W fixed, we have the sub-problem of W:\nW(t+1) = argmin W\n1 2 \u2016WT \u201621,2 +\u03a6(Q (t),P(t) \u2212W). (8)\nAs observed from the problem (8), it can be split into a set of smaller problems. For each row W\u00b7j , instead of directly optimizing (8), we resolve the following equivalent objective:\nW (t+1) \u00b7j = argmin\nW \u00b7j\n1 2 W\u00b7jGW T \u00b7j +\u03a6(Q (t) \u00b7j ,P (t) \u00b7j \u2212W\u00b7j), (9)\nwhere G is formed by:\nG := Diag\n([\n\u2016W\u00b7j\u20161 |W\u00b7j(1)|+ \u01eb , \u2016W\u00b7j\u20161 |W\u00b7j(2)|+ \u01eb , ..., \u2016W\u00b7j\u20161 |W\u00b7j(C)|+ \u01eb\n])\n, (10)\nwhere \u01eb \u2192 0+ (a small constant) is introduced to avoid zero denominators.2 Since both G and W\u00b7j depend on W\u00b7j , to find out the solution to (9), we employ an efficient re-weighted algorithm to iteratively update G and W\u00b7j . As for W\u00b7j , with G fixed, equating the partial derivative of (9) with respect to W\u00b7j to zero yields:\nW (k+1) \u00b7j = (\u00b5 (t)P (t) \u00b7j +Q (t) \u00b7j )(G (k) + \u00b5(t)I)\u22121. (11)\nThen G(k+1) is updated using W(k+1)\u00b7j as in (10). The procedure summarized in Algorithm 1 terminates when converged.\nb sub-problem Dropping the terms independent on b leads to a least squares regression problem:\nb(t+1) = argmin b \u03a6(Z(t),E(t) \u2212Y +XTP(t) + 1bT ) = (\nY \u2212E(t) \u2212XTP(t) \u2212 Z(t) \u00b5(t) )T ( 1 N 1 ) .\n(12)\nE sub-problem Similarly, picking out the terms related to E gives the following problem:\nE(t+1) = argmin E\n\u03bb\n\u00b5(t) (\nY \u25e6E)p+ + 1\n2 \u2016E\u2212 S(t)\u20162F , (13)\nwhere S(t) := Y \u2212 XTP(t) \u2212 1b(t+1)T \u2212 Z (t)\n\u00b5(t) . It can be seen that the above is a single-variable\n2-piece piecewise function. Thus, to seek the minimum of each element in E, we just need to pick the smaller between the minima when yieci \u2265 0 and yie c i < 0. Moreover, we can provide the explicit solution when p := 1 or 2 (for arbitrary p we will discuss it in Sec. 5). When p := 1:\nE(t+1) = \u2126 \u25e6 S \u03bb \u00b5(t) [S(t)] + \u2126\u0304 \u25e6 S(t). (14)\nFor p := 2:\nE(t+1) = \u2126 \u25e6 S(t)/(1 + 2\u03bb\n\u00b5(t) ) + \u2126\u0304 \u25e6 S(t), (15)\nwhere \u2126 \u2208 RN\u00d7C := (Y \u25e6 S(t) > 0) is an indicator matrix, and \u2126\u0304 is the complementary support of \u2126. The definition of shrinkage operator on scalars is S\u01eb>0[u] := sgn(u)max(|u| \u2212 \u01eb, 0). The extension of the shrinkage operator to vectors and matrices is simply applied element-wise.\nP sub-problem There are two terms involve P. The associated optimization problem reads:\nP(t+1) =argmin P \u03a6(Q(t),P\u2212W(t+1)) + \u03a6(Z(t),E(t+1) \u2212Y +XTP+ 1b(t+1)T ). (16)\nThis sub-problem only contains quadratic terms, so it is easy to compute the solution in closed-form:\nP(t+1) = K\u22121 ( W(t+1) \u2212 Q(t)\n\u00b5(t) +X(M \u2212E(t+1))\n)\n, (17)\n2The derived algorithm can be proved to minimize \u2016WT + \u01eb\u201621,2. Certainly, when \u01eb \u2192 0 +, \u2016WT + \u01eb\u201621,2\ninfinitely approaches to \u2016WT \u201621,2.\nAlgorithm 1: W Solver\nInput: W(t), P(t), Q(t), \u00b5(t). Initial.: k \u2190 0; H(k) \u2190 W(t); for j = 0 : M do\nwhile not converged do Update G(k+1) via Eq. (10); Update H(k+1)\u00b7j via Eq. (11); k \u2190 k + 1;\nend end Output: W(t+1) \u2190 H(k)\nAlgorithm 2: Exclusivity Regularized Machine\nInput: Training set {(xi, yi)}Ni=1, positive integer C and positive real value \u03bb. Initial.: t \u2190 0; W(t) \u2208 RM\u00d7C \u2190 1; b(t) \u2208 RC \u2190 0; P(t) \u2208 RM\u00d7C \u2190 0;Q(t) \u2208 RM\u00d7C \u2190 1; Z(t) \u2208 RN\u00d7C \u2190 0; \u00b5(t) \u2190 1; \u03c1 \u2190 1.1; while not converged do\nUpdate W(t+1) via Alg. 1; Update b(t+1) via Eq. (12); Update E(t+1) via Eq. (14) or (15); Update P(t+1) via Eq. (17); Update Multipliers and \u00b5(t+1) via Eq. (18); t \u2190 t+ 1;\nend\nOutput: Final Ensemble 1 C ( \u2211C i=1 w (t) c , \u2211C i=1 b (t) c )\nwhere we denote K\u22121 := (I+XXT )\u22121 and M := Y \u2212 1b(t+1)T \u2212 Z (t)\n\u00b5(t) .\nMultipliers and \u00b5 Besides, there are two multipliers and \u00b5 to update, which are simply given by:\nZ(t+1) = Z(t) + \u00b5(t)(E(t+1) \u2212Y +XTP(t+1) + 1b(t+1)T ); Q(t+1) = Q(t) + \u00b5(t)(P(t+1) \u2212W(t+1));\u00b5(t+1) = \u03c1\u00b5(t), \u03c1 > 1. (18)\nFor clarity, the procedure of solving (2) is outlined in Algorithm 2. The algorithm should not be terminated until the change of objective value is smaller than a pre-defined threshold (in the experiments, we use 0.05). Please see Algorithm 2 for other details that we can not cover in the text."}, {"heading": "3 Theoretical Analysis", "text": "First, we come to the loss term of ERM (5), which accesses the total penalty of base learners as:\nC \u2211\nc=1\nN \u2211\ni=1\n(\n1\u2212 (\u03c6(xi) Twc + bc)yi\n)p\n+ , (19)\nwhere p \u2265 1. Alternatively, the loss of the ensemble {we, be} := { 1C \u2211C c=1wc, 1 C \u2211C c=1 bc} is as:\nN \u2211\ni=1\n(\n1\u2212 (\u03c6(xi) Twe + be)yi\n)p\n+ . (20)\nBased on the above, we have the relationship between the two losses as described in Proposition 1.\nProposition 1. Let {w1, b1},..., {wC , bC} be the component learners obtained by ERM (Alg. 2), and {we, be} := { 1C \u2211C c=1wc, 1 C \u2211C\nc=1 bc} the ensemble, the loss of {we, be} is bounded by the average loss of the base learners.\nProof. Please note that, for each training instance, substituting {we, be} with { 1 C \u2211C c=1wc, 1 C \u2211C c=1 bc} into (20) yields \u2211N i=1 ( 1 C \u2211C c=1 ( 1\u2212(\u03c6(xi) Twc+bc)yi ))p + . Due to the convexity of the hinge loss together with p \u2265 1, the relationship \u2211N\ni=1\n(\n1\u2212(\u03c6(xi) Twe+be)yi\n)p\n+ \u2264\n1 C\n\u2211C\nc=1\n\u2211N\ni=1\n(\n1\u2212 (\u03c6(xi) Twc + bc)yi\n)p\n+ holds by applying the Jensen\u2019s inequality.\nThe proposition indicates that as we optimize ERM (5), an upper bound of the loss of the ensemble is also minimized. Thus, incorporating with our proposed regularizer, ERM is able to achieve the goal of simultaneously optimizing the training error of ensemble and the diversity of components.\nNext, we shall consider the convergence and optimality of the designed algorithms. Before discussing Alg. 2, we have to confirm the property of Alg. 1, which is established by Theorem 1.\nTheorem 1. The updating rules (10) and (11) for solving the problem (9), i.e. Algorithm 1, converges and the obtained optimal solution is exactly the global optimal solution of the problem (8).\nProof. Algorithm 1 is actually a special case of the algorithm proposed in [19]. Due to the limited space, we refer readers to [19] for the detailed proof.\nWith Theorem 1, it is ready to analyze Algorithm 2. To this end, the following lemmas are required.\nLemma 1. [20, 21] Let H be a real Hilbert space endowed with an inner product \u3008\u00b7, \u00b7\u3009 and a corresponding norm \u2016 \u00b7 \u2016, and any y \u2208 \u2202\u2016x\u2016, where \u2202\u2016 \u00b7 \u2016 denotes the subgradient. Then \u2016y\u2016\u2217 = 1 if x 6= 0, and \u2016y\u2016\u2217 \u2264 1 if x = 0, where \u2016 \u00b7 \u2016\u2217 is the dual norm of the norm \u2016 \u00b7 \u2016.\nLemma 2. Both the sequences {Z(t)} and {Q(t)} generated by Algorithm 2 are bounded.\nProof. According to the optimality conditions for (6) with respect to E and W, and the updating rules of multipliers (18), we know Z(t+1) \u2208 \u2202\u2016\u03bb(Y \u25e6E(t+1))+\u2016pp;\u2212Q (t+1) \u2208 \u2202\u2016 12W T \u201621,2. Using Lemma 1 reaches that the sequences {Z(t)} and {Q(t)} are both bounded because the dual norms of \u2016 \u00b7 \u2016p and \u2016 \u00b7 \u20161,2 are \u2016 \u00b7 \u2016 p\np\u22121 and \u2016 \u00b7 \u2016\u221e,2, respectively.\nNow, we have come to the convergence and optimality of our proposed Algorithm 2.\nTheorem 2. The solution consisting of the limit of the sequences {W(t)}, {b(t)} and {E(t)} generated by Algorithm 2, i.e. (W(\u221e),b(\u221e),E(\u221e)), is global optimal to ERM (5), and the convergence rate is at least o( 1\n\u00b5(t) ).\nProof. As the vital natural property of an ALM algorithm, the following holds:\nL\u00b5(t)(W (t+1),b(t+1),E(t+1),P(t+1),Q(t),Z(t)) \u2264 L\u00b5(t)(W (t),b(t),E(t),P(t),Q(t),Z(t)) =\nL\u00b5(t\u22121)(W (t),b(t),E(t),P(t),Q(t\u22121),Z(t\u22121)) +\n1 + \u03c1\n2\u00b5(t\u22121) (\u2016Q(t) \u2212Q(t\u22121)\u20162F + \u2016Z (t) \u2212 Z(t\u22121)\u20162F ).\n(21) Due to\n\u2211\u221e t=1 1+\u03c1 2\u00b5(t\u22121) = \u03c1(1+\u03c1) 2\u00b5(0)(\u03c1\u22121) < \u221e and the boundedness of {Q(t)} and {Z(t)}, we can con-\nclude that L\u00b5(t\u22121)(W (t),b(t),E(t),P(t),Q(t\u22121),Z(t\u22121)) is upper bounded. As a consequence,\n1 2 \u2016W(t)\u201621,2 + \u03bb\u2016(Y \u25e6E (t))+\u2016 p p =L\u00b5(t\u22121) (W (t),b(t),E(t),P(t),Q(t\u22121),Z(t\u22121))\u2212\n\u2016Q(t)\u20162F \u2212 \u2016Q (t\u22121)\u20162F\n2\u00b5(t\u22121) \u2212\n\u2016Z(t)\u20162F \u2212 \u2016Z (t\u22121)\u20162F\n2\u00b5(t\u22121)\n(22)\nis upper bounded, that is to say {W(t)} and {E(t)} are bounded. According to the updating rules of multipliers, the constraints are satisfied when t \u2192 \u221e. In other words, due to the boundedness of the sequences {Q(t)} and {Z(t)}, the right sides of E(t+1)\u2212Y+XTP(t+1)+1b(t+1)T = Z (t+1)\u2212Z(t)\n\u00b5(t)\nand P(t+1) \u2212W(t+1) = Q (t+1)\u2212Q(t)\n\u00b5(t) infinitely approximate to 0. This proves the feasibility of the\nsolution by Alg. 2 as well as the boundedness of {P(t)} and {b(t)}.\nBecause of the above (22) and the boundedness of multipliers {Q(t)} and {Z(t)}, we have:\nlim t\u2192\u221e\n1 2 \u2016W(t)\u201621,2 + \u03bb\u2016(Y \u25e6E (t))+\u2016 p p = lim t\u2192\u221e L\u00b5(t\u22121)(W (t),b(t),E(t),P(t),Q(t\u22121),Z(t\u22121)).\n(23) Thanks to the feasibility of solution, the last two terms in (6) are neglectable. So Alg. 2 converges to a global optimal solution to (5). The convergence rate is at least o( 1\n\u00b5(t) ) according to (22).\nIn addition, we show the complexity of Alg. 2. The operations including matrix addition and subtraction are relatively cheap, and thus can be ignored. Updating each row of W takes O(qC2) and O(qC) for (11) and (10) respectively, where q is the (inner) iteration number of Alg. 1. Please note that, due to the diagonality of G, the inverse of G+ \u00b5I only needs O(C). Therefore, the cost of Alg. 1 is O(qC2M). The b sub-problem requires O(CMN). The complexity of the E subproblem is O(CMN), for both p := 1 and p := 2. Solving P spends O(CMN + CM2). Besides, the update of the multipliers is at O(CMN) expense. In summary, Alg. 2 has the complexity of O(tCM(qC +N +M)), where t is the number of (outer) iterations required to converge."}, {"heading": "4 Experimental Verification", "text": "We use 9 popularly adopted benchmark datasets from various sources for performance evaluation: including sonar (N = 208,M = 60), german (1, 000, 24), australian (690, 14), ijcnn1 (49, 990, 22), heart (270, 13), ionosphere (351, 34), diabetes (768, 8), liver (345, 6) and splice (1, 000, 60).3 All experiments are conducted on a machine with 2.5 GHz CPU and 64G RAM.\nParameter Effect Here, we evaluate the training and testing errors of ERMC (C \u2208 {5, 10, 30} means the component number) against varying values of \u03bb in the range [0.05, 4]. All the results shown in this experiment are averaged over 10 independent trials, each of which randomly samples half data from the sonar dataset for training and the other half for testing. The first picture in Fig. 1 displays the training error and testing error plots of L2 loss ERM with L2 loss PSVM [22] (denoted as L2-PSVM) as reference. From the curves, we can observe that, as \u03bb grows, the training errors drop, as well as composing less base learns leads to a smaller training error. This is because more and more effort is put on fitting data. As regards the testing error, the order is reversed, which corroborates the recognition that the predication gains from the diversity of classifiers, and reveals the effectiveness of our design in comparison with L2-PSVM. Besides, the testing errors change very slightly in a relatively large range of \u03bb, which implies the insensitivity of ERM to \u03bb. The second picture corresponding to p := 1 shows an additional evidence to p := 2. Although the performance gaps between the different cases shrink, the improvement of ERM is still noticeable. Based on this evaluation, we set \u03bb to 2 for both L1-ERM and L2-ERM in the rest experiments.\nConvergence Speed & Training Time Although the convergence rate and complexity of the proposed algorithm have been theoretically provided, it would be more intuitive to see its empirical behavior. Thus, we here show how quick the algorithm converges, without loss of generality, on the ijcnn1 dataset. From the third picture in Fig. 1, we can observe that, when p := 2, all the three cases converge with about 30 iterations. The cases correspond to p := 1 take more iterations than p := 2 (about 70 iterations), but they are still very efficient. Please note that, for a better view of different settings, the objective plots are normalized into the range [0, 1]. The most right picture in Fig. 1 gives curves of how the CPU-time used for training increases with respect to the number of training samples. Since the training time is too short to be accurately counted, we carry out each test for 10 independent trials, and report the total training time (in seconds). As can be seen, the training time for both p := 1 and 2 is quasi linear with respect to the size of training data. For all the three cases correspond to ERM5, ERM10 and ERM30, the choice of p barely brings differences in time. The gaps between the three cases dominantly come from the number of base learners. The primal SVM only needs to learn one classifier while ERM requires to train multiple bases.4\n3All available at www.csie.ntu.edu.tw/\u223ccjlin/libsvmtools/datasets 4In [22], the authors have revealed via extensive experiments, that PSVM (SVM-ALM) is much more\nefficient than SVMperf [23], Pegasos [24], BMRM [25], and TRON [26], PCD [27] and DCD [28].\nPerformance Comparison This part compares our proposed ERM with the classic ensemble models including AdaBoost and Bagging, and the recently designed DRM. The codes of DRM are downloaded from the authors\u2019 website, while those of AdaBoost and Bagging are integrated in the Matlab statistics toolbox (fitensemble function). The base of DRM, \u03bd-SVM, is from LibSVM. The sizes and distributions of the datasets are various, to avoid the effect brought by the amount of training data and test the generalization ability of the ensembles learned from different types of data, the number of training samples for all the datasets is fixed to 150.\nTable 1 provides the quantitative comparison among the competitors. We report the mean testing errors over 10 independent trials by randomly sampling 150 data points from a dataset as its training set and the rest as the testing. AdaBoost and Bagging are inferior to ERM and DRM in most cases. The exception is on the splice dataset. As for our ERM, we can see that it significantly outperforms the others on the australian, sonar, heart and ionosphere, and competes very favorably on the german dataset. On each dataset, we assign ranks to methods. And the average ranks (A.R.) of the competitors over the involved datasets are given in the last column of Tab. 1. It can be observed that the top five average ranks are all lower than 5.0, and four of which are from ERM methods. The best and the second best belong to L2-ERM30 (A.R.=2.5) and L2-ERM10 (A.R.=3.4) respectively, while the fourth and fifth places are taken by L1-ERM10 (A.R.=4.8) and L1-ERM30 (A.R.=4.9) respectively. The third goes to DRM10, the average rank of which is 4.6. The results on the ijcnn1 are not included in the table, because all the competitors perform very closely to each other, which may lead to an unreliable rank.\nAnother issue should be concerned is the efficiency. Table 2 lists the mean training time over all the datasets and each dataset executes 10 runs. From the numbers, we can see the clear advantage of our ERM. L1-ERM10 and L2-ERM10 only spend about 0.05s on training, while the ERMs with 30 components, i.e. L1-ERM30 and L2-ERM30, cost less than 0.14s. Both AdaBoost and Bagging are sufficiently efficient, which take less than 0.3s to accomplish the task. But the training uses 168.57s and 193.97s by DRM for the 10-base and 30-base cases respectively, which are about 2000 times expensive as the proposed ERM. We would like to mention that the core of DRM is implemented in C++, while our ERM is in pure Matlab. Moreover, as theoretically analyzed in Sec. 3 and empirically verified in Sec. 4, our algorithm is (quasi) linear with respect to the size of training set. In other words, the merit of ERM in time would become more conspicuous as the scale of training data increases, in comparison with AdaBoost, Bagging and DRM. Due to space limit, only several experiments are shown in the paper to demonstrate the efficacy of our ERM. To allow more experimental verification, our code can be downloaded from http://cs.tju.edu.cn/orgs/vision/\u02dcxguo/homepage.htm"}, {"heading": "5 Conclusion", "text": "The diversity of component learners is critical to the ensemble performance. This paper has defined a new measurement of diversity, i.e. exclusivity. Incorporating the designed regularizer with the hinge loss function gives a birth to a novel model, namely Exclusivity Regularized Machine. The convergence of the proposed ALM-based algorithm to a global optimal solution is theoretically guaranteed. The experimental results on several benchmark datesets, compared to the state-of-thearts, have demonstrated the clear advantages of our method in terms of accuracy and efficiency.\nOur framework is ready to embrace more elaborate treatments for further improvement. For instance, due to the relationship \u2016u\u20161 = Xr(u,1), as discussed in Sec. 2.1, the sparsity on W can be\npromoted by extending W\u0303 to [W, \u03b21], where \u03b2 is a weight coefficient of the sparsity. In addition, it is difficult to directly solve the E sub-problem (13) with arbitrary given p. Fortunately, in this work, it is always that p \u2265 1. Thus the partial derivative of (13) with respect to E is monotonically increasing. The binary search method can be employed to narrow the possible range of E by half via each operation. It is positive that our ERM can be widely applied to various classification tasks. Although, for avoiding distractions, no experiments are provided to evaluate the performance of the possible variants, it is positive that our ERM can be widely applied to various classification tasks."}, {"heading": "Acknowledgment", "text": "Xiaojie Guo would like to thank Dr. Ju Sun with Department of Electrical Engineering, Columbia University, for his suggestions on this work."}], "references": [{"title": "Ensemble Methods: Foundations and Algorithms", "author": ["Z. Zhou"], "venue": "Boca Raton, FL: Taylor & Francis Group,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2012}, {"title": "The Nature of Statistical Learning Theory", "author": ["V. Vapnik"], "venue": null, "citeRegEx": "2", "shortCiteRegEx": "2", "year": 1995}, {"title": "A modified finite newton method for fast solution of large scale linear svms", "author": ["S. Keerthi", "D. DeCoste"], "venue": "Journal of Machine Learning Research, vol. 6, pp. 627\u2013650, 2005.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2005}, {"title": "A decision-theoretic generalization of on-line learning and an application to boosting", "author": ["Y. Freund", "R. Schapire"], "venue": "Journal of Computer and System Sciences, vol. 55, no. 1, pp. 119\u2013139, 1997.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 1997}, {"title": "Bagging predictors", "author": ["L. Breiman"], "venue": "Machine Learning, vol. 24, no. 2, pp. 123\u2013140, 1996.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 1996}, {"title": "Neural network ensembles, cross validation, and active learning", "author": ["A. Krogh", "J. Vedelsby"], "venue": "NIPS, pp. 231\u2013238, 1995.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 1995}, {"title": "Generalization error of ensemble estimators", "author": ["P. Ueda", "R. Nakano"], "venue": "Proceedings of International Conference on Neural Network (ICNN), pp. 90\u201395, 1996.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 1996}, {"title": "Random forests", "author": ["L. Breiman"], "venue": "Machine Learning, vol. 45, no. 1, pp. 5\u201332, 2001.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2001}, {"title": "Limits on the majority vote accuracy in classification fusion", "author": ["L. Kuncheva", "C. Whitaker", "C. Shipp", "R. Duin"], "venue": "Pattern Analysis and Applications, vol. 6, no. 1, pp. 22\u201331, 2003.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2003}, {"title": "The random subspace method for constructing decision forests", "author": ["T. Ho"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 20, no. 8, pp. 832\u2013844, 1998.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 1998}, {"title": "Design of effective neural network ensembles for image classification purposes", "author": ["G. Giacinto", "F. Roli"], "venue": "Image and Vision Computing, vol. 19, no. 9-10, pp. 699\u2013707, 2001.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2001}, {"title": "An experimental comparison of three methods for constructing ensembles of decision trees: Bagging, boosting, and randomization", "author": ["T. Dietterich"], "venue": "Machine Learning, vol. 40, no. 2, pp. 139\u2013157, 2000.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2000}, {"title": "Diversity regularized machine", "author": ["Y. Yu", "Y. Li", "Z. Zhou"], "venue": "IJCAI, pp. 1603\u20131608, 2011.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2011}, {"title": "On the generalization error bounds of neural networks under diversityinducing mutual angular regularization", "author": ["P. Xie", "Y. Deng", "E. Xing"], "venue": "arXiv:1511.07110v1, 2015.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2015}, {"title": "Latent variable modeling with diversity-inducing mutual angular regularization", "author": ["P. Xie", "Y. Deng", "E. Xing"], "venue": "arXiv:1512.07336v1, 2015.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2015}, {"title": "Diversity regularized ensemble pruning", "author": ["N. Li", "Y. Yu", "Z. Zhou"], "venue": "ECML PKDD, pp. 330\u2013345, 2012.", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2012}, {"title": "Sparse regression using mixed norms", "author": ["M. Kowalski"], "venue": "Applied and Computational Harmonic Analysis, vol. 27, no. 3, pp. 303\u2013324, 2009.", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2009}, {"title": "Exclusive lasso for multi-task feature selection", "author": ["Y. Zhang", "R. Jin", "S. Hoi"], "venue": "AISTATS, pp. 988\u2013995, 2010.", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2010}, {"title": "Exclusive feature learning on arbitrary structures via l1,2-norm", "author": ["D. Kong", "R. Fujimaki", "J. Liu", "F. Nie", "C. Ding"], "venue": "NIPS, pp. 1655\u20131663, 2014.", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2014}, {"title": "Matrix rank minimization with applications", "author": ["M. Fazel"], "venue": "PhD Thesis, Stanford University, 2002.", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2002}, {"title": "Linearized alternating direction method with adaptive penalty for low rank representation", "author": ["Z. Lin", "R. Liu", "Z. Su"], "venue": "NIPS, pp. 695\u2013704, 2011.", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2011}, {"title": "New primal svm solver with linear computational cost for big data classifications", "author": ["F. Nie", "Y. Huang", "X. Wang", "H. Huang"], "venue": "ICML, (Beijing, China), 2014. 9", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2014}, {"title": "Training linear svms in linear time", "author": ["T. Joachims"], "venue": "ACM SIGKDD, pp. 217\u2013226, 2006.", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2006}, {"title": "Pegasos: Primal estimated subgradient solver for svm", "author": ["S. Shalev-Shwartz", "Y. Singer", "N. Srebro"], "venue": "ICML, pp. 807\u2013814, 2007.", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2007}, {"title": "Bundle methods for regularized risk minimization", "author": ["C. Teo", "S. Vishwanathan", "A. Smola", "Q. Le"], "venue": "Journal of Machine Learning Research, vol. 11, pp. 311\u2013365, 2010.", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2010}, {"title": "Trust region newton method for large-scale logistic regression", "author": ["C. Lin", "R. Weng", "S. Keerthi"], "venue": "Journal of Machine Learning Research, vol. 9, pp. 627\u2013650, 2008.", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2008}, {"title": "Coordinate descent method for large-scale L2-loss linear svm", "author": ["K. Chang", "C. Hsieh", "C. Lin"], "venue": "Journal of Machine Learning Research, vol. 9, pp. 1369\u20131398, 2008.", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2008}, {"title": "A dual coordinate descent method for large-scale linear svm", "author": ["C. Hsieh", "K. Chang", "S. Keerthi", "S. Sundararajan", "C. Lin"], "venue": "ICML, pp. 408\u2013415, 2008. 10", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2008}], "referenceMentions": [{"referenceID": 0, "context": "Multiple-class cases can be analogously accomplished by a group of binary classifiers [1].", "startOffset": 86, "endOffset": 89}, {"referenceID": 1, "context": "Arguably, among existing classifiers, Support Vector Machine (SVM) [2][3] is the most popular one due to its promising performance.", "startOffset": 67, "endOffset": 70}, {"referenceID": 2, "context": "Arguably, among existing classifiers, Support Vector Machine (SVM) [2][3] is the most popular one due to its promising performance.", "startOffset": 70, "endOffset": 73}, {"referenceID": 0, "context": "Furthermore, p is a constant typically in the range [1, 2] for being meaningful.", "startOffset": 52, "endOffset": 58}, {"referenceID": 1, "context": "Furthermore, p is a constant typically in the range [1, 2] for being meaningful.", "startOffset": 52, "endOffset": 58}, {"referenceID": 3, "context": "Ensemble approaches, with Boosting [4] and Bagging [5] as representatives, make use of this recognition and achieve strong generalization performance.", "startOffset": 35, "endOffset": 38}, {"referenceID": 4, "context": "Ensemble approaches, with Boosting [4] and Bagging [5] as representatives, make use of this recognition and achieve strong generalization performance.", "startOffset": 51, "endOffset": 54}, {"referenceID": 5, "context": "Error-Ambiguity decomposition [6], Bias-Variance-Covariance decomposition [7] and Strength-Correlation decomposition [8] all confirm the above principle.", "startOffset": 30, "endOffset": 33}, {"referenceID": 6, "context": "Error-Ambiguity decomposition [6], Bias-Variance-Covariance decomposition [7] and Strength-Correlation decomposition [8] all confirm the above principle.", "startOffset": 74, "endOffset": 77}, {"referenceID": 7, "context": "Error-Ambiguity decomposition [6], Bias-Variance-Covariance decomposition [7] and Strength-Correlation decomposition [8] all confirm the above principle.", "startOffset": 117, "endOffset": 120}, {"referenceID": 8, "context": "The evidence includes Q-statistics measure [9], correlation coefficient measure [9], disagreement measure [10], double-fault measure [11], k-statistic measure [12] and mutual angular measure [13, 14, 15].", "startOffset": 43, "endOffset": 46}, {"referenceID": 8, "context": "The evidence includes Q-statistics measure [9], correlation coefficient measure [9], disagreement measure [10], double-fault measure [11], k-statistic measure [12] and mutual angular measure [13, 14, 15].", "startOffset": 80, "endOffset": 83}, {"referenceID": 9, "context": "The evidence includes Q-statistics measure [9], correlation coefficient measure [9], disagreement measure [10], double-fault measure [11], k-statistic measure [12] and mutual angular measure [13, 14, 15].", "startOffset": 106, "endOffset": 110}, {"referenceID": 10, "context": "The evidence includes Q-statistics measure [9], correlation coefficient measure [9], disagreement measure [10], double-fault measure [11], k-statistic measure [12] and mutual angular measure [13, 14, 15].", "startOffset": 133, "endOffset": 137}, {"referenceID": 11, "context": "The evidence includes Q-statistics measure [9], correlation coefficient measure [9], disagreement measure [10], double-fault measure [11], k-statistic measure [12] and mutual angular measure [13, 14, 15].", "startOffset": 159, "endOffset": 163}, {"referenceID": 12, "context": "The evidence includes Q-statistics measure [9], correlation coefficient measure [9], disagreement measure [10], double-fault measure [11], k-statistic measure [12] and mutual angular measure [13, 14, 15].", "startOffset": 191, "endOffset": 203}, {"referenceID": 13, "context": "The evidence includes Q-statistics measure [9], correlation coefficient measure [9], disagreement measure [10], double-fault measure [11], k-statistic measure [12] and mutual angular measure [13, 14, 15].", "startOffset": 191, "endOffset": 203}, {"referenceID": 14, "context": "The evidence includes Q-statistics measure [9], correlation coefficient measure [9], disagreement measure [10], double-fault measure [11], k-statistic measure [12] and mutual angular measure [13, 14, 15].", "startOffset": 191, "endOffset": 203}, {"referenceID": 12, "context": "One exception is Diversity Regularized Machine [13], which attempts to seek the globally-optimal solution.", "startOffset": 47, "endOffset": 51}, {"referenceID": 15, "context": "proposed a pruning strategy to improve the performance of DRM [16].", "startOffset": 62, "endOffset": 66}, {"referenceID": 16, "context": "It has been verified that, as one of mixed norms, the l1,2 is in nature able to capture some structured sparsity [17].", "startOffset": 113, "endOffset": 117}, {"referenceID": 16, "context": "In general, the regression models using such mixed norms can be solved by a modified FOCUSS algorithm [17].", "startOffset": 102, "endOffset": 106}, {"referenceID": 17, "context": "[18] introduced the l1,2 regularizer into a specific task, i.", "startOffset": 0, "endOffset": 4}, {"referenceID": 17, "context": "The responsibility of the l1,2 regularizer is to enforce the negative correlation among categories [18].", "startOffset": 99, "endOffset": 103}, {"referenceID": 18, "context": "[19] utilized l1,2 norm to bring out sparsity at intra-group level in feature selection, and proposed an effective iteratively re-weighted algorithm to solve the corresponding optimization problem.", "startOffset": 0, "endOffset": 4}, {"referenceID": 16, "context": "In this work, besides the view of motivating the l1,2 regularizer, its role in our target problem, say constructing an ensemble of SVMs, is also different with the previous work [17, 18, 19].", "startOffset": 178, "endOffset": 190}, {"referenceID": 17, "context": "In this work, besides the view of motivating the l1,2 regularizer, its role in our target problem, say constructing an ensemble of SVMs, is also different with the previous work [17, 18, 19].", "startOffset": 178, "endOffset": 190}, {"referenceID": 18, "context": "In this work, besides the view of motivating the l1,2 regularizer, its role in our target problem, say constructing an ensemble of SVMs, is also different with the previous work [17, 18, 19].", "startOffset": 178, "endOffset": 190}, {"referenceID": 17, "context": "The functionalities of [18] and [19] are the intra-exclusivity of multiple hypotheses (tasks) and the inter-exclusivity of a single hypothesis respectively, while our principle is the diversity of multiple components of a single ensemble hypothesis.", "startOffset": 23, "endOffset": 27}, {"referenceID": 18, "context": "The functionalities of [18] and [19] are the intra-exclusivity of multiple hypotheses (tasks) and the inter-exclusivity of a single hypothesis respectively, while our principle is the diversity of multiple components of a single ensemble hypothesis.", "startOffset": 32, "endOffset": 36}, {"referenceID": 18, "context": "Algorithm 1 is actually a special case of the algorithm proposed in [19].", "startOffset": 68, "endOffset": 72}, {"referenceID": 18, "context": "Due to the limited space, we refer readers to [19] for the detailed proof.", "startOffset": 46, "endOffset": 50}, {"referenceID": 19, "context": "[20, 21] Let H be a real Hilbert space endowed with an inner product \u3008\u00b7, \u00b7\u3009 and a corresponding norm \u2016 \u00b7 \u2016, and any y \u2208 \u2202\u2016x\u2016, where \u2202\u2016 \u00b7 \u2016 denotes the subgradient.", "startOffset": 0, "endOffset": 8}, {"referenceID": 20, "context": "[20, 21] Let H be a real Hilbert space endowed with an inner product \u3008\u00b7, \u00b7\u3009 and a corresponding norm \u2016 \u00b7 \u2016, and any y \u2208 \u2202\u2016x\u2016, where \u2202\u2016 \u00b7 \u2016 denotes the subgradient.", "startOffset": 0, "endOffset": 8}, {"referenceID": 21, "context": "1 displays the training error and testing error plots of L2 loss ERM with L2 loss PSVM [22] (denoted as L2-PSVM) as reference.", "startOffset": 87, "endOffset": 91}, {"referenceID": 0, "context": "Please note that, for a better view of different settings, the objective plots are normalized into the range [0, 1].", "startOffset": 109, "endOffset": 115}, {"referenceID": 21, "context": "tw/\u223ccjlin/libsvmtools/datasets In [22], the authors have revealed via extensive experiments, that PSVM (SVM-ALM) is much more efficient than SVM [23], Pegasos [24], BMRM [25], and TRON [26], PCD [27] and DCD [28].", "startOffset": 34, "endOffset": 38}, {"referenceID": 22, "context": "tw/\u223ccjlin/libsvmtools/datasets In [22], the authors have revealed via extensive experiments, that PSVM (SVM-ALM) is much more efficient than SVM [23], Pegasos [24], BMRM [25], and TRON [26], PCD [27] and DCD [28].", "startOffset": 145, "endOffset": 149}, {"referenceID": 23, "context": "tw/\u223ccjlin/libsvmtools/datasets In [22], the authors have revealed via extensive experiments, that PSVM (SVM-ALM) is much more efficient than SVM [23], Pegasos [24], BMRM [25], and TRON [26], PCD [27] and DCD [28].", "startOffset": 159, "endOffset": 163}, {"referenceID": 24, "context": "tw/\u223ccjlin/libsvmtools/datasets In [22], the authors have revealed via extensive experiments, that PSVM (SVM-ALM) is much more efficient than SVM [23], Pegasos [24], BMRM [25], and TRON [26], PCD [27] and DCD [28].", "startOffset": 170, "endOffset": 174}, {"referenceID": 25, "context": "tw/\u223ccjlin/libsvmtools/datasets In [22], the authors have revealed via extensive experiments, that PSVM (SVM-ALM) is much more efficient than SVM [23], Pegasos [24], BMRM [25], and TRON [26], PCD [27] and DCD [28].", "startOffset": 185, "endOffset": 189}, {"referenceID": 26, "context": "tw/\u223ccjlin/libsvmtools/datasets In [22], the authors have revealed via extensive experiments, that PSVM (SVM-ALM) is much more efficient than SVM [23], Pegasos [24], BMRM [25], and TRON [26], PCD [27] and DCD [28].", "startOffset": 195, "endOffset": 199}, {"referenceID": 27, "context": "tw/\u223ccjlin/libsvmtools/datasets In [22], the authors have revealed via extensive experiments, that PSVM (SVM-ALM) is much more efficient than SVM [23], Pegasos [24], BMRM [25], and TRON [26], PCD [27] and DCD [28].", "startOffset": 208, "endOffset": 212}], "year": 2016, "abstractText": "It has been recognized that the diversity of base learners is of utmost importance to a good ensemble. This paper defines a novel measurement of diversity, termed as exclusivity. With the designed exclusivity, we further propose an ensemble model, namely Exclusivity Regularized Machine (ERM), to jointly suppress the training error of ensemble and enhance the diversity between bases. Moreover, an Augmented Lagrange Multiplier based algorithm is customized to effectively and efficiently seek the optimal solution of ERM. Theoretical analysis on convergence and global optimality of the proposed algorithm, as well as experiments are provided to reveal the efficacy of our method and show its superiority over state-of-the-art alternatives in terms of accuracy and efficiency.", "creator": "LaTeX with hyperref package"}}}