{"id": "1603.08594", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "29-Mar-2016", "title": "Prepositional Attachment Disambiguation Using Bilingual Parsing and Alignments", "abstract": "In this paper, we attempt to solve the problem of Prepositional Phrase (PP) attachments in English. The motivation for the work comes from NLP applications like Machine Translation, for which, getting the correct attachment of prepositions is very crucial. The idea is to correct the PP-attachments for a sentence with the help of alignments from parallel data in another language. The novelty of our work lies in the formulation of the problem into a dual decomposition based algorithm that enforces agreement between the parse trees from two languages as a constraint. Experiments were performed on the English-Hindi language pair and the performance improved by 10% over the baseline, where the baseline is the attachment predicted by the MSTParser model trained for English. The results demonstrate that the approach to correct the PP-attachments in the English-Hindi language is not simple. The first approach we have used was to construct a binary-vector translation model and the result is the prediction of the attachment, which is similar in the other way. The second approach is to make the model more efficient by combining two different approaches to the problem. The first approach involves combining two different approaches to the problem. This is the first approach we have used to understand how to solve the problem. The second approach is to define a binary-vector translation model in English and then combine the two approaches together. The final approach involves combining two different approaches to the problem. This is the first approach we have used to understand how to solve the problem. The third approach consists of solving an object-oriented version of the problem, one that uses only the PEG package that defines the grammar of the problem. In this paper, we will use PEG package and use a new package from the HIndi language, as an example of how to build a new PEG package. In a later post we will use the PEG package, as an example of how to build a new PEG package. In a later post, we will use the PEG package, as an example of how to build a new PEG package. In this article we will use PEG package, as an example of how to build a new PEG package. The current PEG package contains a full-length version, and a collection of the same features, but has a new version. The current PEG package contains a full-length version, and a collection of the same features, but has a new version. The current PEG package contains a full-length version,", "histories": [["v1", "Tue, 29 Mar 2016 00:06:11 GMT  (38kb,D)", "http://arxiv.org/abs/1603.08594v1", null]], "reviews": [], "SUBJECTS": "cs.CL", "authors": ["geetanjali rakshit", "sagar sontakke", "pushpak bhattacharyya", "gholamreza haffari"], "accepted": false, "id": "1603.08594"}, "pdf": {"name": "1603.08594.pdf", "metadata": {"source": "CRF", "title": "Prepositional Attachment Disambiguation Using Bilingual Parsing and Alignments", "authors": ["Geetanjali Rakshit", "Sagar Sontakke", "Pushpak Bhattacharyya", "Gholamreza Haffari"], "emails": ["geet@cse.iitb.ac.in", "sagarsb@cse.iitb.ac.in", "pb@cse.iitb.ac.in", "first.last@monash.edu"], "sections": [{"heading": "1 Introduction", "text": "Prepositional Phrase (PP) attachment disambiguation is an important problem in NLP, for it often gives rise to incorrect parse trees . Statistical parsers often predict incorrect attachment for prepositional phrases. For applications like Machine Translation, incorrect PP-attachment leads to serious errors in translation. Several approaches have been proposed to solve this problem. We attempt to tackle this problem for English. English is a syntactically ambiguous language with respect to PP attachments. For example, consider the following sentence where the prepositional phrase with pockets may attach either to the verb washed or to the noun jeans.\nSentence(1): I washed the jeans with pockets.\nBelow is the correct dependency parse tree (for sentence 1) where the prepositional phrase with pockets is attached to the noun jeans.\nAnother possible parse tree for the same sentence could be as shown in Figure 2: A statistical parser often predicts the PP-attachment incorrectly, and may lead to incorrect parse trees. Let us now look at another sentence.\nSentence(2): I washed the jeans with soap.\nThe correct dependency tree for sentence [2] is the following (Figure 3), where the prepositional phrase with soap attaches to the verb washed.\nClearly, there is a case of ambiguity that can be resolved only if the semantics are known. In this case, the fact that soap is an aid to the verb washed disambiguates its attachment to the verb rather than the noun jeans. For correctly translating such an English sentence to another language, the attachments need to be marked correctly.\nIn this work, we propose a Dual Decomposition (DD) based algorithm for solving the PP attachment problem. We try to disambiguate the PP attachments for English using the corresponding parallel Hindi corpora. Hindi is a syntactically\nar X\niv :1\n60 3.\n08 59\n4v 1\n[ cs\n.C L\n] 2\n9 M\nar 2\n01 6\nrich language and in most cases exhibits no attachment ambiguities. The use of case markers and the inherent construction of sentences in Hindi make cases of ambiguity rarer. Let us examine how sentences 1 and 2 would look like in Hindi, and if there is a case for ambiguity.\nSentence (3) and sentence (4) are the respective Hindi translations of sentence (1) and (2)).\nSentence (3): m{n j b vAlF jF s DoyF | Sentence (4): m{n sAb n s jF s DoyF |\nIn sentence (3), the prepositional phrase jeb waali attaches to the noun jeans as shown in the figure 4.\nThe parse tree for sentence (4) is shown in figure 5 , where the prepositional phrase saabun se attaches to the verb dhoyee.\nThe case markers waali and se in the two sentences in Hindi make the pp-atttachment clear. In our approach, we make use of the parallel Hindi sentences to disambiguate the PP attachments for English sentences.\nThe roadmap of the paper is as follows: We discuss the literature and related work for solving the PP-attachment problem in section [2]. Section [3] describes our approach, and the Dual Decomposition algorithm in detail. The setup, data, and experiments are covered in Section [4]. With Section [5], we conclude our work and discuss scope for future work."}, {"heading": "2 Related Work", "text": "A number of supervised and unsupervised approaches for solving the PP-attachment problem have been proposed in the literature. Ratnaparkhi\net al. (1994) use a Maximum Entropy Model for solving the PP-attachment decision. Schwartz et al. (2003) propose an unsupervised approach for solving PP attachment using multilingual aligned data. They transform the data into high-level linguistic representations and use it make reattachment decisions. The intuition is similar to our work, but the approach is entirely different. Brill and Resnik (1994) discuss a transformation-based rule derivation method for PP-attachment disambiguation. It is a simple learning algorithm which derives a set of transformation rules from training corpus, which are then used for solving the PPattachment problem. Stetina and Nagao (1997) make use of the semantic dictionary to solve the problem of disambiguating PP attachments. Their work describes use of word sense disambiguation (WSD) for both supervised and unsupervised techniques. Agirre (2008) and Medimi (2007) have used WSD-based strategies in different capacities to solve the problem of PP-attachment. Olteanu and Moldovan (2005) have attempted to solve the pp-attachment problem as a classification problem of attachment either to the preceding verb or the noun, and have used Support Vector Machines (SVMs) that use complex syntactic and semantic features."}, {"heading": "3 Our Approach", "text": "We propose a Dual Decomposition based inference algorithm to look at the problem of PPattachment disambiguation. Dual decomposition, or more generally, Lagrangian Relaxation, is a classical method for combinatorial optimization and has been applied to several inference problems in NLP (Rush and Collins, 2012). We train two separate parser models for English and Hindi each, using the MSTParser, and make use of these models in the inferencing step. The input to the algorithm is a parallel English-Hindi sentence pair, with its word alignments given. We first obtain the predicted parse trees for the English and Hindi sentences from the respective trained parser models as an initialsiation step. The DD algorithm then tries to enforce agreement between the two parse trees subject to the given alignments.\nLet us take a closer look at what we mean by agreement between the two parse trees. Essentially, if we have two words in the English sentence denoted by i and i\u2019, aligned to words j and j\u2019 in the parallel Hindi sentence respectively, we\ncan expect a dependency edge between i and i\u2019 in the English parse tree to correspond to an edge between j and j\u2019 in the Hindi parse tree, and vice versa. Also, in order to accommodate structural diversity in languages (Smith and Eisner, 2006), we can expect an edge in the parse tree in one language to correspond to more than one edge, or rather, a path, in the other language parse tree. This has been captured in the examples in figures 6(A) and 6(B). For an edge in the English parse tree, we term the corresponding edge or path in the Hindi parse tree as the projection or projected path of the English edge on the Hindi parse tree, and similarly there are projected paths from Hindi to English. For matters of simplicity, we ignore the direction of the edges in the parse trees. The dual decomposition inference algorithm tries to bring the parse trees in the two languages through its constraints.\nThe problem is formulated as below: In the above formulation, e and h represent a English and Hindi sentence respectively. Te and Th are the corresponding parse trees. \u03b8E and \u03b8H are the model parameters for the edge-factored parser models trained for English and Hindi respectively. te represents an edge in the English parse tree Te. proj(te, Th) is a projected path in Hindi parse tree (Th) for a given English edge te. The term scr(proj(te, Th)) stands for the score of a projected path in Hindi parse tree (Th) for a\ngiven English edge te. The score of the projected path is calculated as the sum of scores of all edges in the path. Let \u03c0te denote the projected path on sentence h in Hindi for the edge te in the English parse tree. We assume scr(\u03c0te = \u2211 a\u2208\u03c0te \u03c8te(a) where \u03c8te(a) is the score of edge a in the projected path \u03c0te . In the other direction, \u03c0tf and scr(\u03c0tf is similarly defined.\nTo solve this maximization problem in figure 7, we assume one tree to be given and maximize the other and the score of its projected path. The algorithm is described in detail in section 3.1."}, {"heading": "3.1 Dual Decomposition based Algorithm", "text": "We use an iterative Coordinate Descent algorithm (Algorithm 1) which calls the Project Algorithm until convergence. The trees Te and Th are initialized by the previously trained parser models for the respective languages.\nAlgorithm 1 Coordinate Descent Algorithm 1: Initialize Te and Th from the MSTParser mod-\nels 2: for t = 1 to N 3: T+e \u2190 project(Th, e) 4: T+h \u2190 project(Te, h) 5: if (Te == T+e ) or (Th == T + h ) 6: break 7: else 8: Te = T + e 9: Th = T + h\n10: end for\nFor N iterations, the project function returns a parse tree for English which maximizes the agreement between the English and Hindi parse tree when the Hindi parse tree is fixed, and likewise for the Hindi parse tree. The algorithm converges when the trees no longer change,\nLet us now look at the Project algorithm (Algorithm 2) in detail. It predicts the tree for a sentence in the target language, given the parse tree in the source language, and the word alignments between the parallel sentence.\nThe lagrangian multipliers are initialized to zero. The best tree in the target language is predicted by the argmax computation in step 4. This maximization involves the parser model parameters \u03b8(i, j) and the score of the best projected path in the source tree for all edges. r(i, j) denotes the score of the projected path of the edge y(i, j) on\nAlgorithm 2 Project Algorithm (tree T, sen S) Require: A parse tree T (Hindi) and sentence S\n(English) 1: Initialize \u2200t, i, j ut(i, j) = 0 2: 3: for t = 1 to N 4: Y \u2190 argmaxy\u2208Trees(s) (\u2211 i,j y(i, j).[\u03b8(i, j)+\nr(i, j)\u2212 \u2211 t ut(i, j)] ) 5: 6: for t \u2208 T 7: \u03c0t \u2190 argmax\u03c0\u2208paths(project t onto S)\u2211 i,j \u03c0(i, j)[\u03d5t(i, j, S) + ut(i, j)] 8: end for 9:\n10: if \u2200t,i,j ;\u03c0t = y(i, j) then 11: return Y 12: else 13: \u2200t,i,j ut(i, j) \u2190 ut(i, j) \u2212 \u03b1(\u03c0t(i, j) \u2212\ny(i, j)) 14: end for\nthe source tree T. In steps 6 and 7, the best projected path for every edge of the source tree is predicted on the target tree using the classifiers described in section ??. The constraints here are that the edges in the projected paths from the classifiers and the predicted trees are in agreement."}, {"heading": "3.2 Projected Path Prediction", "text": "In order to predict the projected path in one language for an edge in the other language, we use a set of two classifiers in a pipeline. Let us recall that we have two nodes in one language with an edge between them, and we are trying to predict the path of the corresponding aligned nodes in the other language. The first classifier predicts the length of the projected path, and the second predicts the predicted path itself, given the path length from the first classifier. Let us look at these classifiers separately.\nThe classifier for path length prediction is a set of five binary classifiers, which predict the path length to be 1, 2, 3, 4 or 5. We assume projected path lengths to be no greater than 5. These classifiers are perceptrons trained on separate annotated data. The features used were the words and POS tags of the four nodes in the pair of alignments under consideration.\nThe classifier for path prediction is a set of four structured perceptron classifiers. We train four\nclassifiers to predict the paths of length 2, 3, 4 and 5. These set of classifiers were trained on separate annotated data, and the features used were the same as in the set of classifiers for path length prediction."}, {"heading": "4 Experiments and Results", "text": "A parser model was trained for Hindi using the MSTParser (McDonald et al., 2006) by a part of the the Hindi Dependency Treebank data (18708 sentences) from IIIT-Hyderabad (Bhatt et al., 2009). A part of the Penn Treebank (28188 sentences) was used for training an English parser (?). The treebanks were converted to MSTParser format from ConLL format for training. A part of the ILCI English-Hindi Tourism parallel corpus (1500 sentences) was used for training the classifiers. This corpus was POS-tagged using the Stanford POS Tagger (Toutanova et al., 2003) for English and using the Hindi POS Tagger (Reddy and Sharoff, 2011) from IIIT-Hyderabad for Hindi. It was then automatically annotated with dependency parse trees by the parsers we had trained before English and Hindi.\nFor testing, we created a corpus of 100 parallel sentences and their word alignments from the Hindi-English Tourism parallel corpus. We manually annotated the instances of pp-attachment ambiguity. We examine the prediction for attachment of only these cases. The baseline system used is the attachment predicted by the parser models trained using the MSTParser. We ran experiments on the test set for iterations 10 to 60, in steps of 10. The outputs from the MSTParser trained model and the DD algorithm were compared against the gold data for English.\nOur observations have been tabulated in Table 4. The MSTParser model was able to correctly disambiguate 54 number of PP-attachments. Our algorithm, however, performed better and marked 64 number of attachments correctly, in the best case. The baseline accuracy for PP attachment was 54%. With our approach, we were able to achieve an improvement of 10% over the baseline.\nWe also experimented with the number of iterations to see if the attachment predictions got any better. The observations have been plotted in the graph in figure 8 . Our algorithm performed best at 30 iterations.\nIn the event of lack of gold standard data for our experiments, we have used statistical POS taggers\nfor POS tagging the data. Also, for getting word alignments, we have used GIZA++ (Och and Ney, 2003), which again has scope for errors. These kind of errors may cascade and cause our system to underperform."}, {"heading": "5 Conclusion and Future Work", "text": "We were able to achieve an accuracy of 10% over the baseline using our approach. However, in terms of overall dependency parsing and not just with respect to PP-attachment, our system is unable to beat the MSTParser model. However, we need to test our approach on a larger dataset, and across other domains besides Tourism. Besides Hindi, there is also scope for exploring other languages as an aid for pp-attachment disambiguation in English. Our approach could also be used for wh-clause attachment. Since incorrect ppattachment has a direct consequence on Machine Translation, one interesting analysis could be to use pp-attachments from our system and check for improvement in the quality of translation."}], "references": [{"title": "Improving Parsing and PP Attachment Performance with Sense Information", "author": ["Eneko Agirre", "Timothy Baldwin", "David Martinez."], "venue": "ACL. 317\u201332. Citeseer.", "citeRegEx": "Agirre et al\\.,? 2008", "shortCiteRegEx": "Agirre et al\\.", "year": 2008}, {"title": "A multi-representational and multi-layered treebank for hindi/urdu", "author": ["Rajesh Bhatt", "Bhuvana Narasimhan", "Martha Palmer", "Owen Rambow", "Dipti Mishra Sharma", "Fei Xia."], "venue": "Proceedings of the Third Linguistic Annotation Workshop. 186-189. Associa-", "citeRegEx": "Bhatt et al\\.,? 2009", "shortCiteRegEx": "Bhatt et al\\.", "year": 2009}, {"title": "A rule-based approach to prepositional phrase attachment disambiguation", "author": ["Eric Brill", "Philip Resnik."], "venue": "Proceedings of the 15th conference on Computational linguistics-Volume 2. 1198\u20131204. Association for Computational Linguistics.", "citeRegEx": "Brill and Resnik.,? 1994", "shortCiteRegEx": "Brill and Resnik.", "year": 1994}, {"title": "Building a large annotated corpus of English: The Penn Treebank", "author": ["Mitchell P Marcus", "Mary Ann Marcinkiewicz", "Beatrice Santorini."], "venue": "Computational Linguistics. 19(2):313-330. MIT Press.", "citeRegEx": "Marcus et al\\.,? 1993", "shortCiteRegEx": "Marcus et al\\.", "year": 1993}, {"title": "A Flexible Unsupervised PP-Attachment Method Using Semantic Information", "author": ["Srinivas Medimi", "Pushpak Bhattacharyya."], "venue": "IJCAI. 1677\u20131682.", "citeRegEx": "Medimi and Bhattacharyya.,? 2007", "shortCiteRegEx": "Medimi and Bhattacharyya.", "year": 2007}, {"title": "Multilingual dependency analysis with a two-stage discriminative parser", "author": ["Ryan McDonald", "Kevin Lerman", "Fernando Pereira."], "venue": "Proceedings of the Tenth Conference on Computational Natural Language Learning. 216-220. Association for Compu-", "citeRegEx": "McDonald et al\\.,? 2009", "shortCiteRegEx": "McDonald et al\\.", "year": 2009}, {"title": "A Systematic Comparison of Various Statistical Alignment Models", "author": ["Franz Josef Och", "Hermann Ney."], "venue": "Computational Linguistics. 29(1):19-51.", "citeRegEx": "Och and Ney.,? 2003", "shortCiteRegEx": "Och and Ney.", "year": 2003}, {"title": "PPattachment disambiguation using large context", "author": ["Marian Olteanu", "Dan Moldovan."], "venue": "Proceedings of the Conference on Human Language Technology and Empirical Methods in Natural Language Processing. 273\u2013280. Association for Com-", "citeRegEx": "Olteanu and Moldovan.,? 2005", "shortCiteRegEx": "Olteanu and Moldovan.", "year": 2005}, {"title": "A maximum entropy model for prepositional phrase attachment", "author": ["Adwait Ratnaparkhi", "Jeff Reynar", "Salim Roukos."], "venue": "Proceedings of the workshop on Human Language Technology. 250\u2013255. Association for Computational Linguistics.", "citeRegEx": "Ratnaparkhi et al\\.,? 1994", "shortCiteRegEx": "Ratnaparkhi et al\\.", "year": 1994}, {"title": "Cross Language POS Taggers (and other Tools) for Indian Languages: An Experiment with Kannada using Telugu Resources", "author": ["Shiva Reddy", "Serge Sharoff."], "venue": "Proceedings of the Fifth International Workshop On Cross Lingual Information Ac-", "citeRegEx": "Reddy and Sharoff.,? 2011", "shortCiteRegEx": "Reddy and Sharoff.", "year": 2011}, {"title": "A tutorial on dual decomposition and Lagrangian relaxation for inference in natural language processing", "author": ["Alexander M. Rush", "Michael Collins."], "venue": "Journal of Artificial Intelligence Research.", "citeRegEx": "Rush and Collins.,? 2012", "shortCiteRegEx": "Rush and Collins.", "year": 2012}, {"title": "Disambiguation of English PP attachment using multilingual aligned data", "author": ["Lee Schwartz", "Takako Aikawa", "Chris Quirk."], "venue": "Proceedings of MT Summit IX Citeseer.", "citeRegEx": "Schwartz et al\\.,? 2003", "shortCiteRegEx": "Schwartz et al\\.", "year": 2003}], "referenceMentions": [{"referenceID": 6, "context": "Ratnaparkhi et al. (1994) use a Maximum Entropy Model for solving the PP-attachment decision.", "startOffset": 0, "endOffset": 26}, {"referenceID": 6, "context": "Ratnaparkhi et al. (1994) use a Maximum Entropy Model for solving the PP-attachment decision. Schwartz et al. (2003) propose an unsupervised approach for solving PP attachment using multilingual aligned data.", "startOffset": 0, "endOffset": 117}, {"referenceID": 2, "context": "Brill and Resnik (1994) discuss a transformation-based rule derivation method for PP-attachment disambiguation.", "startOffset": 0, "endOffset": 24}, {"referenceID": 2, "context": "Brill and Resnik (1994) discuss a transformation-based rule derivation method for PP-attachment disambiguation. It is a simple learning algorithm which derives a set of transformation rules from training corpus, which are then used for solving the PPattachment problem. Stetina and Nagao (1997) make use of the semantic dictionary to solve the problem of disambiguating PP attachments.", "startOffset": 0, "endOffset": 295}, {"referenceID": 2, "context": "Brill and Resnik (1994) discuss a transformation-based rule derivation method for PP-attachment disambiguation. It is a simple learning algorithm which derives a set of transformation rules from training corpus, which are then used for solving the PPattachment problem. Stetina and Nagao (1997) make use of the semantic dictionary to solve the problem of disambiguating PP attachments. Their work describes use of word sense disambiguation (WSD) for both supervised and unsupervised techniques. Agirre (2008) and Medimi (2007) have used WSD-based strategies in different capacities to solve the problem of PP-attachment.", "startOffset": 0, "endOffset": 509}, {"referenceID": 2, "context": "Brill and Resnik (1994) discuss a transformation-based rule derivation method for PP-attachment disambiguation. It is a simple learning algorithm which derives a set of transformation rules from training corpus, which are then used for solving the PPattachment problem. Stetina and Nagao (1997) make use of the semantic dictionary to solve the problem of disambiguating PP attachments. Their work describes use of word sense disambiguation (WSD) for both supervised and unsupervised techniques. Agirre (2008) and Medimi (2007) have used WSD-based strategies in different capacities to solve the problem of PP-attachment.", "startOffset": 0, "endOffset": 527}, {"referenceID": 2, "context": "Brill and Resnik (1994) discuss a transformation-based rule derivation method for PP-attachment disambiguation. It is a simple learning algorithm which derives a set of transformation rules from training corpus, which are then used for solving the PPattachment problem. Stetina and Nagao (1997) make use of the semantic dictionary to solve the problem of disambiguating PP attachments. Their work describes use of word sense disambiguation (WSD) for both supervised and unsupervised techniques. Agirre (2008) and Medimi (2007) have used WSD-based strategies in different capacities to solve the problem of PP-attachment. Olteanu and Moldovan (2005) have attempted to solve the pp-attachment problem as a classification problem of attachment either to the preceding verb or the noun, and have used Support Vector Machines (SVMs) that use complex syntactic and semantic features.", "startOffset": 0, "endOffset": 649}, {"referenceID": 10, "context": "Dual decomposition, or more generally, Lagrangian Relaxation, is a classical method for combinatorial optimization and has been applied to several inference problems in NLP (Rush and Collins, 2012).", "startOffset": 173, "endOffset": 197}, {"referenceID": 1, "context": ", 2006) by a part of the the Hindi Dependency Treebank data (18708 sentences) from IIIT-Hyderabad (Bhatt et al., 2009).", "startOffset": 98, "endOffset": 118}, {"referenceID": 9, "context": ", 2003) for English and using the Hindi POS Tagger (Reddy and Sharoff, 2011) from IIIT-Hyderabad for Hindi.", "startOffset": 51, "endOffset": 76}, {"referenceID": 6, "context": "Also, for getting word alignments, we have used GIZA++ (Och and Ney, 2003), which again has scope for errors.", "startOffset": 55, "endOffset": 74}], "year": 2016, "abstractText": "In this paper, we attempt to solve the problem of Prepositional Phrase (PP) attachments in English. The motivation for the work comes from NLP applications like Machine Translation, for which, getting the correct attachment of prepositions is very crucial. The idea is to correct the PPattachments for a sentence with the help of alignments from parallel data in another language. The novelty of our work lies in the formulation of the problem into a dual decomposition based algorithm that enforces agreement between the parse trees from two languages as a constraint. Experiments were performed on the EnglishHindi language pair and the performance improved by 10% over the baseline, where the baseline is the attachment predicted by the MSTParser model trained for English.", "creator": "TeX"}}}