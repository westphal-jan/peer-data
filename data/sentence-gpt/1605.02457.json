{"id": "1605.02457", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "9-May-2016", "title": "The Controlled Natural Language of Randall Munroe's Thing Explainer", "abstract": "It is rare that texts or entire books written in a Controlled Natural Language (CNL) become very popular, but exactly this has happened with a book that has been published last year. Randall Munroe's Thing Explainer uses only the 1'000 most often used words of the English language together with drawn pictures to explain complicated things such as nuclear reactors, jet engines, the solar system, and dishwashers. This restricted language is a very interesting new case for the CNL community. I describe here its place in the context of existing approaches on Controlled Natural Languages, and I provide a first analysis from a scientific perspective, covering the word production rules and word distributions.\n\nThe key to this work is not to put too much emphasis on \"natural languages\", but rather to give a good sense of what exactly makes a language such a powerful language. I'll start with the first part, the \"tutorial\", in which I'm able to get a very detailed understanding of all the common words used in English. It's a very important tool, but I would be keen to get an understanding of some of the concepts involved and how they're related to other languages.\nHere's the main thing to know about the language:\n- the word is spoken to us very easily (like \"a man\")\n- the word is spoken to us very easily (like \"a man\") \"tutorial\" is given in an English language like \"a man\" etc.\n- the word is spoken to us very easily (like \"a man\") \"tutorial\" is given in an English language like \"a man\" etc. A new method of writing is to use some of the most common expressions of the language that you see at the beginning of the page.\n- the word is spoken to us very easily (like \"a man\") \"tutorial\" is given in an English language like \"a man\" etc. A new method of writing is to use some of the most common expressions of the language that you see at the beginning of the page.\n- the word is spoken to us very easily (like \"a man\")\n- the word is spoken to us very easily (like \"a man\") \"tutorial\" is given in an English language like \"a man\" etc. A new method of writing is to use some of the most common expressions of the language that you see at the beginning of the page. Some words you see at the beginning of the page. Some words you see at the beginning of the", "histories": [["v1", "Mon, 9 May 2016 07:48:40 GMT  (41kb,D)", "http://arxiv.org/abs/1605.02457v1", null]], "reviews": [], "SUBJECTS": "cs.CL", "authors": ["tobias kuhn"], "accepted": false, "id": "1605.02457"}, "pdf": {"name": "1605.02457.pdf", "metadata": {"source": "CRF", "title": "The Controlled Natural Language of Randall Munroe\u2019s Thing Explainer", "authors": ["Tobias Kuhn"], "emails": ["kuhntobias@gmail.com"], "sections": [{"heading": "1 Introduction", "text": "The recent book Thing Explainer: Complicated Stuff in Simple Words [12] by Randall Munroe (who is most well-known for his xkcd webcomics) is a very interesting case for the research field of Controlled Natural Languages (CNL) [11]. It is \u201ca book of pictures and simple words [...] using only the ten hundred words in our language that people use the most\u201d [12] and it is both, fun and totally serious. The quote is from the introduction of the book, and therefore it is itself written in this language of only the 1\u2019000 most commonly used English words (and so is, of course, the title of the book). The following paragraph is another example from the section about nuclear power plants, explaining radioactivity:\nThe special heat is made when tiny pieces of the metal break down. This lets out a lot of heat, far more than any normal fire could. But for many kinds of metal, it happens very slowly. A piece of metal as old as the Earth might be only half broken down by now. [12]\nThe book has attracted substantial popular interest and press coverage, probably more so than any other book written in a Controlled Natural Language in the recent past, or possibly ever. It has received very positive reviews from prestigious sources such as The New York Times [3], The Guardian [1] (\u201cAt some points, this produces passages of such startling clarity that one forgets there was ever anything difficult to understand about these phenomena.\u201d), and Bill Gates [8] (\u201ca brilliant concept\u201d), in addition to an interview in New Scientist [10]. But\nar X\niv :1\n60 5.\n02 45\n7v 1\n[ cs\n.C L\n] 9\nM ay\n2 01\narguably the most flattering review is the one that appeared in The Huffington Post [9], because the journalist himself used the book\u2019s controlled language to write the entire review in it! (\u201cSo I thought I\u2019d try to tell you a little about this new book the same way, using just those few words.\u201d) The first edition consisted of 300\u2019000 printed copies [3], 34\u2019000 of which were sold in the first week alone,1 and at the time of writing the book is in the top 20 of best selling books at Amazon in the category Science & Math.2 This popularity alone makes it an interesting and important CNL to have a closer look at.\nThe language of Thing Explainer is also interesting because of its intriguingly simple restriction applied on top of the English language, namely to use only the top 1\u2019000 most often used words. This kind of simplicity is only rivaled among existing CNLs by the language E-Prime [5], whose only restriction is that the verb to be is forbidden to use. The fact that the language\u2019s restricted vocabulary is not quite as simple as it looks at first, as we will discover below, does not make the concept less intriguing. Most reviewers and readers seem to agree that Randall Munroe succeeds in proving that virtually everything can be explained in an understandable fashion with this so heavily restricted vocabulary."}, {"heading": "2 Language Analysis", "text": "Even though the book and its language have become very popular, not much has been written about the details of the language, the connection to other similar languages, and the precise rules that underlie it. Randall Munroe himself introduced the language in the book with only a few sentences. It is therefore worth taking a closer look here."}, {"heading": "2.1 Similar Languages", "text": "The new language of Thing Explainer is similar to some of the earliest Englishbased CNLs. Basic English [13] was arguably the first such language, presented in 1930. It restricts the allowed words to just 850 root words, but many variations of the language exist. The chosen words and the rules for their application are much more structured than the Thing Explainer language, however, allowing for only 18 verbs and imposing substantial restrictions on the grammatical structures within which these words can be used. In this sense, Special English [14] \u2014 arguably the second oldest English-based CNL \u2014 is more similar. It defines no grammatical restrictions and does not restrict the number of verbs so drastically. It is based on a list of 1\u2019500 words, and has been used since 1959 by the Voice of America, the official external broadcast institution of the United States. In both cases, the words on the list are carefully selected and not just chosen by their\n1 http://www.publishersweekly.com/pw/by-topic/industry-news/bookselling/ar ticle/68882-the-weekly-scorecard-tracking-unit-print-sales-for-week-e\nnding-november-29-2015.html, retrieved on 9 April 2016 2 http://www.amazon.com/Best-Sellers-Books-Science-Math/zgbs/books/75/, re-\ntrieved on 7 April 2016\nfrequency in English texts, unlike the Thing Explainer language. As another difference, Basic English and Special English define the category for the words on the list, such as noun and verb, and allow the words only to be used in the given category. Other similar languages have a more technical background, such as ASD Simplified Technical English (ASD-STE) [4], which also restricts the allowed words and grammatical structures for the aerospace domain, and there are many other similar languages [11]."}, {"heading": "2.2 Language Properties", "text": "According to the PENS classification scheme, which I proposed in my survey on the topic [11], the language of Thing Explainer has the same type as Special English, which is P1E5N5S1. This is also the type of full unrestricted English, meaning that the restrictions of the Thing Explainer language do not make it considerably different according to the dimensions of the PENS scheme: precision, expressiveness, naturalness, and simplicity. It is not considerably more precise than full English, because no semantic restrictions come with the restricted vocabulary and the grammar is not restricted at all, and therefore the vagueness and ambiguity of natural language is not significantly mitigated. In terms of expressiveness and naturalness, on the other hand, the power of full English is retained: Randall Munroe comes at least close to proving that basically everything that can be expressed in full English can be expressed in the restricted language as well, in a way that is maybe sometimes funny but always fully natural. With respect to the last dimension, the Thing Explainer language is simple when full English can be taken for granted, but it is not significantly simpler than the full language when it has to be described from scratch. Apart from Special English, other CNLs in the same PENS class are E-Prime, Plain Language, and IBM\u2019s EasyEnglish [11]."}, {"heading": "2.3 Word List", "text": "The list of 1\u2019000 words was assembled by manually merging the word frequency lists from several corpora. Randall Munroe reports it like this:\nI spent several months going back over a bunch of different lists and generating some of my own based on the Google Books corpus and even my own email inbox. Then I combined the lists and where they disagreed I just let my sense of consistency be the tie-breaker. [10]\nConjugated forms of verbs and plural forms of nouns are not listed separately but merged with the plain word form, as Randall Munroe explains: \u201cI count different word forms\u2014like \u2018talk,\u2019 \u2018talking,\u2019 and \u2018talked\u2019\u2014as one word.\u201d This does not apply though to comparative and superlative forms of adjectives (good, better, and best are all separate entries), adverb forms of adjectives (easy and easily count as two words), or pronouns (I, me, my, and mine are separate entries too). This results in a list of 998 words, which is part of the book, where the\nmissing two words are explained by the fact that \u201cthere\u2019s a pair of four-letter words that are very common, but which I left off this page since some people don\u2019t like to see them.\u201d"}, {"heading": "2.4 Word Production Rules", "text": "Now that we know how the words ended up on the list, let us have a look at how they are supposed to be used from there to write texts such as the book we discuss here. As there are no grammar restrictions, this boils down to selecting word forms from the list and applying word production rules to arrive at related word forms. Randall Munroe\u2019s own description of these production rules is very short and not very precise (the first sentence has been quoted above already):\nIn this set, I count different word forms\u2014like \u201ctalk,\u201d \u201ctalking,\u201d and \u201ctalked\u201d\u2014as one word. I also allowed most \u201cthing\u201d forms of \u201cdoing\u201d words, like \u201ctalker\u201d\u2014especially if, like \u201cgoer,\u201d it wasn\u2019t a real word but it sounded funny.\nAs this description leaves a lot of room for interpretation, we can use the corpus of word forms observed in Thing Explainer to reverse engineer the specific rules at work. Doing so, we arrive at no less than 13 rules, listed here roughly in decreasing order of how naturally they follow from the above description:\n1. The word forms on the list of the 1\u2019000 most often used words. 2. All conjugation forms of verbs on the list. This includes third singular present\n(-s), past (-ed), and infinitive from (-ing), including irregular forms. 3. Noun forms built from verbs on the list by -er, for example carrier. 4. The plural forms of nouns on the list (-s), for example things, including\nirregular forms like teeth. This rule can also be applied to the word other to produce others, even though it is not a noun. 5. Comparative (-er) and superlative forms (-est) built from adjectives on the list, for example smaller or fastest, and including irregular forms like worse. 6. Adjective forms built from nouns on the list by -y or -ful, for example pointy or colorful. (The word colorful is in fact the only one in Thing Explainer derived from this -ful production rule.) 7. Adverb forms built from adjectives on the list by -ly, for example normally. 8. Noun forms built from adjectives on the list by -ness, for example thickness. 9. Different case and possessive forms of pronouns on the list: they for them,\nus/ours from we/our, and his from he. 10. Verb forms of nouns on the list and noun forms of verbs on the list when\nthe two forms are similar but not equal, such as thought from think, and live from life, including deduced forms like thoughts and living. (These two cases are in fact the only ones observed for this rule in Thing Explainer.) 11. More basic word forms for words on the list, such as nouns from which adjectives on the list were built (person from personal) and verbs from which nouns on the list were built (build from building). (Again, these two cases are the only two observed instances of this rule.)\n12. Verb forms built from adjectives on the list, such as lower from low, including conjugated forms like lowering and lowered. (This example is again the only observed instance of the rule.) 13. Common acronyms for words on the list, such as TV for television. (This example is also the only instance.)\nIt is not completely clear though, whether some of these later rules point to mistakes rather than features. The confusion of TV and television, for example, might just be a mistake and not a feature of the language.\nEven with these rules, six words remain that are used in Thing Explainer but are not allowed according to these rules: some, mad, hat, apart, rid, and worth. It seems that the first one, some, should be on the top 1\u2019000 list, but was accidentally omitted. The omission of they from the list seems to be a similar mistake. It can be generated by rule 9 from them, but it seems unlikely that they would not by itself appear in the top 1\u2019000. The other five extra words might be explained by the fact that Randall Munroe used a kind of spell-checker while writing to help him use only listed words (\u201cAs I wrote, I had tools that would warn me if I used a word that was not on the list, like a spell-checker.\u201d [10]). This spell-checker seems to have over-generated the said words, perhaps because some of them are morphologically close to allowed words: mad to made; hat to\nhate; and rid to ride. At other points, Randall Munroe stretches the rules to the extreme. For example, the page about the US Constitution is entitled \u201cThe US\u2019s laws of the land\u201d, even though US is not on the list, but the pronoun us can be inferred from we via rule 9.\nFigures 1 and 2 show the distribution of the word forms and word occurrences, respectively, with respect to the production rules. Only about 45% of the observed word forms are identical to one on the list (i.e. rule 1). If individual word occurrences are considered, about 79% of the 51\u2019086 word tokens in Thing Explainer are directly found on the list. This difference is not surprising, considering that the most common words mostly have just one word form (the top 10 most common words in the book are the, to, of, a, it, and, in, that, this, and you). Without parsing the grammatical structure of the sentences, it is not always possible to decide which rule was applied, such as in the case of third singular verb forms being indistinguishable from the plural noun forms for words that could be nouns or verbs. Specifically, 260 word forms ending in -s have a root word that could be a noun or a verb (e.g. names), and 21 word forms ending in -er have a root word that could be a verb or an adjective (e.g. cooler). Apart from the listed word forms (rule 1), rules 2 to 4 are most frequently used.\nFrequency distribution of non\u2212lemmatized terms\nFrequency distribution of lemmatized terms\nAs a further note, Arabic numerals were not considered for this analysis. It is not clear whether Randall Munroe wanted them to be part of the language or not. He used them only to refer to page numbers, except for two occurrences of 300 in the phrase \u201c300 years ago\u201d, which he could have written out as \u201cthree hundred,\u201d as he did in many other places."}, {"heading": "2.5 Word Distribution", "text": "Finally, we can have a look at the word frequency distribution of word forms as they are observed in the book and \u201clemmatized\u201d words as they appear on the list. We can check whether they follow a power law distribution (Zipf\u2019s law) as closely as other types of texts [6]. There is no obvious reason a priori why a text in a CNL has to follow the same distribution as an unrestricted one, but it would not be surprising either.\nThe left part of Figure 3 shows that the distribution of word occurrences follows indeed quite closely a distribution of the kind of a power law, which can be seen by the nearly straight line on the log-log plot. Still the line is curved more than other such word distributions [6], and therefore tends a bit towards a \u201cnormal\u201d exponential distribution and away from a pure power law. This effect is even more pronounced in the lemmatized case, as shown on the right hand side part of Figure 3. For texts in unrestricted language, it has been shown that the lemmatized distribution is normally very similar to the one of plain word forms [7]. Still, both distributions are significantly better explained by a power law distribution than an exponential one (with p-values of 0.022 and 0.017, respectively). We can hypothesize that such kinds of CNL texts in general\nmitigate the power law effect as compared to texts in full language, but we cannot make any conclusive statement here."}, {"heading": "3 Methods", "text": "For the analyses presented above, the text is extracted from an electronic version of the book (excluding introduction pages and word list). The book also contains hand written parts, which are not covered. Then all characters except letters, hyphens, and apostrophes are dropped; letters are transformed to lower case; some text extraction errors in the form of missing and extra blank spaces are fixed; words are de-hyphenated; contracted words like don\u2019t are expanded; an is normalized to a; Saxon genitive markers \u2019s are dropped; the text is tokenized at white spaces; and compound words are split (if the compounds are recognized words). The resulting list of tokens then serves as the input for the analyses. Furthermore, WordNet is used to detect the categories of words and to lemmatize irregular forms. For the power law analysis, the Python package powerlaw [2] is used."}, {"heading": "4 Discussion", "text": "While the topics covered by Thing Explainer are entirely serious and the book attempts and (I think) succeeds in seriously conveying complex topics in a highly understandable fashion, the book is also fun and the result of a challenge of the sort how far can we go. Randall Munroe admits in the book that \u201cIn some places, I didn\u2019t use words even when they were allowed. I could have said \u2018ship,\u2019 but I stuck to \u2018boat\u2019 because \u2018space boat\u2019 makes me laugh.\u201d At another place, he writes \u201clight drink that wakes you up\u201d and \u201cdark drink that wakes you up,\u201d even though both, tea and coffee, are on the list. On the other hand, there are a number of simple and important words that are not on the list. Randall Munroe reports: \u201cI could have made it easier for myself. There are a few words I was disappointed didn\u2019t make the cut. The biggest omission was a synonym for \u2018rope\u2019 or \u2018string\u2019. [...] the only word I had was \u2018line\u2019. This fits in some contexts, but has so many other meanings that it was hard to work with.\u201d [10] Other examples where the omission of a word rather leads to confusion than simplification include \u201cthe one after eight\u201d for nine, \u201cwhite stuff, like what we put on food to make it better\u201d for salt, and \u201cdirt branch\u201d for root, apart from the omission of proper names to refer to things like countries or planets. This seems to point to a general problem of such languages with a heavily restricted vocabulary: Writers are forced to circumscribe existing concepts instead of naming them or to involve rough analogies, which can lead to a language that even less precise than full natural language.\nThese deficiencies could be accounted for to make the language even more useful \u2014 at the expense of some of the funniness \u2014 by increasing the number of words from 1\u2019000 to, perhaps, 1\u2019500 (like Special English) or even 2\u2019000 or 3\u2019000, or by selecting the words manually (again like Special English) instead of being\nmainly led by their frequency. There is also a slight inconsistency with respect to how the list of 1\u2019000 words is generated and how it is used. Comparative and superlative forms of adjectives count as separate words when the list is defined, but then these forms can be used in the text even if only the plain form appears on the list. The same applies to adverb forms of adjectives built by -ly and pronouns. Normalizing them as well when the list is generated would free some slots for additional words within the limit of 1\u2019000 words.\nIn general, however, Thing Explainer and its language seem to be a huge success, and this success might yield momentum to the general concept of Controlled Natural Language and existing approaches in this field."}], "references": [{"title": "Thing explainer: Complicated stuff in simple words by Randall Munroe \u2014 funny, precise and beautifully designed", "author": ["N. Alderman"], "venue": "http: //www.theguardian.com/books/2015/dec/17/thing-explainer-complicated -stuff-simple-words-randall-munroe,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2015}, {"title": "powerlaw: a Python package for analysis of heavy-tailed distributions", "author": ["J. Alstott", "E. Bullmore", "D. Plenz"], "venue": "PloS one,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2014}, {"title": "Randall Munroe explains it all for us", "author": ["A. Alter"], "venue": "http://www.nytimes.com/2015/11/ 24/books/randall-munroe-explains-it-all-for-us.html,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2015}, {"title": "A linguistic note: Writing in E-prime", "author": ["D.D. Bourland"], "venue": "General Semantics Bulletin,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 1965}, {"title": "Power-law distributions in empirical data", "author": ["A. Clauset", "C.R. Shalizi", "M.E. Newman"], "venue": "SIAM review,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2009}, {"title": "Zipfs law for word frequencies: Word forms versus lemmas in long texts", "author": ["A. Corral", "G. Boleda", "R. Ferrer-i Cancho"], "venue": "PLoS ONE,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2015}, {"title": "A basic guide for curious minds", "author": ["B. Gates"], "venue": "https://www.gatesnotes.com/Books/T hing-Explainer,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2015}, {"title": "thing explainer\u2019 \u2014 a review of Randall Munroes new book (using the ten hundred most common words)", "author": ["P.H. Gleick"], "venue": "http://www.huffingtonpost.com/peter-h -gleick/thing-explainer---a-revie b 8650772.html,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2015}, {"title": "It\u2019s not a rocket it\u2019s an up goer", "author": ["D. Heaven"], "venue": "New Scientist,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2015}, {"title": "A survey and classification of controlled natural languages", "author": ["T. Kuhn"], "venue": "Computational Linguistics,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2014}, {"title": "Thing Explainer \u2014 Complicated Stuff in Simple Words", "author": ["R. Munroe"], "venue": "Houghton Mifflin Harcourt,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2015}, {"title": "Basic English: a general introduction with rules and grammar", "author": ["C.K. Ogden"], "venue": "Paul Treber & Co., London,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 1930}], "referenceMentions": [{"referenceID": 10, "context": "The recent book Thing Explainer: Complicated Stuff in Simple Words [12] by Randall Munroe (who is most well-known for his xkcd webcomics) is a very interesting case for the research field of Controlled Natural Languages (CNL) [11].", "startOffset": 67, "endOffset": 71}, {"referenceID": 9, "context": "The recent book Thing Explainer: Complicated Stuff in Simple Words [12] by Randall Munroe (who is most well-known for his xkcd webcomics) is a very interesting case for the research field of Controlled Natural Languages (CNL) [11].", "startOffset": 226, "endOffset": 230}, {"referenceID": 10, "context": "] using only the ten hundred words in our language that people use the most\u201d [12] and it is both, fun and totally serious.", "startOffset": 77, "endOffset": 81}, {"referenceID": 10, "context": "[12]", "startOffset": 0, "endOffset": 4}, {"referenceID": 2, "context": "It has received very positive reviews from prestigious sources such as The New York Times [3], The Guardian [1] (\u201cAt some points, this produces passages of such startling clarity that one forgets there was ever anything difficult to understand about these phenomena.", "startOffset": 90, "endOffset": 93}, {"referenceID": 0, "context": "It has received very positive reviews from prestigious sources such as The New York Times [3], The Guardian [1] (\u201cAt some points, this produces passages of such startling clarity that one forgets there was ever anything difficult to understand about these phenomena.", "startOffset": 108, "endOffset": 111}, {"referenceID": 6, "context": "\u201d), and Bill Gates [8] (\u201ca brilliant concept\u201d), in addition to an interview in New Scientist [10].", "startOffset": 19, "endOffset": 22}, {"referenceID": 8, "context": "\u201d), and Bill Gates [8] (\u201ca brilliant concept\u201d), in addition to an interview in New Scientist [10].", "startOffset": 93, "endOffset": 97}, {"referenceID": 7, "context": "arguably the most flattering review is the one that appeared in The Huffington Post [9], because the journalist himself used the book\u2019s controlled language to write the entire review in it! (\u201cSo I thought I\u2019d try to tell you a little about this new book the same way, using just those few words.", "startOffset": 84, "endOffset": 87}, {"referenceID": 2, "context": "\u201d) The first edition consisted of 300\u2019000 printed copies [3], 34\u2019000 of which were sold in the first week alone, and at the time of writing the book is in the top 20 of best selling books at Amazon in the category Science & Math.", "startOffset": 57, "endOffset": 60}, {"referenceID": 3, "context": "This kind of simplicity is only rivaled among existing CNLs by the language E-Prime [5], whose only restriction is that the verb to be is forbidden to use.", "startOffset": 84, "endOffset": 87}, {"referenceID": 11, "context": "Basic English [13] was arguably the first such language, presented in 1930.", "startOffset": 14, "endOffset": 18}, {"referenceID": 9, "context": "Other similar languages have a more technical background, such as ASD Simplified Technical English (ASD-STE) [4], which also restricts the allowed words and grammatical structures for the aerospace domain, and there are many other similar languages [11].", "startOffset": 249, "endOffset": 253}, {"referenceID": 9, "context": "According to the PENS classification scheme, which I proposed in my survey on the topic [11], the language of Thing Explainer has the same type as Special English, which is PENS.", "startOffset": 88, "endOffset": 92}, {"referenceID": 9, "context": "Apart from Special English, other CNLs in the same PENS class are E-Prime, Plain Language, and IBM\u2019s EasyEnglish [11].", "startOffset": 113, "endOffset": 117}, {"referenceID": 8, "context": "[10]", "startOffset": 0, "endOffset": 4}, {"referenceID": 8, "context": "\u201d [10]).", "startOffset": 2, "endOffset": 6}, {"referenceID": 4, "context": "We can check whether they follow a power law distribution (Zipf\u2019s law) as closely as other types of texts [6].", "startOffset": 106, "endOffset": 109}, {"referenceID": 4, "context": "Still the line is curved more than other such word distributions [6], and therefore tends a bit towards a \u201cnormal\u201d exponential distribution and away from a pure power law.", "startOffset": 65, "endOffset": 68}, {"referenceID": 5, "context": "For texts in unrestricted language, it has been shown that the lemmatized distribution is normally very similar to the one of plain word forms [7].", "startOffset": 143, "endOffset": 146}, {"referenceID": 1, "context": "For the power law analysis, the Python package powerlaw [2] is used.", "startOffset": 56, "endOffset": 59}, {"referenceID": 8, "context": "\u201d [10] Other examples where the omission of a word rather leads to confusion than simplification include \u201cthe one after eight\u201d for nine, \u201cwhite stuff, like what we put on food to make it better\u201d for salt, and \u201cdirt branch\u201d for root, apart from the omission of proper names to refer to things like countries or planets.", "startOffset": 2, "endOffset": 6}], "year": 2016, "abstractText": "It is rare that texts or entire books written in a Controlled Natural Language (CNL) become very popular, but exactly this has happened with a book that has been published last year. Randall Munroe\u2019s Thing Explainer uses only the 1\u2019000 most often used words of the English language together with drawn pictures to explain complicated things such as nuclear reactors, jet engines, the solar system, and dishwashers. This restricted language is a very interesting new case for the CNL community. I describe here its place in the context of existing approaches on Controlled Natural Languages, and I provide a first analysis from a scientific perspective, covering the word production rules and word distributions.", "creator": "LaTeX with hyperref package"}}}