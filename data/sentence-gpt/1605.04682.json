{"id": "1605.04682", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "16-May-2016", "title": "High-Performance Computing for Scheduling Decision Support: A Parallel Depth-First Search Heuristic", "abstract": "Many academic disciplines - including information systems, computer science, and operations management - face scheduling problems as important decision making tasks. Since many scheduling problems are NP-hard in the strong sense, there is a need for developing solution heuristics. For scheduling problems with setup times on unrelated parallel machines, there is limited research on solution methods and to the best of our knowledge, parallel computer architectures have not yet been taken advantage of. In particular, most of the research on solution systems has focused on solutions that have a common common origin and design. This work is very valuable for the research of the field.\n\n\n\n\nThe purpose of this study is to determine whether a computer with a single processor can solve any of the two-step tasking tasks described below. In this paper, we focus on solving problem problems in parallel, and use a technique similar to a C-based problem solving system in the form of a parallel computer, that is parallel and can be distributed.\nUsing a parallel system\nIt is important to note that if we were to choose a single processor that handles a problem as a single processing system, we would likely be relying on multiple CPUs that handle all of the tasks of the two-step tasking tasking tasking tasking tasking tasking tasking tasking tasking tasking tasking tasking tasking tasking tasking tasking tasking tasking tasking tasking tasking tasking tasking tasking tasking tasking tasking tasking tasking tasking tasking tasking tasking tasking tasking tasking tasking tasking tasking tasking tasking tasking tasking tasking tasking tasking tasking tasking tasking tasking tasking tasking tasking tasking tasking tasking tasking tasking tasking tasking tasking tasking tasking tasking tasking tasking tasking tasking tasking tasking tasking tasking tasking tasking tasking tasking tasking tasking tasking tasking tasking tasking tasking tasking tasking tasking tasking tasking tasking tasking tasking tasking tasking tasking tasking tasking tasking tasking tasking tasking tasking tasking tasking tasking tasking tasking tasking tasking tasking tasking tasking tasking tasking tasking tasking tasking tasking tasking tasking tasking tasking tasking tasking tasking tasking tasking tasking tasking tasking tasking tasking tasking tasking task", "histories": [["v1", "Mon, 16 May 2016 09:11:08 GMT  (576kb)", "http://arxiv.org/abs/1605.04682v1", "ISBN# 978-0-646-95337-3 Presented at the Australasian Conference on Information Systems 2015 (arXiv:1605.01032)"]], "COMMENTS": "ISBN# 978-0-646-95337-3 Presented at the Australasian Conference on Information Systems 2015 (arXiv:1605.01032)", "reviews": [], "SUBJECTS": "cs.DC cs.AI", "authors": ["gerhard rauchecker", "guido schryen"], "accepted": false, "id": "1605.04682"}, "pdf": {"name": "1605.04682.pdf", "metadata": {"source": "CRF", "title": "High-Performance Computing for Scheduling Decision Support: A Parallel Depth-First Search Heuristic", "authors": ["Gerhard Rauchecker", "Guido Schryen"], "emails": ["gerhard.rauchecker@wiwi.uni-regensburg.de", "guido.schryen@wiwi.uni-regensburg.de"], "sections": [{"heading": null, "text": "Many academic disciplines - including information systems, computer science, and operations management - face scheduling problems as important decision making tasks. Since many scheduling problems are NP-hard in the strong sense, there is a need for developing solution heuristics. For scheduling problems with setup times on unrelated parallel machines, there is limited research on solution methods and to the best of our knowledge, parallel computer architectures have not yet been taken advantage of. We address this gap by proposing and implementing a new solution heuristic and by testing different parallelization strategies. In our computational experiments, we show that our heuristic calculates near-optimal solutions even for large instances and that computing time can be reduced substantially by our parallelization approach.\nKeywords scheduling, decision support, heuristic, high performance computing, parallel algorithms"}, {"heading": "1 Introduction", "text": "Scheduling problems can be found in several academic disciplines. For example, in cloud computing, applications are scheduled (Beloglazov et al. 2012; van der Meer et al. 2012; Yang et al. 2014), in energy management, enterprise resources have to be scheduled (Bodenstein et al. 2011; Brandt and Bodenstein 2012; Zhao et al. 2013), and in sports management, tournaments and leagues are scheduled (Duran et al. 2014; Nurmi et al. 2014; Su et al. 2013). In healthcare management, appointments and visits are scheduled (Mak et al. 2015; Meyer et al. 2014; Paulussen et al. 2013), in disaster management, rescue units are scheduled (Rolland et al. 2010; Schryen et al. 2015; Wex et al. 2014; Wex et al. 2011), and in information systems, scheduling systems are built (Chandra et al. 2012; Faghihi et al. 2014; Miranda et al. 2012). In computer science, software application jobs are assigned to computer processors (Li and Peng 2011; Silberschatz et al. 2013; Terekhov et al. 2014), in operations management, production jobs are scheduled on machines (Joo and Kim 2015; Mensendiek et al. 2015; Wang and Liu 2013) and workers are assigned to shifts or jobs (Cote et al. 2011; Elahipanah et al. 2013; Rauchecker et al. 2014), and in logistics, transportation scheduling problems occur (Emde and Boysen 2014; Sterzik and Kopfer 2013; Ullrich 2013).\nAs numerous scheduling problems are NP-hard (Pinedo 2012), which means that there is no algorithm that can solve the problem to optimality in polynomial time, many large real-world instances are computationally intractable due to time limitations. Thus, there is a need for heuristics which are computationally efficient. However, heuristics lead to suboptimal decisions which result in a waste of time, increased costs, and even fatalities. Therefore, it is important for solution heuristics not only to run computationally efficient but also to be effective, i.e., to find near-optimal solutions. While the effectiveness of (deterministic) heuristics is fixed by their algorithms, the efficiency can often be increased by using modern parallel hardware architectures.\nRecent developments in high performance computing (HPC) have led to a substantial increase in computing power. For example, modern PCs and even smartphones have multiple cores, which allow for parallel code execution. At the extreme, computer clusters and supercomputers, which have up to several hundreds of thousands or even several millions of cores (TOP500 2014), are pushing the boundaries of HPC. Supercomputers have shown an exponential growth in peak performance, with the Tianhe-2 (MilkyWay-2), currently the fastest supercomputer, having more than 54 PFlop/s (5.4\u00b71016\nfloating point operations per second) (TOP500 2014). However, HPC does not require access to a supercomputer; it can also be done on computing clusters, which have become commodity IT resources. For example, they are available at many universities and are provided by some cloud providers, especially by Amazon Web Services (Mauch et al. 2013). To sum up, HPC has not only become technologically feasible, but also economically affordable.\nIn this paper, we focus on a specific problem which occurs in many application domains: the parallel machine scheduling problem on unrelated machines, sequence- and machine-dependent setup times, machine eligibility restrictions, and a total weighted completion time objective function, classified by Pinedo (2012) as in the established -notation (Graham et al.\n1979) and proven to be NP-hard by Wex et al. (2014).\nFor this scheduling problem, we address two research questions:\n How can near-optimal solutions for large instances of the scheduling decision problem be found in reasonable time?\n How efficient is the application of HPC to the scheduling decision problem?\nTo answer these questions, we propose a heuristic based on an exact branch-and-price (b&p) algorithm, which was originally formulated by Lopes and de Carvalho (2007), and evaluate a parallel implementation of the heuristic on a high performance cluster. We demonstrate the efficiency of our heuristic in terms of runtime and the performance of its parallelization based on an established scalability metric. Further, we show the effectiveness of our heuristic by (1) reporting upper bounds of the gap between the (unknown) optimal solution and the heuristic solution and (2) comparing it with an established heuristic.\nThe remainder of this paper is structured as follows: We present the literature related to our research from both the scheduling and the HPC perspective in the following section. The third section outlines the mathematical model of our scheduling problem, a sophisticated branch-and-price algorithm based heuristic, and our techniques to develop a parallel implementation of the heuristic. In the fourth section, we present our computational experiments before presenting and discussing our results in section five and closing the article with a conclusion."}, {"heading": "2 Literature Review", "text": "In this section, we present the relevant literature for our approach from different perspectives. We outline achievements and limitations of existing works in each subsection, which leads to formulating the research questions proposed in the introduction."}, {"heading": "2.1 Scheduling Decision Support", "text": "Scheduling problems appear in many forms and have attracted thousands of research papers which deal with different solution methods to support decision making in real-world settings. In order to structure this large body of research, several comprehensive literature reviews have been conducted. In their well-established surveys, Allahverdi et al. (1999; 2008) classify scheduling problems into those which account for setup times (costs) and those which do not. Problems of the former type are further classified along the dimensions single machine/parallel machines, batch/non-batch and sequencedependent/sequence-independent setup times. Using this classification, the scheduling problem , being considered in this paper, is a generalization of the problem class parallel-\nmachine scheduling on unrelated machines, non-batch sequence-dependent setup times, and a total weighted completion time objective function. To be more precise, the problem class formulated in the literature is more restrictive than our problem ( ) in the sense that, in the former\nproblem class, setup times are machine-independent and each machine is capable of processing each job."}, {"heading": "2.2 Exact Algorithms", "text": "Regarding the NP-hard scheduling problem and related types of problems, there\nare only a few research papers that present exact solution algorithms. The survey of Li and Yang (2009) lists two articles with exact solution algorithms for the problem (which does not\naccount for setup times). The algorithms are capable of solving small instances with 25 jobs and 2 machines in less than 15 minutes (Azizoglu and Kirca 1999) and medium-sized instances with 100 jobs and 20 machines in less than one hour (Chen and Powell 1999). Lopes and de Carvalho (2007)\npresented a b&p strategy for the parallel machine scheduling problem on unrelated\nmachines with sequence- (but not machine-) dependent setup times, release dates, due dates, and a total weighted tardiness objective function. Their algorithm is capable of solving instances with 150 jobs and 50 machines in less than one hour.\nAnother approach is to model our scheduling problem as a quadratic binary program and to have it solved using off-the-shelf optimization software, such as GUROBI or CPLEX. However, computational studies indicate that this strategy is inefficient as it fails to compute optimal solutions for small-sized instances consisting of 40 jobs and 10 machines within several hours (Schryen et al. 2015).\nIn summary, exact algorithms for problems similar to , such as and\n, have been scarcely addressed in the literature and are not capable of solving large\ninstance sizes in reasonable time."}, {"heading": "2.3 Heuristics", "text": "Regarding parallel machine scheduling on unrelated machines with non-batch sequence-dependent setup times, there are only a few publications that develop solution heuristics (Lin and Ying 2014). Kim et al. (2002) and Low (2005) use Simulated Annealing to minimize the total tardiness and the total flow time, while Vallada and Ruiz (2011) minimize the makespan using a genetic algorithm. A Tabu Search to minimize total tardiness, total weighted tardiness, maximum tardiness, and maximum lateness has been investigated by Chen (2006), Chen and Wu (2006), Kim and Shin (2003), and Logendran et al. (2007). Rabadi et al. (2006) introduced a Randomized Priority Search metaheuristic to minimize the makespan while de Paula et al. (2007) presented a Variable Neighborhood Search to minimize the sum of both makespan and total weighted tardiness. Chen (2005), Wex et al. (2014), and Weng et al. (2001) developed problem-specific heuristics that minimize the total weighted completion time and the makespan.\nFor the parallel machine scheduling problem on unrelated machines with a total weighted completion time objective function, there are some approximation algorithms which are based on model relaxations and give a theoretical worst-case performance (see Li and Yang (2009) for an overview). However, these theoretical bounds are not promising for practical contexts as they are not very tight. Tabu search and genetic algorithms are used by Lin et al. (2011) and Vredeveld and Hurkens (2002) while Weng et al. (2001) and Wex et al. (2014) develop problem-specific heuristics. A good overview is further provided by Rodriguez et al. (2013)."}, {"heading": "2.4 High Performance Computing", "text": "HPC is used in many scientific disciplines, including biology, chemistry, physics, geology, weather forecasting, aerodynamic research, and computer science (Bell and Gray 2002; Vecchiola et al. 2009). But to the best of our knowledge, opportunities for modern parallel hardware architectures have been largely ignored in the scheduling literature.\nAlthough HPC has become an integral part of several academic disciplines over the last decades, there is no commonly agreed definition of what HPC actually is. HPC implicitly refers to the use of parallel hardware architectures, which consist of a usually large set of interconnected multi-core processors (nodes). The particular relevance of parallel computing architectures lies in the limitation of speed improvement on a single core due to technological reasons (Hager and Wellein 2010).\nAt the extreme of HPC, supercomputers are used, which perform at or near the currently highest operational rate for computers. Today\u2019s 50 fastest supercomputers operate with more than 1 TFlop/s (TOP500 2014).\nParallel architectures provide a high potential to improve execution times of parallelizable algorithms. Dominating parallelization designs are OpenMP and MPI, with OpenMP allowing for intra-node shared-memory parallelization and MPI providing for inter-node distributed-memory network parallelization (MPI 2012; OpenMP 2013). OpenMP is used to execute a program using multiple threads (on multiple cores) and MPI is used to execute a program using multiple processes (on multiple processors). Both parallelization paradigms can be combined straightforwardly."}, {"heading": "3 Scheduling Model and Parallel Depth-First Search Heuristic", "text": "In this section, we formulate the scheduling problem by means of a mathematical optimization model and we present a heuristic to obtain high-quality solutions. Finally, we present our parallelization concept for the proposed heuristic."}, {"heading": "3.1 Problem Formulation", "text": "In this subsection, we provide a mathematical formulation of our scheduling problem . It comprises jobs which have to be processed on exactly one machine . Let\nbe the set of all feasible schedules on machine , be the number of times job is included in\nschedule , and be the total weighted completion time of schedule on machine . A decision\nvariable is if schedule is used on machine and otherwise. The scheduling problem can then be formulated by the following binary linear optimization model.\nDifferent formulations are proposed in the literature, see Li and Yang (2009) for an overview; the chosen one has proven to be particularly suitable for branch-and-price algorithms (Chen and Powell 1999; Chen and Powell 2003; Lopes and de Carvalho 2007; van den Akker et al. 1999)."}, {"heading": "3.2 Depth-First Search Heuristic", "text": "In this subsection, we describe a depth-first search (DFS) heuristic based on a branch-and-price (b&p) algorithm. A b&p algorithm is a branch-and-bound (b&b) algorithm with the special characteristic that the linear relaxation at each node of the b&b tree is solved using column generation, which was originally introduced to solve huge linear programs by Dantzig and Wolfe (1960). The original formulation of a b&p algorithm goes back to Barnhart et al. (1998).\nB&p algorithms have been established to solve unrelated parallel machine scheduling problems exactly for rather small instances (Chen and Powell 1999; Lopes and de Carvalho 2007). Existing approaches use an implementation based on a node selection strategy where the active node with the best lower bound is selected to be explored next during the b&b algorithm. The selected node is then branched into two child nodes and nodes\u2019 relaxations are solved immediately afterwards. This strategy is called eager best-first strategy (Clausen and Perregaard 1999). However, these implementations fail at solving large instances to optimality due to time limitation.\nWe adapt these algorithms by implementing a different node selection strategy - the so called lazy DFS strategy - which selects the active node with the highest depth in the b&b tree to be processed next. After solving a node\u2019s relaxation, the node is branched into two child nodes which are added to the list of active problems. We terminate the procedure when an integer optimal solution for one of the subproblems is found. An integer optimal solution of an arbitrary subproblem is always a feasible (not necessarily optimal) solution of the original problem and therefore can be used as a heuristic solution value.\nWe select the lazy DFS strategy (i.e., branching on a node after solving its relaxation) based on two premises. First, the DFS strategy quickly finds a feasible solution for (BinLP) and second, lazy DFS strategies are more suitable for parallelization than eager DFS strategies (Clausen and Perregaard 1999).\nEach node in the b&b tree is of a structure similar to (BinLP), only differing by some job ordering\nrestrictions (depending on the branching decisions) which affect only the node-specific sets . The pseudo code of our DFS heuristic is presented in Table 1.\nThe code lines 2, 3, 4, 6, 7, 10, 12, and 13 are self-evident. We briefly explain the other code lines in the following.\nThe selection of an active node in line 8 is always possible since in the case of no active nodes, an optimal solution to the original problem would have been found, which means that the code would have already terminated the while loop.\nThe column (i.e., variable) generation procedure for solving the linear relaxation of a node (lines 1 and 9) is described in the following. As step 1 of the column generation procedure, a restricted form of the linear program is solved by considering only a (typically small) feasible subset of variables and setting the remaining variables to zero. An initial feasible subset of variables is either adopted from the solution of the parent node in the b&b tree or from a solution heuristic (for the root node). As step 2 of\nthe column generation procedure, the algorithm determines whether there are any variables in the\nrelaxed linear program that have a negative reduced cost which is given by\nwhere are the dual variables corresponding to the constraints in the relaxed linear program\n(Lopes and de Carvalho 2007). If there are variables with negative reduced cost, a fixed number of them are added to the restricted problem. Steps 1 and 2 of the column generation procedure are repeated until there are no variables left with negative reduced cost. Having reached this point, the optimal solution of the current restricted problem is also optimal for the node\u2019s linear relaxation, setting all remaining variables to (Lopes and de Carvalho 2007). The problem of finding a variable with minimal reduced cost is called the pricing problem and will be discussed in the next subsection since it is highly suitable for parallelization.\nThe branching (lines 5 and 11) strategy is explained in the following. Let } be the optimal solution of the linear relaxation of the root node (line 5) or the selected node (line 11) and let denote the number of times job is processed immediately before job in schedule . Then we\ndefine the total flow of edge by\n.\nBranching on these variables has been proven to be very efficient in b&p algorithms (Chen and Powell\n1999; Chen and Powell 2003; Lopes and de Carvalho 2007). We branch on the flow variable with\nthe largest integer infeasibility, i.e., the one closest to . The branching is conducted by modifying the sets of feasible schedules in a way that, in one child node, is forced to be processed by immediately before , and in the other child node, is forbidden to be processed by immediately before (Lopes and de Carvalho 2007)."}, {"heading": "3.3 Parallelization of the DFS Heuristic", "text": "There are two possible ways to utilize parallel computing for accelerating the execution speed of the DFS heuristic. First, the major part of the solution of each single b&b node can be parallelized on single multicore processors via shared-memory programming using OpenMP. Second, concurrently active nodes in the b&b tree can be processed independently using different multicore processors.\nWe describe the solution of the pricing problems in the column generation procedure (lines 1 and 9 in Table 1) and its parallelization using OpenMP in the following. Let be an upper bound on the makespan, i.e., the time until all jobs have been processed, of an optimal solution for (BinLP). This value is unknown a priori but can be estimated efficiently (see Lopes and de Carvalho (2007) for\ndetails). For performance reasons, we allow schedules in to be cyclic, i.e., each job is allowed to be processed more than once. Note that this does not affect the DFS heuristic solution because a cyclic schedule can never be used in an integer solution of a subproblem, since one of the coefficients\nwould be larger than .\nArbitrary jobs on a machine , require a time for processing on , a setup time for processing\ndirectly after on , and have a weight . All of these parameters are assumed to be integers. We have\na set of possible predecessors of job on a machine and a fictitious job for modeling purposes.\nLet denote the minimum reduced cost of all schedules that process last and finish processing exactly at time . We initialize for all , , and for all (Lopes and de Carvalho 2007). The parallel pseudo code for the pricing problem is presented in Table 2. The omp parallel for pragmas divide the k-loop among all available threads using OpenMP.\nThe parallel pseudo code for the branching decision (code lines 5 and 11 in Table 1) is presented in Table 3.\nBoth code fragments in Table 2 and Table 3 are highly suitable for parallelization, since the work in each iteration of the k-loops can be done independently on different threads. Our pre-tests showed that the presented ordering of the for-loops and the selected parallelization strategy perform most efficient in terms of execution time since caching of data, i.e., making use of spatial and temporal data locality, is most efficient in this setting.\nIn the following, we describe our strategy to parallelize the independent processing of concurrently active nodes of the b&b tree using the distributed-memory paradigm MPI. The MPI parallelizable part of the algorithm is represented by the while loop in code lines 7 to 12 in Table 1. We use a centralized\nmaster/worker setting for our parallelization as described in Clausen and Perregaard (1999) for instance. The pseudo code for the master process is presented in Table 4.\nThe pseudo code for the worker processes is illustrated in Table 5.\nThe master process is responsible for the tree management while the worker processes perform the solutions of the nodes\u2019 relaxations - except the root node\u2019s relaxation, which is solved by the master process."}, {"heading": "4 Computational Experiments", "text": "Our experiments were conducted on a Linux-based computing cluster consisting of multiple networkconnected computing nodes. Each node is represented by a two-socket Intel Westmere X5675 sharedmemory system with 6 cores per socket and a clock speed of 3.07 GHz. This is a standard architecture in modern high performance systems (Hager and Wellein 2010). The algorithm was coded in C++ and the restricted linear programs during column generation were solved via the GUROBI 6.0 C++ API.\nWe randomly generated ten instances for each of the instance sizes 300/300, 300/150, 300/100, 300/75, 300/60, 300/45, and 300/30, with n/m representing a setting with n jobs and m machines, in order to gain insights into how the DFS heuristic performs and how the parallelization works for different ratios of n to m.\nThe processing times in our experiments are uniformly distributed over , the setup times (which are typically lower than the processing times) are uniformly distributed over }, and the weights are uniformly distributed over . We generated 20 columns in each iteration of the column generation procedure and set the probability that a machine is eligible for processing a job to 20%. Similar settings have been used in the literature (Chen and Powell 1999; Chen and Powell 2003; Lopes and de Carvalho 2007; van den Akker et al. 1999; Weng et al. 2001)."}, {"heading": "5 Results and Discussion", "text": "In this section, we present and evaluate our results. We discuss the effectiveness of the DFS heuristic and its efficiency. Finally, we present our findings about the parallel implementation."}, {"heading": "5.1 Effectiveness of the DFS Heuristic", "text": "For each instance, we calculated the solution of the DFS heuristic and of the best performing heuristic presented by Weng et al. (2001) and Wex et al. (2014) \u2013 we refer to this heuristic as SCHED \u2013 and documented execution times as well as solution quality (cf. subsection 2.3). The pseudo code of the SCHED heuristic is presented in Table 6. Let denote the set of all pairs where machine is eligible of processing job .\nThe average gaps between the DFS heuristic solutions and (1) the best lower bounds (at time of algorithm termination) and (2) the solutions of the SCHED heuristic are presented in Table 7. These measures have been used in the literature, e.g., by Wex et al. (2014) and Schryen et al. (2015), and allow for quantifying the solution quality of DFS compared to (1) optimal solutions and (2) the SCHED heuristic.\nThe gaps are in fact upper bounds on the gap between the DFS heuristic solutions and the optimal solutions. A graphic illustration is provided in Figure 1.\nWe conclude that the DFS heuristic solution values are either optimal or extremely close to the optimum as the average upper bound of the gap is not higher than 0.36% (scenario (300/45)). Even the maximum gap among all 70 tested instances was as low as 0.71%. Furthermore, the SCHED heuristic can be improved considerably by the DFS heuristic in terms of effectiveness."}, {"heading": "5.2 Efficiency of the DFS Heuristic", "text": "The DFS heuristic calculated the solutions in less than 5 minutes even in a purely serial mode of execution. The average runtimes for each ratio n/m are presented in Figure 2.\nWhile the runtimes of the DFS heuristic seem to increase super-linear, the runtimes of the SCHED heuristic were below one second in all tested instances. The super-linear increase of execution time of DFS is a disadvantage compared to SCHED. However, execution times are at an acceptable level for our tested instance sizes as the algorithm terminates within a few minutes."}, {"heading": "5.3 Impact of HPC", "text": "The parallel implementation of our algorithm was tested on different configurations \u2013 1, 6, and 12 threads on 1, 3, and 5 processes. This implementation is capable of substantially reducing runtimes for each of the instance sizes. Figure 3 depicts the decrease in execution time with an increasing number of threads on one process.\nThe effect of HPC was evaluated using an established scalability metric \u2013 the comparison of theoretical and observed parallel speedup on one process and multiple threads (Hager and Wellein 2010). Let denote the purely serial part of a program. The theoretical speedup using threads can then be calculated as\n.\nNote that\n, which is known as Amdahl\u2019s law (Amdahl 1967). Table 8 lists the theoretical\nand observed speedups for all instance sizes and shows that our parallelization achieves runtimes which are just slightly below the theoretical boundaries.\nThe theoretical speedup decreases substantially with an increasing ratio of jobs to machines. The reason for this phenomenon is the increasing part of GUROBI\u2019s execution time compared to the overall execution time. Although GUROBI is claimed to use internal parallelization, we did not observe any parallelization effects in our context. Therefore, we pinned GUROBI to a single thread and consequently added GUROBI\u2019s execution time to the serial part of the algorithm.\nOur experiments further show that average execution times decrease by up to 2% in the best case but increase by up to 106% in the worst case using three or five processes. Using multiple processes therefore does not lead to an improvement in efficiency.\nThe reason for this phenomenon is the increasing number of explored nodes using multiple processes. The MPI approach enables the parallel processing of concurrently active nodes. This effects the exploration of unattractive nodes during the b&b algorithm and thus the DFS strategy becomes less efficient in our problem setting."}, {"heading": "6 Conclusion", "text": "Many academic fields face scheduling problems as important decision making tasks. In this paper, we formulated a new heuristic for the NP-hard scheduling problem . The heuristic is\nbased on a branch-and-price algorithm and uses a lazy depth-first search strategy.\nWe showed that the proposed heuristic can solve large problem instances with 300 jobs in less than five minutes, even in serial execution of the algorithm. In addition, our heuristic returns solutions that differ only marginally from the optimal solution \u2013 0.71% in the worst of all 70 tested scenarios.\nThe solutions were compared with an established solution heuristic for and the\nresults show that this heuristic can be improved by an average 11.35% in the most difficult instance size using our approach. This leads to a high potential to save cost and time in practical applications.\nFurthermore, we implemented different parallelization strategies for our heuristic and analysed their performance. We used shared-memory programming with OpenMP for the parallelization of the pricing problems and the branching decisions. We found that this approach substantially reduces runtimes of the heuristic when using multiple threads. In addition, we tested a distributed-memory MPI approach to process concurrently active nodes in the b&b tree independently on multiple processes. However, this approach tends to increase execution times because of an increasing number of explored b&b nodes. The best hardware setup for our algorithm would therefore be a single multicore processor with a large number of cores.\nThese findings provide substantial value for both the research community and practitioners. The research community can profit from our approach since we have bridged the largely unexplored gap between using HPC and solving scheduling problems. Practitioners can also benefit from our findings as we provide an easily accessible way to determine solutions of large-sized instances in reasonable time that are substantially better \u2013 in terms of the gap to the optimal solution - than solutions generated from an established heuristic proposed in the literature.\nA limitation of our approach is the absence of real problem data. We coped with this problem by generating data sets randomly, which is a widely-used approach in the scheduling literature. However, we are in contact with emergency response organizations in order to evaluate our heuristic in realworld disaster response situations where a large number of incidents needs to be processed by rescue units. This is part of our ongoing work."}, {"heading": "7 References", "text": "Allahverdi, A., Gupta, J.N.D., and Aldowaisan, T. 1999. \"A Review of Scheduling Research Involving Setup Considerations,\" Omega (27:2), pp 219-239. Allahverdi, A., Ng, C.T., Cheng, T.C.E., and Kovalyov, M.Y. 2008. \"A Survey of Scheduling Problems with Setup Times or Costs,\" European Journal of Operational Research (187:3), pp 985-1032. Amdahl, G.M. 1967. \"Validity of the Single Processor Approach to Achieving Large Scale Computing Capabilities,\" Proceedings of the April 18-20, 1967, Spring Joint Computer Conference, pp. 483-485. Azizoglu, M., and Kirca, O. 1999. \"Scheduling Jobs on Unrelated Parallel Machines to Minimize Regular Total Cost Functions,\" IIE Transactions (31:2), pp 153-159. Barnhart, C., Johnson, E.L., Nemhauser, G.L., Savelsbergh, M.W.P., and Vance, P.H. 1998. \"Branchand-Price: Column Generation for Solving Huge Integer Programs,\" Operations Research (46:3), pp 316-329. Bell, G., and Gray, J. 2002. \"What's Next in High-Performance Computing?,\" Communications of the ACM (45:2), pp 91-95. Beloglazov, A., Abawajy, J., and Buyya, R. 2012. \"Energy-Aware Resource Allocation Heuristics for Efficient Management of Data Centers for Cloud Computing,\" Future Generation Computer Systems (28:5), pp 755-768. Bodenstein, C., Schryen, G., and Neumann, D. 2011. \"Reducing Datacenter Energy Usage through Efficient Job Allocation,\" Proceedings of the 19th European Conference on Information Systems. Brandt, T., and Bodenstein, C. 2012. \"Evaluating Scheduling Methods for Energy Cost Reduction in a Heterogeneous Data Center Environment,\" Proceedings of the 20th European Conference on Information Systems. Chandra, C., He, J., Liu, Z., and Ruohonen, T. 2012. \"Some Promising Areas for Is Research in the Healthcare Industry: Implications from a Case Study of Hospital Operation Room Scheduling,\" Proceedings of the 18th American Conference on Information Systems. Chen, J.-F. 2005. \"Unrelated Parallel Machine Scheduling with Secondary Resource Constraints,\" The International Journal of Advanced Manufacturing Technology (26:3), pp 285-292. Chen, J.-F. 2006. \"Minimization of Maximum Tardiness on Unrelated Parallel Machines with Process Restrictions and Setups,\" The International Journal of Advanced Manufacturing Technology (29:5-6), pp 557-563. Chen, J.-F., and Wu, T.-H. 2006. \"Total Tardiness Minimization on Unrelated Parallel Machine Scheduling with Auxiliary Equipment Constraints,\" Omega (34:1), pp 81-89. Chen, Z.-L., and Powell, W.B. 1999. \"Solving Parallel Machine Scheduling Problems by Column Generation,\" INFORMS Journal on Computing (11:1), pp 78-94. Chen, Z.-L., and Powell, W.B. 2003. \"Exact Algorithms for Scheduling Multiple Families of Jobs on Parallel Machines,\" Naval Research Logistics (50:7), pp 823-840. Clausen, J., and Perregaard, M. 1999. \"On the Best Search Strategy in Parallel Branch-and-Bound: Best-First Search Versus Lazy Depth-First Search,\" Annals of Operations Research (90), pp 1- 17. Cote, M.-C., Gendron, B., and Rousseau, L.-M. 2011. \"Grammar-Based Integer Programming Models for Multiactivity Shift Scheduling,\" Management Science (57:1), pp 151-163. Dantzig, G.B., and Wolfe, P. 1960. \"Decomposition Principle for Linear Programs,\" Operations Research (8:1), pp 101-111. de Paula, M.R., Ravetti, M.G., Mateus, G.R., and Pardalos, P.M. 2007. \"Solving Parallel Machines Scheduling Problems with Sequence-Dependent Setup Times Using Variable Neighbourhood Search,\" IMA Journal of Management Mathematics (18:2), pp 101-115. Duran, S., \u00d6zener, O.\u00d6., and Yakici, E. 2014. \"League Scheduling and Game Bundling in Sports Industry,\" Computers & Industrial Engineering (74), pp 92-101. Elahipanah, M., Desaulniers, G., and Lacasse-Guay, E. 2013. \"A Two-Phase MathematicalProgramming Heuristic for Flexible Assignment of Activities and Tasks to Work Shifts,\" Journal of Scheduling (16:5), pp 443-460. Emde, S., and Boysen, N. 2014. \"One-Dimensional Vehicle Scheduling with a Front-End Depot and Non-Crossing Constraints,\" OR Spectrum (36:2), pp 381-400. Faghihi, V., Reinschmidt, K.F., and Kang, J.H. 2014. \"Construction Scheduling Using Genetic Algorithm Based on Building Information Model,\" Expert Systems with Applications (41:16), pp 7565-7578.\nGraham, R.L., Lawler, E.L., Lenstra, J.K., and Rinnooy Kan, A.H.G. 1979. \"Optimization and Approximation in Deterministic Sequencing and Scheduling: A Survey,\" Annals of Discrete Mathematics (5), pp 287-326. Hager, G., and Wellein, G. 2010. Introduction to High Performance Computing for Scientists and Engineers. CRC Press. Joo, C.M., and Kim, B.S. 2015. \"Hybrid Genetic Algorithms with Dispatching Rules for Unrelated Parallel Machine Scheduling with Setup Time and Production Availability,\" Computers & Industrial Engineering (85), pp 102-109. Kim, C.O., and Shin, H.J. 2003. \"Scheduling Jobs on Parallel Machines: A Restricted Tabu Search Approach,\" The International Journal of Advanced Manufacturing Technology (22:3-4), pp 278-287. Kim, D.-W., Kim, K.-H., Jang, W., and Chen, F.F. 2002. \"Unrelated Parallel Machine Scheduling with Setup Times Using Simulated Annealing,\" Robotics and Computer-Integrated Manufacturing (18:3), pp 223-231. Li, J.-F., and Peng, J. 2011. \"Task Scheduling Algorithm Based on Improved Genetic Algorithm in Cloud Computing Environment,\" Journal of Computer Applications (31:1), pp 184-186. Li, K., and Yang, S.-l. 2009. \"Non-Identical Parallel-Machine Scheduling Research with Minimizing Total Weighted Completion Times: Models, Relaxations and Algorithms,\" Applied Mathematical Modelling (33:4), pp 2145-2158. Lin, S.-W., and Ying, K.-C. 2014. \"Abc-Based Manufacturing Scheduling for Unrelated Parallel Machines with Machine-Dependent and Job Sequence-Dependent Setup Times,\" Computers & Operations Research (51), pp 172-181. Lin, Y., Pfund, M.E., and Fowler, J.W. 2011. \"Heuristics for Minimizing Regular Performance Measures in Unrelated Parallel Machine Scheduling Problems,\" Computers & Operations Research (38:6), pp 901-916. Logendran, R., McDonell, B., and Smucker, B. 2007. \"Scheduling Unrelated Parallel Machines with Sequence-Dependent Setups,\" Computers & Operations Research (34:11), pp 3420-3438. Lopes, M.J.P., and de Carvalho, J.M.V. 2007. \"A Branch-and-Price Algorithm for Scheduling Parallel Machines with Sequence Dependent Setup Times,\" European Journal of Operational Research (176:3), pp 1508-1527. Low, C. 2005. \"Simulated Annealing Heuristic for Flow Shop Scheduling Problems with Unrelated Parallel Machines,\" Computers & Operations Research (32:8), pp 2013-2025. Mak, H.-Y., Rong, Y., and Zhang, J. 2015. \"Appointment Scheduling with Limited Distributional Information,\" Management Science (61:2), pp 316-334. Mauch, V., Kunze, M., and Hillenbrand, M. 2013. \"High Performance Cloud Computing,\" Future Generation Computer Systems (29:6), pp 1408-1416. Mensendiek, A., Gupta, J.N.D., and Herrmann, J. 2015. \"Scheduling Identical Parallel Machines with Fixed Delivery Dates to Minimize Total Tardiness,\" European Journal of Operational Research (243:2), pp 514-522. Meyer, G., Adomavicius, G., Johnson, P.E., Elidrisi, M., Rush, W.A., Sperl-Hillen, J.M., and O'Connor, P.J. 2014. \"A Machine Learning Approach to Improving Dynamic Decision Making,\" Information Systems Research (25:2), pp 239-263. Miranda, J., Rey, P.A., and Robles, J.M. 2012. \"Udpskeduler: A Web Architecture Based Decision Support System for Course and Classroom Scheduling,\" Decision Support Systems (52:2), pp 505-513. MPI. 2012. \"Mpi: A Message-Passing Interface Standard Version 3.0.\" Retrieved 30.06.2015, from http://www.mpi-forum.org/docs/mpi-3.0/mpi30-report.pdf Nurmi, K., Kyngas, J., Goossens, D., and Kyngas, N. 2014. \"Scheduling a Professional Sports League Using the Peast Algorithm,\" Proceedings of the 2014 International MultiConference of Engineers and Computer Scientists, pp. 1176-1182. OpenMP. 2013. \"Openmp Application Program Interface Version 4.0.\" Retrieved 30.06.2015, from http://www.openmp.org/mp-documents/OpenMP4.0.0.pdf Paulussen, T., Heinzl, A., and Becker, C. 2013. \"Multi-Agent Based Information Systems for Patient Coordination in Hospitals,\" Proceedings of the 34th International Conference on Information Systems. Pinedo, M.L. 2012. Scheduling: Theory, Algorithms, and Systems. Springer. Rabadi, G., Moraga, R.J., and Al-Salem, A. 2006. \"Heuristics for the Unrelated Parallel Machine\nScheduling Problem with Setup Times,\" Journal of Intelligent Manufacturing (17:1), pp 85- 97.\nRauchecker, G., Yasasin, E., and Schryen, G. 2014. \"A Decision Support System for It Security Incident Management,\" Proceedings of the 11th International Conference on Trust, Privacy, and Security in Digital Business, pp. 36-47. Rodriguez, F.J., Lozano, M., Blum, C., and Garcia-Martinez, C. 2013. \"An Iterated Greedy Algorithm for the Large-Scale Unrelated Parallel Machines Scheduling Problem,\" Computers & Operations Research (40:7), pp 1829-1841. Rolland, E., Patterson, R.A., Ward, K., and Dodin, B. 2010. \"Decision Support for Disaster Management,\" Operations Management Research (3:1-2), pp 68-79. Schryen, G., Rauchecker, G., and Comes, T. 2015. \"Resource Planning in Disaster Response,\" Business & Information Systems Engineering (57:4), pp 243-259. Silberschatz, A., Galvin, P.B., and Gagne, G. 2013. Operating System Concepts. Wiley. Sterzik, S., and Kopfer, H. 2013. \"A Tabu Search Heuristic for the Inland Container Transportation Problem,\" Computers & Operations Research (40:4), pp 953-962. Su, L.-H., Chiu, Y., and Cheng, T.C.E. 2013. \"Sports Tournament Scheduling to Determine the\nRequired Number of Venues Subject to the Minimum Timeslots under Given Formats,\" Computers & Industrial Engineering (65:2), pp 226-232.\nTerekhov, D., Down, D.G., and Beck, J.C. 2014. \"Queueing-Theoretic Approaches for Dynamic Scheduling: A Survey,\" Surveys in Operations Research and Management Science (19:2), pp 105-129. TOP500. 2014. \"Top500 Supercomputer Sites.\" Retrieved 30.06.2015, from http://www.top500.org/list/2014/11/ Ullrich, C.A. 2013. \"Integrated Machine Scheduling and Vehicle Routing with Time Windows,\" European Journal of Operational Research (227:1), pp 152-165. Vallada, E., and Ruiz, R. 2011. \"A Genetic Algorithm for the Unrelated Parallel Machine Scheduling Problem with Sequence Dependent Setup Times,\" European Journal of Operational Research (211:3), pp 612-622. van den Akker, J.M., Hoogeveen, J.A., and van de Velde, S.L. 1999. \"Parallel Machine Scheduling by Column Generation,\" Operations Research (47:6), pp 862-872. van der Meer, D., Dutta, K., and Datta, A. 2012. \"A Cost-Based Database Request Distribution Technique for Online E-Commerce Applications,\" MIS Quarterly (36:2), pp 479-507. Vecchiola, C., Pandey, S., and Buyya, R. 2009. \"High-Performance Cloud Computing: A View of Scientific Applications,\" Proceedings of the 10th International Symposium on Pervasive Systems, Algorithms, and Networks, pp. 4-16. Vredeveld, T., and Hurkens, C. 2002. \"Experimental Comparison of Approximation Algorithms for Scheduling Unrelated Parallel Machines,\" INFORMS Journal on Computing (14:2), pp 175- 189. Wang, S., and Liu, M. 2013. \"A Branch and Bound Algorithm for Single-Machine Production Scheduling Integrated with Preventive Maintenance Planning,\" International Journal of Production Research (51:3), pp 847-868. Weng, M.X., Lu, J., and Ren, H. 2001. \"Unrelated Parallel Machine Scheduling with Setup Consideration and a Total Weighted Completion Time Objective,\" International Journal of Production Economics (70:3), pp 215-226. Wex, F., Schryen, G., Feuerriegel, S., and Neumann, D. 2014. \"Emergency Response in Natural Disaster Management: Allocation and Scheduling of Rescue Units,\" European Journal of Operational Research (235:3), pp 697-708. Wex, F., Schryen, G., and Neumann, D. 2011. \"Intelligent Decision Support for Centralized Coordination During Emergency Response,\" in: Proceedings of the 8th International Conference on Information Systems for Crisis Response and Management. Yang, C.-W., Guo, J.-D., and Chi, J. 2014. \"Min-Cost with Delay Scheduling for Large Scale CloudBased Workflow Applications Platform,\" Proceedings of the 18th Pacific Asian Conference on Information Systems. Zhao, Z., Lee, W.C., Shin, Y., and Song, K.-B. 2013. \"An Optimal Power Scheduling Method for Demand Response in Home Energy Management System,\" IEEE Transactions on Smart Grid (4:3), pp 1391-1400.\nCopyright: \u00a9 2015 Gerhard Rauchecker & Guido Schryen. This is an open-access article distributed under the terms of the Creative Commons Attribution-NonCommercial 3.0 Australia License, which permits non-commercial use, distribution, and reproduction in any medium, provided the original author and ACIS are credited."}], "references": [{"title": "A Survey of Scheduling Problems", "author": ["A. Allahverdi", "C.T. Ng", "T.C.E. Cheng", "M.Y. Kovalyov"], "venue": "Setup Considerations,\" Omega", "citeRegEx": "Allahverdi et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Allahverdi et al\\.", "year": 2008}, {"title": "Scheduling Jobs on Unrelated Parallel Machines", "author": ["M. 483-485. Azizoglu", "O. Kirca"], "venue": null, "citeRegEx": "Azizoglu and Kirca,? \\Q1999\\E", "shortCiteRegEx": "Azizoglu and Kirca", "year": 1999}, {"title": "What's Next in High-Performance Computing?,\" Communications", "author": ["G. Bell", "J. Gray"], "venue": null, "citeRegEx": "Bell and Gray,? \\Q2002\\E", "shortCiteRegEx": "Bell and Gray", "year": 2002}, {"title": "Energy-Aware Resource Allocation Heuristics", "author": ["A. Beloglazov", "J. Abawajy", "R. Buyya"], "venue": null, "citeRegEx": "Beloglazov et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Beloglazov et al\\.", "year": 2012}, {"title": "Reducing Datacenter Energy Usage through", "author": ["C. Bodenstein", "G. Schryen", "D. Neumann"], "venue": null, "citeRegEx": "Bodenstein et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Bodenstein et al\\.", "year": 2011}, {"title": "Evaluating Scheduling Methods for Energy Cost Reduction", "author": ["T. Systems. Brandt", "C. Bodenstein"], "venue": null, "citeRegEx": "Brandt and Bodenstein,? \\Q2012\\E", "shortCiteRegEx": "Brandt and Bodenstein", "year": 2012}, {"title": "Some Promising Areas for Is Research", "author": ["C. Systems. Chandra", "J. He", "Z. Liu", "T. Ruohonen"], "venue": null, "citeRegEx": "Chandra et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Chandra et al\\.", "year": 2012}, {"title": "Minimization of Maximum Tardiness on Unrelated Parallel Machines with Process", "author": ["Chen", "J.-F"], "venue": "International Journal of Advanced Manufacturing Technology", "citeRegEx": "Chen and J..F.,? \\Q2006\\E", "shortCiteRegEx": "Chen and J..F.", "year": 2006}, {"title": "Total Tardiness Minimization on Unrelated Parallel Machine", "author": ["Chen", "J.-F", "Wu", "T.-H"], "venue": null, "citeRegEx": "Chen et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Chen et al\\.", "year": 2006}, {"title": "Scheduling with Auxiliary Equipment Constraints,\" Omega (34:1)", "author": ["Chen", "Z.-L", "W.B. Powell"], "venue": null, "citeRegEx": "Chen et al\\.,? \\Q1999\\E", "shortCiteRegEx": "Chen et al\\.", "year": 1999}, {"title": "Exact Algorithms for Scheduling Multiple Families of Jobs on", "author": ["Chen", "Z.-L", "W.B. Powell"], "venue": "Generation,\" INFORMS Journal on Computing", "citeRegEx": "Chen et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Chen et al\\.", "year": 2003}, {"title": "On the Best Search Strategy in Parallel Branch-and-Bound", "author": ["J. Clausen", "M. Perregaard"], "venue": "Parallel Machines,\" Naval Research Logistics", "citeRegEx": "Clausen and Perregaard,? \\Q1999\\E", "shortCiteRegEx": "Clausen and Perregaard", "year": 1999}, {"title": "Grammar-Based Integer Programming Models", "author": ["Cote", "M.-C", "B. Gendron", "Rousseau", "L.-M"], "venue": null, "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2011}, {"title": "Decomposition Principle for Linear Programs,\" Operations", "author": ["G.B. Dantzig", "P. Wolfe"], "venue": "Multiactivity Shift Scheduling,\" Management Science", "citeRegEx": "Dantzig and Wolfe,? \\Q1960\\E", "shortCiteRegEx": "Dantzig and Wolfe", "year": 1960}, {"title": "League Scheduling and Game Bundling in Sports", "author": ["S. Duran", "O.\u00d6. \u00d6zener", "E. Yakici"], "venue": "IMA Journal of Management Mathematics", "citeRegEx": "Duran et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Duran et al\\.", "year": 2014}, {"title": "One-Dimensional Vehicle Scheduling with a Front-End Depot", "author": ["S. Emde", "N. Boysen"], "venue": "Journal of Scheduling", "citeRegEx": "Emde and Boysen,? \\Q2014\\E", "shortCiteRegEx": "Emde and Boysen", "year": 2014}, {"title": "Non-Crossing Constraints,\" OR Spectrum (36:2)", "author": ["V. Faghihi", "K.F. Reinschmidt", "J.H. Kang"], "venue": null, "citeRegEx": "Faghihi et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Faghihi et al\\.", "year": 2014}, {"title": "A Parallel Heuristic for Scheduling Decision", "author": ["R.L. Graham", "E.L. Lawler", "J.K. Lenstra", "A.H.G. Rinnooy Kan"], "venue": null, "citeRegEx": "Graham et al\\.,? \\Q1979\\E", "shortCiteRegEx": "Graham et al\\.", "year": 1979}, {"title": "Hybrid Genetic Algorithms with Dispatching Rules for Unrelated", "author": ["C.M. Engineers. CRC Press. Joo", "B.S. Kim"], "venue": null, "citeRegEx": "Joo and Kim,? \\Q2015\\E", "shortCiteRegEx": "Joo and Kim", "year": 2015}, {"title": "Scheduling Jobs on Parallel Machines: A Restricted Tabu Search", "author": ["C.O. Kim", "H.J. Shin"], "venue": "Industrial Engineering", "citeRegEx": "Kim and Shin,? \\Q2003\\E", "shortCiteRegEx": "Kim and Shin", "year": 2003}, {"title": "Unrelated Parallel Machine Scheduling", "author": ["278-287. Kim", "D.-W", "Kim", "K.-H", "W. Jang", "F.F. Chen"], "venue": null, "citeRegEx": "Kim et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Kim et al\\.", "year": 2002}, {"title": "Task Scheduling Algorithm Based on Improved Genetic Algorithm", "author": ["Li", "J.-F", "J. Peng"], "venue": null, "citeRegEx": "Li et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Li et al\\.", "year": 2011}, {"title": "Non-Identical Parallel-Machine Scheduling Research with Minimizing", "author": ["K. Li", "Yang", "S.-l"], "venue": "Cloud Computing Environment,\" Journal of Computer Applications", "citeRegEx": "Li et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Li et al\\.", "year": 2009}, {"title": "Abc-Based Manufacturing Scheduling for Unrelated Parallel", "author": ["Lin", "S.-W", "Ying", "K.-C"], "venue": "Mathematical Modelling", "citeRegEx": "Lin et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Lin et al\\.", "year": 2014}, {"title": "Scheduling Unrelated Parallel Machines", "author": ["R. Logendran", "B. McDonell", "B. Smucker"], "venue": "Research (38:6),", "citeRegEx": "Logendran et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Logendran et al\\.", "year": 2007}, {"title": "Sequence-Dependent Setups,\" Computers & Operations Research (34:11)", "author": ["M.J.P. Lopes", "J.M.V. de Carvalho"], "venue": null, "citeRegEx": "Lopes and Carvalho,? \\Q2007\\E", "shortCiteRegEx": "Lopes and Carvalho", "year": 2007}, {"title": "Appointment Scheduling with Limited Distributional", "author": ["Mak", "H.-Y", "Y. Rong", "J. Zhang"], "venue": "Parallel Machines,\" Computers & Operations Research", "citeRegEx": "Mak et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Mak et al\\.", "year": 2015}, {"title": "High Performance Cloud Computing,\" Future", "author": ["V. Mauch", "M. Kunze", "M. Hillenbrand"], "venue": "Management Science", "citeRegEx": "Mauch et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Mauch et al\\.", "year": 2013}, {"title": "Udpskeduler: A Web Architecture Based Decision", "author": ["J. Miranda", "P.A. Rey", "J.M. Robles"], "venue": "Information Systems Research", "citeRegEx": "Miranda et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Miranda et al\\.", "year": 2012}, {"title": "Scheduling a Professional Sports League", "author": ["K. Nurmi", "J. Kyngas", "D. Goossens", "N. Kyngas"], "venue": null, "citeRegEx": "Nurmi et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Nurmi et al\\.", "year": 2014}, {"title": "Multi-Agent Based Information Systems for Patient", "author": ["A. Heinzl", "C. Becker"], "venue": null, "citeRegEx": "Paulussen et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Paulussen et al\\.", "year": 2013}, {"title": "Scheduling: Theory, Algorithms, and Systems", "author": ["M.L. Systems. Pinedo"], "venue": "Springer. Rabadi, G., Moraga, R.J., and Al-Salem, A. 2006. \"Heuristics for the Unrelated Parallel Machine", "citeRegEx": "Pinedo,? 2012", "shortCiteRegEx": "Pinedo", "year": 2012}, {"title": "A Decision Support System for It Security Incident Management,\" Proceedings of the 11th International Conference on Trust, Privacy, and Security in Digital Business, pp", "author": ["G. Rauchecker", "E. Yasasin", "G. Schryen"], "venue": "36-47.", "citeRegEx": "Rauchecker et al\\.,? 2014", "shortCiteRegEx": "Rauchecker et al\\.", "year": 2014}, {"title": "An Iterated Greedy Algorithm for the Large-Scale Unrelated Parallel Machines Scheduling Problem,", "author": ["F.J. Rodriguez", "M. Lozano", "C. Blum", "C. Garcia-Martinez"], "venue": "Computers & Operations Research", "citeRegEx": "Rodriguez et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Rodriguez et al\\.", "year": 2013}, {"title": "Decision Support for Disaster", "author": ["E. Rolland", "R.A. Patterson", "K. Ward", "B. Dodin"], "venue": "Management,\" Operations Management Research", "citeRegEx": "Rolland et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Rolland et al\\.", "year": 2010}, {"title": "Resource Planning in Disaster Response,", "author": ["G. Schryen", "G. Rauchecker", "T. Comes"], "venue": "Business & Information Systems Engineering", "citeRegEx": "Schryen et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Schryen et al\\.", "year": 2015}, {"title": "Operating System Concepts", "author": ["A. Silberschatz", "P.B. Galvin", "G. Gagne"], "venue": "Wiley.", "citeRegEx": "Silberschatz et al\\.,? 2013", "shortCiteRegEx": "Silberschatz et al\\.", "year": 2013}, {"title": "A Tabu Search Heuristic for the Inland Container Transportation Problem,", "author": ["S. Sterzik", "H. Kopfer"], "venue": "Computers & Operations Research", "citeRegEx": "Sterzik and Kopfer,? \\Q2013\\E", "shortCiteRegEx": "Sterzik and Kopfer", "year": 2013}, {"title": "Sports Tournament Scheduling to Determine the Required Number of Venues Subject to the Minimum Timeslots under Given Formats,", "author": ["Su", "L.-H", "Y. Chiu", "T.C.E. Cheng"], "venue": "Computers & Industrial Engineering", "citeRegEx": "Su et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Su et al\\.", "year": 2013}, {"title": "Queueing-Theoretic Approaches for Dynamic Scheduling: A Survey,\" Surveys in Operations", "author": ["D. Terekhov", "D.G. Down", "J.C. Beck"], "venue": "Research and Management Science", "citeRegEx": "Terekhov et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Terekhov et al\\.", "year": 2014}, {"title": "Integrated Machine Scheduling and Vehicle Routing with Time Windows,", "author": ["C.A. Ullrich"], "venue": "European Journal of Operational Research", "citeRegEx": "Ullrich,? \\Q2013\\E", "shortCiteRegEx": "Ullrich", "year": 2013}, {"title": "A Genetic Algorithm for the Unrelated Parallel Machine Scheduling Problem with Sequence Dependent Setup Times,", "author": ["E. Vallada", "R. Ruiz"], "venue": "European Journal of Operational Research", "citeRegEx": "Vallada and Ruiz,? \\Q2011\\E", "shortCiteRegEx": "Vallada and Ruiz", "year": 2011}, {"title": "Parallel Machine Scheduling by Column Generation,", "author": ["J.M. van den Akker", "J.A. Hoogeveen", "S.L. van de Velde"], "venue": "Operations Research", "citeRegEx": "Akker et al\\.,? \\Q1999\\E", "shortCiteRegEx": "Akker et al\\.", "year": 1999}, {"title": "A Cost-Based Database Request Distribution Technique for Online E-Commerce Applications,", "author": ["D. van der Meer", "K. Dutta", "A. Datta"], "venue": "MIS Quarterly", "citeRegEx": "Meer et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Meer et al\\.", "year": 2012}, {"title": "High-Performance Cloud Computing: A View of Scientific Applications,\" Proceedings of the 10th International Symposium on Pervasive Systems, Algorithms, and Networks, pp", "author": ["C. Vecchiola", "S. Pandey", "R. Buyya"], "venue": "4-16.", "citeRegEx": "Vecchiola et al\\.,? 2009", "shortCiteRegEx": "Vecchiola et al\\.", "year": 2009}, {"title": "Experimental Comparison of Approximation Algorithms for Scheduling Unrelated Parallel Machines,", "author": ["T. Vredeveld", "C. Hurkens"], "venue": "INFORMS Journal on Computing", "citeRegEx": "Vredeveld and Hurkens,? \\Q2002\\E", "shortCiteRegEx": "Vredeveld and Hurkens", "year": 2002}, {"title": "A Branch and Bound Algorithm for Single-Machine Production Scheduling Integrated with Preventive Maintenance Planning,", "author": ["S. Wang", "M. Liu"], "venue": "International Journal of Production Research", "citeRegEx": "Wang and Liu,? \\Q2013\\E", "shortCiteRegEx": "Wang and Liu", "year": 2013}, {"title": "Unrelated Parallel Machine Scheduling with Setup Consideration and a Total Weighted Completion Time Objective,", "author": ["M.X. Weng", "J. Lu", "H. Ren"], "venue": "International Journal of Production Economics", "citeRegEx": "Weng et al\\.,? \\Q2001\\E", "shortCiteRegEx": "Weng et al\\.", "year": 2001}, {"title": "Emergency Response in Natural Disaster Management: Allocation and Scheduling of Rescue Units,", "author": ["F. Wex", "G. Schryen", "S. Feuerriegel", "D. Neumann"], "venue": "European Journal of Operational Research", "citeRegEx": "Wex et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Wex et al\\.", "year": 2014}, {"title": "Intelligent Decision Support for Centralized Coordination During Emergency Response,", "author": ["F. Wex", "G. Schryen", "D. Neumann"], "venue": "in: Proceedings of the 8th International Conference on Information Systems for Crisis Response and Management", "citeRegEx": "Wex et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Wex et al\\.", "year": 2011}, {"title": "Min-Cost with Delay Scheduling for Large Scale CloudBased Workflow Applications Platform,", "author": ["Yang", "C.-W", "Guo", "J.-D", "J. Chi"], "venue": "Proceedings of the 18th Pacific Asian Conference on Information Systems", "citeRegEx": "Yang et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Yang et al\\.", "year": 2014}, {"title": "An Optimal Power Scheduling Method for Demand Response in Home Energy Management System,", "author": ["Z. Zhao", "W.C. Lee", "Y. Shin", "Song", "K.-B"], "venue": "IEEE Transactions on Smart Grid", "citeRegEx": "Zhao et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Zhao et al\\.", "year": 2013}], "referenceMentions": [{"referenceID": 3, "context": "For example, in cloud computing, applications are scheduled (Beloglazov et al. 2012; van der Meer et al. 2012; Yang et al. 2014), in energy management, enterprise resources have to be scheduled (Bodenstein et al.", "startOffset": 60, "endOffset": 128}, {"referenceID": 50, "context": "For example, in cloud computing, applications are scheduled (Beloglazov et al. 2012; van der Meer et al. 2012; Yang et al. 2014), in energy management, enterprise resources have to be scheduled (Bodenstein et al.", "startOffset": 60, "endOffset": 128}, {"referenceID": 4, "context": "2014), in energy management, enterprise resources have to be scheduled (Bodenstein et al. 2011; Brandt and Bodenstein 2012; Zhao et al. 2013), and in sports management, tournaments and leagues are scheduled (Duran et al.", "startOffset": 71, "endOffset": 141}, {"referenceID": 5, "context": "2014), in energy management, enterprise resources have to be scheduled (Bodenstein et al. 2011; Brandt and Bodenstein 2012; Zhao et al. 2013), and in sports management, tournaments and leagues are scheduled (Duran et al.", "startOffset": 71, "endOffset": 141}, {"referenceID": 51, "context": "2014), in energy management, enterprise resources have to be scheduled (Bodenstein et al. 2011; Brandt and Bodenstein 2012; Zhao et al. 2013), and in sports management, tournaments and leagues are scheduled (Duran et al.", "startOffset": 71, "endOffset": 141}, {"referenceID": 14, "context": "2013), and in sports management, tournaments and leagues are scheduled (Duran et al. 2014; Nurmi et al. 2014; Su et al. 2013).", "startOffset": 71, "endOffset": 125}, {"referenceID": 29, "context": "2013), and in sports management, tournaments and leagues are scheduled (Duran et al. 2014; Nurmi et al. 2014; Su et al. 2013).", "startOffset": 71, "endOffset": 125}, {"referenceID": 38, "context": "2013), and in sports management, tournaments and leagues are scheduled (Duran et al. 2014; Nurmi et al. 2014; Su et al. 2013).", "startOffset": 71, "endOffset": 125}, {"referenceID": 26, "context": "In healthcare management, appointments and visits are scheduled (Mak et al. 2015; Meyer et al. 2014; Paulussen et al. 2013), in disaster management, rescue units are scheduled (Rolland et al.", "startOffset": 64, "endOffset": 123}, {"referenceID": 30, "context": "In healthcare management, appointments and visits are scheduled (Mak et al. 2015; Meyer et al. 2014; Paulussen et al. 2013), in disaster management, rescue units are scheduled (Rolland et al.", "startOffset": 64, "endOffset": 123}, {"referenceID": 34, "context": "2013), in disaster management, rescue units are scheduled (Rolland et al. 2010; Schryen et al. 2015; Wex et al. 2014; Wex et al. 2011), and in information systems, scheduling systems are built (Chandra et al.", "startOffset": 58, "endOffset": 134}, {"referenceID": 35, "context": "2013), in disaster management, rescue units are scheduled (Rolland et al. 2010; Schryen et al. 2015; Wex et al. 2014; Wex et al. 2011), and in information systems, scheduling systems are built (Chandra et al.", "startOffset": 58, "endOffset": 134}, {"referenceID": 48, "context": "2013), in disaster management, rescue units are scheduled (Rolland et al. 2010; Schryen et al. 2015; Wex et al. 2014; Wex et al. 2011), and in information systems, scheduling systems are built (Chandra et al.", "startOffset": 58, "endOffset": 134}, {"referenceID": 49, "context": "2013), in disaster management, rescue units are scheduled (Rolland et al. 2010; Schryen et al. 2015; Wex et al. 2014; Wex et al. 2011), and in information systems, scheduling systems are built (Chandra et al.", "startOffset": 58, "endOffset": 134}, {"referenceID": 6, "context": "2011), and in information systems, scheduling systems are built (Chandra et al. 2012; Faghihi et al. 2014; Miranda et al. 2012).", "startOffset": 64, "endOffset": 127}, {"referenceID": 16, "context": "2011), and in information systems, scheduling systems are built (Chandra et al. 2012; Faghihi et al. 2014; Miranda et al. 2012).", "startOffset": 64, "endOffset": 127}, {"referenceID": 28, "context": "2011), and in information systems, scheduling systems are built (Chandra et al. 2012; Faghihi et al. 2014; Miranda et al. 2012).", "startOffset": 64, "endOffset": 127}, {"referenceID": 36, "context": "In computer science, software application jobs are assigned to computer processors (Li and Peng 2011; Silberschatz et al. 2013; Terekhov et al. 2014), in operations management, production jobs are scheduled on machines (Joo and Kim 2015; Mensendiek et al.", "startOffset": 83, "endOffset": 149}, {"referenceID": 39, "context": "In computer science, software application jobs are assigned to computer processors (Li and Peng 2011; Silberschatz et al. 2013; Terekhov et al. 2014), in operations management, production jobs are scheduled on machines (Joo and Kim 2015; Mensendiek et al.", "startOffset": 83, "endOffset": 149}, {"referenceID": 18, "context": "2014), in operations management, production jobs are scheduled on machines (Joo and Kim 2015; Mensendiek et al. 2015; Wang and Liu 2013) and workers are assigned to shifts or jobs (Cote et al.", "startOffset": 75, "endOffset": 136}, {"referenceID": 46, "context": "2014), in operations management, production jobs are scheduled on machines (Joo and Kim 2015; Mensendiek et al. 2015; Wang and Liu 2013) and workers are assigned to shifts or jobs (Cote et al.", "startOffset": 75, "endOffset": 136}, {"referenceID": 32, "context": "2015; Wang and Liu 2013) and workers are assigned to shifts or jobs (Cote et al. 2011; Elahipanah et al. 2013; Rauchecker et al. 2014), and in logistics, transportation scheduling problems occur (Emde and Boysen 2014; Sterzik and Kopfer 2013; Ullrich 2013).", "startOffset": 68, "endOffset": 134}, {"referenceID": 15, "context": "2014), and in logistics, transportation scheduling problems occur (Emde and Boysen 2014; Sterzik and Kopfer 2013; Ullrich 2013).", "startOffset": 66, "endOffset": 127}, {"referenceID": 37, "context": "2014), and in logistics, transportation scheduling problems occur (Emde and Boysen 2014; Sterzik and Kopfer 2013; Ullrich 2013).", "startOffset": 66, "endOffset": 127}, {"referenceID": 40, "context": "2014), and in logistics, transportation scheduling problems occur (Emde and Boysen 2014; Sterzik and Kopfer 2013; Ullrich 2013).", "startOffset": 66, "endOffset": 127}, {"referenceID": 31, "context": "As numerous scheduling problems are NP-hard (Pinedo 2012), which means that there is no algorithm that can solve the problem to optimality in polynomial time, many large real-world instances are computationally intractable due to time limitations.", "startOffset": 44, "endOffset": 57}, {"referenceID": 27, "context": "For example, they are available at many universities and are provided by some cloud providers, especially by Amazon Web Services (Mauch et al. 2013).", "startOffset": 129, "endOffset": 148}, {"referenceID": 17, "context": "In this paper, we focus on a specific problem which occurs in many application domains: the parallel machine scheduling problem on unrelated machines, sequence- and machine-dependent setup times, machine eligibility restrictions, and a total weighted completion time objective function, classified by Pinedo (2012) as in the established -notation (Graham et al. 1979) and proven to be NP-hard by Wex et al.", "startOffset": 347, "endOffset": 367}, {"referenceID": 26, "context": "For example, they are available at many universities and are provided by some cloud providers, especially by Amazon Web Services (Mauch et al. 2013). To sum up, HPC has not only become technologically feasible, but also economically affordable. In this paper, we focus on a specific problem which occurs in many application domains: the parallel machine scheduling problem on unrelated machines, sequence- and machine-dependent setup times, machine eligibility restrictions, and a total weighted completion time objective function, classified by Pinedo (2012) as in the established -notation (Graham et al.", "startOffset": 130, "endOffset": 560}, {"referenceID": 17, "context": "In this paper, we focus on a specific problem which occurs in many application domains: the parallel machine scheduling problem on unrelated machines, sequence- and machine-dependent setup times, machine eligibility restrictions, and a total weighted completion time objective function, classified by Pinedo (2012) as in the established -notation (Graham et al. 1979) and proven to be NP-hard by Wex et al. (2014).", "startOffset": 348, "endOffset": 414}, {"referenceID": 1, "context": "The algorithms are capable of solving small instances with 25 jobs and 2 machines in less than 15 minutes (Azizoglu and Kirca 1999) and medium-sized instances with 100 jobs and 20 machines in less than one hour (Chen and Powell 1999).", "startOffset": 106, "endOffset": 131}, {"referenceID": 1, "context": "The algorithms are capable of solving small instances with 25 jobs and 2 machines in less than 15 minutes (Azizoglu and Kirca 1999) and medium-sized instances with 100 jobs and 20 machines in less than one hour (Chen and Powell 1999). Lopes and de Carvalho (2007)", "startOffset": 107, "endOffset": 264}, {"referenceID": 35, "context": "However, computational studies indicate that this strategy is inefficient as it fails to compute optimal solutions for small-sized instances consisting of 40 jobs and 10 machines within several hours (Schryen et al. 2015).", "startOffset": 200, "endOffset": 221}, {"referenceID": 19, "context": "Kim et al. (2002) and Low (2005) use Simulated Annealing to minimize the total tardiness and the total flow time, while Vallada and Ruiz (2011) minimize the makespan using a genetic algorithm.", "startOffset": 0, "endOffset": 18}, {"referenceID": 19, "context": "Kim et al. (2002) and Low (2005) use Simulated Annealing to minimize the total tardiness and the total flow time, while Vallada and Ruiz (2011) minimize the makespan using a genetic algorithm.", "startOffset": 0, "endOffset": 33}, {"referenceID": 19, "context": "Kim et al. (2002) and Low (2005) use Simulated Annealing to minimize the total tardiness and the total flow time, while Vallada and Ruiz (2011) minimize the makespan using a genetic algorithm.", "startOffset": 0, "endOffset": 144}, {"referenceID": 19, "context": "Kim et al. (2002) and Low (2005) use Simulated Annealing to minimize the total tardiness and the total flow time, while Vallada and Ruiz (2011) minimize the makespan using a genetic algorithm. A Tabu Search to minimize total tardiness, total weighted tardiness, maximum tardiness, and maximum lateness has been investigated by Chen (2006), Chen and Wu (2006), Kim and Shin (2003), and Logendran et al.", "startOffset": 0, "endOffset": 339}, {"referenceID": 19, "context": "Kim et al. (2002) and Low (2005) use Simulated Annealing to minimize the total tardiness and the total flow time, while Vallada and Ruiz (2011) minimize the makespan using a genetic algorithm. A Tabu Search to minimize total tardiness, total weighted tardiness, maximum tardiness, and maximum lateness has been investigated by Chen (2006), Chen and Wu (2006), Kim and Shin (2003), and Logendran et al.", "startOffset": 0, "endOffset": 359}, {"referenceID": 19, "context": "A Tabu Search to minimize total tardiness, total weighted tardiness, maximum tardiness, and maximum lateness has been investigated by Chen (2006), Chen and Wu (2006), Kim and Shin (2003), and Logendran et al.", "startOffset": 167, "endOffset": 187}, {"referenceID": 19, "context": "A Tabu Search to minimize total tardiness, total weighted tardiness, maximum tardiness, and maximum lateness has been investigated by Chen (2006), Chen and Wu (2006), Kim and Shin (2003), and Logendran et al. (2007). Rabadi et al.", "startOffset": 167, "endOffset": 216}, {"referenceID": 19, "context": "A Tabu Search to minimize total tardiness, total weighted tardiness, maximum tardiness, and maximum lateness has been investigated by Chen (2006), Chen and Wu (2006), Kim and Shin (2003), and Logendran et al. (2007). Rabadi et al. (2006) introduced a Randomized Priority Search metaheuristic to minimize the makespan while de Paula et al.", "startOffset": 167, "endOffset": 238}, {"referenceID": 19, "context": "A Tabu Search to minimize total tardiness, total weighted tardiness, maximum tardiness, and maximum lateness has been investigated by Chen (2006), Chen and Wu (2006), Kim and Shin (2003), and Logendran et al. (2007). Rabadi et al. (2006) introduced a Randomized Priority Search metaheuristic to minimize the makespan while de Paula et al. (2007) presented a Variable Neighborhood Search to minimize the sum of both makespan and total weighted tardiness.", "startOffset": 167, "endOffset": 346}, {"referenceID": 19, "context": "A Tabu Search to minimize total tardiness, total weighted tardiness, maximum tardiness, and maximum lateness has been investigated by Chen (2006), Chen and Wu (2006), Kim and Shin (2003), and Logendran et al. (2007). Rabadi et al. (2006) introduced a Randomized Priority Search metaheuristic to minimize the makespan while de Paula et al. (2007) presented a Variable Neighborhood Search to minimize the sum of both makespan and total weighted tardiness. Chen (2005), Wex et al.", "startOffset": 167, "endOffset": 466}, {"referenceID": 19, "context": "A Tabu Search to minimize total tardiness, total weighted tardiness, maximum tardiness, and maximum lateness has been investigated by Chen (2006), Chen and Wu (2006), Kim and Shin (2003), and Logendran et al. (2007). Rabadi et al. (2006) introduced a Randomized Priority Search metaheuristic to minimize the makespan while de Paula et al. (2007) presented a Variable Neighborhood Search to minimize the sum of both makespan and total weighted tardiness. Chen (2005), Wex et al. (2014), and Weng et al.", "startOffset": 167, "endOffset": 485}, {"referenceID": 19, "context": "A Tabu Search to minimize total tardiness, total weighted tardiness, maximum tardiness, and maximum lateness has been investigated by Chen (2006), Chen and Wu (2006), Kim and Shin (2003), and Logendran et al. (2007). Rabadi et al. (2006) introduced a Randomized Priority Search metaheuristic to minimize the makespan while de Paula et al. (2007) presented a Variable Neighborhood Search to minimize the sum of both makespan and total weighted tardiness. Chen (2005), Wex et al. (2014), and Weng et al. (2001) developed problem-specific heuristics that minimize the total weighted completion time and the makespan.", "startOffset": 167, "endOffset": 509}, {"referenceID": 19, "context": "A Tabu Search to minimize total tardiness, total weighted tardiness, maximum tardiness, and maximum lateness has been investigated by Chen (2006), Chen and Wu (2006), Kim and Shin (2003), and Logendran et al. (2007). Rabadi et al. (2006) introduced a Randomized Priority Search metaheuristic to minimize the makespan while de Paula et al. (2007) presented a Variable Neighborhood Search to minimize the sum of both makespan and total weighted tardiness. Chen (2005), Wex et al. (2014), and Weng et al. (2001) developed problem-specific heuristics that minimize the total weighted completion time and the makespan. For the parallel machine scheduling problem on unrelated machines with a total weighted completion time objective function, there are some approximation algorithms which are based on model relaxations and give a theoretical worst-case performance (see Li and Yang (2009) for an overview).", "startOffset": 167, "endOffset": 885}, {"referenceID": 19, "context": "A Tabu Search to minimize total tardiness, total weighted tardiness, maximum tardiness, and maximum lateness has been investigated by Chen (2006), Chen and Wu (2006), Kim and Shin (2003), and Logendran et al. (2007). Rabadi et al. (2006) introduced a Randomized Priority Search metaheuristic to minimize the makespan while de Paula et al. (2007) presented a Variable Neighborhood Search to minimize the sum of both makespan and total weighted tardiness. Chen (2005), Wex et al. (2014), and Weng et al. (2001) developed problem-specific heuristics that minimize the total weighted completion time and the makespan. For the parallel machine scheduling problem on unrelated machines with a total weighted completion time objective function, there are some approximation algorithms which are based on model relaxations and give a theoretical worst-case performance (see Li and Yang (2009) for an overview). However, these theoretical bounds are not promising for practical contexts as they are not very tight. Tabu search and genetic algorithms are used by Lin et al. (2011) and Vredeveld and Hurkens (2002) while Weng et al.", "startOffset": 167, "endOffset": 1071}, {"referenceID": 19, "context": "A Tabu Search to minimize total tardiness, total weighted tardiness, maximum tardiness, and maximum lateness has been investigated by Chen (2006), Chen and Wu (2006), Kim and Shin (2003), and Logendran et al. (2007). Rabadi et al. (2006) introduced a Randomized Priority Search metaheuristic to minimize the makespan while de Paula et al. (2007) presented a Variable Neighborhood Search to minimize the sum of both makespan and total weighted tardiness. Chen (2005), Wex et al. (2014), and Weng et al. (2001) developed problem-specific heuristics that minimize the total weighted completion time and the makespan. For the parallel machine scheduling problem on unrelated machines with a total weighted completion time objective function, there are some approximation algorithms which are based on model relaxations and give a theoretical worst-case performance (see Li and Yang (2009) for an overview). However, these theoretical bounds are not promising for practical contexts as they are not very tight. Tabu search and genetic algorithms are used by Lin et al. (2011) and Vredeveld and Hurkens (2002) while Weng et al.", "startOffset": 167, "endOffset": 1104}, {"referenceID": 19, "context": "A Tabu Search to minimize total tardiness, total weighted tardiness, maximum tardiness, and maximum lateness has been investigated by Chen (2006), Chen and Wu (2006), Kim and Shin (2003), and Logendran et al. (2007). Rabadi et al. (2006) introduced a Randomized Priority Search metaheuristic to minimize the makespan while de Paula et al. (2007) presented a Variable Neighborhood Search to minimize the sum of both makespan and total weighted tardiness. Chen (2005), Wex et al. (2014), and Weng et al. (2001) developed problem-specific heuristics that minimize the total weighted completion time and the makespan. For the parallel machine scheduling problem on unrelated machines with a total weighted completion time objective function, there are some approximation algorithms which are based on model relaxations and give a theoretical worst-case performance (see Li and Yang (2009) for an overview). However, these theoretical bounds are not promising for practical contexts as they are not very tight. Tabu search and genetic algorithms are used by Lin et al. (2011) and Vredeveld and Hurkens (2002) while Weng et al. (2001) and Wex et al.", "startOffset": 167, "endOffset": 1129}, {"referenceID": 19, "context": "A Tabu Search to minimize total tardiness, total weighted tardiness, maximum tardiness, and maximum lateness has been investigated by Chen (2006), Chen and Wu (2006), Kim and Shin (2003), and Logendran et al. (2007). Rabadi et al. (2006) introduced a Randomized Priority Search metaheuristic to minimize the makespan while de Paula et al. (2007) presented a Variable Neighborhood Search to minimize the sum of both makespan and total weighted tardiness. Chen (2005), Wex et al. (2014), and Weng et al. (2001) developed problem-specific heuristics that minimize the total weighted completion time and the makespan. For the parallel machine scheduling problem on unrelated machines with a total weighted completion time objective function, there are some approximation algorithms which are based on model relaxations and give a theoretical worst-case performance (see Li and Yang (2009) for an overview). However, these theoretical bounds are not promising for practical contexts as they are not very tight. Tabu search and genetic algorithms are used by Lin et al. (2011) and Vredeveld and Hurkens (2002) while Weng et al. (2001) and Wex et al. (2014) develop problem-specific heuristics.", "startOffset": 167, "endOffset": 1151}, {"referenceID": 19, "context": "A Tabu Search to minimize total tardiness, total weighted tardiness, maximum tardiness, and maximum lateness has been investigated by Chen (2006), Chen and Wu (2006), Kim and Shin (2003), and Logendran et al. (2007). Rabadi et al. (2006) introduced a Randomized Priority Search metaheuristic to minimize the makespan while de Paula et al. (2007) presented a Variable Neighborhood Search to minimize the sum of both makespan and total weighted tardiness. Chen (2005), Wex et al. (2014), and Weng et al. (2001) developed problem-specific heuristics that minimize the total weighted completion time and the makespan. For the parallel machine scheduling problem on unrelated machines with a total weighted completion time objective function, there are some approximation algorithms which are based on model relaxations and give a theoretical worst-case performance (see Li and Yang (2009) for an overview). However, these theoretical bounds are not promising for practical contexts as they are not very tight. Tabu search and genetic algorithms are used by Lin et al. (2011) and Vredeveld and Hurkens (2002) while Weng et al. (2001) and Wex et al. (2014) develop problem-specific heuristics. A good overview is further provided by Rodriguez et al. (2013).", "startOffset": 167, "endOffset": 1251}, {"referenceID": 2, "context": "HPC is used in many scientific disciplines, including biology, chemistry, physics, geology, weather forecasting, aerodynamic research, and computer science (Bell and Gray 2002; Vecchiola et al. 2009).", "startOffset": 156, "endOffset": 199}, {"referenceID": 44, "context": "HPC is used in many scientific disciplines, including biology, chemistry, physics, geology, weather forecasting, aerodynamic research, and computer science (Bell and Gray 2002; Vecchiola et al. 2009).", "startOffset": 156, "endOffset": 199}, {"referenceID": 11, "context": "This strategy is called eager best-first strategy (Clausen and Perregaard 1999).", "startOffset": 50, "endOffset": 79}, {"referenceID": 12, "context": "A b&p algorithm is a branch-and-bound (b&b) algorithm with the special characteristic that the linear relaxation at each node of the b&b tree is solved using column generation, which was originally introduced to solve huge linear programs by Dantzig and Wolfe (1960). The original formulation of a b&p algorithm goes back to Barnhart et al.", "startOffset": 242, "endOffset": 267}, {"referenceID": 12, "context": "A b&p algorithm is a branch-and-bound (b&b) algorithm with the special characteristic that the linear relaxation at each node of the b&b tree is solved using column generation, which was originally introduced to solve huge linear programs by Dantzig and Wolfe (1960). The original formulation of a b&p algorithm goes back to Barnhart et al. (1998). B&p algorithms have been established to solve unrelated parallel machine scheduling problems exactly for rather small instances (Chen and Powell 1999; Lopes and de Carvalho 2007).", "startOffset": 242, "endOffset": 348}, {"referenceID": 11, "context": "First, the DFS strategy quickly finds a feasible solution for (BinLP) and second, lazy DFS strategies are more suitable for parallelization than eager DFS strategies (Clausen and Perregaard 1999).", "startOffset": 166, "endOffset": 195}, {"referenceID": 11, "context": "master/worker setting for our parallelization as described in Clausen and Perregaard (1999) for instance.", "startOffset": 62, "endOffset": 92}, {"referenceID": 47, "context": "Similar settings have been used in the literature (Chen and Powell 1999; Chen and Powell 2003; Lopes and de Carvalho 2007; van den Akker et al. 1999; Weng et al. 2001).", "startOffset": 50, "endOffset": 167}, {"referenceID": 47, "context": "1 Effectiveness of the DFS Heuristic For each instance, we calculated the solution of the DFS heuristic and of the best performing heuristic presented by Weng et al. (2001) and Wex et al.", "startOffset": 154, "endOffset": 173}, {"referenceID": 47, "context": "1 Effectiveness of the DFS Heuristic For each instance, we calculated the solution of the DFS heuristic and of the best performing heuristic presented by Weng et al. (2001) and Wex et al. (2014) \u2013 we refer to this heuristic as SCHED \u2013 and documented execution times as well as solution quality (cf.", "startOffset": 154, "endOffset": 195}, {"referenceID": 47, "context": ", by Wex et al. (2014) and Schryen et al.", "startOffset": 5, "endOffset": 23}, {"referenceID": 35, "context": "(2014) and Schryen et al. (2015), and allow for quantifying the solution quality of DFS compared to (1) optimal solutions and (2) the SCHED heuristic.", "startOffset": 11, "endOffset": 33}], "year": 2016, "abstractText": "Many academic disciplines including information systems, computer science, and operations management face scheduling problems as important decision making tasks. Since many scheduling problems are NP-hard in the strong sense, there is a need for developing solution heuristics. For scheduling problems with setup times on unrelated parallel machines, there is limited research on solution methods and to the best of our knowledge, parallel computer architectures have not yet been taken advantage of. We address this gap by proposing and implementing a new solution heuristic and by testing different parallelization strategies. In our computational experiments, we show that our heuristic calculates near-optimal solutions even for large instances and that computing time can be reduced substantially by our parallelization approach.", "creator": "Microsoft\u00ae Office Word 2007"}}}