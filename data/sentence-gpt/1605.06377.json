{"id": "1605.06377", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "20-May-2016", "title": "Towards Automation of Knowledge Understanding: An Approach for Probabilistic Generative Classifiers", "abstract": "After data selection, pre-processing, transformation, and feature extraction, knowledge extraction is not the final step in a data mining process. It is then necessary to understand this knowledge in order to apply it efficiently and effectively. Up to now, there is a lack of appropriate techniques that support this significant step. This is partly due to the fact that the assessment of knowledge is often highly subjective, e.g., regarding aspects such as novelty or usefulness. These aspects depend on the specific knowledge and requirements of the data miner. There are, however, a number of aspects that are objective and for which it is possible to provide appropriate measures. In this article we focus on classification problems and use probabilistic generative classifiers based on mixture density models that are quite common in data mining applications. We define objective measures to assess the informativeness, uniqueness, importance, discrimination, representativity, uncertainty, and distinguishability of rules contained in these classifiers numerically. These measures not only support a data miner in evaluating results of a data mining process based on such classifiers. As we will see in illustrative case studies, they may also be used to improve the data mining process itself or to support the later application of the extracted knowledge.\n\n\n\n\n\n\nIn this article we will not discuss these issues in detail. We will show that a comprehensive approach to estimating the knowledge-group quality is needed for real-world applications.\n\nIn our next article, we will examine some of the top-notch applications of data mining, such as data mining, processing, and analytics.\n\nData Mining Applications\n\nData Mining\nData Mining\nData Mining\nData Mining\nData Mining\nData Mining\nData Mining\nData Mining\nData Mining\nData Mining\nData Mining\nData Mining\nData Mining\nData Mining\nData Mining\nData Mining\nData Mining\nData Mining\nData Mining\nData Mining\nData Mining\nData Mining\nData Mining\nData Mining\nData Mining\nData Mining\nData Mining\nData Mining\nData Mining\nData Mining\nData Mining\nData Mining\nData Mining\nData Mining\nData Mining\nData Mining\nData Mining\nData Mining\nData Mining\nData Mining\nData Mining\nData Mining\nData Mining\nData Mining\nData Mining\nData Mining\nData Mining\nData Mining\nData Mining\nData Mining\nData Mining\nData Mining\nData Mining\nData Mining\nData Mining\nData Mining\nData Mining\nData Mining\nData Mining\nData Mining\nData Mining\nData", "histories": [["v1", "Fri, 20 May 2016 14:34:49 GMT  (1939kb,D)", "http://arxiv.org/abs/1605.06377v1", "29 pages with 9 figures and 4 tables. Currently under review for Information Sciences"]], "COMMENTS": "29 pages with 9 figures and 4 tables. Currently under review for Information Sciences", "reviews": [], "SUBJECTS": "cs.LG cs.AI", "authors": ["dominik fisch", "christian gruhl", "edgar kalkowski", "bernhard sick", "seppo j ovaska"], "accepted": false, "id": "1605.06377"}, "pdf": {"name": "1605.06377.pdf", "metadata": {"source": "CRF", "title": "Towards Automation of Knowledge Understanding: An Approach for Probabilistic Generative Classifiers", "authors": ["Dominik Fisch", "Christian Gruhl", "Edgar Kalkowski", "Bernhard Sick", "Seppo J. Ovaska"], "emails": ["dominik.fisch@bmw.de)", "cgruhl@uni-kassel.de)", "kalkowski@uni-kassel.de)", "bsick@uni-kassel.de)", "seppo.ovaska@aalto.fi)"], "sections": [{"heading": null, "text": "Towards Automation of Knowledge Understanding: An Approach for Probabilistic Generative Classifiers\nDominik Fisch \u2217 Christian Gruhl \u2020 Edgar Kalkowski \u2020\nBernhard Sick \u2020 Seppo J. Ovaska \u2021\nAfter data selection, pre-processing, transformation, and feature extraction, knowledge extraction is not the final step in a data mining process. It is then necessary to understand this knowledge in order to apply it efficiently and effectively. Up to now, there is a lack of appropriate techniques that support this significant step. This is partly due to the fact that the assessment of knowledge is often highly subjective, e.g., regarding aspects such as novelty or usefulness. These aspects depend on the specific knowledge and requirements of the data miner. There are, however, a number of aspects that are objective and for which it is possible to provide appropriate measures. In this article we focus on classification problems and use probabilistic generative classifiers based on mixture density models that are quite common in data mining applications. We define objective measures to assess the informativeness, uniqueness, importance, discrimination, representativity, uncertainty, and distinguishability of rules contained in these classifiers numerically. These measures not only support a data miner in evaluating results of a data mining process based on such classifiers. As we will see in illustrative case studies, they may also be used to improve the data mining process itself or to support the later application of the extracted knowledge."}, {"heading": "1 Introduction", "text": "Data mining (DM) can be seen as a multi-step process as shown in the data mining pyramid (see Fig. 1) which was introduced by Embrechts et al. in [16]. The idea of this pyramid can briefly be summarized as follows: Raw data are pre-processed to condense application-specific information in attributes or features. Then, knowledge is extracted, e.g., by building classification or regression models. By analyzing this knowledge off-line (i.e., after the model is learned from training data) and by using it in a given application (on-line) it is possible to come to a deeper understanding of its working principles and to gain some experience in using it, respectively. Both will support the efficient and effective application of the knowledge. Finally, this kind of meta-knowledge (knowledge about knowledge) will eventually help to solve similar kinds of application problems. That is, the final step of wisdom is reached by transferring the knowledge to other application domains. While the steps from data over information to knowledge are\n\u2217BMW Group, 80788 Munich, Germany (e-mail: dominik.fisch@bmw.de) \u2020University of Kassel, Department of Electrical Engineering and Computer Science, Wilhelmshoeher Allee 73, 34121 Kassel, Germany (e-mail: {cgruhl,kalkowski,bsick}@uni-kassel.de) \u2021Aalto University, Department of Electrical Engineering and Automation, Espoo, Finland (e-mail: seppo.ovaska@aalto.fi)\nar X\niv :1\n60 5.\n06 37\n7v 1\n[ cs\n.L G\n] 2\n0 M\nay 2\n01 6\nwell supported by appropriate algorithms and commercial or free tools, there is still a lack of techniques that support the subsequent steps.\nIn this article, we address the problem of knowledge understanding by analyzing its properties off-line. We use classifiers based on probabilistic mixture models (CMM, see [22, 6]) which can be used in many DM applications. These classifiers can be termed to be hybrid in the sense that different kinds of distributions are combined for different kinds of attributes (e.g., continuous or categorical) which makes the classifier very flexible. CMM are trained from data samples using expectation maximization or related techniques such as variational Bayesian approaches [6]. For CMM, we propose various measures that assess the informativeness, uniqueness, importance, discrimination, representativity, uncertainty, and distinguishability of rules contained in this classifier. The measures can be used in different ways: For example, it is possible to prune classifiers, to rank classification rules, or to detect novel kinds of knowledge (cf. anomaly detection) during the classifier\u2019s application. However, the proposed measures should be seen as a first yet important step towards an automation of knowledge understanding. Thus, with the assumptions we make, we do not cover all possible aspects of real World applications so far. For instance, other probability distributions are needed for other attribute types. This article is a substantially extended version of a conference article (cf. [20]). The main contributions compared to the previous article are: All existing measures are revised and we introduce two additional measures (uncertainty and distinguishability) to further analyze different aspects of generative classifiers. The evaluation of the measures is also completely new and improved. In four case studies utilizing over 20 artificial and real-world benchmark data sets we illustrate how our proposed measures can help data scientists. In the remainder of the article we first briefly discuss related work in Section 2. Then, we describe the classifier and introduce the various measures in Section 3. Illustrative case studies in Section 4 show how the new measures can be applied. In Section 5 we summarize the key findings and give an outlook to future work."}, {"heading": "2 Related Work", "text": "Obviously, the measures we are looking for are closely related to so-called interestingness measures in data mining. Data mining (DM), today often used as a synonym of knowledge discovery in databases (KDD), deals with the \u201cthe nontrivial process of identifying valid, novel, potentially useful, and ultimately understandable patterns in data\u201d [17]. But, how can this \u201cinterestingness\u201d be assessed numerically? Obviously, there are objective facets of interestingness such as validity and subjective facets such as usefulness (see, e.g., [32, 33, 44, 58, 62]). Objective measures analyze the extracted knowledge without relating it to the users\u2019 prior knowledge or needs. These measures are based, e.g., on so-called information criteria or on data-based measurement techniques (see [65] for an overview). Examples for the former are\nAkaike\u2019s information criterion or the Bayesian information criterion. Examples for the latter are statistical measures such as sensitivity, specificity, precision, etc. determined with a crossvalidation or bootstrapping method on test data (see, e.g., [40, 57, 61, 38, 42, 34]). Some other criteria assess the complexity of rules or rule sets such as a rule system size measure (depends on the number of rules), a computational complexity measure (the CPU run-time needed to evaluate a rule or a rule system), a rule complexity measure (number of attributes considered by a rule), a mean scoring rules measure (the average number of rules that are evaluated to find a conclusion), a fuzzy quality measure (for linguistic terms associated with rules), or the information gain for association rules (see, e.g., [4, 30, 37, 14]). Sometimes, several measures are combined [4, 60]. In [27], interestingness measures for rules are evaluated with regard to the four properties of confirmation, locality, symmetry, and a property termed Ex1 which assures that conclusively confirmatory rules are assigned a higher interestingness value than non-conclusively confirmatory rules and vice versa. Especially, in [27] weaker forms of the locality property and EX1 are proposed together with a new interestingness measure that fulfills the weaker forms of those properties. Two further measures are proposed in [26] and compared to the measure from [27] in terms of the properties they fulfill. Also, in [26] two new Bayesian confirmation measures for the evaluation of rule interestingness measures are proposed. An interestingness measure that does not evaluate rules or classifier components but individual samples is presented in [8]. There, a support vector machine is used and samples close to the decision boundary or distant to any previous samples are classified as interesting. In [66], a support vector machine is used to learn interestingness values of Twitter hashtags from data. Subjective measures consider additional knowledge about the application and information about the data miner such as skills and needs [49, 47]. Examples for subjective measures are novelty [5, 17], usefulness [17], understandability [17], actionability [10, 9], and unexpectedness [13, 35, 59, 48].\nExisting measures are based on different techniques to represent information about the human users and they depend on the form of knowledge representation. Often, Bayesian networks, fuzzy classifiers, or association rules are addressed in related work. Related work can also be found in the field of recommender systems (e.g., in a content-based approach or a collaborative filtering approach) [2, 31]. In this article, we focus on objective measures beyond existing measures for validity (e.g., precision, recall, etc.). We also focus on measures for classification rules and rule sets that are not \u201ccrisp\u201d, but consider samples and knowledge that are \u201cuncertain\u201d. More specifically, we consider probabilistic classifiers and stay within a probabilistic methodological framework to assess the rules contained in these classifiers. In Section 5 we will also address the question of whether these measures could be transferred to other kinds of classifiers, too."}, {"heading": "3 Methodological Foundations", "text": "In this section we will first present the generative classifier paradigm. A generative classifier aims at modeling the processes underlying the \u201cgeneration\u201d of the data [6]. It is termed to be \u201cgenerative\u201d because if these processes are modeled perfectly, a generative model could be used to generate artificial data with exactly the same characteristics as the real data. In contrast, discriminative classifiers aim at finding the optimal decision boundary directly. Today, these two approaches are often combined to exploit their respective advantages. Here, we use probabilistic techniques for our generative classifiers. In a second part of the section, we will introduce our new measures for knowledge understanding."}, {"heading": "3.1 Probabilistic Classifier CMM", "text": "The classifiers we are using here are probabilistic classifiers. That is, for a given, specific Ddimensional input sample x\u2032 we want to compute the posterior distribution p(c|x\u2032), i.e., the probabilities for class membership (with classes c \u2208 C) given the input sample x\u2032. To minimize the risk of classification errors we may then select the class with the highest posterior probability (cf. the principle of winner-takes-all). Generally, the posterior distribution p(c|x) can be determined by (cf. [22])\np(c|x) = p(x|c)p(c) p(x) = p(c) \u2211 i\u2208I p(x|c, i)p(i|c) p(x) , (1)\nwhere p(c) is a multinomial distribution with parameters that are termed class priors and conditional densities p(x|c, i) that are called components. I is the overall set of components in this model. In an approach with separate sets of components for the different classes (i.e., we uniquely assign the components to classes, p(c|i) \u2208 {0, 1}), we can conclude that we only have to sum up over all components assigned to a certain class to determine the class posteriors:\np(c|x) = \u2211\ni\u2208Ic p(x|ic)p(ic) p(x) , (2)\nwhere Ic (with Ic \u2282 I) is the set of components assigned to class c \u2208 C. Note that\np(x) = \u2211 c\u2208C \u2211 ic\u2208Ic p(x|ic)p(ic) = \u2211 i\u2208I p(x|i)p(i). (3)\nThe parameters \u03c0i of the multinomial distribution p(i) are called mixing coefficients. Altogether, we have a classifier consisting of a linear combination of components, where each component is described by a distribution p(x|c, i). To keep the notation uncluttered, a specific component is identified by a single index i \u2208 I in the following (i.e., p(x|i)) if its class is not relevant. Which kind of density functions can we use for the components? Considering a Ddimensional sample x it may have Dcont continuous (i.e., real-valued) dimensions (attributes, features) and Dcat = D \u2212Dcont categorical ones. Without loss of generality we arrange these dimensions such that\nx = (x1, . . . , xDcont\ufe38 \ufe37\ufe37 \ufe38 continuous ,xDcont+1, . . . ,xD\ufe38 \ufe37\ufe37 \ufe38 categorical ). (4)\nNote that we italicize x when we refer to single dimensions. The continuous part of this vector xcont = (x1, . . . , xDcont) with xd \u2208 R for all d \u2208 {1, . . . , Dcont} is modeled with a multivariate normal (i.e., Gaussian) distribution with center \u00b5 and covariance matrix \u03a3. That is, with det(\u00b7) denoting the determinant of a matrix we use the model\nN (xcont|\u00b5,\u03a3) = 1 (2\u03c0) Dcont 2 det(\u03a3) 1 2 exp\n( \u22121\n2 (xcont \u2212 \u00b5)T\u03a3\u22121(xcont \u2212 \u00b5)\n) (5)\nFor many practical applications, the use of Gaussian components or Gaussian mixture models (GMM) can be motivated by the generalized central limit theorem (cf., e.g., [15]) which roughly states that the sum of independent samples from any distribution with finite mean and variance converges to a normal distribution as the sample size goes to infinity. Moreover, any continuous distribution can be approximated arbitrarily well by a finite mixture of normal densities [45].\nFor categorical dimensions we use a 1-of-Kd coding scheme where Kd is the number of possible categories of attribute xd (d \u2208 {Dcont + 1, . . . , D}). The value of such an attribute is represented by a vector xd = (xd1 , . . . , xdKd ) with xdk = 1 if xd belongs to category k and xdk = 0 otherwise.\nThe classifier models categorical dimensions by means of a special case of multinomial distributions. That is, for an input dimension (attribute) xd \u2208 {xDcont+1, . . . ,xD} we use\nM(xd|\u03b4d) = Kd\u220f k=1 (\u03b4dk) xdk (6)\nwith parameters \u03b4d = (\u03b4d1 , . . . , \u03b4dKd ) and restrictions \u03b4dk \u2265 0 and \u2211Kd\nk=1 \u03b4dk = 1. We assume that the categorical dimensions are mutually independent and that there are no dependencies between the categorical and the continuous dimensions. Then, the component densities p(x|i) are defined by\np(x|i) = N (xcont|\u00b5i,\u03a3i) \u00b7 D\u220f\nd=Dcont+1\nM(xd|\u03b4di). (7)\nWith this approach it is possible to model multivariate categorical data sets arbitrarily well despite any independence assumption concerning the categorical variables. Other dimensions (i.e., other feature types that are not continuous or categorical) can be handled by relying on other (hybrid) distributions, which are not considered yet. Beside that, for some feature types conversions under certain assumptions are possible. For instance, rational (Q) and integer (N) dimensions might be interpreted as nearly continuous under appropriate conditions (e.g., if their support set is large enough). Other attributes (e.g., integers with few values actually occurring) can be categorized as preprocessing step before the CMM is trained.\nIn Section 3.1.2 we compare CMM to some other classifier paradigms regarding classification accuracy. In general, these probabilistic generative classifiers offer some other interesting features: risk minimizing cost functions can easily be combined with probabilistic outputs, class priors can be compensated, different models can easily be combined, or anomaly detection techniques can be defined [6, 18]."}, {"heading": "3.1.1 Training of CMM", "text": "How can the various parameters of the classifier be determined? For a given training set X with N samples xn it is assumed that the xn are independent and identically distributed (i.i.d.). First, X is split into C subsets Xc, each containing all samples of the corresponding class c, i.e.,\nXc = {xn|xn belongs to class c}. (8)\nFor each Xc, a mixture model is trained. Here, we perform the parameter estimation by means of a technique called variational Bayesian inference (VI) which realizes the Bayesian idea of regarding the model parameters as random variables whose distributions must be trained [22]. This approach has two important advantages over other methods such as a standard expectation maximization (EM) approach. First, the estimation process is more robust, i.e., it avoids \u201ccollapsing\u201d components, so-called singularities when the variance in one or more directions vanishes. Second, VI optimizes the number of components on its own by pruning irrelevant components, i.e., those that are not considered to notably contribute to the overall density (which is reflected by a reasonably small mixing coefficient). Therefore we start the training with a relatively large number of components and rely on VI to automatically reduce the number of components to a sufficient number. That is, the number of model components is not a critical parameter that has to be considered by a user. For a more detailed discussion on Bayesian inference, and, particularly, VI see [6]. More details concerning the training algorithm can be found in [22]. At this point, we have obtained parameter estimates for the p(x|c, i) and p(i|c), cf. Eq. (1). The parameters for the class priors p(c) are estimated with\n\u03b3c = |Xc| |X| (9)\nwhere | \u00b7 | denotes the cardinality of a set. It should be noted that most of the measures defined in this article are independent from the specific training technique, e.g., VI or EM."}, {"heading": "3.1.2 Classification Performance of CMM Compared to 1NN, SVM, and Decision Trees", "text": "To confirm that CMM are comparable to other classification paradigms regarding their classification accuracy and, thus, sufficiently meaningful to define measures for knowledge understanding, we evaluate their performance on 21 benchmark data sets: phoneme, satimage (real-world data from the UCL Machine Learning Group [64]); australian, credit_a, credit_g, ecoli, glass, heart, iris, pendigits, pima, quality, seeds, segment, vehicle, vowel, wine, yeast (real-world data from the UCI Machine Learning Repository [3]); clouds (artificial data from the UCI Machine Learning Repository [3]); ripley (artificial data proposed in [56]); and two_moons (own, artificial data set). Table 1 contains general information about all data sets, e.g., number of samples, feature (attribute) types, and class distribution.\nThe performance evaluation for all classifiers is done in the same way. At first, 20% of the samples are taken from each data set to function as an independent test set. On the remaining 80%, a parameter search is done using grid search combined with a 4-fold cross validation. The parameters that perform best over all folds are then selected to determine the performance on the test set. The results on the independent test sets, achieved with the same parameters as for the training sets, are set out in Table 2. We can see that CMM perform comparably well.\nOne substantial property of CMM is that the actual number of components in the mixture model has not a strong influence on the decision boundary as long as there is a sufficient number of components in the model. Fig. 2 demonstrates this exemplarily on one of the used data sets (two_moons). Here, a CMM is trained with VI in such a way that the components of the trained models \u201ccover\u201d smaller areas of the input space which leads to models with more components\u20146 components in Fig. 2 (a) up to 12 components in Fig. 2 (c). The images show that the decision boundaries of the resulting CMM classifiers are quite similar.\nWe exploit this property by initiating our VI training with a higher number of initial components and relying on its pruning capabilities."}, {"heading": "3.1.3 Rule Extraction From CMM", "text": "In some applications it is desirable to extract human-readable rules from a trained classifier. This is possible with our classifier if it is parametrized accordingly. For the moment, we focus on a single component p(x|i) and omit the identifying index i. Restrictions concerning the covariance matrix \u03a3 or the number of categories are not necessary. However, to extract a rule set from the CMM, the premises for the continuous input dimensions are obtained from their univariate projections on the axes. This implies that the information about dependencies between different dimensions (i.e., given by the covariances) are lost. Thus, we recommend to force the covariance matrices \u03a3 to be diagonal. Then, the multivariate Gaussians N (xcont|\u00b5,\u03a3) can be split into a product consisting of Dcont univariate Gaussians \u03c8d with d = 1, . . . , Dcont. In this case, the univariate Gaussians \u03c8d are identical to the projections of the corresponding input dimensions. The categorical dimensions can be simplified by considering only categories whose probability is above a certain case-dependent threshold. A rule set (where each component is represented by exactly one rule) can then be derived from the classifier as follows: the variables are the input variables xd (components of the Ddimensional input variable x) and the output variable c which represents the class label. The rule premises are realized by conjunctions of the univariate Gaussians \u03c8d (i.e., their density \u03c8d(xd)) and conjunctions of settings for the categorical dimensions. The settings themselves are written as disjunctions of those categories that have probabilities above a specified threshold. The conclusions (i.e., the class memberships) are given by one class, which is derived from the class affiliation of the component in the premise. The rules have a form which is very similar to that of fuzzy rules, but they have a rather different (i.e., probabilistic) interpretation.\nFig. 3 gives an example for a CMM that is used to extract a rule set. The classifier is embedded in a three dimensional input space with two classes: blue crosses (+) and green circles (\u25e6). The first two dimensions x1 and x2 are continuous and modeled by three bivariate Gaussians. Their mean values (\u00b5i) are described by large crosses (+) and the surrounding ellipses are level curves (i.e., surfaces of constant density) of the Gaussians with shapes defined by their covariance matrix \u03a3i. Since the covariance matrices \u03a3i are only non-zero on their diagonal, all ellipses are axes-oriented. The corresponding projections onto the axes are also illustrated (i.e., the univariate Gaussians). Note, that the projections marked as high result from two Gaussians, since the top right component (in green) is covered by the other components (blue) in both continuous dimensions. The third dimension x3 is categorical with categories A (green), B (blue), and C (red). The distributions of categories are illustrated by the histograms next to every component. Here, only categories with a probability strictly greater than the average 1/Kd are considered in order to simplify the resulting rules. Altogether, the following rule set can be extracted from the classifier in Fig. 3:\nif x1 is low and x2 is high and (x3 is A or x3 is B) then c = blue if x1 is high and x2 is high and x3 is C then c = green if x1 is high and x2 is low then c = blue\nOf course, this readability is accomplished at the cost of a limited modeling capability of the classifier (i.e., diagonal covariance matrices and simplified categorical dimensions) and should, thus, only be used if the application requires this kind of human-readable rules."}, {"heading": "3.2 Measures for Knowledge Understanding", "text": "In the following, we describe seven objective measures that can be used to assess the knowledge incorporated in CMM in an objective way. We will use the term rule instead of component only if we wish to explicitly extract human-readable rules from the CMM. In this article, we focus on measures for single components (i.e., rules). Measures for overall classifiers could easily be\nobtained by averaging measures for components or by considering worst cases etc. Then, it would also be possible to compare different classifiers, for instance. In addition, classical performance measures (e.g., classification error on independent test data) should also be used. If the class a component belongs to is not relevant for a measure, the component is identified by a single index i \u2208 {1, . . . , I} with I = |I|, e.g., p(x|i). Otherwise, it is explicitly denoted by p(x|c, i). If sample data are needed to evaluate a measure, we use the training data for that purpose."}, {"heading": "3.2.1 Informativeness", "text": "A component of the CMM is regarded as being very informative if it is assumed to describe a really distinct kind of process \u201cgenerating\u201d data. To assess the informativeness of a component numerically, we use the Hellinger distance Hel(p(x), q(x)) of two probability densities p(x) and q(x) (cf. [6]). Compared to other statistical distance measures such as the Kullback-Leibler divergence (cf. Section 3.2.5), the Hellinger distance has the advantage of being bounded between 0 and 1. It is defined by\nHel(p(x), q(x)) = \u221a 1\u2212 BC(p(x), q(x)), (10)\nwhere BC(p(x), q(x)) denotes the Bhattacharyya coefficient :\nBC(p(x), q(x)) = \u222b \u221a p(x) \u00b7 q(x) dx (11)\nor for discrete distributions with definition range X :\nBC(p(x), q(x)) = \u2211 x\u2208X \u221a p(x) \u00b7 q(x) (12)\nHel(p(x), q(x)) is 0 if p(x) and q(x) are identical and it approaches 1 when p(x) places most of its probability mass in regions where q(x) assigns a probability of nearly zero and vice versa.\nUsing Fubini\u2019s theorem (cf. [25, 1]) and considering the discrete nature of the multinomial distribution, the Bhattacharyya coefficient of two components i and i\u2032 as defined in Eq. (7) can be computed by\nBC(p(x|i), p(x|i\u2032)) = \u222b \u221a\nN (xcont|\u00b5i,\u03a3i)N (xcont|\u00b5i\u2032 ,\u03a3i\u2032) dxcont\n\u00b7 D\u220f\nd=Dcont+1\nKd\u2211 k=0 \u221a M(ek|\u03b4di)M(ek|\u03b4di\u2032 )\n(13)\nwith ek being the k-th row of the Kd \u00d7Kd identity matrix (i.e., we are iterating over all Kd possible categories of dimension d). The integral can be solved analytically for Gaussians yielding\u222b \u221a\nN (xcont|\u00b5i,\u03a3i)N (xcont|\u00b5i\u2032 ,\u03a3i\u2032) dxcont\n= exp ( \u22121\n8 (\u00b5i \u2212 \u00b5i\u2032)T\n( \u03a3i + \u03a3i\u2032\n2\n)\u22121 (\u00b5i \u2212 \u00b5i\u2032) ) \u00b7 4 \u221a\ndet(\u03a3i) \u00b7 det(\u03a3i\u2032)\u221a det(\n\u03a3i+\u03a3i\u2032 2 )\n. (14)\nThe informativeness of a component i is then determined by its Hellinger distance calculated with respect to the \u201cclosest\u201d component i\u2032 (i\u2032 6= i) contained in the CMM:\ninfo(i) := min i\u2032 6=i\n( Hel ( p(x|i\u2032), p(x|i) )) . (15)\nTo assess the informativeness of the overall classifier a weighted average of the informativeness values of all components may be used. The weights can be determined depending on the respective mixing coefficients and the class priors. The run-time complexity required to evaluate the informativeness of one component is\nO ( I \u00b7 ( D3cont +Dcat \u00b7 max\nd\u2208{1,...,Dcont} {Kd}\n)) (16)\nsince for each other component in the classifier we have to compute the determinant of its covariance matrix and iterate over all categories of its categorical dimensions."}, {"heading": "3.2.2 Uniqueness", "text": "The knowledge contained in the components of a CMM should be unambiguous. This is measured by the uniqueness of a component i which reflects to which degree samples belonging to different classes are covered by that component. Let \u03c1i(xn) denote the responsibility of component i for the generation of sample xn, i.e.,\n\u03c1i(xn) := p(xn|i)p(i) p(xn) . (17)\nThen, we define the uniqueness of component i by\nuniq(i) :=\n\u2211 xn\u2208Xc\n\u03c1i(xn)\u2211 xn\u2208X \u03c1i(xn) . (18)\nTo evaluate the uniqueness of a whole classifier we may, e.g., compute the weighted average of the individual components\u2019 uniqueness values (e.g., using the mixing coefficients as weights). The run-time complexity required to evaluate the uniqueness of a component is O(N \u00b7 I \u00b7 (D3cont +Dcat)) since we have to evaluate the density of each sample for the whole CMM to get the responsibilities which involves a matrix multiplication and the iteration over all categorical dimensions."}, {"heading": "3.2.3 Importance", "text": "The importance of a component measures the relative weight of a component within the classifier. In general, either a small or a large number of components may be regarded as \u201cimportant\u201d, depending on a concrete application. Here, a component i is regarded as very important if its mixing coefficient \u03c0i is far above the average mixing coefficient \u03c0 = 1I . To scale the importance of a component to the interval [0, 1] we additionally use a boundary function that is comprised of two linear functions. One projects all mixing coefficients that are smaller than the average to the interval [0, 0.5] and the other one maps all mixing coefficients that are larger than the average to [0.5, 1]. The importance of component i is then computed by\nimpo(i) := { \u03c0i 2\u03c0 , \u03c0i \u2264 \u03c0 1\u2212\u03c0i 2(\u03c0\u22121) + 1, \u03c0i > \u03c0 . (19)\nAgain, to evaluate the importance with regard to a whole classifier we may, e.g., use a weighted average of the importance values of the contained components.\nThe run-time complexity required to evaluate the importance of one component is O(1) since it just involves constant time computations with the mixing coefficient of the component."}, {"heading": "3.2.4 Discrimination", "text": "The discrimination measure evaluates the influence of a component i on the decision boundary\u2014 and, thus, on the classification performance\u2014of the overall classifier. To calculate the discrimination of component i we create a second CMM by removing i from the original CMM and re-normalizing the mixing coefficients of the remaining components. Then, we compare the achieved classification error on training data (or on test data where available) of the original CMM (Ewith) to the classification error of the CMM without component i (Ewithout):\ndisc(i) := Ewithout \u2212 Ewith. (20)\nIf required by the concrete application (e.g., in some medical applications false positives are acceptable whereas false negatives could be fatal), it is also possible to use more detailed measures such as sensitivity, specificity, or precision to assess the discrimination capability of a component. We also may consider the class priors.\nThe run-time complexity required to evaluate the discrimination of one component is O(N \u00b7 I \u00b7 |C| \u00b7D3cont) since for each training sample we have to evaluate the density of each component for each class."}, {"heading": "3.2.5 Representativity", "text": "The performance of a generative classifier also depends on how well it models the data. This kind of fitness is determined by the continuous dimensions only where we explicitly assume that the data distribution can be modeled by a mixture of Gaussians. Since for categorical data it is always possible to find a distribution that perfectly models the data (cf. determination of a histogram), the representativity measure only considers the continuous dimensions xcont. As the true underlying distribution q(xcont) is unknown for real-world data sets, it must be approximated with a non-parametric density estimation technique, e.g., a standard Parzen window density estimator:\nq(xcont) = 1\nN \u2211 xn\u2208X\n1\n(2\u03c0h2) Dcont 2\n\u00b7 exp ( \u2212\u2016x\ncont \u2212 xcontn \u20162 2 \u00b7 h2\n) . (21)\nHere, h is a user-defined parameter. Suitable values of h depend on the data set X [6], but there are a number of heuristics to estimate h. In [7], for instance, h is set to the average distance of\nthe ten nearest neighbors for each sample, averaged over the whole data set. This non-parametric approach makes no assumptions about the functional form of the underlying distribution. The calculation of the representativity of the classifier is based on a divergence measure. Here, we rely on a variant of the Kullback-Leibler divergence KL(p1(x)||p2(x)) which for two distributions p1(x) and p2(x) is defined as\nKL(p1(x)||p2(x)) = \u2212 \u222b p1(x) ln p2(x)\np1(x) dx. (22)\nOther divergence measures, for example, Jensen\u2013Shannon divergence, could also be used. Since the measure is not symmetric, i.e., KL(p1(x)||p2(x)) 6= KL(p2(x)||p1(x)), we use a variant which we denote KL2(p1(x), p2(x)). It is given by:\nKL2(p1(x), p2(x)) = 1\n2\n( KL(p1(x)||p2(x)) + KL(p2(x)||p1(x)) ) . (23)\nThis measure always takes values greater than or equal to 0 and only vanishes if p1(x) and p2(x) are identical. It would also be possible to use the Hellinger distance Hel(p(xcont), q(xcont)), cf. Eq. (10), to measure the distance between the true data distribution q(xcont) and the model p(xcont), cf. Eq. (3) and (5). However, since this measure is restricted to the unit interval, errors of the approximation in Eq. (24) may result in values close to 1 and, thus, the difference between the models with and without a certain component is typically close to zero. This effect is alleviated by using KL2 which has no upper bound and, thus, the influence of a component on the representativity of the model can be quantified with reasonable precision even in the presence of approximation errors.\nFor the given distribution types Eq. (23) cannot be solved analytically. However, given a dataset X whose elements are distributed according to p1(x), the KL2 divergence can be approximated as follows (cf. the concept of importance sampling)\nK\u0302L2(p1(x), p2(x)) \u2248 1\n2N ( \u2211 xn\u2208X ln p1(xn) p2(xn) + \u2211 xn\u2208X p2(xn) p1(xn) ln p2(xn) p1(xn) ) . (24)\nRepresentativity evaluates the influence of a component on the \u201cgoodness of fit\u201d of the model regarding the data distribution. To calculate the representativity of component i we again create a second CMM without i as described for the discrimination measure. Then, we compare the symmetric K\u0302L2 distance of the CMM with (pwith(xcont)) and without (pwithout(xcont)) component i:\nrepr(i) := K\u0302L2(pwithout(xcont), q(xcont))\u2212 K\u0302L2(pwith(xcont), q(xcont)). (25)\nTo assess the representativity of a whole classifier we could again use a weighted average of the representatvity values of the contained components. Alternatively we could directly use\nK\u0302L2(pwith(x cont), q(xcont)) (26)\nas an assessment of the representativity of the whole classifier. The run-time complexity required to evaluate the representativity of one component is O(N \u00b7 I \u00b7 D3cont) since we have to evaluate the density of each sample which involves a matrix multiplication."}, {"heading": "3.2.6 Uncertainty", "text": "The parameters of the CMM are estimated in a Bayesian fashion (cf. Section 3.1), i.e., they are regarded as random variables whose distributions must be determined from sample data. For the parameters of the categorical dimensions \u03b4di the corresponding distributions are Dirichlet\ndistributions. The centers \u00b5i and covariance matrices \u03a3i of the continuous dimensions are modeled with Gaussian-Inverse-Wishart distributions [6]. To quantify the uncertainty of these parameter estimates we use the entropy H [6]. The entropy of a continuous random variable x with density p(x) is\nH[x] = \u2212 \u222b p(x) ln p(x) dx. (27)\nThe more \u201cconcentrated\u201d the probability mass of the distribution p(x) is, i.e., the more certain the parameter estimate is, the lower is the entropy H[x]. Its value is unbounded and can even be negative for continuous variables. It is also possible to measure the uncertainty for every model parameter individually. In this work, however, we want to calculate an aggregated value quantifying the uncertainty of the estimation of component i. Thus, we sum up the entropies of the corresponding parameter distributions:\nunce(i) := H[\u00b5i,\u03a3i] + D\u2211\nd=Dcont+1\nH[\u03b4di ] (28)\nThis summation of entropies naturally arises from the joint parameter distribution due to the assumption that the continuous dimensions are independent from the categorical ones and the categorical dimensions are mutually independent. Since the absolute value of the entropy values of the categorical dimensions depends on the number of categories and the sum of entropies of all categorical dimensions depends on the number of dimensions in applications where those numbers are very different it may be desirable to weight the summands in Eq. (28) with factors depending on the number of categories per dimension and/or the number of categorical dimensions. Note that we do not consider the mixing coefficients here. There is only one distribution for the whole classifier and, thus, the same entropy value would be added to every component. The entropies of the mentioned distributions are\nH[\u00b5i,\u03a3i] = \u2212 Dcont\n2 log \u03b2i +\nDcont(Dcont + 1)\n4 log\n\u03c0 4 \u2212 Dcont 2 log(det(W i)) + Dcont(\u03bdi + 1) 2\n\u2212 \u03bdi +Dcont + 2 2 Dcont\u2211 d=1 \u03c8 ( \u03bdi + 1\u2212 d 2 ) + Dcont\u2211 d=1 log \u0393 ( \u03bdi + 1\u2212 d 2 ) (29)\nH[\u03b4di ] = \u2212 Kd\u2211 k=1 ( dki \u2212 1) ( \u03c8( dki)\u2212 \u03c8(\u0302di) ) \u2212 lnC( di), (30)\ncf. [6, 36], for instance. Here di = ( d1i , . . . , dKdi) is the parameter vector of the second-order Dirichlet distribution for categorical dimension di and\n\u0302di = Kd\u2211 k=1 dki , (31)\nC( di) = \u0393(\u0302di)\n\u0393( d1i) . . .\u0393( dKdi ) . (32)\n\u0393(\u00b7) is the gamma function defined by\n\u0393(x) = \u222b \u221e 0 tx\u22121 exp(\u2212t) dt, (33)\nand \u03c8(\u00b7) is the digamma function defined by (cf. [6])\n\u03c8(x) = d\ndx ln \u0393(x). (34)\nIn contrast to our previous measures this measure uses the second-order distributions which arise during VI training (cf. Section 3.1.1) as distributions over the actual parameters of our CMM. More details on training models using second-order distributions can be found in [6, 22, 20].\nTo evaluate the uncertainty of a whole classifier we could again compute a weighted average of the uncertainty values of the contained components using the mixing coefficients. Additionally, we might take the uncertainty of the second-order distribution which models the mixing coefficients into account. This uncertainty is modeled by the variances of these distributions. The run-time complexity required to evaluate the uncertainty of one component is\nO ( D3cont +Dcat \u00b7 max\nd\u2208{1,...,Dcat} {Kd}\n) , (35)\nsince we have to compute the determinant of a matrix for the continuous dimensions and sum over the categories of all categorical dimensions."}, {"heading": "3.2.7 Distinguishability", "text": "For the rule set represented by the classifier to be easily understandable for a human expert each two rules should be easily distinguishable. Since categorical dimensions are easily distinguishable by humans we only consider the continuous dimensions here. To measure the distinguishability of two components i and i\u2032 for dimension d \u2208 {1, . . . , Dcont} we first project those components onto d. This yields two univariate Gaussians \u03d5di and \u03d5di\u2032 . In order to restrict our distinguishability measure to the unit interval we omit the normalizing coefficients of the projected Gaussians. This also makes sure that strongly overlapping Gaussians which are not easily distinguishable for a human are assigned a low distinguishability value. To assess the distinguishability of the two components i and i\u2032 with regard to dimension d we now use the intersection point of the two projected Gaussians that lies between their centers which results in\ndsngd(i, i \u2032) := 1\u2212 exp\n( \u2212 (\u00b5di \u2212 \u00b5di\u2032 ) 2\n2(\u03c3di + \u03c3di\u2032 ) 2\n) (36)\nwith dsng(i, i\u2032) \u2208 (0, 1]. We now aggregate those values over all components i\u2032 different from i and over all continuous dimensions d to get the overall distinguishability for component i as\ndsng(i) = min d\u2208{1,...,Dcont} mini\u2208I i 6=i\u2032 {dsngd(i, i\u2032)}  . (37) Values higher than 0.1, for example, could be regarded as desirable, depending on the application. Fig. 4 shows an example of the assessment of the distinguishability of two exemplary Gaussians.\nThe run-time complexity required to evaluate the distinguishability of one component is O(Dcont \u00b7 I) since for each continuous dimension we have to iterate over all components of the classifier to compute the intersection points of the projected Gaussians. The distinguishability of a set of rules (i.e. the whole classifier) is defined to be the distinguishability of the rule with the lowest distinguishability. When evaluating the complete rule set two additional factors may be considered regarding the interpretability of the rule set by a human expert. First, the number I of rules in the rule set should be low because we argue that a classifier with few rules is easier to understand than a classifier with many rules. Second, the number of different terms \u03c4d for each dimension d should be low. For a categorical dimension \u03c4d is given by the number of different categories with non-zero probability forming the disjunctions. To simplify categorical dimensions only categories with a probability above a certain threshold \u03c9 > 0 may be considered (cf. Section 3.1.3). Let Kdi be the set of categories of dimension d of component i. Then we have\n\u03c4d = \u2223\u2223\u2223\u2223\u2223 I\u22c3 i=1 Kdi \u2223\u2223\u2223\u2223\u2223 . (38) For a continuous dimension d the number of different univariate Gaussians \u03d5di is counted. To decide whether two Gaussians should be regarded as being different or not, we use the Hellinger distance (cf. Eq. (10)) of the two Gaussians. The distance should be clearly below a fixed threshold, such as 0.01, for example, to regard two Gaussians as being identical:\n\u03c4d = I\u2211 i=1 hdi (39)\nwhere\nhdi =\n{ 0, if there is a \u03d5di\u2032 with i < i\n\u2032 and Hel(\u03d5di , \u03d5di\u2032 ) \u2264 0.01 1, otherwise . (40)\nThe threshold can be varied in applications depending on the degree of distinguishability that is desired. To assess a complete rule set we could average the number of different terms for all categorical and continuous dimensions. For the classifier shown in Fig. 3 we get \u03c41 = 2, \u03c42 = 2, and \u03c43 = 3 resulting in \u03c4 = 2.3, for example."}, {"heading": "4 Case Studies", "text": "In this section we investigate the properties of the proposed measures in detail by (1) analyzing correlations between these measures and run-times, and by (2) conducting four case studies that demonstrate how the measures can be used in practical applications. These case studies show how measures can be used in the learning phase of the classifier, to improve the classification performance in an active learning setting, while evaluating the trained classifier before using it on-line, and finally during the application phase of the classifier. These case studies can be seen as illustrative examples; many other ways of using the measures are possible."}, {"heading": "4.1 Correlation Analysis and Run-Time", "text": "In the first set of experiments we analyze correlations between the seven measures to investigate their dependencies. Additionally, we measure the run-time of all evaluations of our measures required to compute those correlations to get some empirical evidence to back up the theoretical run-times stated in Section 3.2. For this experiment we again use the 21 benchmark data sets.\nTable 3 shows Spearmans\u2019s rank correlations computed for our seven interestingness measures and averaged over the 21 data sets. Correlations that are statistically significant on a significance level of 0.05 are highlighted with bold typeface in Table 3. Those significant correlations are:\n\u2022 Informativeness is positively correlated to uniqueness. This means that isolated components do not cover many samples. Furthermore, components that are located relatively close to other components of a CMM cover a majority of the samples. This may be due to the fact that many of the benchmark data sets consist of real-world data for which the normal distribution assumption may not be fully satisfied. This leads to clusters being modeled by multiple components rather than by one single component. It is also consistent with importance being negatively correlated to uncertainty.\n\u2022 Importance is positively correlated to discrimination, i.e., components that cover many samples also have a high impact on the decision boundary of the classifier.\n\u2022 Uncertainty is negatively correlated to importance which means that components covering only very few samples yield only very little additional information which expressed through the entropy yields the uncertainty.\n\u2022 Representativity is positively correlated to importance. This is due to the fact that components that have a high mixing coefficient in comparison with the other components of the model also have a high influence on the overall density function which is evaluated by the representativity measure.\nFor several combinations of interestingness measures the values of the correlation coefficients are quite. Especially, the distinguishability measure has no significant correlation (considering Spearman\u2019s correlation coefficient) with any of the other measures. This shows that the distinguishability measure evaluates completely different aspects of the components of a CMM classifier than the other measures. For example, a component can have a high distinguishability while still having either a small or big influence on the decision boundary as measured by discrimination. Apart from the distinguishability, the pair of measures with the lowest correlation is discrimination and uniqueness. If a component has a very high uniqueness it mostly \u201ccovers\u201d samples of one class and if its uniqueness is very low it \u201ccovers\u201d samples of several classes. In both cases the discrimination of the component, i.e. its influence on the decision boundary, can either be very high or low. This just depends on the position of the component with regard to its neighboring components and the decision boundary and notably not on the uniqueness of the component. Altogether, the fact that there are only a few significant correlations between our objective interestingness measures indicates that our measures cover many different aspects of knowledge understanding.\nWe also measured the empirical run-times it took to compute the results given in Table 3. The results are presented in Table 4 and were obtained using a dedicated Linux machine with an Intel Core i7 2600 CPU running at 3.4 GHz. The run-time measurements are predominantly a rough\nguideline to estimate how long it takes to evaluate individual measures in actual applications. In our experimental implementation we optimize many computations and rely on as many caches as possible. For example, inverse covariance matrices required to evaluate the densities are already pre-computed by our training algorithm. Thus, in contrast to what is suggested by the theoretical run-time complexities of our interestingness measures as stated in Section 3.2, the empirical run-times are not dominated by matrix operations but rather by the number of samples in each data set. For small data sets such as seeds, ripley, iris, or heart, the evaluations of all measures require less than a second. In comparison, the pendigits and quality data sets require the highest run-times up to a few hours. With regard to the measures, representativity generally takes the longest to evaluate, followed by discrimination and uniqueness. The evaluation of the other measures is very fast."}, {"heading": "4.2 Knowledge Acquisition Phase: Controlling the Training of a Classifier", "text": "In this set of experiments we use some of our measures, importance, representativity, and uncertainty, to control the VI based training process of a classifier. The training consists of three steps, an E step, an M step and an additional pruning step, which are consecutively executed until a convergence criterion is met. In the E step, samples are gradually assigned to components of the classifier and in the M step, the parameters of the classifier are updated according to the samples (gradually) assigned to them. In the pruning step, unnecessary components are removed from the classifier. Here, we focus on the pruning step and consider three different pruning methods:\n1. Resp: This method is similar to the \u201ctraditional\u201d pruning method used in VI training: A component is removed from the classifier if the sum of its un-normalized responsibilities (cf. Eq. (17)) is below a certain threshold. Often, this threshold is chosen as 1 which means that a component is removed if it is effectively \u201cresponsible\u201d for less than one sample of the training data. A threshold of 2.5 means the component is \u201cresponsible\u201d for less than 2.5 samples and so on. A threshold of 0 is also possible in which case no pruning is done.\n2. Impo: Based on the importance measure (cf. Section 3.2.3) this pruning method uses the mixing coefficient of a component to decide whether or not to prune it. However, in\ncontrast to Resp not only one component is considered but the mixing coefficient is set in relation to the average mixing coefficient of the classifier (or, in other words, the number of components the classifier currently consists of). Thus, a component is removed if its importance is below a certain threshold. Since importance values lie in the interval [0, 1], thresholds in that interval may be considered. Values close to 0 result in slow pruning and values close to 1 lead to fast pruning. A threshold of 0.5 means that all components whose mixing coefficient is below average get pruned.\n3. Unct: In contrast to Resp and Impo this method does not rely on mixing coefficients or responsibilities but takes a completely different approach. It considers the uncertainty of a component (cf. Section 3.2.6) and removes all components whose uncertainty value lies above a certain threshold. The uncertainty of a component is unbounded and it is, thus, more difficult to determine a suitable threshold. However, the following examples provide good starting points for choosing a threshold value.\nFig. 5 visualizes classification errors on test data, numbers of resulting classifier components, and numbers of required VI training steps for the three different pruning methods. We used 4 of the benchmark data sets from Section 4.1 for this experiment: australian, clouds, phoneme, and satimage. Additionally, we added the page_blocks data set from the UCI Machine Learning Repository [3] which consists of real-world data. It can be seen that the Resp method yields the best results for low thresholds in the range [1, 3] but still requires a larger number of VI steps than the other methods. In contrast to Resp, the Impo pruning method leads to a faster decrease in the number of required VI steps while resulting in a similar test error and number of components. The threshold used in the Unct method is rather sensitive to the type of data set used. The australian data set contains categorical dimensions in addition to continuous ones and this leads to rather different entropy values and, thus, different thresholds. In conclusion, we can state that importance and uncertainty can both be used as alternatives to responsibilities for a pruning step of the VI training algorithm by reducing the number of required VI steps and thus making the training process faster. However, further research into an automatic determination of the pruning threshold and the behavior of the pruning methods on different data sets is necessary."}, {"heading": "4.3 Knowledge Analysis Phase: Ranking Components of a Trained Classifier", "text": "In this experiment we analyze the components of a trained classifier with our measures in order to help a potential user of the classifier in understanding the components or rules extracted from those components (cf. Section 3.1.3). We trained a classifier on the phoneme data set from the UCL Machine Learning Group [64] using the restriction to diagonal covariance matrices to enable rule extraction. Fig. 6 shows the resulting classifier. Components are colored according to their class densities and their opacity is dependent on their mixing coefficient. The background of the plot is colored according to the posterior probabilities of the classifier. The black, solid line is the decision boundary. In Table 5, some of our measures are evaluated for the components depicted in Fig. 6. Other measures were omitted for the sake of brevity. From the distinguishability measure we can deduce that components 3 and 6 are those which can least easily be distinguished. This can be confirmed by looking at Fig. 6 which shows that those components overlap to a great extent. Components 5 and 7 can best be distinguished from others when projected to the coordinate axes which is obvious especially in case of component 5 because it is well separated from all other components. The second measure evaluated in Table 5 is discrimination. Since the discrimination value of component 3 is negative, we know that the classification performance could be increased if we removed this component from the classifier. In this case, the classification error on test data decreases from 21.46% to 21.18%. Also, components 4 and 5 are not very important for the classification decision since they are \u201cdominated\u201d by component 2 as we can see from Fig. 6.\nThe components that are most important for the classification decision are components 1 and 6. Those are the only green colored components in an area otherwise dominated by the blue components 3, 7, and 8. The informativeness measure info in Table 5 yields components 4 and especially 5 as those with the greatest distance to all other components. In fact, they have nearly no overlap with other components in Fig. 6. The least informative components are components 3 and 6 since they almost totally overlap. The final measure we evaluated in Table 5 is uniqueness. The components with the highest uniqueness are components 2, 4, and in particular 5 which means they mostly cover samples from one class. Components 3 and 8 have the lowest uniqueness which means they cover samples from both classes. Interestingly, component 6 which nearly completely overlaps with component 3 has a higher uniqueness value.\nThe example shows that the proposed measures can easily be used to analyze a trained classifier. It should be emphasized that the evaluation of a classifier does also work as described in case of higher dimensional input spaces where looking at a two-dimensional visualization would not help very much. Depending on the application, different goals could be achieved by ranking the components of a classifier using our approach. If the aim was to reduce the number of components, for example, one might consider removing component 8 since it received the worst evaluation by four out of seven measures (not all shown here for the sake of brevity): it has the lowest uniqueness, representativity, and importance, and the highest uncertainty."}, {"heading": "4.4 Knowledge Analysis in Active Learning", "text": "The pool-based active learning (PAL) [41] paradigm repetitively asks users (generally termed as oracles) to provide label information for unlabeled data, e.g., in order to train a classifier based on those data. PAL is based on the assumption that unlabeled data can be acquired at no (or low) costs, whereas retrieving label information is very costly. Therefore, at the beginning of a PAL learning cycle a large set of unlabeled data and only a small set of labeled data are available. Based on these data a classifier is trained (here a CMM), which is further on used to\nThe PAL process starts with a generative (probabilistic) model as described in Section 3.1 which can be trained in an unsupervised way. During the PAL process, more and more labels become available that can be considered to train a CMM. In general, the underlying generative model remains unchanged during the PAL process. In [54], this process is extended with a transductive learner, which aims at updating the underlying model using the uniqueness measure, which determines how ambiguous the knowledge modeled by each component is. If the uniqueness value determined for a component is smaller than a predefined threshold, the component is considered to be \u201cdisputed\u201d between two or more classes. In this case, the samples for which the component is responsible (cf. Eq. 17) are determined, a sample-based classifier called Resp-kNN [52] is trained and used to transductively label the underlying samples. Then, a new CMM is trained and the resulting components fused with \u201cnon-disputed\u201d components, where necessary(for details of the fusion technique, see [24]). Consequently, the information provided by the uniqueness measure allows for iteratively improving a CMM during a PAL process. For further information regarding PAL with a transductive learner see [54]. This extension of the PAL process is also shown in Fig. 7.\nFor the case study presented in this section, we embed the probabilistic generative model in a kernel function of a support vector machine (SVM) as described in [55]. In this case study, the uniqueness measure is only applied once, after a final PAL cycle, to emphasize on the possible performance improvement. We have conducted an experiment with the MNIST [46] handwritten digits data set, which consists of a training set of 60 000 and a test set of 10 000 gray-scaled images of handwritten digits (10 classes). We reduced the size of the input dimensions from 784 to 34 (continuous dimensions) by applying a principle component analysis, thus keeping 90% of the total variance. Furthermore, the data has been z-normalized. The PAL process started with an initially labeled set of 40 samples and selected, based on the 4DS [53] selection strategy (corresponds to Q in Fig. 7) five\nsamples in each learning cycle of the PAL process. We decided to actively select 2 575 samples (i.e., the PAL stopped when the size of the labeled set L reached this number). The actively trained classifier (here SVM) had been parametrized only using the training set.\nAfter the PAL process stopped, an adequate number of labeled samples was available. Thus, it was possible to improve the underlying density model by means of the uniqueness measure as sketched above. Then, the density model can better exploit the structure information contained in the labeled samples. Fig. 8 illustrates the learning curve of the SVM on the test set. Moreover, it emphasizes that by employing the uniqueness measure the classification error is reduced by about a half.\nThis promising result indicates a possible improvement of the standard PAL process. In regular time intervals (i.e., cycles of the PAL process) the underlying density model should be evaluated by means of the uniqueness measure and, if necessary, refined."}, {"heading": "4.5 Knowledge Application Phase: Detecting Novel Processes", "text": "Our last set of experiments deals with the application phase of a classifier. We consider the task of novelty detection, i.e., the task of detecting the need of new components that model newly occurring processes in the input space which were not known during training time (cf. [43]). Our example is based on intrusion detection data from the 1999 KDD cup [63]. Specifically, we use data of the attack types \u201cneptune\u201d, \u201csmurf\u201d, \u201cipsweep\u201d, and \u201csatan\u201d. We re-sampled the data to be\nable to consider longer time spans. Each of the four data sets we constructed starts with 54 000 samples of background traffic (large variety but without any attacks). Then, an attack phase starts which lasts until time step 198 000. During the attack phase samples that represent the respective attack are present in a ratio of 1:3. Finally, we continue with more samples only drawn from background traffic to observe how the novelty detectors react to the end of an attack. The classifiers were trained with a separate training data set consisting of 5 000 samples of background traffic only. Our goal is to detect the need for a new component that models data originating from an attack to the network. This shows that intrusion detection systems that detect new kinds of attacks at run-time can be build by relying on our proposed interestingness measures.\nIn order to achieve that goal we evaluate the representativity of the overall classifier after each newly observed sample. The Parzen window estimator of the representativity measure that is used for the evaluation of repr is computed from a sliding window of the most recent 5 000 samples. In Fig. 9 (a), representativity values of the classifiers are shown. For the sake of visualization, the representativity values were normalized to mean 0 and variance 1. During the initial phase, which contains only background traffic, the representativity values of all classifiers are high. When an attack starts at time step 54 000, the representativity values decrease until the sliding window is filled with data that contains 25% of attack samples. Now, the representativity values stay small until the attack to the network stops at time step 198 000. Then, the representativities of the classifiers rise again to high values, similar to the ones in the initial phase.\nFor comparison, Fig. 9 (b) contains results obtained by the novelty detection technique called \u03c72 novelty which is proposed in [23]. This technique measures whether or not each newly observed sample lies within a certain region around any of the classifier components and accumulates reward or punishment values accordingly. Fig. 9 (b) depicts the accumulated novelty values. For the sake of visualization those values were also normalized to mean 0 and variance 1.\nIn conclusion we can state that our representativity measure can be used to detect the need for new components in a classifier. The raw representativity is more sensitive to novel samples than the \u03c72 novelty measure which is more robust, but it is certainly worth to investigate techniques that combine the advantages of both."}, {"heading": "5 Conclusion and Outlook", "text": "In this article, we presented an approach to support or even automate the process of knowledge understanding, an important data mining step. However, the proposed measures should be seen as a first step into that direction, as not all aspects of real world applications could be considered yet. With knowledge understanding we refer to the task of analyzing the knowledge extracted from data in order to gather meta-knowledge (knowledge about knowledge). This can either be done offline (here referred to as \u201cunderstanding\u201d) or online (here referred to as \u201cexperience\u201d) by applying the knowledge. Depending on a concrete application, all or only a part of the measures may be useful. Also it may be preferable to assess continuous and categorical dimensions separately. The measures proposed in this article are objective measures but they have some relation to subjective interestingness measures. For example, informativeness is clearly related to novelty, a \u201cconventional\u201d interestingness measure, since if a rule is quite informative it may also be the case that the user regards this rule as providing a highly novel kind of knowledge. Uniqueness can be seen as being related to understandability, because a high uniqueness value implies that a rule is only associated with a single class, thus making it better understandable. The importance and discrimination measures are both reflecting the usefulness of a component by expressing its relative weight in the classifier and the influence on the decision boundary. Another measure related to usefulness is our uncertainty: A high value states that the parameters of the process underlying the resulting component cannot be precisely determined, which decreases its usefulness of the component. The last measure representativity, which expresses how well a component models the data, has a positive effect on the understandability of the overall model. We defined various measures for CMM (classifier based on a mixture model), a generative, probabilistic classifier. In practical applications, this classifier can be used in combination with discriminative classifiers such as support vector machines (SVM). As we have shown in [21], the probabilistic classifiers with continuous input dimensions are functionally equivalent to certain kinds of support vector machines (with Gaussian kernels), radial basis function neural networks, fuzzy classifiers (with Gaussian membership functions and sum-prod inference), nonlinear Fisher discrimination techniques, relevance vector machines, or direct kernel machines. Thus, some of the measures defined here could be adapted to these kinds of classifiers, as well. As the semantics underlying the knowledge in these classifiers is very different (cf., e.g., membership degrees in fuzzy systems to probabilities in our generative classifiers), this idea has to be investigated in detail. Another option is to use the probabilistic model contained in our CMM in other classifiers, for instance, as we have already shown in [55], to create a data dependent kernel function for SVM. In this article, several use cases were defined and investigated to demonstrate the value and applicability of the proposed measures. We have shown that these measures may be used to control the training process of the classifier (for more details on this problem see also [28]), to analyze the knowledge contained in a trained classifier, and to support tasks such as novelty detection in the application phase of the classifier. Other applications are possible, e.g., pruning at the end of a training process, extraction and ranking of rules contained in a classifier (see, e.g., [20]), concept drift or obsoleteness detection. In our future work, we will also focus on measures for a quantification of experience gained by applying the knowledge extracted from data (e.g., by assessing its usefulness as in [19, 18]), extending the VI training techniques to apply them to large data sets, and on applications of the measures, e.g., in the field of collaborative intrusion detection in cyber-physical systems [29].\nFurther, we will investigate how our measures can be adjusted to suite other types of distributions (i.e., distributions that are required for other attribute types) as well."}, {"heading": "Acknowledgment", "text": "This work was supported by the German Research Foundation (DFG) under grant SI 674/9-1 (project CYPHOC)."}], "references": [{"title": "Online, http://www.encyclopediaofmath.org/index.php?title= Fubini_theorem&oldid=33052, (last access: 13.05.2016", "author": ["Fubini theorem"], "venue": null, "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2016}, {"title": "Toward the next generation of recommender systems: A survey of the state-of-the-art and possible extensions", "author": ["G. Adomavicius", "A. Tuzhilin"], "venue": "IEEE Transactions on Knowledge and Data Engineering", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2005}, {"title": "Rough-fuzzy MLP: modular evolution, rule generation, and evaluation", "author": ["M. Atzmueller", "J. Baumeister", "F. Puppe"], "venue": "Proceedings of the 15th International Conference of Declarative Programming and Knowledge Management", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2004}, {"title": "Evaluating the novelty of text-mined rules using lexical knowledge", "author": ["S. Basu", "R.J. Mooney", "K.V. Pasupuleti", "J. Ghosh"], "venue": "Proceedings of the 7th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2001}, {"title": "Pattern Recognition and Machine Learning", "author": ["C.M. Bishop"], "venue": null, "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2006}, {"title": "Novelty detection and neural network validation", "author": ["C. Bishop"], "venue": "IEE Proceedings \u2013 Vision, Image, and Signal Processing 141(4),", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 1994}, {"title": "Interestingness \u2013 directing analyst focus to significant data", "author": ["M. Bourassa", "J. Fug\u00e8re", "D. Skillicorn"], "venue": "Proceedings of the 2011 European Intelligence and Security Informatics Conference (EISIC", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2011}, {"title": "Domain-driven data mining: Challenges and prospects", "author": ["L. Cao"], "venue": "IEEE Transactions on Knowledge and Data Engineering", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2010}, {"title": "Flexible frameworks for actionable knowledge discovery", "author": ["L. Cao", "Y. Zhao", "H. Zhang", "D. Luo", "C. Zhang", "E. Park"], "venue": "IEEE Transactions on Knowledge and Data Engineering", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2010}, {"title": "LIBSVM: a library for support vector machines. ACM transactions on intelligent systems and technology", "author": ["C. Chang", "C. Lin"], "venue": null, "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2012}, {"title": "Nearest neighbor pattern classification", "author": ["T.M. Cover", "P.E. Hart"], "venue": "IEEE Transactions on Information Theory 13(1),", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 1967}, {"title": "Visualizing interestingness", "author": ["F. Di Fiore"], "venue": "(eds.) Data Mining III. WIT Press,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2002}, {"title": "A systematic approach to the assessment of fuzzy association rules. Data Mining and Knowledge Discovery", "author": ["D. Dubois", "E. Hullermeier", "H. Prade"], "venue": null, "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2006}, {"title": "Pattern Classification", "author": ["R.O. Duda", "P.E. Hart", "D.G. Stork"], "venue": null, "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2001}, {"title": "Introduction to scientific data mining: Direct kernel methods and applications", "author": ["M.J. Embrechts", "B. Szymanski", "K. Sternickel"], "venue": null, "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2005}, {"title": "Knowledge discovery and data mining: Towards a unifying framework", "author": ["U.M. Fayyad", "G. Piatetsky-Shapiro", "P. Smyth"], "venue": "Proceedings of the 2nd International Conference on Knowledge Discovery and Data Mining (KDD", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 1996}, {"title": "Techniques for Knowledge Acquisition in Dynamically Changing Environments", "author": ["D. Fisch", "M. J\u00e4nicke", "E. Kalkowski", "B. Sick"], "venue": "ACM Transactions on Autonomous and Adaptive Systems", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2011}, {"title": "Learning from others: Exchange of classification rules in intelligent distributed systems", "author": ["D. Fisch", "M. J\u00e4nicke", "E. Kalkowski", "B. Sick"], "venue": "Artificial Intelligence 187\u2013188,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2012}, {"title": "In your interest: Objective interestingness measures for a generative classifier", "author": ["D. Fisch", "E. Kalkowski", "B. Sick", "S.J. Ovaska"], "venue": "Proceedings of the 3rd International Conference on Agents and Artificial Intelligence (ICAART", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2011}, {"title": "So near and yet so far: New insight into properties of some well-known classifier paradigms", "author": ["D. Fisch", "B. K\u00fchbeck", "B. Sick", "S.J. Ovaska"], "venue": "Information Sciences", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2010}, {"title": "Training of radial basis function classifiers with resilient propagation and variational Bayesian inference", "author": ["D. Fisch", "B. Sick"], "venue": "Proceedings of the International Joint Conference on Neural Networks (IJCNN", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2009}, {"title": "Intelligente technische Systeme mit der F\u00e4higkeit zum kollaborativen Wissenserwerb. No. 1 in Intelligent Embedded Systems, kassel university", "author": ["D. Fisch"], "venue": null, "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2012}, {"title": "Knowledge fusion for probabilistic generative classifiers with data mining applications", "author": ["D. Fisch", "E. Kalkowski", "B. Sick"], "venue": "Knowledge and Data Engineering, IEEE Transactions on 26(3),", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2014}, {"title": "Sugli integrali multipli", "author": ["G. Fubini"], "venue": "Rend. Acc. Naz. Lincei 16,", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 1907}, {"title": "Entailment and symmetry in confirmation measures of interestingness", "author": ["D.H. Glass"], "venue": "Information Sciences 279,", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2014}, {"title": "Properties of rule interestingness measures and alternative approaches to normalization of measures", "author": ["S. Greco", "R. S\u0142owi\u0144ski", "I. Szcz\u0119ch"], "venue": "Information Sciences 216,", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2012}, {"title": "Self-adapting generative modeling techniques \u2013 a basic building block for many organic computing techniques", "author": ["C. Gruhl"], "venue": "Organic Computing Doctoral Colloquium", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 2014}, {"title": "A concept for securing cyber-physical systems with organic computing techniques", "author": ["J. H\u00e4hner", "S. Rudolph", "S. Tomforde", "D. Fisch", "B. Sick", "N. Kopal", "A. Wacker"], "venue": "Proceedings of the 26th International Conference on Architecture of Computing Systems (ARCS", "citeRegEx": "29", "shortCiteRegEx": "29", "year": 2013}, {"title": "A unified view of objective interestingness measures", "author": ["C. Hebert", "B. Cremilleux"], "venue": "Machine Learning and Data Mining in Pattern Recognition,", "citeRegEx": "30", "shortCiteRegEx": "30", "year": 2007}, {"title": "Evaluating collaborative filtering recommender systems", "author": ["J.L. Herlocker", "J.A. Konstan", "L.G. Terveen", "J.T. Riedl"], "venue": "ACM Transactions on Information Systems", "citeRegEx": "31", "shortCiteRegEx": "31", "year": 2004}, {"title": "Evaluation of interestingness measures for ranking discovered knowledge", "author": ["R.J. Hilderman", "H.J. Hamilton"], "venue": "Proceedings of the 5th Pacific-Asia Conference on Knowledge Discovery and Data Mining (PAKDD", "citeRegEx": "32", "shortCiteRegEx": "32", "year": 2001}, {"title": "Knowledge Discovery and Measures of Interest", "author": ["R.J. Hilderman", "H.J. Hamilton"], "venue": null, "citeRegEx": "33", "shortCiteRegEx": "33", "year": 2001}, {"title": "A study on interestingness measures for associative classifiers", "author": ["M. Jalali-Heravi", "O. Zaiane"], "venue": "Proceedings of the 2010 ACM Symposium on Applied Computing", "citeRegEx": "34", "shortCiteRegEx": "34", "year": 2010}, {"title": "Interestingness of frequent itemsets using Bayesian networks as background knowledge", "author": ["S. Jaroszewicz", "D.A. Simovici"], "venue": "Proceedings of the 10th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD", "citeRegEx": "35", "shortCiteRegEx": "35", "year": 2004}, {"title": "Variational Bayes for continuous hidden Markov models and its application to active learning", "author": ["S. Ji", "B. Krishnapuram", "L. Carin"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence", "citeRegEx": "36", "shortCiteRegEx": "36", "year": 2006}, {"title": "Extracting interpretable fuzzy rules from rbf networks", "author": ["Y. Jin", "B. Sendhoff"], "venue": "Neural Processing Letters 17(2),", "citeRegEx": "37", "shortCiteRegEx": "37", "year": 2003}, {"title": "Association rule pruning based on interestingness measures with clustering", "author": ["S. Kannan", "R. Bhaskaran"], "venue": "International Journal of Computer Science Issues 6(1),", "citeRegEx": "38", "shortCiteRegEx": "38", "year": 2009}, {"title": "Automatic rule generation for protein annotation with the c4.5 data mining algorithm applied on swiss-prot", "author": ["E. Kretschmann", "W. Fleischmann", "R. Apweiler"], "venue": "Bioinformatics 17(10),", "citeRegEx": "39", "shortCiteRegEx": "39", "year": 2001}, {"title": "On selecting interestingness measures for association rules: User oriented description and multiple criteria decision aid", "author": ["P. Lenca", "P. Meyer", "B. Vaillant", "S. Lallich"], "venue": "Computing, Artificial Intelligence and Information Management 184,", "citeRegEx": "40", "shortCiteRegEx": "40", "year": 2008}, {"title": "A sequential algorithm for training text classifiers", "author": ["D.D. Lewis", "W.A. Gale"], "venue": "Proceedings of the Seventeenth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR", "citeRegEx": "41", "shortCiteRegEx": "41", "year": 1994}, {"title": "Probabilistic measures for interestingness of deviations \u2013 a survey", "author": ["A. Masood", "S. Ouaguenouni"], "venue": "International Journal of Artificial Intelligence & Applications (IJAIA)", "citeRegEx": "42", "shortCiteRegEx": "42", "year": 2013}, {"title": "Measuring interestingness \u2013 perspectives on anomaly detection", "author": ["A. Masood", "S. Soong"], "venue": "Computer Engineering and Intelligent Systems", "citeRegEx": "43", "shortCiteRegEx": "43", "year": 2013}, {"title": "A survey of interestingness measures for knowledge discovery", "author": ["K. McGarry"], "venue": "The Knowledge Engineering Review 20(1),", "citeRegEx": "44", "shortCiteRegEx": "44", "year": 2005}, {"title": "Finite Mixture Models", "author": ["G. McLachlan", "D. Peel"], "venue": null, "citeRegEx": "45", "shortCiteRegEx": "45", "year": 2000}, {"title": "Unexpectedness as a measure of interestingness in knowledge discovery", "author": ["B. Padmanabhan", "A. Tuzhilin"], "venue": "Decision Support Systems 27(3),", "citeRegEx": "47", "shortCiteRegEx": "47", "year": 1999}, {"title": "On characterization and discovery of minimal unexpected patterns in rule discovery", "author": ["B. Padmanabhan", "A. Tuzhilin"], "venue": "IEEE Transactions on Knowledge and Data Engineering", "citeRegEx": "48", "shortCiteRegEx": "48", "year": 2006}, {"title": "The interestingness of deviations", "author": ["G. Piatetsky-Shapiro", "C. Matheus"], "venue": "Proceedings of the AAAI-94 Workshop on Knowledge Discovery in Databases (KDD", "citeRegEx": "49", "shortCiteRegEx": "49", "year": 1994}, {"title": "Fast training of support vector machines using sequential minimal optimization. In: Advances in Kernel Methods - Support Vector Learning", "author": ["J.C. Platt"], "venue": "MIT Press (January", "citeRegEx": "50", "shortCiteRegEx": "50", "year": 1998}, {"title": "Programs for Machine Learning", "author": ["R. Quinlan"], "venue": null, "citeRegEx": "51", "shortCiteRegEx": "51", "year": 1993}, {"title": "Resp-knn: A semi-supervised classifier for sparsely labeled data in the field of organic computing", "author": ["T. Reitmaier", "A. Calma"], "venue": "Organic Computing Doctoral Dissertation Colloquium", "citeRegEx": "52", "shortCiteRegEx": "52", "year": 2014}, {"title": "Let us know your decision: Pool-based active training of a generative classifier with the selection strategy 4DS", "author": ["T. Reitmaier", "B. Sick"], "venue": "Information Sciences 230,", "citeRegEx": "53", "shortCiteRegEx": "53", "year": 2013}, {"title": "Transductive active learning \u2013 a new semi-supervised learning approach based on iteratively refined generative models to capture structure in data", "author": ["T. Reitmaier", "A. Calma", "B. Sick"], "venue": "Information Sciences 293,", "citeRegEx": "54", "shortCiteRegEx": "54", "year": 2015}, {"title": "The responsibility weighted mahalanobis kernel for semi-supervised training of support vector machines for classification", "author": ["T. Reitmaier", "B. Sick"], "venue": "Information Sciences 323,", "citeRegEx": "55", "shortCiteRegEx": "55", "year": 2015}, {"title": "Pattern recognition and neural networks. http://www.stats.ox.ac.uk/pub/ PRNN/, [Online] (last access", "author": ["B. Ripley"], "venue": null, "citeRegEx": "56", "shortCiteRegEx": "56", "year": 2016}, {"title": "Interestingness measures for association rules based on statistical validity", "author": ["I. Shaharanee", "F. Hadzic", "T. Dillon"], "venue": "Knowledge-Based Systems", "citeRegEx": "57", "shortCiteRegEx": "57", "year": 2011}, {"title": "A framework for evaluating knowledge-based interestingness of association rules. Fuzzy Optimization and Decision Making", "author": ["B. Shekar", "R. Natarajan"], "venue": null, "citeRegEx": "58", "shortCiteRegEx": "58", "year": 2004}, {"title": "In pursuit of interesting patterns with undirected discovery of exception rules", "author": ["E. Suzuki"], "venue": "Progress in Discovery Science,", "citeRegEx": "59", "shortCiteRegEx": "59", "year": 2002}, {"title": "Evaluation and ordering of rules extracted from feedforward networks", "author": ["I. Taha", "J. Ghosh"], "venue": "Proceedings of the International Conference on Neural Networks", "citeRegEx": "60", "shortCiteRegEx": "60", "year": 1997}, {"title": "Behavior-based clustering and analysis of interestingness measures for association rule mining. Data Mining and Knowledge Discovery", "author": ["C. Tew", "C. Giraud-Carrier", "K. Tanner", "S. Burton"], "venue": null, "citeRegEx": "61", "shortCiteRegEx": "61", "year": 2013}, {"title": "Knowledge evaluation: Other evaluations: usefulness, novelty, and integration of interesting news measures", "author": ["A. Tuzhilin"], "venue": "Handbook of Data Mining and Knowledge Discovery", "citeRegEx": "62", "shortCiteRegEx": "62", "year": 2002}, {"title": "Interestingness measures in rule mining: A valuation", "author": ["J. Vashishtha"], "venue": "Garima Int. Journal of Engineering Research and Applications 4(7),", "citeRegEx": "65", "shortCiteRegEx": "65", "year": 2014}, {"title": "What do people want in microblogs? measuring interestingness of hashtags in twitter", "author": ["J. Weng", "E.P. Lim", "Q. He", "C.K. Leung"], "venue": "Proceedings of the 10th International Conference on Data Mining (ICDM", "citeRegEx": "66", "shortCiteRegEx": "66", "year": 2010}], "referenceMentions": [{"referenceID": 14, "context": "in [16].", "startOffset": 3, "endOffset": 7}, {"referenceID": 14, "context": "Figure 1: The data mining pyramid (adopted from [16]).", "startOffset": 48, "endOffset": 52}, {"referenceID": 20, "context": "We use classifiers based on probabilistic mixture models (CMM, see [22, 6]) which can be used in many DM applications.", "startOffset": 67, "endOffset": 74}, {"referenceID": 4, "context": "We use classifiers based on probabilistic mixture models (CMM, see [22, 6]) which can be used in many DM applications.", "startOffset": 67, "endOffset": 74}, {"referenceID": 4, "context": "CMM are trained from data samples using expectation maximization or related techniques such as variational Bayesian approaches [6].", "startOffset": 127, "endOffset": 130}, {"referenceID": 18, "context": "[20]).", "startOffset": 0, "endOffset": 4}, {"referenceID": 15, "context": "Data mining (DM), today often used as a synonym of knowledge discovery in databases (KDD), deals with the \u201cthe nontrivial process of identifying valid, novel, potentially useful, and ultimately understandable patterns in data\u201d [17].", "startOffset": 227, "endOffset": 231}, {"referenceID": 30, "context": ", [32, 33, 44, 58, 62]).", "startOffset": 2, "endOffset": 22}, {"referenceID": 31, "context": ", [32, 33, 44, 58, 62]).", "startOffset": 2, "endOffset": 22}, {"referenceID": 42, "context": ", [32, 33, 44, 58, 62]).", "startOffset": 2, "endOffset": 22}, {"referenceID": 55, "context": ", [32, 33, 44, 58, 62]).", "startOffset": 2, "endOffset": 22}, {"referenceID": 59, "context": ", [32, 33, 44, 58, 62]).", "startOffset": 2, "endOffset": 22}, {"referenceID": 60, "context": ", on so-called information criteria or on data-based measurement techniques (see [65] for an overview).", "startOffset": 81, "endOffset": 85}, {"referenceID": 38, "context": ", [40, 57, 61, 38, 42, 34]).", "startOffset": 2, "endOffset": 26}, {"referenceID": 54, "context": ", [40, 57, 61, 38, 42, 34]).", "startOffset": 2, "endOffset": 26}, {"referenceID": 58, "context": ", [40, 57, 61, 38, 42, 34]).", "startOffset": 2, "endOffset": 26}, {"referenceID": 36, "context": ", [40, 57, 61, 38, 42, 34]).", "startOffset": 2, "endOffset": 26}, {"referenceID": 40, "context": ", [40, 57, 61, 38, 42, 34]).", "startOffset": 2, "endOffset": 26}, {"referenceID": 32, "context": ", [40, 57, 61, 38, 42, 34]).", "startOffset": 2, "endOffset": 26}, {"referenceID": 2, "context": ", [4, 30, 37, 14]).", "startOffset": 2, "endOffset": 17}, {"referenceID": 28, "context": ", [4, 30, 37, 14]).", "startOffset": 2, "endOffset": 17}, {"referenceID": 35, "context": ", [4, 30, 37, 14]).", "startOffset": 2, "endOffset": 17}, {"referenceID": 12, "context": ", [4, 30, 37, 14]).", "startOffset": 2, "endOffset": 17}, {"referenceID": 2, "context": "Sometimes, several measures are combined [4, 60].", "startOffset": 41, "endOffset": 48}, {"referenceID": 57, "context": "Sometimes, several measures are combined [4, 60].", "startOffset": 41, "endOffset": 48}, {"referenceID": 25, "context": "In [27], interestingness measures for rules are evaluated with regard to the four properties of confirmation, locality, symmetry, and a property termed Ex1 which assures that conclusively confirmatory rules are assigned a higher interestingness value than non-conclusively confirmatory rules and vice versa.", "startOffset": 3, "endOffset": 7}, {"referenceID": 25, "context": "Especially, in [27] weaker forms of the locality property and EX1 are proposed together with a new interestingness measure that fulfills the weaker forms of those properties.", "startOffset": 15, "endOffset": 19}, {"referenceID": 24, "context": "Two further measures are proposed in [26] and compared to the measure from [27] in terms of the properties they fulfill.", "startOffset": 37, "endOffset": 41}, {"referenceID": 25, "context": "Two further measures are proposed in [26] and compared to the measure from [27] in terms of the properties they fulfill.", "startOffset": 75, "endOffset": 79}, {"referenceID": 24, "context": "Also, in [26] two new Bayesian confirmation measures for the evaluation of rule interestingness measures are proposed.", "startOffset": 9, "endOffset": 13}, {"referenceID": 6, "context": "An interestingness measure that does not evaluate rules or classifier components but individual samples is presented in [8].", "startOffset": 120, "endOffset": 123}, {"referenceID": 61, "context": "In [66], a support vector machine is used to learn interestingness values of Twitter hashtags from data.", "startOffset": 3, "endOffset": 7}, {"referenceID": 46, "context": "Subjective measures consider additional knowledge about the application and information about the data miner such as skills and needs [49, 47].", "startOffset": 134, "endOffset": 142}, {"referenceID": 44, "context": "Subjective measures consider additional knowledge about the application and information about the data miner such as skills and needs [49, 47].", "startOffset": 134, "endOffset": 142}, {"referenceID": 3, "context": "Examples for subjective measures are novelty [5, 17], usefulness [17], understandability [17], actionability [10, 9], and unexpectedness [13, 35, 59, 48].", "startOffset": 45, "endOffset": 52}, {"referenceID": 15, "context": "Examples for subjective measures are novelty [5, 17], usefulness [17], understandability [17], actionability [10, 9], and unexpectedness [13, 35, 59, 48].", "startOffset": 45, "endOffset": 52}, {"referenceID": 15, "context": "Examples for subjective measures are novelty [5, 17], usefulness [17], understandability [17], actionability [10, 9], and unexpectedness [13, 35, 59, 48].", "startOffset": 65, "endOffset": 69}, {"referenceID": 15, "context": "Examples for subjective measures are novelty [5, 17], usefulness [17], understandability [17], actionability [10, 9], and unexpectedness [13, 35, 59, 48].", "startOffset": 89, "endOffset": 93}, {"referenceID": 8, "context": "Examples for subjective measures are novelty [5, 17], usefulness [17], understandability [17], actionability [10, 9], and unexpectedness [13, 35, 59, 48].", "startOffset": 109, "endOffset": 116}, {"referenceID": 7, "context": "Examples for subjective measures are novelty [5, 17], usefulness [17], understandability [17], actionability [10, 9], and unexpectedness [13, 35, 59, 48].", "startOffset": 109, "endOffset": 116}, {"referenceID": 11, "context": "Examples for subjective measures are novelty [5, 17], usefulness [17], understandability [17], actionability [10, 9], and unexpectedness [13, 35, 59, 48].", "startOffset": 137, "endOffset": 153}, {"referenceID": 33, "context": "Examples for subjective measures are novelty [5, 17], usefulness [17], understandability [17], actionability [10, 9], and unexpectedness [13, 35, 59, 48].", "startOffset": 137, "endOffset": 153}, {"referenceID": 56, "context": "Examples for subjective measures are novelty [5, 17], usefulness [17], understandability [17], actionability [10, 9], and unexpectedness [13, 35, 59, 48].", "startOffset": 137, "endOffset": 153}, {"referenceID": 45, "context": "Examples for subjective measures are novelty [5, 17], usefulness [17], understandability [17], actionability [10, 9], and unexpectedness [13, 35, 59, 48].", "startOffset": 137, "endOffset": 153}, {"referenceID": 1, "context": ", in a content-based approach or a collaborative filtering approach) [2, 31].", "startOffset": 69, "endOffset": 76}, {"referenceID": 29, "context": ", in a content-based approach or a collaborative filtering approach) [2, 31].", "startOffset": 69, "endOffset": 76}, {"referenceID": 4, "context": "A generative classifier aims at modeling the processes underlying the \u201cgeneration\u201d of the data [6].", "startOffset": 95, "endOffset": 98}, {"referenceID": 20, "context": "[22])", "startOffset": 0, "endOffset": 4}, {"referenceID": 13, "context": ", [15]) which roughly states that the sum of independent samples from any distribution with finite mean and variance converges to a normal distribution as the sample size goes to infinity.", "startOffset": 2, "endOffset": 6}, {"referenceID": 43, "context": "Moreover, any continuous distribution can be approximated arbitrarily well by a finite mixture of normal densities [45].", "startOffset": 115, "endOffset": 119}, {"referenceID": 4, "context": "In general, these probabilistic generative classifiers offer some other interesting features: risk minimizing cost functions can easily be combined with probabilistic outputs, class priors can be compensated, different models can easily be combined, or anomaly detection techniques can be defined [6, 18].", "startOffset": 297, "endOffset": 304}, {"referenceID": 16, "context": "In general, these probabilistic generative classifiers offer some other interesting features: risk minimizing cost functions can easily be combined with probabilistic outputs, class priors can be compensated, different models can easily be combined, or anomaly detection techniques can be defined [6, 18].", "startOffset": 297, "endOffset": 304}, {"referenceID": 20, "context": "Here, we perform the parameter estimation by means of a technique called variational Bayesian inference (VI) which realizes the Bayesian idea of regarding the model parameters as random variables whose distributions must be trained [22].", "startOffset": 232, "endOffset": 236}, {"referenceID": 4, "context": "For a more detailed discussion on Bayesian inference, and, particularly, VI see [6].", "startOffset": 80, "endOffset": 83}, {"referenceID": 20, "context": "More details concerning the training algorithm can be found in [22].", "startOffset": 63, "endOffset": 67}, {"referenceID": 53, "context": "2 Classification Performance of CMM Compared to 1NN, SVM, and Decision Trees To confirm that CMM are comparable to other classification paradigms regarding their classification accuracy and, thus, sufficiently meaningful to define measures for knowledge understanding, we evaluate their performance on 21 benchmark data sets: phoneme, satimage (real-world data from the UCL Machine Learning Group [64]); australian, credit_a, credit_g, ecoli, glass, heart, iris, pendigits, pima, quality, seeds, segment, vehicle, vowel, wine, yeast (real-world data from the UCI Machine Learning Repository [3]); clouds (artificial data from the UCI Machine Learning Repository [3]); ripley (artificial data proposed in [56]); and two_moons (own, artificial data set).", "startOffset": 704, "endOffset": 708}, {"referenceID": 47, "context": "With the training algorithm Sequential Minimal Optimization (SMO) [50], Support Vector Machines (SVM) are one of the most widely used discriminative approaches for pattern recognition tasks.", "startOffset": 66, "endOffset": 70}, {"referenceID": 9, "context": "Consequently, we train SVM with the frequently used libsvm library using RBF (or Gaussian) kernels [11].", "startOffset": 99, "endOffset": 103}, {"referenceID": 48, "context": "5 [51], for instance.", "startOffset": 2, "endOffset": 6}, {"referenceID": 37, "context": ", [39]).", "startOffset": 2, "endOffset": 6}, {"referenceID": 10, "context": "Even though it only classifies with respect to the nearest neighbor, it can be shown that for N \u2192\u221e the maximum classification error is at most twice the maximum of a classifier that yields the best possible classification [12].", "startOffset": 222, "endOffset": 226}, {"referenceID": 4, "context": "[6]).", "startOffset": 0, "endOffset": 3}, {"referenceID": 23, "context": "[25, 1]) and considering the discrete nature of the multinomial distribution, the Bhattacharyya coefficient of two components i and i\u2032 as defined in Eq.", "startOffset": 0, "endOffset": 7}, {"referenceID": 0, "context": "[25, 1]) and considering the discrete nature of the multinomial distribution, the Bhattacharyya coefficient of two components i and i\u2032 as defined in Eq.", "startOffset": 0, "endOffset": 7}, {"referenceID": 0, "context": "To scale the importance of a component to the interval [0, 1] we additionally use a boundary function that is comprised of two linear functions.", "startOffset": 55, "endOffset": 61}, {"referenceID": 4, "context": "Suitable values of h depend on the data set X [6], but there are a number of heuristics to estimate h.", "startOffset": 46, "endOffset": 49}, {"referenceID": 5, "context": "In [7], for instance, h is set to the average distance of", "startOffset": 3, "endOffset": 6}, {"referenceID": 4, "context": "The centers \u03bci and covariance matrices \u03a3i of the continuous dimensions are modeled with Gaussian-Inverse-Wishart distributions [6].", "startOffset": 127, "endOffset": 130}, {"referenceID": 4, "context": "To quantify the uncertainty of these parameter estimates we use the entropy H [6].", "startOffset": 78, "endOffset": 81}, {"referenceID": 4, "context": "[6, 36], for instance.", "startOffset": 0, "endOffset": 7}, {"referenceID": 34, "context": "[6, 36], for instance.", "startOffset": 0, "endOffset": 7}, {"referenceID": 4, "context": "[6])", "startOffset": 0, "endOffset": 3}, {"referenceID": 4, "context": "More details on training models using second-order distributions can be found in [6, 22, 20].", "startOffset": 81, "endOffset": 92}, {"referenceID": 20, "context": "More details on training models using second-order distributions can be found in [6, 22, 20].", "startOffset": 81, "endOffset": 92}, {"referenceID": 18, "context": "More details on training models using second-order distributions can be found in [6, 22, 20].", "startOffset": 81, "endOffset": 92}, {"referenceID": 0, "context": "Since importance values lie in the interval [0, 1], thresholds in that interval may be considered.", "startOffset": 44, "endOffset": 50}, {"referenceID": 0, "context": "It can be seen that the Resp method yields the best results for low thresholds in the range [1, 3] but still requires a larger number of VI steps than the other methods.", "startOffset": 92, "endOffset": 98}, {"referenceID": 39, "context": "4 Knowledge Analysis in Active Learning The pool-based active learning (PAL) [41] paradigm repetitively asks users (generally termed as oracles) to provide label information for unlabeled data, e.", "startOffset": 77, "endOffset": 81}, {"referenceID": 51, "context": "In [54], this process is extended with a transductive learner, which aims at updating the underlying model using the uniqueness measure, which determines how ambiguous the knowledge modeled by each component is.", "startOffset": 3, "endOffset": 7}, {"referenceID": 49, "context": "17) are determined, a sample-based classifier called Resp-kNN [52] is trained and used to transductively label the underlying samples.", "startOffset": 62, "endOffset": 66}, {"referenceID": 22, "context": "Then, a new CMM is trained and the resulting components fused with \u201cnon-disputed\u201d components, where necessary(for details of the fusion technique, see [24]).", "startOffset": 151, "endOffset": 155}, {"referenceID": 51, "context": "For further information regarding PAL with a transductive learner see [54].", "startOffset": 70, "endOffset": 74}, {"referenceID": 52, "context": "For the case study presented in this section, we embed the probabilistic generative model in a kernel function of a support vector machine (SVM) as described in [55].", "startOffset": 161, "endOffset": 165}, {"referenceID": 50, "context": "The PAL process started with an initially labeled set of 40 samples and selected, based on the 4DS [53] selection strategy (corresponds to Q in Fig.", "startOffset": 99, "endOffset": 103}, {"referenceID": 41, "context": "[43]).", "startOffset": 0, "endOffset": 4}, {"referenceID": 21, "context": "Figure 9: Novelty detection with our representativity measure (top) in comparison to the \u03c72 novelty detector as described in [23] (bottom) on 4 intrusion detection data sets.", "startOffset": 125, "endOffset": 129}, {"referenceID": 21, "context": "9 (b) contains results obtained by the novelty detection technique called \u03c72 novelty which is proposed in [23].", "startOffset": 106, "endOffset": 110}, {"referenceID": 19, "context": "As we have shown in [21], the probabilistic classifiers with continuous input dimensions are functionally equivalent to certain kinds of support vector machines (with Gaussian kernels), radial basis function neural networks, fuzzy classifiers (with Gaussian membership functions and sum-prod inference), nonlinear Fisher discrimination techniques, relevance vector machines, or direct kernel machines.", "startOffset": 20, "endOffset": 24}, {"referenceID": 52, "context": "Another option is to use the probabilistic model contained in our CMM in other classifiers, for instance, as we have already shown in [55], to create a data dependent kernel function for SVM.", "startOffset": 134, "endOffset": 138}, {"referenceID": 26, "context": "We have shown that these measures may be used to control the training process of the classifier (for more details on this problem see also [28]), to analyze the knowledge contained in a trained classifier, and to support tasks such as novelty detection in the application phase of the classifier.", "startOffset": 139, "endOffset": 143}, {"referenceID": 18, "context": ", [20]), concept drift or obsoleteness detection.", "startOffset": 2, "endOffset": 6}, {"referenceID": 17, "context": ", by assessing its usefulness as in [19, 18]), extending the VI training techniques to apply them to large data sets, and on applications of the measures, e.", "startOffset": 36, "endOffset": 44}, {"referenceID": 16, "context": ", by assessing its usefulness as in [19, 18]), extending the VI training techniques to apply them to large data sets, and on applications of the measures, e.", "startOffset": 36, "endOffset": 44}, {"referenceID": 27, "context": ", in the field of collaborative intrusion detection in cyber-physical systems [29].", "startOffset": 78, "endOffset": 82}], "year": 2016, "abstractText": "After data selection, pre-processing, transformation, and feature extraction, knowledge extraction is not the final step in a data mining process. It is then necessary to understand this knowledge in order to apply it efficiently and effectively. Up to now, there is a lack of appropriate techniques that support this significant step. This is partly due to the fact that the assessment of knowledge is often highly subjective, e.g., regarding aspects such as novelty or usefulness. These aspects depend on the specific knowledge and requirements of the data miner. There are, however, a number of aspects that are objective and for which it is possible to provide appropriate measures. In this article we focus on classification problems and use probabilistic generative classifiers based on mixture density models that are quite common in data mining applications. We define objective measures to assess the informativeness, uniqueness, importance, discrimination, representativity, uncertainty, and distinguishability of rules contained in these classifiers numerically. These measures not only support a data miner in evaluating results of a data mining process based on such classifiers. As we will see in illustrative case studies, they may also be used to improve the data mining process itself or to support the later application of the extracted knowledge.", "creator": "LaTeX with hyperref package"}}}