{"id": "1605.08283", "review": {"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "26-May-2016", "title": "Discrete Deep Feature Extraction: A Theory and New Architectures", "abstract": "First steps towards a mathematical theory of deep convolutional neural networks for feature extraction were made---for the continuous-time case---in Mallat, 2012, and Wiatowski and B\\\"olcskei, 2015. This paper considers the discrete case, introduces new convolutional neural network architectures, and proposes a mathematical framework for their analysis. Specifically, we establish deformation and translation sensitivity results of local and global nature, and we investigate how certain structural properties of the input signal are reflected in the corresponding feature vectors. The model results in the integration of these observations into a large-scale, deep convolutional neural network that has been extensively tested by Harshan, Cephardt and others.", "histories": [["v1", "Thu, 26 May 2016 13:55:07 GMT  (153kb,D)", "http://arxiv.org/abs/1605.08283v1", "Proc. of International Conference on Machine Learning (ICML), New York, USA, June 2016, to appear"]], "COMMENTS": "Proc. of International Conference on Machine Learning (ICML), New York, USA, June 2016, to appear", "reviews": [], "SUBJECTS": "cs.LG cs.CV cs.IT cs.NE math.IT stat.ML", "authors": ["thomas wiatowski", "michael tschannen", "aleksandar stanic", "philipp grohs", "helmut b\u00f6lcskei"], "accepted": true, "id": "1605.08283"}, "pdf": {"name": "1605.08283.pdf", "metadata": {"source": "META", "title": "Discrete Deep Feature Extraction: A Theory and New Architectures", "authors": ["Thomas Wiatowski", "Michael Tschannen", "Aleksandar Stani\u0107", "Philipp Grohs", "Helmut B\u00f6lcskei"], "emails": ["WITHOMAS@NARI.EE.ETHZ.CH", "MICHAELT@NARI.EE.ETHZ.CH", "ASTANIC@STUDENT.ETHZ.CH", "PHILIPP.GROHS@UNIVIE.AC.AT", "BOELCSKEI@NARI.EE.ETHZ.CH"], "sections": [{"heading": "1. Introduction", "text": "Deep convolutional neural networks (DCNNs) have proven tremendously successful in a wide range of machine learning tasks (Bengio et al., 2013; LeCun et al., 2015). Such networks are composed of multiple layers, each of which computes convolutional transforms followed by the application of non-linearities and pooling operators.\nDCNNs are typically distinguished according to (i) whether the filters employed are learned (in a supervised (LeCun et al., 1998; Huang & LeCun, 2006; Jarrett et al., 2009) or unsupervised (Ranzato et al., 2006; 2007; Jar-\nProceedings of the 33 rd International Conference on Machine Learning, New York, NY, USA, 2016. JMLR: W&CP volume 48. Copyright 2016 by the author(s).\nrett et al., 2009) fashion) or pre-specified (and structured, such as, e.g., wavelets (Serre et al., 2005; Mutch & Lowe, 2006; Mallat, 2012), or unstructured, such as random filters (Ranzato et al., 2007; Jarrett et al., 2009)), (ii) the non-linearities used (e.g., logistic sigmoid, hyperbolic tangent, modulus, or rectified linear unit), and (iii) the pooling operator employed (e.g., sub-sampling, average pooling, or max-pooling). While a given choice of filters, nonlinearities, and pooling operators will lead to vastly different performance results across datasets, it is remarkable that the overall DCNN architecture allows for impressive classification results across an extraordinarily broad range of applications. It is therefore of significant interest to understand the mechanisms underlying this universality.\nFirst steps towards addressing this question and developing a mathematical theory of DCNNs for feature extraction were made\u2014for the continuous-time case\u2014in (Mallat, 2012; Wiatowski & Bo\u0308lcskei, 2015). Specifically, (Mallat, 2012) analyzed so-called scattering networks, where signals are propagated through layers that employ directional wavelet filters and modulus non-linearities but no intra-layer pooling. The resulting wavelet-modulus feature extractor is horizontally (i.e., in every network layer) translation-invariant (accomplished by letting the wavelet scale parameter go to infinity) and deformationstable, both properties of significance in practical feature extraction applications. Recently, (Wiatowski & Bo\u0308lcskei, 2015) considered Mallat-type networks with arbitrary filters (that may be learned or pre-specified), general Lipschitz-continuous non-linearities (e.g., rectified linear unit, shifted logistic sigmoid, hyperbolic tangent, and the modulus function), and a continuous-time pooling operator that amounts to a dilation. The essence of the results in (Wiatowski & Bo\u0308lcskei, 2015) is that vertical (i.e., asymptotically in the network depth) translation invariance and Lipschitz continuity of the feature extractor are induced by the network structure per se rather than the specific choice of filters and non-linearities. For band-limited ar X iv :1 60 5.\n08 28\n3v 1\n[ cs\n.L G\n] 2\n6 M\nay 2\nsignals (Wiatowski & Bo\u0308lcskei, 2015), cartoon functions (Grohs et al., 2016), and Lipschitz-continuous functions (Grohs et al., 2016), Lipschitz continuity of the feature extractor automatically leads to bounds on deformation sensitivity.\nA discrete-time setup for wavelet-modulus scattering networks (referred to as ScatNets) was considered in (Bruna & Mallat, 2013).\nContributions. The purpose of the present paper is to develop a theory of discrete DCNNs for feature extraction. Specifically, we follow the philosophy put forward in (Wiatowski & Bo\u0308lcskei, 2015; Grohs et al., 2016). Our theory incorporates general filters, Lipschitz non-linearities, and Lipschitz pooling operators. In addition, we introduce and analyze a wide variety of new network architectures which build the feature vector from subsets of the layers. This leads us to the notions of local and global feature vector properties with globality pertaining to characteristics brought out by the union of features across all network layers, and locality identifying attributes made explicit in individual layers.\nBesides providing analytical performance results of general validity, we also investigate how certain structural properties of the input signal are reflected in the corresponding feature vectors. Specifically, we analyze the (local and global) deformation and translation sensitivity properties of feature vectors corresponding to sampled cartoon functions (Donoho, 2001). For simplicity of exposition, we focus on the 1-D case throughout the paper, noting that the extension to the higher-dimensional case does not pose any significant difficulties.\nOur theoretical results are complemented by extensive numerical studies on facial landmark detection and handwritten digit classification. Specifically, we elucidate the role of local feature vector properties through a feature relevance study.\nNotation. The complex conjugate of z \u2208 C is denoted by z. We write Re(z) for the real, and Im(z) for the imaginary part of z \u2208 C. We let HN := {f : Z \u2192 C | f [n] = f [n+ N ], \u2200n \u2208 Z} be the set of N -periodic discrete-time signals1, and set IN := {0, 1, . . . , N \u2212 1}. The delta function \u03b4 \u2208 HN is \u03b4[n] := 1, for n = kN , k \u2208 Z, and \u03b4[n] := 0, else. For f, g \u2208 HN , we set \u3008f, g\u3009 := \u2211 k\u2208IN f [k]g[k],\n\u2016f\u20161 := \u2211 n\u2208IN |f [n]|, \u2016f\u20162 := ( \u2211 n\u2208IN |f [n]|\n2)1/2, and \u2016f\u2016\u221e := supn\u2208IN |f [n]|. We denote the discrete Fourier transform (DFT) of f \u2208 HN by f\u0302 [k] :=\u2211 n\u2208IN f [n]e\n\u22122\u03c0ikn/N . The circular convolution of f \u2208 HN and g \u2208 HN is (f \u2217 g)[n] := \u2211 k\u2208IN f [k]g[n \u2212 k].\n1We note that HN is isometrically isomorphic to CN , but we prefer to work with HN for the sake of expositional simplicity.\nWe write (Tmf)[n] := f [n \u2212 m], m \u2208 Z, for the cyclic translation operator. The supremum norm of a continuoustime function c : R \u2192 C is \u2016c\u2016\u221e := supx\u2208R |c(x)|. The indicator function of an interval [a, b] \u2286 R is defined as 1[a,b](x) := 1, for x \u2208 [a, b], and 1[a,b](x) := 0, for x \u2208 R\\[a, b]. The cardinality of the set A is denoted by card(A)."}, {"heading": "2. The basic building block", "text": "The basic building block of a DCNN, described in this section, consists of a convolutional transform followed by a non-linearity and a pooling operation."}, {"heading": "2.1. Convolutional transform", "text": "A convolutional transform is made up of a set of filters \u03a8\u039b = {g\u03bb}\u03bb\u2208\u039b. The finite index set \u039b can be thought of as labeling a collection of scales, directions, or frequency-shifts. The filters g\u03bb\u2014referred to as atoms\u2014 may be learned (in a supervised or unsupervised fashion), pre-specified and unstructured such as random filters, or pre-specified and structured such as wavelets, curvelets, shearlets, or Weyl-Heisenberg functions. Definition 1. Let \u039b be a finite index set. The collection \u03a8\u039b = {g\u03bb}\u03bb\u2208\u039b \u2286 HN is called a convolutional set with Bessel bound B \u2265 0 if\u2211\n\u03bb\u2208\u039b\n\u2016f \u2217 g\u03bb\u201622 \u2264 B\u2016f\u201622, \u2200f \u2208 HN . (1)\nCondition (1) is equivalent to\u2211 \u03bb\u2208\u039b |g\u0302\u03bb[k]|2 \u2264 B, \u2200k \u2208 IN , (2) and hence, every finite set {g\u03bb}\u03bb\u2208\u039b is a convolutional set with Bessel bound B\u2217 := maxk\u2208IN \u2211 \u03bb\u2208\u039b |g\u0302\u03bb[k]|2. As\n(f \u2217 g\u03bb)[n] = \u2329 f, g\u03bb[n\u2212 \u00b7] \u232a , n \u2208 IN , \u03bb \u2208 \u039b, the outputs of the filters g\u03bb may be interpreted as inner products of the input signal f with translates of the atoms g\u03bb. Frame theory (Daubechies, 1992) therefore tells us that the existence of a lower bound A > 0 in (2) according to\nA \u2264 \u2211 \u03bb\u2208\u039b |g\u0302\u03bb[k]|2 \u2264 B, \u2200k \u2208 IN , (3)\nimplies that every element in HN can be written as a linear combination of elements in the set{ g\u03bb[n\u2212 \u00b7] } n\u2208IN ,\u03bb\u2208\u039b (or in more technical parlance, the\nset { g\u03bb[n\u2212 \u00b7] } n\u2208IN ,\u03bb\u2208\u039b\nis complete for HN ). The absence of a lower bound A > 0 may therefore result in \u03a8\u039b failing to extract essential features of the signal f . We note, however, that even learned filters are likely to satisfy (3) as all that is needed is, for each k \u2208 IN , to have g\u0302\u03bb[k] 6= 0 for at least one \u03bb \u2208 \u039b. As we shall see below, the existence of a lower bound A > 0 in (3) is, however, not needed for our theory to apply.\nExamples of structured convolutional sets withA = B = 1 include, in the 1-D case, wavelets (Daubechies, 1992) and Weyl-Heisenberg functions (Bo\u0308lcskei & Hlawatsch, 1997), and in the 2-D case, tensorized wavelets (Mallat, 2009), curvelets (Cande\u0300s et al., 2006), and shearlets (Kutyniok & Labate, 2012a)."}, {"heading": "2.2. Non-linearities", "text": "The non-linearities \u03c1 : C \u2192 C we consider are all pointwise and satisfy the Lipschitz property |\u03c1(x) \u2212 \u03c1(y)| \u2264 L|x\u2212 y|, \u2200x, y \u2208 C, for some L > 0."}, {"heading": "2.2.1. EXAMPLE NON-LINEARITIES", "text": "\u2022 The hyperbolic tangent non-linearity, defined as \u03c1(x) = tanh(Re(x)) + i tanh(Im(x)), where tanh(x) = e\nx\u2212e\u2212x ex+e\u2212x , has Lipschitz constant L = 2.\n\u2022 The rectified linear unit non-linearity is given by \u03c1(x) = max{0,Re(x)} + imax{0, Im(x)}, and has Lipschitz constant L = 2.\n\u2022 The modulus non-linearity is \u03c1(x) = |x|, and has Lipschitz constant L = 1.\n\u2022 The logistic sigmoid non-linearity is defined as \u03c1(x) = sig(Re(x)) + i sig(Im(x)), where sig(x) =\n1 1+e\u2212x , and has Lipschitz constant L = 1/2.\nWe refer the reader to (Wiatowski & Bo\u0308lcskei, 2015) for proofs of the Lipschitz properties of these example nonlinearities."}, {"heading": "2.3. Pooling operators", "text": "The essence of pooling is to reduce signal dimensionality in the individual network layers and to ensure robustness of the feature vector w.r.t. deformations and translations.\nThe theory developed in this paper applies to general pooling operators P : HN \u2192 HN/S , where N,S \u2208 N with N/S \u2208 N, that satisfy the Lipschitz property \u2016Pf \u2212 Pg\u20162 \u2264 R\u2016f \u2212 g\u2016, \u2200f, g \u2208 HN , for some R > 0. The integer S will be referred to as pooling factor, and determines the \u201csize\u201d of the neighborhood values are combined in."}, {"heading": "2.3.1. EXAMPLE POOLING OPERATORS", "text": "\u2022 Sub-sampling, defined as P : HN \u2192 HN/S , (Pf)[n] = f [Sn], n \u2208 IN/S , has Lipschitz constant R = 1. For S = 1, P is the identity operator which amounts to \u201cno pooling\u201d.\n\u2022 Averaging, defined as P : HN \u2192 HN/S , (Pf)[n] =\u2211Sn+S\u22121 k=Sn \u03b1k\u2212Snf [k], n \u2208 IN/S , has Lipschitz con-\nstant R = S1/2 maxk\u2208{0,...,S\u22121} |\u03b1k|. The weights\n{\u03b1k}S\u22121k=0 can be learned (LeCun et al., 1998) or prespecified (Pinto et al., 2008) (e.g., uniform pooling corresponds to \u03b1k = 1S , for k \u2208 {0, . . . , S \u2212 1}).\n\u2022 Maximization, defined as P : HN \u2192 HN/S , (Pf)[n] = maxk\u2208{Sn,...,Sn+S\u22121} |f [k]|, n \u2208 IN/S , has Lipschitz constant R = 1.\nWe refer to Appendix B in the Supplement for proofs of the Lipschitz property of these three example pooling operators along with the derivations of the corresponding Lipschitz constants."}, {"heading": "3. The network architecture", "text": "The architecture we consider is flexible in the following sense. In each layer, we can feed into the feature vector either the signals propagated down to that layer (i.e., the feature maps), filtered versions thereof, or we can decide not to have that layer contribute to the feature vector.\nThe basic building blocks of our network are the triplets (\u03a8d, \u03c1d, Pd) of filters, non-linearities, and pooling operators associated with the d-th network layer and referred to as modules. We emphasize that these triplets are allowed to be different across layers.\nDefinition 2. For network layers d, 1 \u2264 d \u2264 D, let \u03a8d = {g\u03bbd}\u03bbd\u2208\u039bd \u2286 HNd be a convolutional set, \u03c1d : C \u2192 C a point-wise Lipschitz-continuous non-linearity, and Pd : HNd \u2192 HNd+1 a Lipschitz-continuous pooling operator withNd+1 = NdSd , where Sd \u2208 N denotes the pooling factor in the d-th layer. Then, the sequence of triplets\n\u2126 := ( (\u03a8d, \u03c1d, Pd) )\n1\u2264d\u2264D\nis called a module-sequence.\nNote that the dimensions of the spaces HNd satisfy N1 \u2265 N2 \u2265 . . . \u2265 ND. Associated with the module (\u03a8d, \u03c1d, Pd), we define the operator\n(Ud[\u03bbd]f) := Pd(\u03c1d(f \u2217 g\u03bbd)) (4)\nand extend it to paths on index sets\nq = (\u03bb1, \u03bb2, . . . , \u03bbd) \u2208 \u039b1 \u00d7 \u039b2 \u00d7 \u00b7 \u00b7 \u00b7 \u00d7 \u039bd := \u039bd1,\nfor 1 \u2264 d \u2264 D, according to\nU [q]f =U [(\u03bb1, \u03bb2, . . . , \u03bbd)]f\n:=Ud[\u03bbd] \u00b7 \u00b7 \u00b7U2[\u03bb2]U1[\u03bb1]f. (5)\nFor the empty path e := \u2205 we set \u039b01 := {e} and let U [e]f := f , for all f \u2208 HN1 .\nThe network output in the d-th layer is given by (U [q]f) \u2217 \u03c7d, q \u2208 \u039bd1, where \u03c7d \u2208 HNd+1 is referred to as outputgenerating atom. Specifically, we let \u03c7d be (i) the delta\nU [e]f = f\nU [ \u03bb\n(j) 1 ] f(\nU [ \u03bb\n(j) 1 ] f ) \u2217 \u03c71\nU [( \u03bb\n(j) 1 , \u03bb (l) 2\n)] f\n( U [( \u03bb\n(j) 1 , \u03bb (l) 2 )] f ) \u2217 \u03c72\nU [( \u03bb\n(j) 1 , \u03bb (l) 2 , \u03bb (m) 3\n)] f\nU [ \u03bb\n(p) 1 ] f(\nU [ \u03bb\n(p) 1 ] f ) \u2217 \u03c71\nU [( \u03bb\n(p) 1 , \u03bb (r) 2\n)] f\n( U [( \u03bb\n(p) 1 , \u03bb (r) 2 )] f ) \u2217 \u03c72\nU [( \u03bb\n(p) 1 , \u03bb (r) 2 , \u03bb (s) 3\n)] f\nf \u2217 \u03c70\nFigure 1. Network architecture underlying the feature extractor (6). The index \u03bb(k)d corresponds to the k-th atom g\u03bb(k) d of the convolutional set \u03a8d associated with the d-th network layer. The function \u03c7d is the output-generating atom of the d-th layer. The root of the network corresponds to d = 0.\nfunction \u03b4[n], n \u2208 INd+1 , if we want the output to equal the unfiltered features U [q]f , q \u2208 \u039bd1, propagated down to layer d, or (ii) any other signal of length Nd+1, or (iii) \u03c7d = 0 if we do not want layer d to contribute to the feature vector. From now on we formally add \u03c7d to the set \u03a8d+1 = {g\u03bbd+1}\u03bbd+1\u2208\u039bd+1 , noting that {g\u03bbd+1}\u03bbd+1\u2208\u039bd+1 \u222a {\u03c7d} forms a convolutional set \u03a8\u2032d+1 with Bessel boundB \u2032 d+1 \u2264 Bd+1 + maxk\u2208INd+1 |\u03c7\u0302d[k]| 2. We emphasize that the atoms of the augmented set {g\u03bbd+1}\u03bbd+1\u2208\u039bd+1 \u222a {\u03c7d} are employed across two consecutive layers in the sense of \u03c7d generating the output in the d-th layer according to (U [q]f) \u2217 \u03c7d, q \u2208 \u039bd1, and the remaining atoms {g\u03bbd+1}\u03bbd+1\u2208\u039bd+1 propagating the signals U [q]f , q \u2208 \u039bd1, from the d-th layer down to the (d + 1)-st layer according to (4), see Fig. 1. With slight abuse of notation, we shall henceforth write \u03a8d for \u03a8\u2032d and Bd for B \u2032 d as well.\nWe are now ready to define the feature extractor \u03a6\u2126 based on the module-sequence \u2126. Definition 3. Let \u2126 = ( (\u03a8d, \u03c1d, Pd) ) 1\u2264d\u2264D be a modulesequence. The feature extractor \u03a6\u2126 based on \u2126 maps f \u2208 HN1 to its features\n\u03a6\u2126(f) := D\u22121\u22c3 d=0 \u03a6d\u2126(f), (6)\nwhere \u03a6d\u2126(f) := {(U [q]f) \u2217 \u03c7d}q\u2208\u039bd1 is the collection of features generated in the d-th network layer (see Fig. 1).\nThe dimension of the feature vector \u03a6\u2126(f) is given by \u03b50N1 + \u2211D\u22121 d=1 \u03b5dNd+1 (\u220fd k=1 card(\u039bk) ) , where \u03b5d = 1, if an output is generated (either filtered or unfiltered) in the d-th network layer, and \u03b5d = 0, else. As Nd+1 = NdSd = \u00b7 \u00b7 \u00b7 = N1S1\u00b7\u00b7\u00b7Sd , for d \u2265 1, the dimension of the overall feature vector is determined by the pooling factors Sk and, of course, the layers that contribute to the feature vector. Remark 1. It was argued in (Bruna & Mallat, 2013; Ande\u0301n & Mallat, 2014; Oyallon & Mallat, 2014) that the\nfeatures \u03a61\u2126(f) when generated by wavelet filters, modulus non-linearities, without intra-layer pooling, and by employing output-generating atoms with low-pass characteristics, describe mel frequency cepstral coefficients (Davis & Mermelstein, 1980) in 1-D, and SIFT-descriptors (Lowe, 2004; Tola et al., 2010) in 2-D."}, {"heading": "4. Sampled cartoon functions", "text": "While our main results hold for general signals f , we can provide a refined analysis for the class of sampled cartoon functions. This allows to understand how certain structural properties of the input signal, such as the presence of sharp edges, are reflected in the feature vector. Cartoon functions\u2014as introduced in continuous time in (Donoho, 2001)\u2014are piecewise \u201csmooth\u201d apart from curved discontinuities along Lipschitz-continuous hypersurfaces. They hence provide a good model for natural images (see Fig. 2, left) such as those in the Caltech-256 (Griffin et al., 2007) and the CIFAR-100 (Krizhevsky, 2009) datasets, for images of handwritten digits (LeCun & Cortes, 1998) (see Fig. 2, middle), and for images of geometric objects of different shapes, sizes, and colors as in the Baby AI School dataset2.\nBounds on deformation sensitivity for cartoon functions in continuous-time DCNNs were recently reported in (Grohs et al., 2016). Here, we analyze deformation sensitivity for sampled cartoon functions passed through discrete DCNNs.\nDefinition 4. The function c : R \u2192 C is referred to as a cartoon function if it can be written as c = c1 + 1[a,b]c2, where [a, b] \u2286 [0, 1] is a closed interval, and ci : R \u2192 C, i = 1, 2, satisfies the Lipschitz property\n|ci(x)\u2212 ci(y)| \u2264 C|x\u2212 y|, \u2200x, y \u2208 R,\nfor some C > 0. Furthermore, we denote by\nCKCART := {c1 + 1[a,b]c2 | |ci(x)\u2212 ci(y)| \u2264 K|x\u2212 y|, \u2200x, y \u2208 R, i = 1, 2, \u2016c2\u2016\u221e \u2264 K}\nthe class of cartoon functions of variation K > 0, and by CN,KCART := { f [n] = c(n/N), n \u2208 {0, 1, . . . , N \u2212 1} \u2223\u2223\u2223 c = (c1 + 1[a,b]c2) \u2208 CKCART with\na, b /\u2208 { 0, 1\nN , . . . , N \u2212 1 N }} the class of sampled cartoon functions of length N and variation K > 0.\nWe note that excluding the boundary points a, b of the interval [a, b] from being sampling points n/N in the def-\n2http://www.iro.umontreal.ca/%7Elisa/ twiki/bin/view.cgi/Public/BabyAISchool\ninition of CN,KCART is of conceptual importance (see Remark D.1 in the Supplement). Moreover, our results can easily be generalized to classes CN,KCART consisting of functions f [n] = c(n/N) with c containing multiple \u201c1-D edges\u201d (i.e., multiple discontinuity points) according to c = c1 + \u2211L l=1 1[al,bl]c2 with \u2229Ll=1[al, bl] = \u2205. We also note that CN,KCART reduces to the class of sampled Lipschitzcontinuous functions upon setting c2 = 0.\nA sampled cartoon function in 2-D models, e.g., an image acquired by a digital camera (see Fig. 2, middle); in 1- D, f \u2208 CN,KCART can be thought of as the pixels in a row or column of this image (see Fig. 2 right, which shows a cartoon function with 6 discontinuity points)."}, {"heading": "5. Analytical results", "text": "We analyze global and local feature vector properties with globality pertaining to characteristics brought out by the union of features across all network layers, and locality identifying attributes made explicit in individual layers."}, {"heading": "5.1. Global properties", "text": "Theorem 1. Let \u2126 = ( (\u03a8d, \u03c1d, Pd) ) 1\u2264d\u2264D be a modulesequence. Assume that the Bessel bounds Bd > 0, the Lipschitz constants Ld > 0 of the non-linearities \u03c1d, and the Lipschitz constants Rd > 0 of the pooling operators Pd satisfy\nmax 1\u2264d\u2264D\nmax{Bd, BdR2dL2d} \u2264 1. (7)\ni) The feature extractor \u03a6\u2126 is Lipschitz-continuous with Lipschitz constant L\u2126 = 1, i.e.,\n|||\u03a6\u2126(f)\u2212 \u03a6\u2126(h)||| \u2264 \u2016f \u2212 h\u20162, (8)\nfor all f, h \u2208 HN1 , where the feature space norm is defined as\n|||\u03a6\u2126(f)|||2 := D\u22121\u2211 d=0 \u2211 q\u2208\u039bd1 ||(U [q]f) \u2217 \u03c7d||22. (9)\nii) If, in addition to (7), for all d \u2208 {1, . . . , D \u2212 1} the non-linearities \u03c1d and the pooling operators Pd sa-\ntisfy \u03c1d(0) = 0 and Pd(0) = 0 (as all non-linearities and pooling operators in Sections 2.2.1 and 2.3.1, apart from the logistic sigmoid non-linearity, do), then\n|||\u03a6\u2126(f)||| \u2264 \u2016f\u20162, \u2200f \u2208 HN1 . (10) iii) For every variation K > 0 and deformation F\u03c4 of the\nform\n(F\u03c4f)[n] : = c(n/N1 \u2212 \u03c4(n/N1)), n \u2208 IN1 , (11)\nwhere \u03c4 : R \u2192 [\u22121, 1], the deformation sensitivity is bounded according to\n|||\u03a6\u2126(F\u03c4f)\u2212 \u03a6\u2126(f)||| \u2264 4KN1/21 \u2016\u03c4\u20161/2\u221e , (12)\nfor all f \u2208 CN1,KCART.\nProof. See Appendix C in the Supplement.\nThe Lipschitz continuity (8) guarantees that pairwise distances of input signals do not increase through feature extraction. As an immediate implication of the Lipschitz continuity we get robustness of the feature extractor w.r.t. additive bounded noise \u03b7 \u2208 HN1 in the sense of\n|||\u03a6\u2126(f + \u03b7)\u2212 \u03a6\u2126(f)||| \u2264 \u2016\u03b7\u20162, for all f \u2208 HN1 . Remark 2. As detailed in the proof of Theorem 1, the Lipschitz continuity (8) combined with the deformation sensitivity bound (see Proposition D.1 in the Supplement) for the signal class under consideration, namely sampled cartoon functions, establishes the deformation sensitivity bound (12) for the feature extractor. This insight has important practical ramifications as it shows that whenever we have deformation sensitivity bounds for a signal class, we automatically get deformation sensitivity guarantees for the corresponding feature extractor.\nFrom (12) we can deduce a statement on the sensitivity of \u03a6\u2126 w.r.t. translations on R. To this end, we first note that setting \u03c4t(x) = t, x \u2208 R, for t \u2208 [\u22121, 1], (11) becomes\n(F\u03c4tf)[n] = c(n/N1 \u2212 t), n \u2208 IN1 .\nParticularizing (12) accordingly, we obtain\n|||\u03a6\u2126(F\u03c4tf)\u2212 \u03a6\u2126(f)||| \u2264 4KN 1/2 1 |t|1/2, (13)\nwhich shows that small translations |t| of the underlying analog signal c(x), x \u2208 R, lead to small changes in the feature vector obtained by passing the resulting sampled signal through a discrete DCNN. We shall say that (13) is a translation sensitivity bound. Analyzing the impact of deformations and translations over R on the discrete feature vector generated by the sampled analog signal closely models real-world phenomena (e.g., the jittered acquisition of an analog signal with a digital camera, where different values of N1 in (11) correspond to different camera resolutions).\nWe note that, while iii) in Theorem 1 is specific to cartoon functions, i) and ii) apply to all signals in HN1 .\nThe strength of the results in Theorem 1 derives itself from the fact that condition (7) on the underlying modulesequence \u2126 is easily met in practice. To see this, we first note that Bd is determined by the convolutional set \u03a8d, Ld by the non-linearity \u03c1d, andRd by the pooling operator Pd. Condition (7) is met if\nBd \u2264 min{1, R\u22122d L \u22122 d }, \u2200 d \u2208 {1, 2, . . . , D}, (14)\nwhich, if not satisfied by default, can be enforced simply by normalizing the elements in \u03a8d. Specifically, for Cd := max{Bd, R2dL2d} the set \u03a8\u0303d := {C \u22121/2 d g\u03bbd}\u03bbd\u2208\u039bd has Bessel bound B\u0303d = BdCd and hence satisfies (14). While this normalization does not have an impact on the results in Theorem 1, there exists, however, a tradeoff between energy preservation and deformation (respectively translation) sensitivity in \u03a6d\u2126 as detailed in the next section."}, {"heading": "5.2. Local properties", "text": "Theorem 2. Let \u2126 = ( (\u03a8d, \u03c1d, Pd) ) 1\u2264d\u2264D be a modulesequence with corresponding Bessel bounds Bd > 0, Lipschitz constants Ld > 0 of the non-linearities \u03c1d, Lipschitz constants Rd > 0 of the pooling operators Pd, and outputgenerating atoms \u03c7d. Let further L0\u2126 := \u2016\u03c70\u20161 and 3\nLd\u2126 := \u2016\u03c7d\u20161 ( d\u220f k=1 BkL 2 kR 2 k )1/2 , d \u2265 1. (15) i) The features generated in the d-th network layer are Lipschitz-continuous with Lipschitz constant Ld\u2126, i.e.,\n|||\u03a6d\u2126(f)\u2212 \u03a6d\u2126(h)||| \u2264 Ld\u2126\u2016f \u2212 h\u20162, (16)\nfor all f, h \u2208 HN1 , where |||\u03a6d\u2126(f)|||2 :=\u2211 q\u2208\u039bd1\n||(U [q]f) \u2217 \u03c7d||22. ii) If the non-linearities \u03c1k and the pooling operators Pk\nsatisfy \u03c1k(0) = 0 and Pk(0) = 0, respectively, for all k \u2208 {1, . . . , d}, then\n|||\u03a6d\u2126(f)||| \u2264 Ld\u2126\u2016f\u20162, \u2200f \u2208 HN1 . (17)\niii) For all K > 0 and all \u03c4 : R \u2192 [\u22121, 1], the features generated in the d-th network layer satisfy\n|||\u03a6d\u2126(F\u03c4f)\u2212 \u03a6d\u2126(f)||| \u2264 4Ld\u2126KN1/2\u2016\u03c4\u20161/2\u221e , (18)\nfor all f \u2208 CN1,KCART, where F\u03c4f is defined in (11). iv) If the module-sequence employs sub-sampling, ave-\nrage pooling, or max-pooling with corresponding pooling factors Sd \u2208 N, then\n\u03a6d\u2126(Tmf) = T mS1...Sd \u03a6d\u2126(f), (19)\n3We note that \u2016\u03c7d\u20161 in (15) can be upper-bounded (and hence substituted) by Bd+1, see Remark E.1 in the Supplement.\nfor all f \u2208 HN1 and all m \u2208 Z with mS1...Sd \u2208 Z. Here, Tm\u03a6d\u2126(f) refers to element-wise application of Tm, i.e., Tm\u03a6d\u2126(f) := {Tmh | \u2200h \u2208 \u03a6d\u2126(f)}.\nProof. See Appendix E in the Supplement.\nOne may be tempted to infer the global results (8), (10), and (12) in Theorem 1 from the corresponding local results in Theorem 2, e.g., the energy bound in (10) from (17)\naccording to |||\u03a6\u2126(f)||| = (\u2211D\u22121 d=0 |||\u03a6d\u2126(f)|||2 )1/2\n\u2264 \u221a D\u2016f\u20162, where we employed Ld\u2126 \u2264 1 owing to (7). This would, however, lead to the \u201cglobal\u201d Lipschitz constant L\u2126 = 1 in (8), (10), and (12) to be replaced by L\u2126 = \u221a D and thereby render the corresponding results much weaker.\nAgain, we emphasize that, while iii) in Theorem 2 is specific to cartoon functions, i), ii), and iv) apply to all signals in HN1 .\nFor a fixed network layer d, the \u201clocal\u201d Lipschitz constant Ld\u2126 determines the noise sensitivity of the features \u03a6 d \u2126(f) according to\n|||\u03a6d\u2126(f + \u03b7)\u2212 \u03a6d\u2126(f)||| \u2264 Ld\u2126\u2016\u03b7\u20162, (20)\nwhere (20) follows from (16). Moreover, Ld\u2126 via (18) also quantifies the impact of deformations (or translations when \u03c4t(x) = t, x \u2208 R, for t \u2208 [\u22121, 1]) on the feature vector. In practice, it may be desirable to have the features \u03a6d\u2126 become more robust to additive noise and less deformationsensitive (respectively, translation-sensitive) as we progress deeper into the network. Formally, this vertical sensitivity reduction can be induced by ensuring that Ld+1\u2126 < L d \u2126. Thanks to Ld\u2126 = \u2016\u03c7d\u20161B1/2d LdRd \u2016\u03c7d\u22121\u20161 L d\u22121 \u2126 , this can be accomplished by choosing the module-sequence such that \u2016\u03c7d\u20161B1/2d LdRd < \u2016\u03c7d\u22121\u20161. Note, however, that owing to (17) this will also reduce the signal energy contained in the features \u03a6d\u2126(f). We therefore have a tradeoff between deformation (respectively translation) sensitivity and energy preservation. Having control over this tradeoff through the choice of the module-sequence \u2126 may come in handy in practice.\nFor average pooling with uniform weights \u03b1dk = 1 Sd , k = 0, . . . , Sd \u2212 1 (noting that the corresponding Lipschitz constant is Rd = S \u22121/2 d , see Section 2.3.1), we\nget Ld\u2126 = \u2016\u03c7d\u20161 (\u220fd k=1 BkL 2 k\nSk\n)1/2 , which illustrates that\npooling can have an impact on the sensitivity and energy properties of \u03a6d\u2126.\nWe finally turn to interpreting the translation covariance result (19). Owing to the condition mS1...Sd \u2208 Z, we get translation covariance only on the rough grid induced by the product of the pooling factors. In the absence of pooling,\ni.e., Sk = 1, for k \u2208 {1, . . . , d}, we obtain translation covariance w.r.t. the fine grid the input signal f \u2208 HN1 lives on.\nRemark 3. We note that ScatNets (Bruna & Mallat, 2013) are translation-covariant on the rough grid induced by the factor 2J corresponding to the coarsest wavelet scale. Our result in (19) is hence in the spirit of (Bruna & Mallat, 2013) with the difference that the grid in our case is induced by the pooling factors Sk.\n6. Experiments4\nWe consider the problem of handwritten digit classification and evaluate the performance of the feature extractor \u03a6\u2126 in combination with a support vector machine (SVM). The results we obtain are competitive with the state-of-the-art in the literature. The second line of experiments we perform assesses the importance of the features extracted by \u03a6\u2126 in facial landmark detection and in handwritten digit classification, using random forests (RF) for regression and classification, respectively. Our results are based on a DCNN with different non-linearities and pooling operators, and with tensorized (i.e., separable) wavelets as filters, sensitive to 3 directions (horizontal, vertical, and diagonal). Furthermore, we generate outputs in all layers through low-pass filtering. Circular convolutions with the 1-D filters underlying the tensorized wavelets are efficiently implemented using the algorithme a\u0300 trous (Holschneider et al., 1989).\nTo reduce the dimension of the feature vector, we compute features along frequency decreasing paths only (Bruna & Mallat, 2013), i.e., for every node U [q]f , q \u2208 \u039bd\u221211 , we retain only those child nodes Ud[\u03bbd]U [q]f = Pd ( \u03c1d((U [q]f)\u2217g\u03bbd) ) that correspond to wavelets g\u03bbd with scales larger than the maximum scale of the wavelets used to get U [q]f . We refer to (Bruna & Mallat, 2013) for a detailed justification of this approach for scattering networks."}, {"heading": "6.1. Handwritten digit classification", "text": "We use the MNIST dataset of handwritten digits (LeCun & Cortes, 1998) which comprises 60,000 training and 10,000 test images of size 28\u00d728. We setD = 3, and compare different network configurations, each defined by a single module (i.e., we use the same filters, non-linearity, and pooling operator in all layers). Specifically, we consider Haar wavelets and reverse biorthogonal 2.2 (RBIO2.2) wavelets (Mallat, 2009), both with J = 3 scales, the non-linearities described in Section 2.2.1, and the pooling operators described in Section 2.3.1 (with S1 = 1 and S2 = 2). We use a SVM with radial basis function (RBF) kernel for classification. To reduce the dimension of the feature vec-\n4Code available at http://www.nari.ee.ethz.ch/ commth/research/\ntors from 18,424 (or 50,176, for the configurations without pooling) down to 1000, we employ the supervised orthogonal least squares feature selection procedure described in (Oyallon & Mallat, 2014). The penalty parameter of the SVM and the localization parameter of the RBF kernel are selected via 10-fold cross-validation for each combination of wavelet filter, non-linearity, and pooling operator.\nTable 1 shows the resulting classification errors on the test set (obtained for the SVM trained on the full training set). Configurations employing RBIO2.2 wavelets tend to yield a marginally lower classification error than those using Haar wavelets. For the tanh and LogSig non-linearities, max-pooling leads to a considerably lower classification error than other pooling operators. The configurations involving the modulus and ReLU non-linearities achieve classification accuracy competitive with the state-of-theart (Bruna & Mallat, 2013) (class. err.: 0.43%), which is based on directional non-separable wavelets with 6 directions without intra-layer pooling. This is interesting as the separable wavelet filters employed here can be implemented more efficiently."}, {"heading": "6.2. Feature importance evaluation", "text": "In this experiment, we investigate the \u201cimportance\u201d of the features generated by \u03a6\u2126 corresponding to different layers, wavelet scales, and directions in two different learning tasks, namely, facial landmark detection and handwritten digit classification. The primary goal of this experiment is to illustrate the practical relevance of the notion of local properties of \u03a6\u2126 as established in Section 5.2. For facial landmark detection we employ a RF regressor and for handwritten digit classification a RF classifier (Breiman, 2001). In both cases, we fix the number of trees to 30 and select the tree depth using out-of-bag error estimates (noting that increasing the number of trees does not significantly increase the accuracy). The impurity measure used for learning the node tests is the mean square error for facial landmark detection and the Gini impurity for handwritten digit classification. In both cases, feature importance is assessed using the Gini importance (Breiman et al., 1984), averaged over all trees. The Gini importance I(\u03b8, T ) of feature \u03b8 in the (trained) tree T is defined as\nI(\u03b8, T ) = \u2211 `\u2208T : \u03d5(`)=\u03b8 n` ntot (\u0302\u0131`\u2212 n`L n` \u0131\u0302`L\u2212 n`R n` \u0131\u0302`R), where \u03d5(`) denotes the feature determined in the training phase for the test at node `, n` is the number of training samples passed through node `, ntot = \u2211 `\u2208T n`, \u0131\u0302` is the impurity at node `, and `L and `R denote the left and right child node, respectively, of node `. For the feature extractor \u03a6\u2126 we set D = 4, employ Haar wavelets with J = 3 scales and the modulus non-linearity in every network layer, no pooling in the first layer and average pooling with uniform weights 1/S2d , Sd = 2, in layers d = 2, 3.\nFacial landmark detection. We use the Caltech 10,000 Web Faces data base (Angelova et al., 2005). Each of the 7092 images in the data base depicts one or more faces in different contexts (e.g., portrait images, groups of people). The data base contains annotations of the positions of eyes, nose, and mouth for at least one face per image. The learning task is to estimate the positions of these facial landmarks. The annotations serve as ground truth for training and testing. We preprocess the data set as follows. The patches containing the faces are extracted from the images using the Viola-Jones face detector (Viola & Jones, 2004). After discarding false positives, the patches are converted to grayscale and resampled to size 120 \u00d7 120 (using linear interpolation), before feeding them to the feature extractor \u03a6\u2126. This procedure yields a dataset containing a total of 8776 face images. We select 80% of the images uniformly at random to form a training set and use the remaining images for testing. We train a separate RF for each facial landmark. Following (Dantone et al., 2012) we report the localization error, i.e., the `2-distance between the estimated and the ground truth landmark positions, on the test set as a fraction of the (true) inter-ocular distance. The errors obtained are: left eye: 0.062; right eye: 0.064; nose; 0.080, mouth: 0.095. As an aside, we note that these values are comparable with the ones reported in (Dantone et al., 2012) for a conditional RF using patch comparison features (evaluated on a different dataset and a larger set of facial landmarks).\nHandwritten digit classification. For this experiment, we again rely on the MNIST dataset. The training set is obtained by sampling uniformly at random 1, 000 images per digit from the MNIST training dataset and we use the complete MNIST test set. We train two RFs, one based on unmodified images, and the other one based on images subject to a random uniform displacement of at most 4 pixels in (positive and negative) x and y direction to study the impact of offsets on feature importance. The resulting RFs achieve a classification error of 4.2% and 9.6%, respectively.\nDiscussion. Figure 3 shows the cumulative feature importance (per triplet of layer index, wavelet scale, and direction, averaged over all trees in the respective RF) in handwritten digit classification and in facial landmark detection. Table 2 shows the corresponding cumulative fea-\nture importance for each layer.\nFor facial landmark detection, the features in layer 1 clearly have the highest importance, and the feature importance decreases with increasing layer index d. For handwritten digit classification using the unshifted MNIST images, the cumulative importance of the features in the second/third layer relative to those in the first layer is considerably higher than in facial landmark detection (see Table 2). For the translated MNIST images, the importance of the features in the second/third layer is significantly higher than those in the 0-th and in the first layer. An explanation for this observation could be as follows: In a classification task small sensitivity to translations is beneficial. Now, according to our theory (see Section 5.2) translation sensitivity, indeed, decreases with increasing layer index for average pooling as used here. For localization of landmarks, on the other hand, the RF needs features that are covariant on the fine grid of the input image thus favoring features in the layers closer to the root."}, {"heading": "Acknowledgments", "text": "The authors would like to thank C. Geiger for preliminary work on the experiments in Section 6.2 and M. Lerjen for help with computational issues."}, {"heading": "A. Appendix: Additional numerical results", "text": "A.1. Handwritten digit classification\nFor the handwritten digit classification experiment described in Section 6.1, Table 3 shows the classification error for Daubechies wavelets with 2 vanishing moments (DB2).\nA.2. Feature importance evaluation\nFor the feature importance experiment described in Section 6.2, Figure 4 shows the cumulative feature importance (per triplet of layer index, wavelet scale, and direction, averaged over all trees in the respective RF) in facial landmark detection (right eye and mouth)."}, {"heading": "B. Appendix: Lipschitz continuity of pooling operators", "text": "We verify the Lipschitz property\n\u2016P (f)\u2212 P (h)\u20162 \u2264 R\u2016f \u2212 h\u20162, \u2200f, h \u2208 HN ,\nfor the pooling operators in Section 2.3.1.\nSub-sampling: Pooling by sub-sampling is defined as\nP : HN \u2192 HN/S , P (f)[n] = f [Sn], n \u2208 IN/S ,\nwhere N/S \u2208 N. Lipschitz continuity with R = 1 follows from\n\u2016P (f)\u2212 P (h)\u201622 = \u2211\nn\u2208IN/S\n|f [Sn]\u2212 h[Sn]|2\n\u2264 \u2211 n\u2208IN |f [n]\u2212 h[n]|2 = \u2016f \u2212 h\u201622, \u2200f, h \u2208 HN .\nAveraging: Pooling by averaging is defined as\nP : HN \u2192 HN/S , P (f)[n] = Sn+S\u22121\u2211 k=Sn \u03b1k\u2212Snf [k],\nfor n \u2208 IN/S , where N/S \u2208 N. We start by setting \u03b1\u2032 :=\nmaxk\u2208{0,...,S\u22121} |\u03b1k|. Then,\n\u2016P (f)\u2212 P (h)\u201622\n= \u2211\nn\u2208IN/S\n\u2223\u2223\u2223 Sn+S\u22121\u2211 k=Sn \u03b1k\u2212Sn(f [k]\u2212 h[k]) \u2223\u2223\u22232\n\u2264 \u2211\nn\u2208IN/S\n\u2223\u2223\u2223 Sn+S\u22121\u2211 k=Sn \u03b1\u2032|f [k]\u2212 h[k]| \u2223\u2223\u22232\n\u2264 \u03b1\u20322S \u2211\nn\u2208IN/S\nSn+S\u22121\u2211 k=Sn \u2223\u2223\u2223f [k]\u2212 h[k]\u2223\u2223\u22232 (B.1) = \u03b1\u20322S\n\u2211 n\u2208IN \u2223\u2223\u2223f [k]\u2212 h[k]\u2223\u2223\u22232 = \u03b1\u20322S\u2016f \u2212 h\u201622, where we used \u2211 k\u2208IS |f [k]\u2212h[k]| \u2264 S\n1/2\u2016f\u2212h\u20162, f, h \u2208 HS , to get (B.1), see, e.g., (Golub & Van Loan, 2013).\nMaximization: Pooling by maximization is defined as\nP : HN \u2192 HN/S , P (f)[n] = max k\u2208{Sn,...,Sn+S\u22121} |f [k]|,\nfor n \u2208 IN/S , where N/S \u2208 N. We have\n\u2016P (f)\u2212 P (h)\u201622 = \u2211 n\u2208IN/S \u2223\u2223 max k\u2208{Sn,...,Sn+S\u22121} |f [k]|\n\u2212 max k\u2208{Sn,...,Sn+S\u22121}\n|h[k]| \u2223\u22232\n\u2264 \u2211\nn\u2208IN/S\nmax k\u2208{Sn,...,Sn+S\u22121} \u2223\u2223f [k]\u2212 h[k]\u2223\u22232 (B.2) \u2264\n\u2211 n\u2208IN/S S\u22121\u2211 k=0 |f [Sn+ k]\u2212 h[Sn+ k]|2 (B.3)\n= \u2016f \u2212 h\u201622,\nwhere we employed the reverse triangle inequality\u2223\u2223\u2016f\u2016\u221e \u2212 \u2016h\u2016\u221e\u2223\u2223 \u2264 \u2016f \u2212 h\u2016\u221e, f, h \u2208 HS , to get (B.2), and in (B.3) we used \u2016f\u2016\u221e \u2264 \u2016f\u20162, f \u2208 HS , see, e.g., (Golub & Van Loan, 2013)."}, {"heading": "C. Appendix: Proof of Theorem 1", "text": "We start by proving i). The key idea of the proof is\u2014 similarly to the proof of Proposition 4 in (Wiatowski & Bo\u0308lcskei, 2015)\u2014to employ telescoping series arguments. For ease of notation, we let fq := U [q]f and hq := U [q]h, for f, h \u2208 HN1 , q \u2208 \u039bd1. With (9) we have\n|||\u03a6\u2126(f)\u2212 \u03a6\u2126(h)|||2 = D\u22121\u2211 d=0 \u2211 q\u2208\u039bd1\n||(fq \u2212 hq) \u2217 \u03c7d||22\ufe38 \ufe37\ufe37 \ufe38 =:ad .\nThe key step is then to show that ad can be upper-bounded according to\nad \u2264 bd \u2212 bd+1, d = 0, . . . , D \u2212 1, (C.1)\nwith bd := \u2211 q\u2208\u039bd1\n\u2016fq \u2212 hq\u201622, for d = 0, . . . , D, and to note that\nD\u22121\u2211 d=0 ad \u2264 D\u22121\u2211 d=0 (bd \u2212 bd+1) = b0 \u2212 bD\ufe38\ufe37\ufe37\ufe38 \u22650 \u2264 b0\n= \u2211 q\u2208\u039b01 \u2016fq \u2212 hq\u201622 = \u2016f \u2212 h\u201622,\nwhich then yields (8). Writing out (C.1), it follows that we need to establish\n\u2211 q\u2208\u039bd1 \u2016(fq \u2212 hq) \u2217 \u03c7d\u201622 \u2264 \u2211 q\u2208\u039bd1 ||fq \u2212 hq\u201622\n\u2212 \u2211\nq\u2208\u039bd+11\n\u2016fq \u2212 hq\u201622, d = 0, . . . , D \u2212 1. (C.2)\nWe start by examining the second sum on the right-hand side (RHS) in (C.2). Every path\nq\u0303 \u2208 \u039bd+11 = \u039b1 \u00d7 \u00b7 \u00b7 \u00b7 \u00d7 \u039bd\ufe38 \ufe37\ufe37 \ufe38 =\u039bd1 \u00d7\u039bd+1\nof length d + 1 can be decomposed into a path q \u2208 \u039bd1 of length d and an index \u03bbd+1 \u2208 \u039bd+1 according to q\u0303 = (q, \u03bbd+1). Thanks to (5) we have U [q\u0303] = U [(q, \u03bbd+1)] = Ud+1[\u03bbd+1]U [q], which yields\n\u2211 q\u0303\u2208\u039bd+11 \u2016fq\u0303 \u2212 hq\u0303\u201622 = \u2211 q\u2208\u039bd1 \u2211 \u03bbd+1\u2208\u039bd+1 \u2016Ud+1[\u03bbd+1]fq \u2212 Ud+1[\u03bbd+1]hq\u201622. (C.3)\nSubstituting (C.3) into (C.2) and rearranging terms, we obtain\n\u2211 q\u2208\u039bd1 ( \u2016(fq \u2212 hq) \u2217 \u03c7d\u201622 (C.4)\n+ \u2211\n\u03bbd+1\u2208\u039bd+1\n\u2016Ud+1[\u03bbd+1]fq \u2212 Ud+1[\u03bbd+1]hq\u201622 ) (C.5)\n\u2264 \u2211 q\u2208\u039bd1 ||fq \u2212 hq\u201622, d = 0, . . . , D \u2212 1. (C.6)\nWe next note that the sum over the index set \u039bd+1 inside the brackets in (C.4)-(C.5) satisfies\u2211\n\u03bbd+1\u2208\u039bd+1\n\u2016Ud+1[\u03bbd+1]fq \u2212 Ud+1[\u03bbd+1]hq\u201622\n= \u2211\n\u03bbd+1\u2208\u039bd+1\n\u2016Pd+1 ( \u03c1d+1(fq \u2217 g\u03bbd+1) ) \u2212 Pd+1 ( \u03c1d+1(hq \u2217 g\u03bbd+1) ) \u201622\n\u2264 R2d+1 \u2211\n\u03bbd+1\u2208\u039bd+1\n\u2016\u03c1d+1(fq \u2217 g\u03bbd+1) (C.7)\n\u2212 \u03c1d+1(hq \u2217 g\u03bbd+1)\u201622 (C.8) \u2264 R2d+1L2d+1 \u2211\n\u03bbd+1\u2208\u039bd+1\n\u2016(fq \u2212 hq) \u2217 g\u03bbd+1\u201622, (C.9)\nwhere we employed the Lipschitz continuity of Pd+1 in (C.7)-(C.8) and the Lipschitz continuity of \u03c1d+1 in (C.9). Substituting the sum over the index set \u039bd+1 inside the brackets in (C.4)-(C.5) by the upper bound (C.9) yields\u2211 q\u2208\u039bd1 ( \u2016(fq \u2212 hq) \u2217 \u03c7d\u201622\n+ \u2211\n\u03bbd+1\u2208\u039bd+1\n\u2016Ud+1[\u03bbd+1]fq \u2212 Ud+1[\u03bbd+1]hq\u201622 )\n\u2264 \u2211 q\u2208\u039bd1 max{1, R2d+1L2d+1} ( \u2016(fq \u2212 hq) \u2217 \u03c7d\u201622 (C.10)\n+ \u2211\n\u03bbd+1\u2208\u039bd+1\n\u2016(fq \u2212 hq) \u2217 g\u03bbd+1\u201622 ) , (C.11)\nfor d = 0, . . . , D \u2212 1. As {g\u03bbd+1}\u03bbd+1\u2208\u039bd+1 \u222a {\u03c7d} are atoms of the convolutional set \u03a8d+1, and fq, hq \u2208 HNd+1 , we have\n\u2016(fq \u2212 hq) \u2217 \u03c7d\u201622 + \u2211\n\u03bbd+1\u2208\u039bd+1\n\u2016(fq \u2212 hq) \u2217 g\u03bbd+1\u201622\n\u2264 Bd+1\u2016fq \u2212 hq\u201622,\nwhich, when used in (C.10)-(C.11) yields\u2211 q\u2208\u039bd1 ( \u2016(fq \u2212 hq) \u2217 \u03c7d\u201622\n+ \u2211\n\u03bbd+1\u2208\u039bd+1\n\u2016Ud+1[\u03bbd+1]fq \u2212 Ud+1[\u03bbd+1]hq\u201622 )\n\u2264 \u2211 q\u2208\u039bd1 max{Bd+1, Bd+1R2d+1L2d+1}\u2016fq \u2212 hq\u201622,\n(C.12)\nfor d = 0, . . . , D \u2212 1. Finally, invoking (7) in (C.12) we get (C.4)-(C.6) and hence (C.1). This completes the proof of i).\nWe continue with ii). The key step in establishing (10) is to show that for \u03c1d(0) = 0 and Pd(0) = 0, for\nd \u2208 {1, . . . , D \u2212 1}, the feature extractor \u03a6\u2126 satisfies \u03a6\u2126(0) = 0, and to employ (8) with h = 0 which yields\n|||\u03a6(f)||| \u2264 \u2016f\u2016,\nfor f \u2208 HN1 . It remains to prove that \u03a6\u2126(h) = 0 for h = 0. For h = 0, the operator Ud, d \u2208 {1, 2, . . . , D}, defined in (4) satisfies\n(Ud[\u03bbd]h) = Pd ( \u03c1d(h \u2217 g\u03bbd\ufe38 \ufe37\ufe37 \ufe38\n=0\n)\n\ufe38 \ufe37\ufe37 \ufe38 =0 ) \ufe38 \ufe37\ufe37 \ufe38\n=0\n,\nfor \u03bbd \u2208 \u039bd, by assumption. With the definition of U [q] in (5) this then yields (U [q]h) = 0 for h = 0 and all q \u2208 \u039bd1. \u03a6\u2126(0) = 0 finally follows from\n\u03a6\u2126(h) = D\u22121\u22c3 d=0 { ( U [q]h ) \u2217 \u03c7d\ufe38 \ufe37\ufe37 \ufe38\n=0\n} q\u2208\u039bd1 = 0. (C.13)\nWe proceed to iii). The proof of the deformation sensitivity bound (12) is based on two key ingredients. The first one is the Lipschitz continuity result stated in (8). The second ingredient, stated in Proposition D.1 in Appendix D, is an upper bound on the deformation error \u2016f \u2212 F\u03c4f\u20162 given by\n\u2016f \u2212 F\u03c4f\u20162 \u2264 4KN1/21 \u2016\u03c4\u20161/2\u221e , (C.14)\nwhere f \u2208 CN1,KCART . We now show how (8) and (C.14) can be combined to establish (12). To this end, we first apply (8) with h := (F\u03c4f) to get\n|||\u03a6\u2126(f)\u2212 \u03a6\u2126(F\u03c4f)||| \u2264 \u2016f \u2212 F\u03c4f\u20162, (C.15)\nfor f \u2208 CN1,KCART \u2286 HN1 , N1 \u2208 N, and K > 0, and then replace the RHS of (C.15) by the RHS of (C.14). This completes the proof of iii)."}, {"heading": "D. Appendix: Proposition D.1", "text": "Proposition D.1. For every N \u2208 N, every K > 0, and every \u03c4 : R\u2192 [\u22121, 1], we have\n\u2016f \u2212 F\u03c4f\u20162 \u2264 4KN1/2\u2016\u03c4\u20161/2\u221e , (D.1)\nfor all f \u2208 CN,KCART. Remark D.1. As already mentioned at the end of Section 4, excluding the interval boundary points a, b in the definition of sampled cartoon functions CN,KCART (see Definition 4) is necessary for technical reasons. Specifically, without imposing this exclusion, we can not expect to get deformation sensitivity results of the form (D.1). This can be seen as follows. Let us assume that we seek a bound of the form\n\u2016f \u2212 F\u03c4f\u20162 \u2264 CN,K\u2016\u03c4\u2016\u03b1\u221e, for some CN,K > 0 and some \u03b1 > 0, that applies to all f [n] = c(n/N), n \u2208 IN , with c \u2208 CKCART. Take \u03c4(x) = 1/N , in which case the deformation (F\u03c4f)[n] = c(n/N \u2212 1/N) amounts to a simple translation by 1/N and \u2016\u03c4\u2016\u221e = 1/N \u2264 1. Let c(x) = 1[0,2/N ](x). Then c \u2208 CKCART for K = 1 and \u2016f \u2212 F\u03c4f\u20162 = \u221a 2, which obviously does not decay with \u2016\u03c4\u2016\u03b1\u221e = N\u2212\u03b1 for some \u03b1 > 0. We note that this phenomenon occurs only in the discrete case.\nProof. The proof of (D.1) is based on judiciously combining deformation sensitivity bounds for the sampled components c1(n/N), c2(n/N), n \u2208 IN , in (c1 + 1[a,b]c2) \u2208 CKCART, and the sampled indicator function 1[a,b](n/N), n \u2208 IN . The first bound, stated in Lemma D.1 below, reads\n\u2016f \u2212 F\u03c4f\u20162 \u2264 CN1/2\u2016\u03c4\u2016\u221e, (D.2)\nand applies to discrete-time signals f [n] = f(n/N), n \u2208 IN , with f : R\u2192 C satisfying the Lipschitz property with Lipschitz constant C. The second bound we need, stated in Lemma D.2 below, is given by\n\u20161N[a,b] \u2212 F\u03c41 N [a,b]\u20162 \u2264 2N 1/2\u2016\u03c4\u20161/2\u221e , (D.3)\nand applies to sampled indicator functions 1N[a,b][n] := 1[a,b](n/N), n \u2208 IN , with a, b /\u2208 {0, 1N , . . . , N\u22121 N }. We now show how (D.2) and (D.3) can be combined to establish (D.1). For a sampled cartoon function f \u2208 CN,KCART, i.e.,\nf [n] = c1(n/N) + 1[a,b](n/N)c2(n/N)\n=: f1[n] + 1 N [a,b][n]f2[n], n \u2208 IN ,\nwe have\n\u2016f \u2212 F\u03c4f\u20162 \u2264 \u2016f1 \u2212 F\u03c4f1\u20162 + \u20161N[a,b](f2 \u2212 F\u03c4f2)\u20162 + \u2016(1N[a,b] \u2212 F\u03c41 N [a,b])(F\u03c4f2)\u20162 (D.4)\n\u2264 \u2016f1 \u2212 F\u03c4f1\u20162 + \u2016f2 \u2212 F\u03c4f2\u20162 + \u20161N[a,b] \u2212 F\u03c41 N [a,b]\u20162\u2016F\u03c4f2\u2016\u221e,\nwhere in (D.4) we used( F\u03c4 (1 N [a,b]f2) ) [n] = (1[a,b]c2)(n/N \u2212 \u03c4(n/N))\n= 1[a,b](n/N \u2212 \u03c4(n/N))c2((n/N \u2212 \u03c4(n/N))) = (F\u03c41 N [a,b])[n](F\u03c4f2)[n].\nWith the upper bounds (D.2) and (D.3), invoking properties of CN,KCART (namely, (i) c1, c2 satisfy the Lipschitz property with Lipschitz constant C = K and hence f1[n] = c1(n/N), f2[n] = c2(n/N), n \u2208 IN , satisfy (D.2) with C = K, and (ii) \u2016F\u03c4f2\u2016\u221e = supn\u2208IN |(F\u03c4f2)[n]| =\nsupn\u2208IN |c2(n/N \u2212 \u03c4(n/N))| \u2264 supx\u2208R |c2(x)| = \u2016c2\u2016\u221e \u2264 K), this yields\n\u2016f \u2212 F\u03c4f\u20162 \u2264 2KN1/2 \u2016\u03c4\u2016\u221e + 2KN1/2\u2016\u03c4\u20161/2\u221e \u2264 4KN1/2\u2016\u03c4\u20161/2\u221e ,\nwhere in the last step we used \u2016\u03c4\u2016\u221e \u2264 \u2016\u03c4\u20161/2\u221e , which is thanks to the assumption \u2016\u03c4\u2016\u221e \u2264 1. This completes the proof of (D.1).\nIt remains to establish (D.2) and (D.3). Lemma D.1. Let c : R \u2192 C be Lipschitz-continuous with Lipschitz constantC. Let further f [n] := c(n/N), n \u2208 IN . Then,\n\u2016f \u2212 F\u03c4f\u20162 \u2264 CN1/2\u2016\u03c4\u2016\u221e.\nProof. Invoking the Lipschitz property of c according to \u2016f \u2212 F\u03c4f\u201622 = \u2211 n\u2208IN |f [n]\u2212 (F\u03c4f)[n]|2\n= \u2211 n\u2208IN |c(n/N)\u2212 c(n/N \u2212 \u03c4(n/N))|2\n\u2264 C2 \u2211 n\u2208IN |\u03c4(n/N)|2 \u2264 C2N\u2016\u03c4\u20162\u221e\ncompletes the proof.\nWe continue with a deformation sensitivity result for sampled indicator functions 1[a,b](x). Lemma D.2. Let [a, b] \u2286 [0, 1] and set 1N[a,b][n] := 1[a,b](n/N), n \u2208 IN , with a, b /\u2208 {0, 1N , . . . , N\u22121 N }. Then, we have\n\u20161N[a,b] \u2212 F\u03c41 N [a,b]\u20162 \u2264 2N 1/2\u2016\u03c4\u20161/2\u221e .\nProof. In order to upper-bound\n\u20161N[a,b] \u2212 F\u03c41 N [a,b]\u2016 2 2 = \u2211 n\u2208IN |1N[a,b][n]\u2212 (F\u03c41 N [a,b])[n]| 2\n= \u2211 n\u2208IN |1[a,b](n/N)\u2212 1[a,b](n/N \u2212 \u03c4(n/N))|2,\nwe first note that the summand h(n) := |1[a,b](n/N) \u2212 1[a,b](n/N \u2212 \u03c4(n/N))|2 satisfies h(n) = 1, for n \u2208 S, where\nS := { n \u2208 IN \u2223\u2223\u2223 n N \u2208 [a, b] and n N \u2212 \u03c4 ( n N ) /\u2208 [a, b] } \u222a { n \u2208 IN \u2223\u2223\u2223 n N /\u2208 [a, b] and n N \u2212 \u03c4 ( n N ) \u2208 [a, b] } ,\nand h(n) = 0, for n \u2208 IN\\S. Thanks to a, b /\u2208 {0, 1N , . . . , N\u22121 N }, we have S \u2286 \u03a3, where\n\u03a3 := { n \u2208 Z \u2223\u2223\u2223 \u2223\u2223\u2223 n N \u2212 a \u2223\u2223\u2223 < \u2016\u03c4\u2016\u221e}\n\u222a { n \u2208 Z \u2223\u2223\u2223 \u2223\u2223\u2223 n N \u2212 b \u2223\u2223\u2223 < \u2016\u03c4\u2016\u221e}.\nThe cardinality of the set \u03a3 can be upper-bounded by 2 2\u2016\u03c4\u2016\u221e1/N , which then yields\n\u20161N[a,b] \u2212 F\u03c41 N [a,b]\u2016 2 2 = \u2211 n\u2208IN |h(n)|2\n= \u2211 n\u2208S 1 \u2264 \u2211 n\u2208\u03a3 1 \u2264 4N\u2016\u03c4\u2016\u221e. (D.5)\nThis completes the proof.\nRemark D.2. For general a, b \u2208 [0, 1], i.e., when we drop the assumption a, b /\u2208 {0, 1N , . . . , N\u22121 N }, it follows that S \u2286 \u03a3\u2032, where\n\u03a3\u2032 := { n \u2208 Z \u2223\u2223\u2223 \u2223\u2223\u2223 n N \u2212 a \u2223\u2223\u2223 \u2264 \u2016\u03c4\u2016\u221e}\n\u222a { n \u2208 Z \u2223\u2223\u2223 \u2223\u2223\u2223 n N \u2212 b \u2223\u2223\u2223 \u2264 \u2016\u03c4\u2016\u221e}.\nNoting that the cardinality of \u03a3\u2032 can be upper-bounded by 2 ( 2\u2016\u03c4\u2016\u221e 1/N + 1 )\n= 4N\u2016\u03c4\u2016\u221e + 2, this then yields (similarly to (D.5))\n\u20161N[a,b] \u2212 F\u03c41 N [a,b]\u2016 2 2 \u2264 \u2211 n\u2208\u03a3 1 \u2264 4N\u2016\u03c4\u2016\u221e + 2,\nwhich shows that the deformation error\u2014for general a, b \u2208 [0, 1]\u2014does not decay with \u2016\u03c4\u2016\u03b1\u221e for some \u03b1 > 0 (see also the example in Remark D.1)."}, {"heading": "E. Appendix: Theorem 2", "text": "We start by establishing i). For ease of notation, again, we let fq := U [q]f and hq := U [q]h, for f, h \u2208 HN1 , q \u2208 \u039bd1. We have\n|||\u03a6d\u2126(f)\u2212 \u03a6d\u2126(h)|||2 = \u2211 q\u2208\u039bd1 ||(fq \u2212 hq) \u2217 \u03c7d||22 (E.1)\n\u2264 \u2016\u03c7d\u201621 \u2211 q\u2208\u039bd1\n||(fq \u2212 hq)||22\ufe38 \ufe37\ufe37 \ufe38 =:ad , (E.2)\nwhere (E.2) follows by Young\u2019s inequality (Folland, 2015).\nRemark E.1. We emphasize that (E.1) can also be upperbounded byBd+1 \u2211 q\u2208\u039bd1\n||(fq\u2212hq)||22, which follows from the fact that {g\u03bbd+1}\u03bbd+1\u2208\u039bd+1 \u222a {\u03c7d} are atoms of the convolutional set \u03a8d+1 with Bessel bound Bd+1. Hence, one can substitute \u2016\u03c7d\u20161 in (15) by Bd+1.\nThe key step is then to show that ad can be upper-bounded according to\nak \u2264 (BkL2kR2k)ak\u22121, k = 1, . . . , d, (E.3)\nand to note that\nad \u2264 (BdL2dR2d)ad\u22121 \u2264 \u00b7 \u00b7 \u00b7 \u2264 ( d\u220f k=1 BkL 2 kR 2 k ) a0\n= ( d\u220f k=1 BkL 2 kR 2 k ) \u2211 q\u2208\u039b01 \u2016fq \u2212 hq\u201622\n= ( d\u220f k=1 BkL 2 kR 2 k ) \u2016f \u2212 h\u201622,\nwhich yields (16). We now establish (E.3). Every path\nq\u0303 \u2208 \u039bk1 = \u039b1 \u00d7 \u00b7 \u00b7 \u00b7 \u00d7 \u039bk\u22121\ufe38 \ufe37\ufe37 \ufe38 =\u039bk\u221211 \u00d7\u039bk\nof length k can be decomposed into a path q \u2208 \u039bk\u221211 of length k \u2212 1 and an index \u03bbk \u2208 \u039bk according to q\u0303 = (q, \u03bbk). Thanks to (5) we have U [q\u0303] = U [(q, \u03bbk)] = Uk[\u03bbk]U [q], which yields\u2211\nq\u0303\u2208\u039bk1\n\u2016fq\u0303 \u2212 hq\u0303\u201622 = \u2211\nq\u2208\u039bk\u221211\n\u2211 \u03bbk\u2208\u039bk \u2016Uk[\u03bbk]fq\n\u2212 Uk[\u03bbk]hq\u201622. (E.4)\nWe next note that the term inside the sums on the RHS in (E.4) satisfies\n\u2016Uk[\u03bbk]fq \u2212 Uk[\u03bbk]hq\u201622 = \u2016Pk ( \u03c1k(fq \u2217 g\u03bbk) ) \u2212 Pk ( \u03c1k(hq \u2217 g\u03bbk) ) \u201622\n\u2264 L2kR2k\u2016(fq \u2212 hq) \u2217 g\u03bbk\u201622, (E.5)\nwhere we used the Lipschitz continuity of Pk and \u03c1k with Lipschitz constants Rk > 0 and Lk > 0, respectively. As {g\u03bbk}\u03bbk\u2208\u039bk \u222a {\u03c7k\u22121} are the atoms of the convolutional set \u03a8k, and fq, hq \u2208 HNk by (5), we have\u2211\n\u03bbk\u2208\u039bk\n\u2016(fq \u2212 hq) \u2217 g\u03bbk\u201622 \u2264 Bk\u2016fq \u2212 hq\u201622,\nwhich, when used in (E.5) together with (E.4), yields\u2211 q\u0303\u2208\u039bk1 \u2016fq\u0303 \u2212 hq\u0303\u201622 \u2264 BkL2kR2k \u2211 q\u2208\u039bk\u221211 \u2016fq \u2212 hq\u201622,\nand hence establishes (E.3), thereby completing the proof of i).\nWe now turn to ii). The proof of (17) follows\u2014as in the proof of ii) in Theorem 1 in Appendix C\u2014from (16) together with \u03a6d\u2126(h) = {(U [q]h) \u2217 \u03c7d}q\u2208\u039bd1 = 0 for h = 0, see (C.13).\nWe continue with iii). The proof of the deformation sensitivity bound (18) is based on two key ingredients. The\nfirst one is the Lipschitz continuity result in (16). The second ingredient is, again, the deformation sensitivity bound (D.1) stated in Proposition D.1 in Appendix D. Combining (16) and (D.1)\u2014as in the proof of iii) in Theorem 1 in Appendix C\u2014then establishes (18) and completes the proof of iii).\nWe proceed to iv). For ease of notation, again, we let fq := U [q]f , for f \u2208 HN1 , q \u2208 \u039bd1. Thanks to (5), we have fq \u2208 HNd+1 , for q \u2208 \u039bd1. The key step in establishing (19) is to show that the operator Uk, k \u2208 {1, 2, . . . , d}, defined in (4) satisfies the relation\n(Uk[\u03bbk]Tmf) = Tm/Sk(Uk[\u03bbk]f), (E.6)\nfor f \u2208 HNk , m \u2208 Z with mSk \u2208 Z, and \u03bbk \u2208 \u039bk. With the definition of U [q] in (5) this then yields\n(U [q]Tmf) = Tm/(S1\u00b7\u00b7\u00b7Sd)(U [q]f), (E.7)\nfor f \u2208 HN1 , m \u2208 Z with mS1...Sd \u2208 Z, and q \u2208 \u039b d 1. The identity (19) is then a direct consequence of (E.7) and the translation-covariance of the circular convolution operator (which holds thanks to mS1...Sd \u2208 Z):\n\u03a6d\u2126(Tmf) = {( U [q]Tmf ) \u2217 \u03c7d } q\u2208\u039bd1\n= {( Tm/(S1\u00b7\u00b7\u00b7Sd)U [q]f ) \u2217 \u03c7d } q\u2208\u039bd1\n= { Tm/(S1\u00b7\u00b7\u00b7Sd) ( (U [q]f) \u2217 \u03c7d )} q\u2208\u039bd1 = Tm/(S1\u00b7\u00b7\u00b7Sd)\u03a6 d \u2126(f),\nfor f \u2208 HN1 and m \u2208 Z with mS1...Sd \u2208 Z. It remains to establish (E.6):\n(Uk[\u03bbk]Tmf) = ( Pk ( \u03c1k((Tmf) \u2217 g\u03bbk) )) = ( Pk ( \u03c1k(Tm(f \u2217 g\u03bbk)) )) (E.8)\n= ( Pk ( Tm(\u03c1k(f \u2217 g\u03bbk)) )) , (E.9)\nwhere in (E.8) we used the translation covariance of the circular convolution operator (which holds thanks to m \u2208 Z), and in (E.9) we used the fact that point-wise non-linearities commute with the translation operator thanks to\n(\u03c1kTmf)[n] = \u03c1k((Tmf)[n])\n= \u03c1k(f [n\u2212m]) = (Tm\u03c1kf)[n],\nfor f \u2208 HNk , n \u2208 INk , and m \u2208 Z. Next, we note that the pooling operators Pk in Section 2.3.1 (namely, sub-sampling, average pooling, and max-pooling) can all be written as (Pkf)[n] = (P \u2032kf)[Skn], for some P \u2032 k that commutes with the translation operator, namely, for (i) sub-sampling (P \u2032kf)[n] = f [n], with (P \u2032 kTmf)[n] =\n(Tmf)[n] = f [n\u2212m] = (TmP \u2032kf)[n], (ii) average pooling (P \u2032kf)[n] = \u2211n+Sk\u22121 l=n \u03b1l\u2212nf [l] with\n(P \u2032kTmf)[n] = n+Sk\u22121\u2211 l=n \u03b1l\u2212nf [l \u2212m]\n= (n\u2212m)+Sk\u22121\u2211 l\u2032=(n\u2212m) \u03b1l\u2212(n\u2212m)f [l \u2032] = (TmP \u2032 kf)[n],\nand for (iii) max-pooling (P \u2032kf)[n] = maxl\u2208{n,...,n+Sk\u22121} |f [l]| with\n(P \u2032kTmf)[n] = max l\u2208{n,...,n+Sk\u22121} |f [l \u2212m]|\n= max (l\u2212m)\u2208{n\u2212m,...,(n\u2212m)+Sk\u22121}\n|f [l \u2212m]|\n= max l\u2032\u2208{(n\u2212m),...,(n\u2212m)+Sk\u22121}\n|f [l\u2032]|\n= (TmP \u2032 kf)[n],\nin all three cases for f \u2208 HNk , n \u2208 INk , and m \u2208 Z. This then yields\n(PkTmf)[n] = (P \u2032 kTmf)[Skn] = (TmP \u2032 kf)[Skn]\n= P \u2032k(f)[Skn\u2212m] = P \u2032k(f)[Sk(n\u2212 S\u22121k m)] = Pk(f)[n\u2212 S\u22121k m] = (Tm/SkPkf)[n], (E.10)\nfor f \u2208 HNk and n \u2208 INk+1 . Here, we used m/Sk \u2208 Z, which is by assumption. Substituting (E.10) into (E.9) finally yields\n(Uk[\u03bbk]Tmf) = Tm/SkUk[\u03bbk]f,\nfor f \u2208 HNk , m \u2208 Z with mSk \u2208 Z, and \u03bbk \u2208 \u039bk. This completes the proof of (E.6) and hence establishes (19)."}], "references": [{"title": "Deep scattering spectrum", "author": ["J. And\u00e9n", "S. Mallat"], "venue": "IEEE Trans. Sig. Process.,", "citeRegEx": "And\u00e9n and Mallat,? \\Q2014\\E", "shortCiteRegEx": "And\u00e9n and Mallat", "year": 2014}, {"title": "Pruning training sets for learning of object categories", "author": ["A. Angelova", "Y. Abu-Mostafa", "P. Perona"], "venue": "In Proc. of IEEE Conf. Comp. Vision Pattern Recog. (CVPR),", "citeRegEx": "Angelova et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Angelova et al\\.", "year": 2005}, {"title": "Representation learning: A review and new perspectives", "author": ["Y. Bengio", "A. Courville", "P. Vincent"], "venue": "IEEE Trans. Pattern Anal. Mach. Intell.,", "citeRegEx": "Bengio et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Bengio et al\\.", "year": 2013}, {"title": "Discrete Zak transforms, polyphase transforms, and applications", "author": ["H. B\u00f6lcskei", "F. Hlawatsch"], "venue": "IEEE Trans. Sig. Process.,", "citeRegEx": "B\u00f6lcskei and Hlawatsch,? \\Q1997\\E", "shortCiteRegEx": "B\u00f6lcskei and Hlawatsch", "year": 1997}, {"title": "Classification and regression trees", "author": ["L. Breiman", "J. Friedman", "C.J. Stone", "R.A. Olshen"], "venue": null, "citeRegEx": "Breiman et al\\.,? \\Q1984\\E", "shortCiteRegEx": "Breiman et al\\.", "year": 1984}, {"title": "Invariant scattering convolution networks", "author": ["J. Bruna", "S. Mallat"], "venue": "IEEE Trans. Pattern Anal. Mach. Intell.,", "citeRegEx": "Bruna and Mallat,? \\Q2013\\E", "shortCiteRegEx": "Bruna and Mallat", "year": 2013}, {"title": "Fast discrete curvelet transforms", "author": ["E.J. Cand\u00e8s", "L. Demanet", "D. Donoho", "L. Ying"], "venue": "Multiscale Modeling and Simulation,", "citeRegEx": "Cand\u00e8s et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Cand\u00e8s et al\\.", "year": 2006}, {"title": "Realtime facial feature detection using conditional regression forests", "author": ["M. Dantone", "J. Gall", "G. Fanelli", "L. Van Gool"], "venue": "In Proc. of IEEE Conf. Comp. Vision Pattern Recog. (CVPR),", "citeRegEx": "Dantone et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Dantone et al\\.", "year": 2012}, {"title": "Comparison of parametric representations for monosyllabic word recognition in continuously spoken sentences", "author": ["S. Davis", "P. Mermelstein"], "venue": "IEEE Trans. Acoust., Speech, and Signal Process.,", "citeRegEx": "Davis and Mermelstein,? \\Q1980\\E", "shortCiteRegEx": "Davis and Mermelstein", "year": 1980}, {"title": "Sparse components of images and optimal atomic decompositions", "author": ["D. Donoho"], "venue": "Constructive Approximation,", "citeRegEx": "Donoho,? \\Q2001\\E", "shortCiteRegEx": "Donoho", "year": 2001}, {"title": "A course in abstract harmonic analysis, volume 29", "author": ["G.B. Folland"], "venue": "CRC Press,", "citeRegEx": "Folland,? \\Q2015\\E", "shortCiteRegEx": "Folland", "year": 2015}, {"title": "Matrix computations", "author": ["G.H. Golub", "C.F. Van Loan"], "venue": null, "citeRegEx": "Golub and Loan,? \\Q2013\\E", "shortCiteRegEx": "Golub and Loan", "year": 2013}, {"title": "Deep convolutional neural networks on cartoon functions", "author": ["P. Grohs", "T. Wiatowski", "H. B\u00f6lcskei"], "venue": "In Proc. of IEEE Int. Symp. on Inform. Theory (ISIT),", "citeRegEx": "Grohs et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Grohs et al\\.", "year": 2016}, {"title": "A real-time algorithm for signal analysis with the help of the wavelet transform", "author": ["M. Holschneider", "R. Kronland-Martinet", "J. Morlet", "P. Tchamitchian"], "venue": "In Wavelets,", "citeRegEx": "Holschneider et al\\.,? \\Q1989\\E", "shortCiteRegEx": "Holschneider et al\\.", "year": 1989}, {"title": "Large-scale learning with SVM and convolutional nets for generic object categorization", "author": ["F.J. Huang", "Y. LeCun"], "venue": "In Proc. of IEEE Conf. Comp. Vision Pattern Recog. (CVPR),", "citeRegEx": "Huang and LeCun,? \\Q2006\\E", "shortCiteRegEx": "Huang and LeCun", "year": 2006}, {"title": "What is the best multi-stage architecture for object recognition", "author": ["K. Jarrett", "K. Kavukcuoglu", "M.A. Ranzato", "Y. LeCun"], "venue": "In Proc. of IEEE Int. Conf. on Computer Vision (ICCV),", "citeRegEx": "Jarrett et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Jarrett et al\\.", "year": 2009}, {"title": "Learning multiple layers of features from tiny images", "author": ["A. Krizhevsky"], "venue": "MS thesis, University of Toronto,", "citeRegEx": "Krizhevsky,? \\Q2009\\E", "shortCiteRegEx": "Krizhevsky", "year": 2009}, {"title": "Shearlets: Multiscale analysis for multivariate data", "author": ["G. Kutyniok", "Labate", "D. (eds"], "venue": null, "citeRegEx": "Kutyniok et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Kutyniok et al\\.", "year": 2012}, {"title": "Introduction to shearlets. In Shearlets: Multiscale analysis for multivariate data, pp. 1\u201338", "author": ["G. Kutyniok", "D. Labate"], "venue": null, "citeRegEx": "Kutyniok and Labate,? \\Q2012\\E", "shortCiteRegEx": "Kutyniok and Labate", "year": 2012}, {"title": "The MNIST database of handwritten digits", "author": ["Y. LeCun", "C. Cortes"], "venue": "http://yann.lecun.com/exdb/ mnist/,", "citeRegEx": "LeCun and Cortes,? \\Q1998\\E", "shortCiteRegEx": "LeCun and Cortes", "year": 1998}, {"title": "Gradientbased learning applied to document recognition", "author": ["Y. LeCun", "L. Bottou", "Y. Bengio", "P. Haffner"], "venue": "In Proc. of the IEEE,", "citeRegEx": "LeCun et al\\.,? \\Q1998\\E", "shortCiteRegEx": "LeCun et al\\.", "year": 1998}, {"title": "Distinctive image features from scaleinvariant keypoints", "author": ["D.G. Lowe"], "venue": "International Journal of Computer Vision,", "citeRegEx": "Lowe,? \\Q2004\\E", "shortCiteRegEx": "Lowe", "year": 2004}, {"title": "A wavelet tour of signal processing: The sparse way", "author": ["S. Mallat"], "venue": null, "citeRegEx": "Mallat,? \\Q2009\\E", "shortCiteRegEx": "Mallat", "year": 2009}, {"title": "Group invariant scattering", "author": ["S. Mallat"], "venue": "Comm. Pure Appl. Math.,", "citeRegEx": "Mallat,? \\Q2012\\E", "shortCiteRegEx": "Mallat", "year": 2012}, {"title": "Multiclass object recognition with sparse, localized features", "author": ["J. Mutch", "D.G. Lowe"], "venue": "In Proc. of IEEE Conf. Comp. Vision Pattern Recog. (CVPR), pp", "citeRegEx": "Mutch and Lowe,? \\Q2006\\E", "shortCiteRegEx": "Mutch and Lowe", "year": 2006}, {"title": "Deep roto-translation scattering for object classification", "author": ["E. Oyallon", "S. Mallat"], "venue": null, "citeRegEx": "Oyallon and Mallat,? \\Q2014\\E", "shortCiteRegEx": "Oyallon and Mallat", "year": 2014}, {"title": "Why is real-world visual object recognition hard", "author": ["N. Pinto", "D.D. Cox", "J.J. DiCarlo"], "venue": "PLoS Computational Biology,", "citeRegEx": "Pinto et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Pinto et al\\.", "year": 2008}, {"title": "Efficient learning of sparse representations with an energybased model", "author": ["M. Ranzato", "C. Poultney", "S. Chopra", "Y. LeCun"], "venue": "In Proc. of Int. Conf. on Neural Information Processing Systems (NIPS),", "citeRegEx": "Ranzato et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Ranzato et al\\.", "year": 2006}, {"title": "Unsupervised learning of invariant feature hierarchies with applications to object recognition", "author": ["M.A. Ranzato", "F.J. Huang", "Y.L. Boureau", "Y. LeCun"], "venue": "In Proc. of IEEE Conf. Comp. Vision Pattern Recog. (CVPR),", "citeRegEx": "Ranzato et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Ranzato et al\\.", "year": 2007}, {"title": "Object recognition with features inspired by visual cortex", "author": ["T. Serre", "L. Wolf", "T. Poggio"], "venue": "In Proc. of IEEE Conf. Comp. Vision Pattern Recog. (CVPR),", "citeRegEx": "Serre et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Serre et al\\.", "year": 2005}, {"title": "An efficient dense descriptor applied to wide-baseline stereo", "author": ["E. Tola", "V. Lepetit", "Fua", "P. Daisy"], "venue": "IEEE Trans. Pattern Anal. Mach. Intell.,", "citeRegEx": "Tola et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Tola et al\\.", "year": 2010}, {"title": "Robust real-time face detection", "author": ["P. Viola", "M.J. Jones"], "venue": "International Journal of Computer Vision,", "citeRegEx": "Viola and Jones,? \\Q2004\\E", "shortCiteRegEx": "Viola and Jones", "year": 2004}, {"title": "A mathematical theory of deep convolutional neural networks for feature extraction", "author": ["T. Wiatowski", "H. B\u00f6lcskei"], "venue": null, "citeRegEx": "Wiatowski and B\u00f6lcskei,? \\Q2015\\E", "shortCiteRegEx": "Wiatowski and B\u00f6lcskei", "year": 2015}], "referenceMentions": [{"referenceID": 2, "context": "Deep convolutional neural networks (DCNNs) have proven tremendously successful in a wide range of machine learning tasks (Bengio et al., 2013; LeCun et al., 2015).", "startOffset": 121, "endOffset": 162}, {"referenceID": 20, "context": "DCNNs are typically distinguished according to (i) whether the filters employed are learned (in a supervised (LeCun et al., 1998; Huang & LeCun, 2006; Jarrett et al., 2009) or unsupervised (Ranzato et al.", "startOffset": 109, "endOffset": 172}, {"referenceID": 15, "context": "DCNNs are typically distinguished according to (i) whether the filters employed are learned (in a supervised (LeCun et al., 1998; Huang & LeCun, 2006; Jarrett et al., 2009) or unsupervised (Ranzato et al.", "startOffset": 109, "endOffset": 172}, {"referenceID": 29, "context": ", wavelets (Serre et al., 2005; Mutch & Lowe, 2006; Mallat, 2012), or unstructured, such as random filters (Ranzato et al.", "startOffset": 11, "endOffset": 65}, {"referenceID": 23, "context": ", wavelets (Serre et al., 2005; Mutch & Lowe, 2006; Mallat, 2012), or unstructured, such as random filters (Ranzato et al.", "startOffset": 11, "endOffset": 65}, {"referenceID": 28, "context": ", 2005; Mutch & Lowe, 2006; Mallat, 2012), or unstructured, such as random filters (Ranzato et al., 2007; Jarrett et al., 2009)), (ii) the non-linearities used (e.", "startOffset": 83, "endOffset": 127}, {"referenceID": 15, "context": ", 2005; Mutch & Lowe, 2006; Mallat, 2012), or unstructured, such as random filters (Ranzato et al., 2007; Jarrett et al., 2009)), (ii) the non-linearities used (e.", "startOffset": 83, "endOffset": 127}, {"referenceID": 23, "context": "First steps towards addressing this question and developing a mathematical theory of DCNNs for feature extraction were made\u2014for the continuous-time case\u2014in (Mallat, 2012; Wiatowski & B\u00f6lcskei, 2015).", "startOffset": 156, "endOffset": 198}, {"referenceID": 23, "context": "Specifically, (Mallat, 2012) analyzed so-called scattering networks, where signals are propagated through layers that employ directional wavelet filters and modulus non-linearities but no intra-layer pooling.", "startOffset": 14, "endOffset": 28}, {"referenceID": 12, "context": "signals (Wiatowski & B\u00f6lcskei, 2015), cartoon functions (Grohs et al., 2016), and Lipschitz-continuous functions (Grohs et al.", "startOffset": 56, "endOffset": 76}, {"referenceID": 12, "context": ", 2016), and Lipschitz-continuous functions (Grohs et al., 2016), Lipschitz continuity of the feature extractor automatically leads to bounds on deformation sensitivity.", "startOffset": 44, "endOffset": 64}, {"referenceID": 12, "context": "Specifically, we follow the philosophy put forward in (Wiatowski & B\u00f6lcskei, 2015; Grohs et al., 2016).", "startOffset": 54, "endOffset": 102}, {"referenceID": 9, "context": "Specifically, we analyze the (local and global) deformation and translation sensitivity properties of feature vectors corresponding to sampled cartoon functions (Donoho, 2001).", "startOffset": 161, "endOffset": 175}, {"referenceID": 22, "context": "Examples of structured convolutional sets withA = B = 1 include, in the 1-D case, wavelets (Daubechies, 1992) and Weyl-Heisenberg functions (B\u00f6lcskei & Hlawatsch, 1997), and in the 2-D case, tensorized wavelets (Mallat, 2009), curvelets (Cand\u00e8s et al.", "startOffset": 211, "endOffset": 225}, {"referenceID": 6, "context": "Examples of structured convolutional sets withA = B = 1 include, in the 1-D case, wavelets (Daubechies, 1992) and Weyl-Heisenberg functions (B\u00f6lcskei & Hlawatsch, 1997), and in the 2-D case, tensorized wavelets (Mallat, 2009), curvelets (Cand\u00e8s et al., 2006), and shearlets (Kutyniok & Labate, 2012a).", "startOffset": 237, "endOffset": 258}, {"referenceID": 20, "context": "The weights {\u03b1k} k=0 can be learned (LeCun et al., 1998) or prespecified (Pinto et al.", "startOffset": 36, "endOffset": 56}, {"referenceID": 26, "context": ", 1998) or prespecified (Pinto et al., 2008) (e.", "startOffset": 24, "endOffset": 44}, {"referenceID": 21, "context": "It was argued in (Bruna & Mallat, 2013; And\u00e9n & Mallat, 2014; Oyallon & Mallat, 2014) that the features \u03a6\u03a9(f) when generated by wavelet filters, modulus non-linearities, without intra-layer pooling, and by employing output-generating atoms with low-pass characteristics, describe mel frequency cepstral coefficients (Davis & Mermelstein, 1980) in 1-D, and SIFT-descriptors (Lowe, 2004; Tola et al., 2010) in 2-D.", "startOffset": 373, "endOffset": 404}, {"referenceID": 30, "context": "It was argued in (Bruna & Mallat, 2013; And\u00e9n & Mallat, 2014; Oyallon & Mallat, 2014) that the features \u03a6\u03a9(f) when generated by wavelet filters, modulus non-linearities, without intra-layer pooling, and by employing output-generating atoms with low-pass characteristics, describe mel frequency cepstral coefficients (Davis & Mermelstein, 1980) in 1-D, and SIFT-descriptors (Lowe, 2004; Tola et al., 2010) in 2-D.", "startOffset": 373, "endOffset": 404}, {"referenceID": 9, "context": "Cartoon functions\u2014as introduced in continuous time in (Donoho, 2001)\u2014are piecewise \u201csmooth\u201d apart from curved discontinuities along Lipschitz-continuous hypersurfaces.", "startOffset": 54, "endOffset": 68}, {"referenceID": 16, "context": ", 2007) and the CIFAR-100 (Krizhevsky, 2009) datasets, for images of handwritten digits (LeCun & Cortes, 1998) (see Fig.", "startOffset": 26, "endOffset": 44}, {"referenceID": 12, "context": "Bounds on deformation sensitivity for cartoon functions in continuous-time DCNNs were recently reported in (Grohs et al., 2016).", "startOffset": 107, "endOffset": 127}, {"referenceID": 13, "context": "Circular convolutions with the 1-D filters underlying the tensorized wavelets are efficiently implemented using the algorithme \u00e0 trous (Holschneider et al., 1989).", "startOffset": 135, "endOffset": 162}, {"referenceID": 22, "context": "2) wavelets (Mallat, 2009), both with J = 3 scales, the non-linearities described in Section 2.", "startOffset": 12, "endOffset": 26}, {"referenceID": 4, "context": "In both cases, feature importance is assessed using the Gini importance (Breiman et al., 1984), averaged over all trees.", "startOffset": 72, "endOffset": 94}, {"referenceID": 1, "context": "We use the Caltech 10,000 Web Faces data base (Angelova et al., 2005).", "startOffset": 46, "endOffset": 69}, {"referenceID": 7, "context": "Following (Dantone et al., 2012) we report the localization error, i.", "startOffset": 10, "endOffset": 32}, {"referenceID": 7, "context": "As an aside, we note that these values are comparable with the ones reported in (Dantone et al., 2012) for a conditional RF using patch comparison features (evaluated on a different dataset and a larger set of facial landmarks).", "startOffset": 80, "endOffset": 102}, {"referenceID": 10, "context": "2) follows by Young\u2019s inequality (Folland, 2015).", "startOffset": 33, "endOffset": 48}], "year": 2016, "abstractText": "First steps towards a mathematical theory of deep convolutional neural networks for feature extraction were made\u2014for the continuous-time case\u2014 in Mallat, 2012, and Wiatowski and B\u00f6lcskei, 2015. This paper considers the discrete case, introduces new convolutional neural network architectures, and proposes a mathematical framework for their analysis. Specifically, we establish deformation and translation sensitivity results of local and global nature, and we investigate how certain structural properties of the input signal are reflected in the corresponding feature vectors. Our theory applies to general filters and general Lipschitz-continuous non-linearities and pooling operators. Experiments on handwritten digit classification and facial landmark detection\u2014including feature importance evaluation\u2014complement the theoretical findings.", "creator": "LaTeX with hyperref package"}}}