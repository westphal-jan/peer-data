{"id": "1606.06125", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "20-Jun-2016", "title": "Introducing a Calculus of Effects and Handlers for Natural Language Semantics", "abstract": "In compositional model-theoretic semantics, researchers assemble truth-conditions or other kinds of denotations using the lambda calculus. It was previously observed that the lambda terms and/or the denotations studied tend to follow the same pattern: they are instances of a monad. In this paper, we present an extension of the simply-typed lambda calculus that exploits this uniformity using the recently discovered technique of effect handlers (which also addresses the problem of the implicit representation in the original model).\n\n\n\n\nThe technique was used by John Bell, who was an editor at C-SPAN for a short time.\nThe study was published in Proceedings of the National Academy of Sciences, which is presented at the U.S. National Science Foundation in February 2014.", "histories": [["v1", "Mon, 20 Jun 2016 14:05:59 GMT  (36kb)", "http://arxiv.org/abs/1606.06125v1", null], ["v2", "Fri, 8 Jul 2016 07:14:44 GMT  (36kb)", "http://arxiv.org/abs/1606.06125v2", null]], "reviews": [], "SUBJECTS": "cs.CL cs.PL", "authors": ["jirka mar\\v{s}\\'ik", "maxime amblard"], "accepted": false, "id": "1606.06125"}, "pdf": {"name": "1606.06125.pdf", "metadata": {"source": "CRF", "title": null, "authors": [], "emails": ["maxime.amblard}@loria.fr"], "sections": [{"heading": null, "text": "ar X\niv :1\n60 6.\n06 12\n5v 1\n[ cs\n.C L\n] 2\n0 Ju\nKeywords: compositionality, side effects, monads, handlers, deixis, conventional implicature"}, {"heading": "1 Introduction", "text": "The prevailing methodology of formal semantics is compositionality in the sense of Frege: denotations of complex phrases are functions of the denotations of their immediate constituents. However, several phenomena have been identified that challenge this notion of compositionality. Examples include anaphora, presupposition, quantification, deixis and conventional implicature. In all of these examples, simple models of denotation (i.e. noun phrases are individuals, sentences are truth-values) run into complications as the denotations can depend on external values (anaphora, deixis) or on something which is not an immediate constituent (presupposition, quantification, conventional implicature).\nAmong the solutions to these challenges, we find (at least) two types of solutions. First, we have those that relax the condition of compositionality. Notably, the denotation of a complex phrase is no longer a function per se of the denotations of its immediate subconstituents. Rather, it is some other formally defined process.1 Examples of this approach include:\n1 This kind of distinction is the same distinction as the one between a mathematical function and a function in a programming language, which might have all kinds of side effects and therefore not be an actual function.\n\u2013 the incremental algorithm used to build discourse representation structures in DRT, as presented in [12] \u2013 the \u03bb\u00b5 calculus, used in [5] to analyze quantification, since, due to the lack of confluence, function terms do not denote functions over simple denotations \u2013 the use of exceptions and exception handlers in [18] to model presuppositions in an otherwise compositional framework \u2013 the parsetree interpretation step in the logic of conventional implicatures of [23] that builds the denotation of a sentence by extracting implicatures from the denotations of its subparts (including the non-immediate ones)\nThe other approach is to enrich the denotations so that they are parameterized by the external information they need to obtain and contain whatever internal information they need to provide to their superconstituents. Here are some examples of this style:\n\u2013 any kind of semantic indices (e.g. the speaker and addressee for deixis, the current world for modality), since they amount to saying that a phrase denotes an indexed set of simpler meanings \u2013 the continuized semantics for quantification [1] in which denotations are functions of their own continuations \u2022 and more generally, any semantics using type raising or generalized quantifiers for noun phrase denotations \u2013 the dynamic denotations of [7] that are functions of the common ground and their continuation \u2013 compositional event semantics, such as the one in [25], that shift the denotations of sentences from truth-values to predicates on events\nWe want to find a common language in which we could express the above techniques. Our inspiration comes from computer science. There, a concept known as monad has been used:\n\u2013 in denotational semantics to give the domain of interpretation for programming languages that involve side effects [21]. \u2013 in functional programming to emulate programming with side effects via term-level encodings of effectful programs [29].\nThese two principal applications of monads align with the two approaches we have seen above. The one where we change our calculus so it no longer defines pure functions (e.g. is non-deterministic, stateful or throws exceptions) and the one where we use a pure calculus to manipulate terms (denotations) that encode some interaction (e.g. dynamicity, continuations or event predication).\nMonad is a term from category-theory. Its meaning is relative to a category. For us, this will always be the category whose objects are types and whose arrows are functions between different types. A monad is formed by a functor and a pair of natural transformations that satisfy certain laws. In our case, this means that a monad is some type constructor (the functor part) and some combinators (the natural transformations) that follow some basic laws. To give an example of this,\nwe can think of the functor T (\u03b1) = (\u03b1 \u2192 o) \u2192 o together with combinators such as the type raising \u03b7(x) = \u03bbP. P x as a monad of quantification.\nThe relationship between side effects in functional programming and computational semantics has been developed in several works [27,28],2 stretching as far back as 1977 [10]. The usefulness of monads in particular has been discovered by Shan in 2002 [26]. Since then, the problem that remained was how to compose several different monads in a single solution. Charlow used the popular method of monad morphisms3 to combine several monads in his dissertation [4]. Giorgolo and Asudeh have used distributive laws to combine monads [8], while Kiselyov has eschewed monads altogether in favor of applicative functors which enjoy easy composability [13].\nOur approach follows the recent trend in adopting effects and handlers to combine side effects [2,11] and to encode effectful programs in pure functional programming languages [14,3].\nThe idea is that we can represent each of the relevant monads using an algebra. We can then combine the signatures of the algebras by taking a disjoint union. The free algebra of the resulting signature will serve as a universal representation format for the set of all terms built from any of the source algebras and closed under substitution. Then, we will build modular interpreters that will give meanings to the operators of the algebras in terms of individuals, truth-values and functions.\nIn Sect. 2, we will introduce a formal calculus for working with the algebraic terms that we will use in our linguistic denotations. In Sect. 3, we will incrementally build up a fragment involving several of the linguistic phenomena and see the calculus in action. Before we conclude in Sect. 5, we will also discuss some of the formal properties of the calculus in Sect. 4."}, {"heading": "2 Definition of the Calculus", "text": "Our calculus is an extension of the simply-typed lambda calculus (STLC). We add terms of a free algebra into our language and a notation for writing handlers, composable interpreters of these terms. An operator of the free algebra corresponds to a particular interaction that a piece of natural language can have with its context (e.g. a deictic expression might request the speaker\u2019s identity using some operator speaker in order to find its denotation). A handler gives an interpretation to every occurrence of an operator within a term (e.g. direct speech introduces a handler for the operator speaker that essentially rebinds the current speaker to some other entity).\n2 Side effects are to programming languages what pragmatics are to natural languages: they both study how expressions interact with the worlds of their users. It might then come as no surprise that phenomena such as anaphora, presupposition, deixis and conventional implicature yield a monadic description. 3 Also known as monad transformers in functional programming.\nHaving sketched the general idea behind our calculus, we will now turn our attention to the specifics. We start by defining the syntactic constructions used to build the terms of our language."}, {"heading": "2.1 Terms", "text": "First off, let X be a set of variables, \u03a3 a typed signature and E a set of operation symbols. In the definition below, we will let M , N . . . range over terms, x, y, z. . . range over variables from X , c, d. . . range over the names of constants from \u03a3 and op, opi. . . range over the operation symbols in E .\nThe terms of our language are composed of the following:\nM,N ::= \u03bbx.M [abstraction]\n| M N [application]\n| x [variable]\n| c [constant]\n| opMp (\u03bbx.Mc) [operation]\n| \u03b7M [injection]\n| L op1:M1, . . . , opn:Mn, \u03b7:M\u03b7 MN [handler] | \u2212 \u25e6 M [extraction]\n| CM [exchange]\nThe first four constructions \u2014 abstraction, application, variables and constants \u2014 come directly from STLC with constants.\nThe next four deal with the algebraic expressions used to encode computations. Let us sketch the behaviors of these four kinds of expressions.\nThe operation (op) and injection (\u03b7) expressions will serve as the constructors for our algebraic expressions. Algebraic expressions are usually formed by operation symbols and then variables as atoms. Instead of variables, our algebraic expressions use terms from our calculus for atoms. The \u03b7 constructor can thus take an ordinary term from our calculus and make it an atomic algebraic expression. The operation symbols op are then the operations of the algebra.\nThe other three expression types correspond to functions over algebraic expressions.\n\u2013 The most useful is the handler L M.4 It is an iterator for the type of algebraic expressions. The termsM1,. . . ,Mn andM\u03b7 in L op1:M1, . . . , opn:Mn, \u03b7:M\u03b7 M are the clauses for the constructors op1,. . . ,opn and \u03b7, respectively. We will use handlers to define interpretations of operation symbols in algebraic expressions. \u2013 The cherry \u2212 \u25e6 operator allows us to extract terms out of algebraic expressions.\nIf an algebraic expression is of the form \u03b7M , applying \u2212 \u25e6 to it will yield M .\n4 Pronounced \u201cbanana\u201d. See [20] for the introduction of banana brackets.\n\u2013 The exchange operator C permits a kind of commutation between the \u03bbbinder and the operation symbols. We will see its use later."}, {"heading": "2.2 Types", "text": "We now give a syntax for the types of our calculus along with a typing relation. In the grammar below, \u03b1, \u03b2, \u03b3. . . range over types, \u03bd ranges over atomic types from some set T and E, E\u2032. . . range over effect signatures (introduced below).\nThe types of our language consist of:\n\u03b1, \u03b2, \u03b3 ::= \u03b1 \u2192 \u03b2 [function]\n| \u03bd [atom]\n| FE(\u03b1) [computation]\nThe only novelty here is the FE(\u03b1) computation type. This is the type of algebraic expressions whose atoms are terms of type \u03b1 and whose operation symbols come from the effect signature E. We call them computation types and we call terms of these types computations because our algebraic expressions will always represent some kind of program with effects.\nEffect signatures are similar to typing contexts. They are partial mappings from the set of operation symbols E to pairs of types. We will write the elements of effect signatures the following way \u2014 op : \u03b1  \u03b2 \u2208 E means that E maps op to the pair of types \u03b1 and \u03b2.5 When dealing with effect signatures, we will often make use of the disjoint union operator \u228e. The term E1 \u228e E2 serves as a constraint demanding that the domains of E1 and E2 be disjoint and at the same time it denotes the effect signature that is the union of E1 and E2.\nThe typing rules are presented in Figure 1. The typing rules mirror the syntax of terms. Again, the first four rules come\nfrom STLC. The [\u03b7] and [ \u2212 \u25e6 ] rules are self-explanatory and so we will focus on the [op], [L M] and [C] rules.\n[op] To use an operation op : \u03b1  \u03b2, we provide the input parameter Mp : \u03b1 and a continuation \u03bbx.Mc : \u03b2 \u2192 FE(\u03b3), which expects the output of type \u03b2. The resulting term has the same type as the body of the continuation, FE(\u03b3).\nBefore, we have spoken of terms of type FE(\u03b3) as of algebraic expressions generated by the terms of type \u03b3 and the operators in the effect signature E. However, having seen the typing rule for operation terms, it might not be obvious how such a term represents an algebraic expression. Traditionally, algebraic signatures map operation symbols to arities, which are natural numbers. Our effect signatures map each operation symbol to a pair of types \u03b1  \u03b2.\n\u2013 We can explain \u03b1 by analogy to the single-sorted algebra of vector spaces. In a single-sorted vector space algebra, scalar multiplication is viewed as\n5 The two types \u03b1 and \u03b2 are to be seen as the operation\u2019s input and output types, respectively.\na unary operation parameterized by some scalar. So technically, there is a different unary operation for each scalar. All of our operations are similarly parameterized and \u03b1 is the type of that parameter. \u2013 The type \u03b2 expresses the arity of the operator. When we say that an operator has arity \u03b2, where \u03b2 is a type, we mean that it takes one operand for every value of \u03b2 [24]. We can also think of the operator as taking one operand containing x : \u03b2 as a free variable.\nWe can look at the algebraic expression opMp (\u03bbx.Mc) as a description of a program that:\n\u2013 interacts with its context by some operator called op \u2013 to which it provides the input Mp \u2013 and from which it expects to receive an output of type \u03b2 \u2013 which it will then bind as the variable x and continue as the program de-\nscribed by Mc.\n[L M] The banana brackets describe iterators/catamorphisms.6 In the typing rule, E is the input\u2019s signature, E\u2032 is the output\u2019s signature, \u03b3 is the input\u2019s atom type and \u03b4 is the output\u2019s atom type. E is decomposed into the operations that our\n6 These are similar to recursors/paramorphisms. See [20] for the difference. Catamorphisms are also known as folds and the common higher-order function fold found in functional programming languages is actually the iterator/catamorphism for lists.\niterator will actually interpret, the other operations form a residual signature Ef . The output signature will then still contain the uninterpreted operations Ef combined with any operations E\u2032\u2032 that our interpretation might introduce.\n[C] We said before that the C function will let us commute \u03bb and operations. Here we see that, on the type level, this corresponds to commuting the FE( ) and the \u03b1 \u2192 type constructors."}, {"heading": "2.3 Reduction Rules", "text": "We will now finally give a semantics to our calculus. The semantics will be given in the form of a reduction relation on terms. Even though the point of the calculus is to talk about effects, the reduction semantics will not be based on any fixed evaluation order; any subterm that is a redex can be reduced in any context. The reduction rules are given in Fig. 2."}, {"heading": "L (opi:Mi)i\u2208I , \u03b7:M\u03b7 M (\u03b7 N) \u2192 rule L \u03b7 M", "text": "We have the \u03b2 and \u03b7 rules, which, by no coincidence, are the same rules as the ones found in STLC. The rest are function definitions for L M, \u2212 \u25e6 and C.\nBy looking at the definition of L M, we see that it is an iterator. It replaces every occurrence of the constructors opj and \u03b7 with Mj and M\u03b7, respectively.\nThe C function recursively swaps C (\u03bbx. ) with opMp (\u03bby. ) using the Cop rule. When C finally meets the \u03b7 constructor, it swaps (\u03bbx. ) with \u03b7 and terminates. Note that the constraint x /\u2208 FV(Mp) in rule Cop cannot be dismissed by renaming of bound variables. If the parameter Mp contains a free occurrence of x, the evaluation of C will get stuck. C is thus a partial function: it is only applicable when none of the operations being commuted with the \u03bb-binder actually depend on the bound variable."}, {"heading": "2.4 Common Combinators", "text": "When demonstrating the calculus in the next section, the following combinators will be helpful. First, we define a sequencing operator. The operator \u226b=, called bind, replaces all the \u03b1-typed atoms of a FE(\u03b1)-typed expression with FE(\u03b2)typed expressions. More intuitively, M \u226b=N is the program that first runs M to get its result x and then continues as the program N x.\n\u226b= : FE(\u03b1) \u2192 (\u03b1 \u2192 FE(\u03b2)) \u2192 FE(\u03b2)\nM \u226b=N = L \u03b7:N MM\nThe type constructor FE along with the operators \u03b7 and \u226b= form a free monad. Using this monadic structure, we can define the following combinators (variations on application) which we will make heavy use of in Section 3.\n\u226a\u00b7 : FE(\u03b1 \u2192 \u03b2) \u2192 \u03b1 \u2192 FE(\u03b2)\nF \u226a\u00b7 x = F \u226b= (\u03bbf. \u03b7 (f x))\n\u00b7\u226b : (\u03b1 \u2192 \u03b2) \u2192 FE(\u03b1) \u2192 FE(\u03b2)\nf \u00b7\u226bX = X \u226b= (\u03bbx. \u03b7 (f x))\n\u226a\u00b7\u226b : FE(\u03b1 \u2192 \u03b2) \u2192 FE(\u03b1) \u2192 FE(\u03b2)\nF \u226a\u00b7\u226bX = F \u226b= (\u03bbf.X \u226b= (\u03bbx. \u03b7 (f x)))\nAll of these operators associate to the left, so f \u00b7\u226bX \u226a\u00b7\u226b Y should be read as (f \u00b7\u226bX)\u226a\u00b7\u226b Y .\nLet \u25e6 : o \u2192 o \u2192 o be a binary operator on propositions. We define the following syntax for the same operator lifted to computations of propositions.\n\u25e6 : FE(o) \u2192 FE(o) \u2192 FE(o)\nM \u25e6N = (\u03bbmn.m \u25e6 n) \u00b7\u226bM \u226a\u00b7\u226bN"}, {"heading": "3 Linguistic Phenomena as Effects", "text": ""}, {"heading": "3.1 Deixis", "text": "We will now try to use this calculus to do some semantics. Here is our tectogrammar in an abstract categorial grammar presentation [6].\nJohn,Mary,me : NP\nloves : NP \u2212\u25e6NP \u2212\u25e6 S\nAnd here is our semantics.\nJJohnK := \u03b7 j\nJMaryK := \u03b7m\nJmeK := speaker \u22c6 (\u03bbx. \u03b7 x)\nJlovesK := \u03bbOS. love \u00b7\u226b S \u226a\u00b7\u226b O\nIn the semantics for JmeK, we use the speaker operation to retrieve the current speaker and make it available as the value of the variable x. The star (\u22c6) passed to speaker is a dummy value of the unit type 1.\nThis, and all the semantics we will see in this paper, satisfies a homomorphism condition that whenever M : \u03c4 , then JMK : J\u03c4K. In our case, JNP K = FE(\u03b9) and JSK = FE(o), where \u03b9 and o are the types of individuals and propositions, respectively. Of E, we assume that speaker : 1  \u03b9 \u2208 E, since that is the type of speaker used in our semantics.7\nWith this fragment, we can give meanings to trivial sentences like:\n(1) John loves Mary.\n(2) Mary loves me.\nwhose meanings we can calculate as:\nJlovesMary JohnK \u0589 \u03b7 (love jm) (1)\nJlovesmeMaryK \u0589 speaker \u22c6 (\u03bbx. \u03b7 (lovem x)) (2)\nThe meaning of (1) is a proposition of type o wrapped in \u03b7, i.e. something that we can interpret in a model. As for the meaning of (2), the speaker operator has propagated from the me lexical entry up to the meaning of the whole sentence. We now have an algebraic expression having as operands the propositions lovemx for all possible x : \u03b9. In order to get a single proposition which is to be seen as the truth-conditional meaning of the sentence and which can be evaluated in a model, we will need to fix the speaker. We will do so by defining an interpreting handler.\nwithSpeaker : \u03b9 \u2192 F{speaker:1\u03b9}\u228eE(\u03b1) \u2192 FE(\u03b1)\nwithSpeaker = \u03bbsM. L speaker: (\u03bbxk. k s) MM\nNote that we omitted the \u03b7 clause in the banana brackets above. In such cases, we say there is a default clause \u03b7: (\u03bbx. \u03b7 x).\n7 1 is the unit type whose only element is written as \u22c6.\nwithSpeaker s JlovesmeMaryK \u0589 \u03b7 (lovem s)\nSo far, we could have done the same by introducing a constant named me to stand in for the speaker. However, since handlers are part of our object language, we can include them in lexical entries. With this, we can handle phenomena such as direct (quoted) speech, that rebinds the current speaker in a certain scope.\nsaidis : S \u2212\u25e6NP \u2212\u25e6 S\nsaidds : S \u2212\u25e6NP \u2212\u25e6 S\nThose are our new syntactic constructors: one for the indirect speech use of said and the other for the direct speech use (their surface realizations would differ typographically or phonologically). Let us give them some semantics.\nJsaidisK = \u03bbCS. say \u00b7\u226b S \u226a\u00b7\u226b C\n= \u03bbCS. S \u226b= (\u03bbs. say s \u00b7\u226b C)\nJsaiddsK = \u03bbCS. S \u226b= (\u03bbs. say s \u00b7\u226b (withSpeaker sC))\nHere we elaborated the entry for indirect speech so it is easier to compare with the one for direct speech, which just adds a use of the withSpeaker operator.\n(3) John said Mary loves me.\n(4) John said, \u201cMary loves me\u201d.\nJsaidis (lovesmeMary)JohnK \u0589 speaker \u22c6 (\u03bbx. \u03b7 (say j (lovem x))) (3)\nJsaidds (lovesmeMary)JohnK \u0589 \u03b7 (say j (lovemj)) (4)\nThe meaning of sentence (3) depends on the speaker (as testified by the use of the speaker operator) whereas in (4), this dependence has been eliminated due to the use of direct speech."}, {"heading": "3.2 Quantification", "text": "Now we turn our attention to quantificational noun phrases.\nevery,a : N \u2212\u25e6NP\nman,woman : N\nJeveryK := \u03bbN. scope (\u03bbc. \u2200 \u00b7\u226b (C (\u03bbx. (N \u226a\u00b7 x)\u2192 (c x)))) (\u03bbx. \u03b7 x)\nJaK := \u03bbN. scope (\u03bbc. \u2203 \u00b7\u226b (C (\u03bbx. (N \u226a\u00b7 x) \u2227 (c x)))) (\u03bbx. \u03b7 x)\nJmanK := \u03b7man\nJwomanK := \u03b7woman\nThe entries for every and a might seem intimidating. However, if we ignore the \u00b7\u226b, the C, the \u226a\u00b7 and the overline on the logical operator, we get the familiar\ngeneralized quantifiers. These decorations are the plumbing that takes care of the proper sequencing of effects.\nNote that we make use of the C operator here. In the denotation of JaK, the term (\u03bbx. (N \u226a\u00b7 x) \u2227 (c x)) describes the property to which we want to apply the quantifier \u2203. However, this term is of type \u03b9 \u2192 FE(o). In order to apply \u2203, we need something of type \u03b9 \u2192 o. Intuitively, the effects of E correspond to the process of interpretation, the process of arriving at some logical form of the sentence. They should thus be independent of the particular individual that we use as a witness for x when we try to model-check the resulting logical form. This independence allows us use the C operator without fear of getting stuck. Once we arrive at the type FE(\u03b9 \u2192 o), it is a simple case of using \u2203 \u00b7\u226b to apply the quantifier within the computation type.89\nWhile the terms that use the scope operator might be complex, the handler that interprets them is as simple as can be.\nSI = \u03bbM. L scope: (\u03bbck. c k) MM\nSame as with withSpeaker, SI will also be used in lexical items. By interpreting the scope operation in a particular place, we effectively determine the scope of the quantifier. Hence the name of SI, short for Scope Island. If we want to model clause boundaries as scope islands, we can do so by inserting SI in the lexical entries of clause constructors (in our case, the verbs).\nJlovesK := \u03bbOS. SI (JlovesKOS)\nJsaidisK := \u03bbCS. SI (JsaidisKC S)\nJsaiddsK := \u03bbCS. SI (JsaiddsKC S)\nWhenever we use the semantic brackets on the right-hand side of these revised definitions, they stand for the denotations we have assigned previously.\n(5) Every man loves a woman.\n(6) John said every woman loves me.\n(7) John said, \u201cEvery woman loves me\u201d.\nJloves (awoman) (everyman)K\n\u0589 \u03b7 (\u2200x.man x \u2192 (\u2203y.woman y \u2227 love x y)) (5)\nwithSpeaker s Jsaidis (lovesme (everywoman))JohnK\n\u0589 \u03b7 (say j (\u2200x.woman x \u2192 love x s)) (6)\nJsaidds (lovesme (everywoman))JohnK\n\u0589 \u03b7 (say j (\u2200x.woman x \u2192 love x j)) (7)\n8 Other solutions to this problem include separating the language of logical forms and the metalanguage used in the semantic lexical entries to manipulate logical forms as objects [13]. 9 Our C has been inspired by an operator of the same name proposed in [9]: de Groote introduces a structure that specializes applicative functors in a similar direction as monads by introducing the C operator and equipping it with certain laws; our C operator makes the FE type constructor an instance of this structure.\nThe calculus offers us flexibility when modelling the semantics. We might choose to relax the constraint that clauses are scope islands by keeping the old entries for verbs that do not use the SI handler. We might then want to add the SI handler to the lexical entry of saidds, next to the withSpeaker handler, so that quantifiers cannot escape quoted expressions. We might also allow for inverse scope readings by, e.g., providing entries for transitive verbs that evaluate their arguments right-to-left (though then we would have to watch out for crossover effects if we were to add anaphora)."}, {"heading": "3.3 Conventional Implicature", "text": "Our goal is to show the modularity of this approach and so we will continue and plug in one more phenomenon into our growing fragment: conventional implicatures, as analyzed by Potts [23]. Specifically, we will focus on nominal appositives.\nappos : NP \u2212\u25e6NP \u2212\u25e6NP\nbest-friend : NP \u2212\u25e6NP\nJapposK := \u03bbXY.X \u226b= (\u03bbx. SI (\u03b7 x= Y )\u226b= (\u03bbi. implicate i (\u03bbz. \u03b7 x)))\nJbest-friendK := \u03bbX.best-friend \u00b7\u226bX\nIn the denotation of the nominal appositive construction, appos, we first evaluate the head noun phrase X : JNP K to find its referent x : \u03b9. We then want to implicate that x is equal to the referent of Y . The term \u03b7 x = Y (note the line over =) is the term that computes that referent and gives us the proposition we want. We also want to state that no quantifier from within the appositive Y should escape into the matrix clause and so we wrap this computation in the SI handler to establish a scope island. Finally, we pass this proposition as an argument to implicate and we return x as the referent of the noun phrase.\nThe point of the implicate operation is to smuggle non-at-issue content outside the scope of logical operators. The contribution of an appositive should survive, e.g., logical negation.10 The place where we will accommodate the implicated truth-conditions will be determined by the use of the following handler:\naccommodate : F{implicate:o1}\u228eE(o) \u2192 FE(o)\naccommodate = \u03bbM. L implicate: (\u03bbik. \u03b7 i \u2227 k \u22c6) MM\nWe want conventional implicatures to project out of the common logical operators. However, when we consider direct quotes, we would not like to attribute the implicature made by the quotee to the quoter. We can implement this by inserting the accommodate handler into the lexical entry for direct speech.\nJsaiddsK := \u03bbCS. SI (S \u226b= (\u03bbs. say s \u00b7\u226b (withSpeaker s (accommodate C))))\nConsider the following three examples.\n10 In our limited fragment, we will only see it sneak out of a quantifier.\n(8) John, my best friend, loves every woman.\n(9) Mary, everyone\u2019s best friend, loves John.\n(10) A man said, \u201cMy best friend, Mary, loves me\u201d.\nIn (8), the conventional implicature that John is the speaker\u2019s best friend projects from the scope of the quantifier. On the other hand, in (10), the implicature does not project from the quoted clause and so it is not misattributed.\nwithSpeaker s (accommodate Jloves (everywoman) (appos John (best-friendme))K)\n\u0589 \u03b7 ((j = best-friend s) \u2227 (\u2200x.woman x \u2192 love jx)) (8)\naccommodate Jloves John (apposMary (best-friend everyone))K\n\u0589 \u03b7 ((\u2200x.m = best-friendx) \u2227 (lovemj)) (9)\nJsaidds (lovesme (appos (best-friendme)Mary)) (aman)K\n\u0589 \u03b7 (\u2203x.man x \u2227 sayx ((best-friendx = m) \u2227 (love (best-friendx)x))) (10)"}, {"heading": "3.4 Summary", "text": "Let us look back at the modularity of our approach and count how often during the incremental development of our fragment we either had to modify existing denotations or explicitly mention previous effects in new denotations.\nWhen adding quantification:\n\u2013 in the old denotations of verbs, we added the new SI handler so that clauses form scope islands\nWhen adding appositives and their conventional implicatures:\n\u2013 in the old denotations JsaiddsK, we added the new accommodate handler to state that conventional implicatures should not project out of quoted speech \u2013 in the new denotation JapposK, we used the old SI handler to state that appositives should form scope islands\nOtherwise, none of the denotations prescribed in our semantic lexicon had to be changed. We did not have to type-raise non-quantificational NP constructors like JJohnK, JmeK or Jbest-friendK. With the exception of direct speech, we did not have to modify any existing denotations to enable us to collect conventional implicatures from different subconstituents.\nFurthermore, all of the modifications we have performed to existing denotations are additions of handlers for new effects. This gives us a strong guarantee that all of the old results are conserved, since applying a handler to a computation which does not use the operations being handled changes nothing.\nThe goal of our calculus is to enable the creation of semantic lexicons with a high degree of separation of concerns. In this section, we have seen how it can be done for one particular fragment."}, {"heading": "4 Properties of the Calculus", "text": "The calculus defined in Sect. 2 and to which we will refer as L\u03bb M, has some satisfying properties.\nFirst of all, the reduction rules preserve types of terms (subject reduction). The reduction relation itself is confluent and, for well-typed terms, it is also terminating. This means that typed L\u03bb M is strongly normalizing.\nThe proof of subject reduction is a mechanical proof by induction. For confluence and termination, we employ very similar strategies: we make use of general results and show how they apply to our calculus. Due to space limitations, we will pursue in detail only the proof of confluence.\nOur reduction relation is given as a set of rules which map redexes matching some pattern into contracta built up out of the redexes\u2019 free variables. However, our language also features binding, and so some of the rules are conditioned on whether or not certain variables occur freely in parts of the redex. Fortunately, such rewriting systems have been thoroughly studied. Klop\u2019s Combinatory Reduction Systems (CRSs) [16] is one class of such rewriting systems.\nWe will make use of the result that orthogonal CRSs are confluent [16]. A CRS is orthogonal if it is left-linear and non-ambiguous. We will need to adapt our formulation of the reduction rules so that they form a CRS and we will need to check whether we satisfy left-linearity and non-ambiguity (we will see what these two properties mean when we get to them).\nWe refer the reader to [16] for the definition of CRSs. The key point is that in a CRS, the free variables which appear in the left-hand side of a rewrite rule, called metavariables, are explicitly annotated with the set of all free variables that are allowed to occur within a term which would instantiate them. This allows us to encode all of our x /\u2208 FV (M) constraints.\nOne detail which must be taken care of is the set notation (opi:Mi)i\u2208I and the indices I used in the L M rules. We do away with this notation by adding a separate rule for every possible instantiation of the schema. This means that for each sequence of distinct operation symbols op1,. . . ,opn, we end up with:\n\u2013 a special rewriting rule L op1:M1, . . . , opn:Mn, \u03b7:M\u03b7 M (\u03b7 N) \u2192 M\u03b7 N \u2013 for every 1 \u2264 i \u2264 n, a special rewriting rule L op1:M1, . . . , opn:Mn, \u03b7:M\u03b7 M (opiNp (\u03bbx.Nc(x))) \u2192 MiNp (\u03bbx. L op1:M1, . . . , opn:Mn, \u03b7:M\u03b7 MNc(x)) \u2013 for every op\u2032 \u2208 E \\ {opi|1 \u2264 i \u2264 n}, a special rewriting rule L op1:M1, . . . , opn:Mn, \u03b7:M\u03b7 M (op\n\u2032 Np (\u03bbx.Nc(x))) \u2192 op\u2032 Np (\u03bbx. L op1:M1, . . . , opn:Mn, \u03b7:M\u03b7 MNc(x))\nSo now we have a CRS which defines the same reduction relation as the rules we have shown in 2.3. Next, we verify the two conditions. Left-linearity states that no left-hand side of any rule contains multiple occurrences of the same metavariable. By examining our rules, we find that this is indeed the case.11\n11 Multiple occurrences of the same opi are alright, since those are not metavariables.\nNon-ambiguity demands that there is no non-trivial overlap between any of the left-hand sides.12 In our CRS, we have overlaps between the \u03b2 and the \u03b7 rules. We split our CRS into one with just the \u03b7 rule (\u2192\u03b7) and one with all the other rules (\u2192L\u03bb M). Now, there is no overlap in either of these CRSs, so they are both orthogonal and therefore confluent.\nWe then use the Lemma of Hindley-Rosen [17, p. 7] to show that the union of \u2192L\u03bb M and \u2192\u03b7 is confluent when \u2192L\u03bb M and \u2192\u03b7 are both confluent and commute together. For that, all that is left to prove is that \u2192L \u03bb M and \u2192\u03b7 commute. Thanks to another result due to Hindley [17, p. 8], it is enough to prove that for all a, b and c such that a \u2192L\u03bb M b and a \u2192\u03b7 c, we have a d such that b \u0589\u03b7 d and c \u2192=L\u03bb M d. The proof of this is a straightforward induction on the structure of a."}, {"heading": "5 Conclusion", "text": "In our contribution, we have introduced a new calculus motivated by modelling detailed semantics and inspired by current work in programming language theory. Our calculus is an extension of the simply-typed lambda calculus which is the de facto lingua franca of semanticists. Its purpose is to facilitate the communication of semantic ideas without depending on complex programming languages [19,15] and to do so with a well-defined formal semantics.\nWe have demonstrated the features of our calculus on several examples exhibiting phenomena such as deixis, quantification and conventional implicature. While our calculus still requires us to do some uninteresting plumbing to be able to correctly connect all the denotations together, we have seen that the resulting denotations are very generic. We were able to add new phenomena without having to change much of what we have done before and the changes we have made arguably corresponded to places where the different phenomena interact.\nFinally, we have also shown that the calculus shares some of the useful properties of the simply-typed lambda calculus, namely strong normalization.\nIn future work, it would be useful to automate some of the routine plumbing that we have to do in our terms. It will also be important to test the methodology on larger and more diverse fragments (besides this fragment, we have also created one combining anaphora, quantification and presupposition [19]). Last but not least, it would be interesting to delve deeper into the foundational differences between the approach used here, the monad transformers used by Charlow [4] and the applicative functors used by Kiselyov [13]."}], "references": [{"title": "Continuations and the nature of quantification", "author": ["C. Barker"], "venue": "Natural language semantics 10(3), 211\u2013242", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2002}, {"title": "Programming with algebraic effects and handlers", "author": ["A. Bauer", "M. Pretnar"], "venue": "arXiv preprint arXiv:1203.1539", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2012}, {"title": "Programming and reasoning with algebraic effects and dependent types", "author": ["E. Brady"], "venue": null, "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2013}, {"title": "On the semantics of exceptional scope", "author": ["S. Charlow"], "venue": "Ph.D. thesis, New York University", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2014}, {"title": "Towards abstract categorial grammars", "author": ["P. de Groote"], "venue": "Proceedings of the 39th Annual Meeting on Association for Computational Linguistics. pp. 252\u2013259. Association for Computational Linguistics", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2001}, {"title": "Towards a montagovian account of dynamics", "author": ["P. de Groote"], "venue": "Proceedings of SALT. vol. 16", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2006}, {"title": "Natural language semantics with enriched meanings", "author": ["G. Giorgolo", "A. Asudeh"], "venue": null, "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2015}, {"title": "On Logical Relations and Conservativity", "author": ["P. de Groote"], "venue": "NLCS\u201915. Third Workshop on Natural Language and Computer Science", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2015}, {"title": "Making computational sense of montague\u2019s intensional logic", "author": ["J. Hobbs", "S. Rosenschein"], "venue": "Artificial Intelligence 9(3), 287\u2013306", "citeRegEx": "10", "shortCiteRegEx": null, "year": 1977}, {"title": "Handlers in action", "author": ["O. Kammar", "S. Lindley", "N. Oury"], "venue": null, "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2013}, {"title": "From discourse to logic: Introduction to modeltheoretic semantics of natural language, formal logic and discourse representation theory", "author": ["H. Kamp", "U. Reyle"], "venue": "No. 42, Kluwer Academic Pub", "citeRegEx": "12", "shortCiteRegEx": null, "year": 1993}, {"title": "Applicative abstract categorial grammars", "author": ["O. Kiselyov"], "venue": "Proceedings of the Third Workshop on Natural Language and Computer Science", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2015}, {"title": "Extensible effects: an alternative to monad transformers", "author": ["O. Kiselyov", "A. Sabry", "C. Swords"], "venue": null, "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2013}, {"title": "C.c.: Lambda: the ultimate syntax-semantics interface", "author": ["O. Kiselyov", "Shan"], "venue": null, "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2010}, {"title": "Combinatory reduction systems: introduction and survey", "author": ["J.W. Klop", "V. Van Oostrom", "F. Van Raamsdonk"], "venue": null, "citeRegEx": "16", "shortCiteRegEx": "16", "year": 1993}, {"title": "Term rewriting systems", "author": ["Klop", "J.W"], "venue": "Handbook of logic in computer science 2, 1\u2013116", "citeRegEx": "17", "shortCiteRegEx": null, "year": 1992}, {"title": "Expression de la dynamique du discours \u00e0 l\u2019aide de continuations", "author": ["E. Lebedeva"], "venue": "Ph.D. thesis, Universit\u00e9 de Lorraine", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2012}, {"title": "Algebraic Effects and Handlers in Natural Language Interpretation", "author": ["J. Mar\u0161\u0301\u0131k", "M. Amblard"], "venue": "Natural Language and Computer Science", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2014}, {"title": "Functional programming with bananas, lenses, envelopes and barbed wire", "author": ["E. Meijer", "M. Fokkinga", "R. Paterson"], "venue": null, "citeRegEx": "20", "shortCiteRegEx": "20", "year": 1991}, {"title": "Notions of computation and monads", "author": ["E. Moggi"], "venue": "Information and computation 93(1), 55\u201392", "citeRegEx": "21", "shortCiteRegEx": null, "year": 1991}, {"title": "Handlers of algebraic effects", "author": ["G. Plotkin", "M. Pretnar"], "venue": "Programming Languages and Systems, pp. 80\u201394. Springer", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2009}, {"title": "The logic of conventional implicatures", "author": ["C. Potts"], "venue": "Oxford University Press", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2005}, {"title": "Logic and handling of algebraic effects", "author": ["M. Pretnar"], "venue": null, "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2010}, {"title": "Event in compositional dynamic semantics", "author": ["S. Qian", "M. Amblard"], "venue": "Logical Aspects of Computational Linguistics", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2011}, {"title": "Monads for natural language semantics", "author": ["C. Shan"], "venue": "arXiv cs/0205026", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2002}, {"title": "Linguistic side effects", "author": ["Shan", "C.c."], "venue": "Ph.D. thesis, Harvard University Cambridge, Massachusetts", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2005}, {"title": "Computational semantics with functional programming", "author": ["J. Van Eijck", "C. Unger"], "venue": "Cambridge University Press", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2010}, {"title": "The essence of functional programming", "author": ["P. Wadler"], "venue": "Proceedings of the 19th ACM SIGPLAN-SIGACT symposium on Principles of programming languages. pp. 1\u201314. ACM", "citeRegEx": "29", "shortCiteRegEx": null, "year": 1992}], "referenceMentions": [{"referenceID": 24, "context": "It was previously observed [26] that the lambda terms and/or the denotations studied tend to follow the same pattern: they are instances of a monad.", "startOffset": 27, "endOffset": 31}, {"referenceID": 20, "context": "In this paper, we present an extension of the simplytyped lambda calculus that exploits this uniformity using the recently discovered technique of effect handlers [22].", "startOffset": 163, "endOffset": 167}, {"referenceID": 10, "context": "\u2013 the incremental algorithm used to build discourse representation structures in DRT, as presented in [12] \u2013 the \u03bb\u03bc calculus, used in [5] to analyze quantification, since, due to the lack of confluence, function terms do not denote functions over simple denotations \u2013 the use of exceptions and exception handlers in [18] to model presuppositions in an otherwise compositional framework \u2013 the parsetree interpretation step in the logic of conventional implicatures of [23] that builds the denotation of a sentence by extracting implicatures from the denotations of its subparts (including the non-immediate ones)", "startOffset": 102, "endOffset": 106}, {"referenceID": 16, "context": "\u2013 the incremental algorithm used to build discourse representation structures in DRT, as presented in [12] \u2013 the \u03bb\u03bc calculus, used in [5] to analyze quantification, since, due to the lack of confluence, function terms do not denote functions over simple denotations \u2013 the use of exceptions and exception handlers in [18] to model presuppositions in an otherwise compositional framework \u2013 the parsetree interpretation step in the logic of conventional implicatures of [23] that builds the denotation of a sentence by extracting implicatures from the denotations of its subparts (including the non-immediate ones)", "startOffset": 316, "endOffset": 320}, {"referenceID": 21, "context": "\u2013 the incremental algorithm used to build discourse representation structures in DRT, as presented in [12] \u2013 the \u03bb\u03bc calculus, used in [5] to analyze quantification, since, due to the lack of confluence, function terms do not denote functions over simple denotations \u2013 the use of exceptions and exception handlers in [18] to model presuppositions in an otherwise compositional framework \u2013 the parsetree interpretation step in the logic of conventional implicatures of [23] that builds the denotation of a sentence by extracting implicatures from the denotations of its subparts (including the non-immediate ones)", "startOffset": 467, "endOffset": 471}, {"referenceID": 0, "context": "the speaker and addressee for deixis, the current world for modality), since they amount to saying that a phrase denotes an indexed set of simpler meanings \u2013 the continuized semantics for quantification [1] in which denotations are functions of their own continuations \u2022 and more generally, any semantics using type raising or generalized quantifiers for noun phrase denotations \u2013 the dynamic denotations of [7] that are functions of the common ground and their continuation \u2013 compositional event semantics, such as the one in [25], that shift the denotations of sentences from truth-values to predicates on events", "startOffset": 203, "endOffset": 206}, {"referenceID": 5, "context": "the speaker and addressee for deixis, the current world for modality), since they amount to saying that a phrase denotes an indexed set of simpler meanings \u2013 the continuized semantics for quantification [1] in which denotations are functions of their own continuations \u2022 and more generally, any semantics using type raising or generalized quantifiers for noun phrase denotations \u2013 the dynamic denotations of [7] that are functions of the common ground and their continuation \u2013 compositional event semantics, such as the one in [25], that shift the denotations of sentences from truth-values to predicates on events", "startOffset": 408, "endOffset": 411}, {"referenceID": 23, "context": "the speaker and addressee for deixis, the current world for modality), since they amount to saying that a phrase denotes an indexed set of simpler meanings \u2013 the continuized semantics for quantification [1] in which denotations are functions of their own continuations \u2022 and more generally, any semantics using type raising or generalized quantifiers for noun phrase denotations \u2013 the dynamic denotations of [7] that are functions of the common ground and their continuation \u2013 compositional event semantics, such as the one in [25], that shift the denotations of sentences from truth-values to predicates on events", "startOffset": 527, "endOffset": 531}, {"referenceID": 19, "context": "\u2013 in denotational semantics to give the domain of interpretation for programming languages that involve side effects [21].", "startOffset": 117, "endOffset": 121}, {"referenceID": 27, "context": "\u2013 in functional programming to emulate programming with side effects via term-level encodings of effectful programs [29].", "startOffset": 116, "endOffset": 120}, {"referenceID": 25, "context": "The relationship between side effects in functional programming and computational semantics has been developed in several works [27,28], stretching as far back as 1977 [10].", "startOffset": 128, "endOffset": 135}, {"referenceID": 26, "context": "The relationship between side effects in functional programming and computational semantics has been developed in several works [27,28], stretching as far back as 1977 [10].", "startOffset": 128, "endOffset": 135}, {"referenceID": 8, "context": "The relationship between side effects in functional programming and computational semantics has been developed in several works [27,28], stretching as far back as 1977 [10].", "startOffset": 168, "endOffset": 172}, {"referenceID": 24, "context": "The usefulness of monads in particular has been discovered by Shan in 2002 [26].", "startOffset": 75, "endOffset": 79}, {"referenceID": 3, "context": "Charlow used the popular method of monad morphisms to combine several monads in his dissertation [4].", "startOffset": 97, "endOffset": 100}, {"referenceID": 6, "context": "Giorgolo and Asudeh have used distributive laws to combine monads [8], while Kiselyov has eschewed monads altogether in favor of applicative functors which enjoy easy composability [13].", "startOffset": 66, "endOffset": 69}, {"referenceID": 11, "context": "Giorgolo and Asudeh have used distributive laws to combine monads [8], while Kiselyov has eschewed monads altogether in favor of applicative functors which enjoy easy composability [13].", "startOffset": 181, "endOffset": 185}, {"referenceID": 1, "context": "Our approach follows the recent trend in adopting effects and handlers to combine side effects [2,11] and to encode effectful programs in pure functional programming languages [14,3].", "startOffset": 95, "endOffset": 101}, {"referenceID": 9, "context": "Our approach follows the recent trend in adopting effects and handlers to combine side effects [2,11] and to encode effectful programs in pure functional programming languages [14,3].", "startOffset": 95, "endOffset": 101}, {"referenceID": 12, "context": "Our approach follows the recent trend in adopting effects and handlers to combine side effects [2,11] and to encode effectful programs in pure functional programming languages [14,3].", "startOffset": 176, "endOffset": 182}, {"referenceID": 2, "context": "Our approach follows the recent trend in adopting effects and handlers to combine side effects [2,11] and to encode effectful programs in pure functional programming languages [14,3].", "startOffset": 176, "endOffset": 182}, {"referenceID": 18, "context": "See [20] for the introduction of banana brackets.", "startOffset": 4, "endOffset": 8}, {"referenceID": 22, "context": "When we say that an operator has arity \u03b2, where \u03b2 is a type, we mean that it takes one operand for every value of \u03b2 [24].", "startOffset": 116, "endOffset": 120}, {"referenceID": 18, "context": "See [20] for the difference.", "startOffset": 4, "endOffset": 8}, {"referenceID": 4, "context": "Here is our tectogrammar in an abstract categorial grammar presentation [6].", "startOffset": 72, "endOffset": 75}, {"referenceID": 11, "context": "8 Other solutions to this problem include separating the language of logical forms and the metalanguage used in the semantic lexical entries to manipulate logical forms as objects [13].", "startOffset": 180, "endOffset": 184}, {"referenceID": 7, "context": "9 Our C has been inspired by an operator of the same name proposed in [9]: de Groote introduces a structure that specializes applicative functors in a similar direction as monads by introducing the C operator and equipping it with certain laws; our C operator makes the FE type constructor an instance of this structure.", "startOffset": 70, "endOffset": 73}, {"referenceID": 21, "context": "Our goal is to show the modularity of this approach and so we will continue and plug in one more phenomenon into our growing fragment: conventional implicatures, as analyzed by Potts [23].", "startOffset": 183, "endOffset": 187}, {"referenceID": 14, "context": "Klop\u2019s Combinatory Reduction Systems (CRSs) [16] is one class of such rewriting systems.", "startOffset": 44, "endOffset": 48}, {"referenceID": 14, "context": "We will make use of the result that orthogonal CRSs are confluent [16].", "startOffset": 66, "endOffset": 70}, {"referenceID": 14, "context": "We refer the reader to [16] for the definition of CRSs.", "startOffset": 23, "endOffset": 27}, {"referenceID": 17, "context": "Its purpose is to facilitate the communication of semantic ideas without depending on complex programming languages [19,15] and to do so with a well-defined formal semantics.", "startOffset": 116, "endOffset": 123}, {"referenceID": 13, "context": "Its purpose is to facilitate the communication of semantic ideas without depending on complex programming languages [19,15] and to do so with a well-defined formal semantics.", "startOffset": 116, "endOffset": 123}, {"referenceID": 17, "context": "It will also be important to test the methodology on larger and more diverse fragments (besides this fragment, we have also created one combining anaphora, quantification and presupposition [19]).", "startOffset": 190, "endOffset": 194}, {"referenceID": 3, "context": "Last but not least, it would be interesting to delve deeper into the foundational differences between the approach used here, the monad transformers used by Charlow [4] and the applicative functors used by Kiselyov [13].", "startOffset": 165, "endOffset": 168}, {"referenceID": 11, "context": "Last but not least, it would be interesting to delve deeper into the foundational differences between the approach used here, the monad transformers used by Charlow [4] and the applicative functors used by Kiselyov [13].", "startOffset": 215, "endOffset": 219}], "year": 2017, "abstractText": "In compositional model-theoretic semantics, researchers assemble truth-conditions or other kinds of denotations using the lambda calculus. It was previously observed [26] that the lambda terms and/or the denotations studied tend to follow the same pattern: they are instances of a monad. In this paper, we present an extension of the simplytyped lambda calculus that exploits this uniformity using the recently discovered technique of effect handlers [22]. We prove that our calculus exhibits some of the key formal properties of the lambda calculus and we use it to construct a modular semantics for a small fragment that involves multiple distinct semantic phenomena.", "creator": "LaTeX with hyperref package"}}}