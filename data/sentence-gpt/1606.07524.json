{"id": "1606.07524", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "24-Jun-2016", "title": "Preference at First Sight", "abstract": "We consider decision-making and game scenarios in which an agent is limited by his/her computational ability to foresee all the available moves towards the future - that is, we study scenarios with short sight. We focus on how short sight affects the logical properties of decision making in multi-agent settings. We start with single-agent sequential decision making (SSDM) processes, modeling them by a new structure of \"preference-sight trees\" in which two individuals are presented with a list of \"priority choices\". We end by creating the \"preference-sight trees\" (i.e. the selected items in the list, and the items in the list), and then looking at other potential options in each of the group.\n\n\n\nWe analyze the selection of available preferences based on the ability of the selected items to predict their desired behaviors over time and use them to estimate their desired behaviors. We use these \"preference-sight trees\" to identify potential behavioral features, and we analyze the behavioral preferences of each individual. The selection tree we analyze is an image-driven image-driven image-driven image-driven image-driven image-driven image-driven image-driven image-driven image-driven model (FEM).\nThe FEM is a visualizing representation of a situation in which two individuals are presented with a list of items that they do not know, and then view a picture of their selected items. The FEM is a visualizing representation of a situation in which two individuals are presented with a list of items that they do not know. The FEM is a visualizing representation of a situation in which two individuals are presented with a list of items that they do not know, and then view a picture of their selected items. The FEM is a visualizing representation of a situation in which two individuals are presented with a list of items that they do not know. The FEM is a visualizing representation of a situation in which two individuals are presented with a list of items that they do not know, and then view a picture of their selected items. The FEM is a visualizing representation of a situation in which two individuals are presented with a list of items that they do not know, and then view a picture of their selected items. The FEM is a visualizing representation of a situation in which two individuals are presented with a list of items that they do not know, and then view a picture of their selected items.\nThe FEM is a visualizing representation of a situation in which two individuals", "histories": [["v1", "Fri, 24 Jun 2016 00:32:31 GMT  (49kb,D)", "http://arxiv.org/abs/1606.07524v1", "In Proceedings TARK 2015,arXiv:1606.07295"]], "COMMENTS": "In Proceedings TARK 2015,arXiv:1606.07295", "reviews": [], "SUBJECTS": "cs.LO cs.AI", "authors": ["chanjuan liu"], "accepted": false, "id": "1606.07524"}, "pdf": {"name": "1606.07524.pdf", "metadata": {"source": "CRF", "title": "Preference at First Sight", "authors": ["Chanjuan Liu"], "emails": ["chanjuan.pkucs@gmail.com"], "sections": [{"heading": null, "text": "R. Ramanujam (Ed.): TARK 2015 EPTCS 215, 2016, pp. 207\u2013226, doi:10.4204/EPTCS.215.15\nc\u00a9 C. Liu This work is licensed under the Creative Commons Attribution License.\nPreference at First Sight\nChanjuan Liu School of Computer Science and Technology, Dalian University of Technology\nInstitute for Logic, Language and Computation, University of Amsterdam\nchanjuan.pkucs@gmail.com\nWe consider decision-making and game scenarios in which an agent is limited by his/her computational ability to foresee all the available moves towards the future \u2013 that is, we study scenarios with short sight. We focus on how short sight affects the logical properties of decision making in multi-agent settings. We start with single-agent sequential decision making (SSDM) processes, modeling them by a new structure of \u2018preference-sight trees\u2019. Using this model, we first explore the relation between a new natural solution concept of Sight-Compatible Backward Induction (SCBI) and the histories produced by classical Backward Induction (BI). In particular, we find necessary and sufficient conditions for the two analyses to be equivalent. Next, we study whether larger sight always contributes to better outcomes. Then we develop a simple logical special-purpose language to formally express some key properties of our preference-sight models. Lastly, we show how shortsight SSDM scenarios call for substantial enrichments of existing fixed-point logics that have been developed for the classical BI solution concept. We also discuss changes in earlier modal logics expressing \u2018surface reasoning\u2019 about best actions in the presence of short sight. Our analysis may point the way to logical and computational analysis of more realistic game models."}, {"heading": "1 Introduction", "text": "There is a growing interest in the logical foundations, computational implementations, and practical applications of single-agent sequential decision-making (SSDM) problems [32, 23, 28, 18, 9, 26, 24] in such diverse areas as Artificial Intelligence, Control, Logic, Economics, Mathematics, Politics, Psychology, Philosophy, and Medicine. Making decisions is central to agents\u2019 routine and usually, they need to make multiple decisions over time. Indeed, a current situation is a result of past sequentially linked decisions, each impacted by the preceding choices.\nIt is quite natural in sequential decision-making scenarios, particularly, in large systems, that agents may have some uncertainties and limitations on their precise view of the environment. The current literature [9, 28] has studied uncertainty which an agent faces in recognizing possible outcomes after taking an action and the probabilities associated with these outcomes, as well as the partial observability of what the actual state is like. In addition to these, a realistic aspect that affects a SSDM process is the short-sightedness of the agent, which blocks a full view of all the available actions. Short sight plays a critical role in such a situation, since, while making a choice, the ability to foresee a variety of alternatives and predict future decision sequences for each of them, may make a significant difference. Nonetheless, such restrictions have not been discussed systematically yet in decision theory or game theory.\nIn [14], a game-theoretic framework called games with short sight was proposed. This framework explicitly models players\u2019s limited foresight in extensive games and calls for a new solution termed as Sight-Compatible Backward Induction (SCBI). However, many essential issues related to sight remain unclear, such as: What is the exact role of sight? Will the outcome be better when sight is larger? What is the relation between SCBI and classical backward induction(BI)? There are also unexplored issues\npertaining to logical aspects. Which minimal logic is needed for formally characterizing a short-sight framework? Are existing logics for BI still applicable, or can they be extended to fit short-sight scenarios? How different are the logical properties of the game frames for SCBI and for BI? Without such a logical analysis, the framework of [14] does not suffice for disclosing the general features of short sight and the changes it brings about in thinking about decisions and games. Additionally, in multi-player games, short sight has to interact with many other factors, such as agents\u2019 mutual knowledge and interactive decisions and moves.\nHaving said this, we still start by focusing on short sight in single-agent sequential decision-making process. For this, we propose a model of \u2018preference-sight trees\u2019 (P-S trees). As the term says, a P-S tree combines the agent\u2019s preference and its sight, as both are essential to decision problems [33]. We will study how the two are correlated, and cooperate to act on decision-making processes and their final outcomes.\nAs a preliminary illustration, consider the connection between larger sight and better outcome. A first impression might be that an agent will always perform better with larger sight. Surprisingly, this is not always true. Sometimes, one can see much further into the future but receive a small payoff, while having one\u2019s vision restricted to a limited set of future alternatives yields a better payoff. Example 1.1 Alice has to make sequential decisions at two stages (shown in Figure 1). For each stage, she can choose either L or R. Assume that the preference order (from most preferable to least preferable) among the four outcomes is RR,LL,RL,LR. Now consider two cases:\nCase 1. At the start, Alice sees two paths, LR and RL. She chooses R since it initiates RL which is preferable to LR. At the second-stage, Alice then foresees RR and RL. She happily makes the best decision RR.\nCase 2. Alice sees more, e.g., LL, LR, and RL, immediately at the first stage. Therefore she thinks that L is a better initial choice than R. Consequently, at the second-stage, she can only choose from LL and LR.\nConclusion: Even though Alice could see more in Case 2, she ultimately obtains a less preferable outcome.\nThis example demonstrates some of the crucial features that govern SSDM situations: 1) What an agent can foresee plays a crucial role in the decision-making process, since her sight determines the set of available choices. 2) Sight also updates her preferences over the options, and thereby the outcomes obtained in rational play. 3) Although in Case 2, Alice does not get the best result, we can say that, given her sight, she plays optimally in a local sense. In other words, this is a rational plan for her, even though it is not equivalent to the rational outcome of classical decision theory or game theory [29].\nIn this paper, we address all three challenges, but first we clarify our approach. To focus on sight, we ignore other factors such as the probability of moves by Nature. Also, we model the outcome of a decision as completely determined, or in other words, possible outcomes for each alternative and the probability corresponding to each outcome are encapsulated as a black box."}, {"heading": "2 Modeling Single-agent sequential decision-making", "text": "We begin by defining a structure called preference-sight tree for modelling single-agent sequential decision-making (SSDM) processes. Using this model, we then clarify the role that sight plays by discussing a series of changes it produces in agent\u2019s preferences, decision-making procedures and their outcomes."}, {"heading": "2.1 Models", "text": "There are two kinds of models for decision-making scenarios corresponding to two perspectives. One is an explicit model from the perspective of Nature, or an outsider/designer; the other is the implicit model from the perspective of the agent involved, or an insider/decider. The former is complete and perfect in the sense that the outsider holds a full view of all the options together with the objective quality of these options, and thus can explicitly specify the reward of each situation for the decision-maker. In contrast with this, the latter\u2019s views are possibly limited to a near future, especially in large-scale surroundings. Moreover, owing to limited foresight, the agent may also reason mistakenly about the quality of different choices, leading to what we call subjective preference.\nBoth the above perspectives are essential: the former offers a whole picture of the environment, the latter shows the actual play of the decider. In this section, we first introduce an explicit model of preference trees. After this, by endowing such trees with the agent\u2019s view of the process and his/her subjective preference in this view, we formulate an integrated model of preference-sight trees which allows us to model both perspectives together."}, {"heading": "2.1.1 Preference trees (P trees)", "text": "A preference tree is a decision tree with only two elements: histories and preferences. Each history corresponds to a situation resulting from previous decision actions, and a preference represents the objective quality of each of these situations. To ensure the existence of backward induction solutions, we confine ourselves to finite histories.\nDefinition 2.1 (Preference tree) A preference tree is a tuple T = (H, ) where\n\u2022 H is a non-empty set of finite sequences of actions, called histories. \u25e6 The empty sequence \u03b5 is a member of H; \u25e6 If (ak)k=1,...,K \u2208 H and L < K then (ak)k=1,...,L \u2208 H; \u2022 is a total order over H. Let A denote the set of all actions. Any history h can be written as a sequence of actions: (ak)k=1,...,n, where each ak \u2208 A. If there is no an+1 s.t. (ak)k=1,...,n+1 \u2208 H, then history (ak)k=1,...,n is a terminal one. The set of terminal histories is denoted Z. The set of actions that are available at h is denoted A(h)\u2286 A. For any histories h,h\u2032, if h is a prefix of h\u2032 we write h h\u2032. The strict part of is , with h1 h2 if h1 h2 and not h2 h1 for any two histories h1 and h2. Accordingly, h1 \u223c h2 iff h1 h2 and h2 h1.\nSeveral remarks need to be made on the role of preference relations in the above definition: (1) Instead of defining preference merely over terminal histories, we have defined it over all histories, an idea going back to [19]. Here preference over intermediate histories is necessary for our aim of modelling an agent\u2019s decision-making under limited foresight, which usually consists of intermediate histories.\n(3) For convenience, we do not strictly differentiate the two main views of preference: qualitative and quantitative. Although we use qualitative order generally, we sometimes switch to numerical payoff when it is advantageous.1"}, {"heading": "2.1.2 Preference-sight Trees (P-S trees)", "text": "P tree is an explicit model for decision-making scenarios which is independent of an agent. However, for an agent, the tree may appear differently in his/her limited view. [14] proposes the idea of short sight, where the authors use a sight function to denote the set of states that players can actually see at every position in an extensive game. Let us start by adapting their technique to preference trees.\nDefinition 2.2 Let T = (H, ) be a preference tree. A sight function for T is a function s : H\u2192 2H\\{ /0} satisfying s(h)\u2286 H|h and |s(h)|< \u03c9 , where H|h represents the set of histories extending h. As a special case, h \u2208 H|h.\nIn words, the function s assigns to each history h a finite subset of all available histories extending h.\nThe first effect that sight produces is as follows: Given a P tree, for any history h, a sight function always gives us a restricted tree.\nDefinition 2.3 Let T = (H, ) be a preference tree. Given any history h of T , a visible tree Th of T at h is a tuple (Hh, h), where Hh = s(h), i.e., Hh captures the decider\u2019s view of the decision tree; h represents the subjective preference over Hh.\nA visible tree is actually an implicit model in our earlier terms. Hh also contains a set of terminal histories Zh, which are those without successors in s(h). Note that typically, the Zh are non-terminal for T .\nFurther, the preference order h is different from the objective preference . In fact, the formation of h is an update via a bottom-to-top process in terms of an agent\u2019s sight. This updating process involves leaving the payoffs of Zh as the same as their objective payoffs, then updating the payoffs of other histories in Hh backwards, starting from the leaf nodes and proceeding towards the root of the tree.\nThe reason why we employ such an updating process is that, while the objective payoffs reflect the goodness of these situations, they are not the actual reward that an agent can get if he/she chooses this option. At each decision point, the subjective payoff of one available option is inherited from the best reachable terminal histories of the current visible tree. Therefore, the preference relation h in Th is not always consistent with the preference relation in T .\nThis updating process is described by Algorithm 1:\n*For convenience, here we use payoffs P to represent rewards.\nFact 2.1 Let T = (H, ) be a P tree. Each visible tree Th = (Hh, h) is a P tree.\nCorrespondingly, we denote the prefix relation in Th by h, and the actions that are available at h by Ah(h).\nFinally we proceed to define our model of preference-sight trees. A preference-sight tree allows us not only to represent the outsider\u2019s view, i.e., (H, ), but also to derive a series of implicit models, i.e., (Hh, h), one for each h.\n1There is a debate on whether preference and utilities are the same [18, 7]. Here we adopt the operational understanding of utility and do not distinguish it from preference.\nAlgorithm 1: Preference updating in visible trees 1 PU(T,h,s)\nInput: A P tree T = (H, ) (or T = (H,P)), current history h, and a sight function s Output: A visible tree Th = (Hh, h) or (Th = (Hh,Ph))\n2 begin 3 H \u2229 s(h)\u2192 Hh; 4 for any z \u2208 Zh /* Keep the payoffs of terminal histories unchanged */ do 5 P(z)\u2192 Ph(z); 1\u2192 flag[z]; 6 while flag[h] == 0 do 7 for any h\u2032 \u2208 Hh do 8 if (for all (h\u2032a) \u2208 Hh, flag[(h\u2032a)] == 1) /* If all of its children have been visited, reset its payoff as the highest one among them */ 9 then\n10 max{Ph(h\u2032a)}\u2192 Ph(h\u2032); 1\u2192 flag[h\u2032];\n11 Return Th;\nDefinition 2.4 (Preference-sight tree) A preference-sight tree (P-S tree) is a tuple (T,s), where T = (H, ) is a preference tree and s a sight function for T .\nIn P-S trees, an agent\u2019s sight should satisfy the following properties: First, if an agent can see a given future history, then he/she can also see any intermediate history up to that point. Second, if the agent can see a history two steps forward, then after moving one step ahead, he/she can still see it. These features are formally stated as follows.\nFact 2.2 (Properties of sight function) Let (T,s) be a P-S tree. For all h,h\u2032,h\u2032\u2032 \u2208 H, with h h\u2032 h\u2032\u2032, s satisfies :\nDC (Downward-Closed): if h\u2032\u2032 \u2208 s(h), then h\u2032 \u2208 s(h).\nNF (Non-Forgetting): if h\u2032\u2032 \u2208 s(h), then h\u2032\u2032 \u2208 s(h\u2032)."}, {"heading": "2.2 Solution concepts", "text": "Solution concepts are at the center of all choice problems. In what follows, we define two solution concepts for P-S trees, adapted from [30, 14]. After this, we investigate the conditions for their equivalence."}, {"heading": "2.2.1 BI history and SCBI history", "text": "Backward Induction (BI) is well-known in game theory [30]. The process runs like this. First, one determines the optimal strategy of the player who makes the last move of the game. Using this information, one can then determine the optimal action of the next-to-last moving player. The process continues backwards in this way until all players\u2019 actions have been determined in the whole game. Its adaptation to single-agent decision-making process becomes a maximality problem for the agent involved.\nIn a P-S tree, we say that one history h is max in a set of histories \u0393\u2286H, if h \u2208 \u0393 and for any other history h\u2032 in \u0393, it holds that h h\u2032, and we write this as h \u2208 max \u0393. The strict part for max is max .\nDefinition 2.5 (BI history) Let (T,s) be a P-S tree. A history h\u2217 \u2208 Z is a BI history of T , iff h\u2217 \u2208max Z. Also, we use BI to denote the set of BI histories in T .\nA BI history of a P-S tree is a terminal history that is most preferable or equivalently, that has a maximal payoff.\nBackward induction precludes short-sight, while in practice it is impossible for an agent to foresee all final outcomes all the time. In [14], a new solution concept was proposed to capture optimal play of short-sighted players: sight-compatible subgame perfect equilibrium. The main idea is that at each decision point, the current player chooses a locally optimal move by a local BI analysis within the visible part. Here, we adapt this notion to P-S trees, yielding the sight-compatible backward induction history.\nDefinition 2.6 (SCBI history) Let (T,s) be a P-S tree. A history h\u2217 \u2208 Z is a Sight-Compatible Backward Induction history (SCBI history) of T , iff for each history h with h h\u2217, and the action a following h, i.e., (ha) h\u2217, we have that \u2203z \u2208max Zh such that (ha) z. Also, we use SCBI to denote the set of SCBI histories in T .\nThe difference between SCBI and BI histories is obvious. A BI history is one with highest payoff among the set of terminal histories in the P-S tree, while for a SCBI history every restriction of it should be a local BI history for the visible tree. Thus, BI histories are the BI outcomes for the objective model (H, ), while SCBI histories are a combination of best responses to all subjective models (Hh, h). Typically it is the case that SCBI 6= BI.\nExample 2.1 Consider the P-S tree (T,s) in Figure 2, where s(\u03b5) = {L}, and s(L) = {LR}. It is easy to check that BI 6= SCBI, since BI = {LL}, while SCBI = {LR}.\nHowever, sometimes the two notions can be equivalent.\nExample 2.2 Consider a P-S tree, with T and s shown by Figure 3 (a), and Figure 3 (b) respectively. In (b) the three dotted circles represent s(\u03b5), s(L) and s(R). For histories L and R, their objective payoffs in (a) are 1 and 2, respectively. However, in T\u03b5 , the subjective payoff of L is updated to 3 and R to 2. Obviously, BI = SCBI = {LL}."}, {"heading": "2.2.2 Equivalence condition", "text": "Then an interesting question on BI and SCBI histories arises: are there conditions under which the two will be equivalent? To get a feeling for this, a first attempt at an answer looks for a condition related to consistency between subjective and objective preferences.\nTwo histories are said to be \u2018preference-sight consistent\u2019 if the subjective preference in each sightrestricted tree is consistent with the objective preference over them: Definition 2.7 (Preference-sight consistency) Let (T,s) be a P-S tree, and Th be the visible tree at an arbitrary history h. Then for any two histories h1, h2 of Th, we say (h1,h2) satisfies preference-sight consistency at h iff\nh1 h2 iff h1 h h2 If for any history h \u2208 T , the pair of arbitrary two histories (h1,h2) in Th is preference-sight consistent\n(at h), then we say (T,s) is preference-sight consistent.\nIs preference-sight consistency an appropriate condition for BI = SCBI? We have the following observation:\nFact 2.3 Preference-sight consistency does not guarantee that BI = SCBI.\nProof 2.4 Consider Figure 2. Suppose that s(R) contains only one successor. Then it is easy to see that (T,s) is preference-sight consistent. However, BI 6= SCBI.\nNext, does the other direction hold? Fact 2.5 Preference-sight consistency does not follow from BI = SCBI.\nProof 2.6 The situation in Figure 3 is a counterexample, in which BI = SCBI = {LL}, but (T,s) is not preference-sight consistent, since R L and L \u03b5 R.\nWhat is the exact condition for BI = SCBI? From the failure of preference-sight consistency, we can draw a lesson. In Figure 2, the main reason for (T,s) being inconsistent is that at history L, the branch LL, which in fact forms a BI history, is non-observable to the agent. This tells us that the one with maximal payoff should always be visible. Consider then the example in Figure 3. Here all the options are within agent\u2019s sight, but we notice that although the path LL following L finally turns out to be better than that following R, which makes subjectively L \u03b5 R, the objective payoff of L itself is lower than R. Thus, it fails to imply the consistency between preference and sight.\nBased on the above analysis, we now isolate necessary and sufficient conditions for BI = SCBI. First, we define an auxiliary property of sight-reachability, which intuitively reflects whether each restriction of a history is visible. Definition 2.8 (Sight-reachability) A BI history h\u2217 is sight-reachable if, for all (ha) h\u2217, we have (ha) \u2208 Hh, where h,h\u2032 are histories, and a is an action following h. Theorem 2.7 (Equivalence Theorem) For any P-S tree (T,s), SCBI= BI iff the following conditions are satisfied:\nI). Any history h\u2217 \u2208 BI is sight-reachable. II). Any history h\u2217 \u2208 BI is locally optimal: For any history (hh\u2032) h\u2217, if (hh\u2032) \u2208 Zh, then (hh\u2032) \u2208\nmax Zh and for any other (hh\u2032\u2032) \u2208 Zh, (hh\u2032)\u223c (hh\u2032\u2032) iff \u2203z \u2208 BI such that (hh\u2032\u2032) z.\nProof 2.8 (\u21d2) I). We show that every h\u2217 \u2208 BI is sight reachable. That is, for all (hh\u2032) h\u2217, it holds that (ha) \u2208 Hh. By SCBI= BI, we know that any history h\u2217 in BI, is also in SCBI. By Definition 2.6, for each of its prefix h, h\u2217h is max in Zh. So h \u2217 h is in Zh. In addition, by non-emptiness of\nZh, h\u2217h is not an empty sequence. Thus, for all (ha) h \u2217, it holds that (ha) \u2208 Hh. So h\u2217 \u2208 BI is sight-reachable.\nTo show condition II), take any h\u2217 in BI, we have that it is in SCBI. Thus, for all (hh\u2032) h\u2217, if (hh\u2032) \u2208 Zh, then (hh\u2032) is max in Zh. Moreover, for any (hu) \u2208 Zh such that (hh\u2032)\u223c (hu), we have (hu) is a prefix of a BI history, i.e., (hu) \u2208 BIh. For suppose not, then (hu) is not a prefix of SCBI history. Then it must be (hh\u2032) (hu). Contradict.\n(\u21d0) Suppose conditions I) and II) are satisfied. It suffices to show (a)\u201cevery BI history is SCBI history of T \u201d, and (b) \u201c every SCBI history is BI history of T \u201d.\nFor (a), take any BI history h\u2217. By I), all BI histories are sight reachable. Further by II), for all (hh\u2032) h\u2217, if (hh\u2032) \u2208 Zh, then (hh\u2032) is max in Zh. This is to say that for each of its prefix h, h\u2217h is max in Zh. By definition 2.6, h\u2217 is a SCBI history. For (b), take any SCBI history h\u2217. We can show it is a BI history, i.e., h\u2217 is max in Z. For suppose not, then there exists a BI history h\u2032 such that h\u2032 h\u2217. Notice that there must be some history u which is the common prefix of h\u2217 and h\u2032. Since h\u2032 is a BI history, by condition I) and II), we know that h\u2032u h\u2217u. Then h\u2217u is not a prefix of a SCBI history. Thus, h\u2217 is not a SCBI history. Contradiction."}, {"heading": "2.2.3 More sight, better outcome?", "text": "We have seen earlier on that, SCBI may loss global optimality. The BI history definitely has a maximal payoff, while it might not be the case for SCBI, since each action is chosen with a limited sight. So BI SCBI holds without exception, in the sense that any BI history is no worse than any SCBI history. One might conjecture that more sight always contributes to better outcomes. Yet, the fact below falsifies this.\nFact 2.9 Let T be a P tree. Also, let s1 and s2 be two sight functions for T satisfying s1(h) \u2286 s2(h) for any history h in T . Take any two SCBI histories z1 and z2 of (T,s1) and (T,s2) respectively. Then the following three cases are all possible: a) z1 z2; b) z2 z1; c) z1 \u223c z2.\nProof 2.10 Case (a) has been shown in Example 1.1. Case (b): Obviously, Figure 2 offers an instance for this. Case (c): The scenario depicted in Figure 3 is an example.2\nIn conclusion, full sight guarantees a maximal payoff. However, with short sight, increase of sight does not always improve the outcome. The added sight may bring misleading information, e.g., a branch which is temporarily nicer but actually unpromising, and finally gives rise to an even worse outcome. Still, this does not mean that SCBI is deficient: rather, these observations seem realistic for real agents. These issues will be discussed further in Section 4."}, {"heading": "3 A Logical Analysis", "text": "After modelling decision-making with short sight by preference tree models, it is instructive to see what a logical language looks like for reasoning about these models, especially the role of sight in a SSDM process. So far, no such logic has been proposed, though logics of game-theoretic structures have been extensively studied \u2013 see [22, 20] \u2013 while there are a few preliminary logic analyses of sight on its own, [10, 27]. In this section, we design a minimal and natural logical system that supports reasoning about sight in the context of single-agent decision-making processes, characterizing basic properties of preference-sight trees, and formally capturing the results in the previous section."}, {"heading": "3.1 Syntax and Semantics", "text": "To reason about the key ingredients (i.e., histories, preferences, and sights) of a P-S tree, we take P(T,s) as a set of propositional letters, which at least contains the following 2:\n\u2022 h for each history h.\n\u2022 h1 \u2265 h2 encoding the preference relation of the agent over all histories, and the strict part of which is h1 > h2.\n\u2022 s(h) encoding the sight at each history h in T .\nBased on P(T,s), we give a language L for reasoning about P-S trees. In L , we have a key dynamic operator [!\u03d5] for restricting to the worlds satisfying \u03d5 , and a universal modality with A\u03d5 saying that \u03d5 is true in every world.\nDefinition 3.1 (Preference-sight language) Take any set of atomic letters P(T,s). The preference-sight language L is given by the following BNF, where p \u2208 P(T,s):\n\u03d5 ::= p |\u00ac\u03d5 |\u03d5 \u2227\u03c8 |[!\u03d5]\u03c8 | A\u03d5.\nWe write \u3008!\u03d5\u3009\u03d5 to abbreviate \u00ac[!\u03d5]\u00ac\u03d5 .\nDefinition 3.2 (Preference-sight models) For a P-S tree (T,s), a preference-sight model M(T,s) is a tuple (H, ,V ) where the following holds:\n\u2022 H is the set of possible worlds, one for each history, \u2022 is the reachability (prefix) relation among worlds, \u2022 V : PT \u2192 \u03c1(H) is an evaluation function satisfying: (1) \u2200h \u2208 H, V (h) = {h\u2032|h\u2032 h}.\n(2) V (h1 \u2265 h2) = { H, IF h1 h2, /0, Otherwise. (3) \u2200h \u2208 H, V (s(h)) = \u22c3\nh\u2032\u2208s(h) V (h\u2032).\nIntuitively, h is true at all the worlds leading to h. h1 \u2265 h2 is true everywhere if h1 h2, and nowhere otherwise. Finally, V (s(h)) is a union of the worlds that make the given atom true for at least one element of s(h).\nThere seems to be nothing striking in this syntax. However, given the special role of atoms, the natural model update differs from the usual one in dynamic-epistemic logic.\nDefinition 3.3 (Model update) Given a preference-sight model M(T,s) = (H, ,V ) and a set X \u2282 H, the updated model M(T,s)!X produced by the restriction of X is defined as a tuple (X , \u2229X2,V!X), where 3\nV!X(p) = { V!X(h1 \u2265 h2), IF p is of the form h1 \u2265 h2 V (p)\u2229X , Otherwise\n2The idea of defining h is motivated by [1], where the authors define an atomic sentence o for each leaf in a game tree. 3In this definition, ZX denotes the terminal histories in X , i.e., the set of histories that have no successors in X .\nV!X(h1 \u2265 h2) =  X , IF V (z1 \u2265 z2) = H, where z1 \u2208 max {z \u2208 ZX |h1 z}, z2 \u2208 max {z \u2208 ZX |h2 z}\n/0, Otherwise\nM(T,s)!X is the update of the model M (T,s) restricting the set of states to X , and the valuation function accordingly. But crucially, the valuation for preference atoms in the new model reflects the updating process in the visible tree of Algorithm 1. In the following, we omit superscripts (T,s).\nThe semantics for this language is basically standard, [8], so we only mention the truth condition of [!\u03d5]\u03c8:\nLet M be a preference-sight model. For any state h in M,\nM,h |= [!\u03d5]\u03c8 iff M,h |= \u03d5 \u21d2M!\u03d5 ,h |= \u03c8.\nValidity of formulas is defined as usual, cf. [8]."}, {"heading": "3.2 Main characterization results", "text": "Despite its simplicity, L can express our results in previous sections concerning properties and solutions of P-S trees. We introduce some helpful syntactic abbreviations, and then state our main characterization results.\n\u2022 Zh = \u2228 { z | z \u2208 Zh}.\n\u2022 max\u2265X= \u2228 { h | h \u2208 X , and h h\u2032 for \u2200h\u2032 \u2208 X}.\n\u2022 BI = \u2228 { z | z \u2208 BI} (BI holds at T \u2019s BI histories).\n\u2022 SCBI = \u2228 { z | z \u2208 SCBI}, that is, the formula SCBI holds at the SCBI histories of T .\nProposition 3.1 Let (T,s) be a P-S tree and M be a L -model for it. Then (T,s) is preference-sight consistent iff the following formula is valid in M:\u2227\nh \u2227 h1\u2208Hh \u2227 h2\u2208Hh ((h1 \u2265 h2\u2192 [!s(h)]h1 \u2265 h2)\u2227\n(\u3008!s(h)\u3009h1 \u2265 h2\u2192 h1 \u2265 h2))\nLemma 3.2 For any P-S tree (T,s) and model M for it, a BI history h\u2217 is sight-reachable if and only if the following formula holds in M:\n(SR) : \u2227 h \u2227 a\u2208A(h) (A((ha)\u2192 h\u2217)\u2192 (A((ha)\u2192 s(h)))).\nProof 3.3 (\u21d2) Suppose that BI history h\u2217 is sight-reachable. By Definition 2.8, we have that, for all (ha) h\u2217, it holds that (ha) \u2208 s(h), where h,h\u2032 are histories, and a is an action following h. More formally, (ha) h\u2217 can be defined by the formula A((ha)\u2192 h\u2217) in the sense that, in T , for all h and a \u2208 A(h), (ha) h\u2217 iff M |= A((ha)\u2192 h\u2217). And similarly (ha) \u2208 s(h) is defined by A((ha)\u2192 s(h)). Thus if a BI history h\u2217 is sight-reachable, then M |= \u2227 h \u2227\na\u2208A(h)(A((ha)\u2192 h\u2217)\u2192 (A((ha)\u2192 s(h)))). The other direction can be proved in a similar way. 2\nLemma 3.4 Let (T,s) be a P-S tree and M be a L -model for it. A BI history h\u2217 is locally optimal iff the following formula is valid in M:\n(LO) : ( \u2227 h \u2227 (hh\u2032)\u2208Zh (A((hh\u2032)\u2192 h\u2217)\u2192\n(A((hh\u2032)\u2192max Zh)\u2227\u2227 (hh\u2032\u2032)\u2208Zh ((hh\u2032)\u223c (hh\u2032\u2032)\u2194 \u2228 z\u2208BI (A((hh\u2032\u2032)\u2192 z))))).\nProof 3.5 (\u21d0) Suppose BI history h\u2217 is locally optimal. Then for (hh\u2032) h\u2217, if (hh\u2032) \u2208 Zh, we have (hh\u2032) is max in Zh. And for any (hh\u2032\u2032), (hh\u2032\u2032) \u223c (hh\u2032) iff \u2203z \u2208 BI s.t. (hh\u2032\u2032) z. Similar with the above proposition, A((hh\u2032)\u2192 h\u2217) captures that (hh\u2032) h\u2217. And A((hh\u2032\u2032)\u2192 z) shows that (hh\u2032\u2032) z. Finally, ((hh\u2032)\u2192max Zh) demonstrates that (hh\u2032) is max in Zh. Direction (\u21d2) uses a similar check.\nProposition 3.6 (L -characterization of equivalence) Let (T,s) be a preference-sight tree and M a model for it. Then the following formula is valid in M:\n|= (A(BI\u2194 SCBI))\u2194\u2227 h\u2217\u2208Z ((A(h\u2217\u2192 BI))\u2192 (SR\u2227LO))\nProof 3.7 Direction (\u21d2). We need to prove the following: 1) (A(BI\u2194 SCBI))\u2192 \u2227 h\u2217\u2208Z(A(h\u2217\u2192 BI)\u2192 SR).\n2) (A(BI\u2194 SCBI))\u2192 \u2227\nh\u2217\u2208Z(A(h\u2217\u2192 BI)\u2192 LO). For 1). It is equivalent to prove that, for any h\u2217 \u2208 Z, (BI\u2194 SCBI)\u2227(A(h\u2217\u2192BI))\u2192 SR. Suppose \u00ac(SR). Then \u2203(ha) h\u2217, and (ha) /\u2208 Th, and so, at h, the branch leading to h\u2217 is not visible in Th. Thus, the BI history in Th could not be a branch leading to h\u2217. By the definition SCBI, it follows that h\u2217 /\u2208 SCBI. However, by h\u2217\u2192 BI we know that h\u2217 is a BI history. This contradicts BI\u2194 SCBI.\n2) can be proved in a similar style.\nDirection (\u21d0). Suppose that \u00ac(A(BI\u2194 SCBI)). Then (a): \u2203z\u2217 \u2208 BI and z\u2217 /\u2208 SCBI, or (b) : \u2203z\u2217 \u2208 SCBI and z\u2217 /\u2208 BI.\nIf (a), then, by the antecedent, we have that: \u2200(ha) z\u2217,(ha) \u2208 Hh. Also, \u2200(hh\u2032) \u2208 Zh and (hh\u2032) h\u2217, it holds that (hh\u2032) \u2208max Zh. Then it directly follows that z\u2217 is a SCBI history. Contradiction.\nIf (b), then take any z \u2208 BI, which shares a prefix u with z\u2217, i.e., u z and u z\u2217. By the antecedent, we have zu \u2208 max Zh. Since z\u2217 /\u2208 BI, it follows that zu > z\u2217u. Then z\u2217 /\u2208 SCBI. Once more, we have a contradiction. 2"}, {"heading": "3.3 Valid principles", "text": "The operator [!\u03d5] makes L a PAL-like language. However, the special model-update makes it different from standard PAL [11]. This suggests a close look at what is and what is not valid in preference-sight models.\nFirst, some axioms in standard PAL do not hold in preference-sight models. For example, the !ATOM axiom, [!\u03d5]p\u2194 (\u03d5 \u2192 p), is not valid when it is of the form below.\nProposition 3.8 The following is not valid in preference-sight models, where h,h1,h2 represent arbitrary histories.\n!Sight-Preference : [!s(h)]h1 \u2265 h2\u2194 (s(h)\u2192 h1 \u2265 h2).\nProof 3.9 For a counterexample, consider the tree T in Figure ??. It is easy to see that in the model M for T , M |= [!s(\u03b5)]h1 \u2265 h2 and M 2 s(\u03b5)\u2192 h1 \u2265 h2, since there exists a state \u03b5 such that M,\u03b5 |= s(\u03b5) and M,\u03b5 2 h1 \u2265 h2.\nThis proposition says that subjective preference in visible trees is not necessarily consistent with objective preference.\nNow let us see some interesting valid principles and their intuitive interpretations.\nLemma 3.10 The formulas shown in Table 1 are valid, where h,h1,h2, and h3 are arbitrary histories.\nProof 3.11 We only prove some cases, proofs for the others are trivial or standard. For Ts. Take any state u with M,u |= h. Then u\u2208V (h). As the sight function is reflexive, i.e., h\u2208 s(h), it holds that V (h)\u2286 V (s(h)). So u \u2208 V (s(h)). Thus, M,u |= s(h). For T M. Take any state u, any history h and any z \u2208 Z, and suppose M,u |= A(z\u2192 h). Then for any u\u2032, u\u2032 \u2208 V (z) implies that u\u2032 \u2208 V (h). Thus, V (z) \u2286 V (h). It follows that z \u2208 V (h). Given that z is terminal, by the definition of V (h), it must be that h = z. Thus, M,u |= A(h\u2192 z).\nFor DC. Take any state u, suppose for some h1 h2 h3, M,u |= A(h3 \u2192 s(h1)). Then we know V (h3) \u2286 V (s(h1)). It follows that h3 \u2208 s(h1). As the sight function is downward closed, we have h2 \u2208 s(h1). Thus, M,u |= A(h2\u2192 s(h1)).\nFor !ATOM\\SP. Take any state u, and let M,u |= [!\u03d5]p where \u03d5 is not of the form !s(h) and p is not of the form h1 \u2265 h2. It holds that M,u |= \u03d5 implies that M!\u03d5 ,u |= p. By Definition 3.3, M!\u03d5 ,u |= p iff M,u |= p. Therefore, M,u |= \u03d5 implies M,u |= p. Equivalently, then, M,u |= \u03d5 \u2192 p. 2\nInterpretation of valid principles. Each of these axioms has some intuitive appeal. T\u2265, 4 and to\u2265 show the reflexivity, transitivity and totality of the preference relation, respectively. Likewise, Ts says that sight is reflexive. DC characterizes the (downward-closure) property of sight. NF encodes the nonforgetting property of sight. TM guarantees that terminal histories of the P-S tree are actually terminal. One further interesting point is that there is no correspondence of TM for terminal histories of visible trees.\nFact 3.12 The following formula is not valid in preference-sight models:\u2227 u \u2227 z\u2208Zu \u2227 h(A(z\u2192 h)\u2192 A(h\u2192 z)).\nOther validities in the table are axioms for standard PAL. We postpone the study of a complete axiomatization of the logic L until future work.\nTo conclude this section, in L , the ingredients including histories, preferences and sights are encoded as primitive propositions. Various earlier phenomena in P-S trees can thus be captured in a simple, direct and intuitive manner. This special-purpose logic, as we will see soon, is model-dependent, but it can also be formulated generically."}, {"heading": "4 Background in game logics", "text": "In this section, we relate our logic L to existing logics for classical game theory, showing how ideas can be combined where useful. Since so far we have been working with BI and SCBI histories, we first define strategies for P-S trees: A strategy for a P-S tree (T,s) is a function \u03c3 : H \u2192 A such that \u03c3(h) \u2208 A(h). That is, \u03c3 assigns each history h an action that follows h. In particular, for a visible tree Th, a \u2018local strategy\u2019 \u03c3h is a restriction of \u03c3 to Th, such that \u03c3h(h\u2032) = \u03c3(h\u2032) for any h\u2032 \u2208 Th."}, {"heading": "4.1 Generic formulation of L", "text": "In applied logic for structure analysis, there exist two extremes, viz. model-dependent \u2018local languages\u2019 and \u2018generic languages\u2019 that work across models. For a generic logic, a definition of a property \u03c0 is a formula \u03d5 such that for all models M, M has property \u03c0 iff M |= \u03d5 . For a local language, such a formula can depend on a given model M: there exists a formula \u03d5M which depends on M, such that any model M has the property \u03c0 iff M |= \u03d5M. However, in this case, the defining formula can be trivial. For example, one might define \u03d5M simply as follows.\n\u03d5M = { >, if M satisfies \u03c0 \u22a5, Otherwise\nIn this subsection, using a well-known Rationality property as an example, we discuss how modeldependent our earlier language L is, and then show how it can be formulated in a generic way. We first recall the results on classical BI. Given that we have been dealing with single-agent cases until now, in this Section, we will adapt the results from the literature on multi-player games to the single-player case.\nThe BI strategy [2, 3] is the largest subrelation \u03c3 of the total move relation that has at least one successor at each node, while satisfying the rationality (RAT) property:\nRAT No alternative move for the player yields an outcome via further play with \u03c3 that is strictly better than all the outcomes resulting from starting at the current move and then playing \u03c3 all the way down the tree.\nAs argued in [2, 3], this rationality assumption is a confluence property for action and preference:\nCF \u2200x\u2200y(x\u03c3y\u2192\u2200z(x move z\u2192 \u2203u(end(u)\u2227 y\u03c3\u2217u\u2227\u2200v((end(v)\u2227 z\u03c3\u2217v)\u2192 u\u2265 v))))\nWe can observe that there is also a corresponding rationality property for the local BI strategies that constitute an SCBI, which should however now express a confluence property for action, preference and sight. Specifically, for a P-S tree, each local BI strategy for the visible tree Th at h is the largest subrelation \u03c3h of the total move relation in Th, satisfying 1) \u03c3h has at least one successor at each h\u2032 \u2208 Th, and 2) the following rationality property holds:\nRATS In the visible tree, there is one outcome obtained by playing \u03c3h from the start to the end, that is no worse than all the outcomes yielded from any alternative first move followed by further play with \u03c3h.\nThis confluence property involving sight is expressible as follows in our language L :\nProposition 4.1 Let (T,s) be a P-S tree, and let M be any model for it. M satisfies RATS iff M validates the following L -formula, where \u03c3h is the BI strategy for visible tree at h and where (h(\u03c3h)k) stands for the history reached from h after executing \u03c3h for k times.\nCFSM \u2227 h \u2228 z\u2208Zh \u2228 k=l(z)\u2212l(h) (A((h(\u03c3h)k)\u2194 z)\n\u2192 ( \u2227\na\u2032\u2208Ah(h) \u2227 z\u2032\u2208Zh \u2227 m=l(z\u2032)\u2212l(ha\u2032) (A((ha\u2032(\u03c3h)m)\u2194 z\u2032))\u2192\nz\u2265 z\u2032)),\nProof 4.2 We first claim that at state h \u2208 H, for any terminal history z \u2208 Zh, and h\u2032 \u2208 Hh, A(h\u2032 \u2194 z) implies that h\u2032 = z. This is straightforward since A(h\u2032 \u2194 z) demonstrates that prefixes of h\u2032 are the same with those of z, which means that h\u2032 = z. Then M |= CFSM says that there is a terminal history zh following h by playing a local BI strategy \u03c3h, such that z z\u2032 for any other z\u2032 \u2208 Zh which follows an alternative first move a\u2032 \u2208 Ah(h) via further play of \u03c3h. Therefore, we know that M satisfies RATS. 2\nHowever, compared with the generic logic in [4, 3, 2], the given definition in our logic is local. It is obvious that CF, the formula defining the property RAT, is insensitive to models \u2013 while our CFSM relies on a given model for its ranges of big disjunctions and conjunctions, and in its model-dependent notations like s(h) and h1 \u2265 h2. Still, it is also clearly true that our definition is not as trivial as the earlier local trick. Therefore, our logic L seems somewhere between the two extremes of locality and genericity. This feeling can be made precise by moving to a closely related truly generic first-order logic.\nThe relevant modified formula involves some natural auxiliary predicates. x y says that x is a prefix of y; x^y means that x can see y. Corresponding to the BI relation \u03c3 , y\u03c3(x)z says that from y, z is a local backward induction move in the visible tree at x; \u03c3 k describes \u03c3 being composed for k times with k \u2208 N 4; move and \u2265 are still the move relation and preference relation, respectively, of the game.\nProposition 4.3 Any model M satisfies RATS iff it validates the following formula.\nCFS(FO): \u2200x{(\u2203y(x y))\u2192 \u2200u[(x\u03c3(x)u)\u2192\u2200t((x move t \u2227 x^t)\u2192\n\u2203z((x^z\u2227\u00ac\u2203z\u2032(z z\u2032\u2227 x^z\u2032)\u2227\u2203k(u(\u03c3(x))kz))\u2227 \u2200v((x^v\u2227\u00ac\u2203v\u2032(v v\u2032\u2227 v^v\u2032)\u2227\u2203l(t(\u03c3(x))lv))\u2192\n\u2227z\u2265 v)))]}. 4Here x\u03c3 ky is the abbreviation of \u2203y1\u2203y2 \u00b7 \u00b7 \u00b7\u2203yk(x\u03c3y1\u2227 y1\u03c3y2\u2227\u00b7\u00b7 \u00b7\u2227 yk\u22121\u03c3yk \u2227 (yk = y)).\nProof 4.4 It is easy to show that M |= CFS(FO) iff M |= CFSM.2\nIn summary, incorporating basic elements of P-S trees directly into first-order syntax makes L intuitive and natural.\nEven so, other logics exist for dealing with further aspects of game trees and solution procedures, and we will discuss a few examples in what follows with a view to how they behave in the presence of sight."}, {"heading": "4.2 Solution procedures and fixed-point logics", "text": "Recursive solution procedures naturally correspond to definitions in existing fixed-point logics, such as the widely used system LFP(FO). An LFP(FO) formula mirroring the recursive nature of BI is constructed in [4, 6] to define the classical BI relation, based on the above property RAT. Now, we have shown that sight-restricted SCBI, too, is a recursive game solution procedure. Can LFP(FO) be used to define SCBI as well \u2013 and if so, how?\nThe answer is yes, but we need an extension. Rather than a binary relation bi as in [4, 6], characterizing SCBI needs a ternary relation. First, we define the local BI relation in visible trees, which will be denoted by bisight. For any states x,y,z, bisight(x,y,z) means that in the visible tree at x, the local BI strategy is bisight, which chooses z when the current state is y. It is then obvious that bisight should satisfy the following simple first-order definable property, requiring the relevant states to be visible and reachable:\nbisight(x,y,z)\u2192 see(x,y)\u2227 see(x,z)\u2227move(y,z).\nThe intuition of bisight(x,y,z) is then captured as follows:\n\u2200x\u2200y\u2200z(bisight(x,y,z)\u2192\u2200t((see(x, t)\u2227move(y, t)) \u2192 (\u2203u(endsight(x,u)\u2227bi\u2217sight(x,z,u)\u2227\u2200v((endsight(x,v)\u2227\nbi\u2217sight(x, t,v))\u2192 u\u2265 v))))).\nNotice that all occurrences of bisight in the above formulas are still syntactically positive. This allows us to define local BI strategy bisight with LFP(FO).\nProposition 4.5 The strategy bisight can be defined as the relation R in the following LFP(FO) formula.\n\u03bdR,xyz\u2022\u2200x\u2200y\u2200z(R(x,y,z)\u2192\u2200t((see(x, t)\u2227move(y, t)) \u2192 (\u2203u(endsight(x,u)\u2227R\u2217(x,z,u)\u2227\u2200v((endsight(x,v)\u2227\nR\u2217(x, t,v))\u2192 u\u2265 v))))).\nIt can be proved formally that bisight is a greatest-fixed-point of the above formula. Based on bisight, we now proceed to show that the SCBI relation is LFP(FO) definable.\nCorollary 4.6 The SCBI relation scbi for a P-S tree can be represented in the following formula: \u2200x\u2200y(scbi(x,y)\u2194 bisight(x,x,y)).\nAs in the original classical case, this LFP(FO) definability of scbi exposes an intersection between the logical foundation of computation and the recursive nature of sight-compatible backward induction solutions for P-S trees."}, {"heading": "4.3 Modal surface logic of best action", "text": "In contrast with detailed formalism of solutions with LFP(FO), there is the modal surface logic of [5], which enables direct and natural reasoning about best actions without considering the underlying details of recursive computation. First of all, we list its modalities for classical BI. [bi] and [BI] encode the BI move and BI paths respectively. [best]\u03d5 says that \u03d5 is true in some successor of the current node that can be reached in one step via the bi move.\nM,h |= end iff h \u2208 Z. M,h |= [move]\u03d5 iff \u2200 h\u2032 = (ha) with a \u2208 A(h), M,h\u2032 |= \u03d5 . M,h |= [best]\u03d5 iff for all h\u2032 with h\u2032 \u2208 bi(h), M,h\u2032 |= \u03d5 . M,h |= [bi]\u03d5 iff for all h\u2032 with h\u2032 \u2208 bi(h), M,h\u2032 |= \u03d5 . M,h |= [bi\u2217]\u03d5 iff M,u |= \u03d5 for all u with u \u2208 (bi)\u2217(h). M,h |= [BI]\u03d5 iff for all z with z \u2208 BI, M,z |= \u03d5 .\nThe above logic is still applicable in our setting, but it requires substantial extension for sight-related concepts. In accordance with [bi] and [BI], we use [scbi] and [SCBI] as operators for the SCBI strategy and SCBI path, respectively. For the local BI strategy and path in visible trees, the modalities are [bisight] and [BIsight]. Moreover, recall that M!s(h) is the updated model obtained in the way of Definition 3.3.\nM,h |= [scbi]\u03d5 iff for all h\u2032 with h\u2032 \u2208 scbi(h), M,h\u2032 |= \u03d5 . M,h |= [SCBI]\u03d5 iff for all h\u2032 with z \u2208 SCBI, M,z |= \u03d5 . M,h |= [!sight]\u03d5 iff M!s(h),h |= \u03d5. M!s(h),u |= endsight iff u \u2208 Zh. M!s(h),u |= [movesight]\u03d5 iff for \u2200u\u2032 = (ua) with a \u2208 Ah(u), M!s(h),u\u2032 |= \u03d5 . M!s(h),u |= [bestsight]\u03d5 iff M,u\u2032 |= \u03d5 for \u2200u\u2032 \u2208 bih(u). M!s(h),u |= [bisight]\u03d5 iff M,u\u2032 |= \u03d5 for \u2200u\u2032 \u2208 bih(u). M!s(h),u |= [(bisight)\u2217]\u03d5 iff M!s(h),u\u2032 |= \u03d5 for all u\u2032, such that u\u2032 \u2208 (bih)\u2217(u). M,h |= [BIsight]\u03d5 iff for all z with z \u2208 BIh, M,z |= \u03d5 .\nWe give a few illustrations of new issues that arise now.\nCapturing the SCBI strategy For a start, we are now able to characterize the SCBI strategy, in a similar vein as the frame correspondence for the classical BI strategy in [5]. Proposition 4.7 The BI strategy is the unique relation bi satisfying this modal axiom for all propositions p:\n(\u3008bi\u2217\u3009(end\u2227 p))\u2192 ([move][\u03c3\u2217](end\u2227\u3008\u2264\u3009p)) Along the same lines, we can express the SCBI strategy in P-S trees based on the idea that each scbi move coincides with a local BI move within the current visible tree. Proposition 4.8 The SCBI strategy is the relation scbi satisfying the following axioms for all propositions p:\n(1) \u3008scbi\u3009p\u2194 [!sight]\u3008bisight\u3009p.\n(2) [!sight](\u3008(bisight)\u2217\u3009(endsight\u2227 p)\u2192 [movesight]\u3008(bisight)\u2217\u3009(endsight\u2227\u3008\u2264\u3009p)).\nBest action and preference-consistency Turning to properties of frames for the extended modal logic of best action with sight, there are interesting differences when comparing SCBI and classical BI. To see this, we employ operators \u3008best\u3009, \u3008bestsight\u3009, \u3008bi\u2217\u3009, \u3008scbi\u2217\u3009 and (bisight)\u2217. Now we can make some interesting comparisons. Proposition 4.9 For classical backward induction, the axiom \u3008best\u3009\u3008bi\u2217\u3009\u03d5 \u2194 \u3008bi\u2217\u3009\u03d5 holds.\nHowever, the new frames do not have the corresponding axiom for the SCBI strategy, since the actions it recommends are not necessarily the actual best actions according to BI. Even in visible trees, this is also not true. Proposition 4.10 The following formulas are not valid:\n(a) \u3008best\u3009\u3008scbi\u2217\u3009\u03d5 \u2194 \u3008scbi\u2217\u3009\u03d5. (b) [!sight](\u3008best\u3009\u3008(bisight)\u2217\u3009\u03d5 \u2194 \u3008(bisight)\u2217\u3009\u03d5).\nNevertheless, there is a certain coherence between the local BI strategy and local best actions returned by it. Proposition 4.11 The following formula is valid: [!sight](\u3008bestsight\u3009\u3008(bisight)\u2217\u3009\u03d5 \u2194 \u3008(bisight)\u2217\u3009\u03d5).\nAs for the preference relation, SCBI has a property that classical BI lacks: local BI moves never conflict with the preferences in submodels. In other words, within a visible tree, the initial move determined by the local BI strategy is more preferable for the agent than any other first move.\nProposition 4.12 For SCBI, it holds that [!sight](\u3008bestsight\u3009\u03d5 \u2192 [movesight]\u3008\u2264\u3009\u03d5). For BI, although it returns a final optimal path, there is no guarantee that its intermediate histories be preferable. Proposition 4.13 For BI, the following does not hold: \u3008best\u3009\u03d5 \u2192 [move]\u3008\u2264\u3009\u03d5. Path terminality and optimality Using a similar style of modal analysis, we can make the following observations concerning the obvious operators [BI], [SCBI] and [BI]sight .\nProposition 4.14 We have the following three facts: (a) The formula[BI]\u03d5 \u2192 [BI][BI]\u03d5 is valid. (b) For SCBI, the following formula does not hold: [BIsight]\u03d5 \u2192 [BIsight][BIsight]\u03d5. (c) The formula [SCBI]\u03d5 \u2192 [SCBI][SCBI]\u03d5 is valid.\nHere (a) says that from a BI outcome only a terminal history can be reached; (b) shows that the local BI history may not be a terminal history of the whole tree, and (c) says the SCBI history for the whole tree is always terminal.\nAnother phenomenon regarding these operators is the local optimality of SCBI at the cost of being more realistic than BI. We have mentioned this point already in Section 2.2.4: now we can present a precise formal version. Proposition 4.15 Let \u03c3 be any strategy profile, (a). For BI, the following is valid: \u3008BI\u3009\u03d5 \u2192 [\u03c3 ]\u3008\u2264\u3009\u03d5. (b). The following does not hold: \u3008SCBI\u3009\u03d5 \u2192 [\u03c3 ]\u3008\u2264\u3009\u03d5. (c). For SCBI, it holds that [!sight](\u3008BIsight\u3009\u03d5 \u2192 [\u03c3sight]\u3008\u2264sight\u3009\u03d5).\nHere (a) shows the global optimality of the BI path. (b) and (c) together say the SCBI path is not globally optimal, but each move on this path leads to a locally optimal path.\nAltogether, this section has shown the broad logical foundations of our framework, embedding our local language in existing broader generic formalisms, but also enriching and extending these frameworks with aspects of short sight."}, {"heading": "5 Toward Multi-player games", "text": "While our models and results are about single-agent sequential decision-making processes, we believe they are applicable well beyond that. They can be naturally extended to multi-player extensive gamescenarios with short sight. For such a game model, we can build on [14], which makes an assumption that the current player only knows his own sight, and that he believes other players can see as much as he can see and will play according to this belief. That is, this model precludes more complex forms of interactive knowledge and reasoning. But using this same assumption, our model in this paper can be extended to multi-player cases directly. The only thing we have to do is add agent-labeling to SSDM: even though players can change with time, everything including sight, preference, and actions can be modeled from the current player\u2019s perspective.\nWe will not state any results for the extended multi-player model since they are quite similar to what we have shown already. The case where we drop the above assumption and allow a more free modeling of players\u2019 mutual knowledge and beliefs about sight and preference would be more interesting. We will leave this for future work."}, {"heading": "6 Discussion and Conclusion", "text": "Though motivated by single-agent decision-making process, we have gone towards a much more general goal In the process, our analysis significantly adds to current connections between logic, computation, and game solutions.\nIn many recent game-theoretic papers centering on bounded rationality, a model has been used of games with awareness, [15, 17, 21, 13, 16]. This approach generalizes the classical representation of extensive games by modeling players who may not be aware of all the paths. While [14] shows that games with short sight are a well-behaved subclass of games with awareness, there exists a fundamental difference in focus. Players in the latter approach may be unaware of some branches but they can always see some terminal histories, while in the former, players\u2019 sight may only include intermediate histories, ruling out all terminal ones. Moreover, we have shown how short-sight games allow for a natural coexistence of two views of a game, that of insiders and that of outsiders. Having said this, it is clearly an interesting issue to see if our approach in this paper can be extended to cover awareness.\nAnother obvious interface for our logics are heuristic evaluation approaches for intermediate nodes used by the AI community for computational game-solving, [25, 12, 33]. This, too, is a connection that deserves further exploration.\nThere are many additional topics to pursue. We already mentioned multi-player scenarios with nontrivial interactive reasoning about other agents\u2019 preferences, sights, and strategies. This has also been identified as a key task for epistemic game theory, [31]."}, {"heading": "Acknowledgments", "text": "I thank Fenrong Liu for our fruitful collaboration on earlier versions of this paper. Paolo Turrini provided crucial insights on short-sight games and their connections with games and computation, which we are partly exploring together. Sonja Smets provided helpful comments overall. But especially, I thank Johan van Benthem for our longstanding contacts on the logic of short-sight games: Section 4 of this paper owes a lot to his many suggestions and observations. This work is supported by the China Scholarship Council and NSFC grant No.61472369."}], "references": [{"title": "Keep \u2018hoping\u2019 for rationality: a solution to the backward induction paradox", "author": ["Alexandru Baltag", "Sonja Smets", "Jonathan A. Zvesper"], "venue": "Synthese 169(2),", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2009}, {"title": "Exploring a Theory of Play", "author": ["Johan van Benthem"], "venue": "Proc. of TARK,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2011}, {"title": "Game Solution, Epistemic Dynamics and Fixed-Point Logics", "author": ["Johan van Benthem", "Am\u00e9lie Gheerbrant"], "venue": "Fundam. Inform", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2010}, {"title": "Preference logic, conditionals, and solution concepts in games", "author": ["Johan van Benthem", "Sieuwert Van Otterloo", "Olivier Roy"], "venue": "Modality Matters: Twenty-Five Essays in Honour of Krister Segerberga, University of Uppsala,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2006}, {"title": "Toward a Theory of Play: A Logical Perspective on Games and Interaction", "author": ["Johan van Benthem", "Eric Pacuit", "Olivier Roy"], "venue": "Games 2(1),", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2011}, {"title": "Decision Theory and Rationality", "author": ["J.L. Berm\u00fadez"], "venue": null, "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2009}, {"title": "Modeling and Solving Sequential Decision Problems with Uncertainty and Partial Information", "author": ["Blai Tirant Bonet Bretto"], "venue": "Ph.D. thesis, Department of Computer Science,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2004}, {"title": "A Logic of Sights", "author": ["Cedric Degremont", "Soumya Paul", "Nicholas Asher"], "venue": "Journal of Logic and Computation", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2014}, {"title": "Dynamic Epistemic Logic. Synthese library", "author": ["Hans van Ditmarsch", "Wiebe van der Hoek", "Barteld Kooi"], "venue": null, "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2007}, {"title": "The Alpha-Beta Heuristic", "author": ["D. Edwards", "T. Hart"], "venue": "Technical Report 30,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 1963}, {"title": "Games with Unawareness", "author": ["Yossi Feinberg"], "venue": "Stanford Graduate School of Busirness Paper No", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2012}, {"title": "Reasoning About Knowledge of Unawareness Revisited", "author": ["Joseph Y. Halpern", "Leandro C. R\u00eago"], "venue": "Proceedings of the 12th Conference on Theoretical Aspects of Rationality and Knowledge,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2009}, {"title": "Extensive Games with Possibly Unaware Players", "author": ["Joseph Y. Halpern", "Leandro C. R\u00eago"], "venue": "Mathematical Social Sciences", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2014}, {"title": "Extensive games with possibly unaware players", "author": ["Joseph Y. Halpern", "Leandro Chaves R\u00eago"], "venue": null, "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2006}, {"title": "Decision Theory -A Brief Introduction", "author": ["Sven Ove Hansson"], "venue": null, "citeRegEx": "18", "shortCiteRegEx": "18", "year": 1994}, {"title": "A Modal Characterization of Nash Equilibrium", "author": ["Paul Harrenstein", "Wiebe van der Hoek", "John-Jules Meyer", "Cees Witteveen"], "venue": "Fundam. Inf", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2003}, {"title": "On modal logic interpretations of games", "author": ["Paul Harrenstein", "Wiebe Van Der Hoek", "John jules Meyer", "Cees Witteveen"], "venue": "Procs ECAI", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2002}, {"title": "Dynamic unawareness and rationalizable behavior", "author": ["Aviad Heifetz", "Martin Meier", "Burkhard C. Schipper"], "venue": "Games and Economic Behavior", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2013}, {"title": "Modal logic for games and information", "author": ["W. van der Hoek", "M. Pauly"], "venue": "Handbook of Modal Logic, Elsevier,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2006}, {"title": "Sequential Decision Making with Adaptive Utility", "author": ["Brett Houlding"], "venue": "Ph.D. thesis,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2008}, {"title": "Generating Scenario Trees for Multistage Decision Problems", "author": ["Kjetil H\u00f8yland", "Stein W. Wallace"], "venue": "Management Science 47(2),", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2001}, {"title": "Properties of forward pruning in game-tree search. In: proceedings of the 21st national conference on Artificial intelligence - Volume 2, AAAI\u201906", "author": ["Yew Jin Lim", "Wee Sun Lee"], "venue": null, "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2006}, {"title": "Algorithms for Sequential Decision-making", "author": ["Michael Lederman Littman"], "venue": "Ph.D. thesis,", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 1996}, {"title": "A Logic for Extensive Games with Short Sight", "author": ["Chanjuan Liu", "Fenrong Liu", "Kaile Su"], "venue": "LORI, pp. 332\u2013336,", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2013}, {"title": "A tutorial introduction to decision theory", "author": ["D. Warner North"], "venue": "IEEE Transactions on Systems Science and Cybernetics,", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 1968}, {"title": "A Course in Game Theory. MIT Press. Available at https: //mitpress.mit.edu/books/course-game-theory", "author": ["Martin J Osborne", "Ariel Rubinstein"], "venue": null, "citeRegEx": "30", "shortCiteRegEx": "30", "year": 1994}, {"title": "An Introduction to Decision Theory, 1 edition. Cambridge Introductions to Philosophy", "author": ["Martin Peterson"], "venue": null, "citeRegEx": "32", "shortCiteRegEx": "32", "year": 2009}], "referenceMentions": [{"referenceID": 26, "context": "There is a growing interest in the logical foundations, computational implementations, and practical applications of single-agent sequential decision-making (SSDM) problems [32, 23, 28, 18, 9, 26, 24] in such diverse areas as Artificial Intelligence, Control, Logic, Economics, Mathematics, Politics, Psychology, Philosophy, and Medicine.", "startOffset": 173, "endOffset": 200}, {"referenceID": 19, "context": "There is a growing interest in the logical foundations, computational implementations, and practical applications of single-agent sequential decision-making (SSDM) problems [32, 23, 28, 18, 9, 26, 24] in such diverse areas as Artificial Intelligence, Control, Logic, Economics, Mathematics, Politics, Psychology, Philosophy, and Medicine.", "startOffset": 173, "endOffset": 200}, {"referenceID": 24, "context": "There is a growing interest in the logical foundations, computational implementations, and practical applications of single-agent sequential decision-making (SSDM) problems [32, 23, 28, 18, 9, 26, 24] in such diverse areas as Artificial Intelligence, Control, Logic, Economics, Mathematics, Politics, Psychology, Philosophy, and Medicine.", "startOffset": 173, "endOffset": 200}, {"referenceID": 14, "context": "There is a growing interest in the logical foundations, computational implementations, and practical applications of single-agent sequential decision-making (SSDM) problems [32, 23, 28, 18, 9, 26, 24] in such diverse areas as Artificial Intelligence, Control, Logic, Economics, Mathematics, Politics, Psychology, Philosophy, and Medicine.", "startOffset": 173, "endOffset": 200}, {"referenceID": 6, "context": "There is a growing interest in the logical foundations, computational implementations, and practical applications of single-agent sequential decision-making (SSDM) problems [32, 23, 28, 18, 9, 26, 24] in such diverse areas as Artificial Intelligence, Control, Logic, Economics, Mathematics, Politics, Psychology, Philosophy, and Medicine.", "startOffset": 173, "endOffset": 200}, {"referenceID": 22, "context": "There is a growing interest in the logical foundations, computational implementations, and practical applications of single-agent sequential decision-making (SSDM) problems [32, 23, 28, 18, 9, 26, 24] in such diverse areas as Artificial Intelligence, Control, Logic, Economics, Mathematics, Politics, Psychology, Philosophy, and Medicine.", "startOffset": 173, "endOffset": 200}, {"referenceID": 20, "context": "There is a growing interest in the logical foundations, computational implementations, and practical applications of single-agent sequential decision-making (SSDM) problems [32, 23, 28, 18, 9, 26, 24] in such diverse areas as Artificial Intelligence, Control, Logic, Economics, Mathematics, Politics, Psychology, Philosophy, and Medicine.", "startOffset": 173, "endOffset": 200}, {"referenceID": 6, "context": "The current literature [9, 28] has studied uncertainty which an agent faces in recognizing possible outcomes after taking an action and the probabilities associated with these outcomes, as well as the partial observability of what the actual state is like.", "startOffset": 23, "endOffset": 30}, {"referenceID": 24, "context": "The current literature [9, 28] has studied uncertainty which an agent faces in recognizing possible outcomes after taking an action and the probabilities associated with these outcomes, as well as the partial observability of what the actual state is like.", "startOffset": 23, "endOffset": 30}, {"referenceID": 15, "context": "Several remarks need to be made on the role of preference relations in the above definition: (1) Instead of defining preference merely over terminal histories, we have defined it over all histories, an idea going back to [19].", "startOffset": 221, "endOffset": 225}, {"referenceID": 14, "context": "1There is a debate on whether preference and utilities are the same [18, 7].", "startOffset": 68, "endOffset": 75}, {"referenceID": 5, "context": "1There is a debate on whether preference and utilities are the same [18, 7].", "startOffset": 68, "endOffset": 75}, {"referenceID": 25, "context": "In what follows, we define two solution concepts for P-S trees, adapted from [30, 14].", "startOffset": 77, "endOffset": 85}, {"referenceID": 25, "context": "Backward Induction (BI) is well-known in game theory [30].", "startOffset": 53, "endOffset": 57}, {"referenceID": 18, "context": "So far, no such logic has been proposed, though logics of game-theoretic structures have been extensively studied \u2013 see [22, 20] \u2013 while there are a few preliminary logic analyses of sight on its own, [10, 27].", "startOffset": 120, "endOffset": 128}, {"referenceID": 16, "context": "So far, no such logic has been proposed, though logics of game-theoretic structures have been extensively studied \u2013 see [22, 20] \u2013 while there are a few preliminary logic analyses of sight on its own, [10, 27].", "startOffset": 120, "endOffset": 128}, {"referenceID": 7, "context": "So far, no such logic has been proposed, though logics of game-theoretic structures have been extensively studied \u2013 see [22, 20] \u2013 while there are a few preliminary logic analyses of sight on its own, [10, 27].", "startOffset": 201, "endOffset": 209}, {"referenceID": 23, "context": "So far, no such logic has been proposed, though logics of game-theoretic structures have been extensively studied \u2013 see [22, 20] \u2013 while there are a few preliminary logic analyses of sight on its own, [10, 27].", "startOffset": 201, "endOffset": 209}, {"referenceID": 0, "context": "2The idea of defining h is motivated by [1], where the authors define an atomic sentence o for each leaf in a game tree.", "startOffset": 40, "endOffset": 43}, {"referenceID": 8, "context": "However, the special model-update makes it different from standard PAL [11].", "startOffset": 71, "endOffset": 75}, {"referenceID": 1, "context": "The BI strategy [2, 3] is the largest subrelation \u03c3 of the total move relation that has at least one successor at each node, while satisfying the rationality (RAT) property: RAT No alternative move for the player yields an outcome via further play with \u03c3 that is strictly better than all the outcomes resulting from starting at the current move and then playing \u03c3 all the way down the tree.", "startOffset": 16, "endOffset": 22}, {"referenceID": 1, "context": "As argued in [2, 3], this rationality assumption is a confluence property for action and preference:", "startOffset": 13, "endOffset": 19}, {"referenceID": 2, "context": "2 However, compared with the generic logic in [4, 3, 2], the given definition in our logic is local.", "startOffset": 46, "endOffset": 55}, {"referenceID": 1, "context": "2 However, compared with the generic logic in [4, 3, 2], the given definition in our logic is local.", "startOffset": 46, "endOffset": 55}, {"referenceID": 2, "context": "An LFP(FO) formula mirroring the recursive nature of BI is constructed in [4, 6] to define the classical BI relation, based on the above property RAT.", "startOffset": 74, "endOffset": 80}, {"referenceID": 4, "context": "An LFP(FO) formula mirroring the recursive nature of BI is constructed in [4, 6] to define the classical BI relation, based on the above property RAT.", "startOffset": 74, "endOffset": 80}, {"referenceID": 2, "context": "Rather than a binary relation bi as in [4, 6], characterizing SCBI needs a ternary relation.", "startOffset": 39, "endOffset": 45}, {"referenceID": 4, "context": "Rather than a binary relation bi as in [4, 6], characterizing SCBI needs a ternary relation.", "startOffset": 39, "endOffset": 45}, {"referenceID": 3, "context": "In contrast with detailed formalism of solutions with LFP(FO), there is the modal surface logic of [5], which enables direct and natural reasoning about best actions without considering the underlying details of recursive computation.", "startOffset": 99, "endOffset": 102}, {"referenceID": 3, "context": "Capturing the SCBI strategy For a start, we are now able to characterize the SCBI strategy, in a similar vein as the frame correspondence for the classical BI strategy in [5].", "startOffset": 171, "endOffset": 174}, {"referenceID": 11, "context": "In many recent game-theoretic papers centering on bounded rationality, a model has been used of games with awareness, [15, 17, 21, 13, 16].", "startOffset": 118, "endOffset": 138}, {"referenceID": 13, "context": "In many recent game-theoretic papers centering on bounded rationality, a model has been used of games with awareness, [15, 17, 21, 13, 16].", "startOffset": 118, "endOffset": 138}, {"referenceID": 17, "context": "In many recent game-theoretic papers centering on bounded rationality, a model has been used of games with awareness, [15, 17, 21, 13, 16].", "startOffset": 118, "endOffset": 138}, {"referenceID": 10, "context": "In many recent game-theoretic papers centering on bounded rationality, a model has been used of games with awareness, [15, 17, 21, 13, 16].", "startOffset": 118, "endOffset": 138}, {"referenceID": 12, "context": "In many recent game-theoretic papers centering on bounded rationality, a model has been used of games with awareness, [15, 17, 21, 13, 16].", "startOffset": 118, "endOffset": 138}, {"referenceID": 21, "context": "Another obvious interface for our logics are heuristic evaluation approaches for intermediate nodes used by the AI community for computational game-solving, [25, 12, 33].", "startOffset": 157, "endOffset": 169}, {"referenceID": 9, "context": "Another obvious interface for our logics are heuristic evaluation approaches for intermediate nodes used by the AI community for computational game-solving, [25, 12, 33].", "startOffset": 157, "endOffset": 169}], "year": 2016, "abstractText": "We consider decision-making and game scenarios in which an agent is limited by his/her computational ability to foresee all the available moves towards the future \u2013 that is, we study scenarios with short sight. We focus on how short sight affects the logical properties of decision making in multi-agent settings. We start with single-agent sequential decision making (SSDM) processes, modeling them by a new structure of \u2018preference-sight trees\u2019. Using this model, we first explore the relation between a new natural solution concept of Sight-Compatible Backward Induction (SCBI) and the histories produced by classical Backward Induction (BI). In particular, we find necessary and sufficient conditions for the two analyses to be equivalent. Next, we study whether larger sight always contributes to better outcomes. Then we develop a simple logical special-purpose language to formally express some key properties of our preference-sight models. Lastly, we show how shortsight SSDM scenarios call for substantial enrichments of existing fixed-point logics that have been developed for the classical BI solution concept. We also discuss changes in earlier modal logics expressing \u2018surface reasoning\u2019 about best actions in the presence of short sight. Our analysis may point the way to logical and computational analysis of more realistic game models.", "creator": "LaTeX with hyperref package"}}}