{"id": "1606.07849", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "24-Jun-2016", "title": "Focused Meeting Summarization via Unsupervised Relation Extraction", "abstract": "We present a novel unsupervised framework for focused meeting summarization that views the problem as an instance of relation extraction. We adapt an existing in-domain relation learner (Chen et al., 2011) by exploiting a set of task-specific constraints and features to assess the impact of a generalised model (Pitman et al., 2015). The results are described in a series of papers (i) for the purposes of summarizing information and discussing the literature in this context.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "histories": [["v1", "Fri, 24 Jun 2016 22:49:56 GMT  (64kb,D)", "http://arxiv.org/abs/1606.07849v1", "SIGDIAL 2012"]], "COMMENTS": "SIGDIAL 2012", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["lu wang", "claire cardie"], "accepted": false, "id": "1606.07849"}, "pdf": {"name": "1606.07849.pdf", "metadata": {"source": "CRF", "title": "Focused Meeting Summarization via Unsupervised Relation Extraction", "authors": ["Lu Wang", "Claire Cardie"], "emails": ["luwang@cs.cornell.edu", "cardie@cs.cornell.edu"], "sections": [{"heading": "1 Introduction", "text": "For better or worse, meetings play an integral role in most of our daily lives \u2014 they let us share information and collaborate with others to solve a problem, to generate ideas, and to weigh options. Not surprisingly then, there is growing interest in developing automatic methods for meeting summarization (e.g., Zechner (2002), Maskey and Hirschberg (2005), Galley (2006), Lin and Chen (2010), Murray et al. (2010a)). This paper tackles the task of focused meeting summarization , i.e., generating summaries of a particular aspect of a meeting rather than of the meeting as a whole (Carenini et al., 2011). For example, one might want a summary of just the DECISIONS made during the meeting, the ACTION ITEMS that emerged, the IDEAS discussed, or the HYPOTHESES put forth, etc.\nConsider, for example, the task of summarizing\nthe decisions in the dialogue snippet in Figure 1. The figure shows only the decision-related dialogue acts (DRDAs) \u2014 utterances associated with one or more decisions.1 Each DRDA is labeled numerically according to the decision it supports; so the first two utterances support DECISION 1 as do the final two utterances in the snippet. Manually constructed decision abstracts for each decision are shown at the bottom of the figure.2 These constitute the decisionfocused summary for the snippet.\nNotice that many portions of the DRDAs are not relevant to the decision itself: they often begin with phrases that identify the utterance within the discourse as potentially introducing a decision (e.g., \u201cMaybe that could be\u201d, \u201cIt seems like you\u2019re gonna have\u201d), but do not themselves describe the decision. We will refer to this portion of a DRDA (underlined in Figure 1) as the Decision Cue.\nMoreover, the decision cue is generally directly followed by the actual Decision Content (e.g., \u201cbe a little apple\u201d, \u201chave rubber cases\u201d). Decision Content phrases are denoted in Figure 1 via italics and square brackets. Importantly, it is just the decision content portion of the utterance that should be considered for incorporation into the focused summary.\n1These are similar, but not completely equivalent, to the decision dialogue acts (DDAs) of (Bui et al., 2009), (Ferna\u0301ndez et al., 2008), (Frampton et al., 2009).\n2Murray et al. (2010b) show that users much prefer abstractive summaries over extracts when the text to be summarized is a conversation. In particular, extractive summaries drawn from group conversations can be confusing to the reader without additional context; and the noisy, error-prone, disfluent text of speech transcripts is likely to result in extractive summaries with low readability.\nar X\niv :1\n60 6.\n07 84\n9v 1\n[ cs\n.C L\n] 2\n4 Ju\nn 20\nThis paper presents an unsupervised framework for focused meeting summarization that supports the generation of abstractive summaries. (Note that we do not currently generate actual abstracts, but rather aim to identify those Content phrases that should comprise the abstract.) In contrast to existing approaches to focused meeting summarization (e.g., Purver et al. (2007), Ferna\u0301ndez et al. (2008), Bui et al. (2009)), we view the problem as an information extraction task and hypothesize that existing methods for domain-specific relation extraction can be modified to identify salient phrases for use in generating abstractive summaries.\nVery generally, information extraction methods identify a lexical \u201ctrigger\u201d or \u201cindicator\u201d that evokes a relation of interest and then employ syntactic information, often in conjunction with semantic constraints, to find the \u201ctarget phrase\u201d or \u201cargument constituent\u201d to be extracted. Relation instances, then, are represented by indicator-argument pairs (Chen et al., 2011).\nFigure 1 shows some possible indicator-argument pairs for identifying the Decision Content phrases in the dialogue sample. Content indicator words\nare shown in italics; the Decision Content target phrases are the arguments. For example, in the fourth DRDA, \u201crequire\u201d is the indicator, and \u201crubber buttons\u201d and \u201crubber case\u201d are both arguments. Although not shown in Figure 1, it is also possible to identify relations that correspond to the Decision Cue phrases.3\nSpecifically, we focus on the task of decision summarization and, as in previous work in meeting summarization (e.g., Ferna\u0301ndez et al. (2008), Wang and Cardie (2011)), assume that all decision-related utterances (DRDAs) have been identified. We adapt the unsupervised relation learning approach of Chen et al. (2011) to separately identify relations associated with decision cues vs. the decision content within DRDAs by defining a new set of task-specific constraints and features to take the place of the domain-specific constraints and features of the original model. Output of the system is a set of extracted indicator-argument decision content relations (see the \u201cOUR METHOD\u201d sample summary of Table 6) that can be used as the basis of the decision abstract.\nWe evaluate the approach (using the AMI corpus (Carletta et al., 2005)) under two input settings \u2014 in the True Clusterings setting, we assume that the DRDAs for each meeting have been perfectly grouped according to the decision(s) each supports; in the System Clusterings setting, an automated system performs the DRDA-decision pairing. The results show that the relation-based summarization approach outperforms two extractive summarization baselines that select the longest and the most representative utterance for each decision, respectively. (ROUGE-1 F score of 37.47% vs. 32.61% and 33.32% for the baselines given the True Clusterings of DRDAs.) Moreover, our approach performs admirably in comparison to two supervised learning alternatives (scores of 35.61% and 40.87%) that aim to identify the important tokens to include in the decision abstract given the DRDA clusterings. In contrast to our approach which is transferable to different domains or tasks, these methods would require labeled data for retraining for each new meeting corpus.\n3Consider, for example, the phrases underlined in the sixth and seventh DRDAs. \u201cI mean\u201d and \u201cshall we\u201d are two typical Decision Cue phrases where \u201cmean\u201d and \u201cshall\u201d are possible indicators with \u201cI\u201d and \u201cwe\u201d as their arguments, respectively.\nFinally, in order to compare our approach to another relation-based summarization technique, we modify the multi-document summarization system of Hachey (2009) to the single-document meeting scenario. Here again, our proposed approach performs better (37.47% vs. 34.69%). Experiments under the System Clusterings setting produce the same overall results, albeit with lower scores for all of the systems and baselines.\nIn the remainder of the paper, we review related work in Section 2 and give a high-level description of the relation-based approach to focused summarization in Section 3. Sections 4, 5 and 6 present the modifications to the Chen et al. (2011) relation extraction model required for its instantiation for the meeting summarization task. Sections 7 and 8 provide our experimental setup and results."}, {"heading": "2 Related Work", "text": "Most research on spoken dialogue summarization attempts to generate summaries for full dialogues (Carenini et al., 2011). Only recently, however, has the task of focused summarization, and decision summarization, in particular, been addressed. Ferna\u0301ndez et al. (2008) and Bui et al. (2009) employ supervised learning methods to rank phrases or words for inclusion in the decision summary. In comparison, Ferna\u0301ndez et al. (2008) find that the phrase-based approach yields better recall than token-based methods, concluding that phrases have the potential to support better summaries. Input to their system, however, is narrowed down (manually) from the full set of DRDAs to the subset that is useful for summarization. In addition, they evaluate their system w.r.t. informative phrases or words that have been manually annotated within this DRDA subset. We are instead interested in comparing our extracted relations to the abstractive summaries.\nIn contrast to our phrase-based approach, we previously explored a collection of supervised and unsupervised learning methods for utterance-level (i.e., dialogue act) and token-level decision summarization (Wang and Cardie, 2011). We adopt here the two unsupervised baselines (utterance-level summaries) from that work for use in our evaluation. We further employ their supervised summarization methods as comparison points for token-level summarization, adding additional features for consis-\ntency with the other approaches in the evaluation. Murray et al. (2010a) develop an integer linear programming approach for focused summarization at the utterance-level, selecting sentences that cover more of the entities mentioned in the meeting as determined through the use of an external ontology.\nThe most relevant previous work is Hachey (2009), which uses relational representations to facilitate sentence-ranking for multi-document summarization. The method utilizes generic relation extraction to represent the concepts in the documents as relation instances; summaries are generated based on a set cover algorithm that selects a subset of the sentences that best cover the weighted concepts. Thus, the goal of Hachey\u2019s approach is sentence extraction rather than phrase extraction. Although his relation extraction method, like ours (see Section 4), is probabilistic and unsupervised (he uses Latent Dirichelt Allocation (Blei et al., 2003)), the relations are limited to pairs of named-entities, which is not appropriate for our decision summarization setting. Nevertheless, we will adapt his approach for comparison with our relation-based summarization technique and include it for evaluation."}, {"heading": "3 Focused Summarization as Relation Extraction", "text": "Given the DRDAs for each meeting grouped (not necessarily correctly) according to the decisions they support, we put each cluster of DRDAs (ordered according to time within the cluster) into one \u201cdecision document\u201d. The goal will be to produce one decision abstract for each such decision document. We obtain constituent and dependency parses using the Stanford parser (Klein and Manning, 2003; de Marneffe et al., 2006). With the corpus of constituent-parsed decision documents as the input, we will use and modify Chen et al. (2011)\u2019s system to identify decision cue relations and decision content relations for each cluster.4 (Section 6 will make clear how the learned decision cue relations will be used to identify decision content relations.) The salient decision content relation instances will be returned as decision summary com-\n4Other unsupervised relation learning methods might also be appropriate (e.g., Open IE (Banko et al., 2007)), but they generally model relations between pairs of entities and group relations only according to lexical similarity.\nponents. Designed for in-domain relation discovery from standard written texts (e.g., newswire), however, the Chen et al. (2011) system cannot be applied to our task directly. In our setting, for example, neither the number of relations nor the relation types is known in advance.\nIn the following sections, we describe the modifications needed for the spoken meeting genre and decision-focused summarization task. In particular, Chen et al. (2011) provide two mechanisms that allow for this type of tailoring: the feature set used to cluster potential relation instances into groups/types, and a set of global constraints that characterize the general qualities (e.g., syntactic form, prevalence, discourse behavior) of a good relation for the task."}, {"heading": "4 Model", "text": "In this section, we describe the Chen et al. (2011) probabilistic relation learning model used for both Decision Cue and Decision Content relation extraction. The parameter estimation and constraint encoding through posterior inference are presented in Section 5.\nThe relation learning model takes as input clusters of DRDAs, sorted according to utterance time and concatenated into one decision document. We assume one decision will be made per document. The goal for the model is to explain how the decision documents are generated from the latent relation variables. The posterior regularization technique (Section 5) biases inference to adhere to the declarative constraints on relation instances. In general, instead of extracting relation instances strictly satisfying a set of human-written rules, features and constraints are designed to allow the model to reveal diverse relation types and to ensure that the identified relation instances are coherent and meaningful. For each decision document, we select the relation instance with highest probability for each relation type and concatenate them to form the decision summary.\nWe restrict the eligible indicators to be a noun or verb, and eligible arguments to be a noun phrase (NP), prepositional phrase (PP) or clause introduced by \u201cto\u201d (S). Given a pre-specified number of relation types K, the model employs a set of features \u03c6i(w) and \u03c6a(x) (see Section 6) to describe the indicator\nword w and argument constituent x. Each relation type k is associated with a set of feature distributions \u03b8k and a location distribution \u03bbk. \u03b8k include four parameter vectors: \u03b8ik for indicator words, \u03b8 bi k for nonindicator words, \u03b8ak for argument constituents, and \u03b8bak for non-argument constituents. Each decision document is divided into L equal-length segments and the location parameter vector \u03bbk describes the probability of relation k arising from each segment. The plate diagram for the model is shown in Figure 2. The generative process and likelihood of the model are shown in Appendix A."}, {"heading": "5 Parameter Estimation and Inference via Posterior Regularization", "text": "In order to specify global preferences for the relation instances (e.g. the syntactic structure of the expressions), we impose inequality constraints on expectations of the posterior distributions during inference (Graca et al., 2008)."}, {"heading": "5.1 Variational inference with Constraints", "text": "Suppose we are interested in estimating the posterior distribution p(\u03b8, z|x) of a model in general, where \u03b8, z and x are parameters to estimate, latent variables and observations, respectively. We aim to find a distribution q(\u03b8, z) \u2208 Q that minimizes the KLdivergence to the true posterior\nKL(q(\u03b8, z)\u2016p(\u03b8, z|x)) (1)\nA mean-field assumption is made for variational inference, where q(\u03b8, z) = q(\u03b8)q(z). Then we can minimize Equation 1 by performing coordinate descent on q(\u03b8) and q(z). Now we intend to have finelevel control on the posteriors to induce meaningful semantic parts. For instance, we would like most of the extracted relation instances to satisfy a set of predefined syntactic patterns. As presented in (Graca et al., 2008), a general way to put constraints on posterior q is through bounding expectations of given functions: Eq[f(z)] \u2264 b, where f(z) is a deterministic function of z, and b is a pre-specified threshold. For instance, define f(z) as a function to count the number of generated relation instances that meet the pre-defined syntactic patterns, then most of the extracted relation instances will have the desired syntactic structures.\nBy using the mean-field assumption, the model in Section 4 is factorized as\nq(\u03b8, \u03bb, z, i, a) = K\u220f k=1 q(\u03bbk; \u03bb\u0302k)q(\u03b8 i k; \u03b8\u0302 i k)q(\u03b8 bi k ; \u03b8\u0302 bi k )q(\u03b8 a k \u03b8\u0302 a k)q(\u03b8 ba k ; \u03b8\u0302 ba k )\n\u00d7 D\u220f d=1 q(zd,k, id,k, ad,k; c\u0302d,k) (2)\nThe constraints are encoded in the inequalities Eq[f(z, i, a)] \u2265 b or Eq[f(z, i, a)] \u2264 b, and affect the inference as described above. Updates for the parameters are discussed in Appendix B."}, {"heading": "5.2 Task-Specific Constraints.", "text": "We define four types of constraints for the decision relation extraction model.\nSyntactic Constraints. Syntactic constraints are widely used for information extraction (IE) systems (Snow et al., 2005; Banko and Etzioni, 2008), as it has been shown that most relations are expressed via a small number of common syntactic patterns. For each relation type, we require at least 80%5 of the induced relation instances in expectation to match one of the following syntactic patterns:\n\u2022 The indicator is a verb and the argument is a noun phrase. The headword of the argument is the direct object of the indicator or the nominal subject of the indicator.\n5Experiments show that this threshold is suitable for decision relation extraction, so we adopt it from (Chen et al., 2011).\n\u2022 The indicator is a verb and the argument is a prepositional phrase or a clause starting with \u201cto\u201d. The indicator and the argument have the same parent in the constituent parsing tree.\n\u2022 The indicator is a noun and is the headword of a noun phrase, and the argument is a prepositional phrase. The noun phrase with the indicator as its headword and the argument have the same parent in the constituent parsing tree.\nFor relation k, let f(zk, ik, ak) count the number of induced indicator ik and argument ak pairs that match one of the patterns above, and b is set to 0.8D, whereD is the number of decision documents. Then the syntactic constraint is encoded in the inequality Eq[f(zk, ik, ak)] \u2265 b. Prevalence Constraints. The prevalence constraint is enforced on the number of times a relation is instantiated, in order to guarantee that every relation has enough instantiations across the corpus and is task-relevant. Again, we require each relation to have induced instances in at least 80% of decision documents. Occurrence Constraints. Diversity of relation types is enforced through occurrence constraints. In particular, for each decision document, we restrict each word to trigger at most two relation types as indicator and occur at most twice as part of a relation\u2019s argument in expectation. An entire span of argument constituent can appear in at most one relation type. Discourse Constraints. The discourse constraint captures the insight that the final decision on an issue is generally made, or at least restated, at the end of the decision-related discussion. As each decision document is divided into four equal parts, we restrict 50% of the relation instances to be from the last quarter of the decision documents."}, {"heading": "6 Features", "text": "Table 1 lists the features we use for discovering both the decision cue relations and decision content relations. We start with a collection of domainindependent BASIC FEATURES shown to be useful in relation extraction (Banko and Etzioni, 2008; Chen et al., 2011). Then we add MEETING FEATURES, STRUCTURAL FEATURES and SEMANTIC FEATURES that have been found to be good predictors for decision detection (Hsueh and Moore, 2007) or meeting and decision summarization (Gal-\nley, 2006; Murray and Carenini, 2008; Ferna\u0301ndez et al., 2008; Wang and Cardie, 2011). Features employed only for argument\u2019s are listed in the last category in Table 1.\nAfter applying the features in Table 1 and the global constraints from Section 5 in preliminary experiments, we found that the extracted relation instances are mostly derived from decision cue relations. Sample decision cue relations and instances are displayed in Table 2 and are not necessarily surprising: previous research (Hsueh and Moore, 2007) has observed the important role of personal pronouns, such as \u201cwe\u201d and \u201cI\u201d, in decision-making expressions. Notably, the decision cue is always followed by the decision content. As a result, we include two additional features (see Table 3) that rely on the cues to identify the decision content. Finally, we disallow content relation instances with an argument containing just a personal pronoun."}, {"heading": "7 Experiment Setup", "text": "The Corpus. We evaluate our approach on the AMI meeting corpus (Carletta et al., 2005) that consists of 140 multi-party meetings with a wide range\nof annotations. The 129 scenario-driven meetings involve four participants playing different roles on a design team. Importantly, the corpus includes a short (usually one-sentence), manually constructed abstract summarizing each decision discussed in the meeting. In addition, all of the dialogue acts that support (i.e., are relevant to) each decision are annotated as such. We use the manually constructed decision abstracts as gold-standard summaries. System Inputs. We consider two system input settings. In the True Clusterings setting, we use the AMI annotations to create perfect partitionings of the DRDAs for input to the summarization system; in the System Clusterings setting, we employ a hierarchical agglomerative clustering algorithm used for this task in previous work (Wang and Cardie, 2011). The Wang and Cardie (2011) clustering method groups DRDAs according to their LDA topic distribution similarity. As better approaches for DRDA clustering become available, they could be employed instead. Evaluation Metrics. We use the widely accepted ROUGE (Lin and Hovy, 2003) evaluation measure. We adopt the ROUGE-1 and ROUGE-SU4 metrics from (Hachey, 2009), and also use ROUGE2. We choose the stemming option of the ROUGE software at http://berouge.com/ and remove stopwords from both the system and gold-standard summaries. Training and Parameters. The Dirichlet hyperparameters are set to 0.1 for the priors. When training the model, ten random restarts are performed and each run stops when reaching a convergence threshold (10\u22125). Then we select the posterior with\nthe lowest final free energy. For the parameters used in posterior constraints, we either adopt them from (Chen et al., 2011) or choose them arbitrarily without tuning in the spirit of making the approach domain-independent.\nWe compare our decision summarization approach with (1) two unsupervised baselines, (2) the unsupervised relation-based approach of Hachey (2009), (3) two supervised methods, and (4) an upperbound derived from the gold standard decision abstracts.\nThe LONGEST DA Baseline. As in Riedhammer et al. (2010) and Wang and Cardie (2011), this baseline simply selects the longest DRDA in each cluster as the summary. Thus, this baseline performs utterance-level decision summarization. Although it\u2019s possible that decision content is spread over multiple DRDAs in the cluster, this baseline and the next allow us to determine summary quality when summaries are restricted to a single utterance.\nThe PROTOTYPE DA Baseline. Following Wang and Cardie (2011), the second baseline selects the decision cluster prototype (i.e., the DRDA with the largest TF-IDF similarity with the cluster centroid) as the summary.\nThe Generic Relation Extraction (GRE) Method of Hachey (2009). Hachey (2009) presents a generic relation extraction (GRE) for multidocument summarization. Informative sentences are extracted to form summaries instead of relation instances. Relation types are discovered by Latent Dirichlet Allocation, such that a probability is output for each relation instance given a topic (equivalent to relation). Their relation instances are named entity(NE)-mention pairs conforming to a set of pre-specified rules. For comparison, we use these same rules to select noun-mention pairs rather than NE-mention pairs, which is better suited to meetings, which do not contain many NEs.6\n6Because an approximate set cover algorithm is used in GRE, one decision-related dialogue act (DRDA) is extracted each time until the summary reaches the desired length. We run two sets of experiments using this GRE system with different output summaries \u2014 one selects one entire DRDA as the final summary (as Hachey (2009) does), and another one outputs the relation instances with highest probability conditional on each relation type. We find that the first set of experiments gets better\nSupervised Learning (SVMs and CRFs). We also compare our approach to two supervised learning methods \u2014 Support Vector Machines (Joachims, 1998) with RBF kernel and order-1 Conditional Random Fields (Lafferty et al., 2001) \u2014 trained using the same features as our system (see Tables 1 and 3) to identify the important tokens to include in the decision abstract. Three-fold cross validation is conducted for both methods. Upperbound. We also compute an upperbound that reflects the gap between the best possible extractive summaries and the human-written abstracts according to the ROUGE score: for each cluster of DRDAs, we select the words that also appear in the associated decision abstract."}, {"heading": "8 Results and Discussion", "text": "Table 4 illustrates that, using True (DRDA) Clusterings our method outperforms the two baselines and the generic relation extraction (GRE) based system in terms of F score in ROUGE-1 and ROUGESU4 with varied numbers of relations. Note that for GRE based approach, we only list out their best results for utterance-level summarization. If using the salient relation instances identified by GRE as the summaries, the ROUGE results will be significantly\nperformance than the second, so we only report the best results for their system in this paper.\nlower. When measured by ROUGE-2, our method still have better or comparable performances than other unsupervised methods. Moreover, our system achieves F scores in between those of the supervised learning methods, performing better than the CRF in both recall and F score. The recall score for the upperbound in ROUGE-1, on the other hand, indicates that there is still a wide gap between the extractive summaries and human-written abstracts: without additional lexical information (e.g., semantic class information, ontologies) or a real language generation component, recall appears to be a bottleneck for extractive summarization methods that select content only from decision-related dialogue acts (DRDAs).\nResults using the System Clusterings (Table 5) are comparable, although all of the system and baseline scores are much lower. Supervised methods get the best F scores largely due to their high precision; but our method attains the best recall in ROUGE-1.\nDiscussion. To better exemplify the summaries generated by different systems, sample output for each method is shown in Table 6. The GRE system uses an approximate algorithm for set cover extraction, we list the first three selected DRDA in order. We see from the table that utterance-level extractive summaries (Longest DA, Prototype DA, GRE) make more coherent but still far from concise and compact\nabstracts. On the other hand, the supervised methods (SVM, CRF) that produce token-level extracts better identify the overall content of the decision abstract. Unfortunately, they require human annotation in the training phase; in addition, the output is ungrammatical and lacks coherence. In comparison, our system presents the decision summary in the form of phrase-based relations that provide a relatively comprehensive expression."}, {"heading": "9 Conclusions", "text": "We present a novel framework for focused meeting summarization based on unsupervised relation extraction. Our approach is shown to outperform unsupervised utterance-level extractive summarization baselines as well as an existing generic relationextraction-based summarization method. Our approach also produces summaries competitive with those generated by supervised methods in terms of the standard ROUGE score. Overall, we find that relation-based methods for focused summarization have potential as a technique for supporting the generation of abstractive decision summaries. Acknowledgments This work was supported in part by National Science Foundation Grants IIS-0968450 and IIS-1111176, and by a gift from Google."}, {"heading": "Appendix A Generative Process", "text": "The entire generative process is as follows (\u201cDir\u201d and \u201cMult\u201d refer to the Dirichlet distribution and multinomial distribution):\n1. For each relation type k: (a) For each indicator feature \u03c6i, draw feature distribu-\ntions \u03b8ik,\u03c6i , \u03b8 bi k,\u03c6i \u223c Dir(\u03b80)\n(b) For each argument feature \u03c6a, draw feature distributions \u03b8ak,\u03c6a , \u03b8 ba k,\u03c6a \u223c Dir(\u03b80)\n(c) Draw location distribution \u03bbk \u223c Dir(\u03bb0) 2. For each relation type k and decision document d:\n(a) Select decision document segment sd,k \u223c Mult(\u03bbk)\n(b) Select DRDA zd,k uniformly from segment sd,k, and indicator id,k and argument constituent ad,k uniformly from DRDA zd,k 3. For each indicator word w in every decision document d: (a) For each indicator feature \u03c6i(w) \u223c\nMult( 1 Z \u03a0Kk=1\u03b8k,\u03c6i), where \u03b8k,\u03c6i is \u03b8 i k,\u03c6i if id,k = w and \u03b8bik,\u03c6i otherwise. Z is the normalization factor.\n4. For each argument constituent x in every decision document d:\n(a) For each indicator feature \u03c6a(x) \u223c Mult( 1\nZ \u03a0Kk=1\u03b8k,\u03c6a), where \u03b8k,\u03c6a is \u03b8 a k,\u03c6a\nif ad,k = x and \u03b8bak,\u03c6a otherwise. Z is the normalization factor.\nGiven \u03b80 and \u03bb0, The joint distribution of a set of feature parameters \u03b8, the location distributions \u03bb, a set of DRDAs z, and the selected indicators i and arguments a is:\nP (\u03b8, \u03bb, z, i, a; \u03b80, \u03bb0) = K\u220f k=1 P (\u03b8ik; \u03b80)P (\u03b8 bi k ; \u03b80)P (\u03b8 a k |\u03b80)P (\u03b8bak ; \u03b80)P (\u03bbk;\u03bb0)\n\u00d7 ( D\u220f d=1 P (id,k; zd,k)P (ad,k; zd,k)P (zd,k; sd,k)P (sd,k;\u03bbk)\n\u00d7 (P (w = id,k; \u03b8ik) \u220f\nw 6=id,k\nP (w; \u03b8bik ))\n\u00d7 (P (x = ad,k; \u03b8ak) \u220f\nx 6=ad,k\nP (x; \u03b8bak )))"}, {"heading": "Appendix B Updates for the Parameters", "text": "The constraints put on the posterior will only affect the update for q(z). For q(\u03b8), the update is\nq(\u03b8) = argmin q(\u03b8)\nKL(q(\u03b8)\u2016q\u2032(\u03b8)), (3)\nwhere q\u2032(\u03b8) \u221d expEq(z)[log p(\u03b8, z, x)], and q(\u03b8) is updated to q\u2032(\u03b8). For q(z), the update is\nq(z) = argmin q(z)\nKL(q(z)\u2016q\u2032(z))\ns.t. Eq(z)[fc(z)] \u2264 bc, \u2200c \u2208 C (4)\nwhere q\u2032(z) \u221d expEq(\u03b8)[log p(\u03b8, z, x)]. Equation 4 is easily solved via the dual (Graca et al., 2008) (Chen et al., 2011)."}], "references": [{"title": "The Tradeoffs Between Open and Traditional Relation Extraction", "author": ["Michele Banko", "Oren Etzioni."], "venue": "Proceedings of ACL-08: HLT, Columbus, Ohio.", "citeRegEx": "Banko and Etzioni.,? 2008", "shortCiteRegEx": "Banko and Etzioni.", "year": 2008}, {"title": "Open information extraction from the web", "author": ["Michele Banko", "Michael J Cafarella", "Stephen Soderl", "Matt Broadhead", "Oren Etzioni."], "venue": "In IJCAI, pages 2670\u20132676.", "citeRegEx": "Banko et al\\.,? 2007", "shortCiteRegEx": "Banko et al\\.", "year": 2007}, {"title": "Latent dirichlet allocation", "author": ["David M. Blei", "Andrew Y. Ng", "Michael I. Jordan."], "venue": "J. Mach. Learn. Res., 3:993\u20131022, March.", "citeRegEx": "Blei et al\\.,? 2003", "shortCiteRegEx": "Blei et al\\.", "year": 2003}, {"title": "Extracting decisions from multi-party dialogue using directed graphical models and semantic similarity", "author": ["Trung H. Bui", "Matthew Frampton", "John Dowding", "Stanley Peters."], "venue": "Proceedings of the SIGDIAL 2009 Conference, pages 235\u2013243.", "citeRegEx": "Bui et al\\.,? 2009", "shortCiteRegEx": "Bui et al\\.", "year": 2009}, {"title": "Methods for Mining and Summarizing Text Conversations", "author": ["Giuseppe Carenini", "Gabriel Murray", "Raymond Ng."], "venue": "Morgan & Claypool Publishers.", "citeRegEx": "Carenini et al\\.,? 2011", "shortCiteRegEx": "Carenini et al\\.", "year": 2011}, {"title": "In-domain relation discovery with meta-constraints via posterior regularization", "author": ["Harr Chen", "Edward Benson", "Tahira Naseem", "Regina Barzilay."], "venue": "Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language", "citeRegEx": "Chen et al\\.,? 2011", "shortCiteRegEx": "Chen et al\\.", "year": 2011}, {"title": "Generating typed dependency parses from phrase structure trees", "author": ["Marie-Catherine de Marneffe", "Bill MacCartney", "Christopher D. Manning."], "venue": "LREC.", "citeRegEx": "Marneffe et al\\.,? 2006", "shortCiteRegEx": "Marneffe et al\\.", "year": 2006}, {"title": "Identifying relevant phrases to summarize decisions in spoken meetings", "author": ["Raquel Fern\u00e1ndez", "Matthew Frampton", "John Dowding", "Anish Adukuzhiyil", "Patrick Ehlen", "Stanley Peters."], "venue": "INTERSPEECH-2008, pages 78\u201381.", "citeRegEx": "Fern\u00e1ndez et al\\.,? 2008", "shortCiteRegEx": "Fern\u00e1ndez et al\\.", "year": 2008}, {"title": "Real-time decision detection in multi-party dialogue", "author": ["Matthew Frampton", "Jia Huang", "Trung Huu Bui", "Stanley Peters."], "venue": "Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing: Volume 3 - Volume 3, pages 1133\u20131141.", "citeRegEx": "Frampton et al\\.,? 2009", "shortCiteRegEx": "Frampton et al\\.", "year": 2009}, {"title": "A skip-chain conditional random field for ranking meeting utterances by importance", "author": ["Michel Galley."], "venue": "Proceedings of the 2006 Conference on Empirical Methods in Natural Language Processing, pages 364\u2013 372.", "citeRegEx": "Galley.,? 2006", "shortCiteRegEx": "Galley.", "year": 2006}, {"title": "Expectation maximization and posterior constraints", "author": ["Joao Graca", "Kuzman Ganchev", "Ben Taskar."], "venue": "J.C. Platt, D. Koller, Y. Singer, and S. Roweis, editors, Advances in Neural Information Processing Systems 20, pages 569\u2013576. MIT Press, Cambridge, MA.", "citeRegEx": "Graca et al\\.,? 2008", "shortCiteRegEx": "Graca et al\\.", "year": 2008}, {"title": "Multi-document summarisation using generic relation extraction", "author": ["Ben Hachey."], "venue": "Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing: Volume 1 - Volume 1, EMNLP \u201909, pages 420\u2013429, Stroudsburg, PA, USA. Associa-", "citeRegEx": "Hachey.,? 2009", "shortCiteRegEx": "Hachey.", "year": 2009}, {"title": "What decisions have you made: Automatic decision detection in conversational speech", "author": ["Pei-yun Hsueh", "Johanna Moore."], "venue": "In NAACL/HLT 2007.", "citeRegEx": "Hsueh and Moore.,? 2007", "shortCiteRegEx": "Hsueh and Moore.", "year": 2007}, {"title": "Text categorization with Support Vector Machines: Learning with many relevant features", "author": ["Thorsten Joachims."], "venue": "Claire N\u00e9dellec and C\u00e9line Rouveirol, editors, Machine Learning: ECML-98, volume 1398, chapter 19, pages 137\u2013142. Berlin/Heidelberg.", "citeRegEx": "Joachims.,? 1998", "shortCiteRegEx": "Joachims.", "year": 1998}, {"title": "Accurate unlexicalized parsing", "author": ["Dan Klein", "Christopher D. Manning."], "venue": "Proceedings of the 41st Annual Meeting on Association for Computational Linguistics - Volume 1, ACL \u201903, pages 423\u2013430, Stroudsburg, PA, USA. Association for Computational Lin-", "citeRegEx": "Klein and Manning.,? 2003", "shortCiteRegEx": "Klein and Manning.", "year": 2003}, {"title": "Conditional random fields: Probabilistic models for segmenting and labeling sequence data", "author": ["John D. Lafferty", "Andrew McCallum", "Fernando C.N. Pereira."], "venue": "Proceedings of the Eighteenth International Conference on Machine Learning, ICML \u201901, pages", "citeRegEx": "Lafferty et al\\.,? 2001", "shortCiteRegEx": "Lafferty et al\\.", "year": 2001}, {"title": "A risk minimization framework for extractive speech summarization", "author": ["Shih-Hsiang Lin", "Berlin Chen."], "venue": "Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, ACL \u201910, pages 79\u201387, Stroudsburg, PA, USA. Association for", "citeRegEx": "Lin and Chen.,? 2010", "shortCiteRegEx": "Lin and Chen.", "year": 2010}, {"title": "Automatic evaluation of summaries using n-gram co-occurrence statistics", "author": ["Chin-Yew Lin", "Eduard Hovy."], "venue": "Proceedings of the 2003 Conference of the North American Chapter of the Association for Computational Linguistics on Human Language Technol-", "citeRegEx": "Lin and Hovy.,? 2003", "shortCiteRegEx": "Lin and Hovy.", "year": 2003}, {"title": "Comparing Lexical, Acoustic/Prosodic, Structural and Discourse Features for Speech Summarization", "author": ["Sameer Maskey", "Julia Hirschberg."], "venue": "Proc. European Conference on Speech Communication and Technology (Eurospeech).", "citeRegEx": "Maskey and Hirschberg.,? 2005", "shortCiteRegEx": "Maskey and Hirschberg.", "year": 2005}, {"title": "Wordnet: a lexical database for english", "author": ["George A. Miller."], "venue": "Commun. ACM, 38:39\u201341, November.", "citeRegEx": "Miller.,? 1995", "shortCiteRegEx": "Miller.", "year": 1995}, {"title": "Summarizing spoken and written conversations", "author": ["Gabriel Murray", "Giuseppe Carenini."], "venue": "Proceed-", "citeRegEx": "Murray and Carenini.,? 2008", "shortCiteRegEx": "Murray and Carenini.", "year": 2008}, {"title": "Interpretation and transformation for abstracting conversations", "author": ["Gabriel Murray", "Giuseppe Carenini", "Raymond Ng."], "venue": "Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguis-", "citeRegEx": "Murray et al\\.,? 2010a", "shortCiteRegEx": "Murray et al\\.", "year": 2010}, {"title": "Generating and validating abstracts of meeting conversations: a user study", "author": ["Gabriel Murray", "Giuseppe Carenini", "Raymond T. Ng."], "venue": "INLG\u201910.", "citeRegEx": "Murray et al\\.,? 2010b", "shortCiteRegEx": "Murray et al\\.", "year": 2010}, {"title": "Detecting and summarizing action items in multi-party dialogue", "author": ["Matthew Purver", "John Dowding", "John Niekrasz", "Patrick Ehlen", "Sharareh Noorbaloochi", "Stanley Peters."], "venue": "in Proceedings of the 8th SIGdial Workshop on Discourse and Dialogue.", "citeRegEx": "Purver et al\\.,? 2007", "shortCiteRegEx": "Purver et al\\.", "year": 2007}, {"title": "Long story short - global unsupervised models for keyphrase based meeting summarization", "author": ["Korbinian Riedhammer", "Benoit Favre", "Dilek Hakkani-T\u00fcr."], "venue": "Speech Commun., 52(10):801\u2013815, October.", "citeRegEx": "Riedhammer et al\\.,? 2010", "shortCiteRegEx": "Riedhammer et al\\.", "year": 2010}, {"title": "Opening up closings", "author": ["E.A. Schegloff", "H. Sacks."], "venue": "Semiotica, 8(4):289\u2013327.", "citeRegEx": "Schegloff and Sacks.,? 1973", "shortCiteRegEx": "Schegloff and Sacks.", "year": 1973}, {"title": "Learning Syntactic Patterns for Automatic Hypernym Discovery", "author": ["Rion Snow", "Daniel Jurafsky", "Andrew Y. Ng."], "venue": "Lawrence K. Saul, Yair Weiss, and L\u00e9on Bottou, editors, Advances in Neural Information Processing Systems 17, pages 1297\u20131304. MIT Press,", "citeRegEx": "Snow et al\\.,? 2005", "shortCiteRegEx": "Snow et al\\.", "year": 2005}, {"title": "Summarizing decisions in spoken meetings", "author": ["Lu Wang", "Claire Cardie."], "venue": "Proceedings of the Workshop on Automatic Summarization for Different Genres, Media, and Languages, pages 16\u201324, Portland, Oregon, June. Association for Computational Linguis-", "citeRegEx": "Wang and Cardie.,? 2011", "shortCiteRegEx": "Wang and Cardie.", "year": 2011}, {"title": "Automatic summarization of open-domain multiparty dialogues in diverse genres", "author": ["Klaus Zechner."], "venue": "Comput. Linguist., 28:447\u2013485, December.", "citeRegEx": "Zechner.,? 2002", "shortCiteRegEx": "Zechner.", "year": 2002}], "referenceMentions": [{"referenceID": 5, "context": "We adapt an existing in-domain relation learner (Chen et al., 2011) by exploiting a set of task-specific constraints and features.", "startOffset": 48, "endOffset": 67}, {"referenceID": 4, "context": ", generating summaries of a particular aspect of a meeting rather than of the meeting as a whole (Carenini et al., 2011).", "startOffset": 97, "endOffset": 120}, {"referenceID": 22, "context": ", Zechner (2002), Maskey and Hirschberg (2005), Galley (2006), Lin and Chen (2010), Murray et al.", "startOffset": 2, "endOffset": 17}, {"referenceID": 15, "context": ", Zechner (2002), Maskey and Hirschberg (2005), Galley (2006), Lin and Chen (2010), Murray et al.", "startOffset": 18, "endOffset": 47}, {"referenceID": 8, "context": ", Zechner (2002), Maskey and Hirschberg (2005), Galley (2006), Lin and Chen (2010), Murray et al.", "startOffset": 48, "endOffset": 62}, {"referenceID": 8, "context": ", Zechner (2002), Maskey and Hirschberg (2005), Galley (2006), Lin and Chen (2010), Murray et al.", "startOffset": 48, "endOffset": 83}, {"referenceID": 8, "context": ", Zechner (2002), Maskey and Hirschberg (2005), Galley (2006), Lin and Chen (2010), Murray et al. (2010a)).", "startOffset": 48, "endOffset": 106}, {"referenceID": 3, "context": "These are similar, but not completely equivalent, to the decision dialogue acts (DDAs) of (Bui et al., 2009), (Fern\u00e1ndez et al.", "startOffset": 90, "endOffset": 108}, {"referenceID": 7, "context": ", 2009), (Fern\u00e1ndez et al., 2008), (Frampton et al.", "startOffset": 9, "endOffset": 33}, {"referenceID": 8, "context": ", 2008), (Frampton et al., 2009).", "startOffset": 9, "endOffset": 32}, {"referenceID": 3, "context": "These are similar, but not completely equivalent, to the decision dialogue acts (DDAs) of (Bui et al., 2009), (Fern\u00e1ndez et al., 2008), (Frampton et al., 2009). Murray et al. (2010b) show that users much prefer abstractive summaries over extracts when the text to be summarized is a conversation.", "startOffset": 91, "endOffset": 183}, {"referenceID": 6, "context": "(2007), Fern\u00e1ndez et al. (2008), Bui et al.", "startOffset": 8, "endOffset": 32}, {"referenceID": 3, "context": "(2008), Bui et al. (2009)), we view the problem as an information extraction task and hypothesize that existing meth-", "startOffset": 8, "endOffset": 26}, {"referenceID": 5, "context": "Relation instances, then, are represented by indicator-argument pairs (Chen et al., 2011).", "startOffset": 70, "endOffset": 89}, {"referenceID": 6, "context": ", Fern\u00e1ndez et al. (2008), Wang and Cardie (2011)), assume that all decision-related utterances (DRDAs) have been identified.", "startOffset": 2, "endOffset": 26}, {"referenceID": 6, "context": ", Fern\u00e1ndez et al. (2008), Wang and Cardie (2011)), assume that all decision-related utterances (DRDAs) have been identified.", "startOffset": 2, "endOffset": 50}, {"referenceID": 5, "context": "We adapt the unsupervised relation learning approach of Chen et al. (2011) to separately identify relations asso-", "startOffset": 56, "endOffset": 75}, {"referenceID": 11, "context": "Finally, in order to compare our approach to another relation-based summarization technique, we modify the multi-document summarization system of Hachey (2009) to the single-document meeting scenario.", "startOffset": 146, "endOffset": 160}, {"referenceID": 5, "context": "Sections 4, 5 and 6 present the modifications to the Chen et al. (2011) relation extraction model required for its instantiation for the meeting summarization task.", "startOffset": 53, "endOffset": 72}, {"referenceID": 4, "context": "logues (Carenini et al., 2011).", "startOffset": 7, "endOffset": 30}, {"referenceID": 3, "context": "logues (Carenini et al., 2011). Only recently, however, has the task of focused summarization, and decision summarization, in particular, been addressed. Fern\u00e1ndez et al. (2008) and Bui et al.", "startOffset": 8, "endOffset": 178}, {"referenceID": 3, "context": "(2008) and Bui et al. (2009) employ supervised learning methods to rank phrases", "startOffset": 11, "endOffset": 29}, {"referenceID": 7, "context": "In comparison, Fern\u00e1ndez et al. (2008) find that the phrase-based approach yields better recall than token-based methods, concluding that phrases have the potential to support better summaries.", "startOffset": 15, "endOffset": 39}, {"referenceID": 27, "context": ", dialogue act) and token-level decision summarization (Wang and Cardie, 2011).", "startOffset": 55, "endOffset": 78}, {"referenceID": 21, "context": "Murray et al. (2010a) develop an integer linear programming approach for focused summarization at the utterance-level, selecting sentences that cover more of the entities mentioned in the meeting as determined through the use of an external ontology.", "startOffset": 0, "endOffset": 22}, {"referenceID": 11, "context": "The most relevant previous work is Hachey (2009), which uses relational representations to facilitate sentence-ranking for multi-document summarization.", "startOffset": 35, "endOffset": 49}, {"referenceID": 2, "context": "Although his relation extraction method, like ours (see Section 4), is probabilistic and unsupervised (he uses Latent Dirichelt Allocation (Blei et al., 2003)), the relations", "startOffset": 139, "endOffset": 158}, {"referenceID": 14, "context": "We obtain constituent and dependency parses using the Stanford parser (Klein and Manning, 2003; de Marneffe et al., 2006).", "startOffset": 70, "endOffset": 121}, {"referenceID": 5, "context": "With the corpus of constituent-parsed decision documents as the input, we will use and modify Chen et al. (2011)\u2019s system to identify decision cue relations and decision content relations for each cluster.", "startOffset": 94, "endOffset": 113}, {"referenceID": 1, "context": ", Open IE (Banko et al., 2007)), but they generally model relations between pairs of entities and group relations only according to lexical similarity.", "startOffset": 10, "endOffset": 30}, {"referenceID": 5, "context": ", newswire), however, the Chen et al. (2011) system cannot be applied to our task directly.", "startOffset": 26, "endOffset": 45}, {"referenceID": 5, "context": "In particular, Chen et al. (2011) provide two mechanisms that allow for this type of tailoring: the feature set used to cluster potential relation instances into groups/types, and a set of global constraints that characterize the general qualities (e.", "startOffset": 15, "endOffset": 34}, {"referenceID": 5, "context": "In this section, we describe the Chen et al. (2011) probabilistic relation learning model used for both Decision Cue and Decision Content relation extrac-", "startOffset": 33, "endOffset": 52}, {"referenceID": 10, "context": "the syntactic structure of the expressions), we impose inequality constraints on expectations of the posterior distributions during inference (Graca et al., 2008).", "startOffset": 142, "endOffset": 162}, {"referenceID": 10, "context": "As presented in (Graca et al., 2008), a general way to put constraints on posterior q is through bounding expectations of given functions: Eq[f(z)] \u2264 b, where f(z) is a deterministic function of z, and b is a pre-specified threshold.", "startOffset": 16, "endOffset": 36}, {"referenceID": 26, "context": "Syntactic constraints are widely used for information extraction (IE) systems (Snow et al., 2005; Banko and Etzioni, 2008), as it has been shown that most relations are expressed via a small number of common syntactic patterns.", "startOffset": 78, "endOffset": 122}, {"referenceID": 0, "context": "Syntactic constraints are widely used for information extraction (IE) systems (Snow et al., 2005; Banko and Etzioni, 2008), as it has been shown that most relations are expressed via a small number of common syntactic patterns.", "startOffset": 78, "endOffset": 122}, {"referenceID": 5, "context": "Experiments show that this threshold is suitable for decision relation extraction, so we adopt it from (Chen et al., 2011).", "startOffset": 103, "endOffset": 122}, {"referenceID": 0, "context": "We start with a collection of domainindependent BASIC FEATURES shown to be useful in relation extraction (Banko and Etzioni, 2008; Chen et al., 2011).", "startOffset": 105, "endOffset": 149}, {"referenceID": 5, "context": "We start with a collection of domainindependent BASIC FEATURES shown to be useful in relation extraction (Banko and Etzioni, 2008; Chen et al., 2011).", "startOffset": 105, "endOffset": 149}, {"referenceID": 12, "context": "Then we add MEETING FEATURES, STRUCTURAL FEATURES and SEMANTIC FEATURES that have been found to be good predictors for decision detection (Hsueh and Moore, 2007) or meeting and decision summarization (Gal-", "startOffset": 138, "endOffset": 161}, {"referenceID": 9, "context": "Basic Features unigram (stemmed) part-of-speech (POS) constituent label (NP, VP, S/SBAR (start with \u201cto\u201d)) dependency label Meeting Features Dialogue Act (DA) type speaker role topic Structural Features (Galley, 2006) (Wang and Cardie, 2011) in an Adjacency Pair (AP)? if in an AP, AP type if in an AP, the other part is decision-related? if in an AP, the source part or target part? if in an AP and is source part, is the target positive feedback? if in an AP and is target part, is the source a question? Semantic Features (from WordNet) (Miller, 1995) first Synset of head word with the given POS first hypernym path for the first synset of head word Other Features (only for Argument) number of words (without stopwords) has capitalized word or not has proper noun or not", "startOffset": 203, "endOffset": 217}, {"referenceID": 27, "context": "Basic Features unigram (stemmed) part-of-speech (POS) constituent label (NP, VP, S/SBAR (start with \u201cto\u201d)) dependency label Meeting Features Dialogue Act (DA) type speaker role topic Structural Features (Galley, 2006) (Wang and Cardie, 2011) in an Adjacency Pair (AP)? if in an AP, AP type if in an AP, the other part is decision-related? if in an AP, the source part or target part? if in an AP and is source part, is the target positive feedback? if in an AP and is target part, is the source a question? Semantic Features (from WordNet) (Miller, 1995) first Synset of head word with the given POS first hypernym path for the first synset of head word Other Features (only for Argument) number of words (without stopwords) has capitalized word or not has proper noun or not", "startOffset": 218, "endOffset": 241}, {"referenceID": 19, "context": "Basic Features unigram (stemmed) part-of-speech (POS) constituent label (NP, VP, S/SBAR (start with \u201cto\u201d)) dependency label Meeting Features Dialogue Act (DA) type speaker role topic Structural Features (Galley, 2006) (Wang and Cardie, 2011) in an Adjacency Pair (AP)? if in an AP, AP type if in an AP, the other part is decision-related? if in an AP, the source part or target part? if in an AP and is source part, is the target positive feedback? if in an AP and is target part, is the source a question? Semantic Features (from WordNet) (Miller, 1995) first Synset of head word with the given POS first hypernym path for the first synset of head word Other Features (only for Argument) number of words (without stopwords) has capitalized word or not has proper noun or not", "startOffset": 540, "endOffset": 554}, {"referenceID": 12, "context": "are displayed in Table 2 and are not necessarily surprising: previous research (Hsueh and Moore, 2007) has observed the important role of personal pronouns, such as \u201cwe\u201d and \u201cI\u201d, in decision-making expressions.", "startOffset": 79, "endOffset": 102}, {"referenceID": 27, "context": "of the DRDAs for input to the summarization system; in the System Clusterings setting, we employ a hierarchical agglomerative clustering algorithm used for this task in previous work (Wang and Cardie, 2011).", "startOffset": 183, "endOffset": 206}, {"referenceID": 27, "context": "of the DRDAs for input to the summarization system; in the System Clusterings setting, we employ a hierarchical agglomerative clustering algorithm used for this task in previous work (Wang and Cardie, 2011). The Wang and Cardie (2011) cluster-", "startOffset": 184, "endOffset": 235}, {"referenceID": 17, "context": "We use the widely accepted ROUGE (Lin and Hovy, 2003) evaluation measure.", "startOffset": 33, "endOffset": 53}, {"referenceID": 11, "context": "We adopt the ROUGE-1 and ROUGE-SU4 metrics from (Hachey, 2009), and also use ROUGE2.", "startOffset": 48, "endOffset": 62}, {"referenceID": 5, "context": "For the parameters used in posterior constraints, we either adopt them from (Chen et al., 2011) or choose them arbitrarily without tuning in the spirit of making the approach domain-independent.", "startOffset": 76, "endOffset": 95}, {"referenceID": 11, "context": "We compare our decision summarization approach with (1) two unsupervised baselines, (2) the unsupervised relation-based approach of Hachey (2009), (3) two supervised methods, and (4) an upperbound derived from the gold standard decision abstracts.", "startOffset": 132, "endOffset": 146}, {"referenceID": 24, "context": "As in Riedhammer et al. (2010) and Wang and Cardie (2011), this baseline simply selects the longest DRDA in each clus-", "startOffset": 6, "endOffset": 31}, {"referenceID": 24, "context": "As in Riedhammer et al. (2010) and Wang and Cardie (2011), this baseline simply selects the longest DRDA in each clus-", "startOffset": 6, "endOffset": 58}, {"referenceID": 11, "context": "The Generic Relation Extraction (GRE) Method of Hachey (2009). Hachey (2009) presents a generic relation extraction (GRE) for multi-", "startOffset": 48, "endOffset": 62}, {"referenceID": 11, "context": "The Generic Relation Extraction (GRE) Method of Hachey (2009). Hachey (2009) presents a generic relation extraction (GRE) for multi-", "startOffset": 48, "endOffset": 77}, {"referenceID": 11, "context": "We run two sets of experiments using this GRE system with different output summaries \u2014 one selects one entire DRDA as the final summary (as Hachey (2009) does), and another one outputs the relation instances with highest probability conditional on each relation type.", "startOffset": 140, "endOffset": 154}, {"referenceID": 11, "context": "Table 4: ROUGE-1 (R-1), ROUGE-2 (R-2) and ROUGESU4 (R-SU4) scores for summaries produced by the baselines, GRE (Hachey, 2009)\u2019s best results, the supervised methods, our method and an upperbound \u2014 all with perfect/true DRDA clusterings.", "startOffset": 111, "endOffset": 125}, {"referenceID": 13, "context": "We also compare our approach to two supervised learning methods \u2014 Support Vector Machines (Joachims, 1998) with RBF kernel and order-1 Conditional", "startOffset": 90, "endOffset": 106}, {"referenceID": 15, "context": "Random Fields (Lafferty et al., 2001) \u2014 trained using the same features as our system (see Tables 1 and 3) to identify the important tokens to include in the decision abstract.", "startOffset": 14, "endOffset": 37}, {"referenceID": 11, "context": "Table 5: ROUGE-1 (R-1), ROUGE-2 (R-2) and ROUGESU4 (R-SU4) scores for summaries produced by the baselines, GRE (Hachey, 2009)\u2019s best results, the supervised methods and our method \u2014 all with system clusterings.", "startOffset": 111, "endOffset": 125}], "year": 2016, "abstractText": "We present a novel unsupervised framework for focused meeting summarization that views the problem as an instance of relation extraction. We adapt an existing in-domain relation learner (Chen et al., 2011) by exploiting a set of task-specific constraints and features. We evaluate the approach on a decision summarization task and show that it outperforms unsupervised utterance-level extractive summarization baselines as well as an existing generic relation-extraction-based summarization method. Moreover, our approach produces summaries competitive with those generated by supervised methods in terms of the standard ROUGE score.", "creator": "TeX"}}}