{"id": "1606.08130", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "27-Jun-2016", "title": "Propagators and Solvers for the Algebra of Modular Systems", "abstract": "Solving complex problems can involve non-trivial combinations of distinct knowledge bases and problem solvers. The Algebra of Modular Systems is a knowledge representation framework that provides a method for formally specifying such systems in purely semantic terms. Formally, an expression of the algebra defines a class of structures. Many expressive formalism used in practice solve the model expansion task, where a structure is given on the input and an expansion of this structure in the defined class of structures is searched (this practice overcomes the common undecidability problem for expressive logics). In this paper, we construct a solver for the model expansion task for a complex modular systems from an expression in the algebra and black-box propagators or solvers for the primitive modules. To this end, we define a general notion of propagators equipped with an explanation mechanism, an extension of the alge- bra to propagators, and a lazy conflict-driven learning algorithm. The result is a framework for seamlessly combining solving technology from different domains to produce a solver for a combined system.", "histories": [["v1", "Mon, 27 Jun 2016 05:53:57 GMT  (57kb)", "http://arxiv.org/abs/1606.08130v1", null], ["v2", "Mon, 3 Apr 2017 07:50:50 GMT  (881kb)", "http://arxiv.org/abs/1606.08130v2", "To appear in the proceedings of LPAR 21"]], "reviews": [], "SUBJECTS": "cs.AI cs.LO", "authors": ["bart bogaerts", "eugenia ternovska", "david mitchell"], "accepted": false, "id": "1606.08130"}, "pdf": {"name": "1606.08130.pdf", "metadata": {"source": "CRF", "title": "Propagators and Solvers for the Algebra of Modular Systems", "authors": ["Bart Bogaerts", "David Mitchell"], "emails": ["bart.bogaerts@aalto.fi", "ter@cs.sfu.ca", "mitchell@cs.sfu.ca"], "sections": [{"heading": null, "text": "ar X\niv :1\n60 6.\n08 13\n0v 1\n[ cs\n.A I]\n2 7\nJu n\n20 16\nMany expressive formalism used in practice solve the model expansion task, where a structure is given on the input and an expansion of this structure in the defined class of structures is searched (this practice overcomes the common undecidability problem for expressive logics). In this paper, we construct a solver for the model expansion task for a complex modular systems from an expression in the algebra and black-box propagators or solvers for the primitive modules. To this end, we define a general notion of propagators equipped with an explanation mechanism, an extension of the algebra to propagators, and a lazy conflict-driven learning algorithm.\nThe result is a framework for seamlessly combining solving technology from different domains to produce a solver for a combined system."}, {"heading": "1 Introduction", "text": "Almost all non-trivial commercial software systems use libraries of reusable components. The theory of combining conventional imperative programs is relatively well-developed. However, in knowledgeintensive computing, characterized by using so-called declarative programming, research on reusable components is not very developed. It would be desirable to use a program written in Answer Set Programming (ASP) with a specification of an Integer Liner Program (ILP) as building blocks in a complex application. Such a programming method, from existing components, possibly found on the web, would be extremely useful. The main challenge is that the programs may be written in different languages (even legacy languages), and rely on different solving technologies\nIntegration on the semantic level has been achieved in the Algebra of Modular Systems [38, 39]. Formally, a module in this algebra represents a class of structures, independently of any form of representation. Algebraical operations to manipulate such classes are defined, essentially generalising Codd\u2019s Relation Algebra [10] from tables to classes of structures. While the Algebra of Modular Systems provides a good account of how to combine modules, it is still unclear how to combine solving technology from different fields. The goal of this paper is to fill this gap.\n1 Helsinki Institute for Information Technology HIIT, Department of Computer Science, Aalto University, FI-00076 AALTO, Finland, email:bart.bogaerts@aalto.fi 2 Computational Logic Laboratory, Simon Fraser University, Burnaby, Canada, email:{ter,mitchell}@cs.sfu.ca\nContributions To study how pieces of solving technology from different fields can be combined, we extend the algebra to also be applicable to so-called propagators. We show that each of the operations on propagators corresponds to the same operation on modules. For example, if E1, E2 are modules, then \u03c0\u03b4(\u03c3(Q\u2261R)E1 \u00d7 E2) is a compound module. It represents the class of structures A such that some structure A\u2032 exists that coincides with A on \u03b4 and such that A\u2032 satisfies both E1 and E2 and interprets Q the same as R. If P1 and P2 are propagators for E1 and E2 respectively, then we show that in our extended version of the algebra, \u03c0\u03b4(\u03c3(Q\u2261R)P1 \u00d7 P2) is a propagator for \u03c0\u03b4(\u03c3(Q\u2261R)E1 \u00d7 E2). We equip these propagators with an explanation mechanism that generalises lazy clause generation [37], cutting plane generation [11] and counterexample-guided abstraction-refinement [9] (see Section 4, in particular Examples 4.5 and 4.2). This generalisation shows that many existing techniques are actually instances of the same fundamental principles. Furthermore, it will, in the future, allow for very simple proofs of correctness for novel, similar, techniques. Indeed, it suffices to show that a new technique satisfies the general definitions from this paper to guarantee that it yields a correct (learning) solver. We furthermore extend solvers based on these modular propagators with a conflict-analysis method that generalises resolution from conflict-driven clause learning [28]. We study complexity of the combined propagators in terms of complexity of propagators for the individual modules and show that in general, our operations can increase complexity. The resulting framework can capture, by means of its own (i.e., without relying on the complexity of individual modules), the entire polynomial hierarchy. This is useful, for example, to build a propagator for Quantified Boolean Formulas based on a propagator that (only) performs unit propagation for a propositional theory. We discuss how this can be done in Section 5.\nOur formal framework results effectively in a paradigm where pieces of information (modules) are accompanied with implemented technology (propagators) and where composing solving technology is possible with the same ease as composing modules. The algorithms we propose are an important step towards practical usability of the modular system paradigm. Related Work The closest related work is research on technology integration. Examples include but are not limited to [18, 4, 33]. Combined solving is perhaps most developed in the SAT modulo theories (SMT) community, where theory propagations are tightly interleaved with satisfiability solving [32, 36]. For efficient solving, special propagators are identified and either implemented separately or integrated tightly into the main reasoning mechanism. For example, acyclicity is added to SAT and ASP as a special propagator [16, 7]. The main novelty in this paper with respect to these previous approaches is we generalise the Algebra of Modular Systems to an algebra of propaga-\ntors, resulting in a setting where propagators for simple modules (or \u201ctheories\u201d in SMT terminology) can be combined into more complex propagators for the combined module.\nRecently, Lierler and Truszczyn\u0301ski [26] introduced a formalism with compositions (essentially, conjunctions) of modules given through solver-level inferences of the form (M, l), where M is a consistent set of literals and l is a literal not in M . Such pairs are called inferences of the module. Transition graphs for modules are constructed, with actions such as Propagate, Fail, Backtrack, Decide. Solvers based on the transition graph are determined by the selectedge-to-follow function (search strategy). Solving templates are investigated for several formalisms, including SAT and ASP. From individual transition graphs, such graphs are constructed for conjunctions of modules, and their properties are investigated, but more complex combinations of modules are not studied.\nCombining propagators has been studied in detail in constraint programming [8, 20, 23]. This research is often limited to a subset of the operations we consider here, for instance studying only conjunction of two constraint programs [5, 1], disjunction of two constraints [31, 43, 24] or connectives from propositional logic applied to constraints [25, 3]. The objectives of the current paper are similar to those considered the CP community; however, there are some key differences. First of all, we generalised the theory of propagators from constraint programming to the Algebra of Modular Systems. It can be applied in principle to every logic with a model semantics. As such, it can serve as a formal basis to transfer the rich body of work from constraint programming to other fields, such as for instance (Integer) Linear Programming or Answer Set Programming. Second, the traditional treatment of propagation emphasises tractability [20] (the focus is on propagators that can be computed in polynomial time). While it is often important to constrain the complexity of the propagators, it can often be useful as well to allow for complexity increasing operations. In our framework, one of the operations (projection) increases complexity; as such, contrary to the propagators considered in constraint programming, it allows to construct propagators for compound modules for which membership checking is not polynomial. As explained above, this is useful to construct propagators for expressive logics such as QBF. Third, we equip our propagators with a learning mechanism that generalizes for instance lazy clause generation [37] from constraint programming and a conflict analysis mechanism that generalises conflict-driven clause learning [28] from SAT [27]."}, {"heading": "2 Modular Systems", "text": "Structures A (relational)3 vocabulary \u03c4 is a finite set of predicate symbols. A \u03c4 -structure A consists of a domain A and an assignment of an n-ary relation QA over A to all n-predicate symbols Q \u2208 \u03c4 . A domain atom is an expression of the form Q(d) with Q \u2208 \u03c4 , and d a tuple of domain elements. The value of a domain atom Q(d) in a structure A (notation Q(d)A) is true (t) if d \u2208 QA and false (f ) otherwise. From now on, throughout the entire paper, we assume that A is a fixed domain, shared by all structures. This assumption is not needed for the Algebra of Modular Systems in general, but it is convenient for the current paper since the task we tackle (model expansion, see below) requires fixed domains anyway.\nA four-valued \u03c4 -structure A is an assignment Q(d)A of a fourvalued truth value (true, false, unknown (u) or inconsistent (i)) to each domain atom over \u03c4 . If Q(d)A \u2208 {t, f ,u} for each Q(d), we\n3 Without loss of generality, we restrict to relational vocabularies in this paper.\ncall A consistent. If Q(d)A \u2208 {t, f} for each Q(d), we call A twovalued and identify it with the corresponding structure. A four-valued structures is sometimes also called a partial structure, as it provides partial information about values of domain atoms.\nThe precision order on truth values is induced by u <p t <p i, u <p f <p i. This order is pointwise extended to (four-valued) structures: A <p A\u2032 iff for all domain atoms Q(d), Q(d)A <p Q(d)A \u2032\n. The set of all four-valued \u03c4 -structures forms a complete lattice when equipped with the order \u2264p . This means that every set S of (fourvalued) structures has a greatest lower bound glb\u2264p (S) and a least upper bound lub\u2264p (S) in the precision order. Hence, there is a most precise four-valued structure glb(\u2205), which we denote I; I is the most inconsistent structure: it maps all domain atoms to i.\nFour-valued structures are used to approximate structures. If A is a structure and A a partial structure, we say that A approximates A if A\u2264p A. In our algorithms below, four-valued structures will be used to represent the state of a solver: certain domain atoms have been decided (they are mapped to t or f ), other domain atoms atoms have not yet been assigned a value (they are mapped to u), and certain domain atoms are involved in an inconsistency (they are mapped to i). If a partial structure is inconsistent, it no longer approximates any structure. Solvers typically handle situations in which their state is inconsistent by backtracking.\nIfQ(d) is a domain atom and \u03bd \u2208 {t, f , i,u}, we use A[Q(d) : \u03bd] for the (four-valued) structure equal to A except for interpretingQ(d) as \u03bd. We use A[Q : QA \u2032\n] for the four-valued structure equal to A on all symbols except for Q and equal to Q on A\u2032. If \u03b4 \u2286 \u03c4 , we use A|\u03b4 for the structure equal to A on \u03b4 and mapping every other domain atom to u, i.e., A|\u03b4 is the least precise structure that coincides with A on \u03b4. Modules Let \u03c4M = {M1,M2, . . . } be a fixed vocabulary of atomic module symbols and let \u03c4 be a fixed vocabulary. Algebraic expressions for modules are built by the grammar:\nE ::= \u22a5 |Mi | E \u00d7 E | \u2212E | \u03c0\u03b4E | \u03c3Q\u2261RE. (1)\nWe call \u00d7 product, \u2212 complement, \u03c0\u03b4 projection onto \u03b4, and \u03c3Q\u2261R selection. Modules that are not atomic are called compound. Each atomic module symbol Mi has an associated vocabulary voc(Mi) \u2286 \u03c4 . The vocabulary of a compound module is given by \u2022 voc(\u22a5) = \u03c4 , \u2022 voc(E1 \u00d7 E2) = voc(E1) \u222a voc(E2), \u2022 voc(\u2212E) = voc(E), \u2022 voc(\u03c0\u03b4E) = \u03b4, and \u2022 voc(\u03c3\u0398E) = voc(E). Semantics Let C be the set of all \u03c4 -structures with domain A. Modules (atomic and compound) are interpreted by subsets of C.4 A module interpretation assigns to each atomic module Mi \u2208 \u03c4M a set of \u03c4 -structures such that any two \u03c4 -structures A1 and A2 that coincide on voc(Mi) satisfy A1 \u2208 I(M) iff A2 \u2208 I(M). The value of a modular expression E in I, denote JEKI is defined as follows.\nJ\u22a5KI := \u2205. JMiK\nI := I(Mi). JE1 \u00d7 E2K I := JE1K I \u2229 JE2K I . J\u2212EKI := C \u2212 JEKI . J\u03c0\u03b4(E)K I := {A | \u2203A\u2032 (A\u2032 \u2208 JEKI and A|\u03b4 = A\u2032|\u03b4)}. J\u03c3Q\u2261REK I := {A \u2208 EI | QA = RA}.\nWe call A a model of E in I (denoted A |=I E) if A \u2208 JEKI .\n4 If the assumption that A is fixed is dropped, modules are classes of structures instead of sets, but this generality is not needed in this paper.\nIn earlier papers [38, 39], the algebra was presented slightly differently; here, we restrict to a minimal syntax; this is discussed in detail in Section 5.\nExample 2.1. Let \u03c4 = {Edge,Trans} be a vocabulary containing two binary predicates. Let I be a model interpretation, Mt a module with vocabulary \u03c4 such that A |=I Mt if and only if ATrans is the transitive closure of AEdge and Mf is a module with vocabulary {Trans} such that A |=I Mf if and only if TransA is the full binary relation on A. Consider the following compound module\nE := \u03c0{Edge}(Mt \u00d7 (\u2212Mf )).\nIn this case E is a module with vocabulary {Edge} such that A |=I E if and only if EdgeA is a disconnected graph. This can be seen as follows: the module Mt sets Trans to be the transitive closure of Edge . The term (\u2212Mf ) ensures that Trans is not the full binary relation. These two modules are combined conjunctively and the result is projected onto {Edge}, i.e., the value of Trans does not matter in the result.\nFrom now on, we assume that a module interpretation I is given and fixed. Slightly abusing notation, we often omit the reference to I and write, e.g., A |= E instead of A |=I E. Model expansion for modular systems The model expansion task for modular systems is: given a (compound) module E and a partial structure A, find a structure A (or: find all structures A) such that A\u2265p A and A |=I E (if one such exists).\nMitchell and Ternovska [30] have defined methods to apply the lazy clause generation (LCG) paradigm [14] to solve the model expansion problem for modular systems. In particular, given propagators Pi that explain their propagations by means of clauses for atomic modules Mi, they show how to build a LCG-solver for modules of the form E =M1 \u00d7 \u00b7 \u00b7 \u00b7 \u00d7Mn.\nIn this paper, wee generalise the above idea to a setting whereE is an arbitrary (compound) module and to a setting where the learning mechanism is not necessarily clause learning."}, {"heading": "3 Propagators and Solvers", "text": "We define a general notion of propagators. We show how propagators for atomic modules can be composed into propagators for compound modules. Intuitively, a propagator is a blackbox procedure that refines a partial (four-valued) structure by deriving consequences of a given module.\nDefinition 3.1. A propagator is a mapping P from partial structures to partial structures such that the following hold: \u2022 P is \u2264p -monotone: whenever A\u2265p A\u2032, also P (A)\u2265p P (A\u2032). \u2022 P is information-preserving: P (A)\u2265p A for each A.\nDefinition 3.2. Given a module E, a propagator P is an Epropagator if on two-valued structures, it coincides with E, i.e., whenever A is two-valued, P (A) = A if A \u2208 E, and P (A) is inconsistent otherwise.\nAn E-propagator can never \u201close models of E\u201d, as is formalised in the following lemma.\nLemma 3.3. Let P be an E-propagator. If A is a model of E and A\u2265p A, then also A\u2265p P (A).\nProof. Follows immediately from \u2264p -monotonicity and the fact that P (A) = A for two-valued structures A.\nExample 3.4. Modern ASP solvers typically contain (at least) two propagators. One, which we call PPUP , performs unit propagation on the completion of the program P . The other, which we call PPUFS performs unfounded set propagation; that is: it maps a partial structure A to A \u222a {\u00acp | p \u2208 lUFS(P ,A)}, where lUFS(P ,A) is the largest unfounded set of P with respect to A [42].\nIt is easy to see that these two propagators are informationpreserving and \u2264p -monotone.\nExample 3.5. In several constraint solvers that perform bounds reasoning, (finite-domain) integer variables are represented by a relational representation of their bounds: a variable c is represented by a unary predicateQc\u2264 with intended interpretation thatQc\u2264(n) holds iff c \u2264 n. Consider in this setting a propagator Pc\u2264d. This propagator enforces bounds consistency for the constraint c \u2264 d. That is, a partial structure A is mapped by Pc\u2264d to a partial structure A\u2032 such that for each n:\n\u2022 if Qd\u2264(n)A \u2265p t, Qc\u2264(n)A \u2032 = lub\u2264p (Qc\u2264(n) A, Qd\u2264(n) A, \u2022 otherwise, Qc\u2264(n)A \u2032 = Qc\u2264(n) A\nAnd similar equations for Qd\u2264(n). Intuitively, this simply says that if d \u2264 n holds in A, then Pc\u2264d also propagates that c \u2264 n holds. For instance, assume the domain A = {1, . . . , 100} and that A is such that\nQc\u2264(n) A =\n\n\n t if n \u2265 90 u if 90 > n \u2265 10 f otherwise\nQd\u2264(n) A =\n\n\n t if n \u2265 80 u if 80 > n \u2265 20 f otherwise\nThis structure encodes that the value of c is in the interval [10, 90] and d in the interval [20, 80]. In this case, Pc\u2264d propagates that also c \u2264 80 without changing the value of d. Formally:\nQc\u2264(n) Pc\u2264d(A) =\n\n\n t if n \u2265 80 u if 80 > n \u2265 10 f otherwise\nQd\u2264(n) Pc\u2264d(A) = Qd\u2264(n) A\nPropagators and modules\nLemma 3.6. If P is a propagator, then there is a unique module E such that P is an E-propagator. We denote this module module(P ).\nProof. Uniqueness follows immediately from Definition 3.2. Existence follows from the fact that we can define module(P ) as the module such that A |= module(P ) if and only if P (A) = A.\nDefinition 3.7. If E is a module, the E-checker is the propagator PEcheck defined by: 5\nP E check : A 7\u2192\n\n\n A if A is consistent but not two-valued A if A is two-valued and A |= E I otherwise\nLemma 3.8. For each module E, PEcheck is an E-propagator.\nProof. That PEcheck is a propagator follows from the fact that I is more precise than any partial structure A. It follows immediately from the definition that PEcheck coincides withE on two-valued structures. 5 Recall that I denotes the most precise (inconsistent) structure.\nThe E-checker is the least precise E-propagator.\nProposition 3.9. For each E-propagator P and each consistent structure A, P (A)\u2265p PEcheck (A).\nThe proof is trivial. Propagators and Solvers Intuitively, a solver is a procedure that performs model expansion for a given module.\nDefinition 3.10. Let E be a module. AnE-solver is a procedure that takes as input a four-valued structure A and whose output is the set S of all two-valued structures A with A |= E and A\u2265p A.\nPropagators can be used to create solvers and vice versa. We first describe how to build a simple generate-and-check solver from a propagator. Afterwards, we provide an algorithm that uses the solver in a smarter way. In the next section, we discuss how to add a learning mechanism to this solver.\nAlgorithm 3.11. Let P be an E-propagator. We define an E-solver SPgc as follows. S P gc takes as input a structure A. The state of S P gc is a tuple (B,S) of a structure and a set of two-valued structures S; it is initialised as (A,\u2205). SPgc performs depth-first search on the search space of (four-valued) structures more precise than A. Choices consist of updating B to B[Q(d) : t] or to B[Q(d) : f ] for some domain atom withQ(d)B = u. Whenever B is two-valued, the solver checks whether P (B) = B. If yes, B is added to S . After encountering a two-valued structure, it backtracks over its last choice. When the search space has been traversed, SPgc returns S .\nAlgorithm 3.12. The solver SPp extends S P gc by updating B to P (B) before each choice. If B is inconsistent, SPp backtracks.\nProposition 3.13. If the domain A is finite, SPgc and S P p are Esolvers.\nSketch of the proof. Finiteness of A guarantees that depth-first search terminates. Correctness of SPgc follows from the fact that P is an E-propagator (since {A | P (A) = A} = {A | A |= E}).\nCorrectness of SPp follows from Lemma 3.3: no models are lost by propagation.\nIn the above proposition, the condition that A is finite only serves to ensure termination of these two procedures that essentially traverse the entire space of structures more precise than B. All the concepts defined in this paper, for instance propagators, and operations on propagators, can also be used in a setting where the domain is infinite.\nWe now show how to construct a propagator from a solver. We call this propagator optimal, since it always returns the most precise partial structure any propagator could return (cf. Proposition 3.16). In this sense, this propagator actually performs skeptical reasoning.\nDefinition 3.14. Let S be an E-solver. We define an E-propagator PSopt : A 7\u2192 glb\u2264p S(A).\nNotice that if S\u2032 is anE-solver as well, as a function, PSopt = P S\u2032\nopt . However, we include S in the notation since for practical purposes, we need a way to compute PSopt(A); for this, a call to S is used.\nProposition 3.15. If S is an E-solver, PSopt is an E-propagator.\nProof. We first show that PSopt is a propagator. First, for each A \u2208 S(A), it holds that A\u2265p A, hence also PSopt(A)\u2265p A. Second, notice that whenever A1 \u2265p A2, S(A1) \u2286 S(A2), hence\nglb\u2264p S(A1)\u2265p glb\u2264p S(A2). From these two properties, it follows that PSopt is indeed a propagator. The fact that it is also an E-propagator follows from the property that for two-valued A, S(A) = {A} if A |= E and S(A) = \u2205 otherwise.\nProposition 3.16. Let P be any E-propagator and S an E-solver. For each structure A, it holds that PSopt(A)\u2265p P (A).\nProof. From Lemma 3.3, we find that P (A)\u2264p A if A \u2208 S(A). Hence also P (A)\u2264p glb\u2264p S(A) = P S opt (A).\nCombining propagators First, we discuss how propagators for the same module can be combined. Afterwards, we extend the algebra of modular systems to propagators.\nProposition 3.17. Composition P1 \u25e6P2 of two E-propagators is an E propagator. In particular, if P is an E-propagator, also Pn is an E-propagator. We use P\u221e for lim\u2264p P n.\nProposition 3.18. If P1 and P2 are two E-propagators, then (P1 \u25e6 P2)(A)\u2265p P1(A) and (P1 \u25e6 P2)(A)\u2265p P2(A) for each A.\nThe proofs of the two above propositions are trivial. In the next proposition, we show how checkers for compound expressions in the algebra can be built from propagators for atomic modules. These checkers are sufficient for defining the algebra on propagators: if propagators for atomic modules are given, Proposition 3.20 provides us with the means to obtain a propagator for compound expressions. However, for practical purposes, we are often interested in better, i.e., more precise propagators. Hence, after this proposition, we investigate for which operations better propagations can be defined.\nDefinition 3.19. Let P be an E-propagator, P \u2032 an E\u2032-propagator and \u03b4 \u2286 \u03c4 . We define following checkers (we only define their behaviour on two-valued structures since otherwise the behaviour of checkers is trivial): \u2022 P\u22a5check : A 7\u2192 I \u2022 PE\u00d7E \u2032\ncheck : A 7\u2192 lub\u2264p {P (A), P \u2032(A)}\n\u2022 P\u2212Echeck : A 7\u2192\n{\nA if P (A) = I I otherwise\n\u2022 P \u03c0\u03b4Echeck : A 7\u2192\n{\nA if SPp (A|\u03b4) 6= \u2205 I otherwise\n\u2022 P \u03c3Q\u2261RE\ncheck : A 7\u2192\n{\nA if P (A) = A and QA = RA I otherwise\nProposition 3.20. The operations defined in Definition 3.19 indeed defined checkers. Furthermore for each compound module E\u2032\u2032, PE \u2032\u2032\ncheck is an E \u2032\u2032-checker.\nSketch of the proof. Correctness for each of the above follows easily from the definition of the semantics of modular systems.\nNow, we present for several of the operations a better (more precise) propagator (compared to only checking).\nProposition 3.21. Let P be an E-propagator, P \u2032 an E\u2032-propagator and \u03b4 a sub-vocabulary of \u03c4 . We define the following operations: \u2022 P \u00d7 P \u2032 : A 7\u2192 lub\u2264p {P (A), P\n\u2032(A)}. \u2022 \u03c0\u03b4P : A 7\u2192\n\n\n I if A is inconsistent I if A is two-valued on \u03b4 and SPp (A|\u03b4) = \u2205 lub\u2264p (P (A|\u03b4)|\u03b4,A|\u03c4\\\u03b4) otherwise.\n\u2022 \u03c3Q\u2261RP : A 7\u2192 (P (A))[Q : L,R : L] where L = lub\u2264p (Q\nP (A), RP (A)). It then holds that P \u00d7 P \u2032 is an E \u00d7 E\u2032-propagator, \u03c0\u03b4P is a \u03c0\u03b4E propagator and \u03c3Q\u2261R is a \u03c3Q\u2261RE-propagator.\nProof. We provide a proof for projection; the other operations are analogous.\nWe show that \u03c0\u03b4P is a propagator. First, for each four-valued structure A, P (A|\u03b4)\u2265p A|\u03b4 since P is a propagator, hence also \u03c0\u03b4P (A)|\u03b4 = P (A|\u03b4)|\u03b4 \u2265p A|\u03b4 . Furthermore, \u03c0\u03b4P (A)|\u03c4\\\u03b4 = A|\u03c4\\\u03b4. Combining these two yields that \u03c0\u03b4P (A)\u2265p A and hence that \u03c0\u03b4P is indeed information preserving (the cases where P (A) = I are trivial).\nWe show \u2264p -monotonicity of \u03c0\u03b4P . Assume A1 \u2265p A2. If A2 is inconsistent, then so is A1 and thus \u03c0\u03b4P (A1) = \u03c0\u03b4P (A2). If A2 is two-valued on \u03b4 and SPp (A1|\u03b4) = \u2205, then either A1 is inconsistent, or A1|\u03b4 = A2|\u03b4 . In both cases, the result is trivial. If \u03c0\u03b4P (A1) = I, the result is trivial as well, hence we can assume that both A1 and A2 fall in the \u201cotherwise\u201d category in the definition of \u03c0\u03b4P . The \u2264p -monotonicity of \u03c0\u03b4P now follows from the fact that if A1 \u2265p A2 then also (1) A1|\u03b4 \u2265p A2|\u03b4 and thus P (A1|\u03b4)\u2265p P (A2|\u03b4) and (2) A1|\u03c4\\\u03b4 \u2265p A2|\u03c4\\\u03b4 . Hence, we conclude that \u03c0\u03b4P indeed defines a propagator.\nNow, we show that \u03c0\u03b4P is a \u03c0\u03b4E-propagator. Let A be a twovalued structure.\nFirst suppose A |= \u03c0\u03b4E. In this case, there exists a two-valued A\u2032 such that A\u2032 |= E and A|\u03b4 = A\u2032|\u03b4 . Thus, SPp (A|\u03b4) 6= \u2205 in this case. Also, in this case P (A|\u03b4) is consistent and thus P (A|\u03b4)|\u03b4 = A|\u03b4 . We conclude that in this case indeed \u03c0\u03b4P (A) = A.\nNow suppose A 6|= \u03c0\u03b4E. In this case, there exists no structure A\u2032 such that A\u2032|\u03b4 = A|\u03b4 and A\u2032 |= E. Thus SPp (A|\u03b4) = \u2205 and \u03c0\u03b4(A) is indeed inconsistent.\nThe intuitions in the above proposition are as follows. For P \u00d7P \u2032, P computes consequences of E, while P \u2032 computes consequences of E\u2032, given an input structure A. The propagator P \u00d7 P \u2032 combines the consequences found by both: it returns the least upper bound of P (A) and P \u2032(A) in the precision order. That is, it returns the structure in which all domain literals derived by any of the two separate propagators hold (and nothing more). For projection \u03c0\u03c3P , in the twovalued case, the solver SPp is used to check whether A \u2208 \u03c0\u03b4E. For the three-valued case, P is used to propagate on A|\u03b4 , i.e., using only the information about the projected vocabulary \u03b4. From this propagation, only the information that is propagated about \u03b4 is kept (this is P (A|\u03b4)|\u03b4). Indeed \u03c0\u03b4E enforces no restrictions on symbols in \u03c4 \\ \u03b4. Furthermore, we transfer all knowledge we previously had on symbols in \u03c4 \\ \u03b4 (this is some form of inertia); the resulting structure equals P (A|\u03b4) on symbols in \u03b4 and equals A on symbols in \u03c4 \\\u03b4. For selection \u03c3Q\u2261RP , propagation happens according to P . Afterwards, all propagations for Q are also transferred to R and vice versa. This is done by changing the interpretations of both Q and R to the least upper bound (in the precision order) of their interpretations in P (A).\nExample 3.22 (Example 3.4 continued). We already mentioned that typical ASP solvers have two propagators PPUP and P P UFS . The actual propagation is done according to PPASP = P P UP \u00d7 P P UFS . Furthermore, typically, this propagation is executed until a fixed point is reached, hence the entire propagation is described by ( PPASP )\u221e\n. Now let MP be the module such that A |= MP if and only if A is a stable model of P . It is well-known that a structure is a stable model of P if and only if it is a model of the completion and it admits no non-trivial unfounded sets [35]. From this, it follows that MP =\nMPUP \u00d7M P UFS , where M P UP is a module such that A |=M P UP iff A is a model of the completion of P and MPUFS is a module such that A |= MPUFS iff A admits no non-trivial unfounded sets with respect to P . It is easy to see that PPUP and P P UFS are M P UP - and M P UFSpropagators respectively. From this it follows by Propositions 3.21 and 3.17 that PPASP and also ( PPASP )\u221e are MP -propagators.\nUp to this point, we have described three different ways to construct E-propagators: PSopt is the most precise E-propagator if S is anE-solver, Proposition 3.20 describes how to buildE-checkers (the least precise propagators) from propagators for subexpressions of E and Proposition 3.21 illustrates how to build more precise propagators for compound expressions. However, precision is not the only criterion for \u201cgood\u201d propagators. In practice, we expect propagators to be efficiently computable. In the following proposition, we show that this is indeed the case for the propagators defined in Proposition 3.21.\nProposition 3.23. Assume the fixed domain A is finite; furthermore assume access to an oracle that computes P (A) and P \u2032(A). The following hold \u2022 (P \u00d7P \u2032)(A) can be computed in polynomial time (in terms of the\nsize of A), \u2022 (\u03c3Q\u2261RP )(A) can be computed in polynomial time, \u2022 (\u03c0\u03b4P )(A) can be computed in nondeterministic polynomial time.\nSketch of the proof. The first two statements follow easily from the definitions. For instance (P \u00d7 P \u2032)(A) is defined as lub\u2264p {P (A), P \u2032(A)}. Computing this least upper bound can be done by comparing Q(d)P (A and Q(d)P \u2032(A for each domain atom Q(d). There are only polynomially many domain atoms. For the last statement, the complexity is dominated by a call to SPp (A|\u03b4), which is essentially depth-first search.\nProposition 3.23 shows that product and selection do not increase complexity when compared to the complexity of the propagators they compose. However, the situation for projection is different. That is not surprising, since Tasharrofi and Ternovska [40] already showed that the projection operation increases the complexity of the task of deciding whether a structure is a member of a given module or not. As such, Proposition 3.23 actually shows that our propagators for compound expressions only increase complexity when dictated by the complexity of checking membership of the underlying module."}, {"heading": "4 Explanations and Learning", "text": "In many different fields, propagators are defined that explain their propagations in terms of simpler constructs. For instance in CDCLbased ASP solvers [17, 2, 12], the unfounded set propagator explains its propagation by means of clauses. Similar explanations are generated for complex constraints in constraint programming (this is the lazy clause generation paradigm [37]) and in SAT modulo theories [15]. The idea to generate clauses to explain complex constraints already exists for a long time, see e.g. [29]. In integer programming, the cutting plane method [11] is used to enforce a solution to be integer. In this methodology, when a (rational) solution is found, a cutting plane is learned that explains why this particular solution should be rejected. Similarly, in QBF solving, counterexampleguided abstraction-refinement (the CEGAR methodology) counterexample guided abstraction-refinement [9] starts from the idea to first solve a relaxed problem (an abstraction), and on-the-fly add explanations why a certain solution to the relaxation is rejected. De Cat et al.\n[13] defined a methodology where complex formulas are grounded on-the-fly. This is a setting where inference made by complex formulas is explained in terms of simpler formulas (formulas with a lower quantification depth).\nIn this section, we generalise the common idea underlying each of the above paradigms by adding explanations and learning to our abstract framework. We present a general notion of an explaining propagator and define a method to turn such a propagator into a solver that learns from these explanations. An explaining propagator is a propagator that not only returns the partial structure that is the result of its propagations (P (A)), but also an explanation (C(A)). This explanation takes the form of a propagator itself. Depending on the application, this propagator has a specific form. For instance, for lazy clause generation, the explanation must be a (set of) clause(s); in integer linear programming, the explanation must be a (set of) cutting plane(s). In general, there are two conditions on the explanation. First, it should explain why the propagator made certain propagations: C(A) should derive at least what P derives in A. Second, the returned explanation should not be arbitrary, it should be a consequence of the module underlying the propagator P .\nDefinition 4.1. An explaining propagator is tuple (P,C) where P is a propagator and C maps each partial structure either to UNEXPLAINED (notation \u2666) or to an explaining propagator C(A) = (P \u2032, C\u2032) such that the following hold: (1) (explains propagation) P (A)\u2264p P \u2032(A). (2) (soundness): module(P \u2032) \u2286 module(P )\nExample 4.2. Integer linear programs are often divided into two parts: some solver performs search using linear constraints. When a solution is found, a checker checks whether this solution is integervalued. If not, this checker propagates inconsistency and explains this inconsistency by means of a cutting plane. This process fits in our general definition of explaining propagator: a cutting plane can be seen itself as a propagator (actually a simple checker). This propagator explains the inconsistency and is a consequence of the original problem (namely of the integrality constraint).\nAs can be seen, we allow an explaining propagator to not explain certain propagations. For instance, whenever P (A) = A, nothing new is derived, hence there is nothing to explain. We say that (P,C) explains propagation from A if either P (A) = A or C(A) 6= \u2666. Each propagator P as defined in Definition 3.1 can be seen as an explaining propagator (P,C\u2666), whereC\u2666 maps each partial structure to \u2666.\nExample 4.3 (Example 3.5 continued). For each natural number n let cln denote the clause Qc\u2264(n) \u2228 \u00acQd\u2264(n) and let Pn denote the propagator that performs unit propagation on cln. For each A, let UA denote the set of all n\u2019s such that at least one literal from cln is false in A. Furthermore, let Cc\u2264d denote the mapping that maps each four-valued structure A to\n{\n\u2666 if Pc\u2264d(A) = A (\n\u00d7n\u2208UAPn, C\u2666\n)\notherwise,\nwhere \u00d7n\u2208UAPn denotes the product of all Pn with n \u2208 UA. In this case, (Pc\u2264d, Cc\u2264d) is an explaining propagator. It explains each propagation by means of a set of clauses (the product of propagators Pn for individual clauses). This particular explanation is used for instance in MinisatID [12] and many other lazy clause generation CP systems.\nIn general, using anything as explanation is not really a good idea: what we are hoping for is that a propagator explains its propagations in terms of simpler propagators (where the definition of \u201csimple\u201d can vary from field to field). In order to generalise this idea, in what follows we assume that \u227a is a strict well-founded order on the set of all explaining propagators, where smaller propagators are considered \u201csimpler\u201d. In the following definition, we also require that all propagations need to be explained, except for \u227a-minimal propagators.\nDefinition 4.4. We say that an explaining propagator (P,C) respects \u227a if \u2022 Whenever C(A) = \u2666, P (A) = A or (P,C) is \u227a-minimal, \u2022 In all other cases, C(A) \u227a (P,C) and C(A) respects \u227a.\nExample 4.5. For lazy clause generation, the order on propagators would be (P, C) \u227a (P \u2032, C\u2032) if P performs unit propagation for a clause and P \u2032 does not. The conditions in Definition 4.4 guarantee that each non-clausal propagator must explain its propagation in terms of these \u227a-minimal propagators; i.e., in terms of clauses.\nExample 4.6. When grounding lazily [13], one can consider propagators P\u03d5 that perform some form of propagation for a first-order formula \u03d5. A possible order \u227a is then: (P\u03d5, C\u03d5) \u227a (P\u03d5\u2032 , C\u03d5\u2032) if \u03d5 has strictly smaller quantification depth then \u03d5\u2032. For instance, a propagator for a formula \u2200x : \u2203y : \u03c8(x, y) can explain its propagations by means of a propagator for the formula \u2203y : \u03c8(d, y), where d is an arbitrary domain element.\nWe now show explaining propagators can be used.\nAlgorithm 4.7. Let (P,C) be an explaining propagator that respects \u227a. We define a learning solver ls(P,C) as follows. The input of ls(P,C) is a partial structure A. The state of ls(P,C) is a triple (P ,B,S) where P is a set of explaining propagators, B is a (fourvalued) structure, and S is a set of (two-valued) structures. The state is initialised as ({(P,C)},A,\u2205). The solver performs depth-first search on the structure B, where each choice point consists of assigning a value to a domain atom unknown in B. Before each choice point, until a fixed point is reached, B is updated to P \u2217(B) and P to P \u222a {C\u2217(B)}, where (P \u2217, C\u2217) is \u227a-minimal among all elements of P that have P \u2217(B) 6= B. If no such element exists, no more propagation is possible and the solver makes another choice. Whenever B is inconsistent, the solver backtracks. If this search encounters a model (a two-valued structure A with A = P (A), it stores this model in S and adds (P {A}check , C\u2666) to P . After the search space has been traversed (i.e., inconsistency is derived without any choice points left), it returns S .\nProposition 4.8. Assume the domain A is finite. If (P, C) is an Eexplaining propagator, then ls(P,C) is an E-solver.\nSketch of the proof. As before, termination follows from the fact that A is finite. It follows from the second condition in Definition 4.1 that during execution of ls(P,C) , for all P \u2032 \u2208 P , it holds that module(P \u2032) \u2286 module(P ), hence propagation is indeed correct for E.\nThe next question that arises is: how can explaining propagators for individual modules be combined into explaining propagators for compound modules? The answer is not always simple. As for regular propagators, each operation can be defined trivially. In Section 3, being defined trivially meant simply defining the checker. In this case, it means that forC we simply takeC\u2666. Below, we discuss some more interesting cases. We will use the following notations. If d is a tuple\nof domain elements, we use P dQ\u2261R for the propagator that maps each structure A to a structure equal to A except that it interpretsQ(d) and R(d) both as lub\u2264p (Q(d) A, R(d)A). We use PQ\u2261R for the propagator \u00d7{d\u2208An}P d Q\u2261R where A is the domain and n is the arity of Q and R. Furthermore, we use CQ\u2261R for the mapping that sends A to {\n\u2666 if PQ\u2261R(A) = A (\n\u00d7{d\u2208An|Q(d)A 6=R(d)A}P d Q\u2261R, C\u2666\n)\notherwise\nDefinition 4.9. Assume (P, C) and (P \u2032, C\u2032) are explaining propagators. We define the following explaining propagators: \u2022 Product of explaining propagators: (P,C) \u00d7 (P \u2032, C\u2032) = (P \u00d7 P \u2032, C \u00d7 C\u2032) where C \u00d7 C\u2032 maps A to\n\n\n\nC(A)\u00d7 C\u2032(A) if both (P, C) and (P \u2032, C\u2032) explain propagation from A \u2666 otherwise\n\u2022 Projection of an explaining propagator: \u03c0\u03b4(P,C) = (\u03c0\u03b4P, \u03c0\u03b4C), where \u03c0\u03b4C maps A to \n\n \u2666 if A is inconsistent or C(A|\u03b4) = \u2666 \u2666 if A is two-valued on \u03b4 and s(P )(A|\u03b4) = \u2205 \u03c0\u03b4(C(A)) otherwise\n\u2022 Selection of an explaining propagator: \u03c3Q\u2261R(P,C) = (P,C)\u00d7 (PQ\u2261R, CQ\u2261R).\nProposition 4.10. The mappings in Definition 4.9 indeed define explaining propagators.\nProof. The proof is similar for all cases. We only give the proof for projection. The proof is by induction on the structure of C. First assume that C = C\u2666. In this case, \u03c0\u03b4(P,C) = (\u03c0\u03b4P, C\u2666), which is indeed an explaining propagator.\nFor the induction case, we can assume that for each A with C(A) 6= \u2666, \u03c0\u03b4C(A) is an explaining propagator. We show that \u03c0\u03b4(P,C) is an explaining propagator. Choose some A with (\u03c0\u03b4C)(A) 6= \u2666. Let (P \u2032, C\u2032) denote (\u03c0\u03b4C)(A) and (P \u2032\u2032, C\u2032\u2032) denote C(A). From Definition 4.9, we know that P \u2032 = \u03c0\u03b4P \u2032\u2032.\nFirst, we show that \u03c0\u03b4(P,C) explains propagation, i.e., that \u03c0\u03b4P (A)\u2264p P\n\u2032(A). We know that P (A)\u2264p P \u2032\u2032(A) since (P,C) is an explaining propagator. It follows immediately from the definition of \u03c0\u03b4P that also \u03c0\u03b4P (A)\u2264p \u03c0\u03b4P \u2032\u2032(A) = P \u2032(A).\nWe now show that \u03c0\u03b4(P,C) only derives consequences, i.e., that module(P \u2032) |= module(\u03c0\u03b4P ). We know that module(P \u2032\u2032) |= module(P ). From the definition of the semantics of modular systems, it follows that then also \u03c0\u03b4module(P \u2032\u2032) |= \u03c0\u03b4module(P ). Furthermore, from Proposition 3.21, we know that \u03c0\u03b4module(P \u2032\u2032) = module(\u03c0\u03b4P \u2032\u2032) = module(P \u2032) and \u03c0\u03b4module(P ) = module(\u03c0\u03b4P ). The result then follows."}, {"heading": "A Conflict-Driven Learning Algorithm", "text": "The CDCL algorithm for SAT lies at the heart of most modern SAT solvers, and also many SMT solvers, ASP solvers, and others. We now give an algorithm scheme that generalizes the CDCL algorithm to modular systems.\nAlgorithm 4.11. The algorithm cdl (P,C) is obtained by modifying ls(P,C) as follows. Each time propagation leads to an inconsistent state, we update B,P \u2190 B\u2032,P \u222a {(P \u2032, C\u2032)}, where (B\u2032, (P \u2032, C\u2032)) = HandleConflict(B,P), and HandleConflict is a function such that\n(1) (P \u2032, C\u2032) is an explaining propagator that respects \u227a, (2) A \u2264p B\u2032 <p B (backjumping), (3) (P \u222a {(P \u2032, C\u2032)})(B\u2032) >p P(B\u2032) (learning), (4) module(P) \u2286 module(P \u2032) (consequence) After executing HandleConflict, it is optional to restart by re-setting B to A.\nThe intuition is that HandleConflict is some function that returns a state to backtrack to, and a new propagator to add to the set of propagators. This new propagator should, in the structure to which we backtrack, propagate something that was not propagated before. Thus, by analyzing the conflict, we obtain better information and avoid ending up in the same situation again.\nProposition 4.12. Assume A is finite. If (PE , CE) is an Eexplaining propagator that respects \u227a, then cdl (PE ,CE) is an Esolver.\nSketch of the proof. Correctness of cdl (PE ,CE) follows from correctness of ls(P,C) combined with the fourth condition for HandleConflict in Algorithm 4.11. The hardest thing to prove is termination of this algorithm in case restarts are involved. It can be seen that this algorithm terminates by the fact that after each conflict, by the third condition in HandleConflict, for at least one partial structure (namely for B\u2032), strictly more is propagated by (P \u222a {(P \u2032, C\u2032)}) than by P . Since the number of propagators is finite, there cannot be an infinite such sequence, hence only a finite number of conflicts can occur.\nThe purpose of HandleConflct is to perform a conflict analysis analogous to that in standard CDCL. This procedure can be anything; in practice, it will depend on the form \u227a-minimal propagators take and on the proof system used for these minimal propagators. Below, we present a sufficient restriction on \u227a-minimal propagators to ensure that a procedure HandleConflict actually exists.\nProposition 4.13. Suppose that there exists a function F that takes as arguments two \u227a-minimal explaining propagators (P1, C1) and (P2, C2) that respect \u227a, and a partial structure B, and returns an explaining propagator (P,C) that respects \u227a, such that the following hold.\nIf A <p P1(B) <p P2(P1(B)) and B <p P2(B) <p P2(P1(B)), then module(P1) \u00d7 module(P2) \u2286 module(P ) and there exists a structure B\u2032 \u2264p B such that P (B\u2032) >p P2(P1(B \u2032)).\nIn that case, a procedure HandleConflict that satisfies the restrictions in Algorithm 4.11 exists.\nSketch of the proof. The idea is that it suffices to be able to combine \u227a-minimal propagators since all propagations can (by iterated calls to the explanation mechanism) be explained in terms of these propagators. Furthermore, the above condition can be applied iteratively to combine more than two \u227a-minimal propagators.\nThe intuition for F is that it effectively analyses the source of a conflict found by a sequence of propagations. We want to be able to determine a minimum collection of points in the partial structure relevant to the conflict. For this, it suffices that we can take two \u227a- minimal propagators and \u201cresolve\u201d them to obtain one with stronger propagation power. Observe that, if we assume that all \u227a-minimal propagators have a representation as clauses, this function can be implemented by means of the standard resolution used in CDCL conflict analysis process. In general, other resolution mechanisms might\nbe used. The chosen implementation for F essentially determines the proof system that will be used in the solver.\nIterated applications of F , starting from the last two propagators that changed state and working back to earlier propagators allow us to handle conflicts. Note that F is only defined on \u227a-minimal propagators. However, the explanation mechanism in explaining propagators allows us to always reduce propagators to \u227a-minimal propagators by means of calling the explanation method until a minimal propagator is obtained (this is possible since \u227a is a well-founded order)."}, {"heading": "5 Modular patterns", "text": "Sometimes, defining a propagator compositionally does not yield the best result. We identify three patterns for which we can define a better (more precise) propagator by exploiting a global structure. The first two optimisations consist of direct implementations for propagators for expressions in the algebra of modular systems that are not in the minimal syntax (for details, see, e.g., [39]). The latter optimisation is based on techniques that were recently used to nest different SAT solvers to obtain a QBF solver. Disjunction of Modules The disjunction of two modules is defined as E1 + E2 = \u2212(\u2212E1 \u00d7\u2212E2).\nDefinition 5.1. Let P1 and P2 be an E1- (respectively E2-) propagator. We define a propagator\nP1 + P2 : A 7\u2192 glb\u2264p (P1(A), P2(A)).\nIntuitively, this propagator only propagates what holds in both P1(A) and P2(A). As such, it indeed only derives consequences of the disjunction.\nProposition 5.2. The following hold: \u2022 P1 + P2 is a \u2212(\u2212E1 \u00d7\u2212E2) propagator \u2022 For each consistent partial structure A,\n(P1 + P2)(A)\u2265p \u2212 (\u2212P1 \u00d7\u2212P2)(A).\nSketch of the proof. It is easy to see that A |= \u2212(\u2212E1 \u00d7 \u2212E2) iff A |= E1 or A |= E2. The first point now follows directly from the definition of P1+P2. The second point follows from Proposition 3.9 since \u2212(\u2212P1 \u00d7\u2212P2) is an E1 + E2-checker.\nExtended selection It is also possible to allow expressions of the form \u03c3\u0398E where \u0398 consists of expressions of the form Q \u2261 R or Q 6\u2261 R and propositional connectives applied to them (for semantics, see, e.g., [39]). Each such expression can be rewritten to the minimal syntax used in this paper, for instance \u03c3P 6\u2261QE is equivalent to E \u00d7 \u2212\u03c3P\u2261QE. By taking an entire such formula into account at once, more precise reasoning is possible.\nProposition 5.3. Let P be a \u03c3\u0398E-propagator with \u0398 an expression as above. If \u0398 |= Q \u2261 R, then \u03c3Q\u2261RP is also a \u03c3\u0398E propagator.\nProof. Follows directly from the fact that in this case \u03c3Q\u2261R(\u03c3\u0398E) = \u03c3\u0398E.\nProposition 5.3 states that we can use (symbolic) equality reasoning on \u0398 to derive more consequences. This can be used for instance to derive inconsistencies early on.\nExample 5.4. Consider the module\n\u03c3(Q6\u2261R\u2228R\u2261U)\u2227(Q\u2261R)E.\nIt is easy to see that R \u2261 U is a consequence of the selection expression in the above module. As such, Proposition 5.3 guarantees that we are allowed to improve propagators, to also propagate equality between Q and R.\nImproved Negation Janhunen et al. [21] recently defined a solver that combines two SAT solver. The essence of their algorithm can be translated into our theory as follows. Let \u03c4 and \u03b4 be vocabularies, E a \u03c4 \u222a \u03b4-module and S an E-solver. Furthermore, assume that there is a procedure Explain such that for each two-valued \u03c4 -structure A such that S(A) 6= \u2205, A = Explain(A) is a partial \u03c4 -structure such that \u2022 A\u2264p A \u2022 For each two-valued \u03c4 structure B\u2265p A, S(B) 6= \u2205. Thus, Explain explains why a certain module is satisfiable. Given this, Janhunen et al. defined an explaining propagator P for \u2212\u03c0\u03c4E. If A is two-valued on \u03c4 , P calls S(A|\u03c4 ). If the result of this call is not empty, it propagates a conflict and generates an explanation using Explain(A|\u03c4) (see [21] for details). Otherwise, P maps A to itself.\nThis idea has been generalised to work for arbitrary QBF formulas [6]. It actually forms to essence of many SAT-based QBF algorithms [34, 44, 19, 22]. Janhunen et al. [21] further improved this method by introducing a notion of an underapproximation. That is, instead of using an E-solver S, they use an E\u0304-solver S\u0304, where E\u0304 is some module derived from E. This allows them to run S\u0304 before A is twovalued on \u03c4 . Researching how these underapproximations generalise to modular systems is a topic for future work."}, {"heading": "6 Conclusion and Future Work", "text": "In this paper, we defined general notions of solvers and propagators for modular systems. We extended the algebra of modular systems to modular propagators and showed how to build solvers from propagators and vice versa. This means that the We argued that our notion of propagator generalises notions from various domains. Furthermore, we added a notion of explanations to our propagators. These explanations generalise concepts from answer set programming, constraint programming, linear programming and more. We used these explanations to build learning solvers and discussed how learning solvers can be extended with a conflict analysis method, effectively resulting in a generalisation of CDCL for arbitrary proof systems. Finally, we discussed several patterns of modular expressions for which more precise propagation is possible than what would be obtained by creating the propagators following the compositional rules.\nThe main contribution of the paper is that we provide an abstract account of propagators, solvers, explanations, learning and conflict analysis, resulting in a theory that generalises many existing algorithms and allows integration of technology of different fields. Our theory allows to build actual solvers for modular systems and hence provides an important foundation for the practical usability of modular systems.\nSeveral topics for future work remain. While the current theory provides a strong foundation, an implementation is still needed to achieve practical usability. We intend to research more patterns for which improved propagation is possible, and generalise the aforementioned underapproximations to our framework. The Algebra of Modular Systems has been extended with a recursion operator (see for instance [41]); researching what are good propagators for this operator is an open challenge."}], "references": [{"title": "WASP: A native ASP solver based on constraint learning", "author": ["Mario Alviano", "Carmine Dodaro", "Wolfgang Faber", "Nicola Leone", "Francesco Ricca"], "venue": "Proceedings of LPNMR,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2013}, {"title": "Propagating logical combinations of constraints", "author": ["Fahiem Bacchus", "Toby Walsh"], "venue": "Proceedings of IJCAI, pp", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2005}, {"title": "Heterogeneous constraint solving", "author": ["Fr\u00e9d\u00e9ric Benhamou"], "venue": "Proceedings of ALP, pp", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 1996}, {"title": "Answer set programming modulo acyclicity", "author": ["Jori Bomanson", "Martin Gebser", "Tomi Janhunen", "Benjamin Kaufmann", "Torsten Schaub"], "venue": "Proceedings of LPNMR,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2015}, {"title": "Towards \u201cpropagation = logic + control\u201d", "author": ["Sebastian Brand", "Roland H.C. Yap"], "venue": "Proceedings of ICLP, pp", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2006}, {"title": "Counterexample-guided abstraction refinement for symbolic model checking", "author": ["Edmund M. Clarke", "Orna Grumberg", "Somesh Jha", "Yuan Lu", "Helmut Veith"], "venue": "J. ACM,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2003}, {"title": "A relational model of data for large shared data banks", "author": ["E.F. Codd"], "venue": "Communications of the ACM,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 1970}, {"title": "Solution of a largescale traveling-salesman problem", "author": ["G Dantzig", "R Fulkerson", "S Johnson"], "venue": "Operations Research,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 1954}, {"title": "Model expansion in the presence of function symbols using constraint programming", "author": ["Broes De Cat", "Bart Bogaerts", "Jo Devriendt", "Marc Denecker"], "venue": "Proceedings of ICTAI,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2013}, {"title": "Lazy model expansion: Interleaving grounding with search", "author": ["Broes De Cat", "Marc Denecker", "Maurice Bruynooghe", "Peter J. Stuckey"], "venue": "J. Artif. Intell. Res. (JAIR),", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2015}, {"title": "Lazy clause generation reengineered", "author": ["Thibaut Feydy", "Peter J. Stuckey"], "venue": "Proceedings of CP,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2009}, {"title": "DPLL(T): Fast decision procedures", "author": ["Harald Ganzinger", "George Hagen", "Robert Nieuwenhuis", "Albert Oliveras", "Cesare Tinelli"], "venue": "Proceedings of CAV, pp", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2004}, {"title": "SAT modulo graphs: Acyclicity", "author": ["Martin Gebser", "Tomi Janhunen", "Jussi Rintanen"], "venue": "Proceedings of JELIA, pp", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2014}, {"title": "Conflictdriven answer set solving: From theory to practice", "author": ["Martin Gebser", "Benjamin Kaufmann", "Torsten Schaub"], "venue": "AIJ, 187,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2012}, {"title": "Systems integrating answer set programming and constraint programming", "author": ["Michael Gelfond", "Veena S. Mellarkod", "Yuanlin Zhang"], "venue": "Proceedings of LaSh, pp", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2008}, {"title": "Bridging the gap between dual propagation and CNF-based QBF solving", "author": ["Alexandra Goultiaeva", "Martina Seidl", "Armin Biere"], "venue": "Proceedings of DATE,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2013}, {"title": "Structural tractability of propagated constraints", "author": ["Martin J. Green", "Christopher Jefferson"], "venue": "Proceedings of CP,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2008}, {"title": "SAT-TO- SAT: Declarative extension of SAT solvers with new propagators", "author": ["Tomi Janhunen", "Shahab Tasharrofi", "Eugenia Ternovska"], "venue": "in To Appear in the Proceedings of AAAI,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2016}, {"title": "Solving QBF by clause selection", "author": ["Mikol\u00e1s Janota", "Joao Marques-Silva"], "venue": "Proceedings of IJCAI, pp", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2015}, {"title": "An efficient filtering algorithm for disjunction of constraints", "author": ["Olivier Lhomme"], "venue": "Proceedings of CP,", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2003}, {"title": "Arc-consistency filtering algorithms for logical combinations of constraints", "author": ["Olivier Lhomme"], "venue": "Proceedings of CPAIOR,", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2004}, {"title": "Conflict-driven clause learning SAT solvers", "author": ["Jo\u00e3o P. Marques Silva", "In\u00eas Lynce", "Sharad Malik"], "venue": "Handbook of Satisfiability,", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2009}, {"title": "GRASP: A search algorithm for propositional satisfiability", "author": ["Jo\u00e3o P. Marques-Silva", "Karem A. Sakallah"], "venue": "IEEE Transactions on Computers,", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 1999}, {"title": "Hard problems for CSP algorithms", "author": ["David G. Mitchell"], "venue": "Proceedings of AAAI, pp", "citeRegEx": "29", "shortCiteRegEx": "29", "year": 1998}, {"title": "Clause-learning for modular systems", "author": ["David G. Mitchell", "Eugenia Ternovska"], "venue": "Proceedings of LPNMR, pp", "citeRegEx": "30", "shortCiteRegEx": "30", "year": 2015}, {"title": "Constructive disjunction in oz", "author": ["Tobias M\u00fcller", "J\u00f6rg W\u00fcrtz"], "venue": "Proceedings of WLP,", "citeRegEx": "31", "shortCiteRegEx": "31", "year": 1995}, {"title": "Solving SAT and SAT modulo theories: From an abstract Davis\u2013Putnam\u2013 Logemann\u2013Loveland procedure to DPLL(T)", "author": ["Robert Nieuwenhuis", "Albert Oliveras", "Cesare Tinelli"], "venue": "J. ACM,", "citeRegEx": "32", "shortCiteRegEx": "32", "year": 2006}, {"title": "ASP modulo CSP: The clingcon system", "author": ["Max Ostrowski", "Torsten Schaub"], "venue": "TPLP, 12(4\u20135),", "citeRegEx": "33", "shortCiteRegEx": "33", "year": 2012}, {"title": "A comparative study of 2QBF algorithms", "author": ["Darsh P. Ranjan", "Daijue Tang", "Sharad Malik"], "venue": "Online Proceedings of SAT,", "citeRegEx": "34", "shortCiteRegEx": "34", "year": 2004}, {"title": "Lazy satisability modulo theories", "author": ["Roberto Sebastiani"], "venue": "JSAT, 3(3-4),", "citeRegEx": "36", "shortCiteRegEx": "36", "year": 2007}, {"title": "Lazy clause generation: Combining the power of SAT and CP (and MIP?) solving\u2019, in CPAIOR", "author": ["Peter J. Stuckey"], "venue": null, "citeRegEx": "37", "shortCiteRegEx": "37", "year": 2010}, {"title": "A semantic account for modularity in multi-language modelling of search problems", "author": ["Shahab Tasharrofi", "Eugenia Ternovska"], "venue": "Proceedings of FroCoS,", "citeRegEx": "38", "shortCiteRegEx": "38", "year": 2011}, {"title": "Three semantics for modular systems", "author": ["Shahab Tasharrofi", "Eugenia Ternovska"], "venue": "Proceedings of NMR,", "citeRegEx": "39", "shortCiteRegEx": "39", "year": 2014}, {"title": "Modular systems: Semantics, complexity", "author": ["Shahab Tasharrofi", "Eugenia Ternovska"], "venue": "Proceedings of HR workshop,", "citeRegEx": "40", "shortCiteRegEx": "40", "year": 2015}, {"title": "Static and dynamic views on the algebra of modular systems", "author": ["Eugenia Ternovska"], "venue": "Proceedings of NMR,", "citeRegEx": "41", "shortCiteRegEx": "41", "year": 2016}, {"title": "The wellfounded semantics for general logic programs", "author": ["Allen Van Gelder", "Kenneth A. Ross", "John S. Schlipf"], "venue": "J. ACM,", "citeRegEx": "42", "shortCiteRegEx": "42", "year": 1991}, {"title": "Constructive disjunction revisited", "author": ["J\u00f6rg W\u00fcrtz", "Tobias M\u00fcller"], "venue": "Proceedings of KI, pp", "citeRegEx": "43", "shortCiteRegEx": "43", "year": 1996}, {"title": "Towards a symmetric treatment of satisfaction and conflicts in quantified boolean formula evaluation", "author": ["Lintao Zhang", "Sharad Malik"], "venue": "Proceedings of CP,", "citeRegEx": "44", "shortCiteRegEx": "44", "year": 2002}], "referenceMentions": [{"referenceID": 31, "context": "The main challenge is that the programs may be written in different languages (even legacy languages), and rely on different solving technologies Integration on the semantic level has been achieved in the Algebra of Modular Systems [38, 39].", "startOffset": 232, "endOffset": 240}, {"referenceID": 32, "context": "The main challenge is that the programs may be written in different languages (even legacy languages), and rely on different solving technologies Integration on the semantic level has been achieved in the Algebra of Modular Systems [38, 39].", "startOffset": 232, "endOffset": 240}, {"referenceID": 6, "context": "Algebraical operations to manipulate such classes are defined, essentially generalising Codd\u2019s Relation Algebra [10] from tables to classes of structures.", "startOffset": 112, "endOffset": 116}, {"referenceID": 30, "context": "We equip these propagators with an explanation mechanism that generalises lazy clause generation [37], cutting plane generation [11] and counterexample-guided abstraction-refinement [9] (see Section 4, in particular Examples 4.", "startOffset": 97, "endOffset": 101}, {"referenceID": 7, "context": "We equip these propagators with an explanation mechanism that generalises lazy clause generation [37], cutting plane generation [11] and counterexample-guided abstraction-refinement [9] (see Section 4, in particular Examples 4.", "startOffset": 128, "endOffset": 132}, {"referenceID": 5, "context": "We equip these propagators with an explanation mechanism that generalises lazy clause generation [37], cutting plane generation [11] and counterexample-guided abstraction-refinement [9] (see Section 4, in particular Examples 4.", "startOffset": 182, "endOffset": 185}, {"referenceID": 22, "context": "We furthermore extend solvers based on these modular propagators with a conflict-analysis method that generalises resolution from conflict-driven clause learning [28].", "startOffset": 162, "endOffset": 166}, {"referenceID": 14, "context": "Examples include but are not limited to [18, 4, 33].", "startOffset": 40, "endOffset": 51}, {"referenceID": 27, "context": "Examples include but are not limited to [18, 4, 33].", "startOffset": 40, "endOffset": 51}, {"referenceID": 26, "context": "Combined solving is perhaps most developed in the SAT modulo theories (SMT) community, where theory propagations are tightly interleaved with satisfiability solving [32, 36].", "startOffset": 165, "endOffset": 173}, {"referenceID": 29, "context": "Combined solving is perhaps most developed in the SAT modulo theories (SMT) community, where theory propagations are tightly interleaved with satisfiability solving [32, 36].", "startOffset": 165, "endOffset": 173}, {"referenceID": 12, "context": "For example, acyclicity is added to SAT and ASP as a special propagator [16, 7].", "startOffset": 72, "endOffset": 79}, {"referenceID": 3, "context": "For example, acyclicity is added to SAT and ASP as a special propagator [16, 7].", "startOffset": 72, "endOffset": 79}, {"referenceID": 4, "context": "Combining propagators has been studied in detail in constraint programming [8, 20, 23].", "startOffset": 75, "endOffset": 86}, {"referenceID": 16, "context": "Combining propagators has been studied in detail in constraint programming [8, 20, 23].", "startOffset": 75, "endOffset": 86}, {"referenceID": 2, "context": "This research is often limited to a subset of the operations we consider here, for instance studying only conjunction of two constraint programs [5, 1], disjunction of two constraints [31, 43, 24] or connectives from propositional logic applied to constraints [25, 3].", "startOffset": 145, "endOffset": 151}, {"referenceID": 25, "context": "This research is often limited to a subset of the operations we consider here, for instance studying only conjunction of two constraint programs [5, 1], disjunction of two constraints [31, 43, 24] or connectives from propositional logic applied to constraints [25, 3].", "startOffset": 184, "endOffset": 196}, {"referenceID": 36, "context": "This research is often limited to a subset of the operations we consider here, for instance studying only conjunction of two constraint programs [5, 1], disjunction of two constraints [31, 43, 24] or connectives from propositional logic applied to constraints [25, 3].", "startOffset": 184, "endOffset": 196}, {"referenceID": 19, "context": "This research is often limited to a subset of the operations we consider here, for instance studying only conjunction of two constraint programs [5, 1], disjunction of two constraints [31, 43, 24] or connectives from propositional logic applied to constraints [25, 3].", "startOffset": 184, "endOffset": 196}, {"referenceID": 20, "context": "This research is often limited to a subset of the operations we consider here, for instance studying only conjunction of two constraint programs [5, 1], disjunction of two constraints [31, 43, 24] or connectives from propositional logic applied to constraints [25, 3].", "startOffset": 260, "endOffset": 267}, {"referenceID": 1, "context": "This research is often limited to a subset of the operations we consider here, for instance studying only conjunction of two constraint programs [5, 1], disjunction of two constraints [31, 43, 24] or connectives from propositional logic applied to constraints [25, 3].", "startOffset": 260, "endOffset": 267}, {"referenceID": 16, "context": "Second, the traditional treatment of propagation emphasises tractability [20] (the focus is on propagators that can be computed in polynomial time).", "startOffset": 73, "endOffset": 77}, {"referenceID": 30, "context": "Third, we equip our propagators with a learning mechanism that generalizes for instance lazy clause generation [37] from constraint programming and a conflict analysis mechanism that generalises conflict-driven clause learning [28] from SAT [27].", "startOffset": 111, "endOffset": 115}, {"referenceID": 22, "context": "Third, we equip our propagators with a learning mechanism that generalizes for instance lazy clause generation [37] from constraint programming and a conflict analysis mechanism that generalises conflict-driven clause learning [28] from SAT [27].", "startOffset": 227, "endOffset": 231}, {"referenceID": 21, "context": "Third, we equip our propagators with a learning mechanism that generalizes for instance lazy clause generation [37] from constraint programming and a conflict analysis mechanism that generalises conflict-driven clause learning [28] from SAT [27].", "startOffset": 241, "endOffset": 245}, {"referenceID": 31, "context": "In earlier papers [38, 39], the algebra was presented slightly differently; here, we restrict to a minimal syntax; this is discussed in detail in Section 5.", "startOffset": 18, "endOffset": 26}, {"referenceID": 32, "context": "In earlier papers [38, 39], the algebra was presented slightly differently; here, we restrict to a minimal syntax; this is discussed in detail in Section 5.", "startOffset": 18, "endOffset": 26}, {"referenceID": 24, "context": "Mitchell and Ternovska [30] have defined methods to apply the lazy clause generation (LCG) paradigm [14] to solve the model expansion problem for modular systems.", "startOffset": 23, "endOffset": 27}, {"referenceID": 10, "context": "Mitchell and Ternovska [30] have defined methods to apply the lazy clause generation (LCG) paradigm [14] to solve the model expansion problem for modular systems.", "startOffset": 100, "endOffset": 104}, {"referenceID": 35, "context": "largest unfounded set of P with respect to A [42].", "startOffset": 45, "endOffset": 49}, {"referenceID": 6, "context": "This structure encodes that the value of c is in the interval [10, 90] and d in the interval [20, 80].", "startOffset": 62, "endOffset": 70}, {"referenceID": 16, "context": "This structure encodes that the value of c is in the interval [10, 90] and d in the interval [20, 80].", "startOffset": 93, "endOffset": 101}, {"referenceID": 33, "context": "That is not surprising, since Tasharrofi and Ternovska [40] already showed that the projection operation increases the complexity of the task of deciding whether a structure is a member of a given module or not.", "startOffset": 55, "endOffset": 59}, {"referenceID": 13, "context": "For instance in CDCLbased ASP solvers [17, 2, 12], the unfounded set propagator explains its propagation by means of clauses.", "startOffset": 38, "endOffset": 49}, {"referenceID": 0, "context": "For instance in CDCLbased ASP solvers [17, 2, 12], the unfounded set propagator explains its propagation by means of clauses.", "startOffset": 38, "endOffset": 49}, {"referenceID": 8, "context": "For instance in CDCLbased ASP solvers [17, 2, 12], the unfounded set propagator explains its propagation by means of clauses.", "startOffset": 38, "endOffset": 49}, {"referenceID": 30, "context": "Similar explanations are generated for complex constraints in constraint programming (this is the lazy clause generation paradigm [37]) and in SAT modulo theories [15].", "startOffset": 130, "endOffset": 134}, {"referenceID": 11, "context": "Similar explanations are generated for complex constraints in constraint programming (this is the lazy clause generation paradigm [37]) and in SAT modulo theories [15].", "startOffset": 163, "endOffset": 167}, {"referenceID": 23, "context": "[29].", "startOffset": 0, "endOffset": 4}, {"referenceID": 7, "context": "In integer programming, the cutting plane method [11] is used to enforce a solution to be integer.", "startOffset": 49, "endOffset": 53}, {"referenceID": 5, "context": "Similarly, in QBF solving, counterexampleguided abstraction-refinement (the CEGAR methodology) counterexample guided abstraction-refinement [9] starts from the idea to first solve a relaxed problem (an abstraction), and on-the-fly add explanations why a certain solution to the relaxation is rejected.", "startOffset": 140, "endOffset": 143}, {"referenceID": 9, "context": "[13] defined a methodology where complex formulas are grounded on-the-fly.", "startOffset": 0, "endOffset": 4}, {"referenceID": 8, "context": "This particular explanation is used for instance in MinisatID [12] and many other lazy clause generation", "startOffset": 62, "endOffset": 66}, {"referenceID": 9, "context": "When grounding lazily [13], one can consider propagators P\u03c6 that perform some form of propagation for a first-order formula \u03c6.", "startOffset": 22, "endOffset": 26}, {"referenceID": 32, "context": ", [39]).", "startOffset": 2, "endOffset": 6}, {"referenceID": 32, "context": ", [39]).", "startOffset": 2, "endOffset": 6}, {"referenceID": 17, "context": "[21] recently defined a solver that combines two SAT solver.", "startOffset": 0, "endOffset": 4}, {"referenceID": 17, "context": "If the result of this call is not empty, it propagates a conflict and generates an explanation using Explain(A|\u03c4) (see [21] for details).", "startOffset": 119, "endOffset": 123}, {"referenceID": 28, "context": "It actually forms to essence of many SAT-based QBF algorithms [34, 44, 19, 22].", "startOffset": 62, "endOffset": 78}, {"referenceID": 37, "context": "It actually forms to essence of many SAT-based QBF algorithms [34, 44, 19, 22].", "startOffset": 62, "endOffset": 78}, {"referenceID": 15, "context": "It actually forms to essence of many SAT-based QBF algorithms [34, 44, 19, 22].", "startOffset": 62, "endOffset": 78}, {"referenceID": 18, "context": "It actually forms to essence of many SAT-based QBF algorithms [34, 44, 19, 22].", "startOffset": 62, "endOffset": 78}, {"referenceID": 17, "context": "[21] further improved this method by introducing a notion of an underapproximation.", "startOffset": 0, "endOffset": 4}, {"referenceID": 34, "context": "The Algebra of Modular Systems has been extended with a recursion operator (see for instance [41]); researching what are good propagators for this operator is an open challenge.", "startOffset": 93, "endOffset": 97}], "year": 2017, "abstractText": "Solving complex problems can involve non-trivial combinations of distinct knowledge bases and problem solvers. The Algebra of Modular Systems is a knowledge representation framework that provides a method for formally specifying such systems in purely semantic terms. Formally, an expression of the algebra defines a class of structures. Many expressive formalism used in practice solve the model expansion task, where a structure is given on the input and an expansion of this structure in the defined class of structures is searched (this practice overcomes the common undecidability problem for expressive logics). In this paper, we construct a solver for the model expansion task for a complex modular systems from an expression in the algebra and black-box propagators or solvers for the primitive modules. To this end, we define a general notion of propagators equipped with an explanation mechanism, an extension of the algebra to propagators, and a lazy conflict-driven learning algorithm. The result is a framework for seamlessly combining solving technology from different domains to produce a solver for a combined system.", "creator": "LaTeX with hyperref package"}}}