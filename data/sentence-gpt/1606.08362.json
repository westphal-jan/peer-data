{"id": "1606.08362", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "27-Jun-2016", "title": "A Reduction for Optimizing Lattice Submodular Functions with Diminishing Returns", "abstract": "A function $f: \\mathbb{Z}_+^E \\rightarrow \\mathbb{R}_+$ is DR-submodular if it satisfies $f(\\bx + \\chi_i) -f (\\bx) \\ge f(\\by + \\chi_i) - f(\\by)$ for all $\\bx\\le \\by, i\\in E$. Recently, the problem of maximizing a DR-submodular function $f: \\mathbb{Z}_+^E \\rightarrow \\mathbb{R}_+$ subject to a budget constraint $\\|\\bx\\|_1 \\leq B$ as well as additional constraints has received significant attention \\cite{SKIK14,SY15,MYK15,SY16}.\n\n\nIn general, an exponential function is defined by the rule that a given $F \\ge \\b+1 \\leq B$ must satisfy the $f(\\bx + \\chi_i) \\ge f(\\by + \\chi_i) \\ge f(\\by + \\chi_i) -f \\ge f(\\by + \\chi_i) -f \\ge f(\\by + \\chi_i) -f \\ge f(\\by + \\chi_i) -f \\ge f(\\by + \\chi_i) -f \\ge f(\\by + \\chi_i) -f \\ge f(\\by + \\chi_i) -f \\ge f(\\by + \\chi_i) -f \\ge f(\\by + \\chi_i) -f \\ge f(\\by + \\chi_i) -f \\ge f(\\by + \\chi_i) -f \\ge f(\\by + \\chi_i) -f \\ge f(\\by + \\chi_i) -f \\ge f(\\by + \\chi_i) -f \\ge f(\\by + \\chi_i) -f \\ge f(\\by + \\chi_i) -f \\ge f(\\by + \\chi_i) -f \\ge f(\\by + \\chi_i) -f \\ge f(\\by + \\chi_i) -f \\ge f(\\by + \\chi_i) -f \\ge f(\\by + \\chi_i) -f \\ge f(\\by + \\chi_i) -f \\", "histories": [["v1", "Mon, 27 Jun 2016 16:44:44 GMT  (8kb)", "http://arxiv.org/abs/1606.08362v1", null]], "reviews": [], "SUBJECTS": "cs.DS cs.AI cs.LG", "authors": ["alina ene", "huy l nguyen"], "accepted": false, "id": "1606.08362"}, "pdf": {"name": "1606.08362.pdf", "metadata": {"source": "CRF", "title": "A Reduction for Optimizing Lattice Submodular Functions with Diminishing Returns", "authors": ["Alina Ene", "Huy L. Nguyen"], "emails": ["A.Ene@warwick.ac.uk.", "hlnguyen@cs.princeton.edu."], "sections": [{"heading": null, "text": "ar X\niv :1\n60 6.\n08 36\n2v 1\n[ cs\n.D S]\n2 7\nJu n\nIn this note, we give a generic reduction from the DR-submodular setting to the submodular setting. The running time of the reduction and the size of the resulting submodular instance depends only logarithmically on B. Using this reduction, one can translate the results for unconstrained and constrained submodular maximization to the DR-submodular setting for many types of constraints in a unified manner."}, {"heading": "1 Introduction", "text": "Recently, constrained submodular optimization has attracted a lot of attention as a common abstraction of a variety of tasks in machine learning ranging from feature selection, exemplar clustering to sensor placement. Motivated by the use cases where there is a large budget of identical items, a generalization of submodular optimization to integer lattice is proposed by [6]. Previously, submodular functions has been generalized to lattices via the lattice submodular property. A function f : ZE+ \u2192 R+ is lattice submodular if for all x,y \u2208 Z E +,\nf(x) + f(y) \u2265 f(x \u2228 y) + f(x \u2227 y)\nIn the generalization due to [6, 7], a function f is DR-submodular if it satisfies\nf(x+ \u03c7i)\u2212 f(x) \u2265 f(y + \u03c7i)\u2212 f(y)\nfor all x \u2264 y, i \u2208 E (diminishing return property), where \u03c7i is the vector in {0, 1} E that has a 1 in the coordinate corresponding to i and 0 in all other coordinates. It can be shown that any DR-submodular function is also lattice submodular (but the reverse direction is not necessarily true). Similar to submodular functions, the applications can be formulated as maximizing a DR-submodular function f subject to constraints, such as a budget constraint max{f(x) : x \u2208 ZE+, \u2016x\u20161 \u2264 B}. While it is straightforward to reduce optimization of\n\u2217Department of Computer Science and DIMAP, University of Warwick, A.Ene@warwick.ac.uk. \u2020Toyota Technological Institute at Chicago, hlnguyen@cs.princeton.edu.\nDR-submodular function with budget constraint B to optimization of submodular function with B \u00b7E items, the goal of [6] is to find algorithms for this setting with running time logarithmic in B rather than polynomial in B, which follows from the straightforward reduction. Following [6], there have been several works extending problems involving submodular functions to the DR-submodular setting [7, 5, 8].\nIn this note, we give a generic reduction from the DR-submodular setting to the submodular setting. The running time of the reduction and the size of the resulting submodular instance depends only logarithmically on B. Using this reduction, one can translate the results for unconstrained and constrained submodular maximization to the DR-submodular setting for many types of constraints in a unified manner."}, {"heading": "2 The Reduction", "text": "Lemma 1. For any n, there is a decomposition n = a1 + a2 + . . . + at with t \u2264 2 log n + 1 so that for any q \u2264 n, there is a way to express q as the sum of a subset of the multiset {a1, . . . , at}.\nProof. Let n = b02 0 + b12 1 + . . . + bm2 m be the binary representation of n with bm = 1. Let bc1 , bc2 , ..., bcp be all the non-zeroes among b0, . . . , bm\u22121. Let a1 = 1, ai = 2 i\u22122 for 2 \u2264 i \u2264 m + 1, and am+1+j = bcj2 cj for 1 \u2264 j \u2264 p. It is clear that \u2211 i\u2264m+1 ai = 2 m and \u2211\ni ai = n. Consider an arbitrary number 1 < q < n. Let j be the largest bit that is 1 for n but it is 0 for q (j must exist because q < n). Let r be the number that agrees with n on all bits larger or equal to j and has all 0s for the smaller bits. We can form r from a1, . . . , am+1 (which sum up to 2\nm) and the additional numbers from {am+2, . . . , am+1+p} corresponding to the bits equal to 1 from j to m\u2212 1 in the binary representation of r. Notice that r \u2212 q < 2m and it can be written as a sum of numbers from a2, . . . , am+1 (just (r \u2212 q)\u2019s binary representation). By removing those numbers from the representation of q above, we obtain a subset of the ai\u2019s that sums to q.\nCorollary 2. For any n, there is a way to write n = a1 + a2 + . . .+ at with t \u2264 2 log n+1+1/\u01eb so that ai \u2264 \u01ebn \u2200i and for any q \u2264 n, there is a way to express q as the sum of a subset of the multiset {a1, . . . , at}.\nProof. We start with the decomposition of the above lemma and refine it until the condition ai \u2264 \u01ebn \u2200i is satisfied. As long as there exists some ai > \u01ebn, replace ai with two new numbers ai\u2212 \u01ebn and \u01ebn. Each replacement step produces a new term equal to \u01ebn so the number of replacement steps is at most 1/\u01eb. Thus, the number of terms in the decomposition is at most 2 log n+ 1 + 1/\u01eb.\nThe reduction. Suppose we need to optimize f over the domain [B1] \u00d7 [B2] \u00d7 \u00b7 \u00b7 \u00b7 \u00d7 [BE ]. By the above lemma, we can write Bi = ai,1 + . . . + ai,ti with ti \u2264 2 logBi + 1 and any number at most Bi can be written as a sum of a subset of the {ai,j}j \u2019s. Let t = \u2211 i ti. Consider a function\ng defined on the ground set E\u2032 = \u22c3\ni\u2208E{(i, 1), . . . , (i, ti)} defined as follows. Consider y \u2208 {0, 1} E\u2032 .\nLet xi = \u2211\nj yi,jaj and we define g(y) := f(x). By Lemma 1, for any vector x, there is a vector y such that xi = \u2211 j yi,jai,j for all i. Thus, the\nset {g(y)}y captures all of {f(x)}x. Next, we show that g is submodular.\nLemma 3. The function g is submodular.\nProof. Consider 2 vectors y,y\u2032 \u2208 {0, 1}E \u2032 such that yi,j \u2264 y \u2032 i,j for all i, j. Consider an arbitrary element (i0, j0) \u2208 E \u2032 that is not in y\u2032. Let x defined as xi = \u2211 j yi,jai,j and x\n\u2032 defined as x\u2032i =\u2211 j y \u2032 i,jai,j . We have g(y + \u03c7(i0,j0)) \u2212 g(y) = f(x + ai0,j0\u03c7i0) \u2212 f(x) and g(y \u2032 + \u03c7(i0,j0)) \u2212 g(y \u2032) = f(x\u2032 + ai0,j0\u03c7i0)\u2212 f(x \u2032). By the diminishing return property, we have\nf(x+ ai0,j0\u03c7i0)\u2212 f(x) \u2265 f(x \u2032 + ai0,j0\u03c7i0)\u2212 f(x \u2032)."}, {"heading": "3 Modeling Constraints", "text": "We are interested in maximizing f(x) subject to constraints. In this section, we show how to translate constraints on x to constraints for maximizing g(y).\nCardinality constraint. The constraint \u2211\ni xi \u2264 K with K > 1/\u01eb can be translated to\n\u2211\ni,j\nai,jyi,j \u2264 K.\nBy applying Corollary 2, we map from a cardinality constraint to a knapsack constraint where all weights are at most an \u01eb fraction of the budget.\nKnapsack constraint. The knapsack constraint \u2211\ni cixi \u2264 K can be translated to\n\u2211\ni,j\nciai,jyi,j \u2264 K.\nGeneral constraints. Consider the problem max{f(x) : x \u2208 I}, where I \u2286 [B1]\u00d7[B2]\u00d7. . .\u00d7[BE] denotes the set of all solutions that satisfy the constraints.\nWe can apply algorithmic frameworks from the submodular setting \u2014 such as the frameworks based on continuous relaxations and rounding [9, 3] \u2014 to the DR-submodular setting as follows. Let P \u2286 RE+ be a relaxation of I that satisfies the following conditions:\n\u2022 P is downward-closed: if x \u2264 z and z \u2208 P then x \u2208 P.\n\u2022 There is a separation oracle for P: given x, there is an oracle that either correctly decides that x \u2208 P or otherwise returns a hyperplane separating x from P, i.e., a vector v \u2208 RE and D \u2208 R such that \u3008v,x\u3009 \u2265 D and \u3008v, z\u3009 < D for all z \u2208 P.\nWe apply Lemma 1 (or Corollary 2) to obtain the multiset {ai,j}i,j such that, for any vector x, there is a vector y such that xi = \u2211 j yi,jai,j for all i. Define the linear function M : R E\u2032 \u2192 RE where x = M(y) is computed according to xi = \u2211 j yi,jai,j \u2200i. Let g : 2 E\u2032 \u2192 R+ be the submodular function given by the reduction. Let G : [0, 1]E \u2032 \u2192 R+ be the multilinear extension of g:\nG(y) = E[g(R(y))],\nwhere R(y) is a random set that contains each element e \u2208 E\u2032 independently at random with probability ye.\nThus we obtain the following fractional problem: max{G(y) : y \u2208 [0, 1]E \u2032 ,M(y) \u2208 P}. As shown in the following lemma, we can use the separation oracle for P to maximize a linear objective \u3008w,y\u3009, where w \u2208 RE \u2032 , subject to the constraints y \u2208 [0, 1]E \u2032 and M(y) \u2208 P.\nLemma 4. Using the separation oracle for P and an algorithm such as the ellipsoid method, for any vector w \u2208 RE \u2032 , one can find in polynomial time a vector y \u2208 RE \u2032 that maximizes \u3008w,y\u3009 subject to y \u2208 [0, 1]E \u2032 and M(y) \u2208 P.\nProof. It suffices to verify that the separation oracle for P allows us to separate over {y : y \u2208 [0, 1]E \u2032 ,M(y) \u2208 P}. To this end, let y be a vector in RE \u2032 . Separation for the constraint y \u2208 [0, 1]E \u2032 can be done trivially by checking if every coordinate of y is in [0, 1]. Thus, we focus on separation for the constraint M(y) \u2208 P. Using the separation oracle for P, we can check whether M(y) \u2208 P. If yes, then we are done. Otherwise, the oracle returns v \u2208 RE and D \u2208 R such that \u3008v,M(y)\u3009 \u2265 D and \u3008v, z\u3009 < D for all z \u2208 P. Let v\u2032 \u2208 RE \u2032 be v\u2032 = M\u2217(v), where M\u2217 is the adjoint of M i.e. v\u2032i,j = ai,jvi \u2200i, j. Then \u3008v \u2032,y\u3009 = \u3008M\u2217(v),y\u3009 = \u3008v,M(y)\u3009 \u2265 D. Now let y\u2032 be a vector in RE \u2032 such that M(y\u2032) \u2208 P. We have \u3008v\u2032,y\u2032\u3009 = \u3008M\u2217(v),y\u2032\u3009 = \u3008v,M(y\u2032)\u3009 < D. Thus (v\u2032,D) is a hyperplane separating y from {y\u2032 : M(y\u2032) \u2208 P}.\nSince we can solve max{\u3008w,y\u3009 : y \u2208 [0, 1]E \u2032 ,M(y) \u2208 P}, where w \u2208 RE \u2032 , we can approximately solve the fractional problem max{G(y) : y \u2208 [0, 1]E \u2032 ,M(y) \u2208 P} using the (measured) Continuous Greedy algorithm or local search [9, 3, 4]. We note that in some settings, such as when P is a polymatroid polytope1, we can round the resulting fractional solution to the problem max{G(y) : M(y) \u2208 P} and obtain an integral solution (similarly to [8]); in this case, the rounding preserves the value of the fractional solution and thus we obtain an \u03b1-approximation for the problem max{f(x) : x \u2208 I}, where \u03b1 = 1\u2212 1/e for monotone functions and \u03b1 = 1/e for non-monotone functions. The detailed proof is in Theorem 7.\nSome examples of results. Using the reduction above, we immediately get algorithms for maximizing DR-submodular functions subject to various types of constraints. We include a few examples below.\nTheorem 5. There is a 1/2 approximation algorithm for unconstrained DR-submodular maximization with running time O(n+ \u2211 i logBi).\nProof. By the reduction using Lemma 1, we need to solve an unconstrained submodular maximization with O(n + \u2211 i logBi) items. The result follows from applying the Double Greedy algorithm of [2] to the resulting instance of unconstrained submodular maximization.\nTheorem 6. There is a 1 \u2212 1/e \u2212 \u01eb approximation algorithm for maximizing a monotone DRsubmodular function subject to a cardinality constraint B with running time O(m log(m/\u01eb)/\u01eb) where m = n/\u01eb+ \u2211 i logBi.\nProof. If B \u2264 1/\u01eb, the result follows via the trivial reduction of making B copies of every item. Next, we consider the case B > 1/\u01eb. By the reduction using Corollary 2, we need to solve a submodular maximization problem with a knapsack constraint where all weights are at most \u01eb times the budget and there are O(n/\u01eb + \u2211 i logBi) items. The result follows from applying the Density Greedy algorithm with either descending thresholds or lazy evaluation [1].\n1Let \u03c1 : 2E \u2192 Z+ be a monotone submodular function with \u03c1(\u2205) = 0. The polymatroid associated with \u03c1 is the polytope P = {x \u2208 RE+ : \u2211 i\u2208S xi \u2264 \u03c1(S) \u2200S \u2286 E}.\nTheorem 7. There is an \u03b1 approximation algorithm for maximizing a DR-submodular function subject to a polymatroid constraint with running time that is polynomial in n and \u2211 i logBi, where \u03b1 = 1\u2212 1/e if the function is monotone and \u03b1 = 1/e otherwise.\nProof. Let P be the polymatroid polytope. We apply Lemma 1 (or Corollary 2) to obtain the multiset {ai,j}i,j such that, for any vector x, there is a vector y such that xi = \u2211 j yi,jaj for all i. Let g : 2E \u2032 \u2192 R+ be the submodular function given by the reduction. Let G : [0, 1]\nE\u2032 \u2192 R+ be the multilinear extension of g.\nSince we can separate over P in polynomial time using a submodular minimization algorithm, it follows from Lemma 4 that we can optimize any linear (in y) objective over x \u2208 P and xi \u2264 Bi for all i \u2208 E, where x = M(y). Therefore, using the measured Continous Greedy algorithm, we can find an \u03b1-approximate fractional solution to the problem max{G(y) : x \u2208 P, xi \u2264 Bi \u2200i \u2208 E}, where \u03b1 = 1 \u2212 1/e for monotone functions and \u03b1 = 1/e for non-monotone functions. Similarly to [8], we can round the resulting fractional solution without any loss in the approximation. Let z \u2208 ZE be defined as zi = \u230axi\u230b. Define H : [0, 1] E \u2192 R as H(v) = ER[f(z+R(v))] for any v \u2208 R E. Note that H is the multilinear extension of a submodular function agreeing with H on {0, 1}E . Let v \u2208 RE be defined as vi = xi \u2212 \u230axi\u230b. First one can show that H(v) \u2265 G(y) via a hybrid argument. Let z(i) \u2208 ZE be a random integral vector whose first i coordinates are distributed according to M(R(y)) (that is, constructing a randomized rounding of y and then converting it to an integral vector in ZE) and the last |E| \u2212 i coordinates are picked randomly among {zi, zi + 1} so that the expectation is xi. Note that E[f(z (0))] = H(v) and E[f(z(|E|))] = G(y) and we will show that E[f(z(i\u22121))] \u2265 E[f(z(i))]. Indeed, for all j 6= i, z (i) j and z (i\u22121) j are identically distributed so we can couple the randomness so that z (i) j = z (i\u22121) j \u2200j 6= i. Let w be z\n(i) with the ith coordinate zeroed out and define a single variable function g : Z \u2192 R where g(x) = f(w + x \u00b7 ei). Define g\u2032 : R \u2192 R be the piecewise linear function agreeing with g on integral points and g\u2032 does not have any break points other than integral points. By the DR property of f , we have that g\u2032 is concave. Thus, E[g\u2032(z (i) i )] \u2264 g \u2032(E[z (i) i ]). On the other hand, because g \u2032 is linear in [zi, zi + 1], we have E[g\u2032(z (i\u22121) i )] = g \u2032(E[z (i\u22121) i ]) = g \u2032(E[z (i) i ]).\nNext as done in [8, Lemma 13], one can show that the constraints v \u2208 [0, 1]E , z + v \u2208 P are equivalent to a matroid polytope. Thus, one can round v to an integral vector without losing any value in H using strategies such as pipage rounding or swap rounding."}, {"heading": "4 The DR-Submodular Cover Problem", "text": "We conclude this note with some remarks on the DR-submodular cover problem. In this problem, the goal is to minimize the cost c(x) subject to the constraint f(x) \u2265 \u03b1 where f is a DR-submodular function and the cost c is a modular function. This problem has been considered in [7] (in fact, they even consider a more general setting where c is a subadditive function) but there is a mistake in the proof. The proof of [7, Claim 5.2] uses the equality f(x\u2217) = f(xL), which is incorrect since it could happen that f(xL) > f(x\n\u2217). Note that this equality is correct for the usual special case where \u03b1 = maxx\u2208P f(x) but not for the general case considered in [7].\nAlgorithm 1 in [7] in fact fails even for the case where both c and f are modular. For instance, consider E = {1, 2}, f(\u2205) = 0, f({1}) = M,f({2}) = 1, f({1, 2}) = M + 1, c({1}) = M, c({2}) = 1, \u03b1 = 1. The algorithm first picks element 1 as it has the highest density ratio, and then breaks the\nloop as it realizes f is already exceeding \u03b1 = 1. However, the cost of the solution is M , which is arbitrarily larger than the optimal cost, which is 1 for the solution {2}.\nNevertheless, it is known that submodular cover can be reduced to submodular maximization with a knapsack constraint so we can obtain algorithms for DR-submodular objective via the reduction in the previous section."}], "references": [{"title": "Fast algorithms for maximizing submodular functions", "author": ["Ashwinkumar Badanidiyuru", "Jan Vondr\u00e1k"], "venue": "In Proceedings of the Twenty-Fifth Annual ACM-SIAM Symposium on Discrete Algorithms (SODA),", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2014}, {"title": "A tight linear time (1/2)approximation for unconstrained submodular maximization", "author": ["Niv Buchbinder", "Moran Feldman", "Joseph Naor", "Roy Schwartz"], "venue": "SIAM J. Comput.,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2015}, {"title": "Submodular function maximization via the multilinear relaxation and contention resolution schemes", "author": ["Chandra Chekuri", "Jan Vondr\u00e1k", "Rico Zenklusen"], "venue": "SIAM J. Comput.,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2014}, {"title": "A unified continuous greedy algorithm for submodular maximization", "author": ["Moran Feldman", "Joseph Naor", "Roy Schwartz"], "venue": "In Proceedings of the 52nd Annual IEEE Symposium on Foundations of Computer Science (FOCS),", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2011}, {"title": "Budget allocation problem with multiple advertisers: A game theoretic view", "author": ["Takanori Maehara", "Akihiro Yabe", "JP NEC", "Ken-ichi Kawarabayashi"], "venue": "In Proceedings of the 32nd International Conference on Machine Learning (ICML),", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2015}, {"title": "Optimal budget allocation: Theoretical guarantee and efficient algorithm", "author": ["Tasuku Soma", "Naonori Kakimura", "Kazuhiro Inaba", "Ken-ichi Kawarabayashi"], "venue": "In Proceedings of The 31st International Conference on Machine Learning (ICML),", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2014}, {"title": "A generalization of submodular cover via the diminishing return property on the integer lattice", "author": ["Tasuku Soma", "Yuichi Yoshida"], "venue": "In Advances in Neural Information Processing Systems (NIPS),", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2015}, {"title": "Maximizing monotone submodular functions over the integer lattice", "author": ["Tasuku Soma", "Yuichi Yoshida"], "venue": "In International Conference on Integer Programming and Combinatorial Optimization (IPCO),", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2016}, {"title": "Optimal approximation for the submodular welfare problem in the value oracle model", "author": ["Jan Vondr\u00e1k"], "venue": "In Proceedings of the 40th Annual ACM Symposium on Theory of Computing (STOC),", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2008}], "referenceMentions": [{"referenceID": 5, "context": "Recently, the problem of maximizing a DR-submodular function f : ZE+ \u2192 R+ subject to a budget constraint \u2016x\u20161 \u2264 B as well as additional constraints has received significant attention [6, 7, 5, 8].", "startOffset": 183, "endOffset": 195}, {"referenceID": 6, "context": "Recently, the problem of maximizing a DR-submodular function f : ZE+ \u2192 R+ subject to a budget constraint \u2016x\u20161 \u2264 B as well as additional constraints has received significant attention [6, 7, 5, 8].", "startOffset": 183, "endOffset": 195}, {"referenceID": 4, "context": "Recently, the problem of maximizing a DR-submodular function f : ZE+ \u2192 R+ subject to a budget constraint \u2016x\u20161 \u2264 B as well as additional constraints has received significant attention [6, 7, 5, 8].", "startOffset": 183, "endOffset": 195}, {"referenceID": 7, "context": "Recently, the problem of maximizing a DR-submodular function f : ZE+ \u2192 R+ subject to a budget constraint \u2016x\u20161 \u2264 B as well as additional constraints has received significant attention [6, 7, 5, 8].", "startOffset": 183, "endOffset": 195}, {"referenceID": 5, "context": "Motivated by the use cases where there is a large budget of identical items, a generalization of submodular optimization to integer lattice is proposed by [6].", "startOffset": 155, "endOffset": 158}, {"referenceID": 5, "context": "In the generalization due to [6, 7], a function f is DR-submodular if it satisfies", "startOffset": 29, "endOffset": 35}, {"referenceID": 6, "context": "In the generalization due to [6, 7], a function f is DR-submodular if it satisfies", "startOffset": 29, "endOffset": 35}, {"referenceID": 5, "context": "DR-submodular function with budget constraint B to optimization of submodular function with B \u00b7E items, the goal of [6] is to find algorithms for this setting with running time logarithmic in B rather than polynomial in B, which follows from the straightforward reduction.", "startOffset": 116, "endOffset": 119}, {"referenceID": 5, "context": "Following [6], there have been several works extending problems involving submodular functions to the DR-submodular setting [7, 5, 8].", "startOffset": 10, "endOffset": 13}, {"referenceID": 6, "context": "Following [6], there have been several works extending problems involving submodular functions to the DR-submodular setting [7, 5, 8].", "startOffset": 124, "endOffset": 133}, {"referenceID": 4, "context": "Following [6], there have been several works extending problems involving submodular functions to the DR-submodular setting [7, 5, 8].", "startOffset": 124, "endOffset": 133}, {"referenceID": 7, "context": "Following [6], there have been several works extending problems involving submodular functions to the DR-submodular setting [7, 5, 8].", "startOffset": 124, "endOffset": 133}, {"referenceID": 8, "context": "We can apply algorithmic frameworks from the submodular setting \u2014 such as the frameworks based on continuous relaxations and rounding [9, 3] \u2014 to the DR-submodular setting as follows.", "startOffset": 134, "endOffset": 140}, {"referenceID": 2, "context": "We can apply algorithmic frameworks from the submodular setting \u2014 such as the frameworks based on continuous relaxations and rounding [9, 3] \u2014 to the DR-submodular setting as follows.", "startOffset": 134, "endOffset": 140}, {"referenceID": 0, "context": "Let G : [0, 1] \u2032 \u2192 R+ be the multilinear extension of g:", "startOffset": 8, "endOffset": 14}, {"referenceID": 0, "context": "Thus we obtain the following fractional problem: max{G(y) : y \u2208 [0, 1] \u2032 ,M(y) \u2208 P}.", "startOffset": 64, "endOffset": 70}, {"referenceID": 0, "context": "As shown in the following lemma, we can use the separation oracle for P to maximize a linear objective \u3008w,y\u3009, where w \u2208 R \u2032 , subject to the constraints y \u2208 [0, 1] \u2032 and M(y) \u2208 P.", "startOffset": 157, "endOffset": 163}, {"referenceID": 0, "context": "Using the separation oracle for P and an algorithm such as the ellipsoid method, for any vector w \u2208 R \u2032 , one can find in polynomial time a vector y \u2208 R \u2032 that maximizes \u3008w,y\u3009 subject to y \u2208 [0, 1] \u2032 and M(y) \u2208 P.", "startOffset": 191, "endOffset": 197}, {"referenceID": 0, "context": "It suffices to verify that the separation oracle for P allows us to separate over {y : y \u2208 [0, 1] \u2032 ,M(y) \u2208 P}.", "startOffset": 91, "endOffset": 97}, {"referenceID": 0, "context": "Separation for the constraint y \u2208 [0, 1] \u2032 can be done trivially by checking if every coordinate of y is in [0, 1].", "startOffset": 34, "endOffset": 40}, {"referenceID": 0, "context": "Separation for the constraint y \u2208 [0, 1] \u2032 can be done trivially by checking if every coordinate of y is in [0, 1].", "startOffset": 108, "endOffset": 114}, {"referenceID": 0, "context": "Since we can solve max{\u3008w,y\u3009 : y \u2208 [0, 1] \u2032 ,M(y) \u2208 P}, where w \u2208 R \u2032 , we can approximately solve the fractional problem max{G(y) : y \u2208 [0, 1] \u2032 ,M(y) \u2208 P} using the (measured) Continuous Greedy algorithm or local search [9, 3, 4].", "startOffset": 35, "endOffset": 41}, {"referenceID": 0, "context": "Since we can solve max{\u3008w,y\u3009 : y \u2208 [0, 1] \u2032 ,M(y) \u2208 P}, where w \u2208 R \u2032 , we can approximately solve the fractional problem max{G(y) : y \u2208 [0, 1] \u2032 ,M(y) \u2208 P} using the (measured) Continuous Greedy algorithm or local search [9, 3, 4].", "startOffset": 137, "endOffset": 143}, {"referenceID": 8, "context": "Since we can solve max{\u3008w,y\u3009 : y \u2208 [0, 1] \u2032 ,M(y) \u2208 P}, where w \u2208 R \u2032 , we can approximately solve the fractional problem max{G(y) : y \u2208 [0, 1] \u2032 ,M(y) \u2208 P} using the (measured) Continuous Greedy algorithm or local search [9, 3, 4].", "startOffset": 222, "endOffset": 231}, {"referenceID": 2, "context": "Since we can solve max{\u3008w,y\u3009 : y \u2208 [0, 1] \u2032 ,M(y) \u2208 P}, where w \u2208 R \u2032 , we can approximately solve the fractional problem max{G(y) : y \u2208 [0, 1] \u2032 ,M(y) \u2208 P} using the (measured) Continuous Greedy algorithm or local search [9, 3, 4].", "startOffset": 222, "endOffset": 231}, {"referenceID": 3, "context": "Since we can solve max{\u3008w,y\u3009 : y \u2208 [0, 1] \u2032 ,M(y) \u2208 P}, where w \u2208 R \u2032 , we can approximately solve the fractional problem max{G(y) : y \u2208 [0, 1] \u2032 ,M(y) \u2208 P} using the (measured) Continuous Greedy algorithm or local search [9, 3, 4].", "startOffset": 222, "endOffset": 231}, {"referenceID": 7, "context": "We note that in some settings, such as when P is a polymatroid polytope, we can round the resulting fractional solution to the problem max{G(y) : M(y) \u2208 P} and obtain an integral solution (similarly to [8]); in this case, the rounding preserves the value of the fractional solution and thus we obtain an \u03b1-approximation for the problem max{f(x) : x \u2208 I}, where \u03b1 = 1\u2212 1/e for monotone functions and \u03b1 = 1/e for non-monotone functions.", "startOffset": 202, "endOffset": 205}, {"referenceID": 1, "context": "The result follows from applying the Double Greedy algorithm of [2] to the resulting instance of unconstrained submodular maximization.", "startOffset": 64, "endOffset": 67}, {"referenceID": 0, "context": "The result follows from applying the Density Greedy algorithm with either descending thresholds or lazy evaluation [1].", "startOffset": 115, "endOffset": 118}, {"referenceID": 0, "context": "Let G : [0, 1] E \u2192 R+ be the multilinear extension of g.", "startOffset": 8, "endOffset": 14}, {"referenceID": 7, "context": "Similarly to [8], we can round the resulting fractional solution without any loss in the approximation.", "startOffset": 13, "endOffset": 16}, {"referenceID": 0, "context": "Define H : [0, 1] E \u2192 R as H(v) = ER[f(z+R(v))] for any v \u2208 R .", "startOffset": 11, "endOffset": 17}, {"referenceID": 0, "context": "Next as done in [8, Lemma 13], one can show that the constraints v \u2208 [0, 1] , z + v \u2208 P are equivalent to a matroid polytope.", "startOffset": 69, "endOffset": 75}, {"referenceID": 6, "context": "This problem has been considered in [7] (in fact, they even consider a more general setting where c is a subadditive function) but there is a mistake in the proof.", "startOffset": 36, "endOffset": 39}, {"referenceID": 6, "context": "Note that this equality is correct for the usual special case where \u03b1 = maxx\u2208P f(x) but not for the general case considered in [7].", "startOffset": 127, "endOffset": 130}, {"referenceID": 6, "context": "Algorithm 1 in [7] in fact fails even for the case where both c and f are modular.", "startOffset": 15, "endOffset": 18}], "year": 2016, "abstractText": "A function f : ZE+ \u2192 R+ is DR-submodular if it satisfies f(x+\u03c7i)\u2212f(x) \u2265 f(y+\u03c7i)\u2212f(y) for all x \u2264 y, i \u2208 E. Recently, the problem of maximizing a DR-submodular function f : ZE+ \u2192 R+ subject to a budget constraint \u2016x\u20161 \u2264 B as well as additional constraints has received significant attention [6, 7, 5, 8]. In this note, we give a generic reduction from the DR-submodular setting to the submodular setting. The running time of the reduction and the size of the resulting submodular instance depends only logarithmically on B. Using this reduction, one can translate the results for unconstrained and constrained submodular maximization to the DR-submodular setting for many types of constraints in a unified manner.", "creator": "LaTeX with hyperref package"}}}