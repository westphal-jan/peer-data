{"id": "1606.08883", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "28-Jun-2016", "title": "Defending Non-Bayesian Learning against Adversarial Attacks", "abstract": "This paper addresses the problem of non-Bayesian learning over multi-agent networks, where agents repeatedly collect partially informative observations about an unknown state of the world, and try to collaboratively learn the true state. We focus on the impact of the adversarial agents on the performance of consensus-based non-Bayesian learning, where non-faulty agents combine local learning updates with consensus primitives. In particular, we consider the scenario where an unknown subset of agents suffer Byzantine faults -- agents suffering Byzantine faults behave arbitrarily without addressing the problem. In other words, they can do well as non-Bayesian learning, which allows us to estimate the performance of a non-Bayesian learning network by analyzing the available inputs in the network. We then estimate the performance of the network using Bayesian network performance metrics (e.g., SVP, MPS, and PPM) and the predictions of those actors' predictions to those predictions over time. The results were published by the Association for Experimental Bayesian Learning in the journal of the Society for Computational and Experimental Biology (BASA) and the Journal of the Society for Computational and Experimental Biology (BASA).\n\n\n\nAcknowledgments\nThe authors acknowledge all contributions of the researchers.\n\n\nThis paper has been funded by S.L.A.B.T.H.A.T.H.A.T.H.A.T.H.A.T.H.A.T.H.A.T.H.A.T.H.A.T.H.A.T.H.A.T.H.A.T.H.A.T.H.A.T.H.A.T.H.A.T.H.A.T.H.A.T.H.A.T.H.A.T.H.A.T.H.A.T.H.A.T.H.A.T.H.A.T.H.A.T.H.A.T.H.A.T.H.A.T.H.A.T.H.A.T.H.A.T.H.A.T.H.A.T.H.A.T.H.A.T.H.A.T.H.A.T.H.A.T.H.A.T.H.A.T.", "histories": [["v1", "Tue, 28 Jun 2016 20:50:08 GMT  (45kb)", "http://arxiv.org/abs/1606.08883v1", null]], "reviews": [], "SUBJECTS": "cs.DC cs.LG", "authors": ["lili su", "nitin h vaidya"], "accepted": false, "id": "1606.08883"}, "pdf": {"name": "1606.08883.pdf", "metadata": {"source": "CRF", "title": null, "authors": ["Lili Su", "Nitin H. Vaidya"], "emails": ["nhv}@illinois.edu", "(lilisu3@illinois.edu)"], "sections": [{"heading": null, "text": "ar X\niv :1\n60 6.\n08 88\n3v 1\n[ cs\n.D C\n] 2\n8 Ju\nn 20\nagents repeatedly collect partially informative observations about an unknown state of the world, and try to collaboratively learn the true state. We focus on the impact of the adversarial agents on the performance of consensus-based non-Bayesian learning, where non-faulty agents combine local learning updates with consensus primitives. In particular, we consider the scenario where an unknown subset of agents suffer Byzantine faults \u2013 agents suffering Byzantine faults behave arbitrarily.\nWe propose two learning rules.\n\u2013 In our first update rule, each agent updates its local beliefs as (up to normalization) the product of (1) the likelihood of the cumulative private signals and (2) the weighted geometric average of the beliefs of its incoming neighbors and itself. Under reasonable assumptions on the underlying network structure and the global identifiability of the network, we show that all the non-faulty agents asymptotically agree on the true state almost surely. For the case when every agent is failure-free, we show that (with high probability) each agent\u2019s beliefs on the wrong hypotheses decrease at rate O(exp(\u2212Ct2)), where t is the number of iterations, and C is a constant. \u2013 In general when agents may be adversarial, network identifiability condition specified for the above learning rule scales poorly in the number of state candidates m. In addition, the computation complexity per agent per iteration of this learning rule is forbiddingly high. Thus, we propose a modification of our first learning rule, whose complexity per iteration per agent is O(m2n log n), where n is the number of agents in the network. We show that this modified learning rule works under a much weaker network identifiability condition. In addition, this new condition is independent of m.\n\u22c6 This research is supported in part by National Science Foundation award NSF 1421918. Any opinions, findings, and conclusions or recommendations expressed here are those of the authors and do not necessarily reflect the views of the funding agencies or the U.S. government.\n2"}, {"heading": "1 Introduction", "text": "Decentralized hypothesis testing (learning) has received significant amount of attention [1,2,3,5,6,7,8]. The traditional decentralized detection framework consists of a collection of spatially distributed sensors and a fusion center [5,6,7]. The sensors independently collect noisy observations of the environment state, and send only summary of the private observations to the fusion center, where a final decision is made. In the case when the sensors directly send all the private observations, the detection problem can be solved using a centralized scheme. The above framework does not scale well, since each sensor needs to be connected to the fusion center and full reliability of the fusion center is required, which may not be practical as the system scales.\nDistributed hypothesis testing in the absence of fusion center is considered in [2,22,23,21]. In particular, Gale and Kariv [2] studied the distributed hypothesis testing problem in the context of social learning, where fully Bayesian belief update rule is studied. Bayesian update rule is impractical in many applications due to memory and computation constraints of each agent.\nTo avoid the complexity of Bayesian learning, a non-Bayesian learning framework that combines local Bayesian learning with distributed consensus was proposed by Jadbabaie et al. [3], and has attracted much attention [10,14,15,16,11,18,17,13]. Jadbabaie et al. [3] considered the general setting where external signals are observed during each iteration of the algorithm execution. Specifically, the belief of each agent is repeatedly updated as the arithmetic mean of its local Bayesian update and the beliefs of its neighbors \u2013 combining iterative consensus algorithm with local Bayesian update. It is shown [3] that, under this learning rule, each agent learns the true state almost surely. The publication of [3] has inspired significant efforts in designing and analyzing non-Bayesian learning rules with a particular focus on refining the fusion strategies and analyzing the (asymptotic and/or finite time) convergence rates of the refined algorithms [10,14,15,16,11,18,17,13]. In this paper we are particularly interested in the log-linear form of the update rule, in which, essentially, each agent updates its belief as the geometric average of the local Bayesian update and its neighbors\u2019 beliefs [15,10,14,16,11,18,17,13]. The log-linear form (geometric averaging) update rule is shown to converge exponentially fast [10,16]. Taking an axiomatic approach, the geometric averaging fusion is proved to be optimal [13]. An optimization-based interpretation of this rule is presented in [16], using dual averaging method with properly chosen proximal functions. Finite-time convergence rates are investigated independently in [14,11,17]. Both [14] and [18] consider time-varying networks, with slightly different network models. Specifically, [14] assumes that the union of every consecutive B networks is strongly connected, while [18] considers random networks. In this paper, we consider static networks for ease of exposition, although we believe that our results can be easily generalized to time-varying networks.\nThe prior work implicitly assumes that the networked agents are reliable in the sense that they correctly follow the specified learning rules. However, in some practical multi-agent networks, this assumption may not hold. For example, in social networks, it is possible that some agents are adversarial, and try to prevent the true state from being learned by the good agents. Thus, this paper focuses on the fault-tolerant version the non-Bayesian framework proposed in [3]. In particular, we assume that an unknown subset of agents may suffer Byzantine faults.\nAn agent suffering Byzantine fault may not follow the pre-specified algorithms/protocols, and misbehave arbitrarily. For instance, a faulty agent may lie to other agents (possibly non-consistently) about its own estimates. In addition, a faulty agent is assumed to have a complete knowledge of the system, including the network topology, the local functions of all the non-faulty agents, the algorithm specification of the non-faulty agents, the execution of the algorithm, the local estimates of all the non-faulty agents, and contents of messages the other agents send to each other. Also,\n3 the faulty agents can potentially collaborate with each other to prevent the non-faulty agents from achieving their goal. An alternative fault model, where some agents may unexpectedly cease computing and communicate with each other asynchronously, is considered in our companion work [34]. The Byzantine fault-tolerance problem was introduced by Pease et al. [24] and has attracted intensive attention from researchers [25,26,27,30,28,31]. Our goal is to design algorithms that enable all the non-faulty agents to learn the underlying true state.\nThe existing non-Bayesian learning algorithms [10,11,13,14,15,16,17,18] are not robust to Byzantine agents, since the malicious messages sent by the Byzantine agents are indiscriminatingly utilized in the local belief updates. On the other hand, the incorporation of Byzantine consensus is nontrivial, since (i) the effective communication networks are dependent on the all the random local observations, making it non-trivial to adapt analysis of previous algorithms to our setting; and (ii) the problem of identifying tight topological condition for reaching Byzantine multi-dimensional consensus iteratively is open, making it challenging to identify the minimal detectability condition on the networked agents to learn the true environmental state.\nContributions: Our contributions are two-fold.\n\u2013 We first propose an update rule wherein each agent iteratively updates its local beliefs as (up to normalization) the product of (1) the likelihood of the cumulative private signals and (2) the weighted geometric average of the beliefs of its incoming neighbors and itself (using iterative Byzantine multi-dimensional consensus). In contrast to the existing algorithms [14,11], where only the current private signal is used in the update, our proposed algorithm relies on the cumulative private signals. Under reasonable assumptions on the underlying network structure and the global identifiability of the network, we show that all the non-faulty agents asymptotically agree on the true state almost surely. In addition, for the special case when every agent is guaranteed to be failure-free, we show that (with high probability) each agent\u2019s beliefs on the wrong hypotheses decrease at rate O(exp(\u2212Ct2)), where t is the number of iterations, and C is a constant. Thus, our proposed rule may be of independent interest for the failure-free setting considered in [10,11,13,14,15,16,17,18]. \u2013 The local computation complexity per agent of the first learning rule is high due to the adoption of multi-dimensional consensus primitives. More importantly, the network identifiability condition used for that learning rule scales poorly in the number of possible states m. Thus, we propose a modification of our first learning rule, whose complexity per iteration per agent is O(m2n log n), where n is the number of agents in the network. We show that this modified learning rule works under a much weaker global identifiability condition, which is independent of m. We cast the general m\u2013ary hypothesis testing problem into a collection of binary hypothesis testing sub-problems.\nOutline: The rest of the paper is organized as follows. Section 2 presents the problem formulation. Section 3 briefly reviews existing results on vector Byzantine consensus, and matrix representation of the state evolution. Our first algorithm and its correctness analysis are presented in Section 4. Section 5 demonstrates the above learning rule in the special case when f = 0, and presents a finite-time analysis.The modified learning rule and its correctness analysis are summarized in Section 6. Section 7 concludes the paper, and discusses possible extensions."}, {"heading": "2 Problem Formulation", "text": "Network Model: Our network model is similar to the model used in [4,30]. We consider a synchronous system. A collection of n agents (also referred as nodes) are connected by a directed network G(V, E),\n4 where V = {1, . . . , n} and E is the collection of directed edges. For each i \u2208 V, let Ii denote the set of incoming neighbors of agent i. In any execution, up to f agents suffer Byzantine faults. For a given execution, let F denote the set of Byzantine agents, and N denote the set of non-faulty agents. Throughout this paper, we assume that f satisfies the condition implicitly imposed by the given topology conditions mentioned later. We assume that each non-faulty agent knows f , but does not know the actual number of faulty agents |F|. 1 Possible misbehavior of faulty agents includes sending incorrect and mismatching (or inconsistent) messages. The Byzantine agents are also assumed to have complete knowledge of system, including the network topology, underlying running algorithm, the states or even the entire history. The faulty agents may collaborate with each other adaptively [12]. Note that |F| \u2264 f and |N | \u2265 n\u2212 f since at most f agents may fail. (As noted earlier, although we assume a static network topology, our results can be easily generalized to time-varying networks.)\nThroughout this paper, we use the terms agent and node interchangeably.\nObservation Model: Our observation model is identical the model used in [3,11,18]. Let \u0398 = {\u03b81, \u03b82, . . . , \u03b8m} denote a set of m environmental states, which we call hypotheses. In the t-th iteration, each agent independently obtains a private signal about the environmental state \u03b8\u2217, which is initially unknown to every agent in the network. Each agent i knows the structure of its private signal, which is represented by a collection of parameterized marginal distributions Di = {\u2113i(wi|\u03b8)| \u03b8 \u2208 \u0398, wi \u2208 Si}, where \u2113i(\u00b7|\u03b8) is the distribution of private signal when \u03b8 is the true state, and Si is the finite private signal space. For each \u03b8 \u2208 \u0398, and each i \u2208 V, the support of \u2113i(\u00b7|\u03b8) is the whole signal space, i.e., \u2113i(wi|\u03b8) > 0, \u2200wi \u2208 Si and \u2200 \u03b8 \u2208 \u0398. Let sit be the private signal observed by agent i in iteration t, and let st = {s1t , s2t , . . . , snt } be the signal profile at time t (i.e., signals observed by the agents in iteration t). Given an environmental state \u03b8, the signal profile st is generated according to the joint distribution \u21131(s 1 t |\u03b8)\u00d7 \u21132(s2t |\u03b8)\u00d7 \u00b7 \u00b7 \u00b7 \u00d7 \u2113n(snt |\u03b8). In addition, let si1,t be the signal history up to time t for agent i = 1, \u00b7 \u00b7 \u00b7 , n, and let s1,t = {s11,t, s21,t, . . . , sn1,t} be the signal profile history up to time t."}, {"heading": "3 Byzantine Consensus", "text": "In this section, we briefly review relevant exsting results on Byzantine consensus. Byzantine consensus has attracted significant amount of attention [25,26,29,27,30,28,31]. While the past work mostly focus on scalar inputs, the more general vector (or multi-dimensional) inputs have been studied recently [31,29,28]. Complete communication networks are considered in [31,29], where tight conditions on the number of agents are identified. Incomplete communication networks are studied in [28]. Closer to the non-Bayesian learning problem is the class of iterative approximate Byzantine consensus algorithms, where each agent is only allowed to exchange information about its state with its neighbors. In particular, our learning algorithms build upon Byz-Iter algorithm proposed in [28] and a simple algorithm proposed in [30] for iterative Byzantine consensus with vector inputs and scalar inputs, respectively, in incomplete networks. A matrix representation of the non-faulty agents\u2019 states evolution under Byz-Iter algorithm is provided by [28], which also captures the dynamics of the simple algorithm with scalar inputs in [30]. To make this paper self-contained, in this section, we briefly review the algorithm Byz-Iter and its matrix representation.\n3.1 Algorithm Byz-Iter [28]\nAlgorithm Byz-Iter is based on Tverberg\u2019s Theorem [32].\n1 This is because the upper bound f can be learned via long-time performance statistics, whereas, the actual size of F varies across executions, and may be impossible to be predicted in some applications.\n5 Theorem 1. [32] Let f be a nonnegative integer. Let Y be a multiset containing vectors from R m such that |Y | \u2265 (m + 1)f + 1. There exists a partition Y1, Y2, \u00b7 \u00b7 \u00b7 , Yf+1 of Y such that Yi is nonempty for 1 \u2264 i \u2264 f + 1, and the intersection of the convex hulls of Yi\u2019s are nonempty, i.e., \u2229f+1i=1 Conv(Yi) 6= \u00d8, where Conv(Yi) is the convex hull of Yi for i = 1, \u00b7 \u00b7 \u00b7 , f + 1.\nThe proper partition in Theorem 1, and the points in \u2229f+1i=1 Conv(Yi), are referred as Tverberg partition of Y and Tverberg points of Y , respectively.\nFor convenience of presenting our algorithm in Section 4, we present Byz-Iter (described in Algorithm 2) below using One-Iter (described in Algorithm 1) as a primitive. The parameter xi passed to One-Iter at agent i, and yi returned by One-Iter are both m-dimensional vectors. Let vi be the state of agent i that will be iteratively updated, with vit being the state at the end of iteration t and vi0 being the input of agent i. In each iteration t \u2265 1, a non-faulty agent performs the steps inOne-Iter. In particular, in the message receiving step, if a message is not received from some neighbor, that neighbor must be faulty, as the system is synchronous. In this case, the missing message values are set to some default value. Faulty agents may deviate from the algorithm specification arbitrarily. In Byz-Iter, the value returned by One-Iter at agent i is assigned to vit.\nAlgorithm 1: Algorithm One-Iter with input xi at agent i\n1 Zi \u2190 \u00d8; 2 Transmit xi on all outgoing links;\n3 Receive messages on all incoming links. % These message values form a multiset Ri of size |Ii|.% 4 for every C \u2286 Ri \u222a {xi} such that |C| = (m+ 1)f + 1 do 5 add to Zi a Tverberg point of multiset C 6 end 7 Compute yi as follows: yi \u2190 1 1+|Zi| ( xi + \u2211 z\u2208Zi z ) ; 8 Return yi;\nAlgorithm 2: Algorithm Byz-Iter [28]: t-th iteration at agent i\n1 vit \u2190 One-Iter(vit\u22121);\nRemark 1. Note that for each agent i \u2208 N , the computation complexity per iteration is\n\u2126 (( |Ri \u222a {xi}| (m+ 1)f + 1 )) = \u2126 (( |Ii|+ 1 (m+ 1)f + 1 )) .\nIn the worst case, ||Ii|+ 1| = n, and\n\u2126 (( |Ii|+ 1 (m+ 1)f + 1 )) = \u2126 ((\nn\n(m+ 1)f + 1\n))\n= \u2126\n(\n(n\ne\n)(m+1)f+1 )\n.\nSince our first learning rule is based on Algorithm Byz-Iter, the computation complexity of our first proposed algorithm is also high. Nevertheless, our first learning rule contains our main algorithmic\n6 ideas. More importantly, this learning rule can be modified such that the computation complexity per iteration per agent is O(m2n log n). Specifically, the modified learning rule adopts the scalar Byzantine consensus instead of the m\u2013dimensional consensus. This modified learning rule is optimal in the sense that it works under minimal network identifiability requirements.\n3.2 Correctness of Algorithm Byz-Iter\nWe briefly summarize the aspects of correctness proof of Algorithm 2 from [28] that are necessary for our subsequent discussion. By using the Tverberg points in the update of vit above, effectively, the extreme message values (that may potentially be sent by faulty agents) are trimmed away. Informally speaking, trimming certain messages can be viewed as ignoring (or removing) incoming links that carry the outliers. [28] shows that the effective communication network thus obtained can be characterized by a \u201creduced graph\u201d of G(V, E), defined below. It is important to note that the non-faulty agents do not know the identity of the faulty agents.\nDefinition 1 (m\u2013dimensional reduced graph). An m\u2013dimensional reduced graph H(N , EF ) of G(V, E) is obtained by (i) removing all faulty nodes F , and all the links incident on the faulty nodes F ; and (ii) for each non-faulty node (nodes in N ), removing up to mf additional incoming links.\nDefinition 2. A source component in any given m\u2013dimensional reduced graph is a strongly connected component (of that reduced graph), which does not have any incoming links from outside that component.\nIt turns out that the effective communication network is potentially time-varying (partly) due to time-varying behavior of faulty nodes. Assumption 1 below states a condition that is sufficient for reaching approximate Byzantine vector consensus using Algorithm 1 [28].\nAssumption 1 Every m\u2013dimensional reduced graph of G(V, E) contains a unique source component.\nLet Cm be the set of all the m\u2013dimensional reduced graph of G(V, E). Define \u03c7m , |Cm|. Since G(V, E) is finite, we have \u03c7m < \u221e. Let Hm \u2208 Cm be an m\u2013dimensional reduced graph of G(V, E) with source component SHm . Define\n\u03b3m , minHm\u2208Cm |SHm |, (1)\ni.e., \u03b3m is the minimum source component size among all the m\u2013dimensional reduced graphs. Note that \u03b3m \u2265 1 if Assumption 1 holds for a given m.\nTheorem 2. [28] Suppose Assumption 1 holds for a given m \u2265 1. Under Algorithm Byz-Iter, all the non-faulty agents (agents in N ) reach consensus asymptotically, i.e., limt\u2192\u221e |vit \u2212 vjt | = 0,\u2200 i, j \u2208 N .\nThe proof of Theorem 2 relies crucially on a matrix representation of the state evolution."}, {"heading": "3.3 Matrix Representation [28]", "text": "Let |F| = \u03c6 (thus, 0 \u2264 \u03c6 \u2264 f). Without loss of generality, assume that agents 1 through n\u2212 \u03c6 are non-faulty, and agents n\u2212 \u03c6+ 1 to n are Byzantine.\n7 Lemma 1. [28] Suppose Assumption 1 holds for a given m \u2265 1. The state updates performed by the non-faulty agents in the t\u2013th iteration (t \u2265 1) can be expressed as\nvit =\nn\u2212\u03c6 \u2211\nj=1\nAij[t]v j t\u22121, (2)\nwhere A[t] \u2208 R(n\u2212\u03c6)\u00d7(n\u2212\u03c6) is a row stochastic matrix for which there exists an m\u2013dimensional reduced graph Hm[t] with adjacency matrix Hm[t] such that A[t] \u2265 \u03b2mHm[t], where 0 < \u03b2m \u2264 1 is a constant that depends only on G(V, E).\nLet \u03a6(t, r) , A[t] \u00b7 \u00b7 \u00b7A[r] for 1 \u2264 r \u2264 t+ 1. By convention, \u03a6(t, t) = A[t] and \u03a6(t, t+ 1) = I. Note that \u03a6(t, r) is a backward product. Using prior work on coefficients of ergodicity [9], under Assumption 1, it has been shown [28,19] that\nlim t\u2265r, t\u2192\u221e \u03a6(t, r) = 1\u03c0(r), (3)\nwhere \u03c0(r) \u2208 Rn\u2212\u03c6 is a row stochastic vector, and 1 is the column vector with each entry being 1. Recall that \u03c7m is the total number of m\u2013dimensional reduced graphs of G(V, E), and \u03b2m is defined in Lemma 1, and \u03c6 , |F|. The convergence rate in (3) is exponential.\nTheorem 3. [28] For all t \u2265 r \u2265 1, it holds that |\u03a6ij(t, r)\u2212 \u03c0j(r)| \u2264 (1 \u2212 \u03b2\u03bdm)\u2308 t\u2212r+1 \u03bd \u2309, where \u03bd , \u03c7m(n\u2212 \u03c6). Recall that \u03b3m is defined in (1). The next lemma is a consequence of the results in [28].\nLemma 2. [28] For any r \u2265 1, there exists a reduced graph H[r] with source component Sr such that \u03c0i(r) \u2265 \u03b2\u03c7m(n\u2212\u03c6)m for each i \u2208 Sr. In addition, |Sr| \u2265 \u03b3m."}, {"heading": "3.4 Tight Topological Condition for Scalar Iterative Byzantine Consensus", "text": "The above analysis shows that Assumption 1 is sufficient for achieving Byzantine consensus iteratively. For the special case when m = 1,(i.e., the inputs provided at individual non-faulty agents are scalars) it has been shown [30] that Assumption 1 is also necessary.\nTheorem 4. [30] For scalar inputs, iterative approximate Byzantine consensus is achievable among non-faulty agents if and only if every 1-dimensional reduced graph of G(V, E) contains only one source component.\nMoreover, the following simple algorithm (Algorithm 3) works under Assumption 1 when m = 1. In addition, it has been show that the dynamic of the non-faulty agents states admits the same matrix representation as in Subsection 3.3 with the reduced graph being 1\u2013dimensional reduced graph defined in Definition 1.\nWith the above background on Byzantine vector consensus, we are now ready to present our first algorithm and its analysis."}, {"heading": "4 Byzantine Fault-Tolerant Non-Bayesian Learning (BFL)", "text": "In this section, we present our first learning rule, named Byzantine Fault-Tolerant Non-Bayesian Learning (BFL). In BFL, each agent i maintains a belief vector \u00b5i \u2208 Rm, which is a distribution over the set \u0398, with \u00b5i(\u03b8) being the probability with which the agent i believes that \u03b8 is the true\n8 Algorithm 3: Algorithm Scalar Byzantine Consensus: iteration t \u2265 1 [30] 1 Transmit vi[t\u2212 1] on all outgoing links; 2 Receive messages on all incoming links. % These message values wj [t] for each j \u2208 Ii form a multiset\nRi[t] of size |Ii|. %\n3 Sort the received values wj [t] for each j \u2208 Ii in a non-decreasing order; 4 Remove the largest f values and the smallest f values. % Denote the set of indices of incoming\nneighbors whose values have not been removed at iteration t by I\u2217i [t].%\n5 Update vi as follows: vi[t] \u2190 \u2211 j\u2208I\u2217 i [t] wj [t]+v\ni[t\u22121] 1+|I\u2217\ni [t]| ;\nenvironmental state. Since no signals are observed before the execution of an algorithm, the belief \u00b5i is often initially set to be uniform over the set \u0398, i.e., (\n\u00b5i0(\u03b81), \u00b5 i 0(\u03b81), . . . , \u00b5 i 0(\u03b8m)\n)T = ( 1 m , . . . , 1 m )T .\nRecall that \u03b8\u2217 is the true environmental state. We say the networked agents collaboratively learn \u03b8\u2217 if for every non-faulty agent i \u2208 N ,\nlim t\u2192\u221e\n\u00b5it(\u03b8 \u2217) = 1 a.s. (4)\nwhere a.s. denotes almost surely.\nBFL is a modified version of the geometric averaging update rule that has been investigated in previous work [14,15,11,17]. In particular, we modify the averaging rule to take into account Byzantine faults. More importantly, in each iteration, we use the likelihood of the cumulative local observations (instead of the likelihood of the current observation only) to update the local beliefs.\nFor t \u2265 1, the steps to be performed by agent i in the t\u2013th iteration are listed below. Note that faulty agents can deviate from the algorithm specification. The algorithm below uses One-Iter presented in the previous section as a primitive. Recall that si1,t is the cumulative local observations up to iteration t. Since the observations are i.i.d., it holds that \u2113i(s i 1,t|\u03b8) = \u220ft r=1 \u2113i(s i r|\u03b8). So \u2113i(si1,t|\u03b8) can be computed iteratively in Algorithm 4.\nAlgorithm 4: BFL: Iteration t \u2265 1 at agent i 1 \u03b7it \u2190 One-Iter(log \u00b5it\u22121); 2 Observe sit; 3 for \u03b8 \u2208 \u0398 do 4 \u2113i(s i 1,t|\u03b8) \u2190 \u2113i(sit|\u03b8) \u2113i(si1,t\u22121|\u03b8); 5 \u00b5it(\u03b8) \u2190 \u2113i(si1,t|\u03b8) exp(\u03b7it(\u03b8))\u2211m\np=1 \u2113i(s i 1,t|\u03b8p) exp(\u03b7it(\u03b8p))\n;\n6 end\nThe main difference of Algorithm 4 with respect to the algorithms in [14,15,11,17] is that (i) our algorithm uses a Byzantine consensus iteration as a primitive (in line 1), and (ii) \u2113i(s i 1,t|\u03b8) used in line 5 is the likelihood for observations from iteration 1 to t (the previous algorithms instead use \u2113i(s i t|\u03b8) here). Observe that the consensus step is being performed on log of the beliefs, with the result being stored as \u03b7it (in line 1) and used in line 4 to compute the new beliefs.\n9 Recalling the matrix representation of the Byz-Iter algorithm as per Lemma 1, we can write the following equivalent representation of line 1 of Algorithm 4.\n\u03b7it(\u03b8) =\nn\u2212\u03c6 \u2211\nj=1\nAij [t] log \u00b5 j t\u22121(\u03b8) = log\nn\u2212\u03c6 \u220f\nj=1\n\u00b5 j t\u22121(\u03b8) Aij [t], \u2200\u03b8 \u2208 \u0398. (5)\nwhere A[t] is a row stochastic matrix whose properties are specified in Lemma 1. Note that \u00b5it(\u03b8) is random for each i \u2208 N and t \u2265 1, as it is updated according to local random observations. Since the consensus is performed over log \u00b5it \u2208 Rm, the update matrix A[t] is also random. In particular, for each t \u2265 1, matrix A[t] is dependent on all the cumulative observations over the network up to iteration t. This dependency makes it non-trivial to adapt analysis from previous algorithms to our setting. In addition, adopting the local cumulative observation likelihood makes the analysis with Byzantine faults easier."}, {"heading": "4.1 Identifiability", "text": "In the absence of agent failures [3], for the networked agents to detect the true hypothesis \u03b8\u2217, it is sufficient to assume that G(V, E) is strongly connected, and that \u03b8\u2217 is globally identifiable. That is, for any \u03b8 6= \u03b8\u2217, there exists a node j \u2208 V such that the Kullback-Leiber divergence between the true marginal \u2113j(\u00b7|\u03b8\u2217) and the marginal \u2113j(\u00b7|\u03b8), denoted by D (\u2113j(\u00b7|\u03b8\u2217)||\u2113j(\u00b7|\u03b8)), is nonzero; equivalently,\n\u2211 j\u2208V D (\u2113j(\u00b7|\u03b8\u2217)||\u2113j(\u00b7|\u03b8)) 6= 0, (6)\nwhere D (\u2113j(\u00b7|\u03b8\u2217)||\u2113j(\u00b7|\u03b8)) is defined as\nD (\u2113j(\u00b7|\u03b8\u2217)||\u2113j(\u00b7|\u03b8)) , \u2211 wj\u2208Sj \u2113j(wj |\u03b8\u2217) log\n\u2113j(wj |\u03b8\u2217) \u2113j(wj |\u03b8) . (7)\nSince \u03b8\u2217 may change from execution to execution, (6) is required to hold for any choice of \u03b8\u2217. Intuitively speaking, if any pair of states \u03b81 and \u03b82 can be distinguished by at least one agent in the network, then sufficient exchange of local beliefs over strongly connected network will enable every agent distinguish \u03b81 and \u03b82. However, in the presence of Byzantine agents, a stronger global identifiability condition is required. The following assumption builds upon Assumption 1.\nAssumption 2 Suppose that Assumption 1 holds for m = |\u0398|. For any \u03b8 6= \u03b8\u2217, and for any m\u2013dimensional reduced graph H of G(V, E) with SH denoting the unique source component, the following holds\n\u2211\nj\u2208SH D (\u2113j(\u00b7|\u03b8\u2217) \u2016 \u2113j(\u00b7|\u03b8)) 6= 0. (8)\nIn contrast to (6), where the summation is taken over all the agents in the network, in (8), the summation is taken over agents in the source component only. Intuitively, the condition imposed by Assumption 2 is that all the agents in the source component can detect the true state \u03b8\u2217 collaboratively. If iterative consensus is achieved, the accurate belief can be propagated from the source component to every other non-faulty agent in the network.\n10\nRemark 2. We will show later that when Assumption 2 holds, BFL algorithm enables all the nonfaulty agents concentrate their beliefs on the true state \u03b8\u2217 almost surely. That is, Assumption 2 is a sufficient condition for a consensus-based non-Bayesian learning algorithm to exist. However, Assumption 2 is not necessary, observing that Assumption 1 (upon which Assumption 2 builds) is not necessary for m-dimensional Byzantine consensus algorithms to exist. As illustrated by our second learning rule (described later), the adoption of m-dimensional Byzantine consensus primitives is not necessary. Nevertheless, BFL contains our main algorithmic and analytical ideas. In addition, BFL provides an alternative learning rule for the failure-free setting (where no fault-tolerant consensus primitives are needed)."}, {"heading": "4.2 Convergence Results", "text": "Our proof parallels the structure of a proof in [14], but with some key differences to take into account our update rule for the belief vector.\nFor any \u03b81, \u03b82 \u2208 \u0398, and any i \u2208 V, define \u03c8it(\u03b81, \u03b82) and Lt(\u03b81, \u03b82) as follows\n\u03c8it(\u03b81, \u03b82) , log \u00b5it(\u03b81)\n\u00b5it(\u03b82) , Lit(\u03b81, \u03b82) , log\n\u2113i(s i t|\u03b81) \u2113i(s i t|\u03b82) . (9)\nTo show Algorithm 4 solves (4), we will show that \u03c8it(\u03b8, \u03b8 \u2217) a.s.\u2212\u2212\u2192 \u2212\u221e for \u03b8 6= \u03b8\u2217, which implies that \u00b5it(\u03b8)\na.s.\u2212\u2212\u2192 0 for all \u03b8 6= \u03b8\u2217 and for all i \u2208 N , i.e., all non-faulty agents asymptotically concentrate their beliefs on the true hypothesis \u03b8\u2217. We do this by investigating the dynamics of beliefs which is represented compactly in a matrix form.\nFor each \u03b8 6= \u03b8\u2217, and each i \u2208 N = {1, 2, \u00b7 \u00b7 \u00b7 , n\u2212 \u03c6}, we have\n\u03c8it(\u03b8, \u03b8 \u2217) = log\n\u00b5it(\u03b8)\n\u00b5it(\u03b8 \u2217)\n(a) = log\n\n\nn\u2212\u03c6 \u220f\nj=1\n(\n\u00b5 j t\u22121(\u03b8)\n\u00b5 j t\u22121(\u03b8 \u2217)\n)Aij [t]\n\u00d7 \u2113i(s\ni 1,t|\u03b8)\n\u2113i(s i 1,t|\u03b8\u2217)\n\n\n=\nn\u2212\u03c6 \u2211\nj=1\nAij[t] log \u00b5 j t\u22121(\u03b8)\n\u00b5 j t\u22121(\u03b8\n\u2217) + log\n\u2113i(s i 1,t|\u03b8)\n\u2113i(s i 1,t|\u03b8\u2217)\n=\nn\u2212\u03c6 \u2211\nj=1\nAij[t]\u03c8 j t\u22121(\u03b8, \u03b8\n\u2217) + t \u2211\nr=1\nLir(\u03b8, \u03b8\u2217), (10)\nwhere equality (a) follows from (5) and the update of \u00b5i in Algorithm 4, and the last equality follows from (9) and the fact that the local observations are i.i.d. for each agent.\nLet \u03c8t(\u03b8, \u03b8 \u2217) \u2208 Rn\u2212\u03c6 be the vector that stacks \u03c8it(\u03b8, \u03b8\u2217), with the i\u2013th entry being \u03c8it(\u03b8, \u03b8\u2217) for\nall i \u2208 N . The evolution of \u03c8(\u03b8, \u03b8\u2217) can be compactly written as\n\u03c8t(\u03b8, \u03b8 \u2217) = A[t]\u03c8t\u22121(\u03b8, \u03b8 \u2217) + t \u2211\nr=1\nLr(\u03b8, \u03b8\u2217). (11)\nExpanding (11), we get\n\u03c8t(\u03b8, \u03b8 \u2217) = \u03a6(t, 1)\u03c80(\u03b8, \u03b8 \u2217) + t \u2211\nr=1\n\u03a6(t, r + 1)\nr \u2211\nk=1\nLk(\u03b8, \u03b8\u2217). (12)\n11\nFor each \u03b8 \u2208 \u0398 and i \u2208 V, define Hi(\u03b8, \u03b8\u2217) \u2208 Rn\u2212\u03c6 as\nHi(\u03b8, \u03b8 \u2217) ,\n\u2211\nwi\u2208Si \u2113i(wi|\u03b8\u2217) log\n\u2113i(wi | \u03b8) \u2113i(wi | \u03b8\u2217)\n= \u2212D(\u2113i(\u00b7|\u03b8\u2217) \u2016 \u2113i(\u00b7|\u03b8)) by (7) \u2264 0. (13)\nLet H \u2208 C be an arbitrary reduced graph with source component SH. Define C0 and C1 as\n\u2212C0 , min i\u2208V min \u03b81,\u03b82\u2208\u0398;\u03b81 6=\u03b82 min wi\u2208Si\n( log \u2113i(wi|\u03b81) \u2113i(wi|\u03b82) ) , (14)\nC1 , minH\u2208C min \u03b8,\u03b8\u2217\u2208\u0398;\u03b8 6=\u03b8\u2217\n\u2211\ni\u2208SH D(\u2113i(\u00b7|\u03b8\u2217) \u2016 \u2113i(\u00b7|\u03b8)). (15)\nThe constant C0 serves as an universal upper bound on | log \u2113i(wi|\u03b81)\u2113i(wi|\u03b82) | for all choices of \u03b81 and \u03b82, and for all signals. Intuitively, the constant C1 is the minimal detection capability of the source component under Assumption 2.\nDue to |\u0398| = m < \u221e and |Si| < \u221e for each i \u2208 N , we know that C0 < \u221e. Besides, it is easy to see that \u2212C0 \u2264 0 (thus, C0 \u2265 0). In addition, under Assumption 2, we have C1 > 0.\nNow we present a key lemma for our main theorem.\nLemma 3. Under Assumption 2, for any \u03b8 6= \u03b8\u2217, it holds that\n1 t2\nt \u2211\nr=1\n\n\nn\u2212\u03c6 \u2211\nj=1\n\u03a6ij(t, r + 1) r \u2211\nk=1\nLjk(\u03b8, \u03b8\u2217)\u2212 r n\u2212\u03c6 \u2211\nj=1\n\u03c0j(r + 1)Hj(\u03b8, \u03b8 \u2217)\n\n a.s.\u2212\u2212\u2192 0. (16)\nAs it can be seen later, the proof of Lemma 3 is significantly different from the analogous lemma in [14].\nTheorem 5. When Assumption 2 holds, each non-faulty agent i \u2208 N will concentrate its belief on the true hypothesis \u03b8\u2217 almost surely, i.e., \u00b5it(\u03b8) a.s.\u2212\u2212\u2192 0 for all \u03b8 6= \u03b8\u2217.\nProof. Consider any \u03b8 6= \u03b8\u2217. Recall from (12) that\n\u03c8t(\u03b8, \u03b8 \u2217) = \u03a6(t, 1)\u03c80(\u03b8, \u03b8 \u2217) + t \u2211\nr=1\n\u03a6(t, r + 1)\nr \u2211\nk=1\nLk(\u03b8, \u03b8\u2217)\n=\nt \u2211\nr=1\n\u03a6(t, r + 1)\nr \u2211\nk=1\nLk(\u03b8, \u03b8\u2217).\nThe last equality holds as \u00b5i0 is uniform, and \u03c8 i 0(\u03b8, \u03b8 \u2217) = 0 for each i \u2208 N . Since the supports of \u2113i(\u00b7|\u03b8) and \u2113i(\u00b7|\u03b8\u2217) are the whole signal space Si for each agent i \u2208 N , it holds that \u2223 \u2223 \u2223\n\u2113i(wi|\u03b8) \u2113i(wi|\u03b8\u2217)\n\u2223 \u2223\n\u2223 < \u221e for each wi \u2208 Si, and\n0 \u2265 Hi(\u03b8, \u03b8\u2217) \u2265 min wi\u2208Si\n(\nlog \u2113i(wi|\u03b8) \u2113i(wi|\u03b8\u2217)\n)\n\u2265 \u2212 C0 > \u2212\u221e. (17)\n12\nBy (17), we know that |\u2211n\u2212\u03c6j=1 \u03c0j(r+1)Hj(\u03b8, \u03b8\u2217)| \u2264 C0 < \u221e. Due to the finiteness of \u2211n\u2212\u03c6 j=1 \u03c0j(r+ 1)Hj(\u03b8, \u03b8 \u2217), we are able to add and subtract r1 \u2211n\u2212\u03c6 j=1 \u03c0j(r + 1)Hj(\u03b8, \u03b8 \u2217) from (12). We get\n\u03c8t(\u03b8, \u03b8 \u2217) =\nt \u2211\nr=1\n\n\u03a6(t, r + 1)\nr \u2211\nk=1\nLk(\u03b8, \u03b8\u2217)\u2212 r1 n\u2212\u03c6 \u2211\nj=1\n\u03c0j(r + 1)Hj(\u03b8, \u03b8 \u2217)\n\n\n+ t \u2211\nr=1\nr1\nn\u2212\u03c6 \u2211\nj=1\n\u03c0j(r + 1)Hj(\u03b8, \u03b8 \u2217). (18)\nFor each i \u2208 N , we have\n\u03c8it(\u03b8, \u03b8 \u2217) =\nt \u2211\nr=1\n\n\nn\u2212\u03c6 \u2211\nj=1\n\u03a6ij(t, r + 1)\nr \u2211\nk=1\nLjk(\u03b8, \u03b8\u2217)\u2212 r n\u2212\u03c6 \u2211\nj=1\n\u03c0j(r + 1)Hj(\u03b8, \u03b8 \u2217)\n\n\n+\nt \u2211\nr=1\nr\nn\u2212\u03c6 \u2211\nj=1\n\u03c0j(r + 1)Hj(\u03b8, \u03b8 \u2217). (19)\nTo show limt\u2192\u221e \u00b5it(\u03b8) a.s.\u2212\u2212\u2192 0 for \u03b8 6= \u03b8\u2217, it is enough to show \u03c8it(\u03b8, \u03b8\u2217) a.s.\u2212\u2212\u2192 \u2212\u221e. Our convergence proof has similar structure as the analysis in [14]. From Lemma 3, we know that\n1 t2\nt \u2211\nr=1\n\n\nn\u2212\u03c6 \u2211\nj=1\n\u03a6ij(t, r + 1)\nr \u2211\nk=1\nLjk(\u03b8, \u03b8\u2217)\u2212 r n\u2212\u03c6 \u2211\nj=1\n\u03c0j(r + 1)Hj(\u03b8, \u03b8 \u2217)\n\n a.s.\u2212\u2212\u2192 0. (20)\nNext we show that the second term of the right hand side of (19) decreases quadratically in t.\nt \u2211\nr=1\nr\nn\u2212\u03c6 \u2211\nj=1\n\u03c0j(r + 1)Hj(\u03b8, \u03b8 \u2217) \u2264\nt \u2211\nr=1\nr \u2211\nj\u2208Sr \u03c0j(r + 1)Hj(\u03b8, \u03b8\n\u2217) by (13)\n\u2264 t \u2211\nr=1\nr\u03b2\u03c7(n\u2212\u03c6) \u2211\nj\u2208Sr Hj(\u03b8, \u03b8\n\u2217) by Lemma 2\n\u2264 \u2212 t \u2211\nr=1\nr\u03b2\u03c7(n\u2212\u03c6)C1 by (15) and (13)\n\u2264 \u2212 t 2\n2 \u03b2\u03c7(n\u2212\u03c6)C1. (21)\nTherefore, by (19), (20) and (21), almost surely, the following hold\nlim t\u2192\u221e\n1 t2 \u03c8it(\u03b8, \u03b8 \u2217) \u2264 \u22121 2 \u03b2\u03c7(n\u2212\u03c6)C1.\nTherefore, we have \u03c8it(\u03b8, \u03b8 \u2217) a.s.\u2212\u2212\u2192 \u2212\u221e and \u00b5it(\u03b8) a.s.\u2212\u2212\u2192 0 for i \u2208 N and \u03b8 6= \u03b8\u2217, proving Theorem 5.\nWe now present the proof of our key lemma \u2013 Lemma 3.\n13\nProof (Proof of Lemma 3). By (9), we have\n\u2223 \u2223Lir(\u03b8, \u03b8\u2217) \u2223 \u2223 =\n\u2223 \u2223 \u2223 \u2223 log \u2113i(s i t|\u03b8)\n\u2113i(s i t|\u03b8\u2217)\n\u2223 \u2223 \u2223 \u2223\n\u2264 max i\u2208V max \u03b81,\u03b82\u2208\u0398;\u03b81 6=\u03b82 max wi\u2208Si\n\u2223 \u2223 \u2223 \u2223 log \u2113i(wi|\u03b81) \u2113i(wi|\u03b82) \u2223 \u2223 \u2223 \u2223 .\nNote that maxi\u2208V max\u03b81,\u03b82\u2208\u0398;\u03b81 6=\u03b82 maxwi\u2208Si\n\u2223 \u2223\n\u2223 log \u2113i(wi|\u03b81)\n\u2113i(wi|\u03b82)\n\u2223 \u2223 \u2223 is symmetric in \u03b81 and \u03b82. Thus,\n\u2223 \u2223Lir(\u03b8, \u03b8\u2217) \u2223 \u2223 \u2264 max i\u2208V max \u03b81,\u03b82\u2208\u0398;\u03b81 6=\u03b82 max wi\u2208Si\n\u2223 \u2223 \u2223 \u2223 log \u2113i(wi|\u03b81) \u2113i(wi|\u03b82) \u2223 \u2223 \u2223 \u2223 = max i\u2208V max \u03b81,\u03b82\u2208\u0398;\u03b81 6=\u03b82 max wi\u2208Si log \u2113i(wi|\u03b81) \u2113i(wi|\u03b82)\n= max i\u2208V max \u03b81,\u03b82\u2208\u0398;\u03b81 6=\u03b82 max wi\u2208Si \u2212 log \u2113i(wi|\u03b82) \u2113i(wi|\u03b81)\n= \u2212min i\u2208V min \u03b81,\u03b82\u2208\u0398;\u03b81 6=\u03b82 min wi\u2208Si log \u2113i(wi|\u03b82) \u2113i(wi|\u03b81) = \u2212(\u2212C0) = C0 < \u221e. (22)\nThus, adding and subtracting 1 t2 \u2211t r=1 \u2211n\u2212\u03c6 j=1 \u03c0j(r + 1) \u2211r k=1L j k(\u03b8, \u03b8 \u2217) from the first term on the right hand side of (19), we can get\n1 t2\nt \u2211\nr=1\n\n\nn\u2212\u03c6 \u2211\nj=1\n\u03a6ij(t, r + 1) r \u2211\nk=1\nLjk(\u03b8, \u03b8\u2217)\u2212 \u03c0j(r + 1)r n\u2212\u03c6 \u2211\nj=1\nHj(\u03b8, \u03b8 \u2217)\n\n\n= 1\nt2\nt \u2211\nr=1\nn\u2212\u03c6 \u2211\nj=1\n(\u03a6ij(t, r + 1)\u2212 \u03c0j(r + 1)) r \u2211\nk=1\nLjk(\u03b8, \u03b8\u2217)\n+ 1\nt2\nt \u2211\nr=1\nn\u2212\u03c6 \u2211\nj=1\n\u03c0j(r + 1)\n(\nr \u2211\nk=1\nLjk(\u03b8, \u03b8\u2217)\u2212 rHj(\u03b8, \u03b8\u2217) ) . (23)\nFor the first term of the right hand side of (23), we have\n1 t2\n\u2223 \u2223 \u2223 \u2223 \u2223 \u2223 t \u2211\nr=1\nn\u2212\u03c6 \u2211\nj=1\n(\u03a6ij(t, r + 1)\u2212 \u03c0j(r + 1)) r \u2211\nk=1\nLjk(\u03b8, \u03b8\u2217)\n\u2223 \u2223 \u2223 \u2223 \u2223 \u2223\n\u2264 1 t2\nt \u2211\nr=1\nn\u2212\u03c6 \u2211\nj=1\n|\u03a6ij(t, r + 1)\u2212 \u03c0j(r + 1)| r \u2211\nk=1\n\u2223 \u2223\n\u2223 Ljk(\u03b8, \u03b8\u2217)\n\u2223 \u2223 \u2223 (24)\n\u2264 1 t2\nt \u2211\nr=1\nn\u2212\u03c6 \u2211\nj=1\n|\u03a6ij(t, r + 1)\u2212 \u03c0j(r + 1)| rC0 by (22)\n\u2264 1 t2\nt \u2211\nr=1\nn\u2212\u03c6 \u2211\nj=1\n(1\u2212 \u03b2\u03bd)\u2308 t\u2212r\u03bd \u2309rC0 by Theorem 3\n\u2264 1 t2\n(t(n\u2212 \u03c6)C0) t \u2211\nr=1\n(1\u2212 \u03b2\u03bd)\u2308 t\u2212r\u03bd \u2309\n\u2264 (n\u2212 \u03c6)C0 (1\u2212 \u03b2\u03bd)(1\u2212 (1\u2212 \u03b2\u03bd) 1\u03bd )t . (25)\nThus, for every sample path, we have\n1 t2\nt \u2211\nr=1\nn\u2212\u03c6 \u2211\nj=1\n(\u03a6ij(t, r + 1)\u2212 \u03c0j(r + 1)) r \u2211\nk=1\nLjk(\u03b8, \u03b8\u2217) \u2192 0.\n14\nFor the second term of the right hand side of (23), we will show that\n1 t2\nt \u2211\nr=1\nn\u2212\u03c6 \u2211\nj=1\n\u03c0j(r + 1)\n(\nr \u2211\nk=1\nLjk(\u03b8, \u03b8\u2217)\u2212 rHj(\u03b8, \u03b8\u2217) ) a.s.\u2212\u2212\u2192 0,\ni.e., almost surely for any \u01eb > 0 there exists sufficiently large t(\u01eb) such that \u2200 t \u2265 t(\u01eb),\n1 t2\n\u2223 \u2223 \u2223 \u2223 \u2223 \u2223 t \u2211\nr=1\nn\u2212\u03c6 \u2211\nj=1\n\u03c0j(r + 1)\n(\nr \u2211\nk=1\nLjk(\u03b8, \u03b8\u2217)\u2212 rHj(\u03b8, \u03b8\u2217) )\n\u2223 \u2223 \u2223 \u2223 \u2223 \u2223 \u2264 \u01eb. (26)\nWe prove this by dividing r into two ranges r \u2208 {1, \u00b7 \u00b7 \u00b7 , \u221a t} and r \u2208 { \u221a t+ 1, \u00b7 \u00b7 \u00b7 , t}, i.e.,\n1 t2\nt \u2211\nr=1\nn\u2212\u03c6 \u2211\nj=1\n\u03c0j(r + 1)\n(\nr \u2211\nk=1\nLjk(\u03b8, \u03b8\u2217)\u2212 rHj(\u03b8, \u03b8\u2217) )\n= 1\nt2\n\u221a t\n\u2211\nr=1\nn\u2212\u03c6 \u2211\nj=1\n\u03c0j(r + 1)\n(\nr \u2211\nk=1\nLjk(\u03b8, \u03b8\u2217)\u2212 rHj(\u03b8, \u03b8\u2217) )\n+ 1\nt2\nt \u2211\nr= \u221a t+1\nn\u2212\u03c6 \u2211\nj=1\n\u03c0j(r + 1)\n(\nr \u2211\nk=1\nLjk(\u03b8, \u03b8\u2217)\u2212 rHj(\u03b8, \u03b8\u2217) ) . (27)\nFor the first term of the right hand side of (27), we have\n1 t2\n\u2223 \u2223 \u2223 \u2223 \u2223 \u2223\n\u221a t\n\u2211\nr=1\nn\u2212\u03c6 \u2211\nj=1\n\u03c0j(r + 1)\n(\nr \u2211\nk=1\nLjk(\u03b8, \u03b8\u2217)\u2212 rHj(\u03b8, \u03b8\u2217) )\n\u2223 \u2223 \u2223 \u2223 \u2223 \u2223\n\u2264 1 t2\n\u221a t\n\u2211\nr=1\nn\u2212\u03c6 \u2211\nj=1\n\u03c0j(r + 1) (2rC0) by (13) and (22)\n= 1\nt2 (2C0)\n\u221a t\n\u2211\nr=1\nr\n\u2264 C0 ( 1\nt +\n1\nt 3 2\n)\n.\nThus, there exists t1(\u01eb) such that for all t \u2265 t1(\u01eb), it holds that\n1 t2\n\u2223 \u2223 \u2223 \u2223 \u2223 \u2223\n\u221a t\n\u2211\nr=1\nn\u2212\u03c6 \u2211\nj=1\n\u03c0j(r + 1)\n(\nr \u2211\nk=1\nLjk(\u03b8, \u03b8\u2217)\u2212 rHj(\u03b8, \u03b8\u2217) )\n\u2223 \u2223 \u2223 \u2223 \u2223 \u2223 \u2264 \u01eb 2 .\nFor the second term of the right hand side of (27), we have\n1 t2\nt \u2211\nr= \u221a t+1\nn\u2212\u03c6 \u2211\nj=1\n\u03c0j(r + 1)\n(\nr \u2211\nk=1\nLjk(\u03b8, \u03b8\u2217)\u2212 rHj(\u03b8, \u03b8\u2217) )\n= 1\nt\nt \u2211\nr= \u221a t+1\nn\u2212\u03c6 \u2211\nj=1\n\u03c0j(r + 1) r\nt\n(\n1\nr\nr \u2211\nk=1\nLjk(\u03b8, \u03b8\u2217)\u2212Hj(\u03b8, \u03b8\u2217) )\n15\nSince Ljk(\u03b8, \u03b8\u2217)\u2019s are i.i.d., from Strong LLN, we know that 1r \u2211r k=1L j k(\u03b8, \u03b8 \u2217)\u2212Hj(\u03b8, \u03b8\u2217) a.s.\u2212\u2212\u2192 0. That is, with probability 1, the sample path converges. Now, focus on each convergent sample path. For sufficiently large r(\u01eb), it holds that for any r \u2265 r(\u01eb),\n\u2223 \u2223 \u2223 \u2223 \u2223 1 r r \u2211\nk=1\nLjk(\u03b8, \u03b8\u2217)\u2212Hj(\u03b8, \u03b8\u2217) \u2223 \u2223 \u2223 \u2223\n\u2223 \u2264 \u01eb 2 .\nRecall that r \u2265 \u221a t. Thus, we know that there exists sufficiently large t2(\u01eb) such that \u2200 t \u2265 t2(\u01eb),\nr \u2265 \u221a t is large enough and\n\u2223 \u2223 \u2223 \u2223 \u2223 1 r r \u2211\nk=1\nLjk(\u03b8, \u03b8\u2217)\u2212Hj(\u03b8, \u03b8\u2217) \u2223 \u2223 \u2223 \u2223\n\u2223 \u2264 \u01eb 2 .\nThen, we have \u2200 t \u2265 t2(\u01eb),\n1 t2\n\u2223 \u2223 \u2223 \u2223 \u2223 \u2223 t \u2211\nr= \u221a t+1\nn\u2212\u03c6 \u2211\nj=1\n\u03c0j(r + 1)\n(\nr \u2211\nk=1\nLjk(\u03b8, \u03b8\u2217)\u2212 rHj(\u03b8, \u03b8\u2217) )\n\u2223 \u2223 \u2223 \u2223 \u2223 \u2223\n= 1\nt\nt \u2211\nr= \u221a t+1\nn\u2212\u03c6 \u2211\nj=1\n\u03c0j(r + 1) r\nt\n\u2223 \u2223 \u2223 \u2223 \u2223 1 r r \u2211\nk=1\nLjk(\u03b8, \u03b8\u2217)\u2212Hj(\u03b8, \u03b8\u2217) \u2223 \u2223 \u2223 \u2223\n\u2223\n\u2264 1 t\nt \u2211\nr= \u221a t+1\nn\u2212\u03c6 \u2211\nj=1\n\u03c0j(r + 1) r\nt\n\u01eb\n2\n= 1\nt\nt \u2211\nr= \u221a t+1\nr\nt\n\u01eb 2 = \u01eb 2 1 t2\nt \u2211\nr= \u221a t+1\nr\n= \u01eb\n4\n1 t2 (\nt2 \u2212 \u221a t )\n\u2264 \u01eb 2 .\nTherefore, for any \u01eb > 0, there exists max{t1(\u01eb), t2(\u01eb)}, such that for any t \u2265 max{t1(\u01eb), t2(\u01eb)},\n1 t2\n\u2223 \u2223 \u2223 \u2223 \u2223 \u2223 t \u2211\nr=1\nn\u2212\u03c6 \u2211\nj=1\n\u03c0j(r + 1)\n(\nr \u2211\nk=1\nLjk(\u03b8, \u03b8\u2217)\u2212 rHj(\u03b8, \u03b8\u2217) )\n\u2223 \u2223 \u2223 \u2223 \u2223 \u2223 \u2264 \u01eb,\nfor every convergent sample path. In addition, we know a sample path is convergent with probability 1. Thus (26) holds almost surely.\nTherefore, Lemma 3 is proved."}, {"heading": "5 BFL in the absence of Byzantine Agents, i.e., f = 0", "text": "In this section, we present BFL for the special case in the absence of Byzantine agents, i.e., f = 0, named Failure-free BFL. Since f = 0, all the agents in the network are cooperative, and no trimming is needed. Indeed, the BFL for f = 0 is a simple modification of the algorithm proposed in [14].\nFor each time t \u2265 1, we define a matrix that follows the structure of G(V, E) as follows:\nAij ,\n{\n1 |Ii|+1 , j \u2208 Ii \u222a {i} 0, otherwise.\n(28)\n16\nAlgorithm 5: Failure-free BFL\n1 Transmit current belief vector \u00b5it\u22121 on all outgoing edges; 2 Wait until a private signal sit is observed and belief vectors are received from all incoming neighbors Ii; 3 for \u03b8 \u2208 \u0398 do\n4 \u00b5it(\u03b8) \u2190 \u2113i(si1,t|\u03b8)\n\u220f j\u2208Ii\u222a{i} \u00b5 j t\u22121(\u03b8) 1 |Ii|+1\n\u2211m p=1 \u2113i(s i 1,t|\u03b8) \u220f j\u2208Ii\u222a{i} \u00b5 j t\u22121(\u03b8) 1 |Ii|+1\n.\n5 end\nThus, the dynamic of \u03c8it(\u03b8, \u03b8 \u2217) (defined in (9)) under Algorithm 5 can be written as\n\u03c8it(\u03b8, \u03b8 \u2217) = log\n\u00b5it(\u03b8)\n\u00b5it(\u03b8 \u2217)\n= log \u2113i(s\ni 1,t|\u03b8)\n\u220f j\u2208Ii\u222a{i} \u00b5 j t\u22121(\u03b8)\n1 |Ii|+1\n\u2113i(si1,t|\u03b8\u2217) \u220f j\u2208Ii\u222a{i} \u00b5 j t\u22121(\u03b8\n\u2217) 1 |Ii|+1\n= log \u220f\nj\u2208Ii\u222a{i}\n[\n\u00b5 j t\u22121(\u03b8)\n\u00b5 j t\u22121(\u03b8 \u2217)\n] 1 |Ii|+1\n+ log \u2113i(s\ni 1,t | \u03b8)\n\u2113i(si1,t | \u03b8\u2217)\n= log \u220f\nj\u2208Ii\u222a{i}\n[\n\u00b5 j t\u22121(\u03b8)\n\u00b5 j t\u22121(\u03b8 \u2217)\n] 1 |Ii|+1\n+\nt \u2211\nr=1\nlog \u2113i(s\ni r | \u03b8)\n\u2113i(sir | \u03b8\u2217)\n= n \u2211\nj=1\nAij\u03c8 i t\u22121(\u03b8, \u03b8\n\u2217) + t \u2211\nr=1\nLir(\u03b8, \u03b8\u2217) by (9) and (28)\nRecall that \u03c8t(\u03b8, \u03b8 \u2217) \u2208 Rn\u2212\u03c6 is the vector that stacks \u03c8it\u22121(\u03b8, \u03b8\u2217) with the i\u2013th entry being\n\u03c8it\u22121(\u03b8, \u03b8 \u2217) for all i \u2208 N . Since f = 0, i.e., the network is free of failures, it holds that\n0 \u2264 \u03c6 = |F| \u2264 f = 0. Thus, \u03c8t(\u03b8, \u03b8 \u2217) \u2208 Rn. Similar to (12), the evolution of \u03c8t(\u03b8, \u03b8\u2217) can be compactly written as follows.\n\u03c8t(\u03b8, \u03b8 \u2217) = At\u03c80(\u03b8, \u03b8 \u2217) + t \u2211\nr=1\nAt\u2212r r \u2211\nk=1\nLk(\u03b8, \u03b8\u2217)\n=\nt \u2211\nr=1\nAt\u2212r r \u2211\nk=1\nLk(\u03b8, \u03b8\u2217). (29)\nThe last equality holds from the fact that \u03c80(\u03b8, \u03b8 \u2217) = 0.\nAs mentioned before, the non-Bayesian learning rules [14,15,11,17] are consensus-based learning algorithms, wherein agents are required to reach a common decision asymptotically.\nAssumption 3 The underlying communication network G(V, E) is strongly connected. It is easy to see that G(V, E) itself is the only reduced graph of G(V, E), and that Assumption 3 is the special case of Assumption 1 when f = 0. Thus,\n\u03c7m = 1, and \u03bdm = \u03c7m(n\u2212 \u03c6) = n.\n17\nNote that both \u03c7m and \u03bdm are independent of m when f = 0. Henceforth in this section, we drop the subscripts of \u03c7m and \u03bdm for ease of notation.\nSimilar to (3), for any r \u2265 1, we get\nlim t\u2265r, t\u2192\u221e\nAt\u2212r = 1\u03c0.\nSince A is time-invariant, the product limit limt\u2265r, t\u2192\u221eAt\u2212r is also independent of r.\nIt is easy to see that\nA \u2265 1 n H,\nwhere H is the adjacency matrix of the communication graph G(V, E), and that\n\u03c0j \u2265 1\nnn , \u2200 j = 1, \u00b7 \u00b7 \u00b7 , n. (30)\nThe following corollary is a direct consequence of Theorem 3, and its proof is omitted.\nCorollary 1. For all t \u2265 r \u2265 1, it holds that \u2223 \u2223[At\u2212r]ij \u2212 \u03c0j \u2223 \u2223 \u2264 (1\u2212 1 nn )\u2308 t\u2212r n \u2309, where [At\u2212r]ij is the i, j\u2013th entry of matrix At\u2212r.\nIn addition, when f = 0, Assumption 2 becomes\nAssumption 4 Suppose that Assumption 3 holds. For any \u03b8 6= \u03b8\u2217, the following holds\nm \u2211\nj=1\nD (\u2113j(\u00b7|\u03b8\u2217) \u2016 \u2113j(\u00b7|\u03b8)) 6= 0. (31)\nAs an immediate consequence of Theorem 5, we have the following corollary.\nCorollary 2. When Assumption 4 holds, each agent i will concentrate its belief on the true hypothesis \u03b8\u2217 almost surely, i.e., \u00b5it(\u03b8) a.s.\u2212\u2212\u2192 0 for all \u03b8 6= \u03b8\u2217.\nSince Corollary 2 is the special case of Theorem 5 for f = 0, the proof of Corollary 2 is omitted."}, {"heading": "5.1 Finite-Time Analysis of Failure-Free BFL", "text": "In this subsection, we present the convergence rate that is achievable in finite time with high probability. Our proof is similar to the proof presented in [14,17].\nLemma 4. Let \u03bb , ( 1\u2212 ( 1 n )n ) 1 n , and let \u03b8 6= \u03b8\u2217, and consider \u03c8it(\u03b8, \u03b8\u2217) as defined in (9). Then, for each agent i we have\nE [ \u03c8it(\u03b8, \u03b8 \u2217) ] \u2264 nC0 (1\u2212 1 nn )(1\u2212 \u03bb)t\u2212 C1 2nn t2.\n18\nProof. By (29), we have \u03c8it(\u03b8, \u03b8 \u2217) = \u2211t r=1 \u2211n j=1[A t\u2212r]ij \u2211r k=1L j k(\u03b8, \u03b8 \u2217). Taking expectation of \u03c8it(\u03b8, \u03b8 \u2217) with respect to \u2113i(\u00b7 | \u03b8\u2217), we get\nE \u2217 [\u03c8it(\u03b8, \u03b8 \u2217) ] = E\u2217\n\n\nt \u2211\nr=1\nn \u2211\nj=1\n[At\u2212r]ij\nr \u2211\nk=1\nLjk(\u03b8, \u03b8\u2217)\n\n\n= t \u2211\nr=1\nn \u2211\nj=1\n[At\u2212r]ij\nr \u2211\nk=1\nE \u2217 [ Ljk(\u03b8, \u03b8\u2217) ]\n= t \u2211\nr=1\nn \u2211\nj=1\n[At\u2212r]ijrHj(\u03b8, \u03b8 \u2217) by (13)\n= t \u2211\nr=1\nn \u2211\nj=1\n( [At\u2212r]ij \u2212 \u03c0j ) rHj(\u03b8, \u03b8 \u2217) +\nt \u2211\nr=1\nn \u2211\nj=1\n\u03c0jrHj(\u03b8, \u03b8 \u2217). (32)\nFor the first term in the right hand side of (32), we have\nt \u2211\nr=1\nn \u2211\nj=1\n( [At\u2212r]ij \u2212 \u03c0j ) rHj(\u03b8, \u03b8 \u2217) \u2264\nt \u2211\nr=1\nn \u2211\nj=1\n\u2223 \u2223[At\u2212r]ij \u2212 \u03c0j \u2223 \u2223 r |Hj(\u03b8, \u03b8\u2217)|\n\u2264 t \u2211\nr=1\nn \u2211\nj=1\n[\n1\u2212 1 nn\n]\u2308 t\u2212r n \u2309 rC0 by Corollary 1, and (14)\n= nC0\nt \u2211\nr=1\n[\n1\u2212 1 nn\n]\u2308 t\u2212r n \u2309 r\n\u2264 nC0 (1\u2212 1\nnn )(1\u2212 \u03bb)t. (33)\nSince G(V, E) is the only source component, C1 (defined in (15)) becomes\nC1 = min \u03b8,\u03b8\u2217\u2208\u0398;\u03b8 6=\u03b8\u2217\nn \u2211\ni=1\nD(\u2113i(\u00b7|\u03b8\u2217) \u2016 \u2113i(\u00b7|\u03b8)).\nThus, for the second term in the right hand side of (32), we get\nt \u2211\nr=1\nn \u2211\nj=1\n\u03c0jrHj(\u03b8, \u03b8 \u2217) \u2264\nt \u2211\nr=1\nn \u2211\nj=1\n1\nnn rHj(\u03b8, \u03b8\n\u2217) by (30) and (13)\n= 1\nnn\nt \u2211\nr=1\nr\nn \u2211\nj=1\nHj(\u03b8, \u03b8 \u2217)\n\u2264 \u2212 1 nn\nt \u2211\nr=1\nrC1\n\u2264 \u2212 C1 2nn t2. (34)\n19\nBy (33) and (34), (32) becomes\nE \u2217 [\u03c8it(\u03b8, \u03b8 \u2217) ]\n= t \u2211\nr=1\nn \u2211\nj=1\n( [At\u2212r]ij \u2212 \u03c0j ) rHj(\u03b8, \u03b8 \u2217) +\nt \u2211\nr=1\nn \u2211\nj=1\n\u03c0jrHj(\u03b8, \u03b8 \u2217)\n\u2264 nC0 (1\u2212 1 nn )(1\u2212 \u03bb)t\u2212 C1 2nn t2, (35)\nproving the lemma.\nSimilar to [14,17], we also use McDiarmid\u2019s Inequality.\nTheorem 6 (McDiarmid\u2019s Inequality). Let X1, \u00b7 \u00b7 \u00b7 ,Xt be independent random variables and consider the mapping H : X t \u2192 R. If for r = 1, \u00b7 \u00b7 \u00b7 , t, and every sample x1, \u00b7 \u00b7 \u00b7 , xt, x\u2032r \u2208 X , the function H satisfies\n\u2223 \u2223H(x1, \u00b7 \u00b7 \u00b7 , xr, \u00b7 \u00b7 \u00b7 , xt)\u2212H(x1, \u00b7 \u00b7 \u00b7 , x\u2032r, \u00b7 \u00b7 \u00b7 , xt) \u2223 \u2223 \u2264 cr,\nthen for all \u01eb > 0,\nP [|H(x1, \u00b7 \u00b7 \u00b7 , xt)\u2212 E[H(x1, \u00b7 \u00b7 \u00b7 , xt)]| \u2265 \u01eb] \u2264 exp { \u22122\u01eb2 \u2211t\nr=1 c 2 r\n}\n.\nTheorem 7. Under Assumption 4, for any \u03c1 \u2208 (0, 1), there exists an integer T (\u03c1) such that with probability 1\u2212 \u03c1, for all t \u2265 T (\u03c1) and for all \u03b8 6= \u03b8\u2217, we have\n\u00b5it(\u03b8) \u2264 exp (\nnC0\n(1\u2212 1 nn\n)(1\u2212 \u03bb) t\u2212 C1 4nn t2\n)\nwhere C0 and C1 are defined in (14) and (15) respectively, and T (\u03c1) = 64C20n 2n\n3C21 log 1 \u03c1 .\nProof. Since \u00b5it(\u03b8 \u2217) \u2208 (0, 1], we have\n\u00b5it(\u03b8) \u2264 \u00b5it(\u03b8)\n\u00b5it(\u03b8 \u2217)\n= exp ( \u03c8it(\u03b8, \u03b8 \u2217) ) .\nThus, we have\nP\n( \u00b5it(\u03b8) \u2265 exp (\nnC0\n(1\u2212 1 nn\n)(1\u2212 \u03bb) t\u2212 C1 4nn t2\n)) \u2264 P ( \u03c8it(\u03b8, \u03b8 \u2217) \u2265 nC0\n(1\u2212 1 nn\n)(1\u2212 \u03bb)t\u2212 C1 4nn t2\n)\n\u2264 P (\n\u03c8it(\u03b8, \u03b8 \u2217)\u2212 E\u2217 [ \u03c8it(\u03b8, \u03b8 \u2217) ] \u2265 C1 4nn\nt2 ) .\n20\nNote that \u03c8it(\u03b8, \u03b8 \u2217) is a function of the random vector s1, \u00b7 \u00b7 \u00b7 , st. For a given sample path\ns1, \u00b7 \u00b7 \u00b7 , st, and for all p \u2208 {1, \u00b7 \u00b7 \u00b7 , t}, we have\nmax sp\u2208S1\u00d7\u00b7\u00b7\u00b7\u00d7St\n\u03c8it(\u03b8, \u03b8 \u2217)\u2212 min sp\u2208S1\u00d7\u00b7\u00b7\u00b7\u00d7St \u03c8it(\u03b8, \u03b8 \u2217)\n= max sp\u2208S1\u00d7\u00b7\u00b7\u00b7\u00d7St\nt \u2211\nr=1\nn \u2211\nj=1\n[At\u2212r]ij\nr \u2211\nk=1\nLk(\u03b8, \u03b8\u2217)\u2212 min sp\u2208S1\u00d7\u00b7\u00b7\u00b7\u00d7St\nt \u2211\nr=1\nn \u2211\nj=1\n[At\u2212r]ij\nr \u2211\nk=1\nLk(\u03b8, \u03b8\u2217)\n= max sp\u2208S1\u00d7\u00b7\u00b7\u00b7\u00d7St\nt \u2211\nr=p\nn \u2211\nj=1\n[At\u2212r]ij\nr \u2211\nk=1\nLk(\u03b8, \u03b8\u2217)\u2212 min sp\u2208S\nt \u2211\nr=p\nn \u2211\nj=1\n[At\u2212r]ij\nr \u2211\nk=1\nLk(\u03b8, \u03b8\u2217)\n= max sp\u2208S1\u00d7\u00b7\u00b7\u00b7\u00d7St\nt \u2211\nr=p\nn \u2211\nj=1\n[At\u2212r]ijLp(\u03b8, \u03b8\u2217)\u2212 min sp\u2208S\nt \u2211\nr=p\nn \u2211\nj=1\n[At\u2212r]ijLp(\u03b8, \u03b8\u2217)\n\u2264 t \u2211\nr=p\nn \u2211\nj=1\n[At\u2212r]ijC0 + t \u2211\nr=p\nn \u2211\nj=1\n[At\u2212r]ijC0\n= 2C0(t\u2212 p+ 1) , cp.\nBy McDiarmid\u2019s inequality (Theorem 6), we obtain that\nP\n(\n\u03c8\u2217t (\u03b8, \u03b8 \u2217)\u2212 E\u2217 [\u03c8\u2217t (\u03b8, \u03b8\u2217)] \u2265\nC1 4nn t2 ) \u2264 exp ( \u2212 2 C21 16n2n t4\n\u2211t p=1(2C0(t\u2212 p+ 1))2\n)\n\u2264 exp ( \u2212 3C 2 1\n64C20n 2n\nt\n)\n,\nwhere the last inequality follows from the fact that\nt(t+ 1)(2t+ 1) \u2264 4t3 \u2200 t \u2265 2,\nwhich can be shown by induction. Therefore, for a given confidence level \u03c1, in order to have\nP\n( \u00b5it(\u03b8) \u2265 exp (\nnC0\n(1\u2212 1 nn\n)(1\u2212 \u03bb)t\u2212 C1 4nn t2\n))\n\u2264 \u03c1,\nwe require that\nt \u2265 T (\u03c1) = 64C 2 0n 2n\n3C21 log\n1 \u03c1 .\nRemark 3. The above finite-time analysis is not directly applicable for the general case when f > 0, due to the fact that the local beliefs are dependent on all the observations collected so far as well as all the future observations.\nRemark 4. Our analysis for the special when f = 0 also works for time-varying networks [14]. In addition, with identical analysis, we are able to adapt the failure-free scheme to work in the more general setting where there is no underlying true state, and the goal is to have the agents collaboratively identify an optimal \u03b8 \u2208 \u0398 that best explains all the observations obtained over the whole network.\n21"}, {"heading": "6 Modified BFL and Minimal Network Identifiability", "text": "To reduce the computation complexity per iteration in general, and to identify the minimal (tight) global identifiability of the network for any consensus-based learning rule of interest to learn the true state, we propose a modification of the above learning rule, which works under much weaker network topology and global identifiability condition.\nWe decompose the m-ary hypothesis testing problem into m(m\u22121) (ordered) binary hypothesis testing problems. For each pair of hypotheses \u03b81 and \u03b82, each non-faulty agent updates the likelihood ratio of \u03b81 over \u03b82 as follows. Let r i t(\u03b81, \u03b82) be the log likelihood ratio of \u03b81 over \u03b82 kept by agent i at the end of iteration t. Our modified learning rule applies consensus procedures to log likelihood ratio, i.e., rit(\u03b81, \u03b82), which is a scalar. For Algorithm 6, we only require scalar iterative Byzantine (approximate) consensus among the non-faulty agents to be achievable.\nWhen scalar consensus is achievable, the following assumption on the identifiability of the network to detect \u03b8\u2217 is minimal, meaning that if this assumption is not satisfied, then no correct consensus-based non-Bayesian learning exists.\nAssumption 5 Suppose that every 1-dimensional reduced graph of G(V, E) contains only one source component. For any \u03b8 6= \u03b8\u2217, and for any 1-dimensional reduced graph H1 of G(V, E) with SH1 denoting the unique source component, the following holds\n\u2211\nj\u2208SH1\nD (\u2113j(\u00b7|\u03b8\u2217) \u2016 \u2113j(\u00b7|\u03b8)) 6= 0. (36)\nAssumption 5 is minimal for the following reasons: (1) For any consensus-based learning rule to work, the communication network G(V, E) should support consensus with scalar inputs. That is, every 1-dimensional reduced graph of G(V, E) must contain only one source component. (2) Under some faulty behaviors of the Byzantine agents, one particular 1\u2013dimensional reduced graph may govern the entire dynamics of ri(\u03b81, \u03b82). If (36) does not hold for that reduced graph, then the good agents may not able to distinguish \u03b81 from \u03b82.\nAlgorithm 6: Pairwise Learning\n1 Initialization: for \u03b81, \u03b82 \u2208 \u0398, and \u03b81 6= \u03b82 do 2 ri0(\u03b81, \u03b82) \u2190 0; 3 end 4 while t \u2265 1 do 5 for \u03b81, \u03b82 \u2208 \u0398, and \u03b81 6= \u03b82 do 6 Transmit current belief vector rit\u22121(\u03b81, \u03b82) on all outgoing edges; 7 Wait until a private signal sit is observed and log likelihood ratios r\u0303 j t\u22121(\u03b81, \u03b82) are received from all incoming neighbors Ii; 8 Sort the received log likelihood ratios r\u0303jt\u22121(\u03b81, \u03b82) in a non-decreasing order, and\nremove the smallest f values and the largest f values. % Denote the set of indices of incoming neighbors whose ratios have not been removed at iteration t by I\u2217i [t].%\n9 rit(\u03b81, \u03b82) \u2190 \u2211 j\u2208I\u2217 i [t] r\u0303 j t\u22121(\u03b81,\u03b82)+r i t\u22121(\u03b81,\u03b82)\n|I\u2217[t]|+1 + log \u2113i(si1,t|\u03b81) \u2113i(si1,t|\u03b82) .\n10 end\n11 end\n22\nFor each iteration, the computation complexity per agent (non-faulty) can be calculated as follows. The cost-dominant procedure in each iteration is sorting the received log likelihood ratios, which takes O(n log n) operations. In total, we have m(m\u2212 1) order pairs of hypotheses. Thus, the total computation per agent per iteration is O(m2n log n).\nTheorem 8. Suppose Assumption 5 holds. Under Algorithm 6, for any \u03b8 6= \u03b8\u2217, the following holds:\nrit(\u03b8 \u2217, \u03b8) a.s.\u2212\u2212\u2192 +\u221e, and rit(\u03b8, \u03b8\u2217) a.s.\u2212\u2212\u2192 \u2212\u221e.\nProof. By [20], we know that for each pair of hypotheses \u03b81 and \u03b82, there exists a row-stochastic matrix M1,2[t] \u2208 R(n\u2212\u03c6)\u00d7(n\u2212\u03c6) such that\nrit(\u03b81, \u03b82) =\nn\u2212\u03c6 \u2211\nj=1\nM1,2ij [t]r j t\u22121(\u03b81, \u03b82) + log\n\u2113i(s i 1,t | \u03b81) \u2113i(si1,t | \u03b82) . (37)\nNote that matrix M1,2 depends on the choice of hypotheses \u03b81 and \u03b82. For a given pair of hypotheses \u03b81 and \u03b82, let rt(\u03b81, \u03b82) \u2208 Rn\u2212\u03c6 be the vector that stacks rit(\u03b81, \u03b82). The evolution of r(\u03b81, \u03b82) can be compactly written as\nrt(\u03b81, \u03b82) = M 1,2[t]rt\u22121(\u03b81, \u03b82) +\nt \u2211\nr=1\nLr(\u03b81, \u03b82)\n= t \u2211\nr=1\n\u03a61,2(t, r + 1) r \u2211\nk=1\nLk(\u03b81, \u03b82), (38)\nwhere \u03a61,2(t, r+1) , M1,2[t]M1,2[t\u2212 1] \u00b7 \u00b7 \u00b7M1,2[r+1] for r \u2264 t, \u03a61,2(t, t) , M1,2[t] and \u03a61,2(t, t+ 1) , I. We do the analysis for each pair of \u03b81 and \u03b82 separately.\nThe remaining proof is identical to the proof of Theorem 5, and is omitted.\nProposition 1. Suppose there exists \u03b8\u0303 \u2208 \u0398 such that for any \u03b8 6= \u03b8\u0303, it holds that rit(\u03b8\u0303, \u03b8) a.s.\u2212\u2212\u2192 +\u221e, and rit(\u03b8, \u03b8\u0303) a.s.\u2212\u2212\u2192 \u2212\u221e. Then \u03b8\u0303 = \u03b8\u2217.\nProof. We prove this proposition by contradiction. Suppose there exists \u03b8\u0303 6= \u03b8\u2217 \u2208 \u0398 such that for any \u03b8 6= \u03b8\u0303, it holds that rit(\u03b8\u0303, \u03b8) a.s.\u2212\u2212\u2192 +\u221e, and rit(\u03b8, \u03b8\u0303) a.s.\u2212\u2212\u2192 \u2212\u221e. Then we know that rit(\u03b8\u0303, \u03b8\u2217)\na.s.\u2212\u2212\u2192 +\u221e and rit(\u03b8\u2217, \u03b8\u0303) a.s.\u2212\u2212\u2192 \u2212\u221e, contradicting Theorem 8. Thus, Proposition 1 is true."}, {"heading": "7 Conclusion", "text": "This paper addresses the problem of consensus-based non-Bayesian learning over multi-agent networks when an unknown subset of agents may be adversarial (Byzantine). We propose two learning rules, and characterize the tight network identifiability condition for any consensus-based learning rule of interest to exist. In our first update rule, each agent updates its local beliefs as (up to normalization) the product of (1) the likelihood of the cumulative private signals and (2) the weighted geometric average of the beliefs of its incoming neighbors and itself. Under reasonable assumptions on the underlying network structure and the global identifiability of the network, we show that all the non-faulty agents asymptotically agree on the true state almost surely. For the case when every agent is failure-free, we show that (with high probability) each agent\u2019s beliefs on the wrong\n23\nhypotheses decrease at rate O(exp(\u2212Ct2)), where t is the number of iterations, and C is a constant. In general when agents may be adversarial, network identifiability condition specified for the above learning rule scales poorly in m. In addition, the computation complexity per agent per iteration of this learning rule is forbiddingly high. Thus, we propose a modification of our first learning rule, whose complexity per iteration per agent is O(m2n log n). We show that this modified learning rule works under a much weaker global identifiability condition that is independent of m.\nWe so far focussed on synchronous system and static network, our results may be generalizable to asynchronous as well as time varying network.\nThroughout this paper, we assume that consensus among non-faulty agents needs to be achieved. Although this is necessary for the family of consensus-based algorithms (by definition), this is not the case for the non-faulty agents to collaboratively learn the true state in general. Indeed, there is a tradeoff between the capability of the network to reach consensus and the tight condition of the network detectability. For instance, if the network is disconnected, then information cannot be propagated across the connected components. Thus, the non-faulty agents in each connected component have to be able to learn the true state. We leave investigating the above tradeoff as future work."}], "references": [{"title": "Decentralized detection in sensor networks", "author": ["J.-F. Chamberland", "V.V. Veeravalli"], "venue": "IEEE Transactions on Signal Processing,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2003}, {"title": "Bayesian learning in social networks", "author": ["D. Gale", "S. Kariv"], "venue": "Games and Economic Behavior,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2003}, {"title": "Non-bayesian social learning", "author": ["A. Jadbabaie", "P. Molavi", "A. Sandroni", "A. Tahbaz-Salehi"], "venue": "Games and Economic Behavior,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2012}, {"title": "Reaching approximate byzantine consensus with multi-hop communication", "author": ["L. Su", "N.H. Vaidya"], "venue": "In Proceedings of International Symposium on Stabilization, Safety, and Security of Distributed Systems (SSS),", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2015}, {"title": "Decentralized detection by a large number of sensors", "author": ["J. Tsitsiklis"], "venue": "Mathematics of Control, Signals and Systems,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 1988}, {"title": "Decentralized detection", "author": ["J.N. Tsitsiklis"], "venue": "Advances in Statistical Signal Processing,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 1993}, {"title": "Distributed Detection and Data Fusion", "author": ["P.K. Varshney"], "venue": "Springer Science & Business Media,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2012}, {"title": "Stochastic Processes in Engineering Systems", "author": ["E. Wong", "B. Hajek"], "venue": "Springer Science & Business Media,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2012}, {"title": "Weak ergodicity in non-homogeneous markov chains", "author": ["J. Hajnal", "M. Bartlett"], "venue": "In Mathematical Proceedings of the Cambridge Philosophical Society,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 1958}, {"title": "Information heterogeneity and the speed of learning in social networks", "author": ["A. Jadbabaie", "P. Molavi", "A. Tahbaz-Salehi"], "venue": "Columbia Business School Research Paper,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2013}, {"title": "Social learning and distributed hypothesis testing", "author": ["A. Lalitha", "A. Sarwate", "T. Javidi"], "venue": "In Information Theory (ISIT),", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2014}, {"title": "Distributed Algorithms", "author": ["N.A. Lynch"], "venue": null, "citeRegEx": "12", "shortCiteRegEx": "12", "year": 1996}, {"title": "Foundations of non-bayesian social learning", "author": ["P. Molavi", "A. Jadbabaie"], "venue": "Columbia Business School Research Paper,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2015}, {"title": "Nonasymptotic convergence rates for cooperative learning over timevarying directed graphs", "author": ["A. Nedi\u0107", "A. Olshevsky", "C.A. Uribe"], "venue": "arXiv preprint arXiv:1410.1977,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2014}, {"title": "Distributed parameter estimation in networks", "author": ["K.R. Rad", "A. Tahbaz-Salehi"], "venue": "In IEEE Conference on Decision and Control (CDC),", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2010}, {"title": "Exponentially fast parameter estimation in networks using distributed dual averaging", "author": ["S. Shahrampour", "A. Jadbabaie"], "venue": "In IEEE Conference on Decision and Control (CDC),", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2013}, {"title": "Distributed detection: Finite-time analysis and impact of network topology", "author": ["S. Shahrampour", "A. Rakhlin", "A. Jadbabaie"], "venue": "arXiv preprint arXiv:1409.8606,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2014}, {"title": "Finite-time analysis of the distributed detection problem", "author": ["S. Shahrampour", "A. Rakhlin", "A. Jadbabaie"], "venue": "arXiv preprint arXiv:1512.09311,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2015}, {"title": "Products of indecomposable, aperiodic, stochastic matrices", "author": ["J. Wolfowitz"], "venue": "In Proceedings of the American Mathematical Society,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 1963}, {"title": "Matrix Representation of Iterative Approximate Byzantine Consensus in Directed Graphs", "author": ["N.H. Vaidya"], "venue": "arXiv 1203.1888,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2012}, {"title": "Large deviations performance of consensus+ innovations distributed detection with non-gaussian observations", "author": ["D. Bajovi\u0107", "D. Jakoveti\u0107", "J.M. Moura", "J. Xavier", "B. Sinopoli"], "venue": "Signal Processing, IEEE Transactions on,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2012}, {"title": "Distributed detection over adaptive networks using diffusion adaptation", "author": ["F.S. Cattivelli", "A.H. Sayed"], "venue": "Signal Processing, IEEE Transactions on,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 1917}, {"title": "Distributed detection over noisy networks: Large deviations analysis", "author": ["D. Jakoveti\u0107", "J.M. Moura", "J. Xavier"], "venue": "Signal Processing, IEEE Transactions on,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2012}, {"title": "Reaching agreement in the presence of faults", "author": [], "venue": "J. ACM", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 1980}, {"title": "Reaching approximate agreement in the presence of faults", "author": ["D. Dolev", "N.A. Lynch", "S.S. Pinter", "E.W. Stark", "W.E. Weihl"], "venue": "J. ACM,", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 1986}, {"title": "Asymptotically optimal algorithms for approximate agreement", "author": ["A.D. Fekete"], "venue": "Distributed Computing,", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 1990}, {"title": "Consensus of multi-agent networks in the presence of adversaries using only local information", "author": ["H.J. LeBlanc", "H. Zhang", "S. Sundaram", "X. Koutsoukos"], "venue": "In Proceedings of the 1st International Conference on High Confidence Networked Systems, HiCoNS", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2012}, {"title": "Iterative byzantine vector consensus in incomplete graphs", "author": ["N.H. Vaidya"], "venue": "In Distributed Computing and Networking,", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 2014}, {"title": "Byzantine vector consensus in complete graphs", "author": ["N.H. Vaidya", "V.K. Garg"], "venue": "In Proceedings of the 2013 ACM symposium on Principles of distributed computing,", "citeRegEx": "29", "shortCiteRegEx": "29", "year": 2013}, {"title": "Iterative approximate byzantine consensus in arbitrary directed graphs", "author": ["N.H. Vaidya", "L. Tseng", "G. Liang"], "venue": "In Proceedings of the 2012 ACM symposium on Principles of distributed computing,", "citeRegEx": "30", "shortCiteRegEx": "30", "year": 2012}, {"title": "Multidimensional approximate agreement in byzantine asynchronous systems", "author": ["H. Mendes", "M. Herlihy"], "venue": "In Proceedings of the Forty-fifth Annual ACM Symposium on Theory of Computing,", "citeRegEx": "31", "shortCiteRegEx": "31", "year": 2013}, {"title": "Sigron. A generalization of Tverberg\u2019s", "author": ["M.M.A. Perles"], "venue": "theorem. arXiv", "citeRegEx": "32", "shortCiteRegEx": "32", "year": 2007}, {"title": "Network Independent Rates in Distributed Learning", "author": ["A. Nedi\u0107", "A. Olshevsky", "C.A. Uribe"], "venue": "arXiv preprint arXiv:1509.08574,", "citeRegEx": "33", "shortCiteRegEx": "33", "year": 2015}, {"title": "Asynchronous Distributed Hypothesis Testing in the Presence of Crash Failures University of Illinois at Urbana-Champaign", "author": ["L. Su", "N.H. Vaidya"], "venue": "Tech. Rep,", "citeRegEx": "34", "shortCiteRegEx": "34", "year": 2016}], "referenceMentions": [{"referenceID": 0, "context": "2 1 Introduction Decentralized hypothesis testing (learning) has received significant amount of attention [1,2,3,5,6,7,8].", "startOffset": 106, "endOffset": 121}, {"referenceID": 1, "context": "2 1 Introduction Decentralized hypothesis testing (learning) has received significant amount of attention [1,2,3,5,6,7,8].", "startOffset": 106, "endOffset": 121}, {"referenceID": 2, "context": "2 1 Introduction Decentralized hypothesis testing (learning) has received significant amount of attention [1,2,3,5,6,7,8].", "startOffset": 106, "endOffset": 121}, {"referenceID": 4, "context": "2 1 Introduction Decentralized hypothesis testing (learning) has received significant amount of attention [1,2,3,5,6,7,8].", "startOffset": 106, "endOffset": 121}, {"referenceID": 5, "context": "2 1 Introduction Decentralized hypothesis testing (learning) has received significant amount of attention [1,2,3,5,6,7,8].", "startOffset": 106, "endOffset": 121}, {"referenceID": 6, "context": "2 1 Introduction Decentralized hypothesis testing (learning) has received significant amount of attention [1,2,3,5,6,7,8].", "startOffset": 106, "endOffset": 121}, {"referenceID": 7, "context": "2 1 Introduction Decentralized hypothesis testing (learning) has received significant amount of attention [1,2,3,5,6,7,8].", "startOffset": 106, "endOffset": 121}, {"referenceID": 4, "context": "The traditional decentralized detection framework consists of a collection of spatially distributed sensors and a fusion center [5,6,7].", "startOffset": 128, "endOffset": 135}, {"referenceID": 5, "context": "The traditional decentralized detection framework consists of a collection of spatially distributed sensors and a fusion center [5,6,7].", "startOffset": 128, "endOffset": 135}, {"referenceID": 6, "context": "The traditional decentralized detection framework consists of a collection of spatially distributed sensors and a fusion center [5,6,7].", "startOffset": 128, "endOffset": 135}, {"referenceID": 1, "context": "Distributed hypothesis testing in the absence of fusion center is considered in [2,22,23,21].", "startOffset": 80, "endOffset": 92}, {"referenceID": 21, "context": "Distributed hypothesis testing in the absence of fusion center is considered in [2,22,23,21].", "startOffset": 80, "endOffset": 92}, {"referenceID": 22, "context": "Distributed hypothesis testing in the absence of fusion center is considered in [2,22,23,21].", "startOffset": 80, "endOffset": 92}, {"referenceID": 20, "context": "Distributed hypothesis testing in the absence of fusion center is considered in [2,22,23,21].", "startOffset": 80, "endOffset": 92}, {"referenceID": 1, "context": "In particular, Gale and Kariv [2] studied the distributed hypothesis testing problem in the context of social learning, where fully Bayesian belief update rule is studied.", "startOffset": 30, "endOffset": 33}, {"referenceID": 2, "context": "[3], and has attracted much attention [10,14,15,16,11,18,17,13].", "startOffset": 0, "endOffset": 3}, {"referenceID": 9, "context": "[3], and has attracted much attention [10,14,15,16,11,18,17,13].", "startOffset": 38, "endOffset": 63}, {"referenceID": 13, "context": "[3], and has attracted much attention [10,14,15,16,11,18,17,13].", "startOffset": 38, "endOffset": 63}, {"referenceID": 14, "context": "[3], and has attracted much attention [10,14,15,16,11,18,17,13].", "startOffset": 38, "endOffset": 63}, {"referenceID": 15, "context": "[3], and has attracted much attention [10,14,15,16,11,18,17,13].", "startOffset": 38, "endOffset": 63}, {"referenceID": 10, "context": "[3], and has attracted much attention [10,14,15,16,11,18,17,13].", "startOffset": 38, "endOffset": 63}, {"referenceID": 17, "context": "[3], and has attracted much attention [10,14,15,16,11,18,17,13].", "startOffset": 38, "endOffset": 63}, {"referenceID": 16, "context": "[3], and has attracted much attention [10,14,15,16,11,18,17,13].", "startOffset": 38, "endOffset": 63}, {"referenceID": 12, "context": "[3], and has attracted much attention [10,14,15,16,11,18,17,13].", "startOffset": 38, "endOffset": 63}, {"referenceID": 2, "context": "[3] considered the general setting where external signals are observed during each iteration of the algorithm execution.", "startOffset": 0, "endOffset": 3}, {"referenceID": 2, "context": "It is shown [3] that, under this learning rule, each agent learns the true state almost surely.", "startOffset": 12, "endOffset": 15}, {"referenceID": 2, "context": "The publication of [3] has inspired significant efforts in designing and analyzing non-Bayesian learning rules with a particular focus on refining the fusion strategies and analyzing the (asymptotic and/or finite time) convergence rates of the refined algorithms [10,14,15,16,11,18,17,13].", "startOffset": 19, "endOffset": 22}, {"referenceID": 9, "context": "The publication of [3] has inspired significant efforts in designing and analyzing non-Bayesian learning rules with a particular focus on refining the fusion strategies and analyzing the (asymptotic and/or finite time) convergence rates of the refined algorithms [10,14,15,16,11,18,17,13].", "startOffset": 263, "endOffset": 288}, {"referenceID": 13, "context": "The publication of [3] has inspired significant efforts in designing and analyzing non-Bayesian learning rules with a particular focus on refining the fusion strategies and analyzing the (asymptotic and/or finite time) convergence rates of the refined algorithms [10,14,15,16,11,18,17,13].", "startOffset": 263, "endOffset": 288}, {"referenceID": 14, "context": "The publication of [3] has inspired significant efforts in designing and analyzing non-Bayesian learning rules with a particular focus on refining the fusion strategies and analyzing the (asymptotic and/or finite time) convergence rates of the refined algorithms [10,14,15,16,11,18,17,13].", "startOffset": 263, "endOffset": 288}, {"referenceID": 15, "context": "The publication of [3] has inspired significant efforts in designing and analyzing non-Bayesian learning rules with a particular focus on refining the fusion strategies and analyzing the (asymptotic and/or finite time) convergence rates of the refined algorithms [10,14,15,16,11,18,17,13].", "startOffset": 263, "endOffset": 288}, {"referenceID": 10, "context": "The publication of [3] has inspired significant efforts in designing and analyzing non-Bayesian learning rules with a particular focus on refining the fusion strategies and analyzing the (asymptotic and/or finite time) convergence rates of the refined algorithms [10,14,15,16,11,18,17,13].", "startOffset": 263, "endOffset": 288}, {"referenceID": 17, "context": "The publication of [3] has inspired significant efforts in designing and analyzing non-Bayesian learning rules with a particular focus on refining the fusion strategies and analyzing the (asymptotic and/or finite time) convergence rates of the refined algorithms [10,14,15,16,11,18,17,13].", "startOffset": 263, "endOffset": 288}, {"referenceID": 16, "context": "The publication of [3] has inspired significant efforts in designing and analyzing non-Bayesian learning rules with a particular focus on refining the fusion strategies and analyzing the (asymptotic and/or finite time) convergence rates of the refined algorithms [10,14,15,16,11,18,17,13].", "startOffset": 263, "endOffset": 288}, {"referenceID": 12, "context": "The publication of [3] has inspired significant efforts in designing and analyzing non-Bayesian learning rules with a particular focus on refining the fusion strategies and analyzing the (asymptotic and/or finite time) convergence rates of the refined algorithms [10,14,15,16,11,18,17,13].", "startOffset": 263, "endOffset": 288}, {"referenceID": 14, "context": "In this paper we are particularly interested in the log-linear form of the update rule, in which, essentially, each agent updates its belief as the geometric average of the local Bayesian update and its neighbors\u2019 beliefs [15,10,14,16,11,18,17,13].", "startOffset": 222, "endOffset": 247}, {"referenceID": 9, "context": "In this paper we are particularly interested in the log-linear form of the update rule, in which, essentially, each agent updates its belief as the geometric average of the local Bayesian update and its neighbors\u2019 beliefs [15,10,14,16,11,18,17,13].", "startOffset": 222, "endOffset": 247}, {"referenceID": 13, "context": "In this paper we are particularly interested in the log-linear form of the update rule, in which, essentially, each agent updates its belief as the geometric average of the local Bayesian update and its neighbors\u2019 beliefs [15,10,14,16,11,18,17,13].", "startOffset": 222, "endOffset": 247}, {"referenceID": 15, "context": "In this paper we are particularly interested in the log-linear form of the update rule, in which, essentially, each agent updates its belief as the geometric average of the local Bayesian update and its neighbors\u2019 beliefs [15,10,14,16,11,18,17,13].", "startOffset": 222, "endOffset": 247}, {"referenceID": 10, "context": "In this paper we are particularly interested in the log-linear form of the update rule, in which, essentially, each agent updates its belief as the geometric average of the local Bayesian update and its neighbors\u2019 beliefs [15,10,14,16,11,18,17,13].", "startOffset": 222, "endOffset": 247}, {"referenceID": 17, "context": "In this paper we are particularly interested in the log-linear form of the update rule, in which, essentially, each agent updates its belief as the geometric average of the local Bayesian update and its neighbors\u2019 beliefs [15,10,14,16,11,18,17,13].", "startOffset": 222, "endOffset": 247}, {"referenceID": 16, "context": "In this paper we are particularly interested in the log-linear form of the update rule, in which, essentially, each agent updates its belief as the geometric average of the local Bayesian update and its neighbors\u2019 beliefs [15,10,14,16,11,18,17,13].", "startOffset": 222, "endOffset": 247}, {"referenceID": 12, "context": "In this paper we are particularly interested in the log-linear form of the update rule, in which, essentially, each agent updates its belief as the geometric average of the local Bayesian update and its neighbors\u2019 beliefs [15,10,14,16,11,18,17,13].", "startOffset": 222, "endOffset": 247}, {"referenceID": 9, "context": "The log-linear form (geometric averaging) update rule is shown to converge exponentially fast [10,16].", "startOffset": 94, "endOffset": 101}, {"referenceID": 15, "context": "The log-linear form (geometric averaging) update rule is shown to converge exponentially fast [10,16].", "startOffset": 94, "endOffset": 101}, {"referenceID": 12, "context": "Taking an axiomatic approach, the geometric averaging fusion is proved to be optimal [13].", "startOffset": 85, "endOffset": 89}, {"referenceID": 15, "context": "An optimization-based interpretation of this rule is presented in [16], using dual averaging method with properly chosen proximal functions.", "startOffset": 66, "endOffset": 70}, {"referenceID": 13, "context": "Finite-time convergence rates are investigated independently in [14,11,17].", "startOffset": 64, "endOffset": 74}, {"referenceID": 10, "context": "Finite-time convergence rates are investigated independently in [14,11,17].", "startOffset": 64, "endOffset": 74}, {"referenceID": 16, "context": "Finite-time convergence rates are investigated independently in [14,11,17].", "startOffset": 64, "endOffset": 74}, {"referenceID": 13, "context": "Both [14] and [18] consider time-varying networks, with slightly different network models.", "startOffset": 5, "endOffset": 9}, {"referenceID": 17, "context": "Both [14] and [18] consider time-varying networks, with slightly different network models.", "startOffset": 14, "endOffset": 18}, {"referenceID": 13, "context": "Specifically, [14] assumes that the union of every consecutive B networks is strongly connected, while [18] considers random networks.", "startOffset": 14, "endOffset": 18}, {"referenceID": 17, "context": "Specifically, [14] assumes that the union of every consecutive B networks is strongly connected, while [18] considers random networks.", "startOffset": 103, "endOffset": 107}, {"referenceID": 2, "context": "Thus, this paper focuses on the fault-tolerant version the non-Bayesian framework proposed in [3].", "startOffset": 94, "endOffset": 97}, {"referenceID": 33, "context": "An alternative fault model, where some agents may unexpectedly cease computing and communicate with each other asynchronously, is considered in our companion work [34].", "startOffset": 163, "endOffset": 167}, {"referenceID": 23, "context": "[24] and has attracted intensive attention from researchers [25,26,27,30,28,31].", "startOffset": 0, "endOffset": 4}, {"referenceID": 24, "context": "[24] and has attracted intensive attention from researchers [25,26,27,30,28,31].", "startOffset": 60, "endOffset": 79}, {"referenceID": 25, "context": "[24] and has attracted intensive attention from researchers [25,26,27,30,28,31].", "startOffset": 60, "endOffset": 79}, {"referenceID": 26, "context": "[24] and has attracted intensive attention from researchers [25,26,27,30,28,31].", "startOffset": 60, "endOffset": 79}, {"referenceID": 29, "context": "[24] and has attracted intensive attention from researchers [25,26,27,30,28,31].", "startOffset": 60, "endOffset": 79}, {"referenceID": 27, "context": "[24] and has attracted intensive attention from researchers [25,26,27,30,28,31].", "startOffset": 60, "endOffset": 79}, {"referenceID": 30, "context": "[24] and has attracted intensive attention from researchers [25,26,27,30,28,31].", "startOffset": 60, "endOffset": 79}, {"referenceID": 9, "context": "The existing non-Bayesian learning algorithms [10,11,13,14,15,16,17,18] are not robust to Byzantine agents, since the malicious messages sent by the Byzantine agents are indiscriminatingly utilized in the local belief updates.", "startOffset": 46, "endOffset": 71}, {"referenceID": 10, "context": "The existing non-Bayesian learning algorithms [10,11,13,14,15,16,17,18] are not robust to Byzantine agents, since the malicious messages sent by the Byzantine agents are indiscriminatingly utilized in the local belief updates.", "startOffset": 46, "endOffset": 71}, {"referenceID": 12, "context": "The existing non-Bayesian learning algorithms [10,11,13,14,15,16,17,18] are not robust to Byzantine agents, since the malicious messages sent by the Byzantine agents are indiscriminatingly utilized in the local belief updates.", "startOffset": 46, "endOffset": 71}, {"referenceID": 13, "context": "The existing non-Bayesian learning algorithms [10,11,13,14,15,16,17,18] are not robust to Byzantine agents, since the malicious messages sent by the Byzantine agents are indiscriminatingly utilized in the local belief updates.", "startOffset": 46, "endOffset": 71}, {"referenceID": 14, "context": "The existing non-Bayesian learning algorithms [10,11,13,14,15,16,17,18] are not robust to Byzantine agents, since the malicious messages sent by the Byzantine agents are indiscriminatingly utilized in the local belief updates.", "startOffset": 46, "endOffset": 71}, {"referenceID": 15, "context": "The existing non-Bayesian learning algorithms [10,11,13,14,15,16,17,18] are not robust to Byzantine agents, since the malicious messages sent by the Byzantine agents are indiscriminatingly utilized in the local belief updates.", "startOffset": 46, "endOffset": 71}, {"referenceID": 16, "context": "The existing non-Bayesian learning algorithms [10,11,13,14,15,16,17,18] are not robust to Byzantine agents, since the malicious messages sent by the Byzantine agents are indiscriminatingly utilized in the local belief updates.", "startOffset": 46, "endOffset": 71}, {"referenceID": 17, "context": "The existing non-Bayesian learning algorithms [10,11,13,14,15,16,17,18] are not robust to Byzantine agents, since the malicious messages sent by the Byzantine agents are indiscriminatingly utilized in the local belief updates.", "startOffset": 46, "endOffset": 71}, {"referenceID": 13, "context": "In contrast to the existing algorithms [14,11], where only the current private signal is used in the update, our proposed algorithm relies on the cumulative private signals.", "startOffset": 39, "endOffset": 46}, {"referenceID": 10, "context": "In contrast to the existing algorithms [14,11], where only the current private signal is used in the update, our proposed algorithm relies on the cumulative private signals.", "startOffset": 39, "endOffset": 46}, {"referenceID": 9, "context": "Thus, our proposed rule may be of independent interest for the failure-free setting considered in [10,11,13,14,15,16,17,18].", "startOffset": 98, "endOffset": 123}, {"referenceID": 10, "context": "Thus, our proposed rule may be of independent interest for the failure-free setting considered in [10,11,13,14,15,16,17,18].", "startOffset": 98, "endOffset": 123}, {"referenceID": 12, "context": "Thus, our proposed rule may be of independent interest for the failure-free setting considered in [10,11,13,14,15,16,17,18].", "startOffset": 98, "endOffset": 123}, {"referenceID": 13, "context": "Thus, our proposed rule may be of independent interest for the failure-free setting considered in [10,11,13,14,15,16,17,18].", "startOffset": 98, "endOffset": 123}, {"referenceID": 14, "context": "Thus, our proposed rule may be of independent interest for the failure-free setting considered in [10,11,13,14,15,16,17,18].", "startOffset": 98, "endOffset": 123}, {"referenceID": 15, "context": "Thus, our proposed rule may be of independent interest for the failure-free setting considered in [10,11,13,14,15,16,17,18].", "startOffset": 98, "endOffset": 123}, {"referenceID": 16, "context": "Thus, our proposed rule may be of independent interest for the failure-free setting considered in [10,11,13,14,15,16,17,18].", "startOffset": 98, "endOffset": 123}, {"referenceID": 17, "context": "Thus, our proposed rule may be of independent interest for the failure-free setting considered in [10,11,13,14,15,16,17,18].", "startOffset": 98, "endOffset": 123}, {"referenceID": 3, "context": "2 Problem Formulation Network Model: Our network model is similar to the model used in [4,30].", "startOffset": 87, "endOffset": 93}, {"referenceID": 29, "context": "2 Problem Formulation Network Model: Our network model is similar to the model used in [4,30].", "startOffset": 87, "endOffset": 93}, {"referenceID": 11, "context": "The faulty agents may collaborate with each other adaptively [12].", "startOffset": 61, "endOffset": 65}, {"referenceID": 2, "context": "Observation Model: Our observation model is identical the model used in [3,11,18].", "startOffset": 72, "endOffset": 81}, {"referenceID": 10, "context": "Observation Model: Our observation model is identical the model used in [3,11,18].", "startOffset": 72, "endOffset": 81}, {"referenceID": 17, "context": "Observation Model: Our observation model is identical the model used in [3,11,18].", "startOffset": 72, "endOffset": 81}, {"referenceID": 24, "context": "Byzantine consensus has attracted significant amount of attention [25,26,29,27,30,28,31].", "startOffset": 66, "endOffset": 88}, {"referenceID": 25, "context": "Byzantine consensus has attracted significant amount of attention [25,26,29,27,30,28,31].", "startOffset": 66, "endOffset": 88}, {"referenceID": 28, "context": "Byzantine consensus has attracted significant amount of attention [25,26,29,27,30,28,31].", "startOffset": 66, "endOffset": 88}, {"referenceID": 26, "context": "Byzantine consensus has attracted significant amount of attention [25,26,29,27,30,28,31].", "startOffset": 66, "endOffset": 88}, {"referenceID": 29, "context": "Byzantine consensus has attracted significant amount of attention [25,26,29,27,30,28,31].", "startOffset": 66, "endOffset": 88}, {"referenceID": 27, "context": "Byzantine consensus has attracted significant amount of attention [25,26,29,27,30,28,31].", "startOffset": 66, "endOffset": 88}, {"referenceID": 30, "context": "Byzantine consensus has attracted significant amount of attention [25,26,29,27,30,28,31].", "startOffset": 66, "endOffset": 88}, {"referenceID": 30, "context": "While the past work mostly focus on scalar inputs, the more general vector (or multi-dimensional) inputs have been studied recently [31,29,28].", "startOffset": 132, "endOffset": 142}, {"referenceID": 28, "context": "While the past work mostly focus on scalar inputs, the more general vector (or multi-dimensional) inputs have been studied recently [31,29,28].", "startOffset": 132, "endOffset": 142}, {"referenceID": 27, "context": "While the past work mostly focus on scalar inputs, the more general vector (or multi-dimensional) inputs have been studied recently [31,29,28].", "startOffset": 132, "endOffset": 142}, {"referenceID": 30, "context": "Complete communication networks are considered in [31,29], where tight conditions on the number of agents are identified.", "startOffset": 50, "endOffset": 57}, {"referenceID": 28, "context": "Complete communication networks are considered in [31,29], where tight conditions on the number of agents are identified.", "startOffset": 50, "endOffset": 57}, {"referenceID": 27, "context": "Incomplete communication networks are studied in [28].", "startOffset": 49, "endOffset": 53}, {"referenceID": 27, "context": "In particular, our learning algorithms build upon Byz-Iter algorithm proposed in [28] and a simple algorithm proposed in [30] for iterative Byzantine consensus with vector inputs and scalar inputs, respectively, in incomplete networks.", "startOffset": 81, "endOffset": 85}, {"referenceID": 29, "context": "In particular, our learning algorithms build upon Byz-Iter algorithm proposed in [28] and a simple algorithm proposed in [30] for iterative Byzantine consensus with vector inputs and scalar inputs, respectively, in incomplete networks.", "startOffset": 121, "endOffset": 125}, {"referenceID": 27, "context": "A matrix representation of the non-faulty agents\u2019 states evolution under Byz-Iter algorithm is provided by [28], which also captures the dynamics of the simple algorithm with scalar inputs in [30].", "startOffset": 107, "endOffset": 111}, {"referenceID": 29, "context": "A matrix representation of the non-faulty agents\u2019 states evolution under Byz-Iter algorithm is provided by [28], which also captures the dynamics of the simple algorithm with scalar inputs in [30].", "startOffset": 192, "endOffset": 196}, {"referenceID": 27, "context": "1 Algorithm Byz-Iter [28] Algorithm Byz-Iter is based on Tverberg\u2019s Theorem [32].", "startOffset": 21, "endOffset": 25}, {"referenceID": 31, "context": "1 Algorithm Byz-Iter [28] Algorithm Byz-Iter is based on Tverberg\u2019s Theorem [32].", "startOffset": 76, "endOffset": 80}, {"referenceID": 31, "context": "[32] Let f be a nonnegative integer.", "startOffset": 0, "endOffset": 4}, {"referenceID": 27, "context": "Algorithm 2: Algorithm Byz-Iter [28]: t-th iteration at agent i 1 v t \u2190 One-Iter(v t\u22121); Remark 1.", "startOffset": 32, "endOffset": 36}, {"referenceID": 27, "context": "2 Correctness of Algorithm Byz-Iter We briefly summarize the aspects of correctness proof of Algorithm 2 from [28] that are necessary for our subsequent discussion.", "startOffset": 110, "endOffset": 114}, {"referenceID": 27, "context": "[28] shows that the effective communication network thus obtained can be characterized by a \u201creduced graph\u201d of G(V, E), defined below.", "startOffset": 0, "endOffset": 4}, {"referenceID": 27, "context": "Assumption 1 below states a condition that is sufficient for reaching approximate Byzantine vector consensus using Algorithm 1 [28].", "startOffset": 127, "endOffset": 131}, {"referenceID": 27, "context": "[28] Suppose Assumption 1 holds for a given m \u2265 1.", "startOffset": 0, "endOffset": 4}, {"referenceID": 27, "context": "3 Matrix Representation [28] Let |F| = \u03c6 (thus, 0 \u2264 \u03c6 \u2264 f).", "startOffset": 24, "endOffset": 28}, {"referenceID": 27, "context": "[28] Suppose Assumption 1 holds for a given m \u2265 1.", "startOffset": 0, "endOffset": 4}, {"referenceID": 8, "context": "Using prior work on coefficients of ergodicity [9], under Assumption 1, it has been shown [28,19] that lim t\u2265r, t\u2192\u221e \u03a6(t, r) = 1\u03c0(r), (3) where \u03c0(r) \u2208 Rn\u2212\u03c6 is a row stochastic vector, and 1 is the column vector with each entry being 1.", "startOffset": 47, "endOffset": 50}, {"referenceID": 27, "context": "Using prior work on coefficients of ergodicity [9], under Assumption 1, it has been shown [28,19] that lim t\u2265r, t\u2192\u221e \u03a6(t, r) = 1\u03c0(r), (3) where \u03c0(r) \u2208 Rn\u2212\u03c6 is a row stochastic vector, and 1 is the column vector with each entry being 1.", "startOffset": 90, "endOffset": 97}, {"referenceID": 18, "context": "Using prior work on coefficients of ergodicity [9], under Assumption 1, it has been shown [28,19] that lim t\u2265r, t\u2192\u221e \u03a6(t, r) = 1\u03c0(r), (3) where \u03c0(r) \u2208 Rn\u2212\u03c6 is a row stochastic vector, and 1 is the column vector with each entry being 1.", "startOffset": 90, "endOffset": 97}, {"referenceID": 27, "context": "[28] For all t \u2265 r \u2265 1, it holds that |\u03a6ij(t, r)\u2212 \u03c0j(r)| \u2264 (1 \u2212 \u03b2 m) t\u2212r+1 \u03bd \u2309, where \u03bd , \u03c7m(n\u2212 \u03c6).", "startOffset": 0, "endOffset": 4}, {"referenceID": 27, "context": "The next lemma is a consequence of the results in [28].", "startOffset": 50, "endOffset": 54}, {"referenceID": 27, "context": "[28] For any r \u2265 1, there exists a reduced graph H[r] with source component Sr such that \u03c0i(r) \u2265 \u03b2\u03c7m(n\u2212\u03c6) m for each i \u2208 Sr.", "startOffset": 0, "endOffset": 4}, {"referenceID": 29, "context": ", the inputs provided at individual non-faulty agents are scalars) it has been shown [30] that Assumption 1 is also necessary.", "startOffset": 85, "endOffset": 89}, {"referenceID": 29, "context": "[30] For scalar inputs, iterative approximate Byzantine consensus is achievable among non-faulty agents if and only if every 1-dimensional reduced graph of G(V, E) contains only one source component.", "startOffset": 0, "endOffset": 4}, {"referenceID": 29, "context": "8 Algorithm 3: Algorithm Scalar Byzantine Consensus: iteration t \u2265 1 [30] 1 Transmit vi[t\u2212 1] on all outgoing links; 2 Receive messages on all incoming links.", "startOffset": 69, "endOffset": 73}, {"referenceID": 13, "context": "BFL is a modified version of the geometric averaging update rule that has been investigated in previous work [14,15,11,17].", "startOffset": 109, "endOffset": 122}, {"referenceID": 14, "context": "BFL is a modified version of the geometric averaging update rule that has been investigated in previous work [14,15,11,17].", "startOffset": 109, "endOffset": 122}, {"referenceID": 10, "context": "BFL is a modified version of the geometric averaging update rule that has been investigated in previous work [14,15,11,17].", "startOffset": 109, "endOffset": 122}, {"referenceID": 16, "context": "BFL is a modified version of the geometric averaging update rule that has been investigated in previous work [14,15,11,17].", "startOffset": 109, "endOffset": 122}, {"referenceID": 13, "context": "Algorithm 4: BFL: Iteration t \u2265 1 at agent i 1 \u03b7 t \u2190 One-Iter(log \u03bct\u22121); 2 Observe st; 3 for \u03b8 \u2208 \u0398 do 4 li(s i 1,t|\u03b8) \u2190 li(st|\u03b8) li(s1,t\u22121|\u03b8); 5 \u03bct(\u03b8) \u2190 li(s1,t|\u03b8) exp(\u03b7 t(\u03b8)) \u2211m p=1 li(s i 1,t|\u03b8p) exp(\u03b7 t(\u03b8p)) ; 6 end The main difference of Algorithm 4 with respect to the algorithms in [14,15,11,17] is that (i) our algorithm uses a Byzantine consensus iteration as a primitive (in line 1), and (ii) li(s i 1,t|\u03b8) used in line 5 is the likelihood for observations from iteration 1 to t (the previous algorithms instead use li(s i t|\u03b8) here).", "startOffset": 288, "endOffset": 301}, {"referenceID": 14, "context": "Algorithm 4: BFL: Iteration t \u2265 1 at agent i 1 \u03b7 t \u2190 One-Iter(log \u03bct\u22121); 2 Observe st; 3 for \u03b8 \u2208 \u0398 do 4 li(s i 1,t|\u03b8) \u2190 li(st|\u03b8) li(s1,t\u22121|\u03b8); 5 \u03bct(\u03b8) \u2190 li(s1,t|\u03b8) exp(\u03b7 t(\u03b8)) \u2211m p=1 li(s i 1,t|\u03b8p) exp(\u03b7 t(\u03b8p)) ; 6 end The main difference of Algorithm 4 with respect to the algorithms in [14,15,11,17] is that (i) our algorithm uses a Byzantine consensus iteration as a primitive (in line 1), and (ii) li(s i 1,t|\u03b8) used in line 5 is the likelihood for observations from iteration 1 to t (the previous algorithms instead use li(s i t|\u03b8) here).", "startOffset": 288, "endOffset": 301}, {"referenceID": 10, "context": "Algorithm 4: BFL: Iteration t \u2265 1 at agent i 1 \u03b7 t \u2190 One-Iter(log \u03bct\u22121); 2 Observe st; 3 for \u03b8 \u2208 \u0398 do 4 li(s i 1,t|\u03b8) \u2190 li(st|\u03b8) li(s1,t\u22121|\u03b8); 5 \u03bct(\u03b8) \u2190 li(s1,t|\u03b8) exp(\u03b7 t(\u03b8)) \u2211m p=1 li(s i 1,t|\u03b8p) exp(\u03b7 t(\u03b8p)) ; 6 end The main difference of Algorithm 4 with respect to the algorithms in [14,15,11,17] is that (i) our algorithm uses a Byzantine consensus iteration as a primitive (in line 1), and (ii) li(s i 1,t|\u03b8) used in line 5 is the likelihood for observations from iteration 1 to t (the previous algorithms instead use li(s i t|\u03b8) here).", "startOffset": 288, "endOffset": 301}, {"referenceID": 16, "context": "Algorithm 4: BFL: Iteration t \u2265 1 at agent i 1 \u03b7 t \u2190 One-Iter(log \u03bct\u22121); 2 Observe st; 3 for \u03b8 \u2208 \u0398 do 4 li(s i 1,t|\u03b8) \u2190 li(st|\u03b8) li(s1,t\u22121|\u03b8); 5 \u03bct(\u03b8) \u2190 li(s1,t|\u03b8) exp(\u03b7 t(\u03b8)) \u2211m p=1 li(s i 1,t|\u03b8p) exp(\u03b7 t(\u03b8p)) ; 6 end The main difference of Algorithm 4 with respect to the algorithms in [14,15,11,17] is that (i) our algorithm uses a Byzantine consensus iteration as a primitive (in line 1), and (ii) li(s i 1,t|\u03b8) used in line 5 is the likelihood for observations from iteration 1 to t (the previous algorithms instead use li(s i t|\u03b8) here).", "startOffset": 288, "endOffset": 301}, {"referenceID": 2, "context": "1 Identifiability In the absence of agent failures [3], for the networked agents to detect the true hypothesis \u03b8\u2217, it is sufficient to assume that G(V, E) is strongly connected, and that \u03b8\u2217 is globally identifiable.", "startOffset": 51, "endOffset": 54}, {"referenceID": 13, "context": "2 Convergence Results Our proof parallels the structure of a proof in [14], but with some key differences to take into account our update rule for the belief vector.", "startOffset": 70, "endOffset": 74}, {"referenceID": 13, "context": "(16) As it can be seen later, the proof of Lemma 3 is significantly different from the analogous lemma in [14].", "startOffset": 106, "endOffset": 110}, {"referenceID": 13, "context": "Our convergence proof has similar structure as the analysis in [14].", "startOffset": 63, "endOffset": 67}, {"referenceID": 13, "context": "Indeed, the BFL for f = 0 is a simple modification of the algorithm proposed in [14].", "startOffset": 80, "endOffset": 84}, {"referenceID": 13, "context": "As mentioned before, the non-Bayesian learning rules [14,15,11,17] are consensus-based learning algorithms, wherein agents are required to reach a common decision asymptotically.", "startOffset": 53, "endOffset": 66}, {"referenceID": 14, "context": "As mentioned before, the non-Bayesian learning rules [14,15,11,17] are consensus-based learning algorithms, wherein agents are required to reach a common decision asymptotically.", "startOffset": 53, "endOffset": 66}, {"referenceID": 10, "context": "As mentioned before, the non-Bayesian learning rules [14,15,11,17] are consensus-based learning algorithms, wherein agents are required to reach a common decision asymptotically.", "startOffset": 53, "endOffset": 66}, {"referenceID": 16, "context": "As mentioned before, the non-Bayesian learning rules [14,15,11,17] are consensus-based learning algorithms, wherein agents are required to reach a common decision asymptotically.", "startOffset": 53, "endOffset": 66}, {"referenceID": 13, "context": "Our proof is similar to the proof presented in [14,17].", "startOffset": 47, "endOffset": 54}, {"referenceID": 16, "context": "Our proof is similar to the proof presented in [14,17].", "startOffset": 47, "endOffset": 54}, {"referenceID": 13, "context": "Similar to [14,17], we also use McDiarmid\u2019s Inequality.", "startOffset": 11, "endOffset": 18}, {"referenceID": 16, "context": "Similar to [14,17], we also use McDiarmid\u2019s Inequality.", "startOffset": 11, "endOffset": 18}, {"referenceID": 13, "context": "Our analysis for the special when f = 0 also works for time-varying networks [14].", "startOffset": 77, "endOffset": 81}, {"referenceID": 19, "context": "By [20], we know that for each pair of hypotheses \u03b81 and \u03b82, there exists a row-stochastic matrix M1,2[t] \u2208 R(n\u2212\u03c6)\u00d7(n\u2212\u03c6) such that r t(\u03b81, \u03b82) = n\u2212\u03c6 \u2211", "startOffset": 3, "endOffset": 7}], "year": 2016, "abstractText": "Abstract This paper addresses the problem of non-Bayesian learning over multi-agent networks, where agents repeatedly collect partially informative observations about an unknown state of the world, and try to collaboratively learn the true state. We focus on the impact of the adversarial agents on the performance of consensus-based non-Bayesian learning, where non-faulty agents combine local learning updates with consensus primitives. In particular, we consider the scenario where an unknown subset of agents suffer Byzantine faults \u2013 agents suffering Byzantine faults behave arbitrarily.", "creator": "LaTeX with hyperref package"}}}