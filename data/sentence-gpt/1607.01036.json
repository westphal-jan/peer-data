{"id": "1607.01036", "review": {"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "4-Jul-2016", "title": "Bootstrap Model Aggregation for Distributed Statistical Learning", "abstract": "In distributed, or privacy-preserving learning, we are often given a set of probabilistic models estimated from different local repositories, and asked to combine them into a single model that gives efficient statistical estimation. A simple method is to linearly average the parameters of the local models, which, however, tends to be degenerate or not applicable on non-convex models, or models with different parameter dimensions. One more practical strategy is to generate bootstrap samples from the local models, and then learn a joint model based on the combined bootstrap set. Unfortunately, the bootstrap procedure introduces additional noise and can significantly deteriorate the performance. In this work, we propose two variance reduction methods to correct the bootstrap noise, including a weighted M-estimator that is both statistically efficient and practically powerful. Both theoretical and empirical analysis is provided to demonstrate our methods.\n\n\n\nThe goal of this paper was to investigate the performance of individual components of a local model and to address the main differences between these models. We are now investigating how the performance of multiple components of a local model in relation to the bootstrap set was evaluated by the logistic regression model ( Fig. 6 ). In other words, a local model can be calculated by running a logistic regression analysis. A similar approach to the traditional model is used in large samples with multiple component sizes, and to use the same technique to investigate large samples with multiple component sizes.\nThe approach to examining large samples with multiple component sizes is described in a section in the Methods for a detailed discussion of the use of statistical regression and our results.\nWe show that there is a small number of differences between multiple component sizes in the logistic regression model, which is particularly important for larger samples. When comparing multiple component sizes, there is a small decrease in performance of multiple component sizes.\nAlthough this model is based on a number of parameters, the authors believe that this model is a suitable alternative to traditional, linear regression models. They have recommended that the results be interpreted using multiple component sizes to improve their accuracy.\nThe authors say that they have found that the data from the data from the data from the data from the dataset is better than the data from the data from the dataset of the data from the dataset of the data from the dataset of the data from the dataset of the data from the data from the data from the dataset of the data from the dataset of the data from the dataset of the data from the dataset of the data from the dataset of the data from the dataset", "histories": [["v1", "Mon, 4 Jul 2016 20:12:41 GMT  (596kb,D)", "http://arxiv.org/abs/1607.01036v1", "This paper is about variance reduction on Monte Carol estimation of KL divergence"], ["v2", "Wed, 1 Feb 2017 20:06:40 GMT  (596kb,D)", "http://arxiv.org/abs/1607.01036v2", "This paper is about variance reduction on Monte Carol estimation of KL divergence"], ["v3", "Sun, 5 Feb 2017 03:07:51 GMT  (377kb,D)", "http://arxiv.org/abs/1607.01036v3", "This paper is about variance reduction on Monte Carol estimation of KL divergence, NIPS, 2016"], ["v4", "Mon, 27 Feb 2017 21:01:20 GMT  (376kb,D)", "http://arxiv.org/abs/1607.01036v4", "This paper is about variance reduction on Monte Carol estimation of KL divergence, NIPS, 2016"]], "COMMENTS": "This paper is about variance reduction on Monte Carol estimation of KL divergence", "reviews": [], "SUBJECTS": "stat.ML cs.AI cs.LG", "authors": ["jun han", "qiang liu"], "accepted": true, "id": "1607.01036"}, "pdf": {"name": "1607.01036.pdf", "metadata": {"source": "CRF", "title": "Bootstrap Model Aggregation for Distributed Statistical Learning", "authors": ["Jun Han", "Qiang Liu"], "emails": ["jun.han.gr@dartmouth.edu", "qiang.liu@dartmouth.edu"], "sections": [{"heading": "1 Introduction", "text": "Modern data science applications increasingly involve learning complex probabilistic models over massive datasets. In many cases, the datasets are distributed into multiple machines at different locations, between which communication is expensive or restricted; this can be either because the data volume is too large to store or process in a single machine, or due to privacy constraints as these in healthcare or financial systems. There has been a recent growing interest in developing communication-efficient algorithms for probabilistic learning with distributed datasets; see e.g., Boyd et al. (2011); Zhang et al. (2012); Dekel et al. (2012); Liu and Ihler (2014); Rosenblatt and Nadler (2014) and reference therein.\nThis work focuses on a one-shot approach for distributed learning, in which we first learn a set of local models from local machines, and then combine them in a fusion center to form a single model that integrates all the information in the local models. This approach is highly efficient in both computation and communication costs, but casts a challenge in designing statistically efficient combination strategies. Many studies have been focused on a simple linear averaging method that linearly averages the parameters of the local models (e.g., Zhang et al., 2012, 2013; Rosenblatt and Nadler, 2014); although nearly optimal asymptotic error rates can be achieved, this simple method tends to degenerate in practical scenarios for models with non-convex log-likelihood or non-identifiable parameters (such as latent variable models, and neural models), and is not applicable at all for models with non-additive parameters (e.g., when the parameters have discrete or categorical values, or the parameter dimensions of the local models are different).\nA better strategy that overcomes all these practical limitations of linear averaging is the KL-averaging method (Liu and Ihler, 2014; Merugu and Ghosh, 2003), which finds a model that minimizes the sum of Kullback-Leibler (KL) divergence to all the local models. In this way, we directly combine the models, instead of the parameters. The exact KL-averaging is not computationally tractable because of the intractability of calculating KL divergences; a practical approach is to draw (bootstrap)\nar X\niv :1\n60 7.\n01 03\n6v 1\n[ st\nat .M\nL ]\n4 J\nul 2\nsamples from the given local models, and then learn a combined model based on all the bootstrap data. Unfortunately, the bootstrap noise can easily dominate in this approach and we need a very large bootstrap sample size to obtain accurate results. In Section 3, we show that the MSE of the estimator obtained from the naive way is O(N\u22121 + (dn)\u22121), where N is the total size of the observed data, and n is bootstrap sample size of each local model and d is the number of machines. This means that to ensure a MSE of O(N\u22121), which is guaranteed by the centralized method and the simple linear averaging, we need dn & N ; this is unsatisfying since N is usually very large by assumption.\nIn this work, we use variance reduction techniques to cancel out the bootstrap noise and get better KL-averaging estimates. The difficulty of this task is first illustrated using a relatively straightforward control variates method, which unfortunately suffers some of the practical drawback of the linear averaging method due to the use of a linear correction term. We then propose a better method based on a weighted M-estimator, which inherits all the practical advantages of KL-averaging. On the theoretical part, we show that our methods give a MSE of O(N\u22121 + (dn2)\u22121), which significantly improves over the original bootstrap estimator. Empirical studies are provided to verify our theoretical results and demonstrate the practical advantages of our methods.\nThis paper is organized as follows. Section 2 introduces the background, and Section 3 introduces our methods and analyze their theoretical properties. We present numerical results in Section 4 and conclude the paper in Section 5. Detailed proofs can be found in the appendix."}, {"heading": "2 Background and Problem Setting", "text": "Suppose we have a dataset X = {xj , j = 1, 2, ..., N} of size N , i.i.d. drawn from a probabilistic model p(x|\u03b8\u2217) within a parametric family P = {p(x|\u03b8) : \u03b8 \u2208 \u0398}; here \u03b8\u2217 is the unknown true parameter that we want to estimate based on X . In the distributed setting, the dataset X is partitioned into d disjoint subsets, X = \u22c3d k=1X\nk, where Xk denotes the k-th subset which we assume is stored in a local machine. For simplicity, we assume all the subsets have the same data size (N/d).\nThe traditional maximum likelihood estimator (MLE) provides a natural way for estimating the true parameter \u03b8\u2217 based on the whole dataset X ,\nGlobal MLE: \u03b8\u0302mle = arg max \u03b8\u2208\u0398 d\u2211 k=1 N/d\u2211 j=1 log p(xkj | \u03b8), where Xk = {xkj }. (1)\nHowever, directly calculating the global MLE is challenging due to the distributed partition of the dataset. Although distributed optimization algorithms exist (e.g., Boyd et al., 2011; Shamir et al., 2014), they require iterative communication between the local machines and a fusion center, which can be very time consuming in distributed settings, for which the number of communication rounds forms the main bottleneck (regardless of the amount of information communicated at each round).\nWe instead consider a simpler one-shot approach that first learns a set of local models based on each subset, and then send them to a fusion center in which they are combined into a global model that captures all the information. We assume each of the local models is estimated using a MLE based on subset Xk from the k-th machine:\nLocal MLE: \u03b8\u0302k = arg max \u03b8\u2208\u0398 N/d\u2211 j=1 log p(xkj | \u03b8), where k \u2208 [d] = {1, 2, \u00b7 \u00b7 \u00b7 , d}. (2)\nThe major problem is how to combine these local models into a global model. The simplest way is to linearly average all local MLE parameters:\nLinear Average: \u03b8\u0302linear = 1\nd d\u2211 k=1 \u03b8\u0302k.\nComprehensive theoretical analysis has been done for \u03b8\u0302linear (e.g., Zhang et al., 2012; Rosenblatt and Nadler, 2014), which show that it has an asymptotic MLE of E||\u03b8\u0302linear \u2212 \u03b8\u2217|| = O(N\u22121). In fact, it is equivalent to the global MLE \u03b8\u0302mle up to the first order O(N\u22121), and several improvements have been developed to improve the second order term (e.g., Zhang et al., 2012; Huang and Huo, 2015).\nUnfortunately, the linear averaging method can easily break down in practice, or is even not applicable when the underlying model is complex. For example, it may work poorly when the likelihood has multiple modes, or when there exist non-identifiable parameters for which different parameter values correspond to a same model (also known as the label-switching problem); models of this kind include latent variable models and neural networks, and appear widely in machine learning. In addition, the linear averaging method is obviously not applicable when the local models have different numbers of parameters (e.g., Gaussian mixtures with unknown numbers of components), or when the parameters are simply not additive (such as parameters with discrete or categorical values). Further discussions on the practical limitaions of the linear averaging method can be found in Liu and Ihler (2014).\nAll these problems of linear averaging can be well addressed by a KL-averaging method which averages the model (instead of the parameters) by finding a geometric center of the local models in terms of KL divergence (Merugu and Ghosh, 2003; Liu and Ihler, 2014). Specifically, it finds a model p(x | \u03b8\u2217KL) where \u03b8 \u2217 KL is obtained by \u03b8 \u2217 KL = arg min\u03b8 \u2211d k=1 KL(p(x|\u03b8\u0302k) || p(x|\u03b8)), which is equivalent to,\nExact KL Estimator: \u03b8\u2217KL = arg max \u03b8\u2208\u0398\n{ \u03b7(\u03b8) \u2261 d\u2211 k=1 \u222b p(x | \u03b8\u0302k) log p(x | \u03b8)dx } . (3)\nLiu and Ihler (2014) studied the theoretical properties of the KL-averaging method, and showed that it exactly recovers the global MLE, that is, \u03b8\u2217KL = \u03b8\u0302mle, when the distribution family is a full exponential family, and achieves an optimal asymptotic error rate (up to the second order) among all the possible combination methods of {\u03b8\u0302k}. Despite the attractive properties, the exact KL-averaging is not computationally tractable except for very simple models. Liu and Ihler (2014) suggested a naive bootstrap method for approximation: it draws parametric bootstrap sample {x\u0303kj }nj=1 from each local model p(x|\u03b8\u0302k), k \u2208 [d] and use it to approximate each integral in (3). The optimization in (3) then reduces to a tractable one,\nKL-Naive Estimator: \u03b8\u0302KL = arg max \u03b8\u2208\u0398\n{ \u03b7\u0302(\u03b8) \u2261 1\nn d\u2211 k=1 n\u2211 j=1 log p(x\u0303kj | \u03b8) } . (4)\nIntuitively, we can treat each X\u0303k = {x\u0303kj }nj=1 as an approximation of the original subset Xk = {xkj } N/d j=1 , and hence can be used to approximate the global MLE in (1).\nUnfortunately, as we show in the sequel, the accuracy of \u03b8\u0302KL critically depends on the bootstrap sample size n, and one would need n to be nearly as large as the original data size N/d to make \u03b8\u0302KL achieve the baseline asymptotic rate O(N\u22121) that the simple linear averaging achieves; this is highly undesirably since N is often assumed to be large in distributed learning settings."}, {"heading": "3 Main Results", "text": "We propose two variance reduction techniques for improving the KL-averaging estimates and discuss their theoretical and practical properties. We start with a concrete analysis on the KL-naive estimator \u03b8\u0302KL, which was missing in Liu and Ihler (2014).\nAssumption 1. 1. log p(x | \u03b8), \u2202 log p(x|\u03b8)\u2202\u03b8 , and \u22022 log p(x|\u03b8) \u2202\u03b8\u2202\u03b8>\nare continuous for \u2200x \u2208 X and \u2200\u03b8 \u2208 \u0398; 2. \u2202\n2 log p(x|\u03b8) \u2202\u03b8\u2202\u03b8> is positive definite and C1 \u2264 \u2016\u2202 2 log p(x|\u03b8) \u2202\u03b8\u2202\u03b8> \u2016 \u2264 C2 in a neighbor of \u03b8\u2217 for \u2200x \u2208 X , and C1, C2 are some positive constans.\nTheorem 2. Under Assumption 1, \u03b8\u0302KL is a consistent estimator of \u03b8\u2217KL as n\u2192\u221e, and\nE(\u03b8\u0302KL \u2212 \u03b8\u2217KL) = o( 1 dn ), E\u2016\u03b8\u0302KL \u2212 \u03b8\u2217KL\u20162 = O( 1 dn ),\nwhere d is the number of machines and n is the bootstrap sample size for each local model p(x | \u03b8\u0302k).\nThe proof is in Appendix A. Because the MSE between the exact KL estimator \u03b8\u2217KL and the true parameter \u03b8\u2217 is O(N\u22121) as shown in Liu and Ihler (2014), the MSE between \u03b8\u0302KL and the true\nparameter \u03b8\u2217 is\nE\u2016\u03b8\u0302KL \u2212 \u03b8\u2217\u20162 \u2248 E\u2016\u03b8\u0302KL \u2212 \u03b8\u2217KL\u20162 + E\u2016\u03b8 \u2217 KL \u2212 \u03b8 \u2217\u20162 = O(N\u22121 + (dn)\u22121). (5)\nTo make the MSE between \u03b8\u0302KL and \u03b8\u2217 equal O(N\u22121), as what is achieved by the simple linear averaging, we need draw dn & N bootstrap data points in total, which is undesirable since N is often assumed to be very large by the assumption of distributed learning setting (one exception is when the data is distributed due to privacy constraint, in which case N may be relatively small).\nTherefore, it is a critical task to develop more accurate methods that can reduce the noise introduced by the bootstrap process. In the sequel, we introduce two variance reduction techniques to achieve this goal. One is based a (linear) control variates method that improves \u03b8\u0302KL using a linear correction term, and another is a multiplicative control variates method that modifies the M-estimator in (4) by assigning each bootstrap data point with a positive weight to cancel the noise. We show that both method achieves a higher O(N\u22121 + (dn2)\u22121) rate under mild assumptions, while the second method has more attractive practical advantages."}, {"heading": "3.1 Control Variates Estimator", "text": "The control variates method is a technique for variance reduction on Monte Carlo estimation (e.g., Wilson, 1984). It introduces a set of correlated auxiliary random variables with known expectations or asymptotics (referred as the control variates), to balance the variation of the original estimator. In our case, since each bootstrapped subsample X\u0303k = {x\u0303kj }nj=1 is know to be drawn from the local model p(x | \u03b8\u0302k), we can construct a control variate by re-estimating the local model based on X\u0303k:\nBootstrapped Local MLE: \u03b8\u0303k = arg max \u03b8\u2208\u0398 n\u2211 j=1 log p(x\u0303kj | \u03b8), for k \u2208 [d], (6)\nwhere \u03b8\u0303k is known to converge to \u03b8\u0302k asymptotically. This allows us to define the following control variates estimator:\nKL-Control Estimator: \u03b8\u0302KL\u2212C = \u03b8\u0302KL + d\u2211 k=1 Bk(\u03b8\u0303k \u2212 \u03b8\u0302k), (7)\nwhere Bk is a matrix chosen to minimize the asymptotic variance of \u03b8\u0302KL\u2212C ; our derivation shows that the asymptotically optimal Bk has a form of\nBk = \u2212( d\u2211 k=1 I(\u03b8\u0302k)) \u22121I(\u03b8\u0302k), k \u2208 [d], (8)\nwhere I(\u03b8\u0302k) is the empirical Fisher information matrix of the local model p(x | \u03b8\u0302k). Note that this differentiates our method from the typical control variates methods where Bk is instead estimated using empirical covariance between the control variates and the original estimator (in our case, we can not directly estimate the covariance because \u03b8\u0302KL and \u03b8\u0303k are not averages of i.i.d. samples).The procedure of our method is summarized in Algorithm 1. Note that the form of (7) shares some similarity with the one-step estimator in Huang and Huo (2015), but Huang and Huo (2015) focuses on improving the linear averaging estimator, and is different from our setting.\nWe analyze the asymptotic property of the estimator \u03b8\u0302KL\u2212C , and summarize it as follows.\nTheorem 3. Under Assumption (1), \u03b8\u0302KL\u2212C is a consistent estimator of \u03b8\u2217KL as n \u2192 \u221e, and its asymptotic MSE is guaranteed to be smaller than the KL-naive estimator \u03b8\u0302KL, that is,\nnE\u2016\u03b8\u0302KL\u2212C \u2212 \u03b8\u2217KL\u20162 < nE\u2016\u03b8\u0302KL \u2212 \u03b8 \u2217 KL\u20162, as n\u2192\u221e.\nIn addition, whenN > n\u00d7d, the \u03b8\u0302KL\u2212C has \u201czero-variance\u201d in that E\u2016\u03b8\u0302KL\u2212\u03b8\u2217KL\u20162 = O((dn2)\u22121). Further, in terms of estimating the true parameter, we have\nE\u2016\u03b8\u0302KL\u2212C \u2212 \u03b8\u2217\u20162 = O(N\u22121 + (dn2)\u22121). (9)\nAlgorithm 1 KL-Control Variates Method for Combining Local Models 1: Input: Local model parameters {\u03b8\u0302k}dk=1. 2: Generate bootstrap data {x\u0303kj }nj=1 from each p(x|\u03b8\u0302k), for k \u2208 [d]. 3: Calculate the KL-Naive estimator, \u03b8\u0302KL = arg max\u03b8\u2208\u0398 \u2211d k=1 1 n \u2211n j=1 log p(x\u0303 k j |\u03b8).\n4: Re-estimate the local parameters \u03b8\u0303k via (6) based on the bootstrapped data subset {x\u0303kj }nj=1, for k \u2208 [d].\n5: Estimate the empirical Fish information matrix I(\u03b8\u0302k) = 1n \u2211n j=1 \u2202log p(x\u0303kj |\u03b8\u0302k) \u2202\u03b8 \u2202log p(x\u0303kj |\u03b8\u0302k) \u2202\u03b8 > ,\nfor k \u2208 [d]. 6: Ouput: The parameter \u03b8\u0302KL\u2212C of the combined model is given by (7) and (8).\nThe proof is in Appendix B. From (9), we can see that the MSE between \u03b8\u0302KL\u2212C and \u03b8\u2217 reduces to O(N\u22121) as long as n & (N/d)1/2, which is a significant improvement over the KL-naive method which requires n & N/d. When the goal is to achieve an O( ) MSE, we would just need to take n & 1/(d )1/2 when N > 1/ , that is, n does not need to increase with N when N is very large.\nMeanwhile, because \u03b8\u0302KL\u2212C requires a linear combination of \u03b8\u0302k, \u03b8\u0303k and \u03b8\u0302KL, it carries the practical drawbacks of the linear averaging estimator as we discuss in Section 2. This motivates us to develop another KL-weighted method shown in the next section, which achieves the same asymptotical efficiency as \u03b8\u0302KL\u2212C , while still inherits all the practical advantages of KL-averaging."}, {"heading": "3.2 KL-Weighted Estimator", "text": "Our KL-weighted estimator is based on directly modifying the M-estimator for \u03b8\u0302KL in (4), by assigning each bootstrap data point x\u0303kj a positive weight according to the probability ratio p(x\u0303 k j | \u03b8\u0302k)/p(x\u0303 k j | \u03b8\u0303k) of the actual local model p(x|\u03b8\u0302k) and the re-estimated model p(x|\u03b8\u0303k) in (6). Here the probability ratio acts like a multiplicative control variate (Nelson, 1987), which has the advantage of being positive and applicable to non-identifiable, non-additive parameters. Our estimator is defined as\nKL-Weighted Estimator: \u03b8\u0302KL\u2212W = arg max \u03b8\u2208\u0398\n{ \u03b7\u0303(\u03b8) \u2261 d\u2211 k=1 1 n n\u2211 j=1 p(x\u0303kj |\u03b8\u0302k) p(x\u0303kj |\u03b8\u0303k) log p(x\u0303kj |\u03b8) } .\n(10) We first show that this weighted estimator \u03b7\u0303(\u03b8) gives a more accurate estimation of \u03b7(\u03b8) in (3) than the straightforward estimator \u03b7\u0302(\u03b8) defined in (4) for any \u03b8 \u2208 \u0398.\nLemma 4. As n\u2192\u221e, \u03b7\u0303(\u03b8) is a more accurate estimator of \u03b7(\u03b8) than \u03b7\u0302(\u03b8), in that\nnVar(\u03b7\u0303(\u03b8)) \u2264 nVar(\u03b7\u0302(\u03b8)), as n\u2192\u221e, for any \u03b8 \u2208 \u0398. (11)\nThis estimator is motivated by Henmi et al. (2007) in which the same idea is applied to reduce the asymptotic variance in importance sampling. Similar result is also found in Hirano et al. (2003), in which it is shown that a similar weighted estimator with estimated propensity score is more efficient than the estimator using true propensity score in estimating the average treatment effects. Although being a very powerful tool, results of this type seem to be not widely known in machine learning, except several applications in semi-supervised learning (Sokolovska et al., 2008; Kawakita and Kanamori, 2013), and off-policy learning (Li et al., 2015).\nWe go a step further to analyze the asymptotic property of our weighted M-estimator \u03b8\u0302KL\u2212W that maximizes \u03b7\u0303(\u03b8). It is natural to expect that the asymptotic variance of \u03b8\u0302KL\u2212W is smaller than that of \u03b8\u0302KL based on maximizing \u03b7\u0302(\u03b8); this is shown in the following theorem.\nTheorem 5. Under Assumption 1, \u03b8\u0302KL\u2212W is a consistent estimator of \u03b8\u2217KL as n\u2192\u221e, and has a better asymptotic variance than \u03b8\u0302KL, that is,\nnE\u2016\u03b8\u0302KL\u2212W \u2212 \u03b8\u2217KL\u20162 \u2264 nE\u2016\u03b8\u0302KL \u2212 \u03b8 \u2217 KL\u20162, when n\u2192\u221e.\nAlgorithm 2 KL-Weighted Method for Combining Local Models 1: Input: Local MLEs {\u03b8\u0302k}dk=1. 2: Generate bootstrap sample {x\u0303kj }nj=1 from each p(x|\u03b8\u0302k), for k \u2208 [d]. 3: Re-estimate the local model parameter \u03b8\u0303k in (6) based on bootstrap subsample {x\u0303kj }nj=1, for\neach k \u2208 [d]. 4: Output: The parameter \u03b8\u0302KL\u2212W of the combined model is given by (10).\nWhen N > n \u00d7 d, we have E\u2016\u03b8\u0302KL\u2212W \u2212 \u03b8\u2217KL\u20162 = O((dn2)\u22121) as n \u2192 \u221e. Further, its MSE for estimating the true parameter \u03b8\u2217 is\nE\u2016\u03b8\u0302KL\u2212W \u2212 \u03b8\u2217\u20162 = O(N\u22121 + (dn2)\u22121). (12)\nThe proof is in Appendix C. This result is parallel to Theorem 3 for the linear control variates estimator \u03b8\u0302KL\u2212C . Similarly, it reduces to an O(N\u22121) rate once we take n & (N/d)1/2.\nMeanwhile, unlike the linear control variates estimator, \u03b8\u0302KL\u2212W inherits all the practical advantages of KL-averaging: it can be applied whenever the KL-naive estimator can be applied, including for models with non-identifiable parameters, or with different numbers of parameters. The implementation of \u03b8\u0302KL\u2212W is also much more convenient (see Algorithm 2), since it does not need to calculate the Fisher information matrix as required by Algorithm 1."}, {"heading": "4 Empirical Experiments", "text": "We study the empirical performance of our methods on both simulated and real world datasets. We first numerically verify the convergence rates predicted by our theoretical results using simulated data, and then demonstrate the effectiveness of our methods in a challenging setting when the number of parameters of the local models are different as decided by Bayesian information criterion (BIC). Finally, we conclude our experiments by testing our methods on a set of real world datasets.\nThe models we tested include probabilistic principal components analysis (PPCA), mixture of PPCA and Gaussian Mixtures Models (GMM). GMM is given by p(x | \u03b8) = \u2211m s=1 \u03b1sN (\u00b5s,\u03a3s)\nwhere \u03b8 = (\u03b1s,\u00b5s,\u03a3s). PPCA model is defined with the help of a hidden variable t, p(x | \u03b8) =\u222b p(x | t; \u03b8)p(t | \u03b8)dt, where p(x | t; \u03b8) = N (x; \u00b5 + W t, \u03c32), and p(t | \u03b8) = N (t; 0, I) and\n\u03b8 = {\u00b5, W, \u03c32}. The mixture of PPCA is p(x | \u03b8) = \u2211m s=1 \u03b1sps(x | \u03b8s), where \u03b8 = {\u03b1s,\u03b8s}ms=1 and each ps(x | \u03b8s) is a PPCA model. Because all these models are latent variable models with unidentifiable parameters, the direct linear averaging method are not applicable. For GMM, it is still possible to use a matched linear averaging which matches the mixture components of the different local models by minimizing a symmetric KL divergence; the same idea can be used on our linear control variates method to make it applicable to GMM. On the other hand, because the parameters of PPCA-based models are unidentifiable up to arbitrary orthonormal transforms, linear averaging and linear control variates can no longer be applied easily. We use expectation maximization (EM) to learn the parameters in all these three models."}, {"heading": "4.1 Numerical Verification of the Convergence Rates", "text": "We start with verifying the convergence rates in (5), (9) and (12) of MSE E||\u03b8\u0302\u2212\u03b8\u2217||2 of the different estimators for estimating the true parameters. Because there is also an non-identifiability problem in calculating the MSE, we again use the symmetric KL divergence to match the mixture components, and evaluate the MSE on WW> to avoid the non-identifiability w.r.t. orthonormal transforms. To verify the convergence rates w.r.t. n, we fix d and let the total dataset N be very large so that N\u22121 is negligible. Figure 1 shows the results when we vary n, where we can see that the MSE of KL-naive \u03b8\u0302KL is O(n\u22121) while that of KL-control \u03b8\u0302KL\u2212C and KL-weighted \u03b8\u0302KL\u2212W are O(n\u22122); both are consistent with our results in (5), (9) and (12).\nIn Figure 2(a), we increase the number d of local machines, while using a fix n and a very large N , and find that both \u03b8\u0302KL and \u03b8\u0302KL\u2212W scales as O(d\u22121) as expected. Note that since the total\nobservation data size N is fixed, the number of data in each local machine is (N/d) and it decreases as we increase d. It is interesting to see that the performance of the KL-based methods actually increases with more partitions; this is, of course, with a cost of increasing the total bootstrap sample size dn as d increases. Figure 2(b) considers a different setting, in which we increase d when fixing the total observation data size N , and the total bootstrap sample size ntot = n\u00d7 d. According to (5) and (12), the MSEs of \u03b8\u0302KL and \u03b8\u0302KL\u2212W should be about O(n\u22121tot) and O(dn \u22122 tot) respectively when N is very large, and this is consistent with the results in Figure 2(b). It is interesting to note that the MSE of \u03b8\u0302KL is independent with d while that of \u03b8\u0302KL\u2212W increases linearly with d. This is not conflict with the fact that \u03b8\u0302KL\u2212W is better than \u03b8\u0302KL, since we always have d \u2264 ntot.\nFigure 2(c) shows the result when we set n = (N/d)\u03b1 and vary \u03b1, where we find that \u03b8\u0302KL\u2212W quickly converges to the global MLE as \u03b1 increases, while the KL-naive estimator \u03b8\u0302KL converges significantly slower. Figure 2(d) demonstrates the case when we increase N while fix d and n, where we see our KL-weighted estimator \u03b8\u0302KL\u2212W matches closely with N , except when N is very large in which case the O((dn2)\u22121) term starts to dominate, while KL-naive is much worse. We also find the linear averaging estimator performs poorly, and does not scale with O(N\u22121) as the theoretical rate claims; this is due to unidentifiable orthonormal transform in the PPCA model that we test on."}, {"heading": "4.2 Gaussian Mixture with Unknown Number of Components", "text": "We further apply our methods to a more challenging setting for distributed learning of GMM when the number of mixture components is unknown. In this case, we first learn each local model with EM and decide its number of components using BIC selection. Both linear averaging and KL-control \u03b8\u0302KL\u2212C are not applicable in this setting, and and we only test KL-naive \u03b8\u0302KL and KL-weighted \u03b8\u0302KL\u2212W . Since the MSE is also not computable due to the different dimensions, we evaluate \u03b8\u0302KL and \u03b8\u0302KL\u2212W using the log-likelihood on a hold-out testing dataset as shown in Figure 3. We can see that \u03b8\u0302KL\u2212W generally outperforms \u03b8\u0302KL as we expect, and the relative improvement increases\nsignificantly as the dimension of the observation data x increases. This suggests that our variance reduction technique works very efficiently in high dimension problems."}, {"heading": "4.3 Results on Real World Datasets", "text": "Finally, we apply our methods to several real word datasets, including the SensIT Vehicle dataset on which mixture of PPCA is tested, and the Covertype and Epsilon datasets on which GMM is tested. From Figure 4, we can see that our KL-Weight and KL-Control (when it is applicable) again perform the best. The (matched) linear averaging performs poorly on GMM (Figure 4(b)-(c)), while is not applicable on mixture of PPCA."}, {"heading": "5 Conclusion and Discussion", "text": "We propose two variance reduction techniques for distributed learning of complex probabilistic models, including a KL-weighted estimator that is both statistically efficient and widely applicable for even challenging practical scenarios. Both theoretical and empirical analysis is provided to demonstrate our methods. Future directions include extending our methods to discriminant learning tasks, as well as the more challenging deep generative networks on which the exact MLE is not computable tractable, and surrogate likelihood methods with stochastic gradient descent are need. We note that the same KL-averaging problem also appears in the \u201cknowledge distillation\" problem in Bayesian deep neural networks (Korattikara et al., 2015), and it seems that our technique can be applied straightforwardly."}, {"heading": "6 Appendix A", "text": "We study the asymptotic property of the KL-naive estimator \u03b8\u0302KL, and prove Theorem 2."}, {"heading": "6.1 Notations and Assumptions", "text": "To simplify the notations for the proofs in the following, we define the following notations.\ns(x;\u03b8) = log p(x | \u03b8); s\u0307(x;\u03b8) = \u2202 log p(x | \u03b8) \u2202\u03b8 ; s\u0308(x;\u03b8) = \u22022 log p(x | \u03b8) \u2202\u03b82 ; I(\u03b8) = E(s\u0308(x,\u03b8)); I(\u03b8\u0302k,\u03b8\u2217KL) = E(s\u0308(x,\u03b8 \u2217 KL) | \u03b8\u0302k).\n(13)\nWe start with investigating the theoretical property of \u03b8\u0302KL.\nLemma 6. Based on Assumption 1, as n\u2192\u221e, we have E(\u03b8\u0302KL \u2212 \u03b8\u2217KL) = o((dn)\u22121). Further, in terms of estimating the true parameter, we have\nE\u2016\u03b8\u0302KL \u2212 \u03b8\u2217\u20162 = O(N\u22121 + (dn)\u22121). (14)\nProof: Based on Equation (3) and (4), we know d\u2211 k=1 1 n n\u2211 j=1 s\u0307(x\u0303kj ; \u03b8\u0302KL)\u2212 d\u2211 k=1 \u222b p(x|\u03b8\u0302k)s\u0307(x;\u03b8\u2217KL)dx = 0. (15)\nBy the law of large numbers, we can rewrite Equation (15) as d\u2211 k=1 \u222b p(x|\u03b8\u0302k)s\u0307(x; \u03b8\u0302KL)dx\u2212 d\u2211 k=1 \u222b p(x|\u03b8\u0302k)s\u0307(x;\u03b8\u2217KL)dx = op( 1 n ). (16)\nWe also observe that s\u0307(x; \u03b8\u0302KL) \u2212 s\u0307(x;\u03b8\u2217KL) = [ \u222b 1 0 s\u0308(x;\u03b8\u2217KL + t(\u03b8\u0302KL \u2212 \u03b8 \u2217 KL))dt ] (\u03b8\u2217KL \u2212 \u03b8\u0302KL). Therefore, Equation (16) can be written as[ d\u2211 k=1 \u222b p(x|\u03b8\u0302k) \u222b 1 0 s\u0308(x;\u03b8\u2217KL + t(\u03b8\u0302KL \u2212 \u03b8 \u2217 KL))dtdx ] (\u03b8\u2217KL \u2212 \u03b8\u0302KL) = op( 1 n ). (17)\nUnder our Assumption 1, the Fish Information matrix I(\u03b8) is positive definite in a neighborhood of \u03b8\u2217, then we can find constant C1, C2 such that C1 \u2264 \u2016 \u222b p(x|\u03b8\u0302k) \u222b 1 0 s\u0308(x;\u03b8\u2217KL + t(\u03b8\u0302KL\u2212\u03b8 \u2217 KL))dtdx\u2016 \u2264 C2. Therefore, we can get E(\u03b8\u0302KL \u2212 \u03b8\u2217KL) = o((dn)\u22121).\nThe following theorem provides the MSE between \u03b8\u0302KL and \u03b8\u2217KL and that between \u03b8\u0302KL and \u03b8 \u2217.\nTheorem 7. Based on Assumption 1, as n\u2192\u221e, E\u2016\u03b8\u0302KL \u2212 \u03b8\u2217KL\u20162 = O( 1nd ). Further, in terms of estimating the true parameter, we have\nE\u2016\u03b8\u0302KL \u2212 \u03b8\u2217\u20162 = O(N\u22121 + (dn)\u22121). (18)\nProof: According to the Equation (4),\n\u03b8\u0302KL = arg max \u03b8\u2208\u0398 d\u2211 k=1 1 n n\u2211 j=1 s(x\u0303kj ;\u03b8). (19)\nThen the first order derivative of Equation (19) with respect to \u03b8 at \u03b8 = \u03b8\u0302KL is zero, d\u2211 k=1 1 n n\u2211 j=1 s\u0307(x\u0303kj ; \u03b8\u0302KL) = 0. (20)\nBy Taylor expansion of Equation (20), we get d\u2211 k=1 1 n n\u2211 j=1 (s\u0307(x\u0303kj ;\u03b8 \u2217 KL) + s\u0308(x\u0303 k j ; \u03b8\u0302KL)(\u03b8\u0302KL \u2212 \u03b8 \u2217 KL)) + op(\u03b8\u0302KL \u2212 \u03b8 \u2217 KL) = 0.\nBy the law of large numbers, 1n \u2211n j=1 s\u0308(x\u0303 k j ; \u03b8\u0302 \u2217 KL) = I(\u03b8\u0302k,\u03b8 \u2217 KL) + op( 1 n ). Under our Assumption 1, I(\u03b8) is positive definite in a neighborhood of \u03b8\u2217. Since \u03b8\u0302k are in the neighborhood of \u03b8\u2217, I(\u03b8\u0302k,\u03b8\u2217KL) is positive definite, for k = 1 \u2208 [d]. Then we have\n\u03b8\u0302KL \u2212 \u03b8\u2217KL = ( d\u2211 k=1 I(\u03b8\u0302k,\u03b8 \u2217 KL)) \u22121 d\u2211 k=1 1 n n\u2211 j=1 s\u0307(x\u0303kj ;\u03b8 \u2217 KL) + op( 1 n ) = 0. (21)\nBy the central limit theorem, 1\u221a n \u2211n j=1 s\u0307(x\u0303 k j ;\u03b8 \u2217 KL) converges to a normal distribution. By some simple calculation, we have\nCov(\u03b8\u0302KL\u2212\u03b8\u2217KL, \u03b8\u0302KL\u2212\u03b8 \u2217 KL) =\n1 n ( d\u2211 k=1 I(\u03b8\u0302k,\u03b8 \u2217 KL)) \u22121 d\u2211 k=1 Var(s\u0307(x;\u03b8\u2217KL) | \u03b8\u0302k)( d\u2211 k=1 I(\u03b8\u0302k,\u03b8 \u2217 KL)) \u22121.\n(22) According to our Assumption 1, we already know I(\u03b8\u0302k,\u03b8\u2217KL) is positive definite, C1 \u2264 \u2016I(\u03b8\u0302k,\u03b8\u2217KL)\u2016 \u2264 C2. We have ( \u2211d k=1 I(\u03b8\u0302k,\u03b8 \u2217 KL)) \u22121 = O( 1d ) and \u2211d k=1 Var(s\u0307(x;\u03b8 \u2217 KL) | \u03b8\u0302k) = O(d). Therefore, E\u2016\u03b8\u0302KL \u2212 \u03b8\u2217KL\u20162 = trace(Cov(\u03b8\u0302KL \u2212 \u03b8 \u2217 KL, \u03b8\u0302KL \u2212 \u03b8 \u2217 KL)) = O( 1 nd ). Because the MSE between the exact KL estimator \u03b8\u2217KL and the true parameter \u03b8 \u2217 is O(N\u22121) as shown in Liu and Ihler (2014), the MSE between \u03b8\u0302KL and the true parameter \u03b8\u2217 is\nE\u2016\u03b8\u0302KL \u2212 \u03b8\u2217\u20162 \u2248 E\u2016\u03b8\u0302KL \u2212 \u03b8\u2217KL\u20162 + E\u2016\u03b8 \u2217 KL \u2212 \u03b8 \u2217\u20162 = O(N\u22121 + (dn)\u22121). We complete the proof of this theorem."}, {"heading": "7 Appendix B", "text": "In this section, we analyze the MSE of our proposed estimator \u03b8\u0302KL\u2212C and prove Theorem 3.\nTheorem 8. Under Assumptions 1, we have\nas n\u2192\u221e, nE\u2016\u03b8\u0302KL\u2212C \u2212 \u03b8\u2217KL\u20162 < nE\u2016\u03b8\u0302KL \u2212 \u03b8 \u2217 KL\u20162.\nSince \u03b8\u0303k is the MLE of data {x\u0303kj }nj=1, then we have\n(\u03b8\u0303k \u2212 \u03b8\u0302k) = \u2212I(\u03b8\u0302k)\u22121 1\nn n\u2211 j=1 s\u0307(x\u0303kj ; \u03b8\u0302k) + op( 1 n ). (23)\nThen E(\u03b8\u0303k \u2212 \u03b8\u0302k) = o( 1n ). According to Theorem (2), when Bk is a constant matrix, for k \u2208 [d],\nE(\u03b8\u0302KL\u2212C \u2212 \u03b8\u2217KL) = E(\u03b8\u0302KL \u2212 \u03b8 \u2217 KL) + d\u2211 k=1 BkE(\u03b8\u0303k \u2212 \u03b8\u0302k) = o( 1 n ).\nNotice that 1n \u2211n j=1 s\u0307(x\u0303 r j ; \u03b8\u0302r) and 1 n \u2211n j=1 s\u0307(x\u0303 t j ; \u03b8\u0302t) are independent when r 6= t. According to\nEquation (21), we know \u2211d k=1 1 n \u2211n j=1 s\u0307(x\u0303 k j ;\u03b8 \u2217 KL) and 1 n \u2211n j=1 s\u0307(x\u0303 k j ; \u03b8\u0302k) are correlated to each other for k \u2208 [d],\nCov((\u03b8\u0302KL\u2212C \u2212 \u03b8\u2217KL), (\u03b8\u0302KL\u2212C \u2212 \u03b8 \u2217 KL)) = Cov(\u03b8\u0302KL \u2212 \u03b8 \u2217 KL, \u03b8\u0302KL \u2212 \u03b8 \u2217 KL)\n+ 2 d\u2211 k=1 BkCov(\u03b8\u0302KL \u2212 \u03b8KL, \u03b8\u0303k \u2212 \u03b8\u0302k)T + d\u2211 k=1 BkCov((\u03b8\u0303k \u2212 \u03b8\u0302k), (\u03b8\u0303k \u2212 \u03b8\u0302k))BTk .\nWhenBk = \u2212(Cov(\u03b8\u0303k \u2212 \u03b8\u0302k, \u03b8\u0303k \u2212 \u03b8\u0302k))\u22121Cov(\u03b8\u0302KL \u2212 \u03b8\u2217KL, \u03b8\u0303k \u2212 \u03b8\u0302k), we have\nCov(\u03b8\u0302KL\u2212C \u2212 \u03b8\u2217KL, \u03b8\u0302KL\u2212C \u2212 \u03b8 \u2217 KL) = Cov(\u03b8\u0302KL \u2212 \u03b8 \u2217 KL, \u03b8\u0302KL \u2212 \u03b8 \u2217 KL)\u2212\nd\u2211 k=1 Cov(\u03b8\u0303k \u2212 \u03b8\u0302k, \u03b8\u0303k \u2212 \u03b8\u0302k)\u22121Cov(\u03b8\u0302KL \u2212 \u03b8\u2217KL, \u03b8\u0303k \u2212 \u03b8\u0302k)Cov(\u03b8\u0302KL \u2212 \u03b8 \u2217 KL, \u03b8\u0303k \u2212 \u03b8\u0302k)T . (24)\nWe know E\u2016\u03b8\u0302KL\u2212C \u2212 \u03b8\u2217KL\u20162 = trace(Cov(\u03b8\u0302KL\u2212C \u2212 \u03b8 \u2217 KL, \u03b8\u0302KL\u2212C \u2212 \u03b8 \u2217 KL)), E\u2016\u03b8\u0302KL \u2212 \u03b8 \u2217 KL\u20162 = trace(Cov(\u03b8\u0302KL\u2212\u03b8\u2217KL, \u03b8\u0302KL\u2212\u03b8 \u2217 KL)). The second term of Equation (24) is a positive definite matrix, therefore we have nE\u2016\u03b8\u0302KL\u2212C \u2212 \u03b8\u2217KL\u20162 < nE\u2016\u03b8\u0302KL \u2212 \u03b8 \u2217 KL\u20162 as n\u2192\u221e. We complete the proof of this theorem.\nTheorem 9. Under Assumption 1, when N > n \u00d7 d, we have E\u2016\u03b8\u0302KL\u2212C \u2212 \u03b8\u2217KL\u20162 = O( 1dn2 ) as n\u2192\u221e. Further, in terms of estimating the true parameter, we have\nE\u2016\u03b8\u0302KL\u2212C \u2212 \u03b8\u2217\u20162 = O(N\u22121 + (dn2)\u22121).\nFrom Equation (4), we know\nd\u2211 k=1 1 n n\u2211 j=1 \u2202 log p(x\u0303kj |\u03b8\u0302KL) \u2202\u03b8 = 0. (25)\nBy Taylor expansion, Equation (25) can be rewritten as\nd\u2211 k=1 [ 1 n n\u2211 j=1 s\u0307(x\u0303kj ; \u03b8\u0302k) + s\u0308(x\u0303 k j ; \u03b8\u0302k)(\u03b8\u0302KL \u2212 \u03b8\u0302k)) +Op(\u2016\u03b8\u0302KL \u2212 \u03b8\u0302k\u20162)] = 0. (26)\n\u2016\u03b8\u0302KL \u2212 \u03b8\u0302k\u20162 \u2264 \u2016\u03b8\u0302KL \u2212 \u03b8\u2217KL\u20162 + \u2016\u03b8 \u2217 KL \u2212 \u03b8\u0302k\u20162. As we know from Liu and Ihler (2014), we have\n\u2016\u03b8\u2217KL \u2212 \u03b8\u0302k\u20162 \u2264 \u2016\u03b8 \u2217 KL \u2212 \u03b8 \u2217\u20162 + \u2016\u03b8\u2217 \u2212 \u03b8\u0302k\u20162 = Op( d\nN ), (27)\nWhen N > n\u00d7 d, we have \u2016\u03b8\u0302KL \u2212 \u03b8\u0302k\u20162 = Op( 1nd ). And it is also easy to derive\n\u03b8\u0302KL\u2212 \u03b8\u0302k = \u03b8\u0302KL\u2212\u03b8\u2217KL +\u03b8 \u2217 KL\u2212\u03b8 \u2217+\u03b8\u2217\u2212 \u03b8\u0302k = op( 1\nN )+op(\n1\nN )+op(\nd N ) = op( 1 nd + d N ), (28)\nwhere \u03b8\u2217KL \u2212 \u03b8 \u2217 = op( 1 N ) has been proved in Liu and Ihler\u2019s paper(2014). According to the law of large numbers, 1n \u2211n j=1 s\u0308(x\u0303 k j ; \u03b8\u0302k) = I(\u03b8\u0302k) + op( 1 n ), then we have\n(\u03b8\u0302KL \u2212 \u03b8\u2217KL) = \u2212( d\u2211 k=1 I(\u03b8\u0302k)) \u22121 d\u2211 k=1 1 n n\u2211 j=1 s\u0307(x\u0303kj ; \u03b8\u0302k) +Op( 1 nd ). (29)\nNotie that 1n \u2211n j=1 s\u0307(x\u0303 r j ; \u03b8\u0302r) and 1 n \u2211n j=1 s\u0307(x\u0303 t j ; \u03b8\u0302t) are independent when r 6= t. Therefore from (23) and (29), the covariance matrix of n(\u03b8\u0302KL \u2212 \u03b8\u2217KL) and n(\u03b8\u0303k \u2212 \u03b8\u0302k) is\nCov(n(\u03b8\u0302KL \u2212 \u03b8\u2217KL), n(\u03b8\u0303k \u2212 \u03b8\u0302k)) = n( d\u2211 k=1 I(\u03b8\u0302k)) \u22121 + ( d\u2211 k=1 I(\u03b8\u0302k)) \u22121O(1),\nfor k \u2208 [d]. According to Assumption 1, we know \u2211d k=1 I(\u03b8\u0302k) = O(d). Then we will have\nCov(n(\u03b8\u0302KL \u2212 \u03b8\u2217KL), n(\u03b8\u0303k \u2212 \u03b8\u0302k)) = n( d\u2211 k=1 I(\u03b8\u0302k)) \u22121 +O( 1 d ), for k \u2208 [d]. (30)\nAccording to Theorem 2 and Equation (22), by the law of large numbers, it is easy to derive\nCov(n(\u03b8\u0302KL \u2212 \u03b8\u2217KL), n(\u03b8\u0302KL \u2212 \u03b8 \u2217 KL)) = n( d\u2211 k=1 I(\u03b8\u0302k)) \u22121 + o(1).\nCov(n(\u03b8\u0302KL\u2212C \u2212 \u03b8\u2217KL), n(\u03b8\u0302KL\u2212C \u2212 \u03b8 \u2217 KL)) = Cov(n(\u03b8\u0302KL \u2212 \u03b8 \u2217 KL), n(\u03b8\u0302KL \u2212 \u03b8 \u2217 KL)\n+ 2 d\u2211 k=1 BkCov(n(\u03b8\u0302KL \u2212 \u03b8\u2217KL), n(\u03b8\u0303k \u2212 \u03b8\u0302k))> + d\u2211 k=1 BkCov(n(\u03b8\u0303k \u2212 \u03b8\u0302k), n(\u03b8\u0303k \u2212 \u03b8\u0302k))BTk ,\n(31)\nwhere Bk is defined in (8),\nBk = \u2212( d\u2211 k=1 I(\u03b8\u0302k)) \u22121I(\u03b8\u0302k), k \u2208 [d].\nAccording to Equation (23), we know Cov(n(\u03b8\u0303k \u2212 \u03b8\u0302k), n(\u03b8\u0303k \u2212 \u03b8\u0302k)) = n(I(\u03b8\u0302k))\u22121 + o(1). By some simple calculation, we know that n2Cov(\u03b8\u0302KL\u2212C \u2212 \u03b8\u2217KL, \u03b8\u0302KL\u2212C \u2212 \u03b8 \u2217 KL) = O( 1 d ). Therefore, under the Assumption 1, when N > n\u00d7 d, we get the following result,\nE\u2016\u03b8\u0302KL\u2212C \u2212 \u03b8\u2217KL\u20162 = trace(Cov(\u03b8\u0302KL\u2212C \u2212 \u03b8 \u2217 KL, \u03b8\u0302KL\u2212C \u2212 \u03b8 \u2217 KL)) = O(\n1\ndn2 ).\nWe know E\u2016\u03b8\u2217KL \u2212 \u03b8 \u2217\u20162 = O(N\u22121) from Liu and Ihler (2014). Then we have\nE\u2016\u03b8\u0302KL\u2212C \u2212 \u03b8\u2217\u20162 \u2248 E\u2016\u03b8\u0302KL\u2212C \u2212 \u03b8\u2217KL\u20162 + E\u2016\u03b8 \u2217 KL \u2212 \u03b8 \u2217\u20162 = O(N\u22121 + (dn2)\u22121).\nThe proof of this theorem is complete."}, {"heading": "8 Appendix C", "text": "In this section, we analyze the asymptotic property of \u03b8\u0302KL\u2212W and prove Theorem 5. We show the MSE between \u03b8\u0302KL\u2212W and \u03b8\u2217KL is much smaller than the MSE between the KL-naive estimator \u03b8\u0302KL and \u03b8\u2217KL.\nLemma 10. Under Assumption 1, as n\u2192\u221e, \u03b7\u0303(\u03b8) is a more accurate estimator of \u03b7(\u03b8) than \u03b7\u0302(\u03b8), i.e.,\nnVar(\u03b7\u0303(\u03b8)) \u2264 nVar(\u03b7\u0302(\u03b8)), for any \u03b8 \u2208 \u0398. (32)\nBy Taylor expansion,\np(x|\u03b8\u0302k) p(x|\u03b8\u0303k) = 1 + (log p(x|\u03b8\u0302k)\u2212 log p(x|\u03b8\u0303k)) +Op(\u2016\u03b8\u0303k \u2212 \u03b8\u0302k\u20162), (33)\nwe will have\n\u03b7\u0303(\u03b8) = d\u2211 k=1 [ 1 n n\u2211 j=1 (1 + (s(x\u0303kj ; \u03b8\u0302k)\u2212 s(x\u0303 k j ; \u03b8\u0303k)))s(x\u0303 k j ;\u03b8) +Op(\u2016\u03b8\u0303k \u2212 \u03b8\u0302k\u20162)],\nSince s(x; \u03b8\u0302k)\u2212 s(x; \u03b8\u0303k) = s\u0307(x; \u03b8\u0302k)(\u03b8\u0302k \u2212 \u03b8\u0303k), according to equation (23), we have\n\u03b7\u0303(\u03b8) = \u03b7\u0302(\u03b8)\u2212 d\u2211 k=1 1 n n\u2211 j=1 s(x\u0303kj ;\u03b8)s\u0307(x\u0303 k j ; \u03b8\u0302k)(\u03b8\u0303k \u2212 \u03b8\u0302 k ) +Op(\u2016\u03b8\u0303k \u2212 \u03b8\u0302k\u20162),\nThen according to equation (23), we have\n\u03b7\u0302(\u03b8) = \u03b7\u0303(\u03b8)\u2212 d\u2211 k=1 E(s(x\u0303kj ;\u03b8)s\u0307(x\u0303 k j ; \u03b8\u0302k) | \u03b8\u0302k))I(\u03b8\u0302k)\u22121 1 n n\u2211 j=1 s\u0307(x\u0303kj ; \u03b8\u0302k) +Op( d n ),\nDenote \u03be\u0302(\u03b8) = \u2212 \u2211d k=1 E(s(x\u0303 k j ;\u03b8)s\u0307(x\u0303 k j ; \u03b8\u0302k) | \u03b8\u0302k))I(\u03b8\u0302k)\u22121 1n \u2211n j=1 s\u0307(x k j ; \u03b8\u0302k). According to\nHenmi et al. (2007), \u03be\u0302(\u03b8) is the orthogonal projection of \u03b7\u0302(\u03b8) onto the linear space spanned by the score vector component for each \u03b8\u0302k, where k \u2208 [d]. Then we will have Var(\u03b7\u0302(\u03b8)) = Var(\u03b7\u0303(\u03b8)) + Var(\u03be\u0302(\u03b8)). Therefore, nVar(\u03b7\u0303(\u03b8)) \u2264 nVar(\u03b7\u0302(\u03b8)).\nTheorem 11. Under the Assumption 1, for any {\u03b8\u0302k}, we have that\nas n\u2192\u221e, nE\u2016\u03b8\u0302KL\u2212W \u2212 \u03b8\u2217KL\u20162 \u2264 nE\u2016\u03b8\u0302KL \u2212 \u03b8 \u2217 KL\u20162.\nProof: From Equation (10), we know d\u2211 k=1 1 n n\u2211 j=1 p(x\u0303kj |\u03b8\u0302k) p(x\u0303kj |\u03b8\u0303k) s\u0307(x\u0303kj ; \u03b8\u0302KL\u2212W ) = 0.\nSince p(x|\u03b8\u0302k) p(x|\u03b8\u0303k) = exp{log p(x|\u03b8\u0302k)\u2212 log p(x|\u03b8\u0303k)} = 1 + (log p(x|\u03b8\u0302k)\u2212 log p(x|\u03b8\u0303k)) +Op(\u2016\u03b8\u0303k \u2212 \u03b8\u0302k\u20162), we have d\u2211 k=1 1 n n\u2211 j=1 s\u0307(xkj ; \u03b8\u0302KL\u2212W )\u2212 d\u2211 k=1 [ 1 n n\u2211 j=1 s\u0307(xkj ; \u03b8\u0302KL\u2212W )s\u0307(x k j ; \u03b8\u0302k) T (\u03b8\u0303k\u2212\u03b8\u0302k)+Op(\u2016\u03b8\u0303k\u2212\u03b8\u0302k\u20162)] = 0. (34) From the asymptotic property of MLE, we know E\u2016\u03b8\u0303k \u2212 \u03b8\u0302k\u20162 = 1n trace(I(\u03b8\u0302k)). Therefore, we know \u2016\u03b8\u0303k \u2212 \u03b8\u0302k\u20162 = Op( 1n ) and \u2211d k=1 \u2016\u03b8\u0303k \u2212 \u03b8\u0302k\u20162 = Op( d n ).\nSimilar to the derivation of equation (21), according to equation (23), we have the following equation,\n\u03b8\u0302KL\u2212W\u2212\u03b8\u2217KL = ( d\u2211 k=1 I(\u03b8\u0302k,\u03b8 \u2217 KL)) \u22121 d\u2211 k=1 1 n n\u2211 j=1 s\u0307(x\u0303kj ;\u03b8 \u2217 KL)\u2212\n( d\u2211 k=1 I(\u03b8\u0302k,\u03b8 \u2217 KL)) \u22121 d\u2211 k=1 E(s\u0307(x\u0303kj ; \u03b8\u0302KL\u2212W )T s\u0307(x\u0303 k j ; \u03b8\u0302k) | \u03b8\u0302k) 1 n n\u2211 j=1 s\u0307(x\u0303kj ; \u03b8\u0302k) = Op( d n ).\nThen we have,\n\u03b8\u0302KL\u2212\u03b8\u2217KL = \u03b8\u0302KL\u2212W \u2212 \u03b8 \u2217 KL\n\u2212 ( d\u2211 k=1 I(\u03b8\u0302k,\u03b8 \u2217 KL)) \u22121 d\u2211 k=1 E(s\u0307(x\u0303kj ; \u03b8\u0302KL\u2212W )T s\u0307(x\u0303 k j ; \u03b8\u0302k) | \u03b8\u0302k) 1 n n\u2211 j=1 s\u0307(x\u0303kj ; \u03b8\u0302k) = Op( d n ).\nAccording to Henmi et al.(2007), we know the second term of above equation is the orthogonal projection of (\u03b8\u0302KL \u2212 \u03b8\u2217KL) onto the linear space spanned by the score component for each \u03b8\u0302k, for k \u2208 [d]. Then\nnE\u2016\u03b8\u0302KL\u2212W \u2212 \u03b8\u2217KL\u20162 \u2264 nE\u2016\u03b8\u0302KL \u2212 \u03b8 \u2217 KL\u20162.\nWe complete the proof of this theorem.\nTheorem 12. Under the Assumptions 1, when N > n\u00d7 d, E\u2016\u03b8\u0302KL\u2212W \u2212 \u03b8\u2217KL\u20162 = O( 1dn2 ). Further, its MSE for estimating the true parameter \u03b8\u2217 is\nE\u2016\u03b8\u0302KL\u2212W \u2212 \u03b8\u2217\u20162 = O(N\u22121 + (dn2)\u22121).\nAccording to Equation (34),\nd\u2211 k=1 1 n n\u2211 j=1 s\u0307(x\u0303kj ; \u03b8\u0302KL\u2212W )\u2212 d\u2211 k=1 1 n n\u2211 j=1 s\u0307(x\u0303kj ; \u03b8\u0302KL\u2212W )s\u0307(x\u0303 k j ; \u03b8\u0302k) T (\u03b8\u0303k \u2212 \u03b8\u0302k) = Op( d n ).\nApproximating the first term of the above equation by Taylor expansion, we will get\nd\u2211 k=1 1 n n\u2211 j=1 s\u0307(x\u0303kj ; \u03b8\u0302KL\u2212W ) = d\u2211 k=1 [ 1 n n\u2211 j=1 s\u0307(x\u0303kj ; \u03b8\u0302k)\n+ d\u2211 k=1 1 n n\u2211 j=1 s\u0308(x\u0303kj ; \u03b8\u0302k)(\u03b8\u0302KL\u2212W \u2212 \u03b8\u0302k) +Op(\u2016\u03b8\u0302KL\u2212W \u2212 \u03b8\u0302k\u20162)]. (35)\nSince \u2016\u03b8\u0302KL\u2212W \u2212 \u03b8\u0302k\u20162 \u2264 \u2016\u03b8\u0302KL\u2212W \u2212 \u03b8\u2217KL\u20162 + \u2016\u03b8 \u2217 KL \u2212 \u03b8\u0302k\u20162, according to equation (27), then \u2016\u03b8\u0302KL\u2212W\u2212\u03b8\u0302k\u20162 = Op(\u2016\u03b8\u0302KL\u2212W\u2212\u03b8\u2217KL\u20162+ dN ).We can easily derive s\u0307(x\u0303 k j ; \u03b8\u0302KL\u2212W ) = s\u0307(x\u0303 k j ; \u03b8\u0302k)+\nOp(\u03b8\u0302KL\u2212W \u2212 \u03b8\u0302k) for k \u2208 [d]. When N > n\u00d7 d, we will have d\u2211 k=1 1 n n\u2211 j=1 s\u0307(x\u0303kj ; \u03b8\u0302k) + d\u2211 k=1 1 n n\u2211 j=1 s\u0308(x\u0303kj ; \u03b8\u0302k)(\u03b8\u0302KL\u2212W \u2212 \u03b8\u0302k)\n\u2212 \u2211 k 1 n n\u2211 j=1 s\u0307(xkj ; \u03b8\u0302k)s\u0307(x\u0303 k j ; \u03b8\u0302k) T (\u03b8\u0303k \u2212 \u03b8\u0302k) +Op(\u2016\u03b8\u0302KL\u2212W \u2212 \u03b8\u2217KL\u20162) = O( d n ). (36)\n1 n \u2211n j=1 s\u0308(x\u0303 k j ; \u03b8\u0302k) = I(\u03b8\u0302k)+op( 1 n ) and we also know that 1 n \u2211n j=1 s\u0307(x\u0303 k j ; \u03b8\u0302k)s\u0307(x\u0303 k j ; \u03b8\u0302k) T = I(\u03b8\u0302k)+ op(1). From (28), we know \u03b8\u2217KL \u2212 \u03b8\u0302k = op( dN ) = op( 1 n ). When N > n\u00d7 d, we have\nd\u2211 k=1 1 n n\u2211 j=1 s\u0307(x\u0303kj ; \u03b8\u0302k)+ d\u2211 k=1 I(\u03b8\u0302k)(\u03b8\u0302KL\u2212W \u2212 \u03b8\u2217KL)\n+ d\u2211 k=1 1 n I(\u03b8\u0302k)(\u03b8\u0303k \u2212 \u03b8\u0302k)) +Op(\u2016\u03b8\u0302KL\u2212W \u2212 \u03b8\u2217KL\u20162) = O( d n ).\n(37)\nBased on the Equation (23), the first term and the third term of Equation (37) are cancelled. By some simple calculation, we will get\nn2(\u03b8\u0302KL\u2212W \u2212 \u03b8\u2217KL)T ( d\u2211 k=1 I(\u03b8\u0302k))( d\u2211 k=1 I(\u03b8\u0302k))(\u03b8\u0302KL\u2212W \u2212 \u03b8\u2217KL) = Op(d). (38)\nThis indicates, Cov(n( \u2211d k=1 I(\u03b8\u0302k))(\u03b8\u0302KL\u2212W \u2212 \u03b8 \u2217 KL), n( \u2211d k=1 I(\u03b8\u0302k))(\u03b8\u0302KL\u2212W \u2212 \u03b8 \u2217 KL)) = O(d) as n \u2192 \u221e. We know n2E\u2016\u03b8\u0302KL\u2212W \u2212 \u03b8\u2217KL\u20162 = trace(Cov(n(\u03b8\u0302KL\u2212W \u2212 \u03b8 \u2217 KL), n(\u03b8\u0302KL\u2212W \u2212\n\u03b8\u2217KL)). According to Assumption 1, I(\u03b8\u0302k) is positive definite and then trace( \u2211d k=1 I(\u03b8\u0302k)) = O(d). Therefore, we have\nE\u2016\u03b8\u0302KL\u2212W \u2212 \u03b8\u2217KL\u20162 = O( d\nd2n2 ) = O(\n1\ndn2 ).\nWe know E\u2016\u03b8\u2217KL \u2212 \u03b8 \u2217\u20162 = O(N\u22121) from Liu and Ihler (2014). Then we have\nE\u2016\u03b8\u0302KL\u2212W \u2212 \u03b8\u2217\u20162 \u2248 E\u2016\u03b8\u0302KL\u2212W \u2212 \u03b8\u2217KL\u20162 + E\u2016\u03b8 \u2217 KL \u2212 \u03b8 \u2217\u20162 = O(N\u22121 + (dn2)\u22121).\nThe proof of this theorem is complete."}], "references": [{"title": "Communication-efficient algorithms for statistical optimization", "author": ["Y. Zhang", "M.J. Wainwright", "J.C. Duchi"], "venue": "In NIPS,", "citeRegEx": "Zhang et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Zhang et al\\.", "year": 2012}, {"title": "Optimal distributed online prediction using mini-batches", "author": ["O. Dekel", "R. Gilad-Bachrach", "O. Shamir", "L. Xiao"], "venue": "In JMLR,", "citeRegEx": "Dekel et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Dekel et al\\.", "year": 2012}, {"title": "Distributed estimation, information loss and exponential families", "author": ["Q. Liu", "A.T. Ihler"], "venue": "In NIPS,", "citeRegEx": "Liu and Ihler.,? \\Q2014\\E", "shortCiteRegEx": "Liu and Ihler.", "year": 2014}, {"title": "On the optimality of averaging in distributed statistical learning", "author": ["J. Rosenblatt", "B. Nadler"], "venue": "arXiv preprint arXiv:1407.2724,", "citeRegEx": "Rosenblatt and Nadler.,? \\Q2014\\E", "shortCiteRegEx": "Rosenblatt and Nadler.", "year": 2014}, {"title": "Information-theoretic lower bounds for distributed statistical estimation with communication constraints", "author": ["Y. Zhang", "J. Duchi", "M.I. Jordan", "M.J. Wainwright"], "venue": "In NIPS,", "citeRegEx": "Zhang et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Zhang et al\\.", "year": 2013}, {"title": "Privacy-preserving distributed clustering using generative models", "author": ["S. Merugu", "J. Ghosh"], "venue": "In Data Mining,", "citeRegEx": "Merugu and Ghosh.,? \\Q2003\\E", "shortCiteRegEx": "Merugu and Ghosh.", "year": 2003}, {"title": "Communication efficient distributed optimization using an approximate Newton-type method", "author": ["O. Shamir", "N. Srebro", "T. Zhang"], "venue": "In ICML,", "citeRegEx": "Shamir et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Shamir et al\\.", "year": 2014}, {"title": "A distributed one-step estimator", "author": ["C. Huang", "X. Huo"], "venue": "arXiv preprint arXiv:1511.01443,", "citeRegEx": "Huang and Huo.,? \\Q2015\\E", "shortCiteRegEx": "Huang and Huo.", "year": 2015}, {"title": "Variance reduction techniques for digital simulation", "author": ["J.R. Wilson"], "venue": "American Journal of Mathematical and Management Sciences,", "citeRegEx": "Wilson.,? \\Q1984\\E", "shortCiteRegEx": "Wilson.", "year": 1984}, {"title": "On control variate estimators", "author": ["B.L. Nelson"], "venue": "Computers & Operations Research,", "citeRegEx": "Nelson.,? \\Q1987\\E", "shortCiteRegEx": "Nelson.", "year": 1987}, {"title": "Importance sampling via the estimated sampler", "author": ["M. Henmi", "R. Yoshida", "S. Eguchi"], "venue": null, "citeRegEx": "Henmi et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Henmi et al\\.", "year": 2007}, {"title": "Efficient estimation of average treatment effects using the estimated propensity", "author": ["K. Hirano", "G.W. Imbens", "G. Ridder"], "venue": "score. Econometrica,", "citeRegEx": "Hirano et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Hirano et al\\.", "year": 2003}, {"title": "The asymptotics of semi-supervised learning in discriminative probabilistic models", "author": ["N. Sokolovska", "O. Capp\u00e9", "F. Yvon"], "venue": "In ICML. ACM,", "citeRegEx": "Sokolovska et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Sokolovska et al\\.", "year": 2008}, {"title": "Semi-supervised learning with density-ratio estimation", "author": ["M. Kawakita", "T. Kanamori"], "venue": "Machine learning,", "citeRegEx": "Kawakita and Kanamori.,? \\Q2013\\E", "shortCiteRegEx": "Kawakita and Kanamori.", "year": 2013}, {"title": "Toward minimax off-policy value estimation", "author": ["L. Li", "R. Munos", "C. Szepesv\u00e1ri"], "venue": "In AISTATS,", "citeRegEx": "Li et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Li et al\\.", "year": 2015}, {"title": "Bayesian dark knowledge", "author": ["A. Korattikara", "V. Rathod", "K. Murphy", "M. Welling"], "venue": "arXiv preprint arXiv:1506.04416,", "citeRegEx": "Korattikara et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Korattikara et al\\.", "year": 2015}, {"title": "\u03be\u0302(\u03b8) is the orthogonal projection of \u03b7\u0302(\u03b8) onto the linear space spanned by the score vector component for each \u03b8\u0302k, where k \u2208 [d]. Then we will have Var(\u03b7\u0302(\u03b8)) = Var(\u03b7\u0303(\u03b8)) + Var(\u03be\u0302(\u03b8)). Therefore, nVar(\u03b7\u0303(\u03b8)) \u2264 nVar(\u03b7\u0302(\u03b8))", "author": ["\u03b8\u0302k"], "venue": null, "citeRegEx": "\u03b8\u0302k..,? \\Q2007\\E", "shortCiteRegEx": "\u03b8\u0302k..", "year": 2007}], "referenceMentions": [{"referenceID": 3, "context": "Many studies have been focused on a simple linear averaging method that linearly averages the parameters of the local models (e.g., Zhang et al., 2012, 2013; Rosenblatt and Nadler, 2014); although nearly optimal asymptotic error rates can be achieved, this simple method tends to degenerate in practical scenarios for models with non-convex log-likelihood or non-identifiable parameters (such as latent variable models, and neural models), and is not applicable at all for models with non-additive parameters (e.", "startOffset": 125, "endOffset": 186}, {"referenceID": 2, "context": "A better strategy that overcomes all these practical limitations of linear averaging is the KL-averaging method (Liu and Ihler, 2014; Merugu and Ghosh, 2003), which finds a model that minimizes the sum of Kullback-Leibler (KL) divergence to all the local models.", "startOffset": 112, "endOffset": 157}, {"referenceID": 5, "context": "A better strategy that overcomes all these practical limitations of linear averaging is the KL-averaging method (Liu and Ihler, 2014; Merugu and Ghosh, 2003), which finds a model that minimizes the sum of Kullback-Leibler (KL) divergence to all the local models.", "startOffset": 112, "endOffset": 157}, {"referenceID": 0, "context": "(2011); Zhang et al. (2012); Dekel et al.", "startOffset": 8, "endOffset": 28}, {"referenceID": 0, "context": "(2011); Zhang et al. (2012); Dekel et al. (2012); Liu and Ihler (2014); Rosenblatt and Nadler (2014) and reference therein.", "startOffset": 8, "endOffset": 49}, {"referenceID": 0, "context": "(2011); Zhang et al. (2012); Dekel et al. (2012); Liu and Ihler (2014); Rosenblatt and Nadler (2014) and reference therein.", "startOffset": 8, "endOffset": 71}, {"referenceID": 0, "context": "(2011); Zhang et al. (2012); Dekel et al. (2012); Liu and Ihler (2014); Rosenblatt and Nadler (2014) and reference therein.", "startOffset": 8, "endOffset": 101}, {"referenceID": 6, "context": "Although distributed optimization algorithms exist (e.g., Boyd et al., 2011; Shamir et al., 2014), they require iterative communication between the local machines and a fusion center, which can be very time consuming in distributed settings, for which the number of communication rounds forms the main bottleneck (regardless of the amount of information communicated at each round).", "startOffset": 51, "endOffset": 97}, {"referenceID": 3, "context": "Comprehensive theoretical analysis has been done for \u03b8\u0302linear (e.g., Zhang et al., 2012; Rosenblatt and Nadler, 2014), which show that it has an asymptotic MLE of E||\u03b8\u0302linear \u2212 \u03b8\u2217|| = O(N\u22121).", "startOffset": 62, "endOffset": 117}, {"referenceID": 7, "context": "In fact, it is equivalent to the global MLE \u03b8\u0302mle up to the first order O(N\u22121), and several improvements have been developed to improve the second order term (e.g., Zhang et al., 2012; Huang and Huo, 2015).", "startOffset": 158, "endOffset": 205}, {"referenceID": 5, "context": "All these problems of linear averaging can be well addressed by a KL-averaging method which averages the model (instead of the parameters) by finding a geometric center of the local models in terms of KL divergence (Merugu and Ghosh, 2003; Liu and Ihler, 2014).", "startOffset": 215, "endOffset": 260}, {"referenceID": 2, "context": "All these problems of linear averaging can be well addressed by a KL-averaging method which averages the model (instead of the parameters) by finding a geometric center of the local models in terms of KL divergence (Merugu and Ghosh, 2003; Liu and Ihler, 2014).", "startOffset": 215, "endOffset": 260}, {"referenceID": 2, "context": "Further discussions on the practical limitaions of the linear averaging method can be found in Liu and Ihler (2014). All these problems of linear averaging can be well addressed by a KL-averaging method which averages the model (instead of the parameters) by finding a geometric center of the local models in terms of KL divergence (Merugu and Ghosh, 2003; Liu and Ihler, 2014).", "startOffset": 95, "endOffset": 116}, {"referenceID": 2, "context": "(3) Liu and Ihler (2014) studied the theoretical properties of the KL-averaging method, and showed that it exactly recovers the global MLE, that is, \u03b8KL = \u03b8\u0302mle, when the distribution family is a full exponential family, and achieves an optimal asymptotic error rate (up to the second order) among all the possible combination methods of {\u03b8\u0302k}.", "startOffset": 4, "endOffset": 25}, {"referenceID": 2, "context": "(3) Liu and Ihler (2014) studied the theoretical properties of the KL-averaging method, and showed that it exactly recovers the global MLE, that is, \u03b8KL = \u03b8\u0302mle, when the distribution family is a full exponential family, and achieves an optimal asymptotic error rate (up to the second order) among all the possible combination methods of {\u03b8\u0302k}. Despite the attractive properties, the exact KL-averaging is not computationally tractable except for very simple models. Liu and Ihler (2014) suggested a naive bootstrap method for approximation: it draws parametric bootstrap sample {x\u0303kj }j=1 from each local model p(x|\u03b8\u0302k), k \u2208 [d] and use it to approximate each integral in (3).", "startOffset": 4, "endOffset": 488}, {"referenceID": 2, "context": "We start with a concrete analysis on the KL-naive estimator \u03b8\u0302KL, which was missing in Liu and Ihler (2014). Assumption 1.", "startOffset": 87, "endOffset": 108}, {"referenceID": 2, "context": "We start with a concrete analysis on the KL-naive estimator \u03b8\u0302KL, which was missing in Liu and Ihler (2014). Assumption 1. 1. log p(x | \u03b8), \u2202 log p(x|\u03b8) \u2202\u03b8 , and \u2202 log p(x|\u03b8) \u2202\u03b8\u2202\u03b8> are continuous for \u2200x \u2208 X and \u2200\u03b8 \u2208 \u0398; 2. \u2202 2 log p(x|\u03b8) \u2202\u03b8\u2202\u03b8> is positive definite and C1 \u2264 \u2016 2 log p(x|\u03b8) \u2202\u03b8\u2202\u03b8> \u2016 \u2264 C2 in a neighbor of \u03b8\u2217 for \u2200x \u2208 X , and C1, C2 are some positive constans. Theorem 2. Under Assumption 1, \u03b8\u0302KL is a consistent estimator of \u03b8KL as n\u2192\u221e, and E(\u03b8\u0302KL \u2212 \u03b8KL) = o( 1 dn ), E\u2016\u03b8\u0302KL \u2212 \u03b8KL\u2016 = O( 1 dn ), where d is the number of machines and n is the bootstrap sample size for each local model p(x | \u03b8\u0302k). The proof is in Appendix A. Because the MSE between the exact KL estimator \u03b8KL and the true parameter \u03b8\u2217 is O(N\u22121) as shown in Liu and Ihler (2014), the MSE between \u03b8\u0302KL and the true", "startOffset": 87, "endOffset": 758}, {"referenceID": 7, "context": "Note that the form of (7) shares some similarity with the one-step estimator in Huang and Huo (2015), but Huang and Huo (2015) focuses on improving the linear averaging estimator, and is different from our setting.", "startOffset": 80, "endOffset": 101}, {"referenceID": 7, "context": "Note that the form of (7) shares some similarity with the one-step estimator in Huang and Huo (2015), but Huang and Huo (2015) focuses on improving the linear averaging estimator, and is different from our setting.", "startOffset": 80, "endOffset": 127}, {"referenceID": 9, "context": "Here the probability ratio acts like a multiplicative control variate (Nelson, 1987), which has the advantage of being positive and applicable to non-identifiable, non-additive parameters.", "startOffset": 70, "endOffset": 84}, {"referenceID": 12, "context": "Although being a very powerful tool, results of this type seem to be not widely known in machine learning, except several applications in semi-supervised learning (Sokolovska et al., 2008; Kawakita and Kanamori, 2013), and off-policy learning (Li et al.", "startOffset": 163, "endOffset": 217}, {"referenceID": 13, "context": "Although being a very powerful tool, results of this type seem to be not widely known in machine learning, except several applications in semi-supervised learning (Sokolovska et al., 2008; Kawakita and Kanamori, 2013), and off-policy learning (Li et al.", "startOffset": 163, "endOffset": 217}, {"referenceID": 14, "context": ", 2008; Kawakita and Kanamori, 2013), and off-policy learning (Li et al., 2015).", "startOffset": 62, "endOffset": 79}, {"referenceID": 10, "context": "(11) This estimator is motivated by Henmi et al. (2007) in which the same idea is applied to reduce the asymptotic variance in importance sampling.", "startOffset": 36, "endOffset": 56}, {"referenceID": 10, "context": "(11) This estimator is motivated by Henmi et al. (2007) in which the same idea is applied to reduce the asymptotic variance in importance sampling. Similar result is also found in Hirano et al. (2003), in which it is shown that a similar weighted estimator with estimated propensity score is more efficient than the estimator using true propensity score in estimating the average treatment effects.", "startOffset": 36, "endOffset": 201}, {"referenceID": 15, "context": "We note that the same KL-averaging problem also appears in the \u201cknowledge distillation\" problem in Bayesian deep neural networks (Korattikara et al., 2015), and it seems that our technique can be applied straightforwardly.", "startOffset": 129, "endOffset": 155}], "year": 2016, "abstractText": "In distributed, or privacy-preserving learning, we are often given a set of probabilistic models estimated from different local repositories, and asked to combine them into a single model that gives efficient statistical estimation. A simple method is to linearly average the parameters of the local models, which, however, tends to be degenerate or not applicable on non-convex models, or models with different parameter dimensions. One more practical strategy is to generate bootstrap samples from the local models, and then learn a joint model based on the combined bootstrap set. Unfortunately, the bootstrap procedure introduces additional noise and can significantly deteriorate the performance. In this work, we propose two variance reduction methods to correct the bootstrap noise, including a weighted M-estimator that is both statistically efficient and practically powerful. Both theoretical and empirical analysis is provided to demonstrate our methods.", "creator": "LaTeX with hyperref package"}}}