{"id": "1607.07906", "review": {"conference": "AAAI", "VERSION": "v1", "DATE_OF_SUBMISSION": "26-Jul-2016", "title": "Approximation and Parameterized Complexity of Minimax Approval Voting", "abstract": "We present three results on the complexity of Minimax Approval Voting. First, we study Minimax Approval Voting parameterized by the Hamming distance $d$ from the solution to the votes. We show Minimax Approval Voting admits no algorithm running in time $\\mathcal{O}^\\star(2^{o(d\\log d)})$, unless the Exponential Time Hypothesis (ETH) fails. Second, we show Minimax Approval Voting calculates the probability of the winner winning a given candidate on the same basis. Third, we show Minimax Approval Voting does not produce the candidate for the last time $d$. Fourth, we show Minimax Approval Voting uses the two-dimensional model for our model. Finally, we test the model with all the permutations of the models with the largest permutations. Finally, we demonstrate the model with all the permutations of the models with the largest permutations. Finally, we test the model with all the permutations of the models with the largest permutations. Finally, we test the model with all the permutations of the models with the largest permutations. Finally, we test the model with all the permutations. Finally, we test the model with all the permutations. Finally, we test the model with all the permutations. Finally, we test the model with all the permutations. Finally, we test the model with all the permutations. Finally, we test the model with all the permutations. Finally, we test the model with all the permutations. Finally, we test the model with all the permutations. Finally, we test the model with all the permutations. Finally, we test the model with all the permutations. Finally, we test the model with all the permutations. Finally, we test the model with all the permutations. Finally, we test the model with all the permutations. Finally, we test the model with all the permutations. Finally, we test the model with all the permutations. Finally, we test the model with all the permutations. Finally, we test the model with all the permutations. Finally, we test the model with all the permutations. Finally, we test the model with all the permutations. Finally, we test the model with all the permutations. Finally, we test the model with all the permutations. Finally, we test the model with all the permutations. Finally, we test the model with all the permutations", "histories": [["v1", "Tue, 26 Jul 2016 22:06:51 GMT  (18kb)", "http://arxiv.org/abs/1607.07906v1", "14 pages, 3 figures, 2 pseudocodes"]], "COMMENTS": "14 pages, 3 figures, 2 pseudocodes", "reviews": [], "SUBJECTS": "cs.DS cs.AI cs.GT cs.MA", "authors": ["marek cygan", "lukasz kowalik", "arkadiusz socala", "krzysztof sornat"], "accepted": true, "id": "1607.07906"}, "pdf": {"name": "1607.07906.pdf", "metadata": {"source": "CRF", "title": "Approximation and Parameterized Complexity of Minimax Approval Voting", "authors": ["Marek Cygan", "Lukasz Kowalik", "Arkadiusz Soca", "Krzysztof Sornat"], "emails": ["arkadiusz.socala}@mimuw.edu.pl."], "sections": [{"heading": null, "text": "ar X\niv :1\n60 7.\n07 90\n6v 1\n[ cs\n.D S]\n2 6\nJu l 2\n01 6\n2d ), which is essentially tight assuming ETH. Finally, we get a new polynomial-\ntime randomized approximation scheme for Minimax Approval Voting, which runs in time nO(1/\u01eb 2 \u00b7log(1/\u01eb)) \u00b7 poly(m), almost matching the running time of the fastest known PTAS for Closest String due to Ma and Sun [SIAM J. Comp. 2009]."}, {"heading": "1 Introduction", "text": "One of the central problems in artificial intelligence and computational social choice is aggregating preferences of individual agents (see the overview of Conitzer [7]). Here we focus on multi-winner choice, where the goal is to select a k-element subset of a set of candidates. Given preferences of the agents, the subset is identified by means of a voting rule. This scenario covers a variety od settings: nations elect members of parliament or societies elect committees [6], web search engines choose pages to display in response to a query [10], airlines select movies available on board [26], companies select a group of products to promote [22], etc.\nIn this work we restrict our attention to the situation where each vote (expression of the preferences of an agent) is a subset of the candidates. Various voting rules are studied. In the simplest one, Approval Voting (AV), occurences of each candidate are counted and k most often chosen candidates are selected. While this rule has many desirable properties in the single winner case [11], in the multi-winner scenario its merits are often considered less clear [16]. Therefore, numerous alternative rules have been proposed (see [15]), including Satifaction Approval Voting (SAV, satifaction of an agent is the fraction of her approved candidates that are elected; the goal is to maximize the total satisfaction), Proportional Approval Voting (PAV: like SAV, but satisfaction of an agent whose j approved candidates are selected is the j-th harmonic number Hj), Reweighted Approval Voting (RAV: a k-round scheme, in each round another candidate is selected). In this paper we study a rule called Minimax Approval Voting\n\u2217University of Warsaw, Warsaw, Poland, {cygan, kowalik, arkadiusz.socala}@mimuw.edu.pl. The work of M. Cygan is a part of the project TOTAL that has received funding from the European Research Council (ERC) under the European Unions Horizon 2020 research and innovation programme (grant agreement No 677651). L. Kowalik and A. Soca la are supported by the National Science Centre of Poland, grant number 2013/09/B/ST6/03136.\n\u2020University of Wroc law, Wroc law, Poland, krzysztof.sornat@cs.uni.wroc.pl. K. Sornat was supported by the National Science Centre, Poland, grant number 2015/17/N/ST6/03684. During the work on these results, Krzysztof Sornat was an intern at Warsaw Center of Mathematics and Computer Science.\n(MAV), introduced by Brams, Kilgour, and Sanver [2]. Here, we see the votes and the choice as 0-1 strings of length m (characteristic vertors of the subsets). The goal is to minimize the maximum Hamming distance to a vote. (Recall that the Hamming distance H(x, y) of two strings x and y of the same length is the number of positions where x and y differ.)\nOur focus is on the computational complexity of computing the choice based on the MAV rule. In the Minimax Approval Voting decision problem, we are given a multiset S = {s1, . . . , sn} of 0-1 strings of length m (also called votes), and two integers k and d. The question is whether there exists a string s \u2208 {0, 1}m with exactly k ones such that for every i = 1, . . . , n we have H(s, si) \u2264 d. In the optimization version of Minimax Approval Voting we minimize d, i.e., given a multiset S and an integer k as before, the goal is to find a string s \u2208 {0, 1}m with exactly k ones which minimizes maxi=1,...,nH(s, si).\nA reader familiar with string problems might recognize that Minimax Approval Voting is tightly connected with the classical NP-complete problem called Closest String, where we are given n strings over an alphabet \u03a3 and the goal is to find a string that minimizes the maximum Hamming distance to the given strings. Indeed, LeGrand [17] showed that Minimax Approval Voting is NP-complete as well by reduction from Closest String with binary alphabet. This motivated the study on Minimax Approval Voting in terms of approximability and fixed-parameter tractability.\nPrevious results on Minimax Approval Voting First approximation result was a simple 3-approximation algorithm due to LeGrand, Markakis and Mehta [18], obtained by choosing an arbitrary vote and taking any k approved candidates from the vote (extending it arbitrarily to k candidates if needed). Next, a 2-approximation was shown by Caragiannis, Kalaitzis and Markakis using an LP-rounding procedure [5]. Finally, recently Byrka and Sornat [4] presented a polynomial time approximation scheme (PTAS), i.e., an algorithm that for any fixed \u01eb > 0 gives a (1+\u01eb)-approximate solution in polynomial time. More precisely, their algorithm runs in time mO(1/\u01eb 4)+nO(1/\u01eb 3) what is polynomial on number of voters n and number of alternatives m. The PTAS uses information extraction techniques from fixed size (O(1/\u01eb)) subsets of voters and random rounding of the optimal solution of a linear program.\nIn the area of fixed parameter tractability (FPT) the goal is to find algorithms with running time of the form f(r)poly(|I|), where |I| is the size of the input istance I, r is a parameter and f is a function, which is typically at least exponential for NP-complete problems. For more about paremeterized algorithms see the textbook of Cygan et al. [8] or the survey of Bredereck et al.[3] (in the context of computational social choice). The study of FPT algorithms for Minimax Approval Voting was initiated by Misra, Nabeel and Singh [24]. They show for example that Minimax Approval Voting parameterized by the number of ones in the solution k (i.e. k is the paramater r) is W [2]-hard, which implies that there is no FPT algorithm, unless there is a highly unexpected collapse in parameterized complexity classes. From a positive perspective, they show that the problem is FPT when parameterized by the maximum allowed distance d. Their algorithm runs in time1 O\u22c6(d2d)2.\nPrevious results on Closest String It is interesting to compare the known results on Minimax Approval Voting with the corresponding ones on the better researched Closest String. The first PTAS for Closest String was given by Li, Ma and Wang [19] with\n1The O\u22c6 notation suppresses factors polynomial in the input size. 2Actually, in the article [24] the authors claim the slightly better running time of O\u22c6(dd). However, it seems there is a flaw in the analysis: it states that the initial solution v is at distance at most d from the solution, while it can be at distance 2d because of what we call here the k-completion operation. This increases the maximum depth of the recursion to d (instead of the claimed d/2).\nrunning time bounded by nO(1/\u01eb 4). This was later improved by Andoni et al. [1] to nO(\nlog 1/\u01eb\n\u01eb2 ),\nand then by Ma and Sun [23] to nO(1/\u01eb 2).\nThe first FPT algorithm for Closest String, running in time O\u22c6(dd) was given by Gramm, Niedermeier, and Rossmanith [12]. This was later improved by Ma and Sun [23], who gave an algorithm with running time O\u22c6(2O(d) \u00b7|\u03a3|d), which is more efficient for constant-size alphabets. No further substantial progress is possible, since Lokshtanov, Marx and Saurabh [21] have shown that Closest String admits no algorithms in time O\u22c6(2o(d log d)) or O\u22c6(2o(d log |\u03a3|)) , unless the Exponential Time Hypothesis (ETH) [13] fails.\nThe discrepancy between the state of the art for Closest String and Minimax Approval Voting raises interesting questions. First, does the additional constraint in Minimax Approval Voting really makes the problem harder and the PTAS has to be significantly slower? Similarly, although in Minimax Approval Voting the alphabet is binary, no O\u22c6(2O(d))-time algorithm is known, in contrary to Closest String. Can we find such an algorithm? The goal of this work is to answer these questions.\nOur results We present three results on the complexity of Minimax Approval Voting. Let us recall that the Exponential Time Hypothesis (ETH) of Impagliazzo et al. [13] states that there exists a constant c > 0, such that there is no algorithm solving 3-SAT in time O\u22c6(2cn). During the recent years, ETH became the central conjecture used for proving tight bounds on the complexity of various problems, see [20] for a survey. We begin from showing that, unless the ETH fails, there is no algorithm for Minimax Approval Voting running in time O\u22c6(2o(d log d)). In other words, the algorithm of Misra et al. [24] is essentially optimal, and indeed, in this sense Minimax Approval Voting is harder than Closest String. Motivated by this, we then show a parameterized approximation scheme, i.e., a randomized Monte-Carlo algorithm which, given an instance (S, k, d) and a number \u01eb > 0, finds a solution at distance at most (1+ \u01eb)d in time O\u22c6((3/\u01eb)2d) or reports that there is no solution at distance at most d. Note that our lower bound implies that, under (randomized version of) ETH, this is essentially optimal, i.e., there is no parameterized approximation scheme running in time O\u22c6(2o(d log(1/\u01eb))). Indeed, if such an algorithm existed, by picking \u01eb = 1/(d + 1) we get an exact algortihm which contradicts our lower bound. Finally, we get a new polynomialtime randomized approximation scheme for Minimax Approval Voting, which runs in time nO(1/\u01eb\n2\u00b7log(1/\u01eb)) \u00b7 poly(m). Thus the running time almost matches the one of the fastest known PTAS for Closest String (up to a log(1/\u01eb) factor in the exponent).\nOrganization of the paper In Section 2 we introduce some notation and we recall standard probabability bounds that are used later in the paper. In Section 3 we present our lower bound for Minimax Approval Voting parameterized by d. Next, in Section 4 we show a parameterized approximation scheme. Finally, in Section 5 we show a new randomized PTAS. The paper concludes with Section 6, where we discuss directions for future work."}, {"heading": "2 Definitions and Preliminaries", "text": "For every integer n we denote [n] = {1, 2, . . . , n}. For a set of words S \u2286 {0, 1}m and a word x \u2208 {0, 1}m we denote H(x, S) = maxs\u2208S H(x, s). For a string s \u2208 {0, 1}\nm, the number of 1\u2019s in s is denoted as n1(s) and it is also called the Hamming weight of s; similarly n0(s) = m\u2212n1(s) denotes the number of zeroes. Moreover, the set of all strings of length m with k ones is denoted by Sk,m, i.e., Sk,m = {s \u2208 {0, 1}\nm : n1(s) = k}. s[j] means j-th letter of a string s. For a subset of positions P \u2286 [m] we define a subsequence s|P by removing letters on positions [m] \\ P from s.\nFor a string s \u2208 {0, 1}m, any string s\u2032 \u2208 Sk,m at distance |n1(s) \u2212 k| from s is called a k-completion of s. Note that it is easy to find such a k-completion s\u2032: when n1(s) \u2265 k we obtain s\u2032 by replacing arbitrary n1(s) \u2212 k ones in s by zeroes; similarly when n1(s) < k we obtain s\u2032 by replacing arbitrary k \u2212 n1(s) zeroes in s by ones.\nWe will use the following standard Chernoff bounds (see e.g.Chapter 4.1 in [25]).\nTheorem 2.1. Let X1,X2, . . . ,Xn be n independent random 0-1 variables such that for every i = 1, . . . , n we have Pr [Xi = 1] = pi, for pi \u2208 [0, 1]. Let X = \u2211n i=1Xi. Then,\n\u2022 for any 0 < \u01eb \u2264 1 we have:\nPr [X > (1 + \u01eb) \u00b7 E [X]] \u2264 exp ( \u221213\u01eb 2 \u00b7 E [X] )\n(1)\nPr [X < (1\u2212 \u01eb) \u00b7 E [X]] \u2264 exp ( \u221212\u01eb 2 \u00b7 E [X] )\n(2)\n\u2022 for any 1 < \u01eb we have:\nPr [X > (1 + \u01eb) \u00b7 E [X]] \u2264 exp ( \u221213\u01eb \u00b7 E [X] ) (3) Pr [X < (1\u2212 \u01eb) \u00b7 E [X]] = 0 (4)"}, {"heading": "3 A lower bound", "text": "In this section we show a lower bound for Minimax Approval Voting parameterized by d. To this end, we use a reduction from a problem called k \u00d7 k-Clique. In k \u00d7 k-Clique we are given a graph G over the vertex set V = [k] \u00d7 [k], i.e., V forms a grid with k rows and k columns, and the question is whether in G there is a clique containing exactly one vertex in each row.\nLemma 3.1. Given an instance I = (G, k) of k \u00d7 k-Clique with k \u2265 2, one can construct an instance I \u2032 = (S, k, d) of Minimax Approval Voting, such that I \u2032 is a yes-instance iff I is a yes-instance, d = 3k \u2212 3 and the set S contains O(k2\n( 2k\u22122 k\u22122 ) ) strings of length k2 + 2k \u2212 2\neach. The construction takes time polynomial in the size of the output.\nProof. Each string in the set S will be of size m = k2+2k\u22122. Let us split the set of positions [m] into k + 1 blocks, where the first k blocks contain exactly k positions each, and the last (k + 1)-th block contains the remaining 2k \u2212 2 positions. Our construction will enforce that if a solution exists, it will have the following structure: there will be a single 1 in each of the first k blocks and put all zeros in the last block. Intuitively the position of the 1 in the first block encodes the clique vertex of the first row of G, the position of the 1 in the second block encodes the clique vertex of the second row of, etc.\nWe construct the set S as follows.\n\u2022 (nonedge strings) For each pair of nonadjacent vertices v, v\u2032 \u2208 V (G) of G belonging to different rows, i.e., v = (a, b), v\u2032 = (a\u2032, b\u2032), a 6= a\u2032, we add to S a string svv\u2032 , where all the blocks except a-th and a\u2032-th are filled with zeros, while the blocks a, a\u2032 are filled with ones, except the b-th position in block a and the b\u2032-th position in block a\u2032 which are zeros (see Fig. 1). Formally, svv\u2032 contains ones at positions {(a \u2212 1)k + j : j \u2208 [k], j 6= b} \u222a {(a\u2032 \u2212 1)k+ j : j \u2208 [k], j 6= b\u2032}. Note that the Hamming weight of svv\u2032 equals 2k\u2212 2. \u2022 (row strings) For each row i \u2208 [k] we create exactly (2k\u22122 k\u22122 ) strings, i.e., for i \u2208 [k] and\nfor each set X of exactly k\u2212 2 positions in the (k+1)-th block we add to S a string si,X having ones at all positions of the i-th block and at X, all the remaining positions are filled with zeros (see Fig. 2). Note that similarly as for the nonedge strings the Hamming weight of each row string equals 2k\u22122, and to achieve this property we use the (k+1)-th block.\nTo finish the description of the created instance I \u2032 = (S, k, d) we need to define the target distance d, which we set d = 3k \u2212 3. Observe that as the Hamming weight of each string s\u2032 \u2208 S equals 2k \u2212 2, for s \u2208 {0, 1}m with exactly k ones we have H(s, s\u2032) \u2264 d if and only if the positions of ones in s and s\u2032 have a non-empty intersection.\nLet us assume that there is a clique K in G of size k containing exactly one vertex from each row. For i \u2208 [k] let ji \u2208 [k] be the column number of the vertex of K from row i. Define s as a string containing ones exactly at positions {(i\u22121)k+ ji : i \u2208 [k]}, i.e., the (k+1)-th block contains only zeros and for i \u2208 [k] the i-th block contains a single 1 at position ji. Obviously s contains exactly k ones, hence it suffices to show that s has at least one common one with each of the strings in S. This is clear for the row strings, as each row string contains a block full of ones. For a nonedge string svv\u2032 , where v = (a, b) and v\n\u2032 = (a\u2032, b\u2032) note that K does not contain v and v\u2032 at the same time. Consequently s has a common one with svv\u2032 in at least one of the blocks a, a\u2032.\nIn the other direction, assume that s is a string of lengthm with exactly k ones such that the Hamming distance between s and each of the strings in S is at most d, which by construction implies that s as a common one with each of the strings in S. First, we are going to prove that s contains a 1 in each of the first k blocks (and consequently has only zeros in block k+1). For the sake of contradiction assume that this is not the case. Consider a block i \u2208 [k] containing only zeros. Let X be any set of k \u2212 2 positions in block k + 1 containing zeros from s (such a set exists as block k + 1 has 2k \u2212 2 positions). But the row string si,X has 2k \u2212 2 ones at positions where s has zeros, and consequently H(s, si,X) = k+(2k\u2212 2) = 3k\u2212 2 > d = 3k\u2212 3, a contradiction.\nAs we know that s contains exactly one one in each of the first k blocks let ji \u2208 [k] be such a position of block i \u2208 [k]. Create X \u2286 V (G) by taking the vertex from column ji for each row i \u2208 [k]. Clearly X is of size k and it contains exactly one vertex from each row, hence it remains to prove that X is a clique in G. Assume the contrary and let v, v\u2032 \u2208 X be two distinct nonadjacent vertices of X, where v = (i, ji) and v\n\u2032 = (i\u2032, ji\u2032). Observe that the nonedge string svv\u2032 contains zeros at the ji-th position of the i-th block and at the ji\u2032-th position of the i\n\u2032-th block. Since for i\u2032\u2032 \u2208 [k], i\u2032\u2032 6= i, i\u2032\u2032 6= i block i\u2032\u2032 of svv\u2032 contains only zeros, we infer that the sets of positions of ones of s and svv\u2032 are disjoint leading to H(s, svv\u2032) = k+ (2k\u2212 2) = 3k\u2212 2 > d, a contradiction.\nAs we have proved that I is a yes-instance of k \u00d7 k-Clique iff I \u2032 is a yes-instance of Minimax Approval Voting, the lemma follows.\nIn order to derive an ETH-based lower bound we need the following theorem of Lokshtanov, Marx and Saurabh [21].\nTheorem 3.2. Assuming ETH, there is no 2o(k log k)-time algorithm for k \u00d7 k-Clique.\nWe are ready to prove the main result of this section.\nTheorem 3.3. Assuming ETH, there is no 2o(d log d)poly(n,m)-time algorithm for Minimax Approval Voting.\nProof. Using Lemma 3.1, the input instance G of k \u00d7 k-Clique is transformed into an equivalent instance I \u2032 = (S, k, d) of Minimax Approval Voting, where n = |S| = O(k2\n(2k\u22122 k\u22122 ) ) =\n2O(k), each string of S has lengthm = O(k2) and d = \u0398(k). It follows that a 2o(d log d)poly(n,m)time algorithm for Minimax Approval Voting solves k\u00d7k-Clique in time 2o(k log k)2O(k) = 2o(k log k), which contradicts ETH by Theorem 3.2."}, {"heading": "4 Parameterized approximation scheme", "text": "In this section we show the following theorem.\nTheorem 4.1. There exists a randomized algorithm which, given an instance ({si}i=1,...,n, k, d) of Minimax Approval Voting and any \u01eb \u2208 (0, 3), runs in time O ((\n3 \u01eb\n)2d mn\n)\nand either\n(i) reports a solution at distance at most (1 + \u01eb)d from S, or\n(ii) reports that there is no solution at distance at most d from S."}, {"heading": "In the latter case, the answer is correct with probabability at least 1 \u2212 p, for arbitrarily small", "text": "fixed p > 0.\nLet us proceed with the proof. In what follows we assume p = 1/2, since then we can get the claim even if p < 1/2 by repeating the whole algorithm \u2308log2(1/p)\u2309 times. Indeed, then the algorithm returns incorrect answer only if each of the \u2308log2(1/p)\u2309 repetitions returned incorrect answer, which happens with probabability at most (1/2)log2(1/p) = p.\nAssume we are given a yes-instance and let us fix a solution s\u2217 \u2208 Sk,m, i.e., a string at distance at most d from all the input strings. Our approch is to begin with a string x0 \u2208 Sk,m not very far from s\u2217, and next perform a number of steps. In j-th step we either conclude that xj\u22121 is already a (1 + \u01eb)-approximate solution, or with some probability we find another string xj which is closer to s\n\u2217. First observe that if |n1(s1) \u2212 k| > d, then clearly there is no solution and our algorithm\nreports NO. Hence in what follows we assume\n|n1(s1)\u2212 k| \u2264 d. (5)\nWe set x0 to be any k-completion of s1. By (5) we get H(x0, s1) \u2264 d. Since H(s1, s \u2217) \u2264 d, by the triangle inequality we get the following bound.\nH(x0, s \u2217) \u2264 H(x0, s1) +H(s1, s \u2217) \u2264 2d. (6)\nNow we are ready to describe our algorithm precisely (see also Pseudocode 1). We begin with x0 defined as above. Next for j = 1, . . . , d we do the following. If for every i = 1, . . . , n we have H(xj\u22121, si) \u2264 (1 + \u01eb)d the algorithm terminates and returns xj\u22121. Otherwise, fix any i = 1, . . . , n such that H(xj\u22121, si) > (1 + \u01eb)d. Let Pj,0 = {a \u2208 [m] : 0 = xj\u22121[a] 6= si[a] = 1} and Pj,1 = {a \u2208 [m] : 1 = xj\u22121[a] 6= si[a] = 0}. The algorithm samples a position a0 \u2208 Pj,0 and a position a1 \u2208 Pj,1. Then, xj is obtained from xj\u22121 by swapping the 0 at position a0 with the 1 at position a1. If the algorithm finishes without finding a solution, it reports NO.\nThe following lemma is the key to get a lower bound on the probablity that the xj \u2019s get close to s\u2217.\nLemma 4.2. Let x be a string in Sk,m such that H(x, si) \u2265 (1 + \u01eb)d for some i = 1, . . . , n. Let s\u2217 \u2208 Sk,m be any solution, i.e., a string at distance at most d from all the strings si, i = 1, . . . , n. Denote\nP \u22170 = {a \u2208 [m] : 0 = x[a] 6= si[a] = s \u2217[a] = 1} ,\nP \u22171 = {a \u2208 [m] : 1 = x[a] 6= si[a] = s \u2217[a] = 0} .\nThen,\nmin (|P \u22170 | , |P \u2217 1 |) \u2265\n\u01ebd\n2 .\nProof. Let P be the set of positions on which x and si differ, i.e., P = {a \u2208 [m] : x[a] 6= si[a]}. (See Fig. 3.) Note that P \u22170 \u222a P \u2217 1 \u2286 P . Let Q = [m] \\ P .\nThe intuition behind the proof is that if min(|P \u22170 |, |P \u2217 1 |) is small, then s \u2217 differs too much from si, either because s \u2217|P is similar to x|P (when |P \u2217 0 | \u2248 |P \u2217 1 |) or because s\n\u2217|Q has much more 1\u2019s than si|Q (when |P \u2217 0 | differs much from |P \u2217 1 |).\nWe begin with a couple of useful observations on the number of ones in different parts of x, si and s \u2217. Since x and si are the same on Q, we get\nn1(x|Q) = n1(si|Q). (7)\nSince n1(x) = n1(s \u2217), we get n1(x|P ) + n1(x|Q) = n1(s \u2217|P ) + n1(s \u2217|Q), and further\nn1(s \u2217|Q)\u2212 n1(x|Q) = n1(x|P )\u2212 n1(s \u2217|P ). (8)\nFinally note that n1(s \u2217|P ) = |P \u2217 0 |+ n1(x|P )\u2212 |P \u2217 1 |. (9)\nWe are going to derive a lower bound on H(si, s \u2217). First,\nH(si|P , s \u2217|P ) = |P | \u2212 (|P \u2217 0 |+ |P \u2217 1 |) = H(x, si)\u2212 (|P \u2217 0 |+ |P \u2217 1 |) \u2265 (1 + \u01eb)d\u2212 (|P \u2217 0 |+ |P \u2217 1 |).\nOn the other hand,\nH(si|Q, s \u2217|Q) \u2265 |n1(s \u2217|Q)\u2212 n1(si|Q)| =\n(7) = |n1(s \u2217|Q)\u2212 n1(x|Q) =\n(8) = |n1(x|P )\u2212 n1(s \u2217|P )| =\n(9) = ||P \u22171 | \u2212 |P \u2217 0 || .\nIt follows that\nd \u2265 H(si, s \u2217) = H(si|P , s \u2217|P ) +H(si|Q, s \u2217|Q) \u2265 (1 + \u01eb)d\u2212 (|P \u2217 0 |+ |P \u2217 1 |) + ||P \u2217 1 | \u2212 |P \u2217 0 ||\n= (1 + \u01eb)d\u2212 2min(|P \u22170 |, |P \u2217 1 |).\nHence, min(|P \u22170 |, |P \u2217 1 |) \u2265 \u01ebd 2 as required.\nCorollary 4.3. Assume that there is a solution s\u2217 \u2208 Sk,m and that the algorithm created a string xj, for some j = 0, . . . , d. Then,\nPr[H(xj , s \u2217) \u2264 2d\u2212 2j] \u2265\n( \u01eb\n3\n)2j .\nProof. We use induction on j. For j = 0 the claim follows from (6). Consider j > 0. By the induction hypothesis,\nPr[H(xj\u22121, s \u2217) \u2264 2d\u2212 2j + 2] \u2265\n( \u01eb\n3\n)2j\u22122 . (10)\nAssume that H(xj\u22121, s \u2217) \u2264 2d\u2212 2j + 2. Since xj was created, H(xj\u22121, si) > (1 + \u01eb)d for some i = 1, . . . , n. Since H(s\u2217, si) \u2264 d, by the triangle inequality we get the following.\n|Pj\u22121,0|+ |Pj\u22121,1| = H(xj\u22121, si) \u2264 H(xj\u22121, s \u2217) +H(s\u2217, si) \u2264 3d\u2212 2j + 2 \u2264 3d. (11)\nThen, by Lemma 4.2\nPr[H(xj , s \u2217) \u2264 2d\u22122j | H(xj\u22121, s \u2217) \u2264 2d\u22122j+2] \u2265 |P \u22170 | \u00b7 |P \u2217 1 |\n|Pj\u22121,0| \u00b7 |Pj\u22121,1| \u2265\n( \u01ebd 2 )2 ( 3d 2 )2 = ( \u01eb 3 )2 . (12)\nThe claim follows by combining (10) and (12).\nIn order to increase the success probability, we repeat the algorithm until a solution is found or the number of repetitions is at least (3/\u01eb)2d. By Corollary 4.3 the probablity that there is a solution but it was not found is bounded by\n(\n1\u2212 ( \u01eb\n3\n)2d )(3/\u01eb)2d\n=\n(\n1\u2212 1\n(3/\u01eb)2d\n)(3/\u01eb)2d\n\u2264 e\u22121 < 1/2.\nThis finishes the proof of Theorem 4.1.\nPseudocode 2: Parameterized approximation scheme for Minimax Approval Voting\n1 Solve the LP (13\u201316) obtaining an optimal solution (x\u22171, . . . , x \u2217 m, d \u2217); 2 for j \u2208 {1, 2, . . . ,m} do 3 Set x[j] \u2190 1 with probability x\u2217j and x[j] \u2190 0 with probability 1\u2212 x \u2217 j\n4 y \u2190 any k-completion of x; 5 return y"}, {"heading": "5 A fast polynomial time approximation scheme", "text": "The goal of this section is to present a PTAS for Minimax Approval Voting running in time nO(1/\u01eb\n2\u00b7log(1/\u01eb)) \u00b7 poly(m). It is achieved by combining the parameterized approximation scheme from Theorem 4.1 with the following result, which might be of independent interest. Throughout this section OPT denotes the value of the optimum solution s for the given instance ({si}i=1,...,n, k) of Minimax Approval Voting, i.e., OPT = maxi=1,...,nH(s, si),\nTheorem 5.1. There exists a randomized polynomial time algorithm which, for arbitrarily small fixed p > 0, given an instance ({si}i=1,...,n, k) of Minimax Approval Voting and any \u01eb > 0 such that OPT \u2265 122 lnn\n\u01eb2 , reports a solution, which with probabability at least 1\u2212 p is at\ndistance at most (1 + \u01eb) \u00b7OPT from S.\nIn what follows, we prove Theorem 5.1. As in the proof of Theorem 4.1 we assume w.l.o.g. p = 1/2. Note that we can assume \u01eb < 1, for otherwise it suffices to use the 2-approximation of Caragiannis et al. [5]. We also assume n \u2265 3, for otherwise it is a straightforward exercise to find an optimal solution in linear time. Let us define a linear program (13\u201316):\nminimize d (13) m\u2211\nj=1\nxj = k (14)\n\u2211\nj=1,...,m si[j]=1\n(1\u2212 xj) + \u2211\nj=1,...,m si[j]=0\nxj \u2264 d \u2200i \u2208 {1, . . . , n} (15)\nxj \u2208 [0, 1] \u2200j \u2208 {1, . . . ,m} (16)\nThe linear program (13\u201316) is a relaxation of the natural integer program for Minimax Approval Voting, obtained by replacing (16) by the discrete constraint xj \u2208 {0, 1}. Indeed, observe that xj corresponds to the j-th letter of the solution x = x1 \u00b7 \u00b7 \u00b7 xm, (14) states that n1(x) = k, and (15) states that H(x, S) \u2264 d.\nOur algorithm is as follows (see Pseudocode 2). First we solve the linear program in time poly(n,m) using the interior point method [14]. Let (x\u22171, . . . , x \u2217 m, d\n\u2217) be the obtained optimal solution. Clearly, d\u2217 \u2264 OPT. We randomly construct a string x \u2208 {0, 1}m, guided by the values x\u2217j . More precisely, for every j = 1, . . . ,m independently, we set x[j] = 1 with probabability x\u2217j . Note that x needs not contain k ones. Let y by any k-completion of x. The algorithm returns y.\nClearly, the above algorithm runs in polynomial time. In what follows we bound the probability of error. To this end we prove upper bounds on the probabability that x is far from S and the probabability that the number of ones in x is far from k. This is done in Lemmas 5.2 and 5.3.\nLemma 5.2. Pr\n[ H(x, S) > (1 + \u01eb2) \u00b7OPT ] \u2264 14 .\nProof. For every i = 1, . . . , n we define a random variable Di that measures the distance between x\u2217 and si\nDi = \u2211\nj\u2208[m] si[j]=1\n(1\u2212 x[j]) + \u2211\nj\u2208[m] si[j]=0\nx[j].\nNote that x[i] are independent 0-1 random variables. Using linearity of the expectation we obtain\nE[Di] = E\n  \u2211\nj\u2208[m],si[j]=1\n(1\u2212 x[j]) + \u2211\nj\u2208[m],si[j]=0\nx[j]\n\n =\n= \u2211\nj\u2208[m],si[j]=1\n(1\u2212 E[x[j]]) + \u2211\nj\u2208[m],si[j]=0\nE[x[j]] =\n= \u2211\nj\u2208[m],si[j]=1\n(1\u2212 x\u2217j ) + \u2211\nj\u2208[m],si[j]=0\nx\u2217j \u2264\n\u2264 d\u2217 \u2264 OPT. (17)\nNote that Di is a sum of m independent 0-1 random variables Xj = 1 \u2212 x[j] when si[j] = 1 and Xj = x[j] otherwise. Denote \u03b4 = \u01eb \u00b7\nOPT 2E[Di] . We apply Chernoff bounds. For \u03b4 < 1 we have\nPr[Di > ( 1 + \u01eb2 ) \u00b7OPT]\n(17)\n\u2264 Pr [ Di > E[Di] + \u01eb 2 \u00b7OPT ] = Pr [Di > (1 + \u03b4) \u00b7 E[Di]]\n(1) \u2264\n\u2264 exp\n(\n\u2212 1\n3\n(\n\u01eb \u00b7 OPT\n2E[Di]\n)2\nE[Di]\n) (17)\n\u2264 exp\n(\n\u2212 \u01eb2 \u00b7OPT\n12\n)\n.\nIn case \u03b4 \u2265 1 we proceed analogously, using the Chernoff bound (3)\nPr[Di > ( 1 + \u01eb2 ) \u00b7OPT]\n(3) \u2264 exp\n(\n\u2212 \u01eb \u00b7OPT\n6\n) 1>\u01eb \u2264 exp ( \u2212 \u01eb2 \u00b7OPT\n12\n)\n.\nNow we use the union bound to get the claim.\nPr [ H(x, S) \u2264 (1 + \u01eb2) \u00b7OPT ] = Pr [ \u2203i \u2208 [n] Di > ( 1 + \u01eb2 ) \u00b7OPT ] \u2264\n\u2264 n \u00b7 exp\n(\n\u2212 \u01eb2 \u00b7OPT\n12\n)\n\u2264\n\u2264 n \u00b7 exp\n(\n\u2212 122 lnn OPT \u00b7OPT\n12\n)\n<\n< n\u22129 n\u22653 < 1\n4 . (18)\nLemma 5.3.\nPr [ |n1(x)\u2212 k| > \u01eb 2 \u00b7OPT ] < 1\n4 .\nProof. First we note that\nE[n1(x)] = E [ \u2211\nj\u2208[m]\nx[j] ] = \u2211\nj\u2208[m]\nE[x[j]] = \u2211\nj\u2208[m]\nx\u2217j (14) = k. (19)\nPick an i = 1, . . . , n. Define the random variables\nEi = \u2211\nj\u2208[m],si[j]=1\n(1\u2212 x[j]), Fi = \u2211\nj\u2208[m],si[j]=0\nx[j].\nLet Di = Ei + Fi, as in the proof of Lemma 5.2. By (17) we have\nE[Ei] \u2264 E[Ei] + E[Fi] = E[Di] \u2264 OPT (20)\nand analogously E[Fi] \u2264 OPT. (21)\nBoth Ei and Fi are sums of independent 0-1 random variables and we apply Chernoff bounds as follows. When 14\u01eb \u00b7 OPT E[Ei] \u2264 1 then using (1) and (2) we obtain\nPr [\u2223 \u2223 \u2223Ei \u2212 E[Ei] \u2223 \u2223 \u2223 > 1\n4 \u01eb \u00b7OPT\n] (1),(2)\n\u2264\n\u2264 exp\n(\n\u2212 1 3 \u00b7 1 16 \u01eb2 \u00b7\n(OPT)2\nE2 [Ei] \u00b7 E[Ei]\n)\n+ exp\n(\n\u2212 1 2 \u00b7 1 16 \u01eb2 \u00b7\n(OPT)2\nE2 [Ei] \u00b7 E[Ei]\n) 20 \u2264\n\u2264 2 \u00b7 exp\n(\n\u2212 1\n48 \u01eb2 \u00b7OPT\n)\n,\notherwise ( 1 4\u01eb \u00b7 OPT E[Ei] > 1 ) , using (3) and (4), we have\nPr [\u2223 \u2223 \u2223Ei \u2212 E[Ei] \u2223 \u2223 \u2223 > 1\n4 \u01eb \u00b7OPT\n] (3),(4)\n\u2264\n\u2264 exp\n(\n\u2212 1 3 \u00b7 1 4 \u01eb \u00b7 OPT E[Ei] \u00b7 E[Ei]\n)\n+ 0 \u2264\n\u2264 exp\n(\n\u2212 1\n12 \u01eb \u00b7OPT\n) 1>\u01eb \u2264 2 \u00b7 exp ( \u2212 1\n48 \u01eb2 \u00b7OPT\n)\n.\nTo sum up, in both cases we have shown that\nPr [\u2223 \u2223 \u2223Ei \u2212 E[Ei] \u2223 \u2223 \u2223 > 1\n4 \u01eb \u00b7OPT\n]\n\u2264 2 \u00b7 exp\n(\n\u2212 1\n48 \u01eb2 \u00b7OPT\n)\n. (22)\nSimilarly we show\nPr [\u2223 \u2223 \u2223Fi \u2212 E[Fi] \u2223 \u2223 \u2223 > 1\n4 \u01eb \u00b7OPT\n]\n\u2264 2 \u00b7 exp\n(\n\u2212 1\n48 \u01eb2 \u00b7OPT\n)\n. (23)\nWe see that\nn1(x) = \u2211\nj\u2208[m]\nx[j] = n1(si)\u2212 \u2211\nj\u2208[m],si[j]=1\n(1\u2212 x[j]) + \u2211\nj\u2208[m],si[j]=0\nx[j] = n1(si)\u2212 Ei + Fi (24)\nand hence E[n1(x)] = n1(si)\u2212 E[Ei] + E[Fi]. (25)\nAdditionally we will use\n\u2200x, y \u2208 R |x\u2212 y| > a =\u21d2 |x| > a/2 \u2228 |y| > a/2. (26)\nNow we can write\nPr [\u2223 \u2223 \u2223n1(x)\u2212 k \u2223 \u2223 \u2223 > 12\u01eb \u00b7OPT ] (19) = Pr [\u2223 \u2223 \u2223n1(x)\u2212 E[n1(x)] \u2223 \u2223 \u2223 > 12\u01eb \u00b7OPT ] (24),(25) =\n= Pr [\u2223 \u2223 \u2223n1(si)\u2212 Ei + Fi \u2212 n1(si) + E[Ei]\u2212 E[Fi] \u2223 \u2223 \u2223 > 12\u01eb \u00b7OPT ] (26) \u2264 \u2264 Pr [\u2223 \u2223 \u2223Ei \u2212 E[Ei] \u2223 \u2223 \u2223 > 14\u01eb \u00b7OPT \u2228 \u2223 \u2223 \u2223Fi \u2212 E[Fi] \u2223 \u2223 \u2223 > 14\u01eb \u00b7OPT ] \u2264 \u2264 Pr [\u2223 \u2223 \u2223Ei \u2212 E[Ei] \u2223 \u2223 \u2223 > 14\u01eb \u00b7OPT ] + Pr [\u2223 \u2223 \u2223Fi \u2212 E[Fi] \u2223 \u2223 \u2223 > 14\u01eb \u00b7OPT ] (22),(23) \u2264\n\u2264 4 \u00b7 exp ( \u2212 148\u01eb 2 \u00b7OPT ) assum. \u2264 4 \u00b7 exp ( \u221212248 lnn ) n\u22653 < 14 .\nNow we can finish the proof of Theorem 5.1. By Lemmas 5.2 and 5.3 with probabability at least 1/2 both H(x, S) \u2264 (1+ 12\u01eb) \u00b7OPT and H(y, x) = |n1(x)\u2212 k| \u2264 1 2\u01eb \u00b7OPT. By triangle inequality this implies that H(y, S) \u2264 (1 + \u01eb) \u00b7OPT, with probability at least 1/2 as required. We conclude the section by combining Theorems 4.1 and 5.1 to get a fast PTAS.\nTheorem 5.4. For each \u01eb > 0 we can find (1 + \u01eb)-approximation solution for the Minimax Approval Voting problem in time n O ( log 1/\u01eb \u01eb2 )\n\u00b7 poly(m) with probability at least 1 \u2212 r, for any fixed r > 0.\nProof. First we run algorithm from Theorem 4.1 for d = \u2308122 lnn \u01eb2\n\u2309 and p = r/2. If it reports a solution, for every d\u2032 \u2264 d we apply Theorem 4.1 with p = r/2 and we return the best solution. If OPT \u2265 d, even the initial solution is at distance at most (1 + \u01eb)d \u2264 (1 + \u01eb)OPT from S. Otherwise, at some point d\u2032 = OPT and we get (1 + \u01eb)-approximation with probability at least 1\u2212 r/2 > 1\u2212 r.\nIn the case when the initial run of the algorithm from Theorem 4.1 reports NO, we just apply the algorithm from Theorem 5.1, again with p = r/2. With probability at least 1\u2212r/2 the answer NO of the algorithm from Theorem 4.1 is correct. Conditioned on that, we know that OPT > d \u2265 122 lnn\n\u01eb2 and then the algorithm from Theorem 5.1 returns a (1 + \u01eb)-approximation\nwith probability at least 1 \u2212 r/2. Thus, the answer is correct with probabability at least (1\u2212 r/2)2 > 1\u2212 r.\nThe total running time can be bounded as follows.\nO\u2217\n(( 3\n\u01eb\n) 244 lnn \u01eb2\n)\n\u2286 O\u2217 ( n O ( ln 1/\u01eb \u01eb2 )) \u2286 n O ( log 1/\u01eb \u01eb2 ) \u00b7 poly(m)."}, {"heading": "6 Further research", "text": "We conclude the paper with some questions related to this work that are left unanswered. Our PTAS for Minimax Approval Voting is randomized, and it seems there is no direct way of derandomizing it. It might be interesting to find an equally fast deterministic PTAS. The second question is whether there are even faster PTASes for Closest String or Minimax Approval Voting. Recently, Cygan, Lokshtanov, Pilipczuk, Pilipczuk and Saurabh [9] showed that under ETH, there is no PTAS in time f(\u01eb) \u00b7 no(1/\u01eb) for Closest String. This extends to the same lower bound for Minimax Approval Voting, since we can try all values k = 0, 1, . . . ,m. It is a challenging open problem to close the gap in the running time of PTAS either for Closest String or for Minimax Approval Voting."}], "references": [{"title": "On the Optimality of the Dimensionality Reduction Method", "author": ["Alexandr Andoni", "Piotr Indyk", "Mihai Patrascu"], "venue": "In 47th Annual IEEE Symposium on Foundations of Computer Science,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2006}, {"title": "A Minimax Procedure for Electing Committees", "author": ["Steven J. Brams", "D. Marc Kilgour", "M. Remzi Sanver"], "venue": "Public Choice,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2007}, {"title": "Parameterized Algorithmics for Computational Social Choice: Nine Research Challenges", "author": ["Robert Bredereck", "Jiehua Chen", "Piotr Faliszewski", "Jiong Guo", "Rolf Niedermeier", "Gerhard J. Woeginger"], "venue": "Tsinghua Science and Technology,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2014}, {"title": "Sornat. PTAS for Minimax Approval Voting", "author": ["Jaros law Byrka", "Krzysztof"], "venue": "In Proceedings of 10th International Conference Web and Internet Economics,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2014}, {"title": "Approximation Algorithms and Mechanism Design for Minimax Approval Voting", "author": ["Ioannis Caragiannis", "Dimitris Kalaitzis", "Evangelos Markakis"], "venue": "In Proceedings of the Twenty-Fourth AAAI Conference on Artificial Intelligence,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2010}, {"title": "Representative Deliberations and Representative Decisions: Proportional Representation and the Borda Rule", "author": ["John R. Chamberlin", "Paul N. Courant"], "venue": "American Political Science Review, 77:718\u2013733,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 1983}, {"title": "Making Decisions Based on the Preferences of Multiple Agents", "author": ["Vincent Conitzer"], "venue": "Commun. ACM,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2010}, {"title": "Lower Bounds for Approximation Schemes for Closest String", "author": ["Marek Cygan", "Daniel Lokshtanov", "Marcin Pilipczuk", "Michal Pilipczuk", "Saket Saurabh"], "venue": "In 15th Scandinavian Symposium and Workshops on Algorithm Theory, SWAT 2016,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2016}, {"title": "Rank aggregation methods for the Web", "author": ["Cynthia Dwork", "Ravi Kumar", "Moni Naor", "D. Sivakumar"], "venue": "In Proceedings of the Tenth International World Wide Web Conference,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2001}, {"title": "Axioms for Approval Voting", "author": ["Peter C. Fishburn"], "venue": "Direct Proof. Journal of Economic Theory,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 1978}, {"title": "Fixed-Parameter Algorithms for Closest String and Related Problems", "author": ["Jens Gramm", "Rolf Niedermeier", "Peter Rossmanith"], "venue": null, "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2003}, {"title": "On the Complexity of k-SAT", "author": ["Russell Impagliazzo", "Ramamohan Paturi"], "venue": "J. Comput. Syst. Sci.,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2001}, {"title": "A New Polynomial-time Algorithm for", "author": ["Narendra Karmarkar"], "venue": "Linear Programming. Combinatorica,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 1984}, {"title": "Approval Balloting for Multi-winner Elections", "author": ["D. Marc Kilgour"], "venue": "Handbook on Approval Voting,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2010}, {"title": "Sanver. Handbook on Approval Voting. Studies in Choice and Welfare", "author": ["M.R.J.F. Laslier"], "venue": null, "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2010}, {"title": "Analysis of the Minimax Procedure", "author": ["Rob LeGrand"], "venue": "Technical Report WUCSE-2004- 67,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2004}, {"title": "Some Results on Approximating the Minimax Solution in Approval Voting", "author": ["Rob LeGrand", "Evangelos Markakis", "Aranyak Mehta"], "venue": "In 6th International Joint Conference on Autonomous Agents and Multiagent Systems,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2007}, {"title": "On the Closest String and Substring Problems", "author": ["Ming Li", "Bin Ma", "Lusheng Wang"], "venue": "Journal of the ACM,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2002}, {"title": "Lower Bounds Based on the Exponential Time Hypothesis", "author": ["Daniel Lokshtanov", "D\u00e1niel Marx", "Saket Saurabh"], "venue": "Bulletin of the EATCS,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2011}, {"title": "Slightly Superexponential Parameterized Problems", "author": ["Daniel Lokshtanov", "D\u00e1niel Marx", "Saket Saurabh"], "venue": "In Proceedings of the Twenty-Second Annual ACM-SIAM Symposium on Discrete Algorithms,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2011}, {"title": "Budgeted Social Choice: From Consensus to Personalized Decision Making", "author": ["Tyler Lu", "Craig Boutilier"], "venue": "In Proceedings of the 22nd International Joint Conference on Artificial Intelligence,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2011}, {"title": "More Efficient Algorithms for Closest String and Substring Problems", "author": ["Bin Ma", "Xiaoming Sun"], "venue": "SIAM Journal of Computing,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2009}, {"title": "On the Parameterized Complexity of Minimax Approval Voting", "author": ["Neeldhara Misra", "Arshed Nabeel", "Harman Singh"], "venue": "In Proceedings of the 2015 International Conference on Autonomous Agents and Multiagent Systems,", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2015}, {"title": "Randomized Algorithms", "author": ["Rajeev Motwani", "Prabhakar Raghavan"], "venue": null, "citeRegEx": "25", "shortCiteRegEx": "25", "year": 1995}, {"title": "Finding a Collective Set of Items: From Proportional Multirepresentation to Group Recommendation", "author": ["Piotr Krzysztof Skowron", "Piotr Faliszewski", "J\u00e9r\u00f4me Lang"], "venue": "In Proceedings of the Twenty-Ninth AAAI Conference on Artificial Intelligence,", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2015}], "referenceMentions": [{"referenceID": 6, "context": "One of the central problems in artificial intelligence and computational social choice is aggregating preferences of individual agents (see the overview of Conitzer [7]).", "startOffset": 165, "endOffset": 168}, {"referenceID": 5, "context": "This scenario covers a variety od settings: nations elect members of parliament or societies elect committees [6], web search engines choose pages to display in response to a query [10], airlines select movies available on board [26], companies select a group of products to promote [22], etc.", "startOffset": 110, "endOffset": 113}, {"referenceID": 8, "context": "This scenario covers a variety od settings: nations elect members of parliament or societies elect committees [6], web search engines choose pages to display in response to a query [10], airlines select movies available on board [26], companies select a group of products to promote [22], etc.", "startOffset": 181, "endOffset": 185}, {"referenceID": 24, "context": "This scenario covers a variety od settings: nations elect members of parliament or societies elect committees [6], web search engines choose pages to display in response to a query [10], airlines select movies available on board [26], companies select a group of products to promote [22], etc.", "startOffset": 229, "endOffset": 233}, {"referenceID": 20, "context": "This scenario covers a variety od settings: nations elect members of parliament or societies elect committees [6], web search engines choose pages to display in response to a query [10], airlines select movies available on board [26], companies select a group of products to promote [22], etc.", "startOffset": 283, "endOffset": 287}, {"referenceID": 9, "context": "While this rule has many desirable properties in the single winner case [11], in the multi-winner scenario its merits are often considered less clear [16].", "startOffset": 72, "endOffset": 76}, {"referenceID": 14, "context": "While this rule has many desirable properties in the single winner case [11], in the multi-winner scenario its merits are often considered less clear [16].", "startOffset": 150, "endOffset": 154}, {"referenceID": 13, "context": "Therefore, numerous alternative rules have been proposed (see [15]), including Satifaction Approval Voting (SAV, satifaction of an agent is the fraction of her approved candidates that are elected; the goal is to maximize the total satisfaction), Proportional Approval Voting (PAV: like SAV, but satisfaction of an agent whose j approved candidates are selected is the j-th harmonic number Hj), Reweighted Approval Voting (RAV: a k-round scheme, in each round another candidate is selected).", "startOffset": 62, "endOffset": 66}, {"referenceID": 1, "context": "(MAV), introduced by Brams, Kilgour, and Sanver [2].", "startOffset": 48, "endOffset": 51}, {"referenceID": 15, "context": "Indeed, LeGrand [17] showed that Minimax Approval Voting is NP-complete as well by reduction from Closest String with binary alphabet.", "startOffset": 16, "endOffset": 20}, {"referenceID": 16, "context": "Previous results on Minimax Approval Voting First approximation result was a simple 3-approximation algorithm due to LeGrand, Markakis and Mehta [18], obtained by choosing an arbitrary vote and taking any k approved candidates from the vote (extending it arbitrarily to k candidates if needed).", "startOffset": 145, "endOffset": 149}, {"referenceID": 4, "context": "Next, a 2-approximation was shown by Caragiannis, Kalaitzis and Markakis using an LP-rounding procedure [5].", "startOffset": 104, "endOffset": 107}, {"referenceID": 3, "context": "Finally, recently Byrka and Sornat [4] presented a polynomial time approximation scheme (PTAS), i.", "startOffset": 35, "endOffset": 38}, {"referenceID": 2, "context": "[3] (in the context of computational social choice).", "startOffset": 0, "endOffset": 3}, {"referenceID": 22, "context": "The study of FPT algorithms for Minimax Approval Voting was initiated by Misra, Nabeel and Singh [24].", "startOffset": 97, "endOffset": 101}, {"referenceID": 1, "context": "k is the paramater r) is W [2]-hard, which implies that there is no FPT algorithm, unless there is a highly unexpected collapse in parameterized complexity classes.", "startOffset": 27, "endOffset": 30}, {"referenceID": 17, "context": "The first PTAS for Closest String was given by Li, Ma and Wang [19] with The O notation suppresses factors polynomial in the input size.", "startOffset": 63, "endOffset": 67}, {"referenceID": 22, "context": "Actually, in the article [24] the authors claim the slightly better running time of O(d).", "startOffset": 25, "endOffset": 29}, {"referenceID": 0, "context": "[1] to n log 1/\u01eb \u01eb2 , and then by Ma and Sun [23] to nO(1/\u01eb 2).", "startOffset": 0, "endOffset": 3}, {"referenceID": 21, "context": "[1] to n log 1/\u01eb \u01eb2 , and then by Ma and Sun [23] to nO(1/\u01eb 2).", "startOffset": 45, "endOffset": 49}, {"referenceID": 10, "context": "The first FPT algorithm for Closest String, running in time O\u22c6(dd) was given by Gramm, Niedermeier, and Rossmanith [12].", "startOffset": 115, "endOffset": 119}, {"referenceID": 21, "context": "This was later improved by Ma and Sun [23], who gave an algorithm with running time O\u22c6(2O(d) \u00b7|\u03a3|d), which is more efficient for constant-size alphabets.", "startOffset": 38, "endOffset": 42}, {"referenceID": 19, "context": "No further substantial progress is possible, since Lokshtanov, Marx and Saurabh [21] have shown that Closest String admits no algorithms in time O\u22c6(2o(d log d)) or O\u22c6(2o(d log |\u03a3|)) , unless the Exponential Time Hypothesis (ETH) [13] fails.", "startOffset": 80, "endOffset": 84}, {"referenceID": 11, "context": "No further substantial progress is possible, since Lokshtanov, Marx and Saurabh [21] have shown that Closest String admits no algorithms in time O\u22c6(2o(d log d)) or O\u22c6(2o(d log |\u03a3|)) , unless the Exponential Time Hypothesis (ETH) [13] fails.", "startOffset": 229, "endOffset": 233}, {"referenceID": 11, "context": "[13] states that there exists a constant c > 0, such that there is no algorithm solving 3-SAT in time O\u22c6(2cn).", "startOffset": 0, "endOffset": 4}, {"referenceID": 18, "context": "During the recent years, ETH became the central conjecture used for proving tight bounds on the complexity of various problems, see [20] for a survey.", "startOffset": 132, "endOffset": 136}, {"referenceID": 22, "context": "[24] is essentially optimal, and indeed, in this sense Minimax Approval Voting is harder than Closest String.", "startOffset": 0, "endOffset": 4}, {"referenceID": 23, "context": "1 in [25]).", "startOffset": 5, "endOffset": 9}, {"referenceID": 0, "context": ", n we have Pr [Xi = 1] = pi, for pi \u2208 [0, 1].", "startOffset": 39, "endOffset": 45}, {"referenceID": 19, "context": "In order to derive an ETH-based lower bound we need the following theorem of Lokshtanov, Marx and Saurabh [21].", "startOffset": 106, "endOffset": 110}, {"referenceID": 4, "context": "[5].", "startOffset": 0, "endOffset": 3}, {"referenceID": 0, "context": "xj \u2208 [0, 1] \u2200j \u2208 {1, .", "startOffset": 5, "endOffset": 11}, {"referenceID": 12, "context": "First we solve the linear program in time poly(n,m) using the interior point method [14].", "startOffset": 84, "endOffset": 88}, {"referenceID": 7, "context": "Recently, Cygan, Lokshtanov, Pilipczuk, Pilipczuk and Saurabh [9] showed that under ETH, there is no PTAS in time f(\u01eb) \u00b7 no(1/\u01eb) for Closest String.", "startOffset": 62, "endOffset": 65}], "year": 2016, "abstractText": "We present three results on the complexity of Minimax Approval Voting. First, we study Minimax Approval Voting parameterized by the Hamming distance d from the solution to the votes. We show Minimax Approval Voting admits no algorithm running in time O(2 log ), unless the Exponential Time Hypothesis (ETH) fails. This means that the O(d) algorithm of Misra et al. [AAMAS 2015] is essentially optimal. Motivated by this, we then show a parameterized approximation scheme, running in time O((3/\u01eb) 2d ), which is essentially tight assuming ETH. Finally, we get a new polynomialtime randomized approximation scheme for Minimax Approval Voting, which runs in time n 2 \u00b7log(1/\u01eb)) \u00b7 poly(m), almost matching the running time of the fastest known PTAS for Closest String due to Ma and Sun [SIAM J. Comp. 2009].", "creator": "LaTeX with hyperref package"}}}