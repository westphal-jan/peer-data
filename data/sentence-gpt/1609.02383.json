{"id": "1609.02383", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "8-Sep-2016", "title": "Improved Optimistic Mirror Descent for Sparsity and Curvature", "abstract": "Online Convex Optimization plays a key role in large scale machine learning. Early approaches to this problem were conservative, in which the main focus was protection against the worst case scenario. But recently several algorithms have been developed for tightening the regret bounds in easy data instances such as sparsity, predictable sequences, and curved losses due to a single single factor. These algorithms also are not ready to adapt to a full system. We will start with a demonstration of these approaches by showing how to leverage these algorithms to make complex data more easily understand and easily understand the problem.", "histories": [["v1", "Thu, 8 Sep 2016 11:52:05 GMT  (18kb)", "http://arxiv.org/abs/1609.02383v1", null]], "reviews": [], "SUBJECTS": "cs.LG", "authors": ["parameswaran kamalaruban"], "accepted": false, "id": "1609.02383"}, "pdf": {"name": "1609.02383.pdf", "metadata": {"source": "CRF", "title": "Improved Optimistic Mirror Descent for Sparsity and Curvature", "authors": ["Parameswaran Kamalaruban"], "emails": ["kamalaruban.parameswaran@data61.csiro.au"], "sections": [{"heading": null, "text": "ar X\niv :1\n60 9.\n02 38\n3v 1\n[ cs\n.L G\n] 8\nS ep\n2 01\nOnline Convex Optimization plays a key role in large scale machine learning. Early approaches to this problem were conservative, in which the main focus was protection against the worst case scenario. But recently several algorithms have been developed for tightening the regret bounds in easy data instances such as sparsity, predictable sequences, and curved losses. In this work we unify some of these existing techniques to obtain new update rules for the cases when these easy instances occur together. First we analyse an adaptive and optimistic update rule which achieves tighter regret bound when the loss sequence is sparse and predictable. Then we explain an update rule that dynamically adapts to the curvature of the loss function and utilizes the predictable nature of the loss sequence as well. Finally we extend these results to composite losses.\n1 Introduction\nThe Online Convex Optimization (OCO) problem plays a key role in machine learning as it has interesting theoretical implications and important practical applications especially in the large scale setting where computational efficiency is the main concern. [15] provides a detailed analysis of the OCO problem setting and discusses several applications of this paradigm - online regression, prediction with expert advice, and online ranking.\nGiven a convex set \u2126 \u2286 Rn and a set F of convex functions, the OCO problem can be formulated as a repeated game between a learner and an adversary. At each time step t \u2208 [T ], the learner chooses a point xt \u2208 \u2126, then the adversary reveals the loss function ft \u2208 F , and the learner suffers a loss of ft(xt). The learner\u2019s goal is to minimize the regret which is given by\nR(T ) :=\nT \u2211\nt=1\nft(xt)\u2212 inf x\u2208\u2126\nT \u2211\nt=1\nft(x).\nThere are two main classes of minimax optimal update rules for the OCO problem, namely Follow The Regularized Leader (FTRL) and Mirror Descent. In this work we consider the latter class. Given a strongly convex function \u03c8 and a learning rate \u03b7 > 0, standard mirror descent update is given by\nxt+1 = inf x\u2208\u2126\n\u03b7\u3008gt, xt\u3009+ B\u03c8(x, xt), (1)\nwhere gt \u2208 \u2202ft(xt) and B\u03c8(\u00b7, \u00b7) is Bregman divergence (formally defined later). It is well understood that the minimax optimal algorithms achieve a regret bound of O( \u221a T ), which cannot be improved for arbitrary sequences of convex losses [17]. But in practice there are several easy data instances such as sparsity, predictable sequences and curved losses, in which much tighter regret bounds are achievable. Even though minimax analysis gives robust algorithms, they are overly conservative on easy data. Now we consider some of the existing algorithms that automatically adapt to the easy data to learn faster while being robust to worst case as well.\n[6] replaces the single static regularizer in the standard mirror descent update 1 by a data dependent sequence of regularizers. This is a fully adaptive approach as it doesn\u2019t require any prior knowledge about the bound on the term given by\n\u2211T t=1 \u2016gt\u2016 2 to construct the regularizers. Further for a particular choice of\nregularizer sequence they achieved a regret bound of the form O\n(\nmax t\n\u2016xt \u2212 x\u2217\u2016\u221e \u2211n i=1\n\u221a\n\u2211T t=1 g 2 t,i\n)\n, which\nis better than the minimax optimal bound when the gradients of the losses are sparse and the prediction space is box-shaped.\n[4, 14] have shown that an optimistic prediction g\u0303t+1 of the next gradient gt+1 at time t can be used to achieve tighter regret bounds in the case where the loss functions are generated by some predictable process e.g. i.i.d losses with small variance and slowly changing gradients. For the general convex losses, the regret\nbound of this optimistic approach is O\n(\n\u221a\n\u2211T t=1 \u2016gt \u2212 g\u0303t\u2016 2 \u2217\n)\n. But this is a non-adaptive approach since one\nrequires knowledge of the upper bound on \u2211T t=1 \u2016gt \u2212 g\u0303t\u2016 2 \u2217 to set the optimal value for the learning rate. Instead we can employ the standard doubling trick to obtain similar bound with slightly worst constants. Online optimization with curved losses (strong-convex, exp-concave, mixable etc.) is easier than linear losses. When the loss functions are uniformly exp-concave or strongly convex, O(logT ) regret bounds are achieved with appropriate choice of regularizers [7, 9]. But this bound will become worse when the uniform lower bound on the convexity parameters is much smaller. In that case [9] proposed an algorithm that can adapt to the convexity of the loss functions, and achieves O( \u221a T ) regret bounds for arbitrary convex losses and O(logT ) for uniformly strong-convex losses. Even though [11] has shown equivalence between mirror descent and a variant of FTRL (namely FTRLProx) algorithms with adaptive regularizers, no such mapping is available between optimistic mirror descent and optimistic FTRL updates. Recently [12] have combined adaptive FTRL and optimistic FTRL updates to achieve tighter regret bounds for sparse and predictable sequences. In section 3 we extend this unification to obtain adaptive and optimistic mirror descent updates. We obtained a factor of \u221a 2 improvement in the regret bound compared to that of [12], because in their regret analysis they could not apply the strong FTRL lemma from [11].\nIn section 4 we consider the adaptive and optimistic mirror descent update with strongly convex loss functions. In this case we achieve tighter logarithmic regret bound without a priori knowledge about the lower bound on the strong-convexity parameters, in similar spirit of [9]. We also explain a curvature adaptive optimistic algorithm that interpolates the results for general convex losses and strongly-convex losses.\nIn practice the original convex optimization problem itself can have a regularization term associated with the constraints of the problem and generally it is not preferable to linearize those regularization terms. In section 5 we extend all our results to such composite objectives as well.\nThe main contributions of this paper are:\n\u2022 An adaptive and optimistic mirror descent update that achieves tighter regret bounds for sparse and predictable sequences (Section 3).\n\u2022 Improved optimistic mirror descent algorithm that adapts to the curvature of the loss functions (Section 4).\n\u2022 Extension of the unified update rules to the composite objectives (Section 5).\nOmitted proofs are given in the appendix.\n2 Notation and Background\nWe use the following notation throughout. For n \u2208 Z+, let [n] := {1, ..., n}. The ith element of a vector x \u2208 Rn is denoted by xi \u2208 R, and for a time dependent vector xt \u2208 Rn, the ith element is xt,i \u2208 R. The inner product between two vectors x, y \u2208 Rn is written as \u3008x, y\u3009. The gradient of a differentiable function f at x \u2208 Rn is denoted by \u2207f(x) or f \u2032(x). A superscript T , AT denotes transpose of the matrix or vector A.\nAlgorithm 1 Adaptive and Optimistic Mirror Descent\nInput: regularizers r0, r1 \u2265 0. Initialize: x1, x\u03021 = 0 \u2208 \u2126. for t = 1 to T do Predict x\u0302t, observe ft, and incur loss ft(x\u0302t). Compute gt \u2208 \u2202ft(x\u0302t) and g\u0303t+1(g1, ..., gt). Construct rt+1 s.t. r0:t+1 is 1-strongly convex w.r.t. \u2016\u00b7\u2016(t+1). Update\nxt+1 = argmin x\u2208\u2126\n\u3008gt, x\u3009+ Br0:t(x, xt), (2)\nx\u0302t+1 = argmin x\u2208\u2126\n\u3008g\u0303t+1, x\u3009+ Br0:t+1(x, xt+1). (3)\nend for\nGiven x \u2208 Rn, A = diag(x) is the n\u00d7 n matrix with entries Ai,i = xi , i \u2208 [n] and Ai,j = 0 for i 6= j. For a symmetric positive definite matrix A \u2208 Sn++, we have that \u2200x 6= 0, xTAx > 0. If A\u2212B \u2208 Sn++, then we write A \u227b B. The square root of A \u2208 Sn++ is the unique matrix X \u2208 Sn++ such that XX = A and it is denoted as A 1 2 . We use the compressed summation notation Ha:b as shorthand for \u2211b s=aHs, where Hs can be a scalar, vector, matrix, or function. Given a norm \u2016\u00b7\u2016, its dual norm is defined as follows \u2016y\u2016\u2217 := sup x:\u2016x\u2016\u22641 \u3008x, y\u3009. For a time varying norm \u2016\u00b7\u2016(t), its dual norm is written as \u2016\u00b7\u2016(t),\u2217. The dual norm of the Mahalanobis norm \u2016x\u2016A := \u221a xTAx is given by \u2016y\u2016A\u22121 = \u221a\nyTA\u22121y. Given a convex set \u2126 \u2286 Rn and a convex function f : \u2126 \u2192 R, \u2202f(x) denotes the sub-differential of f at x which is defined as \u2202f(x) := {g : f(y) \u2265 f(x) + \u3008g, y \u2212 x\u3009, \u2200y \u2208 \u2126}. A function f : \u2126 \u2192 R is \u03b1-strongly convex with respect to a general norm \u2016\u00b7\u2016 if for all x, y \u2208 \u2126\nf(x) \u2265 f(y) + \u3008g, x\u2212 y\u3009+ \u03b1 2 \u2016x\u2212 y\u20162 , g \u2208 \u2202f(y).\nBregman divergence with respect to a differentiable function g is defined as follows\nBg(x, y) := g(x)\u2212 g(y)\u2212 \u3008\u2207g(y), x\u2212 y\u3009.\nObserve that the function g is \u03b1-strongly convex with respect to \u2016\u00b7\u2016 if and only if for all x, y \u2208 \u2126 : Bg(x, y) \u2265 \u03b1 2 \u2016x\u2212 y\u2016 2 . In this paper we use the following properties of Bregman divergences\n\u2022 Linearity: B\u03b1\u03c8+\u03b2\u03c6(x, y) = \u03b1B\u03c8(x, y) + \u03b2B\u03c6(x, y).\n\u2022 Generalized triangle inequality: B\u03c8(x, y) + B\u03c8(y, z) = B\u03c8(x, z) + \u3008x\u2212 y,\u2207\u03c8(z)\u2212\u2207\u03c8(y)\u3009.\nThe following proposition [16, 1] is handy in deriving explicit update rules for mirror descent algorithms that we have presented in this work.\nProposition 1. Suppose \u03c8 is strictly convex and differentiable, and y satisfies the condition \u2207\u03c8(y) = \u2207\u03c8(u)\u2212 g. Then\nargmin x\u2208\u2126 {\u3008g, x\u3009+ B\u03c8(x, u)} = argmin x\u2208\u2126 B\u03c8(x, y).\n3 Adaptive and Optimistic Mirror Descent\nWhen the sequences are predictable [4] proposed that making an optimistic prediction of xt+1 at time t itself using the optimistic prediction g\u0303t+1(g1, ..., gt) of the next sub-gradient gt+1. For the optimistic\nprediction choices of g\u0303t+1 = 1 t \u2211t s=1 gs and g\u0303t+1 = gt, we obtain the variance bound [8] and the path length bound [4] respectively. Given a 1-strongly convex function \u03c8, and a learning rate \u03b7 > 0, the optimistic mirror descent update can be given by two stage updates as follows\nxt+1 = argmin x\u2208\u2126\n\u03b7\u3008gt, xt\u3009+ B\u03c8(x, xt)\nx\u0302t+1 = argmin x\u2208\u2126\n\u03b7\u3008g\u0303t+1, xt\u3009+ B\u03c8(x, xt+1).\nAdaptive and Optimistic mirror descent update is obtained by replacing the static regularizer \u03c8 by a sequence of data dependent regularizers rt\u2019s, which are chosen such that r0:t is 1-strongly convex with respect to \u2016\u00b7\u2016(t). The unified update is given in Algorithm 1. Note that the regularizer rt+1 is constructed at time t (based on the data observed only up to time t) and is used in the second stage update (3). Also observe that by setting g\u0303t = 0 for all t in Algorithm 1 we recover a slightly modified adaptive mirror descent update given by xt+1 = argmin\nx\u2208\u2126 \u3008gt, xt\u3009+ Br0:t(x, xt), where rt can depend only on g1, ..., gt\u22121.\nThe following lemma is a generalization of Lemma 5 from [4] for time varying norms, which gives a bound on the instantaneous linear regret of Algorithm 1.\nLemma 2. The instantaneous linear regret of Algorithm 1 w.r.t. any x\u2217 \u2208 \u2126 can be bounded as follows\n\u3008x\u0302t \u2212 x\u2217, gt\u3009 \u2264 Br0:t(x\u2217, xt)\u2212 Br0:t(x\u2217, xt+1) + 12 \u2016gt \u2212 g\u0303t\u2016 2 (t),\u2217 .\nProof. Consider\n\u3008gt, x\u0302t \u2212 x\u2217\u3009 = \u3008gt \u2212 g\u0303t, x\u0302t \u2212 xt+1\u3009+ \u3008g\u0303t, x\u0302t \u2212 xt+1\u3009+ \u3008gt, xt+1 \u2212 x\u2217\u3009. (4)\nBy the fact that \u3008a, b\u3009 \u2264 \u2016a\u2016 \u2016b\u2016\u2217 \u2264 12 \u2016a\u2016 2 + 12 \u2016b\u2016 2 \u2217, we have\n\u3008gt \u2212 g\u0303t, x\u0302t \u2212 xt+1\u3009 \u2264 12 \u2016x\u0302t \u2212 xt+1\u2016 2 (t) + 1 2 \u2016gt \u2212 g\u0303t\u2016 2 (t),\u2217 .\nThe first-order optimality condition [2] for x\u2217 = argmin x\u2208\u2126 \u3008g, x\u3009+ B\u03c8(x, y) is given by\n\u3008x\u2217 \u2212 z, g\u3009 \u2264 B\u03c8(z, y)\u2212 B\u03c8(z, x\u2217)\u2212 B\u03c8(x\u2217, y), \u2200z \u2208 \u2126.\nBy applying the above condition for (3) and (2) we have respectively\n\u3008x\u0302t \u2212 xt+1, g\u0303t\u3009 \u2264 Br0:t(xt+1, xt)\u2212 Br0:t(xt+1, x\u0302t)\u2212 Br0:t(x\u0302t, xt), \u3008xt+1 \u2212 x\u2217, gt\u3009 \u2264 Br0:t(x\u2217, xt)\u2212 Br0:t(x\u2217, xt+1)\u2212 Br0:t(xt+1, xt).\nThus by (4) we have\n\u3008gt, x\u0302t \u2212 x\u2217\u3009 \u2264 12 \u2016x\u0302t \u2212 xt+1\u2016 2 (t) + 1 2 \u2016gt \u2212 g\u0303t\u2016 2 (t),\u2217 + Br0:t(x\u2217, xt)\u2212 Br0:t(x\u2217, xt+1)\u2212 Br0:t(xt+1, x\u0302t) \u2264 12 \u2016gt \u2212 g\u0303t\u2016 2 (t),\u2217 + Br0:t(x\u2217, xt)\u2212 Br0:t(x\u2217, xt+1)\nwhere the second inequality is due to 1-strong convexity of r0:t w.r.t. \u2016\u00b7\u2016(t).\nThe following lemma is already proven by [4] and used in the proof of our Theorem 8.\nLemma 3. For Algorithm 1 we have, \u2016x\u0302t \u2212 xt+1\u2016(t) \u2264 \u2016gt \u2212 g\u0303t\u2016(t),\u2217.\nThe following regret bound holds for Algorithm 1 with a sequence of general convex functions ft\u2019s:\nTheorem 4. The regret of Algorithm 1 w.r.t. any x\u2217 \u2208 \u2126 is bounded by T \u2211\nt=1\nft(x\u0302t)\u2212 ft(x\u2217) \u2264 12 T \u2211\nt=1\n\u2016gt \u2212 g\u0303t\u20162(t),\u2217 + T \u2211\nt=1\nBrt(x\u2217, xt) + Br0(x\u2217, x1)\u2212 Br0:T (x\u2217, xT+1).\nProof. Consider\nT \u2211\nt=1\nft(x\u0302t)\u2212 ft(x\u2217)\n\u2264 T \u2211\nt=1\n\u3008gt, x\u0302t \u2212 x\u2217\u3009\n\u2264 T \u2211\nt=1\n1 2 \u2016gt \u2212 g\u0303t\u2016 2 (t),\u2217 + Br0:t(x\u2217, xt)\u2212 Br0:t(x\u2217, xt+1),\nwhere the first inequality is due to the convexity of ft and the second one is due to Lemma 2. Then the following simplification of the sum of Bregman divergence terms completes the proof.\nT \u2211\nt=1\nBr0:t(x\u2217, xt)\u2212 Br0:t(x\u2217, xt+1)\n= Br0(x\u2217, x1)\u2212 Br0:T (x\u2217, xT+1) + T \u2211\nt=1\nBrt(x\u2217, xt)\nNow we analyse the performance of Algorithm 1 with specific choices of regularizer sequences. First we recover the non-adaptive optimistic mirror descent [4] and its regret bound as a corollary of Theorem 4.\nCorollary 5. Given 1-strongly convex (w.r.t. \u2016\u00b7\u2016) function \u03c8, define Rmax(x\u2217) := maxx\u2208\u2126 B\u03c8(x\u2217, x) \u2212 minx\u2208\u2126 B\u03c8(x\u2217, x). If rt\u2019s are given by r0(x) = 1\u03b7\u03c8(x) (for \u03b7 > 0) and rt(x) = 0, \u2200t \u2265 1, then the regret of Algorithm 1 w.r.t. any x\u2217 \u2208 \u2126 is bounded as follows\nT \u2211\nt=1\nft(x\u0302t)\u2212 ft(x\u2217) \u2264 \u03b7\n2\nT \u2211\nt=1\n\u2016gt \u2212 g\u0303t\u20162\u2217 + 1 \u03b7 Rmax(x\u2217).\nFurther if \u2211T t=1 \u2016gt \u2212 g\u0303t\u2016 2 \u2217 \u2264 Q, then by choosing \u03b7 =\n\u221a\n2Rmax(x\u2217) Q , we have\nT \u2211\nt=1\nft(x\u0302t)\u2212 ft(x\u2217) \u2264 \u221a 2Rmax(x\u2217)Q.\nProof. For the given choice of regularizers, we have r0:t(x) = 1 \u03b7 \u03c8(x) and Br0:t(x, y) = 1\u03b7B\u03c8(x, y). Since r0:t is 1-strongly convex w.r.t. 1\u221a \u03b7 \u2016\u00b7\u2016, we have \u2016\u00b7\u2016(t) = 1\u221a\u03b7 \u2016\u00b7\u2016 and \u2016\u00b7\u2016(t),\u2217 = \u221a \u03b7 \u2016\u00b7\u2016\u2217. Then the corollary directly follows from Theorem 4.\nIn this non-adaptive case we need to know an upper bound of \u2211T t=1 \u2016gt \u2212 g\u0303t\u2016 2 \u2217 in advance to choose the optimal value for \u03b7. Instead we can employ the standard doubling trick to obtain similar bounds with slightly worst constants.\nBy leveraging the techniques from [6] we can adaptively construct regularizers based on the observed data. The following corollary describes a regularizer construction scheme for Algorithm 1 which is fully adaptive and achieves a regret guarantee that holds at anytime.\nCorollary 6. Given \u2126 \u2286 \u00d7ni=1[\u2212Ri, Ri], let\nG0 = 0 (5)\nG1 = \u03b3 2I s.t. \u03b32I < (gt \u2212 g\u0303t)(gt \u2212 g\u0303t)T , \u2200t (6)\nGt = (gt\u22121 \u2212 g\u0303t\u22121)(gt\u22121 \u2212 g\u0303t\u22121)T , \u2200t \u2265 2 (7)\nQ1:t = diag\n(\n1\nR1 , ...,\n1\nRn\n)\ndiag (G1:t) 1 2 .\nIf rt\u2019s are given by r0 (x) = 0 and rt (x) = 1 2 \u221a 2 \u2016x\u20162Qt , then the regret of Algorithm 1 w.r.t. any x \u2217 \u2208 \u2126 is bounded by\nT \u2211\nt=1\nft(x\u0302t)\u2212 ft(x\u2217) \u2264 2 \u221a 2 n \u2211\ni=1\nRi\n\u221a \u221a \u221a \u221a\u03b32 + T\u22121 \u2211\nt=1\n(gt,i \u2212 g\u0303t,i)2.\nProof. By letting \u03b7 = \u221a 2 for the given sequence of regularizers, we get r0:t (x) = 1 2\u03b7 \u2016x\u2016 2 Q1:t . Since r0:t is 1-strongly convex w.r.t. 1\u221a \u03b7 \u2016\u00b7\u2016Q1:t , we have \u2016\u00b7\u2016(t) = 1\u221a \u03b7 \u2016\u00b7\u2016Q1:t and \u2016\u00b7\u2016(t),\u2217 = \u221a \u03b7 \u2016\u00b7\u2016Q\u22121 1:t . By using the facts that diag (\u03b11, ..., \u03b1n) 1 2 = diag (\u221a \u03b11, ..., \u221a \u03b1n )\nand diag (\u03b21, ..., \u03b2n) \u00b7 diag (\u03b31, ..., \u03b3n) = diag (\u03b21\u03b31, ..., \u03b2n\u03b3n), the (i, i)-th entry of the diagonal matrix Q1:t can be given as\n(Q1:t)ii = 1\nRi\n\u221a \u221a \u221a \u221adiag ( \u03b32I + t\u22121 \u2211\ns=1\n(gs \u2212 g\u0303s)(gs \u2212 g\u0303s)T )\nii\n= 1\nRi\n\u221a \u221a \u221a \u221a\u03b32 + t\u22121 \u2211\ns=1\n(gs,i \u2212 g\u0303s,i)2.\nNow by Theorem 4 the regret bound of Algorithm 1 with this choice of regularizer sequence can be given as follows\nT \u2211\nt=1\nft(x\u0302t)\u2212 ft(x\u2217) \u2264 12 T \u2211\nt=1\n\u2016gt \u2212 g\u0303t\u20162(t),\u2217 + T \u2211\nt=1\nBrt(x\u2217, xt).\nConsider\n1 2\nT \u2211\nt=1\n\u2016gt \u2212 g\u0303t\u20162(t),\u2217\n= 12\nT \u2211\nt=1\n\u03b7 \u2016gt \u2212 g\u0303t\u20162Q\u22121 1:t\n= \u03b7\n2\nT \u2211\nt=1\nn \u2211\ni=1\n(gt,i \u2212 g\u0303t,i)2 (Q1:t)\u22121ii\n= \u03b7\n2\nT \u2211\nt=1\nn \u2211\ni=1\n(gt,i \u2212 g\u0303t,i)2 Ri \u221a\n\u03b32 + \u2211t\u22121 s=1 (gs,i \u2212 g\u0303s,i) 2\n\u2264 \u03b7 2\nn \u2211\ni=1\nRi\nT \u2211\nt=1\n(gt,i \u2212 g\u0303t,i)2 \u221a\n\u2211t s=1 (gs,i \u2212 g\u0303s,i) 2\n\u2264 \u03b7 n \u2211\ni=1\nRi\n\u221a \u221a \u221a \u221a T \u2211\nt=1\n(gt,i \u2212 g\u0303t,i)2\n\u2264 \u03b7 n \u2211\ni=1\nRi\n\u221a \u221a \u221a \u221a\u03b32 + T\u22121 \u2211\nt=1\n(gt,i \u2212 g\u0303t,i)2,\nwhere the first and third inequalities are due to the fact that \u03b32 \u2265 (gt,i \u2212 g\u0303t,i)2 for all t \u2208 [T ], and the second inequality is due to the fact that for any non-negative real numbers a1, a2, ..., an : \u2211n i=1 ai \u221a \u2211\ni j=1 aj \u2264\n2 \u221a \u2211n i=1 ai. Also observing that\nT \u2211\nt=1\nBrt(x\u2217, xt)\n=\nT \u2211\nt=1\n1\n2\u03b7 \u2016x\u2217 \u2212 xt\u20162Qt\n= 1\n2\u03b7\nT \u2211\nt=1\nn \u2211\ni=1\n(x\u2217i \u2212 xt,i)2 (Qt)ii\n\u2264 1 2\u03b7\nn \u2211\ni=1\n(2Ri) 2 T \u2211\nt=1\n(Qt)ii\n= 2\n\u03b7\nn \u2211\ni=1\nR2i (Q1:T )ii\n= 2\n\u03b7\nn \u2211\ni=1\nRi\n\u221a \u221a \u221a \u221a\u03b32 + T\u22121 \u2211\nt=1\n(gt,i \u2212 g\u0303t,i)2\ncompletes the proof.\nThe regret bound obtained in the above corollary is much tighter than that of [6] and [4] when the sequence of loss functions are sparse and predictable. Since we are using per-coordinate learning rates implicitly we get better bounds for the case where only certain coordinates of the gradients are accurately predictable as well. Even when the loss sequence is completely unpredictable, the above bound is not much worse than a constant factor of the bound in [6].\nBy using Proposition 1 we can derive explicit forms of the update rules given by (2) and (3) with regularizers constructed in Corollary 6. For yt+1 = xt \u2212 \u221a 2Q\u221211:t gt and y\u0302t+1 = xt+1 \u2212 \u221a 2Q\u221211:t+1g\u0303t+1, the updates (2) and (3) can be given as xt+1 = argmin x\u2208\u2126 1 2 \u2016x\u2212 yt+1\u2016 2 Q1:t and x\u0302t+1 = argmin x\u2208\u2126 1 2 \u2016x\u2212 y\u0302t+1\u2016 2 Q1:t+1 respectively. The next corollary explains a regularizer construction method with full matrix learning rates, which is an extension of Corollary 6. But this approach is computationally not preferable, especially in high dimensions, as it costs O(n2) per round of operations.\nCorollary 7. Define D := sup x,y\u2208\u2126\n\u2016x\u2212 y\u20162. Let Q1:t = (G1:t) 1 2 , where Gt\u2019s are given by (5),(6) and (7). If\nrt\u2019s are given by r0 (x) = 0 and rt (x) = 1\u221a 2D \u2016x\u20162Qt , then the regret of Algorithm 1 w.r.t. any x \u2217 \u2208 \u2126 is bounded by T \u2211\nt=1\nft(x\u0302t)\u2212 ft(x\u2217) \u2264 \u221a 2D tr (Q1:T ) .\n4 Optimistic Mirror Descent with Curved Losses\nThe following theorem provides a regret bound of Algorithm 1 for the case where ft is Ht-strongly convex with respect to some general norm \u2016\u00b7\u2016. Since this theorem is an extension of Theorem 2.1 from [9] for the Optimistic Mirror Descent, this inherits the properties mentioned there such as : rt\u2019s can be chosen without the knowledge of uniform lower bound on Ht\u2019s, and O(logT ) bound can be achieved even when some Ht \u2264 0 as long as H1:t\nt > 0.\nTheorem 8. Let ft is Ht-strongly convex w.r.t. \u2016\u00b7\u2016 and Ht \u2264 \u03b3 for all t \u2208 [T ]. If rt\u2019s are given by r0(x) = 0, r1(x) = \u03b3 4 \u2016x\u2016 2 , and rt(x) = Ht\u22121 4 \u2016x\u2016 2 for all t \u2265 2, then the regret of Algorithm 1 w.r.t. any x\u2217 \u2208 \u2126 is bounded by T \u2211\nt=1\nft(x\u0302t)\u2212 ft(x\u2217) \u2264 3 T \u2211\nt=1\n\u2016gt \u2212 g\u0303t\u20162\u2217 H1:t + \u03b3 4 \u2016x\u2217 \u2212 x1\u20162 .\nProof. For the given choice of regularizers, we have r0:t(x) = H1:t\u22121+\u03b3 4 \u2016x\u2016 2 and Br0:t(x, y) = H1:t\u22121+\u03b34 \u2016x\u2212 y\u2016 2. Since r0:t is 1-strongly convex w.r.t. \u221a H1:t\u22121+\u03b3 2 \u2016\u00b7\u2016, we have \u2016\u00b7\u2016(t) = \u221a H1:t\u22121+\u03b3 2 \u2016\u00b7\u2016 and \u2016\u00b7\u2016(t),\u2217 = \u221a 2 H1:t\u22121+\u03b3\n\u2016\u00b7\u2016\u2217. Thus for any x\u2217 \u2208 \u2126 we have\nft(x\u0302t)\u2212 ft(x\u2217)\n\u2264 \u3008gt, x\u0302t \u2212 x\u2217\u3009 \u2212 Ht 2 \u2016x\u0302t \u2212 x\u2217\u20162\n\u2264 12 \u2016gt \u2212 g\u0303t\u2016 2 (t),\u2217 + Br0:t(x\u2217, xt)\u2212 Br0:t(x\u2217, xt+1)\u2212\nHt\n2 \u2016x\u0302t \u2212 x\u2217\u20162\n= \u2016gt \u2212 g\u0303t\u20162\u2217 H1:t\u22121 + \u03b3 + H1:t\u22121 + \u03b3 4 \u2016x\u2217 \u2212 xt\u20162 \u2212 H1:t\u22121 + \u03b3 4 \u2016x\u2217 \u2212 xt+1\u20162 \u2212 Ht 2 \u2016x\u0302t \u2212 x\u2217\u20162 ,\nwhere the first inequality is due to the strong convexity of ft, and the second inequality is due to Lemma 2. Observe that\nT \u2211\nt=1\nH1:t\u22121 + \u03b3\n4\n{ \u2016x\u2217 \u2212 xt\u20162 \u2212 \u2016x\u2217 \u2212 xt+1\u20162 }\n=\nT \u2211\nt=1\n\u2016x\u2217 \u2212 xt+1\u20162 { H1:t + \u03b3 4 \u2212 H1:t\u22121 + \u03b3 4 } + \u03b3 4 \u2016x\u2217 \u2212 x1\u20162 \u2212 H1:T + \u03b3 4 \u2016x\u2217 \u2212 xT+1\u20162\n\u2264 T \u2211\nt=1\nHt\n4 \u2016x\u2217 \u2212 xt+1\u20162 +\n\u03b3 4 \u2016x\u2217 \u2212 x1\u20162 ,\nand\nT \u2211\nt=1\nHt\n4 \u2016x\u2217 \u2212 xt+1\u20162 \u2212\nHt\n2 \u2016x\u0302t \u2212 x\u2217\u20162\n= T \u2211\nt=1\nHt\n4\n{ \u2016x\u2217 \u2212 x\u0302t + x\u0302t \u2212 xt+1\u20162 \u2212 2 \u2016x\u2217 \u2212 x\u0302t\u20162 }\n\u2264 T \u2211\nt=1\nHt\n2 \u2016x\u0302t \u2212 xt+1\u20162\n\u2264 T \u2211\nt=1\nH1:t\u22121 + \u03b3\n2 \u2016x\u0302t \u2212 xt+1\u20162\n\u2264 2 T \u2211\nt=1\n\u2016gt \u2212 g\u0303t\u20162\u2217 H1:t\u22121 + \u03b3 ,\nwhere the first inequality is obtained by applying the triangular inequality of norms the fact that (a+ b)2 \u2264 2a2 + 2b2, the second inequality is due to the facts that Ht \u2264 \u03b3 and H1:t\u22121 \u2265 0, and the third inequality is due to Lemma 3.\nNow by summing up the instantaneous regrets and using the above observation we get\nT \u2211\nt=1\nft(x\u0302t)\u2212 ft(x\u2217) \u2264 3 T \u2211\nt=1\n\u2016gt \u2212 g\u0303t\u20162\u2217 H1:t\u22121 + \u03b3 + \u03b3 4 \u2016x\u2217 \u2212 x1\u20162\n\u2264 3 T \u2211\nt=1\n\u2016gt \u2212 g\u0303t\u20162\u2217 H1:t + \u03b3 4 \u2016x\u2217 \u2212 x1\u20162 ,\nwhere the last inequality is due to the fact that Ht \u2264 \u03b3.\nIn the above theorem if Ht \u2265 H > 0 and \u2016gt \u2212 g\u0303t\u2016\u2217 \u2264 1 (w.l.o.g) for all t, then it obtain a regret bound of the form O ( log \u2211T\nt=1 \u2016gt \u2212 g\u0303t\u2016 2 \u2217\n)\n. When H is small, however, this guaranteed regret can still be large.\nNow instead of running Algorithm 1 on the observed sequence of ft\u2019s, we use the modified sequence of loss functions of the form\nf\u0303t(x) := ft(x) + \u03bbt\n2 \u2016x\u2212 x\u0302t\u20162 , \u03bbt \u2265 0, (8)\nwhich is already considered in [5] for the non-optimistic mirror descent case. Given ft is Ht-strongly convex with respect to \u2016\u00b7\u2016, f\u0303t is (Ht + \u03bbt)-strongly convex. Also note that \u2202f\u0303t(x\u0302t) = \u2202ft(x\u0302t) because the gradient of \u2016x\u2212 x\u0302t\u20162 is 0 when evaluated at x\u0302t [5]. Thus in the updates (2) and (3) the terms gt and g\u0303t+1 remain unchanged, only the regularizers rt\u2019s will change appropriately. By applying Theorem 8 for the modified sequence of losses given by (8) we obtain the following corollary.\nCorollary 9. Let 2R = sup x,y\u2208\u2126\n\u2016x\u2212 y\u2016. Also let ft be Ht-strongly convex w.r.t. \u2016\u00b7\u2016, Ht \u2264 \u03b3, and \u03bbt \u2264 \u03b4,\nfor all t \u2208 [T ]. If Algorithm 1 is performed on the modified functions f\u0303t\u2019s with the regularizers rt\u2019s given by r0(x) = 0, r1(x) = \u03b3+\u03b4 4 \u2016x\u2016 2 , and rt(x) = Ht\u22121+\u03bbt\u22121 4 \u2016x\u2016 2 for all t \u2265 2, then for any sequence \u03bb1, ..., \u03bbT \u2265 0, we get T \u2211\nt=1\nft(x\u0302t)\u2212 ft(x\u2217) \u2264 2R2\u03bb1:T + 3 T \u2211\nt=1\n\u2016gt \u2212 g\u0303t\u20162\u2217 H1:t + \u03bb1:t + \u03b3 + \u03b4 4 \u2016x\u2217 \u2212 x1\u20162 .\nIn the above corollary if we consider the two terms that depend on \u03bbt\u2019s, the first term increases and the second term deceases with the increase of \u03bbt\u2019s. Based on the online balancing heuristic approach [9], the positive solution of 2R2\u03bb1:t = 3 \u2016gt\u2212g\u0303t\u20162\u2217 H1:t+\u03bb1:t is given by\n\u03bbt =\n\u221a\n(H1:t + \u03bb1:t\u22121) 2 + 6\u2016gt\u2212g\u0303t\u20162\u2217 R2\n\u2212 (H1:t + \u03bb1:t\u22121) 2 .\nThe resulting algorithm with the above choice of \u03bbt is given in Algorithm 2. By using the Lemma 3.1 from [9] we obtain the following regret bound for Algorithm 2.\nTheorem 10. The regret of Algorithm 2 on the sequence of ft\u2019s with curvature Ht \u2265 0 is bounded by\nT \u2211\nt=1\nft(x\u0302t)\u2212 ft(x\u2217) \u2264 \u03b3 + \u03b4 4 \u2016x\u2217 \u2212 x1\u20162 + 2 inf\n\u03bb\u2217 1 ,...,\u03bb\u2217 T\n{\n2R2\u03bb\u22171:T + 3 T \u2211\nt=1\n\u2016gt \u2212 g\u0303t\u20162\u2217 H1:t + \u03bb\u22171:t\n}\n.\nAlgorithm 2 Curvature Adaptive and Optimistic Mirror Descent\nInput: r0(x) = 0 and r1(x) = \u03b3+\u03b4 4 \u2016x\u2016 2. Initialize: x1, x\u03021 = 0 \u2208 \u2126. for t = 1 to T do Predict x\u0302t, observe ft, and incur loss ft(x\u0302t). Compute gt \u2208 \u2202ft(x\u0302t) and g\u0303t+1(g1, ..., gt).\nCompute \u03bbt =\n\u221a\n(H1:t+\u03bb1:t\u22121) 2+\n6\u2016gt\u2212g\u0303t\u2016 2 \u2217\nR2 \u2212(H1:t+\u03bb1:t\u22121)\n2\nDefine rt+1(x) = Ht+\u03bbt 4 \u2016x\u2016 2 . Update\nxt+1 = argmin x\u2208\u2126\n\u3008gt, x\u3009+ Br0:t(x, xt),\nx\u0302t+1 = argmin x\u2208\u2126\n\u3008g\u0303t+1, x\u3009+ Br0:t+1(x, xt+1).\nend for\nThus the Algorithm 2 achieves a regret bound which is competitive with the bound achievable by the best offline choice of parameters \u03bbt\u2019s. From the above theorem we obtain the following two corollaries which show\nthat Algorithm 2 achieves intermediate rates between O\n(\n\u221a\n\u2211T t=1 \u2016gt \u2212 g\u0303t\u2016 2 \u2217\n)\nand O ( log \u2211T\nt=1 \u2016gt \u2212 g\u0303t\u2016 2 \u2217\n)\ndepending on the curvature of the losses.\nCorollary 11. For any sequence of convex loss functions ft\u2019s, the bound on the regret of Algorithm 2 is\nO\n(\n\u221a\n\u2211T t=1 \u2016gt \u2212 g\u0303t\u2016 2 \u2217\n)\n.\nProof. Let \u03bb\u22171 = \u221a \u2211T t=1 \u2016gt \u2212 g\u0303t\u2016 2 \u2217, and \u03bb \u2217 t = 0 for all t > 1.\n2R2\u03bb\u22171:T + 3 T \u2211\nt=1\n\u2016gt \u2212 g\u0303t\u20162\u2217 H1:t + \u03bb\u22171:t\n= 2R2\n\u221a \u221a \u221a \u221a T \u2211\nt=1\n\u2016gt \u2212 g\u0303t\u20162\u2217 + 3 T \u2211\nt=1 \u2016gt \u2212 g\u0303t\u20162\u2217 0 + \u221a\n\u2211T t=1 \u2016gt \u2212 g\u0303t\u2016 2 \u2217\n= ( 2R2 + 3 )\n\u221a \u221a \u221a \u221a T \u2211\nt=1\n\u2016gt \u2212 g\u0303t\u201622.\nCorollary 12. Suppose \u2016gt \u2212 g\u0303t\u2016\u2217 \u2264 1 (w.l.o.g) and Ht \u2265 H > 0 for all t \u2208 [T ]. Then the bound on the regret of Algorithm 2 is O (\nlog \u2211T t=1 \u2016gt \u2212 g\u0303t\u2016 2 \u2217\n)\n.\nProof. Set \u03bb\u2217t = 0 for all t.\n2R2\u03bb\u22171:T + 3 T \u2211\nt=1\n\u2016gt \u2212 g\u0303t\u20162\u2217 H1:t + \u03bb\u22171:t = 0 + 3 T \u2211\nt=1\n\u2016gt \u2212 g\u0303t\u20162\u2217 Ht+ 0\n= O\n(\nlog\nT \u2211\nt=1\n\u2016gt \u2212 g\u0303t\u20162\u2217\n)\n,\nAlgorithm 3 Adaptive and Optimistic Mirror Descent with Composite Losses\nInput: regularizers r0, r1 \u2265 0, composite losses {\u03c8t}t where \u03c8t \u2265 0. Initialize: x1, x\u03021 = 0 \u2208 \u2126. for t = 1 to T do Predict x\u0302t, observe ft, and incur loss ft(x\u0302t) + \u03c8t(x\u0302t). Compute gt \u2208 \u2202ft(x\u0302t) and g\u0303t+1(g1, ..., gt). Construct rt+1 s.t. r0:t+1 is 1-strongly convex w.r.t. \u2016\u00b7\u2016(t+1). Update\nxt+1 = argmin x\u2208\u2126\n\u3008gt, x\u3009+ \u03c8t(x) + Br0:t(x, xt), (9)\nx\u0302t+1 = argmin x\u2208\u2126\n\u3008g\u0303t+1, x\u3009+ \u03c8t+1(x) + Br0:t+1(x, xt+1). (10)\nend for\nwhere the last inequality is due to the fact that if at \u2264 1 for all t \u2208 [T ], then \u2211T t=1 at t \u2264 O\n(\nlog \u2211T\nt=1 at\n)\n.\nThe results obtained here can be extended to the applications discussed in [5, 13] to obtain much tighter results.\n5 Composite Losses\nHere we consider the case when observed loss function ft is composed with some non-negative (possibly non-smooth) convex regularizer term \u03c8t to impose certain constraints on the original problem. In this case we generally do not want to linearize the additional regularizer term, thus in the update rules given by (2) and (3) we include \u03c8t and \u03c8t+1 respectively without linearizing them. This extension is presented in Algorithm 3.\nThe following lemma provides a bound on the instantaneous regret of Algorithm 3.\nLemma 13. The instantaneous regret of Algorithm 3 w.r.t. any x\u2217 \u2208 \u2126 can be bounded as follows\n{ft(x\u0302t) + \u03a8t(x\u0302t)} \u2212 {ft(x\u2217) + \u03a8t(x\u2217)} \u2264 12 \u2016gt \u2212 g\u0303t\u2016 2 (t),\u2217 + Br0:t(x\u2217, xt)\u2212 Br0:t(x\u2217, xt+1).\nProof. The instantaneous regret of the algorithm can be bounded as below using the convexity of ft\n{ft(x\u0302t) + \u03a8t(x\u0302t)} \u2212 {ft(x\u2217) + \u03a8t(x\u2217)} \u2264 \u3008gt, x\u0302t \u2212 x\u2217\u3009+ {\u03a8t(x\u0302t)\u2212\u03a8t(x\u2217)} .\nNow consider \u3008gt, x\u0302t \u2212 x\u2217\u3009 = \u3008gt \u2212 g\u0303t, x\u0302t \u2212 xt+1\u3009+ \u3008g\u0303t, x\u0302t \u2212 xt+1\u3009+ \u3008gt, xt+1 \u2212 x\u2217\u3009. (11)\nBy the fact that \u3008a, b\u3009 \u2264 \u2016a\u2016 \u2016b\u2016\u2217 \u2264 12 \u2016a\u2016 2 + 12 \u2016b\u2016 2 \u2217, we have\n\u3008gt \u2212 g\u0303t, x\u0302t \u2212 xt+1\u3009 \u2264 12 \u2016x\u0302t \u2212 xt+1\u2016 2 (t) + 1 2 \u2016gt \u2212 g\u0303t\u2016 2 (t),\u2217\nThe first-order optimality condition for x\u2217 = argmin x\u2208\u2126 \u3008g, x\u3009+ f(x) + B\u03c8(x, y) and for z \u2208 \u2126,\n\u3008x\u2217 \u2212 z, g\u3009 \u2264 \u3008z \u2212 x\u2217, f \u2032(x\u2217)\u3009+ B\u03c8(z, y)\u2212 B\u03c8(z, x\u2217)\u2212 B\u03c8(x\u2217, y).\nBy applying the above condition for (10) and (9) we have respectively\n\u3008x\u0302t \u2212 xt+1, g\u0303t\u3009 \u2264 \u3008\u03a8\u2032t(x\u0302t), xt+1 \u2212 x\u0302t\u3009+ Br0:t(xt+1, xt)\u2212 Br0:t(xt+1, x\u0302t)\u2212 Br0:t(x\u0302t, xt)\n\u3008xt+1 \u2212 x\u2217, gt\u3009 \u2264 \u3008\u03a8\u2032t(xt+1), x\u2217 \u2212 xt+1\u3009+ Br0:t(x\u2217, xt)\u2212 Br0:t(x\u2217, xt+1)\u2212 Br0:t(xt+1, xt). Thus by (11) we have\n\u3008gt, x\u0302t \u2212 x\u2217\u3009+ {\u03a8t(x\u0302t)\u2212\u03a8t(x\u2217)} \u2264 12 \u2016x\u0302t \u2212 xt+1\u2016 2 (t) + 1 2 \u2016gt \u2212 g\u0303t\u2016 2 (t),\u2217 + Br0:t(x\u2217, xt)\u2212 Br0:t(x\u2217, xt+1)\u2212 Br0:t(xt+1, x\u0302t)\n+ \u03a8t(x\u0302t)\u2212\u03a8t(x\u2217) + \u3008\u03a8\u2032t(x\u0302t), xt+1 \u2212 x\u0302t\u3009+ \u3008\u03a8\u2032t(xt+1), x\u2217 \u2212 xt+1\u3009 \u2264 12 \u2016gt \u2212 g\u0303t\u2016 2 (t),\u2217 + Br0:t(x\u2217, xt)\u2212 Br0:t(x\u2217, xt+1)\n+ \u03a8t(x\u0302t) + \u3008\u03a8\u2032t(x\u0302t), xt+1 \u2212 x\u0302t\u3009+ \u3008\u03a8\u2032t(xt+1), x\u2217 \u2212 xt+1\u3009 \u2212\u03a8t(x\u2217) \u2264 12 \u2016gt \u2212 g\u0303t\u2016 2 (t),\u2217 + Br0:t(x\u2217, xt)\u2212 Br0:t(x\u2217, xt+1)\n+ \u03a8t(xt+1) + \u3008\u03a8\u2032t(xt+1), x\u2217 \u2212 xt+1\u3009 \u2212\u03a8t(x\u2217) \u2264 12 \u2016gt \u2212 g\u0303t\u2016 2 (t),\u2217 + Br0:t(x\u2217, xt)\u2212 Br0:t(x\u2217, xt+1) + \u03a8t(x\u2217)\u2212\u03a8t(x\u2217) = 12 \u2016gt \u2212 g\u0303t\u2016 2 (t),\u2217 + Br0:t(x\u2217, xt)\u2212 Br0:t(x\u2217, xt+1)\nwhere the second inequality is due to 1-strong convexity of r0:t w.r.t. \u2016\u00b7\u2016(t), and the third and fourth inequalities are due to the convexity of \u03a8t at x\u0302t and xt+1 respectively.\nFrom the above lemma we can observe that the instantaneous regret of Algorithm 3 is exactly equal to that of the non-composite version (Algorithm 1). Thus all the improvements that we discussed in the previous sections for the non-composite case are also applicable to composite losses as well.\n6 Discussion\nWe present adaptive variants of optimistic mirror descent which improve the existing regret bounds when some of the easy data instances occur together. Algorithms that we have discussed in this paper achieve regret guarantees that hold at any time.\nWe also note that the regret bounds given in this work can be converted into convergence bounds for batch stochastic problems using online-to-batch conversion techniques [3, 10].\nAs in Theorem 8, we can obtain regret bound for the case when the loss function ft is \u03b2t-convex (which is broader class than exp-concave losses) as well. But for the resulting bound we cannot apply Lemma 3.1 from [9] to obtain a near optimal closed form solution of \u03bbt.\nReferences\n[1] Amir Beck and Marc Teboulle. Mirror descent and nonlinear projected subgradient methods for convex optimization. Operations Research Letters, 31(3):167\u2013175, 2003.\n[2] Stephen Boyd and Lieven Vandenberghe. Convex optimization. Cambridge university press, 2004.\n[3] Nicolo Cesa-Bianchi, Alex Conconi, and Claudio Gentile. On the generalization ability of on-line learning algorithms. Information Theory, IEEE Transactions on, 50(9):2050\u20132057, 2004.\n[4] Chao-Kai Chiang, Tianbao Yang, Chia-Jung Lee, Mehrdad Mahdavi, Chi-Jen Lu, Rong Jin, and Shenghuo Zhu. Online optimization with gradual variations. 2012.\n[5] Chuong B Do, Quoc V Le, and Chuan-Sheng Foo. Proximal regularization for online and batch learning. In Proceedings of the 26th Annual International Conference on Machine Learning, pages 257\u2013264. ACM, 2009.\n[6] John Duchi, Elad Hazan, and Yoram Singer. Adaptive subgradient methods for online learning and stochastic optimization. The Journal of Machine Learning Research, 12:2121\u20132159, 2011.\n[7] Elad Hazan, Amit Agarwal, and Satyen Kale. Logarithmic regret algorithms for online convex optimization. Machine Learning, 69(2-3):169\u2013192, 2007.\n[8] Elad Hazan and Satyen Kale. Extracting certainty from uncertainty: Regret bounded by variation in costs. Machine learning, 80(2-3):165\u2013188, 2010.\n[9] Elad Hazan, Alexander Rakhlin, and Peter L Bartlett. Adaptive online gradient descent. In Advances in Neural Information Processing Systems, pages 65\u201372, 2007.\n[10] ShamMKakade and Ambuj Tewari. On the generalization ability of online strongly convex programming algorithms. In Advances in Neural Information Processing Systems, pages 801\u2013808, 2009.\n[11] H Brendan McMahan. Analysis techniques for adaptive online learning. arXiv preprint arXiv:1403.3465, 2014.\n[12] Mehryar Mohri and Scott Yang. Accelerating optimization via adaptive prediction. arXiv preprint arXiv:1509.05760, 2015.\n[13] Francesco Orabona, Luo Jie, and Barbara Caputo. Online-batch strongly convex multi kernel learning. In Computer Vision and Pattern Recognition (CVPR), 2010 IEEE Conference on, pages 787\u2013794. IEEE, 2010.\n[14] Alexander Rakhlin and Karthik Sridharan. Online learning with predictable sequences. arXiv preprint arXiv:1208.3728, 2012.\n[15] Shai Shalev-Shwartz. Online learning and online convex optimization. Foundations and Trends R\u00a9 in Machine Learning, 4(2):107\u2013194, 2011.\n[16] Nati Srebro, Karthik Sridharan, and Ambuj Tewari. On the universality of online mirror descent. In Advances in neural information processing systems, pages 2645\u20132653, 2011.\n[17] Martin Zinkevich. Online convex programming and generalized infinitesimal gradient ascent. 2003.\nA Proofs\nProof. (Proposition 1) Observe that\nargmin x\u2208\u2126\nB\u03c8(x, y)\n= argmin x\u2208\u2126\n\u03c8(x) \u2212 \u03c8(y)\u2212 \u3008\u2207\u03c8(y), x\u2212 y\u3009\n= argmin x\u2208\u2126\n\u03c8(x) \u2212 \u3008\u2207\u03c8(y), x\u3009\n= argmin x\u2208\u2126\n\u03c8(x) \u2212 \u3008\u2207\u03c8(u)\u2212 g, x\u3009\n= argmin x\u2208\u2126\n\u3008g, x\u3009+ \u03c8(x) \u2212 \u03c8(u)\u2212 \u3008\u2207\u03c8(u), x\u2212 u\u3009\n= argmin x\u2208\u2126\n\u3008g, x\u3009+ B\u03c8(x, u).\nProof. (Lemma 3) Since r0:t is 1-strongly convex w.r.t. \u2016\u00b7\u2016(t) we have\nBr0:t(x\u0302t, xt+1) = r0:t(x\u0302t)\u2212 r0:t(xt+1)\u2212 \u3008\u2207r0:t(xt+1), x\u0302t \u2212 xt+1\u3009 \u2265 12 \u2016x\u0302t \u2212 xt+1\u2016 2 (t) ,\nand\nBr0:t(xt+1, x\u0302t) = r0:t(xt+1)\u2212 r0:t(x\u0302t)\u2212 \u3008\u2207r0:t(x\u0302t), xt+1 \u2212 x\u0302t\u3009 \u2265 12 \u2016xt+1 \u2212 x\u0302t\u2016 2 (t) .\nAdding these two bounds, we obtain\n\u2016x\u0302t \u2212 xt+1\u20162(t) \u2264 \u3008\u2207r0:t(x\u0302t)\u2212\u2207r0:t(xt+1), x\u0302t \u2212 xt+1\u3009. (12)\nSuppose yt+1 and y\u0302t satisfy the conditions \u2207r0:t(yt+1) = \u2207r0:t(xt) \u2212 gt and \u2207r0:t(y\u0302t) = \u2207r0:t(xt) \u2212 g\u0303t respectively. Then by applying Proposition 1 to the updates in (3) and (2) of Algorithm 1, we obtain\nxt+1 = argmin x\u2208\u2126\nBr0:t(x, yt+1)\nx\u0302t = argmin x\u2208\u2126\nBr0:t(x, y\u0302t).\nBy applying the first order optimality condition for the above two optimization statements, we have\n\u3008\u2207r0:t(xt+1)\u2212\u2207r0:t(yt+1), x\u0302t \u2212 xt+1\u3009 \u2265 0 \u3008\u2207r0:t(x\u0302t)\u2212\u2207r0:t(y\u0302t), xt+1 \u2212 x\u0302t\u3009 \u2265 0,\nrespectively. Combining these two bounds, we obtain\n\u3008\u2207r0:t(y\u0302t)\u2212\u2207r0:t(yt+1), x\u0302t \u2212 xt+1\u3009 \u2265 \u3008\u2207r0:t(x\u0302t)\u2212\u2207r0:t(xt+1), x\u0302t \u2212 xt+1\u3009.\nBy combining the above result with (12), we obtain\n\u2016x\u0302t \u2212 xt+1\u20162(t) \u2264 \u3008\u2207r0:t(y\u0302t)\u2212\u2207r0:t(yt+1), x\u0302t \u2212 xt+1\u3009 \u2264 \u2016\u2207r0:t(y\u0302t)\u2212\u2207r0:t(yt+1)\u2016(t),\u2217 \u2016x\u0302t \u2212 xt+1\u2016(t) ,\nby a generalized Cauchy-Schwartz inequality. Dividing both sides by \u2016x\u0302t \u2212 xt+1\u2016(t), we have\n\u2016x\u0302t \u2212 xt+1\u2016(t) \u2264 \u2016\u2207r0:t(y\u0302t)\u2212\u2207r0:t(yt+1)\u2016(t),\u2217 = \u2016(\u2207r0:t(xt)\u2212 g\u0303t)\u2212 (\u2207r0:t(xt)\u2212 gt)\u2016(t),\u2217 = \u2016gt \u2212 g\u0303t\u2016(t),\u2217 .\nProof. (Corollary 7) By letting \u03b7 = D\u221a 2 for the given sequence of regularizers, we get r0:t (x) = 1 2\u03b7 \u2016x\u2016 2 Q1:t . Since r0:t is 1-strongly convex w.r.t. 1\u221a \u03b7 \u2016\u00b7\u2016Q1:t , we have \u2016\u00b7\u2016(t) = 1\u221a \u03b7 \u2016\u00b7\u2016Q1:t and \u2016\u00b7\u2016(t),\u2217 = \u221a \u03b7 \u2016\u00b7\u2016Q\u22121 1:t . By Theorem 4 the regret bound of Algorithm 1 with this choice of regularizer sequence can be given as follows\nT \u2211\nt=1\nft(x\u0302t)\u2212 ft(x\u2217) \u2264 12 T \u2211\nt=1\n\u2016gt \u2212 g\u0303t\u20162(t),\u2217 + T \u2211\nt=1\nBrt(x\u2217, xt).\nConsider\n1 2\nT \u2211\nt=1\n\u2016gt \u2212 g\u0303t\u20162(t),\u2217\n= 12\nT \u2211\nt=1\n\u03b7 \u2016gt \u2212 g\u0303t\u20162Q\u22121 1:t\n= \u03b7\n2\nT \u2211\nt=1\n(gt \u2212 g\u0303t)Q\u221211:t (gt \u2212 g\u0303t) T\n= \u03b7\n2\nT \u2211\nt=1\n(gt \u2212 g\u0303t) ( \u03b32I +G2:t )\u2212 12 (gt \u2212 g\u0303t)T\n\u2264 \u03b7 2\nT \u2211\nt=1\n(gt \u2212 g\u0303t) (G2:t+1)\u2212 1 2 (gt \u2212 g\u0303t)T\n\u2264 \u03b7 tr ( G 1 2 2:T+1 )\n\u2264 \u03b7 tr ( ( \u03b32I +G2:T ) 1 2 )\n= \u03b7 tr (Q1:T ) ,\nwhere the first inequality is due to the facts that \u03b32I < Gt+1 and A < B < 0 \u21d2 A 1 2 < B 1 2 and B\u22121 < A\u22121,\nthe second inequality is due to the fact that \u2211T t=1 a T t\n(\n\u2211t s=1 asa T s )\u221212 at \u2264 tr ( \u2211T t=1 ata T t ) (see Lemma 10\nfrom [6]), and the third inequality is due to the fact that \u03b32I < GT+1. Also observing that\nT \u2211\nt=1\nBrt(x\u2217, xt)\n=\nT \u2211\nt=1\n1\n2\u03b7 \u2016x\u2217 \u2212 xt\u20162Qt\n\u2264 1 2\u03b7\nT \u2211\nt=1\n\u2016x\u2217 \u2212 xt\u201622 \u03bbmax (Qt)\n\u2264 1 2\u03b7\nT \u2211\nt=1\n\u2016x\u2217 \u2212 xt\u201622 tr (Qt)\n\u2264 1 2\u03b7\nT \u2211\nt=1\nD2tr (Qt)\n= D2\n2\u03b7 tr (Q1:T ) .\ncompletes the proof.\nB Mirror Descent with \u03b2-convex losses\nGiven a convex set \u2126 \u2286 Rn and \u03b2 > 0, a function f : \u2126 \u2192 R is \u03b2-convex, if for all x, y \u2208 \u2126\nf(x) \u2265 f(y) + \u3008g, x\u2212 y\u3009+ \u03b2 \u2016x\u2212 y\u20162ggT , g \u2208 \u2202f(y).\nAlgorithm 4 Adaptive Mirror Descent\nInput: regularizers r0 \u2265 0. Initialize: x1 = 0 \u2208 \u2126. for t = 1 to T do Predict xt, observe ft, and incur loss ft(xt). Compute gt \u2208 \u2202ft(xt). Construct rt s.t. r0:t is 1-strongly convex w.r.t. \u2016\u00b7\u2016(t). Update\nxt+1 = argmin x\u2208\u2126\n\u3008gt, x\u3009+ Br0:t(x, xt). (13)\nend for\nLemma 14. The instantaneous linear regret of Algorithm 4 w.r.t. any x\u2217 \u2208 \u2126 can be bounded as follows\n\u3008xt \u2212 x\u2217, gt\u3009 \u2264 Br0:t(x\u2217, xt)\u2212 Br0:t(x\u2217, xt+1) + 12 \u2016gt\u2016 2 (t),\u2217 .\nProof. By the first-order optimality condition for (13) we have,\n\u3008x\u2212 xt+1, gt +\u2207r0:t(xt+1)\u2212\u2207r0:t(xt)\u3009 \u2265 0 (14)\nConsider\n\u3008xt \u2212 x\u2217, gt\u3009 = \u3008xt+1 \u2212 x\u2217, gt\u3009+ \u3008xt \u2212 xt+1, gt\u3009 \u2264 \u3008x\u2217 \u2212 xt+1,\u2207r0:t(xt+1)\u2212\u2207r0:t(xt)\u3009+ \u3008xt \u2212 xt+1, gt\u3009 = Br0:t(x\u2217, xt)\u2212 Br0:t(x\u2217, xt+1)\u2212 Br0:t(xt+1, xt) + \u3008xt \u2212 xt+1, gt\u3009 \u2264 Br0:t(x\u2217, xt)\u2212 Br0:t(x\u2217, xt+1)\u2212 Br0:t(xt+1, xt) + 12 \u2016xt \u2212 xt+1\u2016 2 (t) + 1 2 \u2016gt\u2016 2 (t),\u2217 \u2264 Br0:t(x\u2217, xt)\u2212 Br0:t(x\u2217, xt+1) + 12 \u2016gt\u2016 2 (t),\u2217 ,\nwhere the first inequality is due to (14), the second equality is due to the fact that \u3008\u2207\u03c8(a)\u2212\u2207\u03c8(b), c\u2212 a\u3009 = B\u03c8(c, b)\u2212B\u03c8(c, a)\u2212B\u03c8(a, b), the second inequality is due to the fact that \u3008a, b\u3009 \u2264 \u2016a\u2016 \u2016b\u2016\u2217 \u2264 12 \u2016a\u2016 2 + 12 \u2016b\u2016 2 \u2217, and the third inequality is due to the 1-strong convexity of r0:t w.r.t. \u2016\u00b7\u2016(t).\nTheorem 15. Let ft is \u03b2t-convex, \u2200t \u2208 [T ]. If rt\u2019s are given by\nrt(x) = \u2016x\u20162ht , where h0 = In\u00d7n and ht = \u03b2tgtg T t for t \u2265 1, (15)\nthen the regret of Algorithm 4 w.r.t. any x\u2217 \u2208 \u2126 is bounded by T \u2211\nt=1\nft(xt)\u2212 ft(x\u2217) \u2264 1\n4\nT \u2211\nt=1\n\u2016gt\u20162h\u22121 0:t + \u2016x\u2217 \u2212 x1\u201622 .\nProof. For the choice of regularizer sequence {rt} given by (15), we have r0:t(x) = \u2016x\u20162h0:t and Br0:t(x, y) = 1 2 (\u221a 2 \u2016x\u2212 y\u2016h0:t )2 . Since r0:t is 1-strongly convex w.r.t. \u221a 2 \u2016\u00b7\u2016h0:t , we have \u2016\u00b7\u2016(t) = \u221a 2 \u2016\u00b7\u2016h0:t and \u2016\u00b7\u2016(t),\u2217 = 1\u221a 2 \u2016\u00b7\u2016h\u22121 0:t .\nFor any x\u2217 \u2208 \u2126\nft(xt)\u2212 ft(x\u2217)\n\u2264 \u3008gt, xt \u2212 x\u2217\u3009 \u2212 \u03b2t \u2016x\u2217 \u2212 xt\u20162gtgTt \u2264 Br0:t(x\u2217, xt)\u2212 Br0:t(x\u2217, xt+1) + 12 \u2016gt\u2016 2 (t),\u2217 \u2212 \u2016x\u2217 \u2212 xt\u2016 2 \u03b2tgtg T t = \u2016x\u2217 \u2212 xt\u20162h0:t \u2212 \u2016x \u2217 \u2212 xt+1\u20162h0:t \u2212 \u2016x \u2217 \u2212 xt\u20162ht + 1 2 \u2016gt\u2016 2 (t),\u2217 ,\nwhere the first inequality is due to the \u03b2t-convexity of ft(\u00b7), and the second inequality is due to Lemma 14. By summing all the instantaneous regrets we get\nT \u2211\nt=1\nft(xt)\u2212 T \u2211\nt=1\nft(x \u2217)\n\u2264 T \u2211\nt=1\n{\n\u2016x\u2217 \u2212 xt\u20162h0:t \u2212 \u2016x \u2217 \u2212 xt\u20162h0:t\u22121 \u2212 \u2016x \u2217 \u2212 xt\u20162ht } + \u2016x\u2217 \u2212 x1\u20162h0 \u2212 \u2016x \u2217 \u2212 xT+1\u20162h0:T + 1 2\nT \u2211\nt=1\n\u2016gt\u20162(t),\u2217\n\u2264 \u2016x\u2217 \u2212 x1\u201622 + 1\n4\nT \u2211\nt=1\n\u2016gt\u20162h\u22121 0:t .\nNow instead of running Algorithm 4 on the observed sequence of ft\u2019s, we use the modified sequence of loss functions of the form f\u0303t(x) := ft(x) + \u03bbtg(x), \u03bbt \u2265 0, (16) where g(x) is 1-convex. By following the proof of Theorem 15 for the modified sequence of losses given by (16) we obtain the following corollary.\nTheorem 16. Let g(x) be a 1-convex function, A2 = sup x\u2208\u2126 g(x) and B = sup x\u2208\u2126 \u2016g\u2032(x)\u2016(g\u2032(x)g\u2032(x)T )\u22121 . Also let ft be \u03b2t-convex (\u03b2t \u2265 0), \u2200t \u2208 [T ]. If Algorithm 4 is performed on the modified functions f\u0303t\u2019s with the regularizers rt\u2019s given by\nrt(x) = \u2016x\u20162ht , where h0 = In\u00d7n, and ht = \u03b2tgtg T t + \u03bbtg \u2032(xt)g \u2032(xt) T , for t \u2265 1, (17)\nthen for any sequence \u03bb1, ..., \u03bbT \u2265 0, we get T \u2211\nt=1\nft(xt)\u2212 ft(x\u2217) \u2264 ( A2 + B2\n2\n)\n\u03bb1:T + 1 2\nT \u2211\nt=1\n\u2016gt\u20162h\u22121 0:t + \u2016x\u2217 \u2212 x1\u201622 .\nProof. Since ft is \u03b2t-convex and g is 1-convex, for any x \u2217 \u2208 \u2126 we have\n{ft(xt) + \u03bbtg(xt)} \u2212 {ft(x\u2217) + \u03bbtg(x\u2217)} = ft(xt)\u2212 ft(x\u2217) + \u03bbt {g(xt)\u2212 g(x\u2217)} \u2264 \u3008gt, xt \u2212 x\u2217\u3009 \u2212 \u03b2t \u2016x\u2217 \u2212 xt\u20162gtgTt + \u03bbt { \u3008g\u2032(xt), xt \u2212 x\u2217\u3009 \u2212 \u2016x\u2217 \u2212 xt\u20162g\u2032(xt)g\u2032(xt)T } = \u3008gt + \u03bbtg\u2032(xt), xt \u2212 x\u2217\u3009 \u2212 \u2016x\u2217 \u2212 xt\u20162\u03b2tgtgTt +\u03bbtg\u2032(xt)g\u2032(xt)T .\nBy following the similar steps from the proof of Theorem 15 we get\nT \u2211\nt=1\nft(xt) + \u03bbtg(xt)\u2212 { T \u2211\nt=1\nft(x \u2217) + \u03bbtg(x \u2217)\n}\n\u2264 1 4\nT \u2211\nt=1\n\u2016gt + \u03bbtg\u2032(xt)\u20162h\u22121 0:t + \u2016x\u2217 \u2212 x1\u201622 .\nBy using the facts that \u2016x+ y\u20162A \u2264 2 \u2016x\u2016 2 A+2 \u2016y\u2016 2 A, h0:t < ht < \u03bbtg \u2032(xt)g\u2032(xt) T , and \u2016g\u2032(xt)\u2016(g\u2032(xt)g\u2032(xt)T )\u22121 \u2264 B, we have\nT \u2211\nt=1\nft(xt) + \u03bbtg(xt)\u2212 { T \u2211\nt=1\nft(x \u2217) + \u03bbtg(x \u2217)\n}\n\u2264 12 T \u2211\nt=1\n{\n\u2016gt\u20162h\u22121 0:t + \u03bb2t \u2016g\u2032(xt)\u2016 2 h \u22121 0:t\n}\n+ \u2016x\u2217 \u2212 x1\u201622\n\u2264 12 T \u2211\nt=1\n{\n\u2016gt\u20162h\u22121 0:t + \u03bb2t \u2016g\u2032(xt)\u2016 2 (\u03bbtg\u2032(xt)g\u2032(xt)T ) \u22121\n}\n+ \u2016x\u2217 \u2212 x1\u201622\n\u2264 12 T \u2211\nt=1\n\u2016gt\u20162h\u22121 0:t\n+ B2\n2 \u03bb1:T + \u2016x\u2217 \u2212 x1\u201622 .\nBy neglecting the g(xt) terms in the L.H.S. and using the fact that g(x \u2217) \u2264 A2 we get\nT \u2211\nt=1\nft(xt) \u2264 T \u2211\nt=1\nft(x \u2217) +A2\u03bb1:T + 1 2\nT \u2211\nt=1\n\u2016gt\u20162h\u22121 0:t + \u2016x\u2217 \u2212 x1\u201622 + B2 2 \u03bb1:T .\nBut we cannot apply Lemma 3.1 from [9] for the above regret bound to obtain a near optimal closed form solution to \u03bbt. One could employ an optimization algorithm to find the optimal \u03bbt."}], "references": [{"title": "Mirror descent and nonlinear projected subgradient methods for convex optimization", "author": ["Amir Beck", "Marc Teboulle"], "venue": "Operations Research Letters,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2003}, {"title": "On the generalization ability of on-line learning algorithms", "author": ["Nicolo Cesa-Bianchi", "Alex Conconi", "Claudio Gentile"], "venue": "Information Theory, IEEE Transactions on,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2004}, {"title": "Online optimization with gradual variations", "author": ["Chao-Kai Chiang", "Tianbao Yang", "Chia-Jung Lee", "Mehrdad Mahdavi", "Chi-Jen Lu", "Rong Jin", "Shenghuo Zhu"], "venue": null, "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2012}, {"title": "Proximal regularization for online and batch learning", "author": ["Chuong B Do", "Quoc V Le", "Chuan-Sheng Foo"], "venue": "In Proceedings of the 26th Annual International Conference on Machine Learning,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2009}, {"title": "Adaptive subgradient methods for online learning and stochastic optimization", "author": ["John Duchi", "Elad Hazan", "Yoram Singer"], "venue": "The Journal of Machine Learning Research,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2011}, {"title": "Logarithmic regret algorithms for online convex optimization", "author": ["Elad Hazan", "Amit Agarwal", "Satyen Kale"], "venue": "Machine Learning,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2007}, {"title": "Extracting certainty from uncertainty: Regret bounded by variation in costs", "author": ["Elad Hazan", "Satyen Kale"], "venue": "Machine learning,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2010}, {"title": "Adaptive online gradient descent", "author": ["Elad Hazan", "Alexander Rakhlin", "Peter L Bartlett"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2007}, {"title": "On the generalization ability of online strongly convex programming algorithms", "author": ["ShamMKakade", "Ambuj Tewari"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2009}, {"title": "Analysis techniques for adaptive online learning", "author": ["H Brendan McMahan"], "venue": "arXiv preprint arXiv:1403.3465,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2014}, {"title": "Accelerating optimization via adaptive prediction", "author": ["Mehryar Mohri", "Scott Yang"], "venue": "arXiv preprint arXiv:1509.05760,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2015}, {"title": "Online-batch strongly convex multi kernel learning", "author": ["Francesco Orabona", "Luo Jie", "Barbara Caputo"], "venue": "In Computer Vision and Pattern Recognition (CVPR),", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2010}, {"title": "Online learning with predictable sequences", "author": ["Alexander Rakhlin", "Karthik Sridharan"], "venue": "arXiv preprint arXiv:1208.3728,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2012}, {"title": "Online learning and online convex optimization", "author": ["Shai Shalev-Shwartz"], "venue": "Foundations and Trends R  \u00a9 in Machine Learning,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2011}, {"title": "On the universality of online mirror descent", "author": ["Nati Srebro", "Karthik Sridharan", "Ambuj Tewari"], "venue": "In Advances in neural information processing systems,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2011}], "referenceMentions": [{"referenceID": 13, "context": "[15] provides a detailed analysis of the OCO problem setting and discusses several applications of this paradigm - online regression, prediction with expert advice, and online ranking.", "startOffset": 0, "endOffset": 4}, {"referenceID": 4, "context": "[6] replaces the single static regularizer in the standard mirror descent update 1 by a data dependent sequence of regularizers.", "startOffset": 0, "endOffset": 3}, {"referenceID": 2, "context": "[4, 14] have shown that an optimistic prediction g\u0303t+1 of the next gradient gt+1 at time t can be used to achieve tighter regret bounds in the case where the loss functions are generated by some predictable process e.", "startOffset": 0, "endOffset": 7}, {"referenceID": 12, "context": "[4, 14] have shown that an optimistic prediction g\u0303t+1 of the next gradient gt+1 at time t can be used to achieve tighter regret bounds in the case where the loss functions are generated by some predictable process e.", "startOffset": 0, "endOffset": 7}, {"referenceID": 5, "context": "When the loss functions are uniformly exp-concave or strongly convex, O(logT ) regret bounds are achieved with appropriate choice of regularizers [7, 9].", "startOffset": 146, "endOffset": 152}, {"referenceID": 7, "context": "When the loss functions are uniformly exp-concave or strongly convex, O(logT ) regret bounds are achieved with appropriate choice of regularizers [7, 9].", "startOffset": 146, "endOffset": 152}, {"referenceID": 7, "context": "In that case [9] proposed an algorithm that can adapt to the convexity of the loss functions, and achieves O( \u221a T ) regret bounds for arbitrary convex losses and O(logT ) for uniformly strong-convex losses.", "startOffset": 13, "endOffset": 16}, {"referenceID": 9, "context": "Even though [11] has shown equivalence between mirror descent and a variant of FTRL (namely FTRLProx) algorithms with adaptive regularizers, no such mapping is available between optimistic mirror descent and optimistic FTRL updates.", "startOffset": 12, "endOffset": 16}, {"referenceID": 10, "context": "Recently [12] have combined adaptive FTRL and optimistic FTRL updates to achieve tighter regret bounds for sparse and predictable sequences.", "startOffset": 9, "endOffset": 13}, {"referenceID": 10, "context": "We obtained a factor of \u221a 2 improvement in the regret bound compared to that of [12], because in their regret analysis they could not apply the strong FTRL lemma from [11].", "startOffset": 80, "endOffset": 84}, {"referenceID": 9, "context": "We obtained a factor of \u221a 2 improvement in the regret bound compared to that of [12], because in their regret analysis they could not apply the strong FTRL lemma from [11].", "startOffset": 167, "endOffset": 171}, {"referenceID": 7, "context": "In this case we achieve tighter logarithmic regret bound without a priori knowledge about the lower bound on the strong-convexity parameters, in similar spirit of [9].", "startOffset": 163, "endOffset": 166}, {"referenceID": 14, "context": "The following proposition [16, 1] is handy in deriving explicit update rules for mirror descent algorithms that we have presented in this work.", "startOffset": 26, "endOffset": 33}, {"referenceID": 0, "context": "The following proposition [16, 1] is handy in deriving explicit update rules for mirror descent algorithms that we have presented in this work.", "startOffset": 26, "endOffset": 33}, {"referenceID": 2, "context": "3 Adaptive and Optimistic Mirror Descent When the sequences are predictable [4] proposed that making an optimistic prediction of xt+1 at time t itself using the optimistic prediction g\u0303t+1(g1, .", "startOffset": 76, "endOffset": 79}, {"referenceID": 6, "context": "prediction choices of g\u0303t+1 = 1 t \u2211t s=1 gs and g\u0303t+1 = gt, we obtain the variance bound [8] and the path length bound [4] respectively.", "startOffset": 89, "endOffset": 92}, {"referenceID": 2, "context": "prediction choices of g\u0303t+1 = 1 t \u2211t s=1 gs and g\u0303t+1 = gt, we obtain the variance bound [8] and the path length bound [4] respectively.", "startOffset": 119, "endOffset": 122}, {"referenceID": 2, "context": "The following lemma is a generalization of Lemma 5 from [4] for time varying norms, which gives a bound on the instantaneous linear regret of Algorithm 1.", "startOffset": 56, "endOffset": 59}, {"referenceID": 2, "context": "The following lemma is already proven by [4] and used in the proof of our Theorem 8.", "startOffset": 41, "endOffset": 44}, {"referenceID": 2, "context": "First we recover the non-adaptive optimistic mirror descent [4] and its regret bound as a corollary of Theorem 4.", "startOffset": 60, "endOffset": 63}, {"referenceID": 4, "context": "By leveraging the techniques from [6] we can adaptively construct regularizers based on the observed data.", "startOffset": 34, "endOffset": 37}, {"referenceID": 4, "context": "The regret bound obtained in the above corollary is much tighter than that of [6] and [4] when the sequence of loss functions are sparse and predictable.", "startOffset": 78, "endOffset": 81}, {"referenceID": 2, "context": "The regret bound obtained in the above corollary is much tighter than that of [6] and [4] when the sequence of loss functions are sparse and predictable.", "startOffset": 86, "endOffset": 89}, {"referenceID": 4, "context": "Even when the loss sequence is completely unpredictable, the above bound is not much worse than a constant factor of the bound in [6].", "startOffset": 130, "endOffset": 133}, {"referenceID": 7, "context": "1 from [9] for the Optimistic Mirror Descent, this inherits the properties mentioned there such as : rt\u2019s can be chosen without the knowledge of uniform lower bound on Ht\u2019s, and O(logT ) bound can be achieved even when some Ht \u2264 0 as long as H1:t t > 0.", "startOffset": 7, "endOffset": 10}, {"referenceID": 3, "context": "Now instead of running Algorithm 1 on the observed sequence of ft\u2019s, we use the modified sequence of loss functions of the form f\u0303t(x) := ft(x) + \u03bbt 2 \u2016x\u2212 x\u0302t\u2016 , \u03bbt \u2265 0, (8) which is already considered in [5] for the non-optimistic mirror descent case.", "startOffset": 205, "endOffset": 208}, {"referenceID": 3, "context": "Also note that \u2202f\u0303t(x\u0302t) = \u2202ft(x\u0302t) because the gradient of \u2016x\u2212 x\u0302t\u2016 is 0 when evaluated at x\u0302t [5].", "startOffset": 96, "endOffset": 99}, {"referenceID": 7, "context": "Based on the online balancing heuristic approach [9], the positive solution of 2R\u03bb1:t = 3 \u2016gt\u2212g\u0303t\u20162\u2217 H1:t+\u03bb1:t is given by \u03bbt = \u221a", "startOffset": 49, "endOffset": 52}, {"referenceID": 7, "context": "1 from [9] we obtain the following regret bound for Algorithm 2.", "startOffset": 7, "endOffset": 10}], "year": 2016, "abstractText": "Online Convex Optimization plays a key role in large scale machine learning. Early approaches to this problem were conservative, in which the main focus was protection against the worst case scenario. But recently several algorithms have been developed for tightening the regret bounds in easy data instances such as sparsity, predictable sequences, and curved losses. In this work we unify some of these existing techniques to obtain new update rules for the cases when these easy instances occur together. First we analyse an adaptive and optimistic update rule which achieves tighter regret bound when the loss sequence is sparse and predictable. Then we explain an update rule that dynamically adapts to the curvature of the loss function and utilizes the predictable nature of the loss sequence as well. Finally we extend these results to composite losses.", "creator": "LaTeX with hyperref package"}}}