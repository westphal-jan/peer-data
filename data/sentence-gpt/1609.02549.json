{"id": "1609.02549", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "8-Sep-2016", "title": "Learning Lexical Entries for Robotic Commands using Crowdsourcing", "abstract": "Robotic commands in natural language usually contain lots of spatial descriptions which are semantically similar but syntactically different. Mapping such syntactic variants into semantic concepts that can be understood by robots is challenging due to the high flexibility of natural language expressions. To tackle this problem, we collect robotic commands for navigation and manipulation tasks using crowdsourcing and computer vision. These computations are performed by robots through a combination of three steps: a user passes a new task to a robot. A user enters the command in an unedited or automated fashion, and proceeds to perform the task, with a given button pressed. A robot enters a controlled location in the robot's control room. A user clicks a button to initiate an activation of the robot to activate an activation of the robot to activate the robot.\n\n\n\n\nA robot enters an unedited or automated fashion, and proceeds to perform the task, with a given button pressed. A user clicks a button to initiate an activation of the robot to activate the robot to activate the robot to activate the robot to activate the robot to activate the robot to activate the robot to activate the robot to activate the robot to activate the robot to activate the robot to activate the robot to activate the robot to activate the robot to activate the robot to activate the robot to activate the robot to activate the robot to activate the robot to activate the robot to activate the robot to activate the robot to activate the robot to activate the robot to activate the robot to activate the robot to activate the robot to activate the robot to activate the robot to activate the robot to activate the robot to activate the robot to activate the robot to activate the robot to activate the robot to activate the robot to activate the robot to activate the robot to activate the robot to activate the robot to activate the robot to activate the robot to activate the robot to activate the robot to activate the robot to activate the robot to activate the robot to activate the robot to activate the robot to activate the robot to activate the robot to activate the robot to activate the robot to activate the robot to activate the robot to activate the robot to activate the robot to activate the robot to activate the robot to activate the robot to activate the robot to activate the robot to activate the robot to activate the robot to activate the robot to activate the robot to activate the robot to activate the robot to activate the robot to activate the robot to activate the robot to activate the robot to activate the robot to activate the robot to activate the robot to activate the robot to activate the robot to activate the robot to activate the robot to activate", "histories": [["v1", "Thu, 8 Sep 2016 19:51:47 GMT  (116kb,D)", "https://arxiv.org/abs/1609.02549v1", null], ["v2", "Fri, 9 Sep 2016 17:29:27 GMT  (111kb,D)", "http://arxiv.org/abs/1609.02549v2", null], ["v3", "Tue, 1 Nov 2016 15:21:43 GMT  (117kb,D)", "http://arxiv.org/abs/1609.02549v3", null]], "reviews": [], "SUBJECTS": "cs.CL", "authors": ["junjie hu", "jean oh", "anatole gershman"], "accepted": false, "id": "1609.02549"}, "pdf": {"name": "1609.02549.pdf", "metadata": {"source": "CRF", "title": "Learning Lexical Entries for Robotic Commands using Crowdsourcing", "authors": ["Junjie Hu", "Jean Oh", "Anatole Gershman"], "emails": ["junjieh@cs.cmu.edu,", "jeanoh@nrec.ri.cmu.edu,", "anatoleg@cs.cmu.edu"], "sections": [{"heading": "Introduction", "text": "Natural language provides an efficient way for untrained human to instruct a robot to perform collaborative tasks, e.g., navigation and manipulation. However, learning to interpret the meaning of natural language commands is a challenging task (Dukes 2014; Perera and Allen 2013; Chen and Mooney 2011), especially when the robot has little or no prior knowledge of the phrasal expressions in natural language. Due to high flexibility of natural language, it is non-trivial for a robot to cover all the phrasal expressions in natural language when its interpretation module is initially built.\nPopular crowdsourcing platforms such as Amazon Mechanical Turk, provide a fast and cheap way to collect interactive data from participants in a wide range of different communities. Hence, simulating the human machine interaction process for information extraction on crowdsourcing platforms has attracted lots of research interests (Nguyen, Wallace, and Lease 2015; Hladka\u0301, Hana, and Luksova\u0301 2014; Goldberg, Wang, and Kraska 2013). To encourage the diversity of robotic commands, we simulate the interactive process between a robot and various untrained users on Amazon Mechanical Turk, and collect robotic commands during the process. We further apply a phrase-based machine translation model to mapping natural language command to a robotic language that can be understood by a robot.\nCopyright c\u00a9 2016, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved."}, {"heading": "Phrase-based Machine Translation Model", "text": "To tackle the problem of translating natural language commands to language that can be understood by robots, we first define a robot language that consists of predefined key concepts in the robotic task domains. For example, in the navigation task domain, we define the following key concepts.\n\u2022 Action:= navigate \u2022 Object:= traffic barrel | building | car \u2022 Relation:= left | right | front | back Each robot language command can be deterministically constructed by a combination of key concepts in the task domains. See Figure 1 for an illustration. We then adapt a phrase-based machine translation model to translate robotic commands from natural language to the robot language. For the phrase-based machine translation model, the key component is the extracted phrase table that stores several lexical entries. For a particular input (source-language) sentence s = s1 \u00b7 \u00b7 \u00b7 sn, each lexical entry is defined as a tuple (b, e, r), specifying that the span sb \u00b7 \u00b7 \u00b7 se in the sourcelanguage sentence can be translated as the target-language string r. For each lexical entry p = (b, e, r), we estimate a score g(p) \u2208 R that measures the likelihood of translating the span to the target language string by relative frequency under the translation model. For a given lexicon entry p, b(p), e(p), r(p) denote its three components respectively. A derivation y of a source-language sentence is defined as a finite sequence of phrases, p1, p2 \u00b7 \u00b7 \u00b7 pL. For any derivation y, r(y) refers to the translation sentence constructed by concatenating the strings r(p1), r(p2), \u00b7 \u00b7 \u00b7 r(pL). For a sourcelanguage sentence s, we denote Y(s) as a set of possible derivations of s.\nBased on the above notations, we aim to extract lexical entries from parallel textual corpus collected on crowdsourcing platforms, and seek the optimal derivation y\u2217 using beam search for the maximum derivation score f(y\u2217) among all possible derivations Y(s) under a phrase-based translation model.\nIn Equation 1, the score f(y) of a derivation y consists of three parts: (1) h(r(y)) is the log-probability of the target string r(y) under a smoothed trigram language model; (2) g(pk) is the score of pk under a translation model; (3) |e(pk)+1\u2212 b(pk+1)| is the distortion penalty for reordering\nar X\niv :1\n60 9.\n02 54\n9v 3\n[ cs\n.C L\n] 1\nN ov\n2 01\n6\nword alignments between source and target languages.\nf(y) = whh(r(y)) + wg L\u2211 k=1 g(pk) + wd L\u22121\u2211 k=1 |e(pk) + 1\u2212 b(pk+1)|\n(1)\nwhere wh, wg and wd are the weights of the scores given by the language model, the translation model and the distortion penalty respectively. Hence the optimal derivation of a source-language sentence s can be obtained by argmaxy\u2208Y(s) f(y)."}, {"heading": "Experiment", "text": "We present the process of collecting experimental data on Amazon Mechanical Turk, a popular crowdsourcing platform, and extract parallel lexical entries using Moses (Koehn et al. 2007), a machine translation tool."}, {"heading": "Stimulation and Data Collection", "text": "By showing an image that depicts the behaviour of a robot, a turker is first asked to give a command in English (denoted as s) that clearly indicates the spatial information between objects in the environment for a robot. Next, the turker is shown some robotic concepts in several drop-down lists, and asked to select the correct robotic concepts that can be used to construct a robotic command (denoted as r) for the same image. Finally we simulate the scenario where the robot can actively ask for a paraphrase sentence (denoted as t) of the robotic command r in order to help it understand s. Totally we collect 88 tuples of (s, t, r) for navigation task and 120 tuples of (s, t, r) tuples for manipulation task."}, {"heading": "Phrasal Lexicon Extraction and Translation", "text": "To investigate the possibility of using paraphrase sentences to enhance the phrase-based machine translation, we first use Moses to extract parallel phrases between s and r. Then we use Moses to extract parallel phrases between t and r. Table 1 shows the total number of extracted lexical entries when we translate from s to r and from t to r. Comparing the second column with the third one in Table 1, we observe that more lexical entries are extracted from parallel sentences between t and r than those between s and r. This convinces our idea that turkers usually paraphrase natural language commands that are more semantically closed to the robot language commands after the robotic concepts are shown to them. Table 2 shows some lexical entries extracted from natural language commands t paired with robot language commands r. We observe that the extracted lexical entries capture the similarity between source-language phrases and target-language phrases, thus enabling many-toone mapping from syntactic variants in natural language to unique robotic concepts.\nBy optimizing the objective function in Equation 1, we generate the translated robot language sentence using the\nextracted lexical entries. In Table 3, we show two translation results of the examples used in Figure 1. In the first result, the machine translation model can successfully translate the natural language command to the correct robot language command. While in the second result, the translation is not completely correct because the natural language command contains the detail steps for the navigation task. Mapping detail descriptions to highly abstract robot concepts requires more sophisticated semantic reasoning over the natural language. We leave it as our future work."}, {"heading": "Conclusion", "text": "In this paper, we simulate the human robot communication on Amazon Mechanical Turk and collect robotic commands for navigation and manipulation tasks using crowdsourcing. We further investigate the possibility of bridging the gap between natural language command and robot language command using paraphrasing. We will conduct our future work in several challenging aspects. First, lexical entries extracted from different but similar robotic tasks can be shared across tasks. Second, machine teaching by paraphrasing can be integrated with active learning techniques. Robots can perform reasoning over the confusing phrases and actively ask their human partners for paraphrasing."}, {"heading": "Acknowledgments", "text": "This work was conducted in part through collaborative participation in the Robotics Consortium sponsored by the U.S Army Research Laboratory under the Collaborative Technology Alliance Program, Cooperative Agreement W911NF-10-2-0016, and in part by ONR under MURI grant \u201cReasoning in Reduced Information Spaces\u201d (no. N0001409-1-1052). The views and conclusions contained in this document are those of the authors and should not be interpreted as representing the official policies, either expressed or implied, of the Army Research Laboratory of the U.S. Government. The U.S. Government is authorized to reproduce and distribute reprints for Government purposes notwithstanding any copyright notation herein."}], "references": [{"title": "Learning to interpret natural language navigation instructions from observations", "author": ["Chen", "D.L. Mooney 2011] Chen", "R.J. Mooney"], "venue": "In Proceedings of the TwentyFifth AAAI Conference on Artificial Intelligence,", "citeRegEx": "Chen et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Chen et al\\.", "year": 2011}, {"title": "CASTLE: crowd-assisted system for text labeling and extraction", "author": ["Wang Goldberg", "S.L. Kraska 2013] Goldberg", "D.Z. Wang", "T. Kraska"], "venue": "In Proceedings of the First AAAI Conference on Human Computation and Crowdsourcing,", "citeRegEx": "Goldberg et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Goldberg et al\\.", "year": 2013}, {"title": "Crowdsourcing in language classes can help natural language processing", "author": ["Hana Hladk\u00e1", "B. Luksov\u00e1 2014] Hladk\u00e1", "J. Hana", "I. Luksov\u00e1"], "venue": "In Proceedings of the Seconf AAAI Conference on Human Computation and Crowdsourcing,", "citeRegEx": "Hladk\u00e1 et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Hladk\u00e1 et al\\.", "year": 2014}, {"title": "Moses: Open source toolkit for statistical machine translation", "author": ["Koehn"], "venue": "In Proceedings of the 45th annual meeting of the ACL on interactive", "citeRegEx": "Koehn,? \\Q2007\\E", "shortCiteRegEx": "Koehn", "year": 2007}, {"title": "Combining crowd and expert labels using decision theoretic active learning", "author": ["Wallace Nguyen", "A.T. Lease 2015] Nguyen", "B.C. Wallace", "M. Lease"], "venue": "In Proceedings of the Third AAAI Conference on Human Computation and Crowdsourcing,", "citeRegEx": "Nguyen et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Nguyen et al\\.", "year": 2015}, {"title": "SALL-E: situated agent for language learning", "author": ["Perera", "I.E. Allen 2013] Perera", "J.F. Allen"], "venue": "In Proceedings of the Twenty-Seventh AAAI Conference on Artificial Intelligence, July", "citeRegEx": "Perera et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Perera et al\\.", "year": 2013}], "referenceMentions": [], "year": 2016, "abstractText": "Robotic commands in natural language usually contain various spatial descriptions that are semantically similar but syntactically different. Mapping such syntactic variants into semantic concepts that can be understood by robots is challenging due to the high flexibility of natural language expressions. To tackle this problem, we collect robotic commands for navigation and manipulation tasks using crowdsourcing. We further define a robot language and use a generative machine translation model to translate robotic commands from natural language to robot language. The main purpose of this paper is to simulate the interaction process between human and robots using crowdsourcing platforms, and investigate the possibility of translating natural language to robot language with paraphrases.", "creator": "LaTeX with hyperref package"}}}