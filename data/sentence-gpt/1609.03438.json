{"id": "1609.03438", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "12-Sep-2016", "title": "Reactive Multi-Context Systems: Heterogeneous Reasoning in Dynamic Environments", "abstract": "In this paper we introduce reactive multi-context systems (rMCSs), a framework for reactive reasoning in the presence of heterogeneous knowledge sources. In particular, we show how to integrate data streams into multi-context systems (MCSs) and how to model the dynamics of the systems, based on two types of bridge rules. We illustrate how several typical problems arising in the context of stream reasoning can be handled using our framework. Reasoning based on multiple knowledge sources that need to be integrated faces the problem of potential inconsistencies. We discuss various methods for handling inconsistencies, with a special focus on non-existence of equilibria. In particular, we show how methods developed for managed MCSs can be generalized to rMCSs. We also study the issue of nondeterminism in rMCSs. One way of avoiding nondeterminism is by applying an alternative, skeptical semantics. We show how such a semantics, called well-founded semantics, can be defined for rMCSs, and what the effect of using this semantics instead of the original one is. We investigate the complexity of various reasoning problems related to rMCSs. Finally, we discuss related work, with a special focus on two of the most relevant approaches w.r.t. stream reasoning, namely LARS and STARQL. The main point of the paper is that this paper aims to present a new paradigm for non-existence of a certain state and that in the context of a stream-based system, one must avoid all such state conflicts.\n\n\n\n\n\n\nThe paper describes two concepts that can be used to explain both stream and RMS. The first one is to apply RMS to a system that has some degree of dependence on a specific system. RMS is a network (defined by a given protocol, and is a type-specific type) and consists of many elements, including information flows, memory, and network connections. The second is to describe a system that can be managed in a particular way by one or more other, and provide solutions to a particular problem. As these solutions can only be considered with respect to certain properties (e.g., information, memory, network connections), they can be used to solve problems that are not a real problem in an otherwise closed system.\n\nAs an example, the paper discusses how RMS can be used in a given system:\nRMS can be defined through RMS, which is a state-independent approach:\nRMS is a network (defined by", "histories": [["v1", "Mon, 12 Sep 2016 15:12:00 GMT  (333kb,D)", "https://arxiv.org/abs/1609.03438v1", null], ["v2", "Fri, 9 Dec 2016 11:20:56 GMT  (335kb,D)", "http://arxiv.org/abs/1609.03438v2", null]], "reviews": [], "SUBJECTS": "cs.LO cs.AI", "authors": ["gerhard brewka", "stefan ellmauthaler", "ricardo gon\\c{c}alves", "matthias knorr", "jo\\~ao leite", "j\\\"org p\\\"uhrer"], "accepted": false, "id": "1609.03438"}, "pdf": {"name": "1609.03438.pdf", "metadata": {"source": "CRF", "title": "Reactive Multi-Context Systems: Heterogeneous Reasoning in Dynamic Environments", "authors": ["Gerhard Brewka", "Stefan Ellmauthaler", "Ricardo Gon\u00e7alves", "Matthias Knorr", "Jo\u00e3o Leite", "J\u00f6rg P\u00fchrer"], "emails": ["brewka@informatik.uni-leipzig.de", "ellmauthaler@informatik.uni-leipzig.de", "rjrg@fct.unl.pt", "mkn@fct.unl.pt", "jleite@fct.unl.pt", "puehrer@informatik.uni-leipzig.de"], "sections": [{"heading": null, "text": "In this paper, we introduce reactive multi-context systems (rMCSs), a framework for reactive reasoning in the presence of heterogeneous knowledge sources. In particular, we show how to integrate data streams into multi-context systems (MCSs) and how to model the dynamics of the systems, based on two types of bridge rules. We illustrate how several typical problems arising in the context of stream reasoning can be handled using our framework. Reasoning based on multiple knowledge sources that need to be integrated faces the problem of potential inconsistencies. We discuss various methods for handling inconsistencies, with a special focus on non-existence of equilibria. In particular, we show how methods developed for managed MCSs can be generalized to rMCSs. We also study the issue of nondeterminism in rMCSs. One way of avoiding nondeterminism is by applying an alternative, skeptical semantics. We show how such a semantics, called well-founded semantics, can be defined for rMCSs, and what the effect of using this semantics instead of the original one is. We investigate the complexity of various reasoning problems related to rMCSs. Finally, we discuss related work, with a special focus on two of the most relevant approaches w.r.t. stream reasoning, namely LARS and STARQL.\nKeywords: Heterogeneous knowledge, Stream reasoning, Knowledge integration, Reactive systems, Dynamic systems"}, {"heading": "1. Introduction", "text": "The wide and increasing availability of machine-processable data and knowledge \u2013 fueled by initiatives such as the Semantic Web, Linked Open Data, and the Internet of Things, among others \u2013 has prepared the ground and called for a new class of dynamic,\n^This paper combines and unifies the results of [11] and [28], two papers by different subsets of the authors describing independent adaptations of multi-context systems for dynamic environments. The approach developed here generalizes these earlier approaches and substantially improves on the presentation of the underlying concepts.\nEmail addresses: brewka@informatik.uni-leipzig.de (Gerhard Brewka), ellmauthaler@informatik.uni-leipzig.de (Stefan Ellmauthaler), rjrg@fct.unl.pt (Ricardo Gonc\u0327alves), mkn@fct.unl.pt (Matthias Knorr), jleite@fct.unl.pt (Joa\u0303o Leite), puehrer@informatik.uni-leipzig.de (Jo\u0308rg Pu\u0308hrer)\nDecember 12, 2016\nar X\niv :1\n60 9.\n03 43\n8v 2\n[ cs\n.L O\n] 9\nD ec\nrich, knowledge-intensive applications. Such new applications require automated reasoning based on the integration of several heterogeneous knowledge bases \u2013 possibly overlapping, independently developed, and written in distinct languages with different semantic assumptions \u2013 together with data/event streams produced by sensors and detectors, to support automation and problem-solving, to enforce traceable and correct decisions, and to facilitate the internalization of relevant dynamic data and knowledge.\nConsider, for example, a scenario where Dave, an elderly person suffering from dementia, lives alone in an apartment equipped with various sensors, e.g., smoke detectors, cameras, and body sensors measuring relevant body functions (e.g., pulse, blood pressure, etc.). An assisted living application in such a scenario could leverage the information continuously received from the sensors, together with Dave\u2019s medical records stored in a relational database, a biomedical health ontology with information about diseases, their symptoms and treatments, represented in some description logic, some action policy rules represented as a non-monotonic logic program, to name only a few, and use it to detect relevant events, suggest appropriate action, and even raise alarms, while keeping a history of relevant events and Dave\u2019s medical records up to date, thus allowing him to live on his own despite his condition. For example, after detecting that Dave left the room while preparing a meal, the system could alert him to the situation in case he does not return soon, or even turn the stove off in case it detects that Dave fell asleep, not wanting to wake him up because his current treatment/health status values rest over immediate nutrition. Naturally, if Dave is not gone long enough, and no sensor shows any potential problems (smoke, gas, fire, etc.), then the system should seamlessly take no action. Another illustrative example would be a situation where the system observes that Dave\u2019s smart watch is indicating a high heart rate (tachycardia), in which case it would request Dave to measure his blood pressure (hypertension) \u2013 calling for assistance if Dave ignores the request \u2013 and, based on the measurements, determine whether to raise an alarm, calling an ambulance for example, or whether the readings are caused by some infection already under treatment or a decongestant that Dave recently took, in which case nothing would need to be done.\nThe requirements posed by novel applications such as the one just described, together with the availability of a vast number of knowledge bases \u2013 written using many different formalisms \u2013 and streams of data/events produced by sensors/detectors, has led modern research in knowledge representation and reasoning to face two fundamental problems: dealing with the integration of heterogeneous data and knowledge, and dealing with the dynamics of such novel knowledge-based systems.\nIntegration. The first problem stems from the availability of knowledge bases written in many different languages and formats developed over the last decades, from the rather basic ones, such as relational databases or the more recent triple-stores, to the more expressive ones, such as ontology languages (e.g., description logics), temporal and modal logics, non-monotonic logics, or logic programs under answer set semantics, to name just a few. Each of these formalisms was developed for different purposes and with different design goals in mind. Whereas some of these formalisms could be combined to form a new, more expressive formalism, with features from its constituents \u2013 such as dl-programs [15] and Hybrid MKNF [34] which, to different extent, combine\ndescription logics and logic programs under answer set semantics \u2013, in general this is simply not feasible, either due to the mismatch between certain assumptions underlying their semantics, or because of the high price to pay, often in terms of complexity, sometimes even in terms of decidability. It is nowadays widely accepted that there simply is no such thing as a single universal, general purpose knowledge representation language.\nWhat seems to be needed is a principled way of integrating knowledge expressed in different formalisms.\nMulti-context systems (MCSs) provide a general framework for this kind of integration. The basic idea underlying MCSs is to leave the diverse formalisms and knowledge bases untouched, and to use so-called bridge rules to model the flow of information among different parts of the system. An MCS consists of reasoning units \u2013 called contexts for historical reasons [26] \u2013 where each unit is equipped with a collection of bridge rules. In a nutshell, the bridge rules allow contexts to \u201clisten\u201d to other contexts, that is to take into account beliefs held in other contexts.\nBridge rules are similar to logic programming rules (including default negation), with an important difference: they provide means to access other contexts in their bodies. Bridge rules not only allow for a fully declarative specification of the information flow, but they also allow information to be modified instead of being just passed along as is. Using bridge rules we may translate a piece of information into the language/format of another context, pass on an abstraction of the original information, leaving out unnecessary details, select or hide information, add conclusions to a context based on the absence of information in another one, and even use simple encodings of preferences among parent contexts.\nHistorically, MCSs went through several development steps until they reached their present form. Advancing work in [25, 33] aiming to integrate different inference systems, monotonic heterogeneous multi-context systems were defined in [26], with reasoning within as well as across monotonic contexts. The first, still somewhat limited attempts to include non-monotonic reasoning were done in [38] and [12], where default negation in the rules is used to allow for reasoning based on the absence of information from a context.\nThe non-monotonic MCSs of [9] substantially generalize previous approaches, by accommodating heterogeneous and both monotonic and non-monotonic contexts, hence capable of integrating, among many others, \u201ctypical\u201d monotonic logics like description logics or temporal logics, and non-monotonic formalisms like Reiter\u2019s default logic, logic programs under answer set semantics, circumscription, defeasible logic, or theories in autoepistemic logic. The semantics of nonmonotonic MCSs is defined in terms of equilibria: a belief set for each context that is acceptable for its knowledge base augmented by the heads of its applicable bridge rules.\nMore recently, the so-called managed MCSs (mMCSs) [10] addressed a limitation of MCSs in the way they integrate knowledge between contexts. Instead of simply adding the head of an applicable bridge rule to the context\u2019s knowledge base, which could cause some inconsistency, mMCSs allow for operations other than addition, such as, for instance, revision and deletion, hence dealing with the problem of consistency management within contexts.\nDynamics. The second problem stems from the shift from static knowledge-based systems that assume a one-shot computation, usually triggered by a user query, to open and dynamic scenarios where there is a need to react and evolve in the presence of incoming information.\nIndeed, traditional knowledge-based systems \u2013 including the different variants of MCSs mentioned above \u2013 focus entirely on static situations, which is the right thing for applications such as for instance expert systems, configuration or planning problems, where the available background knowledge changes rather slowly, if at all, and where all that is needed is the solution of a new instance of a known problem. However, the new kinds of applications we consider are becoming more and more important, and these require continuous online reasoning, including observing and reacting to events.\nThere are some examples of systems developed with the purpose of reacting to streams of incoming information, such as Reactive ASP [23, 22], C-SPARQL [6], Ontology Streams [31] and ETALIS [3], to name only a few. However, they are very limited in the kind of knowledge that can be represented, and the kind of reasoning allowed, hence unsuitable to address the requirements of the applications we envision, such as those that need to integrate heterogeneous knowledge bases. Additionally, reacting to the streams of incoming information is only part of the dynamic requirements of our applications. In many cases, the incoming information is processed only once, perhaps requiring complex reasoning using various knowledge bases to infer the right way to react, and does not have to be dealt with again \u2013 e.g., concluding that nothing needs to be done after determining that the tachycardia is caused by the decongestant recently taken by Dave. In other cases, it is important that these observations not only influence the current reaction of the system \u2013 do nothing in the previous example \u2013 but, at the same time, be able to change the knowledge bases in a more permanent way, i.e., allowing for the internalization of knowledge. For example, relevant observations regarding Dave\u2019s health status should be added to his medical records, such as for example that he had an episode of tachycardia caused by a decongestant, and, in the future, maybe even revise such episode if it is found that Dave had forgotten to take the decongestant after all. Other more sophisticated changes in the knowledge bases include, for example, an update to the biomedical health ontology whenever new treatments are found, the revision of the policy rules whenever some exceptions are found, etc. EVOLP [2] extends logic programming under answer set semantics with the possibility to specify its evolution, through successive updates, in reaction to external observations. It is nevertheless limited to a single knowledge representation formalism and to a single operation (update).\nIn this paper, we aim to address these challenges. We develop a system that allows us to integrate heterogeneous knowledge bases with streams of incoming information and to use them for continuous online reasoning, reacting, and evolving the knowledge bases by internalizing relevant knowledge. To this end, we introduce reactive MultiContext Systems (rMCSs). These systems build upon mMCSs and thus provide their functionality for integrating heterogeneous knowledge sources, admitting also relevant operations on knowledge bases. In addition, rMCSs can handle continuous streams of input data. Equilibria remain the fundamental underlying semantic notion, but the focus now lies on the dynamic evolution of the systems. In a nutshell, given an initial configuration of knowledge bases, that is, an initial knowledge base for each context,\na specific input stream will lead to a corresponding stream of equilibria, generated by respective updates of the knowledge bases. Contrary to standard MCSs which possess only one type of bridge rules modeling the information flow which needs to be taken into account when equilibria are computed (or the operations that need to be applied in case of mMCSs), rMCSs have an additional, different type of bridge rules, distinguished by the occurrence of the operator next in the head. These rules are used to specify how the configuration of knowledge bases evolves whenever an equilibrium was computed.\nThe paper is organized as follows. In Section 2, we introduce reactive MCSs, our framework for reactive reasoning in the presence of heterogeneous knowledge sources. In particular, we show how to integrate data streams into mMCSs and how to model the dynamics of our systems, based on two types of bridge rules. Section 3 illustrates how several typical problems arising in the context of stream reasoning can be handled using our framework. Reasoning based on multiple knowledge sources that need to be integrated faces the problem of potential inconsistencies. Section 4 discusses various methods for handling inconsistencies, with a special focus on non-existence of equilibria. In particular, we show how methods developed for mMCSs can be generalized to rMCSs. Nondeterminism in rMCSs is discussed in Section 5. One way of avoiding nondeterminism is by applying an alternative, skeptical semantics. We show how such a semantics, called well-founded semantics, can be defined for rMCSs, and what the effect of using this semantics instead of the original one is. The complexity of various problems related to rMCSs is investigated in Section 6. Section 7 discusses related work, with a special focus on two of the most relevant approaches w.r.t. stream reasoning, namely LARS (Logic-based framework for Analyzing Reasoning over Streams) [7] and STARQL [36]. Section 8 concludes and points out directions for future work."}, {"heading": "2. Reactive Multi-Context Systems", "text": "Reactive multi-context systems (rMCSs) make use of basic ideas from managed multi-context systems (mMCSs) [10] which extend multi-context systems (MCSs) as defined by Brewka and Eiter [9] by management capabilities. In particular, similar to mMCSs, we will make use of a management function and bridge rules that allow for conflict resolution between contexts as well as a fine-grained declarative specification of the information flow between contexts. To not unnecessarily burden the reader with repetetive material on these common components, we abstain from recalling the details of mMCSs first. It will be clear from the presentation when new concepts/ideas specific to rMCSs will be presented.\n2.1. Specifying the Components of an rMCS\nSimilar as for previous notions of MCSs, we build on an abstract notion of a logic, which is a triple L = \u3008KB ,BS ,acc\u3009, where KB is the set of admissible knowledge bases of L, which are sets whose elements are called knowledge base formulas; BS is the set of possible belief sets, where elements in belief sets are called beliefs; and\nacc : KB \u2192 2BS is a function describing the semantics of L by assigning to each knowledge base a set of acceptable belief sets.1\nExample 1. We illustrate how different formalisms can be represented by the notion of a logic. The logics presented below will serve as blueprints for the logics we use in examples throughout the paper. First, consider the case of classical propositional logic. Given a propositional signature \u03a3, we denote by F the set of all well-formed propositional formulas over \u03a3. To represent entailment in classical propositional logic over signature \u03a3, we consider the logic Lp = \u3008KBp,BSp,accp\u3009, such that the admissible knowledge bases are given by the set KBp = 2F . Since propositional logic aims at modeling ideal rational reasoning, we identify the set of possible belief sets BSp with the set of deductively closed sets of formulas over \u03a3. Finally, accp maps every kb \u2208 KBp to {E}, where E is the set of formulas entailed by kb.\nQuite similar in spirit are description logics (DLs) as (commonly decidable) fragments of first-order logic [5]. Given a DL language L, we consider the logic Ld = \u3008KBd,BSd,accd\u3009 where KBd is the set of all well-formed DL knowledge bases over L, also called ontologies, BSd is the set of deductively closed subsets of L, and accd maps every kb \u2208 KBd to {E}, where E is the set of formulas in L entailed by kb.\nAs an example for a non-deterministic formalism, consider logic programs under the answer set semantics [24]. Given a set of ground, i.e., variable-free, atoms A, we consider the logic La = \u3008KBa,BSa,acca\u3009, such that KBa is the set of all logic programs over A. The set of possible belief sets is given by the set BSa = 2A of possible answer sets and the function acca maps every logic program to the set of its answer sets.\nGiven a set E of entries, a simple logic for storing elements from E can be realized by the logic Ls = \u3008KBs,BS s,accs\u3009, such that KBs = BS s = 2E , and accs maps every set E\u2032 \u2286 E to {E\u2032}. Such Ls can, e.g., be used to represent a simple database logic. We will call a logic of this type a storage logic.\nIn addition to a logic that captures language and semantics of a formalism to be integrated in an rMCS, a context also describes how a knowledge base belonging to the logic can be manipulated. To this end, we make use of a management function similar as in managed multi-context systems [10].\nDefinition 1 (Context). A context is a triple C = \u3008L,OP ,mng\u3009 where\n\u2022 L = \u3008KB ,BS ,acc\u3009 is a logic,\n\u2022 OP is a set of operations,\n\u2022 mng : 2OP \u00d7KB \u2192 KB is a management function.\n1To ease readability, throughout the paper, we will often use the following convention when writing symbols: single entities are lower-case, while sets of entities and structures with different components are upper-case; in addition, sequences of those are indicated in sans serif, while notions with a temporal dimension are written in calligraphic letters (only upper-case, such as S or I); finally, operators and functions are bold.\nFor an indexed context Ci we will write Li = \u3008KB i,BS i,acci\u3009, OP i, and mngi to denote its components. Note that we leave the exact nature of the operations in OP unspecified. They can be seen as mere labels that determine how the management function should manipulate the knowledge base: we use subsets OP \u2032 of OP as the first argument of the management function that maps a knowledge base to an updated version depending on the presence or absence of operations in OP \u2032. Thus, it is the management function that implements the semantics of the operations. We use a deterministic management function rather than a non-deterministic one as used in mMCS [10]. Note that it is straightforward to adapt our definitions to use non-deterministic management functions as well. However, as they are not essential to our approach, we here refrain from doing so to keep notation simpler.\nExample 2. Consider the assisted living scenario from the Introduction and remember that we target a system that recognizes potential threats caused by overheating of the stove in Dave\u2019s kitchen. We use the context Cst to monitor the stove. Its logic Lst is a storage logic taking E = {pw, tm(cold), tm(hot)} as the set of entries, representing the stove\u2019s power status (on if pw is present, and off otherwise) and a qualitative value for its temperature (cold/hot). At all times, the current temperature and power state of the stove should be stored in a knowledge base over Lst. Thus, the context provides the operations\nOPst = {setPower(off ), setPower(on), setTemp(cold), setTemp(hot)}\nto update the information in the knowledge base. Before defining the management function we need to clarify what we want this function to achieve. We assume the existence of a single temperature sensor constantly providing a measurement which triggers exactly one of the setTemp operations. For this reason, there is no need for the management function to care about persistence of the temperature value, or about conflicting information. The power information, on the other hand, is based on someone toggling a switch, so we definitely need persistence of the fluent pw.\nThe semantics of the operations is thus given, for OP \u2032 \u2286 OPst, by the management function mngst(OP \u2032, kb) =\n{pw | setPower(on) \u2208 OP \u2032\u2228 (pw \u2208 kb \u2227 setPower(off ) 6\u2208 OP \u2032)}\u222a {tm(t) |setTemp(t) \u2208 OP \u2032}.\nAs discussed above, the function simply inserts the current qualitative temperature value. For the power, it ensures that the stove is considered on whenever it is switched on, and also when it is not being switched off and already considered on in the given knowledge base kb. The second alternative implements persistence. Note that whenever both conflicting setPower operations are in OP \u2032, setPower(on) \u201cwins\u201d, that is, pw will be in the knowledge base. This is justified by the application: the damage of, say, unnecessarily turning off the electricity is a lot smaller than that of overlooking a potential overheating of the stove.\nAssume we have a knowledge base kb = {tm(cold)}. Then, an update with the set OP = {setPower(on), setTemp(hot)} of operations would result in the knowledge base mngst(OP , kb) = {pw, tm(hot)}.\nContexts exchange information by manipulating their associated knowledge bases using the management function. The central device for that is given by bridge rules that are rules similar in spirit to those in logic programming and that determine which operations from OP i to apply to kbi in a context Ci. In this work, we are interested in systems composed of contexts whose behavior may not only depend on other contexts, but also on input from the outside. Like communication between contexts, also external information is incorporated by means of bridge rules. To keep the approach as abstract as possible, all we require is that inputs are elements of some formal input language IL. Moreover, we allow for situations where input comes from different sources with potentially different input languages and thus consider tuples \u3008IL1, . . . , ILk\u3009 of input languages.\nDefinition 2 (Bridge Rule). Let C = \u3008C1, . . . ,Cn\u3009 be a tuple of contexts and IL = \u3008IL1, . . . , ILk\u3009 a tuple of input languages. A bridge rule for Ci over C and IL, i \u2208 {1, . . . , n}, is of the form\nop\u2190a1, . . . , aj ,not aj+1, . . . ,not am (1)\nsuch that op = op or op = next(op) for op \u2208 OP i, j \u2208 {0, . . . ,m}, and every atom a`, ` \u2208 {1, . . . ,m}, is one of the following:\n\u2022 a context atom c:b with c\u2208{1, . . . , n} and b \u2208 B for some B \u2208 BS c, or\n\u2022 an input atom s::b with s \u2208 {1, . . . , k} and b \u2208 ILs.\nFor a bridge rule r of the form (1) hd(r) denotes op, the head of r, while bd(r) = {a1, . . . , aj ,not aj+1, . . . ,not am} is the body of r. A literal is either an atom or the default negation of an atom, and we also differentiate between context literals and input literals.\nRoughly, a set of bridge rules for Ci describes which operations to apply to its knowledge base kbi depending on whether currently available beliefs and external inputs match the literals in the body. We define and discuss their precise semantics later in Section 2.2. Bridge rules can be seen as the glue that binds the contexts in an rMCS together. Thus, we are now ready to define reactive multi-context systems.\nDefinition 3 (Reactive Multi-Context System). A reactive Multi-Context System (rMCS) is a tuple M = \u3008C, IL,BR\u3009, where\n\u2022 C = \u3008C1, . . . ,Cn\u3009 is a tuple of contexts;\n\u2022 IL = \u3008IL1, . . . , ILk\u3009 is a tuple of input languages;\n\u2022 BR = \u3008BR1, . . . ,BRn\u3009 is a tuple such that each BRi, i \u2208 {1, . . . , n}, is a set of bridge rules for Ci over C and IL.\nExample 3. We continue by using context Cst from Example 2 as the single context of the rMCS Mex3 = \u3008\u3008Cst\u3009, \u3008ILex3\u3009, \u3008BRex3\u3009\u3009.2 The input language ILex3 = {switch} is used to report whether the switch for changing the power state of the stove has been turned. The bridge rules in BRex3 are given by\nnext(setPower(on))\u2190 ex3::switch,not st:pw. next(setPower(off ))\u2190 ex3::switch, st:pw.\nand react to switching the stove on or off: depending on the current power state of the stove that is stored in a knowledge base associated to Cst, whenever the switch is activated, the bridge rules derive an update of the knowledge base where the power state is reversed.\n2.2. Reacting to External Inputs - Semantics of rMCSs To define the semantics of rMCSs, we first focus on the static case of a single time instant, and only subsequently introduce the corresponding dynamic notions for reacting to inputs changing over time.\nWe start with the evaluation of bridge rules, for which we need to know current beliefs and current external information. The former is captured by the notion of a belief state denoted by a tuple of belief sets \u2013 one for each context \u2013 similar as in previous work on multi-context systems.\nDefinition 4 (Belief State). Let M = \u3008\u3008C1, . . . ,Cn\u3009, IL,BR\u3009 be an rMCS. Then, a belief state for M is a tuple B = \u3008B1, . . . , Bn\u3009 such that Bi \u2208 BS i, for each i \u2208 {1, . . . , n}. We use BelM to denote the set of all beliefs states for M .\nIn addition, to also capture the current external information, we introduce the notion of an input.\nDefinition 5 (Input). Let M = \u3008C, \u3008IL1, . . . , ILk\u3009,BR\u3009 be an rMCS. Then an input for M is a tuple I = \u3008I1, . . . , Ik\u3009 such that Ii \u2286 ILi, i \u2208 {1, . . . , k}. The set of all inputs for M is denoted by InM .\nWe are now ready to define when literals (in bridge rule bodies) are satisfied.\nDefinition 6 (Satisfaction of Literals). Let M = \u3008C, IL,BR\u3009 be an rMCS such that C = \u3008C1, . . . ,Cn\u3009 and IL = \u3008IL1, . . . , ILk\u3009. Given an input I = \u3008I1, . . . , Ik\u3009 for M and a belief state B = \u3008B1, . . . , Bn\u3009 for M , we define the satisfaction of literals given I and B as:\n\u2022 \u3008I,B\u3009 |= a` if a` is of the form c:b and b \u2208 Bc;\n\u2022 \u3008I,B\u3009 |= a` if a` is of the form s::b and b \u2208 Is;\n\u2022 \u3008I,B\u3009 |= not a` if \u3008I,B\u3009 6|= a`.\n2Throughout the paper we sometimes use labels (such as st in Cst) instead of numerical indices in our examples.\nLet r be a bridge rule for Ci over C and IL. Then\n\u2022 \u3008I,B\u3009 |= bd(r) if \u3008I,B\u3009 |= l for every l \u2208 bd(r).\nIf \u3008I,B\u3009 |= bd(r), we say that r is applicable under I and B. The operations encoded in the heads of applicable bridge rules in an rMCS determine which knowledge base updates should take place. We collect them in two disjoint sets.\nDefinition 7 (Applicable Bridge Rules). Let M = \u3008C, IL,BR\u3009 be an rMCS such that C = \u3008C1, . . . ,Cn\u3009 and BR = \u3008BR1, . . . , BRn\u3009. Given an input I for M and a belief state B for M , we define, for each i \u2208 {1, . . . , n}, the sets\n\u2022 appnowi (I,B) = {hd(r) | r \u2208 BRi, \u3008I,B\u3009 |= bd(r),hd(r) \u2208 OP i};\n\u2022 appnexti (I,B) = {op | r \u2208 BRi, \u3008I,B\u3009 |= bd(r),hd(r) = next(op)}.\nIntuitively, the operations in appnowi (I,B) are used for computing temporary changes that influence the semantics of an rMCS for a single point in time. The operations in appnexti (I,B) on the other hand are used for changing knowledge bases over time. They are not used for computing the current semantics but are applied in the next point in time depending on the current semantics. This continuous change of knowledge bases over time is the reason why, unlike in previous work on MCSs, we do not consider knowledge bases as part of the contexts to which they are associated but store them in a separate configuration structure defined next.\nDefinition 8 (Configuration of Knowledge Bases). LetM = \u3008C, IL,BR\u3009 be an rMCS such that C = \u3008C1, . . . ,Cn\u3009. A configuration of knowledge bases for M is a tuple KB = \u3008kb1, . . . , kbn\u3009 such that kbi \u2208 KB i, for each i \u2208 {1, . . . , n}. We use ConM to denote the set of all configurations of knowledge bases for M .\nThe semantics of an rMCS for a single time instant is given in terms of its equilibria.\nDefinition 9 (Equilibrium). Let M = \u3008\u3008C1, . . . ,Cn\u3009, IL,BR\u3009 be an rMCS, KB = \u3008kb1, . . . , kbn\u3009 a configuration of knowledge bases for M , and I an input for M . Then, a belief state B = \u3008B1, . . . , Bn\u3009 for M is an equilibrium of M given KB and I if, for each i \u2208 {1, . . . , n}, we have that\nBi \u2208 acci(kb\u2032), where kb\u2032 = mngi(appnowi (I,B), kbi).\nExample 4. Consider rMCSMex3 from Example 3 and the configuration KB = \u3008kbst\u3009 of knowledge bases for Mex3 with kbst = \u2205, representing that the stove is turned off. Moreover, consider the input I = \u3008{switch}\u3009 for Mex3 and the belief state B = \u3008\u2205\u3009 for Mex3. As both bridge rules in BRex3 use the next operator, we have appnowst (I,B) = \u2205 and consequently, following the definition of the management function mngst in Example 2, kbst remains unchanged, i.e., mngst(app now st (I,B), kbst) = kbst. Thus, accst(mngst(app now st (I,B), kbst)) = {\u2205}. It follows that B is an equilibrium ofMex3 given KB and I.\nBased on an equilibrium at the current time instant, we can compute an updated configuration of knowledge bases using the update function as introduced in the following.\nDefinition 10 (Update Function). Let M = \u3008C, IL,BR\u3009 be an rMCS such that C = \u3008C1, . . . ,Cn\u3009, KB = \u3008kb1, . . . , kbn\u3009 a configuration of knowledge bases for M , I an input for M , and B a belief state for M . Then, the update function for M is defined as updM (KB, I,B) = \u3008kb \u2032 1, . . . , kb \u2032 n\u3009, such that, for each i \u2208 {1 . . . , n}, kb\u2032i = mngi(app next i (I,B), kbi).\nWith all this in place, we can finally show how an rMCS behaves in the presence of external information that changes over time. For this purpose, we assume that an rMCS receives data in a stream of inputs, i.e., an input for each time instant, and we represent individual time instants by natural numbers. These can be interpreted as logical time instants that do not necessarily represent specific physical time points. In particular, we do not assume that every pair of consecutive natural numbers represents equidistant physical time spans.\nDefinition 11 (Input Stream). Let M = \u3008C, IL,BR\u3009 be an rMCS such that IL = \u3008IL1, . . . , ILk\u3009. An input stream for M (until \u03c4 ) is a function I : [1..\u03c4 ] \u2192 InM where \u03c4 \u2208 N \u222a {\u221e}.\nWe will conveniently omit the term \u201cuntil \u03c4\u201d whenever the limit of the stream is irrelevant. Conversely, we will provide an explicit \u03c4 , when we are only interested in the first \u03c4 time instants or when we want to state that the input stream is infinite (in case \u03c4 = \u221e). Clearly, an input stream for M until \u03c4 also fully determines an input stream for M until \u03c4 \u2032 for every 1 \u2264 \u03c4 \u2032 < \u03c4 .\nFor any stream, we commonly represent the functional notation by a superscript, e.g., given an input stream I and t \u2208 [1..\u03c4 ], we will use It to denote I(t), i.e., the input \u3008I1, . . . , Ik\u3009 forM at time t. We also term stream the restriction of an input stream I to a single input language ILi, which can be understood as a function Ii : [1..\u03c4 ] \u2192 2ILi that is fully determined by I.\nNote that It encapsulates (input) data for every input language of M . Hence, we assume that, at every time instant, we have information from every external source of the rMCS. This synchronous approach is required since the evaluation of a bridge rule may depend on the availability of information from multiple streams. One possibility for modeling external sources that do not continuously provide information is setting Its to the empty set for representing a lack of input from the source with language ILs at time t.\nThe semantics of an rMCS over time is given by its equilibria streams for a given initial configuration of knowledge bases and an input stream for the system.\nDefinition 12 (Equilibria Stream). Let M = \u3008C, IL,BR\u3009 be an rMCS, KB a configuration of knowledge bases for M , and I an input stream for M until \u03c4 where \u03c4 \u2208 N \u222a {\u221e}. Then, an equilibria stream of M given KB and I is a function B : [1..\u03c4 ]\u2192 BelM such that\n\u2022 Bt is an equilibrium of M given KBt and It, where KBt is inductively defined as\n\u2013 KB1 = KB \u2013 KBt+1 = updM (KBt, It,Bt).\nWe will also refer to the function KB : [1..\u03c4 ]\u2192 ConM as the configurations stream of M given KB, I, and B.\nNote that the limit \u03c4 of an equilibria stream is aligned with that of the given input stream. Following the definition, it is easy to see that if we have an equilibria stream B of M given KB and I, then the substream of B of size \u03c4 \u2032, with \u03c4 \u2032 \u2264 \u03c4 , is an equilibria stream of M given KB and I \u2032, where I \u2032 is the substream of I of size \u03c4 \u2032. This implies that, conversely, each extension of the input stream can only lead to equilibria streams that extend those obtained given the original input stream.\nExample 5. Reconsider rMCS Mex3, KB, and B from Example 4, as well as an input stream I until 3 with I1 = \u3008{switch}\u3009, I2 = \u3008\u2205\u3009, and I3 = \u3008{switch}\u3009. There is an equilibria stream B of Mex3 given KB and I. Note that the input I1 coincides with input I from Example 4. As B is the only equilibrium of Mex3 given KB and I, we have that B1 = B.\nAs we have appnextst (I,B) = {setPower(on)}, the update function provides the following configuration of knowledge bases for time instant 2 (with KB1 = KB):\nKB2 = updMex3(KB 1, I1,B1) = \u3008mngst(appnextst (I,B), kb)\u3009 = \u3008{pw}\u3009.\nThus, switching the power state at time 1 leads to an updated knowledge base indicating that the stove is on at time 2. The table in Fig. 1 summarizes the equilibria stream and the configurations stream given KB and I. Note that, due to the choice of logic and since all bridge rules use the next operator, equilibria necessarily coincide with the corresponding knowledge base at each time step.\n2.3. Rule Schemata\nFor convenience, we will represent sets of bridge rules using rule schemata. A rule schema is just shorthand for all its instances. Intuitively, it is a parametrized bridge rule and each instance is a bridge rule. It will be convenient to use not only parameters, but also conditions - called instantiation directives - to additionally constrain the set of instances. We will use them, e.g., for allowing arithmetic operations and comparison relations in bridge rules.\nGiven a tuple C = \u3008C1, . . . ,Cn\u3009 of contexts and a tuple IL of input languages, let A be the alphabet of symbols occurring in all possible bridge rules for all contexts Ci \u2208 {C1, . . . ,Cn} over C and IL. We call a string over A an instantiation term for C and IL. Then, an instantiation directive for C and IL is a predicate id(T1, . . . , To), where T1, . . . , To are strings over P \u222a A and where P = {P1, . . . , Pk} is a set of symbols (called parameters) such that P \u2229 A = \u2205. A rule schema R for C and IL with parameters P is of the form\nH \u2190A1, . . . , Aj ,not Aj+1, . . . ,not Am, D1, . . . , Ds (2)\nsuch that H , A1, ..., Am are strings over P \u222aA and Di is an instantiation directive for each 1 \u2264 i \u2264 s.\nA bridge rule r = op \u2190 a1, . . . , aj ,not aj+1, . . . ,not am for Ci over C and IL is an instance of a rule schema R for C and IL with parameters P of the form (2) if r results from H \u2190 A1, . . . , Aj ,not Aj+1, . . . ,not Am by a uniform substitution \u03c3 of parameters with instantiation terms, and for each Di = id(T1, . . . , To), 1 \u2264 i \u2264 s, the predicate id(T1\u03c3, . . . , To\u03c3) holds.\nWe adopt the convention from logic programming that parameters start with uppercase letters. Moreover, we will denote instantiation directives representing comparison and arithmetic operations using standard infix notation. For example, the rule schema\nadd(tmp(S ,X ))\u2190S::temp = X, 45 \u2264 X \u2264 65. (3)\nexpresses that temperature values received on stream S should be added to the knowledge base (tagged with the stream index) if they lie between 45\u25e6C and 65\u25e6C.\nNote that we assume that instantiation directives only evaluate to true if their arguments are substituted by appropriate instantiation terms, for example when X is substituted by numeric values in the temperature example.\nExample 6. The rMCS Mex6 = \u3008\u3008Cst\u3009, \u3008ILst\u3009, \u3008BRst\u3009\u3009 is obtained from the rMCS Mex3 by considering ILst = ILex3\u222a{tmp(T ) | T \u2208 Z} and by adding further bridge rules for context Cst, i.e., BRst extends BRex3 (with st replacing ex3 in input literals) by the instances of the following bridge rule schemata\nsetTemp(cold)\u2190 st::tmp(T ),T \u2264 45. setTemp(hot)\u2190 st::tmp(T ), 45 < T .\nthat classify the current temperature value as cold or hot. The behavior of Mex6 given the same initial configuration of knowledge bases as in Example 5 and an extension of its input stream is summarized in Fig. 2.\nThe example illustrates that the new bridge rules do not use the next operator and hence influence the computation of equilibria rather than the update of knowledge bases for the next step. One can see that information about the temperature does not persist in the knowledge bases of this rMCS. It rather is continuously computed from the input stream.\nSo far, in our examples we have only shown rMCSs with a single context, to ease the presentation. We conclude this section with an extensive example of the assistedliving scenario thereby illustrating the usage of an rMCS with several contexts (and input languages) and the flow of information within these.\nExample 7. In addition to the stove context Cst as in Example 6, the rMCS Mex7 = \u3008C, IL,BR\u3009 with C = \u3008Cst,Cpos,Chm,Cho,Cec\u3009 has four further contexts: context Cpos keeps track of the current position of Dave, context Chm monitors Dave\u2019s health status, Cho is a medical ontology that the system may consult, and Cec is the emergency control context that is responsible for detecting potential threats and taking actions, such as raising an alarm. The five contexts are connected by their corresponding sets of bridge rules BR = \u3008BRst,BRpos,BRhm,BRho,BRec\u3009. Mex7 is illustrated in Figure 3.\nMex7 has four input languages IL = \u3008ILst, ILpos, ILhs, ILdd\u3009 that represent the\nsensors, where ILst has already been described in Ex. 6. ILpos is given by\n{enters(kitchen), enters(bathroom), enters(bedroom)}\nand non-empty sensor (stream) input for Ipos signals when Dave changes rooms. This information is used in context Cpos to keep track of Dave\u2019s position. This context also uses a storage logic with E = {pos(P) | P \u2208 {kitchen, bathroom, bedroom}}, and its corresponding set of bridge rules BRpos is given by the schema\nnext(setPos(P))\u2190 pos::enters(P). setPos(P)\u2190 pos::enters(P).\nThe management function writes Dave\u2019s new position into the knowledge base whenever he changes rooms and keeps the previous position, otherwise, which is why we have a bridge rule with the operator next, to ensure that, as for setPower(P) for Cst, the current position is stored. In addition, here we also have an identical copy of the bridge rule without next with the rationale that the information is available immediately. Intuitively, this will allow us to avoid situations in which the conditions for an alarm would be met including the absence of Dave, although he is just entering the room in question.\nThe input language ILhs is used to provide stream data on the health sensor readings from Dave while ILdd serves to provide data on the (usage of the) drug dispenser. The information from both sensors is used in context Chm which serves as a health monitor and also builds on a storage logic with\nE = {status(asleep),m(drugA),bp(high),bp(normal)}.\nHere, ILhs contains {asleep} \u222a {bpReading(R) | R a blood pressure value} while ILdd contains {dispensed(drugA)} and the bridge rules in BRhm are given by\nsetStatus(asleep)\u2190 hs::asleep. next(setBP(high))\u2190 hs::bpReading(R),R \u2265 140/90.\nnext(setBP(normal))\u2190 hs::bpReading(R),R < 140/90. next(setMed(m(drugA)))\u2190 dd::dispensed(drugA).\nWhile the sleep status can be monitored permanently and new data arrives at every time instant, blood pressure measurements and taking medications are only taken occasionally, so this data needs to be stored until new information arrives. Here, we abstract from the details on the duration of effects of medications. The management function mnghm(OP , kb) can then be defined quite similarly to mngst(OP , kb).\nThe context Cho = \u3008Lho,OPho,mngho\u3009 represents a biomedical health ontology, which uses the DL logic described in Example 1. It contains information on diseases, treatments, and so on, and, it can, e.g., be used to to consult for possible effects of medications by context Cec as explained below. In our case, kbho is simplified to\ndrugA : \u2203contains.ephedrine \u2203contains.ephedrine v causesHighBP\nwhich allows one to derive that drugA causes high blood pressure. In our simple setting, the management function mngho leaves the knowledge base kbho unchanged.\nCec = \u3008Lec,OPec,mngec\u3009 is the context for detecting emergencies. It is implemented as an answer set program, hence the acceptable belief sets of Lec are the answer sets of its knowledge bases as outlined in Example 1. The bridge rules in BRec do not refer to stream input but query other contexts:\nadd(oven(on, hot))\u2190 st:pw, st:tm(hot). add(humanPos(P))\u2190 pos:pos(P). add(status(asleep))\u2190 hm:asleep.\nadd(highBP)\u2190 hm:bp(high). add(highBPMed)\u2190 ho:causesHighBP(D), hm:m(D).\nNote that in the first bridge rule, we only import information for the case that will possibly be problematic, namely if the oven is turned on and hot, whereas, e.g., in the second, we use a schema to keep track of the position in all cases. The answer set program kbec is given by the rules\nturnOff(stove)\u2190 oven(on, hot), status(asleep). alert(stove)\u2190 oven(on, hot),not humanPos(kitchen),not status(asleep).\ncall(medAssist)\u2190 highBP,not highBPMed.\nThe management function of Cec, mngec(OP , kb), that adds information from the bridge rules temporarily as input facts to the context\u2019s knowledge base can be defined similar to the previous contexts.\nAn example run of this entire rMCS is given in Fig. 4. Note that we have omitted from KBt and Bt all information which is fixed to ease the reading, which is why, e.g., KBho and KBec in the figure are always empty. The presented situation begins with Dave in the kitchen, where he turns on the stove at t = 1. The effect of this is visible at t = 2, where he takes his medication (also in the kitchen). Note that blood pressure readings are not constantly done, and therefore at t = 2 no reading occurs. Subsequently, Dave leaves for the bedroom to rest (thus forgetting about the stove), and this change of position is available right away and stored. The next blood pressure reading at t = 4 is high, which is stored in the corresponding knowledge base from t = 5 onwards, at which time point a medical assistent would be called if the medication most likely causing this was not registered. Finally, at t = 6, the oven has become hot, but since Dave has fallen asleep, the context for detecting emergencies initiates turning off the stove to prevent possible problems. If Dave was not asleep yet, an alarm would have been sounded reminding him of the stove instead.\nNote that the rMCS in the scenario is a bit simplified, as e.g., currently the effects of taken medications do not wear off. Such extension can be handled by e.g., incorporating explicit time, one of the modeling features of rMCSs described in the next section.\nt K B t\nI t\na p p n o w\ni (I t , B t )\nB t\na p p n e x t\ni (I t , B t )\n1 \u3008\u2205 , {p\no s( k it c h e n\n)} ,\n\u3008{ tm\np (1\n9 ),\nsw it\nch }, \u2205,\n\u3008{ se tT\nem p (c o ld\n)} , \u2205, \u2205, \u2205,\n\u3008{ tm\n(c o ld\n)} , {p\no s( k it c h e n\n)} ,\n\u3008{ se tP\now er\n(o n\n)} , \u2205,\n{b p (n\no r m a l) }, \u2205, \u2205\u3009\n{b p R\ne a d in\ng (1\n3 5 / 8 6\n)} , \u2205\u3009\n{a d d (h\nu m\na n P\no s( k it c h e n\n)) }\u3009\n{b p (n\no r m a l) }, \u2205,\n{s et B P\n(n o r m a l) }, \u2205, \u2205\u3009\n{h u m\na n P\no s( k it c h e n\n)} \u3009\n2 \u3008{\np w }, {p\no s( k it c h e n\n)} ,\n\u3008{ tm\np (2\n1 )} , \u2205,\n\u3008{ se tT\nem p (c o ld\n)} , \u2205, \u2205, \u2205,\n\u3008{ tm\n(c o ld\n), p w },\n\u3008\u2205 , \u2205,\n{b p (n\no r m a l) }, \u2205, \u2205\u3009\n\u2205, {d\nis p\ne n se\nd (d\nr u g A\n)} \u3009\n{a d d (h\nu m\na n P\no s( k it c h e n\n)) }\u3009\n{p o s( k it c h e n\n)} , {b\np (n\no r m a l) },\n{s et M ed\n(m (d\nr u g A\n)) },\n\u2205, {h\nu m\na n P\no s( k it c h e n\n)} \u3009\n\u2205, \u2205\u3009\n3 \u3008{\np w }, {p\no s( k it c h e n\n)} ,\n\u3008{ tm\np (2\n7 )} , {e\nn te\nrs (b ed\nro o m\n)} ,\n\u3008{ se tT\nem p (c o ld\n)} ,\n\u3008{ tm\n(c o ld\n), p w },\n\u3008\u2205 , {s et P o s( be d ro o m\n)} ,\n{b p (n\no r m a l) , m\n(d r u g A\n)} ,\n{b p R\ne a d in\ng (1\n3 8 / 8 9\n)} , \u2205\u3009\n{s et P o s( be d ro o m\n)} , \u2205, \u2205,\n{p o s( be d ro o m\n)} , {b\np (n\no r m a l) },\n{s et B P\n(n o r m a l) }, \u2205, \u2205\u3009\n\u2205, \u2205\u3009\n{a d d (h\nu m\na n P\no s( be d ro o m\n)) ,\n\u2205, {h\nu m\na n P\no s( be d ro o m\n),\na d d (h\nig h B\nP M\ne d )} \u3009\nh ig\nh B\nP M\ne d }\u3009\n4 \u3008{\np w }, {p\no s( be d ro o m\n)} ,\n\u3008{ tm\np (3\n6 )} , \u2205,\n\u3008{ se tT\nem p (c o ld\n)} , \u2205, \u2205, \u2205,\n\u3008{ tm\n(c o ld\n), p w },\n\u3008\u2205 , \u2205,\n{b p (n\no r m a l) , m\n(d r u g A\n)} ,\n{b p R\ne a d in\ng (1\n4 8 / 9 7\n)} , \u2205\u3009\n{a d d (h\nu m\na n P\no s( be d ro o m\n)) , {p\no s( be d ro o m\n)} , {b\np (n\no r m a l) },\n{s et B P\n(h ig h\n)} , \u2205, \u2205\u3009\n\u2205, \u2205\u3009\na d d (h\nig h B\nP M\ne d )} \u3009\n\u2205, {h\nu m\na n P\no s( be d ro o m\n),\nh ig\nh B\nP M\ne d }\u3009\n5 \u3008{\np w }, {p\no s( be d ro o m\n)} ,\n\u3008{ tm\np (4\n3 )} , \u2205,\n\u3008{ se tT\nem p (c o ld\n)} , \u2205, \u2205, \u2205,\n\u3008{ tm\n(c o ld\n), p w },\n\u3008\u2205 , \u2205,\n{b p (h\nig h\n), m\n(d r u g A\n)} ,\n{b p R\ne a d in\ng (1\n4 6 / 9 5\n)} , \u2205\u3009\n{a d d (h\nu m\na n P\no s( be d ro o m\n)) ,\n{p o s( be d ro o m\n)} , {b\np (h\nig h\n)} ,\n{s et B P\n(h ig h\n)} , \u2205, \u2205\u3009\n\u2205, \u2205\u3009\na d d (h\nig h B\nP M\ne d ),\n\u2205, {h\nu m\na n P\no s( be d ro o m\n),\na d d (h\nig h B\nP )} \u3009\nh ig\nh B\nP M\ne d , h ig\nh B\nP }\u3009\n6 \u3008{\np w }, {p\no s( be d ro o m\n)} ,\n\u3008{ tm\np (5\n1 )} , \u2205,\n\u3008{ se tT\nem p (h\no t) }, \u2205,\n\u3008{ tm\n(h o t) , p w },\n\u3008\u2205 , \u2205, \u2205, \u2205, \u2205\u3009\n{b p (h\nig h\n), m\n(d r u g A\n)} ,\n{a sl\ne e p }, \u2205\u3009\n{s et S ta tu s(\na sl\ne e p )} , \u2205,\n{p o s( be d ro o m\n)} , {b\np (h\nig h\n)} ,\n\u2205, \u2205\u3009\n{a d d (h\nu m\na n P\no s( be d ro o m\n)) ,\n\u2205, {h\nu m\na n P\no s( be d ro o m\n),\na d d (h\nig h B\nP M\ne d ),\nh ig\nh B\nP M\ne d , h ig\nh B\nP ,\na d d (h\nig h B\nP ),\no v e n (o\nn , h o t) , st\na tu\ns( a sl ee\np ),\na d d (o\nv e n (o\nn , h o t)\n), tu\nrn O\nff (s to\nv e )} \u3009\na d d (s\nta tu\ns( a sl ee\np )) }\u3009\nFi gu\nre 4:\nSt re\nam s\nan d\nap pl\nic ab\nle op\ner at\nio ns\nfo rt\nhe ex\nam pl\ne sc\nen ar\nio gi\nve n\nby M\ne x 7"}, {"heading": "3. Modeling with rMCSs", "text": "The running example demonstrates that rMCSs can jointly integrate different formalisms and deal with a dynamic environment. In this section, we want to focus on aspects relevant to the knowledge engineer, namely how to model a certain scenario using an rMCS. To this end, we elaborate on different generic modeling techniques for rMCSs that we consider helpful in typical target applications. For concrete implementations, these techniques can still be refined and tailored towards the specific needs of the problem domain at hand. First, in Section 3.1, we discuss bridge rules as a device for translating stream data to a knowledge base language. When to use the next operator in the head of bridge rules is addressed in Section 3.2. In Section 3.3, we discuss how we deal with time on the object level, including the use of timestamps as well as external and logical clocks. Then, in Section 3.4, another technique is presented that allows for managing conflicting data in input streams on the modeling level, e.g., contradictory sensor measurements. An important issue for systems that are continuously online is when to keep data and when to remove it. In Section 3.5, we discuss how to do this and provide techniques for dynamically adjusting what information is kept in the system. These techniques allow us, e.g., to modify the size of sliding windows for stream data depending on the current situation. While the computation of acceptable belief sets may be easy for some contexts, it might be expensive for others that have to perform complex reasoning. In practice, it will therefore be wise to only evaluate these contexts if necessary. In Section 3.6, we describe a way to control the computation effort by modeling idleness of contexts.\n3.1. Incorporating Stream Data\nBridge rules are responsible for providing a context with information from streams and other contexts. As we deal with heterogeneous context languages and since input languages may differ from context languages, one important aspect of rMCSs (and earlier types of MCSs) is that bridge rules can be seen as a translation device between the different languages: bridge rule bodies use the languages of the source contexts or streams whereas a bridge rule head is an operation that produces a knowledge base in the target language (via the management function). But bridge rules do not necessarily pass information the way it is used in the body. Rather, we can model bridge rules such that we they focus on information relevant to the target context and, e.g., translate sensor data into a form that is convenient for reasoning. Consider the bridge rule schemas\nsetTemp(cold)\u2190 ex3::tmp(T ),T \u2264 45. setTemp(hot)\u2190 ex3::tmp(T ), 45 < T .\nfrom Example 6. In this case, the bridge rules only communicate whether the stove is hot or cold, abstracting away the exact temperature value coming from the sensor. This is in contrast to rule schema (3) discussed in the previous section where parameter X appears in the rule head whereby a concrete temperature value is added to the knowledge base.\n3.2. Using the next operator For gaining a better understanding of when to use the next in the head of a bridge rule, reconsider the example of turning a switch on and off as in Examples 2 and 3. Remember that the bridge rules\nnext(setPower(on))\u2190 ex3::switch,not st:pw. next(setPower(off ))\u2190 ex3::switch, st:pw.\nwere used so that an occurrence of an input atom switch causes the knowledge base to contain an inverted power state at the next time point. In order to highlight the difference, assume we would instead use the bridge rules\nsetPower(on)\u2190 ex3::switch,not st:pw. setPower(off )\u2190 ex3::switch, st:pw.\nwithout next. We refer to the version of Mex3 from Example 3 with these modified bridge rules by M \u2032ex3. Consider the configuration KB = \u3008kbst\u3009 of knowledge bases with kbst = \u2205 and the input I = \u3008{switch}\u3009 as in Example 4. Indeed, M \u2032ex3 has no equilibrium given KB and I: If we take belief state B = \u3008\u2205\u3009 as in Example 4, we have appnowst (I,B) = {setPower(on)} (instead of \u2205 as in Example 4). Consequently, following the definition of mngst in Example 2, we get mngst(app now st (I,B), kbst) = {pw(on)}. But then B is not contained in accst(mngst(appnowst (I,B), kbst)) = {{pw(on)}}, thus, B is not an equilibrium of M \u2032ex3 given KB and I. This is in line with the intuition that without next, turning the switch should affect the current equilibrium. However, B\u2032 = \u3008{pw(on)}\u3009 is also not an equilibrium of M \u2032ex3. Since appnowst (I,B\n\u2032) = {setPower(off )}, we get mngst(appnowst (I,B\u2032), kbst) = \u2205. But then accst(mngst(app now st (I,B\n\u2032), kbst)) = {\u2205} does not contain B\u2032, consequently also B\u2032 is not an equilibrium of M \u2032ex3 given KB and I. The two bridge rules without next prevent stability of a belief state required for an equilibrium: believing that the power is on (respectively off) causes an update of the knowledge base that the power is off (respectively on) which is in turn inconsistent to the belief.\nThe reason why the change considered here does not work is that the two types of bridge rule are meant to be used for different purposes. The bridge rules using next are responsible for changing knowledge bases over time. An rMCS without such bridge rules cannot alter its initial configuration of knowledge bases. Thus, these rules come with an operational flavor. Bridge rules without next on the other hand have a pure declarative nature and their purpose is to semantically integrate the contexts of an rMCS.\nStill, as we have seen in Example 7, it sometimes makes sense to use essentially the same bridge rules with and without next: the bridge rule\nnext(setPos(P))\u2190 pos::enters(P).\nensures that the information about the position of Dave persists in the knowledge base, whereas\nsetPos(P)\u2190 pos::enters(P).\nprovides this information right away for computing equilibria in the current time instant.\n3.3. Integration of Time The structure of input streams and equilibria streams implicitly induces a discrete logical time for rMCSs. In order to operate in dynamic environments, in many cases it is necessary to deal with explicit physical time or logical time, and both can be achieved on the level of modeling. To this end, it is necessary to have access to explicit time points on this level, i.e., in the bridge rules and knowledge bases. A natural way to make such time points explicitly available is the use of an external clock that provides the current time via an input stream Ic. Thus, every input for the rMCS contains information about the current time which can then be queried in bridge rules.\nConsider a context C1 that requires information about the development of temperature values from an incoming sensor over time. The bridge rule schema\nnext(add(tmpAtTime(Temp,T )))\u2190 tmp::tmp(Temp), c::now(T ).\ncan be used to add atoms of form tmpAtTime(Temp,T )) to the context, where Temp is the current temperature and T stands for the time of the sensor reading. This setting also allows for querying, e.g., whether a temperature of 45\u25e6C was exceeded within the last 10 minutes, as expressed in the following bridge rule schema.\nadd(recentlyHot)\u21901:tmpAtTime(Temp,T \u2032), Temp > 45, c::now(T ), T \u2032 \u2265 T \u2212 10.\nNote that constantly adding information, as here, will in practice require that we also forget knowledge again, a matter discussed later in this section.\nAnother possibility is to use logical time synchronized with the length of the equilibria stream, e.g., whenever the use of an external clock is not an option. We can obtain timestamps from the computation of knowledge base updates by using one context Cclock that keeps information about the current logical time that uses the following bridge rule schemas and whose initial knowledge base is assumed to be empty.\nsetTime(now(0 ))\u2190 not clock:timeAvailable. add(timeAvailable)\u2190 clock:now(T ), T > 0.\nnext(setTime(now(T + 1 )))\u2190 clock:now(T ).\nThe first rule is used for initialization ensuring that if no time information is yet available, the logical time is set to the value 0. The third rule increments the current time by one and stores the updated value in the knowledge base of the next time instant. Finally, the second rule, ensures that once this value is greater than 0, the first rule can no longer be applied.\n3.4. Handling Inconsistent Stream Data In many situations, inconsistencies may occur when dealing with multiple external sources of data. Consider, e.g., an array of sensors that measure interdependent properties among which there is one less reliable sensor that sometimes provides values that\nconflict with the data from the remaining sensors. In this case, we would like to use such a measure of reliability to consistently accommodate relevant sensor data. Next, we present a technique for integrating possibly inconsistent stream data into a context of an rMCS. Let M = \u3008C, IL,BR\u3009 be an rMCS with IL = \u3008IL1, . . . , ILk\u3009, and Ci \u2208 C a context whose aim is to receive and consistently accommodate (potentially conflicting) information from the streams. To deal with possible inconsistencies, Ci has bridge rules of the form addC(D, j )\u2190 j::D. for j \u2208 {1, . . . , k}, where the operation addC is meant to consistently add the information of sensor j to the context. To address possible inconsistencies among sensors, we foresee a management function mngi that operates based on a total preference relation \u227a over the available sensors. The second argument of the addC operation provides information about the source of a piece of information and thus a way of imposing preferences on the information to be added. Without loss of generality assume IL1 > . . . > ILk, that is, input language IL1 has highest priority. Moreover, a notion of consistency needs to be specific to the context and so we assume a property cons(kb) that holds if the knowledge base kb is consistent (according to such domain specific notion of consistency).\nWe define inpc0(OP) = \u2205 and inp\u2032j = {d | addC(d, j ) \u2208 OP} for j \u2208 {1, . . . , k}. Then we let\ninpcj(OP) = { inpcj\u22121(OP) \u222a inp\u2032j if cons(inpcj\u22121(OP) \u222a inp\u2032j) inpcj\u22121(OP) otherwise\nand we define mngi(OP , kbi) = kbi \u222a inpck(OP). The intuitive idea is that, starting with the input stream with highest priority, data from each sensor is only incorporated into the knowledge base if such data is consistent with the data already collected from the input streams with higher priority.\nNote that the solution only considers inconsistency of data on the streams. For also considering inconsistency between the streams and the knowledge base kbi of the context, we can set inpc0(OP) = kbi instead of kb c 0(OP) = \u2205.\nAn alternative variant allows us to incorporate meta-information about sensors whose readings are considered inconsistent. Namely, we may change the definition of inpcj(OP) to inp c j\u22121(OP) \u222a {incons(j)} in case a conflict occurs. Such information can then be further leveraged by, e.g., initiating a control of the sensor if such measurements fall outside of the expected parameters of such sensor.\nIn all, this shows how the management function can solve conflicts due to inconsistent stream data based on preferences among the streams. Of course, many more strategies for integrating inconsistent stream data can be thought of. For example, in absence of a global ranking between streams, one way to ensure consistency is to select maximally consistent subsets of stream data. A corresponding management function could then be defined such that mngi(OP , kbi) = kbi \u222a inpmx, where inpmx is a maximal set where inpmx \u2286 {d | addC(d, j ) \u2208 OP , j \u2208 {1, . . . ,m}} and cons(inpmx) holds.\nThe strategies above show how we can deal with contradictory information in the processed data by means of modeling. In Section 4, we address inconsistency on the level of the formalism caused by nonexistence of equilibria or inconsistent belief states.\n3.5. Selective Forgetting and Data Retention\nAs argued in Section 3.3 for the example where we were constantly adding sensor information to some knowledge base, sometimes it is necessary to forget (part of this) knowledge again. In this section, we show how rMCSs can model scenarios where there is a need to dynamically adjust the size of the stored stream history. We do that by considering an extension of our running example. Recall from Example 7 that context Cec is a context for detecting emergencies. In a situation where the stove is hot and Dave is asleep, turnOff(stove) is derived, signaling that the stove must be turned off. In case the stove is hot, but Dave is neither asleep nor in the kitchen, then an alarm is raised, signaling a potential emergency. In the latter case, we do not want to immediately turn the stove off, since it may well be the case that the absence of Dave from the kitchen is short. A situation is only considered a real emergency if Dave is absent from the kitchen for a (predefined) long period of time. To model such situation, we use a context CstE , which collects timestamped alerts raised by context Cec and uses these to check if a real stove-related emergency has occurred. Since we need to reason about time as in Section 3.3, we consider an input stream Ic that provides the current time. The possible knowledge bases of CstE contain elements of the form alert(stove, t) where t \u2208 N, one element of the form winE(t), which defines the limit size of the time window between two alerts above which an emergency should be raised, and possibly one element of the form emergency(stove) that signals the existence of a stove-related emergency. The set of bridge rules of CstE is determined by the following bridge rule schemas:\nnext(add(alert(stove,T )))\u2190 c::now(T ), ec:alert(stove). next(del(alert(stove,T )))\u2190 stE:alert(stove,T ),not ec:alert(stove).\nadd(emergency(stove))\u2190 c::now(T ), ec:alert(stove), stE:alert(stove,T \u2032), stE:winE(Y ), |T \u2212 T \u2032| \u2265 Y.\nThe first rule adds a timestamped stove alert whenever such alert is active on context Cec. The second rule removes all currently stored stove alerts whenever no such alert is coming from context Cec. This guarantees that the knowledge base of CstE does not accumulate unnecessary information. The last bridge rule triggers a real emergency alert whenever, in the history of alerts kept in the knowledge base of CstE , there is an alert whose timestamp differs from the current time more than the acceptable emergency window.\nUsing context CstE , we have shown how to model scenarios where tracking the stream history is triggered by alerts of possible emergencies. We now also consider the case where such alerts trigger the change of the window size of stream history to be kept. Consider a scenario with several potential emergencies, which can be just suspected or confirmed. Based on the status of the emergencies at each time point, we may need to adapt the size of the stream history that is kept. We generically model such scenario with an rMCS with a context Cd, which is used for emergency detection in such a dynamic environment, and an input language ILs, which represents the possible observations. Assume there are m potential emergencies e1, . . . , em we want the context to handle. The role of Cd is to check, based on the observations made, whether\none or more of the emergencies ei are suspected or confirmed. Based on information about potential emergencies, Cd adjusts the time window of the observations that are kept. This is the basis for intelligent forgetting based on dynamic windows.\nThe only assumptions we make about how Cd works internally are:\n\u2022 Cd may signal that emergency ei is suspected (susp(ei)) or confirmed (conf(ei)).\n\u2022 Cd has information about default, respectively actual window sizes for each different observation, defWin(p, x ), win(p, x ), and\n\u2022 Cd has information about the window size for each observation relevant for a particular emergency, rel(p, e, x ).\nThe set of bridge rules for Cd includes the following rules.\nnext(set(win(P ,X )))\u2190 d:defWin(P ,X ),not d:susp(E ). next(set(win(P ,Y )))\u2190 d:rel(P ,E ,Y ), d:susp(E ).\nalarm(E)\u2190 d:conf(E ).\nThe operation set sets the window size to a new value, deleting the old one, while alarm is an operation that adds information to the context knowledge base signaling an alarm. Since an observation can be relevant for more than one emergency, it may be the case that the management function has to deal with operations set(win(p, x )) with the same p but with different values of x. In that case, in order to avoid loosing observations relevant for some suspected emergency, the management function takes the largest value of x as the window size for p.\nFinally, the following bridge rule schemas define addition and deletion of observations from some stream s. The deletion of observations are performed in accordance with the determined window sizes.\nnext(add(P(T )))\u2190 t::now(T ), s::P. next(del(P(T \u2032)))\u2190 d:P(T \u2032), t::now(T ), d:win(P ,Z ), T \u2032 < T \u2212 Z.\nThe management function just performs additions and deletions on the context knowledge base. Since additions always include the (current) time of addition, deletions always refer to an earlier point in time, thus these two operators can never occur simultaneously.\n3.6. Control of computation In this section, we show how to control - at least to some extent - the effort spent on the computation of particular contexts. In situations where the focus is on monitoring and reacting to potential emergencies, it is natural to allocate computational resources only to contexts relevant for the current potential emergencies, and keep the others idle, in the sense that they only minimally use the computation resources of the system. An idle/irrelevant context may still buffer sensor data it receives, as this information may become important in a subsequent time instant. Still, the computation of the semantics of an idle context is therefore limited to buffering relevant sensor data, which is in\ngeneral much lighter than the full computation of the current acceptable belief sets of the context, i.e., its knowledge base.\nHere, we assume that there are m potential emergencies e1, . . . , em as in the previous section, but now we have ` different contexts, Di, 1 \u2264 i \u2264 `, called the detector contexts, whose aim is to detect at each time what emergencies are suspected or not. Besides the detector contexts, we have m other regular contexts, Ci, 1 \u2264 i \u2264 m. In addition, we introduce a specific control context Cc, whose aim is to decide what regular contexts should be idle and for how long. This decision is based on incoming information about suspected emergencies, and also on information about what regular contexts are relevant for each emergency.\nWe build an rMCS where each detector context Di is connected via bridge rules with the control context Cc, sending, at each time instant, information about suspected emergencies. Besides that, Cc contains information of the form relevantFor(i , ej ) about what controlled contexts Ci are relevant for each emergency ej . Based on this information, Cc decides whether it is safe to let one context Ci be idle for some time.\nRegarding each regular context Ci, we modify its original set bridge rules by adding, to the body of each rule, the context literal not c:idle(i). Therefore, the bridge rules of Ci behave exactly as before when the context is not idle, and simply do not fire if the context is idle. Also, we add the bridge rule add(idle) \u2190 c:idle(i), which allows adding meta information to the knowledge base of Ci. The acc function of Ci then behaves as usual whenever idle is not part of the knowledge base, and otherwise just outputs a distinguished belief set {idle}. This guarantees that the computational resources used by an idle context are minimal.\nIn case Ci is idle, we may still want to buffer sensor information it receives, as this may become relevant later. For each rule of the form\nadd(P,T , jr )\u2190 jr::P, t::now(T ).\nin the original set of bridge rules of Ci we add\nnext(bf(P,T , jr ))\u2190 jr::P, t::now(T ), 0:idle(i).\nThe operation bf just adds the atom bf(p, t , jr ) to the knowledge base of the context.3 As mentioned above, this buffered information is not used anywhere, and it just remains in the knowledge base there for later use, namely when the context is no longer idle.\nThe only missing piece is bringing back information from the buffer when the context is no longer idle. This can be done using the pair of bridge rules\nemptyBuffer\u2190 not 0:idle(i). next(emptyBuffer)\u2190 not 0:idle(i).\nWhenever the management function has to execute the operation emptyBuffer, it takes all information out of the buffer, checks whether it is still within the relevant time window, and, if this is the case, adds such time-stamped information to the knowledge\n3We implicitly assume that the language of the context admits constructs of this form.\nbase. In this process, the potential inconsistencies that may arise at each time point are handled in a similar way as discussed in Section 3.4.\nWe now describe the control context Cc. We intend here to give a proof of concept, rather than a sophisticated control method. For this reason, we simply assume that the control context lets a regular context Ci be idle whenever Ci is not relevant for any currently suspected emergency. This can be expressed using the following bridge rule schemata for Cc:\nadd(relevant(K ))\u2190 J :susp(E ), c:relevantFor(K ,E ). add(idle(K ))\u2190 not c:relevant(K ).\nThe first rule identifies the currently relevant regular contexts, based on information about currently suspected emergencies and on the contexts relevant for such emergencies. The second rule then identifies those regular contexts that are currently idle.\nThus, as long as a certain context is not relevant for any possible suspected emergency, it is kept idle and incoming stream data for is buffered. As soon as some suspected emergency arises, the context becomes relevant and no longer idle, the respective buffer is emptied as described above, and non-trivial equilibria are computed for this context as intended."}, {"heading": "4. Inconsistency Management", "text": "The occurrence of inconsistencies within frameworks that aim at integrating knowledge from different sources cannot be neglected, even more so in dynamic settings where knowledge changes over time. There are many reasons why rMCSs may fail to have an equilibria stream. These include the absence of an acceptable belief set for one of its contexts given its current knowledge base at some point in time, some occurring conflict between the operations in the heads of bridge rules, or simply because the input stream is such that the configuration of the flow of information within the rMCS, namely its bridge rules, prevent the existence of such an equilibria stream. In a real world situation, an rMCS without an equilibria stream is essentially useless. Not only can it not be used at the first time point equilibria ceased to exist, but it also cannot recover, even if what caused the problem was the particular input at that time point, which is bound to subsequently change into some other input that would no longer cause any trouble. This is so because an equilibria stream requires the existence of an equilibrium at every time point.\nIn this section, we address the problem of inexistent equilibria streams, also known as global inconsistency. We begin by defining a notion of coherence associated with individual contexts which allows us to first establish sufficient conditions for the existence of equilibria streams, and then abstract away from problems due to specific incoherent contexts and focus on those problems essentially caused by the way the flow of information in rMCSs is organized through its bridge rules. We introduce the notion of a repair, which modifies an rMCS by changing its bridge rules at some particular point in time in order to obtain some equilibria stream, which we dub repaired equilibria stream. We establish sufficient conditions for the existence of repaired equilibria streams and briefly discuss different possible strategies to define such repairs. However,\nrepaired equilibria streams may not always exist either, e.g., because some particular context is incoherent. To deal with such situations, we relax the concept of equilibria stream and introduce the notion of partial equilibria stream, which essentially allows the non-existences of equilibria at some time points. It turns out that partial equilibria streams always exist thus solving the problem of global inconsistency for rMCSs.\nIn [14] the authors addressed the problem of global inconsistency in the context of mMCSs. Just as we do here, they begin by establishing sufficient conditions for the existence of equilibria. Then, they define the notions of diagnosis and explanation, the former corresponding to rules that need to be altered to restore consistency, and the latter corresponding to combinations of rules that cause inconsistency. These two notions turn out to be dual of each other, and somehow correspond to our notion of repair, the main difference being that, unlike in [14], we opt not to allow the (nonstandard) strengthening of bridge-rule to restore consistency, and, of course, that fact that our repairs need to take into account the dynamic nature of rMCSs.\nWe start by introducing two notions of global consistency differing only on whether we consider a particular input stream or all possible input streams.\nDefinition 13. LetM be an rMCS, KB a configuration of knowledge bases forM , and I an input stream forM . Then, M is consistent with respect to KB and I if there exists an equilibria stream of M given KB and I. M is strongly consistent with respect to KB if, for every input stream I for M , M is consistent with respect to KB and I.\nObviously, for a fixed configuration of knowledge bases, strong consistency implies consistency w.r.t. any input stream, but not vice-versa.\nUnfortunately, verifying strong consistency is in general highly complex since it requires checking all possible equilibria streams. Nevertheless, we can establish conditions that ensure that an rMCS M is strongly consistent with respect to a given configuration of knowledge bases KB, hence guaranteeing the existence of an equilibria stream independently of the input. It is based on two notions \u2013 totally coherent contexts and acyclic rMCSs \u2013 that together are sufficient to ensure (strong) consistency.\nTotal coherence imposes that each knowledge base of a context always has at least one acceptable belief set.\nDefinition 14. A context Ci is totally coherent if acci(kb) 6= \u2205, for every kb \u2208 KB i.\nThe second notion describes cycles between contexts which may be a cause of inconsistency. Acyclic rMCSs are those whose bridge rules have no cycles.\nDefinition 15. Given an rMCSM = \u3008\u3008C1, . . . ,Cn\u3009, IL,BR\u3009, /M is the binary relation over contexts of M such that (Ci,Cj) \u2208 /M if there is a bridge rule r \u2208 BRi and j:b \u2208 bd(r) for some b. If (Ci,Cj) \u2208 /M , also denoted by Ci /M Cj , we say that Ci depends on Cj in M , dropping the reference to M whenever unambiguous.\nDefinition 16. An rMCS M is acyclic if the transitive closure of /M is irreflexive.\nWe can show that these two conditions together are indeed sufficient to ensure strong consistency.\nProposition 1. Let M = \u3008\u3008C1, . . . ,Cn\u3009, IL,BR\u3009 be an acyclic rMCS such that every Ci, 1 \u2264 i \u2264 n, is totally coherent, and KB a configuration of knowledge bases for M . Then, M is strongly consistent with respect to KB.\nPROOF. Let M = \u3008\u3008C1, . . . ,Cn\u3009, IL, \u3008BR1, . . . ,BRn\u3009\u3009 be an acyclic rMCS with totally coherent contexts. We first prove that M has an equilibrium given KB and I, for any knowledge base configuration KB = \u3008kb1, . . . , kbn\u3009 for M and input I for M .\nWe prove this by induction on the number of contexts of M , making use of the following simple observation: if M does not have cycles, then there exists some i \u2208 {1, . . . , n} such that refr(j, i) does not hold for any j \u2208 {1, . . . , n} and r \u2208 BRj . It is quite easy to see that if this condition is violated then a cycle necessarily exists.\nLet n = 1. Then, since there are no cycles, no bridge rule in BR1 contains atoms of the form 1:b in its body. Thus, appnowi (I,B) does not depend on B. Total coherence then immediately implies that M has an equilibrium given KB and I.\nLet n = m + 1. We use the above observation, and assume, w.l.o.g., that C1 is a context for which refr(j, 1) does not hold for any j \u2208 {1, . . . ,m + 1} and r \u2208 BRj . Then, the rMCSM\u2217 = \u3008\u3008C2, . . . ,Cm+1\u3009, IL, \u3008BR2, . . . ,BRm+1\u3009\u3009 hasm contexts and it is still acyclic. By induction hypothesis, we can conclude thatM\u2217 has an equilibrium given KB\u2217 = \u3008kb2, . . . , kbm+1\u3009 and I. Let B\u2217 = \u3008B2, . . . , Bm+1\u3009 be such equilibrium. Then, since C1 is assumed to be a totally coherent context, there exists B1 \u2208 BS 1 such that B = \u3008B1, B2, . . . , Bn\u3009 is an equilibrium of M given KB and I. This follows easily from the fact that no set appnowi (I,B) depends on the choice of B1.\nWe have shown that the existence of an equilibrium for M is independent of the given knowledge base configuration KB for M and input I for M . This immediately implies that for any input stream I for M (until \u03c4 ), and any knowledge base configuration KB for M , there exists an equilibria stream of M given KB and I.\nA similar property holds for consistent mMCSs, which indicates that the extension to rMCSs as such does not decrease the likelihood of existence of an equilibria stream. Nevertheless, these conditions are rather restrictive since there are many useful cyclic rMCSs which only under some particular configurations of knowledge bases and input streams may have no equilibria streams.\nTo deal with these, and recover an equilibria stream, one possibility is to repair the rMCSs by locally, and selectively, eliminating some of its bridge rules. Towards introducing the notion of repair, given an rMCS M = \u3008\u3008C1, . . . ,Cn\u3009, IL,BR\u3009, we denote by brM the set of all bridge rules of M , i.e., brM = \u22c3 1\u2264i\u2264n BRi. Moreover, given a set R \u2286 brM , denote by M [R] the rMCS obtained from M by restricting the bridge rules to those not in R.\nDefinition 17 (Repair). Let M = \u3008C, IL,BR\u3009 be an rMCS, KB a configuration of knowledge bases for M , and I an input stream for M until \u03c4 where \u03c4 \u2208 N \u222a {\u221e}. Then, a repair for M given KB and I is a function R : [1..\u03c4 ]\u2192 2brM such that there exists a function B : [1..\u03c4 ]\u2192 BelM such that\n\u2022 Bt is an equilibrium of M [Rt] given KBt and It, where KBt is inductively defined as\n\u2013 KB1 = KB\n\u2013 KBt+1 = updM [Rt](KBt, It,Bt).\nWe refer to B as a repaired equilibria stream of M given KB, I andR.\nNote the generality of this notion, which considers to be a repair essentially any sequence of bridge rules (defined by the repair function R) that, if removed from the rMCS at their corresponding time point, will allow for an equilibrium at that time point. This may include repairs that unnecessarily eliminate some bridge rules, and even the empty repair i.e. the repair R\u2205 such that Rt\u2205 = \u2205 for every t, whenever M already has an equilibria stream given KB and I. This ensures that the set of repaired equilibria streams properly extends the set of equilibria streams, since equilibria streams coincide with repaired equilibria streams given the empty repair.\nProposition 2. Every equilibria stream of M given KB and I is a repaired equilibria stream of M given KB, I and the empty repairR\u2205.\nPROOF. This result follows easily from the observation that M [R\u2205] = M . In this case the conditions in the definition of an equilibria stream of M coincide with those in the definition of a repaired equilibria stream of M .\nIt turns out that for rMCSs composed of totally coherent contexts, repaired equilibria streams always exist.\nProposition 3. Let M = \u3008\u3008C1, . . . ,Cn\u3009, IL,BR\u3009 be an rMCS such that each Ci, i \u2208 {1, . . . , n}, is totally coherent, KB a configuration of knowledge bases forM , and I an input stream forM until \u03c4 . Then, there existsR : [1..\u03c4 ]\u2192 2brM andB : [1..\u03c4 ]\u2192 BelM such that B is a repaired equilibria stream given KB, I andR.\nPROOF. Since each context of M is totally coherent, Prop. 1 guarantees the existence of an equilibrium if M is acyclic. Now just note that if we take R : [1..\u03c4 ]\u2192 2brM such that Rt = brM for every t, then each M [Rt] does not have bridge rules and it is therefore acyclic. Then, for every t, M [Rt] is strongly consistent. Therefore we can easily inductively construct B : [1..\u03c4 ]\u2192 BelM such that B is a repaired equilibria stream given KB, I andR.\nWhenever repair operations are considered in the literature, e.g., in the context of databases [4], there is a special emphasis on seeking repairs that are somehow minimal, the rational being that we want to change things as little as possible to regain consistency. In the case of repairs of rMCS, it is easy to establish an order relation between them, based on a comparison of the bridge rules to be deleted at each time point.\nDefinition 18. LetRa andRb be two repairs for some rMCS M given a configuration of knowledge bases for M , KB and I, an input stream for M until \u03c4 . We say that Ra \u2264 Rb if Ria \u2286 Rib for every i \u2264 \u03c4 , and that Ra < Rb if Ra \u2264 Rb and Ria \u2282 Rib for some i \u2264 \u03c4 .\nThis relation can be straightforwardly used to check whether a repair is minimal, and we can restrict ourselves to adopting minimal repairs. However, there may be good\nreasons to adopt non-minimal repairs, e.g., so that they can be determined as we go, or so that deleted bridge rules are not reinstated, etc. Even though investigating specific types of repairs falls outside the scope of this paper, we nevertheless present and briefly discuss some possibilities.\nDefinition 19 (Types of Repairs). LetR be a repair for some rMCSM given KB and I. We say thatR is a:\nMinimal Repair if there is no repairRa for M given KB and I such thatRa < R.\nGlobal Repair ifRi = Rj for every i, j \u2264 \u03c4 .\nMinimal Global Repair if R is global and there is no global repair Ra for M given KB and I such thatRa < R.\nIncremental Repair ifRi \u2286 Rj for every i \u2264 j \u2264 \u03c4 .\nMinimally Incremental Repair if R is incremental and there is no incremental repairRa and j \u2264 \u03c4 such thatRia \u2282 Ri for every i \u2264 j.\nMinimal repairs perhaps correspond to the ideal situation in the sense that they never unnecessarily remove bridge rules. In some circumstances, it may be the case that if a bridge rule is somehow involved in some inconsistency, it should not be used at any time point, leading to the notion of global repair. Given the set of all repairs, checking which are global is also obviously less complex than checking which are minimal. A further refinement \u2013 minimal global repairs \u2013 would be to only consider repairs that are minimal among the global ones, which would be much simpler to check than checking whether it is simply minimal. Note that a minimal global repair is not necessarily a minimal repair. One of the problems with these types of repairs is that we can only check whether they are of that type globally, i.e., we can only check once we know the entire input stream I. This was not the case with plain repairs, as defined in Def. 17, which could be checked as we go, i.e., we can determine what bridge rules to include in the repair at a particular time point by having access to the input stream I up to that time point only. This is important so that rMCSs can be used to effectively react to their environment. The last two types of repairs defined above allow for just that. Incremental repairs essentially impose that removed bridge rules cannot be reused in the future, i.e., that the set of removed bridge rules monotonically grows with time, while minimally incremental repairs further impose that only minimal sets of bridge rules can be added at each time point. Other types of repairs could be defined, e.g., by defining some priority relation between bridge rules, some distance measure between subsets of bridge rules and minimize it when considering the repair at consecutive time points, among many other options, whose investigation we leave for future work. Repairs could also be extended to allow for the strengthening of bridge rules, besides their elimination, generalizing ideas from [14] and [10] where the extreme case of eliminating the entire body of bridge rules as part of a repair is considered.\nDespite the existence of repaired equilibria streams for large classes of systems, two problems remain: first, computing a repair may be excessively complex, and second, there remain situations where no repaired equilibria stream exists, namely when the\nrMCS contains contexts that are not totally coherent. The second issue could be dealt with by ensuring that for each non-totally coherent context there would be some bridge rule with a management operation in its head that would always restore consistency of the context, and that such rule could always be activated through a repair (for example, by adding a negated reserved atom to its body, and another bridge rule with that atom in its head and an empty body, so that removing this latter rule through a repair would activate the management function and restore consistency of the context). But this would require special care in the way the system is specified, and its analysis would require a very complex analysis of the entire system including the specific behavior of management functions. In practice, it would be quite hard \u2013 close to impossible in general \u2013 to ensure the existence of repaired equilibria streams, and we would still be faced with the first problem, that of the complexity of determining the repairs.\nA solution to this problem is to relax the notion of equilibria stream so that it does not require an equilibrium at every time point. This way, if no equilibrium exists at some time point, the equilibria stream would be undefined at that point, but possibly defined again in subsequent time points. This leads to the following notion of partial equilibria stream.\nDefinition 20 (Partial Equilibria Stream). Let M = \u3008C, IL,BR\u3009 be an rMCS, KB = \u3008kb1, . . . , kbn\u3009 a configuration of knowledge bases for M , and I an input stream for M until \u03c4 where \u03c4 \u2208 N \u222a {\u221e}. Then, a partial equilibria stream of M given KB and I is a partial function B : [1..\u03c4 ] 9 BelM such that\n\u2022 Bt is an equilibrium of M given KBt and It, where KBt is inductively defined as\n\u2013 KB1 = KB\n\u2013 KBt+1 = { updM (KBt, It,Bt), if Bt is not undefined. KBt, otherwise.\n\u2022 or Bt is undefined.\nAs expected, this is a proper generalisation of the notion of equilibria stream:\nProposition 4. Every equilibria stream of M given KB and I is a partial equilibria stream of M given KB and I.\nPROOF. This result follows easily from the observation that for an equilibria stream B of M given KB and I, and every t, Bt is never undefined. Therefore, in this case the conditions in the definition of partial equilibria stream coincide with those for equilibria stream.\nAnd it turns out that partial equilibria streams always exist.\nProposition 5. Let M be an rMCS, KB a configuration of knowledge bases for M , and I an input stream for M until \u03c4 . Then, there exists B : [1..\u03c4 ] 9 BelM such that B is a partial equilibria stream given KB and I.\nPROOF. We just need to note that if we take B : [1..\u03c4 ] 9 BelM such that, for every t, Bt is undefined, then B is trivially a partial equilibria stream given KB and I.\nOne final word to note is that partial equilibria streams not only allow us to deal with situations where equilibria do not exist at some time instants, but they also open the ground to consider other kinds of situations where we do not wish to consider equilibria at some time point, for example because we were not able to compute them on time, or simply because we do not wish to process the input at every time point, e.g., whenever we just wish to sample the input with a lower frequency than it is generated. If we wish to restrict that partial equilibria streams only relax equilibria streams when necessary, i.e., when equilibria do not exist at some time point, we can further impose the following condition on Def. 20:\nBt is undefined =\u21d2 there is no equilibrium of M given KBt and It."}, {"heading": "5. Non-Determinism and Well-Founded Semantics", "text": "Reactive MCSs as considered so far are non-deterministic for two reasons. On the one hand, we allow for contexts whose semantics may return multiple belief sets for the same knowledge base, and on the other hand, the flow of information between contexts established by bridge rules may be the source of non-determinism. As this leads to multiple equilibria and thus to exponentially many equilibria streams, in practice, this may be undesired, which is why it is important to study under which conditions nondeterminism can be avoided.\nThe first source of non-determinism solely depends on the choice of the contexts occurring in the rMCS, i.e., it can be avoided when determining/designing the rMCS in question. The second source, however, requires to consider the entire rMCS when eliminating the non-determinism. This can be achieved by introducing preferences on equilibria using, e.g., preference functions as proposed by Ellmauthaler [16]. One might also adopt language constructs for expressing preferences in ASP such as optimization statements [21] or weak constraints [13], which essentially assign a quality measure to equilibria, or, more recently, add a pre-order on the contexts [35]. Alternatively, and inspired by notions developed for MCSs [9], we may consider restrictions on rMCSs such that these non-determinisms do not occur in the first place. In the remainder of this section, we will focus on such restrictions leading to an alternative well-founded semantics for rMCSs.\nAs a first step towards this objective, only equilibria that are subset-minimal will be considered, also with the aim of avoiding unnecessary self-justifications of information resulting from the interaction of various contexts. Then, grounded equilibria as a special case for so-called reducible MCSs will be presented for which the existence of minimal equilibria can be effectively checked. Subsequently, a well-founded semantics for such reducible MCSs will be defined under which an approximation of all grounded equilibria can be computed deterministically. In the following, we transfer these notions from static MCSs in [9] to dynamic rMCSs and discuss under which (non-trivial) conditions they actually can be applied.\nWe start with the notion of minimal equilibria. Formally, given an rMCS M = \u3008\u3008C1, . . . ,Cn\u3009, IL,BR\u3009, a configuration of knowledge bases KB for M and an input I for M , an equilibrium B = \u3008B1, . . . , Bn\u3009 of M given KB and I is minimal if there is no equilibrium B\u2032 = \u3008B\u20321, . . . , B\u2032n\u3009 of M given KB and I such that B\u2032i \u2286 Bi for all i with 1 \u2264 i \u2264 n and B\u2032j ( Bj for some j with j \u2208 {1 . . . n}.\nThis notion of minimality avoids to some extent unnecessary self-justifications in equilibria (streams). A simple example of such self-justification is shown in Ex. 2 in [9], which can be transcribed to our setting using a simple rMCS without input languages, a single propositional context C1 (see Ex. 2) with empty kb and BR1 only containing add(a)\u2190 1:a. Then both \u3008\u2205\u3009 and \u3008{a}\u3009 are equilibria. The latter is considered dubious as a is justified by itself and minimality would avoid such self-justification. Note that this does not always work.\nExample 8. A single storage context with empty kb and bridge rules add(b)\u2190 not 1:a. and add(a)\u2190 1:a. has two minimal equilibria \u3008{a}\u3009 and \u3008{b}\u3009, the former being selfjustified.\nStill, avoiding non-minimality whenever possible certainly is a decent guiding principle, and, as we will see later, it can be avoided altogether under certain conditions.\nThe problem is that checking for minimality commonly raises the computational complexity of determining equilibria. To avoid that, we now formalize conditions under which minimal equilibria can be effectively checked.\nFor that purpose, we start by introducing the notion of monotonic logics. Namely, a logic L = \u3008KB ,BS ,acc\u3009 is monotonic if\n1. acc(kb) is a singleton set for each kb \u2208 KB , and 2. B \u2286 B\u2032 whenever kb \u2286 kb\u2032, acc(kb) = {B}, and acc(kb\u2032) = {B\u2032}.\nIn other words, L is monotonic if acc is deterministic and monotonic. Maybe not surprisingly, the logics of non-monotonic formalisms such as La for the answer set semantics in Ex. 1 do not satisfy this definition. We therefore proceed with introducing the notion of a reducible logic, which covers monotonic logics, but also includes logics that can be reduced to monotonic ones given a belief set of the logic.\nLogic L = \u3008KB ,BS ,acc\u3009 is reducible iff, for some KB\u2217 \u2286 KB and some reduction function red : KB \u00d7 BS \u2192 KB\u2217,\n1. \u3008KB\u2217,BS ,acc\u3009 is monotonic, 2. for each kb \u2208 KB , and all B,B\u2032 \u2208 BS :\n\u2022 red(kb, B) = kb whenever kb \u2208 KB\u2217, \u2022 red(kb, B) \u2286 red(kb, B\u2032) whenever B\u2032 \u2286 B, and \u2022 acc(red(kb, B)) = {B} iff B \u2208 acc(kb).\nIntuitively, L is reducible, if a) the restriction of L to KB\u2217 is monotonic, and b) there is a reduction function which should not reduce kb further if it already is in KB\u2217, which is antitonic, and by means of which acceptability of a belief set can be checked by the reduction (see also [9]).\nIn a reducible rMCS, the logics of all contexts have to be reducible. Additionally, we require red and mng to be applicable in arbitrary order for all contexts, and that\nsequences of increasing sets of operations are monotonic in the following sense. Given rMCS M = \u3008\u3008C1, . . . ,Cn\u3009, IL,BR\u3009 and, for some i \u2208 {1, . . . n}, kb \u2208 KB i, we say that OP \u2286 OP i in context Ci is monotonic w.r.t. kb, if kb \u2286 mng(OP , kb). Intuitively, a set of monotonic operations will not remove content from the knowledge base to which it is applied.\nDefinition 21. Let M = \u3008\u3008C1, . . . ,Cn\u3009, IL,BR\u3009 be an rMCS, KB a configuration of knowledge bases for M and Si = {hd(r) \u2208 OP i | r \u2208 BRi} for all i \u2208 {1, . . . , n}. Then, M is reducible given KB iff, for all i \u2208 {1, . . . , n},\n1. Li is reducible; 2. for all OP \u2286 Si, all kb \u2208 KB i, and all Bi \u2208 BS i:\nredi(mngi(OP , kb), Bi) = mngi(OP , redi(kb, Bi));\n3. for all OP1 \u2286 . . . \u2286 OPm \u2286 Si and all j \u2208 {1, . . . ,m}: OP j is monotonic w.r.t. kbji where\n(a) kb1i = kbi; (b) kbhi = mngi(OP h\u22121, kbh\u22121i ) for h \u2208 {2, . . . ,m}.\nThe second condition essentially requires that no mngi introduce knowledge base formulas that are affected by redi. The third condition in addition checks whether any sequence of increasing sets of (applicable) operations is monotonic, i.e., whether some kbmi can be obtained in a step-wise, monotonic iteration.\nExample 9. Recall Ex. 7. All contexts but Cec build on a monotonic logic, so their logics are automatically reducible. This also means that condition 2. is trivially satisfied for these contexts using the identity function for redi. At the same time, Lec is reducible using the well-known Gelfond-Lifschitz reduct [24], and clearly none of the bridge rules in BRec can introduce any knowledge base formula (for any kb \u2208 KBec) which is affected by such redec. The third condition is a bit more tricky: in fact, e.g., applying setTemp(hot) to {tm(cold)} yields {tm(hot)}, which is clearly not monotonic. This can however be avoided if it is ensured that kbst does not contain information on the temperature. Then, any increasing sequence of operations is monotonic w.r.t. the corresponding kbji (cf. Ex. 2). The same is not true for BRpos which is why we have to omit the bridge rules setPos(P) \u2190 pos::enters(P). in BRpos, thus only preventing the information of Dave changing the room from being available right away. With this slight adjustment, the rMCS in Ex. 7 is in fact reducible.\nFollowing notions from logic programming, we introduce definite rMCSs.\nDefinition 22. LetM = \u3008\u3008C1, . . . ,Cn\u3009, IL,BR\u3009 be a reducible rMCS given KB. Then, M is definite given KB iff, for all i \u2208 {1, . . . , n},\n1. no r \u2208 BRi contains not; 2. for all B \u2208 BS i: kbi = red(kbi, B).\nThus, in a definite rMCS (given KB), the bridge rules are monotonic and all knowledge bases are already reduced. This suggests the following iteration.\nDefinition 23. Let M be a definite rMCS given KB, and I an input for M . For all i \u2208 {1 . . . n}, let kb0i = kbi and define, for each successor ordinal \u03b1+ 1,\nkb\u03b1+1i = mng(app now i (I,B \u03b1), kb\u03b1i ),\nwhere B\u03b1 = \u3008B\u03b11 , . . . , B\u03b1n \u3009 and acci(kb \u03b1 i ) = {B\u03b1i } for any ordinal \u03b1. Furthermore, for each limit ordinal \u03b1, define kb\u03b1i = \u22c3 \u03b2\u2264\u03b1 kb \u03b2 i , and let kb \u221e i = \u22c3 \u03b1>0 kb \u03b1 i .\nWe next show two properties of the iteration defined in Def. 23 that will prove useful subsequently.\nLemma 1. Let M be a definite rMCS given KB, and I an input for M . The following holds for the iteration in Def. 23 for all ordinals \u03b1:\n1. M is definite given KB\u03b1; 2. for any ordinal \u03b2 with \u03b2 \u2264 \u03b1 we have kb\u03b2i \u2286 kb \u03b1 i for i \u2208 {1, . . . , n}.\nPROOF. We have to show that the lemma holds for all ordinals \u03b1. For the (initial) limit ordinal \u03b1 = 0, 1. and 2. hold trivially.\nNow, suppose we have shown that 1. and 2. hold for all ordinals \u03b11 \u2264 \u03b1. First, consider a successor ordinal \u03b1+ 1. Regarding 1., i.e., M being definite given KB\u03b1+1, 1. of Def. 22 holds trivially as the bridge rules are fix, and 2. follows from the fact that all kb\u03b1i are already in reduced form, and from 2. of Def. 21, which prevents the introduction of reducible content by any mngi. Regarding 2., we already know by the hypothesis that this holds for \u03b1, so we only have to show that kb\u03b1i \u2286 kb \u03b1+1 i holds for all i as well. As all acci for the definite rMCS are monotonic, we also know that B\u03b2 \u2286 B\u03b1 holds for all \u03b2 \u2264 \u03b1. In fact, this holds for any of the \u03b2 just as well, i.e., there is an increasing sequence of B\u03b2 associated to the iteration. Now, since the rMCS is definite, hence no negation occurs in bridge rules, and I is fix, the sequence of all appnowi (I,KB \u03b2) for each \u03b2 is also increasing. But then, by 3. of Def. 21, kb\u03b1i \u2286 kb \u03b1+1 i holds for all i. Now consider a limit ordinal \u03b1\u2032 (with \u03b1 \u2264 \u03b1\u2032). Since in this case, all kb\u03b1 \u2032\ni are just the union of all kb\u03b2i with \u03b2 \u2264 \u03b1\u2032, the claims 1. and 2. trivially follow.\nLemma 1 guarantees that the iteration is well-defined and monotonic and we can show that it yields an equilibrium. In fact, it is the unique minimal equilibrium of M given KB and I.\nProposition 6. Let M be a definite rMCS given KB, and I an input for M . Then \u3008B\u221e1 , . . . , B\u221en \u3009 is the unique minimal equilibrium of M given KB and I. We call it grounded equilibrium of M given KB and I, denoted by GE(M,KB, I).\nPROOF. We first note that \u3008B\u221e1 , . . . , B\u221en \u3009 is indeed an equilibrium. This follows directly from the definition of equilibria (Def. 9) and the fact that the fixpoint in Def. 23 precisely matches it.\nConcerning minimality, suppose it is not a minimal equilibrium. Then, there is some \u3008B\u2032, . . . , B\u2032\u3009 which is also an equilibrium s.t. B\u2032i \u2286 B\u221ei for all i \u2208 {1, . . . , n} andB\u2032i \u2282 B\u221ei for at least one i. Therefore some belief b \u2208 B\u221ei \\B\u2032i and a least ordinal\n\u03b1 exist s.t. b \u2208 B\u03b1i . We consider a b where \u03b1 is least for all such beliefs. If \u03b1 = 0, then acci(kb0i ) = B 0 i and since, by Lemma 1, M is definite given KB\n0, this belief set is unique, hence B\u2032 cannot be an equilibrium (following from monotonicity of the iteration). If \u03b1 > 0, then necessarily some operation in a bridge rule head, applied when creating kb\u03b1i , triggered the occurrence of b in acci(kb \u03b1 i ) = B \u03b1 i . Now, as M is definite given all KB\u03b2 in the iteration of KB\u221e and since \u03b1 is least, this head is also applicable by monotonicity w.r.t. B\u2032. Hence, we obtain a contradiction to B\u2032 being an equilibrium.\nRegarding uniqueness, suppose it is a minimal equilibrium, but not unique. Then, there is some \u3008B\u2032, . . . , B\u2032\u3009 which is also a minimal equilibrium such that at least one of the following holds:\n\u2022 neither B\u2032i \u2286 B\u221ei nor B\u221ei \u2286 B\u2032i for at least one i \u2208 {1, . . . , n};\n\u2022 B\u2032i \u2282 B\u221ei and B\u2032j \u2283 B\u221ej for i 6= j with i, j \u2208 {1, . . . , n}.\nIn both cases, consider some b \u2208 B\u221ei \\B\u2032i. Again, there is a least \u03b1 such that b \u2208 B\u03b1i and \u03b1 is least among all these b. We can apply the same argument as used for proving minimality and obtain a contradiction to B\u2032 being an equilibrium.\nAs pointed out in [9], for many logics, kb\u221ei = kb \u03c9 i holds and the iteration even stops after finitely many steps. This is also the case for the slightly revised scenario in Ex. 9. Moreover, as a consequence of Prop. 6, no self-justifications can occur in the grounded equilibrium of definite rMCSs.\nThis fixpoint iteration cannot be applied to arbitrary reducible rMCSs right away as, e.g., not in the bridge rule bodies and non-reduced knowledge bases may allow the removal of already derived information in the iteration. To counter that, we introduce the notion of a reduct for rMCSs where, for a bridge rule of the form (1), bd(r)+ = {a1, . . . , aj}) and bd(r)\u2212 = {aj+1, . . . , am}.\nDefinition 24. LetM = \u3008C, IL, \u3008BR1, . . . ,BRn\u3009\u3009 be a reducible rMCS given KB, I an input forM , and B = \u3008B1, . . . , Bn\u3009 a belief state ofM . The (I,B)-reduct ofM and KB is obtained as M (I,B) = \u3008IL,C, \u3008BR(I,B)1 , . . . ,BR (I,B) n \u3009\u3009 where BR (I,B) i = {hd(r) \u2190 bd(r)+ | r \u2208 BRi,hd(r) = op with op \u2208 OP i, \u3008I,B\u3009 6|= a` for all a` \u2208 bd(r)\u2212} and as KB(I,B) = \u3008kbB11 , . . . , kb Bn n \u3009 where kb Bi i = redi(kbi, Bi).\nNote that bridge rules with an operation under next in its head are ignored here, as these do not affect the computation of the equilibria anyway.\nFor all reducible rMCSs M given KB, all inputs I for M , and all belief states B for M , the (I,B)-reduct of M and KB is definite. In this case, we can check whether B is a grounded equilibrium for M given KB and I in the usual manner.\nDefinition 25. Let M = \u3008C, IL,BR\u3009 be a reducible rMCS given KB, and I an input for M . A belief state B of M is a grounded equilibrium of M given KB and I iff B = GE(M (I,B),KB(I,B), I).\nGrounded equilibria of reducible rMCSs given some KB are also minimal.\nProposition 7. Every grounded equilibrium of a reducible rMCS M given KB and an input I is a minimal equilibrium of M given KB and I.\nPROOF. We first show that a grounded equilibrium B is indeed an equilibrium. For this, note that B is the unique minimal equilibrium of the definite M (I,B) given KB(I,B) and I by Def. 25 and Prop. 6. Thus, by Def. 9 and since M (I,B) is definite, we know for all i \u2208 {1, . . . , n}:\nBi = acci(kb \u2032), where kb\u2032 = mngi(app now i (I,B), kb Bi i ). (4)\nwith kbBii = redi(kbi, Bi) by Def. 24. Now, according to Def. 24, M (I,B) only differs from M on the sets of bridge rules BR(I,B)i , and the way these are obtained from the BRi ensures that appnowi (I,B) is identical for both M and M\n(I,B). Moreover, by 2. of Def. 21, (4) can be rewritten to (for all i):\nBi = acci(kb \u2032), where kb\u2032 = redi(mngi(app now i (I,B), kbi), Bi). (5)\nIn this case, by the definition of red, we know that, (for all i),\nBi \u2208 acci(mngi(appnowi (I,B), kbi) (6)\nand this shows, by Def. 9, that B is an equilibrium. Now suppose that B is not minimal. Then there is an equilibrium B\u2032 = \u3008B\u20321, . . . , B\u2032n\u3009 of M given KB and I such that B\u2032i \u2286 Bi for all i with 1 \u2264 i \u2264 n and B\u2032j ( Bj for some j with j \u2208 {1 . . . n}. Since red is antitonic by definition, we know that redi(kbi, Bi) \u2286 redi(kbi, B\u2032i) holds for all i \u2208 {1, . . . , n}. Also, by Def. 24, BR\n(I,B\u03b1) i \u2286 BR \u2032(I,B\u2032\u03b1) i for all i. It can thus be shown by induction on \u03b1 for the mono-\ntonic iteration in Def. 23 that B\u03b1i \u2286 B\u2032 \u03b1 i holds for all i \u2208 {1, . . . , n}:\n\u2022 \u03b1 = 0: this holds right away by monotonicity of acci for reduced knowledge bases.\n\u2022 Suppose the claim holds for all ordinals \u03b11 \u2264 \u03b1.\n\u2022 Consider a successor ordinal \u03b1 + 1. As BR(I,B \u03b1) i \u2286 BR \u2032(I,B\u2032\u03b1) i holds, and no\nbridge rule contains not due to the reduction, we have, by the induction hypothesis that appnowi (I,B \u03b1) \u2286 appnowi (I,B\u2032 \u03b1\n). Then, since mngi in the iteration cannot remove beliefs (see 3. of Def. 21), we obtain kb\u03b1+1i \u2286 kb \u2032\u03b1+1 i and thus B\u03b1+1i \u2286 B\u2032 \u03b1+1 i .\n\u2022 Consider a limit ordinal \u03b1\u2032 with \u03b1 \u2264 \u03b1\u2032. As the corresponding knowledge bases are simply the union of those of all smaller ordinals, we necessarily have kb\u03b1 \u2032\ni \u2286 kb\u2032 \u03b1\u2032 i , and thus B \u03b1\u2032 i \u2286 B\u2032 \u03b1\u2032 i .\nSince we already know that B is a grounded equilibrium, we have that Bi = B\u221ei for all i. We conclude thatB\u2032j \u2282 B\u2032 \u221e j holds for at least one j \u2208 {1, . . . , n}. Thus, B\u2032 itself cannot be a grounded equilibrium of M given KB and I by Def. 25.\nSo suppose that B\u2032 is an equilibrium, but not grounded. Then we know that, by Def. 9, for all i \u2208 {1, . . . , n}:\nB\u2032i \u2208 acci(kb \u2032), where kb\u2032 = mngi(app now i (I,B \u2032), kbi). (7)\nIn this case, by the definition of red, we have for all i:\nacci(redi(kb \u2032, B\u2032i)) = {B\u2032i} (8)\nTherefore, by 2. of Def. 21:\nacci(mngi(app now i (I,B \u2032), redi(kbi, B \u2032 i))) = {B\u2032i} (9)\nNow, the kb0i used in the iteration of B \u03b1 i are precisely the redi(kbi, B \u2032 i) for all i. As argued in the proof of Lemma 1, the sequence of operations in the iteration is monotonically increasing. We consider two cases. First, the sequence reaches appnowi (I,B\n\u2032). Then, for all OP j \u2286 appnowi (I,B\u2032), acci(mngi(OP j , kb\u03b1i )) \u2286 B\u2032i. As B\u2032j \u2282 B\u2032 \u221e j holds for at least one j \u2208 {1, . . . , n}, the iteration has to continue beyond the step involving appnowi (I,B\n\u2032), but this contradicts B\u2032 being an equilibrium. Alternatively, the sequence does not reach a step with precisely the operations in appnowi (I,B\n\u2032). In this case, there is a least ordinal s.t. an operation not contained in appnowi (I,B\n\u2032) occurs in the iteration, but this again contradicts that B\u2032 is an equilibrium following the argument applied in the proof of Prop. 6.\nGrounded equilibria of reducible rMCSs are not unique equilibria in general. Consider, e.g., again Ex. 8. Then \u3008{b}\u3009 is a grounded equilibrium, while \u3008{a}\u3009 is not. Still, as checking for grounded equilibria relies on the unique grounded equilibrium of the reduct, we know that no self-justifications can occur in grounded equilibria, which is also why \u3008{a}\u3009 is filtered.\nWe can now introduce grounded equilibria streams provided that rMCS M given KB is reducible for each KB occurring in KB. Unfortunately, checking for reducibility cannot be done a priori as the KB will only be known at runtime (due to 3. of Def. 21). To complete the picture, we also spell out under which conditions an initially reducible rMCS given KB remains reducible.\nDefinition 26. Let M = \u3008C, IL,BR\u3009 be a reducible rMCS given KB. Then M is persistently reducible given KB iff for all sequences OP1, . . .OPm with m > 0 and OP j \u2286 {op | next(op) \u2208 hd(r), r \u2208 BRi}, M is reducible given KBj where KB1 = KB and KBj = \u3008kbj1, . . . , kb j n\u3009 for j > 1 with kb j i = mng(OP j\u22121, kbj\u22121i ).\nThus, any reducible rMCS (given some concrete KB) is persistently reducible if applying any arbitrary sequence of the operations under next occurring in the bridge rules yields again a reducible rMCS.\nIt should be noted that checking for reducible rMCSs is not trivial in general and even less so for persistently reducible rMCSs. Still, certain kinds of contexts clearly satisfy the restrictions including those occurring in the example scenario in Ex. 9. Namely, they either store certain pieces of information, but only do change them using next and not otherwise, or their kb is initially empty and this is never changed\nusing next, so information is only stored temporarily for the computation of the current equilibrium. The scenario is thus persistently reducible for any knowledge base configuration which does not store pieces of information in the initial kbi for contexts of the latter kind.\nThis allows us to introduce grounded equilibria streams.\nDefinition 27. Let M = \u3008C, IL,BR\u3009 be a persistently reducible rMCS given KB, I an input stream for M until s, B = \u3008B1, . . . ,Bs\u3009 an equilibria stream of M given KB and I, and KB the configurations stream of M given KB, I, and B. Then, B is a grounded equilibria stream of M given KB and I iff, for each t \u2208 {1 . . . s}, Bt = GE(M (I,B), (KBt)(I,B), It).\nA grounded equilibria stream of some M given KB and I can thus be understood as a stream of grounded equilibria. It is thus straightforward to see that each equilibrium in a grounded equilibria stream is minimal w.r.t. the knowledge base configuration and input of its time point.\nWe remark that the notion of persistently reducible rMCSs substantially differs from reducible MCSs on which the former are founded. On the one hand, permitting operations in mng beyond simple addition, as used already for mMCSs, requires the non-trivial tests for reducible rMCSs, and in addition, persistent reducibility needs to be verified for the dynamic aspect of rMCSs. Thus, these new notions also extend the work in [9] from MCSs to mMCSs.\nFor reducible rMCSs in general, determining grounded equilibria is not deterministic yet, since we have to guess and check the grounded equilibrium in each step. This is why we now introduce the well-founded semantics for reducible rMCSs M following the ideas in [9]. Its definition is based on the operator \u03b3M,KB,I(B) = GE(M (I,B),KB(I,B), I), provided BS i for each logic Li in all the contexts of M has a least element B\u2217i (w.r.t. subset inclusion). Such rMCSs are called normal.\nIt can be shown that \u03b3M,KB,I is antitonic which means that applying \u03b3M,KB,I twice yields a monotonic operator. Hence, by the Knaster-Tarski theorem, (\u03b3M,KB,I)2 has a least fixpoint which determines the well-founded semantics.\nDefinition 28. Let M be a normal, reducible rMCS given KB, and I an input for M . The well-founded model of M given KB and I, denoted WF(M,KB, I), is the least fixpoint of (\u03b3M,KB,I)2.\nStarting with the belief state B\u2217 = \u3008B\u22171 , . . . , B\u2217n\u3009, this fixpoint can be iterated, establishing the relation between WF(M,KB, I) and grounded equilibria of M .\nProposition 8. Let M = \u3008C, IL,BR\u3009 be a normal, reducible rMCS given KB, I an input for M , WF(M,KB, I) = \u3008W1, . . .Wn\u3009, and B = \u3008B1, . . . , Bn\u3009 a grounded equilibrium of M given KB and I. Then Wi \u2286 Bi for i \u2208 {1 . . . n}.\nPROOF. We show the claim by proving that (\u03b3M,KB,I)2 \u2191 \u03b1)i \u2286 Bi holds for all grounded equilibria B of M given KB and I. For the case \u03b1 = 0, this holds trivially, as the initial belief state is B\u2217.\nSuppose the claim holds for all ordinals \u03b11 \u2264 \u03b1. Consider a successor ordinal \u03b1 + 1. If (\u03b3M,KB,I)2 \u2191 \u03b1 = (\u03b3M,KB,I)2 \u2191 (\u03b1 + 1) then the claim trivially holds by the induction hypothesis. Thus, suppose that (\u03b3M,KB,I)2 \u2191 \u03b1 \u2282 (\u03b3M,KB,I)2 \u2191 (\u03b1 + 1), i.e., new beliefs are added in the step \u03b1 + 1 for (at least) some i. Using Def. 23 and the induction hypothesis, it can be shown that these new beliefs are indeed contained in each grounded equilibrium, while all beliefs that do not occur in the intermediate fixpoint of the squared operator are not true in any grounded equilibrium of M given KB and I, in the very same way as usual for the alternating fixpoint, as e.g., for logic programs, on which this construction is based.\nFinally, regarding a limit ordinal \u03b1\u2032 with \u03b1 \u2264 \u03b1\u2032, the claim holds trivially by the induction hypothesis.\nThe well-founded model of M can thus be viewed as the belief state representing what is accepted in all grounded equilibria, even though WF(M,KB, I) may itself not necessarily be a grounded equilibrium. Yet, if the rMCS is acyclic (i.e., no cyclic dependencies over bridge rules exist between beliefs in the rMCS, see Sect. 4), then the grounded equilibrium of M given KB and I is unique and identical to the wellfounded model. This is indeed the case for the scenario in Example 9.\nThe well-founded semantics can be generalized to streams as follows.\nDefinition 29. Let M = \u3008C, IL,BR\u3009 be a normal, persistently reducible rMCS given KB, and I an input stream for M until \u03c4 . The well-founded stream of M given KB and I is a functionWF : [1..\u03c4 ]\u2192 BelM such that\n\u2022 WF t is the well-founded model of M given KBt and It, where KBt is defined as\n\u2013 KB1 = KB \u2013 KBt = updM (KBt\u22121, It\u22121,WF t\u22121), for t > 1.\nClearly, Prop. 8 also generalizes to the well-founded stream (of M given KB and I) including all the made observations. That is, it need not coincide with any (grounded) equilibria stream, unless the rMCS in question is acyclic, in which case the grounded equilibria stream is unique and does coincide with the well-founded stream. Again, this can be verified for the scenario in Example 9."}, {"heading": "6. Complexity", "text": "In this section, we want to analyze the complexity of answering queries over equilibria streams of rMCSs. As our framework has many degrees of freedom, we need to impose some restrictions in order to get meaningful complexity results. In particular, we are only interested in decision problems with input of finite size, since otherwise the decision problem would unfortunately be undecidable right away. Thus, in the following, we only consider finite rMCSs, i.e., we do not consider rule schemas (which stand potentially for an infinite amount of bridge rules), and assume that all knowledge bases in the given rMCS are finite. Also, we restrict our considerations to finite input streams.\nWe start by introducing the two reasoning problems we consider.\nDefinition 30. The problem Q\u2203, respectively Q\u2200, is deciding whether for a given finite rMCS M , a belief b for the k-th context of M , a configuration of knowledge bases KB forM , and an input stream I until \u03c4 , it holds that b \u2208 Bk for someBt = \u3008B1, . . . , Bn\u3009, (1 \u2264 t \u2264 \u03c4 ), for some, respectively all, equilibria stream(s) B given KB and I.\nAs the complexity of an rMCS depends on that of its individual contexts, we introduce the notion of context complexity (cf. [14]). To do so, we need to focus on relevant parts of belief sets by means of projection. Intuitively, among all beliefs, we only need to consider belief b that we want to query and the beliefs that contribute to the application of bridge rules for deciding Q\u2203 or Q\u2200. Given M , b, k, and I as in Definition 30, the set of relevant beliefs for a context Ci of M is given by\nRBi(M,k:b) ={b\u2032 | r \u2208 BRh, i:b\u2032 \u2208 bd(r) \u2228 not i:b\u2032 \u2208 bd(r), h \u2208 {1 . . . , n}}\u222a {b | k = i}.\nThen, a projected belief state for M and k:b is a tuple\nBk:b|M = \u3008B1 \u2229RB1(M,k:b), . . . , Bn \u2229RBn(M,k:b)\u3009\nwhere B = \u3008B1, . . . , Bn\u3009 is a belief state forM . If B is an equilibrium, then we call this tuple projected equilibrium. The context complexity of Ci in M with respect to k:b for a fixed input I is the complexity of deciding the context problem of Ci, that is, whether for a given projected belief state B = \u3008B1, . . . , Bn\u3009 forM and k:b, there is some belief set B\u2032i for Ci with Bi = B \u2032 i \u2229 RBi(M,k:b) and B\u2032i \u2208 acci(mngi(appi(I,B), kbi)). The context complexity CC(M,k:b) of an entire rMCS is a (smallest) upper bound for the context complexity classes of its contexts.\nTheorem 1. Table 1 summarizes the complexities of membership of problems Q\u2203 and Q\u2200 for finite input steams (until some \u03c4 \u2208 N) depending on the context complexity. Hardness also holds if it holds for the context complexity.\nPROOF. The membership results for theQ\u2203 cases (with the exception of CC(M,k:b) = EXPTIME) can be argued for as follows: a non-deterministic Turing machine can be used to guess a projected belief state Bt = \u3008B1, . . . , Bn\u3009 for all \u03c4 inputs in I in polynomial time. Then, iteratively for each of the consecutive inputs It, first the context problems can be solved either polynomially or using an oracle for the context complexity (the guess of Bt and the oracle guess can be combined which explains why we stay on the same complexity level for higher context complexity). If the answer is \u2019yes\u2019, Bt is the projected equilibrium. We can check whether b \u2208 Bi, compute the updated knowledge bases and continue the iteration until reaching the last input. For PSPACE the same line of argumentation holds as PSPACE = NPSPACE. In the case of CC(M,k:b) = EXPTIME, we iterate through the exponentially many projected belief states for which we solve the context problem in exponential time and proceed as before. The argument is similar for the co-problem of Q\u2200. Hardness holds because being able to solve Q\u2203, respectively the co-problem of Q\u2200, one can decide equilibrium existence for managed MCSs which is hard for the same complexity classes [10] given hardness for the context complexity of the managed MCS."}, {"heading": "EXPTIME EXPTIME EXPTIME", "text": "These results can also be used to show the complexity results of a strongly related problem, namely ensuring that a certain belief does always hold over all time instants for some or all equilibria streams. This can be achieved by simply considering the coproblem of ensuring that the negated belief does not hold at any time instant for some or all equilibria streams. In case the considered belief set itself does not allow us expressing this negated belief, an appropriate additional auxiliary context with adequate bridge rules can be used to represent it and query for it.\nNote that allowing for input streams of infinite length leads to undecidability.\nProposition 9. Given a finite rMCS M , the problems Q\u2203 and Q\u2200 are undecidable for infinite input streams (when \u03c4 =\u221e).\nThe reason is that rMCSs are expressive enough (even with very simple context logics) to simulate a Turing machine such that deciding Q\u2203 or Q\u2200 for infinite runs solves the halting problem. We provide an rMCS that implements a Turing machine service in Appendix A: a fixed rMCS can read the configuration of a Turing machine TM as well as the corresponding input and then simulate a run of TM on that input.\nFor persistently reducible rMCSs, it turns out that the complexity results for the analog problems Q\u2203g and Q \u2200 g on grounded equilibria streams are identical to Q\n\u2203 and Q\u2200 on equilibria streams.\nTheorem 2. Let M = \u3008C, IL,BR\u3009 be a finite, persistently reducible rMCS given KB. Then membership and hardness results for Q\u2203g and Q \u2200 g on grounded equilibria streams for finite input streams coincide with those for Q\u2203 and Q\u2200 in Theorem 1.\nPROOF. As M is assumed to be finite and persistently reducible, the argument is exactly identical to that of Theorem 1. The only difference is here that we also have to guess the intermediate belief states in the iteration, but this does not raise the (worstcase) complexity itself.\nNote that this only holds if checking whether M is persistently reducible is already known/can be neglected. While such assumption is a strong one in general, in Section 5 it is argued that this can be done easily for contexts of certain kinds, including the ones used in the example scenario 7 (and 9).\nRegarding the well-founded stream, we can restrict our attention to the problem Q\u2203wf for the well-founded stream, since it coincides with Q \u2200 wf for the unique wellfounded stream, and to polynomial contexts given the motivation for the well-founded stream.\nTheorem 3. Let M = \u3008C, IL,BR\u3009 be a finite, normal, persistently reducible rMCS given KB such that CC(M,k:b) = P for Q\u2203wf . Then, Q\u2203wf is in P. In addition, hardness holds provided CC(M,k:b) = P is hard.\nPROOF. If CC(M,k:b) = P, then deciding all context problems is polynomial. Also, no guessing of equilibria is required, as each equilibrium can be computed iteratively in polynomial time starting from the belief state containing all least elements of each belief set. Since the context complexity also determines the complexity of performing the update function to obtain the new configuration of knowledge bases, we conclude that the result holds. The result for hardness follows in the same manner as in in the proofs of Theorems 1 and 2.\nThis result, together with the observation that the well-founded stream coincides with the unique grounded equilibrium stream until s, allows us to verify that computing the results in our use case scenario in Example 7 can be done in polynomial time."}, {"heading": "7. Related Work", "text": "Several systems and frameworks for modeling the dynamics of knowledge and the flow of information have been developed. These systems are obviously related to reactive multi-context systems. In this section we provide a comparison with those approaches we consider most relevant, stressing differences as well as commonalities with rMCSs. Note that we focus entirely on dynamic approaches and do not include systems which handle heterogeneous information in a static setting. An interesting example of the latter type are Lierler and Truszczyn\u0301ski\u2019s abstract modular systems [32]. In a nutshell, modular systems realize the communication between different reasoning modules through joint vocabularies rather than bridge rules. These systems are best viewed as alternatives to classical MCSs. It is an open question how to adapt them to a dynamic setting.\nSince rMCSs have been designed for applications involving stream reasoning, we will first consider two recent approaches for stream reasoning, namely LARS [7] and STARQL [36]. Then, we establish the relationship to EVOLP [2], a framework that focuses on dynamics in the form of updates in the restricted setting of generalized logic programs building on similar notions as the operator next used for rMCSs. Moreover, we compare our formalism with asynchronous multi-context systems [18], as well as with reactive ASP [23, 8].\n7.1. Reactive Multi-Context Systems and Stream Reasoning\nReasoning over streaming data is a topic of increasing interest. Key driver is the central role that streams play in current endeavors towards the Internet of Things, the Internet of Services, as well as the vision of a fourth industrial revolution. Stream\nreasoning has been a prominent issue in the Semantic Web community for several years,4 and has also received substantial attention by researchers from areas such as Knowledge Representation and Reasoning and Databases lately [17].\nWe consider rMCSs to be a well-suited formalism for stream reasoning that addresses important challenges that naturally arise in this context. One important benefit of rMCSs is that their managing capabilities provide a dynamic way to decide which data to keep for future reasoning and which data to drop. In this respect, rMCSs offer greater flexibility than sliding-window approaches. Nevertheless, as also demonstrated in Section 3, rMCSs can be used to implement windowing techniques. In the following, we relate rMCSs to two recently proposed frameworks [7, 36] for stream reasoning by demonstrating how tasks suited for these approaches can be solved by an rMCS. Here, we focus at presenting the intuition on how problems can be modeled in the different approaches rather than presenting formal translations between them. As all the involved frameworks are quite general, it would only make sense to look at technical mappings for well-defined restrictions of the general settings, which would limit their value for a general comparison. Moreover, such formal translations would have to mainly deal with bridging technical differences in semantics (e.g., between the equilibrium semantics of rMCS and the FLP semantics used in [7]) rather than giving insight into how we can model stream reasoning tasks in the respective approaches."}, {"heading": "LARS", "text": "The Logic-based framework for Analyzing Reasoning over Streams (LARS) [7] aims at providing a formal declarative logical language for reasoning with streams. LARS is a rule-based formalism, whose language features not only provide different means to refer to or abstract from time, but also a novel window operator, thus providing a flexible mechanism to represent and reason with views on streaming data. Next, we give an overview of this language and show how to run LARS within an rMCS.\nThe LARS language is built over a set of atoms A defined over disjoint sets of predicates P and constants C as usual, where P is divided into two disjoint subsets, the extensional predicates PE , and the intensional predicates PI . The former is intended to be used for input streams, and the latter for intermediate and output streams.\nGiven i, j \u2208 N, an interval is a set of the form [i, j] = {k \u2208 N | i \u2264 k \u2264 j}. An evaluation function over an interval T is a function v : N \u2192 2A such that v(t) = \u2205 if t /\u2208 T . Then, a stream in LARS is a tuple s = \u3008T, v\u3009, where T is an interval and v is an evaluation function over T . A stream is a data stream if it contains only extensional atoms. A stream S = \u3008T, v\u3009 is a substream of a stream S\u2032 = \u3008T \u2032, v\u2032\u3009, denoted by S \u2286 S\u2032, if T \u2286 T \u2032 and v(t) \u2286 v\u2032(t) for all t \u2208 T .\nThe formulas of LARS are defined using the following grammar:\n\u03b1 := a | \u00ac\u03b1 | \u03b1 \u2227 \u03b1 | \u03b1 \u2228 \u03b1 | \u03b1\u2192 \u03b1 | \u2666\u03b1 | \u03b1 | @t\u03b1 | x\u03b9\nwhere a \u2208 A and t \u2208 N. The connectives \u00ac,\u2227,\u2228 and \u2192 are the usual classical connectives. Similarly to modal logics, the operators \u2666 and are used to represent\n4cf. http://streamreasoning.org\nthat a formula holds for some and for each time instant within some interval for a given stream, respectively. The exact operator @t represents the reference to some specific time t \u2208 N, and window operators of the form x\u03b9 allow focusing on more recent substreams, where \u03b9 represents the type of window and x the tuple of parameters for the respective type. Among the operators presented in [7] are, for example, time-based operators n\u03c4 , which allow focusing on the last n time instants of a given stream, or the partition-based operators idx,np , which first split the stream into substreams and then allow focusing on the last n tuples of a particular substream. LARS programs are based on rules composed of such LARS formulas in a way similar to those in logic programming. More precisely, a LARS rule is of the form\n\u03b1\u2190 \u03b21, . . . , \u03b2j ,not \u03b2j+1, . . . ,not \u03b2n\nwhere \u03b1, \u03b21, . . . , \u03b2n are formulas and \u03b1 contains only intentional predicates. Consider a simplified version of the example in [7] that models a scenario where we want to reason about a tram network, including, for example, the prediction of the expected arrival time of a tram at some stop. The key idea is that such information should not only depend on a fixed timetable, but also dynamically on real-time information about the arrival time at a previous stop and the expected travel time between stations (which heavily depends on real-time traffic jam information). LARS allows such combination of static knowledge with a stream of information. Here, static knowledge is composed of atoms of the form plan(L,X ,Y ,T ), where L is the line identifier, X and Y are consecutive tram stops on line L, and T is the expected travel time between X and Y , and atoms of the form line(Id ,L) mean that the tram Id operates on line L. The stream of information contains atoms of the form tram(Id ,X ) meaning that tram Id is at stop X , and atoms of the form jam(X ) meaning that there is a traffic jam near station X . Consider the following example of a LARS rule:\n@T exp(Id ,Y )\u2190 idx,1p @T1tram(Id ,X ), line(Id ,L), not 20\u03c4 \u2666jam(X ), plan(L,X ,Y ,Z ), T = T1 + Z.\nThe intuitive idea of the above rule is that the tram is expected to arrive at stop Y at time T whenever five conditions are met: i) the fact that tram Id stopped at X at time T1 is the last information about stops of Id in the stream; ii) X and Y are consecutive stops of line L; iii) T \u2212 T1 is the travel time between X and Y ; iv) the tram Id is operating on line L; and v) there is no information about traffic jams near station X within the last 20 minutes. Note that the use of default negation not allows for the representation of exceptions, whereas the partition-based operator idx,1p allows for the focus on the last item of the form tram(X ) in the stream, and the time-based operator 20\u03c4 allows for the focus on the last 20 time instants of the stream.\nThe semantics of LARS is based on the FLP semantics of logic programs [19]. Given an input stream D = \u3008T, v\u3009 and time point t \u2208 T , each LARS program P is associated with a set of streams, the answer streams ofP forD at t. Since the semantics of a LARS program is defined for a fixed input data stream and for a particular time point, it is in fact mainly static.\nWe now describe how rMCSs can be used to run a LARS program over a (possibly infinite) input stream. The idea is to define an rMCS with a LARS context and a recent\nsubstream of a (possibly infinite) input stream (in the sense of rMCSs). At each time point, the knowledge base of the LARS context contains the LARS program and the relevant substream of the input stream. Then, the answer streams of the program given the available data stream and the current time point can be computed.\nMore precisely, we assume fixed sets of predicates P and constants C, a fixed window size w \u2208 N and a LARS program P overA, the set of atoms obtained from P and C. Let AE be the set of atoms that include only extensional predicates from PE , and AT be the set of time-tagged atoms, i.e., AT = {\u3008a, t\u3009 | a \u2208 A and t \u2208 N}.\nConsider the rMCS M = \u3008\u3008CLARS\u3009, \u3008IL1, Clock\u3009, \u3008BRCLARS\u3009\u3009 obtained from P and w in the following way:\n\u2022 CLARS = \u3008L,OP ,mng\u3009 where\n\u2022 L = \u3008KB ,BS ,acc\u3009 is such that\n\u2022 KB = {P \u222aA \u222a {now(t)} | A \u2286 AT and t \u2208 N}\n\u2022 BS = {S | S is a stream for A}\n\u2022 acc(kb) = {S | S is an answer stream of P for Dkb at time tkb}\n\u2013 tkb = t such that now(t) \u2208 kb \u2013 T kb = [tkb \u2212 w, tkb] \u2013 vkb(t) = {a | \u3008a, t\u3009 \u2208 kb}, for each t \u2208 N \u2013 Dkb = \u3008T kb, vkb\u3009\n\u2022 OP = {add(\u03b4) | \u03b4 \u2208 AT } \u222a {del(\u03b4) | \u03b4 \u2208 AT } \u222a {add(now(t)) | t \u2208 N}\n\u2022 mng(kb, op) = (kb \u222a {\u03b4 | add(\u03b4) \u2208 op}) \\ {\u03b4 | del(\u03b4) \u2208 op}\n\u2022 IL1 = AE\n\u2022 Clock = N\n\u2022 BRCLARS contains the following rules for managing history:\nadd(now(T ))\u2190 clock::T add(\u3008A, T \u3009)\u2190 1::A, clock::T del(\u3008A, T \u3009)\u2190 clock::T \u2032, T < T \u2032 \u2212 w next(add(\u3008A, T \u3009))\u2190 1::A, clock::T next(del(\u3008A, T \u3009))\u2190 clock::T \u2032, T \u2264 T \u2032 \u2212 w\nGiven an input stream I for M and a time point t \u2208 N, we consider tIt , the unique element of stream Clock at step t, which represents the current time at step t. We also consider the LARS input data stream at time t,DIt = \u3008T, v\u3009, such that T = [tIt \u2212w, tIt ] and v(t\u2032) = {a \u2208 AE | there exists t\u2032\u2032 \u2264 t such that t\u2032 = tIt\u2032\u2032 and a \u2208 It \u2032\u2032\n1 } for t\u2032 \u2208 T , and v(t\u2032) = \u2205 otherwise. Then, given an input stream I for M , at each time point\nt \u2208 N, each equilibria stream B for M given KB = \u3008{P}\u3009 and I is composed of an answer stream of P for DIt at time t I t .\nNote that at each time instant the knowledge base contains only the relevant part of the (possibly infinite) input stream, meaning that information no longer valid is really discarded, and that the current time, given by the stream Clock, is decoupled from the time steps at which equilibria are evaluated. For the sake of presentation, we have assumed a fixed time window w, yet an extension in the spirit of what we presented in Section 3.5 can easily be imagined."}, {"heading": "STARQL", "text": "STARQL (pronounced Star-Q-L) [36], a framework for ontology-based stream reasoning, is developed within the Optique Project [37] that comes with a stream query language inspired by the RDF query language SPARQL [29]. Streams in this framework come in the form of timestamped Description Logic assertions (called ABox assertions). Both, input as well as answers of STARQL queries are streams of this kind. Unlike the related language continuous SPARQL (C-SPARQL) [6], STARQL goes beyond RDF semantics and allows for DL reasoning.\nA STARQL select expression is structured as follows.\nSELECT selectClause(~x, ~y) FROM listOfWindowedStreamExpressions USING listOfResources"}, {"heading": "WHERE \u03a8(~x)", "text": "SEQUENCE BY seqMethod HAVING \u03a6(~x, ~y)\nFor a comprehensive description of syntax and semantics of STARQL, we refer to Optique Deliverable 5.1 [36]. We make use of an example (partly taken from [36]) to explain components of STARQL queries and to describe the core aspects that are relevant for us. It is based on the following STARQL query that creates an output stream S_out that indicates temperature sensors whose readings were monotonically increasing for the past two seconds."}, {"heading": "CREATE STREAM S_out AS", "text": ""}, {"heading": "SELECT {?sens rdf:type MonIncTemp}<NOW>", "text": "FROM S 0s<-[NOW-2s, NOW]->1s USING STATIC ABOX <\\protect\\vrule width0pt\\protect\\href{http://example.org/Astatic}{http://example.org/Astatic}>,\nTBOX <\\protect\\vrule width0pt\\protect\\href{http://example.org/TBox}{http://example.org/TBox}> WHERE { ?sens rdf:type TempSensor } SEQUENCE BY StdSeq AS SEQ1 HAVING FORALL i<= j in SEQ1 ,x,y:"}, {"heading": "IF ( { ?sens rd ?x }<i> AND { ?sens rd ?y }<j> )", "text": "THEN ?x <= ?y\nThe considered input stream contains readings of sensors s0, s1:\nS = {rd(s0, 90)\u30080s\u3009 rd(s1, 30)\u30080s\u3009 rd(s0, 93)\u30081s\u3009 rd(s1, 32)\u30081s\u3009 rd(s0, 94)\u30082s\u3009 rd(s0, 91)\u30083s\u3009 rd(s0, 93)\u30084s\u3009 rd(s0, 95)\u30085s\u3009}\nIn addition, the TBox at http://example.org/TBox contains the axiom"}, {"heading": "BurnerTipTempSensor v TempSensor", "text": "stating that every BurnerTipTempSensor is a temperature sensor, and the ABox at http://example.org/Astatic contains the assertion\nBurnerTipTempSensor(s0)\nstating that s0 is of type BurnerTipTempSensor . The other sensor s1 is thus not (derivable to be) a temperature sensor.\nTaking S as input, the query returns the output stream, represented here as a sequence of timestamped ABox assertions:\nSout = {MonIncTemp(s0)\u30080s\u3009 MonIncTemp(s0)\u30081s\u3009 MonIncTemp(s0)\u30082s\u3009 MonIncTemp(s0)\u30085s\u3009}\nWe observe that temperature sensor s0 had two seconds of monotonic readings at time points 0s, 1s, 2s, and 5s. The FROM part of the query specifies that we consider S as input where the window expression 0s<-[NOW-2s, NOW]->1s states that, at time point t of the evaluation, we are interested in assertions with a time stamp between t \u2212 2s and t. The slide parameter (specified by ->1s) expresses that every second the window moves forward in time. We also assume a pulse of one second, i.e., one query evaluation per second. In STARQL, such a pulse can be defined by a pulse expression declared separately from the SELECT query. The so-called slack parameter for handling out-of-order stream assertions is assumed to be zero (0s<-) and not used in the initial version of STARQL.\nThe input stream data that falls into the window is gathered in a temporal ABox, i.e., a set of timestamped ABox assertions:\nTime Temporal ABox 0s {rd(s0, 90)\u30080s\u3009, rd(s1, 30)\u30080s\u3009} 1s {rd(s0, 90)\u30080s\u3009, rd(s1, 30)\u30080s\u3009, rd(s0, 93)\u30081s\u3009, rd(s1, 32)\u30081s\u3009} 2s {rd(s0, 90)\u30080s\u3009, rd(s1, 30)\u30080s\u3009, rd(s0, 93)\u30081s\u3009, rd(s1, 32)\u30081s\u3009, rd(s0, 94)\u30082s\u3009} 3s {rd(s0, 93)\u30081s\u3009, rd(s1, 32)\u30081s\u3009, rd(s0, 94)\u30082s\u3009, rd(s0, 91)\u30083s\u3009} 4s {rd(s0, 94)\u30082s\u3009, rd(s0, 91)\u30083s\u3009, rd(s0, 93)\u30084s\u3009} 5s {rd(s0, 91)\u30083s\u3009, rd(s0, 93)\u30084s\u3009, rd(s0, 95)\u30085s\u3009}\nVariable bindings for ~x in the condition \u03a8(~x) of the WHERE clause of a query are determined by finding the certain answers for ~x with respect to the ontology formed by the static ABoxes and TBoxes provided by the USING clause. In our example, that means that the variable ?sens is bound to the sensor named s0, because the TBox at http://example.org/TBox together with ABox http://example.org/ Astatic identify only this sensor to be a temperature sensor.\nThe SEQUENCE directive of the query defines how to cluster the information in the temporal ABox obtained as above into a sequence of ABoxes. In the basic STARQL version, the only method for doing so is StdSeq which separates the assertions based on their timestamp. For example, at time 2s we get a sequence of three ABoxes: {rd(s0, 90), rd(s1, 30)}\u30081\u3009, {rd(s0, 93), rd(s1, 32)}\u30082\u3009, and {rd(s0, 94)\u30083\u3009}. Note that the absolute timestamps are replaced by natural numbers marking the ordinal position of the ABox in the sequence.\nThe HAVING clause of the query specifies a condition \u03a6(~x, ~y) that has to hold for this sequence of ABoxes, taking also the ontology parts from the USING clause into consideration. The variables in ~x have already been bound by the WHERE clause, so here ?sens is being bound to s0. The HAVING condition can either bind the remaining open variables in ~y or, as in the example, act as a boolean condition when there are no further open variables. Here, the condition is true if, for all numbers i, j of the sequence (that is from {1, 2, 3}) with i \u2264 j, the condition holds that if there are sensor readings of s0 in the ABoxes with sequence positions i and j, then the reading in ABox i is smaller or equal than that of ABox j.\nFinally, the expression following the SELECT keyword determines the form of the output stream. For every evaluation time in which the HAVING clause holds, an ABox assertion in the form of an RDF triple {?sens rdf:type MonIncTemp}<NOW> augmented with a timestamp is returned where ?sens is replaced by s0 and NOW by the evaluation time.\nWe want to illustrate next how STARQL queries can be realized as rMCSs. Certainly, due to the abstract nature of rMCSs, there are many different ways to do so. Here, we aim at a setting where we assume a correspondence of one equibrium computation per STARQL query evaluation, i.e., in our example there is one equibrium evaluation per second. We assume one rMCS input stream IS that corresponds to the STARQL input stream and one rMCS input stream Ic that provides the current time as in Section 3.3. The data in IS can either be timestamped assertions such as in the original STARQL approach, or unstamped raw data (such as pure sensor values) that will be automatically time-stamped by bridge rules using the current time provided by Ic. While in the former approach it is possible to have timestamps in the current input that differs from the current time, such a situation is avoided with unstamped data. Both variants have their place and purpose. Here, we assume unstamped data.\nWe reserve one rMCS context CtA for the temporal ABox containing the data currently in the window. Its bridge rules add new data from IS and timestamp it similar as in Section 3.3. Moreover, other bridge rules ensure that data not \u201cvisible\u201d in the window is deleted from CtA.\nThere is one context Cw that computes the variable bindings of the WHERE clause. Its knowledge base is a description logic ontology and its bridge rules import assertions and axioms according to the USING clause of the STARQL query. Thus, we\nassume that each static ABox and TBox mentioned in the query is available in a corresponding storage context of the rMCS. These axioms and assertions are also imported to DL contexts for evaluating the HAVING clause: we assume as many such contexts as there can be ABoxes in the sequence of ABoxes created by the SEQUENCE statement. In our example, we have three contexts of this type because there are assertions with at most three different timestamps in the temporal ABox representing the current window. Thus, the sequence operator StdSeq generates ABox sequences of at most size three. The reasoning contexts evaluate the different timepoints in the window. Fore example, the i-th context computes assignments for variable ?x of the expression { ?sens rd ?x }<i>. We still need to reason on top of the results for the individual DL contexts for fully evaluating the HAVING clause: In the example, this is the evaluation of the FORALL condition that ranges over different time points. This can be done with another context Cr that also combines the results of the WHERE and HAVING clauses and produces output as specified in the SELECT statement. Thus, in an equilibrium for time t, the belief set for Cr contains timestamped RDF triples of form {s0 rdf:type MonIncTemp}<t> whenever s0 had monotonically increasing readings during the previous two seconds."}, {"heading": "7.2. EVOLP", "text": "The framework of evolving logic programs EVOLP [2] is a powerful approach for modeling updates of (propositional) generalized logic programs. Here, we show that\nrMCSs are expressive enough to capture EVOLP as a particular case. We assume a basic familiarity with logic programs as such, and only point out that a general logic program is a set of logic program rules that allow default negation in the head. Evolving logic programs are then defined as general logic programs built over a special language which allows them to express self-evolution. The language includes a reserved unary predicate, assert, whose argument may itself be a full-blown rule, thus making arbitrary nesting possible. Formally, given a propositional language L, the extended language Lassert over L is defined inductively as follows:\n1. All propositional atoms in L are atoms in Lassert; 2. if R is a rule over Lassert then assert(R) is an atom in Lassert; 3. nothing else is an atom in Lassert.\nAn evolving logic program over L is a generalized logic program over Lassert. We denote byRL the set of all rules over Lassert.\nThe idea of EVOLP is that programs can update their own rules thus describing their possible self-evolution. Each self-evolution can be represented by a sequence of programs, each program corresponding to a state, and these sequences of programs can be treated as in Dynamic Logic Programs (DLPs) [1]. Dynamic logic programs are sequences P1 \u2295 . . .\u2295 Pn of generalized logic programs, whose semantics is based on the causal rejection principle. The idea is that the most recent rules are put in force, (where Pn is to be seen as the most recent set of rules), and the previous rules are valid as far as possible, i.e., they are only kept if they do not conflict with more recent rules. Here, these intuitions about DLPs are sufficient, and we point to [1] for more details.\nThe semantics of evolving logic programs is based on sequences of interpretations. More precisely, an evolution interpretation of length m of an evolving logic program P over a propositional language L is a finite sequence I = \u3008I1, . . . , Im\u3009 of sets of propositional atoms of Lassert. The evolution trace associated with an evolution interpretation I is the sequence of programs PI = \u3008P 1, . . . , Pm\u3009 such that P 1 = P and, for each 2 \u2264 j \u2264 m, P j = {r | assert(r) \u2208 Ij\u22121}.\nGiven an evolving logic program, the main intuition for the construction of a sequence of programs that corresponds to a possible evolution of P is that whenever an atom assert(r) belongs to an interpretation in a sequence, then the rule r must belong to the program in the next state.\nBesides self-evolution, evolving logic programs also consider evolution caused by the addition of external rules. These rules, called events, are represented as a sequence of evolving logic programs. Given an evolving logic program P over L, such an event sequence over P is a sequence of evolving logic programs over L.\nThis leads to the central model notion of evolving logic programs that also takes into account an incoming event sequence. Let P be an evolving logic program over L, I = \u3008I1, . . . , Im\u3009 an evolution interpretation of length m of P with evolution trace PI = \u3008P 1, . . . , Pm\u3009, and E = \u3008E1, . . . , E`\u3009 an event sequence over P such that ` \u2265 m. Then, I is an evolution stable model of P given E iff for every 1 \u2264 j \u2264 m, we have that Ij is a stable model of P 1 \u2295 P 2 \u2295 . . .\u2295 (P j \u222a Ej).\nWe now show how EVOLP can be captured in the framework of rMCSs. For that, given an evolving logic program P we aim to construct an rMCS MP whose equilibria\nstreams corresponds to the evolution stable models of P . First of all, note that the events in EVOLP can be modeled by the input streams of rMCSs.\nThe intuitive idea for the construction of MP is that, at each instant, the incoming events are temporarily added to a knowledge base. To keep track of these, we consider a context C, whose possible knowledge bases are pairs. The first component of such is to keep track of the sequence of programs P 1 \u2295 . . .\u2295 P j , which corresponds to the trace of an interpretation until the current instant, and the second component is reserved for the current event Ej . Given this intuition, it is clear that acc(\u3008P 1 \u2295 . . .\u2295 P j , E\u3009) should be defined as the set of stable models of P 1\u2295. . .\u2295P j\u22121\u2295(P j\u222aE). To incorporate events, we consider an input language IL of MP defined precisely as the language of events, i.e., the set of evolving logic programs. Moreover, context C contains bridge rules to access the current events, which are then used to update the event\u2019s component of the knowledge base. Also, context C has bridge rules designated to guarantee that the formulas that occur under the predicate assert at the current instant are used to update the knowledge base in the next instant. Finally, the management function mng of C is such that mng(op, \u3008P,E\u3009) updates the program sequence component or the event component depending on whether op is a set of asserts, or a set of events, respectively.\nFormally, let P be an evolving logic program, and consider the following rMCS MP = \u3008\u3008C \u3009, \u3008IL\u3009, \u3008BRC \u3009\u3009 where\n\u2022 C = \u3008L,OP ,mng\u3009 such that\n\u2022 L = \u3008KB ,BS ,acc\u3009 is a logic such that\n\u2022 KB is the set of pairs \u3008D,E\u3009 where D is a dynamic logic program over L, and E is an evolving logic program over L\n\u2022 BS is the set of all subsets of Lassert\n\u2022 acc(\u3008P 1 \u2295 . . .\u2295 P j , E\u3009) is the set of stable models of P 1\u2295 . . .\u2295P j\u22121\u2295(P j\u222a E)\n\u2022 OP = {as(r) | r \u2208 RL} \u222a {ob(r) | r \u2208 RL}\n\u2022 mng(op, \u3008D,E\u3009) = {\u3008D \u2295 U,E\u2032\u3009} where U = {r \u2208 RL | as(r) \u2208 op} and E\u2032 = {r \u2208 RL | ob(r) \u2208 op}\n\u2022 IL = RL\n\u2022 BRC = {next(as(s))\u2190 1:assert(s) | assert(s) \u2208 Lassert} \u222a {ob(s)\u2190 1::s | s \u2208 IL}\nEvolution stable models of P are strongly related to the equilibria streams of MP . Namely, given an event sequence E = \u3008E1, . . . , E`\u3009 over P consider its associated input stream IE = \u3008\u3008E1\u3009, . . . , \u3008E`\u3009\u3009. Then, I = \u3008I1, . . . , I`\u3009 is a evolution stable model of P given E iff I is an equilibria stream for MP given KB = \u3008\u3008P, \u2205\u3009\u3009 and IE .\nThis coincidence between evolution stable models in EVOLP and equilibria streams for rMCSs as defined above can be explained by the fact that, conceptionally, the operators next() and assert are rather similar.\n7.3. Reactive ASP\nClosely related to EVOLP are the two frameworks of Reactive ASP, one implemented as a solver oclingo [23] and one described in [8]. The system oclingo extends an ASP solver for handling external modules provided at runtime by a controller. The output of these external modules can be seen as the observations of EVOLP. Unlike the observations in EVOLP, which can be rules, external modules in oclingo are restricted to produce atoms so the evolving capabilities are very restricted. On the other hand, oclingo permits committing to a specific answer set at each state for the sake of efficiency, a feature that is not part of EVOLP. Reactive ASP as described in [8] can be seen as a more straightforward generalization of EVOLP where operations other than assert for self-updating a program are permitted. Since EVOLP can be captured by rMCSs, and since rMCSs permit several (evolution) operations in the head of bridge rules, it should be clear that Reactive ASP as described in [8] can be captured by rMCSs.\n7.4. Asynchronous Multi-Context Systems\nAsynchronous multi-context systems (aMCSs) are a framework for loosely coupling knowledge representation formalisms and services [18]. Like rMCSs, they consist of heterogeneous contexts and are aware of continuous streams of information. However, the semantics of aMCSs is not defined in terms of equilibria but every context delivers output whenever available. Intuitively, equilibria realize a tight integration approach in which the semantics of the individual contexts are interdependent at each time point, while aMCSs do not reach this high level of integration. Rather, contexts communicate with each other by means of input and output streams over time. Consequently, instead of bridge rules that depend on system-wide equilibria, aMCSs use output rules that define which information should be sent to another context or an output stream of the overall system based on a result of a single context.\nA further difference is the role of non-determinism in the semantics of aMCSs and rMCSs. While multiple equilibria give rise to non-determinism at each step in a run, for aMCSs, all accepted belief sets of a context are computed in a consecutive way. Nevertheless, there is also a source of non-determinism in the case of aMCSs. The durations of computations and communication are taken into consideration in aMCS but their lengths are left open. Thus, the order in which contexts finish their computation can influence the system and resulting knowledge bases.\nFinally, both aMCSs and rMCSs are very general frameworks that allow for simulating Turing machines (cf. Appendix A) and thus for performing multi-purpose computations. A setup to simulate an rMCS by an aMCS has been presented in [18]."}, {"heading": "8. Conclusions", "text": "In this paper, we have introduced reactive Multi-Context Systems (rMCSs), an adaptation of multi-context systems suitable for continuous reasoning in dynamic environments, with the objective to achieve two goals at the same time: integrating heterogeneous knowledge sources and opening knowledge-based systems for dynamic scenarios in the presence of incoming information. For addressing the first goal, we have built rMCSs upon managed multi-context systems, inheriting their functionality for\nintegrating heterogeneous knowledge sources, admitting also relevant operations on knowledge bases. To accommodate the dynamic aspects, rMCSs are equipped with several extensions. For one, bridge rules in our framework allow for input atoms to incorporate the information of multiple external streams of data. Moreover, contrary to standard MCSs which possess only one type of bridge rules modeling the information flow which needs to be taken into account when equilibria are computed (or the operations that need to be applied in case of mMCSs), rMCS have an additional, different type of bridge rules, distinguished by the occurrence of the operator next in the head. These rules are used to specify how the configuration of knowledge bases evolves whenever an equilibrium was computed providing the definition of equilibria streams which define the semantics of rMCSs over time.\nThe resulting formalism is indeed very expressive offering the capabilities to model the integration of heterogeneous knowledge in the presence of incoming information in different dynamic scenarios. Based on a running example dealing with assisted living, we have demonstrated how to model such different dynamic scenarios using rMCSs and addressed several temporal aspects of modeling such as incorporating time on the object level and forgetting.\nOther real world use cases of an even larger scale can be handled as well, such as the one described in [39] where the customs service needs to assess imported cargo for a variety of risk factors including terrorism, narcotics, food and consumer safety, pest infestation, tariff violations, and intellectual property rights. Assessing this risk, even at a preliminary level, involves extensive knowledge about commodities, business entities, trade patterns, government policies and trade agreements. Some of this knowledge may be external to a given customs agency: for instance the broad classification of commodities according to the international Harmonized Tariff System (HTS), or international trade agreements. Other knowledge may be internal to a customs agency, such as lists of suspected violators or of importers who have a history of good compliance with regulations. In [39], all this extensive knowledge is encoded in ontologies based on description logics and logic programming rules under the answer set semantics, and rMCSs naturally cover these formalisms as shown, e.g., in the running example. In addition, they easily allow for the direct modular integration of information given in databases or for example business rules without the need for any prior conversion (which may not be readily available for arbitrary formalisms). While some of the knowledge in this risk assessment scenario is relatively stable, much of it changes rapidly. Changes are made not only at a specific level, such as knowledge about the expected arrival date of a shipment; but at a more general level as well. For instance, while the broad HTS code for tomatoes (0702) does not change, the full classification and tariffs for cherry tomatoes for import into the US changes seasonally. Here again, rMCSs provide mechanisms to easily make changes no matter if they are of a mere temporary nature or more persistent by using sensor data and the incorporation of knowledge via next respectively. And, unlike [39], this flexibility is achieved without having to ensure or to test whether the integrated heterogeneous knowledge is organized in so-called layers.\nNaturally, dealing with inconsistency is an important issue in dynamic settings where knowledge changes over time. Indeed, we may face different kinds of inconsistencies when using rMCSs, e.g., in the form of inconsistent sensor input for which\nwe discuss modeling-based solutions. Another type of inconsistency is the absence of equilibria at certain time points which could potentially render an entire system useless. We have addressed this problem first by showing sufficient conditions on the contexts and the bridge rules that ensure the existence of an equilibria stream. In the cases where these conditions are not met, we have presented two possible solutions, one following an approach based on repairs \u2013 essentially the selective removal of bridge rules to regain an equilibria stream \u2013 and a second by relaxing the notion of equilibria stream to ensure that intermediate inconsistent states can be recovered. Thus, rMCSs remain usable in the face of possible inconsistencies which may always occur in real use cases where knowledge and sensor data from different sources is integrated.\nWe have also addressed the non-determinism of rMCSs and discussed possibilities for avoiding it in situations where it is not desired. To this end, we have also provided a well-founded stream semantics for rMCSs. The study of computational complexity we conducted confirms worst case complexities similar to managed multi-context systems. Hence, the additional integration of sensor data does not raise the worst case complexity of reasoning with heterogeneous knowledge integrated in multi-context systems. In addition, the results confirm that if very efficient reasoning with such rich knowledge is essential, we can restrict to the well-founded stream. This implies some restrictions on the permitted expressiveness, but we have argued that often these restrictions can be accommodated.\nFinally, we compared our approach to related work. Most importantly, we have shown that rMCSs can capture two relevant approaches in stream reasoning, namely LARS [7] and STARQL [36], thus showcasing that rMCSs are indeed \u201cdefined in the right way\u201d for the intended integration of constant streams of data.\nRegarding future work, several interesting lines of research can be considered. First, we may want to extend rMCSs to enhance their applicability in an even wider set of scenarios. Namely, one might adopt language constructs for expressing preferences in ASP such as optimization statements [21] or weak constraints [13], which assign a quality measure to equilibria. This would allow us, e.g., to improve on the potentially high non-determinism when faced with several equilibria at one time point and thus avoid having to consider a possibly huge number of different equilibria. We would also like to explore giving bridge rules access to the entire belief set of another context or an input and not just to one element. A potential application would be counting, e.g., to ask if there was no sensor reading.\nAn alternative to deal with inconsistent states is to follow a paraconsistent approach, as proposed for hybrid knowledge bases in [20, 30]. Also, following the idea of EVOLP [2] as explored in [27], we could allow the bridge rules to change with time, strengthening the evolving and adaptation capabilities of rMCSs. We would also like to establish bridges to asynchronous MCSs [18], a framework for loosely coupling knowledge representation formalisms whose semantics assumes that every context delivers output whenever available.\nThe framework introduced in this paper is highly abstract. Needless to say this was our intention. We wanted to capture a wide range of situations without imposing any restrictions on the KR formalisms used. It is a matter of the application to choose the best suited formalisms to solve a specific task. The downside of this generality, of course, is that the framework as such needs to be instantiated in various ways before it\nis ready-to-use. In particular, we need to select the context logics and define the ways in which contexts and dynamic information interact by specifying adequate bridge rules. We still believe our approach provides a valuable - and to the best of our knowledge unique - solution to the problems outlined in the Introduction, that is, problems which originate in the heterogeneous and dynamic nature of the information available in many challenging applications."}, {"heading": "Acknowledgements", "text": "G. Brewka, S. Ellmauthaler, and J. Pu\u0308hrer were partially supported by the German Research Foundation (DFG) under grants BR-1817/7-1 and FOR 1513. R. Gonc\u0327alves, M. Knorr and J. Leite were partially supported by Fundac\u0327a\u0303o para a Cie\u0302ncia e a Tecnologia (FCT) under project NOVA LINCS (UID/CEC/04516/2013). Moreover, R. Gonc\u0327alves was partially supported by FCT grant SFRH/BPD/100906/2014 and M. Knorr by FCT grant SFRH/BPD/86970/2012."}, {"heading": "Appendix A. rMCSs as a Turing Machine Service", "text": "To demonstrate the expressiveness of rMCSs and prove Proposition 9 we provide an rMCSMTM that implements a service that reads the configuration of a Turing machine (TM) from external sources and simulates a run of the TM on request. The fixed rMCS MTM comes with inexpressive context logics and management functions computable in linear time, thus showing that Turing-completeness arises from the interplay between the contexts over time. We use the following variant of TMs, where S is the set of all tape symbols and Q is the set of all states:\nDefinition 31. A TM is a tuple \u3008Q,\u0393, ,\u03a3, \u03b4, q0, F \u3009, where\n\u2022 Q \u2286 Q is a finite, non-empty set of states,\n\u2022 \u0393 \u2286 S is a finite, non-empty set of tape symbols,\n\u2022 \u2208 \u0393 is the blank symbol,\n\u2022 \u03a3 \u2286 \u0393 is the set of input symbols,\n\u2022 q0 is the initial state,\n\u2022 F \u2286 Q is the set of final states, and\n\u2022 \u03b4 : Q \\ F \u00d7 \u0393\u2192 Q\u00d7 \u0393\u00d7 {\u2190,\u2192} is the (partial) transition function.\nWe assume familiarity with the computation model of TMs, in particular what it means that a TM halts and accepts an input word w \u2208 \u03a3\u2217. MTM is an rMCS with four contexts. Context Ct simulates a tape of a TM, Cq contains information about TM states, Cf encodes a transition function, and Cc is a control context for operating the TM simulation and presenting results. All contexts use a storage logic as in Example 1, where the set of entries is respectively given by\n\u2022 Et = \u22c3\np\u2208Z,s\u2208S {t(p, s), curP(p)},\n\u2022 Eq = \u22c3 q\u2208Q {final(q), curQ(q)},\n\u2022 Ef = {f(q , s, q \u2032, s \u2032,m) | q, q\u2032 \u2208 Q, s, s\u2032 \u2208 S,m \u2208 {L,R}}, and\n\u2022 Ec = {computing, answer(yes), answer(no)}.\nThe input of MTM is provides by four streams over the languages\n\u2022 ILt = Et,\n\u2022 ILq = Eq ,\n\u2022 ILf = Ef , and\n\u2022 ILc = {start, reset},\nwhere ILt allows for setting an initial configuration for the tape, ILq the allowed and final states of the TM to simulate, ILf the transition function, and input over ILc is used to start and reset the simulation.\nThe bridge rule schemata of the tape context Ct are given by\nnext(add(t(P ,S \u2032))) \u2190 q:f(Q ,S ,Q \u2032,S \u2032,D), t:curP(P), q:curQ(Q), t:t(P ,S ), S 6= S\u2032, c:computing.\nnext(rm(t(P ,S ))) \u2190 q:f(Q ,S ,Q \u2032,S \u2032,D), t:curP(P), q:curQ(Q), t:t(P ,S ), S 6= S\u2032, c:computing.\nadd(nextP(P \u2212 1 )) \u2190 q:f(Q ,S ,Q \u2032,S \u2032,\u2190), q:curQ(Q), t:t(P ,S ), t:curP(P), c:computing.\nadd(nextP(P + 1 )) \u2190 q:f(Q ,S ,Q \u2032,S \u2032,\u2192), q:curQ(Q), t:t(P ,S ), t:curP(P), c:computing.\nadd(nextPdefined) \u2190 t:nextP(P), c:computing. next(add(curP(P))) \u2190 t:nextP(P), c:computing. next(rm(curP(P))) \u2190 t:curP(P), t:nextPdefined, c:computing.\nnext(add(X)) \u2190 t::X,not c:computing. next(clear) \u2190 c::reset.\nThe bridge rule schemata for the state context Cq are the following.\nnext(add(curQ(Q \u2032))) \u2190 q:f(Q ,S ,Q \u2032,S \u2032,D), t:curP(P), q:curQ(Q), t:t(P ,S ), Q 6= Q\u2032, c:computing.\nnext(rm(curQ(Q))) \u2190 q:f(Q ,S ,Q \u2032,S \u2032,D), t:curP(P), q:curQ(Q), t:t(P ,S ), Q 6= Q\u2032, c:computing.\nnext(add(X)) \u2190 q::X,not c:computing. next(clear) \u2190 c::reset.\nThe state Cf for the transition function has the bridge rules schemata given next.\nnext(add(X)) \u2190 f ::X,not c:computing. next(clear) \u2190 c::reset.\nFinally, the schemata for Cc are\nadd(answer(\u2032Y \u2032)) \u2190 q:curQ(Q), q:finalQ(Q), c:computing. add(answer(\u2032N \u2032)) \u2190 not t:nextPdefined(Q), q:curQ(Q),\nnot q:finalQ(Q), c:computing.\nnext(add(answer(X ))) \u2190 c:answer(X ), c:computing. next(rm(computing)) \u2190 c:answer(X ), c:computing.\nnext(clear) \u2190 c::reset. next(add(computing)) \u2190 c::start.\nAll contexts use the following management function.\nmng(OP , kb) =  \u2205 if clear \u2208 OP kb \\ {X | rm(X) \u2208 OP}\u222a else {X | add(X) \u2208 OP}\nLet T = \u3008Q,\u0393, ,\u03a3, \u03b4, q0, F \u3009 be a TM and w \u2208 \u03a3\u2217 an input word for T . We want to use MTM with input stream I to simulate T . Assume we start at time t. We first make sure that all knowledge bases are empty by setting Itc = {reset}. This activates the bridge rules in all contexts of MTM that derive next(clear). As a consequence, at time t + 1 the contents of all knowledge bases are deleted. Next, we feed T and w to MTM by sending\n\u2022 final(q) for all q \u2208 F and curQ(q0 ) on the input stream q,\n\u2022 f(q , s, q \u2032, s \u2032) iff \u03b4(q, s) = \u3008q\u2032, s\u2032\u3009 on stream f , and\n\u2022 curP(0 ) and t(p, s) iff s = sp for w = s0, s1, s2, . . . on the tape stream t.\nNote that it does not matter whether we do this all at once at time t + 1 or scattered over multiple time points greater than t. Assume that we finished to incorporate all this information to the knowledge bases at time t\u2032. Then, we set Ijc = {start} to initiate the simulation of T . At time t\u2032+ 1 the entry computing is contained in the knowledge base of context Cc, activating the bridge rules in all contexts that are responsible for the simulation. From now on, depending on the current state curQ(q) and the transition function, the bridge rules of tape context Ct always change the content of the tape on the current tape position indicated by curP(p). A new position p\u2032 of the tape head indicated by the transition function is reflected by deriving nextP(p\u2032). If such a belief is in the equilibrium so is nextPdefined and curP(p\u2032) is added at the next time point. For context Cq the current state is updated according to the transition function. Note that the auxiliary belief nextPdefined is also used in the bridge rules of context Cc for indicating that if the current state is not final and the transition function is undefined for the current state and input symbol, then the answer of the TM is no, indicated by answer(\u2032N \u2032). Conversely, if we arrive at a final state then answer(\u2032Y \u2032) is derived. If T does not halt on input w, then also the simulation in MTM will continue forever, unless we stop the computation by sending reset on input stream Ic once more."}], "references": [{"title": "Dynamic updates of non-monotonic knowledge bases", "author": ["J. Alferes", "J. Leite", "L. Pereira", "H. Przymusinska", "T. Przymusinski"], "venue": "J. Log. Program.,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2000}, {"title": "Evolving logic programs", "author": ["Jos\u00e9 J\u00falio Alferes", "Antonio Brogi", "Jo\u00e3o Alexandre Leite", "Lu\u0131\u0301s Moniz Pereira"], "venue": "Logics in Artificial Intelligence, European Conference,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2002}, {"title": "Stream reasoning and complex event processing in ETALIS", "author": ["D. Anicic", "S. Rudolph", "P. Fodor", "N. Stojanovic"], "venue": "Semantic Web,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2012}, {"title": "Consistent query answers in inconsistent databases", "author": ["Marcelo Arenas", "Leopoldo E. Bertossi", "Jan Chomicki"], "venue": "Proceedings of the Eighteenth ACM SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems, May 31 - June", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 1999}, {"title": "The Description Logic Handbook: Theory, Implementation, and Applications", "author": ["Franz Baader", "Diego Calvanese", "Deborah L. McGuinness", "Daniele Nardi", "Peter F. Patel-Schneider", "editors"], "venue": null, "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2007}, {"title": "C-SPARQL: a continuous query language for RDF data streams", "author": ["D. Barbieri", "D. Braga", "S. Ceri", "E. Della Valle", "M. Grossniklaus"], "venue": "Int. J. Semantic Computing,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2010}, {"title": "LARS: A logicbased framework for analyzing reasoning over streams", "author": ["Harald Beck", "Minh Dao-Tran", "Thomas Eiter", "Michael Fink"], "venue": "Proceedings of the Twenty-Ninth AAAI Conference on Artificial Intelligence, January", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2015}, {"title": "Towards reactive multi-context systems", "author": ["Gerhard Brewka"], "venue": "Proceedings of the 12th International Conference on Logic Programming and Nonmonotonic Reasoning (LPNMR\u201913),", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2013}, {"title": "Equilibria in heterogeneous nonmonotonic multi-context systems", "author": ["Gerhard Brewka", "Thomas Eiter"], "venue": "In Proceedings of the Twenty-Second AAAI Conference on Artificial Intelligence, July 22-26,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2007}, {"title": "Managed multi-context systems", "author": ["Gerhard Brewka", "Thomas Eiter", "Michael Fink", "Antonius Weinzierl"], "venue": "Proceedings of the 22nd International Joint Conference on Artificial Intelligence,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2011}, {"title": "Multi-context systems for reactive reasoning in dynamic environments", "author": ["Gerhard Brewka", "Stefan Ellmauthaler", "J\u00f6rg P\u00fchrer"], "venue": "In ECAI 2014 - 21st European Conference on Artificial Intelligence,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2014}, {"title": "Contextual default reasoning", "author": ["Gerhard Brewka", "Floris Roelofsen", "Luciano Serafini"], "venue": "Proceedings of the 20th International Joint Conference on Artificial Intelligence,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2007}, {"title": "Strong and weak constraints in disjunctive datalog", "author": ["Francesco Buccafurri", "Nicola Leone", "Pasquale Rullo"], "venue": "Logic Programming and Nonmonotonic Reasoning,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 1997}, {"title": "Finding explanations of inconsistency in multi-context systems", "author": ["Thomas Eiter", "Michael Fink", "Peter Sch\u00fcller", "Antonius Weinzierl"], "venue": "Artif. Intell.,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2014}, {"title": "Combining answer set programming with description logics for the semantic web", "author": ["Thomas Eiter", "Giovambattista Ianni", "Thomas Lukasiewicz", "Roman Schindlauer", "Hans Tompits"], "venue": "Artif. Intell.,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2008}, {"title": "Generalizing multi-context systems for reactive stream reasoning applications", "author": ["Stefan Ellmauthaler"], "venue": "Imperial College Computing Student Workshop, ICCSW 2013, September 26/27,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2013}, {"title": "Asynchronous multi-context systems", "author": ["Stefan Ellmauthaler", "J\u00f6rg P\u00fchrer"], "venue": "Essays Dedicated to Gerhard Brewka on the Occasion of His 60th Birthday,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2015}, {"title": "Recursive aggregates in disjunctive logic programs: Semantics and complexity", "author": ["Wolfgang Faber", "Nicola Leone", "Gerald Pfeifer"], "venue": "Logics in Artificial Intelligence,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2004}, {"title": "Paraconsistent hybrid theories", "author": ["Michael Fink"], "venue": "Principles of Knowledge Representation and Reasoning: Proceedings of the Thirteenth International Conference,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2012}, {"title": "A users guide to gringo, clasp, clingo, and iclingo", "author": ["M. Gebser", "R. Kaminski", "B. Kaufmann", "M. Ostrowski", "T. Schaub", "S. Thiele"], "venue": "Potassco Team,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2010}, {"title": "Stream reasoning with answer set programming: Preliminary report", "author": ["Martin Gebser", "Torsten Grote", "Roland Kaminski", "Philipp Obermeier", "Orkunt Sabuncu", "Torsten Schaub"], "venue": "Principles of Knowledge Representation and Reasoning: Proceedings of the Thirteenth International Conference,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2012}, {"title": "Reactive answer set programming", "author": ["Martin Gebser", "Torsten Grote", "Roland Kaminski", "Torsten Schaub"], "venue": "Logic Programming and Nonmonotonic Reasoning - 11th International Conference,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2011}, {"title": "Classical negation in logic programs and disjunctive databases", "author": ["Michael Gelfond", "Vladimir Lifschitz"], "venue": "New Generation Comput.,", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 1991}, {"title": "Multilanguage hierarchical logics or: How we can do without modal logics", "author": ["Fausto Giunchiglia", "Luciano Serafini"], "venue": "Artif. Intell.,", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 1994}, {"title": "Evolving bridge rules in evolving multi-context systems", "author": ["Ricardo Gon\u00e7alves", "Matthias Knorr", "Jo\u00e3o Leite"], "venue": "Computational Logic in Multi-Agent Systems - 15th International Workshop,", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2014}, {"title": "Evolving multi-context systems", "author": ["Ricardo Gon\u00e7alves", "Matthias Knorr", "Jo\u00e3o Leite"], "venue": "In ECAI 2014 - 21st European Conference on Artificial Intelligence,", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 2014}, {"title": "SPARQL 1.1 query language for RDF", "author": ["Steve Harris", "Andy Seaborne"], "venue": "W3C Recommendation,", "citeRegEx": "29", "shortCiteRegEx": "29", "year": 2013}, {"title": "Efficient paraconsistent reasoning with ontologies and rules", "author": ["Tobias Kaminski", "Matthias Knorr", "Jo\u00e3o Leite"], "venue": "Proceedings of the Twenty-Fourth International Joint Conference on Artificial Intelligence,", "citeRegEx": "30", "shortCiteRegEx": "30", "year": 2015}, {"title": "Predicting knowledge in an ontology stream", "author": ["Freddy L\u00e9cu\u00e9", "Jeff Z. Pan"], "venue": "Proceedings of the 23rd International Joint Conference on Artificial Intelligence,", "citeRegEx": "31", "shortCiteRegEx": "31", "year": 2013}, {"title": "On abstract modular inference systems and solvers", "author": ["Yuliya Lierler", "Miroslaw Truszczy\u0144ski"], "venue": "Artif. Intell.,", "citeRegEx": "32", "shortCiteRegEx": "32", "year": 2016}, {"title": "Generality in artificial intelligence", "author": ["John McCarthy"], "venue": "Commun. ACM,", "citeRegEx": "33", "shortCiteRegEx": "33", "year": 1987}, {"title": "Reconciling description logics and rules", "author": ["Boris Motik", "Riccardo Rosati"], "venue": "Journal of the ACM,", "citeRegEx": "34", "shortCiteRegEx": "34", "year": 2010}, {"title": "Preferential multi-context systems", "author": ["Kedian Mu", "Kewen Wang", "Lian Wen"], "venue": "Int. J. Approx. Reasoning,", "citeRegEx": "35", "shortCiteRegEx": "35", "year": 2016}, {"title": "Executive Summary: A semantics for temporal and stream-based query answering in an OBDA context", "author": ["\u00d6zg\u00fcr L. \u00d6z\u00e7ep", "Ralf M\u00f6ller", "Christian Neuenstadt", "Dmitriy Zheleznayakow", "Evgeny Kharlamov", "Ian Horrocks", "Thomas Hubauer", "Mikhail Roshchin. D"], "venue": "Technical report, Optique FP7-ICT-2011-8-318338 Project,", "citeRegEx": "36", "shortCiteRegEx": "36", "year": 2013}, {"title": "The Optique Project: Towards OBDA Systems for Industry (Short Paper), volume", "author": ["Mariano Rodriguez-Muro", "Simon Jupp", "Kavitha Srinivas", "editors"], "venue": "CEUR Workshop Proceedings. CEUR-WS.org,", "citeRegEx": "37", "shortCiteRegEx": "37", "year": 2013}, {"title": "Minimal and absent information in contexts", "author": ["Floris Roelofsen", "Luciano Serafini"], "venue": "Proceedings of the Nineteenth International Joint Conference on Artificial Intelligence,", "citeRegEx": "38", "shortCiteRegEx": "38", "year": 2005}, {"title": "On updates of hybrid knowledge bases composed of ontologies and rules", "author": ["Martin Slota", "Jo\u00e3o Leite", "Theresa Swift"], "venue": "Artif. Intell.,", "citeRegEx": "39", "shortCiteRegEx": "39", "year": 2015}], "referenceMentions": [{"referenceID": 10, "context": "^This paper combines and unifies the results of [11] and [28], two papers by different subsets of the authors describing independent adaptations of multi-context systems for dynamic environments.", "startOffset": 48, "endOffset": 52}, {"referenceID": 25, "context": "^This paper combines and unifies the results of [11] and [28], two papers by different subsets of the authors describing independent adaptations of multi-context systems for dynamic environments.", "startOffset": 57, "endOffset": 61}, {"referenceID": 14, "context": "Whereas some of these formalisms could be combined to form a new, more expressive formalism, with features from its constituents \u2013 such as dl-programs [15] and Hybrid MKNF [34] which, to different extent, combine", "startOffset": 151, "endOffset": 155}, {"referenceID": 31, "context": "Whereas some of these formalisms could be combined to form a new, more expressive formalism, with features from its constituents \u2013 such as dl-programs [15] and Hybrid MKNF [34] which, to different extent, combine", "startOffset": 172, "endOffset": 176}, {"referenceID": 23, "context": "An MCS consists of reasoning units \u2013 called contexts for historical reasons [26] \u2013 where each unit is equipped with a collection of bridge rules.", "startOffset": 76, "endOffset": 80}, {"referenceID": 30, "context": "Advancing work in [25, 33] aiming to integrate different inference systems, monotonic heterogeneous multi-context systems were defined in [26], with reasoning within as well as across monotonic contexts.", "startOffset": 18, "endOffset": 26}, {"referenceID": 23, "context": "Advancing work in [25, 33] aiming to integrate different inference systems, monotonic heterogeneous multi-context systems were defined in [26], with reasoning within as well as across monotonic contexts.", "startOffset": 138, "endOffset": 142}, {"referenceID": 35, "context": "The first, still somewhat limited attempts to include non-monotonic reasoning were done in [38] and [12], where default negation in the rules is used to allow for reasoning based on the absence of information from a context.", "startOffset": 91, "endOffset": 95}, {"referenceID": 11, "context": "The first, still somewhat limited attempts to include non-monotonic reasoning were done in [38] and [12], where default negation in the rules is used to allow for reasoning based on the absence of information from a context.", "startOffset": 100, "endOffset": 104}, {"referenceID": 8, "context": "The non-monotonic MCSs of [9] substantially generalize previous approaches, by accommodating heterogeneous and both monotonic and non-monotonic contexts, hence capable of integrating, among many others, \u201ctypical\u201d monotonic logics like description logics or temporal logics, and non-monotonic formalisms like Reiter\u2019s default logic, logic programs under answer set semantics, circumscription, defeasible logic, or theories in autoepistemic logic.", "startOffset": 26, "endOffset": 29}, {"referenceID": 9, "context": "More recently, the so-called managed MCSs (mMCSs) [10] addressed a limitation of MCSs in the way they integrate knowledge between contexts.", "startOffset": 50, "endOffset": 54}, {"referenceID": 21, "context": "There are some examples of systems developed with the purpose of reacting to streams of incoming information, such as Reactive ASP [23, 22], C-SPARQL [6], Ontology Streams [31] and ETALIS [3], to name only a few.", "startOffset": 131, "endOffset": 139}, {"referenceID": 20, "context": "There are some examples of systems developed with the purpose of reacting to streams of incoming information, such as Reactive ASP [23, 22], C-SPARQL [6], Ontology Streams [31] and ETALIS [3], to name only a few.", "startOffset": 131, "endOffset": 139}, {"referenceID": 5, "context": "There are some examples of systems developed with the purpose of reacting to streams of incoming information, such as Reactive ASP [23, 22], C-SPARQL [6], Ontology Streams [31] and ETALIS [3], to name only a few.", "startOffset": 150, "endOffset": 153}, {"referenceID": 28, "context": "There are some examples of systems developed with the purpose of reacting to streams of incoming information, such as Reactive ASP [23, 22], C-SPARQL [6], Ontology Streams [31] and ETALIS [3], to name only a few.", "startOffset": 172, "endOffset": 176}, {"referenceID": 2, "context": "There are some examples of systems developed with the purpose of reacting to streams of incoming information, such as Reactive ASP [23, 22], C-SPARQL [6], Ontology Streams [31] and ETALIS [3], to name only a few.", "startOffset": 188, "endOffset": 191}, {"referenceID": 1, "context": "EVOLP [2] extends logic programming under answer set semantics with the possibility to specify its evolution, through successive updates, in reaction to external observations.", "startOffset": 6, "endOffset": 9}, {"referenceID": 6, "context": "stream reasoning, namely LARS (Logic-based framework for Analyzing Reasoning over Streams) [7] and STARQL [36].", "startOffset": 91, "endOffset": 94}, {"referenceID": 33, "context": "stream reasoning, namely LARS (Logic-based framework for Analyzing Reasoning over Streams) [7] and STARQL [36].", "startOffset": 106, "endOffset": 110}, {"referenceID": 9, "context": "Reactive multi-context systems (rMCSs) make use of basic ideas from managed multi-context systems (mMCSs) [10] which extend multi-context systems (MCSs) as defined by Brewka and Eiter [9] by management capabilities.", "startOffset": 106, "endOffset": 110}, {"referenceID": 8, "context": "Reactive multi-context systems (rMCSs) make use of basic ideas from managed multi-context systems (mMCSs) [10] which extend multi-context systems (MCSs) as defined by Brewka and Eiter [9] by management capabilities.", "startOffset": 184, "endOffset": 187}, {"referenceID": 4, "context": "Quite similar in spirit are description logics (DLs) as (commonly decidable) fragments of first-order logic [5].", "startOffset": 108, "endOffset": 111}, {"referenceID": 22, "context": "As an example for a non-deterministic formalism, consider logic programs under the answer set semantics [24].", "startOffset": 104, "endOffset": 108}, {"referenceID": 9, "context": "To this end, we make use of a management function similar as in managed multi-context systems [10].", "startOffset": 94, "endOffset": 98}, {"referenceID": 9, "context": "We use a deterministic management function rather than a non-deterministic one as used in mMCS [10].", "startOffset": 95, "endOffset": 99}, {"referenceID": 13, "context": "In [14] the authors addressed the problem of global inconsistency in the context of mMCSs.", "startOffset": 3, "endOffset": 7}, {"referenceID": 13, "context": "These two notions turn out to be dual of each other, and somehow correspond to our notion of repair, the main difference being that, unlike in [14], we opt not to allow the (nonstandard) strengthening of bridge-rule to restore consistency, and, of course, that fact that our repairs need to take into account the dynamic nature of rMCSs.", "startOffset": 143, "endOffset": 147}, {"referenceID": 3, "context": ", in the context of databases [4], there is a special emphasis on seeking repairs that are somehow minimal, the rational being that we want to change things as little as possible to regain consistency.", "startOffset": 30, "endOffset": 33}, {"referenceID": 13, "context": "Repairs could also be extended to allow for the strengthening of bridge rules, besides their elimination, generalizing ideas from [14] and [10] where the extreme case of eliminating the entire body of bridge rules as part of a repair is considered.", "startOffset": 130, "endOffset": 134}, {"referenceID": 9, "context": "Repairs could also be extended to allow for the strengthening of bridge rules, besides their elimination, generalizing ideas from [14] and [10] where the extreme case of eliminating the entire body of bridge rules as part of a repair is considered.", "startOffset": 139, "endOffset": 143}, {"referenceID": 15, "context": ", preference functions as proposed by Ellmauthaler [16].", "startOffset": 51, "endOffset": 55}, {"referenceID": 19, "context": "One might also adopt language constructs for expressing preferences in ASP such as optimization statements [21] or weak constraints [13], which essentially assign a quality measure to equilibria, or, more recently, add a pre-order on the contexts [35].", "startOffset": 107, "endOffset": 111}, {"referenceID": 12, "context": "One might also adopt language constructs for expressing preferences in ASP such as optimization statements [21] or weak constraints [13], which essentially assign a quality measure to equilibria, or, more recently, add a pre-order on the contexts [35].", "startOffset": 132, "endOffset": 136}, {"referenceID": 32, "context": "One might also adopt language constructs for expressing preferences in ASP such as optimization statements [21] or weak constraints [13], which essentially assign a quality measure to equilibria, or, more recently, add a pre-order on the contexts [35].", "startOffset": 247, "endOffset": 251}, {"referenceID": 8, "context": "Alternatively, and inspired by notions developed for MCSs [9], we may consider restrictions on rMCSs such that these non-determinisms do not occur in the first place.", "startOffset": 58, "endOffset": 61}, {"referenceID": 8, "context": "In the following, we transfer these notions from static MCSs in [9] to dynamic rMCSs and discuss under which (non-trivial) conditions they actually can be applied.", "startOffset": 64, "endOffset": 67}, {"referenceID": 8, "context": "2 in [9], which can be transcribed to our setting using a simple rMCS without input languages, a single propositional context C1 (see Ex.", "startOffset": 5, "endOffset": 8}, {"referenceID": 8, "context": "Intuitively, L is reducible, if a) the restriction of L to KB\u2217 is monotonic, and b) there is a reduction function which should not reduce kb further if it already is in KB\u2217, which is antitonic, and by means of which acceptability of a belief set can be checked by the reduction (see also [9]).", "startOffset": 288, "endOffset": 291}, {"referenceID": 22, "context": "At the same time, Lec is reducible using the well-known Gelfond-Lifschitz reduct [24], and clearly none of the bridge rules in BRec can introduce any knowledge base formula (for any kb \u2208 KBec) which is affected by such redec.", "startOffset": 81, "endOffset": 85}, {"referenceID": 8, "context": "As pointed out in [9], for many logics, kbi = kb \u03c9 i holds and the iteration even stops after finitely many steps.", "startOffset": 18, "endOffset": 21}, {"referenceID": 8, "context": "Thus, these new notions also extend the work in [9] from MCSs to mMCSs.", "startOffset": 48, "endOffset": 51}, {"referenceID": 8, "context": "This is why we now introduce the well-founded semantics for reducible rMCSs M following the ideas in [9].", "startOffset": 101, "endOffset": 104}, {"referenceID": 13, "context": "[14]).", "startOffset": 0, "endOffset": 4}, {"referenceID": 9, "context": "Hardness holds because being able to solve Q\u2203, respectively the co-problem of Q\u2200, one can decide equilibrium existence for managed MCSs which is hard for the same complexity classes [10] given hardness for the context complexity of the managed MCS.", "startOffset": 182, "endOffset": 186}, {"referenceID": 29, "context": "An interesting example of the latter type are Lierler and Truszczy\u0144ski\u2019s abstract modular systems [32].", "startOffset": 98, "endOffset": 102}, {"referenceID": 6, "context": "Since rMCSs have been designed for applications involving stream reasoning, we will first consider two recent approaches for stream reasoning, namely LARS [7] and STARQL [36].", "startOffset": 155, "endOffset": 158}, {"referenceID": 33, "context": "Since rMCSs have been designed for applications involving stream reasoning, we will first consider two recent approaches for stream reasoning, namely LARS [7] and STARQL [36].", "startOffset": 170, "endOffset": 174}, {"referenceID": 1, "context": "Then, we establish the relationship to EVOLP [2], a framework that focuses on dynamics in the form of updates in the restricted setting of generalized logic programs building on similar notions as the operator next used for rMCSs.", "startOffset": 45, "endOffset": 48}, {"referenceID": 16, "context": "Moreover, we compare our formalism with asynchronous multi-context systems [18], as well as with reactive ASP [23, 8].", "startOffset": 75, "endOffset": 79}, {"referenceID": 21, "context": "Moreover, we compare our formalism with asynchronous multi-context systems [18], as well as with reactive ASP [23, 8].", "startOffset": 110, "endOffset": 117}, {"referenceID": 7, "context": "Moreover, we compare our formalism with asynchronous multi-context systems [18], as well as with reactive ASP [23, 8].", "startOffset": 110, "endOffset": 117}, {"referenceID": 6, "context": "In the following, we relate rMCSs to two recently proposed frameworks [7, 36] for stream reasoning by demonstrating how tasks suited for these approaches can be solved by an rMCS.", "startOffset": 70, "endOffset": 77}, {"referenceID": 33, "context": "In the following, we relate rMCSs to two recently proposed frameworks [7, 36] for stream reasoning by demonstrating how tasks suited for these approaches can be solved by an rMCS.", "startOffset": 70, "endOffset": 77}, {"referenceID": 6, "context": ", between the equilibrium semantics of rMCS and the FLP semantics used in [7]) rather than giving insight into how we can model stream reasoning tasks in the respective approaches.", "startOffset": 74, "endOffset": 77}, {"referenceID": 6, "context": "LARS The Logic-based framework for Analyzing Reasoning over Streams (LARS) [7] aims at providing a formal declarative logical language for reasoning with streams.", "startOffset": 75, "endOffset": 78}, {"referenceID": 6, "context": "Among the operators presented in [7] are, for example, time-based operators \u03c4 , which allow focusing on the last n time instants of a given stream, or the partition-based operators idx,n p , which first split the stream into substreams and then allow focusing on the last n tuples of a particular substream.", "startOffset": 33, "endOffset": 36}, {"referenceID": 6, "context": "Consider a simplified version of the example in [7] that models a scenario where we want to reason about a tram network, including, for example, the prediction of the expected arrival time of a tram at some stop.", "startOffset": 48, "endOffset": 51}, {"referenceID": 17, "context": "The semantics of LARS is based on the FLP semantics of logic programs [19].", "startOffset": 70, "endOffset": 74}, {"referenceID": 33, "context": "STARQL STARQL (pronounced Star-Q-L) [36], a framework for ontology-based stream reasoning, is developed within the Optique Project [37] that comes with a stream query language inspired by the RDF query language SPARQL [29].", "startOffset": 36, "endOffset": 40}, {"referenceID": 34, "context": "STARQL STARQL (pronounced Star-Q-L) [36], a framework for ontology-based stream reasoning, is developed within the Optique Project [37] that comes with a stream query language inspired by the RDF query language SPARQL [29].", "startOffset": 131, "endOffset": 135}, {"referenceID": 26, "context": "STARQL STARQL (pronounced Star-Q-L) [36], a framework for ontology-based stream reasoning, is developed within the Optique Project [37] that comes with a stream query language inspired by the RDF query language SPARQL [29].", "startOffset": 218, "endOffset": 222}, {"referenceID": 5, "context": "Unlike the related language continuous SPARQL (C-SPARQL) [6], STARQL goes beyond RDF semantics and allows for DL reasoning.", "startOffset": 57, "endOffset": 60}, {"referenceID": 33, "context": "1 [36].", "startOffset": 2, "endOffset": 6}, {"referenceID": 33, "context": "We make use of an example (partly taken from [36]) to explain components of STARQL queries and to describe the core aspects that are relevant for us.", "startOffset": 45, "endOffset": 49}, {"referenceID": 1, "context": "The framework of evolving logic programs EVOLP [2] is a powerful approach for modeling updates of (propositional) generalized logic programs.", "startOffset": 47, "endOffset": 50}, {"referenceID": 0, "context": "Each self-evolution can be represented by a sequence of programs, each program corresponding to a state, and these sequences of programs can be treated as in Dynamic Logic Programs (DLPs) [1].", "startOffset": 188, "endOffset": 191}, {"referenceID": 0, "context": "Here, these intuitions about DLPs are sufficient, and we point to [1] for more details.", "startOffset": 66, "endOffset": 69}, {"referenceID": 21, "context": "Closely related to EVOLP are the two frameworks of Reactive ASP, one implemented as a solver oclingo [23] and one described in [8].", "startOffset": 101, "endOffset": 105}, {"referenceID": 7, "context": "Closely related to EVOLP are the two frameworks of Reactive ASP, one implemented as a solver oclingo [23] and one described in [8].", "startOffset": 127, "endOffset": 130}, {"referenceID": 7, "context": "Reactive ASP as described in [8] can be seen as a more straightforward generalization of EVOLP where operations other than assert for self-updating a program are permitted.", "startOffset": 29, "endOffset": 32}, {"referenceID": 7, "context": "Since EVOLP can be captured by rMCSs, and since rMCSs permit several (evolution) operations in the head of bridge rules, it should be clear that Reactive ASP as described in [8] can be captured by rMCSs.", "startOffset": 174, "endOffset": 177}, {"referenceID": 16, "context": "Asynchronous multi-context systems (aMCSs) are a framework for loosely coupling knowledge representation formalisms and services [18].", "startOffset": 129, "endOffset": 133}, {"referenceID": 16, "context": "A setup to simulate an rMCS by an aMCS has been presented in [18].", "startOffset": 61, "endOffset": 65}, {"referenceID": 36, "context": "Other real world use cases of an even larger scale can be handled as well, such as the one described in [39] where the customs service needs to assess imported cargo for a variety of risk factors including terrorism, narcotics, food and consumer safety, pest infestation, tariff violations, and intellectual property rights.", "startOffset": 104, "endOffset": 108}, {"referenceID": 36, "context": "In [39], all this extensive knowledge is encoded in ontologies based on description logics and logic programming rules under the answer set semantics, and rMCSs naturally cover these formalisms as shown, e.", "startOffset": 3, "endOffset": 7}, {"referenceID": 36, "context": "And, unlike [39], this flexibility is achieved without having to ensure or to test whether the integrated heterogeneous knowledge is organized in so-called layers.", "startOffset": 12, "endOffset": 16}, {"referenceID": 6, "context": "Most importantly, we have shown that rMCSs can capture two relevant approaches in stream reasoning, namely LARS [7] and STARQL [36], thus showcasing that rMCSs are indeed \u201cdefined in the right way\u201d for the intended integration of constant streams of data.", "startOffset": 112, "endOffset": 115}, {"referenceID": 33, "context": "Most importantly, we have shown that rMCSs can capture two relevant approaches in stream reasoning, namely LARS [7] and STARQL [36], thus showcasing that rMCSs are indeed \u201cdefined in the right way\u201d for the intended integration of constant streams of data.", "startOffset": 127, "endOffset": 131}, {"referenceID": 19, "context": "Namely, one might adopt language constructs for expressing preferences in ASP such as optimization statements [21] or weak constraints [13], which assign a quality measure to equilibria.", "startOffset": 110, "endOffset": 114}, {"referenceID": 12, "context": "Namely, one might adopt language constructs for expressing preferences in ASP such as optimization statements [21] or weak constraints [13], which assign a quality measure to equilibria.", "startOffset": 135, "endOffset": 139}, {"referenceID": 18, "context": "An alternative to deal with inconsistent states is to follow a paraconsistent approach, as proposed for hybrid knowledge bases in [20, 30].", "startOffset": 130, "endOffset": 138}, {"referenceID": 27, "context": "An alternative to deal with inconsistent states is to follow a paraconsistent approach, as proposed for hybrid knowledge bases in [20, 30].", "startOffset": 130, "endOffset": 138}, {"referenceID": 1, "context": "Also, following the idea of EVOLP [2] as explored in [27], we could allow the bridge rules to change with time, strengthening the evolving and adaptation capabilities of rMCSs.", "startOffset": 34, "endOffset": 37}, {"referenceID": 24, "context": "Also, following the idea of EVOLP [2] as explored in [27], we could allow the bridge rules to change with time, strengthening the evolving and adaptation capabilities of rMCSs.", "startOffset": 53, "endOffset": 57}, {"referenceID": 16, "context": "We would also like to establish bridges to asynchronous MCSs [18], a framework for loosely coupling knowledge representation formalisms whose semantics assumes that every context delivers output whenever available.", "startOffset": 61, "endOffset": 65}], "year": 2016, "abstractText": "In this paper, we introduce reactive multi-context systems (rMCSs), a framework for reactive reasoning in the presence of heterogeneous knowledge sources. In particular, we show how to integrate data streams into multi-context systems (MCSs) and how to model the dynamics of the systems, based on two types of bridge rules. We illustrate how several typical problems arising in the context of stream reasoning can be handled using our framework. Reasoning based on multiple knowledge sources that need to be integrated faces the problem of potential inconsistencies. We discuss various methods for handling inconsistencies, with a special focus on non-existence of equilibria. In particular, we show how methods developed for managed MCSs can be generalized to rMCSs. We also study the issue of nondeterminism in rMCSs. One way of avoiding nondeterminism is by applying an alternative, skeptical semantics. We show how such a semantics, called well-founded semantics, can be defined for rMCSs, and what the effect of using this semantics instead of the original one is. We investigate the complexity of various reasoning problems related to rMCSs. Finally, we discuss related work, with a special focus on two of the most relevant approaches w.r.t. stream reasoning, namely LARS and STARQL.", "creator": "LaTeX with hyperref package"}}}