{"id": "1609.04873", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "15-Sep-2016", "title": "Distant Supervision for Relation Extraction beyond the Sentence Boundary", "abstract": "The growing demand for structured knowledge has led to great interest in relation extraction, especially in cases with limited supervision. However, existing distance supervision approaches only extract relations expressed in single sentences. In general, cross-sentence relation extraction is under-explored, even in the supervised-learning setting. It is assumed that this has the potential to lead to enhanced understanding of the relationships of groups, individuals and the system. However, cross-sentence relation extraction requires an explicit and clear understanding of the relationships, relationships and structures.\n\n\n\n\n\nThe above information should be taken with a grain of salt. To begin with, the following is an example of a multi-colonized approach to multi-colonized hierarchical relationships that we would like to use in order to demonstrate the multi-colonization of structured knowledge.\nThe following table presents an example of a single-colonized approach to multi-colonized hierarchical relationships:\nA single-colonized hierarchy:\nA hierarchical hierarchy of hierarchical hierarchical structures:\nA hierarchical hierarchy of hierarchical structures:\nA hierarchical hierarchy of hierarchical structures:\nA hierarchical hierarchy of hierarchical structures:\nA hierarchical hierarchy of hierarchical structures:\nA hierarchical hierarchy of hierarchical structures:\nA hierarchical hierarchy of hierarchical structures:\nA hierarchical hierarchy of hierarchical structures:\nA hierarchical hierarchy of hierarchical structures:\nA hierarchical hierarchy of hierarchical structures:\nA hierarchical hierarchy of hierarchical structures:\nA hierarchical hierarchy of hierarchical structures:\nA hierarchical hierarchy of hierarchical structures:\nA hierarchical hierarchy of hierarchical structures:\nA hierarchical hierarchy of hierarchical structures:\nA hierarchical hierarchy of hierarchical structures:\nA hierarchical hierarchy of hierarchical structures:\nA hierarchical hierarchy of hierarchical structures:\nA hierarchical hierarchy of hierarchical structures:\nA hierarchical hierarchy of hierarchical structures:\nA hierarchical hierarchy of hierarchical structures:\nA hierarchical hierarchy of hierarchical structures:\nA hierarchical hierarchy of hierarchical structures:\nA hierarchical hierarchy of hierarchical structures:\nA hierarchical hierarchy of hierarchical structures:\nA hierarchical hierarchy of hierarchical structures:\nA hierarchical hierarchy of hierarchical structures:\nA hierarchical hierarchy of hierarchical structures:\nA hierarchical hierarchy of hierarchical structures:\nA hierarchical hierarchy of hierarchical structures:\nA hierarchical hierarchy of hierarchical structures:\nA hierarchical hierarchy of hierarchical structures:\nA hierarchical hierarchy of hierarchical structures:\nA hierarchical hierarchy of hierarchical structures:\nA hierarchical hierarchy of hierarchical structures:\nA hierarchical hierarchy of hierarchical structures:\nA hierarchical hierarchy of hierarchical structures:\nA hierarchical hierarchy of hierarchical structures:\nA hierarchical hierarchy of hierarchical", "histories": [["v1", "Thu, 15 Sep 2016 22:01:26 GMT  (64kb,D)", "http://arxiv.org/abs/1609.04873v1", "8 pages + 2 pages reference"], ["v2", "Fri, 30 Sep 2016 04:42:20 GMT  (64kb,D)", "http://arxiv.org/abs/1609.04873v2", "8 pages + 3 pages reference"], ["v3", "Mon, 14 Aug 2017 23:54:49 GMT  (64kb,D)", "http://arxiv.org/abs/1609.04873v3", "Presented at EACL 2017; 9 pages (12 pages including references)"]], "COMMENTS": "8 pages + 2 pages reference", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["chris quirk", "hoifung poon"], "accepted": false, "id": "1609.04873"}, "pdf": {"name": "1609.04873.pdf", "metadata": {"source": "CRF", "title": "Distant Supervision for Relation Extraction beyond the Sentence Boundary", "authors": ["Chris Quirk"], "emails": ["chrisq@microsoft.com", "hoifung@microsoft.com"], "sections": [{"heading": "1 Introduction", "text": "The accelerating pace in technological advance and scientific discovery has led to an explosive growth in knowledge. The ensuing information overload creates new urgency in assimilating frag-\nmented knowledge for integration and reasoning. A salient case in point is precision medicine (Bahcall, 2015). The cost of sequencing a person\u2019s genome has fallen below $10001, enabling individualized diagnosis and treatment of complex genetic diseases such as cancer. The availability of measurement for 20,000 human genes makes it imperative to integrate all knowledge about them, which grows rapidly and is scattered in millions of articles in PubMed2. Traditional extraction approaches require annotated examples, which makes it difficult to scale to the explosion of extraction demands. Consequently, there has been increasing interest in indirect supervision (Banko et al., 2007; Poon and Domingos, 2009; Toutanova et al., 2015), with distant supervision (Craven et al., 1998; Mintz et al., 2009) emerging as a particularly promising paradigm for augmenting existing knowledge bases from unlabeled text (Poon et al., 2015; Parikh et al., 2015).\nThis progress is exciting, but distantsupervision approaches have so far been limited to single sentences, thus missing out on relations crossing the sentence boundary. Consider the following example:\u201cThus, the constitutive activation of BRAF mutation leads to EGFR-independent tumorigenicity. Therefore, the oncogenic activation of the RAS signaling\npathway impairs the response of colorectal cancer cells to cetuximab.\u201d Together, the two sentences convey the fact that mutations in the BRAF gene confer resistance to the drug cetuximab, which can not be inferred from either sentence alone. The impact of such missed opportunities is especially pronounced in the tail-end distribution of knowledge. Such information is crucial for integrative reasoning as it includes the newest findings in specialized domains.\n1http://www.illumina.com/systems/ hiseq-x-sequencing-system.html\n2http://www.ncbi.nlm.nih.gov/pubmed\nar X\niv :1\n60 9.\n04 87\n3v 1\n[ cs\n.C L\n] 1\n5 Se\np 20\n16\nIn this paper, we present DISCREX, the first approach for distant supervision to relation extraction beyond the sentence boundary. The key idea is to adopt a document-level graph representation that augments conventional intra-sentential dependencies with new dependencies introduced for adjacent sentences and discourse relations. It provides a unifying way to derive features for classifying relations between entity pairs. As we augment this graph with new arcs, the number of possible paths between entities grow. We demonstrate that feature extraction along multiple paths leads to more robust extraction, allowing the learner to find structural patterns even when the language varies or the parser makes an error.\nThe cross-sentence scenario presents a new challenge in candidate selection. This motivates our concept of minimal-span candidates in Section 3.2. Experiments show that excluding nonminimal candidates substantially improves classification accuracy.\nThere is a long line of research on discourse phenomena, including coreference (Haghighi and Klein, 2007; Poon and Domingos, 2008; Rahman and Ng, 2009; Raghunathan et al., 2010), narrative structures (Chambers and Jurafsky, 2009; Cheung et al., 2013), and rhetorical relations (Marcu, 2000). For the most part, this work has not been connected to relation extraction. Our proposed extraction framework makes it easy to integrate such discourse relations. Our experiments evaluated the impact of coreference and discourse parsing, a preliminary step toward in-depth integration with discourse research.\nWe conducted experiments on extracting druggene interactions from biomedical literature, an important task for precision medicine. By bootstrapping from a recently curated knowledge base (KB) with about 162 known interactions, our DISCREX system learned to extract inter-sentence drug-gene interactions at high precision. Crosssentence extraction doubled the yield compared to single-sentence extraction. Overall, by applying distant supervision, we extracted about 64,000 distinct interactions from about one million PubMed Central full-text articles, attaining two orders of magnitude increase compared to the original KB."}, {"heading": "2 Related Work", "text": "To the best of our knowledge, distant supervision has not been applied to cross-sentence relation ex-\ntraction in the past. For example, Mintz et al. (2009), who coined the term \u201cdistant supervision\u201d, aggregated features from multiple instances for the same relation triple (relation, entity1, entity2), but each instance is a sentence where the two entities co-occur. Thus their approach cannot extract relations where the two entities reside in different sentences. Similarly, Zheng et al. (2016) aggregated information from multiple sentential instances, but could not extract cross-sentence relations.\nDistant supervision has also been applied to completing Wikipedia Infoboxes (Wu and Weld, 2007) or TAC KBP Slot Filling3, where the goal is to extract attributes for a given entity, which could be considered a special kind of relation triples (attribute, entity, value). These scenarios are very different from general cross-sentence relation extraction. For example, the entity in consideration is often the protagonist in the document (title entity of the article). Moreover, state-of-the-art methods also typically consider single-sentence extraction only (Surdeanu et al., 2012; Surdeanu and Ji, 2014).\nIn general, cross-sentence relation extraction has received little attention, even in the supervised-learning setting. Among the limited amount of prior work, Swampillai & Stevenson (2011) is the most relevant to our approach, as it also considered syntactic features and introduced a dependency link between the root nodes of parse trees containing the given pair of entities. However, the differences are substantial. First and foremost, their approach used standard supervised learning rather than distant supervision. Moreover, we introduced the document-level graph representation, which is much more general, capable of incorporating a diverse set of discourse relations and enabling the use of rich syntactic and surface features (Section 3). Finally, Swampillai & Stevenson (2011) evaluated on MUC64, which contains only 318 Wall Street Journal articles. In contrast, we evaluated on large-scale extraction from about one million full-text articles and demonstrated the large impact of cross-sentence extraction for an important real-world application.\nThe lack of prior work in cross-sentence relation extraction may be partially explained by the domains of focus. Prior extraction work focuses\n3http://www.nist.gov/tac/2016/KBP/ ColdStart/index.html\n4https://catalog.ldc.upenn.edu/ LDC2003T13\non newswire text5 and the Web (Craven et al., 2000). In these domains, the extracted relations often involve popular entities, for which there often exist single sentences expressing the relation (Banko et al., 2007). However, there is much less redundancy in specialized domains such as the frontiers of science and technology, where crosssentence extraction is more likely to have a significant impact. The long-tailed characteristics of such domains also make distant supervision a natural choice for scaling up learning. This paper represents a first step toward exploring the confluence of these two directions.\nRecently, there has been increasing interest in relation extraction for biomedical applications (Kim et al., 2009; Ne\u0301dellec et al., 2013). However, past methods are generally limited to single sentences, whether using supervised learning (Bjorne et al., 2009; Poon and Vanderwende, 2010; Riedel and McCallum, 2011) or distant supervision (Poon et al., 2015; Parikh et al., 2015).\nThe idea of leveraging graph representations has been explored in many other settings, such as knowledge base completion (Lao et al., 2011; Gardner and Mitchell, 2015), frame-semantic parsing (Das and Smith, 2011), and other NLP tasks (Radev and Mihalcea, 2008; Subramanya et al., 2010). Linear and dependency paths are popular features for relation extraction (Snow et al., 2006; Mintz et al., 2009). However, past extraction focuses on single sentences, and typically considers the shortest path only. In contrast, we allow interleaving edges from dependency and word adjacency, and consider top K paths rather than just the shortest one. This resulted in substantial accuracy gain (Section 4.5).\nThere has been prior work on leveraging coreference in relation extraction, in the standard single-sentence, supervised setting (Hajishirzi et al., 2013; Durrett and Klein, 2014). Recently, discourse parsing has received renewed interest (Ji and Eisenstein, 2014; Feng and Hirst, 2014; Surdeanu et al., 2015), and discourse information has been shown to improve performance in applications such as question answering (Sharp et al., 2015). In this paper, we generated coreference relations using the state-of-the-art Stanford coreference systems (Lee et al., 2011; Recasens et al., 2013; Clark and Manning, 2015), and generated\n5E.g., MUC6, ACE https://www.ldc.upenn. edu/collaborations/past-projects/ace\nrhetorical relations using the winning approach (Xue et al., 2015) in the CoNLL-2015 Shared Task on Discourse Parsing."}, {"heading": "3 Distant Supervision for Cross-Sentence Relation Extraction", "text": "In this section, we present DISCREX, short for DIstant Supervision for Cross-sentence Relation EXraction. Similar to conventional approaches, DISCREX learns a classifier to predict the relation between two entities, given text spans where the entities co-occur. Unlike most existing methods, however, DISCREX allows text spans comprising multiple sentences and explores potentially many paths between these entities."}, {"heading": "3.1 Distant Supervision", "text": "Like prior approaches, DISCREX learns from an existing knowledge base (KB) and unlabeled text. The KB contains known instances for the given relation. In a preprocessing step, relevant entities are annotated within this text using available entity extraction tools. Co-occurring entity pairs known to have the relation in the KB are chosen as positive examples. Under the assumption that related entities are relatively rare, we randomly sample cooccurring entity pairs not known to have the relation as negative examples. To ensure a balanced training set, we always sampled roughly the same number of negative examples as positive ones."}, {"heading": "3.2 Minimal-Span Candidates", "text": "In standard distant supervision, co-occurring entity pairs with known relations are enlisted as candidates of positive training examples. This is reasonable when the entity pairs are within single sentences. In the cross-sentence scenario, however, this would risk introducing too many wrong examples. Consider the following two sentences: Since amuvatinib inhibits KIT, we validated MET kinase inhibition as the primary cause of cell death. Additionally, imatinib is known to inhibit KIT. The mention of drug-gene pair imatinib and KIT (in bold) span two sentences, but the same pair also co-occur in the second sentence alone. In general, one might find co-occurring entity pairs in a large text span, where the same pairs also co-occur in a smaller text span that overlaps with the larger one. In such cases, if there is a relation between the pair, mostly likely it is expressed in the smaller text span when the entities are closer to each other.\nThis motivates us to define that an co-occurring entity pair has the minimal span if there does not exist another overlapping co-occurrence of the same pair where the distance between the entity mentions is smaller. Here, the distance is measured in the number of consecutive sentences between the two entities. Experimentally, we compared extraction with or without the restriction to minimal-span candidates, and show that the former led to much higher extraction accuracy."}, {"heading": "3.3 Document Graph", "text": "To derive features for entity pairs both within and across sentences, DISCREX introduces a document graph with nodes representing words and edges representing intra- and inter-sentential relations such as dependency, adjacency, and discourse relations. Figure 1 shows an example document graph spanning two sentences. Each node is labeled with its lexical item, lemma, and partof-speech. We used a conventional set of intrasentential edges: typed, collapsed Stanford dependencies derived from syntactic parses (de Marneffe et al., 2006). To mitigate parser errors, we also add edges between adjacent words.\nAs for inter-sentential edges, a simple but intuitive approach is to add an edge between the dependency roots of adjacent sentences: if we imagined that each sentence participated as a node in a type of discourse dependency tree, this represents a simple right-branching baseline. To gather a finer grained representation of rhetorical structure, we ran a state-of-the-art discourse parser (Xue et\nal., 2015) to identify discourse relations, which returned a set of labeled binary relations between spans of words. We found the shortest path between any word in the first span and any word in the second span using only dependency and adjacent sentence edges, and added an edge labeled with the discourse relation between these two words. Another source of potentially crosssentence links comes from coreference. We generated coreference relations using the Stanford Coreference systems (both statistical and deterministic) (Lee et al., 2011; Recasens et al., 2013; Clark and Manning, 2015), and added edges from anaphora to their antecedents."}, {"heading": "3.4 Features", "text": "Dependency paths have been established as a particularly effective source for relation extraction features (Mintz et al., 2009). DISCREX generalizes this idea by defining feature templates over paths in the document graph, which may contain interleaving edges of various types (dependency, word and sentence adjacency, discourse relation). Dependency paths provide interpretable and generalizable features but are subject to parser error. One error mitigation strategy is to add edges between adjacent words, allowing multiple paths between entities.\nFeature extraction begins with a pair of entities in the document graph that potentially are connected by a relation. We begin by finding a path between the entities of interest, and extract features from that path.\nOver each such path, we explore a number of different features. Below, we assume that each path is a sequence of nodes and edges (n1, e1, n2, . . . , eL\u22121, nL), with n1 and nL replaced by special entity marker nodes.6\nWhole path features We extract four binary indicator features for each whole path, with nodes ni represented by their lexical item, lemma, part-ofspeech tag, or nothing. These act as high precision but low recall indicators of useful paths.\nPath n-gram features A more robust and generalizable approach is to consider a sliding window along each path. For each position i, we extract ngram (n = 1\u22125) features starting at each node (ni, then ni \u00b7ei and so on until ni \u00b7ei \u00b7ni+1 \u00b7ei+1 \u00b7ni+2) and each edge (ei up to ei \u00b7ni+1 \u00b7ei+1 \u00b7ni+2 \u00b7ei+2). Again, each node could be represented by its lexical item, lemma, or part of speech, leading to 27 feature templates. Finally, we add three more feature templates using only edge labels (ei; ei \u00b7 ei+1; and ei \u00b7 ei+1 \u00b7 ei+2) for a total of 30 feature templates."}, {"heading": "3.5 Multiple paths", "text": "Most prior work has only looked at the single shortest path between two entities. When authors use consistent lexical and syntactic constructions, and when the parser finds the correct parse, this approach works well. Real data, however, is quite noisy.\nOne way to mitigate errors and be robust against noise is to consider multiple possible paths. Given a document graph with arcs of multiple types, there are often multiple paths between nodes. For instance, we might navigate from the gene to the drug using only syntactic arcs, or only adjacency arcs, or some combination of the two. Considering such variations gives more opportunities to find commonalities between seemingly disparate language.\nWe explore varying the number of shortest paths, N , between the nodes in the document graph corresponding to the relevant entities. By default, all edge types have an equal weight of 1, except edges between adjacent words. Empirically, penalizing adjacency edges led to substantial benefits, though including adjacency arcs was important for benefits from multiple paths. This\n6 This prevents our method from memorizing the entities in the original knowledge base.\nsuggests that the parser produces valuable information, but that we should have a back-off strategy for accommodating parser errors."}, {"heading": "3.6 Evaluation", "text": "There is no gold annotated dataset in distant supervision, so evaluation typically resorts to two strategies. One strategy uses held-out samples from the training dataset, essentially treating the noisy annotation as gold standard. This has the advantage of being automatic, but could produce biased results due to false negatives (i.e., entity pairs not known to have the relation might actually have the relation). Another strategy reports absolute recall (number of extractions from all unlabeled text), as well as estimated precision by manually annotating extraction samples from general text. We conducted both types of evaluation in the experiments."}, {"heading": "4 Experiments", "text": "We consider the task of extracting drug-gene interactions from biomedical literature. A drug-gene interaction is broadly construed as an association between the drug efficacy and the gene status. The status includes mutations and activity measurements (e.g., overexpression). For simplicity, we only consider the relation at the drug-gene level, without distinguishing among details such as drug dosage or distinct gene status."}, {"heading": "4.1 Knowledge Base", "text": "We used the Gene Drug Knowledge Database (GDKD) (Dienstmann et al., 2015) for distant supervision. Figure 2 shows a snapshot of the dataset. Each row specifies a gene, some drugs, the fine-grained relations (e.g., sensitive), the gene status (e.g., mutation), and some supporting article IDs. In this paper, we only consider the coarse drug-gene association and ignore the other fields."}, {"heading": "4.2 Unlabeled Text", "text": "We obtained biomedical literature from PubMed Central7, which as of early 2015 contained about 960,000 full-text articles. We preprocessed the text using SPLAT (Quirk et al., 2012) to conduct tokenization, part-of-speech tagging, and syntactic parsing, and obtained Stanford dependencies (de Marneffe et al., 2006) using Stanford CoreNLP (Manning et al., 2014). We used the entity tag-\n7http://www.ncbi.nlm.nih.gov/pmc/\ngers from Literome (Poon et al., 2014) to identify drug and gene mentions."}, {"heading": "4.3 Candidate Selection", "text": "To avoid unlikely candidates such as entity pairs far apart in the document, we consider entity pairs within K consecutive sentences. K = 1 corresponds to extraction within single sentences. For cross-sentence extraction, we chose K = 3 as it doubled the number of overall candidates, while being reasonably small so as not to introduce too many unlikely ones. Table 1 shows the statistics of drug-gene interaction candidates identified in PubMed Central articles. For K = 3, there are 87,773 instances for which the drug-gene pair has known associations in Gene Drug Knowledge Database (GDKD), which are used as positive training examples. Note that these only include minimal-span candidates (Section 3.2). Without the restriction, there are 225,520 instances matching GDKD, though many are likely false positives."}, {"heading": "4.4 Classifier", "text": "Our classifiers were binary logistic regression models, trained to optimize log-likelihood with an `2 regularizer. We used a weight of 1 for the regularizer; the results were not very sensitive to the specific value. Parameters were optimized using L-BFGS (Nocedal and Wright, 2006). Rather than explicitly mapping each feature to its own dimension, we hashed the feature names and retained 22\nbits (Weinberger et al., 2009). Approximately 4 million possible features seemed to suffice for our problem: fewer bits produced degradations, but more bits did not lead to improvements."}, {"heading": "4.5 Automatic Evaluation", "text": "To evaluate the impact of features, we conducted five-fold cross validation, by treating the positive and negative examples from distant supervision as gold annotation. To avoid train-test contamination, all instances from a document are assigned to the same fold. We then evaluated the average test accuracy across folds. As discussed before, the results could be biased by the noise in annotation, but this automatic evaluation enables an efficient comparison of various design choices.\nFirst, we set out to investigate the impact of\nedge types and path number. We set the weight for adjacent-word edges to 16, to give higher priority to other edge types (weight 1) that are arguably more semantics-related. Table 2 shows the average test accuracy for single-sentence and crosssentence extraction with various edge types and path numbers. Compared to extraction within single sentences, cross-sentence extraction attains a very similar accuracy, even though the recall for the latter is much higher (Table 1).\nAdding more paths other than the shortest one led to a substantial improvement in accuracy. The gain is consistent for both single-sentence and cross-sentence extraction. This is surprising, as prior methods often derive features from the shortest dependency path alone.\nAdding discourse relations, on the other hand, consistently led to a small drop in performance, especially when the path number is small. Upon manual inspection, we found that Stanford Coreference made many errors in biomedical text, such as resolving a dummy pronoun with a nearby entity. In hindsight, this is probably not surprising: state-of-the-art coreference systems are optimized for newswire domain and could be ill-suited for scientific literature (Bell et al., 2016). We are less certain about why discourse parsing didn\u2019t seem to help. There are clearly examples where extraction errors could have been avoided given rhetorical relations (e.g., when the sentence containing the second entity starts a new topic). We leave more indepth investigation to future work.\nNext, we further evaluated the impact of path\nnumber and adjacency edge weight. Only dependency and adjacency edges were included in these experiments. Table 3 shows the results. Penalizing adjacency produces large gains; a harsh penalty is particularly helpful with fewer paths. These results support the hypothesis that dependency edges are usually more meaningful for relation extraction than word adjacency. Therefore, if adjacency edges get the same weights, they might cause some dependency sub-paths drop out of the top K paths, thus degrading performance. When the path number increases, there is a consistent and substantial increase in accuracy, which demonstrates the advantage of allowing adjacency edges to interleave with dependency ones. This presumably helps address syntactic parsing errors, among other things. The importance of adjacency weights decreases with more paths, but it is still significantly better to penalize adjacency edges.\nIn the experiments mentioned above, crosssentence extraction was conducted using minimalspan candidates only. We expected that this would provide a reasonable safeguard to filter out many unlikely candidates. As empirical validation, we also conducted experiments on cross-sentence extraction without the minimal-span restriction, using the base model. Test accuracy dropped sharply from 81.7% to 79.1% (not shown in the table)."}, {"heading": "4.6 PubMed-Scale Extraction", "text": "Our ultimate goal is to extract knowledge from all available text. First, we retrained DISCREX on all available distant-supervision data, not restricting to a subset of the folds as in the automatic evaluation. We used the systems performing best on automatic evaluation, with features derived from\n30 shortest paths between each entity pair, and minimal-span candidates within three sentences for cross-sentence extraction. We then applied the learned extractors to all PubMed Central articles.\nWe grouped the extracted instances into unique drug-gene pairs. The classifier output a probability for each instance. The maximum probability of instances in a group was assigned to the relation as a whole. Table 4 shows the statistics of extracted relations by varying the probability threshold. Cross-sentence extraction obtained far more unique relations compared to single-sentence extraction, improving absolute recall by 89-102%. Table 5 compares the number of unique genes and drugs. DISCREX extractions cover far more genes and drugs compared to GDKD, which bode well for applications in precision medicine."}, {"heading": "4.7 Manual Evaluation", "text": "Automatic evaluation accuracies can be overly optimistic. To assess the true precision of DISCREX, we also conducted manual evaluation on extracted relations. Based on the automatic evaluation, the accuracy is similar for single-sentence and crosssentence extraction. So we focused on the latter. We randomly sampled extracted relation instances and asked two researchers knowledgeable in precision medicine to evaluate their correctness. For each instance, the annotators were provided with the provenance sentences where the druggene pair were highlighted. The annotators assessed in each case whether some relation was mentioned for the given pair.\nA total of 450 instances were judged: 150 were sampled randomly from all candidates (random baseline), 150 from the set of instances with probability no less than 0.5, and 150 with probability no less than 0.9. From each set, we randomly selected 50 relations for review by both annotators. The two annotators agreed on 133 of 150. After\nreview, all disagreements were resolved, and each annotator judged an additional set of 50 relation instances, this time without overlap.\nTable 6 showed the sample precision and what percentage of instances are incorrect due to entity errors vs. relation errors. With either classification threshold, cross-sentence extraction clearly outperformed the random baseline by a wide margin. Not surprisingly, the higher threshold of 0.9 led to higher precision. Interestingly, a significant portion of errors stems from mistakes in entity linking, which has also been observed in prior work (Poon et al., 2015). This suggests that improved entity linking, either in isolation or joint with relation extraction, is an important future direction.\nBased on these estimates, DISCREX extracted about 37,000 correct unique interactions at the threshold of 0.5, and about 20,000 at the threshold of 0.9. In both cases, it expanded the Gene Drug Knowledge Base by two orders of magnitude."}, {"heading": "5 Conclusion", "text": "We present the first approach for applying distant supervision to cross-sentence relation extraction, by adopting a document-level graph representation that incorporates both intra-sentential dependencies and inter-sentential relations such as adjacency and discourse relations. We conducted both automatic and manual evaluation on extracting drug-gene interactions from biomedical literature. With cross-sentence extraction, our DISCREX system doubled the yield of unique interactions, while maintaining the same accuracy. Using distant supervision, DISCREX improved the coverage of the Gene Drug Knowledge Database (GDKD) by two orders of magnitude, without requiring annotated examples.\nFuture work includes: further exploration of features; improved integration with coreference and discourse parsing; combining distant supervision with active learning and crowd sourcing; evaluate the impact of extractions to precision medicine; applications to other domains."}], "references": [{"title": "Precision medicine", "author": ["Orli Bahcall."], "venue": "Nature, 526:335.", "citeRegEx": "Bahcall.,? 2015", "shortCiteRegEx": "Bahcall.", "year": 2015}, {"title": "Open information extraction from the web", "author": ["Michele Banko", "Michael J. Cafarella", "Stephen Soderland", "Matt Broadhead", "Oren Etzioni."], "venue": "Proceedings of the Twentieth International Joint Conference on Artificial Intelligence, pages 2670\u20132676,", "citeRegEx": "Banko et al\\.,? 2007", "shortCiteRegEx": "Banko et al\\.", "year": 2007}, {"title": "An investigation of coreference phenomena in the biomedical domain", "author": ["Dane Bell", "Gustave Hahn-Powell", "Marco A. Valenzuela-Escarcega", "Mihai Surdeanu."], "venue": "Proceedings of LREC.", "citeRegEx": "Bell et al\\.,? 2016", "shortCiteRegEx": "Bell et al\\.", "year": 2016}, {"title": "Extracting complex biological events with rich graphbased feature sets", "author": ["Jari Bjorne", "Juho Heimonen", "Filip Ginter", "Antti Airola", "Tapio Pahikkala", "Tapio Salakoski."], "venue": "Proceedings of the BioNLP Workshop.", "citeRegEx": "Bjorne et al\\.,? 2009", "shortCiteRegEx": "Bjorne et al\\.", "year": 2009}, {"title": "Unsupervised learning of narrative schemas and their participants", "author": ["Nathanael Chambers", "Dan Jurafsky."], "venue": "Proceedings of the Forty Seventh Annual Meeting of the Association for Computational Linguistics.", "citeRegEx": "Chambers and Jurafsky.,? 2009", "shortCiteRegEx": "Chambers and Jurafsky.", "year": 2009}, {"title": "Probabilistic frame induction", "author": ["Jackie Cheung", "Hoifung Poon", "Lucy Vanderwende."], "venue": "Proceedings of Human Language Technologies: The Annual Conference of the North American Chapter of the Association for Computational Linguistics.", "citeRegEx": "Cheung et al\\.,? 2013", "shortCiteRegEx": "Cheung et al\\.", "year": 2013}, {"title": "Entity-centric coreference resolution with model stacking", "author": ["Kevin Clark", "Christopher D. Manning."], "venue": "Proceedings of the Fifty Third Annual Meeting of the Association for Computational Linguistics.", "citeRegEx": "Clark and Manning.,? 2015", "shortCiteRegEx": "Clark and Manning.", "year": 2015}, {"title": "Learning to extract symbolic knowledge from the World Wide Web", "author": ["M.W. Craven", "D. DiPasquo", "D. Freitag", "A. McCallum", "T. Mitchell", "K. Nigam", "S. Slattery."], "venue": "Proceedings of the Fifteenth National Conference on Artificial Intelligence, pages", "citeRegEx": "Craven et al\\.,? 1998", "shortCiteRegEx": "Craven et al\\.", "year": 1998}, {"title": "Learning to construct knowledge bases from the world wide web", "author": ["Mark Craven", "Dan DiPasquo", "Dayne Freitag", "Andrew McCallum", "Tom Mitchell", "Kamal Nigam", "Sean Slattery."], "venue": "Artificial Intelligence, 118:69\u2013113.", "citeRegEx": "Craven et al\\.,? 2000", "shortCiteRegEx": "Craven et al\\.", "year": 2000}, {"title": "Semisupervised frame-semantic parsing for unknown predicates", "author": ["Dipanjan Das", "Noah A. Smith."], "venue": "Proceedings of the Forty Ninth Annual Meeting of the Association for Computational Linguistics.", "citeRegEx": "Das and Smith.,? 2011", "shortCiteRegEx": "Das and Smith.", "year": 2011}, {"title": "Generating typed dependency parses from phrase structure parses", "author": ["Marie-Catherine de Marneffe", "Bill MacCartney", "Christopher D. Manning."], "venue": "Proceedings of the Fifth International Conference on Language Resources and Evaluation, pages 449\u2013", "citeRegEx": "Marneffe et al\\.,? 2006", "shortCiteRegEx": "Marneffe et al\\.", "year": 2006}, {"title": "Database of genomic biomarkers for cancer drugs and clinical targetability in solid tumors", "author": ["Rodrigo Dienstmann", "In Sock Jang", "Brian Bot", "Stephen Friend", "Justin Guinney."], "venue": "Cancer Discovery, 5:118\u2013123.", "citeRegEx": "Dienstmann et al\\.,? 2015", "shortCiteRegEx": "Dienstmann et al\\.", "year": 2015}, {"title": "A joint model for entity analysis: Coreference, typing, and linking", "author": ["Greg Durrett", "Dan Klein."], "venue": "Transactions of the Association for Computational Linguistics.", "citeRegEx": "Durrett and Klein.,? 2014", "shortCiteRegEx": "Durrett and Klein.", "year": 2014}, {"title": "A lineartime bottom-up discourse parser with constraints and post-editing", "author": ["Vanessa Wei Feng", "Graeme Hirst."], "venue": "Proceedings of the Fifty Second Annual Meeting of the Association for Computational Linguistics.", "citeRegEx": "Feng and Hirst.,? 2014", "shortCiteRegEx": "Feng and Hirst.", "year": 2014}, {"title": "Efficient and expressive knowledge base completion using subgraph feature extraction", "author": ["Matt Gardner", "Tom Mitchell."], "venue": "Proceedings of EMNLP.", "citeRegEx": "Gardner and Mitchell.,? 2015", "shortCiteRegEx": "Gardner and Mitchell.", "year": 2015}, {"title": "Unsupervised coreference resolution in a nonparametric bayesian model", "author": ["Aria Haghighi", "Dan Klein."], "venue": "Proceedings of the Forty Fifth Annual Meeting of the Association for Computational Linguistics.", "citeRegEx": "Haghighi and Klein.,? 2007", "shortCiteRegEx": "Haghighi and Klein.", "year": 2007}, {"title": "Joint coreference resolution and named-entity linking with multi-pass sieves", "author": ["Hannaneh Hajishirzi", "Leila Zilles", "Daniel S. Weld", "Luke Zettlemoyer."], "venue": "Proceedings of EMNLP.", "citeRegEx": "Hajishirzi et al\\.,? 2013", "shortCiteRegEx": "Hajishirzi et al\\.", "year": 2013}, {"title": "Representation learning for text-level discourse parsing", "author": ["Yangfeng Ji", "Jacob Eisenstein."], "venue": "Proceedings of the Fifty Second Annual Meeting of the Association for Computational Linguistics.", "citeRegEx": "Ji and Eisenstein.,? 2014", "shortCiteRegEx": "Ji and Eisenstein.", "year": 2014}, {"title": "Overview of BioNLP-09 Shared Task on event extraction", "author": ["Jin-Dong Kim", "Tomoko Ohta", "Sampo Pyysalo", "Yoshinobu Kano", "Junichi Tsujii."], "venue": "Proceedings of the BioNLP Workshop.", "citeRegEx": "Kim et al\\.,? 2009", "shortCiteRegEx": "Kim et al\\.", "year": 2009}, {"title": "Random walk inference and learning in a large scale knowledge base", "author": ["Ni Lao", "Tom Mitchell", "William W. Cohen."], "venue": "Proceedings of EMNLP.", "citeRegEx": "Lao et al\\.,? 2011", "shortCiteRegEx": "Lao et al\\.", "year": 2011}, {"title": "Stanford\u2019s multi-pass sieve coreference resolution system at the conll-2011 shared task", "author": ["Heeyoung Lee", "Yves Peirsman", "Angel Chang", "Nathanael Chambers", "Mihai Surdeanu", "Dan Jurafsky."], "venue": "Proceedings of the CoNLL-2011 Shared Task.", "citeRegEx": "Lee et al\\.,? 2011", "shortCiteRegEx": "Lee et al\\.", "year": 2011}, {"title": "The stanford corenlp natural language processing toolkit", "author": ["Christopher D. Manning", "Mihai Surdeanu", "John Bauer", "Jenny Finkel", "Steven J. Bethard", "David McClosky."], "venue": "Proceedings of the 52nd Annual Meeting of the Association for Com-", "citeRegEx": "Manning et al\\.,? 2014", "shortCiteRegEx": "Manning et al\\.", "year": 2014}, {"title": "The Theory and Practice of Discourse Parsing and Summarization", "author": ["Daniel Marcu."], "venue": "The MIT Press, Cambridge, Massachusetts, November.", "citeRegEx": "Marcu.,? 2000", "shortCiteRegEx": "Marcu.", "year": 2000}, {"title": "Distant supervision for relation extraction without labeled data", "author": ["Mike Mintz", "Steven Bills", "Rion Snow", "Dan Jurafsky."], "venue": "Proceedings of the", "citeRegEx": "Mintz et al\\.,? 2009", "shortCiteRegEx": "Mintz et al\\.", "year": 2009}, {"title": "Overview of BioNLP Shared Task 2013", "author": ["Claire N\u00e9dellec", "Robert Bossy", "Jin-Dong Kim", "Jung jae Kim", "Tomoko Ohta", "Sampo Pyysalo", "Pierre Zweigenbaum."], "venue": "Proceedings of the BioNLP Workshop.", "citeRegEx": "N\u00e9dellec et al\\.,? 2013", "shortCiteRegEx": "N\u00e9dellec et al\\.", "year": 2013}, {"title": "Numerical Optimization", "author": ["J. Nocedal", "S. Wright."], "venue": "Springer, New York, NY.", "citeRegEx": "Nocedal and Wright.,? 2006", "shortCiteRegEx": "Nocedal and Wright.", "year": 2006}, {"title": "Grounded semantic parsing for complex knowledge extraction", "author": ["Ankur Parikh", "Hoifung Poon", "Kristina Toutanova."], "venue": "Proceedings of Human Language Technologies: The Annual Conference of the North American Chapter of the Association for", "citeRegEx": "Parikh et al\\.,? 2015", "shortCiteRegEx": "Parikh et al\\.", "year": 2015}, {"title": "Joint unsupervised coreference resolution with Markov logic", "author": ["Hoifung Poon", "Pedro Domingos."], "venue": "Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing, pages 649\u2013658, Honolulu, HI. ACL.", "citeRegEx": "Poon and Domingos.,? 2008", "shortCiteRegEx": "Poon and Domingos.", "year": 2008}, {"title": "Unsupervised semantic parsing", "author": ["Hoifung Poon", "Pedro Domingos."], "venue": "Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 1\u201310, Singapore. ACL.", "citeRegEx": "Poon and Domingos.,? 2009", "shortCiteRegEx": "Poon and Domingos.", "year": 2009}, {"title": "Joint inference for knowledge extraction from biomedical literature", "author": ["Hoifung Poon", "Lucy Vanderwende."], "venue": "Proceedings of HLT/NAACL 2010.", "citeRegEx": "Poon and Vanderwende.,? 2010", "shortCiteRegEx": "Poon and Vanderwende.", "year": 2010}, {"title": "Literome: Pubmed-scale genomic knowledge base in the cloud", "author": ["Hoifung Poon", "Chris Quirk", "Charlie DeZiel", "David Heckerman."], "venue": "Bioinformatics.", "citeRegEx": "Poon et al\\.,? 2014", "shortCiteRegEx": "Poon et al\\.", "year": 2014}, {"title": "Distant supervision for cancer pathway extraction from text", "author": ["Hoifung Poon", "Kristina Toutanova", "Chris Quirk."], "venue": "Pacific Symposium of Biocomputing.", "citeRegEx": "Poon et al\\.,? 2015", "shortCiteRegEx": "Poon et al\\.", "year": 2015}, {"title": "MSR SPLAT, a language analysis toolkit", "author": ["Chris Quirk", "Pallavi Choudhury", "Jianfeng Gao", "Hisami Suzuki", "Kristina Toutanova", "Michael Gamon", "Wentau Yih", "Lucy Vanderwende."], "venue": "Proceedings of NAACL HLT Demonstration Session.", "citeRegEx": "Quirk et al\\.,? 2012", "shortCiteRegEx": "Quirk et al\\.", "year": 2012}, {"title": "Networks and natural language processing", "author": ["Dragomir R. Radev", "Rada Mihalcea."], "venue": "AI Magazine.", "citeRegEx": "Radev and Mihalcea.,? 2008", "shortCiteRegEx": "Radev and Mihalcea.", "year": 2008}, {"title": "A multipass sieve for coreference resolution", "author": ["Karthik Raghunathan", "Heeyoung Lee", "Sudarshan Rangarajan", "Nathanael Chambers", "Mihai Surdeanu", "Dan Jurafsky", "Christopher Manning."], "venue": "Proceedings of EMNLP.", "citeRegEx": "Raghunathan et al\\.,? 2010", "shortCiteRegEx": "Raghunathan et al\\.", "year": 2010}, {"title": "Supervised models for coreference resolution", "author": ["Altaf Rahman", "Vincent Ng."], "venue": "Proceedings of EMNLP.", "citeRegEx": "Rahman and Ng.,? 2009", "shortCiteRegEx": "Rahman and Ng.", "year": 2009}, {"title": "The life and death of discourse entities: Identifying singleton mentions", "author": ["Marta Recasens", "Marie-Catherine de Marneffe", "Christopher Potts."], "venue": "In", "citeRegEx": "Recasens et al\\.,? 2013", "shortCiteRegEx": "Recasens et al\\.", "year": 2013}, {"title": "Fast and robust joint models for biomedical event extraction", "author": ["Sebastian Riedel", "Andrew McCallum."], "venue": "Proceedings of EMNLP.", "citeRegEx": "Riedel and McCallum.,? 2011", "shortCiteRegEx": "Riedel and McCallum.", "year": 2011}, {"title": "Spinning straw into gold: Using free text to train monolingual alignment models for non-factoid question answering", "author": ["Rebecca Sharp", "Peter Jansen", "Mihai Surdeanu", "Peter Clark."], "venue": "Proceedings of Human Language Technologies: The Annual Con-", "citeRegEx": "Sharp et al\\.,? 2015", "shortCiteRegEx": "Sharp et al\\.", "year": 2015}, {"title": "Semantic taxonomy induction from heterogenous evidence", "author": ["Rion Snow", "Daniel Jurafsky", "Andrew Ng."], "venue": "Proceedings of COLING/ACL 2006.", "citeRegEx": "Snow et al\\.,? 2006", "shortCiteRegEx": "Snow et al\\.", "year": 2006}, {"title": "Efficient graph-based semisupervised learning of structured tagging models", "author": ["Amarnag Subramanya", "Slav Petrov", "Fernando Pereira."], "venue": "Proceedings of EMNLP.", "citeRegEx": "Subramanya et al\\.,? 2010", "shortCiteRegEx": "Subramanya et al\\.", "year": 2010}, {"title": "Overview of the english slot filling track at the tac2014 knowledge base population evaluation", "author": ["Mihai Surdeanu", "Heng Ji."], "venue": "Proceedings of the TAC-KBP 2014 Workshop.", "citeRegEx": "Surdeanu and Ji.,? 2014", "shortCiteRegEx": "Surdeanu and Ji.", "year": 2014}, {"title": "Multi-instance multi-label learning for relation extraction", "author": ["Mihai Surdeanu", "Julie Tibshirani", "Ramesh Nallapati", "Christopher D. Manning."], "venue": "Proceedings of EMNLP.", "citeRegEx": "Surdeanu et al\\.,? 2012", "shortCiteRegEx": "Surdeanu et al\\.", "year": 2012}, {"title": "Two practical rhetorical structure theory parsers", "author": ["Mihai Surdeanu", "Thomas Hicks", "Marco A. Valenzuela-Escarcega."], "venue": "Proceedings of NAACL-HLT: Software Demonstrations.", "citeRegEx": "Surdeanu et al\\.,? 2015", "shortCiteRegEx": "Surdeanu et al\\.", "year": 2015}, {"title": "Extracting relations within and across sentences", "author": ["Kumutha Swampillai", "Mark Stevenson."], "venue": "Proceedings of RANLP.", "citeRegEx": "Swampillai and Stevenson.,? 2011", "shortCiteRegEx": "Swampillai and Stevenson.", "year": 2011}, {"title": "Representing text for joint embedding of text and knowledge bases", "author": ["Kristina Toutanova", "Danqi Chen", "Patrick Pantel", "Hoifung Poon", "Pallavi Choudhury", "Michael Gamon."], "venue": "Proceedings of EMNLP.", "citeRegEx": "Toutanova et al\\.,? 2015", "shortCiteRegEx": "Toutanova et al\\.", "year": 2015}, {"title": "Feature hashing for large scale multitask learning", "author": ["Kilian Weinberger", "Anirban Dasgupta", "John Langford", "Alex Smola", "Josh Attenberg."], "venue": "Proceedings of ICML.", "citeRegEx": "Weinberger et al\\.,? 2009", "shortCiteRegEx": "Weinberger et al\\.", "year": 2009}, {"title": "Automatically semantifying wikipedia", "author": ["Fei Wu", "Daniel S. Weld."], "venue": "Proceedings of CIKM.", "citeRegEx": "Wu and Weld.,? 2007", "shortCiteRegEx": "Wu and Weld.", "year": 2007}, {"title": "The CoNLL-2015 Shared Task on Shallow Discourse Parsing", "author": ["Nianwen Xue", "Hwee Tou Ng", "Sameer Pradhan", "Rashmi Prasad", "Christopher Bryant", "Attapol Rutherford."], "venue": "Proceedings of CoNLL, Shared Task.", "citeRegEx": "Xue et al\\.,? 2015", "shortCiteRegEx": "Xue et al\\.", "year": 2015}, {"title": "Aggregating intersentence information to enhance relation extraction", "author": ["Hao Zheng", "Zhoujun Li", "Senzhang Wang", "Zhao Yan", "Jianshe Zhou."], "venue": "Proceedings of AAAI.", "citeRegEx": "Zheng et al\\.,? 2016", "shortCiteRegEx": "Zheng et al\\.", "year": 2016}], "referenceMentions": [{"referenceID": 0, "context": "A salient case in point is precision medicine (Bahcall, 2015).", "startOffset": 46, "endOffset": 61}, {"referenceID": 1, "context": "Consequently, there has been increasing interest in indirect supervision (Banko et al., 2007; Poon and Domingos, 2009; Toutanova et al., 2015), with distant supervision (Craven et al.", "startOffset": 73, "endOffset": 142}, {"referenceID": 28, "context": "Consequently, there has been increasing interest in indirect supervision (Banko et al., 2007; Poon and Domingos, 2009; Toutanova et al., 2015), with distant supervision (Craven et al.", "startOffset": 73, "endOffset": 142}, {"referenceID": 45, "context": "Consequently, there has been increasing interest in indirect supervision (Banko et al., 2007; Poon and Domingos, 2009; Toutanova et al., 2015), with distant supervision (Craven et al.", "startOffset": 73, "endOffset": 142}, {"referenceID": 7, "context": ", 2015), with distant supervision (Craven et al., 1998; Mintz et al., 2009) emerging as a particularly promising paradigm for augmenting existing knowledge bases from unlabeled text (Poon et al.", "startOffset": 34, "endOffset": 75}, {"referenceID": 23, "context": ", 2015), with distant supervision (Craven et al., 1998; Mintz et al., 2009) emerging as a particularly promising paradigm for augmenting existing knowledge bases from unlabeled text (Poon et al.", "startOffset": 34, "endOffset": 75}, {"referenceID": 31, "context": ", 2009) emerging as a particularly promising paradigm for augmenting existing knowledge bases from unlabeled text (Poon et al., 2015; Parikh et al., 2015).", "startOffset": 114, "endOffset": 154}, {"referenceID": 26, "context": ", 2009) emerging as a particularly promising paradigm for augmenting existing knowledge bases from unlabeled text (Poon et al., 2015; Parikh et al., 2015).", "startOffset": 114, "endOffset": 154}, {"referenceID": 15, "context": "There is a long line of research on discourse phenomena, including coreference (Haghighi and Klein, 2007; Poon and Domingos, 2008; Rahman and Ng, 2009; Raghunathan et al., 2010), narrative structures (Chambers and Jurafsky, 2009; Cheung et al.", "startOffset": 79, "endOffset": 177}, {"referenceID": 27, "context": "There is a long line of research on discourse phenomena, including coreference (Haghighi and Klein, 2007; Poon and Domingos, 2008; Rahman and Ng, 2009; Raghunathan et al., 2010), narrative structures (Chambers and Jurafsky, 2009; Cheung et al.", "startOffset": 79, "endOffset": 177}, {"referenceID": 35, "context": "There is a long line of research on discourse phenomena, including coreference (Haghighi and Klein, 2007; Poon and Domingos, 2008; Rahman and Ng, 2009; Raghunathan et al., 2010), narrative structures (Chambers and Jurafsky, 2009; Cheung et al.", "startOffset": 79, "endOffset": 177}, {"referenceID": 34, "context": "There is a long line of research on discourse phenomena, including coreference (Haghighi and Klein, 2007; Poon and Domingos, 2008; Rahman and Ng, 2009; Raghunathan et al., 2010), narrative structures (Chambers and Jurafsky, 2009; Cheung et al.", "startOffset": 79, "endOffset": 177}, {"referenceID": 4, "context": ", 2010), narrative structures (Chambers and Jurafsky, 2009; Cheung et al., 2013), and rhetorical relations (Marcu, 2000).", "startOffset": 30, "endOffset": 80}, {"referenceID": 5, "context": ", 2010), narrative structures (Chambers and Jurafsky, 2009; Cheung et al., 2013), and rhetorical relations (Marcu, 2000).", "startOffset": 30, "endOffset": 80}, {"referenceID": 22, "context": ", 2013), and rhetorical relations (Marcu, 2000).", "startOffset": 34, "endOffset": 47}, {"referenceID": 23, "context": "For example, Mintz et al. (2009), who coined the term \u201cdistant supervision\u201d, aggregated features from multiple instances for the same relation triple (relation, entity1, entity2), but each instance is a sentence where the two entities co-occur.", "startOffset": 13, "endOffset": 33}, {"referenceID": 23, "context": "For example, Mintz et al. (2009), who coined the term \u201cdistant supervision\u201d, aggregated features from multiple instances for the same relation triple (relation, entity1, entity2), but each instance is a sentence where the two entities co-occur. Thus their approach cannot extract relations where the two entities reside in different sentences. Similarly, Zheng et al. (2016) aggregated information from multiple sentential instances, but could not extract cross-sentence relations.", "startOffset": 13, "endOffset": 375}, {"referenceID": 47, "context": "Distant supervision has also been applied to completing Wikipedia Infoboxes (Wu and Weld, 2007) or TAC KBP Slot Filling3, where the goal is to extract attributes for a given entity, which could be considered a special kind of relation triples (attribute, entity, value).", "startOffset": 76, "endOffset": 95}, {"referenceID": 42, "context": "Moreover, state-of-the-art methods also typically consider single-sentence extraction only (Surdeanu et al., 2012; Surdeanu and Ji, 2014).", "startOffset": 91, "endOffset": 137}, {"referenceID": 41, "context": "Moreover, state-of-the-art methods also typically consider single-sentence extraction only (Surdeanu et al., 2012; Surdeanu and Ji, 2014).", "startOffset": 91, "endOffset": 137}, {"referenceID": 8, "context": "on newswire text5 and the Web (Craven et al., 2000).", "startOffset": 30, "endOffset": 51}, {"referenceID": 1, "context": "In these domains, the extracted relations often involve popular entities, for which there often exist single sentences expressing the relation (Banko et al., 2007).", "startOffset": 143, "endOffset": 163}, {"referenceID": 18, "context": "Recently, there has been increasing interest in relation extraction for biomedical applications (Kim et al., 2009; N\u00e9dellec et al., 2013).", "startOffset": 96, "endOffset": 137}, {"referenceID": 24, "context": "Recently, there has been increasing interest in relation extraction for biomedical applications (Kim et al., 2009; N\u00e9dellec et al., 2013).", "startOffset": 96, "endOffset": 137}, {"referenceID": 3, "context": "However, past methods are generally limited to single sentences, whether using supervised learning (Bjorne et al., 2009; Poon and Vanderwende, 2010; Riedel and McCallum, 2011) or distant supervision (Poon et al.", "startOffset": 99, "endOffset": 175}, {"referenceID": 29, "context": "However, past methods are generally limited to single sentences, whether using supervised learning (Bjorne et al., 2009; Poon and Vanderwende, 2010; Riedel and McCallum, 2011) or distant supervision (Poon et al.", "startOffset": 99, "endOffset": 175}, {"referenceID": 37, "context": "However, past methods are generally limited to single sentences, whether using supervised learning (Bjorne et al., 2009; Poon and Vanderwende, 2010; Riedel and McCallum, 2011) or distant supervision (Poon et al.", "startOffset": 99, "endOffset": 175}, {"referenceID": 31, "context": ", 2009; Poon and Vanderwende, 2010; Riedel and McCallum, 2011) or distant supervision (Poon et al., 2015; Parikh et al., 2015).", "startOffset": 86, "endOffset": 126}, {"referenceID": 26, "context": ", 2009; Poon and Vanderwende, 2010; Riedel and McCallum, 2011) or distant supervision (Poon et al., 2015; Parikh et al., 2015).", "startOffset": 86, "endOffset": 126}, {"referenceID": 19, "context": "The idea of leveraging graph representations has been explored in many other settings, such as knowledge base completion (Lao et al., 2011; Gardner and Mitchell, 2015), frame-semantic parsing (Das and Smith, 2011), and other NLP tasks (Radev and Mihalcea, 2008; Subramanya et al.", "startOffset": 121, "endOffset": 167}, {"referenceID": 14, "context": "The idea of leveraging graph representations has been explored in many other settings, such as knowledge base completion (Lao et al., 2011; Gardner and Mitchell, 2015), frame-semantic parsing (Das and Smith, 2011), and other NLP tasks (Radev and Mihalcea, 2008; Subramanya et al.", "startOffset": 121, "endOffset": 167}, {"referenceID": 9, "context": ", 2011; Gardner and Mitchell, 2015), frame-semantic parsing (Das and Smith, 2011), and other NLP tasks (Radev and Mihalcea, 2008; Subramanya et al.", "startOffset": 60, "endOffset": 81}, {"referenceID": 33, "context": ", 2011; Gardner and Mitchell, 2015), frame-semantic parsing (Das and Smith, 2011), and other NLP tasks (Radev and Mihalcea, 2008; Subramanya et al., 2010).", "startOffset": 103, "endOffset": 154}, {"referenceID": 40, "context": ", 2011; Gardner and Mitchell, 2015), frame-semantic parsing (Das and Smith, 2011), and other NLP tasks (Radev and Mihalcea, 2008; Subramanya et al., 2010).", "startOffset": 103, "endOffset": 154}, {"referenceID": 39, "context": "Linear and dependency paths are popular features for relation extraction (Snow et al., 2006; Mintz et al., 2009).", "startOffset": 73, "endOffset": 112}, {"referenceID": 23, "context": "Linear and dependency paths are popular features for relation extraction (Snow et al., 2006; Mintz et al., 2009).", "startOffset": 73, "endOffset": 112}, {"referenceID": 16, "context": "There has been prior work on leveraging coreference in relation extraction, in the standard single-sentence, supervised setting (Hajishirzi et al., 2013; Durrett and Klein, 2014).", "startOffset": 128, "endOffset": 178}, {"referenceID": 12, "context": "There has been prior work on leveraging coreference in relation extraction, in the standard single-sentence, supervised setting (Hajishirzi et al., 2013; Durrett and Klein, 2014).", "startOffset": 128, "endOffset": 178}, {"referenceID": 17, "context": "Recently, discourse parsing has received renewed interest (Ji and Eisenstein, 2014; Feng and Hirst, 2014; Surdeanu et al., 2015), and discourse information has been shown to improve performance in applications such as question answering (Sharp et al.", "startOffset": 58, "endOffset": 128}, {"referenceID": 13, "context": "Recently, discourse parsing has received renewed interest (Ji and Eisenstein, 2014; Feng and Hirst, 2014; Surdeanu et al., 2015), and discourse information has been shown to improve performance in applications such as question answering (Sharp et al.", "startOffset": 58, "endOffset": 128}, {"referenceID": 43, "context": "Recently, discourse parsing has received renewed interest (Ji and Eisenstein, 2014; Feng and Hirst, 2014; Surdeanu et al., 2015), and discourse information has been shown to improve performance in applications such as question answering (Sharp et al.", "startOffset": 58, "endOffset": 128}, {"referenceID": 38, "context": ", 2015), and discourse information has been shown to improve performance in applications such as question answering (Sharp et al., 2015).", "startOffset": 116, "endOffset": 136}, {"referenceID": 20, "context": "In this paper, we generated coreference relations using the state-of-the-art Stanford coreference systems (Lee et al., 2011; Recasens et al., 2013; Clark and Manning, 2015), and generated", "startOffset": 106, "endOffset": 172}, {"referenceID": 36, "context": "In this paper, we generated coreference relations using the state-of-the-art Stanford coreference systems (Lee et al., 2011; Recasens et al., 2013; Clark and Manning, 2015), and generated", "startOffset": 106, "endOffset": 172}, {"referenceID": 6, "context": "In this paper, we generated coreference relations using the state-of-the-art Stanford coreference systems (Lee et al., 2011; Recasens et al., 2013; Clark and Manning, 2015), and generated", "startOffset": 106, "endOffset": 172}, {"referenceID": 48, "context": "edu/collaborations/past-projects/ace rhetorical relations using the winning approach (Xue et al., 2015) in the CoNLL-2015 Shared Task on Discourse Parsing.", "startOffset": 85, "endOffset": 103}, {"referenceID": 48, "context": "To gather a finer grained representation of rhetorical structure, we ran a state-of-the-art discourse parser (Xue et al., 2015) to identify discourse relations, which returned a set of labeled binary relations between spans of words.", "startOffset": 109, "endOffset": 127}, {"referenceID": 20, "context": "We generated coreference relations using the Stanford Coreference systems (both statistical and deterministic) (Lee et al., 2011; Recasens et al., 2013; Clark and Manning, 2015), and added edges from anaphora to their antecedents.", "startOffset": 111, "endOffset": 177}, {"referenceID": 36, "context": "We generated coreference relations using the Stanford Coreference systems (both statistical and deterministic) (Lee et al., 2011; Recasens et al., 2013; Clark and Manning, 2015), and added edges from anaphora to their antecedents.", "startOffset": 111, "endOffset": 177}, {"referenceID": 6, "context": "We generated coreference relations using the Stanford Coreference systems (both statistical and deterministic) (Lee et al., 2011; Recasens et al., 2013; Clark and Manning, 2015), and added edges from anaphora to their antecedents.", "startOffset": 111, "endOffset": 177}, {"referenceID": 23, "context": "Dependency paths have been established as a particularly effective source for relation extraction features (Mintz et al., 2009).", "startOffset": 107, "endOffset": 127}, {"referenceID": 11, "context": "We used the Gene Drug Knowledge Database (GDKD) (Dienstmann et al., 2015) for distant supervision.", "startOffset": 48, "endOffset": 73}, {"referenceID": 32, "context": "We preprocessed the text using SPLAT (Quirk et al., 2012) to conduct tokenization, part-of-speech tagging, and syntactic parsing, and obtained Stanford dependencies (de Marneffe et al.", "startOffset": 37, "endOffset": 57}, {"referenceID": 21, "context": ", 2006) using Stanford CoreNLP (Manning et al., 2014).", "startOffset": 31, "endOffset": 53}, {"referenceID": 30, "context": "gers from Literome (Poon et al., 2014) to identify drug and gene mentions.", "startOffset": 19, "endOffset": 38}, {"referenceID": 25, "context": "Parameters were optimized using L-BFGS (Nocedal and Wright, 2006).", "startOffset": 39, "endOffset": 65}, {"referenceID": 48, "context": "+disc adds edges for the predicted rhetorical relations by a state-of-the-art discourse parser (Xue et al., 2015).", "startOffset": 95, "endOffset": 113}, {"referenceID": 46, "context": "bits (Weinberger et al., 2009).", "startOffset": 5, "endOffset": 30}, {"referenceID": 2, "context": "In hindsight, this is probably not surprising: state-of-the-art coreference systems are optimized for newswire domain and could be ill-suited for scientific literature (Bell et al., 2016).", "startOffset": 168, "endOffset": 187}, {"referenceID": 31, "context": "Interestingly, a significant portion of errors stems from mistakes in entity linking, which has also been observed in prior work (Poon et al., 2015).", "startOffset": 129, "endOffset": 148}], "year": 2016, "abstractText": "The growing demand for structured knowledge has led to great interest in relation extraction, especially in cases with limited supervision. However, existing distance supervision approaches only extract relations expressed in single sentences. In general, cross-sentence relation extraction is under-explored, even in the supervised-learning setting. In this paper, we propose the first approach for applying distant supervision to crosssentence relation extraction. At the core of our approach is a graph representation that can incorporate both standard dependencies and discourse relations, thus providing a unifying way to model relations within and across sentences. We extract features from multiple paths in this graph, increasing accuracy and robustness when confronted with linguistic variation and analysis error. Experiments on an important extraction task for precision medicine show that our approach can learn an accurate cross-sentence extractor, using only a small existing knowledge base and unlabeled text from biomedical research articles. Compared to the existing distant supervision paradigm, our approach extracted twice as many relations at similar precision, thus demonstrating the prevalence of cross-sentence relations and the promise of our approach.", "creator": "LaTeX with hyperref package"}}}