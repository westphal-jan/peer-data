{"id": "1609.08934", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "28-Sep-2016", "title": "Multiplicative weights, equalizers, and P=PPAD", "abstract": "We show that, by using multiplicative weights in a game-theoretic thought experiment (and an important convexity result on the composition of multiplicative weights with the relative entropy function), a symmetric bimatrix game (that is, a bimatrix matrix wherein the payoff matrix of each player is the transpose of the payoff matrix of the other) either has an interior symmetric equilibrium or there is a pure strategy that is weakly dominated by some mixed strategy. Weakly dominated pure strategies can be detected and eliminated in polynomial time by solving a linear program. Furthermore, interior symmetric equilibria are a special case of a more general notion, namely, that of an \"equalizer,\" which can also be computed efficiently in polynomial time by solving a linear program. An elegant \"symmetrization method\" of bimatrix games [Jurg et al., 1992] and the well-known PPAD-completeness results on equilibrium computation in bimatrix games [Daskalakis et al., 2009, Chen et al., 2009] imply then the compelling P = PPAD.\n\nThe evidence for a linear program (and the best possible model of probability) is well-established for a number of general terms, namely: B, C, and K.\nThe simplest example for a linear program of B = B = C = C = K+2, F , and F = F = F + F + F + F + F + F + F + F + F + F + F + F + F + F + F + F + F + F + F + F + F + F + F + F + F + F + F + F + F + F + F + F + F + F + F + F + F + F + F + F + F + F + F + F + F + F + F + F + F + F + F + F + F + F + F + F + F + F + F + F + F + F + F + F + F + F + F + F + F + F + F + F + F + F + F + F + F + F + F + F + F + F + F + F + F + F + F + F + F + F + F + F + F + F + F + F + F + F + F + F + F + F + F + F + F + F + F", "histories": [["v1", "Wed, 28 Sep 2016 14:43:51 GMT  (17kb)", "http://arxiv.org/abs/1609.08934v1", null]], "reviews": [], "SUBJECTS": "cs.GT cs.CC cs.LG", "authors": ["ioannis avramopoulos"], "accepted": false, "id": "1609.08934"}, "pdf": {"name": "1609.08934.pdf", "metadata": {"source": "CRF", "title": "Multiplicative weights, equalizers, and P=PPAD", "authors": ["Ioannis Avramopoulos"], "emails": [], "sections": [{"heading": null, "text": "ar X\niv :1\n60 9.\n08 93\n4v 1\n[ cs\n.G T\n] 2\n8 Se\np 20\n16\nMultiplicative weights, equalizers, and P=PPAD\nIoannis Avramopoulos\nWe show that, by using multiplicative weights in a game-theoretic thought experiment (and an important convexity result on the composition of multiplicative weights with the relative entropy function), a symmetric bimatrix game (that is, a bimatrix matrix wherein the payoff matrix of each player is the transpose of the payoff matrix of the other) either has an interior symmetric equilibrium or there is a pure strategy that is weakly dominated by some mixed strategy. Weakly dominated pure strategies can be detected and eliminated in polynomial time by solving a linear program. Furthermore, interior symmetric equilibria are a special case of a more general notion, namely, that of an \u201cequalizer,\u201d which can also be computed efficiently in polynomial time by solving a linear program. An elegant \u201csymmetrization method\u201d of bimatrix games [Jurg et al., 1992] and the well-known PPAD-completeness results on equilibrium computation in bimatrix games [Daskalakis et al., 2009, Chen et al., 2009] imply then the compelling P = PPAD."}, {"heading": "1 Introduction", "text": "This paper is an intellectual exercise using multiplicative weights. There are many variants and our results are perhaps not strongly bound to any particular multiplicative weights algorithm, but our favorite is Hedge [Freund and Schapire, 1997, 1999], which we use as a friendly companion to indulge in our intellectual pursuit. Our motivation is to compute Nash equilibria in polynomial time, noting up front that we do not necessarily use Hedge to compute them\u2014for example, we can show as a simple implication of stronger properties that Hedge diverges from the equilibrium of rock-paper-scissors\u2014but we use Hedge to prove some very nice equilibrium properties as well some properties on the structure of strategic games. The fact that Hedge does not necessarily converge is not necessarily bad\u2014we believe it can be used as a powerful model of \u201cevolutionary behavior\u201d (in the sense of dynamical systems as well as that of biology) to explore \u201cterrains\u201d whether physical or conceptual. This paper actually amounts to some notion of proof of such a claim."}, {"heading": "1.1 Our main result", "text": "Our main result is to refute much of the folk wisdom on algorithmic game theory (and perhaps complexity theory in general for that matter) showing P = PPAD."}, {"heading": "1.2 Our detailed questions", "text": "There are many ways to understand the mathematics of this paper, but one of the most fruitful is as a thought experiment: Can multiplicative weights serve as game theory\u2019s foundation? The dominant approach to understanding game theory is by means of the best response, the Nash equilibrium, and how the two are related\u2014the Nash equilibrium is a profile against which no player has an incentive to deviate or, equivalently, it is a fixed point of the game\u2019s best response correspondence. The major problem with this approach is that alternating best responses may oscillate (or worse) and, therefore, game theory\u2019s \u201cnatural dynamic\u201d does not correspond to an equilibrium computation algorithm. Nevertheless, the concept of the best response dynamic is very helpful as it can be used\nto prove that a Nash equilibrium always exists which is soothing in founding a theory of strategic behavior based on the Nash equilibrium. So let us go back to our own question:"}, {"heading": "1.3 Our detailed results and techniques", "text": "Best response dynamics are very problematic because they are discontinuous (and, therefore, often oscillatory or worse). One very prolific way of viewing multiplicative weights is as a continuous approximation of best responses, a point which we support by a lemma: Multiplicative weights are a continuous better response dynamic (for arbitrary values of the learning rate parameter). We do not use this lemma in any of our results and we give it only as an illustration of this important idea. Continuity and the better response property are important in a variety of ways not all of which we explore here. However, our main result crucially relies on this continuity property along with the continuity of the relative entropy function (known also as Kullback-Leibler divergence) and the elementary result in analysis that the composition of continuous functions is continuous."}, {"heading": "1.3.1 Our main overarching strategy", "text": "In contrast to the majority of contributions on equilibrium computation focusing on bimatrix games, we focus instead on the more particular class of symmetric bimatrix games and even more specifically with the computation of symmetric equilibria in this class of games (that is, equilibria wherein both players use the same strategy). Symmetric equilibria in symmetric N -person (and, therefore, also 2-person) games are guaranteed to exist [Nash, 1951]. Symmetric equilibria are also a foundational concept in evolutionary game theory [Maynard Smith and Price, 1973, Maynard Smith, 1982] but we designate evolutionary aspects of equilibrium computation as out of scope of the present paper simply to facilitate a more concise exposition of our results. Having laid out our overarching strategy and approach, we should point out that our main techniques consist in two parts, namely, in definitions and results on the properties of the concepts they define."}, {"heading": "1.3.2 Our main definitions", "text": "An important idea in this paper is captured in the notion of an equalizer, an equilibrium notion generalizing interior equilibria. This idea emerged as follows: Chen et al. [2009] point out that a simple (inefficient) algorithm to find an equilibrium of a (general) bimatrix game is by support enumeration and the solution of a corresponding linear (feasibility) program iteratively for each support until an equilibrium is found. Of course the number of possible supports is exponential and, therefore, this algorithm is inefficient in all games but those with a small number of pure strategies. But there is an important detail in their formulation that can easily go unnoticed:\nGiven some support, the linear program Chen et al. [2009] formulate equalizes the pure strategies in the support and restricts the pure strategies outside the support to yield payoffs that are not superior to the payoffs pure strategies in the support yield. The important observation is that the solution of this linear program can yield an equilibrium lying outside the given support wherein the linear feasibility program is invoked (in that some pure strategies can receive zero probability). The idea of an equalizer emerged in the effort to understand when this phenomenon occurs.\nOne very important \u201ctechnical result\u201d in this paper (which can be used to prove P = PPAD as a simple exercise) is what happens to a symmetric bimatrix game if there is no equalizer. One algorithmically interesting answer is that the absence of an equalizer implies the existence of a weakly dominated pure strategy, which can be detected and eliminated in polynomial time [Conitzer and Sandholm, 2005] without missing out on the overall equilibrium computation objective."}, {"heading": "1.3.3 Our main analytical techniques", "text": "Our proof of this property relies on a pair of lemmas on the behavior of a multiplicative weights dynamic in the vector field of a symmetric bimatrix game which are results that emerged in our effort to prove conditional convergent behavior (conditioned on the behavior of the payoff vector field near an equilibrium). We designate the latter results out of scope to remain concise."}, {"heading": "1.4 Related work", "text": "Our work and contributions in this paper were inspired by the success and beauty of online learning theory, that is, machine learning theory though not in the (most popular) statistical framework but instead in the regret minimization framework viewing nature as a nonstochastic opponent. We apply online learning principles to the problem of Nash equilibrium computation."}, {"heading": "1.4.1 Multiplicative weights", "text": "One of the earliest contributions in online learning is the \u201cweighted majority algorithm\u201d of Littlestone and Warmuth [1994]. Freund and Schapire [1997] extend this algorithm to the problems of \u201conline allocation\u201d as well as that of\u201cboosting.\u201d Arora et al. [2012] treat the history and applications of such algorithms to learning, game theory, and optimization rather comprehensively.\nFreund and Schapire [1999] prove convergence of a multiplicative weights algorithm to the value of a zero-sum game\u2014the algorithm is employed by one of the two player positions and the opponent in the other position is assumed to be arbitrary. We note their result does not imply convergence to the minimax equilibrium, but it furnishes an alternative proof of von Neumann\u2019s minimax theorem.\nMinimax equilibria in zero-sum games (such as the equilibrium of the rock-paper-scissors game) may \u201crepel\u201d the multiplicative weights dynamic (but not always). This is easy to prove using modified versions of analytical techniques employed in this paper (but the proof is omitted for brevity). We note their proof techniques are based on the relative entropy as in this paper.\nSimilar negative results that multiplicative weights are not convergent to Nash equilibria are obtained by [Daskalakis et al., 2010] and [Balkan et al., 2012]. We note that, as mentioned earlier, we do not use multiplicative weights to compute Nash equilibria but rather as a mathematical tool to \u201cprobe\u201d (and characterize) the incentive (payoff) structure of strategic games."}, {"heading": "1.4.2 Equilibrium computation and approximation", "text": "PPAD (Polynomial Parity Arguments on Directed graphs) is a complexity class introduced by Papadimitriou [1994] to capture the difficulty of finding Brouwer fixed points. The archetypical problem in this class is to find an unbalanced vertex in a directed graph given some other unbalanced vertex in the same graph. Such a vertex can always be found but the conjecture was that the amount of time required to find one is exponential. Since PPAD was introduced, various problems have been shown to be PPAD-complete such as that of computing an N -player Nash equilibrium [Daskalakis et al., 2009] and that of computing a 2-player Nash equilibrium [Chen et al., 2009]. Adding support to the conjecture that PPAD captures hard problems, the Lemke-Howson algorithm, generally regarded as the most efficient algorithm for computing a 2-player Nash equilibrium, was shown to run in exponential time in the worst case [Savani and von Stengel, 2004].\nThere are two important threads of results on equilibrium computation and approximation, namely, the approximation of Nash equilibria in bimatrix games and the approximation of KKT (Karush, Kuhn, and Tucker) points in quadratic programs:\n(1) With respect to the first thread of results, under the assumption that PPAD 6= P the most significant open question concerned the existence of a polynomial time approximation scheme (PTAS) for equilibrium computation in bimatrix games (as it was well-known [Chen et al., 2009] that a full polynomial time approximation scheme (FPTAS) would imply P = PPAD, which was considered unlikely). There are two notions of approximation, namely, additive approximations and multiplicative ones. The first quasi-polynomial algorithm for additively approximate Nash equilibria in bimatrix games is due to Lipton et al. [2003] based on the principle of looking for equilibria of small support. There is a rich literature on the additively and multiplicatively approximations of Nash equilibria. An interesting alternative approach, however, is to find an exact Nash equilibrium with high probability. Ba\u0301ra\u0301ny et al. [2005] present an algorithm for finding a Nash equilibrium in random 2-player games that runs in polynomial time with high probability. This algorithm is based on searching for equilibria of small support. We note that the general methods employed in this thread of research depart significantly from our algorithmic and proof techniques:\nThe algorithm we present in this paper instead looks for equilibria of (possibly) large support (as equalizers are typically, but not always so, interior equilibria) and iteratively reduces the size of the game (by iterated elimination of weakly dominated pure strategies), checking for an equalizer in each step, until a single pure strategy remains (implying the game is dominance solvable). Alternatively, one may iteratively reduce the size of the basis game by iterated elimination until no further reduction is possible in which case our results imply the existence of an equalizer. As noted earlier, in contrast to other previous equilibrium computation efforts, our algorithm focuses on symmetric bimatrix games trying to find an equilibrium that is symmetric. (Given a bimatrix game an \u201cequivalent\u201d symmetric bimatrix game can be obtained by the Gale, Kuhn, and Tucker symmetrization method [Jurg et al., 1992].) We have not verified if the absence of an equalizer in general bimatrix games implies the existence of a weakly dominated pure strategy.\n(2) With respect to the second thread of results symmetric equilibria in doubly symmetric bimatrix games (that is, symmetric bimatrix games wherein the payoff matrix is symmetric) are known to coincide with KKT points of a quadratic optimization problem whose objective function is X \u00b7SX, where S is the symmetric payoff matrix and X is a mixed strategy, and whose constraint set is a standard (probability) simplex corresponding to the space of mixed strategies. The computation of KKT points in (general) quadratic programs is known to admit an FPTAS [Ye, 1998]. Our results in this paper imply a polynomial-time algorithm for computing KKT points of quadratic programs over the probability simplex. We believe that our results can be extended to general quadratic programs (over general polytopes) but we have not verified the conjecture."}, {"heading": "1.5 Overview of the rest of the paper", "text": "Section 2 discusses preliminaries on bimatrix games and Nash equilibria. Section 3 gives our equilibrium computation algorithm. We subsequently move on to prove its correctness starting with a preliminary technical result on the structure of the best response correspondence in Section 4. Section 5 is concerned with the definition and properties of \u201cmultiplicative weights dynamics\u201d where some powerful technical lemmas important in the main result of this paper are stated and proven. Section 6 proves our main result concerning an elementary property of a symmetric bimatrix game without an equalizer, which is used to furnish a simple proof that P = PPAD in the same section. Finally, Section 7 concludes the paper."}, {"heading": "2 Preliminaries on bimatrix games", "text": ""}, {"heading": "2.1 Bimatrix games", "text": "A 2-player (bimatrix) game in normal form is specified by a pair of n\u00d7m matrices A and B, the former corresponding to the row player and the latter to the column player. If B = AT , where AT is the transpose of A, the game is called symmetric. A mixed strategy for the row player is a probability vector P \u2208 Rn and a mixed strategy for the column player is a probability vector Q \u2208 Rm. The payoff to the row player of P against Q is P \u00b7 AQ and that to the column player is P \u00b7BQ. Let us denote the space of probability vectors for the row player by P and the corresponding space for the column player by Q. A Nash equilibrium of a 2-player game (A,B) is a pair of mixed strategies P \u2217 and Q\u2217 such that all unilateral deviations from these strategies are not profitable, that is, for all P \u2208 P and Q \u2208 Q, we simultaneously have that\nP \u2217 \u00b7AQ\u2217 \u2265 P \u00b7AQ\u2217"}, {"heading": "P \u2217 \u00b7 BQ\u2217 \u2265 P \u2217 \u00b7 BQ.", "text": "We denote the set of Nash equilibria of (A,B) by NE(A,B)."}, {"heading": "2.2 Symmetric bimatrix games", "text": "Let (C,CT ) be a symmetric bimatrix game. We call a Nash equilibrium (P \u2217, Q\u2217) of (C,CT ) symmetric if P \u2217 = Q\u2217. Let (X\u2217,X\u2217) be a symmetric equilibrium. Then we call X\u2217 a symmetric equilibrium strategy of (C,CT ). A well-known result due to Nash is that every symmetric N -person game, and, therefore, also every symmetric bimatrix game, has a symmetric equilibrium.\nGiven (C,CT ), we denote its set of pure strategies by K(C,CT ) = {1, . . . , n}. Pure strategies are denoted either as i or as Ei, a probability vector whose mass is concentrated in position i. We denote the probability simplex in Rn, where n is the number of pure strategies of (C,CT ), by X(C,CT ). We often refer to X(C,CT ) either as the probability simplex of (C,CT ) or as the evolution space of (C,CT ), and it corresponds to the space of mixed strategies. We denote the set of Nash equilibria of (C,CT ) by NE(C,CT ) and the set of symmetric Nash equilibrium strategies thereof by NE+(C,CT ). Let X \u2208 X(C,CT ) and define\nC(X) . = {i \u2208 {1, . . . , n}|X(i) > 0} .\nWe call C(X) the carrier or support of strategy X \u2208 X(C,CT ). We call X \u2208 X(C,CT ) interior if C(X) = {1, . . . , n}. We denote the relative interior of X(C,CT ) (that is, the set of all interior strategies of X(C,CT )) by X\u030a(C,CT ) and its boundary X\u0304(C,CT ). The carrier game of a strategy X \u2208 X(C,CT ) is the symmetric subgame of (C,CT ) whose pure strategies correspond to C(X)."}, {"heading": "3 Equilibrium computation algorithm", "text": "Let us first give the algorithm we propose for finding a symmetric equilibrium in a symmetric bimatrix game. We first need to declare some subroutines:"}, {"heading": "3.1 Equalizer equilibria (or equalizers)", "text": "The first subroutine we need checks if a symmetric bimatrix game has an \u201cequalizer\u201d and if so computes one. The declaration of this subroutine is:\nEqualizer(C)\nThe input is the payoff matrix C of a symmetric bimatrix game (C,CT ) and the output is either NULL if there is no \u201cequalizer\u201d of (C,CT ) or otherwise the output is a mixed strategy of (C,CT ) corresponding to an \u201cequalizer\u201d of (C,CT ). But let us precisely define what the subroutine checks for (or computes)\u2014to that end we start with the definition of an \u201cequalizer:\u201d\nDefinition 1. X\u2217 \u2208 X(C,CT ) is called an equalizer if\n\u2200X \u2208 X(C,CT ) : (X\u2217 \u2212X) \u00b7 CX\u2217 = 0.\nWe denote the set of equalizers of (C,CT ) by E(C,CT ).\nNote that E(C,CT ) \u2286 NE+(C,CT ). Equalizers generalize interior symmetric equilibrium strategies, as every such strategy is an equalizer, but there exist symmetric bimatrix games with a non-interior equalizer (for example, if a column of C is constant, the corresponding pure strategy of (C,CT ) is an equalizer of (C,CT )). Note that an equalizer can be computed in polynomial time by solving the linear (feasibility) program (LP)\n(CX)1 = \u00b7 \u00b7 \u00b7 = (CX)n, n \u2211\ni=1\nX(i) = 1, X \u2265 0,\nwhich we may equivalently write as\nCX = c1, 1TX = 1, X \u2265 0,\nwhere 1 is a column vector of ones of appropriate dimension. We may write this problem as a standard LP as follows: Let\nA . =\n[\nC \u22121 1T 0\n]\nand Y . =\n[\nX c\n]\n.\nthen\nAY =\n[\nC \u22121 1T 0\n] [\nX c\n]\n=\n[\nCX \u2212 c1 1TX\n]\n,\nand the standard form of our LP, assuming C > 0, is\n[\nCX \u2212 c1 1TX\n]\n=\n[\n0 1\n]\n,X \u2265 0, c \u2265 0\nwhere 0 is a column vector of zeros of appropriate dimension."}, {"heading": "3.2 Strictly and weakly dominated strategies", "text": "The second subroutine we need checks if a pure strategy, say Ei, of a symmetric bimatrix game is \u201cweakly dominated.\u201d The declaration of this subroutine is:\nWeakly-dominated(i, C)\nThis subroutine receives as a input a pure strategy i \u2208 K(C,CT ) and returns as output either True if the pure strategy is \u201cweakly dominated\u201d by some mixed strategy and False otherwise. But let us precisely define the (well-known in game theory) notion of dominance and see how this subroutine can run in polynomial time (with the complexity of linear programming).\nThere are two versions of dominance the stronger of which is commonly referred to as \u201cstrict dominance.\u201d Let us give the precise definition:\nDefinition 2. We say that the pure strategy Ei of (C,C T ) is strictly dominated if\n\u2203X \u2208 X(C,CT ) \u2200Y \u2208 X(C,CT ) : Ei \u00b7 CY < X \u00b7 CY.\nIt is well known that eliminating a strictly dominated strategy cannot eliminate equilibria. Our primary concern though is with a weaker dominance notion which doesn\u2019t have this property:\nDefinition 3. We say that the pure strategy Ei of (C,C T ) is weakly dominated if\n\u2203X \u2208 X(C,CT ) \u2200Y \u2208 X(C,CT ) : Ei \u00b7 CY \u2264 X \u00b7 CY\nand\n\u2203Y \u2208 X(C,CT ) : Ei \u00b7 CY < X \u00b7 CY.\nIf Ei is not weakly dominated we say it is undominated.\nUnlike strict elimination, eliminating weakly dominated strategies can eliminate equilibria, however, every equilibrium of the surviving subgame is also an equilibrium of the basis game. (Note also that, in weak iterated elimination, the order of elimination matters in that the surviving equilibria depend on the order by which strategies are eliminated. This matter is rather tangential to the main subject and result of this paper although a careful treatment of the subject is certainly important. Note that checking if a pure strategy is weakly dominated (by some mixed strategy) admits a polynomial-time algorithm (with the complexity of linear programming) [Conitzer and Sandholm, 2005] (see also [Myerson, 1991] and for iterated dominance see also [Knuth et al., 1988])."}, {"heading": "3.3 The equilibrium computation algorithm", "text": "We may now give the pseudocode for the equilibrium computation algorithm (as Algorithm 1) computing a symmetric equilibrium (that is, a Nash equilibrium wherein both players use the same strategy) in a symmetric bimatrix game\u2014such an equilibrium is guaranteed to exist [Nash, 1951].\nAlgorithm 1 Symmetric-2-player-Nash(C)\n1: if Size(C) == 1 then 2: return 1 3: else 4: if (X\u2217 = Equalizer(C)) != NULL then 5: return X\u2217\n6: else 7: i = 1 8: while Weakly-dominated(i, C) == False do 9: i++\n10: end while 11: Y \u2217 = Symmetric-2-player-Nash(C/{Ei}) 12: return Zero-Pad(Y \u2217) 13: end if\n14: end if\nNotice the structure of the code is recursive: The algorithm receives as input the payoff matrix C of a symmetric bimatrix game (C,CT ) and returns as output a symmetric equilibrium strategy of (C,CT ). Let us briefly go through the pseudocode: If there is only one pure strategy (Line 1), 1 is returned as the solution, that is, a probability vector of one entry (Line 2). If the number of pure strategies is greater than one, the algorithm first checks (in Line 4) if (C,CT ) has an equalizer (an operation that can be performed by solving an LP as noted earlier). If there is an equalizer, the routine terminates with the equalizer as the output (Line 5). Otherwise the algorithm iteratively looks for a weakly dominated pure strategy (Lines 7 to 10) and recursive calls itself on the symmetric subgame that is obtained by removing the pure strategy from the set of pure strategies (Line 11). Padding with zeros (Line 12) ensures consistency of the recursive calls. Note there are other related variants of this specific (pseudocode) implementation that also work.\nWe may now proceed to prove the previous algorithm\u2019s correctness. We start off by giving some elementary and well-known definitions and propositions on \u201cbest responses\u201d for completeness:"}, {"heading": "4 Best responses", "text": "In this section, we give basic background on best responses. Propositions 1, 2, and 3 are standard.\nDefinition 4. Let (A,B) be a bimatrix game and P\u00d7Q be the space of strategy profiles of (A,B). Let Q \u2208 Q be an arbitrary column-player strategy. We say P \u2217(Q) \u2208 P is a best response to Q if"}, {"heading": "P \u2217(Q) \u2208 argmax {P \u00b7AQ|P \u2208 P} .", "text": "Best responses of the column player against row-player strategies are defined similarly.\nWe have the following characterization of Nash equilibria in bimatrix games.\nProposition 1. (X\u2217, Y \u2217) \u2208 P \u00d7Q is a Nash equilibrium of (A,B) if and only if X\u2217 \u2208 P is a best response to Y \u2217 \u2208 Q and, similarly, Y \u2217 is a best response to X\u2217.\nProof. Straightforward from the definition of a Nash equilibrium.\nAn important elementary property of best responses is given by the (aforementioned) best response condition [von Stengel, 2007]:\nProposition 2. Given (A,B) let A and B be m\u00d7n matrices, P\u00d7Q be the space of mixed strategy profiles of (A,B), X \u2208 P, and Y \u2208 Q. Then X is a best response to Y if and only if\n\u2200i = {1, . . . ,m} :\n[\nX(i) > 0 \u21d2 (AY )i = (AY )max \u2261 m\nmax i=1 (AY )i\n]\n.\nThe best response condition implies the following proposition.\nProposition 3. (X\u2217, Y \u2217) \u2208 NE(A,B) if and only if we simultaneously have:\n(i) for all pure strategies Ei \u2208 P such that i \u2208 C(X \u2217), Ei is a best response to Y \u2217 and (ii) for all pure strategies Ej \u2208 Q such that j \u2208 C(Y \u2217), Ej is a best response to X \u2217,\nwhere P\u00d7Q is the space of mixed strategies of (A,B)."}, {"heading": "5 Multiplicative weights: Properties and lemmas", "text": "The next step in the algorithm\u2019s correctness proof is a set of lemmas on \u201cmultiplicative weights dynamics.\u201d The specific dynamic we use to \u201cprobe\u201d the mathematical structure and properties of symmetric bimatrix games is based on Hedge [Freund and Schapire, 1997, 1999]. In this setting, Hedge induces the following dynamic:\nTi(X) = X(i) \u00b7 exp {\u03b1Ei \u00b7 CX}\n\u2211n j=1X(j) exp {\u03b1Ej \u00b7 CX}\n, i = 1, . . . , n. (1)\nIn this section, we give some properties of (1). We first show that X(C,CT ) is invariant under T in that T never escapes the space of mixed strategies of the game (C,CT ) in which it is invoked. Actually we also show that if T is started in the relative interior of X(C,CT ), T cannot escape X\u030a(C,CT ) in a finite number of steps. Then we characterize fixed points and prove some powerful lemmas. We also prove the promised \u201cbetter response property\u201d as Lemma 8 below."}, {"heading": "5.1 Invariance", "text": "Note that, in general, \u03b1 (typically referred to as the learning rate) may depend on X\u2014we make this explicit in somes lemmas for clarity.\nLemma 1. We have\n\u2200\u03b1(X) \u2265 0 : X \u2208 X(C,CT ) \u21d2 T (X) \u2208 X(C,CT )\nand\n\u2200\u03b1(X) \u2265 0 : X \u2208 X\u030a(C,CT ) \u21d2 T (X) \u2208 X\u030a(C,CT ),\nwhere T is as in (1).\nProof. We have that, given any X \u2208 X(C,CT ),\n\u2200\u03b1(X) \u2265 0 : n \u2211\ni=1\nTi(X) =\n\n\nn \u2211\nj=1\nX(j) exp {\u03b1(X)Ej \u00b7 CX}\n\n\n\u22121\n\u00b7 n \u2211\ni=1\nX(i) exp {\u03b1(X)Ei \u00b7 CX} = 1,\nimplying positive invariance of X(C,CT ). Furthermore,\n\u2200\u03b1(X) \u2265 0 : X(i) > 0 \u21d2 Ti(X) > 0,\nfurther implying positive invariance of the relative interior X\u030a(C,CT )."}, {"heading": "5.2 Fixed points of Hedge", "text": "One of game theory\u2019s principles is that \u201cequilibrium\u201d is synonymous to Nash equilibrium, defined as a fixed point of the best response correspondence. The first order principle of the multiplicative weights approach to game theory is, not surprisingly, a fixed point of the multiplicative weights dynamic. In this section, we show how the two concepts are related. We refer to Nash fixed points as \u201cequilibria\u201d and to multiplicative weights fixed points as \u201cfixed points\u201d simply for reasons of remaining backward compatible with the game-theoretic nomenclature.\nDefinition 5. We say X\u2217 \u2208 X(C,CT ) is a fixed point of (C,CT ) if it is a fixed point of (1). That is, if X\u2217 = T (X\u2217). We denote the set of fixed points of (C,CT ) by FX(C,CT ). Note that\n\u2200i \u2208 K(C,CT ) : Ei \u2208 FX(C,C T ).\nWe denote the non-pure fixed points of (C,CT ) by FX+(C,CT ).\nWe have the following characterization of fixed points.\nTheorem 1. X \u2208 FX(C,CT ) if and only if, X is a pure strategy or otherwise\n\u2200i, j \u2208 C(X) : (CX)i = (CX)j .\nProof. First we show sufficiency, that is, if for all i, j \u2208 C(X), (CX)i = (CX)j , then T (X) = X: Some of the coordinates of X are zero and some are positive. Clearly, the zero coordinates will not become positive after applying the map. Now, notice that, for all i \u2208 C(X), exp{\u03b1(X)(CX)i} = \u2211n\nj=1X(j) exp{\u03b1(X)(CX)j}. Therefore, T (X) = X. Now we show necessity, that is, ifX is a fixed point of Hedge, then for all i and for all i, j \u2208 C(X),\n(CX)i = (CX)j : Let X\u0302(i) = Ti(x). Because X is a fixed point, X\u0302(i) = X(i). Therefore,\nX\u0302(i) = X(i)\nX(i) exp {\u03b1(X)(CX)i} \u2211\nj X(j) exp {\u03b1(X)(CX)j} = X(i)\nexp {\u03b1(X)(CX)i} = \u2211\nj\nX(j) exp {\u03b1(X)(CX)j},\nwhich implies exp {\u03b1(X)((CX)i \u2212 (CX)j)} = 1,X(i) > 0,\nand, thus, (CX)i = (CX)j ,X(i) > 0.\nThis completes the proof.\nThe previous theorem says that X\u2217 \u2208 FX(C,CT ) if and only if X\u2217 is an equalizer of its carrier game. This is a necessary condition for equilibrium but it is not sufficient:\nLemma 2. If X\u2217 \u2208 X\u030a(C,CT ), X\u2217 \u2208 FX(C,CT ) if and only if X\u2217 \u2208 NE+(C,CT ).\nProof. The lemma is a straightforward implication of the aforementioned best response condition and Theorem 1: Suppose the interior X\u2217 \u2208 NE+(C,CT ) and recall the best response condition: X is a best response to Y if and only if X(i) > 0 \u21d2 (CY )i = (CY )max. But a symmetric Nash equilibrium strategy is a best response to itself, therefore, X\u2217(i) > 0 \u21d2 (CX\u2217)i = (CX\n\u2217)max. Since X\u2217 is interior, for all i \u2208 K(C,CT ), X\u2217(i) > 0, therefore,\n\u2200i, j \u2208 C(X\u2217) : (CX\u2217)i = (CX \u2217)j .\nThe characterization of fixed points in Theorem 1 completes the proof.\nAs a straightforward implication of the previous lemma we obtain:\nLemma 3. If X\u2217 \u2208 FX(C,CT )/NE+(C,CT ), then X\u2217 \u2208 X\u0304(C,CT ). That is, every non-equilibrium fixed point is a boundary strategy.\nProof. If X\u2217 6\u2208 X\u0304(C,CT ), then X\u2217 \u2208 X\u030a(C,CT ).\nOverall we obtain:\nCorollary 1. NE+(C,CT ) \u2286 FX(C,CT ).\nProof. Every symmetric equilibrium strategy is an equalizer of the its corresponding carrier game by Lemma 2.\nThe fundamental difference between fixed points and equilibria is that fixed points survive \u201cinversion\u201d of incentives. We call this principle \u201cthe virtue of vice versa\u201d and it is proven next:\nTheorem 2. FX(C,CT ) = FX(\u2212C,\u2212CT ).\nProof. The theorem clearly holds for all pure fixed points. Furthermore, by Theorem 1, X\u2217 \u2208 FX+(C,CT ) if and only if\n\u2200X \u2208 X(C\u2217, C\u2217T ) : (X\u2217 \u2212X) \u00b7 C\u2217X\u2217 = 0\nwhere C\u2217 is X\u2217\u2019s carrier game. This completes the proof.\nWe do not invoke the virtue of vice versa in this paper, but it is important to keep in mind."}, {"heading": "5.3 Some lemmas", "text": ""}, {"heading": "5.3.1 Preliminaries: Relative entropy (or Kullback-Leibler divergence)", "text": "Our analysis of multiplicative weights dynamics relies on the relative entropy function between probability distributions (also called Kullback-Leibler divergence). The relative entropy between the n\u00d7 1 probability vectors P > 0 (that is, for all i = 1, . . . , n, P (i) > 0) and Q > 0 is given by\nRE(P,Q) . =\nn \u2211\ni=1\nP (i) ln P (i)\nQ(i) .\nHowever, this definition can be relaxed: The relative entropy between n\u00d7 1 probability vectors P and Q such that, given P , for all Q \u2208 {Q \u2208 X|C(P ) \u2282 C(Q)}, is\nRE(P,Q) . = \u2211\ni\u2208C(P )\nP (i) ln P (i)\nQ(i) .\nWe note the standard well-known properties of the relative entropy [Weibull, 1995, p.96] that (i) RE(P,Q) \u2265 0, (ii) RE(P,Q) \u2265 \u2016P \u2212Q\u20162, where \u2016\u00b7\u2016 is the Euclidean distance, (iii) RE(P,P ) = 0, and (iv) RE(P,Q) = 0 iff P = Q. Note (i) follows from (ii) and (iv) follows from (ii) and (iii)."}, {"heading": "5.3.2 The convexity lemma", "text": "Lemma 4. Let T be as in (1). Then\n\u2200X \u2208 X\u030a(C,CT ) \u2200Y \u2208 X(C,CT ) : RE(Y, T (X)) is a convex function of \u03b1 \u2265 0.\nFurthermore, unless X \u2208 FX(C,CT ), RE(Y, T (X)) is a strictly convex function of \u03b1 > 0.\nProof. We have\nd\nd\u03b1 RE(Y, X\u0302) =\n= d\nd\u03b1\n\n\n\u2211\ni\u2208C(Y )\nY (i) ln\n(\nY (i)\nX\u0302(i)\n)\n\n\n= d\nd\u03b1\n\n\n\u2211\ni\u2208C(Y )\nY (i) ln\n(\nY (i) \u00b7\n\u2211n j=1X(j) exp{\u03b1(CX)j}\nX(i) exp{\u03b1(CX)i}\n)\n\n\n= d\nd\u03b1\n\n\n\u2211\ni\u2208C(Y )\nY (i) ln\n(\n\u2211n j=1X(j) exp{\u03b1(CX)j}\nX(i) exp{\u03b1(CX)i}\n)\n\n\n= \u2211\ni\u2208C(Y )\nY (i) d\nd\u03b1\n(\nln\n(\n\u2211n j=1X(j) exp{\u03b1(CX)j}\nX(i) exp{\u03b1(CX)i}\n))\n.\nFurthermore, using (\u00b7)\u2032 as alternative notation (abbreviation) for d/d\u03b1(\u00b7),\nd\nd\u03b1\n(\nln\n(\n\u2211n j=1X(j) exp{\u03b1(CX)j}\nX(i) exp{\u03b1(CX)i}\n))\n= X(i) exp{\u03b1(CX)i}\n\u2211n j=1X(j) exp{\u03b1(CX)j}\n(\n\u2211n j=1X(j) exp{\u03b1(CX)j}\nX(i) exp{\u03b1(CX)i}\n)\u2032\nand (\n\u2211n j=1X(j) exp{\u03b1(CX)j}\nX(i) exp{\u03b1(CX)i}\n)\u2032\n=\n\u2211n j=1X(j)(CX)j exp{\u03b1(CX)j}X(i) exp{\u03b1(CX)i}\n(X(i) exp{\u03b1(CX)i}) 2 \u2212\n\u2212 X(i)(CX)i\n\u2211n j=1X(j) exp{\u03b1(CX)j} exp{\u03b1(CX)i}\n(X(i) exp{\u03b1(CX)i}) 2 =\n=\n\u2211n j=1X(j)(CX)j exp{\u03b1(CX)j}}\nX(i) exp{\u03b1(CX)i} \u2212\n\u2212 (CX)i\n\u2211n j=1X(j) exp{\u03b1(CX)j}}\nX(i) exp{\u03b1(CX)i} .\nTherefore,\nd\nd\u03b1 RE(Y, X\u0302) =\n\u2211n j=1X(j)(CX)j exp{\u03b1(CX)j} \u2211n\nj=1X(j) exp{\u03b1(CX)j} \u2212 Y \u00b7 CX. (2)\nFurthermore,\nd2\nd\u03b12 RE(Y, X\u0302) =\n(\n\u2211n j=1X(j)((CX)j) 2 exp{\u03b1(CX)j} )( \u2211n j=1X(j) exp{\u03b1(CX)j} )\n(\n\u2211n j=1X(j) exp{\u03b1(CX)j}\n)2 \u2212\n\u2212\n(\n\u2211n j=1X(j)((CX)j) exp{\u03b1(CX)j}\n)2\n(\n\u2211n j=1X(j) exp{\u03b1(CX)j}\n)2 .\nJensen\u2019s inequality implies that\n\u2211n j=1X(j)((CX)j) 2 exp{\u03b1(CX)j} \u2211n\nj=1X(j) exp{\u03b1(CX)j} \u2265\n(\n\u2211n j=1X(j)((CX)j) exp{\u03b1(CX)j} \u2211n\nj=1X(j) exp{\u03b1(CX)j}\n)2\n,\nwhich is equivalent to the numerator of the second derivative being nonnegative asX is a probability vector. Note that the inequality is strict unless\n\u2200i, j \u2208 C(X) : (CX)i = (CX)j .\nThis completes the proof."}, {"heading": "5.3.3 The stability lemmas", "text": "In the next lemma, we invoke the convexity lemma. We have:\nLemma 5. Let Y,X \u2208 X(C,CT ) such that C(Y ) \u2282 C(X) and such that (Y \u2212X) \u00b7 CX > 0. Then there exists \u03b1\u0304 > 0 (which may depend on Y and X) such that\n\u2200\u03b1 \u2208 (0, \u03b1\u0304) : RE(Y, X\u0302) < RE(Y,X),\nwhere X\u0302 = T (X) and T is as in (1).\nProof. (2) implies that\nd\nd\u03b1 RE(Y, X\u0302)\n\u2223 \u2223 \u2223 \u2223\n\u03b1=0\n= (X \u2212 Y ) \u00b7 CX < 0.\nBy the convexity RE(Y, X\u0302) as a function of \u03b1 either\n\u2200\u03b1 > 0 : RE(Y, X\u0302) < RE(Y,X)\nor\n\u2203\u03b1\u0304 > 0 : RE(Y, X\u0302) = RE(Y,X)\nimplying\n\u2200\u03b1 \u2208 (0, \u03b1\u0304) : RE(Y, X\u0302) < RE(Y,X)\nas claimed.\nUnder an additional assumption we can show an even stronger (important in our main result) property:\nLemma 6. Let X be an interior strategy in the probability simplex of (C,CT ), assume X 6\u2208 NE+(C,CT ) and let\nY \u2208 argmax{Y \u00b7 CX|Y \u2208 X(C,CT )}.\nThat is, Y is a best response to X. Then\n\u2200\u03b1 > 0 : RE(Y, X\u0302) < RE(Y,X),\nwhere X\u0302 = T (X) and T is as in (1).\nProof. If X \u2208 NE+(C,CT ), \u2200\u03b1 \u2265 0 : RE(Y, X\u0302) = RE(Y,X) since \u2200\u03b1 \u2265 0 : X\u0302 = X. Otherwise:\nRE(Y, X\u0302)\u2212RE(Y,X) = \u2211\ni\u2208C(Y )\nY (i) ln\n(\n\u2211n j=1X(j) exp{\u03b1(CX)j}\nexp{\u03b1(CX)i}\n)\n(3)\n= ln\n\n\nn \u2211\nj=1\nX(j) exp{\u03b1(CX)j}\n\n\u2212 \u03b1Y \u00b7 CX (4)\n= ln\n\n\nn \u2211\nj=1\nX(j) exp {\u03b1 ((CX)j \u2212 Y \u00b7 CX)}\n\n (5)\n\u2264 n \u2211\nj=1\nX(j) exp {\u03b1 ((CX)j \u2212 Y \u00b7 CX)} \u2212 1. (6)\n(3) follows by plugging in the definition of relative entropy and straight algebra. (4) follows by straightforward properties of the natural logarithm. (5) follows similarly. (6) follows from the standard property of the natural logarithm that ln(y) \u2264 y \u2212 1, y > 0.\nIf\n\u2200j \u2208 {1, . . . , n} : (CX)j = Y \u00b7 CX,\nthen X \u2208 NE+(C,CT ) and, as noted earlier, in this case\n\u2200\u03b1 \u2265 0 : RE(Y, X\u0302) = RE(Y,X).\nAssume, therefore, that\nY \u00b7 CX = n\nmax j=1\n(CX)j > n\nmin j=1 (CX)j ,\nwhere the inequality on the left follows by the best response condition (Proposition 2). Then\n\u2200\u03b1 \u2265 0 : exp {\u03b1 ((CX)j \u2212 Y \u00b7 CX)} \u2264 1\nand there exists j \u2208 {1, . . . , n} such that\n\u2200\u03b1 > 0 : exp {\u03b1 ((CX)j \u2212 Y \u00b7 CX)} < 1.\nTherefore,\n\u2200\u03b1 > 0 : n \u2211\nj=1\nX(j) exp {\u03b1 ((CX)j \u2212 Y \u00b7 CX)} < n \u2211\nj=1\nX(j) = 1.\nThis completes the proof."}, {"heading": "5.3.4 An instability lemma", "text": "The following lemma is crucial. We can prove it in two ways, one invoking the aforementioned convexity lemma and the other by simply invoking Jensen\u2019s inequality. We show both proofs:\nLemma 7. Let Y,X \u2208 X(C,CT ) such that C(Y ) \u2286 C(X) and such that Y 6= X. If\nmax {(CX)i|i \u2208 C(X)} > min{(CX)i|i \u2208 C(X)} ,\nthen\nX \u00b7 CX \u2212 Y \u00b7 CX \u2265 0 \u21d2 \u2200\u03b1 > 0 : RE(Y, X\u0302)\u2212RE(Y,X) > 0.\nwhere X\u0302 = T (X) and T is as in (1).\nProof. We have, by Jensen\u2019s inequality, that\nRE(Y, X\u0302)\u2212RE(Y,X) = \u2211\ni\u2208C(Y )\nY (i) ln Y (i)\nX\u0302(i) \u2212\n\u2211\ni\u2208C(Y )\nY (i) ln Y (i)\nX(i)\n= \u2212 \u2211\ni\u2208C(Y )\nY (i) ln X\u0302(i) + \u2211\ni\u2208C(Y )\nY (i) lnX(i)\n= \u2211\ni\u2208C(Y )\nY (i) ln X(i)\nX\u0302(i)\n= \u2211\ni\u2208C(Y )\nY (i) ln\n(\n\u2211n j=1X(j) exp{\u03b1Ej \u00b7 CX}\nexp{\u03b1Ei \u00b7 CX}\n)\n= ln\n\n\nn \u2211\nj=1\nX(j) exp{\u03b1Ej \u00b7 CX}\n\n\u2212 \u2211\ni\u2208C(Y )\nY (i) ln (exp{\u03b1Ei \u00b7 CX})\n= ln\n\n\nn \u2211\nj=1\nX(j) exp{\u03b1Ej \u00b7 CX}\n\n\u2212 \u03b1 \u2211\ni\u2208C(Y )\nY (i)(Ei \u00b7 CX)\n\u2265 \u03b1 n \u2211\nj=1\nX(j)(Ej \u00b7 CX)\u2212 \u03b1 \u2211\ni\u2208C(Y )\nY (i)(Ei \u00b7 CX)\n= \u03b1(X \u00b7 CX \u2212 Y \u00b7 CX).\nTherefore,\nX \u00b7 CX \u2212 Y \u00b7 CX \u2265 0 \u21d2 \u2200\u03b1 > 0 : RE(Y, X\u0302)\u2212RE(Y,X) \u2265 0.\nIf maxi\u2208C(X){(CX)i} > mini\u2208C(X){(CX)i}, since Jensen\u2019s inequality is strict,\nX \u00b7 CX \u2212 Y \u00b7 CX \u2265 0 \u21d2 \u2200\u03b1 > 0 : RE(Y, X\u0302)\u2212RE(Y,X) > 0.\nThis completes the proof.\nSecond proof of Lemma 7. By the convexity lemma (Lemma 4), unless X \u2208 FX(C,CT ), RE(Y, X\u0302) is strictly convex. (2) implies that\nd\nd\u03b1 RE(Y, X\u0302)\n\u2223 \u2223 \u2223 \u2223\n\u03b1=0\n= (X \u2212 Y ) \u00b7 CX \u2265 0.\nNoting that RE(Y, X\u0302) \u2223 \u2223\n\u2223 \u03b1=0 = RE(Y,X) completes the proof."}, {"heading": "5.4 Better response property", "text": "Let us finally show our promised \u201cbetter response property.\u201d\nDefinition 6. We say that the map T : X(C,CT ) \u2192 X(C,CT ) is a better response dynamic if\n\u2200X \u2208 X : (X\u0302 \u2212X) \u00b7 CX > 0,\nwhere X\u0302 = T (X), unless X is a fixed point of T .\nThe next lemma shows that T as defined in (1) is a better response dynamic.\nLemma 8. X \u2208 X\u030a(C,CT ) implies X\u0302 \u00b7 CX \u2261 T (X) \u00b7 CX > X \u00b7 CX unless X \u2208 FX(C,CT ).\nProof. Suppose first that X 6\u2208 NE+(C,CT ), which implies (CX)max > (CX)min. Since the relative entropy between X\u0302 and X is positive:\nRE(X\u0302,X) =\nn \u2211\ni=1\nX\u0302(i) ln\n(\nX\u0302(i)\nX(i)\n)\n=\nn \u2211\ni=1\nX\u0302(i) ln\n(\nexp {\u03b1(X)Ei \u00b7 CX} \u2211n\nj=1X(j) exp {\u03b1(X)Ej \u00b7 CX}\n)\n> 0.\nTherefore,\nln\n\n\nn \u2211\nj=1\nX(j) exp {\u03b1(X)Ej \u00b7 CX}\n\n <\nn \u2211\ni=1\nX\u0302(i) ln (exp {\u03b1(X)Ei \u00b7 CX}) = \u03b1(X)X\u0302 \u00b7 CX. (7)\nFurthermore, since ln(\u00b7) is concave, we obtain by Jensen\u2019s inequality that\n\u03b1X \u00b7 CX < ln\n\n\nn \u2211\nj=1\nX(j) exp {\u03b1(X)Ej \u00b7 CX}\n\n . (8)\n(7) and (8) imply that\n(X\u0302 \u2212X) \u00b7 CX > 0\nas desired. If X \u2208 FX(C,CT ), Theorem 1 implies X\u0302 = X."}, {"heading": "6 Correctness proof of the equilibrium computation algorithm", "text": "In this section, we prove the correctness of Algorithm 1 and P = PPAD. We need the following result on strategic dominance due to Pearce [1984] (see also [Weibull, 1995, p. 14]):\nProposition 4. The pure strategy Ei of (C,C T ) is undominated if and only if\n\u2203X \u2208 X\u030a(C,CT ) : Ei is a best response to X.\nWe also need the following lemmas:\nLemma 9. Let Y \u2208 X\u0304(C,CT ) and X \u2208 X\u030a(C,CT ). If RE(Y, T (X)) is strictly convex, then exactly one of the following hold:\n(i) lim\u03b1\u2192\u221e (RE(Y, T (X)) \u2212RE(Y,X)) = +\u221e.\n(ii) lim\u03b1\u2192\u221e (RE(Y, T (X)) \u2212RE(Y,X)) < 0.\nFurthermore, a necessary and sufficient condition for (ii) is that Y is a best response to X.\nProof. By the \u201cconvexity lemma\u201d (Lemma 4), RE(Y, T (X)) is strictly convex if and only if X is not a fixed point. So let us assume this is the case. There are now three possibilities:\nFirst possibility: Assume (Y \u2212X) \u00b7 CX \u2264 0. Then the \u201cinstability lemma\u201d (Lemma 7) implies\nlim \u03b1\u2192\u221e (RE(Y, T (X)) \u2212RE(Y,X)) = +\u221e.\nSecond possibility: Assume (Y \u2212X) \u00b7 CX > 0 but Y is not a best response to X. Recall (5):\nRE(Y, X\u0302)\u2212RE(Y,X) = ln\n\n\nn \u2211\nj=1\nX(j) exp {\u03b1 ((CX)j \u2212 Y \u00b7 CX)}\n\n\nand note that by the assumption that Y is not a best response to X there exists i such that (CX)i > Y \u00b7 CX implying that\nlim \u03b1\u2192\u221e\n\n\nn \u2211\nj=1\nX(j) exp {\u03b1 ((CX)j \u2212 Y \u00b7 CX)}\n\n = +\u221e.\nTherefore,\nlim \u03b1\u2192\u221e (RE(Y, T (X)) \u2212RE(Y,X)) = +\u221e.\nThird possibility: Assume Y is a best response to X (implying (Y \u2212X) \u00b7CX > 0). Then Lemma 6 implies that\nlim \u03b1\u2192\u221e (RE(Y, T (X)) \u2212RE(Y,X)) < 0.\nThis completes the proof.\nLemma 10. Suppose X\u030a(C,CT ) \u2229 FX(C,CT ) = \u2205, let X \u2208 X\u030a, and\nY \u2208 argmax{Y \u00b7 CX|Y \u2208 X(C,CT )}.\nThat is, Y is a best response to X. Then\n\u2200X \u2208 X\u030a(C,CT ) : Y \u2208 argmax{Y \u00b7 CX|Y \u2208 X(C,CT )}.\nProof. It is well-known that the best response correspondence is upper hemicontinuous. Finally, upper hemicontinuity of the best response correspondence implies that the set of strategies against which Y is a best response (that is, the lower inverse of Y under the best response correspondence) is closed [Corbae et al., 2009, Theorem 6.1.23]. Suppose now Y is a best response to an interior strategy and that the boundary of the set of strategies against which Y is a best response intersects the interior X\u030a(C,CT ) of the probability simplex of (C,CT ). Let X lie on the boundary of the intersection. Then there exists X \u2032 \u2208 X\u030a(C,CT ) such that\n\u2200\u01eb \u2208 (0, 1] : Y 6\u2208 argmax{Y \u00b7 CX(\u01eb)|Y \u2208 X(C,CT )}\nwhere\nX(\u01eb) = (1\u2212 \u01eb)X + \u01ebX \u2032.\nThat is, Y is best response against X but it is not a best response against any other X(\u01eb). Since, for all X \u2208 X\u030a(C,CT ), X 6\u2208 FX(C,CT ), for all X \u2208 X\u030a(C,CT ), RE(Y, T (X)) is strictly convex (by the convexity lemma). Lemma 9 implies then that\nlim \u03b1\u2192\u221e (RE(Y, T (X)) \u2212RE(Y,X)) < 0\nand\n\u2200\u01eb \u2208 (0, 1] : lim \u03b1\u2192\u221e (RE(Y, T (X(\u01eb))) \u2212RE(Y,X(\u01eb))) = +\u221e.\nSince RE(Y, T (X(\u01eb)))\u2212RE(Y,X(\u01eb)) is continuous, this is clearly impossible. Hence the lemma.\nLemma 11. Suppose X\u030a(C,CT ) \u2229 FX(C,CT ) = \u2205, let X \u2208 X\u030a, and\nY \u2208 argmax{Y \u00b7 CX|Y \u2208 X(C,CT )}.\nThat is, Y is a best response to X. Then\n\u2200X \u2208 X\u030a(C,CT ) : (Y \u2212X) \u00b7 CX > 0.\nProof. Since X 6\u2208 NE+(C,CT ), the best response condition (Proposition 2) implies that\nY \u2208 argmax{Y \u00b7 CX|Y \u2208 X(C,CT )} \u21d2 (Y \u2212X) \u00b7 CX > 0\nand, then, Lemma 10 completes and proof.\nUsing the previous lemma we obtain the following theorem, which is a statement about the incentive structure of a symmetric bimatrix game without an (interior) equalizer:\nTheorem 3. X\u030a(C,CT )\u2229FX(C,CT ) = \u2205 if and only if there exists a weakly dominated pure strategy of (C,CT ).\nProof. By Proposition 4, the pure strategy Ei is undominated if and only if it is a best response to some interior (completely mixed) strategy. Suppose, for the sake of contradiction that every pure strategy is a best response to some interior strategy. Then Lemma 11 implies\n\u2200i \u2208 K(C,CT ) \u2200X \u2208 X\u030a(C,CT ) : (Ei \u2212X) \u00b7 CX > 0. (9)\nWe consider two possibilities:\nFirst possibility: Assume first K(C,CT ) \u2265 3: Consider a pure strategy Ei, a pair of pure strategies Ej1 6= Ej2 different from Ei, and let Y = (1 \u2212 \u01eb)Ej1 + \u01ebEj2 , \u01eb \u2208 (0, 1), such that there exists a convex combination of Ei and Y in X\u030a(C,C T ). Then all such convex combinations are interior. Furthermore (9) implies\n\u2200X as convex combinations of Ei and Y : (Ei \u2212X) \u00b7 CX > 0 and (Y \u2212X) \u00b7 CX > 0,\nwhich is clearly an impossibility as (Ei \u2212X) \u00b7CX > 0 implies the angle between the payoff vector CX and Ei\u2212X is acute and (Y \u2212X)\u00b7CX > 0 similarly. But Ei\u2212X and Y \u2212X point in exactly opposite directions leading to a contradiction. Therefore, there exists a weakly dominated pure strategy.\nSecond possibility: If K(C,CT ) = 2, the argument is entirely analogous.\nThe reverse direction is straightforward from Propositions 3 and 4: If X\u030a(C,CT )\u2229FX(C,CT ) 6= \u2205, every pure strategy is a best response to the interior symmetric equilibrium strategy by Proposition 3 (on best responses). Therefore, Proposition 4 implies every pure strategy is undominated.\nBased on the previous results, we have:"}, {"heading": "6.1 Correctness proof of Algorithm 1", "text": "To prove the correctness of Algorithm 1 it suffices to prove that if E(C,CT ) = \u2205 there exists a weakly dominated pure strategy. But this is a simple implication of Theorem 3 and the straightforward observation that\nE(C,CT ) = \u2205 \u21d2 X\u030a(C,CT ) \u2229 FX(C,CT ) = \u2205.\nNote the algorithm clearly runs in polynomial time.\n6.2 P = PPAD\nThe problem of computing an equilibrium of a bimatrix game is PPAD-complete [Daskalakis et al., 2009, Chen et al., 2009]. Furthermore equilibrium computation in a bimatrix game can be reduced to the problem of equilibrium computation in a symmetric bimatrix game by the symmetrization method of [Jurg et al., 1992]. Since Algorithm 1 always terminates with a symmetric equilibrium of the symmetric game whose payoff matrix it receives as input, and since it is straightforward to verify that its running time is polynomial, that P = PPAD follows immediately."}, {"heading": "7 Concluding remarks", "text": "The computational complexity of our algorithm is good but it is certainly not \u201cperfect\u201d as it can be improved by a significant factor. Improving this algorithm and extending our results to other computational complexity classes is the main subject of our ongoing work on this topic."}, {"heading": "Acknowledgments", "text": "I would like to thank Dick Lipton for comments on a previous draft. Part of this work was performed as I was an associate professor at the JST Erato Kawarabayashi project at the National Institute of Informatics in Tokyo, Japan. I colloquially call the multiplicative weights lemmas \u201cHatori Hanzo\u201d lemmas as a tribute to the country that hosted their development."}], "references": [{"title": "The multiplicative weights update method: A meta-algorithm and its applications", "author": ["S. Arora", "E. Hazan", "S. Kale"], "venue": "Theory of Computing,", "citeRegEx": "Arora et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Arora et al\\.", "year": 2012}, {"title": "A decision-theoretic generalization of on-line learning", "author": ["Y. Freund", "R.E. Schapire"], "venue": "(SAGT", "citeRegEx": "Freund and Schapire.,? \\Q2010\\E", "shortCiteRegEx": "Freund and Schapire.", "year": 2010}, {"title": "Evolution and the Theory of Games", "author": ["J. Maynard Smith"], "venue": "The logic of animal conflict. Nature,", "citeRegEx": "Smith.,? \\Q1994\\E", "shortCiteRegEx": "Smith.", "year": 1994}, {"title": "C", "author": ["Sept."], "venue": "H. Papadimitriou. On the complexity of the parity argument and other inefficient proofs of", "citeRegEx": "Sept.,? 1951", "shortCiteRegEx": "Sept.", "year": 1951}, {"title": "Exponentially many steps for finding a Nash equilibrium in a bimatrix game", "author": ["R. Savani", "B. von Stengel"], "venue": "In Proc. 45th Annual IEEE Symposium on Foundations of Computer Science,", "citeRegEx": "Savani and Stengel.,? \\Q2004\\E", "shortCiteRegEx": "Savani and Stengel.", "year": 2004}, {"title": "Equilibrium computation for two-player games in strategic and extensive form", "author": ["B. von Stengel"], "venue": "Algorithmic Game Theory,", "citeRegEx": "Stengel.,? \\Q2007\\E", "shortCiteRegEx": "Stengel.", "year": 2007}, {"title": "On the complexity of approximating a KKT point of quadratic programming", "author": ["Y. Ye"], "venue": "Mathematical Programming,", "citeRegEx": "Ye.,? \\Q1998\\E", "shortCiteRegEx": "Ye.", "year": 1998}], "referenceMentions": [{"referenceID": 2, "context": "Symmetric equilibria are also a foundational concept in evolutionary game theory [Maynard Smith and Price, 1973, Maynard Smith, 1982] but we designate evolutionary aspects of equilibrium computation as out of scope of the present paper simply to facilitate a more concise exposition of our results. Having laid out our overarching strategy and approach, we should point out that our main techniques consist in two parts, namely, in definitions and results on the properties of the concepts they define. 1.3.2 Our main definitions An important idea in this paper is captured in the notion of an equalizer, an equilibrium notion generalizing interior equilibria. This idea emerged as follows: Chen et al. [2009] point out that a simple (inefficient) algorithm to find an equilibrium of a (general) bimatrix game is by support enumeration and the solution of a corresponding linear (feasibility) program iteratively for each support until an equilibrium is found.", "startOffset": 90, "endOffset": 710}, {"referenceID": 2, "context": "Symmetric equilibria are also a foundational concept in evolutionary game theory [Maynard Smith and Price, 1973, Maynard Smith, 1982] but we designate evolutionary aspects of equilibrium computation as out of scope of the present paper simply to facilitate a more concise exposition of our results. Having laid out our overarching strategy and approach, we should point out that our main techniques consist in two parts, namely, in definitions and results on the properties of the concepts they define. 1.3.2 Our main definitions An important idea in this paper is captured in the notion of an equalizer, an equilibrium notion generalizing interior equilibria. This idea emerged as follows: Chen et al. [2009] point out that a simple (inefficient) algorithm to find an equilibrium of a (general) bimatrix game is by support enumeration and the solution of a corresponding linear (feasibility) program iteratively for each support until an equilibrium is found. Of course the number of possible supports is exponential and, therefore, this algorithm is inefficient in all games but those with a small number of pure strategies. But there is an important detail in their formulation that can easily go unnoticed: Given some support, the linear program Chen et al. [2009] formulate equalizes the pure strategies in the support and restricts the pure strategies outside the support to yield payoffs that are not superior to the payoffs pure strategies in the support yield.", "startOffset": 90, "endOffset": 1269}, {"referenceID": 0, "context": "Freund and Schapire [1997] extend this algorithm to the problems of \u201conline allocation\u201d as well as that of\u201cboosting.", "startOffset": 0, "endOffset": 27}, {"referenceID": 0, "context": "\u201d Arora et al. [2012] treat the history and applications of such algorithms to learning, game theory, and optimization rather comprehensively.", "startOffset": 2, "endOffset": 22}, {"referenceID": 0, "context": "\u201d Arora et al. [2012] treat the history and applications of such algorithms to learning, game theory, and optimization rather comprehensively. Freund and Schapire [1999] prove convergence of a multiplicative weights algorithm to the value of a zero-sum game\u2014the algorithm is employed by one of the two player positions and the opponent in the other position is assumed to be arbitrary.", "startOffset": 2, "endOffset": 170}, {"referenceID": 0, "context": "\u201d Arora et al. [2012] treat the history and applications of such algorithms to learning, game theory, and optimization rather comprehensively. Freund and Schapire [1999] prove convergence of a multiplicative weights algorithm to the value of a zero-sum game\u2014the algorithm is employed by one of the two player positions and the opponent in the other position is assumed to be arbitrary. We note their result does not imply convergence to the minimax equilibrium, but it furnishes an alternative proof of von Neumann\u2019s minimax theorem. Minimax equilibria in zero-sum games (such as the equilibrium of the rock-paper-scissors game) may \u201crepel\u201d the multiplicative weights dynamic (but not always). This is easy to prove using modified versions of analytical techniques employed in this paper (but the proof is omitted for brevity). We note their proof techniques are based on the relative entropy as in this paper. Similar negative results that multiplicative weights are not convergent to Nash equilibria are obtained by [Daskalakis et al., 2010] and [Balkan et al., 2012]. We note that, as mentioned earlier, we do not use multiplicative weights to compute Nash equilibria but rather as a mathematical tool to \u201cprobe\u201d (and characterize) the incentive (payoff) structure of strategic games. 1.4.2 Equilibrium computation and approximation PPAD (Polynomial Parity Arguments on Directed graphs) is a complexity class introduced by Papadimitriou [1994] to capture the difficulty of finding Brouwer fixed points.", "startOffset": 2, "endOffset": 1447}, {"referenceID": 6, "context": "The computation of KKT points in (general) quadratic programs is known to admit an FPTAS [Ye, 1998].", "startOffset": 89, "endOffset": 99}], "year": 2016, "abstractText": "We show that, by using multiplicative weights in a game-theoretic thought experiment (and an important convexity result on the composition of multiplicative weights with the relative entropy function), a symmetric bimatrix game (that is, a bimatrix matrix wherein the payoff matrix of each player is the transpose of the payoff matrix of the other) either has an interior symmetric equilibrium or there is a pure strategy that is weakly dominated by some mixed strategy. Weakly dominated pure strategies can be detected and eliminated in polynomial time by solving a linear program. Furthermore, interior symmetric equilibria are a special case of a more general notion, namely, that of an \u201cequalizer,\u201d which can also be computed efficiently in polynomial time by solving a linear program. An elegant \u201csymmetrization method\u201d of bimatrix games [Jurg et al., 1992] and the well-known PPAD-completeness results on equilibrium computation in bimatrix games [Daskalakis et al., 2009, Chen et al., 2009] imply then the compelling P = PPAD.", "creator": "LaTeX with hyperref package"}}}