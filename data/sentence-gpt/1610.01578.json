{"id": "1610.01578", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "5-Oct-2016", "title": "A new algorithm for identity verification based on the analysis of a handwritten dynamic signature", "abstract": "Identity verification based on authenticity assessment of a handwritten signature is an important issue in biometrics. There are many effective methods for signature verification taking into account dynamics of a signing process. Methods based on partitioning take a very important place among them. In this paper we propose a new approach to signature partitioning. Its most important feature is the possibility of selecting and processing of hybrid partitions in order to increase a precision of the test signature analysis. Partitions are formed by a combination of vertical and horizontal sections of the signature. Vertical sections correspond to the initial, middle, and final time moments of the signing process. In turn, horizontal sections correspond to the signature areas associated with high and low pen velocity and high and low pen pressure on the surface of a graphics tablet. Our previous research on vertical and horizontal sections of the dynamic signature (created independently) led us to develop the algorithm presented in this paper. Selection of sections, among others, allows us to define the stability of the signing process in the partitions, promoting signature areas of greater stability (and vice versa). In the test of the proposed method two databases were used: public MCYT-100 and paid BioSecure. This will allow us to implement and test the dynamic signature, based on the results. This approach will also make it easier for the researchers to study key parameters of signature integrity and identity verification: an initial, middle and final time moment of the signing process in the partitions, and a second one after the final time in the partition. This technique will lead to a better understanding of the nature of the signature process. We aim to make it easier for the researchers to validate the validity of the dynamic signature, based on the results. It can be achieved with the following methods:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "histories": [["v1", "Wed, 5 Oct 2016 19:32:55 GMT  (591kb)", "http://arxiv.org/abs/1610.01578v1", "34 pages, 7 figures"]], "COMMENTS": "34 pages, 7 figures", "reviews": [], "SUBJECTS": "cs.CV cs.AI cs.HC", "authors": ["krzysztof cpalka", "marcin zalasinski", "leszek rutkowski"], "accepted": false, "id": "1610.01578"}, "pdf": {"name": "1610.01578.pdf", "metadata": {"source": "CRF", "title": "A new algorithm for identity verification based on the analysis of a handwritten dynamic signature", "authors": ["Krzysztof Cpa\u0142ka", "Marcin Zalasi\u0144ski", "Leszek Rutkowski"], "emails": ["krzysztof.cpalka@iisi.pcz.pl", "marcin.zalasinski@iisi.pcz.pl", "leszek.rutkowski@iisi.pcz.pl"], "sections": [{"heading": null, "text": "ar X\niv :1\n61 0.\n01 57\n8v 1\n[ cs\n.C V\n] 5\nIdentity verification based on authenticity assessment of a handwritten signature is an important issue in biometrics. There are many effective methods for signature verification taking into account dynamics of a signing process. Methods based on partitioning take a very important place among them. In this paper we propose a new approach to signature partitioning. Its most important feature is the possibility of selecting and processing of hybrid partitions in order to increase a precision of the test signature analysis. Partitions are formed by a combination of vertical and horizontal sections of the signature. Vertical sections correspond to the initial, middle, and final time moments of the signing process. In turn, horizontal sections correspond to the signature areas associated with high and low pen velocity and high and low pen pressure on the surface of a graphics tablet. Our previous research on vertical and horizontal sections of the dynamic signature (created independently) led us to develop the algorithm presented in this paper. Selection of sections, among others, allows us to define the stability of the signing process in the partitions, promoting signature areas of greater stability (and vice versa). In the test of the proposed method two databases were used: public\n\u2217Corresponding author Email addresses: krzysztof.cpalka@iisi.pcz.pl (Krzysztof Cpa\u0142ka),\nmarcin.zalasinski@iisi.pcz.pl (Marcin Zalasi\u0144ski), leszek.rutkowski@iisi.pcz.pl (Leszek Rutkowski)\n1Full postal address: Institute of Computational Intelligence, Cz\u0119stochowa University of Technology, Al. Armii Krajowej 36, 42-200 Cz\u0119stochowa, Poland; Telephone and fax number: 0-48 343250546\nPreprint submitted to Applied Soft Computing October 6, 2016\nMCYT-100 and paid BioSecure.\nKeywords: biometrics, on-line signature, dynamic signature, identity verification, computational intelligence, fuzzy system, interpretability."}, {"heading": "1. Introduction", "text": "Security of IT systems is related to, among others, effective identity verification of system users. This verification may be performed using various methods based on: (a) something you have (e.g. chip card), (b) something you know (e.g. password), (c) something you are (e.g. biometric features). The third approach is the most convenient for people whose identity is verified and the most difficult to forge for potential forgers. Therefore, it is very interesting and it creates possibilities for the development of new solutions. The biometric features used in this approach are divided into two categories: (a) physiological - related to the construction of the human body (e.g. fingerprint, iris, hand geometry, face) and (b) behavioural - related to the human behaviour (e.g. signature, gait, keystrokes). A handwritten signature occupies a special place among behavioural characteristics, its acquisition is not controversial and it is commonly socially acceptable.\nIn the literature there are two main approaches to signature analysis. The first one uses so-called static (off-line) signature and it is based on an analysis of geometric features of the signature, such as shape and size ratios, etc. (see e.g. [1, 2, 3, 4, 5, 6]). The other approach is based on an analysis of the dynamics of signing process and it uses so-called dynamic (on-line) signature. Some authors have also presented a methods based on both these approaches (see [7, 8]). The most commonly used signals, which are the basis of the dynamic signature analysis, are pen pressure on the tablet surface and pen velocity. Velocity signal is determined indirectly on the basis of pen position signals on the tablet surface. The dynamic signature verification is much more effective than the static one because: (a) dynamics of signing is a very individual characteristic feature of the signer, (b) it is difficult to forge, (c) waveforms describing the dynamics of the signature (even if you have them) are difficult to translate into the process of signing, but they are relatively easy to analyse. It should also be emphasized that the algorithms for the analysis of the dynamic signature can be relatively easily used in other areas of application in the field of biometrics, which are based on the analysis of dynamic behaviour (see e.g. [9, 10]).\nIn the literature there are four main approaches to the dynamic signature analysis: (a) global feature-based approach (see e.g. [11, 12, 13, 14, 15]), (b) function-based approach (see e.g. [16, 17, 18, 19, 20, 21]), (c) regional approach (see e.g. [22, 23, 24, 25, 26, 27, 28, 29]) and (d) hybrid approach (see e.g. [30, 31, 32]). Among these approaches to the dynamic signature analysis, the methods based on signature regions are very interesting and effective. In the literature in this field one can find, among others, new methods of selection of the signature regions characteristic of the signer, new ways of interpretation of these signature regions and new ways of signature classification based on selected regions. Many authors use Hidden Markov Models (see e.g. [25]). Other authors propose ways of classification adapted to their methods. In [26] signatures are segmented into strokes and for each of them the reliability measure is computed on the basis of the feature values which belong to the current stroke. In [27] a stroke-based algorithm that splits velocity signal into three bands has been proposed. This approach assumes that low and high-velocity bands of the signal are unstable, whereas the medium-velocity band is useable for discrimination purposes. A more detailed review of the literature on the dynamic signature verification has been presented in our previous papers (see e.g. [22, 23]).\nOur experience with different methods for the dynamic signature verification based on the regional approach induced us to prepare the method presented in this paper. In [23] we propose a method which determines the importance of each time moment of signing process individually for each signer. The method takes into account stability of signing in the considered time moments. The stability is determined using reference signatures. In our other paper i.e. [22] we propose a method, which allows one to select some typical areas in the signature of the user, created as a result of an analysis of pen velocity and pen pressure signals. These areas are associated with high and low pressure and high and low velocity. The proposed methods work with high accuracy and they also have several other important advantages (determination of weights of areas, taking into account all the regions and their weights in the signature verification, signature classification based on the fuzzy classifier), so we have decided to develop a new method that would be a combination of those two methods. Initial attempts to introduce this method are outlined in [33]. However, the algorithm presented in the mentioned paper required an iterative determination of the so-called border of inclusion of reference signatures. In this paper we managed to eliminate this procedure and thus greatly simplify evaluation of the similarity of test\nsignatures to their reference signatures. Thanks to this fact, the system to evaluate the similarity of test signatures to their reference signatures is a full one-class classifier. Moreover, interpretation of the partitions selected by the method described in [33] is different from the interpretation in the algorithm proposed in this paper and the partition analysis in the mentioned method is less precise. Different interpretation of the partitions resulted in the need to change the work of the algorithm in every step. Thus, the algorithm for signature verification proposed in this paper is a new one, which has not been presented in the literature so far.\nThe following features (see Table 1) distinguish the proposed method from the others:\n- It uses fuzzy sets and fuzzy systems theory in evaluation of the similarity of test signatures to their reference signatures. Character of such\nsimilarity is not precise and it is difficult to describe it using the classical theory of sets and two-valued logic. In the proposed method we used \"high similarity\" and \"low similarity\" fuzzy sets to describe similarity values (see [36]). Next, we formulated fuzzy rules and we used approximate inference. Thanks to this we obtained a complete fuzzy system used in the phase of the test signature verification. In the rules description the system takes into account the weights of importance of selected partitions.\n- It allows to interpret the knowledge accumulated in the system used for signature verification. These possibilities result from the fact that: (a) The construction of the fuzzy rules takes into account interpretability criteria of the clear fuzzy rules described in the literature (e.g. in [37]). (b) For all signers we used consistent structure of the fuzzy classifier, in which only the values of the rules\u2019 parameters change, but the reasoning scheme remains unchanged. (c) Input and output signals of the fuzzy classifier and the parameters of its rules have a specific interpretation, referring to the similarity of test signatures to their reference signatures. Thanks to this, the parameters (i.e. the parameters of membership functions and importance weights of the rules) can be determined analytically and the system does not require a learning process.\n- It selects partitions of the signature which have the following interpretation: high and low velocity in the initial, middle and final time moments of signing, high and low pressure in the initial, middle and final time moments of signing.\n- It determines values of weights of importance for each partition. Weights values are proportional to the stability of reference signatures in the partitions. Thanks to this, the proposed method uses all partitions in the evaluation of signature similarity (with varying intensity).\n- It bases on four types of signals: a shape signal of the trajectory x, a shape signal of the trajectory y, a pressure signal of the pen z and a velocity signal of the pen v. They are available as a standard for graphics tablets: the first three of them are acquired directly from the graphics tablet and the velocity is the first derivative of a signature trajectory. Various types of tablets may have different sampling frequency, so in\nthis case acquired signals are subject to the standard normalization procedure. In addition, the signatures should be pre-processed using other standard methods to match their length, rotation, scale and offset.\n- It allows to flexibly adjust a set of signals describing the dynamics of the signature to specific areas of application and hardware capabilities. There are two most common variants of the method. The first assumes that a graphics tablet is used in the training phase and in the verification phase. In this case the precision of the proposed method is the highest, because the signals describing not only the shape of the signature, but also its dynamics, are used in both phases. The second variant assumes that in the training phase the graphics tablet is available and in the verification phase we have a stand-alone (not connected to the computer) device with a touch screen (e.g. a smartphone, a tablet, etc.), from which it is impossible to obtain information about the pen pressure. In this case, the partitions are determined in the training phase on the basis of velocity and pressure. Verification phase takes into account only the shape of the signature. In the description of the method we took into account the second variant, assuming that in the signature verification phase the signals describing the dynamics of the signature may not be available. Obviously, in practice there may be also indirect modes of action (e.g. based on the generation of velocity trajectories in the training phase without knowing the pressure trajectory or using the angle of the pen to the tablet surface during the signing process), but the proposed method can be adapted to each of them.\nIn summary, the proposed new algorithm for identity verification based on the analysis of a handwritten dynamic signature is mainly characterized by new definition of the dynamic signature features (so-called hybrid partitions of the dynamic signature), new way of their processing and use of authorial one-class neuro-fuzzy classifier, whose structure is determined individually for each user without using forged signatures. Due to the above-mentioned mechanisms, the proposed algorithm works very precisely and individually for each user.\nTo test the proposed method we used two databases of the signatures: public MCYT-100 (see [38]) distributed by the Biometric Recognition Group - ATVS (see [39]) and paid BioSecure (BMDB) distributed by the BioSecure Association (see [40]).\nThis paper is organized into 4 sections. Section 2 contains a detailed description of the algorithm. The simulation results are presented in Section 3. The conclusions are drawn in Section 4."}, {"heading": "2. Detailed description of the algorithm", "text": "The proposed algorithm for the dynamic signature verification based on hybrid partitioning works in two phases (see Fig. 1): the training phase (Section 2.1) and the test phase (Section 2.2). In both of them a procedure of signature normalization is performed (see Fig. 2). In this procedure for each user the most typical reference signature, called base signature, is selected. It is one of the reference signatures collected in the acquisition phase, for which the distance to the other reference signatures is the smallest. The distance is calculated according to the adopted distance measure (e.g. Euclidean). Training or test signatures are matched to the base signature using the Dynamic Time Warping algorithm (see e.g. [41, 42, 43]), which operates on the basis of matching velocity and pressure signals. The result of matching the two signatures is a map of their corresponding points. On the basis of the map, trajectories of the signatures are matched. Matching by way of using DTW could not be done directly with the use of trajectories, because this would remove the differences between the shapes of the signatures. It would have a very negative impact on training. Elimination of differences in rotation of the signatures is performed by the PCA algorithm which in the literature is commonly used to make image rotation invariant (see e.g. [44]). The scale and offset are compensated by standard geometric transformations. Various normalization techniques are described in detail in the literature, so their description will not be included in this paper (see e.g. [17, 34, 45, 46])."}, {"heading": "2.1. Training phase", "text": "At the beginning of the training phase partitioning of the reference signatures of each user is realized (Section 2.1.1). Partitions are hybrid because they are created from a combination of vertical and horizontal sections. Vertical sections are time intervals indicating the initial, middle and final phase of signing. Horizontal sections are created in each vertical section. In this process signals describing the dynamics of a signature are taken into account. If the velocity signal is partitioned as first (order of signal processing is arbitrary), then in each time interval the average value of the velocity is determined (averaging discrete values of the velocity). Next, in each time\ninterval two partitions are created: (a) the one associated with the velocity lower than the average and (b) the other one associated with the velocity higher than the average. The procedure is analogous for the second available signal - pen pressure. As a result, the following partitions are created: high and low velocity at the initial, middle and final moment of signing, high and low pen pressure on the graphics tablet surface at the initial, middle and final moment of signing. The number of time moments which affects the number of partitions is a parameter of the algorithm, which may be greater than or equal to 1. Each partition is physically a subset of points of the trajectory x or y, which describes the shape of a signature. After creation of the partitions, determination of the templates of the reference signatures is performed. Each template is associated with a separate partition (Section 2.1.2). With the reference signature templates, the values of partition importance weights can be determined (Section 2.1.3). For example, the weight of importance of the first partition depends on the similarity of the points of the reference signatures from the first partition to the corresponding components of the first template. This similarity is dependent on the value of the Euclidean distance. Higher value of the partition importance weight means that a specified part of the reference signatures associated with this partition was created in a more stable way (with similar value of the velocity or the pressure). Moreover, a greater value of the weight means that in the test phase fragments of the test signatures associated with this partition will be more important in evaluation of the similarity of the test signature to the reference signatures. After creation of the partitions of the reference base signature, creation of the reference signatures templates and calculation of the weights of importance, parameters of the flexible fuzzy one-class classifier are determined in the learning phase (Section 2.1.3). The classifier is used in the test phase to evaluate the similarity of the test signature to the reference signatures. Obviously, partitions of the base signature, the templates of the reference signatures, the weights of importance and the parameters of the classifier are determined individually for each user and they must be stored in a database."}, {"heading": "2.1.1. Creation of the partitions", "text": "Each reference signature j (j = 1, 2, . . . , J , where J is the number of reference signatures) of the user i (i = 1, 2, . . . , I, where I is the number of users) is represented by the following signals:\n- Signals describing the shape of a signature. Signal xi,j = [xi,j,k=1, xi,j,k=2, . . . , xi,j,k=Ki] describes the movement of the pen in the twodimensional space along the x axis, where Ki is the number of signal samples. The number of samples Ki results from the sampling frequency of the graphics tablet and performance of the DTW algorithm in the normalization phase. Thanks to the signature normalization, all trajectories describing the signatures of the user i have the same number of samples Ki. Movement of the pen along the y axis can be described in a similar way: yi,j = [yi,j,k=1, yi,j,k=2, . . . , yi,j,k=Ki]. In order to simplify the description of the algorithm we used the same symbol ai,j = [ai,j,k=1, ai,j,k=2, . . . , ai,j,k=Ki] to describe both shape trajectories, where a \u2208 {x, y}.\n- Signals describing the dynamics of a signature. Signal vi,j = [vi,j,k=1, vi,j,k=2, . . . , vi,j,k=Ki] describes velocity of the pen and trajectory zi,j = [zi,j,k=1, zi,j,k=2, . . . , zi,j,k=Ki] describes the pen pressure on the surface of the graphics tablet. In order to simplify the description of the algorithm we used the same symbol si,j = [si,j,k=1, si,j,k=2, . . . , si,j,k=Ki] to describe both dynamics signals, where s \u2208 {v, z}.\nThe purpose of the partitioning is to assign each point of the signal vi,jBase and the signal zi,jBase of the reference base signature to a single hybrid partition, resulting from a combination of the vertical and the horizontal section, where jBase \u2208 {1, . . . , J} is an index of the base signature. As already mentioned, the base signature is taken into account during partitioning as the most typical reference signature of the user i. Therefore, it is selected from a set of reference signatures and it is not generated by averaging or grouping signals describing reference signatures.\nThe idea of partitioning is shown in Fig. 3. At the beginning of the partitioning, the vertical sections of the signals vi,jBase and zi,jBase are created. Each of them represents a different time moment of signing: (a) initial or final for the case P {s} = 2, (b) initial, middle or final for the case P {s} = 3, (c) initial, first middle, second middle or final for the case P {s} = 4. The vertical sections are indicated by the elements of the vector pv {s} i = [\npv {s} i,k=1, pv {s} i,k=2, . . . , pv {s} i,k=Ki\n]\ndetermined as follows:\npv {s} i,k =\n\n  \n  \n1 for 0 < k \u2264 Ki P {s} 2 for Ki P {s} < k \u2264 2Ki P {s}\n...\nP {s} for (P {s}\u22121)Ki P {s} < k \u2264 Ki\n, (1)\nwhere s \u2208 {v, z} is the signal type used for determination of the partition (velocity v or pressure z), i is the user index (i = 1, 2, . . . , I), j is the reference signature index (j = 1, 2, . . . , J), Ki is the number of samples of normalized signals of the user i (divisible by P {s}), k is an index of the signal sample (k = 1, 2, . . . , Ki) and P\n{s} is the number of the vertical sections (P {s} \u226a Ki and P {s} = P {v} = P {z}). A number of the vertical sections can be arbitrary, but its increase does not increase interpretability and accuracy of the method (see Section 3).\nAfter creation of the vertical sections of the signals vi,jBase and zi,jBase, horizontal sections are created. Each of them represents high and low velocity and high and low pressure in individual moments of signing. Horizontal sections indicated by the elements of the vector ph {s} i = [ ph {s} i,k=1, ph {s} i,k=2, . . . , ph {s} i,k=Ki ] are determined as follows:\nph {s} i,k =\n\n\n\n1 for si,j=jBase,k < avgv {s}\ni,p=pv {s} i,k\n2 for si,j=jBase,k \u2265 avgv {s}\ni,p=pv {s} i,k\n, (2)\nwhere jBase is the base signature index, avgv {s} i,p is an average velocity (when s = v) or an average pressure (when s = z) in the section indicated by the index p of the base signature jBase:\navgv {s} i,p =\n1\nKvi,p\nk= ( p\u00b7Ki\nP{s}\n)\n\u2211\nk= ( (p\u22121)\u00b7Ki\nP{s} +1\n)\nsi,j=jBase,k, (3)\nwhere Kvi,p is the number of samples in the vertical section p, si,j=jBase,k is the sample k of the signal s \u2208 {v, z} describing dynamics of the signature.\nAs a result of partitioning, each sample vi,jBase,k of the signal vi,jBase of the base signature jBase and each sample zi,jBase,k of the signal zi,jBase of the base signature jBase is assigned to the vertical section (assignment information is stored in the vector pv {s} i ) and horizontal section (assignment\ninformation is stored in the vector ph {s} i ). The intersection of the sections forms the partition. Fragments of the shape trajectories xi,j and yi,j , created by taking into account pv {s} i and ph {s} i , will be denoted as a {s} i,j,p,r = [\na {s} i,j,p,r,k=1, a {s} i,j,p,r,k=2, . . . , a {s}\ni,j,p,r,k=Kc {s,a} i,p,r\n]\n. The number of samples belonging\nto the partition (p, r) (created as an intersection of the vertical section p and the horizontal section r, included in the trajectory a {s} i,j,p,r) of the user i associated with the signal a (x or y) and created on the basis of the signal s (velocity or pressure) will be denoted as Kc {s,a} i,p,r . It should be noticed that P {s} \u2211\np=1\nR{s} \u2211\nr=1\nKc {s,a} i,p,r = Ki for a \u2208 {x, y} and s \u2208 {v, z}. The number of partitions\nof the base signature of the user i is equal to P {v} \u00b7 P {z} \u00b7 4. The partitions are used to determine the reference signature templates."}, {"heading": "2.1.2. Generation of the templates", "text": "The following parameters are considered when determining reference signature templates: (a) all J reference signatures of the user i, (b) two shape trajectories of the reference signatures, i.e. xi,j and yi,j and (c) partitions created for the reference base signature, resulting from the intersection of the vertical sections (indicated by pv\n{s} i ) and horizontal sections (indicated\nby ph {s} i ) (Fig. 4). The templates of the signatures are averaged fragments of the reference signatures represented by the shape trajectories xi,j or yi,j . The number of the templates created for the user i is equal to the number\nof the partitions. Each template tc {s,a} i,p,r =\n[\ntc {s,a} i,p,r,k=1, tc {s,a} i,p,r,k=2, ..., tc {s,a}\ni,p,r,k=Kc {s,a} i,p,r\n]\ndescribes fragments of the reference signatures in the partition (p, r) of the user i, associated with the signal a (x or y), created on the basis of the signal s (velocity or pressure), where:\ntc {s,a} i,p,r,k =\n1\nJ\nJ \u2211\nj=1\na {s} i,j,p,r,k. (4)\nAfter determination of the templates tc {s,a} i,p,r , parameters of the fuzzy system for evaluating the similarity of the test signatures to the reference signatures are determined."}, {"heading": "2.1.3. Determination of the parameters of the fuzzy system to evaluate the similarity of the test signatures to the reference signatures", "text": "The test signature verification is based on the answers of the fuzzy system for evaluating the similarity of the test signatures to the reference signatures. Parameters of the system must be selected individually for each user from the database. Moreover, the algorithm for signature verification should: (a) work independently of the number of users (its accuracy should not depend on the number of users in the database), (b) have the ability to easily add the signatures of new users, (c) not take into account signatures of other users in the training and verification phase of the signature. This limits the use of known methods e.g. from the field of non-linear classification and machine learning (evolutionary or gradient). In this paper we propose a new structure of the flexible neuro-fuzzy one-class classifier, whose parameters depend on the reference signature descriptors. They are determined analytically (not in the process of supervised learning) and individually for the user (his/her reference signatures).\nThe first group of parameters of the proposed system are the parameters describing differences between the reference signatures and the templates in the partitions. They are used in the construction of fuzzy rules described later (see (9)) and determined as follows:\ndmax {s,a} i,p,r =\n\u03b4i\nJ \u00b7Kc {s,a} i,p,r\nKc {s,a} i,p,r \u2211\nk=1\nJ \u2211\nj=1\n\u2223 \u2223 \u2223 a {s} i,j,p,r,k \u2212 tc {s,a} i,p,r,k \u2223 \u2223 \u2223 , (5)\n\u03b4i is a parameter which ensures matching of tolerance of the system for evaluating similarity in the test phase (it is assumed that the test signatures can be created in less comfortable conditions than the reference signatures, thus \u03b4i \u2265 1). Thus, values of the parameters describing differences between the reference signatures and the templates in the partitions of the user i take into account the average similarity of the reference signature shape to the templates in the partitions.\nThe second group of parameters of the proposed system are weights of the partitions. They are used for evaluation of the similarity of the test signatures to the templates of the reference signatures of the user i. A high value of the weight means a small dispersion of the shape signal values from the template tc\n{s,a} i,p,r for the reference signatures of the user i. A consequence\nof the high value of the partition weight is lower tolerance of the system for\nsimilarity evaluation in the test phase. Determination of the weights w\n{s,a} i,p,r starts from determination of a dis-\npersion of the reference signatures signals. The dispersion is represented by a standard deviation. Average standard deviation for all samples in the partition is determined as follows:\n\u03c3\u0304 {s,a} i,p,r =\n1\nKc {s,a} i,p,r\nKc {s,a} i,p,r \u2211\nk=1\n\u221a \u221a \u221a \u221a 1\nJ\nJ \u2211\nj=1\n(\na {s} i,j,p,r,k \u2212 tc {s,a} i,p,r,k\n)2\n. (6)\nWith the average standard deviation \u03c3\u0304 {s,a} i,p,r , normalized values of the par-\ntition weights are determined:\nw {s,a} i,p,r = 1\u2212\n\u03c3\u0304 {s,a} i,p,r\nmax p=1,2,...,P {s}\nr=1,2\n{\n\u03c3\u0304 {s,a} i,p,r\n} . (7)\nNormalization of the weights adapts them for use in the one-class flexible fuzzy system used for evaluation of the similarity of the test signatures to the reference signatures. This evaluation is the basis for recognition of signature authenticity."}, {"heading": "2.2. Test phase (verification of signatures)", "text": "At the beginning of the test phase (Fig. 1) the user: (a) creates one signature, which will be verified and (b) claims to be a specific user from the database. Then parameters of the considered user, stored earlier in the database, are downloaded and the signature verification is performed. The list of the parameters is as follows: (a) trajectories of the base signature xi,jBase, yi,jBase, vi,jBase and zi,jBase, (b) vectors of allocation to the sections pv {s} i and ph {s} i , (c) templates of the reference signatures tc {s,a} i,p,r , (d) weights of the partitions w {s,a} i,p,r (p = 1, 2, . . . , P\n{s}, r = 1, 2) and (e) the parameters describing differences between the reference signatures and the templates in the partitions dmax\n{s,a} i,p,r .\nThe first step of the verification phase is acquisition of the test signature. This signature is pre-matched to the reference base signature, represented by the trajectories xi,jBase, yi,jBase and the signals vi,jBase, zi,jBase. This is done analogously as in the case of the reference signatures in the training phase (Fig. 2). Normalized test signature is represented by two shape trajectories:\nxtsti = [xtsti,k=1, xtsti,k=2, . . . , xtsti,k=Ki] and ytsti = [ytsti,k=1, ytsti,k=2, . . . , ytsti,k=Ki]. Their structure is analogous to the shape trajectories xi,j and yi,j of the reference signatures used in the training phase, but they do not have the index j pointing to the signature.\nThe second step of the verification phase is partitioning of the test signature. As a result of partitioning of the shape trajectories xtsti and ytsti their fragments denoted as atst {s} i,p,r = [ a {s} i,p,r,k=1, a {s} i,p,r,k=2, . . . , a {s}\ni,p,r,k=Kc {s,a} i,p,r\n]\nare obtained. During the partitioning the vectors pv {s} i and ph {s} i are used. They are determined in the training phase and their signals indicate sections, in which signals of the vectors xtsti and ytsti should be placed. It was carried out in a similar way in the training phase.\nThe third step of the verification phase (realized after partitioning) is determination of the similarity of fragments of the test signature shape trajectories atst\n{s} i,p,r to the templates of the reference signatures tc {s,a} i,p,r in the par-\ntition (p, r) of the user i associated with the signal a (x or y) created on the basis of the signal s (velocity or pressure). It is determined as follows:\ndtst {s,a} i,p,r =\n1\nKc {s,a} i,p,r\nKc {s,a} i,p,r \u2211\nk=1\n\u2223 \u2223 \u2223atst {s} i,p,r,k \u2212 tc {s,a} i,p,r,k \u2223 \u2223 \u2223. (8)\nAfter determination of the similarities dtst {s,a} i,p,r , total similarity of the test signature to the reference signatures of the user i is determined. A decision on the authenticity of the test signature is taken on the basis of this similarity. The structure of the system for evaluation of the overall similarity is described in Section 2.2.1, evaluation of the signature reliability is described in Section 2.2.2 and interpretability aspects of the system rules are presented in Section 2.2.3."}, {"heading": "2.2.1. Evaluation of the overall similarity of the test signature to the reference signatures", "text": "The system evaluating similarity of the test signature to the reference signatures works on the basis of the signals dtst\n{s,a} i,p,r and takes into account\nthe weights w {s,a} i,p,r . Its response is the basis for the evaluation of the signature reliability. The proposed system works on the basis of two fuzzy rules presented as follows:\n          \n         \nR(1) :\n\n  \nIF (\ndtst {v,x} i,1,1 isA 1{v,x} i,1,1\n)\nwithw {v,x} i,1,1 AND . . .\n. . .AND ( dtst {z,y}\ni,P {z},2 isA\n1{z,y} i,P {z},2\n)\nwithw {z,y}\ni,P {z},2\nTHENyiisB 1\n\n  \nR(2) :\n\n  \nIF (\ndtst {v,x} i,1,1 isA 2{v,x} i,1,1\n)\nwithw {v,x} i,1,1 AND . . .\n. . .AND ( dtst {z,y}\ni,P {z},2 isA\n2{z,y} i,P {z},2\n)\nwithw {z,y}\ni,P {z},2\nTHENyiisB 2\n\n  \n, (9)\nwhere\n- dtst {s,a} i,p,r (i = 1, 2, . . . , I, p = 1, 2, . . . , P {s}, r = 1, 2, s \u2208 {v, z}, a \u2208 {x, y}) are input linguistic variables describing similarity of the shape\ntrajectories\u2019 fragments atst {s} i,p,r of the test signature to the templates of the reference signatures tc {s,a} i,p,r . \"High\" and \"low\" values taken by these variables are Gaussian fuzzy sets A 1{v,x} i,p,r , A 2{v,x} i,p,r (see Fig. 5) described by the following membership functions:\n\u00b5A (x) = exp\n(\n\u22121\n(\nx\u2212 a\n\u03c3\n)2 )\n, (10)\nwhere a is the centre of the Gaussian function and \u03c3 is its width (see e.g. [47]). In the used system the value of the parameter a for the rule R(1) from the rule base (9) is equal to 0 and for the rule R(2) is equal to the value of the border of inclusion of the reference signatures dmax {s,a} i,p,r calculated by the formula (5). The value of the parameter \u03c3 for both rules from the rule base (9) is determined as follows:\n\u03c3 = dmax\n{s,a} i,p,r\n\u221a |log (\u00b5min)| , (11)\nwhere \u00b5min > 0 is a small positive number resulting from the intersection of the Gaussian function (10) with a straight line, described by the equation \u00b5 (x) = \u00b5min, at the point ( dmax {s,a} i,p,r , \u00b5min ) . This approach results from the specificity of the Gaussian function, which\ntends asymptotically to the value 0 (this is the case, in which \u00b5min = 0) but never reaches it. Moreover, it is worth noting that the specific approach to the fuzzification block of the system, and in particular the use of the singleton type fuzzification (see e.g. [47]), allowed us to simplify the rules notation (9). The simplification involves replacing the names of linguistic variables by the names of the signals determined using the formula (8).\n- yi (i = 1, . . . , I) is output linguistic variable meaning \"similarity of the test signature to the reference signatures of the user i\". \"High\" value of this variable is the fuzzy set B1 of \u03b3 type (see Fig. 5), described by the following membership function (see e.g. [47]):\n\u00b5B1 (x) =\n\n\n\n0 for x \u2264 a x\u2212a b\u2212a for a < x \u2264 b\n1 for x > b . (12)\n\"Low\" value is the fuzzy set B2 of L type (see Fig. 5) described by the following membership function (see e.g. [47]):\n\u00b5B2 (x) =\n\n\n\n1 for x \u2264 a b\u2212x b\u2212a for a < x \u2264 b\n0 for x > b . (13)\nIn our system value of the parameter a for both rules from the rule base (9) is equal to 0 and value of the parameter b is equal to 1.\n- w {s,a} i,p,r are weights of the partition associated with the template tc {s,a} i,p,r\nof the user i, calculated by the formula (7). Introduction of the weights of importance distinguishes the proposed flexible neuro-fuzzy system from typical fuzzy systems."}, {"heading": "2.2.2. Verification of the test signature", "text": "In the proposed method the test signature is recognized as belonging to the user i (genuine) if the assumption y\u0304i > cthi is satisfied, where y\u0304i is the value of the output signal of neuro-fuzzy system described by the (9):\ny\u0304i \u2248\nT \u2217\n\n\n\n\u00b5 A\n1{v,x} i,1,1\n(\ndtst {v,x} i,1,1\n)\n, . . . , \u00b5 A 1{z,y}\ni,P{z},2\n(\ndtst {z,y}\ni,P {z},2\n)\n;\nw {v,x} i,1,1 , . . . , w {z,y}\ni,P {z},2\n\n\n\n\n      \nT \u2217\n\n\n\n\u00b5 A\n1{v,x} i,1,1\n(\ndtst {v,x} i,1,1\n)\n, . . . , \u00b5 A 1{z,y}\ni,P{z},2\n(\ndtst {z,y}\ni,P {z},2\n)\n;\nw {v,x} i,1,1 , . . . , w {z,y}\ni,P {z},2\n\n\n\n+\n+T \u2217\n\n\n\n\u00b5 A\n2{v,x} i,1,1\n(\ndtst {v,x} i,1,1\n)\n, . . . , \u00b5 A 2{z,y}\ni,P{z},2\n(\ndtst {z,y}\ni,P {z},2\n)\n;\nw {v,x} i,1,1 , . . . , w {z,y}\ni,P {z},2\n\n\n\n\n      \n,\n(14) where\n- T \u2217 {\u00b7} is the weighted t-norm (see [47]) in the form:\nT \u2217 {\na1, a2; w1, w2\n}\n= T\n{\n1\u2212 w1 \u00b7 (1\u2212 a1) , 1\u2212 w2 \u00b7 (1\u2212 a2)\n}\ne.g. = (1\u2212 w1 \u00b7 (1\u2212 a1)) \u00b7 (1\u2212 w2 \u00b7 (1\u2212 a2))\n, (15)\nwhere t-norm T {\u00b7} is a generalization of the usual two-valued logical conjunction (studied in classical logic), w1 and w2 \u2208 [0, 1] mean weights of importance of the arguments a1, a2 \u2208 [0, 1]. Please note that T \u2217 {a1, a2; 1, 1} = T {a1, a2} and T \u2217 {a1, a2; 1, 0} = a1.\n- cthi \u2208 [0, 1] - coefficient determined experimentally for each user to eliminate disproportion between FAR and FRR error (see e.g. [48]). The values of this coefficient are usually close to 0.5.\nThe formula (14) was established by taking into account the following simplification resulting from the spacing of the fuzzy sets shown in Fig. 5:\n{\n\u00b5B1 (0) = 0, \u00b5B1 (1) = 1 \u00b5B2 (0) = 1, \u00b5B2 (1) = 0 . (16)\nDetailed information about the system described by the rules (9), which allow us to easily derive the relationship (14) on the basis of the assumption (16), can be found e.g. in [49, 50, 51, 52, 53, 54]. It is worth noting that description of the considered neuro-fuzzy system given in this paper is sufficient for its implementation. In our previous papers we have dealt in detail with\nits derivation (it is known in the literature as flexible neuro-fuzzy system of the Mamdani type), gradient and evolutionary learning and applications. The novelty of the algorithm proposed in this paper is a new way of using the system for (a) assessment of the overall similarity of the test signature to the reference signatures and (b) verification of the test signatures. This method does not require a learning step. It allows for a specific interpretation of each parameter of the system and it takes into account the specificity of a considered problem of the dynamic signature verification."}, {"heading": "2.2.3. Aspects of interpretability", "text": "In the literature one can find the conditions for the readability of the fuzzy systems rules. For example, in [37] 4 levels of interpretability are shown: Q1: complexity at the rule base level (it takes into account number of rules and number of conditions), Q2: complexity at the level of fuzzy partitions (it takes into account number of membership functions, number of features or variables), Q3: semantics at the rule base level (it takes into account rules fired at the same time), Q4: semantics at the fuzzy partition level (it takes into account completeness or coverage, normalization, distinguishes ability and complementarity). It should be emphasized that the rules of the form (9) meet all the defined levels.\nMoreover, it is worth noting that in the proposed method: (a) all parameters of the rules are determined analytically and they have a specific interpretation, (b) all rules have the same form for all users, but they differ in the values of the parameters.\nAspects of interpretability used in the method are based on our previous experience with interpretability of rule-based systems (see e.g. [51, 55])."}, {"heading": "3. Simulation results", "text": "Simulations were performed using authorial test environment written in C# for two dynamic signature databases:\n- MCYT-100 database. MCYT-100 database contains signatures of 100 users, acquired using a digitizing tablet. The set of each user contains 25 genuine signatures from one signature contributor and 25 skilled forgeries from five other contributors.\n- BioSecure database. Simulations were performed using commercial DS2 Signature database which contains signatures of 210 users.\n{ { { assessment of the similarity of the test signature to the template related to the signal x and the partition ( =1, =1)p r determined on the basis of the signal v assessment of the similarity of the test signature to the template related to the signal y and the partition ( = , =2)p r determined on the basis of the signal z assessment of the similarity of the test signature to reference signatures represented by templates { }z P\nThe signatures were acquired in two sessions using a digitizing tablet. Each session contains 15 genuine signatures and 10 skilled forgeries per person.\nIn Section 3.1 the course of the simulation is described in detail. In Section 3.2 tables and figures with the results of the simulation are published. In Section 3.3 computational complexity of the proposed algorithm is described. In Section 3.4 conclusions from the simulations are presented."}, {"heading": "3.1. The course of the simulation", "text": "For each user from the MCYT-100 and BioSecure databases we repeated 5 times the training phase and the test phase, according to the block diagram shown in Fig. 1. The results obtained for all users have been averaged. In each of the five performed repetitions we used a different set of training signatures. The described method is commonly used in evaluating the effectiveness of the methods for the dynamic signature verification, which corresponds to the standard crossvalidation procedure. The method of selection of the reference and test signatures for each user was as follows:\n- During the training phase we used 5 randomly selected genuine signatures of each signer. These signatures were used to perform the partitioning, determination of the templates and calculation of the parameters of the system for evaluating the test signatures similarity to the reference signatures.\n- During the test phase we used 15 genuine signatures and 15 forged signatures for the MCYT-100 database. For the BioSecure database we used 10 remaining genuine signatures and all 10 forged signatures."}, {"heading": "3.2. Results of the simulations", "text": "The results of the simulations are presented as follows:\n- Values of the errors FAR (False Acceptance Rate) and FRR (False Rejection Rate) for the database MCYT-100 are presented in Table 2 and for the BioSecure database are presented in Table 4. These errors are used in the literature to evaluate the effectiveness of biometric methods. They have been designated for a different number of partitions. Other (less popular) effectiveness measures of biometric methods may also be used (e.g. the ones described in [56]), but in this case it would be difficult to compare the obtained results with the results of other authors.\n- Comparison of the accuracy of different methods for the signature verification for the MCYT-100 database is presented in Table 3 and for the BioSecure database is presented in Table 5. It is also noteworthy that Table 1 presents main characteristics of the algorithms for the online signature verification based on the regional approach.\n- Weights of importance of the partitions for the MCYT-100 database are presented in Fig. 6 and weights of importance of the partitions for the BioSecure database are presented in Fig. 7. Each weight value is the average value of the weights of all users, determined as follows:\nw\u0304{s,a}p,r = I \u2211\ni=1\nw {s,a} i,p,r . (17)"}, {"heading": "3.3. Computational complexity", "text": "The proposed algorithm does not require high computational complexity (Table 6), because it does not require machine learning and does not use any iterative procedures. The methods proposed in our previous papers (see e.g. [22, 23]) also do not require high computational complexity but they contain an iterative procedure for the purpose of selecting the so-called border of inclusion of the reference signatures. Elimination of this procedure from the proposed algorithm required a change in the approach to the evaluation of the test signature similarity to the reference signatures.\nLow complexity of our algorithm is very important in the verification of the test signature genuineness. It enables the system to immediately take into account the signatures of new users.\nIt has been achieved by eliminating the machine learning, which usually requires anti-patterns (in the signature verification they are descriptors of false signatures, represented by e.g. genuine signatures of other users). Moreover, in this case a greater number of users in the database causes a greater variety of signatures, which provides better learning results. This is a consequence of a more representative learning sequence. In the proposed algorithm the number of users in a database is not relevant."}, {"heading": "3.4. Conclusions from the simulations", "text": "The proposed algorithm can be evaluated as follows:\n- For both considered databases it received the highest accuracy in the case of division of the signature into two partitions associated with time moments of signing (initial and final) (see Table 2 and Table 4). By analysing the results presented in Table 2 and Table 4 it can also be seen that the accuracy of the proposed algorithm does not result from increasing the number of sections.\n- It allowed to select the partitions of the signature in which the reference signatures have been created in the most stable way. These partitions had the highest weight value and the lowest value of the parameters describing differences between the reference signatures and the templates in the partitions. It is associated with the lowest tolerance in evaluation of similarity of the test signatures to the reference signatures. For the MCYT-100 database it was the partition associated with the shape trajectory x, the initial time moment of signing and the high value of velocity (see Fig. 6). In turn, for the BioSecure database it was the partition associated with the shape trajectory x, the initial time moment of signing and the low velocity value (see Fig. 7). Different results for the two test databases confirm the validity of the proposed algorithm, which adapts its operation to the specificity of the reference signatures, individually for each user.\n- For the MCYT-100 database our algorithm promoted partitions associated with the shape trajectory x, because they had higher weight values (see Fig. 6). This shows that for the MCYT-100 database the horizontal movement of the pen was more characteristic during the creation of the reference signatures. In the case of the BioSecure database the algorithm promoted partitions associated with the shape trajectory x for the signal v and the partitions associated with both shape trajectories (x and y) for the signal z (see Fig. 7). This shows that for the BioSecure database the most characteristic for the users are combinations of (a) the horizontal movement of the pen and the velocity signal value and (b) the vertical movement of the pen and both signals value.\n- For both considered databases it promoted partitions associated with the velocity signal, because they had higher weights values (see Fig. 6 and Fig. 7). It shows that the most characteristic signal describing dynamics of the reference signatures was the velocity signal.\n- For both considered databases the algorithm worked with good accuracy in comparison to other methods for the dynamic signature verification (see Table3 and Table 5). Taking into account the additional benefits of the algorithm presented in Table 1, it can be said that it is an interesting method for the dynamic signature verification."}, {"heading": "4. Conclusions", "text": "In this paper we proposed the new algorithm for the dynamic signature verification using partitioning. The algorithm uses signals available as a standard in graphics tablets. It can be also easily adapted to the specific capabilities of used hardware, e.g. standard device with a touch screen, which is not a graphics tablet. Created partitions are associated with the areas of the signature characterized by: high and low pen velocity and high and low pen pressure on the graphics tablet surface at initial, middle and final moment of signing process. The algorithm assigns to the partitions weights of importance, which are used in the evaluation of the similarity of test signatures to reference signatures. The evaluation is realized using the new flexible fuzzy system for the evaluation of signature similarity. It uses clear fuzzy rules which allow us to interpret operation of the system. Parameters of the system are determined analytically. It is realized individually for each user and it does not require signatures of other users and so-called skilled forgeries. Our algorithm has been tested for two signature databases: MCYT-100 and BioSecure. A good accuracy of the signature verification has been achieved for both databases used; however, it worked significantly better for the BioSecure database. Achieved accuracy combined with the additional advantages of the proposed algorithm makes it an interesting solution for identity verification based on the analysis of a handwritten dynamic signature.\nThe weakness of the proposed algorithm is its sensitivity to changes of a handwritten signature occurring over a very long period of time (over a number of years). This is a characteristic of most biometric methods based on the behavioural attributes. We are planning to develop a method which will update the templates during the test phase to determine the trend of signature changes. Moreover, we are also planning to simplify the mechanism of the similarity evaluation by using only the most characteristic partition for each user. For this purpose we should, among others, investigate a dependence between the accuracy of the method and the number of used partitions. We should also develop an effective mechanism for the selection of the partitions."}, {"heading": "Acknowledgment", "text": "The project was financed by the National Science Centre (Poland) on the basis of the decision no. DEC-2012/05/B/ST7/02138."}], "references": [{"title": "Dynamic selection of generative discriminative ensembles for off-line signature verification", "author": ["L. Batista", "E. Granger", "R. Sabourin"], "venue": "Pattern Recognition 45 ", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2012}, {"title": "Signature authentication based on subpattern analysis", "author": ["K.R. Radhika", "M.K. Venkatesha", "G.N. Sekhar"], "venue": "Applied Soft Computing 11 ", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2011}, {"title": "Writer-independent off-line signature verification using surroundedness feature", "author": ["R. Kumar", "J.D. Sharma", "B. Chanda"], "venue": "Pattern Recognition Letters 33 ", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2012}, {"title": "Modular Neural Networks with Fuzzy Response Integration for Signature Recognition", "author": ["M. Beltr\u00e1n", "P. Melin", "L. Trujillo"], "venue": "Bio-inspired Hybrid Intelligent Systems for Image Analysis and Pattern Recognition ", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2009}, {"title": "Development of an automatic method for classification of signatures in a recognition system based on modular neural networks", "author": ["V. Carrera", "P. Melin", "D. Bravo"], "venue": "Recent Advances on Hybrid Intelligent Systems ", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2013}, {"title": "The effective use of the one-class SVM classifier for handwritten signature verification based on writerindependent parameters", "author": ["Y. Guerbai", "Y. Chibani", "B. Hadjadji"], "venue": "Pattern Recognition 48 ", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2015}, {"title": "On-line signature recognition through the combination of real dynamic data and synthetically generated static data", "author": ["J. Galbally", "M. Diaz-Cabrera", "M.A. Ferrer", "M. Gomez-Barrero", "A. Morales", "J. Fierrez"], "venue": "Pattern Recognition 48 ", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2015}, {"title": "Online and Offline Signature Verification: A Combined Approach", "author": ["K.S. Radhika", "S. Gopika"], "venue": "Procedia Computer Science 46 ", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2015}, {"title": "Dynamic visual features for audio-visual speaker verification", "author": ["D. Dean", "S. Sridharan"], "venue": "Computer Speech and Language 24 ", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2010}, {"title": "Human Gait Recognition Based on Kernel PCA Using Projections", "author": ["M. Ekinci", "M. Ayku"], "venue": "Journal of Computer Science and Technology 22 ", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2007}, {"title": "An On-Line Signature Verification System Based on Fusion of Local and Global Information", "author": ["J. Fierrez-Aguilar", "L. Nanni", "J. Lopez-Penalba", "J. Ortega-Garcia", "D. Maltoni"], "venue": "Lecture Notes in Computer Science, Audio-and Video-based Biometric Person Authentication 3546 ", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2005}, {"title": "Ensemble of on-line signature matchers based on overcomplete feature generation", "author": ["A. Lumini", "L. Nanni"], "venue": "Expert Systems with Applications 36 ", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2009}, {"title": "An advanced multi-matcher method for on-line signature verification featuring global features and tokenised random numbers", "author": ["L. Nanni"], "venue": "Neurocomputing 69 ", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2006}, {"title": "Advanced methods for two-class problem formulation for on-line signature verification", "author": ["L. Nanni", "A. Lumini"], "venue": "Neurocomputing 69 ", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2006}, {"title": "Ensemble of Parzen window classifiers for on-line signature verification", "author": ["L. Nanni", "A. Lumini"], "venue": "Neurocomputing 68 ", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2005}, {"title": "On-line signature recognition based on VQ-DTW", "author": ["M. Fa\u00fandez-Zanuy"], "venue": "Pattern Recognition 40 ", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2007}, {"title": "On-line signature verification", "author": ["A.K. Jain", "F.D. Griess", "S.D. Connell"], "venue": "Pattern Recognition 35 ", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2002}, {"title": "Weighted dynamic time warping for time series classification", "author": ["Y.S. Jeong", "M.K. Jeong", "O.A. Omitaomu"], "venue": "Pattern Recognition 44 ", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2011}, {"title": "Identity authentication using improved online signature verification method", "author": ["A. Kholmatov", "B. Yanikoglu"], "venue": "Pattern Recognition Letters 26 ", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2005}, {"title": "Biometric cryptosystem using function based on-line signature recognition", "author": ["E. Maiorana"], "venue": "Expert Systems with Applications 37 ", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2010}, {"title": "A novel local on-line signature verification system", "author": ["L. Nanni", "A. Lumini"], "venue": "Pattern Recognition Letters 29 ", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2008}, {"title": "On-line signature verification using vertical signature partitioning", "author": ["K. Cpa\u0142ka", "M. Zalasi\u0144ski"], "venue": "Expert Systems with Applications 41 ", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2014}, {"title": "New method for the on-line signature verification based on horizontal partitioning", "author": ["K. Cpa\u0142ka", "M. Zalasi\u0144ski", "L. Rutkowski"], "venue": "Pattern Recognition 47 ", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2014}, {"title": "Efficient on-line signature recognition based on multi-section vector quantization", "author": ["M. Fa\u00fandez-Zanuy", "J.M. Pascual-Gaspar"], "venue": "Formal Pattern Analysis & Applications 14 ", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2011}, {"title": "HMM\u2013 based on-line signature verification: Feature extraction and signature modeling", "author": ["J. Fierrez", "J. Ortega-Garcia", "D. Ramos", "J. Gonzalez-Rodriguez"], "venue": "Pattern Recognition Letters 28 ", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2007}, {"title": "Stability and style-variation modeling for on\u2013line signature verification", "author": ["K. Huang", "Y. Hong"], "venue": "Pattern Recognition 36 ", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2003}, {"title": "Velocity-image model for online signature verification", "author": ["M.A.U. Khan", "M.K. Khan", "M.A. Khan"], "venue": "IEEE Trans. Image Process 15 ", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2006}, {"title": "Fast on-line signature recognition based on VQ with time modelling", "author": ["J.M. Pascual\u2013Gaspar", "M. Fa\u00fandez\u2013Zanuy", "C. Vivaracho"], "venue": "Engineering Applications of Artificial Intelligence", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 2011}, {"title": "New Approach for the On-Line Signature Verification Based on Method of Horizontal Partitioning", "author": ["M. Zalasi\u0144ski", "K. Cpa\u0142ka"], "venue": "Lecture Notes In Artificial Intelligence 7895 ", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2013}, {"title": "A hybrid online signature verification system supporting multi-confidential levels defined by data mining techniques", "author": ["J.H. Moon", "S.G. Lee", "S.Y. Cho", "Y.S. Kim"], "venue": "International Journal of Intelligent Systems Technologies and Applications 9 ", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2010}, {"title": "Combining local", "author": ["L. Nanni", "E. Maiorana", "A. Lumini", "P. Campisi"], "venue": "regional and global matchers for a template protected on-line signature verification system, Expert Systems with Applications 37 ", "citeRegEx": "31", "shortCiteRegEx": null, "year": 2010}, {"title": "Legendre polynomials based feature extraction for online signature verification", "author": ["M. Parodi", "J.C. G\u00f3mez"], "venue": "Consistency analysis of feature combinations, Pattern Recognition 47 ", "citeRegEx": "32", "shortCiteRegEx": null, "year": 2014}, {"title": "New method for dynamic signature verification using hybrid partitioning", "author": ["M. Zalasi\u0144ski", "K. Cpa\u0142ka", "M.J. Er"], "venue": "Artificial Intelligence and Soft Computing 8467 ", "citeRegEx": "33", "shortCiteRegEx": null, "year": 2014}, {"title": "Velocity and pressure-based partitions of horizontal and vertical trajectories for on-line signature verification", "author": ["M.T. Ibrahim", "M.A. Khan", "K.S. Alimgeer", "M.K. Khan", "I.A. Taj", "L. Guan"], "venue": "Pattern Recognition 43 ", "citeRegEx": "34", "shortCiteRegEx": null, "year": 2010}, {"title": "Novel algorithm for the on-line signature verification", "author": ["M. Zalasi\u0144ski", "K. Cpa\u0142ka"], "venue": "Lecture Notes in Artificial Intelligence 7268 ", "citeRegEx": "35", "shortCiteRegEx": null, "year": 2012}, {"title": "Fuzzy Sets", "author": ["L.A. Zadeh"], "venue": "Information and Control 8 ", "citeRegEx": "36", "shortCiteRegEx": null, "year": 1965}, {"title": "Interpretability of linguistic fuzzy rule-based systems: An overview of interpretability measures", "author": ["M.J. Gacto", "R. Alcala", "F. Herrera"], "venue": "Information Sciences 181 ", "citeRegEx": "37", "shortCiteRegEx": null, "year": 2011}, {"title": "A", "author": ["J. Ortega-Garcia", "J. Fierrez-Aguilar", "D. Simon", "J. Gonzalez", "M. Faundez-Zanuy", "V. Espinosa"], "venue": "Satue, I., Hernaez, J.-J. Igarza, C. Vivaracho, D. Escudero, Q.-I. Moro, MCYT baseline corpus: a bimodal biometric database, IEE Proc.-Vis. Image Signal Process. 150 ", "citeRegEx": "38", "shortCiteRegEx": null, "year": 2003}, {"title": "Correlation based dynamic time warping of multivariate time series", "author": ["Z. Bank\u00f3", "A. J\u00e1nos"], "venue": "Expert Systems with Applications 39 ", "citeRegEx": "41", "shortCiteRegEx": null, "year": 2012}, {"title": "Constructing gene regulatory networks from microarray data using GA/PSO with DTW", "author": ["C.-P. Lee", "Y. Leu", "W.-N. Yang"], "venue": "Applied Soft Computing 12 ", "citeRegEx": "42", "shortCiteRegEx": null, "year": 2012}, {"title": "Kinect-enabled home-based rehabilitation system using Dynamic Time Warping and fuzzy logic", "author": ["J. Fernandez de C.-J. Su", "C.-Y. Chiang", "J.-Y. Huang"], "venue": "Applied Soft Computing", "citeRegEx": "43", "shortCiteRegEx": "43", "year": 2014}, {"title": "Digital Image Processing", "author": ["R.C. Gonzalez", "R.E. Woods"], "venue": "Pearson Education Inc. ", "citeRegEx": "44", "shortCiteRegEx": null, "year": 2002}, {"title": "A comparative study on the consistency of features in on-line signature verification", "author": ["H. Lei", "V. Govindaraju"], "venue": "Pattern Recognition Letters 26 ", "citeRegEx": "45", "shortCiteRegEx": null, "year": 2005}, {"title": "Development of a Sigma\u2013Lognormal representation for on-line signatures", "author": ["Ch. O\u2019Reilly", "R. Plamondon"], "venue": "Pattern Recognition", "citeRegEx": "46", "shortCiteRegEx": "46", "year": 2009}, {"title": "SVC2004: First International Signature Verification Competition", "author": ["D.Y. Yeung", "H. Chang", "Y. Xiong", "S. George", "R. Kashi", "T. Matsumoto", "G. Rigoll"], "venue": "Lecture Notes in Computer Science 3072 ", "citeRegEx": "48", "shortCiteRegEx": null, "year": 2004}, {"title": "On Design of Flexible Neuro-Fuzzy Systems for Nonlinear Modelling", "author": ["K. Cpa\u0142ka", "O. Rebrova", "R. Nowicki", "L. Rutkowski"], "venue": "International Journal of General Systems 42 ", "citeRegEx": "49", "shortCiteRegEx": null, "year": 2013}, {"title": "Designing and learning of adjustable quasi triangular norms with applications to neuro-fuzzy systems", "author": ["L. Rutkowski", "K. Cpa\u0142ka"], "venue": "IEEE Trans. on Fuzzy Systems 13 ", "citeRegEx": "50", "shortCiteRegEx": null, "year": 2005}, {"title": "A New Method for Design and Reduction of Neuro-Fuzzy Classification Systems", "author": ["K. Cpa\u0142ka"], "venue": "IEEE Trans. Neural Networks 20 ", "citeRegEx": "51", "shortCiteRegEx": null, "year": 2009}, {"title": "On evolutionary designing and learning of flexible neurofuzzy structures for nonlinear classification", "author": ["K. Cpa\u0142ka"], "venue": "Nonlinear Analysis Series A: Theory, Methods and Applications 71 ", "citeRegEx": "52", "shortCiteRegEx": null, "year": 2009}, {"title": "Flexible neuro-fuzzy systems", "author": ["L. Rutkowski", "K. Cpa\u0142ka"], "venue": "IEEE Trans. on Neural Networks 14 ", "citeRegEx": "53", "shortCiteRegEx": null, "year": 2003}, {"title": "Novel Online Speed Profile Generation for Industrial Machine Tool Based on Flexible Neuro-Fuzzy Approximation", "author": ["L. Rutkowski", "A. Przyby\u0142", "K. Cpa\u0142ka"], "venue": "IEEE Trans. Industrial Electronics 59 ", "citeRegEx": "54", "shortCiteRegEx": null, "year": 2012}, {"title": "A new method for designing neuro-fuzzy systems for nonlinear modelling with interpretability aspects", "author": ["K. Cpa\u0142ka", "K. \u0141apa", "A. Przyby\u0142", "M. Zalasi\u0144ski"], "venue": "Neurocomputing 135 ", "citeRegEx": "55", "shortCiteRegEx": null, "year": 2014}, {"title": "Introduction to Biometrics", "author": ["A.K. Jain", "A. Ross"], "venue": "A.K. Jain, P. Flynn, A.A. Ross (Eds.), Handbook of Biometrics ", "citeRegEx": "56", "shortCiteRegEx": null, "year": 2008}, {"title": "B", "author": ["N. Houmani", "S. Garcia-Salicetti", "A. Mayoue"], "venue": "Dorizzi, BioSecure Signature Evaluation Campaign 2009 ", "citeRegEx": "57", "shortCiteRegEx": null, "year": 2009}], "referenceMentions": [{"referenceID": 0, "context": "[1, 2, 3, 4, 5, 6]).", "startOffset": 0, "endOffset": 18}, {"referenceID": 1, "context": "[1, 2, 3, 4, 5, 6]).", "startOffset": 0, "endOffset": 18}, {"referenceID": 2, "context": "[1, 2, 3, 4, 5, 6]).", "startOffset": 0, "endOffset": 18}, {"referenceID": 3, "context": "[1, 2, 3, 4, 5, 6]).", "startOffset": 0, "endOffset": 18}, {"referenceID": 4, "context": "[1, 2, 3, 4, 5, 6]).", "startOffset": 0, "endOffset": 18}, {"referenceID": 5, "context": "[1, 2, 3, 4, 5, 6]).", "startOffset": 0, "endOffset": 18}, {"referenceID": 6, "context": "Some authors have also presented a methods based on both these approaches (see [7, 8]).", "startOffset": 79, "endOffset": 85}, {"referenceID": 7, "context": "Some authors have also presented a methods based on both these approaches (see [7, 8]).", "startOffset": 79, "endOffset": 85}, {"referenceID": 8, "context": "[9, 10]).", "startOffset": 0, "endOffset": 7}, {"referenceID": 9, "context": "[9, 10]).", "startOffset": 0, "endOffset": 7}, {"referenceID": 10, "context": "[11, 12, 13, 14, 15]), (b) function-based approach (see e.", "startOffset": 0, "endOffset": 20}, {"referenceID": 11, "context": "[11, 12, 13, 14, 15]), (b) function-based approach (see e.", "startOffset": 0, "endOffset": 20}, {"referenceID": 12, "context": "[11, 12, 13, 14, 15]), (b) function-based approach (see e.", "startOffset": 0, "endOffset": 20}, {"referenceID": 13, "context": "[11, 12, 13, 14, 15]), (b) function-based approach (see e.", "startOffset": 0, "endOffset": 20}, {"referenceID": 14, "context": "[11, 12, 13, 14, 15]), (b) function-based approach (see e.", "startOffset": 0, "endOffset": 20}, {"referenceID": 15, "context": "[16, 17, 18, 19, 20, 21]), (c) regional approach (see e.", "startOffset": 0, "endOffset": 24}, {"referenceID": 16, "context": "[16, 17, 18, 19, 20, 21]), (c) regional approach (see e.", "startOffset": 0, "endOffset": 24}, {"referenceID": 17, "context": "[16, 17, 18, 19, 20, 21]), (c) regional approach (see e.", "startOffset": 0, "endOffset": 24}, {"referenceID": 18, "context": "[16, 17, 18, 19, 20, 21]), (c) regional approach (see e.", "startOffset": 0, "endOffset": 24}, {"referenceID": 19, "context": "[16, 17, 18, 19, 20, 21]), (c) regional approach (see e.", "startOffset": 0, "endOffset": 24}, {"referenceID": 20, "context": "[16, 17, 18, 19, 20, 21]), (c) regional approach (see e.", "startOffset": 0, "endOffset": 24}, {"referenceID": 21, "context": "[22, 23, 24, 25, 26, 27, 28, 29]) and (d) hybrid approach (see e.", "startOffset": 0, "endOffset": 32}, {"referenceID": 22, "context": "[22, 23, 24, 25, 26, 27, 28, 29]) and (d) hybrid approach (see e.", "startOffset": 0, "endOffset": 32}, {"referenceID": 23, "context": "[22, 23, 24, 25, 26, 27, 28, 29]) and (d) hybrid approach (see e.", "startOffset": 0, "endOffset": 32}, {"referenceID": 24, "context": "[22, 23, 24, 25, 26, 27, 28, 29]) and (d) hybrid approach (see e.", "startOffset": 0, "endOffset": 32}, {"referenceID": 25, "context": "[22, 23, 24, 25, 26, 27, 28, 29]) and (d) hybrid approach (see e.", "startOffset": 0, "endOffset": 32}, {"referenceID": 26, "context": "[22, 23, 24, 25, 26, 27, 28, 29]) and (d) hybrid approach (see e.", "startOffset": 0, "endOffset": 32}, {"referenceID": 27, "context": "[22, 23, 24, 25, 26, 27, 28, 29]) and (d) hybrid approach (see e.", "startOffset": 0, "endOffset": 32}, {"referenceID": 28, "context": "[22, 23, 24, 25, 26, 27, 28, 29]) and (d) hybrid approach (see e.", "startOffset": 0, "endOffset": 32}, {"referenceID": 29, "context": "[30, 31, 32]).", "startOffset": 0, "endOffset": 12}, {"referenceID": 30, "context": "[30, 31, 32]).", "startOffset": 0, "endOffset": 12}, {"referenceID": 31, "context": "[30, 31, 32]).", "startOffset": 0, "endOffset": 12}, {"referenceID": 24, "context": "[25]).", "startOffset": 0, "endOffset": 4}, {"referenceID": 25, "context": "In [26] signatures are segmented into strokes and for each of them the reliability measure is computed on the basis of the feature values which belong to the current stroke.", "startOffset": 3, "endOffset": 7}, {"referenceID": 26, "context": "In [27] a stroke-based algorithm that splits velocity signal into three bands has been proposed.", "startOffset": 3, "endOffset": 7}, {"referenceID": 21, "context": "[22, 23]).", "startOffset": 0, "endOffset": 8}, {"referenceID": 22, "context": "[22, 23]).", "startOffset": 0, "endOffset": 8}, {"referenceID": 22, "context": "In [23] we propose a method which determines the importance of each time moment of signing process individually for each signer.", "startOffset": 3, "endOffset": 7}, {"referenceID": 21, "context": "[22] we propose a method, which allows one to select some typical areas in the signature of the user, created as a result of an analysis of pen velocity and pen pressure signals.", "startOffset": 0, "endOffset": 4}, {"referenceID": 32, "context": "Initial attempts to introduce this method are outlined in [33].", "startOffset": 58, "endOffset": 62}, {"referenceID": 26, "context": "[27] no yes no yes no no Ibrahim et al.", "startOffset": 0, "endOffset": 4}, {"referenceID": 33, "context": "[34] no yes no yes no no Fierrez et al.", "startOffset": 0, "endOffset": 4}, {"referenceID": 24, "context": "[25] yes no no no no no Huang and Hong [26] no yes no yes yes no Fa\u00fandez-Zanuy, Pascual-Gaspar [24] yes no yes no no no Pascual-Gaspar et al.", "startOffset": 0, "endOffset": 4}, {"referenceID": 25, "context": "[25] yes no no no no no Huang and Hong [26] no yes no yes yes no Fa\u00fandez-Zanuy, Pascual-Gaspar [24] yes no yes no no no Pascual-Gaspar et al.", "startOffset": 39, "endOffset": 43}, {"referenceID": 23, "context": "[25] yes no no no no no Huang and Hong [26] no yes no yes yes no Fa\u00fandez-Zanuy, Pascual-Gaspar [24] yes no yes no no no Pascual-Gaspar et al.", "startOffset": 95, "endOffset": 99}, {"referenceID": 27, "context": "[28] yes no yes no no no Zalasi\u0144ski, Cpa\u0142ka [35] no yes no yes yes no Cpa\u0142ka et al.", "startOffset": 0, "endOffset": 4}, {"referenceID": 34, "context": "[28] yes no yes no no no Zalasi\u0144ski, Cpa\u0142ka [35] no yes no yes yes no Cpa\u0142ka et al.", "startOffset": 44, "endOffset": 48}, {"referenceID": 22, "context": "[23] no yes no yes yes yes Cpa\u0142ka, Zalasi\u0144ski [22] yes no no yes yes yes Our method yes yes no yes yes yes", "startOffset": 0, "endOffset": 4}, {"referenceID": 21, "context": "[23] no yes no yes yes yes Cpa\u0142ka, Zalasi\u0144ski [22] yes no no yes yes yes Our method yes yes no yes yes yes", "startOffset": 46, "endOffset": 50}, {"referenceID": 32, "context": "Moreover, interpretation of the partitions selected by the method described in [33] is different from the interpretation in the algorithm proposed in this paper and the partition analysis in the mentioned method is less precise.", "startOffset": 79, "endOffset": 83}, {"referenceID": 35, "context": "In the proposed method we used \"high similarity\" and \"low similarity\" fuzzy sets to describe similarity values (see [36]).", "startOffset": 116, "endOffset": 120}, {"referenceID": 36, "context": "in [37]).", "startOffset": 3, "endOffset": 7}, {"referenceID": 37, "context": "To test the proposed method we used two databases of the signatures: public MCYT-100 (see [38]) distributed by the Biometric Recognition Group - ATVS (see [39]) and paid BioSecure (BMDB) distributed by the BioSecure Association (see [40]).", "startOffset": 90, "endOffset": 94}, {"referenceID": 38, "context": "[41, 42, 43]), which operates on the basis of matching velocity and pressure signals.", "startOffset": 0, "endOffset": 12}, {"referenceID": 39, "context": "[41, 42, 43]), which operates on the basis of matching velocity and pressure signals.", "startOffset": 0, "endOffset": 12}, {"referenceID": 40, "context": "[41, 42, 43]), which operates on the basis of matching velocity and pressure signals.", "startOffset": 0, "endOffset": 12}, {"referenceID": 41, "context": "[44]).", "startOffset": 0, "endOffset": 4}, {"referenceID": 16, "context": "[17, 34, 45, 46]).", "startOffset": 0, "endOffset": 16}, {"referenceID": 33, "context": "[17, 34, 45, 46]).", "startOffset": 0, "endOffset": 16}, {"referenceID": 42, "context": "[17, 34, 45, 46]).", "startOffset": 0, "endOffset": 16}, {"referenceID": 43, "context": "[17, 34, 45, 46]).", "startOffset": 0, "endOffset": 16}, {"referenceID": 0, "context": "where t-norm T {\u00b7} is a generalization of the usual two-valued logical conjunction (studied in classical logic), w1 and w2 \u2208 [0, 1] mean weights of importance of the arguments a1, a2 \u2208 [0, 1].", "startOffset": 125, "endOffset": 131}, {"referenceID": 0, "context": "where t-norm T {\u00b7} is a generalization of the usual two-valued logical conjunction (studied in classical logic), w1 and w2 \u2208 [0, 1] mean weights of importance of the arguments a1, a2 \u2208 [0, 1].", "startOffset": 185, "endOffset": 191}, {"referenceID": 0, "context": "- cthi \u2208 [0, 1] - coefficient determined experimentally for each user to eliminate disproportion between FAR and FRR error (see e.", "startOffset": 9, "endOffset": 15}, {"referenceID": 44, "context": "[48]).", "startOffset": 0, "endOffset": 4}, {"referenceID": 45, "context": "in [49, 50, 51, 52, 53, 54].", "startOffset": 3, "endOffset": 27}, {"referenceID": 46, "context": "in [49, 50, 51, 52, 53, 54].", "startOffset": 3, "endOffset": 27}, {"referenceID": 47, "context": "in [49, 50, 51, 52, 53, 54].", "startOffset": 3, "endOffset": 27}, {"referenceID": 48, "context": "in [49, 50, 51, 52, 53, 54].", "startOffset": 3, "endOffset": 27}, {"referenceID": 49, "context": "in [49, 50, 51, 52, 53, 54].", "startOffset": 3, "endOffset": 27}, {"referenceID": 50, "context": "in [49, 50, 51, 52, 53, 54].", "startOffset": 3, "endOffset": 27}, {"referenceID": 36, "context": "For example, in [37] 4 levels of interpretability are shown: Q1: complexity at the rule base level (it takes into account number of rules and number of conditions), Q2: complexity at the level of fuzzy partitions (it takes into account number of membership functions, number of features or variables), Q3: semantics at the rule base level (it takes into account rules fired at the same time), Q4: semantics at the fuzzy partition level (it takes into account completeness or coverage, normalization, distinguishes ability and complementarity).", "startOffset": 16, "endOffset": 20}, {"referenceID": 47, "context": "[51, 55]).", "startOffset": 0, "endOffset": 8}, {"referenceID": 51, "context": "[51, 55]).", "startOffset": 0, "endOffset": 8}, {"referenceID": 52, "context": "the ones described in [56]), but in this case it would be difficult to compare the obtained results with the results of other authors.", "startOffset": 22, "endOffset": 26}, {"referenceID": 21, "context": "[22, 23]) also do not require high computational complexity but they contain an iterative procedure for the purpose of selecting the so-called border of inclusion of the reference signatures.", "startOffset": 0, "endOffset": 8}, {"referenceID": 22, "context": "[22, 23]) also do not require high computational complexity but they contain an iterative procedure for the purpose of selecting the so-called border of inclusion of the reference signatures.", "startOffset": 0, "endOffset": 8}, {"referenceID": 10, "context": "Method Average FAR Average FRR Average error Methods of other authors ([11, 12, 13, 14, 15, 16, 21, 25, 31, 34]) 0.", "startOffset": 71, "endOffset": 111}, {"referenceID": 11, "context": "Method Average FAR Average FRR Average error Methods of other authors ([11, 12, 13, 14, 15, 16, 21, 25, 31, 34]) 0.", "startOffset": 71, "endOffset": 111}, {"referenceID": 12, "context": "Method Average FAR Average FRR Average error Methods of other authors ([11, 12, 13, 14, 15, 16, 21, 25, 31, 34]) 0.", "startOffset": 71, "endOffset": 111}, {"referenceID": 13, "context": "Method Average FAR Average FRR Average error Methods of other authors ([11, 12, 13, 14, 15, 16, 21, 25, 31, 34]) 0.", "startOffset": 71, "endOffset": 111}, {"referenceID": 14, "context": "Method Average FAR Average FRR Average error Methods of other authors ([11, 12, 13, 14, 15, 16, 21, 25, 31, 34]) 0.", "startOffset": 71, "endOffset": 111}, {"referenceID": 15, "context": "Method Average FAR Average FRR Average error Methods of other authors ([11, 12, 13, 14, 15, 16, 21, 25, 31, 34]) 0.", "startOffset": 71, "endOffset": 111}, {"referenceID": 20, "context": "Method Average FAR Average FRR Average error Methods of other authors ([11, 12, 13, 14, 15, 16, 21, 25, 31, 34]) 0.", "startOffset": 71, "endOffset": 111}, {"referenceID": 24, "context": "Method Average FAR Average FRR Average error Methods of other authors ([11, 12, 13, 14, 15, 16, 21, 25, 31, 34]) 0.", "startOffset": 71, "endOffset": 111}, {"referenceID": 30, "context": "Method Average FAR Average FRR Average error Methods of other authors ([11, 12, 13, 14, 15, 16, 21, 25, 31, 34]) 0.", "startOffset": 71, "endOffset": 111}, {"referenceID": 33, "context": "Method Average FAR Average FRR Average error Methods of other authors ([11, 12, 13, 14, 15, 16, 21, 25, 31, 34]) 0.", "startOffset": 71, "endOffset": 111}, {"referenceID": 22, "context": "80 % Algorithm based on Horizontal Partitioning, AHP ([23]) 5.", "startOffset": 54, "endOffset": 58}, {"referenceID": 21, "context": "Algorithm based on Vertical Partitioning, AVP ([22]) 5.", "startOffset": 47, "endOffset": 51}, {"referenceID": 53, "context": "Method Average FAR Average FRR Average error Methods of other authors ([57]) 3.", "startOffset": 71, "endOffset": 75}, {"referenceID": 22, "context": "13 % Algorithm based on Horizontal Partitioning, AHP ([23]) 2.", "startOffset": 54, "endOffset": 58}, {"referenceID": 21, "context": "Algorithm based on Vertical Partitioning, AVP ([22]) 3.", "startOffset": 47, "endOffset": 51}, {"referenceID": 22, "context": "Step number AHP [23] AVP [22] proposed method 1 2RJKi 2PJKi 2PRJKi 2 RJKi PJKi PRJKi 3 RJ (Ki + 2) PJ (Ki + 2) PRJ (Ki + 2) 4 4R (J + 1) 4P (J + 1) 4PR (J + 1) 5 J (RKi + 2) + nb J (PKi + 2) + nb 6 RJ PJ PRJ 7 1 1 1 Step number: 1.", "startOffset": 16, "endOffset": 20}, {"referenceID": 21, "context": "Step number AHP [23] AVP [22] proposed method 1 2RJKi 2PJKi 2PRJKi 2 RJKi PJKi PRJKi 3 RJ (Ki + 2) PJ (Ki + 2) PRJ (Ki + 2) 4 4R (J + 1) 4P (J + 1) 4PR (J + 1) 5 J (RKi + 2) + nb J (PKi + 2) + nb 6 RJ PJ PRJ 7 1 1 1 Step number: 1.", "startOffset": 25, "endOffset": 29}], "year": 2016, "abstractText": "Identity verification based on authenticity assessment of a handwritten signature is an important issue in biometrics. There are many effective methods for signature verification taking into account dynamics of a signing process. Methods based on partitioning take a very important place among them. In this paper we propose a new approach to signature partitioning. Its most important feature is the possibility of selecting and processing of hybrid partitions in order to increase a precision of the test signature analysis. Partitions are formed by a combination of vertical and horizontal sections of the signature. Vertical sections correspond to the initial, middle, and final time moments of the signing process. In turn, horizontal sections correspond to the signature areas associated with high and low pen velocity and high and low pen pressure on the surface of a graphics tablet. Our previous research on vertical and horizontal sections of the dynamic signature (created independently) led us to develop the algorithm presented in this paper. Selection of sections, among others, allows us to define the stability of the signing process in the partitions, promoting signature areas of greater stability (and vice versa). In the test of the proposed method two databases were used: public Corresponding author Email addresses: krzysztof.cpalka@iisi.pcz.pl (Krzysztof Cpa\u0142ka), marcin.zalasinski@iisi.pcz.pl (Marcin Zalasi\u0144ski), leszek.rutkowski@iisi.pcz.pl (Leszek Rutkowski) Full postal address: Institute of Computational Intelligence, Cz\u0119stochowa University of Technology, Al. Armii Krajowej 36, 42-200 Cz\u0119stochowa, Poland; Telephone and fax number: 0-48 343250546 Preprint submitted to Applied Soft Computing October 6, 2016 MCYT-100 and paid BioSecure.", "creator": "LaTeX with hyperref package"}}}