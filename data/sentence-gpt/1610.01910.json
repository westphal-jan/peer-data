{"id": "1610.01910", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "6-Oct-2016", "title": "Toward Automatic Understanding of the Function of Affective Language in Support Groups", "abstract": "Understanding expressions of emotions in support forums has considerable value and NLP methods are key to automating this. Many approaches understandably use subjective categories which are more fine-grained than a straightforward polarity-based spectrum. However, the definition of such categories is non-trivial and, in fact, we argue for a need to incorporate communicative elements even beyond subjectivity. As one might expect, using a subjective category is no guarantee that any sort of expression of emotion will be understood. Indeed, these categories are usually associated with subjective categories, and are only used as an indicator of how the human mind interacts with emotional and psychological processes. As such, we believe that the concept of subjective or non-trivial category forms the basis for this conceptualization of subjective-category concepts and the ability to interpret them in the context of emotional and psychological processes. To understand this, we have to develop a framework for addressing the concept of subjective or non-trivial categories.\n\n\n\nA.\nWe recommend the following concepts to the reader:\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n", "histories": [["v1", "Thu, 6 Oct 2016 15:23:31 GMT  (188kb)", "http://arxiv.org/abs/1610.01910v1", "9 pages, 1 figure, conference workshop"]], "COMMENTS": "9 pages, 1 figure, conference workshop", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["amit navindgi", "caroline brun", "c\\'ecile boulard masson", "scott nowson"], "accepted": false, "id": "1610.01910"}, "pdf": {"name": "1610.01910.pdf", "metadata": {"source": "CRF", "title": "Toward Automatic Understanding of the Function of Affective Language in Support Groups", "authors": ["Amit Navindgi", "Caroline Brun", "C\u00e9cile Boulard Masson"], "emails": ["navindgi@usc.edu", "@xrce.xerox.com", "scott.nowson@accenture.com"], "sections": [{"heading": null, "text": "ar X\niv :1\n61 0.\n01 91\n0v 1\n[ cs\n.C L\n] 6\nO ct\n2 01\n6"}, {"heading": "1 Introduction", "text": "There are a wealth of opinions on the internet. Social media has lowered the accessibility bar to an even larger audience who are now able to share their voice. However, more than just opinions on external matters, people are able to share their emotions and feelings, talking openly about very personal matters. In fact, further to merely enabling this affective expressionism, studies have shown that anonymity in online presence increases the chance of sharing more personal information and emotions when compared to face-to-face interactions (Hancock et al., 2007).\nMedical support forums are one platform on which users generate emotion-rich content. People exchange factual information about elements\n\u2217 Work carried out while all authors at Xerox Research Centre Europe.\nsuch as treatments or hospitals, and provide emotional support to others with similar experiences (Bringay et al., 2014). This sharing through open discussion is known to be considerably beneficial (Pennebaker et al., 2001).\nUnderstanding affective language in the healthcare domain is an effective application of natural language technologies. Sentiment mining on platforms such as Twitter, for example, can be seen as a quick method to gauge public opinion of government policies (Speriosu et al., 2011). However, the level of affective expression in a support forum setting is considerably more complex than a traditional positive-negative polarity spectrum.\nMore than just a more-fined grained labelling scheme, however, we also need a deeper understanding on the language being used. Much sentiment analysis research has focused on classifying the overall sentiment of a document or short text onto a positive-negative spectrum (Hu and Liu, 2004; Kim and Hovy, 2006). Recently, research work targeting finer grained analysis has emerged, such as aspect-based sentiment analysis (Liu, 2012; Pontiki et al., 2014), or semantic role labelling of emotions (Mohammad et al., 2014). Aspect-based sentiment analysis aims at detecting fine-grained opinions expressed about different aspects of a given entity, while semantic role labelling of emotions aims at capturing not only emotions in texts but also experiencers and stimuli of these emotions. This relatively new trend in social media analytics enables the reliable detection of not simply binary sentiment, but more subtle, nuanced sentiments and mixed feelings. This is important because opinions, emotions and sentiments are not typically one-dimensional but multidimensional, and this is the case in any domain. Even more than this, such affective expression often serve a social purpose (Rothman and Magee, 2016). There is a real need to understand these\nspecific sentiments in order to be able to pinpoint and prioritize decisions and actions to be taken according to goals and applications.\nWith these considerations in mind, We explore a dataset drawn from a health-related support forum, labelled for a variety of expressed sentiments. In this work we do not necessarily seek state-of-theart performance in any specific task. We use this task to argue for two key positions:\n\u2022 that sub-document level analysis is required to best understand affective expressions \u2022 that to fully understand expressions of emotion in support forums, a fine-grained annotation scheme is required which takes into account the social function of such expressions.\nThis paper begins by reviewing work related to our propositions above. In Section 3 we describe the data which we have used, paying particular attention to the annotation scheme. We then report on our experiments, which were defined in order to support the hypotheses above. Following this, in Section 5 we discuss the implication of this work."}, {"heading": "2 Related Work", "text": "As reported earlier, polarity-based studies in the healthcare domain have considerable value. One work squarely in the public policy domain sought to classify tweets related to the recent health care reform in the US into positive and negative (Speriosu et al., 2011). They constructed a Twitter follower graph of relations between users, their tweets and tweets\u2019 content. They applied a semi-supervised label propagation method on unlabelled tweets and obtained better accuracy than a Maximum Entropy classifier.\nAli et al. (2013) experimented with data from multiple forums for people with hearing-loss. They use the subjectivity lexicon of Wilson et al. (2005) and count-based syntactic features (e.g. number of adjectives, adverbs, etc.). This approach outperformed a baseline bag-of-words model, highlighting the importance of subjective lexica for text analysis in health domain. Ofek et al. (2013) use a dynamic sentiment lexicon to improve sentiment analysis in an online community for cancer survivors. They build a domain specific lexicon from training data by representing text as bag-of-words with term-frequency as the attribute values. They train classifiers using abstract features extracted from this lexicon and out-\nperform models trained using features extracted from a general sentiment lexicon.\nSokolova and Bobicev (2013) took the lexicon approach further: they defined a more fine-grained annotation scheme (see Section 3 for more details) and labelled data from an IVF-related forum. Adapting Pointwise Mutual Information and using Semantic Orientation to associate n-gram phrases in the dataset with the document labels, they created a tailored, category-specific set of lexicons. These lexicons performed better, at 6-class classification, than a generic subjectivity lexicon.\nIn selecting their data, Sokolova and Bobicev (2013) \u2013 as Ali et al. (2013) and others have done \u2013 tapped into the domain of on-line support communities. Eastin and LaRose (2005) showed that people who seek support on-line \u2013 be it emotional or informational support \u2013 typically find it. There are considerable benefits to participating in such groups. In a meta-analysis of 28 studies of healthbased forums, Rains and Young (2009) reported that participants perceive an increase in social support, a significant decrease in depression, and significant increases in both quality of life and selfefficacy in managing their condition.\nInformational support is largely based around the sharing of knowledge and experiences. Emotional support is more complex, and can be framed as empathic communication. Pfeil and Zaphiris (2007) identify four components of such communication: understanding, emotions, similarities and concerns.\nIn addition to direct support, another common dimension of such online groups is selfdisclosure (Prost, 2012). Barak and Gluck-Ofri (2007) identify self-disclosure as specific to open support groups (e.g. \u201cCancerNot Alone\u201d or \u201cEmotional Support for Adolescents\u201d) as opposed to, for example, subject-specific discussion forums (e.g. \u201cVegetarianism and Naturalism\u201d or \u201cHarry Potter The Book\u201d). Self-disclosure serves three social functions (Tichon and Shapiro, 2003): requesting implicit support by showing confusion and worries; providing support by sharing details of a personal experience and sharing information to further develop social relationships."}, {"heading": "3 Data", "text": "In this section we discuss aspects of the data we use in detail to support the position of the paper."}, {"heading": "3.1 Data Source", "text": "The data used here1 is that of Bobicev and Sokolova (2015) \u2013 which is an extension to the data used, and described in more depth, in Sokolova and Bobicev (2013). Data was collected from discussion threads on a sub-forum of an In Vitro Fertilization (IVF) medical forum2 intended for discussion by participants who belong to a specific age-group (over 35s). The dataset (henceforth MedSenti) originally contained 1321 posts across 80 different topics."}, {"heading": "3.2 Annotation Details", "text": "There are two approaches to annotation of subjective aspects of communication: from the perspective of a reader\u2019s perception (Strapparava and Mihalcea, 2007) or that of the author (Balahur and Steinberger, 2009). In labelling MedSenti Sokolova and Bobicev (2013) opted for the readercentric model and hence asked the annotators to analyse a post\u2019s sentiment as if they were other discussion participants. This is an important differentiation for automated classification style tasks - models are built to predict how people will understand the emotion expressed, as opposed to the emotion or sentiment an author feels they are conveying. For example, Maks and Vossen (2013) showed in review texts that reader assigned scores were more reliably related to the language used than the original rating of the author. Similarly, Mehl et al. (2006) showed that ratings of personality perceived by a third party \u201cover-hearing\u201d a conversation was strongly correlated with groundtruth labels acquired via self-assessment.\nAs discussed previously, using positive and negative labelling is too coarse for personal, empathic communications, such as those in the health support space. More fine-grained categories are required. The annotation scheme was evolved over multiple rounds of data exploration, with annotators consulted for their opinions on post-level sentiments as components of the evolution of threadlevel sentiment. Responses were grouped and summarised and ultimately three sentiment categories were defined:\n1. confusion, (henceforth CONF) which includes aspects such as \u201cworry, concern, doubt, impatience, uncertainty, sadness, an-\n1Kindly provided to us by the authors. 2http://ivf.ca/forums\ngriness, embarrassment, hopelessness, dissatisfaction, and dislike\u201d 2. encouragement, (ENCO) includes \u201ccheering, support, hope, happiness, enthusiasm, excitement, optimism\u201d 3. gratitude, (GRAT) which represents thankfulness and appreciation\nThough this set of labels was evolved independently \u2013 to the best of our knowledge \u2013 it captures important dimensions identified in the sociology literature. CONF here, for example, maps to expressions of confusion (Tichon and Shapiro, 2003) and those of concern (Pfeil and Zaphiris, 2007).\nBroadly generalising with respect to polar labels, CONF is essentially a negative category while ENCO is positive. GRAT would therefore be a subset of positive expressions. In contrast, however, it was clear that certain expressions which might be considered negative on a word level \u2013 such as those of compassion, sorrow, and pity \u2013 were used with a positive, supportive intention. They were therefore included in the ENCO category, and in fact were often posted with other phrases which would in isolation fall under this label.\nIn addition to the subjective categories, Sokolova and Bobicev (2013) identified two types of objective posts: those with strictly factual information (FACT), and those which combined factual information and short emotional expression (typically of the ENCO type) which were labelled as endorsement (ENDO). Each of the 1321 individual posts was labelled with one of the above five classes by two annotators.3"}, {"heading": "3.3 Data and Label Preprocessing", "text": "We select document labels as per Bobicev and Sokolova (2015): when two labels match, reduce to a single label; when the labels disagree the post is marked with a sixth label ambiguous (AMBI).\nThe posts in MedSenti were taken directly from the forum. Therefore, there were a number which quoted previous posts, as is common in such discussions. For example (quoted text in italics):\npost id 130007 author1 Member 17 September 2008 - 09:01 PM \u201c author2, on Sep 13 2008, 10:47 AM, said:Thanks everyone.author1 - what 3 clinics did you go to prior to Create? Hi author2 I went to a center outside\n3Fleiss kappa = 0.73 (Bobicev and Sokolova, 2015).\nCanada, then Lifequest and Create was the 3rd one, which I decided to go with.Hope this is helpful.author1\u201d\nQuoted text could appear both before or after the main post content. In both cases the quote was replaced with an annotation (\u201cQOTEHERE\u201d) to indicate in future analysis that such a mechanism had been used. There were also a number of posts with quotes which contained no additional, original content. These were removed.\nIn addition, it is worth noting that in order to understand the relationships between document classes, we did not use the AMBI class in any experiments reported in this paper. This leaves 1137 posts in our MedSenti corpus, with the category distribution as per Table 1."}, {"heading": "4 Experiments", "text": "To support our positions stated earlier regarding the understanding of affective expressions in support forums, we conducted a series of experiments. As stated, we are not seeking the achieve state-ofthe-art results, but to highlight some of the challenges with current approaches."}, {"heading": "4.1 Broad methodology", "text": "In this work, we use a robust dependency syntactic parser (Ait-Mokhtar et al., 2001) to extract a wide range of textual features, from word ngrams to more sophisticated linguistic attributes. Our experiments are framed as multi-class classification tasks using liblinear (Fan et al., 2008) and used 5-fold stratified cross-validation. It is worth noting that we do not use, here, a domaintuned lexicon. We re-implemented the Health Affect Lexicon (Sokolova and Bobicev, 2013) and it performed as well as previously reported. However, few studies of such approaches have shown that such lexicons generalise well, and label-based tuning is very task specific. We use the current set\nof categories to make more general points about work in support-related domains."}, {"heading": "4.2 Document Level analysis", "text": "In this set of experiments, we consider each post as a single unit of text with a single label."}, {"heading": "4.2.1 5-class classification", "text": "We utilised a variety of combinations of different linguistic feature sets. These ranged from basic word based n-grams, through semantic dependency features. Here, for illustrative purposes, we list the best performing combination: word uni-, bi-, and trigrams; binary markers for questions, conjunctions and uppercase characters; and a broad-coverage polarity lexicon. Results can be seen in Table 2\nOur best overall score (macro averaged F1 = 0.449) is significantly above the majority class baseline (F = 0.110). This compares favourably with the six-class performance of semantic features of the original data analysis (F1 = 0.397, Sokolova and Bobicev, 2013). However, more important \u2013 and not previously reported \u2013 is the percategory performance which gives more insight into the data. Essentially, we see that ENCO,GRAT and FACT perform relatively well while CONF and in particular ENDO are considerably poor.\nTo further explore this result we report the error matrix in Table 3. Looking at ENDO we see that incredibly only 6% has been correctly classified, while 86% is classified as either FACT or ENCO. This is theoretically understandable since the ENDO category is defined as containing aspects of both the other two categories directly. The reverse mis-classification is considerably less common, as is mis-classification as GRAT. CONF is also mis-classified as FACT a majority, with 43%."}, {"heading": "4.2.2 One-vs-all", "text": "In order to further explore the pattern of errors seen in Table 3, we attempted to directly classify each category individually in a one-vs-all binary task. The results for this task with a feature set consisting of word uni-, bi-, and trigrams, is presented in Table 4. Note we report only for the target class, as the other class is complementary.\nAgain we see a similar pattern of performance: ENCO and FACT are the most distinct from the other classes, while CONF and ENDO are considerably less so. It is worth noting that ENDO is particularly indistinct from the remainder of the corpus \u2013 despite being the third largest category the F-score is a mere 0.011. It is clear that this challenge is not a trivial one - there are distinct patterns of errors when classifying at the document level. In order to investigate this further, we move to sentence-level classification."}, {"heading": "4.3 Sentence Level analysis", "text": "In sentence-level analysis, we tokenise each post into its constituent sentences. The 1137 posts from the MedSenti become 8071 sentences, MedSentisent. Manual annotation at the sentence level is not feasible as it would be a considerably costly exercise. In order to label the corpus with the five categories of sentiment, we explored the use of automated methods."}, {"heading": "4.3.1 Na\u0131\u0308ve Labelling", "text": "The most trivial approach to label sentences is for each sentence to inherit the label of the post in which it is present. Following this na\u0131\u0308ve method, we obtain the distribution as shown in Table 5.\nWe run the 5-class classification scenario on MedSenti-sent using the same conditions and the previous best feature set; the results are shown in Table 6. Overall, the performance is worse than the post-level counterpart, with the exception of a small improvement to ENDO. FACT is the best performing individual category, though now with greater recall than precision.\nAs with document level, we explore the model performance in more depth with the error matrix in Table 7. The main observation we make here is that the drop in performance of the four subjective categories is largely due to mis-classification of sentences as FACT. Sentences in this category are the majority in MedSenti-sent (more than double the next closest category). However, the proportional differences with MedSenti do not seem to be not enough to explain the significant changes.\nA more likely explanation is simply that the errors arise because \u2013 at the very least \u2013 there can be FACT-like sentences in any post. At the time of creation, annotators were asked to label \u201cthe most dominant sentiment in the whole post\u201d (Sokolova and Bobicev, 2013, p. 636). For example, post 141143 contains the sentence:\nAlso, a nurse told me her cousin, 44, got pregnant (ivf)- the cousin lives in the USA.\nThe post itself is labelled ENCO. This sentence is \u2013 strictly speaking \u2013 the reporting of a fact, although it is easy to see how its purpose is to encourage others. However, at the lexico-semantic level, it is a purely objective sentence."}, {"heading": "4.3.2 Subjectivity-informed labelling", "text": "One approach to re-labelling of data is to take advantage of coarser levels of annotation: that of subjectivity. Is it possible to at least distinguish which sentences are objective, and could be labelled as FACT? We have developed a subjectivity model4 built for the SemEval 2016 Aspect Based Sentiment Analysis track (Pontiki et al., 2016), which was among the top performing models for polarity detection. We ran the model on all sentences of the corpus in order to assess their subjectivity. Any sentence with a subjectivity likelihood of < 0.7 (chosen following manual assessment) we consider to be objective; the remainder are subjective. To attempt to eliminate the confusion with the FACT category we eliminated objective sentences from sets previously labelled with the 4 subjective categories. In addition, because this \u201cconfusion\u201d can be bi-directional, we also removed any subjective sentences which were previously FACT. This MedSenti-sent-subj set consists of 4147 sentences. Once again, we use the same experimental settings as previously, with results presented in Table 8.\nAcross the board, performance is marginally better with this approach (against a majority macro averaged baseline of F1 = 0.107). Impor-\n4citation suppressed for anonymity\ntantly, in analysing the error matrix5 the proportion of data mis-classified has dropped considerably (from 51% to 37%). However, a related consequence is that the error-rate between the subjective categories has increased."}, {"heading": "5 Discussion", "text": "Despite the disappointing results in our sentence level experiments, we maintain that this level of analysis, as a step toward aspect-based understanding, is important to explore further. One reason for poor performance with both the MedSentisent and MedSenti-sent-subj is the approach to annotation at the sentence level. Naturally manual annotation of 8K sentences is considerably expensive and time consuming. However, there are clear examples in the data set of distinct labels being required. Consider the following example, (with manually annotated, illustrative labels):\npost id 226470 author1 \u201cauthor2 said [...] <ENCO> Thanks,I think we were afraid of rushing into such a big decision but now I feel it is most important not to have regrets. </ENCO> <FACT> The yale biopsy is a biopsy of the lining of my uterus and it is a new test conducted by Yale University. Here is a link you can read: URL This test is optional and I have to pay for it on my own... no coverage.</FACT>\u201d\nThe first statement of this post is clearly intended to encourage and support the person to whom the author was responding. The second set of sentences is conveying deliberately objective, factual information about their situation. In the MedSenti set this post is labelled as ENDO- the combination of ENCO and FACT. However, the\n5Not presented here for space concerns.\nFACT component of the post is a response to a question in an even earlier post than the quoted message. It could be argued therefore that these sentiment do not relate in the way for which the ENDO label was created. To consider post-level labels, then, we would argue is too coarse grained.\nTo explore the possible confusion introduced by the ENDO category, particularly after removing the objective sentences in MedSenti-sent-subj, we conducted experiments with this category (and FACT) excluded. In this three-class experiment (ENCO,CONF, and GRAT), performance was again reasonable against baseline (F1 = 0.510 over F1 = 0.213), but the error rate was still high, particularly for GRAT. Regardless of the linguistic feature sets, the models we have trained do not appear to be capturing the differences between the subjective categories. This seems contradictory to the original authors\u2019 intention of building \u201ca set of sentiments that [...] makes feasible the use of machine learning methods for automate sentiment detection.\u201d (Sokolova and Bobicev, 2013, p. 636). This is interesting because, from a human reader perspective (see Section 3), the annotation scheme makes intuitive sense. That the expressions of \u201cnegative\u201d emotions such as sympathy be considered in the \u201cpositive\u201d category of ENCO aligns with the social purpose behind such expressions (Pfeil and Zaphiris, 2007). Without explicitly calling attention to it, Sokolova and Bobicev (2013) encoded social purpose into their annotation scheme. As with previous effort in the space, the scheme they have defined is very much tuned to the emotional support domain.\nIn an attempt to understand potential reasons for errors, we created a visualisation of the annotation scheme in terms of scheme category label, higher level polarity, and sentiment target, which can be seen in Figure 1. As per the definitions of the categories, emotions expressed towards external entities, or oneself are clearly either positive-ENCO or negative-CONF. However, the pattern is different in interpersonal expression between forum contributors. In the medical support environment \u201cnegative\u201d expressions, as previously discussed serve a positive and supportive purpose. Also, the category of GRAT\u2013 a positive expression \u2013 is always in this situation directed to another participant. This makes the interpersonal expression loadings both overloaded both in terms of classification and polarity. These relationships,\nin many ways, make machine modelling therein overly noisy.\nOf course, it is fair to say that one direction of work in such a social domain that we did not explore is context. The original authors report subsequently on incorporating context into their experiments: both in terms of the position within a discussion of a post (Bobicev and Sokolova, 2015) and the posting history of an author (Sokolova and Bobicev, 2015). In this work we have eschewed context, though acknowledge that it is significantly important: in the ENCO-FACT sample above, for example, context may enable a better understanding that the ENCO sentence is in response to another ENCO statement, while the FACT is a response to a direct question. In this sense, there is a clear motivation to understand document-level relationships at the sentence level.\nAnother direction which could be explored is an alternative annotation scheme. Prost (2012) suggests an annotation scheme used to identify the sharing of both practice-based and emotional support among participants of online forums for teachers. This annotation scheme is a combination of schemes developed for social support forums with those created for practice-based (e.g. on-the-job, best practise discussions, or seeking of practical advice) forums. The categories identified, along with sub-categories where defined, are described in Table 9.\nMost of the categories are relevant for both types of forums, support and practice-based. However, the building community category is more relevant for support forums while knowledge sharing and and in particular personal attacks are typically only used for practice forums.\nOf course, in addition to having 15 categories, Prost annotated texts at the sub-sentence level. In order to produce the volumes of data that would be necessary for machine-learning based approaches to understanding support forum, this is impractical. There is clearly a balance to be struck between utility and practicality. However, Prost\u2019s scheme illustrates that in sociological circles, it is important to consider the social context of subjective expressions: there are two categories equivalent to GRAT here, one which is more directed, and the other which concerns a bigger picture expression of the value of community."}, {"heading": "6 Conclusion", "text": "In this work we have argued two positions. Despite seemingly poor results at sentence-level, we are convinced that the examples we have provided demonstrate that document-level analysis is insufficient to accurately capture expressions of sentiment in emotional support forums. We have also shown that there are important social dimensions to this type of domain which should also be taken into account. It is clear that there is considerable value to be gained from automated understanding of this increasing body of data; we in the Social NLP community need to consider some more refined approaches in order to maximise both the value itself and its fidelity."}], "references": [{"title": "A multi-input dependency parser", "author": ["Salah Ait-Mokhtar", "Jean-Pierre Chanod", "Claude Roux."], "venue": "Proceedings of the Seventh International Workshop on Parsing Technologies.", "citeRegEx": "Ait.Mokhtar et al\\.,? 2001", "shortCiteRegEx": "Ait.Mokhtar et al\\.", "year": 2001}, {"title": "Can i hear you? sentiment analysis on medical forums", "author": ["Tanveer Ali", "David Schramm", "Marina Sokolova", "Diana Inkpen."], "venue": "Proceedings of the sixth international joint conference on natural language processing, Asian Federation of Natural Lan-", "citeRegEx": "Ali et al\\.,? 2013", "shortCiteRegEx": "Ali et al\\.", "year": 2013}, {"title": "Rethinking sentiment analysis in the news: from theory to practice and back", "author": ["Alexandra Balahur", "Ralf Steinberger."], "venue": "Proceedings of the 1st Workshop on Opinion Mining and Sentiment Analysis, 2009.", "citeRegEx": "Balahur and Steinberger.,? 2009", "shortCiteRegEx": "Balahur and Steinberger.", "year": 2009}, {"title": "Degree and reciprocity of self-disclosure in online forums", "author": ["Azy Barak", "Orit Gluck-Ofri."], "venue": "Cyberpsychology & Behavior, 10(3):407\u2013417.", "citeRegEx": "Barak and Gluck.Ofri.,? 2007", "shortCiteRegEx": "Barak and Gluck.Ofri.", "year": 2007}, {"title": "No sentiment is an island - sentiment classification on medical forums", "author": ["Victoria Bobicev", "Marina Sokolova."], "venue": "Nathalie Japkowicz and Stan Matwin, editors, Discovery Science - 18th International Conference, DS 2015, Banff, AB, Canada,", "citeRegEx": "Bobicev and Sokolova.,? 2015", "shortCiteRegEx": "Bobicev and Sokolova.", "year": 2015}, {"title": "Identifying the Targets of the Emotions Expressed in Health Forums, pages 85\u201397", "author": ["Sandra Bringay", "Eric Kergosien", "Pierre Pompidor", "Pascal Poncelet"], "venue": null, "citeRegEx": "Bringay et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Bringay et al\\.", "year": 2014}, {"title": "Alt.support: modeling social support online", "author": ["Matthew S. Eastin", "Robert LaRose"], "venue": "Computers in Human Behaviour,", "citeRegEx": "Eastin and LaRose.,? \\Q2005\\E", "shortCiteRegEx": "Eastin and LaRose.", "year": 2005}, {"title": "LIBLINEAR: A library for large linear classification", "author": ["Rong-En Fan", "Kai-Wei Chang", "Cho-Jui Hsieh", "XiangRui Wang", "Chih-Jen Lin."], "venue": "Journal of Machine Learning Research, 9:1871\u20131874.", "citeRegEx": "Fan et al\\.,? 2008", "shortCiteRegEx": "Fan et al\\.", "year": 2008}, {"title": "The truth about lying in online dating profiles", "author": ["Jeffrey T. Hancock", "Catalina Toma", "Nicole Ellison."], "venue": "Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, CHI \u201907, pages 449\u2013452, New York, NY, USA. ACM.", "citeRegEx": "Hancock et al\\.,? 2007", "shortCiteRegEx": "Hancock et al\\.", "year": 2007}, {"title": "Mining and summarizing customer reviews", "author": ["Minqing Hu", "Bing Liu."], "venue": "KDD, pages 168\u2013177.", "citeRegEx": "Hu and Liu.,? 2004", "shortCiteRegEx": "Hu and Liu.", "year": 2004}, {"title": "Extracting opinions, opinion holders, and topics expressed in online news media text", "author": ["Soo-Min Kim", "Eduard Hovy."], "venue": "Proceedings of the Workshop on Sentiment and Subjectivity in Text, SST \u201906, pages 1\u20138, Stroudsburg, PA, USA.", "citeRegEx": "Kim and Hovy.,? 2006", "shortCiteRegEx": "Kim and Hovy.", "year": 2006}, {"title": "Sentiment Analysis and Opinion Mining", "author": ["Bing Liu."], "venue": "Synthesis Lectures on Human Language Technologies. Morgan & Claypool Publishers.", "citeRegEx": "Liu.,? 2012", "shortCiteRegEx": "Liu.", "year": 2012}, {"title": "Sentiment analysis of reviews: Should we analyze writer intentions or reader perceptions", "author": ["Isa Maks", "Piek Vossen"], "venue": "In Proceedings of Recent Advances in Natural Language Processing (RANLP),", "citeRegEx": "Maks and Vossen.,? \\Q2013\\E", "shortCiteRegEx": "Maks and Vossen.", "year": 2013}, {"title": "Personality in its natural habitat: manifestations and implicit folk theories of personality in daily life", "author": ["Matthias R. Mehl", "Samuel D. Gosling", "James W. Pennebaker."], "venue": "Journal of personality and social psychology, 90(5):862\u2013877.", "citeRegEx": "Mehl et al\\.,? 2006", "shortCiteRegEx": "Mehl et al\\.", "year": 2006}, {"title": "Proceedings of the 5th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis, chapter Semantic Role Labeling of Emotions in Tweets", "author": ["Saif Mohammad", "Xiaodan Zhu", "Joel Martin"], "venue": null, "citeRegEx": "Mohammad et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Mohammad et al\\.", "year": 2014}, {"title": "Improving sentiment analysis in an online cancer survivor community using dynamic sentiment lexicon", "author": ["Nir Ofek", "Cornelia Caragea", "Lior Rokach", "Greta E Greer."], "venue": "Social Intelligence and Technology (SOCIETY), 2013 International Conference on,", "citeRegEx": "Ofek et al\\.,? 2013", "shortCiteRegEx": "Ofek et al\\.", "year": 2013}, {"title": "Disclosing and sharing emotion: Psychological, social, and health consequences, pages 517\u2013539", "author": ["James W. Pennebaker", "Emmanuelle Zech", "Bernard Rim"], "venue": null, "citeRegEx": "Pennebaker et al\\.,? \\Q2001\\E", "shortCiteRegEx": "Pennebaker et al\\.", "year": 2001}, {"title": "Patterns of empathy in online communication", "author": ["Ulrike Pfeil", "Panayiotis Zaphiris."], "venue": "Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI07), pages 919\u2013928, San Jose, CA, USA.", "citeRegEx": "Pfeil and Zaphiris.,? 2007", "shortCiteRegEx": "Pfeil and Zaphiris.", "year": 2007}, {"title": "Semeval-2014 task 4: Aspect based sentiment analysis", "author": ["Maria Pontiki", "Dimitrios Galanis", "John Pavlopoulos", "Harris Papageorgiou", "Ion Androutsopoulos", "Suresh Manandhar."], "venue": "International Workshop on Semantic Evaluation (SemEval).", "citeRegEx": "Pontiki et al\\.,? 2014", "shortCiteRegEx": "Pontiki et al\\.", "year": 2014}, {"title": "Semeval-2016 task 5: Aspect based sentiment analysis", "author": ["talia Loukachevitch", "Evgeniy Kotelnikov", "N\u00faria Bel", "Salud Mar\u0131\u0301a Jim\u00e9nez-Zafra", "G\u00fcl\u015fen Eryi\u011fit"], "venue": "In Proceedings of the 10th International Workshop on Semantic Evaluation (SemEval-2016),", "citeRegEx": "Loukachevitch et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Loukachevitch et al\\.", "year": 2016}, {"title": "changes entre professionnels de l\u2019ducation sur les forums de discussion: entre soutien psychologique et acquisition de connaissances sur la pratique", "author": ["Magali Prost."], "venue": "Ph.D. thesis, Telecom ParisTech, Paris, France.", "citeRegEx": "Prost.,? 2012", "shortCiteRegEx": "Prost.", "year": 2012}, {"title": "A metaanalysis of research on formal computer-mediated support groups: Examining group characteristics", "author": ["Stephen A. Rains", "Valerie Young"], "venue": null, "citeRegEx": "Rains and Young.,? \\Q2009\\E", "shortCiteRegEx": "Rains and Young.", "year": 2009}, {"title": "Affective expressions in groups and inferences about members\u2019 relational well-being: The effects of socially engaging and disengaging emotions", "author": ["Naomi B. Rothman", "Joe C. Magee."], "venue": "Cognition & Emotion, Special Issue on Emotions in", "citeRegEx": "Rothman and Magee.,? 2016", "shortCiteRegEx": "Rothman and Magee.", "year": 2016}, {"title": "What sentiments can be found in medical forums", "author": ["Marina Sokolova", "Victoria Bobicev"], "venue": "Recent Advances in Natural Language Processing,", "citeRegEx": "Sokolova and Bobicev.,? \\Q2013\\E", "shortCiteRegEx": "Sokolova and Bobicev.", "year": 2013}, {"title": "Learning relationship between authors\u2019 activity and sentiments: A case study of online medical forums", "author": ["Marina Sokolova", "Victoria Bobicev."], "venue": "Galia Angelova, Kalina Bontcheva, and Ruslan Mitkov, editors, Recent Advances in Natural Lan-", "citeRegEx": "Sokolova and Bobicev.,? 2015", "shortCiteRegEx": "Sokolova and Bobicev.", "year": 2015}, {"title": "Twitter polarity classification with label propagation over lexical links and the follower graph", "author": ["Michael Speriosu", "Nikita Sudan", "Sid Upadhyay", "Jason Baldridge."], "venue": "Proceedings of the First workshop on Unsupervised Learning in NLP, EMNLP", "citeRegEx": "Speriosu et al\\.,? 2011", "shortCiteRegEx": "Speriosu et al\\.", "year": 2011}, {"title": "Semeval2007 task 14: Affective text", "author": ["Carlo Strapparava", "Rada Mihalcea."], "venue": "Proceedings of the 2008 ACM symposium on Applied computing, 2008.", "citeRegEx": "Strapparava and Mihalcea.,? 2007", "shortCiteRegEx": "Strapparava and Mihalcea.", "year": 2007}, {"title": "The process of sharing social support in cyberspace", "author": ["Jennifer G. Tichon", "Margaret Shapiro."], "venue": "Cyberpsychology & Behavior, 6(2):161\u2013170.", "citeRegEx": "Tichon and Shapiro.,? 2003", "shortCiteRegEx": "Tichon and Shapiro.", "year": 2003}, {"title": "Recognizing contextual polarity in phraselevel sentiment analysis", "author": ["Theresa Wilson", "Janyce Wiebe", "Paul Hoffmann."], "venue": "Proc. of HLT-EMNLP2005.", "citeRegEx": "Wilson et al\\.,? 2005", "shortCiteRegEx": "Wilson et al\\.", "year": 2005}], "referenceMentions": [{"referenceID": 8, "context": "In fact, further to merely enabling this affective expressionism, studies have shown that anonymity in online presence increases the chance of sharing more personal information and emotions when compared to face-to-face interactions (Hancock et al., 2007).", "startOffset": 233, "endOffset": 255}, {"referenceID": 5, "context": "such as treatments or hospitals, and provide emotional support to others with similar experiences (Bringay et al., 2014).", "startOffset": 98, "endOffset": 120}, {"referenceID": 16, "context": "This sharing through open discussion is known to be considerably beneficial (Pennebaker et al., 2001).", "startOffset": 76, "endOffset": 101}, {"referenceID": 25, "context": "Sentiment mining on platforms such as Twitter, for example, can be seen as a quick method to gauge public opinion of government policies (Speriosu et al., 2011).", "startOffset": 137, "endOffset": 160}, {"referenceID": 9, "context": "Much sentiment analysis research has focused on classifying the overall sentiment of a document or short text onto a positive-negative spectrum (Hu and Liu, 2004; Kim and Hovy, 2006).", "startOffset": 144, "endOffset": 182}, {"referenceID": 10, "context": "Much sentiment analysis research has focused on classifying the overall sentiment of a document or short text onto a positive-negative spectrum (Hu and Liu, 2004; Kim and Hovy, 2006).", "startOffset": 144, "endOffset": 182}, {"referenceID": 11, "context": "Recently, research work targeting finer grained analysis has emerged, such as aspect-based sentiment analysis (Liu, 2012; Pontiki et al., 2014), or semantic role labelling of emotions (Mohammad et al.", "startOffset": 110, "endOffset": 143}, {"referenceID": 18, "context": "Recently, research work targeting finer grained analysis has emerged, such as aspect-based sentiment analysis (Liu, 2012; Pontiki et al., 2014), or semantic role labelling of emotions (Mohammad et al.", "startOffset": 110, "endOffset": 143}, {"referenceID": 14, "context": ", 2014), or semantic role labelling of emotions (Mohammad et al., 2014).", "startOffset": 48, "endOffset": 71}, {"referenceID": 22, "context": "Even more than this, such affective expression often serve a social purpose (Rothman and Magee, 2016).", "startOffset": 76, "endOffset": 101}, {"referenceID": 25, "context": "One work squarely in the public policy domain sought to classify tweets related to the recent health care reform in the US into positive and negative (Speriosu et al., 2011).", "startOffset": 150, "endOffset": 173}, {"referenceID": 1, "context": "Ali et al. (2013) experimented with data from", "startOffset": 0, "endOffset": 18}, {"referenceID": 28, "context": "They use the subjectivity lexicon of Wilson et al. (2005) and count-based syntactic features", "startOffset": 37, "endOffset": 58}, {"referenceID": 15, "context": "Ofek et al. (2013) use a dynamic sentiment lexicon to improve sentiment analysis in an online community for cancer survivors.", "startOffset": 0, "endOffset": 19}, {"referenceID": 20, "context": "In selecting their data, Sokolova and Bobicev (2013) \u2013 as Ali et al.", "startOffset": 25, "endOffset": 53}, {"referenceID": 1, "context": "In selecting their data, Sokolova and Bobicev (2013) \u2013 as Ali et al. (2013) and others have done \u2013 tapped into the domain of on-line support communities.", "startOffset": 58, "endOffset": 76}, {"referenceID": 1, "context": "In selecting their data, Sokolova and Bobicev (2013) \u2013 as Ali et al. (2013) and others have done \u2013 tapped into the domain of on-line support communities. Eastin and LaRose (2005) showed that people who seek support on-line \u2013 be it emotional or informational support \u2013 typically find it.", "startOffset": 58, "endOffset": 179}, {"referenceID": 1, "context": "In selecting their data, Sokolova and Bobicev (2013) \u2013 as Ali et al. (2013) and others have done \u2013 tapped into the domain of on-line support communities. Eastin and LaRose (2005) showed that people who seek support on-line \u2013 be it emotional or informational support \u2013 typically find it. There are considerable benefits to participating in such groups. In a meta-analysis of 28 studies of healthbased forums, Rains and Young (2009) reported that participants perceive an increase in social support, a significant decrease in depression, and significant increases in both quality of life and selfefficacy in managing their condition.", "startOffset": 58, "endOffset": 431}, {"referenceID": 17, "context": "Pfeil and Zaphiris (2007) identify four components of such communication: understanding, emotions, similarities and concerns.", "startOffset": 0, "endOffset": 26}, {"referenceID": 20, "context": "In addition to direct support, another common dimension of such online groups is selfdisclosure (Prost, 2012).", "startOffset": 96, "endOffset": 109}, {"referenceID": 27, "context": "Self-disclosure serves three social functions (Tichon and Shapiro, 2003): requesting implicit support by showing confusion and worries; providing support by sharing details of a personal experience and sharing information to further develop social relationships.", "startOffset": 46, "endOffset": 72}, {"referenceID": 3, "context": "Barak and Gluck-Ofri (2007) identify self-disclosure as specific to open support groups (e.", "startOffset": 0, "endOffset": 28}, {"referenceID": 4, "context": "The data used here1 is that of Bobicev and Sokolova (2015) \u2013 which is an extension to the data used, and described in more depth, in Sokolova and Bobicev (2013).", "startOffset": 31, "endOffset": 59}, {"referenceID": 4, "context": "The data used here1 is that of Bobicev and Sokolova (2015) \u2013 which is an extension to the data used, and described in more depth, in Sokolova and Bobicev (2013). Data was collected from discussion threads on a sub-forum of an In Vitro Fertilization (IVF) medical forum2 intended for discussion by participants who belong to a specific age-group (over 35s).", "startOffset": 31, "endOffset": 161}, {"referenceID": 26, "context": "There are two approaches to annotation of subjective aspects of communication: from the perspective of a reader\u2019s perception (Strapparava and Mihalcea, 2007) or that of the author (Balahur and Steinberger, 2009).", "startOffset": 125, "endOffset": 157}, {"referenceID": 2, "context": "There are two approaches to annotation of subjective aspects of communication: from the perspective of a reader\u2019s perception (Strapparava and Mihalcea, 2007) or that of the author (Balahur and Steinberger, 2009).", "startOffset": 180, "endOffset": 211}, {"referenceID": 2, "context": "There are two approaches to annotation of subjective aspects of communication: from the perspective of a reader\u2019s perception (Strapparava and Mihalcea, 2007) or that of the author (Balahur and Steinberger, 2009). In labelling MedSenti Sokolova and Bobicev (2013) opted for the readercentric model and hence asked the annotators to analyse a post\u2019s sentiment as if they were other discussion participants.", "startOffset": 181, "endOffset": 263}, {"referenceID": 2, "context": "There are two approaches to annotation of subjective aspects of communication: from the perspective of a reader\u2019s perception (Strapparava and Mihalcea, 2007) or that of the author (Balahur and Steinberger, 2009). In labelling MedSenti Sokolova and Bobicev (2013) opted for the readercentric model and hence asked the annotators to analyse a post\u2019s sentiment as if they were other discussion participants. This is an important differentiation for automated classification style tasks - models are built to predict how people will understand the emotion expressed, as opposed to the emotion or sentiment an author feels they are conveying. For example, Maks and Vossen (2013) showed in review texts that reader assigned scores were more reliably related to the language used than the original rating of the author.", "startOffset": 181, "endOffset": 674}, {"referenceID": 2, "context": "There are two approaches to annotation of subjective aspects of communication: from the perspective of a reader\u2019s perception (Strapparava and Mihalcea, 2007) or that of the author (Balahur and Steinberger, 2009). In labelling MedSenti Sokolova and Bobicev (2013) opted for the readercentric model and hence asked the annotators to analyse a post\u2019s sentiment as if they were other discussion participants. This is an important differentiation for automated classification style tasks - models are built to predict how people will understand the emotion expressed, as opposed to the emotion or sentiment an author feels they are conveying. For example, Maks and Vossen (2013) showed in review texts that reader assigned scores were more reliably related to the language used than the original rating of the author. Similarly, Mehl et al. (2006) showed that ratings of personality perceived by a third party \u201cover-hearing\u201d a conversation was strongly correlated with ground-", "startOffset": 181, "endOffset": 843}, {"referenceID": 27, "context": "CONF here, for example, maps to expressions of confusion (Tichon and Shapiro, 2003) and those of concern (Pfeil and Zaphiris, 2007).", "startOffset": 57, "endOffset": 83}, {"referenceID": 17, "context": "CONF here, for example, maps to expressions of confusion (Tichon and Shapiro, 2003) and those of concern (Pfeil and Zaphiris, 2007).", "startOffset": 105, "endOffset": 131}, {"referenceID": 23, "context": "In addition to the subjective categories, Sokolova and Bobicev (2013) identified two types of objective posts: those with strictly factual information (FACT), and those which combined factual information and short emotional expression (typically of the ENCO type) which were labelled as endorsement (ENDO).", "startOffset": 42, "endOffset": 70}, {"referenceID": 4, "context": "We select document labels as per Bobicev and Sokolova (2015): when two labels match, reduce", "startOffset": 33, "endOffset": 61}, {"referenceID": 4, "context": "73 (Bobicev and Sokolova, 2015).", "startOffset": 3, "endOffset": 31}, {"referenceID": 0, "context": "In this work, we use a robust dependency syntactic parser (Ait-Mokhtar et al., 2001) to extract a wide range of textual features, from word ngrams to more sophisticated linguistic attributes.", "startOffset": 58, "endOffset": 84}, {"referenceID": 7, "context": "Our experiments are framed as multi-class classification tasks using liblinear (Fan et al., 2008) and used 5-fold stratified cross-validation.", "startOffset": 79, "endOffset": 97}, {"referenceID": 23, "context": "fect Lexicon (Sokolova and Bobicev, 2013) and it performed as well as previously reported.", "startOffset": 13, "endOffset": 41}, {"referenceID": 17, "context": "That the expressions of \u201cnegative\u201d emotions such as sympathy be considered in the \u201cpositive\u201d category of ENCO aligns with the social purpose behind such expressions (Pfeil and Zaphiris, 2007).", "startOffset": 165, "endOffset": 191}, {"referenceID": 17, "context": "That the expressions of \u201cnegative\u201d emotions such as sympathy be considered in the \u201cpositive\u201d category of ENCO aligns with the social purpose behind such expressions (Pfeil and Zaphiris, 2007). Without explicitly calling attention to it, Sokolova and Bobicev (2013) encoded social purpose into their annotation scheme.", "startOffset": 166, "endOffset": 265}, {"referenceID": 4, "context": "The original authors report subsequently on incorporating context into their experiments: both in terms of the position within a discussion of a post (Bobicev and Sokolova, 2015) and the posting history of an author (Sokolova and Bobicev, 2015).", "startOffset": 150, "endOffset": 178}, {"referenceID": 24, "context": "The original authors report subsequently on incorporating context into their experiments: both in terms of the position within a discussion of a post (Bobicev and Sokolova, 2015) and the posting history of an author (Sokolova and Bobicev, 2015).", "startOffset": 216, "endOffset": 244}, {"referenceID": 20, "context": "Prost (2012) suggests an annotation scheme used to identify", "startOffset": 0, "endOffset": 13}, {"referenceID": 20, "context": "Table 9: Categories and subcategories from support annotation scheme of Prost (2012)", "startOffset": 72, "endOffset": 85}], "year": 2016, "abstractText": "Understanding expressions of emotions in support forums has considerable value and NLP methods are key to automating this. Many approaches understandably use subjective categories which are more finegrained than a straightforward polaritybased spectrum. However, the definition of such categories is non-trivial and, in fact, we argue for a need to incorporate communicative elements even beyond subjectivity. To support our position, we report experiments on a sentiment-labelled corpus of posts taken from a medical support forum. We argue that not only is a more fine-grained approach to text analysis important, but simultaneously recognising the social function behind affective expressions enable a more accurate and valuable level of understanding.", "creator": null}}}