{"id": "1610.04042", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "13-Oct-2016", "title": "Generalized Online Transfer Learning for Climate Control in Residential Buildings", "abstract": "This paper presents an online transfer learning framework for improving temperature predictions in residential buildings. In transfer learning, prediction models trained under a set of available data from a target domain (e.g. the home and family). A high quality, well-accurate assessment of the temperature data in an appropriate context, along with a high level of detail to determine the most accurate predictors of temperature. The use of statistical methods to assess temperature is consistent with the current empirical understanding of climate change.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "histories": [["v1", "Thu, 13 Oct 2016 11:54:43 GMT  (911kb,D)", "http://arxiv.org/abs/1610.04042v1", null]], "reviews": [], "SUBJECTS": "cs.SY cs.LG", "authors": ["thomas grubinger", "georgios chasparis", "thomas natschlaeger"], "accepted": false, "id": "1610.04042"}, "pdf": {"name": "1610.04042.pdf", "metadata": {"source": "CRF", "title": "Generalized Online Transfer Learning for Climate Control in Residential BuildingsI,II", "authors": ["Thomas Grubingera", "Georgios C. Chasparisa", "Thomas Natschl\u00e4gera"], "emails": ["thomas.grubinger@scch.at", "georgios.chasparis@scch.at", "thomas.natschlaeger@scch.at"], "sections": [{"heading": null, "text": "This paper presents an online transfer learning framework for improving temperature predictions in residential buildings. In transfer learning, prediction models trained under a set of available data from a target domain (e.g., house with limited data) can be improved through the use of data generated from similar source domains (e.g., houses with rich data). Given also the need for prediction models that can be trained online (e.g., as part of a model-predictive-control implementation), this paper introduces the generalized online transfer learning algorithm (GOTL). It employs a weighted combination of the available predictors (i.e., the target and source predictors) and guarantees convergence to the best weighted predictor. Furthermore, the use of Transfer Component Analysis (TCA) allows for using more than a single source domains, since it may facilitate the fit of a single model on more than one source domains (houses). This allows GOTL to transfer knowledge from more than one source domains. We further validate our results through experiments in climate control for residential buildings and show that GOTL may lead to non-negligible energy savings for given comfort levels.\nKeywords: Climate control in buildings, Online transfer learning, Model predictive control\nIThe research reported in this paper has been supported by the Austrian Ministry for Transport, Innovation and Technology, the Federal Ministry of Science, Research and Economy, and the Province of Upper Austria in the frame of the COMET center SCCH.\nIIAn earlier version of part of this paper appeared in [1]. \u2217Corresponding author Email addresses: thomas.grubinger@scch.at (Thomas Grubinger),\ngeorgios.chasparis@scch.at (Georgios C. Chasparis), thomas.natschlaeger@scch.at (Thomas Natschl\u00e4ger)\nPreprint submitted to Energy and Buildings October 14, 2016\nar X\niv :1\n61 0.\n04 04\n2v 1\n[ cs\n.S Y\n] 1\n3 O\nct 2"}, {"heading": "1. Introduction", "text": "Recent studies on climate control (heating/cooling) in residential buildings have demonstrated the importance of accurate system identification and prediction for energy savings [2, 3, 4, 5, 6]. In fact, there have been several efforts on exploiting the benefits of such prediction schemes through the development of model-predictive-control (MPC) approaches [2, 3, 4], where predictions of the temperature evolution, weather conditions and user behavior can be incorporated directly into the control design.\nThe current trend on system identification and prediction in a residential building (target house) exploits measurements collected during normal operation of the heating/cooling system. Several identification schemes have been used to generate predictions, including the MIMO ARMAX model [7], ARX models [8] and the neural network approach [9].\nAlthough linear transfer function models are the most commonly used models for system identification in residential buildings (due to the resulting simplified MPC design), changes in weather conditions and/or the heating patterns may give rise to nonlinear phenomena and consequently to variations in the prediction performance. This observation has been pointed out by several authors, leading to more detailed identification schemes, such as the multiple-time scale analysis presented in [4], the more detailed models of HVAC systems discussed in [10] and the nonlinear regression models developed in [5].\nVariations in the weather conditions and/or heating patterns may always occur throughout the year. The reliability of the (target house\u2019s) prediction model may be improved by incorporating the formulation of data/prediction models from other residential buildings (source houses). To this end, this paper addresses the following question: In what form such a \u201cknowledge transfer\u201d from a source house to a target house should be performed and under which conditions it could be beneficial in terms of the resulting prediction performance?\nSuch knowledge transfer objective is usually encountered in machine learning and it may take alternative forms depending on the application itself. In particular, knowledge transfer can usually be performed within the context of Transfer Learning [11]. Generally, transfer learning aims at transferring knowledge from previous (source) tasks to a target task when the latter has limited training data. Transfer learning has received a lot of attention in recent years and has successfully been used in several applications, such as indoor localization [12], image processing [13], land-mine detection [14] and biological applications [15].\nMost transfer learning approaches can be referred to as offline approaches, since learning is performed offline. However, in the context of climate control in residential buildings, data are usually collected continuously and knowledge transfer needs to be implemented in an online fashion. Thus, it is necessary to develop an online transfer learning methodology that will be particularly appropriate for knowledge transfer between different houses. To the best of our knowledge, only the Online Transfer Learning (OTL) [16] method addresses an online learning case. It uses a weighted prediction of an offline classifier (learned on the source scenario data) and an incrementally updated online classifier on the target scenario data. Weighted predictors are also common in ensemble learning methods [17, 18, 19, 20, 21], however predictors are constructed from a single dataset (thus, they are not directly related to transfer learning). An online algorithm for the case of multitask learning [22] was introduced by Dekel et al. [23]. In contrast to transfer learning, multitask learning addresses the problem of learning different tasks in parallel. Furthermore, Dekel\u2019s method is designed for classification tasks, while climate control requires regression tasks.\nGiven the absence of online transfer learning methodologies that can be directly applied for knowledge transfer for climate control in residential buildings, this paper develops an online transfer learning algorithm that is particularly appropriate for climate control. In particular, we introduce generalized online transfer learning (GOTL) that is based on a weighted combination of: (1) an offline model (linear regression model learned on the source data (with data collected over an extended time horizon), and (2) an online regressor (recursive least squares, cf., [24]) learned on the target house \u2013 which is incrementally updated as new data arrives. The proposed algorithm is related to the OTL algorithm of [16]. However, in [16], the weighted predictor is only eligible for classification, while our framework is applicable for both classification and regression. Furthermore, our online transfer learning scheme guarantees convergence to the globally optimal weights for the predictors.\nThe proposed GOTL algorithm is not limited to the use of a single source house. Clearly, standard machine learning methods cannot be applied directly on the combined data of different source houses, as the different datasets were not necessarily generated by the same process. However, (offline) domain generalization [15] methods can be used to jointly model data from different source domains. In this paper, we use the domain generalization method Transfer Component Analysis (TCA) [25, 14]. TCA and domain generalization methods in general, aim to transform data from different domains into a shared subspace, where the distributions of the domains are\nsimilar. Once transformed, a (linear) regression model can be constructed on the joint source house data.\nOur contributions can be summarized as follows: (1) We propose an online transfer learning methodology (GOTL) that is appropriate for knowledge transfer between residential buildings. To the best of our knowledge, this is the first attempt to address knowledge transfer in this application domain. (2) The proposed algorithm builds upon the online transfer learning methodology of [16] and (a) guarantees convergence to the global optimum combination, (b) it addresses both classification and regression tasks. (3) We demonstrate through experiments that is at least as good as either one of the source house and target house predictor. (4) We show that the domain generalization technique TCA can be used to learn a joint model from several source houses, which proves to be even more beneficial for the target task. (5) We demonstrate that the improvement in predictive accuracy translates into non-negligible energy savings for given comfort levels. This paper extends previous work of the authors [1] by contributions (4) and (5) and provides a more detailed presentation of the already published work.\nIn the remainder of the paper, Section 2 provides the framework and the main objective of this paper. Section 3 describes the proposed online transfer learning methodology (GOTL) from a single source domain. In Section 4, we extend our methodology to the case of multiple source domains through the use of TCA. Section 5 provides a description on the experimental framework and Section 6 demonstrates the experimental results. Finally, Section 7 presents concluding remarks and future work."}, {"heading": "2. Framework & Objective", "text": "In this paper, we are interested in the development of a prediction (inputoutput transfer) model of the heat-mass transfer dynamics in residential buildings, that also exploits data collected from other (not necessarily similar) houses. Such prediction models can be used within an MPC and provide predictions of the indoor temperature over an optimization horizon of interest (e.g., several hours ahead).\nA prediction (input-output transfer) model of the heat-mass transfer dynamics in buildings can be formulated in the following generic form:\ny\u0302t = f(yt\u22121, ..., yt\u2212`,ut\u22121, ...,ut\u2212`), (1)\nwhere y \u2208 R denotes the variable of interest, y\u0302 \u2208 R denotes the estimate of y and u \u2208 R1\u00d7m denotes the control inputs/disturbances. The predictor\nf : R`+`m \u2192 R is a linear or nonlinear prediction model. Under the assumption that measurements are perturbed by a white measurement noise, predictors of the form (1) correspond to the maximum a posteriori predictor (as in the case of the Output-Error regression model [26, Chapter 4]). For example, in the context of climate control in buildings, y corresponds to the indoor temperature that needs to be regulated, while u may include all variables directly or indirectly affecting the indoor temperature, such as the flow of the thermal medium, the inlet/outlet temperatures of the thermal medium, the occupants presence, the outdoor temperature and the solar gain.\nLet us assume that measurements of the inputs and output are collected at regular time instances Ts, 2Ts, ..., briefly denoted by t = 1, 2, ..., where Ts corresponds to the sampling period. Assuming that an MPC is implemented for temperature control, let Thor . = MTs denote our optimization horizon over which predictions are requested for some large M \u2208 N. We denote the time instances at which predictions are requested by tk, k = 1, 2, ... such that tk = kM . Note that tk is a subsequence of the time index t, thus predictions are requested over M, 2M, ... time instances. We will often refer to these time instances as the evaluation/optimization instances.\nTo minimize notation, we briefly denote\nxt . = ( yt\u22121 \u00b7 \u00b7 \u00b7 yt\u2212` ut\u22121 \u00b7 \u00b7 \u00b7 ut\u2212` ) . (2)\nSince we will be concerned with providing predictions at time instances tk, k = 1, 2, ..., we will compactly denote the data available at those time instances by\nXk . =  x0 x1 ...\nxtk  , (3) for all k = 1, 2, ... which correspond to time instances tk.\nIn the remainder of the paper, we will assume that data are available both from a target house, where we wish to minimize the prediction error, and one or more source house(s), denoted by the symbol S. We assume that the input-output variables measured in both the source house(s) and target house are the same. Let XS and Xk be the corresponding feature data available at tk. Since we are concerned with transfer learning, the data set XS is assumed a-priori fixed. However, the forthcoming analysis can be extended in a straightforward manner to the case that this data set also\nvaries with time. We introduce two prediction models: (1) fk(\u00b7) is a prediction model that is trained online at time instances tk, k = 1, 2, ... over the currently available data Xk from the target house. (2) fS(\u00b7) denotes a prediction model that is trained offline over the a-priori available data set XS . In case of a single source house the predictor is taking the form fS(\u00b7) = hS(\u00b7), where hS(\u00b7) is a supervised prediction function. In case of multiple source houses fS(\u00b7) = hS(\u03b8(\u00b7)), where \u03b8(\u00b7) is a domain generalization function, which maps the data from the different houses into a shared subspace. Note that in this case, the source data are XS = XS1\u222aXS2\u222a ...\u222aXSD , where D is the number of source houses. The definition of the domain generalization function and its role will be discussed in detail in the forthcoming Section 4.2.\nThe goal of this paper is the computation of a new (combined) predictor for the target house, evaluated at time instances tk, k = 1, 2, ..., which admits the generic form Fk(\u00b7) = Fk(fk(\u00b7), fS(\u00b7)). We wish to address the following optimization problem:\nmin {Fk} K\u2211 k=1 tk+M\u2211 t=tk+1 \u03b4tk+M\u2212t \u2223\u2223Fk(x\u0302t|k)\u2212 yt\u2223\u22232 , (4)\non the target house, where K is the number of evaluation intervals considered and \u03b4 \u2208 (0, 1] is a discount factor. As in an MPC implementation, the measurements y are only available at the beginning of each evaluation interval k, i.e., at time tk, while the performance of a prediction model Fk has to be evaluated over an optimization horizon of M steps ahead. Thus, an estimate x\u0302t|k of xt is used in the formulation of the predictions, which is defined as\nx\u0302t|k . = ( y\u0303t\u22121|k \u00b7 \u00b7 \u00b7 y\u0303t\u2212`|k u\u0303t\u22121|k \u00b7 \u00b7 \u00b7 u\u0303t\u2212`|k ) ,\nwhere y\u0303t|k . = { yt if t \u2264 tk y\u0302t|k if t > tk.\nHere, y\u0302t|k are generated as y\u0302t|k = Fk(x\u0302t|k), where the prediction at time instance t are given by the prediction function fk(\u00b7), which has been trained using all data up to time instance tk. Regarding the estimates of the control inputs and the exogenous disturbances summarized in u\u0303t|k, we consider perfect estimates, since we would like to investigate the prediction performance of Fk over y. Therefore, we set u\u0303t\u2212j|k = ut\u2212j , j \u2208 {1, ..., l}."}, {"heading": "3. Online Transfer Learning from Single Source Domain", "text": ""}, {"heading": "3.1. Generalized Online Transfer Learning (GOTL)", "text": "Obviously, when addressing an optimization problem of the form (4), the optimal choice of a combined predictor may not be computed a-priori, i.e., before receiving the measurements {yt}tkt=t1 from the target house. Thus, an online optimization scheme is required. Besides, the choice of an optimal predictor may change frequently with time, hence requiring frequent revisions of the combined predictor.\nIn this paper, we propose a transfer learning algorithm that addresses the generic problem formulation of (4) in an online fashion under the structural constraint of the form:\nFk(xt;\u03b1k) . = (1\u2212 \u03b1k)fk(xt) + \u03b1kfS(xt), (5)\nwhere \u03b1k \u2208 A .= {0,\u2206, 2\u2206, ..., 1\u2212\u2206, 1} , is a weight assigned to the source predictor. The constant \u2206 \u2208 (0, 1) is selected so that \u2206 = 1/n for some large n \u2208 N.\nIn other words, we consider combined predictors that can be represented as a weighted sum of the two available predictors (the source predictor trained offline and the target predictor trained online). In this case, the optimization problem (4) can be translated to an optimization problem over {\u03b1k} and takes on the following form:\nmin {\u03b1k} K\u2211 k=1 tk+M\u2211 t=tk+1 \u03b4tk+M\u2212t \u2223\u2223Fk(x\u0302t|k;\u03b1k)\u2212 yt\u2223\u22232 . (6)\nThe proposed algorithm Generalized Online Transfer Learning (GOTL) is motivated by the so-called adaptive learning [27] defined in games and it is based on the notion of better reply. It is described in detail in Table 1.\nIn particular, at the end of every evaluation interval k = 1, 2, ..., the current combined predictor Fk, defined in (5) and employing weight \u03b1k, is evaluated over the updated history of measurements Xk+1, i.e., the measurements collected at the end of the evaluation interval k.\nIts performance with respect to the prediction error is then compared with the corresponding performances when the weight \u03b1k is slightly perturbed. In particular, the performance of the weight \u03b1k is compared with the corresponding performances of the weights selected from the set A(\u03b1k)\ndefined as follows:\nA(\u03b1k) .=  {\u03b1k \u2212\u2206, \u03b1k, \u03b1k + \u2206} if \u2206 < \u03b1k < 1\u2212\u2206 {\u03b1k, \u03b1k + \u2206} if \u03b1k \u2264 \u2206 {\u03b1k \u2212\u2206, \u03b1k} if \u03b1k \u2265 1\u2212\u2206.\nComparison between the alternative weights in the set A is performed with respect to the discounted weighted average squared error, Rk, of the combined predictor, defined as\nRk(\u03b1) . = k\u2211 j=1 tj+M\u2211 t=tj+1 \u03b4tj+M\u2212t \u2223\u2223Fj(x\u0302t|j ;\u03b1)\u2212 yt\u2223\u22232, (7)\nfor some \u03b4 \u2208 (0, 1]. Note that the predictions Fj(x\u0302t|j ;\u03b1) (in the evaluation interval j) are generated using the target predictor fj(\u00b7) which has been\ntrained using data up to time tj , Xj . The predictions of Fj(x\u0302t|j ;\u03b1) are evaluated over the time interval t1, ..., tj+1. Lastly, note that the trained predictor fj(\u00b7) does not depend on \u03b1, which implies that it does not have to be refitted when \u03b1 is updated.\nThe proposed scheme is related to the online transfer learning (OTL) algorithm [16]. In reference [16] the weight update is only applicable for classification problems, while GOTL\u2019s weight update mechanism is more general to accommodate both regression and classification problems."}, {"heading": "3.2. Convergence behavior", "text": "Let us define the set of locally-optimal weights\nA\u2217k . = {\u03b1 \u2208 {0,\u2206, ..., 1\u2212\u2206, 1} : Bk(\u03b1) = \u2205} .\nWe can show that GOTL converges to a weight in A\u2217k, as long as the set A\u2217k changes sufficiently slow with k as the following proposition shows.\nProposition 3.1 (Convergence to Local Minima). For any weight update instance k\u2217, if A\u2217k = A\u2217 6= \u2205 for every k = k\u2217, k\u2217 + 1, ..., k\u2217 + n, then \u03b1k\u2217+n \u2208 A\u2217.\nIn other words, if the set of locally optimal weights does not change within the next n update steps, then the process will reach a weight within this set.\nProof. The proof is a direct implication of the definition of the Bk(\u00b7), since at most n update steps are required for the process to approach a weight \u03b1\u2217 \u2208 A\u2217 starting from any initial weight.\nProposition 3.2 (Unique Minimizer). For any update instance k,1 |A\u2217k| = 1. Furthermore, this is the unique globally optimal weight.\nProof. Let us denote the estimation error functions: ej(t) . = fj(x\u0302t|j) \u2212 yt, and eS,j(t) . = fS(x\u0302t|j) \u2212 yt for the target and the source predictor, respectively, when evaluated over the evaluation interval j = 1, 2, .... Let also Ej{\u00b7} denote the discounted weighted average of the values of a random variable evaluated over the evaluation interval j, i.e., Ej{ej} .= \u2211tj+M t=tj+1\n\u03b4tj+M\u2212t{ej(t)}. Then, the optimization problem min\u03b1\u2208ARk(\u03b1) can equivalently be written\n1For any finite set A, |A| denotes its cardinality.\nas:\nmin \u03b1\u2208A k\u2211 j=1 Ej { |(1\u2212 \u03b1)ej + \u03b1eS,j |2 \u2212 |ej |2 } , (8)\nsince the estimation error of the target predictor, ej(t), is independent of \u03b1. Note further that:\n|(1\u2212 \u03b1)ej + \u03b1eS,j |2 \u2212 |ej |2 = \u03b12e2S,j \u2212 \u03b1(2\u2212 \u03b1)e2j + 2\u03b1(1\u2212 \u03b1)eS,jej .\nThus, the optimization (8) can equivalently be written as:\nmin \u03b1\u2208A\n{ \u03b12 k\u2211 j=1 Ej { e2S,j } \u2212 \u03b1(2\u2212 \u03b1) k\u2211 j=1 Ej { e2j } +\n2\u03b1(1\u2212 \u03b1) k\u2211 j=1 Ej {ejeS,j} } .\nNote that the latter objective function is quadratic with respect to \u03b1 and its second gradient with respect to \u03b1 is nonnegative. This implies that the optimization min\u03b1\u2208ARk(\u03b1) admits a unique minimizer.\nIt is also straightforward to check that under the hypotheses of Proposition 3.1, the weight update approaches the unique minimizer after a finite number of steps."}, {"heading": "3.3. Discussion", "text": "Note that the unique minimizer may change with k, depending on the conditions under which the data have been collected. However, according to Proposition 3.1, it is straightforward to check that as long as A\u2217k changes sufficiently slowly with respect to k, the weight update will always approach the (current) minimizer of (7).\nThe question that naturally emerges is under which conditions such a combined predictor will provide a better estimate compared to the target predictor. Let us use the definition of Ej{\u00b7} in the proof of Proposition 3.2. Note that the optimization problem min\u03b1\u2208ARk(\u03b1) is equivalent to (8), which includes the following expectation:\nEj { |(1\u2212 \u03b1)ej + \u03b1eS,j |2 \u2212 |ej |2 } =\n\u03b12Ej{e2S,j} \u2212 \u03b1(2\u2212 \u03b1)Ej{e2j}+ 2\u03b1(1\u2212 \u03b1)Ej{eS,jej}\nFor the combined predictor to provide smaller prediction error compared to the target predictor, the above quantity has to be strictly negative. If the \u201cproduct bias\u201d is of the same sign, i.e., Ej{eS,jej} \u2265 0, then \u03b1 should be sufficiently close to one for the above quantity to be negative. On the other hand, if Ej{eS,jej} < 0, then an 0 < \u03b1 < 1 may improve the prediction error even when Ej{e2S,j} and Ej{e2j} are of similar size, i.e., even when the source and target predictor perform equally well on the target data."}, {"heading": "4. Online Transfer Learning from Multiple Source Domains", "text": ""}, {"heading": "4.1. Transfer Component Analysis (background)", "text": "Domain generalization [28, 15, 14] addresses mismatches between different input distributions. Across-domain information is extracted from the source domain data (where training data is available) and can be used on the target domains (where no training data is available) without re-training. Transfer Component Analysis (TCA) [25, 14] is a popular domain generalization technique that aims to learn a shared subspace between different domains. In the shared subspace, the data distributions of different domains should be close to each other and task-relevant information of the original data should be preserved. In addition to the distribution matching, TCA preserves the properties of the data.2 Furthermore, any machine learning method for regression, classification or clustering can be used on the identified subspace. Although, in its original version by Pan et al., TCA was introduced for two domains [25], here we utilize an extension to multiple source domains introduced by Grubinger et al. [14].\nConsider the setting where measurements are available from multiple source houses i \u2208 1, . . . , D, denoted by XSi and a target house XT . TCA is applicable if P (XSi) 6= P (XSj ), 1 \u2264 i < j \u2264 D, where P (XSi) is the probability distribution of XSi . The goal of TCA is to find a kernel-induce feature map \u03a8 such that P (\u03a8(XSi)) \u2248 P (\u03a8(XSj )) and P (\u03a8(XSi)) \u2248 P (\u03a8(XT )). Once transformed, the combined source and target data can be used in the subsequent machine learning task. Note though that no data from the target houseXT is available for the construction of \u03a8(\u00b7). The assumption of domain generalization is that the source and target domains are related such that common information can be learned from the source domains and applied to the target domain.\n2This is achieved by maximally preserving the data variance, similarly to Principal Component Analysis (PCA) and Kernel-PCA [29].\nThe goal of matching the probability distributions of the available source domains can be translated into a mathematical program as the following derivation demonstrates.\nLet K be a combined Gram matrix [29] of the cross-domain data of the source domain datasets XS1 \u222a XS2 \u222a ... \u222a XSD . Each element Ki,j of K \u2208 RN\u00d7N is given by \u03c6(xi)T\u03c6(xj), whereN is the total number of instances of the source domain datasets and \u03c6 is a kernel function. Note that, with the employment of a linear kernel function in this works the construction of Ki,j simplifies to \u03c6(xi)T\u03c6(xj) = xTi xj . Let the elements Li,j of L \u2208 RN\u00d7N be defined as\nLi,j =\n{ S\u22121 N2n2s\nif xi,xj \u2208 XSd \u2212 1 N2nsnu if xi \u2208 XSd ,xj \u2208 XSu and d 6= u (9)\nwhere d, u \u2208 {1, ..., D}. With parameter matrixW \u2208 RN\u00d7m,m N and the tradeoff parameter \u00b5 \u2265 0 for the complexity term tr(WTW), the objective of TCA is defined as [25]\nmin W\ntr(WWTKLKW) + \u00b5 tr(WTW), s.t. WTKHKW = I. (10)\nHere, the centering matrix H is defined as H = I \u2212 1N 11T, where 1 \u2208 RN is a column vector with all ones and I \u2208 RN\u00d7N is the identity matrix. tr(WTKLKW) corresponds to the mismatch of distribution by the maximum mean discrepancy (MMD) [30] distance and WTKHKW is the variance of the projected samples. The embedding of the data in the latent space is given by WTK. As shown by Pan et al. [25], the solution of W is given by the m N leading eigenvectors of\n(KLK + \u00b5I)\u22121KHK. (11)\nParameter m is commonly selected by cross validation [25, 14]."}, {"heading": "4.2. GOTL under multiple source domains", "text": "In general, GOTL can be applied to multiple source domains following the same outline as described in Section 3.1. The only difference is the use of fS(\u00b7). For the case of a single source house fS(\u00b7) = hS(\u00b7), where hS(\u00b7) is a supervised prediction function. In case of multiple source domains fS(\u00b7) = hS(\u03b8(\u00b7)), where \u03b8(\u00b7) = WT [\u03c6(\u00b7)T\u03c6(xj)]j\u2208N ."}, {"heading": "5. Experimental Setup", "text": "In this section, we describe the experimental setup with which the proposed GOTL algorithm was tested for climate control in residential buildings."}, {"heading": "5.1. Simulation platform", "text": "We used a standard tool for modeling and simulating residential buildings, namely EnergyPlus (V7-2-0) developed by the U.S. Department of Energy [31]. The Building Controls Virtual Test Bed (BCVTB) simulation tool has also been used for allowing data collection and also climate control developed in MATLAB to be implemented during run-time. A three-storey residential building was modeled and simulated with the EnergyPlus environment to allow for collecting data from a realistic residential environment."}, {"heading": "5.2. Data Generation", "text": "The simulated house is equipped with a radiant heating system which operates under an intermittent operation (i.e., on/off) pattern. We are concerned with the prediction and control of the temperature of a single thermal zone of this house. When evaluating the prediction accuracy of the developed prediction models, the data were generated under a standard hysteresis controller with set temperature equal to 21oC and sampling period Ts = 1/2h (cf., [5, Section 5.2]), thus assuming normal operating conditions. When, instead, the developed (online) prediction model was also used to provide predictions under an MPC formulation, the training data were generated under the currently implemented MPC. The details of these experiments will be discussed in a forthcoming section (Section 6.3).\nIndependently of the data generation process (offline or online), there also exists a natural ventilation system that operates autonomously and with a constant air flow, i.e., there is no heating control through the HVAC system. The following parameters can be measured: the temperature of all thermal zones; the outdoor temperature; the water flow and the inlet water temperature of the radiant heating system; and all exogenous heat sources, namely the solar gain and the occupants presence.\nLastly, it is important to note that for the low-order linear models identified in this paper, the experiments (offline or online) will be informative (cf., [5, Section 5.5]). This is due to the intermittent pattern of both the input and disturbance signals, which result in a sufficient number of distinct frequencies in these signals. In particular, even though the experiments presented in this paper are closed-loop experiments (since the water flow of the radiant heating system depends on the zone temperature), the input signal\nof the water flow is a nonlinear function of both the occupancy pattern as well as the zone temperature. Thus, as explained in detail in [5, Section 5.5], it is sufficient for the occupancy pattern signal to be persistently exciting in order for the experiments to be informative. This is indeed the case in the current experiments, due to the intermittent form of the occupancy pattern."}, {"heading": "5.3. Parameter Setup", "text": "For training of either the source predictor fS(\u00b7) or the target predictor fk(\u00b7) we employ a linear transfer model with an output-error model structure (cf., [26, Section 3]). In particular, the function f of the prediction model (1) is defined as a third-order linear transfer model of the output and input/disturbance variables (i.e., ` = 3). The output variable is the temperature of the thermal zone under investigation, while the input/disturbance variables include the water flow, the inlet water temperature, the neighboring zone temperatures (including the outdoor temperature) and the exogenous heat disturbances. Since we want to evaluate the performance of the combined predictor over the temperature of a thermal zone, perfect estimates are assumed for all inputs and exogenous disturbances.\nThe evaluation interval Thor corresponds to a period of 6h, which is relevant for predictions requested within an MPC implementation. As already mentioned, the sampling period was set to Ts = 1/2h. In the computation of the performance function Rk(\u03b1) defined in (7), we employ a forgetting factor of \u03b4 = 0.995. The better reply function accepts increments of \u2206 = 0.025 in the updates of the weight \u03b1k. For the source predictor, we utilize a linear regression model, while for the online training of the target predictor, we employ a recursive least squares algorithm (cf., [24]) with a forgetting factor of 0.999. Finally, for the case of multiple source houses, (Section 6.2), TCA is applied with a linear kernel. The best number of principal components is selected from n = {5, 10, 15, 20, 25, 30}, using 6-fold cross validation (in every fold 1/3 of one of the training scenarios is used for testing)."}, {"heading": "6. Experiments", "text": ""}, {"heading": "6.1. Knowledge transfer with a single source house", "text": "We demonstrate the performance of GOTL by setting up three experiments. With progressing experiment number, the target house is chosen increasingly different from the source house. Table 2 describes the similarities between the source house and the different target houses. Weather data was collected from Washington, DC, (source house) and Linz, Austria, (target house) from November to March 2009. In experiment 3 the target house\nhas also different presence patterns. Presence patterns differ in the definition of the number of people of certain age and gender, as well as their activities (for more details, see [6]).\nThe results of the experiments of Table 2 are depicted in Figure 1 (Experiment 1), Figure 2 (Experiment 2) and Figure 3 (Experiment 3). Four predictors are evaluated: (i) Source house regressor (fS(\u00b7)), trained on XS ; (ii) Target house regressor (fk(\u00b7)), incrementally trained on Xk; (iii) GOTL; and (iv) Ensemble Predictor : a weighted predictor (5) with a fixed \u03b1 = 0.5, similarly to most ensemble methods. In all figures, we demonstrate an exponentially weighted moving average of the Root Mean Squared Error (RMSE). The lower plot in Figures 1-3 always depicts the weights for the source and target house regressor at each time step tk.\nAt the beginning of the evaluation there is not enough data for the target house regressor to make good predictions. Thus, we set the initial evaluation weight to 1 for the source house regressor and 0 for the target house regressor.3 The data for the target house regressor get richer over time. Consequently, the error of the target house regressor drops and the weight of the target house regressor increases.\nThe observations from all three experiments can be summarized as follows: (i) In the first period \u2013 in which the train house regressor is better than the target house regressor \u2013 GOTL has a similar performance as the train house regressor (approx. 16 weeks in Figure 1, approx. 12 weeks in Figure 2 and only 1-2 weeks in Figure 3). The much shorter time horizon in Figure 1 is not unexpected as the target house is more different (the other houses use the same people presence) than the source house \u2013 compared to the other experiments. The only difference between the Experiment 1 and 2 is the size of the house, which explains the slightly longer time horizon where the train house is better than the source house. (ii) In the second period, the weighted combination is at least as good as the target house regressor alone, or better. Particularly in Experiment 2, GOTL is much better than either the train house regressor or the test house regressor alone. In all experiments, GOTL is also at least as accurate as the simple ensemble predictor."}, {"heading": "6.2. Knowledge transfer with multiple source houses using TCA", "text": "We demonstrate that data from multiple source houses can be combined by the domain generalization method TCA and predictive accuracy can be improved \u2013 compared to the use of only one source house. Moreover, the combined source house predictor can be combined with the target house regressor using GOTL.\nFor our evaluation, we use 2 source houses. Weather data from both source houses originate from Washington, DC. Source house regressor 2 has three times the size of source house regressor 1. The used target house has two times the size of source house regressor 1 and uses weather data from Linz, Austria. All three houses facilitate a different presence pattern.\nThe results are depicted in Figure 4. It can be observed that the combined source house regressor is much better than using either one of the source houses alone. One reason for the good source house performance is that the\n3Note that the coefficients for the source house regressor and the target house regressor correspond to \u03b1 and (1\u2212 \u03b1) in Section 3, respectively.\n.\nsource houses are selected, such that the target house size is just in between the sizes of two source houses. GOTL performance is comparable to the combined source house regressor in the first 5 weeks and better than all other regressors afterwards."}, {"heading": "6.3. MPC experiments", "text": "In the previous experiments, we evaluated the prediction performance of the GOTL algorithm when data were generated under a standard hysteresis controller. In those experiments, the prediction models derived were not used in the controller design process, since the objective was primarily the evaluation of the prediction accuracy. In this section, instead, we wish to evaluate the performance of the introduced online transfer learning methodology when employed within an MPC formulation for climate control, i.e., when the prediction models are directly used in the control design. Questions related to whether the derived prediction models may reduce the energy consumption naturally emerge.\nTo this end, we designed a standard MPC for the radiant-heating system of the main living area of the residential building. The goal is to evaluate the performance of the GOTL algorithm with respect to the energy consumption\nand compare it with the case that such online transfer models are not available. The structure of the MPC employed is rather simple and addresses the following optimization problem\nmin \u03ba Nhor\u2211 t=0 { p\u0302(t) ( T\u0302r(t)\u2212 Tset(t) )2 /Nhor } +\nNhor\u22121\u2211 t=0 { \u03b2Ts ( T+w (t)\u2212 T\u0302\u2212w (t) )) + \u03b3TsV\u0307w(t) } (12a)\nvar. T+w (t) \u2208 {45oC}, (12b) V\u0307w(t) \u2208 {0, V\u0307w,max}, (12c) t = 0, 1, 2, ..., Nhor \u2212 1,\nwhere T\u0302r is the temperature prediction of the room provided by the available prediction model (e.g., the GOTL model), Tset is the desired/set temperature, T+w is the inlet water temperature of the radiant heating system, T\u0302\u2212w is a prediction of the outlet water temperature, and V\u0307w is the water flow.\nNote that the first part of the objective function (12a) corresponds to a comfort measure scaled with a positive constant \u03ba. It measures the average squared difference of the room temperature from the desired (or set) temperature entered by the user at time k. The set temperature was set equal to 21oC throughout the optimization horizon. The variable p\u0302 \u2208 {0, 1} is a boolean variable that corresponds to our estimate on whether people are present in the room at time instance t.\nThe second part of the objective function (12a) corresponds to the heating cost, while the third part corresponds to the pump-electricity cost. The nonnegative parameters \u03b2, \u03b3 were previously identified for the heating system of the simulated house and take values: \u03b2 = 0.3333kW/oCh, \u03b3 = 0.5278 \u00b7 103kWsec/hm3. The non-negative constant \u03ba is introduced to allow for adjusting the importance of the comfort cost compared to the energy cost.\nThe p\u0302(t), t = 1, 2, ..., Nhor, as well as the rest of the disturbances (such as the outdoor temperature and the solar gain) are assumed given (i.e., predicted with perfect accuracy). This assumption is essential in order to evaluate precisely the impact of our prediction model T\u0302r in the performance of the derived optimal controller. In fact, we should expect that an accurate prediction of the room temperature will also lead to an efficient controller with respect to the energy consumption.\nThe sampling period was set to Ts = 1/2h, the optimization period was set to Topt = 1h, and the evaluation/optimization horizon was set to Thor = 6h.\nThis implies that Nhor = 6 \u00b7 2 = 12. Furthermore, the control variables are the inlet water temperature which assumes a single value (45oC) and the water flow which assumes only two values, the zero flow and the maximum one, V\u0307w,max = 0.0787kg/sec.\nIn Figure 5, we have generated the comfort-heating cost curve for the available prediction models under varying \u03ba (i.e., under different weights on the comfort cost of the objective function (12a)). The reason for generating such performance curves is the fact that the performance of any two controllers with respect to energy efficiency may only be compared under the same comfort-cost level. Of course, a controller that achieves lower heating costs under the same comfort cost will be more efficient. Experiments were conducted over a five-month period under Experiment 3 of Table 2. The prediction model of the target house was trained online with the data generated under the MPC implementation, using the recursive least squares of Section 5.3. The weights \u03b1 of the GOTL predictor were also updated online according to the online algorithm of Table 1.\nAs we observe in Figure 5, the heating costs under the GOTL predictor are lower than any other prediction model. Under high comfort costs, i.e., when comfort is not of high priority, the energy consumption is very close to the energy consumption of the train model. On the other hand, under low comfort costs, i.e., when comfort is a priority, the energy consumption of the GOTL predictor is about 100 kWh lower compared to the trained predictor (over the five-month period), which is a non-negligible amount of energy. It is also important to note that the performance of the test predictor with respect to the energy consumption is rather poor for these first five months. This verifies our claim over the utility of online transfer learning methodologies for climate control in residential buildings.\n."}, {"heading": "7. Conclusions & Future Work", "text": "We presented the online transfer learning framework GOTL, which is applicable for classification and regression tasks and allows to optimally combine an (offline) source domain predictor with an online target domain predictor. The results demonstrated the utility of the combined predictor to significantly improve prediction accuracy in the first weeks and months of a new building \u2013 compared to either using the source house predictor or target house predictor alone. Further improvements in predictive accuracy can be achieved by facilitating multiple source houses and TCA. Improvements in predictive accuracy also translate into non-negligible energy savings for given comfort levels.\nIt is also important to note the adaptive response of the proposed online transfer learning algorithm. Although the above experiments were evaluated over a period of five winter months, training of an online regressor over longer periods of time may be challenging. This is primarily due to changes either in the weather conditions or in the heating patterns. In such variations, degradations in the prediction error of a target predictor will be significantly reduced by considering the GOTL algorithm, as can easily be seen from the behavior of GOTL during the first few weeks in all the considered experiments."}, {"heading": "8. Bibliography", "text": ""}], "references": [{"title": "Online transfer learning for climate control in residential buildings", "author": ["T. Grubinger", "G.C. Chasparis", "T. Natschl\u00e4ger"], "venue": "in: Proceedings of the 5th Annual European Control Conference ", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2016}, {"title": "Receding-horizon supervisory control of green buildings", "author": ["T. Nghiem", "G. Pappas"], "venue": "in: Proc. of the 2011 American Control Conference, San Francisco, CA, USA", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2011}, {"title": "Use of model predictive control and weather forecasts for energy efficient building climate control", "author": ["F. Oldewurtel", "A. Parisio", "C. Jones", "M. Morari", "D. Gyalistras", "M. Gwerder", "V. Stauch", "B. Lehmann", "M. Morari"], "venue": "Energy and Buildings 45 ", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2012}, {"title": "Model reduction and nonlinear MPC for energy management in buildings", "author": ["C. Touretzky", "M. Baldea"], "venue": "in: Proc. of 2013 American Control Conference (ACC), Washington DC, USA", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2013}, {"title": "Realistic user behavior modeling for energy saving in residential buildings", "author": ["J. Martinez-Gil", "G. Chasparis", "B. Freudenthaler", "T. Natschlaeger"], "venue": "in: 2014 25th International Workshop on Database and Expert Systems Applications (DEXA)", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2014}, {"title": "Multiple ARMAX modeling scheme for forecasting air conditioning system performance", "author": ["J.-M. Yiu", "S. Wang"], "venue": "Energy Conversion and Management 48 ", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2007}, {"title": "Thermal building model identification using time-scaled identification models", "author": ["P. Malisani", "F. Chaplais", "N. Petit", "D. Feldmann"], "venue": "in: Proc. of 49th IEEE Conference on Decision and Control, Atlanta, GA, USA", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2010}, {"title": "Prediction of room temperature and relative humidity by autoregressive linear and nonlinear neural network models for an open office", "author": ["G. Mustafaraj", "G. Lowry", "J. Chen"], "venue": "Energy and Buildings 43 ", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2011}, {"title": "Physics-based modeling and identification for HVAC systems", "author": ["F. Scotton", "L. Huang", "S. Ahmadi", "B. Wahlberg"], "venue": "in: Proc. of 2013 European Control Conference (ECC), Zurich, Switzerland", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2013}, {"title": "A survey on transfer learning", "author": ["S.J. Pan", "Q. Yang"], "venue": "IEEE Trans. on Knowledge and Data Engineering 22 (10) ", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2010}, {"title": "Transfer learning for wifi-based indoor localization", "author": ["S.J. Pan", "V.W. Zheng", "Q. Yang", "D.H. Hu"], "venue": "Proc. of the Workshop on Transfer Learning for Complex Tasks, of the 23rd AAAI Conference on Artificial Intelligence ", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2008}, {"title": "Using deep belief nets to learn covariance kernels for gaussian processes", "author": ["G.E. Hinton", "R. Salakhutdinov"], "venue": "in: Neural Information Processing Systems (NIPS)", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2007}, {"title": "Domain generalization based on transfer component analysis", "author": ["T. Grubinger", "A. Birlutiu", "H. Sch\u00f6ner", "T. Natschl\u00e4ger", "T. Heskes"], "venue": "in: Advances in Computational Intelligence: IWANN 2015, Palma de Mallorca, Spain, June 10-12, 2015. Proceedings, Part I, Springer", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2015}, {"title": "Domain generalization via invariant feature representation", "author": ["K. Muandet", "D. Balduzzi", "B. Sch\u00f6lkopf"], "venue": "in: International Conference on Machine Learning (ICML)", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2013}, {"title": "Online transfer learning", "author": ["P. Zhao", "S.C. Hoi", "J. Wang", "B. Li"], "venue": "Artificial Intelligence 216 ", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2014}, {"title": "Ensemble methods in machine learning", "author": ["T.G. Dietterich"], "venue": "in: Multiple Classifier Systems, Springer", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2000}, {"title": "Online ensemble learning: An empirical study", "author": ["A. Fern", "R. Givan"], "venue": "Machine Learning 53 (1-2) ", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2003}, {"title": "The application of adaboost for distributed", "author": ["W. Fan", "S.J. Stolfo", "J. Zhang"], "venue": "scalable and on-line learning, in: Proc. of the 5th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, ACM", "citeRegEx": "19", "shortCiteRegEx": null, "year": 1999}, {"title": "Learning quickly when irrelevant attributes abound: A new linear-threshold algorithm", "author": ["N. Littlestone"], "venue": "Machine learning 2 (4) ", "citeRegEx": "20", "shortCiteRegEx": null, "year": 1988}, {"title": "The weighted majority algorithm", "author": ["N. Littlestone", "M.K. Warmuth"], "venue": "Information and computation 108 (2) ", "citeRegEx": "21", "shortCiteRegEx": null, "year": 1994}, {"title": "Multi-task feature learning", "author": ["A. A", "T. Evgeniou", "M. Pontil"], "venue": "Advances in Neural Information Processing Systems", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2007}, {"title": "Fundamentals of Adaptive Filtering", "author": ["A. Sayed"], "venue": "John Wiley & Sons, Inc., New Jersey", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2003}, {"title": "Domain adaptation via transfer component analysis", "author": ["S.J. Pan", "I. Tsang", "J. Kwok", "Q. Yang"], "venue": "IEEE Trans. on Neural Networks 22 (2) ", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2011}, {"title": "System Identification: Theory for the User", "author": ["L. Ljung"], "venue": "2nd Edition, Prentice Hall Ptr, Upper Saddle River, NJ", "citeRegEx": "26", "shortCiteRegEx": null, "year": 1999}, {"title": "The evolution of conventions", "author": ["H. Young"], "venue": "Econometrica 61 (1) ", "citeRegEx": "27", "shortCiteRegEx": null, "year": 1993}, {"title": "Generalizing from several related classification tasks to a new unlabeled sample", "author": ["G. Blanchard", "G. Lee", "C. Scott"], "venue": "in: Neural Processing Letters (NIPS)", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2011}, {"title": "K", "author": ["B. Sch\u00f6lkopf", "A. Smola"], "venue": "M\u00fcller, Kernel principal component analysis ", "citeRegEx": "29", "shortCiteRegEx": null, "year": 1999}, {"title": "A kernel method for the two-sample-problem", "author": ["A. Gretton", "K. Borgwardt", "M. Rasch", "B. Sch\u00f6lkopf", "A. Smola"], "venue": "in: Neural Information Processing Systems (NIPS)", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2006}], "referenceMentions": [{"referenceID": 0, "context": "An earlier version of part of this paper appeared in [1].", "startOffset": 53, "endOffset": 56}, {"referenceID": 1, "context": "Recent studies on climate control (heating/cooling) in residential buildings have demonstrated the importance of accurate system identification and prediction for energy savings [2, 3, 4, 5, 6].", "startOffset": 178, "endOffset": 193}, {"referenceID": 2, "context": "Recent studies on climate control (heating/cooling) in residential buildings have demonstrated the importance of accurate system identification and prediction for energy savings [2, 3, 4, 5, 6].", "startOffset": 178, "endOffset": 193}, {"referenceID": 3, "context": "Recent studies on climate control (heating/cooling) in residential buildings have demonstrated the importance of accurate system identification and prediction for energy savings [2, 3, 4, 5, 6].", "startOffset": 178, "endOffset": 193}, {"referenceID": 4, "context": "Recent studies on climate control (heating/cooling) in residential buildings have demonstrated the importance of accurate system identification and prediction for energy savings [2, 3, 4, 5, 6].", "startOffset": 178, "endOffset": 193}, {"referenceID": 1, "context": "In fact, there have been several efforts on exploiting the benefits of such prediction schemes through the development of model-predictive-control (MPC) approaches [2, 3, 4], where predictions of the temperature evolution, weather conditions and user behavior can be incorporated directly into the control design.", "startOffset": 164, "endOffset": 173}, {"referenceID": 2, "context": "In fact, there have been several efforts on exploiting the benefits of such prediction schemes through the development of model-predictive-control (MPC) approaches [2, 3, 4], where predictions of the temperature evolution, weather conditions and user behavior can be incorporated directly into the control design.", "startOffset": 164, "endOffset": 173}, {"referenceID": 3, "context": "In fact, there have been several efforts on exploiting the benefits of such prediction schemes through the development of model-predictive-control (MPC) approaches [2, 3, 4], where predictions of the temperature evolution, weather conditions and user behavior can be incorporated directly into the control design.", "startOffset": 164, "endOffset": 173}, {"referenceID": 5, "context": "Several identification schemes have been used to generate predictions, including the MIMO ARMAX model [7], ARX models [8] and the neural network approach [9].", "startOffset": 102, "endOffset": 105}, {"referenceID": 6, "context": "Several identification schemes have been used to generate predictions, including the MIMO ARMAX model [7], ARX models [8] and the neural network approach [9].", "startOffset": 118, "endOffset": 121}, {"referenceID": 7, "context": "Several identification schemes have been used to generate predictions, including the MIMO ARMAX model [7], ARX models [8] and the neural network approach [9].", "startOffset": 154, "endOffset": 157}, {"referenceID": 3, "context": "This observation has been pointed out by several authors, leading to more detailed identification schemes, such as the multiple-time scale analysis presented in [4], the more detailed models of HVAC systems discussed in [10] and the nonlinear regression models developed in [5].", "startOffset": 161, "endOffset": 164}, {"referenceID": 8, "context": "This observation has been pointed out by several authors, leading to more detailed identification schemes, such as the multiple-time scale analysis presented in [4], the more detailed models of HVAC systems discussed in [10] and the nonlinear regression models developed in [5].", "startOffset": 220, "endOffset": 224}, {"referenceID": 9, "context": "In particular, knowledge transfer can usually be performed within the context of Transfer Learning [11].", "startOffset": 99, "endOffset": 103}, {"referenceID": 10, "context": "Transfer learning has received a lot of attention in recent years and has successfully been used in several applications, such as indoor localization [12], image processing [13], land-mine detection [14] and biological applications [15].", "startOffset": 150, "endOffset": 154}, {"referenceID": 11, "context": "Transfer learning has received a lot of attention in recent years and has successfully been used in several applications, such as indoor localization [12], image processing [13], land-mine detection [14] and biological applications [15].", "startOffset": 173, "endOffset": 177}, {"referenceID": 12, "context": "Transfer learning has received a lot of attention in recent years and has successfully been used in several applications, such as indoor localization [12], image processing [13], land-mine detection [14] and biological applications [15].", "startOffset": 199, "endOffset": 203}, {"referenceID": 13, "context": "Transfer learning has received a lot of attention in recent years and has successfully been used in several applications, such as indoor localization [12], image processing [13], land-mine detection [14] and biological applications [15].", "startOffset": 232, "endOffset": 236}, {"referenceID": 14, "context": "To the best of our knowledge, only the Online Transfer Learning (OTL) [16] method addresses an online learning case.", "startOffset": 70, "endOffset": 74}, {"referenceID": 15, "context": "Weighted predictors are also common in ensemble learning methods [17, 18, 19, 20, 21], however predictors are constructed from a single dataset (thus, they are not directly related to transfer learning).", "startOffset": 65, "endOffset": 85}, {"referenceID": 16, "context": "Weighted predictors are also common in ensemble learning methods [17, 18, 19, 20, 21], however predictors are constructed from a single dataset (thus, they are not directly related to transfer learning).", "startOffset": 65, "endOffset": 85}, {"referenceID": 17, "context": "Weighted predictors are also common in ensemble learning methods [17, 18, 19, 20, 21], however predictors are constructed from a single dataset (thus, they are not directly related to transfer learning).", "startOffset": 65, "endOffset": 85}, {"referenceID": 18, "context": "Weighted predictors are also common in ensemble learning methods [17, 18, 19, 20, 21], however predictors are constructed from a single dataset (thus, they are not directly related to transfer learning).", "startOffset": 65, "endOffset": 85}, {"referenceID": 19, "context": "Weighted predictors are also common in ensemble learning methods [17, 18, 19, 20, 21], however predictors are constructed from a single dataset (thus, they are not directly related to transfer learning).", "startOffset": 65, "endOffset": 85}, {"referenceID": 20, "context": "An online algorithm for the case of multitask learning [22] was introduced by Dekel et al.", "startOffset": 55, "endOffset": 59}, {"referenceID": 21, "context": ", [24]) learned on the target house \u2013 which is incrementally updated as new data arrives.", "startOffset": 2, "endOffset": 6}, {"referenceID": 14, "context": "The proposed algorithm is related to the OTL algorithm of [16].", "startOffset": 58, "endOffset": 62}, {"referenceID": 14, "context": "However, in [16], the weighted predictor is only eligible for classification, while our framework is applicable for both classification and regression.", "startOffset": 12, "endOffset": 16}, {"referenceID": 13, "context": "However, (offline) domain generalization [15] methods can be used to jointly model data from different source domains.", "startOffset": 41, "endOffset": 45}, {"referenceID": 22, "context": "In this paper, we use the domain generalization method Transfer Component Analysis (TCA) [25, 14].", "startOffset": 89, "endOffset": 97}, {"referenceID": 12, "context": "In this paper, we use the domain generalization method Transfer Component Analysis (TCA) [25, 14].", "startOffset": 89, "endOffset": 97}, {"referenceID": 14, "context": "(2) The proposed algorithm builds upon the online transfer learning methodology of [16] and (a) guarantees convergence to the global optimum combination, (b) it addresses both classification and regression tasks.", "startOffset": 83, "endOffset": 87}, {"referenceID": 0, "context": "This paper extends previous work of the authors [1] by contributions (4) and (5) and provides a more detailed presentation of the already published work.", "startOffset": 48, "endOffset": 51}, {"referenceID": 24, "context": "The proposed algorithm Generalized Online Transfer Learning (GOTL) is motivated by the so-called adaptive learning [27] defined in games and it is based on the notion of better reply.", "startOffset": 115, "endOffset": 119}, {"referenceID": 14, "context": "The proposed scheme is related to the online transfer learning (OTL) algorithm [16].", "startOffset": 79, "endOffset": 83}, {"referenceID": 14, "context": "In reference [16] the weight update is only applicable for classification problems, while GOTL\u2019s weight update mechanism is more general to accommodate both regression and classification problems.", "startOffset": 13, "endOffset": 17}, {"referenceID": 25, "context": "Transfer Component Analysis (background) Domain generalization [28, 15, 14] addresses mismatches between different input distributions.", "startOffset": 63, "endOffset": 75}, {"referenceID": 13, "context": "Transfer Component Analysis (background) Domain generalization [28, 15, 14] addresses mismatches between different input distributions.", "startOffset": 63, "endOffset": 75}, {"referenceID": 12, "context": "Transfer Component Analysis (background) Domain generalization [28, 15, 14] addresses mismatches between different input distributions.", "startOffset": 63, "endOffset": 75}, {"referenceID": 22, "context": "Transfer Component Analysis (TCA) [25, 14] is a popular domain generalization technique that aims to learn a shared subspace between different domains.", "startOffset": 34, "endOffset": 42}, {"referenceID": 12, "context": "Transfer Component Analysis (TCA) [25, 14] is a popular domain generalization technique that aims to learn a shared subspace between different domains.", "startOffset": 34, "endOffset": 42}, {"referenceID": 22, "context": ", TCA was introduced for two domains [25], here we utilize an extension to multiple source domains introduced by Grubinger et al.", "startOffset": 37, "endOffset": 41}, {"referenceID": 12, "context": "[14].", "startOffset": 0, "endOffset": 4}, {"referenceID": 26, "context": "This is achieved by maximally preserving the data variance, similarly to Principal Component Analysis (PCA) and Kernel-PCA [29].", "startOffset": 123, "endOffset": 127}, {"referenceID": 26, "context": "Let K be a combined Gram matrix [29] of the cross-domain data of the source domain datasets XS1 \u222a XS2 \u222a .", "startOffset": 32, "endOffset": 36}, {"referenceID": 22, "context": "With parameter matrixW \u2208 RN\u00d7m,m N and the tradeoff parameter \u03bc \u2265 0 for the complexity term tr(WTW), the objective of TCA is defined as [25]", "startOffset": 135, "endOffset": 139}, {"referenceID": 27, "context": "tr(WTKLKW) corresponds to the mismatch of distribution by the maximum mean discrepancy (MMD) [30] distance and WTKHKW is the variance of the projected samples.", "startOffset": 93, "endOffset": 97}, {"referenceID": 22, "context": "[25], the solution of W is given by the m N leading eigenvectors of", "startOffset": 0, "endOffset": 4}, {"referenceID": 22, "context": "Parameter m is commonly selected by cross validation [25, 14].", "startOffset": 53, "endOffset": 61}, {"referenceID": 12, "context": "Parameter m is commonly selected by cross validation [25, 14].", "startOffset": 53, "endOffset": 61}, {"referenceID": 21, "context": ", [24]) with a forgetting factor of 0.", "startOffset": 2, "endOffset": 6}, {"referenceID": 4, "context": "Presence patterns differ in the definition of the number of people of certain age and gender, as well as their activities (for more details, see [6]).", "startOffset": 145, "endOffset": 148}], "year": 2016, "abstractText": "This paper presents an online transfer learning framework for improving temperature predictions in residential buildings. In transfer learning, prediction models trained under a set of available data from a target domain (e.g., house with limited data) can be improved through the use of data generated from similar source domains (e.g., houses with rich data). Given also the need for prediction models that can be trained online (e.g., as part of a model-predictive-control implementation), this paper introduces the generalized online transfer learning algorithm (GOTL). It employs a weighted combination of the available predictors (i.e., the target and source predictors) and guarantees convergence to the best weighted predictor. Furthermore, the use of Transfer Component Analysis (TCA) allows for using more than a single source domains, since it may facilitate the fit of a single model on more than one source domains (houses). This allows GOTL to transfer knowledge from more than one source domains. We further validate our results through experiments in climate control for residential buildings and show that GOTL may lead to non-negligible energy savings for given comfort levels.", "creator": "LaTeX with hyperref package"}}}