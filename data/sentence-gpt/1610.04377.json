{"id": "1610.04377", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "14-Oct-2016", "title": "Civique: Using Social Media to Detect Urban Emergencies", "abstract": "We present the Civique system for emergency detection in urban areas by monitoring micro blogs like Tweets. The system detects emergency related events, and classifies them into appropriate categories like \"fire\", \"accident\", \"earthquake\", etc. We demonstrate our ideas by classifying Twitter posts in real time, visualizing the ongoing event on a map interface and alerting users with options to contact relevant authorities, both online and offline.\n\n\n\n\nThe first step in understanding how we deploy the Civique system has a set of features, namely:\n1) We will only report incidents in cases where there are reported incidents and reporting cases without incident.\n2) We will also investigate incidents of violent incidents where violence or aggression is at fault.\n3) We will also have an integrated dashboard with help for users to keep track of possible incidents in their daily lives.\n4) The second step in understanding the various technologies that have been developed with the Civique system (including data analytics) is to make use of the social media platform as an analytics tool for social media, with the help of an integrated social media platform.\nThe third step in understanding the various technologies that have been developed with the Civique system (including data analytics) is to make use of the social media platform as an analytics tool for social media, with the help of an integrated social media platform. We will also analyze social media content on social media platforms by using a social media platform which is connected with a network of social media platforms by using the social media platform, or by using the social media platform for social media.\nThe first step in understanding the various technologies that have been developed with the Civique system (including data analytics) is to make use of the social media platform as an analytics tool for social media, with the help of an integrated social media platform. We will also investigate social media content on social media platforms by using a social media platform which is connected with a network of social media platforms by using the social media platform, or by using the social media platform for social media. We will also analyse social media content on social media platforms by using a social media platform which is connected with a network of social media platforms by using the social media platform, or by using the social media platform for social media. We will also analyse social media content on social media platforms by using a social media platform which is connected with a network of social media platforms by using the social media platform, or by using the social media platform for social media.\nWe will", "histories": [["v1", "Fri, 14 Oct 2016 09:06:36 GMT  (1228kb,D)", "http://arxiv.org/abs/1610.04377v1", "This paper was presented at Workshop on Social Data Analytics and Management (SoDAM 2016), at Very Large Databases (VLDB 2016), in September 2016"]], "COMMENTS": "This paper was presented at Workshop on Social Data Analytics and Management (SoDAM 2016), at Very Large Databases (VLDB 2016), in September 2016", "reviews": [], "SUBJECTS": "cs.CL cs.CY cs.SI", "authors": ["diptesh kanojia", "vishwajeet kumar", "krithi ramamritham"], "accepted": false, "id": "1610.04377"}, "pdf": {"name": "1610.04377.pdf", "metadata": {"source": "CRF", "title": "Civique: Using Social Media to Detect Urban Emergencies", "authors": ["Diptesh Kanojia", "Vishwajeet Kumar", "Krithi Ramamritham"], "emails": ["diptesh@cse.iitb.ac.in", "vishwajeet@cse.iitb.ac.in", "krithi@cse.iitb.ac.in"], "sections": [{"heading": null, "text": "Keywords: Social Media, Event Detection, Data Analysis, Emergency Detection, Urban Emergency, Twitter"}, {"heading": "1 Introduction", "text": "With the surge in the use of social media, micro-blogging sites like Twitter4, Facebook5, and Foursquare6 have become household words. Growing ubiquity of mobile phones in highly populated developing nations has spurred an exponential rise in social media usage. The heavy volume of social media posts tagged with users\u2019 location information on micro-blogging website Twitter presents a unique opportunity to scan these posts. These Short texts (e.g. \u201dtweets\u201d) on social media contain information about various events happening around the globe, as people post about events and incidents alike. Conventional web outlets provide emergency phone numbers (i.e. 100, 911), etc., and are fast and accurate. Our system, on the other hand, connects its users through a relatively newer platform i.e. social media, and provides an alternative to these conventional methods. In\n? These two authors contributed equally 4 http://www.twitter.com 5 http://www.facebook.com 6 http://foursquare.com\nar X\niv :1\n61 0.\n04 37\n7v 1\n[ cs\n.C L\n] 1\n4 O\ncase of their failure or when such means are busy/occupied, an alternative could prove to be life saving.\nThese real life events are reported on Twitter with different perspectives, opinions, and sentiment. Every day, people discuss events thousands of times across social media sites. We would like to detect such events in case of an emergency. Some previous studies[10] investigate the use of features such as keywords in the tweet, number of words, and context to devise a classifier for event detection. [4] discusses various techniques researchers have used previously to detect events from Twitter. [9] describe a system to automatically detect events about known entities from Twitter. This work is highly specific to detection of events only related to known entities. [2] discuss a system that returns a ranked list of relevant events given a user query.\nSeveral research efforts have focused on identifying events in real time([5][7] [1][10]). These include systems to detect emergent topics from Twitter in real time ([5] [3]), an online clustering technique for identifying tweets in real time [7], a system to detect localized events and also track evolution of such events over a period of time [1]. Our focus is on detecting urban emergencies as events from Twitter messages. We classify events ranging from natural disasters to fire break outs, and accidents. Our system detects whether a tweet, which contains a keyword from a pre-decided list, is related to an actual emergency or not. It also classifies the event into its appropriate category, and visualizes the possible location of the emergency event on the map. We also support notifications to our users, containing the contacts of specifically concerned authorities, as per the category of their tweet.\nThe rest of the paper is as follows: Section 2 provides the motivation for our work, and the challenges in building such a system. Section 3 describes the step by step details of our work, and its results. We evaluate our system and present the results in Section 4. Section 5 showcases our demonstrations in detail, and Section 6 concludes the paper by briefly describing the overall contribution, implementation and demonstration."}, {"heading": "2 Motivation and Challenges", "text": "In 2015, 53% of all unnatural deaths in India were caused by accidents, and 6% by accidental fires7. Moreover, the Indian subcontinent suffered seven earthquakes in 2015, with the recent Nepal earthquake alone killing more than 9000 people and injuring 23, 0008. We believe we can harness the current social media activity on the web to minimize losses by quickly connecting affected people and the concerned authorities. Our work is motivated by the following factors, (a) Social media is very accessible in the current scenario. (The \u201cDigital India\u201d initiative by the Government of India promotes internet activity, and thus a pro-active social\n7 http://www.indiaspend.com/cover-story/fire-accidents-kill-54-every-day-yetdeaths-have-declined-81400 8 https://en.wikipedia.org/wiki/April 2015 Nepal earthquake\nmedia.) (b) As per the Internet trends reported in 20149, about 117 million Indians are connected to the Internet through mobile devices. (c) A system such as ours can point out or visualize the affected areas precisely and help inform the authorities in a timely fashion. (d) Such a system can be used on a global scale to reduce the effect of natural calamities and prevent loss of life.\nThere are several challenges in building such an application: (a) Such a system expects a tweet to be location tagged. Otherwise, event detection techniques to extract the spatio-temporal data from the tweet can be vague, and lead to false alarms. (b) Such a system should also be able to verify the user\u2019s credibility as pranksters may raise false alarms. (c) Tweets are usually written in a very informal language, which requires a sophisticated language processing component to sanitize the tweet input before event detection. (d) A channel with the concerned authorities should be established for them to take serious action, on alarms raised by such a system. (e) An urban emergency such as a natural disaster could affect communications severely, in case of an earthquake or a cyclone, communications channels like Internet connectivity may get disrupted easily. In such cases, our system may not be of help, as it requires the user to be connected to the internet. We address the above challenges and present our approach in the next section."}, {"heading": "3 Our Approach", "text": "We propose a software architecture for Emergency detection and visualization as shown in figure 1. We collect data using Twitter API10, and perform language pre-processing before applying a classification model. Tweets are labelled manually with <emergency>and <non-emergency>labels, and later classified manually to provide labels according to the type of emergency they indicate. We use the manually labeled data for training our classifiers.\nWe use traditional classification techniques such as Support Vector Machines(SVM), and Naive Bayes(NB) for training, and perform 10-fold cross validation to obtain f-scores. Later, in real time, our system uses the Twitter streaming APIs to get data, pre-processes it using the same modules, and detects emergencies using the classifiers built above. The tweets related to emergencies are displayed on the web interface along with the location and information for the concerned authorities. The pre-processing of Twitter data obtained is needed as it usually contains ad-hoc abbreviations, phonetic substitutions, URLs, hashtags, and a lot of misspelled words. We use the following language processing modules for such corrections."}, {"heading": "3.1 Pre-Processing Modules", "text": "We implement a cleaning module to automate the cleaning of tweets obtained from the Twitter API. We remove URLs, special symbols like @ along with the user mentions, Hashtags and any associated text. We also replace special symbols by blank spaces, and inculcate the module as shown in figure 1.\nAn example of such a sample tweet cleaning is shown in table 1. While tweeting, users often express their emotions by stressing over a few characters in the word. For example, usage of words like hellpppp, fiiiiiireeee, ruuuuunnnnn, druuuuuunnnkkk, soooooooo actually corresponds to help, fire, run, drunk, so etc. We use the compression module implemented by [8] for converting terms like \u201cpleeeeeeeaaaaaassseeee\u201d to \u201cplease\u201d.\nIt is unlikely for an English word to contain the same character consecutively for three or more times. We, hence, compress all the repeated windows of character length greater than two, to two characters. For example \u201cpleeeeeaaaassee\u201d is converted to \u201cpleeaassee\u201d. Each window now contains two characters of the same alphabet in cases of repetition. Let n be the number of windows, obtained from the previous step. We, then, apply brute force search over 2n possibilities to select a valid dictionary word.\nTable 2 contains sanitized sample output from our compression module for further processing.\nText Normalization is the process of translating ad-hoc abbreviations, typographical errors, phonetic substitution and ungrammatical structures used in\n9 \u201cInternet trends 2014 report\u201d by Mary Meeker, Kleiner Perkins Caufield & Byers (KPCB)\n10 https://dev.twitter.com/overview/documentation\ntext messaging (Tweets and SMS) to plain English. Use of such language (often referred as Chatting Language) induces noise which poses additional processing challenges.\nWe use the normalization module implemented by [8] for text normalization. Training process requires a Language Model of the target language and a parallel corpora containing aligned un-normalized and normalized word pairs. Our language model consists of 15000 English words taken from various sources on the web.\nParallel corpora was collected from the following sources:\n1. Stanford Normalization Corpora which consists of 9122 pairs of un-normalized and normalized words / phrases. 2. The above corpora, however, lacked acronyms and short hand texts like 2mrw, l8r, b4, hlp, flor which are frequently used in chatting. We collected 215 pairs un-normalized to normalized word/phrase mappings via crowdsourcing.\nTable 3 contains input and normalized output from our module. Users often make spelling mistakes while tweeting. A spell checker makes sure that a valid English word is sent to the classification system. We take this problem into account by introducing a spell checker as a pre-processing module by using the JAVA API of Jazzy spell checker11 for handling spelling mistakes.\nAn example of correction provided by the Spell Checker module is given below:-\nInput: building 4th flor, help Output: building 4th floor, help\nPlease note that, our current system performs compression, normalization and spell-checking if the language used is English. The classifier training and detection process are described below."}, {"heading": "3.2 Emergency Classification", "text": "The first classifier model acts as a filter for the second stage of classification. We use both SVM and NB to compare the results and choose SVM later for stage\n11 http://sourceforge.net/projects/jazzy/\none classification model, owing to a better F-score. The training is performed on tweets labeled with classes \u00a1emergency\u00bf, and \u00a1non-emergency\u00bf based on unigrams as features. We create word vectors of strings in the tweet using a filter available in the WEKA API[6], and perform cross validation using standard classification techniques."}, {"heading": "3.3 Type Classification", "text": "We employ a multi-class Naive Bayes classifier as the second stage classification mechanism, for categorizing tweets appropriately, depending on the type of emergencies they indicate. This multi-class classifier is trained on data manually labeled with classes. We tokenize the training data using \u201cNgramTokenizer\u201d and then, apply a filter to create word vectors of strings before training. We use \u201ctrigrams\u201d as features to build a model which, later, classifies tweets into appropriate categories, in real time. We then perform cross validation using standard techniques to calculate the results, which are shown under the label \u201cStage 2\u201d, in table 4."}, {"heading": "3.4 Location Visualizer", "text": "We use Google Maps Geocoding API12 to display the possible location of the tweet origin based on longitude and latitude. Our visualizer presents the user with a map and pinpoints the location with custom icons for earthquake, cyclone, fire accident etc. Since we currently collect tweets with a location filter for the city of \u201dMumbai\u201d, we display its map location on the interface. The possible occurrences of such incidents are displayed on the map as soon as our system is able to detect it.\nWe also display the same on an Android device using the WebView functionality available to developers, thus solving the issue of portability. Our system displays visualization of the various emergencies detected on both web browsers and mobile devices."}, {"heading": "4 Evaluation", "text": "We evaluate our system using automated, and manual evaluation techniques. We perform 10-fold cross validation to obtain the F-scores for our classification systems. We use the following technique for dataset creation. We test the system\n12 https://developers.google.com/maps/documentation/geocoding\nin realtime environments, and tweet about fires at random locations in our city, using test accounts. Our system was able to detect such tweets and detect them with locations shown on the map."}, {"heading": "4.1 Dataset Creation", "text": "We collect data by using the Twitter API for saved data, available for public use. For our experiments we collect 3200 tweets filtered by keywords like \u201cfire\u201d, \u201cearthquake\u201d, \u201ctheft\u201d, \u201crobbery\u201d, \u201cdrunk driving\u201d, \u201cdrunk driving accident\u201d etc. Later, we manually label tweets with <emergency>and <non-emergency>labels for classification as stage one. Our dataset contains 1313 tweet with positive label <emergency>and 1887 tweets with a negative label <non-emergency>. We create another dataset with the positively labeled tweets and provide them with category labels like \u201cfire\u201d, \u201caccident\u201d, \u201cearthquake\u201d etc."}, {"heading": "4.2 Classifier Evaluation", "text": "The results of 10-fold cross-validation performed for stage one are shown in table 4, under the label \u201cStage 1\u201d. In table 4, For \u201cStage 1\u201d of classification, F-score obtained using SVM classifier is 72.5% as shown in row 2, column 2. We also provide the system with sample tweets in real time and assess its ability to detect the emergency, and classify it accordingly. The classification training for Stage 1 was performed using two traditional classification techniques SVM and NB. SVM outperformed NB by around 4% and became the choice of classification technique for stage one.\nSome false positives obtained during manual evaluation are, \u201cI am sooooo so drunk right nowwwwwwww\u201d and \u201cfire in my office , the boss is angry\u201d. These occurrences show the need of more labeled gold data for our classifiers, and some other features, like Part-of-Speech tags, Named Entity recognition, Bigrams, Trigrams etc. to perform better.\nThe results of 10-fold cross-validation performed for stage two classfication model are also shown in table 4, under the label \u201cStage 2\u201d. The training for\nstage two was also performed using both SVM and NB, but NB outperformed SVM by around 1% to become a choice for stage two classification model.\nWe also perform attribute evaluation for the classification model, and create a word cloud based on the output values, shown in figure 2. It shows that our classifier model is trained on appropriate words, which are very close to the emergency situations viz. \u201cfire\u201d, \u201cearthquake\u201d, \u201caccident\u201d, \u201cbreak\u201d (Unigram representation here, but possibly occurs in a bigram phrase with \u201cfire\u201d) etc. In figure 2, the word cloud represents the word \u201crespond\u201d as the most frequently occurring word as people need urgent help, and quick response from the assistance teams."}, {"heading": "5 Demostration Description", "text": "Users interact with Civique through its Web-based user interface and Android based application interface. The features underlying Civique are demonstrated through the following two show cases:\nShow case 1: Tweet Detection and Classification This showcase aims at detecting related tweets, and classifying them into appropriate categories. For this, we have created a list of filter words, which are used to filter tweets from the Twitter streaming API. These set of words help us filter the tweets related to any incident. We will tweet, and users are able to see how our system captures such tweets and classifies them. Users should be able to see the tweet emerge as an incident on the web-interface, as shown in figure 3 and the on the android application, as shown in figure 4. Figure 5 demonstrates how a notification is generated when our system detects an emergency tweet. When a user clicks the emerged spot, the system should be able to display the sanitized version / extracted spatio-temporal data from the tweet. We test the system in a realtime environment, and validate our experiments. We also report\nthe false positives generated during the process in section 4.2 above.\nShow case 2: User Notification and Contact Info. Civique includes a set of local contacts for civic authorities who are to be / who can be contacted in case of various emergencies. Users can see how Civique detects an emergency and classifies it. They can also watch how the system generates a notification on the web interface and the Android interface, requesting them to contact the authorities for emergencies. Users can change their preferences on the mobile device anytime and can also opt not to receive notifications. Users should be able to contact the authorities online using the application, but in case the online contact is not responsive, or in case of a sudden loss of connectivity, we provide the user with the offline contact information of the concerned civic authorities along with the notifications."}, {"heading": "6 Conclusions", "text": "Civique is a system which detects urban emergencies like earthquakes, cyclones, fire break out, accidents etc. and visualizes them on both on a browsable web interface and an Android application. We collect data from the popular microblogging site Twitter and use language processing modules to sanitize the input. We use this data as input to train a two step classification system, which indicates whether a tweet is related to an emergency or not, and if it is, then what category of emergency it belongs to. We display such positively classified tweets along with their type and location on a Google map, and notify our users to inform the concerned authorities, and possibly evacuate the area, if his location matches\nthe affected area. We believe such a system can help the disaster management machinery, and government bodies like Fire department, Police department, etc., to act swiftly, thus minimizing the loss of life.\nTwitter users use slang, profanity, misspellings and neologisms. We, use standard cleaning methods, and combine NLP with Machine Learning (ML) to further our cause of tweet classification. At the current stage, we also have an Android application ready for our system, which shows the improvised, mobileviewable web interface.\nIn the future, we aim to develop detection of emergency categories on the fly, obscure emergencies like \u201cairplane hijacking\u201d should also be detected by our system. We plan to analyze the temporal sequence of the tweet set from a single location to determine whether multiple problems on the same location are the result of a single event, or relate to multiple events."}], "references": [{"title": "EvenTweet: online localized event detection from twitter", "author": ["H. Abdelhaq", "C. Sengstock", "M. Gertz"], "venue": null, "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2013}, {"title": "Keyword search on microblog data streams:finding contextual messages in real time", "author": ["M.K. Agarwal", "D. Bansal", "M. Garg", "K. Ramamritham1"], "venue": "Proceedings of 19th International Conference on Extending Database Technology (EDBT). pp. 15\u201318", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2016}, {"title": "Enblogue: emergent topic detection in web 2.0 streams", "author": ["F. Alvanaki", "M. Sebastian", "K. Ramamritham", "G. Weikum"], "venue": "Proceedings of the 2011 ACM SIGMOD International Conference on Management of data", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2011}, {"title": "Emerging topic detection on twitter based on temporal and social terms evaluation", "author": ["M. Cataldi", "L.D. caro", "C. schifanella"], "venue": "Proceedings of the Tenth International Workshop on Multimedia Data Mining", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2010}, {"title": "The weka data mining software: an update", "author": ["M. Hall", "E. Frank", "G. Holmes", "B. Pfahringer", "P. Reutemann", "I.H. Witten"], "venue": "ACM SIGKDD explorations newsletter 11(1), 10\u201318", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2009}, {"title": "Beyond Trending Topics: Real-World Event Identification on Twitter", "author": ["B. Hila", "N. Mor", "G. Luis"], "venue": null, "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2011}, {"title": "Transchat: Cross-lingual instant messaging for indian languages", "author": ["D. Kanojia", "S. Dhuliawala", "N. Gupta", "A. Mishra", "P. Bhattarcharyya"], "venue": "Twelth International Conference on Natural Language Processing. ICON", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2015}, {"title": "Extracting events and event descriptions from twitter", "author": ["A.M. Popescu", "M. Pennacchiotti", "D. Paranjpe"], "venue": "Proceedings of the 20th international conference companion on World wide web", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2011}, {"title": "Earthquake shakes Twitter users: realtime event detection by social sensors", "author": ["T. Sakaki", "M. Okazaki", "Y. Matsuo"], "venue": null, "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2010}], "referenceMentions": [{"referenceID": 8, "context": "Some previous studies[10] investigate the use of features such as keywords in the tweet, number of words, and context to devise a classifier for event detection.", "startOffset": 21, "endOffset": 25}, {"referenceID": 7, "context": "[9] describe a system to automatically detect events about known entities from Twitter.", "startOffset": 0, "endOffset": 3}, {"referenceID": 1, "context": "[2] discuss a system that returns a ranked list of relevant events given a user query.", "startOffset": 0, "endOffset": 3}, {"referenceID": 3, "context": "Several research efforts have focused on identifying events in real time([5][7] [1][10]).", "startOffset": 73, "endOffset": 76}, {"referenceID": 5, "context": "Several research efforts have focused on identifying events in real time([5][7] [1][10]).", "startOffset": 76, "endOffset": 79}, {"referenceID": 0, "context": "Several research efforts have focused on identifying events in real time([5][7] [1][10]).", "startOffset": 80, "endOffset": 83}, {"referenceID": 8, "context": "Several research efforts have focused on identifying events in real time([5][7] [1][10]).", "startOffset": 83, "endOffset": 87}, {"referenceID": 3, "context": "These include systems to detect emergent topics from Twitter in real time ([5] [3]), an online clustering technique for identifying tweets in real time [7], a system to detect localized events and also track evolution of such events over a period of time [1].", "startOffset": 75, "endOffset": 78}, {"referenceID": 2, "context": "These include systems to detect emergent topics from Twitter in real time ([5] [3]), an online clustering technique for identifying tweets in real time [7], a system to detect localized events and also track evolution of such events over a period of time [1].", "startOffset": 79, "endOffset": 82}, {"referenceID": 5, "context": "These include systems to detect emergent topics from Twitter in real time ([5] [3]), an online clustering technique for identifying tweets in real time [7], a system to detect localized events and also track evolution of such events over a period of time [1].", "startOffset": 152, "endOffset": 155}, {"referenceID": 0, "context": "These include systems to detect emergent topics from Twitter in real time ([5] [3]), an online clustering technique for identifying tweets in real time [7], a system to detect localized events and also track evolution of such events over a period of time [1].", "startOffset": 255, "endOffset": 258}, {"referenceID": 6, "context": "We use the compression module implemented by [8] for converting terms like \u201cpleeeeeeeaaaaaassseeee\u201d to \u201cplease\u201d.", "startOffset": 45, "endOffset": 48}, {"referenceID": 6, "context": "We use the normalization module implemented by [8] for text normalization.", "startOffset": 47, "endOffset": 50}, {"referenceID": 4, "context": "We create word vectors of strings in the tweet using a filter available in the WEKA API[6], and perform cross validation using standard classification techniques.", "startOffset": 87, "endOffset": 90}], "year": 2016, "abstractText": "We present the Civique system for emergency detection in urban areas by monitoring micro blogs like Tweets. The system detects emergency related events, and classifies them into appropriate categories like \u201cfire\u201d, \u201caccident\u201d, \u201cearthquake\u201d, etc. We demonstrate our ideas by classifying Twitter posts in real time, visualizing the ongoing event on a map interface and alerting users with options to contact relevant authorities, both online and offline. We evaluate our classifiers for both the steps, i.e., emergency detection and categorization, and obtain F-scores exceeding 70% and 90%, respectively. We demonstrate Civique using a web interface and on an Android application, in realtime, and show its use for both tweet detection and visualization.", "creator": "LaTeX with hyperref package"}}}