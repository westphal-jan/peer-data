{"id": "1610.06053", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "19-Oct-2016", "title": "Chinese Restaurant Process for cognate clustering: A threshold free approach", "abstract": "In this paper, we introduce a threshold free approach, motivated from Chinese Restaurant Process, for the purpose of cognate clustering. We show that our approach yields similar results to a linguistically motivated cognate clustering system known as LexStat. Our Chinese Restaurant Process system is fast and does not require any threshold and can be applied to any language family of the world. To test this hypothesis, we first built a cross-language LexStat system. We show that this method offers some advantages as well. It has a better than standard-of-view for the Chinese Restaurant Process and it does not require any threshold, but also can provide the appropriate level of autonomy in the manner of a system that has a maximum possible maximum possible of 10,000 words. This gives a high level of flexibility, and allows us to focus on a new process that is a lot more powerful than a typical linguistic system. It has high speed and good execution, and this is the first step towards demonstrating that LexStat is very powerful.", "histories": [["v1", "Wed, 19 Oct 2016 15:09:21 GMT  (19kb)", "http://arxiv.org/abs/1610.06053v1", null]], "reviews": [], "SUBJECTS": "cs.CL", "authors": ["taraka rama"], "accepted": false, "id": "1610.06053"}, "pdf": {"name": "1610.06053.pdf", "metadata": {"source": "CRF", "title": null, "authors": [], "emails": ["taraka-rama.kasicheyanula@uni-tuebingen.de"], "sections": [{"heading": null, "text": "ar X\niv :1\n61 0.\n06 05\n3v 1\n[ cs\n.C L\n] 1\n9 O\nct 2\n01 6"}, {"heading": "1 Introduction", "text": "Identification of cognates is an important task while establishing genetic relations between languages that are hypothesized to have descended from a single language in the past. For instance, English hound and German Hund are cognates which can be traced back to Proto-Germanic stage. Highly accurate automatic identification of cognates is desired for reducing the effort required in analyzing large language families such as Indo-European (Bouckaert et al., 2012) and Austronesian (Greenhill and Gray, 2009) can take up decades of effort, when performed by hand. A automatic cognate identification system can be helpful for historical linguists to analyze supposedly related language families and also fasten up the making of cognate databases which can be then be analyzed using Bayesian phylogenetic methods (Atkinson and Gray, 2006).\nIn this paper, we work with Swadesh word lists of multiple language groups and attempt to cluster related words together using a nonparametric process known as Chinese Restaurant Process (Gershman and Blei, 2012). We use the sound similarity matrix trained in an unsupervised fashion (Ja\u0308ger, 2013) for the purpose of computing similarity between two words. The CRP based algorithm is similar to the CRP variant of the K-means algorithm introduced by\nKulis and Jordan (2011). Our CRP algorithm does not require any threshold and only has a single hyperparameter known as \u03b1 which allows new clusters to be formed without the requirement of threshold or the number of clusters to be known beforehand.\nPrevious work by List et al. (2016) and Hauer and Kondrak (2011) employ a hand crafted or a machine learned word similarity measure to compute pair-wise distances between words. The pair-wise distance matrix is then supplied to a clustering algorithm such as average linkage clustering (Manning and Schu\u0308tze, 1999) for inferring a tree structure of the words. The average linkage clustering algorithm is an agglomerative algorithm that merges individual clusters until a single cluster is left. The clustering process can be interrupted if the average similarity between two clusters falls below a predetermined threshold.\nThe agglomerative algorithm is simple and usually yields reasonable results across various language families (List, 2012). However, the method suffers from a major drawback that the threshold needs to be known beforehand for achieving high accuracy. In a recent paper, List et al. (2016) use a clustering algorithm known as InfoMap for the purpose of clustering cognates in Sino-Tibetan language groups. The InfoMap algorithm also requires a threshold for finding cognates. The authors find that the algorithm works well if the threshold is adjusted across language groups. In this paper, we compare our system against the LexStat system and show that our system yields comparable results.\nThe structure of the paper is as followed. We define the cognate clustering problem in section 2. In section 3, we describe the string alignment algorithm for the purpose of computing similarity between two strings. We describe our CRP algorithm in section 4. We describe the evaluation of our experiments and datasets in section 5. We present\nthe results of our experiments and discuss them in section 6. We conclude the paper in section 7."}, {"heading": "2 Cognate clustering", "text": "The phylogenetic inference methods require cognate judgments which are only available for a small number of well-studied language families such as Indo-European and Austronesian. For instance, the ASJP database (Brown et al., 2013)1 provides Swadesh word lists (of 40 length that are supposedly important for identifying genetic relationships between languages) transcribed in a uniform format for more than 60% of the world\u2019s languages.2 An example of such a word list is given below:\nThe task at hand is to automatically cluster words according to genealogical relationship. This is achieved by computing similarities between all the word pairs belonging to a meaning and then supplying the resulting distance matrix as an input to a clustering algorithm. The clustering algorithm groups the words into clusters by optimizing a similarity criterion. The similarity between a word pair can be computed using supervised approaches (Hauer and Kondrak, 2011) or by using sequence alignment algorithms such as Needleman-Wunsch (Needleman and Wunsch, 1970) or Levenshtein distance (Levenshtein, 1966). An example of a pairwise distance matrix for meaning \u201call\u201d is shown in table 2."}, {"heading": "3 Sequence alignment", "text": "The Needleman-Wunsch algorithm is the similarity counterpart of the Levenshtein distance. The Needleman-Wunsch algorithm maximizes similarity whereas Levenshtein distance minimizes the\n1asjp.clld.org 2However, the cognacy judgments are only available for a\nsubset of language families.\ndistance. In the Needleman-Wunsch algorithm, a character or sound segment match increases the similarity by 1 and a character mismatch has a weight of \u22121. In contrast to Levenshtein distance which treats insertion, deletion, and substitution equally, the Needleman-Wunsch algorithm introduces a gap opening (deletion operation) penalty parameter that has to be learned separately. A second parameter known as gap extension penalty has lesser penalty than the gap opening parameter and models the fact that deletions occur in chunks (Ja\u0308ger, 2013).\nThe (vanilla) Needleman-Wunsch algorithm is not sensitive to segment pairs and a realistic algorithm should assign high similarity between sound correspondences such as /s/ \u223c /h/ than the sound pair /p/ \u223c /r/.\nIn dialectology (Wieling and Nerbonne, 2015), similarity between two segments is estimated using PMI. The PMI score of two sounds i and j is defined as followed:\nPMI(i, j) = log( p(i, j)\nq(i) \u00b7 q(j) ) (1)\nwhere, p(i, j) is the relative frequency of i, j occurring at the same position in th aligned word pairs whereas, q(.) is the relative frequency of a sound in the whole word list. A positive PMI value indicates that a segment pair cooccurs together whereas, a negative PMI value indicates lack of cooccurrence. This can be interpreted as a strength of relatedness between two segments.\nIn this paper, we use the PMI matrix (of ASJP sound segments) inferred by Ja\u0308ger (2013) for computing the similarity between a word pair. Ja\u0308ger (2013) shows that the PMI matrix shows positive weights for sound pairs such as /p/ \u223c /b/, /t/ \u223c /d/, and /s/ \u223c /h/."}, {"heading": "4 CRP", "text": "In this section, we describe the CRP algorithm and motivate its suitability for cognate clustering.\nGiven a meaning M and the word similarity matrix S of dimensions N \u00d7 N , the CRP algorithm works as follows. The CRP outputs K clusters and the clustering l1, . . . lK .\n1. Initially, assign a word wn to ln where K = N .\n2. Repeat until convergence:\n\u2022 For each word wn: \u2013 Remove wn from its cluster. \u2013 Compute snk the average similarity\nof wn to all words in cluster k. \u2013 If argmax\nk\nsnk < \u03b1 assign wn to a\nnew cluster. \u2013 Else, assign wn to the cluster k\nwhere k = argmax k snk.\nThe current algorithm uses the criterion of average similarity to assign a word to a cluster. A word is assigned to the cluster with which it exhibits the highest average similarity. The intuition behind this decision is that the word should, on an average, be similar to the rest of the words in a cluster. 3\nThe magnitude of the \u03b1 parameter determines the number of new clusters. A value of 0.01 is sufficient for the purpose of forming new clusters. The word similarity is always non-negative and we use a ReLU transformation (max(0, x)) that transforms negative similarity scores to 0. The CRP algorithm identifies cognate clusters of uneven sizes and can also form singleton clusters due to the simple initialization. In our experiments, we find that three full scans of the data are sufficient for the algorithm to reach a local maximum."}, {"heading": "5 Experiments", "text": "Baseline We use a vanilla Needleman-Wunsch with a gap opening penalty of \u22121 and a gap extension penalty of \u22120.5 as the baseline in our experiments.\nLexStat LexStat (List, 2012) is a system offering state-of-the-art alignment algorithms for aligning word pairs and clustering them into cognate sets. The LexStat system weighs matches between sounds using a handcrafted segment similarity matrix that is informed by historical linguistic literature.\n3The average similarity criterion can be modified to the maximum similarity criterion. This is commonly known as single linkage clustering (Manning and Schu\u0308tze, 1999)."}, {"heading": "5.1 Evaluation", "text": "We evaluate the results of clustering analysis using B-cubed F-score (Amigo\u0301 et al., 2009). The Bcubed scores are defined for each individual item as followed. The precision for an item is defined as the ratio between the number of cognates in its cluster to the total number of items in its cluster. The recall for an item is defined as the ratio between the number of cognates in its cluster to the total number of expert labeled cognates. The Bcubed precision and recall are defined as the average of the items\u2019 precision and recall across all the clusters. Finally, the B-cubed F-score for a meaning, is computed as the harmonic mean of the average items\u2019 precision and recall. The B-cubed Fscore for the whole dataset is given as the average of the B-cubed F-scores across all the meanings.\nBoth Hauer and Kondrak (2011) and List et al. (2016) use B-cubed F-scores to test their cognate clustering systems."}, {"heading": "5.2 Datasets", "text": "IELex database The Indo-European Lexical database was created by Dyen et al. (1992) and curated by Michael Dunn. The IELex database is not transcribed in uniform IPA and retains many forms transcribed in the Romanized IPA format of Dyen et al. (1992). We cleaned the IELex database of any non-IPA-like transcriptions and converted the cleaned subset of the database into ASJP format. The cleaned subset has 52 languages and 210 meanings.\nAustronesian vocabulary database The Austronesian Vocabulary Database (ABVD) (Greenhill and Gray, 2009) has word lists for 210 Swadesh concepts and 378 languages.4 The database does not have transcriptions in a uniform IPA format. We removed all symbols that do not appear in the standard IPA and converted the lexical items to ASJP format. For comparison purpose, we use randomly selected 100 languages\u2019 dataset in this paper.5\nShort word lists with cognacy judgments Wichmann and Holman (2013) and List (2014) compiled cognacy wordlists for subsets of families from various scholarly sources such as comparative handbooks and historical linguistics\u2019 articles. The details of this compilation is given below. For\n4http://language.psy.auckland.ac.nz/austronesian/ 5LexStat takes many hours to run on a dataset of 100 lan-\nguages.\neach dataset, we give the number of languages/the number of meanings in parantheses.\n\u2022 Wichmann and Holman (2013): Afrasian (21/40), Mayan (30/100), Mixe-Zoque (10/100), Mon-Khmer (16/100). \u2022 List (2014): ObUgrian (21/110; Hungarian excluded from Ugric sub-family)."}, {"heading": "6 Results", "text": "The B-cubed F-scores of different systems are shown in table 3. The CRP based PMI system performs better than LexStat on four datasets. The CRP algorithm performs slightly worse than the LexStat system on Austronesian and IndoEuropean language families by two points. The LexStat performs better than the PMI-CRP system only on the Ugric languages dataset. The LexStat system\u2019s clustering threshold has been tuned on many smaller datasets whereas, the PMI-CRP does not require any tuning of the threshold and comes closer or performs better than the LexStat system. We also provide the average of Bcubed F-scores across different datasets. The results show that the PMI-CRP system is close to the performance of the LexStat system."}, {"heading": "6.1 Match between predicted and obtained clusters", "text": "We examine the match between the number of predicted clusters and the number of true clusters for the PMI-CRP system across meanings. We report the correlations in table 4. The correlations suggest that the number of predicted clusters correlate highly with the true number of clusters across datasets."}, {"heading": "6.2 Error analysis", "text": "In the case of Indo-European, the PMI-CRP system fails to group all the reflexes for the meaning\n\u201cfive\u201d, \u201cfingernail\u201d, \u201cthree\u201d, \u201ctwo\u201d, and \u201cname\u201d into a single cognate cluster. The reason for this behaviour is the extensive phonological change that affected cognates across the daughter subgroups. The LexStat system also shows similar behaviour when the true number of cognate clusters is 1."}, {"heading": "7 Conclusion", "text": "In this paper, we introduced a CRP based clustering algorithm that is threshold free. The program takes less than two minutes for clustering a large dataset of 100 languages such as Austronesian. We tested the algorithm on a wide range of language families and showed the algorithm yields close or better results than LexStat. Based on the results, we claim that the algorithm can be useful for the comparative linguists to analyze putative language relations at a quick pace.\nThe main limitation of the algorithm is that it fails to retrieve clusters for meanings such as \u201cwhat\u201d, \u201cwho\u201d, and \u201cwe\u201d (in Indo-European) which show high phonological divergence. In comparison, even LexStat makes mistakes when clustering these meanings. Whenever the reflexes show similar word forms, in the case of Mayan (meanings: \u201cwater\u201d and \u201cdie\u201d), the algorithm groups all the reflexes into a single cluster without any error.\nAs part of future work, we plan to use the CRP algorithm for clustering meanings across different language families available in the ASJP database and then supply the cognate clusters to a Bayesian phylogenetic inference software such as MrBayes (Ronquist and Huelsenbeck, 2003) for inferring Bayesian trees for the languages of the world."}], "references": [{"title": "Javier Artiles", "author": ["Enrique Amig\u00f3", "Julio Gonzalo"], "venue": "and Felisa Verdejo.", "citeRegEx": "Amig\u00f3 et al.2009", "shortCiteRegEx": null, "year": 2009}, {"title": "Atkinson and Russell D", "author": ["D Quentin"], "venue": "Gray.", "citeRegEx": "Atkinson and Gray2006", "shortCiteRegEx": null, "year": 2006}, {"title": "and Quentin D", "author": ["Remco Bouckaert", "Philippe Lemey", "Michael Dunn", "Simon J. Greenhill", "Alexander V. Alekseyenko", "Alexei J. Drummond", "Russell D. Gray", "Marc A. Suchard"], "venue": "Atkinson.", "citeRegEx": "Bouckaert et al.2012", "shortCiteRegEx": null, "year": 2012}, {"title": "Holman", "author": ["Cecil H. Brown", "Eric W"], "venue": "and S\u00f8ren Wichmann.", "citeRegEx": "Brown et al.2013", "shortCiteRegEx": null, "year": 2013}, {"title": "Kruskal", "author": ["Isidore Dyen", "Joseph B"], "venue": "and Paul Black.", "citeRegEx": "Dyen et al.1992", "shortCiteRegEx": null, "year": 1992}, {"title": "A tutorial on bayesian nonparametric models", "author": ["Gershman", "Blei2012] Samuel J Gershman", "David M Blei"], "venue": "Journal of Mathematical Psychology,", "citeRegEx": "Gershman et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Gershman et al\\.", "year": 2012}, {"title": "Greenhill and Russell D", "author": ["J Simon"], "venue": "Gray.", "citeRegEx": "Greenhill and Gray2009", "shortCiteRegEx": null, "year": 2009}, {"title": "Clustering semantically equivalent words into cognate sets in multilingual lists", "author": ["Hauer", "Kondrak2011] Bradley Hauer", "Grzegorz Kondrak"], "venue": "In Proceedings of 5th International Joint Conference on Natural Language Processing,", "citeRegEx": "Hauer et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Hauer et al\\.", "year": 2011}, {"title": "Phylogenetic inference from word lists using weighted alignment with empirically determined weights", "author": ["Gerhard J\u00e4ger"], "venue": "Language Dynamics and Change,", "citeRegEx": "J\u00e4ger.,? \\Q2013\\E", "shortCiteRegEx": "J\u00e4ger.", "year": 2013}, {"title": "Revisiting k-means: New algorithms via bayesian nonparametrics", "author": ["Kulis", "Jordan2011] Brian Kulis", "Michael I Jordan"], "venue": "arXiv preprint arXiv:1111.0352", "citeRegEx": "Kulis et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Kulis et al\\.", "year": 2011}, {"title": "Binary codes capable of correcting deletions, insertions and reversals", "author": ["Vladimir I. Levenshtein"], "venue": "In Soviet physics doklady,", "citeRegEx": "Levenshtein.,? \\Q1966\\E", "shortCiteRegEx": "Levenshtein.", "year": 1966}, {"title": "Philippe Lopez", "author": ["Johann-Mattis List"], "venue": "and Eric Bapteste.", "citeRegEx": "List et al.2016", "shortCiteRegEx": null, "year": 2016}, {"title": "LexStat: Automatic detection of cognates in multilingual wordlists", "author": ["Johann-Mattis List"], "venue": "In Proceedings of the EACL 2012 Joint Workshop of LINGVIS & UNCLH,", "citeRegEx": "List.,? \\Q2012\\E", "shortCiteRegEx": "List.", "year": 2012}, {"title": "Sequence comparison in historical linguistics. D\u00fcsseldorf University Press, D\u00fcsseldorf", "author": ["J.-M. List"], "venue": null, "citeRegEx": "List.,? \\Q2014\\E", "shortCiteRegEx": "List.", "year": 2014}, {"title": "Foundations of statistical Natural Language Processing", "author": ["Manning", "Hinrich Sch\u00fctze"], "venue": null, "citeRegEx": "Manning et al\\.,? \\Q1999\\E", "shortCiteRegEx": "Manning et al\\.", "year": 1999}, {"title": "Needleman and Christian D", "author": ["B Saul"], "venue": "Wunsch.", "citeRegEx": "Needleman and Wunsch1970", "shortCiteRegEx": null, "year": 1970}, {"title": "Mrbayes 3: Bayesian phylogenetic inference under mixed models", "author": ["Ronquist", "John P Huelsenbeck"], "venue": null, "citeRegEx": "Ronquist et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Ronquist et al\\.", "year": 2003}, {"title": "Languages with longer words have more lexical change. In Approaches to Measuring Linguistic Differences, pages 249\u2013281", "author": ["Wichmann", "Holman2013] S\u00f8ren Wichmann", "Eric W Holman"], "venue": null, "citeRegEx": "Wichmann et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Wichmann et al\\.", "year": 2013}], "referenceMentions": [], "year": 2016, "abstractText": "In this paper, we introduce a threshold free approach, motivated from Chinese Restaurant Process, for the purpose of cognate clustering. We show that our approach yields similar results to a linguistically motivated cognate clustering system known as LexStat. Our Chinese Restaurant Process system is fast and does not require any threshold and can be applied to any language family of the world.", "creator": "LaTeX with hyperref package"}}}