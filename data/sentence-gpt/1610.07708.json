{"id": "1610.07708", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "25-Oct-2016", "title": "Knowledge will Propel Machine Understanding of Content: Extrapolating from Current Examples", "abstract": "Machine Learning has been a big success story during the AI resurgence. One particular stand out success relates to unsupervised learning from a massive amount of data, albeit much of it relates to one modality/type of data at a time. In spite of early assertions of the unreasonable effectiveness of data, there is increasing recognition of utilizing knowledge whenever it is available or can be created purposefully. In this paper, we focus on discussing the indispensable role of knowledge for deeper understanding of complex text and multimodal data in situations where (i) large amounts of training data (labeled/unlabeled) are not available or labor intensive to create, (ii) the objects (particularly text) to be recognized are complex (i.e., beyond simple entity-person/location/organization names), such as implicit entities and highly subjective content, and (iii) applications need to use complementary or related data in multiple modalities/media. What brings us to the cusp of rapid progress is our ability to (a) create knowledge, varying from comprehensive or cross domain to domain or application specific, and (b) carefully exploit the knowledge to further empower or extend the applications of ML/NLP techniques. Using the early results in several diverse situations - both in data types and applications - we seek to foretell unprecedented progress in our ability for deeper understanding and exploitation of multimodal data.\n\n\n\n\nThis article is presented on a scale from 0\u20135 (3\u20136) to 5 in order to approximate the effectiveness of our knowledge. As the number of individuals within a given class increases, the proportion of individuals who possess the knowledge grows. The authors' research is supported by the Open Science Foundation (http://www.openscience.org/).", "histories": [["v1", "Tue, 25 Oct 2016 02:13:53 GMT  (1114kb,D)", "http://arxiv.org/abs/1610.07708v1", "15 pages, 5 figures"]], "COMMENTS": "15 pages, 5 figures", "reviews": [], "SUBJECTS": "cs.AI cs.CL", "authors": ["amit sheth", "sujan perera", "sanjaya wijeratne"], "accepted": false, "id": "1610.07708"}, "pdf": {"name": "1610.07708.pdf", "metadata": {"source": "CRF", "title": "Knowledge will Propel Machine Understanding of Content: Extrapolating from Current Examples", "authors": ["Amit Sheth", "Sujan Perera", "Sanjaya Wijeratne"], "emails": ["amit@knoesis.org", "sujan@knoesis.org", "sanjaya@knoesis.org"], "sections": [{"heading": null, "text": "Keywords: Semantic analysis of multimodal data, Knowledge-enabled computing, Machine intelligence, Multimodal exploitation, Understanding complex text, Knowledge-enhanced ML and NLP, Knowledge-driven deep content understanding, Semantic search, Domain specific information retrieval, Ontology, Knowledgebases, Background knowledge, EmojiNet, Emoji Sense Disambiguation, Knowledge-aware search, Enhancing statistical models with knowledge, Implicit Entity Linking"}, {"heading": "1 Introduction", "text": "Recent success in the area of Machine Learning (ML) for Natural Language Processing (NLP) has been largely credited to the availability of enormous training datasets and computing power to train complex computational models [11].\nar X\niv :1\n61 0.\n07 70\n8v 1\n[ cs\n.A I]\n2 5\nO ct\n2 01\n6\nComplex NLP tasks such as statistical machine translation and speech recognition have hugely benefitted from web-scale unlabeled data that is freely available for consumption by learning systems such as deep neural nets. However, many traditional research problems related to NLP such as part-of-speech tagging, and named entity recognition (NER), require labeled or human annotated data, where the creation of such datasets is expensive in terms of the human effort required. In spite of early assertion of the unreasonable effectiveness of data (i.e., data alone is sufficient), there is an increasing recognition of utilizing knowledge to solve complex AI problems. A number of AI experts, including Yoav Shoham [34], Oren Etzioni, and Pedro Domingos [8], have talked about this in recent years.\nThe value of domain/world knowledge in solving complex problems was also recognized much earlier [38,6,19]. These early efforts were centered around understanding the language. Hence, the major focus was towards representing linguistic knowledge. The most popular artifacts of these efforts are FrameNet [25] and WordNet [17], which were developed by realizing the ideas of frame semantics [10] and lexical-semantic relations [7], respectively. Both these resources are used extensively by the NLP research community to understand the semantics of natural language.\nThe building and utilization of the knowledge bases took a major leap with the advent of the semantic web in early 2000s. For example, it was the key to the first patent on Semantic Web and a commercial semantic search/browsing and personalization engine 15 years ago [30], where knowledge in multiple domains complemented ML techniques for information extraction (NER, semantic annotation) and helping to build semantic applications [27]. Major efforts in the semantic web community have produced large, cross domain (e.g., DBpedia, Yago, Freebase, Google Knowledge Graph) and domain specific (e.g., Gene Ontology, MusicBrainz, UMLS) knowledge bases in recent years, as well as the intelligent applications discussed next.\nThe value of these knowledge bases has been demonstrated with many applications, including semantic similarity [15], question answering [26], ontology alignment, and word sense disambiguation (WSD) [16], as well as major practical AI services, including Apple\u2019s Siri, Google\u2019s Semantic Search, and IBM\u2019s Watson. For example, Siri relies on knowledge extracted from reputed online resources to answer queries on restaurant searches, movie suggestions, nearby events, etc. In fact, \u201cquestion answering\u201d, which is the core competency of Siri was built by partnering with Semantic Web or Semantic Search service providers who extensively utilize knowledge bases in their applications1. The Jeopardy version of IBM Watson uses semi-structured and structured knowledge bases such as DBpedia, Yago, and WordNet to strengthen the evidence and answer sources to fuel its DeepQA architecture [9]. Google Semantic Search is fueled by Google Knowledge Graph2, which is also used to enrich search results similar to what Taalee/Semagix semantic search engine did 15 years ago [27].\n1 https://en.wikipedia.org/wiki/Siri 2 http://bit.ly/22xUjZ6\nWhile knowledge bases are used in an auxiliary manner in the above scenarios, we argue that they have a major role to play in understanding real-world data. The real-world data has greater complexity that has yet to be appreciated and supported by automated systems. This complexity emerges from various dimensions. Human communication has added many constructs to language which help people to communicate effectively. However, current information extraction solutions fall short in processing complex constructs. One such complexity is the ability to express ideas, facts, and opinions in an implicit manner. For example, the sentence \u201cThe patient showed accumulation of fluid in his extremities, but respirations were unlabored and there were no use of accessory muscles\u201d refers to the clinical conditions \u201cshortness of breath\u201d and \u201cedema\u201d, which would be understood by a clinician. However, the sentence does not contain names of those clinical conditions, rather it contains descriptions that imply the two conditions. Current literature on entity extraction has not paid much attention to implicitly stated entities.\nAnother complexity in real-world data is its multimodal nature. A growing number of real world scenarios involve data coming from different modalities, often complementing each other. There is an increasing availability of physical (including sensor/IoT), cyber, and social data related to events and experiences of human interest [28,35]. For example, in our personalized digital health application for managing asthma in children3, we use sensors measuring the patient\u2019s physiology (e.g., exhaled nitric oxide) and his immediate surroundings (e.g., carbon monoxide, particulate matter, temperature, humidity), data accessible from the Web for the local area (air quality, pollen, weather), and social data (tweets relevant to asthma, web forum data) [1]. Each of these dimensions provide information that are helpful in proving or disproving the hypothesis provided by medical practice and disease management. Hence, understanding the patient status requires interpreting the observations of each modality and establishing the relationship between them to provide a comprehensive picture. Knowledge bases play a major role in establishing the relationships between multiple observations and transcend multiple abstraction levels [29]. We could know the relationship between asthma, nitric oxide and asthma medications through knowledge bases. Unless we have access to that knowledge or process data from all modalities potentially at different levels of abstractions, our predictions would not be accurate. Hence it is imperative for applications such as personalized digital health monitors to process multimodal data and use the available domain knowledge (in our case, a representation of relevant medical protocol) to arrive at accurate decisions. Emoji sense disambiguation is another example for multimodal data analysis, which is discussed later in the paper.\nWe argue that careful exploitation of knowledge can greatly enhance the current ability of (big) data processing; it can especially help in dealing with complex situations. At Kno.e.sis, we have recently dealt with situations where:\n3 http://bit.ly/kAsthma\n1. Large quantities of hand-labeled data required for unsupervised (self-taught) techniques to work well are not available or the annotation effort is significant. 2. The text to be recognized is complex (i.e., beyond simple entity - person/location/organization names) and we need deeper understanding than what traditional information extraction gives, such as complex/compound entities [23], implicit entities [21,22], and subjectivity (emotions, intention) [12,36]. 3. An application can benefit from multimodal data [1,2,4].\nThese efforts, with the exception of compound entities and emotion identification, have centered around exploiting different kinds of knowledge bases and using semantic techniques to complement or enhance ML, statistical techniques, and NLP. Our ideas are inspired by the human brain\u2019s ability to learn and generalize knowledge from a small amount of data (i.e., humans do not need to examine tens of thousands of cat faces to recognize the next cat shown to them), analyze situations by simultaneously and synergistically exploiting multimodal data streams, and understand more complex and nuanced aspects of content especially by knowing (through common-sense knowledge) semantics/identity preserving transformations."}, {"heading": "2 Challenges in creating/using knowledge bases", "text": "Last decade saw an increasing use of background knowledge in solving diverse problems. They heavily used large, publicly available knowledge bases. While applications such as search, browse, and question answering could use these knowledge bases in their current forms, others like movie recommendation, biomedical knowledge discovery, and clinical data interpretation are challenged by the limitations in current knowledge bases. These limitation are three fold;\n1. Messiness of the knowledge bases, 2. Incompleteness and insufficiency of knowledge bases, and 3. Limitations in knowledge representation and reasoning techniques.\nMessiness of the knowledge bases: Rapid growth in knowledge bases is occuring both in terms of numbers and sizes. This growth challenges the proper organization of the knowledge bases on the Web, hence users of the knowledge bases increasingly finding it hard to find the relevant knowledge bases or the relevant portion from the large knowledge bases for the domain of interest (e.g., movie, clinical, biomedical). This highlights the need for identifying relevant knowledge bases from collection of knowledge bases such as linked open data cloud and extracting relevant portion of the knowledge from large knowledge bases such as Wikipedia and DBpedia. In order to address this problem, we are working on automatically identifying and indexing the domains of the knowledge bases [14] and exploiting the semantics of the entities and their relationships to identify the relevant portions of a knowledge base given a domain of interest.\nIncompleteness and insufficiency of knowledge bases: The existing knowledge bases can be incomplete with respect to a task at hand. For example, applications like computer assisted coding and clinical document improvement require comprehensive knowledge about a particular domain (e.g., cardiology, oncology). We observe that although the existing medical knowledge bases (e.g., Unified Medical Language System (UMLS)) are rich in taxonomical relationships, they lack non-taxonomical relationships among clinical entities. We developed an algorithm that uses real-world clinical data and existing knowledge to discover more relationships between clinical entities using a human-in-the-loop model [20]. This model is capable of enriching the existing clinical knowledge bases with more relationships. Yet another challenge is creating personalized knowledge bases for specific tasks. For example, in [31], personal knowledge graphs are created based on the content consumed by a user, taking into account the dynamically changing vocabulary, and applied to improve subsequent filtering of relevant content.\nLimitations in knowledge representation and reasoning techniques: The scope of what is captured in the knowledge bases is rapidly expanding, requiring better modeling and understanding of concepts well beyond entities and relations, and involves subjectivity (intention, emotions, sentiments), temporal information, and more. This expansion challenges the current knowledge representation solutions which are mainly restricted to triple-based representations. The standard knowledge representation languages developed by Semantic Web community (e.g., RDF, OWL) are limited in their expressivity. It is important to be able to express the context of the knowledge represented with triples, to be able to associate probability value for triple based representations signifying uncertainty of the represented fact, and to be able to reason with them. All these requirements are well-recognized by the community and in recent years, we have seen some promising research in these directions. The singleton-property based representation [18] adds ability to make statements about triples (i.e., to express context of the triple) and probabilistic soft logic [13] adds ability to associate probability value with statements (i.e., triples) and reason over them. It will be really exciting to see applications exploiting such enhanced knowledge representation models that perform \u2018human-like\u2019 reasoning on them.\nNext, we will present two new research applications that utilize knowledge bases and multimodal data to address some of the aforementioned challenges identified earlier (i.e., complex nature of the problem, and insufficient manually created knowledge).\nExample 1: Implicit entity linking\nOne of the complexities with data is the ability to express facts, ideas, and opinions in an implicit manner. As humans, we seamlessly use implicit constructs in our daily conversations and rarely find it difficult to decode the content of the messages. Consider two tweets \u201cAren\u2019t we gonna talk about how ridiculous\nthe new space movie with Sandra Bullock is?\u201d and \u201cI\u2019m striving to be +ve in what I say, so I\u2019ll refrain from making a comment abt the latest Michael Bay movie\u201d. The first tweet contains an implicit mention of movie \u2018Gravity\u2019 and the second tweet contains an element of sarcasm and negative sentiment towards the movie \u2018Transformers: Age of Extinction\u2019. Both the sentiment and the movie are implicit in the tweet. While it is possible to express facts, ideas, and opinions in an implicit manner, for brevity, we will focus on how knowledge aids in automated techniques for identifying implicitly mentioned entities in text. We define implicit entities as \u201centities mentioned in text where neither its name nor its synonym/alias/abbreviation or co-reference is explicitly mentioned in the same text\u201d.\nImplicit entities are not a rare occurrence. Our studies found that 21% of the movie mentions and 40% of the book mentions are implicit in tweets, and about 35% and 40% of \u2018edema\u2019 and \u2018shortness of breath\u2019 mentions are implicit in clinical narratives. Whenever we communicate implicitly, we assume common understanding/shared-knowledge with the audience. A reader who does not know that Sandra Bullock starred in the movie \u2018Gravity\u2019 and that it is a space exploration movie, would not be able to decode the implicit mention of the movie \u2018Gravity\u2019 in the first example; a reader who does not know about Michael Bay\u2019s movie release would have no clue about the movie mentioned in the second tweet. These two examples demonstrate the indispensable value of domain knowledge in decoding implicit information in the text. State-of-the-art named entity recognition applications do not capture implicit entities [24]. Also, we have not seen big data-centric or other approaches that can identify implicit entities without the use of background knowledge (that is already available (e.g., in UMLS) or can be created (e.g., from tweets and Wikipedia)).\nThe task of recognizing implicit entities in the text demands comprehensive and up-to-date world knowledge. Individuals resort to a diverse set of entity characteristics to make implicit references. For example, the implicit references to the movie \u2018Boyhood\u2019 use phrases like \u201cRichard Linklater movie\u201d, \u201cEllar Coltrane on his 12-year movie role\u201d, \u201c12-year long movie shoot\u201d, \u201clatest movie shot in my city Houston\u201d, and \u201cMason Evan\u2019s childhood movie\u201d. Hence, it is important to have comprehensive knowledge about the entities to decode their implicit mentions. Another complexity is the temporal relevancy of the knowledge. The same phrase can be used to implicitly refer to different entities at different points in time. For instance, the phrase \u201cspace movie\u201d could refer to the movie \u2018Gravity\u2019 in Fall 2013 while the same phrase in Fall 2015 would likely refer to the movie \u2018The Martian\u2019. On the flip side, the most salient characteristics of the movies may change over time and so will the phrases used to refer to them. The movie \u2018Furious 7\u2019 was frequently referred to with the phrase \u201cPaul Walker\u2019s last movie\u201d in November 2014. This was due to the actor\u2019s death around that time. However, after the movie release in April 2015, the same entity was often mentioned through the phrase \u201cfastest film to reach the $1 billion\u201d.\nWe have developed knowledge-driven solutions that decode the implicit entity mentions in clinical narratives and tweets [21,22]. Our solution models individ-\nual entities of interest by collecting knowledge about the entities from publicly available knowledge bases. These knowledge bases consists of definitions of the entities, other associated concepts, and the strength and the temporal relevance of the associated concepts. The implicit entity linking algorithms are designed to carefully use the knowledge encoded in these models to identify implicit entities in the text.\nExample 2: Emoji sense disambiguation\n\u201cEmoji Sense Disambiguation\u201d is defined as \u201cthe machine\u2019s ability to identify the meaning of an emoji in the context in which the emoji has been used\u201d. This exciting new challange can benefit from carefully curated knowledge (sense inventories) and multimodal data analysis.\nPeople are using emoji as a new language on social media to add color and whimsiness to their messages. Without rigid semantics attached to them, emoji symbols take on different meanings based on the context of a message. This has resulted in ambiguity in emoji use (see Figure 1). Similar to word sense disambiguation, machine readable knowledge bases that list emoji meanings are essential for machines to understand emoji without ambiguity. As a step towards building machines that can understand emoji, at Kno.e.sis we have developed EmojiNet [37], the first machine readable sense inventory for emoji. It links Unicode emoji representations to their English meanings extracted from the Web, enabling systems to link emoji with their context-specific meaning. EmojiNet is automatically constructed by integrating multiple emoji resources with BabelNet, which is the most comprehensive multilingual sense inventory available to date. For example, for the emoji \u2018face with tears of joy\u2019, EmojiNet lists 14 different senses, ranging from happy to sad. An application designed to disambiguate emoji senses can use the senses provided by EmojiNet. Emoji sense disambiguation could improve the research on sentiment and emotion analysis. For example, consider the emoji \u2018face with tears of joy\u2019 which can take the meanings happy and sad based on the context in which it has been used. Current sentiment\nanalysis application does not differentiate among the two meanings when they process the \u2018face with tears of joy\u2019 emoji. However, knowing the meaning of the emoji can improve sentiment prediction. Emoji similarity calculation is another task that could be benefited by knowledge bases and multimodal data analysis. Similar to computing similarity between words, we can calculate the similarity between emoji characters.\nExample 3: Understanding and analysing drug abuse-related discussions on web forums\nThe use of knowledge bases to improve keyword-based search has received much attention from commercial search engines lately. However, the use of knowledge bases alone cannot solve complex, domain-specific information needs. For example, to answer a complex search query such as \u201cHow are drug users engaging in the use of the semi-synthetic opioid Buprenorphine through excessive daily dosage?\u201d may require a search engine to be aware of several facts, including Buprenorphine is a drug, users refer to Buprenorphine with synonyms such as \u2018bupe\u2019, \u2018bupey\u2019, \u2018suboxone\u2019, \u2018subbies\u2019, \u2018suboxone film\u2019, and the prescribed daily dosage range for Buprenorphine. The search engine should also want to have access to ontological knowledge as well as other \u201cintelligible constructs\u201d that are not typically modeled in ontologies, such as frequency of drug use, interval, and dosage, to answer such complex search needs. At Kno.e.sis, we have developed an information retrieval system that integrates ontology-driven query interpretation with synonym-based query expansion and domain specific rules, to facilitate analysis of online web forums for drug abuse-related information extraction. Our system is based on a context-free grammar (CFG) that defines\nthe interpretation of the query language constructs used to search for drug the abuse-related information needs and a domain-specific knowledge base that can be used to understand information in drug-related web forum posts. Our tool utilizes lexical, lexico-ontological, ontological, and rule-based knowledge to understand the information needs behind complex search queries (see Figures 2 and 3) [5].\nExample 4: Understanding city traffic using sensor and textual observations\nWith the increase in urbanization, understanding and controlling city traffic flow has become an important problem. Currently, there are over 1 billion cars on the road network, which is predicted to double by 2020, and there has been an increase of vehicular traffic by 236% from 1981 to 2001 [2]. Zero traffic fatalities and the minimization of traffic delays are some of the challenges that need to be addressed. Early understanding of traffic events is a necessity to address these challenges. The data points that help to understand such events exist in multiple modalities. Sensors deployed on road networks continuously relay important information about travel speed through certain road networks while citizen sensors (i.e. humans) share real-time information about traffic/road conditions on public social media streams such as Twitter. As humans, we know how to inte-\ngrate information from these data sources and understand traffic events (i.e. the slow-moving traffic shown by sensor observations could be due to an accident reported in tweets at location x ). However, current research on understanding city traffic dynamics focuses only on either sensory data or social media data. We can exploit the complementary and corroborative nature of these data sources to understand the traffic events.\nThe first step towards such effort is to materialize the domain knowledge possessed by humans about traffic events to a machine readable format (i.e. to develop a knowledge base on traffic events and their causes). A statistical approach would help to establish the associations between variables of the domain (e.g. there is an association between \u2018bad weather\u2019 and a \u2018traffic jam\u2019). However, such approaches fall short in finding all the variables that exist in the domain, finding all associations between variables, and finding the causal directionality between variables. We developed techniques to leverage domain knowledge to enrich the statistical models that address above shortcomings. Primarily we used the sensor data collected by 511.org to develop an initial probabilistic graphical model that explains the conditional dependencies between variables in traffic domain. Then we leverage the domain knowledge encoded in ConceptNet to add more nodes to the model that represent missing variables, add more edges to the model that represent missing associations, and add directionality to the edges between nodes to represent the conditional dependencies. Figure 4(a) shows a snippet of the ConceptNet and Figure 4(b) demonstrates the enrichment step of the developed model using the domain knowledge in ConceptNet [3].\nThe next step is to understand the sensor observations. The idea is to model \u2018normal\u2019 traffic patterns using sensor observations and then detect any anomalies.\nWe used a Restricted Switching Linear Dynamical System (RSLDS) to model normal speed and travel time dynamics and thereby characterize anomalous dynamics. Using speed and travel time data from each link, we generated time series data for each hour of the day and for each day of the week. Then for each hour of each day of week, we averaged the travel speeds and travel times at each road link (see Figure 4). However, the average speed would not be a real speed that we observed in the data. Thus, to select a speed that exists in the actual data we chose the speed that is closest to the average speed using a point-wise Euclidean distance metric. We used the above speed data to learn parameters for a RSLDS (using log likelihood function), and treated the RSLDS model as a model for the normal traffic dynamics of the San Francisco Bay Area [2]. If the log likelihood value for a particular day of the week and hour of the day is less than the minimum log likelihood value for that time period, we tagged the traffic dynamics as anomalous.\nThe anomalous observations are further analyzed with events extracted from Twitter data and subsequently declared as being explained when we can find traffic causing events in Twitter data (according to the domain model) with a time overlap of the observed anomalous traffic behaviour. Figure 5 demonstrates this process. This example again demonstrates vital role domain knowledge plays to improve the ability of a AI technique such as RSLDS (that help to process large amounts of data to develop a model and identification of anomaly) to improve\ninterpretation of data and in integrated exploitation of complementary data of different modalities. Further exploration of different approaches to represent and exploit semantics appears in [32]."}, {"heading": "3 Conclusions and looking forward", "text": "We discussed the importance of domain/world knowledge in understanding complex data in the real world, particularly, when large amounts of training data are not readily available or is expensive to generate. We demonstrated two use cases (and referred to three additional applications) where knowledge plays an indispensable role in understanding complex language constructs and multimodal data. We are also seeing early efforts in making knowledge bases dynamic and evolve to account for the changes in the real world [33].\nKnowledge seems to play a central role in human learning and intelligence, such as in learning from small amount of data, or in cognition \u2013 especially perception. Our ability to create or deploy just the right knowledge in our computing processes will improve machine intelligence, perhaps in a similar way as knowledge plays a central role in human intelligence. As a corollary of this, two of the specific advances we will see are a deeper and nuanced understanding of content (including but not limited to text) and our ability to process and learn from multimodal data at a semantic level (given that concepts manifest very differently at the data level in different media or modalities). The human brain is extremely adept at processing multimodal data \u2013 our senses are capable of receiving 11 million bits per second, and our brain is able to distill that into a few tens of bits of abstractions (for further explorations, see [29]). Knowledge plays a central role in this abstraction process known as the perception cycle.\nMachine intelligence has been the holy grail of a lot of AI research lately. The statistical pattern matching approach and learning from big data, typically of single modality, has seen tremendous success. For those of us who have pursued brain-inspired computing approaches, we think the time has come for rapid progress using a model-building approach. The ability to build broad (both in terms of coverage as well as variety- not just entities and relationships, but also emotions, intentions and subjectivity features; linguistic, cultural and other aspects of human interest and functions) and static knowledge to domain-specific, purpose-specific, personalized, and/or dynamic knowledge combined with richer representation \u2013 especially probabilistic graph models \u2013 will see very rapid progress. These will complement neural network approaches. We may also see knowledge playing a significant role in enhancing deep learning. Rather than the dominance of data-centric approaches, we will see an interleaving and interplay of the data and knowledge tracks."}, {"heading": "Acknowledgments", "text": "We acknowledge partial support from the National Science Foundation (NSF) award: CNS-1513721: \u201cContext-Aware Harassment Detection on Social Media\u201d,\nNational Institute on Drug Abuse (NIDA) Grant No. 5R01DA039454-02: \u201cTrending: Social Media Analysis to Monitor Cannabis and Synthetic Cannabinoid Use\u201d, National Institutes of Health (NIH) award: MH105384-01A1: \u201cModeling Social Behavior for Healthcare Utilization in Depression\u201d, and Grant No. 2014- PS-PSN-00006 awarded by the Bureau of Justice Assistance. The Bureau of Justice Assistance is a component of the U.S. Department of Justice\u2019s Office of Justice Programs, which also includes the Bureau of Justice Statistics, the National Institute of Justice, the Office of Juvenile Justice and Delinquency Prevention, the Office for Victims of Crime, and the SMART Office. Points of view or opinions in this document are those of the authors and do not necessarily represent the official position or policies of the U.S. Department of Justice, NSF, NIH or NIDA."}], "references": [{"title": "Knowledge-driven personalized contextual mhealth service for asthma management in children", "author": ["P. Anantharam", "T. Banerjee", "A. Sheth", "K. Thirunarayan", "S. Marupudi", "V. Sridharan", "S.G. Forbis"], "venue": "2015 IEEE International Conference on Mobile Services. IEEE", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2015}, {"title": "Understanding city traffic dynamics utilizing sensor and textual observations", "author": ["P. Anantharam", "K. Thirunarayan", "S. Marupudi", "A. Sheth", "T. Banerjee"], "venue": "Proceedings of The 13th AAAI Conference on Artificial Intelligence (AAAI-16), February 12\u201317, Phoenix, Arizona, USA", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2016}, {"title": "Traffic analytics using probabilistic graphical models enhanced with knowledge bases", "author": ["P. Anantharam", "K. Thirunarayan", "A.P. Sheth"], "venue": "Analytics for Cyber Physical Systems workshop at the SIAM Conference on Data Mining (SDM)", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2013}, {"title": "Finding street gang members on twitter", "author": ["L. Balasuriya", "S. Wijeratne", "D. Doran", "A. Sheth"], "venue": "The 2016 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining (ASONAM 2016). vol. 8. San Francisco, CA, USA", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2016}, {"title": "A hybrid approach to finding relevant social media content for complex domain specific information needs", "author": ["D. Cameron", "A. Sheth", "N. Jaykumar", "K. Thirunarayan", "G. Anand", "G.A. Smith"], "venue": "Web Semantics: Science, Services and Agents on the World Wide Web 29", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2014}, {"title": "What are ontologies, and why do we need them? IEEE Intelligent systems", "author": ["B. Chandrasekaran", "J.R. Josephson", "Benjamins", "V.R"], "venue": null, "citeRegEx": "6", "shortCiteRegEx": "6", "year": 1999}, {"title": "Lexical semantics", "author": ["D.A. Cruse"], "venue": "Cambridge University Press", "citeRegEx": "7", "shortCiteRegEx": null, "year": 1986}, {"title": "A few useful things to know about machine learning", "author": ["P. Domingos"], "venue": "Communications of the ACM 55", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2012}, {"title": "Building watson: An overview of the deepqa project", "author": ["D. Ferrucci", "E. Brown", "J. Chu-Carroll", "J. Fan", "D. Gondek", "A.A. Kalyanpur", "A. Lally", "J.W. Murdock", "E. Nyberg", "J Prager"], "venue": "AI magazine 31(3)", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2010}, {"title": "Frame semantics and the nature of language", "author": ["C.J. Fillmore"], "venue": "Annals of the New York Academy of Sciences 280(1)", "citeRegEx": "10", "shortCiteRegEx": null, "year": 1976}, {"title": "The unreasonable effectiveness of data", "author": ["A. Halevy", "P. Norvig", "F. Pereira"], "venue": "IEEE Intelligent Systems 24", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2009}, {"title": "Knowledge Driven Search Intent Mining", "author": ["A. Jadhav"], "venue": "Ph.D. thesis, Wright State University", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2016}, {"title": "A short introduction to probabilistic soft logic", "author": ["A. Kimmig", "S. Bach", "M. Broecheler", "B. Huang", "L. Getoor"], "venue": "Proceedings of the NIPS Workshop on Probabilistic Programming: Foundations and Applications", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2012}, {"title": "Automatic domain identification for linked open data", "author": ["S. Lalithsena", "P. Hitzler", "A. Sheth", "P. Jain"], "venue": "IEEE/WIC/ACM International Joint Conferences on Web Intelligence and Intelligent Agent Technologies. vol. 1", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2013}, {"title": "A review of semantic similarity measures in wordnet", "author": ["L. Meng", "R. Huang", "J. Gu"], "venue": "International Journal of Hybrid Information Technology 6(1)", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2013}, {"title": "Knowledge-based methods for wsd", "author": ["R. Mihalcea"], "venue": "Word Sense Disambiguation: Algorithms and Applications", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2006}, {"title": "Introduction to wordnet: An on-line lexical database", "author": ["G.A. Miller", "R. Beckwith", "C. Fellbaum", "D. Gross", "K.J. Miller"], "venue": "International journal of lexicography 3(4)", "citeRegEx": "17", "shortCiteRegEx": null, "year": 1990}, {"title": "Don\u2019t like rdf reification?: making statements about statements using singleton property", "author": ["V. Nguyen", "O. Bodenreider", "A. Sheth"], "venue": "Proc. of the 23rd inti. conf. on WWW", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2014}, {"title": "Integration of world knowledge for natural language understanding, vol", "author": ["E. Ovchinnikova"], "venue": "3. Springer Science & Business Media", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2012}, {"title": "Semantics driven approach for knowledge acquisition from emrs", "author": ["S. Perera", "C. Henson", "K. Thirunarayan", "A. Sheth", "S. Nair"], "venue": "IEEE journal of BHI 18(2)", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2014}, {"title": "Implicit entity recognition in clinical documents", "author": ["S. Perera", "P. Mendes", "A. Sheth", "K. Thirunarayan", "A. Alex", "C. Heid", "G. Mott"], "venue": "Proceedings of the 4th Joint Conference on Lexical and Computational Semantics (* SEM)", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2015}, {"title": "Implicit entity linking in tweets", "author": ["S. Perera", "P.N. Mendes", "A. Alex", "A. Sheth", "K. Thirunarayan"], "venue": "International Semantic Web Conference. Springer", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2016}, {"title": "Joint extraction of compound entities and relationships from biomedical literature", "author": ["C. Ramakrishnan", "P.N. Mendes", "R.A. da Gama", "G.C. Ferreira", "A. Sheth"], "venue": "Proceedings of the 2008 IEEE/WIC/ACM International Conference on Web Intelligence and Intelligent Agent Technology", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2008}, {"title": "Making sense of microposts (# microposts2015) named entity recognition and linking (neel) challenge", "author": ["G. Rizzo", "A.E.C. Basave", "B. Pereira", "A. Varga", "M. Rowe", "M. Stankovic", "A. Dadzie"], "venue": "# MSM. pp. 44\u201353", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2015}, {"title": "Framenet ii: Extended theory and practice", "author": ["J. Ruppenhofer", "M. Ellsworth", "M.R. Petruck", "C.R. Johnson", "J. Scheffczyk"], "venue": null, "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2006}, {"title": "Question answering on interlinked data", "author": ["S. Shekarpour", "A.C. Ngonga Ngomo", "S. Auer"], "venue": "Proceedings of the 22nd international conference on World Wide Web", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2013}, {"title": "15 years of semantic search and ontology-enabled semantic applications", "author": ["A. Sheth"], "venue": "Blog \u2013 http://j.mp/15yrsSS", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2014}, {"title": "Physical-cyber-social computing: An early 21st century approach", "author": ["A. Sheth", "P. Anantharam", "C. Henson"], "venue": "IEEE Intelligent Systems 28(1)", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2013}, {"title": "Semantic, cognitive, and perceptual computing: Paradigms that shape human experience", "author": ["A. Sheth", "P. Anantharam", "C. Henson"], "venue": "Computer 49(3)", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2016}, {"title": "System and method for creating a semantic web and its applications in browsing, searching, profiling, personalization and advertising", "author": ["A. Sheth", "D. Avant", "C. Bertram"], "venue": null, "citeRegEx": "30", "shortCiteRegEx": "30", "year": 2001}, {"title": "Semantic filtering for social data", "author": ["A. Sheth", "P. Kapanipathi"], "venue": "IEEE Internet Computing 20(4)", "citeRegEx": "31", "shortCiteRegEx": null, "year": 2016}, {"title": "Semantics for the semantic web: The implicit, the formal and the powerful", "author": ["A. Sheth", "C. Ramakrishnan", "C. Thomas"], "venue": "International Journal on Semantic Web and Information Systems (IJSWIS) 1(1), 1\u201318", "citeRegEx": "32", "shortCiteRegEx": null, "year": 2005}, {"title": "Continuous semantics to analyze real-time data", "author": ["Sheth", "C. Amit Thomas", "P. Mehra"], "venue": "Wiki \u2013 http://bit.ly/2cVGbov", "citeRegEx": "33", "shortCiteRegEx": null, "year": 2010}, {"title": "Why knowledge representation matters", "author": ["Y. Shoham"], "venue": "Communications of the ACM 59(1)", "citeRegEx": "34", "shortCiteRegEx": null, "year": 2015}, {"title": "Semantics empowered big data processing with applications", "author": ["K. Thirunarayan", "A. Sheth"], "venue": "AI Magazine 36", "citeRegEx": "35", "shortCiteRegEx": null, "year": 2015}, {"title": "Automatic Emotion Identification from Text", "author": ["W. Wang"], "venue": "Ph.D. thesis, Wright State University", "citeRegEx": "36", "shortCiteRegEx": null, "year": 2015}, {"title": "Emojinet: Building a machine readable sense inventory for emoji", "author": ["S. Wijeratne", "L. Balasuriya", "A. Sheth", "D. Doran"], "venue": "8th International Conference on Social Informatics (SocInfo 2016). Bellevue, WA, USA", "citeRegEx": "37", "shortCiteRegEx": null, "year": 2016}, {"title": "Understanding natural language", "author": ["T. Winograd"], "venue": "Cognitive psychology 3(1)", "citeRegEx": "38", "shortCiteRegEx": null, "year": 1972}], "referenceMentions": [{"referenceID": 10, "context": "Recent success in the area of Machine Learning (ML) for Natural Language Processing (NLP) has been largely credited to the availability of enormous training datasets and computing power to train complex computational models [11].", "startOffset": 224, "endOffset": 228}, {"referenceID": 33, "context": "A number of AI experts, including Yoav Shoham [34], Oren Etzioni, and Pedro Domingos [8], have talked about this in recent years.", "startOffset": 46, "endOffset": 50}, {"referenceID": 7, "context": "A number of AI experts, including Yoav Shoham [34], Oren Etzioni, and Pedro Domingos [8], have talked about this in recent years.", "startOffset": 85, "endOffset": 88}, {"referenceID": 37, "context": "The value of domain/world knowledge in solving complex problems was also recognized much earlier [38,6,19].", "startOffset": 97, "endOffset": 106}, {"referenceID": 5, "context": "The value of domain/world knowledge in solving complex problems was also recognized much earlier [38,6,19].", "startOffset": 97, "endOffset": 106}, {"referenceID": 18, "context": "The value of domain/world knowledge in solving complex problems was also recognized much earlier [38,6,19].", "startOffset": 97, "endOffset": 106}, {"referenceID": 24, "context": "The most popular artifacts of these efforts are FrameNet [25] and WordNet [17], which were developed by realizing the ideas of frame semantics [10] and lexical-semantic relations [7], respectively.", "startOffset": 57, "endOffset": 61}, {"referenceID": 16, "context": "The most popular artifacts of these efforts are FrameNet [25] and WordNet [17], which were developed by realizing the ideas of frame semantics [10] and lexical-semantic relations [7], respectively.", "startOffset": 74, "endOffset": 78}, {"referenceID": 9, "context": "The most popular artifacts of these efforts are FrameNet [25] and WordNet [17], which were developed by realizing the ideas of frame semantics [10] and lexical-semantic relations [7], respectively.", "startOffset": 143, "endOffset": 147}, {"referenceID": 6, "context": "The most popular artifacts of these efforts are FrameNet [25] and WordNet [17], which were developed by realizing the ideas of frame semantics [10] and lexical-semantic relations [7], respectively.", "startOffset": 179, "endOffset": 182}, {"referenceID": 29, "context": "For example, it was the key to the first patent on Semantic Web and a commercial semantic search/browsing and personalization engine 15 years ago [30], where knowledge in multiple domains complemented ML techniques for information extraction (NER, semantic annotation) and helping to build semantic applications [27].", "startOffset": 146, "endOffset": 150}, {"referenceID": 26, "context": "For example, it was the key to the first patent on Semantic Web and a commercial semantic search/browsing and personalization engine 15 years ago [30], where knowledge in multiple domains complemented ML techniques for information extraction (NER, semantic annotation) and helping to build semantic applications [27].", "startOffset": 312, "endOffset": 316}, {"referenceID": 14, "context": "The value of these knowledge bases has been demonstrated with many applications, including semantic similarity [15], question answering [26], ontology alignment, and word sense disambiguation (WSD) [16], as well as major practical AI services, including Apple\u2019s Siri, Google\u2019s Semantic Search, and IBM\u2019s Watson.", "startOffset": 111, "endOffset": 115}, {"referenceID": 25, "context": "The value of these knowledge bases has been demonstrated with many applications, including semantic similarity [15], question answering [26], ontology alignment, and word sense disambiguation (WSD) [16], as well as major practical AI services, including Apple\u2019s Siri, Google\u2019s Semantic Search, and IBM\u2019s Watson.", "startOffset": 136, "endOffset": 140}, {"referenceID": 15, "context": "The value of these knowledge bases has been demonstrated with many applications, including semantic similarity [15], question answering [26], ontology alignment, and word sense disambiguation (WSD) [16], as well as major practical AI services, including Apple\u2019s Siri, Google\u2019s Semantic Search, and IBM\u2019s Watson.", "startOffset": 198, "endOffset": 202}, {"referenceID": 8, "context": "The Jeopardy version of IBM Watson uses semi-structured and structured knowledge bases such as DBpedia, Yago, and WordNet to strengthen the evidence and answer sources to fuel its DeepQA architecture [9].", "startOffset": 200, "endOffset": 203}, {"referenceID": 26, "context": "Google Semantic Search is fueled by Google Knowledge Graph, which is also used to enrich search results similar to what Taalee/Semagix semantic search engine did 15 years ago [27].", "startOffset": 175, "endOffset": 179}, {"referenceID": 27, "context": "There is an increasing availability of physical (including sensor/IoT), cyber, and social data related to events and experiences of human interest [28,35].", "startOffset": 147, "endOffset": 154}, {"referenceID": 34, "context": "There is an increasing availability of physical (including sensor/IoT), cyber, and social data related to events and experiences of human interest [28,35].", "startOffset": 147, "endOffset": 154}, {"referenceID": 0, "context": ", carbon monoxide, particulate matter, temperature, humidity), data accessible from the Web for the local area (air quality, pollen, weather), and social data (tweets relevant to asthma, web forum data) [1].", "startOffset": 203, "endOffset": 206}, {"referenceID": 28, "context": "Knowledge bases play a major role in establishing the relationships between multiple observations and transcend multiple abstraction levels [29].", "startOffset": 140, "endOffset": 144}, {"referenceID": 22, "context": ", beyond simple entity - person/location/organization names) and we need deeper understanding than what traditional information extraction gives, such as complex/compound entities [23], implicit entities [21,22], and subjectivity (emotions, intention) [12,36].", "startOffset": 180, "endOffset": 184}, {"referenceID": 20, "context": ", beyond simple entity - person/location/organization names) and we need deeper understanding than what traditional information extraction gives, such as complex/compound entities [23], implicit entities [21,22], and subjectivity (emotions, intention) [12,36].", "startOffset": 204, "endOffset": 211}, {"referenceID": 21, "context": ", beyond simple entity - person/location/organization names) and we need deeper understanding than what traditional information extraction gives, such as complex/compound entities [23], implicit entities [21,22], and subjectivity (emotions, intention) [12,36].", "startOffset": 204, "endOffset": 211}, {"referenceID": 11, "context": ", beyond simple entity - person/location/organization names) and we need deeper understanding than what traditional information extraction gives, such as complex/compound entities [23], implicit entities [21,22], and subjectivity (emotions, intention) [12,36].", "startOffset": 252, "endOffset": 259}, {"referenceID": 35, "context": ", beyond simple entity - person/location/organization names) and we need deeper understanding than what traditional information extraction gives, such as complex/compound entities [23], implicit entities [21,22], and subjectivity (emotions, intention) [12,36].", "startOffset": 252, "endOffset": 259}, {"referenceID": 0, "context": "An application can benefit from multimodal data [1,2,4].", "startOffset": 48, "endOffset": 55}, {"referenceID": 1, "context": "An application can benefit from multimodal data [1,2,4].", "startOffset": 48, "endOffset": 55}, {"referenceID": 3, "context": "An application can benefit from multimodal data [1,2,4].", "startOffset": 48, "endOffset": 55}, {"referenceID": 13, "context": "In order to address this problem, we are working on automatically identifying and indexing the domains of the knowledge bases [14] and exploiting the semantics of the entities and their relationships to identify the relevant portions of a knowledge base given a domain of interest.", "startOffset": 126, "endOffset": 130}, {"referenceID": 19, "context": "We developed an algorithm that uses real-world clinical data and existing knowledge to discover more relationships between clinical entities using a human-in-the-loop model [20].", "startOffset": 173, "endOffset": 177}, {"referenceID": 30, "context": "For example, in [31], personal knowledge graphs are created based on the content consumed by a user, taking into account the dynamically changing vocabulary, and applied to improve subsequent filtering of relevant content.", "startOffset": 16, "endOffset": 20}, {"referenceID": 17, "context": "The singleton-property based representation [18] adds ability to make statements about triples (i.", "startOffset": 44, "endOffset": 48}, {"referenceID": 12, "context": ", to express context of the triple) and probabilistic soft logic [13] adds ability to associate probability value with statements (i.", "startOffset": 65, "endOffset": 69}, {"referenceID": 23, "context": "State-of-the-art named entity recognition applications do not capture implicit entities [24].", "startOffset": 88, "endOffset": 92}, {"referenceID": 20, "context": "We have developed knowledge-driven solutions that decode the implicit entity mentions in clinical narratives and tweets [21,22].", "startOffset": 120, "endOffset": 127}, {"referenceID": 21, "context": "We have developed knowledge-driven solutions that decode the implicit entity mentions in clinical narratives and tweets [21,22].", "startOffset": 120, "endOffset": 127}, {"referenceID": 36, "context": "sis we have developed EmojiNet [37], the first machine readable sense inventory for emoji.", "startOffset": 31, "endOffset": 35}, {"referenceID": 4, "context": "See [5] for more information.", "startOffset": 4, "endOffset": 7}, {"referenceID": 4, "context": "Our tool utilizes lexical, lexico-ontological, ontological, and rule-based knowledge to understand the information needs behind complex search queries (see Figures 2 and 3) [5].", "startOffset": 173, "endOffset": 176}, {"referenceID": 4, "context": "See [5] for more information.", "startOffset": 4, "endOffset": 7}, {"referenceID": 1, "context": "Currently, there are over 1 billion cars on the road network, which is predicted to double by 2020, and there has been an increase of vehicular traffic by 236% from 1981 to 2001 [2].", "startOffset": 178, "endOffset": 181}, {"referenceID": 2, "context": "See [3] for more information.", "startOffset": 4, "endOffset": 7}, {"referenceID": 2, "context": "Figure 4(a) shows a snippet of the ConceptNet and Figure 4(b) demonstrates the enrichment step of the developed model using the domain knowledge in ConceptNet [3].", "startOffset": 159, "endOffset": 162}, {"referenceID": 2, "context": "See [3] for more information.", "startOffset": 4, "endOffset": 7}, {"referenceID": 1, "context": "We used the above speed data to learn parameters for a RSLDS (using log likelihood function), and treated the RSLDS model as a model for the normal traffic dynamics of the San Francisco Bay Area [2].", "startOffset": 195, "endOffset": 198}, {"referenceID": 31, "context": "Further exploration of different approaches to represent and exploit semantics appears in [32].", "startOffset": 90, "endOffset": 94}, {"referenceID": 32, "context": "We are also seeing early efforts in making knowledge bases dynamic and evolve to account for the changes in the real world [33].", "startOffset": 123, "endOffset": 127}, {"referenceID": 28, "context": "The human brain is extremely adept at processing multimodal data \u2013 our senses are capable of receiving 11 million bits per second, and our brain is able to distill that into a few tens of bits of abstractions (for further explorations, see [29]).", "startOffset": 240, "endOffset": 244}], "year": 2016, "abstractText": "Machine Learning has been a big success story during the AI resurgence. One particular stand out success relates to unsupervised learning from a massive amount of data, albeit much of it relates to one modality/type of data at a time. In spite of early assertions of the unreasonable effectiveness of data, there is increasing recognition of utilizing knowledge whenever it is available or can be created purposefully. In this paper, we focus on discussing the indispensable role of knowledge for deeper understanding of complex text and multimodal data in situations where (i) large amounts of training data (labeled/unlabeled) are not available or labour intensive to create, (ii) the objects (particularly text) to be recognized are complex (i.e., beyond simple entity \u2013 person/location/organization names), such as implicit entities and highly subjective content, and (iii) applications need to use complementary or related data in multiple modalities/media. What brings us to the cusp of rapid progress is our ability to (a) create knowledge, varying from comprehensive or cross domain to domain or application specific, and (b) carefully exploit the knowledge to further empower or extend the applications of ML/NLP techniques. Using the early results in several diverse situations \u2013 both in data types and applications \u2013 we seek to foretell unprecedented progress in our ability for deeper understanding and exploitation of multimodal data.", "creator": "LaTeX with hyperref package"}}}