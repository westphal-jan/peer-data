{"id": "1611.00094", "review": {"conference": "iclr", "VERSION": "v1", "DATE_OF_SUBMISSION": "1-Nov-2016", "title": "Learning recurrent representations for hierarchical behavior modeling", "abstract": "We propose a framework for detecting action patterns from motion sequences and modeling the sensory-motor relationship of animals, using a generative recurrent neural network. The network has a discriminative part (classifying actions) and a generative part (predicting motion), whose recurrent cells are laterally connected, allowing higher levels of the network to represent high level phenomena. We test our framework on two types of data, fruit fly behavior and online handwriting. Our results show that 1) taking advantage of unlabeled sequences, by predicting future motion, significantly improves action detection performance when training labels are scarce, 2) the network learns to represent high level phenomena such as writer identity and fly gender, without supervision, and 3) simulated motion trajectories, generated by treating motion prediction as input to the network, look realistic and may be used to qualitatively evaluate whether the model has learnt generative control rules.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "histories": [["v1", "Tue, 1 Nov 2016 01:03:53 GMT  (5366kb,D)", "http://arxiv.org/abs/1611.00094v1", null], ["v2", "Thu, 3 Nov 2016 23:39:43 GMT  (7526kb,D)", "http://arxiv.org/abs/1611.00094v2", null], ["v3", "Tue, 15 Nov 2016 18:06:10 GMT  (7527kb,D)", "http://arxiv.org/abs/1611.00094v3", null]], "reviews": [], "SUBJECTS": "cs.AI cs.CV", "authors": ["eyrun eyjolfsdottir", "kristin branson", "yisong yue", "pietro perona"], "accepted": true, "id": "1611.00094"}, "pdf": {"name": "1611.00094.pdf", "metadata": {"source": "CRF", "title": "LEARNING RECURRENT REPRESENTATIONS FOR HIERARCHICAL BEHAVIOR MODELING", "authors": ["Eyrun Eyjolfsdottir", "Kristin Branson", "Yisong Yue", "Pietro Perona"], "emails": [], "sections": [{"heading": "1 INTRODUCTION", "text": "Behavioral scientists strive to decode the functional relationship between sensory input and motor output of the brain (Tinbergen, 1963; Moore, 2002). In particular, ethologists study the natural behavior of animals while neuroscientists and psychologists study behavior in a controlled environment, manipulating neural activations and environmental stimuli. These studies require quantitative measurements of behavior to discover correlations or causal relationships between behaviors over time or between behavior and stimuli; automating this process allows for more objective and precise measurements, and significantly increased throughput (Anderson & Perona, 2014). Many industries are also concerned with automatic measurement and prediction of behavior, for applications such as surveillance, assisted living, sports analytics, self driving vehicles, robotic/virtual assistants.\nBehavior is complex and may be perceived at different time-scales of resolution: position, trajectory, action, activity. While position and trajectory are geometrical notions, action and activities are semantic in nature. The analysis of behavior may therefore be divided into two steps: (a) detection and tracking (Spink et al., 2001; Darrell et al., 2000), where the pose of the body over time is estimated and (b) action / activity detection and classification (Kabra et al., 2013; Eyjolfsdottir et al., 2014), where motion is segmented into meaningful intervals, each one of which is associated with a goal or a purpose. One may think of the trajectory of the body as a time-series (analogous to the sounds produced in speech) which has to be decoded into its meaningful components (analogous to words and sentences). Our work focuses on going from (a) to (b), that is to detect and classify actions from motion trajectories. We use data for which tracking and pose estimation is relatively simple, which allows us to focus on modeling the temporal dynamics of pose trajectories without worrying about errors stemming from low level feature extraction.\nSupervised learning is a powerful tool for learning classifiers from examples of actions that an expert considers important. However, it has two drawbacks. First, it requires a lot of training labels which involves time consuming and painstaking annotation. Second, behavior measurement is limited to actions that a human can perceive and believes to be important. We propose a framework that takes advantage of both labeled and unlabeled sequences by simultaneously predicting future motion and detecting actions, which we hypothesize will allow the system to learn action classifiers with fewer expert labels. The model in our framework is a recurrent neural network that we constructed with the goal that hidden states of the model learn to represent and discover behaviors of different semantic\nar X\niv :1\n61 1.\n00 09\n4v 1\n[ cs\n.A I]\n1 N\nov 2\n01 6\nscales. If successful, this would offer an unbiased and less laborious way of measuring behavior. The framework models the sensory-motor relationship of an agent, predicting motion based on its sensory input and motion history, and can be used to simulate an agent by iteratively feeding motion predictions as input to the network, updating sensory inputs accordingly. A model that can simulate realistic behavior has learnt to emulate the generative control laws underlying behavior, which could be a useful tool for behavior analysis (Simon, 1996; Braitenberg, 1984).\nOur experiments focus mainly on the behavior of fruit flies, Drosophila Melanogaster, a popular, relatively simple, model organism for the study of behavior (Siwicki & Kravitz, 2009). To explore the generality of our approach we also test our model on online handwriting data, an interesting human behavior that produces two dimensional trajectories \u2013 one may think of strokes corresponding to elementary motion trajectories, letters to actions, and words to activities.\nTo summarize our contributions:\n1) We propose a framework that simultaneously models the sensory-motor relationship of an agent and classifies its actions, and can be trained with partially labeled data.\n2) We show that motion prediction is a good auxiliary task for action classification, especially when training labels are scarce.\n3) We show that simulated motion trajectories resemble trajectories from the data domain and can be manipulated by activating discriminative cell units.\n4) We show that the network learns to represent high level information, such as gender or identity, at higher levels of the network and low level information, such as velocity, at lower levels.\n5) We test this architecture on both the spontaneous and sporadic behavior of fruit flies, and the intentional and structured behavior of handwriting."}, {"heading": "2 BACKGROUND", "text": "Hidden Markov models (HMMs) have been extensively used for sequence classification. The motivating assumption for HMMs is that there exists a process that transitions with some probability between discrete states, each of which emits observations according to some distribution, and the objective is to learn these functions given a sequence of observations and states. This model is limited in that its transition functions are linear, state space is discrete, and emission distribution is generally assumed to be Gaussian, although generalizations of the model that fall under the category of dynamic Bayesian networks are more expressive (Murphy, 2002).\nRecurrent neural networks (RNNs) have recently been shown to be extremely successful in classifying time series data, especially with the popularization of long short term memory cells (Hochreiter & Schmidhuber, 1997), in applications such as speech recognition (Graves et al., 2013). RNNs have also been used for generative sequence prediction of handwriting (Graves, 2013) as well as speech synthesis (Chung et al., 2015).\nImitation learning involves learning to map a state to an action, from demonstrated sequences of actions. This is a supervised learning technique which, when implemented as an RNN, can be trained via backpropagation using action-error computed at every time step. The problem with this approach is that the domain of states that an agent is trained on consists only of states that the demonstrators encounter, and when an agent makes a mistake it finds itself in a situation never experienced during training. Reinforcement learning handles this by letting an agent explore the domain using an action policy, and updating the policy based on a goal-specific penalty or reward which may be obtained after taking several actions. This exploration can be extremely expensive, and therefore it is common to precede reinforcement learning with imitation learning to start the agent off with a reasonable policy. This strategy is used in (Mnih et al., 2015) where an agent is trained to play Atari games, and in (Silver et al., 2016) for mastering the game of GO.\nAutoencoders (Rumenlhart et al., 1986) have been used in semi-supervised classification to pretrain a network on an auxiliary task, such as denoising, to prevent overfitting on a small number of labeled data (Baldi, 2012). Recent work in this area (Rasmus et al., 2015) proposes to train on the primary and auxiliary task concurrently and using lateral connections (Valpola, 2015) between encoding and decoding layers to allow higher layers of the network to focus on high level features.\nOur framework takes inspiration from each of the works described here."}, {"heading": "3 MODEL", "text": "Our model is a recurrent neural network, with long short term memory, that simultaneously classifies actions and predicts future motion of agents (insects, animals, and humans). Rather than actions being a function of the recurrent state, as is common practice, our model embeds actions in recurrent state units. This way the recurrent function encodes action transition probabilities and motion prediction is a direct function of actions, similar to an HMM. The network takes as input an agent\u2019s motion and sensory input at every time step, and outputs the agent\u2019s next move according to a policy, which is effectively learnt via imitation learning. Similar to autoencoders, our model has a discriminative path, used to embed high level information, and a generative path used to reconstruct the input domain, in our case filling in the future motion. Each discriminative recurrent cell is fully connected with its corresponding generative cell, allowing higher level states to represent higher level information, similar to the idea of Ladder networks (Valpola, 2015)."}, {"heading": "3.1 ARCHITECTURE", "text": "The model can be thought of as two parallel recurrent networks: The discriminative network takes as input an agent\u2019s motion, x, and environmental sensory input, v, and propagates them up through its hidden states which encode high level information, including action labels, y. The generative network decodes the states of the discriminative network, propagating information down to predict the agents locomotion at the next time step, x\u0302. The two networks have the same number of layers and are connected diagonally at each layer such that the information encoded in the hidden units of the discriminative network is propagated to the corresponding layer of the generative network at the next time step. Intuitively, the diagonal connections allow higher levels of the network to represent high level phenomena, such as goals or individuality, while lower levels represent low level information, such as motion. Our experiments confirm this intuition. The model can be trained without any action labels, in which case the hidden state may be used to discover high level information about the data, or with action labels for a subset of the data, in which case each action is assigned to a hidden state unit and will thus contribute to subsequent motion prediction and action classification.\nThe flow of information through the network and the cost associated with its classification and prediction is expressed with the following functions:\nDiscriminative Generative Cost\nh1i = f([xi, vi], h 1 i\u22121) h\u0302 L i+1 = f(h L i , h\u0302 L i ) Cy = \u2211T i=1 Ly(yi, y\u0302i)\nhli = f(h l\u22121 i , h l i\u22121) h\u0302 l i+1 = f([\u0302h\nl+1 i+1, h l i], h\u0302 l i) Cx = \u2211T i=1 Lx(xi+1, x\u0302i+1)\ny\u0302i = (h L i (1 : N) + 1)/2 x\u0302i+1 = g(h\u0302 1 i+1) C = \u03bbCy + (1\u2212 \u03bb)Cx\nwhere f is recurrent cell function, g is a transformation, and Ly and Lx, are loss functions that depend on the target type (see Figure 1). The total cost, C, combines the misclassification cost, Cy , and misprediction cost, Cx, using \u03bb to tradeoff the two. N is the number of labeled actions, L the number of levels, T the number of frames in x, l is the layer index and i the frame index. Classification labels y\u0302i are assigned to the first N units of hLi and scaled from [\u22121 1] to [0 1]. We present our model as part of a general framework where f , g, and number of levels/units are architectural choices to be optimized for each dataset, and loss functions should be selected according to target type; sigmoid cross entropy for multitask classification (where actions can co-occur), softmax cross entropy for multiclass classification (where actions are mutually exclusive), and sum of squared differences for regression (where outputs are real valued).\nFor our experiments we found that 2-3 levels of recurrent cells with 100-200 units worked well, with f as a gated recurrent unit (GRU) cell (Cho et al., 2014) and g as linear transformation. Training parameters that require tuning for each dataset are sequence length, the number of time-steps to propagate error gradients, learning rate, the rate at which gradients are propagated, and the target tradeoff \u03bb whose optimal value may depend both on the output domain of Ly and Lx and whether the primary goal is classification or simulation. Data-specific model parameters are further described in Section 5 and training details in supplementary material1."}, {"heading": "3.2 MULTIMODAL PREDICTION", "text": "Evidence suggests that animal behavior is nondeterministic (Roberts et al., 2016), thus, motion prediction may be better represented as a probability distribution than a function. When future motion is multimodal, the best regression model will pick the average motion of the different modes which may not lie within any of the actual modes (visualized in supplementary material). This observation has been made by others in the context of modeling real-valued sequences with RNNs, (Graves, 2013) model the output of an RNN as a Gaussian mixture model and (Chung et al., 2015) additionally model the hidden recurrent states as random variables. We take a nonparametric approach, making no assumption about the shape of the distribution. We discretize motion into bins and treat the task of predicting future motion as independent multiclass classification problems for each motion feature, which results in a probability distribution over all bins for each dimension. More concretely, each dimension of x is assigned n bins and the target for x\u0302i+1 becomes the binned version of xi+1, denoted as x\u0303i+1, which has exactly one nonzero entry for each dimension of x. The prediction x\u0302i+1 then becomes a discrete distribution over the bins for each feature dimension and the motion prediction loss becomes Lx(xi+1, x\u0302i+1) = \u2211 d(crossentropy(x\u0303i+1, x\u0302i+1)), as opposed to the Euclidean distance in the case when x is a real valued vector. The number of bins determines the granularity of the motor control; a greater number of bins means more precise motion control but is also more expensive to train."}, {"heading": "3.3 SIMULATION", "text": "Given a model that can predict an agent\u2019s future motion from its current state, a virtual agent can be simulated by iteratively feeding predicted motion x\u0302i+1 as input xi+1 to the network. We pick a bin by sampling from the distribution given by x\u0302i+1 and assign a real value to xi+1 by sampling uniformly from the selected bin. An agent\u2019s perception of the environment depends on the agent\u2019s location, therefore, sensory features vi+1 must be computed on the fly for each forward simulation step from the agents perspective at time i + 1. When simulating multiple agents that interact with one another, each agent is moved according to its xi+1 and then vi+1 is computed for each agent based on the new configuration of all agents.\n1www.vision.caltech.edu/\u02dceeyjolfs/behavior_modeling"}, {"heading": "4 DATA", "text": "Our framework is agent centric, it models the behavior of a single agent based on how it moves and experiences the world including other agents. It is applicable to any data that can be represented in terms of motor control (e.g. joystick controller), and sensory input that captures context from the environment (e.g. 1st person camera). We test our model on two types of data, fruit fly behavior and online handwriting. Both can be thought of as a type of behavior represented in the form of trajectories, but the two are complementary: First, flies behave spontaneously, performing actions of interest sporadically and in response to its environment, while handwritten text is intensional and highly structured. Second, handwriting varies significantly between different writers in terms of size, speed, slant, and proportions, while inter-fly variation is relatively small. With the datasets selected for our experiments, listed below, we are interested in answering the following questions: 1) does motion prediction improve action classification, 2) can the model generate realistic simulations (does it learn the sensory-motor control), and 3) can the model discover novel behavioral phenomena?\nFly-vs-fly (Eyjolfsdottir et al., 2014) contains pairs of fruit flies engaging in 10 labeled courtshipand aggressive behaviors. We include this dataset in our experiments to see how our model compares with our previous action detection work which relies on handcrafted window features.\nFlyBowl is a video of 10 male and 10 female fruit flies interacting and is labeled with male wing extensions which is part of their courtship behavior. With this dataset we were particularly interested in whether our model could simulate a virtual fly in a complex, dynamic environment.\nSynthFly is a synthetic dataset containing a single fly moving inside of a rectangular chamber with a stationary object located in the center. The fly is synthesized to move according to the control laws listed in Figure 2. The purpose of this dataset is to test whether our model could learn generative control rules, particularly ones that enforce non-deterministic behavior (see laws 4 and 5).\nIAM-OnDB (Liwicki & Bunke, 2005) contains handwritten text from 195 different writers, acquired using a smart whiteboard that records a list of (x, y) coordinates for each pen stroke. The data is weakly labeled, with each sequence separated into short lines of transcribed text. For consistency with our framework we hand annotated strokes of 10 writers, marking the start and end of the 26 lower case characters, which we use along with data from 35 unlabeled writers for our experiments.\nAll data, along with details about training and test splits, will be available in supplementary material.\nFly representation: Motor control features, x, describe the locomotion of a fly. The flies are tracked from video using FlyTracker2 and from the tracked fly poses we extract motion features represented in the fly\u2019s frame of reference. The 8 features, displayed on top of the fly3 in Figure 3, are: forward displacement, sideways displacement, yaw, body length, left/right wing angle and left/right wing length. These features are designed such that they can animate virtual fly agents. Sensory input features, v, are inspired by a fly\u2019s compound eye which consist of 750 compactly aligned ommatidia. Approximating its vision as a one dimensional 360\u25e6 view, we place 72 5\u25e6 circular sectors around a fly, aligned with its orientation, and project flies that overlap with a sector onto its artificial retina. Flies close to the agent yield high intensity in several ommatidia, and flies that are far away take up few ommatidia with low intensity. We represent chamber walls similarly, projecting them onto a separate channel decreasing intensity exponentially with distance to the fly. This representation is invariant of the shape of the chamber and the number of flies present in the chamber.\nIn order to compare our model with methods presented in Eyjolfsdottir et al. (2014), independently of feature representation, we use the 36 features provided with the Fly-vs-Fly dataset. We assign the first 8 dimensions which describe a fly\u2019s locomotion as motor control and the remaining features which describe its position relative to the other fly and feature derivatives as sensory input.\nHandwriting representation: We represent the motor control, x, as (dx, dy, z) where dx and dy are the x and y displacements from the previous pen recording and z is a binary variable denoting segment visibility. We normalize dx and dy for each writer, providing invariance to writing speed, but character size (number of points per character), slant, and other variations are not explicitly accounted for. As handwriting is not influenced by a changing environment, but rather a function of the internal state and current motion of the writer, we leave the sensory input, v, empty."}, {"heading": "5 EXPERIMENTS AND ANALYSIS", "text": "We evaluate our framework on three objectives: classification, simulation, and discovery. For classification we show the benefit of motion prediction as an auxiliary task, compare our performance on Fly-vs-Fly with previous work, and analyze the performance on IAM-OnDB. We qualitatively show that simulation results for fly behavior and handwriting look convincing, and that the model is able to learn control laws used to generate the SynthFly dataset. For discovery we show that hidden states of the model, trained only to predict motion (without any action labels), cleanly capture high level phenomena that affect behavior, such as fly gender and writer identity.\nModel details: We trained a separate model for each dataset, using a sequence length of 50, a batch size of 20, and 51 bins per dimension for motion prediction. For fly behavior data we used 2 levels of GRU cells (4 cells total) of 100 units each, and for handwriting we used 3 levels of GRU cells (6 cells total) of 200 units each. Parameters were determined using a rough parameter sweep on a subset of the training data. Further training details are described in supplementary material.\n2www.vision.caltech.edu/Tools/FlyTracker 3Original photograph from gompel.org/drosophilidae"}, {"heading": "5.1 CLASSIFICATION", "text": "From the sequence of frame-wise classifications we extract consecutive classifications into intervals (or bouts) of actions. To account for both duration and counting accuracy we use the performance measures described in Eyjolfsdottir et al. (2014), namely the F1 score (harmonic mean of precision and recall), on a per-frame and per-bout level. Bout-wise precision and recall is computed by assigning predicted bouts to ground truth bouts one-to-one, maximizing intersection over overlap. F* is the harmonic mean of the F1-frame and F1-bout scores.\nOur main goal in terms of classification was to get comparable classification performance with many fewer training labels by using motion prediction as an auxiliary task. To measure the benefit of semisupervision we compare our model, which we will refer to as Behavior Embedding Sensory-motor Network (BESNet), with our model without its generative part (similar to a standard RNN but with action labels embedded in hidden states, shown in Figure 5), which we will refer to as Behavior Embedding Network (BENet). We trained both models on each dataset using 3-100% of available labels. Since BESNet is trained to predict future motion, it makes use of unlabeled sequences during training whereas BENet does not. Figure 4 a) shows the frame-wise F1 score for each of the 36 trained models (3 datasets, 6 label fractions, 2 model types), averaged over all action classes in a dataset. This experiment shows that motion prediction as an auxiliary task significantly improves classification performance, especially when labels are scarce.\nIn Figure 4 b) we compare the performance of our network with the best performing method on Flyvs-Fly, which extracts hand crafted features from a window around each frame, classifies frames using a support vector machine (SVM), and fits an HMM to the output of the SVM for smoother prediction \u2013 outperforming sophisticated methods such as structured SVM. For this comparison we used the features published with the dataset as described in Section 4. Although recurrent networks\nimplicitly enable smooth predictions, different actions require different levels of smoothness which we do not explicitly optimize for. Since bout-wise performance is sensitive to small discontinuities in action prediction, due to over segmentation of action intervals, we smooth the output of our network by applying a flat filter, of size equal to 10% of the mean duration of each class, to the output of each action class. Our results show that filtering significantly improves the bout-wise performance and that our performance on the Fly-vs-Fly test set is comparable with that of Eyjolfsdottir et al. (2014), using no handcrafting and no context of future frames (apart from smoothing).\nThe frame-wise confusion matrix for IAM-OnDB in Figure 4 c) shows that characters such as m and n tend to get confused with each other, and k and l tend to be confused with t. This is unsurprising as the beginning of these characters looks approximately the same. Figure 4 d) demonstrates this point, showing that at the beginning of some characters there tends to be more confusion in y\u0302 than towards the end. We applied the same type of filtering to the classification output as we did for Fly-vs-Fly and obtained an F1-(frame, bout) of (0.445, 0.585) averaged over all classes, and (0.567, 0.690) averaged over all instances (weighted average of classes)."}, {"heading": "5.2 MOTION PREDICTION", "text": "Before we look at simulation results, we quantitatively measure the accuracy of one-step predictions. We compute the log-likelihood of FlyBowl test sequences under the motion prediction model: loglik(x) = \u2211T\u22121 i=1 \u22118 d=1 log(x\u0303 d i+1 \u00b7 x\u0302di+1), where x\u0303di+1 is the ground truth indicator vector for bins of motion dimension d, with one non-zero entry, and x\u0302di+1 is a probability distribution over the bins predicted by the model.\nWe compare our model with the following motion prediction policies: 1) uniform distribution over bins, 2) distribution over bins computed from training set, 3) constant motion policy that copies previous indicator vector as motion prediction, and 4) a smooth version of 3) filtered using an optimized Gaussian kernel. The results, shown in Figure 5, demonstrate that the recurrent models learn a significantly better policy. In addition, we compare variants of our model and a standard RNN within our framework (with the same sensory-motor representation, multimodal output, and GRU cells) which shows that recurrence is essential for good motion prediction and that diagonal connections provide a slight performance gain. In Section 5.4 we show that the main benefit of the diagonal connections is that they enable higher levels of the network to capture high level phenomena which naturally lends itself well to adding classification tasks at higher states of the model.\n1\n0.1 0.3 0.4 0.1 0.1xif^\nxif~\nxif~ = bin(xfi, n_bins)\nL( , ) = sum_f(crossentropy ( , )xfi+1~ xfi+1^xi+1 xi+1^\nground truth\nprediction"}, {"heading": "5.3 SIMULATION", "text": "One-step prediction performance does not clearly reveal whether a model has learnt well the generative process underlying the training data. In order to get a better notion of that we look at simulations produced by the learnt models, which can be thought of as very long term predictions. As motion prediction is probabilistic, comparing long term predictions with ground truth becomes difficult as the domain of probable positions becomes exponentially large. Qualitative inspection, however, gives a good intuition about whether the simulated agent has learnt reasonable control laws.\nb) simulated trajectories c) real trajectoriesa) 10 x 20-frame lookaheads for test flies\ngenerated text character injectionsoriginal text\ngenerated text character injectionsoriginal text gen t d text charact injections\nWhile the underlying generative process for the motion of real flies is unknown, simulations from the model trained to imitate them suggest that the model has learnt a reasonable policy. During simulation we place no physical constraints on how the flies can move, but our results show that simulated FlyBowl agents avoid collisions with the chamber walls and with other flies, and that agents are attracted to other flies and occasionally engage in courtship-like behavior. This is shown in Figure 6 and better visualized as video in supplementary material.\nSimulated handwriting is easier to evaluate from a static image as it is easily visualized in 2 dimensions and we are used to recognizing the structure it should produce. Figure 7 shows that the model trained on IAM-OnDB produces character-like trajectories in word-like combinations. Note that handwriting is generated one (dx, dy, z) vector at a time, and each character is composed of roughly 20 such points on average. On the right hand side of Figure 7 we show that we can increase the generation of specific characters by activating their classification units (forcing their values to 1 and others to 0) during simulation. This is possible only because the model embeds classification units in its hidden states such that they directly influence motion prediction.\nThe purpose of the synthetic fly experiment was to test whether our model could learn known control laws from which motion trajectories were generated. Figure 8 shows the output of two recurrent units of the SynthFly model that indicate that the model was able to learn control rules that we designed specifically to ensure a multimodal motion prediction target. One unit fires in correlation with either left or right wing extension, and the other toggles between a negative and positive state as the agent turns left or right to avoid the object. In supplementary material we show a video of this simulation and compare it to a simulation from the model trained with deterministic motion prediction. This comparison clearly demonstrates the benefit of treating motion prediction as a distribution over bins, as the deterministic agent quickly becomes degenerate.\n0 100 200 300 400 500 600 700 800 900 1000 0\n200\nr r rl l l l l l l\nr r rl l l l l l l\nr r rl l l l l l l\nInteresting units"}, {"heading": "5.4 DISCOVERY", "text": "We motivated the structure of our network, specifically the diagonal connections between discriminative and generative cells, with the intuition that it would allow higher levels of the network to better represent high level phenomena. To verify this we train models to only predict future motion, with no classification target, and visualize what the hidden states capture. We apply the model to [x, v], obtaining hidden state vectors hl and h\u0302l, l \u2208 {1, ..., L}, and prediction x\u0302, map the data points (time steps of each fly/writer) for each state to 2 dimensions using t-distributed stochastic neighbor embedding (tSNE, Maaten & Hinton (2008)), and plot them in colors based on known phenomena.\nPlotting data points of a 2 level (L = 2) model trained on FlyBowl in this low dimensional embedding, color coded by gender and left/right wing extension, shows (Figure 9) that gender is very mixed in the input and output states but well separated in the top generative state, while lower level information such as wing extension is well represented at lower levels of the network.\nIn Figure 10 we color code the data points of a 3 level model trained on IAM-OnDB according to three criteria: stroke length, character class, and writer identity. The results show that stroke length is well clustered at low levels but not at high levels, characters are best clustered at mid to top discriminative levels, and writer identity is extremely well clustered at the top generative level but not at low levels. We ran the same experiment for the model trained without diagonal connections (which without a classification target is effectively a standard RNN with 6 levels of GRU cells), and show that it did not learn to represent writer identity in any of its hidden states. Intuitively this is because the network has to carry low level information through every state to predict low level information at the other end, whereas BESNet carries it directly through the low level diagonal connections leaving higher hidden states free to capture high level information. In supplementary material we quantify this observation with character and writer identity probability at each state."}, {"heading": "6 CONCLUSION", "text": "We have proposed a framework for modeling the behavior of animals, that simultaneously classifies their actions and predicts their motion. We showed empirically that motion prediction (a target that requires no expert labeling) is a good auxiliary task for training action classifiers, especially when labels are scarce. We also showed that the generative task can be used to simulate trajectories that look natural to the human eye, and that activating classification units increases the frequency of that action in the simulation. Finally, we showed that the our model lends itself well to discovery of high level information from the data.\nMoving forward, we are interested in working on hierarchical label embedding in the states, assigning higher order activities to units higher in the network. Along those lines, a discrete recurrent network could be trained separately on the wealth of available text, and be placed on top of a realvalued handwriting network. We also aim to explore how this framework can be used to understand the neural mechanisms underlying the generation of behavior in flies."}], "references": [{"title": "Toward a science of computational ethology", "author": ["David J Anderson", "Pietro Perona"], "venue": null, "citeRegEx": "Anderson and Perona.,? \\Q2014\\E", "shortCiteRegEx": "Anderson and Perona.", "year": 2014}, {"title": "Autoencoders, unsupervised learning, and deep architectures", "author": ["Pierre Baldi"], "venue": "ICML unsupervised and transfer learning,", "citeRegEx": "Baldi.,? \\Q2012\\E", "shortCiteRegEx": "Baldi.", "year": 2012}, {"title": "Vehicles Experiments in Synthetic Psychology", "author": ["Valentino Braitenberg"], "venue": null, "citeRegEx": "Braitenberg.,? \\Q1984\\E", "shortCiteRegEx": "Braitenberg.", "year": 1984}, {"title": "Learning phrase representations using rnn encoder-decoder for statistical machine translation", "author": ["Kyunghyun Cho", "Bart Van Merri\u00ebnboer", "Caglar Gulcehre", "Dzmitry Bahdanau", "Fethi Bougares", "Holger Schwenk", "Yoshua Bengio"], "venue": "arXiv preprint arXiv:1406.1078,", "citeRegEx": "Cho et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Cho et al\\.", "year": 2014}, {"title": "A recurrent latent variable model for sequential data", "author": ["Junyoung Chung", "Kyle Kastner", "Laurent Dinh", "Kratarth Goel", "Aaron C Courville", "Yoshua Bengio"], "venue": "In Advances in neural information processing systems,", "citeRegEx": "Chung et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Chung et al\\.", "year": 2015}, {"title": "Integrated person tracking using stereo, color, and pattern detection", "author": ["T. Darrell", "G. Gordon", "M. Harville", "J. Woodfill"], "venue": "International Journal of Computer Vision,", "citeRegEx": "Darrell et al\\.,? \\Q2000\\E", "shortCiteRegEx": "Darrell et al\\.", "year": 2000}, {"title": "Detecting social actions of fruit flies", "author": ["Eyrun Eyjolfsdottir", "Steve Branson", "Xavier P Burgos-Artizzu", "Eric D Hoopfer", "Jonathan Schor", "David J Anderson", "Pietro Perona"], "venue": "In Computer Vision\u2013 ECCV", "citeRegEx": "Eyjolfsdottir et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Eyjolfsdottir et al\\.", "year": 2014}, {"title": "Speech recognition with deep recurrent neural networks", "author": ["Alan Graves", "Abdel-rahman Mohamed", "Geoffrey Hinton"], "venue": "In Acoustics, Speech and Signal Processing (ICASSP),", "citeRegEx": "Graves et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Graves et al\\.", "year": 2013}, {"title": "Generating sequences with recurrent neural networks", "author": ["Alex Graves"], "venue": "arXiv preprint arXiv:1308.0850,", "citeRegEx": "Graves.,? \\Q2013\\E", "shortCiteRegEx": "Graves.", "year": 2013}, {"title": "Long short-term memory", "author": ["Sepp Hochreiter", "J\u00fcrgen Schmidhuber"], "venue": "Neural computation,", "citeRegEx": "Hochreiter and Schmidhuber.,? \\Q1997\\E", "shortCiteRegEx": "Hochreiter and Schmidhuber.", "year": 1997}, {"title": "Jaaba: interactive machine learning for automatic annotation of animal", "author": ["Mayank Kabra", "Alice A Robie", "Marta Rivera-Alba", "Steven Branson", "Kristin Branson"], "venue": "behavior. nature methods,", "citeRegEx": "Kabra et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Kabra et al\\.", "year": 2013}, {"title": "Iam-ondb-an on-line english sentence database acquired from handwritten text on a whiteboard", "author": ["Marcus Liwicki", "Horst Bunke"], "venue": "In Document Analysis and Recognition,", "citeRegEx": "Liwicki and Bunke.,? \\Q2005\\E", "shortCiteRegEx": "Liwicki and Bunke.", "year": 2005}, {"title": "Visualizing data using t-sne", "author": ["Laurens van der Maaten", "Geoffrey Hinton"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Maaten and Hinton.,? \\Q2008\\E", "shortCiteRegEx": "Maaten and Hinton.", "year": 2008}, {"title": "Human-level control through deep reinforcement learning", "author": ["Volodymyr Mnih", "Koray Kavukcuoglu", "David Silver", "Andrei A Rusu", "Joel Veness", "Marc G Bellemare", "Alex Graves", "Martin Riedmiller", "Andreas K Fidjeland", "Georg Ostrovski"], "venue": "Nature, 518(7540):529\u2013533,", "citeRegEx": "Mnih et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Mnih et al\\.", "year": 2015}, {"title": "Some thoughts on the relation between behavior analysis and behavioral neuroscience", "author": ["J Moore"], "venue": "The Psychological Record,", "citeRegEx": "Moore.,? \\Q2002\\E", "shortCiteRegEx": "Moore.", "year": 2002}, {"title": "Dynamic bayesian networks: representation, inference and learning", "author": ["Kevin Patrick Murphy"], "venue": "PhD thesis,", "citeRegEx": "Murphy.,? \\Q2002\\E", "shortCiteRegEx": "Murphy.", "year": 2002}, {"title": "Semisupervised learning with ladder networks", "author": ["Antti Rasmus", "Mathias Berglund", "Mikko Honkala", "Harri Valpola", "Tapani Raiko"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Rasmus et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Rasmus et al\\.", "year": 2015}, {"title": "A stochastic neuronal model predicts random search behaviors at multiple spatial scales in c", "author": ["William M Roberts", "Steven B Augustine", "Kristy J Lawton", "Theodore H Lindsay", "Tod R Thiele", "Eduardo J Izquierdo", "Serge Faumont", "Rebecca A Lindsay", "Matthew Cale Britton", "Navin Pokala"], "venue": "elegans. eLife,", "citeRegEx": "Roberts et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Roberts et al\\.", "year": 2016}, {"title": "Learning internal representation by error propagation, parallel distributed processing", "author": ["DE Rumenlhart", "Geoffrey E Hinton", "Ronald J Williams"], "venue": "Explor. Microstruct. Cognition,", "citeRegEx": "Rumenlhart et al\\.,? \\Q1986\\E", "shortCiteRegEx": "Rumenlhart et al\\.", "year": 1986}, {"title": "Mastering the game of go with deep neural networks and tree", "author": ["David Silver", "Aja Huang", "Chris J Maddison", "Arthur Guez", "Laurent Sifre", "George Van Den Driessche", "Julian Schrittwieser", "Ioannis Antonoglou", "Veda Panneershelvam", "Marc Lanctot"], "venue": "search. Nature,", "citeRegEx": "Silver et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Silver et al\\.", "year": 2016}, {"title": "The sciences of the artificial", "author": ["Herbert A Simon"], "venue": "MIT press,", "citeRegEx": "Simon.,? \\Q1996\\E", "shortCiteRegEx": "Simon.", "year": 1996}, {"title": "Fruitless, doublesex and the genetics of social behavior in drosophila melanogaster", "author": ["Kathleen K Siwicki", "Edward A Kravitz"], "venue": "Current opinion in neurobiology,", "citeRegEx": "Siwicki and Kravitz.,? \\Q2009\\E", "shortCiteRegEx": "Siwicki and Kravitz.", "year": 2009}, {"title": "The ethovision video tracking system\u2014a tool for behavioral phenotyping of transgenic mice", "author": ["AJ Spink", "RAJ Tegelenbosch", "MOS Buma", "LPJJ Noldus"], "venue": "Physiology & behavior,", "citeRegEx": "Spink et al\\.,? \\Q2001\\E", "shortCiteRegEx": "Spink et al\\.", "year": 2001}, {"title": "On aims and methods of ethology", "author": ["Niko Tinbergen"], "venue": "Zeitschrift fu\u0308r Tierpsychologie,", "citeRegEx": "Tinbergen.,? \\Q1963\\E", "shortCiteRegEx": "Tinbergen.", "year": 1963}, {"title": "From neural pca to deep unsupervised learning", "author": ["Harri Valpola"], "venue": "Adv. in Independent Component Analysis and Learning Machines,", "citeRegEx": "Valpola.,? \\Q2015\\E", "shortCiteRegEx": "Valpola.", "year": 2015}], "referenceMentions": [{"referenceID": 23, "context": "Behavioral scientists strive to decode the functional relationship between sensory input and motor output of the brain (Tinbergen, 1963; Moore, 2002).", "startOffset": 119, "endOffset": 149}, {"referenceID": 14, "context": "Behavioral scientists strive to decode the functional relationship between sensory input and motor output of the brain (Tinbergen, 1963; Moore, 2002).", "startOffset": 119, "endOffset": 149}, {"referenceID": 22, "context": "The analysis of behavior may therefore be divided into two steps: (a) detection and tracking (Spink et al., 2001; Darrell et al., 2000), where the pose of the body over time is estimated and (b) action / activity detection and classification (Kabra et al.", "startOffset": 93, "endOffset": 135}, {"referenceID": 5, "context": "The analysis of behavior may therefore be divided into two steps: (a) detection and tracking (Spink et al., 2001; Darrell et al., 2000), where the pose of the body over time is estimated and (b) action / activity detection and classification (Kabra et al.", "startOffset": 93, "endOffset": 135}, {"referenceID": 10, "context": ", 2000), where the pose of the body over time is estimated and (b) action / activity detection and classification (Kabra et al., 2013; Eyjolfsdottir et al., 2014), where motion is segmented into meaningful intervals, each one of which is associated with a goal or a purpose.", "startOffset": 114, "endOffset": 162}, {"referenceID": 6, "context": ", 2000), where the pose of the body over time is estimated and (b) action / activity detection and classification (Kabra et al., 2013; Eyjolfsdottir et al., 2014), where motion is segmented into meaningful intervals, each one of which is associated with a goal or a purpose.", "startOffset": 114, "endOffset": 162}, {"referenceID": 20, "context": "A model that can simulate realistic behavior has learnt to emulate the generative control laws underlying behavior, which could be a useful tool for behavior analysis (Simon, 1996; Braitenberg, 1984).", "startOffset": 167, "endOffset": 199}, {"referenceID": 2, "context": "A model that can simulate realistic behavior has learnt to emulate the generative control laws underlying behavior, which could be a useful tool for behavior analysis (Simon, 1996; Braitenberg, 1984).", "startOffset": 167, "endOffset": 199}, {"referenceID": 15, "context": "This model is limited in that its transition functions are linear, state space is discrete, and emission distribution is generally assumed to be Gaussian, although generalizations of the model that fall under the category of dynamic Bayesian networks are more expressive (Murphy, 2002).", "startOffset": 271, "endOffset": 285}, {"referenceID": 7, "context": "Recurrent neural networks (RNNs) have recently been shown to be extremely successful in classifying time series data, especially with the popularization of long short term memory cells (Hochreiter & Schmidhuber, 1997), in applications such as speech recognition (Graves et al., 2013).", "startOffset": 262, "endOffset": 283}, {"referenceID": 8, "context": "RNNs have also been used for generative sequence prediction of handwriting (Graves, 2013) as well as speech synthesis (Chung et al.", "startOffset": 75, "endOffset": 89}, {"referenceID": 4, "context": "RNNs have also been used for generative sequence prediction of handwriting (Graves, 2013) as well as speech synthesis (Chung et al., 2015).", "startOffset": 118, "endOffset": 138}, {"referenceID": 13, "context": "This strategy is used in (Mnih et al., 2015) where an agent is trained to play Atari games, and in (Silver et al.", "startOffset": 25, "endOffset": 44}, {"referenceID": 19, "context": ", 2015) where an agent is trained to play Atari games, and in (Silver et al., 2016) for mastering the game of GO.", "startOffset": 62, "endOffset": 83}, {"referenceID": 18, "context": "Autoencoders (Rumenlhart et al., 1986) have been used in semi-supervised classification to pretrain a network on an auxiliary task, such as denoising, to prevent overfitting on a small number of labeled data (Baldi, 2012).", "startOffset": 13, "endOffset": 38}, {"referenceID": 1, "context": ", 1986) have been used in semi-supervised classification to pretrain a network on an auxiliary task, such as denoising, to prevent overfitting on a small number of labeled data (Baldi, 2012).", "startOffset": 177, "endOffset": 190}, {"referenceID": 16, "context": "Recent work in this area (Rasmus et al., 2015) proposes to train on the primary and auxiliary task concurrently and using lateral connections (Valpola, 2015) between encoding and decoding layers to allow higher layers of the network to focus on high level features.", "startOffset": 25, "endOffset": 46}, {"referenceID": 24, "context": ", 2015) proposes to train on the primary and auxiliary task concurrently and using lateral connections (Valpola, 2015) between encoding and decoding layers to allow higher layers of the network to focus on high level features.", "startOffset": 103, "endOffset": 118}, {"referenceID": 24, "context": "Each discriminative recurrent cell is fully connected with its corresponding generative cell, allowing higher level states to represent higher level information, similar to the idea of Ladder networks (Valpola, 2015).", "startOffset": 201, "endOffset": 216}, {"referenceID": 3, "context": "For our experiments we found that 2-3 levels of recurrent cells with 100-200 units worked well, with f as a gated recurrent unit (GRU) cell (Cho et al., 2014) and g as linear transformation.", "startOffset": 140, "endOffset": 158}, {"referenceID": 17, "context": "Evidence suggests that animal behavior is nondeterministic (Roberts et al., 2016), thus, motion prediction may be better represented as a probability distribution than a function.", "startOffset": 59, "endOffset": 81}, {"referenceID": 8, "context": "This observation has been made by others in the context of modeling real-valued sequences with RNNs, (Graves, 2013) model the output of an RNN as a Gaussian mixture model and (Chung et al.", "startOffset": 101, "endOffset": 115}, {"referenceID": 4, "context": "This observation has been made by others in the context of modeling real-valued sequences with RNNs, (Graves, 2013) model the output of an RNN as a Gaussian mixture model and (Chung et al., 2015) additionally model the hidden recurrent states as random variables.", "startOffset": 175, "endOffset": 195}, {"referenceID": 6, "context": "With the datasets selected for our experiments, listed below, we are interested in answering the following questions: 1) does motion prediction improve action classification, 2) can the model generate realistic simulations (does it learn the sensory-motor control), and 3) can the model discover novel behavioral phenomena? Fly-vs-fly (Eyjolfsdottir et al., 2014) contains pairs of fruit flies engaging in 10 labeled courtshipand aggressive behaviors.", "startOffset": 335, "endOffset": 363}, {"referenceID": 6, "context": "In order to compare our model with methods presented in Eyjolfsdottir et al. (2014), independently of feature representation, we use the 36 features provided with the Fly-vs-Fly dataset.", "startOffset": 56, "endOffset": 84}, {"referenceID": 6, "context": "b) Performance on Fly-vs-Fly compared with results from Eyjolfsdottir et al. (2014). c) Frame-wise confusion for IAM-OnDB and fraction of training examples for each character.", "startOffset": 56, "endOffset": 84}, {"referenceID": 6, "context": "To account for both duration and counting accuracy we use the performance measures described in Eyjolfsdottir et al. (2014), namely the F1 score (harmonic mean of precision and recall), on a per-frame and per-bout level.", "startOffset": 96, "endOffset": 124}, {"referenceID": 6, "context": "Our results show that filtering significantly improves the bout-wise performance and that our performance on the Fly-vs-Fly test set is comparable with that of Eyjolfsdottir et al. (2014), using no handcrafting and no context of future frames (apart from smoothing).", "startOffset": 160, "endOffset": 188}], "year": 2016, "abstractText": "We propose a framework for detecting action patterns from motion sequences and modeling the sensory-motor relationship of animals, using a generative recurrent neural network. The network has a discriminative part (classifying actions) and a generative part (predicting motion), whose recurrent cells are laterally connected, allowing higher levels of the network to represent high level behavioral phenomena. We test our framework on two types of data, fruit fly behavior and online handwriting. Our results show that 1) taking advantage of unlabeled sequences, by predicting future motion, significantly improves action detection performance when training labels are scarce, 2) the network learns to represent high level phenomena such as writer identity and fly gender, without supervision, and 3) simulated motion trajectories, generated by treating motion prediction as input to the network, look realistic and may be used to qualitatively evaluate whether the model has learnt generative control rules.", "creator": "LaTeX with hyperref package"}}}