{"id": "1611.00454", "review": {"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "2-Nov-2016", "title": "Collaborative Recurrent Autoencoder: Recommend while Learning to Fill in the Blanks", "abstract": "Hybrid methods that utilize both content and rating information are commonly used in many recommender systems. However, most of them use either handcrafted features or the bag-of-words representation as a surrogate for the content information but they are neither effective nor natural enough. To address this problem, we develop a collaborative recurrent autoencoder (CRAE) which is a denoising recurrent autoencoder (DRAE) that models the generation of content sequences in the collaborative filtering (CF) setting. The model generalizes recent advances in recurrent deep learning from i.i.d. input to non-i.i.d. (CF-based) input and provides a new denoising scheme along with a novel learnable pooling scheme for the recurrent autoencoder. To do this, we first develop a hierarchical Bayesian model for the DRAE and then generalize it to the CF setting. The synergy between denoising and CF enables CRAE to make accurate recommendations while learning to fill in the blanks in sequences. Experiments on real-world datasets from different domains (CiteULike and Netflix) show that, by jointly modeling the order-aware generation of sequences for the content information and performing CF for the ratings, CRAE is able to significantly outperform the state of the art on both the recommendation task based on ratings and the sequence generation task based on content information. In each case, the algorithms are applied to the CF settings, which are then re-implemented.\n\n\n\nFor more information, see:\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-", "histories": [["v1", "Wed, 2 Nov 2016 02:49:44 GMT  (1258kb,D)", "http://arxiv.org/abs/1611.00454v1", "To appear at NIPS 2016"]], "COMMENTS": "To appear at NIPS 2016", "reviews": [], "SUBJECTS": "cs.LG cs.AI cs.CL cs.CV stat.ML", "authors": ["hao wang 0014", "xingjian shi", "dit-yan yeung"], "accepted": true, "id": "1611.00454"}, "pdf": {"name": "1611.00454.pdf", "metadata": {"source": "CRF", "title": "Collaborative Recurrent Autoencoder: Recommend while Learning to Fill in the Blanks", "authors": ["Hao Wang", "Xingjian Shi", "Dit-Yan Yeung"], "emails": ["hwangaz@cse.ust.hk", "xshiab@cse.ust.hk", "dyyeung@cse.ust.hk"], "sections": [{"heading": "1 Introduction", "text": "With the high prevalence and abundance of Internet services, recommender systems are becoming increasingly important to attract users because they can help users make effective use of the information available. Companies like Netflix have been using recommender systems extensively to target users and promote products. Existing methods for recommender systems can be roughly categorized into three classes [13]: content-based methods that use the user profiles or product descriptions only, collaborative filtering (CF) based methods that use the ratings only, and hybrid methods that make use of both. Hybrid methods using both types of information can get the best of both worlds and, as a result, usually outperform content-based and CF-based methods.\nAmong the hybrid methods, collaborative topic regression (CTR) [21] was proposed to integrate a topic model and probabilistic matrix factorization (PMF) [15]. CTR is an appealing method in that it produces both promising and interpretable results. However, CTR uses a bag-of-words representation and ignores the order of words and the local context around each word, which can provide valuable information when learning article representation and word embeddings. Deep learning models like convolutional neural networks (CNN) which use layers of sliding windows (kernels) have the potential of capturing the order and local context of words. However, the kernel size in a CNN is fixed during training. To achieve good enough performance, sometimes an ensemble of multiple CNNs with different kernel sizes has to be used. A more natural and adaptive way of modeling text sequences would be to use gated recurrent neural network (RNN) models [8, 3, 19]. A gated RNN takes in one\n30th Conference on Neural Information Processing Systems (NIPS 2016), Barcelona, Spain.\nar X\niv :1\n61 1.\n00 45\n4v 1\n[ cs\n.L G\n] 2\nN ov\n2 01\nword (or multiple words) at a time and lets the learned gates decide whether to incorporate or to forget the word. Intuitively, if we can generalize gated RNNs to the CF setting (non-i.i.d.) to jointly model the generation of sequences and the relationship between items and users (rating matrices), the recommendation performance could be significantly boosted.\nNevertheless, very few attempts have been made to develop feedforward deep learning models for CF, let alone recurrent ones. This is due partially to the fact that deep learning models, like many machine learning models, assume i.i.d. inputs. [16, 6, 7] use restricted Boltzmann machines and RNN instead of the conventional matrix factorization (MF) formulation to perform CF. Although these methods involve both deep learning and CF, they actually belong to CF-based methods because they do not incorporate the content information like CTR, which is crucial for accurate recommendation. [14] uses low-rank MF in the last weight layer of a deep network to reduce the number of parameters, but it is for classification instead of recommendation tasks. There have also been nice explorations on music recommendation [10, 26] in which a CNN or deep belief network (DBN) is directly used for content-based recommendation. However, the models are deterministic and less robust since the noise is not explicitly modeled. Besides, the CNN is directly linked to the ratings making the performance suffer greatly when the ratings are sparse, as will be shown later in our experiments. Very recently, collaborative deep learning (CDL) [24] is proposed as a probabilistic model for joint learning of a probabilistic stacked denoising autoencoder (SDAE) [20] and collaborative filtering. However, CDL is a feedforward model that uses bag-of-words as input and it does not model the order-aware generation of sequences. Consequently, the model would have inferior recommendation performance and is not capable of generating sequences at all, which will be shown in our experiments. Besides order-awareness, another drawback of CDL is its lack of robustness (see Section 3.1 and 3.5 for details). To address these problems, we propose a hierarchical Bayesian generative model called collaborative recurrent autoencoder (CRAE) to jointly model the order-aware generation of sequences (in the content information) and the rating information in a CF setting. Our main contributions are:\n\u2022 By exploiting recurrent deep learning collaboratively, CRAE is able to sophisticatedly model the generation of items (sequences) while extracting the implicit relationship between items (and users). We design a novel pooling scheme for pooling variable-length sequences into fixed-length vectors and also propose a new denoising scheme to effectively avoid overfitting. Besides for recommendation, CRAE can also be used to generate sequences on the fly. \u2022 To the best of our knowledge, CRAE is the first model that bridges the gap between RNN and CF, especially with respect to hybrid methods for recommender systems. Besides, the Bayesian nature also enables CRAE to seamlessly incorporate other auxiliary information to further boost the performance. \u2022 Extensive experiments on real-world datasets from different domains show that CRAE can substantially improve on the state of the art."}, {"heading": "2 Problem Statement and Notation", "text": "Similar to [21], the recommendation task considered in this paper takes implicit feedback [9] as the training and test data. There are J items (e.g., articles or movies) in the dataset. For item j, there is a corresponding sequence consisting of Tj words where the vector e (j) t specifies the t-th word using the 1-of-S representation, i.e., a vector of length S with the value 1 in only one element corresponding to the word and 0 in all other elements. Here S is the vocabulary size of the dataset. We define an I-by-J binary rating matrix R = [Rij ]I\u00d7J where I denotes the number of users. For example, in the CiteULike dataset, Rij = 1 if user i has article j in his or her personal library and Rij = 0 otherwise. Given some of the ratings in R and the corresponding sequences of words e(j)t (e.g., titles of articles or plots of movies), the problem is to predict the other ratings in R.\nIn the following sections, e\u2032(j)t denotes the noise-corrupted version of e (j) t and (h (j) t ; s (j) t ) refers to the concatenation of the two KW -dimensional column vectors. All input weights (like Ye and Yie) and recurrent weights (like We and Wie) are of dimensionality KW -by-KW . The output state h (j) t , gate units (e.g., hot (j)), and cell state s(j)t are of dimensionality KW . K is the dimensionality of the final representation \u03b3j , middle-layer units \u03b8j , and latent vectors vj and ui. IK or IKW denotes a K-by-K or KW -by-KW identity matrix. For convenience we use W+ to denote the collection of all weights and biases. Similarly h+t is used to denote the collection of ht, h i t, h f t , and h o t ."}, {"heading": "3 Collaborative Recurrent Autoencoder", "text": "In this section we will first propose a generalization of the RNN called robust recurrent networks (RRN), followed by the introduction of two key concepts, wildcard denoising and beta-pooling, in our model. After that, the generative process of CRAE is provided to show how to generalize the RRN as a hierarchical Bayesian model from an i.i.d. setting to a CF (non-i.i.d.) setting."}, {"heading": "3.1 Robust Recurrent Networks", "text": "One problem with RNN models like long short-term memory networks (LSTM) is that the computation is deterministic without taking the noise into account, which means it is not robust especially with insufficient training data. To address this robustness problem, we propose RRN as a type of noisy gated RNN. In RRN, the gates and other latent variables are designed to incorporate noise, making the model more robust. Note that unlike [4, 5], the noise in RRN is directly propagated back and forth in the network, without the need for using separate neural networks to approximate the distributions of the latent variables. This is much more efficient and easier to implement. Here we provide the generative process of RRN. Using t = 1 . . . Tj to index the words in the sequence, we have (we drop the index j for items for notational simplicity):\nxt\u22121 \u223c N (Wwet\u22121, \u03bb\u22121s IKW ), at\u22121 \u223c N (Yxt\u22121 + Wht\u22121 + b, \u03bb\u22121s IKW ) (1) st \u223c N (\u03c3(hft\u22121) st\u22121 + \u03c3(hit\u22121) \u03c3(at\u22121), \u03bb\u22121s IKW ), (2)\nwhere xt is the word embedding of the t-th word, Ww is a KW -by-S word embedding matrix, et is the 1-of-S representation mentioned above, stands for the element-wise product operation between two vectors, \u03c3(\u00b7) denotes the sigmoid function, st is the cell state of the t-th word, and b, Y, and W denote the biases, input weights, and recurrent weights respectively. The forget gate units hft and the input gate units hit in Equation (2) are drawn from Gaussian distributions depending on their corresponding weights and biases Yf , Wf , Yi, Wi, bf , and bi:\nhft \u223c N (Yfxt + Wfht + bf , \u03bb\u22121s IKW ), hit \u223c N (Yixt + Wiht + bi, \u03bb\u22121s IKW ).\nThe output ht depends on the output gate hot which has its own weights and biases Y o, Wo, and bo:\nhot \u223c N (Yoxt + Woht + bo, \u03bb\u22121s IKW ), ht \u223c N (tanh(st) \u03c3(hot\u22121), \u03bb\u22121s IKW ). (3)\nIn the RRN, information of the processed sequence is contained in the cell states st and the output states ht, both of which are column vectors of lengthKW . Note that RRN can be seen as a generalized and Bayesian version of LSTM [1]. Similar to [19, 3], two RRNs can be concatenated to form an encoder-decoder architecture."}, {"heading": "3.2 Wildcard Denoising", "text": "Since the input and output are identical here, unlike [19, 3] where the input is from the source language and the output is from the target language, this naive RRN autoencoder can suffer from serious overfitting, even after taking noise into account and reversing sequence order (we find that\nreversing sequence order in the decoder [19] does not improve the recommendation performance). One natural way of handling it is to borrow ideas from the denoising autoencoder [20] by randomly dropping some of the words in the encoder. Unfortunately, directly dropping words may mislead the learning of transition between words. For example, if we drop the word \u2018is\u2019 in the sentence \u2018this is a good idea\u2019, the encoder will wrongly learn the subsequence \u2018this a\u2019, which never appears in a grammatically correct sentence. Here we propose another denoising scheme, called wildcard denoising, where a special word \u2018\u3008wildcard\u3009\u2019 is added to the vocabulary and we randomly select some of the words and replace them with \u2018\u3008wildcard\u3009\u2019. This way, the encoder RRN will take \u2018this \u3008wildcard\u3009 a good idea\u2019 as input and successfully avoid learning wrong subsequences. We call this denoising recurrent autoencoder (DRAE). Note that the word \u2018\u3008wildcard\u3009\u2019 also has a corresponding word embedding. Intuitively this wildcard denoising RRN autoencoder learns to fill in the blanks in sentences automatically. We find this denoising scheme much better than the naive one. For example, in dataset CiteULike wildcard denoising can provide a relative accuracy boost of about 20%."}, {"heading": "3.3 Beta-Pooling", "text": "The RRN autoencoders would produce a representation vector for each input word. In order to facilitate the factorization of the rating matrix, we need to pool the sequence of vectors into one single vector of fixed length 2KW before it is further encoded into a K-dimensional vector. A natural way is to use a weighted average of the vectors. Unfortunately different sequences may need weights of different size. For example, pooling a sequence of 8 vectors needs a weight vector with 8 entries while pooling a sequence of 50 vectors needs one with 50 entries. In other words, we need a weight vector of variable length for our pooling scheme. To tackle this problem, we propose to use a beta distribution. If six vectors are to be pooled into one single vector (using weighted average), we can use the area wp in the range (p\u221216 , p 6 ) of the x-axis of the probability density function (PDF) for the beta distribution Beta(a, b) as the pooling weight. Then the resulting pooling weight vector becomes y = (w1, . . . , w6)T . Since the total area is always 1 and the x-axis is bounded, the beta distribution is perfect for this type of variable-length pooling (hence the name beta-pooling). If we set the hyperparameters a = b = 1, it will be equivalent to average pooling. If a is set large enough and b > a the PDF will peak slightly to the left of x = 0.5, which means that the last time step of the encoder RRN is directly used as the pooling result. With only two parameters, beta-pooling is able to pool vectors flexibly enough without having the risk of overfitting the data."}, {"heading": "3.4 CRAE as a Hierarchical Bayesian Model", "text": "Following the notation in Section 2 and using the DRAE in Section 3.2 as a component, we then provide the generative process of the CRAE (note that t indexes words or time steps, j indexes sentences or documents, and Tj is the number of words in document j):\nEncoding (t = 1, 2, . . . , Tj): Generate x \u2032(j) t\u22121, a (j) t\u22121, and s (j) t according to Equation (1)-(2).\nCompression and decompression (t = Tj + 1):\n\u03b8j \u223c N (W1(h(j)Tj ; s (j) Tj ) + b1, \u03bb \u22121 s IK), (h (j) Tj+1 ; s (j) Tj+1 ) \u223c N (W2 tanh(\u03b8j) + b2, \u03bb\u22121s I2KW ). (4)\nDecoding (t = Tj + 2, Tj + 3, . . . , 2Tj + 1): Generate a (j) t\u22121, s (j) t , and h (j) t according to Equation (1)-(3), after which generate:\ne (j) t\u2212Tj\u22122 \u223c Mult(softmax(Wgh (j) t + bg)).\nBeta-pooling and recommendation:\n\u03b3j \u223c N (tanh(W1fa,b({(h (j) t ; s (j) t )}t) + b1), \u03bb\u22121s IK) (5) vj \u223c N (\u03b3j , \u03bb\u22121v IK), ui \u223c N (0, \u03bb\u22121u IK), Rij \u223c N (uTi vj ,C\u22121ij ).\nNote that each column of the weights and biases in W+ is drawn from N (0, \u03bb\u22121w IKW ) or N (0, \u03bb\u22121w IK). In the generative process above, the input gate hit\u22121 (j) and the forget gate hft\u22121 (j) can be drawn as described in Section 3.1. e\u2032(j)t denotes the corrupted word (with the embedding\nx \u2032(j) t ) and e (j) t denotes the original word (with the embedding x (j) t ). \u03bbw, \u03bbu, \u03bbs, and \u03bbv are hyperparameters and Cij is a confidence parameter (Cij = \u03b1 if Rij = 1 and Cij = \u03b2 otherwise). Note that if \u03bbs goes to infinity, the Gaussian distribution (e.g., in Equation (4)) will become a Dirac delta distribution centered at the mean. The compression and decompression act like a bottleneck between two Bayesian RRNs. The purpose is to reduce overfitting, provide necessary nonlinear transformation, and perform dimensionality reduction to obtain a more compact final representation \u03b3j for CF. The graphical model for an example CRAE where Tj = 2 for all j is shown in Figure 1(left). fa,b({(h(j)t ; s (j) t )}t) in Equation (5) is the result of beta-pooling with hyperparameters a and b. If we denote the cumulative distribution function of the beta distribution as F (x; a, b), \u03c6\n(j) t = (h (j) t ; s (j) t ) for t = 1, . . . , Tj , and \u03c6 (j) t = (h (j) t+1; s (j) t+1) for t = Tj + 1, . . . , 2Tj , then we\nhave fa,b({(h(j)t ; s (j) t )}t) = \u22112Tj t=1(F ( t 2Tj\n, a, b) \u2212 F ( t\u221212Tj , a, b))\u03c6t. Please see Section C of the supplementary materials for details (including hyperparameter learning) of beta-pooling. From the generative process, we can see that both CRAE and CDL are Bayesian deep learning (BDL) models (as described in [25]) with a perception component (DRAE in CRAE) and a task-specific component."}, {"heading": "3.5 Learning", "text": "According to the CRAE model above, all parameters like h(j)t and vj can be treated as random variables so that a full Bayesian treatment such as methods based on variational approximation can be used. However, due to the extreme nonlinearity and the CF setting, this kind of treatment is non-trivial. Besides, with CDL [24] and CTR [21] as our primary baselines, it would be fairer to use maximum a posteriori (MAP) estimates, which is what CDL and CTR do.\nEnd-to-end joint learning: Maximization of the posterior probability is equivalent to maximizing the joint log-likelihood of {ui}, {vj}, W+, {\u03b8j}, {\u03b3j}, {e (j) t }, {e \u2032(j) t }, {h+t\n(j)}, {s(j)t }, and R given \u03bbu, \u03bbv , \u03bbw, and \u03bbs:\nL = log p(DRAE|\u03bbs, \u03bbw)\u2212 \u03bbu 2 \u2211 i \u2016ui\u201622 \u2212 \u03bbv 2 \u2211 j \u2016vj \u2212 \u03b3j\u201622 \u2212 \u2211 i,j Cij 2 (Rij \u2212 uTi vj)2\n\u2212 \u03bbs 2 \u2211 j \u2016 tanh(W1fa,b({(h(j)t ; s (j) t )}t) + b1)\u2212 \u03b3j\u201622,\nwhere log p(DRAE|\u03bbs, \u03bbw) corresponds to the prior and likelihood terms for DRAE (including the encoding, compression, decompression, and decoding in Section 3.4) involving W+, {\u03b8j}, {e(j)t }, {e \u2032(j) t }, {h+t\n(j)}, and {s(j)t }. For simplicity and computational efficiency, we can fix the hyperparameters of beta-pooling so that Beta(a, b) peaks slightly to the left of x = 0.5 (e.g., a = 9.8\u00d7 107, b = 1\u00d7 108), which leads to \u03b3j = tanh(\u03b8j) (a treatment for the more general case with learnable a or b is provided in the supplementary materials). Further, if \u03bbs approaches infinity, the terms with \u03bbs in log p(DRAE|\u03bbs, \u03bbw) will vanish and \u03b3j will become tanh(W1(h (j) Tj , s (j) Tj\n)+b1). Figure 1(right) shows the graphical model of a degenerated CRAE when \u03bbs approaches positive infinity and b > a (with very large a and b). Learning this degenerated version of CRAE is equivalent to jointly training a wildcard denoising RRN and an encoding RRN coupled with the rating matrix. If \u03bbv 1, CRAE will further degenerate to a two-step model where the representation \u03b8j learned by the DRAE is directly used for CF. On the contrary if \u03bbv 1, the decoder RRN essentially vanishes. Both extreme cases can greatly degrade the predictive performance, as shown in the experiments.\nRobust nonlinearity on distributions: Different from [24, 23], nonlinear transformation is performed after adding the noise with precision \u03bbs (e.g. a (j) t in Equation (1)). In this case, the input of the nonlinear transformation is a distribution rather than a deterministic value, making the nonlinearity more robust than in [24, 23] and leading to more efficient and direct learning algorithms than CDL.\nConsider a univariate Gaussian distribution N (x|\u00b5, \u03bb\u22121s ) and the sigmoid function \u03c3(x) = 1 1+exp(\u2212x) , the expectation (see Section F of the supplementary materials for details):\nE(x) = \u222b N (x|\u00b5, \u03bb\u22121s )\u03c3(x)dx = \u03c3(\u03ba(\u03bbs)\u00b5), (6)\nEquation (9) holds because the convolution of a sigmoid function with a Gaussian distribution can be approximated by another sigmoid function. Similarly, we can approximate \u03c3(x)2 with \u03c3(\u03c11(x+\u03c10)),\nwhere \u03c11 = 4\u2212 2 \u221a 2 and \u03c10 = \u2212 log( \u221a 2 + 1). Hence the variance\nD(x) \u2248 \u222b N (x|\u00b5, \u03bb\u22121s ) \u25e6 \u03a6(\u03be\u03c11(x+ \u03c10))dx\u2212 E(x)2 = \u03c3( \u03c11(\u00b5+ \u03c10)\n(1 + \u03be2\u03c121\u03bb \u22121 s )1/2\n)\u2212 E(x)2 \u2248 \u03bb\u22121s , (7)\nwhere we use \u03bb\u22121s to approximate D(x) for computational efficiency. Using Equation (9) and (10), the Gaussian distribution in Equation (2) can be computed as:\nN (\u03c3(hft\u22121) st\u22121 + \u03c3(hit\u22121) \u03c3(at\u22121), \u03bb\u22121s IKW )\n\u2248 N (\u03c3(\u03ba(\u03bbs)h f t\u22121) st\u22121 + \u03c3(\u03ba(\u03bbs)h i t\u22121) \u03c3(\u03ba(\u03bbs)at\u22121), \u03bb\u22121s IKW ), (8)\nwhere the superscript (j) is dropped. We use overlines (e.g., at\u22121 = Yext\u22121 + Weht\u22121 + be) to denote the mean of the distribution from which a hidden variable is drawn. By applying Equation (11) recursively, we can compute st for any t. Similar approximation is used for tanh(x) in Equation (3) since tanh(x) = 2\u03c3(2x)\u2212 1. This way the feedforward computation of DRAE would be seamlessly chained together, leading to more efficient learning algorithms than the layer-wise algorithms in [24, 23] (see Section F of the supplementary materials for more details).\nLearning parameters: To learn ui and vj , block coordinate ascent can be used. Given the current W+, we can compute \u03b3 as \u03b3 = tanh(W1fa,b({(h(j)t ; s (j) t )}t) + b1) and get the following update rules:\nui \u2190 (VCiVT + \u03bbuIK)\u22121VCiRi vj \u2190 (UCiUT + \u03bbvIK)\u22121(UCjRj + \u03bbv tanh(W1fa,b({(h(j)t ; s (j) t )}t) + b1)T ),\nwhere U = (ui)Ii=1, V = (vj) J j=1, Ci = diag(Ci1, . . . ,CiJ) is a diagonal matrix, and Ri = (Ri1, . . . ,RiJ) T is a column vector containing all the ratings of user i.\nGiven U and V, W+ can be learned using the back-propagation algorithm according to Equation (9)-(11) and the generative process in Section 3.4. Alternating the update of U, V, and W+ gives a local optimum of L . After U and V are learned, we can predict the ratings as Rij = uTi vj ."}, {"heading": "4 Experiments", "text": "In this section, we report some experiments on real-world datasets from different domains to evaluate the capabilities of recommendation and automatic generation of missing sequences."}, {"heading": "4.1 Datasets", "text": "We use two datasets from different real-world domains. CiteULike is from [21] with 5,551 users and 16,980 items (articles with text). Netflix consists of 407,261 users, 9,228 movies, and 15,348,808 ratings after removing users with less than 3 positive ratings (following [24], ratings larger than 3 are regarded as positive ratings). Please see Section G of the supplementary materials for details."}, {"heading": "4.2 Evaluation Schemes", "text": "Recommendation: For the recommendation task, similar to [22, 24], P items associated with each user are randomly selected to form the training set and the rest is used as the test set. We evaluate the models when the ratings are in different degrees of density (P \u2208 {1, 2, . . . , 5}). For each value of P , we repeat the evaluation five times with different training sets and report the average performance.\nFollowing [21, 22], we use recall as the performance measure since the ratings are in the form of implicit feedback [9, 12]. Specifically, a zero entry may be due to the fact that the user is not interested in the item, or that the user is not aware of its existence. Thus precision is not a suitable performance measure. We sort the predicted ratings of the candidate items and recommend the top M items for the target user. The recall@M for each user is then defined as:\nrecall@M = # items that the user likes among the top M\n# items that the user likes .\nThe average recall over all users is reported.\nWe also use another evaluation metric, mean average precision (mAP), in the experiments. Exactly the same as [10], the cutoff point is set at 500 for each user.\nSequence generation on the fly: For the sequence generation task, we set P = 5. In terms of content information (e.g., movie plots), we randomly select 80% of the items to include their content in the training set. The trained models are then used to predict (generate) the content sequences for the other 20% items. The BLEU score [11] is used to evaluate the quality of generation. To compute the BLEU score in CiteULike we use the titles as training sentences (sequences). Both the titles and sentences in the abstracts of the articles (items) are used as reference sentences. For Netflix, the first sentences of the plots are used as training sentences. The movie names and sentences in the plots are used as reference sentences. A higher BLEU score indicates higher quality of sequence generation. Since CDL, CTR, and PMF cannot generate sequences directly, a nearest neighborhood based approach is used with the resulting vj . Note that this task is extremely difficult because the sequences of the test set are unknown during both the training and testing phases. For this reason, this task is impossible for existing machine translation models like [19, 3]."}, {"heading": "4.3 Baselines and Experimental Settings", "text": "The models for comparison are listed as follows:\n\u2022 CMF: Collective Matrix Factorization [17] is a model incorporating different sources of information by simultaneously factorizing multiple matrices. \u2022 SVDFeature: SVDFeature [2] is a model for feature-based collaborative filtering. In this paper we use the bag-of-words as raw features to feed into SVDFeature. \u2022 DeepMusic: DeepMusic [10] is a feedforward model for music recommendation mentioned in Section 1. We use the best performing variant as our baseline. \u2022 CTR: Collaborative Topic Regression [21] is a model performing topic modeling and collaborative filtering simultaneously as mentioned in the previous section. \u2022 CDL: Collaborative Deep Learning (CDL) [24] is proposed as a probabilistic feedforward model for joint learning of a probabilistic SDAE [20] and CF. \u2022 CRAE: Collaborative Recurrent Autoencoder is our proposed recurrent model. It jointly performs collaborative filtering and learns the generation of content (sequences).\nIn the experiments, we use 5-fold cross validation to find the optimal hyperparameters for CRAE and the baselines. For CRAE, we set \u03b1 = 1, \u03b2 = 0.01, K = 50, KW = 100. The wildcard denoising rate is set to 0.4. See Section E.1 of the supplementary materials for details."}, {"heading": "4.4 Quantitative Comparison", "text": "Recommendation: The first two plots of Figure 2 show the recall@M for the two datasets when P is varied from 1 to 5. As we can see, CTR outperforms the other baselines except for CDL. Note that as previously mentioned, in both datasets DeepMusic suffers badly from overfitting when the rating matrix is extremely sparse (P = 1) and achieves comparable performance with CTR when the rating matrix is dense (P = 5). CDL as the strongest baseline consistently outperforms other baselines. By jointly learning the order-aware generation of content (sequences) and performing collaborative filtering, CRAE is able to outperform all the baselines by a margin of 0.7% \u223c 1.9% (a relative boost of 2.0% \u223c 16.7%) in CiteULike and 3.5% \u223c 6.0% (a relative boost of 5.7% \u223c 22.5%) in Netflix. Note that since the standard deviation is minimal (3.38\u00d7 10\u22125 \u223c 2.56\u00d7 10\u22123), it is not included in the figures and tables to avoid clutter.\nThe last two plots of Figure 2 show the recall@M for CiteULike and Netflix when M varies from 50 to 300 and P = 1. As shown in the plots, the performance of DeepMusic, CMF, and SVDFeature is\nsimilar in this setting. Again CRAE is able to outperform the baselines by a large margin and the margin gets larger with the increase of M .\nAs shown in Figure 4 and Table 5, we also investigate the effect of a and b in beta-pooling and find that in DRAE: (1) temporal average pooling performs poorly (a = b = 1); (2) most information concentrates near the bottleneck; (3) the right of the bottleneck contains more information than the left. Please see Section D of the supplementary materials for more details.\nAs another evaluation metric, Table 2 compares different models based on mAP. As we can see, compared with CDL, CRAE can provide a relative boost of 35% and 10% for CiteULike and Netflix, respectively. Besides quantitative comparison, qualitative comparison of CRAE and CDL is provided in Section B of the supplementary materials. In terms of time cost, CDL needs 200 epochs (40s/epoch) while CRAE needs about 80 epochs (150s/epoch) for optimal performance.\nSequence generation on the fly: To evaluate the ability of sequence generation, we compute the BLEU score of the sequences (titles for CiteULike and plots for Netflix) generated by different models. As mentioned in Section 4.2, this task is impossible for existing machine translation models like [19, 3] due to the lack of source sequences. As we can see in Table 3, CRAE achieves a BLEU score of 46.60 for CiteULike and 48.69 for Netflix, which is much higher than CDL, CTR and PMF. Incorporating the content information when learning user and item latent vectors, CTR is able to outperform other baselines and CRAE can further boost the BLEU score by sophisticatedly and jointly modeling the generation of sequences and ratings. Note that although CDL is able to outperform other baselines in the recommendation task, it performs poorly when generating sequences on the fly, which demonstrates the importance of modeling each sequence recurrently as a whole rather than as separate words."}, {"heading": "5 Conclusions and Future Work", "text": "We develop a collaborative recurrent autoencoder which can sophisticatedly model the generation of item sequences while extracting the implicit relationship between items (and users). We design a new pooling scheme for pooling variable-length sequences and propose a wildcard denoising scheme to effectively avoid overfitting. To the best of our knowledge, CRAE is the first model to bridge the gap between RNN and CF. Extensive experiments show that CRAE can significantly outperform the state-of-the-art methods on both the recommendation and sequence generation tasks.\nWith its Bayesian nature, CRAE can easily be generalized to seamlessly incorporate auxiliary information (e.g., the citation network for CiteULike and the co-director network for Netflix) for further accuracy boost. Moreover, multiple Bayesian recurrent layers may be stacked together to increase its representation power. Besides making recommendations and guessing sequences on the fly, the wildcard denoising recurrent autoencoder also has potential to solve other challenging problems such as recovering the blurred words in ancient documents."}, {"heading": "A Learning Beta-Pooling", "text": "As mentioned in the paper, fa,b({(h(j)t ; s (j) t )}t) is the result of beta-pooling. The cumulative distribution function of the beta distribution F (x; a, b) = B(x;a,b)B(a,b) = Ix(a, b), where B(x; a, b) =\u222b x 0 ta\u22121(1\u2212 t)b\u22121dt is the incomplete beta function and the denominator B(a, b) = \u0393(a+b)\u0393(a) \u0393(b) . \u0393(\u00b7) is the gamma function and Ix(a, b) is also called the regularized incomplete beta function. If we denote \u03c6(j)t = (h (j) t ; s (j) t ) for t = 1, . . . , Tj and \u03c6 (j) t = (h (j) t+1; s (j) t+1) for t = Tj + 1, . . . , 2Tj , we\nhave fa,b({(h(j)t ; s (j) t )}t) = 2Tj\u2211 t=1 (I t 2Tj (a, b)\u2212 I t\u22121 2Tj (a, b))\u03c6t. Written this way, we can evaluate the gradient of L with respect to a and b and use gradient-based methods to learn them. To illustrate it more clearly, if we take \u03bbs to positive infinity, fix b = 1 and try to learn the optimal value of a, we can maximize the following joint log-likelihood:\nL =\u2212 \u2211 i,j Cij 2 (Rij \u2212 uTi vj)2 \u2212 \u03bbv 2 \u2211 j \u2016vj \u2212 tanh(W1 2Tj\u2211 t=1 [I t 2Tj (a, 1)\u2212 I t\u22121 2Tj (a, 1)]\u03c6t + b1)\u2016 2 2\n+ \u2211 j 2Tj+1\u2211 t=Tj+2 H(e (j) t\u2212Tj\u22121, softmax(Wgh (j) t + bg))\u2212 \u03bbu 2 \u2211 i \u2016ui\u201622 \u2212 \u03bbw 2 g(W+).\nNote that H(\u00b7, \u00b7) denotes the cross-entropy loss for generating words from Mult(softmax(Wgh(j)t + bg)). The term \u2212\u03bbw2 g(W\n+) corresponds to the prior of all weights and biases. Using the property of the regularized incomplete beta function that Ix(a, 1) = xa, the joint log-likelihood can be simplified to\nL =\u2212 \u03bbv 2 \u2211 j \u2016vj \u2212 tanh(W1 2Tj\u2211 t=1 [( t 2Tj ) a \u2212 ( t\u2212 1 2Tj ) a ]\u03c6t + b1)\u2016 2 2 \u2212 \u03bbu 2 \u2211 i \u2016ui\u201622\n\u2212 \u2211 i,j Cij 2 (Rij \u2212 uTi vj)2 + \u2211 j 2Tj+1\u2211 t=Tj+2 H(e (j) t\u2212Tj\u22121, softmax(Wgh (j) t + bg))\u2212 \u03bbw 2 g(W+),\nwhere a only appears in the exponents of ( t2Tj ) a and ( t\u221212Tj ) a, which means we can easily get the gradient of L with respect to a using the chain rule. After each epoch or minibatch, a can be updated based on the gradient with the same learning rate."}, {"heading": "B Qualitative Comparison", "text": "In order to gain a better insight into CRAE, we train CRAE and CDL in the sparsest setting (P = 1) with dataset CiteULike and use them to recommend articles for two example users. The corresponding articles for the target users in the training set and the top 10 recommended articles are shown in Table 4. Note that in the sparsest setting the recommendation task is extremely challenging since there is only one single article for each user in the training set.\nAs we can see, CRAE successfully identified User I as a researcher working on information retrieval with interest in user modeling using user feedback. Consequently, CRAE achieves a high precision of 60% by focusing its recommendations on articles about information retrieval, user modeling, and relevance feedback. On the other hand, the topics of articles recommended by CDL span from visual tracking (Article 4) to bioinformatics (Article 3) and programming language (Article 8). One possible reason is that CDL uses the bag-of-words representation as input and consider each word separately without taking into account the local context of words. For example, looking into CDL\u2019s recommendations more closely, we can find that Article 3 (on bioinformatics) and Article 4 (on visual tracking) are actually irrelevant to the training article \u2018Bayesian adaptive user profiling with explicit and implicit feedback\u2019. CDL probably recommends Article 3 because the word \u2018profiles\u2019 in the title overlaps with the article in the training set. The same thing happens for Article 4 with a word \u2018Bayesian\u2019. With the recurrent learning in CRAE, a sequence is modeled as a whole instead of separate words. As a result, with the local context of each word taken into consideration, CRAE can recognize the whole phrase \u2018user profiling\u2019, rather than \u2018user\u2019 or \u2018profiling\u2019, as a theme of the article.\nA similar phenomenon is found for User II with the article \u2018Taxonomy of trust: categorizing P2P reputation systems\u2019. CDL\u2019s recommendations bet on the single word \u2018systems\u2019 while CRAE identified the article to be on trust propagation from the words \u2018trust\u2019 and \u2018P2P\u2019. In the end, CRAE achieves a precision of 30% and CDL\u2019s precision is 10%."}, {"heading": "C Motivation of Beta-Pooling", "text": "The function fa,b({(h(j)t ; s (j) t )}t) is to pool the output states h (j) t and the cell states s (j) t of 2Tj steps (a 2KW -by-2Tj matrix) into a single vector of length 2KW . If we denote the cumulative distribution function of the beta distribution as F (x; a, b), \u03c6(j)t = (h (j) t ; s (j) t ) for t = 1, . . . , Tj , and \u03c6 (j) t = (h (j) t+1; s (j) t+1) for t = Tj + 1, . . . , 2Tj , then we have\nfa,b({(h(j)t ; s (j) t )}t) = 2Tj\u2211 t=1 (F ( t 2Tj , a, b)\u2212 F ( t\u2212 1 2Tj , a, b))\u03c6t.\nNote that a and b are hyperparameters here. In a generalized setting, they can be learned automatically. Essentially the motivation of beta-pooling is to handle the variable length for different sequences using one unified distribution.\nWhen a = 2 and b = 3, the beta-pooling is close to average pooling but with larger weights to the left of the center (the bottleneck). Following the generative process, the output h(j)t and cell states\ns (j) t of each word are concatenated into (h (j) t ; s (j) t ). For each sequence, (h (j) t ; s (j) t ) of all timesteps are beta-pooled into a vector of length 2KW . The vector is then further encoded into the vector \u03b3j of length K, which is used to guide the CF for the rating matrix. Since the information flows in both ways, the rating matrix can, in return, provide useful information when the wildcard denoising recurrent autoencoder tries to learn to fill in the blanks. This two-way interaction enables both tasks (recommendation task and sequence generation task) to benefit from each other and results in more effective representation \u03b8j for each item.\nNote that the compression layer and the beta-pooling share the same weights and biases. If the hyperparameters of beta-pooling are fixed so that Beta(a, b) peaks slightly to the left of x = 0.5, the generation of \u03b3j in the generative process is equivalent to directly setting \u03b3j = tanh(\u03b8j) where \u03b8j is the compressed representation we get from the compression layer. For example, Beta(a, b) peaks slightly to the left of x = 0.5 (near x = 716 ) when a = 7778, b = 10000, and Tj = 4. The only time step that interacts with the rating matrix is the one when t = 4, which is encoded into \u03b8j and connected to the item latent vector vj ."}, {"heading": "D Experiments on Beta-Pooling and Wildcard Denoising", "text": "As mentioned in the paper, beta-pooling is able to pool a sequence of 2Tj vectors into one single vector of the same size. Note that Tj here can vary for different j. Hyperparameters a and b control the behavior of beta-pooling. When a = b = 1, beta-pooling is equivalent to temporal average pooling that takes the average of the 2Tj vectors. In an extreme case, a and b can be set such that the pooling result is equal to one of the 2Tj vectors (e.g., the Tj-th vector). Figure 4 shows the shape of the beta distribution for different a and b. Table 5 shows the corresponding recall for different beta distributions in CiteULike. As we can see, the average pooling in Figure 4(d) and the pooling with an inverted bell curve in Figure 4(e) perform poorly. On the other hand, distributions in Figure 4(a), (b), (g), and (h) yield the highest accuracy, which means most information concentrates near the bottleneck (middle) of DRAE. Among them, the distributions in Figure 4(b) and (g) outperform those in Figure 4(a) and (h). This shows that simply setting the pooling result to be the middle vector is not good enough and an aggregation of vectors near the middle would be a better choice. Comparing distributions in Figure 4(b) and (g), it can be seen that the latter slightly outperforms the former, probably because there are no input words in the decoder part of DRAE (as shown in the graphical model of CRAE), which makes the hidden and cell states in the decoder part more representative. Similar phenomena happen for Figure 4(a), (c), (f), and (h).\nNote that since CRAE is a joint model, the information flows both ways through beta-pooling. For example, when a = 400 and b = 311, the item representations used for recommendation mostly come from the cell and output states near the bottleneck and in return, the rating information affects the learning of DRAE mainly through the cell and output states near the bottleneck.\nAs mentioned in the paper, for the wildcard denoising scheme, we find that in CiteULike, CRAE performs best with a wildcard denoising rate of 0.4, achieving a recall@300 of 12.71% while the number for CRAE with conventional denoising [20] (dropping words completely) is 10.53% (slightly better than CDL). For reference, the recall of CRAE without any denoising is 9.14%. Similar phenomena are found in Netflix.\nNote that DRAE is a much more general model than RNN autoencoders like [19, 18]. We also try reversing the order of each sequence in the decoder RNN as in [19, 18], but the performance only changes slightly."}, {"heading": "E Hyperparameters", "text": "We provide more details on the hyperparameters in this section.\nE.1 Hyperparameter Settings\nThe vocabulary size S (with the word \u3008wildcard\u3009 included) is 15,050 and 17,949 for CiteULike and Netflix respectively. For CMF and SVDFeature, optimal regularization hyperparameters are used for different P . The learning rate is set to 0.005 for SVDFeature. For DeepMusic, we find that the best performance is achieved using a CNN with two convolutional layers. For CTR, we find that it can achieve good prediction performance when \u03bbu = 0.1, \u03bbv = 10, and K = 50. For CDL, we use similar hyperparameters as mentioned in [24]. The denoising rate is set to 0.3. Dropout rate, \u03bbu, \u03bbv, and \u03bbn are set using the validation sets. For the sequence generation task, we postprocess the generated sequences by deleting consecutive repeated words (e.g., the word \u2018like\u2019 in the sentence \u2018I like like this idea\u2019), as often done in RNN-based sentence generation models.\nE.2 Hyperparameter Sensitivity\nFigure 5 shows the recall@M for CiteULike when \u03bbv is from 0.001 to 10 (P = 5). As mentioned in the paper, when \u03bbv 1 CRAE degenerates to a two-step model with no joint learning on the content sequences and ratings. If \u03bbv 1 the decoder side of CRAE will essentially vanish. Apparently the performance suffers a lot in both extremes, which shows the effectiveness of joint learning in the full CRAE model."}, {"heading": "F Robust Nonlinearity on Distributions", "text": "Different from [24], nonlinear transformation is performed after adding the noise with precision \u03bbs. In this case, the input of the nonlinear transformation is a distribution rather than a deterministic value, making the nonlinearity more robust than in [24] and leading to more efficient and direct learning algorithms than CDL.\nConsider a univariate Gaussian distribution N (x|\u00b5, \u03bb\u22121s ) and the sigmoid function \u03c3(x) = 1 1+exp(\u2212x) , the expectation:\nE(x) = \u222b N (x|\u00b5, \u03bb\u22121s )\u03c3(x)dx\n\u2248 \u222b N (x|\u00b5, \u03bb\u22121s )\u03a6(\u03bex)dx\n= \u03a6(\u03be\u03ba(\u03bbs)\u00b5) = \u03c3(\u03ba(\u03bbs)\u00b5), (9) where the probit function \u03a6(x) = \u222b x \u2212\u221eN (\u03b8|0, 1)d\u03b8, \u03ba(\u03bbs) = (1 + \u03be 2\u03bb\u22121s ) \u2212 12 , and \u03a6(\u03bex), with \u03be2 = \u03c08 , is to approximate \u03c3(x) by matching the slope at the origin. Equation (9) holds because the\nconvolution of a probit function with a Gaussian distribution is another probit function. Similarly, we can approximate \u03c3(x)2 with \u03c3(\u03c11(x+ \u03c10)) by matching both the value and the slope at the origin, where \u03c11 = 4\u2212 2 \u221a 2 and \u03c10 = \u2212 log( \u221a 2 + 1). Hence the variance\nD(x) \u2248 \u222b N (x|\u00b5, \u03bb\u22121s ) \u25e6 \u03a6(\u03be\u03c11(x+ \u03c10))dx\u2212 E(x)2\n= \u03c3( \u03c11(\u00b5+ \u03c10)\n(1 + \u03be2\u03c121\u03bb \u22121 s )1/2\n)\u2212 E(x)2 \u2248 \u03bb\u22121s , (10)\nwhere we use \u03bb\u22121s to approximate D(x) for computational efficiency. Using Equation (9) and (10), the Gaussian distribution in for generating st can be computed as:\nN (\u03c3(hft\u22121) st\u22121 + \u03c3(hit\u22121) \u03c3(at\u22121), \u03bb\u22121s IKW )\n\u2248 N (\u03c3(\u03ba(\u03bbs)h f t\u22121) st\u22121 + \u03c3(\u03ba(\u03bbs)h i t\u22121) \u03c3(\u03ba(\u03bbs)at\u22121), \u03bb\u22121s IKW ), (11)\nwhere the superscript (j) is dropped for clarity. We use overlines (e.g., at\u22121 = Yext\u22121 +Weht\u22121 + be) to denote the mean of the distribution from which a hidden variable is drawn. By applying Equation (11) recursively, we can compute st for any t. Similarly, since tanh(x) = 2\u03c3(2x)\u2212 1, we have:\nE(x) = \u222b N (x|\u00b5, \u03bb\u22121s ) tanh(x)dx\n\u2248 2\u03c3(x(0.25 + \u03be2\u03bb\u22121s )\u2212 1 2 )\u2212 1, (12)\nwhich could be used to approximate h(j)t \u223c N (tanh(s (j) t ) \u03c3(hot\u22121 (j)), \u03bb\u22121s IKW ). This way the feedforward computation of DRAE would be seamlessly chained together, leading to more efficient learning algorithms than the layer-wise algorithms in [24]."}, {"heading": "G Datasets", "text": "We use two datasets from different real-world domains, one from CiteULike 1 and the other from Netflix. The first dataset, CiteULike, is from [21] with 5,551 users and 16,980 items (articles). The titles of the articles are used as content information (sequences of words) in our model. The second dataset, Netflix, consists of both movie ratings from the users and the plots (content information) for the movies. After removing users with less than 3 positive ratings (following [24], ratings larger than 3 are regarded as positive ratings) and movies without plots, we get 407,261 users, 9,228 movies, and 15,348,808 ratings in the final dataset."}], "references": [{"title": "Deep learning. Book in preparation for", "author": ["Y. Bengio", "I.J. Goodfellow", "A. Courville"], "venue": null, "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2015}, {"title": "SVDFeature: a toolkit for feature-based collaborative filtering", "author": ["T. Chen", "W. Zhang", "Q. Lu", "K. Chen", "Z. Zheng", "Y. Yu"], "venue": null, "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2012}, {"title": "Learning phrase representations using RNN encoder-decoder for statistical machine translation", "author": ["K. Cho", "B. van Merrienboer", "C. Gulcehre", "D. Bahdanau", "F. Bougares", "H. Schwenk", "Y. Bengio"], "venue": "In EMNLP,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2014}, {"title": "A recurrent latent variable model for sequential data", "author": ["J. Chung", "K. Kastner", "L. Dinh", "K. Goel", "A.C. Courville", "Y. Bengio"], "venue": "In NIPS,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2015}, {"title": "Variational recurrent auto-encoders", "author": ["O. Fabius", "J.R. van Amersfoort"], "venue": "arXiv preprint arXiv:1412.6581,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2014}, {"title": "A non-iid framework for collaborative filtering with restricted Boltzmann machines", "author": ["K. Georgiev", "P. Nakov"], "venue": "In ICML,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2013}, {"title": "Session-based recommendations with recurrent neural networks", "author": ["B. Hidasi", "A. Karatzoglou", "L. Baltrunas", "D. Tikk"], "venue": "arXiv preprint arXiv:1511.06939,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2015}, {"title": "Long short-term memory", "author": ["S. Hochreiter", "J. Schmidhuber"], "venue": "Neural Computation,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 1997}, {"title": "Collaborative filtering for implicit feedback datasets", "author": ["Y. Hu", "Y. Koren", "C. Volinsky"], "venue": "In ICDM,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2008}, {"title": "Deep content-based music recommendation", "author": ["A.V.D. Oord", "S. Dieleman", "B. Schrauwen"], "venue": "In NIPS,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2013}, {"title": "BLEU: a method for automatic evaluation of machine translation", "author": ["K. Papineni", "S. Roukos", "T. Ward", "W.-J. Zhu"], "venue": "In ACL,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2002}, {"title": "BPR: Bayesian personalized ranking from implicit feedback", "author": ["S. Rendle", "C. Freudenthaler", "Z. Gantner", "L. Schmidt-Thieme"], "venue": "In UAI,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2009}, {"title": "Introduction to Recommender Systems Handbook", "author": ["F. Ricci", "L. Rokach", "B. Shapira"], "venue": null, "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2011}, {"title": "Low-rank matrix factorization for deep neural network training with high-dimensional output targets", "author": ["T.N. Sainath", "B. Kingsbury", "V. Sindhwani", "E. Arisoy", "B. Ramabhadran"], "venue": "In ICASSP,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2013}, {"title": "Probabilistic matrix factorization", "author": ["R. Salakhutdinov", "A. Mnih"], "venue": "In NIPS,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2007}, {"title": "Restricted Boltzmann machines for collaborative filtering", "author": ["R. Salakhutdinov", "A. Mnih", "G.E. Hinton"], "venue": "In ICML,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2007}, {"title": "Relational learning via collective matrix factorization", "author": ["A.P. Singh", "G.J. Gordon"], "venue": "In KDD,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2008}, {"title": "Unsupervised learning of video representations using lstms", "author": ["N. Srivastava", "E. Mansimov", "R. Salakhutdinov"], "venue": "In ICML,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2015}, {"title": "Sequence to sequence learning with neural networks", "author": ["I. Sutskever", "O. Vinyals", "Q.V. Le"], "venue": "In NIPS,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2014}, {"title": "Stacked denoising autoencoders: Learning useful representations in a deep network with a local denoising criterion", "author": ["P. Vincent", "H. Larochelle", "I. Lajoie", "Y. Bengio", "P.-A. Manzagol"], "venue": null, "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2010}, {"title": "Collaborative topic modeling for recommending scientific articles", "author": ["C. Wang", "D.M. Blei"], "venue": "In KDD,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2011}, {"title": "Collaborative topic regression with social regularization for tag recommendation", "author": ["H. Wang", "B. Chen", "W.-J. Li"], "venue": "In IJCAI,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2013}, {"title": "Relational stacked denoising autoencoder for tag recommendation", "author": ["H. Wang", "X. Shi", "D. Yeung"], "venue": "In AAAI,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2015}, {"title": "Collaborative deep learning for recommender systems", "author": ["H. Wang", "N. Wang", "D. Yeung"], "venue": "In KDD,", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2015}, {"title": "Towards Bayesian deep learning: A framework and some existing methods", "author": ["H. Wang", "D. Yeung"], "venue": null, "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2016}, {"title": "Improving content-based and hybrid music recommendation using deep learning", "author": ["X. Wang", "Y. Wang"], "venue": "In ACM MM,", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2014}], "referenceMentions": [{"referenceID": 12, "context": "Existing methods for recommender systems can be roughly categorized into three classes [13]: content-based methods that use the user profiles or product descriptions only, collaborative filtering (CF) based methods that use the ratings only, and hybrid methods that make use of both.", "startOffset": 87, "endOffset": 91}, {"referenceID": 20, "context": "Among the hybrid methods, collaborative topic regression (CTR) [21] was proposed to integrate a topic model and probabilistic matrix factorization (PMF) [15].", "startOffset": 63, "endOffset": 67}, {"referenceID": 14, "context": "Among the hybrid methods, collaborative topic regression (CTR) [21] was proposed to integrate a topic model and probabilistic matrix factorization (PMF) [15].", "startOffset": 153, "endOffset": 157}, {"referenceID": 7, "context": "A more natural and adaptive way of modeling text sequences would be to use gated recurrent neural network (RNN) models [8, 3, 19].", "startOffset": 119, "endOffset": 129}, {"referenceID": 2, "context": "A more natural and adaptive way of modeling text sequences would be to use gated recurrent neural network (RNN) models [8, 3, 19].", "startOffset": 119, "endOffset": 129}, {"referenceID": 18, "context": "A more natural and adaptive way of modeling text sequences would be to use gated recurrent neural network (RNN) models [8, 3, 19].", "startOffset": 119, "endOffset": 129}, {"referenceID": 15, "context": "[16, 6, 7] use restricted Boltzmann machines and RNN instead of the conventional matrix factorization (MF) formulation to perform CF.", "startOffset": 0, "endOffset": 10}, {"referenceID": 5, "context": "[16, 6, 7] use restricted Boltzmann machines and RNN instead of the conventional matrix factorization (MF) formulation to perform CF.", "startOffset": 0, "endOffset": 10}, {"referenceID": 6, "context": "[16, 6, 7] use restricted Boltzmann machines and RNN instead of the conventional matrix factorization (MF) formulation to perform CF.", "startOffset": 0, "endOffset": 10}, {"referenceID": 13, "context": "[14] uses low-rank MF in the last weight layer of a deep network to reduce the number of parameters, but it is for classification instead of recommendation tasks.", "startOffset": 0, "endOffset": 4}, {"referenceID": 9, "context": "There have also been nice explorations on music recommendation [10, 26] in which a CNN or deep belief network (DBN) is directly used for content-based recommendation.", "startOffset": 63, "endOffset": 71}, {"referenceID": 25, "context": "There have also been nice explorations on music recommendation [10, 26] in which a CNN or deep belief network (DBN) is directly used for content-based recommendation.", "startOffset": 63, "endOffset": 71}, {"referenceID": 23, "context": "Very recently, collaborative deep learning (CDL) [24] is proposed as a probabilistic model for joint learning of a probabilistic stacked denoising autoencoder (SDAE) [20] and collaborative filtering.", "startOffset": 49, "endOffset": 53}, {"referenceID": 19, "context": "Very recently, collaborative deep learning (CDL) [24] is proposed as a probabilistic model for joint learning of a probabilistic stacked denoising autoencoder (SDAE) [20] and collaborative filtering.", "startOffset": 166, "endOffset": 170}, {"referenceID": 20, "context": "Similar to [21], the recommendation task considered in this paper takes implicit feedback [9] as the training and test data.", "startOffset": 11, "endOffset": 15}, {"referenceID": 8, "context": "Similar to [21], the recommendation task considered in this paper takes implicit feedback [9] as the training and test data.", "startOffset": 90, "endOffset": 93}, {"referenceID": 3, "context": "Note that unlike [4, 5], the noise in RRN is directly propagated back and forth in the network, without the need for using separate neural networks to approximate the distributions of the latent variables.", "startOffset": 17, "endOffset": 23}, {"referenceID": 4, "context": "Note that unlike [4, 5], the noise in RRN is directly propagated back and forth in the network, without the need for using separate neural networks to approximate the distributions of the latent variables.", "startOffset": 17, "endOffset": 23}, {"referenceID": 0, "context": "Note that RRN can be seen as a generalized and Bayesian version of LSTM [1].", "startOffset": 72, "endOffset": 75}, {"referenceID": 18, "context": "Similar to [19, 3], two RRNs can be concatenated to form an encoder-decoder architecture.", "startOffset": 11, "endOffset": 18}, {"referenceID": 2, "context": "Similar to [19, 3], two RRNs can be concatenated to form an encoder-decoder architecture.", "startOffset": 11, "endOffset": 18}, {"referenceID": 18, "context": "Since the input and output are identical here, unlike [19, 3] where the input is from the source language and the output is from the target language, this naive RRN autoencoder can suffer from serious overfitting, even after taking noise into account and reversing sequence order (we find that", "startOffset": 54, "endOffset": 61}, {"referenceID": 2, "context": "Since the input and output are identical here, unlike [19, 3] where the input is from the source language and the output is from the target language, this naive RRN autoencoder can suffer from serious overfitting, even after taking noise into account and reversing sequence order (we find that", "startOffset": 54, "endOffset": 61}, {"referenceID": 18, "context": "reversing sequence order in the decoder [19] does not improve the recommendation performance).", "startOffset": 40, "endOffset": 44}, {"referenceID": 19, "context": "One natural way of handling it is to borrow ideas from the denoising autoencoder [20] by randomly dropping some of the words in the encoder.", "startOffset": 81, "endOffset": 85}, {"referenceID": 24, "context": "From the generative process, we can see that both CRAE and CDL are Bayesian deep learning (BDL) models (as described in [25]) with a perception component (DRAE in CRAE) and a task-specific component.", "startOffset": 120, "endOffset": 124}, {"referenceID": 23, "context": "Besides, with CDL [24] and CTR [21] as our primary baselines, it would be fairer to use maximum a posteriori (MAP) estimates, which is what CDL and CTR do.", "startOffset": 18, "endOffset": 22}, {"referenceID": 20, "context": "Besides, with CDL [24] and CTR [21] as our primary baselines, it would be fairer to use maximum a posteriori (MAP) estimates, which is what CDL and CTR do.", "startOffset": 31, "endOffset": 35}, {"referenceID": 23, "context": "Robust nonlinearity on distributions: Different from [24, 23], nonlinear transformation is performed after adding the noise with precision \u03bbs (e.", "startOffset": 53, "endOffset": 61}, {"referenceID": 22, "context": "Robust nonlinearity on distributions: Different from [24, 23], nonlinear transformation is performed after adding the noise with precision \u03bbs (e.", "startOffset": 53, "endOffset": 61}, {"referenceID": 23, "context": "In this case, the input of the nonlinear transformation is a distribution rather than a deterministic value, making the nonlinearity more robust than in [24, 23] and leading to more efficient and direct learning algorithms than CDL.", "startOffset": 153, "endOffset": 161}, {"referenceID": 22, "context": "In this case, the input of the nonlinear transformation is a distribution rather than a deterministic value, making the nonlinearity more robust than in [24, 23] and leading to more efficient and direct learning algorithms than CDL.", "startOffset": 153, "endOffset": 161}, {"referenceID": 23, "context": "This way the feedforward computation of DRAE would be seamlessly chained together, leading to more efficient learning algorithms than the layer-wise algorithms in [24, 23] (see Section F of the supplementary materials for more details).", "startOffset": 163, "endOffset": 171}, {"referenceID": 22, "context": "This way the feedforward computation of DRAE would be seamlessly chained together, leading to more efficient learning algorithms than the layer-wise algorithms in [24, 23] (see Section F of the supplementary materials for more details).", "startOffset": 163, "endOffset": 171}, {"referenceID": 20, "context": "CiteULike is from [21] with 5,551 users and 16,980 items (articles with text).", "startOffset": 18, "endOffset": 22}, {"referenceID": 23, "context": "Netflix consists of 407,261 users, 9,228 movies, and 15,348,808 ratings after removing users with less than 3 positive ratings (following [24], ratings larger than 3 are regarded as positive ratings).", "startOffset": 138, "endOffset": 142}, {"referenceID": 21, "context": "Recommendation: For the recommendation task, similar to [22, 24], P items associated with each user are randomly selected to form the training set and the rest is used as the test set.", "startOffset": 56, "endOffset": 64}, {"referenceID": 23, "context": "Recommendation: For the recommendation task, similar to [22, 24], P items associated with each user are randomly selected to form the training set and the rest is used as the test set.", "startOffset": 56, "endOffset": 64}, {"referenceID": 20, "context": "Following [21, 22], we use recall as the performance measure since the ratings are in the form of implicit feedback [9, 12].", "startOffset": 10, "endOffset": 18}, {"referenceID": 21, "context": "Following [21, 22], we use recall as the performance measure since the ratings are in the form of implicit feedback [9, 12].", "startOffset": 10, "endOffset": 18}, {"referenceID": 8, "context": "Following [21, 22], we use recall as the performance measure since the ratings are in the form of implicit feedback [9, 12].", "startOffset": 116, "endOffset": 123}, {"referenceID": 11, "context": "Following [21, 22], we use recall as the performance measure since the ratings are in the form of implicit feedback [9, 12].", "startOffset": 116, "endOffset": 123}, {"referenceID": 9, "context": "Exactly the same as [10], the cutoff point is set at 500 for each user.", "startOffset": 20, "endOffset": 24}, {"referenceID": 10, "context": "The BLEU score [11] is used to evaluate the quality of generation.", "startOffset": 15, "endOffset": 19}, {"referenceID": 18, "context": "For this reason, this task is impossible for existing machine translation models like [19, 3].", "startOffset": 86, "endOffset": 93}, {"referenceID": 2, "context": "For this reason, this task is impossible for existing machine translation models like [19, 3].", "startOffset": 86, "endOffset": 93}, {"referenceID": 16, "context": "The models for comparison are listed as follows: \u2022 CMF: Collective Matrix Factorization [17] is a model incorporating different sources of information by simultaneously factorizing multiple matrices.", "startOffset": 88, "endOffset": 92}, {"referenceID": 1, "context": "\u2022 SVDFeature: SVDFeature [2] is a model for feature-based collaborative filtering.", "startOffset": 25, "endOffset": 28}, {"referenceID": 9, "context": "\u2022 DeepMusic: DeepMusic [10] is a feedforward model for music recommendation mentioned in Section 1.", "startOffset": 23, "endOffset": 27}, {"referenceID": 20, "context": "\u2022 CTR: Collaborative Topic Regression [21] is a model performing topic modeling and collaborative filtering simultaneously as mentioned in the previous section.", "startOffset": 38, "endOffset": 42}, {"referenceID": 23, "context": "\u2022 CDL: Collaborative Deep Learning (CDL) [24] is proposed as a probabilistic feedforward model for joint learning of a probabilistic SDAE [20] and CF.", "startOffset": 41, "endOffset": 45}, {"referenceID": 19, "context": "\u2022 CDL: Collaborative Deep Learning (CDL) [24] is proposed as a probabilistic feedforward model for joint learning of a probabilistic SDAE [20] and CF.", "startOffset": 138, "endOffset": 142}, {"referenceID": 18, "context": "2, this task is impossible for existing machine translation models like [19, 3] due to the lack of source sequences.", "startOffset": 72, "endOffset": 79}, {"referenceID": 2, "context": "2, this task is impossible for existing machine translation models like [19, 3] due to the lack of source sequences.", "startOffset": 72, "endOffset": 79}, {"referenceID": 19, "context": "71% while the number for CRAE with conventional denoising [20] (dropping words completely) is 10.", "startOffset": 58, "endOffset": 62}, {"referenceID": 18, "context": "Note that DRAE is a much more general model than RNN autoencoders like [19, 18].", "startOffset": 71, "endOffset": 79}, {"referenceID": 17, "context": "Note that DRAE is a much more general model than RNN autoencoders like [19, 18].", "startOffset": 71, "endOffset": 79}, {"referenceID": 18, "context": "We also try reversing the order of each sequence in the decoder RNN as in [19, 18], but the performance only changes slightly.", "startOffset": 74, "endOffset": 82}, {"referenceID": 17, "context": "We also try reversing the order of each sequence in the decoder RNN as in [19, 18], but the performance only changes slightly.", "startOffset": 74, "endOffset": 82}, {"referenceID": 23, "context": "For CDL, we use similar hyperparameters as mentioned in [24].", "startOffset": 56, "endOffset": 60}, {"referenceID": 23, "context": "Different from [24], nonlinear transformation is performed after adding the noise with precision \u03bbs.", "startOffset": 15, "endOffset": 19}, {"referenceID": 23, "context": "In this case, the input of the nonlinear transformation is a distribution rather than a deterministic value, making the nonlinearity more robust than in [24] and leading to more efficient and direct learning algorithms than CDL.", "startOffset": 153, "endOffset": 157}, {"referenceID": 23, "context": "This way the feedforward computation of DRAE would be seamlessly chained together, leading to more efficient learning algorithms than the layer-wise algorithms in [24].", "startOffset": 163, "endOffset": 167}, {"referenceID": 20, "context": "The first dataset, CiteULike, is from [21] with 5,551 users and 16,980 items (articles).", "startOffset": 38, "endOffset": 42}, {"referenceID": 23, "context": "After removing users with less than 3 positive ratings (following [24], ratings larger than 3 are regarded as positive ratings) and movies without plots, we get 407,261 users, 9,228 movies, and 15,348,808 ratings in the final dataset.", "startOffset": 66, "endOffset": 70}], "year": 2016, "abstractText": "Hybrid methods that utilize both content and rating information are commonly used in many recommender systems. However, most of them use either handcrafted features or the bag-of-words representation as a surrogate for the content information but they are neither effective nor natural enough. To address this problem, we develop a collaborative recurrent autoencoder (CRAE) which is a denoising recurrent autoencoder (DRAE) that models the generation of content sequences in the collaborative filtering (CF) setting. The model generalizes recent advances in recurrent deep learning from i.i.d. input to non-i.i.d. (CF-based) input and provides a new denoising scheme along with a novel learnable pooling scheme for the recurrent autoencoder. To do this, we first develop a hierarchical Bayesian model for the DRAE and then generalize it to the CF setting. The synergy between denoising and CF enables CRAE to make accurate recommendations while learning to fill in the blanks in sequences. Experiments on real-world datasets from different domains (CiteULike and Netflix) show that, by jointly modeling the order-aware generation of sequences for the content information and performing CF for the ratings, CRAE is able to significantly outperform the state of the art on both the recommendation task based on ratings and the sequence generation task based on content information.", "creator": "LaTeX with hyperref package"}}}