{"id": "1611.02443", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "8-Nov-2016", "title": "Domain Adaptation with L2 constraints for classifying images from different endoscope systems", "abstract": "This paper proposes a method for domain adaptation that extends the maximum margin domain transfer (MMDT) proposed by Hoffman et al., by introducing L_2 distance constraints between samples of different domains; thus, our method is denoted as MMDTL2. Motivated by the differences between the images taken by narrow band imaging (NBI) endoscopic devices, we utilize different NBI devices as different domains and estimate the transformations between samples of different domains, i.e., the distance between the individual images of different domains, and the change between the individual images of different domains. These results show the potential for multiple domain translation and validation of our technique.", "histories": [["v1", "Tue, 8 Nov 2016 09:29:17 GMT  (5438kb,D)", "http://arxiv.org/abs/1611.02443v1", "28 pages"]], "COMMENTS": "28 pages", "reviews": [], "SUBJECTS": "cs.CV cs.LG", "authors": ["toru tamaki", "shoji sonoyama", "takio kurita", "tsubasa hirakawa", "bisser raytchev", "kazufumi kaneda", "tetsushi koide", "shigeto yoshida", "hiroshi mieno", "shinji tanaka", "kazuaki chayama"], "accepted": false, "id": "1611.02443"}, "pdf": {"name": "1611.02443.pdf", "metadata": {"source": "CRF", "title": "Domain Adaptation with L2 constraints for classifying images from different endoscope systems", "authors": ["Toru Tamakia", "Shoji Sonoyama", "Takio Kurita", "Tsubasa Hirakawa", "Bisser Raytchev", "Kazufumi Kaneda", "Tetsushi Koide", "Shigeto Yoshida", "Hiroshi Mieno", "Shinji Tanaka", "Kazuaki Chayama"], "emails": [], "sections": [{"heading": null, "text": "This paper proposes a method for domain adaptation that extends the maximum margin domain transfer (MMDT) proposed by Hoffman et al., by introducing L2 distance constraints between samples of different domains; thus, our method is denoted as MMDTL2. Motivated by the differences between the images taken by narrow band imaging (NBI) endoscopic devices, we utilize different NBI devices as different domains and estimate the transformations between samples of different domains, i.e., image samples taken by different NBI endoscope systems. We first formulate the problem in the primal form, and then derive the dual form with much lesser computational costs as compared to the naive approach. From our experimental results using NBI image datasets from two different NBI endoscopic devices, we find that MMDTL2 is more stable than MMDT and better than support vector machines without adaptation.\nKeywords: Domain adaptation; Dual formulation; Kernels; NBI endoscopy"}, {"heading": "1. Introduction", "text": "In many hospitals, endoscopic examinations (i.e., colonoscopies) using narrow band imaging (NBI) systems are widely performed to diagnose colorectal cancer [1], which is a major cause of cancer deaths worldwide [2]. During examinations, endoscopists observe and examine a polyp based on its visual appearance, including via NBI magnification findings [3, 4], as shown in Figure 1.\n\u2217Corresponding author\nPreprint submitted to *** November 9, 2016\nar X\niv :1\n61 1.\n02 44\n3v 1\n[ cs\nTo support proper diagnosis during examinations, a computer-aided diagnostic system based on the textural appearance of polyps would be helpful; thus, numerous patch-based classification methods for endoscopic images have been proposed [5, 6, 7, 8, 9, 10, 11].\nThis paper focuses on the inconsistencies between training and test images. As with other frequently used machine learning approaches, training classifiers assumes that the distribution of features extracted from both training and test image datasets are the same; however, different endoscope systems may be used to collect training and test datasets, causing such an assumption to be violated. Further, given the rapid development of medical devices (i.e., endoscopies in this case), hospitals can introduce new endoscopes after training images have already been taken. In addition, classifiers may be trained with a training dataset collected by a certain type of endoscope in one hospital, while another hospital might use the same classifiers for images taken by a different endoscope. In general, such inconsistencies lead to the deterioration of classification performance; hence, collecting new images for a new training dataset may be necessary or is at least preferred. However, this is not the case with medical images. It is impractical to collect enough sets of images for all types and manufacturers of endoscopes.\nFigure 2 shows an example of differences between textures captured by different endoscope systems. More specifically, the images shown in Figures 2(a) and 2(b) are the same scene from a printed sheet of a colorectal polyp image taken by different endoscope systems at approximately the same distance to the sheet from the endoscopes. Even for the same manufacture (e.g., Olympus) and the same modality (e.g., NBI), images may differ in terms of factors such as resolution, image quality, sharpness, brightness, and viewing angle. These differences may impact classification performance.\nTo address this problem, Sonoyama et al. [12] proposed a method based on transfer learning [13, 14, 15, 16] to estimate a transformation matrix between feature vectors of training and test datasets captured by different (i.e., old and new) devices. In this prior study, we formulated the problem as a constraint optimization problem and developed an algorithm to estimate a linear transformation; however, a key limitation is that corresponding datasets are required, i.e., each test image (i.e., taken by a new device) must have a corresponding training image (i.e., taken by an old device). Further, these images must capture the same polyp to properly estimate the linear transformation. These restrictions are rather strong, causing our system to be somewhat impractical.\nTherefor, this paper proposes an improved method for a task that does not require image-by-image correspondences between training and test datasets. More specifically, we extend the transfer learning method proposed by Hoffman et al. [20, 21], called maximum margin domain transfer (MMDT). Their approach was a domain adaptation technique to handle the domain shift problem, in which distributions of classes (or categories) in one domain, called the source, change in another domain, called the target. This situation occurs in various applications, and hence, domain adaptation and transfer learning have already been widely studied.\nCompared to previous studies, MMDT had the following advantages: (1) applicability to multiclass problems with one-vs-rest support vector machines (SVMs); (2) the ability to use different feature dimensions in the source and target domains; (3) the ability to handle unlabeled target samples by estimating global class-independent affine transformation matrix W ; and (4) scalability to the number of constraints, i.e., MMDT solves KLs constraints as compared to LtLs in the previous studies, where K is the number of classes and Ls and Lt are the feature dimensions of the source and target domains.\nIn this paper, we therefore propose a non-trivial extension to MMDT for handling inconsistencies between NBI endoscopic devices1. First, we add L2 distance constraints to MMDT, thus calling our method MMDTL2. The original formulation of MMDT uses the Frobenius norm of transformation W as a regularizer, but pulling transformation W into a zero matrix is not intuitive and might not have a good effect on transferring samples. Other regularizers were discussed by [21], e.g., an identity matrix when Ls = Lt, but no examples were given for cases of Ls 6= Lt. Instead of exploring another regularizer, we add more intuitive constraints. Further, target samples in one category should be transformed into the same category of the source domain. To this end, we use the L2 distances between the source and transformed target samples as constraints. Second, we explicitly formulate MMDTL2 as a quadratic programming (QP) problem. In [20, 21], the MMDT problem was described but not in a QP form. In this paper, we explicitly formulate MMDTL2 in the standard QP form, which includes MMDT as a special case (i.e., where no L2 constraints are used). Third, we derive the dual problem of MMDTL2. The QP form men-\n1A conference version of this paper was presented [22]. This paper extends that version with more rigorous derivations, the compact form of the dual formulation, and the kernelization of the method, as well as experiments from different aspects.\ntioned above is a primal form of MMDTL2 in which computational costs are the same as with MMDT. Its computational costs can be very large for samples with large dimensions because transformation W has size Ls \u00d7 Lt, in addition to KLt constraints. Further, a matrix of size Ls(Lt + 1) \u00d7 Ls(Lt + 1) appears in the computation of the primal form. Our derived dual form of MMDTL2 is more scalable and consists of a KM \u00d7KM matrix, where M is the number of target samples, and KM constraints. This is common and therefore reasonable for problems of domain adaptation, including our problem of NBI device inconsistency, namely that the number of target samples is limited or much smaller than that of source samples. Finally, we show that the primal solution can be converted from the dual solution with much lesser computational costs. With our derived formula, this conversion needs matrices of size at most KM \u00d7KM , while with no elaboration, a matrix of size Ls(Lt + 1)\u00d7 Ls(Lt + 1) appears in the conversion. In addition, we derive a kernelization of the dual formulation, which enables us to use a nonlinear transformation as W .\nNote that our dual form is different from the dual form derived by Rodner et al. [23]. Their motivation was to make MMDT scalable in terms of the number of target samples, because in their study, they attempted to adapt large datasets such as ImageNet. Therefore, their dual form still suffers from the large feature dimensions of the source and target samples. In contrast, our formulation is scalable in terms of feature dimensions.\nThe rest of the paper is organized as follows. We formulate problems of MMDT and MMDTL2 in Section 2, and then derive the primal form in Section 3. In Section 4, we show the dual form, and in Section 5, we obtain the primal solution from the dual solution. In Section 6, we present our experimental results using numerical examples and datasets of actual NBI endoscopic images.\nFinally, in Section 7, we conclude this paper and provide avenues for future work."}, {"heading": "2. Problem formulation", "text": "In this section, we introduce the problems of MMDT [21] and our proposed MMDTL2.\nProblem 1 (MMDT). Suppose we are given a training set \u03c7s = {xsn, ysn}Nn=1 \u2282 RLs \u00d7{1, 2, . . . ,K} in the source domain and another set \u03c7t = {xtm, ytm}Mm=1 \u2282 RLt \u00d7 {1, 2, . . . ,K} in the target domain for a K-class classification problem.\nMMDT solves the following optimization problem:\nmin W,\u0398\u0302\n1 2 \u2016W\u20162F + 1 2 \u2016\u0398\u0302\u20162F + ctL(W, \u0398\u0302, \u03c7t) + csL(\u0398\u0302, \u03c7s), (1)\nwhere ct and cs are weights and\nL(W, \u0398\u0302, \u03c7t) = \u2211 k,m max ( 0, 1\u2212 ytkm\u03b8\u0302Tk ( W x\u0302tm 1 )) (2)\nand\nL(\u0398\u0302, \u03c7s) = \u2211 k,m max ( 0, 1\u2212 yskn\u03b8\u0302Tk x\u0302sn )\n(3)\nare hinge loss functions. Here, \u03b8\u0302k \u2208 RLs+1 is an SVM hyperplane parameter (including weights \u03b8k \u2208 RLs and bias bk \u2208 R, i.e., \u03b8\u0302k = (\u03b8Tk , bk)T ) for the kth class stacked into a matrix \u0398\u0302 = (\u03b8\u03021, \u03b8\u03022, . . . , \u03b8\u0302K), y t km = 2\u03b4(y t m, k)\u2212 1 \u2208 {\u22121, 1} is a label in terms of the kth hyperplane, and cs and cs are weights. Note that x\u0302 denotes an augmented vector with 1 as its last element, i.e.,\nx\u0302 = ( x 1 ) .\nIn this problem, we simultaneously obtain K SVM classifiers and transformation W \u2208 RLs\u00d7Lt . One-vs-all SVMs are used for multiclass classification; thus, K hyperplane parameters \u03b8\u0302k are obtained in the source domain. Target samples xtm are transformed by W from the target domain to the source domain, and then the loss function causes them to be classified by the SVMs.\nBecause this problem is non-convex, an alternating optimization approach was used in [21].\nProblem 2 (MMDT with iteration). MMDT solves problem 1 by iteratively solving subproblems\nmin W\n1 2 \u2016W\u20162F + ctL(W, \u0398\u0302, \u03c7t), (4)\nand\nmin \u0398\u0302\n1 2 \u2016\u0398\u0302\u20162F + ctL(W, \u0398\u0302, \u03c7t) + csL(\u0398\u0302, \u03c7s), (5)\ninitializing \u0398\u0302 with\narg min \u0398\u0302\n1 2 \u2016\u0398\u0302\u20162F + csL(\u0398\u0302, \u03c7s). (6)\nAs noted in the Introduction, the use of Frobenius norm \u2016W\u20162F is not intuitive for the transformation matrix. Further, it might not be a good choice for small values of ct because the obtained solution is pulled toward a zero matrix; however, the use of large values of ct impacts the SVM subproblem (5) because C-SVM solvers are known to be unstable for large values of parameter C.\nIn this paper, we therefore propose the following problem, which we call MMDTL2. MMDTL2 incorporates additional constraints of L2 distances to pull target samples to source samples of the same category.\nProblem 3 (MMDTL2). MMDT with L2 constraints solves problem 1 by iteratively solving subproblems\nmin W\n1 2 cf\u2016W\u20162F + ctL(W, \u0398\u0302, \u03c7t) + cdL(W,\u03c7s, \u03c7t), (7)\nand\nmin \u0398\u0302\n1 2 \u2016\u0398\u0302\u20162F + ctL(W, \u0398\u0302, \u03c7t) + csL(\u0398\u0302, \u03c7s) (8)\nwith the same initialization as problem 2, where\ncdL(W,\u03c7s, \u03c7t) = 1\n2 M\u2211 m=1 N\u2211 n=1 snm\u2016W x\u0302tm \u2212 xsn\u201622, (9)\nwhere snm = cd\u03b4(y s n, y t m) is a weight between samples x t m \u2208 RLt and xsn \u2208 RLs and cd is the balance weight. MMDTL2 reduces to MMDT when cf = 1 and cd = 0.\nThe SVM subproblem (8) can be solved by common SVM solvers, as is done for (5) by MMDT. Therefore, in the following sections, we focus on deriving the primal and dual forms of subproblem (7) as standard QP problems."}, {"heading": "3. Primal problem", "text": "In this section, we rephrase subproblem (7) with inequality constraints instead of loss functions.\nProblem 4 (Estimation of W ). We want to find W \u2208 RLs\u00d7(Lt+1) that minimizes the following objective function:\nmin W,{\u03betkm}\n1 2 cf\u2016W\u20162F + cT K\u2211 k=1 M\u2211 m=1 \u03betkm + 1 2 M\u2211 m=1 N\u2211 n=1 snm\u2016W x\u0302tm \u2212 xsn\u201622 (10)\ns.t.\n\u03betkm \u2265 0, (11)\nytkm\u03b8\u0302 T k\n( W x\u0302tm\n1\n) \u2212 1 + \u03betkm \u2265 0. (12)\nFirst, we rewrite the objective function in a matrix form. To this end, we introduce the vec operator and some formulas below."}, {"heading": "3.1. Operator vec", "text": "Here, we define a vectorized operator for rearranging matrix-vector products.\nDefinition 1. For a given matrix W \u2208 RLs\u00d7(Lt+1), denoted by a set of row vectors wi \u2208 RLt as\nW =  wT1 wT2\n... wTLs  , (13) we define operator vec, which vectorizes W in the row-major order as\nvec(W ) =  w1 w2 ... wLs  \u2208 RLs(Lt+1). (14) This definition is different from the one used in the literature, which is defined in the column-major order, for example, in [24]. Next, we can rewrite matrix-vector multiplications using the vec operator, as summarized in the following lemma.\nLemma 1. For given matrix W \u2208 RLs\u00d7(Lt+1) and vectors x \u2208 RLt+1 and z \u2208 RLs , the following equations hold:\nW x\u0302 = (ILs \u2297 x\u0302T )w (15) x\u0302TWTW x\u0302 = wT (ILs \u2297 x\u0302x\u0302T )w (16)\nzTW x\u0302 = vec(zx\u0302T )Tw (17)\nHere, w = vec(W ), ILs \u2208 RLs\u00d7Ls , is an identity matrix and \u2297 is the tensor product.\nProof. First, we have\nW x\u0302 =  wT1 x\u0302 wT1 x\u0302\n... wTLs x\u0302 T\n =  x\u0302Tw1 x\u0302Tw2\n... x\u0302TwLs\n =  x\u0302T x\u0302T . . .\nx\u0302T\n  w1 w2 ...\nwLs\n (18)\n= (ILs \u2297 x\u0302T )w. (19)\nUsing this equation, we have\nx\u0302TWTW x\u0302 = wT  x\u0302 x\u0302 . . .\nx\u0302\n  x\u0302T x\u0302T . . .\nx\u0302T\nw (20)\n= wT  x\u0302x\u0302T x\u0302x\u0302T . . .\nx\u0302x\u0302T w = wT (ILs \u2297 x\u0302x\u0302T )w. (21) Also, we have\nzTW x\u0302 = zT x\u0302 T x\u0302T\n. . .\nw = (z1x\u0302T , z2x\u0302T , . . .)w (22)\n= vec z1x\u0302 T z2x\u0302 T\n...\n T w = vec(zx\u0302T )Tw = wTvec(zx\u0302T ). (23)\nFor later use, we also define\nU(x\u0302) = (ILs \u2297 x\u0302x\u0302T ). (24)"}, {"heading": "3.2. Rewriting terms with vec operator", "text": "In this subsection, we rewrite the L2 term in the objective function using the lemma below.\nLemma 2. The L2 constraint term of MMDTL2 can be written as\n1\n2 M\u2211 m=1 N\u2211 n=1 snm\u2016W x\u0302tm \u2212 xsn\u201622 = 1 2 (wTUw \u2212 2qTw + s), (25)\nwhere U , q, and s are given in the proof below.\nProof. A single L2 term can be rewritten with lemma 1 as\n\u2016W x\u0302tm \u2212 xsn\u201622 = (W x\u0302tm \u2212 xsn)T (W x\u0302tm \u2212 xsn) (26) = (x\u0302tm)\nTWTW x\u0302tm \u2212 2(xsn)TW x\u0302tm + \u2016xsn\u201622 (27) = wTU(x\u0302tm)w \u2212 2vec(xsn(x\u0302tm)T )Tw + \u2016xsn\u201622 (28)\n= wTUmw \u2212 2qTnmw + \u2016xsn\u201622, (29)\nwhere\nUm = U(x\u0302 t m) = (ILs \u2297 x\u0302tm(x\u0302tm)T ) (30)\nand\nqnm = vec(x s n(x\u0302 t m) T ). (31)\nBy summing the terms with weights, we have\n1\n2 M\u2211 m=1 N\u2211 n=1 snm(w TUmw \u2212 2qTnmw + \u2016xsn\u201622) (32)\n= 1\n2 w ( M\u2211 m=1 N\u2211 n=1 snmUm ) w \u2212 ( M\u2211 m=1 N\u2211 n=1 snmq T nm ) w + 1 2 M\u2211 m=1 N\u2211 n=1 snm\u2016xsn\u201622\n(33)\n= 1\n2 (wTUw \u2212 2qTw + s). (34)\nHere, U , q, and s are the corresponding factors; we further rewrite them into the simpler forms shown below.\nU = M\u2211 m=1 N\u2211 n=1 snmUm = M\u2211 m=1 smUm (35)\n= M\u2211 m=1 sm(ILs \u2297 x\u0302tm(x\u0302tm)T ) = (ILs \u2297 M\u2211 m=1 smx\u0302 t m(x\u0302 t m) T ) (36) = (ILs \u2297XtSM (Xt)T ) (37)\nq = M\u2211 m=1 N\u2211 n=1 snmqnm = M\u2211 m=1 N\u2211 n=1 snmvec(x s n(x\u0302 t m) T ) (38)\n= vec( M\u2211 m=1 N\u2211 n=1 snmx s n(x\u0302 t m) T ) (39) = vec(XsS(Xt)T ) (40)\ns = M\u2211 m=1 N\u2211 n=1 snm\u2016xsn\u201622 = N\u2211 n=1 sn\u2016xsn\u201622 (41)\nHere, we use data matrices\nXs = (xs1,x s 2, . . . ,x s N ) \u2208 RLs\u00d7N (42)\nand\nXt = (x\u0302t1, x\u0302 t 2, . . . , x\u0302 t M ) \u2208 R(Lt+1)\u00d7M (43)\nand weights\nS =  s11 \u00b7 \u00b7 \u00b7 s1M... ... sN1 \u00b7 \u00b7 \u00b7 sNM  , (44) sm =\nN\u2211 n=1 snm, sn = M\u2211 m=1 snm, SM = diag(s1, . . . , sm, . . . , sM ). (45)\nNext, we rewrite the conditions in the problem as shown below.\nLemma 3. The condition in problem 4 can be written as\nytkm(\u03c6 T kmw + bk)\u2212 1 + \u03betkm \u2265 0, (46)\nwhere \u03c6km = vec(\u03b8k(x\u0302 t m) T ).\nProof.\nytkm\u03b8\u0302 T k\n( W x\u0302tm\n1\n) \u2212 1 + \u03betkm \u2265 0 (47)\nytkm(\u03b8 T kW x\u0302 t m + bk)\u2212 1 + \u03betkm \u2265 0 (48)\nytkm(vec(\u03b8k(x\u0302 t m) T )Tw + bk)\u2212 1 + \u03betkm \u2265 0 (49) ytkm(\u03c6 T kmw + bk)\u2212 1 + \u03betkm \u2265 0 (50)"}, {"heading": "3.3. Primal QP problem", "text": "In this subsection, we write the problem in the form of a canonical QP problem.\nLemma 4. Problem 4 can be written as\nmin w,\u03be\n1 2 (wT , \u03beT ) ( V 0 0 0 )( w \u03be ) + (\u2212qT , cT1TKM ) ( w \u03be ) + 1 2 s (51)\ns.t.( 0 IKM\nY \u03a6T IKM )( w \u03be ) \u2265 (\n0\n1KM \u2212 Y b\u0303\n) , (52)\nwhere variables are defined in the proof below.\nProof. First, we define two matrices V \u2208 RLs(Lt+1)\u00d7Ls(Lt+1) andA \u2208 R(Lt+1)\u00d7(Lt+1) as follows:\nV = cfILs(Lt+1) + U (53)\n= cfILs(Lt+1) + (ILs \u2297X tSM (X t)T ) (54) = ILs \u2297 (cfILt+1 +XtSM (Xt)T ) (55) = ILs \u2297A (56)\nA = cfILt+1 +X tSM (X t)T (57)\nThen, we rewrite the objective function (10) as\n1 2 cf\u2016w\u201622 + cT K\u2211 k=1 M\u2211 m=1 \u03betkm + 1 2 (wTUw \u2212 2qTw + s) (58) = 1\n2 wTVw \u2212 qTw + 1 2 s+ cT1 T KM\u03be (59)\n= 1\n2 (wT , \u03beT ) ( V 0 0 0 )( w \u03be ) + (\u2212qT , cT1TKM ) ( w \u03be ) + 1 2 s, (60)\nwhere\n\u03be = (\u03bet11, \u03be t 12, . . . , \u03be t 1M , \u03be t 21, . . . , \u03be t KM ) T . (61)\nTo rewrite conditions (11) and (12), we turn these constraints into vector form with a generalized inequality. The first constraint, i.e., (11), can be written as follows:\n\u03be \u2265 0 (62)( 0 IKM )(w \u03be ) \u2265 0. (63)\nThe second constraint, i.e., (12), is\nY (\u03a6Tw + b\u0303)\u2212 1KM + \u03be \u2265 0 (64)\n(Y \u03a6T , IKM ) ( w \u03be ) \u2265 1KM \u2212 Y b\u0303, (65)\nwhere 1KM is a vector of KM ones and\nb = (b1, b2, . . . , bK) T (66)\nb\u0303 = (b\u2297 1M ) = (b1, b1, . . . , b1, b2, . . . , bK)T (67) \u03a6 = (\u03c611,\u03c612, . . . ,\u03c61M ,\u03c621, . . . ,\u03c6KM ) (68) Y = diag(yt11, y t 12, . . . , y t 1M , y t 21, . . . , y t KM ). (69)\nBy combining these inequalities (63) and (65), we have the conditions in a single form, as claimed.\nThis primal QP problem involves very large matrices that are impractical to compute. More precisely, V is a matrix of size Ls(Lt + 1) \u00d7 Ls(Lt + 1), which can be very large when the dimensions of features (Ls and Lt) are large. In the next section, we therefore derive the dual form of the problem, which we expect to be less expensive to compute."}, {"heading": "4. Dual problem", "text": "In this section, we derive the dual of the problem."}, {"heading": "4.1. Lagrangian", "text": "Lemma 5 (Lagrangian). The Lagrangian of problem (51) is given by\nL = \u22121 2 aTY \u03a6TV \u22121\u03a6Y a+ (1T \u2212 b\u0303TY \u2212 qTV \u22121\u03a6Y )a\u2212 1 2 qTV \u22121q + 1 2 s.\n(70)\nProof. The Lagrangian of problem (51) is given by\nL = 1 2 wTVw \u2212 qTw + 1 2 s+ cT K\u2211 k=1 M\u2211 m=1 \u03betkm\n\u2212 K\u2211 k=1 M\u2211 m=1 \u00b5km\u03be t km \u2212 K\u2211 k=1 M\u2211 m=1 akm(y t km(\u03c6 T kmw + bk)\u2212 1 + \u03betkm), (71)\nwhere akm \u2265 0 and \u00b5km \u2265 0 are Lagrange multipliers. To simplify the derivation, we convert it into vector form\nL = 1 2 wTVw \u2212 qTw + 1 2 s+ cT1 T KM\u03be \u2212 \u00b5T \u03be \u2212 aT (Y (\u03a6Tw + b\u0303)\u2212 1KM + \u03be)\n(72)\n= 1\n2 wTVw \u2212 (q + \u03a6Y a)Tw + (cT1KM \u2212 \u00b5\u2212 a)T \u03be + aT (1KM \u2212 Y b\u0303) +\n1 2 s,\n(73)\nwhere\na = (a11, a12, a1M , a21, . . . , aKM ) T (74)\nand\n\u00b5 = (\u00b511, \u00b512, \u00b51M , \u00b521, . . . , \u00b5KM ) T , (75)\nwith a \u2265 0 and \u00b5 \u2265 0. Next, we take the derivatives of the Lagrangian as follows. For w, we have\n\u2202L \u2202w = Vw \u2212 (q + \u03a6Y a) = 0 (76)\nVw = q + \u03a6Y a (77)\nw = V \u22121(q + \u03a6Y a). (78)\nFor \u03be, we have\n\u2202L \u2202\u03be = cT1\u2212 \u00b5\u2212 a = 0 (79)\ncT1\u2212 a = \u00b5 \u2265 0 (80) cT1\u2212 a \u2265 0 (81)\ncT1 \u2265 a \u2265 0 (82)\nfor \u00b5 \u2265 0 and a \u2265 0. By incorporating w and cT into the Lagrangian and using V T = V , we have\nL = 1\n2 wTVw \u2212 (q + \u03a6Y a)Tw + (cT1\u2212 \u00b5\u2212 a)T \u03be + aT (1\u2212 Y b\u0303) +\n1 2 s (83)\n= 1\n2 (V \u22121(q + \u03a6Y a))TV (V \u22121(q + \u03a6Y a))\n\u2212 (q + \u03a6Y a)T (V \u22121(q + \u03a6Y a)) + aT (1\u2212 Y b\u0303) + 1 2 s (84)\n= \u22121 2 (q + \u03a6Y a)TV \u22121(q + \u03a6Y a) + aT (1\u2212 Y b\u0303) + 1 2 s (85) = \u22121 2 (qTV \u22121q + 2qTV \u22121\u03a6Y a+ aTY \u03a6TV \u22121\u03a6Y a) + aT (1\u2212 Y b\u0303) + 1 2 s\n(86)\n= \u22121 2 aTY \u03a6TV \u22121\u03a6Y a+ (1T \u2212 b\u0303TY \u2212 qTV \u22121\u03a6Y )a\u2212 1 2 qTV \u22121q + 1 2 s.\n(87)\nThis is indeed the dual form, but it still involves a large matrix V . In the next subsection, by utilizing the structure of V , we will write L in such a way that it involves only smaller matrices."}, {"heading": "4.2. Lagrangian with a compact form", "text": "To remove the large matrix V , we use the structure of V and rewrite terms involving V (\u03c6TV \u22121\u03c6 and qTV \u22121\u03a6).\nFirst, the inverses of V and A are as follows:\nV \u22121 = (ILs \u2297A)\u22121 = ILs \u2297A\u22121 (88) A\u22121 = (cfILt+1 +X tSM (X t)T )\u22121 (89)\n= 1\ncf ILt+1 \u2212\n1\nc2f Xt(S\u22121M +\n1\ncf (Xt)TXt)\u22121(Xt)T . (90)\nNote that the second form of A\u22121 is obtained using Woodbury\u2019s formula only if SM is non-singular and cf 6= 0; this is usually the case, because diagonal elements of SM are sums of (non-negative) weights.\nLemma 6. Given V of the structure above and vectors a, c \u2208 RLs and b,d \u2208 RLt , we have\nvec(abT )TV \u22121vec(cdT ) = (aT c)bTA\u22121d. (91)\nProof.\nvec(abT )TV \u22121vec(cdT ) (92)\n= (a1b T , a2b T , . . .) A \u22121 A\u22121\n. . .\n c1dc2d\n...\n (93)\n= (a1b T , a2b T , . . .) c1A \u22121d\nc2A \u22121d ...  (94) = \u2211 i aicib TA\u22121d = (aT c)bTA\u22121d (95)\nNext, we explore \u03c6TV \u22121\u03c6 via the lemma below.\nLemma 7. Given matrix \u03a6 \u2208 RLs(Lt+1)\u00d7KM , we have\n\u03a6TV \u22121\u03a6 = (\u0398T\u0398)\u2297G, (96)\nwhere \u0398 = (\u03b81,\u03b82, . . . ,\u03b8K) \u2208 RLs\u00d7K and G \u2208 RM\u00d7M , the latter given in the proof below.\nProof. Using the above lemma, we have\n\u03c6TkmV \u22121\u03c6k\u2032m\u2032 = vec(\u03b8k(x\u0302 t m) T )TV \u22121vec(\u03b8k\u2032(x\u0302 t m\u2032) T ) (97)\n= (\u03b8Tk \u03b8k\u2032)(x\u0302 t m) TA\u22121x\u0302tm\u2032 . (98)\nBy stacking the above equation for m = 1, . . . ,M , we have \u03c6 T k1 ...\n\u03c6TkM\nV \u22121 (\u03c6k\u20321 \u00b7 \u00b7 \u00b7\u03c6k\u2032M) (99)\n= (\u03b8Tk \u03b8k\u2032)  (x\u0302 t 1) TA\u22121x\u0302t1 \u00b7 \u00b7 \u00b7 (x\u0302t1)TA\u22121x\u0302tM ... ...\n(x\u0302tM ) TA\u22121x\u0302t1 \u00b7 \u00b7 \u00b7 (x\u0302tM )TA\u22121x\u0302tM  (100) = (\u03b8Tk \u03b8k\u2032)(X t)TA\u22121Xt (101) = (\u03b8Tk \u03b8k\u2032)G, (102)\nwhere G = (Xt)TA\u22121Xt.\nFinally, by stacking the above equation for k = 1, . . . ,K, we obtain compact form\n\u03a6TV \u22121\u03a6 =  \u03c6T11 ... \u03c6T1M \u03c6T21\n... \u03c6TKM\n V \u22121 ( \u03c611, \u00b7 \u00b7 \u00b7\u03c61M ,\u03c621, \u00b7 \u00b7 \u00b7\u03c6KM ) (103)\n=  (\u03b8T1 \u03b81)G (\u03b8 T 1 \u03b82)G \u00b7 \u00b7 \u00b7 (\u03b8T1 \u03b8K)G (\u03b8T2 \u03b81)G (\u03b8 T 2 \u03b82)G \u00b7 \u00b7 \u00b7 (\u03b8T2 \u03b8K)G ... ... . . . ...\n(\u03b8TK\u03b81)G (\u03b8 T K\u03b82)G \u00b7 \u00b7 \u00b7 (\u03b8TK\u03b8K)G  (104) = (\u0398T\u0398)\u2297G, (105)\nwhere \u0398 = (\u03b81,\u03b82, . . . ,\u03b8K).\nNote that we can rewrite G further as\nG = (Xt)TA\u22121Xt (106)\n= (Xt)T ( 1\ncf ILt+1 \u2212\n1\nc2f Xt(S\u22121M +\n1\ncf (Xt)TXt)\u22121(Xt)T )Xt (107)\n= 1 cf (Xt)TXt \u2212 1 c2f (Xt)TXt(S\u22121M + 1 cf (Xt)TXt)\u22121(Xt)TXt (108) = 1\ncf Kt \u2212 1 c2f Kt(S\u22121M + 1 cf Kt)\u22121Kt, (109)\nwhere Kt = (Xt)TXt is a kernel matrix. If (Kt)\u22121 exists, we obtain\nG = (cf (K t)\u22121 + SM ) \u22121 (110)\nby applying the Woodbury formula. In summary, G \u2208 RM\u00d7M is\nG =  (cf (K t)\u22121 + SM ) \u22121, if (Kt)\u22121 exists, 1 cf Kt \u2212 1 c2f Kt(S\u22121M + 1 cf Kt)\u22121Kt, if (S\u22121M + 1 cf Kt)\u22121 exists,\n(Xt)TA\u22121Xt, otherwise,\n(111)\ndepending on the existence of the inverse of kernel matrix Kt \u2208 RM\u00d7M . It exists when the dimension of the column space of Xt is M , i.e., when the target samples are linearly independent. If not, the second option can be used, i.e., the inverse of S\u22121M + 1 cf Kt, which can be interpreted as the regularization of kernel Kt with diagonal weight matrix S\u22121M . In the next lemma, we rewrite qTV \u22121\u03a6.\nLemma 8. Given matrix \u03a6 \u2208 RLs(Lt+1)\u00d7KM and vector q \u2208 RLs(Lt+1), we have\nqTV \u22121\u03a6 = vec ( \u0398TXsSG )T . (112)\nProof. Using the above lemma in a similar way as with the previous lemma, we have\nqTnmV \u22121\u03c6k\u2032m\u2032 = vec(x s n(x\u0302 t m) T )TV \u22121vec(\u03b8k\u2032(x\u0302 t m\u2032) T ) (113)\n= ((xsn) T\u03b8k\u2032)(x\u0302 t m) TA\u22121x\u0302tm\u2032 (114) = (\u03b8Tk\u2032x s n)(x\u0302 t m) TA\u22121x\u0302tm\u2032 . (115)\nBy adding and stacking the equation, we have( M\u2211 m=1 N\u2211 n=1 snmq T nm ) V \u22121 ( \u03c6k\u20321, \u00b7 \u00b7 \u00b7\u03c6k\u2032M , ) (116)\n= M\u2211 m=1 N\u2211 n=1 snm(\u03b8 T k\u2032x s n)((x\u0302 t m) TA\u22121x\u0302t1, . . . , (x\u0302 t m) TA\u22121x\u0302tM ) (117)\n= M\u2211 m=1 N\u2211 n=1 snm(\u03b8 T k\u2032x s n)((x\u0302 t m) TA\u22121(x\u0302t1, . . . , x\u0302 t M )) (118)\n= M\u2211 m=1 N\u2211 n=1 snm(\u03b8 T k\u2032x s n)(x t m) TA\u22121Xt (119)\n= \u03b8Tk\u2032 M\u2211 m=1 N\u2211 n=1 snmx s n(x\u0302 t m) TA\u22121Xt (120)\n= \u03b8Tk\u2032 ( M\u2211 m=1 N\u2211 n=1 snmx s n(x\u0302 t m) T ) A\u22121Xt (121) = \u03b8Tk\u2032X sS(Xt)TA\u22121Xt (122) = \u03b8Tk\u2032X sSG. (123)\nFinally, by stacking the equation, we have\nqTV \u22121\u03a6 = (\u03b8T1 X stA\u22121Xt, . . . ,\u03b8TKX stA\u22121Xt) (124)\n= (\u03b8T1 X sSG, . . . ,\u03b8TKX sSG) (125)\n= vec  \u03b8\nT 1 ... \u03b8TK\nXsSG  T\n(126)\n= vec ( \u0398TXsSG )T . (127)\nWe now have the final form of the dual and present it in the corollary below.\nCorollary 1. The dual form of the original primal problem is given by\nmax a \u22121 2 aTY T ((\u0398T\u0398)\u2297G)Y a+ (1T \u2212 (Y b\u0303)T \u2212 vec\n( \u0398TXsSG )T Y )a (128)\ns.t. cT1 \u2265 a \u2265 0. (129)\nProof. According to the lemmas derived above, we can write the Lagrangian as\nL = \u22121 2 aTY T\u03a6TV \u22121\u03a6Y a+ (1T \u2212 qTV \u22121\u03a6Y )a+ \u22121 2 qTV \u22121q + 1 2 s (130)\n= \u22121 2 aTY T ((\u0398T\u0398)\u2297G)Y a+ (1T \u2212 (Y b\u0303)T \u2212 vec\n( \u0398TXsSG )T Y )a\n+ \u22121 2 qTV \u22121q + 1 2 s. (131)\nBy omitting the last two terms, which do not involve a, we have the dual problem as claimed.\nNote that this dual form involves matrices of size at most KM\u00d7KM , which is reasonable when the number of categories K and the number of samples in the target domain M are both small.\nIf all snm = 0, then the problem reduces to MMDT, i.e.,\nL = \u22121 2 aTY T ((\u0398T\u0398)\u2297G)Y a+ (1T \u2212 (Y b\u0303)T )a, (132)\nwhere G = (Xt)TXt, since A = I."}, {"heading": "5. Retrieving the primal solution", "text": "After solving the dual problem with a QP solver, we need to convert the dual solution a to w and b by\nw = V \u22121(q + \u03a6Y a), (133)\nthen finally to W . Here, we again face the problem of large matrix V . We, therefore, derive the core parts V \u22121q and V \u22121\u03a6 as shown in the lemmas below.\nLemma 9. Given V of the structure above and vectors c \u2208 RLs and d \u2208 RLt , we have\nV \u22121vec(cdT ) = c\u2297 (A\u22121d). (134)\nProof.\nV \u22121vec(cdT ) = A \u22121 A\u22121\n. . .\n c1dc2d\n...\n = c1A \u22121d c2A\n\u22121d ...  = c\u2297 (A\u22121d) (135)\nLemma 10. Given V , q, and \u03a6, we have\nV \u22121q = M\u2211 m=1 N\u2211 n=1 snmx s n \u2297 (A\u22121x\u0302tm) (136)\nand\nV \u22121\u03a6 = \u0398\u2297 (A\u22121Xt). (137)\nProof. For (136), we have\nV \u22121q = V \u22121 ( M\u2211 m=1 N\u2211 n=1 snmqnm ) (138)\n= V \u22121 ( M\u2211 m=1 N\u2211 n=1 snmvec(x s n(x\u0302 t m) T ) ) (139)\n= M\u2211 m=1 N\u2211 n=1 snmV \u22121vec(xsn(x\u0302 t m) T ) (140)\n= M\u2211 m=1 N\u2211 n=1 snmx s n \u2297 (A\u22121x\u0302tm). (141)\nNext, we derive (137) by first stacking\nV \u22121\u03c6k\u2032m\u2032 = V \u22121vec(\u03b8k\u2032(x\u0302 t m\u2032) T ) (142)\n= \u03b8k\u2032 \u2297 (A\u22121x\u0302tm\u2032) (143)\nfor m = 1, . . . ,M to obtain V \u22121 ( \u03c6k\u20321 \u00b7 \u00b7 \u00b7\u03c6k\u2032M ) (144)\n= (\u03b8k\u2032 \u2297 (A\u22121x\u0302t1), . . . ,\u03b8k\u2032 \u2297 (A\u22121x\u0302tM )) (145) = \u03b8k\u2032 \u2297 (A\u22121x\u0302t1, . . . , A\u22121x\u0302tM ) (146) = \u03b8k\u2032 \u2297 (A\u22121(x\u0302t1, . . . , x\u0302tM )) (147) = \u03b8k\u2032 \u2297 (A\u22121Xt). (148)\nThen, we further stack the above equation for k = 1, . . . ,K to obtain V \u22121\u03a6 = V \u22121 ( \u03c611, \u00b7 \u00b7 \u00b7\u03c61M ,\u03c621, \u00b7 \u00b7 \u00b7\u03c6KM ) (149)\n= (\u03b81 \u2297 (A\u22121Xt), . . . ,\u03b8K \u2297 (A\u22121Xt)) (150) = (\u03b81, . . . ,\u03b8K)\u2297 (A\u22121Xt) (151) = \u0398\u2297 (A\u22121Xt). (152)\nFinally, we show primal solution W directly, i.e., avoiding conversions from a to w, and then to W . Instead, in the corollary below, we construct matrix W from a with much less computational costs.\nCorollary 2. The solution to the primal problem is given by W = ( XsS + \u0398(\u03a5 \u039b)T ) (Xt)TA\u22121, (153)\nwhere is element-wise multiplication and variables are given in the proof below.\nProof. We first use the lemmas above to obtain\nw = V \u22121(q + \u03a6Y a) (154)\n= ( M\u2211 m=1 N\u2211 n=1 snmx s n \u2297 (A\u22121x\u0302tm) ) + ( \u0398\u2297 (A\u22121Xt) ) Y a. (155)\nFor the ith part of w, we have\nwi = ( M\u2211 m=1 N\u2211 n=1 snmx s n,i(A \u22121x\u0302tm) ) + ( (\u03b81,i, . . . , \u03b8K,i)\u2297 (A\u22121Xt) ) Y a. (156)\nThe first term here can be written as\nA\u22121 ( M\u2211 m=1 N\u2211 n=1 snmx s n,ix\u0302 t m ) = A\u22121XtST  xs1,i xs2,i\n... xsN,i  (157) and the second term as\n(\u03b81,iA \u22121Xt, . . . , \u03b8K,iA \u22121Xt)Y a (158)\n= \u03b81,iA \u22121XtY1a1 + \u00b7 \u00b7 \u00b7+ \u03b8K,iA\u22121XtYKaK (159) = A\u22121Xt(\u03b81,iY1a1 + \u00b7 \u00b7 \u00b7+ \u03b8K,iYKaK) (160)\n= A\u22121Xt(Y1a1, . . . , YKaK) \u03b81,i... \u03b8K,i  (161)\n= A\u22121Xt(\u03a5 \u039b) \u03b81,i... \u03b8K,i  , (162) where\nak =  ak1 ak2\n... akM\n (163)\n\u039b = (a1, . . . ,aK) =  a11 \u00b7 \u00b7 \u00b7 aK1... ... a1M \u00b7 \u00b7 \u00b7 aKM  (164) Yk = diag(y t k1, . . . , y t kM ) (165)\n\u03a5 =  y t 11 \u00b7 \u00b7 \u00b7 ytK1 ...\n... yt1M \u00b7 \u00b7 \u00b7 ytKM  . (166) Combining these two terms, we obtain\nwi = A \u22121XtST  xs1,i xs2,i\n... xsN,i\n+A\u22121Xt(Y1a1, . . . , YKaK) \u03b81,i... \u03b8K,i  . (167) By stacking the ith part for i = 1, . . . , Ls, we yield the matrix directly as\nWT = (w1, . . . ,wLs) = A \u22121XtST (Xs)T +A\u22121Xt(Y1a1, . . . , YKaK)\u0398 T (168) = A\u22121Xt ( ST (Xs)T + (Y1a1, . . . , YKaK)\u0398 T ) (169)\n= A\u22121Xt ( ST (Xs)T + (\u03a5 \u039b)\u0398T ) . (170)"}, {"heading": "6. Kernelization", "text": "In this section, we derive the kernel version of the dual formulation. The obtained transformation is further rewritten as\nW = ( XsS + \u0398(\u03a5 \u039b)T ) (Xt)TA\u22121 (171)\n= ( XsS + \u0398(\u03a5 \u039b)T ) (Xt)T\n( 1\ncf ILt+1 \u2212\n1\nc2f Xt(S\u22121M +\n1\ncf (Xt)TXt)\u22121(Xt)T ) (172)\n= ( XsS + \u0398(\u03a5 \u039b)T )( 1 cf (Xt)T \u2212 1 c2f (Xt)TXt(S\u22121M + 1 cf (Xt)TXt)\u22121(Xt)T ) (173) = ( XsS + \u0398(\u03a5 \u039b)T )( 1 cf IM \u2212 1 c2f Kt(S\u22121M + 1 cf Kt)\u22121 ) (Xt)T . (174)\nWe applyW to target sample xt by multiplying it from the left, i.e., W x\u0302t; Therefore, all computations with target samples are inner products, which means we can use kernels to replace the inner products.\nIn the dual form, we write matrix G with the kernel version using kernel matrix Kt as\nKt =  k(x t 1,x t 1) \u00b7 \u00b7 \u00b7 k(xt1,xtM ) ... . . .\n... k(xtM ,x t 1) \u00b7 \u00b7 \u00b7 k(xtM ,xtM )  , (175) where k() is a kernel function. To transform target sample xt with W , we have\nW x\u0302t = ( XsS + \u0398(\u03a5 \u039b)T )( 1 cf IM \u2212 1 c2f Kt(S\u22121M + 1 cf Kt)\u22121 ) k(x t 1,x t) ...\nk(xtM ,x t)  . (176)\nNote that the nonlinearity introduced by this kernelization appears only in the transformation part; target samples are transformed nonlinearly to the source domain. Only linear SVMs in the source domain can be used here because the primal solutions (i.e., hyperplane parameters) of the source-domain SVMs are explicitly used in the estimation of W . Target samples are therefore linearly classified in the source domain after being nonlinearly transformed from the target domain."}, {"heading": "7. Results and discussions", "text": "In this section, we show two sets of experimental results. Our first experiment uses a standard dataset of supervised domain adaptation to compare our proposed MMDTL2 with MMDT. Our second experiment uses datasets consisting of two NBI endoscopic devices to understand how our proposed method behaves given differing numbers of target domain training samples."}, {"heading": "7.1. Office-Caltech dataset", "text": "In this experiment, we compare our proposed MMDTL2 method with MMDT using the Office-Caltech dataset, a standard dataset of domain adaptation [20, 21, 25, 26]. In this dataset, there are four domains, i.e., Amazon, webcam, digital SLR (dslr), and Caltech, each of which has 10 categories. For each pair of domains, each sample is represented by an 800-dimension descriptor. One training set has eight source training samples per category (80 samples in total except the domain Amazon which has 200 source training samples (20 samples per category)), and three target training samples per category (30 samples in total). Further, 20 training/test sets are given (and provided by [25, 27]) by randomly selecting samples from each domain and category, which are used to report average performance measures. Note that different target domains use differing numbers of test samples; more specifically, dslr has 127, webcam has 265, Amazon has 928, and Caltech has 1093.\nTable 1 shows results of MMDT and MMDTL2. The second column shows a reproduction of results from [20, 21] using publicly available code [27] with the\nprovided parameters and necessary preprocessing (i.e., dimensions were reduced from 800 to 20 using principal component analysis (PCA)). In the third column, results are shown for MMDT without the dimensionality reduction via PCA. Finally, results of MMDTL2 are shown in the rightmost column.\nClearly, in comparison with MMDT, our proposed method is not suitable for this dataset. More investigation is necessary here, though a possible reason for this is that the number of training samples (i.e., eight in the source domain and three in the target domain per category) might be too small for the L2 constraint to behave properly. In a more realistic scenario, there are a sufficient number of source training samples, whereas fewer target samples are available. We therefore focus on this revised situation in the next experiment."}, {"heading": "7.2. NBI endoscopic image dataset", "text": "The NBI dataset used in this experiment consisted of two domains. For the first (i.e., source) domain, we used the NBI image dataset consisting of 908 NBI patches collected from endoscopic examinations at Hiroshima University by using OLYMPUS EVIS LUCERA endoscope system [17]; patches were labeled based on NBI magnification findings [3, 4], which categorizes appearances of tumors into types A, B, and C, with type C further sub-classified into C1, C2, and C3 based on microvessel structures (see Figure 1). In this study, we used only types A, B, and C3 in accordance with our previous work [11, 28, 12, 29]. In general, a patch is trimmed from a larger frame of the entire endoscopic image such that the trimmed rectangular region represents the typical texture pattern of the colorectal polyp appearing in the frame. To align the size of patches between source and target domains, we further trimmed the center of each patch to 180\u00d7 180 and created 734 patches with 289 in type A, 365 in type B, and 80 in type C3. Note that this study was conducted with the approval from the Hiroshima University Hospital ethics committee, and informed consents\nwere obtained from the patients and/or family members for the endoscopic examinations.\nFor the second (i.e., target) domain, we used another NBI image dataset consisting of 279 patches with 92 in type A and 187 in type B. These images were taken by OLYMPUS EVIS LUCERA ELITE endoscope system [19], which is a newer model than that of the system of the source domain. Due to the limited number of endoscopic examinations using this newer endoscope system, we trimmed the center square to 180 \u00d7 180 from video frames of 41 NBI examination videos; hence, there are two factors of domain shift here: (1) the NBI endoscopic devices and (2) the differences between still images (i.e., source) and video frames (i.e., target).\nFrom these two domains, we computed convolutional neural network (CNN) features extracted using CaffeNet [30]; more specifically, this is the fc6 feature of 4096 dimensions, which is known to work well for many tasks [31]. These features were used without dimensionality reduction.\nTo see the effect of the number of target samples, we prepared training/test sets as follows. First, we randomly split the source and target domain samples into half; we therefore had a source training set of 367 source samples and a target training set of 139 target samples. Next, we kept a specified number of target samples per category (up to 40) in each of the target training sets, discarding the rest. For the test set, we used 140 target samples. We created 10 training/test sets and reported average performance.\nFigure 3 shows performance results of different methods over the different\nnumbers of target training samples. As a baseline, we also show two SVM results, i.e., source SVM and target SVM. Source SVM estimates an SVM classifier with source and target training samples (and only source samples when no target samples are used). Target SVM does the same, but only with target training samples. MMDT results were obtained using the code provided by [27], just as in our first experiment. There were three results for MMDTL2, i.e., a linear version and two kernel versions with RBF and polynomial kernels.\nEven with no target samples, source SVM performed relatively better and increased its performance as the number of target training samples increased. Target SVM started below 70%, but caught up to source SVM when 20 training target samples were given. The results indicate that our proposed MMDTL2 behaves between source and target SVMs. When one or two target samples are given, MMDTL2 behaves similarly to target SVM and far below the source SVM, but it quickly gains from the benefits of adaptation. With the RBF kernel, MMDTL2 is the best when 10 and 15 training samples are given, but the linear and polynomial kernels become better when more samples are given. MMDTL2 with the linear kernel and target SVM approach one another, which is expected because a sufficient number of target training samples are considered to be the best for classifying target domain samples. Overall, MMDTL2 with a polynomial kernel works the best.\nNote that the results of MMDT seem to be unstable for this dataset given differing numbers of training samples. In the extreme case, e.g., the left half of the plot, where only a couple of training samples are available, MMDT might be a good choice, and this is one possible reason why MMDT works better than MMDTL2 in the first experiment."}, {"heading": "7.3. NBI endoscopic image dataset with high-dimension features", "text": "Figure 4 shows performance results of the given methods as in Figure 3 with the same protocols for training and evaluation. The difference here is the set of features used; more specifically, we use the conv3 features of 64,896 dimensions rather than fc6. We have shown that conv3 features are expected to work better than fc6 features for NBI patch classification problems [32]; however, transformation matrix W for the conv3 features could be very large without our efficient dual formulation. The ability to handle such large dimensions of features is the key advantage of our proposed method. Figure 4 shows that the source SVM is the best when a few target samples are available, just as in Figure 3. Further, our proposed MMDTL2 with a polynomial kernel becomes better at the right half of the plot, and the differences between the source and target SVMs are much more significant than those in Figure 3."}, {"heading": "8. Conclusions", "text": "In this paper, we proposed MMDT with L2 constraints, i.e., MMDTL2, deriving the dual formulation with much lesser computational costs as compared to the naive QP problem. Further, we showed the kernelization of our method.\nExperimental results with NBI datasets from two different endoscopic devices showed that our proposed MMDTL2 with linear and polynomial kernels performed better than the given baselines (i.e., source and target SVMs). Our future work includes using other loss functions for problem formulation. We observed that the one-vs-rest multiclass classification by SVMs was a performance bottleneck of MMDTL2 in our experiments using the Office-Caltech dataset. Given 10 categories, we had 10 SVMs, each classifying test target samples with 80-90% accuracy measures as 10 separated and independent binary classifiers; however, the total performance for multiclass classification was sometimes lower than 40%. Therefore, instead of relying on maximum margin loss functions, multiclass logistic loss might be better here. In the future, we plan to explore this idea and report performance results for the NBI dataset as well."}, {"heading": "Acknowledgment", "text": "Part of this work was supported by Grant-in-Aid for Scientific Research (B) JSPS KAKENHI, Grant Numbers 26280015 and 14J00223, and was with the help of a grant by Chugoku Industrial Innovation Center, respectively."}], "references": [{"title": "High-magnification colonoscopy (with videos)", "author": ["S. Tanaka", "T. Kaltenbach", "K. Chayama", "R. Soetikno"], "venue": "Gastrointest Endosc 64 (4) ", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2006}, {"title": "K", "author": ["H. Kanao", "S. Tanaka", "S. Oka", "M. Hirata", "S. Yoshida"], "venue": "Chayama, Narrowband imaging magnification predicts the histology and invasion depth of colorectal tumors., Gastrointest Endosc 69 (3 Pt 2) ", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2009}, {"title": "Characterization of colorectal tumors using narrow-band imaging magnification: combined diagnosis with both pit pattern and microvessel features", "author": ["S. Oba", "S. Tanaka", "S. Oka", "H. Kanao", "S. Yoshida", "F. Shimamoto", "K. Chayama"], "venue": "Scand J Gastroenterol 45 (9) ", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2010}, {"title": "Classification of endoscopic images using delaunay triangulation-based edge features", "author": ["M. H\u00e4fner", "A. Gangl", "M. Liedlgruber", "A. Uhl", "A. V\u00e9csei", "F. Wrba"], "venue": "in: A. Campilho, M. Kamel (Eds.), Image Analysis and Recognition, Vol. 6112 of Lecture Notes in Computer Science, Springer Berlin Heidelberg", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2010}, {"title": "Endoscopic image classification using edge-based features", "author": ["M. H\u00e4fner", "A. Gangl", "M. Liedlgruber", "A. Uhl", "A. Vecsei", "F. Wrba"], "venue": "in: Pattern Recognition (ICPR), 2010 20th International Conference on", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2010}, {"title": "Predicting the histology of colorectal lesions in a probabilistic framework", "author": ["R. Kwitt", "A. Uhl", "M. H\u00e4fner", "A. Gangl", "F. Wrba", "A. V\u00e9csei"], "venue": "in: Computer Vision and Pattern Recognition Workshops (CVPRW), 2010 IEEE Computer Society Conference on", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2010}, {"title": "A comparison of blood vessel features and local binary patterns for colorectal polyp classification", "author": ["S. Gross", "T. Stehle", "A. Behrens", "R. Auer", "T. Aach", "R. Winograd", "C. Trautwein", "J. Tischendorf"], "venue": "in: Proc. SPIE, Vol. 7260", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2009}, {"title": "Classification of colon polyps in nbi endoscopy using vascularization features", "author": ["T. Stehle", "R. Auer", "S. Gross", "A. Behrens", "J. Wulff", "T. Aach", "R. Winograd", "C. Trautwein", "J. Tischendorf"], "venue": "in: Proc. SPIE, Vol. 7260", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2009}, {"title": "Computer-aided classification of colorectal polyps based on vascular patterns: a pilot study", "author": ["J.J.W. Tischendorf", "S. Gross", "R. Winograd", "H. Hecker", "R. Auer", "A. Behrens", "C. Trautwein", "T. Aach", "T. Stehle"], "venue": "Endoscopy 42 (3) ", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2010}, {"title": "Computer-aided colorectal tumor classification in NBI endoscopy using local features", "author": ["T. Tamaki", "J. Yoshimuta", "M. Kawakami", "B. Raytchev", "K. Kaneda", "S. Yoshida", "Y. Takemura", "K. Onji", "R. Miyaki", "S. Tanaka"], "venue": "Medical Image Analysis 17 (1) ", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2013}, {"title": "Transfer learning for 26  Bag-of-Visual words approach to NBI endoscopic image classification", "author": ["S. Sonoyama", "T. Hirakawa", "T. Tamaki", "T. Kurita", "B. Raytchev", "K. Kaneda", "T. Koide", "S. Yoshida", "Y. Kominami", "S. Tanaka"], "venue": "in: 2015 37th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC), IEEE", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2015}, {"title": "A survey on transfer learning", "author": ["S.J. Pan", "Q. Yang"], "venue": "Knowledge and Data Engineering, IEEE Transactions on 22 (10) ", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2010}, {"title": "Self-taught learning: transfer learning from unlabeled data", "author": ["R. Raina", "A. Battle", "H. Lee", "B. Packer", "A.Y. Ng"], "venue": "in: Proceedings of the 24th international conference on Machine learning, ACM", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2007}, {"title": "Boosting for transfer learning", "author": ["W. Dai", "Q. Yang", "G.-R. Xue", "Y. Yu"], "venue": "in: Proceedings of the 24th international conference on Machine learning, ACM", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2007}, {"title": "Efficient learning of domain-invariant image representations", "author": ["J. Hoffman", "E. Rodner", "T. Darrell", "J. Donahue", "K. Saenko"], "venue": "Proceedings of the 1st International Conference on Learning Representations ", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2013}, {"title": "Asymmetric and category invariant feature transformations for domain adaptation", "author": ["J. Hoffman", "E. Rodner", "J. Donahue", "B. Kulis", "K. Saenko"], "venue": "International Journal of Computer Vision 109 (1-2) ", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2014}, {"title": "Transfer Learning for Endoscopic Image Classification", "author": ["S. Sonoyama", "T. Tamaki", "T. Hirakawa", "B. Raytchev", "K. Kaneda", "T. Koide", "S. Yoshida", "H. Mieno", "S. Tanaka"], "venue": "in: The Korea-Japan joint workshop on Frontiers of Computer Vision ", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2016}, {"title": "K", "author": ["E. Rodner", "J. Hoffman", "J. Donahue", "T. Darrell"], "venue": "Saenko, Towards Adapting ImageNet to Reality: Scalable Domain Adaptation with Implicit Lowrank Transformations ", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2013}, {"title": "Matrix Algebra From a Statistician\u2019s Perspective", "author": ["D.A. Harville"], "venue": "Springer- Verlag, New York", "citeRegEx": "24", "shortCiteRegEx": null, "year": 1997}, {"title": "Geodesic flow kernel for unsupervised domain adaptation", "author": ["B. Gong", "Y. Shi", "F. Sha", "K. Grauman"], "venue": "in: Computer Vision and Pattern Recognition (CVPR), 2012 IEEE Conference on, IEEE", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2012}, {"title": "Adapting Visual Category Models to New Domains", "author": ["K. Saenko", "B. Kulis", "M. Fritz", "T. Darrell"], "venue": "Springer Berlin Heidelberg, Berlin, Heidelberg", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2010}, {"title": "B", "author": ["J. Hoffman", "E. Rodner", "J. Donahue", "K. Saenko", "T. Darrell"], "venue": "Kulis, Domain Adaptation Project ", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2013}, {"title": "SVM-MRF segmentation of colorectal NBI endoscopic images", "author": ["T. Hirakawa", "T. Tamaki", "B. Raytchev", "K. Kaneda", "T. Koide", "Y. Kominami", "S. Yoshida", "S. Tanaka"], "venue": "in: 2014 36th Annual International Conference of the IEEE Engineering in Medicine and Biology Society, Vol. 2014, IEEE", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2014}, {"title": "Trade-off between speed and performance for colorectal endoscopic NBI image classification", "author": ["S. Sonoyama", "T. Tamaki", "T. Hirakawa", "B. Raytchev", "K. Kaneda", "T. Koide", "Y. Kominami", "S. Yoshida", "S. Tanaka"], "venue": "in: S. Ourselin, M. A. Styner (Eds.), Proc. SPIE, Vol. 9413", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2015}, {"title": "CNN Features Off-the-Shelf: An Astounding Baseline for Recognition", "author": ["A. Sharif Razavian", "H. Azizpour", "J. Sullivan", "S. Carlsson"], "venue": "in: The IEEE Conference on Computer Vision and Pattern Recognition (CVPR) Workshops", "citeRegEx": "31", "shortCiteRegEx": null, "year": 2014}, {"title": "Computer-Aided Colorectal Tumor Classification in NBI Endoscopy Using CNN Features", "author": ["T. Tamaki", "S. Sonoyama", "T. Hirakawa", "B. Raytchev", "K. Kaneda", "T. Koide", "S. Yoshida", "H. Mieno", "S. Tanaka"], "venue": "in: The Korea-Japan joint workshop on Frontiers of Computer Vision ", "citeRegEx": "32", "shortCiteRegEx": null, "year": 2016}], "referenceMentions": [{"referenceID": 0, "context": ", colonoscopies) using narrow band imaging (NBI) systems are widely performed to diagnose colorectal cancer [1], which is a major cause of cancer deaths worldwide [2].", "startOffset": 108, "endOffset": 111}, {"referenceID": 1, "context": "During examinations, endoscopists observe and examine a polyp based on its visual appearance, including via NBI magnification findings [3, 4], as shown in Figure 1.", "startOffset": 135, "endOffset": 141}, {"referenceID": 2, "context": "During examinations, endoscopists observe and examine a polyp based on its visual appearance, including via NBI magnification findings [3, 4], as shown in Figure 1.", "startOffset": 135, "endOffset": 141}, {"referenceID": 3, "context": "To support proper diagnosis during examinations, a computer-aided diagnostic system based on the textural appearance of polyps would be helpful; thus, numerous patch-based classification methods for endoscopic images have been proposed [5, 6, 7, 8, 9, 10, 11].", "startOffset": 236, "endOffset": 259}, {"referenceID": 4, "context": "To support proper diagnosis during examinations, a computer-aided diagnostic system based on the textural appearance of polyps would be helpful; thus, numerous patch-based classification methods for endoscopic images have been proposed [5, 6, 7, 8, 9, 10, 11].", "startOffset": 236, "endOffset": 259}, {"referenceID": 5, "context": "To support proper diagnosis during examinations, a computer-aided diagnostic system based on the textural appearance of polyps would be helpful; thus, numerous patch-based classification methods for endoscopic images have been proposed [5, 6, 7, 8, 9, 10, 11].", "startOffset": 236, "endOffset": 259}, {"referenceID": 6, "context": "To support proper diagnosis during examinations, a computer-aided diagnostic system based on the textural appearance of polyps would be helpful; thus, numerous patch-based classification methods for endoscopic images have been proposed [5, 6, 7, 8, 9, 10, 11].", "startOffset": 236, "endOffset": 259}, {"referenceID": 7, "context": "To support proper diagnosis during examinations, a computer-aided diagnostic system based on the textural appearance of polyps would be helpful; thus, numerous patch-based classification methods for endoscopic images have been proposed [5, 6, 7, 8, 9, 10, 11].", "startOffset": 236, "endOffset": 259}, {"referenceID": 8, "context": "To support proper diagnosis during examinations, a computer-aided diagnostic system based on the textural appearance of polyps would be helpful; thus, numerous patch-based classification methods for endoscopic images have been proposed [5, 6, 7, 8, 9, 10, 11].", "startOffset": 236, "endOffset": 259}, {"referenceID": 9, "context": "To support proper diagnosis during examinations, a computer-aided diagnostic system based on the textural appearance of polyps would be helpful; thus, numerous patch-based classification methods for endoscopic images have been proposed [5, 6, 7, 8, 9, 10, 11].", "startOffset": 236, "endOffset": 259}, {"referenceID": 10, "context": "[12] proposed a method based on transfer learning [13, 14, 15, 16] to estimate a transformation matrix between feature vectors of training and test datasets captured by different (i.", "startOffset": 0, "endOffset": 4}, {"referenceID": 11, "context": "[12] proposed a method based on transfer learning [13, 14, 15, 16] to estimate a transformation matrix between feature vectors of training and test datasets captured by different (i.", "startOffset": 50, "endOffset": 66}, {"referenceID": 12, "context": "[12] proposed a method based on transfer learning [13, 14, 15, 16] to estimate a transformation matrix between feature vectors of training and test datasets captured by different (i.", "startOffset": 50, "endOffset": 66}, {"referenceID": 13, "context": "[12] proposed a method based on transfer learning [13, 14, 15, 16] to estimate a transformation matrix between feature vectors of training and test datasets captured by different (i.", "startOffset": 50, "endOffset": 66}, {"referenceID": 14, "context": "[20, 21], called maximum margin domain transfer (MMDT).", "startOffset": 0, "endOffset": 8}, {"referenceID": 15, "context": "[20, 21], called maximum margin domain transfer (MMDT).", "startOffset": 0, "endOffset": 8}, {"referenceID": 1, "context": "Figure 1: NBI magnification findings [3].", "startOffset": 37, "endOffset": 40}, {"referenceID": 15, "context": "Other regularizers were discussed by [21], e.", "startOffset": 37, "endOffset": 41}, {"referenceID": 14, "context": "In [20, 21], the MMDT problem was described but not in a QP form.", "startOffset": 3, "endOffset": 11}, {"referenceID": 15, "context": "In [20, 21], the MMDT problem was described but not in a QP form.", "startOffset": 3, "endOffset": 11}, {"referenceID": 16, "context": "1A conference version of this paper was presented [22].", "startOffset": 50, "endOffset": 54}, {"referenceID": 17, "context": "[23].", "startOffset": 0, "endOffset": 4}, {"referenceID": 15, "context": "Problem formulation In this section, we introduce the problems of MMDT [21] and our proposed MMDTL2.", "startOffset": 71, "endOffset": 75}, {"referenceID": 15, "context": "Because this problem is non-convex, an alternating optimization approach was used in [21].", "startOffset": 85, "endOffset": 89}, {"referenceID": 18, "context": "This definition is different from the one used in the literature, which is defined in the column-major order, for example, in [24].", "startOffset": 126, "endOffset": 130}, {"referenceID": 14, "context": "Office-Caltech dataset In this experiment, we compare our proposed MMDTL2 method with MMDT using the Office-Caltech dataset, a standard dataset of domain adaptation [20, 21, 25, 26].", "startOffset": 165, "endOffset": 181}, {"referenceID": 15, "context": "Office-Caltech dataset In this experiment, we compare our proposed MMDTL2 method with MMDT using the Office-Caltech dataset, a standard dataset of domain adaptation [20, 21, 25, 26].", "startOffset": 165, "endOffset": 181}, {"referenceID": 19, "context": "Office-Caltech dataset In this experiment, we compare our proposed MMDTL2 method with MMDT using the Office-Caltech dataset, a standard dataset of domain adaptation [20, 21, 25, 26].", "startOffset": 165, "endOffset": 181}, {"referenceID": 20, "context": "Office-Caltech dataset In this experiment, we compare our proposed MMDTL2 method with MMDT using the Office-Caltech dataset, a standard dataset of domain adaptation [20, 21, 25, 26].", "startOffset": 165, "endOffset": 181}, {"referenceID": 19, "context": "Further, 20 training/test sets are given (and provided by [25, 27]) by randomly selecting samples from each domain and category, which are used to report average performance measures.", "startOffset": 58, "endOffset": 66}, {"referenceID": 21, "context": "Further, 20 training/test sets are given (and provided by [25, 27]) by randomly selecting samples from each domain and category, which are used to report average performance measures.", "startOffset": 58, "endOffset": 66}, {"referenceID": 14, "context": "The second column shows a reproduction of results from [20, 21] using publicly available code [27] with the", "startOffset": 55, "endOffset": 63}, {"referenceID": 15, "context": "The second column shows a reproduction of results from [20, 21] using publicly available code [27] with the", "startOffset": 55, "endOffset": 63}, {"referenceID": 21, "context": "The second column shows a reproduction of results from [20, 21] using publicly available code [27] with the", "startOffset": 94, "endOffset": 98}, {"referenceID": 1, "context": ", source) domain, we used the NBI image dataset consisting of 908 NBI patches collected from endoscopic examinations at Hiroshima University by using OLYMPUS EVIS LUCERA endoscope system [17]; patches were labeled based on NBI magnification findings [3, 4], which categorizes appearances of tumors into types A, B, and C, with type C further sub-classified into C1, C2, and C3 based on microvessel structures (see Figure 1).", "startOffset": 250, "endOffset": 256}, {"referenceID": 2, "context": ", source) domain, we used the NBI image dataset consisting of 908 NBI patches collected from endoscopic examinations at Hiroshima University by using OLYMPUS EVIS LUCERA endoscope system [17]; patches were labeled based on NBI magnification findings [3, 4], which categorizes appearances of tumors into types A, B, and C, with type C further sub-classified into C1, C2, and C3 based on microvessel structures (see Figure 1).", "startOffset": 250, "endOffset": 256}, {"referenceID": 9, "context": "In this study, we used only types A, B, and C3 in accordance with our previous work [11, 28, 12, 29].", "startOffset": 84, "endOffset": 100}, {"referenceID": 22, "context": "In this study, we used only types A, B, and C3 in accordance with our previous work [11, 28, 12, 29].", "startOffset": 84, "endOffset": 100}, {"referenceID": 10, "context": "In this study, we used only types A, B, and C3 in accordance with our previous work [11, 28, 12, 29].", "startOffset": 84, "endOffset": 100}, {"referenceID": 23, "context": "In this study, we used only types A, B, and C3 in accordance with our previous work [11, 28, 12, 29].", "startOffset": 84, "endOffset": 100}, {"referenceID": 24, "context": "From these two domains, we computed convolutional neural network (CNN) features extracted using CaffeNet [30]; more specifically, this is the fc6 feature of 4096 dimensions, which is known to work well for many tasks [31].", "startOffset": 217, "endOffset": 221}, {"referenceID": 21, "context": "MMDT results were obtained using the code provided by [27], just as in our first experiment.", "startOffset": 54, "endOffset": 58}, {"referenceID": 25, "context": "We have shown that conv3 features are expected to work better than fc6 features for NBI patch classification problems [32]; however, transformation matrix W for the conv3 features could be very large without our efficient dual formulation.", "startOffset": 118, "endOffset": 122}], "year": 2016, "abstractText": "This paper proposes a method for domain adaptation that extends the maximum margin domain transfer (MMDT) proposed by Hoffman et al., by introducing L2 distance constraints between samples of different domains; thus, our method is denoted as MMDTL2. Motivated by the differences between the images taken by narrow band imaging (NBI) endoscopic devices, we utilize different NBI devices as different domains and estimate the transformations between samples of different domains, i.e., image samples taken by different NBI endoscope systems. We first formulate the problem in the primal form, and then derive the dual form with much lesser computational costs as compared to the naive approach. From our experimental results using NBI image datasets from two different NBI endoscopic devices, we find that MMDTL2 is more stable than MMDT and better than support vector machines without adaptation.", "creator": "LaTeX with hyperref package"}}}