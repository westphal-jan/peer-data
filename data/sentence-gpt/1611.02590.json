{"id": "1611.02590", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "8-Nov-2016", "title": "Veracity Computing from Lexical Cues and Perceived Certainty Trends", "abstract": "We present a data-driven method for determining the veracity of a set of rumorous claims on social media data. Tweets from different sources pertaining to a rumor are processed on three levels: first, factuality values are assigned to each tweet based on four textual cue categories relevant for our journalism use case; these amalgamate speaker support in terms of polarity and commitment in terms of certainty and speculation. Next, the proportions of these lexical cues are utilized as predictors for tweet certainty in a generalized linear regression model. Subsequently, lexical cue proportions, predicted certainty, as well as their time course characteristics are used to compute veracity for each rumor in terms of the identity of the rumor-resolving tweet and its binary resolution value judgment. The system operates without access to extralinguistic resources. Evaluated on the data portion for which hand-labeled examples were available, it achieves .74 F1-score on identifying rumor resolving tweets and .76 F1-score on predicting if a rumor is resolved as true or false. The resulting results are estimated as probabilities of confirmed confirmed false false false false false false false false false false false false false false false false false false false false false false false false false false false false false false false false false false false false false false false false false false false false false false false false false false false false false false false false false false false false false false false false false false false false false false false false false false false false false false false false false false false false false false false false false false false false false false false false false false false false false false false false false false false false false false false false false false false false false false false false false false false false false false false false false false false false false false false false false false false false false false false false false false false false false false false false false false false false false false false false false false false false false false false false false false false false false false false false false false false false false false false false false false false false false false false false false false false false false false false false false false false true false false false false false false false false false false false false false false false false false false false false false false false false false false false false false false false false false false false false false false false false true false false false false false false false false false false false false false true false false false false false false false false false false false false false false false false false false false false true false false false false true false false false false false false", "histories": [["v1", "Tue, 8 Nov 2016 16:21:16 GMT  (357kb,D)", "http://arxiv.org/abs/1611.02590v1", "to appear in: Proc. 2nd Workshop on Noisy User-generated Text, Osaka, Japan, 2016"], ["v2", "Fri, 11 Nov 2016 01:19:06 GMT  (354kb,D)", "http://arxiv.org/abs/1611.02590v2", "to appear in: Proc. 2nd Workshop on Noisy User-generated Text, Osaka, Japan, 2016"]], "COMMENTS": "to appear in: Proc. 2nd Workshop on Noisy User-generated Text, Osaka, Japan, 2016", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["uwe d reichel", "piroska lendvai"], "accepted": false, "id": "1611.02590"}, "pdf": {"name": "1611.02590.pdf", "metadata": {"source": "CRF", "title": "Veracity Computing from Lexical Cues and Perceived Certainty Trends", "authors": ["Uwe D. Reichel", "Piroska Lendvai"], "emails": ["uwe.reichel@nytud.mta.hu", "piroska.r@gmail.com"], "sections": [{"heading": "1 Background and Task Definition", "text": "A growing amount of studies investigate how rumors and memes spread and change on social media platforms (Leskovec et al., 2009; Qazvinian et al., 2011; Procter et al., 2013); given the amount of usergenerated content, the need for automatic fact checking and claim verification procedures is obvious. To compute veracity, systems have been created recently for assessing the credibility of sources and claims (Berti-E\u0301quille and Borge-Holthoefer, 2015). Upcoming initiatives endorsed veracity detection in social media content as a shared task, calling for targeted applications and releasing benchmark data1.\nTo tackle this challenge, we implemented a system that seeks to achieve three goals: (i) to compute a judgment indicating how factual a claim is, based on textual cues and predicted speaker certainty, (ii) to identify which tweet is resolving a rumor, in a set of tweets that discuss this rumor, and (iii) to predict the resolution value for the rumor, i.e., whether the rumor is verified as true or false. Veracity computation is based on information from three information layers related to rumorousness: (1) lexical-level factuality cues, (2) temporal patterns, and (3) speaker certainty. The system is purely data-driven and operates without building claim source profiles for the analyzed content. Below we introduce our motivation in the context of previous and related work.\nThe means by which factuality is conveyed are largely but not exclusively encoded on linguistic levels and are tightly related to the notion of certainty. Certainty and other extra-propositional aspects of meaning have prominently been investigated in terms of modality, negation and speculative language phenomena (Morante and Blanco, 2012; Morante and Sporleder, 2012). Benchmark corpora with annotations emerged (Saur\u0131\u0301 and Pustejovsky, 2009; Farkas et al., 2010), and systems have been built (Saur\u0131\u0301 and Pustejovsky, 2012; de Marneffe et al., 2012; Velldal and Read, 2012) to process texts from the genres of literature, newswire, biomedicine and online encyclopedia, typically drawing on lexical and syntactic cues. (Szarvas et al., 2012) propose a method for porting uncertainty detection across genres and domains. (Kilicoglu et al., 2015) present a full-fledged, compositional approach to factuality\n\u2217UDR is supported by an Alexander von Humboldt Society grant. \u2020PL is supported by the PHEME FP7 project (Grant No. 611233).\n1http://alt.qcri.org/semeval2017/task8/\nar X\niv :1\n61 1.\n02 59\n0v 1\n[ cs\n.C L\n] 8\nN ov\n2 01\n6\nmodeling and detection on texts from the domain of biomedicine based on fine-grained typology and dictionary-based classification of extra-propositional phenomena. Several components of the model are motivated by the nature of scientific communication that serves to track hypothesis building processes with tentative results, analogously to journalistic reports about breaking news. (Soni et al., 2014) focus on factuality framing in social media data in quoted claims with a small set of cues, whereas (Finn et al., 2014) implement keyword-based negation detection without providing quantitative evaluation.\nNext to linguistically expressed uncertainty, extralinguistic information such as the temporal distribution of claims is shown to be an important aspect of veracity computation. Previous studies that investigated temporal patterns of linguistic cues tied to claims emerging in real-world events focus on keywords related to sentiment, named entities and domain terms (Temnikova et al., 2014), but not factuality-conveying cues. (Wei et al., 2013) report on the first uncertainty corpus based on tweets, as well as on classification results for uncertain tweets. Next to platform-specific metadata, they utilized cue phrases in annotated uncertain tweets and an algorithm to detect peaks in the data. (Kwon and Cha, 2014) and (Ma et al., 2015) show for rumor detection that accuracy can be improved by not only looking at message-related properties but also at how these properties change over time. (Ma et al., 2015) propose a time series structure for features and their deltas as the input for classification.\nOn the full PHEME dataset, (Lukasik et al., 2016) report on stance detection in the context of temporal dynamics. They utilize textual information via language modeling but do not evaluate the contribution of textual as opposed to other features. On the same dataset, (Zubiaga et al., 2016) analyzed labeled certainty values in dependence of claim resolution, and found that tweeters post messages with statistically similar certainty before and after a claim is resolved, moreover, irrespective of the resolution value.\nIn (Lendvai et al., 2016) we analyzed and validated a subset of the PHEME data on English and German data that temporal distribution and polarity of lexical markers can be used to represent and quantify changes in factuality framing in a rumor\u2019s lifecycle. Our current study furthers this research by incorporating, evaluating, and visualizing temporally anchored features for claim resolution point as well as claim resolution value prediction in English language rumors discussed in potentially noisy, user-generated content.\nThe paper is structured as follows. In Section 2 we introduce the underlying data and certainty annotations, and describe the automatic extension of lexical cues assigned to four levels of factuality. In Section 3 the relation between certainty and each of the factuality levels is assessed, and regression analysis is used for predicting certainty values by cue-type ratios. In Section 4 we quantify trend discontinuities in time series data of lexical cue ratios and predicted certainty scores to describe rumor resolution points. Cue ratios, certainty, as well as their time course characteristics are exploited in Section 5, where we train classifiers to identify claim-resolving tweets within series of tweets spanning a claim\u2019s lifetime, and additionally predict the claim\u2019s resolution value. The findings are discussed in Section 6."}, {"heading": "2 Data", "text": ""}, {"heading": "2.1 Corpus", "text": "We worked on a subset of a freely available, annotated social media corpus2 collected from the Twitter platform3, containing tweets in English related to three crisis events: the Ottawa shooting4, the Sydney Siege5, and the Germanwings crash6. Each event is annotated in terms of several rumorous claims7 \u2013 plausible but at the time of emergence unconfirmed statements, e.g. in the Sydney Siege collection two example claims are \u201dThere is a hostage situation at a cafe in Sydney\u201d and \u201dPolice (authorities) have been in contact with the hostage-taker\u201d. For each claim, there are a set of tweets that discuss or mention that claim, and a single one of these tweet has been manually identified and judged to be authoritatively resolving the claim either as true or false. A resolving tweet for the claim \u201dThe Germanwings plane experienced\n2https://figshare.com/articles/PHEME rumour scheme dataset journalism use case/2068650 3twitter.com 4https://en.wikipedia.org/wiki/2014 shootings at Parliament Hill, Ottawa 5https://en.wikipedia.org/wiki/2014 Sydney hostage crisis 6https://en.wikipedia.org/wiki/Germanwings Flight 9525 7We use rumor, rumorous claim, and claim interchangeably to refer to the same concept.\na rapid descent before crashing\u201d is: #4U9525 took eight minutes to descend from 38,000 feet to impact, says Germanwings CEO Winkelmann; this rumor is annotated by a journalist as resolved True. The verification value is inherited by all the tweets that relate to this claim, also in retrospect. To ensure that there is always exactly a single resolving tweet per claim we discarded the unresolved claims in the given corpus so that the data underlying this study amounts 45 claims containing in sum 11,420 tweets. Tweets are organized into threaded conversations and are marked up with respect to seven categories of evidence, among others stance and certainty; for full details on the corpus we refer to (Zubiaga et al., 2015)."}, {"heading": "2.2 Certainty annotations", "text": "Certainty annotations were pre-assigned in the corpus in relation to stance value annotations by (Zubiaga et al., 2015). Stance represents speaker attitude toward a target: in this corpus, the target is a rumorous claim, and each tweet was manually marked as either supporting, denying, questioning, or commenting a claim. Tweets that received either of the stance labels supporting or denying were additionally assigned a certainty value. This value served to express tweeter confidence with respect to their stance, as perceived by independent, crowdsourced annotators. Each tweet was annotated by 5-7 crowdsourced annotators, in terms of the four labels uncertain, somewhat certain, certain, and underspecified.\nWe further processed these annotations as follows. To cope with frequent annotation mismatches, we did not simply pick the majority-voted certainty label for our subsequent analyses, but aggregated the annotated values for each tweet as follows. The original certainty labels were mapped to the numerical values 0, 1, 2, and NaN, respectively. We then calculated the mean of all non-NaN values and normalized this to the interval between 0 and 1 by dividing it by the maximum score 2. For example, the tweet \u201dNow hearing 148 passengers + crew on board the #A320 that has crashed in southern French Alps. #GermanWings flight. @BBCWorld\u201d was labeled as \u2019certain\u2019 by 4 annotators and labeled as \u2019somewhatcertain\u2019 by 1 annotator, so this tweet was assigned by us the certainty score of 0.9.\nThe intersection of tweets that relate to claims that were not only annotated as relating to a resolved claim, but also annotated with the three utilizable certainty labels uncertain, somewhat certain, certain left us with a relatively small amount of tweets (266), while we also had at our disposal a larger set of tweets (946) with claim resolution annotation but no certainty values assigned. We made use of both collections as described below."}, {"heading": "2.3 Factuality cues: from seeds to extended lists", "text": "The material underlying our study is user-generated content. The data collection method, cf. (Zubiaga et al., 2015) retained only microposts that passed a retweet count threshold, often by media outlets using well-formed language. Since replying tweets are also included in the corpus, a large portion of the data involves noisy texts. Based on the factuality literature, most prominently (Saur\u0131\u0301 and Pustejovsky, 2009) and (Soni et al., 2014), we devised four factuality groups, each holding up to 40 single-token lexical cues. There is no restriction on which part of speech category a cue may belong to.\n\u2022 Knowledge cues, e.g. clarify, confirm, definitely, discover, evidence, explain, official . . . \u2022 Report cues, e.g. according, capture, claim, footage, observe, report, say, show, source . . . \u2022 Belief cues, e.g. apparent, assume, believe, consider, perhaps, potential, presume, suspect . . . \u2022 Doubt cues, e.g. ?, accuse, allege, contrary, deny, incorrect, misstate, not, unsure, why, wrong . . .\nEach group represents one complex aspect of factuality that can be intuitively understood by nonlinguists, i.e. end users in the journalistic verification scenario. Knowledge and belief cues express affirmative factuality polarity on graded levels of certainty. Report cues express affirmative factuality polarity as well, and additionally delegate speaker commitment, as they typically occur in externallyattributed statements and evidence, indicating a stronger level of speculation than knowledge cues. Doubt cues express negative factuality polarity and were selected to be indicative of contradictory or opposingstance statements which can be extremely strong signals for rumorous claims. Involving categories that have been suggested in previous work in fully-fledged factuality taxonomies (see Section 1) would\nrequire extracting higher-level linguistic information such as dependency parses, which are difficult to obtain from noisy data, and are reserved for the extended version of our system.\nStarting from the seed cues, each of the four lists were automatically further populated from available semantic resources: via extracting the top-3 most similar items from the pretrained Google News word embeddings vector8, as well as lemmas from the top-3 synsets from the English WordNet (Fellbaum, 1998) via NLTK9 (Bird et al., 2009). Only single-token items were harvested; each cue token was subsequently extended by its derivationally related forms via the corresponding NLTK function. Using the extended trigger lists, we obtained counts for each tweet via matching each cue list to a tweet\u2019s content, applying the NLTK Snowball Stemmer10 prior to lookup. We have also experimented with syntax-based cue disambiguation, but opted to abandon it for no proven impact on our current task setup. To exemplify cue matching, in the tweet \u201d#BREAKING: @nswpolice say a photo circulating of arrest of man near #MartinPlace is NOT related to the police operation #sydneysiege\u201d our lookup matches two \u2019report\u2019 cues (say and photo) and one \u2019doubt\u2019 cue (not). The cue extension procedure boosted the seed lists with a few hundred new tokens per cue group, leading to more cue matches in tweets.\nArguably, there are cues that might belong to more than one factuality group, most prominently negation words that, depending on their scope, may express certainty as well. We hypothesized however that utilizing the contextual distribution of a cue will represent its certainty-encoding function in rumor resolution timelines in a robust way. We exemplify such a timeline in Figure 1, differentiated by certainty values plotted to the y axis. The increase in cue recall based on extended lists aimed to benefit the certainty and rumor resolution modeling steps that we introduce in the next sections.\nFeatures derived from matched cues Based on the extended cue matching counts, for each tweet we calculated the proportion of cues for each factuality group over all cues: each proportion ranges from 0 (no cue of the respective type) to 1 (cues exclusively of the respective type). Each tweet is thus represented by the four ratios KCR (\u2019knowledge\u2019 cue ratio), RCR (\u2019report\u2019 cue ratio), BCR (\u2019belief\u2019 cue ratio), DCR (\u2019doubt\u2019 cue ratio). The RCR for the above example tweet is 2/3, the DCR 1/3, while KCR and BCR are 0."}, {"heading": "3 Certainty prediction", "text": "Next, we examined the relation of cue ratios to certainty values assigned to tweets via regression analysis.\n8http://code.google.com/p/word2vec/ 9http://www.nltk.org/ modules/nltk/corpus/reader/wordnet.html\n10http://www.nltk.org/api/nltk.stem.html\nMethod To predict the degree of certainty for each tweet, we fitted generalized linear models (GLM) to the tweets manually annotated for perceived certainty. The four lexical cue ratios were defined as predictors and the certainty score (see Section 2.2) as target. To restrict the output to interval [0 1], the distribution of the response was set to binomial, and a logit link function was chosen. A zero inflation problem is given due to the frequent absence of cue words, which we addressed by adding observation weights to the data points as follows: for each of a predictor\u2019s values the variance of the associated target values was measured, normalized by the variance sum, and its inverse taken. Zero values of a predictor co-occurring with a high variance of certainty values thus received a low weight when fed into the regression. The weight of each feature vector was then derived by taking the mean of the predictorrelated weights.\nResults Spearman\u2019s Rho correlations between the single lexical cue ratios and the normalized certainty score are small. Only for KCR (.14) and DCR (\u2212.39) the correlations are significant (Wilcoxon two sided signed rank tests for paired samples, p < 0.05). These two correlations point in the expected direction. The 10-fold cross validation of the GLMs on held out data yielded an average root mean square error of 0.22 (maximum: 0.28), which is significantly lower than the error of the baseline model always predicting the observed mean certainty value (two-sided Wilcoxon signed rank test for paired samples, p < 0.01). Finally, we fitted a GLM to all available training data for certainty prediction of all tweets used for the subsequent claim resolution prediction and resolving tweet localization tasks."}, {"heading": "4 Certainty trend quantification", "text": "Method In our approach we address time course characteristics more explicitly than previous studies (Kwon and Cha, 2014; Ma et al., 2015). That is, instead of bundling feature vectors at different time stamps to a joint vector, we capture time course characteristics by parameters of regression lines fitted through the feature values over time. These regression lines will be used for trend discontinuity analyses as described in detail below. By means of this analysis we augmented the set of variables the following way: for all four cue ratios and the derived certainty score we calculated four discontinuity features yielding five features for each cue ratio and certainty. These variables will be introduced in the following paragraphs and represent:\n\u2022 tweet-intrinsic properties (lexical cue ratios KCR, RCR, BCR, DCR, predicted certainty CRT) \u2022 local discontinuities across pairs of subsequent tweets (* Delta) \u2022 global discontinuities in linear cue and certainty trends (* Reset, * RMSD p, * RMSD f), where the\nasterisk stands for the tweet-intrinsic variables, i.e. the cue ratios and certainty.\nFor measuring discontinuities, tweets were indexed in the order of their time stamps. Local discontinuities are measured in terms of the delta deviations of each tweet i from the preceding tweet, i.e. by subtracting each intrinsic variable\u2019s value of tweet i\u22121 from the corresponding value of tweet i (* Delta). To quantify the amount of discontinuity a tweet induces in the overall trend of a variable, we fitted three regression lines: line lp through the intrinsic values of the preceding tweet sequence 1 . . . i \u2212 1, line lf through the values of the following tweet sequence i + 1 . . . n (n be the number of tweets in a claim), and line la through the entire tweet sequence 1 . . . n. The method is illustrated in Figure 2.\nIn order to measure the amount of discontinuity for each intrinsic variable at each tweet, we calculated the reset, i.e. the difference between the offset of lp and the onset of lf (Reset), and the deviation of each of these lines lp and lf from la in terms of root mean squared deviation (RMSD p, and RMSD f, respectively). The method was adopted from intonation research (Reichel and Ma\u0301dy, 2014), where it is used to quantify pitch discontinuities for prosodic boundary strength prediction.\nApplying the reasoning of (Reichel and Ma\u0301dy, 2014), Reset quantifies the disruption at each tweet, and RMSD p,f quantify the deviation of the tweet preceding and following regression lines from a common trend. Figure 2 gives an example how the regression lines preceding and following a tweet deviate less from a common trend for non-resolving tweets (left half) than for resolving tweets, expressed by lower values for Reset, RMSD p, and RMSD f. This example therefore illustrates a higher impact of the resolving tweet on the claim-level trends.\nResults For all five tweet-intrinsic measures as well for the related sets of four derived local and global discontinuity measures we tested the difference between resolving and non-resolving tweets by linear mixed-effect models with each of the measures as dependent variable, +/\u2212 resolving tweet (RES) and Rumor is Resolved as True vs False (VAL) as the fixed effects, and event as random effect. Due to the large number of tests p-values were corrected for false discovery rate (Benjamini and Yekutieli, 2001). All significant feature differences (after p-value correction, p < 0.05) for RES are shown in Figure 3.\nThe claim resolution value VAL turned out to affect the variables related to doubt cue ratio and to predicted certainty which is shown in Figure 4 (p < 0.01). Significant interactions between RES and VAL solely affect the doubt cue and certainty variables and are presented in Figure 5. All reported findings are discussed in Section 6."}, {"heading": "5 Predicting the resolving tweet and its resolution value", "text": "As illustrated in Section 4 the distinction of tweets in rumor resolving and non-resolving as well as their resolution values have an impact on several of the examined cue ratio, certainty and discontinuity variables. Our next step thus was to use these variables to predict:\n\u2022 for each tweet whether it resolves a rumor or not (RES), \u2022 for each resolving tweet, whether its resolution value is True or False (VAL).\nMethod For both binary classification tasks we enlarged the feature vector for each tweet by tweet density, i.e. the mean number of tweets per minute in a 10 minutes time window centered on the respective tweet. As for the features introduced above, also together with tweet density its four discontinuity measures (cf. Section 4) were added. We then subdivided the features into two sets:\n\u2022 CueSet: consisting of all lexical knowledge, report, belief, and doubt cue ratios, their derived discontinuities, as well as tweet density and its discontinuities. \u2022 CertSet: consisting of the predicted certainty values (cf. section 3) and their discontinuities instead of the raw cue ratios, and of the tweet density features.\nThis division serves to test whether raw cue ratio or derived certainty features are better suited for the two classification tasks. Task RES is carried out on all tweets in our data, whereas task VAL only applies to resolving tweets. Both tasks were carried out and evaluated in isolation to independently assess the respective performance. That is, the training and testing items for VAL were not taken over from the preceding RES classification output but from the original data set.\nSince in both data sets the target value distributions are highly skewed, we applied resampling without replacement to avoid overlaps of training and test items in subsequent 10-fold cross-validation. The maximum sample size was determined as a weighted mean of the given sample sizes to ensure that for VAL and for RES the more frequent class occurs maximally twice as often as the less frequent one. By this resampling the amounts of claims and tweets (cf. section 2.1) were reduced to 39 (13 falsified, 26 verified claims) and 138 (46 resolving, 92 non-resolving tweets), respectively.\nWe then applied AdaBoostM1 classifiers (Freund and Schapire, 1999) (Matlab function fitensemble, 40 weak learners, minimum 2 items per leaf and 3 items per non-final node) to both data sets and comparatively evaluated the results in a ten-fold cross validation.\nResults Table 1 summarizes the mean performance values on the held-out data after cross-validation. BL Accuracy represents the baseline performance which is defined as predicting only the most frequent class and is quite high due to the not entirely resolved skewedness. The results are discussed in the next section."}, {"heading": "6 Discussion and conclusion", "text": "Relation between lexical cues and certainty As described in Section 3, we established a link between lexical cue ratios of different certainty levels and the certainty associated to tweets by means of regression analysis. The zero-inflation problem as well as the reported low correlations between each cue ratio and the certainty values indicate that factuality values cannot fully be expressed by cue-type ratios in isolation but require a more complex model. Applying GLMs to bundle and therefore strengthen these weak relations was a first step in this direction. Certainty is a discourse-level phenomenon that lexical means can represent to some extent but not entirely. In future work we are going to address the representation of certainty phenomena related to higher linguistic levels.\nImpact of rumor resolution on cue ratios and certainty As pointed out in Section 4, for several examined cue ratio and certainty variables significant differences were observed with respect to claim resolution and resolution value. Resolving tweets show higher knowledge (KCR) and report cue ratios (RCR) as well as related discontinuities. Positive resets mark an abrupt increase in knowledge and report cues at the time point of resolution. This is even more pronounced when combining both cue ratio related features to a common one, the factuality cue ratio (FCR= KCR + RCR). Claim resolution has a major impact on the distribution of lexical cues associated with a high certainty level, as after resolution their amount increases. Belief cue ratios, on the contrary, have not proven to be of relevance for distinguishing between resolving and non-resolving tweets. Doubt cue and certainty variables are additionally highly dependent on the claim resolution value. Doubt cues occur more often in falsified claims and show a higher increase after claim resolution when compared to verified claims (DCR Delta, DCR Reset, DCR RMS f). Certainty cues behave exactly the opposite way: they are generally more frequent in verified claims (CRT) and at the resolution point they show an upward shift in verified but a downward shift in falsified claims (CRT Reset). These interpretations are further supported by the RES-VAL interactions for the doubt cue and certainty variables, i.e. the amount and the direction of discontinuity at the resolution point of doubt cues and certainty values depends on whether the claim is verified or falsified.\nPrediction of resolution and its value Table 1 shows that the prediction tasks benefit from the feature sets in different ways. For task RES, the lexical cue set CueSet turned out to be more appropriate, while for VAL the certainty values CertSet. The reason might be that for VAL only resolving tweets and thus a lower amount of data is available suggesting the utility of shorter vectors containing derived instead of raw features. Importantly for sparse data scenarios, the generation of such an intermediate level of cue-integrating features, in our case the predicted certainty, turns out to be beneficial."}], "references": [{"title": "The control of the false discovery rate in multiple testing under dependency", "author": ["Benjamini", "Yekutieli2001] Yoav Benjamini", "Daniel Yekutieli"], "venue": "Annals of Statistics,", "citeRegEx": "Benjamini et al\\.,? \\Q2001\\E", "shortCiteRegEx": "Benjamini et al\\.", "year": 2001}, {"title": "Veracity of data: From truth discovery computation algorithms to models of misinformation dynamics", "author": ["Berti-\u00c9quille", "Javier Borge-Holthoefer"], "venue": "Synthesis Lectures on Data Management,", "citeRegEx": "Berti.\u00c9quille et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Berti.\u00c9quille et al\\.", "year": 2015}, {"title": "Did it happen? the pragmatic complexity of veridicality assessment", "author": ["Christopher D Manning", "Christopher Potts"], "venue": null, "citeRegEx": "Marneffe et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Marneffe et al\\.", "year": 2012}, {"title": "The CoNLL-2010 Shared Task: Learning to detect hedges and their scope in natural language text", "author": ["Veronika Vincze", "Gy\u00f6rgy M\u00f3ra", "J\u00e1nos Csirik", "Gy\u00f6rgy Szarvas"], "venue": "In Proceedings of the 14th Conference on Natural Language Learning", "citeRegEx": "Farkas et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Farkas et al\\.", "year": 2010}, {"title": "Investigating rumor propagation with TwitterTrails", "author": ["Finn et al.2014] Samantha Finn", "Panagiotis Takis Metaxas", "Eni Mustafaraj"], "venue": "arXiv preprint arXiv:1411.3550", "citeRegEx": "Finn et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Finn et al\\.", "year": 2014}, {"title": "A short introduction to boosting", "author": ["Freund", "Schapire1999] Yoav Freund", "Robert E. Schapire"], "venue": "J. Japanese Society for Artificial Intelligence,", "citeRegEx": "Freund et al\\.,? \\Q1999\\E", "shortCiteRegEx": "Freund et al\\.", "year": 1999}, {"title": "A compositional interpretation of biomedical event factuality", "author": ["Graciela Rosemblat", "Michael J Cairelli", "Thomas C Rindflesch"], "venue": "ExProM", "citeRegEx": "Kilicoglu et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Kilicoglu et al\\.", "year": 2015}, {"title": "Modeling bursty temporal pattern of rumors", "author": ["Kwon", "Cha2014] Sejeong Kwon", "Meeyoung Cha"], "venue": "In Proc. ICWSM,", "citeRegEx": "Kwon et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Kwon et al\\.", "year": 2014}, {"title": "Factuality drift assessment by lexical markers in resolved rumors", "author": ["Uwe D Reichel", "Thierry Declerck"], "venue": "In Joint Proceedings of the Posters and Demos Track of the 12th International Conference on Semantic Systems (SEMANTiCS 2016) and the 1st International Workshop on Semantic Change & Evolving Semantics,", "citeRegEx": "Lendvai et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Lendvai et al\\.", "year": 2016}, {"title": "Meme-tracking and the dynamics of the news cycle", "author": ["Lars Backstrom", "Jon Kleinberg"], "venue": "In Proc. of KDD-09", "citeRegEx": "Leskovec et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Leskovec et al\\.", "year": 2009}, {"title": "2016. Hawkes Processes for Continuous Time Sequence Classification: An Application to Rumour Stance Classification in Twitter", "author": ["P.K. Srijith", "Duy Vu", "Kalina Bontcheva", "Arkaitz Zubiaga", "Trevor Cohn"], "venue": "Proceedings of ACL-16", "citeRegEx": "Lukasik et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Lukasik et al\\.", "year": 2016}, {"title": "Detect rumors using time series of social context information on microblogging websites", "author": ["Ma et al.2015] Jing Ma", "Wei Gao", "Zhongyu Wei", "Yueming Lu", "Kam-Fai Wong"], "venue": "In Proceedings of the 24th ACM International on Conference on Information and Knowledge Management,", "citeRegEx": "Ma et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Ma et al\\.", "year": 2015}, {"title": "SEM 2012 shared task: Resolving the scope and focus of negation", "author": ["Morante", "Blanco2012] Roser Morante", "Eduardo Blanco"], "venue": "In Proceedings of the First Joint Conference on Lexical and Computational Semantics", "citeRegEx": "Morante et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Morante et al\\.", "year": 2012}, {"title": "Reading the riots on Twitter: methodological innovation for the analysis of big data", "author": ["Procter et al.2013] Rob Procter", "Farida Vis", "Alex Voss"], "venue": "International Journal of Social Research Methodology,", "citeRegEx": "Procter et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Procter et al\\.", "year": 2013}, {"title": "Rumor has it: Identifying misinformation in microblogs", "author": ["Emily Rosengren", "Dragomir R. Radev", "Qiaozhu Mei"], "venue": "In Proceedings of the Conference on Empirical Methods in Natural Language Processing,", "citeRegEx": "Qazvinian et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Qazvinian et al\\.", "year": 2011}, {"title": "Comparing parameterizations of pitch register and its discontinuities at prosodic boundaries for Hungarian", "author": ["Reichel", "M\u00e1dy2014] Uwe D. Reichel", "Katalin M\u00e1dy"], "venue": "In Proc. Interspeech", "citeRegEx": "Reichel et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Reichel et al\\.", "year": 2014}, {"title": "Factbank: A corpus annotated with event factuality", "author": ["Saur\u0131", "Pustejovsky2009] Roser Saur\u0131", "James Pustejovsky"], "venue": "Language Resources and Evaluation,", "citeRegEx": "Saur\u0131\u0301 et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Saur\u0131\u0301 et al\\.", "year": 2009}, {"title": "Are you sure that this happened? Assessing the factuality degree of events in text", "author": ["Saur\u0131", "Pustejovsky2012] Roser Saur\u0131", "James Pustejovsky"], "venue": null, "citeRegEx": "Saur\u0131\u0301 et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Saur\u0131\u0301 et al\\.", "year": 2012}, {"title": "Modeling factuality judgments in social media text", "author": ["Soni et al.2014] Sandeep Soni", "Tanushree Mitra", "Eric Gilbert", "Jacob Eisenstein"], "venue": "Proc. of ACL", "citeRegEx": "Soni et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Soni et al\\.", "year": 2014}, {"title": "Cross-genre and cross-domain detection of semantic uncertainty", "author": ["Veronika Vincze", "Rich\u00e1rd Farkas", "Gy\u00f6rgy M\u00f3ra", "Iryna Gurevych"], "venue": null, "citeRegEx": "Szarvas et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Szarvas et al\\.", "year": 2012}, {"title": "Building a crisis management term resource for social media: The case of floods and protests", "author": ["Andrea Varga", "Dogan Biyikli"], "venue": "In LREC,", "citeRegEx": "Temnikova et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Temnikova et al\\.", "year": 2014}, {"title": "Factuality detection on the cheap: Inferring factuality for increased precision in detecting negated events", "author": ["Velldal", "Read2012] Erik Velldal", "Jonathon Read"], "venue": "In Proceedings of the ACL-2012 Workshop on ExtraPropositional Aspects of Meaning in Computational Linguistics", "citeRegEx": "Velldal et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Velldal et al\\.", "year": 2012}, {"title": "An Empirical Study on Uncertainty Identification in Social Media Context", "author": ["Wei et al.2013] Zhongyu Wei", "Junwen Chen", "Wei Gao", "Binyang Li", "Lanjun Zhou", "Yulan He", "Kam-fai Wong"], "venue": "Proceedings of ACL", "citeRegEx": "Wei et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Wei et al\\.", "year": 2013}, {"title": "Towards Detecting Rumours in Social Media", "author": ["Maria Liakata", "Rob Procter", "Kalina Bontcheva", "Peter Tolmie"], "venue": null, "citeRegEx": "Zubiaga et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Zubiaga et al\\.", "year": 2015}, {"title": "Analysing how people orient to and spread rumours in social media by looking at conversational threads", "author": ["Maria Liakata", "Rob Procter", "Geraldine Wong Sak Hoi", "Peter Tolmie"], "venue": "PLoS ONE,", "citeRegEx": "Zubiaga et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Zubiaga et al\\.", "year": 2016}], "referenceMentions": [{"referenceID": 9, "context": "A growing amount of studies investigate how rumors and memes spread and change on social media platforms (Leskovec et al., 2009; Qazvinian et al., 2011; Procter et al., 2013); given the amount of usergenerated content, the need for automatic fact checking and claim verification procedures is obvious.", "startOffset": 105, "endOffset": 174}, {"referenceID": 14, "context": "A growing amount of studies investigate how rumors and memes spread and change on social media platforms (Leskovec et al., 2009; Qazvinian et al., 2011; Procter et al., 2013); given the amount of usergenerated content, the need for automatic fact checking and claim verification procedures is obvious.", "startOffset": 105, "endOffset": 174}, {"referenceID": 13, "context": "A growing amount of studies investigate how rumors and memes spread and change on social media platforms (Leskovec et al., 2009; Qazvinian et al., 2011; Procter et al., 2013); given the amount of usergenerated content, the need for automatic fact checking and claim verification procedures is obvious.", "startOffset": 105, "endOffset": 174}, {"referenceID": 3, "context": "Benchmark corpora with annotations emerged (Saur\u0131\u0301 and Pustejovsky, 2009; Farkas et al., 2010), and systems have been built (Saur\u0131\u0301 and Pustejovsky, 2012; de Marneffe et al.", "startOffset": 43, "endOffset": 94}, {"referenceID": 19, "context": "(Szarvas et al., 2012) propose a method for porting uncertainty detection across genres and domains.", "startOffset": 0, "endOffset": 22}, {"referenceID": 6, "context": "(Kilicoglu et al., 2015) present a full-fledged, compositional approach to factuality", "startOffset": 0, "endOffset": 24}, {"referenceID": 18, "context": "(Soni et al., 2014) focus on factuality framing in social media data in quoted claims with a small set of cues, whereas (Finn et al.", "startOffset": 0, "endOffset": 19}, {"referenceID": 4, "context": ", 2014) focus on factuality framing in social media data in quoted claims with a small set of cues, whereas (Finn et al., 2014) implement keyword-based negation detection without providing quantitative evaluation.", "startOffset": 108, "endOffset": 127}, {"referenceID": 20, "context": "Previous studies that investigated temporal patterns of linguistic cues tied to claims emerging in real-world events focus on keywords related to sentiment, named entities and domain terms (Temnikova et al., 2014), but not factuality-conveying cues.", "startOffset": 189, "endOffset": 213}, {"referenceID": 22, "context": "(Wei et al., 2013) report on the first uncertainty corpus based on tweets, as well as on classification results for uncertain tweets.", "startOffset": 0, "endOffset": 18}, {"referenceID": 11, "context": "(Kwon and Cha, 2014) and (Ma et al., 2015) show for rumor detection that accuracy can be improved by not only looking at message-related properties but also at how these properties change over time.", "startOffset": 25, "endOffset": 42}, {"referenceID": 11, "context": "(Ma et al., 2015) propose a time series structure for features and their deltas as the input for classification.", "startOffset": 0, "endOffset": 17}, {"referenceID": 10, "context": "On the full PHEME dataset, (Lukasik et al., 2016) report on stance detection in the context of temporal dynamics.", "startOffset": 27, "endOffset": 49}, {"referenceID": 24, "context": "On the same dataset, (Zubiaga et al., 2016) analyzed labeled certainty values in dependence of claim resolution, and found that tweeters post messages with statistically similar certainty before and after a claim is resolved, moreover, irrespective of the resolution value.", "startOffset": 21, "endOffset": 43}, {"referenceID": 8, "context": "In (Lendvai et al., 2016) we analyzed and validated a subset of the PHEME data on English and German data that temporal distribution and polarity of lexical markers can be used to represent and quantify changes in factuality framing in a rumor\u2019s lifecycle.", "startOffset": 3, "endOffset": 25}, {"referenceID": 23, "context": "Tweets are organized into threaded conversations and are marked up with respect to seven categories of evidence, among others stance and certainty; for full details on the corpus we refer to (Zubiaga et al., 2015).", "startOffset": 191, "endOffset": 213}, {"referenceID": 23, "context": "Certainty annotations were pre-assigned in the corpus in relation to stance value annotations by (Zubiaga et al., 2015).", "startOffset": 97, "endOffset": 119}, {"referenceID": 23, "context": "(Zubiaga et al., 2015) retained only microposts that passed a retweet count threshold, often by media outlets using well-formed language.", "startOffset": 0, "endOffset": 22}, {"referenceID": 18, "context": "Based on the factuality literature, most prominently (Saur\u0131\u0301 and Pustejovsky, 2009) and (Soni et al., 2014), we devised four factuality groups, each holding up to 40 single-token lexical cues.", "startOffset": 88, "endOffset": 107}, {"referenceID": 11, "context": "Method In our approach we address time course characteristics more explicitly than previous studies (Kwon and Cha, 2014; Ma et al., 2015).", "startOffset": 100, "endOffset": 137}], "year": 2017, "abstractText": "We present a data-driven method for determining the veracity of a set of rumorous claims on social media data. Tweets from different sources pertaining to a rumor are processed on three levels: first, factuality values are assigned to each tweet based on four textual cue categories relevant for our journalism use case; these amalgamate speaker support in terms of polarity and commitment in terms of certainty and speculation. Next, the proportions of these lexical cues are utilized as predictors for tweet certainty in a generalized linear regression model. Subsequently, lexical cue proportions, predicted certainty, as well as their time course characteristics are used to compute veracity for each rumor in terms of the identity of the rumor-resolving tweet and its binary resolution value judgment. The system operates without access to extralinguistic resources. Evaluated on the data portion for which hand-labeled examples were available, it achieves .74 F1-score on identifying rumor resolving tweets and .76 F1-score on predicting if a rumor is resolved as true or false. 1 Background and Task Definition A growing amount of studies investigate how rumors and memes spread and change on social media platforms (Leskovec et al., 2009; Qazvinian et al., 2011; Procter et al., 2013); given the amount of usergenerated content, the need for automatic fact checking and claim verification procedures is obvious. To compute veracity, systems have been created recently for assessing the credibility of sources and claims (Berti-\u00c9quille and Borge-Holthoefer, 2015). Upcoming initiatives endorsed veracity detection in social media content as a shared task, calling for targeted applications and releasing benchmark data1. To tackle this challenge, we implemented a system that seeks to achieve three goals: (i) to compute a judgment indicating how factual a claim is, based on textual cues and predicted speaker certainty, (ii) to identify which tweet is resolving a rumor, in a set of tweets that discuss this rumor, and (iii) to predict the resolution value for the rumor, i.e., whether the rumor is verified as true or false. Veracity computation is based on information from three information layers related to rumorousness: (1) lexical-level factuality cues, (2) temporal patterns, and (3) speaker certainty. The system is purely data-driven and operates without building claim source profiles for the analyzed content. Below we introduce our motivation in the context of previous and related work. The means by which factuality is conveyed are largely but not exclusively encoded on linguistic levels and are tightly related to the notion of certainty. Certainty and other extra-propositional aspects of meaning have prominently been investigated in terms of modality, negation and speculative language phenomena (Morante and Blanco, 2012; Morante and Sporleder, 2012). Benchmark corpora with annotations emerged (Saur\u0131\u0301 and Pustejovsky, 2009; Farkas et al., 2010), and systems have been built (Saur\u0131\u0301 and Pustejovsky, 2012; de Marneffe et al., 2012; Velldal and Read, 2012) to process texts from the genres of literature, newswire, biomedicine and online encyclopedia, typically drawing on lexical and syntactic cues. (Szarvas et al., 2012) propose a method for porting uncertainty detection across genres and domains. (Kilicoglu et al., 2015) present a full-fledged, compositional approach to factuality \u2217UDR is supported by an Alexander von Humboldt Society grant. \u2020PL is supported by the PHEME FP7 project (Grant No. 611233). http://alt.qcri.org/semeval2017/task8/ ar X iv :1 61 1. 02 59 0v 1 [ cs .C L ] 8 N ov 2 01 6 modeling and detection on texts from the domain of biomedicine based on fine-grained typology and dictionary-based classification of extra-propositional phenomena. Several components of the model are motivated by the nature of scientific communication that serves to track hypothesis building processes with tentative results, analogously to journalistic reports about breaking news. (Soni et al., 2014) focus on factuality framing in social media data in quoted claims with a small set of cues, whereas (Finn et al., 2014) implement keyword-based negation detection without providing quantitative evaluation. Next to linguistically expressed uncertainty, extralinguistic information such as the temporal distribution of claims is shown to be an important aspect of veracity computation. Previous studies that investigated temporal patterns of linguistic cues tied to claims emerging in real-world events focus on keywords related to sentiment, named entities and domain terms (Temnikova et al., 2014), but not factuality-conveying cues. (Wei et al., 2013) report on the first uncertainty corpus based on tweets, as well as on classification results for uncertain tweets. Next to platform-specific metadata, they utilized cue phrases in annotated uncertain tweets and an algorithm to detect peaks in the data. (Kwon and Cha, 2014) and (Ma et al., 2015) show for rumor detection that accuracy can be improved by not only looking at message-related properties but also at how these properties change over time. (Ma et al., 2015) propose a time series structure for features and their deltas as the input for classification. On the full PHEME dataset, (Lukasik et al., 2016) report on stance detection in the context of temporal dynamics. They utilize textual information via language modeling but do not evaluate the contribution of textual as opposed to other features. On the same dataset, (Zubiaga et al., 2016) analyzed labeled certainty values in dependence of claim resolution, and found that tweeters post messages with statistically similar certainty before and after a claim is resolved, moreover, irrespective of the resolution value. In (Lendvai et al., 2016) we analyzed and validated a subset of the PHEME data on English and German data that temporal distribution and polarity of lexical markers can be used to represent and quantify changes in factuality framing in a rumor\u2019s lifecycle. Our current study furthers this research by incorporating, evaluating, and visualizing temporally anchored features for claim resolution point as well as claim resolution value prediction in English language rumors discussed in potentially noisy, user-generated content. The paper is structured as follows. In Section 2 we introduce the underlying data and certainty annotations, and describe the automatic extension of lexical cues assigned to four levels of factuality. In Section 3 the relation between certainty and each of the factuality levels is assessed, and regression analysis is used for predicting certainty values by cue-type ratios. In Section 4 we quantify trend discontinuities in time series data of lexical cue ratios and predicted certainty scores to describe rumor resolution points. Cue ratios, certainty, as well as their time course characteristics are exploited in Section 5, where we train classifiers to identify claim-resolving tweets within series of tweets spanning a claim\u2019s lifetime, and additionally predict the claim\u2019s resolution value. The findings are discussed in Section 6.", "creator": "LaTeX with hyperref package"}}}