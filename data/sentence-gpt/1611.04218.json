{"id": "1611.04218", "review": {"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "14-Nov-2016", "title": "Preference Completion from Partial Rankings", "abstract": "We propose a novel and efficient algorithm for the collaborative preference completion problem, which involves jointly estimating individualized rankings for a set of entities over a shared set of items, based on a limited number of observed affinity values. Our approach exploits the observation that while preferences are often recorded as numerical scores, the predictive quantity of interest is the underlying rankings. Thus, attempts to closely match the recorded scores may lead to overfitting and impair generalization performance in order to avoid misinterpreting the true associations, because the similarity of information to individual labels has an effect on predictive significance. We investigate the association between individual preferences and the validity of an automated search to identify associations between a single, shared item and the predicted score. Keywords The proposed algorithm will allow individual choices for search patterns to be determined using a combination of information from the following categories: information from the category associated with a shared item. We suggest that the goal of a novel algorithm is to predict a single, shared item at once, and a single, shared item at once. The algorithm identifies an individual item, which the algorithm estimates as having one of three ratings that a person should have, based on the shared item's rank. In our proposed algorithm, we estimate that, given the potential of the individual individual to have, based on the shared item's rank, each given the expected ranking, an individual item should have a given rank. The algorithm identifies a given item that is an attribute (i.e., the highest rated item at that point, and an attribute that is an attribute that is the highest rated item at that point, and an attribute that is the highest rated item at that point, and an attribute that is the highest rated item at that point, and an attribute that is the highest rated item at that point, and an attribute that is the highest rated item at that point, and an attribute that is the highest rated item at that point, and an attribute that is the highest rated item at that point, and an attribute that is the highest rated item at that point, and an attribute that is the highest rated item at that point, and an attribute that is the highest rated item at that point, and an attribute that is the highest rated item at that point, and an attribute that is the highest rated item at that point, and an attribute that is the highest rated item at that point, and an attribute that is the highest rated item at that point, and an attribute that is the highest rated item at that point, and an attribute that is the highest rated item at that", "histories": [["v1", "Mon, 14 Nov 2016 01:17:14 GMT  (110kb,D)", "http://arxiv.org/abs/1611.04218v1", "NIPS 2016"]], "COMMENTS": "NIPS 2016", "reviews": [], "SUBJECTS": "stat.ML cs.LG", "authors": ["suriya gunasekar", "oluwasanmi koyejo", "joydeep ghosh"], "accepted": true, "id": "1611.04218"}, "pdf": {"name": "1611.04218.pdf", "metadata": {"source": "CRF", "title": "Preference Completion from Partial Rankings", "authors": ["Suriya Gunasekar", "Oluwasanmi Koyejo", "Joydeep Ghosh"], "emails": ["suriya@utexas.edu", "sanmi@illinois.edu", "ghosh@ece.utexas.edu"], "sections": [{"heading": "1 Introduction", "text": "Collaborative preference completion is the task of jointly learning bipartite (or dyadic) preferences of set of entities for a shared list of items, e.g., user\u2013item interactions in a recommender system [13; 21]. It is commonly assumed that such entity\u2013item preferences are generated from a small number of latent or hidden factors, or equivalently, the underlying preference value matrix is assumed to be low rank. Further, if the observed affinity scores from various explicit and implicit feedback are treated as exact (or mildly perturbed) entries of the unobserved preference value matrix, then the preference completion task naturally fits in the framework of low rank matrix completion [21; 38]. More generally, low rank matrix completion involves predicting the missing entries of a low rank matrix from a vanishing fraction of its entries observed through a noisy channel. Several low rank matrix completion estimators and algorithms have been developed in the literature, many with strong theoretical guarantees and empirical performance [6; 31; 20; 27; 38; 9].\nRecent research in the preference completion literature have noted that using a matrix completion estimator for collaborative preference estimation may be misguided [10; 33; 22] as the observed entity\u2013item affinity scores from implicit/explicit feedback are potentially subject to systematic monotonic transformations arising from limitations in feedback collection, e.g., quantization and\n30th Conference on Neural Information Processing Systems (NIPS 2016), Barcelona, Spain.\nar X\niv :1\n61 1.\n04 21\n8v 1\n[ st\nat .M\nL ]\n1 4\nN ov\ninherent biases. While simple user biases and linear transofmations can be handled within a low rank matrix framework, more complex transformations like quantization can potentially increase the rank of the observed preference score matrix significantly, thus adversely affecting recovery using standard low rank matrix completion [12]. Further, despite the common practice of measuring preferences using numerical scores, predictions are most often deployed or evaluated based on the item ranking e.g. in recommender systems, user recommendations are often presented as a ranked list of items without the underlying scores. Indeed several authors have shown that favorable empirical/theoretical performance in mean square error for the preference matrix often does not translate to better performance when performance is measured using ranking metrics [10; 33; 22]. Thus, collaborative preference estimation may be better posed as a collection of coupled learning to rank (LETOR) problems [24], where we seek to jointly learn the preference rankings of a set of entities, by exploiting the low dimensional latent structure of the underlying preference values.\nThis paper considers preference completion in a general collaborative LETOR setting. Importantly, while the observations are assumed to be reliable indicators for relative preference ranking, their numerical scores may be quite deviant from the ground truth low rank preference matrix. Therefore, we aim at addressing preference completion under the following generalizations: 1. In a simple setting, for each entity, a score vector representing the its observed affinity interactions\nis assumed to be generated from an arbitrary monotonic transformation of the corresponding entries of the ground truth preference matrix. We make no further generative assumptions on observed scores beyond monotonicity with respect to the underlying low rank preference matrix. 2. We also consider a more general setting, where observed preferences of each entity represent specifications of a partial ranking in the form of a directed acyclic graph (DAG) \u2013 the nodes represent a subset of items, and each edge represents a strict ordering between a pair of nodes. Such rankings may be encountered when the preference scores are consolidated from multiple sources of feedback, e.g., comparative feedback (pairwise or listwise) solicited for independent subsets of items. This generalized setting cannot be handled by standard matrix completion without some way of transforming the DAG orderings into a score vector.\nOur work is in part motivated by an application to neuroimaging meta-analysis as outlined in the following. Cognitive neuroscience aims to quantify the link between brain function with behavior. This interaction is most often measured in humans using Functional Magnetic Resonance Imaging (fMRI) experiments that measure brain activity in response to behavioral tasks. After analysis, the conclusions are often summarized in neuroscience publications which include a table of brain locations that are most actively activated in response to an experimental stimulus. These results can then be synthesized using meta-analysis techniques to derive accurate predictions of brain activity associated with cognitive terms (also known as forward inference) and prediction of cognitive terms associated with brain regions (also known as reverse inference). For our study, we used data from neurosynth [36] - a public repository1 which automatically scrapes information on published associations between brain regions and terms in cognitive neuroscience experiments.\nThe key contributions of the paper are summarized below. \u2022 We propose a convex estimator for low rank preference completion using limited supervision,\naddressing: (a) arbitrary monotonic transformations of preference scores; and (b) partial rankings over items (Section 3.1). We derive generalization error bounds for a surrogate ranking loss that quantifies the trade\u2013off between data\u2013fit and regularization (Section 5). \u2022 We propose efficient algorithms for the estimate under total and partially ordered observations. In the case of total orders, in spite of increased generality, the computational complexity of our algorithm is within a log factor of the standard convex algorithms for matrix completion (Section 4). \u2022 The proposed algorithm is evaluated for a novel application of identifying associations between brain\u2013regions and cognitive terms from the neurosynth dataset [37] (Section 6). Such a large scale meta-analysis synthesizing information from the literature and related tasks has the potential to lead to novel insights into the role of brain regions in cognition and behavior."}, {"heading": "1.1 Notation", "text": "For a matrix M \u2208 Rd1\u00d7d2 , let \u03c31 \u2265 \u03c32 \u2265 . . . be singular values of M . Then, nuclear norm \u2016M\u2016\u2217 = \u2211 i \u03c3i, operator norm \u2016M\u2016op = \u03c31, and Frobenius norm \u2016M\u2016F = \u221a\u2211 i \u03c3 2 i . Let\n1http://neurosynth.org/\n[N ] = {1, 2, . . . , N}. A vector or a set x indexed by j \u2208 [N ] is sometimes denoted as (xj)Nj=1 or simply (xj) whenever N is unambiguous. Let \u2126 \u2282 [d1]\u00d7 [d2] denote a subset of indices of a matrix in Rd1\u00d7d2 . For j \u2208 [d2], let \u2126j = {(i\u2032, j\u2032) \u2208 \u2126 : j\u2032 = j} \u2282 \u2126 denotes the subset of entries in \u2126 from the jth column. Given \u2126 = {(is, js) : s = 1, 2, . . . , |\u2126|}, P\u2126 : X \u2192 (Xisjs) |\u2126| s=1 \u2208 R|\u2126| is the linear subsampling operator, and P\u2217\u2126 : R|\u2126| \u2192 Rd1\u00d7d2 is its adjoint, i.e \u3008y,P\u2126(X)\u3009 = \u3008X,P\u2217\u2126(y)\u3009. For conciseness, we sometimes use the notation X\u2126 to denote P\u2126(X)."}, {"heading": "2 Related Work", "text": "Matrix Completion: Low rank matrix completion has an extensive literature; a few examples include [21; 6; 20; 27] among several others. However, the bulk of these works including those in the context of ranking/recommendation applications focus on (a) fitting the observed numerical scores using squared loss, and (b) evaluating the results on parameter/rating recovery metrics such as root mean squared error (RMSE). The shortcomings of such estimators and results using squared loss in ranking applications have been studied in some recent research [11; 10]. Motivated by collaborative ranking applications, there has been growing interest in addressing matrix completion within an explicit LETOR framework. Weimer et al. [35] and Koyejo et al. [22] propose estimators that involve non\u2013convex optimization problems and their algorithmic convergence and generalization behavior are not well understood. Some recent works provide parameter recovery guarantees for pairwise/listwise ranking observations under specific probabilistic distributional assumptions on the observed rankings [30; 25; 28]. In comparison, the estimators and algorithms in this paper are agnostic to the generative distribution, and hence have much wider applicability.\nLearning to rank (LETOR): LETOR is a structured prediction task of rank ordering relevance of a list of items as a function of pre\u2013selected features [24]. Currently, leading algorithms for LETOR are listwise methods [8] (as is the approach taken in this paper), which fully exploit the ranking structure of ordered observations, and offer better modeling flexibility compared to the pointwise [23] and pairwise methods [15; 17]. A recent listwise LETOR algorithm proposed the idea of monotone retargeting (MR) [2], which elegantly addresses listwise learning to rank (LETOR) task while maintaining the relative simplicity and scalability of pointwise estimation. MR was further extended to incorporate margins in the margin equipped monotonic retargeting (MEMR) formulation [1] to preclude trivial solutions that arise from scale invariance of the initial MR estimate in Acharyya et al. [2]. The estimator proposed in the paper is inspired from the the idea of MR and will be revisited later in the paper. In collaborative preference completion, rather than learning a functional mapping from features to ranking, we seek to exploit the low rank structure in jointly modeling the preferences of a collection of entities without access to preference indicative features.\nSingle Index Models (SIMs) Finally, literature on monotonic single index models (SIMs) also considers estimation under unknown monotonic transformations [16; 19]. However, algorithms for SIMs are designed to solve a harder problem of exactly estimating the non\u2013parametric monotonic transformation and are evaluated for parameter recovery rather than the ranking performance. In general, with no further assumptions, sample complexity of SIM estimators lends them unsuitable for high dimensional estimation. The existing high dimensional estimators for learning SIMs typically assume Lipschitz continuity of the monotonic transformation which explicitly uses the observed score values in bounding the Lipsciptz constant of the monotonic transformation [18; 12]. In comparison, our proposed model is completely agnostic to the numerical values of the preference scores."}, {"heading": "3 Preference Completion from Partial Rankings", "text": "Let the unobserved true preference scores of d2 entities for d1 items be denoted by a rank r min {d1, d2} matrix \u0398\u2217 \u2208 Rd1\u00d7d2 . For each entity j \u2208 [d2], we observe a partial or total ordering of preferences for a subset of items denoted by Ij \u2282 [d1]. Let nj = |Ij | denotes the number of items over which relative preferences of entity j are observed, so that \u2126j = {(i, j) : i \u2208 Ij} denotes the entity-item index set for j, and \u2126 = \u22c3 j \u2126j denotes the index set collected across entities. Let P\u2126 denote the sampling distribution for \u2126. The observed preferences of entity j are typically represented by a listwise preference score vector y(j) \u2208 Rnj .\n\u2200j \u2208 [d2], y(j) = gj(P\u2126j (\u0398\u2217 +W )), (1)\nwhere each (gj) are an arbitrary and unknown monotonic transformations, and W \u2208 Rd1\u00d7d2 is some non\u2013adversarial noise matrix sampled from the distribution PW . The preference completion task is to estimate a unseen rankings within each column of \u0398\u2217 from a subset of orderings (\u2126j , y(j))j\u2208[d2].\nAs (gj) are arbitrary, the exact values of (y(j)) are inconsequential, and the observed preference order can be specified by a constraint set parameterized by a margin parameter as follows:\nDefinition 1 ( \u2013margin Isotonic Set) The following set of vectors are isotonic to y \u2208 Rn with an > 0 margin parameter:\nRn\u2193 (y) = {x \u2208 Rn : \u2200 i, k \u2208 [n], yi < yk \u21d2 xi \u2264 xk \u2212 }.\nIn addition to score vectors, isotonic sets of the form Rn\u2193 (y) are equivalently defined for any DAG y = G([n], E) which denotes a partial ranking among the vertices, with the convention that (i, k) \u2208 E \u21d2 \u2200x \u2208 Rn\u2193 (y), xi \u2264 xk \u2212 . We note from Definition 1 that ties are not broken at random, e.g., if yi1 = yi2 < yk, then \u2200x \u2208 Rn\u2193 (y), xi1 \u2264 xk \u2212 , xi2 \u2264 xk \u2212 , but no particular ordering between xi1 and xi2 is specified.\nLet y(k) denote the kth smallest entry of y \u2208 Rn. We distinguish between three special cases of an observation y representing a partial ranking over [n]. (A) Strict Total Order: y(1) < y(2) < . . . < y(n). (B) Blockwise Total Order: y(1) \u2264 y(2) \u2264 . . . \u2264 y(n), with K \u2264 n unique values. (C) Arbitrary DAG: Partial order induced by a DAG y = G([n], E)."}, {"heading": "3.1 Monotone Retargeted Low Rank Estimator", "text": "Consider any scalable pointwise learning algorithm that fits a model to exact preferences scores. Since no generative model (besides monotonicity) is assumed for the raw numerical scores in the observations, in principle, the scores y(j) for entity j can be replaced or retargeted to any rankingpreserving scores, i.e., by any vector in Rnj\u2193 (y(j)). Monotone Retargeting (MR) [2] exploits this observation to address the combinatorial listwise ranking problem [24] while maintaining the relative simplicity and scalability of pointwise estimates (regression). The key idea in MR is to alternately fit a pointwise algorithm to current relevance scores, and retarget the scores by searching over the space of all monotonic transformations of the scores. Our approach extends and generalizes monotone retargeting for the preference prediction task.\nWe begin by motivating an algorithm for the noise free setting, where it is clear that \u0398\u2217\u2126j \u2208 R nj \u2193 (y (j)), so we seek to estimate a candidate preference matrix X that is in the intersection of (a) the data constraints from the observed preference rankings {X\u2126j \u2208 R nj \u2193 (y\n(j))}, and (b) the model constraints \u2013 in this case low rankness induced by constraining the nuclear norm \u2016X\u2016\u2217. For robust estimation in the presence of noise, we may extend the noise free approach by incorporating a soft penalty on constraint violations. Let z \u2208 R|\u2126|, and with slight abuse of notation, let z\u2126j \u2208 Rnj denote vector of the entries of z \u2208 R|\u2126| corresponding to \u2126j \u2282 \u2126. Upon incorporating the soft penalties, the monotone retargeted low rank estimator is given by:\nX\u0302 = Argmin X min z\u2208R|\u2126|\n\u03bb\u2016X\u2016\u2217 + 1\n2 \u2016z \u2212 P\u2126(X)\u201622 s.t.\u2200j, z\u2126j \u2208 R nj \u2193 (y (j)), (2)\nwhere the parameter \u03bb controls the trade\u2013off between nuclear norm regularization and data fit, and X\u0302 is the set of minimizers of (2). We note that Rn\u2193 (y) is convex, and \u2200\u03bb \u2265 1, the scaling \u03bbRn\u2193 (y) = {\u03bbx \u2200 x \u2208 Rn\u2193 (y)} \u2286 Rn\u2193 (y). The above estimate can be computed using efficient convex optimization algorithms and can handle arbitrary monotonic transformation of the preference scores, thus providing higher flexibility compared to the standard matrix completion.\nAlthough (2) is specified in terms of two parameters, due to the geometry of the problem, it turns out that \u03bb and are not jointly identifiable, as discussed in the following proposition.\nProposition 1 The optimization in (2) is jointly convex in (X, z). Further, \u2200\u03b3 > 0, (\u03bb, \u03b3 ) and (\u03b3\u22121\u03bb, ) lead to equivalent estimators, specifically X\u0302 (\u03bb, \u03b3 ) = \u03b3\u22121X\u0302 (\u03b3\u22121\u03bb, ).\nSince, positive scaling of X\u0302 preserves the resultant preference order, using Proposition 1 without loss of generality, only one of or \u03bb requires tuning with the other remaining fixed."}, {"heading": "4 Optimization Algorithm", "text": "The optimization problem in (2) is jointly convex in (X, z). Further, we later show that the proximal operator of the non\u2013differential component of the estimate \u03bb\u2016X\u2016\u2217 + \u2211 j I(z\u2126j \u2208 R nj \u2193 (y\n(j))) is efficiently computable. This motivates using the proximal gradient descent algorithm [29] to jointly update (X, z). For an appropriate step size \u03b1 = 1/2 and the resulting updates are as follows:\n\u2022 X Update: Singular Value Thresholding The proximal operator for \u03c4\u2016.\u2016\u2217 is the singular value thresholding operator S\u03c4 . For X with singular value decomposition X = U\u03a3V and \u03c4 \u2265 0, S\u03c4 (X) = Us\u03c4 (\u03a3)V, where s\u03c4 is the soft thresholding operator given by s\u03c4 (x)i = max{xi\u2212 \u03c4, 0}. \u2022 z Update: Parallel Projections For hard constraints on z, the proximal operator at v is the Euclidean projection on the constraints given by z \u2190 argminz\u2016z\u2212v\u201622, s.t. z\u2126j \u2208 R nj \u2193 (y\n(j)) \u2200j \u2208 [d2]. These updates decouple along each entity (column) z\u2126j and can be trivially parallelized. Efficient projections ontoRnj\u2193 (y(j)) are discussed Section 4.1.\nAlgorithm 1 Proximal Gradient Descent for (2) with input \u2126, {y(j)j }, and paramter \u03bb for k = 0, 1, 2, . . . , Until (stopping criterion) X(k+1) =S\u03bb/2 ( X(k) + 1 2 (P\u2217\u2126(z(k) \u2212X (k) \u2126 ) ) , (3)\n\u2200j, z(k+1)\u2126j = ProjRnj\u2193 (yj) ( z(k)\u2126j +X(k)\u2126j 2 ) . (4)\n4.1 Projection onto Rn\u2193 (y)\nWe begin with the following definitions that are used in characterizingRn\u2193 (y).\nDefinition 2 (Adjacent difference operator) The adjacent difference operator in Rn, denoted by Dn : Rn \u2192 Rn\u22121 is defined as (Dnx)i = xi \u2212 xi+1, for i \u2208 [n\u2212 1].\nDefinition 3 (Incidence Matrix) For a directed graph G(V,E), the incidence matrixAG \u2208 R|V |\u00d7|E| is such that: if the jth directed edge ej \u2208 E is from ith node to kth node, then (AG)ij = 1, (AG)kj = \u22121, and (AG)lj = 0, \u2200l 6= i or k.\nProjection ontoRn\u2193 (y) is closely related to the isotonic regression problem of finding a univariate least squares fit under consistent order constraints (without margins). This isotonic regression problem in Rn can be solved exactly in O(n) complexity using the classical Pool of Adjacent Violators (PAV) algorithm [14; 4] as:\nPAV(v) = argmin z\u2032\u2208Rn\n||z\u2032 \u2212 v||2 s.t. z\u2032i \u2212 z\u2032i+1 \u2264 0. (5)\nAs we discuss, simple adaptations of isotonic regression can be used for projection onto -margin isotonic sets for the three special cases of interest as summarized in Table 1.\n(A) Strict Total Order: y(1) < y(2) < . . . y(n) In this setting, the constraint set can be characterized asRn\u2193 (y) = {x : Dnx \u2264 \u2212 1}, where 1 is a vector of ones. For this case projection ontoRn\u2193 (y) differs from (5) only in requiring an \u2013separation and a straight forward extension of the PAV algorithm [4] can be used. Let dsl \u2208 Rn be any vector such that 1 = \u2212Dndsl, then by simple substitutions, ProjRn\u2193 (y)(x) = PAV(x\u2212 d sl) + dsl.\n(B) Blockwise Total Order: y(1) \u2264 y(2) \u2264 . . . \u2264 y(n) This is a common setting for supervision in many preference completion applications, where the listwise ranking preferences obtained from ratings over discrete quantized levels 1, 2, . . . ,K, with K n are prevalent. Let y be partitioned into K \u2264 n blocks P = {P1, P2, . . . PK}, such that the entries of y within each partition are equal, and the blocks themselves are strictly ordered,\ni.e., \u2200k \u2208 [K], sup y(Pk\u22121)< inf y(Pk) = sup y(Pk) < inf y(Pk+1),\nwhere P0 = PK+1 = \u03c6, and y(P ) = {yi : i \u2208 P}. Let dbl \u2208 Rn be such that dbli = \u2211K k=1 k Ii\u2208Pk is a vector of block indices dbl =\n[1, 1, .. \u2223\u22232, 2, ..\u2223\u2223K,K, ..,K]>. Let \u03a0P be a set of valid permutations that permute entries only within blocks {Pk \u2208 P}, thenRn\u2193 (y) = {x :\u2203\u03c0\u2208\u03a0P ,Dn\u03c0(x) \u2264 \u2212 Dndbl}. We propose the following steps to compute z\u0302 = ProjRn\u2193 (y)(x) in this case:\nStep 1. \u03c0\u2217(x) s.t. \u2200k \u2208 [K], \u03c0\u2217(x)Pk = sort(xPk) Step 2. z\u0302 = PAV (\u03c0\u2217(x)\u2212 dbl) + dbl.\n(6)\nThe correctness of (6) is summarized by the following Lemma.\nLemma 2 Estimate z\u0302 from (6) is the unique minimizer for\nargmin z \u2016z \u2212 x\u201622 s.t. \u2203\u03c0 \u2208 \u03a0P : Dn\u03c0(z) \u2264 \u2212 Dndbl.\n(C) Arbitrary DAG: y = G([n], E) An arbitrary DAG (not necessarily connected) can be used to represent any consistent order constraints over its vertices, e.g., partial rankings consolidated from multiple listwise/pairwise scores. In this case, the \u2013margin isotonic set is given by Rn\u2193 (y) = {x : A>G x \u2264 \u2212 1} (c.f. Definition 3). Consider dDAG \u2208 Rn such that ith entry dDAGi is the length of the longest directed chain connecting the topological descendants of the node i. It can be easily verified that, the isotonic regression algorithm for arbitrary DAGs applied on x\u2212 dDAG gives the projection ontoRn\u2193 (y). In this most general setting, the best isotonic regression algorithm for exact solution requiresO(nm2 +n3 log n2) computation [34], where m is the number of edges in G. While even in the best case of m = o(n), the computation can be prohibitive, we include this case for completeness. We also note that this case of partial DAG ordering cannot be handled in the standard matrix completion setting without consolidating the partial ranks to total order."}, {"heading": "4.2 Computational Complexity", "text": "It can be easily verified that gradient of 12\u2016P\u2126(X) \u2212 z\u2016 2 2 is 2\u2013Lipschitz continuous. Thus, from standard results on convegence proximal gradient descent [29], Algorithm 1,converges to within an error in objective in O(1/ ) iterations. Compared to proximal algorithms for standard matrix completion [5; 26], the additional complexity in Algorithm 1 arises in the z update (4), which is a simple substitution z(k) = X(k)\u2126 in standard matrix completion. For total orders, the z update of (4) is highly efficient and is asymptotically within an additional log |\u2126| factor of the computational costs for standard matrix completion."}, {"heading": "5 Generalization Error", "text": "Recall that yj are (noisy) partial rankings of subset of items for each user, obtained from gj(\u0398\u2217j +Wj) where W is a noise matrix and gj are unknown and arbitrary transformations that only preserve that ranking order within each column. The estimator and the algorithms described so far are independent of the sampling distribution generating (\u2126, {yj}). In this section we quantify simple generalization error bounds for (2).\nAssumption 1 (Sampling (P\u2126)) For a fixed W and \u0398\u2217, we assume the following sampling distribution. Let be c0 a fixed constant and R be pre\u2013specified parameter denoting the length of single\nlistwise observation. For s = 1, 2, . . . , |S| = c0d2 log d2,\nj(s) \u223c uniform[d2], I(s) \u223c randsample([d1], R), \u2126(s) = {(i, j(s)) : i \u2208 I(s)}, y(s) = gj(s)(P\u2126(s)(\u0398\u2217 +W )).\n(7)\nFurther, we define the notation: \u2200j, Ij = \u22c3 s:j(s)=j I(s), \u2126j = \u22c3 s:j(s)=j \u2126(s), and nj = |\u2126j |.\nFor each column j, the listwise scores {y(s) : j(s) = j} jointly define a consistent partial ranking of Ij as the scores are subsets of a monotonically transformed preference vector gj(\u0398\u2217j +Wj). This consistent ordering is represented by a DAG y(j) = PartialOrder({y(s) : j(s) = j}). We also note that O(d2 log d2) samples ensures that each column is included in the sampling with high probability.\nDefinition 4 (Projection Loss) Let y = G([n], E) or y \u2208 Rn define a partial ordering or total order in Rn, respectively. We define the following convex surrogate loss over partial rankings.\n\u03a6(x, y) = minz\u2208Rn\u2193 (y) \u2016x\u2212 z\u20162\nTheorem 3 (Generalization Bound) Let X\u0302 be an estimate from (2). With appropriate scaling let \u2016X\u0302\u2016F = 1 , then for constants K1 K2, the following holds with probability greater than 1\u2212 \u03b4 over all observed rankings {y(j),\u2126j : j \u2208 [d2]} drawn from (7) with |S| \u2265 c0d2 log d2:\nEy(s),\u2126(s)\u03a6(X\u0302\u2126(s), y(s)) \u2264 1\n|S| |S|\u2211 s=1 \u03a6(X\u0302\u2126(s), y(s)) +K1 \u2016X\u0302\u2016\u2217 log1/4 d\u221a d1d2\n\u221a d log d\nR|S| +K2\n\u221a log 2/\u03b4\n|S| .\nTheorem 3 quantifies the test projection loss over a random R length items I(s) drawn for a random entity/user j(s). The bound provides a trade\u2013off between observable training error and complexity defined by nuclear norm of the estimate."}, {"heading": "6 Experiments", "text": "We evaluate our model on two collaborative preference estimation tasks: (a) a standard user-item recommendataion task on a benchmarked dataset from Movielens, and (b) identifying associations between brain\u2013regions and cognitive terms using the neurosynth dataset [37].\nBaselines: The following baseline models are compared in our experiments:\n\u2022 Retargeted Matrix Completion (RMC): the estimator proposed in (2). \u2022 Standard Matrix Completion (SMC) [7]: We primarily compare our estimator with the\nstandard convex estimator for matrix completion using nuclear norm minimization. \u2022 Collaborative Filtering Ranking CoFi-Rank [35]: This work addresses collaborative filtering\ntask in a listwise ranking setting.\nFor SMC and MRPC, the hyperparameters were tuned using grid search on a logarithmic scale. Due to high computational cost with tuning parameters in CofiRank, we use the code and default parameters provided by the authors.\nEvaluation metrics: The performance on preference estimation tasks are evaluated on four ranking metrics: (a) Normalized Discounted Cummulative Gains (NDCG@N), (b) Precision@N, (c) Spearmann Rho, and (d) Kendall Tau, where the later two metrics measure the correlation of the complete ordering of the list, while the former two metrics primarily evaluate the correctness of ranking in the top of the list (see Liu et. al. [24] for further details on these metrics).\nMovielens dataset (blockwise total order) Movielens is a movie recommendation website administered by GroupLens Research. We used competitive benchmarked movielens 100K dataset. We used the 5\u2013fold train/test splits provided with the dataset (the test splits are non-overlapping). We discarded a small number of users that had less than 10 ratings in any of 5 training data splits. The resultant dataset consists of 923 users and 1682 items. The ratings are blockwise ordered \u2013 taking one of 5 values in the set {1, 2, . . . , 5}. During testing, for each user, the competing models return\na ranking of the test-items, and the performance is averaged across test-users. Table 2 presents the results of our evaluation averaged across 5 train/test splits on the Movielens dataset, along with the standard deviation. We see that the proposed retargeted matrix completion (RMC) significantly and consistently outperforms SMC and CoFi-Rank [35] across ranking metrics.\nNeurosynth Dataset (almost total order) Neurosynth[37] is a publicly available database consisting of data automatically extracted from a large collection of functional magnetic resonance imaging (fMRI) publications (11,362 publications in current version). For each publication , the database contains the abstract text and all reported 3-dimensional peak activation coordinates in the study. The text is pre-processed to remove common stop-words, and any text with less than .1% frequency, leaving a total of 3169 terms. We applied the standard brain map to the activations, removing voxels outside of the grey matter. Next the activations were downsampled from 2mm3 voxels to 10mm3 voxels using the nilearn python package, resulting in a total of 1231 dense voxels. The affinity measure between 3169 terms and 1231 consolidated voxels is obtained by multiplying the term\u00d7 publication and the publication\u00d7 voxels matrices. The resulting data is dense high-rank preference matrix. With very few tied preference values, this setting best fits the case of total ordered observations (case A in Section 4.1). Using this data, we consider the reverse inference task of ranking cognitive concepts (terms) for each brain region (voxel) [37].\nTrain-val-test: We used 10% of randomly sampled entries of the matrix as test data and a another 10% for validation. We created training datasets at various sample sizes by subsampling from the remaining 80% of the data. This random split is replicated multiple times to obtain 3 bootstrapped datasplits (note that unlike cross validation, the test datasets here can have some overlapping entries).\nThe results in Fig. 1 show that the proposed estimate from (2) outperforms standard matrix completion in terms of popular ranking metrics."}, {"heading": "7 Conclusion", "text": "Our work addresses the problem of collaboratively ranking; a task of growing importance to modern problems in recommender systems, large scale meta-analysis, and related areas. We proposed a novel convex estimator for collaborative LETOR from sparsely observed preferences, where the observations could be either score vectors representing total order, or more generally directed acyclic graphs representing partial orders. Remarkably, in the case of complete order, the complexity of our\nalgorithm is within a log factor of the state\u2013of\u2013the\u2013art algorithms for standard matrix completion. Our estimator was empirically evaluated on real data experiments.\nAcknowledgments SG and JG acknowledge funding from NSF grants IIS-1421729 and SCH 1418511."}, {"heading": "A Estimator and Algorithm", "text": "A.1 Proof of Proposition 1\nStatement of the Proposition: The optimization in (2) is jointly convex in (X, z). Further, \u2200\u03b3 > 0, (\u03bb, \u03b3 ) and (\u03b3\u22121\u03bb, ) lead to equivalent estimators, specifically X\u0302 (\u03bb, \u03b3 ) = \u03b3\u22121X\u0302 (\u03b3\u22121\u03bb, ). Proof: Let f\u03bb, (X) = min\nz\u2208R|\u2126| \u03bb\u2016X\u2016\u2217 + 12\u2016z \u2212 P\u2126(X)\u2016 2 2\ns.t. \u2200j, z\u2126j \u2208 R nj \u2193 (y (j)),\n.\nWe have,\nf\u03bb,\u03b3 (X) = min z \u03bb\u2016X\u2016\u2217 +\n1 2 \u2016z \u2212 P\u2126(X)\u201622 s.t. z\u2126j \u2208 R nj \u2193\u03b3 (y (j)),\n(a) = min\nz\u0304 \u03bb\u2016X\u2016\u2217 +\n1 2 \u2016\u03b3z\u0304 \u2212 P\u2126(X)\u201622 s.t. z\u0304\u2126j \u2208 R nj \u2193 (y (j)),\n= \u03b32min z\u0304\n\u03bb \u03b3 \u2016X/\u03b3\u2016\u2217 + 1 2 \u2016z\u0304 \u2212 P\u2126(X/\u03b3)\u201622 s.t. z\u0304\u2126j \u2208 R nj \u2193 (y (j)),\n= \u03b32f\u03b3\u22121\u03bb, (X/\u03b3),\n(8)\nwhere (a) follows from reparameterizing the optimization using z\u0304 = z/\u03b3 as the geometry of Rnj\u2193\u03b3 (y(j)) which is set of linear constraints of the form zi \u2212 zk \u2264 \u03b3 . From above set of equations, if X \u2208 Argmin\nX f\u03bb,\u03b3 (X), then \u03b3\u22121X \u2208 Argmin X f\u03b3\u22121\u03bb, (X).\nA.2 Proof of Lemma 2\nStatement of the Lemma: Consider the following steps,\nStep 1. \u03c0\u2217(x) s.t. \u2200k \u2208 [K], \u03c0\u2217(x)Pk = sort(xPk) Step 2. z\u0302 = PAV (\u03c0\u2217(x)\u2212 dbl) + dbl.\n(9)\nEstimate z\u0302 is the unique minimizer for\nargmin z \u2016z \u2212 x\u201622 s.t. \u2203\u03c0 \u2208 \u03a0P : Dn\u03c0(z) \u2264 Dndbl.\nProof: A version of the lemma for linear orders was proved in [2]. In general,\nmin z \u2016z \u2212 x\u201622 s.t. \u2203\u03c0 \u2208 \u03a0P : Dn\u03c0(z) \u2264 Dndbl\n= min z,\u03c0\u2208\u03a0P\n\u2016z \u2212 x\u201622 s.t. Dn\u03c0(z) \u2264 Dndbl\n(a) = min\nw min \u03c0\u2208\u03a0P\n\u2016\u03c0\u22121(w + dbl)\u2212 x\u201622 s.t. Dnw\n\u2264 0 (b)= min w:Dnw\u22640 min \u03c0\u2208\u03a0P \u2016w + dbl \u2212 \u03c0(x)\u201622 (c) = min\nw:Dnw\u22640 \u2016w + dbl \u2212 \u03c0\u2217(x)\u201622, (10)\nwhere \u03c0\u2217(x) is the update from Step 1 stated above, (a) follows reparametrizing w := \u03c0(z)\u2212 dbl, (b) follows as for all permutations \u03c0 using \u2016x\u201622 = \u2016\u03c0(x)\u201622, and (c) follows form Proposition 4 as Dnw \u2264 0 from constraints and Dndbl \u2264 0 by construction. The final minimization is solved using Step 2.\nProposition 4 For any sorted z \u2208 Rn such Dnz \u2264 0, \u03c0\u2217 = argmin \u03c0\u2208\u03a0P \u2016z \u2212 \u03c0(x)\u201622, where \u03c0\u2217 is the permutation from Step 1.\n\u03a0P allows for all possible permutations within each partition Pk. Proposition follows from optimality of sorting within each block."}, {"heading": "B Generalization Error", "text": "B.1 Background\nDefinition 5 (Rademacher Complexity) LetX1, X2, . . . , Xn \u2208 X be drawn iid from a distribution PX . For a function class F : X \u2192 A, the empirical Rademacher complexity is defined as,\nR\u0302n(F) = E\u03c3 sup f\u2208F ( 1 n n\u2211 i=1 \u03c3if(Xi) ) ,\nwhere \u03c31, \u03c32, . . . , \u03c3n are iid Rademacher variables, i.e., \u00b11 with probability 1/2.\nThe Rademacher complexity with respect tp PX is then defined as Rn(F) = EPX R\u0302n(F).\nTheorem 5 (Generalization Error Bound (Corollary 15 in [3])) Consider a loss function ` : Y \u00d7 Rm \u2192 [0, 1] and a bounded function class F : X \u2192 Rm such that F is a direct sum of F1,F2, . . . ,Fm. Further, if ` is L\u2013Lipschitz continuous with respect to Euclidean distance on Rm and is uniformly bounded. Let {(Xi, Yi), i = 1, 2, . . . , n} be sampled form a distribution PX,Y . Then there exists a constant c such that, for any integer n and any \u03b4 \u2208 (0, 1), with probability atleast 1\u2212 \u03b4, over all sample of length n, the following holds for every f \u2208 F:\nEX,Y `(Y, f(X)) \u2264 1\nn n\u2211 i=1 `(Yi, f(Xi)) + cL m\u2211 i=1 R\u0302n(Fm) + \u221a 8 log(2/\u03b4) n\nB.2 Proof of Theorem 3\nLemma 6 \u03c6(., y) is convex and 2\u2013Lipschitz continuous with respect to `2 norm.\nProof: Convexity follows form \u03a6 being a marginal of a convex function. For a any convex set C and its projection operator PC , we have the following for all x, x\u2032:\n|\u2016x\u2212 PC(x)\u20162 \u2212 \u2016x\u2032 \u2212 PC(x\u2032)\u20162| \u2264 \u2016x\u2212 PC(x)\u2212 x\u2032 + PC(x\u2032)\u20162 \u2264 \u2016x\u2212 x\u2032\u20162 + \u2016PC(x)\u2212 PC(x\u2032)\u20162 \u2264 2\u2016x\u2212 x\u2032\u20162\nConsider a vector class of functions in RR, FR = {\u2126(s) \u2192 X\u2126(s) \u2208 RR : \u2016X\u2016\u2217 \u2264 M}, where \u2126(s) are sampled as in the main paper. Also, consider another function classes Fij = {(i, j)\u2192 Xij : \u2016X\u2016\u2217 \u2264M}. It can be seen that FR is an R way direct sum of Fij . In order to use Theorem 5, we need to estimate the Rademacher complexity of Fij .\nLemma 7 Let \u2126 = \u222aj\u2126j obtained from combining samples form Assumption 1. The distribution of \u2126 is equivalent to uniformly sampling with replacement |\u2126| = c0d2R log d2 entries from [d1]\u00d7 [d2]. Proof : For k = 1, 2 . . . |\u2126|, \u2200(i, j) \u2208 [d1]\u00d7 [d2], P((i, j) = \u2126k) = 1d1d2 .\nThus, given (i, j) \u2208 [d1]\u00d7 [d2], P((i, j) \u2208 \u2126) = |\u2126|d1d2 .\nLemma 8 (Theorem 29 in [32]) For a universal constant K, the Rademacher complexity of matrices in Rd1\u00d7d2 of trace norm M , over uniform sampling of index pairs \u2126 is bounded by the following whenever |\u2126| > d log d\nR({\u2016X\u2016\u2217 \u2264M}) \u2264 K M log1/4 d\u221a\nd1d2\n\u221a d log d\n|\u2126| (11)\nFrom Lemma 7, it can be seen that Lemma 8 applies to samples drawn according to Assumption 1.\nFor the function class FR = {\u2126(s)\u2192 X\u2126(s) : \u2016X\u2016\u2217 \u2264M}, for some M . The theorem now follows by using the Rademacher complexity bound in Lemma 8 and Lipschitz continuity of \u03a6(., y) from 6 in Theorem 5."}], "references": [], "referenceMentions": [], "year": 2016, "abstractText": "We propose a novel and efficient algorithm for the collaborative preference comple-<lb>tion problem, which involves jointly estimating individualized rankings for a set of<lb>entities over a shared set of items, based on a limited number of observed affinity<lb>values. Our approach exploits the observation that while preferences are often<lb>recorded as numerical scores, the predictive quantity of interest is the underlying<lb>rankings. Thus, attempts to closely match the recorded scores may lead to over-<lb>fitting and impair generalization performance. Instead, we propose an estimator<lb>that directly fits the underlying preference order, combined with nuclear norm<lb>constraints to encourage low\u2013rank parameters. Besides (approximate) correctness<lb>of the ranking order, the proposed estimator makes no generative assumption on<lb>the numerical scores of the observations. One consequence is that the proposed<lb>estimator can fit any consistent partial ranking over a subset of the items repre-<lb>sented as a directed acyclic graph (DAG), generalizing standard techniques that<lb>can only fit preference scores. Despite this generality, for supervision representing<lb>total or blockwise total orders, the computational complexity of our algorithm is<lb>within a log factor of the standard algorithms for nuclear norm regularization based<lb>estimates for matrix completion. We further show promising empirical results for a<lb>novel and challenging application of collaboratively ranking of the associations<lb>between brain\u2013regions and cognitive neuroscience terms.", "creator": "LaTeX with hyperref package"}}}