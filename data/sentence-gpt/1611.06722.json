{"id": "1611.06722", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "21-Nov-2016", "title": "False-Friend Detection and Entity Matching via Unsupervised Transliteration", "abstract": "Transliterations play an important role in multilingual entity reference resolution, because proper names increasingly travel between languages in news and social media. Previous work associated with machine translation targets transliteration only single between language pairs, focuses on specific classes of entities (such as cities and celebrities) and relies on manual curation, which limits the expression power of transliteration in multilingual environment. This limitation can be overcome by combining the language-based information between each other to facilitate translation and translation. In this work, we introduce the implementation of the Transliteration Transliteration Transliteration Transliteration Transliteration Transliteration Transliteration Transliteration Transliteration Transliteration Transliteration Transliteration Transliteration Transliteration Transliteration Transliteration Transliteration Transliteration Transliteration Transliteration Transliteration Transliteration Transliteration Transliteration Transliteration Transliteration Transliteration Transliteration Transliteration Transliteration Transliteration Transliteration Transliteration Transliteration Transliteration Transliteration Transliteration Transliteration Transliteration Transliteration Transliteration Transliteration Transliteration Transliteration Transliteration Transliteration Transliteration Transliteration Transliteration Transliteration Transliteration Transliteration Transliteration Transliteration Transliteration Transliteration Transliteration Transliteration Transliteration Transliteration Transliteration Transliteration Transliteration Transliteration Transliteration Transliteration Transliteration Transliteration Transliteration Transliteration Transliteration Transliteration Transliteration Transliteration Transliteration Transliteration Transliteration Transliteration Transliteration Transliteration Transliteration Transliteration Transliteration Transliteration Transliteration Transliteration Transliteration Transliteration Transliteration Transliteration Transliteration Transliteration Transliteration Transliteration Transliteration Transliteration Transliteration Transliteration Transliteration Transliteration Transliteration Transliteration Transliteration Transliteration Transliteration Transliteration Transliteration Transliteration Transliteration Transliteration Transliteration Transliteration Transliteration Transliteration Transliteration Transliteration Transliteration Transliteration Transliteration Transliteration Transliteration Transliteration Transliteration Transliteration Transliteration Transliteration Transliteration Transliteration Transliteration Transliteration Transliteration Transliteration Transliteration Transliteration Transliter", "histories": [["v1", "Mon, 21 Nov 2016 11:07:11 GMT  (1321kb,D)", "http://arxiv.org/abs/1611.06722v1", "11 Pages, ACL style"]], "COMMENTS": "11 Pages, ACL style", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["yanqing chen", "steven skiena"], "accepted": false, "id": "1611.06722"}, "pdf": {"name": "1611.06722.pdf", "metadata": {"source": "CRF", "title": "False-Friend Detection and Entity Matching via Unsupervised Transliteration", "authors": ["Yanqing Chen", "Steven Skiena"], "emails": ["cyanqing@cs.stonybrook.edu", "skiena@cs.stonybrook.edu"], "sections": [{"heading": null, "text": "By contrast, we present an unsupervised transliteration model covering 69 major languages that can generate good transliterations for arbitrary strings between any language pair. Our model yields top-(1, 20, 100) averages of (32.85%, 60.44%, 83.20%) in matching gold standard transliteration compared to results from a recently-published system of (26.71%, 50.27%, 72.79%). We also show the quality of our model in detecting true and false friends from Wikipedia high frequency lexicons. Our method indicates a strong signal of pronunciation similarity and boosts the probability of finding true friends in 68 out of 69 languages."}, {"heading": "1 Introduction", "text": "Transliterations play an important role in multilingual entity reference resolution, because proper names increasingly travel between languages. This process tends to create a substantial number of out of vocabulary (OOV) words in the multilingual analysis of news and social media. When \u201cGangnam style\u201d topped the music charts of more than 30 countries, a word imported from Korean suddenly became part of the language\nspoken by millions of people around the world. News events like the catastrophic failure at nuclear power plant bring words associated with new people and places (\u2018Fukushima\u201d) across languages into common use. These words do not reside in standard vocabulary lexicons, but are generated as needed via a process of transliteration. Detecting transliterated word pairs contributes to many language processing tasks, including entity resolution, translation, topic classification and sentiment analysis, as well as facilitates studying linguistic phenomenon like cross-language morphologic evolution. However, previous transliteration systems generally focus on a small number of language pairs. Further, they only consider morphological similarity even in translation systems, creating a problem of \u201dfalse friends\u201d of word pairs which look/sound alike but mean different things.\nIn this paper, we target the problem of generating transliterations between arbitrary pairs of 69 languages, and detecting borrowed words and entities across these languages. We train both transliteration models and semantic word embeddings in an unsupervised manner using large-scale corpus from Wikipedia. As an example, Figure 1 shows our transliterations of the name \u2018obama into 25 non-Latin scripts. We provide both our transliteration (constructed from scratch) and lowest edit-distance match appearing in 100,000 most frequent Wikipedia lexicons for these languages. Our closest match proves to equal the gold standard for 20 out of 23 languages where it appears in the lexicon. Further, our constructed best differs from the gold standard name within at most one character substitution for 22 out of 25 languages.\nOur major contributions are:\n\u2022 Training Methods for Transliteration \u2013 We used Wikipedia to build a training set for transliteration, starting from the crosslanguage links between personal and place names in Wikipedia. We collect a dataset\nar X\niv :1\n61 1.\n06 72\n2v 1\n[ cs\n.C L\n] 2\n1 N\nov 2\n01 6\nwith 576,403 items contributing one or more transliterations from English to other languages yielding reasonable training and testing sets to learn transliterations. But this is a very dirty training set, because many such translation pairs are not transliterations (e.g. Estados Unidos for United States). We develop unsupervised methods to distinguish true transliterations from false, and thus clean the training set.\n\u2022 Accurate Transliteration via Substring Matching \u2013 We use an expectation maximization approach to use statistics of string alignments to train improved cost matrices via a Bayesian probability model. Our methods employ substring matching instead of single-character transition matrices, enabling\nthe recognition of phonemes, character bigrams, and beyond.\nWe have trained models that permit us to construct transliterations for any string between all pairs of 69 languages. We evaluate our work against a recently-published transliteration system (Durrani et al., 2014) which has been integrated into the Moses statistical machine translation system. We compare our transliteration to Moses on the four languages it supports (Arabic, Chinese, Hindi, and Russian), outperforming it in 61 of 64 standards over the set of languages.\n\u2022 Distinguishing Translations from False Friends \u2013 Similarly spelled or sounding words can have substantially different meanings. Such pairs that span language boundaries are called false friends, e.g. ropa in Spanish means clothes, not rope). By coupling transliteration pair analysis with semantic tests using distributed word embeddings, we can generate comprehensive lexicons of true and false friends. Our methods get very good results in tests against human annotated standards for French (F1=0.890) and Spanish (F1=0.825).\nWe use our approach to generate lexicons of true and false friends between English and 69 languages. We show that the lexically-closest cohort of word pairs has a higher probability of being true friends than words that are more lexically distant in 68 out of 69 languages, indicating our methods provide a good signal to identify borrowed words.\nWe provide a demo that can transliterate any English string to non-Latin languages 1. Our transliteration code, corpora, weight matrices, and false-friend lexicons for all 69 languages will be made publicly available upon acceptance of this paper.\nThe rest of this paper is organized as follows. We review related work in Section 2. In Section 3, we describe the procedure of collecting data. Section 4 talks about our model of learning characterbased transliteration cost matrices. We analyze the performance of our model in Section 5. Section 6 discusses the application of detecting true and false friends. Finally, we conclude with discussion and ideas for future work.\n1https://soundaword.appspot.com/"}, {"heading": "2 Related Work", "text": "Transliteration research first associates with the field of orthographic similarity detections since sound similarities co-exist with orthographic similarities (Brew et al., 1996; Mann and Yarowsky, 2001; Dijkstra et al., 1999; Van Heuven et al., 1998; Kondrak, 2004; Chamizo Dominguez and Nerlich, 2002). This work shows reasonableness of character-based transliteration between close languages (i.e. languages sharing characters) but does not discuss on distant language pairs.\nSimilarly, work on cognate identification also focus on close language pairs (Simard et al., 1993; Inkpen et al., 2005; Schepens et al., 2013; Boada et al., 2013; Kolb, 2008; Kondrak and Dorr, 2004; Resnik, 2011). However, we believe multilingual transliterations contribute to even distant languages (e.g. English and Japanese) when handling OOV words and resolving ambiguities.\nFurther transliteration researches divide into two branches. One tries to study delicate sound changing rules of specific languages (Knight and Graehl, 1998; AbdulJaleel and Larkey, 2003; Suwanvisat and Prasitjutrakul, 1998; Gao et al., 2005; Virga and Khudanpur, 2003; Jagarlamudi and Daume\u0301 III, 2012; Hong et al., 2009). Especially, an excellent ideas of using Wikipedia external links is proposed in (Kirschenbaum and Wintner, 2009; Kirschenbaum and Wintner, 2010) and achieve promising results in English-Hebrew transliteration using Moses (Koehn et al., 2007). However, all these systems are supervised and require extra linguistic background knowledge during processing. Plus, only one among this work evaluates transliteration on up to 4 languages and it is hard to generalize for multiple languages.\nThe other branch learns from only sequence of characters. One of the great advantages against sound based transliteration is that multilingual texts are much easier to obtain. Al-Onaizan and Knight (2002) compares phonetic based systems with spelling based systems on transliterations between English and Arabic. Pouliquen et al. (2006) makes transliteration model based on similar spelling rules in close languages. Recent work of Durrani et al. (2014) is integrated in Moses as a module, providing an unsupervised characterbased transliteration training model. Matthews (2007) proposed a proper name transliteration model on several language pairs. However, we believe utilizing character-based transliteration\nmodel can provide us with even more valuable information in natural language processing tasks."}, {"heading": "3 Data Collection and Pre-processing", "text": "Kirschenbaum and Wintner (2009) inspire us to use Wikipedia external links to build an aligned multilingual corpus. However, their work requires language-specific knowledge, for instance, discarding vowels and filtering out junk data using pre-defined consonant matching. In our task, we use the names of entities (people and places) to create a training set for transliteration. (Francis et al., 2002) state that over 40% of the brands choose to create corresponding foreign names via transliterations, By querying Freebase in categories containing 3,388,225 entries, we create a precise multilingual transliteration dictionary through Wikipedia page titles. We then perform a rough clean up procedure to (1) unify punctuation by converting hyphens, dots, comma to underscores and, (2) remove entries which do not adhere to the (first name, last name) or whole name format Our final collection contains 576,403 English entries with multilingual mapping.\nAs an additional resource, we query Google translation API to get formal translations of certain English proper nouns to all 69 languages. To reduce machine translation error, we manually pick 1,373 entities without no multi-sense ambiguities from the names of people (Census, 2000), countries and capital cities (Wikipedia.org, 2014), resulting in more than 70,000 pairs of proper name transliteration from English. Table 1 shows statistics of final data size in each language. 80% of the final data will be used for training, 10% is for tuning and the remaining 10% is for testing."}, {"heading": "4 Training Transliteration Model", "text": "The purpose of our training is to get a quantified measurement of sound similarities between any possible character strings in arbitrary scripts. We expect to learn pairwise word segmentations and n-gram statistics of correlated string pieces between different languages.\nWe maintain a cost matrix in which the cost of substituting any string s1 in Language1 with string s2 in Langauge2 will first be initialized to len(s1) + len(s2), including empty strings. This way each training example has a fixed cost equal to the total length of two strings. After that we start an R round iteration. In each round we go through all training examples and compute the minimum-cost segmentation matching. We keep tracking of all observations of matched n-grams during this round in observation table. We then adapt Bayesian setting mentioned in (Snyder and Barzilay, 2008) to update cost matrix according to probability calculated by observation table. Figure 2 illustrates the training procedure.\nData used in training example may be flawed as it might not reflect transliteration. Such training examples act as outliners during out training and we cannot find any reasonable matching even for partial string pieces. We here define \u201cDirtiness\u201d to measure how many training examples are flawed in training a specific language. Table 2 shows 10 dirtiest among 69 languages. Big languages included in Table 2 (e.g. Chinese, Korean) are not problematic since we have plenty of training examples. However, we expect a bad performance on small languages like Khmer and Amharic due to lack of high quality data.\nFigure 3a and Fig. 3b present heatmaps generated from our cost matrix showing 1-1 match-\ning rules between characters in these languages. The highlighted diagonals indicate strong similarity between identical Latin characters as expected, making transliteration inside the same language family meaningless. However, these matrices also reflect language differences: e.g. the Spanish \u201cy\u201d more often acts as an English \u201cj\u201d than an English \u201cy\u201d; and the Spanish \u201cb\u201d is close to English \u201cv\u201d while the French \u201cb\u201d matches only with English \u201cb\u201d."}, {"heading": "5 Experimental Results", "text": "In this section we evaluate the quality of our transliteration model."}, {"heading": "5.1 Baseline Model", "text": "We use the transliteration system described in (Durrani et al., 2014) as baseline method to compare our results. The Moses statistical machine translation system integrates their work as a module, and allows training unsupervised transliteration for OOV words. 2"}, {"heading": "5.2 Test Results", "text": "We first compare both systems trained on our Wikipedia dataset. We focus on the performance of phrase table, i.e. measurement of sound similarities between string pieces since our dataset does not contain corpus context, We generate the 100-best transliterations for entries in testing set on four languages of different language families: Chinese, Arabic, Hindi and Russian.\nWe repeated this test using third party datasets to check consistency of training models.3\nWe cleaned data and retained only name mapping to feed the model, since our model does not rely on context and target a generalized method for multiple languages. Note Moses provides several language-specific optimization methods, including weights optimizing (e.g. Mert) and Language Model Smoothing (e.g. Kneser-Ney) that\n2We use the following parameters when configuring Moses: maximum phrase length=3, language model N-gram order=3, language model smoothing & interpolation=Automatically Disabled, Interpolate; alignment heuristic=grow-diag-final; reordering=Monotone; and maximum distortion length=0. The weights for the models are: translation model (0.2, 0.2, 0.2, 0.2, 0.2), language model (0.5), and distortion Model (0.0), with word penalty=-1.\n3Chinese: Chinese - English Name Entity List sv1.0(LDC2005T34). Arabic: Combination of 10001 Arabic Names(LDC2005G02) and (Cettolo et al., 2012) made available for IWSLT-13. Hindi: Indian multi-parallel corpus (Post et al., 2012), and Russian: WMT-13 data (Bojar et al., 2014).\nmight improve performance (Durrani et al., 2014). However, given our goal of unsupervised transliteration, we did not attempt to employ these in our experiments.\nFigure 3 shows the statistics. Our system generally outperforms Moses, winning on 61 of 64 comparisons over the eight languages and metrics. The absolute closest transliteration (top-1) result only matches the translation target in roughly 1/3\nof the test examples, indicating that there are typically a large number of transliterations of similar edit cost. Indeed, the absolute performance score substantially increases with top-20 and top100 results, showing the need to reduce ambiguity through context matching. Our high scores under Levenshtein 1 metric show that we generate reasonable transliteration for a large fraction of strings, retaining good lexical consistency with\nrespect to the gold standard. Mosess performance substantially changes over difference training set, where we do equally well on both corpora."}, {"heading": "6 True and False Friends Detection", "text": "Although our transliteration model is accurate at detecting lexical similarity across languages, words that look alike or sound alike do not necessarily mean the same thing. False friends are word pairs across languages that look the same, but mean something different. For example, the Spanish word ropa means clothes, not rope.\nSuch false friends are the bane of students learning foreign languages. For our transliteration tests to identify true language borrowings, we must also establish that the words have similar semantics. To perform such a test, we relied on the Polyglot distributed word embeddings presented in (Al-Rfou et al., 2013). The L2 norm between two word representations captures its semantic distance.\nHowever, the Polyglot embeddings do not reside in same geometric space of latent dimensions for different languages. Thus instead of directly computing the distance between representations across languages, we check how many pairs of known translations lie within the 300 words closest words in each language in case we are lack of direct translation evidences. This process is illustrated in Figure 4."}, {"heading": "6.1 Evaluation against Human Annotation", "text": "For two languages (French and Spanish) we found published lists of true and false friends with English. We did an evaluation of our results against these human-annotated gold standards, in particular 1756 French-English cognates and 541 false friends suggested in (Inkpen et al., 2005) as well as 1345 of Spanish-English cognates 4 plus 217 false friends 5. Our performance is shown in the table below:\nLang F1 Acc French 0.890 89.2% Spanish 0.825 82.3%\nOur methods yield substantial agreement with these published standards, demonstrating the general soundness of our approach."}, {"heading": "6.2 Cross-Language Scan", "text": "Emboldened by these results, we performed a search for lexically/semantically similar words between English and all 69 of our transliterated languages. The results appear in Table 4. For each language, we report the number of false friends we identify (column N). The other three columns reflect different notions of true friends: single-word\n4http://spanishcognates.org/ 5http://www.esdict.com/\ntranslations according to Google (TP), near neighbors in embedding test (EP), and those which survive both of these semantic tests (B).\nWithout a language-specific analysis of each of the classes, it is difficult to determine which of these reflect language borrowings most accurately. The quality of the word embeddings vary substantially by language, as does the quality of Google\u2019s translation support. Our preferred measure of quality is the ratio of word pairs which survive both tests (B) over all that having Google translations (B+TP). The 33 languages colored red and green all have a ratio of > 0.5, indicating the highest quality embeddings. The red languages denote the five with the best embeddings, with the poorest five (in yellow) reflect languages with excessively small training data (Amharic and Khmer). Our methods have a particularly difficult time with Vietnamese, which bases a misleading similarity to Latin languages at the character level."}, {"heading": "6.3 Cross-Language Validation", "text": "Figure 5 provides a deeper assessment of our cross-language scan. For each language, we identified which words in its 100,000 word vocabulary were lexically very similar (edit distance \u2264 2, which is decided by initial value of substitution) to a word in the English vocabulary. We then con-\nsidered the next closest 10,000 word pairs, which should also be enriched in real transliterations (by contrast, only 0.01% random word pairs have a translation link) \u2013 but less enriched than the initial cohort. Indeed, Figure 5 (left) shows this to be true for 68 of 69 languages, denoted by points in the upper left triangle.\nTo establish that our embedding test accurately eliminates false friends, we pruned the lower half of each cohort according to the embedding test, i.e. retained only those words whose distance in embedding space was below the median value. Figure 5 (right) shows that this action dramatically shifts each language up and to the right. With the exception of three outlier languages (Vietnamese, Latin, and Maltese), well over 50% of our closest cohort are now true friends (translations). For somewhat more than half of the languages, the lexicographically second cohort is now rich in true friends to the 50% level."}, {"heading": "7 Conclusion", "text": "In this paper, we have developed transliteration models that accurately identify borrowed out of vocabulary (OOV) words, for 69 different languages. We have evaluated our transliterations against published gold standards when available and against intrinsic measures when such standards are not available. Further, we demonstrated that adding word embeddings to provide a semantic test enables us to distinguish true borrowings from false friends.\nThere are several directions to improve the fu-\nture quality of our transliteration model:\n\u2022 Phonetic Information \u2013 Our models improve with additional training data, particularly for resource-poor languages. An exciting way to increase this volume would be aligning speech translations as represented in a phonetic dictionary or sound system (e.g. IPA) as suggested in (Jagarlamudi and Daume\u0301 III, 2012).\n\u2022 Multiple transliteration \u2013 Though English Wikipedia has the richest resources in the world, it is not guaranteed that English is the source language of borrowed names. Currently we employ a star network of transliteration pairs centered through English. A richer graph with other important languages (e.g. Russian and Chinese) would improve performance.\n\u2022 Longer-Range Dependencies As we target transliteration, our model should utilize longer range dependencies. Observe that a silent e at the end of English words changes the pronunciation of vowels earlier in the word, so the \u201cli\u201d is different in \u201clit\u201d and \u201clike\u201d. Under context the Moses system with optimization exploits such phenomena, but we believe with we can learn such pronunciation features from the text itself."}, {"heading": "Acknowledgments", "text": "This research was partially supported by NSF Grants DBI-1060572 and IIS-1017181, and a Google Faculty Research Award."}], "references": [{"title": "Statistical transliteration for english-arabic cross language information retrieval", "author": ["AbdulJaleel", "Larkey2003] Nasreen AbdulJaleel", "Leah S Larkey"], "venue": "In Proceedings of the twelfth international conference on Information and knowledge", "citeRegEx": "AbdulJaleel et al\\.,? \\Q2003\\E", "shortCiteRegEx": "AbdulJaleel et al\\.", "year": 2003}, {"title": "Machine transliteration of names in arabic text", "author": ["Al-Onaizan", "Knight2002] Yaser Al-Onaizan", "Kevin Knight"], "venue": "In Proceedings of the ACL-02 workshop on Computational approaches to semitic languages,", "citeRegEx": "Al.Onaizan et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Al.Onaizan et al\\.", "year": 2002}, {"title": "Polyglot: Distributed word representations for multilingual nlp", "author": ["Al-Rfou et al.2013] Rami Al-Rfou", "Bryan Perozzi", "Steven Skiena"], "venue": "arXiv preprint arXiv:1307.1662", "citeRegEx": "Al.Rfou et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Al.Rfou et al\\.", "year": 2013}, {"title": "Effect of multiple translations and cognate status on translation recognition performance of balanced bilinguals", "author": ["Boada et al.2013] Roger Boada", "Rosa Sanchez-Casas", "Jose M Gavilan", "Jose E Garcia-Albea", "Natasha Tokowicz"], "venue": null, "citeRegEx": "Boada et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Boada et al\\.", "year": 2013}, {"title": "Word-pair extraction for lexicography", "author": ["Brew et al.1996] Chris Brew", "David McKelvie"], "venue": "In Proceedings of the second international conference on new methods in language processing,", "citeRegEx": "Brew and McKelvie,? \\Q1996\\E", "shortCiteRegEx": "Brew and McKelvie", "year": 1996}, {"title": "Wit3: Web inventory of transcribed and translated talks", "author": ["Christian Girardi", "Marcello Federico"], "venue": "In Proceedings of the 16th Conference of the European Association for Machine Translation (EAMT),", "citeRegEx": "Cettolo et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Cettolo et al\\.", "year": 2012}, {"title": "False friends: their origin and semantics in some selected languages", "author": ["Chamizo Dominguez", "Brigitte Nerlich"], "venue": "Journal of Pragmatics,", "citeRegEx": "Dominguez et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Dominguez et al\\.", "year": 2002}, {"title": "Recognition of cognates and interlingual homographs: The neglected role of phonology", "author": ["Jonathan Grainger", "Walter JB Van Heuven"], "venue": "Journal of Memory and Language,", "citeRegEx": "Dijkstra et al\\.,? \\Q1999\\E", "shortCiteRegEx": "Dijkstra et al\\.", "year": 1999}, {"title": "Integrating an unsupervised transliteration model into statistical machine translation", "author": ["Hieu Hoang", "Philipp Koehn", "Hassan Sajjad"], "venue": "EACL", "citeRegEx": "Durrani et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Durrani et al\\.", "year": 2014}, {"title": "The impact of linguistic differences on international brand name standardization: A comparison of english and chinese brand names of fortune-500 companies", "author": ["Janet PY Lam", "Jan Walls"], "venue": "Journal of International", "citeRegEx": "Francis et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Francis et al\\.", "year": 2002}, {"title": "Phoneme-based transliteration of foreign names for oov problem", "author": ["Gao et al.2005] Wei Gao", "Kam-Fai Wong", "Wai Lam"], "venue": "In Natural Language Processing\u2013IJCNLP", "citeRegEx": "Gao et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Gao et al\\.", "year": 2005}, {"title": "A hybrid approach to english-korean name transliteration", "author": ["Hong et al.2009] Gumwon Hong", "Min-Jeong Kim", "Do-Gil Lee", "Hae-Chang Rim"], "venue": "In Proceedings of the 2009 Named Entities Workshop: Shared Task on Transliteration,", "citeRegEx": "Hong et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Hong et al\\.", "year": 2009}, {"title": "Automatic identification of cognates and false friends in french and english", "author": ["Inkpen et al.2005] Diana Inkpen", "Oana Frunza", "Grzegorz Kondrak"], "venue": "In Proceedings of the International Conference Recent Advances in Natural Language Pro-", "citeRegEx": "Inkpen et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Inkpen et al\\.", "year": 2005}, {"title": "Regularized interlingual projections: evaluation on multilingual transliteration", "author": ["Jagarlamudi", "Hal Daum\u00e9 III"], "venue": "In Proceedings of the 2012 Joint Conference on Empirical Methods in Natural", "citeRegEx": "Jagarlamudi et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Jagarlamudi et al\\.", "year": 2012}, {"title": "Lightly supervised transliteration for machine translation", "author": ["Kirschenbaum", "Wintner2009] Amit Kirschenbaum", "Shuly Wintner"], "venue": "In Proceedings of the 12th Conference of the European Chapter of the ACL (EACL", "citeRegEx": "Kirschenbaum et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Kirschenbaum et al\\.", "year": 2009}, {"title": "A general method for creating a bilingual transliteration dictionary", "author": ["Kirschenbaum", "Wintner2010] Amit Kirschenbaum", "Shuly Wintner"], "venue": "In Proceedings of the Seventh conference on International Language Resources and Evaluation (LREC\u201910),", "citeRegEx": "Kirschenbaum et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Kirschenbaum et al\\.", "year": 2010}, {"title": "Disco: A multilingual database of distributionally similar words", "author": ["Peter Kolb"], "venue": "Proceedings of KONVENS-2008,", "citeRegEx": "Kolb.,? \\Q2008\\E", "shortCiteRegEx": "Kolb.", "year": 2008}, {"title": "Identification of confusable drug names: A new approach and evaluation methodology", "author": ["Kondrak", "Dorr2004] Grzegorz Kondrak", "Bonnie Dorr"], "venue": "In Proceedings of the 20th international conference on Computational Linguistics,", "citeRegEx": "Kondrak et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Kondrak et al\\.", "year": 2004}, {"title": "Combining evidence in cognate identification", "author": ["Grzegorz Kondrak"], "venue": "In Advances in Artificial Intelligence,", "citeRegEx": "Kondrak.,? \\Q2004\\E", "shortCiteRegEx": "Kondrak.", "year": 2004}, {"title": "Multipath translation lexicon induction via bridge languages", "author": ["Mann", "Yarowsky2001] Gideon S Mann", "David Yarowsky"], "venue": "In Proceedings of the second meeting of the North American Chapter of the Association", "citeRegEx": "Mann et al\\.,? \\Q2001\\E", "shortCiteRegEx": "Mann et al\\.", "year": 2001}, {"title": "Machine transliteration of proper names. Master\u2019s Thesis, University of Edinburgh, Edinburgh, United Kingdom", "author": ["David Matthews"], "venue": null, "citeRegEx": "Matthews.,? \\Q2007\\E", "shortCiteRegEx": "Matthews.", "year": 2007}, {"title": "Constructing parallel corpora for six indian languages via crowdsourcing", "author": ["Post et al.2012] Matt Post", "Chris Callison-Burch", "Miles Osborne"], "venue": "In Proceedings of the Seventh Workshop on Statistical Machine Translation,", "citeRegEx": "Post et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Post et al\\.", "year": 2012}, {"title": "Multilingual person name recognition and transliteration", "author": ["Ralf Steinberger", "Camelia Ignat", "Irina Temnikova", "Anna Widiger", "Wajdi Zaghouani", "Jan Zizka"], "venue": "arXiv preprint cs/0609051", "citeRegEx": "Pouliquen et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Pouliquen et al\\.", "year": 2006}, {"title": "Semantic similarity in a taxonomy: An information-based measure and its application to problems of ambiguity in natural language. arXiv preprint arXiv:1105.5444", "author": ["Philip Resnik"], "venue": null, "citeRegEx": "Resnik.,? \\Q2011\\E", "shortCiteRegEx": "Resnik.", "year": 2011}, {"title": "Cross-language distributions of high frequency and phonetically similar cognates", "author": ["Ton Dijkstra", "Franc Grootjen", "Walter JB van Heuven"], "venue": "PloS one,", "citeRegEx": "Schepens et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Schepens et al\\.", "year": 2013}, {"title": "Using cognates to align sentences in bilingual corpora", "author": ["Simard et al.1993] Michel Simard", "George F Foster", "Pierre Isabelle"], "venue": "In Proceedings of the 1993 conference of the Centre", "citeRegEx": "Simard et al\\.,? \\Q1993\\E", "shortCiteRegEx": "Simard et al\\.", "year": 1993}, {"title": "Unsupervised multilingual learning for morphological segmentation", "author": ["Snyder", "Barzilay2008] Benjamin Snyder", "Regina Barzilay"], "venue": "In ACL,", "citeRegEx": "Snyder et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Snyder et al\\.", "year": 2008}, {"title": "Orthographic neighborhood effects in bilingual word recognition", "author": ["Ton Dijkstra", "Jonathan Grainger"], "venue": "Journal of Memory and Language,", "citeRegEx": "Heuven et al\\.,? \\Q1998\\E", "shortCiteRegEx": "Heuven et al\\.", "year": 1998}, {"title": "Transliteration of proper names in cross-lingual information retrieval", "author": ["Virga", "Khudanpur2003] Paola Virga", "Sanjeev Khudanpur"], "venue": "In Proceedings of the ACL 2003 workshop on Multilingual and mixed-language named entity recognition-Volume", "citeRegEx": "Virga et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Virga et al\\.", "year": 2003}], "referenceMentions": [{"referenceID": 8, "context": "We evaluate our work against a recently-published transliteration system (Durrani et al., 2014) which has", "startOffset": 73, "endOffset": 95}, {"referenceID": 7, "context": "field of orthographic similarity detections since sound similarities co-exist with orthographic similarities (Brew et al., 1996; Mann and Yarowsky, 2001; Dijkstra et al., 1999; Van Heuven et al., 1998; Kondrak, 2004; Chamizo Dominguez and Nerlich, 2002).", "startOffset": 109, "endOffset": 253}, {"referenceID": 18, "context": "field of orthographic similarity detections since sound similarities co-exist with orthographic similarities (Brew et al., 1996; Mann and Yarowsky, 2001; Dijkstra et al., 1999; Van Heuven et al., 1998; Kondrak, 2004; Chamizo Dominguez and Nerlich, 2002).", "startOffset": 109, "endOffset": 253}, {"referenceID": 20, "context": "Pouliquen et al. (2006) makes transliteration model based on similar spelling rules in close languages.", "startOffset": 0, "endOffset": 24}, {"referenceID": 8, "context": "Recent work of Durrani et al. (2014) is integrated in Moses as a module, providing an unsupervised characterbased transliteration training model.", "startOffset": 15, "endOffset": 37}, {"referenceID": 8, "context": "Recent work of Durrani et al. (2014) is integrated in Moses as a module, providing an unsupervised characterbased transliteration training model. Matthews (2007) proposed a proper name transliteration model on several language pairs.", "startOffset": 15, "endOffset": 162}, {"referenceID": 9, "context": "(Francis et al., 2002) state that over 40% of the brands choose to create corresponding foreign names via transliterations, By querying Freebase in categories containing 3,388,225 entries, we create", "startOffset": 0, "endOffset": 22}, {"referenceID": 8, "context": "We use the transliteration system described in (Durrani et al., 2014) as baseline method to com-", "startOffset": 47, "endOffset": 69}, {"referenceID": 5, "context": "Arabic: Combination of 10001 Arabic Names(LDC2005G02) and (Cettolo et al., 2012) made available for IWSLT-13.", "startOffset": 58, "endOffset": 80}, {"referenceID": 21, "context": "Hindi: Indian multi-parallel corpus (Post et al., 2012), and Russian: WMT-13 data (Bojar et al.", "startOffset": 36, "endOffset": 55}, {"referenceID": 8, "context": "might improve performance (Durrani et al., 2014).", "startOffset": 26, "endOffset": 48}, {"referenceID": 2, "context": "To perform such a test, we relied on the Polyglot distributed word embeddings presented in (Al-Rfou et al., 2013).", "startOffset": 91, "endOffset": 113}, {"referenceID": 12, "context": "these human-annotated gold standards, in particular 1756 French-English cognates and 541 false friends suggested in (Inkpen et al., 2005) as well as 1345 of Spanish-English cognates 4 plus 217 false friends 5.", "startOffset": 116, "endOffset": 137}], "year": 2016, "abstractText": "Transliterations play an important role in multilingual entity reference resolution, because proper names increasingly travel between languages in news and social media. Previous work associated with machine translation targets transliteration only single between language pairs, focuses on specific classes of entities (such as cities and celebrities) and relies on manual curation, which limits the expression power of transliteration in multilingual environment. By contrast, we present an unsupervised transliteration model covering 69 major languages that can generate good transliterations for arbitrary strings between any language pair. Our model yields top-(1, 20, 100) averages of (32.85%, 60.44%, 83.20%) in matching gold standard transliteration compared to results from a recently-published system of (26.71%, 50.27%, 72.79%). We also show the quality of our model in detecting true and false friends from Wikipedia high frequency lexicons. Our method indicates a strong signal of pronunciation similarity and boosts the probability of finding true friends in 68 out of 69 languages.", "creator": "LaTeX with hyperref package"}}}