{"id": "1611.08987", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "28-Nov-2016", "title": "Exploiting Unlabeled Data for Neural Grammatical Error Detection", "abstract": "Identifying and correcting grammatical errors in the text written by non-native writers has received increasing attention in recent years. Although a number of annotated corpora have been established to facilitate data-driven grammatical error detection and correction approaches, they are still limited in terms of quantity and coverage because human annotation is labor-intensive, time-consuming, and expensive. In this work, we propose to utilize unlabeled data to train neural network based grammatical error detection models. The basic idea is to cast error detection as a binary classification problem and derive positive and negative training examples from unlabeled data. We introduce an attention-based neural network to capture long-distance dependencies that influence the word being detected. Experiments show that the proposed approach significantly outperforms SVMs and convolutional networks with fixed-size context window. We identify the problem with the treatment of the two main reasons. First, we consider both training and correction, both of which have been described in this work (i.e., in particular, the treatment of the two main reasons for a discrepancy between training and correction). Second, our approach provides information about which problems should be addressed as well as the other possible problems in the treatment of non-native text. Finally, we offer two sets of techniques to train neural network based neural network based neural network based neural network based neural network based neural network based neural network based neural network based neural network based neural network based neural network based neural network based neural network based neural network based neural network based neural network based neural network based neural network based neural network based neural network based neural network based neural network based neural network based neural network based neural network based neural network based neural network based neural network based neural network based neural network based neural network based neural network based neural network based neural network based neural network based neural network based neural network based neural network based neural network based neural network based neural network based neural network based neural network based neural network based neural network based neural network based neural network based neural network based neural network based neural network based neural network based neural network based neural network based neural network based neural network based neural network based neural network based neural network based neural network based neural network based neural network based neural network based neural network based neural network based neural network based neural network based neural network based neural network based neural network based neural network based neural network based neural network based neural network based neural network based neural network based neural network based neural network based neural network based neural network based neural network based neural network based neural network based neural network based neural network based neural", "histories": [["v1", "Mon, 28 Nov 2016 05:32:35 GMT  (232kb,D)", "https://arxiv.org/abs/1611.08987v1", null], ["v2", "Tue, 29 Nov 2016 06:08:59 GMT  (232kb,D)", "http://arxiv.org/abs/1611.08987v2", null]], "reviews": [], "SUBJECTS": "cs.CL", "authors": ["zhuoran liu", "yang liu"], "accepted": false, "id": "1611.08987"}, "pdf": {"name": "1611.08987.pdf", "metadata": {"source": "CRF", "title": "Exploiting Unlabeled Data for Neural Grammatical Error Detection", "authors": ["Zhuoran Liu", "Yang Liu"], "emails": ["liuzhuoran17@163.com,", "liuyang2011@tsinghua.edu.cn"], "sections": [{"heading": "1 Introduction", "text": "Automatic grammatical error detection and correction for natural languages has attracted increasing attention, for a large number of non-native speakers are learning or using foreign languages. Take English as an example. There are a large number of English learners around the world who need instantaneous accurate feedback to help improve their writings (Dahlmeier and Ng [2012]). In the domain of scientific paper writing in which English is the main language, authors also need effective grammar checkers to help them in composing scientific articles (Ford [2015]).\nThere have been several shared tasks addressing grammar errors in recent years. HOO-2011 (Dale and Kilgarriff [2011]), HOO-2012 (Dale, Anisimoff, and Narroway [2012]), CoNLL-2013 (Ng et al. [2013]) and CoNLL2014 (Ng et al. [2014]) shared tasks all aimed to correct grammar errors. The AESW shared task (Daudaravicius et al. [2016]) aimed to identify sentence-level grammar error. These shared tasks helped advanced the research of grammatical error detection or correction.\nDespite these advances, the scarcity of annotated data is still a major limitation on research of grammatical error detection and correction. Researchers need mass annotated data to train a grammar checker, but unfortunately for them, there are only a small amount of annotated corpora available in a limited number of domains. Most annotated corpora are in the domain of learner English, e.g. NUCLE (Dahlmeier, Ng, and Wu [2013]) and CLC (Nicholls [2003]), and others are from domains such as scientific papers, e.g. AESW dataset (Ford [2015]). In order to train their system with enough data, researchers use multiple corpus instead of one (Felice et al. [2014]).\nData scarcity is partly due to difficulties in building an elaborately annotated corpus needed for training of a grammatical error correction system, as is described by the team that built NUS Corpus of Learner English\nar X\niv :1\n61 1.\n08 98\n7v 2\n[ cs\n.C L\n] 2\n9 N\n(Dahlmeier, Ng, and Wu [2013]). In order to obtain a reliable annotation, they set up a guideline for annotators so that corrections are consistent. To ensure that these annotations are available, several annotators proposed their correction independently, and annotations most agreed upon are selected. Such annotating process is labour-intensive and time consuming, and the quality of the corpus are subject to human judgment and other factors such as budget. For example, their team is unable to perform double annotation for the main corpus due to budget constraints. They spent a long time (over half a year) to annotate only 1,414 essays.\nGiven these difficulties in building annotated corpus, we hope to utilize un-annotated error-free texts in unsupervised training of a grammatical error correction or grammatical error detection system. Previously, efforts have been made to explore how realistic grammatical errors could be counterfeited automatically from error-free texts and therefore obtain large amount of annotated data (Felice and Yuan [2014]; Foster and Andersen [2009]; Lee and Lee [2009]; Imamura et al. [2012]). We therefore follow the idea of building a corpus by generating artificial error, since there are vast amount of un-annotated texts available and most of them are error-free. We explored two ways of artificial error generation, which is proved to be effective in our experiment.\nTraining a system to correct grammatical errors might be a more difficult task when there is no supervision, since there are numerous error types and our method to generate artificial errors might not be sophisticated enough to cover all of them. We thus focus on grammatical error detection instead of correction. It is natural to address this task as binary classification, in which we make prediction of whether a word is grammatically correct."}, {"heading": "2 Background", "text": ""}, {"heading": "2.1 Problem Statement", "text": "The goal of word-level grammatical error detection is to identify grammar errors at the word level. For example, given a sentence shown below, a grammatical error detection system is expected to correctly identify the erroneous word \u2018birds\u2019 highlighted by underline:"}, {"heading": "An ugly birds was observed by the man yesterday .", "text": "The task of word-level grammatical error detection is formalized as such: given a sequence of token X = (x1, x2, ..., xn) as input, the error detector outputs its prediction Y = (y1, y2, ..., yn) where yi denotes the correctness of xi in terms of grammaticality.\nWe address this problem as a binary classification problem. In order to predict yt given the current word xt and the whole sentence X = (x1, x2, ..., xn), we need to find a function g(\u00b7) to calculate the conditional probability of each yt given xt and the whole input sequence X:\np(yt|xt) = g(xt, X), (1)\nwhere\nyt = { 1 correct 0 incorrect . (2)\nOur aim is to build a suitable classification model for g(\u00b7)."}, {"heading": "2.2 Support Vector Machines", "text": "A natural approach is to use Support Vector Machine (SVM) to perform classification (Boser, Guyon, and Vapnik [1992]; Cortes and Vapnik [1995]). SVM is trained given a training dataset in the form of {(x1, y1), ..., (xn, yn)},\nwhere xi represents a token with a set of selected linguistic features, and yi denotes the grammatical correctness of the token. It finds a maximum-margin hyperplane that separates correct words from incorrect ones.\nThe problem with this approach is that we need to manually design features in xi. Since human are unable to tell precisely which features are relevant, human-designed features are inadequate in some aspects while being redundant in others. As a result, these designed features are unable to capture all regularities, which might hurt the performance of our error detector."}, {"heading": "2.3 Convolution Network with Fixed Window Size", "text": "To circumvent the problem with feature engineering, a natural thought is to utilize the capability of neural networks in automatic feature extraction (Collobert and Weston [2008]). The simplest way is to take into consideration a fixed size window of words around the current word as its context by applying temporal convolution over the fixed size window. In the example sentence given in Section 2.1, when considering the grammatical correctness of the word \u2018was\u2019 given a context window of size 3, the context window would be birds was observed. The assumption that underlies this method is that only neighbouring words are grammatically related to the current word.\nHere we formalize the method of neural network with fixed size window. Given a word xi, its context ci is\nci = (xi\u2212w/2, ..., xi, ..., xi+w/2). (3)\nLet f(\u00b7) denote a temporal convolution operation with the input frame size equal to the dimension of xi, the output frame size equal to 1, and the kernel width equal to the size of fixed window. A score si of the current word xi is calculated by si = f(ci) which represents grammatical features within the window. This score then goes through a sigmoid layer and yield the probability of yi: p(yi|xi, ci) = \u03c3(si).\nThe first problem with this method is that it is incapable of capturing long-distance dependency. With a fixed window size, the error detector is unable to take into consideration word contexts beyond the window size, while long-distance grammatical dependency is quite common a phenomena. For example, in order to determine whether \u2018was\u2019 is incorrect, we would need to take \u2018yesterday\u2019 into consideration, which requires a large size of context window.\nAnother problem with this approach is that all words within the context window is taken into consideration indiscriminately. In the example above, \u2018was\u2019 might not care about what was done to the birds when determining the verb tense, but \u2018observed\u2019 is given equal attention regardless of the fact that it has no influence on verb tense."}, {"heading": "3 Approach", "text": "In this section we describe our unsupervised approach to word-level grammatical error detection."}, {"heading": "3.1 Model Architecture", "text": "Our intuition is to first encode the input sequence into a sequence of hidden states which contain relevant grammatical information, and then make prediction given a word and its context (see Figure.1). Thus our model consists of two parts: an encoder that adopts a typical architecture of bi-directional LSTM network (Hochreiter and Schmidhuber [1997]), and a classifier that makes predictions based on hidden states of the encoder."}, {"heading": "3.1.1 Encoder", "text": "The encoder takes as input a sentence S of length n, represented by a sequence of vector X = (x1, x2, ..., xn). In an LSTM recurrent neural network, the input X is processed through time and produces a series of memory states (c1, c2, ..., cn) and hidden states (h1, h2, ..., hn). In order to counterbalance the impact of time on hidden states we process the input X two times, forward and backward, to fully encode the information classifier needs.\nThe forward LSTM updates its memory state \u2212\u2192ci and hidden state \u2212\u2192 hi at each time step t:\n[ \u2212\u2192 ht ; \u2212\u2192ct ] = \u2212\u2212\u2212\u2212\u2192 LSTM([ \u2212\u2212\u2192 ht\u22121; \u2212\u2212\u2192ct\u22121]). (4)\nSimilarly, memory state\u2190\u2212ci and hidden state \u2190\u2212 hi is updated by backward LSTM at time step t:\n[ \u2190\u2212 ht ; \u2190\u2212ct ] = \u2190\u2212\u2212\u2212\u2212 LSTM([ \u2190\u2212\u2212 ht+1; \u2190\u2212\u2212ct+1]). (5)\nThe encoder outputs a hidden tape h\u0303 = (h\u03031, h\u03032, ..., h\u0303n), where\nh\u0303t = [\u2212\u2192 ht\u2190\u2212 ht ] . (6)"}, {"heading": "3.1.2 Classifier with Intra-attention", "text": "To predict whether the word at time step t is grammatically problematic, the classifier computes a score given the current word xt and its context at. This score st then goes through a sigmoid layer and makes a binary prediction, with 1 denoting grammatically correct and 0 denoting incorrect. Note that the Classifier does not hold its own state as a decoder does in a traditional encoder-decoder architecture.\nTo address the problem of long-distance dependency, we incorporate an intra-sentence attention mechanism (Bahdanau, Cho, and Bengio [2014]) in our classifier, where all hidden states of encoder is taken into consideration and the attention of classifier on all position of the sentence is dynamically adapted. To describe formally, we compute the context at around the word xt as an attention-weighted sum of {h\u03031, h\u03032, ..., h\u0303n}:\nat = \u2211 i \u03b1t,i \u00b7 h\u0303i, (7)\nwhere\n\u03b1t,i = exp(Et,i)\u2211 j exp(Et,j) , (8)\nEt,i = h\u0303t > \u00b7 h\u0303i. (9)\nVector at represents the grammatical and semantic context at position t. A word is considered to be grammatically erroneous if the word xt does not fit into the current context, i.e. it is incompatible to place xt at position t given the context at. The score st is computed as follows:\nst = x > t \u00b7W \u00b7 at + b. (10)\nwhere b is the bias. Then the probability can be calculated as\np(y|xt, {x1, x2, ..., xn}) = \u03c3(st). (11)\nBy incorporating intra-attention mechanism, we provide a latent structure for the model to learn grammatical relations between words. This makes a lot of sense because the grammaticality of a word is dependent more on the words that have strong grammatical relation with it, while others are negligible when making prediction. For example in Figure.1, when the model tries to determine whether \u2018birds\u2019 is correct in terms of noun number, it will pay a strong attention to \u2018An\u2019."}, {"heading": "3.2 Noise Generation", "text": "Traditionally, a large set of {\u3008X(n), Y (n)\u3009}Nn=1 is needed to effectively train such a grammatical error detector. However in an unsupervised approach, only {X(n)}Nn=1 is given. The key issue is how the corresponding {Y (n)}Nn=1 could be obtained.\nWe adopted the idea of using artificial error for training. It is crucial to find a suitable algorithm for the error generator to produce realistic grammatical error, since the performance of the model relies heavily on the paradigm it saw during training. Since our task is to detect grammatical error on word level, we only consider substitution errors. We compare two ways of substituting the original word for an erroneous one."}, {"heading": "3.2.1 Uniform random substitution", "text": "The simplest way is to substitute a word in a random position with a random word from the vocabulary. The problem with this approach is that some artificial errors generated in this way is apparently irrelevant. For example, it could substitute a word from the sentence"}, {"heading": "An ugly bird was observed by the man yesterday .", "text": "to generate such a sentence as\nAn ugly bird was vocabulary by the man yesterday .\nOne potential problem is that it might be too easy for our classifier to discriminate such erroneous words from the correct ones.\nAlgorithm 1 Build Substitution Set PoS-tag the input text Build a dictionary D of (token, PoS-tag) for all (token, pos) in D do\nif pos in {CC} or {DT, PDT} or {PRP, PRP$} or {IN, TO, RP} or {WDT, WP, WP$, WRB} then Add token to the corresponding substitution set ci else if pos in {NN, NNP, NNPS, NNS} or {VB, VBD, VBG, VBN, VBP, VBZ} then lemma\u2190 Lemmatise token Add token to the corresponding substitution set ci else if pos in {JJ, JJR, JJS} or {RB, RBR, RBS} then stem\u2190 Stem token Add token to the corresponding substitution set ci\nend if end for\nAlgorithm 2 Error generation for all sentence S in training text do\nGet word w at random position of S w\u2032 \u2190 w Search for substitution set ci that contains w if such ci does not exist or ci contains only 1 element then\nwhile w\u2032 == w do w\u2032 \u2190 Select a random word from dictionary D"}, {"heading": "3.2.2 Substitution with linguistic knowledge", "text": "We carefully examined a number of erroneous paradigms and found some characteristics common to all grammatical errors, regardless of the terminology and commonly seen patterns of the domain. To briefly summarize it, errors usually appears when a correct word is substituted by another word, which comes from a finite set of words and that are linguistically related to it, either because they possess the same lemma or the same part-of-speech tag. There is an inexhaustible list of how linguistic knowledge works in substitution. Here we only present several examples in Table.1.\nCombining these two method of error generation, we are able to generate 16 types grammatical errors out\nof 28 specified by CoNLL-2014 Shared Task (Ng et al. [2014]). 1 Details are described by Algorithm 1, which formalizes the construction of substitution set, and Algorithm 2, which formalizes the process of error-generation with linguistic knowledge."}, {"heading": "4 Experiments", "text": ""}, {"heading": "4.1 Settings", "text": ""}, {"heading": "4.1.1 Data", "text": "We used data mainly from three sources (Table 2):\n\u2022 ACL Anthology2 (ACL): training set.\n\u2022 AESW Shared Task Dataset (AESW) (Daudaravicius et al. [2016]) : development and test sets.\n\u2022 CCL Anthology3 (CCL): development and test sets.\nFor training set, we used sentences from papers that appear in ACL Anthology. We crawled all papers up to year 2015, and then select sentences that end with a period, with a length of longer than 5 but no longer than 50, which may contain several clauses separated by commas, colons or semicolons. Formulae and references are excluded, numbers are substituted with a special \u3008num\u3009 token, and parentheses are removed together with the contents in between. We limit the vocabulary to tokens with at least a word-frequency of 2 to eliminate most spelling errors, and replaced all OOVs with a special \u3008unk\u3009 token.\nTo corroborate that the model trained by us actually works with realistic grammatical error, we used two human annotated dataset as our development and test set.\nThe first one is the test set of AESW 2016 Shared Task, but we only used a portion of the erroneous sentences from paragraphs with the attribute of \u201cdomain=Computer Science\u201d; we converted the data format by preserving all words between \u2018\u3008del\u3009\u3008/del\u3009\u2019 and marking them as incorrect, while removing those between \u2018\u3008ins\u3009\u3008/ins\u3009\u2019.\n1The error types can be generated are: Vt, Vm, Vform, SVA, ArtOrDet, Nn, Npos, Pform, Pref, Prep, Wci, Wform, Spar, Trans, Mec, Others. Most of remaining error types we are unable to generate are either semantic errors (Smod, Rloc-, UM), or style problems (Wa, Wtone, Cit), or sentence level problems (Srun, Sfrag, WOinc, WOadv).\n2http://www.aclweb.org/anthology/ 3http://www.cips-cl.org/anthology\nFor example, if the original annotated sentence is\nMore discussions \u3008del\u3009about\u3008/del\u3009\u3008ins\u3009on\u3008/ins\u3009 these issues will be provided in the remainder of the monograph.\nWe convert it into the form of:\nMore discussions about these issues will be provided in the remainder of the monograph.\nThe second human annotated dataset is some erroneous sentences from papers in CCL Anthology annotated by us, which contains grammatical errors since most of them are written by Chinese."}, {"heading": "4.1.2 Baselines", "text": "To the best of our knowledge, word-level grammatical error detection task has never been researched before. Thus we use the two methods described in 2.2 and 2.3. We compared our method to two baselines, both of which are trained on the ACL training set.\n\u2022 Support Vector Machine (SVM).\n\u2022 Convolutional Network (Conv).\nSVM takes into consideration the context in a fixed window of size 5 around the current word, and gives prediction of whether the current word is grammatically correct in the sentence. We first trained an n-gram model with KenLM (Heafield [2011]) on the whole training set without artificial errors, with n up to 3. We then use n-gram scores as the input features into the SVM. In our experiment we used the open-source tool LibLinear (Fan et al. [2008]).\nIn Conv, we use word-embeddings pre-trained using word2vec model in gensim (R\u030cehu\u030ar\u030cek and Sojka [2010]), the dimensionality of which we set to 50 empirically. A temporal convolution is performed over a window of fixed size 3. The kernel width is set to equal to the size of fixed window. This model is implemented using Torch7. 4"}, {"heading": "4.1.3 BiLSTM with Intra-attention", "text": "Our model is implemented using Tensorflow.5 We used cross-entropy as our loss function to optimize. We perform gradient clipping by global norm (Pascanu, Mikolov, and Bengio [2013]) with the function provided in Tensorflow. The dimention of word-embedding and hidden state are set to 150, as a trade-off between performance and training time. The word-embedding matrix is initialized with random uniform distribution within range of \u00b10.05."}, {"heading": "4.2 Results and Discussion", "text": "Tables 3 and 4 presents the results of experiments of two baselines (SVM and T-Conv) and our model (BiLSTM), using uniform random errors (uni.) or errors counterfeited with linguistic knowledge (ling.). From the two tables we can see that our model outperformed the two baselines on both human-annotated datasets (AESW and CCL). The F0.5 score might seem low, but they are actually good results since these models are trained without supervision.\n4http://torch.ch/ 5https://www.tensorflow.org/"}, {"heading": "4.2.1 Effect of Error Types", "text": "If we focus on the task of detecting a limited number of error types (Verb form, Noun Number, Preposition misuse, Article misuse), the model would show better performance on CCL test set, but weaker or only comparable to AESW test set. This is probably because in the annotating phase of CCL test set, we focused heavily on these common types of errors and some other types of errors are neglected. The results are shown in Tables 5 and 6."}, {"heading": "4.2.2 Effect of Attention", "text": "To verify our intra-attention help improve model performance, we removed the attention and performed the same experiment. Comparison of models with and without attention is shown in Tables 5 and 6.\nThough the intra-attention mechanism worked, but in some cases it may fail. We believe that a more sophisticated way of error generation is needed, because currently only those positions where substitution happens have a chance to be labeled incorrect (\u201con-site-error\u201d paradigms). But for the model to learn grammatical relations by attention mechanism, we need massive paradigms where substitution cause another position to be labeled incorrect (\u201coff-site-error\u201d paradigms). For example, in the sentence"}, {"heading": "An ugly bird was observed by the man yesterday .", "text": "If we substitute ugly with beautiful, our system will automatically annotate beautiful as incorrect (on-site-error)\nAn beautiful bird was observed by the man yesterday .\nbut our model will never know why it is incorrect. What we need instead are off-site-errors:\nAn beautiful bird was observed by the man yesterday .\nso that the model knows beautiful is ok with \u2018A\u2019 but not with \u2018An\u2019. Unfortunately our method does not provide such a mechanism to massively produce \u201coff-site-error\u201d paradigms, therefore our model have to rely on very few coincidentally generated \u201coff-site-error\u201d paradigms which are too sparse.\nOur current method also introduced some substitutions which should not be counted as errors. For example, if yesterday is substituted by today:\nAn ugly bird was observed by the man today .\n\u2018today\u2019 is annotated as incorrect under our method, while it does not actually constitute grammatical error, which therefore hurt model performance to some degree."}, {"heading": "4.2.3 Examples", "text": "Our model is found to perform well in some cases, while failing to identify others (Table 7)6. It works well with collocations, as seen in Ex.1. It also works well with morphological problems, as Ex.2 shows. However it is incapable of detecting errors of genre as in Ex.3. In Ex.4, it mistook as incorrect words out of domain of the training data. It is apparent in Ex.5 that our model is aware of the missing are between polarities and opposite,\n6The table contains only a partial list of error type our model detected. Since we only detect errors without inferring their types, we are unable to provide the full list of error types our model is able to detect.\nbut it reports error at a different position. There are other error types our model did not handle well with, such as redundant determiners as in Ex.6."}, {"heading": "5 Related Work", "text": ""}, {"heading": "5.1 Grammatical Error Detection and Correction", "text": "Several shared tasks on grammatical error detection or correction have been carried out in recent years, including HOO-2011 (Dale and Kilgarriff [2011]), HOO-2012 (Dale, Anisimoff, and Narroway [2012]) , CoNLL-2013 (Ng et al. [2013]), and CoNLL-2014 (Ng et al. [2014]). These four shared tasks all focused on grammatical error correction of English written by non-native speakers. The AESW shared task (Daudaravicius et al. [2016]) proposed to evaluate scientific writing automatically based on sentence-level error identification.\nDifferent from these shared tasks, we focus on word-level grammatical error detection, which is a pilot step towards unsupervised approach to error correction.\nTo address the issue of grammatical error, researchers explored and utilized various methods. For example classification method was used by the top ranking team (Rozovskaya et al. [2013]) in CoNLL-2013 shared task. The top ranking team (Felice et al. [2014]) of CoNLL-2014 shared task incorporated in their system a Statistical Machine Translation (SMT) component, which translates erroneous English into correct English. With the development of Neural Machine Translation (NMT) and attention mechanism (Bahdanau, Cho, and Bengio [2014]), the top team (Schmaltz et al. [2016]) of AESW shared task adopted the NMT approach to grammatical error correction.\nIn comparison, we adopted a typical architecture of bi-directional LSTM (Hochreiter and Schmidhuber [1997]) on the encoder side (Cho et al. [2014]), but replace the decoder with a classifier. Since error types are not given in unsupervised training, our classifier does not infer error types but only make binary prediction."}, {"heading": "5.2 Error Generation", "text": "To obtain enough training data, various approaches have been employed to generate artificial error. Markov logic network was used for statistical grammar error simulation (Lee and Lee [2009]). An automatic tool for error generation was developed (Foster and Andersen [2009]), which take as input a corpus and error generation rules. Error inflation was used in UI system (Rozovskaya, Sammons, and Roth [2012]) in HOO-2012 shared task, and similar method was performed on Japanese (Imamura et al. [2012]). To enlarge the size of training set, artificial errors were injected into the corpus by Yuan and Felice in CoNLL-2013 shared task (Yuan and Felice [2013]). Later they further researched the probabilistic manner of artificial error generation with linguistic information (Felice and Yuan [2014]).\nDifferent from (Foster and Andersen [2009]), we build substitution set automatically from un-annotated corpus based on POS tag or lemma, while their tools require a set of rules to work. To compare with (Rozovskaya, Sammons, and Roth [2012]; Yuan and Felice [2013]; Felice and Yuan [2014]), their methods of error generation are based on annotated corpus, while we used only un-annotated error-free texts without any supervision."}, {"heading": "5.3 RNNs and LSTM Units", "text": "Recurrent Neural Network (RNN) with Long Short-term Memory (LSTM) or Gated Recurrent Unit (GRU) has shown a mighty capability to encode informations over long sequences (Cho et al. [2014]). The attention mechanism has enabled a Bi-directional RNN with GRU to achieve even better performance in machine translation (Bahdanau, Cho, and Bengio [2014]) by allowing the decoder to explicitly make use of the memory of encoder. Upon the emergence of attention mechanisms, it has been applied to many NLP topics other than machine translation. Grammatical error correction is of no exception. Schmaltz et al. used a uni-directional LSTM network with attention mechanism and achieved the best performance in the AESW shared task (Schmaltz et al. [2016]).\nDifferent from them, we do not need to generate target sentence because we are not doing correction. Therefore we replaced the decoder with a binary classifier, which take into consideration the information from BiLSTM encoder."}, {"heading": "6 Conclusion and Future Work", "text": "In our work, we have explored unsupervised word-level grammatical error detection using only un-annotated corpus as training data. We showed that it is a viable way for machines to learn grammatical relations and to predict grammatical errors. This inspires us to further extend unsupervised approach to grammatical error correction. In the future, we plan to investigate novel methods for generating artificial errors to enable our model to learn better intra-sentence attention."}], "references": [{"title": "Neural machine translation by jointly learning to align and translate", "author": ["D. Bahdanau", "K. Cho", "Y. Bengio"], "venue": "CoRR abs/1409.0473.", "citeRegEx": "Bahdanau et al\\.,? 2014", "shortCiteRegEx": "Bahdanau et al\\.", "year": 2014}, {"title": "A training algorithm for optimal margin classifiers", "author": ["B.E. Boser", "I. Guyon", "V. Vapnik"], "venue": "COLT.", "citeRegEx": "Boser et al\\.,? 1992", "shortCiteRegEx": "Boser et al\\.", "year": 1992}, {"title": "Learning phrase representations using rnn encoder-decoder for statistical machine translation", "author": ["K. Cho", "B. van Merrienboer", "aglar G\u00fclehre", "D. Bahdanau", "F. Bougares", "H. Schwenk", "Y. Bengio"], "venue": null, "citeRegEx": "Cho et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Cho et al\\.", "year": 2014}, {"title": "A unified architecture for natural language processing: deep neural networks with multitask learning", "author": ["R. Collobert", "J. Weston"], "venue": "ICML.", "citeRegEx": "Collobert and Weston,? 2008", "shortCiteRegEx": "Collobert and Weston", "year": 2008}, {"title": "Support-vector networks", "author": ["C. Cortes", "V. Vapnik"], "venue": "Machine Learning 20:273\u2013297.", "citeRegEx": "Cortes and Vapnik,? 1995", "shortCiteRegEx": "Cortes and Vapnik", "year": 1995}, {"title": "A beam-search decoder for grammatical error correction", "author": ["D. Dahlmeier", "H.T. Ng"], "venue": "EMNLP-CoNLL.", "citeRegEx": "Dahlmeier and Ng,? 2012", "shortCiteRegEx": "Dahlmeier and Ng", "year": 2012}, {"title": "Building a large annotated corpus of learner english: The nus corpus of learner english", "author": ["D. Dahlmeier", "H.T. Ng", "S.M. Wu"], "venue": null, "citeRegEx": "Dahlmeier et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Dahlmeier et al\\.", "year": 2013}, {"title": "Helping our own: The hoo 2011 pilot shared task", "author": ["R. Dale", "A. Kilgarriff"], "venue": "In Proc. of ENLG.", "citeRegEx": "Dale and Kilgarriff,? 2011", "shortCiteRegEx": "Dale and Kilgarriff", "year": 2011}, {"title": "Hoo 2012: A report on the preposition and determiner error correction", "author": ["R. Dale", "I. Anisimoff", "G. Narroway"], "venue": null, "citeRegEx": "Dale et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Dale et al\\.", "year": 2012}, {"title": "A report on the automatic evaluation of scientific writing shared task", "author": ["V. Daudaravicius", "R.E. Banchs", "E. Volodina", "C. Napoles"], "venue": "Proceedings of the 11th Workshop on Innovative Use of NLP for Building Educational Applications, 53\u201362. San Diego, CA: Association for Computational Linguistics.", "citeRegEx": "Daudaravicius et al\\.,? 2016", "shortCiteRegEx": "Daudaravicius et al\\.", "year": 2016}, {"title": "Liblinear: A library for large linear classification", "author": ["R.-E. Fan", "K.-W. Chang", "C.-J. Hsieh", "X.-R. Wang", "C.-J. Lin"], "venue": "Journal of Machine Learning Research 9:1871\u20131874.", "citeRegEx": "Fan et al\\.,? 2008", "shortCiteRegEx": "Fan et al\\.", "year": 2008}, {"title": "Generating artificial errors for grammatical error correction", "author": ["M. Felice", "Z. Yuan"], "venue": "EACL.", "citeRegEx": "Felice and Yuan,? 2014", "shortCiteRegEx": "Felice and Yuan", "year": 2014}, {"title": "Grammatical error correction using hybrid systems and type filtering", "author": ["M. Felice", "Z. Yuan", "O.E. Andersen", "H. Yannakoudakis", "E. Kochmar"], "venue": "CONLL.", "citeRegEx": "Felice et al\\.,? 2014", "shortCiteRegEx": "Felice et al\\.", "year": 2014}, {"title": "Automated evaluation of scientific writing: Aesw shared task proposal", "author": ["H. Ford"], "venue": null, "citeRegEx": "Ford,? \\Q2015\\E", "shortCiteRegEx": "Ford", "year": 2015}, {"title": "Generrate: Generating errors for use in grammatical error detection", "author": ["J. Foster", "O.E. Andersen"], "venue": null, "citeRegEx": "Foster and Andersen,? \\Q2009\\E", "shortCiteRegEx": "Foster and Andersen", "year": 2009}, {"title": "KenLM: faster and smaller language model queries", "author": ["K. Heafield"], "venue": "Proceedings of the EMNLP 2011 Sixth Workshop on Statistical Machine Translation, 187\u2013197.", "citeRegEx": "Heafield,? 2011", "shortCiteRegEx": "Heafield", "year": 2011}, {"title": "Long short-term memory", "author": ["S. Hochreiter", "J. Schmidhuber"], "venue": "Neural Computation 9:1735\u20131780.", "citeRegEx": "Hochreiter and Schmidhuber,? 1997", "shortCiteRegEx": "Hochreiter and Schmidhuber", "year": 1997}, {"title": "Grammar error correction using pseudo-error sentences and domain adaptation", "author": ["K. Imamura", "K. Saito", "K. Sadamitsu", "H. Nishikawa"], "venue": "ACL.", "citeRegEx": "Imamura et al\\.,? 2012", "shortCiteRegEx": "Imamura et al\\.", "year": 2012}, {"title": "Realistic grammar error simulation using markov logic", "author": ["S. Lee", "G.G. Lee"], "venue": "ACL.", "citeRegEx": "Lee and Lee,? 2009", "shortCiteRegEx": "Lee and Lee", "year": 2009}, {"title": "The conll-2013 shared task on grammatical error correction", "author": ["H.T. Ng", "S.M. Wu", "Y. Wu", "C. Hadiwinoto", "J.R. Tetreault"], "venue": "CONLL.", "citeRegEx": "Ng et al\\.,? 2013", "shortCiteRegEx": "Ng et al\\.", "year": 2013}, {"title": "The conll-2014 shared task on grammatical error correction", "author": ["H.T. Ng", "S.M. Wu", "T. Briscoe", "C. Hadiwinoto", "R.H. Susanto", "C. Bryant"], "venue": "CONLL.", "citeRegEx": "Ng et al\\.,? 2014", "shortCiteRegEx": "Ng et al\\.", "year": 2014}, {"title": "The cambridge learner corpus -error coding and analysis for lexicography and elt", "author": ["D. Nicholls"], "venue": null, "citeRegEx": "Nicholls,? \\Q2003\\E", "shortCiteRegEx": "Nicholls", "year": 2003}, {"title": "On the difficulty of training recurrent neural networks", "author": ["R. Pascanu", "T. Mikolov", "Y. Bengio"], "venue": "ICML.", "citeRegEx": "Pascanu et al\\.,? 2013", "shortCiteRegEx": "Pascanu et al\\.", "year": 2013}, {"title": "Software Framework for Topic Modelling with Large Corpora", "author": ["R. \u0158eh\u016f\u0159ek", "P. Sojka"], "venue": "Proceedings of the LREC 2010 Workshop on New Challenges for NLP Frameworks, 45\u201350. Valletta, Malta: ELRA.", "citeRegEx": "\u0158eh\u016f\u0159ek and Sojka,? 2010", "shortCiteRegEx": "\u0158eh\u016f\u0159ek and Sojka", "year": 2010}, {"title": "Generating confusion sets for context-sensitive error correction", "author": ["A. Rozovskaya", "D. Roth"], "venue": "EMNLP.", "citeRegEx": "Rozovskaya and Roth,? 2010", "shortCiteRegEx": "Rozovskaya and Roth", "year": 2010}, {"title": "The university of illinois system in the conll2013 shared task", "author": ["A. Rozovskaya", "K.-W. Chang", "M. Sammons", "D. Roth"], "venue": "CONLL.", "citeRegEx": "Rozovskaya et al\\.,? 2013", "shortCiteRegEx": "Rozovskaya et al\\.", "year": 2013}, {"title": "The ui system in the hoo 2012 shared task on error correction", "author": ["A. Rozovskaya", "M. Sammons", "D. Roth"], "venue": null, "citeRegEx": "Rozovskaya et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Rozovskaya et al\\.", "year": 2012}, {"title": "Sentence-level grammatical error identification as sequence-to-sequence correction", "author": ["A. Schmaltz", "Y. Kim", "A.M. Rush", "S.M. Shieber"], "venue": "CoRR abs/1604.04677.", "citeRegEx": "Schmaltz et al\\.,? 2016", "shortCiteRegEx": "Schmaltz et al\\.", "year": 2016}, {"title": "End-to-end memory networks", "author": ["S. Sukhbaatar", "A. Szlam", "J. Weston", "R. Fergus"], "venue": "NIPS.", "citeRegEx": "Sukhbaatar et al\\.,? 2015", "shortCiteRegEx": "Sukhbaatar et al\\.", "year": 2015}, {"title": "Constrained grammatical error correction using statistical machine translation", "author": ["Z. Yuan", "M. Felice"], "venue": "CONLL.", "citeRegEx": "Yuan and Felice,? 2013", "shortCiteRegEx": "Yuan and Felice", "year": 2013}], "referenceMentions": [{"referenceID": 5, "context": "There are a large number of English learners around the world who need instantaneous accurate feedback to help improve their writings (Dahlmeier and Ng [2012]).", "startOffset": 135, "endOffset": 159}, {"referenceID": 5, "context": "There are a large number of English learners around the world who need instantaneous accurate feedback to help improve their writings (Dahlmeier and Ng [2012]). In the domain of scientific paper writing in which English is the main language, authors also need effective grammar checkers to help them in composing scientific articles (Ford [2015]).", "startOffset": 135, "endOffset": 346}, {"referenceID": 5, "context": "There are a large number of English learners around the world who need instantaneous accurate feedback to help improve their writings (Dahlmeier and Ng [2012]). In the domain of scientific paper writing in which English is the main language, authors also need effective grammar checkers to help them in composing scientific articles (Ford [2015]). There have been several shared tasks addressing grammar errors in recent years. HOO-2011 (Dale and Kilgarriff [2011]), HOO-2012 (Dale, Anisimoff, and Narroway [2012]), CoNLL-2013 (Ng et al.", "startOffset": 135, "endOffset": 465}, {"referenceID": 5, "context": "There are a large number of English learners around the world who need instantaneous accurate feedback to help improve their writings (Dahlmeier and Ng [2012]). In the domain of scientific paper writing in which English is the main language, authors also need effective grammar checkers to help them in composing scientific articles (Ford [2015]). There have been several shared tasks addressing grammar errors in recent years. HOO-2011 (Dale and Kilgarriff [2011]), HOO-2012 (Dale, Anisimoff, and Narroway [2012]), CoNLL-2013 (Ng et al.", "startOffset": 135, "endOffset": 514}, {"referenceID": 5, "context": "There are a large number of English learners around the world who need instantaneous accurate feedback to help improve their writings (Dahlmeier and Ng [2012]). In the domain of scientific paper writing in which English is the main language, authors also need effective grammar checkers to help them in composing scientific articles (Ford [2015]). There have been several shared tasks addressing grammar errors in recent years. HOO-2011 (Dale and Kilgarriff [2011]), HOO-2012 (Dale, Anisimoff, and Narroway [2012]), CoNLL-2013 (Ng et al. [2013]) and CoNLL2014 (Ng et al.", "startOffset": 135, "endOffset": 545}, {"referenceID": 5, "context": "There are a large number of English learners around the world who need instantaneous accurate feedback to help improve their writings (Dahlmeier and Ng [2012]). In the domain of scientific paper writing in which English is the main language, authors also need effective grammar checkers to help them in composing scientific articles (Ford [2015]). There have been several shared tasks addressing grammar errors in recent years. HOO-2011 (Dale and Kilgarriff [2011]), HOO-2012 (Dale, Anisimoff, and Narroway [2012]), CoNLL-2013 (Ng et al. [2013]) and CoNLL2014 (Ng et al. [2014]) shared tasks all aimed to correct grammar errors.", "startOffset": 135, "endOffset": 578}, {"referenceID": 5, "context": "There are a large number of English learners around the world who need instantaneous accurate feedback to help improve their writings (Dahlmeier and Ng [2012]). In the domain of scientific paper writing in which English is the main language, authors also need effective grammar checkers to help them in composing scientific articles (Ford [2015]). There have been several shared tasks addressing grammar errors in recent years. HOO-2011 (Dale and Kilgarriff [2011]), HOO-2012 (Dale, Anisimoff, and Narroway [2012]), CoNLL-2013 (Ng et al. [2013]) and CoNLL2014 (Ng et al. [2014]) shared tasks all aimed to correct grammar errors. The AESW shared task (Daudaravicius et al. [2016]) aimed to identify sentence-level grammar error.", "startOffset": 135, "endOffset": 679}, {"referenceID": 5, "context": "There are a large number of English learners around the world who need instantaneous accurate feedback to help improve their writings (Dahlmeier and Ng [2012]). In the domain of scientific paper writing in which English is the main language, authors also need effective grammar checkers to help them in composing scientific articles (Ford [2015]). There have been several shared tasks addressing grammar errors in recent years. HOO-2011 (Dale and Kilgarriff [2011]), HOO-2012 (Dale, Anisimoff, and Narroway [2012]), CoNLL-2013 (Ng et al. [2013]) and CoNLL2014 (Ng et al. [2014]) shared tasks all aimed to correct grammar errors. The AESW shared task (Daudaravicius et al. [2016]) aimed to identify sentence-level grammar error. These shared tasks helped advanced the research of grammatical error detection or correction. Despite these advances, the scarcity of annotated data is still a major limitation on research of grammatical error detection and correction. Researchers need mass annotated data to train a grammar checker, but unfortunately for them, there are only a small amount of annotated corpora available in a limited number of domains. Most annotated corpora are in the domain of learner English, e.g. NUCLE (Dahlmeier, Ng, and Wu [2013]) and CLC (Nicholls [2003]), and others are from domains such as scientific papers, e.", "startOffset": 135, "endOffset": 1252}, {"referenceID": 5, "context": "There are a large number of English learners around the world who need instantaneous accurate feedback to help improve their writings (Dahlmeier and Ng [2012]). In the domain of scientific paper writing in which English is the main language, authors also need effective grammar checkers to help them in composing scientific articles (Ford [2015]). There have been several shared tasks addressing grammar errors in recent years. HOO-2011 (Dale and Kilgarriff [2011]), HOO-2012 (Dale, Anisimoff, and Narroway [2012]), CoNLL-2013 (Ng et al. [2013]) and CoNLL2014 (Ng et al. [2014]) shared tasks all aimed to correct grammar errors. The AESW shared task (Daudaravicius et al. [2016]) aimed to identify sentence-level grammar error. These shared tasks helped advanced the research of grammatical error detection or correction. Despite these advances, the scarcity of annotated data is still a major limitation on research of grammatical error detection and correction. Researchers need mass annotated data to train a grammar checker, but unfortunately for them, there are only a small amount of annotated corpora available in a limited number of domains. Most annotated corpora are in the domain of learner English, e.g. NUCLE (Dahlmeier, Ng, and Wu [2013]) and CLC (Nicholls [2003]), and others are from domains such as scientific papers, e.", "startOffset": 135, "endOffset": 1278}, {"referenceID": 5, "context": "There are a large number of English learners around the world who need instantaneous accurate feedback to help improve their writings (Dahlmeier and Ng [2012]). In the domain of scientific paper writing in which English is the main language, authors also need effective grammar checkers to help them in composing scientific articles (Ford [2015]). There have been several shared tasks addressing grammar errors in recent years. HOO-2011 (Dale and Kilgarriff [2011]), HOO-2012 (Dale, Anisimoff, and Narroway [2012]), CoNLL-2013 (Ng et al. [2013]) and CoNLL2014 (Ng et al. [2014]) shared tasks all aimed to correct grammar errors. The AESW shared task (Daudaravicius et al. [2016]) aimed to identify sentence-level grammar error. These shared tasks helped advanced the research of grammatical error detection or correction. Despite these advances, the scarcity of annotated data is still a major limitation on research of grammatical error detection and correction. Researchers need mass annotated data to train a grammar checker, but unfortunately for them, there are only a small amount of annotated corpora available in a limited number of domains. Most annotated corpora are in the domain of learner English, e.g. NUCLE (Dahlmeier, Ng, and Wu [2013]) and CLC (Nicholls [2003]), and others are from domains such as scientific papers, e.g. AESW dataset (Ford [2015]).", "startOffset": 135, "endOffset": 1366}, {"referenceID": 5, "context": "There are a large number of English learners around the world who need instantaneous accurate feedback to help improve their writings (Dahlmeier and Ng [2012]). In the domain of scientific paper writing in which English is the main language, authors also need effective grammar checkers to help them in composing scientific articles (Ford [2015]). There have been several shared tasks addressing grammar errors in recent years. HOO-2011 (Dale and Kilgarriff [2011]), HOO-2012 (Dale, Anisimoff, and Narroway [2012]), CoNLL-2013 (Ng et al. [2013]) and CoNLL2014 (Ng et al. [2014]) shared tasks all aimed to correct grammar errors. The AESW shared task (Daudaravicius et al. [2016]) aimed to identify sentence-level grammar error. These shared tasks helped advanced the research of grammatical error detection or correction. Despite these advances, the scarcity of annotated data is still a major limitation on research of grammatical error detection and correction. Researchers need mass annotated data to train a grammar checker, but unfortunately for them, there are only a small amount of annotated corpora available in a limited number of domains. Most annotated corpora are in the domain of learner English, e.g. NUCLE (Dahlmeier, Ng, and Wu [2013]) and CLC (Nicholls [2003]), and others are from domains such as scientific papers, e.g. AESW dataset (Ford [2015]). In order to train their system with enough data, researchers use multiple corpus instead of one (Felice et al. [2014]).", "startOffset": 135, "endOffset": 1486}, {"referenceID": 11, "context": "Previously, efforts have been made to explore how realistic grammatical errors could be counterfeited automatically from error-free texts and therefore obtain large amount of annotated data (Felice and Yuan [2014]; Foster and Andersen [2009]; Lee and Lee [2009]; Imamura et al.", "startOffset": 191, "endOffset": 214}, {"referenceID": 11, "context": "Previously, efforts have been made to explore how realistic grammatical errors could be counterfeited automatically from error-free texts and therefore obtain large amount of annotated data (Felice and Yuan [2014]; Foster and Andersen [2009]; Lee and Lee [2009]; Imamura et al.", "startOffset": 191, "endOffset": 242}, {"referenceID": 11, "context": "Previously, efforts have been made to explore how realistic grammatical errors could be counterfeited automatically from error-free texts and therefore obtain large amount of annotated data (Felice and Yuan [2014]; Foster and Andersen [2009]; Lee and Lee [2009]; Imamura et al.", "startOffset": 191, "endOffset": 262}, {"referenceID": 11, "context": "Previously, efforts have been made to explore how realistic grammatical errors could be counterfeited automatically from error-free texts and therefore obtain large amount of annotated data (Felice and Yuan [2014]; Foster and Andersen [2009]; Lee and Lee [2009]; Imamura et al. [2012]).", "startOffset": 191, "endOffset": 285}, {"referenceID": 4, "context": "2 Support Vector Machines A natural approach is to use Support Vector Machine (SVM) to perform classification (Boser, Guyon, and Vapnik [1992]; Cortes and Vapnik [1995]).", "startOffset": 144, "endOffset": 169}, {"referenceID": 3, "context": "3 Convolution Network with Fixed Window Size To circumvent the problem with feature engineering, a natural thought is to utilize the capability of neural networks in automatic feature extraction (Collobert and Weston [2008]).", "startOffset": 196, "endOffset": 224}, {"referenceID": 16, "context": "Thus our model consists of two parts: an encoder that adopts a typical architecture of bi-directional LSTM network (Hochreiter and Schmidhuber [1997]), and a classifier that makes predictions based on hidden states of the encoder.", "startOffset": 116, "endOffset": 150}, {"referenceID": 19, "context": "of 28 specified by CoNLL-2014 Shared Task (Ng et al. [2014]).", "startOffset": 43, "endOffset": 60}, {"referenceID": 9, "context": "\u2022 AESW Shared Task Dataset (AESW) (Daudaravicius et al. [2016]) : development and test sets.", "startOffset": 35, "endOffset": 63}, {"referenceID": 14, "context": "We first trained an n-gram model with KenLM (Heafield [2011]) on the whole training set without artificial errors, with n up to 3.", "startOffset": 45, "endOffset": 61}, {"referenceID": 10, "context": "In our experiment we used the open-source tool LibLinear (Fan et al. [2008]).", "startOffset": 58, "endOffset": 76}, {"referenceID": 10, "context": "In our experiment we used the open-source tool LibLinear (Fan et al. [2008]). In Conv, we use word-embeddings pre-trained using word2vec model in gensim (\u0158eh\u016f\u0159ek and Sojka [2010]), the dimensionality of which we set to 50 empirically.", "startOffset": 58, "endOffset": 179}, {"referenceID": 6, "context": "1 Grammatical Error Detection and Correction Several shared tasks on grammatical error detection or correction have been carried out in recent years, including HOO-2011 (Dale and Kilgarriff [2011]), HOO-2012 (Dale, Anisimoff, and Narroway [2012]) , CoNLL-2013 (Ng et al.", "startOffset": 170, "endOffset": 197}, {"referenceID": 6, "context": "1 Grammatical Error Detection and Correction Several shared tasks on grammatical error detection or correction have been carried out in recent years, including HOO-2011 (Dale and Kilgarriff [2011]), HOO-2012 (Dale, Anisimoff, and Narroway [2012]) , CoNLL-2013 (Ng et al.", "startOffset": 170, "endOffset": 246}, {"referenceID": 6, "context": "1 Grammatical Error Detection and Correction Several shared tasks on grammatical error detection or correction have been carried out in recent years, including HOO-2011 (Dale and Kilgarriff [2011]), HOO-2012 (Dale, Anisimoff, and Narroway [2012]) , CoNLL-2013 (Ng et al. [2013]), and CoNLL-2014 (Ng et al.", "startOffset": 170, "endOffset": 278}, {"referenceID": 6, "context": "1 Grammatical Error Detection and Correction Several shared tasks on grammatical error detection or correction have been carried out in recent years, including HOO-2011 (Dale and Kilgarriff [2011]), HOO-2012 (Dale, Anisimoff, and Narroway [2012]) , CoNLL-2013 (Ng et al. [2013]), and CoNLL-2014 (Ng et al. [2014]).", "startOffset": 170, "endOffset": 313}, {"referenceID": 6, "context": "1 Grammatical Error Detection and Correction Several shared tasks on grammatical error detection or correction have been carried out in recent years, including HOO-2011 (Dale and Kilgarriff [2011]), HOO-2012 (Dale, Anisimoff, and Narroway [2012]) , CoNLL-2013 (Ng et al. [2013]), and CoNLL-2014 (Ng et al. [2014]). These four shared tasks all focused on grammatical error correction of English written by non-native speakers. The AESW shared task (Daudaravicius et al. [2016]) proposed to evaluate scientific writing automatically based on sentence-level error identification.", "startOffset": 170, "endOffset": 476}, {"referenceID": 6, "context": "1 Grammatical Error Detection and Correction Several shared tasks on grammatical error detection or correction have been carried out in recent years, including HOO-2011 (Dale and Kilgarriff [2011]), HOO-2012 (Dale, Anisimoff, and Narroway [2012]) , CoNLL-2013 (Ng et al. [2013]), and CoNLL-2014 (Ng et al. [2014]). These four shared tasks all focused on grammatical error correction of English written by non-native speakers. The AESW shared task (Daudaravicius et al. [2016]) proposed to evaluate scientific writing automatically based on sentence-level error identification. Different from these shared tasks, we focus on word-level grammatical error detection, which is a pilot step towards unsupervised approach to error correction. To address the issue of grammatical error, researchers explored and utilized various methods. For example classification method was used by the top ranking team (Rozovskaya et al. [2013]) in CoNLL-2013 shared task.", "startOffset": 170, "endOffset": 924}, {"referenceID": 6, "context": "1 Grammatical Error Detection and Correction Several shared tasks on grammatical error detection or correction have been carried out in recent years, including HOO-2011 (Dale and Kilgarriff [2011]), HOO-2012 (Dale, Anisimoff, and Narroway [2012]) , CoNLL-2013 (Ng et al. [2013]), and CoNLL-2014 (Ng et al. [2014]). These four shared tasks all focused on grammatical error correction of English written by non-native speakers. The AESW shared task (Daudaravicius et al. [2016]) proposed to evaluate scientific writing automatically based on sentence-level error identification. Different from these shared tasks, we focus on word-level grammatical error detection, which is a pilot step towards unsupervised approach to error correction. To address the issue of grammatical error, researchers explored and utilized various methods. For example classification method was used by the top ranking team (Rozovskaya et al. [2013]) in CoNLL-2013 shared task. The top ranking team (Felice et al. [2014]) of CoNLL-2014 shared task incorporated in their system a Statistical Machine Translation (SMT) component, which translates erroneous English into correct English.", "startOffset": 170, "endOffset": 995}, {"referenceID": 6, "context": "1 Grammatical Error Detection and Correction Several shared tasks on grammatical error detection or correction have been carried out in recent years, including HOO-2011 (Dale and Kilgarriff [2011]), HOO-2012 (Dale, Anisimoff, and Narroway [2012]) , CoNLL-2013 (Ng et al. [2013]), and CoNLL-2014 (Ng et al. [2014]). These four shared tasks all focused on grammatical error correction of English written by non-native speakers. The AESW shared task (Daudaravicius et al. [2016]) proposed to evaluate scientific writing automatically based on sentence-level error identification. Different from these shared tasks, we focus on word-level grammatical error detection, which is a pilot step towards unsupervised approach to error correction. To address the issue of grammatical error, researchers explored and utilized various methods. For example classification method was used by the top ranking team (Rozovskaya et al. [2013]) in CoNLL-2013 shared task. The top ranking team (Felice et al. [2014]) of CoNLL-2014 shared task incorporated in their system a Statistical Machine Translation (SMT) component, which translates erroneous English into correct English. With the development of Neural Machine Translation (NMT) and attention mechanism (Bahdanau, Cho, and Bengio [2014]), the top team (Schmaltz et al.", "startOffset": 170, "endOffset": 1274}, {"referenceID": 6, "context": "1 Grammatical Error Detection and Correction Several shared tasks on grammatical error detection or correction have been carried out in recent years, including HOO-2011 (Dale and Kilgarriff [2011]), HOO-2012 (Dale, Anisimoff, and Narroway [2012]) , CoNLL-2013 (Ng et al. [2013]), and CoNLL-2014 (Ng et al. [2014]). These four shared tasks all focused on grammatical error correction of English written by non-native speakers. The AESW shared task (Daudaravicius et al. [2016]) proposed to evaluate scientific writing automatically based on sentence-level error identification. Different from these shared tasks, we focus on word-level grammatical error detection, which is a pilot step towards unsupervised approach to error correction. To address the issue of grammatical error, researchers explored and utilized various methods. For example classification method was used by the top ranking team (Rozovskaya et al. [2013]) in CoNLL-2013 shared task. The top ranking team (Felice et al. [2014]) of CoNLL-2014 shared task incorporated in their system a Statistical Machine Translation (SMT) component, which translates erroneous English into correct English. With the development of Neural Machine Translation (NMT) and attention mechanism (Bahdanau, Cho, and Bengio [2014]), the top team (Schmaltz et al. [2016]) of AESW shared task adopted the NMT approach to grammatical error correction.", "startOffset": 170, "endOffset": 1313}, {"referenceID": 6, "context": "1 Grammatical Error Detection and Correction Several shared tasks on grammatical error detection or correction have been carried out in recent years, including HOO-2011 (Dale and Kilgarriff [2011]), HOO-2012 (Dale, Anisimoff, and Narroway [2012]) , CoNLL-2013 (Ng et al. [2013]), and CoNLL-2014 (Ng et al. [2014]). These four shared tasks all focused on grammatical error correction of English written by non-native speakers. The AESW shared task (Daudaravicius et al. [2016]) proposed to evaluate scientific writing automatically based on sentence-level error identification. Different from these shared tasks, we focus on word-level grammatical error detection, which is a pilot step towards unsupervised approach to error correction. To address the issue of grammatical error, researchers explored and utilized various methods. For example classification method was used by the top ranking team (Rozovskaya et al. [2013]) in CoNLL-2013 shared task. The top ranking team (Felice et al. [2014]) of CoNLL-2014 shared task incorporated in their system a Statistical Machine Translation (SMT) component, which translates erroneous English into correct English. With the development of Neural Machine Translation (NMT) and attention mechanism (Bahdanau, Cho, and Bengio [2014]), the top team (Schmaltz et al. [2016]) of AESW shared task adopted the NMT approach to grammatical error correction. In comparison, we adopted a typical architecture of bi-directional LSTM (Hochreiter and Schmidhuber [1997]) on the encoder side (Cho et al.", "startOffset": 170, "endOffset": 1499}, {"referenceID": 2, "context": "In comparison, we adopted a typical architecture of bi-directional LSTM (Hochreiter and Schmidhuber [1997]) on the encoder side (Cho et al. [2014]), but replace the decoder with a classifier.", "startOffset": 129, "endOffset": 147}, {"referenceID": 15, "context": "Markov logic network was used for statistical grammar error simulation (Lee and Lee [2009]).", "startOffset": 72, "endOffset": 91}, {"referenceID": 13, "context": "An automatic tool for error generation was developed (Foster and Andersen [2009]), which take as input a corpus and error generation rules.", "startOffset": 54, "endOffset": 81}, {"referenceID": 13, "context": "An automatic tool for error generation was developed (Foster and Andersen [2009]), which take as input a corpus and error generation rules. Error inflation was used in UI system (Rozovskaya, Sammons, and Roth [2012]) in HOO-2012 shared task, and similar method was performed on Japanese (Imamura et al.", "startOffset": 54, "endOffset": 216}, {"referenceID": 13, "context": "An automatic tool for error generation was developed (Foster and Andersen [2009]), which take as input a corpus and error generation rules. Error inflation was used in UI system (Rozovskaya, Sammons, and Roth [2012]) in HOO-2012 shared task, and similar method was performed on Japanese (Imamura et al. [2012]).", "startOffset": 54, "endOffset": 310}, {"referenceID": 13, "context": "An automatic tool for error generation was developed (Foster and Andersen [2009]), which take as input a corpus and error generation rules. Error inflation was used in UI system (Rozovskaya, Sammons, and Roth [2012]) in HOO-2012 shared task, and similar method was performed on Japanese (Imamura et al. [2012]). To enlarge the size of training set, artificial errors were injected into the corpus by Yuan and Felice in CoNLL-2013 shared task (Yuan and Felice [2013]).", "startOffset": 54, "endOffset": 466}, {"referenceID": 11, "context": "Later they further researched the probabilistic manner of artificial error generation with linguistic information (Felice and Yuan [2014]).", "startOffset": 115, "endOffset": 138}, {"referenceID": 11, "context": "Later they further researched the probabilistic manner of artificial error generation with linguistic information (Felice and Yuan [2014]). Different from (Foster and Andersen [2009]), we build substitution set automatically from un-annotated corpus based on POS tag or lemma, while their tools require a set of rules to work.", "startOffset": 115, "endOffset": 183}, {"referenceID": 11, "context": "Later they further researched the probabilistic manner of artificial error generation with linguistic information (Felice and Yuan [2014]). Different from (Foster and Andersen [2009]), we build substitution set automatically from un-annotated corpus based on POS tag or lemma, while their tools require a set of rules to work. To compare with (Rozovskaya, Sammons, and Roth [2012]; Yuan and Felice [2013]; Felice and Yuan [2014]), their methods of error generation are based on annotated corpus, while we used only un-annotated error-free texts without any supervision.", "startOffset": 115, "endOffset": 381}, {"referenceID": 11, "context": "Later they further researched the probabilistic manner of artificial error generation with linguistic information (Felice and Yuan [2014]). Different from (Foster and Andersen [2009]), we build substitution set automatically from un-annotated corpus based on POS tag or lemma, while their tools require a set of rules to work. To compare with (Rozovskaya, Sammons, and Roth [2012]; Yuan and Felice [2013]; Felice and Yuan [2014]), their methods of error generation are based on annotated corpus, while we used only un-annotated error-free texts without any supervision.", "startOffset": 115, "endOffset": 405}, {"referenceID": 11, "context": "Later they further researched the probabilistic manner of artificial error generation with linguistic information (Felice and Yuan [2014]). Different from (Foster and Andersen [2009]), we build substitution set automatically from un-annotated corpus based on POS tag or lemma, while their tools require a set of rules to work. To compare with (Rozovskaya, Sammons, and Roth [2012]; Yuan and Felice [2013]; Felice and Yuan [2014]), their methods of error generation are based on annotated corpus, while we used only un-annotated error-free texts without any supervision.", "startOffset": 115, "endOffset": 429}, {"referenceID": 2, "context": "3 RNNs and LSTM Units Recurrent Neural Network (RNN) with Long Short-term Memory (LSTM) or Gated Recurrent Unit (GRU) has shown a mighty capability to encode informations over long sequences (Cho et al. [2014]).", "startOffset": 192, "endOffset": 210}, {"referenceID": 2, "context": "3 RNNs and LSTM Units Recurrent Neural Network (RNN) with Long Short-term Memory (LSTM) or Gated Recurrent Unit (GRU) has shown a mighty capability to encode informations over long sequences (Cho et al. [2014]). The attention mechanism has enabled a Bi-directional RNN with GRU to achieve even better performance in machine translation (Bahdanau, Cho, and Bengio [2014]) by allowing the decoder to explicitly make use of the memory of encoder.", "startOffset": 192, "endOffset": 370}, {"referenceID": 2, "context": "3 RNNs and LSTM Units Recurrent Neural Network (RNN) with Long Short-term Memory (LSTM) or Gated Recurrent Unit (GRU) has shown a mighty capability to encode informations over long sequences (Cho et al. [2014]). The attention mechanism has enabled a Bi-directional RNN with GRU to achieve even better performance in machine translation (Bahdanau, Cho, and Bengio [2014]) by allowing the decoder to explicitly make use of the memory of encoder. Upon the emergence of attention mechanisms, it has been applied to many NLP topics other than machine translation. Grammatical error correction is of no exception. Schmaltz et al. used a uni-directional LSTM network with attention mechanism and achieved the best performance in the AESW shared task (Schmaltz et al. [2016]).", "startOffset": 192, "endOffset": 767}], "year": 2016, "abstractText": "Identifying and correcting grammatical errors in the text written by non-native writers has received increasing attention in recent years. Although a number of annotated corpora have been established to facilitate data-driven grammatical error detection and correction approaches, they are still limited in terms of quantity and coverage because human annotation is labor-intensive, time-consuming, and expensive. In this work, we propose to utilize unlabeled data to train neural network based grammatical error detection models. The basic idea is to cast error detection as a binary classification problem and derive positive and negative training examples from unlabeled data. We introduce an attention-based neural network to capture long-distance dependencies that influence the word being detected. Experiments show that the proposed approach significantly outperforms SVMs and convolutional networks with fixed-size context window.", "creator": "LaTeX with hyperref package"}}}