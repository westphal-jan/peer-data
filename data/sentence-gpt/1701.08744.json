{"id": "1701.08744", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "30-Jan-2017", "title": "Click Through Rate Prediction for Contextual Advertisment Using Linear Regression", "abstract": "This research presents an innovative and unique way of solving the advertisement prediction problem which is considered as a learning problem over the past several years. Online advertising is a multi-billion-dollar industry and is growing every year with a rapid pace. The goal of this research is to enhance click through rate of the contextual advertisements using Linear Regression (LRR) and the measurement of the ads delivered. This research has found that online advertising is a very beneficial learning problem, because it can inform an intelligent way of learning. The research will help the research of children by identifying where each ad is coming from, how it came from, how much content it has been generated, and why it is associated with the educational experience of children.\n\n\n\n\nThis research is supported by the University of Cambridge Research Programme and the Massachusetts Institute of Technology and the National Science Foundation.", "histories": [["v1", "Mon, 30 Jan 2017 18:32:59 GMT  (829kb)", "http://arxiv.org/abs/1701.08744v1", "8 pages, 13 Figures, 11 Tables"]], "COMMENTS": "8 pages, 13 Figures, 11 Tables", "reviews": [], "SUBJECTS": "cs.IR cs.AI cs.LG", "authors": ["muhammad junaid effendi", "syed abbas ali"], "accepted": false, "id": "1701.08744"}, "pdf": {"name": "1701.08744.pdf", "metadata": {"source": "CRF", "title": "Click Through Rate Prediction for Contextual Advertisment Using Linear Regression", "authors": ["Muhammad Junaid Effendi", "Syed Abbas Ali"], "emails": ["junaidfnd@gmail.com", "saaj@neduet.edu.pk"], "sections": [{"heading": null, "text": "of solving the advertisement prediction problem which is considered as a learning problem over the past several years. Online advertising is a multi-billion-dollar industry and is growing every year with a rapid pace. The goal of this research is to enhance click through rate of the contextual advertisements using Linear Regression. In order to address this problem, a new technique propose in this paper to predict the CTR which will increase the overall revenue of the system by serving the advertisements more suitable to the viewers with the help of feature extraction and displaying the advertisements based on context of the publishers. The important steps include the data collection, feature extraction, CTR prediction and advertisement serving. The statistical results obtained from the dynamically used technique show an efficient outcome by fitting the data close to perfection for the LR technique using optimized feature selection.\nKeywords-Click Through Rate(CTR), Contextual Advertisements, Machine Learning, Web advertisements, Regression Problem.\nI. INTRODUCTION AND RELATED WORK\nThe online advertising is a very vast industry having more than 50 billion worth. The online advertisers are now growing more and more because of the targeted advertising. This field has already produced a lot of research work in the past from ad click prediction to ad serving. With the rapid increase of ad networks the problem of click prediction has also grown. The advertisement serving is considered as one of the most successful story in the field of Machine Learning. Furthermore, the rise in advertisement serving technologies have also brought a real time bidding solution where advertisements are selected based on the features of the publishers and the viewers. The CTR prediction has been used over the past several years in every type of advertisement format, search engine advertisements, contextual advertisements, text advertisements, display banner advertisements, video advertisements etc.\nMachine Learning has played an important part in the online serving of advertisements, a paper presented by [1] explains how important the machine learning is in the real world. A lot of research work has been seen in this field but none has been done in the way we have explained in this paper. The methodology and the technique used brings a variation to the ad click prediction technique. The change in methodology is the change in the steps, for example the feature extraction.\nThis step has been done in wide variety of ways for the regression problems, linear discriminant analysis (LDA) which is used for classification problem was modified to solve regressions problems by [2]. The mapping of ordinal data into a meaningful continuous stream for linear regression to avoid fitting problems in this research has been done using the concept of k-mean clustering and association rule as presented by [14], [15], respectively. The clustering and rule mining for textual categorization has been previously researched by [16], [17] but have not used to solve the regression problems. Whereas [7] presented the conversion of ordinal data into nominal data and ignored the continuous variables for the regression. On the other side, we have seen several approaches to solve the ad click prediction. It has been done using Logistic Regression by various researchers such as [3], further na\u00efve Bayes has played a vital part in the building of ad click prediction, this can be seen in [4], [5]. With the increase in rapid growth of online activity, the researchers have been trying to find the various techniques to get the suitable advertisements according to the viewers\u2019 interest. The estimation of response for the display advertisements is presented by [6]. Similarly, the more the viewers the ad serving becomes hard to solve, the research presented by [23] has focused on the targeting display advertisements using massive-scale machine learning. Another research in this filed was done by [8] in which the focus is on the comparison of different machine Learning techniques including the logistic regression. The recent growth in the social networking on the internet has produced some great examples of ad serving technologies, Twitter advertising model is also based on the logistic regression, [20]. While, another top network Facebook has used decision trees with logistic regression presented in [21] to serve the ads to their millions of users daily. Logistic Regression has been playing a vital role since the first research in this field. The importance of logistic regression in finding the customers behavior can be seen in the paper written by [9]. These types of models have always come up with an accuracy issues, the goal is to perform regression in a dynamic way for achieving the best possible accuracy. Estimating the errors and accuracy after model selection is one of the important parts of it according to [19]. The focus of this research is centered only to the display banner advertisements which lie within the contextual type. This research paper discusses the complete methodology of the advertisement prediction with several steps which are defined in the later sections. Section II explains the basic working of an advertisement server, how the\nadvertisements are serving over the internet in an efficient way. Section III deals with how the data is collected from viewer\u2019s activity. Section IV describes the research methodology and technique used to predict click through rate. Experimental Results and performance evaluation is discussed in section V. Finally, conclusion is drawn in section VI."}, {"heading": "II. BRIEF OVERVIEW OF SYSTEM", "text": "When a viewer visits any website which is publishing the advertisements, the features are extracted from the website, the content understanding through keyword gathering, ad size, ad placement (above the fold or below the fold), viewer\u2019s location, and many other important features. They are then fed into the ad server where the data processing takes place from where the ad is chosen based on several factors, these factors are usually the order of advertisements which is shown to the viewer in the past, the behavior of the viewer extracted from the browser and most importantly the click through rate of the advertisements are going to be served. This can be understood easily with the help of fig 1. This whole process needs to be done in few milliseconds else the viewer might end up leaving the website without seeing the ad in the ad space. Further feature like ad placement plays a vital role because an advertisement is not serving the purpose if it is unreachable for the viewer [24].\nThe past researches have shown that this is a regression problem and perfectly fits to the logistic model [3, 8], however our goal is to use linear regression with a little variance in the feature selection method where we will use techniques like clustering to make the feature meaningful in order to avoid over fitting and under fitting problems."}, {"heading": "III. COLLECTION OF VIEWERS\u2019 ACTIVITY", "text": "This section presents the technique used for gathering the viewer activity which is used in later machine learning for predicting the click through rate of the advertisements. Since the collection is a necessary step of predicting the CTR for the future ads, a simple algorithm is built to serve the ads and collect the data in the raw form through our practically implemented project and the data gathered is processed later.\nFollowing is the pseudo code for the algorithm used.\nAlgorithm 1: Contextual Ad Serving based on highest bid\nInputs: ad placement, ad size, location, keywords, category\nFor i From 1 To N do\nIf (ad placement && ad size && location && keywords && category)\n//setting advertisements pool\nAdsi <- Ad\nEnd If"}, {"heading": "End For", "text": ""}, {"heading": "For All \ud835\udc22 in Ads do", "text": "For All \ud835\udc23 in Ads do\n//preferring content based\nAdi <- Adsi (count(keywords)==max(keywords))\nIf Adj count(keywords) == Adi count(keywords)\n//getting the ad with maximum bid from the pool\nAd <- Adi (bid==max(bid))\nEnd If\nDisplay <- Ad //display the selected Ad\nEnd For"}, {"heading": "End For", "text": "The purpose of this algorithm is to pick the ad based on the context of the publisher plus the maximum bidder within that contextually selected pool of advertisements. In simpler words, it prefers an ad which is more relevant to the content and then picking the highest bidder in the contextually selected pool of ads. Thus the data collected through this is used in the next sections to perform Linear Regression."}, {"heading": "IV. RESEARCH METHODOLOGY AND TECHNIQUES", "text": "There are several ways to perform ad click prediction, the method and techniques may vary among different types of data sets. From the fig 1 discussed in section III, we have modified the feature selection and machine learning technique blocks using different techniques to serve the same purpose. This section covers the main method and technique used to predict the click through rate of the ad. This will be explained step by step with a proper prove in a proper manner."}, {"heading": "A. Feature Extraction And Selection", "text": "This section deals with two types of features, one which is gathered in the previous section and used to serve advertisements using a contextual and bidding algorithm and the second one extracted on the run time from the viewer, for which the system is going to predict a CTR. Whenever a data is gathered through run time it has several features, the first task is to get the required set of features which are best for the learning algorithm. The data obtained is not in a suitable form\nbefore processing it must be converted to avoid regression problems like over fitting and under fitting [11]. Since there are three different entities Advertiser, Publisher and Viewer linked, so many features are extracted. The following table shows the features extracted from three different sources."}, {"heading": "Features", "text": "These above features can be categorical, nominal and ordinal, also can be discrete or continuous in nature. The features extracted are now needed to be selected efficiently for the learning purpose. The above table has many features that are irrelevant for learning and has no meaning to the click through rate, the output. Advertisement Id, Campaign Id and several other features have no impact on the CTR, so they can be removed from the advertiser list. For the publisher part, all features are important despite that the keywords are meaningless for the regression problems but our task is to make it meaningful since its an important feature for contextual advertisements. This is discussed in the next part of the current section. The features extracted from user are important but not in this scenario because of the toughness of the regression problems, adding them would make the model over fit, thus reducing the efficiency of the system. Following table shows the feature selected for Linear Regression."}, {"heading": "Features", "text": "The above features selected now need to be converted into a suitable form, a form that can be easily processed for the Regression Learning algorithm. Since Regression works only with continuous values, bid remains a perfect feature so no need to work on it. But features like ad size, keywords, ad placement have to be changed into a proper form.\nAd Size and Ad Placement are categorical features these can be mapped as:\n Ad Size to integer, \u2018300x250\u2019 to 1, as an example.  Ad Placement to binary, \u2018Above the Fold\u2019 to 1, as an\nexample.\nBut keywords are values which need to be converted in a continuous stream, since there is no limit and any keyword can be generated by advertiser. The next part focuses on the keyword conversion to continuous stream using clustering to make them meaningful and impactful on the output variable CTR. At this moment the data gathered has the value for CTR, the features and the output now can be used to predict the CTR for the new viewer. For the second type of feature selection where CTR is to be predicted the same process discussed\nearlier takes place with same set of features as shown in table 2 but used to find the click prediction of the ad. This will be used in the later part of this section."}, {"heading": "B. Keywords To Integer Mapping Using Association Rule", "text": "The next step is to make the feature keywords meaningful and impactful on the data. As discussed the keywords cannot be converted into a numerical value because of its random generation. Taking as an example, we have a keyword \u2018football\u2019 and we have to map it to a numerical value which is assumed to be 21. For the next keyword \u2018soccer\u2019 this can however be mapped to a value double to the value of the \u2018football\u2019 keyword 42 or any other value which is not repeated in the system, but the evaluation here will not make any useful impact and will be of meaningless value, this would lead to over fitting problem. In order to solve this problem Association Rule can be used to make it meaningful and to avoid fitting problems [12]. This feature can also be ignored but to add a different dynamic to the problem we have considered it as an important part of learning. Also, because the focus is on the contextual advertisements so keywords here define the context of the page on which the ad needs to be predicted. The Rule Mining and clustering technique is used to understand the given keywords would benefit us by avoiding the over-fitting problem without the use of regularization. The categories of the advertisements are labeled by default and the keywords within it will be mapped into a meaning numerical with respect to its distance."}, {"heading": "Categories", "text": "The focus is only on the sports category and all analysis are based on this category. Following are the sample set of keywords from the sports category.\nAt the moment these keywords look like in the following manner.\nThe three different colors (purple, yellow, blue) shown in fig 4 are the three centroids selected; they are the keywords that represent the clusters, for example the cricket. And the centroids are found using the association rule on the data set collected in the starting section of this research paper.\nThe centroids are picked as the most commonly used keywords. For example, football, cricket and tennis are the most common terms used with other keywords.\nThe association rule mining is a technique to find the relationship among certain data set [16]. With the help of this technique the categorization can be done efficiently until and unless the data set has those keywords.\nThe dark colored are the centroids while the light colors are the related keywords. The overlapping in the purple part of two circles is because of the closeness between the soccer and football keywords. The two gray are the neutral keywords that can be categorized in more than one cluster. England and Spain keywords here refer to those two. Spain can be in football or tennis category and England can be in football or in cricket. The following Fig.6, focus only on the purple clusters, football. Also considering the two neutral circles in its category.\nHere the distance is showing the relation among the keywords. In the real world, Football or soccer is linked with England then it has its Premier League also known as EPL, the La Liga is the Spanish League having a club Real Madrid with its player Ronaldo. Brazil is a direct link to football. The closeness between the keywords can be defined in terms of the distance between the two keywords. The more related the keywords the less the distance between them. This can be viewed in the fig 6. Now the distance between them can be used to map them into a meaningful numerical value. As a sample the following table shows result."}, {"heading": "Football", "text": "The above table shows how much each keyword is related to other in terms of the distance value. The more the keywords the closer the value would be. The values may differ each time since this technique performs every time when the learning needs to be done."}, {"heading": "C. CTR Prediction Using Machine Learning", "text": "Now all the features have been converted into a suitable form and learning can be done easily. The click through rate is predicted when a viewer visits a publisher\u2019s website and within few milliseconds the ad is being served based on the maximum CTR. The features as discussed in the previous section are now sent to calculate the CTR of the ads. The ads are picked according to the location of the viewer and category of the website. The problem has been carried out in two ways, the linear regression equation and the normal equation presented by [10]. The predictions are performed using both the ways and are compared in the next part of this section.\nA) Data Set with Trend\nThe data gathered in the earlier section can be shown in the\nform of graph given below:\nThe fig 7 data have been collected from the last week of September; 2016.The following detailed form is extracted with the help of figure 7, showing only 12 records as a sample.\nB) Linear Regression\nAs discussed Linear Regression works only on continuous values of both independent and dependent variables.\nThe formula of single input LR is given by:\nh\u03b8(x) = \u03b80 + \u03b81x1 (1)\nThe formula of multiple inputs LR is given by:\nh\u03b8(x) = \u03b80 + \u03b81x1 + \u03b82x2 + \u22ef+ \u03b8nxn (2)\nh\u03b8(X) = \u03b8 TX\nBefore proceeding the data needs to be normalized because of the expected gap among the values of a single feature especially the keywords, \u2018football\u2019 and \u2018Ronaldo\u2019 might have a gap which would reduce the accuracy, so feature scaling, in other words normalization could solve this problem. Mean and\nStandard Deviation are the vital two terms that are part of normalization.\nMean:\n\u03bc = \u2211x\nn\u22121 (3)\nStandard Deviation:\n\u03c3 = \u221a \u2211(x\u2212x\u0305)2\nn\u22121 (4)\nNormalization formula:\nxnew = x\u2212 \u03bc\n\u03c3 (5)\nOur goal is to calculate the appropriate parameters to predict the out, the formula to calculate the parameters is given by:\nJ(\u03b80, \u03b81) = 1\n2m \u2211 (h\u03b8(x\n(i)) \u2212 y(i))2mi=1 (6)\nThe main task is to reduce the cost by minimizing the parameters:\nminimize \u03b80,\u03b81 J(\u03b80, \u03b81)\nTo make it efficient the cost must be reduced using the gradient descent:\nRepeat until convergence {\n\u03b8j \u2236= \u03b8j \u2212 \u03b1 \u2202y\n\u2202\u03b8j J(\u03b80, \u03b81) (7)\n(for j = 1 and j = 0)\nThis must run until the parameters start converging. The Simple Linear Regression also known as the single input/feature/independent variable linear regression is used to have the insights of the one to one relationship of each feature with the output. The \u03b80 in both types of linear regression is the interception value. This value is set to 1 which is passed as the interception value, often called as constant [25]. It is used to found the mean of y in case of x=0, however in our problem the intercept value can be removed because the predictors will never be a zero value. It is the response or the output value when all parameters are set to zero [11], [12].\nAlpha (\ud835\udefc) in the gradient descent function is the learning rate which helps alongside the number of iteration to find the best possible parameters. The greater the value of \ud835\udefc the less iterations would be required and vice versa [13]. Here \ud835\udefc is set to 0.01 and number of iterations to 400. The above two values are checked and tested. It gives the optimal value of error."}, {"heading": "V. EXPERIMENTAL RESULTS AND PERFORMANCE EVALUATION", "text": "This section illustrates the demonstrative experiments to enhance click through rate of the contextual advertisements using Linear Regression based on context of the publishers and evaluate the performance of proposed technique in term of accuracy and standard error.\n1. Simple Linear Regression\nThe advertisement size and placement are categorical in natural so they can be ignored for simple linear regression. But all continuous based features like bid and keywords are used to show the direct relation with the outcome CTR using a graphical view. The simple linear regression has been defined earlier in this section is used to find the relationship for the following two relations. The data used has been converted into a normalized form.\nFig 9 shows a linear relation between bid and click through rate. The increase in bid means an increase in CTR and vice versa. Parameters found: 0.034421, 0.030570. For bid = 22, the predicted CTR is 0.036440\nFig 10 shows that there is no such relation between the keywords and CTR. The output can decrease with the increase in input and vice versa. It is an overfitting of data since many points are far from the regression line.\nReducing the three-dimensional space into two-dimensional, shown in fig 12.\nParameters found: -0.001484, 0.017645\nFor Keyword = 51 (England), the predicted CTR is 0.009720. This could be a negative value upon changing the keyword. From fig 10 it is proved that the keyword relation with CTR is not typical as of previous relation but somehow using this feature alongside other features gives an efficient result, discussed in the next part.\n2. Multivariate Linear Regression\nNow taking all features into account and using all in a multivariate linear regression to predict the outcome.\nThe data which has been normalized is used to find the parameters using the gradient descent. Parameters calculated are shown in the table 7. Fig 13 explains how cost function is converged with respect to the number of iteration which is set to 400.\nFrom Matlab, the following results are obtained;\nThe LR using feature scaling and gradient descent gives a result 0.042821. Normal Equation is an easy way of solving Linear Regression problems. It does not require the steps as performed above. But the limitation is that it cannot be used for a large feature set. Normal equation is given by:\n\u03b8 = (XTX)\u22121XTy\u20d7 (8)\nFrom Matlab, the following results are obtained;\nThe normal equation gives a result 0.042946, almost equal to that we got from the previous method but with no work like cost reduction and feature scaling. This result will vary by changing the no. of records in the data set. The results obtained using the keyword as a feature gives almost the same result from the two ways, linear regression and normal equation. The accuracy and the standard error of the system is calculated using the cross validation set, given in table 9:\nTable 9. CROSS VALIDATION SET\nAd\nPlacement Ad Size Bid\nKeywords (Table 5) CTR\n1 1 12 52 0.03\n1 2 32 51 0.05\n1 1 14 49 0.042\n1 1 21 50 0.04\n0 2 25 47.1 0.0001\n0 3 6 48 0.00005\nStandard Error:\nSE = \u221a \u2211(y\u2212y\u2032)2\nN (9)\ny is the observed CTR, y\u2032 is the predicted CTR and N is the total no. of records which is 6.\nThe second last row is the sum and the last row is the mean of the respective column. Standard Error found to be equal to 0.010126512. These types of errors have a direct effect on the accuracy of the training and test data and this is usually found in linear regression [18]. R squared is a useful statistical measure which helps in finding the accuracy of the model [19]."}, {"heading": "R squared:", "text": "R2 = 1 \u2212 \u2211 (yi\u2212y\n\u2032) 2n i=1\n\u2211 (yi\u2212ym) 2n\ni=1\n= 1 \u2212 SSE\nSSTO (10)\nSSE is the sum of squares error, SSTO is the total sum of squares.\nThe last row is the mean value of the respective column. R squared found to be equal to 0.836581861, meaning that 83.65% of data has fitted the model correctly. The accuracy can be increased by removing the keyword from the feature set but the concern here is to use the dynamically converted keyword into a meaningful value as a feature to obtain the best possible results."}, {"heading": "VI. CONCLUSION", "text": "This research presented a new technique of predicting the click through rate for online advertisements using Linear Regression along with some dynamically added feature known as the keyword. The proposed technique helps to calculate the CTR from a different angle despite causing a minor decrease in efficiency. The accuracy found is 83% and removing that feature could take this accuracy to 95% which is a significant increase and fits the model perfectly but the CTR is also dependent on the keywords since the research is based on the contextual advertisements. For future research work, these results can help to combine and reveal further more techniques to enhance the performance of the advertisement serving over the internet."}], "references": [{"title": "Machine Learning in the Real World", "author": ["V. Chaoji", "R. Rastogi", "G. Roy"], "venue": "Proc. VLDB Endow., Vol. 9, No. 13, 2016.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2016}, {"title": "Feature extraction for regression problems and an example application for pose estimation of a face", "author": ["N. Kwak", "S.-I. Choi", "C.-H. Choi"], "venue": "International Conference Image Analysis and Recognition, pp. 435\u2013444. 2008.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2008}, {"title": "Ad click prediction: a view from the trenches", "author": ["H.B. McMahan"], "venue": "Proceedings of the 19th ACM SIGKDD international conference on Knowledge discovery and data mining,, pp. 1222\u20131230,2013.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2013}, {"title": "Predicting clicks: estimating the click-through rate for new ads", "author": ["M. Richardson", "E. Dominowska", "R. Ragno"], "venue": "Proceedings of the 16th international conference on World Wide Web, pp. 521\u2013530, 2007.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2007}, {"title": "Web-scale bayesian click-through rate prediction for sponsored search advertising in microsoft\u2019s bing search engine", "author": ["T. Graepel", "J.Q. Candela", "T. Borchert", "R. Herbrich"], "venue": "Proceedings of the 27th International Conference on Machine Learning (ICML-10), pp. 13\u201320. 2010.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2010}, {"title": "Simple and scalable response prediction for display advertising", "author": ["O. Chapelle", "E. Manavoglu", "R. Rosales"], "venue": "ACM Trans. Intell. Syst. Technol. TIST, Vol. 5, No. 4, p. 61, 2015.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2015}, {"title": "Regression for ordinal variables without underlying continuous variables", "author": ["V. Torra", "J. Domingoferrer", "J. Mateosanz", "M. Ng"], "venue": "Inf. Sci., Vol. 176, No. 4, pp. 465\u2013474, Feb. 2006.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2006}, {"title": "A Logistic Regression Approach to Ad Click Prediction", "author": ["G. Kondakindi", "S. Rana", "A. Rajkumar", "S.K. Ponnekanti", "V. Parakh"], "venue": "Mach. Learn.-Cl. Proj., 2014.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2014}, {"title": "Using logistic regression to predict customer retention", "author": ["A.H. Karp"], "venue": "Proceedings of the Eleventh Northeast SAS Users Group Conference. http://www. lexjansen. om/nesug/nesug98/solu/p095. pdf, 1998.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 1998}, {"title": "Linear Regression", "author": ["A. Ng"], "venue": "CS229 Lect. Notes, vol. 1, no. 1, pp. 1\u20133, 2000.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2000}, {"title": "What you see may not be what you get: a brief, nontechnical introduction to overfitting in regression-type models", "author": ["M.A. Babyak"], "venue": "Psychosom. Med., Vol. 66, No. 3, pp. 411\u2013421, 2004.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2004}, {"title": "The general inefficiency of batch training for gradient descent learning", "author": ["D.R. Wilson", "T.R. Martinez"], "venue": "Neural Netw., Vol. 16, No. 10, pp. 1429\u20131451, Dec. 2003.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2003}, {"title": "Clustering the tagged web", "author": ["D. Ramage", "P. Heymann", "C.D. Manning", "H. Garcia-Molina"], "venue": "Proceedings of the Second ACM  International Conference on Web Search and Data Mining, pp. 54\u201363, 2009.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2009}, {"title": "Fast Algorithms for Mining Association Rules in Datamining", "author": ["P. Usharani"], "venue": "Int. J. of Scientific & Technology research, Vol. 2, pp. 13\u201324, 2013.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2013}, {"title": "An improved K-Means Algorithm Based on Association Rules", "author": ["G. Liu", "S. Huang", "C. Lu", "Y. Du"], "venue": "Int. J. Comput. Theory Eng., Vol. 6, No. 2, p. 146, 2014.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2014}, {"title": "Flow classification using clustering and association rule mining", "author": ["U.K. Chaudhary", "I. Papapanagiotou", "M. Devetsikiotis"], "venue": "2010 15th IEEE International Workshop on Computer Aided Modeling, Analysis and Design of Communication Links and Networks (CAMAD), pp. 76\u2013 80, 2010.", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2010}, {"title": "Data Quality in Linear Regression Models: Effect of Errors in Test Data and Errors in Training Data on Predictive Accuracy.", "author": ["B.D. Klein", "D.F. Rossin"], "venue": "InformingSciJ,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 1999}, {"title": "A general and simple method for obtaining R 2 from generalized linear mixed-effects models", "author": ["S. Nakagawa", "H. Schielzeth"], "venue": "Methods Ecol. Evol., Vol. 4, No. 2, pp. 133\u2013142, Feb. 2013.", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2013}, {"title": "Estimation and accuracy after model selection", "author": ["B. Efron"], "venue": "J. Am. Stat. Assoc., vol. 109, no. 507, pp. 991\u20131007, 2014.", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2014}, {"title": "Click-through Prediction for Advertising in Twitter Timeline", "author": ["C. Li", "Y. Lu", "Q. Mei", "D. Wang", "S. Pandey"], "venue": "pp. 1959\u20131968, 2015.", "citeRegEx": "20", "shortCiteRegEx": null, "year": 1959}, {"title": "Practical Lessons from Predicting Clicks on Ads at Facebook", "author": ["X. He"], "venue": "pp. 1\u20139, 2014.", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2014}, {"title": "Association rules mining: A recent overview", "author": ["S. Kotsiantis", "D. Kanellopoulos"], "venue": "GESTS Int. Trans. Comput. Sci. Eng.,Vol. 32, No. 1, pp. 71\u2013 82, 2006.", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2006}, {"title": "Machine learning for targeted display advertising: Transfer learning in action", "author": ["B. Dalessandro", "F. Provost", "T. Raeder", "C. Perlich", "O. Stitelman"], "venue": "2013.", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2013}, {"title": "If an Advertisement Runs Online And No One Sees It, Is It Still an Ad? Empirical Generalizations in Digital Advertising", "author": ["S. Flosi", "G. Fulgoni", "A. Vollman"], "venue": "J. Advert. Res., Vol. 53, No. 2, pp. 192\u2013199, Jun. 2013.", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2013}, {"title": "An introduction to regression analysis", "author": ["A.O. Sykes"], "venue": "1993.", "citeRegEx": "25", "shortCiteRegEx": null, "year": 1993}], "referenceMentions": [{"referenceID": 0, "context": "Machine Learning has played an important part in the online serving of advertisements, a paper presented by [1] explains how important the machine learning is in the real world.", "startOffset": 108, "endOffset": 111}, {"referenceID": 1, "context": "This step has been done in wide variety of ways for the regression problems, linear discriminant analysis (LDA) which is used for classification problem was modified to solve regressions problems by [2].", "startOffset": 199, "endOffset": 202}, {"referenceID": 13, "context": "The mapping of ordinal data into a meaningful continuous stream for linear regression to avoid fitting problems in this research has been done using the concept of k-mean clustering and association rule as presented by [14], [15], respectively.", "startOffset": 219, "endOffset": 223}, {"referenceID": 14, "context": "The mapping of ordinal data into a meaningful continuous stream for linear regression to avoid fitting problems in this research has been done using the concept of k-mean clustering and association rule as presented by [14], [15], respectively.", "startOffset": 225, "endOffset": 229}, {"referenceID": 15, "context": "The clustering and rule mining for textual categorization has been previously researched by [16], [17] but have not used to solve the regression problems.", "startOffset": 92, "endOffset": 96}, {"referenceID": 16, "context": "The clustering and rule mining for textual categorization has been previously researched by [16], [17] but have not used to solve the regression problems.", "startOffset": 98, "endOffset": 102}, {"referenceID": 6, "context": "Whereas [7] presented the conversion of ordinal data into nominal data and ignored the continuous variables for the regression.", "startOffset": 8, "endOffset": 11}, {"referenceID": 2, "context": "It has been done using Logistic Regression by various researchers such as [3], further na\u00efve Bayes has played a vital part in the building of ad click prediction, this can be seen in [4], [5].", "startOffset": 74, "endOffset": 77}, {"referenceID": 3, "context": "It has been done using Logistic Regression by various researchers such as [3], further na\u00efve Bayes has played a vital part in the building of ad click prediction, this can be seen in [4], [5].", "startOffset": 183, "endOffset": 186}, {"referenceID": 4, "context": "It has been done using Logistic Regression by various researchers such as [3], further na\u00efve Bayes has played a vital part in the building of ad click prediction, this can be seen in [4], [5].", "startOffset": 188, "endOffset": 191}, {"referenceID": 5, "context": "The estimation of response for the display advertisements is presented by [6].", "startOffset": 74, "endOffset": 77}, {"referenceID": 22, "context": "Similarly, the more the viewers the ad serving becomes hard to solve, the research presented by [23] has focused on the targeting display advertisements using massive-scale machine learning.", "startOffset": 96, "endOffset": 100}, {"referenceID": 7, "context": "Another research in this filed was done by [8] in which the focus is on the comparison of different machine Learning techniques including the logistic regression.", "startOffset": 43, "endOffset": 46}, {"referenceID": 19, "context": "The recent growth in the social networking on the internet has produced some great examples of ad serving technologies, Twitter advertising model is also based on the logistic regression, [20].", "startOffset": 188, "endOffset": 192}, {"referenceID": 20, "context": "While, another top network Facebook has used decision trees with logistic regression presented in [21] to serve the ads to their millions of users daily.", "startOffset": 98, "endOffset": 102}, {"referenceID": 8, "context": "The importance of logistic regression in finding the customers behavior can be seen in the paper written by [9].", "startOffset": 108, "endOffset": 111}, {"referenceID": 18, "context": "Estimating the errors and accuracy after model selection is one of the important parts of it according to [19].", "startOffset": 106, "endOffset": 110}, {"referenceID": 23, "context": "Further feature like ad placement plays a vital role because an advertisement is not serving the purpose if it is unreachable for the viewer [24].", "startOffset": 141, "endOffset": 145}, {"referenceID": 2, "context": "The past researches have shown that this is a regression problem and perfectly fits to the logistic model [3, 8], however our goal is to use linear regression with a little variance in the feature selection method where we will use techniques like clustering to make the feature meaningful in order to avoid over fitting and under fitting problems.", "startOffset": 106, "endOffset": 112}, {"referenceID": 7, "context": "The past researches have shown that this is a regression problem and perfectly fits to the logistic model [3, 8], however our goal is to use linear regression with a little variance in the feature selection method where we will use techniques like clustering to make the feature meaningful in order to avoid over fitting and under fitting problems.", "startOffset": 106, "endOffset": 112}, {"referenceID": 10, "context": "before processing it must be converted to avoid regression problems like over fitting and under fitting [11].", "startOffset": 104, "endOffset": 108}, {"referenceID": 11, "context": "In order to solve this problem Association Rule can be used to make it meaningful and to avoid fitting problems [12].", "startOffset": 112, "endOffset": 116}, {"referenceID": 15, "context": "The association rule mining is a technique to find the relationship among certain data set [16].", "startOffset": 91, "endOffset": 95}, {"referenceID": 9, "context": "The problem has been carried out in two ways, the linear regression equation and the normal equation presented by [10].", "startOffset": 114, "endOffset": 118}, {"referenceID": 24, "context": "This value is set to 1 which is passed as the interception value, often called as constant [25].", "startOffset": 91, "endOffset": 95}, {"referenceID": 10, "context": "It is the response or the output value when all parameters are set to zero [11], [12].", "startOffset": 75, "endOffset": 79}, {"referenceID": 11, "context": "It is the response or the output value when all parameters are set to zero [11], [12].", "startOffset": 81, "endOffset": 85}, {"referenceID": 12, "context": "The greater the value of \u03b1 the less iterations would be required and vice versa [13].", "startOffset": 80, "endOffset": 84}, {"referenceID": 17, "context": "These types of errors have a direct effect on the accuracy of the training and test data and this is usually found in linear regression [18].", "startOffset": 136, "endOffset": 140}, {"referenceID": 18, "context": "R squared is a useful statistical measure which helps in finding the accuracy of the model [19].", "startOffset": 91, "endOffset": 95}], "year": 2016, "abstractText": "This research presents an innovative and unique way of solving the advertisement prediction problem which is considered as a learning problem over the past several years. Online advertising is a multi-billion-dollar industry and is growing every year with a rapid pace. The goal of this research is to enhance click through rate of the contextual advertisements using Linear Regression. In order to address this problem, a new technique propose in this paper to predict the CTR which will increase the overall revenue of the system by serving the advertisements more suitable to the viewers with the help of feature extraction and displaying the advertisements based on context of the publishers. The important steps include the data collection, feature extraction, CTR prediction and advertisement serving. The statistical results obtained from the dynamically used technique show an efficient outcome by fitting the data close to perfection for the LR technique using optimized feature selection. Keywords-Click Through Rate(CTR), Contextual Advertisements, Machine Learning, Web advertisements, Regression Problem.", "creator": "Microsoft\u00ae Word 2013"}}}