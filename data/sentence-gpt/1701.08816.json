{"id": "1701.08816", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "30-Jan-2017", "title": "Fully Convolutional Architectures for Multi-Class Segmentation in Chest Radiographs", "abstract": "The recent success of Deep Convolutional Neural Networks on image classification and recognition tasks has led to new applications in very diversifying contexts. One of these is medical imaging where scarcity and imbalance of training data has hindered rapid development of neural network related applications. While the current paradigm of machine learning is much more sophisticated and provides more depth of learning, it has also taken many long-term theoretical approaches and has brought about a huge shift in the understanding of the underlying human behavior. This has led to a change in how we think about the human behavior. Today, I am presenting a series of papers in this article.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "histories": [["v1", "Mon, 30 Jan 2017 20:21:57 GMT  (5018kb,D)", "http://arxiv.org/abs/1701.08816v1", null], ["v2", "Fri, 14 Apr 2017 14:42:02 GMT  (7568kb,D)", "http://arxiv.org/abs/1701.08816v2", "* reworked motivation of the paper and contributions * slightly reduced related work overview * improved the math * added more evaluations (the old ones are still there) * added more images * added new references"], ["v3", "Tue, 18 Apr 2017 13:02:51 GMT  (7568kb,D)", "http://arxiv.org/abs/1701.08816v3", "* simplified math in one place * added one sentence in the conclusions"]], "reviews": [], "SUBJECTS": "cs.CV cs.LG", "authors": ["alexey a novikov", "dimitrios lenis", "david major", "jiri hlad\\r{u}vka", "maria wimmer", "katja b\\\"uhler"], "accepted": false, "id": "1701.08816"}, "pdf": {"name": "1701.08816.pdf", "metadata": {"source": "CRF", "title": "Fully Convolutional Architectures for Multi-Class Segmentation in Chest Radiographs", "authors": ["Alexey A. Novikov", "David Major", "Dimitrios Lenis", "Ji\u0159\u0131\u0301 Hlad\u016fvka", "Maria Wimmer", "Katja B\u00fchler"], "emails": ["(novikov@vrvis.at,", "major@vrvis.at,", "lenis@vrvis.at,", "hladuvka@vrvis.at,", "mwimmer@vrvis.at,", "buehler@vrvis.at)."], "sections": [{"heading": null, "text": "This paper investigates and proposes neural network architectures within the context of automated segmentation of anatomical organs in chest radiographs, namely for lung, clavicles and heart. By relating prior class data distributions to the objective function sparsely represented structures are methodologically emphasized. Scarce training sets and data augmentation are encountered with aggressive data regularization. The problem of highly imbalanced target object appearance in the input data is solved by modifying the objective function.\nThe models are trained and tested on the publicly available JSRT database consisting of 247 X-Ray images the ground-truth masks for which available in the SCR database. The networks have been trained in a multi-class setup with three target classes.\nOur best performing model trained with the negative Dice loss function was able to reach mean Jaccard overlap scores of 94.1% for lungs, 86.6% for heart and 88.7% for clavicles in the multi-label setup, therefore, outperforming the best state-of-the art methods for heart and clavicle and human observer on lung and heart segmentation tasks.\nIndex Terms\u2014Lung segmentation, clavicle segmentation, heart segmentation, fully convolutional network, regularization, imbalanced data, chest radiographs, multi-class segmentation, JSRT dataset\nI. INTRODUCTION\nDESPITE a plethora of modalities and their combinationsin current state of the art medical imaging, radiography holds an esteemed position, forming together with ultrasonography the two main pillars of diagnostic imaging, helping in solving between 70-80% of diagnostic questions [1]. Considering posterior anterior chest radiographs (CXR) as an example, their importance is apparent: in an NHS technical report [2] they are listed as the leading tool in diagnosis and treatment; variations of the size, positions and areas of heart, lung fields, hila structures, clavicles etc. may give indications on the presence of TBC, cancer and other diseases or assist in their early diagnosis.\nHence semantic segmentation of radiographs has been an active field of study. Individual anatomical intricacies like high interpersonal variations in shape and size of central organs like lung fields, clavicles and heart, related to age, size and gender, ambiguous organ boundaries due to organ overlaps and\nA. A. Novikov, D. Major, D. Lenis, J. Hladu\u030avka, M. Wimmer and K. Bu\u0308hler are with the VRVis Center for Virtual Reality and Visualization, 1220 Vienna, Austria, e-mail: (novikov@vrvis.at, major@vrvis.at, lenis@vrvis.at, hladuvka@vrvis.at, mwimmer@vrvis.at, buehler@vrvis.at).\nartifacts caused by movements and image modality intrinsics, are just a few of the reasons why accurate organ segmentation on CXR images still remains an inherently challenging task.\nUnsurprisingly solutions therefore vary in their favored toolsets including rule-, shape- and graph- based methods, pixel classifications and statistical approaches. Based on their recent, rapid success in computer vision challenges [3] neural network (NN) based approaches are successfully used. These solutions, typically avoid using task-specific, manually engineered features. Such features tend to be more capable of describing different aspects of an object. Usually they derive their generalizability out of vast datasets (e.g. ImageNet database [4] holds more than one million labeled training images) that are not available in the medical domain, thereby indicating the need for more delicately assembled network structures."}, {"heading": "A. Related Work", "text": "Due to their above-stated significance, semantic CXR segmentation has been studied extensively in the literature. As approaches vary vastly, only solutions which had been tested against a common dataset are listed below. These training and test sets consist of CXRs made available through the Japanese Society of Radiological Technology (JSRT) [5]. The SCR database with manual segmentations for lung fields, heart and clavicles was introduced in the study by Ginneken et al. [6]. In the algorithms compared in the study the authors performed their evaluations on downsampled images of the smaller resolution, namely 256 \u00d7 256, which reduces computational complexity, but due to downsampling introduces an additional, in specific use cases maybe even problematic border smoothing. As a common overlap measure the different groups used the Jaccard Index [7].\nClassical Approaches: Following and augmenting van Ginneken et al. [6], the space of algorithmic approaches may be roughly partitioned into rule-, shape- and graph- based methods, pixel classification and statistical approaches. Each methodological framework has their own set of advantages, e.g. by limiting to a predefined rule-set or deformable shape, rule and shape based methods will yield anatomical sound solutions. Graph-based methods build upon the anatomy inherent topology and therefore will also adhere to that principle, but simultaneously allow for a higher class of variations, with the tradeoff of higher computational complexity. Pixel classification and statistical approaches treat the problem as a local classification / optimization task and therefore allow for higher variations, maintaining a traceable computation at\nar X\niv :1\n70 1.\n08 81\n6v 1\n[ cs\n.C V\n] 3\n0 Ja\nn 20\n17\n2 the cost of sometimes unrealistic outcome. Typically as the following show, best results can be achieved by hybrid approaches, i.e. the combination of efficient initial segmentations with successive detailed adoptions to plausible outputs.\nAdhering to their importance lung fields have received significant attention. Candemir et al. [8] developed a registrationbased algorithm. The same group proposed a graph-cut based algorithm [9]; focusing on (smoothing-) parameter adaptation, the algorithm achieved a mean score of 0.976 promising qualitatively robust results and time-efficient calculation. A recent hybrid approach stems from the work by Shao et al. [10], combining active shape and appearance models; the group yields a comparable overlap score of 0.946. Ibragimov et al. [11] demonstrate how the combination of landmarkbased segmentation and random shape based random forest classifier can achieve an overlap score of 0.953, while still maintaining computational efficiency. Based on an active shape model approach, specifically addressing the initialization dependency of these models [12], achieves an improvement and an overlay score of 0.954. van Ginneken et al. [6] survey older approaches, back to 2006, that score on the same dataset comparably between 0.713 and 0.969; the survey also evaluated a human observer with a score of 0.9468 which did not vary statistically significantly from the survey leading pixel classification method. Overall lung field segmentation in CXR remains an active topic, with algorithmic setups rivaling the human observer.\nIn comparison, segmentation of clavicles has shown to be more challenging. High variations of their positioning and general shape, the impact of bone density on the radiograph and their overlap with rib and lung structures yield in high personspecific intricacies, thereby big deviations from a theoretical average clavicle and hence a steep impact on overlay scores. van Ginneken et al. [6] include clavicle segmentation in the survey where they were able to reach scores between 0.505 and 0.734. The human observed reached 0.896 which demonstrates that comparing to segmentation of lung and heart fields this task is challenging even for humans. Hogeweg et al. [13] developed a combination of pixel classification, active shape model and dynamic programming that led them to an overlap of 0.850; however the overlap was only measured within the lung fields. Predominantly shape/contour- based models vary on the choice of the underlying feature space. Exemplified on the approach presented by Boussaid et al. [14], the problem is addressed as a deformable contour model, that uses SIFT features to describe the embedding object appearance. Using this, they achieved an overlap score of 0.904.\nStarting from their respective lung field segmentation, most approaches are geared towards a generalizable solution, trying to adapt their algorithm to also span the hearts requirements. Similarly, van Ginneken et al. [6] and Boussaid et al. [14] also report on their segmentation results, yielding in between 0.77 and 0.86 and mean 0.91 overlap scores respectively. In a recent study, Candemir et al. [15] specifically adapted their registration based method [8] to fit heart-position extraction, and achieved an overlap accuracy between 0.697 and 0.087 (compared to 0.954 for their lung field segmentation). Generally, as the heart boundaries are overlapped and occluded by\nthe surrounding lung fields, hence are not clearly visible, exact segmentation remains challenging.\nNeural networks: While conceptually more than 50 years old Neural Networks (NN), the abstracted basis of deep learning, are living through a revival [3]. A deeper understanding of training and numerical behavior and the steep increase of tractable calculation schemes through the leveraging of graphical processing units (GPUs) has allowed this class of approach to become the de facto standard, or at least serious contender in several machine learning branches [3], [16]. For brevity, the following focuses on convolutional neural networks (CNNs), successfully used subclass of NN in computer vision tasks [17].\nA prototypical setup of such CNNs consists of a combination of convolution filters, interspersed with data reduction and pooling layers [18]. The driving idea is to mimic human visual cognition, in that sense that the complete picture is derived out of low-level features, e.g. edges and circles, which in return yield more distinctive features and finally the desired target through recombination in each successive layer.\nRegarding the segmentation of medical images several such setups have been studied; e.g. Greenspan et al. [18] made a summary of the recent state-of-the-art works in the area. As stated above thesemantic segmentation typically builds upon a vast set of training data, e.g. ImageNet [4] and Pascal VOC2012 [19]. Such large datasets are not typical for the medical domain, rendering most current approaches unfeasible, hence calling for a finely tailored strategy. First attempts date back more than 15 years ago; Tsujii et al. [20] use a NN for lung field segmentation yielding in accuracy around 86%. Aece et al. [21] use a CNN as a binary classifier and thereby partition chest radiographs into the two {bone, non-bone} sets in a fully-automated fashion. NNs do not need to be considered as a standalone solution as was demonstrated by Ngo et al. [22]. The group combined regularized level sets with a deep learning approach and yielded on JSRT overlap scores between 0.948 and 0.985. While CXR segmentation has not been covered extensively yet, different modalities like ultrasound, CT and MRT have been explored [23], [24], [25], [26].\nLong et al. [27] address the need for local features that coincide with global structures, and define the Fully Convolutional Net. This type of network allows for arbitrary sized input and output. In combination with layer fusion, i.e. shortcuts between selected layers, this setup achieves a nonlinear, local-to-global feature representation, and allows for a pixelwise classification. By adapting this network-class with successive upsampling layers, i.e. enlarging the field of view of the convolution, Ronneberger et al. [28] guide the resolution of feature extraction, and thereby control the localto-global relations of features. The authors used excessive data augmentation by applying elastic deformations in order to cope with the lack of training data for the cell segmentation task. Elastic deformations however are not reasonable in case of CXR images because that would make rigid organs such as lungs, heart and clavicles look anatomically incorrect and moreover could confuse training by making the network learn features corresponding to such unrealistic structures.\nWe explicitly address the issues of limited options regarding\n3 non-rigid transformations, unbalanced organ representation and ambiguous organ boundaries. We specifically adapt the U-Net model [28] for CXR images by applying other regularization methods and building new architectures performing succesfully without additional data augmentation. We also propose and compare two different training loss functions to deal with the problem of the multi-class segmentation in the case of imbalanced data representation which is the case for clavicles in CXR images as they are under-represented in the sense of pixel area comparing to heart and lung fields. Our solution allows us to simultaneously yield overlap scores, comparable and in many cases surpassing state-of-theart techniques and human performance on all considered tasks including the classically challenging cases of heart and clavicle segmentation."}, {"heading": "B. Contributions", "text": "The major contributions of our work include the following: 1) We propose a multi-class end-to-end approach for seg-\nmentation of anatomical organs in chest radiographs. 2) We propose a solution for training the fully convolu-\ntional models in case of imbalanced data representation. 3) We propose architectures which outperform state-of-the-\nart methods by a large margin, especially on the clavicle segmentation task on publicly available JSRT dataset."}, {"heading": "II. METHODOLOGY", "text": "In this section, we begin with a formal description of the multi-class approach. We then shortly describe the base setup our methods are built on and, finally, we outline our architecture design strategies and propose a number of models applicable to solving the problems specific for CXR images."}, {"heading": "A. Multi-Class Approach", "text": "The input data consists of a set of 2D images J = {I | I \u2208 Rm1\u00d7m2} and the corresponding multi-channel binary ground-truth masks (Li,I) 1\u2264i\u2264n where Li \u2208 {0, 1}m1\u00d7m2 , n is the number of classes we aim to address, and m1,m2 are the image dimensions.\nWe first split J into sets I TRAIN of size K = | I TRAIN | and I TEST = J \\ I TRAIN. As described above, for each I \u2208 J a series of binary ground-truth masks (Li,I) 1\u2264i\u2264n is used. For a later reference let L be the set of all ground truth classes, hence 1 \u2264 n \u2264 |L|.\nThe networks are trained in the following manner: the network is consecutively passed with minibatches K \u2208 N where N is a partition of the set I TRAIN. Minibatches K are non-empty subsets of of I TRAIN derived in a way that every image I \u2208 I TRAIN is included in one and only one of the minibatches K. Additionally, we introduce cK to define the total pixel count over all I \u2208 K.\nFor each I \u2208 K the multi-class output of the network is calculated, i.e. understanding the network as a function\nF : J \u2192 ({0, 1}m1\u00d7m2) 1\u2264i\u2264n (1)\nTherefore, for each pixel of I its semantic class l \u2208 L can be derived in a single step up to some probability.\nIn order to estimate and maximize this probability we can define an energy function\n\u039b(Li,I) : {0, 1} m1\u00d7m2 \u00d7 (Li,I)\u2192 R (2)\nthat estimates the deviation (error) of the network outcome from the desired ground-truth. The error is back-propagated then to update the network parameters. The whole procedure continues until the defined given stopping criteria are fulfilled.\nAt testing time an unseen image I \u2208 I TEST is passed through the network and the multi-label output F(I) is produced. As defined above, the network output consists of series of multichannel segmentation masks. The channels in case of chest radiographs correspond to different body organs.\nThe model is built, initialized and further trained. After the training is finished the learnt model weights and regularization layers are fixed and the model is validated on a set of test images. Main steps of the method are introduced in the following sections in detail."}, {"heading": "B. Base Setup", "text": "The U-Net like architecture which was originally proposed by Ronnenberger et al. [28] consists of contraction and expansion parts. In the contraction part high-level abstract features are extracted by consecutive application of pairs of convolutional and pooling layers. In the expansion part the low-level abstract features are merged with the features from the contractive part respectively. The output of the network is a multi-channel segmentation mask where each channel has the same size as the input image.\nExcellent performance of the Original U-Net architecture has been demonstrated for segmentation of neuronal structures in electron microscopic stacks [28]. For other subject-specific tasks it however requires additional modifications due to a different data representation. In particular, when data is highly imbalanced or in cases when data augmentation is not reasonable. The problem on imbalanced data in medical images occurs due to different sizes of anatomical organs of interest. For example, in JSRT dataset ground-truth masks 60% of pixels belong to background, 29% to lung, 2% to clavicles and 9% to heart respectively, hence emphasizing lung and heart fields over clavicles.\nC. Improvements of U-Net Model for Chest Radiographs\nOn top of the original architecture we analyze and evaluate the network by introducing a number of modifications in architecture and training. We consider a number of possible improvements of the network model in detail and based on the evaluation results propose a number of models tailored to efficiently train and perform multiclass segmentation on medical CXR images. To avoid the data augmentation which was applied in the method by Ronneberger et al. [28] we propose to modify the model by using a more aggressive regularization. On top of this we propose a number of architectures to further improve the segmentation result. In addition to a different model regularization and architectural modifications we propose a different training loss function strategy to cope with the problem of highly imbalanced data\n4 representation. An overview of the proposed archicterutes is depicted in Fig. 1.\nArchitectural Modifications: Acquiring more training data would be of benefit for any learning algorithm. However, in medical imaging getting additional data is not always feasible.\nRonneberger et al. [28] used elastic deformations for data augmentation in order to regularize the model. However elastic deformations are not reasonable in case of chest radiographs because they would make rigid organs such as lungs, heart and clavicles look anatomically incorrect and could then confuse training by making the network learn features corresponding to unrealistic structures.\nThe number of feature maps and layers in the original version of U-Net is large which results in tens of millions of parameters in the system which slows down training and does not necessarily decrease generalization error. Without any regularization training of such large networks can overfit on the data. Especially when there is not much training data available. Overfitting is especially a problem for smaller or thinner prolongated anatomical organs such as clavicles due to their more varying shape representations in CXR images. In the case when the network architecture is deep and availability of training data is limited, another possibility to decrease the generalization test error of the algorithm is more aggressive regularization.\na) All-Dropout - improving accuracy with aggressive regularization: Dropout layer [29] has become a common practice in modern deep network architectures. Moreover, according to Bouthillier et al. [30] it can also play a role of data augmentation at the same time. We therefore propose an architecture with a dropout layer after every convolutional layer in the network. We use the Gaussian dropout which is equivalent to adding a Gaussian distributed random variable with zero mean and standard deviation equal to the activation of the neural unit. According to Srivastava et al. [29] it works even better than the classic one which uses the Bernoulli distribution. Besides, adding such noise is a more natural choice for chest radiographs due to Gaussian noise occuring during their acquisition [31]. In the following we address this architecture as All-Dropout.\nb) InvertedNet - improving accuracy with fewer parameters: One way of dealing with model overfitting is to reduce the number of parameters. We propose a modification of the All-Dropout architecture by a) performing the delayed subsampling of the first pooling layer with (1,1) pooling and b) changing the numbers of feature maps in the network. In this architecture we propose to start with the large number of feature maps and divide it by the factor of two after every pooling layer and increase by the factor of two after every upsampling layer respectively. In this case the networks learn many different variations of structures at the early layers and less high level features at the later layers. This seems more reasonable in case of more rigid anatomical organs such as clavicles because their shapes in the end do not vary too\nmuch and therefore there is no need to learn too many high abstract features. We will call this architecture InvertedNet due to the way the numbers of feature maps are changed with respect to the Original U-Net architecture.\nc) All-Convolutional - improving accuracy by learning pooling: Springenberg et al. [32] showed that having pooling layers replaced by convolutional layers with a higher stride or removing pooling layers completely can improve final results. This modification introduces new parameters in the network but can be considered as a learning of pooling for each part of the network rather than just fixing pooling parameters to constant values. Such pooling learning can be useful for learning better features for smaller and thinner elongated objects. Further motivated the work by Springenberg et al. [32] we adapt the Original U-Net accordingly to the model All-CNN-C: each pooling layer is replaced by a convolutional layer with filter size equal to the pooling size of the replaced pooling layer. We modify the All-Dropout architecture correspondingly and further call this architecture All-Convolutional.\nTraining Strategies: As already mentioned above large differences in sizes between anatomical organs of interest can introduce a problem of imbalanced data representation. In such cases classes are represented in highly different amounts pixel-wise and therefore losses for sparsely represented classes can go unnoticed sometimes. Hence, classic formulations of loss such as crossentropy or negative dice functions would underestimate the classes represented in very small amounts. We address the imbalance in pixel representation by introducing a weighted distance function.\nFollowing the section II-A let L be the set of all groundtruth classes and N a partition of our training set. For K \u2208 N and cK its total pixel count we define rK,l as the ratio:\nrK,l := cl,K cK\n(3)\nwhere cl,K is the number of pixels belonging to the semantic class l \u2208 L in the training batch K.\nFor a distance function d : {0, 1}m1\u00d7m2 \u00d7 {0, 1}m1\u00d7m2 \u2192 R, and an image I \u2208 K we minimize our objective function\n\u039b(Li,I)(I) := \u2211 l\u2208L r\u22121K,l d(F(I)l, Ll,I) (4)\nover the set K and the complete partition. By this sparsely represented classes, e.g. clavicles, are no longer under-represented in favor to large ground-truth mask, e.g. lung fields.\nFor d we chose and evaluated the so-called weighted pixelwise cross-entropy and weighted negative dice loss functions. Cross-entropy is a typical choice for neural networks and dice seems to be a natural choice in case of segmentation problems. The weighted dice loss function in our case takes the sigmoid activation computed at the final output feature map for each channel as the input. The sigmoid activation is defined as:\npk(x) := 1\n1 + e\u2212ak(x) (5)\n5 where ak(x) indicates activation at feature channel k at the pixel x \u2208 I and pk(x) is the approximated probability of the pixel x not belonging to background. In the case of weighted negative dice the output does not have to provide a channel for the background class.\nGiven an image I , let {Li} be the set of non-background pixels in the corresponding ground-truth multi-channel mask and Pk(I) is the set of pixels where the model is sure that they do not belong to the background:\nPk(I) := {x : x \u2208 I \u2227 | pk(x)\u2212 1 | < } (6)\nwhere is a small tolerance value. The distance function d for the negative Dice coefficient for a training image I can then be defined as:\ndLk,I (I) := \u22122 |Pk(I) \u2229 Gk(I) | |Pk(I)|+ | Gk(I)|\n(7)\nwhere Pk(I) is the predicted segmentation mask and Gk(I) is the corresponding ground-truth segmentation mask for the image I for the channel k.\nThe weighted pixelwise cross-entropy takes the softmax activation computed at the final output feature map for each channel as the input. We use the softmax pk(x) as defined by Ronneberger et al. [28] and the distance function d of the cross-entropy for a training image I we define as:\ndLk,I (I) := \u2211 x\u2208I 1Gk(I) log pk(x) cK (8)"}, {"heading": "D. Proposed Network Architectures", "text": "We summarize the proposed architectures: \u2022 All-Dropout: Modified version of the U-Net architecture\n[28] with dropout layers placed after every convolutional layer. Depicted at Fig. 1a.\n\u2022 InvertedNet: Similarly to All-Dropout with the delayed subsampling of the first pooling layer and numbers of feature maps in the network inverted with respect to Original U-Net. Depicted at Fig. 1b.\n\u2022 All-Convolutional: Similar to All-Dropout with pooling layers replaced by new convolutional layers with filter sizes equal to the pooling size of the corresponding pooling layer. Depicted at Fig. 1c.\nWe use padded convolutions in all architectures for all convolutional layers. Therefore output channels will have the same size as the input image except the J-Net architecture where input dimensions are four times larger than of the output. All proposed architectures contain convolutional and dropout layers. In all architectures all convolutional layers are followed by dropout layers except the third convolutional layers in the All-Convolutional architecture where the layer plays a role of the pooling layer it replaces. In all models we used the rectified linear unit functions [33] at all convolutional hidden layers. It is the most common and well performing activation function in modern network architectures [3].\nTo reduce the number of parameters and speed up training, instead of the last dense layers we used the convolutional layer with the number of feature maps equal to the number of considered classes in case of the weighted dice and with one more for background in case of weighted pixelwise crossentropy functions. To splash the values to the [0, 1] range at the output of the network we used the sigmoid function as an activation at the output layer."}, {"heading": "III. EXPERIMENTS", "text": ""}, {"heading": "A. JSRT dataset", "text": "We use the JSRT dataset [5] both for training and testing. The dataset consists of 247 posterior anterior (PA) chest radiographs with a resolution of 2048\u00d72048, 0.175 mm pixel size and 12 bit depth. The reference organ boundaries for JSRT images for left and right lung fields, heart and left and right clavicles were introduced by van Ginneken et al. [6] in 1024\u00d7 1024 resolution and available in the SCR database."}, {"heading": "B. Training Model", "text": "Data has been normalized using the mean and standard deviation across the whole training dataset. It has been zerocentered first by subtracting the mean and then normalized additionally by scaling using its standard deviation. It was then split into training and testing sets. Models were trained on images of one of the following resolutions: 128 \u00d7 128, 256 \u00d7 256 and 512 \u00d7 512. Original images and masks were downsampled to these resolutions by the local averaging algorithm. To make the paper comparable with state-of-the-art methods, most results in our work correspond to the 256\u00d7256 image resolution.\nTo optimize the model we used the Adaptive Moment Estimation method (ADAM) [34] as it employs an adaptive learning rate approach for each parameter. It stores decaying average of both past squared gradients and past gradients. We varied different initial learning rates in order to find the most stable convergence and 10\u22125 and 5 \u2217 10\u22125 seemed to be the most reasonable choices. Training converged slower in the former but more stable than with the latter one. We therefore used the fixed initial rate of 10\u22125 in all our experiments. We used the early stopping criterion with 200 epochs to avoid overfitting."}, {"heading": "C. Performance Metrics", "text": "To evaluate the architectures and compare with state-ofthe-art works, we used the following performance metrics:\nDice Similarity Coefficient:\nD = 2\u00d7 | G \u2229 S | | G |+ | S |\n(9)\nJaccard Similarity Coefficient:\nJ = | G \u2229 S |\n| G |+ | S | \u2212 | G \u2229 S | (10)\n6\n7 where in both coefficients Dsi and J, G represents the ground-truth data and S stands for the segmentation provided by the evaluated method.\nSymmetric Mean Absolute Surface Distance:\nSsg = 1\n(ns + ng) \u00d7  ns\u2211 i=1 | dsgi |+ ng\u2211 j=1 | dgsj |  (11) where ns is the number of pixels in the segmentation provided by the evaluated method, ng is the number of pixels in the ground-truth data mask, dsgi is the distance from i-th pixel in the segmentation to the closest pixel in the ground-truth data mask, and dgsj is the distance from j-th pixel in the ground-truth data mask to the closest pixel in the segmentation provided by the evaluated method."}, {"heading": "IV. RESULTS AND DISCUSSION", "text": ""}, {"heading": "A. Segmentation Performance", "text": "Evaluation results for the proposed architectures for different resolutions are shown in Table I. In addition, results for Original U-Net for three resolutions as well as the best performing methods and human observer results introduced by van Ginneken et al. [6] are added for comparison. Table I is subdivided into five blocks. The first block contains only the human observer result. The second block contains results for the best performing methods summarized by van Ginneken et al. [6]. The third, fourth and fifth blocks contain results of the Original U-Net and the proposed architectures for three different resolutions. Best results for each metric at each block are highlighted in bold font.\nScores for lung segmentation did not vary significantly across the methods. All approaches were able to reach results close to human performance. Though none of our architectures actually outperformed human observed and the Hybrid Voting method [6], one of the models reached the same Jaccard score and all of proposed architectures as well as Original U-Net achieved more accurate object contours according to the symmetric surface distance.\nClavicle segmentation was a bit more challenging task for all our architectures. And it is not surprising because clavicles are much smaller than heart and lungs and their shapes change more significantly from one scan to another. None of the proposed methods could outperform human observer though the methods proposed by van Ginneken et al. [6] have been outperformed. Our best proposed architecture outperformed Hybrid Voting by almost 8% in Jaccard overlap score. All our architectures performed better than the Original U-Net architecture on all image resolutions. In addition, as one can see from the Table I, results for higher resolutions are much better for smaller objects such as clavicles. Except for InvertedNet architecture which showed a poor performance due to the delayed subsample pooling and small filter sizes in the convolutional layers. On lower resolutions though the InvertedNet demonstrated the best performance on the clavicle segmentation where Original U-Net was surpassed by more\nthan 7% and the other two networks by 5% and 6% respectively. The performance of the InvertedNet architecture on high resolution can be improved simply by replacing normal convolutional layers by dilated convolutional layers instead. An example of such modification is shown in Fig. 1d and the performance results is added in the Table I. In summary, clavicles are more challenging for Original U-Net, AllConvolutional and All-Dropout on lower resolutions because of the multiple pooling layers in the contractive part of the network and the lack of regularization. In this case the features extracted by the network become less expressive for smaller objects such as clavicles.\nHeart segmentation was a challenging task for the InvertedNet architecture. It was even slightly outperformed by the Original U-Net which in its turn was surpassed by the other proposed architectures. Two other proposed architectures AllConvolutional and All-Dropout slightly surpassed the human observer on this task.\nThe performance of the overall best architecture InvertedNet has been evaluated with several splits of input data into training and testing sets. Table III shows testing results of the InvertedNet trained with the pixelwise cross-entropy loss function. As theoretically expected overall scores get improved when more training data is given to the network. On the other hand increasing difference between numbers of samples in training and testing sets leads to a slight overfitting on the data and therefore increasing of the final generalization error. This is not the case for the negative dice loss function though where increasing the number of training samples gives much better results. Evaluation results for different testing splits for the negative dice loss function are shown in the Table IV.\nFig. 2 shows how the Original U-Net and the proposed models perform on the test set at each epoch during training. The scores of the Original U-Net typically grow faster than the other networks in the beginning but then reach a plateau and oscillate till the end of the training procedure. Other better regularized architectures though start off slower, reach higher or similar scores in the end. InvertedNet starts really slow in the beginning but reaches the best result in the end.\nFig. 3 shows performance results for Original U-Net and the three proposed architectures on the clavicle segmentation task. The X-axis corresponds to intervals for Jaccard scores and the Y-axis corresponds to percentages of test samples falling into the Jaccard intervals from the X-axis. The factor plot has been produced using results for 50%-50% testing split and pixelwise cross-entropy function. InvertedNet has most samples in the last interval and is the only architecture which did not perform worse than 0.7. Jaccard scores for more than a half of the testing samples for InvertedNet reached scores greater than 0.9 which is a proof of the model robustness.\nAll our proposed architectures reached the best symmetric distance to surface scores among all methods on all organs which is a clear message that convolutional networks are very efficient in extracting features corresponding to object borders. Even in case of quite low contrast difference, for example, on the borders between heart and lung or clavicles and lung.\nFig. 4 shows few examples of the algorithm results for both successful and failed cases. In the white boxes Jaccard\nscores for lungs, clavicles and heart are shown. To extract the shape contours of the segmentation and ground-truth we used morphological outline extraction algorithm on both segmentation result and reference masks. The contour of the\nground-truth is shown in green, segmentation result of the algorithm in red and overlap of two contours in yellow colors respectively."}, {"heading": "B. Timing Performance", "text": "Table II shows overview of the proposed architectures with execution times measured on the PC with Intel(R) Xeon(R) CPU E5-2650 v3 @ 2.30 GHz CPU and GeForce GTX TitanX GPU with 12 GB of memory.\nTo the best of our knowledge our method is the fastest segmentation approach for CXR images up to date. With modern hardware it can process thousands of images per day which is especially beneficial in big clinical environments when hundreds or sometimes thousands of people are being checked every day."}, {"heading": "V. CONCLUSIONS", "text": "In this paper we propose an end-to-end approach for multi-class segmentation of anatomical organs in CXR scans. We introduce and evaluate in total three fully-convolutional architectures which reach high test scores on JSRT public dataset showing similar or outperforming the Original U-Net architecture and other state-of-the-art methods on all organs. Our best architecture outperforms the human observer results\non lungs and heart. Clavicle segmentation is still a challenging task for our architectures though they got much closer to the the human observer scores than any other state-of-theart method did previously. Overall results show that simply adding more regularization and extracting larger number of high level abstract features can be beneficial for improving segmentation of smaller objects such as clavicles. Introducing weighting into the loss-function is crucial when dealing with the highly imbalanced data which is the case in CXR images. Our best architecture has nearly ten times less parameters than the Original U-Net and despite that it outperforms it by a large margin. Trained with the negative Dice loss function it was able to reach mean Jaccard overlap scores of 94.1% for lungs, 86.6% for heart and 88.7% for clavicles."}], "references": [{"title": "Deep learning", "author": ["Y. LeCun", "Y. Bengio", "G. Hinton"], "venue": "Nature, vol. 521, pp. 436\u2013444, 2015.  10", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2015}, {"title": "ImageNet Large Scale Visual Recognition Challenge", "author": ["O. Russakovsky", "J. Deng", "H. Su", "J. Krause", "S. Satheesh", "S. Ma", "Z. Huang", "A. Karpathy", "A. Khosla", "M. Bernstein", "A.C. Berg", "L. Fei-Fei"], "venue": "International Journal of Computer Vision (IJCV), vol. 115, no. 3, pp. 211\u2013252, 2015.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2015}, {"title": "Development of a digital image database for chest radiographs with and without a lung nodule: receiver operating characteristic analysis of radiologists\u2019 detection of pulmonary nodules", "author": ["J. Shiraishi", "S. Katsuragawa", "J. Ikezoe", "T. Matsumoto", "T. Kobayashi", "K.i. Komatsu", "M. Matsui", "H. Fujita", "Y. Kodera", "K. Doi"], "venue": "American Journal of Roentgenology, vol. 174, no. 1, pp. 71\u201374, 2000.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2000}, {"title": "Segmentation of anatomical structures in chest radiographs using supervised methods: a comparative study on a public database", "author": ["B. van Ginneken", "M.B. Stegmann", "M. Loog"], "venue": "Medical Image Analysis, vol. 10, pp. 19\u201340, 2006.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2006}, {"title": "An Elementary Mathematical Theory of Classification and Prediction", "author": ["T. Tanimoto"], "venue": "International Business Machines Corporation,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 1958}, {"title": "Lung segmentation in chest radiographs using anatomical atlases with nonrigid registration", "author": ["S. Candemir", "S. Jaeger", "K. Palaniappan", "J.P. Musco", "R.K. Singh", "Z. Xue", "A. Karargyris", "S. Antani", "G. Thoma", "C.J. McDonald"], "venue": "IEEE Transactions on Medical Imaging, vol. 33, no. 2, pp. 577\u2013590, Feb 2014.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2014}, {"title": "Multi-class regularization parameter learning for graph cut image segmentation", "author": ["S. Candemir", "K. Palaniappan", "Y. Sinan"], "venue": "International Symposium on Biomedical Imaging (ISBI 2013), 2013.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2013}, {"title": "Hierarchical lung field segmentation with joint shape and appearance sparse learning", "author": ["Y. Shao", "Y. Gao", "Y. Guo", "Y. Shi", "X. Yang", "D. Shen"], "venue": "IEEE Transactions on Medical Imaging, vol. 33, no. 9, pp. 1761\u20131780, Sept 2014.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2014}, {"title": "Accurate landmarkbased segmentation by incorporating landmark misdetections", "author": ["B. Ibragimov", "B. Likar", "F. Pernu", "T. Vrtovec"], "venue": "International Symposium on Biomedical Imaging (ISBI 2016), April 2016, pp. 1072\u20131075.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2016}, {"title": "An edge-region force guided active shape approach for automatic lung field detection in chest radiographs", "author": ["T. e. a. Xu"], "venue": "Computerized Medical Imaging and Graphics, vol. 36, pp. 452\u2013463, 2012.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2012}, {"title": "Clavicle segmentation in chest radiographs", "author": ["L. e. a. Hogeweg"], "venue": "Medical Image Analysis, vol. 16, pp. 1490\u20131502, 2012.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2012}, {"title": "Discriminative learning of deformable contour models", "author": ["H. Boussaid", "I. Kokkinos", "N. Paragios"], "venue": "International Symposium on Biomedical Imaging (ISBI 2014), April 2014, pp. 624\u2013628.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2014}, {"title": "Automatic heart localization and radiographic index computation in chest x-rays", "author": ["S. Candemir", "S. Jaeger", "W. Lin", "Z. Xue", "S. Antani", "G. Thoma"], "venue": "2016.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2016}, {"title": "Deep learning for medical image segmentation", "author": ["M. Lai"], "venue": "arXiv e-prints, arXiv:1505.02000, vol. abs/1505.02000, 2015. [Online]. Available: http://arxiv.org/abs/1505.02000", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2000}, {"title": "Imagenet classification with deep convolutional neural networks", "author": ["A. Krizhevsky", "I. Sutskever", "G.E. Hinton"], "venue": "Conference on Neural Information Processing Systems (NIPS 2012), 2012.", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2012}, {"title": "Guest editorial deep learning in medical imaging: Overview and future promise of an exciting new technique", "author": ["H. Greenspan", "B. van Ginneken", "R.M. Summers"], "venue": "IEEE Transactions on Medical Imaging, vol. 35, no. 5, pp. 1153\u20131159, May 2016.", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2016}, {"title": "Semantic image segmentation with deep convolutional nets and fully connected crfs", "author": ["L. Chen", "G. Papandreou", "I. Kokkinos", "K. Murphy", "A.L. Yuille"], "venue": "arXiv e-prints, arXiv:1412.7062v4 [cs.CV], vol. abs/1412.7062, 2014. [Online]. Available: http://arxiv.org/abs/1412.7062", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2014}, {"title": "Automated segmentation of anatomic regions in chest radiographs using an adaptive-sized hybrid neural network", "author": ["O. Tsujii", "M.T. Freedman", "S.K. Mun"], "venue": "Medical physics, vol. 25, pp. 998\u20131007, 1998.", "citeRegEx": "20", "shortCiteRegEx": null, "year": 1998}, {"title": "Segmentation of bone structure in x-ray images using convolutional neural network", "author": ["C. Cernazanu-Glavan", "S. Holban"], "venue": "Advances in Electrical and Computer Engineering, vol. 13, no. 1, pp. 87\u201394, Feb 2013.", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2013}, {"title": "Lung segmentation in chest radiographs using distance regularized level set and deep-structured learning and inference", "author": ["T.A. Ngo", "G. Carneiro"], "venue": "International Conference on Image Processing (ICIP 2015), Sept 2015, pp. 2140\u20132143.", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2015}, {"title": "The segmentation of the left ventricle of the heart from ultrasound data using deep learning architectures and derivative-based search methods", "author": ["G. Carneiro", "J.C. Nascimento", "A. Freitas"], "venue": "IEEE Transactions on Image Processing, vol. 21, no. 3, pp. 968\u2013982, March 2012.", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2012}, {"title": "Brain tumor segmentation with deep neural networks", "author": ["M. Havaei", "A. Davy", "D. Warde-Farley", "A. Biard", "A. Courville", "Y. Bengio", "C. Pal", "P.-M. Jodoin", "H. Larochelle"], "venue": "Medical Image Analysis, 2016.", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2016}, {"title": "Deep learning in the small sample size setting: cascaded feed forward neural networks for medical image segmentation", "author": ["B. Gaonkar", "D. Hovda", "N. Martin", "L. Macyszyn"], "venue": "pp. 97 852I\u201397 852I\u20138, 2016.", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2016}, {"title": "Fully convolutional networks for semantic segmentation", "author": ["J. Long", "E. Shelhamer", "T. Darrell"], "venue": "Computer Vision and Pattern Recognition (CVPR 2015), 2015.", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2015}, {"title": "U-net: Convolutional Networks for biomedical image segmentation", "author": ["O. Ronneberger", "P. Fischer", "T. Brox"], "venue": "International Conference on Medical Image Computing and Computer-Assisted Intervention (MICCAI 2015). Springer, 2015, pp. 234\u2013241.", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2015}, {"title": "Dropout: a simple way to prevent neural networks from overfitting.", "author": ["N. Srivastava", "G.E. Hinton", "A. Krizhevsky", "I. Sutskever", "R. Salakhutdinov"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "29", "shortCiteRegEx": "29", "year": 2014}, {"title": "Dropout as data augmentation", "author": ["X. Bouthillier", "K. Konda", "P. Vincent", "R. Memisevic"], "venue": "arXiv e-prints, arXiv:1412.7062v4 [cs.CV], vol. 1050, p. 8, 2016.", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2016}, {"title": "A method for modeling noise in medical images", "author": ["P. Gravel", "G. Beaudoin", "J.A. De Guise"], "venue": "IEEE Transactions on Medical Imaging, vol. 23, no. 10, pp. 1221\u20131232, 2004.", "citeRegEx": "31", "shortCiteRegEx": null, "year": 2004}, {"title": "Striving for simplicity: The all convolutional net", "author": ["J.T. Springenberg", "A. Dosovitskiy", "T. Brox", "M. Riedmiller"], "venue": "International Conference on Learning Representations (ICLR 2015), 2014.", "citeRegEx": "32", "shortCiteRegEx": null, "year": 2015}, {"title": "Digital selection and analogue amplification coexist in a cortex-inspired silicon circuit", "author": ["R.H. Hahnloser", "R. Sarpeshkar", "M.A. Mahowald", "R.J. Douglas", "H.S. Seung"], "venue": "Nature, vol. 405, no. 6789, pp. 947\u2013951, 2000.", "citeRegEx": "33", "shortCiteRegEx": null, "year": 2000}, {"title": "Adam: A method for stochastic optimization", "author": ["D. Kingma", "J. Ba"], "venue": "International Conference on Learning Representations (ICLR 2015), 2015.", "citeRegEx": "34", "shortCiteRegEx": null, "year": 2015}], "referenceMentions": [{"referenceID": 0, "context": "Based on their recent, rapid success in computer vision challenges [3] neural network (NN) based approaches are successfully used.", "startOffset": 67, "endOffset": 70}, {"referenceID": 1, "context": "ImageNet database [4] holds more than one million labeled training images) that are not available in the medical domain, thereby indicating the need for more delicately assembled network structures.", "startOffset": 18, "endOffset": 21}, {"referenceID": 2, "context": "These training and test sets consist of CXRs made available through the Japanese Society of Radiological Technology (JSRT) [5].", "startOffset": 123, "endOffset": 126}, {"referenceID": 3, "context": "[6].", "startOffset": 0, "endOffset": 3}, {"referenceID": 4, "context": "As a common overlap measure the different groups used the Jaccard Index [7].", "startOffset": 72, "endOffset": 75}, {"referenceID": 3, "context": "[6], the space of algorithmic approaches may be roughly partitioned into rule-, shape- and graph- based", "startOffset": 0, "endOffset": 3}, {"referenceID": 5, "context": "[8] developed a registrationbased algorithm.", "startOffset": 0, "endOffset": 3}, {"referenceID": 6, "context": "The same group proposed a graph-cut based algorithm [9]; focusing on (smoothing-) parameter adaptation, the algorithm achieved a mean score of 0.", "startOffset": 52, "endOffset": 55}, {"referenceID": 7, "context": "[10], combining active shape and appearance models; the group yields a comparable overlap score of 0.", "startOffset": 0, "endOffset": 4}, {"referenceID": 8, "context": "[11] demonstrate how the combination of landmarkbased segmentation and random shape based random forest classifier can achieve an overlap score of 0.", "startOffset": 0, "endOffset": 4}, {"referenceID": 9, "context": "Based on an active shape model approach, specifically addressing the initialization dependency of these models [12], achieves an improvement and an overlay score of 0.", "startOffset": 111, "endOffset": 115}, {"referenceID": 3, "context": "[6] survey older approaches, back to 2006, that score on the same dataset comparably between 0.", "startOffset": 0, "endOffset": 3}, {"referenceID": 3, "context": "[6] include clavicle segmentation in the survey where they were able to reach scores between 0.", "startOffset": 0, "endOffset": 3}, {"referenceID": 10, "context": "[13] developed a combination of pixel classification, active shape model and dynamic programming that led them to an overlap of 0.", "startOffset": 0, "endOffset": 4}, {"referenceID": 11, "context": "[14], the problem is addressed as a deformable contour model, that uses SIFT features to describe the embedding object appearance.", "startOffset": 0, "endOffset": 4}, {"referenceID": 3, "context": "[6] and Boussaid et al.", "startOffset": 0, "endOffset": 3}, {"referenceID": 11, "context": "[14] also report on their segmentation results, yielding in between 0.", "startOffset": 0, "endOffset": 4}, {"referenceID": 12, "context": "[15] specifically adapted their registration based method [8] to fit heart-position extraction, and achieved an overlap accuracy between 0.", "startOffset": 0, "endOffset": 4}, {"referenceID": 5, "context": "[15] specifically adapted their registration based method [8] to fit heart-position extraction, and achieved an overlap accuracy between 0.", "startOffset": 58, "endOffset": 61}, {"referenceID": 0, "context": "Neural networks: While conceptually more than 50 years old Neural Networks (NN), the abstracted basis of deep learning, are living through a revival [3].", "startOffset": 149, "endOffset": 152}, {"referenceID": 0, "context": "of training and numerical behavior and the steep increase of tractable calculation schemes through the leveraging of graphical processing units (GPUs) has allowed this class of approach to become the de facto standard, or at least serious contender in several machine learning branches [3], [16].", "startOffset": 286, "endOffset": 289}, {"referenceID": 13, "context": "of training and numerical behavior and the steep increase of tractable calculation schemes through the leveraging of graphical processing units (GPUs) has allowed this class of approach to become the de facto standard, or at least serious contender in several machine learning branches [3], [16].", "startOffset": 291, "endOffset": 295}, {"referenceID": 14, "context": "For brevity, the following focuses on convolutional neural networks (CNNs), successfully used subclass of NN in computer vision tasks [17].", "startOffset": 134, "endOffset": 138}, {"referenceID": 15, "context": "A prototypical setup of such CNNs consists of a combination of convolution filters, interspersed with data reduction and pooling layers [18].", "startOffset": 136, "endOffset": 140}, {"referenceID": 15, "context": "[18] made a summary of the recent state-of-the-art works in the area.", "startOffset": 0, "endOffset": 4}, {"referenceID": 1, "context": "ImageNet [4] and Pascal VOC2012 [19].", "startOffset": 9, "endOffset": 12}, {"referenceID": 16, "context": "ImageNet [4] and Pascal VOC2012 [19].", "startOffset": 32, "endOffset": 36}, {"referenceID": 17, "context": "[20] use a NN for lung field segmentation yielding in accuracy around 86%.", "startOffset": 0, "endOffset": 4}, {"referenceID": 18, "context": "[21] use a CNN as a binary classifier and thereby partition chest radiographs into the two {bone, non-bone} sets in a fully-automated fashion.", "startOffset": 0, "endOffset": 4}, {"referenceID": 19, "context": "[22].", "startOffset": 0, "endOffset": 4}, {"referenceID": 20, "context": "While CXR segmentation has not been covered extensively yet, different modalities like ultrasound, CT and MRT have been explored [23], [24], [25], [26].", "startOffset": 129, "endOffset": 133}, {"referenceID": 21, "context": "While CXR segmentation has not been covered extensively yet, different modalities like ultrasound, CT and MRT have been explored [23], [24], [25], [26].", "startOffset": 135, "endOffset": 139}, {"referenceID": 22, "context": "While CXR segmentation has not been covered extensively yet, different modalities like ultrasound, CT and MRT have been explored [23], [24], [25], [26].", "startOffset": 147, "endOffset": 151}, {"referenceID": 23, "context": "[27] address the need for local features that coincide with global structures, and define the Fully Convolutional Net.", "startOffset": 0, "endOffset": 4}, {"referenceID": 24, "context": "[28] guide the resolution of feature extraction, and thereby control the localto-global relations of features.", "startOffset": 0, "endOffset": 4}, {"referenceID": 24, "context": "We specifically adapt the U-Net model [28] for CXR images by applying other regularization methods and building new architectures performing succesfully without additional data augmentation.", "startOffset": 38, "endOffset": 42}, {"referenceID": 24, "context": "[28] consists of contraction and expansion parts.", "startOffset": 0, "endOffset": 4}, {"referenceID": 24, "context": "Excellent performance of the Original U-Net architecture has been demonstrated for segmentation of neuronal structures in electron microscopic stacks [28].", "startOffset": 150, "endOffset": 154}, {"referenceID": 24, "context": "[28] we", "startOffset": 0, "endOffset": 4}, {"referenceID": 24, "context": "[28] used elastic deformations for data augmentation in order to regularize the model.", "startOffset": 0, "endOffset": 4}, {"referenceID": 25, "context": "a) All-Dropout - improving accuracy with aggressive regularization: Dropout layer [29] has become a common practice in modern deep network architectures.", "startOffset": 82, "endOffset": 86}, {"referenceID": 26, "context": "[30] it can also play a role of data augmentation at the same time.", "startOffset": 0, "endOffset": 4}, {"referenceID": 25, "context": "[29] it works even better than the classic one which uses the Bernoulli distribution.", "startOffset": 0, "endOffset": 4}, {"referenceID": 27, "context": "during their acquisition [31].", "startOffset": 25, "endOffset": 29}, {"referenceID": 28, "context": "[32] showed that having pooling layers replaced by convolutional layers with a higher stride or removing pooling layers completely can improve final results.", "startOffset": 0, "endOffset": 4}, {"referenceID": 28, "context": "[32] we adapt the Original U-Net accordingly to the model All-CNN-C: each pooling layer is replaced by a convolutional layer with filter size equal to the pooling size of the replaced pooling layer.", "startOffset": 0, "endOffset": 4}, {"referenceID": 24, "context": "[28] and the distance function d of the cross-entropy for a training image I we define as:", "startOffset": 0, "endOffset": 4}, {"referenceID": 24, "context": "\u2022 All-Dropout: Modified version of the U-Net architecture [28] with dropout layers placed after every convolutional layer.", "startOffset": 58, "endOffset": 62}, {"referenceID": 29, "context": "In all models we used the rectified linear unit functions [33] at all convolutional hidden layers.", "startOffset": 58, "endOffset": 62}, {"referenceID": 0, "context": "It is the most common and well performing activation function in modern network architectures [3].", "startOffset": 94, "endOffset": 97}, {"referenceID": 2, "context": "We use the JSRT dataset [5] both for training and testing.", "startOffset": 24, "endOffset": 27}, {"referenceID": 3, "context": "[6] in 1024\u00d7 1024 resolution and available in the SCR database.", "startOffset": 0, "endOffset": 3}, {"referenceID": 30, "context": "To optimize the model we used the Adaptive Moment Estimation method (ADAM) [34] as it employs an adaptive learning rate approach for each parameter.", "startOffset": 75, "endOffset": 79}, {"referenceID": 3, "context": "Human Observer [6] 0.", "startOffset": 15, "endOffset": 18}, {"referenceID": 3, "context": "PC post-processed [6] - 0.", "startOffset": 18, "endOffset": 21}, {"referenceID": 3, "context": "20 Hybrid Voting [6] - 0.", "startOffset": 17, "endOffset": 20}, {"referenceID": 3, "context": "24 ASM Tuned [6] - 0.", "startOffset": 13, "endOffset": 16}, {"referenceID": 3, "context": "[6] are added for comparison.", "startOffset": 0, "endOffset": 3}, {"referenceID": 3, "context": "[6].", "startOffset": 0, "endOffset": 3}, {"referenceID": 3, "context": "Though none of our architectures actually outperformed human observed and the Hybrid Voting method [6], one of the models reached the same Jaccard score and all of proposed architectures as well as Original U-Net achieved more accurate object contours according to the symmetric surface distance.", "startOffset": 99, "endOffset": 102}, {"referenceID": 3, "context": "[6] have been outperformed.", "startOffset": 0, "endOffset": 3}], "year": 2017, "abstractText": "The recent success of Deep Convolutional Neural Networks on image classification and recognition tasks has led to new applications in very diversifying contexts. One of these is medical imaging where scarcity and imbalance of training data has hindered rapid development of neural network related applications. This paper investigates and proposes neural network architectures within the context of automated segmentation of anatomical organs in chest radiographs, namely for lung, clavicles and heart. By relating prior class data distributions to the objective function sparsely represented structures are methodologically emphasized. Scarce training sets and data augmentation are encountered with aggressive data regularization. The problem of highly imbalanced target object appearance in the input data is solved by modifying the objective function. The models are trained and tested on the publicly available JSRT database consisting of 247 X-Ray images the ground-truth masks for which available in the SCR database. The networks have been trained in a multi-class setup with three target classes. Our best performing model trained with the negative Dice loss function was able to reach mean Jaccard overlap scores of 94.1% for lungs, 86.6% for heart and 88.7% for clavicles in the multi-label setup, therefore, outperforming the best state-of-the art methods for heart and clavicle and human observer on lung and heart segmentation tasks.", "creator": "LaTeX with hyperref package"}}}