{"id": "1702.02914", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "9-Feb-2017", "title": "Spatial Filtering for EEG-Based Regression Problems in Brain-Computer Interface (BCI)", "abstract": "Electroencephalogram (EEG) signals are frequently used in brain-computer interfaces (BCIs), but they are easily contaminated by artifacts and noises, so preprocessing must be done before they are fed into a machine learning algorithm for classification or regression. Spatial filters have been widely used to increase the signal-to-noise ratio of EEG for BCI classification problems, but their applications in BCI regression problems have been very limited. This paper proposes two common spatial pattern (CSP) filters for EEG-based regression problems in BCI, which are extended from the CSP filter for classification, by making use of fuzzy sets of CSPs to represent all information about brain activity in the BCI (the CSP filter is used by the BCI as a way to improve classification problems). The first filter was used for classification problems for BIs in the BCI (a CSP filter was used to detect abnormal signal-to-noise ratio for BCI and a CSP filter was used to detect the noise in the BCI). For CSP filtering, the number of CSPs used is as low as 10 in a CSP filter for a CSP filter and 1 in a CSP filter for a CSP filter (the average of the CSP filters of CSPs is 1 in a CSP filter). The last one was used for classification problems (as shown in Figure 2), and in the same CSP filter the CSP filter was used to classify the signal-to-noise ratio for BCI classification problems (as shown in Fig. 3). The most common CSP filters were used to classify the CSP filter as a CSP filter (the average of the CSP filters of BCI and a CSP filter were used to identify noise in the BCI, although this would not necessarily change the signal-to-noise ratio) and to improve classification problems (as shown in Figure 4).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "histories": [["v1", "Thu, 9 Feb 2017 17:44:28 GMT  (525kb)", "http://arxiv.org/abs/1702.02914v1", null]], "reviews": [], "SUBJECTS": "cs.LG cs.HC", "authors": ["dongrui wu", "jung-tai king", "chun-hsiang chuang", "chin-teng lin", "tzyy-ping jung"], "accepted": false, "id": "1702.02914"}, "pdf": {"name": "1702.02914.pdf", "metadata": {"source": "CRF", "title": "Spatial Filtering for EEG-Based Regression Problems in Brain-Computer Interface (BCI)", "authors": ["Dongrui Wu", "Jung-Tai King", "Chun-Hsiang Chuang", "Chin-Teng Lin"], "emails": ["drwu09@gmail.com,", "jtchin2@gmail.com,", "cch.chuang@gmail.com,", "Chin-Teng.Lin@uts.edu.au,", "jung@sccn.ucsd.edu"], "sections": [{"heading": null, "text": "ar X\niv :1\n70 2.\n02 91\n4v 1\n[ cs\n.L G\nIndex Terms\u2014Brain-computer interface, common spatial pattern, EEG, fuzzy sets, psychomotor vigilance task, response speed estimation, spatial filtering\nI. INTRODUCTION\nElectroencephalogram (EEG) signals are the most widely used input for brain-computer interfaces (BCIs) [24], [25], [29], [34], [47], [53], mainly due to the convenience to obtain them, compared with magnetoencephalography (MEG) [32], functional magnetic resonance imaging (fMRI) [44], functional near-infrared spectroscopy (fNIRS) [33], and invasive signals like electrocorticography (ECoG) [35] and intracortical neural recordings [30]. However, EEG signals are often contaminated by ocular, muscular, and cardiac artifacts and various noises (power-line, changes in electrode impedances, etc) [4], [34], [49]. Usually some preprocessing, either manually or automatically [4], [34], is needed to remove the artifacts, and then temporal and spatial filters are applied to further improve the EEG signal quality before feeding it into a classification\nor regression algorithm. The most commonly used temporal filters are band-pass filters and notch filters (at 50 or 60 Hz power-line frequency).\nThis paper focuses on spatial filtering for improving the EEG signal quality. Many such approaches have been proposed in the literature [2], [7], [15], [17], [37], [38], [40], [41], [54]. However, almost all of them focus primarily on EEG classification problems in BCI, whereas EEG regression problems have been largely overlooked. Nevertheless, the latter is also very important in BCI. One example is driver drowsiness (or alertness) estimation from EEG signals, which has been extensively studied in our previous research [26]\u2013[28], [56], [59], [60], [62]. This is a very important problem because drowsy driving is among the most important causes of road crashes, following only to alcohol, speeding, and inattention [43]. According to the National Highway Traffic Safety Administration [52], 2.5% of fatal motor vehicle crashes (on average 886/year in the U.S.) and 2.5% of fatalities (on average 1,004/year in the U.S.) between 2005 and 2009 involved drowsy driving.\nThis paper proposes two spatial filters for EEG-based regression problems in BCI. We also validate their performance in response speed (RS) estimation from EEG signals measured in a large-scale sustained-attention psychomotor vigilance task (PVT) [21], which collected 143 sessions of data from 17 subjects in a 5-month period.\nThe remainder of this paper is organized as follows: Section II reviews the state-of-the-art spatial filters for EEGbased classification problems in BCI. Section III introduces our proposed spatial filters for supervised BCI regression problems. Section IV describes the experimental setup, RS and EEG data preprocessing techniques, and the procedure to evaluate the performances of different spatial filters. Section V presents the results of the comparative studies and parameter sensitivity analysis for the proposed spatial filter. Section VI discusses the limitations of the proposed approaches and outlines several future research directions. Finally, Section VII\n2 draws conclusions."}, {"heading": "II. SPATIAL FILTERS FOR EEG CLASSIFICATION IN BCI", "text": "Many spatial filters have been proposed for EEG classification in BCI. The most basic ones include common average reference (CAR) [48], Laplacian filters [23], and principal component analysis [19]. Some of the more recent and also more sophisticated ones are:\n1) Independent Component Analysis (ICA) [9], [17], [54], which decomposes a multivariate signal into independent non-Gaussian signals. ICA has been widely used in the EEG research community to detect and remove stereotyped eye, muscle, and line noise artifacts [20], [26], [49]. Generally ICA works on an unepoched long block of EEG data, instead of epoched short EEG trials. Let the unepoched EEG data be X \u2208 RC\u00d7T , where C is the number of EEG channels, and T is the number of time samples. ICA assumes that X is the linear combination of c independent sources, i.e., X = AS, where A \u2208 R\nC\u00d7c is the mixing matrix, and the source signals, which are the rows of S \u2208 Rc\u00d7T , are supposed to be stationary, independent, and non-Gaussian. ICA can use various different principles [9], [17], [49], [54] to estimate both unknown A and unknown S simultaneously from X. Once S is obtained, cleaner and more representative features may be extracted from it than from the original X [26]. 2) xDAWN algorithm [38]\u2013[40], which is often used to increase the signal to signal-plus-noise ratio in P300based BCIs. Like ICA, xDAWN also works on the unepoched long block of EEG data X \u2208 RC\u00d7T . It assumes that X = PD\nT +N, where P \u2208 RC\u00d7S represents the P300 signal in an EEG epoch, and D \u2208 RT\u00d7S is a Toeplitz matrix whose first column is defined as:\nD\u03c4k,1 =\n\n\n\n1, \u03c4k is the onset of the kth target stimulus\n0, otherwise (1)\nand N \u2208 RC\u00d7T represents the ongoing background brain activity as well as the artifacts and noises. xDAWN then designs a spatial filtering matrix W\u2217 \u2208 RC\u00d7F , where F is the number of spatial filters, to maximize the signal to signal-plus-noise ratio, i.e.,\nW \u2217 = argmax\nW\nTr(WTPDTDPTW)\nTr(WTXXTW) (2)\nwhere Tr(\u00b7) is the trace of a matrix. (2) is a generalized Rayleigh quotient [14], and its solution W\u2217 is the concatenation of the F eigenvectors associated with the F largest eigenvalues of the matrix (XXT )\u22121PDTDPT . The spatially filtered trial for Xn is then computed as:\nX \u2032 n = W \u2217T Xn, n = 1, ..., N. (3)\n3) Canonical Correlation Analysis (CCA) [15], [41], which finds linear transformations to maximize the correlations\nbetween two datasets. It has been used to improve BCI performance in code-modulated visual evoked potentials [5], steady-state visual evoked potentials [6], and eventrelated potentials like P300 and error-related potentials [45]. Unlike ICA and xDAWN, CCA works on epoched EEG trials. Consider a binary classification problem, with N1 training examples in Class 1 and N2 training examples in Class 2. Let (Xn, yn) be the nth training example, where Xn \u2208 R\nC\u00d7S (C is the number of channels, and S is the number of time samples in each trial), and yn \u2208 {1, 2}. Let X\u0304k \u2208 RC\u00d7S be the average of Xn in Class k (k = 1, 2). We then construct X\u0303 = [X\u03031 X\u03032] and Z\u0303 = [Z\u03031 Z\u03032], where X\u0303k is the concatenation of all Nk Xn in Class k, and Z\u0303k is the concatenation of Nk X\u0304k. CCA first finds two vector filters w\nX\u0303 and w Z\u0303 such that the correlation\nbetween wT X\u0303 X\u0303 and wT Z\u0303 Z\u0303 is maximized. wT X\u0303 X and wT Z\u0303 Z\u0303 are called the first pair of canonical variables. CCA then finds the second pair of canonical variables in a similar way, subject to the constraint that they are uncorrelated with the first pair of canonical variables. This procedure can be continued up to C times. Finally, the spatial filtering matrix is the concatenation of all w\nX\u0303 , which can be applied to each Xn to increase\nits SNR. 4) Common Spatial Patterns (CSP) [7], [37], which is a su-\npervised technique frequently used to enhance the binary classification performance of EEG data. The basic idea is to separate the EEG signal into additive subcomponents which have maximum differences in variance between the two classes. In the following we introduce the one-versus-the-rest (OVR) CSP [11], which extends the traditional CSP from binary classification to K classes. Like CCA, OVR CSP also works on epoched EEG trials. Let (Xn, yn) be the nth training example, as defined above. Assume the mean of Xn has been removed, e.g., by high-pass or band-pass filtering. Then, for Class k, OVR CSP finds a spatial filter matrix W\u2217k \u2208 R\nC\u00d7F , where F is the number of spatial filters, to maximize the variance difference between Class k and the rest:\nW \u2217 k = argmax\nW\nTr(WT \u03a3\u0304kW)\nTr[WT ( \u2211 i6=k \u03a3\u0304i)W] (4)\nwhere \u03a3\u0304k is the mean covariance matrix of trials in Class k. (4) is also a generalized Rayleigh quotient [14], and the solution W\u2217k is the concatenation of the F eigenvectors associated with the F largest eigenvalues of the matrix ( \u2211\ni6=k \u03a3\u0304i) \u22121 \u03a3\u0304k. Finally, we concatenate the K individual OVR CSP spatial filters to obtain the complete filter:\nW \u2217 = [W\u2217 1 , ...W\u2217K ] \u2208 R C\u00d7KF (5)\nand compute the spatially filtered trial for Xn by (3)."}, {"heading": "III. SPATIAL FILTERS FOR SUPERVISED BCI REGRESSION PROBLEMS", "text": "In this section we propose two common spatial pattern for regression (CSPR) filters, which extend the multi-class CSP\n3 filters from classification to regression by making use of fuzzy sets [63], as we have done in [62].\nFirst, a brief introduction of fuzzy sets is given below."}, {"heading": "A. Fuzzy Sets", "text": "A fuzzy set A is comprised of a universe of discourse DA of real numbers together with a membership function \u00b5A : DA \u2192 [0, 1], i.e.,\nA =\n\u222b\nDA\n\u00b5A(x)/x (6)\nHere \u222b\ndenotes the collection of all points x \u2208 DA with associated membership degree \u00b5A(x). An example of a fuzzy set is shown in Fig. 1. The membership degrees are \u00b5A(1) = 0, \u00b5A(3) = 0.5, \u00b5A(5) = 1, \u00b5A(6) = 0.8, and \u00b5A(10) = 0. Observe that this is different from traditional (binary) sets, where each element can only belong to a set completely (i.e., with membership degree 1), or does not belong to it at all (i.e., with membership degree 0); there is nothing in between (i.e., with membership degree 0.5). Fuzzy sets are frequently used in modeling concepts in natural language [22], [36], [55], which may not have clear boundaries."}, {"heading": "B. CSPR-OVR", "text": "Let Xn \u2208 RC\u00d7S (n = 1, ..., N ) be the nth EEG trial, where C is the number of channels and S is the number of time samples in each trial. We assume that the mean of each channel measurement has been removed, which is usually performed by band-pass filtering. Let yn \u2208 {1, ...,K} be the RS of Xn.\nWith the help of fuzzy sets, we can define \u201cfuzzy\u201d classes to connect regression problems and classification problems. Assume K fuzzy classes are used. First, we partition the interval [0, 100] into K + 1 equal intervals, and denote the partition points as {pk}k=1,...,K . It is easy to obtain that\npk = 100 \u00b7 k\nK + 1 , k = 1, ...,K (7)\nFor each pk, we then find the corresponding pk percentile value of all training yn and denote it as Pk. Next we define K fuzzy classes from them, as shown in Fig. 2. In this way, we can \u201cclassify\u201d the training yn into K fuzzy classes, corresponding to the K crisp classes in the CSP for classification. However, note that in the CSP for classification a yn belongs to a crisp class either completely or not at all. For a fuzzy class here, a yn can belong to it at a membership degree in [0, 1].\nFig. 2. The K fuzzy classes for yn, when triangular fuzzy sets are used.\nNext, for each fuzzy class, we compute its mean EEG trial as:\nX\u0304k =\n\u2211N\nn=1 \u00b5k(yn)Xn \u2211N\nn=1 \u00b5k(yn) , k = 1, ...,K (8)\nwhere \u00b5k(yn) is the membership degree of yn in Fuzzy Class k. Substituting (8) into (4), we can solve for the spatial filtering matrix W\u2217k for Fuzzy Class k. Essentially, this W \u2217 k makes those Xn in Fuzzy Class k different from those not in Fuzzy Class k, which will help the regression performance, as we will demonstrate in Section V.\nNext, we construct the concatenated spatial filtering matrix W\n\u2217 by (5), and finally perform the spatial filtering for each EEG trial Xn by (3). The complete CSPR-OVR spatial filter for supervised BCI regression problems is summarized in Algorithm 1.\nAlgorithm 1: The CSPR-OVR spatial filter for supervised BCI regression problems.\nInput: EEG training examples (Xn, yn), where Xn \u2208 R\nC\u00d7S , n = 1, ..., N ; K , the number of fuzzy classes for yn; F , the number of spatial filters for each\nfuzzy class. Output: Spatially filtered EEG trials X\u2032n \u2208 R\nKF\u00d7S . Band-pass filter each Xn to remove the mean of each channel; Compute {pk}k=1,...,K in (7); Compute the corresponding percentile values {Pk}k=1,...,K for yn; Construct the K fuzzy classes as shown in Fig. 2; Compute X\u0304k by (8); Compute W\u2217k by (4); Construct W\u2217 by (5); Return X\u2032n by (3)"}, {"heading": "C. CSPR-OVA", "text": "In (4) we construct the multi-class CSP using an OVR approach, but it can also be constructed using the following one-versus-all (OVA) approach:\nW \u2217 k = argmax\nW\nTr(WT \u03a3\u0304kW)\nTr[WT ( \u2211K i=1 \u03a3\u0304i)W] (9)\n4 The only difference between (9) and (4) is that the numerator of (9) also includes the contribution from Class k itself. If we view Class k as the signal of interest, and all other classes as noises, then (9) maximizes the signal to signal-plus-noise ratio, as (2) in the xDAWN algorithm.\nEquation (9) is also a generalized Rayleigh quotient [14], and the solution W\u2217k is the concatenation of the F eigenvectors associated with the F largest eigenvalues of the matrix ( \u2211K\ni=1 \u03a3\u0304i) \u22121 \u03a3\u0304k. The OVA CSP for classification still uses (5) to construct the final spatial filter, and (3) to perform the filtering.\nUsing the technique introduced in the previous subsection, we can easily develop the CSPR-OVA spatial filter for BCI regression problems. Its procedure is almost identical to that in Algorithm 1. The only difference is that W\u2217k is computed by (9) instead of (4)."}, {"heading": "IV. EXPERIMENTS AND DATA", "text": "This section introduces a PVT experiment that was used to evaluate the performances of the proposed spatial filtering algorithms, the corresponding RS and EEG data preprocessing procedures, and the feature sets."}, {"heading": "A. Experiment Setup", "text": "17 university students (13 males; average age 22.4, standard deviation 1.6) from National Chiao Tung University (NCTU) in Taiwan volunteered to support the data-collection efforts over a 5-month period to study EEG correlates of attention and performance changes under specific conditions of realworld fatigue [21], as determined by the effectiveness score of Readiband [42]. The voluntary, fully informed consent of the persons used in this research was obtained as required by federal and Army regulations [50], [51]. The Institutional Review Board of NCTU approved the experimental protocol.\nAll participants registered their fatigue levels through a smartphone daily, and received notifications to report for experimental trials when the effectiveness score deemed their conditions fitted the experimental requirement (low fatigue: > 90; normal: [70, 90]; high fatigue: < 70). Upon completion of the related questionnaires [Karolinska Sleepiness Scale (KSS) [1], and electronically-adapted visual analog scale for fatigue (VAS-F) and stress (VAS-S)] and the informed consent form, subjects performed a PVT, a dynamic attention-shifting task, a lane-keeping task, and selected surveys (KSS, VASF, VAS-S, state-trait anxiety inventory, and mind-wandering) preceding each condition. EEG data were recorded at 1000 Hz using a 64-channel NeuroScan system. Most participants performed the laboratory experiment thrice in each of the three fatigue states.\nIn this paper we focus on the PVT [10], which is a sustained-attention task that uses RS to measure the speed with which a subject responds to a visual stimulus. It is widely used, particularly by NASA, for its ease of scoring, simple metrics, convergent validity, and free of learning effects. In our experiment, the PVT was presented on a smartphone with each trial initiated as an empty solid white circle centered on the touchscreen that began to fill in red displayed as a\nclockwise sweeping motion like the hand of a clock. The sweeping motion was programmed to turn solid red in one second or terminate upon a response by the participants, which required them to tap the touchscreen with the thumb of their dominant hand. The RS was computed as the inverse of the elapsed time between the appearance of the empty solid white circle and the participant\u2019s response. Following completion of each trial, the circle went back to solid white until the next trial. Inter-trial intervals consisted of random intervals between 2-10 seconds.\n143 sessions of PVT data were collected from the 17 subjects, and each session lasted 10 minutes. Our goal is to predict the RS using a 3-second EEG trial immediately before it."}, {"heading": "B. Performance Evaluation Process", "text": "The following procedure was performed to evaluate the performances of different spatial filters:\n1) EEG data preprocessing to suppress artifacts and noises. 2) RS data preprocessing to suppress outliers. 3) 5-fold cross-validation to compute the regression per-\nformance for each combination of spatial filters and regression method: first randomly partition the trials into five equal folds; then, use four folds for supervised spatial filtering and regression model training, and the remaining fold for testing; repeat this five times so that every fold is used in testing; finally compute the regression performances in terms of root mean square error (RMSE) and correlation coefficient (CC). Two regression methods were used: LASSO, whose adjustable parameter \u03bb was optimized by an inner 5-fold cross-validation on the training dataset, and k-nearest neighbors (kNN) regression, where k = 5. 4) Repeat Step 3 10 times and compute the average regression performance.\nMore details about the first two steps are given in the next two subsections."}, {"heading": "C. EEG Data Preprocessing", "text": "We first downsampled the EEG data to 256 Hz, then epoched them to 3-second trials according to the onset of the PVTs. Let the onset time of the nth PVT be tn. Then, the 62- channel EEG trial in [tn \u2212 3, tn] seconds was used to predict the RS, i.e., Xn \u2208 R62\u00d7768. Each trial was then individually filtered by a [1, 20] Hz finite impulse response band-pass filter to make each channel zero-mean and to remove un-useful high frequency components.\nBecause the inter-trial intervals consisted of random intervals between 2-10 seconds, it\u2019s possible that a 3-second EEG trial covers part of data from the previous trial. Additionally, a trial may also contain the EEG oscillations related to motor reaction (tapping the touchscreen) in the previous trial. To remedy these problems, we removed overlapping trials: let the RS of the nth trial be yn (the corresponding response time is 1/yn); then, the nth trial is removed if tn\u2212tn\u22121 < 1/yn\u22121+3, i.e., when the 3-second EEG data for Trial n overlap with the data and response for the previous trial."}, {"heading": "D. RS Data Preprocessing", "text": "The raw response times for two subjects are shown in Fig. 3. The top panel is from a typical subject, whose response times were mostly shorter than 1 second. The lower panel is from a subject with possible data recording issues, because lots of response times were longer than 5 seconds, which are highly unlikely in practice. So we excluded that subject from consideration in this paper, and only used the remaining 16 subjects.\nAs shown in Fig. 3, the response times were very noisy, and there were obvious outliers. It is very important to suppress the outliers and noises so that the performances of different algorithms can be more accurately compared. In addition to the step in the previous subsection to remove overlapping trials, we also employed the following 2-step procedure for response time preprocessing:\n1) Outlier thresholding, which aimed to suppress abnormally large response times. First, a threshold \u03b8 = my +3\u03c3y was computed for each subject, where my is the mean response time from all sessions of that subject, and \u03c3y is the corresponding standard deviation. Then, all response times larger than \u03b8 were replaced by \u03b8. Note that the threshold was different for different subjects. 2) Moving average smoothing, which replaced each response time by the average response time during a 60 seconds moving window centered at the onset of the corresponding PVT to suppress noises.\nWe then computed the RS as the inverse of the RT. The RSs for the 16 subjects are shown in Fig. 4. Observe that they are roughly in the same range, and many of them are approximately Gaussian."}, {"heading": "E. Feature Extraction", "text": "We extracted the following four feature sets for each preprocessed EEG trial:\n\u2022 Raw: Theta and Alpha powerband features from the bandpass filtered EEG trials. We computed the average power spectral density (PSD) in the Theta band (4-8 Hz) and Alpha band (8-13 Hz) for each channel using Welch\u2019s\nmethod [57], and converted these 62 \u00d7 2 = 124 band powers to dBs as our features. \u2022 CAR: Theta and Alpha powerband features from EEG trials filtered by CAR. This procedure was almost identical to Raw, except that the band-pass filtered EEG trials were also spatially filtered by CAR before the 62\u00d7 2 = 124 powerband features were computed. CAR is one of the most commonly used spatial filters for EEG, and [31] showed that it helped improve EEG classification performance. It simply removes the mean of all channels from each channel. \u2022 OVR: Theta and Alpha powerband features from EEG trials filtered by CSPR-OVR. This procedure was almost identical to CAR, except that the CAR filter was replaced by CSPR-OVR. We used 3 fuzzy classes for the RSs, and 21 spatial filters1 for each fuzzy class, so that the spatially filtered signals had dimensionality 63 \u00d7 1280, roughly the same as the dimensionality of the original signals. We then extracted 63 \u00d7 2 = 126 band power features for each trial. \u2022 OVA: Theta and Alpha powerband features from EEG trials filtered by CSPR-OVA. This procedure was also almost identical to CAR, except that the spatial filtering was performed by CSPR-OVA instead of CAR. There were also 63 \u00d7 2 = 126 band power features for each trial."}, {"heading": "V. EXPERIMENTAL RESULTS", "text": "This section compares the informativeness of the features in Raw, CAR, OVR and OVA, presents the regression performances, and also performs parameter sensitivity analysis for Algorithm 1.\n1We used 21 spatial filters here so that the filtered signals had roughly the same dimensionality as the original signals, which ensured fair performance comparison. In Section V-C we also performed sensitivity analysis on the number of spatial filters.\n6 A. Informativeness of the Features\nBefore studying the regression performances, it is important to check if the extracted features in Raw, CAR, OVR and OVA are indeed meaningful. We picked a typical subject, partitioned his data random into 50% training and 50% testing, and extracted Raw and CAR. We then designed the spatial filters using CSPR-OVR and CSPR-OVA on the training data, and extracted the corresponding OVR and OVA. For each feature set, we identified the top three channels that had the maximum correlation with the RS using the training data, and also computed the corresponding correlation coefficients for the testing data.\nThe results are shown in Fig. 5, where in each subfigure the data on the left of the black dotted line were used for training, and the right for testing. The top thick curve is the RS, and the bottom three curves are the maximally correlated features (note that good features are negatively correlated with the RS) identified from the training data. The training and testing correlation coefficients are shown on the left and right of the corresponding channel, respectively. Observe that the features from CAR had slightly better correlations with the RS in training than those from Raw, but not necessarily in testing. However, the features from OVR and OVA had much higher training and testing correlations to the RS than those from Raw and CAR, suggesting that CSPR-OVR and CSPR-OVA can indeed increase the signal quality. The reason is: if we view Class k as the signal of interest, and all other classes as noises, then CSPR-OVR in (4) enhances the signal to noise ratio of the EEG signal, and CSPR-OVA in (9) enhances the signal to signal-plus-noise ratio."}, {"heading": "B. Regression Performance Comparison", "text": "The RMSEs and CCs of LASSO and kNN using the four feature sets are shown in Fig. 6 for the 16 subjects. Recall that for each subject the feature extraction methods were run 10 times, each with randomly partitioned training and testing data, and the average regression performances are shown here. The average RMSEs and CCs across all subjects are also shown in\nthe last group of each panel. Observe that CAR had comparable or slightly better performance than Raw. Regardless of which regression algorithm was used, generally OVR and OVA had similar performance, and both of them achieved much smaller RMSEs and much larger CCs than Raw and CAR, suggesting that our extension of CSP from supervised classification to supervised regression can indeed improve the regression performance. Finally, LASSO had better performance than kNN on Raw and CAR, but kNN became better on OVR and OVA.\nThe corresponding percentage performance improvements of LASSO and kNN using the four feature sets are shown in Fig. 7, where the legend \u201cLASSO,OVR/Raw\u201d means the percentage performance improvement of LASSO on OVR over LASSO on Raw, and other legends should be interpreted in a similar manner. For both LASSO and kNN, OVR and OVA achieved similar performance improvements over Raw, and also over CAR. For LASSO, on average OVR had 10.02% smaller RMSE than Raw, and 19.39% larger CC. For kNN, on average OVR had 19.77% smaller RMSE than Raw, and 86.47% larger CC.\nWe also performed a two-way Analysis of Variance (ANOVA) for different regression algorithms to check if the RMSE and CC differences among the four feature sets were statistically significant, by setting the subjects as a random effect. The results are shown in Table I, which indicated that there were statistically significant differences in both RMSEs and CCs among different feature sets for both LASSO and kNN.\nThen, non-parametric multiple comparison tests based on Dunn\u2019s procedure [12], [13] were used to determine if the difference between any pair of algorithms was statistically significant, with a p-value correction using the False Discovery Rate method [3]. The p-values are shown in Table II, where the statistically significant ones are marked in bold. Table II shows that, except for the CC of kNN, generally there was no statistically significant difference between Raw and CAR. However, for both LASSO and kNN, the RMSE and CC differences between {OVR, OVA} and {Raw, CAR} were always statistically significant. In all cases, there were no statistically significant differences between OVR and OVA."}, {"heading": "C. Parameter Sensitivity Analysis", "text": "There are two adjustable parameters in CSPR-OVR: K , the number of fuzzy classes for the RSs, and F , the number of spatial filters for each fuzzy class. In this subsection we study the sensitivity of the regression performance to these two parameters.\nThe regression performances for K = {2, 3, 4, 5, 6, 7} (F was fixed to be 21) are shown in Fig. 8. Algorithm 1 was repeated five times, each with a random partition of training and testing data, and the average regression results are shown. For both LASSO and kNN, on average K = 2 gave worst performance, but K = {3, 4, 5, 6, 7} resulted in roughly the same RMSE and CC. Hence, K = 3 seems to be a good compromise between performance and computational cost.\nThe regression performances for F =\n{5, 10, 20, 30, 40, 50, 60} (K was fixed to be 3) are shown in Fig. 9. Algorithm 1 was again repeated five times, and the average regression results are shown. For both LASSO and kNN, generally a larger F resulted in a smaller RMSE and a larger CC, but the performance may reach a plateau at a certain F . Also, a larger F means heavier computational cost, which should be taken into consideration in choosing F . For the PVT experiment, F \u2208 [20, 30] seemed to achieve a good compromise between performance and computational cost."}, {"heading": "D. Different Fuzzy Set Shapes", "text": "In Section III we used triangular fuzzy sets for simplicity, but other shapes can also be used. Fig. 10 illustrates how Gaussian fuzzy sets can be designed here: the center of the kth Gaussian fuzzy class is at Pk [computed from (7)], and\n8 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 Avg Subject 0 0.2 0.4 0.6 R M SE RMSE of LASSO w.r.t. K, the number of fuzzy classes K=2 K=3 K=4 K=5 K=6 K=7\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 Avg Subject\n0\n0.2\n0.4\n0.6\nR M\nSE\nRMSE of kNN w.r.t. K, the number of fuzzy classes\nK=2 K=3 K=4 K=5 K=6 K=7\n(a)\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 Avg Subject\n0.4\n0.6\n0.8\nC C\nCC of LASSO w.r.t. K, the number of fuzzy classes\nK=2 K=3 K=4 K=5 K=6 K=7\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 Avg Subject\n0.4\n0.6\n0.8\nC C\nCC of kNN w.r.t. K, the number of fuzzy classes\nK=2 K=3 K=4 K=5 K=6 K=7\n(b)\nthe spread is specially designed so that two adjacent fuzzy sets intersect at the midpoint with membership grade 0.5. As a result, generally the Gaussian fuzzy classes are not symmetric.\nWhen the Gaussian fuzzy classes in Fig. 10 are used in CSPR-OVR and CSPR-OVA, the results are shown in Fig. 11, which are almost identical to those obtained from triangular fuzzy sets (Fig. 6)."}, {"heading": "E. Robustness to Noise", "text": "It is also important to study the robustness of different spatial filters to noises. According to [64], there are two types of noises: class noise, which is the noise on the model outputs, and attribute noise, which is the noise on the model inputs. In this subsection we focus on the attribute noise.\nAs in [64], for each model input, we randomly replaced q% (q = 0, 10, ..., 40) of all trials from a subject with a uniform noise between its minimum and maximum values. After this was done for both the training and testing data, we extracted feature sets Raw, CAR, OVR and OVA, and trained LASSO and kNN, on the corrupted training data. We then tested their performances on the corrupted testing data. The results are shown in Fig. 12. Generally, as the noise level increased, the performances decreased, which is intuitive. However, OVR and OVA achieved better RMSEs and CCs than Raw and CAR at almost all noise levels, suggesting that it is still beneficial to use CSPR-OVR and CSPR-OVA even under high attribute noise."}, {"heading": "F. Computational cost", "text": "Observe from Algorithm 1 that in training CSPROVR needs to perform a matrix inversion and an eigendecomposition to compute W\u2217; however, once the training\n9 0 10 20 30 40 0.26 0.28 0.3 0.32 0.34 0.36 0.38 R M SE 0 10 20 30 40 0.3 0.4 0.5 0.6 0.7 C C LASSO, Raw LASSO, CAR LASSO, OVR LASSO, OVA kNN, Raw kNN, CAR kNN, OVR kNN, OVA\nFig. 12. Average RMSEs and CCs of the eight approaches wrt different attribute noise levels.\nis done, the filtering of new EEG trials can be conducted very efficiently by a simple matrix multiplication [see (3)]. Let N be the number of training samples. Then, the actual training time of CSPR-OVR and CSPR-OVA increased linearly with N , as shown in Fig. 13. The platform was a Dell XPS15 laptop (Intel i7-6700HQ CPU @2.60GHz, 16 GB memory) running Windows 10 Pro 64-bit and Matlab 2016b. A least squares curve fit shows that the training time is 0.2216 + 0.0003N seconds, which should not be a problem for a practical N ."}, {"heading": "VI. DISCUSSIONS AND FUTURE RESEARCH", "text": "Recall that 5-fold cross-validation was used in the performance evaluation in the previous section, i.e., we concatenated the nine-session data from the same subject, randomly partitioned them into five equal-length folds, and then used four folds for training and the remaining one for testing. So, the training and testing folds contained data from the same sessions. This is equivalent to the case that we label some session-specific data in offline regression. Our results showed that in this case CSPR-OVR and CSPR-OVA can significantly improve the regression performance.\nTo avoid the use of session-specific data, we also investigated a different validation method: leave-one-session-out validation, in which for each subject we trained the spatial filters using eight sessions and tested them on the remaining session. Interestingly, all four feature sets and both regression models achieved very poor performance here. The reasons are: 1) we need a proper way to normalize the RSs from different sessions, as done for the response times in [16]; and, 2) there is large intra-subject variation, meaning that the EEG responses for the same subject vary at different times (recall that these nine sessions were collected at different days); so, the patterns learned from previous sessions become obsolete for the\nnew session, and hence spatial filtering alone does not help. However, our previous research [58], [61], [62] has shown that transfer learning can cope well with the inter-subject variation (individual differences) in both classification and regression problems, and we conjecture that it can also handle the intrasubject variation. One of our future research directions is to demonstrate the performance of CSPR-OVR and CSPR-OVA in a transfer learning framework to individualize a generalized model for regression problems, as done in [18], [46] for EEGbased cognitive performance classification.\nAnother direction of our future research will apply CSPROVR and CSPR-OVA to other important EEG-based regression problems, e.g., drowsiness (or alertness) estimation during driving, and integrate it with more sophisticated feature extraction approaches, e.g., Riemannian geometry [8], for better regression performance."}, {"heading": "VII. CONCLUSIONS", "text": "EEG signals are easily contaminated by artifacts and noises, so preprocessing is needed before they are fed into a machine learning algorithm in BCI. Spatial filters, e.g., ICA, xDAWN, CSP and CCA, have been widely used to increase the EEG signal quality for classification problems, but their applications in BCI regression problems have been very limited. In this paper, we have proposed two CSP filters for EEG-based regression problems in BCI, which were extended from the CSP filter for classification, by making use of fuzzy sets. Extensive experimental results on EEG-based RS estimation from a large-scale study, which collected 143 sessions of PVT data from 17 subjects during a 5-month period, demonstrated that our proposed spatial filters can significantly increase the EEG signal quality. When used in LASSO and kNN, the spatial filters can reduce the estimation RMSE by 10.02 \u2212 19.77%, and at the same time increase the CC by 19.39\u2212 86.47%."}, {"heading": "ACKNOWLEDGEMENT", "text": "Research was sponsored by the U.S. Army Research Laboratory and was accomplished under Cooperative Agreement Numbers W911NF-10-2-0022 and W911NF-10-D-0002/TO 0023. The views and the conclusions contained in this document are those of the authors and should not be interpreted as representing the official policies, either expressed or implied, of the U.S. Army Research Laboratory or the U.S. Government. This work was also partially supported by the Australian Research Council (ARC) under discovery grant DP150101645."}], "references": [{"title": "Subjective and objective sleepiness in the active individual", "author": ["T. Akerstedt", "M. Gillberg"], "venue": "International Journal of Neuroscience, vol. 52, no. 1-2, pp. 29\u201337, 1990.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 1990}, {"title": "MEG decoding using Riemannian geometry and unsupervised classification. Accessed: 8/17/2016", "author": ["A. Barachant"], "venue": null, "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2014}, {"title": "Controlling the false discovery rate: A practical and powerful approach to multiple testing", "author": ["Y. Benjamini", "Y. Hochberg"], "venue": "Journal of the Royal Statistical Society, Series B (Methodological), vol. 57, pp. 289\u2013 300, 1995.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 1995}, {"title": "The PREP pipeline: standardized preprocessing for large-scale EEG analysis", "author": ["N. Bigdely-Shamlo", "T. Mullen", "C. Kothe", "K.-M. Su", "K.A. Robbins"], "venue": "Frontiers in Neuroinformatics, vol. 9, 2015.  10", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2015}, {"title": "A high-speed BCI based on code modulation VEP", "author": ["G. Bin", "X. Gao", "Y. Wang", "Y. Li", "B. Hong", "S. Gao"], "venue": "Journal of neural engineering, vol. 8, no. 2, 2011.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2011}, {"title": "An online multi-channel SSVEP-based brain-computer interface using a canonical correlation analysis method", "author": ["G. Bin", "X. Gao", "Z. Yan", "B. Hong", "S. Gao"], "venue": "Journal of neural engineering, vol. 6, no. 4, 2009.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2009}, {"title": "Optimizing spatial filters for robust EEG single-trial analysis", "author": ["B. Blankertz", "R. Tomioka", "S. Lemm", "M. Kawanabe", "K.R. Muller"], "venue": "IEEE Signal Processing Magazine, vol. 25, no. 1, pp. 41\u201356, 2008.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2008}, {"title": "A new generation of braincomputer interface based on Riemannian geometry", "author": ["M. Congedo", "A. Barachant", "A. Andreev"], "venue": "arXiv: 1310.8115, 2013.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2013}, {"title": "EEGLAB: an open source toolbox for analysis of single-trial EEG dynamics including independent component analysis", "author": ["A. Delorme", "S. Makeig"], "venue": "Journal of Neuroscience Methods, vol. 134, pp. 9\u201321, 2004.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2004}, {"title": "Microcomputer analyses of performance on a portable, simple visual RT task during sustained operations", "author": ["D.F. Dinges", "J.W. Powell"], "venue": "Behavior research methods, instruments, & computers, vol. 17, no. 6, pp. 652\u2013655, 1985.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 1985}, {"title": "Boosting bit rates in non-invasive EEG single-trial classifications by feature combination and multi-class paradigms", "author": ["G. Dornhege", "G.C.B. Blankertz", "K.-R. Muller"], "venue": "IEEE Trans. on Biomedical Engineering, vol. 51, no. 6, pp. 993\u20131002, 2004.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2004}, {"title": "Multiple comparisons among means", "author": ["O. Dunn"], "venue": "Journal of the American Statistical Association, vol. 56, pp. 62\u201364, 1961.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 1961}, {"title": "Multiple comparisons using rank sums", "author": ["\u2014\u2014"], "venue": "Technometrics, vol. 6, pp. 214\u2013252, 1964.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 1964}, {"title": "Matrix Computation, 3rd ed", "author": ["G.H. Golub", "C.F.V. Loan"], "venue": null, "citeRegEx": "14", "shortCiteRegEx": "14", "year": 1996}, {"title": "Relations between two sets of variates", "author": ["H. Hotelling"], "venue": "Biometrika, vol. 28, no. 3/4, pp. 321\u2013377, 1936.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 1936}, {"title": "Investigating the correlation between the neural activity and task performance in a psychomotor vigilance test", "author": ["Z. Hu", "Y. Sun", "J. Lim", "N. Thakor", "A. Bezerianos"], "venue": "Proc. 37th Annual Int\u2019l Conf. of the IEEE Engineering in Medicine and Biology Society (EMBC), Milan, Italy, August 2015, pp. 4725\u20134728.", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2015}, {"title": "Independent component analysis: algorithms and applications", "author": ["A. Hyvarinen", "E. Oja"], "venue": "Neural networks, vol. 13, no. 4, pp. 411\u2013430, 2000.", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2000}, {"title": "Drowsiness/alertness algorithm development and validation using synchronized EEG and cognitive performance to individualize a generalized model", "author": ["R.R. Johnson", "D.P. Popovic", "R.E.O. andMaja Stikic", "D.J. Levendowski", "C. Berka"], "venue": "Biological Psychology, vol. 87, p. 241250, 2011.", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2011}, {"title": "Principal component analysis", "author": ["I. Jolliffe"], "venue": "Wiley Online Library,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2002}, {"title": "Removing electroencephalographic artifacts by blind source separation", "author": ["T.-P. Jung", "S. Makeig", "C. Humphries", "T.-W. Lee", "M.J. Mckeown", "V. Iragui", "T.J. Sejnowski"], "venue": "Psychophysiology, vol. 37, no. 2, pp. 163\u2013178, 2000.", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2000}, {"title": "Inter- and intra-individual variations in sleep, subjective fatigue, and vigilance task performance of students in their real-world environments over extended periods", "author": ["S. Kerick", "C.-H. Chuang", "J.-T. King", "T.-P. Jung", "J. Brooks", "B.T. Files", "K. McDowell", "C.-T. Lin"], "venue": "2016, submitted.", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2016}, {"title": "Fuzzy Sets and Fuzzy Logic: Theory and Applications", "author": ["G.J. Klir", "B. Yuan"], "venue": "Upper Saddle River, NJ: Prentice-Hall,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 1995}, {"title": "Spatial filtering of multichannel electroencephalographic recordings through principal component analysis by singular value decomposition", "author": ["T.D. Lagerlund", "F.W. Sharbrough", "N.E. Busacker"], "venue": "Journal of Clinical Neurophysiology, vol. 14, no. 1, pp. 73\u201382, 1997.", "citeRegEx": "23", "shortCiteRegEx": null, "year": 1997}, {"title": "Brain-computer interface technologies in the coming decades", "author": ["B.J. Lance", "S.E. Kerick", "A.J. Ries", "K.S. Oie", "K. McDowell"], "venue": "Proc. of the IEEE, vol. 100, no. 3, pp. 1585\u20131599, 2012.", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2012}, {"title": "Biosensor technologies for augmented brain-computer interfaces in the next decades", "author": ["L.-D. Liao", "C.-T. Lin", "K. McDowell", "A. Wickenden", "K. Gramann", "T.-P. Jung", "L.-W. Ko", "J.-Y. Chang"], "venue": "Proc. of the IEEE, vol. 100, no. 2, pp. 1553\u20131566, 2012.", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2012}, {"title": "EEG-based drowsiness estimation for safety driving using independent component analysis", "author": ["C.T. Lin", "R.C. Wu", "S.F. Liang", "T.Y. Huang", "W.H. Chao", "Y.J. Chen", "T.P. Jung"], "venue": "IEEE Trans. on Circuits and Systems, vol. 52, pp. 2726\u20132738, 2005.", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2005}, {"title": "Development of wireless brain computer interface with embedded multitask scheduling and its application on real-time driver\u2019s drowsiness detection and warning", "author": ["C.-T. Lin", "Y.-C. Chen", "T.-Y. Huang", "T.-T. Chiu", "L.-W. Ko", "S.-F. Liang", "H.-Y. Hsieh", "S.-H. Hsu", "J.-R. Duann"], "venue": "IEEE Trans. on Biomedical Engineering, vol. 55, no. 5, pp. 1582\u20131591, 2008.", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2008}, {"title": "Adaptive EEG-based alertness estimation system by using ICA-based fuzzy neural networks", "author": ["C.-T. Lin", "L.-W. Ko", "I.-F. Chung", "T.-Y. Huang", "Y.-C. Chen", "T.-P. Jung", "S.-F. Liang"], "venue": "IEEE Trans. on Circuits and Systems-I, vol. 53, no. 11, pp. 2469\u20132476, 2006.", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2006}, {"title": "Evolving signal processing for brain-computer interfaces", "author": ["S. Makeig", "C. Kothe", "T. Mullen", "N. Bigdely-Shamlo", "Z. Zhang", "K. Kreutz-Delgado"], "venue": "Proc. of the IEEE, vol. 100, no. Special Centennial Issue, pp. 1567\u20131584, 2012.", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2012}, {"title": "The Utah intracortical electrode array: a recording structure for potential braincomputer interfaces", "author": ["E.M. Maynard", "C.T. Nordhausen", "R.A. Normann"], "venue": "Electroencephalography and clinical neurophysiology, vol. 102, no. 3, pp. 228\u2013239, 1997.", "citeRegEx": "30", "shortCiteRegEx": null, "year": 1997}, {"title": "Spatial filter selection for EEG-based communication", "author": ["D.J. McFarland", "L.M. McCane", "S.V. David", "J.R. Wolpaw"], "venue": "Electroencephalography and clinical Neurophysiology, vol. 103, pp. 386\u2013394, 1997.", "citeRegEx": "31", "shortCiteRegEx": null, "year": 1997}, {"title": "An MEG-based brain-computer interface (BCI)", "author": ["J. Mellinger", "G. Schalk", "C. Braun", "H. Preissl", "W. Rosenstiel", "N. Birbaumer", "A. Kubler"], "venue": "Neuroimage, vol. 36, no. 3, pp. 581\u2013593, 2007.", "citeRegEx": "32", "shortCiteRegEx": null, "year": 2007}, {"title": "fNIRS-based brain-computer interfaces: a review", "author": ["N. Naseer", "K.-S. Hong"], "venue": "Frontiers in human neuroscience, vol. 9, p. 3, 2015.", "citeRegEx": "33", "shortCiteRegEx": null, "year": 2015}, {"title": "Brain computer interfaces, a review", "author": ["L.F. Nicolas-Alonso", "J. Gomez-Gil"], "venue": "Sensors, vol. 12, no. 2, pp. 1211\u20131279, 2012.", "citeRegEx": "34", "shortCiteRegEx": null, "year": 2012}, {"title": "Decoding vowels and consonants in spoken and imagined words using electrocorticographic signals in humans", "author": ["X. Pei", "D.L. Barbour", "E.C. Leuthardt", "G. Schalk"], "venue": "Journal of neural engineering, vol. 8, no. 4, 2011.", "citeRegEx": "35", "shortCiteRegEx": null, "year": 2011}, {"title": "Fuzzy-set social science", "author": ["C.C. Ragin"], "venue": null, "citeRegEx": "36", "shortCiteRegEx": "36", "year": 2000}, {"title": "Optimal spatial filtering of single trial EEG during imagined hand movement", "author": ["H. Ramoser", "J. Muller-Gerking", "G. Pfurtscheller"], "venue": "IEEE Trans. on Rehabilitation Engineering, vol. 8, no. 4, pp. 441\u2013446, 2000.", "citeRegEx": "37", "shortCiteRegEx": null, "year": 2000}, {"title": "xDAWN algorithm to enhance evoked potentials: application to brain-computer interface", "author": ["B. Rivet", "A. Souloumiac", "V. Attina", "G. Gibert"], "venue": "IEEE Trans. on Biomedical Engineering, vol. 56, no. 8, pp. 2035\u20132043, 2009.", "citeRegEx": "38", "shortCiteRegEx": null, "year": 2009}, {"title": "Theoretical analysis of xDAWN algorithm: application to an efficient sensor selection in a P300 BCI", "author": ["B. Rivet", "H. Cecotti", "A. Souloumiac", "E. Maby", "J. Mattout"], "venue": "Proc. 19th European Signal Processing Conference, Barcelona, Spain, August 2011, pp. 1382\u20131386.", "citeRegEx": "39", "shortCiteRegEx": null, "year": 2011}, {"title": "Optimal linear spatial filters for eventrelated potentials based on a spatio-temporal model: Asymptotical performance analysis", "author": ["B. Rivet", "A. Souloumiac"], "venue": "Signal Processing, vol. 93, no. 2, pp. 387\u2013398, 2013.", "citeRegEx": "40", "shortCiteRegEx": null, "year": 2013}, {"title": "A comparison of ERP spatial filtering methods for optimal mental workload estimation", "author": ["R.N. Roy", "S. Bonnet", "S. Charbonnier", "P. Jallon", "A. Campagne"], "venue": "Proc. 37th Annual Int\u2019l Conf. of the IEEE Engineering in Medicine and Biology Society (EMBC), 2015, pp. 7254\u2013 7257.", "citeRegEx": "41", "shortCiteRegEx": null, "year": 2015}, {"title": "Validation of the fatigue science readiband actigraph and associated sleep/wake classification algorithms. Accessed: 08/11/2016", "author": ["C. Russell", "J. Caldwell", "D. Arand", "L. Myers", "P. Wubbels", "H. Downs"], "venue": null, "citeRegEx": "42", "shortCiteRegEx": "42", "year": 2015}, {"title": "Fatigue, sleepiness and reduced alertness as risk factors in driving", "author": ["F. Sagberg", "P. Jackson", "H.-P. Kruger", "A. Muzer", "A. Williams"], "venue": "Institute of Transport Economics, Oslo, Tech. Rep. TOI Report 739/2004, 2004.", "citeRegEx": "43", "shortCiteRegEx": null, "year": 2004}, {"title": "fMRI brain-computer interface: a tool for neuroscientific research and treatment", "author": ["R. Sitaram", "A. Caria", "R. Veit", "T. Gaber", "G. Rota", "A. Kuebler", "N. Birbaumer"], "venue": "Computational intelligence and neuroscience, 2007.", "citeRegEx": "44", "shortCiteRegEx": null, "year": 2007}, {"title": "Spatial filtering based on canonical correlation analysis for classification of evoked or event-related potentials in EEG data", "author": ["M. Spuler", "A. Walter", "W. Rosenstiel", "M. Bogdan"], "venue": "IEEE Trans. on Neural Systems and Rehabilitation Engineering, vol. 22, no. 6, pp. 1097\u20131103, 2014.", "citeRegEx": "45", "shortCiteRegEx": null, "year": 2014}, {"title": "EEG-derived estimators of present and future cognitive performance", "author": ["M. Stikic", "R.R. Johnson", "D.J. Levendowski", "D.P. Popovic", "R.E. Olmstead", "C. Berka"], "venue": "Frontiers in Human Neuroscience, vol. 5, 2011.", "citeRegEx": "46", "shortCiteRegEx": null, "year": 2011}, {"title": "Fundamentals of EEG measurement", "author": ["M. Teplan"], "venue": "Measurement Science Review, vol. 2, no. 2, pp. 1\u201311, 2002.", "citeRegEx": "48", "shortCiteRegEx": null, "year": 2002}, {"title": "EEG artifact removal \u2013 state-ofthe-art and guidelines", "author": ["J.A. Uriguen", "B. Garcia-Zapirain"], "venue": "Journal of Neural Engineering, vol. 12, no. 3, 2015.  11", "citeRegEx": "49", "shortCiteRegEx": null, "year": 2015}, {"title": "Code of federal regulations protection of human subjects", "author": ["US Department of Defense Office of the Secretary of Defense"], "venue": "Government Printing Office, no. 32 CFR 19, 1999.", "citeRegEx": "50", "shortCiteRegEx": null, "year": 1999}, {"title": "Use of volunteers as subjects of research", "author": ["US Department of the Army"], "venue": "Government Printing Office, no. AR 70-25, 1990.", "citeRegEx": "51", "shortCiteRegEx": null, "year": 1990}, {"title": "Brain-computer interfaces: Beyond medical applications", "author": ["J. van Erp", "F. Lotte", "M. Tangermann"], "venue": "Computer, vol. 45, no. 4, pp. 26\u201334, 2012.", "citeRegEx": "53", "shortCiteRegEx": null, "year": 2012}, {"title": "Independent component approach to the analysis of EEG and MEG recordings", "author": ["R. Vigario", "J. Sarela", "V. Jousmiki", "M. Hamalainen", "E. Oja"], "venue": "IEEE Trans. on Biomedical Engineering, vol. 47, no. 5, pp. 589\u2013593, 2000.", "citeRegEx": "54", "shortCiteRegEx": null, "year": 2000}, {"title": "A Course in Fuzzy Systems and Control", "author": ["L.-X. Wang"], "venue": "Upper Saddle River, NJ: Prentice Hall,", "citeRegEx": "55", "shortCiteRegEx": "55", "year": 1997}, {"title": "Selective transfer learning for EEG-based drowsiness detection", "author": ["C.-S. Wei", "Y.-P. Lin", "Y.-T. Wang", "T.-P. Jung", "N. Bigdely-Shamlo", "C.- T. Lin"], "venue": "Proc. IEEE Int\u2019l Conf. on Systems, Man and Cybernetics, Hong Kong, October 2015.", "citeRegEx": "56", "shortCiteRegEx": null, "year": 2015}, {"title": "The use of fast Fourier transform for the estimation of power spectra: A method based on time averaging over short, modified periodograms", "author": ["P. Welch"], "venue": "IEEE Trans. on Audio Electroacoustics, vol. 15, pp. 70\u2013  73, 1967.", "citeRegEx": "57", "shortCiteRegEx": null, "year": 1967}, {"title": "Online and offline domain adaptation for reducing BCI calibration effort", "author": ["D. Wu"], "venue": "IEEE Trans. on Human-Machine Systems, 2016, in press.", "citeRegEx": "58", "shortCiteRegEx": null, "year": 2016}, {"title": "Online driver\u2019s drowsiness estimation using domain adaptation with model fusion", "author": ["D. Wu", "C.-H. Chuang", "C.-T. Lin"], "venue": "Proc. Int\u2019l Conf. on Affective Computing and Intelligent Interaction, Xi\u2019an, China, September 2015, pp. 904\u2013910.", "citeRegEx": "59", "shortCiteRegEx": null, "year": 2015}, {"title": "Offline EEG-based driver drowsiness estimation using enhanced batch-mode active learning (EBMAL) for regression", "author": ["D. Wu", "V.J. Lawhern", "S. Gordon", "B.J. Lance", "C.-T. Lin"], "venue": "Proc. IEEE Int\u2019l Conf. on Systems, Man and Cybernetics, Budapest, Hungary, October 2016.", "citeRegEx": "60", "shortCiteRegEx": null, "year": 2016}, {"title": "Spectral meta-learner for regression (SMLR) model aggregation: Towards calibrationless brain-computer interface (BCI)", "author": ["D. Wu", "V.J. Lawhern", "S. Gordon", "B.J. Lance", "C.-T. Lin"], "venue": "Proc. IEEE Int\u2019l Conf. on Systems, Man and Cybernetics, Budapest, Hungary, October 2016.", "citeRegEx": "61", "shortCiteRegEx": null, "year": 2016}, {"title": "Driver drowsiness estimation from EEG signals using online weighted adaptation regularization for regression (OwARR)", "author": ["D. Wu", "V.J. Lawhern", "S. Gordon", "B.J. Lance", "C.-T. Lin"], "venue": "IEEE Trans. on Fuzzy Systems, 2016, in press.", "citeRegEx": "62", "shortCiteRegEx": null, "year": 2016}, {"title": "Fuzzy sets", "author": ["L.A. Zadeh"], "venue": "Information and Control, vol. 8, pp. 338\u2013353, 1965.", "citeRegEx": "63", "shortCiteRegEx": null, "year": 1965}], "referenceMentions": [{"referenceID": 23, "context": "Electroencephalogram (EEG) signals are the most widely used input for brain-computer interfaces (BCIs) [24], [25], [29], [34], [47], [53], mainly due to the convenience to obtain them, compared with magnetoencephalography (MEG) [32], functional magnetic resonance imaging (fMRI) [44], functional near-infrared spectroscopy (fNIRS) [33], and invasive signals like electrocorticography (ECoG) [35] and intracortical neural recordings [30].", "startOffset": 103, "endOffset": 107}, {"referenceID": 24, "context": "Electroencephalogram (EEG) signals are the most widely used input for brain-computer interfaces (BCIs) [24], [25], [29], [34], [47], [53], mainly due to the convenience to obtain them, compared with magnetoencephalography (MEG) [32], functional magnetic resonance imaging (fMRI) [44], functional near-infrared spectroscopy (fNIRS) [33], and invasive signals like electrocorticography (ECoG) [35] and intracortical neural recordings [30].", "startOffset": 109, "endOffset": 113}, {"referenceID": 28, "context": "Electroencephalogram (EEG) signals are the most widely used input for brain-computer interfaces (BCIs) [24], [25], [29], [34], [47], [53], mainly due to the convenience to obtain them, compared with magnetoencephalography (MEG) [32], functional magnetic resonance imaging (fMRI) [44], functional near-infrared spectroscopy (fNIRS) [33], and invasive signals like electrocorticography (ECoG) [35] and intracortical neural recordings [30].", "startOffset": 115, "endOffset": 119}, {"referenceID": 33, "context": "Electroencephalogram (EEG) signals are the most widely used input for brain-computer interfaces (BCIs) [24], [25], [29], [34], [47], [53], mainly due to the convenience to obtain them, compared with magnetoencephalography (MEG) [32], functional magnetic resonance imaging (fMRI) [44], functional near-infrared spectroscopy (fNIRS) [33], and invasive signals like electrocorticography (ECoG) [35] and intracortical neural recordings [30].", "startOffset": 121, "endOffset": 125}, {"referenceID": 50, "context": "Electroencephalogram (EEG) signals are the most widely used input for brain-computer interfaces (BCIs) [24], [25], [29], [34], [47], [53], mainly due to the convenience to obtain them, compared with magnetoencephalography (MEG) [32], functional magnetic resonance imaging (fMRI) [44], functional near-infrared spectroscopy (fNIRS) [33], and invasive signals like electrocorticography (ECoG) [35] and intracortical neural recordings [30].", "startOffset": 133, "endOffset": 137}, {"referenceID": 31, "context": "Electroencephalogram (EEG) signals are the most widely used input for brain-computer interfaces (BCIs) [24], [25], [29], [34], [47], [53], mainly due to the convenience to obtain them, compared with magnetoencephalography (MEG) [32], functional magnetic resonance imaging (fMRI) [44], functional near-infrared spectroscopy (fNIRS) [33], and invasive signals like electrocorticography (ECoG) [35] and intracortical neural recordings [30].", "startOffset": 228, "endOffset": 232}, {"referenceID": 43, "context": "Electroencephalogram (EEG) signals are the most widely used input for brain-computer interfaces (BCIs) [24], [25], [29], [34], [47], [53], mainly due to the convenience to obtain them, compared with magnetoencephalography (MEG) [32], functional magnetic resonance imaging (fMRI) [44], functional near-infrared spectroscopy (fNIRS) [33], and invasive signals like electrocorticography (ECoG) [35] and intracortical neural recordings [30].", "startOffset": 279, "endOffset": 283}, {"referenceID": 32, "context": "Electroencephalogram (EEG) signals are the most widely used input for brain-computer interfaces (BCIs) [24], [25], [29], [34], [47], [53], mainly due to the convenience to obtain them, compared with magnetoencephalography (MEG) [32], functional magnetic resonance imaging (fMRI) [44], functional near-infrared spectroscopy (fNIRS) [33], and invasive signals like electrocorticography (ECoG) [35] and intracortical neural recordings [30].", "startOffset": 331, "endOffset": 335}, {"referenceID": 34, "context": "Electroencephalogram (EEG) signals are the most widely used input for brain-computer interfaces (BCIs) [24], [25], [29], [34], [47], [53], mainly due to the convenience to obtain them, compared with magnetoencephalography (MEG) [32], functional magnetic resonance imaging (fMRI) [44], functional near-infrared spectroscopy (fNIRS) [33], and invasive signals like electrocorticography (ECoG) [35] and intracortical neural recordings [30].", "startOffset": 391, "endOffset": 395}, {"referenceID": 29, "context": "Electroencephalogram (EEG) signals are the most widely used input for brain-computer interfaces (BCIs) [24], [25], [29], [34], [47], [53], mainly due to the convenience to obtain them, compared with magnetoencephalography (MEG) [32], functional magnetic resonance imaging (fMRI) [44], functional near-infrared spectroscopy (fNIRS) [33], and invasive signals like electrocorticography (ECoG) [35] and intracortical neural recordings [30].", "startOffset": 432, "endOffset": 436}, {"referenceID": 3, "context": "However, EEG signals are often contaminated by ocular, muscular, and cardiac artifacts and various noises (power-line, changes in electrode impedances, etc) [4], [34], [49].", "startOffset": 157, "endOffset": 160}, {"referenceID": 33, "context": "However, EEG signals are often contaminated by ocular, muscular, and cardiac artifacts and various noises (power-line, changes in electrode impedances, etc) [4], [34], [49].", "startOffset": 162, "endOffset": 166}, {"referenceID": 47, "context": "However, EEG signals are often contaminated by ocular, muscular, and cardiac artifacts and various noises (power-line, changes in electrode impedances, etc) [4], [34], [49].", "startOffset": 168, "endOffset": 172}, {"referenceID": 3, "context": "Usually some preprocessing, either manually or automatically [4], [34], is needed to remove the artifacts, and then temporal and spatial filters are applied to further improve the EEG signal quality before feeding it into a classification or regression algorithm.", "startOffset": 61, "endOffset": 64}, {"referenceID": 33, "context": "Usually some preprocessing, either manually or automatically [4], [34], is needed to remove the artifacts, and then temporal and spatial filters are applied to further improve the EEG signal quality before feeding it into a classification or regression algorithm.", "startOffset": 66, "endOffset": 70}, {"referenceID": 1, "context": "Many such approaches have been proposed in the literature [2], [7], [15], [17], [37], [38], [40], [41], [54].", "startOffset": 58, "endOffset": 61}, {"referenceID": 6, "context": "Many such approaches have been proposed in the literature [2], [7], [15], [17], [37], [38], [40], [41], [54].", "startOffset": 63, "endOffset": 66}, {"referenceID": 14, "context": "Many such approaches have been proposed in the literature [2], [7], [15], [17], [37], [38], [40], [41], [54].", "startOffset": 68, "endOffset": 72}, {"referenceID": 16, "context": "Many such approaches have been proposed in the literature [2], [7], [15], [17], [37], [38], [40], [41], [54].", "startOffset": 74, "endOffset": 78}, {"referenceID": 36, "context": "Many such approaches have been proposed in the literature [2], [7], [15], [17], [37], [38], [40], [41], [54].", "startOffset": 80, "endOffset": 84}, {"referenceID": 37, "context": "Many such approaches have been proposed in the literature [2], [7], [15], [17], [37], [38], [40], [41], [54].", "startOffset": 86, "endOffset": 90}, {"referenceID": 39, "context": "Many such approaches have been proposed in the literature [2], [7], [15], [17], [37], [38], [40], [41], [54].", "startOffset": 92, "endOffset": 96}, {"referenceID": 40, "context": "Many such approaches have been proposed in the literature [2], [7], [15], [17], [37], [38], [40], [41], [54].", "startOffset": 98, "endOffset": 102}, {"referenceID": 51, "context": "Many such approaches have been proposed in the literature [2], [7], [15], [17], [37], [38], [40], [41], [54].", "startOffset": 104, "endOffset": 108}, {"referenceID": 25, "context": "One example is driver drowsiness (or alertness) estimation from EEG signals, which has been extensively studied in our previous research [26]\u2013[28], [56], [59], [60], [62].", "startOffset": 137, "endOffset": 141}, {"referenceID": 27, "context": "One example is driver drowsiness (or alertness) estimation from EEG signals, which has been extensively studied in our previous research [26]\u2013[28], [56], [59], [60], [62].", "startOffset": 142, "endOffset": 146}, {"referenceID": 53, "context": "One example is driver drowsiness (or alertness) estimation from EEG signals, which has been extensively studied in our previous research [26]\u2013[28], [56], [59], [60], [62].", "startOffset": 148, "endOffset": 152}, {"referenceID": 56, "context": "One example is driver drowsiness (or alertness) estimation from EEG signals, which has been extensively studied in our previous research [26]\u2013[28], [56], [59], [60], [62].", "startOffset": 154, "endOffset": 158}, {"referenceID": 57, "context": "One example is driver drowsiness (or alertness) estimation from EEG signals, which has been extensively studied in our previous research [26]\u2013[28], [56], [59], [60], [62].", "startOffset": 160, "endOffset": 164}, {"referenceID": 59, "context": "One example is driver drowsiness (or alertness) estimation from EEG signals, which has been extensively studied in our previous research [26]\u2013[28], [56], [59], [60], [62].", "startOffset": 166, "endOffset": 170}, {"referenceID": 42, "context": "This is a very important problem because drowsy driving is among the most important causes of road crashes, following only to alcohol, speeding, and inattention [43].", "startOffset": 161, "endOffset": 165}, {"referenceID": 20, "context": "We also validate their performance in response speed (RS) estimation from EEG signals measured in a large-scale sustained-attention psychomotor vigilance task (PVT) [21], which collected 143 sessions of data from 17 subjects in a 5-month period.", "startOffset": 165, "endOffset": 169}, {"referenceID": 46, "context": "The most basic ones include common average reference (CAR) [48], Laplacian filters [23], and principal component analysis [19].", "startOffset": 59, "endOffset": 63}, {"referenceID": 22, "context": "The most basic ones include common average reference (CAR) [48], Laplacian filters [23], and principal component analysis [19].", "startOffset": 83, "endOffset": 87}, {"referenceID": 18, "context": "The most basic ones include common average reference (CAR) [48], Laplacian filters [23], and principal component analysis [19].", "startOffset": 122, "endOffset": 126}, {"referenceID": 8, "context": "1) Independent Component Analysis (ICA) [9], [17], [54], which decomposes a multivariate signal into independent non-Gaussian signals.", "startOffset": 40, "endOffset": 43}, {"referenceID": 16, "context": "1) Independent Component Analysis (ICA) [9], [17], [54], which decomposes a multivariate signal into independent non-Gaussian signals.", "startOffset": 45, "endOffset": 49}, {"referenceID": 51, "context": "1) Independent Component Analysis (ICA) [9], [17], [54], which decomposes a multivariate signal into independent non-Gaussian signals.", "startOffset": 51, "endOffset": 55}, {"referenceID": 19, "context": "ICA has been widely used in the EEG research community to detect and remove stereotyped eye, muscle, and line noise artifacts [20], [26], [49].", "startOffset": 126, "endOffset": 130}, {"referenceID": 25, "context": "ICA has been widely used in the EEG research community to detect and remove stereotyped eye, muscle, and line noise artifacts [20], [26], [49].", "startOffset": 132, "endOffset": 136}, {"referenceID": 47, "context": "ICA has been widely used in the EEG research community to detect and remove stereotyped eye, muscle, and line noise artifacts [20], [26], [49].", "startOffset": 138, "endOffset": 142}, {"referenceID": 8, "context": "ICA can use various different principles [9], [17], [49], [54] to estimate both unknown A and unknown S simultaneously from X.", "startOffset": 41, "endOffset": 44}, {"referenceID": 16, "context": "ICA can use various different principles [9], [17], [49], [54] to estimate both unknown A and unknown S simultaneously from X.", "startOffset": 46, "endOffset": 50}, {"referenceID": 47, "context": "ICA can use various different principles [9], [17], [49], [54] to estimate both unknown A and unknown S simultaneously from X.", "startOffset": 52, "endOffset": 56}, {"referenceID": 51, "context": "ICA can use various different principles [9], [17], [49], [54] to estimate both unknown A and unknown S simultaneously from X.", "startOffset": 58, "endOffset": 62}, {"referenceID": 25, "context": "Once S is obtained, cleaner and more representative features may be extracted from it than from the original X [26].", "startOffset": 111, "endOffset": 115}, {"referenceID": 37, "context": "2) xDAWN algorithm [38]\u2013[40], which is often used to increase the signal to signal-plus-noise ratio in P300based BCIs.", "startOffset": 19, "endOffset": 23}, {"referenceID": 39, "context": "2) xDAWN algorithm [38]\u2013[40], which is often used to increase the signal to signal-plus-noise ratio in P300based BCIs.", "startOffset": 24, "endOffset": 28}, {"referenceID": 13, "context": "(2) is a generalized Rayleigh quotient [14], and its solution W is the concatenation of the F eigenvectors associated with the F largest eigenvalues of the matrix (XX )\u22121PDDP .", "startOffset": 39, "endOffset": 43}, {"referenceID": 14, "context": "3) Canonical Correlation Analysis (CCA) [15], [41], which finds linear transformations to maximize the correlations between two datasets.", "startOffset": 40, "endOffset": 44}, {"referenceID": 40, "context": "3) Canonical Correlation Analysis (CCA) [15], [41], which finds linear transformations to maximize the correlations between two datasets.", "startOffset": 46, "endOffset": 50}, {"referenceID": 4, "context": "It has been used to improve BCI performance in code-modulated visual evoked potentials [5], steady-state visual evoked potentials [6], and eventrelated potentials like P300 and error-related potentials [45].", "startOffset": 87, "endOffset": 90}, {"referenceID": 5, "context": "It has been used to improve BCI performance in code-modulated visual evoked potentials [5], steady-state visual evoked potentials [6], and eventrelated potentials like P300 and error-related potentials [45].", "startOffset": 130, "endOffset": 133}, {"referenceID": 44, "context": "It has been used to improve BCI performance in code-modulated visual evoked potentials [5], steady-state visual evoked potentials [6], and eventrelated potentials like P300 and error-related potentials [45].", "startOffset": 202, "endOffset": 206}, {"referenceID": 6, "context": "4) Common Spatial Patterns (CSP) [7], [37], which is a supervised technique frequently used to enhance the binary classification performance of EEG data.", "startOffset": 33, "endOffset": 36}, {"referenceID": 36, "context": "4) Common Spatial Patterns (CSP) [7], [37], which is a supervised technique frequently used to enhance the binary classification performance of EEG data.", "startOffset": 38, "endOffset": 42}, {"referenceID": 10, "context": "In the following we introduce the one-versus-the-rest (OVR) CSP [11], which extends the traditional CSP from binary classification to K classes.", "startOffset": 64, "endOffset": 68}, {"referenceID": 13, "context": "(4) is also a generalized Rayleigh quotient [14], and the solution W k is the concatenation of the F eigenvectors associated with the F largest eigenvalues of the matrix ( \u2211", "startOffset": 44, "endOffset": 48}, {"referenceID": 60, "context": "filters from classification to regression by making use of fuzzy sets [63], as we have done in [62].", "startOffset": 70, "endOffset": 74}, {"referenceID": 59, "context": "filters from classification to regression by making use of fuzzy sets [63], as we have done in [62].", "startOffset": 95, "endOffset": 99}, {"referenceID": 0, "context": "A fuzzy set A is comprised of a universe of discourse DA of real numbers together with a membership function \u03bcA : DA \u2192 [0, 1], i.", "startOffset": 119, "endOffset": 125}, {"referenceID": 21, "context": "Fuzzy sets are frequently used in modeling concepts in natural language [22], [36], [55], which may not have clear boundaries.", "startOffset": 72, "endOffset": 76}, {"referenceID": 35, "context": "Fuzzy sets are frequently used in modeling concepts in natural language [22], [36], [55], which may not have clear boundaries.", "startOffset": 78, "endOffset": 82}, {"referenceID": 52, "context": "Fuzzy sets are frequently used in modeling concepts in natural language [22], [36], [55], which may not have clear boundaries.", "startOffset": 84, "endOffset": 88}, {"referenceID": 0, "context": "For a fuzzy class here, a yn can belong to it at a membership degree in [0, 1].", "startOffset": 72, "endOffset": 78}, {"referenceID": 13, "context": "Equation (9) is also a generalized Rayleigh quotient [14], and the solution W k is the concatenation of the F eigenvectors associated with the F largest eigenvalues of the matrix", "startOffset": 53, "endOffset": 57}, {"referenceID": 20, "context": "6) from National Chiao Tung University (NCTU) in Taiwan volunteered to support the data-collection efforts over a 5-month period to study EEG correlates of attention and performance changes under specific conditions of realworld fatigue [21], as determined by the effectiveness score of Readiband [42].", "startOffset": 237, "endOffset": 241}, {"referenceID": 41, "context": "6) from National Chiao Tung University (NCTU) in Taiwan volunteered to support the data-collection efforts over a 5-month period to study EEG correlates of attention and performance changes under specific conditions of realworld fatigue [21], as determined by the effectiveness score of Readiband [42].", "startOffset": 297, "endOffset": 301}, {"referenceID": 48, "context": "The voluntary, fully informed consent of the persons used in this research was obtained as required by federal and Army regulations [50], [51].", "startOffset": 132, "endOffset": 136}, {"referenceID": 49, "context": "The voluntary, fully informed consent of the persons used in this research was obtained as required by federal and Army regulations [50], [51].", "startOffset": 138, "endOffset": 142}, {"referenceID": 0, "context": "Upon completion of the related questionnaires [Karolinska Sleepiness Scale (KSS) [1], and electronically-adapted visual analog scale for fatigue (VAS-F) and stress (VAS-S)] and the informed consent form, subjects performed a PVT, a dynamic attention-shifting task, a lane-keeping task, and selected surveys (KSS, VASF, VAS-S, state-trait anxiety inventory, and mind-wandering) preceding each condition.", "startOffset": 81, "endOffset": 84}, {"referenceID": 9, "context": "In this paper we focus on the PVT [10], which is a sustained-attention task that uses RS to measure the speed with which a subject responds to a visual stimulus.", "startOffset": 34, "endOffset": 38}, {"referenceID": 0, "context": "Each trial was then individually filtered by a [1, 20] Hz finite impulse response band-pass filter to make each channel zero-mean and to remove un-useful high frequency components.", "startOffset": 47, "endOffset": 54}, {"referenceID": 19, "context": "Each trial was then individually filtered by a [1, 20] Hz finite impulse response band-pass filter to make each channel zero-mean and to remove un-useful high frequency components.", "startOffset": 47, "endOffset": 54}, {"referenceID": 54, "context": "method [57], and converted these 62 \u00d7 2 = 124 band powers to dBs as our features.", "startOffset": 7, "endOffset": 11}, {"referenceID": 30, "context": "CAR is one of the most commonly used spatial filters for EEG, and [31] showed that it helped improve EEG classification performance.", "startOffset": 66, "endOffset": 70}, {"referenceID": 11, "context": "Then, non-parametric multiple comparison tests based on Dunn\u2019s procedure [12], [13] were used to determine if the difference between any pair of algorithms was statistically significant, with a p-value correction using the False Discovery Rate method [3].", "startOffset": 73, "endOffset": 77}, {"referenceID": 12, "context": "Then, non-parametric multiple comparison tests based on Dunn\u2019s procedure [12], [13] were used to determine if the difference between any pair of algorithms was statistically significant, with a p-value correction using the False Discovery Rate method [3].", "startOffset": 79, "endOffset": 83}, {"referenceID": 2, "context": "Then, non-parametric multiple comparison tests based on Dunn\u2019s procedure [12], [13] were used to determine if the difference between any pair of algorithms was statistically significant, with a p-value correction using the False Discovery Rate method [3].", "startOffset": 251, "endOffset": 254}, {"referenceID": 19, "context": "For the PVT experiment, F \u2208 [20, 30] seemed to achieve a good compromise between performance and computational cost.", "startOffset": 28, "endOffset": 36}, {"referenceID": 29, "context": "For the PVT experiment, F \u2208 [20, 30] seemed to achieve a good compromise between performance and computational cost.", "startOffset": 28, "endOffset": 36}, {"referenceID": 15, "context": "The reasons are: 1) we need a proper way to normalize the RSs from different sessions, as done for the response times in [16]; and, 2) there is large intra-subject variation, meaning that the EEG responses for the same subject vary at different times (recall that these nine sessions were collected at different days); so, the patterns learned from previous sessions become obsolete for the new session, and hence spatial filtering alone does not help.", "startOffset": 121, "endOffset": 125}, {"referenceID": 55, "context": "However, our previous research [58], [61], [62] has shown that transfer learning can cope well with the inter-subject variation (individual differences) in both classification and regression problems, and we conjecture that it can also handle the intrasubject variation.", "startOffset": 31, "endOffset": 35}, {"referenceID": 58, "context": "However, our previous research [58], [61], [62] has shown that transfer learning can cope well with the inter-subject variation (individual differences) in both classification and regression problems, and we conjecture that it can also handle the intrasubject variation.", "startOffset": 37, "endOffset": 41}, {"referenceID": 59, "context": "However, our previous research [58], [61], [62] has shown that transfer learning can cope well with the inter-subject variation (individual differences) in both classification and regression problems, and we conjecture that it can also handle the intrasubject variation.", "startOffset": 43, "endOffset": 47}, {"referenceID": 17, "context": "One of our future research directions is to demonstrate the performance of CSPR-OVR and CSPR-OVA in a transfer learning framework to individualize a generalized model for regression problems, as done in [18], [46] for EEGbased cognitive performance classification.", "startOffset": 203, "endOffset": 207}, {"referenceID": 45, "context": "One of our future research directions is to demonstrate the performance of CSPR-OVR and CSPR-OVA in a transfer learning framework to individualize a generalized model for regression problems, as done in [18], [46] for EEGbased cognitive performance classification.", "startOffset": 209, "endOffset": 213}, {"referenceID": 7, "context": ", Riemannian geometry [8], for better regression performance.", "startOffset": 22, "endOffset": 25}], "year": 2017, "abstractText": "Electroencephalogram (EEG) signals are frequently used in brain-computer interfaces (BCIs), but they are easily contaminated by artifacts and noises, so preprocessing must be done before they are fed into a machine learning algorithm for classification or regression. Spatial filters have been widely used to increase the signal-to-noise ratio of EEG for BCI classification problems, but their applications in BCI regression problems have been very limited. This paper proposes two common spatial pattern (CSP) filters for EEG-based regression problems in BCI, which are extended from the CSP filter for classification, by making use of fuzzy sets. Experimental results on EEG-based response speed estimation from a large-scale study, which collected 143 sessions of sustained-attention psychomotor vigilance task data from 17 subjects during a 5-month period, demonstrate that the two proposed spatial filters can significantly increase the EEG signal quality. When used in LASSO and knearest neighbors regression for user response speed estimation, the spatial filters can reduce the root mean square estimation error by 10.02 \u2212 19.77%, and at the same time increase the correlation to the true response speed by 19.39 \u2212 86.47%.", "creator": "LaTeX with hyperref package"}}}