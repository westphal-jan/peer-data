{"id": "1702.03594", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "12-Feb-2017", "title": "Genetic and Memetic Algorithm with Diversity Equilibrium based on Greedy Diversification", "abstract": "The lack of diversity in a genetic algorithm's population may lead to a bad performance of the genetic operators since there is not an equilibrium between exploration and exploitation. In those cases, genetic algorithms present a fast and unsuitable convergence. In a variety of cases, the resulting algorithm is either biased or too slow, or a mistake is made. A single human has the capacity to detect patterns of variation in genes, so that in the case of a genetic algorithm, there is no discrimination between exploration and exploitation. The problem is that the system can do it very well, because it has the capabilities of sophisticated genetic algorithms and a set of strategies to reduce the competition between the various regions. The same is true of many other artificial intelligence algorithms, such as X-rays, MRI, and GPS, which are currently available in several languages.\n\n\n\nIn this study, we investigated the impact of genetic algorithms on genetic algorithms and its performance in the production of gene sequences, and its performance in the production of genes, as well as on the production of gene sequences. The authors determined the most efficient (and most highly efficient) genetic algorithms on the basis of a statistical test. As the results were analyzed, the results were obtained.", "histories": [["v1", "Sun, 12 Feb 2017 23:23:17 GMT  (177kb,D)", "http://arxiv.org/abs/1702.03594v1", "27 pages, 5 figures, 11 tables"]], "COMMENTS": "27 pages, 5 figures, 11 tables", "reviews": [], "SUBJECTS": "cs.AI", "authors": ["andr\\'es herrera-poyatos", "francisco herrera"], "accepted": false, "id": "1702.03594"}, "pdf": {"name": "1702.03594.pdf", "metadata": {"source": "CRF", "title": "GENETIC AND MEMETIC ALGORITHM WITH DIVERSITY EQUILIBRIUM BASED ON GREEDY DIVERSIFICATION", "authors": [], "emails": ["andreshp9@gmail.com,", "herrera@decsai.ugr.es"], "sections": [{"heading": null, "text": "In this paper we develop a novel hybrid genetic algorithm which attempts to obtain a balance between exploration and exploitation. It confronts the diversity problem using the named greedy diversification operator. Furthermore, the proposed algorithm applies a competition between parent and children so as to exploit the high quality visited solutions. These operators are complemented by a simple selection mechanism designed to preserve and take advantage of the population diversity.\nAdditionally, we extend our proposal to the field of memetic algorithms, obtaining an improved model with outstanding results in practice.\nThe experimental study shows the validity of the approach as well as how important is taking into account the exploration and exploitation concepts when designing an evolutionary algorithm.\nKeywords: genetic algorithms, memetic algorithms, exploration vs exploitation, population diversity, hybridization.\n1. Introduction\nOptimization problems are a relevant topic of artificial intelligence. In order to solve these problems, computer scientists have found inspiration in nature, developing bio-inspired algorithms [5], [30] and, in particular, evolutionary algorithms [25].\nGenetic algorithms [7] are one of the most famous evolutionary algorithms. They are founded in the concepts of evolution and genetic. A solution to an optimization problem is view as a chromosome. Genetic algorithms maintain a population of chromosomes which evolves thanks to the selection, crossover and mutation operators. The evolution process ends when a predefined criteria is achieved.\nThe equilibrium between exploration and exploitation is the key for success when designing an evolutionary algorithm. M. Crepinsek et al. [2] define exploration as \u201cthe process of visiting entirely new regions of the search space\u201d, whereas exploitation is \u201cthe process of visiting those regions of the search space within the neighborhood of previously visited points\u201d. If an heuristic is mainly focused in exploration, then it may not find the high quality neighbors of the promising visited solutions. Conversely, if an heuristic is mainly focused in exploitation, then it may not explore the regions of the search space which lead to most of the high quality solutions for the problem. Hence, our purpose is developing a genetic algorithm which\n1\nar X\niv :1\n70 2.\n03 59\n4v 1\n[ cs\n.A I]\n1 2\nFe b\n2 ANDRE\u0301S HERRERA-POYATOS 1 AND FRANCISCO HERRERA 1,2\nintercalates the exploration and exploitation phases as needed, focusing the attention in the population diversity.\nThe population diversity is one of the cornerstone of the genetic algorithms\u2019 performance. Note that a genetic algorithm\u2019s population converges if, and only if, the population diversity converges to zero. If this happens, then the heuristic has entered in a never-ending exploitation phase. We say that it has converged to a local optimum due to the lack capability for increasing the population diversity. Hence, the diversity problem \u2013 maintaining a healthy population diversity \u2013 is closely related to achieving a proper equilibrium between exploration and exploitation. There are various proposals of the specialized literature which address this problem [6].\nIn this proposal we tackle the diversity problem formulating a diversification operator which introduces diversity to the population when it is needed. The inserted new chromosomes are generated by a randomized greedy algorithm. Afterwards, we use this operator to design an hybrid genetic algorithm, which is shown to maintain a stable population diversity. The hybridization between greedy randomized and genetic algorithms produces great results because the greedy chromosomes allow the heuristic to explore the promising regions of the search space. Hybridization of evolutionary algorithms with other heuristics is a common practice which helps to improve the evolutionary algorithms\u2019 performance [18], [21]. Furthermore, the proposed genetic algorithm use a competition between parent and children, similar to the one used by differential evolution [26], so as to exploit the high quality visited solutions. These operators are complemented by simple selection mechanism which we call randomized adjacent selection and is designed to preserve and take advantage of the population diversity. We refer to the proposed algorithm as genetic algorithm with diversity equilibrium based on greedy diversification (GADEGD).\nIn order to obtain an improved model, we also extend the previous algorithm to the field of memetic algorithms [12]. The new algorithm is called memetic algorithm with diversity equilibrium based on greedy diversification (MADEGD).\nWe have developed an experimental study for each of both models using the traveling salesman problem [16], [9] as the case of study. In GADEGD\u2019s study we analyze its parameters and we match it against other state of the art genetic algorithms (CHC [3] and Micro-GA [13]) in terms of the solutions quality, the convergence to optimal solutions and the population diversity. Furthermore, we show how GADEGD\u2019s components contribute to its performance. In MADEGD\u2019s study we also analyze its parameters and compare it with GADEGD. Additionaly, MADEGD is matched against other state of the art metaheuristics based on local search (GRASP [4] and iterated greedy [23], [10]) from a triple perspective, the solutions quality, the population diversity and the number of calls to the local search.\nThe remainder of this article is organized as follows. In Section 2, we shortly introduce genetic and memetic algorithms. In Section 3, we study the diversity problem in genetic algorithms and we also present the greedy diversification operator, the other GADEGD\u2019s components and the corresponding experimental analysis. In Section 4, we formulate MADEGD and show the associated experimental results. In Section 5, we point out the obtained conclusions."}, {"heading": "2. Genetic and memetic algorithms", "text": "In this section we briefly introduce genetic and memetic algorithms (Sections 2.1 and 2.2 respectively) and provide the pseudo-codes which are used in the experimental analysis. Lastly, we particularize in the application of these algorithms to the traveling salesman problem (Section 2.3), which is employed as the case of study."}, {"heading": "GENETIC AND MEMETIC ALGORITHM WITH DIVERSITY EQUILIBRIUM BASED ON GREEDY DIVERSIFICATION 3", "text": "2.1. Genetic Algorithms. Let f be the objective function associated to an optimization problem, f : S \u2192 R, where S is the set of all the possible solutions. The purpose is minimizing (resp. maximizing) f . Thus, a solution s is better than another if its objective value f(s) is smaller (resp. greater).\nLet Pt be a finite subset of S. Pt is called the population of the genetic algorithm. We can define a genetic algorithm as a population based metaheuristic [29], [1], [27] which uses the selection, crossover and mutation operators to obtain a new population Pt+1 from Pt. The process is repeated until a stopping criteria is achieved. Then, the best solution found or the best solution in the last population is returned.\nA genetic algorithm with the previous definition does not guarantee that there is a chromosome in the new population as good as the previous populations\u2019 chromosomes. However, this statement can be achieved applying the elitism criteria, appending the best solution in Pt, denoted bs(Pt), to Pt+1. Afterwards, some models also delete the worst solution from Pt+1, denoted ws(Pt+1). Elitism has been proved to improve the genetic algorithm results in most cases, even theoretically [22]. Consequently, genetic algorithms with elitism are a popular model among computer scientists.\nAlgorithm 1 BuildNewPopulation(P )\nRequire: A population P . 1: P \u2032 \u2190 \u2205 2: Select |P |\n2 pairs of chromosomes from P using binary tournament selection .\n3: Cross each pair, with a probability pc \u2208 (0, 1], getting two children if crossed. 4: Add the new children and the pairs that have not been crossed to P \u2032. 5: Produce a mutation in each solution of P \u2032 with a probability pm \u2208 (0, 1]. 6: Elitism: ws(P \u2032)\u2190 bs(P ) 7: return P \u2032\nAlgorithm 1 shows how a new population is built in a usual generational genetic algorithm with elitism. The binary tournament selection [8] is a widely used selection scheme in genetic algorithms. The variables pc and pm are known as the crossover and mutation probability respectively. We have used the values pc = 0.7 and pm = 0.1 as it is common in the literature. From Algorithm 1 one can easily constructs a genetic algorithm, see Algorithm 2. However, this standard model may not work properly due to the lack of diversity in the population as it is shown in Section 3.\nAlgorithm 2 Generational genetic algorithm with elitism\nRequire: The population size, named n.\n1: Initialize P0 with n random elements from S. 2: t\u2190 0 3: while stopping criteria is not achieved do 4: Pt+1 \u2190 BuildNewPopulation(Pt) 5: t\u2190 t + 1 6: end while 7: return bs(Pt)\n2.2. Memetic Algorithms. Memetic algorithms hybridize evolutionary algorithms and local search procedures in order to obtain a model with a better exploration and exploitation. We will focus our attention in the subset of memetic algorithms in which the evolutionary scheme is carried out by a genetic algorithm.\nAn usual hybridization consists in applying the local search once per each genetic algorithm iteration. The chromosome to which the local search is applied is the one with the best\n4 ANDRE\u0301S HERRERA-POYATOS 1 AND FRANCISCO HERRERA 1,2\nobjective value among those population\u2019s solutions that have not been improved by the local search yet, what is indicated by a boolean variable. Other approaches apply the local search to each population element. However, these waste too much time improving low quality solutions. It is better to use the computational resources improving only the promising chromosomes as the first approach did.\nMemetic algorithms with high quality local searches usually outperform genetic algorithms. One of the reasons is that the local search improves the population quality introducing diversity at the same time. Hence, we could classify local search as an excellent mutation operator but with a high complexity cost. Furthermore, the evolutionary character of the algorithm implies that the local search is likely applied to better solutions as time passes, obtaining a good synergy.\nAlgorithm 3 shows a memetic algorithm\u2019s pseudo-code. It has two differences with Algorithm 2. First, the population is initialized with a randomized greedy algorithm, explained in Algorithm 5, so as to not apply the local search to random solutions. Otherwise, too much time would be consumed by the local search at the beginning of the algorithm. Secondly, the local search is applied once per iteration as we discussed before.\nAlgorithm 3 Memetic algorithm\nRequire: The population size, named n.\n1: Initialize P0 with n solutions obtained by a greedy randomized algorithm. 2: t\u2190 0 3: while stopping criteria is not achieved do 4: Pt+1 \u2190 BuildNewPopulation(Pt) 5: Apply the local search to the best solution not previously improved of Pt+1 (if it exits). 6: t\u2190 t + 1 7: end while 8: return bs(Pt)\n2.3. Application to the traveling salesman problem. We have used the traveling salesman problem as the case of study for our proposal. Given a complete and weighed graph, this problem consists in obtaining the Hamiltonian cycle which minimize the sum of its edges\u2019 weighs. This sum is named the solution cost. Therefore, it is a minimization problem and the objective function provides the cost of each solution.\nWe have chosen the traveling salesman problem because it is a classical NP Hard problem which has been extensively employed to study heuristics in the specialized literature [28].\nResearchers have developed a huge amount of genetic operators for the traveling salesman problem [14]. We use the well known crossover OX and exchange mutation which have shown a good performance in experimental studies.\nOne of the best heuristics for the traveling salesman problem is a local search named LinKernighan [17]. We have chosen a modern version [11] as the local search for the experimental study."}, {"heading": "3. GADEGD: Genetic algorithm with diversity equilibrium based on greedy diversification", "text": "In this section we propose a novel genetic algorithm with the aim of obtaining a good balance between exploration and exploitation.\nFirst, we introduce a measure of the population diversity and we show the diversity problem in genetic algorithms. Secondly, we develop an operator to tackle the diversity problem, called the greedy diversification operator. Thirdly, we introduce the genetic algorithm with diversity"}, {"heading": "GENETIC AND MEMETIC ALGORITHM WITH DIVERSITY EQUILIBRIUM BASED ON GREEDY DIVERSIFICATION 5", "text": "equilibrium based on greedy diversification (GADEGD). At last, we show the experimental results of the proposal from a triple perspective: solutions quality, convergence to optimal solutions and population diversity.\n3.1. Population diversity in genetic algorithms. The diversity of a population is a measure of how different its chromosomes are. If the diversity is low, then the chromosomes are similar. On the other hand, if the diversity is high, then the chromosomes are quite different.\nWe need a distance measure, d : S \u00d7 S \u2192 R+0 , in order to quantify the differences between two solutions. Then, we can define the diversity of the population as the mean of the distance between all pairs of chromosomes, which can be written as following:\nDt =\n\u2211 s,s\u2032\u2208Pt d(s, s \u2032)\nn(n\u2212 1)\nIn the traveling salesman problem a good distance measure is the number of edges in which two chromosomes differ. The maximum distance between two chromosomes for this measure is the number of cities in the problem. Therefore, the same happens for the diversity measure proposed before.\nFigure 1 shows how the population diversity evolves in a execution of a standard genetic algorithm (Algorithm 2). The instance is berlin52, which consists of 52 cities and can be found in TSPLIB [20]. Each figure\u2019s point corresponds to the average population diversity in the last 0.01 seconds. The diversity starts near the maximum possible value since the initial chromosomes are randomly chosen. Afterwards, the diversity quickly decreases because the algorithm focuses the search in a specific region of the search space. However, the diversity diminution is excessive, converging to a number close to zero eventually. This fact indicates that the algorithm has converged to a local optimum, not being able to reach better solutions. Consequently, if the local optimum is not good enough, then the algorithm results will be disappointing. We aim to avoid this fast and unsuitable convergence so as to improve the algorithm performance.\n6 ANDRE\u0301S HERRERA-POYATOS 1 AND FRANCISCO HERRERA 1,2\nIn genetic algorithms, the population diversity is maintained by the mutation operator. The diversity depends on the value pm which was defined as the probability of mutating a chromosome in an iteration. If pm is equal to zero, then the diversity will tend to zero after few iterations. If pm is increased, then the diversity will converge to a higher value. Nonetheless, the mutation operator introduces diversity at the cost of deteriorating, most of the time, the quality of the solutions to which it is applied. Hence, low values are assigned to the mutation probability in the specific literature (between 0.1 and 0.2 per chromosome) not allowing a high diversity as it is shown in Figure 1 (where pm is 0.1).\n3.2. Greedy diversification operator. Population diversity is a double-edged sword. It is needed to explore the solutions space but it can imply not finishing the exploration process. If it is the case, then not enough time is dedicated to the exploitation phase which is essential to get higher quality solutions. Therefore, it is desired a diversification operator that only introduces diversity if it is necessary.\nThis operator would be applied to every new population as it is shown in Algorithm 4.\nAlgorithm 4 Genetic algorithm with diversification\nRequire: The population size, named n. 1: Initialize P0 with n random elements from S. 2: t\u2190 0 3: while stopping criteria is not achieved do 4: Pt+1 \u2190 BuildNewPopulation(Pt) 5: Pt+1 \u2190 Diversification(Pt+1) 6: t\u2190 t + 1 7: end while 8: return bs(Pt)\nThe diversification operator should delete the population\u2019s repeated chromosomes because they waste the population\u2019s slots and reduce the diversity. Furthermore, the chromosomes that are left in the population should have a good objective value and be potentially good for the crossover operator. The diversification operator ought also to have a low computational cost since the optimization is done by the evolutionary scheme. We propose using a greedy randomized algorithm to obtain chromosomes satisfying these conditions.\nGreedy randomized algorithms provide acceptable chromosomes from the objective value perspective that also contain high quality genetic material thanks to the greedy selection function. The randomized aspect of the algorithm supplies the diversity required in the generated solutions. There are some conditions to implement a greedy randomized algorithm for an optimization problem. First, the solution must be represented as a set or list of elements. Secondly, it is needed a greedy function which provides the quality of an element according to those that have been already added to the solution. The building process is iterative. In each step a new element is added to the solution until it is fully completed. In order to add a new element, a restricted candidate list (RCL) must be determined. Afterwards, an element randomly chosen from the RCL is added to the solution. This process is presented in Algorithm 5.\nThe RCL contains the best elements conforming to the greedy function. The list\u2019s size can be constant or variable, in which case it depends on the elements quality. The variable size RCL contains the elements whose greedy value is less than (1 + \u03c3) times the best element\u2019s value, where \u03c3 is a fixed real value greater than zero. This model obtains better solutions because it controls the quality of the elements added to the list. It also keeps the diversity in the generated solutions since the RCL can be very large when multiple elements are good"}, {"heading": "GENETIC AND MEMETIC ALGORITHM WITH DIVERSITY EQUILIBRIUM BASED ON GREEDY DIVERSIFICATION 7", "text": "Algorithm 5 Greedy Randomized Algorithm\n1: solution\u2190 \u2205 2: while solution is not finished do 3: Build the RCL. 4: x\u2190 randomElement(RCL) 5: solution\u2190 solution \u222a x 6: Adapt the greedy function to the new partial solution. 7: end while 8: return solution\nenough. In our experiments we use \u03c3 = 0.1 although this parameter can be optimized in each application domain.\nParticularizing in the traveling salesman problem, a solution is conceived as a list of nodes. The greedy function provides the distance of each node which is not in the solution to the last node appended to the solution. Thus, a node is better than another one if its distance to the last node appended is smaller. As a consequence, the obtained solution is mostly comprised of short edges. Therefore, if we cross this greedy solution with another one, we get a child which has a fair number of short edges and, hence, it is probably a high quality solution.\nThus, the first element of our proposal is a diversification operator which uses the greedy randomized algorithm to substitute those chromosomes that share similarity characteristics with other population solutions. This procedure increase the diversity and also keeps the population quality. In order to formalize the operator, let us consider an arbitrary characteristic featured in the problem\u2019s solutions and let C be the set of all its possible values. The function g : S \u2192 C provides, given a solution s, the value g(s) \u2208 C which the solution possesses. For instance, a characteristic could be the solution\u2019s objective value or whether the solution has a concrete element or not. It could even be the solution itself.\nAlgorithm 6 Greedy diversification operator\nRequire: The genetic algorithm population, named P , and the characteristic function g : S \u2192 C. 1: P \u2032 \u2190 \u2205 2: Sort P by the objective function (the better solutions are placed first). 3: k \u2190 0 4: for s in P do 5: if exists s\u2032 in P \u2032 such as g(s) = g(s\u2032) then 6: k \u2190 k + 1 7: else 8: P \u2032 \u2190 P \u2032 \u222a s 9: end if 10: end for 11: for i = 1 to k do 12: P \u2032 \u2190 P \u2032 \u222aGreedyRandomizedAlgorithm() 13: end for 14: return P \u2032\nAlgorithm 6 uses this terminology to show a general definition of the greedy diversification operator. This operator removes the population\u2019s worst solutions that share the characteristic\u2019s value with other ones. Then, it fills the new population with greedy randomized solutions. The efficiency in the worst case is \u03b8(|P |(log |P |+ \u03c6+ \u00b5)), where \u03c6 and \u00b5 are the complexity of applying g to a solution and obtaining a greedy randomized solution respectively.\nThe choice of g affects the amount of diversity introduced and the operator complexity. A first approach is using the identity function (Id : S \u2192 S and Id(s) = s) as g. In this case the algorithm just substitutes the repeated solutions in the population. Algorithm 7 provides an\n8 ANDRE\u0301S HERRERA-POYATOS 1 AND FRANCISCO HERRERA 1,2\nefficient implementation for this approach. In the case of the traveling salesman problem, we can implement the identity function and the greedy randomized algorithm with efficiencies \u03b8(m) and \u03b8(m2) respectively, where m is the number of nodes in the instance. Consequently, the efficiency in the worst case is \u03b8(|P |(log |P | + m2)). However, the experimental analysis in Section 3.4 shows that Algorithm 7 complexity in practice is O(|P | log |P |+m2) since two solutions usually have different objective values and few repeated solutions are found after a genetic algorithm\u2019s iteration.\nAlgorithm 7 Greedy diversification operator with g = Id\nRequire: The genetic algorithm population, named P . 1: P \u2032 \u2190 {bs(P )} 2: Sort P by the objective function (the better solutions are placed first). 3: for i = 1 to n\u2212 1 do 4: if f(P [i\u2212 1]) = f(P [i]) and P [i\u2212 1] = P [i] then 5: P \u2032 \u2190 P \u2032 \u222aGreedyRandomizedAlgorithm() 6: else 7: P \u2032 \u2190 P \u2032 \u222a P [i] 8: end if 9: end for 10: return P \u2032\nA second approach is using the objective function as g. In this case more diversity is introduced but some interesting solutions might be lost. The implementation is the same that the one given in Algorithm 7 but without comparing two solutions in the line 4. The practical complexity remains the same too. Both approaches\u2019 results are contrasted in Section 3.4.1.\n3.3. Genetic algorithm with diversity equilibrium based on greedy diversification. Algorithm 4 with the greedy diversification operator given in Algorithm 7 presents a much better performance than Algorithm 2 as we show in Section 3.4. However, the synergy among the genetic and diversification operators can be improved. Therefore, we propose a novel genetic algorithm with the following characteristics:\n(1) A novel selection mechanism which does not apply pressure and helps to preserve the diversity in the new population. We call it randomized adjacent selection. (2) The crossover probability is equal to 1. (3) A competition between parent and children to increase the pressure applied to the\npopulation. (4) The greedy diversification operator is used instead of the mutation operator.\nThe new algorithm is named genetic algorithm with diversity equilibrium based on greedy diversification since it gets a healthy diversity thanks to the greedy diversification operator and it is referred as GADEGD. The mentioned algorithm\u2019s components are explained in the rest of the section.\nSelection schemes in genetic algorithms usually ignore the population\u2019s worst solutions. Some examples are the tournament or ranking selection [8], which select the worst solutions with a very low probability. If we use these mechanisms, then the greedy solutions introduced by the diversification operator will not be selected eventually. Furthermore, we desire every chromosome to be crossed in order to take advantage of the population diversity. As a consequence, we propose randomly sorting the population and crossing the adjacent solutions, considering the first and last solution also as contiguous. Each pair of adjacent solutions is crossed with probability 1, generating only one child. We call it randomized adjacent selection."}, {"heading": "GENETIC AND MEMETIC ALGORITHM WITH DIVERSITY EQUILIBRIUM BASED ON GREEDY DIVERSIFICATION 9", "text": "Note that this scheme assures that each solution has exactly two children. Consequently, all the genetic material is used to build the new population, what preserves the diversity.\nThe randomized adjacent selection conserves the diversity but does not apply any pressure to the population. The competition between parent and children is the mechanism chosen for that purpose. We propose a process similar to the one used by the differential evolution algorithms; each child only competes with its left parent and the best of both solution is added to Pt+1. Consequently, the population Pt+1 contains a descendant for each solution of Pt or the solution itself. This statement implies that if the population Pt is diverse, then the population Pt+1 will likely be diverse too. Furthermore, the population Pt+1 is always better than Pt in terms of the objective function. The competition between parent and children can be considered a strong elitism that, in our case, preserves the diversity thanks to the randomized adjacent selection.\nAlgorithm 8 BuildNewPopulationGADEGD(P )\nRequire: A population P . 1: P \u2032 \u2190 \u2205 2: Sort P randomly. 3: for i = 0 to n\u2212 1 do 4: parent1\u2190 P (i) 5: parent2\u2190 P ((i + 1) mod n) 6: child\u2190 Crossover(parent1, parent2) 7: if f(child) is better than f(parent1) then 8: P \u2032 \u2190 P \u2032 \u222a child 9: else 10: P \u2032 \u2190 P \u2032 \u222a parent1 11: end if 12: end for 13: return P \u2032\nAlgorithm 8 shows how a new population is built in GADEGD. Note that the code is very simple, what is an advantage versus more complicated models.\nIn genetic algorithms, the mutation operator introduces diversity and allows the algorithm to explore the neighborhood of the population\u2019s solutions. However, GADEGD does not need it any more since it is able to keep the population diversity by itself. Consequently, the mutation operator just decrease the solutions quality and should not be used. Algorithm 9 contains the pseudo-code of GADEGD.\nAlgorithm 9 Genetic algorithm with diversity equilibrium based on greedy diversification\nRequire: The population size, named n, and the characteristic function g : S \u2192 C. 1: Initialize P0 with n random elements from S. 2: t\u2190 0 3: while stopping criteria is not achieved do 4: Pt+1 \u2190 BuildNewPopulationGADEGD(Pt) 5: Pt+1 \u2190 GreedyDiversification(Pt+1, g) 6: t\u2190 t + 1 7: end while 8: return bs(Pt)\nFigure 2 shows how the population diversity evolves for GADEGD and the implemented genetic algorithms (Algorithms 9 and 2 respectively) in the instance berlin52. Here GADEGD has been executed with g = Id. Note that GADEGD is designed to maintain a diverse population and so it does. The initial diversity decreases quickly in both algorithms. Afterwards,\n10 ANDRE\u0301S HERRERA-POYATOS 1 AND FRANCISCO HERRERA 1,2\nGADEGD keeps the diversity in a high and stabilized value. Its components allows the algorithm to work with good solutions in multiple zones of the search space. Besides, if the population diversity decreases, then the greedy diversification introduces new chromosomes.\n3.4. Experimental analysis. The experiments were done in a computer with 8 GB of RAM and a processor Intel I5 with 2.5 GHz. The 18 instances of the traveling salesman problem can be found in the TSPLIB library. Each result is computed as the average of 30 executions.\nThe experimental analysis contains 3 subsections. First, we provide a study of the GADEGD\u2019s parameters: the population size and the characteristic function. In the second subsection the algorithm is compared against other state of the art algorithms from a triple perspective: the solutions quality, the convergence to the instances\u2019 optimums and the population diversity. Lastly, we analyze how much the GADEGD\u2019s components contribute to its performance.\n3.4.1. GADEGD\u2019s parameters analysis. The population size has a huge impact on a genetic algorithm behavior. On the one hand, a greater population size contribute to the exploration of the solutions\u2019 space, avoiding a fast and unsuitable convergence. However, a large population needs much more computational time to exploit the most promising solutions. On the other hand, a smaller population size implies a higher exploitation and a sooner convergence. The optimal population size depends on the execution\u2019s time and the algorithm facilities to maintain a diverse population. If this optimal value is very large, then the algorithm has probably difficulties to explore the solutions space and keep the population diversity. If this is the case, then the algorithm is probably improvable.\nGenetic algorithms are usually assigned a population size between 30 and 100 in the literature although this value tends to grow with the improvements in hardware. There are also models which work under small populations [13]. In our case, we want the algorithm to have a medium sized population because we try to achieve an equilibrium between exploration and exploitation."}, {"heading": "GENETIC AND MEMETIC ALGORITHM WITH DIVERSITY EQUILIBRIUM BASED ON GREEDY DIVERSIFICATION 11", "text": "Table 1 compares the population sizes 32 and 64 in terms of the mean and standard deviation of the obtained solutions\u2019 objective value. In these experiments the GADEGD\u2019s characteristic function is g = Id and the execution\u2019s time is 0.1m seconds, where m is the instance\u2019s number of nodes. The experiments show that 64 is a better population size than 32, obtaining the best results most of the time. We also have executed the algorithm with smaller and larger population sizes and they had a significant worse performance. Consequently, we are using 64 as the standard population size for the GADEGD algorithm.\nTable 1. GADEGD with g = Id and population sizes 32 and 64. The execution time is 0.1m seconds. The best results are highlighted in bold. The last row indicates the number of times that each model got the best result in any instance.\nProblem Optimum Mean objective value Standard deviation\nn = 32 n = 64 n = 32 n = 64\neil51 426 427.2 427.267 0.4 1.26315 berlin52 7542 7555.1 7572.57 39.3 55.4068 st70 675 682.467 682.067 5.03808 4.21057 eil76 538 549.8 549.5 0.979796 1.43178 pr76 108159 109169 109395 942.768 573.954 kroA100 21282 21385.8 21352.5 134.201 119.631 rd100 7910 7917.13 7919.47 28.619 35.4445 eil101 629 631.7 633.3 3.06757 4.09186 lin105 14379 14436.2 14430.5 33.7544 18.2916 ch150 6528 6588.67 6578.67 20.277 20.6968 rat195 2323 2393.47 2386.83 16.126 17.6335 d198 15780 16076.4 16053.9 75.0803 95.1888 ts225 126643 127550 127427 391.036 524.795 a280 2579 2718.63 2704.5 26.2824 26.9923 lin318 42029 43815.3 43739.5 429.102 412.694 fl417 11861 12323.7 12303.9 105.208 134.313 pcb442 50778 55741 55502 633.782 639.032 rat575 6773 7677.5 7670.97 83.7412 78.0105\n5 13\nThe most essential GADEGD\u2019s parameter is the characteristic function. We have used the functions g = Id and g = f explained in Section 3.2. More complex models did not obtained better results in practice. Table 2 compares both functions\u2019 performance. The model g = Id reaches better solutions in most instances. The function g = f introduces too much diversity and it might substitute not repeated chromosomes with unique characteristics. Hence, the model g = Id is the one chosen for the rest of the study.\nTable 2 also shows the percent of explored solutions which are generated in the greedy diversification. This value is usually between 2 and 10 %. In average, this means that the algorithm introduces between 1 and 7 greedy solutions per iteration for both characteristics functions. Consequently, we can consider the practical complexity of these greedy diversification algorithms as O(|P | log |P | + m2) as we mentioned in Section 3.2. Note that if the\n12 ANDRE\u0301S HERRERA-POYATOS 1 AND FRANCISCO HERRERA 1,2\nGADEGD algorithm converges, then the greedy diversification introduces more greedy solutions to increase the population diversity. If it is not the case, then less greedy solutions are introduced (see instances 1 and 18 respectively in Table 2).\n3.4.2. Comparison with other genetic algorithms which use diversity mechanisms instead of mutations. In this section we compare GADEGD with the genetic algorithm given in Algorithm 2 and other recognized models which do not use the mutation operator: CHC [3] and Micro-GA [13]. We study the quality of the obtained solutions, the convergence to the problems\u2019 optimums and the population diversity in order to illustrate GADEGD\u2019s performance.\nCHC was the first genetic algorithm which applies a competition between parent and children. CHC has already been applied to the traveling salesman problem variations [24]. Our implementation has the following characteristics:\n\u2022 Population size = 60 \u2022 Random selection with incest prevention mechanism that avoids crossing similar so-\nlutions."}, {"heading": "GENETIC AND MEMETIC ALGORITHM WITH DIVERSITY EQUILIBRIUM BASED ON GREEDY DIVERSIFICATION 13", "text": "\u2022 Competition between parent and children: the population Pt+1 contains the best chromosomes between parent and children. \u2022 Reinitialization of the population when it converges (detected by the incest prevention\nmechanism): the best chromosome is left and the other ones are replaced by random solutions.\nThe Micro-GA was proposed as a genetic algorithm with a small population and fast convergence. It was the first genetic algorithm which uses a reinitialization of the population when it converges. It has the following characteristics:\n\u2022 Population size = 5 \u2022 The best solution in Pt is added to Pt+1. \u2022 Two pairs of parent are selected by a variation of the tournament selection. \u2022 Both pairs are crossed, generating two children per pair that are added to Pt+1. \u2022 Reinitialization of the population when it converges (all the solutions have the same\nobjective value): the best chromosome is left and the other ones are replaced by random solutions.\n14 ANDRE\u0301S HERRERA-POYATOS 1 AND FRANCISCO HERRERA 1,2\nBoth algorithms assign 1 to the crossover probability and do not use the mutation operator. In this sense, they are similar to our proposal. However, they use a reinitialization of the population in contrast to GADEGD\u2019s greedy diversification.\nTable 3 shows the results obtained by these algorithms. They are good in instances with few nodes. However, if the instances are harder, then they do not perform well, the random solutions are not good enough as a reinitialization mechanism. Consequently, we propose a greedy reinitialization for CHC and Micro-GA, replacing the population by greedy solutions obtained from Algorithm 5 instead of random chromosomes. The results are also presented in Table 3. As we expected, the new models with the greedy reinitialization outperform the older ones in any instance. This fact shows that genetic algorithms hybridize fairly well with greedy algorithms, there is a great synergy between the greedy chromosomes and the crossover operator as we mentioned in Section 3.2.\nTable 4 compares, in terms of the solution\u2019s quality, the algorithms GADEGD, a generational genetic algorithm (Algorithm 2) and both CHC and Micro-GA with greedy reinitialization. GADEGD performs considerably better than the other algorithms in 17 out of 18 instances. The main reason behind the better performance of GADEGD is the greedy diversification. It introduces diversity before the algorithm has totally converged and, consequently,"}, {"heading": "GENETIC AND MEMETIC ALGORITHM WITH DIVERSITY EQUILIBRIUM BASED ON GREEDY DIVERSIFICATION 15", "text": "it constantly keeps a high quality and diverse population, what can not been achieved by the (greedy) reinitialization used in CHC and Micro-GA. In those algorithms the diversity and the quality of the solutions are not stable and they generally vary inversely until the population is reinitialized. When the population is reinitialized, the algorithms do a lot of effort to build a high quality population again and, consequently, computation time is wasted.\nNote the poor results that the generational genetic algorithm offers, which are due to the low diversity and fast convergence. It is known that this model can not reach the performance of CHC and Micro-GA with the classic reinitialization, see Table 3. Consequently, the performance\u2019s differences compared with those algorithms with greedy reinitialization are huge.\nGADEGD not only obtains high quality solutions but is also able to reach the problems\u2019 optimal solutions. We have developed Table 5 in order to study how difficult is for the algorithms to converge to the instances\u2019 optimums. Each entry contains the number of times that the corresponding algorithm has reached an optimal solution and the average time needed to do so. The results are taken from 30 executions per algorithm and instance, each of which lasts at most 20 seconds. GADEGD presents the fastest convergence. It also reaches the optimums more often than the other algorithms. The greedy diversification contributes to this convergence since it introduces new greedy chromosomes progressively, allowing the population\u2019s solutions to find the genetic material which they need to generate better descendants.\nFigure 3 shows how the algorithms\u2019 best solution evolve in the instance d198. The data is taken from a 60 seconds execution, plotting the objective value of the best solution found as time passes. The generational genetic algorithm is omitted in the study due to its bad performance. GADEGD, CHC and Micro-GA make a huge improvement to the initial solutions. However, after some iterations, they find more difficulties since the proportion of better chromosomes in the solutions space is getting smaller. At this point the exploitation of the best solutions\u2019 neighborhood and the capability to find new potential chromosomes are the most important qualities. The three algorithms have characteristics that help to achieve these purposes. However, Micro-GA\u2019s small population can be an encumbrance to fully achieve these qualities, being the algorithm with the worst performance. Furthermore, the reinitialization of both CHC and Mircro-GA makes the algorithm to start the search again, losing time in the process. GADEGD does not have these problems and it does actually find better solutions after 25 seconds, not falling into local optimums.\n16 ANDRE\u0301S HERRERA-POYATOS 1 AND FRANCISCO HERRERA 1,2\nFigure 4 shows how the population diversity evolves for the four algorithms studied: GADEGD, a generational GA and both CHC and Micro-GA with greedy reinitialization. The data corresponds to the execution given in Figure 3. Each value is computed as the mean of the diversity in an interval of time. As we showed before, the generational genetic algorithm can not maintain a suitable diversity. On the other hand, GADEGD, CHC and Micro-GA present similar diversity in average thanks to the diversification and reinitialization operators. Note that the reinitialization procedure makes radical changes in the population and, as a consequence, the real diversity (not average) varies from zero to high values throughout the CHC and Micro-GA execution."}, {"heading": "GENETIC AND MEMETIC ALGORITHM WITH DIVERSITY EQUILIBRIUM BASED ON GREEDY DIVERSIFICATION 17", "text": "3.4.3. GADEGD\u2019s components analysis. One could wonder if GADEGD would perform equally well introducing random solutions in the diversification operator instead of greedy ones, what would increase the diversity even more. However, this model does not achieve the same results in practice. As we pointed out in Section 3.2, greedy solutions contains a high quality genetic material that is transferred to its children and, after a few generations, spread to the whole population. The good performance of the hybridization between greedy and genetic algorithms is corroborated in Section 3.4.2, where we compared a reinitialization with greedy solutions with a randomized reinitialization for CHC and Micro-GA.\nAnother important question is how the greedy diversification does actually influence the algorithm\u2019s performance. Table 2 showed that this mechanism generates between 2 and 5 per cent of the solutions for g = Id, what is an considerable amount of solutions. We introduce Table 6 in order to check if these solutions were important for the algorithm\u2019s results.\nFirst, we have executed GADEGD without the greedy diversification operator. As one could expect, the algorithm\u2019s high pressure with no diversification scheme implies a very fast convergence and, thus, very poor results. Secondly, we have applied the greedy diversification\n18 ANDRE\u0301S HERRERA-POYATOS 1 AND FRANCISCO HERRERA 1,2\nto the generational genetic algorithm given in Algorithm 2. The results prove that the greedy diversification makes a huge positive impact in genetic algorithms\u2019 performance. However, as we indicated in Section 3.2, the synergy among the components of this model was improvable in theory. The results also show that this synergy was increased in the GADEGD algorithm, which obtains the best results in 17 out of 18 instances.\nThe competition between parent and children plays a crucial role in using the diversity efficiently since it allows to select and exploit the most promising region of the solutions\u2019 space. If an usual elitism is used instead of the competition scheme in GADEGD, then the diversity is not properly controlled and the algorithm results are not good enough as it is shown in Table 7. This table also includes the results obtained from a GADEGD version in which the binary tournament selection replaces the randomized adjacent selection. In this case the pressure applied to the population is excessive and the population diversity is partially lost, as we explained in Section 3.3. Consequently, it can not reach the performance of GADEGD."}, {"heading": "GENETIC AND MEMETIC ALGORITHM WITH DIVERSITY EQUILIBRIUM BASED ON GREEDY DIVERSIFICATION 19", "text": "In summary, each GADEGD\u2019s component is relevant for the algorithm\u2019s performance. The cooperation among all the introduced components allows to achieve a healthy diversity and an equilibrium between exploration and exploitation."}, {"heading": "4. Memetic algorithm with diversity equilibrium based on greedy diversification", "text": "In this section we extend GADEGD to the field of memetic algorithms. First, we argue how to define this new metaheuristic, called MADEGD. Secondly, we develop an experimental study in which MADEGD\u2019s behaviour is analysed and compared with other state of the art heuristics based on local search.\n4.1. Memetic algorithm with diversity equilibrium based on greedy diversification. MADEGD is obtained when GADEGD is hybridized with a local search procedure, as it is done in memetic algorithms. In Section 2.2 we argued that a good hybridization is applying the local search once per iteration to the best population\u2019s chromosome that has not been improved before. Hence, we use this scheme in MADEGD. However, we must decide whether the greedy diversification operator is applied before of after the local search. We choose to use the greedy diversification first in order to avoid that a repeated solution introduced by a crossover is improved.\nAnother important question is how to initialize the population. If the population were randomly chosen, then the local search would be applied to very low quality solution in the initial iterations, what consumes too much time. Therefore, we initialize the population with solutions obtained by a greedy randomized algorithm as we did in Algorithm 3.\nLastly, GADEGD has two parameters, the characteristic function and the population size. GADEGD obtained the best results when the characteristic function was g = Id. Hence, we use this function in MADEGD. The population size is analyzed in Section 4.2.1.\nAlgorithm 10 Memetic algorithm with diversity equilibrium based on greedy diversification\nRequire: The population size, named n. 1: Initialize P0 with n solutions obtained by a greedy randomized algorithm. 2: t\u2190 0 3: while stopping criteria is not achieved do 4: Pt+1 \u2190 BuildNewPopulationGADEGD(Pt) 5: Pt+1 \u2190 GreedyDiversification(Pt+1, Id) 6: Apply the local search to the best solution not previously improved of P t+1 (if it exits). 7: t\u2190 t + 1 8: end while 9: return bs(Pt)\nAlgorithm 10 shows the pseudo-code of MADEGD. Note that if a greedy solution is added to MADEGD\u2019s population, then it will be crossed with the population\u2019s solutions (which are presumably better) until it is good enough to be improved by the local search. Consequently, the algorithm is finding potential chromosomes which are in the path between various greedy and high quality population\u2019s solutions. This fact will allow the local search to perform the best it is able to.\nThe application of MADEGD to the traveling salesman problem is straightforward. The greedy randomized algorithm is the same used in the greedy diversification (see Section 3.2). Furthermore, we use Lin-Kernighan as the local search procedure.\n20 ANDRE\u0301S HERRERA-POYATOS 1 AND FRANCISCO HERRERA 1,2\n4.2. Experimental analysis. The experimental analysis contains 3 subsections. First, we study how the population size affects MADEGD. Secondly, we compare it with GADEGD in order to understand how the local search change the algorithm\u2019s behaviour, contrasting its better performance. Thirdly, MADEGD is matched against another memetic algorithm, GRASP and iterated greedy from a triple perspective, solutions quality, population diversity and calls to the local search.\n4.2.1. Analysis of the population size. In Section 3.4.1 we mentioned how important the population size is for a genetic algorithm. The same arguments are valid in the field of memetic algorithms. Table 8 contains the results obtained by MADEGD with population sizes 8, 16, 32 and 64. Note that the performance is better when the population is smaller. The reason is that most of the computational time is wasted in the local search. Consequently, less iterations of the genetic operators are applied and a higher pressure is needed, what is provided by the smaller population size.\nWe have executed the algorithm with greater execution times concluding that the size 8 is not good enough because it does not provide sufficient exploration of the solutions space. As a consequence, we propose 16 as the standard population size for MADEGD."}, {"heading": "GENETIC AND MEMETIC ALGORITHM WITH DIVERSITY EQUILIBRIUM BASED ON GREEDY DIVERSIFICATION 21", "text": "Note that population based heuristics usually need a bigger population to avoid premature convergence. However, MADEGD does not necessary needs a big size thanks to the greedy diversification.\n4.2.2. Comparison with the genetic algorithm with diversity equilibrium based on greedy diversification. Table 9 presents the results obtained by MADEGD and GADEGD with population sizes 16 and 64 respectively. The mean objective value of the solutions obtained by MADEGD is drastically better, what shows how effective is the local search combined with the genetic operators and the greedy diversification. In fact, MADEGD finds the optimum solutions in most instances.\nIn Section 3.4.1 it was noticed that GADEGD needs 64 as the population size to keep an equilibrium between exploration and exploitation. However, as it is pointed out previously, MADEGD requires a smaller population because it performs less iterations. This statement is corroborated in Table 9, which provides the average number of solutions computed in each instance by both algorithms. GADEGD generates between 10 and 50 more solutions than MADEGD. However, MADEGD iterations are much more effective thanks to the local search.\nTable 9. MADEGD vs GADEGD with population sizes 16 y 64 respectively. The execution time is 0.1m seconds. The best results are highlighted in bold and the worst are underlined. The last row indicates the number of times that each model got the best result in any instance.\nProblem Optimum Mean objective value Number of generated solutions\nMADEGD GADEGD MADEGD GADEGD\neil51 426 426.167 427.267 128759 1692820 berlin52 7542 7542 7572.57 46387.8 1731320 st70 675 675 682.067 114622 1674870 eil76 538 538 549.5 127619 1740730 pr76 108159 108159 109395 60987.1 1377370 kroA100 21282 21282 21352.5 51970.3 14260 rd100 7910 7910 7919.47 54622.7 1473510 eil101 629 629 633.3 92876.7 1407060 lin105 14379 14379 14430.5 34887.5 538391 ch150 6528 6541.5 6578.67 50950 1270930 rat195 2323 2329.4 2386.83 47671 379744 d198 15780 15801.4 16053.9 16071.4 362111 ts225 126643 126794 127427 53980.6 724328 a280 2579 2582.8 2704.5 45372.8 612916 lin318 42029 42300 43739.5 10964.5 485157 fl417 11861 11940.8 12303.9 5499.87 422658 pcb442 50778 51257.1 55502 16309 231215 rat575 6773 6874.23 7670.97 3522.03 125132\n18 0\n22 ANDRE\u0301S HERRERA-POYATOS 1 AND FRANCISCO HERRERA 1,2\n4.2.3. Comparison with other local search based multi-start metaheuristics. Local search based multi-start metaheuristics try to apply the local search to promising solutions placed in different regions of the search space. Consequently, they require an underneath procedure which supplies high quality and diverse solutions on which local search will be executed. Hence, local search based metaheuristics can be understood as an hybridization between local search and other heuristics.\nMemetic algorithms are local search based multi-start metaheuristics in which the local search is applied to new solutions obtained by the evolutionary operators. This hybridization presents several advantages. First, the evolution scheme guarantees that the local search will be applied to better solutions as time passes. Secondly, the solutions obtained by the local search contain some information which can be used in the evolutionary algorithm\u2019s iterations, obtaining a better performance. However, if the evolutionary scheme doesn\u2019t pay enough attention to the exploration, then the local search is applied to similar solutions over and over. Consequently, it might always find the same local optimums and the computation time is wasted. Hence, the evolutionary scheme should have a good equilibrium between exploration and exploitation in order to obtain a high performance memetic algorithm.\nOther local search based multi-start metaheuristics, such as GRASP [4] and iterated greedy [23], [10], use techniques founded on randomized greedy algorithms. Greedy solutions are placed in promising regions of the solutions space and, thus, the local search is highly productive on them.\nAlgorithm 11 describes how GRASP works, at each iteration a greedy solution is obtained by a randomized greedy algorithm and it is improved by the local search. The best solution found is returned at the end of the algorithm.\nAlgorithm 11 GRASP\n1: while stopping criteria is not achieved do 2: s\u2190 GreedyRandomizedAlgorithm() 3: s\u2032 \u2190 LocalSearch(s) 4: if s\u2032 is the best solution found then 5: best solution\u2190 s\u2032 6: end if 7: end while 8: return best solution\nGRASP does not use the information obtained in the past computations, its iterations are independent and equally productive in average. Iterated greedy try to overcome this issue modifying a previously visited solution with a greedy technique in order to create new elements of the solution space. Algorithm 12 provides an usual implementation of iterated greedy. At each step, a destruction procedure is applied to the best solution found. The destruction procedure removes a subset of the solution\u2019s data, obtaining a partial solution. Afterwards, the partial solution is reconstructed by a randomized greedy technique and the obtained solution is improved by the local search.\nParticularizing in the traveling salesman problem, the destruction procedure consist in removing a random sublist of the solution\u2019s representation. The reconstruction step is carried out by the randomized greedy algorithm based on the nearest neighbor philosophy which was introduced in Section 3.2. We have implemented GRASP and iterated greedy using Lin-Kernighan as the local search procedure.\nNote that the destruction - reconstruction step of iterated greedy can be understood as a crossover between the best solution found and a greedy solution. Thus, we can see iterated greedy as an hybridization between greedy and memetic algorithms. From this perspective the"}, {"heading": "GENETIC AND MEMETIC ALGORITHM WITH DIVERSITY EQUILIBRIUM BASED ON GREEDY DIVERSIFICATION 23", "text": "Algorithm 12 Iterated Greedy\n1: best solution\u2190 GreedyRandomizedAlgorithm() 2: best solution\u2190 LocalSearch(best solution) 3: while stopping criteria is not achieved do 4: s\u2190 Destruction(best solution) 5: s\u2032 \u2190 RandomizedGreedyReconstruction(s) 6: s\u2032\u2032 \u2190 LocalSearch(s\u2032) 7: if s\u2032\u2032 is the best solution found then 8: best solution\u2190 s\u2032\u2032 9: end if\n10: end while 11: return best solution\nmodel is improvable in terms of exploration and exploitation. The population size is 1 and, thus, it usually operates in the same region of the search space. Furthermore, the local search is always applied in each iteration even if the obtained solution is not good enough. Hence, we can conclude that iterated greedy is more focused on exploitation than on exploration.\nMADEGD is also an hybridization between greedy and memetic algorithms. However, it combines the best of both worlds. The greedy diversification promotes the exploration of the promising regions of the search space when it is needed. Furthermore, the competition\n24 ANDRE\u0301S HERRERA-POYATOS 1 AND FRANCISCO HERRERA 1,2\nbetween parent and children control the population\u2019s quality and, as a consequence, the local search is likely applied to better solutions each iteration. As we mentioned before, if a greedy solution enters in the population, then it will get crossed with better chromosomes until it is good enough to be improved by the local search.\nThis synergy is the reason behind the results presented in Table 10, which compares the performance of MADEGD, the memetic algorithm given in Algorithm 3 (MA), GRASP and iterated greedy (IG). MADEGD loosely obtains the best result in every instance. MA also outperforms GRASP and IG thanks to the evolutionary character. Note that GADEGD\u2019s results are better than the MA\u2019s ones in instances with less than 110 cities (see Table 9) in spite of implementing a version of Lin-Kernighan as the local search, one of the best heuristics for the travelling salesman problem.\nTable 11 provides the average number of calls to the local search in Table 10\u2019s executions. MA is the heuristic which presents more calls to the local search. This fact is due to the population convergence, the local search is much faster because the solutions to which it is applied are near to local optimums. GRASP and IG are the algorithms with less number of calls to the local search. Each iteration of those algorithms consists in applying the local search to a greedy or partially greedy solution, what is very time consuming since there is a lot of room for optimization. MADEGD mixes the best of both worlds again since it constantly explores the search space but the local search is only applied to the best possible solutions.\nThe number of calls to the local search of GRASP and IG is equal to the number of generated solutions. However, both MA and MADEGD just apply the local search in an iteration if there is a solution no previously improved by the local search. Table 11 also shows the percent of iterations in which the local search was applied to a population\u2019s solution for both memetic algorithms. MA always applies the local search since the population is almost fully generated by the crossover operator. However, MADEGD, after a fair number of iterations, only applies the local search if a new solution has entered the population after the competition between parent and children. Nonetheless, the percent is always greater than 85%, what shows that the crossover operator is able to find better chromosomes than the"}, {"heading": "GENETIC AND MEMETIC ALGORITHM WITH DIVERSITY EQUILIBRIUM BASED ON GREEDY DIVERSIFICATION 25", "text": "parents. This fact is essential for the algorithm\u2019s good behavior since if the crossover were not good enough, then no solution would enter the population and the algorithm would converge to a local optimum.\nFinally, Figure 5 shows how the diversity evolves in an execution of MADEGD and the memetic algorithm. It is very similar to Figure 2. The memetic algorithm converges too fast to a local optimum, what avoids a proper exploration of the search space."}, {"heading": "5. Conclusion", "text": "In this paper we have introduced a novel genetic algorithm, GADEGD, which attempts to achieve a balance between exploration and exploitation. The algorithm\u2019s key operator is the greedy diversification, which maintains a diversity equilibrium in the population. Furthermore, the algorithm uses the randomized adjacent selection and a competition between parent and children. These operators have been selected in order to increase the components\u2019 synergy.\nWe have also extended the algorithm to the field of memetic algorithms, MADEGD, obtaining a more competitive metaheuristic which outperforms a generational memetic algorithm, GRASP and iterated greedy in our studies.\nThe greedy diversification has been proved to be a relevant operator for designing population based metaheuristics and, in particular, genetic and memetic algorithms. An heuristic\n26 ANDRE\u0301S HERRERA-POYATOS 1 AND FRANCISCO HERRERA 1,2\nwhich uses this operator has much more facilities to constantly keep a high quality and diverse population, what can not be achieved by the widely used mutation operator.\nThe developed work reaffirms our initial assertions, the equilibrium between exploration and exploitation and the diversity problem should be taken into account when designing genetic and memetic algorithms. Hybridization helps to solve both problems, providing exploration and exploitation mechanisms to evolutionary algorithms.\nFinally, we believe that the proposed metaheuristics and operators can be fruitfully applied to high dimensional or large scale problems [15], [19], where memetic algorithms are one of the most powerful metaheuristics. These problem require a careful exploration of the search space and an effective exploitation of the best solutions found. Therefore, as a future work we will be extending the current results to the large scale framework.\nReferences\n[1] I. Boussa\u0308\u0131d, J. Lepagnot, and P. Siarry. \u201cA survey on optimization metaheuristics.\u201d In: Information Sciences 237 (2013), pp. 82\u2013117. [2] M. Crepinsek, S. H. Liu, and M. Mernik. \u201cExploration and exploitation in evolutionary algorithms: a survey\u201d. In: ACM Computing Surveys 45 (2013), p. 35. [3] L. J. Eshelman. \u201cThe CHC adaptive search algorithm: How to have safe search when engaging in nontraditional genetic recombination\u201d. In: Foundations of genetic algorithms (1991), pp. 265\u2013283. [4] T. A. Feo and M. G. Resende. \u201cGreedy randomized adaptive search procedures\u201d. In: Journal of global optimization 6 (1995), pp. 109\u2013133. [5] N. Forbes. Imitation of life: how biology is inspiring computing. Cambridge: Mit Press, 2004. [6] Brian Mc Ginley et al. \u201cMaintaining healthy population diversity using adaptive crossover, mutation, and selection\u201d. In: IEEE Transactions on Evolutionary Computation 15 (2011), pp. 692\u2013714. [7] D. E. Goldberg. Genetic Algorithms in Search, Optimization & Machine Learning. Addison-Wesley, Reading, MA, 1989. [8] D. E. Goldberg and K. Deb. \u201cA comparative analysis of selection schemes used in genetic algorithms\u201d. In: Foundations of Genetic Algorithms (1991), pp. 69\u201393. [9] Gregory Gutin and Abraham P. Punnen, eds. The traveling salesman problem and its variations. Springer Science & Business Media, 2006.\n[10] K. Karabulut and M. F. Tasgetiren. \u201cA variable iterated greedy algorithm for the traveling salesman problem with time windows\u201d. In: Information Sciences 279 (2014), pp. 383\u2013 395. [11] D. Karapetyan and G. Gutin. \u201cLin-Kernighan heuristic adaptations for the generalized traveling salesman problem\u201d. In: European Journal of Operational Research 208 (2011), pp. 221\u2013232. [12] N. Krasnogor and J. Smith. \u201cA tutorial for competent memetic algorithms: model, taxonomy, and design issues\u201d. In: IEEE Transactions on Evolutionary Computation 9 (2005), pp. 474\u2013488. [13] K. Krishnakumar. \u201cMicro-genetic algorithms for stationary and non-stationary function optimization\u201d. In: Advances in Intelligent Robotics Systems Conference, International Society for Optics and Photonics (1990), pp. 289\u2013296. [14] P. Larran\u0303aga et al. \u201cGenetic algorithms for the travelling salesman problem: A review of representations and operators\u201d. In: Artificial Intelligence Review 13 (1999), pp. 129\u2013 170.\nREFERENCES 27\n[15] Miguel Lastra, Daniel Molina, and Jose\u0301 Manuel Ben\u0301\u0131tez. \u201cA high performance memetic algorithm for extremely high-dimensional problems\u201d. In: Information Sciences 293 (2015), pp. 35\u201358. [16] E. L. Lawler et al. The traveling salesman problem: a guided tour of combinatorial optimization. New York: Wiley, 1985. [17] S. Lin and B. W. Kernighan. \u201cAn effective heuristic algorithm for the traveling-salesman problem\u201d. In: Operations research 21 (1973), pp. 498\u2013516. [18] M. Lozano and C. Garc\u0301\u0131a-Mart\u0301\u0131nez. \u201cHybrid metaheuristics with evolutionary algorithms specializing in intensification and diversification: Overview and progress report\u201d. In: Computers & Operations Research 37 (2010), pp. 481\u2013497. [19] Sedigheh Mahdavi, Mohammad Ebrahim Shiri, and Shahryar Rahnamayan. \u201cMetaheuristics in large-scale global continues optimization: A survey\u201d. In: Information Sciences 295 (2015), pp. 407\u2013428. [20] G. Reinelt. \u201cTSPLIB - A traveling salesman problem library\u201d. In: ORSA Journal on Computing 3 (1991), pp. 376\u2013384. url: http://www.iwr.uni-heidelberg.de/groups/ comopt/software/TSPLIB95/index.html. [21] F. J. Rodriguez, C. Garcia-Martinez, and M. Lozano. \u201cHybrid metaheuristics based on evolutionary algorithms and simulated annealing: taxonomy, comparison, and synergy test\u201d. In: IEEE Transactions on Evolutionary Computation 16 (2012), pp. 787\u2013800. [22] G. Rudolph. \u201cConvergence analysis of canonical genetic algorithms\u201d. In: IEEE Transactions on Neural Networks 5 (1994), pp. 96\u2013101. [23] R. Ruiz and T. Stu\u0308tzle. \u201cA simple and effective iterated greedy algorithm for the permutation flowshop scheduling problem\u201d. In: European Journal of Operational Research 177 (2007), pp. 2033\u20132049. [24] A. Simoes and E. Costa. \u201cCHC-based algorithms for the dynamic traveling salesman problem\u201d. In: Applications of Evolutionary Computation Volume 6624 of the series Lecture Notes in Computer Science (2011), pp. 354\u2013363. [25] Moshe Sipper. \u201cNotes on the origin of evolutionary computation.\u201d In: Complexity 4 (1999), pp. 15\u201321. [26] R. Storn and K. Price. \u201cDifferential evolution - a simple and efficient heuristic for global optimization over continuous spaces\u201d. In: Journal of global optimization 11 (1997), pp. 341\u2013359. [27] E. G. Talbi. Metaheuristics: from design to implementation. John Wiley & Sons, 2009. [28] T. Weise et al. \u201cBenchmarking optimization algorithms: an open source framework\nfor the traveling salesman problem\u201d. In: IEEE Computational Intelligence Magazine 9 (2014), pp. 40\u201352.\n[29] N. Xiong et al. \u201cA Walk into Metaheuristics for Engineering Optimization: Principles, Methods and Recent Trends\u201d. In: International Journal of Computational Intelligence Systems 8 (2015), pp. 606\u2013636. [30] Xin She Yang. Nature-Inspired Metaheuristic Algorithms: Second Edition. Luniver Press, 2010."}], "references": [{"title": "Be\u0144\u0131tez. \u201cA high performance memetic algorithm for extremely high-dimensional problems", "author": ["Miguel Lastra", "Daniel Molina", "Jos\u00e9 Manuel"], "venue": "Information Sciences", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2015}, {"title": "The traveling salesman problem: a guided tour of combinatorial optimization", "author": ["E.L. Lawler"], "venue": "New York: Wiley,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 1985}, {"title": "An effective heuristic algorithm for the traveling-salesman problem", "author": ["S. Lin", "B.W. Kernighan"], "venue": "In: Operations research", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 1973}, {"title": "Gar\u0107\u0131a-Mart\u0301\u0131nez. \u201cHybrid metaheuristics with evolutionary algorithms specializing in intensification and diversification: Overview and progress report", "author": ["C.M. Lozano"], "venue": "Computers & Operations Research", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2010}, {"title": "Metaheuristics in large-scale global continues optimization: A survey", "author": ["Sedigheh Mahdavi", "Mohammad Ebrahim Shiri", "Shahryar Rahnamayan"], "venue": "Information Sciences", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2015}, {"title": "TSPLIB - A traveling salesman problem library", "author": ["G. Reinelt"], "venue": "ORSA Journal on Computing", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 1991}, {"title": "Hybrid metaheuristics based on evolutionary algorithms and simulated annealing: taxonomy, comparison, and synergy test", "author": ["F.J. Rodriguez", "C. Garcia-Martinez", "M. Lozano"], "venue": "IEEE Transactions on Evolutionary Computation", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2012}, {"title": "Convergence analysis of canonical genetic algorithms", "author": ["G. Rudolph"], "venue": "IEEE Transactions on Neural Networks", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 1994}, {"title": "A simple and effective iterated greedy algorithm for the permutation flowshop scheduling problem", "author": ["R. Ruiz", "T. St\u00fctzle"], "venue": "European Journal of Operational Research", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2007}, {"title": "CHC-based algorithms for the dynamic traveling salesman problem", "author": ["A. Simoes", "E. Costa"], "venue": "Notes in Computer Science", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2011}, {"title": "Notes on the origin of evolutionary computation.", "author": ["Moshe Sipper"], "venue": "In: Complexity", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 1999}, {"title": "Differential evolution - a simple and efficient heuristic for global optimization over continuous spaces", "author": ["R. Storn", "K. Price"], "venue": "Journal of global optimization", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 1997}, {"title": "Metaheuristics: from design to implementation", "author": ["E.G. Talbi"], "venue": null, "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2009}, {"title": "Benchmarking optimization algorithms: an open source framework for the traveling salesman problem", "author": ["T. Weise"], "venue": "IEEE Computational Intelligence Magazine", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 2014}, {"title": "A Walk into Metaheuristics for Engineering Optimization: Principles, Methods and Recent Trends", "author": ["N. Xiong"], "venue": "In: International Journal of Computational Intelligence Systems", "citeRegEx": "29", "shortCiteRegEx": "29", "year": 2015}, {"title": "Nature-Inspired Metaheuristic Algorithms: Second Edition", "author": ["Xin She Yang"], "venue": null, "citeRegEx": "30", "shortCiteRegEx": "30", "year": 2010}], "referenceMentions": [], "year": 2017, "abstractText": "The lack of diversity in a genetic algorithm\u2019s population may lead to a bad performance of the genetic operators since there is not an equilibrium between exploration and exploitation. In those cases, genetic algorithms present a fast and unsuitable convergence. In this paper we develop a novel hybrid genetic algorithm which attempts to obtain a balance between exploration and exploitation. It confronts the diversity problem using the named greedy diversification operator. Furthermore, the proposed algorithm applies a competition between parent and children so as to exploit the high quality visited solutions. These operators are complemented by a simple selection mechanism designed to preserve and take advantage of the population diversity. Additionally, we extend our proposal to the field of memetic algorithms, obtaining an improved model with outstanding results in practice. The experimental study shows the validity of the approach as well as how important is taking into account the exploration and exploitation concepts when designing an evolution-", "creator": "LaTeX with hyperref package"}}}