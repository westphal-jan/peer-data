{"id": "1702.07285", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "23-Feb-2017", "title": "Are Emojis Predictable?", "abstract": "Emojis are ideograms which are naturally combined with plain text to visually complement or condense the meaning of a message. Despite being widely used in social media, their underlying semantics have received little attention from a Natural Language Processing standpoint. In this paper, we investigate the relation between words and emojis, studying the novel task of predicting which emojis are evoked by text-based tweet messages. We train several models based on Long Short-Term Memory networks (LSTMs) in this task. Our experimental results show that our neural model outperforms two baselines as well as humans solving the same task, suggesting that computational models are able to better capture the underlying semantics of emojis.\n\n\n\n\n\n\nThe paper highlights the significant differences in understanding the effect of word and message processing in humans and non-human primates. One of the main differences is that words can be interpreted without changing the meaning of words, while words can be interpreted as words. Using the language-based model, we used a novel task, which uses the word sentence-to-word model, which uses a text-based model. It has been hypothesized that words could be interpreted as sentences instead of sentences. As expected, we used a novel task to predict what word and sentence will be interpreted as words, but not as words. In addition to this, we used a novel task to predict what word and sentence will be interpreted as words and sentence will be interpreted as words. As the authors of this paper reported, the word sentence-to-word model is able to capture the meaning of words, so that words can be interpreted as words. However, our results suggest that words can be interpreted as words instead of sentences.", "histories": [["v1", "Thu, 23 Feb 2017 16:47:01 GMT  (316kb,D)", "https://arxiv.org/abs/1702.07285v1", "To appear at EACL 2017"], ["v2", "Fri, 24 Feb 2017 12:59:19 GMT  (316kb,D)", "http://arxiv.org/abs/1702.07285v2", "To appear at EACL 2017"]], "COMMENTS": "To appear at EACL 2017", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["francesco barbieri", "miguel ballesteros", "horacio saggion"], "accepted": false, "id": "1702.07285"}, "pdf": {"name": "1702.07285.pdf", "metadata": {"source": "CRF", "title": "Are Emojis Predictable?", "authors": ["Francesco Barbieri", "Miguel Ballesteros", "Horacio Saggion"], "emails": ["horacio.saggion}@upf.edu", "miguel.ballesteros@ibm.com"], "sections": [{"heading": "1 Introduction", "text": "The advent of social media has brought along a novel way of communication where meaning is composed by combining short text messages and visual enhancements, the so-called emojis. This visual language is as of now a de-facto standard for online communication, available not only in Twitter, but also in other large online platforms such as Facebook, Whatsapp, or Instagram.\nDespite its status as language form, emojis have been so far scarcely studied from a Natural Language Processing (NLP) standpoint. Notable exceptions include studies focused on emojis\u2019 semantics and usage (Aoki and Uchida, 2011; Barbieri et al., 2016a; Barbieri et al., 2016b; Barbieri et al., 2016c; Eisner et al., 2016; Ljubes\u030cic and Fis\u030cer, 2016), or sentiment (Novak et al., 2015). However, the interplay between text-based messages\nand emojis remains virtually unexplored. This paper aims to fill this gap by investigating the relation between words and emojis, studying the problem of predicting which emojis are evoked by textbased tweet messages.\nMiller et al. (2016) performed an evaluation asking human annotators the meaning of emojis, and the sentiment they evoke. People do not always have the same understanding of emojis, indeed, there seems to exist multiple interpretations of their meaning beyond their designer\u2019s intent or the physical object they evoke1. Their main conclusion was that emojis can lead to misunderstandings. The ambiguity of emojis raises an interesting question in human-computer interaction: how can we teach an artificial agent to correctly interpret and recognise emojis\u2019 use in spontaneous conversation?2 The main motivation of our research is that an artificial intelligence system that is able to predict emojis could contribute to better natural language understanding (Novak et al., 2015) and thus to different natural language processing tasks such as generating emoji-enriched social media content, enhance emotion/sentiment analysis systems, and improve retrieval of social network material.\nIn this work, we employ a state of the art classification framework to automatically predict the most likely emoji a Twitter message evokes. The model is based on Bidirectional Long Short-term Memory Networks (BLSTMs) with both standard lookup word representations and character-based representation of tokens. We will show that the BLSTMs outperform a bag of words baseline, a baseline based on semantic vectors, and human annotators in this task.\n1https://www.washingtonpost.com/news/theintersect/wp/2016/02/19/the-secret-meanings-of-emoji/\n2http://www.dailydot.com/debug/emojimiscommunicate/\nar X\niv :1\n70 2.\n07 28\n5v 2\n[ cs\n.C L\n] 2\n4 Fe\nb 20\n17"}, {"heading": "100.7 89.9 59 33.8 28.6 27.9 22.5 21.5 21 20.8", "text": ""}, {"heading": "2 Dataset and Task", "text": "Dataset: We retrieved 40 million tweets with the Twitter APIs3. Tweets were posted between October 2015 and May 2016 geo-localized in the United States of America. We removed all hyperlinks from each tweet, and lowercased all textual content in order to reduce noise and sparsity. From the dataset, we selected tweets which include one and only one of the 20 most frequent emojis, resulting in a final dataset4 composed of 584,600 tweets. In the experiments we also consider the subsets of the 10 (502,700 tweets) and 5 most frequent emojis (341,500 tweets). See Table 1 for the 20 most frequent emojis that we consider in this work. Task: We remove the emoji from the sequence of tokens and use it as a label both for training and testing. The task for our machine learning models is to predict the single emoji that appears in the input tweet."}, {"heading": "3 Models", "text": "In this Section, we present and motivate the models that we use to predict an emoji given a tweet. The first model is an architecture based on Recurrent Neural Networks (Section 3.1) and the second and third are the two baselines (Section 3.2.1 and 3.2.2). The two major differences between the RNNs and the baselines, is that the RNNs take into account sequences of words and thus, the entire context."}, {"heading": "3.1 Bi-Directional LSTMs", "text": "Given the proven effectiveness and the impact of recurrent neural networks in different tasks (Chung et al., 2014; Vinyals et al., 2015; Dzmitry et al., 2014; Dyer et al., 2015; Lample et al., 2016; Wang et al., 2016, inter-alia), which also includes modeling of tweets (Dhingra et al., 2016), our emoji prediction model is based on bi-directional\n3https://dev.twitter.com 4Available at http://sempub.taln.upf.edu/tw/eacl17\nLong Short-term Memory Networks (Hochreiter and Schmidhuber, 1997; Graves and Schmidhuber, 2005). The B-LSTM can be formalized as follows:\ns = max {0,W[fw;bw] + d}\nwhere W is a learned parameter matrix, fw is the forward LSTM encoding of the message, bw is the backward LSTM encoding of the message, and d is a bias term, then passed through a componentwise ReLU. The vector s is then used to compute the probability distribution of the emojis given the message as:\np(e | s) = exp\n( g>e s+ qe )\u2211 e\u2032\u2208E exp ( g>e\u2032s+ qe\u2032\n) where ge\u2032 is a column vector representing the (output) embedding5 of the emoji e, and qe is a bias term for the emoji e. The set E represents the list of emojis. The loss/objective function the network aims to minimize is the following:\nLoss = \u2212log(p(em | s))\nwhere m is a tweet of the training set T , s is the encoded vector representation of the tweet and em is the emoji contained in the tweet m . The inputs of the LSTMs are word embeddings6. Following, we present two alternatives explored in the experiments presented in this paper. Word Representations: We generate word embeddings which are learned together with the updates to the model. We stochastically replace (with p = 0.5) each word that occurs only once in the training data with a fixed represenation (outof-vocabulary words vector). When we use pretrained word embeddings, these are concatenated with the learned vector representations obtaining a final representation for each word type. This is similar to the treatment of word embeddings by Dyer et al. (2015). Character-based Representations: We compute character-based continuous-space vector embeddings (Ling et al., 2015b; Ballesteros et al., 2015) of the tokens in each tweet using, again, bidirectional LSTMs. The character-based approach learns representations for words that are orthographically similar, thus, they should be able to handle different alternatives of the same word type occurring in social media.\n5The output embeddings of the emojis have 100 dimensions.\n6100 dimensions."}, {"heading": "3.2 Baselines", "text": "In this Section we describe the two baselines. Unlike the previous model, the baselines do not take into account the word order. However, in the second baseline (Section 3.2.2) we abstract on the plain word representation using semantic vectors, previously trained on Twitter data."}, {"heading": "3.2.1 Bag of Words", "text": "We applied a bag of words classifier as baseline, since it has been successfully employed in several classification tasks, like sentiment analysis and topic modeling (Wallach, 2006; Blei, 2012; Titov and McDonald, 2008; Maas et al., 2011; Davidov et al., 2010). We represent each message with a vector of the most informative tokens (punctuation marks included) selected using term frequency\u2212inverse document frequency (TFIDF). We employ a L2-regularized logistic regression classifier to make the predictions."}, {"heading": "3.2.2 Skip-Gram Vector Average", "text": "We train a Skip-gram model (Mikolov et al., 2013) learned from 65M Tweets (where testing instances have been removed) to learn Twitter semantic vectors. Then, we build a model (henceforth, AVG) which represents each message as the average of the vectors corresponding to each token of the tweet. Formally, each message m is represented with the vector Vm :\nV m =\n\u2211 t\u2208Tm St\n|Tm|\nWhere Tm are the set of tokens included in the message m , St is the vector of token t in the Skipgram model, and |Tm | is the number of tokens in m . After obtaining a representation of each message, we train a L2-regularized logistic regression, (with \u03b5 equal to 0.001)."}, {"heading": "4 Experiments and Evaluation", "text": "In order to study the relation between words and emojis, we performed two different experiments. In the first experiment, we compare our machine learning models, and in the second experiment, we pick the best performing system and compare it against humans."}, {"heading": "4.1 First Experiment", "text": "This experiment is a classification task, where in each tweet the unique emoji is removed and\nused as a label for the entire tweet. We use three datasets, each containing the 5, 10 and 20 most frequent emojis (see Section 2). We analyze the performance of the five models described in Section 3: a bag of words model, a Bidirectional LSTM model with character-based representations (char-BLSTM), a Bidirectional LSTM model with standard lookup word representations (word-BLSTM). The latter two were trained with/without pretrained word vectors. To pretrain the word vectors, we use a modified skip-gram model (Ling et al., 2015a) trained on the English Gigaword corpus7 version 5.\nWe divide each dataset in three parts, training (80%), development (10%) and testing (10%). The three subsets are selected in sequence starting from the oldest tweets and from the training set since automatic systems are usually trained on past tweets, and need to be robust to future topic variations.\nTable 2 reports the results of the five models and the baseline. All neural models outperform the baselines in all the experimental setups. However, the BOW and AVG are quite competitive, suggesting that most emojis come along with specific words (like the word love and the emoji ). However, considering sequences of words in the models seems important for encoding the meaning of the tweet and therefore contextualize the emojis used. Indeed, the B-LSTMs models always outperform BOW and AVG. The character-based model with pretrained vectors is the most accurate at predicting emojis. The character-based model seems to capture orthographic variants of the same word in social media. Similarly, pretrained vectors allow to initialize the system with unsuper-\n7https://catalog.ldc.upenn.edu/LDC2003T05\nvised pre-trained semantic knowledge (Ling et al., 2015a), which helps to achieve better results.\nQualitative Analysis of Best System: We analyze the performances of the char-BLSTM with pretrained vectors on the 20-emojis dataset, as it resulted to be the best system in the experiment presented above. In Table 3 we report Precision, Recall, F-measure and Ranking8 of each emoji. We also added in the last column the occurrences of each emoji in the test set.\nThe frequency seems to be very relevant. The Ranking of the most frequent emojis is lower than the Ranking of the rare emojis. This means that if an emoji is frequent, it is more likely to be on top of the possible choices even if it is a mistake. On the other hand, the F-measure does not seem to depend on frequency, as the highest F-measures are scored by a mix of common and uncommon emojis ( , , , and ) which are respectively the\n8The Ranking is a number between 1 and 20 that represents the average number of emojis with higher probability than the gold emoji in the probability distribution of the classifier.\nfirst, second, the sixth and the second last emoji in terms of frequencies.\nThe frequency of an emoji is not the only important variable to detect the emojis properly; it is also important whether in the set of emojis there are emojis with similar semantics. If this is the case the model prefers to predict the most frequent emojis. This is the case of the emoji that is almost never predicted, even if the Ranking is not too high (4.69). The model prefers similar but most frequent emojis, like (instead of ). The same behavior is observed for the emoji, but in this case the performance is a bit better due to some specific words used along with the blue heart: \u201cblue\u201d, \u201csea\u201d and words related to childhood (e.g. \u201clittle\u201d or \u201cDisney\u201d).\nAnother interesting case is the Christmas tree emoji , that is present only three times in the test set (as the test set includes most recent tweets and Christmas was already over; this emoji is commonly used in tweets about Christmas). The model is able to recognize it twice, but missing it once. The correctly predicted cases include the word \u201cChristmas\u201d; and it fails to predict: \u201cgetting into the holiday spirit with this gorgeous pair of leggings today ! #festiveleggings\u201d, since there are no obvious clues (the model chooses instead probably because of the intended meaning of \u201choliday\u201d and \u201cgorgeous\u201d.).\nIn general the model tends to confuse similar emojis to and , probably for their higher frequency and also because they are used in multiple contexts. An interesting phenomenon is that is often confused with . The first one represent a small face crying, and the second one a small face laughing, but the results suggest that they appear in similar tweets. The punctuation and tone used is often similar (many exclamation marks and words like \u201comg\u201d and \u201chahaha\u201d). Irony may also play a role to explain the confusion, e.g. \u201cI studied journalism and communications , I\u2019ll be an awesome speller! Wrong. haha so much fun\u201d."}, {"heading": "4.2 Second Experiment", "text": "Given that Miller et al. (2016) pointed out that people tend to give multiple interpretations to emojis, we carried out an experiment in which we evaluated human and machine performances on the same task. We randomly selected 1,000 tweets from our test set of the 5 most frequent emojis used in the previous experiment, and asked\nhumans to predict, after reading a tweet (with the emoji removed), the emoji the text evoked. We opted for the 5 emojis task to reduce annotation efforts. After displaying the text of the tweet, we asked the human annotators \u201cWhat is the emoji you would include in the tweet?\u201d, and gave the possibility to pick one of 5 possible emojis ,\n, , , and . Using the crowdsourcing platform \u2018\u2019CrowdFlower\u201d, we designed an experiment where the same tweet was presented to four annotators (selecting the final label by majority agreement). Each annotator assessed a maximum of 200 tweets. The annotators were selected from the United States of America and of high quality (level 3 of CrowdFlower). One in every ten tweets, was an obvious test question, and annotations from subjects who missed more than 20% of the test questions were discarded. The overall inter-annotator agreement was 73% (in line with previous findings (Miller et al., 2016)). After creating the manually annotated dataset, we compared the human annotation and the char-BLSTM model with the gold standard (i.e. the emoji used in the tweet).\nWe can see in Table 4, where the results of the comparison are presented, that the char-BLSTM performs better than humans, with a F1 of 0.65 versus 0.50. The emojis that the char-BLSTM struggle to predict are and , while the human annotators mispredict and mostly. We can see in the confusion matrix of Figure 1 that is misclassified as by both human and LSTM, and the emoji is mispredicted as and . An interesting result is the number of times was chosen by human annotators; this emoji occurred 100 times (by chance) in the test set, but it was chosen 208 times, mostly when the correct label was the laughing emoji . We do not observe the same be-\nhavior in the char-BLSTMs, perhaps because they encoded information about the probability of these two emojis and when in doubt, the laughing emoji was chosen as more probable."}, {"heading": "5 Conclusions", "text": "Emojis are used extensively in social media, however little is known about their use and semantics, especially because emojis are used differently over different communities (Barbieri et al., 2016a; Barbieri et al., 2016b). In this paper, we provide a neural architecture to model the semantics of emojis, exploring the relation between words and emojis. We proposed for the first time an automatic method to, given a tweet, predict the most probable emoji associated with it. We showed that the LSTMs outperform humans on the same emoji prediction task, suggesting that automatic systems are better at generalizing the usage of emojis than humans. Moreover, the good accuracy of the LSTMs suggests that there is an important and unique relation between sequences of words and emojis.\nAs future work, we plan to make the model able to predict more than one emoji per tweet, and explore the position of the emoji in the tweet, as close words can be an important clue for the emoji prediction task."}, {"heading": "Acknowledgments", "text": "We thank the three reviewers for their time and their useful suggestions. First and third authors acknowledge support from the TUNER project (TIN2015-65308-C5-5-R, MINECO/FEDER, UE) and the Maria de Maeztu Units of Excellence Programme (MDM-2015-0502)."}], "references": [{"title": "A method for automatically generating the emotional vectors of emoticons using weblog articles", "author": ["Aoki", "Uchida2011] Sho Aoki", "Osamu Uchida"], "venue": "In Proceedings of the 10th WSEAS International Conference on Applied Computer and Applied", "citeRegEx": "Aoki et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Aoki et al\\.", "year": 2011}, {"title": "Improved transitionbased parsing by modeling characters instead of words with lstms", "author": ["Chris Dyer", "Noah A. Smith"], "venue": "In Proceedings of the 2015 Conference on Empirical Methods in Natural Lan-", "citeRegEx": "Ballesteros et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Ballesteros et al\\.", "year": 2015}, {"title": "Revealing Patterns of Twitter Emoji Usage in Barcelona and Madrid", "author": ["Luis Espinosa Anke", "Horacio Saggion"], "venue": "In 19 th International Conference of the Catalan Association for Artificial Intelligence,", "citeRegEx": "Barbieri et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Barbieri et al\\.", "year": 2016}, {"title": "2016b. How Cosmopolitan Are Emojis? Exploring Emojis Usage and Meaning over Different Languages with Distributional Semantics", "author": ["German Kruszewski", "Francesco Ronzano", "Horacio Saggion"], "venue": null, "citeRegEx": "Barbieri et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Barbieri et al\\.", "year": 2016}, {"title": "What does this emoji mean? a vector space skip-gram model for twitter emojis", "author": ["Francesco Ronzano", "Horacio Saggion"], "venue": "In Language Resources and Evaluation conference,", "citeRegEx": "Barbieri et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Barbieri et al\\.", "year": 2016}, {"title": "Probabilistic topic models", "author": ["David M Blei"], "venue": "Communications of the ACM,", "citeRegEx": "Blei.,? \\Q2012\\E", "shortCiteRegEx": "Blei.", "year": 2012}, {"title": "Empirical evaluation of gated recurrent neural networks on sequence modeling", "author": ["Chung et al.2014] Junyoung Chung", "Caglar Gulcehre", "KyungHyun Cho", "Yoshua Bengio"], "venue": "arXiv preprint arXiv:1412.3555", "citeRegEx": "Chung et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Chung et al\\.", "year": 2014}, {"title": "Semi-supervised recognition of sarcastic sentences in twitter and amazon", "author": ["Oren Tsur", "Ari Rappoport"], "venue": "In Proceedings of the Fourteenth Conference on Computational Natural Language Learning,", "citeRegEx": "Davidov et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Davidov et al\\.", "year": 2010}, {"title": "Tweet2vec: Character-based distributed representations for social media", "author": ["Zhong Zhou", "Dylan Fitzpatrick", "Michael Muehl", "William Cohen"], "venue": "In Proceedings of the 54th Annual Meeting of the Association", "citeRegEx": "Dhingra et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Dhingra et al\\.", "year": 2016}, {"title": "Transition-based dependency parsing with stack long short-term memory", "author": ["Dyer et al.2015] Chris Dyer", "Miguel Ballesteros", "Wang Ling", "Austin Matthews", "Noah A. Smith"], "venue": "In Proceedings of the 53rd Annual Meeting of the Association", "citeRegEx": "Dyer et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Dyer et al\\.", "year": 2015}, {"title": "Neural machine translation by jointly learning to align and translate", "author": ["Cho Kyunghyun", "Bengio Yoshua"], "venue": "Proceeding of the third International Conference on Learning Representations,", "citeRegEx": "Dzmitry et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Dzmitry et al\\.", "year": 2014}, {"title": "emoji2vec: Learning emoji representations from their description", "author": ["Eisner et al.2016] Ben Eisner", "Tim Rockt\u00e4schel", "Isabelle Augenstein", "Matko Bosnjak", "Sebastian Riedel"], "venue": "In Proceedings of The Fourth International Workshop on Natural Lan-", "citeRegEx": "Eisner et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Eisner et al\\.", "year": 2016}, {"title": "Framewise phoneme classification with bidirectional LSTM networks", "author": ["Graves", "Schmidhuber2005] Alex Graves", "J\u00fcrgen Schmidhuber"], "venue": "In Proceedings of the International Joint Conference on Neural Networks (IJCNN),", "citeRegEx": "Graves et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Graves et al\\.", "year": 2005}, {"title": "Long short-term memory", "author": ["Hochreiter", "Schmidhuber1997] Sepp Hochreiter", "J\u00fcrgen Schmidhuber"], "venue": "Neural Computation,", "citeRegEx": "Hochreiter et al\\.,? \\Q1997\\E", "shortCiteRegEx": "Hochreiter et al\\.", "year": 1997}, {"title": "Neural architectures for named entity recognition", "author": ["Miguel Ballesteros", "Sandeep Subramanian", "Kazuya Kawakami", "Chris Dyer"], "venue": "In Proceedings of the 2016 Conference of the North American Chapter", "citeRegEx": "Lample et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Lample et al\\.", "year": 2016}, {"title": "2015a. Two/too simple adaptations of word2vec for syntax problems", "author": ["Ling et al.2015a] Wang Ling", "Chris Dyer", "Alan W Black", "Isabel Trancoso"], "venue": "In Proceedings of the 2015 Conference of the North American Chapter of the Association for Compu-", "citeRegEx": "Ling et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Ling et al\\.", "year": 2015}, {"title": "Finding function in form: Compositional character models", "author": ["Ling et al.2015b] Wang Ling", "Chris Dyer", "Alan W Black", "Isabel Trancoso", "Ramon Fermandez", "Silvio Amir", "Luis Marujo", "Tiago Luis"], "venue": null, "citeRegEx": "Ling et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Ling et al\\.", "year": 2015}, {"title": "A global analysis of emoji usage", "author": ["Ljube\u0161ic", "Fi\u0161er2016] Nikola Ljube\u0161ic", "Darja Fi\u0161er"], "venue": "In Proceedings of the 10th Web as Corpus Workshop (WAC-X) and the EmpiriST Shared Task,", "citeRegEx": "Ljube\u0161ic et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Ljube\u0161ic et al\\.", "year": 2016}, {"title": "Learning word vectors for sentiment analysis", "author": ["Maas et al.2011] Andrew L. Maas", "Raymond E. Daly", "Peter T. Pham", "Dan Huang", "Andrew Y. Ng", "Christopher Potts"], "venue": "In Proceedings of the 49th Annual Meeting of the Association", "citeRegEx": "Maas et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Maas et al\\.", "year": 2011}, {"title": "Exploiting similarities among languages for machine translation", "author": ["Quoc V Le", "Ilya Sutskever"], "venue": "arXiv preprint arXiv:1309.4168", "citeRegEx": "Mikolov et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Mikolov et al\\.", "year": 2013}, {"title": "Blissfully Happy\u201d or Ready to Fight: Varying Interpretations of Emoji", "author": ["Miller et al.2016] Hannah Miller", "Jacob ThebaultSpieker", "Shuo Chang", "Isaac Johnson", "Loren Terveen", "Brent Hecht"], "venue": "Proceeding of the International AAAI Conference", "citeRegEx": "Miller et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Miller et al\\.", "year": 2016}, {"title": "Sentiment of emojis", "author": ["Jasmina Smailovi\u0107", "Borut Sluban", "Igor Mozeti\u010d"], "venue": "PloS one,", "citeRegEx": "Novak et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Novak et al\\.", "year": 2015}, {"title": "Modeling online reviews with multigrain topic models", "author": ["Titov", "McDonald2008] Ivan Titov", "Ryan McDonald"], "venue": "In Proceedings of the 17th international conference on World Wide Web,", "citeRegEx": "Titov et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Titov et al\\.", "year": 2008}, {"title": "Grammar as a foreign language", "author": ["Lukasz Kaiser", "Terry Koo", "Slav Petrov", "Ilya Sutskever", "Geoffrey Hinton"], "venue": "In Proceeding of the conference on Neural Information Processing Systems,", "citeRegEx": "Vinyals et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Vinyals et al\\.", "year": 2015}, {"title": "Topic modeling: Beyond bag-of-words", "author": ["Hanna M Wallach"], "venue": "In Proceedings of the 23rd International Conference on Machine Learning,", "citeRegEx": "Wallach.,? \\Q2006\\E", "shortCiteRegEx": "Wallach.", "year": 2006}, {"title": "Learning distributed word representations for bidirectional lstm recurrent neural network", "author": ["Wang et al.2016] Peilu Wang", "Yao Qian", "Frank K. Soong", "Lei He", "Hai Zhao"], "venue": "In Proceedings of the 2016 Conference of the North American Chapter", "citeRegEx": "Wang et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Wang et al\\.", "year": 2016}], "referenceMentions": [{"referenceID": 11, "context": "Notable exceptions include studies focused on emojis\u2019 semantics and usage (Aoki and Uchida, 2011; Barbieri et al., 2016a; Barbieri et al., 2016b; Barbieri et al., 2016c; Eisner et al., 2016; Ljube\u0161ic and Fi\u0161er, 2016), or sentiment (Novak et al.", "startOffset": 74, "endOffset": 216}, {"referenceID": 21, "context": ", 2016; Ljube\u0161ic and Fi\u0161er, 2016), or sentiment (Novak et al., 2015).", "startOffset": 48, "endOffset": 68}, {"referenceID": 21, "context": "The ambiguity of emojis raises an interesting question in human-computer interaction: how can we teach an artificial agent to correctly interpret and recognise emojis\u2019 use in spontaneous conversation?2 The main motivation of our research is that an artificial intelligence system that is able to predict emojis could contribute to better natural language understanding (Novak et al., 2015) and thus to different natural language processing tasks such as generating emoji-enriched social media content, enhance emotion/sentiment analysis systems, and improve retrieval of social network material.", "startOffset": 369, "endOffset": 389}, {"referenceID": 8, "context": ", 2016, inter-alia), which also includes modeling of tweets (Dhingra et al., 2016), our emoji prediction model is based on bi-directional", "startOffset": 60, "endOffset": 82}, {"referenceID": 1, "context": "Character-based Representations: We compute character-based continuous-space vector embeddings (Ling et al., 2015b; Ballesteros et al., 2015) of the tokens in each tweet using, again, bidirectional LSTMs.", "startOffset": 95, "endOffset": 141}, {"referenceID": 8, "context": "This is similar to the treatment of word embeddings by Dyer et al. (2015). Character-based Representations: We compute character-based continuous-space vector embeddings (Ling et al.", "startOffset": 55, "endOffset": 74}, {"referenceID": 24, "context": "We applied a bag of words classifier as baseline, since it has been successfully employed in several classification tasks, like sentiment analysis and topic modeling (Wallach, 2006; Blei, 2012; Titov and McDonald, 2008; Maas et al., 2011; Davidov et al., 2010).", "startOffset": 166, "endOffset": 260}, {"referenceID": 5, "context": "We applied a bag of words classifier as baseline, since it has been successfully employed in several classification tasks, like sentiment analysis and topic modeling (Wallach, 2006; Blei, 2012; Titov and McDonald, 2008; Maas et al., 2011; Davidov et al., 2010).", "startOffset": 166, "endOffset": 260}, {"referenceID": 18, "context": "We applied a bag of words classifier as baseline, since it has been successfully employed in several classification tasks, like sentiment analysis and topic modeling (Wallach, 2006; Blei, 2012; Titov and McDonald, 2008; Maas et al., 2011; Davidov et al., 2010).", "startOffset": 166, "endOffset": 260}, {"referenceID": 7, "context": "We applied a bag of words classifier as baseline, since it has been successfully employed in several classification tasks, like sentiment analysis and topic modeling (Wallach, 2006; Blei, 2012; Titov and McDonald, 2008; Maas et al., 2011; Davidov et al., 2010).", "startOffset": 166, "endOffset": 260}, {"referenceID": 19, "context": "We train a Skip-gram model (Mikolov et al., 2013) learned from 65M Tweets (where testing instances have been removed) to learn Twitter semantic vectors.", "startOffset": 27, "endOffset": 49}, {"referenceID": 20, "context": "Given that Miller et al. (2016) pointed out that people tend to give multiple interpretations to emojis, we carried out an experiment in which we evaluated human and machine performances on the same task.", "startOffset": 11, "endOffset": 32}, {"referenceID": 20, "context": "The overall inter-annotator agreement was 73% (in line with previous findings (Miller et al., 2016)).", "startOffset": 78, "endOffset": 99}], "year": 2017, "abstractText": "Emojis are ideograms which are naturally combined with plain text to visually complement or condense the meaning of a message. Despite being widely used in social media, their underlying semantics have received little attention from a Natural Language Processing standpoint. In this paper, we investigate the relation between words and emojis, studying the novel task of predicting which emojis are evoked by text-based tweet messages. We train several models based on Long ShortTerm Memory networks (LSTMs) in this task. Our experimental results show that our neural model outperforms two baselines as well as humans solving the same task, suggesting that computational models are able to better capture the underlying semantics of emojis.", "creator": "LaTeX with hyperref package"}}}