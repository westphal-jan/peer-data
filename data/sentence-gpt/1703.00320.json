{"id": "1703.00320", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "1-Mar-2017", "title": "Investigating the Characteristics of One-Sided Matching Mechanisms Under Various Preferences and Risk Attitudes", "abstract": "One-sided matching mechanisms are fundamental for assigning a set of indivisible objects to a set of self-interested agents when monetary transfers are not allowed. Two widely-studied randomized mechanisms in multiagent settings are the Random Serial Dictatorship (RSD) and the Probabilistic Serial Rule (PS). Both mechanisms require only that agents specify ordinal preferences and have a number of desirable economic and computational properties, such as the probability of a given set of random agents to make a given distribution (the probability of a given set of values being determined) in addition to the usual and generalized effects of certain random agents, such as the probability of the first positive outcome for a given set of the other-dimensional conditions in the case of an agent. In the case of two random agents, the probability of a given set of values being determined (the probability of a given set of values being determined) in addition to the usual and generalized effects of some random agents is high, and the probability of a given set of values being determined is low. A system using such an explicit algorithm has two goals: to provide a way for non-random agents to perform specific functions on a given set of values (but which is different than one), and to use a generalized algorithm for a given set of values (but which is different than one). One approach uses the same generalized algorithm but uses more specialized mechanisms. For example, with the ability to perform specific functions on a given set of values (for instance, for example, to make a single-choice selection of one, the likelihood of a given set of values being determined is low, or if the probability of a given set of values being determined is high, or if the probability of a given set of values being determined is high, or if the probability of a given set of values being determined is high, or if the probability of a given set of values being determined is high, or if the probability of a given set of values being determined is high, or if the probability of a given set of values being determined is high, or if the probability of a given set of values being determined is high, or if the probability of a given set of values being determined is high, or if the probability of a given set of values being determined is high, or if the probability of a given set of values being determined is high, or if the probability of a given set of values being determined is high, or if the probability of a given set of values being determined is high,", "histories": [["v1", "Wed, 1 Mar 2017 14:42:20 GMT  (7325kb,D)", "http://arxiv.org/abs/1703.00320v1", "arXiv admin note: text overlap witharXiv:1503.01488"]], "COMMENTS": "arXiv admin note: text overlap witharXiv:1503.01488", "reviews": [], "SUBJECTS": "cs.GT cs.AI cs.MA", "authors": ["hadi hosseini", "kate larson", "robin cohen"], "accepted": false, "id": "1703.00320"}, "pdf": {"name": "1703.00320.pdf", "metadata": {"source": "CRF", "title": "Investigating the Characteristics of One-Sided Matching Mechanisms Under Various Preferences and Risk Attitudes", "authors": ["Hadi Hosseini", "Kate Larson"], "emails": ["hhvcs@rit.edu", "klarson@uwaterloo.ca", "rcohen@uwaterloo.ca"], "sections": [{"heading": null, "text": "In this paper, we first consider the space of general ordinal preferences and provide empirical results on the (in)comparability of RSD and PS. We analyze their respective economic properties under general and lexicographic preferences. We then instantiate utility functions with the goal of gaining insights on the manipulability, efficiency, and envyfreeness of the mechanisms under different riskattitude models. Our results hold under various preference distribution models, which further confirm the broad use of RSD in most practical applications.\nKeywords One-Sided Matching \u00b7 Random Serial Dictatorship \u00b7 Probabilistic Serial Rule \u00b7 Strategyproofness \u00b7 Social Welfare \u00b7 Fairness \u00b7 Risky Attitudes"}, {"heading": "1 Introduction", "text": "One-sided matching mechanisms have been extensively adopted in many resource allocation settings such as assigning dormitory rooms or offices to students, stu-\nHadi Hosseini Department of Computer Science, Rochester Institute of Technology, Rochester, NY, USA E-mail: hhvcs@rit.edu\nKate Larson Cheriton School of Computer Science, University of Waterloo, Waterloo, ON, Canada E-mail: klarson@uwaterloo.ca\nRobin Cohen Cheriton School of Computer Science, University of Waterloo, Waterloo, ON, Canada E-mail: rcohen@uwaterloo.ca\nar X\niv :1\n70 3.\n00 32\n0v 1\n[ cs\n.G T\n] 1\nM ar\n2 01\ndents to public schools, college courses to students, organs and medical resources to patients, and members to subcommittees [5, 16, 34, 43]. Two prominent (randomized) matching mechanisms that only elicit ordinal preferences from agents are Random Serial Dictatorship (RSD) [2] and Probabilistic Serial Rule (PS) [14]. Both mechanisms have important economic properties and are practical to implement. The RSD mechanism has strong truthful incentives but guarantees neither efficiency nor envyfreeness. PS satisfies efficiency and envyfreeness; however, it is susceptible to manipulation. Therefore, there are subtle points to be considered when deciding which mechanism to use. For example, given a particular preference profile, the mechanisms often produce random assignments which are simply incomparable and thus, without additional knowledge of the underlying utility models of the agents, it is difficult to determine which is the \u201cbetter\u201d outcome. Furthermore, properties like efficiency, truthfulness, and envyfreeness can depend on whether there is underlying structure in the preferences, and even in general preference models it is valuable to understand under what conditions a mechanism is likely to be efficient, truthful, or envyfree as this can guide designers choices.\nIn this paper, we study the comparability of PS and RSD when there is only one copy of each object, and analyze the space of all preference profiles for different numbers of agents and objects. Working in the space of general ordinal preferences, we provide empirical results on the (in)comparability of RSD and PS and analyze their respective economic properties. We show that despite the inefficiency of RSD, the fraction of random assignments at which PS stochastically dominates RSD vanishes, especially when the number of agents is less than or equal to the available objects. We also investigate the manipulability of PS and show that PS is almost always 99% manipulable for any combination of agents and objects, and the fraction of strongly manipulable profiles goes to one as the ratio of objects to agents increases. We show similar trends under lexicographic preferences, and further present results on envy of RSD. Our results show that although the fraction of envious agents grows with the number of agents, there is a sudden drop in the fraction of envious agents when there are equal number of agents and objects.\nIn Section 5, we instantiate utility functions for agents to gain deeper insights on the manipulability, social welfare, and envyfreeness of the two mechanisms under different risk attitudes. Our main result is that under risk aversion, the social welfare of RSD is as good as PS but RSD does create envy among the agents (though the fraction of envious profiles and the total envy are small). Moreover, when the number of agents and objects are equal, RSD assignments are less likely to be dominated by PS, and overall RSD assignments create negligible envy among agents. We also show that PS is highly susceptible to manipulation in almost all combinations of agents and objects. The fraction of manipulable profiles and the gain from manipulation rapidly increases, particularly when agents become more risk averse. In Section 7, we consider two statistical preference distribution models, namely Mallows Models and Polya-Eggenberger Urn Models, and show that the same patterns and trends hold for various combinations of agents and objects, when varying risk parameters and utility functions."}, {"heading": "2 Preliminaries", "text": "In this section, we describe the basic one-sided matching problem and introduce the two mechanisms we study in detail, Random Serial Dictatorship (RSD) [2] and Probabilistic Serial Rule (PS) [14]. We then introduce a number of properties and criteria used to evaluate these mechanisms.\nA one-sided matching problem consists of a set of n agents, N , and a set of m indivisible objects, M .1 Each agent i \u2208 N has a private strict preference ordering, i, over M where a i b indicates that agent i prefers to receive object a over object b. We represent the preference ordering of agent i by the ordered list of objects i= a i b i c or i= (abc), for short. We let P denote the set of all complete and strict preference orderings over M . A preference profile \u2208 Pn specifies a preference ordering for each agent, and we use the standard notation \u2212i= ( 1, . . . , i\u22121, i+1, . . . , n) to denote preferences orderings of all agents except i and thus = ( i, \u2212i).\nThe goal in a one-sided matching problem is to assign the objects in M to the agents in N according to preference profiles, under the constraint that no object can be assigned to more than one agent. If m = n then this means that each agent will receive exactly one object, however if m < n then some agents will receive no object and if m > n then some agents may receive multiple objects. An assignment is represented as a matrix\nA =  A1 A2 ... An  =  A1,1 A1,2 . . . A1,m A2,1 A2,2 . . . A2,m ... ... . . . ... An,1 An,2 . . . An,m  where Ai,j \u2208 [0, 1] is the probability that agent i is assigned object j. We let A denote the set of all feasible assignments where an assignment A \u2208 A is feasible if and only if \u2200j \u2208 M , \u2211 i\u2208N Ai,j = 1. If A \u2208 A is such that Ai,j \u2208 {0, 1} then we say that A is a deterministic assignment; otherwise, A is a random assignment. Every random assignment can be represented as a convex combination of deterministic assignments [49], and thus we view random assignments as a probability distribution over a set of deterministic assignments.\n2.1 Matching Mechanisms\nIn general, a matching mechanism, M, is a mapping from the set of preference profiles, Pn to the set of feasible assignments, A. That is,M : Pn 7\u2192 A. We focus our attention on two widely studied mechanisms for one-side matching: Random Serial Dictatorship (RSD) [2] and Probabilistic Serial Rule (PS) [13].\nRSD relies on the concept of priority orderings over agents. Such an ordering is an ordered list of agents where the first agent gets to select its most preferred object from the set of objects, the second agent then selects its most preferred\n1 This problem is sometimes called the assignment problem or house allocation problem in the literature.\nobject from the set of remaining objects and so on until no objects remain.2 Given a preference profile \u2208 Pn, RSD returns an assignment RSD( ) \u2208 A which is a uniform distribution over all deterministic assignments induced from all possible priority orderings over the set of agents. RSD has been widely adopted for fair and strategyproof assignments for the school choice problem, course assignment, house allocation, and room assignment [1\u20133,47]\nPS treats objects as a set of divisible goods of equal size and simulates a simultaneous eating algorithm. Each agent starts \u201ceating\u201d its most preferred object, all at the same rate. Once an object is gone (eaten away) then the agent starts eating its next preferred object among the remaining objects. This process terminates when all objects have been \u201ceaten\u201d. Given a preference profile \u2208 Pn, PS( ) \u2208 A is a random assignment where Ai,j is the probability (fraction) that object j is assigned to (or \u201ceaten by\u201d) agent i.\n2.2 General Properties\nIn this section we define key properties for matching mechanisms. To evaluate the quality of a random assignment, we use first-order stochastic dominance [14, 22]. Given a random assignment Ai, the probability that agent i is assigned an object that is at least as good as object ` is defined as follows\nw( i, `, Ai) = \u2211\nj\u2208M :j i`\nAi,j (1)\nWe say an agent always prefers assignment Ai to Bi, if for each object ` the probability of assigning an object at least as good as ` under Ai is greater or equal that of Bi, and strictly greater for some object.\nDefinition 1 (Stochastic Dominance) Given a preference ordering i, random assignment Ai stochastically dominates (sd) assignment Bi(6= Ai) if\n\u2200` \u2208M, w( i, `, Ai) \u2265 w( i, `, Bi) (2)\nA matching mechanism is sd-efficient if at all preference profiles \u2208 Pn, for all agents i \u2208 N , the prescribed assignment is not stochastically dominated by any other assignment.\nDefinition 2 (sd-Efficiency) A random assignment is sd-efficient if for all agents, it is not stochastically dominated by any other random assignment.\nAn important desirable property in matching mechanisms is strategyproofness, that is the mechanism is designed so that no agent has incentive to misreport its preferences.\n2 When n < m and agents can receive more than one object, RSD requires a careful method for the picking sequence at each priority ordering to ensure strategyproofness. This picking sequence should be based on an arbitrary serial dictatorship quota mechanism, which directly affects the efficiency and envy of the assignments [15, 23]. For simplicity, we use the variant of RSD based on a quasi-dictatorial mechanism [40] where the first agent selects its most preferred (m\u2212 n+ 1) objects, and the rest of the agents choose one object each.\nDefinition 3 (sd-Strategyproofness) Mechanism M is sd-strategyproof if at all preference profiles \u2208 Pn, for all agents i \u2208 N , and for any misreport \u2032i\u2208 Pn, such that A =M( ) and A\u2032 =M( \u2032i, \u2212i), we have:\n\u2200` \u2208M, w( i, `, Ai) \u2265 w( i, `, A\u2032i) (3)\nSd-strategyproofness is a strict requirement. It implies that under any utility model consistent with the preference orderings, no agent can improve her expected utility by misreporting. We say that a mechanism is weakly sd-strategyproof if at all preference profiles there is no misreport such that for all ` \u2208M , w( i, `, A\u2032i) \u2265 w( i, `, Ai) with at least one `\u2032 \u2208 M such that w( i, `\u2032, A\u2032i) > w( i, `\u2032, Ai). Clearly, sd-strategyproofness implies weak sd-strategyproofness but the converse does not hold.\nAn assignment is manipulable if it is not sd-strategyproof. If there exists some agent who strictly benefits from the manipulation, (i.e. the mechanism is not even weakly sd-strategyproof) then we say the assignment is sd-manipulable (or strictly manipulable).\nWe are also interested in whether mechanisms are fair and use the notion of envyfreeness to this end. An assignment is sd-envyfree if each agent strictly prefers her random allocation to any other agent\u2019s assignment.\nDefinition 4 (sd-Envyfreeness) Given agent i\u2019s preference i, assignment Ai is sd-envyfree if for all agents \u2200k 6= i \u2208 N ,\n\u2200` \u2208M, w( i, `, Ai) \u2265 w( i, `, Ak) (4)\nWe say an assignment is weakly sd-envyfree if the inequality in Equation 4 is strict for some ` \u2208 M , but there exists at least one `\u2032 for which the inequality in Equation 4 does not hold. A matching mechanism satisfies sd-envyfreeness if at all preference profiles \u2208 Pn, it induces sd-envyfree assignments for all agents.\nLastly, we are interested in investigating efficiency, manipulation, and envy of the random mechanisms when preferences are lexicographic. Under lexicographic preferences, given two allocations, an agent prefers the one in which there is a higher probability for getting the most-preferred object.\nDefinition 5 (Lexicographic Dominance) Given a preference ordering i, random assignment Ai lexicographically dominates (ld) assignment Bi if\n\u2203 ` \u2208M : w( i, `, Ai) > w( i, `, Bi) \u2227 (5) \u2200 k i ` : w( i, `, Ai) = w( i, `, Bi).\nWe say that allocation A lexicographically dominates another allocation B if there exists no agent i \u2208 N that lexicographically prefers Bi to Ai. Thus, an allocation mechanism is lexicographically efficient (ld-efficient) if for all preference profiles its induced allocation is not lexicographically dominated by any other random allocation.\n2.3 Properties of RSD and PS\nThe theoretical properties of PS and RSD have been well studied in the economics literature [14], and we summarize the results in Table 1. Both mechanisms are ex post efficient, that is, their realized outcomes cannot be improved without making at least one agent worse off. PS has been shown to be both sd-envyfree and sdefficient. However, it is not even weakly sd-strategyproof when n < m [28] and is only weakly sd-strategyproof when n \u2265 m. On the other hand, RSD is always sdstrategyproof, but it is only weakly sd-envyfree and is not sd-efficient. Example 1 illustrates the sd-inefficiency of RSD.\nExample 1 Suppose there are four agents N = {1, 2, 3, 4} and four objects M = {a, b, c, d}. Consider the following preference profile = ((abcd), (abcd), (badc), (badc)). Table 2 shows the outcomes for PS( ) and RSD( ). In this example, all agents strictly prefer the assignment induced by PS over the RSD assignment. Thus, RSD is inefficient at this preference profile."}, {"heading": "3 Incomparability of RSD and PS", "text": "We argue that the theoretical findings on RSD and PS do not necessarily provide enough guidance to a market designer trying to select the correct mechanism for a specific setting. For example, while we know that PS is sd-efficient and RSD is not, this does not mean that PS assignment always stochastically dominate the assignments prescribed by RSD.\nExample 2 Suppose there are three agents N = {1, 2, 3} and three objects M = {a, b, c}. Consider the following preference profile = ((acb), (abc), (bac)). Table 3 shows PS( ) and RSD( ). Neither assignment dominates the other since agent 1 is ambivalent between the two assignments while agent 2 prefers PS( ) and agent 3 prefers RSD( ).\nIf we knew the utility functions of the agents, consistent with their ordinal preferences, then we might be able to use the notion of (utilitarian) social welfare to help determine the better assignment.3 However, it is easy to construct different utility functions for the agents in Example 2 where both RSD and PS maximize social welfare. Similarly, the envy of RSD and the manipulability of PS both depend on the structure of preference profiles, and thus, a compelling question, that justifies studying the practical implications of deploying a matching mechanism, is to analyze the space of preference profiles to find the likelihood of inefficient, manipulable, or envious assignments under these mechanisms. In Example 2, for instance, if utilities of agents 1 and 2 are 10, 9, and 1, and agent 3\u2019s utility is 10, 6, and 4 for the first, second, and third objects respectively, then PS assignment outperforms that of RSD with respect to social welfare because (12 \u00b7 10 + 1 2 \u00b7 9 + (0) \u00b7 1) + (12 \u00b7 10 + 1 4 \u00b7 9 + 1 4 \u00b7 1) + ( 3 4 \u00b7 10 + (0) \u00b7 6 + 1 4 \u00b7 4) > ( 1 2 \u00b7 10 + 1 2 \u00b7 9 + (0) \u00b7 1) + (12 \u00b7 10 + 1 6 \u00b7 9 + 1 3 \u00b7 1) + ( 5 6 \u00b7 10 + (0) \u00b7 6 + 1 6 \u00b7 4). However, if utility functions change such that all agents have the same utilities of 10, 9, and 1 for the first, second, and third objects respectively, then the social welfare under RSD outperforms that of PS because (12 \u00b710 + 1 2 \u00b79 + (0) \u00b71) + ( 1 2 \u00b710 + 1 6 \u00b79 + 1 3 \u00b71) + ( 5 6 \u00b710 + (0) \u00b79 + 1 6 \u00b71) > (12 \u00b7 10 + 1 2 \u00b7 9 + (0) \u00b7 1) + ( 1 2 \u00b7 10 + 1 4 \u00b7 9 + 1 4 \u00b7 1) + ( 3 4 \u00b7 10 + (0) \u00b7 9 + 1 4 \u00b7 1)."}, {"heading": "4 General and Lexicographic Preferences", "text": "The theoretical properties of PS and RSD only provide limited insight into their practical applications. In particular, when deciding which mechanism to use in different settings, the incomparability of PS and RSD leaves us with an ambiguous choice in terms of efficiency, manipulability, and envyfreeness. Thus, we examine the properties of RSD and PS in the space of all possible preference profiles as well as under lexicographic preferences. Lexicographic preferences are present in various applications and have been extensively studied in artificial intelligence and multiagent systems as a means of assessing allocations based on ordinal preferences [18, 21, 44]. Under lexicographic preferences, an allocation that assigns a higher probability to the top ranked object is always preferred to any other allocation, regardless of the probabilities assigned to objects in the next positions. Only when two allocations assign equal probabilities to the top ranked object, the probability of the next preferred object is considered. In the rest of this paper, we denote the efficiency, strategyproofness, manipulability, and envyfreeness with ld(lexicographically dominate) prefix.\n3 Given utility functions for the agents, where ui(j) is the utility agent i derives from being assigned object j, the (utilitarian) social welfare of an assignment A is \u2211 i \u2211 j Ai,jui(j).\nThe number of all possible preference profiles is super exponential (m!)n. For each combination of n agents and m objects we performed a brute force coverage of all possible preference profiles. Thus, for all subsequent figures each data point shows the fraction of all possible preference profiles. For the cases of n = 10 and m \u2208 {9, 10}, we randomly generated 1,000 instances by sampling from a uniform preference profile distribution. For each preference profile, we ran both PS and RSD mechanisms and compared their outcomes in terms of the stochastic dominance relation. Appendix A illustrates our numerical results. Note that not only is computing RSD probabilities #P-complete (and thus intractable) [6, 45], but checking the desired properties such as envyfreeness, efficiency, and manipulablity of random allocations is shown to be NP-hard for general settings [9, 10]. Thus, for larger settings even if we randomly sample preference profiles it is not easy to verify the aforementioned properties.\n4.1 Preliminary Results\nOur experimentation disclose several intriguing observations, confirming theoretical results and providing additional insights into matching markets. A preliminary look at our empirical results illustrates the following: when m \u2264 2, n \u2264 3, PS coincides exactly with RSD, which results in the best of the two mechanisms, i.e., both mechanisms are sd-efficient, sd-strategyproof, and sd-envyfree. Another interesting observation is that when m = 2, for all n, PS is sd-strategyproof (although the PS assignments are not necessarily equivalent to assignments induced by RSD), RSD is sd-envyfree, and for most instances when m = 2, PS stochastically dominates RSD, particularly when n \u2265 4.\n4.2 Efficiency\nOur first finding is that the fraction of preference profiles at which RSD and PS prescribe identical random assignments goes to 0 when n grows. There are two conclusions that one can draw. First, this result confirms the theoretical results\nof Manea on asymptotic inefficiency of RSD [33], in that, in most instances, the assignments induced by RSD are not identical to the PS assignments. Second, this result suggests that the incomparability of outcomes is significant, that is, the social welfare of the random outcomes is highly dependent on the underlying utility models.\nThe fraction of preference profiles \u2208 Pn for which RSD is stochastically dominated by PS at converges to zero as nm \u2192 1. Figure 1a shows that when m grows beyond m > 5, due to incomparability of RSD and PS with regard to the stochastic dominance relation, the RSD assignments are rarely stochastically dominated by sd-efficient assignments prescribed by PS.\nWe also see similar results when we restrict ourselves to lexicographic preferences (Figure 1b). The fraction of preference profiles \u2208 Pn for which RSD is lexicographically dominated by PS at converges to zero as nm \u2192 1.\nFor lexicographic preferences, we also observe that the fraction of preference profiles for which PS assignments strictly dominate RSD-induced allocations goes to 1 when the number of agents and objects diverge. The fraction of preference profiles \u2208 Pn for which RSD is lexicographically dominated by PS at converges to 1 as |n \u2212m| grows. Intuitively, when some agents can receive more than one object (n < m) or when there are not sufficient objects (n > m) for all agents, in each realized ordering of agents by RSD, those with higher priority are treated very differently than those in lower priority. Thus, the RSD outcome tend to be unfair and undesirable for most agents.\nOne immediate conclusion is that although RSD does not guarantee either sd-efficiency or ld-efficiency, in most settings when nm \u2192 1 (and also n \u2264 m for sd-efficiency according to Figure 1a), neither of the two mechanisms is preferred in terms of efficiency. Hence, one cannot simply rule out the RSD mechanism.\n4.3 Manipulability of PS\nOne critical issue with deploying PS is that it does not provide incentives for honest reporting of preferences. Although for n \u2265 m PS is weakly sd-strategyproof [14]\nand ld-strategyproof [46], when n < m PS no longer satisfies these two properties.4 The real concern is that, in the absence of strategyproofness, PS allocations are only efficient (or envyfree) with respect to the reported preferences. Thus, if an agent decides to manipulate the outcome by misreporting its preferences, PS will no longer guarantee efficiency, nor envyfreeness with respect to the true underlying preferences. Thus, we are interested in understanding the degree to which PS allocations are manipulable.\nFigure 2 shows that the fraction of manipulable profiles goes to 1 as n or m grow. PS is almost 99% manipulable for n > 5,m > 5. Another interesting observation is that, for all n < m, the fraction of sd-manipulable preference profiles goes to 1 as m \u2212 n grows (Figure 2b). These results imply that when agents are permitted to receive more than a single object, agents can strictly benefit from misreporting their preferences.\nMoreover, at those instances of problem where PS is sd-strategyproof, the assignment prescribed by PS most often coincides with the RSD induced assignment. For example, when n = m = 5, PS is only sd-strategyproof at 11% of preference profiles, 7% of which are identical to the assignments induced by RSD. This insight further confirms the vulnerability of PS to misreporting (See Table 6 for detailed numerical results).\nAs illustrated in Figure 3, the manipulability of PS under lexicographic preferences has a similar trend when there are more objects than agents (n < m) and the fraction of ld-manipulable preference profiles converges to 1 even more rapidly when mn grows.\n4 A recent experimental study on the incentive properties of PS shows that human subjects are less likely to manipulate the mechanism when misreporting is a Nash equilibrium. However, subjects\u2019 tendency for misreporting is still significant even when it does not improve their allocations [24].\n4.4 Envy in RSD\nThe PS mechanism has a desirable fairness property and is guaranteed to satisfy sd-envyfreeness, whereas RSD is not sd-envyfree. To further investigate the envy among agents under RSD, we measured the fraction of agents that are weakly sd-envious of at least one other agent.\nFigure 4 shows that for RSD, the percentage of agents that are weakly envious increases with the number of agents. Figure 4a reveals an interesting observation: fixing any n > 3, the percentage of agents that are (weakly) envious grows with the number of objects, however, there is a sudden drop in the percentage of envious agents when there are equal number of agents and objects.\nFor better understanding of the population of agents who feel (weakly) envious under RSD, we illustrate the various envy profiles based on the percentage of envious agents in all instances of the problem when n = m (Figure 4b). One observation is that there are few distinct envy profiles at each n, each representing a particular class of preference profiles, and by increasing n, the fraction of agents that are envious of at least one other agent increases."}, {"heading": "5 Utility Models", "text": "Given a utility model consistent with an agent\u2019s preference ordering, we can find the agent\u2019s expected utility for a random assignment. Let ui denote agent i\u2019s Von Neumann-Morgenstern (VNM) utility model consistent with its preference ordering i. That is, ui(a) > ui(b) if and only if a i b. Then, agent i\u2019s expected utility for random assignment Ai is E(ui|Ai) = \u2211 j\u2208M Ai,jui(j).\nWe say that agent i (strictly) prefers assignment Ai to Bi if and only if E(ui|Ai) > E(ui|Bi). A mechanism is strategyproof if there exists no agent that can improve its expected utility by misreporting its preference ordering.\nDefinition 6 (Strategyproof) Mechanism M is strategyproof if for all agents i \u2208 N , and for any misreport \u2032i\u2208 Pn, such that A =M( ) and A\u2032 =M( \u2032i, \u2212i), given a utility model ui consistent with i, we have E(ui|Ai) \u2265 E(ui|A\u2032i).\nA matching mechanism is envyfree if for all preference profiles it prescribes an envyfree assignment.\nDefinition 7 (Envyfreeness) Assignment A is envyfree if for all i, k \u2208 N , given utility model ui consistent with i, we have E(ui|Ai) \u2265 E(ui|Ak).\nGiven utility functions for the agents, the (utilitarian) social welfare of an assignment A is \u2211 i E(ui|Ai). A random assignment A is sd-efficient if and only if there exists a profile of utility values consistent with such that A maximizes the social welfare ex ante [14,37]. This existence result does not shed light on the social welfare when comparing two random assignments, since an assignment can be sd-efficient but may not have desirable ex ante social welfare. Consider the following random assignments: assignment A which is sd-efficient and assignment B 6= A which is not stochastically dominated by A. Given a preference profile, A is guaranteed to maximize the social welfare for at least one profile of consistent utilities. However, there may be other profiles of utilities consistent with preferences at which B maximizes the sum of utilities (social welfare).\nExample 3 Consider the problem introduced in Example 2 with assignments illustrated in Table 3. Let\u2019s assume that all agents have the same utility model u1 = u2 = u3 where the utilities are 10, 9, 0 for the first, second, and third objects respectively. The sum of expected utilities under the PS assignment is (12 \u00b7 10 + 1 2 \u00b7 9+0)+(12 \u00b710+ 1 4 \u00b79+ 1 4 \u00b70)+( 3 4 \u00b710+0 \u00b79+ 1 4 \u00b70), while the sum of expected utilities under the RSD allocation is (12 \u00b710+ 1 2 \u00b79+0)+( 1 2 \u00b710+ 1 6 \u00b79+ 1 3 \u00b70)+( 5 6 \u00b710+0\u00b79+ 1 6 \u00b70). It is easy to see that for this profile, the ex ante social welfare under RSD is larger than that of PS.\nThus, given a profile of utilities we investigate the (ex ante) social welfare of the assignments under PS and RSD.\n5.1 Instantiating Utility Functions\nTo deepen our understanding as to the performance of the two mechanisms, we investigate different utility models. In particular we look at the performance of the mechanisms when the agents are all risk neutral (i.e. have linear utility functions), when agents are risk seeking and when agents are risk averse.\nOur first utility model is the well-studied linear utility model. Given an agent i\u2019s preference ordering i, we let r( i, j) denote the rank of object j. For example, given preference ordering a i b i c then r( i, a) = 1, r( i, b) = 2 and r( i , c) = 3. The utility function for agent i, given object j is ui(j) = m\u2212 r( i, j).\nWe use an exponential utility model to capture risk attitudes beyond riskneutrality. An exponential utility has been shown to provide an appropriate translation for individuals\u2019 utility models [4]. In particular, we define the exponential utility as follows:\nui(j) = { (1\u2212 e\u2212\u03b1(m\u2212r( i,j)))/\u03b1, \u03b1 6= 0 m\u2212 r( i, j), \u03b1 = 0\n(6)\nThe parameter \u03b1 represents the agent\u2019s risk attitude. If \u03b1 > 0 then the agent is risk averse, while if \u03b1 < 0 then the agent is risk seeking. When \u03b1 = 0 then the\nagent is risk neutral and we have a linear utility model. The value |\u03b1| represents the intensity of the attitude. That is, given two agents with \u03b11 > \u03b12 > 0, we say that agent 1 is more risk averse than agent 2. Similarly if \u03b11 < \u03b12 < 0 then agent 1 is more risk seeking than agent 2. Figure 5 illustrates the risk curvature for various risk taking and risk averse \u03b1 parameters.\nTable 4 shows sample utility values for various risk taking, neutral, and risk averse utility profiles. These values show how a utility for objects in various ranking positions will change according to risk attitude models. Note that we do normalize the utilities such that all utilities add up to 1."}, {"heading": "6 Results", "text": "For our experiments, we vary three parameters: the number of agents n, the number of objects m, and the risk attitude factor \u03b1. Each data point in the graphs shows the average over all possible preference profiles. We study the same settings as in Section 4 when n \u2265 m and n < m. For each utility function, we look at homogeneous populations of agents where agents have the same risk attitudes but may have difference ordinal preferences.\nTo compare the social welfare, we investigate the percentage change (or improvement) in social welfare of PS compared to RSD under various utility models. That is,\n\u2211 i E(ui|PS( ))\u2212 \u2211 i E(ui|RSD( ))\u2211\ni E(ui|RSD( )) .\nTo measure the manipulability of PS, we are interested in answering two key questions: i) In what fraction of profiles is PS manipulable by at least one agent? and ii) If manipulation is possible, what is the average percentage of maximum gain? That is,\nmax i {E(ui|PS( \u2032 i, \u2212i))\u2212 E(ui|PS( )) E(ui|PS( )) }.\nTo study the envy under the RSD mechanism, we consider two measures: i) the fraction of envious agents, and ii) the total envy felt by all agents.\n6.1 Linear Utility Model\nWe first looked at how RSD and PS perform under the assumption that the utility models are linear (Figure 6). In most cases, the social welfare under PS increases compared to RSD; however, the social welfare of PS is very close to that of RSD when n = m (less than 0.015 overall improvement in all cases). Interestingly, under RSD the fraction of envious agents gets close to 0 when n \u2265 m. With regards to strategyproofness, PS is manipulable in most combinations of n and m and the fraction of manipulable profiles and the utility gain from manipulation increases as the number of objects compared to agents increases.\n6.2 Risk Seeking\nFigure 7 presents our results in terms of percentage change in social welfare between PS and RSD. Positive numbers show the percentage of improvement in social welfare from PS to RSD. Negative values represent those cases where RSD has increased social welfare compared to PS.\nSocial welfare: Fixing \u03b1 < 0, for n \u2265 m when nm grows PS improves the social welfare compared to RSD in all instances of the problem and the percentage of improvement also increases. A similar trend holds when varying risk intensity \u03b1 for fixed n and m where n 6= m. For n < m, when mn grows the fraction of profiles at which PS has higher social welfare compared to RSD rapidly increases and the percentage change is also noticeably larger, quickly getting close to 90% improvement (Figures 7a, 7c, and 7e). This social welfare gap between PS and RSD grows as the risk intensity |\u03b1| increases. Surprisingly, this trend changes for equal number of agents and objects n = m: the more risk-seeking agents are (larger |\u03b1|), RSD becomes more desirable than PS, and in fact, RSD improves the social welfare in more instances.\nEnvy: Figure 8 shows that for n \u2265 m, the fraction of envious agents under all profiles vanishes and RSD becomes envyfree. This is more evident when agents are more risk-seeking. Intuitively, these observations confirm the theoretical findings about the envyfreeness of RSD under lexicographic preferences [23]. This is because one can consider lexicographic preferences as risk-seeking preferences where an object in a higher ranking is infinitely preferred to all objects that are ranked\nless preferably [23]. When n < m, our quasi-dictatorial extension of RSD creates some envy among the agents, because the agent with the highest priority receives m\u2212n+1 objects, while all other agents receive at most one object. An interesting result is the envy created by RSD starts to fade out when the risk intensity |\u03b1| increases.\nManipulability: Figure 9 shows the manipulability of the PS assignments when agents are risk seeking. We see that the possibility of manipulation (and any gain) decreases as the risk intensity increases. When n \u2265 m the fraction of manipulable profiles goes to 0 the more risk seeking agents become. However, when\nn < m even though the fraction of manipulable profiles (and manipulation gain) decreases, the fraction of manipulable profiles goes to 1 as mn grows.\n6.3 Risk Aversion\nSocial welfare: Figures 7b, 7d, and 7f show that, fixing risk factor \u03b1 > 0, when n m grows, PS assignments are superior to that of RSD in terms of social welfare in more instances, and the percentage change in social welfare increases. Fixing risk\nfactor \u03b1 > 0 and when mn grows, RSD is more likely to have the same social welfare as PS, and in fact in some instances the social welfare under RSD is better than the social welfare under PS. Fixing m and n, when the risk intensity \u03b1 increases RSD is more likely to have the same social welfare as PS, that is, the welfare gap between PS and RSD closes when agents are more risk averse (\u03b1 increases). This result is insightful and states that under risk aversion the random allocations prescribed by RSD are either as good as PS or in some cases even are superior to the allocations prescribed by PS due to the underlying shape of the utility\nmodels. Figure 17 illustrates the percentage change in social welfare based on the difference between available objects and agents (m \u2212 n) for risk seeking, linear, and risk averse utilities with different risk intensities.\nEnvy: In Figure 10 we observe that when n \u2265 m, the fraction of envious agents and total envy grows as nm \u2192 1. Increasing the risk intensity (|\u03b1|), the fraction of envious agents increases; however, the total envy among the agents remains considerably low. For n < m, the fraction of envious agents and total envy grows as risk intensity increases. An interesting observation is that envy is maximized\nwhen m = n+ 1, and it decreases as mn grows. This is mostly due to the choice of using randomized quasi-dictatorial mechanism for implementing RSD where the first dictator receives m+ n\u2212 1 objects and all other agents only receive a single object. Lastly, we noticed that in all instance where RSD creates envy among the agents, around 25% of agents bear more than 50% of envy. That is, few agents feel extremely envious while all other agents are either envyfree or only feel a minimal amount of envy.\nManipulability: Figures 11 illustrates the manipulability of the PS assignments when agents have risk averse preferences. The fraction of manipulable pro-\nfiles rapidly goes to 1 as mn grows. Similarly, as agents become more risk averse (\u03b1 increases) the fraction of manipulable profiles goes to 1 and the manipulation gain increases."}, {"heading": "7 Other Ranking Distribution Models", "text": "In this section, we use variations of two statistical models that are commonly used to capture realistic preference distributions in a population of players. Considerable\nwork in computational social choice and machine learning has exploited these statistical models to capture the distribution of ranking preferences in a population of agents [8,30,31]. We will focus on Mallows Models and Polya-Eggenberger Urn Models (Urn) [11,32,35].\nIn Mallows models the population is distributed around a reference ranking proportional to the Kendall-Tau (KT) distance [25, 26]. Henceforth, preferences closer to the reference ranking are more likely to appear in the population. In other words, agents\u2019 preferences deviate from the reference ranking with decreasing probability as rankings move away from the reference. Mallows models are parametrized by a reference ranking and a dispersion parameter. Formally, given a reference ranking (\u0302) and a dispersion parameter (\u03c6), we have\nP ( ) = 1 Z \u03c6KT ( ,\u0302), \u2200 \u2208 P (7)\nwhere Z = 1 \u00b7 (1 + \u03c6) \u00b7 (1 + \u03c6 + \u03c62) . . . (1 + . . . + \u03c6m\u22121). When \u03c6 = 1 the Mallows model is equivalent to the uniform distribution, and when \u03c6 = 0 the distribution mass is entirely on the reference ranking. It is also possible for an agent population to have multiple references. In these cases, Mallows Mixture models are parametrized by a set of ranking reference with their corresponding dispersion parameters.\nIn the Urn distribution model, with every random selection of a preference order the probability of this preference order being selected in subsequent samples increases. Intuitively, we can think of a collection of m! preference orderings and every time an ordering is sampled uniformly from this collection, it will be replaced by two copies of the same preference ordering.\nWe use the PrefLib Toolkit [36] to generate Mallows and Urn distribution models. In our experiments, we used Mallows model with one reference ranking as well as Mallows mixture models with five reference rankings. Every data point in the figures is averaged over 1,000 samples.\nIn general, the same patterns under the uniform preference distribution hold for various numbers of agents and objects and when varying the risk parameter and utility functions.\nSocial welfare: Figures 12 and 13 show the results of our simulation for social welfare when agents\u2019 preferences are drawn from Mallows models. These results are consistent with pure Mallows models with single reference rankings (Figure 12) as well as Mallows mixture models with five references (Figure 13). The percentage change in social welfare is infinitesimal when n \u2265 m for both risk averse and risk seeking populations. Under risk aversion, this percentage change in social welfare remains small when n < m. Similar to the uniform populations, the negative values show that in some cases, particularly when n = m, RSD assignments outperform those under PS assignments.\nManipulability: The PS assignments remain very susceptible to manipulation even under more natural assumptions on how the preferences are distributed. Figures 14 illustrates the manipulability of the PS assignments and the average gain from manipulation when agents are drawn from Mallows mixture models under risk averse and risk seeking attitudes.\nThe fraction of manipulable profiles and manipulation gain goes to 0 when agents are risk seeking. Under risk aversion, the fraction of manipulable profiles and manipulation gain rapidly increases as mn grows (Figure 14). These results hold\nunder pure Mallows distribution (Figure 15) as well as under the Polya-Urn model (Figure 16) but with slightly slower growth. This is consistent with the fact that, in less diverse populations, agents\u2019 preference are more similar and conflicting, and thus manipulation is less likely (even though still significantly considerable) as opposed to more diverse and uniform set of profiles."}, {"heading": "8 Related Literature", "text": "Assignment problems with ordinal preferences have attracted interest from many researchers. Svensson showed that serial dictatorship is the only deterministic mechanism that is strategyproof, nonbossy, and neutral [48]. Random Serial Dictatorship (RSD) (uniform randomization over all serial dictatorship assignments) satisfies strategyproofness, proportionality, and ex post efficiency [2]. Bogomolnaia and Moulin noted the inefficiency of RSD from the ex ante perspective, and characterized the matching mechanisms based on first-order stochastic dominance [14]. They proposed the probabilistic serial mechanism as an efficient and envyfree mechanism with regards to ordinal preferences. While PS is not strategyproof, it satisfies weak strategyproofness for problems with equal number of agents and objects. However, PS is strictly manipulable (not weakly strategyproof) when there are more objects than agents [27]. Kojima and Manea, showed that in large assignment problems with sufficiently many copies of each object, truth-telling is a weakly dominant strategy in PS [28]. In fact PS and RSD mechanisms become equivalent [17], that is, the inefficiency of RSD and manipulability of PS vanishes when the number of copies of each object approaches infinity.\nThe practical implications of deploying RSD and PS have been the center of attention in many one-sided matching problems [1,38]. In the school choice setting with multi-capacity alternatives, Pathak observed that many students obtained a more desirable random assignment through PS in public schools of New York\nCity [41]; however, the efficiency difference was quite small. These equivalence results and their extensions to all random mechanisms [29], do not hold when the quantities of each object is limited to one.\nOther interesting aspects of PS and RSD such as computational complexity and best-response strategies have also been explored [8, 9, 19]. In this vein, Aziz et al. proved the existence of pure Nash equilibria, but showed that computing\nan equilibrium is NP-hard [8]. Nevertheless, Mennle et al. [39] showed that agents can easily find near-optimal strategies by simple local and greedy search. In the absence of truthful incentives, the outcome of PS is no longer guaranteed to be efficient or envyfree with respect to agents\u2019 true underlying preferences, and this inefficiency may result in outcomes that are worse than RSD, especially in \u2018small\u2019 markets [19]. The utilitarian and egalitarian welfare guarantees of RSD have been studied under ordinal and linear utility assumptions [7,12]. For arbitrary utilities, RSD provides the best approximation ratio for utilitarian social welfare when m = n among all mechanisms that rely only on ordinal preferences [20]."}, {"heading": "9 Discussion", "text": "We studied the space of general preferences and provided empirical results on the incomparability of RSD and PS. It is worth mentioning that at preference profiles where PS and RSD induce identical assignments, RSD is sd-efficient, sdenvyfree, and sd-strategyproof. However, PS is still highly manipulable. We further strengthen this argument by providing an observation in Example 4:\nExample 4 Consider the following preference profile = ((bca), (cab), (bca)). Table 5 shows the prescribed random assignment. In this example, with PS as the matching mechanism, agent 1 can misreport her preference as \u20321= (cba), and manipulate her assignment to 1/4(b), 1/2(c), 1/4(a). It is easy to see that agent 1\u2019s misreport improves her expected outcome for all utility models where 2 6u1(c) > 1 4u1(b) + 1 12u1(a) (for example utilities 10, 9, 0 for b, c, a respectively.).\nWe investigated various utility models according to different risk attitudes. Our findings hold under various assumptions on the population of agents and preference profile distributions. Our main results are:\n\u2013 In terms of efficiency, the fraction of preference profiles \u2208 Pn for which PS stochastically (or lexicographically) dominates RSD converges to zero as n m \u2192 1. When instantiating the preferences with actual utility functions, PS allocations are only slightly better than RSD allocations in terms of social welfare when varying n and m, particularly under risk averse utilities. In fact, in some cases RSD allocations are superior in terms of social welfare (see Figure 17). \u2013 PS is almost 99% manipulable when n \u2264 m and the fraction of sd- and ldmanipulable profiles rapidly goes to 1 as mn grows. When instantiating the preferences with utility functions, the manipulability of PS increases as agents become more risk averse. Moreover, an agent\u2019s utility gain from manipulation also grows when the risk intensity increases.\n\u2013 For risk seeking utilities, when n \u2265 m the fraction of envious agents under all profiles vanishes and RSD becomes envyfree. For risk averse utilities, the fraction of envious agents increases as agents become more risk averse. However, the total amount of envy just slightly grows, and surprisingly, only few agents feel extremely envious while all other agents are either envyfree or only feel a minimal amount of envy.\nAn interesting future direction is to study egalitarian social welfare of the matching mechanisms in single and multi unit assignment problems as well as in the full preference domain. Another open direction is to provide a parametric analysis of the matching mechanisms according to the risk aversion factor."}, {"heading": "10 Design Recommendations for Multiagent Systems Practitioners", "text": "Our work in this paper can be used to help guide designers of multiagent systems who need to solve allocation problems. If a designer strongly requires sd-efficiency then the theoretical results of PS indicate that it is better than RSD. However, our results show that PS is highly prone to manipulation for various combinations of agents and objects. This manipulation and the possible gain from manipulation become more severe particularly when agents are risk averse, and designers need to take this into consideration. On the other hand, while RSD does not theoretically guarantee sd-efficiency, our results show that it tends to do quite well \u2013 sometimes even outperforming PS in terms of social welfare. RSD also has the added advan-\ntage of being sd-strategyproof and thus is not prone to the manipulation problems of PS.\nAlthough computing RSD probabilities (fractional assignments) is #P-hard [6, 45], RSD is easy to implement in practice. However, the welfare cost of adopting manipulable mechanisms such as PS raises concern and has real consequences [16, 42]. Even though computing optimal manipulation strategies is computationally hard for the PS mechanism, evidentially individuals can easily figure out how to manipulate such mechanisms using simple greedy heuristics [16,39]. Our investigations show that in many instances RSD performs as desirably as PS in terms of social welfare. Conversely, PS assignments are highly susceptible to manipulation especially when agents are risk averse.\nThese findings suggest that in multiagent settings where mechanism designers are unsure of sincere reporting of their preferences or when agents are mostly risk averse, the use of RSD is more desirable to ensure truthful reporting while providing reasonable social welfare. However, PS is still a desirable allocation mechanism for its fairness and efficiency properties, particularly in settings where agents are sincere."}, {"heading": "A Numerical Results", "text": "The following table shows the results of comparing RSD and PS under ordinal preferences for various combinations of agents and objects. Note that in most instances, RSD and PS do not induce the same random allocation.\nDominance RSD PS manipulability\nn m Equal SD LD weakEnvy weak SD LD"}, {"heading": "2 2 100% 0% 0% 0% 0% 0% 0%", "text": ""}, {"heading": "2 3 27% 18% 29% 23% 31% 31% 31%", "text": ""}, {"heading": "2 4 10% 36% 60% 20% 53% 53% 53%", "text": ""}, {"heading": "2 5 3% 39% 78% 16% 78% 78% 78%", "text": ""}, {"heading": "2 6 1% 45% 90% 13% 87% 87% 87%", "text": ""}, {"heading": "2 7 0% 46% 95% 12% 95% 95% 95%", "text": ""}, {"heading": "2 8 0% 45% 96% 11% 97% 97% 97%", "text": ""}, {"heading": "2 9 0% 47% 96% 11% 100% 100% 100%", "text": ""}, {"heading": "2 10 0% 48% 99% 9% 99% 99% 99%", "text": ""}, {"heading": "3 2 100% 0% 0% 0% 0% 0% 0%", "text": ""}, {"heading": "3 3 67% 0% 0% 11% 24% 0% 0%", "text": ""}, {"heading": "3 4 3% 5% 40% 47% 77% 5% 5%", "text": ""}, {"heading": "3 5 0% 4% 75% 46% 96% 26% 27%", "text": ""}, {"heading": "3 6 0% 6% 84% 42% 95% 53% 54%", "text": ""}, {"heading": "3 7 0% 5% 90% 41% 100% 68% 69%", "text": ""}, {"heading": "3 8 0% 5% 93% 39% 100% 80% 83%", "text": ""}, {"heading": "3 9 0% 9% 96% 35% 100% 90% 92%", "text": ""}, {"heading": "3 10 0% 7% 95% 34% 100% 94% 94%", "text": ""}, {"heading": "4 2 62% 38% 38% 0% 0% 0% 0%", "text": ""}, {"heading": "4 3 33% 34% 46% 21% 42% 0% 0%", "text": ""}, {"heading": "4 4 21% 3% 8% 27% 72% 0% 0%", "text": ""}, {"heading": "4 5 0% 0% 48% 61% 96% 1% 1%", "text": ""}, {"heading": "4 6 0% 0% 76% 62% 98% 17% 18%", "text": ""}, {"heading": "4 7 0% 0% 84% 62% 100% 33% 35%", "text": ""}, {"heading": "4 8 0% 1% 93% 61% 99% 52% 54%", "text": ""}, {"heading": "4 9 0% 1% 94% 60% 100% 65% 69%", "text": ""}, {"heading": "4 10 0% 2% 95% 56% 100% 79% 85%", "text": ""}, {"heading": "5 2 39% 61% 61% 0% 0% 0% 0%", "text": ""}, {"heading": "5 3 8% 34% 83% 27% 66% 0% 0%", "text": ""}, {"heading": "5 4 3% 19% 53% 42% 94% 0% 0%", "text": ""}, {"heading": "5 5 6% 1% 7% 42% 90% 0% 0%", "text": ""}, {"heading": "5 6 0% 0% 58% 69% 100% 0% 0%", "text": ""}, {"heading": "5 7 0% 0% 84% 71% 100% 4% 4%", "text": ""}, {"heading": "5 8 0% 0% 91% 71% 100% 18% 18%", "text": ""}, {"heading": "5 9 0% 0% 94% 71% 100% 32% 36%", "text": ""}, {"heading": "5 10 0% 0% 97% 70% 100% 49% 55%", "text": "Continued on the next page\nDominance RSD PS manipulability\nn m Equal SD LD weakEnvy weak SD LD"}, {"heading": "6 2 21% 79% 79% 0% 0% 0% 0%", "text": ""}, {"heading": "6 3 2% 71% 96% 31% 59% 0% 0%", "text": ""}, {"heading": "6 4 0% 22% 88% 52% 90% 0% 0%", "text": ""}, {"heading": "6 5 0% 9% 46% 59% 98% 0% 0%", "text": ""}, {"heading": "6 6 3% 1% 7% 54% 96% 0% 0%", "text": ""}, {"heading": "6 7 0% 0% 62% 74% 100% 0% 0%", "text": ""}, {"heading": "6 8 0% 0% 89% 74% 100% 1% 1%", "text": ""}, {"heading": "6 9 0% 0% 95% 75% 100% 8% 9%", "text": ""}, {"heading": "6 10 0% 0% 97% 75% 100% 23% 25%", "text": ""}, {"heading": "7 2 12% 88% 88% 0% 0% 0% 0%", "text": ""}, {"heading": "7 3 1% 64% 99% 33% 83% 0% 0%", "text": ""}, {"heading": "7 4 0% 26% 97% 57% 99% 0% 0%", "text": ""}, {"heading": "7 5 0% 8% 87% 66% 100% 0% 0%", "text": ""}, {"heading": "7 6 0% 2% 41% 69% 100% 0% 0%", "text": ""}, {"heading": "7 7 1% 1% 6% 61% 99% 0% 0%", "text": ""}, {"heading": "7 8 0% 0% 71% 79% 100% 0% 0%", "text": ""}, {"heading": "7 9 0% 0% 93% 79% 100% 0% 0%", "text": ""}, {"heading": "7 10 0% 0% 96% 78% 100% 5% 6%", "text": ""}, {"heading": "8 2 8% 92% 92% 0% 0% 0% 0%", "text": ""}, {"heading": "8 3 0% 63% 100% 34% 76% 0% 0%", "text": ""}, {"heading": "8 4 0% 33% 99% 60% 95% 0% 0%", "text": ""}, {"heading": "8 5 0% 10% 97% 70% 100% 0% 0%", "text": ""}, {"heading": "8 6 0% 4% 83% 74% 100% 0% 0%", "text": ""}, {"heading": "8 7 0% 1% 29% 74% 100% 0% 0%", "text": ""}, {"heading": "8 8 0% 0% 5% 69% 99% 0% 0%", "text": ""}, {"heading": "8 9 0% 0% 70% 81% 100% 0% 0%", "text": ""}, {"heading": "8 10 0% 0% 93% 82% 100% 0% 0%", "text": ""}, {"heading": "9 2 3% 97% 97% 0% 0% 0% 0%", "text": ""}, {"heading": "9 3 0% 76% 100% 35% 70% 0% 0%", "text": ""}, {"heading": "9 4 0% 33% 100% 62% 100% 0% 0%", "text": ""}, {"heading": "9 5 0% 19% 99% 72% 100% 0% 0%", "text": ""}, {"heading": "9 6 0% 6% 98% 76% 100% 0% 0%", "text": ""}, {"heading": "9 7 0% 2% 78% 78% 100% 0% 0%", "text": ""}, {"heading": "9 8 0% 0% 26% 78% 100% 0% 0%", "text": ""}, {"heading": "9 9 0% 0% 4% 71% 100% 0% 0%", "text": ""}, {"heading": "9 10 0% 0% 69% 84% 100% 0% 0%", "text": ""}, {"heading": "10 2 2% 99% 99% 0% 0% 0% 0%", "text": ""}, {"heading": "10 3 0% 70% 100% 37% 79% 0% 0%", "text": ""}, {"heading": "10 4 0% 46% 100% 63% 98% 0% 0%", "text": ""}, {"heading": "10 5 0% 17% 100% 73% 97% 0% 0%", "text": ""}, {"heading": "10 6 0% 10% 99% 77% 100% 0% 0%", "text": ""}, {"heading": "10 7 0% 2% 95% 79% 100% 0% 0%", "text": ""}, {"heading": "10 8 0% 1% 77% 80% 100% 0% 0%", "text": ""}, {"heading": "10 9 0% 0% 21% 79% 100% 0% 0%", "text": "Continued on the next page"}, {"heading": "10 10 0% 0% 4% 73% 100% 0% 0%", "text": ""}], "references": [{"title": "Strategy-proofness versus efficiency in matching with indifferences: redesigning the new york city high school match", "author": ["A. Abdulkadiro\u011flu", "P.A. Pathak", "A.E. Roth"], "venue": "Tech. rep., National Bureau of Economic Research", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2009}, {"title": "Random serial dictatorship and the core from random endowments in house allocation problems", "author": ["A. Abdulkadiro\u011flu", "T. S\u00f6nmez"], "venue": "Econometrica 66(3), 689\u2013701", "citeRegEx": "2", "shortCiteRegEx": null, "year": 1998}, {"title": "House allocation with existing tenants", "author": ["A. Abdulkadiro\u011flu", "T. S\u00f6nmez"], "venue": "Journal of Economic Theory 88(2), 233\u2013260", "citeRegEx": "3", "shortCiteRegEx": null, "year": 1999}, {"title": "Essays in the theory of risk-bearing", "author": ["K.J. Arrow"], "venue": null, "citeRegEx": "4", "shortCiteRegEx": "4", "year": 1974}, {"title": "Mix and match: A strategyproof mechanism for multi-hospital kidney exchange", "author": ["I. Ashlagi", "F. Fischer", "I.A. Kash", "A.D. Procaccia"], "venue": "Games and Economic Behavior", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2013}, {"title": "The computational complexity of random serial dictatorship", "author": ["H. Aziz", "F. Brandt", "M. Brill"], "venue": "Economics Letters 121(3), 341\u2013345", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2013}, {"title": "Egalitarianism of random assignment mechanisms", "author": ["H. Aziz", "J. Chen", "A. Filos-Ratsikas", "S. Mackenzie", "N. Mattei"], "venue": "arXiv preprint arXiv:1507.06827", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2015}, {"title": "Equilibria under the probabilistic serial rule", "author": ["H. Aziz", "S. Gaspers", "S. Mackenzie", "N. Mattei", "N. Narodytska", "T. Walsh"], "venue": "Proceedings of the 24th International Conference on Artificial Intelligence, IJCAI 2015, pp. 1105\u20131112. AAAI Press", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2015}, {"title": "Manipulating the probabilistic serial rule", "author": ["H. Aziz", "S. Gaspers", "S. Mackenzie", "N. Mattei", "N. Narodytska", "T. Walsh"], "venue": "Proceedings of the 14th International Conference on Autonomous Agents and Multiagent Systems (AAMAS 2015), pp. 1451\u20131459. International Foundation for Autonomous Agents and Multiagent Systems", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2015}, {"title": "Fair assignment of indivisible objects under ordinal preferences", "author": ["H. Aziz", "S. Gaspers", "S. Mackenzie", "T. Walsh"], "venue": "Artificial Intelligence 227, 71\u201392", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2015}, {"title": "Paradox of voting under an urn model: the effect of homogeneity", "author": ["S. Berg"], "venue": "Public Choice 47(2), 377\u2013387", "citeRegEx": "11", "shortCiteRegEx": null, "year": 1985}, {"title": "Social welfare in one-sided matching markets without money", "author": ["A. Bhalgat", "D. Chakrabarty", "S. Khanna"], "venue": "Approximation, Randomization, and Combinatorial Optimization. Algorithms and Techniques, pp. 87\u201398. Springer", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2011}, {"title": "Probabilistic assignment of objects: Characterizing the serial rule", "author": ["A. Bogomolnaia", "E.J. Heo"], "venue": "Journal of Economic Theory 147(5), 2072\u20132082", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2012}, {"title": "A new solution to the random assignment problem", "author": ["A. Bogomolnaia", "H. Moulin"], "venue": "Journal of Economic Theory 100(2), 295\u2013328", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2001}, {"title": "Manipulating picking sequences", "author": ["S. Bouveret", "J. Lang"], "venue": "In Proceedings of the 21st European Conference on Artificial Intelligence (ECAI14), pp. 141\u2013146. IOS Press, Prague, Czech Republic", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2014}, {"title": "The multi-unit assignment problem: Theory and evidence from course allocation at harvard", "author": ["E. Budish", "E. Cantillon"], "venue": "The American economic review 102(5), 2237\u201371", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2012}, {"title": "Asymptotic equivalence of probabilistic serial and random priority mechanisms", "author": ["Y.K. Che", "F. Kojima"], "venue": "Econometrica 78(5), 1625\u20131672", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2010}, {"title": "Preferences in AI: An overview", "author": ["C. Domshlak", "E. H\u00fcllermeier", "S. Kaci", "H. Prade"], "venue": "Artificial Intelligence 175(7), 1037\u20131052", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2011}, {"title": "An equilibrium analysis of the probabilistic serial mechanism", "author": ["\u00d6. Ekici", "O. Kesten"], "venue": "International Journal of Game Theory pp. 1\u201320", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2015}, {"title": "Social welfare in one-sided matchings: Random priority and beyond", "author": ["A. Filos-Ratsikas", "S.K.S. Frederiksen", "J. Zhang"], "venue": "Algorithmic Game Theory, pp. 1\u201312. Springer", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2014}, {"title": "Lexicographic orders, utilities and decision rules: A survey", "author": ["P.C. Fishburn"], "venue": "Management Science pp. 1442\u20131471", "citeRegEx": "21", "shortCiteRegEx": null, "year": 1974}, {"title": "Rules for ordering uncertain prospects", "author": ["J. Hadar", "W.R. Russell"], "venue": "The American Economic Review pp. 25\u201334", "citeRegEx": "22", "shortCiteRegEx": null, "year": 1969}, {"title": "Strategyproof quota mechanisms for multiple assignment problems", "author": ["H. Hosseini", "K. Larson"], "venue": "arXiv preprint arXiv:1507.07064", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2015}, {"title": "An experimental study on the incentives of the probabilistic serial mechanism", "author": ["D. Hugh-Jones", "M. Kurino", "C. Vanberg"], "venue": "Tech. rep., Discussion Paper, Social Science Research Center Berlin (WZB), Research Area Markets and Politics, Research Unit Market Behavior", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2013}, {"title": "A new measure of rank correlation", "author": ["M.G. Kendall"], "venue": "Biometrika 30(1/2), 81\u201393", "citeRegEx": "25", "shortCiteRegEx": null, "year": 1938}, {"title": "Rank correlation methods", "author": ["M.G. Kendall"], "venue": null, "citeRegEx": "26", "shortCiteRegEx": "26", "year": 1948}, {"title": "Random assignment of multiple indivisible objects", "author": ["F. Kojima"], "venue": "Mathematical Social Sciences 57(1), 134\u2013142", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2009}, {"title": "Incentives in the probabilistic serial mechanism", "author": ["F. Kojima", "M. Manea"], "venue": "Journal of Economic Theory 145(1), 106\u2013123", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2010}, {"title": "Ordinal efficiency, fairness, and incentives in large markets", "author": ["Q. Liu", "M. Pycia"], "venue": "Unpublished mimeo", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2013}, {"title": "Learning mallows models with pairwise preferences", "author": ["T. Lu", "C. Boutilier"], "venue": "Proceedings of the 28th international conference on machine learning (ICML-11), pp. 145\u2013152", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2011}, {"title": "Robust approximation and incremental elicitation in voting protocols", "author": ["T. Lu", "C. Boutilier"], "venue": "In Proceedings of the 22nd International Joint Conference on Artificial Intelligence, IJCAI 2011, vol. 22, p. 287", "citeRegEx": "31", "shortCiteRegEx": null, "year": 2011}, {"title": "Non-null ranking models", "author": ["C.L. Mallows"], "venue": "Biometrika 44(1/2), 114\u2013130", "citeRegEx": "32", "shortCiteRegEx": null, "year": 1957}, {"title": "Asymptotic ordinal inefficiency of random serial dictatorship", "author": ["M. Manea"], "venue": "Theoretical Economics 4(2), 165\u2013197", "citeRegEx": "33", "shortCiteRegEx": null, "year": 2009}, {"title": "Algorithmics of matching under preferences", "author": ["D. Manlove"], "venue": "World Scientific Publishing", "citeRegEx": "34", "shortCiteRegEx": null, "year": 2013}, {"title": "Analyzing and modeling rank data", "author": ["J.I. Marden"], "venue": "Chapman & Hall/CRC Monographs on Statistics & Applied Probability", "citeRegEx": "35", "shortCiteRegEx": null, "year": 1996}, {"title": "Preflib: A library of preference data http://preflib.org", "author": ["N. Mattei", "T. Walsh"], "venue": "Proceedings of the 3rd International Conference on Algorithmic Decision Theory (ADT", "citeRegEx": "36", "shortCiteRegEx": "36", "year": 2013}, {"title": "Ordinal efficiency and the polyhedral separating hyperplane theorem", "author": ["A. McLennan"], "venue": "Journal of Economic Theory 105(2), 435\u2013449", "citeRegEx": "37", "shortCiteRegEx": null, "year": 2002}, {"title": "Hybrid mechanisms: Trading off strategyproofness and efficiency in one-sided matching", "author": ["T. Mennle", "S. Seuken"], "venue": "Tech. rep.", "citeRegEx": "38", "shortCiteRegEx": null, "year": 2014}, {"title": "The power of local manipulation strategies in assignment mechanisms", "author": ["T. Mennle", "M. Weiss", "B. Philipp", "S. Seuken"], "venue": "Proceedings of the 24th International Conference on Artificial Intelligence, IJCAI\u201915, pp. 82\u201389. AAAI Press", "citeRegEx": "39", "shortCiteRegEx": null, "year": 2015}, {"title": "Strategyproof multiple assignment using quotas", "author": ["S. P\u00e1pai"], "venue": "Review of Economic Design 5(1), 91\u2013105", "citeRegEx": "40", "shortCiteRegEx": null, "year": 2000}, {"title": "Lotteries in student assignment", "author": ["P.A. Pathak"], "venue": "Unpublished mimeo, Harvard University", "citeRegEx": "41", "shortCiteRegEx": null, "year": 2006}, {"title": "Lotteries in student assignment: An equivalence result", "author": ["P.A. Pathak", "J. Sethuraman"], "venue": "Theoretical Economics 6(1), 1\u201317", "citeRegEx": "42", "shortCiteRegEx": null, "year": 2011}, {"title": "Kidney exchange", "author": ["A.E. Roth", "T. S\u00f6nmez", "M.U. \u00dcnver"], "venue": "The Quarterly Journal of Economics 119(2), 457\u2013488", "citeRegEx": "43", "shortCiteRegEx": null, "year": 2004}, {"title": "A note on object allocation under lexicographic preferences", "author": ["D. Saban", "J. Sethuraman"], "venue": "Journal of Mathematical Economics", "citeRegEx": "44", "shortCiteRegEx": null, "year": 2013}, {"title": "The complexity of computing the random priority allocation matrix", "author": ["D. Saban", "J. Sethuraman"], "venue": "Mathematics of Operations Research 40(4), 1005\u20131014", "citeRegEx": "45", "shortCiteRegEx": null, "year": 2015}, {"title": "Allocation of divisible goods under lexicographic preferences", "author": ["L.J. Schulman", "V.V. Vazirani"], "venue": "arXiv preprint arXiv:1206.4366", "citeRegEx": "46", "shortCiteRegEx": null, "year": 2012}, {"title": "Course bidding at business schools", "author": ["T. S\u00f6nmez", "M.U. \u00dcnver"], "venue": "International Economic Review 51(1), 99\u2013123", "citeRegEx": "47", "shortCiteRegEx": null, "year": 2010}, {"title": "Strategy-proof allocation of indivisible goods", "author": ["L.G. Svensson"], "venue": "Social Choice and Welfare 16(4), 557\u2013567", "citeRegEx": "48", "shortCiteRegEx": null, "year": 1999}, {"title": "A certain zero-sum two-person game equivalent to the optimal assignment problem", "author": ["J. Von Neumann"], "venue": "Contributions to the Theory of Games 2, 5\u201312", "citeRegEx": "49", "shortCiteRegEx": null, "year": 1953}], "referenceMentions": [{"referenceID": 4, "context": "dents to public schools, college courses to students, organs and medical resources to patients, and members to subcommittees [5, 16, 34, 43].", "startOffset": 125, "endOffset": 140}, {"referenceID": 15, "context": "dents to public schools, college courses to students, organs and medical resources to patients, and members to subcommittees [5, 16, 34, 43].", "startOffset": 125, "endOffset": 140}, {"referenceID": 33, "context": "dents to public schools, college courses to students, organs and medical resources to patients, and members to subcommittees [5, 16, 34, 43].", "startOffset": 125, "endOffset": 140}, {"referenceID": 42, "context": "dents to public schools, college courses to students, organs and medical resources to patients, and members to subcommittees [5, 16, 34, 43].", "startOffset": 125, "endOffset": 140}, {"referenceID": 1, "context": "Two prominent (randomized) matching mechanisms that only elicit ordinal preferences from agents are Random Serial Dictatorship (RSD) [2] and Probabilistic Serial Rule (PS) [14].", "startOffset": 133, "endOffset": 136}, {"referenceID": 13, "context": "Two prominent (randomized) matching mechanisms that only elicit ordinal preferences from agents are Random Serial Dictatorship (RSD) [2] and Probabilistic Serial Rule (PS) [14].", "startOffset": 172, "endOffset": 176}, {"referenceID": 1, "context": "Investigating the Characteristics of One-Sided Matching Mechanisms 3 2 Preliminaries In this section, we describe the basic one-sided matching problem and introduce the two mechanisms we study in detail, Random Serial Dictatorship (RSD) [2] and Probabilistic Serial Rule (PS) [14].", "startOffset": 237, "endOffset": 240}, {"referenceID": 13, "context": "Investigating the Characteristics of One-Sided Matching Mechanisms 3 2 Preliminaries In this section, we describe the basic one-sided matching problem and introduce the two mechanisms we study in detail, Random Serial Dictatorship (RSD) [2] and Probabilistic Serial Rule (PS) [14].", "startOffset": 276, "endOffset": 280}, {"referenceID": 0, "context": "An,m \uf8f7\uf8f7\uf8f7\uf8f8 where Ai,j \u2208 [0, 1] is the probability that agent i is assigned object j.", "startOffset": 23, "endOffset": 29}, {"referenceID": 48, "context": "Every random assignment can be represented as a convex combination of deterministic assignments [49], and thus we view random assignments as a probability distribution over a set of deterministic assignments.", "startOffset": 96, "endOffset": 100}, {"referenceID": 1, "context": "We focus our attention on two widely studied mechanisms for one-side matching: Random Serial Dictatorship (RSD) [2] and Probabilistic Serial Rule (PS) [13].", "startOffset": 112, "endOffset": 115}, {"referenceID": 12, "context": "We focus our attention on two widely studied mechanisms for one-side matching: Random Serial Dictatorship (RSD) [2] and Probabilistic Serial Rule (PS) [13].", "startOffset": 151, "endOffset": 155}, {"referenceID": 0, "context": "RSD has been widely adopted for fair and strategyproof assignments for the school choice problem, course assignment, house allocation, and room assignment [1\u20133,47] PS treats objects as a set of divisible goods of equal size and simulates a simultaneous eating algorithm.", "startOffset": 155, "endOffset": 163}, {"referenceID": 1, "context": "RSD has been widely adopted for fair and strategyproof assignments for the school choice problem, course assignment, house allocation, and room assignment [1\u20133,47] PS treats objects as a set of divisible goods of equal size and simulates a simultaneous eating algorithm.", "startOffset": 155, "endOffset": 163}, {"referenceID": 2, "context": "RSD has been widely adopted for fair and strategyproof assignments for the school choice problem, course assignment, house allocation, and room assignment [1\u20133,47] PS treats objects as a set of divisible goods of equal size and simulates a simultaneous eating algorithm.", "startOffset": 155, "endOffset": 163}, {"referenceID": 46, "context": "RSD has been widely adopted for fair and strategyproof assignments for the school choice problem, course assignment, house allocation, and room assignment [1\u20133,47] PS treats objects as a set of divisible goods of equal size and simulates a simultaneous eating algorithm.", "startOffset": 155, "endOffset": 163}, {"referenceID": 13, "context": "To evaluate the quality of a random assignment, we use first-order stochastic dominance [14, 22].", "startOffset": 88, "endOffset": 96}, {"referenceID": 21, "context": "To evaluate the quality of a random assignment, we use first-order stochastic dominance [14, 22].", "startOffset": 88, "endOffset": 96}, {"referenceID": 14, "context": "This picking sequence should be based on an arbitrary serial dictatorship quota mechanism, which directly affects the efficiency and envy of the assignments [15, 23].", "startOffset": 157, "endOffset": 165}, {"referenceID": 22, "context": "This picking sequence should be based on an arbitrary serial dictatorship quota mechanism, which directly affects the efficiency and envy of the assignments [15, 23].", "startOffset": 157, "endOffset": 165}, {"referenceID": 39, "context": "For simplicity, we use the variant of RSD based on a quasi-dictatorial mechanism [40] where the first agent selects its most preferred (m\u2212 n+ 1) objects, and the rest of the agents choose one object each.", "startOffset": 81, "endOffset": 85}, {"referenceID": 13, "context": "3 Properties of RSD and PS The theoretical properties of PS and RSD have been well studied in the economics literature [14], and we summarize the results in Table 1.", "startOffset": 119, "endOffset": 123}, {"referenceID": 27, "context": "However, it is not even weakly sd-strategyproof when n < m [28] and is only weakly sd-strategyproof when n \u2265 m.", "startOffset": 59, "endOffset": 63}, {"referenceID": 17, "context": "Lexicographic preferences are present in various applications and have been extensively studied in artificial intelligence and multiagent systems as a means of assessing allocations based on ordinal preferences [18, 21, 44].", "startOffset": 211, "endOffset": 223}, {"referenceID": 20, "context": "Lexicographic preferences are present in various applications and have been extensively studied in artificial intelligence and multiagent systems as a means of assessing allocations based on ordinal preferences [18, 21, 44].", "startOffset": 211, "endOffset": 223}, {"referenceID": 43, "context": "Lexicographic preferences are present in various applications and have been extensively studied in artificial intelligence and multiagent systems as a means of assessing allocations based on ordinal preferences [18, 21, 44].", "startOffset": 211, "endOffset": 223}, {"referenceID": 5, "context": "Note that not only is computing RSD probabilities #P-complete (and thus intractable) [6, 45], but checking the desired properties such as envyfreeness, efficiency, and manipulablity of random allocations is shown to be NP-hard for general settings [9, 10].", "startOffset": 85, "endOffset": 92}, {"referenceID": 44, "context": "Note that not only is computing RSD probabilities #P-complete (and thus intractable) [6, 45], but checking the desired properties such as envyfreeness, efficiency, and manipulablity of random allocations is shown to be NP-hard for general settings [9, 10].", "startOffset": 85, "endOffset": 92}, {"referenceID": 8, "context": "Note that not only is computing RSD probabilities #P-complete (and thus intractable) [6, 45], but checking the desired properties such as envyfreeness, efficiency, and manipulablity of random allocations is shown to be NP-hard for general settings [9, 10].", "startOffset": 248, "endOffset": 255}, {"referenceID": 9, "context": "Note that not only is computing RSD probabilities #P-complete (and thus intractable) [6, 45], but checking the desired properties such as envyfreeness, efficiency, and manipulablity of random allocations is shown to be NP-hard for general settings [9, 10].", "startOffset": 248, "endOffset": 255}, {"referenceID": 32, "context": "of Manea on asymptotic inefficiency of RSD [33], in that, in most instances, the assignments induced by RSD are not identical to the PS assignments.", "startOffset": 43, "endOffset": 47}, {"referenceID": 13, "context": "Although for n \u2265 m PS is weakly sd-strategyproof [14]", "startOffset": 49, "endOffset": 53}, {"referenceID": 45, "context": "and ld-strategyproof [46], when n < m PS no longer satisfies these two properties.", "startOffset": 21, "endOffset": 25}, {"referenceID": 23, "context": "However, subjects\u2019 tendency for misreporting is still significant even when it does not improve their allocations [24].", "startOffset": 114, "endOffset": 118}, {"referenceID": 13, "context": "A random assignment A is sd-efficient if and only if there exists a profile of utility values consistent with such that A maximizes the social welfare ex ante [14,37].", "startOffset": 159, "endOffset": 166}, {"referenceID": 36, "context": "A random assignment A is sd-efficient if and only if there exists a profile of utility values consistent with such that A maximizes the social welfare ex ante [14,37].", "startOffset": 159, "endOffset": 166}, {"referenceID": 3, "context": "An exponential utility has been shown to provide an appropriate translation for individuals\u2019 utility models [4].", "startOffset": 108, "endOffset": 111}, {"referenceID": 22, "context": "Intuitively, these observations confirm the theoretical findings about the envyfreeness of RSD under lexicographic preferences [23].", "startOffset": 127, "endOffset": 131}, {"referenceID": 22, "context": "less preferably [23].", "startOffset": 16, "endOffset": 20}, {"referenceID": 7, "context": "Investigating the Characteristics of One-Sided Matching Mechanisms 21 work in computational social choice and machine learning has exploited these statistical models to capture the distribution of ranking preferences in a population of agents [8,30,31].", "startOffset": 243, "endOffset": 252}, {"referenceID": 29, "context": "Investigating the Characteristics of One-Sided Matching Mechanisms 21 work in computational social choice and machine learning has exploited these statistical models to capture the distribution of ranking preferences in a population of agents [8,30,31].", "startOffset": 243, "endOffset": 252}, {"referenceID": 30, "context": "Investigating the Characteristics of One-Sided Matching Mechanisms 21 work in computational social choice and machine learning has exploited these statistical models to capture the distribution of ranking preferences in a population of agents [8,30,31].", "startOffset": 243, "endOffset": 252}, {"referenceID": 10, "context": "We will focus on Mallows Models and Polya-Eggenberger Urn Models (Urn) [11,32,35].", "startOffset": 71, "endOffset": 81}, {"referenceID": 31, "context": "We will focus on Mallows Models and Polya-Eggenberger Urn Models (Urn) [11,32,35].", "startOffset": 71, "endOffset": 81}, {"referenceID": 34, "context": "We will focus on Mallows Models and Polya-Eggenberger Urn Models (Urn) [11,32,35].", "startOffset": 71, "endOffset": 81}, {"referenceID": 24, "context": "In Mallows models the population is distributed around a reference ranking proportional to the Kendall-Tau (KT) distance [25, 26].", "startOffset": 121, "endOffset": 129}, {"referenceID": 25, "context": "In Mallows models the population is distributed around a reference ranking proportional to the Kendall-Tau (KT) distance [25, 26].", "startOffset": 121, "endOffset": 129}, {"referenceID": 35, "context": "We use the PrefLib Toolkit [36] to generate Mallows and Urn distribution models.", "startOffset": 27, "endOffset": 31}, {"referenceID": 47, "context": "Svensson showed that serial dictatorship is the only deterministic mechanism that is strategyproof, nonbossy, and neutral [48].", "startOffset": 122, "endOffset": 126}, {"referenceID": 1, "context": "Random Serial Dictatorship (RSD) (uniform randomization over all serial dictatorship assignments) satisfies strategyproofness, proportionality, and ex post efficiency [2].", "startOffset": 167, "endOffset": 170}, {"referenceID": 13, "context": "Bogomolnaia and Moulin noted the inefficiency of RSD from the ex ante perspective, and characterized the matching mechanisms based on first-order stochastic dominance [14].", "startOffset": 167, "endOffset": 171}, {"referenceID": 26, "context": "However, PS is strictly manipulable (not weakly strategyproof) when there are more objects than agents [27].", "startOffset": 103, "endOffset": 107}, {"referenceID": 27, "context": "Kojima and Manea, showed that in large assignment problems with sufficiently many copies of each object, truth-telling is a weakly dominant strategy in PS [28].", "startOffset": 155, "endOffset": 159}, {"referenceID": 16, "context": "In fact PS and RSD mechanisms become equivalent [17], that is, the inefficiency of RSD and manipulability of PS vanishes when the number of copies of each object approaches infinity.", "startOffset": 48, "endOffset": 52}, {"referenceID": 0, "context": "The practical implications of deploying RSD and PS have been the center of attention in many one-sided matching problems [1,38].", "startOffset": 121, "endOffset": 127}, {"referenceID": 37, "context": "The practical implications of deploying RSD and PS have been the center of attention in many one-sided matching problems [1,38].", "startOffset": 121, "endOffset": 127}, {"referenceID": 40, "context": "City [41]; however, the efficiency difference was quite small.", "startOffset": 5, "endOffset": 9}, {"referenceID": 28, "context": "These equivalence results and their extensions to all random mechanisms [29], do not hold when the quantities of each object is limited to one.", "startOffset": 72, "endOffset": 76}, {"referenceID": 7, "context": "Other interesting aspects of PS and RSD such as computational complexity and best-response strategies have also been explored [8, 9, 19].", "startOffset": 126, "endOffset": 136}, {"referenceID": 8, "context": "Other interesting aspects of PS and RSD such as computational complexity and best-response strategies have also been explored [8, 9, 19].", "startOffset": 126, "endOffset": 136}, {"referenceID": 18, "context": "Other interesting aspects of PS and RSD such as computational complexity and best-response strategies have also been explored [8, 9, 19].", "startOffset": 126, "endOffset": 136}, {"referenceID": 7, "context": "a b c A1 1/3 1/2 1/6 A2 1/3 0 2/3 A3 1/3 1/2 1/6 an equilibrium is NP-hard [8].", "startOffset": 75, "endOffset": 78}, {"referenceID": 38, "context": "[39] showed that agents can easily find near-optimal strategies by simple local and greedy search.", "startOffset": 0, "endOffset": 4}, {"referenceID": 18, "context": "In the absence of truthful incentives, the outcome of PS is no longer guaranteed to be efficient or envyfree with respect to agents\u2019 true underlying preferences, and this inefficiency may result in outcomes that are worse than RSD, especially in \u2018small\u2019 markets [19].", "startOffset": 262, "endOffset": 266}, {"referenceID": 6, "context": "The utilitarian and egalitarian welfare guarantees of RSD have been studied under ordinal and linear utility assumptions [7,12].", "startOffset": 121, "endOffset": 127}, {"referenceID": 11, "context": "The utilitarian and egalitarian welfare guarantees of RSD have been studied under ordinal and linear utility assumptions [7,12].", "startOffset": 121, "endOffset": 127}, {"referenceID": 19, "context": "For arbitrary utilities, RSD provides the best approximation ratio for utilitarian social welfare when m = n among all mechanisms that rely only on ordinal preferences [20].", "startOffset": 168, "endOffset": 172}], "year": 2017, "abstractText": "One-sided matching mechanisms are fundamental for assigning a set of indivisible objects to a set of self-interested agents when monetary transfers are not allowed. Two widely-studied randomized mechanisms in multiagent settings are the Random Serial Dictatorship (RSD) and the Probabilistic Serial Rule (PS). Both mechanisms require only that agents specify ordinal preferences and have a number of desirable economic and computational properties. However, the induced outcomes of the mechanisms are often incomparable and thus there are challenges when it comes to deciding which mechanism to adopt in practice. In this paper, we first consider the space of general ordinal preferences and provide empirical results on the (in)comparability of RSD and PS. We analyze their respective economic properties under general and lexicographic preferences. We then instantiate utility functions with the goal of gaining insights on the manipulability, efficiency, and envyfreeness of the mechanisms under different riskattitude models. Our results hold under various preference distribution models, which further confirm the broad use of RSD in most practical applications.", "creator": "LaTeX with hyperref package"}}}