{"id": "1703.00380", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "1-Mar-2017", "title": "Personal Model Training under Privacy Constraints", "abstract": "Many current Internet services rely on inferences from models trained on user data. Commonly, both the training and inference tasks are carried out using cloud resources fed by personal data collected at scale from users. Holding and using such large collections of personal data in the cloud creates privacy risks to the data subjects, but is currently required for users to benefit from such services. Although data in the cloud has been collected from users for over 10 years, it can be used to map traffic to user information and provide insights into other activities, including driving or other drivers.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "histories": [["v1", "Wed, 1 Mar 2017 16:50:44 GMT  (1162kb,D)", "https://arxiv.org/abs/1703.00380v1", "Databox Project Technical Report"], ["v2", "Wed, 21 Jun 2017 15:02:12 GMT  (440kb,D)", "http://arxiv.org/abs/1703.00380v2", "Databox Project Technical Report"]], "COMMENTS": "Databox Project Technical Report", "reviews": [], "SUBJECTS": "cs.LG", "authors": ["sandra servia-rodriguez", "liang wang", "jianxin r zhao", "richard mortier", "hamed haddadi"], "accepted": false, "id": "1703.00380"}, "pdf": {"name": "1703.00380.pdf", "metadata": {"source": "CRF", "title": "Personal Model Training under Privacy Constraints", "authors": ["Sandra Servia-Rodriguez", "Liang Wang", "Jianxin R. Zhao", "Richard Mortier", "Hamed Haddadi"], "emails": [], "sections": [{"heading": "1. INTRODUCTION", "text": "Large-scale data collection from individuals is at the heart of many current Internet business models. Access to these data allow companies to train models from which to infer user behaviour and preferences, typically leveraging the generous computation resources available in the public cloud. Unfortunately, this data collection is increasingly pervasive and invasive, notwithstanding regulatory frameworks such as the EU\u2019s General Data Protection Regulation (GDPR) which attempt to restrain it. The result is that user privacy is compromised, and this is becoming an increasing concern due to reporting of the ongoing stream of security breaches that result in malicious parties accessing such personal data.\nSuch data collection causes privacy to be compromised even without security being breached though. For example, consider wearable devices that report data they collect from in-built sensors, e.g., accelerometer traces and heart rate data, to the device manufacturer. The device might anonymise such data for the manufacturer to use in improving their models for recognising the user\u2019s current activity, an entirely le-\ngitimate and non-invasive practice. However, the manufacturer might fail to effectively anonymise these data and instead use them for other purposes such as determining mood, or even to sell to third-parties without the users\u2019 knowledge. It is not only data from wearables that creates such risks: web queries, article reads and searches, visits to shopping sites and browsing online catalogues are also indexed, analysed, and traded by thousands of tracking services in order to build preference models [25].\nSo far, users\u2019 personal data were mainly sensed through their computers, their smartphones or wearable devices such as smartwatches and smart wristbands. But nowadays smart technology is entering into our homes. We are heading towards an ecosystem to the revolution where sooner or later, every device in our home will talk to an Amazon Echo [1], Google Home [3], or Apple HomeKit [2]. Apart from controlling smart home appliances such as light bulbs and thermostats with our voice, these smart controllers for the entire home will be required to perform more complex tasks such as detecting how many people are in the house and who they are, recognising the activity they are performing or even telling us what to wear. In this new scenario, users are becoming progressively more aware of the privacy risks of sharing their voice, video or any other data sensed in their homes with the service providers, at the same time that these applications are demanding more accurate and personalised solutions. Sending personal data to the public cloud to perform these tasks seems no longer to be an acceptable solution, but solutions should take advantage of the resource capabilities of personal devices and bring the processing locally, where data resides.\nApproaches such as homomorphic encryption allow user data to be encrypted, protecting against unintended release of such data, while still being amenable to data processing. This affords users better privacy \u2013 their data cannot be used arbitrarily \u2013 while allowing data processors to collect and use such data in cloud computing environments. However, current practical techniques limit the forms of computation that can be supported. We are interested in an alternative approach where we reduce or remove the flow of user data to the cloud completely, instead moving computation to where the data already resides under the user\u2019s control [20, 41]. This can mitigate risks of breach and misuse of data by sim-\nar X\niv :1\n70 3.\n00 38\n0v 2\n[ cs\n.L G\n] 2\n1 Ju\nn 20\n17\nply avoiding it being collected at scale in the first place: attack incentives are reduced as the attacker must gain access to millions of devices to capture data for millions of users, rather than accessing a single cloud service. However, it presents challenges for the sorts of model learning processes required: how can such models be learnt without access to the users\u2019 personal data?\nIn this paper we address these challenges using the Edge Computing paradigm. Specifically, our contributions include: (i) we develop our personal training method for implementing machine learning in an environment where personal data largely remains on constrained devices under the control of the data subject (\u00a72); (ii) we apply this method to two wellknown learning tasks, one supervised (activity recognition from accelerometer traces, \u00a73), and one unsupervised (modelling topics in text documents, \u00a74) and report the results; and (iii) we explore the robustness of our method against adversarial attacks, as well as the feasibility of implementing such techniques on a representative resource-constrained personal device: a Raspberry Pi 3 Model B [6] (\u00a75).\nThe essence of our approach is a two-step process: (i) we first train a shared model using a small set of voluntarily shared users\u2019 data and distribute this model to all users; and (ii) we then retrain this model locally using personal data held by each user, drawing inferences from the resulting personal model. We evaluate this approach using (i) a neural network to recognise users\u2019 activity on the WISDM dataset [36] and (ii) the Latent Dirichlet Algorithm (LDA) [17] to identify topics in the Wikipedia and NIPS datasets [4, 9]. In both cases we show that the model resulting from local re-training of an initial model learnt from a small set of users performs with higher accuracy than either the initial model alone or a model trained using only data from the specific user of interest.\nWe also demonstrate the feasibility of training and testing a small classifier in a resource-constraint, light-weight personal device: a Raspberry Pi 3 Model B [6]. We find that such a device is certainly capable of supporting these algorithms, with negligible time to obtain inferences (on the order of milliseconds), and reasonable training times as well (on the order of tens of seconds)."}, {"heading": "2. METHODOLOGY", "text": "The current approach, which we wish to avoid, of sending all users\u2019 personal data to the cloud for processing, is one extreme of a spectrum whose other extreme would be to train a model for a specific user using only that user\u2019s data. For some applications, e.g., activity recognition, it has been shown that a model trained solely using data from the individual concerned provides more accurate predictions for that individual than a model trained using data from other individuals [50]. At the same time, this solution offers more privacy to the user as all computation, for both training and inference, can be done locally on the device [20]. However, this approach leads to substantial interactional overheads as\ntraining the model will likely require each user to label a significant amount of data by hand before they can obtain accurate inferences.\nWe propose and evaluate an alternative, hybrid approach that splits computation between the cloud and the users\u2019 personal devices. We start by first training a model in the cloud using data from a small (relative to the population) set of users. We then distribute this shared model to users\u2019 personal devices, where it can be used locally to generate inferences. In addition, it can be retrained using locally-stored personal data to become a personal model, specialised for the user in question.\nWe now describe this approach following the overview depicted in Figure 1. For clarity of exposition, we first describe our approach in the case of supervised learning, taking the activity recognition task we later use in our evaluation as a running example. We then generalise this description to other applications, including our second evaluation example of identifying topics in documents which uses an unsupervised algorithm. This suggests that any learning task, supervised or unsupervised, is amenable to our approach allowing features extracted from users\u2019 personal data that they do not wish to disclose to be used to further personalise the initial shared model.\nWe start by training a shared model, MS , to recognise the activity that the user is performing using data sensed with his smartphone\u2019s built-in sensors. This batch learning is done on a remote server in the cloud using available public data, dp. In the event of not having sufficient public data available for this task, data can be previously gathered from a set of users that have agreed to share their personal data perhaps by providing them with suitable incentives. To assure the confidentiality of their data as well as their presence in the dataset, the shared model might be obtained using differentially private training [46, 39, 28, 44].\nThe user u then obtains the shared model from the remote server. With every new sample or group of samples gathered from the smartphone\u2019s sensors, the activity that the user is performing is locally inferred using this model. In order to allow for more accurate inferences, the user is prompted to \u201cvalidate\u201d the results by reporting the activity they were performing. The new labelled data so gathered are then used for locally retraining the model, resulting in a new personal model, MP ."}, {"heading": "2.1 Architecture", "text": "Having described our approach, we now sketch a system architecture that might be used to implement it. This is divided into two parts: (i) residing in the cloud, the first part is responsible for constructing a shared model using batch learning; and (ii) residing on each individual user\u2019s device, the second part tunes the model from the first part using the locally available data, resulting in a personal model.\nWe identify five components in this architecture:\n1. The batch training module resides in the cloud, and is responsible for training a shared model as the starting point using public, or private but shared, datasets that it also maintains. As this component may need to support multiple applications, it will provide a collection of different machine learning algorithms to build various needed models. It may also need to perform more traditional, large scale processing, but can easily be built using modern data processing frameworks designed for datacenters such as Mllib [40] or GraphLab [38].\n2. The distribution module resides on users\u2019 devices and is responsible for obtaining the shared model and maintaining it locally. In the case of very large scale deployments, standard content distribution or even peerto-peer techniques could be used to alleviate load on the cloud service.\n3. The personalisation module builds a personal model by refining the model parameters of the shared model using the personal data available on the user\u2019s device. This module will also require a repository of different learning algorithms, but the nature of personal computational devices means that there will be greater resource constraints applied to the performance and efficiency of the algorithm implementation.\n4. The communication module handles all the communications between peers or those between an individual node and the server. Nodes can register themselves with the server, on top of which we can implement more sophisticated membership management.\n5. The inference module provides a service at the client to respond to model queries, using the most refined model available.\nIn our implementation, we rely on several existing software libraries to provide the more mundane of these functions, e.g., ZeroMQ [10] satisfies most of the requirements of the communication and model distribution modules, and so we do not discuss these further here.\nThere are many toolkits, e.g., theano [8] and scikit-learn [7], that provide a rich set of machine learning algorithms for use in the batch training and personalisation modules. However, in the case of the latter, we must balance convenience with performance considerations due to the resource-constrained nature of these devices. In light of this, we use a more recent library, Owl [5], to generate more compact and efficient native code on a range of platforms."}, {"heading": "2.2 Typical Workflow", "text": "We briefly summarise the workflow we envisage using activity recognition as an example.\n1. When the user activates the device for the first time, the device contacts the server and registers itself in order to join the system. The device notices there is no local data for building the model, and sends a request to the server to obtain the shared model.\n2. After processing the registration, the server receives the download request. The shared model has been trained using a initial dataset collected in a suitably ethical and trustworthy way, e.g., with informed consent, appropriate compensation, and properly anonymised. The server can either approve the download request, or return a list of peers from whom the requesting user can retrieve the model.\n3. Having obtained the shared model, the device can start processing inference requests. At the same time, the device continuously collects user\u2019s personal data, in this case, their accelerometer traces. Once enough local data is collected, the personalisation phase starts, refining the shared model to create a personal model.\n4. After the personal model has been built, the system uses it to serve requests, and continues to refine it as more personal data is collected.\nThis methodology and hypothesised architecture can be applied to supervised and unsupervised learning tasks in different domains. We next show how it applies to (supervised) activity recognition (\u00a73) and (unsupervised) topic modelling (\u00a74) using two well-known learning algorithms respectively."}, {"heading": "3. ACTIVITY RECOGNITION USING ACCELEROMETER TRACES", "text": "In this section, we validate our methodology for supervised learning using a neural network to recognise users\u2019 activity using accelerometer traces. Our evaluation for unsupervised learning is detailed in \u00a74, where we take the task of identifying topics in documents as a case study.\nHere we consider a scenario where smartphone users want to train a motion-based activity classifier without revealing their data to others. To test the algorithms, we use the WISDM Human Activity Recognition dataset [36], which is a collection of accelerometer data on an Android phone by 35 subjects performing 6 activities (walking, jogging, walking upstairs, walking downstairs, sitting and standing). These subjects carried an Android phone in their front pants leg pocket while were asked to perform each one of these activities for specific periods of time. Various time domain variables were extracted from the signal, and we consider the statistical measures obtained for every 10 seconds of accelerometer samples in [36] as the d = 43 dimensional features in our models. Our final sample contains 5, 418 accelerometer traces from 35 users, with in average 150.50 traces per user and standard deviation of 44.73.\nFor the purpose of validation, we compare the performance of the following models:\n\u2022 Shared: classifier trained using data from N \u2212 1 subjects and tested using data from the remaining subject;\n\u2022 Local: classifier trained using only data from 1 subject and tested using also data from the same subject; and\n\u2022 Personal: classifier trained using data from N \u2212 1 subjects (shared model), retrained using data from 1 subject (local model) and tested using also data from the latter subject (personal model).\nThus, we simulated a case where a shared model MS is trained with data from 34 subjects, while the personal model ML is trained with different samples of data from the remaining participant (u). We then compare the accuracy of the personal model with the shared and local models. To this aim, we simulated two other cases: the shared model trained using data from 34 subjects, and the local model trained using only local data from u. Being Su the samples of u and Sr the samples of all subjects but u, the samples considering for training, validation and test in each model are the following:\n\u2022 Shared:\n\u2013 Training set: 80% of Sr \u2013 Validation set: 20% of Sr \u2013 Test set: 20% of Su\n\u2022 Local:\n\u2013 Training set: {1..60%} of Su \u2013 Validation set: {1..20%} of Su \u2013 Test set: 20% of Su\n\u2022 Personal: We started from the shared model and, in order to fine-tune it to obtain the (personal model), we considered the same setup as in the local model."}, {"heading": "3.1 Multi-Layer Perceptron", "text": "We used a Multi-Layer Perceptron as the supervised learning algorithm for recognising activity using accelerometer traces. A Multi-Layer Perceptron or MLP is a type of feedforward Artificial Neural Network that consists of two layers, input and output, and one or more hidden layers between these two layers. The input layer is passive and merely receives the data, while both hidden and output layers actively process the data. The output layer also produces the results. Figure 2 shows a graphical representation of a MLP with a single hidden layer. Each node in a layer is connected to all the nodes in the previous layer. Training this structure is equivalent to finding proper weights and bias for all the connections between consecutive layers such that a desired output is generated for a corresponding input.\nThe standard back-propagation learning algorithm is used for training the MLP neural architecture. For each accelerometer trace in the training set, weights and bias are modified by computing the discrepancy between the desired and actual outputs and feeding back this error to the inputs, updating the weights and bias in proportion to their responsibility for the output error. The main steps of the back-propagation algorithm are the following:\n1. Initialise the parameters. All wij\u2019s (wjk\u2019s) are initialised to small random values such as the variance of neurons in the network should be 2.0/N (2.0/M ), being wij (wjk) the value of the connection weight between unit j (k) and unit i (j) in the previous layer, and N (M ) the number of input (hidden) units [30]. The bias, bj (bk), are initialised to zero.\n2. Compute the class scores. Let the individual components of an input accelerometer trace be denoted by ai, with i = 1, 2, ..., N . The output of the neurons at the hidden layer are obtained as: Hj = \u03d5( \u2211N i=1 aiwij +\nbj) with j = 1, 2, ...,M , where \u03d5(\u00b7) is the activation function and wij is the weight associated to the connection between the i-th input node and the j-th hidden node, and bj the bias. The current recommendation is to use ReLU (Rectified Linear Unit) units [42, 30] as the activation function (\u03d5(x) = max(0, x)) though other options are possible. The outputs of the MLP are obtained using Ok = \u03d5( \u2211M j=1Hjwjk + bk), with k = 1, 2, ..., C. Here, wjk is the weight associated to the connection between the j-th hidden node and the k-th output node, and bk the bias.\n3. Compute the analytic gradient with back-propagation. This is done by an iterative gradient descent procedure in the weight space which minimises the total loss between the desired and actual outputs of all nodes in the system. The delta terms for every node in the output layer are calculated using \u03b4ok = (Ok \u2212 dk)\u03d5\u2032(\u00b7), with k = 1, 2, ..., C. Here, \u03d5\u2032(\u00b7) is the first derivative of the activation function. Delta terms for the hidden\ninput layer\nhidden layer\noutput layer\nnodes are obtained by \u03b4hj = \u2211C k=1(wjk\u03b4 o k)\u03d5 \u2032(\u00b7), with j = 1, 2, ...,M .\n4. Performing a parameter update. That is, adjust the weights and bias according to the delta terms and \u03b7, the learning rate parameter. For the weights, this is done using wij = wij \u2212 \u03b7\u03b4hj ai and wjk = wjk \u2212 \u03b7\u03b4okHj . The bias are updated according to bj = bj \u2212 \u03b7\u03b4hj and bk = bk \u2212 \u03b7\u03b4ok.\nThis process is repeated until the network stabilises (converges).\nIn order to control the capacity of Neural Networks to prevent overfitting, `2-regularisation is perhaps the most common form of regularisation. It can be implemented by, for every weight w in the network, adding the term 12\u03bbw\n2 to the objective, where \u03bb is the regularisation strength. Earlystopping is another mechanism to combat overfitting by monitoring the model\u2019s performance on a validation set. A validation set is a set of examples neither used for training nor for testing. During training, if the model\u2019s performance ceases to improve sufficiently on the validation set, or even degrades with further optimisation, then the training gives up on much further optimisation.\nAn important aspect of the MLP is the initialisation of the weights and bias, and here is also the main contribution of our proposal. For the shared model, MS , we initialise the weights to random small values and the bias to zero in both layers, as suggested by previous literature [30]. However, for training the personal model, MP , we start from the weights and bias of the shared model, MS ."}, {"heading": "3.2 Experimental setup", "text": "We set up a Multilayer Perceptron with 2 layers for activity recognition, including 1 hidden layer with 128 nodes and\n1 logistic regression layer, resulting in 6, 406 parameters to be determined during training. We construct the input layer using the statistical measures of users\u2019 accelerometer traces. Because of the sensitivity learning stages to feature scaling [31] we normalise all statistical measures to have zero mean and unit standard deviation. In the output layer each unit corresponds to an activity inference class, such that unit states can be interpreted as posterior probabilities.\nAll training procedures were implemented in python using the Theano deep learning library [8]. The training and testing were performed with 5-fold cross validation, using early stopping as well as `2-regularisation to prevent overfitting. Each neuron\u2019s weight in the shared and local models was initialised randomly from N (0, 1)/ \u221a 2.0/n, where n is the number of its inputs, and biases were all initialised to zero. Parameters in the personal model were initialised to the values obtained in the shared model. Finally, we used grid search to determine the values of the hyper-parameters, setting the learning rate to 0.05 for the shared model and to 0.001 for the local and personal models, and the `2-regularisation strength to 1e\u22125 for all the models. The training epochs were set to 1000 in all models, while the batch size was set equal to the size of the training sets in the shared model, and to 1 (online learning) in the local and personal ones. The reasons behind this are the small size of the dataset, and the availability of the training samples in a real scenario (samples for the shared model can be assumed to be all available for training, whereas samples in the local and personal models become available for training as time goes by).\nWe repeated the experiment for each participant, using 5- fold cross-validation and different number of samples to train the local and personal models. In each simulation of every user, we incremented in 1 the number of samples used for training, and also in 1 the ones for validation until reaching 60% of samples for training and 20% for validation, respectively."}, {"heading": "3.3 Results", "text": "Figure 3 reports the accuracy achieved with each model when considering different number of local samples per user. Results show that the effect of training or retraining a model with few samples from the individual under test produces worse predictions than using samples from other individuals (shared model). That is, while the model is adapting to the new scenario, the performance of the prediction slightly drops. However, when more samples (20 on average or more) are used to retrain this shared model, the accuracy of the prediction exceeds the accuracy obtained with the shared model itself. Specifically, the accuracy increases with increments in the number of samples used for retraining the model. That is, the more local samples considered to retrain the model, the more personalised it becomes for the considered individual. However, although the improvement on the accuracy with the increment of the number of samples is also shared with the local model, more samples per individual are required\nfor training a model from scratch (local model) in order to obtain the same accuracy than when starting from a shared model (personal model). We also observe that, after on average 163 samples, the local model performs better than the personal model. However, this is not significant, since there is one unique user in the dataset with that number of samples or higher available for training. In summary, (i) retraining a shared model locally using 20 or more samples from the user increases the accuracy with respect to that obtained with the shared model, and (ii) to obtain the same accuracy when training a model from scratch using only local samples, more than 150 training samples are required on average."}, {"heading": "4. TOPIC MODELLING OF PERSONAL TEXT CORPUS", "text": "Text corpus, such as web pages, documents, e-books and emails, is one of the most widely distributed media on the Internet and also dominates many users\u2019 devices. Text classification therefore has a wide application to facilitate people\u2019s daily life by grouping or filtering the items in a text corpus based on certain topics. Because personal text corpus often contains a significant amount of private information, uploading such corpus to a public cloud will certainly breach user privacy.\nConsider now a scenario where users wish to classify the textual documents on their computers without revealing their content to others. Being more precise, we consider researchers working on a confidential project within a company that do not wish to disclose the publications they are reading, but they do wish to have the documents classified according to their content. To simulate such a scenario, we use two text datasets in our evaluation: the NIPS [4] and the Wikipedia [9] datasets. The NIPS dataset is a collection of papers published in NIPS conference over the past two decades. It contains about 1.5k papers and 1.9 million words. For Wikipedia, we download its latest English dump in January 2017 which\ncontains about 5 million articles and 2.9 billion words. For the purpose of validation, we compare the performance of the following models:\n\u2022 Local: topic extraction using only data from the NIPS dataset (local data);\n\u2022 Personal: topic extraction using only data from the Wikipedia dataset (shared model), and retraining using data from the NIPS dataset (local model).\nThus, we simulated a case where a shared model MS is trained with data from the Wikipedia dataset, while the personal model ML is trained with the NIPS dataset. We then compare the accuracy of the personal model with the local model. To this aim, we also simulated the case where the local model trained using only local data from the NIPS dataset."}, {"heading": "4.1 Latent Dirichlet Allocation", "text": "A topic model is an effective tool for text mining. It aims to construct a statistical model to represent the abstract \u201ctopics\u201d contained in a collection of documents. By doing so, similar documents can be grouped together for future queries. As each document is composed of a sequence of words, it is often represented as a very high-dimensional and sparse vector using a bag-of-words model. Each dimension represents one unique vocabulary in the dictionary extracted from the corpus, and the magnitude of each dimension is often calculated as the term frequency in the corresponding document. Therefore, the dimensionality of these vectors depends on the size of dictionary, and it is common the dimensionality is over dozens of thousands.\nLDA is a generative model which explicitly models topics as latent variables based on the co-occurrences of terms and documents in a text corpus. LDA is similar to pLSA [32] but replaces the maximum likelihood estimator with Bayesian estimator, hence it is sometimes referred to as the Bayesian version of pLSA. LDA assumes that the topic distribution has a Dirichlet prior.\nAs each document can be represented as a vector, finding a given document\u2019s similar documents is equivalent to search for its k-nearest neighbours in the high-dimensional space. Many prior works [49, 27, 29, 34] focus on building compact and efficient data structure and search algorithm to speed up the queries to the models.\nAs mentioned, LDA is an unsupervised learning and its goal in training is to maximise its likelihood function. Its model contains two important parameters:\n\u2022 Document-Topic distribution: it indicates the probability distribution of each document over a set of topics.\n\u2022 Topic-Word distribution: it indicates the probability distribution of each topic over a set of words extracted from the text corpus.\nEssentially, the two parameters are represented as two matrices in the algorithm containing the information of documenttopic and topic-word assignment respectively. A typical training task can be divided into two phases: First, the two parameters will be initialised by assuming both have a Dirichlet prior; second, the model will be updated by applying Collapsed Gibbs Sampling to all the documents. The second phase will be applied iteratively until we reach the predefined number of iterations or the model converges. To evaluate the effectiveness of an LDA model, we can measure the log likelihood of the constructed model over a test data set. The log likelihood indicates how well the model can interpret the given data set, and the higher value it is, the better it is."}, {"heading": "4.2 Experiment setup", "text": "In our topic modelling scenario, a user u owns a set of text documents,Du, and wants to identify their topics without revealing their content. There is another set of publicly available documents, Dr, that he can benefit from. The set of u\u2019s documents, Du, is composed by the documents in the NIPS dataset, whereas Dr is formed by different random samples of documents from the Wikipedia dataset.\nWe start by building a shared LDA model called MS out of the public available documents Dr as we did in the previous activity recognition case. However, one thing worth noting here is that MS only includes the Topic-Word distribution (as well as a dictionary to tokenise the documents) which is a very sparse matrix. The Document-Topic parameter depends on the specific text corpus and is not useful for others to initialise a personal model, hence it is not necessary to include into MS .\nWe then build the new LDA model, personal model or MP , using the new document samples that corresponds to users\u2019 personal data, i.e., Du, and compare it with the local model trained solely using user\u2019s documents. Specifically, the method for building the local model is just repeating the typical process of building the model from scratch. Alternative method, i.e. the method to build the personal model, is to request MS and use it to initialise the local Document-Topic distribution parameter instead of assuming a Dirichlet prior. In the following, we will compare and present the accuracy and efficiency of the local and personal models.\nWe use the topic modelling module in Owl [5] library to perform the aforementioned experiments. Each experiment is repeated 10 times to guarantee its consistency."}, {"heading": "4.3 Improved accuracy and efficiency", "text": "Figure 4 presents the evolution of log likelihood in each iteration while building the personal (MP ) and local models. NIPS dataset is used in this first experiment, and the shared model, MS , is trained using 50% of the data. A user\u2019s local data are generated by randomly selecting 300 documents from the rest of the dataset.\nThe two lines in the figure correspond to the two ways of building the user\u2019s topic model: the red line is for using\nMS to initialise model (personal model) whereas the blue line is for building the model from scratch by solely using the user\u2019s local documents (local model). As we see, the personal model is able to achieve higher likelihood in each iteration than the local one. Meanwhile, it also indicates that the model is able to converge much faster given a target accuracy.\nThe NIPS dataset is larger than the activity recognition dataset, which allows us to raise and answer the next question: how much public data do we need to use for building the shared model MS? This question becomes very relevant especially when the amount of public or shared data is limited. In the next experiment, while keeping the rest of the experiment settings the same, we build multiple shared models MS by increasing the amount of documents for training step by step, from 100 to 1000. With these newMS , we repeat the same experiment presented in Figure 4 to investigate how the amount of public data used to train MS impacts the personal training (personal model). Figure 5 presents our results. The blue line with \u201c+\u201d marker at the bottom is the same as that in Figure 4, representing the training without using MS (local model). The rest of the lines represent the log likelihood of the MS using different percentage of the 1000 documents as the public sample. All MS models are trained using a fix number (i.e., 50) of iterations.\nResults in Figure 5 show that including more data in MS will certainly improve the efficiency and accuracy when localising or personalising the shared model which is reflected as gradually improved likelihood in each line. Note that including more data in training MS will not increase the parameter size therefore it does not introduce extra overhead in distributing the shared model. However, these results also deliver another important message, namely such benefits drop quickly as we add more and more data. The most significant improvement appears in the very beginning when we only include a small amount of data (i.e., 10%). To\nsome extent, it justifies the our proposal by showing a small amount of public data is able to boost the local training."}, {"heading": "4.4 Topic-based local dataset", "text": "Wikipedia dataset contains a rich set of meta information such as manually assigned topic categories, which can help us in simulating users who have different interests in various topics. Users of different interest may possess a rather different local dataset from each other. The question is whether our method is still effective when the topics in the local data are only a subset of those included in the documents used for training the shared model.\nTo answer the question, we design other experiment wherein when we generate the local dataset, we only randomly select the articles from a pre-determined topic, e.g., computer networking, architecture design, British history. We generate multiple local datasets using different topics. The x-axis in Figure 6 shows the topic indices in the Wikipedia dataset, and we present the results of 10 of those selected topics. The way of selecting the shared data for training MS remains the same. In total, we randomly sample 1000 articles from the whole Wikipedia as public or shared data, and 500 articles of a given topic for each local dataset.\nWe first measure the absolute amount of improvement in log likelihood between the first and the tenth iteration while training a local model, based on which we then calculate how much we can improve by starting with a shared model (personal model). The results in upper part of Figure 6 show that the improvement varies between 3.22% to 4.53% with an average equals to 3.85%. We also measure the improvement in efficiency by investigating how much we can reduce the number of iterations to reach a targeted log likelihood with the help of a shared model. In this experiment, we set the targeted log likelihood to\u221210.203 and the lower part of Figure 6 presents our results. Similar to the upper one, using a shared model can significantly boosts the training efficiency,\nwith the minimum over 30% reduction in iterations over all cases. On average, we are able to save over 37.8% iterations. Another thing worth mentioning here is that since the shared model is already sparse, it further reduces the time spent in each iteration than training purely on local data (local model) which needs to start with a highly dense local model. This indicates the saving is even more significant in terms of absolute amount of training time reduced."}, {"heading": "5. PRACTICAL CONSIDERATIONS", "text": "In the following, we discuss the privacy guarantees of our methodology and its robustness against adversarial attacks (\u00a75.1), as well as empirically verify such robustness against the special case of poisoning attacks (\u00a75.2). We then demonstrate the feasibility of its deployment by presenting a performance evaluation on a representative resource-constrained device (\u00a75.3)."}, {"heading": "5.1 Adversarial attacks", "text": "Our system can suffer the attacks and consequences of malicious users. There are several potential attacks against any learning system [14, 33]. Here we focus on how privacy and causative attacks might affect our system. On a privacy attack the adversary obtains information from the learner, compromising the secrecy or privacy of the system\u2019s users. The aim of a causative attack is on altering the parameters of the target model by manipulating the training dataset. An example of this type of attacks are poisoning attacks, where an attacker may poison the training data by injecting care-\nfully designed samples to eventually compromise the whole learning process. The target model then updates itself with the poisoned data and gradually compromises. Below we describe the potential effects of these attacks in our system.\nOur solution guarantees the confidentiality of users\u2019 data (potential users) given that their devices are not compromised, since their personal data never leave their devices. Since both the data and the personal model resides on the user\u2019s device, attacks such as model inversion [26] \u2013where an attacker, given the model and some auxiliary information about the user, can determine some user\u2019s raw data; and membership query [47], where, given a data record and black-box access to a model, an adversary could determine if the record was in the model\u00e2A\u0306Z\u0301s training dataset, cannot affect our users. However, we cannot assure the confidentiality of the data, neither robustness against these attacks, for those users that have freely aggreed to share their data in the same way as the big corporations are not doing so with their customers data. For many applications we envisage and describe in the introduction, such as those based on object recognition or those that work with textual data, there is already a large amount of data freely available on the Internet with which to build the shared model, and whose confidentiality does not need to be guraranteed. On the other hand, for applications such as face or speaker recognition, techniques based on differentially private training [46, 39, 28, 44] could be applied in order to, a priori, guarantee the confidentiality of the volunteers\u2019 data. On the contrary, the training of the personal model for the final users happens locally on their devices so that neither their data nor their personal model leave their devices, and its confidentiality is guaranteed by the security offered by their device, security that is out of the scope of the methodology proposed here."}, {"heading": "5.2 Poisoning attacks", "text": "We envisage two different points or steps in our system that adversaries might wish to attack: when building the shared model in a remote server in the public cloud using public data available or shared by a group of volunteers, and when personalising the model by local retraining in the user\u2019s device (personalisation). In the case of a poisoning attack to our proposed methodology, the shared model can be corrupted by malicious volunteers poisoning the data with fake samples. However, during the local retraining, if the adversary wishes to corrupt the personal model, he needs to gain access to the local device of the user to poison the data and fool the model. In the following, we explore the effects of adding corrupted samples to the data used to train the shared model in the supervised learning task. Poisoning the data to train the personal model needs the attacker to gain access to the local device of the user, and so we do not discuss these further here.\nSome schemes have been proposed to conduct poisoning attacks against SVMs [16, 52], but we have barely seen any work about poisoning attacks against neural networks. Our\ngoal is not on how to design the best poissoning attack to achive a given output or to avoid being detected, but on the effects of poisoning data into our model. Therefore we consider a dumb adversary that randomly alters labels into our training set without any other goal than misclassifying samples. Specifically, we simulate a scenario where part of the data used for training the shared model is corrupted. That is, a scenario where one or several volunteers intentionally alter the labels of their samples in the training set, and explore the effect that different amounts of data corrupted in the training set of the shared model cause in the personal model of the user.\nTo this aim, we corrupted different samples of the training set (10%, 20%, 30%, 50%, 70% and 90%). In order to generate each corrupted sample, we consider the original features of the sample to be corrupted, but assigning it a random activity. This random activity label was selected by a random generator with equal probability for each activity (walking, standing, etc.). Figure 7 represents the accuracy, in average, of the personal model for different percentages of corrupted samples in the training set of the shared model. We observe that the more corrupted samples used to build the shared model, the less improvement we get when starting to train the personal model. More interestingly, when less than 50% of the samples are corrupted, the accuracy obtained with the personal model is similar to the one when no samples are poisoned, specially when few samples are used to train the local model. Moreover, when the 90% of the samples are poisoned, the accuracy of the personal model is not worse than the local model.\nNow we consider a \u201csmarter\u201d adversary that has access to other volunteers\u2019 data and therefore can obtain the distribution of labels in the dataset. In order to minimise the chances of being discovered, this adversary corrupts its samples by adding random labels with the probability of each label being the same as the one in the original data. Figure 8 shows the results when the labels corrupted follow the same distribution than the original sample (\u201csmarter\u201d adversary). In this case, we observe similar results as when poisoning the samples completely random. One difference is that when few samples of the concerned user are used to train the personal model, the system behaves worse than the local model, specially when the percentage of corrupted samples is large. But, when using more samples, the system behaves better than the local one and similar to the system under the effects of the \u201cdumb\u201d adversary. In conclusion, our system is quite robust against poisoning attacks against the shared model."}, {"heading": "5.3 Deployment Feasibility", "text": "The success of our privacy-preserving methodology for learning personal models is conditional on the ability to run model refinement in near real-time on resource-constrained personal devices which lack the capabilities of cloud-based servers. These environments are of increasing interest for deployment of such techniques as availability of computa-\ntion resources outside datacenters continues to increase with creation of \u201cfog computing\u201d environments using cheep and energy-efficient platforms such as those based on ARM processors [18].\nTo verify the deployment feasibility of our approach on resource-constrained personal devices we evaluate, for both tasks, the second phase of our approach, testing the refinement and inference aspects on a Raspberry Pi 3 Model B [6] as representative of these sorts of environments.\nFigure 9 shows the time taken for training a personal model (refining the initial shared model), and for the alternative approach of learning a local model using only a single user\u2019s data available locally, for the setup in \u00a73. In both cases training takes seconds to complete, with time increasing linearly with the number of samples considered due to the online nature of the training process (only one sample is considered\nat every update of the model). The time for making the inference is insignificant compared with the time for training, being on the order of milliseconds.\nFigure 10 reproduces results from \u00a74 on the same resourceconstrained device using the NIPS dataset. Figures 10(a-b) show the time spent per iteration while building the model, respectively varying the number of training documents while keeping the vocabulary size fixed, and the vocabulary size while keeping the number of training documents fixed. Each test is repeated for 20 iterations. In both cases, we observe the expected linear growth in model training time.\nFigures 10(c-d) show the time it takes to reach a certain level of likelihood (we use -10.230 as the threshold, as in the previous experiments) given different shared models. All models are trained with 200 documents. The results align with what we have found out in Figure 5: including more data decreases both the time and number of iterations required to reach the desired precision threshold. This decrease is most obvious when the model moves from not using any data to including a small amount (10%). As further data are included, the benefits quickly diminish."}, {"heading": "6. RELATED WORK", "text": "Data-driven solutions are now pervasive in areas such as advertising, smart cities and eHealth [22, 51]. Almost everything we do in our daily lives is tracked by some means or another. Although careful analysis of these data can be highly beneficial for us as individuals and for society in general, this approach usually entails invasion of privacy, a high price that progressively more people are not willing to pay [19].\nSeveral privacy-preserving analytical solutions have been proposed to guarantee the confidentiality of personal data while extracting useful information [13, 12, 24, 15]. Prominent among them are those that build on Dwork\u2019s differential privacyframework [45, 48, 21, 26, 11], which formalises the idea that a query over a sensitive database should not reveal\nwhether any one person is included in the dataset [23]. Most of these techniques usually are based on adding noise during the training, which leads to a challenging trade-off between accuracy and privacy.\nDistributed machine learning is also an active topic of research [37], and a straightforward solution for privacy-preserving analytics. Different entities usually own different datasets which, if aggregated, would provide useful knowledge. However, the sensitivity of such data often prevents these entities from sharing their datasets, restricting access to only a small set of selected people as in the case of patients\u2019 medical records [15]. Several solutions have been proposed for distributed privacy-preserving learning, where information is learnt from data owned by different entities without disclosing either the data or the entities in the data. Shokri and Shmatikov [46] and McMahan et al. [39] propose solutions where multiple parties jointly learn a neural-network model for a given objective by sharing their learning parameters, but without sharing their input datasets. A different approach is proposed by Hamm et al. [28] and Papernot et al. [44], where privacy-preserving models are learned locally from disjoint datasets, and then combined on a privacy-preserving fashion.\nContrary to previous approaches, we do not aim to learn a global model from sensitive data from multiple parties, but to learn a personalised model for each individual party that builds on a model learnt from a relatively small set of others parties, without requiring access to their raw data. Instead, we build personal learning models, similar to the personal recommender system by Balasubramanian et al. [35] but generalising the solution to any learning algorithm. Our solution takes advantage of transfer learning [43] to achieve better performance than algorithms trained using only local data, particularly in those (relatively common )situations where local data is a scarce resource."}, {"heading": "7. CONCLUSION", "text": "Our privacy-preserving methodology for learning analytics relies on the ability of current personal devices such as smartphones, tablets and small form-factor computers such as the Raspberry Pi to carry out traditionally resource-demanding\ntasks. By splitting model training between the cloud and the personal device, we avoid sending personal data to untrustworthy remote entities in the cloud while maintaining and improving accuracy. Users thus keep all rights over their personal data while retaining the benefits of learning-based services.\nWe demonstrated our methodology for two learning tasks, one supervised and one unsupervised: activity recognition from accelerometer data, and identification of topics in text documents. Our experiments showed improvements both in accuracy and efficiency using this methodology with respect to both traditional cloud-based solutions and solutions based on training the model using only the data available from the user to whom we are providing the service. We also demonstrated the feasibility of our approach by examining performance of implementation of the local step of our methodology on a Raspberry Pi 3 Model B.\nOur results prove that this approach is promising, and we believe that it is widely applicable and able to positively improve the privacy-preservation of applications where data is distributed between entities whose confidentiality needs to be secured. In a world where the Internet of Things is connecting progressively more devices everyday \u2013some of which already reside in our home, and the rising concerns about the possibility of private data leaving or getting stolen from our smart homes, our privacy-preserving methodology comes to the aid of designers and developers of smart home applications to fulfill the need of privacy guarantees that their users demand. However, there are certainly areas appropriate for future work. For example, our current solution does not leverage any cooperation between user nodes, and we plan to explore a cooperative learning approach to allow similar users to jointly train machine learning models in cases where they do not individually have sufficient labelled data locally to retrain a shared model, likely the case during the first moments they use the learning service. A potential solution to boost the accuracy may deal with similar users retraining the shared model collaboratively, in a privacy-preserving fashion.\n8. ACKNOWLEDGMENTS\nThis work was supported by the EPSRC through Grant EP/N028260/1, \u201cDatabox: Privacy-Aware Infrastructure for Managing Personal Data\"."}, {"heading": "9. REFERENCES", "text": "[1] Amazon echo. https://www.amazon.com/ Amazon-Echo-Bluetooth-Speaker-with-WiFi-Alexa/ dp/B00X4WHP5E/. Accessed May 25, 2017.\n[2] Apple homekit. https://www.apple.com/ios/home/. Accessed May 25, 2017.\n[3] Google home. https://madeby.google.com/home/. Accessed May 25, 2017.\n[4] Nips - bag of words data set. https://archive.ics.uci.edu/ml/ machine-learning-databases/ bag-of-words/. Accessed January 20, 2017.\n[5] Owl - an ocaml numerical library. https://github.com/ryanrhymes/owl. Accessed January 20, 2017.\n[6] Raspberry pi. https://www.raspberrypi.org/ products/raspberry-pi-3-model-b/. Accessed February 15, 2017.\n[7] scikit-learn. http://scikit-learn.org/. Accessed January 20, 2017.\n[8] Theano deep learning. http: //deeplearning.net/software/theano. Accessed January 20, 2017.\n[9] Wikipedia dataset. https: //dumps.wikimedia.org/enwiki/latest/. Accessed January 20, 2017.\n[10] Zeromq - distributed messaging. http://zeromq.org. Accessed January 20, 2017.\n[11] M. Abadi, A. Chu, I. Goodfellow, H. B. McMahan, I. Mironov, K. Talwar, and L. Zhang. Deep learning with differential privacy. In Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security, pages 308\u2013318. ACM, 2016.\n[12] C. C. Aggarwal and S. Y. Philip. A general survey of privacy-preserving data mining models and algorithms. In Privacy-preserving data mining, pages 11\u201352. Springer, 2008.\n[13] R. Agrawal and R. Srikant. Privacy-preserving data mining. In Proceedings of the 2000 ACM SIGMOD International Conference on Management of Data, SIGMOD \u201900, pages 439\u2013450, New York, NY, USA, 2000. ACM.\n[14] M. Barreno, B. Nelson, A. D. Joseph, and J. Tygar. The security of machine learning. Machine Learning, 81(2):121\u2013148, 2010.\n[15] G. Bellala and B. Huberman. Securing private data sharing in multi-party analytics. First Monday, 21(9), 2016.\n[16] B. Biggio, B. Nelson, and P. Laskov. Poisoning attacks against support vector machines. arXiv preprint arXiv:1206.6389, 2012.\n[17] D. M. Blei, A. Y. Ng, and M. I. Jordan. Latent dirichlet allocation. J. Mach. Learn. Res., 3:993\u20131022, Mar. 2003.\n[18] F. Bonomi, R. Milito, J. Zhu, and S. Addepalli. Fog computing and its role in the internet of things. In Proceedings of the First Edition of the MCC Workshop on Mobile Cloud Computing, MCC \u201912, pages 13\u201316, New York, NY, USA, 2012. ACM.\n[19] L. Brandimarte, A. Acquisti, and G. Loewenstein. Misplaced confidences. Social Psychological and Personality Science, 4(3):340\u2013347, 2013.\n[20] A. Chaudhry, J. Crowcroft, H. Howard, A. Madhavapeddy, R. Mortier, H. Haddadi, and D. McAuley. Personal data: Thinking inside the box. In Proceedings of The Fifth Decennial Aarhus Conference on Critical Alternatives, AA \u201915, pages 29\u201332. Aarhus University Press, 2015.\n[21] K. Chaudhuri, C. Monteleoni, and A. D. Sarwate. Differentially private empirical risk minimization. Journal of Machine Learning Research, 12(Mar):1069\u20131109, 2011.\n[22] C. P. Chen and C.-Y. Zhang. Data-intensive applications, challenges, techniques and technologies: A survey on big data. Information Sciences, 275:314 \u2013 347, 2014.\n[23] C. Dwork. Differential privacy: A survey of results. In International Conference on Theory and Applications of Models of Computation, pages 1\u201319. Springer, 2008.\n[24] Z. Erkin, J. R. Troncoso-pastoriza, R. L. Lagendijk, and F. Perez-Gonzalez. Privacy-preserving data aggregation in smart metering systems: an overview. IEEE Signal Processing Magazine, 30(2):75\u201386, March 2013.\n[25] M. Falahrastegar, H. Haddadi, S. Uhlig, and R. Mortier. Tracking personal identifiers across the web. In Passive and Active Measurement conference (PAM 2016), 2016.\n[26] M. Fredrikson, E. Lantz, S. Jha, S. Lin, D. Page, and T. Ristenpart. Privacy in pharmacogenetics: An end-to-end case study of personalized warfarin dosing. In USENIX Security, pages 17\u201332, 2014.\n[27] K. Hajebi, Y. Abbasi-Yadkori, H. Shahbazi, and H. Zhang. Fast approximate nearest-neighbor search with k-nearest neighbor graph. In Proceedings of the Twenty-Second International Joint Conference on Artificial Intelligence - Volume Volume Two, IJCAI\u201911, pages 1312\u20131317. AAAI Press, 2011.\n[28] J. Hamm, P. Cao, and M. Belkin. Learning privately from multiparty data. In Proceedings of the 33rd International Conference on Machine Learning, pages 555\u00e2A\u0306S\u0327\u2013563, 2016.\n[29] J. He, W. Liu, and S.-F. Chang. Scalable similarity search with optimized kernel hashing. In Proceedings of the 16th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD \u201910, pages 1129\u20131138, New York, NY, USA, 2010. ACM.\n[30] K. He, X. Zhang, S. Ren, and J. Sun. Delving deep into rectifiers: Surpassing human-level performance on imagenet classification. In Proceedings of the IEEE international conference on computer vision, pages 1026\u20131034, 2015.\n[31] G. Hinton. A practical guide to training restricted boltzmann machines. Momentum, 9(1):926, 2010.\n[32] T. Hofmann. Probabilistic latent semantic indexing. In Proceedings of the 22Nd Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR \u201999, pages 50\u201357, New York, NY, USA, 1999. ACM.\n[33] L. Huang, A. D. Joseph, B. Nelson, B. I. Rubinstein, and J. Tygar. Adversarial machine learning. In Proceedings of the 4th ACM workshop on Security and artificial intelligence, pages 43\u201358. ACM, 2011.\n[34] V. Hyv\u00c3u\u030bnen, T. Pitk\u00c3d\u2019nen, S. Tasoulis, E. J\u00c3d\u2019\u00c3d\u2019saari, R. Tuomainen, L. Wang, J. Corander, and T. Roos. Fast nearest neighbor search through sparse random projections and voting. In 2016 IEEE International Conference on Big Data (Big Data), pages 881\u2013888, Dec 2016.\n[35] S. Jain, V. Tiwari, A. Balasubramanian, N. Balasubramanian, and S. Chakraborty. Pria: A private intelligent assistant. In Proceedings of the 18th International Workshop on Mobile Computing Systems and Applications, HotMobile \u201917, pages 91\u201396, New York, NY, USA, 2017. ACM.\n[36] J. R. Kwapisz, G. M. Weiss, and S. A. Moore. Activity recognition using cell phone accelerometers. ACM SigKDD Explorations Newsletter, 12(2):74\u201382, 2011.\n[37] M. Li, D. G. Andersen, A. J. Smola, and K. Yu. Communication efficient distributed machine learning with the parameter server. In Advances in Neural Information Processing Systems, pages 19\u201327, 2014.\n[38] Y. Low, D. Bickson, J. Gonzalez, C. Guestrin, A. Kyrola, and J. M. Hellerstein. Distributed graphlab: A framework for machine learning and data mining in the cloud. Proc. VLDB Endow., 5(8):716\u2013727, Apr. 2012.\n[39] H. B. McMahan, E. Moore, D. Ramage, S. Hampson, et al. Communication-efficient learning of deep networks from decentralized data. arXiv preprint arXiv:1602.05629, 2016.\n[40] X. Meng, J. Bradley, B. Yavuz, E. Sparks,\nS. Venkataraman, D. Liu, J. Freeman, D. Tsai, M. Amde, S. Owen, et al. Mllib: Machine learning in apache spark. Journal of Machine Learning Research, 17(34):1\u20137, 2016.\n[41] R. Mortier, J. Zhao, J. Crowcroft, L. Wang, Q. Li, H. Haddadi, Y. Amar, A. Crabtree, J. Colley, T. Lodge, T. Brown, D. McAuley, and C. Greenhalgh. Personal data management wiht the Databox: What\u2019s inside the box? In Proc. Cloud Assisted Networking workshop at ACM CoNEXT, Dec. 12 2016.\n[42] V. Nair and G. E. Hinton. Rectified linear units improve restricted boltzmann machines. In Proceedings of the 27th International Conference on Machine Learning (ICML-10), pages 807\u2013814, 2010.\n[43] S. J. Pan and Q. Yang. A survey on transfer learning. IEEE Transactions on knowledge and data engineering, 22(10):1345\u20131359, 2010.\n[44] N. Papernot, M. Abadi, \u00da. Erlingsson, I. Goodfellow, and K. Talwar. Semi-supervised knowledge transfer for deep learning from private training data. In Proceedings of the 5th International Conference on Learning Representations, 2017.\n[45] A. D. Sarwate and K. Chaudhuri. Signal processing and machine learning with differential privacy: Algorithms and challenges for continuous data. IEEE signal processing magazine, 30(5):86\u201394, 2013.\n[46] R. Shokri and V. Shmatikov. Privacy-preserving deep learning. In Proceedings of the 22nd ACM SIGSAC conference on computer and communications security, pages 1310\u20131321. ACM, 2015.\n[47] R. Shokri, M. Stronati, and V. Shmatikov. Membership inference attacks against machine learning models. In Proceedings of the 38th IEEE Symposium on Security and Privacy, 2017.\n[48] S. Song, K. Chaudhuri, and A. D. Sarwate. Stochastic gradient descent with differentially private updates. In Global Conference on Signal and Information Processing (GlobalSIP), 2013 IEEE, pages 245\u2013248. IEEE, 2013.\n[49] L. Wang, S. Tasoulis, T. Roos, and J. Kangasharju. Kvasir: Scalable provision of semantically relevant web content on big data framework. IEEE Transactions on Big Data, 2(3):219\u2013233, Sept 2016.\n[50] G. M. Weiss and J. W. Lockhart. The impact of personalization on smartphone-based activity recognition. In AAAI Workshop on Activity Context Representation: Techniques and Languages, 2012.\n[51] X. Wu, X. Zhu, G. Q. Wu, and W. Ding. Data mining with big data. IEEE Transactions on Knowledge and Data Engineering, 26(1):97\u2013107, Jan 2014.\n[52] H. Xiao, H. Xiao, and C. Eckert. Adversarial label flips attack on support vector machines. In Proceedings of the 20th European Conference on Artificial Intelligence, pages 870\u2013875. IOS Press, 2012."}], "references": [{"title": "Deep learning with differential privacy", "author": ["M. Abadi", "A. Chu", "I. Goodfellow", "H.B. McMahan", "I. Mironov", "K. Talwar", "L. Zhang"], "venue": "In Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2016}, {"title": "A general survey of privacy-preserving data mining models and algorithms", "author": ["C.C. Aggarwal", "S.Y. Philip"], "venue": "In Privacy-preserving data mining,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2008}, {"title": "Privacy-preserving data mining", "author": ["R. Agrawal", "R. Srikant"], "venue": "In Proceedings of the 2000 ACM SIGMOD International Conference on Management of Data,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2000}, {"title": "The security of machine learning", "author": ["M. Barreno", "B. Nelson", "A.D. Joseph", "J. Tygar"], "venue": "Machine Learning,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2010}, {"title": "Securing private data sharing in multi-party analytics", "author": ["G. Bellala", "B. Huberman"], "venue": "First Monday,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2016}, {"title": "Poisoning attacks against support vector machines", "author": ["B. Biggio", "B. Nelson", "P. Laskov"], "venue": "arXiv preprint arXiv:1206.6389,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2012}, {"title": "Latent dirichlet allocation", "author": ["D.M. Blei", "A.Y. Ng", "M.I. Jordan"], "venue": "J. Mach. Learn. Res.,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2003}, {"title": "Fog computing and its role in the internet of things", "author": ["F. Bonomi", "R. Milito", "J. Zhu", "S. Addepalli"], "venue": "In Proceedings of the First Edition of the MCC Workshop on Mobile Cloud Computing,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2012}, {"title": "Misplaced confidences", "author": ["L. Brandimarte", "A. Acquisti", "G. Loewenstein"], "venue": "Social Psychological and Personality Science,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2013}, {"title": "Personal data: Thinking inside the box", "author": ["A. Chaudhry", "J. Crowcroft", "H. Howard", "A. Madhavapeddy", "R. Mortier", "H. Haddadi", "D. McAuley"], "venue": "In Proceedings of The Fifth Decennial Aarhus Conference on Critical Alternatives,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2015}, {"title": "Differentially private empirical risk minimization", "author": ["K. Chaudhuri", "C. Monteleoni", "A.D. Sarwate"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2011}, {"title": "Data-intensive applications, challenges, techniques and technologies: A survey on big data", "author": ["C.P. Chen", "C.-Y. Zhang"], "venue": "Information Sciences,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2014}, {"title": "Differential privacy: A survey of results", "author": ["C. Dwork"], "venue": "In International Conference on Theory and Applications of Models of Computation,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2008}, {"title": "Privacy-preserving data aggregation in smart metering systems: an overview", "author": ["Z. Erkin", "J.R. Troncoso-pastoriza", "R.L. Lagendijk", "F. Perez-Gonzalez"], "venue": "IEEE Signal Processing Magazine,", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2013}, {"title": "Tracking personal identifiers across the web", "author": ["M. Falahrastegar", "H. Haddadi", "S. Uhlig", "R. Mortier"], "venue": "In Passive and Active Measurement conference (PAM", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2016}, {"title": "Privacy in pharmacogenetics: An end-to-end case study of personalized warfarin dosing", "author": ["M. Fredrikson", "E. Lantz", "S. Jha", "S. Lin", "D. Page", "T. Ristenpart"], "venue": "In USENIX Security,", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2014}, {"title": "Fast approximate nearest-neighbor search with k-nearest neighbor graph", "author": ["K. Hajebi", "Y. Abbasi-Yadkori", "H. Shahbazi", "H. Zhang"], "venue": "In Proceedings of the Twenty-Second International Joint Conference on Artificial Intelligence - Volume Volume Two,", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2011}, {"title": "Learning privately from multiparty data", "author": ["J. Hamm", "P. Cao", "M. Belkin"], "venue": "In Proceedings of the 33rd International Conference on Machine Learning,", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 2016}, {"title": "Scalable similarity search with optimized kernel hashing", "author": ["J. He", "W. Liu", "S.-F. Chang"], "venue": "In Proceedings of the 16th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD", "citeRegEx": "29", "shortCiteRegEx": "29", "year": 2010}, {"title": "Delving deep into rectifiers: Surpassing human-level performance on imagenet classification", "author": ["K. He", "X. Zhang", "S. Ren", "J. Sun"], "venue": "In Proceedings of the IEEE international conference on computer vision,", "citeRegEx": "30", "shortCiteRegEx": "30", "year": 2015}, {"title": "A practical guide to training restricted boltzmann machines. Momentum", "author": ["G. Hinton"], "venue": null, "citeRegEx": "31", "shortCiteRegEx": "31", "year": 2010}, {"title": "Probabilistic latent semantic indexing", "author": ["T. Hofmann"], "venue": "In Proceedings of the 22Nd Annual International ACM SIGIR Conference on Research and Development in Information Retrieval,", "citeRegEx": "32", "shortCiteRegEx": "32", "year": 1999}, {"title": "Adversarial machine learning", "author": ["L. Huang", "A.D. Joseph", "B. Nelson", "B.I. Rubinstein", "J. Tygar"], "venue": "In Proceedings of the 4th ACM workshop on Security and artificial intelligence,", "citeRegEx": "33", "shortCiteRegEx": "33", "year": 2011}, {"title": "Fast nearest neighbor search through sparse random projections and voting", "author": ["V. Hyv\u00c3\u0171nen", "T. Pitk\u00c3d\u2019nen", "S. Tasoulis", "E. J\u00c3d\u2019\u00c3d\u2019saari", "R. Tuomainen", "L. Wang", "J. Corander", "T. Roos"], "venue": "IEEE International Conference on Big Data (Big Data),", "citeRegEx": "34", "shortCiteRegEx": "34", "year": 2016}, {"title": "Pria: A private intelligent assistant", "author": ["S. Jain", "V. Tiwari", "A. Balasubramanian", "N. Balasubramanian", "S. Chakraborty"], "venue": "In Proceedings of the 18th International Workshop on Mobile Computing Systems and Applications, HotMobile", "citeRegEx": "35", "shortCiteRegEx": "35", "year": 2017}, {"title": "Activity recognition using cell phone accelerometers", "author": ["J.R. Kwapisz", "G.M. Weiss", "S.A. Moore"], "venue": "ACM SigKDD Explorations Newsletter,", "citeRegEx": "36", "shortCiteRegEx": "36", "year": 2011}, {"title": "Communication efficient distributed machine learning with the parameter server", "author": ["M. Li", "D.G. Andersen", "A.J. Smola", "K. Yu"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "37", "shortCiteRegEx": "37", "year": 2014}, {"title": "Distributed graphlab: A framework for machine learning and data mining in the cloud", "author": ["Y. Low", "D. Bickson", "J. Gonzalez", "C. Guestrin", "A. Kyrola", "J.M. Hellerstein"], "venue": "Proc. VLDB Endow.,", "citeRegEx": "38", "shortCiteRegEx": "38", "year": 2012}, {"title": "Communication-efficient learning of deep networks from decentralized data", "author": ["H.B. McMahan", "E. Moore", "D. Ramage", "S. Hampson"], "venue": "arXiv preprint arXiv:1602.05629,", "citeRegEx": "39", "shortCiteRegEx": "39", "year": 2016}, {"title": "Mllib: Machine learning in apache spark", "author": ["X. Meng", "J. Bradley", "B. Yavuz", "E. Sparks", "S. Venkataraman", "D. Liu", "J. Freeman", "D. Tsai", "M. Amde", "S. Owen"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "40", "shortCiteRegEx": "40", "year": 2016}, {"title": "Personal data management wiht the Databox: What\u2019s inside the box", "author": ["R. Mortier", "J. Zhao", "J. Crowcroft", "L. Wang", "Q. Li", "H. Haddadi", "Y. Amar", "A. Crabtree", "J. Colley", "T. Lodge", "T. Brown", "D. McAuley", "C. Greenhalgh"], "venue": "In Proc. Cloud Assisted Networking workshop at ACM CoNEXT,", "citeRegEx": "41", "shortCiteRegEx": "41", "year": 2016}, {"title": "Rectified linear units improve restricted boltzmann machines", "author": ["V. Nair", "G.E. Hinton"], "venue": "In Proceedings of the 27th International Conference on Machine Learning", "citeRegEx": "42", "shortCiteRegEx": "42", "year": 2010}, {"title": "A survey on transfer learning", "author": ["S.J. Pan", "Q. Yang"], "venue": "IEEE Transactions on knowledge and data engineering,", "citeRegEx": "43", "shortCiteRegEx": "43", "year": 2010}, {"title": "Semi-supervised knowledge transfer for deep learning from private training data", "author": ["N. Papernot", "M. Abadi", "\u00da. Erlingsson", "I. Goodfellow", "K. Talwar"], "venue": "In Proceedings of the 5th International Conference on Learning Representations,", "citeRegEx": "44", "shortCiteRegEx": "44", "year": 2017}, {"title": "Signal processing and machine learning with differential privacy: Algorithms and challenges for continuous data", "author": ["A.D. Sarwate", "K. Chaudhuri"], "venue": "IEEE signal processing magazine,", "citeRegEx": "45", "shortCiteRegEx": "45", "year": 2013}, {"title": "Privacy-preserving deep learning", "author": ["R. Shokri", "V. Shmatikov"], "venue": "In Proceedings of the 22nd ACM SIGSAC conference on computer and communications security,", "citeRegEx": "46", "shortCiteRegEx": "46", "year": 2015}, {"title": "Membership inference attacks against machine learning models", "author": ["R. Shokri", "M. Stronati", "V. Shmatikov"], "venue": "In Proceedings of the 38th IEEE Symposium on Security and Privacy,", "citeRegEx": "47", "shortCiteRegEx": "47", "year": 2017}, {"title": "Stochastic gradient descent with differentially private updates", "author": ["S. Song", "K. Chaudhuri", "A.D. Sarwate"], "venue": "In Global Conference on Signal and Information Processing (GlobalSIP), 2013 IEEE,", "citeRegEx": "48", "shortCiteRegEx": "48", "year": 2013}, {"title": "Kvasir: Scalable provision of semantically relevant web content on big data framework", "author": ["L. Wang", "S. Tasoulis", "T. Roos", "J. Kangasharju"], "venue": "IEEE Transactions on Big Data,", "citeRegEx": "49", "shortCiteRegEx": "49", "year": 2016}, {"title": "The impact of personalization on smartphone-based activity recognition", "author": ["G.M. Weiss", "J.W. Lockhart"], "venue": "In AAAI Workshop on Activity Context Representation: Techniques and Languages,", "citeRegEx": "50", "shortCiteRegEx": "50", "year": 2012}, {"title": "Data mining with big data", "author": ["X. Wu", "X. Zhu", "G.Q. Wu", "W. Ding"], "venue": "IEEE Transactions on Knowledge and Data Engineering,", "citeRegEx": "51", "shortCiteRegEx": "51", "year": 2014}, {"title": "Adversarial label flips attack on support vector machines", "author": ["H. Xiao", "C. Eckert"], "venue": "In Proceedings of the 20th European Conference on Artificial Intelligence,", "citeRegEx": "52", "shortCiteRegEx": "52", "year": 2012}], "referenceMentions": [{"referenceID": 14, "context": "It is not only data from wearables that creates such risks: web queries, article reads and searches, visits to shopping sites and browsing online catalogues are also indexed, analysed, and traded by thousands of tracking services in order to build preference models [25].", "startOffset": 266, "endOffset": 270}, {"referenceID": 9, "context": "We are interested in an alternative approach where we reduce or remove the flow of user data to the cloud completely, instead moving computation to where the data already resides under the user\u2019s control [20, 41].", "startOffset": 204, "endOffset": 212}, {"referenceID": 30, "context": "We are interested in an alternative approach where we reduce or remove the flow of user data to the cloud completely, instead moving computation to where the data already resides under the user\u2019s control [20, 41].", "startOffset": 204, "endOffset": 212}, {"referenceID": 25, "context": "We evaluate this approach using (i) a neural network to recognise users\u2019 activity on the WISDM dataset [36] and (ii) the Latent Dirichlet Algorithm (LDA) [17] to identify topics in the Wikipedia and NIPS datasets [4, 9].", "startOffset": 103, "endOffset": 107}, {"referenceID": 6, "context": "We evaluate this approach using (i) a neural network to recognise users\u2019 activity on the WISDM dataset [36] and (ii) the Latent Dirichlet Algorithm (LDA) [17] to identify topics in the Wikipedia and NIPS datasets [4, 9].", "startOffset": 154, "endOffset": 158}, {"referenceID": 39, "context": ", activity recognition, it has been shown that a model trained solely using data from the individual concerned provides more accurate predictions for that individual than a model trained using data from other individuals [50].", "startOffset": 221, "endOffset": 225}, {"referenceID": 9, "context": "At the same time, this solution offers more privacy to the user as all computation, for both training and inference, can be done locally on the device [20].", "startOffset": 151, "endOffset": 155}, {"referenceID": 35, "context": "To assure the confidentiality of their data as well as their presence in the dataset, the shared model might be obtained using differentially private training [46, 39, 28, 44].", "startOffset": 159, "endOffset": 175}, {"referenceID": 28, "context": "To assure the confidentiality of their data as well as their presence in the dataset, the shared model might be obtained using differentially private training [46, 39, 28, 44].", "startOffset": 159, "endOffset": 175}, {"referenceID": 17, "context": "To assure the confidentiality of their data as well as their presence in the dataset, the shared model might be obtained using differentially private training [46, 39, 28, 44].", "startOffset": 159, "endOffset": 175}, {"referenceID": 33, "context": "To assure the confidentiality of their data as well as their presence in the dataset, the shared model might be obtained using differentially private training [46, 39, 28, 44].", "startOffset": 159, "endOffset": 175}, {"referenceID": 29, "context": "It may also need to perform more traditional, large scale processing, but can easily be built using modern data processing frameworks designed for datacenters such as Mllib [40] or GraphLab [38].", "startOffset": 173, "endOffset": 177}, {"referenceID": 27, "context": "It may also need to perform more traditional, large scale processing, but can easily be built using modern data processing frameworks designed for datacenters such as Mllib [40] or GraphLab [38].", "startOffset": 190, "endOffset": 194}, {"referenceID": 25, "context": "To test the algorithms, we use the WISDM Human Activity Recognition dataset [36], which is a collection of accelerometer data on an Android phone by 35 subjects performing 6 activities (walking, jogging, walking upstairs, walking downstairs, sitting and standing).", "startOffset": 76, "endOffset": 80}, {"referenceID": 25, "context": "Various time domain variables were extracted from the signal, and we consider the statistical measures obtained for every 10 seconds of accelerometer samples in [36] as the d = 43 dimensional features in our models.", "startOffset": 161, "endOffset": 165}, {"referenceID": 19, "context": "0/M ), being wij (wjk) the value of the connection weight between unit j (k) and unit i (j) in the previous layer, and N (M ) the number of input (hidden) units [30].", "startOffset": 161, "endOffset": 165}, {"referenceID": 31, "context": "The current recommendation is to use ReLU (Rectified Linear Unit) units [42, 30] as the activation function (\u03c6(x) = max(0, x)) though other options are possible.", "startOffset": 72, "endOffset": 80}, {"referenceID": 19, "context": "The current recommendation is to use ReLU (Rectified Linear Unit) units [42, 30] as the activation function (\u03c6(x) = max(0, x)) though other options are possible.", "startOffset": 72, "endOffset": 80}, {"referenceID": 19, "context": "For the shared model, MS , we initialise the weights to random small values and the bias to zero in both layers, as suggested by previous literature [30].", "startOffset": 149, "endOffset": 153}, {"referenceID": 20, "context": "Because of the sensitivity learning stages to feature scaling [31] we normalise all statistical measures to have zero mean and unit standard deviation.", "startOffset": 62, "endOffset": 66}, {"referenceID": 21, "context": "LDA is similar to pLSA [32] but replaces the maximum likelihood estimator with Bayesian estimator, hence it is sometimes referred to as the Bayesian version of pLSA.", "startOffset": 23, "endOffset": 27}, {"referenceID": 38, "context": "Many prior works [49, 27, 29, 34] focus on building compact and efficient data structure and search algorithm to speed up the queries to the models.", "startOffset": 17, "endOffset": 33}, {"referenceID": 16, "context": "Many prior works [49, 27, 29, 34] focus on building compact and efficient data structure and search algorithm to speed up the queries to the models.", "startOffset": 17, "endOffset": 33}, {"referenceID": 18, "context": "Many prior works [49, 27, 29, 34] focus on building compact and efficient data structure and search algorithm to speed up the queries to the models.", "startOffset": 17, "endOffset": 33}, {"referenceID": 23, "context": "Many prior works [49, 27, 29, 34] focus on building compact and efficient data structure and search algorithm to speed up the queries to the models.", "startOffset": 17, "endOffset": 33}, {"referenceID": 3, "context": "There are several potential attacks against any learning system [14, 33].", "startOffset": 64, "endOffset": 72}, {"referenceID": 22, "context": "There are several potential attacks against any learning system [14, 33].", "startOffset": 64, "endOffset": 72}, {"referenceID": 15, "context": "Since both the data and the personal model resides on the user\u2019s device, attacks such as model inversion [26] \u2013where an attacker, given the model and some auxiliary information about the user, can determine some user\u2019s raw data; and membership query [47], where, given a data record and black-box access to a model, an adversary could determine if the record was in the model\u00e2\u0102\u0179s training dataset, cannot affect our users.", "startOffset": 105, "endOffset": 109}, {"referenceID": 36, "context": "Since both the data and the personal model resides on the user\u2019s device, attacks such as model inversion [26] \u2013where an attacker, given the model and some auxiliary information about the user, can determine some user\u2019s raw data; and membership query [47], where, given a data record and black-box access to a model, an adversary could determine if the record was in the model\u00e2\u0102\u0179s training dataset, cannot affect our users.", "startOffset": 250, "endOffset": 254}, {"referenceID": 35, "context": "On the other hand, for applications such as face or speaker recognition, techniques based on differentially private training [46, 39, 28, 44] could be applied in order to, a priori, guarantee the confidentiality of the volunteers\u2019 data.", "startOffset": 125, "endOffset": 141}, {"referenceID": 28, "context": "On the other hand, for applications such as face or speaker recognition, techniques based on differentially private training [46, 39, 28, 44] could be applied in order to, a priori, guarantee the confidentiality of the volunteers\u2019 data.", "startOffset": 125, "endOffset": 141}, {"referenceID": 17, "context": "On the other hand, for applications such as face or speaker recognition, techniques based on differentially private training [46, 39, 28, 44] could be applied in order to, a priori, guarantee the confidentiality of the volunteers\u2019 data.", "startOffset": 125, "endOffset": 141}, {"referenceID": 33, "context": "On the other hand, for applications such as face or speaker recognition, techniques based on differentially private training [46, 39, 28, 44] could be applied in order to, a priori, guarantee the confidentiality of the volunteers\u2019 data.", "startOffset": 125, "endOffset": 141}, {"referenceID": 5, "context": "Some schemes have been proposed to conduct poisoning attacks against SVMs [16, 52], but we have barely seen any work about poisoning attacks against neural networks.", "startOffset": 74, "endOffset": 82}, {"referenceID": 41, "context": "Some schemes have been proposed to conduct poisoning attacks against SVMs [16, 52], but we have barely seen any work about poisoning attacks against neural networks.", "startOffset": 74, "endOffset": 82}, {"referenceID": 7, "context": "tion resources outside datacenters continues to increase with creation of \u201cfog computing\u201d environments using cheep and energy-efficient platforms such as those based on ARM processors [18].", "startOffset": 184, "endOffset": 188}, {"referenceID": 11, "context": "RELATED WORK Data-driven solutions are now pervasive in areas such as advertising, smart cities and eHealth [22, 51].", "startOffset": 108, "endOffset": 116}, {"referenceID": 40, "context": "RELATED WORK Data-driven solutions are now pervasive in areas such as advertising, smart cities and eHealth [22, 51].", "startOffset": 108, "endOffset": 116}, {"referenceID": 8, "context": "Although careful analysis of these data can be highly beneficial for us as individuals and for society in general, this approach usually entails invasion of privacy, a high price that progressively more people are not willing to pay [19].", "startOffset": 233, "endOffset": 237}, {"referenceID": 2, "context": "Several privacy-preserving analytical solutions have been proposed to guarantee the confidentiality of personal data while extracting useful information [13, 12, 24, 15].", "startOffset": 153, "endOffset": 169}, {"referenceID": 1, "context": "Several privacy-preserving analytical solutions have been proposed to guarantee the confidentiality of personal data while extracting useful information [13, 12, 24, 15].", "startOffset": 153, "endOffset": 169}, {"referenceID": 13, "context": "Several privacy-preserving analytical solutions have been proposed to guarantee the confidentiality of personal data while extracting useful information [13, 12, 24, 15].", "startOffset": 153, "endOffset": 169}, {"referenceID": 4, "context": "Several privacy-preserving analytical solutions have been proposed to guarantee the confidentiality of personal data while extracting useful information [13, 12, 24, 15].", "startOffset": 153, "endOffset": 169}, {"referenceID": 34, "context": "Prominent among them are those that build on Dwork\u2019s differential privacyframework [45, 48, 21, 26, 11], which formalises the idea that a query over a sensitive database should not reveal", "startOffset": 83, "endOffset": 103}, {"referenceID": 37, "context": "Prominent among them are those that build on Dwork\u2019s differential privacyframework [45, 48, 21, 26, 11], which formalises the idea that a query over a sensitive database should not reveal", "startOffset": 83, "endOffset": 103}, {"referenceID": 10, "context": "Prominent among them are those that build on Dwork\u2019s differential privacyframework [45, 48, 21, 26, 11], which formalises the idea that a query over a sensitive database should not reveal", "startOffset": 83, "endOffset": 103}, {"referenceID": 15, "context": "Prominent among them are those that build on Dwork\u2019s differential privacyframework [45, 48, 21, 26, 11], which formalises the idea that a query over a sensitive database should not reveal", "startOffset": 83, "endOffset": 103}, {"referenceID": 0, "context": "Prominent among them are those that build on Dwork\u2019s differential privacyframework [45, 48, 21, 26, 11], which formalises the idea that a query over a sensitive database should not reveal", "startOffset": 83, "endOffset": 103}], "year": 2017, "abstractText": "Many current Internet services rely on inferences from models trained on user data. Commonly, both the training and inference tasks are carried out using cloud resources fed by personal data collected at scale from users. Holding and using such large collections of personal data in the cloud creates privacy risks to the data subjects, but is currently required for users to benefit from such services. We explore how to provide for model training and inference in a system where computation is moved to the data in preference to moving data to the cloud, obviating many current privacy risks. Specifically, we take an initial model learnt from a small set of users and retrain it locally using data from a single user. We evaluate on two tasks: one supervised learning task, using a neural network to recognise users\u2019 current activity from accelerometer traces; and one unsupervised learning task, identifying topics in a large set of documents. In both cases the accuracy is improved. We also demonstrate the robustness of our approach against adversarial attacks, as well as its feasibility by presenting a performance evaluation on a representative resource-constrained device (a Raspberry Pi).", "creator": "LaTeX with hyperref package"}}}