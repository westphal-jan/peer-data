{"id": "1703.00796", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "2-Mar-2017", "title": "Unsupervised Steganalysis Based on Artificial Training Sets", "abstract": "In this paper, an unsupervised steganalysis method that combines artificial training setsand supervised classification is proposed. We provide a formal framework for unsupervisedclassification of stego and cover images in the typical situation of targeted steganalysis (i.e., in order to produce a picture of the task set) for each of the task sets and use in the context of this paper. This paper describes a model of unsupervised classification and describes a model of machine learning that combines machine learning and deep learning to investigate the neural networks used to generate and organize high-level image sets in parallel to the training algorithms.\n\n\n\n\n\n\n\nThis paper is a work in progress with the \"Unsupervised Training and Image Analysis of Machine Learning.\" It is available as a PDF at: http://www.aricl.com/content/d/12/1/7-3.pdf", "histories": [["v1", "Thu, 2 Mar 2017 14:25:13 GMT  (1136kb,D)", "http://arxiv.org/abs/1703.00796v1", null]], "reviews": [], "SUBJECTS": "cs.MM cs.LG", "authors": ["daniel lerch-hostalot", "david meg\\'ias"], "accepted": false, "id": "1703.00796"}, "pdf": {"name": "1703.00796.pdf", "metadata": {"source": "CRF", "title": "Unsupervised Steganalysis Based on Artificial Training Sets", "authors": ["Daniel Lerch-Hostalot", "David Me\u01f5\u0131as"], "emails": ["dlerch@uoc.edu", "dmegias@uoc.edu"], "sections": [{"heading": null, "text": "In this paper, an unsupervised steganalysis method that combines artificial training sets and supervised classification is proposed. We provide a formal framework for unsupervised classification of stego and cover images in the typical situation of targeted steganalysis (i.e., for a known algorithm and approximate embedding bit rate). We also present a complete set of experiments using 1) eight different image databases, 2) image features based on Rich Models, and 3) three different embedding algorithms: Least Significant Bit (LSB) matching, Highly undetectable steganography (HUGO) and Wavelet Obtained Weights (WOW). We show that the experimental results outperform previous methods based on Rich Models in the majority of the tested cases. At the same time, the proposed approach bypasses the problem of Cover Source Mismatch \u2013when the embedding algorithm and bit rate are known\u2013 , since it removes the need of a training database when we have a large enough testing set. Furthermore, we provide a generic proof of the proposed framework in the machine learning context. Hence, the results of this paper could be extended to other classification problems similar to steganalysis.\nKeywords: Unsupervised steganalysis, Cover source mismatch, Machine learning"}, {"heading": "1. Introduction", "text": "Data hiding is a collection of techniques to embed secret data into digital media. These techniques can be used in many different application scenarios, such as secret communications, copyright protection or authentication of digital contents, among others. Images are the most common carriers for data hiding because of their widespread use in the Internet.\nWithin data hiding, steganography is a major branch whose goal is to secretly communicate data, making it undetectable for an attacker. On the other hand, steganalysis is another branch whose goal is to detect messages previously hidden using steganography.\nMany of the image steganalysis methods in the state of the art (Pevny\u0301 et al., 2010a; Fridrich and Kodovsky\u0301, 2012) use feature-based steganalysis and machine learning classification. In order to apply this methodology, the steganalyst needs to extract a set of features\nEmail addresses: dlerch@uoc.edu (Daniel Lerch-Hostalot), dmegias@uoc.edu (David Meg\u0301\u0131as)\nfrom a training data set and train a classifier. Then, the classifier is tested using a testing data set and, if the results are satisfactory, the classifier is considered successful.\nThis approach is widely adopted in classification tasks. The classifier is trained with a specific data set and, consequently, its classification capabilities usually decrease as the testing data set differs from the training data. As a result, this methodology is not fully effective when used in real-world scenarios.\nThe data set obtained after feature extraction depends on many factors, such as the steganographic algorithm used for hiding data into the cover source, the algorithm used for feature extraction or the properties of the cover source in different aspects (e.g. size, noise and hardware used for acquisition). If similar cover source is used, the feature extraction process provides data sets with similar representation and, therefore, the machine learning tools work properly and the classification results are satisfactory. However, if different cover source is used, the data sets obtained by feature extraction are also different, producing a degradation of the classification results. Machine learning (Mitchell, 1997; Bishop, 2006) literature refers to this problem as domain adaptation, whereas the term used to refer to this situation in steganalysis is cover source mismatch (CSM). This constitutes an important open problem in the field (Ker et al., 2013), which was initially reported in (Cancelli et al., 2008).\nSeveral approaches to deal with the CSM problem have been proposed in the recent years. In the BOSS competition (Filler et al., 2010), the BOSSrank database (which suffers from CSM) had to be used as a testing set. Some participants of the competition tried to include the testing set images in the training set (Gul and Kurugollu, 2011; Fridrich et al., 2011). This idea was called \u201ctraining on a contaminated database\u201d (Fridrich et al., 2011). This approach consists in applying denoising algorithms to estimate the cover sources of the testing set and using these estimated covers to generate new stego samples, by embedding new information into them. After that, these new estimated cover and stego samples are included in the training set.\nIn 2012, a solution based on training a classifier with a huge variety of images was proposed (Lubenko and Ker, 2012). This approach consists in applying machine learning to millions of images. Due to the high time and memory requests, this step is performed using on-line classifiers. Later on, in 2013, the use of rich features in universal steganalysis was analyzed (Pevny\u0301 and Ker, 2013). Since rich features are not sensitive enough for their application in universal steganalysis, the authors apply linear projections informed by embedding methods and an anomaly detector. This approach tries to make these projections sensitive to stego content and, at the same time, insensitive to cover variation.\nIn 2014, different methods to deal with CSM were presented. Ker and Pevny\u0301 (2014) show the possibility of centering features when there is a shift in the cover sources, by subtracting an estimated centroid of the cover features. Ker and Pevny\u0301 also use weighted ensemble methods to deal with situations in which the features are moving in different directions after embedding. Kodovsky\u0301 et al. (2014) present three different strategies to deal with CSM. The first one consists in training with a mixture of different cover sources. The second approach uses different classifiers trained on different sources and, in the testing step, the testing set is classified using the closest source. The third strategy is similar to the second one, but\ntesting each image separately using the closest source. In 2014, another approach, based on Ensemble Classifiers with Feature Selection (EC-FS) (Chaumont and Kouider, 2012), was proposed by Pasquet et al. (2014). In this new method, Pasquet et al. use the EC-FS classifier with the Islet approach, a pre-processing step that consists in organizing images in clusters and assigning a steganalyzer to each cluster. Using this technique, a classifier can manage the diversity of the images more easily, after learning with a set of close feature vectors (in each cluster, the distance between the feature vectors is relatively small). This allows reducing the number of required images from millions to a few thousands.\nIn this paper we present a new approach based on bypassing the CSM problem rather than addressing it. The proposed technique consists in creating an \u201cartificial\u201d training set from the testing set. This artificial training set is formed by applying the targeted steganographic algorithm to the testing data (the data set A) twice. If the testing set A is formed by stego and cover images, a first application of the steganographic algorithm results in a \u201ctransformed\u201d set B with \u201cdouble stego\u201d and stego images. The second application of the steganographic algorithm produces a \u201cdouble transformed\u201d set C that includes \u201ctriple stego\u201d and \u201cdouble stego\u201d images. We show how the sets A and C can be used as artificial training data to finally classify the set B into stego and \u201cdouble stego\u201d images. Since there is a bijection between the elements of A and B, this is equivalent to the classification of the images in A as cover or stego.\nThe idea behind the proposal is that part of the images that we want to classify \u2013 the cover images\u2013 can be transformed into images that belong to the other class that we want to classify: the class of stego images. This fact is exploited to create an artificial training set that is used to find a boundary between classes with remarkable accuracy. This classification technique can thus have a relevant impact in the way in which steganalysis is usually approached, since it allows classifying the images without a real training set, which constitutes the direct cause of the CSM problem.\nIn this paper, we provide results for three different steganographic methods, namely, Least Significant Bit (LSB) matching (LSB matching) (Mielika\u0308inen, 2006), Highly undetectable steganography (HUGO) (Pevny\u0301 et al., 2010b) and Wavelet Obtained Weights (WOW) (Holub and Fridrich, 2012). Nevertheless, the proposed method is general and can be applied to any steganographic system, such as the more recent methods suggested by Karakis\u0327 et al. (2015).\nThe rest of this paper is organized as follows. Section 2 presents the proposed method, which is formalised in Section 3. Section 4 presents the experimental results obtained using the proposed method for eight different image databases in a cross-domain environment. Finally, Section 5 summarizes the conclusions of this work and suggests some directions for further research."}, {"heading": "2. Proposed Method", "text": "This section presents a description of the method proposed in the paper. First of all, we assume that the embedding algorithm and the approximate bit rate used by the steganographer are known. Using the same algorithm and bit rate, we can perform\nnew embedding operations to all the images in the testing database. Let A be the testing data set; B the transformed set, obtained after embedding data in all the images of A; and C the double transformed set, obtained after embedding data in all the images of B. As a result, A contains cover and stego images, B contains stego and \u201cdouble stego\u201d images, and C contains \u201cdouble stego\u201d and \u201ctriple stego\u201d images. The interesting fact of this situation is that, if we create an artificial training set formed by A and C, we can train a classifier to learn the boundary between A and C. In principle, the same boundary can be used to classify the transformed set B into stego and \u201cdouble stego\u201d images. Furthermore, the existing bijection between the elements of B and A makes it possible to relate each stego image of B with a cover image in A, and each \u201cdouble stego\u201d image in B with a stego image in A. Hence, classifying B as stego or \u201ddouble stego\u201d images is equivalent to classifying A as cover or stego images. The bijection between the elements of A and B can be recorded in order to complete the classification of the original testing set A.\nA simple graphical representation of this approach is shown in Fig.1 to illustrate the rationale behind the proposed algorithm. In Fig.1a, we can see the set A, with the cover and stego samples depicted as white and gray circles, respectively. Although the cover and stego images are shown with circles of different color, note that this set is not labeled for classification (since it is the testing data set). In Fig.1b, the set B, resulting from the application of the steganographic algorithm to all the images of the A, are shown. In this case, the cover images of A become stego images of B (white triangles), whereas the stego images of A become \u201cdouble stego\u201d images of B (gray triangles). Similarly, in Fig.1c, we can see the \u201cdouble transformed\u201d set C, which contains \u201cdouble stego\u201d (white stars) and \u201ctriple stego\u201d images (gray stars). In Fig.1d, all the data sets A, B and C are shown together.\nThe boundary between A and C can be found using machine learning with A \u222a C as a training set, as shown in Fig.1e. In this step, two different labels must be used, one for the images of A and the other one for those of C. Then, this trained classifier can be applied to the set B as depicted in Fig.1f, where the learnt boundary is used to classify the images of B as stego or \u201cdouble stego\u201d. Finally, this result can be applied to separate A into cover and stego images, since stego images in B match cover images in A, whereas \u201cdouble stego\u201d images in B match stego images in A.\nA flowchart of the proposed algorithm is shown in Fig.2. For the sake of notational simplicity, (A, \u03bb\u20321) and (B, \u03bb \u2032 2) stand for the Cartesian products A \u00d7 {\u03bb\u20321} and B \u00d7 {\u03bb\u20322}, respectively. Similarly, a function applied to a set, e.g. Ebr(A), means that the function is applied to all the elements (images) of that set, and the resulting image set is returned. The call to the function Train returns a classifier Clf. This classifier is then used to separate B into stego (\u03bb\u20321) and \u201cdouble stego\u201d (\u03bb \u2032 2) images, by calling the function Classify. The final loop \u201ctranslates\u201d the classification of the images of B, as stego (\u03bb\u20321) or \u201cdouble stego\u201d (\u03bb\u20322), into the classification of the images of A, as cover (\u03bb1) or stego (\u03bb2). In this loop, n = |A| = |B| = |C|, where | \u00b7 | stands for the cardinality of a set.\nIt must be taken into account that the notation in the flowchart is deliberately abused, since the training and classification procedures are not carried out directly with the images, but with their feature vectors which must be extracted before.\nA theoretical analysis of the approach is provided in the next section. The theoretical\nanalysis includes a theorem and a proof based on the assumptions taken (which are standard assumptions in the field of targeted steganalysis)."}, {"heading": "3. Theoretical Analysis", "text": "This section is aimed at providing a theoretical framework for the suggested method, by means of definitions, lemmas, a theorem and proofs.\nFirst of all, we provide a formalisation of learning algorithms with some basic definitions. Consider an input space X (of samples) and an output space L = {\u03bb1, \u03bb2, . . . , \u03bbM} (of labels), and assume that the pairs (xi, li) \u2208 X \u00d7 L are random variables i.i.d. according to an unknown distribution D, such that each xi is associated to a unique label li.\nThe goal of a classification (learning) algorithm is to find a function h : X \u2192 L that predicts li from xi. The function h is an approximation of an unknown labeling function t : X \u2192 L that relates each value of X with its corresponding unique label in L.\nThere are two types of classification methods:\n\u2022 Supervised classification: in this case, we use a training set ofm known samples (pairs) {(x1, l1), (x2, l2), . . . , (xm, lm)} \u2282 X \u00d7 L in a training fase to obtain the function h.\nAfter that, the function h is used to classify a testing set of n vectors {x\u20321, x\u20322, . . . , x\u2032n} \u2282 X, without any label assigned to them.\n\u2022 Unsupervised classification: in this case, the learning algorithm obtains the function h to classify a testing set without requiring any training set.\nNow, we provide some definitions required for the proposed method and a formal proof by means of a theorem.\nDefinition 1. We call splitting function to a function s : X \u2032 \u2192 s[X \u2032], where X \u2032, s[X \u2032], s[s[X \u2032]], s[s[s[X \u2032]]] \u2282 X, such that:\n1. When s(xi) = xj and t(xi) = \u03bbk, then t(xj) = \u03bbk+1 (with \u03bbk \u2208 L for k < M), 2. X \u2032 \u2229 s[X \u2032] = \u2205, 3. X \u2032 \u2229 s[s[X \u2032]] = \u2205, and 4. X \u2032 \u2229 s[s[s[X \u2032]]] = \u2205.\nDefinition 2. Given a set V of n1 vectors {v1, v2, . . . , vn1} \u2286 X \u2032, such that t(vi) = \u03bb1 for all i = 1, 2, . . . , n1, and X\n\u2032 \u2282 X, and a set W of n2 vectors {w1, w2, . . . , wn2} \u2286 s[X \u2032], whereby s[X \u2032] \u2282 X, for some splitting function s (and hence X \u2032 \u2229 s[X \u2032] = \u2205, X \u2032 \u2229 s[s[X \u2032]] = \u2205 and X \u2032 \u2229 s[s[s[X \u2032]]] = \u2205), we call A = V \u222aW an s-partable set.\nRemark 1. Note that the label corresponding to the vectors of W , according to Def.1, is \u03bb2.\nRemark 2. The sets V and W are disjoint as per Condition 2 of Def.1 and, thus, we assume that some feature set exists to classify the elements of A into V and W by using machine learning. In an s-partable set, we should be able to approximately classify the set A = V \u222aW into the subsets V (with label \u03bb1) and W (with label \u03bb2), hence the name \u201cs-partable\u201d. This would occur if the splitting function produces some \u201cmeasurable difference\u201d when applied to the original data vectors.\nLemma 1. Given an s-partable set A \u2286 X \u2032 \u222a s[X \u2032], for some splitting function s, then s[s[X \u2032]] \u2229 A = \u2205.\nProof.\ns[s[X \u2032]] \u2229 A \u2286 s[s[X \u2032]] \u2229 (X \u2032 \u222a s[X \u2032]) = (s[s[X \u2032]] \u2229X \u2032) \u222a (s[s[X \u2032]] \u2229 s[X \u2032]) = \u2205 \u222a \u2205 = \u2205.\nNote that (s[s[X \u2032]] \u2229X \u2032) = \u2205 due to Condition 3 in Def.1 and (s[s[X \u2032]] \u2229 s[X \u2032]) = \u2205 due to Condition 2 in Def.1 (with Y \u2032 = s[X \u2032]).\nLemma 2. Given an s-partable set A \u2286 X \u2032 \u222a s[X \u2032], for some splitting function s, then s[X \u2032] \u2229 s[s[A]] = \u2205.\nProof.\ns[X \u2032] \u2229 s[s[A]] \u2286 s[X \u2032] \u2229 (s[s[X \u2032]] \u222a s[s[s[X \u2032]]]) = (s[X \u2032] \u2229 s[s[X \u2032]]) \u222a (s[X \u2032] \u2229 s[s[s[X \u2032]]]) = \u2205 \u222a \u2205 = \u2205.\nNote that (s[X \u2032] \u2229 s[s[X \u2032]]) = \u2205 due to Condition 2 in Def.1 (with Y \u2032 = s[X \u2032]) and (s[X \u2032] \u2229 s[s[s[X \u2032]]]) = \u2205 due to Condition 3 in Def.1 (again, with Y \u2032 = s[X \u2032]).\nLemma 3. Given an s-partable set A \u2286 X \u2032 \u222a s[X \u2032], for some splitting function s, then A \u2229 s[s[A]] = \u2205.\nProof. The proof directly follows from considering\nA \u2229 s[s[A]] \u2286 (X \u2032 \u222a s[X \u2032]) \u2229 (s[s[X \u2032]] \u222a s[s[s[X \u2032]]]),\nand then applying the distributive property of set algebra and Conditions 2, 3 and 4 of Def.1.\nTheorem 1. Unsupervised classification of an s-partable set A = {a1, a2, . . . , an}, formed as per Def.2 for some splitting function s, can be achieved with supervised classification of B = s[A] as a testing set if the function s is known (or can be approximated) by constructing an artificial training set.\nRationale behind the proof. The proof provided below is based on the following principles:\n1. The set A of samples to be classified and the set of \u201cdouble transformed\u201d samples C = s[s[A]] are disjoint as per Lemma 3. Hence, we assume that a machine learning algorithm (for some set of features) can be trained to separate A and C. Thus, we merge these two sets for training (using different labels for the elements of A and C). 2. The set of \u201ctransformed samples\u201d B = s[A] has elements either in s[X \u2032] or in s[s[X \u2032]]. These two sets are disjoint as per Condition 2 of Def.1. 3. The intersection between the subset of the elements of B belonging to s[X \u2032] and C is empty, but the intersection of the same subset with A is not. Hence, if we use the trained algorithm to classify B, there is a high probability that the elements of B belonging to s[X \u2032] will be classified with the label used for the elements of A. 4. Similarly, the intersection between the subset of the elements of B belonging to s[s[X \u2032]] and A is empty, but the intersection of the same subset with C is not. Hence, the elements of B belonging to s[s[X \u2032]] will be classified mainly with the same label as those of C.\n5. Separating the elements of B into s[X \u2032] and [s[s[X \u2032]] is equivalent to separating the elements of A into X \u2032 and s[X \u2032], due to the existing bijection between the elements of A and B.\nProof. Since A is an s-partable set by definition (for the splitting function s), some elements ai belong to the set X\n\u2032 and some other belong to s[X \u2032]. A classification function must assign the labels \u03bb1 and \u03bb2 for the elements ai belonging to X\n\u2032 and s[X \u2032], respectively. Consider two additional sets B = {b1, b2, . . . , bn} = s[A], with bi = s(ai), and C = {c1, c2, . . . , cn} = s[B] = s[s[A]], with ci = s(bi) = s(s(ai)). Since A \u2286 X \u2032 \u222a s[X \u2032], then B \u2286 s[X \u2032] \u222a s[s[X \u2032]] and C \u2286 s[s[X \u2032]] \u222a s[s[s[X \u2032]]]. Now, construct an auxiliary training set T as follows:\nT = {(a1, \u03bb\u20321), (a2, \u03bb\u20321), . . . , (an, \u03bb\u20321), (c1, \u03bb\u20322), (c2, \u03bb\u20322), . . . , (cn, \u03bb\u20322)},\nsuch that T \u2282 (A\u222aC)\u00d7L\u2032 for L\u2032 = {\u03bb\u20321, \u03bb\u20322}. Note that the label \u03bb\u20321 is used for the elements of A and the label \u03bb\u20322 is used for the elements of C = s[s[A]].\nIf we use supervised classification with the training set T , we can obtain a classifying function h : T \u2192 L\u2032. This classification is possible since, as proven in Lemma 3, the intersection between A and C = s[s[A]] is the empty set. Now, if the function h can classify T into A and C, the same function would classify B into s[X \u2032] and s[s[X \u2032]], since s[s[X \u2032]] \u2229 A = \u2205 (as proven in Lemma 1) and s[X \u2032] \u2229 C = \u2205 (as proven in Lemma 2). On the other hand, s[X \u2032] \u2229 A and s[s[X \u2032]] \u2229 C are not empty. Note also that, by Def.1, s[X \u2032] \u2229 s[s[X \u2032]] = \u2205.\nThus, using the same function h, we can classify each bi with the label \u03bb \u2032 1 (if it belongs to s[X \u2032]) or \u03bb\u20322 (if it belongs to s[s[X \u2032]]). Therefore, this function also classifies A into X \u2032 and s[X \u2032], since bi = s(ai). If bi is classified with the label \u03bb \u2032 1, this means that bi = s(ai) belongs to s[X \u2032] and ai belongs to X \u2032. Similarly, if bi is classified with the label \u03bb \u2032 2, then bi = s(ai) belongs to s[s[X \u2032]] and ai belongs to s[X \u2032]. Hence, the classification of bi = s(ai) as \u03bb \u2032 1 or \u03bb \u2032 2 is equivalent to the classification of ai as \u03bb1 or \u03bb2, respectively. Consequently, we can finally classify A without labeled samples and, by definition, this is unsupervised classification.\nRemark 3. Unsupervised classification of A is thus achieved due to the application of the splitting function s to A (twice), which allows creating an artificial training set and to use supervised classification. Hence, if we have a training set and we use it to find a function h : X \u2192 L for classifying a testing set, by definition, this is supervised classification. Remark 4. Note, however, that some degree of misclassification of the elements in B is possible, because the elements in B will not be either in A nor C. Since A = V \u222aW will usually be a strict subset of X \u2032\u222as[X \u2032], the elements bi \u2208 s[X \u2032] will be outside W (and outside A), and some of them may be classified incorrectly with the label \u03bb\u20322. Similarly, the elements bj \u2208 s[s[X \u2032]] will be outside s[s[V ]] (and outside C), and some of them may be classified incorrectly with the label \u03bb\u20321. This will lead to some degree of error in the unsupervised classification of B. The larger the difference introduced by the splitting function s is, the least likely the misclassification will become. In any case, it must be taken into account that machine learning classification processes are not error-free."}, {"heading": "3.1. Application to Steganalysis", "text": "The application of the framework described above to steganalysis can be carried out in the following way:\n\u2022 The set X is formed by samples of feature vectors of images (some of them stego and some of them cover).\n\u2022 The splitting function s is the steganographic method we want to detect (using approximately the same embedding bit rate). We assume no knowledge about the secret keys of the steganographic scheme.\n\u2022 The set X \u2032 represents the features of cover images, whereas the set s[X \u2032] represents the features of stego images. Note that X \u2032\u2229 s[X \u2032] = \u2205, since an image cannot be cover and stego at the same time.\n\u2022 Note that the above condition also implies that successive applications of the embedding method produce disjoint sets. Since the condition applies to any subset X \u2032 \u2282 X, we also require, for example, that s[X \u2032]\u2229s[s[X \u2032]] = \u2205. Some steganographic algorithms may not satisfy this condition. For example, LSB replacement1 with an embedding bit rate close to 1 bit per pixel (bpp) may not produce significant differences between s[X \u2032] and s[s[X \u2032]]. Since the proposed method is designed for targeted steganalysis, this condition can be considered known by the steganalyst.\n\u2022 Another problem related to this condition is the fact that the \u201csplitting\u201d properties of the embedding process must be fulfilled for some specific feature set, which is used for training the artificial training set and then classifying the \u201ctransformed samples\u201d. For example, the Adaptive Steganography by Oracle (ASO) embedding algorithm (Kouider et al., 2013) is particularly designed to enhance its undetectability with respect to the features used by Ensemble Classifiers as proposed in (Kodovsky\u0301 et al., 2012). Hence, if we use this set of features for classification, it is likely that the suggested approach is not effective for ASO steganography.\n\u2022 The set s[s[X \u2032]] is formed by the features of \u201cdouble stego\u201d images and, again, we have X \u2032\u2229s[s[X \u2032]] = \u2205, since an image cannot be cover and \u201cdouble stego\u201d at the same time. The same applies for \u201ctriple stego\u201d images: X \u2032 \u2229 s[s[s[X \u2032]]] = \u2205.\n\u2022 The s-partable set A = V \u222aW is the testing set for the machine learning classification problem. This set is formed by some cover images (belonging to V \u2282 X \u2032) and some stego images (belonging to W \u2282 s[X \u2032]).\n\u2022 The label \u03bb1 corresponds to cover images, whereas \u03bb2 refers to stego images.\n1Not to be mistaken for LSB matching.\n\u2022 The application of the splitting function s to V obviously produces stego images with no possible intersection with the set of cover images (X \u2032). The same thing occurs after different applications of the splitting function, producing \u201cdouble stego\u201d images, \u201ctriple stego\u201d images, and so on.\n\u2022 B = s[A] is formed by \u201cstego\u201d (s[V ] \u2282 s[X \u2032]) and \u201cdouble stego\u201d (s[W ] \u2282 s[s[X \u2032]]) images.\n\u2022 C = s[B] = s[s[A]] is formed by \u201cdouble stego\u201d (s[s[V ]] \u2282 s[s[X \u2032]]) and \u201ctriple stego\u201d (s[s[W ]] \u2282 s[s[s[X \u2032]]]) images.\nWith these definitions, the method described in this section can be applied for the classification of stego and cover images, yielding an unsupervised steganalytic system."}, {"heading": "4. Experimental Results", "text": "This section presents the results obtained with the proposed method and a comparison with existing techniques in the literature to illustrate the performance of the suggested approach.\nIn order to test the proposed approach, we have selected eight distinct image databases:\n\u2022 The BOSS database is the set of training images for the competition Break Our Steganographic System! (Filler et al., 2010). This database is formed by 10,000 cover images with a fixed size of 512 \u00d7 512 pixels, obtained with seven different cameras (Bas et al., 2011). The cover images were provided together with a stego set, obtained after embedding the cover images using HUGO steganography with 0.40 bpp. Hence, the whole training set was formed by 20,000 images. However, after the competition, a weakness was found (Kodovsky\u0301 et al., 2011) in the creation of the stego set, which can be removed embedding with a different threshold (T = 255 instead of the default value T = 90 that was used in the BOSS challenge). Therefore, we have repaired the database of 20,000 images by replacing the stego set with the 10,000 cover images embedded with HUGO steganography and 0.40 bpp, using the correct value of the threshold.\n\u2022 The RANK database (often referred to as BOSSrank) is the set of testing images from the competition Break Our Steganographic System! (Filler et al., 2010). This database is formed by 1,000 cover images with a fixed size of 512 \u00d7 512 pixels. These images were first provided in the competition as a testing set and, hence, they were unlabeled and different from those of BOSS. 847 of the RANK images were taken using one of the cameras used to generate the BOSS database, but the remaining 153 images were taken with a camera not included in the BOSS database (Bas et al., 2011). Thus, these 153 images exhibit the CSM problem with respect to the BOSS database. After the competition, the whole cover set was released. Again, we have repaired the stego set using the correct threshold for HUGO steganography with 0.40 bpp (i.e., T = 255). The repaired database is formed by 942 images, 471 of which are cover and 471 stego.\n\u2022 The NRCS database consists of images from the National Resource Conservation System (NRCS, n.d) with a fixed size of 2100\u00d7 1500 pixels.\n\u2022 The ESO database consists of images from the European Southern Observatory (ESO, n.d) with variable sizes about 1200\u00d7 1200 pixels.\n\u2022 The Interactions database consists of images from Interactions.org (INTE, n.d) with variable sizes about 600\u00d7 400 pixels.\n\u2022 The NOAA database consists of images from the National Oceanic and Atmospheric Administration (NOAA, n.d) with variable sizes about 2000\u00d7 1500 pixels.\n\u2022 The Albion database consists of images from the Plant Image Database of the Albion College (ALBI, n.d) with a fixed size of 1024\u00d7 685 pixels.\n\u2022 The Calphotos database consists of images from the Regents of the University of California (CALP, n.d) with variable sizes about 700\u00d7 500 pixels.\nThe steganographic algorithms used in the experiments are LSB matching (Mielika\u0308inen, 2006), with embedding bit rates of 0.25 and 0.10 bpp, HUGO (Pevny\u0301 et al., 2010b), with embedding bit rates of 0.40 and 0.20 bpp, and WOW (Holub and Fridrich, 2012), with embedding bit rates of 0.40 and 0.20 bpp.\nSince we are addressing targeted steganalysis, the splitting function used for the proposed unsupervised approach is the same steganographic algorithm and the same embedding bit rate, unless otherwise explicitly specified. Note, however, that although we are using the same embedding bit rate, the secret key of the steganographic algorithm (which determines the exact embedded pixels) is not used in our splitting function (since the secret key is assumed unknown by the steganalyzer).\nThe steganalysis approach taken in this paper stems from the well-known Rich Models framework (Fridrich and Kodovsky\u0301, 2012), which proposes a feature extraction step using multiple submodels, and a classification step based on Ensemble Classifiers (Breiman, 2001; Kodovsky\u0301 et al., 2011, 2012). Ensemble Classifiers scale very well with the number of training samples and dimensionality, and provide similar accuracy compared to the well-known Support Vector Machine (SVM) approach if enough training samples are used (Kodovsky\u0301 et al., 2011, 2012). On the other hand, SVMs \u2013particularly the Gaussian Kernel based SVM (G-SVM)\u2013 are more accurate with a relatively small number of samples and dimensions.\nFor a fair comparison between the traditional supervised approach and the proposed unsupervised method, we used two different classifications techniques. The supervised approach used the full Spatial domain Rich Model (SRM) feature set and was trained with the BOSS database. In most of the experiments, we used 19,000 images for training (9,500 cover and 9,500 stego), chosen randomly from the full database of 10,000 cover and 10,000 stego images. For a particular experiment (Section 4.4), we used a different training set, as explicitly detailed below.\nOn the other hand, it must be taken into account that the proposed method is designed for small sets of images, since we do not have a training set and, therefore, Ensemble\nClassifiers are not the best choice. For this reason, we used a G-SVM together with a standard feature selection phase (34,671 dimensions are too many for training a G-SVM). More specifically, the feature selection step chooses the best 500 features based on their ANOVA F -value. Hence, we provide the best possible settings for both the supervised and the proposed methods, which allows a fair comparison between them.\nWhenever SVMs were used, we chose an SVM with a Gaussian kernel. This classifier must be adjusted to provide optimal results. In particular, the values for the parameters C and \u03b3 must be selected to provide the classifier with the ability to generalize. This process was carried out as described in (Hsu et al., 2003). For all the experiments with SVMs in this paper, we used cross-validation on the training set applying the following multiplicative grid for C and \u03b3:\nC \u2208 { 2\u22125, 2\u22123, 2\u22121, 21, 23, . . . , 215 } ,\n\u03b3 \u2208 { 2\u221215, 2\u221213, 2\u221211, . . . , 2\u22121, 21, 23 } ."}, {"heading": "4.1. Same Number of Cover and Stego Images and CSM", "text": "To compare the results obtained with the supervised method and the proposed approach, we carried out different experiments. As mentioned above, these experiments were performed using Ensemble Classifiers in the case of supervised classification and G-SVM with feature selection for the proposed method.\nIn this section, all the experiments with supervised classification were performed training with a database of 19,000 images. The remaining 1,000 images were used as the testing set when the training and testing databases matched. For the proposed method, all the experiments were carried out using only the testing set.\nIn the first group of experiments, the testing sets consisted of 250 images, 125 of which were cover and the other 125 were stego. The aim of this experiment was to compare how the CSM problem affects the results obtained with supervised classification in contrast with those provided by the proposed method. For this reason, we used the BOSS database as training set for the supervised method and all the databases (including BOSS) for testing. When the testing database is different from BOSS, the CSM problem came along.\nIn Table 1, we can see the results using LSB Matching with embedding bit rates of 0.25 and 0.10 bpp, HUGO (Pevny\u0301 et al., 2010b) with embedding bit rates of 0.40 and 0.20 bpp and WOW (Holub and Fridrich, 2012) with embedding bit rates of 0.40 and 0.20 bpp. In all the cases, we provide the results using both supervised classification (column \u201cSUP\u201d) and the proposed method (Artificial Training Sets, column \u201cATS\u201d).\nIt can be observed that the suggested unsupervised approach provided the best results for almost all cases (the best results are boldfaced). Note, also, that the CSM problem is completely avoided with the proposed method, since it does not need a training database, which represents one of the major drawbacks of supervised steganalysis. The worst case occurs with the NRCS database and HUGO with an embedding bit rate of 0.20 bpp, for which none of the two methods succeeded in classifying the images correctly (yielding classification accuracies about 0.5, i.e., equivalent to random guessing).\nOne may think that the results obtained with the suggested method and those of the supervised approach should be almost identical when no CSM problem occurs. However, even when there was no CSM (first row of Table 1), we obtained a classification accuracy difference in favor of the suggested approach. We think that the reason for this difference, even when there is no CSM, is the fact that the artificial training step required by our method is performed exactly with the same images of the testing set. Even within the same database, there will be significant differences between different images. This will lead to relevant differences between the training and the testing sets and degraded classification results when traditional supervised methods are used. The suggested \u201cartificial training\u201d step is applied to exactly the same images used for testing, which prevents this \u201cdegradation\u201d.\nAnother experiment was conducted using the RANK database. This is the testing database of the Break Our Steganographic System! competition, formed by 1,000 images, which contain both samples from the BOSS database domain and others from a different domain. Hence, this experiment also exhibits the CSM problem. The results are shown in the first two rows of Table 2 for both the supervised approach and the proposed method. In this case the testing set was formed by 471 cover and 471 stego images. We can notice that the accuracy of the proposed method is, again, much higher than that of the supervised counterpart."}, {"heading": "4.2. Reduced and Unbalanced Number of Stego Samples", "text": "In this section, we illustrate a real-world situation of steganalysis, namely, the lack (or a reduced number) of stego samples in the testing set. Generally, communicating parties that use steganography do not embed information in many images. Therefore, we can probably find enough cover sources from these parties, but relatively fewer stego images.\nTo test this scenario, we carried out different experiments similar to those presented in the previous section, but using 125 cover images and only 50 stego images in the testing set. After that, other experiments were carried out using 125 cover and only 10 stego images. The tested steganographic systems were LSB matching with 0.25 and 0.10 bpp, and HUGO with 0.40 and 0.20 bpp.\nThe results for 50 stego images are shown in Table 3 for LSB matching and in Table 4 for HUGO. The results using 10 stego images are shown in Table 5 for LSB matching and in Table 6 for HUGO. These tables do not only show the classification accuracy (\u201cAcc\u201d), but also the details about true positives (\u201cTP\u201d), true negatives (\u201cTN\u201d), false positives (\u201cFP\u201d) and false negatives (\u201cFN\u201d). In both cases, we can see that the accuracy decreased compared to that obtained with a greater number of stego samples, but a remarkable level of detection was still achieved. For example, using the BOSS database and LSB matching with a 0.10 bpp bit rate, we obtained a classification accuracy of 94% when the number of stego and cover images was the same (as shown in Table 1). When we used only 50 stego images, the accuracy decreased to 78%. Finally, when we used only 10 stego images, the accuracy was further reduced to 70%. Although the accuracy decreased, a remarkable level of detection was achieved even for only 10 stego images. In particular, we notice that the number of true positives was very high with LSB matching for both cases (10 and 50 stego images), and still quite acceptable for HUGO steganography with 50 stego images. This means that\na stego image was very likely to be detected (and further analysis might be carried out to discard false positives).\nThe worst situation for the proposed system came out when the number of stego images was reduced to 10. In this case, the results obtained with the supervised approach were better than those of the proposed method when no CSM occurs (the first row of Tables 5 and 6). In case of CSM (the other rows), the proposed system provided better results than the supervised method for some testing databases and worse results for others. This illustrates that the performance of the proposed system decreases when the ratio between the number of stego images and the total number of testing images is very small. This situation is further analysed by means of other experiments in this section.\nWe also performed an experiment using the RANK database with two different ratios between cover and stego images: 70%/30% (471/202) and 90%/10% (471/52). The results, shown in Table 2, illustrate that the proposed method provided excellent detection accuracy (greater than or equal to 80%) for these cases. This shows that the accuracy is still high for unbalanced testing sets. The next experiment was performed in order to determine the threshold to obtain convenient detection results (classification accuracy) with the proposed approach as the ratio between stego and cover images is considered.\nSince the classification accuracy seems to decrease when we have an unbalanced testing set, considering the relative number of cover and stego images, we carried out the next family of experiments to investigate how the proposed method behaved with different ratios of stego images. In Table 7, the detection accuracy obtained with an increasing ratio of stego images is shown for a testing set taken from the BOSS database embedded using HUGO with 0.40 bpp. We began with a testing database of 125 cover and 0 stego images (125/0) and, in each step, we removed five cover and added five stego images, until a testing set of 0 cover and 125 stego images (0/125) was formed for the last experiment. We can see that the proposed ATS method provided convenient results (accuracy over 70%) when the ratio of cover and stego images was roughly between 10% and 95%. The accuracy decreased when either the number of stego or cover images was very small (less than 10% of stego images or less than 5% of cover images). A particularly difficult situation occurred when the testing set was formed exclusively by cover images. Even in that case, the proposed approach tried to separate the testing set into cover and stego images, leading to poor classification results (only 26% of the testing images were correctly classified as cover images). This situation shall be prevented, since testing sets formed only by cover images can be very usual in realworld scenarios. This problem shall be addressed in the future research to avoid such a high level of false positives.\nAnother interesting real-world scenario comes along when the total number of testing images is very small. This situation may occur, for example, when only a few images are found in a USB stick and they have to be evaluated by a steganalyst. In order to test this scenario, we carried out a set of experiments using very small sets (with only 20, 15, 10 and 8 images) with variable cover/stego ratios. In Table 8, the results obtained with 1) ten cover and ten stego images, and 2) five cover and five stego images, are shown. Similarly, in Table 9, we can see the results obtained with 1) five cover and ten stego images, and 2) ten cover and five stego images. Finally, Table 10, shows the results obtained with 1) five\ncover and three stego images, and 2) three cover and five stego images. The algorithms and embedding bit rates used in the experiments were LSBM with 0.25 bpp and HUGO with 0.40 bpp. The results shown in the tables are the average values obtained after repeating each experiment ten times with a different selection of images. Because of this, the true and false positive and negative values are not integers. It is worth pointing out that the results are remarkable even when the number of stego/cover images were 3/5 and 5/3, with detection accuracies close to or higher than 70%, except for the NRCS database. Taking into account the reduced size of these testing sets, we can conclude that the reliability of the proposed system is quite noteworthy."}, {"heading": "4.3. Testing Set from Mixed Databases", "text": "This section presents an even more challenging situation for the proposed steganalysis approach. In the next experiments, the images (both cover and stego) came from different databases with an uneven proportion. The mixed data set was formed by 280 images as follows: 70 images from BOSS, 60 images from INTE, 50 images from CALP, 40 images from ESO, 30 images form ALBN, 20 images from NOAA and ten images from NRCS. Then, we selected 140 of these images as cover and the other 140 images as stego, randomly. After that, we embedded a message in the 140 images selected as stego using LSB matching with an embedding bit rate of 0.10 bpp, and removed the corresponding original (cover) images from the testing set. We can see the results after applying the proposed steganalysis method in the first row of Table 11, which shows that the classification accuracy is still quite large (79%), despite the hostile scenario.\nAfter that, we applied the same procedure as above but using 50 stego images only (and a total of 190 images between cover and stego). In this case, the results obtained after applying the proposed steganalysis method are shown in the second row of Table 11. Since the images in the different databases have different sizes, we repeated the same experiment but with all the images clipped to 512 \u00d7 512 pixels, as shown in the last two rows of the table.\nWe can see that the only problem with the proposed approach was a relatively high number of false positives. However, even in this challenging situation, the accuracy of the suggested method was still above 70%. Again, the most remarkable property of these results is the ability of the method to provide a very large number of true positives. Note that using images with the same size the accuracy increases about 10 percentage points for the proposed method and 20 percentage points for the supervised approach. In any case, the best classification results are always those provided by the proposed method.\nOn the other hand, the supervised approach, trained with the BOSS database consisting of 19,000 images, does not yield good classification results, probably due to the CSM problem. Since the other databases do not have that many images, including them in the training set would not be a convenient strategy, since the training set would be unbalanced (it would contain many more images from BOSS than from the other databases). Nevertheless, there are some techniques in the state of the art that allow to deal with the CSM problem with supervised classification, such as the methods of (Pasquet et al., 2014), in which a clustering\napproach is used, and (Lubenko and Ker, 2012), in which millions of images are used for training."}, {"heading": "4.4. Testing Set with Mixed Embedding Bit Rates", "text": "As detailed in Sections 2 and 3, the proposed approach requires using the targeted steganographic system as a splitting function with approximately the same embedding bit rate. The experiment presented in this section uses three of the selected databases and the stego images were generated with the same steganographic method (LSB matching) but with five different embedding bit rates: 0.25, 0.20, 0.15, 0.10 and 0.05 bpp. We took 250 images for the testing set: 125 cover images (without any change) and 125 stego images obtained using the embedding method and one of the five possible embedding bit rates. Once embedded, the original sources were removed from the testing set. The stego image set was thus formed by 25 images for each embedding bit rate.\nThe main difficulty with addressing this steganalysis problem is the fact that we do not know the embedding bit rate. Even worse, the embedding bit rate is different for different images in the stego set. However, the suggested approach requires a splitting function that is approximately the same that the targeted steganographic method. Thus, we need to choose an appropriate splitting function.\nIt can be easily understood (from the analysis presented in Section 3) that using LSB matching with a low embedding bit rate will not conveniently separate the testing set. A stego image with a 0.10 bpp embedding bit rate would have 10% of pixels selected for embedding and, on average, half of them (a 5% of the total) would be modified compared to the corresponding cover image (the other half will already have the correct value in the LSB). If this stego image is embedded again, with an embedding bit rate of 0.10 bpp, the number of modified pixels with respect to the corresponding cover image would be, approximately, 5% (already modified) + 95% \u00b7 5% (modified by the second embedding) = 9.75%. This number is not exact, since some already modified pixels could be reverted to the original value in the second embedding, but it suffices to illustrate the problem. Similarly, the number of pixels modified for a cover image embedded with 0.20 bpp is 10% on average. The \u201cdouble stego\u201d image (embedded with 0.10 bpp twice) will have differences of up to \u00b12 for a few pixels (about a 0.25% of them), whereas a 9.5% of them will have differences of \u00b11 compared to the cover image. Hence, it would be very difficult to separate \u201cdouble stego\u201d images with 0.10 bpp from stego images with 0.20 bpp. This means that the condition X \u2032 \u2229 s[X \u2032] = \u2205 would not be satisfied.\nOn the other hand, a too large embedding rate, e.g. 0.50 bpp, would make it difficult to separate the 0.05 bpp stego images from the cover images: a 0.05 bpp stego image embedded again with a 0.50 bpp bit rate would modify approximately 2.5% + 97.5% \u00b7 25% = 26.875% of pixels on average, compared to the corresponding cover image, most of them with a difference of \u00b11, whereas a cover image embedded with a 0.50 bpp bit rate modifies 25% of the pixels, on average, with a difference of \u00b11.\nHence, the selection of the appropriate embedding bit rate for the splitting function in this situation is critical. To overcome this difficulty, for this particular experiment, we used\nLSB matching with 0.25 bpp as a splitting function to check if the separation property could still be achieved.\nThe results, shown in Table 12, illustrate that this approach leads to excellent classification results, greater than 85% in accuracy, for three different databases. For the supervised method, we used a training set formed with 9,500 cover images, and 5 \u00b7 9,500 = 47,500 stego images, since we embedded the chosen images once for each tested embedding bit rate (i.e. 0.25, 0.20, 0.15, 0.10 and 0.05 bpp). The training was carried out with the BOSS database and, hence, the results of the last two rows of the table also exhibit the CSM problem. It must be pointed out that, although the training set contained stego images embedded with all the tested bit rates, the supervised approach could not classify the testing set even when there was no CSM problem (first row).\nThis experiment shows that the proposed method can still be applied even if we do not know the exact embedding bit rate of the targeted steganographic system. However, a method for selecting the optimal embedding bit rate for the splitting function is required and must be addressed in the future research."}, {"heading": "4.5. Testing Set with Unknown Message Length", "text": "The usual scenario in steganography assumes, by the Kerckhoffs\u2019 principle, that the steganalyst knows all details about the steganographic channel except the secret keys. However, in a real-world scenario, some details, such as the embedding bit rate, are rarely known. This problem is often referred to as detecting messages of unknown length (Pevny\u0301, 2011).\nIn the state of the art, there are quantitative steganalyzers that try to discover the embedding bit rate. In (Pevny\u0301, 2011) and (Kodovsky\u0301 and Fridrich, 2013), the authors use a regression algorithm for obtaining a mapping F : F 7\u2192 P \u2286 R, where F \u2261 Rn is a feature space representation of images and P is a compact subset representing the space of embedding bit rates. Unfortunately, there is not a direct way of applying this framework in the proposed method. The suggested system is unsupervised and there is no training set with which we can train the regression algorithm. Despite that, in this section, we present some experiments about how to deal with a testing set of images for which the embedding bit rate is not fully known, which is a challenging situation for the proposed system. Below, we propose a methodology based on the measure of distance between the centroids of the different classes.\nAs a result of applying the proposed method (see Section 2 and Fig.1), we obtain a classification of B into stego and \u201cdouble stego\u201d images and, by the existing bijection between the elements of B and A, a classification of A into cover and stego images. Therefore, if the classification is successful, we expect that the elements of the stego part of A be similar to those of the stego part of B (see Fig.1d). Likewise, we expect that the elements of the cover part of A be dissimilar to those of the stego part of A (see Fig.1a). To exploit this idea, we can calculate the centroid of the cover part of A, namely CAcover , the centroid of the stego part of A, namely CAstego , and the centroid of the stego part of B, namely CBstego , and compute the distances between them: d(CAstego , CBstego) and d(CAcover , CAstego). This computation\ncan be carried out using a standard distance measure d, such as the Euclidean distance:\nd(x, y) = \u221a\u221a\u221a\u221a n\u2211 i=0 (xi \u2212 yi)2.\nWe expect short distances for d(CAstego , CBstego), because they are similar, and large distances for d(CAcover , CAstego), since they are dissimilar. Then, we can compute a score value S as follows:\nS = d(CAstego , CBstego)\nd(CAcover , CAstego) .\nThis value will be small when the classification is correct, that is, when we have managed to guess the correct algorithm and embedding bit rate. Therefore, the steganalyst can select a list of tentative bit rates and try them sequentially. The bit rate that provides the lowest score will most possibly be the right one (or close to it).\nAlthough there are several open questions with respect to this methodology, which shall be addressed in the future research, some results are shown in Table 13. These experiments were performed using 200 images of the BOSS database, 100 of which were cover and 100 stego. Some tests were also carried out with only cover images. In that case, we only used 100 images in the testing set. The distances were calculated using 50 features, selected from the best F -values of an ANOVA test. The details of the different experiments are discussed below.\nWe carried out experiments with an unknown message length for three different steganographic algorithms: LSB matching, HUGO and WOW, with an embedding bit rate of 0.40 bpp in all cases. The steganalyst needed to find out what the real embedding bit rate was and, for this purpose, he/she prepared a list of tentative bit rates, namely 0.10, 0.20, 0.30, 0.40, 0.50 and 0.60 bpp. The procedure is straightforward: the steganalyst only had to apply the proposed method one time for each tentative bit rate and keep the results with lowest score. As shown Table 13, in all three cases, the lowest score indicated the correct bitrate."}, {"heading": "4.6. Real-time Construction of the Testing Set", "text": "Another relevant scenario to consider for the proposed scheme is how to proceed when we do not have access to the whole set of images (formed with stego and cover samples) at the same time. This can be the typical situation that arises when we are eavesdropping the communications between two (or more) parties. If these parties exchange a few images (or even one image) from time to time, it is not possible to run the proposed classification method with the complete set of images, as shown in the previous sections.\nIn this case, the testing set A will be built dynamically. To deal with this realistic scenario, we propose the following procedure:\n1. Collect the images of the testing set A one by one until |A| \u2265 nmin, where nmin is a minimum number of images required to apply the method. Hence, the set A = {I1, I2, . . . , Inmin} is built, where Ij stands for the image obtained at the j-th iteration.\n2. Classify the set A into cover (V ) and stego (W ) images applying the proposed method. Output the label of each image (\u201ccover\u201d or \u201cstego\u201d). 3. When a new image Ik is obtained, add the new image into the set A := A\u222a {Ik}, and repeat Step 2.\nAs shown in Section 4.2, nmin can be very small and still provide remarkable detection accuracy. In the experiments presented below, the value nmin = 10 has been used.\nAlthough the strategy of repeating the classification with the whole set may appear simplistic, in fact, it is the best option from the accuracy point of view. As shown below by means of several experiments, the classification accuracy increases with the number of classified images. Hence, when a new image is obtained, it is better to classify the whole set of images again and output the result of the last classification. Needless to say, this strategy also requires more computational effort. Accuracy is thus obtained in exchange for computational cost. We consider this strategy realistic, since the classification of even hundreds of images can be carried out in just a few minutes with standard hardware. If reduced computation time is a strong requirement in a real-time implementation of the scheme, accuracy can be sacrificed by selecting a subset of the collected images for each classification.\nIn addition, this re-classification of the whole testing set each time a new image is obtained produces a side effect: for each image, we do not only have the last classification result (as \u201ccover\u201d or \u201cstego\u201d) but also the results obtained in all the previous classifications (iterations). In fact, assuming that we obtain the images one by one, if n = |A| is the current number of images (i.e., In is the last image that has been included into the set A), we have the following number of classification results (labels), nl, per each image:\nnl(Ik) = { max(0, n\u2212 nmin + 1), if k \u2264 nmin, max(0, n\u2212 k + 1), otherwise.\nNow, we can compute ml(Ik) as the number of times that each image has been classified with the same label as in the last classification experiment. In the best case for classification \u201cconfidence\u201d, we will have ml(Ik) = nl(Ik), that is, the image Ik has been classified with the same label in all the iterations. In the worst case, we will have ml(Ik) = 1, meaning that the previous nl(Ik)\u22121 classification experiments yielded the opposite label compared to the current experiment. With these considerations, we can define a simple \u201cconfidence level\u201d for the classification result of each image:\nc(Ik) = ml(Ik)\nnl(Ik) , if nl(Ik) > 0. (1)\nThe value of the confidence level provided in Equation 1 satisfies c(Ik) \u2208 (0, 1]. The closer c(Ik) to 1, the more confident we can be about the classification of Ik and, conversely, the closer c(Ik) to 0, the less confident we can be about the label assigned to that image. One of the advantages of such a measurement is that it can be computed without knowledge of the true category of each image. The confidence level of the classification of an image Ik always begins with c(Ik) = 1 the first time it is classified, and it will typically have a\nlower value as it is re-classified each time a new image is included into the set A. The values provided by this indicator are also analysed in the experiments below.\nThe first experiment to test this scenario was simulated taking 155 images, 124 of which were cover and the remaining 31 have been embedded using HUGO steganography with 0.40 bpp (i.e. 20% of the images were stego). At each iteration, a random image was selected from the set and added into A. As remarked above, we set nmin = 10. Hence, the first classification experiment was carried out when the 10-th image was selected. The results, in terms of average classification accuracy and average confidence level are shown in Fig.3a, using a solid line for accuracy and a dashed one for confidence. At each iteration, the average accuracy and the average confidence were computed for the set of available images. As accuracy is concerned, the classification results with a few images (approximately less\nthan 50) were low, but when the number of images reaches this threshold, the accuracy increased, reaching a 70% (0.7) in the last iteration. On the other hand, the confidence, started from a high value, showed a significant decrease in the first few iterations and at some iteration (again about 50 images) started a quite regular increase. We can also observe a strong correlation between both curves, specially when the number of collected images was significant enough. This situation is really remarkable, since in a real experiment we would not know the real accuracy, but we would be able to compute the confidence measurement, since it only depends on the past classification results. When the confidence reaches a \u201csteady state\u201d behavior, the same occurs with the accuracy. Hence, this provides with a strong indicator of the quality of the classification results.\nThe same procedure was applied for other testing sets of images. Fig.3b shows the results obtained with 150 images, 105 of which were cover and the remaining 45 stego (i.e. 30% of stego images). The behavior of both variables was similar to that of the previous experiment, but the threshold in the number of images required for a high accuracy and confidence was lower (about 30 images). In this case, the final accuracy was also higher, about 80% (0.8).\nFig. 3c provides the results obtained for 250 images, 125 of which were stego (i.e. 50% of stego images). The situation was similar to that of the previous two experiments. From a certain iteration (again about 30 images) the accuracy and confidence curves showed a more regular behavior, mostly increasing. In this case, the final accuracy was higher, close to 90% (0.9), due to the larger number of images in the final testing set (250 images, compared to 155 for the first experiment and 150 for the second one).\nThe correlation between accuracy and confidence could also be observed for the iterations in which there was a sudden variation in both variables. When accuracy shows a sudden increase or decrease, a similar situation occurs with confidence, but the increase or decrease was sometimes reversed compared to accuracy. There is a simple explanation for this situation. A large variation in confidence means that many images changed their label at that iteration. This change of label could be right, leading to an increased accuracy, or wrong, leading to a decrease in accuracy. Only occasionally, these variations were compensated as right and wrong classification results (leading to small variations in accuracy). It can also be observed that the higher the number of images, the more likely the variations in accuracy and confidence had the same sign. This explains the strong positive correlation between both curves when the number of images reaches a minimum threshold (about 30-50).\nThe results shown in Figs.3a-3c provide only one simulation in each case. Such a simulated experiment tries to reproduce the situation that we would find in a real-life experiment, i.e. the images would be obtained one by one, or in a small number at each iteration. However, the results obtained in this way can be biased due to the generation of the pseudorandom numbers used to select the image order. In order to avoid this bias, we carried out 100 simulations with the same set of 105 cover and 45 stego images, but using a different seed for the pseudo-random selection (ordering) of the images at each simulation. Fig.3d shows the averaged results of these 100 simulations for both accuracy and confidence (please note the scale change in the vertical axis with respect to the other three cases). In this figure, we can notice that accuracy became a much \u201csofter\u201d curve, starting from low values (about 55%) and reaching high accuracy (over 80%) for the complete set. The increase in accuracy\nis almost monotonic, and the oscillations were almost suppressed by averaging the results of 100 experiments. In addition, we can also observe the same \u201csofter\u201d shape of the confidence measurement. The correlation between accuracy and confidence when the number of images was larger than 30 was almost perfect. Both curves increased approximately linearly, with roughly the same slope.\nThese experiments suggest that using all the available images increases the accuracy and justifies the method proposed for a real-time implementation of our scheme. No accuracy gain can be expected, a priori, from discarding some images from the testing set.\nIt must be taken into account that if the ratio of stego images varies too much in realtime, the value of accuracy may not increase as regularly as shown in Fig.3. As discussed in Section 4.2, if the percentage of stego images is below 10% or above 95%, the detection accuracy results may decrease significantly. This situation may occur if, from some given moment, (nearly) only cover or (nearly) only stego images were obtained, leading to a very low or a very high percentage of stego images. This kind of scenario must be prevented to maintain the accuracy results in acceptable values."}, {"heading": "5. Conclusion", "text": "In this paper, a novel unsupervised steganalysis method is presented. We show how unsupervised steganalysis can be addressed by using an artificial training set and supervised classification if we know the algorithm and the embedding bit rate used for steganography. Hence, the suggested method is applicable in targeted steganalysis. Using the proposed approach, we can also bypass the CSM problem and outperform the state-of-the-art methods. Removing the necessity of a training data set in the machine learning problem is the major contribution of this paper.\nThe proposed approach has been tested using three steganographic methods: LSB matching, HUGO and WOW. It is shown that we can achieve better classification accuracy than that obtained using traditional supervised steganalysis (Rich Models, Ensemble Classifiers and SVM), while avoiding the CSM problem that makes the performance of supervised steganalysis decrease significantly.\nFurthermore, through the different experiments presented in the paper, we show that the proposed method can address complex real-world situations, in which we do not have a clear training database (e.g., when the images come from different databases), the number of stego images is reduced or the images are obtained one by one, in real time. We show that the suggested method provides remarkable performance even if the images are selected unevenly from different databases or if the embedding bit rate is unknown and variable for different stego samples.\nAs future work, it would be worth researching how the suggested method can be applied in situations for which we do not know the image database, the steganographic algorithm or the embedding bit rate used, as it would occur in real-world steganalysis. The experiments with images taken unevenly from different databases show some decrease in the accuracy results of the method. Besides, if the message length is unknown, the approaches presented in the paper shall be analyzed more deeply, though the preliminary results are promising.\nSimilarly, the case when the testing set is formed only by cover images needs be specifically addressed to avoid a large number of false positives. In addition, it would also be interesting to investigate how to proceed when we cannot estimate the splitting function, e.g. when we deal with a novel and unknown steganographic scheme. This would mean porting the proposed approach to the problem of universal steganalysis.\nFinally, we propose to investigate the application of this approach in other fields, beyond steganalysis, with similar properties. The idea behind the proposed method could be exploited whenever a splitting function can be defined in a machine learning classification problem."}, {"heading": "Acknowledgment", "text": "This work was partly funded by the Spanish Government through grants TIN2011-27076C03-02 \u201cCO-PRIVACY\u201d and TIN2014-57364-C2-2-R \u201cSMARTGLACIS\u201d."}], "references": [{"title": "break our steganographic system\u201d: The ins and outs of organizing boss", "author": ["P. Bas", "T. Filler", "T. Pevn\u00fd"], "venue": "Proceedings of the 13th International Conference on Information Hiding", "citeRegEx": "Bas et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Bas et al\\.", "year": 2011}, {"title": "Pattern Recognition and Machine Learning", "author": ["C.M. Bishop"], "venue": "Information Science and Statistics Series. Springer", "citeRegEx": "Bishop,? \\Q2006\\E", "shortCiteRegEx": "Bishop", "year": 2006}, {"title": "Regents of the University of California, Berkeley. Available: http://calphotos.berkeley", "author": ["CALP", "n.d"], "venue": "edu/, accessed on May", "citeRegEx": "CALP and n.d.,? \\Q2016\\E", "shortCiteRegEx": "CALP and n.d.", "year": 2016}, {"title": "A Comparative Study of \u00b11 Steganalyzers", "author": ["G. Cancelli", "G. Do\u00ebrr", "M. Barni", "I.J. Cox"], "venue": "Multimedia Signal Processing,", "citeRegEx": "Cancelli et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Cancelli et al\\.", "year": 2008}, {"title": "Steganalysis by Ensemble Classifiers with Boosting by Regression, and Post-Selection of Features", "author": ["M. Chaumont", "S. Kouider"], "venue": "Image Processing (ICIP),", "citeRegEx": "Chaumont and Kouider,? \\Q2012\\E", "shortCiteRegEx": "Chaumont and Kouider", "year": 2012}, {"title": "Break our Steganographic System (BOSS)", "author": ["T. Filler", "T. Pevn\u00fd", "P. Bas"], "venue": "http://exile.felk.cvut. cz/boss/, accessed on September", "citeRegEx": "Filler et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Filler et al\\.", "year": 2010}, {"title": "Rich Models for Steganalysis of Digital Images", "author": ["J. Fridrich", "J. Kodovsk\u00fd"], "venue": "IEEE Trans. Information Forensics and Security", "citeRegEx": "Fridrich and Kodovsk\u00fd,? \\Q2012\\E", "shortCiteRegEx": "Fridrich and Kodovsk\u00fd", "year": 2012}, {"title": "Breaking HUGO: The Process Discovery", "author": ["J. Fridrich", "J. Kodovsk\u00fd", "V. Holub", "M. Goljan"], "venue": "Proceedings of the 13th International Conference on Information Hiding", "citeRegEx": "Fridrich et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Fridrich et al\\.", "year": 2011}, {"title": "A New Methodology in Steganalysis : Breaking Highly Undetectable Steganography (HUGO)", "author": ["G. Gul", "F. Kurugollu"], "venue": "Proceedings of the 13th International Conference on Information Hiding", "citeRegEx": "Gul and Kurugollu,? \\Q2011\\E", "shortCiteRegEx": "Gul and Kurugollu", "year": 2011}, {"title": "Designing Steganographic Distortion Using Directional Filters", "author": ["V. Holub", "J.J. Fridrich"], "venue": "In: International Workshop on Information Forensics and Security (WIFS)", "citeRegEx": "Holub and Fridrich,? \\Q2012\\E", "shortCiteRegEx": "Holub and Fridrich", "year": 2012}, {"title": "A Practical Guide to Support Vector Classification", "author": ["Hsu", "C.-W", "Chang", "C.-C", "Lin", "C.-J"], "venue": "Tech. rep., Department of Computer Science, National Taiwan University, accessed on May", "citeRegEx": "Hsu et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Hsu et al\\.", "year": 2003}, {"title": "A novel fuzzy logic-based image steganography method to ensure medical data security", "author": ["R. Karaki\u015f", "I. G\u00fcller", "I. \u00c7apraz", "E. Bilir"], "venue": "Computers in Biology and Medicine", "citeRegEx": "Karaki\u015f et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Karaki\u015f et al\\.", "year": 2015}, {"title": "Moving Steganography and Steganalysis from the Laboratory into the Real World", "author": ["A.D. Ker", "P. Bas", "R. B\u00f6hme", "R. Cogranne", "S. Craver", "T. Filler", "J. Fridrich", "T. Pevn\u00fd"], "venue": "Proceedings of the First ACM Workshop on Information Hiding and Multimedia Security", "citeRegEx": "Ker et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Ker et al\\.", "year": 2013}, {"title": "A Mishmash of Methods for Mitigating the Model Mismatch Mess", "author": ["A.D. Ker", "T. Pevn\u00fd"], "venue": "Proceedings of SPIE - The International Society for Optical Engineering\u201d", "citeRegEx": "Ker and Pevn\u00fd,? \\Q2014\\E", "shortCiteRegEx": "Ker and Pevn\u00fd", "year": 2014}, {"title": "Quantitative Steganalysis Using Rich Models", "author": ["J. Kodovsk\u00fd", "J. Fridrich"], "venue": "Proceedings of SPIE - The International Society for Optical Engineering\u201d", "citeRegEx": "Kodovsk\u00fd and Fridrich,? \\Q2013\\E", "shortCiteRegEx": "Kodovsk\u00fd and Fridrich", "year": 2013}, {"title": "On Dangers of Overtraining Steganography to Incomplete Cover Model", "author": ["J. Kodovsk\u00fd", "J. Fridrich", "V. Holub"], "venue": "Proceedings of the Thirteenth ACM Multimedia Workshop on Multimedia and Security. MM&Sec \u201911", "citeRegEx": "Kodovsk\u00fd et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Kodovsk\u00fd et al\\.", "year": 2011}, {"title": "Ensemble Classifiers for Steganalysis of Digital Media", "author": ["J. Kodovsk\u00fd", "J.J. Fridrich", "V. Holub"], "venue": "IEEE Transactions on Information Forensics and Security", "citeRegEx": "Kodovsk\u00fd et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Kodovsk\u00fd et al\\.", "year": 2012}, {"title": "Study of Cover Source Mismatch in Steganalysis and Ways to Mitigate its Impact", "author": ["J. Kodovsk\u00fd", "V. Sedighi", "J. Fridrich"], "venue": "Proceedings of SPIE - The International Society for Optical Engineering\u201d", "citeRegEx": "Kodovsk\u00fd et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Kodovsk\u00fd et al\\.", "year": 2014}, {"title": "Adaptive steganography by oracle (ASO)", "author": ["S. Kouider", "M. Chaumont", "W. Puech"], "venue": "In: International Conference on Multimedia and Expo (ICME)", "citeRegEx": "Kouider et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Kouider et al\\.", "year": 2013}, {"title": "Going from Small to Large Data in Steganalysis", "author": ["I. Lubenko", "A.D. Ker"], "venue": "Media Watermarking, Security, and Forensics 2012. Vol. 8303 of Proceedings of SPIE - The International Society for Optical Engineering. pp. 0M01\u20130M10", "citeRegEx": "Lubenko and Ker,? \\Q2012\\E", "shortCiteRegEx": "Lubenko and Ker", "year": 2012}, {"title": "LSB Matching Revisited", "author": ["J. Mielik\u00e4inen"], "venue": "Signal Processing Letters", "citeRegEx": "Mielik\u00e4inen,? \\Q2006\\E", "shortCiteRegEx": "Mielik\u00e4inen", "year": 2006}, {"title": "National Oceanic and Atmospheric Administration (NOAA)", "author": ["NOAA", "n.d"], "venue": "Available: http://www. photolib.noaa.gov/, accessed on May", "citeRegEx": "NOAA and n.d.,? \\Q2016\\E", "shortCiteRegEx": "NOAA and n.d.", "year": 2016}, {"title": "National Resource Conservation System (NRCS) Photo Gallery", "author": ["NRCS", "n.d"], "venue": "Available: http:// photogallery.nrcs.usda.gov/res/sites/photogallery/, accessed on May", "citeRegEx": "NRCS and n.d.,? \\Q2016\\E", "shortCiteRegEx": "NRCS and n.d.", "year": 2016}, {"title": "Steganalysis with Cover-Source Mismatch and a Small Learning Database", "author": ["J. Pasquet", "S. Bringay", "M. Chaumont"], "venue": "Signal Processing Conference (EUSIPCO),", "citeRegEx": "Pasquet et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Pasquet et al\\.", "year": 2014}, {"title": "Detecting Messages of Unknown Length", "author": ["T. Pevn\u00fd"], "venue": "Proceedings of SPIE - The International Society for Optical Engineering\u201d", "citeRegEx": "Pevn\u00fd,? \\Q2011\\E", "shortCiteRegEx": "Pevn\u00fd", "year": 2011}, {"title": "Steganalysis by Subtractive Pixel Adjacency Matrix", "author": ["T. Pevn\u00fd", "P. Bas", "J.J. Fridrich"], "venue": "IEEE Transactions on Information Forensics and Security", "citeRegEx": "Pevn\u00fd et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Pevn\u00fd et al\\.", "year": 2010}, {"title": "Using High-Dimensional Image Models to Perform Highly Undetectable Steganography", "author": ["T. Pevn\u00fd", "T. Filler", "P. Bas"], "venue": "Information Hiding - 12th International Conference", "citeRegEx": "Pevn\u00fd et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Pevn\u00fd et al\\.", "year": 2010}, {"title": "The Challenges of Rich Features in Universal Steganalysis", "author": ["T. Pevn\u00fd", "A.D. Ker"], "venue": "Proceedings of SPIE - The International Society for Optical Engineering 8665,", "citeRegEx": "Pevn\u00fd and Ker,? \\Q2013\\E", "shortCiteRegEx": "Pevn\u00fd and Ker", "year": 2013}], "referenceMentions": [{"referenceID": 6, "context": "Many of the image steganalysis methods in the state of the art (Pevn\u00fd et al., 2010a; Fridrich and Kodovsk\u00fd, 2012) use feature-based steganalysis and machine learning classification.", "startOffset": 63, "endOffset": 113}, {"referenceID": 1, "context": "Machine learning (Mitchell, 1997; Bishop, 2006) literature refers to this problem as domain adaptation, whereas the term used to refer to this situation in steganalysis is cover source mismatch (CSM).", "startOffset": 17, "endOffset": 47}, {"referenceID": 12, "context": "This constitutes an important open problem in the field (Ker et al., 2013), which was initially reported in (Cancelli et al.", "startOffset": 56, "endOffset": 74}, {"referenceID": 3, "context": ", 2013), which was initially reported in (Cancelli et al., 2008).", "startOffset": 41, "endOffset": 64}, {"referenceID": 5, "context": "In the BOSS competition (Filler et al., 2010), the BOSSrank database (which suffers from CSM) had to be used as a testing set.", "startOffset": 24, "endOffset": 45}, {"referenceID": 8, "context": "Some participants of the competition tried to include the testing set images in the training set (Gul and Kurugollu, 2011; Fridrich et al., 2011).", "startOffset": 97, "endOffset": 145}, {"referenceID": 7, "context": "Some participants of the competition tried to include the testing set images in the training set (Gul and Kurugollu, 2011; Fridrich et al., 2011).", "startOffset": 97, "endOffset": 145}, {"referenceID": 7, "context": "This idea was called \u201ctraining on a contaminated database\u201d (Fridrich et al., 2011).", "startOffset": 59, "endOffset": 82}, {"referenceID": 19, "context": "In 2012, a solution based on training a classifier with a huge variety of images was proposed (Lubenko and Ker, 2012).", "startOffset": 94, "endOffset": 117}, {"referenceID": 27, "context": "Later on, in 2013, the use of rich features in universal steganalysis was analyzed (Pevn\u00fd and Ker, 2013).", "startOffset": 83, "endOffset": 104}, {"referenceID": 1, "context": "Machine learning (Mitchell, 1997; Bishop, 2006) literature refers to this problem as domain adaptation, whereas the term used to refer to this situation in steganalysis is cover source mismatch (CSM). This constitutes an important open problem in the field (Ker et al., 2013), which was initially reported in (Cancelli et al., 2008). Several approaches to deal with the CSM problem have been proposed in the recent years. In the BOSS competition (Filler et al., 2010), the BOSSrank database (which suffers from CSM) had to be used as a testing set. Some participants of the competition tried to include the testing set images in the training set (Gul and Kurugollu, 2011; Fridrich et al., 2011). This idea was called \u201ctraining on a contaminated database\u201d (Fridrich et al., 2011). This approach consists in applying denoising algorithms to estimate the cover sources of the testing set and using these estimated covers to generate new stego samples, by embedding new information into them. After that, these new estimated cover and stego samples are included in the training set. In 2012, a solution based on training a classifier with a huge variety of images was proposed (Lubenko and Ker, 2012). This approach consists in applying machine learning to millions of images. Due to the high time and memory requests, this step is performed using on-line classifiers. Later on, in 2013, the use of rich features in universal steganalysis was analyzed (Pevn\u00fd and Ker, 2013). Since rich features are not sensitive enough for their application in universal steganalysis, the authors apply linear projections informed by embedding methods and an anomaly detector. This approach tries to make these projections sensitive to stego content and, at the same time, insensitive to cover variation. In 2014, different methods to deal with CSM were presented. Ker and Pevn\u00fd (2014) show the possibility of centering features when there is a shift in the cover sources, by subtracting an estimated centroid of the cover features.", "startOffset": 34, "endOffset": 1866}, {"referenceID": 1, "context": "Machine learning (Mitchell, 1997; Bishop, 2006) literature refers to this problem as domain adaptation, whereas the term used to refer to this situation in steganalysis is cover source mismatch (CSM). This constitutes an important open problem in the field (Ker et al., 2013), which was initially reported in (Cancelli et al., 2008). Several approaches to deal with the CSM problem have been proposed in the recent years. In the BOSS competition (Filler et al., 2010), the BOSSrank database (which suffers from CSM) had to be used as a testing set. Some participants of the competition tried to include the testing set images in the training set (Gul and Kurugollu, 2011; Fridrich et al., 2011). This idea was called \u201ctraining on a contaminated database\u201d (Fridrich et al., 2011). This approach consists in applying denoising algorithms to estimate the cover sources of the testing set and using these estimated covers to generate new stego samples, by embedding new information into them. After that, these new estimated cover and stego samples are included in the training set. In 2012, a solution based on training a classifier with a huge variety of images was proposed (Lubenko and Ker, 2012). This approach consists in applying machine learning to millions of images. Due to the high time and memory requests, this step is performed using on-line classifiers. Later on, in 2013, the use of rich features in universal steganalysis was analyzed (Pevn\u00fd and Ker, 2013). Since rich features are not sensitive enough for their application in universal steganalysis, the authors apply linear projections informed by embedding methods and an anomaly detector. This approach tries to make these projections sensitive to stego content and, at the same time, insensitive to cover variation. In 2014, different methods to deal with CSM were presented. Ker and Pevn\u00fd (2014) show the possibility of centering features when there is a shift in the cover sources, by subtracting an estimated centroid of the cover features. Ker and Pevn\u00fd also use weighted ensemble methods to deal with situations in which the features are moving in different directions after embedding. Kodovsk\u00fd et al. (2014) present three different strategies to deal with CSM.", "startOffset": 34, "endOffset": 2183}, {"referenceID": 4, "context": "In 2014, another approach, based on Ensemble Classifiers with Feature Selection (EC-FS) (Chaumont and Kouider, 2012), was proposed by Pasquet et al.", "startOffset": 88, "endOffset": 116}, {"referenceID": 20, "context": "In this paper, we provide results for three different steganographic methods, namely, Least Significant Bit (LSB) matching (LSB matching) (Mielik\u00e4inen, 2006), Highly undetectable steganography (HUGO) (Pevn\u00fd et al.", "startOffset": 138, "endOffset": 157}, {"referenceID": 9, "context": ", 2010b) and Wavelet Obtained Weights (WOW) (Holub and Fridrich, 2012).", "startOffset": 44, "endOffset": 70}, {"referenceID": 4, "context": "In 2014, another approach, based on Ensemble Classifiers with Feature Selection (EC-FS) (Chaumont and Kouider, 2012), was proposed by Pasquet et al. (2014). In this new method, Pasquet et al.", "startOffset": 89, "endOffset": 156}, {"referenceID": 4, "context": "In 2014, another approach, based on Ensemble Classifiers with Feature Selection (EC-FS) (Chaumont and Kouider, 2012), was proposed by Pasquet et al. (2014). In this new method, Pasquet et al. use the EC-FS classifier with the Islet approach, a pre-processing step that consists in organizing images in clusters and assigning a steganalyzer to each cluster. Using this technique, a classifier can manage the diversity of the images more easily, after learning with a set of close feature vectors (in each cluster, the distance between the feature vectors is relatively small). This allows reducing the number of required images from millions to a few thousands. In this paper we present a new approach based on bypassing the CSM problem rather than addressing it. The proposed technique consists in creating an \u201cartificial\u201d training set from the testing set. This artificial training set is formed by applying the targeted steganographic algorithm to the testing data (the data set A) twice. If the testing set A is formed by stego and cover images, a first application of the steganographic algorithm results in a \u201ctransformed\u201d set B with \u201cdouble stego\u201d and stego images. The second application of the steganographic algorithm produces a \u201cdouble transformed\u201d set C that includes \u201ctriple stego\u201d and \u201cdouble stego\u201d images. We show how the sets A and C can be used as artificial training data to finally classify the set B into stego and \u201cdouble stego\u201d images. Since there is a bijection between the elements of A and B, this is equivalent to the classification of the images in A as cover or stego. The idea behind the proposal is that part of the images that we want to classify \u2013 the cover images\u2013 can be transformed into images that belong to the other class that we want to classify: the class of stego images. This fact is exploited to create an artificial training set that is used to find a boundary between classes with remarkable accuracy. This classification technique can thus have a relevant impact in the way in which steganalysis is usually approached, since it allows classifying the images without a real training set, which constitutes the direct cause of the CSM problem. In this paper, we provide results for three different steganographic methods, namely, Least Significant Bit (LSB) matching (LSB matching) (Mielik\u00e4inen, 2006), Highly undetectable steganography (HUGO) (Pevn\u00fd et al., 2010b) and Wavelet Obtained Weights (WOW) (Holub and Fridrich, 2012). Nevertheless, the proposed method is general and can be applied to any steganographic system, such as the more recent methods suggested by Karaki\u015f et al. (2015). The rest of this paper is organized as follows.", "startOffset": 89, "endOffset": 2634}, {"referenceID": 18, "context": "For example, the Adaptive Steganography by Oracle (ASO) embedding algorithm (Kouider et al., 2013) is particularly designed to enhance its undetectability with respect to the features used by Ensemble Classifiers as proposed in (Kodovsk\u00fd et al.", "startOffset": 76, "endOffset": 98}, {"referenceID": 16, "context": ", 2013) is particularly designed to enhance its undetectability with respect to the features used by Ensemble Classifiers as proposed in (Kodovsk\u00fd et al., 2012).", "startOffset": 137, "endOffset": 160}, {"referenceID": 5, "context": "\u2022 The BOSS database is the set of training images for the competition Break Our Steganographic System! (Filler et al., 2010).", "startOffset": 103, "endOffset": 124}, {"referenceID": 0, "context": "This database is formed by 10,000 cover images with a fixed size of 512 \u00d7 512 pixels, obtained with seven different cameras (Bas et al., 2011).", "startOffset": 124, "endOffset": 142}, {"referenceID": 15, "context": "However, after the competition, a weakness was found (Kodovsk\u00fd et al., 2011) in the creation of the stego set, which can be removed embedding with a different threshold (T = 255 instead of the default value T = 90 that was used in the BOSS challenge).", "startOffset": 53, "endOffset": 76}, {"referenceID": 5, "context": "\u2022 The RANK database (often referred to as BOSSrank) is the set of testing images from the competition Break Our Steganographic System! (Filler et al., 2010).", "startOffset": 135, "endOffset": 156}, {"referenceID": 0, "context": "847 of the RANK images were taken using one of the cameras used to generate the BOSS database, but the remaining 153 images were taken with a camera not included in the BOSS database (Bas et al., 2011).", "startOffset": 183, "endOffset": 201}, {"referenceID": 20, "context": "The steganographic algorithms used in the experiments are LSB matching (Mielik\u00e4inen, 2006), with embedding bit rates of 0.", "startOffset": 71, "endOffset": 90}, {"referenceID": 9, "context": "20 bpp, and WOW (Holub and Fridrich, 2012), with embedding bit rates of 0.", "startOffset": 16, "endOffset": 42}, {"referenceID": 6, "context": "The steganalysis approach taken in this paper stems from the well-known Rich Models framework (Fridrich and Kodovsk\u00fd, 2012), which proposes a feature extraction step using multiple submodels, and a classification step based on Ensemble Classifiers (Breiman, 2001; Kodovsk\u00fd et al.", "startOffset": 94, "endOffset": 123}, {"referenceID": 10, "context": "This process was carried out as described in (Hsu et al., 2003).", "startOffset": 45, "endOffset": 63}, {"referenceID": 9, "context": "20 bpp and WOW (Holub and Fridrich, 2012) with embedding bit rates of 0.", "startOffset": 15, "endOffset": 41}, {"referenceID": 23, "context": "Nevertheless, there are some techniques in the state of the art that allow to deal with the CSM problem with supervised classification, such as the methods of (Pasquet et al., 2014), in which a clustering", "startOffset": 159, "endOffset": 181}, {"referenceID": 19, "context": "approach is used, and (Lubenko and Ker, 2012), in which millions of images are used for training.", "startOffset": 22, "endOffset": 45}, {"referenceID": 24, "context": "This problem is often referred to as detecting messages of unknown length (Pevn\u00fd, 2011).", "startOffset": 74, "endOffset": 87}, {"referenceID": 24, "context": "In (Pevn\u00fd, 2011) and (Kodovsk\u00fd and Fridrich, 2013), the authors use a regression algorithm for obtaining a mapping F : F 7\u2192 P \u2286 R, where F \u2261 R is a feature space representation of images and P is a compact subset representing the space of embedding bit rates.", "startOffset": 3, "endOffset": 16}, {"referenceID": 14, "context": "In (Pevn\u00fd, 2011) and (Kodovsk\u00fd and Fridrich, 2013), the authors use a regression algorithm for obtaining a mapping F : F 7\u2192 P \u2286 R, where F \u2261 R is a feature space representation of images and P is a compact subset representing the space of embedding bit rates.", "startOffset": 21, "endOffset": 50}], "year": 2017, "abstractText": "In this paper, an unsupervised steganalysis method that combines artificial training sets and supervised classification is proposed. We provide a formal framework for unsupervised classification of stego and cover images in the typical situation of targeted steganalysis (i.e., for a known algorithm and approximate embedding bit rate). We also present a complete set of experiments using 1) eight different image databases, 2) image features based on Rich Models, and 3) three different embedding algorithms: Least Significant Bit (LSB) matching, Highly undetectable steganography (HUGO) and Wavelet Obtained Weights (WOW). We show that the experimental results outperform previous methods based on Rich Models in the majority of the tested cases. At the same time, the proposed approach bypasses the problem of Cover Source Mismatch \u2013when the embedding algorithm and bit rate are known\u2013 , since it removes the need of a training database when we have a large enough testing set. Furthermore, we provide a generic proof of the proposed framework in the machine learning context. Hence, the results of this paper could be extended to other classification problems similar to steganalysis.", "creator": "LaTeX with hyperref package"}}}