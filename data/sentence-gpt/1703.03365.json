{"id": "1703.03365", "review": {"conference": "nips", "VERSION": "v1", "DATE_OF_SUBMISSION": "9-Mar-2017", "title": "Learning Active Learning from Data", "abstract": "In this paper, we suggest a novel data-driven approach to active learning: Learning Active Learning (LAL). The key idea behind LAL is to train a regressor that predicts the expected error reduction for a potential sample in a particular learning state. By treating the query selection procedure as a regression problem we are not restricted to dealing with existing AL heuristics; instead, we learn strategies based on experience from previous active learning experiments. For example, using regression and a real-time model of the regression problem to model the LAL is likely to generate a correlation with the expected return from error (which would allow us to see the difference in the results of all data sets).\n\n\n\n\nThe training results are presented in a separate paper for LAL, which is presented in a section in the previous paper. The data presented here have been presented in a separate paper for LAL.\nTo gain further insight into the regression problem, we will use the following methods:\nTraining the data set\nWe will have to use the following methods to determine the LAL model (more details on the training method) to gain insight into how the models actually train. In most cases we will then train the LAL with the same training procedure as the original model in our current training procedure.\nTrain the LAL to a training program in real time.\nTrain the LAL to a training program in real time.\nTrain the LAL to a training program in real time.\nTraining the LAL to a training program in real time.\nTrain the LAL to a training program in real time.\nIn real time.\nThis process takes some time to gain insight into the data that makes the training procedure the most effective. For example, we can train the LAL to a training program in real time, and learn the LAL to a training program in real time. As we see here, the regression problem in the original training model is an issue due to the fact that we only learn the LAL for our training routine. As it should be, the model is not a regression problem.\nThe regression problem in the original training model is an issue because it contains an error correction error. This error is the result of an error correction error. The regression problem in the original training model is an error correction error. This error is the result of an error correction error. This error is the result of an error correction error. This error is the result of an error correction error.\nWe can use the following methods", "histories": [["v1", "Thu, 9 Mar 2017 17:36:52 GMT  (970kb,D)", "http://arxiv.org/abs/1703.03365v1", null], ["v2", "Fri, 31 Mar 2017 07:33:28 GMT  (973kb,D)", "http://arxiv.org/abs/1703.03365v2", null], ["v3", "Fri, 14 Jul 2017 12:59:12 GMT  (803kb,D)", "http://arxiv.org/abs/1703.03365v3", null]], "reviews": [], "SUBJECTS": "cs.LG", "authors": ["ksenia konyushkova", "raphael sznitman", "pascal fua"], "accepted": true, "id": "1703.03365"}, "pdf": {"name": "1703.03365.pdf", "metadata": {"source": "META", "title": "Learning Active Learning from Real and Synthetic Data", "authors": ["Ksenia Konyushkova", "Raphael Sznitman", "Pascal Fua"], "emails": ["KSENIA.KONYUSHKOVA@EPFL.CH", "RAPHAEL.SZNITMAN@ARTORG.UNIBE.CH", "PASCAL.FUA@EPFL.CH"], "sections": [{"heading": "1. Introduction", "text": "Many modern machine learning techniques require large amounts of training data to reach their full potential. However, annotated data is hard and expensive to obtain, especially in specialized domains where only experts whose time is scarce and precious can provide reliable annotations. Active learning (AL) is an established way to ease the data collection process by automatically deciding which instances an annotator should label to train an algorithm as quickly as possible and with the minimal amount of annotation effort.\nOver the years many AL strategies have been developed for various tasks, without any one of them clearly outperforming all others in all cases. Consequently, a number\nof approaches have been proposed to automatically select the best strategy. Recent examples include bandit algorithms (Baram et al., 2004; Hsu & Lin, 2015), aggregating strategies whose experience can be transferred between domains (Chu & Lin, 2016), and approaches based on Reinforcement Learning (Ebert et al., 2012).\nA common limitation of all these approaches is that they cannot go beyond combining pre-existing, often handdesigned or computationally expensive, heuristics. In this paper, we propose to go further by allowing our method to discover the right strategies while being trained to discern effective AL approaches. In other words, our approach Learns Active Learning (LAL) and automatically comes up with task-appropriate query selection strategies.\nMore specifically, we formulate LAL as a regression problem. Given a trained classifier and its output for a specific sample with unknown label, we predict the reduction in generalization error that can be expected by adding the label to that point. In practice, we show that we can train such a regression function on synthetic data and generalize to the real data by taking features to be simple statistics, such as the variance of the classifier output or predicted probability distribution over possible labels for a specific datapoint. Furthermore, if one can provide a slightly larger initial set of annotated data, the regressor can be trained on it to help further extend the annotated set for very different classification tasks. We show that LAL works well on real data from several different domains such as biomedical imaging, economics, molecular biology, and high energy physics. It outperforms other methods without requiring hand-crafted heuristics."}, {"heading": "2. Related Work", "text": "The last decade has produced many different AL strategies. They include uncertainty sampling (Tong & Koller, 2002; Joshi et al., 2009; Settles, 2010; Yang et al., 2015),\nar X\niv :1\n70 3.\n03 36\n5v 1\n[ cs\n.L G\n] 9\nM ar\nquery-by-committee (Gilad-bachrach et al., 2005; Iglesias et al., 2011), expected model change (Settles, 2010; Sznitman & Jedynak, 2010; Vezhnevets et al., 2012), expected error (Joshi et al., 2012), and variance (Hoi et al., 2006) minimization, Bayesian AL (Houlsby et al., 2011). Among these, uncertainty sampling is both one of the simplest and one of the most popular. The intuition behind it is very natural as it proposes users to first label samples that are the most uncertain, that is, closest the classifier\u2019s current decision boundary. This strategy and most of the methods mentioned above work very well in cases such as the ones of Figs. 1, 2 but often fail in the more difficult one of Fig. 4. While both examples are synthetic, analogous situations arise regularly in real data (Baram et al., 2004).\nIn general there are two main types of AL strategies: theoretically motivated approaches that are not always tractable in real applications (e.g. expected reduction in error, information theoretic approaches) and approaches that demonstrated empirical increase in performance but whose convergence is not well understood. Among AL methods designed to handle complex real-world situations, some cater to specific classifiers, such as those that rely on Gaussian Processes (Kapoor et al., 2007), and applications, such as natural language processing (Tong & Koller, 2002; Olsson, 2009), sequence labeling tasks (Settles & Craven, 2008), visual recognition (Luo et al., 2004; Long et al., 2015), semantic segmentation (Vezhnevets et al., 2012), foreground-background segmentation (Konyushkova et al., 2015), image delineation (Mosinska et al., 2016), and preference learning (Singla et al., 2016). However, there is no one algorithm that outperforms all others for all tasks and datasets (Settles & Craven, 2008). Moreover, various querying strategies aim to maximize different performance metrics as evidenced in the case of multi-class classification (Settles, 2010).\nAs a result, meta learning algorithms have been gaining in popularity in recent years (Tamar et al., 2016), but they are rarely designed to deal with AL scenarios. The few existing approaches tackle the problem by combining AL strategies. Baram et al. (2004) combine several known heuristics during the AL execution with the help of a bandit algorithm. This is made possible by the use of the maximum entropy criterion, which estimates the classification performance without labels during AL. Hsu & Lin (2015) extend this line of work but move the focus from datasamples as arms to heuristics as arms in the bandit process and use a new unbiased estimator of the test error, which enables it to outperform the previous method. Chu & Lin (2016) go further and suggest transferring the bandit-learnt combination of AL heuristics between different tasks. Another view on the problem is presented in Ebert et al. (2012), where they balance exploration and exploitation with a Markov decision process.\nThe common limitation of these approaches is that they do not go beyond combining already existing approaches and are not designed to automatically propose new heuristics, as LAL does."}, {"heading": "3. Towards Data Driven Active Learning", "text": "In this section we briefly introduce the standard Active Leaning (AL) framework along with uncertainty sampling (US), the most frequently-used heuristic to implement it (Tong & Koller, 2002; Joshi et al., 2009; Settles, 2010; Yang et al., 2015). Despite its simplicity, US often works remarkably well in practice. However, we will show that it displays an optimal behavior only in a limited number of situations and by this we will motivate the fact that one cannot rely on a single heuristic, no matter how good."}, {"heading": "3.1. Active Learning (AL)", "text": "While the generic machine learning task is to find the best statistical model given training data, the task of AL is to select which data should be annotated in order to learn the model as quickly as possible. In practice, this means that instead of asking experts to annotate all the available data, we select iteratively which datapoints should be annotated next. The goal is to reach the a comparable accuracy level faster.\nSuppose we are interested in classifying datapoints from a target dataset D\u0303 = {(x1, y1), . . . , (xN , yN )}, where xi is a d-dimensional feature representation of a datapoint and yi \u2208 {0, 1} is its binary label. We choose a classifier f that can be trained on some Lt \u2282 D\u0303 to map features to labels fLt(xi) = y\u0302i through the predicted probability p(yi = y | Lt, xi). The standard AL procedure unfolds as follows.\n1. It starts with a small labeled training dataset Lt \u2282 D\u0303 with t = 0.\n2. A classifier fLt is trained using Lt.\n3. fLt is applied to the remainder of the data Ut for which annotations are unavailable.\n4. A query selection procedure picks an instance x\u2217 \u2208 Ut to be annotated at the next iteration. Usually, x\u2217 maximizes a heuristic criterion based on the datasets Lt and Ut, along with the predictions of the current classifier p(yi = y | Lt, xi) for unlabeled samples xi \u2208 Ut.\n5. x\u2217 is given a label y\u2217 by an expert, or an oracle in synthetic examples. We then take the new labeled set Lt+1 to be Lt\u222a (x\u2217, y\u2217) and the new sets of unlabeled samples to be Ut+1 = Ut \\ x\u2217.\n6. Increment t, go back to step 2 and iterate until the desired accuracy is achieved or the number of iterations has reached a predefined limit."}, {"heading": "3.2. Uncertainty Sampling", "text": "US has been reported to be successful in numerous scenarios and settings (Tong & Koller, 2002; Joshi et al., 2009; Settles, 2010; Yang et al., 2015; Konyushkova et al., 2015; Mosinska et al., 2016). As discussed in Section 2, it is based on selecting first samples about which the current classifier is least certain. There are many definitions of maximum uncertainty but one of the most widely accepted is to select samples that maximize the entropy H over predicted classes. In other words, this means taking x\u2217 to be\narg max xi\u2208Ut\nH[p(yi = y | xi,Lt)] . (1)"}, {"heading": "3.3. Success, Failure, and Motivation", "text": "We now motivate our approach by presenting two toy examples, one in which US is empirically observed to be the optimal (greedy) solution and another one, where it makes suboptimal decisions. To this, let us consider a simple two-dimensional dataset D\u0303 that consists of two clouds of datapoints corresponding to two different classes: D\u0303 = {(xi, yi)}, where xi \u2208 R2 and each class contains equal number of points, as shown in Fig. 1(a). The data in each cloud comes from a Gaussian distribution with a different mean but the same variance.\nLet us further assume that a dataset D\u0303\u2032 from the same distribution is available for testing. We can initialize the AL procedure of Section 3.1 given one sample from each class and their respective labels L0 = {(x1, 0), (x2, 1)}. U0 comprises the remaining data points. We start with a simple logistic regression classifier f on L0 and then test it on D\u0303\u2032. If D\u0303\u2032 is big, the error on it can be considered as a good approximation to the generalization error. The loss of fL0 on D\u0303\u2032 is `0 = \u2211 (x\u2032i,y \u2032 i)\u2208D\u0303\u2032 `(y\u0302i, y \u2032 i), where y\u0302i = fL0(x \u2032 i). In this example we will consider simple 0/1 loss.\nConsider the US strategy that selects sample x\u2217 according to Eq. 1. In this case it would be a datapoint with probability of class 0 close to 0.5. Let us try to label every point x from U0 one by one, form a new labeled set Lx = L0 \u222a (x, y) and check what error a new classifier fLx yields on D\u0303\u2032, that is, `x = \u2211 (x\u2032i,y \u2032 i)\u2208D\u0303\u2032 (y\u0302i, y \u2032 i), where y\u0302i = fLx(x \u2032 i). The difference between errors obtained with classifiers constructed on L0 and Lx indicates how much the addition of a new datapoint x reduces the generalization error \u03b4`(x,L0) = `0 \u2212 `x.\nWe repeat this experiment 10000 times and plot the mean (blue) and variance (red) of \u03b4`(x,L0) in Fig. 1(c). The\npoints with pi closest to 0.5, the one that US picks, is indeed close to being the one that yields the greatest error reduction.\nNext, we repeat the above experiment, but with one class (y = 0) containing twice as many datapoints as the other (y = 1), as shown in Fig. 1(b). As before, we plot the average error reduction as a function of pi in Fig. 1(d). However, this time the values of pi that correspond to the largest expected error reduction are further from 0.5 than before and US becomes suboptimal. And the more unbalanced the two classes are, the more serious the bias becomes. In more complex and more realistic cases, there are many other factors such as label noise, outliers or shape of distribution that can further compound the problem,\nThis is why many query selection procedures take into account statistical properties of the datasets and classifier. However, there is no simple way to foresee the influence of all possible factors. Thus, in this paper, we suggest Learning Active Learning (LAL) by taking many factors into account to predict the potential error reduction. By treating the query selection module as a regressor we do not restrict ourselves to pre-existing AL heuristics but can construct new ones. This approach can be customized for any type of classifier and dataset. For instance, in the example of Section 3.3 we expect LAL to automatically adapt pi to the relative prevalence of the two classes without having to explicitly state such a rule. We will see in the results section that this is indeed one of the many thing that LAL can handle, even in much more complex real-world cases.\nAnother AL scenario where learning AL strategy from data is useful is warm start. It is largely overlooked in the literature but has a significant practical interest, especially in highly specialized domains as we consider. We assume that\nin order to understand if the machine learning based approach is possible in an application, some sufficient dataset D0 is made available prior to AL. However, further classification improvement can be very annotation costly. In this situation we can benefit from the available training dataD0 to learn a specialized LAL strategy."}, {"heading": "4. Approach", "text": "We now formulate LAL as a regression problem. We model the dependency between the state of the learning and the expected greedy improvement of the generalization error. To this end, given a representative dataset with ground truth available, we simulate an online learning procedure using a Monte-Carlo style approach. We further extend the approach to account for selection bias caused by AL.\nMore specifically, we split the dataset into training D and testing D\u2032 data and use a small subset of labels from D to train an initial classifier, which performance is tested on D\u2032. A number of parameters \u03c6 that characterizes the state of the classifier is evaluated. We then incorporate unused labels from D individually to retrain the classifier. This lets us correlate the increase in classification performance \u03b4, or lack thereof, with the previously computed classifier parameters \u03c6 and parameters \u03c8 of the newly added datapoint. We then repeat this process for different initializations, sizes of labeled subset, and initially selected samples. The iterative LAL strategy accounts for the bias introduce by AL into the training data and yields the best results as it will be shown in Sec. 6. We formalize this process in the remainder of the section."}, {"heading": "4.1. Monte-Carlo LAL", "text": "Let the representative dataset discussed above be split into a training D = {(xi, yi)} and a testing set D\u2032 = {(x\u2032i, y\u2032i)} with xi \u2208 Rd and yi \u2208 {0, 1}. Let f be a classifier with a given training procedure.\nWe start the LAL Monte-Carlo procedure by splitting D into a labeled set L\u03c4 of size \u03c4 and an unlabeled set U\u03c4 containing the remaining points. We then train a classifier f on L\u03c4 , resulting in a function fL\u03c4 that we use to predict class labels for elements x\u2032 of the testing set D\u2032 and estimate the test classification loss `\u03c4 . We further characterize the classifier state by recording k parameters \u03c61(L\u03c4 ), . . . , \u03c6k(L\u03c4 ), which are specific to particular classifier families and change as the training progresses. For example, they can be the parameters of the kernel function if f is kernel-based, average depths of the trees if f is a random forest, or prediction variability if f is an ensemble classifier.\nNext, we randomly select a new datapoint x from U\u03c4 to form a new labeled set L\u03c4+1 = L\u03c4 \u222a x and retrain.\nWe characterize the effect of a datapoint on the state of learning by instantiating r parameters \u03c81(x), . . . , \u03c8r(x). For example, they can include the predicted probability of class y, the distance to the closest point in the dataset or the distance to the closest labeled point. The new classifier fL\u03c4+1 results in the test-set loss `\u03c4+1. Finally, we record the difference between previous and new loss \u03b4`(L\u03c4 , x) = `\u03c4 \u2212 `\u03c4+1. In the end, \u03b4`(L\u03c4 , x) is associated to the learning state in which it was received. The learning state is characterized by a vector \u03be(L\u03c4 , x) =[ \u03c61(L\u03c4 ) . . . \u03c6k(L\u03c4 ) \u03c81(x) . . . \u03c8r(x) ] , whose elements depend both on the state of the current classifier and on the datapoint, \u03c6 and \u03c8, respectively.\nNext, we repeat the whole sampling procedure for Q different initializations L1\u03c4 ,L2\u03c4 , . . . ,LQ\u03c4 and T various labeled subset sizes \u03c4 = 2, . . . , T + 2. For each initialization q and iteration \u03c4 we sample M different datapoints xq\u03c4m each of which yields classifier/datapoint state pairs along with the reduction in error associated to them. This results in Q\u00d7M \u00d7T MONTECARLOLAL observations \u03beq\u03c4m of dimensionality k + r that can be represented as a matrix \u039e whose lines are feature vectors: \u03c61(L12) . . . \u03c6k(L12) \u03c81(x121 ) . . . \u03c8r(x121 ) \u03c61(L12) . . . \u03c6k(L12) \u03c81(x122 ) . . . \u03c8r(x122 ) ... . . . ... ... . . . ... \u03c61(Lq\u03c4 ) . . . \u03c6k(Lq\u03c4 ) \u03c81(xq\u03c4m ) . . . \u03c8r(xq\u03c4m ) ... . . . ... ... . . .\n... \u03c61(LQT ) . . . \u03c6k(L Q T ) \u03c81(x QT M ) . . . \u03c8r(x QT M )  and associated vector \u2206 of labels \u03b4`(Lq\u03c4 , xmq\u03c4 ). Alg. 1 summarizes the steps of LAL data generation for a fixed \u03c4 and a given classifier f .\nOur next insight is that these observations lie on a smooth manifold and that similar states of the classifier correspond to similar behaviors when annotating similar samples. We thus formulate the task of predicting the potential error reduction of annotating a specific sample in a given the classifier state as a regression problem. We look for a mapping\ng : \u03be(L, x)\u2192 \u03b4`(L, x). (2) Then MONTECARLOLAL strategy selects a datapoint with the highest error reduction potential at iteration t:\nx\u2217 = arg max xi\u2208Ut\ng( [ \u03c61(Lt) . . . \u03c8r(xi) ] ). (3)\nNote that MONTECARLOLAL does not depend explicitly on the representative datasetD, but only on the chosen classifier and the choice of parameters \u03c6 and \u03c8. Therefore, it can be used to select samples that promise the greatest increase in classifier performance in domains D\u0303 other than the one we use to learn the strategy. Alg. 2 summarizes the MONTECARLOLAL learning procedure.\nAlgorithm 1 LALGENDATA Input: training dataset D, test dataset D\u2032, classification procedure f , partitioning function SPLIT, size \u03c4 Initialize: L\u03c4 , U\u03c4 \u2190 SPLIT(D, \u03c4 ) train a classifier fL\u03c4 estimate the test set loss `\u03c4 compute the classification state parameters \u03c6 \u2190 \u03c61(L\u03c4 ), . . . , \u03c6k(L\u03c4 ) for m = 1 to M do\nselect xm \u2208 U\u03c4 form a new labeled dataset L\u03c4+1 \u2190 L\u03c4 \u222a xm compute the datapoint parameters \u03c8 \u2190 \u03c81(xm), . . . , \u03c8r(xm) train a classifier fL\u03c4+1 estimate the new test loss `\u03c4+1 compute the loss reduction \u03b4`(L\u03c4 , xm)\u2190 `\u03c4 \u2212 `\u03c4+1 \u03bem \u2190 {\u03c6, \u03c8}\nend for \u039e\u2190 {\u03bem} Return: matrix of learning states \u039e \u2208 RM\u00d7(k+r), vector of reductions in error \u2206 \u2208 RM\u00d71\nAlgorithm 2 MONTECARLOLAL Input: iteration range {\u03c4min, . . . , \u03c4max}, classification procedure f SPLIT\u2190 random partitioning function Initialize: generate train set D and test dataset D\u2032 for \u03c4 in {\u03c4min, . . . \u03c4max} do\n\u039e\u03c4 ,\u2206\u03c4 \u2190 LALGENDATA (D,D\u2032, f, SPLIT, \u03c4 ) end for \u039e,\u2206\u2190 {\u039e\u03c4}, {\u2206\u03c4} train a regressor g : \u03be(L, x)\u2192 \u03b4`(x,L) on data \u039e,\u2206 construct AL strategy A(g): x\u2217 = arg maxxi\u2208Ut g[\u03be(Lt, xi)] Return: active learning strategy A(g)"}, {"heading": "4.2. Iterative LAL", "text": "MONTECARLOLAL strategy of Alg. 2 makes an implicit over-simplification in the way the dataset D is split into a labeled set L\u03c4 and unlabeled set U\u03c4 : No matter how many labeled samples \u03c4 are available, the labeled subset L\u03c4 consists of randomly chosen samples. However, when MONTECARLOLAL is applied at iteration t of AL, the labeled set Lt is constructed of samples selected by it at previous iterations, which is therefore not random.\nTo account for this, we modify the approach of Section 4.1 as follows. We learn a different AL strategy A\u03c4 at every iteration \u03c4 . A\u03c4 tells us which datapoint should be selected at iteration t = \u03c4 \u2212 2 of AL. When we execute iteration \u03c4 , we simulate AL procedure that start with 2 labeled samples and applies strategyA2, . . . ,A\u03c4 to select 3, . . . , (\u03c4 + 1)-th\nAlgorithm 3 ITERATIVELAL Input: iteration range {\u03c4min, . . . \u03c4max}, classification procedure f SPLIT\u2190 random partitioning function Initialize: generate train set D and test dataset D\u2032 for \u03c4 in {\u03c4min, . . . , \u03c4max} do\n\u039e\u03c4 ,\u2206\u03c4 \u2190 LALGENDATA (D,D\u2032, f, SPLIT, \u03c4 ) train a regressor g\u03c4 : \u03be(L, x)\u2192 \u03b4`(x,L) on \u039e\u03c4 ,\u2206\u03c4 SPLIT\u2190A(g\u03c4 )\nend for \u039e,\u2206\u2190 {\u039e\u03c4 ,\u2206\u03c4} train a regressor g : \u03be(L, x)\u2192 \u03b4`(x,L) on \u039e,\u2206 Return: active learning strategy A(g)\ndatapoints. In this way, samples at iteration \u03c4 + 1 depend on the samples at iteration \u03c4 and the sampling bias of AL is well represented in data \u039e,\u2206 from which the final strategy is leant. Alg. 3 depicts the final procedure."}, {"heading": "5. LAL Strategies Implementation", "text": "In this section we provide details about how we build the dataset \u039e,\u2206 to learn LAL strategies MONTECARLOLAL and ITERATIVELAL and select relevant features to instantiate the regression problem. We discuss the choice of classifier and regressor and provide values for key parameters for LAL procedure.\nRepresentative data for training LAL. Recall from Section 4.1 that we learn the mapping g of Eq. 2 from \u039e,\u2206 that was obtained from an example dataD that can be completely unrelated to the one on which we will do the AL D\u0303. Since the easiest way to obtain an example dataset is to synthesize it, we did this first and, as will be shown in the Results section, it turned out to be surprisingly effective.\nIn practice, we generate example 2-D datasets such as the ones depicted by Fig. 2 (a,b,c), where the 2 classes have Gaussian distributions with random means and variances and appear in various proportions. In our experiments, we set the size of training and test dataset to 400 and 4000 respectively and the imbalance between classes varies from 0.1 to 0.9. Each mean is drawn independently from a uniform distribution from 0 to 1 and the covariance is obtained by multiplying matrices whose entries are drawn uniformly between \u22120.5 and 0.5 with their transposes. We use 0/1 loss through LAL data generation.\nIn warm start experiments, we used a small (N0 << N ) subset of data of the domain for AL, on which we learn A(g) and initial AL classifier fL0 . We split them into training and test subsets and ran the LAL procedures as described in Sec. 4.1 and Sec. 4.2.\nChoice of classifier and regressor. We use Random Forest (RF) and Gaussian Process (GP) classifiers for f and RF and GP regressors for g in the corresponding experiments. Due to the dimensionality of real datasets, GP was only used in experiment with simulated data TwoGaussian-clouds.\nClassifier features. The vector \u03be that characterize the state of the learning process is composed of the following features: a) predicted probability: p(yi = 0|Dt, xi) b) proportion of class 0 in Dt c) out-of-bag cross-validated accuracy of fDt d) variance of feature importances of fDt e) forest variance computed as variance of trees\u2019 predictions on Ut f) average tree depth of the forest g) size of Lt.\nOnce the data \u039e,\u2206 was collected and regression solved, we can plot which features have the highest relative importance (Fig. 2 (d)).\nIn GP case we use a) predicted probability p(yi = 0|Dt, xi) b) predicted variance by GP c) variance and d) lengthscale of RBF kernel e) kernel density estimation for xi with respect to labeled and f) unlabeles samples g) size of Lt.\nParameters used to construct LAL. The LAL data generation parameters are set to the following values: M = 50, T = 48, Q = 500. Moreover, for every new initialization we use a new representative dataset from model of Fig. 2 (a-c) that insures that the learnt strategy can generalize to various problems."}, {"heading": "6. Experiments", "text": "We now compare the performance of LAL against several baselines both on synthetic and real data."}, {"heading": "6.1. Baselines and Protocol", "text": "We compare the following three versions of our approach:\n\u2022 LAL-MC-2D. LAL strategy learned as discussed in Sec. 4.1 where D is synthetic 2D dataset of Sec. 5. \u2022 LAL-iterative-2D. Similar to LAL-MC-2D but learnt according to Sec. 4.2. \u2022 LAL-MC-WS: Similar to LAL-MC-2D but D is a subset of the data D\u0303 on which AL is performed.\nagainst the following baselines:\n\u2022 Rs: random sampling. \u2022 Us: uncertainty sampling according to Sec. 3.2. \u2022 Kapoor: approach of Kapoor et al. (2007) that bal-\nances exploration against exploitation by incorporating mean and variance estimation of the GP classifier.\nIn our experiments we chose Us as our primary baseline because our approach makes use of the same information \u2013 predicted probability distribution over classes \u2013 as the datapoint features \u03c8. To compare against Kapoor, we included variance into \u03c8 for a fair comparison.\nIn AL experiments we then select samples to be labeled from the training set and report the classification performance on the test set. When using LAL-MC-2D and LALiterative-2D, we begin with one sample from each of two classed to initialize AL. We will refer to this setting as a cold start. In LAL-MC-WS strategy we start with a larger training set, which we will refer to as a warm start.\nThen, we perform from 100 to 1800 AL iterations depending on the dataset size and the task complexity and repeat\neach experiment 50 \u2212 100 times. In the figures below, we plot average classification quality as a function of the number of samples having been annotated.\nThe performance metrics we use are task-specific, they include classification accuracy, VOC score (Everingham et al., 2010), dice score (Gordillo et al., 2013), AMS score (Adam-Bourdarios et al., 2014) and area under ROC curve."}, {"heading": "6.2. Synthetic Data", "text": "We first demonstrate the performance of AL approach on the synthetic data generated using the model of Sec. 5, but previously unseen. Next we test our approach on the notoriously hard XOR-like datasets.\nTwo-Gaussian-clouds experiment. We generate 1000 new unseen datasets of the type depicted in Fig. 2 and test AL with GP and RF classifiers. Fig. 3 depicts the average test accuracy as a function of a number of labeled samples.\nIn case of both classifiers the proposed strategy is able to select datapoints that help to construct better classifiers\nquicker than Us heuristics. This experiment demonstrates that the LAL approach is robust to the type of chosen classifier f and parameters \u03c6 and \u03c8. Even in this simple task, when we are very close to the optimal performance, we can make better decisions by taking the learning state into account.\nXOR-like experiment XOR-like datasets are wellknown to be challenging for most machine learning techniques and AL is not an exception. Some works (Baram et al., 2004) report that various AL algorithms struggle with the type of tasks that is depicted in Fig. 4 (a), (b), (c). The reason for this is intuitively clear: any AL strategy relies on the prediction made by a classifier trained on available data. The prediction based on limited data is very distant from the ground truth in this case. When we have only two labeled instances in data like in Fig. 4 (a), at least two out of four groups of data are not represented in the training set at all. The classifier fL2 will guide further selection to refine the initial boundary and completely overlook the other two groups of datapoints. The task for AL becomes even more challenging when the XOR structure resembles a checkerboard as depicted in Fig. 4 (b). In the limiting case like this\nwe cannot expect to get better quality of prediction faster than with random sampling. Another XOR-like dataset that has more natural shape is the banana dataset from Ra\u0308tsch et al. (2001). Note that these datasets do not resemble in the least the data used to train LAL, as can be seen by comparing Figs.2 and 4).\nFigs. 4(d), (e), (f) show the average performance of AL strategies for the classification tasks depicted by Figs. 4 (a), (b), (c). As expected, Us looses to Rs. Nevertheless, LALiterative-2D adapts its selection strategy to perform better or at least comparably to Rs for AL even under such adversarial conditions. In other words, even though LAL has never seen an XOR-like dataset during its training, it still performs well by adapting its selection strategy on the basis of the statistics of the samples it encounters."}, {"heading": "6.3. Real Data", "text": "We now turn to real data from the domains where annotating is hard because it requires special training and education. Note that all the datasets are of a very different nature that means that their feature distributions have nothing to do with the syntactic example of Sec. 5.\n\u2022 Striatum: 3D Electron Microscopy stack of rat neural tissue from striatum. The task is to detect and segment mitochondria in it (Lucchi et al., 2012; Konyushkova et al., 2015).\n\u2022 MRI: brain scans with MRI are obtained from BRATS competition (Menza et al., 2014). The task is to segment brain tumor in T1, T2, FLAIR, and postGadolinium T1 MR images.\n\u2022 Credit card: The task is to detect credit card fraud transactions in transaction made by European cardholders in September 2013 (Dal Pozzolo et al., 2015).\n\u2022 Splice: In this dataset from the domain of molecular biology, our task is to detect splice junctions in DNA sequences (Lorena et al., 2002).\n\u2022 Higgs: This dataset from the domain of high energy physics contains the data that simulates the ATLAS experiment (Adam-Bourdarios et al., 2014).\nCold Start AL. We start with a standard setup to benchmark AL algorithms. Fig. 5 depicts the results of applying Rs, Us, LAL-MC-2D, and LAL-iterative-2D in three datasets Striatum, MRI, Credit card. Recall that the LAL strategies still all rely on the same regressor learned from 2D synthetic data and have not been fine-tuned for the specific problems at hand.\nBoth LAL strategies outperform Us, with LAL-iterative2D being the best of the two. Considering that the LAL regressor was learned using a simple 2D synthetic dataset, it is in fact somewhat surprising that it can deal with much more complex and unrelated datasets. This is something we intend to investigate further.\nWarm Start AL. We now turn to a more realistic scenario where a larger dataset is available to train the initial classifier before beginning AL, as discussed in Section 3. We can take advantage of the larger initial training set to learn an AL strategy that is tailored for the problem at hand. This is valuable for applications where task or feature distribution is so different from synthetic data that AL strategy cannot be transfered, for example, for tasks where feature distributions contain missing or categorical variables. We tested LAL-MC-WS approach on the Splice and Higgs datasets by starting with 100 and 200 randomly selected datapoints. Fig. 6 demonstrates the learning curve for Us and for LAL. For Splice dataset we report accuracy and AUC and for Higgs dataset we report AMS score and AUC. We conclude that LAL approach is indeed useful in this problem settings."}, {"heading": "7. Conclusion", "text": "In this paper we introduced a new approach to AL that is driven by data \u2013 Learning Active Learning. We found out that a LAL that was exposed to AL experiments on simple 2D data can sometimes generalize surprisingly well to challenging new domains. The ability to learn LAL from a subset of data of interest allows to further extend applicability of our approach. LAL demonstrated robustness to the choice of type of classifier and features.\nIn future work we would like to incorporate more features into LAL that will allow to compare it to various exploration/exploitation strategies. Furthermore we would like to address issues of multi-class classification and batchmode AL."}, {"heading": "Acknowledgements", "text": "We would like to thank Carlos Becker, Helge Rhodin and Lucas Maystre for their discussions and comments on the text."}], "references": [{"title": "The higgs boson machine learning challenge", "author": ["Adam-Bourdarios", "Claire", "Cowan", "Glen", "Germain", "C\u00e9cile", "Guyon", "Isabelle", "K\u00e9gl", "Bal\u00e1zs", "Rousseau", "David"], "venue": "In NIPS 2014 Workshop on High-energy Physics and Machine Learning,", "citeRegEx": "Adam.Bourdarios et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Adam.Bourdarios et al\\.", "year": 2014}, {"title": "Online Choice of Active Learning Algorithms", "author": ["Baram", "Yoram", "El-Yaniv", "Ran", "K. Luz", "Kobi"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Baram et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Baram et al\\.", "year": 2004}, {"title": "Can active learning experience be transferred? 2016", "author": ["Chu", "Hong-Min", "Lin", "Hsuan-Tien"], "venue": "URL http: //arxiv.org/abs/1608.00667", "citeRegEx": "Chu et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Chu et al\\.", "year": 2016}, {"title": "Calibrating probability with undersampling for unbalanced classification", "author": ["Dal Pozzolo", "Andrea", "Caelen", "Olivier", "Johnson", "Reid A", "Bontempi", "Gianluca"], "venue": "In Computational Intelligence,", "citeRegEx": "Pozzolo et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Pozzolo et al\\.", "year": 2015}, {"title": "RALF: A Reinforced Active Learning Formulation for Object Class Recognition", "author": ["S. Ebert", "M. Fritz", "B. Schiele"], "venue": "In IEEE Conference on Computer Vision and Pattern Recognition (CVPR),", "citeRegEx": "Ebert et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Ebert et al\\.", "year": 2012}, {"title": "Query by Committee Made Real", "author": ["R. Gilad-bachrach", "A. Navot", "N. Tishby"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Gilad.bachrach et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Gilad.bachrach et al\\.", "year": 2005}, {"title": "State of the Art Survey on MRI Brain Tumor Segmentation", "author": ["N. Gordillo", "E. Montseny", "P. Sobrevilla"], "venue": "Magnetic Resonance in Medicine,", "citeRegEx": "Gordillo et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Gordillo et al\\.", "year": 2013}, {"title": "Batch Mode Active Learning and Its Application to Medical Image Classification", "author": ["S.C. Hoi", "R. Jin", "J. Zhu", "M.R. Lyu"], "venue": "In International Conference on Machine Learning,", "citeRegEx": "Hoi et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Hoi et al\\.", "year": 2006}, {"title": "Bayesian active learning for classification and preference", "author": ["Houlsby", "Neil", "Husz\u00e1r", "Ferenc", "Ghahramani", "Zoubin", "Lengyel", "M\u00e1t\u00e9"], "venue": "learning. stat,", "citeRegEx": "Houlsby et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Houlsby et al\\.", "year": 2011}, {"title": "Active learning by learning", "author": ["Hsu", "Wei-Ning", "Lin", "Hsuan-Tien"], "venue": "AAAI, pp. 2659\u20132665,", "citeRegEx": "Hsu et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Hsu et al\\.", "year": 2015}, {"title": "Combining Generative and Discriminative Models for Semantic Segmentation", "author": ["J.E. Iglesias", "E. Konukoglu", "A. Montillo", "Z. Tu", "A. Criminisi"], "venue": "In Information Processing in Medical Imaging,", "citeRegEx": "Iglesias et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Iglesias et al\\.", "year": 2011}, {"title": "Scalable Active Learning for Multiclass Image Classification", "author": ["A.J. Joshi", "F. Porikli", "N.P. Papanikolopoulos"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence,", "citeRegEx": "Joshi et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Joshi et al\\.", "year": 2012}, {"title": "MultiClass Active Learning for Image Classification", "author": ["A.J. Joshi", "F. Porikli", "N. Papanikolopoulos"], "venue": "In Conference on Computer Vision and Pattern Recognition,", "citeRegEx": "Joshi et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Joshi et al\\.", "year": 2009}, {"title": "Active Learning with Gaussian Processes for Object Categorization", "author": ["A. Kapoor", "K. Grauman", "R. Urtasun", "T. Darrell"], "venue": "In International Conference on Computer Vision,", "citeRegEx": "Kapoor et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Kapoor et al\\.", "year": 2007}, {"title": "Introducing Geometry into Active Learning for Image Segmentation", "author": ["K. Konyushkova", "R. Sznitman", "P. Fua"], "venue": "In International Conference on Computer Vision,", "citeRegEx": "Konyushkova et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Konyushkova et al\\.", "year": 2015}, {"title": "Fully Convolutional Networks for Semantic Segmentation", "author": ["J. Long", "E. Shelhamer", "T. Darrell"], "venue": "In Conference on Computer Vision and Pattern Recognition,", "citeRegEx": "Long et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Long et al\\.", "year": 2015}, {"title": "Splice junction recognition using machine learning techniques", "author": ["Lorena", "Ana Carolina", "Batista", "Gustavo EAPA", "de Carvalho", "Andr\u00e9 Carlos Ponce Leon Ferreira", "Monard", "Maria Carolina"], "venue": "In WOB, pp", "citeRegEx": "Lorena et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Lorena et al\\.", "year": 2002}, {"title": "Structured Image Segmentation Using Kernelized Features", "author": ["A. Lucchi", "Y. Li", "K. Smith", "P. Fua"], "venue": "In European Conference on Computer Vision,", "citeRegEx": "Lucchi et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Lucchi et al\\.", "year": 2012}, {"title": "Active Learning to Recognize Multiple Types of Plankton", "author": ["T. Luo", "K. Kramer", "S. Samson", "A. Remsen", "D.B. Goldgof", "L.O. Hall", "T. Hopkins"], "venue": "In International Conference on Pattern Recognition,", "citeRegEx": "Luo et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Luo et al\\.", "year": 2004}, {"title": "The Multimodal Brain Tumor Image Segmentation Benchmark (BRATS)", "author": ["B. Menza", "A Jacas"], "venue": "IEEE Transactions on Medical Imaging,", "citeRegEx": "Menza and Jacas,? \\Q2014\\E", "shortCiteRegEx": "Menza and Jacas", "year": 2014}, {"title": "Active Learning for Delineation of Curvilinear Structures", "author": ["A. Mosinska", "R. Sznitman", "P. Glowacki", "P. Fua"], "venue": "In Conference on Computer Vision and Pattern Recognition,", "citeRegEx": "Mosinska et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Mosinska et al\\.", "year": 2016}, {"title": "A Literature Survey of Active Machine Learning in the Context of Natural Language Processing", "author": ["F. Olsson"], "venue": "Swedish Institute of Computer Science,", "citeRegEx": "Olsson,? \\Q2009\\E", "shortCiteRegEx": "Olsson", "year": 2009}, {"title": "Soft margins for adaboost", "author": ["R\u00e4tsch", "Gunnar", "Onoda", "Takashi", "M\u00fcller", "K-R"], "venue": "Machine learning,", "citeRegEx": "R\u00e4tsch et al\\.,? \\Q2001\\E", "shortCiteRegEx": "R\u00e4tsch et al\\.", "year": 2001}, {"title": "Active Learning Literature Survey", "author": ["B. Settles"], "venue": "Technical report, University of Wisconsin\u2013Madison,", "citeRegEx": "Settles,? \\Q2010\\E", "shortCiteRegEx": "Settles", "year": 2010}, {"title": "An Analysis of Active Learning Strategies for Sequence Labeling Tasks", "author": ["B. Settles", "M. Craven"], "venue": "In Conference on Empirical Methods in Natural Language Processing,", "citeRegEx": "Settles and Craven,? \\Q2008\\E", "shortCiteRegEx": "Settles and Craven", "year": 2008}, {"title": "Actively learning hemimetrics with applications to eliciting user preferences", "author": ["Singla", "Adish", "Tschiatschek", "Sebastian", "Krause", "Andreas"], "venue": "In ICML,", "citeRegEx": "Singla et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Singla et al\\.", "year": 2016}, {"title": "Active Testing for Face Detection and Localization", "author": ["R. Sznitman", "B. Jedynak"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence,", "citeRegEx": "Sznitman and Jedynak,? \\Q2010\\E", "shortCiteRegEx": "Sznitman and Jedynak", "year": 2010}, {"title": "Value iteration networks", "author": ["Tamar", "Aviv", "Levine", "Sergey", "Abbeel", "WU Pieter", "YI", "Thomas", "Garrett"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Tamar et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Tamar et al\\.", "year": 2016}, {"title": "Support Vector Machine Active Learning with Applications to Text Classification", "author": ["S. Tong", "D. Koller"], "venue": "Machine Learning,", "citeRegEx": "Tong and Koller,? \\Q2002\\E", "shortCiteRegEx": "Tong and Koller", "year": 2002}, {"title": "Weakly Supervised Structured Output Learning for Semantic Segmentation", "author": ["A. Vezhnevets", "V. Ferrari", "J.M. Buhmann"], "venue": "In Conference on Computer Vision and Pattern Recognition,", "citeRegEx": "Vezhnevets et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Vezhnevets et al\\.", "year": 2012}, {"title": "Multi-Class Active Learning by Uncertainty Sampling with Diversity Maximization", "author": ["Y. Yang", "Z. Ma", "F. Nie", "X. Chang", "A.G. Hauptmann"], "venue": "International Journal of Computer Vision,", "citeRegEx": "Yang et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Yang et al\\.", "year": 2015}], "referenceMentions": [{"referenceID": 1, "context": "Recent examples include bandit algorithms (Baram et al., 2004; Hsu & Lin, 2015), aggregating strategies whose experience can be transferred between domains (Chu & Lin, 2016), and approaches based on Reinforcement Learning (Ebert et al.", "startOffset": 42, "endOffset": 79}, {"referenceID": 4, "context": ", 2004; Hsu & Lin, 2015), aggregating strategies whose experience can be transferred between domains (Chu & Lin, 2016), and approaches based on Reinforcement Learning (Ebert et al., 2012).", "startOffset": 167, "endOffset": 187}, {"referenceID": 12, "context": "They include uncertainty sampling (Tong & Koller, 2002; Joshi et al., 2009; Settles, 2010; Yang et al., 2015), ar X iv :1 70 3.", "startOffset": 34, "endOffset": 109}, {"referenceID": 23, "context": "They include uncertainty sampling (Tong & Koller, 2002; Joshi et al., 2009; Settles, 2010; Yang et al., 2015), ar X iv :1 70 3.", "startOffset": 34, "endOffset": 109}, {"referenceID": 30, "context": "They include uncertainty sampling (Tong & Koller, 2002; Joshi et al., 2009; Settles, 2010; Yang et al., 2015), ar X iv :1 70 3.", "startOffset": 34, "endOffset": 109}, {"referenceID": 5, "context": "query-by-committee (Gilad-bachrach et al., 2005; Iglesias et al., 2011), expected model change (Settles, 2010; Sznitman & Jedynak, 2010; Vezhnevets et al.", "startOffset": 19, "endOffset": 71}, {"referenceID": 10, "context": "query-by-committee (Gilad-bachrach et al., 2005; Iglesias et al., 2011), expected model change (Settles, 2010; Sznitman & Jedynak, 2010; Vezhnevets et al.", "startOffset": 19, "endOffset": 71}, {"referenceID": 23, "context": ", 2011), expected model change (Settles, 2010; Sznitman & Jedynak, 2010; Vezhnevets et al., 2012), expected error (Joshi et al.", "startOffset": 31, "endOffset": 97}, {"referenceID": 29, "context": ", 2011), expected model change (Settles, 2010; Sznitman & Jedynak, 2010; Vezhnevets et al., 2012), expected error (Joshi et al.", "startOffset": 31, "endOffset": 97}, {"referenceID": 11, "context": ", 2012), expected error (Joshi et al., 2012), and variance (Hoi et al.", "startOffset": 24, "endOffset": 44}, {"referenceID": 7, "context": ", 2012), and variance (Hoi et al., 2006) minimization, Bayesian AL (Houlsby et al.", "startOffset": 22, "endOffset": 40}, {"referenceID": 8, "context": ", 2006) minimization, Bayesian AL (Houlsby et al., 2011).", "startOffset": 34, "endOffset": 56}, {"referenceID": 1, "context": "While both examples are synthetic, analogous situations arise regularly in real data (Baram et al., 2004).", "startOffset": 85, "endOffset": 105}, {"referenceID": 13, "context": "Among AL methods designed to handle complex real-world situations, some cater to specific classifiers, such as those that rely on Gaussian Processes (Kapoor et al., 2007), and applications, such as natural language processing (Tong & Koller, 2002; Olsson, 2009), sequence labeling tasks (Settles & Craven, 2008), visual recognition (Luo et al.", "startOffset": 149, "endOffset": 170}, {"referenceID": 21, "context": ", 2007), and applications, such as natural language processing (Tong & Koller, 2002; Olsson, 2009), sequence labeling tasks (Settles & Craven, 2008), visual recognition (Luo et al.", "startOffset": 63, "endOffset": 98}, {"referenceID": 18, "context": ", 2007), and applications, such as natural language processing (Tong & Koller, 2002; Olsson, 2009), sequence labeling tasks (Settles & Craven, 2008), visual recognition (Luo et al., 2004; Long et al., 2015), semantic segmentation (Vezhnevets et al.", "startOffset": 169, "endOffset": 206}, {"referenceID": 15, "context": ", 2007), and applications, such as natural language processing (Tong & Koller, 2002; Olsson, 2009), sequence labeling tasks (Settles & Craven, 2008), visual recognition (Luo et al., 2004; Long et al., 2015), semantic segmentation (Vezhnevets et al.", "startOffset": 169, "endOffset": 206}, {"referenceID": 29, "context": ", 2015), semantic segmentation (Vezhnevets et al., 2012), foreground-background segmentation (Konyushkova et al.", "startOffset": 31, "endOffset": 56}, {"referenceID": 14, "context": ", 2012), foreground-background segmentation (Konyushkova et al., 2015), image delineation (Mosinska et al.", "startOffset": 44, "endOffset": 70}, {"referenceID": 20, "context": ", 2015), image delineation (Mosinska et al., 2016), and preference learning (Singla et al.", "startOffset": 27, "endOffset": 50}, {"referenceID": 25, "context": ", 2016), and preference learning (Singla et al., 2016).", "startOffset": 33, "endOffset": 54}, {"referenceID": 23, "context": "Moreover, various querying strategies aim to maximize different performance metrics as evidenced in the case of multi-class classification (Settles, 2010).", "startOffset": 139, "endOffset": 154}, {"referenceID": 27, "context": "As a result, meta learning algorithms have been gaining in popularity in recent years (Tamar et al., 2016), but they are rarely designed to deal with AL scenarios.", "startOffset": 86, "endOffset": 106}, {"referenceID": 1, "context": "Baram et al. (2004) combine several known heuristics during the AL execution with the help of a bandit algorithm.", "startOffset": 0, "endOffset": 20}, {"referenceID": 1, "context": "Baram et al. (2004) combine several known heuristics during the AL execution with the help of a bandit algorithm. This is made possible by the use of the maximum entropy criterion, which estimates the classification performance without labels during AL. Hsu & Lin (2015) extend this line of work but move the focus from datasamples as arms to heuristics as arms in the bandit process and use a new unbiased estimator of the test error, which enables it to outperform the previous method.", "startOffset": 0, "endOffset": 271}, {"referenceID": 1, "context": "Baram et al. (2004) combine several known heuristics during the AL execution with the help of a bandit algorithm. This is made possible by the use of the maximum entropy criterion, which estimates the classification performance without labels during AL. Hsu & Lin (2015) extend this line of work but move the focus from datasamples as arms to heuristics as arms in the bandit process and use a new unbiased estimator of the test error, which enables it to outperform the previous method. Chu & Lin (2016) go further and suggest transferring the bandit-learnt combination of AL heuristics between different tasks.", "startOffset": 0, "endOffset": 505}, {"referenceID": 1, "context": "Baram et al. (2004) combine several known heuristics during the AL execution with the help of a bandit algorithm. This is made possible by the use of the maximum entropy criterion, which estimates the classification performance without labels during AL. Hsu & Lin (2015) extend this line of work but move the focus from datasamples as arms to heuristics as arms in the bandit process and use a new unbiased estimator of the test error, which enables it to outperform the previous method. Chu & Lin (2016) go further and suggest transferring the bandit-learnt combination of AL heuristics between different tasks. Another view on the problem is presented in Ebert et al. (2012), where they balance exploration and exploitation with a Markov decision process.", "startOffset": 0, "endOffset": 677}, {"referenceID": 12, "context": "In this section we briefly introduce the standard Active Leaning (AL) framework along with uncertainty sampling (US), the most frequently-used heuristic to implement it (Tong & Koller, 2002; Joshi et al., 2009; Settles, 2010; Yang et al., 2015).", "startOffset": 169, "endOffset": 244}, {"referenceID": 23, "context": "In this section we briefly introduce the standard Active Leaning (AL) framework along with uncertainty sampling (US), the most frequently-used heuristic to implement it (Tong & Koller, 2002; Joshi et al., 2009; Settles, 2010; Yang et al., 2015).", "startOffset": 169, "endOffset": 244}, {"referenceID": 30, "context": "In this section we briefly introduce the standard Active Leaning (AL) framework along with uncertainty sampling (US), the most frequently-used heuristic to implement it (Tong & Koller, 2002; Joshi et al., 2009; Settles, 2010; Yang et al., 2015).", "startOffset": 169, "endOffset": 244}, {"referenceID": 12, "context": "US has been reported to be successful in numerous scenarios and settings (Tong & Koller, 2002; Joshi et al., 2009; Settles, 2010; Yang et al., 2015; Konyushkova et al., 2015; Mosinska et al., 2016).", "startOffset": 73, "endOffset": 197}, {"referenceID": 23, "context": "US has been reported to be successful in numerous scenarios and settings (Tong & Koller, 2002; Joshi et al., 2009; Settles, 2010; Yang et al., 2015; Konyushkova et al., 2015; Mosinska et al., 2016).", "startOffset": 73, "endOffset": 197}, {"referenceID": 30, "context": "US has been reported to be successful in numerous scenarios and settings (Tong & Koller, 2002; Joshi et al., 2009; Settles, 2010; Yang et al., 2015; Konyushkova et al., 2015; Mosinska et al., 2016).", "startOffset": 73, "endOffset": 197}, {"referenceID": 14, "context": "US has been reported to be successful in numerous scenarios and settings (Tong & Koller, 2002; Joshi et al., 2009; Settles, 2010; Yang et al., 2015; Konyushkova et al., 2015; Mosinska et al., 2016).", "startOffset": 73, "endOffset": 197}, {"referenceID": 20, "context": "US has been reported to be successful in numerous scenarios and settings (Tong & Koller, 2002; Joshi et al., 2009; Settles, 2010; Yang et al., 2015; Konyushkova et al., 2015; Mosinska et al., 2016).", "startOffset": 73, "endOffset": 197}, {"referenceID": 13, "context": "\u2022 Kapoor: approach of Kapoor et al. (2007) that balances exploration against exploitation by incorporating mean and variance estimation of the GP classifier.", "startOffset": 22, "endOffset": 43}, {"referenceID": 6, "context": ", 2010), dice score (Gordillo et al., 2013), AMS score (Adam-Bourdarios et al.", "startOffset": 20, "endOffset": 43}, {"referenceID": 0, "context": ", 2013), AMS score (Adam-Bourdarios et al., 2014) and area under ROC curve.", "startOffset": 19, "endOffset": 49}, {"referenceID": 1, "context": "Some works (Baram et al., 2004) report that various AL algorithms struggle with the type of tasks that is depicted in Fig.", "startOffset": 11, "endOffset": 31}, {"referenceID": 22, "context": "Another XOR-like dataset that has more natural shape is the banana dataset from R\u00e4tsch et al. (2001). Note that these datasets do not resemble in the least the data used to train LAL, as can be seen by comparing Figs.", "startOffset": 80, "endOffset": 101}, {"referenceID": 17, "context": "The task is to detect and segment mitochondria in it (Lucchi et al., 2012; Konyushkova et al., 2015).", "startOffset": 53, "endOffset": 100}, {"referenceID": 14, "context": "The task is to detect and segment mitochondria in it (Lucchi et al., 2012; Konyushkova et al., 2015).", "startOffset": 53, "endOffset": 100}, {"referenceID": 16, "context": "\u2022 Splice: In this dataset from the domain of molecular biology, our task is to detect splice junctions in DNA sequences (Lorena et al., 2002).", "startOffset": 120, "endOffset": 141}, {"referenceID": 0, "context": "\u2022 Higgs: This dataset from the domain of high energy physics contains the data that simulates the ATLAS experiment (Adam-Bourdarios et al., 2014).", "startOffset": 115, "endOffset": 145}], "year": 2017, "abstractText": "In this paper, we suggest a novel data-driven approach to active learning: Learning Active Learning (LAL). The key idea behind LAL is to train a regressor that predicts the expected error reduction for a potential sample in a particular learning state. By treating the query selection procedure as a regression problem we are not restricted to dealing with existing AL heuristics; instead, we learn strategies based on experience from previous active learning experiments. We show that LAL can be learnt from a simple artificial 2D dataset and yields strategies that work well on real data from a wide range of domains. Moreover, if some domain-specific samples are available to bootstrap active learning, the LAL strategy can be tailored for a particular problem.", "creator": "LaTeX with hyperref package"}}}