{"id": "1703.05667", "review": {"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "16-Mar-2017", "title": "End-to-End Learning for Structured Prediction Energy Networks", "abstract": "Structured Prediction Energy Networks (Belanger and McCallum, 2016) (SPENs) are a simple, yet expressive family of structured prediction models. An energy function over candidate structured outputs is given by a deep network, and predictions are formed by gradient-based optimization. Unfortunately, we have struggled to apply the structured SVM (SSVM) learning method of Belanger and McCallum, 2016 to applications with more complex structure than multi-label classification. In general, SSVMs are unreliable whenever exact energy minimization is intractable. In response, we present end-to-end learning for SPENs, where the energy function is discriminatively trained by back-propagating through gradient-based prediction. This paper presents a collection of methods necessary to apply the technique to problems with complex structure. For example, we avoid vanishing gradients when learning SPENs for convex relaxations of discrete prediction problems and explicitly train models such that energy minimization converges quickly in practice. Using end-to-end learning, we demonstrate the power of SPENs on 7-Scenes depth image denoising and CoNLL-2005 semantic role labeling tasks. In both, we outperform competitive baselines that employ more simplistic energy functions, but perform exact energy minimization. In particular, for denoising we achieve 40 PSNR, outperforming the previous state-of-the-art of 36.3 PSNR, outperforming the previous state-of-the-art of 42.3 PSNR, outperforming the previous state-of-the-art of 40.3 PSNR, outperforming the previous state-of-the-art of 42.3 PSNR, outperforming the previous state-of-the-art of 42.3 PSNR, outperforming the previous state-of-the-art of 42.3 PSNR, outperforming the previous state-of-the-art of 42.3 PSNR, outperforming the previous state-of-the-art of 42.3 PSNR, outperforming the previous state-of-the-art of 42.3 PSNR, outperforming the previous state-of-the-art of 42.3 PSNR, outperforming the previous state-of-the-art of 42.3 PSNR, outperforming the previous state-of-the-art of 42.3 PSNR, outperforming the previous state-of-the-art of 42.3 PSNR, outper", "histories": [["v1", "Thu, 16 Mar 2017 15:14:48 GMT  (81kb,D)", "http://arxiv.org/abs/1703.05667v1", null], ["v2", "Sat, 15 Jul 2017 04:50:13 GMT  (93kb,D)", "http://arxiv.org/abs/1703.05667v2", "ICML 2017"]], "reviews": [], "SUBJECTS": "stat.ML cs.LG", "authors": ["david belanger", "bishan yang", "andrew mccallum"], "accepted": true, "id": "1703.05667"}, "pdf": {"name": "1703.05667.pdf", "metadata": {"source": "META", "title": "End-to-End Learning for Structured Prediction Energy Networks", "authors": ["David Belanger", "Bishan Yang", "Andrew McCallum"], "emails": ["langer@cs.umass.edu>."], "sections": [{"heading": "1. Introduction", "text": "In a variety of domains, we predict a structured output y, given input x. For example, given a noisy image, we predict a clean version of it, or given a sentence we predict its semantic structure. Often, it is insufficient to employ\n1University of Massachusetts, Amherst 2Carnegie Mellon University. Correspondence to: David Belanger <belanger@cs.umass.edu>.\na feed-forward predictor y = F (x), since this may have prohibitive sample complexity, fail to model global interactions among outputs, or fail to enforce hard output constraints. Instead, it can be advantageous to define the prediction function implicitly, via energy minimization (LeCun et al., 2006):\ny\u0302 = arg miny Ex(y), (1)\nwhere values ofEx(\u00b7) depend on x and learned parameters.\nThis approach includes factor graphs, eg. conditional random fields (CRFs) (Lafferty et al., 2001) and many recurrent neural networks. Output constraints are enforced using constrained optimization. Compared to feed-forward approaches, energy minimization provides practitioners with better opportunities to inject prior knowledge about likely outputs, and often has more parsimonious models.\nOn the other hand, energy-based prediction requires nontrivial search in the space of outputs, and search techniques often need to be designed on a case-by-case basis. For factor graphs, the efficiency of prediction often scales poorly with treewidth of the graph.\nStructured prediction energy networks (SPENs) (Belanger & McCallum, 2016) help reduce these concerns. They can capture high-arity interactions among components of y that would lead to intractable graphical models and provide a mechanism for automatic structure learning. This is accomplished by expressing the energy function in Eq. (1) as a deep architecture and forming predictions by approximately optimizing y using gradient descent.\nWhile providing the expressivity and generality of deep networks, SPENs also maintain the useful semantics of energy functions: domain experts can design architectures to capture known properties of the data, energy functions can be combined additively, and we can perform constrained optimization over y. Most importantly, SPENs provide for black-box interaction with the energy, via forward and back-propagation. This allows practioners to explore a wide variety of models without the need to hand-design corresponding prediction methods.\nBelanger & McCallum (2016) train SPENs using a structured SVM (SSVM) loss (Taskar et al., 2004; Tsochantaridis et al., 2004) and achieve competitive performance\nar X\niv :1\n70 3.\n05 66\n7v 1\n[ st\nat .M\nL ]\n1 6\nM ar\n2 01\n7\non simple multi-label classification tasks. Unfortunately, we have found it difficult to extend their method to more complex domains. SSVMs are unreliable when exact energy minimization is intractable, as loss-augmented inference may fail to discover margin violations (Sec. 2.3).\nIn response, we present end-to-end training of SPENs, where one directly back-propagates through a computation graph that unrolls gradient-based energy minimization. This does not assume that exact minimization is tractable, and instead directly optimizes the practical performance of a particular approximate minimization algorithm. End-to-end training for gradient-based prediction was introduced in Domke (2012) and applied to deep energy models by Brakel et al. (2013).\nWhen applying end-to-end training to SPENs for problems with sophisticated output structure, we have encountered a variety of technical challenges. The core contribution of this paper is a set of general-purpose solutions for overcoming these. First, we employ specific architectures, parameter tying schemes, and pretraining methods that reduce overfitting and improve efficiency. Second, we alleviate the effect of vanishing gradients when training SPENs defined over the convex relaxation of discrete prediction problems. Third, we train energies such that gradient-based minimization is fast. Fourth, we reduce SPENs\u2019 computation and memory overhead.\nWe demonstrate our SPEN training methods on two substantial tasks. Neither set of experiments presents SSVM results, as we could not achieve reasonable results using the method.\nWe first consider depth image denoising on the 7-Scenes dataset (Newcombe et al., 2011), where we employ deep convnets as priors over images. This provides substantial performance improvements, from 36 to 40 PSNR, over the state-of-the-art, which unrolls more sophisticated optimization than us, but uses a simpler prior (Wang et al., 2016) .\nNext, we show the advantages of SPENs for semantic role labeling (SRL), with evaluation on the CoNLL-2005 dataset (Carreras & Ma\u0300rquez, 2005). SRL extracts complex semantic structures over verbal predicates and phrasal arguments. The task is challenging for SPENs because the output is discrete, sparse, and subject to rigid non-local constraints. We show how to apply SPENs and demonstrate promising results over strong baselines that use deep features and encode structural constraints using traditional graphical models.\nDespite substantial differences between the two applications, learning and prediction for all models is performed using the same gradient-based prediction and end-to-end learning code. This black-box interaction with the model provides many opportunities for further use of SPENs."}, {"heading": "2. Structured Prediction Energy Networks", "text": "A SPEN is defined as an instance energy-based structured prediction Eq. (1) where the energy is given by a deep neural network that provides a subroutine for efficiently evaluating ddyEx(y) (Belanger & McCallum, 2016). Differentiability necessitates that the energy is defined on continuous inputs. For the remainder of the paper, y will always be continuous. Prediction is performed by gradient-based optimization with respect to y.\nThis section first motivates the SPENs employed in this paper, by contrasting them with alternative energy-based approaches to structured prediction. Then, we present two families of methods for training energy-based structured prediction models that have been explored in prior work."}, {"heading": "2.1. Black-Box vs. Factorized Energy Functions", "text": "The definition of SPENs above is extremely general and includes many existing modeling techniques. However, both this paper and Belanger & McCallum (2016) depart from most prior work by employing monolithic energy functions that only provide forward and back-propagation.\nThis contrasts with the two principal families of energybased models in the literature, where the tractability of (approximate) energy minimization depends crucially on the factorization structure of the energy. First, factor graphs assume a graph over components of y, where the energy decomposes over the set of cliques. This structure provides opportunities for (approximate) energy minimizaton using message passing, MCMC, or combinatorial solvers (Koller & Friedman, 2009). Second, autoregressive models, such as recurrent neural networks (RNNs) assume a partial ordering on the components of y such that the energy for component yi only depends on its predecessors. Approximate energy minimization can be performed using search in the space of prefixes of y using beam search or greedy search (Goodfellow et al., 2016).\nBy not relying on any such factorization when choosing learning and prediction algorithms for SPENs, we can consider much broader families of deep energy functions. We do not specify the interaction structure in advance, but instead learn it automatically by fitting a deep network. This can capture sophisticated global interactions among components of y that are difficult to represent using a factorized energy. Of course, the downside of such SPENs is that they provide few guarantees, particularly when employing non-convex energies. Furthermore, for problems with hard constraints on outputs, the ability to do effective constrained optimization may depend crucially on leveraging some factorization structure."}, {"heading": "2.2. SPEN Learning as Conditional Density Estimation", "text": "One method for estimating the parameters of a SPEN energy Ex(y) is to maximize the conditional likelihood of y:\nP(y|x) \u221d exp (\u2212Ex(y)) . (2)\nUnfortunately, computing the likelihood requires the partition function, which is intractable for black-box energies with no available factorization structure. In contrastive backprop, this is circumvented by performing contrastive divergence training, with Hamiltonian Monte Carlo sampling from the energy surface (Mnih & Hinton, 2005; Hinton et al., 2006; Ngiam et al., 2011). Recently, Zhai et al. (2016) trained energy-based density models for anomaly detection by exploiting the connections between denosing autoencoders, energy-based models, and score matching (Vincent, 2011).\nOverall, this density estimation may have high sample complexity because it seeks to fit the entire conditional distribution, rather than simply learning an energy function that yields high-quality predictions."}, {"heading": "2.3. SPEN Learning with Exact Energy Minimization", "text": "Let \u2206(y\u0302,y\u2217) be a non-negative task-specific cost function for comparing y\u0302 and the ground truth y\u2217. Belanger & McCallum (2016) employ a structured SVM (SSVM) loss (Taskar et al., 2004; Tsochantaridis et al., 2004):\u2211\n{xi,yi}\nmax y [\u2206(y,yi)\u2212 Exiy) + Exi(yi)]+ , (3)\nwhere [\u00b7]+ = max(0, \u00b7). Each step of minimizing Eq. (3) by subgradient descent requires loss-augmented inference:\nmin y (\u2212\u2206(y,yi) + Exi(y)) . (4)\nFor differentiable \u2206(y,yi), Eq. (4) can be solved by firstorder methods.\nSolving Eq. (4) probes the model for margin violations. If none exist, the gradient of the loss with respect to the parameters is zero. Therefore, SSVM performance does not degrade gracefully with optimization errors in the inner prediction problem, since this may fail to discover margin violations that exist. Performance can be recovered if Eq. (4) returns a lower bound (Finley & Joachims, 2008). However, this is not possible in general. Overall, our experiments avoid an empirical comparison between SSVM and end-to-end training, namely because SSVM learning is unstable and difficult to tune.\nThe implicit function theorem offers an alternative framework for training energy-based predictors (Foo et al., 2008; Samuel & Tappen, 2009). See Domke (2012) for an\noverview. While a naive implementation requires inverting Hessians, one can solve the product of an inverse Hessian and a vector using conjugate gradients, which can leverage the techniques discussed in Sec. 3 as a subroutine. To perform reliably, the method unfortunately requires exact energy minimization and many conjugate gradient iterations.\nOverall, both of these learning algorithms only update the energy function in the neighborhoods of the ground truth and the predictions of the current model. On the other hand, it is advantageous to shape the entire energy surface such that is exhibits certain properties, e.g., gradient descent converges quickly when initialized well (Sec. 4.3). Therefore, these methods may be undesirable even for problems where exact energy minimization is tractable.\nFor non-convex Ex(\u00b7), gradient-based prediction will only find a local optimum. Amos et al. (2016) present inputconvex neural networks (ICNNs), which employ an easyto-implement method for constraining the parameters of a SPEN such that the energy is convex with respect to y, but perhaps non-convex with respect to the parameters. One simply uses convex, non-decreasing non-linearities and only non-negative parameters in any part of the computation graph downstream from y. Here, prediction will return the global optimum, but convexity, especially when achieved this way, may impose a strong restriction on the expressivity of the energy. Their construction is a sufficient condition for achieving convexity, but there are convex energies that disobey this property. Our experiments present some results for instances of ICNNs. In general, non-convex SPENS perform slightly better."}, {"heading": "3. Learning with Unrolled Optimization", "text": "The algorithms of Sec. 2.3 are unreliable with non-convex energies because we can not simply use the output of inexact energy minimization as a drop-in replacement for the exact minimizer. Instead, we draw on prior work for end-to-end learning of gradient-based predictors (Gregor & LeCun, 2010; Domke, 2012; Maclaurin et al., 2015; Andrychowicz et al., 2016; Wang et al., 2016; Metz et al., 2017; Greff et al., 2017). Rather than reasoning about the energy minimum as an abstract quantity, the authors pose a specific gradient-based algorithm for approximate energy minimization and optimize its empirical performance using back-propagation. This is a form of direct risk minimization (Stoyanov et al., 2011; Domke, 2013).\nConsider simple gradient descent:\nyT = y0 \u2212 T\u2211\nt=1\n\u03b7t d\ndy Ex(yt). (5)\nTo learn the energy function end-to-end, we can backpropagate through the unrolled optimization Eq. (5) for\nfixed T . With this, it can be rendered API-equivalent to a feed-forward network, and can thus be trained using standard methods. Furthermore, certain hyperparameters, such as the learning rate \u03b7t, are trainable (Domke, 2012).\nThis backpropagation requires non-standard interaction with a neural-network library because Eq. (5) computes gradients in the forward pass, and thus it must compute second order terms in the backwards pass. We can save space and computation by avoiding instantiating Hessian terms and instead directly computing Hessian-vector products. These can be achieved three ways. First, the method of Pearlmutter (1994) is exact, but requires non-trivial code modifications. Second, some libraries construct computation graphs for gradients that are themselves differentiable. Third, we can employ finite-differences (Domke, 2012).\nIt is clear that Eq. (5) can be naturally extended to certain alternative optimization methods, such as gradient descent with momentum, or L-BFGS (Domke, 2012). This requires an additional state vector ht that is evolved along with yt across iterations. Andrychowicz et al. (2016) also unroll gradient-descent, but employ a generic LSTM (Hochreiter & Schmidhuber, 1997), with per-coordinate updates to y."}, {"heading": "4. End-to-End Learning for SPENs", "text": "We now present details for end-to-end training of SPENs. We first describe architectures suitable for backpropating through gradient descent. We then describe considerations for learning SPENs defined for the convex relaxation of discrete labeling problems. Then, we describe how to encourage our models to optimize quickly in practice. Finally, we present methods for improving the speed and memory overhead of SPEN implementations."}, {"heading": "4.1. Architectures", "text": "To train SPENs end-to-end, we write Eq. (5) as:\nyT = Init(F (x))\u2212 T\u2211\nt=1\n\u03b7t d\ndy E(yt ; F (x)). (6)\nHere, Init(\u00b7) is a differentiable procedure for predicting an initial iterate y0. Following Belanger & McCallum (2016), we employ Ex(\u00b7) = E(\u00b7 ; F (x)), where the dependence of Ex(\u00b7) on x comes by way of an arbitrary parametrized feature function F (x). This is useful because test-time prediction can avoid back-propagation through F (x).\nWe assume our energy splits into global and local terms: E(y ;F (x)) = Eg(y ;F (x)) + \u2211 i El(yi ;F (x)). (7)\nHere, i indexes the components of y and Eg(y ;F (x)) is an arbitrary deep network that provides a global function that couples components together. The local term is\nanalogous to the local potentials in an undirected graphical model. We also use the local term to provide an implementation of the Init(\u00b7) network in Eq. (6).\nFor general continuous output problems, we employ El(yi;F (x)) = (yi \u2212 Gi(F (x))2 and Init(F (x)) = Gi(F (x)). For relaxations of discrete problems, we employ El(yi;F (x)) = y>i Gi(F (x)) and Init(F (x)) = SoftMax(Gi(F (x)). In both, Init(\u00b7) returns the expected y under the distribution P(y) \u221d exp(\u2212 \u2211 iE\nl(yi ;F (x))). Gi(\u00b7) may be a learned network with extra parameters.\nWe pretrain our features F (x) by training the feed-forward predictor Init(F (x)). We also stabilize learning by first clamping the local terms for a few epochs while updating Eg(y ;F (x)).\nTo back-propagate through Eq. (6), the energy function must be at least twice differentiable with respect to y. Therefore, we can\u2019t use non-linearities with discontinuous gradients. Instead of ReLUs, we use a SoftPlus with a reasonably high temperature. Note that, F (x) and Init(\u00b7) can be arbitrary networks that are sub-differentiable with respect to their parameters. We compute Hessian-vector products using the finite-difference method of (Domke, 2012), as this allows black-box interaction with the energy.\nOur experiments unroll either Eq. (6) or an analogous version implementing gradient descent with momentum. We avoid the LSTM-based approach of Andrychowicz et al. (2016) because it diminishes the semantics of the energy, since interaction between the optimizer and the energy is complicated and non-linear."}, {"heading": "4.2. End-to-End Learning for Discrete Problems", "text": "To apply SPENs to a discrete structured prediction problem, we relax to a constrained continuous problem, apply SPEN prediction, and then round to a discrete output. For example, for tagging each pixel of a h \u00d7 w image with a binary label, we would relax from {0, 1}w\u00d7h to [0, 1]w\u00d7h, and if the pixels can take on one of D values, we would relax from y \u2208 {0, . . . , D}w\u00d7h to \u2206w\u00d7hD , where \u2206D is the probabilty simplex on D elements.\nWhile this rounding introduces poorly-understood sources of error, it has worked well for multi-label classification (Belanger & McCallum, 2016), sequence tagging (Vilnis et al., 2015), and translation (Hoang et al., 2017).\nBoth [0, 1]w\u00d7h and \u2206w\u00d7hD are Cartesian products of probability simplices. To optimize over them, we can employ existing methods for projected gradient optimization over the simplex.\nFor example, it would be natural to apply Euclidean pro-\njected gradient descent. Over [0, 1], we have:\nyt+1 = Clip0,1 [yt \u2212 \u03b7t\u2207Ex(yt), ] (8)\nThis is unusable for end-to-end learning, however, since back-propagation through the projection will yield 0 gradients whenever yt \u2212 \u03b7t\u2207Ex(yt) /\u2208 [0, 1]. This is similarly problematic for projection onto \u2206w\u00d7hD (Duchi et al., 2008).\nAlternatively, we can apply entropic mirror descent, ie. projected gradient with distance measured by KL divergence (Beck & Teboulle, 2003). For y \u2208 \u2206w\u00d7hD , we have:\nyt+1 = SoftMax (log(yt)\u2212 \u03b7t\u2207Ex(yt)) (9)\nThis is applicable for end-to-end learning. However the updates are similar to a vanilla RNN with sigmoid activations, which is vulnerable to vanishing gradients (Hochreiter et al., 2001).\nInstead, we have found it useful to avoid constrained optimization entirely, by optimizing un-normalized logits lt, with yt = SoftMax(lt):\nlt+1 = lt \u2212 \u03b7t\u2207Ex (SoftMax(lt)) . (10)\nHere, the updates to lt are additive, and thus will be less susceptible to vanishing gradients (Srivastava et al., 2015; He et al., 2016).\nFinally, Amos et al. (2016) present the bundle entropy method for convex optimization with simplex constraints, along with a method for differentiating the output of the optimizer. However, like the implicit function theorem, they assume exact optimization. Also, learning for Eq. (6) can be performed using generic learning software, since the unrolled optimization obeys the API of a feed-forward predictor, but this is not true for their method."}, {"heading": "4.3. Learning to Optimize Quickly", "text": "We next enumerate methods for learning a model such that gradient-based energy minimization converges to highquality y quickly. When using such methods, we have found it important to maintain the same optimization configuration, such as T , at both train and test time.\nFirst, we can encourage rapid optimizaton by defining our loss function as a sum of losses on every iterate yt, rather than only the final one. Let `(yt, y\u2217) be a differentiable loss between an iterate and the ground truth. We employ\nL = 1\nT T\u2211 t=1 wt`(yt, y \u2217), (11)\nwhere wt = 1T\u2212t+1 . This encourages the model to achieve high-quality predictions early. It has the additional benefit\nthat it reduces vanishing gradients, since a learning signal is introduced at every timestep.\nSecond, for the simplex-constrained problems of Sec. 4.2, we smooth the energy with an entropy term \u2211 iH(yi). This introduces extra strong convexity, which helps improve convergence. It also strengthens the parallel between SPEN prediction and marginal inference in a Markov random field, where the inference objective is expected energy plus entropy (Koller & Friedman, 2009).\nThird, we can set T to a small value. Of course, this guarantees that optimization converges quickly on the train data. Here, we lose the contract that Eq. (6) is even performing energy minimization, since it hasn\u2019t converged, but this may be acceptable if predictions are accurate. For example, some experiments achieve good performance with T = 3."}, {"heading": "4.4. Efficient Implementation", "text": "Since we can explicitly encourage our model to converge quickly, it is important to exploit fast convergence at train time. Eq. (6) is unrolled for a fixed T . However, if optimization converges at T0 < T , it suffices to start backpropagation at T0, since the updates to yt for t > T0 are the identity. Therefore, we unroll for a fixed number of iterations T , but iterate only until convergence is detected.\nTo support back-propagation, a naive implementation of Eq. (6) would require T clones of the energy (with tied parameters). We reduce memory overhead by checkpointing the inputs and outputs of the energy, but discarding its internal state. This allows us to use a single copy of the energy, but requires recomputing forward evaluations at specific yt during the backwards pass. This is necessary for our experiments to be able to run on a 12GB GPU. To save additional memory, we could have avoided storing the intermediate iterates yt, and instead reconstructed them on the fly (Maclaurin et al., 2015)."}, {"heading": "5. Image Denoising Experiments", "text": "Let x \u2208 [0, 1]w\u00d7h be an observed grayscale image. We assume that it is a noisy realization of a latent clean image y \u2208 [0, 1]w\u00d7h, which we estimate using MAP inference. Consider a Gaussian noise model with variance \u03c32 and a prior P(y). The associated energy function is:\n\u2016y \u2212 x\u201622 \u2212 \u03c32 logP(y). (12)\nThere are three general families for the prior. First, it can be hard-coded. Second, it can be learned by approximate density estimation. Third, given a collection of {x,y} pairs, we can perform supervised learning, where the prior\u2019s parameters are discriminatively trained such that the output of a particular algorithm for mimimizing Eq. (12) is highquality. End-to-end learning has proven to be highly suc-\ncesful for the third approach (Tappen et al., 2007; Barbu, 2009; Schmidt et al., 2010; Sun & Tappen, 2011; Domke, 2012; Wang et al., 2016), and thus it is important to evaluate the methods of this paper on the task."}, {"heading": "5.1. Image Priors", "text": "Much of the existing work on end-to-end training for denoising considers some form of a field-of-experts (FOE) prior (Roth & Black, 2005). We consider an `1 version, which assigns high probability to images with sparse activations from K learned filters:\nP(y) \u221d exp ( \u2212 \u2211 k \u2016(fk \u2217 y)\u20161 ) . (13)\nWang et al. (2016) perform end-to-end learning for Eq. (13), by unrolling proximal gradient methods that analytically handle the non-differentiable `1 term.\nThis paper assumes we only have black-box interaction with the energy. In response, we alter Eq. (13) such that it is twice differentiable, so that we can unroll generic firstorder optimization methods. We approximate Eq. (13) by leveraging a SoftPlus with temperature, replacing | \u00b7 | with:\nSoftAbs(y) = 0.5 SoftPlus(y) + 0.5 SoftPlus(\u2212y). (14)\nThe principal advantage of learning algorithms that are not hand-crafted to the problem structure is that they provide the opportunity to employ more expressive energies. In response, we also consider a deeper prior, given by:\nP(y) \u221d exp (\u2212DNN(y)) . (15)\nHere, DNN(y) is a general deep convolutional network that takes an image and returns a number. The architecture in our experiments consists of a 7 \u00d7 7 \u00d7 32 convolution, a SoftPlus, another 7 \u00d7 7 \u00d7 32 convolution, a SoftPlus, a 1\u00d7 1\u00d7 1 convolution, and finally spatial average pooling. The method of Wang et al. (2016) can not handle this prior."}, {"heading": "5.2. Experimental Setup", "text": "We evaluate on the 7-Scenes dataset (Newcombe et al., 2011), where we seek to denoise depth measurements from a Kinect sensor. Our data processing and hyperparameters are designed to replicate the setup of Wang et al. (2016), who demonstrate state-of-the art results for energyminimization-based denoising on the dataset. Table 1 summarizes our results for a selection of configurations. Example outputs are given in Figure 1. We train using random 96 \u00d7 128 crops from 200 images of the same scene. We report PSNR for 5500 images from different scenes."}, {"heading": "5.3. Results and Discussion", "text": "The first row of Table 1 presents various baselines. BM3D is a widely-used non-parametric method (Dabov et al., 2007). FilterForest adaptively selects denoising filters for each location (Fanello et al., 2014). ProximalNet is the system of Wang et al. (2016). FOE-20 is an attempt to replicate ProximalNet using end-to-end SPEN learning. We unroll 20 steps of gradient descent with momentum 0.75 and use the modification in Eq. (14). Note it performs similarly to ProximalNet, which unrolls 5 iterations of sophisticated optimization. If we train a feed-forward convnet, using the same architecture as our DNN prior, but without spatial pooling, we obtain 36.95.\nThe next set of results consider improved instances of the FOE model. First, FOE-20+ is identical to FOE-20, except that it employs the average loss Eq. (11), uses a momentum constant of 0.25, and treats the learning rates \u03b7t as trainable parameters. We find that this results in both better performance and faster convergence. Of course, we could achieve fast convergence by simply setting T to be small. In response, we consider FOE-3. This only unrolls for T = 3 iterations and obtains superior performance.\nThe final two results are with the DNN prior Eq. (15). DeepPrior-20 unrolls 20 steps of gradient descent with a momentum constant of 0.25. The gain in performance is substantial, especially considering that a PSNR of 30 can be obtained with elementary signal processing. Similar to FOE-3 vs. FOE-20+, we experience a modest performance gain using DeepPrior-3, which only unrolls for 3 gradient steps but is otherwise identical.\nIn general, it is superior to only unroll for a few iterations. One possible reason is that the shallow depth of the unrolled architecture is easier to train. Truncated optimization with respect to y may also provide an interesting prior over outputs (Duvenaud et al., 2016), which can be particularly useful because the Gaussian noise model assumed in Eq. (12) is not characteristic of the data collection process (Wang et al., 2016). This is consistent with the observation of (Wang et al., 2014) that better energy minimization for FOE models may not improve PSNR. Also, note that unrolling for 20 iterations often results in oversmoothed outputs for all of the configurations.\nFinally, the best performance we could obtain with an input-convex neural network is 39.77, using the same configuration as the DeepPrior-3. When the model takes so few gradient steps, it is unclear whether convexity matters. Note both Eq. (13) and our modification are convex wrt. y."}, {"heading": "6. Semantic Role Labeling Experiments", "text": "Semantic role labeling (SRL) predicts the semantic structure of predicates and arguments in sentences (Gildea & Jurafsky, 2002). For example, in the sentence \u201cI want to buy a car,\u201d the verbs \u201cwant\u201d and \u201cbuy\u201d are two predicates, and \u201cI\u201d is an argument that refers to the wanter and buyer, \u201cto buy a car\u201d is the thing wanted, and \u201ca car\u201d is the thing bought. Given predicates, we seek to identify arguments and their semantic roles in relation to each predicate. Formally, given a set of predicates p in a sentence x and a set of candidate argument spans a, we assign a discrete semantic role r to each pair of predicate and argument, where r can be either a pre-defined role label or an empty label.\nExisting work imposes hard constraints on r, such as excluding overlapping arguments and repeated core roles during prediction. The objective is to minimize the energy:\nmin r E(r ;x,p,a) s.t. r \u2208 Q(x,p,a), (16)\nwhere Q(x,p,a) is set of feasible joint role assignments. This constrained optimization problem can be solved using integer linear programming (ILP) (Punyakanok et al.,\n2008) or its relaxations (Das et al., 2012). These methods rely on the output of local classifiers that are unaware of structural constraints during training. More recently, Ta\u0308ckstro\u0308m et al. (2015) account for the constraint structure using dynamic programming at train time. FitzGerald et al. (2015) extend this using neural network features and show improved results."}, {"heading": "6.1. Data and Preprocessing and Baselines", "text": "We consider the CoNLL 2005 shared task data (Carreras & Ma\u0300rquez, 2005), with standard data splits and official evaluation scripts. We apply similar preprocessing as Ta\u0308ckstro\u0308m et al. (2015). This includes part-of-speech tagging, dependency parsing, and using the parse to generate candidate arguments.\nOur baseline is an arc-factored model for the conditional probability of the predicate-argument arc labels:\nP(r|x,p,a) = \u03a0iP(ri|x,p,a). (17) where P(ri|x,p,a) \u221d exp ( g(ri,x,p,a) ) . Here, each conditional distribution is given by a logistic regression model. We compute g(ri,x,p,a) using a multi-layer perceptron (MLP) similar to FitzGerald et al. (2015). Its inputs are discrete features extracted from the argument span and the predicate (including words, pos tags, and syntactic dependents), and the dependency path and distance between the argument and the predicate. These features are transformed to a 300-dimensional representation linearly, where the embeddings of word types are initialized using newswire embeddings from (Mikolov et al., 2013). We map from 300 dimensions to 250 to 47 (the number of semantic roles in CoNLL) using linear transformations separated by tanh layers. We apply dropout to the embedding layer with rate 0.5, and train using Adam with default settings (Kingma & Ba, 2014) and a standard log loss.\nWhen using the negative log of Eq. (17) as an energy in Eq. (16), there are variety of methods for finding the optimal r \u2208 Q(x,p,a). First, we can employ simple heuristics for locally resolving constraint violation. The Local + H system uses Eq. (17) and these. We can instead use the AD3 message passing algorithm (Martins et al., 2011) to solve the LP relaxation of this constrained problem. We use Local + AD3 to refer to this system. Since the LP relaxation does not guarantee feasible outputs, we post-process the AD3 output using the same heuristics as Local + H."}, {"heading": "6.2. SPEN Model", "text": "We employ a pretrained version of Eq. (17) to provide the local energy term of a SPEN. This is augmented with global terms that couple the outputs together.\nThe SPEN performs continuous optimization over the re-\nlaxed set yi \u2208 \u2206A for each discrete label ri, where A is the number of possible roles. The preprocessing generates sparse predicate-argument candidates, but we optimize over the complete bipartite graph between predicates and arguments to support vectorization. We have y \u2208 \u2206n\u00d7mA , where n and m are the max number of predicates and arguments. Invalid arcs are constrained to the empty label."}, {"heading": "6.2.1. GLOBAL ENERGY TERMS", "text": "From the pre-trained model Eq. (17), we define fr as the predicate-argument arc features, We also have predicate features fp and argument feature fa, given by the average word embedding of the token spans. The hidden layers of any MLP below are 50-dimensional. Each MLP is two layers, with a SoftPlus in the middle. All parameters are trained discriminatively using end-to-end training.\nLet yp \u2208 \u2206mA be the sub-tensor of y for a given predicate p and let zp = \u2211 k yp[:, k] \u2208 [0, 1]m, where zp[a] is the total amount of mass assigned to the arc between predicate p and argument a, obtained by summing over possible labels. We also define wp = \u2211 k yp[k, :] \u2208 RA+. This is a length-A vector containing how much total mass of each arc label is https://www.youtube.com/assigned to predicate p. Finally, define sr = \u2211 k y[:, :, k]. This is the total mass assigned to arc r, obtained by summing over the possible labels that the arc can take on.\nThe global energy is defined by the sum of the following terms. The first energy term scores the set of arguments attached to each predicate. It computes a weighted average of the features fa for the arguments assigned to predicate p, with weights given by zp. It then concatenates this with fp, and passes the result through a two-layer multi-layer perceptron (MLP) that returns a single number. The total energy is the sum of the MLP output for every predicate. The second energy term scores the labels of the arcs attached to each predicate. We concatenate fp with wp and pass this through an MLP as above. The third energy term models how many arguments a predicate should take on. For each predicate, we predict how many arguments should attach to it, using a linear function applied to fp. The energy is set to the squared difference between this and the total mass attached to the predicate under y, which is given by\u2211\nk wp[k]. The fourth energy term averages wp over all p and applies an MLP to the result. The fifth term computes a weighted average of the arc features fr, with weights given by sr and also applies an MLP to the result. The last two terms capture general topical coherence of the prediction."}, {"heading": "6.2.2. CONSTRAINT ENFORCEMENT", "text": "As with Ta\u0308ckstro\u0308m et al. (2015), we seek to account for constraints Q(x,p,a) during both inference and learning, rather than only imposing them via post-processing.\nTherefore, we include additional energy terms that encode membership in Q(x,p,a) as twice-differentiable soft constraints that can be applied to y. All of the constraints in Q(x,p,a) express that certain arcs can not co-occur. For example, two arguments can not attach to the same predicate if the arguments correspond to spans of tokens that overlap. Consider general binary variables a and b with corresponding relaxations a\u0304, b\u0304 \u2208 [0, 1]. We convert the constraint\u00ac(a\u2227b) into an energy function \u03b1SoftPlus(a\u0304+b\u0304\u22121), where \u03b1 is a learned parameter.\nWe consider SPEN + H and SPEN + AD3, which employ heuristics or AD3 to enforce the output constraints. Rather than applying these methods to the probabilities from Eq. (17), we use the output of energy minimization."}, {"heading": "6.3. Results and Discussion", "text": "Table 2 contains results on the CoNLL 2005 WSJ dev and test sets and the Brown test set. We compare the SPEN systems and Local systems and the best non-ensemble systems of Ta\u0308ckstro\u0308m et al. (2015) and FitzGerald et al. (2015), which have similar overall setups as us. Note that Zhou & Xu (2015) obtain slightly better performance using alternative methods.\nFor these, \u2018Local\u2019 refers to fitting Eq. (17) without regard for the output constraints, whereas \u2018Structured\u2019 explicitly considers them during training. We select our SPEN configuration by maximizing performance of SPEN + AD3 on the dev data. Our best system unrolls for 10 iterations, trains per-iteration learning rates, uses no momentum, and unrolls Eq. (10). Here, we do not use entropy smoothing. However, the same performance on the WSJ test set (but slightly worse on the dev set) can be obtained using entropy smoothing and only 5 unrolled iterations.\nOverall, SPEN + AD3 performs the best of all systems on the WSJ test data. We expect our diminished performance on the Brown test set is due to overfitting. The Brown set is not from the same source as the train, dev, and test WSJ data. SPENs are more susceptible to overfitting because the expressive global term introduces many parameters.\nNote that SPEN + AD3 and SPEN + H performs identically, whereas LOCAL + AD3 and LOCAL + H do not. This is because our learned global energy encourages constraint satisfaction during gradient-based optimization of y. Using the method of Amos et al. (2016) for restricting the energy to be convex wrt y, we obtain 80.2 on the test set. When taking so few gradient steps, it is hard to understand the impact of convex energies."}, {"heading": "7. Conclusion and Future Work", "text": "SPENs are a flexible, expressive framework for structured prediction. This paper provides a new training method that allows them to be applied to considerably more complex tasks than those of Belanger & McCallum (2016). We unroll an approximate energy minimization algorithm into a fixed-size computation graph that is trainable by gradient descent. In our experiments, good performance can often be achieved using just a few gradient steps on the energy surface. We encourage future work exploring properties of this truncated optimization. We also would like to perform iterative optimization in a learned feature space, rather than output space, as in Nguyen et al. (2016)."}], "references": [{"title": "Input convex neural networks", "author": ["Amos", "Brandon", "Xu", "Lei", "Kolter", "J Zico"], "venue": "arXiv preprint:", "citeRegEx": "Amos et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Amos et al\\.", "year": 2016}, {"title": "Learning to learn by gradient descent by gradient descent", "author": ["Andrychowicz", "Marcin", "Denil", "Misha", "Gomez", "Sergio", "Hoffman", "Matthew W", "Pfau", "David", "Schaul", "Tom", "de Freitas", "Nando"], "venue": null, "citeRegEx": "Andrychowicz et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Andrychowicz et al\\.", "year": 2016}, {"title": "Training an active random field for realtime image denoising", "author": ["Barbu", "Adrian"], "venue": "IEEE Transactions on Image Processing,", "citeRegEx": "Barbu and Adrian.,? \\Q2009\\E", "shortCiteRegEx": "Barbu and Adrian.", "year": 2009}, {"title": "Mirror descent and nonlinear projected subgradient methods for convex optimization", "author": ["Beck", "Amir", "Teboulle", "Marc"], "venue": "Operations Research Letters,", "citeRegEx": "Beck et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Beck et al\\.", "year": 2003}, {"title": "Structured prediction energy networks", "author": ["Belanger", "David", "McCallum", "Andrew"], "venue": "In ICML,", "citeRegEx": "Belanger et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Belanger et al\\.", "year": 2016}, {"title": "Training energy-based models for time-series", "author": ["Brakel", "Phil\u00e9mon", "Stroobandt", "Dirk", "Schrauwen", "Benjamin"], "venue": "imputation. JMLR,", "citeRegEx": "Brakel et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Brakel et al\\.", "year": 2013}, {"title": "Introduction to the conll-2005 shared task: Semantic role labeling", "author": ["Carreras", "Xavier", "M\u00e0rquez", "Llu\u0131\u0301s"], "venue": "In CoNLL,", "citeRegEx": "Carreras et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Carreras et al\\.", "year": 2005}, {"title": "Image denoising by sparse 3-d transform-domain collaborative filtering", "author": ["Dabov", "Kostadin", "Foi", "Alessandro", "Katkovnik", "Vladimir", "Egiazarian", "Karen"], "venue": "IEEE Transactions on image processing,", "citeRegEx": "Dabov et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Dabov et al\\.", "year": 2007}, {"title": "An exact dual decomposition algorithm for shallow semantic parsing with constraints", "author": ["Das", "Dipanjan", "Martins", "Andr\u00e9 FT", "Smith", "Noah A"], "venue": "In Conference on Lexical and Computational Semantics,", "citeRegEx": "Das et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Das et al\\.", "year": 2012}, {"title": "Generic methods for optimization-based modeling", "author": ["Domke", "Justin"], "venue": "In AISTATS,", "citeRegEx": "Domke and Justin.,? \\Q2012\\E", "shortCiteRegEx": "Domke and Justin.", "year": 2012}, {"title": "Learning graphical model parameters with approximate marginal inference", "author": ["Domke", "Justin"], "venue": "Pattern Analysis and Machine Intelligence,", "citeRegEx": "Domke and Justin.,? \\Q2013\\E", "shortCiteRegEx": "Domke and Justin.", "year": 2013}, {"title": "Efficient projections onto the l 1-ball for learning in high dimensions", "author": ["Duchi", "John", "Shalev-Shwartz", "Shai", "Singer", "Yoram", "Chandra", "Tushar"], "venue": "In ICML,", "citeRegEx": "Duchi et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Duchi et al\\.", "year": 2008}, {"title": "Early stopping as nonparametric variational inference", "author": ["Duvenaud", "David", "Maclaurin", "Dougal", "Adams", "Ryan P"], "venue": "In AISTATS,", "citeRegEx": "Duvenaud et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Duvenaud et al\\.", "year": 2016}, {"title": "Filter forests for learning datadependent convolutional kernels", "author": ["Fanello", "Sean Ryan", "Keskin", "Cem", "Kohli", "Pushmeet", "Izadi", "Shahram", "Shotton", "Jamie", "Criminisi", "Antonio", "Pattacini", "Ugo", "Paek", "Tim"], "venue": "In CVPR,", "citeRegEx": "Fanello et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Fanello et al\\.", "year": 2014}, {"title": "Training structural svms when exact inference is intractable", "author": ["Finley", "Thomas", "Joachims", "Thorsten"], "venue": "In ICML,", "citeRegEx": "Finley et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Finley et al\\.", "year": 2008}, {"title": "Semantic role labeling with neural network factors", "author": ["FitzGerald", "Nicholas", "T\u00e4ckstr\u00f6m", "Oscar", "Ganchev", "Kuzman", "Das", "Dipanjan"], "venue": "In EMNLP, pp", "citeRegEx": "FitzGerald et al\\.,? \\Q2015\\E", "shortCiteRegEx": "FitzGerald et al\\.", "year": 2015}, {"title": "Efficient multiple hyperparameter learning for log-linear models", "author": ["Foo", "Chuan-sheng", "Do", "Chuong B", "Ng", "Andrew Y"], "venue": "In NIPS, pp", "citeRegEx": "Foo et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Foo et al\\.", "year": 2008}, {"title": "Automatic labeling of semantic roles", "author": ["Gildea", "Daniel", "Jurafsky"], "venue": "Computational linguistics,", "citeRegEx": "Gildea et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Gildea et al\\.", "year": 2002}, {"title": "Deep Learning", "author": ["Goodfellow", "Ian", "Bengio", "Yoshua", "Courville", "Aaron"], "venue": null, "citeRegEx": "Goodfellow et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Goodfellow et al\\.", "year": 2016}, {"title": "Highway and residual networks learn unrolled iterative estimation", "author": ["Greff", "Klaus", "Srivastava", "Rupesh K", "Schmidhuber", "J\u00fcrgen"], "venue": null, "citeRegEx": "Greff et al\\.,? \\Q2017\\E", "shortCiteRegEx": "Greff et al\\.", "year": 2017}, {"title": "Learning fast approximations of sparse coding", "author": ["Gregor", "Karol", "LeCun", "Yann"], "venue": "In ICML,", "citeRegEx": "Gregor et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Gregor et al\\.", "year": 2010}, {"title": "Deep residual learning for image recognition", "author": ["He", "Kaiming", "Zhang", "Xiangyu", "Ren", "Shaoqing", "Sun", "Jian"], "venue": null, "citeRegEx": "He et al\\.,? \\Q2016\\E", "shortCiteRegEx": "He et al\\.", "year": 2016}, {"title": "Unsupervised discovery of nonlinear structure using contrastive backpropagation", "author": ["Hinton", "Geoffrey", "Osindero", "Simon", "Welling", "Max", "Teh", "Yee-Whye"], "venue": "Cognitive science,", "citeRegEx": "Hinton et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Hinton et al\\.", "year": 2006}, {"title": "Decoding as continuous optimization in neural machine translation", "author": ["Hoang", "Cong Duy Vu", "Haffari", "Gholamreza", "Cohn", "Trevor"], "venue": "arXiv preprint:1701.02854,", "citeRegEx": "Hoang et al\\.,? \\Q2017\\E", "shortCiteRegEx": "Hoang et al\\.", "year": 2017}, {"title": "Long shortterm memory", "author": ["Hochreiter", "Sepp", "Schmidhuber", "J\u00fcrgen"], "venue": "Neural computation,", "citeRegEx": "Hochreiter et al\\.,? \\Q1997\\E", "shortCiteRegEx": "Hochreiter et al\\.", "year": 1997}, {"title": "Gradient flow in recurrent nets: the difficulty of learning", "author": ["Hochreiter", "Sepp", "Bengio", "Yoshua", "Frasconi", "Paolo", "Schmidhuber", "J\u00fcrgen"], "venue": "long-term dependencies,", "citeRegEx": "Hochreiter et al\\.,? \\Q2001\\E", "shortCiteRegEx": "Hochreiter et al\\.", "year": 2001}, {"title": "Adam: A method for stochastic optimization", "author": ["Kingma", "Diederik", "Ba", "Jimmy"], "venue": "arXiv preprint arXiv:1412.6980,", "citeRegEx": "Kingma et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Kingma et al\\.", "year": 2014}, {"title": "Probabilistic graphical models: principles and techniques", "author": ["Koller", "Daphne", "Friedman", "Nir"], "venue": "MIT press,", "citeRegEx": "Koller et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Koller et al\\.", "year": 2009}, {"title": "Conditional random fields: Probabilistic models for segmenting and labeling sequence data", "author": ["Lafferty", "John D", "McCallum", "Andrew", "Pereira", "Fernando CN"], "venue": "In ICML,", "citeRegEx": "Lafferty et al\\.,? \\Q2001\\E", "shortCiteRegEx": "Lafferty et al\\.", "year": 2001}, {"title": "A tutorial on energy-based learning", "author": ["LeCun", "Yann", "Chopra", "Sumit", "Hadsell", "Raia", "M Ranzato", "F. Huang"], "venue": "Predicting Structured Data,", "citeRegEx": "LeCun et al\\.,? \\Q2006\\E", "shortCiteRegEx": "LeCun et al\\.", "year": 2006}, {"title": "Gradient-based hyperparameter optimization through reversible learning", "author": ["Maclaurin", "Dougal", "Duvenaud", "David", "Adams", "Ryan P"], "venue": "In ICML,", "citeRegEx": "Maclaurin et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Maclaurin et al\\.", "year": 2015}, {"title": "An augmented lagrangian approach to constrained map inference", "author": ["Martins", "Andr\u00e9 FT", "Figeuiredo", "Mario AT", "Aguiar", "Pedro MQ", "Smith", "Noah A", "Xing", "Eric P"], "venue": "In ICML,", "citeRegEx": "Martins et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Martins et al\\.", "year": 2011}, {"title": "Unrolled generative adversarial networks", "author": ["Metz", "Luke", "Poole", "Ben", "Pfau", "David", "Sohl-Dickstein", "Jascha"], "venue": null, "citeRegEx": "Metz et al\\.,? \\Q2017\\E", "shortCiteRegEx": "Metz et al\\.", "year": 2017}, {"title": "Distributed representations of words and phrases and their compositionality", "author": ["Mikolov", "Tomas", "Sutskever", "Ilya", "Chen", "Kai", "Corrado", "Greg S", "Dean", "Jeff"], "venue": "In NIPS,", "citeRegEx": "Mikolov et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Mikolov et al\\.", "year": 2013}, {"title": "Learning nonlinear constraints with contrastive backpropagation", "author": ["Mnih", "Andriy", "Hinton", "Geoffrey"], "venue": "In IJCNN,", "citeRegEx": "Mnih et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Mnih et al\\.", "year": 2005}, {"title": "Learning deep energy models", "author": ["Ngiam", "Jiquan", "Chen", "Zhenghao", "Koh", "Pang W", "Ng", "Andrew Y"], "venue": "In ICML,", "citeRegEx": "Ngiam et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Ngiam et al\\.", "year": 2011}, {"title": "Plug & play generative networks: Conditional iterative generation of images in latent space", "author": ["Nguyen", "Anh", "Yosinski", "Jason", "Bengio", "Yoshua", "Dosovitskiy", "Alexey", "Clune", "Jeff"], "venue": "arXiv pre-print", "citeRegEx": "Nguyen et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Nguyen et al\\.", "year": 2016}, {"title": "Fast exact multiplication by the hessian", "author": ["Pearlmutter", "Barak A"], "venue": "Neural computation,", "citeRegEx": "Pearlmutter and A.,? \\Q1994\\E", "shortCiteRegEx": "Pearlmutter and A.", "year": 1994}, {"title": "The importance of syntactic parsing and inference in semantic role labeling", "author": ["Punyakanok", "Vasin", "Roth", "Dan", "Yih", "Wen-tau"], "venue": "Computational Linguistics,", "citeRegEx": "Punyakanok et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Punyakanok et al\\.", "year": 2008}, {"title": "Fields of experts: A framework for learning image priors", "author": ["Roth", "Stefan", "Black", "Michael J"], "venue": "In CVPR,", "citeRegEx": "Roth et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Roth et al\\.", "year": 2005}, {"title": "Learning optimized map estimates in continuously-valued mrf models", "author": ["Samuel", "Kegan GG", "Tappen", "Marshall F"], "venue": "In CVPR,", "citeRegEx": "Samuel et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Samuel et al\\.", "year": 2009}, {"title": "A generative perspective on mrfs in low-level vision", "author": ["Schmidt", "Uwe", "Gao", "Qi", "Roth", "Stefan"], "venue": "In CVPR,", "citeRegEx": "Schmidt et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Schmidt et al\\.", "year": 2010}, {"title": "Training very deep networks", "author": ["Srivastava", "Rupesh K", "Greff", "Klaus", "Schmidhuber", "J\u00fcrgen"], "venue": "In NIPS,", "citeRegEx": "Srivastava et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Srivastava et al\\.", "year": 2015}, {"title": "Empirical risk minimization of graphical model parameters given approximate inference, decoding, and model structure", "author": ["Stoyanov", "Veselin", "Ropson", "Alexander", "Eisner", "Jason"], "venue": "In AISTATS,", "citeRegEx": "Stoyanov et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Stoyanov et al\\.", "year": 2011}, {"title": "Learning non-local range markov random field for image restoration", "author": ["Sun", "Jian", "Tappen", "Marshall F"], "venue": "In CVPR,", "citeRegEx": "Sun et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Sun et al\\.", "year": 2011}, {"title": "Efficient inference and structured learning for semantic role labeling", "author": ["T\u00e4ckstr\u00f6m", "Oscar", "Ganchev", "Kuzman", "Das", "Dipanjan"], "venue": "TACL,", "citeRegEx": "T\u00e4ckstr\u00f6m et al\\.,? \\Q2015\\E", "shortCiteRegEx": "T\u00e4ckstr\u00f6m et al\\.", "year": 2015}, {"title": "Learning gaussian conditional random fields for low-level vision", "author": ["Tappen", "Marshall F", "Liu", "Ce", "Adelson", "Edward H", "Freeman", "William T"], "venue": "In CVPR,", "citeRegEx": "Tappen et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Tappen et al\\.", "year": 2007}, {"title": "Support vector machine learning for interdependent and structured output spaces", "author": ["Tsochantaridis", "Ioannis", "Hofmann", "Thomas", "Joachims", "Thorsten", "Altun", "Yasemin"], "venue": "In ICML,", "citeRegEx": "Tsochantaridis et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Tsochantaridis et al\\.", "year": 2004}, {"title": "Bethe projections for non-local inference", "author": ["Vilnis", "Luke", "Belanger", "David", "Sheldon", "Daniel", "McCallum", "Andrew"], "venue": null, "citeRegEx": "Vilnis et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Vilnis et al\\.", "year": 2015}, {"title": "A connection between score matching and denoising autoencoders", "author": ["Vincent", "Pascal"], "venue": "Neural Computation,", "citeRegEx": "Vincent and Pascal.,? \\Q2011\\E", "shortCiteRegEx": "Vincent and Pascal.", "year": 2011}, {"title": "Efficient inference of continuous markov random fields with polynomial potentials", "author": ["Wang", "Shenlong", "Schwing", "Alex", "Urtasun", "Raquel"], "venue": "In NIPS,", "citeRegEx": "Wang et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Wang et al\\.", "year": 2014}, {"title": "Proximal deep structured models", "author": ["Wang", "Shenlong", "Fidler", "Sanja", "Urtasun", "Raquel"], "venue": "In NIPS,", "citeRegEx": "Wang et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Wang et al\\.", "year": 2016}, {"title": "Deep structured energy based models for anomaly detection", "author": ["Zhai", "Shuangfei", "Cheng", "Yu", "Lu", "Weining", "Zhang", "Zhongfei"], "venue": "In ICML,", "citeRegEx": "Zhai et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Zhai et al\\.", "year": 2016}, {"title": "End-to-end learning of semantic role labeling using recurrent neural networks", "author": ["Zhou", "Jie", "Xu", "Wei"], "venue": "In ACL, pp", "citeRegEx": "Zhou et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Zhou et al\\.", "year": 2015}], "referenceMentions": [{"referenceID": 29, "context": "Instead, it can be advantageous to define the prediction function implicitly, via energy minimization (LeCun et al., 2006):", "startOffset": 102, "endOffset": 122}, {"referenceID": 28, "context": "conditional random fields (CRFs) (Lafferty et al., 2001) and many recurrent neural networks.", "startOffset": 33, "endOffset": 56}, {"referenceID": 47, "context": "Belanger & McCallum (2016) train SPENs using a structured SVM (SSVM) loss (Taskar et al., 2004; Tsochantaridis et al., 2004) and achieve competitive performance ar X iv :1 70 3.", "startOffset": 74, "endOffset": 124}, {"referenceID": 5, "context": "End-to-end training for gradient-based prediction was introduced in Domke (2012) and applied to deep energy models by Brakel et al. (2013).", "startOffset": 118, "endOffset": 139}, {"referenceID": 51, "context": "This provides substantial performance improvements, from 36 to 40 PSNR, over the state-of-the-art, which unrolls more sophisticated optimization than us, but uses a simpler prior (Wang et al., 2016) .", "startOffset": 179, "endOffset": 198}, {"referenceID": 18, "context": "Approximate energy minimization can be performed using search in the space of prefixes of y using beam search or greedy search (Goodfellow et al., 2016).", "startOffset": 127, "endOffset": 152}, {"referenceID": 22, "context": "In contrastive backprop, this is circumvented by performing contrastive divergence training, with Hamiltonian Monte Carlo sampling from the energy surface (Mnih & Hinton, 2005; Hinton et al., 2006; Ngiam et al., 2011).", "startOffset": 155, "endOffset": 217}, {"referenceID": 35, "context": "In contrastive backprop, this is circumvented by performing contrastive divergence training, with Hamiltonian Monte Carlo sampling from the energy surface (Mnih & Hinton, 2005; Hinton et al., 2006; Ngiam et al., 2011).", "startOffset": 155, "endOffset": 217}, {"referenceID": 22, "context": "In contrastive backprop, this is circumvented by performing contrastive divergence training, with Hamiltonian Monte Carlo sampling from the energy surface (Mnih & Hinton, 2005; Hinton et al., 2006; Ngiam et al., 2011). Recently, Zhai et al. (2016) trained energy-based density models for anomaly detection by exploiting the connections between denosing autoencoders, energy-based models, and score matching (Vincent, 2011).", "startOffset": 177, "endOffset": 248}, {"referenceID": 47, "context": "Belanger & McCallum (2016) employ a structured SVM (SSVM) loss (Taskar et al., 2004; Tsochantaridis et al., 2004): \u2211", "startOffset": 63, "endOffset": 113}, {"referenceID": 16, "context": "The implicit function theorem offers an alternative framework for training energy-based predictors (Foo et al., 2008; Samuel & Tappen, 2009).", "startOffset": 99, "endOffset": 140}, {"referenceID": 16, "context": "The implicit function theorem offers an alternative framework for training energy-based predictors (Foo et al., 2008; Samuel & Tappen, 2009). See Domke (2012) for an overview.", "startOffset": 100, "endOffset": 159}, {"referenceID": 0, "context": "Amos et al. (2016) present inputconvex neural networks (ICNNs), which employ an easyto-implement method for constraining the parameters of a SPEN such that the energy is convex with respect to y, but perhaps non-convex with respect to the parameters.", "startOffset": 0, "endOffset": 19}, {"referenceID": 30, "context": "Instead, we draw on prior work for end-to-end learning of gradient-based predictors (Gregor & LeCun, 2010; Domke, 2012; Maclaurin et al., 2015; Andrychowicz et al., 2016; Wang et al., 2016; Metz et al., 2017; Greff et al., 2017).", "startOffset": 84, "endOffset": 228}, {"referenceID": 1, "context": "Instead, we draw on prior work for end-to-end learning of gradient-based predictors (Gregor & LeCun, 2010; Domke, 2012; Maclaurin et al., 2015; Andrychowicz et al., 2016; Wang et al., 2016; Metz et al., 2017; Greff et al., 2017).", "startOffset": 84, "endOffset": 228}, {"referenceID": 51, "context": "Instead, we draw on prior work for end-to-end learning of gradient-based predictors (Gregor & LeCun, 2010; Domke, 2012; Maclaurin et al., 2015; Andrychowicz et al., 2016; Wang et al., 2016; Metz et al., 2017; Greff et al., 2017).", "startOffset": 84, "endOffset": 228}, {"referenceID": 32, "context": "Instead, we draw on prior work for end-to-end learning of gradient-based predictors (Gregor & LeCun, 2010; Domke, 2012; Maclaurin et al., 2015; Andrychowicz et al., 2016; Wang et al., 2016; Metz et al., 2017; Greff et al., 2017).", "startOffset": 84, "endOffset": 228}, {"referenceID": 19, "context": "Instead, we draw on prior work for end-to-end learning of gradient-based predictors (Gregor & LeCun, 2010; Domke, 2012; Maclaurin et al., 2015; Andrychowicz et al., 2016; Wang et al., 2016; Metz et al., 2017; Greff et al., 2017).", "startOffset": 84, "endOffset": 228}, {"referenceID": 43, "context": "This is a form of direct risk minimization (Stoyanov et al., 2011; Domke, 2013).", "startOffset": 43, "endOffset": 79}, {"referenceID": 1, "context": "Andrychowicz et al. (2016) also unroll gradient-descent, but employ a generic LSTM (Hochreiter & Schmidhuber, 1997), with per-coordinate updates to y.", "startOffset": 0, "endOffset": 27}, {"referenceID": 1, "context": "We avoid the LSTM-based approach of Andrychowicz et al. (2016) because it diminishes the semantics of the energy, since interaction between the optimizer and the energy is complicated and non-linear.", "startOffset": 36, "endOffset": 63}, {"referenceID": 48, "context": "While this rounding introduces poorly-understood sources of error, it has worked well for multi-label classification (Belanger & McCallum, 2016), sequence tagging (Vilnis et al., 2015), and translation (Hoang et al.", "startOffset": 163, "endOffset": 184}, {"referenceID": 23, "context": ", 2015), and translation (Hoang et al., 2017).", "startOffset": 25, "endOffset": 45}, {"referenceID": 11, "context": "This is similarly problematic for projection onto \u2206w\u00d7h D (Duchi et al., 2008).", "startOffset": 57, "endOffset": 77}, {"referenceID": 25, "context": "However the updates are similar to a vanilla RNN with sigmoid activations, which is vulnerable to vanishing gradients (Hochreiter et al., 2001).", "startOffset": 118, "endOffset": 143}, {"referenceID": 42, "context": "Here, the updates to lt are additive, and thus will be less susceptible to vanishing gradients (Srivastava et al., 2015; He et al., 2016).", "startOffset": 95, "endOffset": 137}, {"referenceID": 21, "context": "Here, the updates to lt are additive, and thus will be less susceptible to vanishing gradients (Srivastava et al., 2015; He et al., 2016).", "startOffset": 95, "endOffset": 137}, {"referenceID": 0, "context": "Finally, Amos et al. (2016) present the bundle entropy method for convex optimization with simplex constraints, along with a method for differentiating the output of the optimizer.", "startOffset": 9, "endOffset": 28}, {"referenceID": 30, "context": "To save additional memory, we could have avoided storing the intermediate iterates yt, and instead reconstructed them on the fly (Maclaurin et al., 2015).", "startOffset": 129, "endOffset": 153}, {"referenceID": 46, "context": "cesful for the third approach (Tappen et al., 2007; Barbu, 2009; Schmidt et al., 2010; Sun & Tappen, 2011; Domke, 2012; Wang et al., 2016), and thus it is important to evaluate the methods of this paper on the task.", "startOffset": 30, "endOffset": 138}, {"referenceID": 41, "context": "cesful for the third approach (Tappen et al., 2007; Barbu, 2009; Schmidt et al., 2010; Sun & Tappen, 2011; Domke, 2012; Wang et al., 2016), and thus it is important to evaluate the methods of this paper on the task.", "startOffset": 30, "endOffset": 138}, {"referenceID": 51, "context": "cesful for the third approach (Tappen et al., 2007; Barbu, 2009; Schmidt et al., 2010; Sun & Tappen, 2011; Domke, 2012; Wang et al., 2016), and thus it is important to evaluate the methods of this paper on the task.", "startOffset": 30, "endOffset": 138}, {"referenceID": 50, "context": "The method of Wang et al. (2016) can not handle this prior.", "startOffset": 14, "endOffset": 33}, {"referenceID": 50, "context": "Our data processing and hyperparameters are designed to replicate the setup of Wang et al. (2016), who demonstrate state-of-the art results for energyminimization-based denoising on the dataset.", "startOffset": 79, "endOffset": 98}, {"referenceID": 7, "context": "BM3D is a widely-used non-parametric method (Dabov et al., 2007).", "startOffset": 44, "endOffset": 64}, {"referenceID": 13, "context": "FilterForest adaptively selects denoising filters for each location (Fanello et al., 2014).", "startOffset": 68, "endOffset": 90}, {"referenceID": 7, "context": "BM3D is a widely-used non-parametric method (Dabov et al., 2007). FilterForest adaptively selects denoising filters for each location (Fanello et al., 2014). ProximalNet is the system of Wang et al. (2016). FOE-20 is an attempt to replicate ProximalNet using end-to-end SPEN learning.", "startOffset": 45, "endOffset": 206}, {"referenceID": 12, "context": "Truncated optimization with respect to y may also provide an interesting prior over outputs (Duvenaud et al., 2016), which can be particularly useful because the Gaussian noise model assumed in Eq.", "startOffset": 92, "endOffset": 115}, {"referenceID": 51, "context": "(12) is not characteristic of the data collection process (Wang et al., 2016).", "startOffset": 58, "endOffset": 77}, {"referenceID": 50, "context": "This is consistent with the observation of (Wang et al., 2014) that better energy minimization for FOE models may not improve PSNR.", "startOffset": 43, "endOffset": 62}, {"referenceID": 38, "context": "This constrained optimization problem can be solved using integer linear programming (ILP) (Punyakanok et al., 2008) or its relaxations (Das et al.", "startOffset": 91, "endOffset": 116}, {"referenceID": 8, "context": ", 2008) or its relaxations (Das et al., 2012).", "startOffset": 27, "endOffset": 45}, {"referenceID": 8, "context": ", 2008) or its relaxations (Das et al., 2012). These methods rely on the output of local classifiers that are unaware of structural constraints during training. More recently, T\u00e4ckstr\u00f6m et al. (2015) account for the constraint structure using dynamic programming at train time.", "startOffset": 28, "endOffset": 200}, {"referenceID": 8, "context": ", 2008) or its relaxations (Das et al., 2012). These methods rely on the output of local classifiers that are unaware of structural constraints during training. More recently, T\u00e4ckstr\u00f6m et al. (2015) account for the constraint structure using dynamic programming at train time. FitzGerald et al. (2015) extend this using neural network features and show improved results.", "startOffset": 28, "endOffset": 303}, {"referenceID": 45, "context": "We apply similar preprocessing as T\u00e4ckstr\u00f6m et al. (2015). This includes part-of-speech tagging, dependency parsing, and using the parse to generate candidate arguments.", "startOffset": 34, "endOffset": 58}, {"referenceID": 33, "context": "These features are transformed to a 300-dimensional representation linearly, where the embeddings of word types are initialized using newswire embeddings from (Mikolov et al., 2013).", "startOffset": 159, "endOffset": 181}, {"referenceID": 15, "context": "We compute g(ri,x,p,a) using a multi-layer perceptron (MLP) similar to FitzGerald et al. (2015). Its inputs are discrete features extracted from the argument span and the predicate (including words, pos tags, and syntactic dependents), and the dependency path and distance between the argument and the predicate.", "startOffset": 71, "endOffset": 96}, {"referenceID": 31, "context": "We can instead use the AD message passing algorithm (Martins et al., 2011) to solve the LP relaxation of this constrained problem.", "startOffset": 52, "endOffset": 74}, {"referenceID": 45, "context": "As with T\u00e4ckstr\u00f6m et al. (2015), we seek to account for constraints Q(x,p,a) during both inference and learning, rather than only imposing them via post-processing.", "startOffset": 8, "endOffset": 32}, {"referenceID": 44, "context": "We compare the SPEN systems and Local systems and the best non-ensemble systems of T\u00e4ckstr\u00f6m et al. (2015) and FitzGerald et al.", "startOffset": 83, "endOffset": 107}, {"referenceID": 15, "context": "(2015) and FitzGerald et al. (2015), which have similar overall setups as us.", "startOffset": 11, "endOffset": 36}, {"referenceID": 15, "context": "(2015) and FitzGerald et al. (2015), which have similar overall setups as us. Note that Zhou & Xu (2015) obtain slightly better performance using alternative methods.", "startOffset": 11, "endOffset": 105}, {"referenceID": 0, "context": "Using the method of Amos et al. (2016) for restricting the energy to be convex wrt y, we obtain 80.", "startOffset": 20, "endOffset": 39}, {"referenceID": 36, "context": "We also would like to perform iterative optimization in a learned feature space, rather than output space, as in Nguyen et al. (2016).", "startOffset": 113, "endOffset": 134}], "year": 2017, "abstractText": "Structured Prediction Energy Networks (Belanger & McCallum, 2016) (SPENs) are a simple, yet expressive family of structured prediction models. An energy function over candidate structured outputs is given by a deep network, and predictions are formed by gradient-based optimization. Unfortunately, we have struggled to apply the structured SVM (SSVM) learning method of Belanger & McCallum (2016) to applications with more complex structure than multi-label classification. In general, SSVMs are unreliable whenever exact energy minimization is intractable. In response, we present end-to-end learning for SPENs, where the energy function is discriminatively trained by back-propagating through gradient-based prediction. This paper presents a collection of methods necessary to apply the technique to problems with complex structure. For example, we avoid vanishing gradients when learning SPENs for convex relaxations of discrete prediction problems and explicitly train models such that energy minimization converges quickly in practice. Using end-to-end learning, we demonstrate the power of SPENs on 7-Scenes image denoising and CoNLL-2005 semantic role labeling tasks. In both, we outperform competitive baselines that employ more simplistic energy functions, but perform exact energy minimization. In particular, for denoising we achieve 40 PSNR, outperforming the previous state-of-the-art of 36.", "creator": "LaTeX with hyperref package"}}}