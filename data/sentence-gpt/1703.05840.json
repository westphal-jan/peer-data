{"id": "1703.05840", "review": {"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "16-Mar-2017", "title": "Conditional Accelerated Lazy Stochastic Gradient Descent", "abstract": "In this work we introduce a conditional accelerated lazy stochastic gradient descent algorithm with optimal number of calls to a stochastic first-order oracle and convergence rate $O\\left(\\frac{1}{\\varepsilon^2}\\right)$ improving over the projection-free, Online Frank-Wolfe based stochastic gradient descent of Hazan and Kale [2012] with convergence rate $O\\left(\\frac{1}{\\varepsilon^4}\\right)$. If all those operations have an algorithm with the optimization-free, Online Frank-Wolfe based linear regression of all of the calls to a stochastic first-order oracle to a stochastic first-order oracle and convergence rate $O\\left(\\frac{1}{\\varepsilon^5}\\right)$ and over all of the calls to a stochastic first-order oracle to a stochastic first-order oracle and convergence rate $O\\left(\\frac{1}{\\varepsilon^6}\\right)$ and over all of the calls to a stochastic first-order oracle and convergence rate $O\\left(\\frac{1}{\\varepsilon^7}\\right)$ and over all of the calls to a stochastic first-order oracle and convergence rate $O\\left(\\frac{1}{\\varepsilon^8}\\right)$ and over all of the calls to a stochastic first-order oracle and convergence rate $O\\left(\\frac{1}{\\varepsilon^9}\\right)$ and over all of the calls to a stochastic first-order oracle and convergence rate $O\\left(\\frac{1}{\\varepsilon^10}\\right)$ and over all of the calls to a stochastic first-order oracle and convergence rate $O\\left(\\frac{1}{\\varepsilon^11}\\right)$ and over all of the calls to a stochastic first-order oracle and convergence rate $O\\left(\\frac{1}{\\varepsilon^12}\\right)$ and over all of the calls to a stochastic first-order oracle and convergence rate $O\\left(\\frac{1}{\\varepsilon^13}\\right)$ and over all of the calls to a stochastic first-order oracle and convergence", "histories": [["v1", "Thu, 16 Mar 2017 22:15:17 GMT  (4860kb,D)", "http://arxiv.org/abs/1703.05840v1", "33 pages, 9 figures"], ["v2", "Fri, 24 Mar 2017 20:28:16 GMT  (4861kb,D)", "http://arxiv.org/abs/1703.05840v2", "33 pages, 9 figures"], ["v3", "Wed, 5 Apr 2017 13:24:06 GMT  (4861kb,D)", "http://arxiv.org/abs/1703.05840v3", "33 pages, 9 figures"], ["v4", "Mon, 10 Apr 2017 16:43:11 GMT  (4861kb,D)", "http://arxiv.org/abs/1703.05840v4", "33 pages, 9 figures"]], "COMMENTS": "33 pages, 9 figures", "reviews": [], "SUBJECTS": "cs.LG stat.ML", "authors": ["guanghui lan", "sebastian pokutta", "yi zhou", "daniel zink"], "accepted": true, "id": "1703.05840"}, "pdf": {"name": "1703.05840.pdf", "metadata": {"source": "META", "title": "Conditional Accelerated Lazy Stochastic Gradient Descent", "authors": ["Guanghui Lan", "Sebastian Pokutta", "Yi Zhou", "Daniel Zink"], "emails": ["george.lan@isye.gatech.edu", "sebastian.pokutta@isye.gatech.edu", "yizhou@gatech.edu", "daniel.zink@gatech.edu"], "sections": [{"heading": null, "text": "\u03b52 )\nimproving over the projection-free, Online Frank-Wolfe based stochastic gradient descent of Hazan and Kale [2012] with convergence rate O( 1\n\u03b54 )."}, {"heading": "1 Introduction", "text": "The conditional gradient method (also known as: Frank-Wolfe algorithm) proposed in Frank and Wolfe [1956], gained much popularity in recent years due to its simple projection-free scheme and fast practical convergence rates. We consider the basic convex programming (CP) problem\nf\u2217 := min x\u2208X f(x), (1)\nwhere X \u2286 Rn is a closed convex set and f : X \u2192 R is a smooth convex function such that \u2203L > 0,\n\u2016f \u2032(x)\u2212 f \u2032(y)\u2016\u2217 \u2264 L\u2016x\u2212 y\u2016, \u2200x, y \u2208 X. (2)\nThe classic conditional gradient (CG) method solves (1) iteratively by minimizing a series of linear approximations of f over the feasible set X. More specifically, given xk\u22121 \u2208 X at the k-th iteration, it updates xk according to the following steps:\n1) Call the first-order (FO) oracle to compute (f(xk\u22121), f \u2032(xk\u22121)) and set pk = f \u2032(xk\u22121).\n2) Call the linear optimization (LO) oracle to compute\nyk \u2208 argminx\u2208X\u3008pk, x\u3009. (3)\n3) Set xk = (1\u2212 \u03bbk)xk\u22121 + \u03bbkyk for some \u03bbk \u2208 [0, 1].\nar X\niv :1\n70 3.\n05 84\n0v 1\n[ cs\n.L G\n] 1\nCompared to most other first-order methods, such as, gradient descent algorithms and accelerated gradient algorithms Nesterov [1983, 2004], the CG method is computationally cheaper in some cases, since it only requires the solution of a linear optimization subproblem (3) rather than an often costly projection onto the feasible region X.\nThere has been extensive and fruitful research on the general class of linear-optimization-based convex programming (LCP) methods (which covers the CG method and its variants) and their applications in machine learning (e.g., Ahipasaoglu and Todd [2013], Bach et al. [2012], Beck and Teboulle [2004], Cox et al. [2013], Clarkson [2010], Freund and Grigas [2013], Hazan [2008], Harchaoui et al. [2012], Jaggi [2011, 2013], Jaggi and Sulovsk\u00fd [2010], Luss and Teboulle [2013], Shen et al. [2012], Hazan and Kale [2012], Lan [2013], Lan and Zhou [2014], Braun et al. [2016]). It should be noted that even the computational cost for LO oracle to solve the linear optimization subproblem (3) is high for some complex feasible regions. Recently, several approaches have been considered to address this issue. Jaggi [2013] demonstrated practical speed up for the CG method by approximately solving (3). Braun et al. [2016] proposed a class of modified CG methods, namely the lazy conditional gradient (LCG) algorithms, which call a weak separation oracle rather than solving the linear subproblem (3) in the classical CG method. In fact, the weak separation oracle is computationally more efficient than approximate minimization used in Jaggi [2013], at the expense of not providing any guarantee for function value improvement with respect to (3). Furthermore, as shown in Jaggi [2013] and Lan [2013], the total number of iterations for the LCP methods to find an -solution of (1) (i.e., a point x\u0304 \u2208 X, s.t. f(x\u0304) \u2212 f\u2217 \u2264 ) cannot be smaller than O(1/ ), which is not improvable even when the objective function f is strongly convex. Improved complexity results can only be obtained under stronger assumptions on the LO oracle or the feasible set (see, e.g., Garber and Hazan [2013], Lan [2013]). However, the O(1/ ) bound does not preclude the existence of more efficient LCP algorithms for solving (1). Lan and Zhou [2014] proposed a class of conditional gradient sliding methods (CGS), which significantly improve the complexity bounds in terms of the number of gradient evaluations while maintaining optimal complexity bounds for the LO oracle calls required by the LCP methods.\nInspired by Braun et al. [2016] and Lan and Zhou [2014], in this paper we focus on a class of modified LCP methods that require only improving solutions for a certain separation problem rather than solving the linear optimization subproblem (3) explicitly through LO oracle calls while simultaneously minimizing the number of gradient evaluations when performing weak separation over the feasible set X. At first these two objectives seem to be incompatible as Braun et al. [2016] gives up the dual guarantee to simplify the oracle, while the dual guarantee of CG iterations is at the core of the analysis in Lan and Zhou [2014]. We overcome this impasse by carefully modifying both techniques.\nIt should be mentioned that Hazan and Kale [2012] proposed the online Frank-Wolfe (OFW) algorithm, which obtains O(1/ 4) rate of convergence for stochastic problems. Indeed, if we consider the objective function f(x) := E[F (x, \u03be)] for stochastic optimization, the OFW method can be applied to solve (1) by viewing the iteratively observed function ft as the current realization of the true objective function f , i.e., ft(\u00b7) = F (\u00b7, \u03bet). Without re-evaluating the (sub)gradients at the updated points, the OFW obtains O(T\u22121/4) bound for any (smooth or non-smooth) objective functions (see Theorem 4.4 in Hazan and Kale [2012]), which implies O(1/ 4) rate of convergence in terms of the number of (sub)gradient evaluations for stochastic optimization. However, we can show that our proposed algorithm obtains O(1/ 2) rate of convergence for stochastic problems, which is much better than the convergence rate of the OFW method. We would like to stress that the stochastic optimization bound in Hazan and Kale [2012, Theorem 4.1] which gives a guarantee\nof O(1/ 2), requires to re-evaluate all gradients at the current iterate and as such the number of gradient evaluations required grows quadratically in t.\nContributions Our main contributions can be briefly summarized as follows. We consider stochastic smooth optimization, where we have only access to unbiased estimators of the gradients of f via a stochastic first-order (SFO) oracle. By incorporating a modified LCG procedure [Braun et al., 2016] into a modified CGS method [Lan and Zhou, 2014] we obtain a new conditional accelerated lazy stochastic gradient descent algorithm (CALSGD) and we show that the number of calls to the weak separation oracle can be optimally bounded by O(1/ ), while the optimal bound of O(1/ 2) on the total number of calls to the SFO oracle can be maintained. In addition, if the exact gradients of f can be accessed by an FO oracle, the latter bound can be significantly improved to O(1/ \u221a ). In order to achieve the above we will present a modified lazy conditional gradient method, and show that the total number of iterations (or calls to the weak separation oracle) performed by it can be bounded by O(1/ ) under a stronger termination criterion, i.e., the primal-dual gap function.\nWe also consider strongly convex and smooth functions and show that without enforcing any stronger assumptions on the weak separation oracle or the feasible set X, the total number of calls to the FO (resp., SFO) oracle can be optimally bounded by O(log 1/ ) (resp., O(1/ )) for variants of the proposed method to solve deterministic (resp., stochastic) strongly convex and smooth problems. Furthermore, we also generalize the proposed algorithms to solve an important class of non-smooth convex programming problems with a saddle point structure. By adaptively approximating the original non-smooth problem via a class of smooth functions, we are able to show that the deterministic version of CALSGD can obtain an -solution within O(1/ ) number of linear operator evaluations and O(1/ 2) number of calls to the weak separation oracle, respectively. The former bound will increase to O(1/ 2) for non-smooth stochastic optimization.\nFinally, we demonstrate practical speed ups of CALSGD through preliminary numerical experiments for the video co-localization problem, the structured regression problem and quadratic optimization over the standard spectrahedron; an extensive study is beyond the scope of this paper and left for future work. In all cases we report a substantial improvements in performance."}, {"heading": "1.1 Notation and terminology", "text": "Let X \u2286 Rn be a convex compact set, and \u2016 \u00b7 \u2016X be the norm associated with the inner product in Rn. For the sake of simplicity, we often skip the subscript in the norm \u2016 \u00b7 \u2016X . We define the diameter of the set X as\nDX \u2261 DX,\u2016\u00b7\u2016 := max x,y\u2208X \u2016x\u2212 y\u2016. (4)\nFor a given norm \u2016 \u00b7 \u2016, we denote its conjugate by \u2016s\u2016\u2217 = max\u2016x\u2016\u22641\u3008s, x\u3009. For a linear operator A : Rn \u2192 Rm, we use \u2016A\u2016 to denote its operator norm defined as \u2016A\u2016 := max\u2016x\u2016\u22641 \u2016Ax\u2016. Let f : X \u2192 R be a convex function, we denote its linear approximation at x by\nlf (x; y) := f(x) + \u3008f \u2032(x), y \u2212 x\u3009. (5)\nClearly, if f satisfies (2), then\nf(y) \u2264 lf (x; y) + L2 \u2016y \u2212 x\u2016 2, \u2200x, y \u2208 X. (6)\nNotice that the constant L in (2) and (6) depends on \u2016 \u00b7 \u2016. Moreover, we say f is smooth with curvature at most C, if\nf(y) \u2264 lf (x; y) + C2 , \u2200 x, y \u2208 X. (7)\nIt is clear that if X is bounded, we have C \u2264 LD2X . In the following we also use R++ to denote the set of strictly positive reals."}, {"heading": "2 Conditional Accelerated Lazy Stochastic Gradient Descent", "text": "We now present a new method for stochastic gradient descent that is based on the stochastic conditional gradient sliding (SCGS) method and the parameter-free lazy conditional gradient (LCG) procedure from Section 2.2, which we refer to as the Conditional Accelerated Lazy Stochastic Gradient Descent (CALSGD) method.\nWe consider the stochastic optimization problem:\nf\u2217 := min x\u2208X {f(x) = E\u03be[F (x, \u03be)]}, (8)\nwhere f(x) is a smooth convex function satisfying (2)."}, {"heading": "2.1 The algorithm", "text": "Throughout this section, we assume that there exists a stochastic first-order (SFO) oracle, which for a search point zk \u2208 X outputs a stochastic gradient F \u2032(zk, \u03bek), s.t.\nE [F \u2032(zk, \u03bek)] = f \u2032(zk), (9) E [ \u2016F \u2032(zk, \u03bek)\u2212 f \u2032(zk)\u20162\u2217 ] \u2264 \u03c32. (10)\nIf \u03c3 = 0, the stochastic gradient F \u2032(zk, \u03bek) is the exact gradient at point zk, i.e., F \u2032(zk, \u03bek) = f \u2032(zk). Our algorithmic framework is inspired by the SCGS method by Lan and Zhou [2014]. However, instead of applying the classic CG method to solve the projection subproblem appearing in the accelerated gradient (AG) method, the CALSGD method utilizes a modified parameter-free LCG algorithm (see Section 2.2) to approximately solve the subproblem \u03c8(x) defined in (16) and skips the computations of the stochastic gradient F \u2032(z, \u03be) from time to time when performing weak separation over the feasible region X. The main advantages of our method are that it does not solve a traditional projection problem and achieves the optimal bounds on the number of calls to the SFO and LOsepX oracles (see Oracle 1 in Subsection 2.2) for solving problem (1)-(8). To the authors\u2019 best knowledge, no such algorithms have been developed before in the literature; we present the algorithm below in Algorithm 1.\nAlgorithm 1 Conditional Accelerated Lazy Stochastic Gradient Descent (CALSGD) Input: Initial point x0 \u2208 X, iteration limit N , and weak separation oracle accuracy \u03b1 \u2265 1. Let \u03b2k \u2208 R++, \u03b3k \u2208 [0, 1], and \u03b7k \u2208 R+, k = 1, 2, . . ., be given and set y0 = x0. for k = 1, 2, . . . , N do\nzk = (1\u2212 \u03b3k)yk\u22121 + \u03b3kxk\u22121, (11)\ngk = 1 Bk \u2211Bk j=1F \u2032(zk, \u03bek,j), (12) xk = LCG(gk, \u03b2k, xk\u22121, \u03b1, \u03b7k), (13) yk = (1\u2212 \u03b3k)yk\u22121 + \u03b3kxk, (14)\nwhere F \u2032(zk, \u03bek,j), j = 1, . . . , Bk, are stochastic gradients computed by the SFO at zk. end for Output: yN .\nWe hasten to make some observations about the CALSGD method. Firstly, we apply mini-batches to estimate the gradient at point zk, where the parameter {Bk} denotes the batch sizes used to compute gk. It can be easily seen from (9), (10), and (12) that\nE[gk \u2212 f \u2032(zk)] = 0 and E[\u2016gk \u2212 f \u2032(zk)\u20162\u2217] \u2264 \u03c3 2 Bk , (15)\nand hence gk is an unbiased estimator of f \u2032(zk). In fact, letting SBk = \u2211Bk j=1(F\n\u2032(zk, \u03bek,j)\u2212 f \u2032(zk)), from (9) and (10), by induction, we have\nE [ \u2016SBk\u20162\u2217 ] = E [ \u2016SBk\u22121 + F \u2032(zk, \u03bek,Bk)\u2212 f \u2032(zk)\u20162\u2217 ] = E [ \u2016SBk\u22121\u20162\u2217 + \u2016F \u2032(zk, \u03bek,Bk)\u2212 f \u2032(zk)\u20162\u2217 + 2\u3008SBk\u22121, F \u2032(zk, \u03bek,Bk)\u2212 f \u2032(zk)\u3009\n] = E [ \u2016SBk\u22121\u20162\u2217 ] + E [ \u2016F \u2032(zk, \u03bek,Bk)\u2212 f \u2032(zk)\u20162\u2217\n] = \u2211Bk j=1E [ \u2016F \u2032(zk, \u03bek,j)\u2212 f \u2032(zk)\u20162\u2217 ] \u2264 Bk\u03c32,\nwhich together with the fact that gk \u2212 f \u2032(zk) = 1Bk \u2211Bk j=1 [F\n\u2032(zk, \u03bek,j)\u2212 f \u2032(zk)] = 1BkSBk , implies the second relationship in (15).\nSecondly, in view of the SCGS method in Lan and Zhou [2014], xk obtained in (13) should be an approximate solution to the gradient sliding subproblem\nmin x\u2208X\n{ \u03c8k(x) := \u3008gk, x\u3009+ \u03b2k2 \u2016x\u2212 xk\u22121\u2016 2 } , (16)\nsuch that for some \u03b7k \u2265 0 we have\n\u3008\u03c8\u2032k(xk), xk \u2212 x\u3009 = \u3008gk + \u03b2k(xk \u2212 xk\u22121), xk \u2212 x\u3009 \u2264 \u03b7k, (17)\nfor all x \u2208 X. If we solve the subproblem (16) exactly (i.e., \u03b7k = 0), then CALSGD will reduce to the accelerated stochastic approximation method by Lan [2009, 2012]. However, by employing the LCG procedure (see Procedure 1 in Subsection 2.2), we only need to use a weak separation oracle, but still maintaining the optimal bounds on stochastic first-order oracle as in Lan [2009, 2012], Lan and Zhou [2014].\nThirdly, observe that the CALSGD method so far is conceptual only as we have not yet specified the LCG procedure and the parameters {Bk}, {\u03b2k}, {\u03b3k}, and {\u03b7k}. We will come back to this issue after introducing the LCG procedure and establishing its main convergence properties."}, {"heading": "2.2 The parameter-free lazy conditional gradient procedure", "text": "The classical CG method is a well-known projection-free algorithm, which requires only the solution of a linear optimization subproblem (3) rather than the projection over X per iteration. Therefore, it has computational advantages over many other first-order methods when projection over X is costly. The LCG procedure presented in this subsection, a modification of the vanilla LCG method in Braun et al. [2016], goes several steps further than CG and even vanilla LCG method. Firstly, it replaces LO oracle by a weaker separation oracle LOsep, which is no harder than linear optimization and often much simpler. Secondly, it uses a stronger termination criterion, the Frank-Wolfe gap (cf. (18)), than vanilla LCG method. Finally, it maintains the same order of convergence rate as the CG and the vanilla LCG method.\nWe present the LOsep oracle in Oracle 1 below.\nOracle 1 Weak Separation Oracle LOsepP (c, x,\u03a6, \u03b1) Input: c \u2208 Rn linear objective, x \u2208 P point, \u03b1 \u2265 1 accuracy, \u03a6 > 0 objective value; Output: y \u2208 P vertex with either (1) cT (x\u2212 y) > \u03a6/\u03b1, or (2) y = argmaxy\u2208P cT (x\u2212 z) \u2264 \u03a6.\nObserve that the oracle has two output modes. In particular, Oracle 1 first verifies whether there exists an improving point y \u2208 P with the required guarantee and if so it outputs this point, which we refer it as a positive call. If no such point exists the oracle certifies this by providing the maximizer y, which then also provides a new duality gap. We refer to this case as a negative call. The computational advantages of this oracle are that it can reuse previously seen solutions y if they satisfy the improvement condition and even if LO oracle has to be called, the optimization can be terminated early once the improvement condition is satisfied. Finally, the parameter \u03b1 allows to only approximately satisfy the improvement condition making separation even easier; in our applications we set the parameter \u03b1 slightly larger than 1.\nWe present the LCG procedure based on Braun et al. [2016] below. We adapted the parameterfree version to remove any dependence on hard to estimate parameters. For any smooth convex function \u03c6, we define its duality gap as\ngap\u03c6,X(x) \u2261 gap\u03c6(x) := max y\u2208X \u2207\u03c6(x)T (x\u2212 y). (18)\nClearly, by convexity the duality gap is an upper bound on f(x) \u2212 f(x\u2217). Given any accuracy parameter \u03b7 \u2265 0, the LCG procedure solves minx\u2208X \u03c6(x) approximately with accuracy \u03b7, i.e., it outputs a point u\u0304 \u2208 X, s.t. gap\u03c6(u\u0304) \u2264 \u03b7.\nProcedure 1 Parameter-free Lazy Conditional Gradients (LCG) procedure Input: access to gradients of smooth convex function \u03c6, u1 \u2208 X vertex, LOsepX weak linear\nseparation oracle, accuracy \u03b1 \u2265 1, duality gap bound \u03b7 Output: u\u0304 \u2208 X with bounded duality gap, i.e., gap\u03c6(u\u0304) \u2264 \u03b7 1: \u03a60 \u2190 maxu\u2208X \u2207\u03c6(u1)T (u1 \u2212 u) 2: for t = 1 to T \u2212 1 do 3: vt \u2190 LOsepX(\u2207\u03c6(ut), xt,\u03a6t\u22121, \u03b1) 4: if not \u2207\u03c6(ut)T (ut \u2212 vt) > \u03a6t\u22121/\u03b1 then 5: if \u03a6t\u22121 = \u03b7 then 6: return u\u0304 = ut 7: end if 8: else 9: \u03a6t \u2190 max { \u03a6t\u22121 2 , \u03b7 }\n{Update \u03a6t} 10: end if 11: \u03bbt \u2190 argmin \u03c6((1\u2212 \u03bbt)ut + \u03bbtvt) 12: ut+1 \u2190 (1\u2212 \u03bbt)ut + \u03bbtvt 13: end for\nThe LCG procedure is a parameter-free algorithm. Note that while line search can be expensive in general, for our subproblems, function evaluation is very cheap. The algorithm needs only one LO oracle call to estimate the initial functional value gap at Line 1. Alternatively, this can be also done approximately via binary search with LOsep. The algorithm maintains a sequence, {\u03a6t}, that provides valid upper bounds for the functional value gap at the current iterate, i.e., \u03c6(ut)\u2212\u03c6\u2217 \u2264 2\u03a6t\u22121 (see Theorem 5.1 of Braun et al. [2016]), and it halves the value of \u03a6t only when the current oracle call is negative. Finally, our LCG procedure exits at Line 5 whenever LOsepX returns a negative call and \u03a6t\u22121 = \u03b7, which ensures that gap\u03c6(u\u0304) = maxy\u2208X\u3008\u2207\u03c6(u\u0304), u\u0304\u2212 y\u3009 \u2264 \u03b7.\nTheorem 2.1 below provides a bound for the total number of iterations (or calls to the LOsepX oracle) that the LCG procedure requires to generate a point u\u0304 \u2208 X with gap\u03c6(u\u0304) \u2264 \u03b7. Theorem 2.1. Procedure 1 returns a point u\u0304 \u2208 X such that the duality gap at point u\u0304 is bounded by \u03b7, i.e., gap\u03c6(u\u0304) \u2264 \u03b7. Furthermore, the total number of iterations T (and hence LOsepX calls) performed by Procedure 1 is at most\nT \u2264\n{ \u03ba+\n8\u03b12C\u03c6 \u03b7 + 2, \u03b7 < \u03b1C\u03c6; \u03ba+ 4\u03b1+ 4\u03b12C\u03c6 \u03b7 + 2, \u03b7 \u2265 \u03b1C\u03c6,\n(19)\nwith \u03ba := 4\u03b1 \u2308 log \u03a60\u03b1C\u03c6 \u2309 + log \u03a60\u03b7 .\nProof. From the observations above, it is clear that the duality gap at the output point u\u0304 is bounded by \u03b7.\nAlso observe that the procedure calls LOsepX once per iteration. In order to demonstrate the bound in (19), we split the LCG procedure into two phases, and bound the number of iterations separately for each phase. Let C\u03c6 denote the curvature of the smooth convex function \u03c6.\nWe say Procedure 1 is in the first phase whenever \u03a6t\u22121 > \u03b7. In view of Theorem 5.1 in Braun et al. [2016], it is clear that the number of iterations in the first phase can be bounded as\nT1 \u2264 4\u03b1 \u2308 log \u03a60\u03b1C\u03c6 \u2309 + 4\u03b12C\u03c6 \u03b7 + log \u03a60 \u03b7 .\nProcedure 1 enters the second phase when \u03a6t\u22121 \u2264 \u03b7. Again with the argumentation in Theorem 5.1 in Braun et al. [2016], we obtain that the total number of positive calls in this phase can be bounded by 4\u03b1\n2C\u03c6 \u03b7 , if \u03b7 < \u03b1C\u03c6, or by 4\u03b1 if \u03b7 \u2265 \u03b1C\u03c6. Moreover, the procedure exits whenever the\ncurrent LOsepX oracle call is a negative call. Hence, the number of iterations in the second phase can be bounded by\nT2 \u2264\n{ 4\u03b12C\u03c6 \u03b7 + 1, \u03b7 < \u03b1C\u03c6;\n4\u03b1+ 1, \u03b7 \u2265 \u03b1C\u03c6. Thus, our bound in (19) can be obtained from the above two bounds plus one more LO oracle call at Line 1."}, {"heading": "2.3 The convergence properties of CALSGD", "text": "This subsection is devoted to establishing the main convergence properties of the CALSGD method. Since the algorithm is stochastic, we will establish the convergence results for finding a stochastic -solution, i.e., a point x\u0304 \u2208 X s.t. E[f(x\u0304)\u2212 f(x\u2217)] \u2264 . We first state a simple technical result from Lan and Zhou [2014, Lemma 2.1] that we will use.\nLemma 2.2. Let wt \u2208 (0, 1], t = 1, 2, . . ., be given. Also let us denote\nWt :=\n{ 1 t = 1\n(1\u2212 wt)Wt\u22121 t \u2265 2.\nSuppose that Wt > 0 for all t \u2265 2 and that the sequence {\u03b4t}t\u22650 satisfies\n\u03b4t \u2264 (1\u2212 wt)\u03b4t\u22121 +Bt, t = 1, 2, . . . .\nThen for any 1 \u2264 l \u2264 k, we have \u03b4k \u2264Wk (\n1\u2212wl Wl \u03b4l\u22121 + \u2211k i=l Bi Wi ) .\nTheorem 2.3 describes the main convergence properties of the CALSGD method (cf. Algorithm 1).\nTheorem 2.3. Let \u0393k be defined as follows,\n\u0393k :=\n{ 1 k = 1\n\u0393k\u22121(1\u2212 \u03b3k) k \u2265 2. (20)\nSuppose that {\u03b2k} and {\u03b3k} in the CALSGD algorithm satisfy\n\u03b31 = 1 and L\u03b3k \u2264 \u03b2k, k \u2265 1. (21)\na) If \u03b2k\u03b3k \u0393k \u2265 \u03b2k\u22121\u03b3k\u22121\u0393k\u22121 , k \u2265 2, (22)\nthen under assumptions (9) and (10), we have\nE [f(yk)\u2212 f(x\u2217)] \u2264 \u03b2k\u03b3k2 D 2 X + \u0393k k\u2211 i=1 [ \u03b7i\u03b3i \u0393i + \u03b3i\u03c3 2 2\u0393iBi(\u03b2i\u2212L\u03b3i) ] , (23)\nwhere x\u2217 is an arbitrary optimal solution of (8) and DX is defined in (4).\nb) If \u03b2k\u03b3k \u0393k \u2264 \u03b2k\u22121\u03b3k\u22121\u0393k\u22121 , k \u2265 2, (24)\n(rather than (22)) is satisfied, then the result in part a) holds by replacing \u03b2k\u03b3kD2X with \u03b21\u0393k\u2016x0 \u2212 x\u2217\u20162 in the first term of the RHS of (23).\nc) Under the assumptions in part a) or b), the number of inner iterations performed at the k-th outer iterations is bounded by\nTk =\n{ \u03ba+ 8\u03b12\u03b2kD 2 X\n\u03b7k + 2, \u03b7k < \u03b1\u03b2kD 2 X ;\n\u03ba+ 4\u03b1+ 4\u03b12\u03b2kD 2 X\n\u03b7k + 2, \u03b7k \u2265 \u03b1\u03b2kD2X ,\n(25)\nwith \u03ba := 4\u03b1 \u2308 log\n\u03a6k0 \u03b1\u03b2kD2X\n\u2309 + log\n\u03a6k0 \u03b7k .\nProof. Let us denote \u03b4k,j = F \u2032(zk, \u03bek,j) \u2212 f \u2032(zk) and \u03b4k \u2261 gk \u2212 f \u2032(zk) = \u2211Bk j=1 \u03b4k,j/Bk. We first show part a). In view of (6), (11) and (14), we have\nf(yk) \u2264 lf (zk; yk) + L2 \u2016yk \u2212 zk\u2016 2\n= (1\u2212 \u03b3k)lf (zk; yk\u22121) + \u03b3klf (zk;xk) + L\u03b3 2 k 2 \u2016xk \u2212 xk\u22121\u2016 2 = (1\u2212 \u03b3k)f(yk\u22121) + \u03b3klf (zk;xk) + \u03b2k\u03b3k2 \u2016xk \u2212 xk\u22121\u2016 2 \u2212 \u03b3k(\u03b2k\u2212L\u03b3k)2 \u2016xk \u2212 xk\u22121\u2016 2,\nwhere the last inequality follows from the convexity of f(\u00b7). Also observe that by (17), we have\n\u3008gk + \u03b2k(xk \u2212 xk\u22121), xk \u2212 x\u3009 \u2264 \u03b7k, \u2200x \u2208 X,\nwhich implies that\n1 2\u2016xk \u2212 xk\u22121\u2016 2 = 12\u2016xk\u22121 \u2212 x\u2016 2 \u2212 12\u2016xk \u2212 x\u2016 2 \u2212 \u3008xk\u22121 \u2212 xk, xk \u2212 x\u3009 \u2264 12\u2016xk\u22121 \u2212 x\u2016 2 \u2212 12\u2016xk \u2212 x\u2016 2 + 1\u03b2k \u3008gk, x\u2212 xk\u3009+ \u03b7k \u03b2k .\nCombing the above two relations, we have\nf(yk) \u2264 (1\u2212 \u03b3k)f(yk\u22121) + \u03b3klf (zk, xk) + \u03b3k\u3008gk, x\u2212 xk\u3009 + \u03b2k\u03b3k2 [ \u2016xk\u22121 \u2212 x\u20162 \u2212 \u2016xk \u2212 x\u20162 ] + \u03b7k\u03b3k \u2212 \u03b3k(\u03b2k\u2212L\u03b3k)2 \u2016xk \u2212 xk\u22121\u2016 2\n= (1\u2212 \u03b3k)f(yk\u22121) + \u03b3klf (zk, x) + \u03b3k\u3008\u03b4k, x\u2212 xk\u3009 + \u03b2k\u03b3k2 [ \u2016xk\u22121 \u2212 x\u20162 \u2212 \u2016xk \u2212 x\u20162 ] + \u03b7k\u03b3k \u2212 \u03b3k(\u03b2k\u2212L\u03b3k)2 \u2016xk \u2212 xk\u22121\u2016 2.\nUsing the above inequality and the fact that\n\u3008\u03b4k, x\u2212 xk\u3009 \u2212 (\u03b2k\u2212L\u03b3k)2 \u2016xk \u2212 xk\u22121\u2016 2 = \u3008\u03b4k, x\u2212 xk\u22121\u3009+ \u3008\u03b4k, xk\u22121 \u2212 xk\u3009 \u2212 (\u03b2k\u2212L\u03b3k)2 \u2016xk \u2212 xk\u22121\u2016 2\n\u2264 \u3008\u03b4k, x\u2212 xk\u22121\u3009+ \u2016\u03b4k\u2016 2 \u2217\n2(\u03b2k\u2212L\u03b3k) ,\nwe obtain for all x \u2208 X,\nf(yk) \u2264 (1\u2212 \u03b3k)f(yk\u22121) + \u03b3kf(x) + \u03b7k\u03b3k + \u03b2k\u03b3k2 [ \u2016xk\u22121 \u2212 x\u20162 \u2212 \u2016xk \u2212 x\u20162 ] + \u03b3k\u3008\u03b4k, x\u2212 xk\u22121\u3009+ \u03b3k\u2016\u03b4k\u2016 2 \u2217\n2(\u03b2k\u2212L\u03b3k) . (26)\nSubtracting f(x) from both sides of (26) and applying Lemma 2.2, we have\nf(yk)\u2212 f(x) \u2264 \u0393k(1\u2212 \u03b31) [f(y0)\u2212 f(x)] + \u0393k \u2211k i=1 \u03b7i\u03b3i \u0393i + \u0393k \u2211k i=1 \u03b2i\u03b3i 2\u0393i [ \u2016xk\u22121 \u2212 x\u20162 \u2212 \u2016xk \u2212 x\u20162 ] + \u0393k \u2211k i=1 \u03b3i \u0393i [ \u3008\u03b4i, x\u2212 xi\u22121\u3009+ \u2016\u03b4i\u2016 2 \u2217 2(\u03b2i\u2212L\u03b3i) ] . (27)\nAlso observe that\u2211k i=1 \u03b2i\u03b3i \u0393i (\u2016xi\u22121 \u2212 x\u20162 \u2212 \u2016xi \u2212 x\u20162)\n= \u03b21\u03b31\u03931 \u2016x0 \u2212 x\u2016 2 \u2212 \u03b2k\u03b3k\u0393k \u2016xk \u2212 x\u2016 2 + \u2211k i=2 ( \u03b2i\u03b3i \u0393i \u2212 \u03b2i\u22121\u03b3i\u22121\u0393i\u22121 ) \u2016xi\u22121 \u2212 x\u20162\n\u2264 \u03b21\u03b31\u03931 D 2 X + \u2211k i=2 ( \u03b2i\u03b3i \u0393i \u2212 \u03b2i\u22121\u03b3i\u22121\u0393i\u22121 ) D2X\n= \u03b2k\u03b3k\u0393k D 2 X ,\nwhere the inequality follows from the third assumption in (22) and the definition of DX in (4). Therefore, from the above two relations and the fact that \u03b31 = 1, we can conclude that\nf(yk)\u2212 f(x) \u2264 \u03b2k\u03b3k2 D 2 X + \u0393k \u2211k i=1 \u03b3i \u0393i [ \u03b7i + \u2016\u03b4i\u20162\u2217 2(\u03b2i\u2212L\u03b3i) + \u2211Bi j=1B \u22121 i \u3008\u03b4i,j , x\u2212 xi\u22121\u3009 ] . (28)\nNote that by our assumptions on SFO, the random variables \u03b4i,j are independent of the search point xi\u22121 and hence E[\u3008\u03b4i,j , x\u2217 \u2212 xi\u22121\u3009] = 0. In addition, relation (15) implies that E[\u2016\u03b4i\u20162\u2217] \u2264 \u03c32/Bi. Using the previous two observations and taking expectation on both sides of (28) (with x = x\u2217) we obtain (23).\nSimilarly, Part b) follows from (27), the assumption that \u03b31 = 1, and the fact that\u2211k i=1 \u03b2i\u03b3i \u0393i (\u2016xi\u22121 \u2212 x\u20162 \u2212 \u2016xi \u2212 x\u20162) \u2264 \u03b21\u03b31\u03931 \u2016x0 \u2212 x\u2016 2 \u2212 \u03b2k\u03b3k\u0393k \u2016xk \u2212 x\u2016 2 \u2264 \u03b21\u2016x0 \u2212 x\u20162, (29)\ndue to the assumptions in (21) and (24). Let \u03a6k0 denote the initial bound obtained in Line 1 of the LCG procedure at the k-th outer iteration. The result in Part c) follows immediately from (19) and the fact that C\u03c8k = \u03b2kD2X .\nNow we provide two different sets of parameters {\u03b2k}, {\u03b3k}, {\u03b7k}, and {Bk}, which lead to optimal complexity bounds on the number of calls to the SFO and LOsepX oracles.\nCorollary 2.4. Suppose that {\u03b2k}, {\u03b3k}, {\u03b7k}, and {Bk} in the CALSGD method are set to\n\u03b2k = 4L k+2 , \u03b3k = 3 k+2 , \u03b7k = LD2X k(k+1) , and Bk =\n\u2308 \u03c32(k+2)3\nL2D2X\n\u2309 , k \u2265 1, (30)\nand we assume \u2016f \u2032(x\u2217)\u2016 is bounded for any optimal solution x\u2217 of (8). Under assumptions (9) and (10), we have\nE [f(yk)\u2212 f(x\u2217)] \u2264 6LD 2 X (k+2)2 + 9LD2X 2(k+1)(k+2) , \u2200k \u2265 1. (31)\nAs a consequence, the total number of calls to the SFO and LOsepX oracles performed by the CALSGD method for finding a stochastic -solution of (1), respectively, can be bounded by\nO {\u221a LD2X + \u03c32D2X 2 } , (32)\nand O {\u221a LD2X log\nLD2X \u039b + LD2X\n} with probability 1\u2212 \u039b. (33)\nProof. It can be easily seen from (30) that (21) holds. Also note that by (30), we have\n\u0393k = 6 k(k+1)(k+2) , (34)\nand hence \u03b2k\u03b3k \u0393k = 2Lk(k+1)k+2 ,\nwhich implies that (22) holds. It can also be easily checked from (34) and (30) that\u2211k i=1 \u03b7i\u03b3i \u0393i \u2264 kLD 2 X 2 , \u2211k i=1 \u03b3i \u0393iBi(\u03b2i\u2212L\u03b3i) \u2264 kLD2X 2\u03c32 .\nUsing the bound in (23), we obtain (31), which implies that the total number of outer iterations N can be bounded by O (\u221a LD2X/ ) under the assumptions (9) and (10). The bound in (32) then immediately follows from this observation and the fact that the number of calls to the SFO oracle is bounded by \u2211N\nk=1Bk \u2264 \u2211N k=1 \u03c32(k+2)3\nL2D2X +N \u2264 \u03c3\n2(N+3)4 4L2D2X +N.\nWe now provide a good estimation for \u03a6k0 (cf. Line 1 in LCG procedure) at the k-th outer iteration. In view of the definition of \u03a6k0 and \u03c8(\u00b7) (cf. (16)), we have,\n\u03a6k0 = \u3008\u03c8\u2032k(xk\u22121), xk\u22121 \u2212 x\u3009 = \u3008gk, xk\u22121 \u2212 x\u3009.\nMoreover, let Ak := \u2016gk \u2212 f \u2032(zk)\u2016\u2217 \u2265 \u221a N\u03c32\n\u039bBk , by Chebyshev\u2019s inequality and (15), we obtain,\nProb{Ak} \u2264 E[\u2016gk\u2212f \u2032(zk)|2\u2217]\u039bBk N\u03c32 \u2264 \u039b N , \u2200\u039b < 1, k \u2265 1,\nwhich implies that Prob{ \u22c2N k=1 A\u0304k} \u2264 1\u2212 \u039b. Hence, by Cauchy-Schwarz and triangle inequalities, we have with probability 1\u2212 \u039b,\n\u03a6k0 = \u3008gk \u2212 f \u2032(zk), xk\u22121 \u2212 x\u3009+ \u3008f \u2032(zk), xk\u22121 \u2212 x\u3009} \u2264 (\u221a N\u03c32\n\u039bBk + \u2016f \u2032(zk)\u2212 f \u2032(x\u2217)\u2016\u2217 + \u2016f \u2032(x\u2217)\u2016\u2217\n) DX\n\u2264 (\u221a\nN \u039bk3 + 1 ) LD2X + \u2016f \u2032(x\u2217)\u2016\u2217DX , (35)\nwhere the last inequality follows from (6) and (30).\nNote that we always have \u03b7k < \u03b1\u03b2kD2X . Therefore, it follows from the bound in (25), (30), and (35) that the total number of inner iterations can be bounded by\u2211N\nk=1Tk \u2264 \u2211N k=1 [ 4\u03b1 ( log \u03a6k0 \u03b1\u03b2kD2X + 1 ) + log \u03a6k0 \u03b7k + 8\u03b12\u03b2kD 2 X \u03b7k + 2 ]\n\u2264 N\u2211 k=1 [ 5\u03b1 log ( 2k2 (\u221a N \u039bk3 + 1 + \u2016f \u2032(x\u2217)\u2016\u2217 LDX )) + 32\u03b12k ] + (4\u03b1+ 2)N\n= O ( N log N 2\n\u039b +N 2 +N\n) ,\nwhich implies that our bound in (33).\nWe now provide a slightly improved complexity bound on the number of calls to the SFO oracle which depends on the distance from the initial point to the set of optimal solutions, rather than the diameter DX . In order to obtain this improvement, we need to estimate D0 \u2265 \u2016x0 \u2212 x\u2217\u2016 and to fix the number of iterations N in advance. This result will play an important role for the analysis of the CALSGD method to solve strongly convex problems (see Section 4.1).\nCorollary 2.5. Suppose that there exists an estimate D0 s.t. \u2016x0 \u2212 x\u2217\u2016 \u2264 D0 \u2264 DX . Also assume that the outer iteration limit N \u2265 1 is given. If\n\u03b2k = 3L k , \u03b3k = 2 k+1 , \u03b7k = 2LD20 Nk , and Bk =\n\u2308 \u03c32N(k+1)2\nL2D20\n\u2309 , k \u2265 1. (36)\nUnder assumptions (9) and (10),\nE [f(yN )\u2212 f(x\u2217)] \u2264 8LD 2 0 N(N+1) , \u2200N \u2265 1.\nAs a consequence, the total number of calls to the SFO and LOsepX oracles performed by the CALSGD method for finding a stochastic -solution of (1), respectively, can be bounded by\nO {\u221a LD20 + \u03c32D20 2 } , (37)\nand (33).\nProof. The proof is similar to Corollary 2.4, and hence details are skipped.\nIt should be pointed out that the complexity bound for the number of calls to the LOsep oracle in (33) is established with probability 1\u2212 \u039b. However, the probability parameter \u039b only appears in the non-dominant term."}, {"heading": "3 Deterministic CALSGD", "text": "Our goal in this section is to present a deterministic version of CALSGD, which we refer to as CALGD. Instead of calling the SFO oracle to compute the stochastic gradients, we assume that we have access to the exact gradients of f . Therefore, the CALGD method calls the FO oracle to obtain the exact gradients f \u2032(zk) at the k-th outer iteration.\nThe CALGD method is formally described as follows.\nAlgorithm 2 The conditional accelerated lazy gradient descent (CALGD) method This algorithm is the same as Algorithm 1 except that steps (12) and (13) are replaced by\nxk = LCG(f \u2032(zk), \u03b2k, xk\u22121, \u03b1, \u03b7k). (38)\nSimilarly to the stochastic case, we can easily see that xk obtained in (38) is an approximate solution for the gradient sliding subproblem\nmin x\u2208X\n{ \u03c8k(x) := \u3008f \u2032(zk), x\u3009+\n\u03b2k 2 \u2016x\u2212 xk\u22121\u20162\n} (39)\nsuch that for all x \u2208 X\n\u3008\u03c8\u2032k(xk), xk \u2212 x\u3009 = \u3008f \u2032(zk) + \u03b2k(xk \u2212 xk\u22121), xk \u2212 x\u3009 \u2264 \u03b7k, (40)\nfor some \u03b7k \u2265 0. Theorem 3.1 describes the main convergence properties of the above CALGD method.\nTheorem 3.1. Let \u0393k be defined as in (20). Suppose that {\u03b2k} and {\u03b3k} in the CALGD algorithm satisfy (21).\na) If (22) is satisfied, then for any x \u2208 X and k \u2265 1,\nf(yk)\u2212 f(x\u2217) \u2264 \u03b2k\u03b3k2 D 2 X + \u0393k \u2211k i=1 \u03b7i\u03b3i \u0393i . (41)\nwhere x\u2217 is an arbitrary optimal solution of (1) and DX is defined in (4).\nb) If (24) (rather than (22)) is satisfied, then for any x \u2208 X and k \u2265 1,\nf(yk)\u2212 f(x\u2217) \u2264 \u03b21\u0393k2 \u2016x0 \u2212 x \u2217\u20162 + \u0393k \u2211k i=1 \u03b7i\u03b3i \u0393i . (42)\nc) Under the assumptions in either part a) or b), the number of inner iterations performed at the k-th outer iteration can be bounded by (25).\nProof. Since the convergence results stated in Theorem 2.3 cover the deterministic case when we set \u03b4k,j = F\n\u2032(zk, \u03bek,j)\u2212 f \u2032(zk) \u2261 0, Part a) immediately follows from (23) with \u03c3 = 0. Similarly, Part b) follows from (27), (29) and \u03b4i = \u2211Bi j=1\u03b4i,j = 0. The proof of Part c) is exactly the same as that of Theorem 2.3.c).\nClearly, there exist various options to specify the parameters {\u03b2k}, {\u03b3k}, and {\u03b7k} so as to guarantee the convergence of the CALGD method. In the following corollaries, we provide two different parameter settings for {\u03b2k}, {\u03b3k}, and {\u03b7k}, which lead to optimal complexity bounds on the total number of calls to the FO and LOsep oracles for smooth convex optimization.\nCorollary 3.2. If {\u03b2k}, {\u03b3k}, and {\u03b7k} in the CALGD method are set to\n\u03b2k = 3L k+1 , \u03b3k = 3 k+2 , and \u03b7k = LD2X k(k+1) , \u2200k \u2265 1, (43)\nand we assume that \u2016f \u2032(x\u2217)\u2016 is bounded for any optimal solution x\u2217 of (1), then for any k \u2265 1,\nf(yk)\u2212 f(x\u2217) \u2264 15LD 2 X\n2(k+1)(k+2) . (44)\nAs a consequence, the total number of calls to the FO and LOsep oracles performed by the CALGD method for finding an -solution of (1) can be bounded by O (\u221a LD2X/ ) and O ( LD2X/ ) respectively.\nProof. It can be easily seen from (43) that (21) holds, \u0393k is given by (34), and\n\u03b2k\u03b3k \u0393k = 9L(k+1)(k+2) k(k+1)(k+2) 6 = 3Lk 2 ,\nwhich implies that (22) is satisfied. It then follows from Theorem 3.1.a), (43), and (34) that\nf(yk)\u2212 f(x\u2217) \u2264 9LD 2 X 2(k+1)(k+2) + 6 k(k+1)(k+2) \u2211k i=1 \u03b7i\u03b3i \u0393i\n= 15LD2X\n2(k+1)(k+2) ,\nwhich implies that the total number of outer iterations performed by the CALGD method for finding an -solution can be bounded by N = \u221a 15LD2X/(2 ).\nWe first provide a valid upper bound for \u03a6k0 defined in Line 1 when the CALGD method enters the LCG procedure at the k-th outer iteration. In view of the definitions of \u03a6k0 and \u03c8(\u00b7) at Line 1 and (39), respectively, we have, for any k \u2265 1,\n\u03a6k0 = \u3008\u03c8\u2032k(xk\u22121), xk\u22121 \u2212 x\u3009 = \u3008f \u2032(zk), xk\u22121 \u2212 x\u3009 \u2264 (\u2016f \u2032(zk)\u2212 f \u2032(x\u2217)\u2016+ \u2016f \u2032(x\u2217)\u2016)\u2016xk\u22121 \u2212 x\u2016 \u2264 LD2X + \u2016f \u2032(x\u2217)\u2016DX , (45)\nwhere the first inequality follows from Cauchy-Schwarz and the triangle inequality, and the second inequality follows from (2) and (4). Note that we always have \u03b7k < \u03b1\u03b2kD2X . Therefore, similar to the stochastic case, our O(LD2X/ ) bound immediately follows from the above relation, (25), and (43).\nAs before in the stochastic case, we can slightly improve the complexity bound on the calls to the FO oracle in terms of the dependence on DX .\nCorollary 3.3. Suppose that there exists an estimate D0 \u2265 \u2016x0 \u2212 x\u2217\u2016 and that the outer iteration limit N \u2265 1 is given. If\n\u03b2k = 2L k , \u03b3k = 2 k+1 , \u03b7k = 2LD20 Nk , (46)\nfor k \u2265 1, then f(yN )\u2212 f(x\u2217) \u2264 6LD 2 0\nN(N+1) . (47)\nAs a consequence, the total number of calls to the FO and LOsep oracles performed by the CALGD method for finding an -solution of (1) can be bound by\nO ( D0 \u221a L ) and O ( LD2X ) (48)\nrespectively.\nProof. The proof is similar to Corollary 3.2, and hence omitted."}, {"heading": "4 Generalizations to other optimization problems", "text": "We generalize the CALGD and CALSGD methods to solve two other classes of problems frequently seen in machine learning. In particular, we discuss the CALGD method with a restarting technique for solving smooth and strongly convex problems in Subsection 4.1, and in Subsection 4.3 we extend the CALGD method to solve a special class of non-smooth problems. Discussions for the similar extensions for CALSGD method can be found in Subsection 4.2 and 4.4."}, {"heading": "4.1 Strongly convex optimization", "text": "In this subsection, we assume that the objective function f is not only smooth (i.e., (6) holds), but also strongly convex, that is, \u2203 \u00b5 > 0 s.t.\nf(y)\u2212 f(x)\u2212 \u3008f \u2032(x), y \u2212 x\u3009 \u2265 \u00b52 \u2016y \u2212 x\u2016 2, \u2200x, y \u2208 X. (49)\nFor simplicity, we first establish the convergence results for the deterministic case, i.e., we have access to the exact gradients of the objective function f .\nThe shrinking conditional gradient method in Lan [2013] needs to make additional assumptions on the LO oracle to obtain a linear rate of convergence. However, we will show now that CALGD (relying on the vanilla weak separation oracle) can obtain a linear rate of convergence in terms of the number of calls to the FO oracle and O(LD2X/ ) rate of convergence in the total number of calls to the LOsep oracle. In view of the lower complexity bound established for the LO oracle to solve strongly convex problems in Jaggi [2013] and Lan [2013], our bound for the LOsep oracle is not improvable.\nWe are now ready to formally describe the CALGD method for solving strongly convex problems, which is obtained by properly restarting the CALGD method (Algorithm 2).\nAlgorithm 3 The CALGD method for strongly convex problems Input: Initial point p0 \u2208 X and an estimate \u03b40 > 0 satisfying f(p0)\u2212 f(x\u2217) \u2264 \u03b40. for s = 1, 2, . . . do Call the CALGD method in Algorithm 2 with input\nx0 = ps\u22121 and N = \u2308 2 \u221a 6L \u00b5 \u2309 , (50)\nand parameters \u03b2k = 2L k , \u03b3k = 2 k+1 , and \u03b7k = \u03b7s,k := 8L\u03b402 \u2212s \u00b5Nk , (51)\nand let ps be its output solution. end for\nIn Algorithm 3, we restart the CALGD method for smooth optimization (i.e., Algorithm 2) every d2 \u221a\n6L/\u00b5e iterations. We call each loop iteration a phase of the above CALGD algorithm. Observe that {\u03b7k} decrease by a factor of 2 as s increments by 1, while {\u03b2k} and {\u03b3k} remain the same. The following theorem shows the convergence of the above variant of the CALGD method.\nTheorem 4.1. Assume (49) holds and let {ps} be generated by Algorithm 3. Then,\nf(ps)\u2212 f(x\u2217) \u2264 \u03b402\u2212s, s \u2265 0.\nAs a consequence, the total number of calls to the FO and LOsep oracles performed by this algorithm for finding an -solution of problem (1) can be bounded by\nO {\u221a\nL \u00b5 \u2308 log2 max ( 1, \u03b40 )\u2309} and O { LD2X } , (52)\nrespectively.\nProof. Denote the total number of phases performed by CALGD method to obtain an -solution of (1) by S. In view of the complexity results obtained in Theorem 2.5 in Lan and Zhou [2014], we conclude that\nS = \u2308 log2 max ( 1, \u03b40 )\u2309 . (53)\nThe total number of calls to the FO oracle performed by Algorithm 3 is clearly bounded by NS, which immediately implies our first result in (52).\nNow, let Ts,k denote the number of calls to the LOsep oracle required at the k-th outer iteration in the s-th phase. It follows from Theorem 3.1.c), (45), and (51) that\nTs,k \u2264 O ( \u03b2kD 2 X\n\u03b7s,k\n) = O ( \u00b5D2X2\nsN \u03b40\n) .\nTherefore, the total number of calls to the LOsep oracle can be bounded by\u2211S s=1 \u2211N k=1Ts,k \u2264 \u2211S s=1 \u2211N k=1O ( \u00b5D2X2 sN \u03b40 ) = O ( \u00b5D2XN 2\n\u03b40\n\u2211S s=12 s )\n= O ( \u00b5D2XN 2\n\u03b40 2S+1 ) = O ( \u00b5D2XN 2 ) ,\nwhich implies our second bound in (52) due to the definitions of N and S in (50) and (53), respectively.\nIn view of classic complexity theory for convex optimization, the bound on the total number of calls to the FO oracle (cf. first bound in (52)) is optimal for strongly convex optimization. Moreover, in view of the complexity results established in Lan [2013] and the fact that the LOsep oracle is weaker than the LO oracle, the bound on the total number of calls to the LOsep oracle (cf. second bound in (52)) is not improvable either."}, {"heading": "4.2 Strongly convex stochastic optimization", "text": "Similarly to the deterministic case we present an optimal algorithm for solving stochastic smooth and strongly convex problems.\nAlgorithm 4 The CALSGD method for solving strongly convex problems Input: Initial point p0 \u2208 X and an estimate \u03b40 > 0 satisfying f(p0)\u2212 f(x\u2217) \u2264 \u03b40. for s = 1, 2, . . . do Call the CALSGD method in Algorithm 1 with input\nx0 = ps\u22121 and N = \u2308 4 \u221a 2L \u00b5 \u2309 , (54)\nand parameters\n\u03b2k = 3L k , \u03b3k = 2 k+1 , \u03b7k = \u03b7s,k :=\n8L\u03b402 \u2212s\n\u00b5Nk , and Bk = Bs,k := \u2308 \u00b5\u03c32N(k+1)2\n4L2\u03b402\u2212s\n\u2309 , (55)\nand let ps be its output solution. end for\nThe main convergence properties of Algorithm 4 are as follows.\nTheorem 4.2. Assume that (49) holds and let {ps} be generated by Algorithm 4. Then,\nE[f(ps)\u2212 f(x\u2217)] \u2264 \u03b402\u2212s, s \u2265 0.\nAs a consequence, the total number of calls to the SFO and LOsep oracles performed by this algorithm for finding a stochastic -solution of problem (1)-(8) can be bounded by\nO { \u03c32 \u00b5 + \u221a L \u00b5 \u2308 log2 max ( 1, \u03b40 )\u2309} , (56)\nand O { LD2X } , with probability 1\u2212 \u039b, (57)\nrespectively.\nProof. In view of Corollary 2.5, and Theorem 3.4 in Lan and Zhou [2014], the total number of phases, S, performed by CALSGD method to find a stochastic -solution of problem (1)-(8) is bounded by (53). Since the number of outer iterations in each phase is at most N , the total number of calls to the SFO oracle is bounded by\u2211S\ns=1 \u2211N k=1Bk \u2264 \u2211S s=1 \u2211N k=1 ( \u00b5\u03c32N(k+1)2 4L2\u03b402\u2212s + 1 )\n\u2264 \u00b5\u03c3 2N(N+1)3\n12L2\u03b40\n\u2211S s=12 s + SN\n\u2264 \u00b5\u03c3 2N(N+1)3\n3L2 + SN.\nMoreover, similar to (35), we obtain a good estimator for \u03a6s,k0 , for any 0 < \u039b \u2264 1\n\u03a6s,k0 \u2264 (\u221a 4SL2\u03b40 \u039b\u00b5k22s + 1 ) LD2X + \u2016f \u2032(x\u2217)\u2016\u2217DX ,\nwith probability 1\u2212\u039b. Let Ts,k denote the number of calls to the LOsep oracle required at the k-th outer iteration in the s-th phase of the CALSGD method. It follows from Theorem 2.3.c), the above relation, and (55) that with probability 1\u2212 \u039b,\nTs,k \u2264 O ( log \u03a6s,k0 \u03b7s,k + \u03b2kD 2 X \u03b7s,k ) = O ( \u00b5D2X2 sN \u03b40 ) holds. Therefore, the total number of calls to the LOsep oracle is bounded by\u2211S\ns=1 \u2211N k=1Ts,k \u2264 \u2211S s=1 \u2211N k=1O ( \u00b5D2X2 sN \u03b40 ) = O ( \u00b5D2XN 2\u03b4\u221210 \u2211S s=12 s )\n= O ( \u00b5D2XN 2 ) ,\nwhich implies the bound in (57), due to the definitions of N and S in (54) and (53), respectively.\nAccording to Theorem 4.2, the total number of calls to the SFO oracle is bounded by O(1/ ), which is optimal in view of the classic complexity theory for strongly convex optimization (see [Ghadimi and Lan, 2012, 2013]). Moreover, the total number of calls to the LOsep oracle is bounded by O(1/ ), which is the same bound as for the CALGD method for strongly convex optimization and hence not improvable."}, {"heading": "4.3 Non-smooth optimization: Saddle point problems", "text": "For the sake of simplicity, we consider the deterministic case, i.e., the problem of interest is an important class of saddle point problems with f given in the form of\nf(x) = max y\u2208Y\n{ \u3008Ax, y\u3009 \u2212 f\u0302(y) } , (58)\nwhere A : Rn \u2192 Rm denotes a linear operator, Y \u2208 Rm is a convex compact set, and f\u0302 : Y \u2192 R is a simple convex function. Since the objective function f is non-smooth, we cannot directly apply the CALGD method presented in the previous section. However, as shown by Nesterov [2005], the function f(\u00b7) in (58) can be closely approximated by a class of smooth convex functions. More specifically, let \u03c9 : Y \u2192 R be a given strongly convex function with strongly convex modulus \u03c3\u03c9 > 0, i.e.,\n\u03c9(y) \u2265 \u03c9(x) + \u3008\u03c9\u2032(x), y \u2212 x\u3009+ \u03c3\u03c92 \u2016y \u2212 x\u2016 2,\u2200x, y \u2208 Y,\nand let us denote c\u03c9 := argminy\u2208Y \u03c9(y), W (y) := \u03c9(y)\u2212 \u03c9(c\u03c9)\u2212 \u3008\u2207\u03c9(c\u03c9), y \u2212 c\u03c9\u3009 and\nD2Y,W := max y\u2208Y W (y).\nIt can be easily seen that\n\u2016y \u2212 c\u03c9\u20162 \u2264 2\u03c3\u03c9W (y) \u2264 2 \u03c3\u03c9 D2Y,W , \u2200y \u2208 Y,\nand hence that \u2016y1 \u2212 y2\u20162 \u2264 4\u03c3\u03c9D 2 Y,W , \u2200y1, y2 \u2208 Y.\nIn view of these relations, the function f(\u00b7) in (58) can be closely approximated by\nf\u03c4 (x) := max y\u2208Y\n{ \u3008Ax, y\u3009 \u2212 f\u0302(y)\u2212 \u03c4 [W (y)\u2212D2Y,W ] } . (59)\nIn particular, for any \u03c4 \u2265 0,\nf(x) \u2264 f\u03c4 (x) \u2264 f(x) + \u03c4 D2Y,W , \u2200x \u2208 X.\nMoreover, Nesterov [2005] shows that f\u03c4 (\u00b7) is differentiable and its gradients are Lipschitz continuous with the Lipschitz constant given by\nL\u03c4 := \u2016A\u2016 2\n\u03c4\u03c3\u03c9 . (60)\nThroughout this subsection, we assume that the feasible region Y and the function f\u0302 are simple enough, so that the subproblem in (59) is easy to solve. Therefore, the major computational cost for gradient calculations of f\u03c4 lie in the evaluations of the linear operator A and its adjoint operator AT . We are now ready to present a variant of the CALGD method, which can achieve optimal bounds on the number of calls to the LOsep oracle and the number of evaluations of the linear operators A and AT .\nAlgorithm 5 The CALGD method for solving saddle point problems This algorithm is the same as Algorithm 2 except that (38) is replaced by\nxk = LCG(f \u2032 \u03c4k (zk), \u03b2k, xk\u22121, \u03b1, \u03b7k), (61)\nfor some \u03c4k \u2265 0.\nIn Theorem 4.3 we state the main convergence properties of this modified CALGD method to solve the saddle point problem in (1)-(58).\nTheorem 4.3. Suppose that \u03c41 \u2265 \u03c42 \u2265 . . . \u2265 0. Also assume that {\u03b2k} and {\u03b3k} satisfy (21) (with L replaced by L\u03c4k defined in (60)) and (22). Then, for all k \u2265 1,\nf(yk)\u2212 f(x\u2217) \u2264 \u03b2k\u03b3k2 D 2 X + \u0393k \u2211k i=1 \u03b3i \u0393i ( \u03b7i + \u03c4iD2Y,W ) , (62)\nwhere x\u2217 is an arbitrary optimal solution of (1)-(58). Moreover, the number of inner iterations performed at the k-th outer iteration is bounded by (25).\nProof. The proof is similar to Theorem 4.1 in Lan and Zhou [2014], and hence omitted.\nWe now provide two different sets of parameter settings for {\u03b2k}, {\u03b3k}, {\u03b7k}, and {\u03c4k} which can guarantee the optimal convergence of the above variant of the CALGD method for saddle point optimization. Specifically, Corollary 4.4 gives a static setting for parameter {\u03c4k} under the assumption that the outer iteration limit N \u2265 1 is given, while a dynamic setting is provided in Corollary 4.5.\nCorollary 4.4. Assume the outer iteration limit N \u2265 1 is given. If\n\u03c4k \u2261 \u03c4 = 2\u2016A\u2016DXDY,W\u221a\u03c3\u03c9N , k \u2265 1, (63)\nand {\u03b2k}, {\u03b3k}, and {\u03b7k} used in Algorithm 5 are set to\n\u03b2k = 3L\u03c4k k+1 , \u03b3k = 3 k+2 , and \u03b7k = L\u03c4kD 2 X k2 , k \u2265 1, (64)\nthen the number of linear operator evaluations (for A and AT ) and the number of calls to the LOsep oracle performed by Algorithm 5 for finding an -solution of problem (1)-(58), respectively, is bounded by\nO { \u2016A\u2016DXDY,W\u221a\n\u03c3\u03c9\n} and O { \u2016A\u20162D2XD 2 Y,W\n\u03c3\u03c9 2\n} . (65)\nProof. In view of the result in Corollary 4.2 of Lan and Zhou [2014], our first bound in (65) immediately follows. Moreover, it follows from (45), (25), (63), (64) and (60) that the total number of calls to the LOsep oracle is bounded by\u2211N\nk=1Tk \u2264 \u2211N k=1O ( \u03b2kD 2 X\n\u03b7k\n) = \u2211N k=1O ( L\u03c4kD 2 X k+1 k2\nL\u03c4kD 2 X\n) = O(N2),\nwhich implies our second bound in (65).\nCorollary 4.5. Suppose that parameter {\u03c4k} is now set to\n\u03c4k = 2\u2016A\u2016DX DY,W \u221a \u03c3\u03c9k , k \u2265 1, (66)\nand the parameters {\u03b2k}, {\u03b3k}, and {\u03b7k} used in Algorithm 5 are set as in (64). Then, the number of linear operator evaluations (for A and AT ) and the number of calls to the LOsep oracle performed by Algorithm 5 for finding an -solution of problem (1)-(58) is bounded by the two bounds as given in (65) respectively.\nProof. The proof is similar to the Corollary 4.4, and hence omitted.\nIn view of the discussions in Chen et al. [2014], the obtained bound on the total number of operator evaluations (cf. first bound in (65)) is not improvable for solving the saddle point problems in (1)-(58). Moreover, according to Lan [2013] and the fact that the LOsep oracle is weaker than LO oracle, the O(1/ 2) bound on the total number of calls to the LOsep is not improvable."}, {"heading": "4.4 Non-smooth stochastic optimization: stochastic saddle point problems", "text": "In this subsection, we briefly discuss stochastic saddle point problems, i.e., only stochastic gradients of f\u03c4 (cf. (59)) are available. In particular, we consider the situation when the original objective function f in (1) is given by\nf(x) = E [ max y\u2208Y \u3008A\u03bex, y\u3009 \u2212 f\u0302(y, \u03be) ] , (67)\nwhere f\u0302(\u00b7, \u03be) is simple concave function for all \u03be \u2208 \u039e and A\u03be is a random linear operator such that\nE [ \u2016A\u03be\u20162 ] \u2264 L2A (68)\nWe can solve this stochastic saddle point problem by replacing (61) with\nxk = LCG(gk, xk\u22121, \u03b2k, \u03b7k),\nwhere gk = 1Bk \u2211Bk j=1 F \u2032 \u03c4k\n(zk, \u03bek,j) for some \u03c4k \u2265 0 and Bk \u2265 1. By properly specifying {\u03b2k}, {\u03b7k}, {\u03c4k}, and {Bk}, we can show that the number of linear operator evaluations (for A\u03be and AT\u03be ) and the number of calls to the LOsep oracle performed by this variant of CALSGD method for finding a stochastic -solution of problem (1)-(67) is bounded by\nO { L2AD 2 XD 2 Y,W\n\u03c3\u03c9 2\n} ,\nand\nO { L2AD 2 XD 2 Y,W\n\u03c3\u03c9 2 } with probability 1 \u2212 \u039b respectively. This result can be proved by combining the techniques in Section 2 and those in Theorem 4.3. However, we skip the details of these developments for the sake of simplicity."}, {"heading": "5 Experimental results", "text": "We present preliminary experimental results showing the performance of CALSGD compared to OFW for stochastic optimization. As examples we use the video co-localization problem, which can be solved by quadratic programming over a path polytope, different structured regression problems, and quadratic programming over the standard spectrahedron. In all cases we use objective functions of the form \u2016Ax \u2212 b\u20162, with A \u2208 Rm\u00d7n, i.e., m examples over a feasible region of dimension n. In each example there is a density parameter d specifying the fraction of non-zero entries in A. We compute b = Ax\u2217 with some feasible point x\u2217 so that in all examples the optimal value is 0. For comparability we use a batch size of 128 for all algorithms to compute each gradient and the full matrix A for the actual objective function values. Since the function values are not used by any algorithm, each algorithm has only the information provided by the 128 examples sampled in that specific round. All graphs show the function value using a logscale on the vertical axis. We implemented all algorithms using Python 2.7 using Gurobi 7.0 Gurobi Optimization [2016] as the solver for our linear models.\nIn Figure 1 we compare the performance of three algorithms: CALSGD, SCGS and OFW. As described above SCGS is the non-lazy counterpart of CALSGD. In the four graphs of Figure 1 we report the objective function value over the number of iterations, the wall clock time in seconds, the number of calls to the linear oracle, and the number of gradient evaluations in that order. In all these measures, our proposed algorithms outperform OFW by multiple orders of magnitude. As expected in number of iterations and number of gradient evaluations both versions CALSGD and SCGS perform equally well, however in wall clock time and in the number of calls to the linear oracle we observe the advantage of the weaker LOsep oracle over LO.\nFor the rest of the results we compare only the best version of our algorithm CALSGD with OFW. We report on each example the performance of the algorithms over the number of iterations and wall clock time in seconds. The three problem we consider are the following.\nVideo co-localization Video co-localization is the problem of identifying and object over multiple frames of a video. As shown by Joulin et al. [2014] this problem can be solved by quadratic programming over a path/flow polytope. In Figures 2, 3 and 4 we show that our algorithm CALSGD performs significantly better than OFW on this type of instances. We use path polytopes available at http://lime.cs.elte.hu/~kpeter/data/mcf/road/. The non-zero entries of A in this section are chosen uniformly from [0, 1] and the density parameter we used is d = 0.8.\nStructured regression For our structured regression instances we solve the objective function \u2016Ax\u2212 b\u20162 as described before over different polytopes. In Figure 5 the feasible region is the convex hull of all Hamiltonian cycles of graphs of different size. In Figure 6 the polytopes are the standard formulation of the cut problem and the Birkhoff polytope.\nConvex optimization over spectrahedra We consider instances of the problem of finding the minimum of a convex function over the standard spectrahedron, which is defined as Sn := {X \u2208 Rn\u00d7n | X < 0, tr(X) = 1}. In this case the linear minimization problem for an objective function C is solved by computing an eigenvector for the largest eigenvalue of \u2212C. We use the same method to implement LOsepSn . We show results on three different sized instances, in Figure 7 for n = 50, Figure 8 for n = 100 and in Figure 9 for n = 150."}], "references": [{"title": "A Modified Frank-Wolfe Algorithm for Computing Minimum-Area Enclosing Ellipsoidal Cylinders: Theory and Algorithms", "author": ["S. Ahipasaoglu", "M. Todd"], "venue": "Computational Geometry,", "citeRegEx": "Ahipasaoglu and Todd.,? \\Q2013\\E", "shortCiteRegEx": "Ahipasaoglu and Todd.", "year": 2013}, {"title": "On the equivalence between herding and conditional gradient algorithms", "author": ["F. Bach", "S. Lacoste-Julien", "G. Obozinski"], "venue": "In the 29th International Conference on Machine Learning,", "citeRegEx": "Bach et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Bach et al\\.", "year": 2012}, {"title": "A conditional gradient method with linear rate of convergence for solving convex linear systems", "author": ["A. Beck", "M. Teboulle"], "venue": "Math. Methods Oper. Res.,", "citeRegEx": "Beck and Teboulle.,? \\Q2004\\E", "shortCiteRegEx": "Beck and Teboulle.", "year": 2004}, {"title": "Lazifying conditional gradient algorithms", "author": ["G. Braun", "S. Pokutta", "D. Zink"], "venue": "arXiv preprint arXiv:1610.05120,", "citeRegEx": "Braun et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Braun et al\\.", "year": 2016}, {"title": "Optimal primal-dual methods for a class of saddle point problems", "author": ["Y. Chen", "G. Lan", "Y. Ouyang"], "venue": "SIAM Journal on Optimization,", "citeRegEx": "Chen et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Chen et al\\.", "year": 2014}, {"title": "Coresets, sparse greedy approximation, and the frank-wolfe algorithm", "author": ["K.L. Clarkson"], "venue": "ACM Trans. Algorithms,", "citeRegEx": "Clarkson.,? \\Q2010\\E", "shortCiteRegEx": "Clarkson.", "year": 2010}, {"title": "Dual subgradient algorithms for large-scale nonsmooth learning problems", "author": ["B. Cox", "A. Juditsky", "A.S. Nemirovski"], "venue": "Manuscript, School of ISyE, Georgia Tech, Atlanta, GA,", "citeRegEx": "Cox et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Cox et al\\.", "year": 2013}, {"title": "An algorithm for quadratic programming", "author": ["M. Frank", "P. Wolfe"], "venue": "Naval Research Logistics Quarterly,", "citeRegEx": "Frank and Wolfe.,? \\Q1956\\E", "shortCiteRegEx": "Frank and Wolfe.", "year": 1956}, {"title": "New Analysis and Results for the Frank-Wolfe Method", "author": ["R.M. Freund", "P. Grigas"], "venue": "ArXiv e-prints,", "citeRegEx": "Freund and Grigas.,? \\Q2013\\E", "shortCiteRegEx": "Freund and Grigas.", "year": 2013}, {"title": "A Linearly Convergent Conditional Gradient Algorithm with Applications to Online and Stochastic Optimization", "author": ["D. Garber", "E. Hazan"], "venue": null, "citeRegEx": "Garber and Hazan.,? \\Q2013\\E", "shortCiteRegEx": "Garber and Hazan.", "year": 2013}, {"title": "Optimal stochastic approximation algorithms for strongly convex stochastic composite optimization, I: a generic algorithmic framework", "author": ["S. Ghadimi", "G. Lan"], "venue": "SIAM Journal on Optimization,", "citeRegEx": "Ghadimi and Lan.,? \\Q2012\\E", "shortCiteRegEx": "Ghadimi and Lan.", "year": 2012}, {"title": "Optimal stochastic approximation algorithms for strongly convex stochastic composite optimization, II: shrinking procedures and optimal algorithms", "author": ["S. Ghadimi", "G. Lan"], "venue": "SIAM Journal on Optimization,", "citeRegEx": "Ghadimi and Lan.,? \\Q2013\\E", "shortCiteRegEx": "Ghadimi and Lan.", "year": 2013}, {"title": "Conditional gradient algorithms for machine learning", "author": ["Z. Harchaoui", "A. Juditsky", "A.S. Nemirovski"], "venue": "NIPS OPT workshop,", "citeRegEx": "Harchaoui et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Harchaoui et al\\.", "year": 2012}, {"title": "Sparse approximate solutions to semidefinite programs", "author": ["E. Hazan"], "venue": "LATIN 2008: Theoretical Informatics,", "citeRegEx": "Hazan.,? \\Q2008\\E", "shortCiteRegEx": "Hazan.", "year": 2008}, {"title": "Projection-free online learning", "author": ["E. Hazan", "S. Kale"], "venue": "arXiv preprint arXiv:1206.4657,", "citeRegEx": "Hazan and Kale.,? \\Q2012\\E", "shortCiteRegEx": "Hazan and Kale.", "year": 2012}, {"title": "Sparse Convex Optimization Methods for Machine Learning", "author": ["M. Jaggi"], "venue": "PhD thesis, ETH Zu\u0308rich,", "citeRegEx": "Jaggi.,? \\Q2011\\E", "shortCiteRegEx": "Jaggi.", "year": 2011}, {"title": "Revisiting frank-wolfe: Projection-free sparse convex optimization", "author": ["M. Jaggi"], "venue": "In the 30th International Conference on Machine Learning,", "citeRegEx": "Jaggi.,? \\Q2013\\E", "shortCiteRegEx": "Jaggi.", "year": 2013}, {"title": "Sulovsk\u00fd. A simple algorithm for nuclear norm regularized problems", "author": ["M.M. Jaggi"], "venue": "In the 27th International Conference on Machine Learning,", "citeRegEx": "Jaggi,? \\Q2010\\E", "shortCiteRegEx": "Jaggi", "year": 2010}, {"title": "Efficient image and video co-localization with frank-wolfe algorithm", "author": ["A. Joulin", "K. Tang", "L. Fei-Fei"], "venue": "In European Conference on Computer Vision,", "citeRegEx": "Joulin et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Joulin et al\\.", "year": 2014}, {"title": "Convex optimization under inexact first-order information", "author": ["G. Lan"], "venue": "Ph.D. dissertation, School of Industrial and Systems Engineering, Georgia Institute of Technology, Atlanta, GA 30332,", "citeRegEx": "Lan.,? \\Q2009\\E", "shortCiteRegEx": "Lan.", "year": 2009}, {"title": "An optimal method for stochastic composite optimization", "author": ["G. Lan"], "venue": "Mathematical Programming,", "citeRegEx": "Lan.,? \\Q2012\\E", "shortCiteRegEx": "Lan.", "year": 2012}, {"title": "The complexity of large-scale convex programming under a linear optimization oracle", "author": ["G. Lan"], "venue": "Technical Report,", "citeRegEx": "Lan.,? \\Q2013\\E", "shortCiteRegEx": "Lan.", "year": 2013}, {"title": "Conditional gradient sliding for convex optimization", "author": ["G. Lan", "Y. Zhou"], "venue": "Optimization-Online preprint (4605),", "citeRegEx": "Lan and Zhou.,? \\Q2014\\E", "shortCiteRegEx": "Lan and Zhou.", "year": 2014}, {"title": "Conditional gradient algorithms for rank one matrix approximations with a sparsity constraint", "author": ["R. Luss", "M. Teboulle"], "venue": "SIAM Review,", "citeRegEx": "Luss and Teboulle.,? \\Q2013\\E", "shortCiteRegEx": "Luss and Teboulle.", "year": 2013}, {"title": "A method for unconstrained convex minimization problem with the rate of convergence O(1/k)", "author": ["Y.E. Nesterov"], "venue": "Doklady AN SSSR,", "citeRegEx": "Nesterov.,? \\Q1983\\E", "shortCiteRegEx": "Nesterov.", "year": 1983}, {"title": "Introductory Lectures on Convex Optimization: a basic course", "author": ["Y.E. Nesterov"], "venue": "Kluwer Academic Publishers,", "citeRegEx": "Nesterov.,? \\Q2004\\E", "shortCiteRegEx": "Nesterov.", "year": 2004}, {"title": "Smooth minimization of nonsmooth functions", "author": ["Y.E. Nesterov"], "venue": "Mathematical Programming,", "citeRegEx": "Nesterov.,? \\Q2005\\E", "shortCiteRegEx": "Nesterov.", "year": 2005}, {"title": "Positive semidefinite metric learning using boosting-like algorithms", "author": ["C. Shen", "J. Kim", "L. Wang", "A. van den Hengel"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Shen et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Shen et al\\.", "year": 2012}], "referenceMentions": [{"referenceID": 13, "context": "Abstract In this work we introduce a conditional accelerated lazy stochastic gradient descent algorithm with optimal number of calls to a stochastic first-order oracle and convergence rate O( 1 \u03b52 ) improving over the projection-free, Online Frank-Wolfe based stochastic gradient descent of Hazan and Kale [2012] with convergence rate O( 1 \u03b54 ).", "startOffset": 291, "endOffset": 313}, {"referenceID": 7, "context": "The conditional gradient method (also known as: Frank-Wolfe algorithm) proposed in Frank and Wolfe [1956], gained much popularity in recent years due to its simple projection-free scheme and fast practical convergence rates.", "startOffset": 83, "endOffset": 106}, {"referenceID": 0, "context": ", Ahipasaoglu and Todd [2013], Bach et al.", "startOffset": 2, "endOffset": 30}, {"referenceID": 0, "context": ", Ahipasaoglu and Todd [2013], Bach et al. [2012], Beck and Teboulle [2004], Cox et al.", "startOffset": 2, "endOffset": 50}, {"referenceID": 0, "context": ", Ahipasaoglu and Todd [2013], Bach et al. [2012], Beck and Teboulle [2004], Cox et al.", "startOffset": 2, "endOffset": 76}, {"referenceID": 0, "context": ", Ahipasaoglu and Todd [2013], Bach et al. [2012], Beck and Teboulle [2004], Cox et al. [2013], Clarkson [2010], Freund and Grigas [2013], Hazan [2008], Harchaoui et al.", "startOffset": 2, "endOffset": 95}, {"referenceID": 0, "context": ", Ahipasaoglu and Todd [2013], Bach et al. [2012], Beck and Teboulle [2004], Cox et al. [2013], Clarkson [2010], Freund and Grigas [2013], Hazan [2008], Harchaoui et al.", "startOffset": 2, "endOffset": 112}, {"referenceID": 0, "context": ", Ahipasaoglu and Todd [2013], Bach et al. [2012], Beck and Teboulle [2004], Cox et al. [2013], Clarkson [2010], Freund and Grigas [2013], Hazan [2008], Harchaoui et al.", "startOffset": 2, "endOffset": 138}, {"referenceID": 0, "context": ", Ahipasaoglu and Todd [2013], Bach et al. [2012], Beck and Teboulle [2004], Cox et al. [2013], Clarkson [2010], Freund and Grigas [2013], Hazan [2008], Harchaoui et al.", "startOffset": 2, "endOffset": 152}, {"referenceID": 0, "context": ", Ahipasaoglu and Todd [2013], Bach et al. [2012], Beck and Teboulle [2004], Cox et al. [2013], Clarkson [2010], Freund and Grigas [2013], Hazan [2008], Harchaoui et al. [2012], Jaggi [2011, 2013], Jaggi and Sulovsk\u00fd [2010], Luss and Teboulle [2013], Shen et al.", "startOffset": 2, "endOffset": 177}, {"referenceID": 0, "context": ", Ahipasaoglu and Todd [2013], Bach et al. [2012], Beck and Teboulle [2004], Cox et al. [2013], Clarkson [2010], Freund and Grigas [2013], Hazan [2008], Harchaoui et al. [2012], Jaggi [2011, 2013], Jaggi and Sulovsk\u00fd [2010], Luss and Teboulle [2013], Shen et al.", "startOffset": 2, "endOffset": 224}, {"referenceID": 0, "context": ", Ahipasaoglu and Todd [2013], Bach et al. [2012], Beck and Teboulle [2004], Cox et al. [2013], Clarkson [2010], Freund and Grigas [2013], Hazan [2008], Harchaoui et al. [2012], Jaggi [2011, 2013], Jaggi and Sulovsk\u00fd [2010], Luss and Teboulle [2013], Shen et al.", "startOffset": 2, "endOffset": 250}, {"referenceID": 0, "context": ", Ahipasaoglu and Todd [2013], Bach et al. [2012], Beck and Teboulle [2004], Cox et al. [2013], Clarkson [2010], Freund and Grigas [2013], Hazan [2008], Harchaoui et al. [2012], Jaggi [2011, 2013], Jaggi and Sulovsk\u00fd [2010], Luss and Teboulle [2013], Shen et al. [2012], Hazan and Kale [2012], Lan [2013], Lan and Zhou [2014], Braun et al.", "startOffset": 2, "endOffset": 270}, {"referenceID": 0, "context": ", Ahipasaoglu and Todd [2013], Bach et al. [2012], Beck and Teboulle [2004], Cox et al. [2013], Clarkson [2010], Freund and Grigas [2013], Hazan [2008], Harchaoui et al. [2012], Jaggi [2011, 2013], Jaggi and Sulovsk\u00fd [2010], Luss and Teboulle [2013], Shen et al. [2012], Hazan and Kale [2012], Lan [2013], Lan and Zhou [2014], Braun et al.", "startOffset": 2, "endOffset": 293}, {"referenceID": 0, "context": ", Ahipasaoglu and Todd [2013], Bach et al. [2012], Beck and Teboulle [2004], Cox et al. [2013], Clarkson [2010], Freund and Grigas [2013], Hazan [2008], Harchaoui et al. [2012], Jaggi [2011, 2013], Jaggi and Sulovsk\u00fd [2010], Luss and Teboulle [2013], Shen et al. [2012], Hazan and Kale [2012], Lan [2013], Lan and Zhou [2014], Braun et al.", "startOffset": 2, "endOffset": 305}, {"referenceID": 0, "context": ", Ahipasaoglu and Todd [2013], Bach et al. [2012], Beck and Teboulle [2004], Cox et al. [2013], Clarkson [2010], Freund and Grigas [2013], Hazan [2008], Harchaoui et al. [2012], Jaggi [2011, 2013], Jaggi and Sulovsk\u00fd [2010], Luss and Teboulle [2013], Shen et al. [2012], Hazan and Kale [2012], Lan [2013], Lan and Zhou [2014], Braun et al.", "startOffset": 2, "endOffset": 326}, {"referenceID": 0, "context": ", Ahipasaoglu and Todd [2013], Bach et al. [2012], Beck and Teboulle [2004], Cox et al. [2013], Clarkson [2010], Freund and Grigas [2013], Hazan [2008], Harchaoui et al. [2012], Jaggi [2011, 2013], Jaggi and Sulovsk\u00fd [2010], Luss and Teboulle [2013], Shen et al. [2012], Hazan and Kale [2012], Lan [2013], Lan and Zhou [2014], Braun et al. [2016]).", "startOffset": 2, "endOffset": 347}, {"referenceID": 0, "context": ", Ahipasaoglu and Todd [2013], Bach et al. [2012], Beck and Teboulle [2004], Cox et al. [2013], Clarkson [2010], Freund and Grigas [2013], Hazan [2008], Harchaoui et al. [2012], Jaggi [2011, 2013], Jaggi and Sulovsk\u00fd [2010], Luss and Teboulle [2013], Shen et al. [2012], Hazan and Kale [2012], Lan [2013], Lan and Zhou [2014], Braun et al. [2016]). It should be noted that even the computational cost for LO oracle to solve the linear optimization subproblem (3) is high for some complex feasible regions. Recently, several approaches have been considered to address this issue. Jaggi [2013] demonstrated practical speed up for the CG method by approximately solving (3).", "startOffset": 2, "endOffset": 592}, {"referenceID": 0, "context": ", Ahipasaoglu and Todd [2013], Bach et al. [2012], Beck and Teboulle [2004], Cox et al. [2013], Clarkson [2010], Freund and Grigas [2013], Hazan [2008], Harchaoui et al. [2012], Jaggi [2011, 2013], Jaggi and Sulovsk\u00fd [2010], Luss and Teboulle [2013], Shen et al. [2012], Hazan and Kale [2012], Lan [2013], Lan and Zhou [2014], Braun et al. [2016]). It should be noted that even the computational cost for LO oracle to solve the linear optimization subproblem (3) is high for some complex feasible regions. Recently, several approaches have been considered to address this issue. Jaggi [2013] demonstrated practical speed up for the CG method by approximately solving (3). Braun et al. [2016] proposed a class of modified CG methods, namely the lazy conditional gradient (LCG) algorithms, which call a weak separation oracle rather than solving the linear subproblem (3) in the classical CG method.", "startOffset": 2, "endOffset": 692}, {"referenceID": 0, "context": ", Ahipasaoglu and Todd [2013], Bach et al. [2012], Beck and Teboulle [2004], Cox et al. [2013], Clarkson [2010], Freund and Grigas [2013], Hazan [2008], Harchaoui et al. [2012], Jaggi [2011, 2013], Jaggi and Sulovsk\u00fd [2010], Luss and Teboulle [2013], Shen et al. [2012], Hazan and Kale [2012], Lan [2013], Lan and Zhou [2014], Braun et al. [2016]). It should be noted that even the computational cost for LO oracle to solve the linear optimization subproblem (3) is high for some complex feasible regions. Recently, several approaches have been considered to address this issue. Jaggi [2013] demonstrated practical speed up for the CG method by approximately solving (3). Braun et al. [2016] proposed a class of modified CG methods, namely the lazy conditional gradient (LCG) algorithms, which call a weak separation oracle rather than solving the linear subproblem (3) in the classical CG method. In fact, the weak separation oracle is computationally more efficient than approximate minimization used in Jaggi [2013], at the expense of not providing any guarantee for function value improvement with respect to (3).", "startOffset": 2, "endOffset": 1019}, {"referenceID": 0, "context": ", Ahipasaoglu and Todd [2013], Bach et al. [2012], Beck and Teboulle [2004], Cox et al. [2013], Clarkson [2010], Freund and Grigas [2013], Hazan [2008], Harchaoui et al. [2012], Jaggi [2011, 2013], Jaggi and Sulovsk\u00fd [2010], Luss and Teboulle [2013], Shen et al. [2012], Hazan and Kale [2012], Lan [2013], Lan and Zhou [2014], Braun et al. [2016]). It should be noted that even the computational cost for LO oracle to solve the linear optimization subproblem (3) is high for some complex feasible regions. Recently, several approaches have been considered to address this issue. Jaggi [2013] demonstrated practical speed up for the CG method by approximately solving (3). Braun et al. [2016] proposed a class of modified CG methods, namely the lazy conditional gradient (LCG) algorithms, which call a weak separation oracle rather than solving the linear subproblem (3) in the classical CG method. In fact, the weak separation oracle is computationally more efficient than approximate minimization used in Jaggi [2013], at the expense of not providing any guarantee for function value improvement with respect to (3). Furthermore, as shown in Jaggi [2013] and Lan [2013], the total number of iterations for the LCP methods to find an -solution of (1) (i.", "startOffset": 2, "endOffset": 1156}, {"referenceID": 0, "context": ", Ahipasaoglu and Todd [2013], Bach et al. [2012], Beck and Teboulle [2004], Cox et al. [2013], Clarkson [2010], Freund and Grigas [2013], Hazan [2008], Harchaoui et al. [2012], Jaggi [2011, 2013], Jaggi and Sulovsk\u00fd [2010], Luss and Teboulle [2013], Shen et al. [2012], Hazan and Kale [2012], Lan [2013], Lan and Zhou [2014], Braun et al. [2016]). It should be noted that even the computational cost for LO oracle to solve the linear optimization subproblem (3) is high for some complex feasible regions. Recently, several approaches have been considered to address this issue. Jaggi [2013] demonstrated practical speed up for the CG method by approximately solving (3). Braun et al. [2016] proposed a class of modified CG methods, namely the lazy conditional gradient (LCG) algorithms, which call a weak separation oracle rather than solving the linear subproblem (3) in the classical CG method. In fact, the weak separation oracle is computationally more efficient than approximate minimization used in Jaggi [2013], at the expense of not providing any guarantee for function value improvement with respect to (3). Furthermore, as shown in Jaggi [2013] and Lan [2013], the total number of iterations for the LCP methods to find an -solution of (1) (i.", "startOffset": 2, "endOffset": 1171}, {"referenceID": 0, "context": ", Ahipasaoglu and Todd [2013], Bach et al. [2012], Beck and Teboulle [2004], Cox et al. [2013], Clarkson [2010], Freund and Grigas [2013], Hazan [2008], Harchaoui et al. [2012], Jaggi [2011, 2013], Jaggi and Sulovsk\u00fd [2010], Luss and Teboulle [2013], Shen et al. [2012], Hazan and Kale [2012], Lan [2013], Lan and Zhou [2014], Braun et al. [2016]). It should be noted that even the computational cost for LO oracle to solve the linear optimization subproblem (3) is high for some complex feasible regions. Recently, several approaches have been considered to address this issue. Jaggi [2013] demonstrated practical speed up for the CG method by approximately solving (3). Braun et al. [2016] proposed a class of modified CG methods, namely the lazy conditional gradient (LCG) algorithms, which call a weak separation oracle rather than solving the linear subproblem (3) in the classical CG method. In fact, the weak separation oracle is computationally more efficient than approximate minimization used in Jaggi [2013], at the expense of not providing any guarantee for function value improvement with respect to (3). Furthermore, as shown in Jaggi [2013] and Lan [2013], the total number of iterations for the LCP methods to find an -solution of (1) (i.e., a point x\u0304 \u2208 X, s.t. f(x\u0304) \u2212 f\u2217 \u2264 ) cannot be smaller than O(1/ ), which is not improvable even when the objective function f is strongly convex. Improved complexity results can only be obtained under stronger assumptions on the LO oracle or the feasible set (see, e.g., Garber and Hazan [2013], Lan [2013]).", "startOffset": 2, "endOffset": 1553}, {"referenceID": 0, "context": ", Ahipasaoglu and Todd [2013], Bach et al. [2012], Beck and Teboulle [2004], Cox et al. [2013], Clarkson [2010], Freund and Grigas [2013], Hazan [2008], Harchaoui et al. [2012], Jaggi [2011, 2013], Jaggi and Sulovsk\u00fd [2010], Luss and Teboulle [2013], Shen et al. [2012], Hazan and Kale [2012], Lan [2013], Lan and Zhou [2014], Braun et al. [2016]). It should be noted that even the computational cost for LO oracle to solve the linear optimization subproblem (3) is high for some complex feasible regions. Recently, several approaches have been considered to address this issue. Jaggi [2013] demonstrated practical speed up for the CG method by approximately solving (3). Braun et al. [2016] proposed a class of modified CG methods, namely the lazy conditional gradient (LCG) algorithms, which call a weak separation oracle rather than solving the linear subproblem (3) in the classical CG method. In fact, the weak separation oracle is computationally more efficient than approximate minimization used in Jaggi [2013], at the expense of not providing any guarantee for function value improvement with respect to (3). Furthermore, as shown in Jaggi [2013] and Lan [2013], the total number of iterations for the LCP methods to find an -solution of (1) (i.e., a point x\u0304 \u2208 X, s.t. f(x\u0304) \u2212 f\u2217 \u2264 ) cannot be smaller than O(1/ ), which is not improvable even when the objective function f is strongly convex. Improved complexity results can only be obtained under stronger assumptions on the LO oracle or the feasible set (see, e.g., Garber and Hazan [2013], Lan [2013]).", "startOffset": 2, "endOffset": 1565}, {"referenceID": 0, "context": ", Ahipasaoglu and Todd [2013], Bach et al. [2012], Beck and Teboulle [2004], Cox et al. [2013], Clarkson [2010], Freund and Grigas [2013], Hazan [2008], Harchaoui et al. [2012], Jaggi [2011, 2013], Jaggi and Sulovsk\u00fd [2010], Luss and Teboulle [2013], Shen et al. [2012], Hazan and Kale [2012], Lan [2013], Lan and Zhou [2014], Braun et al. [2016]). It should be noted that even the computational cost for LO oracle to solve the linear optimization subproblem (3) is high for some complex feasible regions. Recently, several approaches have been considered to address this issue. Jaggi [2013] demonstrated practical speed up for the CG method by approximately solving (3). Braun et al. [2016] proposed a class of modified CG methods, namely the lazy conditional gradient (LCG) algorithms, which call a weak separation oracle rather than solving the linear subproblem (3) in the classical CG method. In fact, the weak separation oracle is computationally more efficient than approximate minimization used in Jaggi [2013], at the expense of not providing any guarantee for function value improvement with respect to (3). Furthermore, as shown in Jaggi [2013] and Lan [2013], the total number of iterations for the LCP methods to find an -solution of (1) (i.e., a point x\u0304 \u2208 X, s.t. f(x\u0304) \u2212 f\u2217 \u2264 ) cannot be smaller than O(1/ ), which is not improvable even when the objective function f is strongly convex. Improved complexity results can only be obtained under stronger assumptions on the LO oracle or the feasible set (see, e.g., Garber and Hazan [2013], Lan [2013]). However, the O(1/ ) bound does not preclude the existence of more efficient LCP algorithms for solving (1). Lan and Zhou [2014] proposed a class of conditional gradient sliding methods (CGS), which significantly improve the complexity bounds in terms of the number of gradient evaluations while maintaining optimal complexity bounds for the LO oracle calls required by the LCP methods.", "startOffset": 2, "endOffset": 1695}, {"referenceID": 0, "context": ", Ahipasaoglu and Todd [2013], Bach et al. [2012], Beck and Teboulle [2004], Cox et al. [2013], Clarkson [2010], Freund and Grigas [2013], Hazan [2008], Harchaoui et al. [2012], Jaggi [2011, 2013], Jaggi and Sulovsk\u00fd [2010], Luss and Teboulle [2013], Shen et al. [2012], Hazan and Kale [2012], Lan [2013], Lan and Zhou [2014], Braun et al. [2016]). It should be noted that even the computational cost for LO oracle to solve the linear optimization subproblem (3) is high for some complex feasible regions. Recently, several approaches have been considered to address this issue. Jaggi [2013] demonstrated practical speed up for the CG method by approximately solving (3). Braun et al. [2016] proposed a class of modified CG methods, namely the lazy conditional gradient (LCG) algorithms, which call a weak separation oracle rather than solving the linear subproblem (3) in the classical CG method. In fact, the weak separation oracle is computationally more efficient than approximate minimization used in Jaggi [2013], at the expense of not providing any guarantee for function value improvement with respect to (3). Furthermore, as shown in Jaggi [2013] and Lan [2013], the total number of iterations for the LCP methods to find an -solution of (1) (i.e., a point x\u0304 \u2208 X, s.t. f(x\u0304) \u2212 f\u2217 \u2264 ) cannot be smaller than O(1/ ), which is not improvable even when the objective function f is strongly convex. Improved complexity results can only be obtained under stronger assumptions on the LO oracle or the feasible set (see, e.g., Garber and Hazan [2013], Lan [2013]). However, the O(1/ ) bound does not preclude the existence of more efficient LCP algorithms for solving (1). Lan and Zhou [2014] proposed a class of conditional gradient sliding methods (CGS), which significantly improve the complexity bounds in terms of the number of gradient evaluations while maintaining optimal complexity bounds for the LO oracle calls required by the LCP methods. Inspired by Braun et al. [2016] and Lan and Zhou [2014], in this paper we focus on a class of modified LCP methods that require only improving solutions for a certain separation problem rather than solving the linear optimization subproblem (3) explicitly through LO oracle calls while simultaneously minimizing the number of gradient evaluations when performing weak separation over the feasible set X.", "startOffset": 2, "endOffset": 1985}, {"referenceID": 0, "context": ", Ahipasaoglu and Todd [2013], Bach et al. [2012], Beck and Teboulle [2004], Cox et al. [2013], Clarkson [2010], Freund and Grigas [2013], Hazan [2008], Harchaoui et al. [2012], Jaggi [2011, 2013], Jaggi and Sulovsk\u00fd [2010], Luss and Teboulle [2013], Shen et al. [2012], Hazan and Kale [2012], Lan [2013], Lan and Zhou [2014], Braun et al. [2016]). It should be noted that even the computational cost for LO oracle to solve the linear optimization subproblem (3) is high for some complex feasible regions. Recently, several approaches have been considered to address this issue. Jaggi [2013] demonstrated practical speed up for the CG method by approximately solving (3). Braun et al. [2016] proposed a class of modified CG methods, namely the lazy conditional gradient (LCG) algorithms, which call a weak separation oracle rather than solving the linear subproblem (3) in the classical CG method. In fact, the weak separation oracle is computationally more efficient than approximate minimization used in Jaggi [2013], at the expense of not providing any guarantee for function value improvement with respect to (3). Furthermore, as shown in Jaggi [2013] and Lan [2013], the total number of iterations for the LCP methods to find an -solution of (1) (i.e., a point x\u0304 \u2208 X, s.t. f(x\u0304) \u2212 f\u2217 \u2264 ) cannot be smaller than O(1/ ), which is not improvable even when the objective function f is strongly convex. Improved complexity results can only be obtained under stronger assumptions on the LO oracle or the feasible set (see, e.g., Garber and Hazan [2013], Lan [2013]). However, the O(1/ ) bound does not preclude the existence of more efficient LCP algorithms for solving (1). Lan and Zhou [2014] proposed a class of conditional gradient sliding methods (CGS), which significantly improve the complexity bounds in terms of the number of gradient evaluations while maintaining optimal complexity bounds for the LO oracle calls required by the LCP methods. Inspired by Braun et al. [2016] and Lan and Zhou [2014], in this paper we focus on a class of modified LCP methods that require only improving solutions for a certain separation problem rather than solving the linear optimization subproblem (3) explicitly through LO oracle calls while simultaneously minimizing the number of gradient evaluations when performing weak separation over the feasible set X.", "startOffset": 2, "endOffset": 2009}, {"referenceID": 0, "context": ", Ahipasaoglu and Todd [2013], Bach et al. [2012], Beck and Teboulle [2004], Cox et al. [2013], Clarkson [2010], Freund and Grigas [2013], Hazan [2008], Harchaoui et al. [2012], Jaggi [2011, 2013], Jaggi and Sulovsk\u00fd [2010], Luss and Teboulle [2013], Shen et al. [2012], Hazan and Kale [2012], Lan [2013], Lan and Zhou [2014], Braun et al. [2016]). It should be noted that even the computational cost for LO oracle to solve the linear optimization subproblem (3) is high for some complex feasible regions. Recently, several approaches have been considered to address this issue. Jaggi [2013] demonstrated practical speed up for the CG method by approximately solving (3). Braun et al. [2016] proposed a class of modified CG methods, namely the lazy conditional gradient (LCG) algorithms, which call a weak separation oracle rather than solving the linear subproblem (3) in the classical CG method. In fact, the weak separation oracle is computationally more efficient than approximate minimization used in Jaggi [2013], at the expense of not providing any guarantee for function value improvement with respect to (3). Furthermore, as shown in Jaggi [2013] and Lan [2013], the total number of iterations for the LCP methods to find an -solution of (1) (i.e., a point x\u0304 \u2208 X, s.t. f(x\u0304) \u2212 f\u2217 \u2264 ) cannot be smaller than O(1/ ), which is not improvable even when the objective function f is strongly convex. Improved complexity results can only be obtained under stronger assumptions on the LO oracle or the feasible set (see, e.g., Garber and Hazan [2013], Lan [2013]). However, the O(1/ ) bound does not preclude the existence of more efficient LCP algorithms for solving (1). Lan and Zhou [2014] proposed a class of conditional gradient sliding methods (CGS), which significantly improve the complexity bounds in terms of the number of gradient evaluations while maintaining optimal complexity bounds for the LO oracle calls required by the LCP methods. Inspired by Braun et al. [2016] and Lan and Zhou [2014], in this paper we focus on a class of modified LCP methods that require only improving solutions for a certain separation problem rather than solving the linear optimization subproblem (3) explicitly through LO oracle calls while simultaneously minimizing the number of gradient evaluations when performing weak separation over the feasible set X. At first these two objectives seem to be incompatible as Braun et al. [2016] gives up the dual guarantee to simplify the oracle, while the dual guarantee of CG iterations is at the core of the analysis in Lan and Zhou [2014].", "startOffset": 2, "endOffset": 2434}, {"referenceID": 0, "context": ", Ahipasaoglu and Todd [2013], Bach et al. [2012], Beck and Teboulle [2004], Cox et al. [2013], Clarkson [2010], Freund and Grigas [2013], Hazan [2008], Harchaoui et al. [2012], Jaggi [2011, 2013], Jaggi and Sulovsk\u00fd [2010], Luss and Teboulle [2013], Shen et al. [2012], Hazan and Kale [2012], Lan [2013], Lan and Zhou [2014], Braun et al. [2016]). It should be noted that even the computational cost for LO oracle to solve the linear optimization subproblem (3) is high for some complex feasible regions. Recently, several approaches have been considered to address this issue. Jaggi [2013] demonstrated practical speed up for the CG method by approximately solving (3). Braun et al. [2016] proposed a class of modified CG methods, namely the lazy conditional gradient (LCG) algorithms, which call a weak separation oracle rather than solving the linear subproblem (3) in the classical CG method. In fact, the weak separation oracle is computationally more efficient than approximate minimization used in Jaggi [2013], at the expense of not providing any guarantee for function value improvement with respect to (3). Furthermore, as shown in Jaggi [2013] and Lan [2013], the total number of iterations for the LCP methods to find an -solution of (1) (i.e., a point x\u0304 \u2208 X, s.t. f(x\u0304) \u2212 f\u2217 \u2264 ) cannot be smaller than O(1/ ), which is not improvable even when the objective function f is strongly convex. Improved complexity results can only be obtained under stronger assumptions on the LO oracle or the feasible set (see, e.g., Garber and Hazan [2013], Lan [2013]). However, the O(1/ ) bound does not preclude the existence of more efficient LCP algorithms for solving (1). Lan and Zhou [2014] proposed a class of conditional gradient sliding methods (CGS), which significantly improve the complexity bounds in terms of the number of gradient evaluations while maintaining optimal complexity bounds for the LO oracle calls required by the LCP methods. Inspired by Braun et al. [2016] and Lan and Zhou [2014], in this paper we focus on a class of modified LCP methods that require only improving solutions for a certain separation problem rather than solving the linear optimization subproblem (3) explicitly through LO oracle calls while simultaneously minimizing the number of gradient evaluations when performing weak separation over the feasible set X. At first these two objectives seem to be incompatible as Braun et al. [2016] gives up the dual guarantee to simplify the oracle, while the dual guarantee of CG iterations is at the core of the analysis in Lan and Zhou [2014]. We overcome this impasse by carefully modifying both techniques.", "startOffset": 2, "endOffset": 2582}, {"referenceID": 0, "context": ", Ahipasaoglu and Todd [2013], Bach et al. [2012], Beck and Teboulle [2004], Cox et al. [2013], Clarkson [2010], Freund and Grigas [2013], Hazan [2008], Harchaoui et al. [2012], Jaggi [2011, 2013], Jaggi and Sulovsk\u00fd [2010], Luss and Teboulle [2013], Shen et al. [2012], Hazan and Kale [2012], Lan [2013], Lan and Zhou [2014], Braun et al. [2016]). It should be noted that even the computational cost for LO oracle to solve the linear optimization subproblem (3) is high for some complex feasible regions. Recently, several approaches have been considered to address this issue. Jaggi [2013] demonstrated practical speed up for the CG method by approximately solving (3). Braun et al. [2016] proposed a class of modified CG methods, namely the lazy conditional gradient (LCG) algorithms, which call a weak separation oracle rather than solving the linear subproblem (3) in the classical CG method. In fact, the weak separation oracle is computationally more efficient than approximate minimization used in Jaggi [2013], at the expense of not providing any guarantee for function value improvement with respect to (3). Furthermore, as shown in Jaggi [2013] and Lan [2013], the total number of iterations for the LCP methods to find an -solution of (1) (i.e., a point x\u0304 \u2208 X, s.t. f(x\u0304) \u2212 f\u2217 \u2264 ) cannot be smaller than O(1/ ), which is not improvable even when the objective function f is strongly convex. Improved complexity results can only be obtained under stronger assumptions on the LO oracle or the feasible set (see, e.g., Garber and Hazan [2013], Lan [2013]). However, the O(1/ ) bound does not preclude the existence of more efficient LCP algorithms for solving (1). Lan and Zhou [2014] proposed a class of conditional gradient sliding methods (CGS), which significantly improve the complexity bounds in terms of the number of gradient evaluations while maintaining optimal complexity bounds for the LO oracle calls required by the LCP methods. Inspired by Braun et al. [2016] and Lan and Zhou [2014], in this paper we focus on a class of modified LCP methods that require only improving solutions for a certain separation problem rather than solving the linear optimization subproblem (3) explicitly through LO oracle calls while simultaneously minimizing the number of gradient evaluations when performing weak separation over the feasible set X. At first these two objectives seem to be incompatible as Braun et al. [2016] gives up the dual guarantee to simplify the oracle, while the dual guarantee of CG iterations is at the core of the analysis in Lan and Zhou [2014]. We overcome this impasse by carefully modifying both techniques. It should be mentioned that Hazan and Kale [2012] proposed the online Frank-Wolfe (OFW) algorithm, which obtains O(1/ ) rate of convergence for stochastic problems.", "startOffset": 2, "endOffset": 2698}, {"referenceID": 0, "context": ", Ahipasaoglu and Todd [2013], Bach et al. [2012], Beck and Teboulle [2004], Cox et al. [2013], Clarkson [2010], Freund and Grigas [2013], Hazan [2008], Harchaoui et al. [2012], Jaggi [2011, 2013], Jaggi and Sulovsk\u00fd [2010], Luss and Teboulle [2013], Shen et al. [2012], Hazan and Kale [2012], Lan [2013], Lan and Zhou [2014], Braun et al. [2016]). It should be noted that even the computational cost for LO oracle to solve the linear optimization subproblem (3) is high for some complex feasible regions. Recently, several approaches have been considered to address this issue. Jaggi [2013] demonstrated practical speed up for the CG method by approximately solving (3). Braun et al. [2016] proposed a class of modified CG methods, namely the lazy conditional gradient (LCG) algorithms, which call a weak separation oracle rather than solving the linear subproblem (3) in the classical CG method. In fact, the weak separation oracle is computationally more efficient than approximate minimization used in Jaggi [2013], at the expense of not providing any guarantee for function value improvement with respect to (3). Furthermore, as shown in Jaggi [2013] and Lan [2013], the total number of iterations for the LCP methods to find an -solution of (1) (i.e., a point x\u0304 \u2208 X, s.t. f(x\u0304) \u2212 f\u2217 \u2264 ) cannot be smaller than O(1/ ), which is not improvable even when the objective function f is strongly convex. Improved complexity results can only be obtained under stronger assumptions on the LO oracle or the feasible set (see, e.g., Garber and Hazan [2013], Lan [2013]). However, the O(1/ ) bound does not preclude the existence of more efficient LCP algorithms for solving (1). Lan and Zhou [2014] proposed a class of conditional gradient sliding methods (CGS), which significantly improve the complexity bounds in terms of the number of gradient evaluations while maintaining optimal complexity bounds for the LO oracle calls required by the LCP methods. Inspired by Braun et al. [2016] and Lan and Zhou [2014], in this paper we focus on a class of modified LCP methods that require only improving solutions for a certain separation problem rather than solving the linear optimization subproblem (3) explicitly through LO oracle calls while simultaneously minimizing the number of gradient evaluations when performing weak separation over the feasible set X. At first these two objectives seem to be incompatible as Braun et al. [2016] gives up the dual guarantee to simplify the oracle, while the dual guarantee of CG iterations is at the core of the analysis in Lan and Zhou [2014]. We overcome this impasse by carefully modifying both techniques. It should be mentioned that Hazan and Kale [2012] proposed the online Frank-Wolfe (OFW) algorithm, which obtains O(1/ ) rate of convergence for stochastic problems. Indeed, if we consider the objective function f(x) := E[F (x, \u03be)] for stochastic optimization, the OFW method can be applied to solve (1) by viewing the iteratively observed function ft as the current realization of the true objective function f , i.e., ft(\u00b7) = F (\u00b7, \u03bet). Without re-evaluating the (sub)gradients at the updated points, the OFW obtains O(T\u22121/4) bound for any (smooth or non-smooth) objective functions (see Theorem 4.4 in Hazan and Kale [2012]), which implies O(1/ ) rate of convergence in terms of the number of (sub)gradient evaluations for stochastic optimization.", "startOffset": 2, "endOffset": 3274}, {"referenceID": 3, "context": "By incorporating a modified LCG procedure [Braun et al., 2016] into a modified CGS method [Lan and Zhou, 2014] we obtain a new conditional accelerated lazy stochastic gradient descent algorithm (CALSGD) and we show that the number of calls to the weak separation oracle can be optimally bounded by O(1/ ), while the optimal bound of O(1/ ) on the total number of calls to the SFO oracle can be maintained.", "startOffset": 42, "endOffset": 62}, {"referenceID": 22, "context": ", 2016] into a modified CGS method [Lan and Zhou, 2014] we obtain a new conditional accelerated lazy stochastic gradient descent algorithm (CALSGD) and we show that the number of calls to the weak separation oracle can be optimally bounded by O(1/ ), while the optimal bound of O(1/ ) on the total number of calls to the SFO oracle can be maintained.", "startOffset": 35, "endOffset": 55}, {"referenceID": 19, "context": "Our algorithmic framework is inspired by the SCGS method by Lan and Zhou [2014]. However, instead of applying the classic CG method to solve the projection subproblem appearing in the accelerated gradient (AG) method, the CALSGD method utilizes a modified parameter-free LCG algorithm (see Section 2.", "startOffset": 60, "endOffset": 80}, {"referenceID": 19, "context": "Secondly, in view of the SCGS method in Lan and Zhou [2014], xk obtained in (13) should be an approximate solution to the gradient sliding subproblem", "startOffset": 40, "endOffset": 60}, {"referenceID": 19, "context": ", \u03b7k = 0), then CALSGD will reduce to the accelerated stochastic approximation method by Lan [2009, 2012]. However, by employing the LCG procedure (see Procedure 1 in Subsection 2.2), we only need to use a weak separation oracle, but still maintaining the optimal bounds on stochastic first-order oracle as in Lan [2009, 2012], Lan and Zhou [2014]. Thirdly, observe that the CALSGD method so far is conceptual only as we have not yet specified the LCG procedure and the parameters {Bk}, {\u03b2k}, {\u03b3k}, and {\u03b7k}.", "startOffset": 89, "endOffset": 348}, {"referenceID": 3, "context": "The LCG procedure presented in this subsection, a modification of the vanilla LCG method in Braun et al. [2016], goes several steps further than CG and even vanilla LCG method.", "startOffset": 92, "endOffset": 112}, {"referenceID": 3, "context": "We present the LCG procedure based on Braun et al. [2016] below.", "startOffset": 38, "endOffset": 58}, {"referenceID": 3, "context": "1 of Braun et al. [2016]), and it halves the value of \u03a6t only when the current oracle call is negative.", "startOffset": 5, "endOffset": 25}, {"referenceID": 3, "context": "1 in Braun et al. [2016], it is clear that the number of iterations in the first phase can be bounded as", "startOffset": 5, "endOffset": 25}, {"referenceID": 3, "context": "1 in Braun et al. [2016], we obtain that the total number of positive calls in this phase can be bounded by 4\u03b1 C\u03c6 \u03b7 , if \u03b7 < \u03b1C\u03c6, or by 4\u03b1 if \u03b7 \u2265 \u03b1C\u03c6.", "startOffset": 5, "endOffset": 25}, {"referenceID": 16, "context": "The shrinking conditional gradient method in Lan [2013] needs to make additional assumptions on the LO oracle to obtain a linear rate of convergence.", "startOffset": 45, "endOffset": 56}, {"referenceID": 15, "context": "In view of the lower complexity bound established for the LO oracle to solve strongly convex problems in Jaggi [2013] and Lan [2013], our bound for the LOsep oracle is not improvable.", "startOffset": 105, "endOffset": 118}, {"referenceID": 15, "context": "In view of the lower complexity bound established for the LO oracle to solve strongly convex problems in Jaggi [2013] and Lan [2013], our bound for the LOsep oracle is not improvable.", "startOffset": 105, "endOffset": 133}, {"referenceID": 19, "context": "5 in Lan and Zhou [2014], we conclude that S = \u2308 log2 max ( 1, \u03b40 )\u2309 .", "startOffset": 5, "endOffset": 25}, {"referenceID": 19, "context": "Moreover, in view of the complexity results established in Lan [2013] and the fact that the LOsep oracle is weaker than the LO oracle, the bound on the total number of calls to the LOsep oracle (cf.", "startOffset": 59, "endOffset": 70}, {"referenceID": 19, "context": "4 in Lan and Zhou [2014], the total number of phases, S, performed by CALSGD method to find a stochastic -solution of problem (1)-(8) is bounded by (53).", "startOffset": 5, "endOffset": 25}, {"referenceID": 24, "context": "However, as shown by Nesterov [2005], the function f(\u00b7) in (58) can be closely approximated by a class of smooth convex functions.", "startOffset": 21, "endOffset": 37}, {"referenceID": 24, "context": "Moreover, Nesterov [2005] shows that f\u03c4 (\u00b7) is differentiable and its gradients are Lipschitz continuous with the Lipschitz constant given by L\u03c4 := \u2016A\u2016 2 \u03c4\u03c3\u03c9 .", "startOffset": 10, "endOffset": 26}, {"referenceID": 19, "context": "1 in Lan and Zhou [2014], and hence omitted.", "startOffset": 5, "endOffset": 25}, {"referenceID": 19, "context": "2 of Lan and Zhou [2014], our first bound in (65) immediately follows.", "startOffset": 5, "endOffset": 25}, {"referenceID": 4, "context": "In view of the discussions in Chen et al. [2014], the obtained bound on the total number of operator evaluations (cf.", "startOffset": 30, "endOffset": 49}, {"referenceID": 4, "context": "In view of the discussions in Chen et al. [2014], the obtained bound on the total number of operator evaluations (cf. first bound in (65)) is not improvable for solving the saddle point problems in (1)-(58). Moreover, according to Lan [2013] and the fact that the LOsep oracle is weaker than LO oracle, the O(1/ ) bound on the total number of calls to the LOsep is not improvable.", "startOffset": 30, "endOffset": 242}, {"referenceID": 18, "context": "As shown by Joulin et al. [2014] this problem can be solved by quadratic programming over a path/flow polytope.", "startOffset": 12, "endOffset": 33}, {"referenceID": 13, "context": "In the example of the Birkhoff polytope it almost looks like as if OFW converges suboptimally, however this is due to the large number of iterations required: the convergence rate of OFW as shown by Hazan and Kale [2012] is O(T\u22121/4), so if we compute the improvement with logarithmic scale, from, e.", "startOffset": 199, "endOffset": 221}, {"referenceID": 13, "context": "In the example of the Birkhoff polytope it almost looks like as if OFW converges suboptimally, however this is due to the large number of iterations required: the convergence rate of OFW as shown by Hazan and Kale [2012] is O(T\u22121/4), so if we compute the improvement with logarithmic scale, from, e.g., iteration 1500 to iteration 4500, we get \u22121/4(log(1500)\u2212 log(4500)) \u2248 0.", "startOffset": 199, "endOffset": 359}], "year": 2017, "abstractText": "In this work we introduce a conditional accelerated lazy stochastic gradient descent algorithm with optimal number of calls to a stochastic first-order oracle and convergence rate O( 1 \u03b52 ) improving over the projection-free, Online Frank-Wolfe based stochastic gradient descent of Hazan and Kale [2012] with convergence rate O( 1 \u03b54 ).", "creator": "LaTeX with hyperref package"}}}