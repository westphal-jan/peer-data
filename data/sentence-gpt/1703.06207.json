{"id": "1703.06207", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "17-Mar-2017", "title": "Cooperating with Machines", "abstract": "Since Alan Turing envisioned Artificial Intelligence (AI) [1], a major driving force behind technical progress has been competition with human cognition. Historical milestones have been frequently associated with computers matching or outperforming humans in difficult cognitive tasks (e.g. face recognition [2], personality classification [3], driving cars [4], or playing video games [5]), or defeating humans in strategic zero-sum encounters (e.g. Chess [6], Checkers [7], Jeopardy! [8], Poker [9], or Go [10]). In contrast, less attention has been given to developing autonomous machines that establish mutually cooperative relationships with people who may not share the machine's preferences. A main challenge has been that human cooperation does not require sheer computational power, but rather relies on intuition [11], cultural norms [12], emotions and signals [13, 14, 15, 16], and pre-evolved dispositions toward cooperation [17], common-sense mechanisms that are difficult to encode in machines for arbitrary contexts. Here, we combine a state-of-the-art machine-learning algorithm with novel mechanisms for generating and acting on signals to produce a new learning algorithm that cooperates with people and other machines at levels that rival human cooperation in a variety of two-player repeated stochastic games. This is the first general-purpose algorithm that is capable, given a description of a previously unseen game environment, of learning to cooperate with people within short timescales in scenarios previously unanticipated by algorithm designers. This is achieved without complex opponent modeling or higher-order theories of mind, thus showing that flexible, fast, and general human-machine cooperation is computationally achievable using a non-trivial, but ultimately simple, set of algorithmic mechanisms. The goal of this study is to test the limits of a Turing machine-learning algorithm that is capable of developing a robust set of neural networks, using very different mathematical methods. Using a general-purpose neural network, we have obtained a novel and comprehensive set of neural networks that is capable of reproducing and executing the tasks associated with the new learning algorithm. For instance, the number of computers that have been built to perform tasks with different computer architectures can be much larger than the number of computational cores required to build the algorithms, or even in some cases large, machine-learning applications. At this point, we hope that this algorithm can become an important starting point for our research in understanding the effects of artificial intelligence on the performance of human activity in a wide variety of tasks. We also hope", "histories": [["v1", "Fri, 17 Mar 2017 21:50:16 GMT  (1428kb,D)", "http://arxiv.org/abs/1703.06207v1", null], ["v2", "Tue, 21 Mar 2017 14:26:33 GMT  (1428kb,D)", "http://arxiv.org/abs/1703.06207v2", null], ["v3", "Tue, 17 Oct 2017 01:04:09 GMT  (1428kb,D)", "http://arxiv.org/abs/1703.06207v3", null]], "reviews": [], "SUBJECTS": "cs.AI", "authors": ["jacob w crandall", "mayada oudah", "tennom", "fatimah ishowo-oloko", "sherief abdallah", "jean-fran\\c{c}ois bonnefon", "manuel cebrian", "azim shariff", "michael a goodrich", "iyad rahwan"], "accepted": false, "id": "1703.06207"}, "pdf": {"name": "1703.06207.pdf", "metadata": {"source": "CRF", "title": "Cooperating with Machines", "authors": ["Jacob W. Crandall", "Mayada Oudah", "Fatimah Ishowo-Oloko", "Sherief Abdallah", "Jean-Fran\u00e7ois Bonnefon", "Manuel Cebrian", "Azim Shariff", "Michael A. Goodrich", "Iyad Rahwan"], "emails": ["crandall@cs.byu.edu", "irahwan@mit.edu"], "sections": [{"heading": null, "text": "\u2217Correspondence should be addressed to crandall@cs.byu.edu and irahwan@mit.edu\nar X\niv :1\n70 3.\n06 20\n7v 1\n[ cs"}, {"heading": "1 Introduction", "text": "The emergence of driverless cars, autonomous trading algorithms, and autonomous drone technologies highlight a larger trend in which artificial intelligence (AI) is enabling machines to autonomously carry out complex tasks on behalf of their human stakeholders. To effectively represent their stakeholders in many tasks, these autonomous machines must repeatedly interact with other people and machines that do not fully share the same goals and preferences. While the majority of AI milestones have focused on developing humanlevel wherewithal to compete with people [6, 7, 8, 9, 10], most scenarios in which AI must interact with people and other machines are not zero-sum interactions. As such, AI must also have the ability to cooperate, even in the midst of conflicting interests and threats of being exploited. Our goal is to understand how to build AI algorithms that cooperate with people and other machines at levels that rival human cooperation in arbitrary two-player repeated interactions.\nAlgorithms capable of forming cooperative relationships with people and other machines in arbitrary scenarios are not easy to come by. A successful algorithm must satisfy several conditions. First, it must not be domain-specific \u2013 it must have superior performance in a wide variety of scenarios (generality). Second, the algorithm must learn to establish effective relationships with people and machines without prior knowledge of associates\u2019 behaviors (flexibility). To do this, it must be able to deter potentially exploitative behavior from its partner and, when beneficial, determine how to elicit cooperation from a (potentially distrustful) partner who might be disinclined to cooperate. Third, when associating with people, the algorithm must learn effective behavior within very short timescales \u2013 i.e., within only a few rounds of interaction (learning speed). These requirements create many technical challenges (see SI.A.2), the sum of which often causes AI algorithms to fail to cooperate, even when doing so would be beneficial in the long run.\nIn addition to these computational challenges, human-AI cooperation is difficult due to differences in the way that humans and machines reason. While AI relies on computationally intensive search and random exploration to generate strategic behavior, human cooperation appears to rely on intuition [11], cultural norms [12], emotions and signals [13, 14], and pre-evolved dispositions toward cooperation [17]. In particular, cheap talk (i.e., costless signals) is important to human cooperation in repeated interactions [15, 16], as it helps people coordinate quickly on desirable equilibrium and create shared representations [18, 19, 20, 21]. As such, in addition to generating strategic behavior, we consider that AI algorithms must generate and respond to costless signals at levels that are conducive to human understanding."}, {"heading": "2 Results", "text": "The primary contribution of this work is the development and analysis of a new learning system that couples a state-of-the-art machine-learning algorithm with novel mechanisms for generating and responding to signals. Via extensive simulations and user studies, we show that this learning system learns to establish and maintain effective relationships with people and other machines in a wide-variety of repeated interactions at levels that rival human cooperation. In so doing, we also investigate the algorithmic mechanisms that are responsible for its success."}, {"heading": "2.1 Cooperating with People and Other Machines", "text": "Over the last several decades, algorithms for generating strategic behavior in repeated games have been developed in many disciplines, including economics, evolutionary biology, and the AI and machine-learning communities. To begin to evaluate the ability of these algorithms to forge successful cooperative relation-\nships, we selected and evaluated 25 representative algorithms from these fields, including classical algorithms such as (generalized) generous tit-for-tat (i.e., GODFATHER) and win-stay-lose-shift (WSLS) [39], evolutionarily evolved memory-one and memory-two stochastic strategies [40], machine-learning algorithms (including reinforcement learning), belief-based algorithms [41], and expert algorithms [42, 43]. Via extensive simulations, we compared these algorithms with respect to six different performance metrics (see SI.B.2) across the periodic table of 2x2 games [37] (see Methods and SI.A.3).\nThe results of this evaluation, which are overviewed in Methods (see Figure 6 in particular) and are described in detailed in SI.B, demonstrate the difficulty of developing algorithms that can forge effective longterm relationships in many different scenarios. The results show that only S++ [43] was a top-performing algorithm across all metrics at all game lengths when associating with other algorithms. However, despite its fast learning speeds and its success in interacting with other machines in many different scenarios, S++ does not, in its current form, consistently forge cooperate relationships with people (SI.D), though it does cooperate with people as frequently as people cooperate with each other in the same studies. Thus, none of these existing algorithms establishes effective long-term relationships with both people and machines.\nWe hypothesized that S++\u2019s inability to consistently learn to cooperate with people appears to be tied to its inability to generate and respond to costless signals. Humans are known for their ability to effectively coordinate on cooperative equilibria using costless signals called cheap talk [15, 16]. However, while signaling comes naturally to humans, the same cannot be said of sophisticated AI algorithms, such as machinelearning algorithms. To be useful, costless signals should be connected with behavioral processes. Unfortunately, most machine-learning algorithms have low-level internal representations that are often not easily expressed in terms of high-level behavior, especially in arbitrary scenarios. As such, it is not obvious how these algorithms can be used to generate and respond to costless signals at levels that people understand.\nFortuitously, unlike typical machine-learning algorithms, the internal structure of S++ provides a clear, high-level representation of the algorithm\u2019s dynamic strategy that can be described in terms of the dynamics of the underlying experts. Since each expert encodes a high-level philosophy, S++ could potentially be used to generate signals (i.e., cheap talk) that describe its intentionality. Speech acts from its partner can also be compared to its experts\u2019 philosophies to improve its expert-selection mechanism. In this way, S++ can be augmented with the ability to generate and respond to cheap talk. The resulting new algorithm, dubbed S# (pronounced \u2018S sharp\u2019), is depicted in Figure 1 (see Methods and SI.C for details about the algorithm).\nWe conducted a series of three user studies (see SI.D\u2013F for details) involving 220 participants, who played in a total of 472 games, to determine the ability of S# to forge cooperative relationships with people. Representative results are found in the final (culminating) study, in which participants played three representative repeated games (drawn from distinct payoff families; see SI.A.3) via a computer interface that hid the identity of their partner. In some conditions, players could engage in cheap talk by sending messages at the beginning of each round via the computer interface. Consistent with prior work investigating cheap talk in repeated games [16], messages were limited to the predetermined speech acts available to S#.\nThe proportion of mutual cooperation achieved by Human-Human, Human-S#, and S#-S# pairings are shown in Figures 2a-b. When cheap talk was not permitted, Human-Human and Human-S# pairings did not frequently result in cooperative relationships. However, across all three games, the presence of cheap talk doubled the proportion of mutual cooperation experienced by these two pairings. While S#\u2019s speech profile was distinct from that of humans (Figure 2c), subjective, post-interaction assessments indicate that S# used cheap talk to promote cooperation as effectively as people (Figure 2d). In fact, many participants were unable to distinguish S# from a human player (Figure 2e). Together, these results illustrate that, across the games studied, the combined behavioral and signaling strategies of S# were as effective as those of human players.\n(d) \u00a0Prune \u00a0experts \u00a0  \u00a0  \u00a0  \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0then \u00a0use \u00a0algorithm \u00a0S \u00a0to \u00a0select \u00a0an \u00a0expert \u00a0\ne4 \u00a0\ne2 \u00a0\ne3 \u00a0\ne1 \u00a0 e6 \u00a0\ne5 \u00a0\ne7 \u00a0 e6 \u00a0\nS \u00a0\n(c) \u00a0Compute \u00a0set \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0of \u00a0 \u00a0experts \u00a0  \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0congruent \u00a0with \u00a0incoming \u00a0signal \u00a0\ne4 \u00a0\ne2 \u00a0\ne3 \u00a0\ne1 \u00a0 e6 \u00a0\ne5 \u00a0\ne7 \u00a0\nEvent \u00a0 Explana/on \u00a0\ns \u00a0 Expert\t\r \u00a0is\t\r \u00a0sa-sfied\t\r \u00a0with\t\r \u00a0new\t\r \u00a0payoff\t\r \u00a0 f \u00a0 Expert \u00a0forgives \u00a0other \u00a0player \u00a0 d \u00a0 Partner \u00a0defected \u00a0against \u00a0S# \u00a0 g \u00a0 Partner\t\r \u00a0profited\t\r \u00a0from\t\r \u00a0defec=on\t\r \u00a0(guilty)\t\r \u00a0 p \u00a0 Expert \u00a0punished \u00a0guilty \u00a0partner \u00a0 u \u00a0 Expert \u00a0failed \u00a0to \u00a0punish \u00a0guilty \u00a0partner \u00a0\nNUL \u00a0 Auto \u00a0transi=on; \u00a0no \u00a0input \u00a0considered \u00a0\nSignal \u00a0 Text \u00a0\n0 \u00a0 Do \u00a0as \u00a0I \u00a0say, \u00a0or \u00a0I\u2019ll \u00a0punish \u00a0you. \u00a0 1 \u00a0 I \u00a0accept \u00a0your \u00a0last \u00a0proposal. \u00a0 2 \u00a0 I \u00a0don\u2019t \u00a0accept \u00a0your \u00a0proposal. \u00a0 3 \u00a0 That\u2019s \u00a0not \u00a0fair. \u00a0 4 \u00a0 I \u00a0don\u2019t \u00a0trust \u00a0you. \u00a0 5 \u00a0 Excellent! \u00a0 6 \u00a0 Sweet. \u00a0We \u00a0are \u00a0geTng \u00a0rich. \u00a0 7 \u00a0 Give \u00a0me \u00a0another \u00a0chance. \u00a0 8 \u00a0 Okay. \u00a0I \u00a0forgive \u00a0you. \u00a0 9 \u00a0 I\u2019m \u00a0changing \u00a0my \u00a0strategy. \u00a0 10 \u00a0 We \u00a0can \u00a0both \u00a0do \u00a0be]er \u00a0than \u00a0this. \u00a0 11 \u00a0 Curse \u00a0you. \u00a0 12 \u00a0 You \u00a0betrayed \u00a0me. \u00a0 13 \u00a0 You \u00a0will \u00a0pay \u00a0for \u00a0this! \u00a0 14 \u00a0 In \u00a0your \u00a0face! \u00a0 15 \u00a0 Let\u2019s \u00a0always \u00a0play \u00a0<action pair>. \u00a0 16 \u00a0 This \u00a0round, \u00a0let\u2019s \u00a0play \u00a0<action pair>. \u00a0 17 \u00a0 Don\u2019t \u00a0play \u00a0<action>. \u00a0 18 \u00a0 Let\u2019s \u00a0alterna=ve \u00a0between \u00a0 \u00a0 <action pair> \u00a0and \u00a0<action pair>. \u00a0 \u03b5 \u00a0 <empty> \u00a0\nS0 \u00a0 S1 \u00a0\nInput \u00a0 event \u00a0 Output \u00a0signal \u00a0 (speech) \u00a0\n(g) \u00a0Speech-\u2010genera/on \u00a0 \u00a0 mechanism \u00a0for \u00a0expert \u00a0e6 \u00a0\nmeet \u00a0 \u00a0 aspira=on \u00a0 congruent \u00a0\nStart \u00a0\nS2 \u00a0 S3 \u00a0 S4 \u00a0 S5 \u00a0 S6 \u00a0\nS7 \u00a0\nS8 \u00a0\nNUL\u00e015+0 \u00a0\n\u00e0 \u00a0 r(M): \u00a0randomly \u00a0pick \u00a0 message \u00a0from \u00a0set \u00a0M \u00a0Si \u00a0\nInternal \u00a0state \u00a0\nd\u00e0r({11,12}) \u00a0\nd\u00e0r({11,12}) \u00a0\ns\u00e05 \u00a0 s\u00e05 \u00a0 s\u00e0\u03b5 \u00a0 s\u00e06 \u00a0\ns\u00e0\u03b5 \u00a0 d\u00e0r({11,12}) \u00a0\ns\u00e05 \u00a0\np\u00e014 \u00a0\np\u00e0\u03b5 \u00a0\ng\u00e0r({11,12})+13 \u00a0\ng\u00e0 r({11,12})+13 \u00a0\nNUL\u00e015+0 \u00a0\nthe underlying experts. Since many of the experts encode high-level ideas (such as trigger strategies), we can augment S++ with the ability to generate speech acts that describe its intentionality, and to incorporate speech acts from its partner into its decision-making mechanisms. The resulting new algorithm, dubbed S# (pronounced \u2018S sharp\u2019) is depicted in Figure 5 (see SI for details).\nS# differs from S++ in two ways. First, the partner\u2019s proposed plans, signaled via speech acts, are used to further reduce the set of experts that S# considers selecting (Figure 5-top). Formally, let Econg(t) denote the set of experts at round t that are congruent with the joint plan proposed by S#\u2019s partner (see SI for how congruence is computed). Then, S# considers selecting experts from the following set:\nE(t) = {ej 2 Econg(t) : \u21e2j(t) \u21b5(t)}. (3)\nIf this set is empty (i.e., no desirable options are congruent with the partner\u2019s proposal), E(t) is calculated as in Eq. (1). Second, S# also extends S++ by generating speech acts that convey the \u201cstream of conscience\u201d of the algorithm. Specifically, a finite-state machine with output is generated for each expert (Figure 5-bottom). Given the current state of the expert and game outcomes, the state machine produces speech derived from a pre-determined set of phrases. These speech acts are game-generic, not tied to a specific to the game. Speech systems for repeated stochastic games and repeated normal-form games are provided in the SI.\nTo evaluate the ability of S# to consistently cooperate with people, we conducted a third, 66-participant, user study in which S# and people interacted in three normal-form games (Prisoner\u2019s Dilemma, Chicken, and the Alternator Game). The participants were divided into two categories: those that could and could not communicate. When communication was permitted, players could send messages, limited to the predetermined set of speech acts available to S#, to their partner at the beginning of each round. The results of the study are summarized in Figure 6. When communication was not allowed, the results were similar to previous studies. However, when communication was possible, mutual cooperation in human-human and human-S# pairings doubled. Overall, pairings of two S# players produced the highest levels of mutual cooperation. Together, these results demonstrate the effectiveness of #\u2019s combined learning and speech systems, which consistently form cooperative relationships with people and other machines.\nPotential implications. Our results open the opportunity to study human-machine cooperation in a way that builds on the rich literature on human cooperation in behavioral economics and evolutionary biology [32]. In particular, as machines become increasingly autonomous, we see human-machine cooperation as a phenomenon that emerges from the interaction among self-interested parties [33], rather than by explicit design constraints programmed into domain-specific computational systems [34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44]. Our results demonstrate that emergent cooperation between humans and autonomous, self-regarding, machines is now feasible.\nWhile advanced AI algorithms are gaining the ability to consistently learn to cooperate among themselves even without communication, human cooperation appears to benefit significantly from signaling. In light of these findings, greater effort must be placed on developing autonomous machines that can effectively communicate with people, and vice versa, in order to create shared representations [45, 46, 47, 41] and coordinate quickly on desirable equilibria. Our work emphasizes the importance of this problem, and presents case studies that others can work from to continue to make progress [46].\nSince Alan Turing argued that machines could potentially demonstrate intelligence, AI has been regularly portrayed as a threat to humanity, paving the way to severe disruption of labor markets [48], or machine-dominated dystopian futures. The fear of enslavement by machines was encapsulated in a famous\nstatement by British physician Havelock Ellis in 1922: \u201cThe greatest task before civilization at present is\nto make machines what they ought to be, the slaves, instead of the masters of men\u201d [49]. Most attempts to\ncurb this threat have followed the path of hardcoding legal or moral principles into computer code, such as\nthe underlying experts. Since many of the experts encode high-level ideas (such as trigger strategies), we can augment S++ with the ability to generate speech acts that describe its intentionality, and to incorporate speech acts from its partner into its decision-making mechanisms. The resulting new algorithm, dubbed S# (pronounced \u2018S sharp\u2019) is depicted in Figure 5 (see SI for details).\nS# differs from S++ in two ways. First, the partner\u2019s proposed plans, signaled via speech acts, are used to further reduce the set of experts that S# considers selecting (Figure 5-top). Formally, let Econg(t) denote the set of experts at round t that are congruent with the joint plan proposed by S#\u2019s partner (see SI for how congruence is computed). Then, S# considers selecting experts from the following set:\nE(t) = { j 2 Econg(t) : \u21e2j(t) \u21b5(t)}. (3)\nIf this set is empty (i.e., no desirable options are congruent with the partner\u2019s proposal), E(t) is calculated as in Eq. (1). Second, S# also extends S++ by generating speech acts that convey the \u201cstream of conscience\u201d of the algorithm. Specifically, a finite-state machine with output is generated for each expert (Figure 5-bottom). Given the current state of the expert and game outcomes, the state machine produces speech derived from a pre-determined set of phrases. These speech acts are game-generic, not tied to a specific to the game. Speech systems for repeated stochastic games and repeated normal-form games are provided in the SI.\nTo evaluate the ability of S# to consistently cooperate with people, we conducted a third, 66-participant, user study in which S# and people interacted in three normal-form games (Prisoner\u2019s Dilemma, Chicken, and the Alternator Game). The participants were divided into two categories: those that could and could not communicate. When communication was permitted, players could send messages, limited to the predetermined set of speech acts available to S#, to their partner at the beginning of each round. The results of the study are summarized in Figure 6. When communication was not allowed, the results were similar to previous studies. However, when communication was possible, mutual cooperation in human-human and human-S# pairings doubled. Overall, pairings of two S# players produced the highest levels of mutual cooperation. Together, thes results demonst ate he effectiveness of S#\u2019s combined learning and speech systems, which consistently form cooperative relationships with people and other ma hines.\nPotential implic tions. Our results open the opportunity to study human-machine cooperation in a way that builds on the rich literature on human cooperation in be avioral economics and e oluti nary biology [32]. In particular, as machines b ome incr asingly autonom us, we see human-mac ine cooperation as a phenomenon that emerges fro the interaction among self-interested parties [33], rather than by explicit design constraints programmed into domain-specific computational systems [34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44]. Our results demonstrate that emergent cooperation between hu ans and autonomous, self-regarding, machines is now feasible.\nWhile advanced AI algorithms are gaining the ability to consistently learn to cooperate among themselves even without communication, human cooperation appears to benefit significantly from signaling. In light of these findings, greater effort must be placed on developing autonomous machines that can effectively communicate with people, and vice versa, in order to create shared representations [45, 46, 47, 41] and coordinate quickly on desirable equilibria. Our work emphasizes the importance of this problem, and presents case studies that others can work from to continue to make progress [46].\nSince Alan Turing argued that machines could potentially demonstrate intelligence, AI has been regularly portrayed as a threat to humanity, paving the way to severe disruption of labor markets [48], or machine-dominated dystopian futures. The fear of enslavement by machines was encapsulated in a famous statement by British physician Havelock Ellis in 1922: \u201cThe greatest task before civilization at present is to make machines what they ought to be, the slaves, instead of the masters of men\u201d [49]. Most attempts to curb this threat have followed the path of hardcoding legal or moral principles into computer code, such as\n(a) \u00a0Compute \u00a0a \u00a0set \u00a0E of \u00a0experts \u00a0{ej} \u00a0 \u00a0  \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0from \u00a0the \u00a0game \u00a0descrip=on \u00a0\n(b) \u00a0Iden=fy \u00a0experts \u00a0whose \u00a0poten=al \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0meets \u00a0aspira=on \u00a0level \u00a0 \u03c1 j (t)\nPo te nt ia l \u03c1\nj ( t)\ne1 \u00a0 e2 \u00a0 e3 \u00a0 e4 \u00a0 e5 \u00a0 e6 \u00a0 e7 \u00a0\nA B\nA B\n\u03b1(t)\ne4 \u00a0\ne2 \u00a0\ne3 \u00a0\ne1 \u00a0 e6 \u00a0\ne5 \u00a0\ne7 \u00a0\n\u03b1(t)\n \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0Update \u00a0each \u00a0expert \u00a0according \u00a0to \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0its \u00a0own \u00a0internal \u00a0representa=on \u00a0\ne4 \u00a0\ne2 \u00a0\ne3 \u00a0\ne1 \u00a0 e6 \u00a0\ne5 \u00a0\ne7 \u00a0\n(f) \u00a0Update \u00a0aspira=on \u00a0level: \u00a0 \u03b1(t +m) =\u03b1(t)\u03bbm + R(1\u2212\u03bbm )\n(e) \u00a0Follow \u00a0the \u00a0selected \u00a0expert \u00a0for \u00a0  \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0m \u00a0rounds \u00a0 \u00a0\nE6 \u00a0\nPartner \u00a0\nA B\nA B E6 \u00a0\nPartner \u00a0\nA B\nA\nB\u2026 \u00a0 Round \u00a0t \u00a0 Round \u00a0t+m-\u20101 \u00a0\nState \u00a0transi=on \u00a0 Rand miza=on \u00a0\nFigure 1: An overview of S#, an algorithm that interweaves signaling capabilities into S++ [43]. (a) Prior to beginning the game, S# uses the description of the game to compute a set E of expert strategies. Each expert encodes a strategy or learning algorithm that defines behavior over all game states. (b) S# computes the potential, or highest expected utility, of each expert in E. The potentials are then compared to an aspiration level \u03b1(t), which encodes the average per-round payoff that the algorithm believes is achievable, to determine a set of experts that could potentially meet the agent\u2019s aspirations. (c) S# determines which experts carry out plans that are congruent with its partner\u2019s last proposed plan. (d) S# selects an expert (using algorithm S [45, 46]) from among those experts that both potentially meet its aspirations (step b) and are congruent with its partner\u2019s latest proposal (step c). If E(t) is empty, S# selects its expert from among the set of experts that meet its aspiration level (step b). The currently selected expert generates signals based on its game-generic state machine (bottom). Given the current state of the expert and game events, the expert produces speech from a predetermined list of speech acts. (e) The machine follows the strategy dictated by the selected expert for m rounds of the repeated game. (f) The machine updates its aspiration level based on the average reward R it has received over the last m rounds of the game. The experts are also updated according to their own internal representations. The algorithm then returns to step b. The process repeats for the duration of the repeated game. Details are given in SI.C. Note that S++ is identical to S# except that S++ (1) replaces step c with Econg(t) = E, and (2) does not generate speech acts."}, {"heading": "2.2 Distinguishing Algorithmic Mechanisms", "text": "Why is S# so successful in forging cooperative relationships with both people and other algorithms? Are its algorithmic mechanisms fundamentally different from those of other algorithms for repeated games? We have identified three algorithmic mechanisms responsible for S#\u2019s success. Clearly, Figure 2 demonstrates that the first of these mechanisms is S#\u2019s ability to generate and respond to relevant signals people can understand, a trait not present in previous learning algorithms designed for repeated interactions. These signaling capabilities expand S#\u2019s flexibility in that they also allow S# to more consistently forge cooperative relationships with people. Figure 3a demonstrates one simple reason that this mechanism is so important: signals help both S# and humans to more quickly experience mutual cooperation with their partners.\nSecond, our implementation of S# uses a rich set of experts that includes a variety of equilibrium strategies and even a simple learning algorithm (see SI.C.1). While none of these individual experts has an overly complex representation (e.g., no expert remembers the full history of play), these experts are more sophisticated than those traditionally considered (though not explicitly excluded) in the discussion of expert algorithms [22, 23, 24]. This more sophisticated set of experts permits S# to adapt to a variety of partners and game types, whereas algorithms that rely on a single strategy or a less sophisticated set of experts are only successful in particular kinds of games played with particular partners [25] (Figure 3c). Thus, in general, simplifying S# by removing experts from this set will tend to limit the algorithm\u2019s flexibility and generality, though doing so will not always negatively impact its performance when paired with particular associates in particular games.\nFinally, S#\u2019s somewhat non-conventional expert-selection mechanism (see Eq. 1) is central to its success. While techniques such as \u03b5-greedy exploration (e.g., EEE) and regret-matching (e,g., Exp3) have permeated algorithm development in the AI community, S# instead uses an expert-selection mechanism closely aligned with recognition-primed decision making [26]. Given the same full, rich set of experts, more traditional expert-selection mechanisms establish effective relationships in far fewer scenarios than S# (Figure 3c). Figures 3a-b provide insights into why this is so. Compared to the other expert-selection mechanisms, S# has a greater combined ability to quickly establish a cooperative relationship with its partner (Figure 3a) and then to maintain it (Figure 3b), a condition brought about by S#\u2019s tendency to not deviate from cooperation after mutual cooperation has been established (i.e., loyalty).\nThe loyalty brought about by S#\u2019s expert-selection mechanism helps explain why S#-S# pairings substantially outperformed Human-Human pairings in our study (Figure 2a-b). S#\u2019s superior performance can be attributed to two human tendencies. First, while S# did not typically deviate from cooperation after successive rounds of mutual cooperation (Figure 3b), many human players did. Almost universally, such deviations led to reduced payoffs to the deviator. Second, a sizable portion of our participants failed to keep some of their verbal commitments. On the other hand, since S#\u2019s verbal commitments are derived from its intended future behavior, it typically carries out the plans it proposes. Had participants followed S#\u2019s strategy in these two regards, Human-Human pairings would have performed nearly as well, on average, as S#-S# pairings (Figure 3d \u2013 see SI.F.4 for details)."}, {"heading": "2.3 Repeated Stochastic Games", "text": "The previous results were demonstrated for normal-form games. However, S++ also learns effectively in repeated stochastic games [27], which are more complex scenarios in which a round consists of a sequence of moves by both players. In these games, S++ is distinguished, again, by its ability to adapt to many different machine associates in a variety of different scenarios [27]. As in normal-form games, S++ can be augmented with cheap talk to form S#. While S++ does not consistently forge effective relationships with\npeople in these more complex scenarios, our results show that S# does. Representative results are shown in Figure 4, which considers a turning-taking scenario in which two players must learn how to share a set of blocks. Like people, S# uses cheap talk to substantially increase its payoffs when associating with other people in this game (Figure 4b). These results mirror those we observe in normal-form games (compare Figures 4b and 2b). See SI.E for additional details and results."}, {"heading": "3 Discussion", "text": "Our studies of human-S# partnerships were limited to five repeated games, selected carefully to represent different classes of games from the periodic table of games (see SI.A.3). Though future work should address more scenarios, S#\u2019s success in establishing cooperative relationships with people in these representative games, along with its consistently high performance across all classes of 2x2 games and various repeated stochastic games [27] when associating with other algorithms, gives us some confidence that these results will generalize to many other scenarios.\nSince Alan Turing envisioned Artificial Intelligence, major milestones have focused on defeating humans in zero-sum encounters [6, 7, 8, 9, 10]. However, in many scenarios, successful machines must cooperate with, rather than compete against, humans and other machines, even in the midst of conflicting interests and threats of being exploited. Our work demonstrates how autonomous machines can learn to establish cooperative relationships with people and other machines in repeated interactions. We showed that human-machine and machine-machine cooperation is achievable using a non-trivial, but ultimately simple, set of algorithmic mechanisms. These mechanisms include computing a variety of expert strategies optimized for various scenarios, a particular meta-strategy for a particular meta-strategy for selecting experts to follow, and the ability to generate and respond to simple signals. We hope that this first extensive demonstration of human cooperation with autonomous machines in repeated games will spur significant further research that will ensure that autonomous machines, designed to carry out human endeavors, will cooperate with humanity."}, {"heading": "4 Methods", "text": "Detailed methods and analysis are provided in the SI. In this section, we overview three different aspects of these methods and analysis: the benchmark of games used to compare algorithms and people, results from our comparison of AI algorithms, and a description of S#."}, {"heading": "4.1 Benchmark Games for Studying Cooperation", "text": "As with all historical grand challenges in AI, it is important to identify a class of benchmark problems to compare the performance of different algorithms. When it comes to human cooperation, a fundamental benchmark has been 2\u00d72, general-sum, repeated games [28]. This class of games has been a workhorse for decades in the fields of behavioral economics [29], mathematical biology [30], psychology [31], sociology [32], computer science [33], and political science [34]. These fields have revealed many aspects of human cooperative behavior through canonical games, such as the Prisoner\u2019s Dilemmas, Chicken, Battle of the Sexes, and the Stag Hunt. Such games, therefore, provide a well-established, extensively studied, and widely understood benchmark for studying the capabilities of machines to develop cooperative relationships.\nThe periodic table of 2\u00d7 2 games (Figure 5; see SI.A.3; [28, 35, 36, 37, 38]) identifies and categorizes 144 unique game structures that present many unique scenarios in which machines may need to cooperate.\nA Periodic Table of 2x2 Games\nWe use this set of game structures as a benchmark against which to compare the abilities of algorithms to cooperate. Successful algorithms should be able to forge successful relationships with both people and machines across all of these repeated games. In particular, we can use these games to quantify the abilities of various state-of-the-art machine learning algorithms to satisfy the aforementioned properties: generality across games, flexibility across opponent types (including humans), and speed of learning.\nLike the majority of work in repeated interactions, we focus on two-player normal-form games to more easily understand how machines can forge cooperative relationships with people. Nevertheless, we are interested in algorithms that can also be used in more complex interactions, including the more general case of repeated (two-player) stochastic games (see, for example, Figure 4). Studies evaluating the ability of S# to forge cooperative relationships with people in repeated stochastic games have yielded similar results to those we report for two-player normal-form games (e.g., Figure 4b). These studies are described in SI.E."}, {"heading": "4.2 Interacting with Other Machines: AI Algorithms for Repeated Interactions", "text": "With the goal of identifying successful algorithmic mechanisms for playing arbitrary repeated games, we selected and evaluated 25 existing algorithms (see Figure 6a) with respect to six different performance metrics (see SI.B.2) across the periodic table of 2x2 games. These representative algorithms included classical algorithms such as (generalized) generous tit-for-tat (i.e., GODFATHER) and win-stay-lose-shift (WSLS) [39], evolutionarily evolved memory-one and memory-two stochastic strategies [40], machine-learning algorithms (including reinforcement learning), belief-based algorithms [41], and expert algorithms [42, 43].\nResults of this evaluation are summarized in Figure 6a. Detailed analysis is provided in SI.B. We make two high-level observations. First, it is interesting to observe which algorithms were less successful in these evaluations. For instance, while generalized tit-for-tat, WSLS, and memory-one and memorytwo stochastic strategies (e.g., MEM-1 and MEM-2) are successful in prisoner\u2019s dilemmas, they are not consistently effective across the full set of 2x2 games. These algorithms are particularly ineffective in longer interactions, as they do not effectively adapt to their associate\u2019s behavior. Additionally, algorithms that minimize regret (e.g., Exp3 [22], GIGA-WoLF [23], and WMA [24]), which is the central component of world-champion computer poker algorithms [9], also performed poorly.\nSecond, while many algorithms had high performance with respect to some measure, only S++ [43] was a top-performing algorithm across all metrics at all game lengths. Furthermore, it maintained this high performance in each class of game and when associating with each class of algorithm (see SI.B.5). S++ learns to cooperate with like-minded associates, exploit weaker competition, and bound its worst-case performance (Figure 6b). Perhaps most importantly, whereas many machine-learning algorithms do not learn cooperative behavior until after thousands of rounds of interaction (if at all), S++ tends to do so within relatively few rounds of interaction (Figure 6c), likely fast enough to support interactions with people."}, {"heading": "4.3 S#: A Machine-Learning Algorithm that Talks", "text": "S# is derived from S++ [43], an expert algorithm that combines and builds on decades of research in computer science, economics, and the behavioral and social sciences. S++ uses the description of the game environment to compute a diverse set of experts, each of which uses distinct mathematics and assumptions to produce a strategy over the entire space of the game. S++ then uses a meta-level control strategy based on aspiration learning [44, 45, 46] to dynamically reduce this set of experts. Formally, let E denote the set of experts computed by S++. In each epoch (beginning in round t), S++ computes the potential \u03c1j(t) of each expert ej \u2208 E, and compares this potential with its aspiration level \u03b1(t) to form a reduced set E(t) of\nexperts:\nE(t) = {ej \u2208 E : \u03c1j(t) \u2265 \u03b1(t)}. (1)\nThis reduced set consists of the experts that S++ believes could potentially produce satisfactory payoffs. It then selects one expert esel(t) \u2208 E(t) using a satisficing decision rule [45, 46]. Over the next m rounds, it follows the strategy prescribed by esel(t), after which it updates its aspiration level as follows:\n\u03b1(t+m)\u2190 \u03bbm\u03b1(t) + (1\u2212 \u03bbm)R, (2)\nwhere \u03bb \u2208 (0, 1) is the learning rate and R is the average payoff obtained by S++ in the last m rounds. It also updates each expert ej \u2208 E based on its peculiar reasoning mechanism, and then begins a new epoch.\nThese results demonstrate the ability of S++ to effectively establish and maintain profitable long-term relationships with machines in arbitrary repeated games. Does S++ also learn to form cooperative relationships with people?\nS# differs from S++ in two ways. First, the partner\u2019s proposed plans, signaled via speech acts, are used to further reduce the set of experts that S# considers selecting (Figure 1c). Formally, let Econg(t) denote the set of experts in round t that are congruent with the last joint plan proposed by S#\u2019s partner (see SI.C.2.2). Then, S# considers selecting experts from the following set:\nE(t) = {ej \u2208 Econg(t) : \u03c1j(t) \u2265 \u03b1(t)}. (3)\nIf this set is empty (i.e., no desirable options are congruent with the partner\u2019s proposal), E(t) is calculated as in Eq. (1). Second, S# also extends S++ by generating speech acts that convey the \u201cstream of consciousness\u201d of the algorithm (Figure 1d). Specifically, a finite-state machine with output is generated for each expert. Given the state of the expert and the game outcomes, the state machine of the currently selected expert produces speech derived from a predetermined set of phrases. The set of speech acts, which are largely game-generic (though some adaptations must be made for multi-stage games; see SI.E.3.4) allows S# to provide feedback to its partner, make threats, provide various explanations to manage the relationship, and propose and agree to plans.\nSee SI.C for an in-depth description of S#."}], "references": [{"title": "Computing machinery and intelligence", "author": ["A.M. Turing"], "venue": "Mind, pages 433\u2013460", "citeRegEx": "1", "shortCiteRegEx": null, "year": 1950}, {"title": "Face recognition algorithms surpass humans matching faces over changes in illumination", "author": ["A.J. Toole", "P.J. Phillips", "F. Jiang", "J. Ayyad", "N. Penard", "H. Abdi"], "venue": "Pattern Analysis and Machine Intelligence, IEEE Transactions on, 29(9):1642\u20131646", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2007}, {"title": "Computer-based personality judgments are more accurate than those made by humans", "author": ["W. Youyou", "M. Kosinski", "D. Stillwell"], "venue": "Proceedings of the National Academy of Sciences, 112(4):1036\u20131040", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2015}, {"title": "Junior: The Stanford entry in the urban challenge", "author": ["M. Montemerlo", "J. Becker", "S. Bhat", "H. Dahlkamp", "D. Dolgov", "S. Ettinger", "D. Haehnel", "T. Hilden", "G. Hoffmann", "B. Huhnke", "D. Johnston", "S. Klumpp", "D. Langer", "A. Levandowski", "J. Levinson", "J. Marcil", "D. Orenstein", "J. Paefgen", "I. Penny", "A. Petrovskaya", "M. Pflueger", "G. Stanek", "D. Stavens", "A. Vogt", "S. Thrun"], "venue": "Journal of Field Robotics, 25(9):569\u2013597", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2008}, {"title": "et al", "author": ["V. Mnih", "K. Kavukcuoglu", "D. Silver", "A.A. Rusu", "J. Veness", "M.G. Bellemare", "A. Graves", "M. Riedmiller", "A.K. Fidjeland", "G. Ostrovski"], "venue": "Human-level control through deep reinforcement learning. Nature, 518(7540):529\u2013533", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2015}, {"title": "Deep blue", "author": ["M. Campbell", "A.J. Hoane", "F. Hsu"], "venue": "Artificial intelligence, 134(1):57\u201383", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2002}, {"title": "Checkers is solved", "author": ["J. Schaeffer", "N. Burch", "Y. Bj\u00f6rnsson", "A. Kishimoto", "M. M\u00fcller", "R. Lake", "P. Lu", "S. Sutphen"], "venue": "Science, 317(5844):1518\u20131522", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2007}, {"title": "et al", "author": ["D. Ferrucci", "E. Brown", "J. Chu-Carroll", "J. Fan", "D. Gondek", "A.A. Kalyanpur", "A. Lally", "J.W. Murdock", "E. Nyberg", "J. Prager"], "venue": "Building Watson: An overview of the DeepQA project. AI Magazine, 31(3):59\u201379", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2010}, {"title": "Heads-up limit holdem poker is solved", "author": ["M. Bowling", "N. Burch", "M. Johanson", "O. Tammelin"], "venue": "Science, 347(6218):145\u2013149", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2015}, {"title": "G", "author": ["D. Silver", "A. Huang", "C.J. Maddison", "A. Guez", "L. Sifre"], "venue": "van den Driessche, J. Schrittwieser, I. Angonoglou, V. Panneershelvam, M. Lanctot, S. Dieleman, D. Grewe, J. Nham, N. Kalchbrenner, I. Sutskever, T. Lillicrap, M. Leach, K. Kavukcuoglu, T. Graepel, and D. Hassabis. Mastering the game of Go with deep neural networks and tree search. Nature, 529:484\u2013489", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2016}, {"title": "Social heuristics shape intuitive cooperation", "author": ["D.G. Rand", "A. Peysakhovich", "G.T. Kraft-Todd", "G.E. Newman", "O. Wurzbacher", "M.A. Nowak", "J.D. Greene"], "venue": "Nature Communications, 5", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2014}, {"title": "Culture and the evolution of human cooperation", "author": ["R. Boyd", "P.J. Richerson"], "venue": "Philosophical Transactions of the Royal Society B: Biological Sciences, 364", "citeRegEx": "12", "shortCiteRegEx": null, "year": 1533}, {"title": "Passions Within Reason: The Strategic Role of the Emotions", "author": ["R.H. Frank"], "venue": "W. W. Norton & Company", "citeRegEx": "13", "shortCiteRegEx": null, "year": 1988}, {"title": "The Stag Hunt and the Evolution of Social Structure", "author": ["B. Skyrms"], "venue": "Cambridge Press", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2003}, {"title": "Conversation and cooperation in social dilemmas a meta-analysis of experiments from 1958 to 1992", "author": ["D. Sally"], "venue": "Rationality and society, 7(1):58\u201392", "citeRegEx": "15", "shortCiteRegEx": null, "year": 1995}, {"title": "Communication and cooperation in social dilemmas: A meta-analytic review", "author": ["D. Balliet"], "venue": "Rationality and society, 54(1):39?57", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2009}, {"title": "Humans display a cooperative phenotype that is domain general and temporally stable", "author": ["A. Peysakhovich", "M. A Nowak", "D.G. Rand"], "venue": "Nature Communications, 5", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2014}, {"title": "Common ground and coordination in joint activity", "author": ["G. Klein", "P.J. Feltovich", "J.M. Bradshaw", "D.D. Woods"], "venue": "Organizational simulation, 53", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2005}, {"title": "Socially intelligent robots: Dimensions of human\u2013robot interaction", "author": ["K. Dautenhahn"], "venue": "Philosophical Transactions of the Royal Society B: Biological Sciences, 362", "citeRegEx": "19", "shortCiteRegEx": null, "year": 1480}, {"title": "Toward sociable robots", "author": ["C. Breazeal"], "venue": "Robotics and autonomous systems, 42(3):167\u2013175", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2003}, {"title": "Modeling information exchange opportunities for effective human\u2013 computer teamwork", "author": ["E. Kamar", "Y. Gal", "B.J. Grosz"], "venue": "Artificial Intelligence, 195:528\u2013550", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2013}, {"title": "Gambling in a rigged casino: the adversarial multi-armed bandit problem", "author": ["P. Auer", "N. Cesa-Bianchi", "Y. Freund", "R.E. Schapire"], "venue": "Proceedings of the 36th Symposium on the Foundations of Computer Science, pages 322\u2013331", "citeRegEx": "22", "shortCiteRegEx": null, "year": 1995}, {"title": "Convergence and no-regret in multiagent learning", "author": ["M. Bowling"], "venue": "Advances in Neural Information Processing Systems 17, pages 209\u2013216", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2004}, {"title": "A decision-theoretic generalization of on-line learning and an application to boosting", "author": ["Y. Freund", "R.E. Schapire"], "venue": "Proceedings of the 2nd European Conference on Computational Learning Theory, pages 23\u201337", "citeRegEx": "24", "shortCiteRegEx": null, "year": 1995}, {"title": "The evolution of representation in simple cognitive networks", "author": ["L. Marstaller", "A. Hintze", "C. Adami"], "venue": "Neural Computation, 25:2079\u20132107", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2013}, {"title": "Recognition-primed decisions", "author": ["G. Klein"], "venue": "W. B. Rouse, editor, Advances in man-machine systems research, volume 5, pages 47\u201392. Greenwhich, CT: JAI Press", "citeRegEx": "26", "shortCiteRegEx": null, "year": 1989}, {"title": "Robust learning in repeated stochastic games using meta-gaming", "author": ["J.W. Crandall"], "venue": "Proceedings of the International Joint Conference on Artificial Intelligence", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2015}, {"title": "A Taxonomy of 2x2 Games", "author": ["A. Rapoport", "M.J. Guyer"], "venue": "Bobbs-Merrill", "citeRegEx": "28", "shortCiteRegEx": null, "year": 1967}, {"title": "Behavioral game theory", "author": ["Colin Camerer"], "venue": "New Age International,", "citeRegEx": "29", "shortCiteRegEx": "29", "year": 2010}, {"title": "Evolutionary games and population dynamics", "author": ["Josef Hofbauer", "Karl Sigmund"], "venue": "Cambridge university press,", "citeRegEx": "30", "shortCiteRegEx": "30", "year": 1998}, {"title": "Human cooperation", "author": ["D.G. Rand", "M.A. Nowak"], "venue": "Trends in Cognitive Sciences, 17(8):413\u2013425", "citeRegEx": "31", "shortCiteRegEx": null, "year": 2013}, {"title": "Social dilemmas: The anatomy of cooperation", "author": ["Peter Kollock"], "venue": "Annual review of sociology,", "citeRegEx": "32", "shortCiteRegEx": "32", "year": 1998}, {"title": "A polynomial-time Nash equilibrium algorithm for repeated games", "author": ["M.L. Littman", "P. Stone"], "venue": "Decision Support Systems, 39:55\u201366", "citeRegEx": "33", "shortCiteRegEx": null, "year": 2005}, {"title": "The Evolution of Cooperation", "author": ["R. Axelrod"], "venue": "Basic Books, New York", "citeRegEx": "34", "shortCiteRegEx": null, "year": 1984}, {"title": "The 2x2 Game", "author": ["A. Rapoport", "M.J. Guyer", "D.G. Gordon"], "venue": "The University of Michigan Press", "citeRegEx": "35", "shortCiteRegEx": null, "year": 1976}, {"title": "A Theory of Moves", "author": ["S.J. Brams"], "venue": "Cambridge University Press", "citeRegEx": "36", "shortCiteRegEx": null, "year": 1994}, {"title": "The Topology of the 2x2 Games: A New Period Table", "author": ["D. Robinson", "D. Goforth"], "venue": "Routledge", "citeRegEx": "37", "shortCiteRegEx": null, "year": 2005}, {"title": "Navigating the topology of 2x2 games: An introductory note on payoff families", "author": ["B. Bruns"], "venue": "normalization, and natural order. CoRR, abs/1010.4727", "citeRegEx": "38", "shortCiteRegEx": null, "year": 2010}, {"title": "A strategy of win-stay", "author": ["M. Nowak", "K. Sigmund"], "venue": "lose-shift that outperforms tit-for-tat in the prisoner\u2019s dilemma game. Nature, 364:56\u201358", "citeRegEx": "39", "shortCiteRegEx": null, "year": 1993}, {"title": "Critical dynamics in the evolution of stochastic strategies for the iterated prisoner\u2019s dilemma", "author": ["D. Iliopoulous", "A. Hintze", "C. Adami"], "venue": "PLOS Computational Biology, 6(10):1\u20138", "citeRegEx": "40", "shortCiteRegEx": null, "year": 2010}, {"title": "The Theory of Learning in Games", "author": ["D. Fudenberg", "D.K. Levine"], "venue": "The MIT Press", "citeRegEx": "41", "shortCiteRegEx": null, "year": 1998}, {"title": "Exploration\u2013exploitation tradeoffs for expert algorithms in reactive environments", "author": ["D. de Farias", "N. Megiddo"], "venue": "In Advances in Neural Information Processing Systems", "citeRegEx": "42", "shortCiteRegEx": "42", "year": 2004}, {"title": "Towards minimizing disappointment in repeated games", "author": ["J.W. Crandall"], "venue": "Journal of Artificial Intelligence Research, 49:111\u2013142", "citeRegEx": "43", "shortCiteRegEx": null, "year": 2014}, {"title": "Rational choice and the structure of the environment", "author": ["H.A. Simon"], "venue": "Psychological Review, 63(2):129\u2013 138", "citeRegEx": "44", "shortCiteRegEx": null, "year": 1956}, {"title": "D", "author": ["R. Karandikar", "D. Mookherjee"], "venue": "R., and F. Vega-Redondo. Evolving aspirations and cooperation. Journal of Economic Theory, 80:292\u2013331", "citeRegEx": "45", "shortCiteRegEx": null, "year": 1998}, {"title": "Satisficing and learning cooperation in the prisoner\u2019s dilemma", "author": ["J.R. Stimpson", "M.A. Goodrich", "L.C. Walters"], "venue": "Proceedings of the 17th National Conference on Artificial Intelligence, pages 535\u2013544", "citeRegEx": "46", "shortCiteRegEx": null, "year": 2001}, {"title": "The bargaining problem", "author": ["J.F. Nash"], "venue": "Econometrica, 28:155\u2013162", "citeRegEx": "47", "shortCiteRegEx": null, "year": 1950}], "referenceMentions": [{"referenceID": 0, "context": "Abstract Since Alan Turing envisioned Artificial Intelligence (AI) [1], a major driving force behind technical progress has been competition with human cognition.", "startOffset": 67, "endOffset": 70}, {"referenceID": 1, "context": "face recognition [2], personality classification [3], driving cars [4], or playing video games [5]), or defeating humans in strategic zero-sum encounters (e.", "startOffset": 17, "endOffset": 20}, {"referenceID": 2, "context": "face recognition [2], personality classification [3], driving cars [4], or playing video games [5]), or defeating humans in strategic zero-sum encounters (e.", "startOffset": 49, "endOffset": 52}, {"referenceID": 3, "context": "face recognition [2], personality classification [3], driving cars [4], or playing video games [5]), or defeating humans in strategic zero-sum encounters (e.", "startOffset": 67, "endOffset": 70}, {"referenceID": 4, "context": "face recognition [2], personality classification [3], driving cars [4], or playing video games [5]), or defeating humans in strategic zero-sum encounters (e.", "startOffset": 95, "endOffset": 98}, {"referenceID": 5, "context": "Chess [6], Checkers [7], Jeopardy! [8], Poker [9], or Go [10]).", "startOffset": 6, "endOffset": 9}, {"referenceID": 6, "context": "Chess [6], Checkers [7], Jeopardy! [8], Poker [9], or Go [10]).", "startOffset": 20, "endOffset": 23}, {"referenceID": 7, "context": "Chess [6], Checkers [7], Jeopardy! [8], Poker [9], or Go [10]).", "startOffset": 35, "endOffset": 38}, {"referenceID": 8, "context": "Chess [6], Checkers [7], Jeopardy! [8], Poker [9], or Go [10]).", "startOffset": 46, "endOffset": 49}, {"referenceID": 9, "context": "Chess [6], Checkers [7], Jeopardy! [8], Poker [9], or Go [10]).", "startOffset": 57, "endOffset": 61}, {"referenceID": 10, "context": "A main challenge has been that human cooperation does not require sheer computational power, but rather relies on intuition [11], cultural norms [12], emotions and signals [13, 14, 15, 16], and pre-evolved dispositions toward cooperation [17], common-sense mechanisms that are difficult to encode in machines for arbitrary contexts.", "startOffset": 124, "endOffset": 128}, {"referenceID": 11, "context": "A main challenge has been that human cooperation does not require sheer computational power, but rather relies on intuition [11], cultural norms [12], emotions and signals [13, 14, 15, 16], and pre-evolved dispositions toward cooperation [17], common-sense mechanisms that are difficult to encode in machines for arbitrary contexts.", "startOffset": 145, "endOffset": 149}, {"referenceID": 12, "context": "A main challenge has been that human cooperation does not require sheer computational power, but rather relies on intuition [11], cultural norms [12], emotions and signals [13, 14, 15, 16], and pre-evolved dispositions toward cooperation [17], common-sense mechanisms that are difficult to encode in machines for arbitrary contexts.", "startOffset": 172, "endOffset": 188}, {"referenceID": 13, "context": "A main challenge has been that human cooperation does not require sheer computational power, but rather relies on intuition [11], cultural norms [12], emotions and signals [13, 14, 15, 16], and pre-evolved dispositions toward cooperation [17], common-sense mechanisms that are difficult to encode in machines for arbitrary contexts.", "startOffset": 172, "endOffset": 188}, {"referenceID": 14, "context": "A main challenge has been that human cooperation does not require sheer computational power, but rather relies on intuition [11], cultural norms [12], emotions and signals [13, 14, 15, 16], and pre-evolved dispositions toward cooperation [17], common-sense mechanisms that are difficult to encode in machines for arbitrary contexts.", "startOffset": 172, "endOffset": 188}, {"referenceID": 15, "context": "A main challenge has been that human cooperation does not require sheer computational power, but rather relies on intuition [11], cultural norms [12], emotions and signals [13, 14, 15, 16], and pre-evolved dispositions toward cooperation [17], common-sense mechanisms that are difficult to encode in machines for arbitrary contexts.", "startOffset": 172, "endOffset": 188}, {"referenceID": 16, "context": "A main challenge has been that human cooperation does not require sheer computational power, but rather relies on intuition [11], cultural norms [12], emotions and signals [13, 14, 15, 16], and pre-evolved dispositions toward cooperation [17], common-sense mechanisms that are difficult to encode in machines for arbitrary contexts.", "startOffset": 238, "endOffset": 242}, {"referenceID": 5, "context": "While the majority of AI milestones have focused on developing humanlevel wherewithal to compete with people [6, 7, 8, 9, 10], most scenarios in which AI must interact with people and other machines are not zero-sum interactions.", "startOffset": 109, "endOffset": 125}, {"referenceID": 6, "context": "While the majority of AI milestones have focused on developing humanlevel wherewithal to compete with people [6, 7, 8, 9, 10], most scenarios in which AI must interact with people and other machines are not zero-sum interactions.", "startOffset": 109, "endOffset": 125}, {"referenceID": 7, "context": "While the majority of AI milestones have focused on developing humanlevel wherewithal to compete with people [6, 7, 8, 9, 10], most scenarios in which AI must interact with people and other machines are not zero-sum interactions.", "startOffset": 109, "endOffset": 125}, {"referenceID": 8, "context": "While the majority of AI milestones have focused on developing humanlevel wherewithal to compete with people [6, 7, 8, 9, 10], most scenarios in which AI must interact with people and other machines are not zero-sum interactions.", "startOffset": 109, "endOffset": 125}, {"referenceID": 9, "context": "While the majority of AI milestones have focused on developing humanlevel wherewithal to compete with people [6, 7, 8, 9, 10], most scenarios in which AI must interact with people and other machines are not zero-sum interactions.", "startOffset": 109, "endOffset": 125}, {"referenceID": 10, "context": "While AI relies on computationally intensive search and random exploration to generate strategic behavior, human cooperation appears to rely on intuition [11], cultural norms [12], emotions and signals [13, 14], and pre-evolved dispositions toward cooperation [17].", "startOffset": 154, "endOffset": 158}, {"referenceID": 11, "context": "While AI relies on computationally intensive search and random exploration to generate strategic behavior, human cooperation appears to rely on intuition [11], cultural norms [12], emotions and signals [13, 14], and pre-evolved dispositions toward cooperation [17].", "startOffset": 175, "endOffset": 179}, {"referenceID": 12, "context": "While AI relies on computationally intensive search and random exploration to generate strategic behavior, human cooperation appears to rely on intuition [11], cultural norms [12], emotions and signals [13, 14], and pre-evolved dispositions toward cooperation [17].", "startOffset": 202, "endOffset": 210}, {"referenceID": 13, "context": "While AI relies on computationally intensive search and random exploration to generate strategic behavior, human cooperation appears to rely on intuition [11], cultural norms [12], emotions and signals [13, 14], and pre-evolved dispositions toward cooperation [17].", "startOffset": 202, "endOffset": 210}, {"referenceID": 16, "context": "While AI relies on computationally intensive search and random exploration to generate strategic behavior, human cooperation appears to rely on intuition [11], cultural norms [12], emotions and signals [13, 14], and pre-evolved dispositions toward cooperation [17].", "startOffset": 260, "endOffset": 264}, {"referenceID": 14, "context": ", costless signals) is important to human cooperation in repeated interactions [15, 16], as it helps people coordinate quickly on desirable equilibrium and create shared representations [18, 19, 20, 21].", "startOffset": 79, "endOffset": 87}, {"referenceID": 15, "context": ", costless signals) is important to human cooperation in repeated interactions [15, 16], as it helps people coordinate quickly on desirable equilibrium and create shared representations [18, 19, 20, 21].", "startOffset": 79, "endOffset": 87}, {"referenceID": 17, "context": ", costless signals) is important to human cooperation in repeated interactions [15, 16], as it helps people coordinate quickly on desirable equilibrium and create shared representations [18, 19, 20, 21].", "startOffset": 186, "endOffset": 202}, {"referenceID": 18, "context": ", costless signals) is important to human cooperation in repeated interactions [15, 16], as it helps people coordinate quickly on desirable equilibrium and create shared representations [18, 19, 20, 21].", "startOffset": 186, "endOffset": 202}, {"referenceID": 19, "context": ", costless signals) is important to human cooperation in repeated interactions [15, 16], as it helps people coordinate quickly on desirable equilibrium and create shared representations [18, 19, 20, 21].", "startOffset": 186, "endOffset": 202}, {"referenceID": 20, "context": ", costless signals) is important to human cooperation in repeated interactions [15, 16], as it helps people coordinate quickly on desirable equilibrium and create shared representations [18, 19, 20, 21].", "startOffset": 186, "endOffset": 202}, {"referenceID": 38, "context": ", GODFATHER) and win-stay-lose-shift (WSLS) [39], evolutionarily evolved memory-one and memory-two stochastic strategies [40], machine-learning algorithms (including reinforcement learning), belief-based algorithms [41], and expert algorithms [42, 43].", "startOffset": 44, "endOffset": 48}, {"referenceID": 39, "context": ", GODFATHER) and win-stay-lose-shift (WSLS) [39], evolutionarily evolved memory-one and memory-two stochastic strategies [40], machine-learning algorithms (including reinforcement learning), belief-based algorithms [41], and expert algorithms [42, 43].", "startOffset": 121, "endOffset": 125}, {"referenceID": 40, "context": ", GODFATHER) and win-stay-lose-shift (WSLS) [39], evolutionarily evolved memory-one and memory-two stochastic strategies [40], machine-learning algorithms (including reinforcement learning), belief-based algorithms [41], and expert algorithms [42, 43].", "startOffset": 215, "endOffset": 219}, {"referenceID": 41, "context": ", GODFATHER) and win-stay-lose-shift (WSLS) [39], evolutionarily evolved memory-one and memory-two stochastic strategies [40], machine-learning algorithms (including reinforcement learning), belief-based algorithms [41], and expert algorithms [42, 43].", "startOffset": 243, "endOffset": 251}, {"referenceID": 42, "context": ", GODFATHER) and win-stay-lose-shift (WSLS) [39], evolutionarily evolved memory-one and memory-two stochastic strategies [40], machine-learning algorithms (including reinforcement learning), belief-based algorithms [41], and expert algorithms [42, 43].", "startOffset": 243, "endOffset": 251}, {"referenceID": 36, "context": "2) across the periodic table of 2x2 games [37] (see Methods and SI.", "startOffset": 42, "endOffset": 46}, {"referenceID": 42, "context": "The results show that only S++ [43] was a top-performing algorithm across all metrics at all game lengths when associating with other algorithms.", "startOffset": 31, "endOffset": 35}, {"referenceID": 14, "context": "Humans are known for their ability to effectively coordinate on cooperative equilibria using costless signals called cheap talk [15, 16].", "startOffset": 128, "endOffset": 136}, {"referenceID": 15, "context": "Humans are known for their ability to effectively coordinate on cooperative equilibria using costless signals called cheap talk [15, 16].", "startOffset": 128, "endOffset": 136}, {"referenceID": 15, "context": "Consistent with prior work investigating cheap talk in repeated games [16], messages were limited to the predetermined speech acts available to S#.", "startOffset": 70, "endOffset": 74}, {"referenceID": 31, "context": "Our results open the opportunity to study human-machine cooperation in a way that builds on the rich literature on human cooperation in behavioral economics and evolutionary biology [32].", "startOffset": 182, "endOffset": 186}, {"referenceID": 32, "context": "In particular, as machines become increasingly autonomous, we see human-machine cooperation as a phenomenon that emerges from the interaction among self-interested parties [33], rather than by explicit design constraints programmed into domain-specific computational systems [34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44].", "startOffset": 172, "endOffset": 176}, {"referenceID": 33, "context": "In particular, as machines become increasingly autonomous, we see human-machine cooperation as a phenomenon that emerges from the interaction among self-interested parties [33], rather than by explicit design constraints programmed into domain-specific computational systems [34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44].", "startOffset": 275, "endOffset": 319}, {"referenceID": 34, "context": "In particular, as machines become increasingly autonomous, we see human-machine cooperation as a phenomenon that emerges from the interaction among self-interested parties [33], rather than by explicit design constraints programmed into domain-specific computational systems [34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44].", "startOffset": 275, "endOffset": 319}, {"referenceID": 35, "context": "In particular, as machines become increasingly autonomous, we see human-machine cooperation as a phenomenon that emerges from the interaction among self-interested parties [33], rather than by explicit design constraints programmed into domain-specific computational systems [34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44].", "startOffset": 275, "endOffset": 319}, {"referenceID": 36, "context": "In particular, as machines become increasingly autonomous, we see human-machine cooperation as a phenomenon that emerges from the interaction among self-interested parties [33], rather than by explicit design constraints programmed into domain-specific computational systems [34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44].", "startOffset": 275, "endOffset": 319}, {"referenceID": 37, "context": "In particular, as machines become increasingly autonomous, we see human-machine cooperation as a phenomenon that emerges from the interaction among self-interested parties [33], rather than by explicit design constraints programmed into domain-specific computational systems [34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44].", "startOffset": 275, "endOffset": 319}, {"referenceID": 38, "context": "In particular, as machines become increasingly autonomous, we see human-machine cooperation as a phenomenon that emerges from the interaction among self-interested parties [33], rather than by explicit design constraints programmed into domain-specific computational systems [34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44].", "startOffset": 275, "endOffset": 319}, {"referenceID": 39, "context": "In particular, as machines become increasingly autonomous, we see human-machine cooperation as a phenomenon that emerges from the interaction among self-interested parties [33], rather than by explicit design constraints programmed into domain-specific computational systems [34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44].", "startOffset": 275, "endOffset": 319}, {"referenceID": 40, "context": "In particular, as machines become increasingly autonomous, we see human-machine cooperation as a phenomenon that emerges from the interaction among self-interested parties [33], rather than by explicit design constraints programmed into domain-specific computational systems [34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44].", "startOffset": 275, "endOffset": 319}, {"referenceID": 41, "context": "In particular, as machines become increasingly autonomous, we see human-machine cooperation as a phenomenon that emerges from the interaction among self-interested parties [33], rather than by explicit design constraints programmed into domain-specific computational systems [34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44].", "startOffset": 275, "endOffset": 319}, {"referenceID": 42, "context": "In particular, as machines become increasingly autonomous, we see human-machine cooperation as a phenomenon that emerges from the interaction among self-interested parties [33], rather than by explicit design constraints programmed into domain-specific computational systems [34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44].", "startOffset": 275, "endOffset": 319}, {"referenceID": 43, "context": "In particular, as machines become increasingly autonomous, we see human-machine cooperation as a phenomenon that emerges from the interaction among self-interested parties [33], rather than by explicit design constraints programmed into domain-specific computational systems [34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44].", "startOffset": 275, "endOffset": 319}, {"referenceID": 44, "context": "In light of these findings, greater effort must be placed on developing autonomous machines that can effectively communicate with people, and vice versa, in order to create shared representations [45, 46, 47, 41] and coordinate quickly on desirable equilibria.", "startOffset": 196, "endOffset": 212}, {"referenceID": 45, "context": "In light of these findings, greater effort must be placed on developing autonomous machines that can effectively communicate with people, and vice versa, in order to create shared representations [45, 46, 47, 41] and coordinate quickly on desirable equilibria.", "startOffset": 196, "endOffset": 212}, {"referenceID": 46, "context": "In light of these findings, greater effort must be placed on developing autonomous machines that can effectively communicate with people, and vice versa, in order to create shared representations [45, 46, 47, 41] and coordinate quickly on desirable equilibria.", "startOffset": 196, "endOffset": 212}, {"referenceID": 40, "context": "In light of these findings, greater effort must be placed on developing autonomous machines that can effectively communicate with people, and vice versa, in order to create shared representations [45, 46, 47, 41] and coordinate quickly on desirable equilibria.", "startOffset": 196, "endOffset": 212}, {"referenceID": 45, "context": "Our work emphasizes the importance of this problem, and presents case studies that others can work from to continue to make progress [46].", "startOffset": 133, "endOffset": 137}, {"referenceID": 31, "context": "Our results open the opportunity to study human-machine cooperation in a way that builds on the rich literature on human cooperation in be avioral economics and e oluti nary biology [32].", "startOffset": 182, "endOffset": 186}, {"referenceID": 32, "context": "In particular, as machines b ome incr asingly autonom us, we see human-mac ine cooperation as a phenomenon that emerges fro the interaction among self-interested parties [33], rather than by explicit design constraints programmed into domain-specific computational systems [34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44].", "startOffset": 170, "endOffset": 174}, {"referenceID": 33, "context": "In particular, as machines b ome incr asingly autonom us, we see human-mac ine cooperation as a phenomenon that emerges fro the interaction among self-interested parties [33], rather than by explicit design constraints programmed into domain-specific computational systems [34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44].", "startOffset": 273, "endOffset": 317}, {"referenceID": 34, "context": "In particular, as machines b ome incr asingly autonom us, we see human-mac ine cooperation as a phenomenon that emerges fro the interaction among self-interested parties [33], rather than by explicit design constraints programmed into domain-specific computational systems [34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44].", "startOffset": 273, "endOffset": 317}, {"referenceID": 35, "context": "In particular, as machines b ome incr asingly autonom us, we see human-mac ine cooperation as a phenomenon that emerges fro the interaction among self-interested parties [33], rather than by explicit design constraints programmed into domain-specific computational systems [34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44].", "startOffset": 273, "endOffset": 317}, {"referenceID": 36, "context": "In particular, as machines b ome incr asingly autonom us, we see human-mac ine cooperation as a phenomenon that emerges fro the interaction among self-interested parties [33], rather than by explicit design constraints programmed into domain-specific computational systems [34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44].", "startOffset": 273, "endOffset": 317}, {"referenceID": 37, "context": "In particular, as machines b ome incr asingly autonom us, we see human-mac ine cooperation as a phenomenon that emerges fro the interaction among self-interested parties [33], rather than by explicit design constraints programmed into domain-specific computational systems [34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44].", "startOffset": 273, "endOffset": 317}, {"referenceID": 38, "context": "In particular, as machines b ome incr asingly autonom us, we see human-mac ine cooperation as a phenomenon that emerges fro the interaction among self-interested parties [33], rather than by explicit design constraints programmed into domain-specific computational systems [34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44].", "startOffset": 273, "endOffset": 317}, {"referenceID": 39, "context": "In particular, as machines b ome incr asingly autonom us, we see human-mac ine cooperation as a phenomenon that emerges fro the interaction among self-interested parties [33], rather than by explicit design constraints programmed into domain-specific computational systems [34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44].", "startOffset": 273, "endOffset": 317}, {"referenceID": 40, "context": "In particular, as machines b ome incr asingly autonom us, we see human-mac ine cooperation as a phenomenon that emerges fro the interaction among self-interested parties [33], rather than by explicit design constraints programmed into domain-specific computational systems [34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44].", "startOffset": 273, "endOffset": 317}, {"referenceID": 41, "context": "In particular, as machines b ome incr asingly autonom us, we see human-mac ine cooperation as a phenomenon that emerges fro the interaction among self-interested parties [33], rather than by explicit design constraints programmed into domain-specific computational systems [34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44].", "startOffset": 273, "endOffset": 317}, {"referenceID": 42, "context": "In particular, as machines b ome incr asingly autonom us, we see human-mac ine cooperation as a phenomenon that emerges fro the interaction among self-interested parties [33], rather than by explicit design constraints programmed into domain-specific computational systems [34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44].", "startOffset": 273, "endOffset": 317}, {"referenceID": 43, "context": "In particular, as machines b ome incr asingly autonom us, we see human-mac ine cooperation as a phenomenon that emerges fro the interaction among self-interested parties [33], rather than by explicit design constraints programmed into domain-specific computational systems [34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44].", "startOffset": 273, "endOffset": 317}, {"referenceID": 44, "context": "In light of these findings, greater effort must be placed on developing autonomous machines that can effectively communicate with people, and vice versa, in order to create shared representations [45, 46, 47, 41] and coordinate quickly on desirable equilibria.", "startOffset": 196, "endOffset": 212}, {"referenceID": 45, "context": "In light of these findings, greater effort must be placed on developing autonomous machines that can effectively communicate with people, and vice versa, in order to create shared representations [45, 46, 47, 41] and coordinate quickly on desirable equilibria.", "startOffset": 196, "endOffset": 212}, {"referenceID": 46, "context": "In light of these findings, greater effort must be placed on developing autonomous machines that can effectively communicate with people, and vice versa, in order to create shared representations [45, 46, 47, 41] and coordinate quickly on desirable equilibria.", "startOffset": 196, "endOffset": 212}, {"referenceID": 40, "context": "In light of these findings, greater effort must be placed on developing autonomous machines that can effectively communicate with people, and vice versa, in order to create shared representations [45, 46, 47, 41] and coordinate quickly on desirable equilibria.", "startOffset": 196, "endOffset": 212}, {"referenceID": 45, "context": "Our work emphasizes the importance of this problem, and presents case studies that others can work from to continue to make progress [46].", "startOffset": 133, "endOffset": 137}, {"referenceID": 42, "context": "Figure 1: An overview of S#, an algorithm that interweaves signaling capabilities into S++ [43].", "startOffset": 91, "endOffset": 95}, {"referenceID": 44, "context": "(d) S# selects an expert (using algorithm S [45, 46]) from among those experts that both potentially meet its aspirations (step b) and are congruent with its partner\u2019s latest proposal (step c).", "startOffset": 44, "endOffset": 52}, {"referenceID": 45, "context": "(d) S# selects an expert (using algorithm S [45, 46]) from among those experts that both potentially meet its aspirations (step b) and are congruent with its partner\u2019s latest proposal (step c).", "startOffset": 44, "endOffset": 52}, {"referenceID": 21, "context": ", no expert remembers the full history of play), these experts are more sophisticated than those traditionally considered (though not explicitly excluded) in the discussion of expert algorithms [22, 23, 24].", "startOffset": 194, "endOffset": 206}, {"referenceID": 22, "context": ", no expert remembers the full history of play), these experts are more sophisticated than those traditionally considered (though not explicitly excluded) in the discussion of expert algorithms [22, 23, 24].", "startOffset": 194, "endOffset": 206}, {"referenceID": 23, "context": ", no expert remembers the full history of play), these experts are more sophisticated than those traditionally considered (though not explicitly excluded) in the discussion of expert algorithms [22, 23, 24].", "startOffset": 194, "endOffset": 206}, {"referenceID": 24, "context": "This more sophisticated set of experts permits S# to adapt to a variety of partners and game types, whereas algorithms that rely on a single strategy or a less sophisticated set of experts are only successful in particular kinds of games played with particular partners [25] (Figure 3c).", "startOffset": 270, "endOffset": 274}, {"referenceID": 25, "context": ", Exp3) have permeated algorithm development in the AI community, S# instead uses an expert-selection mechanism closely aligned with recognition-primed decision making [26].", "startOffset": 168, "endOffset": 172}, {"referenceID": 26, "context": "However, S++ also learns effectively in repeated stochastic games [27], which are more complex scenarios in which a round consists of a sequence of moves by both players.", "startOffset": 66, "endOffset": 70}, {"referenceID": 26, "context": "In these games, S++ is distinguished, again, by its ability to adapt to many different machine associates in a variety of different scenarios [27].", "startOffset": 142, "endOffset": 146}, {"referenceID": 26, "context": "Though future work should address more scenarios, S#\u2019s success in establishing cooperative relationships with people in these representative games, along with its consistently high performance across all classes of 2x2 games and various repeated stochastic games [27] when associating with other algorithms, gives us some confidence that these results will generalize to many other scenarios.", "startOffset": 263, "endOffset": 267}, {"referenceID": 5, "context": "Since Alan Turing envisioned Artificial Intelligence, major milestones have focused on defeating humans in zero-sum encounters [6, 7, 8, 9, 10].", "startOffset": 127, "endOffset": 143}, {"referenceID": 6, "context": "Since Alan Turing envisioned Artificial Intelligence, major milestones have focused on defeating humans in zero-sum encounters [6, 7, 8, 9, 10].", "startOffset": 127, "endOffset": 143}, {"referenceID": 7, "context": "Since Alan Turing envisioned Artificial Intelligence, major milestones have focused on defeating humans in zero-sum encounters [6, 7, 8, 9, 10].", "startOffset": 127, "endOffset": 143}, {"referenceID": 8, "context": "Since Alan Turing envisioned Artificial Intelligence, major milestones have focused on defeating humans in zero-sum encounters [6, 7, 8, 9, 10].", "startOffset": 127, "endOffset": 143}, {"referenceID": 9, "context": "Since Alan Turing envisioned Artificial Intelligence, major milestones have focused on defeating humans in zero-sum encounters [6, 7, 8, 9, 10].", "startOffset": 127, "endOffset": 143}, {"referenceID": 27, "context": "When it comes to human cooperation, a fundamental benchmark has been 2\u00d72, general-sum, repeated games [28].", "startOffset": 102, "endOffset": 106}, {"referenceID": 28, "context": "This class of games has been a workhorse for decades in the fields of behavioral economics [29], mathematical biology [30], psychology [31], sociology [32], computer science [33], and political science [34].", "startOffset": 91, "endOffset": 95}, {"referenceID": 29, "context": "This class of games has been a workhorse for decades in the fields of behavioral economics [29], mathematical biology [30], psychology [31], sociology [32], computer science [33], and political science [34].", "startOffset": 118, "endOffset": 122}, {"referenceID": 30, "context": "This class of games has been a workhorse for decades in the fields of behavioral economics [29], mathematical biology [30], psychology [31], sociology [32], computer science [33], and political science [34].", "startOffset": 135, "endOffset": 139}, {"referenceID": 31, "context": "This class of games has been a workhorse for decades in the fields of behavioral economics [29], mathematical biology [30], psychology [31], sociology [32], computer science [33], and political science [34].", "startOffset": 151, "endOffset": 155}, {"referenceID": 32, "context": "This class of games has been a workhorse for decades in the fields of behavioral economics [29], mathematical biology [30], psychology [31], sociology [32], computer science [33], and political science [34].", "startOffset": 174, "endOffset": 178}, {"referenceID": 33, "context": "This class of games has been a workhorse for decades in the fields of behavioral economics [29], mathematical biology [30], psychology [31], sociology [32], computer science [33], and political science [34].", "startOffset": 202, "endOffset": 206}, {"referenceID": 27, "context": "3; [28, 35, 36, 37, 38]) identifies and categorizes 144 unique game structures that present many unique scenarios in which machines may need to cooperate.", "startOffset": 3, "endOffset": 23}, {"referenceID": 34, "context": "3; [28, 35, 36, 37, 38]) identifies and categorizes 144 unique game structures that present many unique scenarios in which machines may need to cooperate.", "startOffset": 3, "endOffset": 23}, {"referenceID": 35, "context": "3; [28, 35, 36, 37, 38]) identifies and categorizes 144 unique game structures that present many unique scenarios in which machines may need to cooperate.", "startOffset": 3, "endOffset": 23}, {"referenceID": 36, "context": "3; [28, 35, 36, 37, 38]) identifies and categorizes 144 unique game structures that present many unique scenarios in which machines may need to cooperate.", "startOffset": 3, "endOffset": 23}, {"referenceID": 37, "context": "3; [28, 35, 36, 37, 38]) identifies and categorizes 144 unique game structures that present many unique scenarios in which machines may need to cooperate.", "startOffset": 3, "endOffset": 23}, {"referenceID": 36, "context": "Figure 5: We compared algorithms across the periodic table of 2x2 games based on the topology of Robinson and Goforth [37] for scenarios in which the players exhibit a strict ordinal preference ordering over the four game outcomes (specified by the values 1, 2, 3, and 4).", "startOffset": 118, "endOffset": 122}, {"referenceID": 46, "context": "The solutions played in the Nash bargaining solution (NBS [47] \u2013 i.", "startOffset": 58, "endOffset": 62}, {"referenceID": 37, "context": "The figure is adapted from the graphic developed by Bruns [38].", "startOffset": 58, "endOffset": 62}, {"referenceID": 38, "context": ", GODFATHER) and win-stay-lose-shift (WSLS) [39], evolutionarily evolved memory-one and memory-two stochastic strategies [40], machine-learning algorithms (including reinforcement learning), belief-based algorithms [41], and expert algorithms [42, 43].", "startOffset": 44, "endOffset": 48}, {"referenceID": 39, "context": ", GODFATHER) and win-stay-lose-shift (WSLS) [39], evolutionarily evolved memory-one and memory-two stochastic strategies [40], machine-learning algorithms (including reinforcement learning), belief-based algorithms [41], and expert algorithms [42, 43].", "startOffset": 121, "endOffset": 125}, {"referenceID": 40, "context": ", GODFATHER) and win-stay-lose-shift (WSLS) [39], evolutionarily evolved memory-one and memory-two stochastic strategies [40], machine-learning algorithms (including reinforcement learning), belief-based algorithms [41], and expert algorithms [42, 43].", "startOffset": 215, "endOffset": 219}, {"referenceID": 41, "context": ", GODFATHER) and win-stay-lose-shift (WSLS) [39], evolutionarily evolved memory-one and memory-two stochastic strategies [40], machine-learning algorithms (including reinforcement learning), belief-based algorithms [41], and expert algorithms [42, 43].", "startOffset": 243, "endOffset": 251}, {"referenceID": 42, "context": ", GODFATHER) and win-stay-lose-shift (WSLS) [39], evolutionarily evolved memory-one and memory-two stochastic strategies [40], machine-learning algorithms (including reinforcement learning), belief-based algorithms [41], and expert algorithms [42, 43].", "startOffset": 243, "endOffset": 251}, {"referenceID": 21, "context": ", Exp3 [22], GIGA-WoLF [23], and WMA [24]), which is the central component of world-champion computer poker algorithms [9], also performed poorly.", "startOffset": 7, "endOffset": 11}, {"referenceID": 22, "context": ", Exp3 [22], GIGA-WoLF [23], and WMA [24]), which is the central component of world-champion computer poker algorithms [9], also performed poorly.", "startOffset": 23, "endOffset": 27}, {"referenceID": 23, "context": ", Exp3 [22], GIGA-WoLF [23], and WMA [24]), which is the central component of world-champion computer poker algorithms [9], also performed poorly.", "startOffset": 37, "endOffset": 41}, {"referenceID": 8, "context": ", Exp3 [22], GIGA-WoLF [23], and WMA [24]), which is the central component of world-champion computer poker algorithms [9], also performed poorly.", "startOffset": 119, "endOffset": 122}, {"referenceID": 42, "context": "Second, while many algorithms had high performance with respect to some measure, only S++ [43] was a top-performing algorithm across all metrics at all game lengths.", "startOffset": 90, "endOffset": 94}, {"referenceID": 42, "context": "3 S#: A Machine-Learning Algorithm that Talks S# is derived from S++ [43], an expert algorithm that combines and builds on decades of research in computer science, economics, and the behavioral and social sciences.", "startOffset": 69, "endOffset": 73}, {"referenceID": 43, "context": "S++ then uses a meta-level control strategy based on aspiration learning [44, 45, 46] to dynamically reduce this set of experts.", "startOffset": 73, "endOffset": 85}, {"referenceID": 44, "context": "S++ then uses a meta-level control strategy based on aspiration learning [44, 45, 46] to dynamically reduce this set of experts.", "startOffset": 73, "endOffset": 85}, {"referenceID": 45, "context": "S++ then uses a meta-level control strategy based on aspiration learning [44, 45, 46] to dynamically reduce this set of experts.", "startOffset": 73, "endOffset": 85}, {"referenceID": 44, "context": "It then selects one expert esel(t) \u2208 E(t) using a satisficing decision rule [45, 46].", "startOffset": 76, "endOffset": 84}, {"referenceID": 45, "context": "It then selects one expert esel(t) \u2208 E(t) using a satisficing decision rule [45, 46].", "startOffset": 76, "endOffset": 84}], "year": 2017, "abstractText": "Since Alan Turing envisioned Artificial Intelligence (AI) [1], a major driving force behind technical progress has been competition with human cognition. Historical milestones have been frequently associated with computers matching or outperforming humans in difficult cognitive tasks (e.g. face recognition [2], personality classification [3], driving cars [4], or playing video games [5]), or defeating humans in strategic zero-sum encounters (e.g. Chess [6], Checkers [7], Jeopardy! [8], Poker [9], or Go [10]). In contrast, less attention has been given to developing autonomous machines that establish mutually cooperative relationships with people who may not share the machine\u2019s preferences. A main challenge has been that human cooperation does not require sheer computational power, but rather relies on intuition [11], cultural norms [12], emotions and signals [13, 14, 15, 16], and pre-evolved dispositions toward cooperation [17], common-sense mechanisms that are difficult to encode in machines for arbitrary contexts. Here, we combine a state-of-the-art machine-learning algorithm with novel mechanisms for generating and acting on signals to produce a new learning algorithm that cooperates with people and other machines at levels that rival human cooperation in a variety of two-player repeated stochastic games. This is the first general-purpose algorithm that is capable, given a description of a previously unseen game environment, of learning to cooperate with people within short timescales in scenarios previously unanticipated by algorithm designers. This is achieved without complex opponent modeling or higher-order theories of mind, thus showing that flexible, fast, and general human-machine cooperation is computationally achievable using a non-trivial, but ultimately simple, set of algorithmic mechanisms. \u2217Correspondence should be addressed to crandall@cs.byu.edu and irahwan@mit.edu ar X iv :1 70 3. 06 20 7v 1 [ cs .A I] 1 7 M ar 2 01 7", "creator": "LaTeX with hyperref package"}}}