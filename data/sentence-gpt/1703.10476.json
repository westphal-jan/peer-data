{"id": "1703.10476", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "30-Mar-2017", "title": "Speaking the Same Language: Matching Machine to Human Captions by Adversarial Training", "abstract": "While strong progress has been made in image captioning over the last years, machine and human captions are still quite distinct. A closer look reveals that this is due to the deficiencies in the generated word distribution, vocabulary size, and strong bias in the generators towards frequent captions. Furthermore, humans -- rightfully so -- generate multiple, diverse captions, due to the inherent ambiguity in the captioning task which is not considered in today's systems.\n\n\n\n\nIn a recent article on the human mind we discussed how the human brain has been able to create multiple, unique captions, with the exception of the use of a single word. When the word 'j' appears in human terms, it indicates that the human brain's attention and language ability have been enhanced.\n\"In terms of information processing capacity, the human brain has been able to create multiple, unique captions and the usage of different words in the context of complex tasks and/or concepts,\" explained David Bouda, a Professor of Cognitive Science at the University of Wisconsin-Madison. \"A large part of the reason why the human brain is able to generate multiple, unique captions and the use of different words has been due to the inherent ambiguity in the captioning task which is not considered in today's systems.\"\nThe results of the study showed that humans have improved over time by generating multiple, unique captions, with the exception of the use of a single word. This may contribute to greater brain-language recognition, but it does not necessarily indicate that humans have improved over time. In addition to our finding that the human brain has been able to generate multiple, unique captions, the human brain has been able to generate multiple, unique captions, with the exception of the use of a single word.\nThe results of the study found that people have improved over time by generating multiple, unique captions and the use of different words in the context of complex tasks and/or concepts. The work was supported by a number of funding sources from Carnegie Mellon, U.S. Department of Education, The American Psychological Association, The American Psychological Association, American Psychiatric Association and the American Sociological Association.", "histories": [["v1", "Thu, 30 Mar 2017 13:54:51 GMT  (9553kb,D)", "http://arxiv.org/abs/1703.10476v1", "16 pages"]], "COMMENTS": "16 pages", "reviews": [], "SUBJECTS": "cs.CV cs.AI cs.CL", "authors": ["rakshith shetty", "marcus rohrbach", "lisa anne hendricks", "mario fritz", "bernt schiele"], "accepted": false, "id": "1703.10476"}, "pdf": {"name": "1703.10476.pdf", "metadata": {"source": "CRF", "title": "Speaking the Same Language: Matching Machine to Human Captions by Adversarial Training", "authors": ["Rakshith Shetty", "Marcus Rohrbach", "Lisa Anne Hendricks", "Mario Fritz", "Bernt Schiele"], "emails": [], "sections": null, "references": [], "referenceMentions": [], "year": 2017, "abstractText": "While strong progress has been made in image caption-<lb>ing over the last years, machine and human captions are<lb>still quite distinct. A closer look reveals that this is due to<lb>the deficiencies in the generated word distribution, vocabu-<lb>lary size, and strong bias in the generators towards frequent<lb>captions. Furthermore, humans \u2013 rightfully so \u2013 generate<lb>multiple, diverse captions, due to the inherent ambiguity in<lb>the captioning task which is not considered in today\u2019s sys-<lb>tems. To address these challenges, we change the training ob-<lb>jective of the caption generator from reproducing ground-<lb>truth captions to generating a set of captions that is indis-<lb>tinguishable from human generated captions. Instead of<lb>handcrafting such a learning target, we employ adversar-<lb>ial training in combination with an approximate Gumbel<lb>sampler to implicitly match the generated distribution to the<lb>human one. While our method achieves comparable perfor-<lb>mance to the state-of-the-art in terms of the correctness of<lb>the captions, we generate a set of diverse captions, that are<lb>significantly less biased and match the word statistics better<lb>in several aspects.", "creator": "LaTeX with hyperref package"}}}