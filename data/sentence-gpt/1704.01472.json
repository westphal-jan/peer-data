{"id": "1704.01472", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "4-Apr-2017", "title": "Automatic Breast Ultrasound Image Segmentation: A Survey", "abstract": "Breast cancer is one of the leading causes of cancer death among women worldwide. In clinical routine, automatic breast ultrasound (BUS) image segmentation is very challenging and essential for cancer diagnosis and treatment planning. Many BUS segmentation approaches have been studied in the last two decades, and have been proved to be effective on private datasets in many diseases.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "histories": [["v1", "Tue, 4 Apr 2017 14:23:26 GMT  (1410kb)", "http://arxiv.org/abs/1704.01472v1", "71 pages, 6 tables, 166 references"]], "COMMENTS": "71 pages, 6 tables, 166 references", "reviews": [], "SUBJECTS": "cs.CV cs.LG", "authors": ["min xian", "yingtao zhang", "h d cheng", "fei xu", "boyu zhang", "jianrui ding"], "accepted": false, "id": "1704.01472"}, "pdf": {"name": "1704.01472.pdf", "metadata": {"source": "CRF", "title": "Automatic Breast Ultrasound Image Segmentation: A Survey", "authors": ["Min Xian", "Yingtao Zhang", "H. D. Cheng", "Fei Xu", "Boyu Zhang", "Jianrui Ding"], "emails": [], "sections": [{"heading": null, "text": "1 / 71\nBreast cancer is one of the leading causes of cancer death among women worldwide. In clinical routine, automatic breast ultrasound (BUS) image segmentation is very challenging and essential for cancer diagnosis and treatment planning. Many BUS segmentation approaches have been studied in the last two decades, and have been proved to be effective on private datasets. Currently, the advancement of BUS image segmentation seems to meet its bottleneck. The improvement of the performance is increasingly challenging, and only few new approaches were published in the last several years. It is the time to look at the field by reviewing previous approaches comprehensively and to investigate the future directions. In this paper, we study the basic ideas, theories\uff0cpros and cons of the approaches, group them into categories, and extensively review each category in depth by discussing the principles, application issues, and advantages/disadvantages.\nKeyword: breast ultrasound (BUS) images, breast cancer, segmentation, benchmark, early detection, computer-aided diagnosis (CAD)\n2 / 71"}, {"heading": "1. Introduction", "text": "Breast cancer occurs in the highest frequency in women among all cancers, and is also one of the leading causes of cancer death worldwide [1, 2]. Scientists do not definitely know what causes breast cancer, and only know some risk factors that can increase the likelihood of developing breast cancer: getting older, genetics, radiation exposure, dense breast tissue, alcohol consumption, etc. The key of reducing the mortality is to find signs and symptoms of breast cancer at its early stage by clinic examination [3]. Breast ultrasound (BUS) imaging has become one of the most important and effective modality for the early detection of breast cancer because of its noninvasive, nonradioactive and cost-effective nature [4]; and it is most suitable for large scale breast cancer screening and diagnosis in low-resource countries and regions.\nComputer-Aided Diagnosis (CAD) systems based on B-mode breast ultrasound have been de-\nveloped to overcome the considerable inter- and intra-variabilities of the breast cancer diagnosis, and have been clinically-tested their ability to improve the performance of the breast cancer diagnosis. BUS segmentation, extracting tumor region from normal tissue regions of a BUS image, is a crucial step for a BUS CAD system. Base on the segmentation results, quantitative features will be extracted to describe tumor shape, size, orientation, echo pattern, etc., and be input into a classifier to determine the category of the tumors. Therefore, the precision of BUS segmentation directly affects the performance of the quantitative analysis and diagnosis of tumors.\nAutomatic BUS segmentation has been extensively studied in the last two decades. Due to the\npoor quality of BUS images, automatic BUS segmentation is a quite challenging task. We can\n3 / 71\nclassify existing approaches into semi-automated and fully automated groups according to the degree of human intervention involved in segmentation process. In most semi-automated methods, user needs to specify a region of interest (ROI) including the lesion, a seed in the lesion, or initial boundary. Fully automated segmentation approaches need no user intervention, and usually model the knowledge of breast ultrasound and oncology as prior constraints for the segmentation. However, many segmentation techniques were employed in both semiautomatic and fully automatic approaches.\nIn this paper, we classify breast cancer segmentation approaches into six main categories: (1)\ngraph-based approaches, (2) deformable models, (3) learning-based approaches, (4) thresholding, (5) region growing, and (6) watershed. As shown in Fig. 1, the first three categories dominate BUS image segmentation approaches; and the last three categories are the classical image processing approaches. The category of the others is composed of three small sub-categories, each contains only few literatures. Due to the challenging nature of the task, just using single image processing technique cannot achieve desirable results; and most successful approaches employ hybrid techniques and model biological priors.\n4 / 71\nThe rest of the paper is organized as follows: in sections 2 - 5, we review automatic BUS image\nsegmentation methods by presenting the principle of each category, discussing their advantages and disadvantages, and summarizing the most valuable strategies. In section 6, we discuss the approaches of three small sub-categories briefly. In section 7, the fundamental issues in BUS segmentation are discussed, e.g., denoising, interaction, biological priors modeling, validation, and the possible problem-solving strategies. Section 8 is the conclusion and the future directions."}, {"heading": "2. Graph-based approaches", "text": "Graph-based approaches gain increasing popularity in BUS image segmentation because they offer several advantages: (1) they provide a simple way to organize task-related priors and image information in a unified framework; (2) they are flexible and suitable for expressing soft constraints between random variables; and (3) the computation based on graphical manipulation is very efficient [5].\nLet = ( , \u2130) be a graph comprising a set of nodes (vertices) = { , , \u22ef , }, and\neach of them corresponds to an image pixel or superpixel; and a set of links (edges) \u2130 =\n\u2329 , \u232a , \u2208 , and each of them connects two adjacent nodes according to a predefined\nneighborhood system = { | = 1, \u22ef , } where is the set of neighbors of node .\nEach link \u2329 , \u232a is associated with a nonnegative weight ( , ). The weight is\nusually defined as the cost of separating the two connected nodes into different classes. The segmentation of an image is transferred to partition the graph into non-overlap subgraphs. The BUS segmentation is usually modeled as a bi-segmentation problem; therefore, the goal is to partition\n5 / 71\ngraph G into two subgraphs (tumor and non-tumor). Let = ( , \u2130 ) be the subgraph corresponding to non-tumor regions, and = ( , \u2130 ) be the subgraph corresponding to the tumor regions, where , \u2286 and \u2130 , \u2130 \u2286 \u2130, \u222a = , \u2229 = \u2205, and \u2130 \u2229 \u2130 = \u2205."}, {"heading": "2.1 MRF-MAP approaches", "text": "Markov random field (MRF) is a undirected graphical model, and provides a convenient way to model context-dependent entities (pixels or superpixels). In MRF, a site set = { } is introduced to index the node set ; each site i is associated with a random variable ; = { } is the configuration (implementation) of random variable set = { } , and takes value from a label set \u2112 = { } where m is the number of labels (classes). In BUS image segmentation, the label set is usually defined as \u2112 = { , } where denotes tumor and denotes non-tumor.\nLet ( ) be the joint probability (also called the prior distribution) denoted as ( = ). X\nis said to be a MRF on S with respect to a neighborhood system if and only if it satisfies the positivity and Markovianity:\n( ) = ( | { }) ( { }) > 0\n= ( | ) ( { }) (1)\nwhere { } denotes a set of labels for sites \u2212 { }, and is the set of labels for the neighboring sites of i.\nMaximum a posteriori (MAP) is the most popular optimality criterion for MRF modeling and\nthe optimal ( \u2217) is found by\n\u2217 = argmax ( | ) = argmax ( | ) ( ) (2)\n6 / 71\nwhere d is the observation (image), ( | ) is the posterior distribution and ( | ) is the likelihood distribution. The Hammersley-Clifford theorem [6] established the equivalence between MRF and Gibbs random field (GRF), and the MAP is equivalently found by minimizing the posterior energy function\n\u2217 = argmin ( | ) = argmin ( | ) + ( ) (3)\nwhere ( | ) = ( | ) + ( ), and ( | ) is the likelihood energy and ( ) is prior energy.\nThere are two major parts in the MRF-MAP modeling for BUS image segmentation: (1) de-\nfining the prior and likelihood energies and determining the corresponding initial parameters; and (2) designing optimization algorithm for finding the minimum of the posterior energy.\nAshton and Parker [7] define the MRF prior energy as the Ising/Potts model\n( ) = ( ) \u2208 + , \u2208\u2208\n(4)\n, = , if =\n\u2212 , otherwise (5)\nwhere is a positive constant. The assumption that every site s takes any label equally likely makes ( ) a constant for all configurations; therefore, ( ) is usually defined on the pairwise term ( ( , )).\nThey also assume that the intensities of a low-pass filtered image follow the Gaussian distri-\nbution, and the likelihood energy is given by\n( | ) = ln + \u2212\n2( ) \u2208\n(6)\nwhere di is the intensity of the pixel at site i, is the label of site i, and and are the local class mean and standard deviation, respectively. The parameters ( and ) are estimated by\n7 / 71\nusing a modified adaptive k-mean method [8] which estimates the class mean locally using a sliding window.\nBoukerroui et al. [9] stated that healthy and pathological breast tissues present different tex-\ntures of BUS images, and improved the method in [7] by modeling both intensity and texture distributions in the likelihood energy; they also assume that the texture features represented by using co-occurrence matrix follow the Gaussian distribution; and the parameters were estimated similarly to the method in [7].\nTo improve the additivity of BUS image segmentation method, Boukerroui et al. [10] modified\nthe method in [9] by introducing a weighting function considering both global and local statistics. The weighting function is defined on the Kolmogorov-Smirnov distance between the global intensity distribution of the entire sites of a class and the distribution of the sites of the same class in a local window.\nIn [11], the proposed method followed the MRF-MAP framework, and formulated the BUS\nsegmentation similar to [7], the only difference is that the Gaussian parameters are defined globally and specified manually. In order to improve the process of manual selection of Gaussian parameters in [11], reference [12] proposed a one-click user interaction to estimate Gaussian parameters automatically. The user specified only one pixel in tumor and the method opens a small window and a large window to obtain the lesion and background information, respectively. The foreground and background parameters were estimated using the pixel intensity distributions in the small and large windows. However, how to decide the window sizes was not discussed. [13] introduced the tissue\n8 / 71\nstiffness information of ultrasound elastography to the method in [11] by modifying the one-dimensional tumor and background Gaussian distributions as bivariate Gaussian distributions; however, it did not discuss how to determine the Gaussian parameters.\nThe energy function of MRF-MAP can be optimized by using Simulated Annealing (SA) [14]\nand Iterated Conditional Mode (ICM) [15] algorithms. Because ICM is much faster than SA, the ICM is preferred in most BUS image segmentation approaches [7, 9, 11 - 13]. ICM takes a local greedy strategy: it starts with an initial labeling from estimation or user interaction, then selects label for each site to minimize the energy function; and the steps repeat until converge.\nICM is quite sensitive to the initialization (parameters) because of its high possibility of con-\nverging to local minima, especially, for non-convex energies in high-dimensional space [35]. A detailed comparison between ICM and other MRF energy minimization techniques can be found in [35]. Therefore, one important issue of applying ICM is how to learn the parameters: Gibbsian parameter (Eq. 6), number of classes (m), and parameters of the initial Gaussian distribution. The number of classes is usually set from 2 to 4 for BUS image; and \u03b2 could be set adaptively [7] or set to a constant [11-13]; and the parameters of Gaussian distribution are usually initialized by using K-means algorithm [7, 9, 10]."}, {"heading": "2.2 Graph cuts", "text": "Graph cuts was proposed to solve a special case in MRF-MAP framework [16]: the global optimization of the binary labelling problem (\u2112 = { , }). It was then improved to solve the general (color image segmentation) and multi-label problem [17, 18]. Graph cuts has been widely applied\n9 / 71\nto image segmentation. In this section, we will present the basic concepts of graph cuts, and review the approaches utilizing graph cuts for BUS image segmentation.\nThe main idea of graph cuts is to employ the theories and algorithms of the min-cut (s-t cut)\nand max-flow for binary segmentation. The graph is defined as following.\n= ( , \u2130 ), = \u222a { , },\n\u2130 = \u2130 \u222a {\u2329 , \u232a| \u2208 } \u222a {\u2329 , \u232a| \u2208 } (7)\nAs shown in Eq. (7), graph cuts introduces two auxiliary nodes s and t representing the source\nand sink, respectively; the newly added edges between each node in and the terminal nodes (s and t) are called the t-links, and the original edges among neighboring nodes in \u2130 are called the nlinks.\nA cut ( ) of is defined by\n= \u2329 , \u232a \u2329 , \u232a \u2208 \u2260 (8)\nwhere and are the labels for nodes and , respectively; and the default labels for nodes s and t are l1 and l2, respectively. The cost of the cut is given by\n( ) = ( , ) \u2329 , \u232a\u2208\n= \u2219 ( , ) + (1 \u2212 ) ( , ) \u2208 + \u2212 , \u2208 , \u2208\n(9)\nIn Eq. (9), defines the weight of edge in \u2130 ; the cost function of a cut can be decomposed\ninto two terms: the data term and the smoothness term. The data term is similar to the likelihood energy of MAP-MRF, which is usually modeled based on domain related knowledge (e.g., color\n10 / 71\ndistribution, shape and location); and the smoothness term is usually to penalize the discontinuity between neighboring nodes. The segmentation of an image is to find a cut that minimizes ( ); the minimum s-t cut is equivalent to maximize the flow (max-flow) from s to t according to the Ford-Fulkerson theorem [19]. If a cost function is submodular [20], it can be represented by a graph ( ), and the function can be minimized by using the max-flow algorithm. The Boykov-Kolmogorov version [21] of the implementation of the max-flow algorithm can be downloaded from http://vision.csd.uwo.ca/code/.\nBy applying graph cuts for BUS image segmentation, the key issue is how to define the data\nterm and smoothness term. Xian et al. [22] proposed a fully automatic BUS image segmentation framework in which the cost function modeled the information in the frequency and space domains. The data term modeled the tumor pose, position and intensity distribution; and the weights are given by\n( , ) = \u2212 [ ( ) \u2219 Pr( | = 1)] (10)\n( , ) = \u2212 1 \u2212 ( ) \u2219 Pr( | = 0) (11)\nG(i) is a 2D elliptical Gaussian function to model the tumor pose and position, and is constructed based on the results of the ROI generation [22]. ( | ) defines the intensity distributions of the tumor and nor-tumor regions. The smoothness term is constructed based on the intensity discontinuities in the space domain and the edge detection results in the frequency domain; and the weight function is defined by\n, = 1 \u2212 , + , (12)\n11 / 71\nwhere ED is the edge detector defined in the frequency domain, and De is the Euclidean distance between two nodes. For details, please refer [22, 23].\nIn [24], the graph is built on image regions, and user needs to specify a group of foreground\n(tumor) regions (F) and a group of background regions (B) to initialize the graph. The weight of any t-link is set to \u221e if the node belongs to \u2229 , and all other weights of t-links are set to 0; the weight function of the smoothness term is defined by utilizing region intensity difference and edge strength [138].\nIn [25], a discriminative graph cut was proposed, in which ( , ) and ( , ) in the data\nterm were determined online by training a Probabilistic Boosting Tree (PBT) [26] classifier based on the detection results (foreground and background patches); and ( , ) in the smoothness term was learned offline utilizing the training set by the PBT. Hao et al. [27] constructed a hierarchical multiscale superpixel classification framework to define the weights in the data term. The hierarchical classifier has four layers (20, 50, 200, and 800 superpixels/nodes, respectively) built by using the normalized cut and k-means for multiscale representation; and a SVM classifier for each layer was trained based on superpixel histogram, position, shape clues, SGLD features and dense SIFT descriptor. The histogram difference (Euclidean distance) between adjacent superpixels was used to define the weights in the smoothness term. In [28], both the region-level [29] and pixellevel features were utilized to define the weights in the data term; and all weights were learned by using a structural SVM [30]. 2.3 Normalized cut\n12 / 71\nIn ( ), the smoothness term is also called the length regularizer, and the minimization of\n( ) will cause the bias to favor small component (\u201cshrinking\u201d problem). To avoid bias, Shi et al. [31] proposed the Normalized cut to reformulate the energy function by considering both the disconnected links and the links inside each component:\n( , ) = ( , )\n( , ) + ( ) + ( , ) ( , ) + ( )\n= \u2211 ,\n\u2211 \u2211 + \u2211 , \u2211 \u2211\n(13)\nwhere = ( , \u2130 ) and = ( , \u2130 ) are two subgraphs where , \u2286 and \u2130 , \u2130 \u2286 \u2130, \u222a = , \u2229 = \u2205, and \u2130 \u2229 \u2130 = \u2205; ( , ) is the total weight of the links between and ; ( ) and ( ) are the total weights in and , respectively; with this definition, the cut with small component will have small ( ) or ( ) and large NCut value. The minimization of Eq. (14) can be transferred to the solution of the eigenvalue system if the equation is rewritten in the matrix form as following:\nmin ( , ) = min ( \u2212 )\n(14)\n. . = 0 and \u2208 {1, \u2212 }\nwhere D is an \u00d7 diagonal matrix with (\u2211 ) on its diagonal, and the weight matrix\n= \u00d7 is a symmetrical matrix; vector y is set as (1 + ) \u2212 (1 \u2212 ), and b is defined as \u2211 \u2211 (\u2211 , \u2212 \u2211 \u2211 )\u2044 . To make the equation tractable, the constraint is relaxed to allow yi take real values; and the eigenvector with the second smallest eigenvalue of the Laplacian matrix (D \u2013 W) is the solution of the relaxed equation. Once the eigenvector with the second smallest eigenvalue is computed, one can bipartition the graph by choosing a split point of the\n13 / 71\neigenvector (two-way cut). A recursive implementation of Normalized cut was proposed [31], which repeated the bipartition step on subgraphs until certain criterion is satisfied.\nGenerally, three main steps are for applying Normalized Cut to BUS image segmentation: (1)\nconstructing a weighted graph (pixel-level or superpixel-level) to define the weight matrix (W); (2) solving the Laplacian matrix (D\u2212W) to obtain the eigenvectors, and applying the two-way cut or k-way cut to partition BUS image; and (3) determining the final tumor region by user interaction or formulated prior knowledge.\n[27, 34] applied normalized cut as an initial step to segment BUS images into small patches,\nand the final segmentation needs extra merging step and formulated knowledge to determine the tumor region. Gao et al. [32] stated that traditional edge-driven approaches are too sensitive to noise and heavily depend on image denoising. [33] proposed a semi-automatic BUS image segmentation method based on Normalized cut. The feature of each pixel is defined using homogeneous patches, and weight (wij) between two nodes was defined as the similarity. Manual determination of ROI was needed in the segmentation, and the number of classes in the Normalized Cut was set as 2."}, {"heading": "2.4 Summary", "text": "Graph-based approaches account for the second largest portion of BUS image segmentation literatures (Fig. 1). They are among the earliest techniques for BUS image segmentation, fade away due to the successful application of other powerful approaches such as deformable models (section 3),\n14 / 71\nand surge again because of the dramatic advances of graph models and energy optimization algorithms.\nMRF-MAP-ICM is a flexible framework for image multi-partition (not just tumor or non-\ntumor). Most BUS image segmentation approaches based on this framework achieving good performance by designing better likelihood energy and obtaining better initialization. Only obtaining locally optimal solution is the main shortcoming of these approaches. Graph cuts provides an efficient framework for image bi-partition and MRF energy global optimization, and is the main factor to make graph-based models popular again in BUS image segmentation. The approaches based on graph cuts focus on designing more comprehensive data and smoothness terms to deal with low contrast, inhomogeneity, and not well-defined boundary problems of BUS images. The \u201cshrink\u201d problem is the common disadvantage of these approaches, and the extension [18] can only find the approximate solution of multiple labeling of graph cuts. Normalized cut avoids the \u201cshrink\u201d problem by considering both the disconnected links and the links inside each component. However, without the likelihood energy or data term, it cannot integrate semantic information into the energy, and usually needs user interaction or combining with other approach to achieve good performance; high computational cost is another drawback of Normalized cut. A detailed comparison of nine typical graph-based BUS image segmentation approaches is listed in Table 1.\nAs illustrated in Table 1, two approaches [25, 28] learned all parameters of graph models by\nusing discriminative learning. This strategy enhances the robustness of graph models. Another potentially useful strategy is to build high-order graph models, in which every pair of nodes in the\ngraph has an edge; it can be applied to represent the global correlation among nodes, and can obtain a more representative smoothness term. The traditional algorithms such as ICM and max-flow cannot solve the high-order graph model effectively, and an efficient approach to optimize the fully connected graph model was proposed in [36].\n16 / 71"}, {"heading": "3. Deformable models", "text": "Deformable models (DMs) are curves or surfaces that can move toward to the object boundary under the influence of forces defined on the curve or surface by using the knowledge of image. DMs can deal with biological structures with significant variability, and permit user to integrate expertise to guide the segmentation when necessary; therefore, they have been applied to BUS image segmentation extensively in the last decade.\nDMs are proposed by Terzopoulos [37], and then become a popular and active field after the\nsnake approach for planar image proposed by Kass et al. [38]. Generally, DMs can be classified into two categories according to the curve or surface representation during deformation: (1) the parametric DMs (PDMs) and (2) the geometric DMs (GDMs). In PDMs, curve or surface is represented by its parametric form explicitly, e.g., curve is defined as {( ( ), ( ))| \u2208 [0, 1]} where ( ( ), ( )) is the coordinates of point p on C. The representation is intuitive and can lead to a fast implementation. GDMs represent curves and surfaces implicitly as a level set of a scalar function, e.g., = {( , )| ( , ) = 0}. It can adapt to topological changes of targets, which is helpful for segmenting multi-objects and objects with unknown topology."}, {"heading": "3.1 Parametric deformable models", "text": "Finding object boundaries (parameterized curves and surfaces) using PDMs is formulated to minimize an energy function including internal and external energies. The internal term is used to control the continuity and smoothness of curves and surfaces; and the external energy function is calculated using image features to attract curves to object boundary.\n17 / 71\nLet ( ) = ( ( ), ( )), \u2208 [0, 1] be a deformable curve; it moves to the optimal object boundary by minimizing\n\u2130( ) = \u2130 ( ) + \u2130 ( ). (15)\nThe internal energy is defined by\n\u2130 ( ) = 1 2\n( \u2219 ( ) + \u2219 ( ) ) (16)\nwhere indicates the first order derivative of C that keeps the continuity of curve, and is the second order derivative that controls the smoothness of curve; and are the weights; large\nwill lead the change in distances between points on curve to have high cost, and large will\npenalize more on non-smooth curve. The external energy is defined as the integral of a cost function based on image features along curve C:\n\u2130 ( ) = ( ) (17)\nwhere is the cost function based on image features. The general formulation of P in the original DMs [38] is defined by\n( , ) = ( , ) + ( , ) + ( , ) (18)\nwhere , and extract image line, edge and termination features, respectively; while , and are the corresponding weights. Minimization: the problem of finding the curve C minimizing \u2130( ) is to find the extrema of functional which satisfies Euler-Lagrange equation [38]:\n\u2130( ) = \u2212\u03b1( ) + ( ) + \u2207 = 0 (19)\n18 / 71\nThe above equation states that the functional derivative vanishes at the optimal curve. Given an initial curve C0, we can apply the gradient descent minimization to optimize \u2130( ) iteratively. At step t + 1, the pth point on curve C is updated as\n( ) = ( ) + ( ) (20)\nwhere is the step size, F is the force on curve defined as the negative of the functional derivative\n= \u03b1( ) \u2212 ( ) \u2212\u2207 (21)\nwhere the internal forces Fint discourage curve stretching and bending, and the external forces Fext often are composed of multiple forces to make the models flexible enough to handle different tasks.\n19 / 71\nThe default PDMs discussed above may converge poorly for real image segmentation tasks\nbecause of several limitations, e.g., failing to converge to concave boundaries, and poor performance if the initial curve is not close to the minimum. Several variants have been proposed to address the problems of the default PDMs by introducing different external energy (Table 2)."}, {"heading": "3.2 Geometric deformable models (GDMs)", "text": "GDMs [40, 41] are proposed to overcome the two primary limitations of PDMs: lack of topology adaptivity and parameterization dependence. In GDMs, a 2D curve (C) at time t is represented implicitly as the zero-level set of a scalar function ( ): = { ( , ) = ( , )| ( , , ) = 0}, and the curve deformation utilizes curve\u2019s geometric measures such as the unit norm and curvature, and image properties. Let ( , ) and ( , ) be the speed and the unit normal vector of the pth point of an evolving curve at time t, respectively; the partial derivative of C with respect to t can be defined as the normal component of :\n= \u2219 , (22)\nsince the tangential component does not affect the geometry of an evolving curve.\nBecause of the curve representation by using level set function in GDMs, the deformation of\ncurve is realized by evolving the level set function rather than tracking the evolution of the curve, which enables the automatic topology adaption of the embedded curve. Given a level set function\n( , , ), and a curve { ( , )}, we have\n( ( , ), ) = 0, + \u2207 = 0 (23)\n20 / 71\nIf is negative inside and positive outside, the inside-pointing unit norm can be defined as = \u2212 \u2207\n|\u2207 | , and we can obtain\n= \u2212\u2207 \u2219 \u2219 = \u2219 |\u2207 | (24)\nNotice that the speed function is the key of GDMs; and it is usually defined as a function of the curvature ( ); to avoid the final curve shrinking to a point, image related information such as gradient is usually formulated to slow down the evolving process and to attract the evolving curve to the desired boundary. Three important issues need to consider in GDMs implementation: (1) designing the speed function. The foremost step in applying GDM is to design an appropriate speed function that can stop the evolving curve at the desirable object contour. A commonly used speed function is formulated as [42-44]\n= \u2219 ( + ) \u2212 \u2329\u2207 , \u232a (25) = 1\n1 + |\u2207( \u2217 )| (26)\nwhere is a constant to speed up the curve deformation, g is the stopping function by using image gradient to slow down and to stop the curve evolving at high gradient locations, and the second term (\u2329\u2207 , \u232a) makes the stopping power stronger when there are no perfect edges. (2) Initializing the level set function; the initial level set function is usually the signed distance from each point to the zero level set. A fast computation approach is described in [41]. (3) Reinitializing the level set function; the speed function is defined only on the zero level set; the level function deformation requires it to be extended to all level sets; the extensions [45] can cause\n21 / 71\nthe irregularity problem of level set function. The reinitialization is applied to provide a numerical approach to replace the level set function with newly signed distance functions. For more information about the reinitialization, please refer [45-47]."}, {"heading": "3.3 Edge-based vs. Region-based DMs", "text": "DMs provide a flexible image segmentation framework that can incorporate both low-level image features and various prior knowledge, such as edge, local region statistics, shape, and intensity distribution. The DMs can be classified into edge-based [38, 41, 42, 44, 48] and region-based [47, 49, 66] according to the information to construct the external force in PDMs or speed function in GDMs. Edge-based DMs aim to attract the evolving curve to object boundary by defining the deformation force or speed using image gradient [42-44], and the models depend on image gradient to stop curve deformation. Region-based DMs model region features to guide the curve deformation; by modeling local region features, region-based models can usually achieve better performance than edge-based models; specially, if images have plenty of noise and weak object boundary."}, {"heading": "3.4 Deformable models for BUS image segmentation", "text": "The application of DMs for BUS image segmentation can be divided into two stages. In the first stage BUS image segmentation approaches apply the ideas of PDMs, and focus on developing method to generate good initialization. To achieve global deformation and local variation of irregular tumor, Chen et al. [50] applied the B-snake model [51] for BUS image sequence segmentation. The external forces are composed of the balloon force and the second gradient of Gaussian smoothed image. No quantitative result was reported. In [52], Chen et al. proposed a cell-based\n22 / 71\ndual snake [53] to handle the two problems of applying traditional DMs for BUS image segmentation: (1) initial contour should be placed close to the tumor boundary; and (2) cannot capture highly winding tumor boundary. The attraction force between the inner and outer snakes makes the dual snake model escape from the local minimum. Qualitative evaluation has been conducted on both synthetic and real ultrasound images, but no quantitative result was reported. In [54, 55], Madabhushi et al. proposed a fully automatic approach for BUS image segmentation using PDM which is initialized by utilizing the boundary points produced in tumor localization step; and the balloon forces are employed in the external forces. The approach was evaluated by employing 90 BUS images with TP = 75%, FP = 20%.9, FN = 25%, HE = 19.7 and ME = 6.8.\nIn [56, 57], Sahiner applied PDM for 3D BUS tumor segmentation, the external forces have\ntwo terms; the first term is defined on image gradient calculated using 3\u00d73 Sobel filters; and the second term is the balloon force. They evaluated the approach using the final tumor classification results of 102 BUS images.\nIn [58, 59], Chang et al. applied DM for 3D breast ultrasound image segmentation. The sticks\nfilter [60] was utilized to enhance edge and reduce speckle noise. They evaluated the approach using eight 3D BUS cases, and the match rate was utilized for quantitative evaluation and the average is about 95%. Huang et al. [61] proposed an automatic BUS image segmentation approach by using the gradient vector flow (GVF) model [70]. The initial boundary was obtained by using Watershed approach. The approach was validated using 20 BUS images with similarity index = 0.884, overlap fraction = 0.81, and extra fraction = 0.058. Yap et al. [62] proposed a fully automatic\n23 / 71\napproach by applying GVF model. In its initial contour generation step, a fixed threshold was employed for candidate generation. The rules based on segment size and each segment\u2019s distance to the predefined reference point (RP) were applied to determine the initial tumor region. Totally 360 BUS images were utilized, but no quantitative results reported.\nIn the second stage, many works modified DMs to improve segmentation performance. Yezzi\net al. [42] modified traditional GDMs to have an additional term (\u2329\u2207 , \u232a) that provided stronger stopping power at object edges. Deng et al. [63] proposed a fast GDM method for biomedical image segmentation. The computation cost is linearly proportional to the number of image pixels. They only update the speed function and evolve the level set functions in a small window. The experimental results showed that it was much faster than the narrow band algorithm [52]. Liu et al. [64] proposed a fully automatic BUS image segmentation based on texture classification and GDM. The approach has two steps: the first step generated candidate tumor regions by using a well-trained texture classifier (SVM) to classify image lattices (16\u00d716) into normal tissue and tumor, and a probability distance-based GDMs approach was proposed to find the final tumor boundary. The method was validated using 103 BUS images.\nGomez et al. [65] stated that GDMs establish stopping term based on image gradient may not\nwork well because of the noisy and weak boundary. They proposed a BUS image segmentation approach based on the active contour without edges (ACWE) model [66] which defined the stopping term using Mumford-Shah technique and was robust to segment images with weak boundaries.\n24 / 71\nThe initial contour is a five-pixel radius circle centered at a point in the tumor marked by user. They evaluated the approach using 50 BUS images.\nLiu et al. [67] proposed an interactive BUS image segmentation approach utilizing region-\nbased GDMs, in which the probability density difference between the intensity distributions (tumor and background) and the estimated Rayleigh distribution are applied to enforce priors of intensity distribution. The approach was compared with two other GDM approaches [66, 68] using 79 BUS images. Rodtook et al. [69] modified the generalized GVF [70] approach based on a continuous force field analysis, and applied it to BUS image segmentation. Daoud et al. [71] considered the SNR and local intensity value as two important features for estimating tumor boundary, and built a two-fold termination criterion based on the two features in discrete dynamic DMs [72]. Gao et al. [73] proposed a level set approach for BUS image segmentation based on the method in [47] by redefining the edge-based stop function using phase congruency [74] which is invariant to intensity magnitude, and integrated GVF model into the level set framework.\nCai et al. [75] proposed phase-based DM in which the local region statistics [49] is introduced\nto solve the inhomogeneous intensity problem, and the phase-based edge indicator is used to replace the conventional gradient-based edge operator. Lin et al. [76] modified the local region-based level set approach [77] by using additional constrained energies centered at four markers specified by radiologist. [78] proposed a fully automatic robust region-based level set approach with contour points classification (low contrast class and high contrast class). Different points on the curve may have different energy functions determined by the proposed locally signed pressure force function.\nFor the points in the low contrast class, both the global and local region-based energies [66, 77] are used; while for the high contrast class, only the local region-based [77] energy is utilized. [79] adopted the region-based approach in [78], proposed a learning based approach (multivariate linear regression and support vector regression) to produce the parameters adaptively, and proved better performance using 481 BUS images. Yuan et al. [80] proposed a new level set based DM approach; the local divergence and a smoothing kernel were introduced to improve the speed function.\nKuo et al. [81, 82] proposed a semi-automatic approach for 3D BUS image segmentation. The\napproach utilized user interaction to generate the volume of interest (VOI), applied the radial-gradient index [83] to estimate the initial lesion boundary, and implemented the region-based DM [48, 49] iteratively to find the final contour. The stopping criterion was defined as ( \u0305 \u2212 \u0305 ) \u2212 ( \u0305 \u2212 \u0305 ) = 0 [84], where \u0305 and \u0305 were the mean intensities inside and outside the segmented regions at step t, respectively. The approach was validated using 98 3D BUS images."}, {"heading": "3.5 Summary", "text": "26 / 71\n[85], 2010 GDMs S 79 Model the difference between the\nregional intensity distribution and the estimated prior distribution\nSlow; sensitive to initialization\n[124], 2012 PDMs S 20 Redefine the edge-based stopping\nfunction using phase information\nValidated only on a small dataset; sensitive to noise\n[139], 2013 GDMs S 168 Use both local statistics and phase\ninformation to define the speed function; and handle weak boundary and inhomogeneity problems better\nSlow\n[148], 2013 GDMs F 861 Region-based GDM and solve the\ninhomogeneity problem better\nSlow and sensitive to initialization\n[166], 2014 GDMs S 98(3D) Use Region-based GDM and han-\ndle inhomogeneity problem\nSlow and need user interaction to extract VOI\nDM is the most popular approach applied to BUS image segmentation. For PDMs, the explicit curve or surface representation allows direct model interaction and can lead to fast implementation. The results of most PDMs are sensitive to initialization, and different initial curve or surface may converge to different local minimal locations and lead to quite different results; consequently, many variants of PDMs extend the attraction range to avoid local minima. The curves or surfaces of PDMs do not split and merge during the deforming process, which makes PDMs unable to adapt to topological change and to segment multiple objects with single initialization. GDMs apply level set functions to represent curves and surfaces implicitly, and inspire great progress in the related fields. There are two advantages of GDMs: (1) they can allow shapes to change topology during the evolving process, which makes them suitable for segmenting multiple objects and time-varying objects; and (2) the numerical computation of the curve and surface propagation can be implemented without parameterizing the objects. GDMs transfer the n-dimensional curve and surface\n27 / 71\ndeformation into n+1-dimensional level set function, which needs to extend the speed function to all level set functions and increases the computational cost greatly.\nTable 3 presents detailed comparison of 10 typical DMs-based BUS image segmentation ap-\nproaches. Because of the two advantages, GDMs become more popular than traditional PDMs in BUS image segmentation; and most successful approaches focus on improving the performance of GDMs to deal with the weak boundary and inhomogeneity of BUS images. There are two useful strategies: (1) redefining the stopping function ( ), and making it independent of image gradient; and (2) redesigning the speed function by using regional statistics."}, {"heading": "4. Learning-based approaches", "text": "Image segmentation can also be viewed as a classification problem, classifying pixels or superpixels into different categories. Therefore, it is quite common to apply machine learning approaches to image segmentation tasks. Both supervised and unsupervised learning approaches have been employed. By applying the unsupervised methods, BUS image is first partitioned into disjoint regions, and then prior knowledge (location, size, appearance, etc.) is utilized to determine the final tumor region."}, {"heading": "4.1 Unsupervised learning approaches", "text": "K-means and Fuzzy C-means (FCM) are two popular unsupervised learning (clustering) approaches. Because K-means can be viewed as a special case of FCM, we only present the theoretical background of FCM in this section.\n28 / 71\nFCM was proposed in [85] and improved in [86]. Let = { , \u22ef } be a finite set of data\n(pixels or superpixels), = { } be a list of C cluster centers; and FCM partitions set D into C clusters by minimizing the following objective function:\n( ) \u2212 (27)\nIn Eq. (28), \u2208 [0,1] is the membership value representing the degree of data point belonging to cluster , and is given by\n= 1\n\u2211 \u2212\n\u2016 \u2212 \u2016\n(28)\nwhere m ( \u2208 and \u2265 1) is the fuzzifier, and determines the degree of cluster fuzziness; a large m leads fuzzier clusters (smaller ); if m = 1, takes values 0 or 1, which implies a hard partition (K-means); and m is usually set to 2 if no domain knowledge is introduced. The cluster centers are computed on all data points and weighted by their membership values:\n= \u2211\n\u2211 (29)\nThe objective function (Eq. (27)) is optimized iteratively to find the local minimum in two simple steps: (1) decide the number of clusters (C) and assign the initial membership values ( ); and (2) iteratively update the cluster centers (Eq. (29)) and the membership values (Eq. (28)) until the membership values\u2019 change between two iterations is less than a predefined threshold.\nThe main advantage of the FCM is that each data point can belong to every cluster with a\ncorresponding membership value rather than just belong to one cluster as in K-means, and FCM\n29 / 71\ncan achieve better performance for overlapped data points. However, like K-means, the FCM algorithm can only find the local minima and the results depend on the initialization. A detailed comparison of BUS image segmentation approaches based on K-means and FCM is listed in Table 4.\nIn [7, 9, 10], K-means was utilized to estimate the parameters of distributions in graph-based\nmodels, and the predefined number of clusters should be set. Xu et al. [87] proposed a BUS image segmentation method using the spatial FCM (sFCM) [88] with local texture and intensity features. In sFCM, the membership value of each point is updated by using its neighbors\u2019 membership values. The number of clusters (C) is set as 2, and the initial membership values are assigned by using the modes of image histogram. Lo et al. [89] applied FCM to generate image regions in four clusters, then extracted the morphology, location, and size features of each region; and finally trained a linear regression model [90] to produce the tumor likelihoods for all regions. The region with the highest likelihood is considered as a tumor. Moon et al. [91] applied FCM to image regions produced by using the mean shift method [92]; the number of clusters is set to 4, and the regions belonging to the darkest cluster are extracted as the tumor candidates. [91] trained a linear regression model to estimate the tumor likelihoods of candidate regions utilizing seven quantitative features which were extracted according to the American College of Radiology (ACR) Breast Imaging Reporting and Data System (BI-RADS) [93]. [89, 91] did not discuss how to initialize the membership values in FCM. To deal with the blur boundary and uncertainty in BUS images, Shan et al. [94, 95] extended the FCM and proposed the neutrosophic l-means (NLM) clustering which takes\n30 / 71\nthe indeterminacy of membership into consideration, and can handle the uncertainty in BUS images much better."}, {"heading": "4.2 Supervised learning approaches", "text": ""}, {"heading": "4.2.1 Support vector machine (SVM)", "text": "SVM is one of the most popular supervised-learning models in machine learning, and can be utilized for both linear classification (linear SVM) and non-linear classification (kernel SVM) [96, 99] by mapping its inputs to high dimensional spaces.\nLet {( , )} be a training dataset of n points where is either 1 or -1, indicating the\nclass of data point ; SVM aims to find a hyperplane which can separate the training samples by a gap as wide as possible. Let w be the normal vector to the hyperplane, and { = (0, 1 \u2212\n( \u2219 + ))} be slack variables for the soft margins; then the problem can be formulated as\na constrained quadratic optimization problem [97]\n1\n+ \u2016 \u2016 (30)\n. . \u2200 , ( \u2219 + ) \u2265 1 \u2212 \u2265 0\nFinally, w and b learned from the training dataset can be used to classify new data by computing = ( \u2219 + ).\nLiu et al. [98] trained a kernel SVM classifier [99] using the local image features to classify\nsmall image lattices (16\u00d716) into tumor or non-tumor classes; the radius basis function (RBF) was\n31 / 71\nutilized; and 18 features, including 16 features from co-occurrence matrix and the mean and variance of the intensities, were extracted from a lattice; then some post-processing operations, like removing line-like areas and filling holes, were utilized to determine the final tumor regions. Jiang et al. [100] proposed two-step BUS segmentation approach. First, a set of candidate tumor regions were produced by using Adaboost classifier [101] and 24 Haar-like features [102]; and a SVM classifier was trained using the quantized intensity features produced by K-means clustering to determine the false positive and true positive regions. Second, random walk [103] was applied to generate the final tumor boundary by placing seed at the center of each true region."}, {"heading": "4.2.2 Artificial Neural network (ANN)", "text": "ANN is another popular supervised learning approach for BUS image segmentation. ANN mimics the biological neural networks, and is capable of approximating arbitrary function from observed data.\nA typical ANN has three layers: an input layer, a hidden layer and an output layer, intercon-\nnected by weighted links, e.g., = [ , , \u22ef , , ] is the weight vector of the links between jth hidden units and the input units, and = [ , , \u22ef , , ] is the weight vector between the kth unit in the output layer and the hidden units. The units in the layers are usually called \u2018neurons\u2019. The input neurons represent the feature vector = [ , \u22ef , ] ; hj is the output of the jth hidden neuron; and = [ , \u22ef , ] yielded in the output layers will be used for classification. The output of the kth neuron in the output layer ( ) is\n32 / 71\n= , \u2219 \u2219 (31)\nwhere (\u2219) is the activation function of a neuron (hidden and output layers), and converts a neuron\u2019s weighted input to its output value; the preferred activation function should be non-linear and differentiable such as the sigmoid and hyperbolic tangent functions.\nThe learning process of ANN is to determine the weights of all links using a set of training\ndata. In practical situations, the mean-squared error (MSE) is commonly used as the cost function and the well-known backpropagation algorithm is for training ANNs.\nHuang et al. [103] proposed an ANN-based method to segment 3D BUS images by processing\n2D images slices. First, thresholding was applied to generate candidate regions; then five region features (average gray level intensity, entropy, ratio of region size to slice size, ratio of region size to the size of its bounding box, and the distance from the region center to image center), were used as the inputs of NN; furthermore, among all the slices, the image having a region with the highest NN output was set as the reference image in which the region was set as tumor region; the reference image and tumor region was compared with adjacent slices to find new tumor regions, which later was used as a new reference. The 3D boundary of BUS tumors was reconstructed after all image slices were processed. The number of hidden unites and output units was not discussed.\n[104] trained an ANN to generate the threshold for BUS image segmentation. Two feature\nextraction approaches were proposed: 1) using 128 \u00d7 nkey SIFT features where nkey is the number of key points; 2) exacting 4 texture features (contrast, correlation, energy and homogeneity) of\n33 / 71\n40\u00d740 region around each key point using GLCM along four directions, and the final dimension of the texture feature matrix is 16 \u00d7 nkey. Therefore, the input feature vector is 144 \u00d7 nkey. The ANN has 3 layers, 60 nodes in hidden nodes, one node in the output layer. The stop criterion is 10- 7 of the MSE.\nShan et al. [105, 106] trained an ANN using three new features: the phase in the max-energy\norientation (PMO) based on phase congruency, radial distance (RD) and the joint probability of intensity and texture [30]. The NN had 6 hidden units and 1 output unit. 4.2.3 Naive Bayesian classifiers (NBCs)\nNBCs are a family of probabilistic classifiers based on the strong independence assumption:\ngiven the class variable, each feature is independent of other features in the feature vector. By using the strong independence assumption and the Bayes\u2019 theorem, the conditional distribution over the class variable is\n( | ) = 1 ( ) ( | ) , = 1, \u22ef , (32)\nwhere = [ , \u22ef , ] is the variable of n independent features, and = [ , \u22ef ] is K class labels; = ( ) is a constant if the values of the feature variables are known; ( ) is the prior distribution of label .\nNBC commonly combines the conditional distribution and the MAP decision rule to con-\nstruct the classifier:\n= argmax ( ) \u220f ( | ) (33)\nApplying NBC, the first thing is to calculate the prior by assuming equiprobable classes ( ( ) =\n( ), \u2260 ) or by estimating from the training set; and then one must assume the conditional dis-\ntribution ( ( | )) over feature variables or learn a nonparametric model from training set.\nYang et al. [138] proposed a whole breast tumor detection method by classifying slice pixels\ninto tumor (x1) or normal tissue (x2) by using NBC. Two features, local (5\u00d75 mask) intensity mean and stick filter [60] output, were utilized; the class priors were assumed to be equiprobable, and the conditional distribution of each feature ( ) was assumed to be Rayleigh distribution:\n( | ) = \u2044 , = 1, 2 (34)\nwhere is the Rayleigh parameter and can be estimated from training data. NBC produced a set of suspected lesions, and a two-phase lesion selection method based on region shape features (area size, width-height ratio, region ratio and compactness) and region continuity and volume size were applied for final tumor region decision [108].\n35 / 71\n[103] ANN F 93 cases (3D) Fully automatic Depended on fixed threshold to\nproduce candidate regions; relatively low performance\n[106], 2012\nANN F 120 images Achieved good performance by us-\ning the phase information, radial distance and the joint distribution of texture and intensity\nDepended on fixed reference point to generate the initial ROI\n[107], 2012\nNBC F 31 cases\n(Whole BUS images)\nAchieved high sensitive ratio Depended on the assumption of\nintensity distribution; depended on post selection to reduce false positive ratio"}, {"heading": "4.3 Summary", "text": "Unsupervised learning is simple and fast, and has been widely utilized in many BUS image\nsegmentation approaches. However, because of the challenging nature of BUS image segmentation, unsupervised approaches are only used as a preprocessing step to generate candidate image regions and more sophisticated methods are usually employed to perform the final segmentation; for example, in [7, 9, 10], K-means is utilized to estimate the initial parameters of intensity or texture distributions; and in [89, 91], logistic regression is utilized for clustering results to find the final tumor.\nSupervised learning provides a good framework to integrate different levels of features and to\nlearn knowledge between the inputs and target outputs. Many BUS image segmentation approaches achieve good performance by using supervised learning approaches. Most of them design features using domain knowledge (feature engineering) to improve the performance. They can be integrated with other segmentation techniques, e.g., in [25, 28], supervised learning approaches learn the parameters of the graph-based models from the training data; they also can be used to perform\n36 / 71\nsegmentation alone, e.g., in [120], a well-trained ANN was applied to perform the tumor segmentation. One common disadvantage of the supervised learning approaches is that they cannot produce accurate tumor boundary, and refinement is usually necessary.\nLearning-based approaches thrive in BUS image segmentation in the last decade and we be-\nlieve new deep learning techniques [162] such as deep convolutional neural networks (CNNs) and recurrent neural network (RNN) will make great progress in segmenting BUS images in the near future."}, {"heading": "5. Classical Approaches: thresholding, region growing and watershed", "text": "In this section, we will discuss some classical segmentation approaches applied to BUS image segmentation, and they are usually combined with other methods to achieve good performance."}, {"heading": "5.1 Thresholding", "text": "Thresholding is the most intuitive, simple and fast segmentation approach, and enjoys popu-\nlarity in BUS image segmentation. It groups image pixels directly into regions by using a single threshold (two classes) or multiple thresholds (multiple classes) based on pixel features (e.g., intensity, color, local mean, standard deviation, etc). A threshold th segments image pixels into two classes:\n( ) = , ( ) > \u210e , ( ) \u2264 \u210e\n(35)\nwhere I(p) is the intensity of the pth pixel; and and are the labels for two classes. When th is a constant over entire image, the method is called global thresholding; if th is changing over the local features, the method is referred as adaptive/local thresholding. Global thresholding is fast and\n37 / 71\nworks well when the intensity distributions of objects and background are sufficiently distinct; however, if the object-background contrast is low, image is noisy, and/or illumination varies across the image, global thresholding cannot achieve good performance. There are two solutions: (1) applying image enhancement technics before global thresholding, and (2) using local thresholding method adaptively.\nThresholding is often used as a pre-segmentation step for tumor localization and the compu-\ntational efficiency is more important than the accuracy; therefore, the pre-segmentation scheme of global thresholding with image enhancement is preferred.\nThere are three main approaches to select the global threshold. The first is to choose empirical\nvalue as the threshold for the whole dataset [109-111]; the second approach is to select the threshold for each image based on domain related rules [112, 113]; and the third is to generate the threshold automatically based on statistical-decision theory [22, 114, 115]."}, {"heading": "5.2 Region growing", "text": "Region growing extracts image regions from a set of pixels (seeds) and growing seeds to bigger regions utilizing predefined growth criteria. Seed generation: the seeds can be placed by user interactively [116, 117] or generated automatically [54, 55, 113, 118]. In [54, 55], Madabhushi et al. selected seed ( \u2217) automatically from a set of candidate pixels by formulating empirical rules [55]:\n\u2217 = argmax \u0393 , \u2219 \u2110 \u2219\n(36)\n38 / 71\nwhere and are the intensity and texture values of pixel p, respectively; \u0393( , ) is pixel p\u2019s value of joint intensity and texture probability; \u2110 refers to the local mean value of \u0393 around p; is the row position (origin at the lower-left of image) of p and avoids selecting seed from the shadowing region which appears in the bottom of BUS image; and is the distance between p and image center. [118] used this method for seed generation. For each pixel p adjacent to the seed region, if p satisfies (growing criterion): \u2110 /\u2110 \u2217 \u2208 [ , ], p will be added to the seed region, where and are selected by experiment. The growing process will stop until no more pixel satisfying the condition\nShan et al. [113] proposed another automatic seed generation approach. Thresholding was\nused to generate a group of candidate regions; and the region ranking criteria based on region location, size and local feature, were utilized to determine a true tumor region ( \u2217):\n\u2217 = argmax ( )\n\u2219 ( ) (37)\nwhere ( ) is the number of pixels in region r; is the distance between the center of r and the fixed reference point (center of the top half of image); is the center of region r; and ( ) is the local variance of a circular region at the center of region r; a pixel inside region \u2217 will be selected as the seed. Let I(p) and (\u0305 ) be intensity and local mean intensity of pixel p, respectively, the growing criterion is defined by\n1 \u2212 ( ) \u2264 1 \u2212 | ( ) \u2212 ( )|\n( ) \u2265\n1 \u2212 ( ) \u2265 1 \u2212 | (\u0305 ) \u2212 ( )|\n( ) \u2265 (38)\n39 / 71\nwhere m(r) is the average intensity of the current seed region, and t1, t2 and t3 are set as 0.5, 0.2 and 0.99, respectively. The growing processing stops when no more pixel satisfies the above condition.\nKwak et al. [117] defined the cost of growing a region by modelling common contour\nsmoothness and region similarity (mean intensity and size):\n( , ) = ( ) \u2212 ( )\n\u2219 ( , ) + \u2219 ( ) \u2219 ( ) ( ) + ( ) , \u2208 ( ) (39)\nwhere (\u2219) denotes the mean intensity of a region, (\u2219) is the pixel number of the region,\n( , ) is the length of the common contour between the seed region rs and region r, ( ) is a set of regions adjacent to rs, and and are two predefined constants. The region with the minimum value of J will be added to the seed region. The growing will repeat until \u2211 ( , )\u2208 ( ) over the length of contour rs reaches the maximum. 5.3 Watershed Watershed is a powerful image segmentation method, and usually produces more stable results than thresholding and region growing approaches, and offers a framework to integrate domain-related priors as well. There are different definitions of watershed [119, 120]. The most popular definition is the watershed by flooding [119]; and the idea is to place a water source in each local minimum (marker), then flooding the image from the markers, and building barriers at the points of the first contact of different water sources. The barriers are the watershed and the boundaries of objects. The most common implementation of watershed for image segmentation can be found in [121]. In practice, watershed is usually applied to gradient image on which the pixels with small values in a catchment basin correspond to an object. The key issue in watershed segmentation is the marker\n40 / 71\nselection. One approach is to choose the local minimum gradient as the marker, which will usually result in over-segmentation due to noise, and further step such as region merging should be involved. The other approaches choose makers based on more complex predefined criteria that can utilize the task-related priors.\nHuang et al. [122] applied the watershed to segment the preprocessed BUS images and the\nmarkers were selected based on grey level and connectivity. [109, 123] used watershed to segment ROI into small regions, and used the predefined criteria (area, mean intensity, geodesic center, etc) to determine the final tumor region. 255 groups of markers were selected by thresholding (th = 1, 2, \u22ef, 255) the image [124, 125]; the external and the internal markers were defined by using the morphological dilation and erosion. Watershed method was applied to generate 255 potential lesion boundaries by using the markers on different thresholds; the average radial derivative (ARD) function was applied to determine the final tumor boundary. Zhang et al. [126, 127] applied watershed to determine the boundaries of gray level images. The markers are set as the connected dark regions; and post processing based on predefined criteria (region location, mean intensity, and ratio of width to length) is needed to refine the results. [128] applied watershed to generate meaningful regions, and refined the regions by removing the top 50% hyper-echogenic (bright) regions and the regions connected to the image border to generate candidate tumor regions; the candidate regions were distinguished between tumors and non-tumors by using a logistic regression classifier [129] trained using region morphology, intensity and texture features. 5.4 Summary\n41 / 71\nproaches: thresholding, region growing and Watershed; and discuss their applications to BUS image segmentation. The three approaches are quite simple, fast and efficient to conduct initial segmentation of BUS image, and facilitate further segmentation procedures. The most common purpose of applying these approaches is to locate tumor by generating candidate regions or boundaries, and to use the results to initialize further segmentation. These classical approaches usually use\n42 / 71\nsimple low-level image features such as intensity and local statistics to perform segmentation, and are vulnerable to low image quality due to noise, inhomogeneity and low contrast. Therefore, to achieve good performance of BUS image segmentation, two additional steps are usually needed: first, image preprocessing step is applied to improve image quality by denoising and enhancing contrast; second, more delicate approaches are utilized to refine the segmentation results."}, {"heading": "6. Other approaches", "text": "Beside the four main categories of BUS image segmentation approaches discussed in sections 2-5, there exist some interesting approaches presented in few papers. We discuss them briefly in this section. Cellular automata (CA): CA was introduced by von Neumann [133] and applied to interactive image segmentation [134]. In image segmentation, a cell is usually associated with a pixel or superpixel. A CA is defined as a triplet = ( , , ) where St is the state set, denotes the neighborhood system, and is the transition function which defines the rule of updating the cell state based on the states of the neighborhood cells at previous step. The Moore neighborhood (8- neighbor) and von Neumann neighborhood (4-neighbor) are two commonly used neighborhood systems in CA. Each element in the state set St has three components: the cell label (lp), cell strength ( \u2208 [0, 1]), and feature vector (Vp). The states of all cells are initialized as (lp, , Vp) = (0, 0, Vp) where Vp can be initialized in different ways, e.g., the color vector or intensity of a pixel; when user specified seed cells, the strength values of the seed cells will be set to 1, and their labels will be set accordingly (e.g., 1 for foreground seed, and 0 for background seed). After the initialization, CA\n43 / 71\nwill update the states of all cells according to the evaluation rule: let ( , , ) be the state of cell p at time step t, and the state of the cell at time step t+1 is defined by\n, , = , , , ( , ) \u2219 >\n, , , \u210e (40)\nwhere cell q belongs to ( ), and ( , ) \u2208 [0, 1] is the transition function usually defined on the similarity between and .\nLiu et al. [135] constructed the transition function by integrating the global information on the\ntransition chain and local texture correlation. The CA-based segmentation approaches are widely used for interactive segmentation and could achieve good performance of BUS image segmentation. There are three main advantages of CA-based approaches: (1) support multiple objects segmentation; (2) can generate very precise object boundary and does not have the \u201cshrink\u201d problem; and (3) support user input on the fly. These approaches usually start with user interaction to initialize the labels of seed cells, and then update the states of all other cells according to the evolution rule until all cells reach the stable states or the fixed number of iterations is reached. The procedures are simple and easy to implement, but two important issues have to be considered. First, CA-based approaches need accurate user interactions, and different initializations may lead to quite different segmentation results. Second, because all cells are visited during each iteration, therefore, the computation cost is high; especially, when the image size is large. For a fast CA-based segmentation approach, refer [137]. Cell competition: Chen et al. [138] proposed a cell-competition approach for BUS image segmentation. The cells are small image regions generated by using a two-pass Watershed segmentation;\n44 / 71\nand then adjacent cells compete to generate new regions by splitting or merging. There are two types of competitions. In Type I competition, two adjacent cells from different regions compete with each other; a cell may split from a region and merge into another region. In Type II competition, one cell splits from a multi-cell region and forms a single-cell region.\nChen et al. [138] applied the cell competition approach to partition manually selected image\nROI into several regions, and to form the final tumor ROI by user interaction. Cheng et al. [139] applied the approach to an initial slice selected by user, and used the results to partition the cells of other slices into object or background regions. The two regions in each slice compete to find the tumor boundaries. Chiang et al. [140] extended the approach to segment 3D BUS image, and applied Graph cuts to image regions for finding the final tumor boundary. Cell competition approaches are designed to partition image into small regions, and no task-related knowledge is integrated in the competition mechanism. It is simple and fast, but needs large amount of user interactions to select ROI before the competition or to select tumor regions after the competition. Radial gradient index (RGI): RGI is utility function (Eq. (41)) which was proposed in [141] to segment mammograms. It calculates around the boundary of each candidate partition, and the partition with the largest RGI value is selected as the tumor region.\n(\u2133 ) = 1\n\u2211 |\u2207 ( )|\u2208\u2133 \u2207 ( ) \u2219 ( ) | ( )|\n\u2208\u2133\n(41)\nIn Eq. (42), \u2133 is a set of contour points of the ith image partition; |\u2207 ( )| is the absolute\nvalue of the intensity gradient at point p; and ( ) is the radial vector point from the partition center to point p. The RGI value measures the proportion of the intensity gradients of the boundary\n45 / 71\npoints along the radial direction. It takes values in [-1, 1]; RGI value 1 indicates that all the gradients point outward along the radial vector; and -1 signifies that all the gradients point inward along the radial vector. For actual BUS tumor regions, the RGI values are expected to close to 1.\nDrukker et al. [142] applied RGI to perform tumor detection. The RGI value is calculated on\na set of contours centered at each pixel, and the maximal RGI value of each pixel is used to replace pixel\u2019s intensity, which formed a RGI-filtered image; then thresholding was applied on the RGIfiltered image to determine a region of interest (ROI). In [142], the contour with max ARD value [25,26] was chosen as the final tumor contour. In [143, 144], a NN with five 5 hidden units was used to classify the candidate lesions into true positive and false positive; Kuo et al. [145, 146] applied RGI to find the initial tumor contour of 3D BUS image. The RGI calculation is simple and easy to implement; however, it calculates a group of RGI values for each pixel, and the computation cost is quite high; furthermore, it depends on image gradient, and cannot obtain accurate tumor boundary of BUS image due to low image quality."}, {"heading": "7. Fundamental Issues of BUS Image Segmentation", "text": "Extensive BUS segmentation approaches have been studied in the last two decades, and many of them achieved good performances utilizing their own datasets. In this section, we discuss the fundamental issues in BUS segmentation, and summarize the successful strategies employed in stateof-the-art approaches. 7.1 Denoising and Preserving Edge\n46 / 71\nIn ultrasound imaging, speckle noise is inherent to coherent illumination and Rayleigh scattering caused by tissue microstructures [147], and it is a major difficulty in BUS image segmentation. Many de-speckle approaches have been applied, e.g., mean filter, Gaussian low-pass filter, speckle reducing anisotropic diffusion (SRAD) [148], nonlinear coherence diffusion (NCD) [149], sticks filter [60], bilateral filter [150, 151], fractional subpixel diffusion [157], etc.\nMean filter and Gaussian low-pass filter are simple and fast, and widely used in early BUS\nsegmentation approaches [22, 52, 61, 59, 62, 63, 109, 115, 112, 123, 133, 138]; SRAD, NCD, sticks filter, and fractional subpixel diffusion are specially designed to deal with speckle noise, and because of their excellent property in edge preservation, these approaches obtained popularity in BUS segmentation [34, 58, 65, 89, 95, 103, 105, 106, 113, 114, 124, 125, 158, 165, 166].\nThe mean filter and Gaussian low-pass filter have the side effect of blurring edges, and are\nonly suitable for the approaches insensitive to image edges or gradient. For the edge-based approaches, e.g., edge-based DMs, watershed, and edge detection approaches, denoising with edge preservation approaches are preferred to avoid the leakage of final segmentation."}, {"heading": "7.2 Human Intervention", "text": "Many semi-automatic approaches exist in literatures; user interactions like setting seeds, drawing initial boundary or ROI are required in these approaches. Radiologists\u2019 interaction could be useful in segmenting extremely difficult BUS cases which have very low image quality; however, these interactions make the approaches operator-dependent and the results unreproducible; furthermore, it is also impossible to apply the semi-automatic approaches to a large-scale BUS image dataset,\n47 / 71\nbecause of the great cost of human labor and time. The intensity and sensitivity of interaction are two important criteria for evaluating interactive segmentation approaches [152, 153]; because user interaction has large degree of arbitrariness and different interaction may lead to quite different results. However, no work has been done in BUS image segmentation to evaluate the approach\u2019s interaction sensitivity and intensity yet.\nFully automatic BUS image segmentation has many advantages in comparison with interactive\nsegmentation, such as fully operator-independent, objective, and suitable for large scale tasks; hence, we believe that fully automatic segmentation is the trends in the future for BUS CAD systems. Many fully automatic approaches [22, 25, 64, 98, 100, 106, 109, 115] have been proposed in the last few years.\nIn fully automatic BUS segmentation, the key step to make an approach completely automatic\nis the tumor detection, which outputs ROI, rough boundary, seeds, or candidate regions to localize tumors, and initializes the subsequent segmentation steps. Ikedo et al. [109] determined tumor ROI by using vertical and horizontal edges detected by using the Canny edge detector. Liu et al. [64, 98] detected tumor ROI by using a well-trained texture classifier (SVM) to classify image lattices (16\u00d716) into normal tissue and tumor. Zhang et al. [25] estimated the bounding box of tumor using a binary classifier trained by negative (normal tissues) and positive (tumor) patches. Jiang et al. [100] applied ensemble learning method (Adaboost) to generate a boosted classifier for locating candidate rectangular regions; then these regions were refined by a SVM to generate the final true regions. Shan et al. [106] formulated the texture, spatial location, and size of the candidate area to\n48 / 71\nrank the regions obtained from the iterative thresholding, and selected the center of the winning region as the seed. Xian et al. [22, 115] took advantage of the layer structure of BUS image, and proposed the adaptive reference position (RP) generation and multipath search algorithm to locate the tumor ROI quickly, which outperformed the tumor location approaches utilizing fixed and inflexible constraints. Shao et al. [154] detected tumor in BUS image by estimating tumor\u2019s saliency; the approach modeled both the radiologists\u2019 attention mechanism and the layer structure of BUS image.\n[62] and some early works [58-61] detected tumor automatically based on low-level image\nfeatures, e.g., intensity and gradient, which made these approaches quite fast; but they strongly depended on image enhancement. The approaches [54, 55, 113, 106] constructing empirical formulas to model domain priors provided effective means for tumor detection, but the fixed RP formulated in these approaches limited their robustness and flexibility. One direction to improve these approaches is to model more robust prior, e.g., adaptive RP [22]; the second direction is to improve the generality of the formulas by constructing them in a learning-based framework. Learning based fully automatic approaches [25, 64, 98, 100] are promising and drawing increasing popularity recently. There are two directions to improve these approaches: (1) incorporating both global and local features into the learning framework; and (2) learning deep representation of breast structure towards the better understanding of BUS image by using deep convolutional neural network.\n[22, 115, 154] obtain fully automatic BUS image segmentation modeling biological priors of\nBUS images or visual attention mechanism, which open new avenues for fully automatic BUS\n49 / 71\nimage segmentation; one possible improvement is to utilize the learning-based framework to learn the empirical parameter adaptively and automatically."}, {"heading": "7.3 Modeling Prior Knowledge", "text": "Many ordinary image segmentation frameworks have been applied to BUS image segmentation; however, just applying ordinary image segmentation approaches only can achieve poor performance; and successful BUS segmentation approaches should model domain-related priors appropriately. We summarize the major priors that have been modeled in BUS image segmentation as follows.\nIntensity distribution. It is widely used in BUS image segmentation, and the approaches can\nbe classified into following categories: (1) using empirical distribution to model the intensity distribution of tumor or normal tissues, e.g., Gaussian, Raleigh, exponential model, etc; (2) defining intensity distribution implicitly by using histograms and classifiers. In graph-based approaches [7, 9 - 11], Gaussian distribution of tumor intensity is usually applied to define the likelihood energy (data term). Liu et al. [67] model the probability density difference between the intensity distribution of tumor/background region and estimated Rayleigh distribution to improve the performance of GDM. In [22, 54, 55], no explicit distribution was predefined, and histogram was applied to describe the distribution of tumor region and normal tissues; In [25, 27, 28], supervised learning approaches are introduced to train the classifiers to output the probability of each image region to be tumor or background.\n50 / 71\nTexture and local region statistics. Texture and other local region features have more descrip-\ntive power than intensity, and have been studied in many works [9, 10, 64, 98] that they can distinguish tumor regions from normal tissues with high accuracy. In [9, 10], the texture distributions are utilized to build the likelihood energy of the graph model. Madabhushi et al. [54, 55] trained a texture histogram of tumor regions, and incorporated it with the trained intensity distribution to determine the candidate tumor regions. Liu et al. [64, 98] extracted statistic texture from local regions (16\u00d716 grid), and learned a SVM classifier that could localize tumors accurately.\nEdge or gradient. In edge-based DMs, [42, 50, 52, 56 - 59, 61 - 63], image gradient is applied\nto constructing the external force or speed function of the evolving curve; as discussed in section 3.3, because of the speckle noise and week boundary problems, the performance of most approaches depends on both denoising and edge preservation techniques; [73, 75] defined the stop function of GDM for edge detection results in the frequency domain rather than in the spatial domain, which makes the GDM insensitive to image contrast and work well on weak boundaries. Xian et al. [22, 115] proposed an edge detector in the frequency domain and incorporate it into a graph-based framework, which made the pairwise energy less sensitive to image contrast and brightness.\nLayer structure. The breast is composed of different layers of tissues, e.g., skin, premammary,\nmammary, retromammary, muscle layers. Due to the difference of their physical properties, different layers have different appearances in BUS images. The location and depth of these layers may\nhave great variation, that makes them difficult to detect; however, some works [22, 115, 154] have utilized the layer structure information to segment breast tumors.\nTopological properties. Human vision system is very sensitive to the topological properties of\nobjects, and some works have been investigated [115, 152, 153] for both natural and medical image processing tasks. In [152, 153], the Neutro-Connectedness (NC) is proposed to compute both the connectedness structure and map, which has solve the problems of high interaction intensity and interaction-dependence in interactive image segmentation successfully; and [115] utilized the NC to solve the weak boundary of BUS images.\nSmoothness. In graph-based models, it corresponds the smoothness term (pairwise energy),\nand the minimization of the energy makes the models produce a smooth boundary; however, it is important to notice that the smoothness term also makes the models have the tendency to shrink, and high weight of this term will cause the \u201cshrink problem\u201d that generates much shorter boundary than the real boundary.\n52 / 71"}, {"heading": "7.4 Validation: ground truth, metrics, and BUS image datasets", "text": "Most BUS image segmentation approaches discussed in this paper have been evaluated quantitatively, and two major approaches have been utilized. The first approach is to evaluate segmentation performance by using physical phantoms or simulation software, e.g., Field II [155, 156]. The advantage of this approach is that the ground truth is very accurate; but the physical phantoms cannot represent the real breast anatomy exactly, and the simulation software uses simple acquisition model and cannot represent the real BUS image acquisition process well. The second approach for validation is to compare the segmentation result with manually delineated boundary. The problem of this approach is that the manually delineated ground truth could be flawed because of human error; however, this problem could be solved by labeling the boundary multiple times by same person and/or multiple radiologists. Currently, evaluating BUS image segmentation approaches through the ground truth delineated by radiologists is widely acceptable.\nIn BUS Image segmentation, many quantitative metrics utilized. In Table 5, we list eight com-\nmonly used metrics; the first six are area metrics and the last two are boundary metrics. Notice that in some papers [127, 137, 23, 22, 115], the similarity index (SI) refers to Jaccard index (JI), but in paper [61], SI is defined as the Dice\u2019s coefficient (DSC); for clarity, we recommend to use the original names of the two metrics, JI and DSC, instead. FNR equals to 1 - TRP; therefore, it is not necessary to present both.\nCurrently, there is no public BUS image benchmark with a reasonable number of clinical cases;\nand the performance of most approaches are validated by only using private datasets; it is difficult\n53 / 71\nto compare different approaches objectively; therefore, there is a pressing need for establishing a BUS image benchmark. It will be valuable for comparing existing methods/algorithms by using a public dataset objectively, and for determining which approach achieves better performance and what segmentation strategies should pursue. We are building a BUS image benchmark for such purpose which can be accessed from the website http://cvprip.cs.usu.edu/busbench."}, {"heading": "8. Conclusions and Future Directions", "text": "In this paper, we reviewed the automatic BUS image segmentation approaches. First, we clas-\nsified all the approaches into four major categories based on the fundamental technical principles. Second, in sections 2 \u2013 5, we presented the theoretical principles of each method, discussed their advantages and disadvantages, and summarized the strategies for BUS image segmentation. Third, in section 6, approaches of other three small sub-categories are briefly discussed. Fourth, in section 7, we discussed four fundamental open issues in BUS image segmentation and summarized the future research directions.\nUnconstrainted BUS image segmentation techniques: currently, most BUS image segmen-\ntation approaches work well on BUS images collected in controlled settings such as high image contrast, less artifacts, containing only one tumor per image, etc. However, their performance degrades greatly with BUS images having large variations in image quality, degree and location of artifacts, and number of tumors per image. Therefore, to promote the application of BUS CAD systems in clinical practice, it is crucial to develop unconstrainted BUS segmentation techniques\n54 / 71\nwhich are invariant to image settings. One potential direction is to learn invariant and discriminative representations of tumors in BUS images.\nBenchmark: A publicly accessible BUS image benchmark can be valuable to compare exist-\ning approaches, to discover useful strategies that can contribute to better segmentation performance, to help researchers to develop better approaches, and to eventually promote the development and advance of breast cancer research. Building of a publicly accessible BUS image dataset requires incredible effort (many years of hard work, and large amount of resources); however, its impact will be significant and profound. (introduce our work)\nDeep learning: in the last several years, deep learning has demonstrated impressive perfor-\nmance for many tasks such as object recognition [158], image classification [159], semantic segmentation [160], medical applications [161], facial expression recognition [163], speech recognition [164], etc. Deep learning models have large potential to achieve good performance for BUS image segmentation because of their ability to characterize large image variations and to learn compact image representation using sufficiently large BUS image dataset.\nHigh performance segmentation: performance is evaluated by memory cost, speed, and ac-\ncuracy. Currently, many BUS image segmentation approaches are computation and memory intensive, which limits their widespread applications. For example, it is difficult to integrate resourceintensive algorithms into portable BUS devices for real time applications. In some resource-limited regions or countries, many lives lost because of unavailability of accurate and low-cost breast cancer detection techniques and devices; high performance approaches consume much less resources\n55 / 71\nthan traditional resource-intensive approaches, and is vital important to provide an affordable means for breast cancer early detection."}], "references": [{"title": "Cancer statistics", "author": ["R.L. Siegel", "K.D. Miller", "A. Jemal"], "venue": "2015, CA-Cancer J. Clin. 65 ", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2015}, {"title": "Breast cancer in China", "author": ["L. Fan", "K. Strasser-Weippl", "J.-J. Li", "J. St Louis", "D.M. Finkelstein", "K.-D. Yu", "W.-Q. Chen", "Z.-M. Shao", "P.E. Goss"], "venue": "Lancet Oncol. 15 ", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2014}, {"title": "Computerized detection and classification of cancer on breast ultrasound", "author": ["K. Drukker", "M.L. Giger", "C.J. Vyborny", "E.B. Mendelson"], "venue": "Acad. Radiol. 11 ", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2004}, {"title": "Automated breast cancer detection and classification using ultrasound images: a survey", "author": ["H.D. Cheng", "J. Shan", "W. Ju", "Y.H. Guo", "L. Zhang"], "venue": "Pattern Recognt. 43 ", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2010}, {"title": "Pattern recognition and machine learning", "author": ["C.M. Bishop"], "venue": "Springer, New York, NY", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2006}, {"title": "Markov field on finite graphs and lattices", "author": ["J.M. Hammersley", "P. Clifford"], "venue": "", "citeRegEx": "6", "shortCiteRegEx": null, "year": 1971}, {"title": "Multiple resolution Bayesian segmentation of ultrasound images", "author": ["E.A. Ashton", "K.J. Parker"], "venue": "Ultrason. Imaging 17 ", "citeRegEx": "7", "shortCiteRegEx": null, "year": 1995}, {"title": "An adaptive clustering algorithm for image segmentation", "author": ["T.N. Pappas"], "venue": "IEEE Trans. Signal Process. 40 ", "citeRegEx": "8", "shortCiteRegEx": null, "year": 1992}, {"title": "Multiresolution texture based adaptive clustering algorithm for breast lesion segmentation", "author": ["D. Boukerroui", "O. Basset", "N. Guerin", "A. Baskurt"], "venue": "EJU 8 ", "citeRegEx": "9", "shortCiteRegEx": null, "year": 1998}, {"title": "Segmentation of ultrasound images-multiresolution 2D and 3D algorithm based on global and local statistics", "author": ["D. Boukerroui", "A. Baskurt", "J.A. Noble", "O. Basset"], "venue": "Pattern Recognit. Lett. 24 ", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2003}, {"title": "Segmentation of ultrasound B-mode images with intensity inhomogeneity correction", "author": ["G. Xiao", "M. Brady", "J.A. Noble", "Y. Zhang"], "venue": "IEEE TMI 21 ", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2002}, {"title": "Simultaneous lesion segmentation and bias correction in breast ultrasound images", "author": ["G. Pons", "J. Mart\u00ed", "R. Mart\u00ed", "J.A. Noble"], "venue": "in: Pattern Recognition and Image Analysis, Springer", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2011}, {"title": "Breast-lesion segmentation combining B-mode and elastography ultrasound", "author": ["G. Pons", "J. Mart\u00ed", "R. Mart\u00ed", "S. Ganau", "J.A. Noble"], "venue": "Ultrason. Imaging 38 ", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2016}, {"title": "Stochastic relaxation", "author": ["S. Geman", "D. Geman"], "venue": "Gibbs distributions, and the Bayesian restoration of images, IEEE TPAMI ", "citeRegEx": "14", "shortCiteRegEx": null, "year": 1984}, {"title": "On the statistical analysis of dirty pictures", "author": ["J. Besag"], "venue": "J. R. Stat. Soc. Series B ", "citeRegEx": "15", "shortCiteRegEx": null, "year": 1986}, {"title": "Exact maximum a posteriori estimation for binary images", "author": ["D.M. Greig", "B.T. Porteous", "A.H. Seheult"], "venue": "J. R. Stat. Soc. Series B (Methodol.) ", "citeRegEx": "16", "shortCiteRegEx": null, "year": 1989}, {"title": "A maximum-flow formulation of the n-camera stereo correspondence problem", "author": ["S. Roy", "I.J. Cox"], "venue": "in: IEEE ICCV, Bombay, India", "citeRegEx": "17", "shortCiteRegEx": null, "year": 1998}, {"title": "Fast approximate energy minimization via graph cuts", "author": ["Y. Boykov", "O. Veksler", "R. Zabih"], "venue": "IEEE TPAMI 23 ", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2001}, {"title": "Maximal flow through a network", "author": ["L.R. Ford", "D.R. Fulkerson"], "venue": "Can. J. Math. 8 ", "citeRegEx": "19", "shortCiteRegEx": null, "year": 1956}, {"title": "What energy functions can be minimized via graph cuts", "author": ["V. Kolmogorov", "R. Zabin"], "venue": "IEEE TPAMI 26 ", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2004}, {"title": "An experimental comparison of min-cut/max-flow algorithms for energy minimization in vision", "author": ["Y. Boykov", "V. Kolmogorov"], "venue": "IEEE TPAMI. 26 ", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2004}, {"title": "Fully automatic segmentation of breast ultrasound images based on breast characteristics in space and frequency domains", "author": ["M. Xian", "Y. Zhang", "H.D. Cheng"], "venue": "Pattern Recognit., 48 ", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2015}, {"title": "Multiple-domain knowledge based MRF model for tumor segmentation in breast ultrasound images", "author": ["M. Xian", "J. Huang", "Y. Zhang", "X. Tang"], "venue": "in: IEEE ICIP", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2012}, {"title": "Cell-based graph cut for segmentation of 2D/3D sonographic breast images", "author": ["H.-H. Chiang", "J.-Z. Cheng", "P.-K. Hung", "C.-Y. Liu", "C.-H. Chung", "C.-M. Chen"], "venue": "in: IEEE ISBI", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2010}, {"title": "Database-guided breast tumor detection and segmentation in 2d ultrasound images", "author": ["J. Zhang", "S.K. Zhou", "S. Brunke", "C. Lowery", "D. Comaniciu"], "venue": "in: SPIE MI", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2010}, {"title": "Probabilistic boosting-tree: Learning discriminative models for classification", "author": ["Z. Tu"], "venue": "recognition, and clustering, in: IEEE ICCV", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2005}, {"title": "Multiscale superpixel classification for tumor segmentation in breast ultrasound images", "author": ["Z. Hao", "Q. Wang", "H. Ren", "K. Xu", "Y.K. Seong", "J. Kim"], "venue": "in: IEEE ICIP", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2012}, {"title": "Learning a structured graphical model with boosted top-down features for ultrasound image segmentation", "author": ["Z. Hao", "Q. Wang", "X. Wang", "J.B. Kim", "Y. Hwang", "B.H. Cho", "P. Guo", "W.K. Lee"], "venue": "in: MICCAI", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2013}, {"title": "Object detection with discriminatively trained part-based models", "author": ["P.F. Felzenszwalb", "R.B. Girshick", "D. McAllester", "D. Ramanan"], "venue": "IEEE TPAMI 32 ", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2010}, {"title": "Support vector machine learning for interdependent and structured output spaces", "author": ["I. Tsochantaridis", "T. Hofmann", "T. Joachims", "Y. Altun"], "venue": "in: ACM ICML, Menlo Park, CA", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2004}, {"title": "Normalized cuts and image segmentation", "author": ["J. Shi", "J. Malik"], "venue": "IEEE TPAMI 22 ", "citeRegEx": "31", "shortCiteRegEx": null, "year": 2000}, {"title": "Segmentation of ultrasonic breast tumors based on homogeneous patch", "author": ["L. Gao", "W. Yang", "Z. Liao", "X. Liu", "Q. Feng", "W. Chen"], "venue": "Med. Phys. 39 ", "citeRegEx": "32", "shortCiteRegEx": null, "year": 2012}, {"title": "Texture-oriented anisotropic filtering and geodesic active contours in breast tumor ultrasound segmentation", "author": ["M. Alem\u00e1n-Flores", "L. \u00c1lvarez", "V. Caselles"], "venue": "J. Math. Imaging Vis. 28 ", "citeRegEx": "33", "shortCiteRegEx": null, "year": 2007}, {"title": "Automated segmentation of breast lesions in ultrasound images", "author": ["X. Liu", "Z. Huo", "J. Zhang"], "venue": "in: IEEE EMBS", "citeRegEx": "34", "shortCiteRegEx": null, "year": 2005}, {"title": "A comparative study of energy minimization methods for markov random fields", "author": ["R. Szeliski", "R. Zabih", "D. Scharstein", "O. Veksler", "V. Kolmogorov", "A. Agarwala", "M. Tappen", "C. Rother"], "venue": "in: IEEE ECCV", "citeRegEx": "35", "shortCiteRegEx": null, "year": 2006}, {"title": "Efficient inference in fully connected crfs with gaussian edge potentials", "author": ["V. Koltun"], "venue": "Adv. Neural Inf. Process. Syst. 2 ", "citeRegEx": "36", "shortCiteRegEx": null, "year": 2011}, {"title": "On matching deformable models to images", "author": ["D. Terzopoulos"], "venue": "in: Topical Meeting on Machine Vision Tech. Digest Series", "citeRegEx": "37", "shortCiteRegEx": null, "year": 1987}, {"title": "Snakes: Active contour models", "author": ["M. Kass", "A. Witkin", "D. Terzopoulos"], "venue": "IJCV 1 ", "citeRegEx": "38", "shortCiteRegEx": null, "year": 1988}, {"title": "On active contour models and balloons", "author": ["L.D. Cohen"], "venue": "CVGIP: Image Underst. 53 ", "citeRegEx": "39", "shortCiteRegEx": null, "year": 1991}, {"title": "A geometric model for active contours in image processing", "author": ["V. Caselles", "F. Catt\u00e9", "T. Coll", "F. Dibos"], "venue": "Numer. Math. 66 ", "citeRegEx": "40", "shortCiteRegEx": null, "year": 1993}, {"title": "Shape modeling with front propagation: A level set approach", "author": ["R. Malladi", "J.A. Sethian", "B.C. Vemuri"], "venue": "IEEE TPAMl 17 ", "citeRegEx": "41", "shortCiteRegEx": null, "year": 1995}, {"title": "A geometric snake model for segmentation of medical imagery", "author": ["A. Yezzi Jr", "S. Kichenassamy", "A. Kumar", "P. Olver", "A. Tannenbaum"], "venue": "IEEE TMI 16 ", "citeRegEx": "42", "shortCiteRegEx": null, "year": 1997}, {"title": "Conformal curvature flows: from phase transitions to active vision", "author": ["S. Kichenassamy", "A. Kumar", "P. Olver", "A. Tannenbaum", "A. Yezzi Jr"], "venue": "Arch. Ration. Mech. Anal. 134 ", "citeRegEx": "43", "shortCiteRegEx": null, "year": 1996}, {"title": "Geodesic active contours", "author": ["V. Caselles", "R. Kimmel", "G. Sapiro"], "venue": "IJCV 22 ", "citeRegEx": "44", "shortCiteRegEx": null, "year": 1997}, {"title": "Level set methods and fast marching methods: evolving interfaces in computational geometry", "author": ["J.A. Sethian"], "venue": "fluid mechanics, computer vision, and materials science, Cambridge university press", "citeRegEx": "45", "shortCiteRegEx": null, "year": 1999}, {"title": "Level set methods and dynamic implicit surfaces", "author": ["S. Osher", "R. Fedkiw"], "venue": "Springer Science & Business Media", "citeRegEx": "46", "shortCiteRegEx": null, "year": 2006}, {"title": "Distance regularized level set evolution and its application to image segmentation", "author": ["C. Li", "C. Xu", "C. Gui", "M.D. Fox"], "venue": "IEEE TIP 19 ", "citeRegEx": "47", "shortCiteRegEx": null, "year": 2010}, {"title": "Level set evolution without re-initialization: a new variational formulation", "author": ["C. Li", "C. Xu", "C. Gui", "M.D. Fox"], "venue": "in: IEEE CVPR", "citeRegEx": "48", "shortCiteRegEx": null, "year": 2005}, {"title": "Minimization of region-scalable fitting energy for image segmentation", "author": ["C. Li", "C.-Y. Kao", "J.C. Gore", "Z. Ding"], "venue": "IEEE TIP 17 ", "citeRegEx": "49", "shortCiteRegEx": null, "year": 2008}, {"title": "Adaptive expanding B-snake model for extracting ultrasound breast lump boundary", "author": ["Y. Chen", "K.C. Keong", "S.-B. Wee", "Q. Zou"], "venue": "in: IEEE ANZIIS", "citeRegEx": "50", "shortCiteRegEx": null, "year": 2001}, {"title": "Active contour models: Overview", "author": ["S. Menet", "P. Saint-Marc", "G. Medioni"], "venue": "implementation and applications, in: IEEE SMC", "citeRegEx": "51", "shortCiteRegEx": null, "year": 1990}, {"title": "Cell-based dual snake model: a new approach to extracting highly winding boundaries in the ultrasound images", "author": ["C.-M. Chen", "H.H.-S. Lu", "Y.-S. Huang"], "venue": "Ultrasound Med. Biol. 28 ", "citeRegEx": "52", "shortCiteRegEx": null, "year": 2002}, {"title": "A robust snake implementation: a dual active contour", "author": ["S.R. Gunn", "M.S. Nixon"], "venue": "IEEE TPAMI 19 ", "citeRegEx": "53", "shortCiteRegEx": null, "year": 1997}, {"title": "Automatic boundary extraction of ultrasonic breast lesions", "author": ["A. Madabhushi", "D. Metaxas"], "venue": "in: IEEE ISBI", "citeRegEx": "54", "shortCiteRegEx": null, "year": 2002}, {"title": "Combining low", "author": ["A. Madabhushi", "D.N. Metaxas"], "venue": "high-level and empirical domain knowledge for automated segmentation of ultrasonic breast lesions, IEEE TMI 22 ", "citeRegEx": "55", "shortCiteRegEx": null, "year": 2003}, {"title": "Three-dimensional active contour model for characterization of solid breast masses on threedimensional ultrasound images", "author": ["B. Sahiner", "A. Ramachandran", "H.-P. Chan", "M.A. Roubidoux", "L.M. Hadjiiski", "M.A. Helvie", "N. Petrick", "C. Zhou"], "venue": "in: SPIE MI", "citeRegEx": "56", "shortCiteRegEx": null, "year": 2003}, {"title": "Computerized characterization of breast masses on threedimensional ultrasound volumes", "author": ["B. Sahiner", "H.-P. Chan", "M.A. Roubidoux", "M.A. Helvie", "L.M. Hadjiiski", "A. Ramachandran", "C. Paramagul", "G.L. LeCarpentier", "A. Nees", "C. Blane"], "venue": "Med. Phys. 31 ", "citeRegEx": "57", "shortCiteRegEx": null, "year": 2004}, {"title": "Segmentation of breast tumor in three-dimensional ultrasound images using three-dimensional discrete active contour model", "author": ["R.-F. Chang", "W.-J. Wu", "W.K. Moon", "W.-M. Chen", "W. Lee", "D.-R. Chen"], "venue": "Ultrasound Med. Biol. 29 ", "citeRegEx": "58", "shortCiteRegEx": null, "year": 2003}, {"title": "3-D breast ultrasound segmentation using active contour model", "author": ["D.-R. Chen", "R.-F. Chang", "W.-J. Wu", "W.K. Moon", "W.-L. Wu"], "venue": "Ultrasound Med. Biol. 29 ", "citeRegEx": "59", "shortCiteRegEx": null, "year": 2003}, {"title": "Detection of lines and boundaries in speckle imagesapplication to medical ultrasound", "author": ["R.N. Czerwinski", "D.L. Jones", "W.D. O'Brien Jr"], "venue": "IEEE TMI, 18 ", "citeRegEx": "60", "shortCiteRegEx": null, "year": 1999}, {"title": "Automatic contouring for breast tumors in 2-D sonography", "author": ["Y.-L. Huang", "D.-R. Chen"], "venue": "in: IEEE EMBS", "citeRegEx": "61", "shortCiteRegEx": null, "year": 2006}, {"title": "Fully automatic lesion boundary detection in ultrasound breast images", "author": ["M. Yap", "E.A. Edirisinghe", "H.E. Bez"], "venue": "in: SPIE MI", "citeRegEx": "62", "shortCiteRegEx": null, "year": 2007}, {"title": "A fast level set method for segmentation of low contrast noisy biomedical images", "author": ["J. Deng", "H.T. Tsui"], "venue": "Pattern Recogn Lett, 23 ", "citeRegEx": "63", "shortCiteRegEx": null, "year": 2002}, {"title": "Automated Segmentation of Ultrasonic Breast Lesions Using Statistical Texture Classification and Active Contour Based on Probability Distance", "author": ["B. Liu", "H.D. Cheng", "J.H. Huang", "J.W. Tian", "J.F. Liu", "X.L. Tang"], "venue": "Ultrasound Med. Biol., 35 ", "citeRegEx": "64", "shortCiteRegEx": null, "year": 2009}, {"title": "Active Contours without Edges Applied to Breast Lesions on Ultrasound", "author": ["W. G\u00f3mez", "A. Infantosi", "L. Leija", "W. Pereira"], "venue": "in: Springer MEDICON", "citeRegEx": "65", "shortCiteRegEx": null, "year": 2010}, {"title": "Active contours without edges", "author": ["T.F. Chan", "L.A. Vese"], "venue": "IEEE TIP 10 ", "citeRegEx": "66", "shortCiteRegEx": null, "year": 2001}, {"title": "Probability density difference-based active contour for ultrasound image segmentation", "author": ["B. Liu", "H. Cheng", "J. Huang", "J. Tian", "X. Tang", "J. Liu"], "venue": "Pattern Recogn. 43 ", "citeRegEx": "67", "shortCiteRegEx": null, "year": 2010}, {"title": "Geodesic active contours and level sets for the detection and tracking of moving objects", "author": ["N. Paragios", "R. Deriche"], "venue": "IEEE TPAMI 22 (3) ", "citeRegEx": "68", "shortCiteRegEx": null, "year": 2000}, {"title": "Continuous force field analysis for generalized gradient vector flow field", "author": ["A. Rodtook", "S.S. Makhanov"], "venue": "Pattern Recogn. 43 ", "citeRegEx": "69", "shortCiteRegEx": null, "year": 2010}, {"title": "Generalized gradient vector flow external forces for active contours", "author": ["C. Xu", "J.L. Prince"], "venue": "Signal Process. 71 ", "citeRegEx": "70", "shortCiteRegEx": null, "year": 1998}, {"title": "Accurate Segmentation of Breast Tumors in Ultrasound Images Using a Custom-Made Active Contour Model and Signal-to-Noise Ratio Variations", "author": ["M.I. Daoud", "M.M. Baba", "F. Awwad", "M. Al-Najjar", "E.S. Tarawneh"], "venue": "in: IEEE SITIS", "citeRegEx": "71", "shortCiteRegEx": null, "year": 2012}, {"title": "A discrete dynamic contour model", "author": ["S. Lobregt", "M.A. Viergever"], "venue": "IEEE TMI 14 ", "citeRegEx": "72", "shortCiteRegEx": null, "year": 1995}, {"title": "Phase-and gvf-based level set segmentation of ultrasonic breast tumors", "author": ["L. Gao", "X. Liu", "W. Chen"], "venue": "J Appl. Math. 2012 ", "citeRegEx": "73", "shortCiteRegEx": null, "year": 2012}, {"title": "Phase congruency: A low-level image invariant", "author": ["P. Kovesi"], "venue": "Psychological Research Psychologische Forschung, 64 ", "citeRegEx": "74", "shortCiteRegEx": null, "year": 2000}, {"title": "A phase-based active contour model for segmentation of breast ultrasound images", "author": ["L. Cai", "Y. Wang"], "venue": "in: IEEE BMEI", "citeRegEx": "75", "shortCiteRegEx": null, "year": 2013}, {"title": "Ultrasound lesion segmentation using clinical knowledge-driven constrained level set", "author": ["Q. Lin", "S. Liu", "S.S. Parajuly", "Y. Deng", "L. Boroczky", "S. Fu", "Y. Wu", "Y. Pen"], "venue": "in: IEEE EMBC", "citeRegEx": "76", "shortCiteRegEx": null, "year": 2013}, {"title": "Localizing region-based active contours", "author": ["S. Lankton", "A. Tannenbaum"], "venue": "IEEE TIP 17 ", "citeRegEx": "77", "shortCiteRegEx": null, "year": 2008}, {"title": "A robust region-based active contour model with point classification for ultrasound breast lesion segmentation", "author": ["Z. Liu", "L. Zhang", "H. Ren", "J.-Y. Kim"], "venue": "in: SPIE MI", "citeRegEx": "78", "shortCiteRegEx": null, "year": 2013}, {"title": "Ultrasound breast lesion segmentation using adaptive parameters", "author": ["B.H. Cho", "Y.K. Seong", "J. Kim", "Z. Liu", "Z. Hao", "E.Y. Ko", "K.-G. Woo"], "venue": "in: SPIE MI", "citeRegEx": "79", "shortCiteRegEx": null, "year": 2014}, {"title": "Active contour driven by local divergence energies for ultrasound image segmentation", "author": ["J. Yuan"], "venue": "IET Image Processing, 7 ", "citeRegEx": "80", "shortCiteRegEx": null, "year": 2013}, {"title": "Segmentation of breast masses on dedicated breast computed tomography and three-dimensional breast ultrasound images", "author": ["H.-C. Kuo", "M.L. Giger", "I. Reiser", "K. Drukker", "J.M. Boone", "K.K. Lindfors", "K. Yang", "A. Edwards", "C.A. Sennett"], "venue": "JMI 1 ", "citeRegEx": "81", "shortCiteRegEx": null, "year": 2014}, {"title": "Level set segmentation of breast masses in contrast-enhanced dedicated breast CT and evaluation of stopping criteria", "author": ["H.-C. Kuo", "M.L. Giger", "I. Reiser", "J.M. Boone", "K.K. Lindfors", "K. Yang", "A. Edwards"], "venue": "J. Digit. Imaging 27 ", "citeRegEx": "82", "shortCiteRegEx": null, "year": 2014}, {"title": "Automated seeded lesion segmentation on digital mammograms", "author": ["M. Kupinski", "M.L. Giger"], "venue": "IEEE TMI 17 ", "citeRegEx": "83", "shortCiteRegEx": null, "year": 1998}, {"title": "A dual-stage method for lesion segmentation on digital mammograms", "author": ["Y. Yuan", "M.L. Giger", "H. Li", "K. Suzuki", "C. Sennett"], "venue": "Med. Phys. 34 ", "citeRegEx": "84", "shortCiteRegEx": null, "year": 2007}, {"title": "A fuzzy relative of the ISODATA process and its use in detecting compact well-separated clusters", "author": ["J.C. Dunn"], "venue": "Journal of Cybernetics 3 ", "citeRegEx": "85", "shortCiteRegEx": null, "year": 1973}, {"title": "Pattern recognition with fuzzy objective function algorithms", "author": ["C.B. James"], "venue": "Kluwer Academic Publishers, Norwell, MA, USA", "citeRegEx": "86", "shortCiteRegEx": null, "year": 1981}, {"title": "A modified spatial fuzzy clustering method based on texture analysis for ultrasound image segmentation", "author": ["Y. Xu"], "venue": "in: IEEE ISIE", "citeRegEx": "87", "shortCiteRegEx": null, "year": 2009}, {"title": "Fuzzy c-means clustering with spatial information for image segmentation", "author": ["K.-S. Chuang", "H.-L. Tzeng", "S. Chen", "J. Wu", "T.-J. Chen"], "venue": "Comput. Med. Imag. Grap. 30 ", "citeRegEx": "88", "shortCiteRegEx": null, "year": 2006}, {"title": "Computer-aided multiview tumor detection for automated whole breast ultrasound", "author": ["C. Lo", "Y.-W. Shen", "C.-S. Huang", "R.-F. Chang"], "venue": "Ultrason. Imaging 36 ", "citeRegEx": "89", "shortCiteRegEx": null, "year": 2014}, {"title": "and S", "author": ["D.W. Hosmer Jr"], "venue": "Lemeshow, Applied logistic regression: John Wiley & Sons", "citeRegEx": "90", "shortCiteRegEx": null, "year": 2004}, {"title": "Mean Shift", "author": ["Y.Z. Cheng"], "venue": "Mode Seeking, and Clustering, IEEE TPAMI 17 ", "citeRegEx": "92", "shortCiteRegEx": null, "year": 1995}, {"title": "A fully automatic segmentation method for breast ultrasound images", "author": ["J. Shan"], "venue": "Dissertation, Utah State University", "citeRegEx": "94", "shortCiteRegEx": null, "year": 2011}, {"title": "A novel segmentation method for breast ultrasound images based on neutrosophic l-means clustering", "author": ["J. Shan", "H. Cheng", "Y. Wang"], "venue": "Med. Phys. 39 ", "citeRegEx": "95", "shortCiteRegEx": null, "year": 2012}, {"title": "A training algorithm for optimal margin classifiers", "author": ["B.E. Boser", "I.M. Guyon", "V.N. Vapnik"], "venue": "in: ACM Computational learning theory", "citeRegEx": "96", "shortCiteRegEx": null, "year": 1992}, {"title": "Support-vector networks", "author": ["C. Cortes", "V. Vapnik"], "venue": "Machine Learning 20 ", "citeRegEx": "97", "shortCiteRegEx": null, "year": 1995}, {"title": "Fully automatic and segmentationrobust classification of breast tumors based on local texture analysis of ultrasound images", "author": ["B. Liu", "H.D. Cheng", "J.H. Huang", "J.W. Tian", "X.L. Tang", "J.F. Liu"], "venue": "Pattern Recognit. 43 ", "citeRegEx": "98", "shortCiteRegEx": null, "year": 2010}, {"title": "Statistical Learning Theory", "author": ["V. Vapnik"], "venue": "Wiley-Interscience, New York", "citeRegEx": "99", "shortCiteRegEx": null, "year": 1998}, {"title": "Learning-based automatic breast tumor detection and segmentation in ultrasound images", "author": ["P. Jiang", "J. Peng", "G. Zhang", "E. Cheng", "V. Megalooikonomou", "H. Ling"], "venue": "in: IEEE ISBI", "citeRegEx": "100", "shortCiteRegEx": null, "year": 2012}, {"title": "A decision-theoretic generalization of on-line learning and an application to boosting", "author": ["Y. Freund", "R.E. Schapire"], "venue": "J. Comput. Syst. Sci. 55 ", "citeRegEx": "101", "shortCiteRegEx": null, "year": 1997}, {"title": "Robust real-time face detection", "author": ["P. Viola", "M.J. Jones"], "venue": "IJCV, 57 ", "citeRegEx": "102", "shortCiteRegEx": null, "year": 2004}, {"title": "Neural network analysis applied to tumor segmentation on 3D breast ultrasound images", "author": ["S.-F. Huang", "Y.-C. Chen", "W.K. Moon"], "venue": "in: IEEE ISBI", "citeRegEx": "103", "shortCiteRegEx": null, "year": 2008}, {"title": "Segmentation of Breast Ultrasound Images Using Neural Networks", "author": ["A.A. Othman", "H.R. Tizhoosh"], "venue": "in: Springer EANN", "citeRegEx": "104", "shortCiteRegEx": null, "year": 2011}, {"title": "Completely automatic segmentation for breast ultrasound using multiple-domain features", "author": ["J. Shan", "Y. Wang", "H.-D. Cheng"], "venue": "in: IEEE ICIP", "citeRegEx": "105", "shortCiteRegEx": null, "year": 2010}, {"title": "Completely Automated Segmentation Approach for Breast Ultrasound Images Using Multiple-Domain Features", "author": ["J. Shan", "H.D. Cheng", "Y.X. Wang"], "venue": "Ultrasound Med. Biol. 38 ", "citeRegEx": "106", "shortCiteRegEx": null, "year": 2012}, {"title": "Whole breast lesion detection using naive Bayes classifier for portable ultrasound", "author": ["M.-C. Yang", "C.-S. Huang", "J.-H. Chen", "R.-F. Chang"], "venue": "Ultrasound Med. Biol. 38 ", "citeRegEx": "107", "shortCiteRegEx": null, "year": 2012}, {"title": "An easy measure of compactness for 2D and 3D shapes", "author": ["E. Bribiesca"], "venue": "Pattern Recogn. 41 ", "citeRegEx": "108", "shortCiteRegEx": null, "year": 2008}, {"title": "Development of a fully automatic scheme for detection of masses in whole breast ultrasound images", "author": ["Y. Ikedo", "D. Fukuoka", "T. Hara", "H. Fujita", "E. Takada", "T. Endo", "T. Morita"], "venue": "Med. Phys. 34 ", "citeRegEx": "109", "shortCiteRegEx": null, "year": 2007}, {"title": "Fully automatic lesion boundary detection in ultrasound breast images", "author": ["M. Yap", "E.A. Edirisinghe", "H.E. Bez"], "venue": "in: SPIE MI", "citeRegEx": "110", "shortCiteRegEx": null, "year": 2007}, {"title": "A novel algorithm for initial lesion detection in ultrasound breast images", "author": ["M.H. Yap"], "venue": "J. Appl. Clin. Med. Phys 9 ", "citeRegEx": "111", "shortCiteRegEx": null, "year": 2008}, {"title": "Computer-aided diagnosis of solid breast nodules: use of an artificial neural network based on multiple sonographic features", "author": ["S. Joo", "Y.S. Yang", "W.K. Moon", "H.C. Kim"], "venue": "IEEE TMI 23 ", "citeRegEx": "112", "shortCiteRegEx": null, "year": 2004}, {"title": "A novel automatic seed point selection algorithm for breast ultrasound images", "author": ["J. Shan", "H.D. Cheng", "Y.X. Wang"], "venue": "in: ICPR", "citeRegEx": "113", "shortCiteRegEx": null, "year": 2008}, {"title": "Automatic ultrasound segmentation and morphology based diagnosis of solid breast tumors", "author": ["R.-F. Chang", "W.-J. Wu", "W.K. Moon", "D.-R. Chen"], "venue": "Breast cancer research and treatment, 89 ", "citeRegEx": "114", "shortCiteRegEx": null, "year": 2005}, {"title": "A Fully Automatic Breast Ultrasound Image Segmentation Approach Based on Neutro-Connectedness", "author": ["M. Xian", "H.D. Cheng", "Y. Zhang"], "venue": "in: ICPR", "citeRegEx": "115", "shortCiteRegEx": null, "year": 2014}, {"title": "3D segmentation of breast tumor in ultrasound images", "author": ["J.I. Kwak", "M.N. Jung", "S.H. Kim", "N.C. Kim"], "venue": "in: SPIE, MI", "citeRegEx": "116", "shortCiteRegEx": null, "year": 2003}, {"title": "RD-based seeded region growing for extraction of breast tumor in an ultrasound volume", "author": ["J.I. Kwak", "S.H. Kim", "N.C. Kim"], "venue": "in: Computational Intelligence and Security, Springer", "citeRegEx": "117", "shortCiteRegEx": null, "year": 2005}, {"title": "Lesion segmentation in breast sonography", "author": ["J. Massich", "F. Meriaudeau", "E. P\u00e9rez", "R. Mart\u00ed", "A. Oliver", "J. Mart\u00ed"], "venue": "in: Digital Mammography, Springer", "citeRegEx": "118", "shortCiteRegEx": null, "year": 2010}, {"title": "Use of watersheds in contour detection", "author": ["S. Beucher", "C. Lantu\u00e9joul"], "venue": "in: International workshop on image processing: real-time edge and motion detection/estimation, Rennes, France", "citeRegEx": "119", "shortCiteRegEx": null, "year": 1979}, {"title": "Watershed cuts: Minimum spanning forests and the drop of water principle", "author": ["J. Cousty", "G. Bertrand", "L. Najman", "M. Couprie"], "venue": "IEEE TPAMI 31 ", "citeRegEx": "120", "shortCiteRegEx": null, "year": 2009}, {"title": "The morphological approach to segmentation: the watershed transformation", "author": ["S. Beucher", "F. Meyer"], "venue": "Optical Engineering-New York-Marcel Dekker Incorporated 34 ", "citeRegEx": "121", "shortCiteRegEx": null, "year": 1992}, {"title": "Watershed segmentation for breast tumor in 2-D sonography", "author": ["Y.-L. Huang", "D.-R. Chen"], "venue": "Ultrasound Med. Biol.,30 ", "citeRegEx": "122", "shortCiteRegEx": null, "year": 2004}, {"title": "Computer-aided detection system of breast masses on ultrasound images", "author": ["Y. Ikedo", "D. Fukuoka", "T. Hara", "H. Fujita", "E. Takada", "T. Endo", "T. Morita"], "venue": "in: SPIE MI", "citeRegEx": "123", "shortCiteRegEx": null, "year": 2006}, {"title": "Computerized lesion segmentation of breast ultrasound based on marker-controlled watershed transformation", "author": ["W. G\u00f3mez", "L. Leija", "A. Alvarenga", "A. Infantosi", "W. Pereira"], "venue": "Med. Phys. 37 ", "citeRegEx": "124", "shortCiteRegEx": null, "year": 2010}, {"title": "Segmentation of Breast Nodules on Ultrasonographic Images Based on Marke d-Controlled Watershed Transform", "author": ["W. G\u00f3mez", "L. Leija", "W.C.A. Pereira", "A.F.C. Infantosi"], "venue": "Computaci\u00f3n y Sistemas, 14 ", "citeRegEx": "125", "shortCiteRegEx": null, "year": 2010}, {"title": "Novel approaches to image segmentation based on neutrosophic logic", "author": ["M. Zhang"], "venue": "PhD thesis, Utah State University", "citeRegEx": "126", "shortCiteRegEx": null, "year": 2010}, {"title": "Segmentation of ultrasound breast images based on a neutrosophic method", "author": ["M. Zhang", "L. Zhang", "H.-D. Cheng"], "venue": "Opt. Eng. 49 ", "citeRegEx": "127", "shortCiteRegEx": null, "year": 2010}, {"title": "Multi-Dimensional Tumor Detection in Automated Whole Breast Ultrasound Using Topographic Watershed", "author": ["C.M. Lo", "R.T. Chen", "Y.C. Chang", "Y.W. Yang", "M.J. Hung", "C.S. Huang", "R.F. Chang"], "venue": "IEEE TMI 33 ", "citeRegEx": "128", "shortCiteRegEx": null, "year": 2014}, {"title": "and S", "author": ["D.W. Hosmer"], "venue": "Lemeshow, Applied logistic regression: Wiley-Interscience", "citeRegEx": "129", "shortCiteRegEx": null, "year": 2000}, {"title": "A threshold selection method from gray-level histograms", "author": ["N. Otsu"], "venue": "Automatica, 11 ", "citeRegEx": "130", "shortCiteRegEx": null, "year": 1975}, {"title": "Morphological gradients", "author": ["J.-F. Rivest", "P. Soille", "S. Beucher"], "venue": "in: SPIE/IS&T Symposium on Electronic Imaging: Science and Technology", "citeRegEx": "131", "shortCiteRegEx": null, "year": 1992}, {"title": "Automatic segmentation of breast lesions on ultrasound", "author": ["K. Horsch", "M.L. Giger", "L.A. Venta", "C.J. Vyborny"], "venue": "Med. Phys 28 ", "citeRegEx": "132", "shortCiteRegEx": null, "year": 2001}, {"title": "Computerized diagnosis of breast lesions on ultrasound", "author": ["K. Horsch", "M.L. Giger", "L.A. Venta", "C.J. Vyborny"], "venue": "Med. Phys 29 ", "citeRegEx": "133", "shortCiteRegEx": null, "year": 2002}, {"title": "GrowCut: Interactive multi-label ND image segmentation by cellular automata", "author": ["V. Vezhnevets", "V. Konouchine"], "venue": "in: proc. of Graphicon, Citeseer", "citeRegEx": "135", "shortCiteRegEx": null, "year": 2005}, {"title": "An effective approach of lesion segmentation within the breast ultrasound image based on the cellular automata principle", "author": ["Y. Liu", "H. Cheng", "J. Huang", "Y. Zhang", "X. Tang"], "venue": "JDI 25 ", "citeRegEx": "136", "shortCiteRegEx": null, "year": 2012}, {"title": "An effective interactive medical image segmentation method using fast growcut", "author": ["L. Zhu", "I. Kolesov", "Y. Gao", "R. Kikinis", "A. Tannenbaum"], "venue": "in: MICCAI Workshop on Interactive Medical Image Computing", "citeRegEx": "137", "shortCiteRegEx": null, "year": 2014}, {"title": "Cell-competition algorithm: A new segmentation algorithm for multiple objects with irregular boundaries in ultrasound images", "author": ["C.-M. Chen", "Y.-H. Chou", "C.S. Chen", "J.-Z. Cheng", "Y.-F. Ou", "F.-C. Yeh", "K.-W. Chen"], "venue": "Ultrasound Med. Biol.31 ", "citeRegEx": "138", "shortCiteRegEx": null, "year": 2005}, {"title": "Cell-based two-region competition algorithm with a map framework for boundary delineation of a series of 2D ultrasound images", "author": ["J.-Z. Cheng", "C.-M. Chen", "Y.-H. Chou", "C.S. Chen", "C.-M. Tiu", "K.-W. Chen"], "venue": "Ultrasound Med. Biol. 33 ", "citeRegEx": "139", "shortCiteRegEx": null, "year": 2007}, {"title": "Cell-based graph cut for segmentation of 2D/3D sonographic breast images", "author": ["H.-H. Chiang", "J.-Z. Cheng", "P.-K. Hung", "C.-Y. Liu", "C.-H. Chung", "C.-M. Chen"], "venue": "in: IEEE ISBI", "citeRegEx": "140", "shortCiteRegEx": null, "year": 2010}, {"title": "Automated seeded lesion segmentation on digital mammograms", "author": ["M. Kupinski", "M.L. Giger"], "venue": "IEEE TMI 17 ", "citeRegEx": "141", "shortCiteRegEx": null, "year": 1998}, {"title": "Computerized lesion detection on breast ultrasound", "author": ["K. Drukker", "M.L. Giger", "K. Horsch", "M.A. Kupinski", "C.J. Vyborny", "E.B. Mendelson"], "venue": "Med. Phys 29 ", "citeRegEx": "142", "shortCiteRegEx": null, "year": 2002}, {"title": "Computerized analysis of sonograms for the detection of breast lesions", "author": ["K. Drukker", "M.L. Giger", "K. Horsch", "C.J. Vyborny"], "venue": "in: SPIE MI", "citeRegEx": "143", "shortCiteRegEx": null, "year": 2002}, {"title": "Computerized detection and classification of lesions on breast ultrasound", "author": ["K. Drukker", "M.L. Giger", "C.J. Vyborny", "R.A. Schmidt", "E.B. Mendelson", "M. Stern"], "venue": "in: SPIE MI", "citeRegEx": "144", "shortCiteRegEx": null, "year": 2003}, {"title": "Automatic 3D lesion segmentation on breast ultrasound images", "author": ["H.-C. Kuo", "M.L. Giger", "I. Reiser", "K. Drukker", "A. Edwards", "C.A. Sennett"], "venue": "in: SPIE MI", "citeRegEx": "145", "shortCiteRegEx": null, "year": 2013}, {"title": "Finite-element methods for active contour models and balloons for 2-D and 3- D images", "author": ["L.D. Cohen", "I. Cohen"], "venue": "IEEE TPAMI 15 ", "citeRegEx": "146", "shortCiteRegEx": null, "year": 1993}, {"title": "Wall position and thickness estimation from sequences of echocardiographic images", "author": ["J.M. Dias", "J.M. Leitao"], "venue": "IEEE TMI 15 ", "citeRegEx": "147", "shortCiteRegEx": null, "year": 1996}, {"title": "Speckle reducing anisotropic diffusion", "author": ["Y. Yu", "S.T. Acton"], "venue": "IEEE TIP 11 ", "citeRegEx": "148", "shortCiteRegEx": null, "year": 2002}, {"title": "Real-time speckle reduction and coherence enhancement in ultrasound imaging via nonlinear anisotropic diffusion", "author": ["K.Z. Abd-Elmoniem", "A.-B. Youssef", "Y.M. Kadah"], "venue": "IEEE TBE 49 ", "citeRegEx": "149", "shortCiteRegEx": null, "year": 2002}, {"title": "Bilateral filtering for gray and color images", "author": ["C. Tomasi", "R. Manduchi"], "venue": "in: IEEE ICCV", "citeRegEx": "150", "shortCiteRegEx": null, "year": 1998}, {"title": "On the origin of the bilateral filter and ways to improve it", "author": ["M. Elad"], "venue": "IEEE TIP 11 ", "citeRegEx": "151", "shortCiteRegEx": null, "year": 2002}, {"title": "Neutro-connectedness cut", "author": ["M. Xian", "Y. Zhang", "H.-D. Cheng", "F. Xu", "J. Ding"], "venue": "IEEE TIP 25 ", "citeRegEx": "152", "shortCiteRegEx": null, "year": 2016}, {"title": "EISeg: Effective Interactive Segmentation, in: ICPR, 2016 (accepted)", "author": ["M. Xian", "F. Xu", "H.D. Cheng"], "venue": null, "citeRegEx": "153", "shortCiteRegEx": "153", "year": 2016}, {"title": "A saliency model for automated tumor detection in breast ultrasound images", "author": ["H. Shao", "Y. Zhang", "M. Xian", "H.D. Cheng", "F. Xu", "J. Ding"], "venue": "in: IEEE ICIP", "citeRegEx": "154", "shortCiteRegEx": null, "year": 2015}, {"title": "Field: A program for simulating ultrasound systems", "author": ["J.A. Jensen"], "venue": "in: Medical & Biological Engineering & Computing, Citeseer", "citeRegEx": "155", "shortCiteRegEx": null, "year": 1996}, {"title": "Calculation of pressure fields from arbitrarily shaped", "author": ["J.A. Jensen", "N.B. Svendsen"], "venue": "apodized, and excited ultrasound transducers, IEEE TUFFC 39 ", "citeRegEx": "156", "shortCiteRegEx": null, "year": 1992}, {"title": "Fractional subpixel diffusion and fuzzy logic approach for ultrasound speckle reduction", "author": ["Y. Zhang", "H.D. Cheng", "J. Tian", "J. Huang", "X. Tang"], "venue": "Pattern Recogn, 43 ", "citeRegEx": "157", "shortCiteRegEx": null, "year": 2010}, {"title": "Multi-column deep neural network for traffic sign classification", "author": ["D. Cire\u015fan", "U. Meier", "J. Masci", "J. Schmidhuber"], "venue": "Neural Networks, 32 ", "citeRegEx": "158", "shortCiteRegEx": null, "year": 2012}, {"title": "Multi-column deep neural networks for image classification", "author": ["D. Ciregan", "U. Meier", "J. Schmidhuber"], "venue": "in: IEEE CVPR", "citeRegEx": "159", "shortCiteRegEx": null, "year": 2012}, {"title": "Fully convolutional networks for semantic segmentation", "author": ["J. Long", "E. Shelhamer", "T. Darrell"], "venue": "in: IEEE CVPR", "citeRegEx": "160", "shortCiteRegEx": null, "year": 2015}, {"title": "Computer-Aided diagnosis with deep learning architecture: applications to breast lesions in us images and pulmonary nodules in CT scans", "author": ["J.-Z. Cheng", "D. Ni", "Y.-H. Chou", "J. Qin", "C.-M. Tiu", "Y.-C. Chang", "C.-S. Huang", "D. Shen", "C.-M. Chen"], "venue": "Scientific reports, 6 ", "citeRegEx": "161", "shortCiteRegEx": null, "year": 2016}, {"title": "Deep learning: methods and applications", "author": ["L. Deng", "D. Yu"], "venue": "Foundations and Trends in Signal Processing, 7 ", "citeRegEx": "162", "shortCiteRegEx": null, "year": 2014}, {"title": "Deep convolutional neural networks for smile recognition", "author": ["P.O. Glauner"], "venue": "arXiv preprint arXiv:1508.06535, ", "citeRegEx": "163", "shortCiteRegEx": null, "year": 2015}, {"title": "New types of deep neural network learning for speech recognition and related applications: An overview", "author": ["L. Deng", "G. Hinton", "B. Kingsbury"], "venue": "in: IEEE ICASSP", "citeRegEx": "164", "shortCiteRegEx": null, "year": 2013}, {"title": "A robust graph-based segmentation method for breast tumors in ultrasound images", "author": ["Q.-H. Huang", "S.-Y. Lee", "L.-Z. Liu", "M.-H. Lu", "L.-W. Jin", "A.-H. Li"], "venue": "Ultrasonics, 52 ", "citeRegEx": "165", "shortCiteRegEx": null, "year": 2012}, {"title": "Optimized graph-based segmentation for ultrasound images", "author": ["Q. Huang", "X. Bai", "Y. Li", "L. Jin", "X. Li"], "venue": "Neurocomputing, 129 ", "citeRegEx": "166", "shortCiteRegEx": null, "year": 2014}], "referenceMentions": [{"referenceID": 0, "context": "Introduction Breast cancer occurs in the highest frequency in women among all cancers, and is also one of the leading causes of cancer death worldwide [1, 2].", "startOffset": 151, "endOffset": 157}, {"referenceID": 1, "context": "Introduction Breast cancer occurs in the highest frequency in women among all cancers, and is also one of the leading causes of cancer death worldwide [1, 2].", "startOffset": 151, "endOffset": 157}, {"referenceID": 2, "context": "The key of reducing the mortality is to find signs and symptoms of breast cancer at its early stage by clinic examination [3].", "startOffset": 122, "endOffset": 125}, {"referenceID": 3, "context": "Breast ultrasound (BUS) imaging has become one of the most important and effective modality for the early detection of breast cancer because of its noninvasive, nonradioactive and cost-effective nature [4]; and it is most suitable for large scale breast cancer screening and diagnosis in low-resource countries and regions.", "startOffset": 202, "endOffset": 205}, {"referenceID": 4, "context": "Graph-based approaches Graph-based approaches gain increasing popularity in BUS image segmentation because they offer several advantages: (1) they provide a simple way to organize task-related priors and image information in a unified framework; (2) they are flexible and suitable for expressing soft constraints between random variables; and (3) the computation based on graphical manipulation is very efficient [5].", "startOffset": 413, "endOffset": 416}, {"referenceID": 5, "context": "The Hammersley-Clifford theorem [6] established the equivalence between MRF and Gibbs random field (GRF), and the MAP is equivalently found by minimizing the posterior energy function \u2217 = argmin ( | ) = argmin ( | ) + ( ) (3) where ( | ) = ( | ) + ( ), and ( | ) is the likelihood energy and ( ) is prior energy.", "startOffset": 32, "endOffset": 35}, {"referenceID": 6, "context": "Ashton and Parker [7] define the MRF prior energy as the Ising/Potts model ( ) = ( ) \u2208 + , \u2208 \u2208 (4) , = , if = \u2212 , otherwise (5) where is a positive constant.", "startOffset": 18, "endOffset": 21}, {"referenceID": 7, "context": "7 / 71 using a modified adaptive k-mean method [8] which estimates the class mean locally using a sliding window.", "startOffset": 47, "endOffset": 50}, {"referenceID": 8, "context": "[9] stated that healthy and pathological breast tissues present different textures of BUS images, and improved the method in [7] by modeling both intensity and texture distributions in the likelihood energy; they also assume that the texture features represented by using co-occurrence matrix follow the Gaussian distribution; and the parameters were estimated similarly to the method in [7].", "startOffset": 0, "endOffset": 3}, {"referenceID": 6, "context": "[9] stated that healthy and pathological breast tissues present different textures of BUS images, and improved the method in [7] by modeling both intensity and texture distributions in the likelihood energy; they also assume that the texture features represented by using co-occurrence matrix follow the Gaussian distribution; and the parameters were estimated similarly to the method in [7].", "startOffset": 125, "endOffset": 128}, {"referenceID": 6, "context": "[9] stated that healthy and pathological breast tissues present different textures of BUS images, and improved the method in [7] by modeling both intensity and texture distributions in the likelihood energy; they also assume that the texture features represented by using co-occurrence matrix follow the Gaussian distribution; and the parameters were estimated similarly to the method in [7].", "startOffset": 388, "endOffset": 391}, {"referenceID": 9, "context": "[10] modified the method in [9] by introducing a weighting function considering both global and local statistics.", "startOffset": 0, "endOffset": 4}, {"referenceID": 8, "context": "[10] modified the method in [9] by introducing a weighting function considering both global and local statistics.", "startOffset": 28, "endOffset": 31}, {"referenceID": 10, "context": "In [11], the proposed method followed the MRF-MAP framework, and formulated the BUS segmentation similar to [7], the only difference is that the Gaussian parameters are defined globally and specified manually.", "startOffset": 3, "endOffset": 7}, {"referenceID": 6, "context": "In [11], the proposed method followed the MRF-MAP framework, and formulated the BUS segmentation similar to [7], the only difference is that the Gaussian parameters are defined globally and specified manually.", "startOffset": 108, "endOffset": 111}, {"referenceID": 10, "context": "In order to improve the process of manual selection of Gaussian parameters in [11], reference [12] proposed a one-click user interaction to estimate Gaussian parameters automatically.", "startOffset": 78, "endOffset": 82}, {"referenceID": 11, "context": "In order to improve the process of manual selection of Gaussian parameters in [11], reference [12] proposed a one-click user interaction to estimate Gaussian parameters automatically.", "startOffset": 94, "endOffset": 98}, {"referenceID": 12, "context": "[13] introduced the tissue", "startOffset": 0, "endOffset": 4}, {"referenceID": 10, "context": "8 / 71 stiffness information of ultrasound elastography to the method in [11] by modifying the one-dimensional tumor and background Gaussian distributions as bivariate Gaussian distributions; however, it did not discuss how to determine the Gaussian parameters.", "startOffset": 73, "endOffset": 77}, {"referenceID": 13, "context": "The energy function of MRF-MAP can be optimized by using Simulated Annealing (SA) [14] and Iterated Conditional Mode (ICM) [15] algorithms.", "startOffset": 82, "endOffset": 86}, {"referenceID": 14, "context": "The energy function of MRF-MAP can be optimized by using Simulated Annealing (SA) [14] and Iterated Conditional Mode (ICM) [15] algorithms.", "startOffset": 123, "endOffset": 127}, {"referenceID": 6, "context": "Because ICM is much faster than SA, the ICM is preferred in most BUS image segmentation approaches [7, 9, 11 - 13].", "startOffset": 99, "endOffset": 114}, {"referenceID": 8, "context": "Because ICM is much faster than SA, the ICM is preferred in most BUS image segmentation approaches [7, 9, 11 - 13].", "startOffset": 99, "endOffset": 114}, {"referenceID": 10, "context": "Because ICM is much faster than SA, the ICM is preferred in most BUS image segmentation approaches [7, 9, 11 - 13].", "startOffset": 99, "endOffset": 114}, {"referenceID": 12, "context": "Because ICM is much faster than SA, the ICM is preferred in most BUS image segmentation approaches [7, 9, 11 - 13].", "startOffset": 99, "endOffset": 114}, {"referenceID": 34, "context": "ICM is quite sensitive to the initialization (parameters) because of its high possibility of converging to local minima, especially, for non-convex energies in high-dimensional space [35].", "startOffset": 183, "endOffset": 187}, {"referenceID": 34, "context": "A detailed comparison between ICM and other MRF energy minimization techniques can be found in [35].", "startOffset": 95, "endOffset": 99}, {"referenceID": 6, "context": "The number of classes is usually set from 2 to 4 for BUS image; and \u03b2 could be set adaptively [7] or set to a constant [11-13]; and the parameters of Gaussian distribution are usually initialized by using K-means algorithm [7, 9, 10].", "startOffset": 94, "endOffset": 97}, {"referenceID": 10, "context": "The number of classes is usually set from 2 to 4 for BUS image; and \u03b2 could be set adaptively [7] or set to a constant [11-13]; and the parameters of Gaussian distribution are usually initialized by using K-means algorithm [7, 9, 10].", "startOffset": 119, "endOffset": 126}, {"referenceID": 11, "context": "The number of classes is usually set from 2 to 4 for BUS image; and \u03b2 could be set adaptively [7] or set to a constant [11-13]; and the parameters of Gaussian distribution are usually initialized by using K-means algorithm [7, 9, 10].", "startOffset": 119, "endOffset": 126}, {"referenceID": 12, "context": "The number of classes is usually set from 2 to 4 for BUS image; and \u03b2 could be set adaptively [7] or set to a constant [11-13]; and the parameters of Gaussian distribution are usually initialized by using K-means algorithm [7, 9, 10].", "startOffset": 119, "endOffset": 126}, {"referenceID": 6, "context": "The number of classes is usually set from 2 to 4 for BUS image; and \u03b2 could be set adaptively [7] or set to a constant [11-13]; and the parameters of Gaussian distribution are usually initialized by using K-means algorithm [7, 9, 10].", "startOffset": 223, "endOffset": 233}, {"referenceID": 8, "context": "The number of classes is usually set from 2 to 4 for BUS image; and \u03b2 could be set adaptively [7] or set to a constant [11-13]; and the parameters of Gaussian distribution are usually initialized by using K-means algorithm [7, 9, 10].", "startOffset": 223, "endOffset": 233}, {"referenceID": 9, "context": "The number of classes is usually set from 2 to 4 for BUS image; and \u03b2 could be set adaptively [7] or set to a constant [11-13]; and the parameters of Gaussian distribution are usually initialized by using K-means algorithm [7, 9, 10].", "startOffset": 223, "endOffset": 233}, {"referenceID": 15, "context": "2 Graph cuts Graph cuts was proposed to solve a special case in MRF-MAP framework [16]: the global optimization of the binary labelling problem (L = { , }).", "startOffset": 82, "endOffset": 86}, {"referenceID": 16, "context": "It was then improved to solve the general (color image segmentation) and multi-label problem [17, 18].", "startOffset": 93, "endOffset": 101}, {"referenceID": 17, "context": "It was then improved to solve the general (color image segmentation) and multi-label problem [17, 18].", "startOffset": 93, "endOffset": 101}, {"referenceID": 18, "context": "The segmentation of an image is to find a cut that minimizes ( ); the minimum s-t cut is equivalent to maximize the flow (max-flow) from s to t according to the Ford-Fulkerson theorem [19].", "startOffset": 184, "endOffset": 188}, {"referenceID": 19, "context": "If a cost function is submodular [20], it can be represented by a graph ( ), and the function can be minimized by using the max-flow algorithm.", "startOffset": 33, "endOffset": 37}, {"referenceID": 20, "context": "The Boykov-Kolmogorov version [21] of the implementation of the max-flow algorithm can be downloaded from http://vision.", "startOffset": 30, "endOffset": 34}, {"referenceID": 21, "context": "[22] proposed a fully automatic BUS image segmentation framework in which the cost function modeled the information in the frequency and space domains.", "startOffset": 0, "endOffset": 4}, {"referenceID": 21, "context": "The data term modeled the tumor pose, position and intensity distribution; and the weights are given by ( , ) = \u2212 [ ( ) \u2219 Pr( | = 1)] (10) ( , ) = \u2212 1 \u2212 ( ) \u2219 Pr( | = 0) (11) G(i) is a 2D elliptical Gaussian function to model the tumor pose and position, and is constructed based on the results of the ROI generation [22].", "startOffset": 317, "endOffset": 321}, {"referenceID": 21, "context": "For details, please refer [22, 23].", "startOffset": 26, "endOffset": 34}, {"referenceID": 22, "context": "For details, please refer [22, 23].", "startOffset": 26, "endOffset": 34}, {"referenceID": 23, "context": "In [24], the graph is built on image regions, and user needs to specify a group of foreground (tumor) regions (F) and a group of background regions (B) to initialize the graph.", "startOffset": 3, "endOffset": 7}, {"referenceID": 134, "context": "The weight of any t-link is set to \u221e if the node belongs to \u2229 , and all other weights of t-links are set to 0; the weight function of the smoothness term is defined by utilizing region intensity difference and edge strength [138].", "startOffset": 224, "endOffset": 229}, {"referenceID": 24, "context": "In [25], a discriminative graph cut was proposed, in which ( , ) and ( , ) in the data term were determined online by training a Probabilistic Boosting Tree (PBT) [26] classifier based on the detection results (foreground and background patches); and ( , ) in the smoothness term was learned offline utilizing the training set by the PBT.", "startOffset": 3, "endOffset": 7}, {"referenceID": 25, "context": "In [25], a discriminative graph cut was proposed, in which ( , ) and ( , ) in the data term were determined online by training a Probabilistic Boosting Tree (PBT) [26] classifier based on the detection results (foreground and background patches); and ( , ) in the smoothness term was learned offline utilizing the training set by the PBT.", "startOffset": 163, "endOffset": 167}, {"referenceID": 26, "context": "[27] constructed a hierarchical multiscale superpixel classification framework to define the weights in the data term.", "startOffset": 0, "endOffset": 4}, {"referenceID": 27, "context": "In [28], both the region-level [29] and pixellevel features were utilized to define the weights in the data term; and all weights were learned by using a structural SVM [30].", "startOffset": 3, "endOffset": 7}, {"referenceID": 28, "context": "In [28], both the region-level [29] and pixellevel features were utilized to define the weights in the data term; and all weights were learned by using a structural SVM [30].", "startOffset": 31, "endOffset": 35}, {"referenceID": 29, "context": "In [28], both the region-level [29] and pixellevel features were utilized to define the weights in the data term; and all weights were learned by using a structural SVM [30].", "startOffset": 169, "endOffset": 173}, {"referenceID": 30, "context": "[31] proposed the Normalized cut to reformulate the energy function by considering both the disconnected links and the links inside each component: ( , ) = ( , ) ( , ) + ( ) + ( , ) ( , ) + ( ) = \u2211 , \u2211 \u2211 + \u2211 , \u2211 \u2211 (13)", "startOffset": 0, "endOffset": 4}, {"referenceID": 30, "context": "A recursive implementation of Normalized cut was proposed [31], which repeated the bipartition step on subgraphs until certain criterion is satisfied.", "startOffset": 58, "endOffset": 62}, {"referenceID": 26, "context": "[27, 34] applied normalized cut as an initial step to segment BUS images into small patches, and the final segmentation needs extra merging step and formulated knowledge to determine the tumor region.", "startOffset": 0, "endOffset": 8}, {"referenceID": 33, "context": "[27, 34] applied normalized cut as an initial step to segment BUS images into small patches, and the final segmentation needs extra merging step and formulated knowledge to determine the tumor region.", "startOffset": 0, "endOffset": 8}, {"referenceID": 31, "context": "[32] stated that traditional edge-driven approaches are too sensitive to noise and heavily depend on image denoising.", "startOffset": 0, "endOffset": 4}, {"referenceID": 32, "context": "[33] proposed a semi-automatic BUS image segmentation method based on Normalized cut.", "startOffset": 0, "endOffset": 4}, {"referenceID": 17, "context": "The \u201cshrink\u201d problem is the common disadvantage of these approaches, and the extension [18] can only find the approximate solution of multiple labeling of graph cuts.", "startOffset": 87, "endOffset": 91}, {"referenceID": 24, "context": "As illustrated in Table 1, two approaches [25, 28] learned all parameters of graph models by using discriminative learning.", "startOffset": 42, "endOffset": 50}, {"referenceID": 27, "context": "As illustrated in Table 1, two approaches [25, 28] learned all parameters of graph models by using discriminative learning.", "startOffset": 42, "endOffset": 50}, {"referenceID": 35, "context": "The traditional algorithms such as ICM and max-flow cannot solve the high-order graph model effectively, and an efficient approach to optimize the fully connected graph model was proposed in [36].", "startOffset": 191, "endOffset": 195}, {"referenceID": 8, "context": "[9], 1998 MRFMAP-ICM S Qualitative Integrate texture distribution; estimate distribution parameters locally Depend heavily on parameters estimation; assume the Gaussian distribution of features", "startOffset": 0, "endOffset": 3}, {"referenceID": 10, "context": "[11], 2002 MRFMAP-ICM S Qualitative Estimate distortion and segment image simultaneously User interaction to set parameters; assume the Gaussian distribution of features [10], 2003 MRFMAP-ICM S Qualitative Introduce the distance between global and local statistics to improve the adaptivity Assume the Gaussian distribution of features [13], 2016 MRFMAP-ICM S 33 images Integrate tissue stiffness information from ultrasound elastography Assume the Gaussian distribution of features", "startOffset": 0, "endOffset": 4}, {"referenceID": 9, "context": "[11], 2002 MRFMAP-ICM S Qualitative Estimate distortion and segment image simultaneously User interaction to set parameters; assume the Gaussian distribution of features [10], 2003 MRFMAP-ICM S Qualitative Introduce the distance between global and local statistics to improve the adaptivity Assume the Gaussian distribution of features [13], 2016 MRFMAP-ICM S 33 images Integrate tissue stiffness information from ultrasound elastography Assume the Gaussian distribution of features", "startOffset": 170, "endOffset": 174}, {"referenceID": 12, "context": "[11], 2002 MRFMAP-ICM S Qualitative Estimate distortion and segment image simultaneously User interaction to set parameters; assume the Gaussian distribution of features [10], 2003 MRFMAP-ICM S Qualitative Introduce the distance between global and local statistics to improve the adaptivity Assume the Gaussian distribution of features [13], 2016 MRFMAP-ICM S 33 images Integrate tissue stiffness information from ultrasound elastography Assume the Gaussian distribution of features", "startOffset": 336, "endOffset": 340}, {"referenceID": 22, "context": "[23], 2015 Graph cuts F 184 images No distribution assumption; model the tumor pose, position; construct smoothness term in both spatial and frequency domains \u201cshrink\u201d problem", "startOffset": 0, "endOffset": 4}, {"referenceID": 23, "context": "[24], 2010 Graph cuts S 13 images Graph cuts on regions User interaction to set the foreground and background priors; \u201cshrink\u201d problem", "startOffset": 0, "endOffset": 4}, {"referenceID": 24, "context": "[25], 2010 Graph cuts F 347 images Learn the data and smoothness terms from images using deterministic model \u201cshrink\u201d problem", "startOffset": 0, "endOffset": 4}, {"referenceID": 27, "context": "[28], 2013 Graph cuts F 469 images Integrate features of superpixel and detection windows into the data term; learn all model parameters by using structured support vector machine [30] \u201cshrink\u201d problem", "startOffset": 0, "endOffset": 4}, {"referenceID": 29, "context": "[28], 2013 Graph cuts F 469 images Integrate features of superpixel and detection windows into the data term; learn all model parameters by using structured support vector machine [30] \u201cshrink\u201d problem", "startOffset": 180, "endOffset": 184}, {"referenceID": 31, "context": "[32], 2012 Normalized cut S 100 images No shrink problem Manually select ROI", "startOffset": 0, "endOffset": 4}, {"referenceID": 36, "context": "DMs are proposed by Terzopoulos [37], and then become a popular and active field after the snake approach for planar image proposed by Kass et al.", "startOffset": 32, "endOffset": 36}, {"referenceID": 37, "context": "[38].", "startOffset": 0, "endOffset": 4}, {"referenceID": 0, "context": ", curve is defined as {( ( ), ( ))| \u2208 [0, 1]} where ( ( ), ( )) is the coordinates of point p on C.", "startOffset": 38, "endOffset": 44}, {"referenceID": 0, "context": "17 / 71 Let ( ) = ( ( ), ( )), \u2208 [0, 1] be a deformable curve; it moves to the optimal object boundary by minimizing E( ) = E ( ) + E ( ).", "startOffset": 33, "endOffset": 39}, {"referenceID": 37, "context": "The general formulation of P in the original DMs [38] is defined by ( , ) = ( , ) + ( , ) + ( , ) (18) where , and extract image line, edge and termination features, respectively; while , and are the corresponding weights.", "startOffset": 49, "endOffset": 53}, {"referenceID": 37, "context": "Minimization: the problem of finding the curve C minimizing E( ) is to find the extrema of functional which satisfies Euler-Lagrange equation [38]: E( ) = \u2212\u03b1( ) + ( ) + \u2207 = 0 (19)", "startOffset": 142, "endOffset": 146}, {"referenceID": 69, "context": "Gradient Vector Flow (GVF) [70] \u2217 = , where v is the vector of GVF field Relatively free of the initial contour; can deal with concave boundaries Difficult to set the blending parameter; strong and weak edges create similar flow; cannot deal with topological changes", "startOffset": 27, "endOffset": 31}, {"referenceID": 38, "context": "Balloon model [39] \u2217 = + is the unit vector to the curve, and k is the amplitude Increased attraction range; can find the minima even the initial contour is smaller than the minima contour; limited to extract 2D curve Cannot handle concave boundary; difficult to set the strength of the pressure; amply the issue of ignoring weak edges; cannot deal with topological changes", "startOffset": 14, "endOffset": 18}, {"referenceID": 142, "context": "Distance map [146] and Balloon model [39] \u2217 = \u2212\u2207 \u2016\u2207 \u2016 + + \u2207[ ] d defines the distance map calculating the distance between each pixel and its closest edge; is the weight Normalized the external force to give more stable results; Increased attraction range; extended to extract 3D surface Cannot handle concave boundary; cannot deal with topological changes", "startOffset": 13, "endOffset": 18}, {"referenceID": 38, "context": "Distance map [146] and Balloon model [39] \u2217 = \u2212\u2207 \u2016\u2207 \u2016 + + \u2207[ ] d defines the distance map calculating the distance between each pixel and its closest edge; is the weight Normalized the external force to give more stable results; Increased attraction range; extended to extract 3D surface Cannot handle concave boundary; cannot deal with topological changes", "startOffset": 37, "endOffset": 41}, {"referenceID": 39, "context": "2 Geometric deformable models (GDMs) GDMs [40, 41] are proposed to overcome the two primary limitations of PDMs: lack of topology adaptivity and parameterization dependence.", "startOffset": 42, "endOffset": 50}, {"referenceID": 40, "context": "2 Geometric deformable models (GDMs) GDMs [40, 41] are proposed to overcome the two primary limitations of PDMs: lack of topology adaptivity and parameterization dependence.", "startOffset": 42, "endOffset": 50}, {"referenceID": 41, "context": "A commonly used speed function is formulated as [42-44] = \u2219 ( + ) \u2212 \u3008\u2207 , \u3009 (25) = 1 1 + |\u2207( \u2217 )| (26) where is a constant to speed up the curve deformation, g is the stopping function by using image gradient to slow down and to stop the curve evolving at high gradient locations, and the second term (\u3008\u2207 , \u3009) makes the stopping power stronger when there are no perfect edges.", "startOffset": 48, "endOffset": 55}, {"referenceID": 42, "context": "A commonly used speed function is formulated as [42-44] = \u2219 ( + ) \u2212 \u3008\u2207 , \u3009 (25) = 1 1 + |\u2207( \u2217 )| (26) where is a constant to speed up the curve deformation, g is the stopping function by using image gradient to slow down and to stop the curve evolving at high gradient locations, and the second term (\u3008\u2207 , \u3009) makes the stopping power stronger when there are no perfect edges.", "startOffset": 48, "endOffset": 55}, {"referenceID": 43, "context": "A commonly used speed function is formulated as [42-44] = \u2219 ( + ) \u2212 \u3008\u2207 , \u3009 (25) = 1 1 + |\u2207( \u2217 )| (26) where is a constant to speed up the curve deformation, g is the stopping function by using image gradient to slow down and to stop the curve evolving at high gradient locations, and the second term (\u3008\u2207 , \u3009) makes the stopping power stronger when there are no perfect edges.", "startOffset": 48, "endOffset": 55}, {"referenceID": 40, "context": "A fast computation approach is described in [41].", "startOffset": 44, "endOffset": 48}, {"referenceID": 44, "context": "(3) Reinitializing the level set function; the speed function is defined only on the zero level set; the level function deformation requires it to be extended to all level sets; the extensions [45] can cause", "startOffset": 193, "endOffset": 197}, {"referenceID": 44, "context": "For more information about the reinitialization, please refer [45-47].", "startOffset": 62, "endOffset": 69}, {"referenceID": 45, "context": "For more information about the reinitialization, please refer [45-47].", "startOffset": 62, "endOffset": 69}, {"referenceID": 46, "context": "For more information about the reinitialization, please refer [45-47].", "startOffset": 62, "endOffset": 69}, {"referenceID": 37, "context": "The DMs can be classified into edge-based [38, 41, 42, 44, 48] and region-based [47, 49, 66] according to the information to construct the external force in PDMs or speed function in GDMs.", "startOffset": 42, "endOffset": 62}, {"referenceID": 40, "context": "The DMs can be classified into edge-based [38, 41, 42, 44, 48] and region-based [47, 49, 66] according to the information to construct the external force in PDMs or speed function in GDMs.", "startOffset": 42, "endOffset": 62}, {"referenceID": 41, "context": "The DMs can be classified into edge-based [38, 41, 42, 44, 48] and region-based [47, 49, 66] according to the information to construct the external force in PDMs or speed function in GDMs.", "startOffset": 42, "endOffset": 62}, {"referenceID": 43, "context": "The DMs can be classified into edge-based [38, 41, 42, 44, 48] and region-based [47, 49, 66] according to the information to construct the external force in PDMs or speed function in GDMs.", "startOffset": 42, "endOffset": 62}, {"referenceID": 47, "context": "The DMs can be classified into edge-based [38, 41, 42, 44, 48] and region-based [47, 49, 66] according to the information to construct the external force in PDMs or speed function in GDMs.", "startOffset": 42, "endOffset": 62}, {"referenceID": 46, "context": "The DMs can be classified into edge-based [38, 41, 42, 44, 48] and region-based [47, 49, 66] according to the information to construct the external force in PDMs or speed function in GDMs.", "startOffset": 80, "endOffset": 92}, {"referenceID": 48, "context": "The DMs can be classified into edge-based [38, 41, 42, 44, 48] and region-based [47, 49, 66] according to the information to construct the external force in PDMs or speed function in GDMs.", "startOffset": 80, "endOffset": 92}, {"referenceID": 65, "context": "The DMs can be classified into edge-based [38, 41, 42, 44, 48] and region-based [47, 49, 66] according to the information to construct the external force in PDMs or speed function in GDMs.", "startOffset": 80, "endOffset": 92}, {"referenceID": 41, "context": "Edge-based DMs aim to attract the evolving curve to object boundary by defining the deformation force or speed using image gradient [42-44], and the models depend on image gradient to stop curve deformation.", "startOffset": 132, "endOffset": 139}, {"referenceID": 42, "context": "Edge-based DMs aim to attract the evolving curve to object boundary by defining the deformation force or speed using image gradient [42-44], and the models depend on image gradient to stop curve deformation.", "startOffset": 132, "endOffset": 139}, {"referenceID": 43, "context": "Edge-based DMs aim to attract the evolving curve to object boundary by defining the deformation force or speed using image gradient [42-44], and the models depend on image gradient to stop curve deformation.", "startOffset": 132, "endOffset": 139}, {"referenceID": 49, "context": "[50] applied the B-snake model [51] for BUS image sequence segmentation.", "startOffset": 0, "endOffset": 4}, {"referenceID": 50, "context": "[50] applied the B-snake model [51] for BUS image sequence segmentation.", "startOffset": 31, "endOffset": 35}, {"referenceID": 51, "context": "In [52], Chen et al.", "startOffset": 3, "endOffset": 7}, {"referenceID": 52, "context": "22 / 71 dual snake [53] to handle the two problems of applying traditional DMs for BUS image segmentation: (1) initial contour should be placed close to the tumor boundary; and (2) cannot capture highly winding tumor boundary.", "startOffset": 19, "endOffset": 23}, {"referenceID": 53, "context": "In [54, 55], Madabhushi et al.", "startOffset": 3, "endOffset": 11}, {"referenceID": 54, "context": "In [54, 55], Madabhushi et al.", "startOffset": 3, "endOffset": 11}, {"referenceID": 55, "context": "In [56, 57], Sahiner applied PDM for 3D BUS tumor segmentation, the external forces have two terms; the first term is defined on image gradient calculated using 3\u00d73 Sobel filters; and the second term is the balloon force.", "startOffset": 3, "endOffset": 11}, {"referenceID": 56, "context": "In [56, 57], Sahiner applied PDM for 3D BUS tumor segmentation, the external forces have two terms; the first term is defined on image gradient calculated using 3\u00d73 Sobel filters; and the second term is the balloon force.", "startOffset": 3, "endOffset": 11}, {"referenceID": 57, "context": "In [58, 59], Chang et al.", "startOffset": 3, "endOffset": 11}, {"referenceID": 58, "context": "In [58, 59], Chang et al.", "startOffset": 3, "endOffset": 11}, {"referenceID": 59, "context": "The sticks filter [60] was utilized to enhance edge and reduce speckle noise.", "startOffset": 18, "endOffset": 22}, {"referenceID": 60, "context": "[61] proposed an automatic BUS image segmentation approach by using the gradient vector flow (GVF) model [70].", "startOffset": 0, "endOffset": 4}, {"referenceID": 69, "context": "[61] proposed an automatic BUS image segmentation approach by using the gradient vector flow (GVF) model [70].", "startOffset": 105, "endOffset": 109}, {"referenceID": 61, "context": "[62] proposed a fully automatic", "startOffset": 0, "endOffset": 4}, {"referenceID": 41, "context": "[42] modified traditional GDMs to have an additional term (\u3008\u2207 , \u3009) that provided stronger stopping power at object edges.", "startOffset": 0, "endOffset": 4}, {"referenceID": 62, "context": "[63] proposed a fast GDM method for biomedical image segmentation.", "startOffset": 0, "endOffset": 4}, {"referenceID": 51, "context": "The experimental results showed that it was much faster than the narrow band algorithm [52].", "startOffset": 87, "endOffset": 91}, {"referenceID": 63, "context": "[64] proposed a fully automatic BUS image segmentation based on texture classification and GDM.", "startOffset": 0, "endOffset": 4}, {"referenceID": 64, "context": "[65] stated that GDMs establish stopping term based on image gradient may not work well because of the noisy and weak boundary.", "startOffset": 0, "endOffset": 4}, {"referenceID": 65, "context": "They proposed a BUS image segmentation approach based on the active contour without edges (ACWE) model [66] which defined the stopping term using Mumford-Shah technique and was robust to segment images with weak boundaries.", "startOffset": 103, "endOffset": 107}, {"referenceID": 66, "context": "[67] proposed an interactive BUS image segmentation approach utilizing regionbased GDMs, in which the probability density difference between the intensity distributions (tumor and background) and the estimated Rayleigh distribution are applied to enforce priors of intensity distribution.", "startOffset": 0, "endOffset": 4}, {"referenceID": 65, "context": "The approach was compared with two other GDM approaches [66, 68] using 79 BUS images.", "startOffset": 56, "endOffset": 64}, {"referenceID": 67, "context": "The approach was compared with two other GDM approaches [66, 68] using 79 BUS images.", "startOffset": 56, "endOffset": 64}, {"referenceID": 68, "context": "[69] modified the generalized GVF [70] approach based on a continuous force field analysis, and applied it to BUS image segmentation.", "startOffset": 0, "endOffset": 4}, {"referenceID": 69, "context": "[69] modified the generalized GVF [70] approach based on a continuous force field analysis, and applied it to BUS image segmentation.", "startOffset": 34, "endOffset": 38}, {"referenceID": 70, "context": "[71] considered the SNR and local intensity value as two important features for estimating tumor boundary, and built a two-fold termination criterion based on the two features in discrete dynamic DMs [72].", "startOffset": 0, "endOffset": 4}, {"referenceID": 71, "context": "[71] considered the SNR and local intensity value as two important features for estimating tumor boundary, and built a two-fold termination criterion based on the two features in discrete dynamic DMs [72].", "startOffset": 200, "endOffset": 204}, {"referenceID": 72, "context": "[73] proposed a level set approach for BUS image segmentation based on the method in [47] by redefining the edge-based stop function using phase congruency [74] which is invariant to intensity magnitude, and integrated GVF model into the level set framework.", "startOffset": 0, "endOffset": 4}, {"referenceID": 46, "context": "[73] proposed a level set approach for BUS image segmentation based on the method in [47] by redefining the edge-based stop function using phase congruency [74] which is invariant to intensity magnitude, and integrated GVF model into the level set framework.", "startOffset": 85, "endOffset": 89}, {"referenceID": 73, "context": "[73] proposed a level set approach for BUS image segmentation based on the method in [47] by redefining the edge-based stop function using phase congruency [74] which is invariant to intensity magnitude, and integrated GVF model into the level set framework.", "startOffset": 156, "endOffset": 160}, {"referenceID": 74, "context": "[75] proposed phase-based DM in which the local region statistics [49] is introduced to solve the inhomogeneous intensity problem, and the phase-based edge indicator is used to replace the conventional gradient-based edge operator.", "startOffset": 0, "endOffset": 4}, {"referenceID": 48, "context": "[75] proposed phase-based DM in which the local region statistics [49] is introduced to solve the inhomogeneous intensity problem, and the phase-based edge indicator is used to replace the conventional gradient-based edge operator.", "startOffset": 66, "endOffset": 70}, {"referenceID": 75, "context": "[76] modified the local region-based level set approach [77] by using additional constrained energies centered at four markers specified by radiologist.", "startOffset": 0, "endOffset": 4}, {"referenceID": 76, "context": "[76] modified the local region-based level set approach [77] by using additional constrained energies centered at four markers specified by radiologist.", "startOffset": 56, "endOffset": 60}, {"referenceID": 77, "context": "[78] proposed a fully automatic robust region-based level set approach with contour points classification (low contrast class and high contrast class).", "startOffset": 0, "endOffset": 4}, {"referenceID": 65, "context": "25 / 71 For the points in the low contrast class, both the global and local region-based energies [66, 77] are used; while for the high contrast class, only the local region-based [77] energy is utilized.", "startOffset": 98, "endOffset": 106}, {"referenceID": 76, "context": "25 / 71 For the points in the low contrast class, both the global and local region-based energies [66, 77] are used; while for the high contrast class, only the local region-based [77] energy is utilized.", "startOffset": 98, "endOffset": 106}, {"referenceID": 76, "context": "25 / 71 For the points in the low contrast class, both the global and local region-based energies [66, 77] are used; while for the high contrast class, only the local region-based [77] energy is utilized.", "startOffset": 180, "endOffset": 184}, {"referenceID": 78, "context": "[79] adopted the region-based approach in [78], proposed a learning based approach (multivariate linear regression and support vector regression) to produce the parameters adaptively, and proved better performance using 481 BUS images.", "startOffset": 0, "endOffset": 4}, {"referenceID": 77, "context": "[79] adopted the region-based approach in [78], proposed a learning based approach (multivariate linear regression and support vector regression) to produce the parameters adaptively, and proved better performance using 481 BUS images.", "startOffset": 42, "endOffset": 46}, {"referenceID": 79, "context": "[80] proposed a new level set based DM approach; the local divergence and a smoothing kernel were introduced to improve the speed function.", "startOffset": 0, "endOffset": 4}, {"referenceID": 80, "context": "[81, 82] proposed a semi-automatic approach for 3D BUS image segmentation.", "startOffset": 0, "endOffset": 8}, {"referenceID": 81, "context": "[81, 82] proposed a semi-automatic approach for 3D BUS image segmentation.", "startOffset": 0, "endOffset": 8}, {"referenceID": 82, "context": "The approach utilized user interaction to generate the volume of interest (VOI), applied the radial-gradient index [83] to estimate the initial lesion boundary, and implemented the region-based DM [48, 49] iteratively to find the final contour.", "startOffset": 115, "endOffset": 119}, {"referenceID": 47, "context": "The approach utilized user interaction to generate the volume of interest (VOI), applied the radial-gradient index [83] to estimate the initial lesion boundary, and implemented the region-based DM [48, 49] iteratively to find the final contour.", "startOffset": 197, "endOffset": 205}, {"referenceID": 48, "context": "The approach utilized user interaction to generate the volume of interest (VOI), applied the radial-gradient index [83] to estimate the initial lesion boundary, and implemented the region-based DM [48, 49] iteratively to find the final contour.", "startOffset": 197, "endOffset": 205}, {"referenceID": 83, "context": "The stopping criterion was defined as ( \u0305 \u2212 \u0305 ) \u2212 ( \u0305 \u2212 \u0305 ) = 0 [84], where \u0305 and \u0305 were the mean intensities inside and outside the segmented regions at step t, respectively.", "startOffset": 64, "endOffset": 68}, {"referenceID": 29, "context": "/ year Category F/S Dataset Useful Strategies Disadvantages [30], 2003 PDMs F 90 Use the balloon force to increase the attraction range.", "startOffset": 60, "endOffset": 64}, {"referenceID": 32, "context": "Fixed reference point; difficult to set the strength of the balloon force [33] 2003 PDMs F 8(3D) Define the external force using local texture features Validated only on a small dataset, and sensitive to initialization [39], 2004 PDMS S 102 (3D) Use the balloon force to increase the attraction range.", "startOffset": 74, "endOffset": 78}, {"referenceID": 38, "context": "Fixed reference point; difficult to set the strength of the balloon force [33] 2003 PDMs F 8(3D) Define the external force using local texture features Validated only on a small dataset, and sensitive to initialization [39], 2004 PDMS S 102 (3D) Use the balloon force to increase the attraction range.", "startOffset": 219, "endOffset": 223}, {"referenceID": 58, "context": "No quantitative evaluation of the segmentation [59], 2007 PDMS F 360 Use GVF to extend the attraction range and to handle concave boundaries Fixed threshold and reference point are applied for initial boundary generation; no quantitative evaluation [69], 2009 PDMs F 103 Use a well-trained texture classifier to detect tumor ROI Predefined rules to exclude false classified regions", "startOffset": 47, "endOffset": 51}, {"referenceID": 68, "context": "No quantitative evaluation of the segmentation [59], 2007 PDMS F 360 Use GVF to extend the attraction range and to handle concave boundaries Fixed threshold and reference point are applied for initial boundary generation; no quantitative evaluation [69], 2009 PDMs F 103 Use a well-trained texture classifier to detect tumor ROI Predefined rules to exclude false classified regions", "startOffset": 249, "endOffset": 253}, {"referenceID": 84, "context": "26 / 71 [85], 2010 GDMs S 79 Model the difference between the regional intensity distribution and the estimated prior distribution Slow; sensitive to initialization", "startOffset": 8, "endOffset": 12}, {"referenceID": 121, "context": "[124], 2012 PDMs S 20 Redefine the edge-based stopping function using phase information Validated only on a small dataset; sensitive to noise [139], 2013 GDMs S 168 Use both local statistics and phase information to define the speed function; and handle weak boundary and inhomogeneity problems better Slow", "startOffset": 0, "endOffset": 5}, {"referenceID": 135, "context": "[124], 2012 PDMs S 20 Redefine the edge-based stopping function using phase information Validated only on a small dataset; sensitive to noise [139], 2013 GDMs S 168 Use both local statistics and phase information to define the speed function; and handle weak boundary and inhomogeneity problems better Slow", "startOffset": 142, "endOffset": 147}, {"referenceID": 144, "context": "[148], 2013 GDMs F 861 Region-based GDM and solve the inhomogeneity problem better Slow and sensitive to initialization", "startOffset": 0, "endOffset": 5}, {"referenceID": 162, "context": "[166], 2014 GDMs S 98(3D) Use Region-based GDM and handle inhomogeneity problem Slow and need user interaction to extract VOI DM is the most popular approach applied to BUS image segmentation.", "startOffset": 0, "endOffset": 5}, {"referenceID": 84, "context": "28 / 71 FCM was proposed in [85] and improved in [86].", "startOffset": 28, "endOffset": 32}, {"referenceID": 85, "context": "28 / 71 FCM was proposed in [85] and improved in [86].", "startOffset": 49, "endOffset": 53}, {"referenceID": 0, "context": "(28), \u2208 [0,1] is the membership value representing the degree of data point belonging to cluster , and is given by = 1 \u2211 \u2212 \u2016 \u2212 \u2016 (28)", "startOffset": 8, "endOffset": 13}, {"referenceID": 6, "context": "In [7, 9, 10], K-means was utilized to estimate the parameters of distributions in graph-based models, and the predefined number of clusters should be set.", "startOffset": 3, "endOffset": 13}, {"referenceID": 8, "context": "In [7, 9, 10], K-means was utilized to estimate the parameters of distributions in graph-based models, and the predefined number of clusters should be set.", "startOffset": 3, "endOffset": 13}, {"referenceID": 9, "context": "In [7, 9, 10], K-means was utilized to estimate the parameters of distributions in graph-based models, and the predefined number of clusters should be set.", "startOffset": 3, "endOffset": 13}, {"referenceID": 86, "context": "[87] proposed a BUS image segmentation method using the spatial FCM (sFCM) [88] with local texture and intensity features.", "startOffset": 0, "endOffset": 4}, {"referenceID": 87, "context": "[87] proposed a BUS image segmentation method using the spatial FCM (sFCM) [88] with local texture and intensity features.", "startOffset": 75, "endOffset": 79}, {"referenceID": 88, "context": "[89] applied FCM to generate image regions in four clusters, then extracted the morphology, location, and size features of each region; and finally trained a linear regression model [90] to produce the tumor likelihoods for all regions.", "startOffset": 0, "endOffset": 4}, {"referenceID": 89, "context": "[89] applied FCM to generate image regions in four clusters, then extracted the morphology, location, and size features of each region; and finally trained a linear regression model [90] to produce the tumor likelihoods for all regions.", "startOffset": 182, "endOffset": 186}, {"referenceID": 90, "context": "[91] applied FCM to image regions produced by using the mean shift method [92]; the number of clusters is set to 4, and the regions belonging to the darkest cluster are extracted as the tumor candidates.", "startOffset": 74, "endOffset": 78}, {"referenceID": 88, "context": "[89, 91] did not discuss how to initialize the membership values in FCM.", "startOffset": 0, "endOffset": 8}, {"referenceID": 91, "context": "[94, 95] extended the FCM and proposed the neutrosophic l-means (NLM) clustering which takes", "startOffset": 0, "endOffset": 8}, {"referenceID": 92, "context": "[94, 95] extended the FCM and proposed the neutrosophic l-means (NLM) clustering which takes", "startOffset": 0, "endOffset": 8}, {"referenceID": 93, "context": "1 Support vector machine (SVM) SVM is one of the most popular supervised-learning models in machine learning, and can be utilized for both linear classification (linear SVM) and non-linear classification (kernel SVM) [96, 99] by mapping its inputs to high dimensional spaces.", "startOffset": 217, "endOffset": 225}, {"referenceID": 96, "context": "1 Support vector machine (SVM) SVM is one of the most popular supervised-learning models in machine learning, and can be utilized for both linear classification (linear SVM) and non-linear classification (kernel SVM) [96, 99] by mapping its inputs to high dimensional spaces.", "startOffset": 217, "endOffset": 225}, {"referenceID": 94, "context": "Let w be the normal vector to the hyperplane, and { = (0, 1 \u2212 ( \u2219 + ))} be slack variables for the soft margins; then the problem can be formulated as a constrained quadratic optimization problem [97] 1 + \u2016 \u2016 (30)", "startOffset": 196, "endOffset": 200}, {"referenceID": 95, "context": "[98] trained a kernel SVM classifier [99] using the local image features to classify small image lattices (16\u00d716) into tumor or non-tumor classes; the radius basis function (RBF) was", "startOffset": 0, "endOffset": 4}, {"referenceID": 96, "context": "[98] trained a kernel SVM classifier [99] using the local image features to classify small image lattices (16\u00d716) into tumor or non-tumor classes; the radius basis function (RBF) was", "startOffset": 37, "endOffset": 41}, {"referenceID": 97, "context": "[100] proposed two-step BUS segmentation approach.", "startOffset": 0, "endOffset": 5}, {"referenceID": 98, "context": "First, a set of candidate tumor regions were produced by using Adaboost classifier [101] and 24 Haar-like features [102]; and a SVM classifier was trained using the quantized intensity features produced by K-means clustering to determine the false positive and true positive regions.", "startOffset": 83, "endOffset": 88}, {"referenceID": 99, "context": "First, a set of candidate tumor regions were produced by using Adaboost classifier [101] and 24 Haar-like features [102]; and a SVM classifier was trained using the quantized intensity features produced by K-means clustering to determine the false positive and true positive regions.", "startOffset": 115, "endOffset": 120}, {"referenceID": 100, "context": "Second, random walk [103] was applied to generate the final tumor boundary by placing seed at the center of each true region.", "startOffset": 20, "endOffset": 25}, {"referenceID": 100, "context": "[103] proposed an ANN-based method to segment 3D BUS images by processing 2D images slices.", "startOffset": 0, "endOffset": 5}, {"referenceID": 101, "context": "[104] trained an ANN to generate the threshold for BUS image segmentation.", "startOffset": 0, "endOffset": 5}, {"referenceID": 102, "context": "[105, 106] trained an ANN using three new features: the phase in the max-energy orientation (PMO) based on phase congruency, radial distance (RD) and the joint probability of intensity and texture [30].", "startOffset": 0, "endOffset": 10}, {"referenceID": 103, "context": "[105, 106] trained an ANN using three new features: the phase in the max-energy orientation (PMO) based on phase congruency, radial distance (RD) and the joint probability of intensity and texture [30].", "startOffset": 0, "endOffset": 10}, {"referenceID": 29, "context": "[105, 106] trained an ANN using three new features: the phase in the max-energy orientation (PMO) based on phase congruency, radial distance (RD) and the joint probability of intensity and texture [30].", "startOffset": 197, "endOffset": 201}, {"referenceID": 134, "context": "[138] proposed a whole breast tumor detection method by classifying slice pixels into tumor (x1) or normal tissue (x2) by using NBC.", "startOffset": 0, "endOffset": 5}, {"referenceID": 59, "context": "Two features, local (5\u00d75 mask) intensity mean and stick filter [60] output, were utilized; the class priors were assumed to be equiprobable, and the conditional distribution of each feature ( ) was assumed to be Rayleigh distribution: ( | ) = \u2044 , = 1, 2 (34) where is the Rayleigh parameter and can be estimated from training data.", "startOffset": 63, "endOffset": 67}, {"referenceID": 105, "context": "NBC produced a set of suspected lesions, and a two-phase lesion selection method based on region shape features (area size, width-height ratio, region ratio and compactness) and region continuity and volume size were applied for final tumor region decision [108].", "startOffset": 257, "endOffset": 262}, {"referenceID": 6, "context": "Category F/S Dataset Advantages Disadvantages [7, 9, 10] Adaptive K-means S Several images Achieved better performance than the standard K-means on images with local intensity variations Sensitive to initialization; only used for estimating distribution parameters [89] FCM F 58 lesions (ABUS images) High sensitive rate Sensitive to initialization; high false positive rate [91] FCM F 148 lesions (ABUS images) High sensitive rate Sensitive to initialization; used fixed threshold to merge regions [98] SVM F 112 images Utilized local texture features to classify local lattices and achieved high precision and recall ratio Only produced rough tumor boundaries; depended on post processing rules to refine the results [100] SVM F 112 images Balanced sensitivity and specificity Slow; depended on random walk to generate the final boundary", "startOffset": 46, "endOffset": 56}, {"referenceID": 8, "context": "Category F/S Dataset Advantages Disadvantages [7, 9, 10] Adaptive K-means S Several images Achieved better performance than the standard K-means on images with local intensity variations Sensitive to initialization; only used for estimating distribution parameters [89] FCM F 58 lesions (ABUS images) High sensitive rate Sensitive to initialization; high false positive rate [91] FCM F 148 lesions (ABUS images) High sensitive rate Sensitive to initialization; used fixed threshold to merge regions [98] SVM F 112 images Utilized local texture features to classify local lattices and achieved high precision and recall ratio Only produced rough tumor boundaries; depended on post processing rules to refine the results [100] SVM F 112 images Balanced sensitivity and specificity Slow; depended on random walk to generate the final boundary", "startOffset": 46, "endOffset": 56}, {"referenceID": 9, "context": "Category F/S Dataset Advantages Disadvantages [7, 9, 10] Adaptive K-means S Several images Achieved better performance than the standard K-means on images with local intensity variations Sensitive to initialization; only used for estimating distribution parameters [89] FCM F 58 lesions (ABUS images) High sensitive rate Sensitive to initialization; high false positive rate [91] FCM F 148 lesions (ABUS images) High sensitive rate Sensitive to initialization; used fixed threshold to merge regions [98] SVM F 112 images Utilized local texture features to classify local lattices and achieved high precision and recall ratio Only produced rough tumor boundaries; depended on post processing rules to refine the results [100] SVM F 112 images Balanced sensitivity and specificity Slow; depended on random walk to generate the final boundary", "startOffset": 46, "endOffset": 56}, {"referenceID": 88, "context": "Category F/S Dataset Advantages Disadvantages [7, 9, 10] Adaptive K-means S Several images Achieved better performance than the standard K-means on images with local intensity variations Sensitive to initialization; only used for estimating distribution parameters [89] FCM F 58 lesions (ABUS images) High sensitive rate Sensitive to initialization; high false positive rate [91] FCM F 148 lesions (ABUS images) High sensitive rate Sensitive to initialization; used fixed threshold to merge regions [98] SVM F 112 images Utilized local texture features to classify local lattices and achieved high precision and recall ratio Only produced rough tumor boundaries; depended on post processing rules to refine the results [100] SVM F 112 images Balanced sensitivity and specificity Slow; depended on random walk to generate the final boundary", "startOffset": 265, "endOffset": 269}, {"referenceID": 95, "context": "Category F/S Dataset Advantages Disadvantages [7, 9, 10] Adaptive K-means S Several images Achieved better performance than the standard K-means on images with local intensity variations Sensitive to initialization; only used for estimating distribution parameters [89] FCM F 58 lesions (ABUS images) High sensitive rate Sensitive to initialization; high false positive rate [91] FCM F 148 lesions (ABUS images) High sensitive rate Sensitive to initialization; used fixed threshold to merge regions [98] SVM F 112 images Utilized local texture features to classify local lattices and achieved high precision and recall ratio Only produced rough tumor boundaries; depended on post processing rules to refine the results [100] SVM F 112 images Balanced sensitivity and specificity Slow; depended on random walk to generate the final boundary", "startOffset": 499, "endOffset": 503}, {"referenceID": 97, "context": "Category F/S Dataset Advantages Disadvantages [7, 9, 10] Adaptive K-means S Several images Achieved better performance than the standard K-means on images with local intensity variations Sensitive to initialization; only used for estimating distribution parameters [89] FCM F 58 lesions (ABUS images) High sensitive rate Sensitive to initialization; high false positive rate [91] FCM F 148 lesions (ABUS images) High sensitive rate Sensitive to initialization; used fixed threshold to merge regions [98] SVM F 112 images Utilized local texture features to classify local lattices and achieved high precision and recall ratio Only produced rough tumor boundaries; depended on post processing rules to refine the results [100] SVM F 112 images Balanced sensitivity and specificity Slow; depended on random walk to generate the final boundary", "startOffset": 719, "endOffset": 724}, {"referenceID": 100, "context": "35 / 71 [103] ANN F 93 cases (3D) Fully automatic Depended on fixed threshold to produce candidate regions; relatively low performance [106], 2012 ANN F 120 images Achieved good performance by using the phase information, radial distance and the joint distribution of texture and intensity Depended on fixed reference point to generate the initial ROI", "startOffset": 8, "endOffset": 13}, {"referenceID": 103, "context": "35 / 71 [103] ANN F 93 cases (3D) Fully automatic Depended on fixed threshold to produce candidate regions; relatively low performance [106], 2012 ANN F 120 images Achieved good performance by using the phase information, radial distance and the joint distribution of texture and intensity Depended on fixed reference point to generate the initial ROI", "startOffset": 135, "endOffset": 140}, {"referenceID": 104, "context": "[107], 2012 NBC F 31 cases (Whole BUS images) Achieved high sensitive ratio Depended on the assumption of intensity distribution; depended on post selection to reduce false positive ratio 4.", "startOffset": 0, "endOffset": 5}, {"referenceID": 6, "context": "However, because of the challenging nature of BUS image segmentation, unsupervised approaches are only used as a preprocessing step to generate candidate image regions and more sophisticated methods are usually employed to perform the final segmentation; for example, in [7, 9, 10], K-means is utilized to estimate the initial parameters of intensity or texture distributions; and in [89, 91], logistic regression is utilized for clustering results to find the final tumor.", "startOffset": 271, "endOffset": 281}, {"referenceID": 8, "context": "However, because of the challenging nature of BUS image segmentation, unsupervised approaches are only used as a preprocessing step to generate candidate image regions and more sophisticated methods are usually employed to perform the final segmentation; for example, in [7, 9, 10], K-means is utilized to estimate the initial parameters of intensity or texture distributions; and in [89, 91], logistic regression is utilized for clustering results to find the final tumor.", "startOffset": 271, "endOffset": 281}, {"referenceID": 9, "context": "However, because of the challenging nature of BUS image segmentation, unsupervised approaches are only used as a preprocessing step to generate candidate image regions and more sophisticated methods are usually employed to perform the final segmentation; for example, in [7, 9, 10], K-means is utilized to estimate the initial parameters of intensity or texture distributions; and in [89, 91], logistic regression is utilized for clustering results to find the final tumor.", "startOffset": 271, "endOffset": 281}, {"referenceID": 88, "context": "However, because of the challenging nature of BUS image segmentation, unsupervised approaches are only used as a preprocessing step to generate candidate image regions and more sophisticated methods are usually employed to perform the final segmentation; for example, in [7, 9, 10], K-means is utilized to estimate the initial parameters of intensity or texture distributions; and in [89, 91], logistic regression is utilized for clustering results to find the final tumor.", "startOffset": 384, "endOffset": 392}, {"referenceID": 24, "context": ", in [25, 28], supervised learning approaches learn the parameters of the graph-based models from the training data; they also can be used to perform", "startOffset": 5, "endOffset": 13}, {"referenceID": 27, "context": ", in [25, 28], supervised learning approaches learn the parameters of the graph-based models from the training data; they also can be used to perform", "startOffset": 5, "endOffset": 13}, {"referenceID": 117, "context": ", in [120], a well-trained ANN was applied to perform the tumor segmentation.", "startOffset": 5, "endOffset": 10}, {"referenceID": 158, "context": "Learning-based approaches thrive in BUS image segmentation in the last decade and we believe new deep learning techniques [162] such as deep convolutional neural networks (CNNs) and recurrent neural network (RNN) will make great progress in segmenting BUS images in the near future.", "startOffset": 122, "endOffset": 127}, {"referenceID": 106, "context": "The first is to choose empirical value as the threshold for the whole dataset [109-111]; the second approach is to select the threshold for each image based on domain related rules [112, 113]; and the third is to generate the threshold automatically based on statistical-decision theory [22, 114, 115].", "startOffset": 78, "endOffset": 87}, {"referenceID": 107, "context": "The first is to choose empirical value as the threshold for the whole dataset [109-111]; the second approach is to select the threshold for each image based on domain related rules [112, 113]; and the third is to generate the threshold automatically based on statistical-decision theory [22, 114, 115].", "startOffset": 78, "endOffset": 87}, {"referenceID": 108, "context": "The first is to choose empirical value as the threshold for the whole dataset [109-111]; the second approach is to select the threshold for each image based on domain related rules [112, 113]; and the third is to generate the threshold automatically based on statistical-decision theory [22, 114, 115].", "startOffset": 78, "endOffset": 87}, {"referenceID": 109, "context": "The first is to choose empirical value as the threshold for the whole dataset [109-111]; the second approach is to select the threshold for each image based on domain related rules [112, 113]; and the third is to generate the threshold automatically based on statistical-decision theory [22, 114, 115].", "startOffset": 181, "endOffset": 191}, {"referenceID": 110, "context": "The first is to choose empirical value as the threshold for the whole dataset [109-111]; the second approach is to select the threshold for each image based on domain related rules [112, 113]; and the third is to generate the threshold automatically based on statistical-decision theory [22, 114, 115].", "startOffset": 181, "endOffset": 191}, {"referenceID": 21, "context": "The first is to choose empirical value as the threshold for the whole dataset [109-111]; the second approach is to select the threshold for each image based on domain related rules [112, 113]; and the third is to generate the threshold automatically based on statistical-decision theory [22, 114, 115].", "startOffset": 287, "endOffset": 301}, {"referenceID": 111, "context": "The first is to choose empirical value as the threshold for the whole dataset [109-111]; the second approach is to select the threshold for each image based on domain related rules [112, 113]; and the third is to generate the threshold automatically based on statistical-decision theory [22, 114, 115].", "startOffset": 287, "endOffset": 301}, {"referenceID": 112, "context": "The first is to choose empirical value as the threshold for the whole dataset [109-111]; the second approach is to select the threshold for each image based on domain related rules [112, 113]; and the third is to generate the threshold automatically based on statistical-decision theory [22, 114, 115].", "startOffset": 287, "endOffset": 301}, {"referenceID": 113, "context": "Seed generation: the seeds can be placed by user interactively [116, 117] or generated automatically [54, 55, 113, 118].", "startOffset": 63, "endOffset": 73}, {"referenceID": 114, "context": "Seed generation: the seeds can be placed by user interactively [116, 117] or generated automatically [54, 55, 113, 118].", "startOffset": 63, "endOffset": 73}, {"referenceID": 53, "context": "Seed generation: the seeds can be placed by user interactively [116, 117] or generated automatically [54, 55, 113, 118].", "startOffset": 101, "endOffset": 119}, {"referenceID": 54, "context": "Seed generation: the seeds can be placed by user interactively [116, 117] or generated automatically [54, 55, 113, 118].", "startOffset": 101, "endOffset": 119}, {"referenceID": 110, "context": "Seed generation: the seeds can be placed by user interactively [116, 117] or generated automatically [54, 55, 113, 118].", "startOffset": 101, "endOffset": 119}, {"referenceID": 115, "context": "Seed generation: the seeds can be placed by user interactively [116, 117] or generated automatically [54, 55, 113, 118].", "startOffset": 101, "endOffset": 119}, {"referenceID": 53, "context": "In [54, 55], Madabhushi et al.", "startOffset": 3, "endOffset": 11}, {"referenceID": 54, "context": "In [54, 55], Madabhushi et al.", "startOffset": 3, "endOffset": 11}, {"referenceID": 54, "context": "selected seed ( \u2217) automatically from a set of candidate pixels by formulating empirical rules [55]: \u2217 = argmax \u0393 , \u2219 I \u2219 (36)", "startOffset": 95, "endOffset": 99}, {"referenceID": 115, "context": "[118] used this method for seed generation.", "startOffset": 0, "endOffset": 5}, {"referenceID": 110, "context": "[113] proposed another automatic seed generation approach.", "startOffset": 0, "endOffset": 5}, {"referenceID": 114, "context": "[117] defined the cost of growing a region by modelling common contour smoothness and region similarity (mean intensity and size): ( , ) = ( ) \u2212 ( ) \u2219 ( , ) + \u2219 ( ) \u2219 ( ) ( ) + ( ) , \u2208 ( ) (39) where (\u2219) denotes the mean intensity of a region, (\u2219) is the pixel number of the region, ( , ) is the length of the common contour between the seed region rs and region r, ( ) is a set of regions adjacent to rs, and and are two predefined constants.", "startOffset": 0, "endOffset": 5}, {"referenceID": 116, "context": "There are different definitions of watershed [119, 120].", "startOffset": 45, "endOffset": 55}, {"referenceID": 117, "context": "There are different definitions of watershed [119, 120].", "startOffset": 45, "endOffset": 55}, {"referenceID": 116, "context": "The most popular definition is the watershed by flooding [119]; and the idea is to place a water source in each local minimum (marker), then flooding the image from the markers, and building barriers at the points of the first contact of different water sources.", "startOffset": 57, "endOffset": 62}, {"referenceID": 118, "context": "The most common implementation of watershed for image segmentation can be found in [121].", "startOffset": 83, "endOffset": 88}, {"referenceID": 119, "context": "[122] applied the watershed to segment the preprocessed BUS images and the markers were selected based on grey level and connectivity.", "startOffset": 0, "endOffset": 5}, {"referenceID": 106, "context": "[109, 123] used watershed to segment ROI into small regions, and used the predefined criteria (area, mean intensity, geodesic center, etc) to determine the final tumor region.", "startOffset": 0, "endOffset": 10}, {"referenceID": 120, "context": "[109, 123] used watershed to segment ROI into small regions, and used the predefined criteria (area, mean intensity, geodesic center, etc) to determine the final tumor region.", "startOffset": 0, "endOffset": 10}, {"referenceID": 121, "context": "255 groups of markers were selected by thresholding (th = 1, 2, \u22ef, 255) the image [124, 125]; the external and the internal markers were defined by using the morphological dilation and erosion.", "startOffset": 82, "endOffset": 92}, {"referenceID": 122, "context": "255 groups of markers were selected by thresholding (th = 1, 2, \u22ef, 255) the image [124, 125]; the external and the internal markers were defined by using the morphological dilation and erosion.", "startOffset": 82, "endOffset": 92}, {"referenceID": 123, "context": "[126, 127] applied watershed to determine the boundaries of gray level images.", "startOffset": 0, "endOffset": 10}, {"referenceID": 124, "context": "[126, 127] applied watershed to determine the boundaries of gray level images.", "startOffset": 0, "endOffset": 10}, {"referenceID": 125, "context": "[128] applied watershed to generate meaningful regions, and refined the regions by removing the top 50% hyper-echogenic (bright) regions and the regions connected to the image border to generate candidate tumor regions; the candidate regions were distinguished between tumors and non-tumors by using a logistic regression classifier [129] trained using region morphology, intensity and texture features.", "startOffset": 0, "endOffset": 5}, {"referenceID": 126, "context": "[128] applied watershed to generate meaningful regions, and refined the regions by removing the top 50% hyper-echogenic (bright) regions and the regions connected to the image border to generate candidate tumor regions; the candidate regions were distinguished between tumors and non-tumors by using a logistic regression classifier [129] trained using region morphology, intensity and texture features.", "startOffset": 333, "endOffset": 338}, {"referenceID": 107, "context": "[110, 111] Global thresholding Pre-segmentation Fixed threshold Depended on image enhancement; could not adapt to variations of image quality.", "startOffset": 0, "endOffset": 10}, {"referenceID": 108, "context": "[110, 111] Global thresholding Pre-segmentation Fixed threshold Depended on image enhancement; could not adapt to variations of image quality.", "startOffset": 0, "endOffset": 10}, {"referenceID": 110, "context": "[113] Global thresholding Candidate tumor region generation Iterative thresholding by finding the local minima of histogram.", "startOffset": 0, "endOffset": 5}, {"referenceID": 112, "context": "[115] Global thresholding ROI generation Otsu\u2019s algorithm [130] Depended on image preprocessing.", "startOffset": 0, "endOffset": 5}, {"referenceID": 127, "context": "[115] Global thresholding ROI generation Otsu\u2019s algorithm [130] Depended on image preprocessing.", "startOffset": 58, "endOffset": 63}, {"referenceID": 54, "context": "[55] Region grow Pre-segmentation Selected seed by formulating empirical rules.", "startOffset": 0, "endOffset": 4}, {"referenceID": 114, "context": "[117] Region grow Final segmentation User interaction to set an elliptical seed region Depended on image enhancement; the growth criteria were defined by formulating contour roughness and region inhomogeneity.", "startOffset": 0, "endOffset": 5}, {"referenceID": 119, "context": "[122] Watershed Final segmentation Selected marker by using intensity and connectivity Depended on image enhancement.", "startOffset": 0, "endOffset": 5}, {"referenceID": 121, "context": "[124] Watershed Pre-segmentation Decided the external and internal markers by computing the Beucher gradient [131] of the morphological dilation and erosion of the binary image Depended on image preprocessing; select 255 groups of markers by thresholding image using thresholds from 0 to 255; needed additional geometrical measure [132, 133] to decide the final tumor contour.", "startOffset": 0, "endOffset": 5}, {"referenceID": 128, "context": "[124] Watershed Pre-segmentation Decided the external and internal markers by computing the Beucher gradient [131] of the morphological dilation and erosion of the binary image Depended on image preprocessing; select 255 groups of markers by thresholding image using thresholds from 0 to 255; needed additional geometrical measure [132, 133] to decide the final tumor contour.", "startOffset": 109, "endOffset": 114}, {"referenceID": 129, "context": "[124] Watershed Pre-segmentation Decided the external and internal markers by computing the Beucher gradient [131] of the morphological dilation and erosion of the binary image Depended on image preprocessing; select 255 groups of markers by thresholding image using thresholds from 0 to 255; needed additional geometrical measure [132, 133] to decide the final tumor contour.", "startOffset": 331, "endOffset": 341}, {"referenceID": 130, "context": "[124] Watershed Pre-segmentation Decided the external and internal markers by computing the Beucher gradient [131] of the morphological dilation and erosion of the binary image Depended on image preprocessing; select 255 groups of markers by thresholding image using thresholds from 0 to 255; needed additional geometrical measure [132, 133] to decide the final tumor contour.", "startOffset": 331, "endOffset": 341}, {"referenceID": 124, "context": "[127] Watershed Pre-segmentation Used regions on the binary edge map as markers Depended on empirical rules to refine the results [128] Watershed Pre-segmentation Local intensity minima Depended on empirical rules to refine the results In this section, we present the theoretic background of three classical image segmentation approaches: thresholding, region growing and Watershed; and discuss their applications to BUS image segmentation.", "startOffset": 0, "endOffset": 5}, {"referenceID": 125, "context": "[127] Watershed Pre-segmentation Used regions on the binary edge map as markers Depended on empirical rules to refine the results [128] Watershed Pre-segmentation Local intensity minima Depended on empirical rules to refine the results In this section, we present the theoretic background of three classical image segmentation approaches: thresholding, region growing and Watershed; and discuss their applications to BUS image segmentation.", "startOffset": 130, "endOffset": 135}, {"referenceID": 130, "context": "Cellular automata (CA): CA was introduced by von Neumann [133] and applied to interactive image segmentation [134].", "startOffset": 57, "endOffset": 62}, {"referenceID": 0, "context": "Each element in the state set St has three components: the cell label (lp), cell strength ( \u2208 [0, 1]), and feature vector (Vp).", "startOffset": 94, "endOffset": 100}, {"referenceID": 0, "context": "where cell q belongs to ( ), and ( , ) \u2208 [0, 1] is the transition function usually defined on the similarity between and .", "startOffset": 41, "endOffset": 47}, {"referenceID": 131, "context": "[135] constructed the transition function by integrating the global information on the transition chain and local texture correlation.", "startOffset": 0, "endOffset": 5}, {"referenceID": 133, "context": "For a fast CA-based segmentation approach, refer [137].", "startOffset": 49, "endOffset": 54}, {"referenceID": 134, "context": "[138] proposed a cell-competition approach for BUS image segmentation.", "startOffset": 0, "endOffset": 5}, {"referenceID": 134, "context": "[138] applied the cell competition approach to partition manually selected image ROI into several regions, and to form the final tumor ROI by user interaction.", "startOffset": 0, "endOffset": 5}, {"referenceID": 135, "context": "[139] applied the approach to an initial slice selected by user, and used the results to partition the cells of other slices into object or background regions.", "startOffset": 0, "endOffset": 5}, {"referenceID": 136, "context": "[140] extended the approach to segment 3D BUS image, and applied Graph cuts to image regions for finding the final tumor boundary.", "startOffset": 0, "endOffset": 5}, {"referenceID": 137, "context": "(41)) which was proposed in [141] to segment mammograms.", "startOffset": 28, "endOffset": 33}, {"referenceID": 0, "context": "It takes values in [-1, 1]; RGI value 1 indicates that all the gradients point outward along the radial vector; and -1 signifies that all the gradients point inward along the radial vector.", "startOffset": 19, "endOffset": 26}, {"referenceID": 138, "context": "[142] applied RGI to perform tumor detection.", "startOffset": 0, "endOffset": 5}, {"referenceID": 138, "context": "In [142], the contour with max ARD value [25,26] was chosen as the final tumor contour.", "startOffset": 3, "endOffset": 8}, {"referenceID": 24, "context": "In [142], the contour with max ARD value [25,26] was chosen as the final tumor contour.", "startOffset": 41, "endOffset": 48}, {"referenceID": 25, "context": "In [142], the contour with max ARD value [25,26] was chosen as the final tumor contour.", "startOffset": 41, "endOffset": 48}, {"referenceID": 139, "context": "In [143, 144], a NN with five 5 hidden units was used to classify the candidate lesions into true positive and false positive; Kuo et al.", "startOffset": 3, "endOffset": 13}, {"referenceID": 140, "context": "In [143, 144], a NN with five 5 hidden units was used to classify the candidate lesions into true positive and false positive; Kuo et al.", "startOffset": 3, "endOffset": 13}, {"referenceID": 141, "context": "[145, 146] applied RGI to find the initial tumor contour of 3D BUS image.", "startOffset": 0, "endOffset": 10}, {"referenceID": 142, "context": "[145, 146] applied RGI to find the initial tumor contour of 3D BUS image.", "startOffset": 0, "endOffset": 10}, {"referenceID": 143, "context": "46 / 71 In ultrasound imaging, speckle noise is inherent to coherent illumination and Rayleigh scattering caused by tissue microstructures [147], and it is a major difficulty in BUS image segmentation.", "startOffset": 139, "endOffset": 144}, {"referenceID": 144, "context": ", mean filter, Gaussian low-pass filter, speckle reducing anisotropic diffusion (SRAD) [148], nonlinear coherence diffusion (NCD) [149], sticks filter [60], bilateral filter [150, 151], fractional subpixel diffusion [157], etc.", "startOffset": 87, "endOffset": 92}, {"referenceID": 145, "context": ", mean filter, Gaussian low-pass filter, speckle reducing anisotropic diffusion (SRAD) [148], nonlinear coherence diffusion (NCD) [149], sticks filter [60], bilateral filter [150, 151], fractional subpixel diffusion [157], etc.", "startOffset": 130, "endOffset": 135}, {"referenceID": 59, "context": ", mean filter, Gaussian low-pass filter, speckle reducing anisotropic diffusion (SRAD) [148], nonlinear coherence diffusion (NCD) [149], sticks filter [60], bilateral filter [150, 151], fractional subpixel diffusion [157], etc.", "startOffset": 151, "endOffset": 155}, {"referenceID": 146, "context": ", mean filter, Gaussian low-pass filter, speckle reducing anisotropic diffusion (SRAD) [148], nonlinear coherence diffusion (NCD) [149], sticks filter [60], bilateral filter [150, 151], fractional subpixel diffusion [157], etc.", "startOffset": 174, "endOffset": 184}, {"referenceID": 147, "context": ", mean filter, Gaussian low-pass filter, speckle reducing anisotropic diffusion (SRAD) [148], nonlinear coherence diffusion (NCD) [149], sticks filter [60], bilateral filter [150, 151], fractional subpixel diffusion [157], etc.", "startOffset": 174, "endOffset": 184}, {"referenceID": 153, "context": ", mean filter, Gaussian low-pass filter, speckle reducing anisotropic diffusion (SRAD) [148], nonlinear coherence diffusion (NCD) [149], sticks filter [60], bilateral filter [150, 151], fractional subpixel diffusion [157], etc.", "startOffset": 216, "endOffset": 221}, {"referenceID": 21, "context": "Mean filter and Gaussian low-pass filter are simple and fast, and widely used in early BUS segmentation approaches [22, 52, 61, 59, 62, 63, 109, 115, 112, 123, 133, 138]; SRAD, NCD, sticks filter, and fractional subpixel diffusion are specially designed to deal with speckle noise, and because of their excellent property in edge preservation, these approaches obtained popularity in BUS segmentation [34, 58, 65, 89, 95, 103, 105, 106, 113, 114, 124, 125, 158, 165, 166].", "startOffset": 115, "endOffset": 169}, {"referenceID": 51, "context": "Mean filter and Gaussian low-pass filter are simple and fast, and widely used in early BUS segmentation approaches [22, 52, 61, 59, 62, 63, 109, 115, 112, 123, 133, 138]; SRAD, NCD, sticks filter, and fractional subpixel diffusion are specially designed to deal with speckle noise, and because of their excellent property in edge preservation, these approaches obtained popularity in BUS segmentation [34, 58, 65, 89, 95, 103, 105, 106, 113, 114, 124, 125, 158, 165, 166].", "startOffset": 115, "endOffset": 169}, {"referenceID": 60, "context": "Mean filter and Gaussian low-pass filter are simple and fast, and widely used in early BUS segmentation approaches [22, 52, 61, 59, 62, 63, 109, 115, 112, 123, 133, 138]; SRAD, NCD, sticks filter, and fractional subpixel diffusion are specially designed to deal with speckle noise, and because of their excellent property in edge preservation, these approaches obtained popularity in BUS segmentation [34, 58, 65, 89, 95, 103, 105, 106, 113, 114, 124, 125, 158, 165, 166].", "startOffset": 115, "endOffset": 169}, {"referenceID": 58, "context": "Mean filter and Gaussian low-pass filter are simple and fast, and widely used in early BUS segmentation approaches [22, 52, 61, 59, 62, 63, 109, 115, 112, 123, 133, 138]; SRAD, NCD, sticks filter, and fractional subpixel diffusion are specially designed to deal with speckle noise, and because of their excellent property in edge preservation, these approaches obtained popularity in BUS segmentation [34, 58, 65, 89, 95, 103, 105, 106, 113, 114, 124, 125, 158, 165, 166].", "startOffset": 115, "endOffset": 169}, {"referenceID": 61, "context": "Mean filter and Gaussian low-pass filter are simple and fast, and widely used in early BUS segmentation approaches [22, 52, 61, 59, 62, 63, 109, 115, 112, 123, 133, 138]; SRAD, NCD, sticks filter, and fractional subpixel diffusion are specially designed to deal with speckle noise, and because of their excellent property in edge preservation, these approaches obtained popularity in BUS segmentation [34, 58, 65, 89, 95, 103, 105, 106, 113, 114, 124, 125, 158, 165, 166].", "startOffset": 115, "endOffset": 169}, {"referenceID": 62, "context": "Mean filter and Gaussian low-pass filter are simple and fast, and widely used in early BUS segmentation approaches [22, 52, 61, 59, 62, 63, 109, 115, 112, 123, 133, 138]; SRAD, NCD, sticks filter, and fractional subpixel diffusion are specially designed to deal with speckle noise, and because of their excellent property in edge preservation, these approaches obtained popularity in BUS segmentation [34, 58, 65, 89, 95, 103, 105, 106, 113, 114, 124, 125, 158, 165, 166].", "startOffset": 115, "endOffset": 169}, {"referenceID": 106, "context": "Mean filter and Gaussian low-pass filter are simple and fast, and widely used in early BUS segmentation approaches [22, 52, 61, 59, 62, 63, 109, 115, 112, 123, 133, 138]; SRAD, NCD, sticks filter, and fractional subpixel diffusion are specially designed to deal with speckle noise, and because of their excellent property in edge preservation, these approaches obtained popularity in BUS segmentation [34, 58, 65, 89, 95, 103, 105, 106, 113, 114, 124, 125, 158, 165, 166].", "startOffset": 115, "endOffset": 169}, {"referenceID": 112, "context": "Mean filter and Gaussian low-pass filter are simple and fast, and widely used in early BUS segmentation approaches [22, 52, 61, 59, 62, 63, 109, 115, 112, 123, 133, 138]; SRAD, NCD, sticks filter, and fractional subpixel diffusion are specially designed to deal with speckle noise, and because of their excellent property in edge preservation, these approaches obtained popularity in BUS segmentation [34, 58, 65, 89, 95, 103, 105, 106, 113, 114, 124, 125, 158, 165, 166].", "startOffset": 115, "endOffset": 169}, {"referenceID": 109, "context": "Mean filter and Gaussian low-pass filter are simple and fast, and widely used in early BUS segmentation approaches [22, 52, 61, 59, 62, 63, 109, 115, 112, 123, 133, 138]; SRAD, NCD, sticks filter, and fractional subpixel diffusion are specially designed to deal with speckle noise, and because of their excellent property in edge preservation, these approaches obtained popularity in BUS segmentation [34, 58, 65, 89, 95, 103, 105, 106, 113, 114, 124, 125, 158, 165, 166].", "startOffset": 115, "endOffset": 169}, {"referenceID": 120, "context": "Mean filter and Gaussian low-pass filter are simple and fast, and widely used in early BUS segmentation approaches [22, 52, 61, 59, 62, 63, 109, 115, 112, 123, 133, 138]; SRAD, NCD, sticks filter, and fractional subpixel diffusion are specially designed to deal with speckle noise, and because of their excellent property in edge preservation, these approaches obtained popularity in BUS segmentation [34, 58, 65, 89, 95, 103, 105, 106, 113, 114, 124, 125, 158, 165, 166].", "startOffset": 115, "endOffset": 169}, {"referenceID": 130, "context": "Mean filter and Gaussian low-pass filter are simple and fast, and widely used in early BUS segmentation approaches [22, 52, 61, 59, 62, 63, 109, 115, 112, 123, 133, 138]; SRAD, NCD, sticks filter, and fractional subpixel diffusion are specially designed to deal with speckle noise, and because of their excellent property in edge preservation, these approaches obtained popularity in BUS segmentation [34, 58, 65, 89, 95, 103, 105, 106, 113, 114, 124, 125, 158, 165, 166].", "startOffset": 115, "endOffset": 169}, {"referenceID": 134, "context": "Mean filter and Gaussian low-pass filter are simple and fast, and widely used in early BUS segmentation approaches [22, 52, 61, 59, 62, 63, 109, 115, 112, 123, 133, 138]; SRAD, NCD, sticks filter, and fractional subpixel diffusion are specially designed to deal with speckle noise, and because of their excellent property in edge preservation, these approaches obtained popularity in BUS segmentation [34, 58, 65, 89, 95, 103, 105, 106, 113, 114, 124, 125, 158, 165, 166].", "startOffset": 115, "endOffset": 169}, {"referenceID": 33, "context": "Mean filter and Gaussian low-pass filter are simple and fast, and widely used in early BUS segmentation approaches [22, 52, 61, 59, 62, 63, 109, 115, 112, 123, 133, 138]; SRAD, NCD, sticks filter, and fractional subpixel diffusion are specially designed to deal with speckle noise, and because of their excellent property in edge preservation, these approaches obtained popularity in BUS segmentation [34, 58, 65, 89, 95, 103, 105, 106, 113, 114, 124, 125, 158, 165, 166].", "startOffset": 401, "endOffset": 471}, {"referenceID": 57, "context": "Mean filter and Gaussian low-pass filter are simple and fast, and widely used in early BUS segmentation approaches [22, 52, 61, 59, 62, 63, 109, 115, 112, 123, 133, 138]; SRAD, NCD, sticks filter, and fractional subpixel diffusion are specially designed to deal with speckle noise, and because of their excellent property in edge preservation, these approaches obtained popularity in BUS segmentation [34, 58, 65, 89, 95, 103, 105, 106, 113, 114, 124, 125, 158, 165, 166].", "startOffset": 401, "endOffset": 471}, {"referenceID": 64, "context": "Mean filter and Gaussian low-pass filter are simple and fast, and widely used in early BUS segmentation approaches [22, 52, 61, 59, 62, 63, 109, 115, 112, 123, 133, 138]; SRAD, NCD, sticks filter, and fractional subpixel diffusion are specially designed to deal with speckle noise, and because of their excellent property in edge preservation, these approaches obtained popularity in BUS segmentation [34, 58, 65, 89, 95, 103, 105, 106, 113, 114, 124, 125, 158, 165, 166].", "startOffset": 401, "endOffset": 471}, {"referenceID": 88, "context": "Mean filter and Gaussian low-pass filter are simple and fast, and widely used in early BUS segmentation approaches [22, 52, 61, 59, 62, 63, 109, 115, 112, 123, 133, 138]; SRAD, NCD, sticks filter, and fractional subpixel diffusion are specially designed to deal with speckle noise, and because of their excellent property in edge preservation, these approaches obtained popularity in BUS segmentation [34, 58, 65, 89, 95, 103, 105, 106, 113, 114, 124, 125, 158, 165, 166].", "startOffset": 401, "endOffset": 471}, {"referenceID": 92, "context": "Mean filter and Gaussian low-pass filter are simple and fast, and widely used in early BUS segmentation approaches [22, 52, 61, 59, 62, 63, 109, 115, 112, 123, 133, 138]; SRAD, NCD, sticks filter, and fractional subpixel diffusion are specially designed to deal with speckle noise, and because of their excellent property in edge preservation, these approaches obtained popularity in BUS segmentation [34, 58, 65, 89, 95, 103, 105, 106, 113, 114, 124, 125, 158, 165, 166].", "startOffset": 401, "endOffset": 471}, {"referenceID": 100, "context": "Mean filter and Gaussian low-pass filter are simple and fast, and widely used in early BUS segmentation approaches [22, 52, 61, 59, 62, 63, 109, 115, 112, 123, 133, 138]; SRAD, NCD, sticks filter, and fractional subpixel diffusion are specially designed to deal with speckle noise, and because of their excellent property in edge preservation, these approaches obtained popularity in BUS segmentation [34, 58, 65, 89, 95, 103, 105, 106, 113, 114, 124, 125, 158, 165, 166].", "startOffset": 401, "endOffset": 471}, {"referenceID": 102, "context": "Mean filter and Gaussian low-pass filter are simple and fast, and widely used in early BUS segmentation approaches [22, 52, 61, 59, 62, 63, 109, 115, 112, 123, 133, 138]; SRAD, NCD, sticks filter, and fractional subpixel diffusion are specially designed to deal with speckle noise, and because of their excellent property in edge preservation, these approaches obtained popularity in BUS segmentation [34, 58, 65, 89, 95, 103, 105, 106, 113, 114, 124, 125, 158, 165, 166].", "startOffset": 401, "endOffset": 471}, {"referenceID": 103, "context": "Mean filter and Gaussian low-pass filter are simple and fast, and widely used in early BUS segmentation approaches [22, 52, 61, 59, 62, 63, 109, 115, 112, 123, 133, 138]; SRAD, NCD, sticks filter, and fractional subpixel diffusion are specially designed to deal with speckle noise, and because of their excellent property in edge preservation, these approaches obtained popularity in BUS segmentation [34, 58, 65, 89, 95, 103, 105, 106, 113, 114, 124, 125, 158, 165, 166].", "startOffset": 401, "endOffset": 471}, {"referenceID": 110, "context": "Mean filter and Gaussian low-pass filter are simple and fast, and widely used in early BUS segmentation approaches [22, 52, 61, 59, 62, 63, 109, 115, 112, 123, 133, 138]; SRAD, NCD, sticks filter, and fractional subpixel diffusion are specially designed to deal with speckle noise, and because of their excellent property in edge preservation, these approaches obtained popularity in BUS segmentation [34, 58, 65, 89, 95, 103, 105, 106, 113, 114, 124, 125, 158, 165, 166].", "startOffset": 401, "endOffset": 471}, {"referenceID": 111, "context": "Mean filter and Gaussian low-pass filter are simple and fast, and widely used in early BUS segmentation approaches [22, 52, 61, 59, 62, 63, 109, 115, 112, 123, 133, 138]; SRAD, NCD, sticks filter, and fractional subpixel diffusion are specially designed to deal with speckle noise, and because of their excellent property in edge preservation, these approaches obtained popularity in BUS segmentation [34, 58, 65, 89, 95, 103, 105, 106, 113, 114, 124, 125, 158, 165, 166].", "startOffset": 401, "endOffset": 471}, {"referenceID": 121, "context": "Mean filter and Gaussian low-pass filter are simple and fast, and widely used in early BUS segmentation approaches [22, 52, 61, 59, 62, 63, 109, 115, 112, 123, 133, 138]; SRAD, NCD, sticks filter, and fractional subpixel diffusion are specially designed to deal with speckle noise, and because of their excellent property in edge preservation, these approaches obtained popularity in BUS segmentation [34, 58, 65, 89, 95, 103, 105, 106, 113, 114, 124, 125, 158, 165, 166].", "startOffset": 401, "endOffset": 471}, {"referenceID": 122, "context": "Mean filter and Gaussian low-pass filter are simple and fast, and widely used in early BUS segmentation approaches [22, 52, 61, 59, 62, 63, 109, 115, 112, 123, 133, 138]; SRAD, NCD, sticks filter, and fractional subpixel diffusion are specially designed to deal with speckle noise, and because of their excellent property in edge preservation, these approaches obtained popularity in BUS segmentation [34, 58, 65, 89, 95, 103, 105, 106, 113, 114, 124, 125, 158, 165, 166].", "startOffset": 401, "endOffset": 471}, {"referenceID": 154, "context": "Mean filter and Gaussian low-pass filter are simple and fast, and widely used in early BUS segmentation approaches [22, 52, 61, 59, 62, 63, 109, 115, 112, 123, 133, 138]; SRAD, NCD, sticks filter, and fractional subpixel diffusion are specially designed to deal with speckle noise, and because of their excellent property in edge preservation, these approaches obtained popularity in BUS segmentation [34, 58, 65, 89, 95, 103, 105, 106, 113, 114, 124, 125, 158, 165, 166].", "startOffset": 401, "endOffset": 471}, {"referenceID": 161, "context": "Mean filter and Gaussian low-pass filter are simple and fast, and widely used in early BUS segmentation approaches [22, 52, 61, 59, 62, 63, 109, 115, 112, 123, 133, 138]; SRAD, NCD, sticks filter, and fractional subpixel diffusion are specially designed to deal with speckle noise, and because of their excellent property in edge preservation, these approaches obtained popularity in BUS segmentation [34, 58, 65, 89, 95, 103, 105, 106, 113, 114, 124, 125, 158, 165, 166].", "startOffset": 401, "endOffset": 471}, {"referenceID": 162, "context": "Mean filter and Gaussian low-pass filter are simple and fast, and widely used in early BUS segmentation approaches [22, 52, 61, 59, 62, 63, 109, 115, 112, 123, 133, 138]; SRAD, NCD, sticks filter, and fractional subpixel diffusion are specially designed to deal with speckle noise, and because of their excellent property in edge preservation, these approaches obtained popularity in BUS segmentation [34, 58, 65, 89, 95, 103, 105, 106, 113, 114, 124, 125, 158, 165, 166].", "startOffset": 401, "endOffset": 471}, {"referenceID": 148, "context": "The intensity and sensitivity of interaction are two important criteria for evaluating interactive segmentation approaches [152, 153]; because user interaction has large degree of arbitrariness and different interaction may lead to quite different results.", "startOffset": 123, "endOffset": 133}, {"referenceID": 149, "context": "The intensity and sensitivity of interaction are two important criteria for evaluating interactive segmentation approaches [152, 153]; because user interaction has large degree of arbitrariness and different interaction may lead to quite different results.", "startOffset": 123, "endOffset": 133}, {"referenceID": 21, "context": "Many fully automatic approaches [22, 25, 64, 98, 100, 106, 109, 115] have been proposed in the last few years.", "startOffset": 32, "endOffset": 68}, {"referenceID": 24, "context": "Many fully automatic approaches [22, 25, 64, 98, 100, 106, 109, 115] have been proposed in the last few years.", "startOffset": 32, "endOffset": 68}, {"referenceID": 63, "context": "Many fully automatic approaches [22, 25, 64, 98, 100, 106, 109, 115] have been proposed in the last few years.", "startOffset": 32, "endOffset": 68}, {"referenceID": 95, "context": "Many fully automatic approaches [22, 25, 64, 98, 100, 106, 109, 115] have been proposed in the last few years.", "startOffset": 32, "endOffset": 68}, {"referenceID": 97, "context": "Many fully automatic approaches [22, 25, 64, 98, 100, 106, 109, 115] have been proposed in the last few years.", "startOffset": 32, "endOffset": 68}, {"referenceID": 103, "context": "Many fully automatic approaches [22, 25, 64, 98, 100, 106, 109, 115] have been proposed in the last few years.", "startOffset": 32, "endOffset": 68}, {"referenceID": 106, "context": "Many fully automatic approaches [22, 25, 64, 98, 100, 106, 109, 115] have been proposed in the last few years.", "startOffset": 32, "endOffset": 68}, {"referenceID": 112, "context": "Many fully automatic approaches [22, 25, 64, 98, 100, 106, 109, 115] have been proposed in the last few years.", "startOffset": 32, "endOffset": 68}, {"referenceID": 106, "context": "[109] determined tumor ROI by using vertical and horizontal edges detected by using the Canny edge detector.", "startOffset": 0, "endOffset": 5}, {"referenceID": 63, "context": "[64, 98] detected tumor ROI by using a well-trained texture classifier (SVM) to classify image lattices (16\u00d716) into normal tissue and tumor.", "startOffset": 0, "endOffset": 8}, {"referenceID": 95, "context": "[64, 98] detected tumor ROI by using a well-trained texture classifier (SVM) to classify image lattices (16\u00d716) into normal tissue and tumor.", "startOffset": 0, "endOffset": 8}, {"referenceID": 24, "context": "[25] estimated the bounding box of tumor using a binary classifier trained by negative (normal tissues) and positive (tumor) patches.", "startOffset": 0, "endOffset": 4}, {"referenceID": 97, "context": "[100] applied ensemble learning method (Adaboost) to generate a boosted classifier for locating candidate rectangular regions; then these regions were refined by a SVM to generate the final true regions.", "startOffset": 0, "endOffset": 5}, {"referenceID": 103, "context": "[106] formulated the texture, spatial location, and size of the candidate area to", "startOffset": 0, "endOffset": 5}, {"referenceID": 21, "context": "[22, 115] took advantage of the layer structure of BUS image, and proposed the adaptive reference position (RP) generation and multipath search algorithm to locate the tumor ROI quickly, which outperformed the tumor location approaches utilizing fixed and inflexible constraints.", "startOffset": 0, "endOffset": 9}, {"referenceID": 112, "context": "[22, 115] took advantage of the layer structure of BUS image, and proposed the adaptive reference position (RP) generation and multipath search algorithm to locate the tumor ROI quickly, which outperformed the tumor location approaches utilizing fixed and inflexible constraints.", "startOffset": 0, "endOffset": 9}, {"referenceID": 150, "context": "[154] detected tumor in BUS image by estimating tumor\u2019s saliency; the approach modeled both the radiologists\u2019 attention mechanism and the layer structure of BUS image.", "startOffset": 0, "endOffset": 5}, {"referenceID": 61, "context": "[62] and some early works [58-61] detected tumor automatically based on low-level image features, e.", "startOffset": 0, "endOffset": 4}, {"referenceID": 57, "context": "[62] and some early works [58-61] detected tumor automatically based on low-level image features, e.", "startOffset": 26, "endOffset": 33}, {"referenceID": 58, "context": "[62] and some early works [58-61] detected tumor automatically based on low-level image features, e.", "startOffset": 26, "endOffset": 33}, {"referenceID": 59, "context": "[62] and some early works [58-61] detected tumor automatically based on low-level image features, e.", "startOffset": 26, "endOffset": 33}, {"referenceID": 60, "context": "[62] and some early works [58-61] detected tumor automatically based on low-level image features, e.", "startOffset": 26, "endOffset": 33}, {"referenceID": 53, "context": "The approaches [54, 55, 113, 106] constructing empirical formulas to model domain priors provided effective means for tumor detection, but the fixed RP formulated in these approaches limited their robustness and flexibility.", "startOffset": 15, "endOffset": 33}, {"referenceID": 54, "context": "The approaches [54, 55, 113, 106] constructing empirical formulas to model domain priors provided effective means for tumor detection, but the fixed RP formulated in these approaches limited their robustness and flexibility.", "startOffset": 15, "endOffset": 33}, {"referenceID": 110, "context": "The approaches [54, 55, 113, 106] constructing empirical formulas to model domain priors provided effective means for tumor detection, but the fixed RP formulated in these approaches limited their robustness and flexibility.", "startOffset": 15, "endOffset": 33}, {"referenceID": 103, "context": "The approaches [54, 55, 113, 106] constructing empirical formulas to model domain priors provided effective means for tumor detection, but the fixed RP formulated in these approaches limited their robustness and flexibility.", "startOffset": 15, "endOffset": 33}, {"referenceID": 21, "context": ", adaptive RP [22]; the second direction is to improve the generality of the formulas by constructing them in a learning-based framework.", "startOffset": 14, "endOffset": 18}, {"referenceID": 24, "context": "Learning based fully automatic approaches [25, 64, 98, 100] are promising and drawing increasing popularity recently.", "startOffset": 42, "endOffset": 59}, {"referenceID": 63, "context": "Learning based fully automatic approaches [25, 64, 98, 100] are promising and drawing increasing popularity recently.", "startOffset": 42, "endOffset": 59}, {"referenceID": 95, "context": "Learning based fully automatic approaches [25, 64, 98, 100] are promising and drawing increasing popularity recently.", "startOffset": 42, "endOffset": 59}, {"referenceID": 97, "context": "Learning based fully automatic approaches [25, 64, 98, 100] are promising and drawing increasing popularity recently.", "startOffset": 42, "endOffset": 59}, {"referenceID": 21, "context": "[22, 115, 154] obtain fully automatic BUS image segmentation modeling biological priors of BUS images or visual attention mechanism, which open new avenues for fully automatic BUS", "startOffset": 0, "endOffset": 14}, {"referenceID": 112, "context": "[22, 115, 154] obtain fully automatic BUS image segmentation modeling biological priors of BUS images or visual attention mechanism, which open new avenues for fully automatic BUS", "startOffset": 0, "endOffset": 14}, {"referenceID": 150, "context": "[22, 115, 154] obtain fully automatic BUS image segmentation modeling biological priors of BUS images or visual attention mechanism, which open new avenues for fully automatic BUS", "startOffset": 0, "endOffset": 14}, {"referenceID": 6, "context": "In graph-based approaches [7, 9 - 11], Gaussian distribution of tumor intensity is usually applied to define the likelihood energy (data term).", "startOffset": 26, "endOffset": 37}, {"referenceID": 8, "context": "In graph-based approaches [7, 9 - 11], Gaussian distribution of tumor intensity is usually applied to define the likelihood energy (data term).", "startOffset": 26, "endOffset": 37}, {"referenceID": 10, "context": "In graph-based approaches [7, 9 - 11], Gaussian distribution of tumor intensity is usually applied to define the likelihood energy (data term).", "startOffset": 26, "endOffset": 37}, {"referenceID": 66, "context": "[67] model the probability density difference between the intensity distribution of tumor/background region and estimated Rayleigh distribution to improve the performance of GDM.", "startOffset": 0, "endOffset": 4}, {"referenceID": 21, "context": "In [22, 54, 55], no explicit distribution was predefined, and histogram was applied to describe the distribution of tumor region and normal tissues; In [25, 27, 28], supervised learning approaches are introduced to train the classifiers to output the probability of each image region to be tumor or background.", "startOffset": 3, "endOffset": 15}, {"referenceID": 53, "context": "In [22, 54, 55], no explicit distribution was predefined, and histogram was applied to describe the distribution of tumor region and normal tissues; In [25, 27, 28], supervised learning approaches are introduced to train the classifiers to output the probability of each image region to be tumor or background.", "startOffset": 3, "endOffset": 15}, {"referenceID": 54, "context": "In [22, 54, 55], no explicit distribution was predefined, and histogram was applied to describe the distribution of tumor region and normal tissues; In [25, 27, 28], supervised learning approaches are introduced to train the classifiers to output the probability of each image region to be tumor or background.", "startOffset": 3, "endOffset": 15}, {"referenceID": 24, "context": "In [22, 54, 55], no explicit distribution was predefined, and histogram was applied to describe the distribution of tumor region and normal tissues; In [25, 27, 28], supervised learning approaches are introduced to train the classifiers to output the probability of each image region to be tumor or background.", "startOffset": 152, "endOffset": 164}, {"referenceID": 26, "context": "In [22, 54, 55], no explicit distribution was predefined, and histogram was applied to describe the distribution of tumor region and normal tissues; In [25, 27, 28], supervised learning approaches are introduced to train the classifiers to output the probability of each image region to be tumor or background.", "startOffset": 152, "endOffset": 164}, {"referenceID": 27, "context": "In [22, 54, 55], no explicit distribution was predefined, and histogram was applied to describe the distribution of tumor region and normal tissues; In [25, 27, 28], supervised learning approaches are introduced to train the classifiers to output the probability of each image region to be tumor or background.", "startOffset": 152, "endOffset": 164}, {"referenceID": 8, "context": "Texture and other local region features have more descriptive power than intensity, and have been studied in many works [9, 10, 64, 98] that they can distinguish tumor regions from normal tissues with high accuracy.", "startOffset": 120, "endOffset": 135}, {"referenceID": 9, "context": "Texture and other local region features have more descriptive power than intensity, and have been studied in many works [9, 10, 64, 98] that they can distinguish tumor regions from normal tissues with high accuracy.", "startOffset": 120, "endOffset": 135}, {"referenceID": 63, "context": "Texture and other local region features have more descriptive power than intensity, and have been studied in many works [9, 10, 64, 98] that they can distinguish tumor regions from normal tissues with high accuracy.", "startOffset": 120, "endOffset": 135}, {"referenceID": 95, "context": "Texture and other local region features have more descriptive power than intensity, and have been studied in many works [9, 10, 64, 98] that they can distinguish tumor regions from normal tissues with high accuracy.", "startOffset": 120, "endOffset": 135}, {"referenceID": 8, "context": "In [9, 10], the texture distributions are utilized to build the likelihood energy of the graph model.", "startOffset": 3, "endOffset": 10}, {"referenceID": 9, "context": "In [9, 10], the texture distributions are utilized to build the likelihood energy of the graph model.", "startOffset": 3, "endOffset": 10}, {"referenceID": 53, "context": "[54, 55] trained a texture histogram of tumor regions, and incorporated it with the trained intensity distribution to determine the candidate tumor regions.", "startOffset": 0, "endOffset": 8}, {"referenceID": 54, "context": "[54, 55] trained a texture histogram of tumor regions, and incorporated it with the trained intensity distribution to determine the candidate tumor regions.", "startOffset": 0, "endOffset": 8}, {"referenceID": 63, "context": "[64, 98] extracted statistic texture from local regions (16\u00d716 grid), and learned a SVM classifier that could localize tumors accurately.", "startOffset": 0, "endOffset": 8}, {"referenceID": 95, "context": "[64, 98] extracted statistic texture from local regions (16\u00d716 grid), and learned a SVM classifier that could localize tumors accurately.", "startOffset": 0, "endOffset": 8}, {"referenceID": 41, "context": "In edge-based DMs, [42, 50, 52, 56 - 59, 61 - 63], image gradient is applied to constructing the external force or speed function of the evolving curve; as discussed in section 3.", "startOffset": 19, "endOffset": 49}, {"referenceID": 49, "context": "In edge-based DMs, [42, 50, 52, 56 - 59, 61 - 63], image gradient is applied to constructing the external force or speed function of the evolving curve; as discussed in section 3.", "startOffset": 19, "endOffset": 49}, {"referenceID": 51, "context": "In edge-based DMs, [42, 50, 52, 56 - 59, 61 - 63], image gradient is applied to constructing the external force or speed function of the evolving curve; as discussed in section 3.", "startOffset": 19, "endOffset": 49}, {"referenceID": 55, "context": "In edge-based DMs, [42, 50, 52, 56 - 59, 61 - 63], image gradient is applied to constructing the external force or speed function of the evolving curve; as discussed in section 3.", "startOffset": 19, "endOffset": 49}, {"referenceID": 58, "context": "In edge-based DMs, [42, 50, 52, 56 - 59, 61 - 63], image gradient is applied to constructing the external force or speed function of the evolving curve; as discussed in section 3.", "startOffset": 19, "endOffset": 49}, {"referenceID": 60, "context": "In edge-based DMs, [42, 50, 52, 56 - 59, 61 - 63], image gradient is applied to constructing the external force or speed function of the evolving curve; as discussed in section 3.", "startOffset": 19, "endOffset": 49}, {"referenceID": 62, "context": "In edge-based DMs, [42, 50, 52, 56 - 59, 61 - 63], image gradient is applied to constructing the external force or speed function of the evolving curve; as discussed in section 3.", "startOffset": 19, "endOffset": 49}, {"referenceID": 72, "context": "3, because of the speckle noise and week boundary problems, the performance of most approaches depends on both denoising and edge preservation techniques; [73, 75] defined the stop function of GDM for edge detection results in the frequency domain rather than in the spatial domain, which makes the GDM insensitive to image contrast and work well on weak boundaries.", "startOffset": 155, "endOffset": 163}, {"referenceID": 74, "context": "3, because of the speckle noise and week boundary problems, the performance of most approaches depends on both denoising and edge preservation techniques; [73, 75] defined the stop function of GDM for edge detection results in the frequency domain rather than in the spatial domain, which makes the GDM insensitive to image contrast and work well on weak boundaries.", "startOffset": 155, "endOffset": 163}, {"referenceID": 21, "context": "[22, 115] proposed an edge detector in the frequency domain and incorporate it into a graph-based framework, which made the pairwise energy less sensitive to image contrast and brightness.", "startOffset": 0, "endOffset": 9}, {"referenceID": 112, "context": "[22, 115] proposed an edge detector in the frequency domain and incorporate it into a graph-based framework, which made the pairwise energy less sensitive to image contrast and brightness.", "startOffset": 0, "endOffset": 9}], "year": 2017, "abstractText": "Breast cancer is one of the leading causes of cancer death among women worldwide. In clinical routine, automatic breast ultrasound (BUS) image segmentation is very challenging and essential for cancer diagnosis and treatment planning. Many BUS segmentation approaches have been studied in the last two decades, and have been proved to be effective on private datasets. Currently, the advancement of BUS image segmentation seems to meet its bottleneck. The improvement of the performance is increasingly challenging, and only few new approaches were published in the last several years. It is the time to look at the field by reviewing previous approaches comprehensively and to investigate the future directions. In this paper, we study the basic ideas, theories,pros and cons of the approaches, group them into categories, and extensively review each category in depth by discussing the principles, application issues, and advantages/disadvantages. Keyword: breast ultrasound (BUS) images, breast cancer, segmentation, benchmark, early detection, computer-aided diagnosis (CAD)", "creator": null}}}