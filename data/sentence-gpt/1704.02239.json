{"id": "1704.02239", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "7-Apr-2017", "title": "\\'Echantillonnage de signaux sur graphes via des processus d\\'eterminantaux", "abstract": "We consider the problem of sampling k-bandlimited graph signals, \\ie, linear combinations of the first k graph Fourier modes. We know that a set of k nodes embedding all k-bandlimited signals always exists, thereby enabling their perfect reconstruction after sampling. Unfortunately, to exhibit such a set, one needs to partially diagonalize the graph Laplacian, which becomes prohibitive at large scale. We propose a novel strategy based on determinantal point processes that side-steps partial diagonalisation and enables reconstruction with only O(k) samples. While doing so, we exhibit a new general algorithm to sample determinantal process, faster than the state-of-the-art algorithm by an order k. It would be a much more efficient and accurate way to generate and analyze k-bandlimited signal signals, because of its simplicity and ease of implementation. This approach is highly scalable, and in the long run, one cannot rely on any of the O(k) samples for all measurements. We are also working with a new general algorithm to derive the partial diagonalisation algorithm from a graph Laplacian that has the following attributes: linear Fourier, \u03b3s, and \u03b3s. The solution is to provide the solution for a partial diagonalisation, a linear solution of \u03b3s, and \u03b3s in all k-bandlimited channels, where the output from a channel is an integer and contains \u03b3s, and \u03b3s. To obtain a partial diagonalisation, we use a linear Fourier, \u03b3s, and \u03b3s to obtain a partial diagonalisation, a linear solution of \u03b3s, and \u03b3s. We will now use the linear Fourier Fourier Fourier transform for a final distribution of \u03b3s, \u03b3s, and \u03b3s. The solution is to specify the function \u03b3s, \u03b3s, and \u03b3s, and \u03b3s as part of a Fourier transform, a function of \u03b3s, and \u03b3s. The problem is, for example, that \u03b3s will be labeled \u03b3s, \u03b3s, and \u03b3s in a different way in Laplacian. The function \u03b3s is an O(k) sample which can be generated from the given output in any given channel. The solution is to define an O(k) sample which can be generated from a stream of O(k) samples. We use a non-O(k) sample", "histories": [["v1", "Fri, 7 Apr 2017 14:11:36 GMT  (352kb,D)", "https://arxiv.org/abs/1704.02239v1", "in French"], ["v2", "Wed, 5 Jul 2017 09:34:13 GMT  (353kb,D)", "http://arxiv.org/abs/1704.02239v2", "in French"]], "COMMENTS": "in French", "reviews": [], "SUBJECTS": "cs.DS cs.DM cs.LG", "authors": ["nicolas tremblay", "simon barthelme", "pierre-olivier amblard cnrs", "gipsa-cics cnrs", "gipsa-vibs)"], "accepted": false, "id": "1704.02239"}, "pdf": {"name": "1704.02239.pdf", "metadata": {"source": "CRF", "title": "E\u0301chantillonnage de signaux sur graphes via des processus de\u0301terminantaux", "authors": ["Nicolas TREMBLAY", "Simon BARTHELM\u00c9", "Pierre-Olivier AMBLARD"], "emails": ["prenom.nom@gipsa-lab.fr"], "sections": [{"heading": "1 Introduction", "text": "E\u0301tant donne\u0301e une certaine classe de signaux, e\u0301chantillonner consiste a\u0300 mesurer un signal un nombre de fois suffisant pour une certaine ta\u0302che, e.g. a\u0300 des fins de reconstruction. Pour les signaux de\u0301finis sur des graphes, une classe de re\u0301gularite\u0301 souvent utilise\u0301e est celle des signaux a\u0300 bande limite\u0301e k (cf la de\u0301finition 1). Dans ce contexte, il existe deux types de me\u0301thodes d\u2019e\u0301chantillonnage : i) celles qui calculent les k premiers modes de Fourier du graphe et cherchent via des heuristiques k n\u0153uds qui les discriminent tous [2], ii) celles qui s\u2019affranchissent de ce calcul, et qui soit cherchent un nombre de n\u0153uds proche de k et re\u0301solvent des proble\u0300mes combinatoires qui ne passent pas a\u0300 l\u2019e\u0301chelle [3], soit s\u2019autorisent un nombre de n\u0153uds de l\u2019ordre de O(k log k) et permettent de passer a\u0300 l\u2019e\u0301chelle via un e\u0301chantillonnage iid adapte\u0301 au graphe [4], soit via des marches ale\u0301atoires sur graphe spe\u0301cifiques [5]. Contributions. Nous proposons une me\u0301thode base\u0301e sur les processus ponctuels de\u0301terminantaux (PPD) [6], des processus ale\u0301atoires connus pour favoriser la diversite\u0301 des e\u0301chantillons. Nous adaptons un algorithme d\u2019e\u0301chantillonnage de PPD, et montrons comment cet algorithme peut e\u0302tre utilise\u0301 dans le cadre de l\u2019e\u0301chantillonnage des signaux a\u0300 bande limite\u0301e sur graphe."}, {"heading": "2 Notations et objectif", "text": "Les matrices sont en majuscule, e.g. K ; les vecteurs en minuscules et en gras, e.g. x ; les ensembles en cursive, e.g. A ; KA,B est la restriction de K aux lignes (resp. colonnes) indexe\u0301es par les e\u0301le\u0301ments deA (resp. B) ; enfin : KA = KA,A. On note \u03b4s le vecteur dont les entre\u0301es sont nulles sauf en s, et In la matrice identite\u0301 de dimension n. Soit G un graphe compose\u0301 de N n\u0153uds interconnecte\u0301s selon la matrice d\u2019adjacence W \u2208\nRN\u00d7N tel que Wij = Wji > 0 repre\u0301sente le poids associe\u0301 au lien connectant i a\u0300 j. Notons D la matrice diagonale des degre\u0301s : on a Dii = \u2211 j Wij . Le laplacien associe\u0301 a\u0300 G s\u2019e\u0301crit L = D\u2212W \u2208 RN\u00d7N , il est semi-de\u0301fini positif et se diagonalise en L = U\u039bU\u1d40, ou\u0300 U = (u1|u2| . . . |uN ) \u2208 RN\u00d7N est la matrice de ses vecteurs propres et \u039b = diag(\u03bb1, \u03bb2, . . . , \u03bbN ) \u2208 RN\u00d7N la matrice diagonale de ses valeurs propres, range\u0301es dans l\u2019ordre croissant 0 = \u03bb1 6 \u03bb2 6 . . . 6 \u03bbN . Par analogie au traitement du signal discret classique, ui est conside\u0301re\u0301 comme le i-e\u0300me mode de Fourier du graphe [7]. Pour k \u2208 N\u2217, on de\u0301finit Uk = (u1| . . . |uk) \u2208 RN\u00d7k la concate\u0301nation des k premiers modes de Fourier du graphe. Un signal a\u0300 bande limite\u0301e se de\u0301finit alors :\nDe\u0301finition 1 (Signal a\u0300 bande limite\u0301e k). Un signal x \u2208 RN de\u0301fini sur les n\u0153uds d\u2019un graphe G est a\u0300 bande limite\u0301e k \u2208 N\u2217 si x \u2208 span(Uk), i.e., \u2203 \u03b1 \u2208 Rk tel que x = Uk\u03b1.\nEn notant m le nombre de mesures, e\u0301chantillonner consiste a\u0300 choisir un ensemble de m n\u0153uds A = {s1, . . . , sm}. Notons M = (\u03b4s1 |\u03b4s2 | . . . |\u03b4sm)\u1d40 \u2208 Rm\u00d7N la matrice de mesure associe\u0301e : le signal x \u2208 RN mesure\u0301 en A s\u2019e\u0301crit\ny = Mx+ n \u2208 Rm, (1) ou\u0300 n \u2208 Rm est un bruit de mesure. E\u0301tant donne\u0301 que x est suppose\u0301 e\u0302tre a\u0300 bande limite\u0301e k, on le reconstruit a\u0300 partir de sa mesure y en calculant xrec = Uk(MUk)\u2020y, ou\u0300 (MUk)\u2020 est le pseudo-inverse de Moore-Penrose de MUk \u2208 Rm\u00d7k. Notons \u03c31 6 . . . 6 \u03c3k les valeurs singulie\u0300res de MUk. Le signal x est parfaitement reconstructible (au bruit pre\u0300s) a\u0300 partir de y si U\u1d40kM \u1d40MUk est inversible, i.e., si \u03c321 > 0. Dans ce cas :\nxrec = Uk(U \u1d40 kM \u1d40MUk) \u22121U\u1d40kM \u1d40y (2)\n= x+ Uk(U \u1d40 kM \u1d40MUk) \u22121U\u1d40kM \u1d40n. (3)\nar X\niv :1\n70 4.\n02 23\n9v 2\n[ cs\n.D S]\n5 J\nul 2\nAlgorithm 1 E\u0301chantillonner un m-PPD a\u0300 noyau K [8, Sec 2.4] Entre\u0301e : K,m S \u2190 \u2205, de\u0301finir p0 = diag(K) \u2208 RN p\u2190 p0 for n = 1, . . . ,m do :\n\u00b7 Tirer sn avec probabilite\u0301 P(s) = p(s)/ \u2211\ni p(i) \u00b7 S \u2190 S \u222a {sn} \u00b7 Mettre a\u0300 jour p : \u2200i p(i) = p0(i)\u2212 K\u1d40S,iK\u22121S KS,i\nend for Sortie : A \u2190 S.\nParmi tous les choix possibles deA (et donc de M) qui ve\u0301rifient \u03c321 > 0, lesquels sont optimaux? Il existe plusieurs de\u0301finitions d\u2019optimalite\u0301 [5], nous nous inte\u0301ressons ici a\u0300 la suivante :\nAMV = arg max A s.t. |A|=k k\u220f i=1 \u03c32i , (4)\nou\u0300 \u201cMV\u201d signifie \u201cvolume maximal\u201d : en effet, en maximisant le produit des valeurs singulie\u0300res, on maximise le de\u0301terminant de U\u1d40kM\n\u1d40MUk, c\u2019est-a\u0300-dire le volume forme\u0301 par les k lignes e\u0301chantillonne\u0301es de Uk. TrouverAMV est NP-complet [1]. Notre objectif est de s\u2019en approcher, c\u2019est-a\u0300-dire : trouver un ensemble de taille k (comme AMV) ou proche de k tel qu\u2019on ait la meilleure reconstruction possible des signaux a\u0300 bande limite\u0301e k."}, {"heading": "3 Processus de\u0301terminantaux", "text": "Notons [N ] l\u2019ensemble des sous-ensembles de {1, . . . , N} et K \u2208 RN\u00d7N une matrice semi-de\u0301finie positive (SDP). On convient que det(\u2205) = 1. De\u0301finition 2 (m-PPD). Conside\u0301rons un processus ponctuel, i.e., un processus qui tire ale\u0301atoirement un ensemble A \u2208 [N ]. Ce processus est un m-PPD a\u0300 noyau K si : i) P(A) = 0, pour tout A tel que |A| 6= m. ii) P(A) = 1Z det(KA), pour tout A tel que |A| = m, ou\u0300 Z est la constante de normalisation.\nProposition 1. Si K est un noyau de projection, i.e., K = XX\u1d40 avec X \u2208 RN\u00d7d et X\u1d40X = Id, et si d > m, alors l\u2019algorithme 1 e\u0301chantillonne un m-PPD a\u0300 noyau K. De\u0301monstration. Notons Sn (resp. pn(i)) l\u2019ensemble des n e\u0301chantillons obtenus (resp. la valeur de p(i)) a\u0300 l\u2019issue de l\u2019e\u0301tape n de la boucle de l\u2019algorithme 1. On a : Sn = Sn\u22121 \u222a {sn}. En utilisant le comple\u0301ment de Schur, on a : \u2200n \u2208 [1,m] ,\u2200i, det ( KSn\u22121\u222a{i} ) = ( Ki,i \u2212 K\u1d40Sn\u22121,iK \u22121 Sn\u22121KSn\u22121,i ) det ( KSn\u22121\n) = pn\u22121(i) det ( KSn\u22121 ) . (5)\nA\u0300 partir de (5), et sachant que i) K est SDP : \u2200S, det(KS) > 0, ii) d > m, on peut montrer que pn(i) > 0 et \u2211 i pn(i) 6= 0, c\u2019est-a\u0300-dire qu\u2019a\u0300 chaque ite\u0301ration de la boucle, la probabilite\u0301 P(s) est bien de\u0301finie. La boucle e\u0301tant re\u0301pe\u0301te\u0301e m fois, la sortie de l\u2019algorithme, note\u0301e A, est ne\u0301cessairement de taille m, en accord avec le point i) de la De\u0301f. 2. Enfin, montrons que P(A) est conforme au point ii). Par construction de A :\nP(A) = m\u220f l=1 P(sl|s1, s2, . . . , sl\u22121) = m\u220f l=1 pl\u22121(sl)\u2211N i=1 pl\u22121(i) . (6)\nAlgorithm 2 E\u0301chantillonner un m-PPD, algorithme e\u0301quivalent Entre\u0301e : K = [k1, . . . ,kN ],m S \u2190 \u2205, de\u0301finir p = diag(K) \u2208 RN for n = 1, . . . ,m do :\n\u00b7 Tirer sn avec probabilite\u0301 P(s) = p(s)/ \u2211\ni p(i) \u00b7 S \u2190 S \u222a {sn} \u00b7 Calculer fn = ksn \u2212 \u2211n\u22121 l=1 flfl(sn)\n\u00b7 Normaliser fn \u2190 fn/ \u221a fn(sn)\n\u00b7 Mettre a\u0300 jour p : \u2200i p(i)\u2190 p(i)\u2212 fn(i)2 end for Sortie : A \u2190 S.\nOr, en e\u0301crivant (5) pour i = sn, et en ite\u0301rant, on obtient :\u220fm l=1 pl\u22121(sl) = det(KA). Reste a\u0300 montrer que le de\u0301nominateur de (6) ne de\u0301pend pas des e\u0301chantillons choisis. C\u2019est la\u0300 ou\u0300 l\u2019hypothe\u0300se d\u2019un noyau de projection est essentielle. On a :\n\u2200l \u2208 [1,m], N\u2211 i=1 pl\u22121(i) = N\u2211 i=1 p0(i)\u2212 N\u2211 i=1 K\u1d40Sl\u22121,iK \u22121 Sl\u22121KSl\u22121,i\nOn a \u2211N\ni=1 p0(i) = Tr(XX \u1d40) = Tr(X\u1d40X) = d. De plus, soit M\nla matrice de mesure associe\u0301e a\u0300 Sl\u22121 : N\u2211 i=1 K\u1d40Sl\u22121,iK \u22121 Sl\u22121KSl\u22121,i = Tr ( XX\u1d40M\u1d40(MXX\u1d40M\u1d40)\u22121MXX\u1d40 ) = Tr ( (MXX\u1d40M\u1d40)\u22121MXX\u1d40XX\u1d40M ) = Tr(Il\u22121) = l \u2212 1,\npar invariance de la trace aux permutations circulaires. Ainsi :\nP(A) = 1 Z det(KA) avec Z = m\u220f l=1 d\u2212 l + 1, (7)\nce qui termine la preuve.\nAMV, l\u2019ensemble a\u0300 approcher, est l\u2019ensemble le plus probable du m-PPD (avec m = k) a\u0300 noyau Kk = UkU \u1d40 k . Si nous avons les ressources pour calculer Uk, une premie\u0300re strate\u0301gie d\u2019e\u0301chantillonnage est donc l\u2019Alg. 1 applique\u0301 a\u0300 Kk. Dans le cas contraire, nous proposons dans la suite un nouvel algorithme d\u2019e\u0301chantillonnage de m-PPD, de complexite\u0301 infe\u0301rieure d\u2019un facteurm, qui permet d\u2019appliquer des techniques d\u2019approximation polynomiale, e\u0301vitant ainsi toute e\u0301tape de diagonalisation."}, {"heading": "4 Approximation via des filtres sur graphe", "text": ""}, {"heading": "4.1 Re\u0301e\u0301criture de l\u2019algorithme d\u2019e\u0301chantillonnage", "text": "Proposition 2. L\u2019algorithme 2 est e\u0301quivalent a\u0300 l\u2019algorithme 1 : il e\u0301chantillonne aussi un m-PPD a\u0300 noyau de projection K. De\u0301monstration. Conside\u0301rons Sn,Sn\u22121, pn(i) de\u0301finis comme pre\u0301ce\u0301demment et montrons que les pn(i) dans les boucles des deux algorithmes sont e\u0301gaux. Dans l\u2019Alg. 2 : pn(i) = pn\u22121(i)\u2212 fn(i) 2 = p0(i) \u2212 \u2211n l=1 fl(i) 2 (ou\u0300 les {fi} sont de\u0301finis dans l\u2019algorithme ; notamment : f1 = ks1 ). En comparant avec pn(i) obtenu dans l\u2019Alg. 1, il suffit de montrer que :\n\u2200n\u2200i n\u2211\nl=1\nfl(i) 2 = K\u1d40Sn,iK \u22121 Sn KSn,i. (8)\nNous allons montrer plus ge\u0301ne\u0301ralement que :\n\u2200n\u2200i, j n\u2211\nl=1\nfl(i)fl(j) = K \u1d40 Sn,iK \u22121 Sn KSn,j . (9)\nPour ce faire, nous proposons une re\u0301currence. Initialisation. C\u2019est vrai pour n = 1, ou\u0300 Sn est re\u0301duit a\u0300 {s1} : \u2200i, j K\u1d40Sn,iK \u22121 Sn KSn,j = Ks1,iKs1,j/Ks1,s1 = f1(i)f1(j).\nHypothe\u0300se. Supposons que (9) est vraie a\u0300 l\u2019e\u0301tape n\u2212 1. Re\u0301currence. Montrons qu\u2019elle est e\u0301galement vraie a\u0300 l\u2019e\u0301tape n. En utilisant l\u2019identite\u0301 de Woodbury sur K\u22121Sn , on montre que :\nK\u1d40Sn,iK \u22121 Sn KSn,j = K \u1d40 Sn\u22121,iK \u22121 Sn\u22121KSn\u22121,j +\nzn(i)zn(j)\nzn(sn) ,\nou\u0300 zn(i) = Ksn,i \u2212 K\u1d40Sn\u22121,snK \u22121 Sn\u22121KSn\u22121,i. En remplac\u0327ant K\u1d40Sn\u22121,iK \u22121 Sn\u22121KSn\u22121,j par \u2211n\u22121 l=1 fl(i)fl(j) gra\u0302ce a\u0300 l\u2019hypothe\u0300se, il nous reste a\u0300 montrer que :\n\u2200i, j fn(i)fn(j) = zn(i)zn(j)\nzn(sn) . (10)\nOr, par construction dans l\u2019Algorithme 2, fn(i) s\u2019e\u0301crit :\n\u2200i fn(i) = Ksn,i \u2212 \u2211n\u22121 l=1 fl(i)fl(sn)\u221a\nKsn \u2212 \u2211n\u22121 l=1 fl(sn) 2 . (11)\nEn utilisant une seconde fois l\u2019hypothe\u0300se (2), on montre que :\n\u2200i fn(i) = zn(i)\u221a zn(sn) , (12)\nce qui prouve (10) et termine la preuve.\nL\u2019algorithme 2 est un algorithme ge\u0301ne\u0301ral pour e\u0301chantillonner unm-PPD a\u0300 noyau de projection. Sa complexite\u0301 est enO(Nm2), alors que la complexite\u0301 de l\u2019algorithme 1 est en O(Nm3). Notons que des ide\u0301es similaires pour re\u0301duire la complexite\u0301 d\u2019un facteur m existent dans la litte\u0301rature (par exemple dans [9]) mais sous des formes un peu cache\u0301es, et, a\u0300 notre connaissance, n\u2019ont jamais e\u0301te\u0301 vraiment explicite\u0301es dans le cas discret."}, {"heading": "4.2 Approcher l\u2019e\u0301chantillonnage d\u2019un PPD", "text": "Nous allons voir que la manie\u0300re dont l\u2019algorithme 2 fait appel a\u0300 K permet de tirer profit d\u2019approximations polynomiales usuellement utilise\u0301es lors d\u2019ope\u0301rations de filtrage sur graphe. Rappelons que nous conside\u0301rons le m-PPD associe\u0301 au noyau Kk. Or : Kk = Uhk(\u039b)U\u1d40, ou\u0300 hk(\u039b) = diag(hk(\u03bb1), . . . , hk(\u03bbN )) et hk(\u03bb) est tel que hk(\u03bb) = 1 si \u03bb 6 \u03bbk et hk(\u03bb) = 0 sinon. En traitement du signal sur graphes, Kk est un filtre passe-bas ide\u0301al de fre\u0301quence de coupure \u03bbk. Approximation polynomiale. [7] Conside\u0301rons le polyno\u0302me de Tchebychev h\u0303k de degre\u0301 r qui approche au mieux hk :\n\u2200\u03bb \u2208 [0, \u03bbN ] h\u0303k(\u03bb) = r\u2211\nl=1\n\u03b1l\u03bb l ' hk(\u03bb).\nOn a : Kk ' Uh\u0303k(\u039b)U\u1d40 = r\u2211\nl=1\n\u03b1lU\u039b lU\u1d40 = r\u2211 l=1 \u03b1lL l = h\u0303k(L).\nFiltrage rapide sur graphe. On ne calcule jamais explicitement h\u0303k(L) qui est en ge\u0301ne\u0301ral dense de taille N \u00d7 N . En revanche, e\u0301tant donne\u0301 un signal x de\u0301fini sur le graphe, le signal filtre\u0301 par hk, Kkx, est approche\u0301 par h\u0303k(L)x = \u2211r l=1 \u03b1lL lx,\nAlgorithm 3 E\u0301chantillonnage approche\u0301 d\u2019un m-PPD a\u0300 noyau K = hk(L)\nEntre\u0301e : L, hk(\u03bb), r, m Calculer \u03bbN , la plus grande valeur propre de L Calculer le polyno\u0302me h\u0303k de degre\u0301 r approchant hk sur [0, \u03bbN ] Estimer p = diag(h\u0303k(L)) \u2208 RN comme vu dans la Sec. 4.2 for n = 1, . . . ,m do :\n\u00b7 Tirer sn \u2190 argmax(p) \u00b7 Calculer fn = h\u0303k(L)\u03b4sn \u2212 \u2211n\u22121 l=1 flfl(sn)\n\u00b7 Normaliser fn \u2190 fn/ \u221a fn(sn)\n\u00b7 Mettre a\u0300 jour p(i)\u2190 p(i)\u2212 fn(i)2 end for Output : A = {s1, . . . , sm}\nqui se calcule via r multiplications matrice-vecteur si bien que le nombre d\u2019ope\u0301rations ne\u0301cessaires pour filtrer un signal est de l\u2019ordre de r|E| ou\u0300 |E| est le nombre de liens du graphe. Estimation de la diagonale de Kk. Soit R \u2208 RN\u00d7n une matrice contenant n signaux ale\u0301atoires gaussiens de moyenne nulle et de variance 1/n. Notons que :\nE (\u2225\u2225\u2225\u03b4\u1d40i h\u0303k(L)R\u2225\u2225\u22252) = \u03b4\u1d40i h\u0303k(L)E(RR\u1d40)h\u0303k(L)\u03b4i (13) = \u03b4\u1d40i (h\u0303k(L)) 2\u03b4i ' \u03b4\u1d40i K2k\u03b4i = Kk(i, i) (14)\nLa ie\u0300me valeur de la diagonale de Kk, p0(i), est donc approche\u0301e par la norme de la ie\u0300me ligne de h\u0303k(L)R, i.e. :\np0(i) ' \u2225\u2225\u2225\u03b4\u1d40i h\u0303k(L)R\u2225\u2225\u22252 , (15)\net, via le lemme de Johnson-Lindenstrauss, on montre qu\u2019un nombre de signaux ale\u0301atoires n = O(logN) est suffisant pour avoir une estimation convenable avec haute probabilite\u0301 [10]. Algorithme d\u2019approximation. On souhaite approcher l\u2019algorithme 2 avec entre\u0301e Kk sans avoir a\u0300 calculer Uk. Pour ce faire, on suit l\u2019algorithme 3 en lui donnant comme entre\u0301e 1 L, hk(\u03bb), r = 50 etm le nombre d\u2019e\u0301chantillons souhaite\u0301. Au lieu d\u2019acce\u0301der directement a\u0300 la diagonale d\u2019un noyau K connu, on l\u2019estime a\u0300 l\u2019aide de l\u2019e\u0301quation (15). Puis, au lieu d\u2019acce\u0301der aux colonnes ks directement, on les estime via le filtrage rapide associe\u0301 : ks ' h\u0303k(L)\u03b4s. Au vu des erreurs d\u2019approximation successives, l\u2019e\u0301cart entre les {fl} calcule\u0301s au cours des algorithmes 2 et 3 ne cesse de s\u2019accro\u0131\u0302tre au fur et a\u0300 mesure de la boucle. Pour stabiliser l\u2019algorithme 3 : i) le nouvel e\u0301chantillon est celui qui maximise p (mise a\u0300 part l\u2019estimation de la diagonale de K, l\u2019algorithme n\u2019est donc plus ale\u0301atoire) ; ii) et on s\u2019autorise m > k (ce qui n\u2019a pas de sens pour l\u2019algorithme 2 applique\u0301 a\u0300 Kk qui est de rang k). Aussi, en pratique, on fait quelques modifications mineures : i) apre\u0300s la mise a\u0300 jour de p, on force p(si) = 0 pour tous les e\u0301chantillons si de\u0301ja\u0300 choisis ; ii) lors de la normalisation de fn, si fn(sn) 6 0 a\u0300 cause de l\u2019approximation, alors on normalise fn par \u221a \u2016fn\u2016 /N . Ces choix sont cependant arbitraires : une comparaison rigoureuse des diffe\u0301rentes possibilite\u0301s de stabilisation fera l\u2019objet de travaux futurs.\n1. pour avoir hk(\u03bb), il faut \u03bbk , que nous estimons en suivant [4, Sec. 4.2]."}, {"heading": "5 Simulations", "text": "Trois graphes. Nous conside\u0301rons le graphe routier du Minnesota (N = 2642), le graphe correspondant au maillage 3D d\u2019un objet (graphe \u201cBunny\u201d avecN = 2503), et une re\u0301alisation d\u2019un graphe ale\u0301atoire avec communaute\u0301s issue du mode\u0300le stochastique par blocs (MSB) avec N = 1000, 10 communaute\u0301s de me\u0302me taille et de parame\u0300tre de structure = c/4, ou\u0300 c correspond a\u0300 la limite ou\u0300 les structures en communaute\u0301s ne sont plus de\u0301tectables ; et plus est petit, plus la structure en communaute\u0301s est forte. Voir par exemple [5, sec. 4] pour des de\u0301tails sur ; [4, Fig. 1] pour des illustrations des deux premiers graphes. Pour ge\u0301ne\u0301rer les signaux a\u0300 bande limite\u0301e. Dans tous ces exemples, nous choisissons k = 10. Chaque signal x a\u0300 bande limite\u0301e k est ge\u0301ne\u0301re\u0301 en calculant Uk, puis en calculant x = Uk\u03b1 ou\u0300 \u03b1 \u2208 Rk est tire\u0301 ale\u0301atoirement selon une gaussienne G(0, 1), puis en normalisant x pour qu\u2019il soit de norme 1. Les diffe\u0301rentes me\u0301thodes d\u2019e\u0301chantillonnage compare\u0301es. On compare 5 me\u0301thodes d\u2019e\u0301chantillonnage : i) l\u2019e\u0301chantillonnage iid uniforme sans remise, ii) l\u2019e\u0301chantillonnage iid selon p = diag(Kk) sans remise (comme dans [4]), iii) la me\u0302me strate\u0301gie mais avec une distribution p ' diag(Kk) estime\u0301e via (15), iv) l\u2019e\u0301chantillonnage de\u0301pendant en suivant l\u2019algorithme 3, et v) l\u2019e\u0301chantillonnage selon le PPD ide\u0301al, c\u2019est-a\u0300-dire en suivant l\u2019algorithme 1 avec la le\u0301ge\u0300re modification qu\u2019a\u0300 chaque ite\u0301ration de la boucle on tire l\u2019e\u0301chantillon qui maximise la probabilite\u0301 (cela donne de meilleures performances de reconstruction dans les cas teste\u0301s). Les quatre premie\u0300res me\u0301thodes peuvent e\u0301chantillonner un nombre quelconque de n\u0153udsm ; la dernie\u0300re e\u0301chantillonne ne\u0301cessairement k n\u0153uds. Le bruit de mesure n \u2208 Rm est tire\u0301 selon une Gaussienne de moyenne nulle et d\u2019e\u0301cart-type \u03c3, et est ajoute\u0301 a\u0300 la mesure du signal, comme dans (1). On fixe \u03c3 = 10\u22123. Reconstruction des signaux e\u0301chantillonne\u0301s. Quelle que soit la me\u0301thode choisie, on reconstruit les signaux avec (2), c\u2019esta\u0300-dire avec la connaissance de Uk. Il existe des moyens de reconstruction qui ne ne\u0301cessitent pas Uk (voir [4]) ; mais nous souhaitons ici comparer exclusivement l\u2019e\u0301chantillonnage. Discussion des re\u0301sultats. La Fig. 1 montre que notre me\u0301thode approche la performance du PPD a\u0300 noyau Kk plus rapidement que les autres, de\u0300s m = O(k). Pour le graphe du Minnesota, a\u0300 petit m, notre performance est moindre. Ceci dit, nous retrouvons une meilleure performance pour d\u2019autres choix de k. De nombreuses expe\u0301riences ont e\u0301te\u0301 mene\u0301es sur d\u2019autres re\u0301alisations du MSB, avec d\u2019autres valeurs de k (diffe\u0301rentes de k = 10 choisie ici), et \u03c3, et des communaute\u0301s de taille he\u0301te\u0301roge\u0300ne : nous trouvons toujours des comportements similaires."}, {"heading": "6 Conclusion", "text": "Nous proposons l\u2019algorithme 2, une re\u0301e\u0301criture moins cou\u0302teuse de l\u2019algorithme 1 d\u2019e\u0301chantillonnage dem-DPP a\u0300 noyau de projection. Dans les cas ou\u0300 le noyau est de la forme K = hk(L) ou\u0300 L est une matrice diagonalisable (de pre\u0301fe\u0301rence parcimonieuse), nous proposons l\u2019algorithme 3 qui, via des approximations polynomiales, permet d\u2019approcher l\u2019e\u0301chantillonnage du m-PPD associe\u0301 a\u0300 K sans jamais calculer explicitement K, potentiellement dense, et en e\u0301vitant tout calcul de diagonalisation de L. Nous illustrons avec succe\u0300s l\u2019inte\u0301re\u0302t de cet algorithme pour l\u2019e\u0301chantillonnage de signaux sur graphe a\u0300 bande limite\u0301e. Remerciements. Ce travail a e\u0301te\u0301 en partie soutenu par le LabEx PERSYVAL-Lab (ANR-11-LABX-0025-01), l\u2019ANR GenGP (ANR-16-CE23-0008), le LIA CNRS/Melbourne Univ Geodesic. Re\u0301fe\u0301rences [1] A. C\u0327ivril, M. Magdon-Ismail. On selecting a maximum volume submatrix of a matrix and related problems. Theoretical Computer Science, no. 47, vol. 410, p. 4801\u20134811, 2009. [2] S. Chen, R. Varma, A. Sandryhaila, J. Kovacevic. Discrete Signal Processing on Graphs : Sampling Theory. IEEE Transactions on Signal Processing, no. 24, vol. 63, p. 6510\u20136523, 2015. [3] A. Anis, A. Gadde, A. Ortega. Efficient Sampling Set Selection for Bandlimited Graph Signals Using Graph Spectral Proxies. IEEE Transactions on Signal Processing, no. 14, vol. 64, p. 3775\u20133789, 2016. [4] G. Puy, N. Tremblay, R. Gribonval, P. Vandergheynst. Random sampling of bandlimited signals on graphs. Applied and Computational Harmonic Analysis, in press, 2016. [5] N. Tremblay, P-0. Amblard, S. Barthelme\u0301. Graph sampling with determinantal processes. arXiv preprint, 1703.01594, 2017. [6] A. Kulesza, B. Taskar, Determinantal point processes for machine learning. Found. and Trends in Mach. Learn., no. 2, vol. 5, p. 123\u2013286, 2012. [7] D. Shuman, S. Narang, P. Frossard, A. Ortega, P. Vandergheynst, The emerging field of signal processing on graphs : Extending highdimensional data analysis to networks and other irregular domains. IEEE Signal Processing Magazine, no. 3, vol. 30, p. 83\u201398, 2013. [8] R. Bardenet, A. Hardy, Monte Carlo with determinantal point processes. arXiv preprint, 1605.00361, 2016. [9] F. Lavancier, J. Moller, E. Rubak, Determinantal point process models and statistical inference. Journal of the Royal Statistical Society : Series B (Statistical Methodology), no. 4, vol. 77, p. 853\u2013877, 2015 [10] N. Tremblay, G. Puy, R. Gribonval, P. Vandergheynst. Accelerated spectral clustering using graph filtering of random signals. ICASSP, 2016."}], "references": [{"title": "On selecting a maximum volume submatrix of a matrix and related problems", "author": ["A. \u00c7ivril", "M. Magdon-Ismail"], "venue": "Theoretical Computer Science, no. 47, vol. 410, p. 4801\u20134811", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2009}, {"title": "Discrete Signal Processing on Graphs : Sampling Theory", "author": ["S. Chen", "R. Varma", "A. Sandryhaila", "J. Kovacevic"], "venue": "IEEE Transactions on Signal Processing, no. 24, vol. 63, p. 6510\u20136523", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2015}, {"title": "Efficient Sampling Set Selection for Bandlimited Graph Signals Using Graph Spectral Proxies", "author": ["A. Anis", "A. Gadde", "A. Ortega"], "venue": "IEEE Transactions on Signal Processing, no. 14, vol. 64, p. 3775\u20133789", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2016}, {"title": "Random sampling of bandlimited signals on graphs", "author": ["G. Puy", "N. Tremblay", "R. Gribonval", "P. Vandergheynst"], "venue": "Applied and Computational Harmonic Analysis, in press", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2016}, {"title": "P-0", "author": ["N. Tremblay"], "venue": "Amblard, S. Barthelm\u00e9. Graph sampling with determinantal processes. arXiv preprint, 1703.01594", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2017}, {"title": "Determinantal point processes for machine learning", "author": ["A. Kulesza", "B. Taskar"], "venue": "Found. and Trends in Mach. Learn., no. 2, vol. 5, p. 123\u2013286", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2012}, {"title": "The emerging field of signal processing on graphs : Extending highdimensional data analysis to networks and other irregular domains", "author": ["D. Shuman", "S. Narang", "P. Frossard", "A. Ortega", "P. Vandergheynst"], "venue": "IEEE Signal Processing Magazine, no. 3, vol. 30, p. 83\u201398", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2013}, {"title": "Monte Carlo with determinantal point processes", "author": ["R. Bardenet", "A. Hardy"], "venue": "arXiv preprint, 1605.00361", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2016}, {"title": "Determinantal point process models and statistical inference", "author": ["F. Lavancier", "J. Moller", "E. Rubak"], "venue": "Journal of the Royal Statistical Society : Series B (Statistical Methodology),", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2015}, {"title": "Accelerated spectral clustering using graph filtering of random signals", "author": ["N. Tremblay", "G. Puy", "R. Gribonval", "P. Vandergheynst"], "venue": "ICASSP", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2016}], "referenceMentions": [{"referenceID": 1, "context": "Dans ce contexte, il existe deux types de m\u00e9thodes d\u2019\u00e9chantillonnage : i) celles qui calculent les k premiers modes de Fourier du graphe et cherchent via des heuristiques k n\u0153uds qui les discriminent tous [2], ii) celles qui s\u2019affranchissent de ce calcul, et qui soit cherchent un nombre de n\u0153uds proche de k et r\u00e9solvent des probl\u00e8mes combinatoires qui ne passent pas \u00e0 l\u2019\u00e9chelle [3], soit s\u2019autorisent un nombre de n\u0153uds de l\u2019ordre de O(k log k) et permettent de passer \u00e0 l\u2019\u00e9chelle via un \u00e9chantillonnage iid adapt\u00e9 au graphe [4], soit via des marches al\u00e9atoires sur graphe sp\u00e9cifiques [5].", "startOffset": 205, "endOffset": 208}, {"referenceID": 2, "context": "Dans ce contexte, il existe deux types de m\u00e9thodes d\u2019\u00e9chantillonnage : i) celles qui calculent les k premiers modes de Fourier du graphe et cherchent via des heuristiques k n\u0153uds qui les discriminent tous [2], ii) celles qui s\u2019affranchissent de ce calcul, et qui soit cherchent un nombre de n\u0153uds proche de k et r\u00e9solvent des probl\u00e8mes combinatoires qui ne passent pas \u00e0 l\u2019\u00e9chelle [3], soit s\u2019autorisent un nombre de n\u0153uds de l\u2019ordre de O(k log k) et permettent de passer \u00e0 l\u2019\u00e9chelle via un \u00e9chantillonnage iid adapt\u00e9 au graphe [4], soit via des marches al\u00e9atoires sur graphe sp\u00e9cifiques [5].", "startOffset": 381, "endOffset": 384}, {"referenceID": 3, "context": "Dans ce contexte, il existe deux types de m\u00e9thodes d\u2019\u00e9chantillonnage : i) celles qui calculent les k premiers modes de Fourier du graphe et cherchent via des heuristiques k n\u0153uds qui les discriminent tous [2], ii) celles qui s\u2019affranchissent de ce calcul, et qui soit cherchent un nombre de n\u0153uds proche de k et r\u00e9solvent des probl\u00e8mes combinatoires qui ne passent pas \u00e0 l\u2019\u00e9chelle [3], soit s\u2019autorisent un nombre de n\u0153uds de l\u2019ordre de O(k log k) et permettent de passer \u00e0 l\u2019\u00e9chelle via un \u00e9chantillonnage iid adapt\u00e9 au graphe [4], soit via des marches al\u00e9atoires sur graphe sp\u00e9cifiques [5].", "startOffset": 528, "endOffset": 531}, {"referenceID": 4, "context": "Dans ce contexte, il existe deux types de m\u00e9thodes d\u2019\u00e9chantillonnage : i) celles qui calculent les k premiers modes de Fourier du graphe et cherchent via des heuristiques k n\u0153uds qui les discriminent tous [2], ii) celles qui s\u2019affranchissent de ce calcul, et qui soit cherchent un nombre de n\u0153uds proche de k et r\u00e9solvent des probl\u00e8mes combinatoires qui ne passent pas \u00e0 l\u2019\u00e9chelle [3], soit s\u2019autorisent un nombre de n\u0153uds de l\u2019ordre de O(k log k) et permettent de passer \u00e0 l\u2019\u00e9chelle via un \u00e9chantillonnage iid adapt\u00e9 au graphe [4], soit via des marches al\u00e9atoires sur graphe sp\u00e9cifiques [5].", "startOffset": 588, "endOffset": 591}, {"referenceID": 5, "context": "Nous proposons une m\u00e9thode bas\u00e9e sur les processus ponctuels d\u00e9terminantaux (PPD) [6], des processus al\u00e9atoires connus pour favoriser la diversit\u00e9 des \u00e9chantillons.", "startOffset": 82, "endOffset": 85}, {"referenceID": 6, "context": "Par analogie au traitement du signal discret classique, ui est consid\u00e9r\u00e9 comme le i-\u00e8me mode de Fourier du graphe [7].", "startOffset": 114, "endOffset": 117}, {"referenceID": 4, "context": "Parmi tous les choix possibles deA (et donc de M) qui v\u00e9rifient \u03c3 1 > 0, lesquels sont optimaux? Il existe plusieurs d\u00e9finitions d\u2019optimalit\u00e9 [5], nous nous int\u00e9ressons ici \u00e0 la suivante :", "startOffset": 142, "endOffset": 145}, {"referenceID": 0, "context": "TrouverAMV est NP-complet [1].", "startOffset": 26, "endOffset": 29}, {"referenceID": 8, "context": "Notons que des id\u00e9es similaires pour r\u00e9duire la complexit\u00e9 d\u2019un facteur m existent dans la litt\u00e9rature (par exemple dans [9]) mais sous des formes un peu cach\u00e9es, et, \u00e0 notre connaissance, n\u2019ont jamais \u00e9t\u00e9 vraiment explicit\u00e9es dans le cas discret.", "startOffset": 121, "endOffset": 124}, {"referenceID": 6, "context": "[7] Consid\u00e9rons le polyn\u00f4me de Tchebychev h\u0303k de degr\u00e9 r qui approche au mieux hk :", "startOffset": 0, "endOffset": 3}, {"referenceID": 9, "context": "et, via le lemme de Johnson-Lindenstrauss, on montre qu\u2019un nombre de signaux al\u00e9atoires n = O(logN) est suffisant pour avoir une estimation convenable avec haute probabilit\u00e9 [10].", "startOffset": 174, "endOffset": 178}, {"referenceID": 3, "context": "On compare 5 m\u00e9thodes d\u2019\u00e9chantillonnage : i) l\u2019\u00e9chantillonnage iid uniforme sans remise, ii) l\u2019\u00e9chantillonnage iid selon p = diag(Kk) sans remise (comme dans [4]), iii) la m\u00eame strat\u00e9gie mais avec une distribution p ' diag(Kk) estim\u00e9e via (15), iv) l\u2019\u00e9chantillonnage d\u00e9pendant en suivant l\u2019algorithme 3, et v) l\u2019\u00e9chantillonnage selon le PPD id\u00e9al, c\u2019est-\u00e0-dire en suivant l\u2019algorithme 1 avec la l\u00e9g\u00e8re modification qu\u2019\u00e0 chaque it\u00e9ration de la boucle on tire l\u2019\u00e9chantillon qui maximise la probabilit\u00e9 (cela donne de meilleures performances de reconstruction dans les cas test\u00e9s).", "startOffset": 158, "endOffset": 161}, {"referenceID": 3, "context": "Il existe des moyens de reconstruction qui ne n\u00e9cessitent pas Uk (voir [4]) ; mais nous souhaitons ici comparer exclusivement l\u2019\u00e9chantillonnage.", "startOffset": 71, "endOffset": 74}, {"referenceID": 0, "context": "[1] A.", "startOffset": 0, "endOffset": 3}, {"referenceID": 1, "context": "[2] S.", "startOffset": 0, "endOffset": 3}, {"referenceID": 2, "context": "[3] A.", "startOffset": 0, "endOffset": 3}, {"referenceID": 3, "context": "[4] G.", "startOffset": 0, "endOffset": 3}, {"referenceID": 4, "context": "[5] N.", "startOffset": 0, "endOffset": 3}, {"referenceID": 5, "context": "[6] A.", "startOffset": 0, "endOffset": 3}, {"referenceID": 6, "context": "[7] D.", "startOffset": 0, "endOffset": 3}, {"referenceID": 7, "context": "[8] R.", "startOffset": 0, "endOffset": 3}, {"referenceID": 8, "context": "[9] F.", "startOffset": 0, "endOffset": 3}, {"referenceID": 9, "context": "853\u2013877, 2015 [10] N.", "startOffset": 14, "endOffset": 18}], "year": 2017, "abstractText": "We consider the problem of sampling k-bandlimited graph signals, i.e., linear combinations of the first k graph Fourier modes. We know that a set of k nodes embedding all k-bandlimited signals always exists, thereby enabling their perfect reconstruction after sampling. Unfortunately, to exhibit such a set, one needs to partially diagonalize the graph Laplacian, which becomes prohibitive at large scale. We propose a novel strategy based on determinantal point processes that side-steps partial diagonalisation and enables reconstruction with only O(k) samples.", "creator": "LaTeX with hyperref package"}}}