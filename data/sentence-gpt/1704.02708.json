{"id": "1704.02708", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "10-Apr-2017", "title": "Distribution-free Evolvability of Vector Spaces: All it takes is a Generating Set", "abstract": "In Valiant's model of evolution, a class of representations is evolvable iff a polynomial-time process of random mutations guided by selection converges with high probability to a representation as $\\epsilon$-close as desired from the optimal one, for any required $\\epsilon&gt;0$. Several previous positive results exist that can be related to evolving a vector space, but each former result imposes restrictions either on (re)initialisations, distributions, performance functions and/or the mutator. In this paper, we show that all it takes to evolve a complete normed vector space is merely a set that generates the space. Furthermore, it takes only $\\tilde{O}(1/\\epsilon^2)$ steps and it is essentially strictly monotonic, agnostic and handles target drifts that rival some proven in fairly restricted settings. In the context of the model, we bring to the fore new results not documented previously. Evolution appears to occur in a mean-divergence model reminiscent of Markowitz mean-variance model for portfolio selection, and the risk-return efficient frontier of evolution shows an interesting pattern: when far from the optimum, the mutator always has access to mutations close to the efficient frontier. Toy experiments in supervised and unsupervised learning display promising directions for this scheme to be used as a (new) provable gradient-free stochastic optimisation algorithm. However, the potential of this optimisation could have many uses, including. We suggest that as a consequence of the large number of experiments, the model of evolution is generally considered as unsupervised (even if it takes all of the input from the target to the correct target) or even an optimised, non-supervised, version of that model, and not an optimised, version of the model. Furthermore, in many cases, we need to consider the possibility of the optimisation of the model of evolution, as the selection and time constraints are often non-supervised, and consider the possibility of the optimisation of the model of evolution in the near future. In short, the possibility of the optimisation of the model of evolution may be used in many domains. However, this approach is unlikely to be sufficient in all domains. As a consequence, the best we can show is that the optimal selection should be achieved from any given model to a given version. The problem arises when there is a large number of experiments. In particular, for example, it might be useful to look", "histories": [["v1", "Mon, 10 Apr 2017 04:41:38 GMT  (1988kb,D)", "http://arxiv.org/abs/1704.02708v1", null]], "reviews": [], "SUBJECTS": "cs.LG", "authors": ["richard nock", "frank nielsen"], "accepted": false, "id": "1704.02708"}, "pdf": {"name": "1704.02708.pdf", "metadata": {"source": "CRF", "title": "Distribution-free Evolvability of Vector Spaces: All it takes is a Generating Set", "authors": ["Richard Nock", "Frank Nielsen"], "emails": ["richard.nock@data61.csiro.au", "frank.nielsen@acm.org"], "sections": [{"heading": null, "text": "keywords: Evolvability, phenotype/genotype, vector spaces, portfolio selection, Markowitz meanvariance model, Bregman divergence."}, {"heading": "1 Introduction", "text": "The classical stochastic models of evolution are population-based, asymptotic and involve possibly complex set of selection mechanisms (Cerf, 1998). On the computational side of Darwinian evolution, Valiant\u2019s model has simplified the evolution steps to that of a single organism evolving with mutations, and put the constraint that near-optimal evolution has to be observable in a polynomial number of iterations (Valiant, 2009). Evolution makes local modifications to a function that acts as an organism. This function maps environmental conditions (or experiences) to outputs. There is an\nar X\niv :1\n70 4.\n02 70\n8v 1\n[ cs\n.L G\n] 1\noptimal such function, unknown, called the target, t. All functions of interest, including t, belong to a class of representations, G. G is said to be evolvable if, roughly speaking, these local modifications yield a close approximation to the target t in polynomial time and with high probability. Approximation is measured according to the functions\u2019 output to experimental conditions.\nThere are two main difficulties in Valiant\u2019s original model. The first is statistical: the Turingcomputable mechanism that performs local modifications, called a mutator, performs random guided mutations, and these mutations are not evaluated on a true discrepancy between the current function and the target, but on an estimated discrepancy, relying on a fixed but unknown distribution sampling the environmental conditions. The second is computational, as we require that the mutated function comes close enough to the optimum in time polynomial in the relevant parameters.\nThere has been quite a large amount of work in the evolvability model (Table 1 below), yet no result has shown so far that complex enough forms of organisms (models) can be evolved in settings that would compose evolvability with unrestricted target, loss and distribution, under the simplest forms of mutator \u2014 e.g. constraint-free versions of the \u201chill climber\u201d of Valiant (2012). Such results would be important because Valiant\u2019s model is an original contender for computational approaches to evolution (Chastain et al., 2014), but no result so far formalizes the idea that a stochastic evolution as simple in mechanisms as the one that governs life-at-large can indeed produce sufficiently fit and complex models in a reduced amount of time. To our knowledge, only the class of singletons over boolean strings has been formally shown to tick most relevant checkboxes (Feldman, 2009), but it is a model space far too simple to fit in.\nTo summarize our contribution, we show that any finite dimensional vector space is a candidate answer for the model class. Our proof is constructive, that is, we explicit all parameters of the evolvability scheme. Noticeably, an efficient mutator can be obtained from any generating set of the vector space. We provide additional characterisations of evolution, as well as toy experiments in unsupervised and supervised learning.\nTo be more specific, we consider complete normed vector spaces (\u201cvector spaces\u201d for short) and mutators that use simple mutations. Each mutation is a linear combination of functions. The mutator acts on any fixed set of these mutations that would just be able to generate the gene encoding space. We make no other assumption on the mutator: the mutations available are therefore the same for any organism, as well as the mutator\u2019s tolerance in the evolvability model. Given these parameters, what we show in essence is:\n(1) any vector space is distribution-free, strictly monotonically evolvable from any of these mutators, using any twice differentiable Bregman divergence as a performance function;\n(2) when the target organism slowly drifts, or is \u201ctoo complex\u201d for the available mutations, then the same scheme still guarantees approximate convergence to the best evolvable organism. This includes agnostic evolvability as a special case.\nComparison with related works: we do not perform reinitializations of evolution like (Valiant, 2012), the mutator is not organism-dependent like in (Kanade et al., 2010), we have no distribution assumptions like in (Angelino and Kanade, 2014; Kanade et al., 2010) or a requirement to know this distribution like in (Feldman, 2008), and the same scheme can be made agnostic or\nAlgorithm 1 Simple-Evol-Gen(f0) Input: initial representation f0, T ; For t = 0, 1, ..., T \u2212 1\nStep t.1: Sample S as per (10); Step t.2: Compute BENE(ft) and NEUT(ft) using N (ft) as per (7) Step t.3: if BENE(ft) 6= \u2205 then sample uniformly ft+1 in BENE(ft) as per (3);\nelse if NEUT(ft) 6= \u2205 then sample uniformly ft+1 in NEUT(ft) as per (4); else sample uniformly ft+1 in N (ft);\nReturn fT ;\nhandle drift more significant than some allowed in more restricted settings (Kanade et al., 2010). Also, we do not rely on the trick that model representations \u201chardcode\u201d the optimisation steps, a beautiful trick but expensive space-wise (Feldman, 2008, 2009; Valiant, 2012). We insists on the no-distribution assumption: in some works, this distribution is constrained, smooth and nice (Angelino and Kanade, 2014), uniform (Michael, 2012; Valiant, 2009), spherically symmetric (Kanade et al., 2010), a product of Gaussians with polynomial variance (Kanade et al., 2010), or with support restricted to a ball (Valiant, 2012), or just known (Feldman, 2008).\nBecause our analysis does not rely on such sophisticated assumptions, the algorithm we end up studying is an extremely simple evolutionary scheme, sketched in Algorithm 1 (Simple-Evol-Gen). The analysis turns out to be quite involved but the simplicity of the algorithm make them potentially amenable to a variety of specific input-, domain- or problem-dependent tunings.\nOne specific part of our analysis is the choice to rely on Bregman divergences for performance functions. We make this choice not just because they generalize performance functions previously used (Kanade et al., 2010; Valiant, 2009). Above all, they have been conveniently axiomatized and are the loss functions appearing, in the clear or in disguise, in numerous geometric, supervised or unsupervised learning problems (Amari and Nagaoka, 2000; Banerjee et al., 2005a,b; Bartlett et al., 2006). One very appealing feature of Bregman divergences is the fact that they are the exhaustive class of distortion measures for several essential properties: (i) when the population minimizer is the population\u2019s average (Abernethy and Frongillo, 2012; Banerjee et al., 2005a; Nock et al., 2016) \u2014 which grounds simple statistical estimators with powerful characteristics \u2014, and (ii) when the space is embedded with a dually flat structure (Amari and Nagaoka, 2000, Section 3.4) \u2014 which makes it amenable to simple but powerful optimization methods like mirror descent.\nOur work also brings to the fore some new quantitative and qualitative results pertaining to evolution. First, evolution occurs in a model reminiscent of the mean-variance approach of Markowitz (Kitano, 2010; Markowitz, 1952): returns are computed with respect to the target while risk premiums rely solely on the mutation, quantifying the risk of mutations \u2014 hence, to be considered beneficial, a mutation shall exhibit sufficient return while incurring limited risk. Second, the proof shows the existence of superior beneficial mutations, displaying significant returns with respect to the premiums (compared to evolvability\u2019s requirements). Third, evolution does not just approximately converge to the optimum: with high probability, it converges strictly monotonically and then may get trapped (in a specific sense) around the optimum for a potentially large number of iterations. Fourth, we characterize analytically an efficient frontier for evolution, previously documented in systems biology (Kitano, 2010); interestingly, when the current organism is \u201cfar\u201d from\nthe target (in a specific sense), all superior beneficial mutations are close to the efficient frontier, and therefore display an approximately optimal risk-return tradeoff. We complete our results with preliminary toy experiments (one sketched in Figure 1) in supervised and unsupervised learning, displaying some promising directions for Evolvability to spin out provable stochastic gradient-free optimization algorithms.\nThe rest of this paper is organised as follows: Section \u00a72 details the evolvability model, Section \u00a73 states and gives a high-level proof of our main result and \u00a74 discusses and concludes. For space considerations and to lighten the papers body, an Appendix with three sections (i) provides the complete proof of our main result (\u00a7 6), (ii) states and proves additional results (\u00a7 7), and finally present toy experiments with our simple mutator (\u00a7 8)."}, {"heading": "2 Evolvability model", "text": "In Valiant\u2019s Evolvability model, evolution repeatedly operates random mutations over an organism, guided by weak selection. We recall the main components of the model, giving in the relevant cases how we adapt them to our setting (Feldman, 2009; Valiant, 2009).\nTopology of representations \u2014 Organisms are represented by functions f : X \u2192 Rd of a set G, called the representation class, supposed to be polynomial-time Turing-evaluatable. X is the set of conditions or experiences. For any f \u2208 G, a neighborhood function is defined, N (f) \u2286 G, that depends on an accuracy parameter > 0. The size of the neighborhood is required to be polynomial in 1/ , d and the dimension of X, dim(X).\nPerformances of representations \u2014 Performances are measured with respect to an unknown but fixed distribution D over X, relatively to an unknown target function t \u2208 G. The expected performance of some f \u2208 G with respect to t is:\nPerft,\u03d5(f,D) . = \u2212Ex\u223cD[D\u03d5(f(x)\u2016t(x))] , (1)\nwhereD\u03d5 is Bregman divergence with (twice differentiable) generator\u03d5 : Rd \u2192 R (Banerjee et al., 2005a,b; Boissonnat et al., 2010). By extension, the empirical performance realized by f on an i.i.d. sample S is defined as Perft,\u03d5(f, S) . = \u2212Ex\u223cS[D\u03d5(f(x)\u2016t(x))]. Our expected performance (1) generalizes Valiant\u2019s which computes ED[ft]. In Valiant\u2019s setting, d = 1, the output of functions is {\u22121, 1} and D\u03d5 is the square loss DSQL, and so Perft,SQL(f,D) = 2(ED[f(x)t(x)] \u2212 1). Notice that we do not necessarily know the complete link between mutations and expression. This is very natural, yet estimating performances in the real world is not just the problem of sampling in D, it is also the problem of observing and measuring the performances. One could name this model a \u201cPetri dish\u201d model of performance evaluation.\nSelection by mutations \u2014 A mutator\nMUT : G\u00d7 N \u2192 G \u222a {\u22a5} (2)\nis a randomized polynomial-time Turing machine that depends upon an accuracy > 0 and a tolerance T > 0. Tolerance is required to be polynomial in , 1/d and 1/dim(X). The mutator returns a so-called \u201cmutant\u201d of some input f \u2208 G based on a weak evaluation of the quality of the elements of N (f). More precisely, it takes as input a sample size m > 0, samples i.i.d. a set S of m conditions, and outputs some g \u2208 BENE(f) at random if BENE(f) 6= \u2205, or else g \u2208 NEUT(f) at random if NEUT(f) 6= \u2205, using a fixed distribution \u00b5(g, f) with support BENE(f) or NEUT(f). Those two sets BENE(f) and NEUT(f) are defined respectively by:\nBENE(f) .= {g \u2208 N (f) : Perft,\u03d5(g, S) \u2265 Perft,\u03d5(f, S) + T} , (3) NEUT(f) .= {g \u2208 N (f) : |Perft,\u03d5(g, S)\u2212 Perft,\u03d5(f, S)| < T} . (4)\nIf both sets BENE(f) and NEUT(f) are empty, the mutator outputs \u22a5, meaning in that last case that evolution has failed.\nRepresentations \u2014 Our framework being non-boolean, we define the models that we evolve. Let [n] .= {0, 1, ..., n} and [n]\u2217 .= {1, ..., n} where n is a natural integer. First, we have a set of functions {g1, g2, ..., gdG} \u2282 G, each of which is of the form gj : X \u2192 Rd for j \u2208 [dG] for some dG > 0, with the assumption that \u2016gj(x)\u201622 \u221e,\u2200x \u2208 X (where \u201d \u221e\u201d means finite). Each of them can be thought as encoding the quantitative production of particular proteins under any experimental condition. The set of functions that we evolve lies in the span of {g1, g2, ..., gdG}\u2014 which we also denote as G for simplicity \u2014, i.e., consists of linear combinations of functions of G.\nHowever, because we want our model to be general, we do not evolve directly G. For this reason, we define a set of vectors B .= {b1, b2, ..., bdB}, with bi \u2208 RdG , that will represent our set of mutations. Each (column) vector, bi . = [b1i \u00b7 \u00b7 \u00b7 b dG i ] > maps to a function bi(x) = \u2211 j b j i \u00b7gj(x). Their span, span(B), defines a vector space: this is the vector space we want to evolve. Two interesting cases emerge, that we will cover in our analysis: span(B) \u2282 G, which corresponds to robust evolvability, and span(B) = G but dB dG, which corresponds to an overcomplete (\u201cwasteful\u201d) encoding of functions, or redundancy in the encoding (observed in the living). An organism f that our mutator builds has evolved from some initial f0 and can therefore be represented as f = f0 + \u2211 i f\nibi, where [f 1 f 2 ... fdB ] \u2208 NdB . Each of these coordinates i is a proxy for the number of times mutation bi was triggered. Finally, To avoid confusion with Rd, we let \u2016.\u2016G denote the L2 norm computed with respect to {g1, g2, ..., gdG}, i.e. the norms of the coordinates in G.\nEvolvability horizon \u2014 In the same way as PAC-learnability allows to be polynomial in the size of the target concept, evolvability has to allow a time complexity that depends on some complexity measure with respect to the target organism, and not just the number of description variables, which would be dim(X) in our case \u2014 in short, we allow more time to evolve mammals than protozoa. Evolvability results on complex representations alleviate this distinction by putting constraints on representations (Kanade et al., 2010; Valiant, 2012). We integrate this notion in the form of what we call the Evolvability horizon.\nDefinition 1 The Evolvability horizon TD(f0) (TD for short) of some organism f0 with respect to target t is:\nTD . = \u2308 \u2016t\u2212 f0\u2016G maxi \u2016bi\u2016G \u2309 . (5)\nTD quantifies the necessary number of mutations to come up with an encoding of an organism \u201cclose\u201d to that of t. Any evolution in time o(TD) iterations, using only B, would be bound to fail in the worst case.\nEvolvability \u2014 We now provide our definition of evolvability, following (Feldman, 2009; Kanade et al., 2010; Valiant, 2009).\nDefinition 2 Assume the following fixed, for any accuracy > 0: representation class G, mutator neighborhood N and distribution \u00b5, distribution D, generator \u03d5, tolerance T. Then G is distribution-free evolvable by mutator MUT(., .) iff for any initial representation f0 and target representation t such that TD \u221e, there exist polynomial functions m and T (both polynomial in\nd, dim(X), 1/ , TD) such that \u22000 < \u2264 1, then with probability\u2265 1\u2212 , the sequence f0, f1, ..., fT with fj . = MUT(fj\u22121,m), \u2200j \u2208 [T ]\u2217, satisfies:\nPerft,\u03d5(fT ,D) \u2265 \u2212 . (6) Our model of evolution holds without initialisation (Feldman, 2008; Valiant, 2009). We have simplified the presentation of the model, in particular removing the notion of \u201cevolution algorithm\u201d and specifying evolution directly from the mutator. This does not weaken the results."}, {"heading": "3 Main result: vector spaces are evolvable", "text": "The main notations are summarized in Appendix, Subsection 6.1.\nDefinition 3 A mutator is permissible iff the neighborhood used by the mutator is defined as:\nN (f) . = {f} \u2295 {\u03c3\u03b1bi : \u03c3 \u2208 {\u22121,+1}, bi \u2208 B} , (7) for some set B .= {b1, b2, ..., bdB}, where\u2295 is Minkowski sum. \u03b1 > 0 (fixed) is called the magnitude of the mutations and \u03c3 is called the polarity of the mutation.\nWe have not detailed the distribution of the mutator, \u00b5 (Section 2). In fact, it can be any distribution with full support and (at least) inversely polynomial density, following e.g., (Kanade et al., 2010). We shall consider that it is the simplest of all, the uniform distribution. We also remark that B is not necessarily a basis, nor normal, nor orthogonal. Also, \u03b1 is the key parameter to be tuned to comply with evolvability. We evolve vector spaces under three assumptions that we unite in a Singularity-Free (SF) setting.\nDefinition 4 The (SF) setting is defined by the following three assumptions: (i) any genome \u201ccan be coded\u201d: span(B) = G,\n(ii) any target organism t is \u201cunique\u201d: arg minf Perft,\u03d5(f,D) = {t} (\u2200t \u2208 G), and (iii) any non-void genome gets \u201cexpressed\u201d: Px\u223cD[g(x) 6= 0Rd ] > 0,\u2200g 6= 0G.\nEach of (i-iii) allows to define parameters that will be useful to quantify evolution. We now provide a concise version of our main results, hiding the less important parameters in the corresponding \u03b8, O\u0303 notations (the complete statement of the Theorem is in Theorem 19).\nTheorem 5 (evolvability of vector spaces, concise statement) Assume (SF) holds. Then G is distribution-free evolvable by any permissible mutator MUT, with tolerance:\nT = \u03b8( 2) , (8)\nand magnitude of mutations:\n\u03b1 = \u03b8( ) . (9)\nThe number of conditions sampled at each iteration satisfies:\nm = O\u0303 ( T 4D 2 log ( dBTD )) . (10)\nFinally, the number of evolution steps T sufficient to comply with ineq. (6) is T = O\u0303 (T 4D/ 2)."}, {"heading": "3.1 Proof of Theorem 5 : key steps", "text": "The proof of Theorem 5 relies on two key definitions: (a) evolvability occurs in a mean-divergence model reminiscent of Markowitz\u2019 mean-variance model (Markowitz, 1952), and (b) the analysis is driven by a quantity that ties the expression and encoding of f . Let us start by (a).\nDefinition 6 For any representation f , condition x, magnitude \u03b1 and polarity \u03c3, we let\nRf,i(x) . = \u3008\u03c3bi(x), (\u2207\u03d5 \u25e6 t)(x)\u2212 (\u2207\u03d5 \u25e6 f)(x)\u3009 , and (11) \u03a0f,i(x) . = 1\n\u03b1 D\u03d5(f(x)\u2212 \u03b1 \u00b7 (\u2212\u03c3)bi(x)\u2016f(x)) (12)\nthe mutator\u2019s return and premium on x given f , omitting \u03c3 and \u03b1 in the notations.\nWe give an equivalent definition for the set of beneficial mutations, using returns and premiums.\nLemma 7 BENE(f) = {f + \u03c3\u03b1bi \u2208 N (f) : ES[Rf,i(x)]\u2212 ES[\u03a0f,i(x)] \u2265 (T/\u03b1)}. (Proof in Appendix, Subsection 6.3) One reason to relate the decomposition in Lemma 7 to a mean-divergence model comes from when D\u03d5 is Mahalanobis divergence, the model simplifies to an equivalent of Markowitz model (Markowitz, 1952) in which \u03a0f,i(x) = (\u03b1/2) \u00b7 \u3008bi(x),Mbi(x)\u3009 (M symmetric positive definite), i.e. the magnitude of mutations \u03b1 is exactly Arrow-Pratt measure of absolute risk aversion \u2014 since \u03b1 > 0, evolution is \u201crisk averse\u201d. Since it does not depend on t, the mutator\u2019s premium quantifies the (local) risk of mutating. Hereafter, we let \u201cexpected\u201d return and \u201cexpected\u201d premium denote the expectation of (11) and (12) over a distribution on X. We now address (b).\nDefinition 8 The phenotype-to-genotype (PG) ratio of f \u2208 G given distribution D is:\n\u03c1(f |D) .= ED[\u2016f(x)\u2016 2 2]\n\u2016f\u2016G = VarD[\u2016f(x)\u20162] + (ED[\u2016f(x)\u20162])2 \u2016f\u2016G . (13)\nThe PG-divergence between f \u2208 G and g \u2208 G given distribution D is \u03c1(f, g|D) .= \u03c1(f \u2212 g|D). A justification for the name of \u03c1(f, g|D) comes from the fact that \u03c1(f |D) = \u03c1(f, 0G|D), 0G representing a \u201cvoid genome\u201d. The proof of the Theorem relies on two arguments. The first establishes that, provided the mutator samples sufficient conditions m, the set of beneficial mutations is never empty with high probability, as long as the current f is \u201cfar\u201d from the optimum, where this distance notion relies on the PG-divergence between f and the target t. In fact, we show a bit more, as in this case mutations may be superior beneficial: we call them superior beneficial because while beneficial mutations shall be proven to yield an improvement of \u2126( 2) in performance, those superior beneficial mutations yield a greater increase of \u2126( ). In the second argument, we show that when the first argument does not hold anymore, the requirements of evolvability are met, and the number of evolution steps is polynomial in all required parameters, so vector spaces are evolvable. To formalize these two arguments, we need several definitions. There is a basis in B which is important, B\u2217.\nDefinition 9 Let B\u2217 \u2286 B be the basis that maximises BG(B\u2032) .= BG(B\u2032)/maxb\u2208B\u2032 \u2016b\u2016G over all bases B\u2032 \u2286 B, where\nBG(B \u2032) . = (1\u2212 \u03ban(B\u2032)) \u00b7 (1\u2212 \u03baa(B\u2032)) \u00b7 \u2211 b\u2208B\u2032 \u2016b\u2016G dG\n(14)\nand \u03ban(B\u2032) and \u03baa(B\u2032) denote non-negative reals such that:\nG(B\u2032) = (1\u2212 \u03ban(B\u2032) 2 dGA(B\u2032) , (15)\ncos(\u03b8V) = 1\u2212 (1\u2212 \u03baa(B\u2032)) 1 dG\u22121 . (16)\nHere, G(.) and A(.) are the geometric and arithmetic means1 of the squared norms in B\u2032, and \u03b8V . = minb6=b\u2032\u2208B\u2032 min{|\u2220b, b\u2032|, |\u03c0 \u2212 \u2220b, b\u2032|} \u2208 [0, \u03c0/2] is the minimal angle between two vectors.\nBG(.) aggregates several key components of the basis in arguments, including volume and norms. Roughly, the larger BG(.), the better for evolution (smaller samples, larger magnitude for mutations). It turns out that this parameter tends to be larger as the basis in argument becomes closer to orthonormality, and so orthonormal bases represent the \u201ceasiest\u201d cases for evolution from this standpoint. They turn out to be the ones chosen in (Kanade et al., 2010, Section 6).\nLemma 10 \u2200B\u2032 a basis of G, BG(B\u2032) and BG(B\u2032) are strictly positive. Proof If \u03ban(B\u2032) = 1, then one vector in B\u2032 is the null vector, if \u03baa(B\u2032) = 1, then two vectors in B\u2032 are collinear, in whichever case B\u2032 cannot be a basis. Thus, (\u03ban(B\u2032), \u03baa(B\u2032)) \u2208 [0, 1)2. Finally, no basis vector can be the null vector, so BG(B\u2032) > 0 and BG(B\u2032) > 0, as claimed.\nWithout loss of generality, we are assume that maxi\u2208[dB]\u2217 \u2016bi\u2016G = maxbi\u2208B\u2217 \u2016bi\u2016G, and supi,x \u03c9(B\u2032\u222a {bi}, x) \u2264 supx \u03c9(B\u2217, x) for any basis B\u2032 \u2286 B and bi \u2208 B, where \u03c9(B\u2032, x) . = \u2211\nbi\u2208B\u2032 \u2016bi(x)\u201622 for any B\u2032 \u2286 B and any x \u2208 X. These two assumptions simplify derivations without restricting our results. We also assume supx \u03c9(B\u2217, x) is polynomial in all genome parameters, d, dim(X)), TD, in order not to laden the polynomial dependences of the evolvability model by one which takes into account the maximal magnitude of expressions.\nLet us denote \u03a8 .= Ex\u223cD[G>x Gx] where G>x stacks all gi(x) in column, and 0 \u2264 \u03b3 \u2264 \u03b3\u2032 \u221e (resp. 0 \u2264 \u00b5 \u2264 \u00b5\u2032 \u221e) the min/max eigenvalues of the Hessian of \u03d5 (resp. \u03a8).\nLemma 11 Under (SF), \u03b3 > 0 and \u00b5 > 0.\nThe proof follows from the fact that if \u03b3 were zero, then the Bregman divergence would make it possible for some f 6= t to have optimal performance, violating (ii) in (SF). If \u00b5 were zero, then some genomes would get expressed only on conditions sets of zero measure, violating (iii) in (SF).\nDefinition 12 Let Gt . = {f \u2208 G : Perft,\u03d5(f,D) \u2265 \u2212 }, and\nGt,D . = { f \u2208 G : \u2203bi \u2208 B\u2217, \u03c1(f, t|D) \u2265 \u221a edG\n\u03b3BG(B\u2217)\n( \u03c4 + \u03b1\u03b3\u2032 \u00b7 \u2016bi\u2016G \u00b7 \u03c1(bi|D) +\nT \u03b1\n)} ,(17)\nwhere \u03b1, \u03c4, T > 0 are fixed beforehand. Let Gt,D \u2287 GMON .= {fj : fj\u2032 \u2208 Gt,D,\u2200j\u2032 \u2208 [j]}, where fj . = MUT(fj\u22121,m), and GMON . = {fj}Tj=1\\GMON the sequence \u201cfollowing\u201d GMON.\n1The Geometric and Arithmetic means of reals z1, z2, ..., zm are G . = ( \u220f j zj) 1/m, A . = (1/m) \u00b7\u2211j zj .\nHence, GMON is the longest prefix sequence of evolved organisms that are all in Gt,D. Note that we do not assume that GMON 6= \u2205. A key property of GMON is that its sequence of organisms has monotonically increasing performances and yields with high probability non-empty beneficial sets. This is our first argument.\nTheorem 13 Assume (SF) holds. Suppose \u03b1, \u03c4, T > 0 fixed, and mutator is run for T > 0 iterations, sampling at each iteration a number of conditions\nm = \u2126\n( \u03b3\u20322 supx \u03c9 2(B\u2217, x)\n\u03c4 2\n( \u03b3\u2032\u00b5\u2032\n\u03b3\u00b5 \u00b7 T\n2 D\nB 2\nG(B \u2217)\n+ \u03b12 ) log ( dBT )) . (18)\nThen the following holds true with probability \u2265 1\u2212 :\nBENE(fj) 6= \u2205 , \u2200fj \u2208 GMON , (19)\nwhere we recall that fj . = MUT(fj\u22121,m).\n(Proof in Appendix, Subsection 6.4)\nLemma 14 If GMON 6= \u2205, then let GMON .= {fj}Tj=j? for some j? \u2208 [T ]\u2217. Then fj? \u2208 Gt.\n(Proof in Appendix, Subsection 6.5) Hence, the first element in GMON complies with evolvability requirements in eq. (6). What remains to be shown is that as long as the current organism fj stays in GMON (\u2286 Gt,D), the performance increases by a substantial amount, guaranteeing that the following scenario occurs: either at some point it escapes GMON, in which case Lemma 14 guarantees that evolvability requirements are met, or it never escapes Gt,D and after a polynomial number of iterations, it satisfies evolvability requirements as well, achieving our second argument. This is shown in the following Lemma.\nLemma 15 Fix T and \u03b1 as in (30) and (31), and in eqs (17, 18) let \u03c4 .= \u03b8( /U), with:\nU . = \u03b3\u2032 3 2\u00b5\u2032 1 2\n\u03b3 3 2\u00b5 1 2\n\u00b7 2 \u221a edG\nBG(B\u2217) \u00b7 TD .\nThen, with probability \u2265 1\u2212 , (fj \u2208 GMON)\u21d2 Perft,\u03d5(fj+1,D) = Perft,\u03d5(fj,D) + \u2126( 2),\u2200j \u2208 [T ]\u2217. Finally, the number of evolution steps sufficient for GMON to comply with (6) is T = O\u0303 (T 4D/ 2).\n(Proof in Appendix, Subsection 6.6)"}, {"heading": "4 Discussion and conclusion", "text": "Some additional property of our mutator are proven in the Appendix, all being collated in Subsection 7.1. In short, evolution can be trapped around the target provided we constraint a bit more some key parameters that influence tolerance and magnitude of mutations. In this case, when we escape the monotonic sequence that brings evolvability in Theorem 19, the organism is going to stay within the evolvability requirements, for a number of iterations / mutations steps that we can control. Also, evolution can be agnostic (Angelino and Kanade, 2014; Feldman, 2009), i.e. we\ncan alleviate condition (i) in setting (SF) and show that evolution converges to the \u201cbest\u201d evolvable organism in terms of performances with high probability. Evolution can also handle target drift (Kanade et al., 2010).\nTable 1 summarizes the main features of our approach and compares with related approaches in the literature. Comparison relies on what can be related to \u201csimple\u201d mechanisms for evolution, with weak assumptions about the task. The approach that has the closest properties to ours is (Feldman, 2009) (Theorem 18), yet it evolves a very simple class of concept (singletons). We have sometimes stretched the results to make them comparable, in particular for those that have the least to do with vector spaces (Feldman, 2009; Diochnos and Tura\u0301n, 2009). In these papers, the magnitude of mutations cannot be a real (organisms evolved are boolean concepts), yet the mutators flip boolean values as well, so they have \u201coptimal\u201d magnitude from this standpoint. We have not displayed properties regarding drift, since it is known that strict monotonicity is sufficient to handle some drift (Kanade et al., 2010), yet the amount tolerable may be significantly smaller than ours.\nTo summarize, what we have shown is that, to evolve a complete vector space, one merely needs a norm and a set that generates the space. With these two ingredients, a straightforward mutator is enough to observe strict monotonicity in evolution with high probability, and handle agnostic evolvability. Note that the mutator operates local modifications that belong to the same set for any organism. This probably makes it unusable on sophisticated approaches (Feldman, 2008; Valiant, 2012), but we claim that it is in fact very natural (Feldman, 2011). The fact that our positive results span most of the features of positive results proven so far, even outside strict monotonicity (Table 1), shows that strict monotone evolution may be in some cases virtually as powerful as evolution at large from Valiant\u2019s model. Row \u201cnon-reflexive neighborhood\u201d is a new feature that we have found nowhere else: the fact that the current organism f does not belong to the mutant set forces the mutator to evolve f without the safety net that reflexive mutations belong to neutral neighbors, which therefore somewhat artificially contain \u201cworst case\u201d evolution.\nOur result generalizes in several directions the result that appears to be the closest to ours (Feldman, 2011) (Theorems 4.1, 4.4), i.e., outside the binary classification framework, the realm of well-behaved losses, single-dimensional outputs and non-agnostic evolvability. Our framework is also more general. Feldman requires the target organism to have minimal non-zero margin over all conditions, which is equivalent to replacing the non-zero probability by a unit probability in assumption (iii) of setting (SF), and therefore weakens the general purpose of the result \u2014 even when the minimal margin assumption is reasonable in the restricted binary classification setting. Finally, our analysis displays better dependences on the key parameters \u03b1, T,m: inspection of the bounds of Feldman shows that the guarantees on performance increase may be very loose, namely as small as O\u0303( a) for some potentially large constant a, which is significantly worse than our \u2126\u0303( 2) guarantee in GMON.\nFigure 2 presents a complete synthetic view of the main mechanisms shown in our paper (including in the Appendix), with two properties never explicitly documented before: the fact that the apparent weakness of the mutator (which works regardless of the set that generates G) does not prevent it to be able to \u201ccompete\u201d with the best mutators when far from the target, and the fact that evolution may just be trapped \u201cclose\u201d to the target when it has succeeded. The agnostic evolution setting relies on an analogue to Bregman orthogonal projection theorems (Amari and Nagaoka, 2000) involving the performance function.\nSeveral of the parameters that emerge from the analysis have been documented in the life\nsciences, such as the existence of the efficient frontier in systems biology (Kitano, 2010), or the importance of phenotypic variance, the numerator of the PG-ratio, considered beneficial in several areas related to biology, agriculture, and evolution (Geiler-Samerotte et al., 2013). A contribution to the model of evolution was the fact that we perform our mutations not directly on the \u201cgenes expression\u201d, but on unknown functions on which directly depend the expressions. We chose the dependences to be unknown, but linear. An interesting problem would be to go beyond.\nFinally, Valiant\u2019s PAC model led to the intuition and then existence of some of the most powerful algorithms for supervised learning: boosting algorithms. We do believe that the Evolvability model will not just be useful to describe evolution \u201cbelow\u201d the polynomial complexity horizon: it might be the basis of efficient (new) stochastic optimization algorithms as well. Our experiments are at the most preliminary, but they display some promising encouragements in this direction, in particular as a contribution of Evolvability to provable gradient-free stochastic optimization."}, {"heading": "5 Acknowledgments", "text": "Work started while RN was visiting Sony Computer Science Laboratories, Inc. (Tokyo)."}, {"heading": "6 Appendix \u2014 Proofs of the results in the main body", "text": "6.1 Basic notations and helper Lemmata t target organism fj evolved organism B\u2032 basis \u2286 B B\u2032 dG \u00d7 dG transition matrix for basis B\u2032 in orthonormal \u201cgene\u201d basis {g1, g2, .., gdG} \u03b4(x)\n. = (t\u2212 f)(x) = GxB\u2217(t\u2212 f), difference of expressions between target t and organism f measured with respect to basis B\u2217\n\u03b4i coordinate i of vector \u03b4 \u2016.\u2016G norm in canonical (\u201cgene\u201d) basis of G gi canonical basis vector of G\ngi(x) gene expression output (in Rd) of gj on some x \u2208 X Gx\n. = [g1(x)|g2(x)| \u00b7 \u00b7 \u00b7 |gdG(x)] \u2208 Rd\u00d7dG per-gene output matrix on some x \u2208 X\n\u03a8 . = Ex\u223cD[G>x Gx] \u2208 RdG\u00d7dG ker(.) null space\nUnless otherwise stated, all organisms are expressed in basis B\u2217 \u2286 B, that is,\nf(x) = GxB \u2217f , (20)\nand the norm of the encoding of f expressed in basis B\u2217 shall be \u2016f\u2016G .= \u221a \u3008B\u2217f, B\u2217f\u3009 . (21)\nWe use in several places the following Lemmata.\nLemma 16 Under setting (SF), there exists symmetric positive definite matrix M such that ED[Rf,i(x)] = \u3008B\u2217bi,MB\u2217\u03b4\u3009,\u2200bi \u2208 B (coordinates of \u03b4 .= t\u2212 f, bi expressed in basis B\u2217). Proof Because \u03d5 is twice differentiable and strictly convex, a Taylor expansion of\u2207\u03d5 around t(x) yields\n(\u2207\u03d5 \u25e6 t)(x) = (\u2207\u03d5 \u25e6 f)(x) + H(x)(t\u2212 f)(x) = (\u2207\u03d5 \u25e6 f)(x) + H(x)GxB\u2217\u03b4 , (22)\nfor some value of the Hessian H(x) of \u03d5, therefore symmetric positive definite. We get\nED[\u3008bi(x), (\u2207\u03d5 \u25e6 t)(x)\u2212 (\u2207\u03d5 \u25e6 f)(x)\u3009] = ED[\u3008GxB\u2217bi, H(x)GxB\u2217\u03b4\u3009] = ED[\u3008B\u2217bi, G>x H(x)GxB\u2217\u03b4\u3009] = \u3008B\u2217bi,ED[G>x H(x)Gx]B\u2217\u03b4\u3009 .\n= \u3008B\u2217bi,MB\u2217\u03b4\u3009 ,\nwith\nM . = ED[G>x H(x)Gx] . (23)\nBecause of (iii) in (SF), for any g 6= 0G \u2208 G, for each x \u2208 X for which it is expressed, we have g(x) = GxB \u2217g 6= 0Rd and so\n\u3008B\u2217g,MB\u2217g\u3009 = \u222b X p(x)\u3008g(x), H(x)g(x)\u3009dx\n\u2265 Px\u223cD[g(x) 6= 0Rd ] \u00b7 min g(x)6=0Rd \u3008g(x), H(x)g(x)\u3009 > 0 ,\nshowing M is positive definite.\nLemma 17 Under setting (SF), for any f, t \u2208 G (coordinates expressed in basis B\u2217), the following holds, for some M\u2032 symmetric positive definite:\nEx\u223cD[D\u03d5(f(x)\u2016t(x))] = \u3008B\u2217(f \u2212 t),M\u2032B\u2217(f \u2212 t)\u3009 , (24) Ex\u223cD[D\u03d5(f(x)\u2016t(x))] \u2208 [ \u03b3\n2 \u00b7 \u3008B\u2217(f \u2212 t),\u03a8B\u2217(f \u2212 t)\u3009, \u03b3\n\u2032\n2 \u00b7 \u3008B\u2217(f \u2212 t),\u03a8B\u2217(f \u2212 t)\u3009\n] .(25)\nProof Both results are a consequence of (Amari and Nagaoka, 2000), that for any twice differentiable \u03d5,\nD\u03d5(f(x)\u2016t(x)) = 1\n2 \u00b7 \u3008GxB\u2217(f \u2212 t), H(x)GxB\u2217(f \u2212 t)\u3009 , (26)\nfor some value of the Hessian H(x) of \u03d5, therefore symmetric positive definite. Then, we define M\u2032 as\nM\u2032 . = 1\n2 \u00b7 M , (27)\nwhere M is defined in eq. (23), and so M\u2032 0. We then use the definition of \u03b3 to obtain ineq. (25)."}, {"heading": "6.2 Complete statement of Theorem 5", "text": "We first provide a more complete statement of Theorem 5. We now define two key parameters:\nU . = \u03b3\u2032 3 2\u00b5\u2032 1 2\n\u03b3 3 2\u00b5 1 2\n\u00b7 2 \u221a edG\nBG(B\u2217) \u00b7 TD , (28)\nV . = \u03b3\u2032 \u00b7 max i\u2208[dB]\u2217 {ED[\u2016bi(x)\u201622]} , (29)\nand triples of evolution \u201cknobs\u201d, (z\u03c4 , z\u03b1, zT) \u2208 R3+\u2217, all absolute constants.\nDefinition 18 Set R \u2282 R3 is defined as the subset of triples (z1, z2, z3) such that (i) z1, z2, z3 > 0, (ii) z3 \u2212 z1z2 > 0, (iii) z22 \u2212 z2(1\u2212 z1) + z3 \u2264 0.\nRemark that R 6= \u2205, since for example (1/9, 1/3, 2/27) \u2208 R. We now state our main result.\nTheorem 19 (evolvability of vector spaces, complete statement) Assume (SF) holds, and fix any (z\u03c4 , z\u03b1, zT) \u2208 R. G is distribution-free evolvable by any permissible mutator MUT, with tolerance:\nT .= zT\nU2 max{1, V } \u00b7 2 = \u03b8( 2) , (30)\nand magnitude of mutations:\n\u03b1 . = z\u03b1\nU max{1, V } \u00b7 = \u03b8( ) . (31)\nThe number of conditions sampled at each iteration satisfies:\nm = O\n( \u03b3\u20326\u00b5\u20322 supx \u03c9 2(B\u2217, x)\n\u03b34\u00b52 \u00b7 1 B 4 G(B \u2217) \u00b7 T\n4 D 2 log\n( dBTD )) = O\u0303 ( T 4D 2 log ( dBTD )) .(32)\nFinally, the number of evolution steps T sufficient to comply with ineq. (6) is T = O\u0303 (T 4D/ 2).\nRemark that z\u03c4 is defined but not used in the Theorem statement. It shall be used in its proof below."}, {"heading": "6.3 Proof of Lemma 7", "text": "By definition,\nBENE(f) = {g \u2208 N (f) : Perft,\u03d5(g, S) \u2265 Perft,\u03d5(f, S) + T} = {g \u2208 N (f) : ES[\u3008g(x)\u2212 f(x), (\u2207\u03d5 \u25e6 t)(x)\u2212 (\u2207\u03d5 \u25e6 f)(x)\u3009 \u2212D\u03d5(g(x)\u2016f(x))] \u2265 T}\n= { f + \u03c3\u03b1bi \u2208 N (f) : ES [\u3008\u03c3bi(x), (\u2207\u03d5 \u25e6 t)(x)\u2212 (\u2207\u03d5 \u25e6 f)(x)\u3009] \u2212ES [ 1 \u03b1 D\u03d5((f + \u03b1 \u00b7 \u03c3bi)(x)\u2016f(x)) ] \u2265 T \u03b1 } = { f + \u03c3\u03b1bi \u2208 N (f) : ES[Rf,i(x)]\u2212 ES[\u03a0f,i(x)] \u2265\nT \u03b1\n} , (33)\nas claimed (end of the proof of Lemma 7)."}, {"heading": "6.4 Proof of Theorem 13", "text": "The proof of the Theorem consists of the following building blocks:\nBB.1 we show a result more general than eq. (19), namely, over all steps j \u2208 [T ]\u2217 and with high probability:(\n\u2203bi \u2208 B\u2217 : \u03c1(fj, t|D) \u2265 \u221a edG\n\u03b3BG(B\u2217)\n( \u03c4 + \u03b1\u03b3\u2032 \u00b7 \u2016bi\u2016G \u00b7 \u03c1(bi|D) +\nT \u03b1 )) \u21d2 BENE(fj) 6= \u2205 . (34)\nThis is more general since we show that eq. (19) holds for all organisms of the evolution sequence that belong to Gt,D, and not just the \u201cfirst\u201d ones in GMON. To have this with high probability it is sufficient to sample m = \u2126\u0303(maxj \u2016t\u2212 fj\u20162G) conditions, which may be hard to upperbound depending on fj;\nBB.2 we show that, in the subsequence GMON, maxj \u2016t\u2212 fj\u20162G may be conveniently upperbounded.\n\u21aa\u2192 (Proof of [BB.1]) We temporarily drop subscript j in fj for clarity. The proof involves the following three steps. First, we show that for any current representation f , there always exist a mutation whose expected return is at least a (positive) fraction of the PG-divergence between f and the target t. Its proof involves a simple lowerbound on the volume induced by an arbitrary basis of vectors, which may be of independent interest. Second, we show that, in the evolvability setting, this mutation is special: whenever the current representation f is in GMON, there is always \u03c3 \u2208 {\u22121, 1}, bi \u2208 B such that\nED[Rf,i(x)]\u2212 ED[\u03a0f,i(x)] \u2265 T \u03b1 + \u03c4 . (35)\nWe shall see that this guarantees equivalently ED[Rf,i(x)] \u2212 ED[\u03a0f,i(x)] = \u2126( ) \u2014 we call this mutation superior beneficial, since the right hand side exceeds the beneficial requirements (eq. (33)) by \u03c4 , and furthermore the left hand side is measured on D. Third and last, even when the mutation picked is not superior beneficial, sampling a number of examples large enough is sufficient to guarantee BENE(f) 6= \u2205. More precisely, when m is large enough, the sum of the two differences between (ED[Rf,i(x)]\u2212ED[\u03a0f,i(x)]) and (ES[Rf,i(x)]\u2212ES[\u03a0f,i(x)]) in absolute value is at most \u03c4 over each of the T iterations, with probability \u2265 1 \u2212 . Using (35) then proves the statement of the Theorem because of the definition of BENE(f) in (33).\nLemma 20 Assume (SF) holds. Then for any distribution D and any representations t, f \u2208 G with coordinates expressed in basis B\u2217,\nmax bi\u2208B\u2217\n|ED[Rf,i(x)]| \u2265 K \u00b7 \u03c1(f, t|D) , (36)\nwhere\nK . = \u03b3\u221a edG \u00b7BG(B\u2217) , (37)\nand BG(B\u2217) is the corrected average norm in eq. (14).\nProof: The majority of the proof consists in showing first that ineq. (36) holds for\nK . = \u03b3\u221a e \u00b7 ( G(B\u2217)dG A(B\u2217)dG\u22121 \u00b7 (1\u2212 cos(\u03b8B\u2032)) dG\u22121 \u00b7 (1 + (dG \u2212 1) \u00b7 cos(\u03b8B\u2032)) dG ) 1 2 , (38)\nwhere parameters G(B\u2217), A(B\u2217), \u03b8B\u2032 are defined in eqs (15, 16). Then, we show that ineq. (36) holds for the expression of K in eq. (37). Define for short:\n\u03b4 . = t\u2212 f = \u2211 i\u2208dG \u03b4ibi , (39)\nassuming without loss of generality that B\u2217 .= {b1, b2, ..., bdG}. From Lemma 16, there exists symmetric positive definite matrix M such that ED[Rf,i(x)] = \u3008bi,MB\u2217\u03b4\u3009, \u2200bi \u2208 B\u2217. This allows to\nget the last equality of:\n\u3008B\u2217\u03b4,MB\u2217\u03b4\u3009 = \u2211 i\u2208[dG] \u03b4i \u00b7 \u3008bi,MB\u2217\u03b4\u3009\n\u2264 \u2211 i\u2208[dG] (\u03b4i)2  12 \u2211 i\u2208[dG] \u3008bi,MB\u2217\u03b4\u3009  12 (40) \u2264 \u221a dG max\ni\u2208[dG] |\u3008bi,MB\u2217\u03b4\u3009| \u00b7 \u2211 i\u2208[dG] (\u03b4i)2  12\n= \u221a dG max\ni\u2208[dG] |ED[Rf,i(x)]| \u00b7 \u2211 i\u2208[dG] (\u03b4i)2  12 . (41) Ineq. (40) is Cauchy-Schwartz inequality. Furthermore, the derivations of Lemma 16 and the definition of \u03b3 yields \u3008B\u2217\u03b4,MB\u2217\u03b4\u3009 = ED[\u3008B\u2217\u03b4, G>x H(x)GxB\u2217\u03b4\u3009] \u2265 \u03b3 \u00b7 ED[\u3008GxB\u2217\u03b4, GxB\u2217\u03b4\u3009] . = \u03b3 \u00b7 ED[\u2016\u03b4(x)\u201622]. Combining this with (41) yields:\nmax i\u2208[dG]\n|ED[Rf,i(x)]| \u2265 \u03b3ED[\u2016\u03b4(x)\u201622]\n\u221a dG (\u2211 i\u2208[dG] (\u03b4 i)2 ) 1 2 . (42)\nLet us work on the (\u2211 j (\u03b4 j)2 )1/2 term, and relate it to the norm \u2016\u03b4\u2016G .= \u221a \u3008B\u2217\u03b4, B\u2217\u03b4\u3009, with B\u2217 be the transition matrix that collects vectors from B\u2217 in column, expressed in the orthonormal gene basis of G. We now need the following Lemma.\nLemma 21 Under (SF), B\u2217>B\u2217 0. Proof Let \u03c6B\u2217 : G \u2192 G the linear form that B\u2217 represents. Condition (i) in (SF) implies that \u03c6B\u2217 is injective, and therefore ker(\u03c6B\u2217) = {0G}, and thus \u3008B\u2217z, B\u2217z\u3009 = \u3008z, B\u2217>B\u2217z\u3009 > 0 whenever z 6= 0G (End of the proof of Lemma 21). We denote {(\u03bbj, uj)}dGj=1 the pairs (strictly positive eigenvalues in non-decreasing order, orthonormal eigenvectors), with uj \u2208 RdG , so that the following decomposition holds: B\u2217>B\u2217 = \u2211 i \u03bbiuiu > i .\nIt comes:\n\u2016\u03b4\u20162G . = \u3008B\u2217\u03b4, B\u2217\u03b4\u3009 = \u2211 i\u2208[dG] \u03bbi\u3008\u03b4, ui\u30092\n= \u2211 i\u2208[dG] (\u03b4i)2  \u00b7 \u2211 i\u2208[dG] \u03bbi cos 2(\u03b4, ui) (43)\n\u2265 \u03bb1 \u00b7 \u2211 i\u2208[dG] (\u03b4i)2  \u00b7 \u2211 i\u2208[dG] cos2(v, ui)\n= \u03bb1 \u00b7 \u2211 i\u2208[dG] (\u03b4i)2  , (44) where eq. (43) comes from the fact that ujs are normal and (44) comes from the fact that they are orthogonal. Let us define\nB\u2217\u2032 . = ( dG\u2211\ni\u2208[dG] \u2016bi\u20162G\n) 1 2\n\u00b7 B\u2217 . (45)\nB\u2217\u2032 satisfies:\ntr(B\u2217\u2032>B\u2217\u2032) = dG . (46)\nLet 0 < \u03bb\u03031 \u2264 \u03bb\u03032 \u2264 ... \u2264 \u03bb\u0303dG the eigenvalues of B\u2217\u2032>B\u2217\u2032, all strictly positive because of Lemma 21. The Arithmetic-Geometric-Harmonic means inequality brings:\ndG\u220f i=2\n\u03bb\u0303i \u2264 ( 1\ndG \u2212 1 dG\u2211 i=2 \u03bb\u0303i\n)dG\u22121\n=\n( tr(B\u2217\u2032>B\u2217\u2032)\u2212 \u03bb\u03031\ndG \u2212 1\n)dG\u22121\n= ( dG \u2212 \u03bb\u03031 dG \u2212 1 )dG\u22121\n\u2264 (\ndG dG \u2212 1\n)dG\u22121 , (47)\nMultiplying both sides by \u03bb\u03031 and reorganising, we get: \u03bb\u03031 \u2265 ( dG \u2212 1 dG )dG\u22121 det ( B\u2217\u2032>B\u2217\u2032 )\n\u2265 det ( B\u2217\u2032>B\u2217\u2032 )\ne , (48)\nsince function u(n) .= ((n\u22121)/n)n\u22121 is strictly decreasing on n \u2208 N\u2217 and has limit lim+\u221e u(n) = 1/e. Finally, using eq. (48), we obtain from eq. (45):\n\u03bb1 =\n\u2211 i\u2208[dG] \u2016bi\u2016 2 G\ndG \u00b7 \u03bb\u03031 \u2265 \u2211 i\u2208[dG] \u2016bi\u2016 2 G\ndG \u00b7 det\n( B\u2217\u2032>B\u2217\u2032 ) e\n= 1\ne \u00b7 det (\u2211i\u2208[dG] \u2016bi\u20162G dG ) 1 dG B\u2217\u2032>B\u2217\u2032  = 1\ne \u00b7 det ( dG\u2211 i\u2208[dG] \u2016bi\u20162G ) dG\u22121 2dG B\u2217> ( dG\u2211 i\u2208[dG] \u2016bi\u20162G ) dG\u22121 2dG B\u2217  . (49) Let us define\nB\u0303 . = ( dG\u2211\ni\u2208[dG] \u2016bi\u20162G\n) dG\u22121 2dG\n\u00b7 B\u2217 , (50)\nso that ineq. (49) reads\n\u03bb1 \u2265 1\ne \u00b7 det\n( B\u0303 > B\u0303 ) = 1\ne \u00b7 vol(B\u0303)2 , (51)\nwhere we let vol(B\u0303)2 .= det ( B\u0303 > B\u0303 ) denote the squared volume induced by set B\u0303, since the columns\nof B\u0303 also define a basis of G, B\u0303 .= {b\u03031, b\u03032, ..., b\u0303dG}, with\nb\u0303i . =\n( dG\u2211\ni\u2032\u2208[dG] \u2016bi\u2032\u20162G\n) dG\u22121 2dG\n\u00b7 bi ,\u2200i \u2208 [dG] . (52)\nPutting eq. (51) and (44) altogether, we obtain\u2211 i\u2208[dG] (\u03b4i)2  12 \u2264 \u2016v\u2016G\u221a \u03bb1\n\u2264 \u221ae \u00b7 \u2016v\u2016G vol(B\u0303) . (53)\nCombining eq. (42) and this last inequality yields:\nmax i\u2208[dG]\n|ED[Rf,i(x)]| \u2265 \u03b3vol(B\u0303)\u221a edG \u00b7 ED[\u2016\u03b4(x)\u2016 2 2]\n\u2016\u03b4\u2016G = \u03b3vol(B\u0303)\u221a\nedG \u00b7 \u03c1(f \u2212 t|D)\n= \u03b3vol(B\u0303)\u221a\nedG \u00b7 \u03c1(f, t|D) . (54)\nLet us now work on vol(B\u0303). Denoting SdG the symmetric group of degree dG, we have:\nvol(B\u0303) = ( det(B\u0303 > B\u0303) ) 1 2\n= \u2211 \u03c3\u2208SdG sign(\u03c3) \u220f i\u2208[dG] \u3008b\u0303i, b\u0303\u03c3(i)\u3009  12\n= \u2211 \u03c3\u2208SdG sign(\u03c3) \u220f i\u2208[dG] \u2016b\u0303i\u2016G\u2016b\u0303\u03c3(i)\u2016G cos(b\u0303i, b\u0303\u03c3(i))  12 = \u220f i\u2208[dG] \u2016b\u0303i\u2016G \u2211 \u03c3\u2208SdG sign(\u03c3) \u220f i\u2208[dG] cos(b\u0303i, b\u0303\u03c3(i))\n 12 . (55) Eq. (55) does not depend on the orientation of the vectors in B\u0303: changing b\u0303i to \u2212b\u0303i keeps the same expression (in each product, exactly two cosines change of sign), and there is one such orientation of all vectors such that all angles are in [0, \u03c0/2]. The quantity (55) being then decreasing if all cosines increase, it is minimized by the one in which all angles equal \u03b8B, in which case expression (55) admits the simplified lowerbound:\n\u220f i\u2208[dG] \u2016b\u0303i\u2016G \u2211 \u03c3\u2208SdG sign(\u03c3) dG\u220f k=1 cos(b\u0303k, b\u0303\u03c3(k))  12 \u2265 \u220f i\u2208[dG] \u2016b\u0303i\u2016G \u2211 \u03c3\u2208SdG sign(\u03c3) cos\u03c5(\u03c3)(\u03b8B\u2217)  12 .\n= Al \u221a Aa , (56)\nwhere \u03c5(\u03c3) = |{i : \u03c3(i) 6= i}| counts the number of integers whose position has changed through the permutation \u03c3 \u2208 SdG , or similarly it is the size of the \u201cderanged\u201d sub-permutation of \u03c3. We now proceed through finding simplified expressions for Al and Aa, the parts that respectively depends on lengthes and angles.\nWe first compute Al. We have from the definition of b\u0303i in (52): Al = \u220f i\u2208[dG] \u2016b\u0303i\u2016G\n= \u220f i\u2208[dG] \u2225\u2225\u2225\u2225\u2225\u2225\u2225 ( dG\u2211 i\u2032\u2208[dG] \u2016bi\u2032\u20162G ) dG\u22121 2dG \u00b7 bi \u2225\u2225\u2225\u2225\u2225\u2225\u2225 G\n= ( dG\u2211\ni\u2208[dG] \u2016bi\u20162G\n) dG\u22121 2 \u220f\ni\u2208[dG]\n\u2016bi\u2016G\n= \u220f i\u2208[dG] \u2016bi\u20162G 1 dG  dG 2 /(\u2211 i\u2208[dG] \u2016bi\u2016 2 G dG ) dG\u22121 2\n= G\ndG 2 B\nA dG\u22121 2\nB\n. (57)\nWe now compute Aa. Let us define polynomial PdG(z) by:\nPdG(z) . = \u2211 \u03c3\u2208SdG sign(\u03c3)(1\u2212 z)\u03c5(\u03c3) . (58)\nNotice that Aa = PdG(1 \u2212 cos(\u03b8B\u2217)). While the max degree of PdG(z) is dG, we now show that PdG(z) involves only two monomials, of degree dG and dG \u2212 1.\nLemma 22 PdG(z) = zdG\u22121 \u00b7 (dG \u2212 (dG \u2212 1) \u00b7 z). Proof Denote \u03bak the coefficient of (\u2212z)k in PdG(z), for k \u2208 [dG]. It satisfies:\n\u03bak = \u2211\n\u03c3\u2208SdG :\u03c5(\u03c3)\u2265k\nsign(\u03c3)\n( \u03c5(\u03c3)\nk\n) (59)\n= dG\u2211 j=k ( dG j )( j k ) \u2211 \u03c3\u2208Sj :\u03c5(\u03c3)=j sign(\u03c3) . (60)\nThe inner sum is the sum of all signs of all derangements of a set of j elements. To compute its expression, define Uj \u2208 {0, 1}j\u00d7j the matrix whose diagonal elements are 0 and off-diagonal elements are 1. It satisfies\ndet (Uj) = \u2211\n\u03c3\u2208Sj :\u03c5(\u03c3)=j\nsign(\u03c3) . (61)\nUj has eigenvalue \u22121 of order j\u2212 1 (all vectors with 1 and \u22121 in two consecutive coordinates and zero elsewhere are corresponding eigenvectors), and since its trace is zero, it also admits j \u2212 1 as\neigenvalue of order 1. It follows from eq. (61):\u2211 \u03c3\u2208Sj :\u03c5(\u03c3)=j sign(\u03c3) = (\u22121)j\u22121(j \u2212 1) , (62)\nout of which we obtain\n\u03bak = dG\u2211 j=k ( dG j )( j k ) \u2211 \u03c3\u2208Sj :\u03c5(\u03c3)=j sign(\u03c3)\n= dG\u2211 j=k ( dG j )( j k ) (\u22121)j\u22121(j \u2212 1)\n= dG! k! \u00b7 dG\u2211 j=k (\u22121)j\u22121(j \u2212 1) (dG \u2212 j)!(j \u2212 k)!\n= dG! k! \u00b7 dG\u2212k\u2211 j=0 (\u22121)j+k\u22121(j + k \u2212 1) (dG \u2212 k \u2212 j)!j!\n= (\u22121)k\u22121 ( dG k ) \u00b7 dG\u2212k\u2211 j=0 ( dG \u2212 k j ) (\u22121)j(j + k \u2212 1)\n= (\u22121)k\u22121 ( dG k ) \u00b7 [ (k \u2212 1) \u00b7 dG\u2212k\u2211 j=0 ( dG \u2212 k j ) (\u22121)j\ufe38 \ufe37\ufe37 \ufe38\n\u03a3k\n+ dG\u2212k\u2211 j=1 ( dG \u2212 k j ) (\u22121)jj\ufe38 \ufe37\ufe37 \ufe38\n\u03a3\u2032k\n] . (63)\nWe observe that\n\u03a3k = (\u22121 + 1)dG\u2212k = 0 ,\u2200k \u2264 dG \u2212 1 . (64)\nFurthermore,\n\u03a3\u2032k = dG\u2212k\u2211 j=1 ( dG \u2212 k j ) (\u22121)jj\n= \u2212(dG \u2212 k) \u00b7 dG\u2212k\u2211 j=1 ( dG \u2212 k \u2212 1 j \u2212 1 ) (\u22121)j\u22121\n= \u2212(dG \u2212 k) \u00b7 dG\u2212k\u22121\u2211 j=0 ( dG \u2212 k \u2212 1 j ) (\u22121)j = \u2212(dG \u2212 k)(\u22121 + 1)dG\u2212k\u22121 = 0 ,\u2200k \u2264 dG \u2212 2 . (65)\nWe thus get\n\u03bak = 0 ,\u2200k \u2264 dG \u2212 2 . (66)\nFurthermore, eqs (59) and (62) also yields: \u03badG\u22121 = \u2211\n\u03c3\u2208SdG :\u03c5(\u03c3)=dG\u22121\nsign(\u03c3) + dG \u00b7 \u2211\n\u03c3\u2208SdG :\u03c5(\u03c3)=dG\nsign(\u03c3)\n= dG \u00b7 \u2211\n\u03c3\u2208SdG\u22121:\u03c5(\u03c3)=dG\u22121\nsign(\u03c3) + dG \u00b7 \u2211\n\u03c3\u2208SdG :\u03c5(\u03c3)=dG\nsign(\u03c3)\n= (\u22121)dG\u22121 \u00b7 (\u2212dG(dG \u2212 2)) + (\u22121)dG\u22121dG(dG \u2212 1) = (\u22121)dG\u22121dG , (67)\n\u03badG = \u2211\n\u03c3\u2208SdG :\u03c5(\u03c3)=dG\nsign(\u03c3)\n= (\u22121)dG\u22121(dG \u2212 1) . (68)\nPlugging eqs (65), (67), (68) in (58), we obtain the simplified expression:\nPdG(z) = z dG\u22121 \u00b7 (dG \u2212 (dG \u2212 1) \u00b7 z) ,\nas claimed (end of the proof of Lemma 22).\nWe obtain\nAa = (1\u2212 cos(\u03b8B\u2217))dG\u22121 \u00b7 (1 + (dG \u2212 1) \u00b7 cos(\u03b8B\u2217)) . (69)\nThere remains to put together eqs (54), (55), (56), (57) and (69) to obtain the statement of (36) with the expression of K in eq. (38), and finish the main part of the proof of Lemma 20.\nTo obtain (37) and finish the proof of Lemma 20, we just have to remark that it follows from eq. (57) and ineq. (15) that\nAl \u2265 \u221a A(B\u2217)(1\u2212 \u03ban(B\u2217))\n= 1\u2212 \u03ban(B\u2217)\u221a\ndG \u00b7 \u2211 i\u2208[dG] \u2016bi\u20162G  12\n\u2265 (1\u2212 \u03ban(B\u2217)) \u00b7 \u2211\ni\u2208[dG] \u2016bi\u2016G dG , (70)\nwhere ineq. (70) comes from p-norm inequalities. Finally, because cos(\u03b8B\u2217) \u2265 0, condition (16) yields:\nAa \u2265 (1\u2212 cos(\u03b8B\u2217))dG\u22121 \u2265 (1\u2212 \u03baa(B\u2217)) , (71)\nbecause of the definition of \u03baa(B\u2217). Putting altogether ineqs. (55) and (56) with the lowerbounds on ineqs. (70) and (71), we obtain:\nvol(B\u0303) \u2265 (1\u2212 \u03ban(B\u2217)) \u00b7 (1\u2212 \u03baa(B\u2217)) \u00b7 \u2211\ni\u2208[dG] \u2016bi\u2016G dG\n= BG(B \u2217) . (72)\nFinally, combining ineq. (54) and (72) yields the statement of (36) with the expression of K in eq. (37), as claimed (end of the proof of Lemma 20). The following Lemma now shows that for any current representation f , there always exists a mutation with guaranteed lowerbound on its expected return minus its expected premium, where the lowerbound depends on the PG-ratio of the mutation and the PG-divergence between f and target t.\nLemma 23 Let B\u2217 \u2286 B be any basis of G, and assume (SF) holds. Then for any distribution D and any representations t, f \u2208 G with coordinates expressed in basis B\u2217, \u2203\u03c3 \u2208 {\u22121, 1},\u2203bi \u2208 B\u2217 such that:\nED[Rf,i(x)]\u2212 ED[\u03a0f,i(x)] \u2265 \u03b3\u221a edG \u00b7BG(B\u2217) \u00b7 \u03c1(f, t|D)\u2212 \u03b1\u03b3\u2032 \u00b7 \u2016bi\u2016G \u00b7 \u03c1(bi|D) , (73)\nwhere B\u2217 \u2286 B is defined in eq. (14). Proof: We use Lemma 20 and Definition (11), with which we obtain that there exists, at any call of the mutator, polarity \u03c3 \u2208 {\u22121,+1} and basis vector bi \u2208 B\u2217 such that:\nmax bi\u2208B\u2217 |ED[Rf,i(x)]| \u2265 \u03b3\u221a edG \u00b7BG(B\u2217) \u00b7 \u03c1(f, t|D) . (74)\nOn the expected premium\u2019s side, we have for any bi \u2208 B\u2217 whose coordinates are given in B\u2217,\nED[\u03a0f,i(x)] . = 1\n\u03b1 ED[D\u03d5(f(x)\u2212 \u03b1 \u00b7 (\u2212\u03c3)bi(x)\u2016f(x))]\n\u2264 \u03b1\u03b3 \u2032\n2 \u00b7 \u3008B\u2217bi,\u03a8B\u2217bi\u3009 (75)\n= \u03b1\u03b3\u2032\n2 \u00b7 ED[\u2016bi(x)\u201622] (76)\n= \u03b1\u03b3\u2032\n2 \u00b7 \u2016bi\u2016G \u00b7 \u03c1(bi|D) ,\u2200\u03c3 \u2208 {\u22121, 1},\u2200bi \u2208 B\u2217 . (77)\nEq. (75) uses the definition of M in (23) and Lemma 17. Eq. (76) come from the fact that B\u2217bi, gives the coordinates of bi in the orthonormal gene basis of G. Putting altogether (74) and (77) with 1/2 factor dropped yields the statement of the Lemma. Notice that terms BG \u00b7 \u03c1(f, t|D) and \u2016bi\u2016G \u00b7 \u03c1(bi|D) are homogeneous in (73), as both quantify a PG-ratio or divergence, weighted by a (corrected) length of the encoding.\nIt comes from Lemma 23 that in the (SF) setting, for some evolution step j \u2208 [T ]\u2217, if mutant fj satisfies, for some \u03c3 \u2208 {\u22121, 1} and bi \u2208 B\u2217,\n\u03c1(fj, t|D) \u2265 \u221a edG\n\u03b3BG(B\u2217)\n( \u03c4 + \u03b1\u03b3\u2032 \u00b7 \u2016bi\u2016G \u00b7 \u03c1(bi|D) +\nT \u03b1\n) , (78)\nthen, chaining with ineq. (73), we get\nED[Rfj ,i(x)]\u2212 ED[\u03a0fj ,i(x)] \u2265 \u03b3\u221a edG \u00b7BG(B\u2217) \u00b7 \u03c1(fj, t|D)\u2212 \u03b1\u03b3\u2032 \u00b7 \u2016bi\u2016G \u00b7 \u03c1(bi|D)\n\u2265 T \u03b1 + \u03c4 , (79)\ni.e. the mutation involving bi \u2208 B\u2217 is superior beneficial. This does not show however that the mutator will pick one of these mutations, and it does not show that the mutator will pick some bi \u2208 B\u2217. In fact, this is not even enough to show that BENE(f) is not empty since it involves estimates (Lemma 7). To show that BENE(f) is not empty, we now show that with high probability the estimates ES[Rfj ,i(x)] and ES[\u03a0fj ,i(x)] are both within \u03c4/2 of their true values, implying in this case from ineq. (79)\nES[Rfj ,i(x)]\u2212 ES[\u03a0fj ,i(x)] \u2265 (\nT \u03b1 + \u03c4\n) \u2212 \u03c4 = T\n\u03b1 , (80)\nand thus BENE(fj) as defined in (33) is indeed not empty. Remark this relies on the sole assumption that fj \u2208 Gt,D; fj may not be in GMON. The constraint that fj \u2208 GMON shall be used to compute the number of conditions needed for ineq. (80) to hold with high probability in the sequence GMON, which shall then be used to prove evolvability.\nLemma 24 Let B\u2217 \u2286 B be any basis of G, and assume (SF) holds. Then for any distribution D and any representations t, f \u2208 G with coordinates expressed in basis B\u2217, the following inequalities hold over the i.i.d. sampling of S (of size m) according to D:\nPS\u223cD [\u2203i, \u03c3 : |ES[Rf,i(x)]\u2212 ED[Rf,i(x)]| \u2265 \u03c4 ] \u2264 2dB exp ( \u2212 BG(B \u2217)2m\u03c4 2\n2e\u03b3\u20322\u2016t\u2212 f\u20162G supx \u03c92(B\u2217, x)\n) , (81)\nPS\u223cD [\u2203i, \u03c3 : |ES[\u03a0f,i(x)]\u2212 ED[\u03a0f,i(x)]| \u2265 \u03c4 ] \u2264 2dB exp ( \u2212 2m\u03c4 2\n\u03b12\u03b3\u20322 supx \u03c9 2(B\u2217, x)\n) . (82)\nProof: Both bounds are direct applications of the independent bounded differences inequality (IBDI, (McDiarmid, 1998)). We first prove (81). Again, we let B\u2217 .= {b1, b2, ..., bdG} without loss of generality, and t\u2212 f = \u03b4 .= \u2211i\u2208[dG] \u03b4ibi. Take any \u03c3 \u2208 {\u22121, 1}, bi \u2208 B (the coordinates of this being in B\u2217). Using notations from Lemma 16 (eq. (22)), we have\nRf,i(x) . = \u3008\u03c3bi(x), (\u2207\u03d5 \u25e6 t)(x)\u2212 (\u2207\u03d5 \u25e6 f)(x)\u3009 = \u03c3 \u00b7 \u3008GxB\u2217bi, H(x)GxB\u2217\u03b4\u3009 \u2264 \u03b3\u2032 \u00b7 |\u3008GxB\u2217bi, GxB\u2217\u03b4\u3009| (83) \u2264 \u03b3\u2032 \u00b7 \u221a \u3008GxB\u2217bi, GxB\u2217bi\u3009 \u00b7 \u221a \u3008GxB\u2217\u03b4, GxB\u2217\u03b4\u3009 (84)\n= \u03b3\u2032 \u00b7 \u2016bi(x)\u20162 \u00b7 \u2016t(x)\u2212 f(x)\u20162 ,\u2200x \u2208 X . (85)\nIneq. (83) follows from the definition of \u03b3\u2032, ineq. (84) is Cauchy-Schwartz. Finally, we know that \u2200x \u2208 X, letting \u03b4 .= t\u2212 f ,\n\u2016t(x)\u2212 f(x)\u201622 . = \u3008GxB\u2217\u03b4, GxB\u2217\u03b4\u3009\n= \u2329\u2211 i\u2208[dG] \u03b4i \u00b7 GxB\u2217bi, \u2211 i\u2208[dG] \u03b4i \u00b7 GxB\u2217bi \u232a . (86)\nFor any reals ai and vectors ui (i \u2208 [dG]), we have \u3008 \u2211 i\u2208[dG] ai\u00b7ui, \u2211 i\u2208[dG] ai\u00b7ui\u3009 \u2264 \u2211\ni,i\u2032\u2208[dG] ai\u2016ui\u2016ai\u2032\u2016ui\u2016 = ( \u2211 i\u2208[dG] ai\u2016ui\u2016) 2 \u2264 (\u2211i\u2208[dG] a2i ) \u00b7 (\u2211i\u2208[dG] \u2016ui\u20162) (from Cauchy-Schwartz inequality), and so eq. (86) yields\n\u2016t(x)\u2212 f(x)\u201622 \u2264 \u2211 i\u2208[dG] (\u03b4i)2  \u00b7 \u2211 i\u2208[dG] \u3008GxB\u2217bi, GxB\u2217bi\u3009\n= \u2211 i\u2208[dG] (\u03b4i)2  \u00b7 \u2211 i\u2208[dG] \u2016bi(x)\u201622\n\u2264 e\u2016t\u2212 f\u2016 2 G BG(B\u2217)2 \u00b7 \u2211 i\u2208[dG] \u2016bi(x)\u201622 . (87)\nIneq. (87) follows from ineqs (53) and (72). Putting altogether ineqs (85) and (87), we get\nRf,i(x) \u2264 \u03b3\u2032\u2016bi(x)\u20162 \u00b7 \u221a e\u2016t\u2212 f\u2016G BG(B\u2217) \u00b7 \u2211 i\u2032\u2208[dG] \u2016bi\u2032(x)\u201622  12\n\u2264 \u221a e\u03b3\u2032\u2016t\u2212 f\u2016G BG(B\u2217)\n\u00b7 \u2211\ni\u2032\u2208[dG]\u222a{i}\n\u2016bi\u2032(x)\u201622\n= \u221a e\u03b3\u2032\u2016t\u2212 f\u2016G \u00b7 \u03c9(B\u2217 \u222a {bi}, x) BG(B\u2217)\n\u2264 \u221ae\u03b3\u2032\u2016t\u2212 f\u2016G \u00b7 \u03c9(B\u2217, x)\nBG(B\u2217) , (88)\nby the properties of B\u2217. Hence, between two sets S and S\u2032 of the same size m and that would differ from a single element, we have:\n|ES[Rf,i(x)]\u2212 ES\u2032 [Rf,i(x)]|\n\u2264 2 m \u00b7 \u221ae\u03b3\u2032\u2016t\u2212 f\u2016G \u00b7 supx \u03c9(B \u2217, x) BG(B\u2217) . = \u03b3\u2206(B \u2217) . (89)\nThe following bound follows from (McDiarmid, 1998) (Theorem 3.1) and the union bound over B:\nPS\u223cD [\u2203i : |ES[Rf,i(x)]\u2212 ED[Rf,i(x)]| \u2265 \u03c4 ] \u2264 2dB exp ( \u2212 2\u03c4 2\nm\u03b32\u2206(B \u2217)\n) .\nWe replace \u03b3\u2206(B\u2217) by its expression in ineq. (89) and obtain (81) . We proceed in the same way for the expected mutator\u2019s premium (82). We know from eq. (26) that, for some value of the Hessian H of \u03d5, we have\n\u03a0f,i(x) = \u03b1\n2 \u00b7 \u3008GxB\u2217bi, HGxB\u2217bi\u3009\n\u2264 \u03b1\u03b3 \u2032\n2 \u00b7 |\u3008GxB\u2217bi, GxB\u2217bi\u3009|\n= \u03b1\u03b3\u2032\n2 \u00b7 \u2016bi(x)\u201622 , (90)\nwhere the inequality comes from Lemma 11. So, the variation in average premium between two sets S and S\u2032 of the same size m and that would differ from a single condition satisfies:\n|ES[\u03a0f,i(x)]\u2212 ES\u2032 [\u03a0f,i(x)]| \u2264 1\nm \u00b7 \u03b1\u03b3\u2032 \u00b7 sup x \u03c9({i}, x)\n\u2264 1 m \u00b7 \u03b1\u03b3\u2032 \u00b7 sup i\u2032,x \u03c9({i\u2032}, x)\n\u2264 1 m \u00b7 \u03b1\u03b3\u2032 \u00b7 sup x \u03c9(B\u2217, x) , (91)\nby the properties of B\u2217, which yields, out of the IBDI (McDiarmid, 1998) and the union bound over B, the following bound:\nPS\u223cD [\u2203i, \u03c3 : |ES[\u03a0f,i(x)]\u2212 ED[\u03a0f,i(x)]| \u2265 \u03c4 ] \u2264 2dB exp ( \u2212 2m\u03c4 2\n\u03b12\u03b3\u20322 supx \u03c9 2(B\u2217, x)\n) ,\nas claimed. Suppose now that the mutator samples a sufficient number m of examples that would ensure that the right hand-sides of (81) and (82) are no more than /T for deviation \u03c4/2 (and not \u03c4 ). By the union bound, the probability that there exists a run (among the T ) of the mutator, and some i, \u03c3 such that one of the averages on S of R\u03d5,i(x) or \u03a0f,i(x) deviates from its respective expectation on D by more than \u03c4/2 is no more than T \u00b7 ( /T ) = . Hence, with probability \u2265 1\u2212 , we shall have at all j \u2208 [T ]\u2217 runs of the mutator and for the corresponding \u03c3, bi picked at each call of the mutator:\n|(ES[Rfj ,i(x)]\u2212 ES[\u03a0fj ,i(x)])\u2212 (ED[Rfj ,i(x)]\u2212 ED[\u03a0fj ,i(x)])| \u2264 |ES[Rfj ,i(x)]\u2212 ED[Rfj ,i(x)]|+ |ES[\u03a0fj ,i(x)]\u2212 ED[\u03a0fj ,i(x)]| \u2264 (\u03c4/2) + (\u03c4/2) = \u03c4 , (92)\nand hence ineq. (80) holds over all T iterations, thus whenever fj \u2208 Gt,D, even when the mutator does not pick superior beneficial mutations, or even mutations from B\u2217, it still has non-empty BENE(f), as claimed in (34).\nUsing Lemma 24, the sufficient number of conditions m that ensures this is found to be any integer that satisfies:\nm = \u2126\n( \u03b3\u20322 supx \u03c9 2(B\u2217, x)\n\u03c4 2\n( maxj \u2016t\u2212 fj\u20162G\nBG(B\u2032)2 + \u03b12\n) log ( dBT )) . (93)\n\u21aa\u2192 (Proof of [BB.2]) The bound in ineq. (93) may be problematic as little tells us about \u2016t\u2212 fj\u2016G and how big it can be. Fortunately, it is sufficient for evolution that we focus on subset GMON \u2286 Gt,D. In this subset, we can bound \u2016t \u2212 fj\u2016G, in a very simple way. Recall that sampling a number of example that complies with ineq. (93) is sufficient to guarantee with high probability that ED[Rfj ,i(x)] \u2212 ED[\u03a0fj ,i(x)] \u2265 (T/\u03b1) \u2212 \u03c4 where bi is the mutation picked by the mutator, which\nimplies in particular\nPerft,\u03d5(f + \u03c3\u03b1bi,D) \u2265 Perft,\u03d5(f,D) + \u03b1 ( T \u03b1 \u2212 \u03c4 )\n= Perft,\u03d5(f,D) + T \u2212 \u03b1\u03c4 . (94) But\nT \u2212 \u03b1\u03c4 = zT U2 max{1, V } \u00b7 2 \u2212 z\u03b1z\u03c4 U2 max{1, V } \u00b7 2\n= zT \u2212 z\u03b1z\u03c4\nU2 max{1, V } \u00b7 2\n> 0 , (95)\nbecause (z\u03c4 , z\u03b1, zT) \u2208 R (Definition 18). Hence, as long as f \u2208 Gt,D (and so, f \u2208 GMON), we are guaranteed that\nPerft,\u03d5(fj,D) \u2265 Perft,\u03d5(f0,D) . (96) To obtain our bound on \u2016t\u2212 fj\u2016G, we need the following Lemma.\nLemma 25 Under setting (SF), \u2212(1/2)\u03b3\u2032\u00b5\u2032\u2016t \u2212 f\u20162G \u2264 Perft,\u03d5(f,D) \u2264 \u2212(1/2)\u03b3\u00b5\u2016t \u2212 f\u20162G, \u2200f, t \u2208 G. Proof Let \u03b4 .= f \u2212 t. We get from Lemma 17 and the definition of \u03a8,\nEx\u223cD[D\u03d5(f(x)\u2016t(x))] \u2264 \u03b3\u2032\n2 \u00b7 \u3008B\u2217\u03b4,\u03a8B\u2217\u03b4\u3009\n\u2264 \u03b3 \u2032\u00b5\u2032\n2 \u00b7 \u3008B\u2217\u03b4, B\u2217\u03b4\u3009\n= \u03b3\u2032\u00b5\u2032\n2 \u00b7 \u2016\u03b4\u20162G . (97)\nWe would obtain similarly Ex\u223cD[D\u03d5(f(x)\u2016t(x))] \u2265 (\u03b3\u00b5)/2\u2016t\u2212 f\u20162G. Using Lemma 25 brings\n\u2016t\u2212 fj\u20162G \u2264 \u2212 2\n\u03b3\u00b5 \u00b7 Perft,\u03d5(fj,D)\n\u2264 \u2212 2 \u03b3\u00b5 \u00b7 Perft,\u03d5(f0,D) (98) \u2264 \u03b3 \u2032\u00b5\u2032\n\u03b3\u00b5 \u00b7 \u2016t\u2212 f0\u20162G\n= \u03b3\u2032\u00b5\u2032\n\u03b3\u00b5 \u00b7 T 2D max i\u2208[dB]\u2217 \u2016bi\u20162G ,\u2200fj \u2208 GMON , (99)\nbecause of the definition of TD. Ineq. (98) comes from ineq. (96). Using the last inequality (99), we obtain that a sufficient condition for m to meet (93) is:\nm = \u2126\n( \u03b3\u20322 supx \u03c9 2(B\u2217, x)\n\u03c4 2\n( \u03b3\u2032\u00b5\u2032\n\u03b3\u00b5 \u00b7 maxi\u2208[dB]\u2217 \u2016bi\u2016 2 G\nB2G(B \u2032)\n\u00b7 T 2D + \u03b12 ) log ( dBT )) ,\nbut since maxi\u2208[dB]\u2217 \u2016bi\u2016G = maxbi\u2208B\u2217 \u2016bi\u2016G by the properties of B\u2217, then it is sufficient that\nm = \u2126\n( \u03b3\u20322 supx \u03c9 2(B\u2217, x)\n\u03c4 2\n( \u03b3\u2032\u00b5\u2032\n\u03b3\u00b5 \u00b7 T\n2 D\nB 2\nG(B \u2217)\n+ \u03b12 ) log ( dBT )) ,\nwhich is eq. (18). This achieves the proof of Theorem 13."}, {"heading": "6.5 Proof of Lemma 14", "text": "Because of the definition of Gt,D, whenever f 6\u2208 Gt,D,\n\u03c1(f, t|D) < \u221a edG\n\u03b3BG(B\u2217)\n( \u03c4 + \u03b1\u03b3\u2032 \u00b7 max\nbi\u2208B\u2217 {\u2016bi\u2016G \u00b7 \u03c1(bi|D)}+ T \u03b1\n) . (100)\nIf fj?\u22121 is in GMON but fj? is not in GMON, then ineq. (100) is satisfied by fj? , along with, because of ineq. (99) on fj?\u22121 and the triangle inequality,\n\u2016t\u2212 fj?\u2016G \u2264 \u2016t\u2212 fj?\u22121\u2016G + \u2016fj?\u22121 \u2212 fj?\u2016G \u2264 ( \u03b3\u2032\u00b5\u2032\n\u03b3\u00b5\n) 1 2\n\u00b7 TD max i\u2208[dB]\u2217 \u2016bi\u2016G + \u2016fj?\u22121 \u2212 fj?\u2016G\n=\n( \u03b3\u2032\u00b5\u2032\n\u03b3\u00b5\n) 1 2\n\u00b7 TD max i\u2208[dB]\u2217 \u2016bi\u2016G + \u03b1\u2016b\u2016G (101)\n\u2264 2 \u00b7 ( \u03b3\u2032\u00b5\u2032\n\u03b3\u00b5\n) 1 2\n\u00b7 TD max i\u2208[dB]\u2217 \u2016bi\u2016G , (102)\nsince U \u2265 1 and for any (z\u03c4 , z\u03b1, zT) \u2208 R, we can show that we have z\u03b1 \u2264 1, implying \u03b1 \u2264 1. We have also let b .= fj? \u2212 fj?\u22121 \u2208 B in eq. (101). Multiplying ineq (100) by \u03b3\u2032\u2016t \u2212 fj?\u2016G and using ineq. (102) yields\n\u03b3\u2032\u2016t\u2212 fj?\u2016G \u00b7 \u03c1(fj? , t|D)\n< \u03b3\u2032\u2016t\u2212 fj?\u2016G \u00b7 \u221a edG\n\u03b3BG(B\u2217)\n( \u03c4 + \u03b1\u03b3\u2032 \u00b7 max\nbi\u2208B\u2217 {\u2016bi\u2016G \u00b7 \u03c1(bi|D)}+ T \u03b1 ) \u2264 \u03b3 \u2032 3 2\u00b5\u2032 1 2\n\u03b3 3 2\u00b5\n1 2 G\n\u00b7 2 \u221a edG \u00b7\nmaxbi\u2208B\u2217 \u2016bi\u2016G BG(B\u2217)\n\u00b7 TD \u00b7 ( \u03c4 + \u03b1\u03b3\u2032 \u00b7 max\nbi\u2208B\u2217 {\u2016bi\u2016G \u00b7 \u03c1(bi|D)}+ T \u03b1\n) (103)\n= \u03b3\u2032 3 2\u00b5\u2032 1 2\n\u03b3 3 2\u00b5\n1 2 G\n\u00b7 2 \u221a edG\nBG(B\u2217) \u00b7 TD\ufe38 \ufe37\ufe37 \ufe38\n=U\n\u00b7 ( \u03c4 + \u03b1\u03b3\u2032 \u00b7 max\ni\u2208[dB]\u2217 {\u2016bi\u2016G \u00b7 \u03c1(bi|D)}+ T \u03b1\n) (104)\n\u2264 U\u03c4 + \u03b1U max{1, V }+ UT \u03b1 = z\u03c4 \u00b7 + z\u03b1 \u00b7 + zT z\u03b1 \u00b7 , (105)\nby definition of U, \u03b1, V, T in eqs. (28, 29, 30, 31). Ineq. (103) holds because of ineq. (99). Hence, we obtain that\nEx\u223cD[D\u03d5(fj?(x)\u2016t(x))] \u2264 \u03b3\u2032\u2016t\u2212 fj?\u2016G \u00b7 \u03c1(fj? , t|D) \u2264 z\u03c4 \u00b7 + z\u03b1 \u00b7 +\nzT z\u03b1 \u00b7\n= ( z\u03c4 + z\u03b1 +\nzT z\u03b1\n) \u00b7 (106)\n\u2264 , (107) because (z\u03c4 , z\u03b1, zT) \u2208 R and condition (iii) in Definition 18. Ineq. (107) is equivalent to:\nPerft,\u03d5(fj? ,D) \u2265 \u2212 , and so fj? \u2208 Gt, as claimed."}, {"heading": "6.6 Proof of Lemma 15", "text": "We first provide the complete expression of \u03c4 ,\n\u03c4 . = z\u03c4 U \u00b7 . (108)\nWe also remove subscripts in organisms for clarity. Under the conditions of Theorem 13, when the current organism f \u2208 GMON \u2286 Gt,D, we have BENE(f) 6= \u2205 and thus the next mutation picks polarity \u03c3 \u2208 {\u22121, 1} and bi \u2208 B such that ES[Rf,i(x)] \u2212 ES[\u03a0f,i(x)] \u2265 T/\u03b1. The left-hand side is an average computed over the mutator\u2019s sample S. Its difference with its true value (expectation over D) in absolute value is no more than \u03c4 over all T iterations with probability \u2265 1\u2212 when m meets bound (18). Hence, with probability\u2265 1\u2212 , the mutation will always exhibit ED[Rf,i(x)]\u2212 ED[\u03a0f,i(x)] \u2265 (T/\u03b1)\u2212 \u03c4 , and so, using the definition of BENE in eq. (33) and the expressions of T, \u03b1, \u03c4 in eqs (30, 31, 108),\nPerft,\u03d5(f + \u03c3\u03b1bi,D) \u2265 Perft,\u03d5(f,D) + \u03b1 ( T \u03b1 \u2212 \u03c4 )\n= Perft,\u03d5(f,D) + T \u2212 \u03b1\u03c4 = Perft,\u03d5(f,D) +\nzT U2V \u00b7 2 \u2212 z\u03b1z\u03c4 U2V \u00b7 2\n= Perft,\u03d5(f,D) + zT \u2212 z\u03b1z\u03c4 U2V\n\u00b7 2 (109) = Perft,\u03d5(f,D) + \u2126( 2) ,\nsince (z\u03c4 , z\u03b1, zT) \u2208 R (condition (ii), Definition 18). Hence, as long as f \u2208 GMON, we have a guaranteed increase in performances given by ineq. (109). If f never leaves GMON, how long would it take for evolvability conditions to be met ? To compute it, we need the following Lemma.\nLemma 26 Assume (SF) holds. The initial representation f0 satisfies\nED[D\u03d5(f0(x)||t(x))] \u2264 \u03b3\u2032\u00b5\u2032\n2 max bi\u2208B\u2217\n\u2016bi\u20162G \u00b7 T 2D . (110)\nProof We have from the definition of TD,\nEx\u223cD[D\u03d5(f0(x)\u2016t(x))] .= \u2212Perft,\u03d5(f0,D)\n\u2264 \u03b3 \u2032\u00b5\u2032\n2 \u2016f0 \u2212 t\u20162G (111)\n\u2264 \u03b3 \u2032\u00b5\u2032\n2 max i\u2208[dG]\u2217\n\u2016bi\u20162G \u00b7 T 2D\n= \u03b3\u2032\u00b5\u2032\n2 max bi\u2208B\u2217\n\u2016bi\u20162G \u00b7 T 2D .\nIneq. (111) comes from Lemma 25. The last identity comes from the properties of B\u2217.\nThe way we use Lemma 26 is the following: when the number of iterations T times the minimal performance variation in ineq. (109) exceeds ineq (110), then with high probability f \u2208 Gt and thus meets the condition of convergence for evolvability in ineq. (6) (Definition 2). So, we want\nT \u2265 U 2V \u03b3\u2032\u00b5\u2032maxi\u2208[dG]\u2217 \u2016bi\u20162G\nzT \u2212 z\u03b1z\u03c4 \u00b7 T\n2 D\n2 2 . (112)\nTaking into account the expression of U and V , it is sufficient that\nT \u2265 1 zT \u2212 z\u03b1z\u03c4\n\u00b7 \u03b3 \u20325\u00b5\u20322 maxi\u2208[dB]\u2217{ED[\u2016bi(x)\u201622] \u03b33\u00b5 \u00b7 edG maxi\u2208[dB]\u2217 \u2016bi\u2016 4 G\nB2G(B \u2217)\n\u00b7 T 4 D\n2 , (113)\nthat is, disregarding absolute constants and all other parameters in the O\u0303 notation, it is sufficient that\nT = O\u0303 ( T 4D 2 ) , (114)\nas claimed.\nRemark \u2014 To pack the proof of Theorem 19, we finally need to check that the number of examplesm in ineq. (32) is indeed sufficient, which is upperbounded by the number of iterations to satisfy evolvability requirements while staying in GMON, i.e. using T as in ineq . (113). Considering the other parameters, \u03c4 in eq. (108), the fact that \u03b1 is O(1) in eq. (31), we obtain from ineq. (18) that it is sufficient to sample\nm = O\n( \u03b3\u20326\u00b5\u20322 supx \u03c9 2(B\u2217, x)\n\u03b34\u00b52G \u00b7 1 B 4 G(B \u2217) \u00b7 T\n4 D 2 log\n( dBTD ))\n= O\u0303 ( T 4D 2 log ( dBTD )) , (115)\nas claimed. Notice that we have essentially hidden in the O\u0303 notation of ineqs (114) and (115) the eventual (polynomial) dependences of \u03c9(., .) in TD."}, {"heading": "7 Appendix \u2014 Additional properties", "text": ""}, {"heading": "7.1 Statement of the main results", "text": "Trapping evolution around the target \u2014 Theorem 19 relies on the existence of a monotonic sequence (with respect to performances) which leads to satisfying the conditions of evolution. Provided we constrain a bit more set R, we can do more than the requirements of evolvability: when we escape this monotonic sequence, the mutated organism is going to stay within the evolvability requirements, over a number of iterations / mutations steps that we can control.\nDefinition 27 Fix N \u2208 N\u2217. Set RN \u2282 R3 is the subset of triples (z1, z2, z3) such that (i) z1, z2, z3 > 0, (ii) z3 \u2212 z1z2 > 0, and (iii) (a+ b)z22 \u2212 z2(1\u2212 bz1) + bz3 \u2264 0, where a . = N/U and b . = 2\u03b3\u2032/\u03b3.\nIt is worthwhile remarking that RN \u2282 R, and furthermore RN 6= \u2205 since we can choose for example:\nz1 = 1\n4b , z2 =\n1\n32(a+ b) , z3 =\n1\n64b(a+ b) . (116)\nTheorem 28 Assume (SF) holds, and (z\u03c4 , z\u03b1, zT) \u2208 RN for some N \u2208 N\u2217, and all other parameters are fixed according to Theorem 13. Let f? be the first organism in the sequence f0, f1, ..., fT to hit Gt. Then, with probability \u2265 1\u2212 , fj?+j \u2208 Gt,\u2200j \u2208 [N ]. (Proof in Appendix, Subsection 7.2)\nAchieving agnostic evolvability \u2014 One important question is what happens when t cannot be evolved from B?, i.e. when alleviating condition (i) in setting (SF). Ideally, we would like evolution to converge to the \u201cbest\u201d evolvable organism in terms of performances. To our knowledge, few positive result exist in the agnostic / improper evolvability model (Angelino and Kanade, 2014; Feldman, 2009), and the most unrestricted one holds for extremely simple representations: singletons (Feldman, 2009).\nTheorem 29 If we relax assumption (i) in (SF) but keep (ii, iii), then Theorem 19 holds mutatis mutandis with the replacement of ineq. (6) by:\nPerft,\u03d5(fT ,D) \u2265 sup f\u2208span(B) Perft,\u03d5(f,D)\u2212 . (117)\n(Proof in Appendix, Subsection 7.3)\nEvolvability with target drift \u2014 Another important question is what happens when the target organism drifts slowly (Kanade et al., 2010). In (Kanade et al., 2010), there is a sequence of targets t0, t1, ... and the objective is to replace the static requirement in ineq. (6) by one which takes into account the last target tT , when ti is allowed to slightly drift with respect to ti\u22121 with respect to its performances. In our case, since we separate the encoding from computing performances, we allow the encoding to drift, which is perhaps more natural \u2014 drift affects genotype before performances. Also, the evaluation of beneficial and neutral mutations in BENE and NEUT are done for fj\u22121 with respect to tj\u22121.\nTheorem 30 Assume (SF) holds and the target organism sequence t0, t1, ... drifts according to:\n\u2016ti+1 \u2212 ti\u2016G \u2264 zT \u2212 z\u03b1z\u03c4\n2U2V (2 + T 2D maxi\u2208[dB]\u2217 \u2016bi\u20162G) \u00b7 4 , \u2200i \u2265 0 . (118)\nThen Theorem 19 holds mutatis mutandis with the replacement of ineq. (6) by:\nPerftT ,\u03d5(fT ,D) \u2265 \u2212 . (119) (Proof in Appendix, Subsection 7.4) Up to factors that depend upon \u03b3, \u03b3\u2032, \u00b5, \u00b5\u2032, our model of drift is equivalent to the performance drift model of (Kanade et al., 2010) (see Lemma 25 below), yet, as a function of , we tolerate drifts that are larger by factor \u03b8(1/ 2) than theirs, taking as reference their result on the weakest distribution assumptions (product Gaussians), assumptions that we also alleviate. Dependence on TD is necessary up to some extent, as otherwise worst-case drifts would defeat evolution by artificially increasing the actual horizon to the last target (TD is computed for t0).\nEvolution on the efficient frontier \u2014 The fact that beneficial mutations involve a mean-divergence decomposition of the expression asks for the nature of the efficient frontier, that is, the set of mutations that would minimize ED[\u03a0f,i(x)] subject to a fixed ED[Rf,i(x)]. This would give \u201cnature\u2019s best bet\u201d against our, perhaps, modest and small B. To answer this question, we consider the restricted case of Mahalanobis divergence. Let us alleviate the constraint that b involves only elements from B, and, for notational convenience, define b(x) .= \u2211dG i=1 b\nigi(x). In this case, finding the efficient frontier is solving, similarly to that of the efficient portfolio (Merton, 1972),\narg min b\u2208RdG\n\u03a0(b) . = \u03b1\n2 \u00b7 ED [\u3008b(x),Mb(x)\u3009] (120) s.c. {\nED [\u3008b(x),M(t\u2212 f)(x)\u3009] = r \u30081dG , b\u3009 = n . (121)\nWe let the \u201cefficient frontier\u201d denote the equation that gives r as a function of \u03a0(.), and for that purpose generalize \u03a8 to \u03a8M . = Ex\u223cD[G>x MGx], for any M \u2208 Rd\u00d7d.\nTheorem 31 Under setting (SF), the equation of the efficient frontier is\nr = { n\u00b7\u30081dG ,t\u2212f\u3009 \u30081dG ,\u03a8 \u22121 M 1dG \u3009 \u00b7 ( 1\u00b1 \u221a (\u03be(t\u2212 f)\u2212 1)(\u03be(b)\u2212 1) )\nif \u30081dG , t\u2212 f\u3009 6= 0 \u00b1n \u00b7 \u221a \u30081dG ,\u03a8\u22121M 1dG\u3009 \u00b7 \u3008t\u2212 f,\u03a8M(t\u2212 f)\u3009 \u00b7 (\u03be(b)\u2212 1) if \u30081dG , t\u2212 f\u3009 = 0 (122)\nwhere \u03be(u) .= \u30081dG ,\u03a8\u22121M 1dG\u3009 \u00b7 \u3008u,\u03a8Mu\u3009/(\u30081dG , u\u3009)2 \u2265 1 (defined for \u30081dG , u\u3009 6= 0). (Proof in Appendix, Subsection 7.5) The equation depends on \u03a0(b) since \u03be(b) = (2\u30081dG ,\u03a8\u22121M 1dG\u3009/(\u03b1n2))\u00b7 \u03a0(b) \u221d \u03a0(b). The question is now how large can r be independently of the mutation process, under the constraint that the mutator picks b \u221d \u03b1b\u2032 with \u03b1 = O( ) and \u30081dG , b\u2032\u3009 constant (call it setting \u201cD\u201d). This prevents this mutator to \u201cartificially\u201d beat ours just because of the magnitude of mutations. Let us define vectors `l . = [\u30081dG ,\u03a8\u22121M 1dG\u3009 \u30081dG , t\u2212f\u3009]>, `r . = [\u30081dG , t\u2212f\u3009 \u3008t\u2212f,\u03a8M(t\u2212f)\u3009]> and `\u2217 .\n= [n r]>. We also put in (D) the constraint \u03be(t \u2212 f) > 1 (implying det[`l|`r] 6= 0), and the fact that the decomposition `\u2217 . = vl`l + vr`r satisfies |vl| + |vr| = O(tr[`l|`r]). This implies in particular that n, r cannot be significantly larger than \u2016t\u2212 f0\u20162dG , and so nature cannot have the organism \u201cjump\u201d from far (f0) to close to target (t) in just one or few mutations.\nLemma 32 Under settings (SF + D), returns on the efficient frontier satisfy r = O\u0303( ).\n(The bound, in Appendix, Subsection 7.6, is explicit without the tilde notation) Hence, in the (D) regime, the mutation mechanism on the efficient frontier enjoys a dependence on of the same order as that of superior beneficial mutations, that always exist in B under setting (SF) alone \u2014 if we modify our mutator so that it picks the best mutation at each iteration, like Opt-Sel in (Angelino and Kanade, 2014), then we are guaranteed to have mutations with a near-optimal dependence in throughout all GMON."}, {"heading": "7.2 Proof of Theorem 28", "text": "Let fj? \u2208 Gt be the first organism in the sequence f0, f1, ..., fT to hit Gt. Because of Theorem 13 and Lemma 14, with high probability, all organisms before fj? belong to GMON. We have two cases, either fj? \u2208 GMON or fj? \u2208 GMON. We know already that with high probability, as long as the mutated organism fj stays in GMON, its performance cannot decrease; therefore, if fj? \u2208 GMON, then all subsequent mutated organism in GMON also belong to Gt. What will be sufficient to show Theorem 28 will be to show that the sequence GMON, clamped to its first element not before fj? (we call it G ?\nMON ), satisfies\nCard(G ?\nMON \u2229 Gt) \u2265 N . (123)\nLet fj\u2032? denote the first element of G ? MON , with therefore j\u2032? \u2265 j? and fj\u2032?\u22121 \u2208 GMON. Let us define \u03b4 .\n= t \u2212 fj? , \u03b4\u2032\u2032 .\n= \u2211N\nk=1 \u03c3k\u03b1b\u03b2(k) and \u03b4 \u2032 .= \u03b4 \u2212 \u03b4\u2032\u2032, \u03c3k \u2208 {\u22121, 1} and \u03b2 : [N ] \u2192 [dB] gives the\nmutations chosen to evolve further fj\u2032? for N steps. All coordinates for \u03b4, \u03b4 \u2032, \u03b4\u2032\u2032, b\u03b2(k) are expressed in basis B\u2217. Using eq. (24) in Lemma 17 and the expression of M 0 in (23), and Lemma 17, we\nget, for any N \u2032 \u2208 [N ],\nEx\u223cD D\u03d5 fj\u2032? + \u2211\nk\u2208[N \u2032]\n\u03c3k\u03b1b\u03b2(k)  (x) \u2225\u2225\u2225\u2225\u2225\u2225 t(x)  = 1 2 \u00b7 \u3008B\u2217\u03b4\u2032,MB\u2217\u03b4\u2032\u3009\n\u2264 \u03b3 \u2032\n2 \u00b7 \u3008B\u2217\u03b4\u2032,\u03a8B\u2217\u03b4\u2032\u3009 . (124)\nWe then observe \u03b3\u2032\n2 \u00b7 \u3008B\u2217\u03b4\u2032,\u03a8B\u2217\u03b4\u2032\u3009 \u2264 \u03b3\u2032 \u00b7 \u3008B\u2217\u03b4,\u03a8B\u2217\u03b4\u3009+ \u03b1\u03b3\u2032 \u00b7 \u3008B\u2217\u03b4\u2032\u2032,\u03a8B\u2217\u03b4\u2032\u2032\u3009 (125) \u2264 \u03b3\u2032 \u00b7 \u3008B\u2217\u03b4,\u03a8B\u2217\u03b4\u3009+N \u2032\u03b1\u03b3\u2032 \u00b7 \u2211 k\u2208[N \u2032] \u3008B\u2217b\u03b2(k),\u03a8B\u2217b\u03b2(k)\u3009 (126)\n= \u03b3\u2032 \u00b7 \u3008B\u2217\u03b4,\u03a8B\u2217\u03b4\u3009+N \u2032\u03b1\u03b3\u2032 \u00b7 \u2211 k\u2208[N \u2032] Ex\u223cD[\u2016b\u03b2(k)(x)\u201622]\n\u2264 2\u03b3 \u2032\n\u03b3 \u00b7 Ex\u223cD[D\u03d5(fj\u2032?(x)\u2016t(x))] +N \u2032\u03b1\u03b3\u2032 \u00b7 \u2211 k\u2208[N \u2032] Ex\u223cD[\u2016b\u03b2(k)(x)\u201622](127)\n\u2264 2\u03b3 \u2032\n\u03b3 \u00b7 Ex\u223cD[D\u03d5(fj\u2032?(x)\u2016t(x))] +N \u2032\u03b1 \u00b7max{1, V } (128)\n= 2\u03b3\u2032\n\u03b3 \u00b7 Ex\u223cD[D\u03d5(fj\u2032?(x)\u2016t(x))] + N \u2032z\u03b1 U\n(129)\n\u2264 2\u03b3 \u2032 \u03b3 \u00b7 ( z\u03c4 + z\u03b1 + zT z\u03b1 ) \u00b7 + N \u2032z\u03b1 U\n(130)\n=\n( 2\u03b3\u2032 \u03b3 \u00b7 ( z\u03c4 + z\u03b1 + zT z\u03b1 ) + N \u2032z\u03b1 U ) \u00b7\n\u2264 ( 2\u03b3\u2032 \u03b3 \u00b7 ( z\u03c4 + z\u03b1 + zT z\u03b1 ) + Nz\u03b1 U ) \u00b7 (131)\n\u2264 . (132) Ineqs (125) and (126) hold because for any inner product \u3008., .\u3009 and set {u1, u2, ..., uM},\u2329\u2211\nk\u2208[M ] uk, \u2211 k\u2208[M ] uk\n\u232a \u2264 M \u00b7\n\u2211 k\u2208[M ] \u3008uk, uk\u3009 , (133)\nsince right hand side minus left hand side is \u2211\nk 6=k\u2032\u3008uk \u2212 uk\u2032 , uk \u2212 uk\u2032\u3009 \u2265 0. Ineq. (127) comes from Lemma 17. Ineq. (128) holds because of the definition of V in eq. (29). Eq. (129) holds because of the definition of \u03b1 in eq. (31). Finally, ineq. (130) holds because we know from ineq. (106) that since fj\u2032? 6\u2208 GMON, then fj\u2032? 6\u2208 Gt,D, and so\nEx\u223cD[D\u03d5(fj\u2032?(x)\u2016t(x))] \u2264 ( z\u03c4 + z\u03b1 +\nzT z\u03b1\n) \u00b7 , (134)\nand ineq. (132) holds because (z\u03c4 , z\u03b1, zT) \u2208 RN (Definition 27). Indeed, constraint (iii) yields equivalently\n2\u03b3\u2032 \u03b3 \u00b7 ( z2\u03b1 + z\u03b1z\u03c4 + zT ) + Nz2\u03b1 U \u2264 z\u03b1 ,\nwhich, after dividing by z\u03b1 > 0 yields that the factor in front of in eq. (131) is \u2264 1. Hence, the moment the sequence f0, f1, ... hits Gt, it shall stay inside Gt with high probability for at least N further evolution steps. This ends the proof of Theorem 28."}, {"heading": "7.3 Proof of Theorem 29", "text": "Let B\u2217 a basis for span(B). Suppose dim(span(B\u2217)) < dG and denote B\u22a5 any basis for the supplementary space of span(B\u2217) in G, and B\u22a5 its matrix in the orthonormal basis of G. Whenever t 6\u2208 span(B\u2217), there uniquely exists two vectors tin \u2208 span(B\u2217) and tout \u2208 span(B\u22a5) such that t = tin + tout.\nFor the sake of readability, we represent tin in B\u2217 and tout in B\u22a5, such that G 3 t = B\u2217tin + B\u22a5tout. This being defined, for any t\u2217 \u2208 span(B\u2217), we then have, for some M(t, t\u2217) 0:\nEx\u223cD[D\u03d5(f(x)\u2016t(x))] = Ex\u223cD[D\u03d5(f(x)\u2016t\u2217(x))] + Ex\u223cD[D\u03d5(t\u2217(x)\u2016t(x))] + Ex\u223cD[\u3008(t\u2217 \u2212 f)(x),\u2207\u03d5 \u25e6 t(x)\u2212\u2207\u03d5 \u25e6 t\u2217(x)\u3009] = Ex\u223cD[D\u03d5(f(x)\u2016t\u2217(x))] + Ex\u223cD[D\u03d5(t\u2217(x)\u2016t(x))]\n+\u3008B\u2217(t\u2217 \u2212 f),M(t, t\u2217)(B\u22a5tout + B\u2217tin \u2212 B\u2217t\u2217)\u3009 (135) = Ex\u223cD[D\u03d5(f(x)\u2016t\u2217(x))] + Ex\u223cD[D\u03d5(t\u2217(x)\u2016t(x))]\n+ \u3008t\u2217 \u2212 f, B\u2217>M(t, t\u2217)B\u22a5tout\u3009\ufe38 \ufe37\ufe37 \ufe38 =0 +\u3008B\u2217(t\u2217 \u2212 f),M(t, t\u2217)(B\u2217tin \u2212 Bt\u2217)\u3009 (136) = Ex\u223cD[D\u03d5(f(x)\u2016t\u2217(x))] + Ex\u223cD[D\u03d5(t\u2217(x)\u2016t(x))] + \u3008t\u2217 \u2212 f, B\u2217>M(t, t\u2217)B\u2217(tin \u2212 t\u2217)\u3009 . (137)\nThe first equality is the Bregman triangle equality (Amari and Nagaoka, 2000). Eq. (135) comes from Lemma 16 (matrix M(t, t\u2217) is defined as in (23); our notation puts in emphasis the fact that the matrix depends on t and t\u2217, but not on f ). We indeed have \u3008t\u2217 \u2212 f, B\u2217>M(t, t\u2217)B\u22a5tout\u3009 = 0 in eq. (136) since we can always choose B\u22a5 such that:\nB\u2217>M(t, t\u2217)B\u22a5 = 0 . (138)\nTo see that this holds, remark that B\u2217>M(t, t\u2217)B\u22a5 = (P>B\u2217)>(P>B\u22a5) for some transfer matrix P. Since it is a transfer matrix, rank(P>B\u2217) = rank(B\u2217) = dim(span(B\u2217)), so we can find d\u00d7 (dG \u2212 dim(span(B\u2217))) full rank matrix M\u0303 such that (P>B\u2217)>M\u0303 = 0, which allows to pick B\u22a5 = (P>)\u22121M\u0303, define accordingly B\u22a5 with the column vectors, and therefore ensures eq. (138) satisfied.\nWe need however to check that B\u2217 and B\u22a5 are indeed supplementary in G. Suppose that some h belongs to both spans of B\u2217 and B\u22a5 as defined here. Let h\u2217 and h\u22a5 be its (unique) coordinates in both sets, therefore satisfying B\u2217h\u2217 = B\u22a5h\u22a5. We obtain B\u2217h\u2217 = (P>)\u22121M\u0303h\u22a5, or equivalently (P>B\u2217)>P>B\u2217h\u2217 = (P>B\u2217)>M\u0303h\u22a5 = 0G, implying\nh\u2217 \u2208 ker((P>B\u2217)>P>B\u2217) = ker(B\u2217>M(t, t\u2217)B\u2217) ,\nand therefore h\u2217 = 0B\u2217 (since M(t, t\u2217) 0 and B\u2217 has full rank), and so h\u22a5 = 0B\u22a5 , and finally h = 0G, implying span(B\u2217)\u2229span(B>) = {0G} and since dim(span(B\u2217))+dim(span(B\u22a5)) = dG, B\u2217 and B\u22a5 are supplementary in G, as claimed.\nIn eq. (137), \u3008t\u2217 \u2212 f, B\u2217>M(t, t\u2217)B\u2217(tin \u2212 t\u2217)\u3009 zeroes over all f iff tin = t\u2217 since again ker(B\u2217>M(t, t\u2217)B\u2217) = {0B\u2217}. So\nEx\u223cD[D\u03d5(f(x)\u2016t(x))] = Ex\u223cD[D\u03d5(f(x)\u2016tin(x))] + Ex\u223cD[D\u03d5(tin(x)\u2016t(x))], \u2200f \u2208 G ,(139) from which we get, from the non-negativity of Bregman divergences and (ii) in setting (SF),\ntin = arg sup f\u2208span(B) Perft,\u03d5(f,D) .\nThen, since since the rightmost expectation in eq. (139) does not depend on f , we can equivalently reformulate the definitions of BENE and NEUT in eqs (3) and (4) by:\nBENE(f) = {g \u2208 N (f) : Perftin,\u03d5(g, S) \u2265 Perftin,\u03d5(f, S) + T} , (140) NEUT(f) = {g \u2208 N (f) : |Perftin,\u03d5(g, S)\u2212 Perftin,\u03d5(f, S)| \u2264 T} . (141)\nReplacing t by tin in TD, we get that Theorem 19 can now be applied with all three conditions in (SF) and guarantees this time from ineq. (6):\nPerftin,\u03d5(fT ,D) \u2265 \u2212 , (142) and so, from eq. (139),\nPerft,\u03d5(fT ,D) = Perftin,\u03d5(fT ,D) + sup f\u2208span(B) Perft,\u03d5(f,D)\n\u2265 sup f\u2208span(B) Perft,\u03d5(f,D)\u2212 ,\nas claimed."}, {"heading": "7.4 Proof of Theorem 30", "text": "First, we reformulate the definitions of BENE and NEUT in eqs (3) and (4) to fit to the model (Kanade et al., 2010):\nBENE(fj) = {g \u2208 N (fj) : Perftj ,\u03d5(g, S) \u2265 Perftj ,\u03d5(fj, S) + T} , (143) NEUT(fj) = {g \u2208 N (fj) : |Perftj ,\u03d5(g, S)\u2212 Perftj ,\u03d5(fj, S)| \u2264 T} . (144)\nWe also replace Gt,D by a sequence Gtj ,D, so GMON is now the prefix sequence of f0, f1, ... such that fj \u2208 Gtj ,D. The definition of Gtj ,D is the same as in (17).\nThe proof consists of three steps: first (part (i)), we show that Lemma 15 still holds when t is allowed to drift following ineq. (118). Then (part (ii)), we show that the bound in m is the same as in (18). Finally (part (iii)), we show that Lemma 14 also holds, completing the proof. Part (i) \u2014To prove the first part, let \u03b2(i) denote the index of the b. \u2208 B chosen by mutator at step i. We reuse ineq. (109), and get this time\nPerfti+1,\u03d5(fi+1,D) . = Perfti+1,\u03d5(fi + \u03c3\u03b1b\u03b2(i),D) \u2265 Perfti+1,\u03d5(fi,D) + \u03b1 ( T \u03b1 \u2212 \u03c4 )\n= Perfti+1,\u03d5(fi,D) + zT \u2212 z\u03b1z\u03c4 U2V \u00b7 2 . (145)\nNow, we use the Bregman triangle equality (Amari and Nagaoka, 2000), which yields\nEx\u223cD[D\u03d5(fi(x)\u2016ti(x))] = Ex\u223cD[D\u03d5(fi(x)\u2016ti+1(x))] + Ex\u223cD[D\u03d5(ti+1(x)\u2016ti(x))]\n+Ex\u223cD[\u3008(ti+1 \u2212 fi)(x),\u2207\u03d5 \u25e6 ti(x)\u2212\u2207\u03d5 \u25e6 ti+1(x)\u3009] , and so, reorganizing,\nPerfti+1,\u03d5(fi,D) = Perfti,\u03d5(fi,D) + Ex\u223cD[D\u03d5(ti+1(x)\u2016ti(x))] +Ex\u223cD[\u3008(ti+1 \u2212 fi)(x),\u2207\u03d5 \u25e6 ti(x)\u2212\u2207\u03d5 \u25e6 ti+1(x)\u3009] . (146)\nLemma 16 yields, for some symmetric positive definite M defined in the same way as in (23),\nEx\u223cD[\u3008(ti+1 \u2212 fi)(x),\u2207\u03d5 \u25e6 ti(x)\u2212\u2207\u03d5 \u25e6 ti+1(x)\u3009] = \u3008B\u2217(ti+1 \u2212 fi),MB\u2217(ti \u2212 ti+1)\u3009 = \u2212\u03b3\u2032|\u3008B\u2217(ti+1 \u2212 fi),\u03a8B\u2217(ti \u2212 ti+1)\u3009| (147) \u2265 \u2212\u03b3\u2032\u00b5\u2032\u2016ti+1 \u2212 fi\u2016G\u2016ti \u2212 ti+1\u2016G (148)\n\u2265 \u2212\u03b3\u2032\u00b5\u2032 ( \u2016t0 \u2212 fi\u2016G +\ni+1\u2211 k=1\n\u2016tk+1 \u2212 tk\u2016G ) \u00b7 \u2016ti+1 \u2212 ti\u2016G (149)\n. = \u2212\u03b3\u2032\u00b5\u2032 ( \u2016t0 \u2212 fi\u2016G +\ni+1\u2211 k=1 \u03bdk\n) \u00b7 \u03bdi+1 , (150)\nwhere we denote \u03bdk . = \u2016tk+1 \u2212 tk\u2016G. Ineqs (147) and (148) hold because of the definition and properties of \u03a8 and Cauchy-Schwartz inequality. Inequality (149) holds because of the triangle inequality. Now, we also have Ex\u223cD[D\u03d5(ti+1(x)\u2016ti(x))] = \u2212Perfti,\u03d5(ti+1,D) \u2265 (1/2)\u03b3\u00b5 \u00b7 \u03bdi+1 because of Lemma 25, so if we fold ineq (150) and eq. (146) into ineq. (145), then we get, \u2200fi \u2208 GMON, Perfti+1,\u03d5(fi+1,D)\n\u2265 Perfti,\u03d5(fi,D) + \u03b3\u00b5\n2 \u00b7 \u03bdi+1 \u2212 \u03b3\u2032\u00b5\u2032\n( \u2016t0 \u2212 fi\u2016G +\ni+1\u2211 k=1 \u03bdk\n) \u00b7 \u03bdi+1 +\nzT \u2212 z\u03b1z\u03c4 U2V \u00b7 2\n= Perfti,\u03d5(fi,D)\u2212 \u03bdi+1 2 \u00b7 ( \u03b3\u2032\u00b5\u2032 ( \u2016t0 \u2212 fi\u2016G + i+1\u2211 k=1 \u03bdk ) \u2212 \u03b3\u00b5 ) + zT \u2212 z\u03b1z\u03c4 U2V \u00b7 2\n\u2265 Perfti,\u03d5(fi,D)\u2212 \u03bdi+1 2 \u00b7 ( \u03b3\u2032\u00b5\u2032 (\u221a \u03b3\u2032\u00b5\u2032 \u03b3\u00b5 \u00b7 TD max i\u2208[dB]\u2217 \u2016bi\u2016G + i+1\u2211 k=1 \u03bdk ) \u2212 \u03b3\u00b5 ) + zT \u2212 z\u03b1z\u03c4 U2V \u00b7 2 (151)\n\u2265 Perfti,\u03d5(fi,D)\u2212 \u03bdi+1\n2 \u00b7 \u03b3\u2032\u00b5\u2032 1 + max { 1, 2\u03b3\u2032\u00b5\u2032 \u03b3\u00b5 \u00b7 T 2D max i\u2208[dB]\u2217 \u2016bi\u20162G } \ufe38 \ufe37\ufe37 \ufe38\n. =W\n+ i+1\u2211 k=1 \u03bdk \u2212 \u03b3\u00b5 \n+ zT \u2212 z\u03b1z\u03c4 U2V \u00b7 2 , (152)\nwhere ineq. (151) follows from ineq. (99). Now, remark that \u03b3\u2032\u00b5\u2032W \u2212 \u03b3\u00b5 > 0, and suppose we ensure that, if fi \u2208 GMON, \u2200i \u2208 [T ]\u2217, then\n\u03bdi+1 \u2264 \u03b7 \u00b7 zT \u2212 z\u03b1z\u03c4\nU2V (\u03b3\u2032\u00b5\u2032W \u2212 \u03b3\u00b5) \u221a T \u00b7 2 , (153)\nfor some \u03b7 > 0. In this case, assuming that the outermost parenthesis is non negative, and letting X . = (zT \u2212 z\u03b1z\u03c4 )/(U2V ), we can assert\nPerfti+1,\u03d5(fi+1,D) \u2265 Perfti,\u03d5(fi,D)\u2212 ( \u03b7 \u00b7 X\n2 \u221a T \u00b7 2 + \u03b72 \u00b7 \u03b3\n\u2032\u00b5\u2032X2\n2(\u03b3\u2032\u00b5\u2032W \u2212 \u03b3\u00b5) \u00b7 4\n) +X \u00b7 2 .(154)\nNow, we want to fing \u03b7 such that:\n\u03b7 \u00b7 X 2 \u221a T \u00b7 2 + \u03b72 \u00b7 \u03b3\n\u2032\u00b5\u2032X2\n2(\u03b3\u2032\u00b5\u2032W \u2212 \u03b3\u00b5) \u00b7 4 \u2264 X 2 \u00b7 2 .\nReorganizing, we find that it is sufficient that\n\u03b72 \u00b7 \u03b3 \u2032\u00b5\u2032X\n\u03b3\u2032\u00b5\u2032W \u2212 \u03b3\u00b5 \u00b7 2 + \u03b7\u221a T \u2212 1 \u2264 0 ,\nand so we need\n\u03b7 \u2264 (\u03b3 \u2032\u00b5\u2032W \u2212 \u03b3\u00b5) 2\u03b3\u2032\u00b5\u2032X \u221a T \u00b7 (\u221a 1 + 4T\u03b3\u2032\u00b5\u2032X \u03b3\u2032\u00b5\u2032W \u2212 \u03b3\u00b5 \u00b7 2 \u2212 1 ) .\nSince \u221a 1 + x \u2265 1 + (x/2)\u2212 x2/8 \u2265 0 for x \u2208 [0, 2(1 + \u221a 3)], it is sufficient that\n\u03b7 \u2264 \u221a T \u00b7 2 \u00b7 ( 1\u2212 T\u03b3 \u2032\u00b5\u2032X\n\u03b3\u2032\u00b5\u2032W \u2212 \u03b3\u00b5 \u00b7 2\n) , (155)\nand we want\nT < \u03b3\u2032\u00b5\u2032W \u2212 \u03b3\u00b5 \u03b3\u2032\u00b5\u2032X \u00b7 1 2 2 . (156)\nIn this case, we can check that 4T\u03b3\u2032\u00b5\u2032X/(\u03b3\u2032\u00b5\u2032W \u2212 \u03b3\u00b5) < 2 < 2(1 + \u221a\n3). Replacing X and W by their expressions, we want equivalently\nT \u2264 U 2V \u03b3\u2032\u00b5\u2032 zT \u2212 z\u03b1z\u03c4 \u00b7 ( 1 + max { 1, 2\u03b3\u2032\u00b5\u2032 \u03b3\u00b5 \u00b7 T 2D max i\u2208[dB]\u2217 \u2016bi\u20162G } \u2212 \u03b3\u00b5 \u03b3\u2032\u00b5\u2032 ) \u00b7 1 2 2 . (157)\nNow, we have\n1 + max{1, 2xy} \u2212 1 x \u2265 2y , \u2200x \u2265 1,\u2200y \u2265 0 , (158)\nand so to ensure ineq. (157), it is sufficient to ensure\nT \u2264 U 2V \u03b3\u2032\u00b5\u2032maxi\u2208[dB]\u2217 \u2016bi\u20162G\nzT \u2212 z\u03b1z\u03c4 \u00b7 T\n2 D 2 . (159)\nIn this case, we can fix\n\u03b7 =\n\u221a T\n2 \u00b7 2 , (160)\nwhich replaces ineq. (153) by\n\u03bdi+1 \u2264 zT \u2212 z\u03b1z\u03c4\n2U2V (\u03b3\u2032\u00b5\u2032W \u2212 \u03b3\u00b5) \u00b7 4 ,\nwhich holds if\n\u03bdi+1 \u2264 zT \u2212 z\u03b1z\u03c4\n2U2V (2 + T 2D maxi\u2208[dB]\u2217 \u2016bi\u20162G) \u00b7 4 . (161)\nIn this case, ineq. (154) becomes\nPerfti+1,\u03d5(fi+1,D) \u2265 Perfti,\u03d5(fi,D) + zT \u2212 z\u03b1z\u03c4\n2U2V \u00b7 2 . (162)\nSo if the drift is bounded as in ineq. (161), then we lose by a factor at most 2 over the improvement without drift as guaranteed in GMON by Lemma 15. We then need to check that the number of iterations in ineq. (112) now becomes\nT \u2265 U 2V \u03b3\u2032\u00b5\u2032maxi\u2208[dG]\u2217 \u2016bi\u20162G\nzT \u2212 z\u03b1z\u03c4 \u00b7 T\n2 D 2 , (163)\nwhose right-hand side matches ineq. (159). Since ineq. (152) is never tight, picking T of the order of the right-hand side of ineq. (163) allows for GMON to comply with ineq. (119) with a number of steps of the same order as for T in Lemma 15. Hence, Lemma 15 still holds.\nPart (ii) \u2014 Notice that as long as fj \u2208 GMON, we can still bound \u2016tj \u2212 fj\u20162G in the same way as we do in ineq. (99), because ineq. (98) can still be used via the fact that Perfti+1,\u03d5(fi+1,D) \u2265 Perfti,\u03d5(fi,D), as shown by ineq. (162), so the order of the number of examples in ineq. (18) does not change because the order of T does not change.\nPart (iii) \u2014 Because of the definition of Gtj ,D, if we let fj? to denote the first organism out of the prefix sequence GMON (fj?\u22121 is in GMON but fj? is not), and tj? the target at the same index in the target sequence, then ineq. (102) still holds with tj? , and so we shall observe again, in place of ineq. (107)\nEx\u223cD[D\u03d5(fj?(x)\u2016tj?(x))] \u2264 \u03b3\u2032\u2016tj? \u2212 fj?\u2016G \u00b7 \u03c1(fj? , tj? |D) \u2264 , (164)\nwhich means\nPerftj? ,\u03d5(fj? ,D) \u2265 \u2212 ,\nand so fj? satisfies ineq. (119), as claimed."}, {"heading": "7.5 Proof of Theorem 31", "text": "Let \u03b4 .= t\u2212 f for short. We solve\nmin \u03a0(b) . = \u03b1\n2 \u00b7 \u3008b,\u03a8Mb\u3009 s.c. { \u3008b,\u03a8M\u03b4\u3009 = r \u30081dG , b\u3009 = n , (165)\nLetting \u03bbr and \u03bbn the two Lagrange multipliers for the two constraints, we obtain the first order condition \u03b1\u03a8Mb\u2212 \u03bbr\u03a8M\u03b4 \u2212 \u03b1\u03bbn1 = 0, i.e.,\nb = \u03bbr \u03b1 \u00b7 \u03b4 + \u03bbn \u03b1 \u00b7\u03a8\u22121 M 1dG , (166)\nfrom which we obtain, using the constraints, the following system:{ \u03b1r = \u03bbr \u00b7 \u3008\u03b4,\u03a8M\u03b4\u3009+ \u03bbn \u00b7 \u30081dG , \u03b4\u3009 \u03b1n = \u03bbr \u00b7 \u30081dG , \u03b4\u3009+ \u03bbn \u00b7 \u30081dG ,\u03a8\u22121M 1dG\u3009 .\nLemma 33 For any symmetric positive definite M, \u03a8M 0. The lemma is a direct consequence of assumption (iii) in (SF). Lemma 33 yields that \u03a8M is invertible. To simplify this system, let us denote for short:\nPb . = \u03b1\n2 \u00b7 \u3008b,\u03a8Mb\u3009 ,\nP\u03b4 . = \u03b1\n2 \u00b7 \u3008\u03b4,\u03a8M\u03b4\u3009 ,\nS . = \u30081dG ,\u03a8\u22121M 1dG\u3009 , \u2206\n. = \u30081dG , \u03b4\u3009 .\nWe obtain the simplified system:{ \u03b1r = 2P\u03b4\n\u03b1 \u00b7 \u03bbr + \u2206 \u00b7 \u03bbn\n\u03b1n = \u2206 \u00b7 \u03bbr + S \u00b7 \u03bbn , (167)\nadmitting the solution\n\u03bbr = \u03b12Sr \u2212 \u03b12\u2206n 2SP\u03b4 \u2212 \u03b1\u22062 , (168) \u03bbn = 2\u03b1P\u03b4n\u2212 \u03b12\u2206r 2SP\u03b4 \u2212 \u03b1\u22062 . (169)\nWe note that 2SP\u03b4 \u2212 \u03b1\u22062 = \u03b1(\u3008\u03b4,\u03a8M\u03b4\u3009\u30081dG ,\u03a8\u22121M 1dG\u3009 \u2212 (\u30081dG , \u03b4\u3009)2) \u2265 0 from Cauchy-Schwartz inequality. Suppose that 2SP\u03b4 \u2212 \u03b1\u22062 > 0. Multiplying eq. (166) by \u03b1\u03a8Mb yields\n2Pb = \u03bbrr + \u03bbnn\n= \u03b12Sr2 \u2212 \u03b12\u2206nr\n2SP\u03b4 \u2212 \u03b1\u22062 +\n2\u03b1P\u03b4n 2 \u2212 \u03b12\u2206nr\n2SP\u03b4 \u2212 \u03b1\u22062\n= \u03b12Sr2 \u2212 2\u03b12\u2206nr + 2\u03b1P\u03b4n2\n2SP\u03b4 \u2212 \u03b1\u22062 ,\nthat is, r is solution of\n\u03b12Sr2 \u2212 2\u03b12\u2206nr + 2(\u03b1P\u03b4n2 \u2212 2SPbP\u03b4 + \u03b1Pb\u22062) = 0 , from which\nr = \u2206n S \u00b1 1 \u03b1S\n\u221a \u03b12\u22062n2 \u2212 2S(\u03b1P\u03b4n2 \u2212 2SPbP\u03b4 + \u03b1Pb\u22062)\n= \u2206n S \u00b1 \u221a( \u2206n S )2 \u2212 2 \u03b12S (\u03b1P\u03b4n2 \u2212 2SPbP\u03b4 + \u03b1Pb\u22062)\n= \u2206n S \u00b1 \u221a( \u2206n S )2 \u2212 ( \u2206n S )2( 2S \u03b1\u22062 \u00b7 P\u03b4 \u2212 4S2 \u03b12\u22062n2 \u00b7 PbP\u03b4 + 2S \u03b1n2 \u00b7 Pb )\n= \u2206n S \u00b7 ( 1\u00b1 \u221a 1\u2212 (\u03be(\u03b4) + \u03be(b)\u2212 \u03be(\u03b4) \u00b7 \u03be(b)) ) = \u2206n S \u00b7 ( 1\u00b1 \u221a (\u03be(\u03b4)\u2212 1)(\u03be(b)\u2212 1) ) , (170)\nwith, whenever \u30081dG , u\u3009 6= 0,\n\u03be(u) . = \u30081dG ,\u03a8\u22121M 1dG\u3009\u3008u,\u03a8Mu\u3009\n(\u30081dG , u\u3009)2 \u2265 1 ,\nfrom Cauchy-Schwartz inequality. This ends the proof of Theorem 31 when \u2206 6= 0 and \u3008\u03b4,\u03a8M\u03b4\u3009\u30081dG ,\u03a8\u22121M 1dG\u3009\u2212 (\u30081dG , \u03b4\u3009)2 > 0.\nNow, if \u2206 = 0, r is solution of\n\u03b12Sr2 \u2212 2P\u03b4(2SPb \u2212 \u03b1n2) = 0 . (171) Remark that 2SPb \u2212 \u03b1n2 = \u03b1(\u30081dG ,\u03a8\u22121M 1dG\u3009\u3008b,\u03a8Mb\u3009 \u2212 (\u30081dG , b\u3009)2) \u2265 0 (Cauchy-Schwartz inequality and \u03b1 \u2265 0), so eq. (171) always has a solution,\nr = \u00b1 (n S ) \u00b7 \u221a 2SP\u03b4 \u03b1 \u00b7 (\u03be(b)\u2212 1) .\nTo finish up, when 2SP\u03b4 \u2212 \u03b1\u22062 = 0, system (167) simplifies to{ \u03b1Sr = \u2206 \u00b7 (\u2206 \u00b7 \u03bbr + S \u00b7 \u03bbn) \u03b1n = \u2206 \u00b7 \u03bbr + S \u00b7 \u03bbn ,\nand so r = \u2206n/S. We check that 2SP\u03b4\u2212\u03b1\u22062 = 0 is equivalent to stating \u03be(\u03b4) = 1, in which case we also check that eq. (170) becomes r = \u2206n/S."}, {"heading": "7.6 Proof of Lemma 32", "text": "We shall prove the more explicit bound that r = O(\u03c1(t\u2212 f0) \u00b7 ), with (here, x \u2228 y .= max{x, y})\n\u03c1(u) . = |\u30081dG , u\u3009|dG \u00b7 ( \u03b3\u2032\u00b5\u2032\n\u03b3\u00b5\n) 5 2 \u00b7 ( 1 \u2228 ( 1\n\u03b3\u2032\u00b5\u2032\n) + \u03b3\u00b5\u2016u\u2016dG\u221a\ndG \u00b7 1 \u2228 (\u2016u\u2016dG\u221a dG ))2 .\nLet us define for short 0 < \u03c8min \u2264 \u03c8max the minimal and maximal eigenvalues of \u03a8M. Let \u03b4 .= t\u2212f for short and column vectors\n`l = [ \u30081dG ,\u03a8\u22121M 1dG\u3009 \u30081dG , \u03b4\u3009 ] , `r = [ \u30081dG , \u03b4\u3009 \u3008\u03b4,\u03a8M\u03b4\u3009 ] , `\u2217 = [ n r ] .\nSince \u30081dG ,\u03a8\u22121M 1dG\u3009 \u2264 dG/\u03c8min and \u3008b,\u03a8Mb\u3009 \u2264 \u03c8max\u2016b\u20162dG , we have\n\u03be(b) = \u30081dG ,\u03a8\u22121M 1dG\u3009\u3008b,\u03a8Mb\u3009\nn2\n\u2264 dG\u03c8max n2\u03c8min \u00b7 \u2016b\u20162dG .\nWe have also from eq. (166),\n\u2016b\u20162dG = \u03bb2r \u03b12 \u00b7 \u2016\u03b4\u20162dG + 2\u03bbr\u03bbn \u03b12 \u00b7 \u3008\u03b4,\u03a8\u22121 M 1dG\u3009+ \u03bb2n \u03b12 \u00b7 \u30081dG ,\u03a8\u22122M 1dG\u3009 . (172)\nIt comes from eqs (168, 169),\n\u03bb2r \u03b12 = \u03b12(\u30081dG ,\u03a8\u22121M 1dG\u3009 \u00b7 r \u2212 \u30081dG , \u03b4\u3009 \u00b7 n)2 (\u30081dG ,\u03a8\u22121M 1dG\u3009\u3008\u03b4,\u03a8M\u03b4\u3009 \u2212 (\u30081dG , \u03b4\u3009)2)2 ,\n= \u03b12 det2[`l|`\u2217]\ndet2[`l|`r] ,\n\u03bbr\u03bbn \u03b12 = \u03b12 det[`l|`\u2217] det[`\u2217|`r] det2[`l|`r] ,\n\u03bb2n \u03b12 = \u03b12 det2[`\u2217|`r] det2[`l|`r] .\nUsing the fact that \u3008\u03b4,\u03a8\u22121 M 1dG\u3009 \u2264 \u221a dG\u2016\u03b4\u2016dG/\u03c8min and \u30081dG ,\u03a8\u22122M 1dG\u3009 \u2264 dG/\u03c82min, we obtain from eq. (172)\n\u03be(b) \u2264 dG\u03c8max \u03c8min \u00b7 (\u03b1 n )2 \u00b7 ( \u03c8min\u2016\u03b4\u2016dG \u00b7 det[`l|`\u2217] + \u221a dG \u00b7 det[`\u2217|`r] \u03c8min \u00b7 det[`l|`r] )2 . (173)\nLet vl, vr be such that `\u2217 = vl \u00b7 `l + vr \u00b7 `r. Such reals are guaranteed to exist since det[`l|`r] = \u30081dG ,\u03a8\u22121M 1dG\u3009 \u00b7 \u3008\u03b4,\u03a8M\u03b4\u3009 \u2212 (\u30081dG , \u03b4\u3009)2 6= 0 by assumption. Then det[`\u2217|`r] = vl \u00b7 det[`l|`r] and det[`l|`\u2217] = vr \u00b7 det[`l|`r]. We get\n\u03be(b) \u2264 dG\u03c8max \u03c8min \u00b7 (\u03b1 n )2 \u00b7 (\u221a dG \u03c8min + \u2016\u03b4\u2016dG )2 \u00b7 ( | det[`l|`\u2217]|+ | det[`\u2217|`r]| det[`l|`r] )2 = dG\u03c8max \u03c8min \u00b7 (\u03b1 n )2 \u00b7 (\u221a dG \u03c8min + \u2016\u03b4\u2016dG )2 \u00b7 (|vl|+ |vr|)2\n\u2264 dG\u03c8max \u03c8min \u00b7 (\u03b1 n )2 \u00b7 (\u221a dG \u03c8min + \u2016\u03b4\u2016dG )2 \u00b7 ( dG \u03c8min + \u03c8max\u2016\u03b4\u20162dG )2 . (174)\nAlgorithm 2 Simple-Evol(S) Input: sample S; Initialize f \u2190 f0; For t = 0, 1, ..., T \u2212 1 Step t.1: if t%1000 = 0 then B\u2190 Gen(S); Step t.2: Compute BENE(ft) and NEUT(ft) using N (ft) as in (7) Step t.3: if BENE(ft) 6= \u2205 then ft+1 \u223cunif. BENE(ft);\nelse if NEUT(ft) 6= \u2205 then ft+1 \u223cunif. NEUT(ft); else ft+1 \u223cunif. N (ft);\nReturn fT ;\nThe last inequality comes from assumption (D), since\ntr[`l|`r] = \u30081dG ,\u03a8\u22121M 1dG\u3009+ \u3008\u03b4,\u03a8M\u03b4\u3009\n\u2264 dG \u03c8min + \u03c8max\u2016\u03b4\u20162dG .\nIf n = \u03b8(\u03b1), then the dependence in the magnitude of mutations disappear and, taking the square root in ineq. (174),\n\u221a \u03be(b) = O (\u221a dG\u03c8max \u03c8min (\u221a dG \u03c8min + \u2016\u03b4\u2016dG ) \u00b7 ( dG \u03c8min + \u03c8max\u2016\u03b4\u20162dG )) , (175)\nout of which we get, assuming \u30081dG , \u03b4\u3009 6= 0, the following upperbound for returns on the efficient frontier:\nr = O\n{ |\u30081dG , \u03b4\u3009|\u03c8max dG \u00b7 ( 1 + \u221a dG\u03c8max \u03c8min (\u221a dG \u03c8min + \u2016\u03b4\u2016dG ) \u00b7 ( dG \u03c8min + \u03c8max\u2016\u03b4\u20162dG )) \u00b7 }\n= O { |\u30081dG , \u03b4\u3009| \u00b7 ( \u03c8max \u03c8min ) 3 2 \u00b7 ( 1 + \u03c8min\u2016\u03b4\u2016dG\u221a dG ) \u00b7 ( dG \u03c8min + \u03c8max\u2016\u03b4\u20162dG ) \u00b7 }\n= O { |\u30081dG , \u03b4\u3009|dG \u00b7 ( \u03c8max \u03c8min ) 5 2 \u00b7 ( 1 + \u03c8min\u2016\u03b4\u2016dG\u221a dG ) \u00b7 ( 1 \u03c8max + \u03c8min\u2016\u03b4\u20162dG dG ) \u00b7 }\n= O { |\u30081dG , \u03b4\u3009|dG \u00b7 ( \u03c8max \u03c8min ) 5 2 \u00b7 ( 1 \u2228 ( 1 \u03c8max ) + \u03c8min\u2016\u03b4\u2016dG\u221a dG \u00b7 1 \u2228 (\u2016\u03b4\u2016dG\u221a dG ))2 \u00b7 } .\nWe then conclude, noting that we can fix \u03c8min = \u03b3\u00b5 and \u03c8max = \u03b3\u2032\u00b5\u2032."}, {"heading": "8 Appendix \u2014 Toy experiments", "text": "We have performed some toy experiments to illustrate how evolution works with our simple mutator, in two different settings of machine learning, illustrated in the right column of Table 2.\nThe high-level implementation of the algorithm, Simple-Evol, is sketched in Algorithm 2 (Gen(S) returns a random set from S that generates R2) and explained below. \u21aa\u2192 Supervised learning: we generate a mixture of 2D spherical Gaussians with random variance and a random number of vectors in each; vectors of each Gaussian are all labeled positive (black) or negative (grey, class picked uniformly at random). The data is not linearly separable, so the optimal linear separator does not have zero error, and we are in the agnostic setting of Theorem 29. The performance chosen is (minus) the square loss. To speed the mutator, we threshold the number m of conditions sampled at each iteration to a maximum of 50000. \u21aa\u2192 Unsupervised: to guarantee an optimum that can be measured and compared with, the problem is the estimation of a sample mean. The performance of an organism f with respect to target \u00b5\u0302 is Perf\u00b5,\u03d5(f, S) . = \u2212\u2016f \u2212 \u00b5\u0302S\u201622. Notice that the target is the distribution\u2019s expectation. To complicate this easy task, we restrict the computation of \u00b5\u0302S over 5 vectors chosen at random in\nthe data. Hence, while the expectation of \u00b5\u0302S is still the sample\u2019s expectation, the variance of \u00b5\u0302S is large. In Table 2 (top right), the small green dots display the \u00b5\u0302S picked. They spread on a large portion of the domain around the target. In both supervised and unsupervised experiments, all data are normalized to fit in a disk of unit norm. we implement the mutator and all other parameters as they are given above, picking = 1\n10\nand B consisting of two randomly chosen vectors in the data that generate R2, flipped to get four mutations. Each 1000 evolvability steps, we renew the basis, still completely at random. Sometimes, in particular for the supervised experiment, both BENE and NEUT are empty. In this case of \u201cfailure\u201d, we just force evolution\u2019s hand by taking one of the mutants, chosen uniformly at random in the neighborhood. Therefore, there is not other optimization process carried out in our implementation than the weak optimization achieved by the mutator.\nTable 2 presents the results obtained. While it has no pretention whatsoever to bring significant experimental support for the theory developed \u2014 and even less to argue for any superiority of our approach against the state of the art \u2014, it displays interesting patterns of convergence. In particular, the conditions for evolvability to be met are achieved quite early in the process, and the the presence of failures in the supervised case does not prevent evolution to reach classifiers close to the optimal classifier in the longer run."}], "references": [], "referenceMentions": [], "year": 2017, "abstractText": "In Valiant\u2019s model of evolution, a class of representations is evolvable iff a polynomialtime process of random mutations guided by selection converges with high probability to a representation as -close as desired from the optimal one, for any required > 0. Several previous positive results exist that can be related to evolving a vector space, but each former result imposes restrictions either on (re)initialisations, distributions, performance functions and/or the mutator. In this paper, we show that all it takes to evolve a complete normed vector space is merely a set that generates the space. Furthermore, it takes only \u00d5(1/ 2) steps and it is essentially strictly monotonic, agnostic and handles target drifts that rival some proven in fairly restricted settings. In the context of the model, we bring to the fore new results not documented previously. Evolution appears to occur in a mean-divergence model reminiscent of Markowitz mean-variance model for portfolio selection, and the risk-return efficient frontier of evolution shows an interesting pattern: when far from the optimum, the mutator always has access to mutations close to the efficient frontier. Toy experiments in supervised and unsupervised learning display promising directions for this scheme to be used as a (new) provable gradient-free stochastic optimisation algorithm. keywords: Evolvability, phenotype/genotype, vector spaces, portfolio selection, Markowitz meanvariance model, Bregman divergence.", "creator": "LaTeX with hyperref package"}}}