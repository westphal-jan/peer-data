{"id": "1704.03275", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "11-Apr-2017", "title": "Scavenger 0.1: A Theorem Prover Based on Conflict Resolution", "abstract": "This paper introduces Scavenger, the first theorem prover for pure first-order logic without equality based on the new conflict resolution calculus. Conflict resolution has a restricted resolution inference rule that resembles (a first-order generalization of) unit propagation as well as a rule for assuming decision literals and a rule for deriving new clauses by (a first-order generalization of) conflict-driven clause learning.\n\n\n\nScavenger is a free-to-use tool for generating a testable set of theorem proofs, as well as a generic version of (an improved version) of (a previous version) the \"Scavenger Testable Testable-A\" (a version) that includes all the information about how the results are compared with other problems.\nSee also [ edit ]", "histories": [["v1", "Tue, 11 Apr 2017 13:11:57 GMT  (165kb,D)", "http://arxiv.org/abs/1704.03275v1", null], ["v2", "Tue, 31 Oct 2017 09:09:33 GMT  (168kb,D)", "http://arxiv.org/abs/1704.03275v2", "Published at CADE 2017"]], "reviews": [], "SUBJECTS": "cs.LO cs.AI cs.FL", "authors": ["daniyar itegulov", "john slaney", "bruno woltzenlogel paleo"], "accepted": false, "id": "1704.03275"}, "pdf": {"name": "1704.03275.pdf", "metadata": {"source": "CRF", "title": "Scavenger 0.1: A Theorem Prover Based on Conflict Resolution", "authors": ["Daniyar Itegulov", "John Slaney", "Bruno Woltzenlogel Paleo"], "emails": ["ditegulov@gmail.com", "john.slaney@anu.edu.au", "bruno.wp@gmail.com"], "sections": [{"heading": "1 Introduction", "text": "The outstanding efficiency of current propositional Sat-solvers naturally raises the question of whether it would be possible to employ similar ideas for automating first-order logical reasoning. The recent Conflict Resolution calculus (CR) [24] can be regarded as a crucial initial step to answer this question. From a prooftheoretical perspective, it generalizes to first-order logic the two main mechanisms on which modern Sat-solvers are based: unit propagation and conflict-driven clause learning. The calculus is proven sound (by simulation by a clausal natural deduction calculus) and refutationally complete (by simulation of the usual resolution calculus), and it is shown that subderivations in CR are isomorphic to the implication graphs maintained by Sat-solvers.\nThis paper goes one step further by defining proof search algorithms for CR. Familiarity with the propositional CDCL procedure [17] is assumed, even though it is briefly sketched in Section 2. The main challenge in lifting this procedure to first-order logic is that, unlike in propositional logic, first-order unit propagation does not always terminate and true clauses do not necessarily have uniformly true literals (cf. Section 4). Our solutions to these challenges are discussed in Section 5 and Section 6, and experimental results are presented in Section 7.\nRelated Work: Other attempts to lift DPLL [12, 18] or CDCL [17] to firstorder logic include Model Evolution [2, 4, 3, 23], Geometric Resolution [22], NonRedundant Clause Learning [1] and the Semantically-Guided Goal Sensitive procedure [5, 6, 8, 7]. A brief summary of these approaches and a comparison with\n? Author order is alphabetical by surname.\nar X\niv :1\n70 4.\n03 27\n5v 1\n[ cs\n.L O\n] 1\n1 A\nCR can be found in [24]. Furthermore, many architectures [11, 15, 16, 28, 10] for first-order and higher-order theorem proving use a Sat-solver as a black box for propositional reasoning, without attempting to lift it; and Semantic Resolution [25, 14] is yet another related approach that uses externally built first-order models to guide resolution."}, {"heading": "2 Propositional CDCL", "text": "During search in the propositional case, a Sat-solver keeps a model (a.k.a. trail) consisting of a (conjunctive) list of decision literals and propagated literals. Literals of unit clauses are automatically added to the trail, and whenever a clause has only one literal that is not falsified by the current model, this literal is added to the model (thereby satisfying that clause). This process is known as unit-propagation. If unit propagation reaches a conflict (i.e. a situation where the dual of a literal already contained in the model would have to be added to it), the Sat-solver backtracks, removing from the model decision literals responsible for the conflict (as well as propagated literals entailed by the removed decision literals) and deriving, or learning, a conflict-driven clause consisting1 of duals of the decision literals responsible for the conflict (or the empty clause, if there were no decision literals). If unit propagation terminates without reaching a conflict and all clauses are satisfied by the model, then the input clause set is satisfiable. If some clauses are still not satisfied, the Sat-solver chooses and assigns another decision literal, adding it to the trail, and satisfying the clauses that contain it."}, {"heading": "3 Conflict Resolution", "text": "The inference rules of the conflict resolution calculus CR are shown in Fig. 1. The unit propagating resolution rule is a chain of restricted resolutions with unit clauses as left premises and a unit clause as final conclusion. Decision literals are denoted by square brackets, and the conflict-driven clause learning rule allows to infer a new clause consisting of negations of instances of decision literals used to reach a conflict (a.k.a. the empty clause \u22a5). A clause learning inference is said to discharge the decision literals that it uses. As in the resolution calculus, CR derivations are directed acyclic graphs that are not necessarily tree-like. A CR refutation is a CR derivation of \u22a5 with no undischarged decision literals.\nFrom a natural deduction point of view, a unit propagating resolution rule can be regarded as a chain of implication eliminations taking unification into account, whereas decision literals and conflict driven clause learning are reminiscent of, respectively, assumptions and chains of negation introductions, also generalized to first-order through unification. Therefore, CR can be considered a first-order hybrid of resolution and natural deduction.\n1 In practice, optimizations (e.g. 1UIP) are used, and more sophisticated clauses, which are not just disjunctions of duals of the decision literals involved in the conflict, can be derived. But these optimizations are inessential to the focus of this paper."}, {"heading": "4 Lifting Challenges", "text": "First-order logic presents many new challenges for methods based on propagation and decisions, of which the following can be singled out:\n(1) non-termination of unit-propagation: In first-order logic, unit propagation may never terminate. For example, the clause set {p(a),\u00acp(X) \u2228 p(f(X)), q \u2228 r,\u00acq\u2228r, q\u2228\u00acr,\u00acq\u2228\u00acr} is clearly unsatisfiable, because there is no assignment of p and q to true or false that would satisfy all the last four clauses. However, unit propagation would derive the following infinite sequence of units, by successively resolving \u00acp(X) \u2228 p(f(X)) with previously derived units, starting with p(a): {p(f(a)), p(f(f(a))), . . . , p(f(. . . (f(a)) . . .)), . . .}. Consequently, a proof search strategy that would wait for unit propagation to terminate before making decisions would never be able to conclude that the given clause set is unsatisfiable.\n(2) absence of uniformly true literals in satisfied clauses: While in the propositional case, a clause that is true in a model always has at least one literal\nthat is true in that model, this is not so in first-order logic, because shared variables create dependencies between literals. For instance, the clause set {p(X) \u2228 q(X),\u00acp(a), p(b), q(a),\u00acq(b)} is satisfiable, but there is no model where p(X) is uniformly true (i.e. true for all instances of X) or q(X) is uniformly true.\n(3) propagation without satisfaction: In the propositional case, when only one literal of a clause is not false in the model, this literal is propagated and added to the model, and the clause necessarily becomes true in the model and does not need to be considered in propagation anymore, at least until backtracking. In the first-order case, on the other hand, a clause such as p(X) \u2228 q(X) would propagate the literal q(a) in a model containing \u00acp(a), but p(X)\u2228 q(X) does not become true in a model where q(a) is true. It must remain available for further propagations. If, for instance, the literal \u00acp(b) is added to the model, the clause will be used again to propagate q(b).\n(4) quasi-falsification without propagation: A clause is quasi-falsified by a model iff all but one of its literals are false in the model. In first-order logic, in contrast to propositional logic, it is not even the case that a clause will necessarily propagate a literal when only one of its literals is not false in the model. For instance, the clause p(X) \u2228 q(X) \u2228 r(X) is quasi-falsified in a model containing \u00acp(a) and \u00acq(b), but no instance of r(X) can be propagated.\nThe first two challenges affect the search in a conceptual level, and possible solutions are discussed in Section 5. The last two challenges prevent a direct firstorder generalization of the data structures (e.g. watched literals) that make unit propagation so efficient in the propositional case. Partial solutions are discussed in Section 6."}, {"heading": "5 First-Order Model Construction and Proof Search", "text": "Despite the fundamental differences between propositional and first-order logic described in the previous section, the first-order algorithms presented aim to adhere as much as possible to the propositional procedure sketched in the Section 2. As in the propositional case, the model under construction is a (conjunctive) list of literals, but literals may now contain (universal) variables. If a literal `[X] is in a model M , then any instance `[t] is said to be true in M . Note that checking that a literal ` is true in a model M is more expensive in first-order logic than in propositional logic: whereas in the latter it suffices to check that ` is in M , in the former it is necessary to find a literal `\u2032 in M and a substitution \u03c3 such that ` = `\u2032\u03c3. A literal ` is said to be strongly true in a model M iff ` is in M .\nThere is a straightforward solution for the second challenge (i.e. the absence of uniformly true literals in satisfied clauses): a clause is satisfied by a model M iff all its relevant instances have a literal that is true inM , where an instance is said to be relevant if it substitutes the clause\u2019s variables by terms that occur in M . Thus, for instance, the clause p(X)\u2228q(X) is satisfied by the model [\u00acp(a), p(b), q(a),\u00acq(b)], because both relevant instances p(a) \u2228 q(a) and p(b) \u2228 q(b) have literals that are\ntrue in the model. However, this solution is clearly costly, because it requires the generation of many instances. Fortunately, in many (though not all) cases, a satisfied clause will have a literal that is true in M , in which case the clause is said to be uniformly satisfied. Checking uniform satisfaction is cheaper than checking satisfaction. However, a drawback of uniform satisfaction is that the model construction algorithm may repeatedly attempt to satisfy a clause that is not uniformly satisfied, by choosing one of its literals as a decision literal. For instance, the clause p(X) \u2228 q(X) is not uniformly satisfied by the model [\u00acp(a), p(b), q(a),\u00acq(b)]. Without knowing that this clause is already satisfied by the model, the procedure would try to choose either p(X) or q(X) as a decision literal. But any of these choices is useless decision, because they would lead to a conflict with resulting conflict-driven clause equal to a previously derived clause or to a unit clause containing a literal that is part of the current model. A clause is said to be weakly satisfied by a model M if and only if all its literals are useless decisions.\nBecause of the first challenge (i.e. the non-termination of unit-propagation in the general first-order case), it is crucial to make decisions during unit propagation. In the example given in item 1 of Section 4, for instance, deciding q at any moment would allow the propagation of r and \u00acr (respectively due to the 4th and 6th clauses), triggering a conflict. The learned clause would be \u00acq and it would again trigger a conflict by the propagation of r and \u00acr (this time due to the 3rd and 5th clauses). As this last conflict does not depend on any decision literal, the empty clause is derived and thus the clause set is refuted. The question is how to interleave decisions and propagations. One straightforward approach is to keep track of the propagation depth2 in the implication graph: any decision literal or literal propagated by a unit clause has propagation depth 0; any other literal has propagation depth k + 1, where k is the maximum propagation depth of its predecessors. Then propagation is performed exhaustively only up to a propagation depth threshold h. A decision literal is then chosen and the threshold is incremented. Such eager decisions guarantee that a decision will eventually be made, even if there is an infinite propagation path. However, eager decisions may also lead to spurious conflicts generating useless conflictdriven clauses. For instance, the clause set {1 : p(a), 2 : \u00acp(X) \u2228 p(f(X)), 3 : \u00acp(f(f(f(f(f(f(a))))))), 4 : \u00acr(X)\u2228q(X), 5 : \u00acq(g(X))\u2228\u00acp(X), 6 : z(X)\u2228r(X)} (where clauses have been numbered for easier reference) is unsatisfiable, because a conflict with no decisions can be obtained by propagating p(a) (by 1), and then p(f(a)), p(f(f(a))), . . . , p(f(f(f(f(f(f(a))))))), (by 2, repeatedly), which conflicts with \u00acp(f(f(f(f(f(f(a))))))) (by 3). But the former propagation has depth 6. If the propagation depth threshold is lower than 6, a decision literal is chosen before that conflict is reached. If r(X) is chosen, for example, in an\n2 Because of the isomorphism between implication graphs and subderivations in Conflict Resolution [24], the propagation depth is equal to the corresponding subderivation\u2019s height, where initial axiom clauses and learned clauses have height 0 and the height of the conclusion of a unit-propagating resolution inference is k + 1 where k is the maximum height of its unit premises.\nattempt to satisfy the sixth clause, there are propagations (using r(X) and clauses 1, 4, 5 and 6) with depth lower than the threshold and reaching a conflict that generates the clause \u00acr(g(a)), which is useless for showing unsatisfiability of the whole clause set. This is not a serious issue, because useless clauses are often generated in conflicts with non-eager decisions as well. Nevertheless, this example suggests that the starting threshold and the strategy for increasing the threshold have to be chosen wisely, since the performance may be sensitive to this choice.\nInterestingly, the problem of non-terminating propagation does not manifest in fragments of first-order logic where infinite unit propagation paths are impossible. A well-known and large fragment is the effectively propositional (a.k.a. BernaysScho\u0308nfinkel) class, consisting of sentences with prenex forms that have an \u2203\u2217\u2200\u2217 quantifier prefix and no function symbols. For this fragment, a simpler proof search strategy that only makes decisions when unit propagation terminates, as in the propositional case, suffices. Infinite unit propagation paths do not occur in the effectively propositional fragment because there are no function symbols and hence the term depth3 does not increase arbitrarily. Whenever the term depth is bounded, infinite unit propagation paths cannot occur, because there are only finitely many literals with bounded term depth (given the finite set of constant, function and predicate symbols with finite arity occurring in the clause set).\nThe insight that term depth is important naturally suggests a different approach for the general first-order case: instead of limiting the propagation depth, limit the term depth instead, allowing arbitrarily long propagations as long as the term depth of the propagated literals are smaller than the current term depth threshold. A literal is propagated only if its term depth is smaller than the threshold. New decisions are chosen when the term-depth-bounded propagation terminates and there are still clauses that are not uniformly satisfied. As before, eager decisions may lead to spurious conflicts, but bounding propagation by term depth seems intuitively more sensible than bounding it by propagation depth."}, {"heading": "6 Implementation Details", "text": "Scavenger is implemented in Scala and its source code and usage instructions are available in https://gitlab.com/aossie/Scavenger. Its packrat combinator parsers are able to parse TPTP CNF files without let expressions [27]. Although Scavenger is a first-order prover, every logical expression is converted to a simply typed lambda expression, implemented by the abstract class E with concrete subclasses Sym, App and Abs for, respectively, symbols, applications and abstractions. A trait Var is used to distinguish variables from other symbols. Scala\u2019s case classes are used to make E behave like an algebraic datatype with (pattern-matchable) constructors. Simply typed lambda expressions are chosen despite Scavenger\u2019s current focus on untyped first-order logic, because we intend to generalize Scavenger to multi-sorted first-order logic and higher-order logic and support TPTP TFF and THF in the future. Every clause is internally represented\n3 The depth of constants and variables is zero and the depth of a complex term is k+ 1 when k is the maximum depth of its proper subterms.\nas an immutable two-sided sequent consisting of a set of positive literals in the succedent and a set of negative literals in the antecedent.\nWhen a problem is unsatisfiable, Scavenger can output a CR refutation, which is internally represented as a collection of ProofNode objects, which can be instances of the following immutable classes: UnitPropagatingResolution, Conflict, ConflictDrivenClauseLearning, Axiom, Decision. The first three classes correspond directly to the rules shown in Fig. 1. Axiom is used for leaf nodes containing input clauses, and Decision represents a fictive rule holding decision literals. Each class is responsible for checking, typically through require statements, the soundness conditions of its corresponding inference rule. The Axiom, Decision and ConflictDrivenClauseLearning classes are less than 5 lines of code each. Conflict and UnitPropagatingResolution are respectively 15 and 35 lines of code. The code for analyzing conflicts, traversing the subderivations (conflict graphs) and finding decisions that contributed to the conflict, is implemented in a superclass, and is 17 lines long.\nThe following three variants of Scavenger were implemented:\n\u2013 EP-Scavenger: This variant aims at the effectively propositional fragment. Propagation is not bounded, and decisions are made only when propagation terminates. \u2013 PD-Scavenger: Propagation is bounded by a propagation depth threshold starting at 0. Input clauses are assigned depth 0. Derived clauses and propagated literals obtained while the depth threshold is k are assigned depth k+1. The threshold is incremented whenever every input clause that is neither uniformly satisfied nor weakly satisfied is used to derive a new clause or to propagate a new literal. If this is not the case, a decision literal is chosen (and assigned depth k + 1) to uniformly satisfy one of the clauses that is neither uniformly satisfied nor weakly satisfied. \u2013 TD-Scavenger: Propagation is bounded by a term depth threshold starting at 0 and incrementing with 50% probability whenever propagation terminates (and choosing a decision literal when the threshold is not incremented). Only uniform satisfaction of clauses is checked.\nThe third and fourth challenges discussed in Section 4 are critical for performance, because they prevent a direct first-order generalization of data structures such as watched literals, which enables efficient detection of clauses that are ready to propagate literals. Without knowing exactly which clauses are ready to propagate, Scavenger (in its three variants) loops through all clauses with the goal of using them for propagation. However, actually trying to use a given clause for propagation is costly. In order to avoid this cost, Scavenger performs two quicker tests. Firstly, it checks whether the clause is uniformly satisfied (by checking whether one of its literals belongs to the model). If it is, then the clause is dismissed. This is an imperfect test, however. Occasionally, some satisfied clauses will not be dismissed, because (in first-order logic) not all satisfied clauses are uniformly satisfied. Secondly, for every literal ` of every clause, Scavenger keeps a set of decision literals and propagated literals that are unifiable with `. A clause c is quasi-falsified when at most one literal of c has an empty set associated with it.\nThis is a rough analogue of watched literals for detecting quasi-falsified clauses. Again, this is an imperfect test, because (in first-order logic) not all quasi-falsified clauses are ready to propagate. Despite the imperfections of these tests, they do reduce the number of clauses that need to be considered for propagation, and they are quick and simple to implement.\nOverall, the three variants of Scavenger listed above have been implemented very concisely. Their main classes are only 168, 342 and 176 lines long, respectively, and no attempt has been made to increase efficiency at the expense of code readability.\nScavenger still has no sophisticated backtracking and restarting mechanism, as propositional Sat-solvers do. When Scavenger reaches a conflict, it restarts almost completely: all derived conflict-driven clauses are kept, but the model under construction is reset to the empty model."}, {"heading": "7 Experiments", "text": "Experiments were conducted4 in the StarExec cluster [26] to evaluate Scavenger\u2019s performance on TPTP v6.4.0 benchmarks in CNF form and without equality. For comparison, all 29 provers available in StarExec\u2019s TPTP community and capable of reasoning on the selected benchmarks were evaluated as well. For each job pair, the timeouts were 300 CPU seconds and 600 Wallclock seconds.\n4 Raw experimental data are available at https://doi.org/10.5281/zenodo.293187.\nFig 2 shows how many of the 572 unsatisfiable effectively propositional problems each prover can solve within a given amount of time. As expected, TDScavenger outperforms PD-Scavenger, supporting the intuition that term depth is a more natural criterion for bounding unit propagation, and EP-Scavenger tends to be slightly faster than TD-Scavenger, although TD-Scavenger surprisingly solved one problem more than EP-Scavenger. For a first implementation, the best variants of Scavenger show an acceptable performance. Capable of solving 350 problems within the 300s time limit, TD-Scavenger outperformed LEO-II, ZenonModulo and Geo-III, and solved only 1 problem less than SOS-2.0 and 12 less than Otter-3.3. Although Otter-3.3 has long ceased to be a state-of-the-art prover and has been replaced by Prover9, the fact that Scavenger solves almost as many problems as Otter-3.3 is encouraging, because Otter-3.3 is a mature prover with 15 years of development, implementing (in the C language) several refinements of proof search for resolution and paramodulation (e.g. orderings, set of support, splitting, demodulation, subsumption) [19, 20], whereas Scavenger is a yet unrefined and concise implementation (in Scala) of a comparatively straightforward search strategy for proofs in the Conflict Resolution calculus, completed in slightly more than 3 months.\nFigure 3 shows the performance on all 1606 unsatisfiable (not necessarily effectively propositional) problems. All variants of Scavenger outperformed PEPR, GrAnDe, DarwinFM, Paradox, ZenonModulo and LEO-II; and EP-Scavenger additionally outperformed Geo-III. Solving 891 problems, EP-Scavenger was significantly better than PD-Scavenger (782) and TD-Scavenger (695). This suggests that non-termination of unit-propagation is an uncommon issue in practice: EP-Scavenger is still able to solve many problems, even though it does not care to bound propagation, whereas the other two variants solve fewer problems because of the overhead of bounding propagation even when it is not necessary. Nevertheless, there were 28 problems solved only by PD-Scavenger and 26 problems solved only by TD-Scavenger (among Scavenger\u2019s variants)."}, {"heading": "8 Conclusions and Future Work", "text": "Scavenger is the first theorem prover based on the new Conflict Resolution calculus. The experiments show that its performance is promising, albeit not yet competitive.\nA comparison of the performance of the three variants of Scavenger shows that it is non-trivial to interleave decisions within possibly non-terminating unitpropagations, and further research is needed to determine (possibly in a problem dependent way) optimal initial depth thresholds and threshold incrementation strategies. Alternatively, entirely different criteria could be explored for deciding to make an eager decision before propagation is over. For instance, decisions could be made if a fixed or dynamically adjusted amount of time elapses.\nThe performance bottleneck that needs to be most urgently addressed in future work is backtracking and restarting. Currently, all variants of Scavenger restart after every conflict, keeping derived conflict-driven clauses but throwing away the\nmodel construct so far. They must reconstruct models from scratch after every conflict. This requires a lot of repeated re-computation, and therefore a significant performance boost could be expected through a more sensible backtracking strategy. There might also be room to improve Scavenger\u2019s rough first-order analogue for the watched literals data structure, even though the first-order challenges make it unlikely that something as good as the propositional watched literals data structure could ever be developed. Furthermore Scavenger currently uses no term indexing [21] and its unification algorithm is implemented naively. Scavenger inherits from the proof compression system Skeptik [9] many data structures that had been implemented aiming at convenient proof manipulation instead of efficient theorem proving.\nScavenger\u2019s already acceptable performance despite the implementation improvement possibilities just discussed above indicates that automated theorem proving based on the Conflict Resolution calculus is feasible. However, much work remains to be done to determine whether this approach will eventually become competitive with today\u2019s fastest provers.\nAcknowledgments: We thank Ezequiel Postan for his implementation of TPTP parsers for Skeptik [9], which we have reused in Scavenger. We thank Albert A. V. Giegerich, Aaron Stump and Geoff Sutcliffe for all their help in setting up our experiments in StarExec. This research was partially funded by the Australian Government through the Australian Research Council and by the Google Summer of Code 2016 program."}], "references": [{"title": "Non-redundant clause learning", "author": ["G. Alagi", "C. Weidenbach"], "venue": "FroCoS. pp. 69\u201384", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2015}, {"title": "A first order Davis-Putnam-Longeman-Loveland procedure", "author": ["P. Baumgartner"], "venue": "Proceedings of the 17th International Conference on Automated Deduction (CADE). pp. 200\u2013219", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2000}, {"title": "Model evolution based theorem proving", "author": ["P. Baumgartner"], "venue": "IEEE Inteligent Systems 29(1), 4\u201310", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2014}, {"title": "The model evolution calculus", "author": ["P. Baumgartner", "C. Tinelli"], "venue": "CADE. pp. 350\u2013364", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2003}, {"title": "Constraint manipulation in SGGS", "author": ["M.P. Bonacina", "D.A. Plaisted"], "venue": "Proceedings of the Twenty-Eighth Workshop on Unification (UNIF), Seventh International Joint Conference on Automated Reasoning (IJCAR) and Sixth Federated Logic Conference (FLoC)", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2014}, {"title": "SGGS theorem proving: an exposition", "author": ["M.P. Bonacina", "D.A. Plaisted"], "venue": "Schulz, S., Moura, L.D., Konev, B. (eds.) Proceedings of the Fourth Workshop on Practical Aspects in Automated Reasoning (PAAR), Seventh International Joint Conference on Automated Reasoning (IJCAR) and Sixth Federated Logic Conference (FLoC), July 2014. EasyChair Proceedings in Computing (EPiC), vol. 31, pp. 25\u201338", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2015}, {"title": "Semantically-guided goal-sensitive reasoning: Inference system and completeness", "author": ["M.P. Bonacina", "D.A. Plaisted"], "venue": "Journal of Automated Reasoning", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2016}, {"title": "Semantically-guided goal-sensitive reasoning: Model representation", "author": ["M.P. Bonacina", "D.A. Plaisted"], "venue": "Journal of Automated Reasoning", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2016}, {"title": "Skeptik: A proof compression system", "author": ["J. Boudou", "A. Fellner", "B. Woltzenlogel Paleo"], "venue": "July 19-22,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2014}, {"title": "Satallax: An automatic higher-order prover", "author": ["C.E. Brown"], "venue": "Gramlich, B., Miller, D., Sattler, U. (eds.) IJCAR. Lecture Notes in Computer Science, vol. 7364, pp. 111\u2013117. Springer", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2012}, {"title": "The anatomy of Equinox \u2013 an extensible automated reasoning tool for first-order logic and beyond (talk abstract)", "author": ["K. Claessen"], "venue": "Proceedings of the 23rd International Conference on Automated Deduction (CADE-23). pp. 1\u20133", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2011}, {"title": "A computing procedure for quantification theory", "author": ["M. Davis", "H. Putnam"], "venue": "Journal of the ACM 7, 201\u2013215", "citeRegEx": "12", "shortCiteRegEx": null, "year": 1960}, {"title": "Automated Reasoning, First International Joint Conference, IJCAR 2001, Siena, Italy, June 18-23, 2001, Proceedings, Lecture Notes in Computer Science, vol", "author": ["R. Gor\u00e9", "A. Leitsch", "Nipkow", "T. (eds."], "venue": "2083. Springer", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2001}, {"title": "iProver - an instantiation-based theorem prover for first-order logic (system description)", "author": ["K. Korovin"], "venue": "Armando, A., Baumgartner, P., Dowek, G. (eds.) IJCAR. Lecture Notes in Computer Science, vol. 5195, pp. 292\u2013298. Springer", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2008}, {"title": "Inst-Gen - a modular approach to instantiation-based automated reasoning", "author": ["K. Korovin"], "venue": "Programming Logics. pp. 239\u2013270", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2013}, {"title": "Conflict-driven clause learning SAT solvers", "author": ["I.L. Jo\u00e3o Marques-Silva", "S. Malik"], "venue": "Handbook of Satisfiability, pp. 127 \u2013 149", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2008}, {"title": "A machine program for theorem proving", "author": ["G.L. Martin Davis", "D. Loveland"], "venue": "Communications of the ACM 57, 394\u2013397", "citeRegEx": "18", "shortCiteRegEx": null, "year": 1962}, {"title": "OTTER 3.3 reference manual", "author": ["W. McCune"], "venue": "CoRR cs.SC/0310056", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2003}, {"title": "Geometric resolution: A proof procedure based on finite model search", "author": ["H. de Nivelle", "J. Meng"], "venue": "3rd International Joint Conference on Automated Reasoning (IJCAR). pp. 303\u2013317", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2006}, {"title": "Lemma learning in the model evolution calculus", "author": ["A.F. Peter Baumgartner", "C. Tinelli"], "venue": "LPAR. pp. 572\u2013586", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2006}, {"title": "Conflict resolution: a first-order resolution calculus with decision literals and conflict-driven clause learning", "author": ["J. Slaney", "B. Woltzenlogel Paleo"], "venue": "Journal of Automated Reasoning pp", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2017}, {"title": "SCOTT: A model-guided theorem prover", "author": ["J.K. Slaney"], "venue": "Proceedings of the 13th International Joint Conference on Artificial Intelligence. Chambe\u0301ry, France, August 28 - September", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 1993}, {"title": "StarExec: A cross-community infrastructure for logic solving", "author": ["A. Stump", "G. Sutcliffe", "C. Tinelli"], "venue": "Proceedings. pp", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2014}, {"title": "The TPTP problem library and associated infrastructure: The FOF and CNF parts, v3.5.0", "author": ["G. Sutcliffe"], "venue": "Journal of Automated Reasoning", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2009}, {"title": "AVATAR: The architecture for first-order theorem provers", "author": ["A. Voronkov"], "venue": "CAV. pp. 696\u2013710", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2014}], "referenceMentions": [{"referenceID": 20, "context": "The recent Conflict Resolution calculus (CR) [24] can be regarded as a crucial initial step to answer this question.", "startOffset": 45, "endOffset": 49}, {"referenceID": 15, "context": "Familiarity with the propositional CDCL procedure [17] is assumed, even though it is briefly sketched in Section 2.", "startOffset": 50, "endOffset": 54}, {"referenceID": 11, "context": "Related Work: Other attempts to lift DPLL [12, 18] or CDCL [17] to firstorder logic include Model Evolution [2, 4, 3, 23], Geometric Resolution [22], NonRedundant Clause Learning [1] and the Semantically-Guided Goal Sensitive procedure [5, 6, 8, 7].", "startOffset": 42, "endOffset": 50}, {"referenceID": 16, "context": "Related Work: Other attempts to lift DPLL [12, 18] or CDCL [17] to firstorder logic include Model Evolution [2, 4, 3, 23], Geometric Resolution [22], NonRedundant Clause Learning [1] and the Semantically-Guided Goal Sensitive procedure [5, 6, 8, 7].", "startOffset": 42, "endOffset": 50}, {"referenceID": 15, "context": "Related Work: Other attempts to lift DPLL [12, 18] or CDCL [17] to firstorder logic include Model Evolution [2, 4, 3, 23], Geometric Resolution [22], NonRedundant Clause Learning [1] and the Semantically-Guided Goal Sensitive procedure [5, 6, 8, 7].", "startOffset": 59, "endOffset": 63}, {"referenceID": 1, "context": "Related Work: Other attempts to lift DPLL [12, 18] or CDCL [17] to firstorder logic include Model Evolution [2, 4, 3, 23], Geometric Resolution [22], NonRedundant Clause Learning [1] and the Semantically-Guided Goal Sensitive procedure [5, 6, 8, 7].", "startOffset": 108, "endOffset": 121}, {"referenceID": 3, "context": "Related Work: Other attempts to lift DPLL [12, 18] or CDCL [17] to firstorder logic include Model Evolution [2, 4, 3, 23], Geometric Resolution [22], NonRedundant Clause Learning [1] and the Semantically-Guided Goal Sensitive procedure [5, 6, 8, 7].", "startOffset": 108, "endOffset": 121}, {"referenceID": 2, "context": "Related Work: Other attempts to lift DPLL [12, 18] or CDCL [17] to firstorder logic include Model Evolution [2, 4, 3, 23], Geometric Resolution [22], NonRedundant Clause Learning [1] and the Semantically-Guided Goal Sensitive procedure [5, 6, 8, 7].", "startOffset": 108, "endOffset": 121}, {"referenceID": 19, "context": "Related Work: Other attempts to lift DPLL [12, 18] or CDCL [17] to firstorder logic include Model Evolution [2, 4, 3, 23], Geometric Resolution [22], NonRedundant Clause Learning [1] and the Semantically-Guided Goal Sensitive procedure [5, 6, 8, 7].", "startOffset": 108, "endOffset": 121}, {"referenceID": 18, "context": "Related Work: Other attempts to lift DPLL [12, 18] or CDCL [17] to firstorder logic include Model Evolution [2, 4, 3, 23], Geometric Resolution [22], NonRedundant Clause Learning [1] and the Semantically-Guided Goal Sensitive procedure [5, 6, 8, 7].", "startOffset": 144, "endOffset": 148}, {"referenceID": 0, "context": "Related Work: Other attempts to lift DPLL [12, 18] or CDCL [17] to firstorder logic include Model Evolution [2, 4, 3, 23], Geometric Resolution [22], NonRedundant Clause Learning [1] and the Semantically-Guided Goal Sensitive procedure [5, 6, 8, 7].", "startOffset": 179, "endOffset": 182}, {"referenceID": 4, "context": "Related Work: Other attempts to lift DPLL [12, 18] or CDCL [17] to firstorder logic include Model Evolution [2, 4, 3, 23], Geometric Resolution [22], NonRedundant Clause Learning [1] and the Semantically-Guided Goal Sensitive procedure [5, 6, 8, 7].", "startOffset": 236, "endOffset": 248}, {"referenceID": 5, "context": "Related Work: Other attempts to lift DPLL [12, 18] or CDCL [17] to firstorder logic include Model Evolution [2, 4, 3, 23], Geometric Resolution [22], NonRedundant Clause Learning [1] and the Semantically-Guided Goal Sensitive procedure [5, 6, 8, 7].", "startOffset": 236, "endOffset": 248}, {"referenceID": 7, "context": "Related Work: Other attempts to lift DPLL [12, 18] or CDCL [17] to firstorder logic include Model Evolution [2, 4, 3, 23], Geometric Resolution [22], NonRedundant Clause Learning [1] and the Semantically-Guided Goal Sensitive procedure [5, 6, 8, 7].", "startOffset": 236, "endOffset": 248}, {"referenceID": 6, "context": "Related Work: Other attempts to lift DPLL [12, 18] or CDCL [17] to firstorder logic include Model Evolution [2, 4, 3, 23], Geometric Resolution [22], NonRedundant Clause Learning [1] and the Semantically-Guided Goal Sensitive procedure [5, 6, 8, 7].", "startOffset": 236, "endOffset": 248}, {"referenceID": 20, "context": "CR can be found in [24].", "startOffset": 19, "endOffset": 23}, {"referenceID": 10, "context": "Furthermore, many architectures [11, 15, 16, 28, 10] for first-order and higher-order theorem proving use a Sat-solver as a black box for propositional reasoning, without attempting to lift it; and Semantic Resolution [25, 14] is yet another related approach that uses externally built first-order models to guide resolution.", "startOffset": 32, "endOffset": 52}, {"referenceID": 13, "context": "Furthermore, many architectures [11, 15, 16, 28, 10] for first-order and higher-order theorem proving use a Sat-solver as a black box for propositional reasoning, without attempting to lift it; and Semantic Resolution [25, 14] is yet another related approach that uses externally built first-order models to guide resolution.", "startOffset": 32, "endOffset": 52}, {"referenceID": 14, "context": "Furthermore, many architectures [11, 15, 16, 28, 10] for first-order and higher-order theorem proving use a Sat-solver as a black box for propositional reasoning, without attempting to lift it; and Semantic Resolution [25, 14] is yet another related approach that uses externally built first-order models to guide resolution.", "startOffset": 32, "endOffset": 52}, {"referenceID": 24, "context": "Furthermore, many architectures [11, 15, 16, 28, 10] for first-order and higher-order theorem proving use a Sat-solver as a black box for propositional reasoning, without attempting to lift it; and Semantic Resolution [25, 14] is yet another related approach that uses externally built first-order models to guide resolution.", "startOffset": 32, "endOffset": 52}, {"referenceID": 9, "context": "Furthermore, many architectures [11, 15, 16, 28, 10] for first-order and higher-order theorem proving use a Sat-solver as a black box for propositional reasoning, without attempting to lift it; and Semantic Resolution [25, 14] is yet another related approach that uses externally built first-order models to guide resolution.", "startOffset": 32, "endOffset": 52}, {"referenceID": 21, "context": "Furthermore, many architectures [11, 15, 16, 28, 10] for first-order and higher-order theorem proving use a Sat-solver as a black box for propositional reasoning, without attempting to lift it; and Semantic Resolution [25, 14] is yet another related approach that uses externally built first-order models to guide resolution.", "startOffset": 218, "endOffset": 226}, {"referenceID": 20, "context": "2 Because of the isomorphism between implication graphs and subderivations in Conflict Resolution [24], the propagation depth is equal to the corresponding subderivation\u2019s height, where initial axiom clauses and learned clauses have height 0 and the height of the conclusion of a unit-propagating resolution inference is k + 1 where k is the maximum height of its unit premises.", "startOffset": 98, "endOffset": 102}, {"referenceID": 23, "context": "Its packrat combinator parsers are able to parse TPTP CNF files without let expressions [27].", "startOffset": 88, "endOffset": 92}, {"referenceID": 22, "context": "Experiments were conducted in the StarExec cluster [26] to evaluate Scavenger\u2019s performance on TPTP v6.", "startOffset": 51, "endOffset": 55}, {"referenceID": 17, "context": "orderings, set of support, splitting, demodulation, subsumption) [19, 20], whereas Scavenger is a yet unrefined and concise implementation (in Scala) of a comparatively straightforward search strategy for proofs in the Conflict Resolution calculus, completed in slightly more than 3 months.", "startOffset": 65, "endOffset": 73}, {"referenceID": 8, "context": "Scavenger inherits from the proof compression system Skeptik [9] many data structures that had been implemented aiming at convenient proof manipulation instead of efficient theorem proving.", "startOffset": 61, "endOffset": 64}, {"referenceID": 8, "context": "Acknowledgments: We thank Ezequiel Postan for his implementation of TPTP parsers for Skeptik [9], which we have reused in Scavenger.", "startOffset": 93, "endOffset": 96}], "year": 2017, "abstractText": "This paper introduces Scavenger, the first theorem prover for pure first-order logic without equality based on the new conflict resolution calculus. Conflict resolution has a restricted resolution inference rule that resembles (a first-order generalization of) unit propagation as well as a rule for assuming decision literals and a rule for deriving new clauses by (a first-order generalization of) conflict-driven clause learning.", "creator": "TeX"}}}