{"id": "1704.05295", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "18-Apr-2017", "title": "Semantic Similarity from Natural Language and Ontology Analysis", "abstract": "Artificial Intelligence federates numerous scientific fields in the aim of developing machines able to assist human operators performing complex treatments -- most of which demand high cognitive skills (e.g. learning or decision processes) while they are in the process of learning.\n\n\n\n\nThe artificial intelligence is based on the idea that human behavior is made possible through conscious input and input -- such as \"thinking\", \"making\" the decision. It can be used to train humans to use the language, language, or visual information to better understand the problem. In addition, it can be used as a \"machine learning\" tool to assist humans in their tasks.\nThe aim of the Artificial Intelligence is to produce artificial intelligence within a short time frame. In the long run, human decision-making would have a large impact on human decision making.\nAs with human decisions, the goal is to produce a human's own decision, and then it will be used to train humans to practice them. However, there are limits in this approach, where artificial intelligence will not allow people to make decisions that will be easier for the human to make. However, such a limitation will result in an important limitation.\nIn order to implement the artificial intelligence, researchers must first understand the basic functions of the human brain, so that the machine can make the decision for those who are trained to perform their tasks. It is important to determine what is important to the machine's decision-making.\nThe Artificial Intelligence is not just a robot, but also a full-fledged machine. The robot will operate on human thought, speech and decision making.\nTo learn more about the artificial intelligence, see: The Artificial Intelligence\nThis article originally appeared on \"Inhumanity: Artificial Intelligence, Computers, and the Future\", the International Journal of Computers, December, 2013.", "histories": [["v1", "Tue, 18 Apr 2017 12:24:26 GMT  (2858kb,D)", "http://arxiv.org/abs/1704.05295v1", "preprint version of the book Semantic Similarity from Natural Language and Ontology Analysis (Synthesis Lectures on Human Language Technologies - Morgan &amp; Claypool publishers)"]], "COMMENTS": "preprint version of the book Semantic Similarity from Natural Language and Ontology Analysis (Synthesis Lectures on Human Language Technologies - Morgan &amp; Claypool publishers)", "reviews": [], "SUBJECTS": "cs.AI cs.CL", "authors": ["s\\'ebastien harispe", "sylvie ranwez", "stefan janaqi", "jacky montmain"], "accepted": false, "id": "1704.05295"}, "pdf": {"name": "1704.05295.pdf", "metadata": {"source": "CRF", "title": "Semantic Similarity from Natural Language and Ontology analysis preprint", "authors": ["S\u00e9bastien Harispe", "Sylvie Ranwez", "Stefan Janaqi", "Jacky Montmain"], "emails": [], "sections": [{"heading": null, "text": "Semantic Similarity\nfrom Natural Language and Ontology analysis\npreprint\nSe\u0301bastien Harispe, Sylvie Ranwez, Stefan Janaqi, Jacky Montmain Ecole des mines d\u2019Ale\u0300s - LGI2P\nar X\niv :1\n70 4.\n05 29\n5v 1\n[ cs\n.A I]\n1 8\nA pr\n2 01\n7\nii\nAbstract\nArtificial Intelligence federates numerous scientific fields in the aim of developing machines able to assist human operators performing complex treatments \u2013 most of which demand high cognitive skills (e.g. learning or decision processes). Central to this quest is to give machines the ability to estimate the likeness or similarity between things in the way human beings estimate the similarity between stimuli.\nIn this context, this book focuses on semantic measures: approaches designed for comparing semantic entities such as units of language, e.g. words, sentences, or concepts and instances defined into knowledge bases. The aim of these measures is to assess the similarity or relatedness of such semantic entities by taking into account their semantics, i.e. their meaning \u2013 intuitively, the words tea and coffee, which both refer to stimulating beverage, will be estimated to be more semantically similar than the words toffee (confection) and coffee, despite that the last pair has a higher syntactic similarity. The two state-of-theart approaches for estimating and quantifying semantic similarities/relatedness of semantic entities are presented in detail: the first one relies on corpora analysis and is based on Natural Language Processing techniques and semantic models while the second is based on more or less formal, computer-readable and workable forms of knowledge such as semantic networks, thesaurus or ontologies.\nSemantic measures are widely used today to compare units of language, concepts, instances, or even resources indexed by them (e.g., documents, genes). They are central elements of a large variety of Natural Language Processing applications and knowledge-based treatments, and have therefore naturally been subject to intensive and interdisciplinary research efforts during last decades. Beyond a simple inventory and categorization of existing measures, the aim of this monograph is to convey novices as well as researchers of these domains towards a better understanding of semantic similarity estimation and more generally semantic measures. To this end, we propose an in-depth characterisation of existing proposals by discussing their features, the assumptions on which they are based and empirical results regarding their performance in particular applications. By answering these questions and by providing a detailed discussion on the foundations of semantic measures, our aim is to give the reader key knowledge required to: (i) select the more relevant methods according to a particular usage context, (ii) understand the challenges offered to this field of study, (iii) distinguish room of improvements for state-of-the-art approaches and (iv) stimulate creativity towards the development of new approaches. In this aim, several definitions, theoretical and practical details, as well as concrete applications are presented.\nkeywords: Semantic similarity, semantic relatedness, semantic measures, distributional measures, domain ontology, knowledge-based semantic measure.\niii\niv\nContents"}, {"heading": "1 Introduction to semantic measures 1", "text": "1.1 Semantic measures in action . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2\n1.1.1 Natural Language Processing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2 1.1.2 Knowledge engineering, Semantic Web and Linked Data . . . . . . . . . . . . . . . 3 1.1.3 Biomedical Informatics & Bioinformatics . . . . . . . . . . . . . . . . . . . . . . . 3 1.1.4 Other applications . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4\n1.2 From similarity towards semantic measures . . . . . . . . . . . . . . . . . . . . . . . . . . 4 1.2.1 Human cognition, similarity and existing models . . . . . . . . . . . . . . . . . . . 4 1.2.2 Definitions of semantic measures and related vocabulary . . . . . . . . . . . . . . . 8 1.2.3 From distance and similarities to semantic measures . . . . . . . . . . . . . . . . . 12 1.3 Classification of semantic measures . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14 1.3.1 How to classify semantic measures . . . . . . . . . . . . . . . . . . . . . . . . . . . 14 1.3.2 A general classification of semantic measures . . . . . . . . . . . . . . . . . . . . . 16"}, {"heading": "2 Corpus-based semantic measures 19", "text": "2.1 From text analysis to semantic measures . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19 2.2 Semantic evidence of word similarity in natural language . . . . . . . . . . . . . . . . . . . 23\n2.2.1 The meaning of words . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23 2.2.2 Structural relationships: Paradigmatic and Syntagmatic . . . . . . . . . . . . . . 23 2.2.3 The notion of context . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24 2.2.4 Distributional semantics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 27\n2.3 Distributional measures . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29 2.3.1 Implementation of the distributional hypothesis . . . . . . . . . . . . . . . . . . . . 29 2.3.2 From distributional model to word similarity . . . . . . . . . . . . . . . . . . . . . 31 2.3.3 Capturing deeper co-occurrences . . . . . . . . . . . . . . . . . . . . . . . . . . . . 36 2.4 Other corpus-based measures . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 36 2.5 Advantages and limits of corpus-based measures . . . . . . . . . . . . . . . . . . . . . . . 37\n2.5.1 Advantages of corpus-based measures . . . . . . . . . . . . . . . . . . . . . . . . . 37 2.5.2 Limits of corpus-based measures . . . . . . . . . . . . . . . . . . . . . . . . . . . . 37\n2.6 Conclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 38"}, {"heading": "3 Knowledge-based semantic measures 39", "text": "3.1 Ontologies as graphs and formal notations . . . . . . . . . . . . . . . . . . . . . . . . . . . 40\n3.1.1 Ontologies as graphs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 40 3.1.2 Relationships . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 44 3.1.3 Graph traversals . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 44 3.1.4 Notations for taxonomies . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 44\n3.2 Types of semantic measures and graph properties . . . . . . . . . . . . . . . . . . . . . . . 46 3.2.1 Semantic measures on cyclic semantic graphs . . . . . . . . . . . . . . . . . . . . . 46 3.2.2 Semantic measures on acyclic graphs . . . . . . . . . . . . . . . . . . . . . . . . . . 50 3.3 Semantic evidence in semantic graphs and their interpretations . . . . . . . . . . . . . . . 50 3.3.1 Semantic evidence in taxonomies . . . . . . . . . . . . . . . . . . . . . . . . . . . . 50 3.3.2 Concept specificity . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 52 3.3.3 Strength of connotations between concepts . . . . . . . . . . . . . . . . . . . . . . 58 3.4 Semantic similarity between a pair of concepts . . . . . . . . . . . . . . . . . . . . . . . . 59 3.4.1 Structural approach . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 60 3.4.2 Feature-based approach . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 64\nv\nvi CONTENTS\n3.4.3 Information theoretical approach . . . . . . . . . . . . . . . . . . . . . . . . . . . . 65\n3.4.4 Hybrid approach . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 66\n3.4.5 Considerations when comparing concepts in semantic graphs . . . . . . . . . . . . 67\n3.4.6 List of pairwise semantic similarity measures . . . . . . . . . . . . . . . . . . . . . 69\n3.5 Semantic similarity between groups of concepts . . . . . . . . . . . . . . . . . . . . . . . . 78\n3.5.1 Direct approach . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 78\n3.5.2 Indirect approach . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 78\n3.5.3 List of groupwise semantic similarity measures . . . . . . . . . . . . . . . . . . . . 79\n3.6 Other knowledge-based measures . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 83\n3.6.1 Semantic measures based on logic-based semantics . . . . . . . . . . . . . . . . . . 83\n3.6.2 Semantic measures for multiple ontologies . . . . . . . . . . . . . . . . . . . . . . . 83\n3.7 Advantages and limits of knowledge-based measures . . . . . . . . . . . . . . . . . . . . . 84\n3.8 Mixing knowledge-based and corpus-based approaches . . . . . . . . . . . . . . . . . . . . 85\n3.8.1 Generalities . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 85\n3.8.2 Wikipedia-based measure: how to benefit from structured encyclopaedia knowledge 86\n3.9 Conclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 93"}, {"heading": "4 Evaluation of semantic measures 95", "text": "4.1 A general introduction to semantic measure evaluation . . . . . . . . . . . . . . . . . . . . 95\n4.2 Criteria for semantic measure evaluation . . . . . . . . . . . . . . . . . . . . . . . . . . . . 96\n4.2.1 Accuracy, Precision and Robustness . . . . . . . . . . . . . . . . . . . . . . . . . . 96\n4.2.2 Computational complexity . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 98\n4.2.3 Mathematical properties . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 98\n4.2.4 Semantics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 99\n4.2.5 Technical details . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 99\n4.3 Existing protocols and datasets . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 100\n4.3.1 Protocols used to compare measures . . . . . . . . . . . . . . . . . . . . . . . . . . 100\n4.3.2 Datasets . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 101\n4.4 Discussions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 112"}, {"heading": "5 Conclusion and research directions 115", "text": ""}, {"heading": "A Examples of syntagmatic contexts 123", "text": ""}, {"heading": "B A brief introduction to Singular Value Decomposition 127", "text": ""}, {"heading": "C Other models for representing units of language 129", "text": ""}, {"heading": "D Software tools and source code libraries 135", "text": "Bibliography 140\nAuthor\u2019s Biography 167\nPreface\nIn the last decades, numerous researchers from different domains have provided a lot of efforts developing and studying the notion of semantic measure and more specifically the notions of semantic similarity and semantic relatedness. Indeed, from the biomedical domain, where ontologies and conceptual annotations abound \u2013 e.g., genes are characterised by concepts from the Gene Ontology, scientific articles are indexed by terms defined into the Medical Subject Heading thesaurus (MeSH) \u2013 to Natural Language Processing (NLP) where text mining requires the semantics of units of language to be compared, researchers provided a vast body of research related to semantic measures: algorithms and approaches designed in the aim of comparing concepts, instances characterised by concepts and units of language w.r.t their meaning. Despite the vast literature dedicated to the domain, most of which is related to the definition of new measures, no extensive introduction proposes to highlight the large diversity of contributions which have been proposed so far. In this context, understanding the foundations of these measures, knowing the numerous approaches which have been proposed and distinguishing those to use in particular application contexts is challenging.\nThis book proposes an extended introduction to semantic measures targeting both students and domain experts. The aim is to provide a general introduction to the diversity of semantic measures in order to distinguish the central notions and the key concepts of the domain. In a second step, we present the two main families of measures to further discuss technical details related to specific implementations. By organising information about measures and by providing references to key research papers, our aim is to improve semantic measure understanding, to facilitate their use and to provide an condensed overview of state-of-the-art contributions related to the domain.\nThe first chapter introduces the motivations which highlight the importance of studying semantic measures. Starting by presenting various applications that benefit from semantic measures in different usage contexts, it then guides the reader towards a deeper understanding of those measures. Intuitive notions and the vocabulary commonly used in the literature are introduced. We present in particular the central notions of semantic relatedness, semantic similarity, semantic distance. . . More formal definitions and properties used for studying semantic measures are also proposed. Next, these definitions and properties are used to characterise the broad diversity of measures which have been introduced in the literature. A classification of semantic measures is then proposed; it distinguishes the two main approaches corresponding to corpus-based and knowledge-based semantic measures. These two families of semantic measures are further presented in detail in Chapter 2 and Chapter 3 respectively. The foundations of these measures and several implementations which have been proposed in the literature are discussed \u2013 software tools enabling practical use of measures are also presented in appendix. Chapter 4 is dedicated to semantic measures evaluation and selection. It presents several aspects of measures that can be studied for their comparison, as well as state-of-the-art protocols and datasets used for their evaluation. Finally, Chapter 5 concludes by summarising important notions which are introduced in this book, and by highlighting several important research directions which must be studied for improving both semantic measures and their understanding.\nBy following this progression, we hope that the reader will find a detailed and stimulating introduction to semantic measures. Our aim is to give the reader access to an extensive state-of-the-art of this field, as well as key knowledge required to: (i) select the more relevant methods according to a particular usage context, (ii) understand the challenges offered to this field of study, (iii) distinguish room of improvements for state-of-the-art approaches and (iv) stimulate creativity towards the development of new approaches.\nSe\u0301bastien Harispe, Sylvie Ranwez, Stefan Janaqi, and Jacky Montmain N\u0131\u0302mes \u2013 France, January 2015\nvii\nviii CONTENTS\nChapter 1\nIntroduction to semantic measures\nBack in the 60s, the quest for artificial intelligence (AI) had originally been motivated by the assumption that \u201c[. . . ] every aspect of learning or any other feature of intelligence can in principle be so precisely described that a machine can be made to simulate it [. . . ]\u201d (McCarthy et al., 2006). Even if this assumption has today proved to be pretentious and perhaps even unattainable, efforts are still made to design intelligent agents which are able to resolve complex problems and to perform elaborated tasks. To this end, AI federates numerous scientific communities to tackle a large diversity of problems in the aim of giving machines the ability to reason, to understand knowledge, to learn, to plan, to manoeuvre, to communicate, and to perceive (Russell and Norvig, 2009). Central to this quest is the ability to estimate some likeness between things in the way human is able to compare stimuli, e.g. to compare objects, situations. This is a key notion to induce reasoning and therefore to provide machines with intelligence, i.e., the \u201cability to acquire and apply knowledge and skills\u201d (Oxford Dict., 2012). In this context, numerous contributions have focused on designing and studying semantic measures for comparing semantic entities such as units of language, e.g. words, sentences, or concepts and instances defined into knowledge bases. The aim of these measures is to assess the similarity or relatedness of such semantic entities by taking into account their semantics, otherwise stated their meaning. These measures are cornerstones of refined processing of texts and ontologies and therefore play an important role in numerous domains.\nSemantic measures are widely used today to compare semantic entities such as units of language, concepts or even semantically characterised instances, according to information supporting their meaning. They are based on the analysis of semantic proxies, corpora of texts or ontologies1, from which semantic evidence can be extracted. Notice that here, according to the literature related to the field, the notion of semantic measure is not framed in the rigorous mathematical definition of measure. It should instead be understood as any theoretical tool, mathematical function, algorithm or approach which enables the comparison of semantic entities according to semantic evidence. Generally speaking, these measures are used to estimate the degree of semantic likeness between semantic entities through a numerical value. Therefore, even if a large diversity of measures exists to estimate the similarity or the distance between specific mathematical objects (e.g., vectors, matrices, graphs, sets, fuzzy sets), data structures (e.g., lists, objects) and data types (e.g., numbers, strings, dates), the main particularity of semantic measures compared to traditional similarity or distance functions relies on two aspects: (i) they are dedicated to the comparison of semantic entities and (ii) they are based on the analysis of semantic proxies from which semantic evidence can be extracted. This semantic evidence is expected to directly or indirectly characterise the meaning of compared elements. As an example, the measures used to compare two words according to their sequences of characters cannot be considered as semantic since only the characters of the words and their ordering is taken into account, not their meaning. Indeed, according to such syntactic measures, the two words car and vehicle would be regarded as distant despite their closely related semantics. Semantic measures enable to overcome the limitation of such syntactic measures by comparing semantic entities w.r.t their semantics. To this aim, semantic measures rely on the analysis of two broad types of semantic proxies: corpora of texts and ontologies. These semantic proxies are used to extract semantic evidence which will next be used by semantic measures to support the comparison of compared units of language, concepts or instances.\nThe first type of semantic proxy corresponds to unstructured or semi-structured texts (e.g., plain texts, dictionaries). These texts contain informal evidence of semantic relationships between units of language. Let us consider a simple example. Since it is common to drink coffee with sugar and nothing\n1Or more generally knowledge bases.\n1"}, {"heading": "2 CHAPTER 1. INTRODUCTION TO SEMANTIC MEASURES", "text": "particular links coffee to cats, most will agree that the pair of words (coffee,sugar) is more semantically coherent than the pair of words (coffee,cat) \u2013 otherwise stated that the words (coffee,sugar) are more semantically related than the words (coffee,cat). Interestingly, corpus of texts can be used to derive the same conclusion. To this end, a semantic measure will take advantage of the fact that the word coffee is more likely to co-occur with the word sugar than with the word cat. Simply stated, it is possible to use observations regarding the distribution of words in a corpus in order to estimate the strength of the semantic relationship which links two words, e.g., based on the assumption that semantically related words tend to co-occur.\nThe second type of semantic proxy from which semantic evidence can be extracted encompasses a large range of knowledge models. From structured vocabularies to highly formal ontologies, these proxies are structured and model, in an explicit manner, knowledge about the entities they define. As an example, in an ontology defining the concepts Coffee and Sugar, a specific relationship will probably explicitly define the link between the two concepts, e.g., that Coffee canBeDrinkWith Sugar. Semantic measures based on knowledge base analysis rely on techniques which take advantage of network-based (e.g., thesaurus, taxonomies), or logic-based ontologies to extract semantic evidence on which the comparison will be based.\nFrom gene analysis to recommendation systems, semantic measures have recently been found to cover a broad field of applications and are now essential metrics for leverage data mining, data analysis, classification, knowledge extraction, textual processing or even information retrieval based on text corpora or ontologies. They play an essential role in numerous treatments which require the analysis of the meaning (i.e., semantics) of compared entities. In this context, the study of semantic measures has always been an interdisciplinary effort. Communities of Psychology, Cognitive Sciences, Linguistics, Natural Language Processing, Semantic Web, and Biomedical informatics being among the most active contributors (2014). Due to the interdisciplinary nature of semantic measures, recent decades have been highly prolific in contributions related to the notion of semantic relatedness, semantic similarity and semantic distance, etc. This book provides an organised state of the art of semantic measures and proposes a classification of existing measures. Yet before introducing the technical aspects required to further introduce semantic measures, we will briefly discuss their large diversity of applications."}, {"heading": "1.1 Semantic measures in action", "text": "Semantic measures are used to solve problems in a broad range of applications and domains. They are essential tools for the design of numerous algorithms and treatments in which semantics matters. In this section, we present diverse practical applications involving semantic measures. Three domains of application are considered in particular: (i) Natural Language Processing, (ii) Knowledge Engineering/Semantic Web and Linked Data, and (iii) Biomedical informatics and Bioinformatics. Since they are transversal, additional applications related to information retrieval and clustering are also briefly considered.\nThe list of applications presented in this section is far from being exhaustive. An extensive classification of contributions related to semantic measures is proposed in the state-of-the-art presented in this manuscript (Harispe et al., 2013b, version 2). This classification underlines the broad range of applications of semantic measures and highlights the large number of communities involved."}, {"heading": "1.1.1 Natural Language Processing", "text": "Linguists have, quite naturally, been among the first to study semantic measures in the aim of comparing units of language (e.g., words, sentences, paragraphs, documents). The estimation of word/concept relatedness plays an important role in detecting paraphrasing, e.g., duplicate content and plagiarism (Fernando and Stevenson, 2008), in generating thesauri or texts (Iordanskaja et al., 1991), in summarising texts (Kozima, 1993), in identifying discourse structure, and in designing question answering systems (Bulskov et al., 2002; Freitas et al., 2011; Wang et al., 2012a) to mention a few. The effectiveness of semantic measures to resolve both syntactic and semantic ambiguities has also been demonstrated on several occasions, e.g., (Sussna, 1993; Resnik, 1999; Patwardhan, 2003).\nSeveral surveys related to the usage of semantic measures and to the techniques used for their design for natural language processing can be found in (Weeds, 2003; Curran, 2004; Sahlgren, 2008; Dinu, 2011; Mohammad and Hirst, 2012a; Panchenko, 2013)."}, {"heading": "1.1. SEMANTIC MEASURES IN ACTION 3", "text": ""}, {"heading": "1.1.2 Knowledge engineering, Semantic Web and Linked Data", "text": "Interest in semantic measures is still growing while several initiatives promote the Semantic Web and Linked Data paradigms to provide \u201can extension of the current [Web], in which information is given well-defined meaning, better enabling computers and people to work in cooperation\u201d (Berners-Lee et al., 2001).\nCommunities associated to Knowledge Engineering, Semantic Web and Linked Data play an import role in the definition of methodologies and standards to formally express machine-understandable knowledge representations. They extensively study the problematic associated to the expression of structured and controlled vocabularies, as well as ontologies, i.e., formal and explicit specification of a shared conceptualisation defining a set of concepts, their relationships and axioms to model a domain2 (Gruber, 1993). These models rely on structured knowledge representations in which the semantics of the concepts (classes) and relationships (properties) are rigorously and formally defined in an unambiguous way. These (on-going) efforts have led to the definition of several languages which can be used today to express formal, computer-readable and processable forms of knowledge. Such models are therefore proxies of choice to compare the concepts and the instances of the domain they model. As we will see, the taxonomy of concepts, which is the backbone of ontologies, is particularly useful to estimate the degree of similarity between concepts.\nIn this field, semantic measures can be used as part of processes aiming to integrate heterogeneous ontologies (refer to ontology alignment and instance matching) (Euzenat and Shvaiko, 2013); they are used to find similar/duplicate entities defined in different ontologies. Applications to provide inexact search capabilities over ontologies or to improve classical information retrieval techniques have also been proposed, e.g., (Hliaoutakis, 2005; Varelas et al., 2005; Hliaoutakis et al., 2006; Kiefer et al., 2007; Sy et al., 2012; Pirro\u0301, 2012). In this context, semantic measures have also been successfully applied to learning tasks using Semantic Web technologies (D\u2019Amato, 2007). Their benefits for designing recommendation systems based on the Linked Data paradigm have also been stressed, e.g., (Passant, 2010; Harispe et al., 2013a)."}, {"heading": "1.1.3 Biomedical Informatics & Bioinformatics", "text": "A large number of semantic measures have been defined in biomedical informatics and bioinformatics. In these domains, semantic measures are commonly used to study various types of instances which have been semantically characterised using ontologies (genes, proteins, drugs, diseases, phenotypes)3. Several surveys related to the usage of semantic measures in the biomedical domain underline the diversity of their applications, e.g. for diagnosis, disease classification, drug design and gene analysis (Pedersen et al., 2007; Pesquita et al., 2009a; Guzzi et al., 2012). As an illustration, here we focus on applications related to studies on the Gene Ontology (GO) (Ashburner et al., 2000).\nThe GO is the preferred example with which to highlight the large adoption of ontologies in biology; it is extensively used to conceptually annotate gene (products) on the basis of experimental observations or automatic inferences. A gene is classically annotated by a set of concepts structured in the GO. These annotations formally characterise genes regarding their molecular functions, their cellular location and the biological processes in which they are involved. Thanks to semantic measures, these annotations make the automatic comparison of genes possible, not on the basis of particular gene properties (e.g. nucleotidic/proteic sequence, structural similarity, gene expression), but rather on the analysis of biological aspects which are formalised by the GO. Genes can be further analysed by considering their representation in a semantic space expressing our current understanding of particular aspects of biology. In such cases, conceptual annotations bridge the gap between global knowledge of biology defined in the GO (e.g., organisation of molecular functions) and fine-grained understanding of specific instances (e.g., the specific role of a gene at molecular level). In this context, semantic measures enable computers to take advantage of this knowledge to analyse genes and therefore open interesting perspectives to infer new knowledge.\nAs an example, various studies have highlighted the relevance of semantic measures to assess the functional similarity of genes (Wang et al., 2007; Du et al., 2009), to build gene clusters (Sheehan et al., 2008), to validate and to study protein-protein interactions (Xu et al., 2008), to analyse gene expression (Xu et al., 2009), to evaluate gene set coherence (Diaz-Diaz and Aguilar-Ruiz, 2011) or to recommend\n2More about ontologies can be found in (Gruber, 1995; Guarino et al., 2009; Fernandez-Lopez and Corcho, 2010). 3Biology and biomedicine are heavy users of ontologies, e.g., BioPortal, a portal dedicated to ontologies related to\nbiology and the biomedical domain, references hundreds of ontologies (Whetzel et al., 2011)."}, {"heading": "4 CHAPTER 1. INTRODUCTION TO SEMANTIC MEASURES", "text": "gene annotations (Couto et al., 2006), among others. A survey dedicated to semantic measures applied to the GO can be found in (Guzzi et al., 2012)."}, {"heading": "1.1.4 Other applications", "text": "Information Retrieval (IR) uses semantic measures to overcome the limitations of techniques based on plain lexicographic term matching, i.e., simple IR models consider that a document is relevant according to a query only if the terms specified in the query occur in the document. Semantic measures enable the meaning of words to be taken into account by going over syntactic search. They can therefore be used to improve classic models, e.g., synonyms will no longer be considered as totally different words. As an example, semantic measures have been successfully used in the design of ontology-based information retrieval systems and for query expansion, e.g., (Hliaoutakis, 2005; Hliaoutakis et al., 2006; Varelas et al., 2005; Baziz et al., 2007; Saruladha et al., 2010b; Sy et al., 2012).\nAn important aspect is that semantic measures based on ontologies allow for the analysis and querying of non-textual resources and therefore do not restrict IR techniques in text analysis, e.g., genes annotated by concepts can be queried (Sy et al., 2012). In the same vein, the definition of efficient generic indexing solutions based on semantic measures are proposed in (Fiorini et al., 2014).\nGeoInformatics actively contributes to the study of semantic measures. In this domain, measures have for instance been used to compute the similarity between locations according to semantic characterisations of their geographic features (Janowicz et al., 2011), e.g. estimating the semantic similarity of tags defined in the OpenStreetMap Semantic Network4 (Ballatore et al., 2012). Readers interested in the application of semantic measures in this field may also refer to (Akoka et al., 2005; Andrea Rodr\u0301\u0131guez and Egenhofer, 2004; Rodr\u0301\u0131guez et al., 2005; Janowicz, 2006; Formica, 2008; Janowicz et al., 2008)."}, {"heading": "1.2 From similarity towards semantic measures", "text": "This section first introduces generalities related to the notion of similarity. We introduce in particular several models which have been proposed by cognitive sciences in order to study the human capacity to evaluate similarity of objects. Presenting these contributions will help us to better understand the models generally used to analyse object comparison. As we will see, they will be of specific interest for studying semantic measures. Indeed, the main models of similarity defined by cognitive sciences play an important role to understand the diversity of approaches which have been proposed to design semantic measures.\nThe next aim of this section is to introduce the vocabulary which is commonly used to refer to the notion of semantic measures, i.e. semantic similarity, semantic relatedness, semantic distance, etc. Several mathematical definitions and properties related to distance and similarity are also presented. These definitions will be further used to distinguish mathematical properties of interest for the characterization and the study of semantic measures in Section 1.3."}, {"heading": "1.2.1 Human cognition, similarity and existing models", "text": "Human capacity to evaluate the similarity of things (e.g., objects, stimuli) has long been studied by cognitive sciences and psychology. It has been characterised as a central element of the human cognitive system and is therefore understood nowadays as a pivotal notion to simulate intelligence (Rissland, 2006). It is indeed a key element to initiating the process of learning in which the capacity to recognise similar situations helps us to build our experience5, to activate mental traces, to make decisions, to innovate by applying experience gained in solving similar problems6 (Holyoak and Koh, 1987; Ross, 1987; Novick, 1988; Ross, 1989; Vosniadou and Ortony, 1989; Gentner and Markman, 1997). The importance of the notion of similarity for cognitive processes, and in particular for the process of learning, has also been stressed by the theories of transfer which highlights that new skills are expected to be easier to learn if similar to skills already learned (Markman and Gentner, 1993). In this context, similarity is therefore\n4http://wiki.openstreetmap.org/wiki/OSM_Semantic_Network 5Cognitive models based on categorisation consider that human classify things, e.g., experience of life, according to their similarity to some prototype, abstraction or previous examples (Markman and Gentner, 1993). 6Here the similarity is associated to the notion of generalisation and is measured in terms of probability of inter-stimulusconfusion errors (Nosofsky, 1992)."}, {"heading": "1.2. FROM SIMILARITY TOWARDS SEMANTIC MEASURES 5", "text": "commonly considered as a central component of memory retrieval, categorisation, pattern recognition, problem solving, reasoning, as well as social judgement, e.g., refer to Markman and Gentner (1993); Hahn et al. (2003); Goldstone and Son (2004) for associated references.\nAs we have seen, from mathematics to psychology, the notion of similarity is central in numerous fields and is particularly important for human cognition and intelligent system design. In this subsection, we provide a brief overview of the psychological theories of similarity by introducing the main models proposed by cognitive sciences to study and explain (human) appreciation of similarity.\nCognitive models of similarity generally aim to study the way humans evaluate the similarity of two mental representations according to some kind of psychological space (Tversky, 2004). They are therefore based on assumptions regarding the mental representation of the compared objects from which the similarity will be estimated. Indeed, as stated by several authors, the notion of similarity, per se, can be criticised as a purely artificial notion. In Goodman (1972), the notion of similarity is defined as \u201can imposture, a quack\u201d because objectively, everything is equally similar to everything else. The authors emphasise that, conceptually, two random objects have an infinitive number of properties in common and infinite different properties7, e.g. a flower and a computer are both smaller than 10m, 9.99m, 9.98m, etc. An important notion to understand, which has been underlined by cognitive sciences, is that different degrees of similarities emerge only when some predicates are selected or weighted more than others. As stated in Hahn (2011), \u201dthis important observation doesn\u2019t mean that similarity is not an explanatory notion but rather that the notion of similarity is heavily framed in psychology\u201d. Similarity assessment must therefore not be understood as an attempt to compare object realisations through the evaluation of their properties, but rather as a process aiming to compare objects as they are understood by the agent which estimates the similarity (e.g., a person, an algorithm). The notion of similarity therefore only makes sense according to the consideration of a partial (mental) representation on which the estimation of object similarity is based \u2013 this aspect of the notion of similarity will be essential for the rest of this book.\nContrary to real objects, representations of objects do not contain infinitesimal properties. As an example, our mental representations of things only capture a limited number of dimensions of the object which is represented. Therefore, the philosophical worries regarding the soundness of similarity vanish given that similarity aim at comparing partial representations of objects and not objects themselves, e.g., human mental representation of objects (Hahn, 2011). It is important to understand that studying human capacity to assess similarity, the similarity is thus estimated between mental representations \u2013 i.e. representations, not the real objects. This will also be the case for semantic similarity measures. Considering that these representations are the ones of a human agent, the notion of similarity may thus be understood as how similar objects appear to us. Considering the existential requirement of representations to compare things or objects, much of the history of research on similarity in cognitive sciences focuses on the definition of models of the mental representation of objects, to further consider measures which will be used to compare objects based on their representations.\nThe central role of cognitive sciences regarding the study of similarity relies on the design of cognitive models of both, mental representations and similarity. These models are used to study how humans store their knowledge and interact with it in order to compare object representations. Cognitive scientists then test these models according to our understanding of human appreciation of similarity. Indeed, evaluations of human appreciation of similarity help us to distinguish constraints/expectations on the properties an accurate model should have. This approach is essential to reject hypotheses and improve the models. As an example, studies have demonstrated that appreciation of similarity is sometimes asymmetric: the similarity between a person and his portrait is commonly expected to be lower than the inverse.8 Therefore, the expectation of asymmetric estimation of similarity is incompatible with the mathematical properties of a distance, which is symmetric by definition. Models based on distance axioms thus appeared inadequate and have to be revised or to be used with moderation. In this context, the introduction of cognitive models of similarity will be particularly useful to understand the foundations of some approaches adopted for the definition of semantic measures.\nCognitive models of similarity are commonly organised into four different approaches: (i) Spatial models, (ii) Feature models, (iii) Structural models and (iv) Transformational models. We briefly intro-\n7 This statement also stands if we restrict the comparison of objects to a finite set of properties. The reader may refer to Andersen\u2019s famous story of the Ugly Duckling. Proved by Watanabe and Donovan (1969), the Ugly Duckling theorem highlights the intrinsic bias associated to classification, showing that all things are equal and therefore that an ugly duckling is as similar to a swan as two swans are to each other. The important teaching is that biases are required to make a judgement and to classify, i.e., to prefer certain categories over others.\n8Indeed, Tversky (1977) stresses that We say \u201cthe portrait resembles the person\u201d rather than \u201cthe person resembles the portrait\u201d."}, {"heading": "6 CHAPTER 1. INTRODUCTION TO SEMANTIC MEASURES", "text": "duce these four models \u2013 more detailed introductions have been proposed by Goldstone and Son (2004) and Schwering (2008). A captivating talk introducing cognition and similarity, on which this introduction is based, can also be found in (Hahn, 2011).\nSpatial models\nThe spatial models, also named geometric models, rely on one of the most influencal theories of similarity in cognitive sciences. They are based on the notion of psychological distance and consider objects (here perceptual effects of stimuli or concepts) as points in a multi-dimensional metric space.\nSpatial models consider similarity as a function of the distance between the mental representations of the compared objects. These models derive from Shepard\u2019s spatial model of similarity. Objects are represented in a multi-dimensional space and their locations are defined by their dimensional differences (Shepard, 1962).\nIn his seminal work on generalisation, Shepard (1987) provides a statistical technique in the form of Multi-Dimensional Scaling (MDS) to derive locations of objects represented in a multi-dimensional space. MDS can be used to derive some potential spatial representations of objects from proximity data (similarity between pairs of objects). Based on these spatial representations of objects, Shepard derived the universal law of generalisation which demonstrates that various kinds of stimuli (e.g., Morse code signals, shapes, sounds) have the same lawful relationship between distance (in an underlined MDS) and perceive similarity measures (in terms of confusability) \u2013 the similarity between two stimuli was defined as an exponentially decreasing function of their distance9.\nBy demonstrating a negative exponential relationship between similarity and generalisation, Shepard established the first sound model of mental representation on which cognitive sciences will base their studies on similarity. The similarity is in this case assumed to be the inverse of the distance separating the perceptual representations of the compared stimuli (Ashby and Perrin, 1988). Similarity defined as a function of distance is therefore implicitly constrained to the axiomatic properties of distance \u2013 these properties will be detailed in the following chapter, Section 1.2.3.\nA large number of geometric models have been proposed. They have long been among the most popular in cognitive sciences. However, despite their intuitive nature and large popularity, geometric models have been subject to intense criticism due to the constraints defined by the distance axioms. Indeed, several empirical analyses have questioned and challenged the validity of the geometric framework (i.e., both the model and the notion of psychological distance), by underlying inconsistencies with human appreciation of similarity, e.g., violation of the symmetry, triangle inequality and identity of the indiscernibles, e.g. (Tversky, 1977; Tversky and Itamar, 1978; Tversky and Gati, 1982)10.\nFeature models\nTo respond to the limitation of the geometric models, Tversky (1977) proposes the feature model in which evaluated objects are manipulated through sets of features. A feature \u201cdescribes any property, characteristic, or aspect of objects that are relevant to the task under study\u201d (Tversky and Gati, 1982). Therefore, feature models evaluate the similarity of two stimuli according to a feature-matching function F which makes use of their common and distinct features:\nsimF (u, v) = F (U \u2229 V,U \\ V, V \\ U) (1.1)\nThe function F is expected to be non-decreasing, i.e., the similarity increases when common (distinct) features are added (removed). Feature models are thus based on the assumption that F is monotone and that common and distinct features of compared objects are enough for their comparison. In addition, an important aspect is that the feature-matching process is expressed in terms of a matching function as defined in set theory (i.e., binary evaluation).\nThe similarity of two objects is further derived as a parametrised function of their common and distinct features. Two models, the contrast model (simCM ) and the ratio model (simRM ) were initially\n9 The similarity between two stimuli is here understood as the probability that a response to one stimulus will be generalised to the other (Shepard, 1987). With sim(A,B) the similarity between two stimuli A,B and dist(A,B) their distance, we obtain the relation sim(A,B) = e\u2212dist(A,B), that is dist(A,B) = \u2212log sim(A,B), a form of entropy.\n10 Note that recent contributions propose to answer these inconsistencies by generalising the classical geometric framework through quantum probability (Pothos et al., 2013). Compared objects are represented in a quantum model in which they are not seen as points or distributions of points, but entire subspaces of potentially very high dimensionality, or probability distributions of these spaces."}, {"heading": "1.2. FROM SIMILARITY TOWARDS SEMANTIC MEASURES 7", "text": "proposed by Tversky (1977). They can be used to compare two objects u and v represented through sets of features U and V :\nsimCM (u, v) = \u03b3f(U \u2229 V )\u2212 \u03b1f(U \\ V )\u2212 \u03b2f(V \\ U) (1.2)\nsimRM (u, v) = f(U \u2229 V )\n\u03b1f(U \\ V ) + \u03b2f(V \\ U) + f(U \u2229 V ) (1.3)\nThe symmetry of the measures produced by the two models can be tuned according to the parameters \u03b1 and \u03b2. This enables the design of asymmetric measures. In addition, one of the major constructs of the feature model is the function f which is used to capture the salience of a (set of) feature(s). The salience of a feature is defined as a notion of specificity: \u201cthe salience of a stimulus includes intensity, frequency, familiarity, good form, and informational content\u201d (Tversky, 1977). Therefore, the operators \u2229,\u222a and \\ are based on feature matching (F ) and the function f evaluates the contribution of the common or distinct features (distinguished by previous operators) to estimate the similarity11.\nStructural alignment models\nStructural models are based on the assumption that objects are represented by structured representations. Indeed, a strong criticism of the feature model was that (features of) compared objects are considered to be unstructured, contrary to evidence suggesting that perceptual representations are well characterised by hierarchical systems of relationships, e.g., (Gentner and Markman, 1994; Markman and Gentner, 1993).\nStructural alignment models are structure mapping models in which the similarity is estimated using matching functions which will evaluate the correspondence between the compared elements (Gentner and Markman, 1994; Markman and Gentner, 1993). Here, the process of similarity assessment is expected to involve a structural alignment between two mental representations in order to distinguish correspondences. Hence, the greater the number of correspondences, the more similar the objects will be considered. In some cases, the similarity is estimated in an equivalent manner to analogical mapping (Markman and Gentner, 1990) and similarity is expected to involve mapping between both features and relationships.\nAnother example of a structural model was proposed by Goldstone (1996, 1994a), who proposed to model similarity as an interactive activation and mapping model using connectionism activation networks based on mappings between representations.\nTranformational models\nTransformational models assume that similarity is defined by the transformational distance between mental representations (Hahn et al., 2003). The similarity is framed in representational distortion (Chater and Hahn, 1997) and is expected to be assessed based on the analysis of the modifications required to transform one representation to another. The similarity, which can be explained in terms of the Kolmogorov complexity theory (Li and Vita\u0301nyi, 2008), is therefore regarded as a decreasing function of transformational complexity (Hahn et al., 2003).\nUnification of cognitive models of similarity\nSeveral studies highlighted links and deep parallels between the various cognitive models. Tenenbaum and Griffiths (2001) propose a unification of spatial, feature-based and structure-based models through a framework relying on the generalisation of Bayesian inference \u2013 see Gentner (2001) for criticisms. Alternatively, Hahn (2011) proposes to introduce the transformational model as a generalisation of the spatial, feature and structure-based models.\nIn this section, we have briefly presented several cognitive models which have been proposed to explain and study (human) appreciation of similarity. These models are characterised by particular interpretations and assumptions on the way knowledge is mentally represented and processed. This highlights that the notion of object representation is central for comparing objects, and directly impacts the second critical dimension of similarity: the strategy adopted to compare object representations in\n11As an example, the notion of the salience associated to a feature implicitly defines the possibility of designing measures which do not respect the identity of the indiscernibles, i.e. which enable non-maximal self-similarity."}, {"heading": "8 CHAPTER 1. INTRODUCTION TO SEMANTIC MEASURES", "text": "order to assess the similarity of objects. As we will see, these two components will be of major importance for the definition and characterisation of semantic measures.\nIn addition, we have also stressed that the fundamental differences between the models also rely on the conceptual approach used to explain similarity assessment, and more particularly on the mathematical properties of the measure which is used to compare the objects, e.g., symmetry, triangle inequality. These mathematical properties are also of major importance to better understand the models and the approaches which can be used to compare objects \u2013 similarly, semantic measures will also be analysed considering these mathematical properties.\nWe have also introduced that, interestingly and despite the strong differences between the different models presented, several meaningful initiatives have been undertaken to unify the cognitive models. To this end, researchers have proposed to develop frameworks which generalise existing models of similarity \u2013 once again this kind of initiative will also be found in studies related to semantic measures."}, {"heading": "1.2.2 Definitions of semantic measures and related vocabulary", "text": "Generalities\nThe goal of semantic measures is easy to understand \u2013 they aim to capture the strength of the semantic interaction between semantic elements (e.g., words, concepts) based on their meaning. Are the words car and auto more semantically related than the words car and mountain? Most people would agree that they are. This has been proved in multiple experiments, inter-human agreement on semantic similarity ratings is high, e.g. (Rubenstein and Goodenough, 1965; Miller and Charles, 1991; Pakhomov et al., 2010)12.\nAppreciation of similarity is obviously subject to multiple factors. Our personal background is an example of such a factor, e.g., elderly people and teenagers will probably not associate the same score of semantic similarity between the two concepts Phone and Computer13. However, most of the time, a consensus regarding the estimation of the strength of the semantic link between elements, i.e. semantic relatedness, can be reached (Miller and Charles, 1991) \u2013 this is what makes the notion of semantic measures intuitive and fascinating14.\nThe majority of semantic measures try to mimic the human capacity to assess the degree of relatedness between things according to semantic evidence. However, strictly speaking, semantic measures evaluate the strength of the semantic interactions between semantic entities according to the analysis of semantic proxies (texts, ontologies), nothing more. Thus, not all measures aim at mimicking human appreciation of similarity. In some cases, designers of semantic measures only aim to compare elements according to the information defined in a semantic proxy, no matter if the results produced by the measure correlate with human appreciation of semantic similarity/relatedness. This is, for instance, often the case in the design of semantic measures based on domain-specific ontologies. In these cases, the ontology can be associated to our understanding of the world, or a domain, and the semantic measure can be regarded as our capacity to take advantage of this knowledge to compare things. The aim, therefore, is to be coherent with the knowledge expressed in the considered semantic proxy, without regards to the coherence of the modelled knowledge. As an example, a semantic measure based on an ontology built by animal experts would not consider the two concepts Sloth and Monkey to be similar, even if most people think sloths are monkeys. Given that semantic measures aim at comparing things according to their meaning captured from semantic evidence, it is difficult to further define the notion of semantic measures without defining the concepts of Meaning and Semantics.\nThough risking the disappointment of the reader, this section will not face the challenge of demystifying the notion of Meaning. As stressed by Sahlgren (2006) \u201cSome 2000 years of philosophical controversy should warn us to steer well clear of such pursuits\u201d. The reader can refer to the various theories proposed by linguists and philosophers. In this contribution, we only consider that we are dealing with the notion of semantic meaning proposed by linguists: how meaning is conveyed through signs or language. Regarding the notion of semantics, it can be defined as the meaning or interpretation of any lexical units,\n12As an example, considering three benchmarks, Schwartz and Gomez (2011) observed 73% to 89% human interagreement between scores of semantic similarity associated to pairs of words.\n13Given that nowadays smartphones are kinds of computers and very different to the first communication devices. 14Despite some hesitations and interrogations regarding the notion of (semantic) similarity, it is commonly admitted that the notions related to similarity make sense. However, there are numerous examples of authors who question their relevance, e.g. \u201cSimilarity, ever ready to solve philosophical problems and overcome obstacles, is a pretender, an impostor, a quack.\u201d(Goodman, 1972) or \u201cMore studies need to performed with human subjects in order to discover whether semantic distance actually has any meaning independent of a particular person, and how to use semantic distance in a meaningful way\u201d (Delugach, 1993), refer also to the work of Murphy and Medin (1985); Goldstone (1994b); Hahn and Ramscar (2001)."}, {"heading": "1.2. FROM SIMILARITY TOWARDS SEMANTIC MEASURES 9", "text": "linguistic expressions or instances which are semantically characterised according to a specific context. We further generally define the notion of semantic measure by the following definition:\nDefinition: Semantic measures are mathematical tools used to estimate the strength of the semantic relationship between units of language, concepts or instances, through a (numerical) description obtained according to the comparison of information supporting their meaning.\nIt is important to stress the diversity of the domain (in a mathematical sense) in which semantic measures can be used. They can be used to drive word-to-word, concept-to-concept, text-to-text or even instance-to-instance comparisons. In this book, when we do not focus on a specific type of measure, we will refer, as much as possible, to any element of the domain of measures through the generic term element \u2013 which refers to semantic entities or entities semantically characterised. It can therefore be any unit of language (e.g. word, text), a concept/class, an instance which is semantically characterised in an ontology (e.g., gene products, ideas, locations, persons).\nWe formally define a semantic measure as a function:\n\u03c3k : Ek \u00d7 Ek \u2192 R+ (1.4)\nwith Ek the set of elements of type k \u2208 K and K, the various types of elements which can be compared regarding their semantics, e.g., K = {words, concepts, sentences, texts, webpages, instances annotated by concepts. . . }.\nThis expression can be generalised so as to take into account the comparison of different types of elements. This could be interesting to evaluate entailment of texts or to compare words and concepts, among others. However, here, we restrict our study to the comparison of pairs of elements of the same nature (a domain of study which is already a vast subject of research)15. In addition, the co-domain of the function \u03c3k could also be relaxed to consider measures which produce results defined into more complex scales, e.g. discrete or bipolar scales. For convenience we focus on measures which are defined in R+. We stress that semantic measures must implicitly or explicitly take advantage of semantic evidence. As an example, as we have said, measures comparing words through their syntactical similarity cannot be considered as semantic measures; recall that semantics refers to evidence regarding the meaning of compared elements.\nThe distinction between approaches that can and cannot be assimilated to semantic measures is sometimes narrow; there is no clear boundary distinguishing non-semantics to semantic-augmented approaches, but rather a range of approaches. Some explanations can be found in the difficulty of clearly characterising the notion of meaning. For instance, someone can say that measures used to evaluate the syntactical distance between words capture semantic evidence related to the meaning of the words. Indeed, the sequence of characters associated to a word derives from its etymology which is sometimes related to its meaning, e.g., words created through morphology derivation such as subset from set.\nTherefore, the notion of semantic measure is sometimes difficult to distinguish from measures used to compare specific data structures. This fine line can also be explained by the fact that some semantic measures compare elements which are represented through canonical forms corresponding to specific data structures for which specific (non-semantic) similarity measures have been defined. As an example, units of language represented as vectors can be compared using vector similarity measures, or pure graph similarity measures can be used to compare entities defined into semantic graphs.\nIn some cases, the semantics of the measure is therefore not captured by the measure used to compare the canonical forms of the elements. It is rather the process of mapping an element (e.g., word, concept) from a semantic space (text, ontology) to a specific data structure (e.g., vector, set), which semantically enhances the comparison. This, however, is an interesting paradox, the definition of the rigorous semantics of the notion of semantic measure is hard to define.\nHowever, an important aspect to underline is that, over the years, semantic measures have been studied through various notions and not always in rigorous terms, i.e. using a well-defined terminology. Some definitions are even still subject to debate and not all communities agree on the semantics carried by the terminology they use \u2013 the notions which are commonly used in the literature to refer to semantic measures are: semantic similarity, semantic relatedness, semantic distance, taxonomic distance, semantic dissimilarity, conceptual distance, etc. These notions can have different meanings depending on the\n15Note however, that semantic measures for the comparison of units of language of different sizes are also studied in the literature, e.g. to compare the meaning carried by sentences and paragraphes. For more information the reader can refer to the notion of cross-level semantic similarity (Jurgens et al., 2014)."}, {"heading": "10 CHAPTER 1. INTRODUCTION TO SEMANTIC MEASURES", "text": "communities and/or the authors which refer to them. This highlights the difficulty to define and reduce these notions into formal mathematical frameworks. We propose to clarify the definitions considered in this book.\nSemantic relatedness and semantic similarity\nAmong the various notions associated to semantic measures, this section defines the two central notions of semantic relatedness and semantic similarity, which are among the most commonly referred to in the literature. Several authors have already distinguished them in different communities, e.g., (Resnik, 1999; Pedersen et al., 2007). Based on these works, we propose the following definitions.\nDefinition Semantic relatedness: the strength of the semantic interactions between two elements with no restrictions on the types of the semantic links considered.\nNote that compared to the general definition of semantic measure, the notion of interaction used to define semantic relatedness refers to a positive value, i.e. the more two elements interact the more related they will be considered. As an example, compared to semantic relatedness, semantic distance refers to the degree of repulsion between the two compared elements.\nDefinition Semantic similarity : subset of the notion of semantic relatedness only considering taxonomic relationships in the evaluation of the semantic interaction between two elements.\nIn other words, semantic similarity measures compare elements regarding the constitutive properties they share and those which are specific to them. The two concepts Tea and Cup are therefore highly related despite the fact that they are not similar: the concept Tea refers to a Drink and the concept Cup refers to a Vessel. Thus, the two concepts share few of their constitutive properties. This highlights a potential interpretation of the notion of similarity, which can be understood in term of substitution, i.e., evaluating the implication to substitute the compared elements: Tea by Coffee or Tea by Cup.\nIn some specific cases, communities such as linguists will consider a more complex definition of the notion of semantic similarity for words. Indeed, word-to-word semantic similarity is sometimes evaluated not only considering (near-)synonymy, or the lexical relations which can be considered as equivalent to the taxonomic relationships for words, e.g., hyponymy and hypernymy or even troponymy for verbs. In some contributions, linguists also consider that the estimation of the semantic similarity of two words must also take into account other lexical relationships, such as antonymy (Mohammad and Hirst, 2012a) \u2013 different definitions of the notion of semantic similarity can be found in the literature.\nIn other cases, the notion of semantic similarity refers to the approach used to compare the elements, not the semantics associated to the results of the measure. As an example, designers of semantic measures relying on ontologies sometimes use the term semantic similarity to denote measures based on a specific type of semantic relatedness which only considers meronymy, e.g., partial ordering of concepts defined by partWhole relationships. The semantics associated to the scores of relatedness computed from such restrictions differs from semantic similarity.16 In this book, for the sake of clarity, we consider that only taxonomic relationships are used to estimate the semantic similarity of compared elements.\nOlder contributions related to semantic measures do not stress the difference between the notions of similarity and relatedness. The reader must therefore understand that in the literature, authors sometimes introduce semantic similarity measures which estimate semantic relatedness and vice versa. In addition, despite the fact that the distinction between the two notions is now commonly admitted by most communities, it is still common to observe improper use of both notions.\nExtensive terminology refers to the notion of semantic measures and contributions related to the domain often refer to the notions of semantic distance, closeness, nearness or taxonomic distance, etc. The following subsection proposes to clarify the semantics associated to the terminology which is commonly used in the literature.\n16Nevertheless, as we will see, technically speaking, most approaches defined to compute semantic similarities based on ontologies can be used on any restriction of semantic relatedness considering a type of relationship which is transitive, reflexive and antisymmetric."}, {"heading": "1.2. FROM SIMILARITY TOWARDS SEMANTIC MEASURES 11", "text": "The diversity of types of semantic measures\nWe have so far introduced the broad notion of semantic measures and have also distinguished the two central notions of semantic relatedness and semantic similarity. Extensive terminology has been used in the literature to refer to the notion of semantic measure. Thus, we here define the meaning of the terms commonly used (the list may not be exhaustive):\n\u2022 Semantic relatedness, sometimes called proximity, closeness, nearness, or attributional similarity (Turney and Pantel, 2010) ; refers to the notion introduced above.\n\u2022 Semantic similarity has also already been defined. In some cases, the term taxonomic semantic similarity is used to stress the fact that only taxonomic relationships are used to estimate the similarity.17\n\u2022 Semantic distance is generally considered as the inverse of semantic relatedness, and all semantic interactions between the compared elements are considered. These measures respect (for the most part) the mathematical properties of distances which will be introduced later. Semantic distance is also sometimes denoted as farness.\n\u2022 Semantic dissimilarity is understood as the inverse of semantic similarity.\n\u2022 Taxonomic distance also corresponds to the semantics associated to the notion of dissimilarity. However, these measures are expected to respect the properties of distances.\nFigure 1.1 presents a graph in which the various notions related to semantic measures are (informally) structured through semantic relationships. Most of the time, the notion considered to be the inverse of semantic relatedness is denoted as semantic distance, whether or not the measure respects the mathematical properties characterising a distance. Therefore, for the purpose of organising the different notions, we introduce the term semantic unrelatedness to denote the set of measures whose semantics is the inverse to the one carried by semantic relatedness measures, without necessarily respecting the properties of a distance. To our knowledge, this notion has never been used in the literature.\n17Sometimes the notions of attributional or relational similarities are used to refer to semantic similarity (Baroni and Lenci, 2010)."}, {"heading": "12 CHAPTER 1. INTRODUCTION TO SEMANTIC MEASURES", "text": ""}, {"heading": "1.2.3 From distance and similarities to semantic measures", "text": "Are semantic measures mathematical measures? What are the specific properties of a distance or a similarity measure? Do semantic similarity measures correspond to similarity measures in the way mathematicians understand them? As we have seen in Section 1.2.2, contributions related to semantic measures do not rely on formal definitions of the notion of measure or distance. Indeed, contributions related to semantic measures generally rely on the commonly admitted and intuitive expectations regarding these notions, i.e. similarity (resp. distance) must be higher (resp. lower) the more (resp. less) the two compared elements share commonness18. However, the notions of measure and distance have been rigorously defined in Mathematics through specific axioms from which particular properties derive. These notions have been expressed for well-defined objects (element domain). Several contributions rely on these axiomatic definitions and interesting results have been demonstrated according to them. This section briefly introduces the mathematical background related to the notions of distance and similarity. It will help us to rigorously define and better characterise semantic measures in mathematical terms; it is a prerequisite to clarify the fuzzy terminology commonly used in studies related to semantic measures.\nFor more information on the definition of measures, distance and similarity, the reader can refer to: (i) the seminal work of Deza and Deza (2013) \u2013 Encyclopedia of Distances, (ii) the work of Hagedoorn (2000)\u2013 A theory of similarity measures, Chapter 2, and (iii) the definitions proposed by D\u2019Amato (2007). Most of the definitions proposed in this section have been formulated based on these contributions. Therefore, for convenience, we will not systematically refer to them. In addition, contrary to most of the definitions presented in these works, here we focus on highlighting the semantics of the various definitions according to the terminology introduced in Section 1.2.2.\nDistance and similarity in Mathematics\nFor the definitions presented hereafter, based on D\u2019Amato (2007), we consider a set D which defines the elements of the domain we want to compare and a totally ordered set (V, ). We also consider the element minV as the element of V such as \u2200v \u2208 V : minV v, maxV \u2208 V such as \u2200v \u2208 V : v maxV ; and 0V \u2208 V such as minV 0V maxV .19\nDefinition Distance: a function dist : D\u00d7D \u2192 V is a distance on D if, \u2200x, y \u2208 D, the function is:\n\u2022 Non-negative, dist(x, y) 0V . \u2022 Symmetric, dist(x, y) = dist(y, x). \u2022 Reflexive dist(x, x) = 0V and \u2200y \u2208 D \u2227 y 6= x : dist(x, x) \u227a dist(x, y).\nTo be considered as a distance in a metric space, the distance must additionally respect two properties:\n\u2022 The identity of indiscernibles also known as strictness property, minimality or self-identity, that is dist(x, y) = 0V iff x = y. \u2022 The triangle inequality, when V \u2286 R, the distance between two points must be the shortest distance along any path: dist(x, y) \u2264 dist(x, z) + dist(z, y).\nDespite the fact that some formal definitions of similarity have been proposed, e.g., (Hagedoorn, 2000; Deza and Deza, 2013), contrary to the notion of distance, there is no axiomatic definition of similarity that sets the standard; the notion appears in different fields of Mathematics, e.g., figures with the same shape are denoted similar (in geometry), similar matrices are expected to have the same eigenvalues, etc. In this book, we consider the following definition.\nDefinition Similarity : a function sim : D \u00d7 D \u2192 V is a similarity on D if, for all x, y \u2208 D, the function sim is non-negative (sim(x, y) 0V ), symmetric (sim(x, y) = sim(y, x)) and reflexive, i.e., sim(x, x) = maxV and \u2200x, y \u2208 D \u2227 y 6= x : sim(x, x) sim(x, y).\n18 The works of D\u2019Amato (2007) and Blanchard et al. (2008) are among the exceptions. 19E.g. different definitions of V could be V = R, V = [0, 1], V = {very low, low, medium, high, very high}."}, {"heading": "1.2. FROM SIMILARITY TOWARDS SEMANTIC MEASURES 13", "text": "Definition Normalised function: any function f on D (e.g. similarity, distance) with values in [0, 1].\nNotice that a normalised similarity sim can be transformed into a distance dist considering multiple approaches; inversely, a normalised distance can also be converted into a similarity. Some of the approaches used for such transformations are presented in (Deza and Deza, 2013, Chapter 1).\nAs we have seen, distance and similarity measures are formally defined in mathematics as functions with specific properties. These properties are extensively used to demonstrate results and to develop proofs. However, the benefits of fulfilling some of these properties, e.g., triangle inequality for distance metric, have been subject to debate among researchers. As an example, Jain et al. (1999) stress that the mutual neighbour distance used in clustering tasks doesn\u2019t satisfy the triangle inequality but perform well in practice \u2013 to conclude by \u201cThis observation supports the viewpoint that the dissimilarity does not need to be a metric\u201d. Another example is the semantic measure proposed by Resnik for comparing concepts defined in a taxonomy20 (Resnik, 1995). This measure does not respect the identity of the indiscernibles, the similarity of a concept to itself can even be low when general concepts are evaluated. However, despite the fact that this property may seem counter-intuitive, this measure has proved to perform well in several usage contexts. This highlights the gap which often exists between (i) formal definitions of measures which are based on axiomatic definitions and rigid expectations of well-defined properties and (ii) results provided by empirical evaluations which sometimes challenge the benefits of respecting specific properties characterising measures.\nA large number of properties which are not presented in this section have been distinguished to further characterise distance or similarity functions, e.g., see (Deza and Deza, 2013). These properties are important and needed for theoretical proofs. However, as we have seen, the definition of semantic measures proposed in the literature is not framed in the mathematical axiomatic definitions of distance or similarity. In some cases, such a distortion among the terminology creates difficulties in bridging the gap between the various communities involved in the study of semantic measures and similarity/distance. As an example, in the Encyclopedia of distances, Deza and Deza (2013) do not distinguish the notions of distance and dissimilarity, which is the case in the literature related to semantic measures (refer to Section 1.2.2). In this context, the following section defines the terminology commonly adopted in the study of semantic measures w.r.t the mathematical properties already introduced.\nFlexibility of semantic measures\nNotice that we have not introduced the precise and technical mathematical definition of a measure proposed by measure theory. This can be disturbing considering that this manuscript extensively refers to the notion of semantic measure. The notion of measure we use is indeed not framed in the rigorous mathematical definition of measure. Such a definition would exclude many semantic measures defined in the literature. The notion of measure considered in this book therefore refers to the common sense of the term measure, any \u201cmeasuring instruments\u201d which can be used to \u201cassess the importance, effect, or value of (something)\u201d (Oxford Dict., 2012) \u2013 in our case, any functions answering the definitions of semantic distance/relatedness/similarity/etc. proposed in Section 1.2.2.\nVarious communities have used the concepts of similarity or distance without considering the rigorous axiomatic definitions proposed in mathematics but rather using their broad intuitive meanings21. To be in accordance with most contributions related to the field, and to facilitate the reading of this book, we will not limit ourselves to the mathematical definitions of distance and similarity.\nThe literature related to semantic measures generally refers to a semantic distance as any (nonnegative) function, designed to capture the inverse of the strength of the semantic interactions linking two elements. Such functions must respect that: the higher the strength of the semantic interactions between two elements, the lower their distance. The axiomatic definition of a distance (metric) may not be respected. A semantic distance is, most of the time, what we define as a function estimating semantic\n20The measure will be introduced gradually in Chapter 3 \u2013 for the interested reader the similarity between two concepts u, v is defined by sim(u, v) = IC(MICA(u, v)) with IC(x) the specificity of the concept x which is defined as the inverse of the logarithm of the probability of occurrence of a concept in a corpus of texts, i.e. \u2212log(p(x)) and MICA(u, v) the common ancestor of u and v which is the most specific, i.e. the common ancestor with the maximal IC.\n21 As we have seen, researchers in cognitive science have demonstrated that human expectations regarding (semantic) distance challenges the mathematical axiomatic definition of distance. Thus, the communities involved in the definition of semantic measures mainly consider a common vision of these notions without always clearly defining their mathematical properties."}, {"heading": "14 CHAPTER 1. INTRODUCTION TO SEMANTIC MEASURES", "text": "unrelatedness. However, to be in accordance with the literature, we will use the term semantic distance to refer to any function designed to capture semantic unrelatedness. We will explicitly specify that the function respects (or does not respect) the axiomatic definition of a distance (metric) when required.\nSemantic relatedness measures are functions which are associated to an inverse semantics of the one associated to semantic unrelatedness: the higher the strength of the semantic interactions between two elements, the higher the function will estimate their semantic relatedness.\nThe terminology we use (distance, relatedness, similarity) refers to the definitions presented in Section 1.2.2. To be clear, the terminology refers to the semantics of the functions, not their mathematical properties. However, we further consider that semantic measures must be characterised through mathematical properties. Table 1.1 and Table 1.2 summarise some of the properties which can be used to formally characterise any function designed in order to capture the intuitive notions of semantic distance and relatedness/similarity. These properties will be used in this book to characterise some of the measures that we will consider. They are essential to further understand the semantics associated to the measures and to distinguish semantic measures which are adapted to specific contexts and usage."}, {"heading": "1.3 Classification of semantic measures", "text": "We have seen that various mathematical properties can be used to characterise technical aspects of semantic measures. This section distinguishes other general aspects which may be interesting to classify semantic measures. They will be used to introduce the large diversity of approaches proposed in the literature. First we present some of the general aspects of semantic measures which can be relevant for their classification, and subsequently introduce two general classes of measures."}, {"heading": "1.3.1 How to classify semantic measures", "text": "The classification of semantic measures can be made according to several aspects; we propose to discuss four of them:\n1. The type of elements that the measure aims to compare.\n2. The semantic proxies used to extract the semantics required by the measure.\n3. The semantic evidence and assumptions considered during the comparison.\n4. The canonical form adopted to represent an element and how to handle it."}, {"heading": "1.3. CLASSIFICATION OF SEMANTIC MEASURES 15", "text": "Types of elements compared: words, concepts, instances, etc.\nSemantic measures can be used to compare various types of elements:\n\u2022 Units of language: words, sentences, paragraphs, documents.\n\u2022 Concepts/Classes, groups of concepts.\n\u2022 Semantically characterised instances.\nSemantic measures can therefore be classified according to the type of elements they aim to compare.\nSemantic proxies from which semantics is distilled\nSemantic measures require a source of information to compare two semantic entities. It will be used to characterise compared elements and to extract the semantics required by the measure.\nDefinition Semantic proxy : any source of information from which indication of the semantics of the compared elements, which will be used by a semantic measure, can be extracted.\nTwo broad types of semantic proxies can be distinguished:\n\u2022 Unstructured or semi-structured texts: Text corpora, controlled vocabularies, dictionaries.\n\u2022 Structured: ontologies, e.g., thesaurus, structured vocabularies, taxonomies.\nSemantic evidence and considered assumptions\nDepending on the semantic proxy used to support the comparison of elements, various types of semantic evidence can be considered. The nature of this evidence conditions the assumptions associated to the measure.\nDefinition Semantic evidence: any clue or indication based on semantic proxy analysis from which, often based on assumptions, a semantic measure will be based.\nAs an example, considering the measures which rely on text analysis, we have already mentioned that the proximity or relatedness of terms can be assessed considering that pairs of terms which co-occur frequently are more related. In this case, the co-occurrence of words is considered as semantic evidence; its interpretation is governed by the assumption that relatedness of terms is a function of their degree of co-occurrence.\nCanonical forms used to represent compared elements\nThe canonical form (representation) chosen to process a specific element can also be used to distinguish the measures defined for comparing a specific type of element. Since a canonical form corresponds to a specific reduction of the element, the degree of granularity with which the element is represented may highly impact the analysis. The selected canonical form is of major importance since it influences the semantics associated to the score produced by a measure, that is to say, how a score must/can be understood/interpreted. This particular aspect is essential when inference must be driven from scores produced by semantic measures.\nIt is therefore important to stress that a semantic measure is defined to process a given type of element which is represented through a specific canonical form."}, {"heading": "16 CHAPTER 1. INTRODUCTION TO SEMANTIC MEASURES", "text": ""}, {"heading": "1.3.2 A general classification of semantic measures", "text": "Figure 1.2 presents a partial overview of the landscape of semantic measures which can be used to compare various types of semantic entities (e.g. words, concepts, instances). It summarizes one of the classifications of semantic measures which can be proposed. As we have seen, measures can first be classified based on the elements they can compare. Based on this aspect, we distinguish two main types of measures:\n\u2022 Corpus-based measures used to compare units of language, concepts or instances from text analysis, i.e. unstructured semantic proxies. These measures are generally used to compare words or more generally units of language. However, they can also be adapted for comparing concepts or instances by considering that disambiguation techniques have been used to identify concept or instance denotations in texts.\n\u2022 Knowledge-based measures which are designed for comparing entities defined in ontologies, i.e. structured semantic proxies. Knowledge-based measures can also be used to compare units of language, e.g., sentences or texts, for instance by considering that disambiguation techniques have been used for establishing bridges between texts and ontologies.\nHybrid strategies can also be defined mixing both distributional and knowledge-based measures. Nevertheless, in the literature, measures are generally defined for comparing a specific type of elements: units of language or entities defined in an ontology. Therefore, classifying measures based on the elements they compare and the semantic proxy which is used in the analysis, i.e. texts or ontologies (knowledge representation system), helps to distinguish the general types of measures which have been proposed.\nThese measures are based on different semantic evidence and assumptions which are used to capture the semantics of compared elements, e.g. the distributional hypothesis, intentional or extensional evidence expressed into ontologies. Based on these evidence and assumptions, a model is defined for comparing two elements \u2013 such a model is generally denoted a semantic measure. Various specific types of approaches have been proposed for distributional and knowledge-based measures, Figure 1.2 structures several broad categories. Depending on the strategy which is used for defining the measure and the evidence and assumptions which are considered, the semantics of the measure, i.e. the meaning which can be associated to the scores it produces, may vary.\nThis chapter has introduced the notion of semantic measures. We have presented their practical usages in different application contexts, general definitions associated to the notion have been proposed, and different semantics which can be associated to them have been distinguished. This latter point helped us to better capture the meaning of semantic measures (results). To this end, we define the terminology classically found in the literature, e.g., semantic similarity/proximity/relatedness/distance, and we proposed an organisation of the notions commonly used, e.g. semantic similarity is a component of semantic relatedness. In a second step, to better understand the characteristics of semantic measures, we distinguished several central aspects of measures which can be used to categorising the large diversity of measure proposals. As a result, a general classification of the variety of semantic measures defined in the literature has been presented. Such a classification highlights the similarities and differences of the numerous measures and approaches which have been proposed in the literature. It can therefore be used to better understand the large diversity of measures and to characterise areas of research which have not been explored for designing measures. Importantly, this overview of semantic measures and the proposed classification also stresses the breadth of this field of study and the difficulty to define the notions on which are based semantic measures, e.g., semantic relatedness and semantic similarity.\nThe two following chapters are dedicated to an in-depth introduction to both corpus-based and knowledge-based semantic measures."}, {"heading": "1.3. CLASSIFICATION OF SEMANTIC MEASURES 17", "text": "18 CHAPTER 1. INTRODUCTION TO SEMANTIC MEASURES\nChapter 2\nCorpus-based semantic measures"}, {"heading": "2.1 From text analysis to semantic measures", "text": "Corpus-based semantic measures enable the comparison of units of language from the analysis of unstructured or semi-structured texts. They are more generally used to compare words, sentences or texts based on NLP techniques which most often only rely on statistical analysis of word usage in texts, e.g. based on the analysis of word (co-)occurrences and the linguistic contexts in which they occur. As we will see in this chapter, corpus-based measures cannot most of the time be reduced to single mathematical formulae. They rather refer to complex pipelines of treatments which are used (i) to extract the semantics of compared units of language, to further (ii) compare these units by analysing their semantics. To this end, corpus-based semantic measures take advantage of a large variety of NLP and information retrieval algorithms \u2013 which makes corpus-based semantic measures a broad field of study at a crossroad between several domains, in particular computational linguistics and information retrieval.\nCorpus-based measures are often denoted distributional measures in the literature (Mohammad and Hirst, 2012a). This is to stress that most measures are explicitly or implicitly based on the distributional hypothesis \u2013 a central hypothesis of distributional semantics which states that words occurring in similar contexts convey similar meaning (Harris, 1981). Nevertheless, like Mihalcea et al. (2006) and other authors, we here adopt the more general denotation of corpus-based semantic measures. This is to ease the introduction of the variety of measures which are based on corpus or natural language analysis, including those for which the distributional hypothesis is not considered to be the root of the approach. That is the case for measures which are based on the analysis of results provided by information retrieval systems. To stress this point, different classifications of semantic measures based on text analysis have been proposed in the literature, e.g. (Mihalcea et al., 2006; Panchenko, 2013). The one which has been adopted in this chapter is among the most used. In addition, even if this reflection is out of the scope of this book and will therefore not be discussed hereafter, evidence indicate that all corpus-based semantic measures are somehow implicitly or explicitly defined into the framework of distributional semantics (which will be introduced in this chapter).\nMuch of the literature related to corpus-based measures focuses on the comparison of a pair of words; extensive surveys have been proposed by Weeds (2003); Curran (2004); Sahlgren (2008); Dinu (2011); Mohammad and Hirst (2012a); Panchenko (2013). Several contributions have also been proposed to compare larger units of language such as pairs of sentences or texts, e.g. (Corley and Mihalcea, 2005; Yu et al., 2006; Hughes and Ramage, 2007; Ramage et al., 2009; Buscaldi et al., 2013). However, most of these latter measures are extensions of measures which have been defined for comparing words, or rely on approaches which are also used to compare words, e.g. topic models such as Latent Semantic Analysis (Lintean et al., 2010) or Latent Dirichlet Allocation (Blei et al., 2003). Therefore, for the sake of clarity and due to space constraint, this chapter mainly introduces semantic measures which have been defined for comparing words. We will not present measures which can be used to compare texts or sentences1.\nGenerally speaking, corpus-based semantic measures are based on a strategy which will be used to capture the meaning of a word \u2013 this meaning is often regarded as a function of its usage in a semantic\n1A large literature is dedicated to the subject. As an introduction to the field the reader may refer to the broad overview of measures provided by Achananuparp et al. (2008). We also encourage the reader to take an interest to the central notion of compositionality which is essential in order to adapt models commonly used for assessing the similarity of words in order to process units of language larger than words (Kamp et al., 2014).\n19"}, {"heading": "20 CHAPTER 2. CORPUS-BASED SEMANTIC MEASURES", "text": "space built from a corpus of texts. Depending on the strategy which is adopted to (i) characterise the meaning of a word, and to (ii) represent the semantic space in which this meaning is defined, a specific canonical form will be selected to represent a word. This canonical form corresponds to a data structure which is expected to encompass evidence of the meaning of the word. It can be regarded as the second proxy layer from which the meaning of a word will be processed \u2013 the first one being the natural language under study. This representation will be of major importance for defining corpus-based semantic measures. It enables the meaning of words to be processed by algorithms and therefore enables words to be compared based on the comparison of their respective canonical forms.\nDespite the fact that corpus-based semantic measures are most often complex processes composed of multiple algorithms, four main components characterise the definition of a strategy for assessing the semantic similarity of words2:\n1. A premise on what the meaning of a word is.\n2. A set of assumptions which defines the semantic evidence convey by natural language from which the meaning of a word can be captured.\n3. A representation of a word such as (most of) its meaning \u2013 as defined in 1 and captured by the semantic evidence defined in 2 \u2013 can be processed by algorithms. In some cases, this is a two-step process as a representation of the whole semantic space will first be defined to next extract a specific canonical form of a word.\n4. An algorithm or mathematical function specifically designed for comparing two word representations.\nAll corpus-based semantic measures defined in the literature differ regarding the strategies which have been adopted to implement each of these components \u2013 mainly components 2, 3 and 4.\nThe premise which defines the meaning of a word (Component 1) directly impacts the choice of (i) the semantic evidence which will be used to define the representation of a word and (ii) the approach which will be used to compare these representations. Nevertheless, this aspect is not always discussed when measures are defined. As we will see, the meaning of a word is generally considered to be a function of its usage \u2013 according to the distributional hypothesis.\nNote also that the comparison of two words representations (Component 4) has, technically speaking, no direct relationship with semantic analysis. Indeed, this step mainly refers to the definition or the use of mathematical functions or algorithms for comparing data structures. In some cases, this step corresponds to the definition of ad hoc functions used to compare complex representations of words. However, in most cases, words are represented using well-known mathematical objects (e.g. sets, vectors, probability distributions, nodes in graphs). In these cases, state-of-the-art measures defined for comparing these mathematical objects are used, regardless of the semantics carried by these objects.\nFigure 2.1 presents a general and conceptual overview of the various steps which can be used for defining corpus-based measures. Most of the approaches proposed in the literature can be break up into some of these steps. Each of these steps will be presented in this chapter and we will show how they can be combined in order to assess the semantic relatedness of words. Below, the five steps presented in Figure 2.1 are introduced:\n1. The semantic proxy which is used is a corpus of unstructured or semi-structured texts, for instance retrieved from the Web. This corpus can be preprocessed depending on the strategy which is used for defining the measure. Such a preprocessing can involve, among others: stemming/lemmatization, Part-Of-Speech (POS) tagging, and removal of specific words, e.g. stop words \u2013 in some cases the study focuses on specific POS such as nouns or verbs.\n2. At this stage, the vocabulary is distinguished, almost always implicitly. It contains all the words for which the measure will be able to compute a score of relatedness. Note that the notion of words may refers to a set of lemma or to complex objects such as a set of pairs \u3008lemma, POS\u3009 for instance.\n2Note that these components are found in all the approaches which can be used for comparing units of language (e.g., sentences, texts)."}, {"heading": "2.1. FROM TEXT ANALYSIS TO SEMANTIC MEASURES 21", "text": "3. Based on the (preprocessed) corpus and the vocabulary considered, a model is next built. It will be used to characterise all the words of the vocabulary under study. This model is generally a matrix which represents each word of the vocabulary using a set of contexts. As we will see, most of the diversity of measures can be explained by the variety of strategies which have been proposed to build such a model. The construction of this model is based on a set of assumptions regarding (i) the meaning of words and (ii) the semantic evidence which can be used for evaluating this meaning. As an example, the model can be a word to word co-occurrence matrix considering that two words co-occur if they appear in a word window of a specified size. In some cases syntactic patterns are used to study word co-occurrences. In other cases, using an information retrieval system, the model can also be a word-document matrix which specifies the relevant documents w.r.t a given word.\nAt this stage, a raw model is built. Some transformations can be applied on it; we distinguish the phase of refinement and the phase of reduction:\n\u2022 The refinement refers to the treatments which are used to improve the model by incorporating additional information extracted from the corpus under study. As an example, some of the approaches incorporate corpora statistics to take into account the informativeness of specific"}, {"heading": "22 CHAPTER 2. CORPUS-BASED SEMANTIC MEASURES", "text": "words, e.g. by taking into account term frequency.\n\u2022 The reduction refers to the use of specific techniques for reducing the potentially high dimensionality of the matrix. Note that this matrix is generally sparse as most of the words never co-occur in the same contexts. This step generally involves specific matrix processing and reduction techniques such as Singular Value Decomposition (SVD) (Berry et al., 1995; Golub and Van Loan, 2012) \u2013 these approaches will be briefly introduced later.\n4. The transformation step aims at obtaining the general model, here denoted semantic model, which will be analysed for comparing the words. In some cases the semantic model, originally represented as a matrix, will be transformed into a graph representation. Therefore, interestingly, a bridge can be established between corpus-based and knowledge-based measures which will be discussed in detail in Chapter 3. Indeed, some of the strategies represent the semantic space using well-known knowledge representation models. As an example, it has been proposed to build semantic networks or referential networks from dictionaries and thesauruses to further compare words according to the strength of their interconnections in the semantic network, e.g. (Nitta, 1988; Kozima and Furugori, 1993; Niwa and Nitta, 1994; Kozima and Ito, 1997; Blondel, 2002; Ho and Ce\u0301drick, 2004; Iosif and Potamianos, 2012). This kind of approaches will be discussed in Chapter 3 which is dedicated to knowledge-based measures.\n5. Finally, two words can be compared analysing the semantic model which has been defined. Once again a large variety of measures can be used depending on the representation of a word the model enables. However, despite the diversity of measures proposed in the literature, two general approaches for defining corpus-based measures can be distinguished:\n\u2022 Distributional measures: semantic measures based on distributional semantic models (Baroni and Lenci, 2010) and the distributional hypothesis (Harris, 1981).\n\u2022 Other types of measures: measures based on approaches which do not explicitly rely on the distributional hypothesis, e.g. approaches based on information retrieval systems.\nThese two approaches are presented in this chapter. However, we will mainly focus on distributional measures as they are both the most studied and the most used in the literature. Let us remind that the measures which rely on a graph-based representation of the semantic model will be presented in the chapter dedicated to knowledge-based measures (Chapter 3).\nThe aim of this chapter is not to introduce the extensive list of corpus-based measures which have been proposed in the literature. It is rather to present the central notions on which corpus-based measures rely. Therefore, a large portion of this chapter is dedicated to the introduction of the key notions of context and semantic model. Several examples of context and semantic model definitions will be illustrated. We next present several examples of measures which can be used to take advantage of these context and semantic model definitions for designing semantic measures.\nThe reader must indeed understand that the central aspect of corpus-based semantic measures relies in the definition of the semantic model from which will be extracted the processable representation of a word. Indeed, next, the definition or use of a measure for comparing two word representations is most often only a matter of a technical discussion on mathematical formulae dedicated to the comparison of specific data structures - e.g., vectors, sets.\nThe remainder of this chapter is organised as follow. After a brief introduction of what it is generally understood by word meaning, Section 2.2 presents several types of semantic evidence which can be extracted from natural language for assessing the similarity of words or more generally for assessing the similarity of two units of language. In this section, important concepts related to corpus-based measures will be introduced, e.g. distributional semantics, the distributional hypothesis, the notion of context. Section 2.3 presents several proposals of distributional measures. Section 2.4 briefly introduces the other types of measures which have been proposed in the literature. Section 2.5 discusses the advantage and limits of corpus-based measures. Finally, Section 2.6 concludes the chapter."}, {"heading": "2.2. SEMANTIC EVIDENCE OF WORD SIMILARITY IN NATURAL LANGUAGE 23", "text": ""}, {"heading": "2.2 Semantic evidence of word similarity in natural language", "text": "In this section we first briefly discuss the notion of word meaning to further introduce semantic evidence which is commonly used to compare words from natural language analysis. In particular, we introduce the two structural relationships which can be studied between words, namely paradigmatic and syntagmatic relationships."}, {"heading": "2.2.1 The meaning of words", "text": "The notions of meaning and semantics have been extensively discussed by numerous communities, e.g. (Osgood, 1952; Aitchison, 2012), and this survey does not aim to propose an in-depth analysis of the different theories proposed so far. Nevertheless, as we saw in Section 2.1, the definition of word meaning directly influences the way semantic measures are defined. Indeed, an accurate measurement technique can only be defined if a clear and non-ambiguous definition of what we want to measure has been defined. However, the notion of semantic similarity or semantic relatedness of words \u2013 what we want to measure using corpus-based semantic measures \u2013 is generally not defined in the contributions related to semantic measures. The authors generally refer to the intuitive notion of word similarity/relatedness w.r.t their meaning by giving examples of the behaviour expected by measures, e.g. the measure must enable to distinguish that the two words (cup, tea) are more semantically related than the two words (cup, wine)3. In this context, considering that measures can be evaluated using benchmarks composed of expected results of similarity, finely defining the notion of word meaning may seem unnecessary. This explains that some authors have questioned the relevance to finely characterise the notion of word meaning for assessing the similarity/relatedness of words, e.g. (Karlgren and Sahlgren, 2001; Sahlgren, 2006). The necessity to define what we consider by word meaning for designing word similarity measure is still an open debate.\nAn important point to understand is that most contributions related to corpus-based semantic measures consider semantic relatedness as linguistic relatedness. The meaning of a word is assumed to be directly or indirectly explainable by the sole study of language, independently from both (i) the knowledge of language users and (ii) the environment. Therefore, the notion of linguistic relatedness, commonly denoted semantic relatedness, fall within the domain of Semantics, i.e. the study of language in isolation, and does not refer to the domain of Pragmatics which also incorporates the analysis of the context in which the language is used (Cruse, 2011). As discussed in Sahlgren (2008), this does not mean that linguists do not consider that extralinguistic factors play a role in defining the meaning of language, and therefore that linguistics can for instance be used to compare the meaning of the signified or the referent of a signifier4 \u2013 it only means that it is generally considered that \u201dFor a large class of cases \u2013 though not for all \u2013 in which we employ the word \u201dmeaning\u201d it can be defined thus: the meaning of a word is its use in the language\u201d, i.e. \u201dmeaning is use\u201d (Wittgenstein, 2010), i.e. \u201dNot the meanings that are in our heads, and not the meanings that are out there in the world, but the meanings that are in the text\u201d (Sahlgren, 2008).\nFocusing on semantic measures, it rather means that corpus-based measures compare words w.r.t their linguistic meaning, i.e. the meaning of words which can be captured by analysing language in isolation, without regard on the amount of meaning of a word which is explicitly or implicitly conveyed by language. In corpus-based semantic measures words are therefore solely compared w.r.t their usage in texts. Interestingly, the usage of words in texts is assumed to reflect a commonly accepted meaning of words. This central notion relates to some of the early work of Firth: \u201dThe complete meaning of a word is always contextual\u201d (Firth, 1935). It will be further discussed through the introduction of the distributional hypothesis.\nTherefore, in the majority of cases, corpus-based measures are assumed to evaluate the distributional relatedness of words: words are considered to be related if they occur in the same context"}, {"heading": "2.2.2 Structural relationships: Paradigmatic and Syntagmatic", "text": "An interesting point to note is that a structural vision of language is adopted in most contributions related to corpus-based semantic measures. Structuralism have been developed based on the work of\n3What we did in this book for introducing the notion of semantic similarity and semantic measures. 4Signifier refers to the word, sequence of graphemes (letters), phonetic. The signified refers to the mental representation of a concrete or abstract concept the signifier refer to, and the referent is the concrete object in the real world (Chandler, 2007)."}, {"heading": "24 CHAPTER 2. CORPUS-BASED SEMANTIC MEASURES", "text": "Saussure (1857-1913)5. Here the natural language is regarded as a sequence of symbols (such as words) with no a priori semantics. These symbols are considered to be structured by two types of relationships:\n\u2022 Paradigmatic relationships. All symbols (e.g. words) are regarded as paradigms which are members of a specific class or semantic group. Paradigms are considered to establish a paradigmatic relationship \u2013 or associative relation \u2013 if they can be substituted, at least without modifying the grammatical coherence of the sentence. Therefore, a paradigm is generally considered as a set of symbols which refer to a specific class, e.g. verbs or nouns are examples of grammatical paradigms. Therefore, the paradigmatic vision considers a sentence as a sequence of disjunction of paradigms p0\u2228p1\u2228p2\u2228p3 . . .\u2228pi with pi a specific paradigm. As an example, in Table 2.1 the word cat could be replaced by the word dog without implication on the grammatical coherence of the sentence. Note that the notion of class or semantic group which can link the various paradigms is broadly defined in the literature (Booij et al., 2000). It may refer to the lexical category of the syntagm or even to its meaning when classes refer to synonyms, hypo/hypernyms, antonyms.6\n\u2022 Syntagmatic relationships correspond to the chain of associations of the symbols which compose a sentence, or a larger lexical unit. The selection of specific paradigms and their combination generates a syntagm which traduces the sequence of lexical units related by syntagmatic relationships. This contributes to define the meaning of a sentence. A syntagm is governed by the grammar of the language in use, i.e. the rules which define the coherency of expressing a specific chain of symbols. According the syntagmatic vision, a sentence is regarded as a sequence of conjunction of paradigms of the form p0 \u2227 p1 \u2227 p2 \u2227 p3 . . . \u2227 pi with pi a specific paradigm, e.g. the two sentences presented in Table 2.1 correspond to specific chains of paradigms.\nParadigmatic analysis refers to the study of specific patterns in texts, in contrast to syntagmatic analysis which will be based on the analysis of a surface representation of the language in which words cooccurrence is a central component. Kozima and Furugori (1993), among others, mention the importance of these two types of structural relationships for discussing the relatedness of words. However, due to the different nature of these relationships, and the different information they convey, some authors have proposed to distinguish the notions of paradigmatic and syntagmatic relatedness (Sahlgren, 2008):\n\u2022 Paradigmatic relatedness refers to the notion of substitutability w.r.t the impact of substituting a word by another, e.g. on the grammatical coherence of a sentence. Indeed, more finely, paradigmatic relatedness of two words can be seen as a function of the impact of substituting two words on the meaning conveyed by a sentence. Paradigmatic relationships between words must therefore be evaluated by means of indirect co-occurrences. As an example, the two synonyms father and dad will not often co-occur, but will rather tend to occur with the same words \u2013 this can be captured by analysing second-order co-occurrences or more generally indirect co-occurrences of words. Paradigmatic relatedness is a broad notion. Indeed, the association of specific paradigms in the same semantic group may be justified by a variety of semantic relationships which can be established between paradigms, e.g. hypo/hypernymy, synonymy, antonymy.\n\u2022 Syntagmatic relatedness is mainly captured inside a specific text region by means of words collocation and direct co-occurrence (Kozima and Furugori, 1993), i.e. first-order co-occurrences.\nAs we will see, structuralism and more particularly paradigmatic and syntagmatic relationships are central for the definition of corpus-based semantic measures."}, {"heading": "2.2.3 The notion of context", "text": "The notion of context is central in several natural language analysis. It is of major importance for capturing the meaning of a word through the analysis of syntagmatic and paradigmatic relationships.\n5For more information, the reader may refer to the work of Culler (1986); Adedimeji (2007); De Saussure (1989). 6Interestingly the association of specific paradigms into a specific class may be motivated by the notion of semantic\nrelatedness (Booij et al., 2000)."}, {"heading": "2.2. SEMANTIC EVIDENCE OF WORD SIMILARITY IN NATURAL LANGUAGE 25", "text": "Indeed, the meaning of a word is generally considered to be understandable only w.r.t a context of use, i.e. according to its usage which is defined through the structural relationships the word establishes. Thus, the notion of context is central to perform structural processing of natural language by analysing paradigmatic and syntagmatic relationships. As an example, first-order co-occurrences of words will be evaluated by studying the syntagmatic relationships between words.\nSeveral approaches have been proposed for defining the context of a word. They differ in their linguistic sophistication, algorithmic complexity, reliability, and information they consider (Curran, 2004). A basic approach is to consider the context of a word as the document of the corpus in which the word occurs. Such a definition of context refers to the semantic model on which is based Vector Space Model (VSM) \u2013 a widely known model which have been proposed in Information Retrieval to characterising documents w.r.t. the vocabulary which constitutes the corpus (Salton and McGill, 1983; Turney and Pantel, 2010). In VSM a document is considered as a topical unit. It is represented as a vector which highlights the words it contains. In this aim, the corpus is used to derive a semantic model which corresponds to a document-word matrix. A basic example of such a matrix is presented in Table 2.2 \u2013 wi refers to the word i and dj to the document j of the corpus.\nIf the word wi occurs in the document dj the cell (wi, dj) will be filled by the value 1. Based on this model, when a query must be evaluated in order to find the more relevant documents, this is the vector representation of the query which will be evaluated. The information retrieval system will be based on a similarity function which will assess the similarity between the vector-based representation of the query and the vector representation of each document (i.e. the columns of the matrix) \u2013 vector comparison techniques will be introduced in Section 2.3, just consider for now that the similarity of two vectors can easily be computed using specific mathematical formulae.\nTherefore, by considering the transpose of the document-word matrix used in VSM, we can consider that each word is also represented according to a vector representation \u2013 the rows of the matrix in Table 2.2, e.g. w0 is represented by the vector [1, 1, 0, 0]. This vector representation of a word highlights the documents in which the word occurs. Thus, considering that vector similarity can be assessed using specific mathematical functions, the semantic relatedness of two words can simply be defined as a function of the similarity of their vector-based representations.\nMore generally, as stressed by Sahlgren (2006) and other authors, we can consider that VSM relies on a semantic model which is a specific expression of a more general approach. Such a general approach does not constrain words to be characterised by documents but enables to build semantic models in which words are analysed w.r.t contexts, e.g. paragraph, sentence, word window \u2013 in the case of VSM the semantic model refers to a document-word matrix, the context selected is therefore a document7.\nThus, more generally, a semantic model can be defined as a matrix in which each row i is a vector representation of the word wi, and each dimension of the vector refers to a specific context cn, i.e. the row i provides a vector-based representation of the corresponding word wi with ~wi = (c1, c2, . . . , cn). The notion of context is therefore essential for the definition of semantic measures. It is a core element of the semantic model from which a word will be characterised and represented to further be compared.\nIn this section we introduce the contexts which can be defined for studying word co-occurrences and to build semantic models. We will next discuss how these semantic models can be used for assessing the relatedness of words. Several alternative approaches have been proposed to define processable definitions of context; this section will introduce the two broad types of contexts which can be analysed but will not cover in detail the large literature dedicated to their tuning and to the numerous variants which have been proposed and evaluated. For more information the reader may refer to (Weeds, 2003; Curran, 2004; Sahlgren, 2006) and to the specific contributions which will be introduced hereafter. The notion of context is generally considered according to the type of structural relationships which is studied. Syntagmatic and paradigmatic contexts are therefore commonly distinguished; both types of contexts\n7In some contributions VSM also refer to other models such as distributional models - and may refer to any model in which dimensions of vectors/matrices/tensors are derived from event frequencies (Turney and Pantel, 2010).\n26 CHAPTER 2. CORPUS-BASED SEMANTIC MEASURES\nare introduced.\nSyntagmatic contexts\nSyntagmatic contexts refer to the study of co-occurrences in sequential ordering of words. Using this approach a specific window size of words will generally be used to define a context, e.g. using a five noun window the word bananas will be analysed by considering contexts such as \u201d. . . [Monkeys love fruits such as bananas, they are a great healthy food source] for them. . . \u201d . Considering multiple-words windows enables to not only focus on collocation of words but also to capture words which co-occur considering larger text regions and several words between them. A variety of alternative linguistic constructs can be used to define a syntagmatic context: a sentence, a paragraph, an n-size word window or even a window composed of several characters to mention a few. Different techniques can be used to process a context depending on its definition and on its the tuning:\n\u2022 Contexts which correspond to relatively large text regions such as documents, paragraphs or sentences will generally be analysed by counting the occurrences of each word in each context. This can be used to build a word-context matrix, e.g. a word-document matrix. Such a semantic model can also be used to compute a word co-occurrence matrix if required, e.g., by considering that two words which occur in the same context co-occur.\n\u2022 Contexts which are defined considering shorter text regions, e.g. composed of a window of few words, are generally not used to build word-context matrices. In this case the aim is generally to scan the documents by sliding the predefined window using a specific step, e.g. one word. At each step, the window will be processed by considering a focal word which is generally located at the center of the window, e.g. the word banana in the example presented above. Considering this focal word, the co-occurrences between the focal word and the other words composing the window are analysed. Let us note that, intuitively, the size of the window which is considered will define the sparseness of the co-occurrence matrix since the more a window is narrow the less two words will tend to co-occur.\nA large variety of approaches and configurations can be adopted to define syntagmatic contexts. Concrete and simple examples of syntagmatic contexts and associated processing are provided in Appendix A. More refined models have also been proposed in the literature. As an example, some authors have proposed to consider directional models based on oriented windows. During the co-occurrence evaluation, these models also take into account the location (left or right) of the words which co-occur with the focal word under study. It has also been proposed to weight co-occurrences according to the distance of the words inside a window. In some cases, the focal word is not located at the center of the window and an asymmetric window is used to evaluate word co-occurrences.\nGenerally, window-based context extractors and more generally strategies based on syntagmatic context analysis benefit of low algorithmic complexity. They are therefore commonly considered as a solution of choice to process large corpora (Curran, 2004). They generally rely on several user defined parameters but have the advantage to be language independent \u2013 except specific pre-processing and particular configurations considering oriented windows.\nAdopting another approach, syntagmatic relationships between words can also be studied defining specific lexical patterns. As an example, for studying co-occurrences between two nouns, particular types of lexical relationships can be analysed, e.g. considering two words w1 and w2, we can evaluate their co-occurrences by analysing the following patterns:\n\u2022 Hyponymy, Hyperonymy: \u3008w1,is a, w2\u3009, \u3008w1,such as, w2\u3009\n\u2022 Synonymy, Antonymy: \u3008w1,or,w2\u3009\n\u2022 etc.\nThis patterns can be used to define a three dimensional co-occurrence matrix with dimensions (Word1, Word2, Pattern). Such an approach can be used to define semantic model particularly adapted to the design of parametric semantic measures. Indeed, using such model semantic designer can compare words by controlling the importance which is given to each lexical pattern and therefore finely control the semantics of the scores produced by the measure."}, {"heading": "2.2. SEMANTIC EVIDENCE OF WORD SIMILARITY IN NATURAL LANGUAGE 27", "text": "Additional references: Examples of use of syntagmatic contexts in the definition of semantic measures: Schu\u0308tze and Pedersen (1997); Yoshida et al. (2003).\nParadigmatic contexts\nParadigmatic contexts refer to indirect co-occurrences, that is to say situations in which two words occur with the same words but not together. This is often the case for words which establish paradigmatic relationships such as synonymy, hyperonymy, co-hyponymy, troponymy, antonymy or meronymy. Generally, paradigmatic relationships are characterised by analysing words which are surrounded by the same words. Therefore, such contexts are generally defined in terms of grammatical dependency between words. Otherwise stated, word occurrences w.r.t paradigmatic contexts can be used to assess the distributional similarity of words in terms of lexical substituability (Weeds, 2003)8.\nMost of the paradigmatic patterns are of the form \u3008w, t,x\u3009 or \u3008x, t, w\u3009, with t the dependency under study, x a word which is part of the pattern and w the word the pattern is used to characterise. As an example, the pattern \u3008w, SUBJ, GROW\u3009 can be defined in order to study words which are subjects of the verb to grow. Using such a pattern it is therefore possible to distinguish that the words plant and tree frequently occur with such a pattern, e.g. in the sentence \u201dSoil provides a base which the roots hold on to as a plant grows bigger\u201d the word plant occurs with this pattern; examples of sentences in which the pattern \u201dtree grows\u201d occurs are also numerous. Conversely, the word botany will never or significantly less frequently occurs with this specific pattern. This pattern which refers to a specific paradigmatic context can therefore be used to characterise that the words (plant,tree) together are probably more semantically related than the word botany and tree for instance. Paradigmatic contexts are also denoted pair-pattern by Turney and Pantel (2010), and refer to the notion of extended distributional hypothesis proposed by Lin and Pantel (2001).\nIn order to analyse words using paradigmatic contexts, a specific size of window and a direction is generally considered. In more advanced approaches specific patterns will be used to characterise slight variation in the contexts, e.g. lexical-syntactic patterns. The reader can refer to the work of Curran (2004) for examples of use of lexical-syntactic patterns. It shows how to characterise words based on complex context extractors, e.g. using Cass or Sextant parsers to mention a few. Panchenko (2013)9 also presents several references related to the definition of pattern-based approaches and to the use of paradigmatic contexts. He also introduces an approach which can be used to consider multi-word expressions10 in the definition of paradigmatic contexts.\nAdditional references: Examples of use of paradigmatic contexts in the definition of semantic measures: Hirschman et al. (1975); Hindle (1990); Hatzivassiloglou and McKeown (1993); Grefenstette (1994); Takenobu et al. (1995); Lin (1998b,a); Dagan et al. (1999); Lee (2001); Weeds (2003); Van Der Plas and Bouma (2004); Heylen et al. (2008); Panchenko (2013).\nAccording to Mohammad and Hirst (2012b), Lin (1998b) highlights that, in the context of paradigmatic context analysis, using more patterns tend to improve the results of semantic measures. In addition, interestingly, McCarthy et al. (2007) showed that syntagmatic contexts and more particularly simple sliding window approaches can be used to obtained results almost as good as those obtained using syntactic patterns. However, as we saw in this section, both syntagmatic and paradigmatic contexts are of particular importance for analysing relationships between words. They will both be used for defining semantic models on which will be based semantic measures. Indeed, as we will see in the next section, syntagmatic and paradigmatic relationships between words are the cornerstones of distributional semantics, a branch of study which have been extremely prolific on the definition of corpus-based semantic measures."}, {"heading": "2.2.4 Distributional semantics", "text": "Distributional semantics is a branch of study which explores how statistical analysis of large corpora, and in particular word distributions and statistical regularities w.r.t linguistic contexts, can be used to\n8As stressed in Weeds\u2019 thesis, several authors only consider paradigmatic contexts to estimate semantic similarity. This is because the notion of semantic similarity is sometimes only evaluated w.r.t synonymy, i.e. what is the impact of substituting a word by another on the meaning of a specific sentence.\n9Chapter 2. 10E.g. \u201dmachine learning\u201d."}, {"heading": "28 CHAPTER 2. CORPUS-BASED SEMANTIC MEASURES", "text": "model semantics (Lenci, 2008). Distributional semantics proposes a usage-based study of word meaning and extensively relies on one of the main tenets of computational linguistics and statistical semantics: the distributional hypothesis (Harris, 1954; Weaver, 1955; Firth, 1957; Sahlgren, 2008)11.\nThe distributional hypothesis, and by extension distributional semantics, is based on the assumption that words occurring in the same contexts tend to be semantically close (Harris, 1981). This hypothesis is of major importance for the definition of corpus-based semantic measures. It was made popular through the idea of (Firth, 1957): \u201dYou shall know a word by the company it keeps\u201d12, and is indeed based on the assumption that:\n1. The context associated to a word can be characterised by the words surrounding it, i.e. through the definition of syntagmatic and paradigmatic contexts \u2013 refers to syntagmatic and paradigmatic structural relationships and to the notion of context introduced in sections 2.2.2 and 2.2.3 respectively.\n2. Words occurring in similar contexts, e.g., often surrounded by the same words, are likely to be semantically related; it is assumed that \u201dsimilar things are being said about both of them\u201d (Mohammad and Hirst, 2012b) \u2013 otherwise stated the association of their meaning is often used to refer to a specific topic which makes that the two words are de facto semantically related.\nThe relevance of the distributional hypothesis and distributional semantics has been stressed out of linguistics, several contributions in psychology and cognitive sciences use it for studying knowledge acquisition and memory to cite a few. Indeed, the distribution hypothesis has been linked to cognitive processes related to language acquisition, processing and understanding (McDonald and Ramscar, 2001). It has for instance been shown that statistical properties of language, and more particularly statistical relationships between neighbouring speech sounds, plays an important role in word segmentation in infants, and therefore speech acquisition (Saffran et al., 1996). Word distribution analysis has also been identified as an interesting evidence to derive syntactic categories (Redington et al., 1998).\nTherefore distributional semantics became an approach of choice to model semantics of words w.r.t their usage contexts. This enthusiasm for distributional semantics relies on the statistical foundation of the approach which generally requires little expensive human supervision and therefore makes distributional semantics particularly adapted to large corpora analysis. In addition, this approach has been proved to be particularly interesting for solving NLP problems. Indeed, based on the distributional hypothesis, several distributional models have been proposed, e.g. topic models such as Latent Semantic Analysis (LSA), or Hypertext Analogue to Language (HAL) \u2013 they will be introduced later. As we will see, these distributional models are extensively and successfully used to analyse semantic relatedness of words \u2013 they have also proved to be particularly successful to perform a variety of NLP tasks and to design information retrieval systems13.\nThus, distributional semantics provides a theoretical framework for assessing the semantic similarity or relatedness of words by means of distributional analysis, i.e. by considering an implementation of the distributional hypothesis. Otherwise stated, it is often implicitly considered that distributional similarity of words is equivalent to semantic similarity. However, note that in the study of distributional semantics, some authors distinguish distributional similarity of words to their semantic similarity. This is in particular the case when specific definitions of semantic similarity and distributional similarity are considered. As an example, in (Weeds, 2003, chap 1.), the author considers that (i) the notion of semantic similarity is defined in terms of inter-substituability, i.e. regarding the impact to substitute a word by another on the meaning of a sentence, and (ii) the distributional similarity of words is defined only considering the impact of substituting two words on the grammatical coherence of the sentence. Considering this specific definition of semantic similarity, the assumption that distributional similarity equates semantic similarity cannot be true \u2013 \u201ddistributional similarity is [in this case] a weaker requirement than semantic similarity\u201d (Weeds, 2003). However, as we will see, in most cases, authors assume that distributional similarity can be considered as a valuable estimator of semantic relatedness.\nIn addition, even if highly popular and of major importance for computational linguistics, the place of the distributional hypothesis is often subject to debate in the linguistic community. Some researchers, advocates of a strong vision of the distributional hypothesis, consider that it can be used to fully characterise the meaning of language, while others, i.e. weak distributional hypothesis advocates, only see\n11The term has been introduced in (McDonald and Ramscar, 2001). 12Also implicitly discussed in (Weaver, 1955) originally written in 1949 (source: wiki of the Association for Computational Linguistics http://aclweb.org/aclwiki accessed 09/13). 13They have also been proved to be of particular interest in other related domains, e.g. for psychologists interested in semantic representation building and processing for cognitive tasks (Kamp et al., 2014)."}, {"heading": "2.3. DISTRIBUTIONAL MEASURES 29", "text": "this hypothesis as a way to study linguistic meaning (Lenci, 2008). Despite the central importance of this debate for studying methods which can be used to manipulate the meaning of units of language through distributional models, we here consider that this debate is out of the scope of this book. In addition, from a practical point of view, distributional semantics and the application of the distributional hypothesis have been proved to be successful in the definition of corpus-based semantic measures \u2013 this will be illustrated in the next section which introduces distributional measures for comparing words.\nIn some cases, authors consider the distributional hypothesis as a component of a more general framework denoted the statistical semantics hypothesis (Turney and Pantel, 2010). This general hypothesis has been proposed to defend Vector Space Models, a very popular class of models of words and texts that will be presented in this chapter. It states that meaning of texts can be studied by analysing statistical patterns of human word usage. The hypothesis is therefore related to the strong vision of the distributional hypothesis that has been aforementioned. Links with the statistical semantics hypothesis defined by Turney and Pantel (2010) will be provided in the following presentation."}, {"heading": "2.3 Distributional measures", "text": "Distributional measures are the corpus-based semantic measures which have been the more studied in the literature (Weeds, 2003; Curran, 2004; Sahlgren, 2008; Dinu, 2011; Mohammad and Hirst, 2012a; Panchenko, 2013). They rely on the distributional hypothesis introduced in Section 2.2.4 and are therefore based on the assumption that words which occur in the same contexts are semantically related. These measures rely on a distributional semantic model which corresponds to a semantic space built from the distributional analysis of corpora (Baroni and Lenci, 2010)14. This semantic model, here denoted distributional model, is used to manipulate the semantics of specific units of languages, e.g. words, documents. Based on this semantic model, specific canonical representations of words, denoted distributional profiles of words, can be built according to the contexts in which they occur15. As we will see, an important part of the large literature related to distributional measures is dedicated to the various approaches which have been proposed and tested to instantiate distributional model based on various context definitions. Thus, depending on the distributional model which is selected and depending on the definition of the distributional profile which is used to represent a word, a large diversity of distributional measures have been proposed and evaluated."}, {"heading": "2.3.1 Implementation of the distributional hypothesis", "text": "Studies of distributional measures are tightly related to spatial representations of both the semantic space which characterises a corpus and the words to compare \u2013 in the vain of the spatial models proposed in Information Retrieval, e.g. Vector Space Models (VSM) and topic models, and according to the spatial model of similarity which has been widely studied in cognitive sciences (refers to Section 1.2.1). Distributional models are generally defined to capture the meaning of words through distributional profiles of words build from context analysis. These profiles represent words into a multi-dimensional space defined by the distributional model under study. Using this strategy, words are therefore considered as specific points of a highly multi-dimensional space. The various dimensions which characterise a word generally refer to the various words of the vocabulary or to the notion of paradigmatic and syntagmatic contexts which have been introduced in Section 2.2.316\nThe various distributional measures are therefore mainly distinguished by (i) the strategy which is used to build the distributional model and (ii) the measure which is used to process the distributional profile of words extracted from the model. This section introduces the different strategies which have been proposed to build a distributional model. Next, the approaches which have been proposed to represent words based on these semantic models, and the measures which can be used to compare such word representations will be presented.\nThe construction of the distributional model mainly depends on the steps presented below, some of them have already been discussed:\n14As stressed by the authors, such semantic models based on distributional semantics have been denoted through a variety of names in the literature, e.g. vector spaces, semantic spaces, word spaces, corpus-based semantic models.\n15A distributional profile is also denoted a contextual vector in the literature. 16Considering these two types of contexts corresponds to the distributional hypothesis and the extended distributional\nhypothesis in the general statistical semantics hypothesis defined by Turney and Pantel (2010)."}, {"heading": "30 CHAPTER 2. CORPUS-BASED SEMANTIC MEASURES", "text": "\u2022 Pre-processing techniques of the corpus (optional), e.g., stop filter, part-of-speech filter. As we have seen, in some cases, this step defines the vocabulary which will be considered and therefore the pairs of words for which a semantic relatedness can be assessed.\n\u2022 Type of context used to build the distributional model. Depending if syntagmatic or paradigmatic contexts are used, the context which is used to characterise a word may be a document, a paragraph, a sentence, a potentially oriented word windows, a number of letters, etc. The various contexts which can be used to characterise a word by analysing syntagmatic and paradigmatic relationships of words have been introduced in Section 2.2.3.\n\u2022 Frequency weighting (optional). The function used to transform the raw counts associated to each context in order to incorporate frequency and additional knowledge relative to the informativeness of contexts \u2013 this step is used to reduce the impact of frequent words or more generally contexts. A large number of approaches have been proposed in the literature. The most popular approach to weight the importance of words in texts is TF-IDF (Salton and McGill, 1983):\ntfidfi,d = tfi,d \u00b7 idfi (2.1)\nwith tfi,d the frequency of the term ti in a document d (more exactly the number of occurrences of ti in d) and idfi the inverse document frequency of ti is defined by:\nidfi = log |D| |Dti |\n(2.2)\nwith |D| the set of documents of the corpus and Dti \u2286 D = {dj \u2208 D | ti \u2208 dj} the set of documents in which the term ti occurs. The rationale is to consider a word important for a document if it (i) frequently occurs in it (high tf) and (ii) is rarely found in the documents of the corpus (high idf). Numerous alternative expressions modelling this intuitive idea have been proposed.\nAssociation measures such as Pointwise Mutual Information (PMI) can also be used to refine raw co-occurrences17. More complex weighting schemes commonly used in information retrieval can also be adopted, e.g. Lnu.tc (Bellot et al., 2014).\n\u2022 Dimension reduction technique (optional) used to reduce the distributional model represented as a matrix, generally a word-context matrix. This process is used to reduce the sparseness of the matrix, it can be done by removing the most frequent contexts, i.e. low entropy columns. Matrix factorisation techniques can also be used to reduce the number of dimensions (and therefore the initial amount of information), e.g. using Singular Value Decomposition (SVD) (Berry et al., 1995; Golub and Van Loan, 2012) \u2013 alternative approaches for matrix factorization can also be applied, e.g. Principal Component Analysis, Independent Component Analysis to cite a few (Turney and Pantel, 2010). In some cases such treatments have the interesting properties of removing noise by finding the most important axes of variation. By forcing correspondences between words and context in the reduction process this also enables the discovering of latent dimensions. As we will discuss in Section 2.3.3, reduction techniques are also used to highlight high order co-occurrences, i.e. indirect co-occurrences between words. Appendix B introduces the intuitions, interesting properties and limits of SVD.\nA large number of distributional models have been proposed and studied in the literature, some of them will be introduced in this chapter (e.g. Latent Semantic Analysis, Explicit Semantic Analysis, Hyperspace Analogue to Language). We invite interested readers to refer to the original contribution for details, and to start by studying contributions related to vector space model, e.g. we recommend the detailed survey provided by Turney and Pantel (2010) as a general introduction to distributional models. Reisinger and Mooney (2010) also propose how to define a VSM that enables context-dependent vector representations of words that tries to solve the problem of lexical ambiguity of words. We also encourage the reader to study the contributions related to the definition of general frameworks dedicated to distributional models unification (Baroni and Lenci, 2010). Finally, since this book focuses on semantic measures, and cannot present the whole literature related to models of units of language, this chapter will only introduce some of the models that have been proposed so far. Other (recent and more complex) models that are of interest for semantic measure design are also briefly presented in Appendix C. We discuss in particular, how language models can be used to derive representations of words and we\n17This approach will be introduced in Equation 2.7 page 34."}, {"heading": "2.3. DISTRIBUTIONAL MEASURES 31", "text": "introduce the reader to compositionality, i.e. how to combine models to build representations of complex units of language such as sentences. We advise the reader to consult this appendix only when traditional distributional models presented herein are fully understood.\nDistributional measures differ regarding the type of distributional models they use. They also differ considering the approach used to assess the similarity/distance of words that are characterised w.r.t the distributional model \u2013 recall that words are represented by distributional profiles build from the analysis of distributional models. In some cases words will be considered as vectors or (fuzzy) sets to cite a few. In other cases, the matrix will be used to extract statistics on which will be based the measures. Several approaches will be presented in the next section \u2013 according to the literature, most of them are particular instantiations of the spatial model of similarity through distributional semantics.\nHowever, an important aspect to understand is that distributional models, e.g. word co-occurrence matrices, are not necessarily tight to the geometrical model. Distributional semantics and implementations of the distributional hypothesis must therefore not only be regarded as a means to obtain a geometrical representation of words through vector representations \u2013 even if some authors do not distinguish distributional semantics from the geometrical representation of words which can be made from distributional models (Kamp et al., 2014). Indeed, as we will see, first of all, distributional models contain statistics which are valuable in the aim of assessing the similarity or relatedness of words. However, as we will see, these measures can be defined independently from the geometrical/spatial model commonly considered in the design of distributional measures and can for instance exclusively rely on information theoretical notions."}, {"heading": "2.3.2 From distributional model to word similarity", "text": "We have introduced how, by implementing the distributional hypothesis, distributional models can be used to characterise word by analysing their usage contexts. Based on these models, several distributional measures have been proposed. They differ regarding the conceptual approach on which they are based and on the type of distributional models they have been designed for. Indeed, as we have seen, distributional models can be of various forms, e.g. word-context matrix, word-word matrix or even sometimes three dimensional word-word-context matrices18. This section briefly introduces three main types of approaches which have been proposed to assess word similarity from distributional models:\n\u2022 The geometric/spatial approach which evaluates the relative positions of two words in the semantic space defined by contexts vectors.\n\u2022 The set-based approach which rely on the analysis of the overlap of the set of contexts in which the words occur.\n\u2022 The probabilistic approach which is based on probabilistic models and measures proposed by information theory.\nDue to space constraint, we will only consider specific examples of measures for each category. For detailed information the reader may refer to the presentations provided in original references. Technical details and several measures have also been introduced by Weeds (2003); Curran (2004); Sahlgren (2006); Mohammad and Hirst (2012b); Panchenko (2013).\nThe geometric or spatial approach\nThe geometric approach is based on the assumption that compared elements are defined in a semantic space corresponding to the intuitive spatial model of similarity proposed by cognitive sciences (see Section 1.2.1). A word is considered as a point in a multi-dimensional space representing the diversity of the vocabulary in use or more generally the various contexts which are used to characterise a word. Two words are therefore compared regarding their location in this multi-dimensional space. The dimensions which are considered to represent the semantic space are defined by the contexts used to build the distributional model. Words are represented through their corresponding vector in the matrix and are therefore compared through measures used to compare vectors. This approach as already been illustrated when introducing contexts in Section 2.2.3.\n18Refer to the complex syntagmatic context analysis based on lexical patterns which is introduced page 26."}, {"heading": "32 CHAPTER 2. CORPUS-BASED SEMANTIC MEASURES", "text": "We define u and v the vector representations of the words u and v, with n the size of the vectors, and uk the value of u in dimension k. Among the measures commonly used for comparing vectors, we distinguish:\n\u2022 Minkowski Lp distance metric:\ndistLP (u, v) =\n( n\u2211\nk=1\n|uk \u2212 vk|p ) 1 p\n(2.3)\nsimLP (u, v) = 1\ndistLP (u, v) + 1\nInstances of this measure are L1 Manhattan distance (p = 1) and the L2 Euclidian distance (p = 2).\n\u2022 Cosine similarity, the cosine of the angle between the vectors \u2013 the similarity is inversely proportional to the angle. The cosine similarity between u and v is:\nsimcos(u, v) = \u2211n k=1 ukvk\u221a\u2211n\nk=1 u 2 k \u221a\u2211n k=1 v 2 k\n(2.4)\n\u2022 Measures of correlation can also be used in some cases (Schu\u0308tze, 1998; Ganesan et al., 2003). For instance, the similarity of two words can be defined as the coefficient of the Pearson\u2019s product-moment correlation between their vector representations (the cosine similarity of re-centered vectors):\nsimPearson(u, v) = \u2211n k=1(uk \u2212 u)(vk \u2212 v)\u221a\u2211n\nk=1(uk \u2212 u)2 \u221a\u2211n k=1(vk \u2212 v)2 (2.5)\nNumerous approaches rely on the cosine similarity which, contrary to the Lp family also incorporates information about contexts in which the words do not co-occur. However, as stressed by Lee (1999), the cosine similarity appears to be less effective in some experiments based on paradigmatic context analysis (Weeds, 2003). Other approaches for comparing vectors are introduced by Mohammad and Hirst (2012b), the reader can also refer to the collection of measures proposed by Deza and Deza (2013).\nNumerous approaches based on multidimensional representation of words exist. The most popular approaches based on the spatial model are briefly presented. For each of them we present: (i) the approach used to build the distributional model, (ii) the strategy considered to extract distributional profiles of words and (iii) the measure used to compare these profiles:\n\u2022 LSA \u2013 Latent Semantic Analysis (Deerwester et al., 1990; Landauer and Dumais, 1997; Landauer et al., 1998), also called Latent Semantic Indexing (LSI) in Information Retrieval. This approach is used to represent a word-context matrix, generally a word-document matrix, which can be used to extract a distributional profile of a word. Two word profiles can next be compared using the measures which have been presented above \u2013 the cosine similarity measure was used initially (Equation 2.4). In this approach, the sparseness of the matrix is reduced using Singular Value Decomposition which is a linear algebra operation used to reduce the number of contexts considered in the matrix. This operation is used to obtain a low-rank approximation of the matrix and therefore obtain a more compact representation of the word-context matrix which is used to characterise a word. Such a treatment has also the interesting property to put into light latent concepts by highlighting indirect co-occurrences between words \u2013 i.e. words occurring within a similar context but not necessarily occurring together.\n\u2022 ESA \u2013 Explicit Semantic Analysis (Gabrilovich and Markovitch, 2007). Compared to LSA which uses latent concepts, ESA is based on explicit description of concepts. The approach relies on the analysis of corpora which are composed of texts describing specific concepts. The approach has originally been developed to be used with Wikipedia assuming that an article refers to a specific concept. Then, a word-concept (i.e. word-article) matrix is built in order to characterise a word. Each cell of the matrix refers to the strength of association between the pairs word/concept \u2013 TF-IDF is used (Salton and McGill, 1983). Words are next compared using the cosine similarity of the vector representations of words."}, {"heading": "2.3. DISTRIBUTIONAL MEASURES 33", "text": "\u2022 HAL \u2013 Hyperspace Analogue to Language (Lund and Burgess, 1996). This approach is used to generate a word co-occurrence matrix. Co-occurrences are analysed considering syntagmatic context and a ten word sliding window is used by considering a specific model for counting co-occurrences, i.e. the distance between words in the window are taken into account to weight co-occurrences. In addition, each word is characterised by a vector of twice the size of the vocabulary since words co-occurrence counts are oriented, i.e. two word co-occurrence matrices are computed, one for each side. The similarity of word representations was originally computed using the Minkowski distance, Equation 2.3.\n\u2022 Schutze wordspace (Schu\u0308tze, 1993). In this approach n-gram co-occurrences are analysed to further build word profiles based on it. In the original approach 5000 frequent four-grams were considered to build a four-gram co-occurrence matrix. A four-gram n1 was considered to co-occur with another four-gram n2 if n1 was located at least at 200 four-grams to the left of n2. The matrix is also reduced using SVD. Next, based on this matrix, the vector representations of a word is built summing the vectors which represent each of the 500 n-gram which occurs to the left and right of each occurrence of the word under study (vector representation of words are also normalised). Finally, the similarity between word vectors are computed using the normalised correlation coefficient, based on Equation 2.5.\n\u2022 Random indexing (Kanerva et al., 2000). This approach is based on a two step process. To each context used to characterise a word, e.g. a document or a paragraph, is associated an index vector which corresponds to a randomly generated vector. It will be used to build the vector representation of the words. Each time the word is encountered within a context, e.g. paragraph, the vector associated to the corresponding context will be added to the vector representation of the word. This approach can be used to reduce the high-dimensionality of the sparse word-context matrices produces by other topic model approaches, such as LSA, HAL. It can also be used to avoid the computing expensive reduction of the matrix (which must be computed each time the model is updated). The various measures which can be used to compare vector representation of words can be used with this space model. Nevertheless, note that this model to do not generate a statistically meaningful distributional model composed of specific statistics such as co-occurrences.\n\u2022 COALS \u2013 Correlated Occurrence Analogue to Lexical Semantic (Rohde et al., 2006). This approach uses a four word (weighted) sliding window to compute a word-word co-occurrence matrix. A reduction of the number of columns can be performed in order to focus on the most common words, e.g. considering a frequency threshold. A correlation normalisation is next applied to each cell of the matrix by computing the Pearson correlation between the pair of words which is associated to each cell (Equation 2.5). Negative values are discarded and positive values are square rooted. Reduction of the matrix based on SVD can also be applied. Finally, the cosine similarity (Equation 2.4) is used to compute the similarity of word vectors.\nWe have presented several distributional models from which semantic measures based on the spatial model can be defined. Nevertheless, nothing prevent the use of the statistics provided by most of these distributional model for defining other types of semantic measures.\nThe set-based approach\nWords are compared regarding the number of contexts in which they occur which are common and different (Curran, 2004). The comparison can be made using classical set-based measures (e.g., Dice index, Jaccard coefficient). The reader may refer to the several set-based operators which have for instance been used to compare words in (Bollegala, 2007b; Terra and Clarke, 2003). As an example to compare the words u and v, with C(u) the sets of contexts in which the word u occurs, the similarity can be defined using Dice index:\nsimDice(u, v) = 2|C(u) \u2229C(v)| |C(u)|+ |C(v)| (2.6)\nExtensions have also been proposed in order to take into account a weighting scheme through fuzzy sets, e.g. (Grefenstette, 1994). Set-based measures relying on information theory metrics have also been proposed, they are introduced in the following subsection which presents the measures based on probabilistic approaches."}, {"heading": "34 CHAPTER 2. CORPUS-BASED SEMANTIC MEASURES", "text": "The probabilistic approach\nThe distributional hypothesis enables to express the semantic relatedness of words in term of probability of co-occurrence, i.e. regarding both, the contexts in which compared words appear together and alone. These two evidences can intuitively be used to estimate the strength of association between two words. This strength of association can also be seen as the mutual information of two words which can be expressed regarding the probability the two words occur in the corpus, as well as the probability the two words co-occur in the same context. Once again a large diversity of measures have been proposed in the literature. Only those which are frequently used are presented (Dagan et al., 1999; Mohammad and Hirst, 2012b).\nWith p(u) the probability that the word u occurs in a context and p(u, v) the probability that the two words u and v occurs in the same context \u2013 the notion of context may refer to windows of different sizes or event larger units of language depending on the implementation of the notion of context which is considered (Section 2.2.3). For convenience following formulae are introduced without defining a specific implementation of the notion of context.\n\u2022 Pointwise Mutual Information (PMI) (Fano, 1961).\npmi(u, v) = log p(u, v)\np(u)p(v) (2.7)\nThe PMI was first adapted for the comparison of words by (Church and Hanks, 1990). It is based on the analysis of the number of co-occurrences and individual occurrences of words (marginal frequencies), e.g., in paragraphs or sentences \u2013 examples of use are discussed in (Turney, 2001; Lemaire and Denhie\u0300re, 2008; Mohammad and Hirst, 2012b). On of the limitation of PMI is its biais towards rare words (Manning and Schu\u0308tze, 1999): considering that u and v are two words that always co-occur, we will have p(u, v) = p(u), and pmi(u, v) = log(1/p(u)). Thus, when u is rare, i.e. p(u) is low, the value of pmi(u, v) will be high.\nTo overcome the fact that PMI is biased towards infrequent words, various adaptations and correction factors have been proposed (Pantel and Lin, 2002; Mohammad and Hirst, 2012b). For instance, the Normalised PMI (NPMI) is defined as follows:\nnpmi(u, v) = pmi(u, v)\n\u2212log p(u, v) (2.8)\nOther adaptations have also been proposed, e.g. (Han et al., 2013) propose PMImax, an adaptation of PMI in order to take into account multiple senses of words. Note that (N)PMI functions have also been often used to refine word-context matrices (distributional model) by incorporating information on word association. Another variation of PMI widely used in NLP is the Positive PMI (PPMI) which forces to only consider positive PMI values (Niwa and Nitta, 1994). As an example, Bullinaria and Levy (2007) showed that PPMI outperforms numerous weighting approaches for semantic relatedness computations based on context-co-occurrence analyses. PPMI is defined by :\nppmi(u, v) = max(0, pmi(u, v)) (2.9)\n\u2022 Confusion probability and Maximum likelihood Estimate (MLE) can also be used \u2013 refer to the work of Dagan et al. (1999) for both details and examples.\nVector representation of words obtained from most distributional models can also be seen as distribution functions corresponding to distribution profiles19. Therefore, the several approaches which have been proposed by information theory to compare probability mass functions20 can also be used to compare vector representations of words. Note that measures which consider word representations as probability mass functions imply that the vector representation of words are normalised such as the sum of the vector equals one. The functions commonly used in the probabilistic approach are the followings:\n19i.e. word representation. Distributional profiles are introduced in Section 2.3. Notice that these vectors can also be vectors of strength of association if one of the metrics presented above (e.g. PMI) has been used to convert the initial wordcontext matrix. As an example, considering an initial word-word co-occurrence matrix, this can be done by substituting the value of each cell of the matrix by the corresponding PMI or NPMI values.\n20The reader may refer to the work of Cover and Thomas (2006) for an introduction to the field of Information Theory."}, {"heading": "2.3. DISTRIBUTIONAL MEASURES 35", "text": "\u2022 Kullback-Leibler divergence (information gain or relative entropy) is a classic measure used to compare two probability distributions. It is often characterised as the loss of information when a probability distribution is approximated by another. The distance between two words p and q can thus be estimated by the relative entropy between their respective distributions p and q.\ndistKL(p, q) = n\u2211\nk=1\npklog pk qk\n(2.10)\nThis measure is positive, asymmetric and ensures that distKL(p, p) = 0. However, this distance does not satisfies the triangle inequality. It can also be applied on conditional probabilities (Dagan et al., 1999). Please refer to the details discussed in the contribution of Cover and Thomas (2006) for more information.\n\u2022 Jensen-Shannon divergence. This function also measures the distance between two probability distributions.\ndistJS(p, q) = 1\n2 dKL(p,m) +\n1 2 dKL(q,m) (2.11)\nwith m = p+q2 . This measure is based on the Kullback-Leibler divergence with the interesting properties of being symmetric and to be bounded between 0 and 1 \u2013 it has also been demonstrated that in specific cases this measure is an approximation of the \u03c72 test (Cover and Thomas, 2006).\n\u2022 \u03c72 distance \u2013 several variants exists in the literature.\ndist\u03c72(p, q) = 1\n2\n\u2211\ni\n(pi \u2212 qi)2 pi + qi\n(2.12)\n\u2022 Other measures such as Skew Divergence or Kendall\u2019s \u03c4 (Lee, 1999; Curran, 2004) and the measures presented in Section 2.3.2 for comparing vector representations of words can also be used.\nAn excerpt of the similarity functions which can be used to compare probability distributions can be found in the work of Pantel and Lin (2002); a comprehensive survey presenting a large collection of measures is also proposed by Cha (2007)21.\nSeveral combinations of measures can therefore be used to mix both the strength of association (weighting scheme, e.g., PMI) and the measures which can be used to compare the probability functions/vectors. Alternatively, fuzzy metrics can also be considered for comparing words according to their strength of association \u2013 the reader may refer to the contribution of Mohammad and Hirst (2012b) for detailed examples.\nThe probabilistic approach does not only refers to the different measures based on information theory. Several statistical techniques have also been proposed to define distributional models (or topic models); two of them are briefly presented:\n\u2022 Probabilistic Latent Semantics Analysis (PLSA) is a statistical technique based on mixture decomposition which are derived from latent class model (Hofmann, 1999). Its aim is to propose an approach with a solid foundation in statistics in order to respond to some limitations associated to LSA (e.g. overfitting, word and documents are assumed to be joint by a Gaussian model). The latent variables which are considered in PLSA correspond to topics. The probabilistic model relies on two conditional probabilities: the probability that a word is associated to a given topic and the probability that a document refers to a topic \u2013 refer to the work of Cohen and Widdows (2009) for details.\n\u2022 LDA \u2013 Latent Dirichlet Allocation (Blei et al., 2003). This topic model is similar to PLSA but adopt a different approach w.r.t the assumption on the topic distribution in document. The interested reader will refer to the original publication and to the multiple adaptations proposed for defining semantic measures, e.g. (Dinu and Lapata, 2010).\n21An interesting correlation analysis between measures is also provided."}, {"heading": "36 CHAPTER 2. CORPUS-BASED SEMANTIC MEASURES", "text": ""}, {"heading": "2.3.3 Capturing deeper co-occurrences", "text": "Most of the measures which have been presented so far are based on distributional models build considering syntagmatic contexts. They can only be used to estimate the similarity of words regarding their first order co-occurrences, i.e., the similarity is mainly assessed by studying the contexts in which the words occur together. However, a strong limitation of first order co-occurrence studies (which only rely on simple syntagmatic context, i.e. those not based on syntagmatic patterns) is that words which do not co-occur in the same context will have a low similarity. However, in some cases, similar or related words never co-occur in the same syntagmatic contexts - in particular if short contexts are considered. As an example, even if syntactic context analyses perform well for synonymy detection in general (Turney, 2001), specific synonyms may not co-occurs syntagmatically. As an example, some studies of large corpus have observed that the words road and street almost never co-occurs in the same word window, although they can be considered as synonyms in most cases (Lemaire and Denhie\u0300re, 2008). As we have seen, this specific aspect of word similarity can be studied by analysing paradigmatic contexts, as these words will tend to occur in similar paradigmatic contexts. Approaches have also been proposed to capture this type of word similarity by processing results of syntagmatic context analysis.\nIndeed, focusing on syntagmatic contexts, specific techniques have also been proposed to highlight deeper relationships between words, e.g., second order co-occurrences, i.e. co-occurrences which correspond to paradigmatic relationships. These techniques will transform the word-context matrix to enable evidence of deeper co-occurrence to be captured. To this end matrix factorisation techniques can be used (e.g. SVD is presented in Appendix B).\nStatistical analysis can be used to distinguish valuable patterns in order to highlight deeper cooccurrences between words. These patterns, which represent the relationships between words, can be identified using several techniques; among them we distinguish:\n\u2022 LSA (Dumais et al., 1988), HLA (Lund and Burgess, 1996), PLSA (Hofmann, 1999), LDA (Blei et al., 2003). These approaches have been introduced in Section 2.3.2.\n\u2022 SOC-PMI Second Order Co-occurence PMI (Islam and Inkpen, 2006). This approach can be used to consider related words of the compared words when computing their PMI. Related words were originally obtained using a Web-based search engine; other approaches can also be adopted.\n\u2022 Syntax or dependency-based model, i.e. models which are based on paradigmatic context analysis \u2013 refers to Section 2.2.3.\nWe recall that Appendix C presents other models that can be used to derive word representations."}, {"heading": "2.4 Other corpus-based measures", "text": "The large majority of corpus-based measures are distributional measures and therefore extensively rely on the distributional hypothesis. However, other approaches have been proposed to assess the semantic similarity or relatedness of words based on corpora analysis. As an example, several authors have proposed to compare words w.r.t results returned by an information retrieval system, e.g. using results provided by Web search engines considering the words to compare (Chen et al., 2006; Sahami and Heilman, 2006; Bollegala, 2007b; Cilibrasi and Vitanyi, 2007; Gracia and Mena, 2008). In this case, even if many information retrieval systems are based on an implementation of the distributional hypothesis, these measures are generally not considered as distributional measures per se.\nOther approaches are based on specific treatments performed on semi-structured texts. In Lesk (1986) the author proposes to compare words based on the number of words\u2019 overlap of their descriptions in dictionaries. In other cases, measures also take into consideration more or less structural information, e.g. information expressed into WordNet, Probase (Wu et al., 2012) or other semantic networks (Nitta, 1988; Kozima and Furugori, 1993; Niwa and Nitta, 1994; Kozima and Ito, 1997; Blondel, 2002; Ho and Ce\u0301drick, 2004; Iosif and Potamianos, 2012; Zhila et al., 2013). These approaches are based on concepts which will be introduced in the section dedicated to knowledge-based semantic measures. As an example, (Jarmasz and Szpakowicz, 2003b,a) propose a measure which uses Roget\u2019s Thesaurus to compute the similarity of words. Words are regarded as if they were structured by a taxonomy and the similarity of two words is defined as a function of the depth of the most specific common ancestor of the two words. In other cases a graph representation of a corpus of texts will be build and used as a semantic proxy. For instance, Muller et al. (2006) analyse a dictionary to generate a graph in which nodes are entries in the dictionary or words which occurs in definitions. An edge is created between an entry and each word in"}, {"heading": "2.5. ADVANTAGES AND LIMITS OF CORPUS-BASED MEASURES 37", "text": "its definition. The similarity between words is next evaluated using a random-walk approach. Numerous measures mixing knowledge-based and corpus-based approaches will be introduced in Section 3.8."}, {"heading": "2.5 Advantages and limits of corpus-based measures", "text": "Here, we list some of the advantages and limits of corpus-based semantic measures and in particular those of distributional measures."}, {"heading": "2.5.1 Advantages of corpus-based measures", "text": "\u2022 They are unsupervised and can be used to compare the relatedness of words expressed in corpora without prior knowledge regarding their meaning or usage \u2013 in comparison to knowledge-based measures.\n\u2022 They enable fine-grained analysis of the semantics of measures as tuning of measures can be done by considering syntagmatic and paradigmatic relationships. As we saw, specific measures can also be used to target specific relationships between words, e.g. antonymy.\n\u2022 They can be used to compare numerous units of language (from words to texts)."}, {"heading": "2.5.2 Limits of corpus-based measures", "text": "\u2022 The words to compare must occur at least few times.\n\u2022 They highly depend on the corpus which is used. This specific point can also be considered as an advantage as the measure is context-dependent. Sense-tagged corpora are most of the time not available (Resnik, 1999; Sa\u0301nchez et al., 2011). The construction of a representative corpus of text can be challenging in some usage contexts, e.g., biomedical studies.\n\u2022 It is difficult to estimate the relatedness between concepts or instances due to the disambiguation process which is required prior to the comparison. Distributional measures are mainly designed for the comparison of words. However, some pre-processing and disambiguation techniques can be used to enable concepts or instances comparison from text analysis. Interesting words for the consideration of lexical ambiguity in distributional models have also been proposed, e.g. (Reisinger and Mooney, 2010) propose a VSM that enables context-dependent vector representations of words to be build. Nevertheless, the computational complexity of approaches based on disambiguation is most of the time a drawback making such approaches impracticable with large corpora analysis. The comparison of multi-word expressions can also not be performed using most approaches.\n\u2022 It is difficult to estimate the semantic similarity between two words using these measures. Even if different observations are provided in the literature, it is commonly considered that distributional measures can only be used to capture semantic relatedness. This is due to the large amount of relationships that can be associated to a pair of co-occurring words (Chaffin and Herrmann, 1984; Zhila et al., 2013). And to the fact that co-occurrence is generally, for the most part, only considered as an evidence of relatedness, e.g., (Batet, 2011). Additional considerations have to be made to capture specific relationships. As an example, Mohammad and Hirst (2012b) specifies that similarity can be captured performing specific pre-processing or using specific paradigmatic contexts \u2013 Mohammad et al. (2008) show for instance that semantic measures can be used to detect antonyms. In the same vein, Ferret (2010) proposes an interesting study on the use of corpus-based semantic measures for synonymy extraction22. The reader may also refer to the recent work of Yih et al. (2012) in which the authors propose a modification of LSA to assess the degree of synonymy and antonymy between words.\n\u2022 It is generally difficult to explain and to trace the semantics of the relatedness in some cases, e.g. when the approach is based on a general implementation of the distributional hypothesis it is difficult to deeply understand the semantics associated to the co-occurrences and therefore to the scores produced by the measure.\n22As we will see in Chapter 4 which is dedicated to semantic measure evaluation, synonymy detection is frequently used to compare and to analyse measures."}, {"heading": "38 CHAPTER 2. CORPUS-BASED SEMANTIC MEASURES", "text": "Software solutions and source code libraries that provide corpus-based semantic measures implementations are presented in Appendix D. Chapter 4 also provides information related to the evaluation protocoles and datasets that can be used to compare these measures."}, {"heading": "2.6 Conclusion", "text": "Due to their central importance for applications based on natural language analysis, corpus-based semantic measures have attracted a lot of interest in the last decades. This has led to the proposal of a large variety of measures which can be used to compare different types of units of language \u2013 from words to documents. As an introduction to corpus-based semantic measures and to illustrate the type of semantic evidence which can be extracted from natural language analysis in order to compare units of language, this chapter has focused on presenting measures for comparing words. This type of measures is cornerstone of corpus-based semantic measures. Indeed, these measures are based on important notions and models which are used to design measures for comparing larger lexical units.\nAs we saw, most of the measures which have been proposed in the literature are based on distributional semantics and rely on distributional semantics through the definition or extension of topic models, e.g., LSA, HAL, LDA. These measures are based on syntagmatic and paradigmatic analyses of language, i.e. according to the distributional hypothesis, words are compared w.r.t the contexts in which they occur. An important aspect of this approach is therefore that its roots are based on a quantitative analysis of word occurrences w.r.t. the central notion of context detailed in this chapter.\nWe have also introduced alternative approaches to pure-distributional measures. They take advantage of external algorithms which are used to distinguish relevant resources considering specific words. Words will therefore be compared by analysing the set of resources which are associated to them. It\u2019s worth to note that most of the time these resources are retrieved based on algorithms which also take into account the distributional hypothesis, sometimes implicitly, e.g. approaches based on information retrieval algorithms. This challenges the ability to differentiate corpus-based measures defined as purely distributional, i.e. distributional measures, and other measures.\nAn interesting and important aspect of corpus-based measures is therefore the large diversity of lexical units they can compare and the diversity of approaches and adaptations defined in the literature. In this context, important research efforts focus on defining methods for adapting corpus-based measures dedicated to the comparison of words, and more particularly distributional measures, in order to compare larger lexical units such as sentences, paragraphs or documents. To this end, a central aspect to study is semantic compositionality w.r.t semantic similarity: how to evaluate larger units of language than words using approaches commonly used to define corpus-based measures, e.g., using the distributional hypothesis and by adapting distributional models (Kamp et al., 2014). Challenges related to this field of study also aim at incorporating the consideration of linguistic expressions, e.g. anaphora or even negation (to cite a few) into existing models. It is indeed commonly considered that current models and in particular distributional semantics provide quantitative evidence of semantic similarity and therefore only give access to a rough approximation of the meaning which is conveyed by natural language (Baroni and Lenci, 2010). This highlights the narrow link which exists between the study of semantic measures and the study of computable models of natural language such as distributional models.\nAnother interesting and important topic refers to the unification of corpus-based measures in order to define models which are generic enough to be used for comparing lexical units of different granularities, i.e. in order that the same approach/measure can be used to define corpus-based semantic measures for comparing words or paragraphs (Pilehvar et al., 2013).\nChapter 3\nKnowledge-based semantic measures\nAs we have seen, two main families of semantic measures can be distinguished: corpus-based measures, which take advantage of unstructured or semi-structured texts, and knowledge-based measures which rely on ontologies.\nCorpus-based measures are essential for comparing units of languages such as words, or even concepts when there is no formal expression of knowledge available to drive the comparison. On the contrary, knowledge-based semantic measures rely on more or less formal expressions of knowledge explicitly defining how the compared entities, i.e. concepts or instances, must be understood. Thus, they are not constrained to the comparison of units of language and can be used to drive the comparison of any formally described pieces of knowledge, which encompasses a large diversity of elements, e.g., concepts, genes, person, music bands, etc.\nThis chapter focuses on knowledge-based measures and we will more particularly introduce measures which rely on ontologies processed as semantic graphs or semantic networks. These measures are generally used to compare terms structured through unambiguous semantic relationships or concepts defined in taxonomies and knowledge organisation systems. It also encompasses measures commonly used to compare terms or senses defined into lexical databases such as WordNet (Miller, 1998; Fellbaum, 2010).\nThe main limitation of knowledge-based measures is their strong dependence on the availability of an ontology \u2013 an expression of knowledge which can be difficult to obtain and may therefore not be available for all fields of studies. However, in recent decades, we have observed, both in numerous scientific communities and industrial fields, the growing adoption of knowledge-enhanced approaches based on ontologies. As an example the Open Biological and Biomedical Ontology (OBO) foundry gives access to hundreds of ontologies related to biology and biomedicine. Moreover, thanks to the large efforts made to standardise the technology stack which can be used to define and to take advantage of ontologies (e.g., RDF(S), OWL, SPARQL \u2013 triple stores implementations) and thanks to the increasing adoption of the Linked Data and Semantic Web paradigms, a large number of initiatives give access to ontologies in numerous domains (e.g., biology, geography, cooking, sports).\nIn the introduction, we also point out that several large corporations adopt ontologies to support large-scale worldwide systems. The most significant example over recent years is the adoption of the Knowledge Graph by Google, a graph built from a large collection of billions of non-ambiguous subjectpredicate-object statements used to formally describe general or domain-specific pieces of knowledge (Singhal, 2012). This ontology is used to enhance their search engine capabilities and millions of users benefit from it on a daily basis. Several examples of such large ontologies are now available: DBpedia, Freebase, Wikidata, Yago.\nAnother significant fact about the increasing adoption of ontologies is the joint effort made by the major search engines companies, e.g., Bing (Microsoft), Google, Yahoo! and Yandex, to design Schema.org1, a set of structured schemas defining a vocabulary which can be used by publishers to define meta-data with the aim of characterising the content of their web pages in an unambiguous manner.\nAnother interesting aspect of the last few years is the growing adoption of graph databases (e.g., Neo4J2, OrientDB3, Titan4). These databases rely on a graph model to describe information in a NoSQL\n1http://schema.org 2http://www.neo4j.org/ 3http://www.orientechnologies.com/orientdb/ 4http://thinkaurelius.github.io/titan/\n39"}, {"heading": "40 CHAPTER 3. KNOWLEDGE-BASED SEMANTIC MEASURES", "text": "fashion. They actively contribute to the growing adoption of the graph property model \u2013 thinking in terms of connected entities (Robinson et al., 2013).\nIn this context, a lot of attention has been given to ontologies, which in numerous cases merely correspond to semantic graphs or semantic networks \u2013 characterised elements (concepts, instances and relationships) are defined in an unambiguous manner without using complex logical constructs. Such semantic graphs have the interesting properties of being easily expressed and maintained while ensuring a good ratio between semantic expressiveness and effectiveness (in term of computational complexity). This justifies the large number of contributions related to the design of semantic measures dedicated to semantic graphs \u2013 a diversity of measures to which this chapter is dedicated.\nDue to space constraint we will not introduce knowledge-based measures which refer to logic-based measures, i.e. measures used to compare knowledge base entities defined using complex logical constructs. These measures are used to process knowledge bases, generally defined using description logics, which cannot most of the time be considered as simple graphs \u2013 even if a partial representation of the knowledge they define can be reduced as a graph. An introduction to logic-based measures can be found in (D\u2019Amato, 2007), several references are also provided in Section 3.6.1 and in (Harispe et al., 2013b, version 2). In addition, this chapter will not detail the semantic measures which have been proposed for comparing concepts taking into account multiple ontologies, they are however introduced in Section 3.6.2.\nThis chapter is structured as follow. Section 3.1 provides information regarding the processing of ontologies through semantic graph representations. It also defines the formal notations which will be used to present the measures. Section 3.2 distinguishes different types of measures w.r.t the properties of the semantic graph considered. Section 3.3 presents the foundations of numerous knowledge-based measures by introducing semantic evidence which can be extracted from semantic graph analysis (mainly taxonomies). Section 3.5 presents numerous measures which have been proposed for assessing the semantic similarity of concepts defined in a taxonomy. Section 3.6 briefly introduces knowledge-based measures which are not detailed in this chapter, i.e. logic-based measures and measures based on the analysis of multiple ontologies \u2013 several references are provided. Section 3.7 discusses the advantages and limits of knowledge-based measures. Finally, Section 3.9 concludes this chapter."}, {"heading": "3.1 Ontologies as graphs and formal notations", "text": "This section presents the type of ontologies and knowledge organisation system considered in this book. It also provides important information regarding ontology processing through graph analysis \u2013 information which is generally not provided in contribution related to semantic measures. We next introduce the notations which will be used in this chapter to refer to particular constitutive elements of a semantic graph."}, {"heading": "3.1.1 Ontologies as graphs", "text": "We briefly introduces the reader to ontologies which can be processed as graphs. However, this section does not aim at: (i) presenting the field of Knowledge Representation, (ii) discussing the broad diversity of ontologies which have been proposed in the literature, and (iii) introducing the language and specifications which can be used to express ontologies, e.g., RDF(S), OWL. Here, we assume that the reader is already familiar with knowledge modelling and to the associated terminology. An introduction to this field of study is provided by Gruber (1993); Baader et al. (2010); Hitzler et al. (2011).\nNumerous ontologies can be expressed as graphs. In addition, more complex ontologies can be reduced or used to generate knowledge represented as a graph. This section discusses specific aspects of ontologies related to graph representations. We first introduce simple ontologies which can be represented as graphs (e.g., taxonomies) to further discuss the case of more complex ontologies.\nTaxonomies and partially ordered sets\nTaxonomies are used to structure elements which have similar characteristics into ordered classes. They were originally used in biology to define taxa (classes), by categorising organisms sharing common properties. A taxonomy is a function of a taxonomic scheme which defines the properties considered to distinguish classes. Depending on this scheme, the number of classes and their ordering may vary.\nThe semantics carried by a taxonomy is non-ambiguous as the interpretation of the taxonomic relationship is formally expressed through particular properties/axioms. Indeed, considering a set of"}, {"heading": "3.1. ONTOLOGIES AS GRAPHS AND FORMAL NOTATIONS 41", "text": "elements C (e.g. concepts), a taxonomy is a non-strict partial order (poset) of C. It can be defined by C , a binary relation over C which is5 : (i) reflexive \u2200c \u2208 C : c c, (ii) antisymmetric \u2200u, v \u2208 C : (u v \u2227 v u)\u21d2 u = v and (iii) transitive \u2200u, v, w \u2208 C : (u v \u2227 v w)\u21d2 u w.\nNote that in some rare cases taxonomies are totally ordered, but generally, they are only partially ordered, i.e., \u2203(u, v) \u2208 C : u v \u2227 v u. Given that they generally contain a root element denoted > which subsumes all other elements, i.e., \u2200c \u2208 C, c >, they can be represented as a connected, Rooted and Directed Acyclic Graph (RDAG).\nA taxonomy of concepts C can therefore be formally defined as a semantic graph O : \u3008C,R,E,AO\u3009 with C the set of concepts, R a singleton defining the unique predicate which can be used to order the concepts, i.e. R = {subClassOf} and E \u2286 C \u00d7R\u00d7C the set of oriented relationships (edges) which defines the ordering of C.\nOnly considering O : \u3008C,R,E\u3009 leads to a labelled graph structuring elements of C through labelled oriented edges. Nevertheless, by defining the sets of axioms associated to the taxonomic predicate defined in R, e.g., associated relationships are considered reflexive, antisymmetric and transitive, AO explicitly and formally states that O is a taxonomy per se and not a simple graph data structure. These axioms can be used to define inference techniques and more generally to ensure the coherence of specific algorithms w.r.t the knowledge defined in the representations. As an example, Figure 3.1 denotes an example of taxonomy represented by a graph structure.\nAlthough simple, taxonomies are knowledge organisation systems which are used in numerous processes; they are also the backbones of more refined ontologies and are therefore considered as essential components of knowledge modelling. Most of the measures detailed in this chapter rely on these simple ontologies. The notion of taxonomy has been detailed here through a taxonomy of concepts, we also consider R the taxonomic of predicates in which subPredicateOf refers to the taxonomic relationship defining that one predicate inherits from another6.\nGeneral discussion on ontologies as graphs\nAlthough some ontologies cannot be reduced to simple graphs, a large part of the knowledge they model can generally be expressed as a graph. Therefore, an important aspect to understand is that ontologies, even if they are not explicitly defined as graphs, can be reduced into graphs. Indeed, in all cases, a partial representation of the knowledge defined in expressive ontologies can be manipulated as a graph. The example of the taxonomy has been underlined but this is also the case for the knowledge which links instances to classes (also obtained by a common reasoning procedure). In this case, the ontology can be reduced as a graph in which instances are represented as nodes and linked to their class(es) by simple subject\u2013predicate\u2013object (spo) statements. Therefore, any complex ontology, in which sets of concepts and instances have been defined, can be represented as a connected graph in which nodes denote concepts or instances.\nIn this chapter we consider a graph-based formalism frequently used to manipulate ontologies. It can be used to express numerous network-based ontologies and, sometimes through reductions, ontologies\n5Note that we adopt the notation used in the literature related to poset instead of the notation commonly used in description logics (v).\n6Generally named subPropertyOf, e.g., in RDFS."}, {"heading": "42 CHAPTER 3. KNOWLEDGE-BASED SEMANTIC MEASURES", "text": "which rely on complex logic constructs. It corresponds to an extension of the structure O : \u3008C,R,E,AO\u3009 which has been presented to introduce taxonomies as graphs. Extensions have been made to take instances, data values and multiple predicates into consideration. The next subsection presents this formalism in detail.\nTypes of ontologies considered in this chapter\nRegardless of the particularities of some domain-specific ontologies and regardless of the language considered for the modelling, all approaches used to represent knowledge share common components:\n\u2022 Concepts (Classes), set of things sharing common properties, e.g., Human.\n\u2022 Instances, i.e., members of classes, e.g., alan (an instance of the class Human).\n\u2022 Predicates, the types of relationships defining the semantic relationships which can be established between instances or classes, e.g., subClassOf.\n\u2022 Relationships, concrete links between classes and instances which carry a specific semantics, e.g., alan isA Human \u2013 alan worksAt BletchleyPark. Relationships form spo statements.\n\u2022 Attributes, properties of instances, e.g., Alan hasName Turing.\n\u2022 Axioms, for instance defined through properties of the predicates, e.g. taxonomic relationships are transitive, the definition of the domain and the range (co-domain) of predicates, or constraints on predicate and attributes, e.g., Any Human has exactly 2 legs.\nIn practice, numerous ontologies do not rely on complex logical constructs or complex concept/predicate definitions but rather correspond to a formal semantic network, here denoted semantic graphs. In addition, we have stressed the fact that complex ontologies can also be regarded as semantic graphs (sometimes considering partial reductions).\nA semantic graph, in which instances of classes and data values of specific datatypes are considered, can formally be defined by O : \u3008C,R, I, V,E,AO\u3009, with:\n\u2022 C the set of concepts. \u2022 R the set of predicates. \u2022 I the set of instances. \u2022 V the set of data values. \u2022 E the set of oriented relationships of a specific predicate r \u2208 R: E \u2286 ECC \u222a ERR \u222a EII \u222a EIC \u222a ECI \u222a ECV \u222a ERV \u222a EIV with:\n\u2013 ECC \u2286 C \u00d7R\u00d7 C \u2013 ERR \u2286 R\u00d7R\u00d7R \u2013 EII \u2286 I \u00d7R\u00d7 I \u2013 EIC \u2286 I \u00d7R\u00d7 C \u2013 ECI \u2286 C \u00d7R\u00d7 I \u2013 ECV \u2286 C \u00d7R\u00d7 V \u2013 ERV \u2286 R\u00d7R\u00d7 V \u2013 EIV \u2286 I \u00d7R\u00d7 V\n\u2022 AO the set of axioms defining the interpretations of classes and predicates."}, {"heading": "3.1. ONTOLOGIES AS GRAPHS AND FORMAL NOTATIONS 43", "text": "The sets of concepts (C), predicates (R), instances (I), values (V ) are expected to be mutually disjoint7. We consider that each instance is a member of at least one concept and that the taxonomies of concepts C , and predicates R (if any), correspond to connected and rooted directed acyclic graphs (RDAGs). In this manuscript we will mainly manipulate such an ontology without considering predicate taxonomies.\nIn the following, we consider that a lexical reference \u2013 didactical device (Guarino and Giaretta, 1995) \u2013 is used to refer, in an unambiguous manner, to any node which refers to a concept/predicate/instance. Although we will use a literal in this manuscript, in practice, this unique identifier is a URI or a domainspecific identifier \u2013 except data values (V) which are (typed) literals.\nFigure 3.2 presents an example of a semantic graph related to the music domain which involves related concepts, predicates, instances and data values8.\nIn this example, concepts are taxonomically structured in the layer C, e.g. MusicBand, MusicGenre. Several types of instances are also defined in layer I, e.g. rollingStones, rock. These instances can be characterised according to specific concepts, e.g. the statement rollingStones isA MusicBand defines that rollingStones is a member of the class MusicBand. In addition, instances can be interconnected through specific predicates, e.g., rollingStones hasGenre rock. Specific data values (layer D) can also be used to specify information relative to both concepts and instances, e.g., rollingStones haveBeenFormedIn \"1962-01-01\"\u2227\u2227xsd:date. All relationships which link the various nodes of the graph are directed and semantically characterised, i.e., they carry an unambiguous and controlled semantics. Notice that extra information are not represented in this figure, e.g., the taxonomy of predicates, axiomatic definitions of predicate properties.\nWe denote GT , the taxonomic reduction of the ontology, i.e. the layer C in Figure 3.2. GT corresponds to the taxonomy C , and therefore only contains concepts. As we will see, this reduction is widely used to compute the semantic similarity between concepts; it will be extensively used in this chapter.\nWe will alos denote GTI (T stands for Taxonomic and I for isA relationship) the graph composed of the layers C and I in Figure 3.2 (only considering edges in ECC , EII and EIC 9).\nKnowledge modelling is a vast domain and a large diversity of ontologies have been proposed to express knowledge in a machine understandable form. This section has briefly introduced several ontologies\n7Note that a set of data types (D) can easily be added. 8Representation of a subgraph extracted from DBpedia (Auer et al., 2007). 9Triplets are rarely defined in ECI ."}, {"heading": "44 CHAPTER 3. KNOWLEDGE-BASED SEMANTIC MEASURES", "text": "which can be processed as graphs. We have also introduced the formalism adopted in this manuscript to represent such ontologies and to refer to some of their essential components."}, {"heading": "3.1.2 Relationships", "text": "The relationships of a semantic graph are distinguished according to their predicate and to the pair of elements they link. They can also be denoted statements or triplets in some contributions. As an example, the triplet (u, t, v) corresponds to the unique relationship of type t \u2208 R which links the elements u, v: u is named the subject, t the predicate and v the object. Relationships are central elements of semantic graphs and will be used to define algorithms and to characterise paths in the graph.\nSince the relationships are oriented, we denote t\u2212 the type of relationship carrying the inverse semantic of t. We therefore consider that any relationship (u, t, v) implicitly implies (v, t\u2212, u), even if the type of relationship t\u2212 and the relationship (v, t\u2212, u) are not explicitly defined in the graph. As an example, the relationship Human subClassOf Mammal implies the inverse relationship Mammal subClassOf\u2212 Human (even if the ontology defines that superClassOf is the inverse of subClassOf\u2212, i.e. subClassOf\u2212 \u2261 superClassOf). The notion of inverse predicate will be considered to discuss detailed paths. In some ontology languages, inverse relationships between predicates are explicitly defined by specific construct, e.g., owl:inverseOf in OWL."}, {"heading": "3.1.3 Graph traversals", "text": "Graph traversals are often represented through paths in a graph, i.e., sequence of relationships linking two nodes. To express such graph paths, we adopt the following notations10.\n\u2022 Path: Sequence of relationships [(ci\u22121, ti, ci), (ci, ti+1, ci+1), . . .]. To lighten the formalism, if a single predicate is used the path is denoted [ci\u22121, ci, ci+1, . . .]t.\n\u2022 Path Pattern: We denote \u03c0 = \u3008t1, . . . , tn\u3009 with tn \u2208 R, a path pattern which corresponds to a list of predicates11. Therefore, any path which is a sequence of relationships is an instance of a specific path pattern \u03c0.\nWe extend the use of the path pattern notation to express concise expressions of paths:\n\u2022 \u3008t\u2217\u3009 corresponds to the set of paths of any length composed only of relationships having for predicate t.\n\u2022 \u3008t\u2217\u2217\u3009 corresponds to the set of paths of any length composed of relationships associated to the predicate t or t\u2212.\nAs an example, {Human, \u3008subClassOf\u2217\u3009, Animal} refers to all paths which link concepts Human and Animal and which are only composed of relationships subClassOf (they do not contain relationships of type subClassOf\u2212).\nWe also mix the notations to characterise set of paths between specific elements. As an example, {u, \u3008t, subClassOf\u2217\u3009, v} represents the set of paths which (i) link the elements u and v, (ii) start by a relationship of predicate t, and (iii) end by a (possibly empty) path of subClassOf relationships. As an example the concept membership function I which characterises instances of a specific concept can formally be redefined by:\nI(X) = {i|{i, \u3008isA,subClassOf\u2217\u3009, X} 6= \u2205 } (3.1) To lighten the formalism, we consider that the set of paths {u, \u3008p\u2217\u3009, v} can be shortened by {u, p, v},\ne.g. {Human, \u3008subClassOf\u2217\u3009, Animal} = {Human, subClassOf, Animal} and {Human, \u3008subClassOf\u2217\u2217\u3009, Animal} = {Human, subClassOf\u2217, Animal}"}, {"heading": "3.1.4 Notations for taxonomies", "text": "The taxonomy GT is the semantic graph associated to the non-strict partial order defined over the set of concepts C. We introduce the notations used to characterise GT as well as its concepts; some of them have already been introduced and are repeated for clarity:\n\u2022 C(GT ) shortened by C refers to the set of concepts defined in GT . 10These notations are based on an adaptation of the notations used by Lao (2012). 11In SPARQL 1.1, such paths are denoted using path properties t1/t2/t3."}, {"heading": "3.1. ONTOLOGIES AS GRAPHS AND FORMAL NOTATIONS 45", "text": "\u2022 E(GT ) shortened by ET refers to the set of relationships defined in GT with:\nET \u2286 C \u00d7 {subClassOf} \u00d7 C \u2286 ET \u2286 ECC12\n\u2022 A concept v subsumes another concept u if u v, i.e., {u, subClassOf, v} 6= \u2205. Several additional denominations will be used; it is commonly said that v is an ancestor of u, that u is subsumed by v and that u is a descendant of v.\n\u2022 C+(u) \u2286 C, with u \u2208 C, the set of concepts such as:\nC+(u) = {c|(u, subClassOf, c) \u2208 ET }\n\u2022 C\u2212(u) \u2286 C, with u \u2208 C, the set of concepts such as:\nC\u2212(u) = {c|(c, subClassOf, u) \u2208 ET }\n\u2022 C(u) \u2286 C, with u \u2208 C, the set of neighbours of concepts such as:\nC(u) = C+(u) \u222a C\u2212(u)\n\u2022 A(u) the set of concepts which subsumes u, also named the ancestors of u, i.e., A(u) = {c|{u, subClassOf, c} 6= \u2205} \u222a {u}. We also denote A\u2212(u) = A(u) \\ {u} the exclusive set of ancestors of u.\n\u2022 parents(u) the minimal subset of A\u2212(u) from which A\u2212(u) can be inferred according to the taxonomy GT , i.e., if GT doesn\u2019t contain taxonomic redundancies 13 we obtain: parents(u) = C+(u).\n\u2022 D(u) the set of concepts which are subsumed by u, also named the descendants of u, i.e., D(u) = {c|{c, subClassOf, u} 6= \u2205} \u222a {u}. We also denote D\u2212(u) = D(u) \\ {u} the exclusive set of descendants of u.\n\u2022 children(u) the minimal subset of D\u2212(u) from which D\u2212(u) can be inferred according to the taxonomy GT , i.e., if GT doesn\u2019t contain taxonomic redundancies we obtain: children(u) = C \u2212(u).\n\u2022 roots(GT ), shortened by roots, the set of concepts {c|A(c) = {c}}. We call the root, denoted as >, the unique concept (if any) which subsumes all concepts, i.e., \u2200c \u2208 C, c >.\n\u2022 leaves(GT ), shortened by leaves, the set of concepts without descendants, i.e. leaves = {c|D(c) = {c}}. We also note leaves(u) the set of leaves subsumed by a concept (inclusive if u is a leaf), i.e., leaves(u) = D(u) \u2229 leaves.\n\u2022 depth(u), the length of the longest path in {u, subClassOf,>}, for convenience we also consider depth(GT ) = argmax\nc\u2208C depth(c).\n\u2022 G+T (u) the graph composed of A(u) and the set of relationships which link two concepts in A(u).\n\u2022 G\u2212T (u) the graph composed of D(u) and the set of relationships which link two concepts in D(u).\n\u2022 GT (u) = G+T (u) \u222aG\u2212T (u) the graph induced by A(u) \u222aD(u).\n\u2022 \u2126(u, v), the set of Non Comparable Common Ancestors (NCCAs) of the concepts u, v. \u2126(u, v) is formally defined by: \u2200(x, y) \u2208 \u2126(u, v), (x, y) \u2208 {A(u)\u2229A(v)}\u00d7{A(u)\u2229A(v)}\u2227x /\u2208 A(y)\u2227y /\u2208 A(x). NCCAs are also called the Disjoint Common Ancestors (DCAs) in some contributions, e.g. (Couto et al., 2005).\n12ECC were used to introduce semantic graphs 13Taxonomic redundancies refer to taxonomic relationships which can be inferred analysing other relationships. As an\nexample if it is define that u \u227a v and v \u227a w, a relationship which explicitly defines that u \u227a w is considered redundant."}, {"heading": "46 CHAPTER 3. KNOWLEDGE-BASED SEMANTIC MEASURES", "text": "\u2022 A taxonomic tree is defined as a special case of taxonomy in which: \u2200c \u2208 C : |parents(c)| < 2.\nDespite the fact that these notations are used to characterise the taxonomy of concepts GT and that specific semantics is associated to the notations (e.g., parents, children), they can be used to characterise any poset.\nUsing these notations, the next section introduces semantic evidence which are commonly used to assess the semantic similarity or relatedness of concepts or instances defined into semantic graphs."}, {"heading": "3.2 Types of semantic measures and graph properties", "text": "Two main groups of measures can be distinguished depending on the properties of semantic graphs they are adapted to:\n\u2022 Measures adapted to semantic graphs composed of (multiple) predicate(s) which potentially induce cycles.\n\u2022 Measures adapted to taxonomies, i.e., acyclic semantic graphs composed of a unique predicate inducing transitivity.\nThe two types are introduced in the following sections."}, {"heading": "3.2.1 Semantic measures on cyclic semantic graphs", "text": "Considering all predicates defined in a semantic graph potentially leads to a cyclic graph. Nevertheless, only few semantic measures framed in the relational setting have been designed to deal with cycles. Since these measures take advantage of all predicates, they are generally used to evaluate semantic relatedness (and not semantic similarity). Notice that they can be used to compare concepts and instances. Two types of measures can be further distinguished:\n\u2022 Measures based on graph traversal, i.e., pure graph-based measures. These measures have initially been proposed to study node interactions in a graph and essentially derive from graph theory contributions. They can be used to estimate the relatedness of nodes considering that greater the (direct or indirect) interconnection between two nodes, the more related they are. These measures are not semantic measures per se but rather graph measures used to compare nodes. However, they can be used on semantic graphs and can also be adapted in order to take into account evidence of semantics defined in the graph (e.g. strength of connotation).\n\u2022 Measures based on the graph property model. These measures consider concepts or instances as sets of properties distinguished from the graph.\nSemantic measures based on graph traversals\nMeasures based on graph traversals can be used to compare any pair of concepts or instances represented as nodes. These measures rely on algorithms designed for graph analysis which are generally used in a straightforward manner. Nevertheless, some adaptations have been proposed in order to take into account the semantics defined in the graph. Among the large diversity of measures and metrics which can be used to estimate the relatedness (distance, interconnection, etc.) of two nodes in a graph, we distinguish:\n\u2022 Shortest path approaches.\n\u2022 Random-walk approaches.\n\u2022 Other interconnection measures.\nThe main advantage of these measures is their unsupervised nature. Their main drawback is the absence of extensive control over the semantics which are taken into account; this generates difficulties in justifying, explaining, and therefore analysing the resulting scores. However, in some cases, these drawbacks are reduced by enabling fine-grain control over the predicates considered during the comparison. This is done by tuning the contribution of each relationship or predicate."}, {"heading": "3.2. TYPES OF SEMANTIC MEASURES AND GRAPH PROPERTIES 47", "text": "Shortest path approaches\nThe shortest path problem is one of oldest problems of graph theory. It can be applied to compare both pairs of instances and concepts considering their relatedness as a function of the distance between their respective nodes. More generally, the relatedness is estimated as a function of the weight of the shortest path linking them. Classical algorithms proposed by graph theory can be used. The algorithm to use depends on specific properties of the graph, e.g., Do the constraints applied to the shortest path (really) induce cycles? Are there non-negative weights associated to relationships? Is the graph considered to be oriented?\nRada et al. (1989) were among the first to use the shortest path technique to compare two concepts defined in a semantic graph (initially a taxonomy). This approach is sometimes denoted as the edge-counting strategy in the literature (edge refers to relationship). As the shortest path may contain relationships of any predicate we call it unconstrained shortest path (usp).\nOne of the drawbacks of the usp in the design of semantic measures lies in the fact that the meaning of the relationships from where the relatedness derives is not taken into account. In fact, complex semantic paths which involve multiple predicates and only those composed of taxonomic relationships are considered equally. Therefore, propositions to penalise any usp reflecting complex semantic relationships have been proposed (Hirst and St-Onge, 1998; Bulskov et al., 2002). Approaches for considering particular predicates in a specific manner have also been described. To this end, a weighting scheme can be considered in order to tune the contribution of each relationship or predicate in the computation of the final score \u2013 this weighting scheme can be derived from the notion of strength of connotation (Section 3.3.3).\nRandom walk approaches\nThese approaches are based on a Markov chain model of random walks (Spitzer, 1964). The random walk is defined through a transition probability associated to each relationship. The walker can therefore walk from node to node \u2013 each node represents a state of the Markov chain. Several measures can be used to compare two nodes u and v based on this technique; a selection of measures introduced by Fouss et al. (2007) is listed:\n\u2022 The average first-passage time, hitting time, i.e., the average number of steps needed by the walker to go from u to v.\n\u2022 The average commute time, Euclidean commute time distance.\n\u2022 The average first passage cost.\n\u2022 The pseudo inverse of the Laplacian matrix.\nThese approaches are closely related to spectral clustering and spectral embedding techniques (Saerens et al., 2004). Examples of measures based on random walk techniques are defined and discussed in (Muller et al., 2006; Hughes and Ramage, 2007; Ramage et al., 2009; Fouss et al., 2007; Alvarez and Yan, 2011; Garla and Brandt, 2012).\nAs an example, the hitting time H(u, v) of two nodes u, v is defined as the expected number of steps needed by a random walker to go from u to v. The hitting time can recursively be defined by:\nH(u, v) = 1 + \u2211\nk\u2208N+(u) p(u, k)H(k, v) (3.2)\nWith N+(u) the set of nodes which are linked to u by an outgoing relationship starting from u and p(u, k) the transition probability of the Markov Chain:\np(u, k) = w(u, k)\u2211\ni\u2208N+(u) w(u, i)\nWith w(u, k) the weight of the relationship between u and k. The commute time C(u, v) = H(u, v)+H(v, u) corresponds to the expected time needed for a random walker to travel from u to v and back to u. Intuitively, the more paths that connect u and v, the smaller their commute distance becomes. Several technical criticisms of classical approaches used to evaluate"}, {"heading": "48 CHAPTER 3. KNOWLEDGE-BASED SEMANTIC MEASURES", "text": "hitting and commute times, as well as associated extensions, have been formulated in the literature, e.g., (Sarkar et al., 2008; von Luxburg et al., 2011).\nIn a similar vein, approaches based on graph-kernel can also be used to estimate the relatedness of two nodes in a graph (Kondor and Lafferty, 2002); they have already been applied to the design of semantic measures by Guo et al. (2006).\nNote that these measures take advantage of second-order information which is generally hard to interpret (in terms of semantics).\nOther measures based on interaction analysis\nSeveral approaches exploiting graph structure analysis can be used to estimate the relatedness of two nodes through their interconnections. Chebotarev and Shamis (2006b,a) proposed the use of indirect paths linking two nodes by means of the matrix-forest theorem. simRank, proposed by Jeh and Widom (2002), is an example of such a measure. Considering N as the set of nodes of the graph, N\u2212(n) as the nodes linked to the node n by a single relationship ending with n (i.e., in-neighbours), simRank similarity is defined by:\nsimRank(u, v) = |N | |N\u2212(u)||N\u2212(v)| \u2211\nx\u2208N\u2212(u)\n\u2211\ny\u2208N\u2212(v) simRank(x, y) (3.3)\nNote that simRank is a normalised function. Olsson et al. (2011) propose an adaptation of the measure for semantic graphs built from Linked Data.\nSemantic measures for the graph property model\nThe second type of measures which can be used to compare a pair of instances/concepts defined in a (potentially) cyclic semantic graph relies on the graph property model. Here the graph is not only considered as a data structure which highlights the interactions between the different elements it defines. It is considered as a data model in which concepts and instances are describes through sets of properties. The properties may sometimes refer to specific data types. Therefore, the nodes of the graph may refer to data values, concepts, instances or even predicates \u2013 the semantic graphs generally correspond to RDF graphs or labelled graphs.\nIn this case the measures take advantage of semantic graphs by encompassing expressive definitions of concepts/instances through properties. The measures rely on the comparison of the different properties which characterise the concepts or instances being compared. Therefore the study of these measures inherits from early work related to both the comparison of objects defined into knowledge base and the comparison of entities defined in a subset of the first order logic (Bisson, 1992, 1995). As an example, these measures have been extensively studied for comparing objects analysing their different properties. They are based on the aggregation of specific measures enabling the comparison of each of the properties characterising compared objects (Valtchev and Euzenat, 1997; Valtchev, 1999b,a). Considering the domain of knowledge representation, these contributions have formed the basis of several frameworks which are used for comparing instances or concepts in the field of ontology alignment or instance matching, e.g., OWL Lite Alignment (OLA) method has been proposed to compare ontologies based on aggregations of several measures (Euzenat and Valtchev, 2004; Euzenat et al., 2004).\nIn this presentation, we do not introduce the expressive formalisms which have been introduced in earlier contributions (Bisson, 1992, 1995; Euzenat and Valtchev, 2004; Euzenat et al., 2004; Harispe et al., 2013a), e.g. for comparing objects defined in a knowledge base (Valtchev and Euzenat, 1997; Valtchev, 1999b,a; Harispe et al., 2013a). We rather distinguish two general approaches which have been proposed and which are commonly used to compare concepts or instances.\nElements represented as a list of direct property An element can be evaluated by studying its direct properties, i.e., the set of values associated to the element according to a specific predicate. As an example, focusing on relationships related to instances, two types of relationships can be distinguished:\n\u2022 Taxonomic relationships (isA) \u2013 relationships which link instances to concepts.\n\u2022 Non-taxonomic relationships:"}, {"heading": "3.2. TYPES OF SEMANTIC MEASURES AND GRAPH PROPERTIES 49", "text": "\u2013 Which link two instances (object properties in OWL).\n\u2013 Which link instances to data values (datatype properties in OWL).\nTwo elements will be compared w.r.t values associated to each property considered. To this end, for each property considered, a specific measure will be used to compare associated values (concepts, data values, instances).\nProperties which link two instances associate a set of instances to the instance which is characterised. Considering Figure 3.2 page 43, the property genre can be used to characterise the instance rollingStones through a set of instances {i|\u2203(rollingStones, genre, i)}, i.e., {rock, ...}. Such properties therefore refer to sets, they are often compared using simple set-based measures \u2013 they will for example evaluate the cardinality of the intersection (e.g., the number of music genres that two bands have in common).\nTaxonomic properties are evaluated using semantic measures adapted to concept comparison. These measures will be presented in Section 3.4.\nProperties associated to data values can be compared using measures adapted to the type of data considered, e.g., a measure for comparing dates if the corresponding property refers to a date.\nFinally, the scores produced by the various measures (associated to the various properties) are aggregated in order to obtain a global score of relatedness of the two elements (Euzenat and Shvaiko, 2013). Such a representation has been formalised in the framework proposed by Ehrig et al. (2004). This is a strategy which is commonly adopted in ontology alignment, instance matching or link discovery between instances; SemMF (Oldakowski and Bizer, 2005), SERIMI (Araujo et al., 2011) and SILK (Volz et al., 2009) are all based on this approach. The reader can also refers to the extensive survey presented in (Euzenat and Shvaiko, 2013).\nConsideration of indirect properties of elements Several contributions underline the relevance of indirect properties in comparing entities represented through graphs, especially in object models (Bisson, 1995). Referring to Figure 3.2 (page 43), indirect properties might be used to consider properties of music genres (e.g., rock, rockNroll) to compare two music bands (e.g., rollingStones - doors).\nThis approach relies on a representation of the compared elements which is an extension of the canonical form used to represent an element as a list of properties. This approach can be implemented to take into account the indirect properties of compared elements, e.g., properties induced by the elements associated to the element that we want to characterise.\nAlbertoni and De Martino (2006) extended the formal framework proposed in Ehrig et al. (2004) to allow for the consideration of some indirect properties. This framework is dedicated to instance comparison. It formally defines an indirect property of an instance along a path in the graph. The indirect properties to be taken into account depend on the context of use of the framework, e.g., application context.\nFrom a different perspective, Andrejko and Bielikova\u0301 (2013) suggested an unsupervised approach to compare two instances by considering their indirect properties. Each direct property which is shared between the compared instances plays a role in computing the global relatedness. When the property links two instances, a recursive process is applied to take into account properties of associated instances with the instances being processed. Lastly, the measure aggregates the scores obtained during the recursive process. The authors have also proposed to weigh the contribution of the various properties in the aggregation so as to define a personalised information retrieval approach.\nIn (Harispe et al., 2013a) the authors also proposed an approach enabling more expressive formulations of measures to compare entities based on the analysis of direct and indirect properties. This approach enables to define aggregations of properties in order to consider new properties during the comparison of entities, e.g. it is impossible to evaluate an instance of a class Person whose weight and size have been specified through his body mass index (which can be computed from the weight and size alone).\nAll the measures which can be used on the whole semantic graph G can also be used for any reduction GR\u2032 \u2286 G; the reduction GR\u2032 is the subgraph of G built only considering the relationships of G that are of specific types defined into R\u2032 \u2282 R, with R the set of types of relationships of G. As an example,"}, {"heading": "50 CHAPTER 3. KNOWLEDGE-BASED SEMANTIC MEASURES", "text": "the taxonomy GT is the reduction GR\u2032 \u2286 G obtained defining R\u2032 = {subClassOf}.14 Depending on the types of relationships that are considered, i.e. R\u2032, a large number of reductions can be obtained. Some of them have the interesting property to be acyclic. Depending on the topological properties of the reduction, two cases can be distinguished:\n1. The reduction GR\u2032 leads to a cyclic graph. Measures presented for cyclic graphs can be used.\n2. GR\u2032 is acyclic \u2013 particular techniques and algorithms can be used. Most semantic measures defined for acyclic graphs focus on taxonomic relationships defined in GR\u2032 and consider the reduction to be the taxonomy of concepts GT . However, some measures consider a specific subset of R\n\u2032, e.g., R\u2032 = {isA, partOf}, which also produces an acyclic graph (Wang et al., 2007). The measures which can be used in this case are usually a generalisation of semantic similarity measures designed for GT ."}, {"heading": "3.2.2 Semantic measures on acyclic graphs", "text": "Semantic measures applied to graph-based ontologies were originally designed for taxonomies. Since most ontologies are usually composed mainly of taxonomic relationships or represent poset structures, substantial literature is dedicated to semantic similarity measures15. In particular, a large diversity of semantic measures focus on GT and have been defined for the comparison of pairs of concepts. These measures are presented in details in Section 3.4."}, {"heading": "3.3 Semantic evidence in semantic graphs and their interpreta-", "text": "tions\nA semantic graph carries explicit semantics, e.g. through the taxonomy defining concepts partial ordering. It also contains implicit semantic evidence. According to Section 1.3.1 page (15), we consider semantic evidence as any information on which interpretations can be based according to the meaning carried by the ontology or the elements it defines (concepts, instances, relationships).\nSemantic evidence derives from the study of specific factors (e.g., number of concepts, depth of a concepts, average number of relationships associated to a concept) which can be used to discuss particular properties of the semantic graph (e.g., coverage, expressiveness) or particular properties of its elements (e.g. specificity of concepts). The acquisition of semantic evidence is generally made using the following process. Based on the analysis of specific factors using particular metrics, some properties of both the semantic graph and the elements it defines can be obtained. Based on these properties, and either based on high assumptions or theoretically justified by the core semantics on which relies the ontology, semantic evidence can be obtained. As an example of semantic evidence, the number of concepts described in a taxonomy can be interpreted as a clue on the degree of coverage of the ontology. One can also consider that the deeper a concept w.r.t the depth of GT , the more specific the concept.\nAs we will see, several properties are used to consider extra semantics from semantic graphs; they are especially important for the design of semantic measures. Indeed, semantic evidence is core elements of measures; it has been used for instance to: (i) normalise measures, (ii) estimate the specificity of concepts and to (iii) weigh the relationships defined in the graph, i.e., to estimate the strength of connotation between concept/instances. It is therefore central for both designers and users of semantic measures to know: (i) the properties which can be used to derive semantic evidence, (ii) how it is computed, and (iii) the assumptions on which its interpretation relies.\nMost of the properties used to derive semantic evidence are well-known graph properties defined by graph theory. In this section, we only introduce the main properties which are based on the study of a taxonomy of concepts (GT ). We go on to introduce two applications of these properties: the estimation of the specificity of concepts and the estimation of the strength of connotation between concepts."}, {"heading": "3.3.1 Semantic evidence in taxonomies", "text": "Semantic evidence used to process more general semantic graphs are adaptations of the graph properties commonly used to assess the similarity of nodes of a taxonomy. The interested reader can refer\n14In the Figure 3.2, page 43, subClassOf relationships are in red color and the taxonomic reduction GT = GR\u2032 \u2286 G obtained defining R\u2032 = {subClassOf} thus corresponds the graph shown onto the layer C.\n15According to the literature we consider that semantic measures on GT are necessarily semantic similarity measure."}, {"heading": "3.3. SEMANTIC EVIDENCE IN SEMANTIC GRAPHS AND THEIR INTERPRETATIONS 51", "text": "to the numerous contributions proposed by the graph theory community. In this section we mainly focus on semantic evidence commonly exploited in taxonomies. Two kinds of semantic evidence can be distinguished:\n\u2022 Intentional evidence which can also be called intrinsic evidence, which is based on the analysis of properties associated to the topology of GT .\n\u2022 Extensional evidence which is based on the analysis of both the topology of GT and the distribution of concepts\u2019 usage, i.e., the number of instances associated to concepts.\nNotice that we don\u2019t consider semantic evidence purely extensional, i.e., only based on concepts\u2019 usage, without taking the taxonomy into account. Indeed, in most cases, the distribution of concepts\u2019 usage must be evaluated considering the transitivity of the taxonomic relationship. If this is not the case, incoherent results could be obtained, As an example, if the transitivity of the taxonomic relationship is not considered to propagate the usage of concepts (instance membership), the distribution of instances can be incoherent w.r.t the partial order defined by the taxonomy, i.e., a concept can have more instances than one of its ancestors.\nWe further distinguish the evidence which is based on global properties (i.e., derived from the full taxonomy), from that based on local properties of concepts.\nIntentional evidence\nGlobal properties\n\u2022 Depth of the taxonomy \u2013 maximal number of ancestors of a concept\nThe depth of the taxonomy corresponds to the maximal depth of a concept in GT . It informs on the degree of expressiveness/granularity of the taxonomy. As an example, the deeper GT , the more detailed the taxonomy is expected to be.\nThe maximal number of ancestors of a concept is also used as an estimator of the upper bound of the degree of expressiveness of a concept. Inversely, the number of concepts defined in GT , i.e., |D(>)| if > exists, can also be used as an upper bound of the degree of generality of a concept.\n\u2022 Diameter \u2013 width of the taxonomy\nThe width of the taxonomy corresponds to the length of the longest shortest path which links two concepts in GT .\n16 It also informs on the degree of coverage of the taxonomy. GT is generally assumed to better cover a domain the bigger its diameter. The rational of this assumption is that bigger is the diameter, the higher the maximal number of concepts separating two concepts and therefore the higher is the likelihood that meaningful concepts of the domain have been expressed into the ontology.\nLocal properties\n\u2022 Local density\nIt can be considered that relationships in dense parts of a taxonomy represent smaller taxonomic distances. Metrics such as compactness can be used to characterise local density (Botafogo et al., 1992)17. Other metrics such as the (in/out)-branching factor of a concept (|C+(u)|, |C\u2212(u)|), the number of neighbours of a given concept (|C(u)|), can also be used (Sussna, 1993). It is generally assumed that the higher the number of neighbours of a concept, the more general it is.\n\u2022 Number of ancestors \u2013 depth \u2013 number of descendants \u2013 number of subsumed leaves \u2013 distance to leaves.\n16Backtracks, loops or detours excluded, ref: http://mathworld.wolfram.com/GraphDiameter.html 17Author also introduces interesting factors for graph-based analysis; the depth of a node is also introduced."}, {"heading": "52 CHAPTER 3. KNOWLEDGE-BASED SEMANTIC MEASURES", "text": "The number of ancestors of a concept is often considered to be directly proportional to its degree of expressiveness. The more a concept is subsumed, the more detailed/restrictive the concept is expected to be. The number of ancestors can also be interpreted w.r.t the maximal number of ancestors a concept of the taxonomy can have. The depth of a concept is also expected to be directly proportional to its degree of expressiveness. The deeper the concept (according to the maximal depth), the more detailed/restrictive the concept is regarded18. A local depth of a concept can also be evaluated according to the depth of the branch in which it is defined.\nIn a similar fashion, in some cases the distance of a concept to the leaves it subsumes, or the number of leaves it subsumes, will be considered as an estimator of expressiveness: the greater the distance/number the less expressive the concept is considered.\nExtensional evidence\nGlobal properties\n\u2022 Distribution of instances among the concepts.\nThe distribution of instances among concepts, i.e., concept usage, can be used to design local correction factors, e.g., to correct estimations of the expressiveness of a concept. This is generally made by evaluating the balance of the distribution.\nLocal properties\n\u2022 Number of instances associated to a concept\nThe number of instances of a concept is expected to be inversely proportional to its expressiveness, the less instances a concept has, the more specific it is expected to be.\nThis semantic evidence and its interpretations have been used to characterise notions extensively used by semantic measures. They are indeed used to estimate the specificity of concepts as well as the strength of connotations between concepts. These two notions are introduced in detail in the following subsections."}, {"heading": "3.3.2 Concept specificity", "text": "Not all concepts have the same degree of specificity. Indeed, most people will agree that Dog is a more specific description of a LivingBeing than Animal. The notion of specificity can be associated to the concept of salience which has been defined by Tversky (1977) to characterise a stimulus according to its \u201cintensity, frequency, familiarity, good form, and informational content\u201d. In Bell et al. (1988), it is also specified that \u201csalience is a joint function of intensity and what Tversky calls diagnosticity, which is related to the variability of a feature in a particular set [i.e., universe, collection of instances]\u201d. The idea is to capture the amount of information carried by a concept \u2013 this amount is expected to be directly proportional to its degree of specificity and generality.\nThe notion of specificity of a concept is not totally artificial and can be explained by the roots of taxonomies. Indeed, the transitivity of the taxonomic relationship specifies that not all concepts have the same degree of specificity or detail. In knowledge modelling, the ordering of two concepts u \u227a v defines that u must be considered as more abstract (less specific) than v. In fact, the taxonomy explicitly defines that all instances of u are also instances of v. This expression is illustrated by Figure 3.3; we can see that the more a concept is subsumed by numerous concepts: (A) the number of properties which characterise the concept increases (intentional interpretation), and (B) its number of instances decreases (extensional interpretation).\nTherefore, another way of comparing the specificity of concepts defined in a total order19 is to study their usage, analysing their respective number of instances. The concept which contains the highest\n18Note that the depth of a concept as an estimator of its degree of expressiveness can be seen as an inverse function of the notion of status introduced by Harary et al. (1965) for organisation study.\n19For any pair of concepts u, v either u v or v u."}, {"heading": "3.3. SEMANTIC EVIDENCE IN SEMANTIC GRAPHS AND THEIR INTERPRETATIONS 53", "text": "number of instances will be the least specific (its universe of interpretation is larger). In this case, it is therefore possible to assess the specificity of ordered concepts either by studying the topology of the graph, or the set of instances associated to them.\nNevertheless, in taxonomies, concepts are generally only partially ordered. This implies that presented evidence used to compare the specificity of two ordered concepts cannot be used without assumptions, i.e., concepts which are not ordered are in some sense not comparable. This aspect is underlined in Figure 3.4. It is impossible to compare, in an exact manner, the specificity of two non-ordered concepts. This is due to the fact that the amount of shared and distinct properties between these concepts can only be estimated w.r.t the properties which characterise the common concepts they derive from, i.e., their Non Comparable Common Ancestors (NCCAs). However, this estimation can only be a lower bound of their commonality since extra properties shared by the two concepts may not be carried by such NCCAs.\nAs we will see, the estimation of the degree of specificity of concepts is of major importance in the design of semantic measures. Therefore, given that discrete levels of concept specificity are not explicitly expressed in a taxonomy, various approaches and functions have been explored to evaluate concept specificity. We denote such a function as \u03b8:\n\u03b8 : C \u2192 R+ (3.4)"}, {"heading": "54 CHAPTER 3. KNOWLEDGE-BASED SEMANTIC MEASURES", "text": "The function \u03b8 may rely on the intrinsic and/or extrinsic properties presented above. It must be in agreement with the taxonomic representation which defines that concepts are always semantically broader than their specialisations20. Thus, \u03b8 must monotonically decrease from the leaves (concepts without descendants) to the root(s) of the taxonomy:\nx y \u21d2 \u03b8(x) \u2265 \u03b8(y) (3.5)\nWe present examples of \u03b8 functions which have been defined in the literature.\nBasic intrinsic estimators of concept specificity\nThe specificity of concepts can be estimated considering the location of its corresponding node in the graph. A naive approach will define the specificity of the concept c, \u03b8(c), as a function of some simple properties related to c, e.g., \u03b8(c) = f(depth(c)), \u03b8(c) = f(A(c)) or \u03b8(c) = f(D(c)) with A(c) and D(c) the ancestors and descendants of c.\nThe main drawback of simple specificity estimators is that concepts with a similar depth or an equal number of ancestors/descendants will have similar specificities, which is a heavy assumption. In fact, two concepts can be described with various degrees of detail, independently of their depth, e.g., (Yu et al., 2007a). More refined \u03b8 functions have been proposed to address this limitation.\nExtrinsic information content\nAnother strategy explored by designers of semantic measures has been to characterise the specificity of concepts according to Shannon\u2019s Information Theory. The specificity of a concept will further be regarded as the amount of information the concept conveys, its Information Content (IC). The IC of a concept can for example be estimated as a function of the size of the universe of interpretations associated to it (i.e. instances). The IC is a common expression of \u03b8 and was originally defined by Resnik (1995) to assess the informativeness of concepts from a corpus of texts.\nThe IC of the concept c is defined as inversely proportional to p(c), the probability to encounter an instance of c in a collection of instances (negative entropy). The original IC definition was based on the number of occurrences of a concept in a corpus of texts.\nWe denote eIC any IC which relies on extrinsic information, i.e., information not provided by the ontology21. They are based on the analysis of concept usage in a corpus of texts or on the analysis of a collection of instances for which associated concepts are known22. We consider the formulation of eIC originally defined by Resnik (1995):\np(c) = |I(c)| |I|\nwith I(c) the set of instances of c, e.g., occurrences of c in a corpus, instances in an ontology {i|{i, \u3008isA, subClassOf\u2217\u3009, c} 6= \u2205}.\neICResnik(c) = \u2212log(p(c)) (3.6) = log(|I|)\u2212 log(|I(c)|)\nThe suitability of the log function can be supported by the work of Shepard (1987)23. Notice also the link with Inverse Document Frequency (IDF) which is commonly used in information retrieval (Jones, 1972):\nIDF (c) = log( |I| |I(c)| ) (3.7)\n= log(|I|)\u2212 log(|I(c)|) = IC(c)\n20This explains that the specificity of concepts cannot be estimated only considering extrinsic information. 21Note that if the instances are represented in the graph, some eIC are indeed iIC. 22As an example, usage of concepts defined in the Gene Ontology can be known studying gene annotations which provide genes and associated Gene Ontology concepts, e.g. refer to UniprotKB. 23Shepard derived his universal law of stimulus generalisation based on the consideration that logarithm functions are suited to approximate semantic distance (Al-Mubaid and Nguyen, 2006)."}, {"heading": "3.3. SEMANTIC EVIDENCE IN SEMANTIC GRAPHS AND THEIR INTERPRETATIONS 55", "text": "The main drawback of \u03b8 functions based on extrinsic information lies in their tight dependence on concepts usage: they will automatically reflect its bias24. Nevertheless, in some cases, the consideration of such bias is desired as all concepts which are highly represented will be considered less informative, even the concepts which seem specific w.r.t intrinsic factors (e.g., depth of concepts). However, in some cases, bias in concept usage can badly affect IC estimation and may not be adapted. In addition, IC computation based on text analysis can be both time consuming and challenging given that, in order to be accurate, complex disambiguation techniques have to be used to detect which concept occurs in texts or knowledge bases.\nIntrinsic information content\nIn order to avoid the dependency of eIC calculus to concept usage, various intrinsic IC formulations (iIC ) have been proposed. They can be used to define \u03b8 functions by only considering structural information extracted from the ontology, e.g., the intrinsic factors presented in Section 3.3.1. iIC formulations extend basic specificity estimators presented above.\nMultiple topological characteristics can be used to express iIC, e.g., number of descendants, ancestors, depths, etc. (Seco et al., 2004; Schickel-Zuber and Faltings, 2007; Zhou et al., 2008; Sa\u0301nchez et al., 2011). As an example, the formulation proposed by Zhou et al. (2008) enables to consider the contribution of both the depth and the number of descendants of a concept to compute its specificity:\niICZhou(c) = k\n( 1\u2212 log(|D(c)|)\nlog(|C|)\n) + (1\u2212 k) log(depth(c))\nlog(depth(GT )) (3.8)\nwith |C| the number of concepts defined in the taxonomy,D(c) the descendants of c, depth(c) its depth, depth(GT ) the maximal depth of a concept in GT and k \u2208 [0, 1] a parameter used to set the contribution of both components (originally set to 0.6).\nIn (Sa\u0301nchez et al., 2011), the iIC incorporates additional semantic evidence in the aim of better distinguishing the concepts with the same numbers of descendants but different degrees of concreteness \u2013 here captured as a function of the number of ancestors a concept has.\niICSanchez(c) = \u2212log\n  |leaves\u2212(c)| |A(c)| + 1\n|leaves|+ 1\n  (3.9)\nWe denote leaves\u2212(c) the exclusive set of leaves of the concept c, i.e., if c is a leaf leaves\u2212(c) = \u2205. Note that iICSanchez will set the same iIC for each leaf. To avoid this, we propose the following modification:\niICSanchez\u2032(c) = \u2212log\n  |leaves(c)| |A(c)|\n|leaves|+ 1\n  (3.10)\niICs are of particular interest as only the topology of the taxonomy is considered. They prevent errors related to bias on concept usage. However, the relevance of iIC relies on the assumption that GT expresses enough knowledge to rigorously evaluate the specificities of concepts. Therefore, as a counterpart, iICs are sensitive to structural bias in the taxonomy and are therefore sensitive to unbalanced taxonomy, degrees of completeness, homogeneity and coverage of the taxonomy (Batet et al., 2010a).\nNon-taxonomic information content\nBoth introduced iIC and eIC only take taxonomic relationships into account. In order to take advantage of all predicates and semantic relationships, Pirro\u0301 and Euzenat (2010a) proposed the extended IC (extIC).\nextIC(c) = \u03b1EIC(c) + \u03b2IC(c) (3.11) EIC(c) = \u2211\nr\u2208R\n\u2211 u\u2208Cr(u) iIC(u)\n|Cr(u)|\nWith Cr(u) the set of concepts linked to the concept c by any relationship of type r \u2208 R (i.e., generalisation of C(u)). In this formula, the contribution of the various relationships of the same predicate\n24As an example, this can be problematic for GO-based studies as some genes are studied and annotated more than others (e.g., drug related genes) and annotation distribution patterns among species reflect abnormal distortions, e.g. human \u2013 mouse (Thomas et al., 2012)."}, {"heading": "56 CHAPTER 3. KNOWLEDGE-BASED SEMANTIC MEASURES", "text": "is averaged. However, the more a concept establishes relationships of different predicates, the higher its EIC will be. We thus propose to average EIC by |R|, or to weigh the contribution of the different predicates.\nList of functions defined to estimate concept specificity\nWe have presented various strategies which can be used to estimate the specificities of concepts defined in a partially ordered set (\u03b8 functions). It is important to understand that these estimators are based on assumptions regarding ontologies. Table 3.1 lists some of the properties of some of the \u03b8 functions proposed in the literature \u2013 proposals are ordered by date. Ex inf. refers to the use of extensional information."}, {"heading": "3.3. SEMANTIC EVIDENCE IN SEMANTIC GRAPHS AND THEIR INTERPRETATIONS 57", "text": "N a m\ne s\n\u2013 R\ne fe\nre n\nc e s\nE x in f\nC o - d o m\na in\nC o m\nm e n ts\nD ep\nth N\no [0\n, 1 ]\nN o rm\na li\nse d\nd ep\nth o r\nm a x\nd ep\nth ca\nn b\ne u\nse d\n. In\na g ra\np h , co n si d er in g th e m in im a l d ep th o f a co n ce p t d o es n \u2019t en su re th a t th e sp ec ifi ci ty in cr ea se s a cc o rd in g to th e p a rt ia l o rd er - in g (d u e to m u lt iin h er it a n ce ).\nIC R\nes n\nik (R\nes n\nik ,\n19 95\n) Y\nes [0 ,+ \u221e\n[ , [0 , 1 ]\nD ep\nen d\no n\nco n\nce p\nt u\nsa g e. I C\n(c )\n= \u2212 lo g (|I\n(c )|/ |I |).\nN o r-\nm a li\nse d\nve rs\nio n\ns h av\ne a ls\no b\nee n\np ro\np o se\nd ,\ne. g .,\n(S h\nee h\na n\net a l.\n, 2 0 0 8 ).\nIC R\nes n\nik in\ntr in\nsi c\n(R es\nn ik\n, 19\n9 5)\nN o\n[0 ,\n1 ]\nR es\nn ik\n\u2019s IC\nw it\nh \u2200c \u2208 C\nth e\nn u\nm b\ner o f\nin st\na n\nce s\na ss\no ci\na te d to c (w it h o u t ta x o n o m ic in fe re n ce s) se t to o n e. IC S ec o (S ec o, 20 05 ) N o [0 , 1 ] IC es ti m a te d fr o m th e n u m b er o f d es ce n d a n ts . D ep th n on -l in ea r (S ec o, 20 05 ) N o [0 , 1 ] U se lo g to in tr o d u ce n o n -l in ea r es ti m a ti o n o f d ep th . T A M (Y u et al ., 20 07 a) Y es [0 ,+ \u221e [ T h e p ro b a b il it y p (c ) a ss o ci a te d to a co n ce p t is co m p u te d a s th e n u m b er o f p a ir s o f in st a n ce s w h ic h a re m em b er s o f c d iv id ed b y to ta l th e n u m b er o f p a ir s. ID F (C h ab al ie r et al ., 20 07 ) Y es [0 ,+ \u221e [ In ve rs e D o cu m en t F re q u en cy (I D F ) o b ta in ed b y d iv id in g th e n u m b er o f in st a n ce s b y th e n u m b er o f in st a n ce s o f th e co n ce p t (J o n es , 1 9 7 2 ), i. e. I D F (c ) = lo g (|I |/ |I (c )|) . A s w e sa w , in S ec ti o n 3 .3 .2 , th is fo rm u la ti o n is si m il a r to IC p ro p o se d b y R es n ik (1 9 9 5 ). A P S (S ch ic ke lZ u b er an d F al ti n gs , 2 00 7) N o [0 ,1 / 2 ] iI C b a se d o n th e n u m b er o f d es ce n d a n ts o f a co n ce p t. IC Z h ou (Z h ou et al ., 20 08 ) N o [0 ,1 ] P a ra m et ri c h y b ri d iI C m ix in g S ec o \u2019s IC a n d n o n li n ea r d ep th . ex tI C (P ir ro\u0301 an d E u - ze n at , 20 10 a) N o [0 , 1 ] iI C b a se d o n a ll p re d ic a te s. IC S an ch ez et al (A ) (S a\u0301n ch ez et al ., 20 11 ) N o [0 ,+ \u221e [ C o n si d er th e n u m b er o f le av es co n ta in ed in D (c ), th e h ig h er it is , th e le ss sp ec ifi c c is co n si d er ed . IC S an ch ez et a l. (B ) (S a\u0301n ch ez et al ., 20 11 ) N o [0 ,+ \u221e [ R efi n ed ve rs io n A (s ee a b ov e) ex p lo it in g D (c ).\nT ab\nle 3.\n1: S\nel ec\nti on\nof \u03b8\nfu n\nct io\nn s\nw h\nic h\nca n\nb e\nu se\nd to\nes ti\nm a te\nth e\nsp ec\nifi ci\nty o f\na co\nn ce\np t\nd efi\nn ed\nin a\nta x o n\no m\ny."}, {"heading": "58 CHAPTER 3. KNOWLEDGE-BASED SEMANTIC MEASURES", "text": ""}, {"heading": "3.3.3 Strength of connotations between concepts", "text": "A notion strongly linked to concept specificity is the strength of connotation between a pair of concepts/instances, i.e., the strength of the relationship(s) which links two concepts/instances. Otherwise stated, this notion can be used to assess the strength of interaction associated to a specific relationship.\nConsidering taxonomic relationships, it is generally considered that the strength of connotation between concepts is stronger the deeper two concepts are in the taxonomy. As an example, the taxonomic relationship linking concepts SiberianTiger and Tiger will generally be considered to be stronger than the one linking the concepts Animal and LivingBeing. Such a notion is quite intuitive and has for instance been studied by Quillian and Collins in the early studies of semantic networks (Collins and Quillian, 1969) \u2013 hierarchical network models were built according to response time to questions, i.e., mental activations evaluated w.r.t the time people took to correctly answer questions related to two concepts, e.g., a Canary is an Animal \u2013 a Canary is a Bird \u2013 a Canary is a Canary. Based on the variation of times taken to correctly answer questions involving two ordered concepts (e.g., Canary \u2013 Animal), the authors highlighted human sensibility to non-uniform strength of connotation and its link to concept specificity.\nIt is worth noting that the estimation of the strength of connotation of two linked concepts is in some sort a measure of the semantic similarity or taxonomic distance between two directly ordered concepts. The models used to estimate the strength of connotation between two concepts are generally based on the assumption that the taxonomic distance associated to a taxonomic relationship shrinks with the depth of the two concepts it links (Richardson et al., 1994). Given that the strength of connotation between concepts is not explicitly expressed in a taxonomy, it has been suggested that several intrinsic factors need considering in order to refine its estimation, e.g., (Richardson et al., 1994; Young Whan and Kim, 1990; Sussna, 1993).\nA taxonomy only explicitly defines the partial ordering of its concepts, which means that if a concept v subsumes another concept u, all the instances of u are also instances of v, i.e., u v \u21d2 I(u) \u2286 I(v). Nevertheless, non-uniform strength of connotation aim to consider that all taxonomic relationships do not convey the same semantics.\nStrictly speaking, taxonomic relationships only define concept ordering and concept inclusion. Therefore, according to the extensional interpretation which can be made of a taxonomy, the size of the universe of interpretation of a concept, i.e., the size of the set of its possible instances w.r.t the whole set of instances, must reduce the more a concept is specialised25. This reduction of the universe of eligible interpretations associated to a concept (i.e. instances), corresponds to a specific understanding of the semantics of non-uniform strengths of connotation. Alternative explanations which convey the same semantics can also be expressed according to the insights of the various cognitive models which have been introduced in Section 1.2.1:\n\u2022 Spatial/Geometric model: it states that the distance between concepts is a non-linear function which must take salience of concept into account.\n\u2022 Feature model (which represents a concept as a set of properties): It can be seen as the difficulty to further distinguish a concept which is relevant to characterise the set of instances of a domain.\n\u2022 Alignment and Transformational models: the effort of specialisation which must be done to extend a concept increases the more a concept has been specialised.\nAll these interpretations state the same central notion \u2013 the strength of connotation which links two concepts is a function of two factors: (i) the specificities of the linked concepts, and (ii) the variation of these specificities. The semantic evidence introduced in the previous section, as well as the notion of IC, can be used to assess the strength of connotation of two concepts.\nAs an example, the strength of connotation w which characterises a taxonomic relationship linking two concepts u, v, with u v, can be defined as a function of the ICs of u and v (Jiang and Conrath, 1997): w(u, v) = IC(u)\u2212 IC(v).\nIt is important to stress that estimations of the strength of connotations based on the density of concepts, the branching factor, the maximal depth or the width of the taxonomy, are based on assumptions regarding the definition of the ontology.\nWe have presented various semantic evidence which can be used to extract knowledge from an ontology represented as a semantic graph. We have also presented two applications of such semantic evidence for\n25We here consider a finite universe."}, {"heading": "3.4. SEMANTIC SIMILARITY BETWEEN A PAIR OF CONCEPTS 59", "text": "assessing the specificity of a concept defined in a taxonomy and the strength of interaction between two elements defined in a semantic graph. As we will see, semantic evidence are central for the definition of semantic measures. We will now introduce semantic measures which can used to compare pairs of concepts and pairs of groups of concepts."}, {"heading": "3.4 Semantic similarity between a pair of concepts", "text": "The majority of semantic measures framed in the relational setting have been proposed to assess the semantic similarity or taxonomic distance of a pair of concepts defined in a taxonomy. Given that they are designed to compare two concepts, these measures are denoted as pairwise measures in some communities, e.g., bioinformatics (Pesquita et al., 2009a). As we will see, extensive literature is dedicated to these measures \u2013 they can be used to compare any pairs of nodes expressed in a graph which defines a (partial) ordering, that is to say, any graph structured by relationships which are transitive, reflexive and antisymmetric (e.g., isA, partOf).\nThe main approaches used to compare concepts defined in a taxonomy are:\n\u2022 Measures based on graph structure analysis. They estimate the similarity as a function of the degree of interconnection between concepts. They are generally regarded as measures which are framed in the spatial model \u2013 the similarity of two concepts is estimated as a function of their distance in the graph, e.g., based on the analysis of the lengths of the paths which link the concepts. These measures can also be considered as being framed in the transformational model by considering them as functions which estimate the similarity of two concepts regarding the difficulty to transform one concept into another.\n\u2022 Measures based on concept features analysis. This approach extracts features of concepts from the graph. These features will be subsequently analysed to estimate the similarity as a function of shared and distinct features of the compared concepts. This approach is conceptually framed in the feature model. The diversity of feature-based measures relies on the diversity of strategies which have been proposed to characterise concept features, and to take advantage of them in order to assess the similarity.\n\u2022 Measures based on Information Theory. Based on a function used to estimate the amount of information carried by a concept, i.e., its Information Content (IC), these measures assess the similarity w.r.t the amount of information which is shared and distinct between compared concepts. This approach is framed in information theory. However, in some cases, it can be seen as a derivative of the feature-based approach in which features are not compared using a boolean featurematching evaluation (shared/not shared), but also incorporate their saliency, i.e. their degree of informativeness.\n\u2022 Hybrid measures. Measures which are based on multiple paradigms.\nThe broad classification of measures that we propose is interesting as an introduction to basic approaches defined to assess the similarity of two concepts \u2013 and to put them in perspective with the models of similarity proposed by cognitive sciences. It is however challenging to constrain the diversity of measures to this broad classification. It is important to understand that these four main approaches are highly interlinked and cannot be seen as disjoint categories. As an example, all measures rely in some sense on the analysis of the structure of the taxonomy, i.e., they all take advantage of the partial ordering defined by the (structure of the) taxonomy. These categories must be seen as devices used by designers of semantic measures to introduce approaches and to highlight relationships between several proposals. Indeed, as we will see, numerous approaches can be regarded as hybrid measures which take advantage of techniques and paradigms used to characterise measures of a specific approach. Therefore, the affiliation of a specific measure to a particular category is often subject to debate, e.g., as it is exposed in (Batet, 2011). This can be partially explained by the fact that several measures can be redefined or approximated using reformulations, in a way that further challenge the classification. Indeed, the more you analyse semantic measures, the harder it is to restrict them to specific boxes; the analogy can be made with the relationship between cognitive models of similarity26.\n26Refer to dedicated Section 1.2.1 and more particularly to efforts made for the unification of the various models."}, {"heading": "60 CHAPTER 3. KNOWLEDGE-BASED SEMANTIC MEASURES", "text": "Several classifications of measures have been proposed. The most common one is to distinguish measures according to the elements of the graph that they take into account (Pesquita et al., 2009a). This classification distinguishes three approaches: (i) edge-based \u2013 measures focusing on relationship analysis, (ii) node-based \u2013 measures based on node analysis, and (iii) hybrid measures \u2013 measures which mix both approaches. In the literature, edge-based measures often refer to structural measures, nodebased measures refer to measures framed in the feature-model and those based on information theory. Hybrid measures are those which implicitly or explicitly mix several paradigms.\nAnother interesting way to classify measures is to study whether they are (i) intentional, i.e., based on the explicit definition of the concepts expressed by the taxonomy, (ii) extensional, i.e., based on the analysis of the realisations of the concepts (i.e., instances), or (iii) hybrid, measures which mix both intentional and extensional information about concepts. Refer to (Gandon et al., 2005; Aime\u0301, 2011)27 for examples of such classifications. In some cases, authors will mix several types of classifications to present measures. In this section, we will introduce the measures according to the four approaches presented above: (i) structural, (ii) feature-based, (iii) framed in information theory, and (iv) hybrid. We will also specify the extensional, intentional, or hybrid nature of the measures.\nNumerous concept-to-concept measures have been defined for trees, i.e. special taxonomies which correspond to graphs without multiple inheritances. In the literature, these measures are generally considered to be applied as it is on taxonomies (which are DAGs). However, in DAGs, some adaptations deserve to be made and several components of measures generally need to be redefined in order to avoid ambiguity, e.g., to be implemented on computer software. For the sake of clarity, we first highlight the diversity of proposals by introducing the most representative measures defined according to the different approaches. In most cases, measures will be presented according to their original definitions. When the measures have been defined for trees, we will not necessarily stress the modifications which must be taken into account for them to be used on DAGs. These modifications will be discussed after the introduction of the diversity of measures. For convenience, subClassOf relationships will be denoted isa \u2013 there is no ambiguity with isA since GT only contains concepts."}, {"heading": "3.4.1 Structural approach", "text": "Structural measures rely on graph-traversal approaches presented in Section 3.2.1 (e.g., shortest path techniques, random walk approaches). They focus on the analysis of the interconnection between concepts to estimate their similarity. However, most of the time, they consider specific tuning in order to take into account specific properties and interpretations induced by the transitivity of the taxonomic relationships. In this context, some authors, e.g., (Hliaoutakis, 2005), have linked this approach to the spreading activation theory (Collins and Loftus, 1975). The similarity is in this case seen as a function of propagation between concepts through the graph.\nBack in the eighties, Rada et al. (1989) expressed the taxonomic distance of two concepts defined in a taxonomic tree as a function of the shortest path linking them28. We denote sp(u, isa\u2217, v) the shortest path between two concepts u and v, i.e., the path of minimal length in {u, isa\u2217, v}. Remember that the length of a path has been defined as the sum of the weights associated to the edges which compose the path. When the edges are not weighted we refer to the edge-counting strategy \u2013 the length of the shortest path is the number of edges it contains. The taxonomic distance is therefore defined by29:\ndistRada(u, v) = sp(u, isa \u2217, v) (3.12)\nDistance-to-similarity conversions can also be applied to express a similarity from a distance. A semantic similarity can therefore be defined in a straightforward manner:\nsimRada(u, v) = 1\ndistRada(u, v) + 1 (3.13)\nNotice the importance of considering the transitive reduction of the tree/graph to obtain coherent results using measures based on the shortest path. In the following presentation, we consider that the\n27In french. 28It is worth noting that they didn\u2019t invent the notion of shortest path in a graph. In addition, in Foo et al. (1992), the authors refer to a measure proposed by Gardner et al. (1987) to compare concepts defined in a conceptual graph using the shortest path technique.\n29In this chapter, equations named dist refer to taxonomic distances."}, {"heading": "3.4. SEMANTIC SIMILARITY BETWEEN A PAIR OF CONCEPTS 61", "text": "taxonomy GT doesn\u2019t contain redundant relationships (here redundancies refer to relationships which can be inferred due to the transitivity of taxonomic relationships).\nIn a tree, the shortest path sp(u, isa\u2217, v) contains a unique common ancestor of u and v. This common ancestor is the Least Common Ancestor (LCA)30 of the two concepts according to any function \u03b8 (since the \u03b8 function is monotonically decreasing)31. Therefore, in trees, we obtain distRada(u, v) = sp(u, isa, LCA(u, v)) + sp(v, isa, LCA(u, v)).\nSeveral issues with the shortest path techniques have been formulated. The edge-counting strategy, or more generally any shortest path approach with uniform edge weight, has been criticised for the fact that the distance represented by an edge linking two concepts does not take concept specificities/salience into account32. Several modifications have therefore been proposed to break this constraining uniform appreciation of edges. Implicit or explicit models defining non-uniform strength of connotation between concepts have therefore been introduced e.g., (Young Whan and Kim, 1990; Sussna, 1993; Richardson et al., 1994).\nOne of the main challenges of designers of semantic measures over the years has therefore been to refine measures by taking advantage of semantic evidence related to concept specificity and the strength of connotation between concepts. The different strategies and factors used to appreciate concept specificity as well as strength of connotations have already been introduced in Section 3.3. Another use of the various semantic evidence which can be extracted from GT has been to normalise the measures. As an example, Resnik (1995) suggested considering the maximal depth of the taxonomy to bound the edge-counting strategy:\nsimResnik\u2212eb(u, v) = 2 \u00b7 depth(GT )\u2212 sp(u, isa, LCA(u, v))\u2212 sp(v, isa, LCA(u, v)) (3.14)\nTo simulate non uniform edge weighing, Leacock and Chodorow (1998)33 introduced a logarithmic transformation of the edge counting strategy:\nsimLC(u, v) = \u2212log (\nN\n2 \u00b7 depth(GT )\n) = log(2 \u00b7 depth(GT ))\u2212 log(N) (3.15)\nwithN the cardinality of the union of the sets of nodes involved in the shortest paths sp(u, isa, LCA(u, v)) and sp(v, isa, LCA(u, v)).\nAuthors have also proposed taking into account the specificity of compared concepts, e.g., (Mao and Chu, 2002), sometimes as a function of the depth of their LCA, e.g.,(Wu and Palmer, 1994; Pekar and Staab, 2002; Wang et al., 2012b). As an example, Wu and Palmer (1994) proposed expressing the similarity of two concepts as a ratio taking into account the shortest path linking the concepts as well as the depth of their LCA.\nsimWP (u, v) = 2 \u00b7 depth(LCA(u, v))\n2 \u00b7 depth(LCA(u, v)) + sp(u, isa, LCA(u, v)) + sp(v, isa, LCA(u, v)) (3.16)\nThis function is of the form:\nf(x, y, z) = x\n(x+ (y + z)/2)\nwith x the depth of the LCA of the two concepts u, v and y + z the length of the shortest path linking u, v. It is easy to see that for any given non-null length of the shortest path, this function increases with x; otherwise stated, to a given shortest path length, simWP (u, v) increases with the depth of LCA(u, v). In addition, as expected, for a given depth of the LCA, the longer the shortest path which links u, v, less similar they will be considered.\nBased on a specific expression of the notion of depth, a parametrised expression of simWP has been proposed in Wang and Hirst (2011). A variation was also proposed by Pekar and Staab (2002):\nsimPS(u, v) = depth(LCA(u, v))\nsp(u, isa, LCA(u, v)) + sp(v, isa, LCA(u, v)) + depth(LCA(u, v)) (3.17)\n30The Least Common Ancestor is also denoted as the Last Common Ancestor (LCA), the Most Specific Common Ancestor (MSCA), the Least Common Subsumer/Superconcept (LCS) or Lowest SUPER-ordinate (LSuper) in the literature.\n31Here relies the importance of applying the transitive reduction of the taxonomic graph/tree, redundant taxonomic relationships can challenge this statement and therefore heavily impact the semantics of the results.\n32As an example, Foo et al. (1992) quotes remarks made in Sowa personal communication. 33Note that according to Resnik (1995), this approach was already proposed in an 1994 unpublished paper by the same\nauthors (Leacock and Chodorow, 1994)."}, {"heading": "62 CHAPTER 3. KNOWLEDGE-BASED SEMANTIC MEASURES", "text": "Zhong et al. (2002) also proposed comparing concepts taking into account the notion of depth:\ndistZhong(u, v) = 2 \u00b7 1 2kdepth(LCA(u,v)) \u2212 1 2kdepth(u) \u2212 1 2kdepth(v) (3.18)\nwith k > 1 a factor defining the contribution of the depth. In a similar fashion, Li et al. (2003, 2006) defined a parametric function in which both the length of the shortest path and the depth of the LCA are taken into account:\nsimLB(u, v) = e \u2212\u03b1distRada(u,v) \u00d7 df(u, v) (3.19)\nwith,\ndf(u, v) = e\u03b2h \u2212 e\u2212\u03b2h e\u03b2h + e\u2212\u03b2h\nThe parameter h corresponds to the depth of the LCA of the compared concepts, i.e. h = depth(LCA(u, v)). The parameter \u03b2 > 0 is used to tune the depth factor (df) and to set the importance given to the degree of specificity of concepts. The function used to express df corresponds to the hyperbolic tangent which is normalised between 0 and 1. It defines the degree of non-linearity to associate to the depth of the LCA. In addition, \u03b1 \u2265 0 controls the importance of the taxonomic distance expressed as a function of the length of the shortest path linking the two concepts.\nApproaches have also been proposed to modify existing measures in order to obtain particular properties. As an example, Slimani et al. (2006) proposed an adaptation of the measure proposed by Wu and Palmer (1994) (Equation 3.16) in order to avoid the fact that, in some cases, neighbour concepts can be estimated as more similar than ordered concepts. To this end, the authors introduced simtbk which is based on a factor used to penalise concepts defined in the neighbourhood:\nsimtbk(u, v) = simWP (u, v)\u00d7 pf(u, v) (3.20)\nwith,\npf(u, v) = (1\u2212 \u03bb)(min(depth(u), depth(v))\u2212 depth(GT )) + \u03bb(depth(u) + depth(v) + 1)\u22121\nIn the same vein (Ganesan et al., 2012; Shenoy et al., 2012) recently proposed alternative measures answering the same problem. The approach proposed by Shenoy et al. (2012) is presented34:\nsimShenoy(u, v) = 2 \u00b7 depth(GT ) \u00b7 e\u2212\u03bbL/depth(GT )\ndepth(u) + depth(v) (3.21)\nwith L the weight of the shortest path computed by penalising paths with multiple changes of type of relationships, e.g. a path following the pattern \u3008isa, isa\u2212, isa, . . .\u3009. Note that the penalisation of paths inducing complex semantics, e.g., which involves multiple types of relationships, was already introduced in (Hirst and St-Onge, 1998; Bulskov et al., 2002).\nSeveral approaches have also been proposed to consider density of concepts, e.g., through analysis of cluster of concepts (Al-Mubaid and Nguyen, 2006). Other adaptations also proposed taking into account concepts\u2019 distance to leaves (Wu et al., 2006), and variable strengths of connotation considering particular strategies (Lee et al., 1993; Zhong et al., 2002), e.g., using IC variability among two linked concepts or multiple topological criteria (Jiang and Conrath, 1997; Alvarez et al., 2011).\nIn terms of the spreading activation theory, measures have also been defined as a function of transfer between the compared concepts (Schickel-Zuber and Faltings, 2007). Wang et al. (2007) use a similar approach based on a specific definition of the strength of connotation. Finally, pure graph-based approaches defined for the comparison of nodes can also be used to compare concepts defined in a taxonomy (refer to Section 3.2.1). As an example, Garla and Brandt (2012) and Yang et al. (2012) define semantic similarity measures using random walk techniques such as the personalised page rank approach.\nAs we have seen, most structural semantic similarity measures are extensions or refinements of the intuitive shortest path distance considering intrinsic factors to consider both the specificity of concepts and variable strengths of connotations. Nevertheless, the algorithmic complexity of the shortest path algorithms hampers the suitability of these measures for large semantic graphs35. To remedy this problem, we have seen that shortest path computation can be substituted by approximation based on the\n34Note that we assume that the paper contains an error in the equation defining the measure. The formula is considered to be X/(Y + Z), not X/Y + Z as written in the paper.\n35A linear algorithm in O(C + E) exists for DAGs; nevertheless search for sp(u, isa\u2217, v) requires the consideration of cyclic graphs for which algorithms, such as Dijkstra\u2019s, are in O(C2) or O(E+C \u00b7 logC) using sophisticated implementation."}, {"heading": "3.4. SEMANTIC SIMILARITY BETWEEN A PAIR OF CONCEPTS 63", "text": "depth of the LCA of the compared concepts36, and that several measures proposed by graph theory can be used instead.\nTowards other estimators of semantic similarity\nMost criticisms related to the initial edge-counting approach were linked to the uniform consideration of edge weights. As we have seen, to remedy this, several authors proposed considering a great deal of semantic evidence to differentiate strengths of connotation between concepts.\nOne of the central findings conveyed by early developments in structure-based measures is that the similarity function can be broken down into several components, in particular those distinguished by the feature model: commonality and difference. Indeed, the shortest path between two concepts can be seen as the difference between the two concepts (considering that all specialisation add properties to a concept). More particularly, in trees, or under specific constraints in graphs, we have seen that the shortest path linking two concepts contains their LCA. It can therefore be broken down into two parts corresponding to the shortest paths which link compared concepts to their LCA: in most cases, sp(u, isa\u2217, v) = sp(u, isa, LCA(u, v)) + sp(v, isa, LCA(u, v)). Therefore, the LCA can be seen as a proxy which partially summarises the commonality of compared concepts37. Distances between compared concepts and their LCA can therefore be used to estimate their differences.\nThe fact that measures can be broken down into specific components evaluating commonalities and differences is central in the design of the approaches which will further be introduced: the featurebased strategy and the information theoretical strategy. As we will see, they mainly define alternative strategies to characterise compared concepts in order to express semantic measures as a function of their commonalities and differences.\n36The algorithmic complexity of the LCA computation is significantly lower than the computation of the shortest path: constant after linear preprocessing (Harel and Tarjan, 1984).\n37The LCA only partially summarises commonality. Indeed, it can only be considered as an upper-bound of the commonality since highly similar concepts (Man, Women) may have a general concept for LCA (LivingBeing). This LCA will only encompass a partial amount of their commonalities. Please refer to Section 3.3.2. In addition, notice that in some cases the set of NCCAs contains other concepts than the LCA."}, {"heading": "64 CHAPTER 3. KNOWLEDGE-BASED SEMANTIC MEASURES", "text": ""}, {"heading": "3.4.2 Feature-based approach", "text": "The feature-based approach generally refers to measures which rely on a taxonomic interpretation of the feature model proposed by Tversky (1977) (introduced in Section 1.2.1). However, as we will see, contrary to the original definition of the feature model, this approach is not necessarily framed in set theory38.\nThe main idea is to represent concepts as collections of features, i.e., characteristics describing the concepts, to further express measures based on the analysis of their common and distinct features. The score of the measures will only be influenced by the strategy adopted to characterise concept features39, and the strategy adopted for their comparison.\nAs we will see, the reduction of concepts to collections of features makes it possible to set the semantic similarity estimation back in the context of classical binary similarity or distance measures (e.g., set-based measures).\nAn approach commonly used to represent the features of a concept is to consider its ancestors as features40. We denote A(u) the set of ancestors of the concept u. Since the Jaccard index that was proposed 100 years ago, numerous binary measures have been defined in various fields. A survey of these measures distinguishes 76 of them in Choi et al. (2010). Considering that the features of a concept u are defined by A(u), an example of a semantic similarity measure expressed from the Jaccard index was proposed in Maedche and Staab (2001)41:\nsimCMatch(u, v) = |A(u) \u2229A(v)| |A(u) \u222aA(v)| (3.22)\nAnother example of a set-based expression of the feature-based approach is proposed in Bulskov et al. (2002):\nsimBulskov(u, v) = \u03b1 |A(u) \u222aA(v)| |A(u)| + (1\u2212 \u03b1) |A(u) \u222aA(v)| |A(v)| (3.23)\nwith \u03b1 \u2208 [0, 1] a parameter used to tune the symmetry of the measure. Rodr\u0301\u0131guez and Egenhofer (2003) also proposed a formulation derived from the ratio model defined by Tversky (introduced in Section 1.2.1):\nsimRE(u, v) = |A(u) \u2229A(v)|\n\u03b3|A(u) \\A(v)|+ (1\u2212 \u03b3)|A(v) \\A(u)|+ |A(u) \u2229A(v)| (3.24)\nwith \u03b3 \u2208 [0, 1], a parameter that enables the tuning of the symmetry of the measure. Sa\u0301nchez et al. (2012) define the taxonomic distance of two concepts as a function of the ratio between their distinct and shared features:\ndistSanchez(u, v) = log2\n( 1 +\n|A(u) \\A(v)|+ |A(v) \\A(u)| |A(u) \\A(v)|+ |A(v) \\A(u)|+ |A(u) \u2229A(v)|\n) (3.25)\nVarious refinements of these measures have been proposed, e.g., to enrich concept features by taking their descendants into account (Ranwez et al., 2006).\nThe feature-based measures may not be intentional, i.e., they are not expected to solely rely on the knowledge defined in the taxonomy. When instances of the concepts are known, the feature of a concept can also be seen by extension and be defined on the basis of instances associated to concepts. As an example, the Jaccard index can be used to compare two ordered concepts according to their shared and distinct features, here characterised by extension:\nsimJacExt(u, v) = |I(u) \u2229 I(v)| |I(u) \u222a I(v)| (3.26)\nwith I(u) \u2286 I the set of instances of the concept u. Note that this approach makes no sense if the desire is to compare concepts which are not ordered \u2013 the set I(u) \u2229 I(v) will tend to be empty.\n38You will recall that the feature matching function on which the feature model is based, relies on binary evaluations of the features \u201cIn the present theory, the assessment of similarity is described as a feature-matching process. It is formulated, therefore, in terms of the set-theoretical notion of a matching function rather than in terms of the geometric concept of distance\u201d (Tversky and Itamar, 1978).\n39As stressed in Schickel-Zuber and Faltings (2007), there is a narrow link with the multi-attribute utility theory (Keeney, 1993) in which the utility of an item is a function of the preference on the attributes of the item.\n40Its implicit senses if the concept refers to a synset. 41This is actually a component of a more refined measure."}, {"heading": "3.4. SEMANTIC SIMILARITY BETWEEN A PAIR OF CONCEPTS 65", "text": "D\u2019Amato et al. (2008) also define an extensional measures considering:\nsimD\u2032Amato(u, v) = min(|I(u)|, |I(v)|) |I(LCA(u, v))| ( 1\u2212 |I(LCA(u, v))||I| )( 1\u2212 min(|I(u)|, |I(v)|)|I(LCA(u, v))| ) (3.27)\nClassical feature-based measures summarise the features of a concept through a set representation which generally corresponds to a set of concepts or instances. However, alternative approaches can also be explored. Therefore, even if, to our knowledge, such approaches have not been defined, the features of a concept could also be represented as a set of relationships, as a subgraph, etc.\nIn addition, regardless of the strategy adopted to characterise the features of a concept (other concepts, relationships, instances), the comparison of the features is not necessarily driven by a set-based measure. Indeed, the collections of features can also be seen as vectors. As an example, a concept u can be represented by a vector U in a chosen real space of dimension |C|, e.g., considering that each dimension associated to an ancestor of u is set to 1. Vector-based measures will evaluate the distance of two concepts by studying the coordinates of their respective projections.\nIn this vein, Bodenreider et al. (2005) proposed the comparison of two concepts according to their representation through the Vector Space Model. Considering a concept-to-instance matrix, a weight corresponding to the IC42 of the concept u is associated to the cell (u, i) of the matrix if the instance i \u2208 I(u). The vectors representing two concepts are then compared using the classical dot product of the vectors presented in Section 2.3.2."}, {"heading": "3.4.3 Information theoretical approach", "text": "The information theoretical approach relies on Shannon\u2019s information theory (Shannon, 1948). As with the feature-based strategy, these measures rely on the comparison of two concepts according to their commonalities and differences, here defined in terms of information. This approach formally introduces the notion of salience of concepts through the definition of their informativeness Information Content (IC) \u2013 Section 3.3.2 introduces the notion of IC.\nResnik (1995) defines the similarity of a couple of concepts as a function of the IC of their common ancestor which maximises an IC function (originally eIC), i.e., their Most Informative Common Ancestor (MICA).\nsimResnik(u, v) = IC(MICA(u, v)) (3.28)\nResnik\u2019s measure doesn\u2019t explicitly capture the specificities of compared concepts. Indeed, pairs of concepts with an equivalent MICA will have the same semantic similarity, whatever their respective ICs. To correct this limitation, several authors refined the measure proposed by Resnik to incorporate specificities of compared concepts. We here present the measures proposed by Lin (1998a)43 \u2013 simLin , (Jiang and Conrath, 1997) \u2013 distJC , (Mazandu and Mulder, 2013) \u2013 simNunivers, (Pirro\u0301 and Seco, 2008; Pirro\u0301, 2009) \u2013 simPSec and (Pirro\u0301 and Euzenat, 2010b) \u2013 simFaith:\nsimLin(u, v) = 2 \u00b7 IC(MICA(u, v)) IC(u) + IC(v)\n(3.29)\ndistJC(u, v) = IC(u) + IC(v)\u2212 2 \u00b7 IC(MICA(u, v)) (3.30)\nsimNunivers(u, v) = IC(MICA(u, v))\nmax(IC(u), IC(v)) (3.31)\nsimPSec(u, v) = 3 \u00b7 IC(MICA(u, v))\u2212 IC(u)\u2212 IC(v) (3.32)\nsimFaith(u, v) = IC(MICA(u, v))\nIC(u) + IC(v)\u2212 IC(MICA(u, v)) (3.33)\nTaking into account specificities of compared concepts can lead to high similarities (low distances) when comparing general concepts. As an example, when comparing general concepts using simLin, the maximal similarity will be obtained comparing a (general) concept to itself. In fact, the identity of the indiscernibles is generally ensured (except for the root which generally has an IC equal to 0). However,\n42Originally the authors used the IDF but we saw that both the IC and the IDF are similar (Section 3.3.2). 43Originally defined as: simLin(u, v) = 2\u00d7log(MICA(u,v)) log(u)+log(v)"}, {"heading": "66 CHAPTER 3. KNOWLEDGE-BASED SEMANTIC MEASURES", "text": "some treatments require this property not to be respected. Authors have therefore proposed to lower the similarity of two concepts according to the specificity of their MICA, e.g. (Schlicker et al., 2006; Li et al., 2010). The measure proposed by Schlicker et al. (2006) is presented:\nsimRel(u, v) = simLin(u, v)\u00d7 (1\u2212 p(MICA(u, v))) (3.34)\nwith p(MICA(u, v)) the probability of occurrence of the MICA. An alternative approach proposed by Li et al. (2010) relies on the IC of the MICA and can therefore be used without extensional information on concepts, i.e., using an intrinsic expression of the IC.\nAuthors have also proposed to characterise the information carried by a concept by summing the ICs of its ancestors (Mazandu and Mulder, 2011; Cross and Yu, 2011):\nsimMazandu(u, v) = 2 \u00b7\u2211c\u2208A(u)\u2229A(v) IC(c)\u2211\nc\u2208A(u) IC(c) + \u2211 c\u2208A(v) IC(c)\n(3.35)\nsimJacAnc(u, v) = \u2211 c\u2208A(u)\u2229A(v) IC(c)\u2211 c\u2208A(u)\u222aA(v) IC(c)\n(3.36)\nThese measures can also be considered as hybrid strategies between the feature-based and information theory approaches. One can consider that these measures rely on a redefinition of the way to characterise the information conveyed by a concept (by summing the IC of the ancestors). Other interpretations can simply consider that features are weighted. Thus, following the set-based representations of features, authors have also studied these measures as fuzzy measures (Cross, 2004; Popescu et al., 2006; Cross, 2006; Cross and Sun, 2007; Cross and Yu, 2010, 2011), e.g., defining the membership function of a feature corresponding to a concept as a function of its IC.\nFinally, other measures based on information theory have also been proposed, e.g., (Maguitman and Menczer, 2005; Maguitman et al., 2006; Cazzanti and Gupta, 2006). As an example, in Maguitman and Menczer (2005) the similarity is estimated as a function of prior and posterior probability regarding instances and concept membership."}, {"heading": "3.4.4 Hybrid approach", "text": "Other techniques take advantage of the various aforementioned paradigms. Among the numerous proposals, (Jiang and Conrath, 1997; Bin et al., 2009) defined measures in which density, depth, strength of connotation and ICs of concepts are taken into account. We present the measure proposed by Jiang and Conrath (1997)44. The strength of association w(u, v) between two concepts u, v is defined as follows:\nw(u, v) = (\u03b2 + (1\u2212 \u03b2)) dens|children(v)| \u00d7 ( depth(v) + 1 depth(v) )\u03b1 \u00d7 (IC(u)\u2212 IC(v))\u00d7 T (u, v)\nThe factor dens refers to the average density of the whole taxonomy, see Jiang and Conrath (1997) for details. The factors \u03b1 \u2265 0 and \u03b2 \u2208 [0, 1] control the importance of the density factor and the depth respectively. T (u, v) defines weights associated to predicates. Finally, the similarity is defined by the weight of the shortest path which links compared concepts and which contains their LCA:\ndistJC\u2212Hybrid(u, v) = \u2211\n(s,p,o)\u2208sp(u,isa,LCA(u,v))\u222asp(v,isa,LCA(u,v)) w(s, o)\nDefining \u03b1 = 0, \u03b2 = 1 and T (u, v) = 1, we obtain the information theoretical measure proposed by the same authors, i.e., distJC(u, v) = IC(u) + IC(v)\u2212 2 \u00b7 IC(MICA(u, v)) (Equation 3.30).\nSingh et al. (2013) proposed a mixing strategy based on (Jiang and Conrath, 1997) IC-based measure distJC . They consider transition probabilities between concepts relying on a depth-based estimation of the strength of connotation.\nRodr\u0301\u0131guez and Egenhofer (2003) also proposed mixing a feature-based approach considering structural properties such as the concepts\u2019 depth. Finally, Paul et al. (2012) defined multiple measures based on an aggregation of several existing measures.\n44This measure is a parametric distance. Couto et al. (2003) discuss the implementation, Othman et al. (2008) propose a genetic algorithm which can be used to tune the parameters and Wang and Hirst (2011) propose a redefinition of the notion of depth and density initially proposed."}, {"heading": "3.4. SEMANTIC SIMILARITY BETWEEN A PAIR OF CONCEPTS 67", "text": ""}, {"heading": "3.4.5 Considerations when comparing concepts in semantic graphs", "text": "Several measures introduced in the previous sections were initially defined to compare concepts expressed in a tree. However, despite the fact that this subject is almost never discussed in the literature, several considerations must be taken into account in order to estimate the similarity of concepts defined in a semantic graph in which multiple inheritances can exist \u2013 please refer to notations introduced in Section 3.1.\nShortest path\nA tree is a specific type of graph in which multiple inheritances cannot be encountered, i.e. \u2200c \u2208 C, |parents(c)| < 2. This implies that two concepts u, v which are not ordered will have no common descendants, i.e., G\u2212T (u) \u2229 G\u2212T (v) = \u2205. Therefore, if there is no redundant taxonomic relationship, the shortest path which links u, v always contains a single common ancestor of u, v: LCA(u, v). However, in a graph, since two non-ordered concepts u, v can have common descendants, i.e., G\u2212T (u)\u2229G\u2212T (v) 6= \u2205, the shortest path which links u, v can in some cases not contain one of their common ancestors. Figure 3.5 illustrates the modifications induced by multiple inheritances.\nIn Figure 3.5, the shortest path linking the two non-ordered concepts C5 and C7 in the tree (i.e. without considering red dotted edges) is [C5 \u2212 C3 \u2212 C1 \u2212 Root \u2212 C2 \u2212 C4 \u2212 C7]. However, if we consider multiple inheritances (red dotted edges), it is possible to link C5 and C7 through paths which do not contain one of their common ancestors, e.g., [C5\u2212C3\u2212C6\u2212C4\u2212C7] or even [C5\u2212C8\u2212C7]. The shortest path which contains a common ancestor of the compared concepts is defined in the search space corresponding to the graph G+T (u) \u222a G+T (v). In practice, despite the fact that in most graphs G\u2212T (u) \u2229 G\u2212T (v) 6= \u2205 (for two non-ordered concepts), it is commonly admitted that the shortest path must contain a single ancestor of the two compared concepts. Given this constraint, the edge-counting taxonomic distance of u and v in G+T (u) \u222a G+T (u) is generally (implicitly45) defined by: distSP (u, v) =\n45Generalisation of measures defined from trees to graphs is poorly documented in the literature."}, {"heading": "68 CHAPTER 3. KNOWLEDGE-BASED SEMANTIC MEASURES", "text": "sp(u, isa, LCA(u, v)) + sp(v, isa, LCA(u, v)).\nNote that when non comparable common ancestors (NCCAs) are shared between compared concepts, the ancestor which maximises the similarity is expected to be considered. Depending on the \u03b8 function which is used, the shortest path doesn\u2019t necessarily involve the concept of the NCCAs which maximise \u03b8, e.g. the deeper in the taxonomy. As an example, in order to distinguish which NCCA to consider, Schickel-Zuber and Faltings (2007) took into account a mix between depth and reinforcement (number of different paths leading from one concept to another).\nNevertheless, the shortest path techniques can also be relaxed to consider paths which do not involve common ancestors or which involve multiple common ancestors:\nsimSP\u2212R(u, v) = 1\nsp(u, isa\u2217, v) + 1\nNotion of depth\nThe definition of the notion of depth must also be reconsidered when the taxonomy is not a tree. Remember that, in a tree without redundancies, the depth of a concept has been defined as the length of the shortest path linking the concept to the root. The depth of a concept is a simple example of specificity estimator. In a tree, this estimator makes perfect sense since the depth of a concept is directly correlated to its number of ancestors since depth(c) = |A(c)| \u2212 1.\nIn a graph, or in a tree with redundant taxonomic relationships, we must ensure that the depth is monotonically decreasing according to the ordering of concepts. As an example, to apply depth-based measures to graphs, we must ensure that depth(LCA(u, v)) is lower or equal to both depth(u) and depth(v). To this end, the maximal depth of a concept must be used, i.e., the length of the longest path in {u, isa,>}, denoted lp(u, isa,>). As an example, the measure proposed by Pekar and Staab (2002) \u2013 Equation 3.17 \u2013 is therefore implicitly generalised to:\nsimPS\u2212G(u, v) = lp(LCA(u, v), isa,>)\nlp(u, isa, LCA(u, v)) + lp(v, isa, LCA(u, v)) + lp(LCA(u, v), isa,>)\nNotion of least common ancestors\nMost measures which have been presented take advantage of the notions of LCA or MICA. However, in graphs, these measures do not consider the whole set of NCCAs \u2013 denoted \u2126(u, v) for the concepts u and v. To remedy this, several authors have proposed adaptations of existing measures. As an example, Couto et al. (2005); Couto and Silva (2011) proposed GraSM and DiShIn strategies.\nIn (Couto et al., 2005) the authors proposed the modification of information theoretical measures based on the notion of MICA. The authors recommended substituting the IC of the MICA by the average of the ICs of the concepts which compose the set of NCCAs. A redefinition of the measure proposed by (Lin, 1998a) \u2013 Equation 3.29 \u2013 is presented:\nsimLin\u2212GraSM (u, v) = 2 \u00b7\n\u2211 c\u2208\u2126(u,v) IC(c)\n|\u2126(u,v)| IC(u) + IC(v)\n(3.37)\n= 2 \u00b7\u2211c\u2208\u2126(u,v) IC(c)\n|\u2126(u, v)| \u00d7 (IC(u) + IC(v))\nWang et al. (2012b) also proposed averaging the similarity between the concepts according to their multiple NCCAs:\nsimWang(u, v) =\n\u2211 a\u2208\u2126(u,v)\n2\u00b7depth(a)2 da(>,u)\u00d7da(>,v) |\u2126(u, v)|\nWith da(>, u) the average length of the set of paths which contain the concept a and which link the concept u to the root of the taxonomy (>).\nAs we have underlined, numerous approaches have been defined to compare pairs of concepts defined in a taxonomy, these measures can be used to compare any pair of nodes defined in a poset. Table 3.2 to Table 3.5 present some properties of a selection of measures defined to compare pairs of concepts."}, {"heading": "3.4. SEMANTIC SIMILARITY BETWEEN A PAIR OF CONCEPTS 69", "text": ""}, {"heading": "3.4.6 List of pairwise semantic similarity measures", "text": "Several semantic measures which can be used to compare concepts defined in a taxonomy or any pair of elements defined in a poset. Measures are ordered according to their date of publication. Other contributions studying some properties of pairwise measures can be found in Yu (2010); Slimani (2013). IOI: Identify of the Indiscernibles. Some of the values associated to specific measures have not been complete yet. This is generally because the reference associated to the measure was not available or because the properties of the measure are still under study."}, {"heading": "70 CHAPTER 3. KNOWLEDGE-BASED SEMANTIC MEASURES", "text": "S tr\nu c tu\nra l\nM e a su\nre s\nN a m\ne T\ny p\ne C\no n\nst .\nR a n\ng e\nIO I\nC o m\nm e n t\nS h\nor te\nst P\nat h\nst ra\nte gy\nS im\n/ R\nel N\no n\ne R\n+ Y\nes M\nea su\nre s\na re\nd efi\nn ed\na s\na fu\nn ct\nio n\no f\nth e\nw ei\ng h t\no f\nth e\nsh or\nte st\np a th\nli n\nk in\ng co\nm -\np a re\nd co\nn ce\np ts\n. S\nev er\na l\nm o d\nifi ca\nti o n\ns ca n b e co n si d er ed d ep en d in g o n th e st ra te g y a d o p te d , e. g ., w ei g h in g o f th e re la ti o n sh ip s (a cc o rd in g to th ei r p re d ic a te ), co n st ra in ts o n th e in cl u si o n of a co m m o n a n ce st o r o f th e co m p a re d co n ce p ts , et\nc. R ad a et al . (1 98 9) D is t (I S A ) D A G R + Y es S p ec ifi c sh o rt es t p a th st ra\nte g y\nw it\nh u\nn i-\nfo rm\ned g e\nw ei\ng h t.\nT h\ne sh\no rt\nes t\np a th is co n st ra in ed to co n ta in in g th e L C A o f th e co m p a re d co n ce p ts\n. Y ou n g W h an an d K im (1 99 0) x x x x x L ee et al . (1 9 93 ) x x x x x S u ss n a (1 99 3) D is t R D A G R + Y es O ri g in a ll y d efi n ed a s\na p\na ra\nm et\nri c\nse m\na n - ti c re la te d n es s. U n d er sp ec ifi c co n st ra in ts , th is m ea su re ca n b e u se d a s a se m a n ti c si m - il a ri ty . S h o rt es t p at h te ch n iq u e w h ic h ta ke in to a cc o u n t n o n -u n if o rm st re n g th s o f co n - n o ta ti o n . T h is la tt er is tu n ed a cc o rd in g to th e d ep th o f th e co m p a re d co n ce p ts a n d to th e w ei g h ts a ss o ci a te d to p re d ic a te s. R ic h a rd so n et al . (1 99 4) x x x x T h e a u th o rs p ro p os e se ve ra l in tr in si c m et - ri cs (e .g ., d ep th , d en si ty ) to w ei g h th e re - la ti o n sh ip s a n d d efi n e h y b ri d m ea su re s b y m ix in g th e st ru ct u ra l a n d in fo rm a ti o n th eo re ti ca l a p p ro a ch . N o m ea su re ex p li ci tl y is d efi n ed . W u an d P al m er (1 99 4 ) S im R D A G [0 ,1 ] Y es T h e si m il a ri ty is a ss es se d a s a fu n ct io n o f th e d ep th o f th e co m p a re d co n ce p ts a n d th e d ep th o f th ei r L C A ."}, {"heading": "3.4. SEMANTIC SIMILARITY BETWEEN A PAIR OF CONCEPTS 71", "text": "L ea\nco ck\nan d\nC h\no d\nor ow\n(1 99 4, 19 9 8)\nS im\nR D\nA G\nR +\nY es\nR a d\na et\na l.\n(1 9 8 9 )\nfo rm\nu la\nti o n\np en\na li\nsi n g lo n g sh o rt es t p a th b et w ee n th e co m p a re d co n ce p ts a cc o rd in g to th e d ep th o f th e ta x - o n o m\ny. R es n ik (1 99 5) S im R D A G [0 ,2 D ] Y es S im il\na ri\nty b\na se\nd o n\nth e\nsh o rt\nes t\np a th\nte ch - n iq u e w h ic h h a s b ee n b o u n d b y (t w ic e) th e d ep th o f th e ta x o n o m y (D\n). H ir st an d S tO n ge (1 99 8) S im / R el N o n e R + Y es S h o rt es t p a th p en a li si n g m\nu lt\nip le\nch a n\ng es\no f\np re\nd ic\na te\n. C\na n\nb e\nu se\nd a s\na si\nm il a ri ty o r re la te d n es s m ea su re d ep en d in g o n th e re la ti o n sh ip s w h ic h a re co n si d er ed . Z h on g et al . (2 00 2 ) D is t R D A G [0 ,m a x [ Y es T a x o n o m ic d is ta n ce ta k in g in to a cc o u n t th e d ep th o f th e co m p a re d co n ce p ts . W it h m a x d efi n ed a s m a x = 1 / k d e p th (L C A (u ,v )) w it h k a g iv en co n st a n t. P ek ar an d S ta ab (2 00 2 ) S im R D A G [0 ,1 ] Y es S h o rt es t p a th te ch n iq u e w h ic h ta ke s in to a cc o u n t th e d ep th o f th e L C A o f th e co m - p a re d co n ce p ts . M ao an d C h u (2 00 2) S im D A G R + N o M o d ifi ca ti o n o f R a d a et a l. (1 9 8 9 ) fo rm u la - ti o n ta k in g in to a cc o u n t co n ce p t sp ec ifi ci ty a s a n o n -l in ea r fu n ct io n o f th e n u m b er o f d es ce n d a n ts a co n ce p t h a s. L i et al . (2 0 03 ) x x x x x L i et al . (2 0 06 ) S im R D A G R + N o M ea su re co n si d er in g b o th th e le n g th o f th e sh o rt es t p a th li n k in g th e co m p a re d co n - ce p ts a n d th ei r d ep th . G an es an et al . (2 00 3) S im x x x R ef er to th e fu n ct io n n a m ed le a fs im in th e p u b li ca ti o n . Y u et a l. (2 00 5) S im R D A G [0 ,1 ] Y es M ea su re a ll ow in g n o n -n u ll si m il a ri ty o n ly to o rd er ed p a ir s o f co n ce p ts ."}, {"heading": "72 CHAPTER 3. KNOWLEDGE-BASED SEMANTIC MEASURES", "text": "W u\net al\n. (2\n00 6 )\nS im\nR D\nA G\n[0 ,1\n] N\no T\na k e\nin to\na cc\no u\nn t\nco m\np a re\nd co\nn ce\np ts\n(i )\nco m\nm o n\na li\nty (l\nen gt\nh o f\nth e\nlo n\ng es\nt sh\na re d p a th fr o m th e co n ce p ts to th e ro o t) , (i i) sp ec ifi ci ty (d efi n ed a s a fu n ct io n o f th e sh o rt es t p a th fr om th e co n ce p t to th e le av es it su b su m es ) a n d (i ii ) lo ca l d is ta n ce (R a d a et a l. (1 9 8 9 ) d is ta n ce ).\nS li\nm an\ni et\nal .\n(2 00\n6) S\nim R\nD A\nG [0\n,1 ]\nY es\nM o d\nifi ca\nti o n\no f\nW u\na n\nd P\na lm\ner (1\n9 9 4 )\nm ea\nsu re\nto av\no id\nca se\ns in\nw h\nic h\nn ei\ng h b\no u rs o f a co n ce p t m ig h t h av e h ig h er si m il a rit y va lu es th a n co n ce p ts w h ic h a re o rd er ed w it h it\n. B la n ch ar d et al . (2 0 06 ) S im R D A G [0 ,1 ] N o M ea su re\nw h\nic h\nco m\np a re\ntw o\nco n\nce p\nts w\n.r .t\nth ei\nr d\nep th\na n\nd th\ne d\nep th\no f\nth ei\nr L\nC A . O ri g in a ll y d efi n ed fo r tr ee s a n d ex te n d ed fo r D A G in (B la n ch a rd , 2 0 0 8 )\nN ag\nar an\nd A\nlM\nu b\nai d\n(2 00\n8) S\nim D\nA G\nR +\nY es\nU se\na m\no d\nifi ca\nti on\no f\nsh o rt\nes t\np a th\nco n - st ra in ed b y th e L C A .\nC h\no et\nal .\n(2 00\n3) S\nim D\nA G\nR +\nN o\nM u\nlt ip\nle fa\nct o rs\na re\nco n\nsi d\ner ed\nto ta\nk e\nin to\na cc\no u\nn t\nth e\nsp ec\nifi ci\nty o f\nth e\nco m\np a re d co n ce p ts\n. A lv ar ez an d Y an (2 01 1) (S S A ) S im / R el R D A G [0 ,1 ] N o T h is m\nea su\nre re\nli es\no n\nth re\ne co\nm p\no n\nen ts\nev a lu\na ti\nn g\n(i )\nth e\nsh o rt\nes t\np a th\nli n\nk in\ng th e co m p a re d co n ce p ts (a w ei g h in g sc h em e is a p p li ed to th e g ra p h ), (i i) th ei r L C A , a n d (i ii ) th ei r li te ra l d efi n it io n s.\nW an\ng et\nal .\n(2 0 12\nb )\nS im\nR D\nA G\n[0 ,1\n] Y\nes A\np p\nro a ch\nta k in\ng in\nto a cc\no u\nn t\nth e\nd ep th o f th e co m p a re d co n ce p ts , a s w el l a s th e d ep th o f a ll th ei r D C A\ns. S h en oy et al . (2 0 12 ) S im R D A G x x M o d ifi ca ti o n o f W u a n\nd P\na lm\ner (1\n9 9 4 )\nm ea\nsu re\nto av\no id\nca se\ns in\nw h\nic h\nn ei\ng h b\no u rs o f a co n ce p t m ig h t h av e h ig h er si m il a rit y va lu es th a n co n ce p ts w h ic h a re o rd er ed w it h it ."}, {"heading": "3.4. SEMANTIC SIMILARITY BETWEEN A PAIR OF CONCEPTS 73", "text": "G an\nes an\net al\n. (2\n01 2)\nS im\nR D\nA G\nx x\nM o d\nifi ca\nti o n\no f\nW u\na n\nd P\na lm\ner (1\n9 9 4 )\nm ea\nsu re\nto av\no id\nca se\ns in\nw h\nic h\nn ei\ng h b\no u rs o f a co n ce p t m ig h t h av e h ig h er si m il a rit y va lu es th a n co n ce p ts w h ic h a re o rd er ed w it h it\n. T ab le 3. 2 : S em a n ti c si m il a ri ty m ea su re s o r ta x o n o m ic d\nis ta\nn ce s d efi n ed u si n g a st ru ct u ra l a p p ro a ch . T h es e m ea su re s ca n b e u se d to co m p ar e a p a ir o f co n ce p ts d efi n ed in a ta x o n o m y o r a n y p a ir o f el em en ts d efi n ed in a p a rt ia ll y o rd er ed se t"}, {"heading": "74 CHAPTER 3. KNOWLEDGE-BASED SEMANTIC MEASURES", "text": "In fo\nrm a ti\no n\nth e o re\nti c a l\nM e a su\nre s\nN a m\ne T\ny p\ne C\no n\nst .\nR a n\ng e\nIO I\nC o m\nm e n t\nR es\nn ik\n(1 99\n5 )\nS im\nD A\nG [0 ,1\n], [0 ,+ \u221e\n[ N\no T\nh e\nsi m\nil a ri\nty is\nd efi\nn ed\na s\nth e\nIC o f\nM IC\nA . T\nh e\nra n\ng e\no f th\ne m\nea su\nre d\nep en\nd s\no n\nth e\nIC .\nJ ia\nn g\nan d\nC on\nra th\n(1 99\n7) D\nis t\nD A\nG [0\n,1 ]\nY es\nT h\ne ta\nx o n\no m\nic d\nis ta\nn ce\nco m\np u\nte d\na s a fu n ct io n o f th e IC o f th e co m p a re d cl a ss es a n d th ei r M IC A .\nL in\n(1 99\n8a )\nS im\nD A\nG [0\n,1 ]\nY es\nT h\ne si\nm il\na ri\nty is\nco m\np u\nte d\na s\na ra\nti o\nb e-\ntw ee\nn th\ne IC\no f\nth e\nM IC\nA o f\nco m\np a re d cl a ss es a n d th e su m o f th ei r re sp ec ti ve IC s.\nS ch\nli ck\ner et\nal .\n(2 0 06\n) S\nim D\nA G\n[0 ,1\n] N\no M\no d\nifi ca\nti o n\no f\nL in\n(1 9 9 8 a )\nin o rd\ner to\nta ke\nin to\na cc\no u\nn t\nth e\nsp ec\nifi ci\nty o f\nth e\nM IC\nA ,\ni. e.\n, to\nav o id\nh ig\nh sc\no re\no f\nsi m ila ri ty co m p a ri n g tw o g en er a l cl a ss es (d u e to th e ra ti o ).\nC ou\nto et\nal .\n(2 00\n7) S\nim D\nA G\n[0 ,1\n] N\no D\ner iv\na ti\nv e\no f\nL in\n(1 9 9 8 a )\nm ea\nsu re in w h ic h a ll th e D C A s o f th e co m p a re d cl a ss es a re ta ke n in to a cc o u n t.\nY u\net al\n. (2\n00 7b\n) S\nim D\nA G\n[0 ,+ \u221e\n[ N\no T\no ta\nl A\nn ce\nst ry\nM ea\nsu re\n(T A\nM )\n\u2013 m\nea -\nsu re\nb a se\nd o n\na sp\nec ifi\nc d\nefi n\nit io\nn o f\nth e\nL C\nA .\nP ir\nro\u0301 an\nd S\nec o\n(2 00\n8) ;\nP ir ro\u0301 (2 00 9)\nS im\nD A\nG [0 ,x\n] N\no W\nit h x\nth e\nm a x im\na l\nIC va\nlu e.\nF o rm\nu la - ti o n si m il a r to J ia n g a n d C o n ra th (1 9 9 7 ) b u t w h ic h g iv es m o re im p o rt a n ce to th e in fo rm a ti ve n es s o f th e M IC A .\nL i\net al\n. (2\n01 0)\nS im\nD A\nG [0\n,1 ]\nN o\nL in\n(1 9 9 8 a )\nm ea\nsu re\nm o d ifi\ned to\nta ke\nsp ec\nifi ci\nty in\nto a cc\no u\nn t,\ni. e.\nto av\no id\nh ig h sc o re o f si m il a ri ty co m p a ri n g tw o g en er a l cl a ss es .\nP ir\nro\u0301 an\nd E\nu ze\nn at\n(2 01\n0 b\n) S\nim D\nA G\n[0 ,1\n] Y\nes R\na ti\no fo\nrm u\nla ti\no n\nsi m\nil a r\nto th\ne m\nea su re p ro p o se d b y L in (1 9 9 8 a ) b u t w h ic h g iv es m o re im p o rt a n ce to th e d iff er en ce b etw ee n th e co m p a re d co n ce p ts ."}, {"heading": "3.4. SEMANTIC SIMILARITY BETWEEN A PAIR OF CONCEPTS 75", "text": "M az\nan d\nu a n\nd M\nu ld\ner (2\n01 1)\nsi m\nD IC\nS im\nD A\nG [0\n,1 ]\nY es\nM ea\nsu re\nsi m\nil a r\nto L\nin (1\n9 9 8 a )\nb u\nt w\nh ic h u se s a n ew a p p ro a ch to ch a ra ct er is e th e IC o f a co n ce p t.\nM az\nan d\nu an\nd M\nu ld\ner (2\n01 3 )\nS im\nN u\nn iv\ner S\nim D\nA G\n[0 ,1\n] Y\nes IC\no f\nth e\nM IC\nA o f\nth e\nco m\np a re\nd cl\na ss es d iv id ed b y th e m a x im a l IC o f th e co m - p a re d cl a ss es .\nT ab\nle 3.\n3 :\nS em\na n ti\nc si\nm il\na ri\nty m\nea su\nre s\no r\nta x o n\no m\nic d\nis ta\nn ce s d efi n ed u si n g a n in fo rm a ti o n th eo re ti ca l a p p ro a ch . T h es e m ea su re s ca n b e u se d to co m p a re a p a ir o f co n ce p ts d efi n ed in a ta x o n o m y or an y p ai r o f el em en ts d efi n ed in a p a rt ia ll y o rd er ed se t"}, {"heading": "76 CHAPTER 3. KNOWLEDGE-BASED SEMANTIC MEASURES", "text": "F e a tu\nre -b\na se\nd M\ne a su\nre s\nN a m\ne T\ny p\ne C\no n\nst .\nR a n\ng e\nIO I\nC o m\nm e n t\nM ae\nd ch\ne an\nd S\nta ab\n(2 00\n1) S\nim D\nA G\n[0 ,1\n] Y\nes F\nea tu\nre -b\na se\nd ex\np re\nss io\nn re\nly in\ng o n\nth e\nJ a c-\nca rd\nin d\nex .\nB o d\nen re\nid er\net a l.\n(2 00\n5) S\nim D\nA G\n[0 ,1\n] x\nC o si\nn e\nsi m\nil a ri\nty o n\na ve\nct o r-\nb a se\nd re\np re\nse n - ta ti o n o f th e cl a ss es . T h e ve ct o r re p re se n ta - ti o n is b u il t a cc o rd in g to th e se t o f in st a n ce s o f th e cl a ss es .\nR an\nw ez\net al\n. (2\n0 06\n) D\nis t\nD A\nG R\n+ Y\nes T\nh e\nd is\nta n\nce is\nd efi\nn ed\na s\na fu\nn ct\nio n\no f\nth e\nn u\nm b\ner o f\nd es\nce n\nd a n ts\no f\nth e\nL C\nA o f\nth e\nco m - p a re d co n ce p ts . T h is m ea su re re sp ec ts d is - ta n ce a x io m s (i .e ., p os it iv it y, sy m m et ry , tr ia n g le in eq u a li ty ).\nJ ai\nn an\nd B\nad er\n(2 01\n0) S\nim D\nA G\n[0 ,1\n] N\no B\nu il\nd a\nm et\na -g\nra p\nh re\nd u ci\nn g\nth e\no ri\ng in\na l\no n - to lo g y in to cl u st er o f re la te d co n ce p ts . S im - il a ri ty is a ss es se d th ro u g h a sp ec ifi c fu n ct io n ev a lu a ti n g L C A in fo rm a ti o n co n te n t.\nB at\net et\na l.\n(2 01\n0b )\nS im\nD A\nG R\n+ Y\nes C\no m\np a ri\nso n\no f\nth e\ncl a ss\nes a cc\no rd\nin g\nto th\nei r\na n\nce st\no rs\n. F\no rm\nu la\nti o n\nex p\nre ss\ned a s\na d\nis -\nta n\nce co\nn ve\nrt ed\nto a\nsi m\nil a ri\nty u\nsi n\ng n\neg a ti ve lo g .\nT ab\nle 3.\n4 :\nS em\na n ti\nc si\nm il\na ri\nty m\nea su\nre s\no r\nta x o n\no m\nic d\nis ta\nn ce s d es ig n ed u si n g a fe a tu re -b a se d a p p ro a ch . T h es e m ea su re s ca n b e u se d to co m p a re a p a ir o f co n ce p ts d efi n ed in a ta x o n o m y o r a n y p ai r of el em en ts d efi n ed in a p a rt ia ll y o rd er ed se t"}, {"heading": "3.4. SEMANTIC SIMILARITY BETWEEN A PAIR OF CONCEPTS 77", "text": "H y b\nri d\nM e a su\nre s\nN a m\ne T\ny p\ne C\no n\nst .\nR a n\ng e\nIO I\nC o m\nm e n t\nJ ia\nn g\nan d\nC on\nra th\n(1 9 97\n); C\nou to\net al\n. (2\n00 3)\n; O\nth m\na n\net al . (2 00 8)\nS im\n/ D\nis t\nR D\nA G\n[0 ,1\n] V\na r.\nS tr\na te\ng y\nb a se\nd o n\nth e\nsh o rt\nes t\np a th\nco n - st ra in ed b y th e L C A o f th e co m p a re d cl a ss es . R el a ti o n sh ip s a re w ei g h te d a cc o rd - in g to th e d iff er en ce o f IC o f th e cl a ss es th ey li n k .\nA l-\nM u\nb a id\nan d\nN gu\ny en\n(2 00\n6) S im\nD A\nG [0 ,+ \u221e\n[ Y\nes A\nss ig\nn s\ncl u\nst er\n(s )\nto cl\na ss\nes .\nT h\ne si\nm il\na ri ty is co m p u te d co n si d er in g m u lt ip le m et ri cs . W an g et al . (2 00 7) S im / R el R D A G [0 ,1 ] Y es T h is m ea su re a s or ig in a ll y b ee n d efi n ed a s a se m a n ti c re la te d n es s. It ca n a ls o b e u se d to co m p u te se m a n ti c si m il a ri ty . It re li es o n a n o n -l in ea r a p p ro a ch to ch a ra ct er is e th e st re n g th o f co n n o ta ti o n a n d a sp ec ifi c a p - p ro a ch to ch a ra ct er is e th e in fo rm a ti v en es s o f a co n ce p ts . A lv ar ez an d Y an (2 01 1) S im / R el R D A G [0 ,1 ] N o E x p lo it s th re e co m p o n en ts ev a lu a ti n g co n - ce p ts , th ei r sh o rt es t p a th (a w ei g h ti n g sc h em e is a p p li ed to th e g ra p h ), th ei r L C A , a n d th ei r li te ra l d efi n it io n s. P au l et al . (2 01 2) S im x x x M u lt ip le a p p ro a ch es a re m ix ed T ab le 3. 5 : S em a n ti c si m il a ri ty m ea su re s o r ta x o n o m ic d is ta n ce s d es ig n ed u si n g a n h y b ri d a p p ro a ch . T h es e m ea su re s ca n b e u se d to co m p ar e a p a ir o f co n ce p ts d efi n ed in a ta x o n o m y o r a n y p a ir o f el em en ts d efi n ed in a p a rt ia ll y o rd er ed se t"}, {"heading": "78 CHAPTER 3. KNOWLEDGE-BASED SEMANTIC MEASURES", "text": ""}, {"heading": "3.5 Semantic similarity between groups of concepts", "text": "Two main approaches are commonly distinguished to introduce semantic similarity measures designed for the comparison of two sets of concepts, i.e., groupwise measures:\n\u2022 Direct approach, the measures which can be used to directly compare the sets of concepts according to information characterising the sets w.r.t the information defined in the taxonomy.\n\u2022 Indirect approach, the measures which assess the similarity of two sets of concepts using one or several pairwise measures, i.e. measures designed for the comparison of a pair of concepts. They are generally simple aggregations of the scores of similarities associated to the pairs of concepts defined in the Cartesian product of the two compared sets.\nNote that the sets are generally expected to not contain semantically redundant concepts, i.e., they do not contain any pair of ordered concepts \u2013 \u2200(u, v) \u2208 X,u v \u2227 v u.\nOnce again, a large diversity of measures have been proposed, some of which are presented in the next subsections."}, {"heading": "3.5.1 Direct approach", "text": "The direct approach corresponds to a generalisation of the approaches defined for the comparison of pairs of concepts in order to compare two sets of concepts. It is worth noting that classical set-based approaches can be used. The sets can also be compared through their vector representations, e.g., using the cosine similarity measure. Nevertheless, these measures are in most cases not relevant to be used considering the semantics they convey \u2013 they do not take into account the similarity of the elements composing compared sets46, e.g., sim({Man, Girl}, {Women, Boy}) = 0.\nStructural approach\nConsidering G+T (X) as the graph induced by the union of the ancestors of the concepts which compose the set X, Gentleman (2007) defined the similarity of two sets of concepts (U, V ) according to the length of the longest sp(c, isa,>) which links the concept c \u2208 G+T (U) \u2229G+T (V ) to the root (>).\nFeature-based approach\nThe feature-based measures are characterised by the approach adopted to express the features of a set of concepts.\nSeveral measures have been proposed from set-based measures. We introduce simUI (Gentleman, 2007)47, and the Normalised Term Overlap measure simNTO (Mistry and Pavlidis, 2008). For convenience, we consider C+T (X) as the set of concepts contained in G + T (X):\nsimUI(U, V ) = |C+T (U) \u2229 C+T (V )| |C+T (U) \u222a C+T (V )|\n(3.38)\nsimNTO(U, V ) = |C+T (U) \u2229 C+T (V )|\nmin(|C+T (U)|, |C+T (V )|) (3.39)\nInformation theoretical measures\nAmong others, Pesquita et al. (2007) proposed considering the information content of the concepts (originally an eIC expression):\nsimGIC(U, V ) =\n\u2211 c\u2208C+T (U)\u2229C + T (V )\nIC(c) \u2211 c\u2208C+T (U)\u222aC + T (V ) IC(c) (3.40)"}, {"heading": "3.5.2 Indirect approach", "text": "In Section 3.4, we introduced numerous measures for comparing a pair of concepts (pairwise measures). They can be used to drive the comparison of sets of concepts.\n46These simple approaches are generally used when the compared sets contain semantically redundant concepts. 47Also published through the name Term Overlap (TO) in Mistry and Pavlidis (2008)."}, {"heading": "3.5. SEMANTIC SIMILARITY BETWEEN GROUPS OF CONCEPTS 79", "text": "Improvements of direct measures using concept similarity\nOne of the main drawbacks of basic vector-based measures is that they consider dimensions as mutually orthogonal and do not exploit concept relationships. In order to remedy this, vector-based measures have been formulated to:\n\u2022 Weigh dimensions considering concept specificity evaluations (e.g., IC) (Huang et al., 2007; Chabalier et al., 2007; Benabderrahmane et al., 2010b).\n\u2022 Exploit an existing pairwise measure to perform vector products (Ganesan et al., 2003; Benabderrahmane et al., 2010b).\nTherefore, pairwise measures can be used to refine the measures proposed to compare sets of concepts using a direct approach.\nAggregation strategies\nA two-step indirect strategy can also be adopted in order to take advantage of pairwise measures to compare sets of concepts:\n1. The similarity of pairs of concepts obtained from the Cartesian product of the two compared sets has to be computed.\n2. Pairwise scores are then summarised using an aggregation strategy, also called mixing strategy in the literature.\nClassic aggregation strategies can be applied (e.g. max, min, average); more refined strategies have also been proposed. Among the most commonly used we present: Max average (Max-Avg), Best Match Max \u2013 BMM (Schlicker et al., 2006) and Best Match Average \u2013 BMA (Pesquita et al., 2008):\nsimAvg(U, V ) =\n\u2211 u\u2208U \u2211 v\u2208V sim(u, v)\n|U | \u00d7 |V | (3.41)\nsimMax\u2212Avg(U, V ) = 1 |U | \u2211\nu\u2208U maxv\u2208V sim(u, v) (3.42)\nsimBMM (U, V ) = max(simMax\u2212Avg(U, V ), simMax\u2212Avg(V,U)) (3.43)\nsimBMA(U, V ) = simMax\u2212Avg(U, V ) + simMax\u2212Avg(V,U)\n2 (3.44)\n3.5.3 List of groupwise semantic similarity measures"}, {"heading": "80 CHAPTER 3. KNOWLEDGE-BASED SEMANTIC MEASURES", "text": "D ir\ne c t\nG ro\nu p w\nis e\nM e a su\nre s\nN a m\ne T\ny p\ne A\np p\nro a ch\nC o n\nst .\nR a n\ng e\nIO I\nC o m\nm e n t\n(G an\nes an\net al\n., 20\n03 )\nO p\nti m\nis ti c G en ea lo gy M ea su re\nS im\nH y b\nri d\nR D\nA G\n[0 ,1\n] Y\nes F\nea tu\nre -b\na se\nd a p\np ro\na ch\nta k -\nin g\nin to\nco n\nsi d\ner a ti\no n\nst ru ctu ra l p ro p er ti es d u ri n g th e co m p a ri so n\n. (P o p es cu et al ., 20 06 ) A S im F ea tu re - b a se d D A G [0 ,1 ] ye s W ei g h te\nd J a cc\na rd\n(P o p\nes cu\net al\n., 20\n06 )\nB S\nim F\nea tu\nre -\nb a se\nd D\nA G\n[0 ,1\n] x\nF u\nzz y\nM ea\nsu re\n(C h\nab al\nie r\net al\n., 2 00\n7) S\nim F\nea tu\nre -\nb a se\nd (V\nec -\nto r)\nR D\nA G\n[0 ,1\n] Y\nes G\nro u\np s\no f\nco n\nce p\nts a re\nre p\nre -\nse n te\nd u\nsi n\ng th\ne V\nec to\nr S\np a ce\nM o d\nel a n\nd co\nm p\na re\nd u\nsi n g th e co si n e si m il a ri ty .\n(G en\ntl em\nan ,\n20 07\n) S\nim L\nP S\nim S\ntr u\nct u\nra l\nR D\nA G\n[0 ,1\n] Y\nes S\nim il\na ri\nty a s\na fu\nn ct\nio n\no f\nth e\nlo n\ng es\nt co\nm m\no n\np a th\nfo u\nn d\nin th\ne g ra\np h\nin d\nu ce\nd b y\nth e\nco m\np a re\nd g ro\nu p\ns o f\nco n\nce p\nts .\n(C h\no et\nal .,\n2 00\n7) S\nim F\nea tu\nre -\nb a se\nd R\nD A\nG R\n+ N\no F\nea tu\nre -b\na se\nd m\nea su\nre ta\nk -\nin g\nin to\na cc\no u\nn t\nth e\nsp ec ifi ci ty o f th e co m p a re d co n - ce p ts .\n(P es\nq u\nit a\net al\n., 2 00\n8) S\nim G\nIC S\nim F\nea tu\nre -\nb a se\nd D\nA G\n[0 ,1\n] Y\nes J a cc\na rd\nm ea\nsu re\nin w\nh ic\nh a\nse t\no f\nco n\nce p\nts is\nre p\nre se\nn te d b y th e co n ce p ts co n ta in ed in th e g ra p h it in d u ce s.\n(S h\nee h\nan et\nal .,\n2 00\n8) S\nS A\nS im\nF ea\ntu re - b a se\nd R\nD A\nG [0\n,1 ]\nY es\nE x te\nn d\ns th\ne n\no ti\no n\no f\nM IC A to p a ir o f g ro u p s o f co n ce p ts th en re d efi n e th e D ic e co effi - ci en\nt. (A li an d D ea n e, 2 00 9) S im F ea tu re - b a se d D A G [0 ,1 ] N o C o m\nm o n\na li\nty is\na ss\nes se\nd co\nn -\nsi d\ner in\ng sh\na re\nd n\no d\nes in\nth e\ng ra\np h\nin d\nu ce\nd b y\nth e\na n\nce s-\nto rs\nof th\ne co\nm p\na re\nd se\nts o f\nco n\nce p\nts .\n3.5. SEMANTIC SIMILARITY BETWEEN GROUPS OF CONCEPTS 81\n(J ai\nn an\nd B\nad er\n, 20\n10 )\nT C\nS S\nS im\nF ea\ntu re - b a se\nd R\nD A\nG [0\n,1 ]\nN o\nM a x\nS tr\na te\ng y\nco n\nsi d\ner in\ng a\nsp ec\nifi c\np a ir\nw is\ne m\nea su re (D ia zD ia z an d A gu il ar -R u iz , 20 11 ) S im S tr u ct u ra l R D A G [0 ,1 ] Y es D is ta n ce ta k in g in to a cc\no u\nn t\nth e\nsh o rt\nes t\np a th\nb et\nw ee\nn th e co n ce p ts a n d th e d ep th s o f th e co m p a re d co n ce p ts . (A lv ar ez an d Y an , 20 11 ) S im / R el S tr u ct u ra l N o n e R + Y es M ea su re b a se d o n th e a n a ly - si s o f st ru ct u ra l p ro p er ti es o f th e g ra p h . (A lv ar ez et al ., 20 11 ) S P G K S im S tr u ct u ra l N o n e Y es T h e se t o f co n ce p ts is re p re - se n te d b y th e g ra p h in d u ce d b y th e co n ce p ts it su b su m es . A si m il a ri ty m ea su re is u se d to co m p a re th e tw o g ra p h s. (T en g et al ., 2 01 3) S im x x x x x T ab le 3. 6 : S em a n ti c si m il a ri ty m ea su re s o r ta x o n o m ic d is ta n ce s d es ig n ed u si n g a d ir ec t a p p ro a ch . T h es e m ea su re s ca n b e u se d to co m p ar e a p a ir o f g ro u p s o f co n ce p ts d efi n ed in a ta x o n o m y o r a n y p ai r of gr ou p o f el em en ts d efi n ed in a p a rt ia ll y o rd er ed se t"}, {"heading": "82 CHAPTER 3. KNOWLEDGE-BASED SEMANTIC MEASURES", "text": "In d\nir e c t\nG ro\nu p w\nis e\nM e a su\nre s\nb a se\nd o n\na d\nir ec\nt a p\np ro\na ch\nN a m\ne T\ny p\ne A\np p\nro a ch\nC o n\nst .\nR a n\ng e\nIO I\nC o m\nm e n t\n(G an\nes an\net a l.\n, 20\n03 )\nG C\nS M\nS im\nF ea\ntu re - b a se\nd R\nD A\nG [0\n,1 ]\nY es\nG C\nS M\n: G\nen er\na li\nse d\nC o si\nn e-\nS im\nil a ri\nty M\nea su\nre .\nG ro\nu p s o f co n ce p ts a re re p re se n te d u si n g th e V ec to r S p a ce M o d el . D im en si o n s a re n o t co n si d er ed in d ep en d en t, i. e. th e si m il a ri ty o f tw o d im en si o n s is co m p u te d u si n g a n a p p ro a ch si m il a r to th e o n e p ro p o se d b y W u a n d P a lm er (1 9 9 4 ) m ea su re . T h e si m il a ri ty b et w ee n th e ve ct o r re p re se n ta ti o n s o f tw o g ro u p s o f co n ce p ts is es ti m a te d u si n g to th e co si n e si m il a ri ty .\n(H u\na n\ng et\nal .,\n20 07\n) x\nx R\nD A\nG [0\n,1 ]\nY es x (B en ab d er ra h m an e et al ., 20 10 b ) In te ll ig o S im F ea tu re - b a se d (V ec - to r) R D A G [0 ,1 ] Y es G\nro u\np s\no f\ncl a ss\nes a re\nre p\nre -\nse n te\nd u\nsi n\ng th\ne V\nec to\nr S\np a ce\nM o d\nel -\nA ls\no co\nn si\nd er\n(B en\na b - d er ra h m a n e et a l. , 2 0 1 0 a ). T h e d im en si o n s a re n o t co n si d er ed to b e in d ep en d en t.\nT ab\nle 3.\n7 :\nS em\na n ti\nc si\nm il\na ri\nty m\nea su\nre s\no r\nta x o n\no m\nic d\nis ta\nn ce s d es ig n ed u si n g a n in d ir ec t a p p ro a ch . T h es e m ea su re s ca n b e u se d to co m p ar e a p a ir o f g ro u p s o f co n ce p ts d efi n ed in a ta x o n o m y o r an y p ai r of g ro u p o f el em en ts d efi n ed in a p a rt ia ll y o rd er ed se t"}, {"heading": "3.6. OTHER KNOWLEDGE-BASED MEASURES 83", "text": ""}, {"heading": "3.6 Other knowledge-based measures", "text": ""}, {"heading": "3.6.1 Semantic measures based on logic-based semantics", "text": "Semantic measures based on the relational setting cannot be used to directly compare complex descriptions of classes or instances which rely on logic-based semantics, e.g. description logics (DLs). To this end, semantic measures which are capable of taking into account logic-based semantics have been proposed. They are for instance used to compare complex concept definitions expressed in OWL.\nAmong the diversity of proposals, measures based on simple DLs, e.g., only allowing concept conjunction (logic A), were initially proposed through extensions of semantic measures based on graph analysis (Borgida et al., 2005). More refined semantic measures have since been designed to exploit high expressiveness of DLs, e.g. ALC, ALN , SHI, ELH description logics (D\u2019Amato et al., 2005a; Fanizzi and D\u2019Amato, 2006; Janowicz, 2006; Hall, 2006; Arau\u0301jo and Pinto, 2007; D\u2019Amato et al., 2008, 2005b; Janowicz and Wilkes, 2009; Stuckenschmidt, 2009; Lehmann and Turhan, 2012).\nAs an example D\u2019Amato et al. (2005a) proposed to compare complex concept descriptions by aggregating functions which consider various components of their ALC normal forms48. These measures rely mostly on extensions of the feature model proposed by Tversky. They have been extensively covered in the thesis of D\u2019Amato (2007)."}, {"heading": "3.6.2 Semantic measures for multiple ontologies", "text": "Several approaches have been designed to estimate the relatedness of concepts or instances using multiple ontologies. These approaches are sometimes named cross-ontology semantic similarity/relatedness measures in the literature, e.g., (Petrakis et al., 2006). Their aim is twofold:\n\u2022 To enable the comparison of elements which have not been defined in the same ontology (the ontologies must model a subset of equivalent elements).\n\u2022 To refine the comparison of elements by incorporating a larger amount of information during the process.\nThese measures are in some senses related to those commonly used for the task of ontology alignment/mapping and instance matching (Euzenat and Shvaiko, 2013). Therefore, prior to their introduction we will first highlight the relationship between these measures and those designed for the aforementioned processes.\nComparison with ontology alignment/mapping and instance matching The task of ontology mapping aims at finding links between the classes and predicates defined in a collection of ontologies. These mappings are further used to build an alignment between ontologies. Instance matching focuses on finding similar instances defined in a collection of ontologies. These approaches generally rely on multiple matchers which will be aggregated for evaluating the similarity of the compared elements (Euzenat and Shvaiko, 2013; Shvaiko and Euzenat, 2013). The commonly distinguished matchers are:\n\u2022 Terminological \u2013 based on string comparison of the labels or definitions.\n\u2022 Structural \u2013 mainly based on the structuration of classes and predicates.\n\u2022 Extensional \u2013 based on instance analysis. 48Primitives and restrictions (both existential and universal) are considered."}, {"heading": "84 CHAPTER 3. KNOWLEDGE-BASED SEMANTIC MEASURES", "text": "\u2022 Logic-based \u2013 rely on logical constructs used to define the elements of the ontologies.\nThe score produced by these matchers is generally aggregated; a threshold is used to estimate if two (groups of) elements are similar enough to define a mapping between them. In some cases, the mapping will be defined between an element and a set of elements, e.g., depending on the difference of granularity of the compared ontologies, a concept can be mapped to a set of concepts. The problem of ontology alignment/mapping and instance matching is a field of study in itself. The techniques used for this purpose involve semantic similarity measures for the design of structural, extensional and logic-based matchers (terminological matchers are not semantic). However, the measures used in this context aim to find exact matches and are therefore generally not suited for the comparison of non-equivalent elements defined in different ontologies. Indeed, techniques used for ontology alignment are for instance not suited to answering questions such as: to which degree are the two concepts Coffee and Cup related?\nIn every instance, technically speaking, nothing prevents the use of matching techniques to estimate the similarity between elements defined in different ontologies. Indeed, the problem of knowing if two elements must be considered as equivalent can be reformulated as a function of their degree of semantic similarity. Nevertheless, a clear distinction of the problem of ontology alignment and semantic measure design exists in the literature. This can be partially explained by the fact that, in practice, compared to approaches used for ontology alignment and instance matching, semantic measures based on multiple ontologies:\n\u2022 Can be used to estimate the semantic relatedness and not only the semantic similarity of compared elements.\n\u2022 Sometimes rely on strong assumptions and approximations which cannot be considered to derive alignments, e.g., measures based on shortest path techniques.\n\u2022 Focus on the design of techniques for the comparison of elements defined in different ontologies which generally consider a set of existing mappings between ontologies.\nIn short, ontology alignment and instance matching are complex processes which use specific types of (semantic) similarity measures and which can be used to support the design of semantic measures involving multiple ontologies. We briefly present the main approaches which have been proposed for the definition of semantic measures based on multiple ontologies.\nMain approaches for the definition of semantic measures using multiple ontologies The design of semantic measures for the comparison of elements defined in different ontologies have attracted less attention than classical semantic measures designed for single ontologies. They have been successfully used to support data integration (Rodr\u0301\u0131guez and Egenhofer, 2003; Lange et al., 2007), clustering (Batet et al., 2010b), or information retrieval tasks (Xiao and Cruz, 2005), to cite a few. In this context, several contributions have focused on the design of semantic measures based on multiple ontologies without focusing on specific application contexts.\nThe measures proposed in the literature can be distinguished according to the approach they adopt \u2013 we consider the same classification used for semantic measures defined for a single ontology (the list of references may not be exhaustive):\n\u2022 Structural approach: (Al-Mubaid and Nguyen, 2009).\n\u2022 Feature-based approach: (Petrakis et al., 2006; Batet et al., 2010b, 2013; Sole\u0301-Ribalta et al., 2014; Sa\u0301nchez and Batet, 2013).\n\u2022 Information Theoretical approach: (Saruladha, 2011; Saruladha and Aghila, 2011; Saruladha et al., 2010a; Sa\u0301nchez and Batet, 2013; Batet et al., 2014).\n\u2022 Hybrid approach: (Rodr\u0301\u0131guez and Egenhofer, 2003)."}, {"heading": "3.7 Advantages and limits of knowledge-based measures", "text": "Advantages"}, {"heading": "3.8. MIXING KNOWLEDGE-BASED AND CORPUS-BASED APPROACHES 85", "text": "\u2022 They can be used to compare all types of elements defined in an ontology, i.e., terms, concepts, instances. These measures can therefore be used to compare entities which cannot be compared using text analysis. Indeed, knowledge-based measures can be used to compare any entities which is defined into an ontology through their semantic representations. As an example, knowledge-based semantic measures can be used to compare gene products according to conceptual annotations corresponding to their molecular functions, the biological processes in which they are involved or their cellular location.\n\u2022 They give access to fine control on the semantic relationships taken into account to compare the elements. This aspect is important to understand the semantics associated to a score of semantic measures, e.g., semantic similarity/relatedness.\n\u2022 Generally easier and less complex to compute than corpus-based measures measures. Indeed, knowledge-based semantic measures do not require complex and time-consuming preprocessing, such as the semantic model building in corpus-based measures. In addition, several efficient measures have been proposed and efficient implementation enable the use of some knowledge-based measures in computational intensive applications. Some problems can however be encountered in using measures which take into account complex logic constructors (e.g. some measures introduced in Section 3.6.1).\nLimits\n\u2022 Require an ontology describing the elements to compare. This is a strong limitation if no ontology is available for the domain to consider. Nevertheless, we stress that a large body of literature is dedicated to knowledge base generation/enrichment from text analysis (e.g., refer to the field of ontology learning and Information extraction). Several knowledge base semantic measures could therefore be applied on knowledge base generated by aforementioned text analysis techniques.\n\u2022 The use of logic-based measures can be challenging to compare elements defined in large ontologies (high computational complexity).\n\u2022 Measures based on graph analysis generally require the knowledge to be modelled in a specific manner in the graph and are not designed to take non-binary relationships into account. Such relationships are used in specific ontologies and play an important role in defining specific properties to relationships/statements. This can be an issue when reification techniques are used to express such knowledge49. However, most measures based on graph analysis are not adapted to this case. This aspect is relative to the mapping of an ontology to a semantic graph."}, {"heading": "3.8 Mixing knowledge-based and corpus-based approaches", "text": "As stated in Chapter 2, corpus-based semantic measures are of particular interest for comparing units of language by taking into account (quantitative) evidence of semantic similarity/relatedness encompassed in texts. In addition to these measures, this chapter has introduced knowledge-based measures that can be used to compare resources characterized by knowledge bases (concepts, instances, annotated objects). A spectrum of solutions may be envisaged to deal with either heterogeneous and unstructured texts on one hand and well-structured and annotated resources on the other hand. This section presents measures that propose to combine the two approaches presented so far, i.e. corpus-based and knowledge-based, into hybrid solutions. Section 3.8.1 introduces generalities about hybrid measures and briefly presents the different approaches that can be used for their definition. In Section 3.8.2, we will in particular focus on Wikipedia-based measures; by relying on the well-known Wikipedia encyclopedia they have the interesting property to take advantage of both a rich corpus of texts and a conceptual organization of categories."}, {"heading": "3.8.1 Generalities", "text": "Hybrid measures have been proposed to take advantage of both corpus-based and knowledge-based semantic measures to compare units of language and entities defined into ontologies. They will not be presented in detail, only references are provided. Most of the time hybrid measures combine several\n49This is done by defining a ternary relationship, i.e., the (binary) relationship is expressed by a node of the graph."}, {"heading": "86 CHAPTER 3. KNOWLEDGE-BASED SEMANTIC MEASURES", "text": "single semantic similarity (Panchenko and Morozova, 2012). Among the various mixing strategies, two broad types of approaches can be distinguished: Pure-hybrid measures and Aggregated measures.\n\u2022 Pure-hybrid measures correspond to measures which are not based on the aggregation of several measures; they are designed by defining a strategy which takes advantage of both corpus and ontology analysis. First and most common examples of pure-hybrid measures are semantic measures based on the information theoretical approach. As an example, (Resnik, 1995) proposed to estimate the amount of information carried by a concept as the inverse of the probability of the concept occurring in texts (refer to Section 3.3.2 for more information). The information content is the cornerstone of information theoretical measures, it can therefore be used to take advantage of several knowledge-based measures by considering corpus-based information. Other authors have also proposed to mix text analysis and structure-based (knowledge-based) measures. The extended gloss overlap measure introduced by (Banerjee and Pedersen, 2002), and the two measures based on context vectors proposed by (Patwardhan, 2003) are good examples. Another interesting approach is proposed in (Mohammad and Hirst, 2006). The authors propose a framework to exploit a thesaurus in order to derive word-concept distributional models that have the interesting property to be very compressed while finely characterising words. In (Alvarez and Lim, 2007), the authors propose to use WordNet and to adopt an hybrid approach in order to build a semantic model represented as a graph. The approach mixes gloss analysis as well as the analysis of WordNet structure. Interested readers may also consider (Li et al., 2003; Patwardhan et al., 2003; Banerjee and Pedersen, 2003; Patwardhan and Pedersen, 2006; Muller et al., 2006).\n\u2022 Aggregated measures derive from the aggregation combining corpus-based, knowledge-based and even hybrid semantic measures50. Scores of selected measures are aggregated according to the average, min, max, median or any aggregation function which can be designed to aggregate matrix of scores51.\nSeveral studies have demonstrated the gain of performance mixing knowledge-based and corpus-based approaches (Panchenko and Morozova, 2012) \u2013 see also the work of (Petrakis et al., 2006)."}, {"heading": "3.8.2 Wikipedia-based measure: how to benefit from structured encyclopaedia knowledge", "text": "Started in 2001, the Wikipedia52 initiative rapidly aroused great interest and became a reference encyclopaedia for all Internet users, including (self-proclaimed) experts that do not hesitate to share and organise valuable knowledge covering a variety of subjects. Then, it is not surprising that, in the middle of the 2000\u2019s, many efforts have been made to exploit this organised and free knowledge source in order to achieve information retrieval, classification, mining, or even business intelligence to mention a few. Indeed with more than 4.5 million articles53 providing free-access to textual definitions in many languages, that are linked together and associated with structured categories54, Wikipedia constitutes a stimulating playground for scientists involved in Computational Linguistics.\nSeveral Wikipedia-based initiatives have been proposed in order to assess the semantic relatedness between words or Wikipedia topics (sometimes denoted concepts). These measures take advantage of the various facets of Wikipedia. They generally jointly rely on corpus-based measures exploiting textual information and approaches that analyse Wikipedia topics organisations or structured representations extracted from Wikipedia, e.g. structures defined by the hyperlinks between the articles. This diversity prevents precisely positioning Wikipedia-based approaches all together at a unique place the measure classification provided in Figure 1.2 (page 17). In addition, as we will see, a particularity of Wikipediabased measures is that a large majority of them exploit hyperlink relationships between topics \u2013 a kind of proxy that, even if structured and informative, cannot be regarded as knowledge models (i.e. ontologies)55.\n50Pure-hybrid measures can also be part of the aggregation. 51Several aggregations will be discussed in the introduction of semantic similarity measures which can be used to compare groups of concepts \u2013 Section 3.5.2 52https://www.wikipedia.org 534 675 000 articles on 2015, January. 54Since May 2004. 55Contrary to texts and knowledge bases that have been denoted semantic proxies in Section 1.3.1, this proxy do not always convey semantics."}, {"heading": "3.8. MIXING KNOWLEDGE-BASED AND CORPUS-BASED APPROACHES 87", "text": "As far as the definition of semantic measures based on Wikipedia covers a lot of scientific works, for reading convenience, this section is organised with respect to the various techniques that have been proposed and the background knowledge they exploit:\n1. The graph structure that rely on hyperlink relationships defined between articles,\n2. The text content of these articles\n3. The underlying structured categories that are associated to each article.\nIt should be noted that all of these approaches aim at quantifying semantic relatedness between words, texts or Wikipedia topics (as we said, topics, also denoted articles, are sometimes considered as concept definitions).\nMeasuring semantic relatedness by exploiting Wikipedia\u2019s hyperlink relationships\nEach hyperlink of an article pointing towards another article indicates a relation between them. The semantics of this relationship is unknown but the target article is often assumed to help understanding the source article. This graph of hyperlinks between topics thus represents a substantial amount of (human) knowledge that is embodied into Wikipedia (Yazdani and Popescu-Belis, 2013)56. Several approaches have been proposed to extract information analysing this graph; some works consider the original orientation of links while other consider that they only traduce an association between topics and therefore consider the graph to be undirected.\nAccording to (Milne and Witten, 2008), leaving aside textual and hierarchical contexts to focus on hyperlinks (more than 90 million links), leads to intermediate solutions, faster than text-based ones and having quite good accuracy compared to knowledge-based measures. Wikipedia Link-based Measure (WLM57), the solution proposed by Milne and Witten, only takes into account hyperlinks among articles to assess the relatedness of two words. Using anchors found in the body of Wikipedia articles, they identify candidate article/word relations in the aim of characterising a word through a set of articles. Each article is represented by a list of incoming and outgoing links. Then, by comparing links, they deduce the semantic relatedness between articles. To achieve this, they defined the following measure:\nsr(a, b) = log(max(|A|, |B|))\u2212 log(|A \u2229B|)) log(|W |)\u2212 log(min(|A|, |B|)) (3.45)\nWhere a and b are the two articles of interest, A and B are the sets of articles linked to a and b respectively, and W is the entire set of Wikipedia articles. The relatedness between two words is then computed using sr to compare the sets of articles they are associated to.\nThe approach of (Turdakov and Velikhov, 2008) also proposes to compute relatedness58 between articles based on hyperlink analysis. The measure relies on the Dice coefficient; it also uses heuristics and statistical properties on the links included in the articles. The semantic relatedness between two articles is assessed according to their shared and distinct hyperlinks (i.e. linked articles):\ndice(a, b) = 2\u00d7 |A \u2229B| |A|+ |B| (3.46)\nWhere A (resp. B) is the set of articles linked to article a (resp. b) considering both incoming and outgoing links. In this approach the links are weighted according to some characteristics (e.g. symmetry) and some weights are related to the category structure associated with the articles (the category structure of Wikipedia will be discussed in Section 3.8.2). The heuristics they use proposes to reduce the search space according to the number of (incoming/outgoing) links an article has \u2013 this is done to avoid comparing all articles if the more similar have to be found. This relatedness measure leads to good results when applied to word sense disambiguation59. To this end, they proposed the following approach. For each word, the set of articles that contain the word in their title is identified (including disambiguation pages). The semantic relatedness between two words is then assessed according to the links their corresponding\n56Note that some of these links are automatically generated based on disambiguation techniques. 57This measure is one of the more cited in the literature. 58The authors also use the term similarity to describe their work but even if the distinction between similarity and relatedness is not clearly made in their contribution and may be discussed, we here consider that their approach assesses relatedness.\n59Good enough for (Rui-Qin, 2012) to simply copy this approach for words relatedness estimation."}, {"heading": "88 CHAPTER 3. KNOWLEDGE-BASED SEMANTIC MEASURES", "text": "articles share \u2013 only articles with the highest relatedness are taken into account. Despite the good results of these methods, it should be noticed that a previous phase including text analysis is needed to ensure word disambiguation. This may sometimes leads to high computation time due to the large number of articles to process.\nFor (Yeh et al., 2009), Wikipedia encyclopaedia contains articles in a variety of topics wide enough to allow some association between words that are apparently not related only considering a simple text analysis. They go further by claiming that the graph structure of Wikipedia provides some relatedness information not present in the text of the articles. Contrary to previous cited works that only consider the links included in the articles that are compared, they consider the whole graph composed of all the links within Wikipedia to assess the relatedness between texts. This graph is extracted using a random walk strategy. Vertices refer to articles while edges are defined by the hyperlinks among articles. Three types of links are distinguished:\n1. Infobox links \u2013 articles often contains infoboxes that enumerate attributes and characteristics for a given topic,\n2. Categorical links \u2013 links that refer to the category associated to a topic/article and thus provide hyponymic and meronymic information, this will be discussed in Section 3.8.2 below.\n3. Content links \u2013 all the other links.\nThis measure also relies on a generality attribute that encodes how much an article is more general than another. This attribute is computed by comparing the number of their incoming links \u2013 an article that is more specific than another one is assumed to have less incoming links. The semantic relatedness is then computed using personalised PageRank (random walk) algorithm (Hughes and Ramage, 2007), see Section 3.4. To apply personalized PageRank, it is necessary to construct a custom teleport vector representing the initial mass distribution over the article nodes. Two strategies are proposed to build this vector. The first one is based on a dictionary built either by using the article titles or extracted anchors given by WMiner (Lokeshkumar and Sengottuvelan, 2014). This dictionary is then filtered in different ways for their tests. They observed that smaller graphs might lead to information loss: by pruning the dictionary, some entities are isolated and will not be taken into account during the relatedness calculus. The second strategy proposes to initialise the random walk by using Explicit Semantic Analysis (ESA) (Gabrilovich and Markovitch, 2009) and to analyse the whole set of articles. This latter strategy gives the best results and slightly improves the ESA method (that will be discussed in the next section).\nIn the meantime, Wubben and Van den Bosch argue that the graph extracted from Wikipedia is well adapted to relatedness assessment. They propose FLP (Free Link Path), a semantic relatedness metric based on the notion of shortest-path between two Wikipedia articles \u2013 the graph is composed60 of 2 million nodes (articles) and 55 million edges (internal links - links outside Wikipedia are ignored) (Wubben, 2008; Wubben and van den Bosch, 2009). All the articles are parsed to extract their titles and the outgoing links they contain. In the same time, an inverted index is built to associate to each article the incoming links and thus to extract the whole hyperlink graph. Using a breadth-first search over this graph, the shortest-path between articles is computed and the relatedness is derived from it. The results they obtained are interesting but are outperformed by vector-based approaches that will be presented in the next section.\nA similar approach is adopted by Yazdani et al. to compare texts using a random walk strategy on a generated graph61 (Yazdani and Popescu-Belis, 2011, 2013). In this graph the nodes are Wikipedia articles62, they are intended to represent concepts; links are either hyperlinks between articles or derived from similarity of content. For the latter, a word co-occurrence approach is used to represent text articles by vectors, a cosine similarity is then used to assess vector similarity. Each article is linked with the k most similar articles, with a weight that reflects this similarity score (k is set to 10 in their evaluation). The semantic relatedness of two concepts is then assessed by analysing their distance into the graph. To do this, an adaptation of the random walk method denoted Visiting Probability is used. Therefore, when two texts are compared, they are projected onto a set of nodes (Wikipedia articles) by using\n60In 2008. 61A distinction may be done here between what (Yazdani and Popescu-Belis, 2013) call concept network extracted from Wikipedia (each node is an article associated to a concepts and the links are the hyperlinks content in them) and a formal conceptual model (formalized taxonomy or ontology) that may be associated to Wikipedia but that will be discussed in Section 3.8.2.\n62As many other Wikipedia-based approaches, some pruning is done to keep only articles that correspond to proper concepts. Here all articles from the following categories are removed: Talk, Image, Template, Category, Portal and List, and also disambiguation pages."}, {"heading": "3.8. MIXING KNOWLEDGE-BASED AND CORPUS-BASED APPROACHES 89", "text": "aforementioned vector-based similarity. The semantic relatedness of these texts is then deduced based on the distances of their corresponding nodes. This method has been applied for text clustering with success \u2013 this, using several sets of parameters (e.g. weights attributed to the types of links). That makes the author underline the relevance of hyperlinks within this process. They also claim that, in the context of document clustering, random walk methods clearly outperform other methods, namely cosine similarity between the TF-IDF vectors of documents. However by mixing various strategies (vector-based measure, random walks and probabilistic adjustments) their method requires a lot of memory space and computational time. This approach has been improved, as exposed in (Yazdani and Popescu-Belis, 2013), in order to address this problem, among other things. Two truncation methods are proposed to make the algorithm tractable. In addition they propose to improve the Visiting Probability approach by integrating additional factors, such as the density of connections associated to articles. They also enlarge the scope of their evaluation and applied their work to word similarity, text similarity, document clustering/classification and information retrieval. By this way they demonstrate the generality of the knowledge resource associated to their approach and that this method provides a unified and robust answer to measuring semantic relatedness.\nRecently, (West et al., 2009; Singer et al., 2013) studied an original strategy that does not use the links themselves but the human navigational path on them. The authors argue that while many hyperlinks correspond to semantic links in Wikipedia, many other do not. \u201cLinks are often added based on the inclination of the author, rather than because the concepts are related\u201d (West et al., 2009). Therefore, other approaches only capture semantics from a limited set of people (Wikipedia editors) and neglect pragmatics, i.e. how Wikipedia is used (Singer et al., 2013). For the authors: \u201cHumans tend to find intuitive paths instead of necessarily short paths, while contrary an automatic algorithm would try to find a shortest path between two concepts that may not be as semantically rich and intuitive as navigational path conducted by a human\u201d. Their second argument lies in the nature of compared entities. Using such a method allows, for example, assessing semantic relatedness between an image and a textual page. Their experiments are based on the way people navigate on Wikipedia network. Observations have been gathered from online games played on Wikipedia; players have to reach an article from another unrelated article, only by clicking links in the articles that are encountered \u2013 the games that have been used are Wikispeedia63 for (West et al., 2009) or from Wikigame64 for (Singer et al., 2013). The measure proposed by West et al. is based on information theory after calculating a probability distribution over out-links of a current page. This method has some benefits, in particular its asymmetry may be interesting for some treatments. But it has also a major limit: only the distance between nodes (articles) that belong to a path that has been encountered during a game may be calculated. The authors argue that it is incremental but it is however limited to a small subset of Wikipedia. To overcome this limitation, (Singer et al., 2013) proposes a new way of calculating semantic relatedness between two concepts (articles) by using the similarity between their corresponding co-occurrence vectors. The underlying assumption is that word are semantically related if they share similar neighbours. Henceforth, two concepts may be compared even if they do not appear in the same path. The semantic relatedness between any Wikipedia concepts may hence be calculated; moreover, they have identified characteristics of navigational path that are most useful for its computing. An interesting thought about semantics of navigational path is described in (Singer et al., 2013). We will not report it here since it is a bit far from our purpose but we encourage the reader to refer to the original contribution for more details.\nIn a general manner, considering complexity, time calculus and correlation with human expert judgments, link-based Wikipedia semantic measures seem to be very efficient solutions. However they suffer from a noise problem. Indeed, as underlined by (Yeh et al., 2009), similar methods based, for example, on WordNet does not need pruning (i.e. cleaning) to compete with text-based methods. Yet, this pruning is necessary when using Wikipedia. It is due to the fact that links in Wikipedia may convey to marginal information with regard to the subject they are related to. A previous step of ad-hoc pruning is thus always needed before applying link-based methods. Therefore, (Yeh et al., 2009) argue that texts of Wikipedia provide a stronger signal than their link structure, which is in line with (Yazdani and Popescu-Belis, 2011) that recommends using both hyperlinks and lexical similarity links in order to take into account linguistic as well as extra-linguistic dimensions of texts.\n63http://cs.mcgill.ca/~rwest/wikispeedia/ 64http://www.thewikigame.com"}, {"heading": "90 CHAPTER 3. KNOWLEDGE-BASED SEMANTIC MEASURES", "text": "Text analysis of Wikipedia content and vector-based approaches\nAs explained in Chapter 2, corpus-based approaches estimate semantic relatedness using statistical analysis of collection of texts that must be large enough to ensure a correct characterisation of words. Wikipedia offers such a large corpus.\nInspired by Vector Space Models used in information retrieval, (Gabrilovich and Markovitch, 2007) proposed Explicit Semantic Analysis (ESA)65 to measure the semantic relatedness between words and texts (e.g. queries and documents) \u2013 this approach has briefly been presented in Section 2.3.2. In ESA, text meaning is represented into a high-dimensional space of concepts. Those concepts are derived from Wikipedia, once again each article of the encyclopaedia is considered to match a concept. Texts are processed to be represented as a vectors of Wikipedia concepts called interpretation vectors. To achieve this, ESA exploits a weighted inverted index extracted from Wikipedia articles, where weighted concepts are attached to words (the weights are function of TF-IDF measures). This inverted index allows, when parsing an input text, to associate to it a weighted vector of Wikipedia concepts by merging the concepts associated to each of the words it contains. The semantic relatedness between two texts is then assessed thanks to vector similarity measures applied to the interpretation vectors of the two texts. For two words a and b and their corresponding ESA vectors ~a and ~b, the relatedness is for instance given by their cosine similarity. This semantic interpretation of texts leads to disambiguate word senses since it takes into account the context of the neighbourhood of words. However, even if the results are very close to human judgements, when processing some datasets, the main drawback of this method is time calculus. Indeed, since all the articles have to be compared, the computation complexity is really high. This method has been extended in (Radinsky et al., 2011) where the authors present a new semantic relatedness model, Temporal Semantic Analysis (TSA). This method captures temporal information in addition to knowledge extracted from Wikipedia. While ESA represents word semantics as a vector of concepts, TSA uses a more refined representation. Each concept is no longer a scalar, but is instead represented as time series over a corpus of temporally-ordered documents. This attempt to incorporate temporal evidence into models of semantic relatedness is quite innovative and their evaluation shows that TSA provides consistent improvements over state-of-the-art results of ESA on multiple benchmarks.\nIn line with ESA, Zesch et al. suggested to apply concept vector based measure to assess semantic relatedness (Zesch et al., 2008). In their proposal, several popular resources are compared: Wiktionary, Wikipedia, English and German WordNets. Several approaches are studied, one relying on a pathbased approach, another one generalising the vector-based approach described above. We will focus here on the latter since it is the one used by the authors of (Zesch et al., 2008) to deal with Wikipedia content. They propose to capture the meaning of a word w using a high dimensional concept vector ~v = (v1, v2, . . . , v|W |), where |W | is the number of Wikipedia documents. The value vi depends on the number of occurrences of the word w in the article numbered i (e.g. using TF-IDF score). Each word being represented in this concept vector space, vector measures may be used to assess the relatedness of two words (e.g. cosine). The authors claim that this approach \u201dmay be applied to any lexical semantic resource that offers a textual representation of a concept\u201d. Using Wikipedia, they only take into account the first paragraph of the article considering that it contains shorter and more focussed information. From their comparative works, vector-based measures have proved to better perform than path-length ones when operating on collaboratively constructed resources. The choice of the resource is also discussed \u2013 it is showed that Wiktionary outperforms Wikipedia when ranking word pairs, even if it leads to lower performances on a German dataset.\nTo take into account the semantic wealth offered by the multiple languages spoken around the word would be of particular interest in many domains. In information retrieval, for example, one can search for images related to a specific subject and characterised in different language (e.g. a given dermatologic manifestation in the medical domain). The growing need for cross-lingual solutions for information retrieval, text classification or annotation, to cite a few, has been underlined in (Hassan and Mihalcea, 2009). The authors propose to address this challenge by exploiting the interlanguage links contained into Wikipedia (250 language versions exist). In order to achieve this, they propose an extension of the ESA approach (in which each article is considered to match a concept). To calculate the cross-lingual relatedness of two words, they measure the closeness of their concept vector representations, which are built from Wikipedia using an extension of ESA. Three major changes of ESA have been proposed. The first one concerns the relatedness metric. Instead of the cosine calculus between the vectors, they chose to apply a Lesk-like metric (briefly discussed in Section 2.4). This choice has been made to take into\n65This work is also one of the more cited in the Wikipedia-based measure literature. Due to the high quality of its results, it is often used as a way to derive a semantic representation of articles or words(Singer et al., 2013)."}, {"heading": "3.8. MIXING KNOWLEDGE-BASED AND CORPUS-BASED APPROACHES 91", "text": "account the possible asymmetry between languages. With a and b two words and ~A and ~B their ESA concept vectors, we denote A and B the sets of concepts with a non-zero weight encountered in ~A and ~B respectively. The coverage of ~A by ~B is defined by:\nG( ~A| ~B) = \u2211\nt\u2208B \u03c9ci(a) (3.47)\nWith \u03c9ci(a) the weight associated to the concept ci in vector ~A. The relatedness between two words a and b is defined by:\nrelHassan(a, b) = G( ~B| ~A) +G( ~A| ~B)\n2 (3.48)\nThe second change they suggest is to modify the weight calculus of ESA in order to take into account the length of the articles that are associated to a concept. Instead of giving as weight the TF-IDF value associated with a concept ci they propose to use:\n\u03c9ci(a) = tfi(a)\u00d7 log( M\n|ci| ) (3.49)\nWith tfi(a) the term frequency of the word a in the concept ci (i.e. in the related article), M a constant representing the maximum vocabulary size on Wikipedia concepts and |ci| the size of the vocabulary used in the description of the concept ci.\nThe last change concerns the use of Wikipedia category graph (see following section). The weight is scaled by the inverse of the distance di of the concept category (category associated with the concept ci) to the root one.\n\u03c9ci(a) = tfi(a)\u00d7 log( M|ci| )\ndi (3.50)\nThe cross-lingual relatedness is then computed as follows. Given Cx and Cy the sets of all Wikipedia concepts in languages x and y. If trxy : Cx \u2192 Cy is a translation function that maps a concept ci \u2208 Cx to a concept c\u2032i \u2208 Cy via the interlanguage links. The projection of the ESA vector ~t from the language x to the language y can be written: trvecxy (~t) = {\u03c9trxy(c1), . . . , \u03c9trxy(cn)}. The relatedness between two words ax and bx in given languages x, y is then defined by:\nrelcrosslingual(ax, by) = G(trvecxy ( ~B)| ~A) +G( ~A|trvecxy ( ~B))\n2 (3.51)\nIf the relation described by the interlanguage links is assumed to be reflexive, in practice it is not always the case since users are accredited with the responsibility of maintaining these links. A pretreatment is applied to detect the missing links and enforces the reflexivity property. Even if the results vary from a language to another according to the coverage conveyed by Wikipedia in these languages (the number of pages and the number of interlanguage links), the correlations obtained by this method on well-known benchmarks slightly outperforms results obtained by monolingual measures.\nA recent work bridges the two research streams presented in both previous sections. It consists in using frequency occurrences and link probability to assess relatedness between words (and by extension between texts) (Jabeen et al., 2013). This CPRel method (Context Profile based Relatedness) relies on a context profile extracted from Wikipedia and that is associated to each word. Wikipedia articles are filtered to keep only relevant words and links that point towards another Wikipedia article. The match between a word and article titles is done using Link Probability (LP) [Mihalcea et al. 2007]. Once a set of articles is associated to a word, they are weighted according to their term frequency (based on TF calculus) and link probability. These weights define a vector representation of the word into the space of articles. The relatedness between two words is then computed using cosine similarity. On some benchmark their results are comparable with other Wikipedia-based approaches but ESA performs best overall.\nWikipedia relies on a category organisation that may be used to measure semantic relatedness\nAs we saw, in addition to text articles, Wikipedia stores a great deal of information about the relationships between the articles in the form of hyperlinks, info boxes and category pages (Yeh et al., 2009). In the contributions presented in the previous sections, authors often assimilate Wikipedia articles to"}, {"heading": "92 CHAPTER 3. KNOWLEDGE-BASED SEMANTIC MEASURES", "text": "concepts since articles are considered to define a particular entity. However, the structure offered by the hyperlink relationships between them cannot be regarded as knowledge models (i.e. ontologies). In this section, we are really talking about a knowledge organisation that is composed of Wikipedia categories structured through conceptual relationships (e.g. hyponymy, meronymy). Wikipedia\u2019s categories have been collaboratively developed and used to tag Wikipedia articles. They are assigned to pages in order to group together those discussing similar subjects. They are next used to help readers to find an article or to navigate on related ones. Wikipedia\u2019s categories have been standardised and organised by unambiguous relationships \u2013 the structure organizing the categories can indeed be regarded as a light ontology. These categories are therefore of particular interest for semantic similarity calculus since they provide a way to compare topic articles not only using corpus-based measures, but also using semantic measures based on knowledge organization (in particular those introduced in Section 3.4).\nThe first authors that have used the structure of Wikipedia\u2019s categories to assess semantic similarity or relatedness of words were (Strube and Ponzetto, 2006). In their WikiRelate! method, words are first mapped to articles; this is done by analysing the titles and the hyperlinks of articles. Then words are compared considering two features of the texts they are associated to: (i) their content overlap (using an adaptation of aforementioned Lesk\u2019s measure) and (ii) the relatedness of their Wikipedia categories \u2013 several measures have been tested (Rada, Leacock and Chodorow, Wu and Palmer, Resnik measures, please refer to Section 3.4 for an introduction to these measures). They obtain good results on datasets of human judgements, which make them stress the benefits of using the categories organisation for designing Wikipedia-based semantic measures.\nWithin their BabelRelate! method, (Navigli and Ponzetto, 2012) further explore the hybrid approach of semantic relatedness between two words by using BabelNet, a very large multilingual lexical knowledge resource that integrates Wikipedia and WordNet (Navigli and Ponzetto, 2010). This solution combines the analysis of the graph of word senses by using a graph-based algorithm (a kind of node counting strategy). By using the whole graph containing word translations, they are able to prune parts of the graph that are the result of ambiguity and polysemy in the input language (infrequent senses, noisy relations). This strategy helps to rapidly characterise the subgraph that represents the core semantic of words, i.e. the most frequent translations, senses, in all languages. The relatedness is then assessed by analysing these graphs. Interestingly, the authors argue that, contrary to the method defined by (Hassan and Mihalcea, 2009), their proposal does not suffer from unbalanced performance across languages since it is based on a unique and common resource (BabelNet). They also observed that the more languages are used, the better the results.\nFinally, in (Taieb et al., 2013), a system combining all semantic information in the different components of Wikipedia (articles, graph of hyperlinks, category organisation) is presented to compute the semantic relatedness between words. A pre-processing step provides for each Wikipedia category a semantic description vector (named CSD for Category Semantic Depiction). It is computed by considering the weights of stems extracted from the articles assigned to the target category. Then, a vector representation of a word is derived analysing the CSDs of the set of all categories it is associated to. Finally, the semantic relatedness of two words is assessed according to the similarity of their respective vectors (e.g. using Dice, overlap and cosine measures). This approach performs well and even sometimes outperforms ESA.\nWith an increasing quality and coverage, Wikipedia is an undeniable worldwide success. As we saw in this section, by providing a free multi-language encyclopaedia in which topics are interlinked, organised by structured categories and finely characterised (e.g., using infoboxes), the several facets of Wikipedia are of particular interest and have proved to be particularly helpful in the design of accurate semantic measures. Wikipedia has always been a catalyser of new semantic measure design and will, for sure, continue to be. Research tracks related to this unique resource are numerous. As an example, through the definition of DBpedia (Auer et al., 2007), recent contributions in Knowledge Representation and Information Extraction have proved that Wikipedia can also be used to generate large knowledge bases. This will help us to finely structure and characterise Wikipedia content, and to better capture the semantic interactions between the underlying concepts associated to articles. Interestingly, by obtaining such a large knowledge base and its associated natural language counterpart, a new kind of hybrid semantic proxy will arise and will probably open both interesting and promising perspectives for semantic\n3.9. CONCLUSION 93\nmeasures.\nSoftware solutions and source code libraries that provide knowledge-based semantic measures implementations are presented in Appendix D. Information about evaluation protocols and datasets that can be used to compare these measures are also provided in Chapter 4."}, {"heading": "3.9 Conclusion", "text": "This chapter introduced the reader to the diversity of knowledge-based measures which can be used to compare concepts or instances defined into ontologies. We focused in particular on the measures which are based on the analysis of a graph representation of the ontology, i.e. the strategy commonly adopted to define knowledge-based measures. We proposed an in-depth analysis of the measures which can be used to assess the similarity of concepts defined in a taxonomy. By analysing these measures we distinguished the semantic evidence which can be extracted from ontologies. We next presented in detail the three main types of measures, i.e., structure-based, feature-based and those based on informationtheoretical approaches. This helped us to highlight the foundation of knowledge-based semantic measures and to discuss the core elements of these measures. Next, we briefly introduced the measures which rely on complex logic-based construct analysis and those which rely on the analysis of several ontologies. Finally, we defined the advantages and limits of knowledge-based measures and we introduced some hybrid-measures which have been proposed to mix corpus-based and knowledge-based measures.\n94 CHAPTER 3. KNOWLEDGE-BASED SEMANTIC MEASURES\nChapter 4\nMethods and datasets for the evaluation of semantic measures\nThis chapter is dedicated to semantic measure evaluation and discusses in particular two important topics: (i) how to objectively evaluate measures and (ii) how to guide their selection with regard to specific needs. To tackle these central questions, we propose technical discussions on both methodological and practical aspects related to semantic measure evaluation. This will help us to underline, among others, the properties of measures that must be considered for their analysis. An overview of the underlying mathematical frameworks that can support measure evaluation and a detailed discussion of existing evaluation protocols are also provided. Concrete examples of datasets used to evaluate semantic measures in the literature are next introduced. The various topics discussed in this chapter are suited for both research and practical purposes, e.g. they are adapted to measure designers willing to evaluate new proposals, as well as users seeking for existing solutions adapted to their needs.\nDespite its central importance \u2013 considering the large diversity and the widespread use of semantic measures \u2013 the topic of measure evaluation is far from being extensively discussed in the literature. To overcome this substantial lack, this chapter proposes to aggregate a large body of literature in order to provide an overview of state-of-the-art approaches and resources available. However, considering the width of this topic and the diversity of approaches that have been explored to evaluate measures, this chapter will not propose an in-depth analysis of all relevant aspects of measures that can be discussed for their evaluations. In addition, even if some references to interesting state-of-the-art comparisons are provided, we will not analyse, cross and aggregate existing results to summarize measure performances in different evaluation settings.\nThe first section of this chapter discusses the problems of semantic measure evaluation and selection in a general manner. Section 2 presents several criteria of measures that can be considered for their evaluations. Section 3 introduces the protocols and datasets that are commonly used to evaluate measure accuracy. Finally, Section 4 concludes this chapter by highlighting its important teaching and by discussing, among others, the open challenges related to this important topic."}, {"heading": "4.1 A general introduction to semantic measure evaluation", "text": "In general terms, any evaluation aims to distinguish the benefits and drawbacks of the compared alternatives according to specific criteria. Such comparisons are most of the time used to rank the relevance of using an alternative in a specific usage context regarding a set of criteria \u2013 in our case the alternatives are the measures. Semantic measures can be evaluated with regard to theoretical or empirical properties. Based on these evaluations, comparison will be made possible considering a way to (i) compare the values of considered properties and (ii) to aggregate these comparisons. This underlines the strong dependency that exists between the criteria that are considered for the evaluation and the conclusions that can be obtained. Indeed, as we will see in this chapter, an important notion to understand is that there is no best semantic measure in absolute. There are only measures that outperform others in specific conditions. Even if this does not prevent the fact that specific measures may outperform other measures in most of (experimental) conditions, it makes clear that conclusions about measure performance will be difficult to generalise. Indeed the set of criteria to consider and the way to interpret the values taken for each of these criteria strongly depend on the purpose of the comparison, e.g. comparing measures in\n95"}, {"heading": "96 CHAPTER 4. EVALUATION OF SEMANTIC MEASURES", "text": "order to distinguish the one which is the best adapted to a specific use case. Considering that measure evaluation can only be made considering specific aspects of them, prior to compare a set of alternatives, a user which is searching for a measure must pay attention to carefully analyse his needs. It will for instance not be possible to distinguish the measure a user must use \u201cto compare two concepts defined into an ontology\u201d, or \u201cto compare two terms\u201d without defining: the constraint the measure must respect (e.g. symmetry), the information which is available (e.g., corpora, knowledge bases), and what the elusive objective to compare two concepts/terms means for him, i.e. are we talking about semantic similarity / relatedness, etc. Users must understand that answering these questions may be critical to distinguish a measure that is adapted to their needs.\nThe comparison of measures is therefore only possible considering a set of criteria and a way to compare and to aggregate these criteria. The latter are defined by the use case that motivates the comparison. Considering this intuitive but important remark, three important questions arise in the aim of comparing semantic measures:\n1. What are the criteria that can be used?\n2. How to evaluate the relevance of a measure regarding a specific set of criteria?\n3. Which criteria must be considered to evaluate measures in a specific context?\nEven if a complete answer to these three questions cannot be provided only considering existing research contributions \u2013, and could alone justify a complete textbook \u2013, this section proposes substantial material and reflections in the aim of contributing and better understanding semantic measure evaluation and comparison."}, {"heading": "4.2 Criteria for semantic measure evaluation", "text": "Several criteria can be used to analyse semantic measures. Some can be studied theoretically while others require empirical analyses. Among the criteria that are the most frequently considered evaluating semantic measures, we distinguish their:\n\u2022 Accuracy, precision and robustness.\n\u2022 Computational complexity, e.g., algorithmic complexity.\n\u2022 Mathematical properties.\n\u2022 Semantics.\n\u2022 Characterisation regarding technical details.\nThese criteria can be used to discuss numerous facets of semantic measures. They are detailed in corresponding subsections."}, {"heading": "4.2.1 Accuracy, Precision and Robustness", "text": "The accuracy of a measure can only be discussed according to predefined expectations regarding the results produced by the measure. Indeed, as defined in the field of metrology, the science of measurement, the accuracy of a measurement must be understood as the closeness of the measurement of a quantity regarding the (actual) true value of that quantity (BIPM et al., 2012). As we have seen when defining semantic measures, the quantities estimated by semantic (similarity, relatedness, etc.) measures, even if they may be intuitive, are today only weakly characterised by abstract terms \u2013 in comparison to quantities commonly measured in other fields, e.g. inertial mass in Physics. In addition, as stressed when semantic measures have been introduced in Chapter 1, formal definitions may only be considered when a system of formal definitions will be accepted and adopted by the various researchers studying this broad topic. The possibility to reach such an objective is still an open research topic. As we will see, this intuitive and volatile nature of semantic measures has deep implications for their evaluation.\nIndeed, it is important to stress that evaluating accuracy of semantic measures is made difficult by the fact that the true value of a semantic measure (similarity, relatedness, etc.) is unknown; and, more importantly, may not exist. The notion of similarity of terms or concepts is by nature a subjective notion. As an example, there is no, per se, true value associated to the semantic relatedness between the two"}, {"heading": "4.2. CRITERIA FOR SEMANTIC MEASURE EVALUATION 97", "text": "concepts Communism and Freedom. Disregarding as much as possible philosophical considerations, it can be said that concepts are in our mind and that there are as many true values of semantic measures as concept representations of pairs of compared concepts (i.e. individuals).\nTherefore, the accuracy of semantic measures is generally evaluated by considering averaged expectations regarding their values, that is to say, by considering consensual values of the quantities they try to capture. This is generally made by analysing human expectations of semantic similarity/relatedness/etc., and by considering averaged values of these expectations. As an example, measures will be compared to scores of semantic relatedness of word pairs that have been assessed by humans into a specific scale, e.g. 0-4 \u2013 several datasets of this kind will be introduced in Section 4.3.2 . Thus, according to the implicit considerations made in the literature, the accuracy of a semantic measure is often considered as the closeness of its measurement with the averaged human expectations. Correlations are preferred to distances between measurements and average experts\u2019 assessments because they only take into account the way the two signals behave instead of too arbitrary absolute values. In this case, the accuracy is generally defined as the Pearson\u2019s correlation coefficient r. Considering that expected and measured values are contained into two vectors x and y of size n, the Pearson correlation r is defined by:\nr(x, y) = \u2211n i=1(xi \u2212 x)(yi \u2212 y)\u221a\u2211n\ni=1(xi \u2212 x)2 \u221a\u2211n i=1(yi \u2212 y)2 (4.1)\nPearson\u2019s correlation is a linear correlation; less frequently, non-linear correlations are studied, e.g. in (Shen et al., 2010).\nSometimes, the accuracy of a measure is only evaluated by analysing the ordering of the pairs that is induced by their scores of similarity/relatedness. In this case evaluations are made using Spearman\u2019s correlation, e.g. in (Huynh et al., 2014; Maguitman and Menczer, 2005; Pedersen et al., 2007; Pesaranghader et al., 2014). Considering two vectors x and y of size n that specify respectively the expected and estimated rank of each pair, Spearman\u2019s correlation \u03c1 is defined by:\n\u03c1(x, y) = 1\u2212 6 \u2211n i=1 (xi \u2212 yi)2 n(n2 \u2212 1) (4.2)\nAdaptations of this definition are also often considered in order to evaluate measure accuracy indirectly, that is to say, using datasets that do not directly refer to human expectations regarding measured notions. In this case, the accuracy of a measure is often indirectly evaluated by evaluating (the accuracy of) a system that depends on it. As an example, the aim of such a system may be to resolve a classification problem \u2013 e.g. by considering (i) that the degree of membership of an item to a class is defined as a function of its similarity with the gravity centre of the class, and (ii) that the class to which an item will be affected to is the class for which the item has the highest membership degree. Using this approach, systems are generally evaluated studying their accuracy, using the traditional formula of accuracy:\naccuracy = #(true positive) + #(true negative)\n#(true positive, true negative, false positive, false negative) (4.3)\nWith #(X) the number of elements assigned to class X, e.g. #(true positive) is the number of elements which have been correctly classified by the system.\nIn all cases, the notion of accuracy of a measure is per se defined according to a context, e.g., the true values considered, the semantic proxy (specific corpus, ontology, etc.), the tuning of the measure parameters (if any). Indeed, there is no guarantee that a measure that has been proved accurate in a specific evaluation setting will be accurate in other settings. The accuracy of a particular semantic measure tuning can therefore only be discussed with regard to a specific usage context, without absolute guarantee that the results that are obtained can be generalized to other usage contexts \u2013 even if empirical analyses have shown that specific measures tend to outperform others in many contexts.\nThe precision of a measure (or more generally any system of measurement) corresponds to the degree of reproducibility or repeatability of the score produced by the measure under unchanged conditions. Since most semantic measures are based on deterministic algorithms, and therefore produce the same result given a specific input, evaluating the precision of a measure generally makes no sense. Evaluations of semantic measures therefore focus most of the time on the notion of accuracy. We will further discuss the precision of a measure as a mathematical property. Nevertheless, when a measure is evaluated analysing the precision of a system depending on it, e.g. a classification system, the precision will be defined by:\nprecision = #(true positive)\n#(true positive, false positive) (4.4)"}, {"heading": "98 CHAPTER 4. EVALUATION OF SEMANTIC MEASURES", "text": "Accuracy and precision can be used to estimate the performance of a measure according to expected results. As we said, these results are only valid in a very specific evaluation setting \u2013 which depends on the dataset, measure parameters and resources (text corpora, knowledge base, etc.) that are considered. Nevertheless, these criteria alone may not be sufficient to analyse measure performance. For instance, most of the time, nobody will be able to ensure that expected results that are considered into a specific dataset are not impacted by uncertainty \u2013 and that they will be the same if the benchmark was obtained using other participants. Therefore, intuitively, rather than only considering the measure which best performs according to specific expected results (provided by humans), most system designers will prefer to use a simply satisfying measure which, in revenge, would still ensure a good performance even if human assessments were slightly different. Imprecision and variability in human evaluations, as well as any disturbances that may affect the human assessment process support this cautious behaviour. Put another way, evaluation protocols must also take into account the capacity for a measure to produce robust scores considering the uncertainty related to the way the human expected similarity values have been obtained, or disturbances of the semantic proxies on which relies the measure (modification of the ontologies, corpora).\nIn this context, it is important to know how sensible/robust measure performances are to perturbation of evaluation settings. This aspect of a measure can be evaluated by analysing its robustness. It has been studied in (Janaqi et al., 2014); the authors propose a framework that can be used to evaluate semantic measure robustness, e.g. by disturbing expected results by an uncertainty model \u2013 technical details are not provided herein. To date, the robustness of semantic measures has only faintly been analysed and only few comparisons have been proposed."}, {"heading": "4.2.2 Computational complexity", "text": "The computational complexity of semantic measures is of major importance in most applications. Indeed, considering the growing volumes of datasets processed in semantic analysis (large corpus of texts and knowledge bases), this aspect is most often critical for concrete usages of semantic measures.\nAs an example, considering alternatives with equivalent performances in a specific evaluation setting, most system designers will prefer to make moderate concessions on measure accuracy for a significant reduction of computational time. Indeed, reducing the expectation on measure accuracy may lower the final performance of a system, although using a measure with a strong computational complexity may simply prevent its use, e.g. information retrieval systems often depend on semantic measure computations that are made on-the-fly.\nHowever, the literature relative to the computational complexity of semantic measures is very limited. In particular, the algorithmic complexity of semantic measures, i.e. the amount of resources required (e.g. time, storage), is most of the time never analysed \u2013 the paper of Turney and Pantel (2010) is among the exceptions. It is therefore difficult to discuss algorithmic implications of current proposals. This hampers non-empirical evaluations of measures and burdens measure selection. It is nevertheless difficult to blame semantic measure designers for not providing detailed algorithmic analyses of their proposal. First, these extensive analyses are both technical and difficult to make. Second, they are only possible for specific cases as they depend on technical considerations that exceed semantic measure definitions, e.g., the type of data structures used to represent the semantic proxy on which rely the measures, the algorithm used in specific treatments (e.g. graph traversals). This later point may create a gap between theoretical capabilities of measures and computational complexity of their practical implementations into software.\nThe reader must therefore understand that, to date, and despite the major importance of the computational complexity of measures, evaluation and comparison of measures regarding this criterion is difficult and most of the time not possible. Nowadays, comparisons of measures regarding this specific aspect most often rely on empirical evaluation of specific measure implementations. For an example of such a comparison in a specific setting you can refer to https://github.com/sharispe/sm-tools-evaluation."}, {"heading": "4.2.3 Mathematical properties", "text": "Several mathematical properties that are of interest for characterising semantic measures have been distinguished in Section 1.2.3, e.g., symmetry, identity of the indiscernibles1, precision (for non-deterministic measures), and normalization. These properties enable to deeply characterize semantic measures and to select proposals adapted to specific usage contexts. Indeed, specific properties may be required to ensure the coherency of treatments depending on semantic measures. As an example, considering that\n1i.e. does not return the maximal similarity when comparing a term/concept to itself."}, {"heading": "4.2. CRITERIA FOR SEMANTIC MEASURE EVALUATION 99", "text": "a measure is not symmetric or does not respect the identity of the indiscernibles can lead to undesired results and therefore may be inappropriate for some applications.2 Some of these mathematical properties are also essential to apply specific optimization techniques in order to reduce the computational complexity of measures while ensuring valid results. In addition, and this is a critical point that will be discussed hereafter, these properties play an important role to finely characterise the semantics carried by measures, i.e., the meaning of the results the measures produced."}, {"heading": "4.2.4 Semantics", "text": "The meaning (semantics) of the results obtained by a measure must be carefully considered when selecting a measure. This semantics is defined by the assumptions on which relies the algorithmic design of the measure. Some of these assumptions can be understood through the mathematical properties of the measure. The others are defined by the cognitive model on which the measure is based, the semantic proxy in use and the semantic evidence analysed. As saw in Section 1.3.1, the semantic evidence taken into account by the measure defines its type and therefore its general semantics (e.g., the measure evaluates semantic similarity, relatedness, etc.) \u2013 it therefore largely impacts the results.\nIt is however difficult to finally compare measures regarding the semantics they carry. Nevertheless, it is essential for end-users to understand that measure selection may in some case strongly impact the conclusions that can be supported by the measurement (e.g. semantic similarity, relatedness, etc.). As an example, designing a recommendation system that will return items considering the focal concept Coffee may return completely different results depending on the semantic of the measure; if it is a semantic similarity the system will favour results that can (partially) substitute Coffee, e.g.Arabica, Tea, Hot Chocolate, while using a semantic proximity it will not only return beverages but also close concepts, e.g. Cup, Coffee bean."}, {"heading": "4.2.5 Technical details", "text": "What we denote technical details are the several extra-parameters that have to be considered when choosing semantic measures for a specific usage context. Some of them are not relevant for comparing measure proposals but may play an important role when a measure has to be used in specific applications. They may therefore be of interest for designers of systems that rely on semantic measures. Among the numerous technical details that have to be considered we distinguish:\n\u2022 The availability of supported implementations of the measure and the license associated to these implementations. Some measures require technical and substantial work in order to be implemented. When comparing measures for a specific application, it may therefore be important to reduce the set of alternatives that are considered according to this practical aspect. Appendix D presents numerous software tools that provide implementations of state-of-the-art-measures.\n\u2022 The dependency of the measure to specific resources (knowledge base, corpora, training datasets). Are these resources freely available in the domain of interest? In addition, the end-user must consider the sensibility of measure accuracy on these resources (if reported).\n\u2022 The availability of several evaluations that support the performance of the measure in multiple evaluation settings.\nSome aspects of measures that have been discussed in this section (e.g. accuracy) may be evaluated empirically using specific datasets. The following section details protocols that are generally adopted to evaluate semantic measures. Datasets that are commonly used are next presented.\n2It is however the case using particular measures in specific contexts. As an example using Resnik\u2019s measure to compare concepts defined into a taxonomy (c.f. Section 3.4.3), the similarity of a general concept (near to the root) to itself will be low.\n100 CHAPTER 4. EVALUATION OF SEMANTIC MEASURES"}, {"heading": "4.3 Existing protocols and datasets", "text": "In the literature, accuracy of semantic measures is generally considered as the de-facto metric to evaluate and compare measure performance. It can be evaluated using a direct or an indirect approach depending on the expected scores (true values) that are considered. In this section, we detail the protocols commonly used to evaluate measures using the two approaches. Then, we present numerous datasets that can be used to compare measures."}, {"heading": "4.3.1 Protocols used to compare measures", "text": "In most cases, accuracy of measures is evaluated using a direct approach, i.e., based on expected scores of measurement (e.g., similarity, relatedness) of pairs of terms/concepts. In other cases, measures are evaluated indirectly, by analysing results of treatments which depend on semantic measures. In all cases, the evaluation of measure accuracy is performed regarding specific expectations/assumptions of expected results:\n\u2022 Direct evaluation: based on the correlation of semantic measures with expected scores. Measures are generally evaluated regarding their capacity to mimic human ratings of semantic similarity/relatedness. In this case, the accuracy of measures is discussed based on their correlations with gold standard benchmarks composed of pairs of terms/concepts associated to expected ratings. Results are commonly evaluated using Pearson\u2019s and Spearman\u2019s correlations. Figure 4.1 illustrates the direct evaluation approach.\n\u2022 Indirect evaluation: This evaluation highly depends on the domain of study, e.g. NLP, Bioinformatics. Figure 4.2 illustrates the approach. Two strategies can be applied:\n1. The first one evaluates measure accuracy analysing the performance of applications or algorithms which depend on semantic measures, e.g., accuracy of term disambiguation techniques, performance of a classifier or a clustering approach relying on semantic measures to mention a few. As an example, considering that the measure is evaluated through the analysis of disambiguation algorithm, the object of study would be the terms in specific (sentential) contexts; the expected results would be the mappings between the terms and their disambiguated forms and the results obtained would be produced by a disambiguation system based on the evaluated measure. In this scenario, the performance of the measure will be discussed with regard to the performance of the disambiguation process, i.e. the semantic measure that permits to obtain the best results (fixing the other parameters) will be considered to be the best in this context. Therefore, the method used to compare expected and obtained results depends on the type of the results considered.\n2. The second strategy works by analysing the correlation of measures with domain-specific metrics that are expected to behave like semantic measures in specific contexts. As an example, in Bioinformatics, semantic measures are designed to compare gene products according to their conceptual annotations. Evaluations have been made by comparing correlations between\n4.3. EXISTING PROTOCOLS AND DATASETS 101\nscores of measures and the similarity of gene evaluated according to their DNA sequences (Lord et al., 2003).\nIn the following section different datasets that can be used to compare semantic measures are presented in a syntactic manner. Then each one is detailed with regard to specific properties."}, {"heading": "4.3.2 Datasets", "text": "Most of datasets are based on human-ratings and are composed of pairs of terms/concepts for which humans have been asked to assign scores of semantic similarity or relatedness. The instructions provided to the participants vary among the datasets. These variations may impact the notion of similarity or relatedness considered by the participants. Generally, the quality of a dataset is assessed by analysing inter-agreement of participants, i.e. how scores of participants correlate. This inter-agreement also defines the level of accuracy measure designers may go after. These datasets can be used to evaluate measures according to a direct approach, i.e. regarding the (Pearson\u2019s or Spearman\u2019s) correlations of measures with averaged scores provided by humans. In some cases, cleaning techniques are applied to exclude abnormal ratings (outliers) from the datasets prior to the evaluation.\nSeveral datasets are listed in Table 4.1 \u2013 they are organised in chronological order. The large majority of them are in English. Some have been manually or automatically translated into other languages or mapped to knowledge bases (e.g. WordNet). In this case, word pairs are (manually) mapped to unambiguous pairs of concepts in order to be used to evaluate knowledge-based semantic measures3. Some datasets are also dedicated to specific domains (e.g., medicine) and other focus on specific type of words (e.g. verbs, rare words).\n3In most cases, the concepts associated to the terms are not communicated in contributions related to knowledgebased semantic measures. In some cases, words are mapped to multiple concepts and the best score is considered for the evaluation, in accordance with the fact that annotators seem to consider the closest sense pair when evaluating the similarities (Mohammad and Hirst, 2012b). Nevertheless, these particular cases are poorly documented in the literature.\n102 CHAPTER 4. EVALUATION OF SEMANTIC MEASURES\nR e fe\nre n\nc e s\nT y p\ne o f\ne v a lu\na ti\no n\nS iz\ne In\nte r-\na g re\ne m\ne n t\nP ea\nrs o n\n(r ),\nS p\nea rm\na n\n(\u03c1 )\n(R u\nb en\nst ei\nn an\nd G\no o d en ou g h , 19 65 )\nS em\na n ti\nc si\nm il\na ri\nty o f\np a ir\ns o f\nn o u\nn s\n6 5\nr =\n0 .9\n9 o n\nav g .\nva lu\nes o f\ntw o\ng ro\nu p\ns. In\ntr a -a\ng re\nem en\nt r = 0. 8 5\n(M il\nle r\nan d\nC h\nar le\ns, 19\n91 )\nS em\na n ti\nc si\nm il\na ri\nty o f\np a ir\ns o f\nn o u\nn s\n3 0\nr =\n0. 8 8 4 8\nT O\nE F\nL (L\nan d\nau er\nan d\nD u\nm ai\ns, 19\n97 )\nS em\na n ti\nc S\nim il\na ri\nty o f\nw o rd\ns u sin g sy n o n y m y q u es ti o n\ns 8 0\n5 2 .7\nW or\nd S\nim 3 53\n(F in\nke ls\nte in\net al\n., 2 00\n2) S\nem a n ti\nc re\nla te\nd n\nes s\no f\np a ir\ns o f\nn o u\nn s.\nT w\no se ts 1 5 3 / 2 0 0\n\u03c1 =\n0. 6 6 1\nE S\nL (T\nu rn\ney ,\n20 01\n) S\nem a n ti\nc si\nm il\na ri\nty o f\nw o rd\np a ir s b a se d o n sy n o n y m y q u es ti o n\ns 5 0\nN o t\nfo u\nn d\n(T u\nrn ey\net al\n., 20\n03 )\nS A T an al og y q u es ti on s\nS em\na n ti\nc si\nm il\na ri\nty o f\nw o rd s b a se d o n a n a lo g y q u es ti o n\ns 3 7 4\nN o t\nfo u\nn d\n(J ar\nm as\nz an\nd S\nzp a ko\nw ic z, 20 0 3a ) S\nem a n ti\nc si\nm il\na ri\nty b\na se\nd o n\nsy n\non y m\nd et\nec ti\no n\np ro\nb le\nm s\n3 0 0\nN o t\nfo u\nn d\n(B oy\nd -G\nra b\ner et\nal .,\n20 06\n) S em\na n ti\nc re\nla te\nd n\nes s\no f\np a ir\ns o f\nW or\nd N\net S\ny n\nse ts\n1 0 0 0 0 0\nC f.\np a p\ner 4\nG u\nr6 5\n(G u\nre v y ch\n, 20\n05 )\nG er\nm a n\nve rs\nio n\no f\nR u\nb ei\nn st\nei n\n& G\no o d\nen o u\ng h\nb en\nch m\na rk\n6 5\nr =\n0. 8 1\nG u\nr3 50\nd at\nas et\n5 S\nem a n ti\nc re\nla te\nd n\nes s\no f\nG er\nm a n\nw or\nd p\na ir\ns 2 2 2\nr =\n0. 6 9\nZ G\n22 2\nd at\nas et\n(Z es\nch an d G u re v y ch , 20 06 )\nS em\na n ti\nc re\nla te\nd n\nes s\no f\nG er\nm a n\nw or\nd p\na ir\ns 3 5 0\nr =\n0. 4 9\n(P ed\ner se\nn et\nal .,\n20 07\n) S em\na n ti\nc re\nla te\nd n\nes s\nb et\nw ee n m ed ic a l w o rd\ns6 2 9\nF o r\n1 0 1\np a ir\ns r\n= 0 .5\n1 F\no r\n2 9\np a ir\ns r\n= 0 .6\n8 (p\nh y si\nci a n\ns) r = 0. 7 8 (c o d er s)\n(P ak\nh om\nov et\nal .,\n20 10\n) S em\na n ti\nc si\nm il\na ri\nty a n\nd re\nla te\nd -\nn es\ns o f\np a ir\ns o f\nU M\nL S\nco n\nce p ts (m ed ic a l d o m a in )\n5 6 6\n(s im ) 5 8 7 (r el\n) r\n= 0.\n5 0\n(s im\n) r\n= 0.\n4 7\n(r el\n)\n4 S\np ec\nifi c\nd et\na il\ns h\na v e\nto b\ne co\nn si\nd er\ned .\n5 D\nes cr\nib ed\nin h t t p s : / / w w w . u k p . t u - d a r m s t a d t . d e / d a t a / s e m a n t i c - r e l a t e d n e s s / g e r m a n - r e l a t e d n e s s - d a t a s e t s\n6 A\nsu b\nse t\no f\n2 9\np a ir\ns w\nit h\nh ig\nh er\nin te\nra g re\nem en\nt is\ng en\ner a ll\ny co\nn si\nd er\ned a m\no n\ng th\ne 1 0 1\np a ir\ns.\n4.3. EXISTING PROTOCOLS AND DATASETS 103\nC on\nce p\ntS im\n(S ch\nw ar tz an d G om ez , 20 11 )\nS em\na n ti\nc si\nm il\na ri\nty o f\np a ir\ns o f\nW or\nd N\net sy\nn se\nts .\nD is\na m\nb ig\nu a te\nth e\np a ir\ns o f\nn o u\nn s\no f\nR u\nb en\nst ei n & G o o d en o u g h (R G ), M il le r & C h ar le s (M C ) a n d W o rd S im 3 5 3 (W S )\n2 8\n(M C ) 6 5 (R G ) 9 7 (W S )\nr =\n0 .9\n3 (R\nG ) r\n= 0 .8\n9 (M\nC )\nr =\n0. 8 6\n(W S\n)\n(R ad\nin sk\ny et\nal .,\n20 11\n) S em\na n ti\nc re\nla te\nd n\nes s\no f\np a ir\ns o f\nn o u\nn s\n2 8 0\nN o t\nfo u\nn d\nM tu\nrk -7\n71 (H\nal aw\ni et\nal .,\n20 1 2)\nS em\na n ti\nc re\nla te\nd n\nes s\no f\np a ir\ns o f\nn o u\nn s\n7 7 1\nr =\n0. 8 9\n(Z ie\ngl er\net al\n., 20\n12 )\nS em\na n ti\nc re\nla te\nd n\nes s\no f\np a ir\ns o f\nn o u\nn s\nw h\nic h\na re\nd is\na m\nb ig\nu a te d b y D B p ed ia U R Is 7\n2 5\na n\nd 3 0\nr =\n0. 7 1\na n\nd r\n= 0.\n7 0\nS ta\nn fo\nrd \u2019s\nC on\nte x tu al W or d S im il ar it ie s (S C W S ) (H u an g et al ., 20 12 )\nS em\na n ti\nc re\nla te\nd n\nes s\no f\np a ir\ns o f\nw or\nd s\nin co\nn te\nx t\n2 0 0 3\nN o t\nfo u\nn d\nT h\ne S\nta n\nfo rd\nR ar\ne W\nor d\n(R W\n) S\nim il\nar it\ny D\nat as et (L u on g et al ., 20 13 )\nS em\na n ti\nc re\nla te\nd n\nes s\no f\np a ir\ns o f\nra re\nw o rd\ns 2 0 3 4\nN o t\nfo u\nn d\nM E\nN te\nst C\nol le\nct io n (B ru n i et al ., 20 14\n) S\nem a n ti\nc re\nla te\nd n\nes s\no f\np a ir\ns o f\nw or\nd s\n3 0 0 0\n\u03c1 =\n0. 8 4\nS im\nL ex\n-9 99\n(H il\nl et\nal .,\n20 1 4)\nS em\na n ti\nc si\nm il\na ri\nty o f\np a ir\ns o f\nw or\nd s\n9 9 9\n\u03c1 =\n0. 6 7\n(B ak\ner et\na l.\n, 20\n14 )\nS em\na n ti\nc re\nla te\nd n\nes s\no f\np a ir\ns o f\nve rb\ns 1 4 3\nN o t\nfo u\nn d\nT ab\nle 4.\n1: S\nu m\nm a ry\no f\nd a ta\nse ts\nth a t\na re\nco m\nm o n\nly u\nse d\nfo r\nco m - p ar in g se m an ti c m ea su re s. In te ra g re em en t: re fe r to th e d et a il s p ro v id ed in th e d es cr ip ti o n o f th e d a ta se t a n d / o r to th e o ri g in a l p u b li ca ti on s to u n d er st a n d h ow th es e va lu es h av e b ee n co m p u te d . E ac h re su lt h a s sp ec ifi ci ti es th a t m u st b e co n si d er ed fo r fu rt h er an al y se s \u2013 co m p a ri so n b et w ee n va lu es is n o t a lw ay s d ir ec tl y p o ss ib le .\n7 U\nn if\no rm\nR es\no u\nrc e\nId en\nti fi\ner s\na re\nu se\nd to\nre fe\nr to\nco n\nce p\nt w\nit h\no u\nt a m\nb ig\nu it\ny.\nThe reader can also consider these interesting websites about datasets (that may be updated in the future):\n\u2022 Manaal Faruqi8 website maintains a list of various datasets that can be used to evaluate semantic measures.\n\u2022 The ACL website9 and the Semantic Measure Library website10 also provide information about datasets.\nIn the following, we detail several aspects of each aforementioned datasets. We discuss in particular the specific aims of the datasets. We also introduce the protocols and settings that have been used during acquisition. This will help us to underline the semantics which is associated to the expected scores that have been provided by the participants.\n(Rubenstein and Goodenough, 1965) \u2013 noun similarity\nThe procedure used to obtain this dataset is well documented in the associated paper. The dataset is composed of 65 pairs of nouns (ordinary English nouns), e.g. cord/smile \u2013 pairs were introduced as theme pairs in the experiment. Each pair was written into a card in order to obtain a shuffled deck of 65 cards for each participant. Next, participants were asked to order the cards according to the similarity of the pairs of nouns written on them. Finally, participants were asked to evaluate the (semantic) similarity of each pair using a 0-4 scale \u2013 the higher the number associated to the card, the greater the \u201csimiliarity of meaning\u201d. This experiment was designed to evaluate semantic similarity, which was defined as the \u201camount of similarity of meaning\u201d (i.e. degree of synonymy) to the participants. Participants were 51 paid college undergraduates. Two groups of 15 and 36 subjects were considered \u2013 respectively called group 1 and 2.\nThe intra-subject reliability was computed using group 1 on 36 pairs of nouns for which participants were asked to assign the similarity twice, two weeks apart. The intra-subject reliability was computed using Pearson\u2019s correlation: a score of r = 0.85 was obtained. Inter-subject correlation is not communicated in this experiment but the reported correlation of mean judgements of the two different groups was impressively high (r = 0.99). This encouraged the authors to merge the results of the two groups to finally only consider a single group of 51 participants. For each pair of nouns, only the average similarity of the scores provided by all the participants is available. Examples of results are provided in Table 4.2.\nThe benchmark of Rubenstein and Goodenough is largely used in the evaluation of semantic similarity measures. It has also been translated into German by Gurevych (2005).\n(Miller and Charles, 1991) \u2013 noun similarity\nMiller & Charles benchmark is a subset of Rubenstein and Goodenough\u2019s benchmark composed of a selection of 30 pairs. Three sets of 10 pairs of nouns with high, intermediate and low levels of similarity were chosen; for each set of pairs of nouns, the scores in the original Rubenstein and Goodenough\u2019s benchmark were respectively 3 or 4, between 1 and 3, and 0 or 1. The similarities of the 30 pairs of nouns were then assessed by 38 participants. These participants received the instructions provided by Rubenstein and Goodenough. Inter-subject correlation is 0.8848. Interestingly, human rating obtained by Miller and Charles, and Rubenstein and Goodenough are highly correlated, with a Pearson\u2019s correlation\n8http://www.cs.cmu.edu/~mfaruqui/suite.html 9http://www.aclweb.org/aclwiki\n10http://www.semantic-measures-library.org\n4.3. EXISTING PROTOCOLS AND DATASETS 105\nof 0.97, e.g. reported by Bollegala (2007a). Note that, as stressed by Budanitsky and Hirst (2006), due to a typographical error, the pair cord/smile was changed to chord/smile. This seems to have no impact on the overall evaluation since both pairs have low levels of similarity. Only the averaged similarities are provided in the dataset. This benchmark has also been translated into Arabic, Romanian and Spanish (Hassan and Mihalcea, 2009).\nTOEFL (Landauer and Dumais, 1997) \u2013 word similarity\nThis dataset is designed to evaluate semantic similarity of words. It evaluates the degree of synonymy of pairs of nouns, verbs, and adjectives. It is composed of 80 multiple-choice synonymy questions that have been selected from the Test of English as a Foreign Language (TOEFL). Each question provides a problem word and 4 choices of synonyms with a single expected answer \u2013 an example of question is provided below. For each question, participants were asked to select the synonym with the \u201cmost similar meaning\u201d with the problem word associated to the question. Averaged result obtained from a large sample of applicants to U.S colleges from non-English countries is 51.6 correct answers (64.5%) \u2013 reduced to 52.7% when these scores are corrected by penalizing errors to lower the impact of correct answers that could have been obtained by guessing.\nAdditional information about this dataset can be found at: http://lsa.colorado.edu/papers/plato/ plato.annote.html#evaluate\nExample of question11: considering the focal word levied and the following choices (a) imposed, (b) believed, (c) requested, (d) correlated, the expected solution is (a) imposed.\nWordSim353 (Finkelstein et al., 2002) \u2013 word relatedness\nTwo sets of English pairs of words along with human ratings of semantic relatedness. The first set contains 153 pairs including the 30 nouns pairs contained in (Miller and Charles, 1991) dataset. 13 participants evaluated it. The second set contains 200 pairs evaluated by 16 participants. Participants were asked to assess the \u201crelatedness\u201d of words in a 0-10 discrete scale associated to the semantics \u201ctotally unrelated words\u201d (0) to \u201cvery much related or identical words\u201d (10). A correlation of 0.95 is reported between the scores proposed by the participants of WordSim353 and those assessed in Miller and Charles experiment. Row results, as well as mean scores are provided for the two sets. A concatenation of the sets composed of 353 pairs with averaged scores is also provided. (Hill et al., 2014) reports an inter-agreement of \u03c1 = 0.661 using Spearman\u2019s correlation. The benchmark is available at http: //www.cs.technion.ac.il/~gabr/resources/data/wordsim353.\nWordSim353 have also been translated into French (Joubarne and Inkpen, 2011), Arabic, Romanian and Spanish (Hassan and Mihalcea, 2009).\nESL (Turney, 2001) \u2013 word similarity\nESL, English as a Second Language, is similar to the TOEFL dataset (Landauer and Dumais, 1997). It proposes to evaluate the semantic similarity of pairs of nouns, verbs or adjectives by providing 50 multiple-choice synonym questions (4 choices by question). These questions have been selected from a collection of questions for students of ESL. Inter-agreement between student results is not provided. This dataset is available on request from Peter Turney.\nAdditional information about this dataset can be found at: http://a4esl.org/q/j/dt/mc-2000-01syn. html\nProviding the definition \u201cA rusty nail is not as strong as a clean, new one.\u201d and the following choices (a) corroded, (b) black, (c) dirty, (d) painted, the expected solution is (a) corroded.12\nSAT Analogy questions (Turney and Littman, 2003) \u2013 similarity of word relationships\nThis dataset is composed of 374 multiple-choice analogy questions collected by Michael Littman from the Scholastic Aptitude Test (SAT). It has been used to evaluate contextual semantic similarity of semantic relationship between words (Turney, 2006). This notion is evaluated studying the analogy between the\n11Example from http://www.aclweb.org/aclwiki/index.php?title=TOEFL_Synonym_Questions_(State_of_the_art) 12Example from http://www.aclweb.org/aclwiki/index.php?title=ESL_Synonym_Questions_(State_of_the_art)\n106 CHAPTER 4. EVALUATION OF SEMANTIC MEASURES\nrelationships that link words. Each question is composed of a problem pair of words with a single valid answer among 5 choices of pair of words. As an example, considering the problem pair cat:meow and the 5 choices mouse:scamper, bird:peck, dog:bark, horse:groom, lion:scratch, the expected answer is dog:bark since the semantic relationships which link these words and the words of the problem pair (cat:meow) are the same \u201cthe name of the sound made by the animal\u201d. Another example of question is provided below. This benchmark is available on request from Peter Turney. Human performances are not provided.\nProviding the stem mason:stone and the following choices (a) teacher:chalk, (b) carpenter:wood, (c) soldier:gun, (d) photograph:camera, (e) book:word, the expected solution is (b) carpenter:wood.13"}, {"heading": "300 RDWP \u2013 (Jarmasz and Szpakowicz, 2003a) word similarity", "text": "This dataset is composed of 300 synonym detection problems. They have been selected for the Word Power game of the Canadian edition proposed at Reader\u2019s Digest Word (2000, 2001) \u2013 refer to the work of Jarmasz and Szpakowicz (2003a) for details about the original dataset. Each question is composed of a problem word, and 4 candidate answers. Participants have been asked to \u201cCheck the word or phrase you believe is nearest in meaning\u201d. The following example is provided by Jarmasz and Szpakowicz (2003a).\nProviding the problem word: ode and the following choices (a) heavy debt, (b) poem, (c) sweet smell, (d) surprise, the expected solution is (b) poem.\n(Boyd-Graber et al., 2006) \u2013 WordNet synset relatedness\nThis benchmark provides human appreciation of semantic relatedness for a large number of pairs of WordNet synsets. It is composed of two datasets of about 100K randomly selected pairs of synsets. Trained undergraduates were used to build the first dataset. The second dataset was made from participants selected on the Amazon Mechanical Turk platform. It is reported to contain noise \u2013 refer to the original documentation for more details. Figure 4.3 presents the scale proposed to the participants.\nAdditional information about this dataset can be found at: http://wordnet.cs.princeton.edu/downloads. html\n(Yang and Powers, 2006) \u2013 verb relatedness\nThis dataset provides semantic similarities for 144 pairs of verbs. According to the authors this is the first benchmark dedicated to the evaluation of verb semantic similarity. The verbs have been selected from TOEFL (Test of English as a Foreign Language) and ESL (English as a second Language) tests \u2013 details on how the pairs of verbs have been obtained from these tests are provided in the contribution of Yang and Powers (2006). 2 academic staffs and 4 postgraduate students have assessed the semantic similarities \u2013 4 were native Australian English speakers and 2 were near-native speakers. A 0 (not at all related) to 4 (inseparably related) discrete scale has been used. A Pearson\u2019s correlation of r = 0.866 is reported among the participants.\n(Pedersen et al., 2007) \u2013 concept relatedness\nThis dataset is composed of pairs of medical concepts represented by pairs of non-ambiguous words. Similarly to the definition of Rubenstein and Goodenough, 120 pairs of terms equally divided into four classes of degree of relatedness from practically synonymous to unrelated were chosen. Participants were 3 physicians and 9 medical coders. They annotated each pair using the following discrete scale: practically synonymous (4.0), related (3.0), marginally related (2.0) and unrelated (1.0). A low correlation of 0.51 between the participant scores was obtained. Therefore, a subset of this set composed of 30 pairs with\n13Example from http://www.aclweb.org/aclwiki/index.php?title=SAT_Analogy_Questions_(State_of_the_art)\nhigher inter-agreement is generally considered \u2013 one pair was later deleted since no correspondence with a concept was found into the SNOMED-CT (structured terminology). Using the subset of 29 pairs, the average correlation among physicians and medical coders is 0.68 and 0.78 respectively. Considering average scores of each member of each group, the correlation between physicians and medical coders is 0.85. 10 medical coders also assessed the similarity of the pairs of words of the Rubenstein and Goodenough and Miller and Charles benchmarks. They obtained an inter-agreement of 0.84 and 0.88 with the values obtained in the original experiments. Only averaged similarities of both physicians and medical coders are available. Table 4.3 presents some of the entries that compose the dataset.\nThis dataset has also been used to compare concepts defined into MeSH or SNOMED-CT \u2013 correspondences between labels and concept identifiers are provided by Batet et al. (2014) and Harispe et al. (2013c)."}, {"heading": "WS Sim (Agirre et al., 2009) \u2013 cross-lingual word similarity", "text": "This dataset is used to evaluate Spanish/English cross-lingual semantic similarity and relatedness. It is composed of the set of pairs of words of Rubenstein & Goodenough and WordSim 353 datasets, in which the second word of each pair has been translated into Spanish. The two translators agreed on translating 72% and 84% of Rubenstein & Goodenough and WordSim 353 pairs respectively. Information about this benchmark is available at http://alfonseca.org/eng/research/wordsim353.html.\n(Pakhomov et al., 2010) \u2013 word similarity/relatedness\nThis dataset provides scores of semantic similarity and relatedness between pairs of medical terms \u2013 terms refer to UMLS concepts. Two sets of concept pairs are studied. The first contains 566 pairs and is dedicated to semantic similarity. The second is composed of 587 pairs rated for semantic relatedness. Scores were obtained from 8 medical of the University of Minnesota Medical School, 4 participated to the similarity task and 4 to the relatedness task. This work can also be used to compare concepts defined into medical knowledge-base, e.g. MeSH or SNOMED-CT (Batet et al., 2014).\nConceptSim (Schwartz and Gomez, 2011) \u2013 concept similarity\nConceptSim disambiguates WordSim 353, Rubenstein & Goodenough (and therefore Miller & Charles) datasets by mapping each word to a unique synset of WordNet 3.0. Two annotators with an interagreement that ranged from 86 to 93% made the disambiguation. The final version of the benchmark contains the mapped pairs after annotator agreement. Original mapping of the two annotators are provided. Even if differences could be observed between the similarity of the ambiguous and disambiguated pairs, the similarities of the original experiments are generally considered when evaluating measures using this dataset. The benchmark is available to download at http://www.seas.upenn.edu/~hansens/ conceptSim.\n(Radinsky et al., 2011) \u2013 word relatedness\nThis dataset is composed of 280 pairs of words with associated semantic relatedness scores. Participants were Amazon Mechanical Turk workers. Each participant evaluated 50 pairs and an average of 23 rating is reported for each pair. Outliers were removed using correlations with ten pairs of WordSim353 datasets. A version of this dataset is available at: http://tx.technion.ac.il/~kirar/Datasets.html\nMturk-771 (Halawi et al., 2012) \u2013 word relatedness\nThis dataset is composed of 771 pairs of English words along with their semantic relatedness. Each pair of words has been evaluated by at least 20 participants from the Amazon Mechanical Turk platform. Inter-correlation of the results was assessed to 0.89 with small variance. Participants were asked to assign the relatedness of batch of 50 pairs of words using a 1-5 discrete scale ranging to \u201cnot related\u201d to \u201chighly related\u201d. In order to assess the quality and reliability of the evaluation, each batch of 50 word pairs contained 10 pairs known to have extreme relatedness values. This was used to control dataset quality. Evaluations which contained more than one error on the control quality pairs were not considered for building the final benchmark. Both raw and mean scores are available for download at http://www2.mta.ac.il/~gideon/mturk771.html\n14. Examples of entries of this dataset are provided in Table 4.4.\n(Ziegler et al., 2012) \u2013 concept relatedness\nTwo sets of concept/instance pairs denoted by English words. Contrary to most of existing benchmarks, the compared word refers to concepts or instances such as name of artists, brand names, qualified concepts. The first set contains 25 pairs, the second 30. Participants were asked to assign the relatedness of pairs of concepts using a 1-5 discrete scale ranging to the semantics \u201cno proximity\u201d to \u201csynonymy\u201d. The scores of relatedness were assessed based on an online survey. Most participants were not native people (Germans, Italians, Turkish). Inter-subject correlations based on Pearson\u2019s correlation are about 0.70 for the two sets \u2013 which is good considering the facts that the benchmark is composed of names of brands, artists, making the comparison more difficult, e.g. the label has to be understood by the participants. In addition, contrary to most experiments the majority of the participants were not native people. Both average similarities and associated standard deviations are provided. Examples of entries are given in Table 4.5.\nSCWS (Huang et al., 2012) \u2013 word similarity in context\nStanford\u2019s Contextual Word Similarities (SCWS) provides the semantic similarity of 2003 pairs of words in sentential contexts to ensure that the meaning of words is not ambiguous. Each pair has been evaluated by 10 participants taken on the Amazon Mechanical Turk platform. Details about the dataset are provided in (Huang et al., 2012). It can be downloaded at: http://www-nlp.stanford.edu/~ehhuang/ SCWS.zip.\nExample of results that have been obtained for the comparison of the words activity (n) and inaction (n) considering the following contexts:\n14Contrary to the details provided in the paper, the documentation specified that each pair was evaluated by ten people.\nactivity (n): \u201ctons of poultry and 61 million tons of eggs were produced worldwide. Chickens account for much of human poultry consumption, though turkeys, ducks, and geese are also relatively common. Many species of birds are also hunted for meat. Bird hunting is primarily a recreational activity except in extremely undeveloped areas. The most important birds hunted in North and South America are waterfowl ; other widely hunted birds include pheasants, wild turkeys, quail, doves , partridge , grouse , snipe , and woodcock . Muttonbirding is also popular in Australia and\u201d.\ninaction (n): \u201crespect which always marked his communications with the court. It has been insinuated both by contemporary and by later critics that being disappointed at his loss of popularity, and convinced of the impossibility of co-operating with his colleagues, he exaggerated his malady as a pretext for the inaction that was forced upon him by circumstances. But there is no sufficient reason to doubt that he was really, as his friends represented, in a state that utterly unfitted him for business. He seems to have been freed for a time from the pangs of\u201d.\nThe average relatedness is 6. Details of the 10 scores are: 10, 9, 8 (\u00d73), 7, 5, 3, 2, 0."}, {"heading": "RW (Luong et al., 2013) \u2013 Rare word relatedness", "text": "This benchmark provides the semantic similarity for 2034 pairs of rare words. Details about the dataset and its construction are provided in (Luong et al., 2013). Participants were recruited from the Amazon Mechanical Turk platform. For each pair, 10 ratings have been obtained using a 0-10 discrete scale. The benchmark can be downloaded at: http://www-nlp.stanford.edu/~lmthang/morphoNLM. Examples of entries are provided in Table 4.6.\nMEN Test (Bruni et al., 2014) \u2013 word relatedness\nThe MEN Test Collection provides scores of semantic relatedness for 3000 pairs of words. Scores were obtained from English native speaker available from the Amazon Mechanical Turk platform. Contrary to other experiments, participants did not rate the semantic relatedness of pairs of terms using a discrete scale but rather used comparative tests. They were asked to distinguish the most related pair of words among two candidate word pairs. For each pair, 50 binary scores (more or less related than the other pair) have been obtained and used to compute the score of relatedness in a 0-50 discrete scale. Since candidate pairs were randomly generated no score of inter-agreement between participants has been reported. However, as a control, a \u03c1 = 0.68 Spearman correlation between the scores of relatedness provided by two of the authors in a 0-7 discrete scale is reported. In addition, a Spearman correlation of \u03c1 = 0.84 between the average values of these scores and those obtained using participants is reported. Details and downloads are provided at http://clic.cimec.unitn.it/~elia.bruni/MEN.html. Examples of entries are provided in Table 4.7.\n110 CHAPTER 4. EVALUATION OF SEMANTIC MEASURES\nSim-Lex-999 (Hill et al., 2014) \u2013 word similarity\nSim-Lex-999 is dedicated to the evaluation of the semantic similarity between words. It provides semantic similarity scores for 999 pairs of words that have been assessed by participants selected from the Amazon Mechanical Turk platform. Words refer to concepts selected from the University of South Florida (USF) Norms dataset \u2013 a dataset that provides ratings for the concreteness of several concepts (Nelson et al., 2004). However, contrary to (Huang et al., 2012) which disambiguates words by providing a sentential context, in this case only labels are provided to the participants \u2013 instructions are presented in Figure 4.4.\nEach participant had to provide similarity ratings in a 0-7 discrete scale for 20 pairs of words. Each pair was evaluated by an average of 50 participants. The Spearman correlation between participants is 0.67. Refer to the work of Hill et al. (2014) for details about the protocol used to obtain this benchmark. Sim-Lex-999 can be downloaded at: http://www.cl.cam.ac.uk/~fh295/simlex.html.\n(Baker et al., 2014) \u2013 verb similarity\nThis dataset provides score of semantic relatedness for 143 pairs of verbs. For each pair, 10 participants have a relatedness score in a 0-10 discrete scale. The dataset can be downloaded from http://ie. technion.ac.il/~roiri/. Examples of entries are provided in Table 4.8.\nThe Semantic Textual Similarity campaign and related datasets\nThe Semantic Textual Similarity (STS) campaign provides state-of-the-art resources and methods for comparing measures and systems dedicated to sentence semantic similarity evaluations \u2013 defined as the\n\u201cdegree of semantic equivalence\u201d between two sentences. Detailed information about STS, the resources it proposes and the community it federates can be found at http://ixa2.si.ehu.es/stswiki/index.php.\nThe STS campaign is proposed since 2012 at SemEval \u2013 a series of evaluations dedicated to computer systems related to semantics (Agirre et al., 2012). The datasets used in this campaign are composed of pairs of sentences from specific or existing paraphrase and machine translation datasets. The similarity between the sentences of each pair is defined by participants into a 0 to 5 discrete scale \u2013 considering that 5 means \u201cThe two sentences are completely equivalent, as they mean the same thing\u201d while 0 means \u201cThe two sentences are on different topics\u201d. Details are provided in the associated documentation. The challenge is to design a system that will assign a score of relatedness with an optional score of confidence when comparing two sentences. Example of expected results are presented in Table 4.9.\nSome datasets provided by STS are also available in Spanish. Specific evaluations have also been proposed. As an example, in 2014, a Cross-Level Semantic Similarity Task proposed to evaluate measures able to compare semantic similarity across different sizes of texts (paragraph to sentence, phrase to word. . . ).\nAmong the benchmarks used to evaluate text relatedness, users can also consider:\n\u2022 (Li et al., 2006) \u2013 sentence similarity benchmark which is based on the definitions of the terms that compose (Rubenstein and Goodenough, 1965) dataset. 32 participants assessed similarity using a 0 to 4 scale (unrelated to alike). A subset of 30 pairs of definitions is generally considered.\n\u2022 (Lee et al., 2005) \u2013 text to text similarity which is based on pairs of documents built from a collection of 50 short documents presenting news (source: Australian Broad-casting Corporation\u2019s news mail service). For each pairs, ten participants have proposed relatedness scores into a 1 to 5 discrete scale (unrelated \u2013 alike). The final benchmark contains similarity for all the 2500 document pairs.\n\u2022 Microsoft research paraphrase benchmark15(MSR Paraphrase) can also be used to compare the similarity of texts. This manually created benchmark contains next to 6K pairs of sentences from diverse Web sources \u2013 Inter-agreement was evaluated between 82 and 84%. In the context of STS evaluation, this benchmark has been enriched by specifying how related are the sentences which are not considered to be paraphrased.\n\u2022 Microsoft research Video Paraphrase Corpus. Built using Amazon Mechanical Turk to obtain a sentence description of the video \u2013 120k descriptions have been collected for 2000 videos. Based on this dataset 1500 pairs of sentences have been generated considering sentences describing the same video or different videos \u2013 details are provided in the work of Agirre et al. (2012).\n\u2022 Other datasets can be adapted to evaluate semantic similarity or relatedness, e.g. benchmarks used to evaluate distributional semantic models (Baroni and Lenci, 2011) or domain-specific datasets (Hassan et al., 2012).\nOther evaluations not based on human ratings\nWe have presented numerous datasets that can be used to evaluate semantic measures with regard to expected scores of similarity or relatedness of compared elements (terms, concepts, sentences). These datasets can be used to assess measure accuracy by directly analysing their ability to mimic human appreciation of semantic similarity or relatedness. Using indirect evaluations, the accuracy of measures\n15http://research.microsoft.com/en-us/downloads/607D14D9-20CD-47E3-85BC-A2F65CD28042/default.aspx\n112 CHAPTER 4. EVALUATION OF SEMANTIC MEASURES\ncan also be evaluated by analysing the impact of a specific choice of measure on the performance of systems. Accuracy and precision measures introduced in Section 4.2.1 are generally used in this case. As an example of indirect evaluation, McInnes and Pedersen (2013) evaluated measures by analysing the performance of a disambiguation system. Particular strategies are defined for specific domains. In Bioinformatics, evaluated systems can be used to obtain expected groups of genes or proteins, e.g. protein families, genes involved in similar metabolic pathways, or to distinguish pairs of proteins that will interact. In other cases, semantic measures will be evaluated by analysing the correlation between the semantic similarity of gene conceptual annotations (groups of concepts defined into an ontology) and the score of similarity of gene DNA sequences. Please refer to the work of Guzzi et al. (2012) and Pesquita et al. (2009a,b) for details related to evaluations in Bioinformatics."}, {"heading": "4.4 Discussions", "text": "In this chapter, we have introduced several important aspects related to the evaluation and the selection of semantic measures. First, we have discussed multiple characteristics of measures that can be discussed in order to select the measures that are adapted to a specific usage context: accuracy, precision, robustness, computational complexity, mathematical properties, semantics, as well as other technical details such as the availability of free concrete implementations. Next, we have presented state-of-the-art methodologies and datasets commonly used to empirically evaluate measure accuracy. Using this information, users will be able (i) to deeply analyse a specific choice of measure and (ii) to better understand the implication of this choice on the system he develops.\nIn the process of selecting a specific measure, end-users must first characterise as much as possible the properties his ideal measure must respect, the resources which are available and other constraints that will be useful to orient the selection (e.g. computational complexity, computer resources, and implementation availability). These points are dependant on the usage context and therefore prevent the definition of a generic turnkey solution. However, once this work has been performed, we have introduced and identified a variety of datasets that can be used to empirically evaluate measures with regard to particular applications. Existing comparisons can be analysed from the literature or publicly available results published onto the Web16. An important point to stress \u2013 that has voluntary not been discussed in this chapter \u2013 is that for most datasets measure proposals equalling human inter-agreement have been proposed. This stresses that efficient solutions have already been proposed and that, in most cases, ad-hoc solutions are not required. Using existing implementations of measures and tools dedicated to evaluation presented in Appendix D, as well as publicly available benchmarks, specific empirical analysis can also be done to perform fine-grained analysis of measures and eventually tune studied alternatives. Finally, if the datasets that have been presented are not representative of a specific use case of interest, the reader can refer to the benchmarks descriptions provided in this chapter to design new ones.\nDespite the numerous datasets and evaluation approaches presented in this chapter, evaluating semantic measures is both conceptually and practically an open challenge. Many biases are yet to be excluded from future datasets to improve evaluation process. For instance we stress that:\n\u2022 Uncertainty in expected values could be better managed if individual assessments were provided instead of average values as a summary of the collected evaluations.\n\u2022 Similarity expected scores are imprecise values and should be modelled as such whereas they are currently defined on a linearly ordered finite scale, e.g. 0-4.\n\u2022 Providing similarity scores for individual pairs of words is probably less natural for participants than providing pairwise comparison of the similarity of word pairs.\n\u2022 The difficulty of evaluation depends on the pairs of concepts to be compared; hence, all the required scores should not contribute equally to the overall assessment of the measure accuracy.\nIn this context, research on how to better evaluate semantic measures must be made. Initiatives defining systematic and reproducible approaches for comparing measures, such as the Semantic Textual Similarity campaign (Agirre et al., 2012), must also be encouraged. Indeed, nowadays, this field of study suffers from the lack of reproducible results and shared evaluation platform \u2013 they could greatly ease the comparison of existing proposals, and help us to better understand both benefits and drawbacks of\n16As an example ACL website provides provides several results for numerous approaches. Consult: http://www.aclweb. org/aclwiki\n4.4. DISCUSSIONS 113\nexisting proposals \u2013 initiatives such as (Faruqui and Dyer, 2014; Pesquita et al., 2009b) must also be encouraged, supported, improved and adopted. This is necessary to enable the emergence of general knowledge about semantic measures from existing comparison results.\nMore analysis of existing benchmarks must also be performed in order to criticise their relevance and to underline their strengths and limits. Differences between contextualised semantic similarity and semantic similarity of ambiguous words must deeply be studied. To date, by only providing pairs of words, most datasets delegate sense selection to the participants, which necessarily impact the quality of the evaluation (Budanitsky, 2001), and probably the whole meaning of the evaluation. Difference between the semantic similarity/relatedness of different types of words, e.g. nouns, verbs, adjectives must also be better understood. Better understanding expected scores of semantic similarity or relatedness will, without doubt, help us to improve and better define semantic measures.\nA large number of state-of-the-art evaluation results related to semantic measures are based on reduced datasets that only contain a few dozens of pairs of elements, e.g. Miller and Charles dataset. This highly reduces and even questions the conclusions that can be derived from them, e.g. are these results biased? Additional evaluations must be performed using the various larger datasets recently proposed.\nAll these contributions will help us to better compare semantic measures and to precise more finely the quantities estimated by these measures. This will be required to characterise the various dimensions today encompassed into the notions of semantic similarity, proximity or distance.\n114 CHAPTER 4. EVALUATION OF SEMANTIC MEASURES\nChapter 5\nConclusion and research directions\nThe capacity of assessing the similarity of objects or stimuli has long been characterised as a central component for establishing numerous cognitive processes. It is therefore not surprising that measures of similarity or distance play an important role in a large variety of treatments and algorithms, and are of particular interest for the development of Artificial Intelligence. In this context, this book focused on the complex notion of semantic similarity and more generally on semantic measures: how to compare units of languages (words, paragraphs, texts) or conceptualised entities, i.e. concepts or instances defined in ontologies, by taking into account their semantics and therefore their meaning.\nWe first introduced numerous applications in which approaches for the estimation of semantic similarity, relatedness or distance play an important role, as well as the numerous communities involved in their study. We also introduced important contributions related to the notion of similarity: the various models of similarity proposed and studied by Psychology and the formal axiomatic definitions of distance and similarity considered in Mathematics. This helped us identifying the depth of this interdisciplinary area of research, a depth which has been in particular illustrated by highlighting and organizing the large and often poorly defined vocabulary introduced in the literature, i.e. semantic similarity, semantic relatedness, semantic distance. Next, we introduced a general classification of semantic measures and the two broad families of semantic measures: corpus-based measures used to compare units of languages from natural language analysis and knowledge-based measures used to compare concepts and instances defined into ontologies. The foundations of these two approaches have been detailed and several examples of approaches have been introduced.\nWe hope this introduction helped the reader to understand the concept of semantic measure and to discover the variety of approaches proposed so far. Indeed, even if this book only propose an introduction to semantic measures, and do not discuss in detail all types of measures proposed in the literature, as well as important topics such as the evaluation of measures or the selection of context-specific measures, we are convinced it provides enough material and references to give the reader access to a deep understanding of this topic. We also hope that this overview of the field will help researchers identifying research directions to galvanise this topic. To conclude, we propose to discuss some of the challenges we have identified based on the analysis of a large body of literature dedicated to semantic measures:\n\u2022 Better characterise semantic measures and their semantics;\n\u2022 Provide theoretical and software tools for the study of semantic measures;\n\u2022 Standardise ontology handling;\n\u2022 Improve models for compositionality;\n\u2022 Study current models of semantic measures w.r.t language specificities;\n\u2022 Promote interdisciplinary;\n\u2022 Study the algorithmic complexity of measures.\n\u2022 Support context-specific selection of semantic measures.\n115\n116 CHAPTER 5. CONCLUSION AND RESEARCH DIRECTIONS\nResearch directions\nBetter characterise semantic measures and their semantics\nThroughout the introduction of semantic measures, we have stressed the importance of controlling their semantics, i.e., the meaning of the scores they produce. This particular aspect is of major importance since the semantics of measures must explicitly be understood by end-users: it conditions the relevance to use a specific measure in a particular context.\nNevertheless, the semantics of semantic measures is generally not discussed in proposals (except some broad distinction between the notion of semantic similarity and relatedness). However, semantic similarity based on taxonomies can have different meanings depending on the assumptions on which they rely. In this introduction, we have underlined that the semantics associated to semantic measures can only be understood w.r.t: (i) the semantic proxy used to support the comparison, (ii) the mathematical properties associated to the measures, and (iii) the semantic evidence and assumptions on which the measures are based.\nThe semantics of the measures can therefore only be captured if a deep characterisation of semantic measures is provided. In recent decades, researchers have mainly focused on the design of semantic measures, and despite the central role of the semantics of semantic measures, few contributions have focused on this specific aspect. This can be partially explained by the fact that numerous semantic measures have been designed in order to mimic human appreciation of semantic similarity/relatedness. In this case, the semantics to be carried by the measures is expected to be implicitly constrained by the benchmarks used to evaluate the accuracy of measures. Nevertheless, despite evaluation protocols based on ad hoc benchmarks being relevant to compare semantic measures in specific contexts of use, they do not give access to a deep understanding of measures. Indeed, even if their usefulness is not to discuss, they often do not provide enough general knowledge on semantic measures, e.g. to predict the behaviour of measures in other usage contexts.\nThere are numerous implications involved in a better characterisation of semantic measures. We have already stressed its importance for the selection of semantic measures in specific contexts of use. Such a characterisation could also benefit cognitive sciences. Indeed, as we saw in Section 1.2.1, cognitive models aiming to explain human appreciation of similarity have been supported by the study of properties expected by the measures. As an example, remember that spatial models have been challenged according to the fact that human appreciation of similarity has proven not to be in accordance with axioms of distance. Therefore, characterising (i) which semantic measures best performed according to human expectations of semantic similarity/relatedness and (ii) the properties satisfied by these measures could help cognitive scientists to improve existing models of similarity or to derive more accurate ones.\nIn Chapter 1, we have presented an overview of the various semantic measures which have been proposed to compare units of language, concepts or instances which are semantically characterised. In particular, in Section 1.3, we distinguished various aspects of semantic measures which must be taken into account for their broad classification: (i) The types of elements which can be compared, (ii) The semantic proxies used to extract semantic evidence on which the measures will be based and (iii) The canonical form adopted to represent the compared elements and therefore enable the design of algorithms for their comparison.\nIn Section 1.2.2, based on several notions introduced in the literature, we proposed a characterisation of the general semantics which can be associated to semantic measures (e.g., similarity, relatedness, distance, taxonomic distance). In Section 1.2.3, we recalled some of the mathematical properties which can be used to further characterise semantic measures. Finally, throughout this introduction, and particularly in Section 2.2 and Section 3.3, we distinguished extensive semantic evidence on which corpus-based and knowledge-based semantic measures can be defined. We also underlined the assumptions associated to their consideration.\nWe encourage designer of semantic measures to provide an in-depth characterisation of measures they propose. To this end, they can use, among others, the various aspects and properties of the measures distinguished in this book and briefly summarised above.\nWe also encourage the communities involved in the study of semantic measures to better define what a good semantic measure is and to define exactly what makes one measure better than another. Within this goal, the study of the role of usage context seems to be of major importance. Indeed, the accuracy of measures can only be discussed w.r.t specific expectations of measures. Several other properties of measures could also be taken into account and further investigated:\n117\n\u2022 Algorithmic complexity, which is of major importance for most of concrete use cases, but so far only poorly discussed in the literature.\n\u2022 Degree of control on the semantics of the scores produced by the measures. A measure could be evaluated according to the understanding of its semantics. It could also be interesting to consider the degree of control a end-user can have on the semantics of the results. Indeed, this aspect is important in several applications based on semantic measures, e.g. synonymy detection.\n\u2022 The trust which can be associated to a score. Is it possible to evaluate the trust we can have on a specific similarity or relatedness assessment, e.g. based on prior analysis of the semantic proxy which is used.\n\u2022 The robustness of a measure, i.e., the capacity for a measure to produce robust scores considering the uncertainty associated to expected scores, or disturbances of the semantic proxies on which the measure relies (modification of the ontologies, corpus modifications). As an example, we proposed an approach for studying the robustness of a semantic measure in (Janaqi et al., 2014).\n\u2022 The discriminative power of the measure, i.e., the distribution of the scores produced by a measure.\nProvide tools for the study of semantic measures\nThe communities studying and using semantic measures require software solutions, benchmarks, and theoretical tools to compute, compare and analyse semantic measures.\nDevelop datasets\nThere are a host of benchmarks for evaluating semantic similarity and relatedness (Rubenstein and Goodenough, 1965; Miller and Charles, 1991; Finkelstein et al., 2002; Pedersen et al., 2007; Pakhomov et al., 2010; Halawi et al., 2012; Ziegler et al., 2012) \u2013 several references and additional information are provided in Chapter 4. Most of them aim at evaluating the accuracy of semantic measures according to human appreciation of similarity/relatedness. For the most part, they are composed of a reduced number of entries, e.g., pairs of words/concepts, and have been computed using a reduced pool of subjects.\nInitiatives for the development of benchmarks must be encouraged in order to obtain larger benchmarks in various domains of study. Word-to-word benchmarks must be conceptualised (as much as possible)1 in order for them to be used to evaluate knowledge-based semantic measures. It is also important to propose benchmarks which are not based on human appreciation of similarity, i.e., benchmarks relying on an indirect evaluation strategy \u2013 evaluations based on the analysis of the performance of processes which rely on semantic measures.\nNevertheless, we underline that important efforts have recently been made to propose valuable evaluation campaigns related to semantic measures. Thus, at SemEval conferences2, SEM tasks have been organised in 2012, 2013, 2014 and 2015 in order to compare systems in several task related to semantic similarity, e.g. text similarity, cross-level semantic similarity3(Agirre et al., 2012).\nDevelop generic open-source software\nAn overview of the main software solutions dedicated to semantic measures is provided in Appendix D. They are of major importance to: (i) ease the use of the theoretical contributions related to semantic measures, (ii) support large scale comparisons of measures and therefore (iii) better understand the measures and (iv) develop new proposals.\nSoftware solutions dedicated to distributional measures are generally developed without being restricted to a specific corpus of texts. They can therefore be used in a large diversity of contexts of use, as long as the semantic proxy considered corresponds to a corpus of texts, e.g. DKPro (Ba\u0308r et al., 2013), Semilar (Rus et al., 2013), Disco (Kolb, 2008) among others (Harispe et al., 2013b).\nConversely, software solutions dedicated to knowledge-based semantic measures are generally developed for a specific domain, e.g., WordNet (Pedersen et al., 2004), UMLS (McInnes et al., 2009) \u2013 you can also refer to the large number of solutions developed for the Gene Ontology alone (Harispe et al., 2013b). Such a diversity of software is limiting for designers of semantic measures since implementations made for\n1E.g. using DBpedia URIs. 2http://en.wikipedia.org/wiki/SemEval 3When language units of different sizes are compared.\n118 CHAPTER 5. CONCLUSION AND RESEARCH DIRECTIONS\na specific ontology cannot be reused in applications relying on others ontologies. In addition, it hampers the reproducibility of results since some of our experiments have shown that specific implementations tend to produce different results4. In this context, we encourage the development of generic open-source software solutions which are not restricted to specific ontologies. This is challenging since the formalism used to express ontologies is not always the same and specificities of particular ontologies sometimes deserve to be taken into account in order to develop semantic measures. However, there are several cases in which generic software can be developed. As an example, numerous knowledge-based semantic measures rely on data structures corresponding to poset or more generally semantic graphs. Other measures are designed to take advantage of ontologies expressed in standardised languages such as RDF(S), OWL. Generic software solutions can be developed to encompass these cases. Reaching such a goal could open interesting perspectives. Indeed, based on such generic and robust software supported by several communities, domain specific tools and various programming language interfaces can subsequently be developed to support specific use cases and ontologies.\nIn this context, we initiated the Semantic Measures Library project which aims to develop open source software solutions dedicated to semantic measures, e.g. the Semantic Measures Library (SML) and Toolkit (Harispe et al., 2014b). These software solutions can be used for large-scale computation and analysis of semantic similarities, proximities or distances between terms or concepts defined in ontologies, e.g., structured vocabularies, taxonomies, RDF graphs. The comparison of instances (e.g., documents, patient records, genes) annotated by concepts is also supported. An important aspect of these software solutions is that they are generic and are therefore not tailored to a specific application context. They can thus be used with various controlled vocabularies and knowledge representation languages (e.g. OBO, RDF, OWL). The project targets both designers and practitioners of semantic measures providing a Java source code library, as well as a command-line toolkit which can be used on personal computers or computer clusters. More information about this project can be found in the Appendix D and at http://www.semantic-measures-library.org.\nThe diversity of software solutions is also beneficial as it generally stimulates the development of robust solutions. Therefore, another interesting initiative, complementary to the development of generic software solutions dedicated to semantic measures, could be to provide generic and domain specific tests to facilitate both the development and the evaluation of software solutions. Such tests could for instance inventory expected scores of semantic measures for a reduced example of a corpus/ontology. This specific aspect is important in order to standardise software solutions dedicated to semantic measures and to ensure the users of specific solutions that the score produced by measure implementations are in accordance with the original definitions of the measures.\nAs discussed in (Harispe et al., 2013b) and other contributions, the evaluation of semantic measures is mainly governed by empirical studies used to assess their accuracy according to expected scores/behaviours of the measures. Therefore, the lack of open-source software solutions implementing a large diversity of measures hampers their study. It explains, for instance, that evaluations of measures available in the literature only involve the comparison of a subset of measures which is not representative of the diversity of semantic measures available today. Initiatives aiming at developing robust open-source software solutions which give access to a large catalogue of measures must therefore be encouraged. It is worth noting the importance of these solutions being open-source. Our communities also lack open-source software dedicated to the evaluation of semantic measures. Indeed, despite some initiatives such as DKPro Similar and CESSM (Collaborative Evaluation of Semantic Similarity Measures) - please refer to Appendix D -, evaluations are not made through a common framework as it is done in most communities, e.g. information retrieval (Voorhees and Harman, 2005; NIST, 2012), ontology alignment (Grau et al., 2013; Euzenat and Shvaiko, 2013). Large efforts have therefore to be made to ease the systematic use of the evaluation protocols presented in Chapter 4. This is mandatory to finely compare and evaluate semantic measures in a large scale fashion. Complementary to evaluation campaign such as SemEval, the development of such tools must ensure fair comparison of results, as well as experiment reproducibility - one of the aim of three recent tools: DKPro Similarity, Semilar and Semantic Measures Library.\nDevelop theoretical tools\nIt is currently difficult to study the overwhelming amount of proposed semantic measures, e.g., deriving the interesting properties of measures requires the analysis of each measure independently, which is\n4You can refer to the evaluation proposed at https://github.com/sharispe/sm-tools-evaluation.\n119\nlimiting and hampers both theoretical and empirical analyses of measures. However, several initiatives have proposed theoretical tools to ease the characterisation of measures, for instance by means of measure unification (Cross et al., 2013; Cross, 2006; Cross and Yu, 2010; Pirro\u0301 and Euzenat, 2010a; Sa\u0301nchez and Batet, 2011; Mazandu and Mulder, 2013; Cross et al., 2013; Harispe et al., 2013c), and by means of semantic model unification in distributional semantics, e.g. (Baroni and Lenci, 2010).\nAs an example, in (Harispe et al., 2013c), we show how several knowledge-based measures can be unified through a limited number of abstract core elements \u2013 this highlights that several measure expressions which have been proposed independently in the literature are only particular expressions of more general measures. Therefore, based on this theoretical characterisation of measures, we further illustrate how thousands of specific semantic measure expressions can be analysed in detail. In particular, we demonstrate how such an approach, based on a theoretical framework and implemented using SML open-source library, can be used to analyse the core elements of semantic measures which best impact measure accuracy in a specific context of use.\nMore efforts must be done to use existing theoretical tools and to propose new ones and to analyse semantic measures. Indeed, these contributions open interesting perspectives on studying groups of measures and enable to obtain more thoughtful results on semantic measures. They are also essential to better understand limitations of existing measures and the benefits of new proposals. Finally, they are central to distinguish the main components on which measures rely, and to improve our understanding of semantic measures based on detailed characterisation of family of measures.\nStandardise ontology handling\nSeveral knowledge-based semantic measures are based on the transformation of an ontology into a semantic graph. However, this process of transformation is currently overly subject to interpretations and deserves to be carefully discussed and formalised. Indeed, we stress that numerous measures consider ontologies as semantic graphs despite the fact that the formalism on which some ontologies rely cannot be mapped to semantic graphs without reductions \u2013 this is the case for some expressive logic-based ontologies (e.g. numerous ontologies which are expressed into OWL). The impact of such a reduction of ontologies is of major importance since it can highly affect semantic measure results5. Therefore, the treatment performed to map an ontology into a semantic graph is generally not documented, which explains some of the difficulties encountered to reproduce the results of some experiments6. In this context, we think that ontology handling must be carefully discussed and standardized if possible. This is important to ensure that theoretical contributions such as measure definitions can indeed be compared without the comparison being dependent on the implementation of the measure.\nCompositionality for comparing large units of language\nOne of the most important challenges offered to semantic measure designer is to integrate and to adapt existing approaches in order to compare large units of language such as sentences, paragraphs or documents. To this end, important research efforts are made and are required to study semantic compositionality w.r.t semantic similarity: (i) how to evaluate the semantics of larger units of language than words or concepts, (ii) how to capture this semantics into semantic models and (iii) how to design measures adapted to these models.\nAs we saw in Chapter 2 and more particularly in C, several attempts have been proposed to adapt distributional models and new original approaches are designed (Kamp et al., 2014; Baroni et al., 2014) \u2013 challenges related to this field of study aim to take advantage of more refined language analysis to improve existing models, e.g. by considering linguistic expressions, e.g., anaphora, negation or named entity recognition to cite a few.\nCorpus-based semantic measures and language specificities\nIt is important to analyse semantic measures in order to ensure that accurate models of semantic similarity and semantic relatedness are available to process resources which are not expressed in English. Among others, open problems are related to: (i) the evaluation of the use of exiting models in different languages, (ii) the definition of measures which are accurate for multiple languages and (iii) the definition and study of language-specific processes which can be used to improve measure accuracy.\n5Consider, for instance, a taxonomy in which redundant relationships have been defined \u2013 redundancies highly impact shortest path computation. Should they be considered?\n6Refer to the evaluation proposed at: https://github.com/sharispe/sm-tools-evaluation\n120 CHAPTER 5. CONCLUSION AND RESEARCH DIRECTIONS\nPromote interdisciplinarity\nFrom cognitive sciences to biomedical informatics, the study of semantic measures involves numerous communities. Efforts have to be made to promote interdisciplinary studies and to federate the contributions made in the various fields. We briefly provide a non-exhaustive list of the main communities involved in semantic measure study and the communities/fields of study which must be relevant to solicit to further analyse semantic measures. The list is alphabetically ordered and may not be exhaustive:\n\u2022 Biomedical Informatics and Bioinformatics are very active in the definition and study of semantic measures; these communities are also active users of semantic measures.\n\u2022 Cognitive Sciences propose cognitive models of similarity and mental representations which can be used to (i) improve the design of semantic measures and (ii) better understand human expectations w.r.t similarity/relatedness. This community can also use empirical evaluation studies of semantic measures to discuss the cognitive models it proposes.\n\u2022 Complexity Theory is an important field of study which is essential to analyse complexity of semantic measures.\n\u2022 Geoinformatics defines and studies numerous semantic measures. Members of this community are also active users of semantic measures.\n\u2022 Graph Theory proposed several major contributions relative to graph processing. Such theoretical works are essential for the optimisation of measures relying on network-based ontologies. This community will probably play an important role on knowledge-based semantic measures in the near future, since large semantic graphs composed of billions of relationships are now available \u2013 processing such graphs requires the development of optimised techniques.\n\u2022 Information Retrieval defines and studies semantic measures taking advantage of corpus of texts or ontologies. They also actively contribute to the development of topic models which are central for the design of corpus-based distributional measures.\n\u2022 Information Theory plays an important role in better understanding the notion of information and in defining metrics which can be used to capture the amount of information which is conveyed, shared and distinct between compared elements, e.g., notion of information content.\n\u2022 Knowledge Engineering studies and defines ontologies which will further be used in applications involving semantic measure calculus. It could, for instance, play an important role in characterising the assumptions made by semantic measures.\n\u2022 Linguistics and Natural Language Processing are actively involved in the definition of distributional measures. They propose models to characterise corpus-based semantic proxies and to define measures for the comparison of units of language.\n\u2022 Logic defines formal methods to express and take advantage of knowledge. This community can play an important role in characterising the complexity of knowledge-based semantic measures, for instance.\n\u2022 Machine Learning plays an important role in the definition of techniques and parameterised functions which can be used for the definition and tuning of semantic measures.\n\u2022 Measure Theory defines a mathematical framework to study and define the notion of measure. It is essential for deriving properties of measures, better characterising semantic measures and taking advantage of theoretical contributions proposed by this community.\n\u2022 Metrology studies both theoretical and practical aspects of measurements.\n121\n\u2022 Optimisation area may lead to important contributions in order to optimise measures, to study their complexity and to improve their tuning.\n\u2022 Philosophy also plays an important role in the definition of essential concepts on which semantic measures rely, e.g., definition of the notions of Meaning, Context.\n\u2022 Semantic Web and Linked Data define standards (e.g., languages, protocols) and processes to take advantage of ontologies. The problem of ontology alignment and instance matching are actively involved in the definition of (semantic) measures based on ontologies.\n\u2022 Statistics and Data Mining propose several data analysis techniques which can be used to better characterise and understand semantic measures.\nStudy the algorithmic complexity of semantic measures\nMost contributions have focused on the definition of semantic measures. However, their algorithmic complexity is near inexistent despite the fact that this aspect is essential for practical applications to be efficient and tractable. Therefore, to date, no comparative studies can be made to discuss the benefits of using computationally expensive measures. However, these aspects are essential for comparing semantic measures. Indeed, in most application contexts, users will prefer to reduce measure accuracy for a significant reduction of the computational time and resources required to use a measure. To this end, designers of semantic measures must as much as possible provide the algorithmic complexity of their proposals. In addition, as the theoretical complexity and the practical efficiency of an implementation may differ, developers of software tools must provide metrics to discuss and compare the performance of measure implementations.\nSupport context-specific selection of semantic measures\nBoth theoretical and software tools must be proposed to orient end-users of semantic measures in the selection of measures according to the needs defined by their application contexts. Indeed, despite the fact that most people only (blindly) consider benchmark results in order to select a measure, efforts have to be made in order to orient end-users in the selection of the best suited approaches according to their usage context \u2013 understanding the implications (if any) of using one approach compared to another. To this end, the numerous properties of the measures presented in this book can be used to guide the selection of semantic measures. However, numerous large-scale comparative studies have to be performed in order to better understand the benefits of selecting a specific semantic measure in a particular context of use.\n122 CHAPTER 5. CONCLUSION AND RESEARCH DIRECTIONS"}, {"heading": "Appendix A", "text": "Examples of syntagmatic contexts\nTo illustrate examples of syntagmatic context we will consider the raw text extracted from the Wikipedia article which refers to the topic Tree1 \u2013 sentences are numbered:\n\u201d(1) In botany, a tree is a perennial plant with an elongated stem, or trunk, supporting branches and leaves in most species. (2) Trees play a significant role in reducing erosion and moderating the climate. (3) They remove carbon dioxide from the atmosphere and store large quantities of carbon in their tissues. (4) Trees and forests provide a habitat for many species of animals and plants.\u201d\nFor convenience, in this example only nouns are considered; we obtain the following surface representation of the text:\n(1) botany tree plant stem trunk branch leaf species. (2) tree role erosion climate. (3) carbon dioxide atmosphere quantity carbon tissue. (4) tree forest habitat species animal plant.\nWe will now present three examples of syntagmatic context definitions and examples of processing which can be done to represent words w.r.t their syntagmatic contexts. To reduce the size of the matrices which are used to characterise the words, not all the nouns which compose the surface representation presented above will be represented in matrices. To each context definition we present:\n\u2022 The corresponding word-context matrix which characterises the words w.r.t the context definition which has been defined.\n\u2022 A Figure showing the similarity of the vector representation of each word according to a two dimensional projection \u2013 the aim is to intuitively appreciate the impact that the notion of context can have on the definition of words representation and therefore on the estimation of word similarity. Technically speaking the figure is generated using a MultiDimensional Scaling (MDS) algorithms (Borg and Groenen, 2005) on a similarity matrix between the word vector representations2. The results will not be discussed in detail but we invite the reader to compare the results which have been obtained using those reduced examples.\nThree examples are presented:\n1. The context is defined as a sentence, sj refers to Sentence j. The semantic model is a word-sentence matrix and a word is therefore represented by a vector in which each dimension refers to a sentence \u2013 therefore, if the word wi composes the sentence sj the cell (wi,sj) will be set to 1.\n2. The context is defined as a sentence \u2013 the semantic model is a word-word matrix which highlights the number of time two words co-occured in sentences. The co-occurrences are computed counting all pairs of words which can be made from each sentence. Note that this matrix can be computed from the matrix which have been obtained in Example 1.\n3. The semantic model is a word-word matrix. The context is defined as a five word window, i.e. two words to the left and the right of the focal word. For instance, considering Sentence 1, the\n1http://en.wikipedia.org/wiki/Tree (accessed 26/06/14) 2The similarity between the vectors is computed using the cosine similarity \u2013 presented in Section 2.3.2, Equation 2.4.\n123\n124 APPENDIX A. EXAMPLES OF SYNTAGMATIC CONTEXTS\nwindow associated to the focal word stem would be: botany tree plant stem trunk branches leaves species. The sliding step of the window is defined as one word. Finally for each iteration, the current window is processed and the co-occurrences associated to the focal word are updated, i.e. by counting the pairs of words which can be built with the focal word and the words which compose the window.\n125\nw1 w2 w3 w4 w5 w6 w7 w8 w9 w10 w11 w12 atmosphere w1 1 0 0 0 0 0 0 0 0 0 0 0 botany w2 0 1 0 0 0 0 0 2 0 0 2 0 branch w3 0 0 1 0 0 0 2 0 2 2 0 2 climate w4 0 0 0 1 0 0 0 0 0 0 0 0 forest w5 0 0 0 0 1 2 0 0 2 0 2 0 habitat w6 0 0 0 0 2 1 0 0 2 0 2 0 leaf w7 0 0 2 0 0 0 1 0 2 0 2 2 plant w8 0 2 0 0 0 0 0 2 2 2 2 2 species w9 0 0 2 0 2 2 2 2 2 0 2 0 stem w10 0 0 2 0 0 0 0 2 0 1 2 2 tree w11 0 2 0 0 2 2 2 2 2 2 3 0 trunk w12 0 0 2 0 0 0 2 2 0 2 0 1\n126 APPENDIX A. EXAMPLES OF SYNTAGMATIC CONTEXTS"}, {"heading": "Appendix B", "text": ""}, {"heading": "A brief introduction to Singular", "text": "Value Decomposition\nSingular Value Decomposition (SVD) is one of the fundamental algorithms of linear algebra. It is largely used to factorize matrices in many field related to data analysis. In Computational Linguistics, SVD has been made popular through its use in distributional models that aim to derive (word) meaning representations through the analysis of (word) co-occurrence matrices, e.g. Latent Semantic Analysis (LSA) \u2013 refer to Section 2.3 for an introduction to these models.\nThe main motivation of SVD is to factorize matrices. This is interesting since several distributional models rely on highly dimensional but very sparse spaces. Therefore, their sizes tend to be very large which can be limiting for their processing in practice. SVD is therefore used as a way to reduce model sizes. In addition, since the process of factorization identifies and orders the dimensions along which data points exhibit the most variation, the reduction has the interesting property to reduce noise as well as sparsity. This contributes to improve the quality of the vector representations by focusing on informative dimensions. To this end, SVD consider that the optimal reduction, is the lower dimensional subspace onto which the original data have to be projected while preserving maximal data variability. This is done by grouping dimensions with highly correlated values \u2013 generally 300 dimensions are considered to build vector representation of words. It is however important to stress that the semantics of newly created dimensions can only be explained as a linear combination of the original dimensions this why, when applied to distributional models, SVD are often considered as a method able to reveal latent concepts and high-order co-occurrences. Figure B.1 illustrates the process which is performed by SVD.\nNevertheless, one of the limits of this technique is that, as for any projection/factorization method, the reduction will necessarily imply some loss of information. Indeed, two points (e.g. words) that were originally differentiated into an highly dimensional space can both be projected into the same coordinates in the lower dimensional subspace that has been selected, i.e. they can be both reduced to the same vector representation. Another limit of SVD is their high algorithmic complexity. It can be limiting for processing large models - it must also be computed each time the model is updated.\nTechnical aspects of SVD are largely covered in the literature. We recommend referring to the seminal book of (Golub and Van Loan, 2012). The articles of (Deerwester et al., 1990; Landauer et al., 1998; Turney and Pantel, 2010) are also very good introductions to SVD applied to distributional models.\n127\n128 APPENDIX B. A BRIEF INTRODUCTION TO SINGULAR VALUE DECOMPOSITION"}, {"heading": "Appendix C", "text": ""}, {"heading": "A brief overview of other models for", "text": "representing units of language\nThe definition of models from which the meaning of units of language can be derived is a vibrant and prolific topic in the literature since several decades. This problematic is indeed central for Computational Linguistics and plays an important role for the design of corpus-based semantic measures. As we saw, most corpus-based measures that can be used for comparing words only differ regarding the approach they adopt to represent word meaning, generally through vector-based representations. The way those vectors are next compared is most often unchanged, e.g. using the well-known cosine similarity measure. The large literature related to the definition and combination of models that can be used to manipulate the semantics of complex units of language is therefore central to deeply understand corpus-based semantic measures. Nevertheless, as the reader will understand, this book cannot provide an in-depth presentation of all the models that have been proposed so far. An introduction to several models that rely on the distributional hypothesis has already been proposed in Chapter 2, e.g., VSM, LDA, ESA. Understanding more sophisticated models most often requires technical knowledge about specific machine learning techniques (e.g. neural networks), statistics and linear algebra; this makes more complex their introduction to a large audience. In addition, these sophisticated models are most often not proposed in the aim of assessing semantic similarity/relatedness of units of language, or to generate explicit representations of their meaning. They rather envision a large goal, to model language. These models, denoted language models, can however generally be used to derive useful representations of units of language \u2013 if they do not explicitly integrate such representations in their modeling. Here, we propose a brief introduction to several popular language models. Our main goals are to (i) underline the intuitions that motivate their definitions and (ii) to stress how they can be used in the aim of defining semantic measures \u2013 most of the time to compare words. We will next briefly discuss some of the models that have been proposed to capture the semantics of larger units of language. Technical details of the contributions that we will present can be found on provided references.\nLanguage models\nThe distributional models we have seen so far can be used to derive word meaning representations based on the analysis of statistics on their usage \u2013 they rely on direct or indirect implementations of the distributional hypothesis (cf. Chapter 2). As from now, you can retain that both distributional and language models proposed in the literature, without exception, only differ on the way they capture and take advantage of this information. The aim of distributional models was generally to build word representations in a real space of n dimensions, by representing words through real-value vectors. The language models we will now introduce propose to model language for answering specific tasks in Computational Linguistics or related fields, e.g. machine translation, speech recognition or handwriting recognition to mention a few. These approaches aim to model languages in order to enable predictions such as (i) what are the words that are more likely to appear after a given sequence of continuous words, or (ii) what is the more probable context (e.g. sequence of words) considering a specific word. Designing models that are efficient in answering those questions can for instance be used for question answering, spellchecking or disambiguation.\n129\n130 APPENDIX C. OTHER MODELS FOR REPRESENTING UNITS OF LANGUAGE\nN-gram models\nA simple and popular language model that has been proposed to predict the next word according to given context is the n-gram model (Manning and Schu\u0308tze, 1999) \u2013 since several variations have been proposed we can say that n-gram is a generic approach, a class of models. Depending on the design of the model, a n-gram can be a sequence of n contiguous words, syllables, letters, etc. \u2013 here we only consider ngrams of words; n is generally set between 1 and 5 in this case. N-gram models rely on the analysis of the statistical properties of n-grams in texts. These statistical properties are derived by scanning large corpora composed of billions of words using a sliding window of size n with a specific step.1 Therefore, using those statistics about word sequence observations, it is possible to predict the word wn based on the context of its n\u2212 1 preceding words (w1, . . . , wn\u22121). More precisely, we can compute the probability that a specific word w will occur after a given sequence S of n\u2212 1 words; this is defined by p(w|S) :\np(w|S) = o(S,w) o(S)\n(C.1)\nWith o(S) the number of time the sequence S has been observed and o(S,w) the number of time S was directly followed by the word w. Using basics of Information Theory, n-gram models have the ability to predict sequential data by estimating the probability p(wn|w1, . . . , wn\u22121). As any Markov model, these models assume the independence hypothesis, i.e. that wn only depends on w1, . . . , wn\u22121.2 A n-gram model can therefore be used to compute the conditional probability distribution of words knowing a word sequence of size n\u2212 1. This can be used to derive the likelihood of a word knowing a specific n\u2212 1 sequence of words. More importantly for our concern, the conditional probabilities of a word for all the sequences that have been observed can be used to obtain a vector representation of a word. Once again, this representation encompasses information about the usage of the word, and is therefore assumed to give access to some of its meaning. Note that this representation is built considering a specific type of syntagmatic context (refer to Section 2.2). Nevertheless, this approach can be difficult to implement in practice because of the large number of sequences that are observed; this number corresponds to the number of dimensions of the space into which words will be represented. Indeed, due to the high variability of n-grams in language, the n-gram model suffers the curse of dimensionality. Otherwise stated, the number of parameters of n-gram models (i.e. number of n \u2212 1 sequences that have been observed) grows exponentially with n. Nevertheless, most of the dimensions will be set to zero and only very sparse vectors will have to be compared. In (Joubarne and Inkpen, 2011) the authors adopt two other approaches that study the distribution of words among n-grams. The first approach estimates the relatedness of two words by considering their PMI (Point-wise Mutual Information), i.e. the probability that the two words occur in the same n-gram divided by the probabilities they occur. The second approach relies on the Second Order Co-occurrence PMI (SOC-PMI) that have been defined in (Islam and Inkpen, 2006). N-gram statistics have also been used in the design of semantic measures dedicated to the comparison of sentences (Ba\u0308r et al., 2012).\nN-gram models provide good results when trained with large corpus. However, one of the main drawbacks of this probabilistic model is that, per definition, it poorly performs with n-grams that are not observed in the learning corpus. As an example, consider the following sequence of words: \u201che was driven his bike\u2019. If the model is built using a 4-gram strategy, the likelihood associated to the word bike considering the context \u201che was driving\u201d will be derived from the amount of time the association context+\u201cbike\u201d has been encountered in the corpus. Therefore, if the association never occurs, the likelihood of the word bike knowing aforementioned context will de facto be set to zero. Since the model suffers the curse of dimensionality, this problem increases the larger n is set. This stresses the second limit of these models: their dependency to very large datasets. Several strategies have therefore been studied to overstep these limits. As an example, several forms of smoothing techniques have been studied to avoid and prevent problems induced by unseen n-grams. These techniques are essential to ensure good performance. Several other adaptations have been proposed to overcome the data sparsity issue, i.e. the fact that input data will only give access to a reduce set of the language diversity; skip-gram is one of these proposals (Guthrie et al., 2006). This model generalises n-gram by allowing words to be skipped in order to generate n-gram that would not have been seen while they could improve language modeling. As an example, considering the phrase \u201cFrance is a beautiful country...\u201d, a 1-skip-3gram will generate the following 3-grams : \u201cFrance is a\u201d, \u201cFrance a beautiful\u201d, \u201cis a beautiful\u201d, \u201cis beautiful country\u201d, \u201ca\n1Google provides interesting results on n-gram statistics over time at: https://books.google.com/ngrams 2The fact that this assumption is rough for language modeling is not questioned. This restriction is however required\nto ensure tractable algorithmic complexity.\n131\nbeautiful country\u201d, \u201ca country\u201d. Another interesting variation of n-gram models are cache models (Kuhn and De Mori, 1990). They rely on the simple idea that words recently observed are more likely to appear again in the short term. Consider for instance the case of rare words that will often occur in a specific text, e.g. the word Paris will often occur in a text talking about the French capital. Therefore, cache models propose to keep track of recent contexts when estimating the probability distributions of words. Others variants are class-based models (Brown et al., 1992); they propose to replace words by classes of words sharing specific features. By reducing the number of n-grams that are possible, they reduce the number of parameters of the model (i.e. fighting the curse of dimensionality). This approach can also be used to derive probability distributions for unseen contexts.\nContribution and results related to n-gram models are numerous; we have here introduced basics of this popular class of models. We have also discussed how they can be used to compute the relatedness of words. Despite their limits, n-gram models (including variants) are still very popular and competitive language models. They are used in numerous practical applications. This is especially true considering that improvements that are achieved using more complex models are often made at the cost of a significant increase of computational complexity \u2013 an increase that is often unacceptable considering the constraints of real world applications.\nEven if adaptations have been proposed to solve drawbacks of n-gram models, the dependency of this approach to very large corpora is still considered as incompatible with several contexts \u2013 remind that we are talking about billions of words, constituting such a dataset can be problematic in specific domains. This has encouraged the study of models that are less greedy and that can be used considering significantly smaller input datasets. We can therefore say that by being very costly in terms of input datasets but very cheap in terms of computational complexity, n-gram models implement a kind of nobrain or brute force approach in modeling language. Alternative language models, by being cheap in terms of input dataset requirement but costly in terms of computational complexity, propose to adopt an opposite strategy using more refined learning approaches. Some of these models are now briefly introduced.\nSome statistical learning models have been studied to overcome the intrinsic limitations of n-gram models. During the learning phase, these models directly learn and process representations of units of language \u2013 once again, for convenience, we will here focus on word representation. Based on word usage analysis, these approaches build (implicit) word representations by optimizing the performance of a statistical learning algorithm with respect to a specific goal. As an example, such a model can be a neural network that, similarly to n-gram, will be able to predict the most probable word considering a given context. Such language models implicitly or explicitly rely on word modeling. A representation of word, often in the form of a vector, can generally be derived from them. Therefore, compared to classical distributional models that will simply build word representations by considering a deterministic approach, learning methods will implicitly learn word representations using heuristics that will optimize models \u2013 that internally encompass or depend on these word representations. This is why these methods are generally said to learn word representations, or more explicitly learn models from which word representations can be extracted. It is important to stress that, as we said, the primary source of information available to all methods for learning word representations is still word usage in a corpus \u2013 they therefore also extensively rely on the distributional hypothesis. Several type of learning approaches can be used to derive language models. Among the most popular, we will discuss the language models that are based on neural networks. Other types of models will next be cited.\nNeural network models\nThe main rationale of Neural Network Language based Models (NNLM) is to take advantage of similarities between contexts for assessing the probability distribution of words considering a given context. Indeed, as we saw, when assessing the likelihood of words for a specific context, simplest n-gram models will only consider observations in which this exact context has been observed.3 However, even if the sequence \u201che was driven his bike\u201d has never been observed, it is intuitive to say that the context \u201che was driven his\u201d is more likely to generate the words car, bike or truck than the words mountain or house. This can once again simply be explained by the distributional hypothesis: words that frequently occur with the word drive are more likely to be referring to things that can be driven (i.e. vehicle). It could therefore be interesting to provide a way to represent contexts in such a way that, by learning the probability distribution associated to a context, knowledge for similar contexts will be generalized \u2013\n3We have seen that smoothing have next been proposed to correct this limit but put this aside for now.\n132 APPENDIX C. OTHER MODELS FOR REPRESENTING UNITS OF LANGUAGE\ni.e. to design an approach that will be robust to slight variations of contexts. This is the main aim of NNLMs. Similar contexts are, in some sense, processed similarly in order to generalize knowledge that can be extracted from occurrences. As an example, the observation \u201che was driven his bike\u201d will not only contributes to improve the likelihood to see bike after the context \u201che was driven his\u201d. It will also improve the likelihood to see the words car, truck, etc. after this specific context. Technically, the generalization is made possible by projecting observations onto a low-dimensional space, and by building a model that will generate word conditional distribution probabilities from this projection. Therefore, two observations that are similar will (hopefully) be projected the same way. Thus, similar sets of parameters will be learned for similar observations. Parameters of the model are in some sense shared among similar observations. This is an important point: NNLMs share parameters among similar observations in order to overcome the exponential increase of parameters when considering large contexts.\nA variety of NNLM architectures have been proposed. For language models that aim to compute conditional probabilities of words from a vocabulary V knowing a specific context (i.e. sequence of continuous words), several NNLMs adopt the following setting. They consider that input words are represented by vectors \u2013 such representations can simply be built by considering that each word is associated to a unique identifier between 0 and |V | \u2212 1, and that its corresponding vector is a vector of size |V | filled with 0 values, expect for the dimension associated to its identifier which is set to 1. These representations are used to derive the representation of a n-word context (sequence observation) \u2013 generally setting n between 5 and 10. This is done by building a n\u00d7|V | matrix that contains the vectors of the words of the context. Finally, considering numerous contexts and expected next word probability distribution provided by the input dataset, the NNLM learn optimal parameters of the model and optimal word representations. The aim is to set these variables such as the model will generate word probability distributions best fitting expectations. This setting has first been defined in (Bengio et al., 2003). In this case, word representations are simply learned by the model and can therefore be used in a straightforward manner to compare words using measures designed for comparing vectors.\nContributions on NNLMs have led to many results. Numerous contributions have for instance focused on designing recurrent NNLMs, e.g. to avoid the fact that in (Bengio et al., 2003) the context size had to be defined manually (Mikolov et al., 2013). Among them we invite the reader to refer to the numerous contributions of Mikolov. In conclusion, NNLMs are generally considered to be complex models with regard to their computational requirements. Nevertheless, they have the interesting property of achieving efficient results with reduced input datasets.\nMore generally we encourage the reader to refer to embedding-based methods that can be used to build elaborated representations of units of language from which semantic similarity and relatedness measures can be defined. In addition, other types of language models have been proposed and will not be introduced in this book. Among others we can cite: conditional restricted Boltzmann machine, (hierarchical) log-bilinear models, global log-bilinears (Pennington et al., 2014). A brief introduction of several models can be found in (Mikolov, 2012).\nCompositionality: representing complex units of language\nAs we saw, a substantial literature is dedicated to the definition and analysis of models that aim to represent word meaning. An important area of research is also dedicated to the study of how larger units of language such as compound words, noun-adjective pairs or sentences can be represented. This challenge aim to define compositional approaches that represent meaning of units of language by combining different models representing meaning of their constituents. Compositional approaches assume that, since complex units of language are built by compositions (of simpler units) \u2013 sentences are sequences of words -, their meaning is also formed by composition. It is here considered that \u201cthe meaning of complex expression is a function of the meaning of its parts and of their syntactic mode of combination\u201d.4 Central questions faced by compositionality are therefore (i) how to finely capture the semantics of short units of language through representations and (ii) how to combine them to derive meaning of their combination. A large number of contributions related to the former question have already been introduced, we now expose how they can be combined to derive compositional models; once again the following introduction is far to cover the diversity of the literature on this topic.\nSimple models of compositionality have for instance proposed to give access to the meaning of a sentence by aggregating vector representations of its words using linear models. As an example (Landauer\n4http://plato.stanford.edu/entries/compositionality \u2013 we strongly encourage the reader to refer to this resource for a complete and historical introduction to the notion of compositionality.\n133\nand Dumais, 1997) propose to represent a sentence by averaging the vector representations of its word. More generally, (Mitchell and Lapata, 2010) present a framework to combine word representations in order to represent the meaning of phrase or sentence into a vector space. This framework can be used to generate models by defining composition through the aggregation of representations by vector functions such as addition and multiplication. Another approach that has been tested by several authors proposes to model composition in terms of matrix multiplication. In (Baroni and Zamparelli, 2010) the authors define a compositional model for pairs of adjective-words by multiplying vector representations of words by matrix representations of adjectives. Several operations that can be performed on vector model to derive compositional models are discussed in (Widdows, 2008). An original approach that defines compositionality in terms of similarity composition is also exposed in (Turney, 2012).\nSimplest approaches based on linear models fail to model the complexity of the semantics of large units of languages. This is mainly because word ordering is not taken into account. More generally, any model that only relies on commutative operations such as addition or multiplication will not take into account syntax, order of language constituents, and negation. More complex models have therefore been proposed; some of them are limiting as they generate highly dimensional representations that depend on a large number of parameters. In (Socher et al., 2011), an interesting model based on a nonlinear function is studied to overcome limits of simple compositional models. In (Socher et al., 2012) the authors propose to model compositionality by considering learning models in which words of a sentence, represented by vectors, are structured through a parse tree; matrices are also used to model the effect of the sequential ordering of words on the global semantics of the sentence.\nDesigning efficient models that are able to capture the meaning of large units of language is an important challenge faced by Computational linguistics. This is also central for the design of accurate semantic measures that will be able to compare complex units of language by finely analysing their semantics. Thanks to an increasing interest on compositional models, and to a better understanding of the perspectives they open, a large number of contributions have recently been made; they have lead to more efficient models but have also underlined the wideness of this complex field of study. We advise interested readers to consult (Kamp et al., 2014) and the website of the Composes project5 that is dedicated to this vibrant topic (Baroni et al., 2014) \u2013 the website references important documentations and publications, as well as software, models and datasets used for evaluation.\n5Compositional Operations in Semantic Space, European Research Council project (nr. 283554): http://clic.cimec. unitn.it/composes\n134 APPENDIX C. OTHER MODELS FOR REPRESENTING UNITS OF LANGUAGE"}, {"heading": "Appendix D", "text": "Software tools and source code libraries\nThis appendix provides an overview of existing software solutions and source code libraries dedicated to semantic measure computation and analysis. These contributions are important to both usage and evaluations of semantic measures. First, they provide implementations of existing proposals to end-users and therefore contribute to the large adoption of semantic measures - this is not a little thing considering that implementations are most often very technical. Second, by providing common platforms for measure evaluation, these development projects are also essential to support research contributions in the field. They enable to reproduce experiments and provide easy-way for researchers to test and evaluate new proposals. This aspect is particularly important since evaluation of semantic measures extensively relies on empirical analyses (c.f. Chapter 4).\nThroughout this book we have underlined that numerous groups of researchers are deeply involved in the study of semantic measures, e.g. Natural Language Processing, Artificial Intelligence, Semantic Web and Bioinformatics, to mention a few. Moreover, due to their popularity, numerous proposals exist for a wide range of applications - refer to the large collection of measures presented in chapters 2 and 3. Nevertheless, no extensive software tool today federates the various communities through a common development and application framework. Most of the contributions are supported by few developers and only exist thank to their will to develop, correct and support useful tools for the community.\nA few popular and robust solutions exist for computing corpus-based measures. These tools can most often be used on any (english) corpora. Specific distributional models build from popular corpora are also generally provided. However, for a long time, most software solutions dedicated to knowledge-based measures were developed for particular applications and ontologies, e.g. in the biomedical domain.\nThe aim of this appendix is not to provide an extensive comparison of the tools that are presented. Ordering of tools is therefore made considering subjective criteria such as popularity of the tool in the community, functionalities provided, source code base, documentation available, support. We invite the reader to refer to the official websites for more information about these tools. The information presented hereafter has been obtained in January 2015, improvements could have been made and the developer base may have also change. In addition, the authors of this book are related to the Semantic Measures Library a project that will be presented hereafter. Nevertheless, even if we provide slightly more information about this project compared to the others, we will not provide detailed information about the project since our objective is to introduce the reader to the diversity of tools available to date. Since the large majority of projects focus on corpus-based or knowledge-based measures, but do not cover both types, we first present those dedicated to the former to next discuss those related to the latter. Finally, we discuss the tools that have been proposed to ease measure evaluation.\nTools for corpus-based semantic measures\nTable D.1 presents several free source code libraries and software solutions that can be used to compute the semantic similarity/relatedness between pairs of words and/or sentences. Most of the measures implemented in these tools evaluate semantic relatedness analysing syntagmatic relationships. Note also that the documentation of the tools sometimes refers to the notion of semantic similarity without considering the definition adopted in this book \u2013 and therefore semantic similarity most often refer to\n135\nsemantic relatedness. For each tool we provide: its name, associated reference (and starting date), the type of objects that can be compared and the type of the tool: LIB refers to source code library, CLI to command-line tool1, and GUI to Graphical User Interface. The programming language used for the development is also specified.\nA brief description of each tool is also provided hereafter.\nDKPro Similarity is a framework dedicated to the comparison of pairs of words and pairs of texts (Ba\u0308r et al., 2013). It provides numerous implementations of state-of-the-art semantic relatedness measures in Java - some knowledge-based measures are also available to compare WordNet synsets. This project is part of the DKPro Core2 project which develops a collection of software components dedicated to NLP. These components have the interesting properties to be based on the Apache UIMA framework. The last version of DKPro Similarity has been release in October 2013 (version 2.1.0), it is distributed under the open-source Apache Software Licence. The source code and extensive documentation are available from the dedicated website. Website: https://code.google.com/p/dkpro-similarity-asl\nSemilar proposes a software and development environment dedicated to corpus-based semantic measures (Rus et al., 2013). It provides both a Java library and a GUI-based interface. Semilar can be used to compare words and sentences. Numerous measures have been implemented, and several distributional models are made available. Semilar is still in alpha version (2014), consult the website for licence information. Website: http://www.semanticsimilarity.org\nDisco is an open-source Java library dedicated to the semantic similarity computation between words (Kolb, 2008, 2009). The tool is distributed under the Apache License, version 2.0. Several measures are implemented. Interestingly, numerous languages are also supported: Arabic, Czech, Dutch, English, French, German, Italian, Russian, and Spanish. Last version available to date is version 1.4 (released in 2013). Website: http://www.linguatools.de/disco/disco_en.html\nNLTK is a popular and elegant NLP platform developed in Python (Bird, 2006). It contains a module dedicated to WordNet which provides specific semantic measures for comparing two synsets (no extensive list of measures available). In addition, (Tomasik and Sutherland, 2008) present a NLTK module for large-scale computation of specific corpus-based measures. NLTK is distributed under the Apache 2.0\n1Most of tools provide a way to execute source code using command lines. CLI refers to interfaces that are used to guide the user by providing documentation, multiple parameter tuning, batch computation capabilities, etc.\n2https://code.google.com/p/dkpro-core-asl\n137\nlicense. Website: http://www.nltk.org\nGenSim is a Python platform dedicated to statistical semantics (Rehurek and Sojka, 2010). It is well documented and provides several efficient distributional models and measures implementations. Gensim is distributed under the LGPL Licence. Both open-source and business supports are provided. The last release has been developed in 2014. Website: https://radimrehurek.com/gensim\nWikiBrain is a well-documented Java project that proposes Wikipedia-based algorithms for semantic relatedness computation (Sen et al., 2014). It can be used to compare both sentences and Wikipedia pages (topics). According to the documentation, efforts have been made to ensure efficiency and shorten computational time. WikiBrain is distributed under the Apache 2.0 license. The project is today actively maintained. WikiBrain is also a nice project to consider for those interested in interacting with Wikipedia Website: http://shilad.github.io/wikibrain\nTakeLab Semantic Text Similarity System is a Python code that can be used to compare two sentences (Saric\u0301 et al., 2012). It is licensed under a derivative of a BSD-license that requires proper attribution (c.f. website). This source code corresponds to a submission proposed to the SemEval evaluation campaign (cf. to Chapter 4 for more information). Website: http://takelab.fer.hr/sts\nSemSim is a Java library that can be used to evaluate the semantic relatedness of words and to compute distributional models from texts. It can also be used to compute distributional models. The source code is distributed under licence LGPL v3. The last version has been released in 2013. Website: https://github.com/marekrei/semsim\nMechaglot can be used to compare sentences. It is distributed under the Creative Commons AttributionShareAlike 4.0 International License. This project is still under development and to date only provides an alpha version for developers. Website: http://mechaglot.sourceforge.net\nNumerous web services and web interfaces can be used to compute semantic relatedness between words and texts. Since these links may change and/or the services may not be supported in the future, we orient the reader to the updated list of links provided at Wikipedia: http://en.wikipedia.org/ wiki/Semantic_similarity.\nTools for knowledge-based semantic measures\nMost software solutions dedicated to knowledge-based semantic measures have been developed for a specific usage context and are dedicated to a specific ontology/ structured terminology, e.g., Wordnet (Pedersen et al., 2004), Unified Medical Language System (UMLS) (McInnes et al., 2009), the Gene Ontology (GO)3, the Disease Ontology (DO) (Li et al., 2011), Medical Subject Headings (MeSH) (Pirro\u0301 and Euzenat, 2010a). By supporting Web Ontology Language (OWL), Resource Description Framework (RDF) and Open Biomedical Ontologies (OBO) format, some tools have also been developed in a generic manner. They can be used with any ontology defined in these formats.\nTable D.2 summarises some characteristics of existing libraries/tools. We present the name of the tool, the ontologies and formats that are supported, the type of tools, command-line tool (CLI) and/or source code library (LIB). We also specify the programming language and if the measure can be used to compare pairs of concepts (P) and/or pairs of groups of concepts (G).\nIn the following, for convenience, semantic similarity/relatedness refers to knowledge-based semantic similarity/relatedness. We also recall that DKPro Similarity and NLTK implement measures that can be used to compare two synsets.\n3Note that half a dozen libraries/tools are dedicated to the Gene Ontology: http://www.geneontology.org/GO.tools_ by_type.semantic_similarity.shtml\nA brief description of each tool presented in Table D.2 is also provided:\nSML stands for Semantic Measures Library (Harispe et al., 2014a). This is a Java library dedicated to semantic measure computation, development and analysis. It is developed by Se\u0301bastien Harispe, one of the author of this book. SML implements numerous measures for comparing concepts and groups of concepts defined into ontologies. Numerous formats (OBO, RDF, OWL) and domain-specific ontologies are supported (e.g., WordNet, MesH, SNOMED-CT). Fine tuning is made available to control measure parameters and data pre-processing. In addition to the library, a command-line toolkit is also developed for non-developers. Both the library and the toolkit are optimized to handle large dataset and to ensure fast computation4. They are distributed under a GPL compatible license. Last release: 2014. Website: http://www.semantic-measures-library.org\nFastSemSim is a Python library dedicated to semantic similarity computation (Guzzi et al., 2012). It can be used to compare pairs of concepts and pairs of groups of concepts. Any OBO ontology can be loaded. Other formats can also manually be loaded into specific data structures that can be considered as data sources by the library. FastSemSim is designed to provide efficient implementation of measures. It is distributed under the GPL Licence. Last version: 2014 Website: https://sites.google.com/site/fastsemsim/\nSimPack is a Java library that can be used to compare pairs of concepts defined into ontologies (Bernstein et al., 2005). It implements a large variety of measures and can load RDF/OWL ontologies. SimPack is distributed under the LGPL license. SimPack has not been updated since 2008. Website: https://files.ifi.uzh.ch/ddis/oldweb/ddis/research/simpack/\nSemMF is a Java library that can be used to compare objects defined into RDF graphs. It is distributed under LGPL licence(Oldakowski and Bizer, 2005). Website: http://semmf.ag-nbi.de/doc/index.html\n4A comparison with other tools is provided at: https://github.com/sharispe/sm-tools-evaluation\n139\nOntoSim is an efficient Java library dedicated to the comparison of ontologies (David and Euzenat, 2008). Several measures provided in this library can also be used to compare objects defined into RDF graphs. Website: http://ontosim.gforge.inria.fr/\nYTEX Semantic Similarity is a Java library that can be used to compare two concepts or two groups of concepts defined into an ontology (Garla and Brandt, 2012). The library can be used with UMLS, SNOMED-CT and MeSH. It is also possible to load other ontologies through SQL queries. Website: https://code.google.com/p/ytex/wiki/SemanticSim_V06\nThe Similarity Library is Java library that can be used to compare pairs of concepts defined into several ontologies (WordNet, MesH, GO) (Pirro\u0301 and Euzenat, 2010a). The library is made available on request. Website: https://simlibrary.wordpress.com/\nWordNet-Similarity is a Perl module dedicated to semantic similarity and relatedness measures between WordNet synsets (Pedersen et al., 2004). This package has been largely used in the literature. Last version: 2008. Website: http://wn-similarity.sourceforge.net/\nWS4J is a Java library dedicated to the development of semantic measures for WordNet. It is distributed under the GPL licence. Last version: 2013 Website: http://code.google.com/p/ws4j/\nUMLS-Similarity is a Perl module that can be used to compare concepts defined into UMLS (McInnes et al., 2009) Website: http://umls-similarity.sourceforge.net/\nOWLSim is a Java Library for the comparison of pairs of concepts defined in OBO or OWL format (Washington et al., 2009). Last version: 2013. Website: http://code.google.com/p/owltools/wiki/OwlSim\nDOSim is an R package dedicated to semantic similarity computation for the Disease Ontology (Li et al., 2011). DOSim is distributed under the GPL licence. Last version: 2010 Website: http://210.46.85.150/platform/dosim/\nDOSE is another R package dedicated to semantic similarity computation for the Disease Ontology. DOSE is distributed under the Artistic-2.0 licence. Website: http://www.bioconductor.org/packages/release/bioc/html/DOSE.html\nTools for the analysis of semantic measures\nTools and source code libraries implementing numerous measures have been presented in the previous section. They represent important contributions for those interested in comparing new proposals, and can be used to select measures adapted to a specific domain. We now provide specific information relative to four tools that provide interesting functionalities for measure evaluation. Recall that protocols and dataset evaluation have been introduced in Chapter 4.\nDKPro Similarity provides several functionalities that can ease the evaluation of semantic measures. It gives access to several evaluation datasets and experiments that are commonly used to compare corpusbased semantic measures, e.g. it contains several word pair similarity/relatedness datasets5. DKPro similarity can also be used to reproduce SemEval-2012 best system6 \u2013 more information about this tool can be found in Section D.\n5https://code.google.com/p/dkpro-similarity-asl/wiki/WordPairSimilarity 6https://code.google.com/p/dkpro-similarity-asl/wiki/SemEval2013\n140 BIBLIOGRAPHY\nSML provides numerous knowledge-based measures implementation that can be used through parametric functions. These implementations and additional code included into the library provide an easy way to compare semantic measure, e.g. regarding their accuracy. As an example, in Figure D.1, the surfaces represent the accuracy of large configuration of measures \u2013 each point in the surface corresponds to the accuracy of a specific measure configuration. Tsversky ratio and contrast models abstract functions were used; these measures can be expressed through parametric functions depending on two parameters alpha and beta \u2013 here represented by the abscissa and the ordinate in the figures. Therefore, each figure corresponds to a specific expression of other parameters of the measures that are fixed. The evaluation is made by comparing estimated similarity with human expected values. This experiment underlines the benefits of efficient tools dedicated to semantic measure computation and to analysis semantic measures \u2013 details are provided in (Harispe et al., 2013c). More information about SML are also given in Section D.\nSemEval is an evaluation campaign related to semantic analysis in which several tracks are related to semantic measures. We encourage the reader to consult the resources that are made available for these tasks. Tools and source codes are generally provided to ease measure evaluation. More information can be found on the wiki maintained by the IXA Group from the University of the Basque Country: http://ixa2.si.ehu.es/stswiki.\nCESSM is a platform that can be used to evaluate semantic measures over the Gene Ontology (Pesquita et al., 2009b). Several evaluation strategies are implemented. New measures can thus be compared to existing results. Datasets used in the evaluations can also be downloaded. The source code is not available to download but can be requested to the platform maintainers. Website: http://xldb.di.fc.ul.pt/tools/cessm"}], "references": [], "referenceMentions": [], "year": 2017, "abstractText": "Artificial Intelligence federates numerous scientific fields in the aim of developing machines able to assist human operators performing complex treatments \u2013 most of which demand high cognitive skills (e.g. learning or decision processes). Central to this quest is to give machines the ability to estimate the likeness or similarity between things in the way human beings estimate the similarity between stimuli. In this context, this book focuses on semantic measures: approaches designed for comparing semantic entities such as units of language, e.g. words, sentences, or concepts and instances defined into knowledge bases. The aim of these measures is to assess the similarity or relatedness of such semantic entities by taking into account their semantics, i.e. their meaning \u2013 intuitively, the words tea and coffee, which both refer to stimulating beverage, will be estimated to be more semantically similar than the words toffee (confection) and coffee, despite that the last pair has a higher syntactic similarity. The two state-of-theart approaches for estimating and quantifying semantic similarities/relatedness of semantic entities are presented in detail: the first one relies on corpora analysis and is based on Natural Language Processing techniques and semantic models while the second is based on more or less formal, computer-readable and workable forms of knowledge such as semantic networks, thesaurus or ontologies. Semantic measures are widely used today to compare units of language, concepts, instances, or even resources indexed by them (e.g., documents, genes). They are central elements of a large variety of Natural Language Processing applications and knowledge-based treatments, and have therefore naturally been subject to intensive and interdisciplinary research efforts during last decades. Beyond a simple inventory and categorization of existing measures, the aim of this monograph is to convey novices as well as researchers of these domains towards a better understanding of semantic similarity estimation and more generally semantic measures. To this end, we propose an in-depth characterisation of existing proposals by discussing their features, the assumptions on which they are based and empirical results regarding their performance in particular applications. By answering these questions and by providing a detailed discussion on the foundations of semantic measures, our aim is to give the reader key knowledge required to: (i) select the more relevant methods according to a particular usage context, (ii) understand the challenges offered to this field of study, (iii) distinguish room of improvements for state-of-the-art approaches and (iv) stimulate creativity towards the development of new approaches. In this aim, several definitions, theoretical and practical details, as well as concrete applications are presented. keywords: Semantic similarity, semantic relatedness, semantic measures, distributional measures, domain ontology, knowledge-based semantic measure.", "creator": "LaTeX with hyperref package"}}}