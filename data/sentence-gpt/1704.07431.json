{"id": "1704.07431", "review": {"conference": "EMNLP", "VERSION": "v1", "DATE_OF_SUBMISSION": "24-Apr-2017", "title": "A Challenge Set Approach to Evaluating Machine Translation", "abstract": "Neural machine translation represents an exciting leap forward in translation quality. But what longstanding weaknesses does it resolve, and which remain? We address these questions with a challenge set approach to translation evaluation and error analysis. A challenge set consists of a small set of sentences, each hand-designed to probe a system's capacity to bridge a particular structural divergence between languages. To exemplify this approach, we present an English-French challenge set, and use it to analyze phrase-based and neural systems. The resulting analysis provides not only a more fine-grained picture of the strengths of neural systems, but also insight into which linguistic phenomena remain out of reach.\n\n\n\n\nThe challenge to understand the implications of this challenge requires an approach that is able to be both novel and non-linear, in the context of an attempt to understand why a language has become such a \"transformation\" across languages. The challenge is to investigate why an entire culture can be written in different languages. We are exploring several other approaches to understanding the effect on a language's ability to speak and express in order to help to understand the impact of a language's linguistic system on the development of language comprehension and language comprehension.\nThe challenge is to understand how the language itself can change over time. In addition to understanding the ways language itself can transform itself and its language, we will use this approach to develop a new understanding of the language itself. The challenge is to find a common sense explanation that enables us to understand how language is changing and how that changes in language comprehension and language comprehension in particular.\nIf you are interested in the key characteristics of language, including the potential consequences of learning language, it should be viewed as a possible form of cognitive science. While there are currently no formal models of the possible influence of language on language comprehension in terms of what is in the natural language and what is not. However, we can look into this approach with great skepticism because it is not in principle an adequate method to understand exactly why language is changing or what it is doing.", "histories": [["v1", "Mon, 24 Apr 2017 19:34:38 GMT  (43kb)", "http://arxiv.org/abs/1704.07431v1", "26 pages, including appendix"], ["v2", "Fri, 5 May 2017 16:28:52 GMT  (55kb)", "http://arxiv.org/abs/1704.07431v2", "27 pages, including appendix. Machine readable data included in a separate file"], ["v3", "Wed, 10 May 2017 00:03:19 GMT  (55kb,A)", "http://arxiv.org/abs/1704.07431v3", "27 pages, including appendix. Machine readable data included in a separate file"], ["v4", "Sun, 6 Aug 2017 17:13:11 GMT  (56kb,A)", "http://arxiv.org/abs/1704.07431v4", "EMNLP 2017. 28 pages, including appendix. Machine readable data included in a separate file"], ["v5", "Tue, 29 Aug 2017 02:08:33 GMT  (56kb,A)", "http://arxiv.org/abs/1704.07431v5", "EMNLP 2017. 28 pages, including appendix. Machine readable data included in a separate file. This version corrects typos in the challenge set"]], "COMMENTS": "26 pages, including appendix", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["pierre isabelle", "colin cherry", "george f foster"], "accepted": true, "id": "1704.07431"}, "pdf": {"name": "1704.07431.pdf", "metadata": {"source": "CRF", "title": null, "authors": [], "emails": ["first.last@nrc.gc.ca"], "sections": [{"heading": null, "text": "ar X\niv :1\n70 4.\n07 43\n1v 1\n[ cs\n.C L\n] 2\n4 A\npr 2\n01 7\nexciting leap forward in translation quality. But what longstanding weaknesses does it resolve, and which remain? We address these questions with a challenge set approach to translation evaluation and error analysis. A challenge set consists of a small set of sentences, each hand-designed to probe a system\u2019s capacity to bridge a particular structural divergence between languages. To exemplify this approach, we present an English-French challenge set, and use it to analyze phrase-based and neural systems. The resulting analysis provides not only a more fine-grained picture of the strengths of neural systems, but also insight into which linguistic phenomena remain out of reach."}, {"heading": "1 Introduction", "text": "The advent of neural techniques in machine translation (MT) (Kalchbrenner and Blunsom, 2013; Cho et al., 2014; Sutskever et al., 2014) has led to profound improvements in MT quality. For \u201ceasy\u201d language pairs such as English/French or English/Spanish in particular, neural (NMT) systems are much closer to human performance than previous statistical techniques (Wu et al., 2016). This puts pressure on automatic evaluation metrics such as BLEU (Papineni et al., 2002), which exploit surface-matching heuristics that are relatively insensitive to subtle differences. As NMT continues to improve, these metrics will inevitably lose their effectiveness. Another challenge posed by NMT systems is their opacity: while it was usually clear which phenomena were ill-handled by previous statistical systems\u2014and why\u2014these questions are more difficult to answer for NMT.\nWe propose a new evaluation methodology centered around a challenge set of difficult examples that are designed using expert linguistic knowledge to probe an MT system\u2019s capabilities. This methodology is complementary to the standard practice of randomly selecting a test set from \u201creal text,\u201d which remains necessary in order to predict performance on new text. By concentrating on difficult examples, a challenge set is intended to provide a stronger signal to developers. Although we believe that the general approach is compatible with automatic metrics, we used manual evaluation for the work presented here. Our challenge set consists of short sentences that each focus on one particular phenomenon, which makes it easy to collect reliable manual assessments of MT output by asking direct yes-no questions. An example is shown in Figure 1.\nWe generated a challenge set for English to French translation by canvassing areas of linguistic divergence between the two language pairs, especially those where errors would be made visible by French morphology. Example choice was also partly motivated by extensive knowledge of the weaknesses of phrase-based MT (PBMT). Neither of these characteristics is essential to our method, however, which we envisage evolving as NMT progresses. We used our challenge set to evaluate in-house PBMT and NMT systems as well as Google\u2019s GNMT system.\nIn addition to proposing the novel idea of a challenge set evaluation, our contribution includes our annotated English-French challenge set, which we provide in an appendix and will make available in a separate machine-readable file. We also supply further evidence that NMT is systematically better than PBMT, even when BLEU score differences are small. Finally, we give an analysis of the challenges that remain to be solved in NMT, an area that has received little attention thus far."}, {"heading": "2 Related Work", "text": "A number of recent papers have evaluated NMT using broad performance metrics. The WMT 2016 News Translation Task (Bojar et al., 2016) evaluated submitted systems according to both BLEU and human judgments. NMT systems were submitted to 9 of the 12 translation directions, winning 4 of these and tying for first or second in the other 5, according to the official human ranking. Since then, controlled comparisons have used BLEU to show that NMT outperforms strong PBMT systems on 30 translation directions from the United Nations Parallel Corpus (Junczys-Dowmunt et al., 2016a), and on the IWSLT English-Arabic tasks (Durrani et al., 2016). These evaluations indicate that NMT performs better on average than previous technologies, but they do not help us understand what aspects of the translation have improved.\nSome groups have conducted more detailed error analyses. Bentivogli et al. (2016) carried out a number of experiments on IWSLT 2015 EnglishGerman evaluation data, where they compare machine outputs to professional post-edits in order to automatically detect a number of error categories. Compared to PBMT, NMT required less postediting effort over-all, with substantial improvements in lexical, morphological and word order errors. NMT consistently out-performed PBMT, but its performance degraded faster as sentence length increased. Later, Toral and Sa\u0301nchez-Cartagena (2017) conducted a similar study, examining the outputs of competition-grade systems for the 9 WMT 2016 directions that included NMT competitors. They reached similar conclusions regarding morphological inflection and word order, but found an even greater degradation in NMT performance as sentence length increased, perhaps due to these systems\u2019 use of subword units.\nMost recently, Sennrich (2016) proposed an ap-\nproach to perform targeted evaluations of NMT through the use of contrastive translation pairs. This method introduces a particular type of error automatically in reference sentences, and then checks whether the NMT system\u2019s conditional probability model prefers the original reference or the corrupted version. Using this technique, they are able to determine that a recently-proposed character-based model improves generalization on unseen words, but at the cost of introducing new grammatical errors.\nOur approach differs from these studies in a number of ways. First, whereas others have analyzed sentences drawn from an existing bitext, we conduct our study on sentences that are manually constructed to exhibit canonical examples of specific linguistic phenomena. This challenge set methodology allows us to emphasize the difficult cases in an otherwise \u201ceasy\u201d language pair. These sentences are designed to allow us to dive deep into phenomena of interest, and do a much finergrained analysis of the strengths of NMT than has come before. However, this strategy also necessitates that we work on many fewer sentences. We leverage the small size of our challenge set to manually evaluate whether the system\u2019s actual output correctly handles our phenomena of interest. Manual evaluation side-steps some of the pitfalls that can come with Sennrich (2016)\u2019s contrastive pairs, as a ranking of two contrastive sentences may not necessarily reflect whether the error in question will occur in the system\u2019s actual output."}, {"heading": "3 Challenge Set Evaluation", "text": "Our challenge set is meant to measure the ability of MT systems to deal with some of the more difficult problems that arise in translating English into French. This particular language pair happened to be most convenient for us, but similar sets can be built for any language pair.\nOne aspect of MT performance that we aimed to exclude from our evaluation is robustness to sparse data. To control for this, when crafting source and reference sentences, we chose words that occurred at least 100 times in the training corpus described in section 4.1.1\n1With three principled exceptions: boeuf (87 occurrences) and spilt (58 occurrences)\u2014both part of idiomatic phrases\u2014and guitared (0 occurrences)."}, {"heading": "3.1 Building the Challenge Set", "text": "The challenging aspect of the test set we are presenting stems from the fact that the source English sentences have been chosen so that their closest French equivalent will be structurally divergent from the source in some crucial way. Translational divergences have been extensively studied in the past \u2013 see for example (Vinay and Darbelnet, 1958; Dorr, 1994). We expect the level of difficulty of an MT test set to correlate well with its density in divergence phenomena. We classify divergence phenomena into three main types: morpho-syntactic, lexicosyntactic and purely syntactic divergences."}, {"heading": "Morpho-syntactic divergences", "text": "In some languages, word morphology (e.g. inflections) carries more grammatical information than in others. When translating a word towards the richer language, there is a need to recover additional grammatically-relevant information from the context of the target language word. Note that we only include in our set cases where the relevant information is available in the linguistic context.2\nWe lack the space to describe all the subtypes of morpho-syntactic divergences that appear in our challenge set, but illustrate through representative examples. One particularly important case is that of subject-verb agreement. French verbs typically have more than 30 different inflected forms, while English verbs typically have 4 or 5. As a result, English verb forms strongly underspecify their French counterparts. Much of the missing information must be filled in through forced agreement in person, number and gender with the grammatical subject of the verb. But extracting these parameters can prove difficult. For example, the agreement features of a coordinated noun phrase are a complex function of the coordinated elements: a) the gender is feminine if all conjuncts are feminine, otherwise masculine wins; b) the conjunct with the smallest person (p1<p2<p3) wins; and c) the number is always plural when the coordination is \u201cet\u201d but the case is more complex with \u201cou\u201d.\n2The so-called Winograd Schema Challenges (https://en.wikipedia.org/wiki/Winograd Schema Challenge) often involve cases where common-sense reasoning is required to correctly choose between two potential antecedent phrases for a pronoun. Such cases become En \u2192 Fr translation challenges when the pronoun in the source sentence is they and its alternative antecedents happen to have different grammatical genders in French: they \u2192 ils/elles.\nA second example of morpho-syntactic divergence between English and French is the more explicit marking of the subjunctive mood in French subordinate clauses. In the following example, the verb \u201cpartiez\u201d, unlike its English counterpart, is marked as subjunctive:\nHe demanded that you leave immediately. \u2192 Il a exige\u0301 que vous partiez imme\u0301diatement.\nWhen translating an English verb within a subordinate clause, the context must be examined for possible subjunctive triggers. Typically these are specific lexical items found in a governing position with respect to the subordinate clause: verbs such as \u201cexiger que\u201d, adjectives such as \u201cregrettable que\u201d or subordinate conjunctions such as \u201ca\u0300 condition que\u201d."}, {"heading": "Lexico-syntactic divergences", "text": "Syntactically governing words such as verbs tend to impose specific requirements on their complements: they subcategorize for complements of a certain syntactic type. But a source language governor and its target language counterpart can diverge on their respective requirements. The translation of such words must then trigger adjustments in the target language complement pattern. We can only examine here a few of the subtypes instantiated in our challenge set.\nA good example is argument switching. This refers to the situation where the translation of a source verb Vs as Vt is correct but only provided the arguments (usually the subject and the object) are flipped around. The translation of \u201cto miss\u201d as \u201cmanquer a\u0300\u201d is such a case:\nJohn misses Mary \u2192 Mary manque a\u0300 John.\nFailing to perform the switch results in a severe case of mistranslation.\nA second example of lexico-syntactic divergence is that of \u201ccrossing movement\u201d verbs. Consider the following example:\nTerry swam across the river \u2192 Terry a traverse\u0301 la rivie\u0300re a\u0300 la nage.\nThe French translation could be glossed as, \u201cTerry crossed the river by swimming.\u201d A literal translation such as \u201cTerry a nage\u0301 a\u0300 travers la rivie\u0300re,\u201d is ruled out."}, {"heading": "Syntactic divergences", "text": "Some syntactic divergences are not relative to the presence of a particular lexical item but rather stem from differences in the basic set of available syntactic patterns. Source-language instances of structures that do not exist in the target language must be mapped onto equivalent structures. Here are some of the subtypes appearing in our challenge set.\nThe position of French pronouns is a major case of divergence from English. French is basically an SVO language just like English but it departs from that canonical order when post-verbal complements are pronominalized: the pronouns must then be cliticized, that is phonetically attached to the verb, in this case to the left side of the verb.\nHe gave Mary a book. \u2192 Il a donne\u0301 un livre a\u0300 Marie.\nHe gavei itj to herk . \u2192 Il lej luik a donne\u0301i.\nAnother example of syntactic divergence between English and French is that of stranded prepositions. When forming a relative clause or a question on a prepositional phrase, English can leave the preposition stranded, fronting only the pronominalized object of that preposition. In French, the preposition needs to be fronted alongside its object:\nThe girl whomi he was dancing withj is rich. \u2192 La fille avecj quii il dansait est riche.\nA final example of syntactic divergence is the use of the so-called middle voice. While English uses the passive voice in subjectless generic statements, French tends to prefer the use of a special pronominal construction where the pronoun \u201cse\u201d has no real referent:\nCaviar is eaten with bread. \u2192 Le caviar se mange avec du pain.\nThis completes our exemplification of morphosyntactic, lexico-syntactic and purely syntactic divergences. Our actual test set includes several more subcategories of each type. The ability of MT systems to deal with each such subcategory is then tested using at least three different test sentences. We use short test sentences so as to keep the targeted divergence in focus. The 108 sentences that constitute our current challenge set can be found in Appendix A."}, {"heading": "3.2 Evaluation Methodology", "text": "Given the very small size of our challenge set, it is easy to perform a human evaluation of the respective outputs of a handful of different systems. The obvious advantage is that the assessment is then absolute instead of relative to one or a few reference translations.\nThe intent of each challenge sentence is to test one and only one system capability, namely that of coping correctly with the particular associated divergence subtype. As illustrated in Figure 1, we provide annotators with a question that specifies the divergence phenomenon currently being tested, along with a reference translation with the areas of divergence highlighted. As a result, judgments become straightforward: was the targeted divergence correctly bridged, yes or no?3 There is no need to mentally average over a number of different aspects of the test sentence as one does when rating the global translation quality of a sentence, e.g. on a 5-point scale. However, we acknowledge that measuring translation performance on complex sentences exhibiting many different phenomena remains crucial. We see our approach as being complementary to evaluations of overall translation quality.\nOne consequence of our divergence-focused approach is that faulty translations will be judged as successes when the faults lie outside of the targeted divergence zone. However, this problem is mitigated by our use of short test sentences."}, {"heading": "4 Machine Translation Systems", "text": "We trained state-of-the-art neural and phrasebased systems for English-French translation on data from the WMT 2014 evaluation."}, {"heading": "4.1 Data", "text": "We used the LIUM shared-task subset of theWMT 2014 corpora,4 retaining the provided tokenization and corpus organization, but mapping characters to lowercase. Table 1 gives corpus statistics.\n3 Sometimes the system produces a translation that circumvents the divergence issue. For example, it may dodge a divergence involving adverbs by reformulating the translation to use an adjective instead. In these rare cases, we instruct our annotators to abstain from making a judgment, regardless of whether the translation is correct or not.\n4http://www.statmt.org/wmt14/translation-task.html http://www-lium.univ-lemans.fr/\u223cschwenk/nnmt-sharedtask"}, {"heading": "4.2 Phrase-based systems", "text": "To ensure a competitive PBMT baseline, we performed phrase extraction using both IBM4 and HMM alignments with a phrase-length limit of 7; after frequency pruning, the resulting phrase table contained 516M entries. For each extracted phrase pair, we collected statistics for the hierarchical reordering model of Galley and Manning (2008).\nWe trained an NNJM model (Devlin et al., 2014) on the HMM-aligned training corpus, with input and output vocabulary sizes of 64K and 32K. Words not in the vocabulary were mapped to one of 100 mkcls classes. We trained for 60 epochs of 20K x 128 minibatches, yielding a final dev-set perplexity of 6.88.\nOur set of log-linear features consisted of forward and backward Kneser-Ney smoothed phrase probabilities and HMM lexical probabilities (4 features); hierarchical reordering probabilities (6); the NNJM probability (1); a set of sparse features as described by Cherry (2013) (10,386); wordcount and distortion penalties (2); and 5-gram language models trained on the French half of the training corpus and the French monolingual corpus (2). Tuning was carried out using batch lattice MIRA (Cherry and Foster, 2012). Decoding used the cube-pruning algorithm of Huang and Chiang (2007), with a distortion limit of 7.\nWe include two phrase-based systems in our comparison: PBMT-1 has data conditions that exactly match those of the NMT system, in that it does not use the language model trained on the French monolingual corpus, while PBMT-2 uses both language models."}, {"heading": "4.3 Neural systems", "text": "To build our NMT system, we used the Nematus toolkit,5 which implements a single-layer neural sequence-to-sequence architecture with attention (Bahdanau et al., 2015) and gated recurrent\n5https://github.com/rsennrich/nematus\nunits (Cho et al., 2014). We used 512-dimensional word embeddings with source and target vocabulary sizes of 90K, and 1024-dimensional state vectors. The model contains 172M parameters.\nWe preprocessed the data using a BPE model learned from source and target corpora (Sennrich et al., 2016). Sentences longer than 50 words were discarded. Training used the Adadelta algorithm (Zeiler, 2012), with a minibatch size of 100 and gradients clipped to 1.0. It ran for 5 epochs, writing a checkpoint model every 30K minibatches. Following Junczys-Dowmunt et al. (2016b), we averaged the parameters from the last 8 checkpoints. To decode, we used the AmuNMT decoder (Junczys-Dowmunt et al., 2016a) with a beam size of 4.\nWhile our primary results will focus on the above PBMT and NMT systems, where we can describe replicable configurations, we have also evaluated Google\u2019s production system,6 which has recently moved to NMT (Wu et al., 2016). Notably, the \u201cGNMT\u201d system uses (at least) 8 encoder and 8 decoder layers, compared to our 1 layer for each, and it is trained on corpora that are \u201ctwo to three decimal orders of magnitudes bigger than the WMT.\u201d The evaluated outputs were downloaded in December 2016."}, {"heading": "5 Experiments", "text": "The 108-sentence English-French challenge set presented in Appendix A was submitted to the four MT systems described in section 4: PBMT-1, PBMT-2, NMT, and GNMT. Three bilingual native speakers of French rated each translated sentence as either a success or a failure according to the protocol described in section 3.2. For example, the 26 sentences of the subcategories S1-S5 of Appendix A are all about different cases of subjectverb agreement. The corresponding translations were judged successful if and only if the translated verb correctly agrees with the translated subject."}, {"heading": "5.1 Quantitative comparison", "text": "Table 2 summarizes our results in terms of percentage of successful translations, globally and over each main type of divergence. For comparison with traditional metrics, we also include BLEU scores measured on the WMT 2014 test set.\nAs we can see, the two PBMT systems fare very poorly on our challenge set, especially in\n6https://translate.google.com\nthe morpho-syntactic and purely syntactic types. Their relatively better handling of lexico-syntactic cases probably reflects the fact that PBMT systems are naturally more attuned to lexical cues than to morphology or syntax. The two NMT systems are clear winners in all three categories. The GNMT system is best overall with a success rate of 68%, likely due to the data and architectural factors mentioned in section 4.3.7\nWMT BLEU scores correlate poorly with challenge-set performance. The large gap of 2.3 BLEU points between PBMT-1 and PBMT-2 corresponds to only a 1% gain on the challenge set, while the small gap of 0.4 BLEU between PBMT-2 and NMT corresponds to a 21% gain.\nInter-annotator agreement (final column in table 2) is excellent overall, with all three annotators agreeing on almost 90% of system outputs. Syntactic divergences appear to be somewhat harder to judge than other categories."}, {"heading": "5.2 Qualitative assessment of NMT", "text": "We now turn to an analysis of the strengths and weaknesses of neural MT through the microscope of our divergence categorization system, hoping that this may help focus future research on key issues. In this discussion we ignore the results obtained by PBMT-2 and compare: a) the results obtained by PBMT-1 to those of NMT, both systems having been trained on the same dataset; and b) the results of these two systems with those of Google NMT which was trained on a much larger dataset.\nIn the remainder of the present section we will reference the sentences of our challenge set using the subcategory-based numbering scheme S1-S26\n7We cannot offer a full comparison with the pre-NMT Google system. However, in October 2016 we ran a smaller 35-sentence version of our challenge set on both the Google system and our PBMT-1 system. The Google system only got 4 of those examples right (11.4%) while our PBMT-1 got 6 (17.1%).\nas assigned in Appendix A."}, {"heading": "Strengths of neural MT", "text": "Overall, both neural MT systems do much better than PBMT-1 at bridging divergences. Their dramatic advantage on morpho-syntactic divergences (a jump from 16% to 72% in the case of our two local systems) results from achievements such as the following:\n\u2022 The subject\u2019s head noun agreement features\nget correctly passed to the verb phrase across intervening noun phrase complements (sentences S1a-c).\n\u2022 Subject agreement marks appear to be cor-\nrectly distributed to each element of a coordinated verb phrase (S3a-c).\n\u2022 Much of the calculus that is at stake in de-\ntermining the agreement features of a subject noun phrase (cf. our relevant description in section 3.1) appears to be correctly captured in the 12 translations of S4.\n\u2022 Most instances of the difficult case of past\nparticiple agreement after the \u201cavoir\u201d auxiliary are correctly handled (S5b-e).\nThe NMT systems are also better at handling\nlexico-syntactic divergences. For example:\n\u2022 They can perform the required restructuring\nof English double object constructions (sentences S8a-S8c).\n\u2022 They can discriminate between an NP com-\nplement and a sentential complement starting with an NP: cf. to know NP versus to know NP is VP (S11b-e)\n\u2022 They often correctly restructure English NP-\nto-VP complements (S12a-c).\nFinally, NMT systems also turn out to better handle purely syntactic divergences. For example:\n\u2022 The differences in yes-no question syntax is\ncorrectly bridged (S17a-c).\n\u2022 English pronouns in verb complement po-\nsition are often correctly cliticized, that is, moved before the main verb and caseinflected correctly (S23a-e).\n\u2022 The Google NMT system manages to cor-\nrectly translate tag questions (S18a-c), most cases of the \u201cinalienable possession\u201d construction (S25a-e), zero relative pronouns (S26a-c) and constructions with stranded prepositions (S19a-f).\nThe large gap observed between the results of the in-house and Google NMT systems indicates that current neural MT systems are extremely data hungry. But given enough data, they can successfully tackle some challenges that are often thought of as extremely difficult. A case in point is that of stranded prepositions, in which English and French happen to diverge in their handling of the celebrated \u201cWH-movement\u201d long-distance dependencies. Specifically, in the French translation, the preposition must be repatriated with its fronted WH object no matter how far on the left it happens to be."}, {"heading": "Weaknesses of neural MT", "text": "In spite of its clear edge over PBMT, NMT is not without some serious shortcomings. Some of them have been mentioned already, such as the tendency of system output to degrade with sentence length. By design this particular problem could not be observed with our challenge set. But many others get highlighted by an analysis of our results. Globally, we note that even using a staggering quantity of data and a highly sophisticated NMT model, the Google system fails to reach the 70% mark on our challenge set. Thus, there is ample room for improvement. The fine-grained error categorization associated with the challenge set makes it possible to single out precise areas where more research is needed. A first analysis of our results yields the following observations.\nIncomplete generalizations. In several cases, while partial results might suggest that NMT has correctly captured a basic generalization about linguistic data, further instances reveal that this is not fully the case. Here are some examples:\n\u2022 The calculus governing the agreement fea-\ntures of coordinated noun phrases (see section 3.1) appears to be handled correctly most\nof the time. However unlike our NMT system, the Google NMT system gets into difficulty with mixed-person subjects (sentences S4d1-3).\n\u2022 While some subjunctive mood triggers are\ncorrectly captured (e.g. \u201cdemander que\u201d and \u201cmalheureux que\u201d), others such as the very common subordinate conjunction provided that \u2192 a\u0300 condition que are getting missed (sentence S6a).\n\u2022 The NMT systems often appear to have suc-\ncessfully captured the semantic relation that ties together the two nouns of an English noun compound, thereby giving rise to the correct preposition in the French translation N1 N2 \u2192 N2 Prep N1. However, some cases that one might think of as easy are being missed. For example, the Google translation of \u201csteak knife\u201d (sentence S14c) fails to convey that this is a knife intended to cut steak; similarly, the Google translation of \u201cpaper filter\u201d (sentence S14i) suggests the filter is intended to filter paper rather being made of it.\n\u2022 The so-called French \u201cinalienable posses-\nsion\u201d construction arises when an agent performs an action on one of her body parts, e.g. I brushed my teeth. In such cases the French translation normally follows a pattern that can be glossed as He brushed the teeth to himself. In our dataset, the Google system gets this right for examples in the first and third persons (sentences S25a,b) but fails to do the same with the example in the second person (sentence S25c).\nThen there are also phenomena that current NMT systems, even with massive amounts of data, appear to be completely missing:\n\u2022 Idioms. While PBMT-1 produces an accept-\nable translation for half of the idiomatic expressions of S15 and S16, the local NMT system misses them all and the Google system does just slightly better. It looks as if NMT systems lack sufficient capacity for rawmemorization.\n\u2022 Control verbs. Two different classes of verbs\ncan govern a subject NP, an object NP plus an infinitival complement. With verbs of the \u201cobject-control\u201d class (e.g. \u201cpersuade\u201d), the\nobject of the verb is understood as the semantic subject of the infinitive. But with those of the subject class (e.g. \u201cpromise\u201d), it is rather the subject of the verb which plays that semantic role. None of the systems tested here appear to get a grip on subject control cases, as evidenced by the lack of correct feminine agreement on the French adjectives in sentences S2b-d.\n\u2022 Argument switching verbs. All systems tested\nhere mistranslate sentences S7a-c by failing to perform the required argument switch: NP1 misses NP2 \u2192 NP2 manque a\u0300 NP1.\n\u2022 Crossing movement verbs. None of the sys-\ntems managed to correctly restructure the regular manner-of-movement verbs e.g. swim across X\u2192 traverser X a\u0300 la nage in sentences S10a-c, let alone the even harder example S10d, in which the word \u201cguitar\u201d is spontaneously recast as a manner-of-movement verb.\n\u2022 Middle voice. None of the systems tested\nhere were able to recast the English \u201cgeneric passive\u201d of S21a-c into the expected French \u201cmiddle voice\u201d pronominal construction."}, {"heading": "6 Conclusions", "text": "We have presented a radically different kind of evaluation for machine translation systems: the use of challenge sets designed to stress-test MT systems on \u201chard\u201d linguistic material, while providing a fine-grained linguistic classification of their successes and failures. This approach is not meant to replace our community\u2019s traditional evaluation tools but to supplement them.\nOur proposed error categorization scheme makes it possible to bring to light different strengths and weaknesses of PBMT and neural MT. With the exception of idiom processing, in all cases where a clear difference was observed it turned out to be in favor of neural MT. A key factor in NMT\u2019s superiority appears to be its ability to overcome many limitations of n-gram language modeling. This is clearly at play in dealing with subject-verb agreement, double-object verbs, overlapping subcategorization frames and last but not least, the pinnacle of Chomskyan linguistics, WH-movement (in this case, stranded prepositions).\nBut our challenge set also brings to light some important shortcomings of current neural MT, re-\ngardless of the massive amounts of training data it may have been fed. As may have been already known or suspected, NMT systems struggle with the translation of idiomatic phrases. Perhaps more interestingly, we notice that neural MT\u2019s impressive generalizations still seem somewhat brittle. For example, the NMT system can appear to have mastered the rules governing subject-verb agreement or inalienable possession in French, only to trip over a rather obvious instantiation of those rules. Probing where these boundaries are, and how they relate to the neural system\u2019s training data and architecture is an obvious next step."}, {"heading": "7 Future Work", "text": "It is our hope that the insights derived from our challenge set evaluation will help inspire future MT research, and call attention to the fact that even \u201ceasy\u201d language pairs like English-French still have many linguistic issues left to be resolved. But there are also several ways to improve and expand upon our challenge set approach itself.\nFirst, though our human judgments of output sentences allowed us to precisely assess the phenomena of interest, this approach is not scalable to large sets, and requires access to native speakers in order to replicate the evaluation. It would be interesting to see whether similar scores could be achieved through automatic means. The existence of human judgments for this set provides a goldstandard by which proposed automatic judgments may be meta-evaluated.\nSecond, the construction of such a challenge set is as much an art as a science, and requires indepth knowledge of the structural divergences between the two languages of interest. A method to automatically create such a challenge set for a new language pair would be extremely useful. One could imagine approaches that search for divergences, indicated by atypical output configurations, or perhaps by a system\u2019s inability to reproduce a reference from its own training data. Localizing a divergence within a difficult sentence pair would be another useful subtask.\nFinally, and perhaps most interestingly, we would like to explore how to train anMT system to improve its performance on these divergence phenomena. This could take the form of designing a curriculum to demonstrate a particular divergence to the machine, or altering the network structure to more easily capture such generalizations."}, {"heading": "Acknowledgments", "text": "We would like to thank Cyril Goutte, Eric Joanis and Michel Simard, who graciously spent the time required to rate the output of four different MT systems on our challenge sentences. We also thank Roland Kuhn for valuable discussions, and comments on an earlier version of the paper."}, {"heading": "A Supplemental Material", "text": "We include a rendering of our challenge set in the pages that follow, along with system output for the PBMT-1, NMT and Google systems. Sentences are grouped by linguistic category and subcategory. For convenience, we also include a reference translation, which is a manually-crafted translation that is designed to be the most straightforward solution to the divergence problem at hand. Needless to say, this reference translation is seldom the only acceptable solution to the targeted divergence problem. Our judges were provided these references, but were instructed to use their knowledge of French to judge whether the divergence was correctly bridged, regardless of the translation\u2019s similarity to the reference.\nIn all translations, the locus of the targeted divergence is highlighted in boldface and it is specifically on that portion that our annotators were asked to provide a judgment. For each system output, we provide a summary of our annotator\u2019s judgments on its handling of the phenomenon of interest. We label the translation with a\u2713 if two or more annotators judged the divergence to be correctly bridged, and with an \u2717 otherwise.\nWe will also release a machine-readable version of this same data, including all of the individual judgments, in the hope that others will find interesting new uses for this data."}, {"heading": "Morpho-Syntactic", "text": ""}, {"heading": "S-V agreement, across distractors", "text": "Is subject-verb agrement correct? (Possible interference distractors between the subject\u2019s head and the verb). S1a Source The repeated calls from his mother should have alerted us.\nRef Les appels re\u0301pe\u0301te\u0301s de sa me\u0300re auraient du\u0302 nous alerter. PBMT-1 Les appels re\u0301pe\u0301te\u0301s de sa me\u0300re aurait du\u0302 nous a alerte\u0301s. \u2717 NMT Les appels re\u0301pe\u0301te\u0301s de sa me\u0300re devraient nous avoir alerte\u0301s. \u2713 Google Les appels re\u0301pe\u0301te\u0301s de sa me\u0300re auraient du\u0302 nous alerter. \u2713\nS1b Source The sudden noise in the upper rooms should have alerted us.\nRef Le bruit soudain dans les chambres supe\u0301rieures aurait du\u0302 nous alerter. PBMT-1 Le bruit soudain dans les chambres supe\u0301rieures auraient du\u0302 nous a alerte\u0301s. \u2717 NMT Le bruit soudain dans les chambres supe\u0301rieures devrait nous avoir alerte\u0301. \u2713 Google Le bruit soudain dans les chambres supe\u0301rieures devrait nous avoir alerte\u0301. \u2713\nS1c Source Their repeated failures to report the problem should have alerted us.\nRef Leurs e\u0301checs re\u0301pe\u0301te\u0301s a\u0300 signaler le proble\u0300me auraient du\u0302 nous alerter. PBMT-1 Leurs e\u0301checs re\u0301pe\u0301te\u0301s de signaler le proble\u0300me aurait du\u0302 nous a alerte\u0301s. \u2717 NMT Leurs e\u0301checs re\u0301pe\u0301te\u0301s pour signaler le proble\u0300me devraient nous avoir alerte\u0301s. \u2713 Google Leur e\u0301chec re\u0301pe\u0301te\u0301 a\u0300 signaler le proble\u0300me aurait du\u0302 nous alerter. \u2713\nS-V agreement, through control verbs Does the flagged adjective agree correctly with its subject? (Subject-control versus object-control verbs). S2a Source She asked her brother not to be arrogant.\nRef Elle a demande\u0301 a\u0300 son fre\u0300re de ne pas se montrer arrogant. PBMT-1 Elle a demande\u0301 a\u0300 son fre\u0300re de ne pas e\u0302tre arrogant. \u2713 NMT Elle a demande\u0301 a\u0300 son fre\u0300re de ne pas e\u0302tre arrogant. \u2713 Google Elle a demande\u0301 a\u0300 son fre\u0300re de ne pas e\u0302tre arrogant. \u2713\nS2b Source She promised her brother not to be arrogant.\nRef Elle a promis a\u0300 son fre\u0300re de ne pas e\u0302tre arrogante. PBMT-1 Elle a promis son fre\u0300re a\u0300 ne pas e\u0302tre arrogant. \u2717 NMT Elle a promis a\u0300 son fre\u0300re de ne pas e\u0302tre arrogant . \u2717 Google Elle a promis a\u0300 son fre\u0300re de ne pas e\u0302tre arrogant. \u2717\nS2c Source She promised her doctor to remain active after retiring.\nRef Elle a promis a\u0300 son me\u0301decin de demeurer active apre\u0300s s\u2019e\u0302tre retire\u0301e. PBMT-1 Elle a promis son me\u0301decin pour demeurer actif apre\u0300s sa retraite. \u2717 NMT Elle a promis a\u0300 son me\u0301decin de rester actif apre\u0300s sa retraite. \u2717 Google Elle a promis a\u0300 son me\u0301decin de rester actif apre\u0300s sa retraite. \u2717\nS2d Source My mother promised my father to be more prudent on the road.\nRef Ma me\u0300re a promis a\u0300 mon pe\u0300re d\u2019e\u0302tre plus prudente sur la route. PBMT-1 Ma me\u0300re , mon pe\u0300re a promis d\u2019e\u0302tre plus prudent sur la route. \u2717 NMT Ma me\u0300re a promis a\u0300 mon pe\u0300re d\u2019e\u0302tre plus prudent sur la route. \u2717 Google Ma me\u0300re a promis a\u0300 mon pe\u0300re d\u2019e\u0302tre plus prudent sur la route. \u2717"}, {"heading": "S-V agreement, coordinated targets", "text": "Do the marked verbs/adjective agree correctly with their subject? (Agreement distribution over coordinated predicates)\nS3a Source The woman was very tall and extremely strong.\nRef La femme e\u0301tait tre\u0300s grande et extre\u0302mement forte. PBMT-1 La femme e\u0301tait tre\u0300s gentil et extre\u0302mement forte. \u2717 NMT La femme e\u0301tait tre\u0300s haute et extre\u0302mement forte. \u2713 Google La femme e\u0301tait tre\u0300s grande et extre\u0302mement forte. \u2713\nS3b Source Their politicians were more ignorant than stupid.\nRef Leurs politiciens e\u0301taient plus ignorants que stupides. PBMT-1 Les politiciens e\u0301taient plus ignorants que stupide. \u2717 NMT Leurs politiciens e\u0301taient plus ignorants que stupides. \u2713 Google Leurs politiciens e\u0301taient plus ignorants que stupides. \u2713\nS3c Source We shouted an insult and left abruptly.\nRef Nous avons lance\u0301 une insulte et nous sommes partis brusquement. PBMT-1 Nous avons crie\u0301 une insulte et a quitte\u0301 abruptement. \u2717 NMT Nous avons crie\u0301 une insulte et nous avons laisse\u0301 brusquement. \u2713 Google Nous avons crie\u0301 une insulte et nous sommes partis brusquement. \u2713\nS-V agreement, feature calculus on coordinated source Do the marked verbs/adjective agree correctly with their subject? (Masculine singular ET masculine singular yields masculine plural). S4a1 Source The cat and the dog should be watched.\nRef Le chat et le chien devraient e\u0302tre surveille\u0301s. PBMT-1 Le chat et le chien doit e\u0302tre regarde\u0301e. \u2717 NMT Le chat et le chien doivent e\u0302tre regarde\u0301s. \u2713 Google Le chat et le chien doivent e\u0302tre surveille\u0301s. \u2713\nS4a2 Source My father and my brother will be happy tomorrow.\nRef Mon pe\u0300re et mon fre\u0300re seront heureux demain. PBMT-1 Mon pe\u0300re et mon fre\u0300re sera heureux de demain. \u2717 NMT Mon pe\u0300re et mon fre\u0300re seront heureux demain. \u2713 Google Mon pe\u0300re et mon fre\u0300re seront heureux demain. \u2713\nS4a3 Source My book and my pencil could be stolen.\nRef Mon livre et mon crayon pourraient e\u0302tre vole\u0301s. PBMT-1 Mon livre et mon crayon pourrait e\u0302tre vole\u0301. \u2717 NMT Mon livre et mon crayon pourraient e\u0302tre vole\u0301s. \u2713 Google Mon livre et mon crayon pourraient e\u0302tre vole\u0301s. \u2713\nDo the marked verbs/adjectives agree correctly with their subject? (Feminine singular ET feminine singular yields feminine plural). S4b1 Source The cow and the hen must be fed.\nRef La vache et la poule doivent e\u0302tre nourries. PBMT-1 La vache et de la poule doivent e\u0302tre nourris. \u2717 NMT La vache et la poule doivent e\u0302tre alimente\u0301es. \u2713 Google La vache et la poule doivent e\u0302tre nourries. \u2713\nS4b2 Source My mother and my sister will be happy tomorrow.\nRef Ma me\u0300re et ma s\u0153ur seront heureuses demain. PBMT-1 Ma me\u0300re et ma s\u0153ur sera heureux de demain. \u2717 NMT Ma me\u0300re et ma s\u0153ur seront heureuses demain. \u2713 Google Ma me\u0300re et ma s\u0153ur seront heureuses demain. \u2713\nS4b3 Source My shoes and my socks will be found.\nRef Mes chaussures et mes chaussettes seront retrouve\u0301es. PBMT-1 Mes chaussures et mes chaussettes sera trouve\u0301 . \u2717 NMT Mes chaussures et mes chaussettes seront trouve\u0301es. \u2713 Google Mes chaussures et mes chaussettes seront trouve\u0301es. \u2713\nDo the marked verbs/adjectives agree correctly with their subject? (Masculine singular ET feminine singular yields masculine plural.) S4c1 Source The dog and the cow are nervous.\nRef Le chien et la vache sont nerveux. PBMT-1 Le chien et la vache sont nerveux. \u2713 NMT Le chien et la vache sont nerveux. \u2713 Google Le chien et la vache sont nerveux. \u2713\nS4c2 Source My father and my mother will be happy tomorrow.\nRef Mon pe\u0300re et ma me\u0300re seront heureux demain. PBMT-1 Mon pe\u0300re et ma me\u0300re se fera un plaisir de demain. \u2717 NMT Mon pe\u0300re et ma me\u0300re seront heureux demain. \u2713 Google Mon pe\u0300re et ma me\u0300re seront heureux demain. \u2713\nS4c3 Source My refrigerator and my kitchen table were stolen.\nRef Mon re\u0301frige\u0301rateur et ma table de cuisine ont e\u0301te\u0301 vole\u0301s. PBMT-1 Mon re\u0301frige\u0301rateur et ma table de cuisine ont e\u0301te\u0301 vole\u0301s. \u2713 NMT Mon re\u0301frige\u0301rateur et ma table de cuisine ont e\u0301te\u0301 vole\u0301s. \u2713 Google Mon re\u0301frige\u0301rateur et ma table de cuisine ont e\u0301te\u0301 vole\u0301s. \u2713\nDo the marked verbs/adjectives agree correctly with their subject? (Smallest coordinated grammatical person wins.) S4d1 Source Paul and I could easily be convinced to join you.\nRef Paul et moi pourrions facilement e\u0302tre convaincus de se joindre a\u0300 vous. PBMT-1 Paul et je pourrais facilement e\u0302tre persuade\u0301e de se joindre a\u0300 vous. \u2717 NMT Paul et moi avons facilement pu e\u0302tre convaincus de vous rejoindre. \u2713 Google Paul et moi pourrait facilement e\u0302tre convaincu de vous rejoindre. \u2717\nS4d2 Source You and he could be surprised by her findings.\nRef Vous et lui pourriez e\u0302tre surpris par ses de\u0301couvertes. PBMT-1 Vous et qu\u2019il pouvait e\u0302tre surpris par ses conclusions. \u2717 NMT Vous et lui pourriez e\u0302tre surpris par ses conclusions. \u2713 Google Vous et lui pourrait e\u0302tre surpris par ses de\u0301couvertes. \u2717\nS4d3 Source We and they are on different courses.\nRef Nous et eux sommes sur des trajectoires diffe\u0301rentes. PBMT-1 Nous et ils sont en cours de diffe\u0301rents. \u2717 NMT Nous et nous sommes sur des parcours diffe\u0301rents. \u2717 Google Nous et ils sont sur des parcours diffe\u0301rents. \u2717"}, {"heading": "S-V agreement, past participles", "text": "Are the agreement marks of the flagged participles the correct ones? (Past participle placed after auxiliary AVOIR agrees with verb object iff object precedes auxiliary. Otherwise participle is in masculine singular form).\nS5a Source The woman who saw a mouse in the corridor is charming.\nRef La femme qui a vu une souris dans le couloir est charmante. PBMT-1 La femme qui a vu une souris dans le couloir est charmante. \u2713 NMT La femme qui a vu une souris dans le couloir est charmante. \u2713 Google La femme qui a vu une souris dans le couloir est charmante. \u2713\nS5b Source The woman that your brother saw in the corridor is charming.\nRef La femme que votre fre\u0300re a vue dans le couloir est charmante. PBMT-1 La femme que ton fre\u0300re a vu dans le couloir est charmante. \u2717 NMT La femme que votre fre\u0300re a vu dans le corridor est charmante. \u2717 Google La femme que votre fre\u0300re a vue dans le couloir est charmante. \u2713\nS5c Source The house that John has visited is crumbling.\nRef La maison que John a visite\u0301e tombe en ruines. PBMT-1 La maison que John a visite\u0301 est en train de s\u2019e\u0301crouler. \u2717 NMT La maison que John a visite\u0301e est en train de s\u2019 effondrer. \u2713 Google La maison que John a visite\u0301 est en ruine. \u2717\nS5d Source John sold the car that he had won in a lottery.\nRef John a vendu la voiture qu\u2019 il avait gagne\u0301e dans une loterie. PBMT-1 John a vendu la voiture qu\u2019il avait gagne\u0301 a\u0300 la loterie. \u2717 NMT John a vendu la voiture qu\u2019 il avait gagne\u0301e dans une loterie. \u2713 Google John a vendu la voiture qu\u2019 il avait gagne\u0301e dans une loterie. \u2713"}, {"heading": "Subjunctive mood", "text": "Is the flagged verb in the correct mood? (Certain triggering verbs, adjectives or subordinate conjunctions, induce the subjunctive mood in the subordinate clause that they govern).\nS6a Source He will come provided that you come too.\nRef Il viendra a\u0300 condition que vous veniez aussi. PBMT-1 Il viendra a\u0300 condition que vous venez aussi. \u2717 NMT Il viendra lui aussi que vous le faites. \u2717 Google Il viendra a\u0300 condition que vous venez aussi. \u2717\nS6b Source It is unfortunate that he is not coming either.\nRef Il est malheureux qu\u2019il ne vienne pas non plus. PBMT-1 Il est regrettable qu\u2019il n\u2019est pas non plus a\u0300 venir. \u2717 NMT Il est regrettable qu\u2019 il ne soit pas non plus. \u2717 Google Il est malheureux qu\u2019il ne vienne pas non plus. \u2713\nS6c Source I requested that families not be separated.\nRef J\u2019ai demande\u0301 que les familles ne soient pas se\u0301pare\u0301es. PBMT-1 J\u2019ai demande\u0301 que les familles ne soient pas se\u0301pare\u0301es. \u2713 NMT J\u2019ai demande\u0301 que les familles ne soient pas se\u0301pare\u0301es. \u2713 Google J\u2019ai demande\u0301 que les familles ne soient pas se\u0301pare\u0301es. \u2713"}, {"heading": "Lexico-Syntactic", "text": ""}, {"heading": "Argument switch", "text": "Are the experiencer and the object of the \u201cmissing\u201d situation correctly preserved in the French translation? (Argument switch). S7a Source Mary sorely misses Jim.\nRef Jim manque cruellement a\u0300 Mary. PBMT-1 Marie manque cruellement de Jim. \u2717 NMT Mary a lamentablement manque\u0301 de Jim . \u2717 Google Mary manque cruellement a\u0300 Jim. \u2717\nS7b Source My sister is really missing New York.\nRef New York manque beaucoup a\u0300 ma s\u0153ur. PBMT-1 Ma s\u0153ur est vraiment absent de New York. \u2717 NMT Ma s\u0153ur est vraiment manquante a\u0300 New York. \u2717 Google Ma s\u0153ur manque vraiment New York. \u2717\nS7c Source What he misses most is his dog.\nRef Ce qui lui manque le plus, c\u2019est son chien. PBMT-1 Ce qu\u2019il manque le plus, c\u2019est son chien. \u2717 NMT Ce qu\u2019il manque le plus, c\u2019est son chien. \u2717 Google Ce qu\u2019il manque le plus, c\u2019est son chien. \u2717"}, {"heading": "Double-object verbs", "text": "Are \u201cgift\u201d and \u201crecipient\u201d arguments correctly rendered in French? (English double-object constructions) S8a Source John gave his wonderful wife a nice present.\nRef John a donne\u0301 un beau pre\u0301sent a\u0300 sa merveilleuse e\u0301pouse. PBMT-1 John a donne\u0301 sa merveilleuse femme un beau cadeau. \u2717 NMT John a donne\u0301 a\u0300 sa merveilleuse femme un beau cadeau. \u2713 Google John a donne\u0301 a\u0300 son e\u0301pouse merveilleuse un pre\u0301sent gentil. \u2713\nS8b Source John told the kids a nice story.\nRef John a raconte\u0301 une belle histoire aux enfants. PBMT-1 John a dit aux enfants une belle histoire. \u2713 NMT John a dit aux enfants une belle histoire. \u2713 Google John a raconte\u0301 aux enfants une belle histoire. \u2713\nS8c Source John sent his mother a nice postcard.\nRef John a envoye\u0301 une belle carte postale a\u0300 sa me\u0300re. PBMT-1 John a envoye\u0301 sa me\u0300re une carte postale de nice. \u2717 NMT John a envoye\u0301 sa me\u0300re une carte postale de nice. \u2717 Google John envoya a\u0300 sa me\u0300re une belle carte postale. \u2713"}, {"heading": "Fail to", "text": "Is the meaning of \u201cfail to\u201d correctly rendered in the French translation?\nS9a Source John failed to see the relevance of this point.\nRef John n\u2019a pas vu la pertinence de ce point. PBMT-1 John a omis de voir la pertinence de ce point. \u2717 NMT John n\u2019a pas vu la pertinence de ce point. \u2713 Google John a omis de voir la pertinence de ce point. \u2717\nS9b Source He failed to respond.\nRef Il n\u2019a pas re\u0301pondu. PBMT-1 Il n\u2019a pas re\u0301ussi a\u0300 re\u0301pondre. \u2713 NMT Il n\u2019a pas re\u0301pondu. \u2713 Google Il n\u2019a pas re\u0301pondu. \u2713\nS9c Source Those who fail to comply with this requirement will be penalized.\nRef Ceux qui ne se conforment pas a\u0300 cette exigence seront pe\u0301nalise\u0301s. PBMT-1 Ceux qui ne se conforment pas a\u0300 cette obligation seront pe\u0301nalise\u0301s. \u2713 NMT Ceux qui ne se conforment pas a\u0300 cette obligation seront pe\u0301nalise\u0301s. \u2713 Google Ceux qui ne respectent pas cette exigence seront pe\u0301nalise\u0301s. \u2713"}, {"heading": "Manner-of-movement verbs", "text": "Is the movement action expressed in the English source correctly rendered in French? (Mannerof-movement verbs with path argument may need to be rephrased in French). S10a Source John would like to swim across the river.\nRef John aimerait traverser la rivie\u0300re a\u0300 la nage. PBMT-1 John aimerait nager dans la rivie\u0300re. \u2717 NMT John aimerait nager a\u0300 travers la rivie\u0300re. \u2717 Google John aimerait nager a\u0300 travers la rivie\u0300re. \u2717\nS10b Source They ran into the room.\nRef Ils sont entre\u0301s dans la chambre a\u0300 la course. PBMT-1 Ils ont couru dans la chambre. \u2717 NMT Ils ont couru dans la pie\u0300ce. \u2717 Google Ils coururent dans la pie\u0300ce. \u2717\nS10c Source The man ran out of the park.\nRef L\u2019homme est sorti du parc en courant. PBMT-1 L\u2019homme a manque\u0301 du parc. \u2717 NMT L\u2019 homme s\u2019 enfuit du parc. \u2717 Google L\u2019homme sortit du parc. \u2717\nHard example featuring spontaneous noun-to-verb derivation (\u201cnonce verb\u201d). S10d Source John guitared his way to San Francisco.\nRef John s\u2019est rendu jusqu\u2019a\u0300 San Francisco en jouant de la guitare. PBMT-1 John guitared son chemin a\u0300 San Francisco. \u2717 NMT John guitared sa route a\u0300 San Francisco. \u2717 Google John a guite\u0301 son chemin a\u0300 San Francisco. \u2717"}, {"heading": "Overlapping subcat frames", "text": "Is the French verb for \u201cknow\u201d correctly chosen? (Choice between \u201csavoir\u201d/\u201cconna\u0131\u0302tre\u201d depends on syntactic nature of its object) S11a Source Paul knows that this is a fact.\nRef Paul sait que c\u2019est un fait. PBMT-1 Paul sait que c\u2019est un fait. \u2713 NMT Paul sait que c\u2019est un fait. \u2713 Google Paul sait que c\u2019est un fait. \u2713\nS11b Source Paul knows this story.\nRef Paul conna\u0131\u0302t cette histoire. PBMT-1 Paul conna\u0131\u0302t cette histoire. \u2713 NMT Paul conna\u0131\u0302t cette histoire. \u2713 Google Paul conna\u0131\u0302t cette histoire. \u2713\nS11c Source Paul knows this story is hard to believe.\nRef Paul sait que cette histoire est difficile a\u0300 croire. PBMT-1 Paul conna\u0131\u0302t cette histoire est difficile a\u0300 croire. \u2717 NMT Paul sait que cette histoire est difficile a\u0300 croire. \u2713 Google Paul sait que cette histoire est difficile a\u0300 croire. \u2713\nS11d Source He knows my sister will not take it.\nRef Il sait que ma soeur ne le prendra pas. PBMT-1 Il sait que ma soeur ne prendra pas. \u2713 NMT Il sait que ma soeur ne le prendra pas. \u2713 Google Il sait que ma soeur ne le prendra pas. \u2713\nS11e Source My sister knows your son is reliable.\nRef Ma s\u0153ur sait que votre fils est fiable. PBMT-1 Ma soeur conna\u0131\u0302t votre fils est fiable. \u2717 NMT Ma s\u0153ur sait que votre fils est fiable. \u2713 Google Ma s\u0153ur sait que votre fils est fiable. \u2713\nNP to VP Is the English \u201cNP to VP\u201d complement correctly rendred in the French translation? (Sometimes one needs to translate this structure as a finite clause). S12a Source John believes Bill to be dishonest.\nRef John croit que Bill est malhonne\u0302te. PBMT-1 John estime que le projet de loi soit malhonne\u0302te. \u2713 NMT John croit que le projet de loi est malhonne\u0302te. \u2713 Google John croit que Bill est malhonne\u0302te. \u2713\nS12b Source He liked his father to tell him stories.\nRef Il aimait que son pe\u0300re lui raconte des histoires. PBMT-1 Il aimait son pe\u0300re pour lui raconter des histoires. \u2717 NMT Il aimait son pe\u0300re pour lui raconter des histoires. \u2717 Google Il aimait son pe\u0300re a\u0300 lui raconter des histoires. \u2717\nS12c Source She wanted her mother to let her go.\nRef Elle voulait que sa me\u0300re la laisse partir. PBMT-1 Elle voulait que sa me\u0300re de lui laisser aller. \u2717 NMT Elle voulait que sa me\u0300re la laisse faire. \u2713 Google Elle voulait que sa me\u0300re la laisse partir. \u2713"}, {"heading": "Factitives", "text": "Is the English verb correctly rendered in the French translation? (Agentive use of some French verbs require embedding under \u201cfaire\u201d). S13a Source John cooked a big chicken.\nRef John a fait cuire un gros poulet. PBMT-1 John cuit un gros poulet. \u2717 NMT John cuit un gros poulet. \u2717 Google John a fait cuire un gros poulet. \u2713\nS13b Source John melted a lot of ice.\nRef John a fait fondre beaucoup de glace. PBMT-1 John fondu a lot of ice. \u2717 NMT John a fondu beaucoup de glace. \u2717 Google John a fondu beaucoup de glace. \u2717\nS13c Source She likes to grow flowers.\nRef Elle aime faire pousser des fleurs. PBMT-1 Elle aime a\u0300 se de\u0301velopper des fleurs. \u2717 NMT Elle aime a\u0300 cultiver des fleurs. \u2713 Google Elle aime faire pousser des fleurs. \u2713"}, {"heading": "Noun Compounds", "text": "Is the English nominal compound rendered with the right preposition in the French translation? S14a Source Use the meat knife.\nRef Utilisez le couteau a\u0300 viande. PBMT-1 Utilisez le couteau de viande. \u2717 NMT Utilisez le couteau a\u0300 viande. \u2713 Google Utilisez le couteau a\u0300 viande. \u2713\nS14b Source Use the butter knife.\nRef Utilisez le couteau a\u0300 beurre. PBMT-1 Utilisez le couteau a\u0300 beurre. \u2713 NMT Utilisez le couteau au beurre. \u2717 Google Utilisez le couteau a\u0300 beurre. \u2713\nS14c Source Use the steak knife.\nRef Utilisez le couteau a\u0300 steak. PBMT-1 Utilisez le steak couteau. \u2717 NMT Utilisez le couteau a\u0300 steak. \u2713 Google Utilisez le couteau de steak. \u2717\nS14d Source Clean the water filter.\nRef Nettoyez le filtre a\u0300 eau. PBMT-1 Nettoyez le filtre a\u0300 eau. \u2713 NMT Nettoyez le filtre a\u0300 eau. \u2713 Google Nettoyez le filtre a\u0300 eau. \u2713\nS14e Source Clean the juice filter.\nRef Nettoyez le filtre a\u0300 jus. PBMT-1 Nettoyez le filtre de jus. \u2717 NMT Nettoyez le filtre de jus. \u2717 Google Nettoyez le filtre a\u0300 jus. \u2713\nS14f Source Clean the tea filter.\nRef Nettoyez le filtre a\u0300 the\u0301. PBMT-1 Nettoyez le filtre a\u0300 the\u0301. \u2713 NMT Nettoyez le filtre de the\u0301. \u2717 Google Nettoyez le filtre a\u0300 the\u0301. \u2713\nS14g Source Clean the cloth filter.\nRef Nettoyez le filtre en tissu. PBMT-1 Nettoyez le filtre en tissu. \u2713 NMT Nettoyez le filtre en tissu. \u2713 Google Nettoyez le filtre en tissu. \u2713\nS14h Source Clean the metal filter.\nRef Nettoyez le filtre en me\u0301tal. PBMT-1 Nettoyez le filtre en me\u0301tal. \u2713 NMT Nettoyez le filtre en me\u0301tal. \u2713 Google Nettoyez le filtre me\u0301tallique. \u2713\nS14i Source Clean the paper filter.\nRef Nettoyez le filtre en papier. PBMT-1 Nettoyez le filtre en papier. \u2713 NMT Nettoyez le filtre en papier. \u2713 Google Nettoyez le filtre a\u0300 papier. \u2717"}, {"heading": "Common idioms", "text": "Is the English idiomatic expression correctly rendered with a suitable French idiomatic expression? S15a Source Stop beating around the bush.\nRef Cessez de tourner autour du pot. PBMT-1 Cesser de battre la campagne. \u2717 NMT Arre\u0302tez de battre autour de la brousse. \u2717 Google Arre\u0302ter de tourner autour du pot. \u2713\nS15b Source You are putting the cart before the horse.\nRef Vous mettez la charrue devant les b\u0153ufs. PBMT-1 Vous pouvez mettre la charrue avant les b\u0153ufs. \u2713 NMT Vous mettez la charrue avant le cheval. \u2717 Google Vous mettez le chariot devant le cheval. \u2717\nS15c Source His comment proved to be the straw that broke the camel\u2019s back.\nRef Son commentaire s\u2019est ave\u0301re\u0301 e\u0302tre la goutte d\u2019eau qui a fait de\u0301border le vase. PBMT-1 Son commentaire s\u2019est re\u0301ve\u0301le\u0301 e\u0302tre la goutte d\u2019eau qui fait de\u0301border le vase. \u2713 NMT Son commentaire s\u2019est ave\u0301re\u0301 e\u0302tre la paille qui a brise\u0301 le dos du chameau. \u2717 Google Son commentaire s\u2019est ave\u0301re\u0301 e\u0302tre la paille qui a casse\u0301 le dos du chameau. \u2717\nS15d Source His argument really hit the nail on the head.\nRef Son argument a vraiment fait mouche. PBMT-1 Son argument a vraiment mis le doigt dessus. \u2713 NMT Son argument a vraiment frappe\u0301 le clou sur la te\u0302te. \u2717 Google Son argument a vraiment frappe\u0301 le clou sur la te\u0302te. \u2717\nS15e Source It\u2019s no use crying over spilt milk.\nRef Ce qui est fait est fait. PBMT-1 Ce n\u2019est pas de pleurer sur le lait re\u0301pandu. \u2717 NMT Il ne sert a\u0300 rien de pleurer sur le lait hache\u0301. \u2717 Google Ce qui est fait est fait. \u2713\nS15f Source It is no use crying over spilt milk.\nRef Ce qui est fait est fait. PBMT-1 Il ne suffit pas de pleurer sur le lait re\u0301pandu. \u2717 NMT Il ne sert a\u0300 rien de pleurer sur le lait e\u0301cre\u0301me\u0301. \u2717 Google Il est inutile de pleurer sur le lait re\u0301pandu. \u2717"}, {"heading": "Syntactically flexible idioms", "text": "Is the English idiomatic expression correctly rendered with a suitable French idiomatic expression? S16a Source The cart has been put before the horse.\nRef La charrue a e\u0301te\u0301 mise devant les b\u0153ufs. PBMT-1 On met la charrue devant le cheval. \u2717 NMT Le chariot a e\u0301te\u0301 mis avant le cheval. \u2717 Google Le chariot a e\u0301te\u0301 mis devant le cheval. \u2717\nS16b Source With this argument, the nail has been hit on the head.\nRef Avec cet argument, la cause est entendue. PBMT-1 Avec cette argument, l\u2019ongle a e\u0301te\u0301 frappe\u0301e a\u0300 la te\u0302te. \u2717 NMT Avec cet argument , l\u2019ongle a e\u0301te\u0301 touche\u0301 a\u0300 la te\u0302te. \u2717 Google Avec cet argument, le clou a e\u0301te\u0301 frappe\u0301 sur la te\u0302te. \u2717"}, {"heading": "Syntactic", "text": ""}, {"heading": "Yes-no question syntax", "text": "Is the English question correctly rendered as a French question? S17a Source Have the kids ever watched that movie?\nRef Les enfants ont-ils de\u0301ja\u0300 vu ce film? PBMT-1 Les enfants jamais regarde\u0301 ce film? \u2717 NMT Les enfants ont-ils de\u0301ja\u0300 regarde\u0301 ce film? \u2713 Google Les enfants ont-ils de\u0301ja\u0300 regarde\u0301 ce film? \u2713\nS17b Source Hasn\u2019t your boss denied you a promotion?\nRef Votre patron ne vous a-t-il pas refuse\u0301 une promotion? PBMT-1 N\u2019a pas nie\u0301 votre patron vous un promotion? \u2717 NMT Est-ce que votre patron vous a refuse\u0301 une promotion ? \u2713 Google Votre patron ne vous a-t-il pas refuse\u0301 une promotion? \u2713\nS17c Source Shouldn\u2019t I attend this meeting?\nRef Ne devrais-je pas assister a\u0300 cette re\u0301union? PBMT-1 Ne devrais-je pas assister a\u0300 cette re\u0301union? \u2713 NMT Est-ce que je ne devrais pas assister a\u0300 cette re\u0301union? \u2713 Google Ne devrais-je pas assister a\u0300 cette re\u0301union? \u2713"}, {"heading": "Tag questions", "text": "Is the English \u201ctag question\u201d element correctly rendered in the translation? S18a Source Mary looked really happy tonight, didn\u2019t she?\nRef Mary avait l\u2019air vraiment heureuse ce soir, n\u2019est-ce pas? PBMT-1 Marie a regarde\u0301 vraiment heureux de ce soir, n\u2019est-ce pas elle ? \u2717 NMT Mary s\u2019est montre\u0301e vraiment heureuse ce soir, ne l\u2019 a pas fait ? \u2717 Google Mary avait l\u2019air vraiment heureuse ce soir, n\u2019est-ce pas? \u2713\nS18b Source We should not do that again, should we?\nRef Nous ne devrions pas refaire cela, n\u2019est-ce pas? PBMT-1 Nous ne devrions pas faire qu\u2019une fois encore , faut-il? \u2717 NMT Nous ne devrions pas le faire encore , si nous ? \u2717 Google Nous ne devrions pas recommencer, n\u2019est-ce pas? \u2713\nS18c Source She was perfect tonight, was she not?\nRef Elle e\u0301tait parfaite ce soir, n\u2019est-ce pas? PBMT-1 Elle e\u0301tait parfait ce soir, elle n\u2019e\u0301tait pas? \u2717 NMT Elle e\u0301tait parfaite ce soir , n\u2019e\u0301tait-elle pas? \u2717 Google Elle e\u0301tait parfaite ce soir, n\u2019est-ce pas? \u2713"}, {"heading": "WH-MVT and stranded preps", "text": "Is the dangling preposition of the English sentence correctly placed in the French translation? S19a Source The guy that she is going out with is handsome.\nRef Le type avec qui elle sort est beau. PBMT-1 Le mec qu\u2019elle va sortir avec est beau. \u2717 NMT Le mec qu\u2019 elle sort avec est beau. \u2717 Google Le mec avec qui elle sort est beau. \u2713\nS19b Source Whom is she going out with these days?\nRef Avec qui sort-elle ces jours-ci? PBMT-1 Qu\u2019est-ce qu\u2019elle allait sortir avec ces jours ? \u2717 NMT A\u0300 qui s\u2019 adresse ces jours-ci? \u2717 Google Avec qui sort-elle de nos jours? \u2713\nS19c Source The girl that he has been talking about is smart.\nRef La fille dont il a parle\u0301 est brillante. PBMT-1 La jeune fille qu\u2019il a parle\u0301 est intelligent. \u2717 NMT La fille qu\u2019 il a parle\u0301 est intelligente. \u2717 Google La fille dont il a parle\u0301 est intelligente. \u2713\nS19d Source Who was he talking to when you left?\nRef A\u0300 qui parlait-il au moment ou\u0300 tu est parti? PBMT-1 Qui est lui parler quand vous avez quitte\u0301? \u2717 NMT Qui a-t-il parle\u0301 a\u0300 quand vous avez quitte\u0301 ? \u2717 Google Avec qui il parlait quand vous e\u0302tes parti? \u2713\nS19e Source The city that he is arriving from is dangerous.\nRef La ville d\u2019ou\u0300 il arrive est dangereuse. PBMT-1 La ville qu\u2019il est arrive\u0301 de est dangereuse. \u2717 NMT La ville qu\u2019 il est en train d\u2019 arriver est dangereuse. \u2717 Google La ville d\u2019ou\u0300 il vient est dangereuse. \u2713\nS19f Source Where is he arriving from?\nRef D\u2019ou\u0300 arrive-t-il? PBMT-1 Ou\u0300 est-il arrive\u0301? \u2717 NMT De quoi s\u2019 agit-il ? \u2717 Google D\u2019ou\u0300 vient-il? \u2713"}, {"heading": "Adverb-triggered inversion", "text": "Is the adverb-triggered subject-verb inversion in the English sentence correctly rendered in the French translation? S20a Source Rarely did the dog run.\nRef Rarement le chien courait-il. PBMT-1 Rarement le chien courir. \u2717 NMT Il est rare que le chien marche. \u2717 Google Rarement le chien courir. \u2717\nS20b Source Never before had she been so unhappy.\nRef Jamais encore n\u2019avait-elle e\u0301te\u0301 aussi malheureuse. PBMT-1 Jamais auparavant , si elle avait e\u0301te\u0301 si malheureux. \u2717 NMT Jamais auparavant n\u2019 avait e\u0301te\u0301 si malheureuse. \u2717 Google Jamais elle n\u2019avait e\u0301te\u0301 aussi malheureuse. \u2713\nS20c Source Nowhere were the birds so colorful.\nRef Nulle part les oiseaux n\u2019e\u0301taient si colore\u0301s. PBMT-1 Nulle part les oiseaux de fac\u0327on colore\u0301e . \u2717 NMT Les oiseaux ne sont pas si colore\u0301s . \u2717 Google Nulle part les oiseaux e\u0301taient si colore\u0301s. \u2717"}, {"heading": "Middle voice", "text": "Is the generic statement made in the English sentence correctly and naturally rendered in the French translation? S21a Source Soup is eaten with a large spoon.\nRef La soupe se mange avec une grande cuille\u0300re PBMT-1 La soupe est mange\u0301 avec une grande cuille\u0300re. \u2717 NMT La soupe est consomme\u0301e avec une grosse cuille\u0300re. \u2717 Google La soupe est consomme\u0301e avec une grande cuille\u0300re. \u2717\nS21b Source Masonry is cut using a diamond blade.\nRef La mac\u0327onnerie se coupe avec une lame a\u0300 diamant. PBMT-1 La mac\u0327onnerie est coupe\u0301 a\u0300 l\u2019aide d\u2019une lame de diamant. \u2717 NMT La mac\u0327onnerie est coupe\u0301e a\u0300 l\u2019aide d\u2019une lame de diamant. \u2717 Google La mac\u0327onnerie est coupe\u0301e a\u0300 l\u2019aide d\u2019une lame de diamant. \u2717\nS21c Source Champagne is drunk in a glass called a flu\u0302te.\nRef Le champagne se boit dans un verre appele\u0301 flu\u0302te. PBMT-1 Le champagne est ivre dans un verre appele\u0301 une flu\u0302te. \u2717 NMT Le champagne est ivre dans un verre appele\u0301 flu\u0302te. \u2717 Google Le Champagne est bu dans un verre appele\u0301 flu\u0302te. \u2717"}, {"heading": "Fronted \u201cshould\u201d", "text": "Fronted \u201cshould\u201d is interpreted as a conditional subordinator. It is normally translated as \u201csi\u201d with imperfect tense. S22a Source Should Paul leave, I would be sad.\nRef Si Paul devait s\u2019en aller, je serais triste. PBMT-1 Si le conge\u0301 de Paul, je serais triste. \u2717 NMT Si Paul quitte , je serais triste. \u2717 Google Si Paul s\u2019en allait, je serais triste. \u2713\nS22b Source Should he become president, she would be promoted immediately.\nRef S\u2019il devait devenir pre\u0301sident, elle recevrait imme\u0301diatement une promotion. PBMT-1 S\u2019il devait devenir pre\u0301sident , elle serait encourage\u0301e imme\u0301diatement . \u2713 NMT S\u2019 il devait devenir pre\u0301sident , elle serait imme\u0301diatement promue . \u2713 Google Devrait-il devenir pre\u0301sident, elle serait imme\u0301diatement promue. \u2717\nS22c Source Should he fall, he would get up again immediately.\nRef S\u2019 il venait a\u0300 tomber, il se rele\u0300verait imme\u0301diatement. PBMT-1 S\u2019il devait tomber, il allait se lever imme\u0301diatement de nouveau. \u2713 NMT s\u2019 il tombe , il serait de nouveau imme\u0301diatement. \u2717 Google S\u2019il tombe, il se le\u0300vera imme\u0301diatement. \u2717"}, {"heading": "Clitic pronouns", "text": "Are the English pronouns correctly rendered in the Freench translations? S23a Source She had a lot of money but he did not have any.\nRef Elle avait beaucoup d\u2019argent mais il n\u2019en avait pas. PBMT-1 Elle avait beaucoup d\u2019argent mais il n\u2019en avait pas. \u2713 NMT Elle avait beaucoup d\u2019 argent , mais il n\u2019 a pas eu d\u2019 argent. \u2713 Google Elle avait beaucoup d\u2019argent mais il n\u2019en avait pas. \u2713\nS23b Source He did not talk to them very often.\nRef Il ne leur parlait pas tre\u0300s souvent. PBMT-1 Il n\u2019a pas leur parler tre\u0300s souvent. \u2717 NMT Il ne leur a pas parle\u0301 tre\u0300s souvent. \u2713 Google Il ne leur parlait pas tre\u0300s souvent. \u2713\nS23c Source The men are watching each other.\nRef Les hommes se surveillent l\u2019un l\u2019autre PBMT-1 Les hommes se regardent les uns les autres. \u2713 NMT Les hommes se regardent les uns les autres. \u2713 Google Les hommes se regardent. \u2717\nS23d Source He gave it to the man.\nRef Il le donna a\u0300 l\u2019homme. PBMT-1 Il a donne\u0301 a\u0300 l\u2019homme. \u2717 NMT Il l\u2019 a donne\u0301 a\u0300 l\u2019 homme. \u2713 Google Il le donna a\u0300 l\u2019homme. \u2713\nS23e Source He did not give it to her.\nRef Il ne le lui a pas donne\u0301. PBMT-1 Il ne lui donner. \u2717 NMT Il ne l\u2019 a pas donne\u0301 a\u0300 elle. \u2717 Google Il ne lui a pas donne\u0301. \u2717"}, {"heading": "Ordinal placement", "text": "Is the relative order of the ordinals and numerals correct in the French tranlation? S24a Source The first four men were exhausted.\nRef Les quatre premiers hommes e\u0301taient tous e\u0301puise\u0301s. PBMT-1 Les quatre premiers hommes e\u0301taient e\u0301puise\u0301s. \u2713 NMT Les quatre premiers hommes ont e\u0301te\u0301 e\u0301puise\u0301s. \u2713 Google Les quatre premiers hommes e\u0301taient e\u0301puise\u0301s. \u2713\nS24b Source The last three candidates were eliminated.\nRef Les trois derniers candidats ont e\u0301te\u0301 e\u0301limine\u0301s. PBMT-1 Les trois derniers candidats ont e\u0301te\u0301 e\u0301limine\u0301s. \u2713 NMT Les trois derniers candidats ont e\u0301te\u0301 e\u0301limine\u0301s. \u2713 Google Les trois derniers candidats ont e\u0301te\u0301 e\u0301limine\u0301s. \u2713\nS24c Source The other two guys left without paying.\nRef Les deux autres types sont partis sans payer. PBMT-1 Les deux autres mecs ont laisse\u0301 sans payer. \u2713 NMT Les deux autres gars a\u0300 gauche sans payer. \u2713 Google Les deux autres gars sont partis sans payer. \u2713"}, {"heading": "Inalienable possession", "text": "Is the French translation correct and natural both in: a) its use of a particular determiner on the body part noun; and b) the presence or absence of a reflexive pronoun before the verb? S25a Source He washed his hands.\nRef Ils s\u2019est lave\u0301 les mains. PBMT-1 Ils se lavait les mains. \u2713 NMT Il a lave\u0301 ses mains. \u2717 Google Ils se lava les mains. \u2713\nS25b Source I brushed my teeth.\nRef Jeme suis brosse\u0301 les dents. PBMT-1 J\u2019ai brosse\u0301 mes dents. \u2717 NMT J\u2019 ai brosse\u0301 mes dents. \u2717 Google Je me suis brosse\u0301 les dents. \u2713\nS25c Source You brushed your teeth.\nRef Tu t\u2019es brosse\u0301 les dents PBMT-1 Vous avez brosse\u0301 vos dents. \u2717 NMT vous avez brosse\u0301 vos dents. \u2717 Google Tu as brosse\u0301 les dents. \u2717\nS25d Source I raised my hand.\nRef J\u2019ai leve\u0301 la main. PBMT-1 J\u2019ai leve\u0301 la main. \u2713 NMT J\u2019ai souleve\u0301 mamain. \u2717 Google Je levai la main. \u2713\nS25e Source He turned his head.\nRef Il a tourne\u0301 la te\u0302te. PBMT-1 Il a transforme\u0301 sa te\u0302te. \u2717 NMT Il a tourne\u0301 sa te\u0302te. \u2717 Google Il tourna la te\u0302te. \u2713\nS25f Source He raised his eyes to heaven.\nRef Il leva les yeux au ciel. PBMT-1 Il a e\u0301voque\u0301 les yeux au ciel. \u2713 NMT Il a leve\u0301 les yeux sur le ciel. \u2713 Google Il leva les yeux au ciel. \u2713"}, {"heading": "Zero REL PRO", "text": "Is the English zero relative pronoun correctly translated as a non-zero one in the French translation? S26a Source The strangers the woman saw were working.\nRef Les inconnus que la femme vit travaillaient. PBMT-1 Les e\u0301trangers la femme vit travaillaient. \u2717 NMT Les inconnus de la femme ont travaille\u0301. \u2717 Google Les e\u0301trangers que la femme vit travaillaient. \u2713\nS26b Source The man your sister hates is evil.\nRef L\u2019homme que votre s\u0153ur de\u0301teste est me\u0301chant. PBMT-1 L\u2019homme ta soeur hait est le mal. \u2717 NMT L\u2019 homme que ta soeur est le mal est le mal. \u2713 Google L\u2019homme que votre s\u0153ur hait est me\u0301chant. \u2713\nS26c Source The girl my friend was talking about is gone.\nRef La fille dont mon ami parlait est partie. PBMT-1 La jeune fille mon ami a parle\u0301 a disparu. \u2717 NMT La petite fille de mon ami e\u0301tait re\u0301volue. \u2717 Google La fille dont mon ami parlait est partie. \u2713"}], "references": [{"title": "Neural machine translation by jointly learning to align and translate", "author": ["Dzmitry Bahdanau", "Kyunghyun Cho", "Yoshua Bengio."], "venue": "Proceedings of the Third International Conference on Learning Representations (ICLR). San Diego, USA.", "citeRegEx": "Bahdanau et al\\.,? 2015", "shortCiteRegEx": "Bahdanau et al\\.", "year": 2015}, {"title": "Neural versus phrase-based machine translation quality: a case study", "author": ["Luisa Bentivogli", "Arianna Bisazza", "Mauro Cettolo", "Marcello Federico."], "venue": "Proceedings of the 2016 Conference on Empirical Methods in Natural", "citeRegEx": "Bentivogli et al\\.,? 2016", "shortCiteRegEx": "Bentivogli et al\\.", "year": 2016}, {"title": "Findings of the 2016 conference on machine translation", "author": ["Popel", "Matt Post", "Raphael Rubino", "Carolina Scarton", "Lucia Specia", "Marco Turchi", "Karin Verspoor", "Marcos Zampieri."], "venue": "Proceedings of the First Conference on Ma-", "citeRegEx": "Popel et al\\.,? 2016", "shortCiteRegEx": "Popel et al\\.", "year": 2016}, {"title": "Improved reordering for phrase-based translation using sparse features", "author": ["Colin Cherry."], "venue": "Proceedings of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language", "citeRegEx": "Cherry.,? 2013", "shortCiteRegEx": "Cherry.", "year": 2013}, {"title": "Batch tuning strategies for statistical machine translation", "author": ["Colin Cherry", "George Foster."], "venue": "Proceedings of the 2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Lan-", "citeRegEx": "Cherry and Foster.,? 2012", "shortCiteRegEx": "Cherry and Foster.", "year": 2012}, {"title": "Fast and robust neural network joint models for statistical machine translation", "author": ["Jacob Devlin", "Rabih Zbib", "ZhongqiangHuang", "Thomas Lamar", "Richard Schwartz", "John Makhoul."], "venue": "Proceedings of the 52nd Annual Meeting of the Asso-", "citeRegEx": "Devlin et al\\.,? 2014", "shortCiteRegEx": "Devlin et al\\.", "year": 2014}, {"title": "Machine translation divergences: a formal description and proposed solution", "author": ["Bonnie J. Dorr."], "venue": "Computational Linguistics 20:4.", "citeRegEx": "Dorr.,? 1994", "shortCiteRegEx": "Dorr.", "year": 1994}, {"title": "QCRI machine translation systems for IWSLT 16", "author": ["Nadir Durrani", "Fahim Dalvi", "Hassan Sajjad", "Stephan Vogel."], "venue": "Proceedings of the 13th InternationalWorkshop on Spoken Language Translation (IWSLT). Seattle, Washington.", "citeRegEx": "Durrani et al\\.,? 2016", "shortCiteRegEx": "Durrani et al\\.", "year": 2016}, {"title": "A simple and effective hierarchical phrase reordering model", "author": ["Michel Galley", "Christopher D. Manning."], "venue": "Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing. Association for Computational", "citeRegEx": "Galley and Manning.,? 2008", "shortCiteRegEx": "Galley and Manning.", "year": 2008}, {"title": "Forest rescoring: Faster decoding with integrated language models", "author": ["Liang Huang", "David Chiang."], "venue": "Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics. Association for Computational Lin-", "citeRegEx": "Huang and Chiang.,? 2007", "shortCiteRegEx": "Huang and Chiang.", "year": 2007}, {"title": "Is neural machine translation ready for deployment? a case study on 30 translation directions", "author": ["Marcin Junczys-Dowmunt", "Tomasz Dwojak", "Hieu Hoang."], "venue": "Proceedings of the 13th International Workshop on Spoken Language Translation", "citeRegEx": "Junczys.Dowmunt et al\\.,? 2016a", "shortCiteRegEx": "Junczys.Dowmunt et al\\.", "year": 2016}, {"title": "The amu-uedin submission to the wmt16 news translation task: Attention-based nmt models as feature functions in phrase-based smt", "author": ["Marcin Junczys-Dowmunt", "Tomasz Dwojak", "Rico Sennrich."], "venue": "Proceedings of the First Conference", "citeRegEx": "Junczys.Dowmunt et al\\.,? 2016b", "shortCiteRegEx": "Junczys.Dowmunt et al\\.", "year": 2016}, {"title": "Recurrent continuous translation models", "author": ["Nal Kalchbrenner", "Phil Blunsom."], "venue": "Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing. Association for Computational Linguistics,", "citeRegEx": "Kalchbrenner and Blunsom.,? 2013", "shortCiteRegEx": "Kalchbrenner and Blunsom.", "year": 2013}, {"title": "Bleu: a method for automatic evaluation of machine translation", "author": ["Kishore Papineni", "Salim Roukos", "Todd Ward", "Wei-Jing Zhu."], "venue": "Proceedings of 40th Annual Meeting of the Association for Computational Linguis-", "citeRegEx": "Papineni et al\\.,? 2002", "shortCiteRegEx": "Papineni et al\\.", "year": 2002}, {"title": "How grammatical is characterlevel neural machine translation? assessing MT quality with contrastive translation pairs", "author": ["Rico Sennrich."], "venue": "CoRR abs/1612.04629. http://arxiv.org/abs/1612.04629.", "citeRegEx": "Sennrich.,? 2016", "shortCiteRegEx": "Sennrich.", "year": 2016}, {"title": "Neural machine translation of rare words with subword units", "author": ["Rico Sennrich", "Barry Haddow", "Alexandra Birch."], "venue": "Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume", "citeRegEx": "Sennrich et al\\.,? 2016", "shortCiteRegEx": "Sennrich et al\\.", "year": 2016}, {"title": "Sequence to sequence learning with neural networks", "author": ["Ilya Sutskever", "Oriol Vinyals", "Quoc V Le."], "venue": "Advances in Neural Information Processing Systems 27. Curran Associates, Inc., pages 3104\u20133112.", "citeRegEx": "Sutskever et al\\.,? 2014", "shortCiteRegEx": "Sutskever et al\\.", "year": 2014}, {"title": "A multifaceted evaluation of neural versus statistical machine translation for 9 language directions", "author": ["Antonio Toral", "V\u0131\u0301ctorM. S\u00e1nchez-Cartagena"], "venue": "In Proceedings of the The 15th Conference of the European Chapter of the Association", "citeRegEx": "Toral and S\u00e1nchez.Cartagena.,? \\Q2017\\E", "shortCiteRegEx": "Toral and S\u00e1nchez.Cartagena.", "year": 2017}, {"title": "Stylistique compar\u00e9e du fran\u00e7ais et de l\u2019anglais, volume 1", "author": ["Jean-Paul Vinay", "Jean Darbelnet."], "venue": "Didier, Paris.", "citeRegEx": "Vinay and Darbelnet.,? 1958", "shortCiteRegEx": "Vinay and Darbelnet.", "year": 1958}, {"title": "ADADELTA: an adaptive learning rate method", "author": ["Matthew D. Zeiler."], "venue": "CoRR abs/1212.5701. http://arxiv.org/abs/1212.5701.", "citeRegEx": "Zeiler.,? 2012", "shortCiteRegEx": "Zeiler.", "year": 2012}], "referenceMentions": [{"referenceID": 12, "context": "The advent of neural techniques in machine translation (MT) (Kalchbrenner and Blunsom, 2013; Cho et al., 2014; Sutskever et al., 2014) has led to profound improvements in MT quality.", "startOffset": 60, "endOffset": 134}, {"referenceID": 16, "context": "The advent of neural techniques in machine translation (MT) (Kalchbrenner and Blunsom, 2013; Cho et al., 2014; Sutskever et al., 2014) has led to profound improvements in MT quality.", "startOffset": 60, "endOffset": 134}, {"referenceID": 13, "context": "This puts pressure on automatic evaluation metrics such as BLEU (Papineni et al., 2002), which exploit surface-matching heuristics that are relatively insensitive to subtle differences.", "startOffset": 64, "endOffset": 87}, {"referenceID": 10, "context": "Since then, controlled comparisons have used BLEU to show that NMT outperforms strong PBMT systems on 30 translation directions from the United Nations Parallel Corpus (Junczys-Dowmunt et al., 2016a), and on the IWSLT English-Arabic tasks (Durrani et al.", "startOffset": 168, "endOffset": 199}, {"referenceID": 7, "context": ", 2016a), and on the IWSLT English-Arabic tasks (Durrani et al., 2016).", "startOffset": 48, "endOffset": 70}, {"referenceID": 1, "context": "Bentivogli et al. (2016) carried out a number of experiments on IWSLT 2015 EnglishGerman evaluation data, where they compare machine outputs to professional post-edits in order to automatically detect a number of error categories.", "startOffset": 0, "endOffset": 25}, {"referenceID": 1, "context": "Bentivogli et al. (2016) carried out a number of experiments on IWSLT 2015 EnglishGerman evaluation data, where they compare machine outputs to professional post-edits in order to automatically detect a number of error categories. Compared to PBMT, NMT required less postediting effort over-all, with substantial improvements in lexical, morphological and word order errors. NMT consistently out-performed PBMT, but its performance degraded faster as sentence length increased. Later, Toral and S\u00e1nchez-Cartagena (2017) conducted a similar study, examining the outputs of competition-grade systems for the 9 WMT 2016 directions that included NMT competitors.", "startOffset": 0, "endOffset": 520}, {"referenceID": 14, "context": "Most recently, Sennrich (2016) proposed an approach to perform targeted evaluations of NMT through the use of contrastive translation pairs.", "startOffset": 15, "endOffset": 31}, {"referenceID": 14, "context": "Manual evaluation side-steps some of the pitfalls that can come with Sennrich (2016)\u2019s contrastive pairs, as a ranking of two contrastive sentences may not necessarily reflect whether the error in question will occur in the system\u2019s actual output.", "startOffset": 69, "endOffset": 85}, {"referenceID": 18, "context": "Translational divergences have been extensively studied in the past \u2013 see for example (Vinay and Darbelnet, 1958; Dorr, 1994).", "startOffset": 86, "endOffset": 125}, {"referenceID": 6, "context": "Translational divergences have been extensively studied in the past \u2013 see for example (Vinay and Darbelnet, 1958; Dorr, 1994).", "startOffset": 86, "endOffset": 125}, {"referenceID": 5, "context": "We trained an NNJM model (Devlin et al., 2014) on the HMM-aligned training corpus, with input and output vocabulary sizes of 64K and 32K.", "startOffset": 25, "endOffset": 46}, {"referenceID": 4, "context": "Tuning was carried out using batch lattice MIRA (Cherry and Foster, 2012).", "startOffset": 48, "endOffset": 73}, {"referenceID": 5, "context": "For each extracted phrase pair, we collected statistics for the hierarchical reordering model of Galley and Manning (2008). We trained an NNJM model (Devlin et al.", "startOffset": 97, "endOffset": 123}, {"referenceID": 3, "context": "Our set of log-linear features consisted of forward and backward Kneser-Ney smoothed phrase probabilities and HMM lexical probabilities (4 features); hierarchical reordering probabilities (6); the NNJM probability (1); a set of sparse features as described by Cherry (2013) (10,386); wordcount and distortion penalties (2); and 5-gram language models trained on the French half of the training corpus and the French monolingual corpus (2).", "startOffset": 260, "endOffset": 274}, {"referenceID": 3, "context": "Our set of log-linear features consisted of forward and backward Kneser-Ney smoothed phrase probabilities and HMM lexical probabilities (4 features); hierarchical reordering probabilities (6); the NNJM probability (1); a set of sparse features as described by Cherry (2013) (10,386); wordcount and distortion penalties (2); and 5-gram language models trained on the French half of the training corpus and the French monolingual corpus (2). Tuning was carried out using batch lattice MIRA (Cherry and Foster, 2012). Decoding used the cube-pruning algorithm of Huang and Chiang (2007), with a distortion limit of 7.", "startOffset": 260, "endOffset": 583}, {"referenceID": 0, "context": "To build our NMT system, we used the Nematus toolkit, which implements a single-layer neural sequence-to-sequence architecture with attention (Bahdanau et al., 2015) and gated recurrent", "startOffset": 142, "endOffset": 165}, {"referenceID": 15, "context": "We preprocessed the data using a BPE model learned from source and target corpora (Sennrich et al., 2016).", "startOffset": 82, "endOffset": 105}, {"referenceID": 19, "context": "Training used the Adadelta algorithm (Zeiler, 2012), with a minibatch size of 100 and gradients clipped to 1.", "startOffset": 37, "endOffset": 51}, {"referenceID": 10, "context": "To decode, we used the AmuNMT decoder (Junczys-Dowmunt et al., 2016a) with a beam size of 4.", "startOffset": 38, "endOffset": 69}, {"referenceID": 10, "context": "Following Junczys-Dowmunt et al. (2016b), we averaged the parameters from the last 8 checkpoints.", "startOffset": 10, "endOffset": 41}], "year": 2017, "abstractText": "Neural machine translation represents an exciting leap forward in translation quality. But what longstanding weaknesses does it resolve, and which remain? We address these questions with a challenge set approach to translation evaluation and error analysis. A challenge set consists of a small set of sentences, each hand-designed to probe a system\u2019s capacity to bridge a particular structural divergence between languages. To exemplify this approach, we present an English-French challenge set, and use it to analyze phrase-based and neural systems. The resulting analysis provides not only a more fine-grained picture of the strengths of neural systems, but also insight into which linguistic phenomena remain out of reach.", "creator": "LaTeX with hyperref package"}}}