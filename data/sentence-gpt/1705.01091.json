{"id": "1705.01091", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "2-May-2017", "title": "PDE approach to the problem of online prediction with expert advice: a construction of potential-based strategies", "abstract": "We consider a sequence of repeated prediction games and formally pass to the limit. The supersolutions of the resulting non-linear parabolic partial differential equation are closely related to the potential functions in the sense of N.\\,Cesa-Bianci, G., Tautis, A., and N.\\,Cesa-Bianci. (In this work, there is significant divergence between the observed estimates of N.\\,Cesa-Bianci and the observed predictions of N.\\,Cesa-Bianci. I, and E. M. (2009) show the potential functions in a set of superpositions, such as the first set of superpositions for the sequence. The predicted outcomes (N.\\,Cesa-Bianci and G. A. (2009) show that the probability of a given superpositions is proportional to the observed predictions of N.\\,Cesa-Bianci and G. A. (2009) show that the predicted outcomes are not consistent. A superpositions can be predicted by using a number of subpositions, but are not specific to superpositions. For example, the predicted predictions of L. S. and C. S. (2009) show that the predicted outcomes are inversely correlated with predicted outcomes by the same number of subpositions. For example, the predicted predictions of L. S. and C. S. (2009) show that the predicted outcomes are not inconsistent. For example, the predicted predictions of L. S. and C. S. (2009) show that the predicted outcomes are not consistent.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "histories": [["v1", "Tue, 2 May 2017 17:56:54 GMT  (8kb)", "http://arxiv.org/abs/1705.01091v1", "7 pages"]], "COMMENTS": "7 pages", "reviews": [], "SUBJECTS": "cs.LG", "authors": ["dmitry b rokhlin"], "accepted": false, "id": "1705.01091"}, "pdf": {"name": "1705.01091.pdf", "metadata": {"source": "CRF", "title": "PDE APPROACH TO THE PROBLEM OF ONLINE PREDICTION WITH EXPERT ADVICE: A CONSTRUCTION OF POTENTIAL-BASED STRATEGIES", "authors": ["DMITRY B. ROKHLIN"], "emails": [], "sections": [{"heading": null, "text": "ar X\niv :1\n70 5.\n01 09\n1v 1\n[ cs\n.L G\n] 2\nM ay\n2 01\n7\n1. Introduction\nLet B be any set. In the problem of online prediction with expert advice a forecaster predicts a sequence (bt) n\u22121 t=0 , bt \u2208 B on the basis of expert opinions f it \u2208 A, i = 1, . . . , N , where A is a convex subset of a vector space. More precisely, at round t \u2208 {0, . . . , n \u2212 1} forecaster\u2019s guess at is a convex combination of expert advices:\nat = \u3008pt, ft\u3009 := N \u2211\ni=1\npitf i t , pt \u2208 \u2206 := {z \u2265 0 : \u3008z, 1\u3009 = 1} ,\nbased on the available history and current advices: pt = pt((bs) t\u22121 s=0, (fs) t s=0).\nLet l : A\u00d7 B 7\u2192 [0, 1] be a loss function. Forecaster\u2019s aim is to keep the regret\nRn =\nn\u22121 \u2211\nt=0\nl(\u3008pt, ft\u3009, bt)\u2212 min 1\u2264i\u2264N\nn\u22121 \u2211\nt=0\nl(f it , bt)\nsmall. This regret Rn measures the quality of predictions by comparing the cumulative loss of the forecaster with that of a best expert, chosen in hindsight.\nWe refer to [4] for more information on this problem. The basic result (see, e.g, [4, Theorem 2.2]) guarantees the existence of a prediction strategy p\u2217 achieving the uniform bound\nRn ( (p\u2217t ) n\u22121 t=0 , (ft) n\u22121 t=0 , (bt) n\u22121 t=0 )\n\u221a n\n\u2264 C (1.1)\nfor any (bt) n\u22121 t=0 , (ft) n\u22121 t=0 under the assumption that l is convex in its first argument. Moreover, this bound cannot be improved without further assumptions: [4, Theorem 3.7]. The inequality (1.1) implies that in the long run on average the forecaster predicts as well as a best expert: Rn/n\u2192 0, n\u2192 \u221e.\nThere are plenty of strategies achieving the bound (1.1). In [3] it was shown that for a rather general class of online learning problems the construction of such strategies can\n2010 Mathematics Subject Classification. 68T05, 68W27, 35K55. Key words and phrases. regret, online learning, potentials, non-linear parabolic PDE, weighted average\nforecaster. 1\nbe based on the notion of potential function. More recently [7] proposed a systematic way for the construction of potentials in the case of randomized prediction, mentioning that \u201cThe origin/recipe for \u201cgood\u201d potential functions has always been a mystery (at least to the authors).\u201d The authors of [7] considered a recurrence relation, for the value function of a repeated game, determining the optimal regret, and showed that potential functions are related to relaxations of this function, which are consistent with the mentioned recurrence relation. To obtain such relaxations they used upper bounds, developed in the theory of online learning and capturing the complexity of the problem.\nIn this paper we show that for the problem of prediction with expert advice there is another \u201cnatural\u201d way for the appearance of potential-based algorithms. As in [7], we consider a repeated game, determining the optimal regret, and the correspondent recurrence relation for the value functions vn. Further, in contrast to [7], we simply pass to the limit as n\u2192 \u221e and get a non-linear parabolic Bellman-Isaacs type partial differential equation in [0, 1]\u00d7RN . A rigorous justification of this procedure can be performed within the theory of viscosity solutions. However, being interested only in the construction of prediction strategies, we need not do it! As usual, a Bellman-type equation at least formally produces optimal strategies. More precisely, we consider the strategies, generated by appropriate smooth supersolutions, and then directly check the inequality (1.1), using the argumentation similar to that of the verification method from the theory of optimal control.\nThe described approach is mainly inspired by the paper [6], where there was studied a link between fully non-linear second order (parabolic and elliptic) PDE and repeated games. Its application to the problems of online learning theory was initiated in [10], where an asymptotics of the sequential Rademacher complexity (the last notion was introduced in [8]) of a finite function class was related to the viscosity solution of a G-heat equation. In turn, the result of [10] is based on the central limit theorem under model uncertainty, studied within the same approach in [9].\n2. Prediction game and the limiting PDE\nThe worst-case regret\nRn = sup f0\u2208AN inf p0\u2208\u2206 sup b0\u2208B . . . sup fn\u22121\u2208AN inf pn\u22121\u2208\u2206 sup bn\u22121\u2208B\nRn((pt) n\u22121 t=0 , (ft) n\u22121 t=0 , (bt) n\u22121 t=0 )\nis a result of the repeated game between the predictor, an adversary and experts. In this game the adversary has an informational advantage over the predictor and experts, since bt is chosen after the sequences (pj) t j=0, (fj) t j=0 are revealed. Furthermore, the predictor has an informational advantage over the experts, since the choice of pt can be based on (fj) t j=0, (bj) t\u22121 j=0. Finally, experts can use only the information contained in (pj) t\u22121 j=0, (bj) t\u22121 j=0. The adversary and experts play against the predictor, trying to maximize his regret. To get a recurrent formula for Rn let us introduce the family of state processes\nX i,t,x,p,f,bs+1 = X i,t,x,p,f,b s + 1\u221a n ri(ps, fs, bs), s = t, . . . , n\u2212 1, (2.2)\nri = l(\u3008pt, ft\u3009, bt)\u2212 l(f it , bt), X i,t,x,p,f,bt = xi \u2208 R. Summing up the increments X i,0,0,p,f,bs+1 \u2212X i,0,0,p,f,bs , we obtain\n1\u221a n Rn((pt) n\u22121 t=0 , (ft) n\u22121 t=0 , (bt) n\u22121 t=0 ) = max { X1,0,0,p,f,bn , . . . , X N,0,0,p,f,b n } .\nLet us introduce the value functions\nvn(t/n, x) = sup ft\u2208AN inf pt\u2208\u2206 sup bt\u2208B . . . sup fn\u22121\u2208AN inf pn\u22121\u2208\u2206 sup bn\u22121\u2208B g(X t,x,p,f,bn ),\nvn(1, x) = g(x),\nwhere t = 0, . . . , n\u2212 1, g(x) = max{x1, . . . , xn}. From the dynamic programming theory it is known that vn satisfies the recurrence relations\nvn(t/n, x) = sup f\u2208AN inf p\u2208\u2206 sup b\u2208B\nvn((t+ 1)/n, x+ r(p, f, b)/ \u221a n), (2.3)\nt \u2264 n\u22121, r = (r1, . . . , rN). We stress that we need not rigorously justify this and subsequent claims, since our goal is to formally construct prediction strategies. Their verification is delayed to the last step.\nFor a moment imagine that vn is a smooth function, satisfying (2.3) on [0, 1\u2212 1/n]\u00d7RN . Then, by Taylor\u2019s formula we get\n0 = sup f\u2208AN inf p\u2208\u2206 sup b\u2208B\n{\u221a n\u3008vnx(t, x), r(p, f, b)\u3009+ vnt (t, x)\n+ 1\n2 \u3008vnxx(t, x)r(p, f, b), r(p, f, b)\u3009+ o(1)\n}\n, (2.4)\nwhere vnx , v n xx are the gradient vector and the Hessian matrix.\nWe will say that the loss function l satisfies the Blackwell condition if\n\u0393(\u03b3, f) := {p \u2208 \u2206 : \u3008\u03b3, r(p, f, b)\u3009 \u2264 0, b \u2208 B} 6= \u2205 (2.5) for all (\u03b3, f) \u2208 RN+ \u00d7 AN . Clearly, \u0393(0, f) = \u2206. The Blackwell condition (2.5) is satisfied if l is convex in its first argument. In this case p = \u03b3/\u3008\u03b3, 1\u3009 \u2208 \u0393(\u03b3, f) for \u03b3 \u2208 RN+\\{0}, since\nN \u2211\ni=1\n\u03b3iri ( \u03b3 \u3008\u03b3, 1\u3009 , f, b ) = \u3008\u03b3, 1\u3009l (\u3008\u03b3, f\u3009 \u3008\u03b3, 1\u3009 , b ) \u2212 N \u2211\ni=1\n\u03b3il(f i, b) \u2264 0\nby Jensen\u2019s inequality. By the nature of vn these functions are non-decreasing in each xi. Indeed, v\nn(t/n, x) is the optimal worst-case regret if the initial regret with respect to i-th expert at time moment t equals to xi. From (2.4) we get\n0 \u2264 sup f\u2208AN inf p\u2208\u0393(vnx ,f) sup b\u2208B\n{\nvnt (t, x) + 1\n2 \u3008vnxx(t, x)r(p, f, b), r(p, f, b)\u3009+ o(1)\n}\n.\nSo, we expect that the limiting function v satisfies the inequality\n\u2212 vt(t, x)\u2212G(vx(t, x), vxx(t, x)) \u2264 0, (2.6)\nG(\u03b3, S) = 1\n2 sup f\u2208AN inf p\u2208\u0393(\u03b3,f) sup b\u2208B\n\u3008Sr(p, f, b), r(p, f, b)\u3009,\nand the boundary condition v(1, x) = g(x). Note that G(\u03b3, S) \u2265 G(\u03b3, S \u2032), if the symmetric N \u00d7N matrix S \u2212 S \u2032 is non-negative definite. Hence,\n\u2212 ut(t, x)\u2212G(ux(t, x), uxx(t, x)) = 0 (2.7) is a fully non-linear parabolic equation (see [5]). Along with (2.7) we consider the boundary condition\nu(1, x) = g(x) = max{x1, . . . , xn}. (2.8)\nThe functions vn are defined on Qn = {0, 1/n, . . . , (n \u2212 1)/n, 1} \u00d7 RN . To describe their limiting behavior in a rigorous way, one can consider the Barles-Perthame half-relaxed (weak) upper limit:\nv(t, x) = sup{ lim vnk(tk, xk) : Qnk \u220b (tk, xk) \u2192 (t, x) and vnk(tk, xk) converges}.\nFrom the results of [1, 2, 6] and the above calculations we expect that v is a viscosity subsolution of (2.7), (2.8). Note, that by the definition,\nlim sup n\u2192\u221e 1\u221a n Rn \u2264 v(0, 0). (2.9)\n3. Smooth supersolutions and induced weighted average forecasting strategies\nTake a smooth supersolution w of (2.7), (2.8):\n\u2212 wt(t, x)\u2212G(wx(t, x), wxx(t, x)) \u2265 0, w(1, x) \u2265 g(x), (3.10) which is non-decreasing in each variable xi. Assuming a comparison result: v \u2264 w, we conclude that the inequality (2.9) holds true for w(0, 0) instead of v(0, 0). We also expect that a strategy pt(x) \u2208 \u0393(wx(t, x), f) will produce the regret, satisfying this bound.\nLet us look for supersolutions of the form w(t, x) = c(1\u2212 t) +\u03a6(x), where c is a constant, \u03a6(x) \u2265 g(x), (3.11)\nand \u03a6 is non-decreasing in each variable. The differential inequality (3.10) implies the condition G(\u03a6x(x),\u03a6xx(x)) \u2264 c. This condition is satisfied if\n1 2 sup x\u2208RN \u3008\u03a6xx(x)h, h\u3009 \u2264 c, |hi| \u2264 1, i = 1, . . . , N. (3.12)\nThen by the Blackwell condition (2.5) there exists a vector-function\np\u2217(x, f) \u2208 \u0393(\u03a6x(x), f). (3.13) If l is convex in its first argument and \u03a6 is strictly increasing in each variable, then, according to the remark after the formula (2.5), one can take\np\u2217(x, f) = \u03a6x(x)\n\u3008\u03a6x(x), 1\u3009 \u2208 \u0393(\u03a6x(x), f). (3.14)\nConsider the discrete-time state process (2.2), generated by the prediction strategy, related to p\u2217:\nX\u2217,is+1 = X \u2217,i s + 1\u221a n ri(p\u2217s, fs, bs), p \u2217 s = p \u2217(X\u2217s , fs), X \u2217 0 = 0. (3.15)\nNote, that p\u2217t automatically satisfies the inequality \u3008\u03a6x(X\u2217t ), r(p\u2217t , ft, bt)\u3009 \u2264 0 (3.16) which is also called the Blackwell condition: see [3, 4]. For a convex function a 7\u2192 l(a, b) from (3.14) we get a weighted average forecaster:\na\u2217t = \u3008p\u2217t , ft\u3009 = \u3008\u03a6x(X\u2217t ), ft\u3009 \u3008\u03a6x(X\u2217t ), 1\u3009 . (3.17)\nTheorem 1. Let the Blackwell condition (2.5) be satisfied, and let \u03a6 : RN 7\u2192 R be a twice continuously differentiable function, which non-decreases in each variable and meets the conditions (3.11), (3.12). Then a prediction strategy\na\u2217t = \u3008p\u2217t , f\u3009, p\u2217t = p\u2217(X\u2217t , ft), t = 0, . . . , n\u2212 1, where p\u2217 satisfies (3.13) and X\u2217 is defined by (3.15), produces the regret, satisfying the inequality (1.1) with C = c+ \u03a6(0).\nProof. For w(t, x) = c(1\u2212 t) + \u03a6(x) by Taylor\u2019s formula we get w((t+ 1)/n,X\u2217t+1)\u2212 w(t/n,X\u2217t ) = \u2212c/n + \u03a6(X\u2217t+1)\u2212 \u03a6(X\u2217t )\n= \u2212c/n + \u3008\u03a6x(X\u2217t ), r(p\u2217t , ft, bt)\u3009/ \u221a n + 1\n2 \u3008\u03a6xx(\u03bet)r(p\u2217t , ft, bt), r(p\u2217t , ft, b\u2217t )\u3009/n \u2264 0,\nfor some \u03bet, where the last inequality is implied by (3.16) and (3.12). Now the assertion of the theorem follows from the condition (3.11):\nRn/ \u221a n = g(X\u2217n) \u2264 w(1, X\u2217n) = \u03a6(X\u2217n) \u2264 w(0, X\u22170) = c+ \u03a6(0).\nFollowing [3, 4] we call \u03a6 a potential function. The most natural smooth upper bound for max{x1, . . . , xN}, and hence a candidate for a potential, is a soft-maximum function\n\u03a6(x) = 1\n\u03b7 ln\n(\nN \u2211\ni=1\ne\u03b7xi\n)\n, \u03b7 > 0. (3.18)\nThis function is included in a more general class \u03a6(x) = \u03c8 (\n\u2211N i=1 \u03c6(xi)\n)\nconsidered in [3, 4],\nwhere \u03c8 and \u03c6 are assumed to be concave and convex respectively. The following inequality is also taken from [3, 4]:\n\u3008\u03a6xx(x)h, h\u3009 \u2264 \u03c8\u2032 ( N \u2211\nk=1\n\u03c6(xk)\n)\nN \u2211\ni=1\n\u03c6\u2032\u2032(xi)h 2 i .\nFor (3.18) we have \u03c8(x) = \u03b7\u22121 ln x, \u03c6(x) = e\u03b7x,\n1 2 \u3008\u03a6xx(x)h, h\u3009 \u2264 \u03b7 2\nN \u2211\ni=1\ne\u03b7xi \u2211N\nk=1 e \u03b7xk\nh2i \u2264 c = \u03b7\n2 , |hi| \u2264 1.\nFor p\u2217t generated by (3.18), in accordance with Theorem 1 we have\nRn\u221a n \u2264 c+ \u03a6(0) = \u03b7 2 + lnN \u03b7 =\n\u221a 2 lnN\nfor an \u201coptimal\u201d choice \u03b7 = \u221a 2 lnN (cf. [4, Corollary 2.2]). The formula (3.17) reduces to\na\u2217t = \u3008\u03a6x(X\u2217t ), ft\u3009 \u3008\u03a6x(X\u2217t ), 1\u3009 = N \u2211\ni=1\ne\u03b7X \u2217,i t\n\u2211N j=1 e\n\u03b7X\u2217,jt f it =\nN \u2211\ni=1\ne\u2212\u03b7L i t/ \u221a n\n\u2211N j=1 e\n\u2212\u03b7Ljt/ \u221a n f it ,\nwhere Lit = \u2211t\u22121 s=0 l(f i t , bs) is the cumulative loss of i-th expert. This is a basic version of the exponentially weighted average forecaster: see [4, Chapter 2].\n4. Randomized prediction\nAssume that the forecaster randomly chooses a prediction by taking a sample It from a probability distribution pt = (p 1 t , . . . , p N t ) over {y1, . . . , yN}. His cumulative loss is compared with the cumulative loss of a best fixed prediction:\nn\u22121 \u2211\nt=0\nl(It, bt)\u2212 min 1\u2264i\u2264N\nn\u22121 \u2211\nt=0\nl(yi, b),\nand the regret is defined as the expectation of this quantity with respect to the induced artificial probability measure:\nRn =\nn\u22121 \u2211\nt=0\nN \u2211\nj=1\npjt l(yj , bt)\u2212 min 1\u2264i\u2264N\nn\u22121 \u2211\nt=0\nl(yi, bt) = min 1\u2264i\u2264N\nn\u22121 \u2211\nt=0\nri(pt, bt),\nri(p, b) =\nN \u2211\nj=1\npjl(yj , b)\u2212 l(yi, b).\nThe game, where the forecaster knows the previous moves: pt = pt(b0, . . . , bt\u22121), and the adversary knows the prediction algorithm: bt = bt(p0, . . . , pt) but not the predictions It itself, corresponds to the case of an oblivious adversary: [4, Chapter 2]. However, the case of non-oblivious adversary is not interesting for the problem of this form: see [4, Lemma 4.1].\nThe described game is simpler than that considered above, since the \u201cexperts\u201d, corresponding to fixed predictions, do not play against the forecaster. Moreover, the condition (2.5) is satisfied regardless of the convexity of l. Repeating the reasoning of Section 2, we get the inequality (2.6) with\nG(\u03b3, S) = 1\n2 inf p\u2208\u0393(\u03b3) sup b\u2208B\n\u3008Sr(p, b), r(p, b)\u3009,\n\u0393(\u03b3) =\n{\np \u2208 \u2206 : N \u2211\ni=1\n\u03b3i\nN \u2211\nj=1\npjl(yj, b)\u2212 N \u2211\ni=1\nl(yi, b) \u2264 0, b \u2208 B } .\nSo, a prediction strategy satisfying\npi,\u2217t = \u03a6xi(X\n\u2217 t )\n\u3008\u03a6x(X\u2217t ), 1\u3009 for \u03a6x(X\n\u2217 t ) 6= 0,\nwhere \u03a6 meets the conditions of Theorem 1, and X\u2217t is defined by the recursion of the form\n(3.15), produces the regret Rn \u2264 C/ \u221a n. In particular, C = \u221a 2 lnN for the exponentially weighted average forecaster, discussed after Theorem 1. Finally, we note that the case of internal regret (see [4, Section 4.4]) can be considered in the same way.\n5. Acknowledgments\nThe research is supported by the Russian Science Foundation, project 17-19-01038.\nReferences\n[1] Barles, G., Perthame, B.: Exit time problems in optimal control and vanishing viscosity method. SIAM J. Control Optim. 26(5), 1133\u20131148 (1988) [2] Barles, G., Souganidis, P.E.: Convergence of approximation schemes for fully nonlinear second order equations. Asymptot. Anal. 4, 271\u2013283 (1991) [3] Cesa-Bianchi, N., Lugosi, G.: Potential-based algorithms in on-line prediction and game theory. Mach. Learn. 51(3), 239261 (2003) [4] Cesa-Bianchi, N., Lugosi, G.: Prediction, learning, and games. Cambridge University Press, New York (2006) [5] Crandall, M., Ishii, H., Lions, P.L.: User\u2019s guide to viscosity solutions of second order partial differential equations. Bull. Amer. Math. Soc. 27(1), 1\u201367 (1992) [6] Kohn, R., Serfaty, S.: A deterministic-control-based approach to fully nonlinear parabolic and elliptic equations. Commun. Pur. Appl. Math. 63(10), 1298\u20131350 (2010) [7] Rakhlin, A., Shamir, O., Sridharan, K.: Relax and randomize: from value to algorithms. In: F. Pereira, C.J.C. Burges, L. Bottou, K.Q. Weinberger (eds.) Advances in Neural Information Processing Systems 25, pp. 2141\u20132149. Curran Associates, Inc. (2012) [8] Rakhlin, A., Sridharan, K., Tewari, A.: Online learning: random averages, combinatorial parameters, and learnability. In: J.D. Lafferty, C.K.I. Williams, J. Shawe-Taylor, R.S. Zemel, A. Culotta (eds.) Advances in Neural Information Processing Systems 23, pp. 1984\u20131992. Curran Associates, Inc. (2010) [9] Rokhlin, D.: Central limit theorem under uncertain linear transformations. Stat. Probabil. Lett. 107, 191\u2013198 (2015) [10] Rokhlin, D.: Asymptotic sequential Rademacher complexity of a finite function class. Arch. Math. 108(3), 325\u2013335 (2017)\nInstitute of Mathematics, Mechanics and Computer Sciences, Southern Federal Univer-\nsity, Mil\u2019chakova str., 8a, 344090, Rostov-on-Don, Russia\nE-mail address, Dmitry B. Rokhlin: rokhlin@math.rsu.ru"}], "references": [{"title": "Exit time problems in optimal control and vanishing viscosity method", "author": ["G. Barles", "B. Perthame"], "venue": "SIAM J. Control Optim", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 1988}, {"title": "Convergence of approximation schemes for fully nonlinear second order equations", "author": ["G. Barles", "P.E. Souganidis"], "venue": "Asymptot. Anal", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 1991}, {"title": "Potential-based algorithms in on-line prediction and game theory", "author": ["N. Cesa-Bianchi", "G. Lugosi"], "venue": "Mach. Learn. 51(3),", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2003}, {"title": "Prediction, learning, and games", "author": ["N. Cesa-Bianchi", "G. Lugosi"], "venue": null, "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2006}, {"title": "User\u2019s guide to viscosity solutions of second order partial differential equations", "author": ["M. Crandall", "H. Ishii", "P.L. Lions"], "venue": "Bull. Amer. Math. Soc. 27(1),", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 1992}, {"title": "A deterministic-control-based approach to fully nonlinear parabolic and elliptic equations", "author": ["R. Kohn", "S. Serfaty"], "venue": "Commun. Pur. Appl. Math. 63(10),", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2010}, {"title": "Relax and randomize: from value to algorithms", "author": ["A. Rakhlin", "O. Shamir", "K. Sridharan"], "venue": "Advances in Neural Information Processing Systems", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2012}, {"title": "Online learning: random averages, combinatorial parameters, and learnability", "author": ["A. Rakhlin", "K. Sridharan", "A. Tewari"], "venue": "Advances in Neural Information Processing Systems", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2010}, {"title": "Central limit theorem under uncertain linear transformations", "author": ["D. Rokhlin"], "venue": "Stat. Probabil. Lett. 107,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2015}, {"title": "Asymptotic sequential Rademacher complexity of a finite function class", "author": ["D. Rokhlin"], "venue": "Arch. Math. 108(3),", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2017}], "referenceMentions": [{"referenceID": 0, "context": "Let l : A\u00d7 B 7\u2192 [0, 1] be a loss function.", "startOffset": 16, "endOffset": 22}, {"referenceID": 3, "context": "We refer to [4] for more information on this problem.", "startOffset": 12, "endOffset": 15}, {"referenceID": 2, "context": "In [3] it was shown that for a rather general class of online learning problems the construction of such strategies can 2010 Mathematics Subject Classification.", "startOffset": 3, "endOffset": 6}, {"referenceID": 6, "context": "More recently [7] proposed a systematic way for the construction of potentials in the case of randomized prediction, mentioning that \u201cThe origin/recipe for \u201cgood\u201d potential functions has always been a mystery (at least to the authors).", "startOffset": 14, "endOffset": 17}, {"referenceID": 6, "context": "\u201d The authors of [7] considered a recurrence relation, for the value function of a repeated game, determining the optimal regret, and showed that potential functions are related to relaxations of this function, which are consistent with the mentioned recurrence relation.", "startOffset": 17, "endOffset": 20}, {"referenceID": 6, "context": "As in [7], we consider a repeated game, determining the optimal regret, and the correspondent recurrence relation for the value functions v.", "startOffset": 6, "endOffset": 9}, {"referenceID": 6, "context": "Further, in contrast to [7], we simply pass to the limit as n\u2192 \u221e and get a non-linear parabolic Bellman-Isaacs type partial differential equation in [0, 1]\u00d7RN .", "startOffset": 24, "endOffset": 27}, {"referenceID": 0, "context": "Further, in contrast to [7], we simply pass to the limit as n\u2192 \u221e and get a non-linear parabolic Bellman-Isaacs type partial differential equation in [0, 1]\u00d7RN .", "startOffset": 149, "endOffset": 155}, {"referenceID": 5, "context": "The described approach is mainly inspired by the paper [6], where there was studied a link between fully non-linear second order (parabolic and elliptic) PDE and repeated games.", "startOffset": 55, "endOffset": 58}, {"referenceID": 9, "context": "Its application to the problems of online learning theory was initiated in [10], where an asymptotics of the sequential Rademacher complexity (the last notion was introduced in [8]) of a finite function class was related to the viscosity solution of a G-heat equation.", "startOffset": 75, "endOffset": 79}, {"referenceID": 7, "context": "Its application to the problems of online learning theory was initiated in [10], where an asymptotics of the sequential Rademacher complexity (the last notion was introduced in [8]) of a finite function class was related to the viscosity solution of a G-heat equation.", "startOffset": 177, "endOffset": 180}, {"referenceID": 9, "context": "In turn, the result of [10] is based on the central limit theorem under model uncertainty, studied within the same approach in [9].", "startOffset": 23, "endOffset": 27}, {"referenceID": 8, "context": "In turn, the result of [10] is based on the central limit theorem under model uncertainty, studied within the same approach in [9].", "startOffset": 127, "endOffset": 130}, {"referenceID": 4, "context": "7) is a fully non-linear parabolic equation (see [5]).", "startOffset": 49, "endOffset": 52}, {"referenceID": 0, "context": "From the results of [1, 2, 6] and the above calculations we expect that v is a viscosity subsolution of (2.", "startOffset": 20, "endOffset": 29}, {"referenceID": 1, "context": "From the results of [1, 2, 6] and the above calculations we expect that v is a viscosity subsolution of (2.", "startOffset": 20, "endOffset": 29}, {"referenceID": 5, "context": "From the results of [1, 2, 6] and the above calculations we expect that v is a viscosity subsolution of (2.", "startOffset": 20, "endOffset": 29}, {"referenceID": 2, "context": "16) which is also called the Blackwell condition: see [3, 4].", "startOffset": 54, "endOffset": 60}, {"referenceID": 3, "context": "16) which is also called the Blackwell condition: see [3, 4].", "startOffset": 54, "endOffset": 60}, {"referenceID": 2, "context": "Following [3, 4] we call \u03a6 a potential function.", "startOffset": 10, "endOffset": 16}, {"referenceID": 3, "context": "Following [3, 4] we call \u03a6 a potential function.", "startOffset": 10, "endOffset": 16}, {"referenceID": 2, "context": "considered in [3, 4], where \u03c8 and \u03c6 are assumed to be concave and convex respectively.", "startOffset": 14, "endOffset": 20}, {"referenceID": 3, "context": "considered in [3, 4], where \u03c8 and \u03c6 are assumed to be concave and convex respectively.", "startOffset": 14, "endOffset": 20}, {"referenceID": 2, "context": "The following inequality is also taken from [3, 4]: \u3008\u03a6xx(x)h, h\u3009 \u2264 \u03c8\u2032 ( N", "startOffset": 44, "endOffset": 50}, {"referenceID": 3, "context": "The following inequality is also taken from [3, 4]: \u3008\u03a6xx(x)h, h\u3009 \u2264 \u03c8\u2032 ( N", "startOffset": 44, "endOffset": 50}], "year": 2017, "abstractText": "We consider a sequence of repeated prediction games and formally pass to the limit. The supersolutions of the resulting non-linear parabolic partial differential equation are closely related to the potential functions in the sense of N.Cesa-Bianci, G. Lugosi (2003). Any such supersolution gives an upper bound for forecaster\u2019s regret and suggests a potentialbased prediction strategy, satisfying the Blackwell condition. A conventional upper bound for the worst-case regret is justified by a simple verification argument.", "creator": "LaTeX with hyperref package"}}}