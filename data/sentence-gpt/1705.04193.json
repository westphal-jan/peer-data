{"id": "1705.04193", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "11-May-2017", "title": "Nonnegative Matrix Factorization with Transform Learning", "abstract": "Traditional NMF-based signal decomposition relies on the factorization of spectral data which is typically computed by means of the short-time Fourier transform. In this paper we propose to relax the choice of a pre-fixed transform and learn a short-time unitary transform together with the factorization, using a novel block-descent algorithm. This improves the fit between the processed data and its approximation and is in turn shown to induce better separation performance in a speech enhancement experiment. We also propose a general approach to calculating frequency and amplitude (frequency and amplitude) of a signal to minimize the variability of the amplitude. We propose a general solution to solve an acoustic problem, which is by adding a new filter to amplify it to the frequency.\n\n\n\n\n\n\nThe first phase was a natural frequency in the upper frequency range in the upper frequency range. The result was that the signal was delivered by the right-hand side of the frequency range, with two parallel phases of the signal being delivered by the left-hand side. This result was that the signal was delivered by the right-hand side of the frequency range, with two parallel phases of the signal being delivered by the right-hand side. This result was that the signal was delivered by the right-hand side of the frequency range, with two parallel phases of the signal being delivered by the right-hand side. This result was that the signal was delivered by the right-hand side of the frequency range, with two parallel phases of the signal being delivered by the right-hand side. This result was that the signal was delivered by the right-hand side of the frequency range, with two parallel phases of the signal being delivered by the right-hand side. This result was that the signal was delivered by the right-hand side of the frequency range, with two parallel phases of the signal being delivered by the right-hand side. This result was that the signal was delivered by the right-hand side of the frequency range, with two parallel phases of the signal being delivered by the right-hand side.\n\n\n\nThe second phase was a natural frequency in the upper frequency range. The result was that the signal was delivered by the right-hand side of the frequency range, with two parallel phases of the signal being delivered by the right-hand side. This result was that the signal was delivered by the right-hand side of the frequency range, with two parallel phases of the signal being delivered by the right-hand side. This result was that the signal", "histories": [["v1", "Thu, 11 May 2017 14:12:23 GMT  (308kb,D)", "http://arxiv.org/abs/1705.04193v1", null]], "reviews": [], "SUBJECTS": "cs.LG", "authors": ["dylan fagot", "c\\'edric f\\'evotte", "herwig wendt"], "accepted": false, "id": "1705.04193"}, "pdf": {"name": "1705.04193.pdf", "metadata": {"source": "CRF", "title": "NONNEGATIVE MATRIX FACTORIZATION WITH TRANSFORM LEARNING", "authors": ["Dylan Fagot", "C\u00e9dric F\u00e9votte", "Herwig Wendt"], "emails": ["firstname.lastname@irit.fr"], "sections": [{"heading": null, "text": "Index Terms\u2014 Nonnegative matrix factorization (NMF), transform learning, single-channel source separation"}, {"heading": "1. INTRODUCTION", "text": "Nonnegative matrix factorization (NMF) has become a privileged approach to spectral decomposition in several fields such as remote sensing and audio signal processing. In the latter field, it has led to state-of-the-art results in source separation [1] or music transcription [2]. The nonnegative data V \u2208 RM\u00d7N+ is typically the spectrogram |X| or |X|\u25e62 of some temporal signal y \u2208 RT , where X \u2208 CM\u00d7N is a short-time Fourier transform (STFT) of y, | \u00b7 | denotes the entry-wise absolute value and \u25e6 here denotes entry-wise exponentiation. NMF produces the approximate factorization\nV \u2248WH, (1)\nwhere W \u2208 RM\u00d7K+ is a nonnegative matrix referred to as dictionary that contains spectral patterns characteristic of the data while H \u2208 RK\u00d7N+ is the nonnegative matrix that contains the activation coefficients that approximate the data samples onto the dictionary. The factorization is usually low-rank (K < min(M,N)) but not necessarily so (in which case regularization constraints should apply on W and/or H). The decomposition (1) can then be inverted back to the time domain or post-processed in various ways to solve a variety of audio signal processing problems.\nIn this traditional setting, the STFT (or any regularly-paved time-frequency transform) acts as a pre-processing of the raw temporal data y. This is a potential limitation as any ill-chosen specification of the time-frequency transform may harm the quality of the decomposition. As such, we here propose to learn the transform together with the latent factors W and H. We propose to address this task by solving an optimization problem of the form\nmin \u03c6,W,H\nD(|\u03c6(y)|\u25e62|WH) (2)\nsubject to structure constraints on \u03c6 : RT \u2192 CM\u00d7N and to nonnegativity of W and H, and where D( \u00b7 | \u00b7 ) is a measure of fit.\nWe present the details of our approach and its connections with the state of the art in Section 2. Section 3 describes an algorithm\nthat returns stationary points of (2). Section 4 and 5 report results from music decomposition & speech enhancement experiments. In particular, we show that the proposed framework can significantly improve separation accuracy as compared to standard STFT-based NMF."}, {"heading": "2. NMF MEETS TRANSFORM LEARNING", "text": ""}, {"heading": "2.1. Learning a short-time unitary transform", "text": "As a first step, we propose in this paper to gently depart from the traditional STFT setting by restricting the transform \u03c6(y) to be a short-time unitary transform, likewise the STFT. Let us denote by Y \u2208 RM\u00d7N the matrix that contains adjacent & overlapping shorttime frames of size M of y and denote by \u03a6FT \u2208 CM\u00d7M the unitary complex-valued Fourier matrix with coefficients [\u03a6FT]qm = exp (j2\u03c0(q \u2212 1)(m\u2212 1)/M). Under these notations, the power spectrogram of y is simply given by |\u03a6FTY|\u25e62. As such, traditional NMF may be cast as\nmin W,H\nD(|\u03a6FTY|\u25e62|WH) s.t. W \u2265 0,H \u2265 0, (3)\nwhere the notation A \u2265 0 expresses the nonnegativity of A. We propose in this work to relax the pre-fixed transform \u03a6FT and learn it jointly with W and H. This means we consider the following problem\nmin \u03a6,W,H\nD(|\u03a6Y|\u25e62|WH) s.t. \u03a6H\u03a6 = I,W \u2265 0,H \u2265 0. (4)\nWe choose at this stage to impose \u03a6 to be unitary likewise the STFT though one could consider relaxing this assumption as well. The unitary constraint implicitly keeps \u03a6 nonsingular and excludes trivial solutions such as (\u03a6,W,H) = (0,0,0) or (1M\u00d7M ,1M\u00d71,11\u00d7M |Y|\u25e62), where 1M\u00d7N denotes the M \u00d7 N matrix filled with ones. In this paper, we also choose the measure of fit D( \u00b7 | \u00b7 ) to be the Itakura-Saito (IS) divergence DIS(A|B) =\u2211 ij(aij/bij \u2212 log(aij/bij) \u2212 1). Used with power spectral data, it is known to underly a variance-structured Gaussian composite model that is relevant to the representation of audio signals [3] and has proven an efficient choice for audio source separation, e.g., [4]. However, the proposed framework can accommodate any other measure of fit. We denote byC (\u03a6,W,H) = DIS ( |\u03a6Y|\u25e62|WH\n) the IS-based objective function in problem (4). We refer to the objective described by (4) as TL-NMF, which stands for transformlearning NMF."}, {"heading": "2.2. Connection to other works", "text": "TL-NMF is inspired by the work of Ravishankar & Bresler [5] on learning sparsifying transforms. Given a collection of data samples Y (such as images collected in the columns of Y), their work\nar X\niv :1\n70 5.\n04 19\n3v 1\n[ cs\n.L G\n] 1\n1 M\nay 2\n01 7\nAlgorithm 1: TL-NMF Input : Y, \u03c4 Output: \u03a6, W, H s.t. |\u03a6Y|\u25e62 \u2248WH Initialize \u03a6, W and H while > \u03c4 do\nW\u2190W \u25e6 ((WH) \u25e6\u22122\u25e6|\u03a6Y|\u25e62)HT\n(WH)\u25e6\u22121HT % MM update [10]\nH\u2190 H \u25e6 W T ((WH)\u25e6\u22122\u25e6|\u03a6Y|\u25e62)\nWT (WH)\u25e6\u22121 % MM update [10]\nNormalize W and H to remove scale ambiguity Compute \u03b3 and \u2126 as in Section 3 \u03a6\u2190 \u03c0 (\u03a6 + \u03b3\u2126) Compute stopping criterion as in Eq. (6)\nend\nconsist in finding an invertible transform \u03a6 such that the output of \u03a6Y is sparse. We are instead looking for a transform \u03a6 such that |\u03a6Y|\u25e62 can be well approximated by a NMF. Note that we could more generally consider the problem of finding \u03a6 such that \u03a6Y is low-rank.\nTL-NMF can be viewed as finding a one-layer factorizing network, where Y acts as the raw data, \u03a6 the linear operator, | \u00b7 |\u25e62 the nonlinearity and WH the output of the network. As future work, we could imagine fully bridging deep learning and NMF by looking for a cascade of decompositions fL(\u03a6L . . . f1(\u03a61Y)) such that the output is a NMF. Some recent papers have combined deep learning and NMF but in a different way. For instance, [6] considers a discriminative NMF setting and [7] studies nonnegative auto-encoders.\nFinally, note that TL-NMF still operates in a transformed domain and is not directly related to synthesis-based NMF models in which the raw data y(t) is modeled as y(t) = \u2211 k ck(t) where the spectrogram of ck(t) is penalized so as to be closely rank-one [8, 9]."}, {"heading": "3. ALGORITHM", "text": "We describe a block-coordinate descent algorithm that returns stationary points of problem (4). Like the objective function in (3), the objective function C (\u03a6,W,H) is nonconvex and the returned solution depends on initialization. The blocks are the individual variables W, H and \u03a6 that are updated in turn until a convergence criterion is met. We use for W and H the standard multiplicative IS-NMF updates presented in, e.g., [10], that can be derived from a majorization-minimization procedure. Let us now turn our attention towards the update of \u03a6. We propose to use a gradient-descent procedure with a line-search step selection followed by a projection onto the unitary constraint, following the approach of [11]. The main benefit of this approach is that it yields an efficient yet simple algorithm for finding a unitary update for \u03a6.\nThe gradient of the objective function with respect to (w.r.t.) \u03a6 is given by\n\u2207 def= \u2207\u03a6C (\u03a6) = 2 (\u2206 \u25e6X)YT (5)\nwhere X = \u03a6Y, \u2206 = V\u0302\u25e6\u22121 \u2212V\u25e6\u22121, V = |X|\u25e62, V\u0302 = WH. The steepest manifold-dependent descent direction is given by the natural gradient \u2126 = \u03a6\u2207H\u03a6 \u2212 \u2207. A suitable step-size \u03b3 is then chosen according to the Armijo rule so that the projection \u03c0 (\u03a6 + \u03b3\u2126) of the updated transform onto the unitary constraint induces a significant decrease of the objective function [11].\nOur block-coordinate descent algorithm is stopped when the relative variation\n(i) = C(\u03a6(i),W(i),H(i))\u2212 C(\u03a6(i\u22121),W(i\u22121),H(i\u22121))\nC(\u03a6(i\u22121),W(i\u22121),H(i\u22121)) (6)\nbetween iteration i \u2212 1 and i falls below a given threshold \u03c4 . The resulting TL-NMF algorithm is summarized in Algorithm 1. In our experiments, we used nonnegative random values for initializing W and H. The transform \u03a6 is initialized with baseline STFT, i.e., \u03a6 = \u03a6FT."}, {"heading": "4. MUSIC DECOMPOSITION EXPERIMENT", "text": "In this section, we report results obtained with the proposed algorithm for decomposing real audio data y(t) consisting of a 23s excerpt of Mamavatu by Susheela Raman that has been downsampled to fs = 16kHz. Y is constructed using 40ms-long, 50%- overlapping temporal segments that are windowed with a sine bell. This construction leads to M = 640 and N = 1191. The behavior of TL-NMF is compared to traditional IS-NMF, which we recall only amounts to TL-NMF with fixed transform \u03a6FT. The two algorithms are run with the same stopping threshold \u03c4 = 10\u22125 and arbitrary decomposition rank K = 6.\nFig. 1 displays the objective function values w.r.t. iterations for the two approaches. They are initialized with the same starting point so that they return the same objective value at iteration i = 0. Fig. 1 shows that the proposed algorithm enables to drastically reduce the objective value at convergence as compared to traditional IS-NMF: IS-NMF converges to a divergence of 6.7 \u00d7 105 while our variant reaches 5.5 \u00d7 104. This indicates that the proposed algorithm is effective in exploiting the extra flexibility offered by learning the transform \u03a6 jointly with the factorization.\nWe now examine examples of the atoms returned by TL-NMF (rows \u03c6m of \u03a6). Fig. 2 displays the real and imaginary parts of the twelve atoms which most contribute to the audio signal, in the sense that they correspond to the twelve largest values of ||\u03c6mY||2. It can be observed on the one hand that TL-NMF learns basis elements that do not drastically deviate from the Fourier atoms in that they, e.g., tend to maintain a dominant oscillatory pattern close to the initial Fourier atom. On the other hand, the learnt atoms are also different in that they are neither smooth nor necessarily periodical. They do not necessarily respect phase-quadrature of the real and imaginary part nor respect the Hermitian symmetry that is inherent in \u03a6FT. Because we are dealing with a nonconvex problem and using a descent algorithm, the estimated transform \u03a6 is inevitably dependent on its Fourier initialization. The effect of this initialization will be more thoroughly studied in future work. However it makes sense in this preliminary work to use \u03a6FT as the initialization as it corresponds to the traditional NMF setting."}, {"heading": "5. SUPERVISED SOURCE SEPARATION", "text": "In the previous section, we reported results of exploratory nature that show how TL-NMF is effective in learning a transform. We now examine whether learning an adaptive transform is actually usefully for source separation. To this end, we consider a supervised NMF-based separation setting that follows the approach of [12]. In the following we address the separation of speech from interfering noise, but the method can be applied to any classes of sound."}, {"heading": "5.1. Principle", "text": "We assume that we are given speech and noise training data ys(t) and yn(t) from which we form short-time matrices Ys and Yn of sizes M \u00d7 Ns and M \u00d7 Nn, as in Section 2.1. Given a noisy speech recording y(t) with short-time matrix Y, traditional supervised NMF amounts to estimating activation matrices Hs and Hn such that\nV \u2248WsHs + WnHn, (7)\nsubject to sparsity of Hs and Hn, where V = |\u03a6FTY|\u25e62, Ws = |\u03a6FTYs|\u25e62, Wn = |\u03a6FTYn|\u25e62 [12]. Temporal source and noise estimates are then reconstructed in a second step by so-called Wiener filtering [3], based on the spectrogram estimates V\u0302s = WsHs and V\u0302n = WnHn.\nIn this section, we generalize this procedure by again learning an optimal transform within the separation procedure. To this end, we propose to build an approximation like Eq. (7) but where the fixed transform \u03a6 = \u03a6FT is now relaxed and learnt together with Hs and Hn. This means we propose to minimize\nCe(\u03a6,Hs,Hn) def = DIS ( |\u03a6Y|\u25e62 \u2223\u2223 |\u03a6Ys|\u25e62Hs + |\u03a6Yn|\u25e62Hn) + \u03bbs||Hs||1 + \u03bbn||Hn||1 s.t. \u03a6H\u03a6 = I,Hs \u2265 0,Hn \u2265 0. (8)\nThe sparsity-inducing `1 terms on Hs and Hn regularize the factorization which becomes potentially overcomplete in the event of large training datasets. Note how \u03a6 now appears in both sides of the data-fitting term DIS(\u00b7|\u00b7) as the same transform is logically applied to the mixed data Y and the training data Ys and Yn. This requires to slightly modify the gradient of Ce w.r.t. \u03a6 as compared to Section 2 and described in next section. After optimization, given V = |\u03a6Y|\u25e62 along with speech and noise spectrogram estimates V\u0302s = |\u03a6Ys|\u25e62Hs and V\u0302n = |\u03a6Yn|\u25e62Hn, temporal estimates may still be produced with Wiener filtering, i.e.,\nY\u0302s = \u03a6 H ( V\u0302s V \u25e6 (\u03a6Y) ) (9)\nfollowed by standard overlap-adding of the columns of Y\u0302s to return y\u0302s(t), and likewise for the noise. This is exactly the same procedure than in traditional NMF-based separation except that the Fourier and inverse-Fourier operations are replaced by \u03a6 and \u03a6H ."}, {"heading": "5.2. Algorithm", "text": "Denote Ytrain = [Ys,Yn], Xtrain = \u03a6Ytrain, W = |Xtrain|\u25e62, H =[ HTs ,H T n ]T and V\u0302 = WH. Given W, H can be updated with\nAlgorithm 2: Supervised TL-NMF Input : Y, Ytrain, \u03c4 Output: \u03a6, H Initialize \u03a6, H while > \u03c4 do\nV = |\u03a6Y|\u25e62, W = |\u03a6Ytrain|\u25e62 H\u2190 H \u25e6 W T ((WH)\u25e6\u22122\u25e6V)\nWT (WH)\u25e6\u22121+[\u03bbs1N\u00d7Ns ,\u03bbn1N\u00d7Nn ] T\nCompute \u03b3 and \u2126 as in Section 5.2 \u03a6\u2190 \u03c0 (\u03a6 + \u03b3\u2126) Compute stopping criterion\nend\nmultiplicative rules derived from majorization-minimization as in [10]. We use again a gradient-descent approach for the update of \u03a6. The gradient of the objective function (8) can be expressed as\n\u2207\u03a6Ce (\u03a6,H) = 2 (\u2206 \u25e6X)YT + 2 (\u039e \u25e6Xtrain)YTtrain (10)\nwhere \u2206 = V\u0302\u25e6\u22121 \u2212 V\u25e6\u22121 and \u039e = \u2206eHT with \u2206e = V\u0302\u2212V V\u0302\u25e62\n. Note that the first term of Eq. (10) is the gradient in Eq. (5). The second term is nothing but the gradient of the data-fitting term DIS with its first argument fixed. Based on Eq. (10), we again use a line-search step selection in the steepest natural gradient direction followed by a projection, like in Section 3 and following [11]. The resulting algorithm is summarized in Algorithm 2."}, {"heading": "5.3. Speech enhancement experiment", "text": "We consider clean speech and noise data from the TIMIT corpus [13] and the CHIME challenge,1 respectively. For speech training data ys(t), we use all utterances but the first one in the train/fcjf0 directory (about 21s in total). For noise training data yn(t), we use 30s of the file BGD 150204 010 BUS.CH1.wav, which contains noise recorded in a bus. A simulated mixed signal y(t) of duration 3s is generated by mixing the remaining speech utterance with another segment of the noise file (as such, the test data is not included in the training data), using a signal-to-noise ratio of\u221210dB. The audio files sampling frequency is fs = 16kHz and short-term matrices Y, Ys and Yn are constructed using 40ms-long, 50%- overlapping windowed segments like in Section 4, leading to dimensions M = 640, N = 149, Ns = 1059 and Nn = 1517. The regularization parameters \u03bbs and \u03bbn are arbitrarily set to 102 and we again used \u03c4 = 10\u22125.\nOur supervised TL-NMF approach is compared to the traditional supervised NMF procedure (with the IS divergence) described in Section 5.1, based on the same training data and using the same regularization parameters (only the transform \u03a6 differs between the two approaches). Source separation performance was assessed using the standard BSS eval criteria [14]. We also compute the performance criteria obtained by y\u0302s = y\u0302n = y/2 as an indicative baseline. Table 1 reports the comparison results. The results show that the extra adaptability offered by TL-NMF is clearly beneficial as far as source separation capabilities are concerned. Indeed, TL-NMF improves the signal to distortion, interference, and artifact ratios for the speech source by 4.3, 8.0 and 4.1dB, respectively, as compared to traditional IS-NMF. Interestingly, the noise\n1http://spandh.dcs.shef.ac.uk/chime_challenge\nseparation performance is very similar for TL-NMF and IS-NMF, indicating that the speech source is the one that principally benefits from the adaptive transform. The scores are dependent on the values of \u03bbs and \u03bbn but the speech separation performance of TLNMF was found superior to IS-NMF for all values we tested. This will be reported in a forthcoming long version of this paper.\nFig. 3 displays the values of the objective function Ce returned by supervised TL-NMF and supervised IS-NMF (in which case \u03a6 = \u03a6FT). It clearly indicates that, at convergence, the value of the objective function obtained by the proposed algorithm is nearly one order of magnitude lower than that of IS-NMF: the latter algorithm makes the objective function reach a value of 9.5 \u00d7 104 (IS divergence of 6.8 \u00d7 104) while our algorithm brings the objective function value down to 1.5\u00d7 104 (IS divergence of 6.0\u00d7 103)."}, {"heading": "6. CONCLUSION AND FUTURE WORK", "text": "We addressed the task of learning the transform underlying NMFbased signal decomposition jointly with the factorization. Specifically, we have proposed a block-coordinate descent algorithm that enables us to find a unitary transform \u03a6 jointly with the dictionary W and the activation matrix H. To our knowledge, the proposed algorithm is the first operational procedure for learning a transform in the context of NMF. Our preliminary experiments with real audio data indicate that automatically adapting the transform to the signal pays off when seeking latent factors that accurately represent the data. In particular, the improvement in data fit permits to achieve source separation performance that compares very favorably against the state-of-the-art. Note that although our presentation focused on the processing of audio data, the approach can be adapted to many other settings where NMF is applied to preprocessed data.\nFuture work will include studying the effect of the initialization of \u03a6, the influence of the value ofK on the learnt transform as well as relaxations of the unitary constraint on \u03a6, e.g., to nonsingular matrices \u03a6. Also, the use of alternative optimization strategies that lend themselves well to dealing with nonconvex problems in high dimension, including stochastic gradient descent, will be investigated."}, {"heading": "7. REFERENCES", "text": "[1] P. Smaragdis, C. Fe\u0301votte, G. Mysore, N. Mohammadiha, and M. Hoffman, \u201cStatic and dynamic source separation using nonnegative factorizations: A unified view,\u201d IEEE Signal Processing Magazine, vol. 31, no. 3, pp. 66\u201375, May 2014.\n[2] E. Vincent, N. Bertin, and R. Badeau, \u201cHarmonic and inharmonic nonnegative matrix factorization for polyphonic pitch transcription,\u201d in Proc. IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), 2008.\n[3] C. Fe\u0301votte, N. Bertin, and J.-L. Durrieu, \u201cNonnegative matrix factorization with the itakura-saito divergence : With application to music analysis,\u201d Neural Computation, vol. 21, no. 3, pp. 793\u2013830, 2009.\n[4] B. King, C. Fe\u0301votte, and P. Smaragdis, \u201cOptimal cost function and magnitude power for NMF-based speech separation and music interpolation,\u201d in Proc. IEEE International Workshop on Machine Learning for Signal Processing (MLSP), 2012.\n[5] S. Ravishankar and Y. Bresler, \u201cLearning sparsifying transforms,\u201d IEEE Transactions on Signal Processing, vol. 61, no. 5, pp. 1072\u20131086, 2013.\n[6] J. L. Roux, J. R. Hershey, and F. Weninger, \u201cDeep NMF for speech separation,\u201d in Proc. IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), 2015.\n[7] P. Smaragdis and S. Venkataramani, \u201cA neural network alternative to non-negative audio models,\u201d in Proc. IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), 2017.\n[8] C. Fe\u0301votte and M. Kowalski, \u201cLow-rank time-frequency synthesis,\u201d in Advances in Neural Information Processing Systems (NIPS), 2014.\n[9] H. Kameoka, \u201cMulti-resolution signal decomposition with time-domain spectrogram factorization,\u201d in Proc. IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), 2015.\n[10] C. Fe\u0301votte and J. Idier, \u201cAlgorithms for nonnegative matrix factorization with the \u03b2-divergence,\u201d Neural Computation, vol. 23, no. 9, pp. 2421\u20132456, 2011.\n[11] J. H. Manton, \u201cOptimization algorithms exploiting unitary constraints,\u201d IEEE Transactions on Signal Processing, vol. 50, no. 3, pp. 635\u2013650, 2002.\n[12] P. Smaragdis, B. Raj, and M. V. Shashanka, \u201cSupervised and semi-supervised separation of sounds from single-channel mixtures,\u201d in Proc. International Conference on Independent Component Analysis and Signal Separation (ICA), 2007.\n[13] J. S. Garofolo, L. F. Lamel, W. M. Fisher, J. G. Fiscus, and D. S. Pallett, \u201cTimit acoustic-phonetic continuous speech corpus LDC93S1,\u201d Philadelphia: Linguistic Data Consortium, Tech. Rep., 1993.\n[14] E. Vincent, R. Gribonval, and C. Fe\u0301votte, \u201cPerformance measurement in blind audio source separation,\u201d IEEE Transactions on Audio, Speech, and Language Processing, vol. 14, no. 4, pp. 1462\u20131469, 2006."}], "references": [{"title": "Static and dynamic source separation using nonnegative factorizations: A unified view", "author": ["P. Smaragdis", "C. F\u00e9votte", "G. Mysore", "N. Mohammadiha", "M. Hoffman"], "venue": "IEEE Signal Processing Magazine, vol. 31, no. 3, pp. 66\u201375, May 2014.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2014}, {"title": "Harmonic and inharmonic nonnegative matrix factorization for polyphonic pitch transcription", "author": ["E. Vincent", "N. Bertin", "R. Badeau"], "venue": "Proc. IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), 2008.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2008}, {"title": "Nonnegative matrix factorization with the itakura-saito divergence : With application to music analysis", "author": ["C. F\u00e9votte", "N. Bertin", "J.-L. Durrieu"], "venue": "Neural Computation, vol. 21, no. 3, pp. 793\u2013830, 2009.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2009}, {"title": "Optimal cost function and magnitude power for NMF-based speech separation and music interpolation", "author": ["B. King", "C. F\u00e9votte", "P. Smaragdis"], "venue": "Proc. IEEE International Workshop on Machine Learning for Signal Processing (MLSP), 2012.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2012}, {"title": "Learning sparsifying transforms", "author": ["S. Ravishankar", "Y. Bresler"], "venue": "IEEE Transactions on Signal Processing, vol. 61, no. 5, pp. 1072\u20131086, 2013.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2013}, {"title": "Deep NMF for speech separation", "author": ["J.L. Roux", "J.R. Hershey", "F. Weninger"], "venue": "Proc. IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), 2015.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2015}, {"title": "A neural network alternative to non-negative audio models", "author": ["P. Smaragdis", "S. Venkataramani"], "venue": "Proc. IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), 2017.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2017}, {"title": "Low-rank time-frequency synthesis", "author": ["C. F\u00e9votte", "M. Kowalski"], "venue": "Advances in Neural Information Processing Systems (NIPS), 2014.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2014}, {"title": "Multi-resolution signal decomposition with time-domain spectrogram factorization", "author": ["H. Kameoka"], "venue": "Proc. IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), 2015.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2015}, {"title": "Algorithms for nonnegative matrix factorization with the \u03b2-divergence", "author": ["C. F\u00e9votte", "J. Idier"], "venue": "Neural Computation, vol. 23, no. 9, pp. 2421\u20132456, 2011.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2011}, {"title": "Optimization algorithms exploiting unitary constraints", "author": ["J.H. Manton"], "venue": "IEEE Transactions on Signal Processing, vol. 50, no. 3, pp. 635\u2013650, 2002.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2002}, {"title": "Supervised and semi-supervised separation of sounds from single-channel mixtures", "author": ["P. Smaragdis", "B. Raj", "M.V. Shashanka"], "venue": "Proc. International Conference on Independent Component Analysis and Signal Separation (ICA), 2007.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2007}, {"title": "Timit acoustic-phonetic continuous speech corpus LDC93S1", "author": ["J.S. Garofolo", "L.F. Lamel", "W.M. Fisher", "J.G. Fiscus", "D.S. Pallett"], "venue": "Philadelphia: Linguistic Data Consortium, Tech. Rep., 1993.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 1993}, {"title": "Performance measurement in blind audio source separation", "author": ["E. Vincent", "R. Gribonval", "C. F\u00e9votte"], "venue": "IEEE Transactions on Audio, Speech, and Language Processing, vol. 14, no. 4, pp. 1462\u20131469, 2006.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2006}], "referenceMentions": [{"referenceID": 0, "context": "In the latter field, it has led to state-of-the-art results in source separation [1] or music transcription [2].", "startOffset": 81, "endOffset": 84}, {"referenceID": 1, "context": "In the latter field, it has led to state-of-the-art results in source separation [1] or music transcription [2].", "startOffset": 108, "endOffset": 111}, {"referenceID": 2, "context": "Used with power spectral data, it is known to underly a variance-structured Gaussian composite model that is relevant to the representation of audio signals [3] and has proven an efficient choice for audio source separation, e.", "startOffset": 157, "endOffset": 160}, {"referenceID": 3, "context": ", [4].", "startOffset": 2, "endOffset": 5}, {"referenceID": 4, "context": "TL-NMF is inspired by the work of Ravishankar & Bresler [5] on learning sparsifying transforms.", "startOffset": 56, "endOffset": 59}, {"referenceID": 9, "context": "Initialize \u03a6, W and H while > \u03c4 do W\u2190W \u25e6 ((WH) \u25e6\u22122\u25e6|\u03a6Y|\u25e62)HT (WH)\u25e6\u22121HT % MM update [10] H\u2190 H \u25e6 W T ((WH)\u25e6\u22122\u25e6|\u03a6Y|\u25e62) WT (WH)\u25e6\u22121 % MM update [10] Normalize W and H to remove scale ambiguity Compute \u03b3 and \u03a9 as in Section 3 \u03a6\u2190 \u03c0 (\u03a6 + \u03b3\u03a9) Compute stopping criterion as in Eq.", "startOffset": 83, "endOffset": 87}, {"referenceID": 9, "context": "Initialize \u03a6, W and H while > \u03c4 do W\u2190W \u25e6 ((WH) \u25e6\u22122\u25e6|\u03a6Y|\u25e62)HT (WH)\u25e6\u22121HT % MM update [10] H\u2190 H \u25e6 W T ((WH)\u25e6\u22122\u25e6|\u03a6Y|\u25e62) WT (WH)\u25e6\u22121 % MM update [10] Normalize W and H to remove scale ambiguity Compute \u03b3 and \u03a9 as in Section 3 \u03a6\u2190 \u03c0 (\u03a6 + \u03b3\u03a9) Compute stopping criterion as in Eq.", "startOffset": 139, "endOffset": 143}, {"referenceID": 5, "context": "For instance, [6] considers a discriminative NMF setting and [7] studies nonnegative auto-encoders.", "startOffset": 14, "endOffset": 17}, {"referenceID": 6, "context": "For instance, [6] considers a discriminative NMF setting and [7] studies nonnegative auto-encoders.", "startOffset": 61, "endOffset": 64}, {"referenceID": 7, "context": "Finally, note that TL-NMF still operates in a transformed domain and is not directly related to synthesis-based NMF models in which the raw data y(t) is modeled as y(t) = \u2211 k ck(t) where the spectrogram of ck(t) is penalized so as to be closely rank-one [8, 9].", "startOffset": 254, "endOffset": 260}, {"referenceID": 8, "context": "Finally, note that TL-NMF still operates in a transformed domain and is not directly related to synthesis-based NMF models in which the raw data y(t) is modeled as y(t) = \u2211 k ck(t) where the spectrogram of ck(t) is penalized so as to be closely rank-one [8, 9].", "startOffset": 254, "endOffset": 260}, {"referenceID": 9, "context": ", [10], that can be derived from a majorization-minimization procedure.", "startOffset": 2, "endOffset": 6}, {"referenceID": 10, "context": "We propose to use a gradient-descent procedure with a line-search step selection followed by a projection onto the unitary constraint, following the approach of [11].", "startOffset": 161, "endOffset": 165}, {"referenceID": 10, "context": "A suitable step-size \u03b3 is then chosen according to the Armijo rule so that the projection \u03c0 (\u03a6 + \u03b3\u03a9) of the updated transform onto the unitary constraint induces a significant decrease of the objective function [11].", "startOffset": 211, "endOffset": 215}, {"referenceID": 11, "context": "To this end, we consider a supervised NMF-based separation setting that follows the approach of [12].", "startOffset": 96, "endOffset": 100}, {"referenceID": 11, "context": "subject to sparsity of Hs and Hn, where V = |\u03a6FTY|, Ws = |\u03a6FTYs|, Wn = |\u03a6FTYn| [12].", "startOffset": 79, "endOffset": 83}, {"referenceID": 2, "context": "Wiener filtering [3], based on the spectrogram estimates V\u0302s = WsHs and V\u0302n = WnHn.", "startOffset": 17, "endOffset": 20}, {"referenceID": 9, "context": "multiplicative rules derived from majorization-minimization as in [10].", "startOffset": 66, "endOffset": 70}, {"referenceID": 10, "context": "(10), we again use a line-search step selection in the steepest natural gradient direction followed by a projection, like in Section 3 and following [11].", "startOffset": 149, "endOffset": 153}, {"referenceID": 12, "context": "We consider clean speech and noise data from the TIMIT corpus [13] and the CHIME challenge, respectively.", "startOffset": 62, "endOffset": 66}, {"referenceID": 13, "context": "Source separation performance was assessed using the standard BSS eval criteria [14].", "startOffset": 80, "endOffset": 84}], "year": 2017, "abstractText": "Traditional NMF-based signal decomposition relies on the factorization of spectral data which is typically computed by means of the short-time Fourier transform. In this paper we propose to relax the choice of a pre-fixed transform and learn a short-time unitary transform together with the factorization, using a novel block-descent algorithm. This improves the fit between the processed data and its approximation and is in turn shown to induce better separation performance in a speech enhancement experiment.", "creator": "LaTeX with hyperref package"}}}