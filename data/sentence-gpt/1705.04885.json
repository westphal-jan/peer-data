{"id": "1705.04885", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "13-May-2017", "title": "Awareness improves problem-solving performance", "abstract": "The brain's self-monitoring of activities, including internal activities -- a functionality that we refer to as awareness -- has been suggested as a key element of consciousness. Here we investigate whether the presence of an inner-eye-like process (monitor) that supervises the activities of a number of subsystems (operative agents) engaged in the solution of a problem can improve the problem-solving efficiency of the system. The problem is to find the global maximum of a NK fitness landscape and the performance is measured by the time required to find that maximum. The operative agents explore blindly the fitness landscape and the monitor provides them with feedback on the quality (fitness) of the proposed solutions. This feedback is then used by the operative agents to bias their searches towards the fittest regions of the landscape. We find that a weak feedback between the monitor and the operative agents improves the performance of the system, regardless of the difficulty of the problem, which is gauged by the number of local maxima in the landscape. For easy problems (i.e., landscapes without local maxima), the performance improves monotonically as the feedback strength increases, but for difficult problems, there is an optimal value of the feedback strength beyond which the system performance degrades very rapidly. Thus, the performance improvement of the system is not a function of the local maxima in the spatial landscape. In contrast, the performance improvement is observed by the participant agent as the performance increases, but by the participant agent as the performance increases, and by the participant agent as the performance decreases, the performance improves, and the performance improves. The data suggest that the optimal performance of the system is not measured by the average time required to complete a task. However, there are many possibilities in the data as to whether it is possible to compare the performance performance of a task on an autonomous, self-serving, or an autonomous model, with other aspects of the system being evaluated in real time.\n\n\n\n\n\nOur results indicate that the optimal performance of the system is not measured by the average time required to complete a task. The performance improvement of the system is not measured by the average time required to complete a task, as we suggested. It is measured by the target activity of the agent to increase the time required to perform a task.\n\nIn contrast, the optimal performance of the system is not measured by the average time required to perform a task. The performance improvement of the system is not measured by the average time required to perform a task.\nThe task performance improvement", "histories": [["v1", "Sat, 13 May 2017 20:40:24 GMT  (27kb,D)", "http://arxiv.org/abs/1705.04885v1", null]], "reviews": [], "SUBJECTS": "cs.AI", "authors": ["jos\\'e f fontanari"], "accepted": false, "id": "1705.04885"}, "pdf": {"name": "1705.04885.pdf", "metadata": {"source": "CRF", "title": "Awareness improves problem-solving performance", "authors": ["Jos\u00e9 F. Fontanari"], "emails": [], "sections": [{"heading": null, "text": "Awareness improves problem-solving performance\nJose\u0301 F. Fontanari Instituto de F\u0301\u0131sica de Sa\u0303o Carlos, Universidade de Sa\u0303o Paulo,\nCaixa Postal 369, 13560-970 Sa\u0303o Carlos, Sa\u0303o Paulo, Brazil\nThe brain\u2019s self-monitoring of activities, including internal activities \u2013 a functionality that we refer to as awareness \u2013 has been suggested as a key element of consciousness. Here we investigate whether the presence of an inner-eye-like process (monitor) that supervises the activities of a number of subsystems (operative agents) engaged in the solution of a problem can improve the problemsolving efficiency of the system. The problem is to find the global maximum of a NK fitness landscape and the performance is measured by the time required to find that maximum. The operative agents explore blindly the fitness landscape and the monitor provides them with feedback on the quality (fitness) of the proposed solutions. This feedback is then used by the operative agents to bias their searches towards the fittest regions of the landscape. We find that a weak feedback between the monitor and the operative agents improves the performance of the system, regardless of the difficulty of the problem, which is gauged by the number of local maxima in the landscape. For easy problems (i.e., landscapes without local maxima), the performance improves monotonically as the feedback strength increases, but for difficult problems, there is an optimal value of the feedback strength beyond which the system performance degrades very rapidly.\nI. INTRODUCTION\nWhat is consciousness for? From a biological perspective, an auspicious answer to this mind-opening question (see [1] for a thorough discussion of the theories of consciousness) views consciousness as a source of information about brain states \u2013 a brain\u2019s schematic description of those states \u2013 and suggests that the evolutionary usefulness of such inner eye is to provide human beings with an effective tool for doing natural psychology, i.e., for imagining what might be happening inside another person\u2019s head [2]. Hence, the conception of other people as beings with minds originates from the way each individual sees himself and, in that sense, solely extraordinarily social creatures, probably humans only, would evolve consciousness as a response to the pressures to handle interpersonal relationships [2]. There is an alternative, equally attractive, possibility that we may first unconsciously suppose other consciousness, and then infer our own by generalization [3]. We note that the hypothesis that consciousness is closely related to social ability has been suggested in many forms by many authors (see, e.g., [4\u20137]), but the original insight that consciousness and cognition are products of social behaviors probably dates back to Vygostsky in the 1930s [8].\nThis approach, however, is not very helpful to the engineer who wants to build a conscious machine. Fortunately, the recently proposed attention schema theory of consciousness [9, 10] offers some hope to our engineer by positing that awareness is simply a schematic model of one\u2019s state of attention, i.e., awareness is an internal model of attention. (The intimate connection between awareness and consciousness is expressed best by the view that consciousness is simply the awareness of what we have done or said, reflected back to us [3].) Building a functioning attention schema is a feasible software project today, which could then be coupled to the existing perceptual schemas [11] to create a conscious\nmachine. As before, the selective value of such internal model stems from the possibility of attributing the same model to other people, i.e, of doing natural psychology [10].\nInternal models or inner eyes keep track of processes that, within an evolutionary perspective, are useful to monitor and provide feedback to (or report on) those very same processes. This feedback can be thought of as the mechanism by which \u2018mind\u2019 influences matter [10]. Here we show that the inner monitoring can be useful in a more general problem-solving scenario. (The word awareness in the title of this paper is used with the meaning of inner monitoring.) In particular, we consider a number L of subsystems or operative agents that search randomly for the solution of a problem, viz. finding the global maximum of a rugged fitness landscape (see Section II), and a single monitor that tracks the quality of the solution found by each agent (i.e., its fitness) and records the best solution at each time. The feedback to the operative agents occurs with frequency p \u2264 1, i.e., on the average each agent receives feedback from the monitor p \u00d7 \u2206t times during the time interval \u2206t. The feedback consists of displaying the best solution among all agents at that time, so the operative agents can copy small pieces of that solution (see Section III for details).\nThe performance of the system composed of L operative agents and a monitor is measured, essentially, by the time it takes to find the global maximum of the fitness landscape. (Since we may want to compare performances for different values of L, the actual performance measure must be properly scaled by L, as discussed in Section III) The relevant comparison is between the case p = 0 where the monitor has no effect on the operation of the system (a scenario akin to the doctrine of epiphenomenalism [1]), and the case p > 0 where the system receives feedback from the monitor. If the speed to solve problems has a survival value to the individuals and if that speed increases in the presence of feedback from the ar X\niv :1\n70 5.\n04 88\n5v 1\n[ cs\n.A I]\n1 3\nM ay\n2 01\n7\n2 monitor, then one may argue for the plausibility of the\nevolution, as well as for the commonplaceness, of such inner-eyes-like processes in the brain.\nWe find that the performance of the system for small values of the feedback frequency or strength p, which is likely the most realistic scenario, is superior to the performance in absence of feedback, regardless of the difficulty of the task and of the size of the system. This finding lends support to the inner-eye scenario for brain processes. In the case of easy tasks (i.e., landscapes without local maxima), the performance always improves with increasing p, but for rugged landscapes the situation is more complicated: there exists an optimal value of p, which depends both on the complexity of the task and on the system size, beyond which the system performance deteriorates abruptly.\nThe rest of this paper is organized as follows. Since the tasks of varying complexity presented to the problemsolving system are finding the global maxima of rugged fitness landscapes generated by the NK model, in Section II we offer an outline of that classic model [12]. The problem-solving system is then described in great detail in Section III. We explore the space of parameters of the problem-solving system as well as of the NK model in Section IV, where we present and analyze the results of our simulations. Finally, Section V is reserved to our concluding remarks."}, {"heading": "II. TASK", "text": "The task posed to a system of L agents is to find the unique global maximum of a fitness landscape generated using the NK model [12]. For our purposes, the advantage of using the NK model is that it allows the tuning of the ruggedness of the landscape \u2013 and hence of the difficulty of the task \u2013 by changing the integer parameters N and K. More specifically, the NK landscape is defined in the space of binary strings x = (x1, . . . , xN ) with xi = 0, 1 and so the parameterN determines the size of the state space, given by 2N . For each bit string x is assigned a distinct real-valued fitness value \u03a6 (x) \u2208 [0, 1] which is an average of the contributions from each element i of the string, i.e.,\n\u03a6 (x) = 1\nN N\u2211 i=1 \u03c6i (x) , (1)\nwhere \u03c6i is the contribution of element i to the fitness of string x. It is assumed that \u03c6i depends on the state xi as well as on the states of the K right neighbors of i, i.e., \u03c6i = \u03c6i (xi, xi+1, . . . , xi+K) with the arithmetic in the subscripts done modulo N . The parameter K = 0, . . . , N \u2212 1 is called the degree of epistasis and determines the ruggedness of the landscape for fixed N . The functions \u03c6i are N distinct real-valued functions on {0, 1}K+1 and, as usual, we assign to each \u03c6i a uniformly\ndistributed random number in the unit interval so that \u03a6 \u2208 (0, 1) has a unique global maximum [12].\nThe increase of the parameter K from 0 to N \u2212 1 decreases the correlation between the fitness of neighboring strings (i.e., strings that differ at a single bit) in the state space. In particular, the local fitness correlation is given by corr (x, x\u0303i) = 1\u2212 (K + 1) /N where x\u0303i is the string x with bit i flipped. Hence for K = N\u22121 the fitness values are uncorrelated and the NK model reduces to the Random Energy model [13, 14]. Finding the global maximum of the NK model for K > 0 is an NP-complete problem [15], which means that the time required to solve all realizations of that landscape using any currently known deterministic algorithm increases exponentially fast with the length N of the strings. However, for K = 0 the (smooth) landscape has a single maximum that is easily located by picking for each string element i the state xi = 0 if \u03c6i (0) > \u03c6i (1) or the state xi = 1, otherwise. On the average, the number of local maxima increases with increasing K. This number can be associated with the difficulty of the task provided the search heuristic explores the local correlations of fitness values to locate the global maximum of the fitness landscape, which is the case of the search heuristic used in our simulations.\nSince the fitness values \u03a6 (x) are random, the number of local maxima varies considerably between landscapes characterized by the same values of N and K > 0, which makes the performance of any search heuristic based on the local correlations of the fitness landscape strongly dependent on the particular realization of the landscape. Hence we evaluate the system performance in a sample of 100 distinct realizations of the NK fitness landscape for fixed N and K. In particular, we fix the string length to N = 16 and allow the degree of epistasis to take on the values K = 0, 1, 3 and 5. In addition, in order to study landscapes with different state space sizes but the same correlation between the fitness of neighboring states we consider also strings of length N = 12 and N = 20.\nTable I shows the mean number of maxima, as well as two extreme statistics, namely, the minimum and the maximum number of maxima, in the sample of 100 landscapes used in the computational experiments. Although the landscapes (N = 12,K = 2), (N = 16,K = 3) and (N = 20,K = 4) exhibit the same local fitness correla-\n3 tion, viz. corr (x, x\u0303i) = 3/4, the number of local maxima differs widely. We note, however, that the density of local maxima decreases with increasing N provided the local fitness correlation is kept fixed."}, {"heading": "III. MODEL", "text": "Once the task is specified we can decide on the best representation for the operative agents that will explore the state space of the problem. Clearly, an appropriate representation for searching NK landscapes is to portray those agents as binary strings, and so henceforth we will use the terms agent and string interchangeably. The agents are organized on a star topology and can interact only with a central agent \u2013 the monitor \u2013 that does not search the state space but simply surveys and displays the best performing string at a given moment. Figure 1 illustrates the topology of the communication network used in the computational experiments.\nThe L peripheral strings are initialized randomly with equal probability for the bits 0 and 1 and the central node displays the fittest string produced in this random setup. The search begins with the selection of one of the peripheral agents at random \u2013 the target agent. This agent can choose between two distinct processes to move on the state space.\nThe first process, which happens with probability p, is the copy of a single bit of the string displayed by the monitor. The copy procedure is implemented as follows. First, the monitor string and the target string are compared and the different bits are singled out. Then one of the distinct bits of the target string is selected at random and flipped, so this bit is now the same in both strings. The second process, which happens with probability 1\u2212p, is the elementary move in the state space, which consists of picking a bit at random from the target string and\nflipping it. This elementary move allows the agents to explore in an incremental way the 2N -dimensional state space. In the case the target string is identical to the monitor string (i.e., the fittest string in the network at that time), the target agent flips a randomly chosen bit with probability one.\nAfter the target agent is updated, we increment the time t by the quantity \u2206t = 1/L. Since a string operation always results in a change of fitness, we need to recalculate the best string and, in case of change, update the display of the central node. Then another target agent is selected at random and the procedure described above is repeated. Note that during the increment from t to t + 1 exactly L, not necessarily distinct, peripheral strings are updated.\nThe search ends when one of the agents hits the global maximum and we denote by t\u2217 the halting time. The efficiency of the search is measured by the total number of peripheral string updates necessary to find that maximum, i.e., Lt\u2217 [16, 17] and so the computational cost of a search is defined as C \u2261 Lt\u2217/2N , where for convenience we have rescaled t\u2217 by the size of the state space 2N .\nThe parameter p measures the frequency or strength of the feedback from the monitor (inner eye) to the peripheral operative agents. We note that the peripheral agents are not programmed to solve any task: they just flip bits at random and occasionally copy a bit from the string displayed in the central node. Only the central agent is capable to evaluate the goodness of the solutions. But it is not allowed to search the state space itself; its role is simply to evaluate and display the solutions found by the peripheral agents. This approach is akin to the ActorCritic model of reinforcement learning [18], in which one part of the program \u2013 the Actor \u2013 chooses the action to perform and the other part \u2013 the Critic \u2013 indicates how good this action was. The case p = 0 corresponds to the baseline situation in which the peripheral agents do not receive any feedback from the central agent, which, however, still evaluates the goodness of the solutions and halts the search when the global maximum is found.\nOur model may be viewed as a simple reinterpretation of the well-studied model of distributed cooperative problem-solving systems based on imitative learning [19\u2013 21]. In fact, the scenario presented above is identical to the situation where there is no central agent but each peripheral agent is linked to all others and can imitate the best agent in the network with probability p. In that imitative learning scenario, any agent is able to search the state space and evaluate the quality of its solution as well as those of the other agents in the network. The advantage of the present interpretation is that only one special agent is endowed with the ability to evaluate the quality of the solutions, which is clearly a very sophisticated process that should be kept separated from the more mechanical state space search. Following the social brain reasoning line, the organisms have probably first evolved variants of this evaluative process to access their external environment, which includes the other or-\n4 ganisms, and then modified those processes for internal evaluation. In the present interpretation, the system exhibited in Fig. 1 is a module of the cognitive system of a single organism, whereas in the imitative learning scenario each agent is seen as an independent organism."}, {"heading": "IV. RESULTS", "text": "As a measure of the performance of the system in searching for the global maximum of the NK landscapes, we consider the mean computational cost \u3008C\u3009, which is obtained by averaging the computational cost over 105 distinct searches for each landscape realization, and the result is then averaged over 100 landscape realizations. In addition to this performance measure, we carry out diverse measurements to get insight on the diversity of the strings at the halting time t\u2217. In particular, defining the normalized Hamming distance between the bit strings x\u03b1 and x\u03b2 as\nd ( x\u03b1,x\u03b2 ) = 1\n2 \u2212 1 2N N\u2211 i=1 (1\u2212 2x\u03b1i ) ( 1\u2212 2x\u03b2i ) , (2)\nwe can introduce the mean pairwise distance between the L strings in the system,\nd\u0304 = 2\nL (L\u2212 1) L\u22121\u2211 \u03b1=1 L\u2211 \u03b2=\u03b1+1 d ( x\u03b1,x\u03b2 ) . (3)\nThis distance can be interpreted as follows: if we pick two strings at random, they will differ by Nd\u0304 bits on average. Hence d\u0304 yields a measure of the dispersion of the strings in the state space. The distance d\u0304 must also be averaged over the independent searches and landscape realizations, resulting in the measure \u3008d\u0304\u3009.\nWe note that many applications of social heuristics to solve combinatorial problems (see, e.g., [16, 17, 22, 23]) resort to circuitous representations for the agents as well as for their moves on the state space, making it difficult to gauge the complexity, or lack thereof, of the tasks solved by those heuristics. The advantage of using NK landscapes is that we can control the difficulty of the tasks and, accordingly, in Fig. 2 we show the mean computational cost for tasks of different complexities.\nIn the case of single-maximum landscapes (K = 0), copying the fittest string displayed by the central node is an optimal strategy since it guarantees, on the average, a move towards the maximum. This is the reason that for a fixed system size L the best performance is achieved for p = 1. However, the regime of small p is probably the more relevant since one expects that the feedback between the monitor and the operative agents should happen much less frequently than the motion in the state space.\nThe presence of local maxima (K > 0) makes copying the central node string a risky strategy since that string may display misleading information about the location of\n0.003\n0.01\n0.1\n1\n2\n0 0.2 0.4 0.6 0.8 1\n< C\n>\np\nFIG. 2. (Color online) Mean computational cost \u3008C\u3009 as function of the strength p of the feedback between the monitor and the operative agents for the system size L = 20 and (bottom to top) K = 0, 1, 3 and 5. The length of the bit strings is N = 16. Note the logarithmic scale of the axis of ordinates.\nthe global maximum. In fact, the disastrous performance observed for large p is caused by the trapping in the local maxima, from which escape can be extremely costly. The culprit of the bad performance is a groupthink-like phenomenon, which occurs when people put unlimited faith in a leader and so everyone in the group starts thinking alike [24]. Interestingly, the results of Fig. 2 shows that for K > 0 there is a value p = popt that minimizes the computational cost and is practically unaffected by the complexity of the task. However, as we will see in the following, popt decreases with increasing L and increases with increasing N .\nFigure 3 offers a view of the distribution of strings in the state space at the moment t = t\u2217 that the global maximum is found. For a fixed task complexity (i.e., for a fixed K), the mean pairwise Hamming distance \u3008d\u0304\u3009\n5 is a monotonically decreasing function of p, so that the strings become more similar to each other as p increases, as expected. In addition, for K > 0 this function has an inflection point at p \u2248 popt. Somewhat surprisingly, these results show that for p < popt the spreading of the strings in the state space is greater in the case of difficult tasks, which is clearly a good strategy to circumvent the local maxima. This behavior is reversed in the region where the computational cost is extremely high, indicating that a large number of strings are close to the local maxima when the global maximum is found. We know that because we have measured also the mean Hamming distance to the global maximum and found that this distance is greater than the typical distance between two strings.\nTo look at the effect of the state space size N on the performance of the system it is convenient to vary K as well so as to keep the local fitness correlation of the landscapes unchanged. Figure 4 shows the mean computational cost for three families of NK landscapes with local fitness correlation equal to 3/4 for a fixed system size. Since variation of K does not affect the value of the optimal feedback strength (see Fig. 2), the change of popt observed in the figure is due to the variation of the parameter N . The finding that popt, as well as the quality of the optimal computational cost, increases with the size of the problem space indicates that the trapping effect of the local maxima is due to the density of those maxima and not to their absolute number (see Table I). We note that the case p = 0 can be solved analytically (see [20]) and the reason that for fixed L 2N the computational cost decreases with N is that the chance of reverting spin flips (and hence wasting moves) decreases as the length of the strings increases. Only in the limit N \u2192 \u221e the probability of reverting flips is zero, so that \u3008C\u3009 = 1 in\nthat limit.\n0\n0.4\n0.8\n1.2\n1.6\n2\n0 0.2 0.4 0.6 0.8\n< C\n>\np\nFIG. 5. (Color online) Mean computational cost \u3008C\u3009 as function of the strength p of the feedback between the monitor and the operative agents for different system sizes (top to bottom at p = 0.2) L = 10, 20, 40 and 80. The parameters of the rugged NK landscape are N = 16 and K = 3.\nIn order to offer the reader a complete view of the behavior of the system, in Fig. 5 we show the computational cost for different system sizes L. The results show that the optimal feedback popt decreases with increasing L but the quality of the optimal cost is not very sensitive to the system size. This figure reveals also the nontrivial interplay between the system size L and the feedback strength p. In fact, for each p there is an optimal system size that minimizes the computational cost [20]. This optimal size decreases from infinity for p\u2192 0 to L = 2 for p = 1.\nFinally, we note that since finding the global maxima of NK landscapes with K > 0 is an NP-Complete problem [15], one should not expect that the imitative search (or any other search strategy, for that matter) would find those maxima much more rapidly than the independent search for a large sample of landscape realizations as that considered here."}, {"heading": "V. DISCUSSION", "text": "Theories of consciousness are typically expressed verbally and stated in somewhat vague and general terms even by the standards of philosophical theories. For instance, many notorious thought experiments of the field (e.g., Mary\u2019s room [25] and the philosopher\u2019s zombie [26]) have multiple interpretations because their specifications are unclear [27] and even the so-called \u2018hard problem\u2019 of consciousness (i.e., how physical processes in the brain give rise to subjective experience [26]) is viewed by some researchers as a hornswoggle problem [28] and a major misdirection of attention [29].\nPerhaps what is missing is an effort to express theories of consciousness, or at least some of their premises, as computer programs [30]. This would require a complete and detailed specification of all assumptions, otherwise\n6 the program would not run in the computer [31]. (Of course, this research program does not apply to those theories that are built on the premise of the impossibility of such a computer simulation.) With very few exceptions (see, e.g., [32]) computer simulations and mathematical models have greatly aided the elucidation of nonintuitive issues on Evolutionary Biology [33], and we see no intrinsic reason that could prevent the use of those tools to verify assumptions and predictions of theories of consciousness, particularly of those theories that grant a selective value to consciousness.\nIn this paper we explore a key element of the theories that view consciousness as a schematic description of the brain\u2019s states, namely, the existence of inner-eye-like processes that monitor those states and provide feedback on their suitability to the attainment of the organism\u2019s goals [2, 10]. We use a cartoonish model of this scenario, in which a group of operative agents search blindly for the global maximum of a fitness landscape and a monitor provides them with feedback on the quality (fitness) of the proposed solutions. This feedback is then used by the operative agents to bias their searches towards the (hopefully) fittest regions of the landscape. We interpret this self-monitoring as the awareness of the system about the computation it is carrying out.\nWe find that a weak feedback between the monitor and the operative agents improves the performance of the system, regardless of the difficulty of the task, which\nis gauged by the number of local maxima in the landscape. In the case of easy tasks (i.e., landscapes without local maxima), the performance improves monotonically as the feedback strength increases, but for difficult tasks too much feedback leads to a disastrous performance (see Fig. 2). Of course, one expects that the value of the feedback strength, which measures the influence of the innereye process on the low-level cognitive processes, will be determined by natural selection and so it is likely to be set to an optimal value that guarantees the maximization of the system performance.\nIn closing, our findings suggest that the inner-monitoring of the system behavior (computations, in our case), which is a key element in some theories of consciousness [2, 10], results in an improved general problem-solving capacity. However, if a system that, in the words of Dennett [27], \u201c... monitors its own activities, including even its own internal activities, in an indefinite upward spiral of reflexivity\u201d can be said to be conscious is an issue that is best left to the philosophers,"}, {"heading": "ACKNOWLEDGMENTS", "text": "The research of JFF was supported in part by grant 15/21689-2, Sa\u0303o Paulo Research Foundation (FAPESP) and by grant 303979/2013-5, Conselho Nacional de Desenvolvimento Cient\u0301\u0131fico e Tecnolo\u0301gico (CNPq).\n[1] Blackmore, S., 2003. Consciousness: An Introduction. Oxford University Press, Oxford. [2] Humphrey, N., 1999. A History of the Mind: Evolution and the Birth of Consciousness. Copernicus Press, New York. [3] Jaynes, J., 1976. The origin of consciousness in the breakdown of the bicameral mind. Houghton Mifflin, Boston. [4] Frith, C., 1995. Consciousness is for other people. Behav. Brain. Sci. 18, 682\u2013683. [5] Perlovsky, L., 2006. Toward physics of the mind: Concepts, emotions, consciousness, and symbols. Phys. Life Rev. 3, 23\u201355. [6] Carruthers, P., 2009. How we know our own minds: the relationship between mindreading and metacognition. Behav. Brain. Sci. 32, 121\u2013138. [7] Baumeister, R.F., Masicampo, E.J., 2010. Conscious thought is for facilitating social and cultural interactions: how mental simulations serve the animal-culture interface. Psychol. Rev. 117, 945\u2013971. [8] Vygotsky, L.S., 1986. Thought and Language. The MIT Press, Cambridge, MA. [9] Graziano, M., Kastner, S., 2011. Human consciousness and its relationship to social neuroscience: A novel hypothesis. Cogn. Neurosci. 2, 98\u2013113. [10] Graziano, M., 2013. Consciousness and the Social Brain. Oxford University Press, Oxford, UK. [11] Murphy, R.R., 2000. Introduction to AI Robotics. MIT Press, Cambridge, MA.\n[12] Kauffman, S.A., Levin, S., 1987. Towards a general theory of adaptive walks on rugged landscapes. J. Theor. Biol. 128, 11\u201345. [13] Derrida, B., 1981. Random-energy Model: An Exactly Solvable Model of Disordered Systems. Phys. Rev. B 24, 2613\u20132626. [14] Saakian, D.B., Fontanari, J.F., 2009. Evolutionary dynamics on rugged fitness landscapes: exact dynamics and information theoretical aspects, Phys. Rev. E 80, 041903. [15] Solow, D., Burnetas, A., Tsai, M., Greenspan, N.S., 2000. On the Expected Performance of Systems with Complex Interactions Among Components. Complex Systems 12, 423\u2013456. [16] Clearwater, S.H., Huberman, B.A., Hogg, T., 1991. Cooperative Solution of Constraint Satisfaction Problems. Science 254, 1181\u20131183. [17] Clearwater, S.H., Hogg, T., Huberman, B.A., 1992. Cooperative Problem Solving. In: Huberman, B.A. (Ed.), Computation: The Micro and the Macro View. World Scientific, Singapore, pp. 33\u201370. [18] Barto, A.G., 1995. Adaptive critic and the basal ganglia. In: Houk, J.C., Davis, J.L., Beiser D.G. (Eds.), Models of information processing in the basal ganglia. MIT Press, Cambridge, pp. 215 \u2013232. [19] Fontanari, J.F., 2014. Imitative Learning as a Connector of Collective Brains. PLoS ONE 9, e110517. [20] Fontanari, J.F., 2015. Exploring NK Fitness Landscapes Using Imitative Learning. Eur. Phys. J. B 88, 251.\n7 [21] Fontanari, J.F., 2016. When more of the same is better. EPL 113, 28009. [22] Kennedy, J., 1998. Thinking is social: Experiments with the adaptive culture model. J. Conflict Res. 42, 56\u201376. [23] Fontanari, J.F., 2010. Social interaction as a heuristic for combinatorial optimization problems. Phys. Rev. E 82, 056118. [24] Janis, I.L., 1982. Groupthink: psychological studies of policy decisions and fiascoes. Houghton Mifflin, Boston. [25] Jackson, F., 1982. Epiphenomenal Qualia. Phil. Q. 32, 127\u2013136. [26] Chalmers, D., 1996. The Conscious Mind: In Search of a Fundamental Theory. Oxford University Press, Oxford. [27] Dennett, D.C., 1991. Consciousness Explained. Little, Brown and Company, Boston. [28] Churchland, P.S., 1996. The Hornswoggle problem. J. Conscious. Stud. 3, 402\u2013408. [29] Dennett, D.C., 1996. Facing backwards on the problem of consciousness. J. Conscious. Stud. 3, 4\u20136. [30] Perlovsky, L., 2001. Neural Networks and Intellect: Using Model-Based Concepts. Oxford University Press, Oxford. [31] Cangelosi, A., Parisi, D., 2002. Computer Simulation: A New Scientific Approach to the Study of Language Evolution. In: Cangelosi, A., Parisi, D. (Eds.), Simulating the Evolution of Language. Springer, London, pp. 3\u201328. [32] Santos, M., Szathma\u0301ry, E., Fontanari, J.F., 2015. Phenotypic Plasticity, the Baldwin Effect, and the Speeding up of Evolution: the Computational Roots of an Illusion. J. Theor. Biol. 371, 127\u2013136. [33] Dawkins, R., 1986. The Blind Watchmaker. Oxford University Press, Oxford."}], "references": [{"title": "Consciousness: An Introduction", "author": ["S. Blackmore"], "venue": null, "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2003}, {"title": "A History of the Mind: Evolution and the Birth of Consciousness", "author": ["N. Humphrey"], "venue": null, "citeRegEx": "2", "shortCiteRegEx": "2", "year": 1999}, {"title": "The origin of consciousness in the breakdown of the bicameral mind", "author": ["J. Jaynes"], "venue": null, "citeRegEx": "3", "shortCiteRegEx": "3", "year": 1976}, {"title": "Consciousness is for other people", "author": ["C. Frith"], "venue": "Behav. Brain. Sci", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 1995}, {"title": "Toward physics of the mind: Concepts, emotions, consciousness, and symbols", "author": ["L. Perlovsky"], "venue": "Phys. Life Rev", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2006}, {"title": "How we know our own minds: the relationship between mindreading and metacognition", "author": ["P. Carruthers"], "venue": "Behav. Brain. Sci", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2009}, {"title": "Conscious thought is for facilitating social and cultural interactions: how mental simulations serve the animal-culture", "author": ["R.F. Baumeister", "E.J. Masicampo"], "venue": "interface. Psychol", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2010}, {"title": "Thought and Language", "author": ["L.S. Vygotsky"], "venue": null, "citeRegEx": "8", "shortCiteRegEx": "8", "year": 1986}, {"title": "Human consciousness and its relationship to social neuroscience: A novel hypothesis", "author": ["M. Graziano", "S. Kastner"], "venue": "Cogn. Neurosci", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2011}, {"title": "Consciousness and the Social Brain", "author": ["M. Graziano"], "venue": null, "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2013}, {"title": "Introduction to AI Robotics", "author": ["R.R. Murphy"], "venue": null, "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2000}, {"title": "Towards a general theory of adaptive walks on rugged landscapes", "author": ["S.A. Kauffman", "S. Levin"], "venue": "J. Theor. Biol", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 1987}, {"title": "Random-energy Model: An Exactly Solvable Model of Disordered Systems", "author": ["B. Derrida"], "venue": "Phys. Rev. B", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 1981}, {"title": "Evolutionary dynamics on rugged fitness landscapes: exact dynamics and information theoretical aspects", "author": ["D.B. Saakian", "J.F. Fontanari"], "venue": "Phys. Rev. E", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2009}, {"title": "On the Expected Performance of Systems with Complex Interactions Among Components", "author": ["D. Solow", "A. Burnetas", "M. Tsai", "N.S. Greenspan"], "venue": "Complex Systems", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2000}, {"title": "Cooperative Solution of Constraint Satisfaction Problems", "author": ["S.H. Clearwater", "B.A. Huberman", "T. Hogg"], "venue": "Science", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 1991}, {"title": "Cooperative Problem Solving", "author": ["S.H. Clearwater", "T. Hogg", "B.A. Huberman"], "venue": "Computation: The Micro and the Macro View. World Scientific,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 1992}, {"title": "Adaptive critic and the basal ganglia", "author": ["A.G. Barto"], "venue": null, "citeRegEx": "18", "shortCiteRegEx": "18", "year": 1995}, {"title": "Imitative Learning as a Connector of Collective Brains", "author": ["J.F. Fontanari"], "venue": "PLoS ONE 9,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2014}, {"title": "Exploring NK Fitness Landscapes Using Imitative Learning", "author": ["J.F. Fontanari"], "venue": "Eur. Phys. J. B", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2015}, {"title": "Thinking is social: Experiments with the adaptive culture model", "author": ["J. Kennedy"], "venue": "J. Conflict Res", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 1998}, {"title": "Social interaction as a heuristic for combinatorial optimization problems", "author": ["J.F. Fontanari"], "venue": "Phys. Rev. E", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2010}, {"title": "Groupthink: psychological studies of policy decisions and fiascoes", "author": ["I.L. Janis"], "venue": null, "citeRegEx": "24", "shortCiteRegEx": "24", "year": 1982}, {"title": "The Conscious Mind: In Search of a Fundamental Theory", "author": ["D. Chalmers"], "venue": null, "citeRegEx": "26", "shortCiteRegEx": "26", "year": 1996}, {"title": "Consciousness Explained", "author": ["D.C. Dennett"], "venue": null, "citeRegEx": "27", "shortCiteRegEx": "27", "year": 1991}, {"title": "The Hornswoggle problem", "author": ["P.S. Churchland"], "venue": "J. Conscious. Stud", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 1996}, {"title": "Facing backwards on the problem of consciousness", "author": ["D.C. Dennett"], "venue": "J. Conscious. Stud", "citeRegEx": "29", "shortCiteRegEx": "29", "year": 1996}, {"title": "Neural Networks and Intellect: Using Model-Based Concepts", "author": ["L. Perlovsky"], "venue": null, "citeRegEx": "30", "shortCiteRegEx": "30", "year": 2001}, {"title": "Computer Simulation: A New Scientific Approach to the Study of Language Evolution", "author": ["A. Cangelosi", "D. Parisi"], "venue": null, "citeRegEx": "31", "shortCiteRegEx": "31", "year": 2002}, {"title": "Phenotypic Plasticity, the Baldwin Effect, and the Speeding up of Evolution: the Computational Roots of an Illusion", "author": ["M. Santos", "E. Szathm\u00e1ry", "J.F. Fontanari"], "venue": "J. Theor. Biol", "citeRegEx": "32", "shortCiteRegEx": "32", "year": 2015}, {"title": "The Blind Watchmaker", "author": ["R. Dawkins"], "venue": null, "citeRegEx": "33", "shortCiteRegEx": "33", "year": 1986}], "referenceMentions": [{"referenceID": 0, "context": "What is consciousness for? From a biological perspective, an auspicious answer to this mind-opening question (see [1] for a thorough discussion of the theories of consciousness) views consciousness as a source of information about brain states \u2013 a brain\u2019s schematic description of those states \u2013 and suggests that the evolutionary usefulness of such inner eye is to provide human beings with an effective tool for doing natural psychology, i.", "startOffset": 114, "endOffset": 117}, {"referenceID": 1, "context": ", for imagining what might be happening inside another person\u2019s head [2].", "startOffset": 69, "endOffset": 72}, {"referenceID": 1, "context": "Hence, the conception of other people as beings with minds originates from the way each individual sees himself and, in that sense, solely extraordinarily social creatures, probably humans only, would evolve consciousness as a response to the pressures to handle interpersonal relationships [2].", "startOffset": 291, "endOffset": 294}, {"referenceID": 2, "context": "There is an alternative, equally attractive, possibility that we may first unconsciously suppose other consciousness, and then infer our own by generalization [3].", "startOffset": 159, "endOffset": 162}, {"referenceID": 3, "context": ", [4\u20137]), but the original insight that consciousness and cognition are products of social behaviors probably dates back to Vygostsky in the 1930s [8].", "startOffset": 2, "endOffset": 7}, {"referenceID": 4, "context": ", [4\u20137]), but the original insight that consciousness and cognition are products of social behaviors probably dates back to Vygostsky in the 1930s [8].", "startOffset": 2, "endOffset": 7}, {"referenceID": 5, "context": ", [4\u20137]), but the original insight that consciousness and cognition are products of social behaviors probably dates back to Vygostsky in the 1930s [8].", "startOffset": 2, "endOffset": 7}, {"referenceID": 6, "context": ", [4\u20137]), but the original insight that consciousness and cognition are products of social behaviors probably dates back to Vygostsky in the 1930s [8].", "startOffset": 2, "endOffset": 7}, {"referenceID": 7, "context": ", [4\u20137]), but the original insight that consciousness and cognition are products of social behaviors probably dates back to Vygostsky in the 1930s [8].", "startOffset": 147, "endOffset": 150}, {"referenceID": 8, "context": "Fortunately, the recently proposed attention schema theory of consciousness [9, 10] offers some hope to our engineer by positing that awareness is simply a schematic model of one\u2019s state of attention, i.", "startOffset": 76, "endOffset": 83}, {"referenceID": 9, "context": "Fortunately, the recently proposed attention schema theory of consciousness [9, 10] offers some hope to our engineer by positing that awareness is simply a schematic model of one\u2019s state of attention, i.", "startOffset": 76, "endOffset": 83}, {"referenceID": 2, "context": "(The intimate connection between awareness and consciousness is expressed best by the view that consciousness is simply the awareness of what we have done or said, reflected back to us [3].", "startOffset": 185, "endOffset": 188}, {"referenceID": 10, "context": ") Building a functioning attention schema is a feasible software project today, which could then be coupled to the existing perceptual schemas [11] to create a conscious machine.", "startOffset": 143, "endOffset": 147}, {"referenceID": 9, "context": "e, of doing natural psychology [10].", "startOffset": 31, "endOffset": 35}, {"referenceID": 9, "context": "This feedback can be thought of as the mechanism by which \u2018mind\u2019 influences matter [10].", "startOffset": 83, "endOffset": 87}, {"referenceID": 0, "context": "(Since we may want to compare performances for different values of L, the actual performance measure must be properly scaled by L, as discussed in Section III) The relevant comparison is between the case p = 0 where the monitor has no effect on the operation of the system (a scenario akin to the doctrine of epiphenomenalism [1]), and the case p > 0 where the system receives feedback from the monitor.", "startOffset": 326, "endOffset": 329}, {"referenceID": 11, "context": "Since the tasks of varying complexity presented to the problemsolving system are finding the global maxima of rugged fitness landscapes generated by the NK model, in Section II we offer an outline of that classic model [12].", "startOffset": 219, "endOffset": 223}, {"referenceID": 11, "context": "The task posed to a system of L agents is to find the unique global maximum of a fitness landscape generated using the NK model [12].", "startOffset": 128, "endOffset": 132}, {"referenceID": 0, "context": "For each bit string x is assigned a distinct real-valued fitness value \u03a6 (x) \u2208 [0, 1] which is an average of the contributions from each element i of the string, i.", "startOffset": 79, "endOffset": 85}, {"referenceID": 11, "context": "distributed random number in the unit interval so that \u03a6 \u2208 (0, 1) has a unique global maximum [12].", "startOffset": 94, "endOffset": 98}, {"referenceID": 12, "context": "Hence for K = N\u22121 the fitness values are uncorrelated and the NK model reduces to the Random Energy model [13, 14].", "startOffset": 106, "endOffset": 114}, {"referenceID": 13, "context": "Hence for K = N\u22121 the fitness values are uncorrelated and the NK model reduces to the Random Energy model [13, 14].", "startOffset": 106, "endOffset": 114}, {"referenceID": 14, "context": "Finding the global maximum of the NK model for K > 0 is an NP-complete problem [15], which means that the time required to solve all realizations of that landscape using any currently known deterministic algorithm increases exponentially fast with the length N of the strings.", "startOffset": 79, "endOffset": 83}, {"referenceID": 15, "context": ", Lt\u2217 [16, 17] and so the computational cost of a search is defined as C \u2261 Lt\u2217/2N , where for convenience we have rescaled t\u2217 by the size of the state space 2 .", "startOffset": 6, "endOffset": 14}, {"referenceID": 16, "context": ", Lt\u2217 [16, 17] and so the computational cost of a search is defined as C \u2261 Lt\u2217/2N , where for convenience we have rescaled t\u2217 by the size of the state space 2 .", "startOffset": 6, "endOffset": 14}, {"referenceID": 17, "context": "This approach is akin to the ActorCritic model of reinforcement learning [18], in which one part of the program \u2013 the Actor \u2013 chooses the action to perform and the other part \u2013 the Critic \u2013 indicates how good this action was.", "startOffset": 73, "endOffset": 77}, {"referenceID": 15, "context": ", [16, 17, 22, 23]) resort to circuitous representations for the agents as well as for their moves on the state space, making it difficult to gauge the complexity, or lack thereof, of the tasks solved by those heuristics.", "startOffset": 2, "endOffset": 18}, {"referenceID": 16, "context": ", [16, 17, 22, 23]) resort to circuitous representations for the agents as well as for their moves on the state space, making it difficult to gauge the complexity, or lack thereof, of the tasks solved by those heuristics.", "startOffset": 2, "endOffset": 18}, {"referenceID": 20, "context": ", [16, 17, 22, 23]) resort to circuitous representations for the agents as well as for their moves on the state space, making it difficult to gauge the complexity, or lack thereof, of the tasks solved by those heuristics.", "startOffset": 2, "endOffset": 18}, {"referenceID": 21, "context": ", [16, 17, 22, 23]) resort to circuitous representations for the agents as well as for their moves on the state space, making it difficult to gauge the complexity, or lack thereof, of the tasks solved by those heuristics.", "startOffset": 2, "endOffset": 18}, {"referenceID": 22, "context": "The culprit of the bad performance is a groupthink-like phenomenon, which occurs when people put unlimited faith in a leader and so everyone in the group starts thinking alike [24].", "startOffset": 176, "endOffset": 180}, {"referenceID": 19, "context": "We note that the case p = 0 can be solved analytically (see [20]) and the reason that for fixed L 2 the computational cost decreases with N is that the chance of reverting spin flips (and hence wasting moves) decreases as the length of the strings increases.", "startOffset": 60, "endOffset": 64}, {"referenceID": 19, "context": "In fact, for each p there is an optimal system size that minimizes the computational cost [20].", "startOffset": 90, "endOffset": 94}, {"referenceID": 14, "context": "Finally, we note that since finding the global maxima of NK landscapes with K > 0 is an NP-Complete problem [15], one should not expect that the imitative search (or any other search strategy, for that matter) would find those maxima much more rapidly than the independent search for a large sample of landscape realizations as that considered here.", "startOffset": 108, "endOffset": 112}, {"referenceID": 23, "context": ", Mary\u2019s room [25] and the philosopher\u2019s zombie [26]) have multiple interpretations because their specifications are unclear [27] and even the so-called \u2018hard problem\u2019 of consciousness (i.", "startOffset": 48, "endOffset": 52}, {"referenceID": 24, "context": ", Mary\u2019s room [25] and the philosopher\u2019s zombie [26]) have multiple interpretations because their specifications are unclear [27] and even the so-called \u2018hard problem\u2019 of consciousness (i.", "startOffset": 125, "endOffset": 129}, {"referenceID": 23, "context": ", how physical processes in the brain give rise to subjective experience [26]) is viewed by some researchers as a hornswoggle problem [28] and a major misdirection of attention [29].", "startOffset": 73, "endOffset": 77}, {"referenceID": 25, "context": ", how physical processes in the brain give rise to subjective experience [26]) is viewed by some researchers as a hornswoggle problem [28] and a major misdirection of attention [29].", "startOffset": 134, "endOffset": 138}, {"referenceID": 26, "context": ", how physical processes in the brain give rise to subjective experience [26]) is viewed by some researchers as a hornswoggle problem [28] and a major misdirection of attention [29].", "startOffset": 177, "endOffset": 181}, {"referenceID": 27, "context": "Perhaps what is missing is an effort to express theories of consciousness, or at least some of their premises, as computer programs [30].", "startOffset": 132, "endOffset": 136}, {"referenceID": 28, "context": "the program would not run in the computer [31].", "startOffset": 42, "endOffset": 46}, {"referenceID": 29, "context": ", [32]) computer simulations and mathematical models have greatly aided the elucidation of nonintuitive issues on Evolutionary Biology [33], and we see no intrinsic reason that could prevent the use of those tools to verify assumptions and predictions of theories of consciousness, particularly of those theories that grant a selective value to consciousness.", "startOffset": 2, "endOffset": 6}, {"referenceID": 30, "context": ", [32]) computer simulations and mathematical models have greatly aided the elucidation of nonintuitive issues on Evolutionary Biology [33], and we see no intrinsic reason that could prevent the use of those tools to verify assumptions and predictions of theories of consciousness, particularly of those theories that grant a selective value to consciousness.", "startOffset": 135, "endOffset": 139}, {"referenceID": 1, "context": "In this paper we explore a key element of the theories that view consciousness as a schematic description of the brain\u2019s states, namely, the existence of inner-eye-like processes that monitor those states and provide feedback on their suitability to the attainment of the organism\u2019s goals [2, 10].", "startOffset": 289, "endOffset": 296}, {"referenceID": 9, "context": "In this paper we explore a key element of the theories that view consciousness as a schematic description of the brain\u2019s states, namely, the existence of inner-eye-like processes that monitor those states and provide feedback on their suitability to the attainment of the organism\u2019s goals [2, 10].", "startOffset": 289, "endOffset": 296}, {"referenceID": 1, "context": "In closing, our findings suggest that the inner-monitoring of the system behavior (computations, in our case), which is a key element in some theories of consciousness [2, 10], results in an improved general problem-solving capacity.", "startOffset": 168, "endOffset": 175}, {"referenceID": 9, "context": "In closing, our findings suggest that the inner-monitoring of the system behavior (computations, in our case), which is a key element in some theories of consciousness [2, 10], results in an improved general problem-solving capacity.", "startOffset": 168, "endOffset": 175}, {"referenceID": 24, "context": "However, if a system that, in the words of Dennett [27], \u201c.", "startOffset": 51, "endOffset": 55}, {"referenceID": 0, "context": "[1] Blackmore, S.", "startOffset": 0, "endOffset": 3}, {"referenceID": 1, "context": "[2] Humphrey, N.", "startOffset": 0, "endOffset": 3}, {"referenceID": 2, "context": "[3] Jaynes, J.", "startOffset": 0, "endOffset": 3}, {"referenceID": 3, "context": "[4] Frith, C.", "startOffset": 0, "endOffset": 3}, {"referenceID": 4, "context": "[5] Perlovsky, L.", "startOffset": 0, "endOffset": 3}, {"referenceID": 5, "context": "[6] Carruthers, P.", "startOffset": 0, "endOffset": 3}, {"referenceID": 6, "context": "[7] Baumeister, R.", "startOffset": 0, "endOffset": 3}, {"referenceID": 7, "context": "[8] Vygotsky, L.", "startOffset": 0, "endOffset": 3}, {"referenceID": 8, "context": "[9] Graziano, M.", "startOffset": 0, "endOffset": 3}, {"referenceID": 9, "context": "[10] Graziano, M.", "startOffset": 0, "endOffset": 4}, {"referenceID": 10, "context": "[11] Murphy, R.", "startOffset": 0, "endOffset": 4}, {"referenceID": 11, "context": "[12] Kauffman, S.", "startOffset": 0, "endOffset": 4}, {"referenceID": 12, "context": "[13] Derrida, B.", "startOffset": 0, "endOffset": 4}, {"referenceID": 13, "context": "[14] Saakian, D.", "startOffset": 0, "endOffset": 4}, {"referenceID": 14, "context": "[15] Solow, D.", "startOffset": 0, "endOffset": 4}, {"referenceID": 15, "context": "[16] Clearwater, S.", "startOffset": 0, "endOffset": 4}, {"referenceID": 16, "context": "[17] Clearwater, S.", "startOffset": 0, "endOffset": 4}, {"referenceID": 17, "context": "[18] Barto, A.", "startOffset": 0, "endOffset": 4}, {"referenceID": 18, "context": "[19] Fontanari, J.", "startOffset": 0, "endOffset": 4}, {"referenceID": 19, "context": "[20] Fontanari, J.", "startOffset": 0, "endOffset": 4}, {"referenceID": 20, "context": "[22] Kennedy, J.", "startOffset": 0, "endOffset": 4}, {"referenceID": 21, "context": "[23] Fontanari, J.", "startOffset": 0, "endOffset": 4}, {"referenceID": 22, "context": "[24] Janis, I.", "startOffset": 0, "endOffset": 4}, {"referenceID": 23, "context": "[26] Chalmers, D.", "startOffset": 0, "endOffset": 4}, {"referenceID": 24, "context": "[27] Dennett, D.", "startOffset": 0, "endOffset": 4}, {"referenceID": 25, "context": "[28] Churchland, P.", "startOffset": 0, "endOffset": 4}, {"referenceID": 26, "context": "[29] Dennett, D.", "startOffset": 0, "endOffset": 4}, {"referenceID": 27, "context": "[30] Perlovsky, L.", "startOffset": 0, "endOffset": 4}, {"referenceID": 28, "context": "[31] Cangelosi, A.", "startOffset": 0, "endOffset": 4}, {"referenceID": 29, "context": "[32] Santos, M.", "startOffset": 0, "endOffset": 4}, {"referenceID": 30, "context": "[33] Dawkins, R.", "startOffset": 0, "endOffset": 4}], "year": 2017, "abstractText": "The brain\u2019s self-monitoring of activities, including internal activities \u2013 a functionality that we refer to as awareness \u2013 has been suggested as a key element of consciousness. Here we investigate whether the presence of an inner-eye-like process (monitor) that supervises the activities of a number of subsystems (operative agents) engaged in the solution of a problem can improve the problemsolving efficiency of the system. The problem is to find the global maximum of a NK fitness landscape and the performance is measured by the time required to find that maximum. The operative agents explore blindly the fitness landscape and the monitor provides them with feedback on the quality (fitness) of the proposed solutions. This feedback is then used by the operative agents to bias their searches towards the fittest regions of the landscape. We find that a weak feedback between the monitor and the operative agents improves the performance of the system, regardless of the difficulty of the problem, which is gauged by the number of local maxima in the landscape. For easy problems (i.e., landscapes without local maxima), the performance improves monotonically as the feedback strength increases, but for difficult problems, there is an optimal value of the feedback strength beyond which the system performance degrades very rapidly.", "creator": "LaTeX with hyperref package"}}}