{"id": "1705.08992", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "24-May-2017", "title": "Matroids Hitting Sets and Unsupervised Dependency Grammar Induction", "abstract": "This paper formulates a novel problem on graphs: find the minimal subset of edges in a fully connected graph, such that the resulting graph contains all spanning trees for a set of specifed sub-graphs. This formulation is motivated by an un-supervised grammar induction problem from computational linguistics. We present a reduction to some known problems and algorithms from graph theory, provide computational complexity results, and describe an approximation algorithm. For this problem, the basic theorem of logarithm is that it does not specify the extent to which the solution may be applied in a graph. The result of a linear algebra is the extent to which one is able to represent an edge on the graph. In a graph, there is a linear algebra. For the graph, it represents the extent to which any edge is the edge in the graph. For the graph, the extent to which any edge is the edge in the graph.\n\n\n\nThe result of a linear algebra is the extent to which an edge is the edge in the graph. The extent to which the edge is a node or node is determined in the graph.\nFor a graph, the extent to which the edge is a node or node is determined in the graph. The extent to which the edge is a node or node is determined in the graph. The extent to which any edge is a node or node is determined in the graph.\nThe extent to which a node or node is determined in the graph. The extent to which a node or node is determined in the graph. The extent to which the edge is a node or node is determined in the graph. In the graph, a node or node is determined in the graph.\nThe extent to which a node or node is determined in the graph. The extent to which the edge is a node or node is determined in the graph. In the graph, a node or node is determined in the graph. In the graph, a node or node is determined in the graph. In the graph, a node or node is determined in the graph. In the graph, a node or node is determined in the graph. In the graph, a node or node is determined in the graph. In the graph, a node or node is determined in the graph. In the graph, a node or node is determined in the graph. In the graph, a node or node is determined in the graph. In the graph, a node or node is determined in the graph. In the graph, a node or node is determined in the", "histories": [["v1", "Wed, 24 May 2017 22:53:56 GMT  (62kb,D)", "https://arxiv.org/abs/1705.08992v1", null], ["v2", "Sat, 15 Jul 2017 20:24:11 GMT  (62kb,D)", "http://arxiv.org/abs/1705.08992v2", "11 pages 4 figures"]], "reviews": [], "SUBJECTS": "cs.DM cs.CL cs.DS", "authors": ["nicholas harvey", "vahab mirrokni", "david karger", "virginia savova", "leonid peshkin"], "accepted": false, "id": "1705.08992"}, "pdf": {"name": "1705.08992.pdf", "metadata": {"source": "CRF", "title": "Matroids Hitting Sets and Unsupervised Dependency Grammar Induction", "authors": ["Nicholas Harvey", "David Karger", "Vahab Mirrokni", "Virginia Savova", "Leonid Peshkin"], "emails": ["peshkin@gmail.com"], "sections": [{"heading": "1 Introduction", "text": "Linguistic representations of natural language syntax arrange syntactic dependencies among the words in a sentence into a tree structure, of which the string is a one dimensional projection. We are concerned with the task of analyzing a set of several sentences, looking for the most parsimonious set of corresponding syntactic structures, solely on the basis of co-occurrence of words in sentences. We proceed by first presenting an example, then providing a general formulation of dependency structure and grammar induction.\nConsider a sentence \u201dHer immediate predecessor suffered a nervous breakdown.\u201d A dependency grammar representation of this sentence shown in Figure 1 captures dependency between the subject, the object and the verb, as well as dependency between the determiner and the adjectives and their respective nouns. In this sentence, the subject predecessor and the object breakdown are related to the verb\nIn a dependency tree, each word is the mother of its dependents, otherwise known as their HEAD. To linearize the dependency tree in Figure 2.left into a string, we introduce the dependents recursively next to their heads: iteration 1: suffered iteration 2: predecessor suffered breakdown iteration 3: her predecessor suffered a breakdown.\nDependency and the related link grammars have received a lot of attention in the field of computational linguistics in recent years, since these grammars enable much easier parsing than alternatives that are more complex lexicalized parse structures. There are applications to such popular tasks as machine translation and information retrieval. However, all of the work is concerned with parsing, i.e. inducing a parse structure given a corpus and a grammar, rather than with grammar induction. Some work is concerned with inducing parameters of the grammar from annotated corpora, for example see work by Eisner on dependency parsing [1] or more recent work by McDonald et al. [5] and references therein. It has been pointed out [5] that parsing with dependency grammars is related to Minimal Spanning Tree algorithms in general and in particular Chu-Liu-Edmonds MST algorithm was applied to dependency parsing.\nAn established computational linguistics textbook has the following to say on the subject [3]: \u201d... doing grammar induction from scratch is still a difficult, largely unsolved problem, and hence much emphasis has been placed on learning from bracketed corpora.\u201d If grammar is not provided to begin with, parsing has to be done concurrently with learning the grammar. In the presence of grammar, among all the possibilities one needs to pick a syntactic structure consistent with the grammar. In the absence of grammar, it makes sense to appeal to Occam\u2019s razor principle and look for the minimal set of dependencies which are consistent among themselves.\nMore formally, a dependency grammar consists of a lexicon of terminal symbols (words), and an inventory of dependency relations specifying inter-lexical requirements. A string is generated by a dependency grammar if and only if:\n\u2022 Every word but one (ROOT) is dependent on another word.\nar X\niv :1\n70 5.\n08 99\n2v 2\n[ cs\n.D M\n] 1\n5 Ju\n\u2022 No word is dependent on itself either directly or indirectly. \u2022 No word is directly dependent on more than one word. \u2022 Dependencies do not cross.\nUnlike the first three constraints, the last constraint is a linearization constraint, usually introduced to simplify the structure and is empirically problematic. The structure in figure 2.left is an example of so-called projective parse, in which dependency links mapped onto the sentences word sequence do not cross. Figure 2.right illustrates an incorrect parse of the sentence with non-projective dependancies: \u201dher\u201d\u2192\u201dsuffered\u201d is crossing \u201da\u201d\u2192\u201dpredecessor\u201d). While the vast majority of English sentences observe the projectivity constraint, other languages allow much more flexibility in word order. Non-projective structures include wh-relative clauses [7], parentheticals [4], cross-serial constructions of the type found in Dutch and Swiss-German [6], as well as free or relaxed word order languages [8]. Therefore, it is interesting whether grammar induction can be performed without regard to word order.\nA truly cross-linguistic formulation of dependency parsing corresponds to finding a spanning tree (parse) in a completely connected subgraph of word nodes and dependency edges. The grammar induction problem in the same setting corresponds to inducing the minimal fully-connected subgraph which contains spanning trees for all sentences in a given corpus. Consider three sentences: \u201dHer immediate predecessor suffered a nervous breakdown.\u201d, \u201dHer predecessor suffered a stroke.\u201d, \u201dIt is a nervous breakdown.\u201d Intuitively, the repetition of a word cooccurrence informs us about grammatical co-dependence.\nHere is a formulation of the grammar induction problem as an optimization problem: Given a lexicon V and a set of k sentences S1, . . . , Sk s.t. Si \u2282 V (a.k.a. corpus) the objective is to find the most parsimonious combination of dependency structures. i.e. such set of spanning trees for all Si that has the minimal cardinality of a joint set of edges.\nIn section 2 of this paper, we formally introduce the related graph-theoretic problem. In section 2.1 we show that the problem is hard to approximate within a factor of c log n for weighted instances, and hard to approximate within some constant factor (APX-hard) for unweighed instances. In section 3, we generalize the problem to matroids. Here we prove that the problem is hard to approximate within a factor of c log n, even for unweighed instances. We conclude with a positive result \u2013 an algorithm for the matroid problem which constructs a solution whose cardinality is within O(log n) of optimal."}, {"heading": "2 The Problem for Spanning-Trees", "text": "Let G = (V,E) be a graph and let S1, . . . , Sk be arbitrary subsets of V . Our objective is to find a set of edges F \u2286 E such that\n\u2022 F contains a spanning tree for each induced subgraph G[Si], and\n\u2022 |F | is minimized. We call this the Min Spanning-Tree Hitting Set problem. Figure 3 illustrates one instance of this problem. A graph G consist of two sub-graphs G1 and G2. We present one possible correct solution on the left (|F | = 4) and two sample incorrect solutions (|F | = 5) on the right. The Min SpanningTree Hitting Set problem may be generalized to include a weight function w on the edges of G. The objective for the weighted problem is the same as before, except that we seek to minimize w(F ). Notice that the problem initially appears similar to the group Steiner problem [2], since the objective is to connect certain subsets of the nodes. However, our condition on the subgraph is slightly different: we require that the given subsets of nodes are internally connected.\nTo develop some intuition for this problem, let\u2019s analyze a simple greedy ad-hoc solution: first, assign all the edges weight equivalent to the number of sub-graphs it is included into, i.e. count the frequency of node pairs in the input set; then fragment the graph into subgraphs, keeping the weights and run the standard MST algorithm, to find a spanning tree for each subgraph. Figure 4 presents a counterexample to simple heuristics approaches. The following sub-sets make up the input as indicated via edges of distinct color and pattern in the figure: {1, 4, 5}, {2, 4, 5}, {3, 4, 5}, {1, 4}, {1, 5}, {2, 4}, {2, 5}, {3, 4}, {3, 5}. The optimal solution to this instance does not contain the edge {4, 5}, yet this edge is a member of the most (namely three) sub-sets."}, {"heading": "2.1 Hardness for Weighted Instances", "text": "We now show that the weighted problem is NP-hard to approximate within a factor of log n. To do so, we exhibit a\nreduction from Min Hitting Set, which is known to be hard to approximate within log n.\nAn instance of Min Hitting Set consists of a universe U = {u1, . . . , un} and a collection of sets T = {T1, . . . , Tm}, each of which is a subset of U . We construct a weighted instance of Min Spanning-Tree Hitting Set as follows. Let r 6\u2208 V be a new vertex. We set\nV = U + r\nE = KU \u222a { {r, ui} : for all ui \u2208 U } S{i,j} = {ui, uj} for 1 \u2264 i < j \u2264 n\nS\u2032i = Ti + r for 1 \u2264 i \u2264 m,\nwhere KU denotes (the edges of) the complete graph on vertex set U . The edges belonging to KU have weight 1 and the edges incident with r have weight n3. Let h denote the minimum weight of a Spanning-Tree Hitting Set in G. Let h\u2032 denote the minimum cardinality of a Hitting Set for T .\nClaim 1 h = h\u2032 \u00b7 n3 + ( n 2 ) .\nProof: First we show that h\u2032 \u2264 ( h \u2212 ( n 2 )) /n3 Let F be a spanning-tree hitting set. Clearly KU \u2286 F , because of the sets S{i,j}. So all edges in F \\KU are of the form {r, ui}. Now define C = { ui : {r, ui} \u2208 F }. We now show that C is a hitting set. Consider a set Ti. Since F contains a spanning tree for S\u2032i, it must contain some edge {r, ui}. This shows that C hits the set Ti.\nNow we show that h \u2264 h\u2032 \u00b7 n3 + ( n 2 ) . Let C \u2286 U be a hitting set for T . Let F = KU\u222a{ {r, ui} : for all ui \u2208 C }. We now show that F is a spanning-tree hitting set. Each set S{i,j} is clearly hit by the set KU . So consider a set S\u2032i = Ti + r. All edges {ua, ub} with a, b \u2208 Ti are contained in KU . Furthermore, since C is a hitting set, there exists an element ua \u2208 Ti \u2229 C. This implies that {r, ua} \u2208 F , and hence F contains a spanning tree for G[S\u2032i].\nGiven an instance T of Hitting Set, it is NP-hard to decide whetherOPT (T ) \u2264 f(n) orOPT (T ) > \u03b1 log n\u00b7f(n) for some constant \u03b1 > 0 and some function f . To prove log n-hardness of Min Spanning-Tree Hitting Set, we must similarly show that for any instance y, there exists a constant\n\u03b2 > 1 and a function g such that it is NP-hard to decide whether OPT (G) \u2264 g(y) or OPT (G) > \u03b2 log n \u00b7 g(y).\nFrom our reduction, we know that it is NP-hard to distinguish between\nOPT (G) \u2264 f(n) \u00b7 n3 + ( n 2 ) or\nOPT (G) > \u03b1 log n \u00b7 f(n) \u00b7 n3 + ( n 2 ) .\nNow note that \u03b1 log n \u00b7 f(n) \u00b7 n3 + ( n 2 ) f(n) \u00b7 n3 + ( n 2\n) = \u03b1 log n \u00b7 ( f(n) \u00b7 n3 + ( n 2 ) /(\u03b1 log n)\n) f(n) \u00b7 n3 + ( n 2\n) = \u03b1 log n \u00b7 ( 1\u2212 ( n 2 ) \u00b7 ( 1\u2212 1/\u03b1 log n) ) f(n) \u00b7 n3 + ( n 2\n) ) \u2265 \u03b2 log n for some constant \u03b2 > 0. Letting g(y) = f(n) \u00b7 n3 + ( n 2 ) , it follows that Min Spanning-Tree Hitting Set is NP-hard to approximate within log n."}, {"heading": "2.2 Hardness for Unweighted Instances", "text": "We show APX-hardness for the unweighted problem via a reduction from Vertex Cover. The approach is similar to the construction in Section 2.1. Suppose we have an instance G\u2032 = (V \u2032, E\u2032) of the Vertex Cover problem. We use the fact that Vertex Cover is equivalent to Min Hitting Set where U = E\u2032 and T = E\u2032. The construction differs only in that E\u2032 is used in place of the edge set KU ; the sets S{i,j} are adjusted accordingly. Let h denote the minimum cardinality of a Spanning-Tree Hitting Set in G. Let c denote the minimum cardinality of a Vertex Cover in G\u2032. A claim identical to Claim 1 shows that h = c+ |E\u2032|.\nRecall that Vertex Cover is APX-hard even for constantdegree instances; see, e.g., Vazirani [11, \u00a729]. So we may assume that |E\u2032| \u2264 d2 |V\n\u2032|. Given an instance G\u2032 = (V \u2032, E\u2032) of Vertex Cover with degree at most some constant d, it is NPhard to decide whether OPT (G\u2032) \u2264 \u03b1\u2032|V \u2032| or OPT (G\u2032) > \u03b2\u2032|V \u2032| for some constant \u03b1\u2032 < \u03b2\u2032. To prove APX-hardness of Min Spanning-Tree Hitting Set, we must similarly show that for any instance G, there exists a constant \u03b3 > 1 such that it is NP-hard to decide whether OPT (G) \u2264 f(G) or OPT (G) > \u03b3f(G). From our reduction, we know that it is NP-hard to distinguish between\nOPT (G) \u2264 \u03b1\u2032(|V | \u2212 1) + (|E| \u2212 |V |+ 1) or\nOPT (G) > \u03b2\u2032(|V | \u2212 1) + (|E| \u2212 |V |+ 1). Now note that\n\u03b2\u2032(|V | \u2212 1) + (|E| \u2212 |V |+ 1) \u03b1\u2032(|V | \u2212 1) + (|E| \u2212 |V |+ 1) =\n1 + (\u03b2\u2032 \u2212 \u03b1\u2032)(|V | \u2212 1)\n\u03b1\u2032(|V | \u2212 1) + (|E| \u2212 |V |+ 1) \u2265\n1 + (\u03b2\u2032 \u2212 \u03b1\u2032)(|V | \u2212 1)\n(d/2\u2212 1 + \u03b1\u2032)|V |+ 1\u2212 \u03b1\u2032 =\n1 + \u03b2\u2032 \u2212 \u03b1\u2032 d/2 + \u03b1\u2032 \u00b7 |V | \u2212 1 |V | \u2212 1 ,\nwhich is a constant greater than 1. Letting \u03b3 be this constant, and letting f(y) = \u03b1\u2032(|V | \u2212 1) + (|E| \u2212 |V |+ 1), it follows that Min Spanning-Tree Hitting Set is APX-hard."}, {"heading": "3 The Problem for Matroids", "text": "The Min Spanning-Tree Hitting Set can be rephrased as a question about matroids. Let E be a ground set. Let Mi = (E, Ii) be a matroid for 1 \u2264 i \u2264 k. Our objective is to find F \u2286 E such that\n\u2022 F contains a basis for each Mi, and\n\u2022 |F | is minimized.\nWe call this the Minimum Basis Hitting Set problem."}, {"heading": "3.1 Connection to Matroid Intersection", "text": "Suppose we switch to the dual matroids. Note that F contains a basis for Mi if and only E \\ F \u2208 I\u2217i . Then our objective to find F \u2032 \u2286 E such that\n\u2022 F \u2032 \u2208 I\u2217i for each i, and\n\u2022 |F \u2032| is maximized.\nSuppose that such a set is found, and let F := E \\ F \u2032. The first property implies that F contains a basis for each Mi. The second property implies that |F | is minimized. Stated this way, it is precisely the Matroid k-Intersection problem. So, from the point of view of exact algorithms, Min Basis Hitting Set and Matroid k-Intersection problems are equivalent. However, this reduction is not approximationpreserving, and implies nothing about approximation algorithms."}, {"heading": "3.2 Hardness", "text": "Theorem 2 Min Basis-Hitting Set is NP-hard.\nProof: We do a reduction from the well-known problem Minimum Hitting Set. An instance of this problem consists of a family of sets C = {C1, . . . , Ck}. The objective is to find a set F \u2286 E such that F \u2229 Ci 6= \u2205 for each i. This problem is NP-complete.\nNow we reduce it to Minimum Basis Hitting Set. For each set Ci, set Mi = (E, Ii) be the matroid where Ii = { {c} : c \u2208 Ci } \u222a {\u2205}. That is, Mi is the rank-1 uniform matroid on Ci. So a basis hitting set for these matroids corresponds precisely to a hitting set for the the sets C.\nCorollary 3 Min Basis Hitting Set is NP-hard to approximate with c log n for some positive constant c.\nProof: It is well-known that Min Hitting Set is equivalent to Set Cover, and is therefore NP-hard to approximate within c log n for some positive constant c. Since reduction given in Theorem 3.2 is approximation preserving, the same hardness applies to Min Basis Hitting Set."}, {"heading": "3.3 An Approximation Algorithm", "text": "We consider the greedy algorithm for the Min Basis Hitting Set problem. Let O \u2286 E denote an optimum solution. Let rankj denote the rank function for matroid Mj and let rj be the rank of Mj , i.e., rj = rankj(E). Let Fi denote the set that has been chosen after the ith step of the algorithm. Initially, we have F0 = \u2205. For S \u2286 E, let P (S, e) = \u2211k j=1 ( rankj(S + e) \u2212 rankj(S) ) ; intuitively, this is the total \u201cprofit\u201d obtained, or rank that is hit, by adding e to S. Let Ri denote \u2211k j=1 ( rj \u2212 rankj(Fi) ) ; intuitively, if the algorithm has chosen a set Fi, thenRi is the total amount of \u201cresidual rank\u201d that remains to be hit.\nConsider the ith step of the algorithm. Let\u2019s denote the profit obtained by choosing ei by pi = maxe 6\u2208Fi\u22121 P (Fi\u22121, e). The greedy algorithm chooses an element ei 6\u2208 Fi\u22121 achieving the maximum profit. We now analyze the efficiency of this algorithm. Let Oi be a minimum-cardinality set that contains Fi and is a basis hitting set.\nFor any set S \u2287 Fi and any e 6\u2208 S, we have (by submodularity):\nrankj(S + e) + rankj(Fi) \u2264 rankj(Fi + e) + rankj(S) rankj(S + e)\u2212 rankj(S) \u2264 rankj(Fi + e)\u2212 rankj(Fi)\nP (S, e) \u2264 P (Fi, e) \u2264 pi This implies that each edge in Oi \\ Fi has profit at most pi. SinceOi must ultimately hit all of the residual rank, but each element hits at most pi, we have Ri\u22121 \u2264 pi \u00b7 |Oi \\ Fi|.\nNow, note that |Oi \\ Fi| \u2264 |O|. This is is because of the non-decreasing property of rankj : if O is a basis hitting set then so is O \u222a Fi. This observation yields the inequality 1 \u2264 pi \u00b7 |O|/Ri\u22121. Suppose that the greedy algorithm halts with a solution of cardinality s. Then we have\ns \u2264 s\u2211\ni=1\npi \u00b7 |O| Ri\u22121\n\u2264 |O| \u00b7 s\u2211\ni=1\npi Ri\u22121\n\u2264 |O| \u00b7 s\u2211\ni=1 \u2211 0\u2264j<pi\n1\nRi\u22121 \u2212 j \u2264 |O| \u00b7 logR0.\nHere, the last inequality follows from the fact that Ri = Ri\u22121 \u2212 pi for 1 \u2264 i \u2264 s. Note that R0 = \u2211k j=1 rj is the total rank of the given matroids.\nThe preceding argument shows that the greedy algorithm has approximation ratio O(log n), where n is the length of\nthe input. Table 1 presents description of the algorithm. Informally speaking, the algorithm could be explain as follows: Estimate potential number of sub-graphs each edge would contribute to if used. Loop through all edges, adding in (greedily) the edge which contributes to the most spanning trees, then re-calculate potential contributions."}, {"heading": "3.4 Contrast with Matroid Union", "text": "Consider the matroid union problem for matroids M\u2217i . The matroid union problem is:\nmax { | \u22c3 i Si| : Si \u2208 I\u2217i } But note that Si \u2208 I\u2217i iff ri(V \\Si) = ri(V ). In other words, Si \u2208 I\u2217i iff S\u0304i contains a basis for Mi. And maximizing the size of the union is the same as minimizing the size of the complement of the union. So an equivalent problem is:\nmin { | \u22c2 i Si| : Si contains a basis for Mi }\nThe minimum does not change if we assume that Si in fact is a basis. So, letting Ti denote S\u0304i, we obtain the equivalent problem:\nmin { | \u22c2 i Ti| : Ti is a basis for Mi } This problem is solvable in polynomial time, because it is just matroid union in disguise. It is quite similar to the Minimum Basis Hitting Set problem, except that it has an \u201cintersection\u201d rather than an \u201cunion\u201d."}, {"heading": "3.5 Empirical study", "text": "We ran preliminary experiments with the approximation algorithm on adult child-directed speech from the CHILDES corpus [9]. These experiments demonstrated that the algorithm performs better than the baseline adjacency heuristic because of its ability to pick out non-adjacent dependencies. For example, the sentence \u201dIs that a woof?\u201d is parsed into the following set of links: woof-is, that-is, a-woof. The links correspond to the correct parse tree of the sentence, In contrast, the baseline adjacency heuristic would parse the sentence into is-that; that-a; and a-woof, which fails to capture the dependence between the predicate noun \u201dwoof\u201d and the verb, and postulates a non-existent dependency between the determiner \u201da\u201d and the subject \u201dthat\u201d. However, more work is needed to thoroughly assess the performance. In particular, one problem for direct application is the presence of repeated words in the sentence. The current implementation avoids the issue of repeated words in its entirety, by filtering the input text. An alternative approach is to erase the edges among repeated words from the original fully connected graph. This assumes that no word can be a dependent of itself, which might be a problem in some contexts (e.g. \u201dI know that you know\u201d). Related work which was not completed at the time of writing this manuscript seeks to incorporate adjacency as a soft linguistic constraint on the graph by increasing initial weight edges of adjacent words."}, {"heading": "4 Discussion", "text": "We presented some theoretical results for a problem on graphs which is inspired by the unsupervised link grammar induction problem from linguistics. Numerous possible directions for the future work would include searching for more efficient approximation algorithms under various additional constraints on admissible spanning trees, as well as characterizing instances of the problem which could be solved efficiently. Another possible direction is allowing \u201dungrammatical\u201d corpus as input, e.g. searching efficiently for partial solutions, where several sentences remain unparsed or not fully parsed. Another direction is to look for a solution to a directed graph analog of the problem considered here, which would require finding minimal set of arborescences and relate to the directed dependency parsing. One other question which remains open is an edge weighing scheme which would reflect syntactic consideration and particular language-related constraints, as in the so-called Optimality Theory [10].\nExploring relation of this problem to other application would be interesting. One such example could be an autonomous network design, where an objective is to efficiently design a network that must connect joint units of organizations which do not necessarily trust each other and want to maintain their own skeletal sub-network in case their partner\u2019s links fail."}], "references": [{"title": "Three new probabilistic models for dependency parsing: An exploration", "author": ["J. Eisner"], "venue": "In Proceedings of the 16th International Conference on Computational Linguistics", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 1996}, {"title": "A compendium on steiner tree problems", "author": ["M. Hauptmann", "M. Karpinski"], "venue": null, "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2013}, {"title": "Foundations of Statistical Natural Language Processing", "author": ["C.D. Manning", "H. Sch\u00fctze"], "venue": "The MIT Press, Cambridge, Massachusetts", "citeRegEx": "3", "shortCiteRegEx": null, "year": 1999}, {"title": "Parentheticals and discontinuous constituent structure", "author": ["J. McCawley"], "venue": "Linguistic Inquiry, 13:91\u2013106", "citeRegEx": "4", "shortCiteRegEx": null, "year": 1982}, {"title": "Non-projective dependency parsing using spanning tree algorithms", "author": ["R. McDonald", "F. Pereira", "K. Ribarov", "J. Hajic"], "venue": "HLT/EMNLP", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2005}, {"title": "A linear precedence account of cross-serial dependencies", "author": ["A. Ojeda"], "venue": "Linguistics and Philosophy, 11:457\u2013 492", "citeRegEx": "6", "shortCiteRegEx": null, "year": 1988}, {"title": "Taxemes and immediate constituents", "author": ["K. Pike"], "venue": "Language, 19:65\u201382", "citeRegEx": "7", "shortCiteRegEx": null, "year": 1943}, {"title": "Free word order and phrase structure rules", "author": ["G. Pullum"], "venue": "Proceedings of NELS, volume 12", "citeRegEx": "8", "shortCiteRegEx": null, "year": 1982}, {"title": "Parsing the CHILDES database: Methodology and lessons learned", "author": ["K. Sagae", "A. Lavie", "B. MacWhinney"], "venue": null, "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2001}, {"title": "Structures and Strings", "author": ["V. Savova"], "venue": "PhD thesis, Johns Hopkins University", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2006}, {"title": "Approximation Algorithms", "author": ["V. Vazirani"], "venue": "Springer", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2001}], "referenceMentions": [{"referenceID": 0, "context": "Some work is concerned with inducing parameters of the grammar from annotated corpora, for example see work by Eisner on dependency parsing [1] or more recent work by McDonald et al.", "startOffset": 140, "endOffset": 143}, {"referenceID": 4, "context": "[5] and references therein.", "startOffset": 0, "endOffset": 3}, {"referenceID": 4, "context": "It has been pointed out [5] that parsing with dependency grammars is related to Minimal Spanning Tree algorithms in general and in particular Chu-Liu-Edmonds MST algorithm was applied to dependency parsing.", "startOffset": 24, "endOffset": 27}, {"referenceID": 2, "context": "An established computational linguistics textbook has the following to say on the subject [3]: \u201d.", "startOffset": 90, "endOffset": 93}, {"referenceID": 6, "context": "Non-projective structures include wh-relative clauses [7], parentheticals [4], cross-serial constructions of the type found in Dutch and Swiss-German [6], as well as free or relaxed word order languages [8].", "startOffset": 54, "endOffset": 57}, {"referenceID": 3, "context": "Non-projective structures include wh-relative clauses [7], parentheticals [4], cross-serial constructions of the type found in Dutch and Swiss-German [6], as well as free or relaxed word order languages [8].", "startOffset": 74, "endOffset": 77}, {"referenceID": 5, "context": "Non-projective structures include wh-relative clauses [7], parentheticals [4], cross-serial constructions of the type found in Dutch and Swiss-German [6], as well as free or relaxed word order languages [8].", "startOffset": 150, "endOffset": 153}, {"referenceID": 7, "context": "Non-projective structures include wh-relative clauses [7], parentheticals [4], cross-serial constructions of the type found in Dutch and Swiss-German [6], as well as free or relaxed word order languages [8].", "startOffset": 203, "endOffset": 206}, {"referenceID": 1, "context": "Notice that the problem initially appears similar to the group Steiner problem [2], since the objective is to connect certain subsets of the nodes.", "startOffset": 79, "endOffset": 82}, {"referenceID": 8, "context": "We ran preliminary experiments with the approximation algorithm on adult child-directed speech from the CHILDES corpus [9].", "startOffset": 119, "endOffset": 122}, {"referenceID": 9, "context": "One other question which remains open is an edge weighing scheme which would reflect syntactic consideration and particular language-related constraints, as in the so-called Optimality Theory [10].", "startOffset": 192, "endOffset": 196}], "year": 2017, "abstractText": "This paper formulates a novel problem on graphs: find the minimal subset of edges in a fully connected graph, such that the resulting graph contains all spanning trees for a set of specified subgraphs. This formulation is motivated by an unsupervised grammar induction problem from computational linguistics. We present a reduction to some known problems and algorithms from graph theory, provide computational complexity results, and describe an approximation algorithm.", "creator": "TeX"}}}