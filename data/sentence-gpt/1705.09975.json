{"id": "1705.09975", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "28-May-2017", "title": "A Deep Multi-View Learning Framework for City Event Extraction from Twitter Data Streams", "abstract": "Cities have been a thriving place for citizens over the centuries due to their complex infrastructure. The emergence of the Cyber-Physical-Social Systems (CPSS) and context-aware technologies boost a growing interest in analysing, extracting and eventually understanding city events which subsequently can be utilised to leverage the citizen observations of their cities. In this paper, we investigate the feasibility of using Twitter textual streams for extracting city events. We propose a hierarchical multi-view deep learning approach to contextualise citizen observations of various city systems and services. Our goal has been to build a flexible architecture that can learn representations useful for tasks, thus avoiding excessive task-specific feature engineering. We apply our approach on a real-world dataset consisting of event reports and tweets of over four months from San Francisco Bay Area dataset and additional datasets collected from London. The results of our evaluations show that our proposed solution outperforms the existing models and can be used for extracting city related events with an averaged accuracy of 81% over all classes. To further evaluate the impact of our Twitter event extraction model, we have used two sources of authorised reports through collecting road traffic disruptions data from Transport for London API, and parsing the Time Out London website for sociocultural events. The analysis showed that 49.5% of the Twitter traffic comments are reported approximately five hours prior to the authorities official records. Moreover, we discovered that amongst the scheduled sociocultural event topics; tweets reporting transportation, cultural and social events are 31.75% more likely to influence the distribution of the Twitter comments than sport, weather and crime topics. Finally, while most of the tweets generated through Twitter data are from real-world incidents, we found that the tweet processing was not sufficient for the data gathering. Thus, while we believe that our proposed approach to social media data is a valuable and valuable one, we also find that it may offer a different approach for monitoring events across the entire city.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "histories": [["v1", "Sun, 28 May 2017 18:22:15 GMT  (5180kb,D)", "http://arxiv.org/abs/1705.09975v1", null]], "reviews": [], "SUBJECTS": "cs.SI cs.CL", "authors": ["nazli farajidavar", "sefki kolozali", "payam barnaghi"], "accepted": false, "id": "1705.09975"}, "pdf": {"name": "1705.09975.pdf", "metadata": {"source": "CRF", "title": "A Deep Multi-View Learning Framework for City Event Extraction from Twitter Data Streams", "authors": ["Nazli Farajidavara", "Sefki Kolozalib", "Payam Barnaghic"], "emails": [], "sections": [{"heading": "1 Introduction", "text": "Recent advances in ubiquitous computing and context-aware technologies have boosted the interest in smart city framework designs. These frameworks endeavour to provide authorities and citizens with real-time information and assistance in the decision-making and resource allocation processes. Meantime, the departmental structure of a city can be very complex, and its management continues to be strained by various factors, such as dynamic nature of their services, population growth and continuously shrinking pool of available financial resources. Figure 1(a) illustrates an evidence of some of the common departments that provide public support and management for London and their budget re-allocations within the past two years. 1\nSome of the services offered by these departments are dynamic, e.g., transportation services and their behaviour may vary in response to social and cultural events, accidents, and weather conditions. In this sense, understanding events occurring in cities is of great contemporary interest [23,28,33] to city authorities to enhance their management and to optimise operations and interactions among various city departments and services. A possible way to do this is through getting continues feedback and event reports from citizens, who are the front-end users of these services.\nMeanwhile, the emergence of social networks, such as Twitter2, Facebook3 and Instagram4, offers enormous 1https://www.gov.uk/government/publications/public-expenditure-statistical-analyses-2015 2http://twitter.com/ 3http://facebook.com/ 4http://www.instagram.com\nar X\niv :1\n70 5.\n09 97\n5v 1\n[ cs\n.S I]\n2 8\nM ay\ninformation that can be exploited for citizen sensing. This could be used to notify citizens as well as authorities regarding the events occurring in smart urban spaces (Figure 1(b) depicts samples of real-world city events reported directly by citizens on social media). However, the citizen sensing [10,38] component that can provide complementary or corroborative information is often ignored in state-of-the-art analytics for smart cities [15].\nIn this article we propose a hybrid pipeline for real-time sensing in cities through utilisation of complementary dynamic data sources, namely Twitter, London Road disruption reports from traffic sensors; and Time Out London. The proposed data processing pipeline involves data wrappers, a novel Natural Language Processing (NLP) component based on multi-view learning, and multi-sensor correlation analysis. We presented a priliminary version of this pipeline in [14]. And in this article we will further focus on the detailed theoretical design aspects of the model and include extended experiments to showcase its performance. The multi-view learning component combines the output of a Convolutional Neural Network (CNN) learning with a name entity event extraction to enable a near real-time city-related event extraction from short informal text corpus of Twitter. Developing a scalable automatic city event annotation system, we show that our proposed solution achieves performance boost compared to the state-of-the-art approaches [3, 36]. Up to our knowledge, this is the first time that a multi-view deep learning algorithm has been proposed in the context of city event extraction. Subsequently, we conducted a similarity analysis on the processed data from social media, road sensors, and Web of Data, and discover the associations between incidents in near real-time. The research contributions are four-fold in high-level and can be summarised as follows: i) Automated real-time data collection wrappers for Twitter and city sensors; ii) A near real-time NLP component for classifying Twitter data; iii) A correlation analysis for detecting the dependencies between Twitter stream and city sensors and web driven data records; iv) A web interface for displaying and visualising the citys event highlights. The fine-grained contributions of the proposed NLP component are as follows: ii-i) real-time multi-label event extraction from Twitter, ii-ii) a novel multi-view deep learning formulation for event extraction based on graphical models, ii-iii) late classification results fusion for an enhanced event location extraction from tweets.\nThe paper is organised as follows. Section 2 describes the benchmark task of interest - Tweet annotation - where we discuss related works. In Section 3, we describe the proposed multi-view pipeline. Section 4 details our experimental setup and discusses the evaluation results. Finally, in Section 5 we derive a conclusion for our work and provide future directions."}, {"heading": "2 Related work", "text": "Typically, a city has many departments such as public safety, urban planning, energy, water, transportation, social programs, and education [6, 7]. The live updates on the performance and quality of services offered by these depart-\nments are important for city authorities to leverage the management of city resources and for citizens to make more informed decisions using the city services and to interact better with surrounding environment. Meanwhile, social media networks, such as Twitter offer a near real-time communication platforms which can be utilised to facilitate this purpose. Such information can complement sensor data and textual reports collected from conventional sources or city departments, and it can help to enhance the public services. For example, sensors deployed on a road may report reduced speed of vehicles which can be explained by the procession obstructing traffic that is reported on social media.\nThe design of such platform which utilises the social media as a source for public sensing in city-related event extraction context, needs to address the following research question: How to extract city infrastructure related events from Twitter? How to exploit event and location knowledge-bases for event extraction? And finally how accurately these Twitter extracted events are matching the reality of city events?\nThe studies such as [3, 32] assumed the presence of event data sources such as sensory data (e.g., loop detectors) and formal report of events (e.g., eventful5) in a city. While utilisation of such a formal data source can serve as a reliable source for training an automated event extraction system, such resources may not be available with short latency or even not exist at all in many cities. Therefore, we need the alternative and complementary data sources for training such model for different cities.\nEvent extraction from textual corpus, can be categorised into two groups according to the structure of the text; formal corpus vs informal. Where the former refers to the grammatical text such as news documents and the later addresses the user-generated content with no overt structure that might contain a lot of slang and non-standard abbreviations and notations (as it is the case in data obtained from Twitter).\nIn formal text analysis domain, Liu et al. [29] proposed to alleviate information overload in daily news by extracting key entity and significant event of news documents. A bipartite graph was induced in [4], based on the entities and their associations to documents using mutual reinforcement principle capturing salient entities and the documents with salient entities used to rank the news events. Extraction of local events from blog entries carried out by [34]. Use of lightweight patterns to extract global crisis events from news text presented in [39]. Event extraction in the context of detecting infectious disease outbreak was achieved by [19] where the event schema consisted of date range, geo-location, disease name, organism type and number affected by the disease, and the organism survival information. The event extraction then obtained by finite-state pattern matching on the tokenized input text. More recently, adding convolutional layers to the neural network language model of Bengio et al. [8], Collorbert et al. [12] developed their convolutional neural network model that shared representations across the tasks of language modelling, part of speech tagging, chuncking, named entity recognition, semantic role labelling, and syntactic parsing. Although the proposed model was not specifically designed for event extraction, its performance surpassed the state of the art methods on majority of the language modelling tasks.\nEvent extraction from informal text (which is our main focus in this paper due to the informal nature of Twitter textual content) is also addressed in literature [3, 5, 36]. In [5], the authors used temporal (volume changes), social (replies, broadcast), topical (coherence of clusters), and Twitter-centric (multi-word hashtags) features to train a classifier that performed better than the baseline. Ritter et al. [36], solved the task in an unsupervised manner by building a calendar of significant events such as sports, concert, protests, politics, TV, and religion. Their approach utilised the Latent Drichlet Allocations (LDA) method to model each entity in terms of a mixture of event types and each event type in terms of a mixture of entities. Recent stdudies in [41, 44] utilised the LDA for hit and run crimes and traffic related event extraction, respectivlely. And in [30], the authors used the latent topic model for semantic role labeling task in Twitter data. A generalised linear regression model also used to capture the association between topics and crimes from a training dataset. Lampos and Cristianini [27] proposed to use an optimised feature selection approach with a regressor to estimate the intensity of environmental and epidemiological events based on event markers.\nConsidering the same assumption as of [32], Anantharam et al. [3] developed an automatic data annotation unit to obtain ground truth by using officially reported traffic events 6 and location 7 knowledge-bases. The authors then used this annotated data to train a CRF-based event extraction model to capture long-term word dependencies for Twitter analysis. While their proposed approach for the preparation of the ground-truth data has shown a good wordtagging performance, the proposed CRF-based event extraction had some limitations. The model was designed to only extract traffic events. Precisely speaking, since the automatic annotation unit was trained with the officially reported ground-truth traffic events of a limited time period, the model performed poorly in the prediction of future incidents specifically reported by new users. Besides, although the location terms have been extracted, they were not utilised to\n5http://eventful.com/ 6http://511.org 7https://www.openstreetmap.org/\nassociate locations with extracted events. Instead, the authors assumed that the tweet\u2019s geo-location tag (the location where the users tweet the events) can serve as the event locations, which is not always valid.\nIn multi-view learning literature, Chen et al. [11] developed a statistical framework that learns a predictive subspace shared by multiple views based on a generic multi-view latent space Markov network. Kumar et al. [25] co-trained unsupervised learning models and proposed a spectral clustering algorithm for multi-view data. Quadrianto and Lampert [35] studied the metric learning problem in cross-media retrieval tasks with the aim to learn metrics with which the original multi-view higher dimensional features can be projected into a shared feature space, so that the Euclidean distance in this space is meaningful not only within a single view, but also among different views. In our multi-view learning model we used the Restricted Boltzmann Machines formulation to be consistent with the rest of the neural network architecture of CNNs.\nWhile in all proposed platforms for event extraction from Twitter, the main focus had been on training an NLP model using tweet\u2019s informal text corpus, the human intelligence learning model does not work as such. As human, we initially learn the semantic meaning of the words in a language. We then, been taught on the synthetic structure (Grammar rules) of the sentence at the school by means of formal corpus (i.e. books). Analogously, NLP approaches which are jointly attempt to accomplish the PoS and NER tagging using the informal Twitter corpus will not acquire the potential of being extended to future data due to their intrinsic limitation. Taking this into consideration, we have proposed an NLP framework for informal text classification which is not only applicable to future data but also addresses the the limitations of the other state of the art approaches. We utilised a CRF-based Name Entity Recognition (NER) model of [3] and extending it beyond traffic event extraction, we have proposed a multi-view learning pipeline which fuses the CRF output with the part of speech (POS) tags extracted from the Convolutional Neural Network (CNN) [12] model, for leveraging the city event extraction.\nUtilising a CNN model which is trained on formal texts for PoS tagging of tweet words is plausible, since the underlying syntactic role of words in a language are still valid even in informal texts such as Twitter corpora despite their variation in sentence grammatical structures. In terms of CRF training, unlike Anantharam [3] et al.\u2019s model, our proposed model is trained on more generic categorical data and is capable of detecting a wider categorical range of city events. This allows the model to better generalise to future events and incidents. While various neural network architectures [13,18,40] have been proposed in literature and their performance are investigated for Twitter sentiment classification, to the best of our knowledge, this is the first time that the CNN text analysis is utilised for city even extraction from informal text and its result is integrated with a CRF NER tagger in a deep multi-view learning framework to obtain an enhanced sentence-level inference and event extraction. To further validate the verity of the extracted events, we have parsed data from London Traffic API and TimeOut London sociocultural resources and evaluated the veracity of twitter extracted events through a graph-based similarity analysis."}, {"heading": "3 Methodology", "text": "Our proposed hybrid approach is based on undirected graphical models. Figure 2 depicts the diagram of the proposed hybrid approach. We developed three data wrappers to collect data from the city; Twitter stream API 8, Transport for London API 9, and Time Out London 10 parser. Furthermore, we developed a data processing component that involves of two main parts: i) Natural Language Processing (NLP) on Twitter data streams and ii) similarity analysis on Twitter, road sensor data, and scheduled events collected from Time Out London website. We used the Google translate API to automatically detect the source language on non-English tweets and translate them into English to facilitate the text analysis step."}, {"heading": "3.1 Twitter NLP Component", "text": "Figure 3 shows the data processing units of the proposed NLP component which is composed of three sub-components: a semantic embedding subspace learning, a syntactic embedding subspace learning, and a multi-view event extraction.\nGiven a tweet text represented by xi = words(Tweeti), we are interested in associating it with one or multiple city-related event classes from the events set: C = {TransportationEvent, WeatherEvent, CulturalEvent, SocialEvent,\n8https://dev.twitter.com/streaming 9http://data.tfl.gov.uk/tfl\n10http://www.timeout.com/london\nSportEvent, FoodEvent, CriminalEvent} along with a Location tag. To assign event tags to tweets, we have assumed that each tweet contains only one sentence. Considering the 140 character limit of a tweet, this assumption sounded plausible. We then decomposed sentences into semantic and syntactic embeddings where the former deals with the meaning of the words in the sentence and the later addresses its grammar structure.\nThe fusion of these embeddings have been used to provide an explicit insight to the meaning of sentences to facilitate their classification. This fusion can be formulated as a multi-view learning task where each embedding contributes to a distinct view of the same training data. Although baseline methods such as one proposed by [3] had shown an acceptable performance on time and location dependent annotation tasks, they will not generalise well to annotation task of varying locations and times. To address these generalisation issue, we have estimated the semantic and syntactic embedding matrices off line and independently, using more comprehensive data.\nInspired by human cognitive ability, we believe that a Part of Speech (PoS) word tagging approach which has been trained on encyclopedia corpus can help in extracting a more realistic syntactic embedding of the tweet. This in practice can resemble humans general grammar knowledge. Doing though, we have adopted the CNN graphical model (CNN) proposed in [12] which had been trained on entire English Wikipedia.\nTo align the formulation of the semantic embedding extraction with the CNN based syntactic embedding, and to capture the long term dependencies in name phrases, we have chosen the Conditional Random Field (CRF) formulation of undirected graphical models for Name Entity Recognition (NER). To do so, we have used phrases, short reports and location terms extracted from official websites and authority reports (listed in Table 1) to built class conditional corpora. These conditional corpora are then used to train CRF models for name entity recognition.\nTo fuse the information gained from these two embeddings, we have proposed a multi-view learning approach.\nIn order to be consistent with the rest of the architecture, we have chosen a supervised learning undirected graphical model, Restricted Boltzmann Machine (RBM). This formulation in practice uses the obtained tags of the two previous embeddings for mutually validating and scoring them for a final sentence-level inference 11.\nAn example of sentence level inference is in the case of tweets such as \u201cseeing someone being given a parking ticket\u201d where individual words \u201cparking\u201d and \u201cticket\u201d can belong to classes Transportation and Cultural events respectively while considering these words\u2019 grammar roles can resolve this confusion.\nThe output of the system can be represented as < \u02c6etype, \u02c6eloc, \u02c6tloc, \u02c6ttime, \u02c6eimpact > where < \u02c6etype, \u02c6eloc are representing the event type and location, extracted from the proposed NLP analysis framework, \u02c6tloc, \u02c6ttime are tweets geo-location and time of report (meta data obtained from Twitter Streaming API) and finally \u02c6eimpact > denotes the event impact. The event annotation impact score is calculated as the product of event severity and event likelihood scores as in [42]."}, {"heading": "3.1.1 CRF Name Entity Tagging", "text": "The CRF is an undirected graphcal model [24] containing nodes that correspond to the set: words(Tweeti) \u22c3 T where words(Tweeti) = xi = {w1, w2, ..., wM} and T = Tagset. The model defines factors between (a) neighbouring tags (tagj , tagj+1) and (b) tags and words (tagj , wordj) in a sequence where tagj \u2208 T and wj \u2208 words(Tweeti). The factor function maps all possible values of inputs variable combinations to Real numbers (also known as potential for the input variable combination) and can be formulated as, V \u2192 R where V \u2282 words(Tweeti) \u22c3 T , e.g., \u03a6(tagj , tagj+1) captures the number of times tagj appears before tagj+1 in a text. Concretely, if tagj is BLocation representing the beginning location term, and tagj+1 is I-Location, representing the intermediate location term, \u03a6(B \u2212 Location, I \u2212 Location) maps to the number of times this sequence appears in the corpus which may not be a normalised value. The factors \u03a6(tagj , wj) for each word (where the wj is always observed) captures the number of times the word wj was labelled with the tagj . Let\u2019s assume wj is a word e.g. \u201cPiccadily\u201d and tagj is B-Location, then \u03a6(B \u2212 Location, P iccadily) captures the number of times the word \u201cPiccadily\u201d was labelled with the tag B-Location in the corpus.\nMore specifically, if there are |words(Tweeti)|words in a tweet sequence, we need (|words(Tweeti)|\u22121) factors to define relations between neighbouring tags and |words(Tweeti)| factors to define the relation between tags and words. Finding the most likely tag assignment to a word in a tweet can be formalised as maximising the probability P (tags|words(Tweeti)) as shown in Table 2 (a).\nEssentially, the tag assignment resulting in the highest probability score is chosen as the final tag assignment for all the words. Even though the model captures the relation between adjacent tags, tag assignment is done based on the global maximum i.e., tags that result in highest overall score are assigned to all the words. Such a global assignment of tags naturally captures long distance dependencies in text.\nThe location and event tagging module uses the linear chain CRF model presented in Table 2 (b) which is implemented in LingPipe [2]. In a linear chain CRF model, each tag type and its positions in a corpus are extracted using a feature extractor function f which takes position and the tags as input. The first word in the sequence will have \u201cnull\u201d as the previous tag. For the rest of the words in the input sequence, the feature function is invoked with all possible tags (1, .., i, ...,M). \u03b2(M) are the coefficient vectors learned for each output tag in the tag set T where M is the number\n11Note that retraining the last supervised learning layer of a deep architecture is a common practice in deep learning\nof tags from the corpus. The corresponding scores for tag assignment given words is provided as a regression model and is not normalised. To get the probability of tag assignment, these scores need to be normalised by summation over all possible tags as shown in Table 2 (b). Though the features are extracted locally using the function f , the global normalisation captures long distance relationships in the word sequences.\nTraining the CRF Model The objective is to spot event and location terms in tweets. Identifying locations in a tweet is challenging as location references in the text are hard to recognise especially in the presence of non-standard abbreviations, spellings, and capitalisation convention. To address these challenges, we train the sequence model with the knowledge of locations from Open Street Maps (OSM) [20].\nOn the other hand, identifying event terms is even more challenging especially given the open domain nature of city related events. To address this issue, background knowledge consisting of domain dictionaries are obtained from event reports of different web pages (see Table 1), e.g. sport, weather and locations are such categories of events. The CRF is trained on short reports of such categorical event reports and then applied to our data for event terms name entity recognition. The result of this step (shown in Fig. 3), forms the semantic embedding view and will be denoted with \u03c6(x). This embedding can also be considered as a naive projection (embedding) of the output label space, Y ."}, {"heading": "3.1.2 CNN Word Tagging", "text": "The CNN model takes the input sentence and learns several layers of feature extraction that process the input tweets. The features computed by the deep layers of the network are automatically trained by back-propagation. Fig. 4 depicts the CNN network architecture.\nWord-Level Feature Extraction The CNN Word Tagging unit considers a fixed-sized word dictionary 12W . Given a sentence ofM words w1, w2, ..., wM , where wm \u2208 W , it is first embedded into aD-dimensional vector space where the index is taken from a finite dictionary of size |W|, by applying a look-up table operation:\nLTW (wm) = W ( 0, . . . , 0, 1at indexm, 0, . . . , 0 )T2 = Wwm (1)\nMatrix W \u2208 RD\u00d7|W| represents the parameters to be trained in this look-up layer. Each column Wn \u2208 RD corresponds to the embedding of the mth word in the dictionaryW .\n12Unknown words are mapped to a special unknown word. Numbers references are also mapped to a \u201cnumber\u201d word.\nHaving in mind the matrix-vector notation in Eq. 1, the look-up table applied over the sentence can be seen as an efficient implementation of a convolution with a kernel width of size one. Parameters W are thus initialised randomly and trained as any other neural network layer. These representations have been trained on the English Wikipedia corpus 13 affter using the Penn Treebank tokenizer 14 and after removing all pragraphs containing non-roman characters and all MediaWiki markups. The extracted features contain syntactic and semantic information which appears to be useful for inference.\nIn practice, it is common that one wants to represent a word with more than one feature. In such a scenario, the low-caps words and the \u201dcaps\u201d feature: wm = (wlowcapsm , w caps m ) can be used and to obtain this, one needs to apply different look-up tables for each discrete feature (LTW lowcaps and LTW caps ), and the final word embedding is formed by concatenating the output of all these look-up tables:\nLTWwords(wm) = ( LTW lowcaps(w lowcaps m ) T2 , LTW caps(w caps m ) T2 )\n(2)\nFor simplicity, we followed [12] suggestion and considered only one look-up table.\n13Available for download at http://download.wikipedia.org 14Available at http://www.cis.upenn.edu/ treebank/tokenization.html.\nSentence-Level Representation Scores for all tags T2 and all words in the sentence are produced by applying a classical Convolutional Neural Network over the look-up table embeddings obtained from Eq. 1. More precisely, all successive windows of text (of size K) are considered by sliding over the sentence, from position 1 to M . At position m, the neural network of the structural inference step is trained with the vector x\u2032m resulting from the concatenation of the embeddings:\nx\u2032m = ( WT2wm\u2212(K\u22121)/2 , . . . ,W T2 wm+(K\u22121)/2 )T2 (3) The words with index exceeding the sentence boundaries (m(K1)/2 < 1 or m+ (K1)/2 > M) are mapped to a special padding word. As any classical neural network, Collobert proposed architecture performs several matrix-vector operations on its inputs interleaved with some non-linear transfer function f2. It outputs a vector of size |T2| for each word at position m, interpreted as a score for each tag in T2 and each word wm in the sentence:\ns(x\u2032m) = M 2f2(M 1x\u2032m) (4)\nwhere H denotes the number of the hidden units and the matrices M1 \u2208 RH\u00d7(KD) and M2 \u2208 R|T2|\u00d7H are the parameters to be trained on the network. The hard version of the hyperbolic tangent function is utilised as the transfer function:\nf2(u) =  \u22121 if u < \u22121 u if \u22121 5 u 5 1 1 if u > 1\n(5)\nFine details of the adopted CNN architecture are explained in [12]."}, {"heading": "3.1.3 Multi-view Learning for tweet Annotation", "text": "The dictionary-based NER approaches explained in previous sections are beneficial when a text (i.e. tweet) contains some event terms that is previously seen by the model in the predefined general English words.\nGiven a sentence, these methods extract event terms by searching for word sequences that match the lexical entries, and create a token graph according to the word order. The next step is to estimate the score of every path using the weights of node and edges estimated by training CRF (or CNN) and selecting the best path in a joint learning model.\nWhile combining the two proposed NER tagging approaches can lead in performance enhancement, when term ambiguity and variability are very high, specifically in the case of tweets of short-sentence nature, dictionary-based Named Entity Recognition (NER) may not be an ideal solution even though large-scale terminological resources are available [37].\nA common solution to enhance the performance would be the addition of named entities to a Named Entity dictionary. However, in the case of multi-class annotation this might increase the risk of class confusions. Moreover, retraining of NER models is required to guarantee achieving task specific class labels.\nConsensus principle of multi-view learning as a joint learning model aims to maximise the agreement on multiple distinct views. Suppose the available Twitter data sample X has two views: the semantic view, \u03c6(x), which is obtained from CRF+CNN NER word tagging and the syntactic view, \u03b8(x), which is derived from CNN PoStagging. An example (xi,yi) is therefore viewed as (\u03b8(xi), \u03c6(xi), y\u0302i), where y\u0302i is the final label assigned to sample xi.\nWhile the PoS tagging output of the CNN model will shed a light on the grammatical structure of the text (i.e. tweet) and possibly facilitates the global inference on tweet\u2019s meaning, its NER location and organisation named entity recognition output can be utilised for boosting the Location name entity recognition of CRF model.\nSince retraining the last supervised fully connected layer of a convolutional neural network for adapting the learning for a new task is a common practice in deep learning, we adopted the Restricted Boltzman Machine (RBM) [16] formulation to perform the multi-view learning with the aim of event classification.\nThe RBM is a Markov Random Field associated with a bipartite undirected graph. In the Bernoulli RBM, our focus in this work, the visible and hidden variables are assumed to take values (v, h) \u2208 [0, 1]. Each value encodes the probability that the specific feature would be active. Perceiving the RBM as an energy model [1,17], the RBM feature learning encodes an input vector v, using a vector of latent variables h = \u03c3(WTv). Therefore each column of the weight matrix W can be viewed as a filter which corresponds to network\u2019s hidden variable hn in which \u03c3 is a nonlinearity, such as the sigmoid, \u03c3(u) = 11+exp(u) . The weight parameters W are then estimated through maximising\nthe likelihood of the observations via Gibbs sampling [21] based on a set of training examples and the activity of the hidden unit. The model is defined as the sum over the filter responses:\nh = WT(FTv) (FTv) (6)\nwhere is element-wise product and the columns of B contain subspace projection filters that are learned along with W from data.\nWhen an energy model is applied to a concatenation of two views of a data, a response that is closely related to the response of a multi-view sparse coding model is obtainable. Inspired by Memisevic [31] multi-view image correlation model, we can formulate our view fusion problem via defining a compatibility energy function E : X \u00d7 X \u2032 \u2192 R that encode the relationship between the two views as shown in Fig. 5. We have modelled the visible layer of the RBM as the concatenation of two embeddings BTv = \u0398Tx + \u03a6Tx where \u0398 denotes the part of the filter B in Eq. 6 that is applied to input sentence x to extract its syntactic embedding and \u03a6 denote the part of the filter B in Eq. 6 that extracts the semantic embedding of the sentence which can be perceived as a projection of the label space Y. W in this formulation is a d \u00d7 |C| matrix representing the parameter space with d = d1 + d2 where d1 and d2 are the two view embedding dimensionality and |.| represents the cardinality of the label set.\nSubstituting B in Eq. 6 with a concatenation of view projection matrices \u03a6 and \u0398 and v with (x,y)d1+d2 , the hidden unit activities in the multi-view feature learning scenario, take the form:\nhi = d\u2211 j Wij(\u0398 Tx + \u03a6Tx)2 = 2 d\u2211 j (\u0398Tx)(\u03a6Tx) + d\u2211 j Wij(\u0398 Tx)2 + d\u2211 j Wij(\u03a6 Tx)2 (7)\nIn this formulation, the quadratic terms in Eq. 7 are view-specific optimisation problems which have already been solved through the prior CNN and CRF training steps.\nHaving an estimate of the subspace projection matrices \u0398 and \u03a6, we now just need to learn the weight matrix W from in-domain data (tweet instances). Given the fact that the activity of the second layer in the proposed architecture (see Fig. 5) will be the concatenation of the projected views, the last layer can be trained by simply maximising the loglikelihoods over the training set. Given a sentence x, the network with energy function E(v, h) = \u2211 i \u2211 j wijvihj +\u2211\ni bivi + \u2211 j kjhj and parameter set \u03be = (W,b,k) computes a score s c \u03be(x) for each event label c \u2208 C. In order to transform these scores into a conditional probability distribution of labels given the sentence and the set of network\nparameters, one can apply a softmax operation on the scores:\np(c|x, \u03be) = e sc\u03be(x)\u2211\n\u2200i\u2208C s i \u03be(x)\n(8)\nTaking the log from two sides of the Eq.(8):\nlog p(c|x, \u03be) = sc\u03be(x)\u2212 log( \u2211 \u2200i\u2208C si\u03be(x)) (9)\nOne can then use the gradient decent theorem to minimise the negative log probability with respect to \u0398. The backpropagation algorithm is a natural choice to efficiently compute gradients of the network architecture as stated in [12]."}, {"heading": "3.2 Tweet Impact Estimation", "text": "Many factors are contributing in reliability of an event extracted from Twitter data; there might be multiple references to the same event and the event\u2019s extracted location might be different from the location where the tweet is published.\nTo capture this, we define the tweet impact factor as the product of event severity and event likelihood scores following [42]:\n\u02c6eimpact = scores \u00d7 scorel (10)\nwhere the event severity score, scores, is calculated following the spatio-temporal event grouping approach of [3] referred as Thematic Coherence. The Thematic Coherence approach considers events with similar entities, reported within a grid gi \u2208 G (where G is a set of all grids in a city) and time \u03b4t as multiple references of the same event and reports the severity score as the total number of events falling in this criteria.\nIn our evaluations, we have fixed the time \u03b4t to five minutes and unlike [3] who used the tweet\u2019s geo-tag for computing the thematic coherence, upon existence we have utilised the extracted event location (the output of the multi-view tweet annotation described in section 3.1.3) along with the predicted event type for grouping and computing the event severity scores.\nWe have also formulated the event likelihood score computation as follows:\nscorel = 1\u2212 Dist(location, gC)\nDist(gBB(0), gBB(1)) (11)\nwhere the Dist(g1, g2) function measures the Vincenty distance [22] between two geolocation coordinates. The (latitude, longitude) pairs, gCC , gBB(0) and gBB(1) are corresponding to city-specific centroid and bounding box information, respectively which are estimated using the Flickr\u2019s Geo API Explorer 15. Therefore, these values will be set as gC = (\u22120.1280, 51.5077), gBB(0) = (\u22120.5103, 51.2868), gBB(1) = (0.3340, 51.6923) for the London city. The event likelihood score in practice will assign more impact to the events which are reported closer to the city centre."}, {"heading": "3.3 Similarity Analysis Graph Representation", "text": "For the similarity analysis, we narrowed down our focus to the event classes which enabled the access to the authority event records, namely the Transport and traffic reports and scheduled sociocultural records. To do this, we collected officially registered traffic reports from London open data store portal and parsed the Time Out London webpage to get a list of scheduled sociocultural events taking place in London along with their timestamp and locations.\nTwo graph structure have been considered to represent the spatial distribution of the traffic and sociocultural records. Let assume that, GT = {nT1 , nT2 , ..., nT|T |} and G\nSC = {nSC1 , nSC2 , ..., nSC|SC|} representing the traffic and sociocultural record graphs respectively where |.| denotes the cardinality of each record set. The edge values in these graphs are associated with the pair-wise Euclidean distances between the nodes which are in 3D coordinates and are denoted with feature vectors ni = (xi,yi, zi, ti, ei). The first three variables, x, y, z, represent the spatial coordinate of a point after polar to Cartesian conversion and ti, ei are the event timestamp and event type, respectively. We employed these two graphs for detecting the nearest node to each of the automatically annotated Twitter events. Moreover, we have taken into account the spatio-spectral topography of London city presented in Fig. 6. As one can note, the spectral\n15https://www.flickr.com/places/info/44418\nstructure of the city infers a spectral weighting of computed distances. Meaning that, the farther we move away from the city centre, the distance turns to be inversely prominent. Taking this into account, given that seven target graphs each represents the twitter events of each class and simplifying the location vector of each node with Pi = (xi, yi, zi), we then formulated the graph dissimilarities with respect to authority graphs (i.e. traffic) as follows:\nD\u0302c = \u03a3i=1:|c|min(d(P Gc i , P GT j )/\u03bbj) (12)\nwhere d(.) represents the Euclidean distance between two points. The points superscripts, Gc, GT , shows the graph memberships, and |c| denotes the cardinality of tweets, which are classified as event type c and with Pcentre being the Cartesian conversion of the city centre geo-coordinates 16. The parameter \u03bb is formulated as \u03bbj = d(PTj , Pcentre). In practice, the value of the parameter imposes higher weight to close-to-centre events compared to off centre events."}, {"heading": "4 Experimental Setup and Results", "text": "Our experimental objective is to evaluate the proposed framework performance and its extendability for tweet classification where the data is collected from new locations and at varying time with respect to training data. To showcase this, we conducted experiments on textual Twitter data collected from two geographically different locations: San Francisco Bay area and London.\nOur objective in the following evaluations are three-fold: i) to quantify the extent to which our framework can extract city events from Twitter where we compare our approach with the state-of-the-art baselines [3, 36] on San Francisco data, ii) to evaluate the performance boost of the proposed MV-RBM approach for sentence inference rather than just word tagging by testing the model on locally collected dataset from London; iii) finally to perform similarity analysis and study how well the Twitter extracted events are matching with authority reports.\n16Following flicker, (-0.127, 51.507) is considered as the (longitude, latitude) pair describing the city centre"}, {"heading": "4.1 Datasets", "text": "To make the evaluation, we constrain our experiments to the domain of city related events. The proposed approach is generic enough to be applied to any other cities for which the Twitter data is available. The final aim in the proposed pipeline is to assign one (or multiple) label(s) to each tweet out of a set of city event classes {Crime, Transportation (Trans.), Cultural event, Sport, Social event, Food, Weather and Location}. We leverage the open domain knowledge available for a city, specifically, vocabulary related to each of these categories from official and authorised web reports as summarised in Table1, i.e. Transportation (Trans.) vocabulary is constructed using phrases that are taken from http://511.org 17 web page, the Open Street Map (OSM) 18 of the cities is used for extracting the city location terms and the Wikipedia cultural activities hierarchy 19 is utilised for constructing the Cultural event terms."}, {"heading": "4.1.1 Data Collection through Twitter Streaming API", "text": "The Twitter data which is used in this study has been collected via Twitter Streaming API which allows searching for keywords, hash tags, user Ids and geographic bounding boxes simultaneously. The filter API facilitates the search by providing a continues stream of tweets matching the search criteria. Three key parameters are used for the search:\n\u2022 Follow: a comma-separated list of user Ids to follow, which returns all of publicly published tweets in the stream.\n\u2022 Track: a comma-separated list of keywords to track.\n\u2022 Location: a comma-separated list of geographic bounding boxes containing the coordinates of the southwest point and the northeast point as a (longitude, latitude) pair.\nTwitter Streaming API limits the number of parameters which can be supplied in one request. Up to 400 keywords, 25 geographic bounding boxes and 5000 user Ids can be provided in one request. In addition, the API returns all matching tweets up to a volume equal to the streaming cap where the cap is currently set to 1% of the total current volume of tweets published on Twitter [26].\nWe used the San Francisco Twitter data collected by [3] for a period of four months (Aug 2013 to Nov 2013). While the original dataset contained over 8 million tweets for this time period, the authors sub-sampled the data, resulting in a test dataset of size 500 tweets for testing their trained model. We have used the same test dataset for our comparative evaluations. This dataset is referred to as San Francisco. Additionally, we have collected data from London using all API parameters (Location bounding box, tracking and following official news agency user names and user Ids) at two different timestamps, referenced in the remaining of this paper as London1 and London2. The London1 data is composed of 3000 tweets collected between 15th and 31th of May 2015 and manually cleaned and annotated for training and testing the MV-RBM model. The manual annotation results undergo a second investigation for ensuring their consistency and validity. We have asked a group of technical users, who work in the field of smart cities to peer-review the validation of the annotations. The London2 data is collected on 3ed of February 2016 and is of size 1.1MB. In section 4.3, we used this dataset to examine the Twitter extracted event similarity with the road sensor data and the scheduled events that are parsed from the Web.\nTemporal distribution of daily tweets collected from San Francisco and London1 datasets are shown in Fig. 7(a)."}, {"heading": "4.1.2 Ground-truth Annotation Tool", "text": "To facilitate the ground-truth annotation of London data, we have developed a GUI tool. A view of this tool is represented in Fig. 7(b) 20.\nFor this study, we have used this tool to annotate the 3000 London1 tweets for constructing a training dataset of size 2000 and a test set of size 1000 tweets for training and evaluating our model. We have asked a group of seven technical users who work on smart city research in our team to peer-review the annotations. Following criteria have been asked to be considered during the annotations:\n\u2022 The user is asked to assign tweets to one or more classes of events, having in mind the potential effect of the event on city daily pattern\n17http://511.org 18http://www.openstreetmap.org 19http://en.wikipedia.org/wiki/Category:Cultural_events 20The annotation tool is available for downloading at: http://goo.gl/UBTKQp\n\u2022 The \u201cSocial\u201d class is the class which includes voting, election, protest and other city related group activities\n\u2022 The class \u201cOther\u201d is an indicator for tweets which either their contents can not be associated with any of the provided classes (i.e. personal messages and opinion sharing) or they are hard to be understood (i.e. ambiguous notes and texts that are hard to follow in the absence of background knowledge).\nThe result of the ground-truth annotation is used for training the proposed multi-view learning model and to perform evaluations."}, {"heading": "4.2 Performance Evaluation I: Word Level Annotation", "text": "In this section we will evaluate the three proposed city-event classification algorithms performance. We present detailed performance measures on the two datasets collocated from two different cities and show how different steps of the proposed multi-view learning model can help to achieve an enhanced performance considering all different views of the same data."}, {"heading": "4.2.1 CRF Tweets Tagging Evaluation", "text": "In order to evaluate our CRF name entity recognition model and to assess the efficiency of the proposed classconditioned report catalogues, we compared the performance of our model against two state-of-the-art approaches: B1 [36] and B2 [3]. Unlike our supervised event extraction, the two baseline approaches are unsupervised. Therefore, we had to combine all event classes of our framework against the non-event (other) class and mainly focus on the coverage of events and the event locations. We have used the SanFrancisco dataset for this comparison as the baseline approaches had been evaluated using this dataset. Table 3 shows this evaluation results.\nWe found that our CRF-NER model performed equally well as the best performing baseline model, B2, recalling for 95% vs 93% precision on Location terms detection and 84% vs 86% precision on event detections. Note that while B2 [3] method had been trained on a large corpus of approximately 8 million tweets collected from San Francisco, out CRF model was only trained on generic city-independent report catalogues of Table 1 which means we did not provide domain (city) specific prior knowledge for training our CRF model. Instead, we used the CRF-NER tagging approach that is more flexible due to benefiting from a more generic set of conditional class terms. This enabled us to remove any geographical or temporal bias. However, our model performed as well as the model, which is specifically trained for a controlled domain (San Francisco Bay area) with access to official traffic reports of a given time period. Overall, we developed a model that is more flexible and adaptable, while producing results that were as good as the baseline approach. Therefore, our approach can be used for other cities with potentially varying event distribution.\nTo demonstrate the granular performance on each of our defined city event classes, we have presented the NER tagging results in terms of confusion matrix in Table 4. In order to obtain the ground truth NER tags for this confusion matrix, we have used the same tagging schema as of proposed in [3], with the B- and I- prefixes referring to beginning and intermediate tags respectively where exist multiple consecutive tags in an entity phrase 21.\nIn Table 4 we have reported Precision, recall and f-measure scores for class dependent word tagging for the same dataset. The one vs. all Tweet classification accuracies are also computed via dividing the true positive rate by total number of samples of a class.\nThe noteworthy is the slight difference between the one vs. all Tweet classification accuracy and word-tagging recall rate in Table 4. This in fact is caused by the intrinsic difference in word-level tagging vs. Tweet annotation made by human experts where whole Tweet meaning has taken into account and inference is involved. Investigating the Ground-truth Tweet annotations by expert users depicts that annotation differences are occurring under two general circumstances. The first source of such slight differences is where CRF-based label prediction mistakes are initiated from the assumptions made in sentence class label associations. As also reported by Anantharam et al. [3], subtle changes in context result in diverse interpretation of Tweet and subtle difference in location and event references and can cause loss of precision. An example is where tweets are assigned to class \u201cOther\u201d. This class association is based on absence of any non-other class word tags within a Tweet. This means that if a word in a Tweet is tagged as \u201cLocation\u201d the Tweet will be labelled as \u201cLocation\u201d regardless of its global meaning.\nThe second, is where wrong Ground-truth labels are assigned to tweets due to experts\u2019 lack of common-knowledge. This itself is of two origins: i) people normally are not aware of all events taking place and also of all locations existing in a city, and ii) there are oddly phrased tweets which understanding them is quite challenging without following tweets on a specific topic which are tweeted by a specific user - the user Ids were not included in our data due to user privacy policy.). While we have minimised the probability of such mistakes caused due to lack of individuals general knowledge with our peer-reviewed annotation scheme, the second cause remains intact as following historical data from a user is not allowed on Twitter stream API. This user\u2019s ground-truth annotation mistake, indeed demonstrates the necessity of an automated machine annotation model.\n21Note that in this way each detected event (location) phrase in a given tweet might be composed of multiple terms and thereby multiple tags.\nIn order to partially tackle the failures caused by the CRF-dictionary annotation, we have proposed an alternative to Anantharam et al. CRF learning by boosting the CRF dictionary knowledge view through utilising a CNN generated view which jointly aims at enhancing the Location word tagging and providing words grammar roles. The two views of the data are then fed to a multi-view learning framework to enable a sentence-level reasoning and classification. In the next two sections, we will further investigate and evaluate these claims."}, {"heading": "4.2.2 CNN-enhanced LOCATION Tagging Evaluations", "text": "As mentioned earlier, two alternative solutions can help in enhancing the word level Tweet annotation: i) boosting the word tagging through fusion of multiple approaches and ii) training a model which considers a sentence level reasoning for Tweet annotations (i.e. classification) rather than solely relying on event-tag occurrences.\nTo achieve the former enhancement, we used the CNN derived tags which boosts the tagging accuracy of the LOCATION class from 0.96 which was previously reported in Table 4 to 0.99. This Location tagging enhancement is important in our framework since it will enable us to assign more accurate locations to each extracted event rather than assigning the events to their tweeted locations 22 which was reported in previous studies [3].\nTo better evaluate our claims we have also tested our proposed word tagging approaches on a more realistic dataset collected from London referenced as London1. Unlike the San Francisco test data [3], the London1 data has not been cleaned prior to evaluations. Though basic pre-processing steps such as tokenizing and stop word removals have been included in the pipeline. The dataset is divided into two sub-corpora for training and testing the fused NER model. The results are reported in Table 5.\nComparing this results with the performance measure on San Francisco data shows a slight degradation in Tweet event annotation performance for all classes. The main reason is that the San Francisco data which had been used in previous experiments had gone through additional data cleanings (see details in [3]) prior to testing which in turn helped in leveraging the final performance. Moreover, the effect of the CNN tagging which enhances the San Francisco Location term tagging is slightly controversial in the case of London1 data. While San Francisco Twitter users 23 were more frequently and correctly used the \u201c@\u201d and \u201c#\u201d characters for referring to locations and organisation names, the London1 twitters have been observed to ignore these rules more frequently."}, {"heading": "4.3 Performance Evaluation II: Multi-View Learning", "text": "Benefiting from the name entity word tags and word syntactic roles assigned by CNN, in this section we will investigate how the two views can be trained simultaneously to realise an enhanced tweet class inference. As one might have noticed in Table 3, the cardinality of tweets belonging to \u201cOther\u201d category makes the Twitter corpora quite unbalanced for a supervised learning task. To tackle this issue, we have sub-sampled the subset of data of \u201cOther\u201d class prior to our multi-view training step. This data sub-sampling step after the CRF NER tagging sounds plausible as the absence of any name entity tags from all non-other classes in a tweet can be assumed as a course classification of that tweet as class \u201cOther\u201d. Table 6 demonstrates the performance evaluation of the proposed multi-view approach (presented in Sec. 4.2.2). The performance is reported in terms of one vs. all class accuracies and the multi-view approach shows 5% improvement in the performance compared to the single view model that classified tweeted events according to the CRF NER word tagging.\nHowever, one can note a degradation of performance when it is compared with San Francisco data classification results (last row of Table 4). As mentioned before, this degradation was expected, as unlike the San Francisco data (the collection and filtering described in [3]), non of the London datasets has been cleaned prior to the system annotation.\n22Tweet\u2019s Geo-tags in most of the occasions is different from actual event\u2019s location as people rarely publish their thoughts about an event exactly in the actual venue of that event.\n23One should also note that the San Fransicso bay areas is populated by industrial companies and organisation which in practice will lead in more harmonic text patterns of tweets published within its relative bounding box.\nWe obtained a lower performance on \u201cSocial\u201d, \u201cCultural\u201d and \u201cFood\u201d topics compared to other topics. This can be explained by two reasons: class conditional dictionary term similarities in \u201cSocial\u201d and \u201cCultural\u201d categories and incomplete class conditional dictionaries in \u201cFood\u201d category.\nAlthough extra cautions have been taken for constructing class-specific dictionaries however, there were some terms and phrases which contributed in more than one dictionary. This has made the event extraction process more challenging in such scenarios.\nThe effect of the dictionary problem can be reduced by increasing the training data from the categories that provide less accurate results. However, we did not tend to bias our data by providing more training samples of these categories and reported the results based on fair number of annotated tweets for our categories. An example is in tweet \u201cRainbow food @ The Good Life Eatery\u201d where the rainbow food phrase will be tagged as \u201cB-Weather\u201d and \u201cB-Food\u201d using the single-view CRF NER tagging while the actual tag should have been \u201cB-Food\u201d and \u201cI-Food\u201d. Such mistake will be resolved, once the NER tagging outcome is jointly weighted with the PoS tags derived from CNN, in our proposed multi-view learning step.\nThe multi-view training step can in fact provide more flexibility in expanding class-specific dictionaries. However, adding more terms will require the model to be trained with a larger size training data and will cause higher time and computational complexity and requires more manual annotation effort."}, {"heading": "4.4 Performance Evaluation II: Similarity Analysis", "text": "We measured the similarity of the extracted Twitter events against the road sensor data and scheduled sociocultural events that are parsed from the Web. The London2 dataset is used for this experiment.\nThe comparison results are reported in terms of classes average distance (represented with \u00b5) from their nearest authority (web) record which was described in sec. 3.3 along with its variance (represented by \u03c3) and a similarity measure. To compute the similarities from the average distance values, we have first rescaled the averaged distances by the within-class maximum average distance (sport class distance) and then subtracted the result from one. Doing so, the similarity values are confined to be between 0 and 1 where closer to one values will guarantee higher similarity and values close to zero show a higher level of dissimilarity. First row results in Table 7 show different Twitter event distributions compared against the ground-truth traffic sensor data, where (latitude, longitude) polar coordinated are converted to Cartesian values 24 and Euclidean distance used as the metric. The results showed that the smallest\naverage distance of 0.74, considering the variance intervals, correspond to the Traffic events, which is a proof of an acceptable tweet classification performance. Additionally, a comparison of Twitter traffic report times with their nearest neighbour authority traffic record time-stamp, showed that 49.5% of the Twitter traffic alerts are reported on average 297.5 minutes. This is approximately 5 hours prior to the authority\u2019s official reports. This finding highlights the advantage of utilising the social media, particularly Twitter driven knowledge in facilitating and speeding up the city traffic management and potentially smoothing the task-handling. Second row results in Table 7 show different\n24We have used the Haversine formula explained at https://en.wikipedia.org/wiki/Haversine_formula.\nTwitter class distributions compared with the ground-truth sociocultural data, which was parsed form Time Out London computed in the same way to traffic similarities. In our experiments, we discovered higher similarity measurements for traffic, cultural and social tweet event classes with 1.73, 2.95 and 2.00 respective average distance values. This, in fact, proves that the popular and well-advertised cultural activities are potential high-traffic zones. It is important to point out that the Time Out London sociocultural event set does not separate the social events, such as special events held in pubs and restaurants, from cultural events (i.e. exhibitions and ceremonies) while our proposed pipeline labels these events differently."}, {"heading": "4.5 Case Studies and Web Interface", "text": "Table 8 represents case studies for London2 classified events. Investigating the content of the misclassified tweets (shown in the last three rows in the table), one can spot the counter-effect of conversational language complexity on classification task where people occasionally use metaphors to emphasise their concepts i.e. shooting ourselves in the foot to describe the extend of a spoiled situation and the dessert miss the rain to describe a lingering missing sensation.\nWhile in a recent study Zuao et al. [43] proposed to model the intrinsic geometry of tweets through a low-rank, non-linear manifold to visualize the tweets distribution in a two dimensional Euclidean space, in this study we have focused on a visualisation in the real space. To facilitate this, we have developed a Web interface. The interface displays the classification results on a Google map in near real-time and it is composed of four elements; i) Google map canvas layer on which the processed and annotated tweets are displayed with their class-identical icons; ii) a live London traffic layer from Google traffic API - code coloured paths on the map; iii) a bar chart panel which presents the class distribution histogram of daily tweets; and iv) a panel for displaying Twitter time line. The map data is being updated every 60 seconds by appending the past minute\u2019s tweets to existing ones up to a 60-minutes time window. In practice, the whole data will be updated on hourly basis. Clicking on each event a dialogue box is shown on the map which reveals the underlying tweet content along with its time-stamp. The twitter user id and the names are anonymised for privacy purpose. The web interface 25 utilises javascript and HTML coding to read the data results\n25The interface is accessible at http://iot.ee.surrey.ac.uk/citypulse-social/.\nsaved in a CSV data structure format and displays the tweets on the map in near real time with less than 60 seconds latency. Fig. 8 shows an screen shot of the web-interface 26."}, {"heading": "5 Conclusions", "text": "In this paper, we developed a multi-label event detection framework for live annotation and classification of Twitter data, in a smart city context.\nWe have introduced a set of common event dictionaries with minimal overlaps for facilitating the detection of cityrelated events and developed a GUI to facilitate the ground-truth annotation of tweets for machine learning tasks. More importantly, we have developed a novel multi-view learning framework that utilises the Convolutional Neural Network (CNN) features with CRF-dictionary driven NER tags for sentence-level event annotation. The proposed model is tested on geographically different English speaking cities and the results have proved promising. The evaluation results showed that our proposed solution is capable of annotating tweet words with an averaged accuracy of 81% over all event classes. And the multi-view deep learning model boosted the performance over a single-view event classification approach by 5%.\nWe have also performed similarity analysis which showed how authority driven traffic reports and scheduled sociocultural events can affect the traffic pattern and how citizens project on them through social media. The evaluations showed that 49.5% of the Twitter traffic comments are reported approximately five hours prior to authority\u2019s official records and the scheduled sociocultural events have observed influencing the distribution of the twitter comments of traffic class, along as cultural and social classes. The study highlights the possibility of utilising social media as human probes for realising a real-time Physical-Cyber-Social platform for ranking, completing and potentially speeding up the city service deliveries. Finally, we have developed a live stream analysis interface to present the analysis results and case studies on a Google map. The proposed interface enables the public to visualise their city and neighbourhood event patterns.\nThe proposed model serves as a proof of concept and improvements can be made in several stages of the pipeline. For example, the model can be tested on non-English twitter streams, the multi-view learning labels can be updated with an online recursive learning model which is more adaptive and provides performance feedback to the rest of the pipeline.\n26The interface is accessible at http://iot.ee.surrey.ac.uk/citypulse-social/.\nAcknowledgement: This work has been carried out in the scope of the European Commission\u2019s Seventh Framework Programme funded project CityPulse (FP7-609035)."}], "references": [{"title": "Spatiotemporal energy models for the perception of motion", "author": ["Edward H. Adelson", "James R. Bergen"], "venue": "J. OPT. SOC. AM. A,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 1985}, {"title": "Extracting city traffic events from social streams", "author": ["Pramod Anantharam", "Payam Barnaghi", "Krishnaprasad Thirunarayan", "Amit P. Sheth"], "venue": "In ACM Transactions on Intelligent Systems and Technology,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2015}, {"title": "Bipartite Graphs and Their Applications", "author": ["Armen S. Asratian", "Tristan M.J. Denley", "Roland H\u00e4ggkvist"], "venue": null, "citeRegEx": "4", "shortCiteRegEx": "4", "year": 1998}, {"title": "Beyond trending topics: Real-world event identification on twitter", "author": ["Hila Becker", "Mor Naaman", "Luis Gravano"], "venue": "Proceedings of the Fifth International Conference on Weblogs and Social Media,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2011}, {"title": "Getting clever about smart cities: new opportunities require new business models", "author": ["Jennifer B\u00e9lissent"], "venue": "In Vendor Strategy Professionals,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2010}, {"title": "Service providers accelerate smart city projects", "author": ["Jennifer B\u00e9lissent", "Frederic Giron"], "venue": "In Forrester,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2013}, {"title": "A neural probabilistic language model", "author": ["Yoshua Bengio", "R\u00e9jean Ducharme", "Pascal Vincent", "Christian Janvin"], "venue": "J. Mach. Learn. Res.,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2003}, {"title": "Building a smarter planet, one city at a time. online", "author": ["Anthony Bernal", "Chief Programmer"], "venue": null, "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2011}, {"title": "Participatory sensing", "author": ["J. Burke", "D. Estrin", "M. Hansen", "A. Parker", "N. Ramanathan", "S. Reddy", "M.B. Srivastava"], "venue": "In In: Workshop on World-Sensor-Web (WSW06): Mobile Device Centric Sensor Networks and Applications,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2006}, {"title": "Predictive subspace learning for multi-view data: a large margin approach", "author": ["Ning Chen", "Jun Zhu", "Eric P. Xing"], "venue": null, "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2010}, {"title": "Natural language processing (almost) from scratch", "author": ["Ronan Collobert", "Jason Weston", "L\u00e9on Bottou", "Michael Karlen", "Koray Kavukcuoglu", "Pavel Kuksa"], "venue": "J. Mach. Learn. Res.,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2011}, {"title": "Deep convolutional neural networks for sentiment analysis of short texts", "author": ["Cicero dos Santos", "Maira Gatti"], "venue": "In Proceedings of COLING 2014, the 25th International Conference on Computational Linguistics: Technical Papers,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2014}, {"title": "Physical-cyber-social similarity analysis in smart cities", "author": ["Nazli FarajiDavar", "Sefki Kolozali", "Payam M. Barnaghi"], "venue": "IEEE World Forum on Internet of Things,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2016}, {"title": "Smart city: An event driven architecture for monitoring public spaces with heterogeneous sensors", "author": ["Luca Filipponi", "Andrea Vitaletti", "Giada Landi", "Vincenzo Memeo", "Giorgio Laura", "Paolo Pucci"], "venue": "In Fourth International Conference in Sensor Technologies and Applications SENSORCOMM,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2010}, {"title": "An introduction to restricted boltzmann machines", "author": ["Asja Fischer", "Christian Igel"], "venue": "CIARP, volume 7441 of Lecture Notes in Computer Science,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2012}, {"title": "Nueral encoding of the binocular disparity: Energu models, position shifts and phase shift", "author": ["D. Fleet", "H. Wagner", "D. Heeger"], "venue": "Vision Research,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 1996}, {"title": "Domain adaptation for large-scale sentiment classification: A deep learning approach", "author": ["Xavier Glorot", "Antoine Bordes", "Yoshua Bengio"], "venue": "In Proceedings of theTwenty-eight International Conference on Machine Learning (ICML\u201911),", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2011}, {"title": "Real-time event extraction for infectious disease outbreaks", "author": ["Ralph Grishman", "Silja Huttunen", "Roman Yangarber"], "venue": "In Proceedings of the Second International Conference on Human Language Technology Research,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2002}, {"title": "Openstreetmap: User-generated street maps", "author": ["Mordechai (Muki) Haklay", "Patrick Weber"], "venue": "IEEE Pervasive Computing,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2008}, {"title": "A fast learning algorithm for deep belief nets", "author": ["Geoffrey E. Hinton", "Simon Osindero", "Yee-Whye Teh"], "venue": "Neural Comput.,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2006}, {"title": "Algorithms for geodesics", "author": ["Charles F.F. Karney"], "venue": "In Journal of Geodesy,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2013}, {"title": "Smarter cities series: a foundation for understanding ibm smarter cities", "author": ["Michael Kehoe", "Michael Cosgrove", "SD Gennaro", "Colin Harrison", "Wim Harthoorn", "John Hogan", "Pam Nesbitt John Meegan", "Christina Peters"], "venue": "In An IBM Redguide publication. An IBM Redguide publication,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2011}, {"title": "Probabilistic Graphical Models: Principles and Techniques", "author": ["D. Koller", "N. Friedman"], "venue": null, "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2009}, {"title": "Co-regularized multi-view spectral clustering", "author": ["Abhishek Kumar", "Piyush Rai", "Hal Daum\u00e9 III"], "venue": "In Proceedings of the Conference on Neural Information Processing Systems (NIPS), Granada,", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2011}, {"title": "Twitter Data Analytics", "author": ["Shamanth Kumar", "Fred Morstatter", "Huan Liu"], "venue": null, "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2013}, {"title": "Nowcasting events from the social web with statistical learning", "author": ["Vasileios Lampos", "Nello Cristianini"], "venue": "ACM Trans. Intell. Syst. Technol.,", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2012}, {"title": "Ciscos big bet on new songdo: creating cities from scratch", "author": ["Greg Lindsay"], "venue": "http://www.fastcompany.com/", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 2010}, {"title": "Extracting key entities and significant events from online daily news", "author": ["Mingrong Liu", "Yicen Liu", "Liang Xiang", "Xing Chen", "Qing Yang"], "venue": "In Intelligent Data Engineering and Automated Learning - IDEAL 2008, 9th International Conference,", "citeRegEx": "29", "shortCiteRegEx": "29", "year": 2008}, {"title": "Semantic role labeling: An introduction to the special issue", "author": ["Llu\u0131\u0301s M\u00e0rquez", "Xavier Carreras", "Kenneth C. Litkowski", "Suzanne Stevenson"], "venue": "Comput. Linguist.,", "citeRegEx": "30", "shortCiteRegEx": "30", "year": 2008}, {"title": "On multi-view feature learning", "author": ["Roland Memisevic"], "venue": "CoRR, abs/1206.4609,", "citeRegEx": "31", "shortCiteRegEx": "31", "year": 2012}, {"title": "Complex event processing and data mining for smart cities", "author": ["Dunja Mladeni\u0107", "Alexandra Moraru"], "venue": "In Conference on Data Mining and Data Warehouses", "citeRegEx": "32", "shortCiteRegEx": "32", "year": 2012}, {"title": "Smarter cities and their innovation challenges", "author": ["Milind Naphade", "Guruduth Banavar", "Colin Harrison", "Jurij Paraszczak", "Robert Morris"], "venue": null, "citeRegEx": "33", "shortCiteRegEx": "33", "year": 2011}, {"title": "Discovering volatile events in your neighborhood: Local-area topic extraction from blog entries", "author": ["Masayuki Okamoto", "Masaaki Kikuchi"], "venue": null, "citeRegEx": "34", "shortCiteRegEx": "34", "year": 2009}, {"title": "Kernel-based learning. In: Encyclopedia of systems biology", "author": ["Novi Quadrianto", "Christoph H Lampert"], "venue": null, "citeRegEx": "35", "shortCiteRegEx": "35", "year": 2013}, {"title": "Open domain event extraction from twitter", "author": ["Alan Ritter", "Mausam", "Oren Etzioni", "Sam Clark"], "venue": "In Proceedings of the 18th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD", "citeRegEx": "36", "shortCiteRegEx": "36", "year": 2012}, {"title": "How to make the most of ne dictionaries in statistical ner", "author": ["Yutaka Sasaki", "Yoshimasa Tsuruoka", "John McNaught", "Sophia Ananiadou"], "venue": "In Proceedings of the Workshop on Current Trends in Biomedical Natural Language Processing,", "citeRegEx": "37", "shortCiteRegEx": "37", "year": 2008}, {"title": "Citizen sensing, social signals, and enriching human experience", "author": ["Amit P. Sheth"], "venue": "In IEEE Transactions on Internet Computing,", "citeRegEx": "38", "shortCiteRegEx": "38", "year": 2015}, {"title": "Real-time news event extraction for global crisis monitoring", "author": ["Hristo Tanev", "Jakub Piskorski", "Martin Atkinson"], "venue": "editors, NLDB,", "citeRegEx": "39", "shortCiteRegEx": "39", "year": 2008}, {"title": "Coooolll: A deep learning system for twitter sentiment classification", "author": ["Duyu Tang", "Furu Wei", "Bing Qin", "Ting Liu", "Ming Zhou"], "venue": "In Proceedings of the 8th International Workshop on Semantic Evaluation (SemEval", "citeRegEx": "40", "shortCiteRegEx": "40", "year": 2014}, {"title": "Automatic crime prediction using events extracted from twitter posts", "author": ["Xiaofeng Wang", "Matthew S Gerber", "Donald E Brown"], "venue": "In Social Computing, Behavioral-Cultural Modeling and Prediction,", "citeRegEx": "41", "shortCiteRegEx": "41", "year": 2012}, {"title": "Statistical Methods for Immunogenicity Assessment", "author": ["Harry Yang", "Jianchun Zhang", "Binbing Yu", "Wei Zhao"], "venue": null, "citeRegEx": "42", "shortCiteRegEx": "42", "year": 2015}, {"title": "Jointly event extraction and visualization on twitter via probabilistic modelling. In Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, ACL 2016", "author": ["Deyu Zhou", "Tianmeng Gao", "Yulan He"], "venue": "Long Papers,", "citeRegEx": "43", "shortCiteRegEx": "43", "year": 2016}, {"title": "Real world city event extraction from twitter data streams", "author": ["Yuchao Zhou", "Suparna De", "Klaus Moessner"], "venue": "Procedia Computer Science,", "citeRegEx": "44", "shortCiteRegEx": "44", "year": 2016}], "referenceMentions": [{"referenceID": 1, "context": "We apply our approach on a real-world dataset consisting of event reports and tweets collected by [3] over four months from San Francisco Bay Area dataset and additional datasets collected from Greater London.", "startOffset": 98, "endOffset": 101}, {"referenceID": 21, "context": "In this sense, understanding events occurring in cities is of great contemporary interest [23,28,33] to city authorities to enhance their management and to optimise operations and interactions among various city departments and services.", "startOffset": 90, "endOffset": 100}, {"referenceID": 26, "context": "In this sense, understanding events occurring in cities is of great contemporary interest [23,28,33] to city authorities to enhance their management and to optimise operations and interactions among various city departments and services.", "startOffset": 90, "endOffset": 100}, {"referenceID": 31, "context": "In this sense, understanding events occurring in cities is of great contemporary interest [23,28,33] to city authorities to enhance their management and to optimise operations and interactions among various city departments and services.", "startOffset": 90, "endOffset": 100}, {"referenceID": 7, "context": "Figure 1: A: Common city departments [\u00a9 [9]], B: Tweets reporting various concerns about a city spanning power supply, water quality, traffic jams, and public transport delays (\u00a9 [3]).", "startOffset": 40, "endOffset": 43}, {"referenceID": 1, "context": "Figure 1: A: Common city departments [\u00a9 [9]], B: Tweets reporting various concerns about a city spanning power supply, water quality, traffic jams, and public transport delays (\u00a9 [3]).", "startOffset": 179, "endOffset": 182}, {"referenceID": 8, "context": "However, the citizen sensing [10,38] component that can provide complementary or corroborative information is often ignored in state-of-the-art analytics for smart cities [15].", "startOffset": 29, "endOffset": 36}, {"referenceID": 36, "context": "However, the citizen sensing [10,38] component that can provide complementary or corroborative information is often ignored in state-of-the-art analytics for smart cities [15].", "startOffset": 29, "endOffset": 36}, {"referenceID": 13, "context": "However, the citizen sensing [10,38] component that can provide complementary or corroborative information is often ignored in state-of-the-art analytics for smart cities [15].", "startOffset": 171, "endOffset": 175}, {"referenceID": 12, "context": "We presented a priliminary version of this pipeline in [14].", "startOffset": 55, "endOffset": 59}, {"referenceID": 1, "context": "Developing a scalable automatic city event annotation system, we show that our proposed solution achieves performance boost compared to the state-of-the-art approaches [3, 36].", "startOffset": 168, "endOffset": 175}, {"referenceID": 34, "context": "Developing a scalable automatic city event annotation system, we show that our proposed solution achieves performance boost compared to the state-of-the-art approaches [3, 36].", "startOffset": 168, "endOffset": 175}, {"referenceID": 4, "context": "Typically, a city has many departments such as public safety, urban planning, energy, water, transportation, social programs, and education [6, 7].", "startOffset": 140, "endOffset": 146}, {"referenceID": 5, "context": "Typically, a city has many departments such as public safety, urban planning, energy, water, transportation, social programs, and education [6, 7].", "startOffset": 140, "endOffset": 146}, {"referenceID": 1, "context": "The design of such platform which utilises the social media as a source for public sensing in city-related event extraction context, needs to address the following research question: How to extract city infrastructure related events from Twitter? How to exploit event and location knowledge-bases for event extraction? And finally how accurately these Twitter extracted events are matching the reality of city events? The studies such as [3, 32] assumed the presence of event data sources such as sensory data (e.", "startOffset": 438, "endOffset": 445}, {"referenceID": 30, "context": "The design of such platform which utilises the social media as a source for public sensing in city-related event extraction context, needs to address the following research question: How to extract city infrastructure related events from Twitter? How to exploit event and location knowledge-bases for event extraction? And finally how accurately these Twitter extracted events are matching the reality of city events? The studies such as [3, 32] assumed the presence of event data sources such as sensory data (e.", "startOffset": 438, "endOffset": 445}, {"referenceID": 27, "context": "[29] proposed to alleviate information overload in daily news by extracting key entity and significant event of news documents.", "startOffset": 0, "endOffset": 4}, {"referenceID": 2, "context": "A bipartite graph was induced in [4], based on the entities and their associations to documents using mutual reinforcement principle capturing salient entities and the documents with salient entities used to rank the news events.", "startOffset": 33, "endOffset": 36}, {"referenceID": 32, "context": "Extraction of local events from blog entries carried out by [34].", "startOffset": 60, "endOffset": 64}, {"referenceID": 37, "context": "Use of lightweight patterns to extract global crisis events from news text presented in [39].", "startOffset": 88, "endOffset": 92}, {"referenceID": 17, "context": "Event extraction in the context of detecting infectious disease outbreak was achieved by [19] where the event schema consisted of date range, geo-location, disease name, organism type and number affected by the disease, and the organism survival information.", "startOffset": 89, "endOffset": 93}, {"referenceID": 6, "context": "[8], Collorbert et al.", "startOffset": 0, "endOffset": 3}, {"referenceID": 10, "context": "[12] developed their convolutional neural network model that shared representations across the tasks of language modelling, part of speech tagging, chuncking, named entity recognition, semantic role labelling, and syntactic parsing.", "startOffset": 0, "endOffset": 4}, {"referenceID": 1, "context": "Event extraction from informal text (which is our main focus in this paper due to the informal nature of Twitter textual content) is also addressed in literature [3, 5, 36].", "startOffset": 162, "endOffset": 172}, {"referenceID": 3, "context": "Event extraction from informal text (which is our main focus in this paper due to the informal nature of Twitter textual content) is also addressed in literature [3, 5, 36].", "startOffset": 162, "endOffset": 172}, {"referenceID": 34, "context": "Event extraction from informal text (which is our main focus in this paper due to the informal nature of Twitter textual content) is also addressed in literature [3, 5, 36].", "startOffset": 162, "endOffset": 172}, {"referenceID": 3, "context": "In [5], the authors used temporal (volume changes), social (replies, broadcast), topical (coherence of clusters), and Twitter-centric (multi-word hashtags) features to train a classifier that performed better than the baseline.", "startOffset": 3, "endOffset": 6}, {"referenceID": 34, "context": "[36], solved the task in an unsupervised manner by building a calendar of significant events such as sports, concert, protests, politics, TV, and religion.", "startOffset": 0, "endOffset": 4}, {"referenceID": 39, "context": "Recent stdudies in [41, 44] utilised the LDA for hit and run crimes and traffic related event extraction, respectivlely.", "startOffset": 19, "endOffset": 27}, {"referenceID": 42, "context": "Recent stdudies in [41, 44] utilised the LDA for hit and run crimes and traffic related event extraction, respectivlely.", "startOffset": 19, "endOffset": 27}, {"referenceID": 28, "context": "And in [30], the authors used the latent topic model for semantic role labeling task in Twitter data.", "startOffset": 7, "endOffset": 11}, {"referenceID": 25, "context": "Lampos and Cristianini [27] proposed to use an optimised feature selection approach with a regressor to estimate the intensity of environmental and epidemiological events based on event markers.", "startOffset": 23, "endOffset": 27}, {"referenceID": 30, "context": "Considering the same assumption as of [32], Anantharam et al.", "startOffset": 38, "endOffset": 42}, {"referenceID": 1, "context": "[3] developed an automatic data annotation unit to obtain ground truth by using officially reported traffic events 6 and location 7 knowledge-bases.", "startOffset": 0, "endOffset": 3}, {"referenceID": 9, "context": "[11] developed a statistical framework that learns a predictive subspace shared by multiple views based on a generic multi-view latent space Markov network.", "startOffset": 0, "endOffset": 4}, {"referenceID": 23, "context": "[25] co-trained unsupervised learning models and proposed a spectral clustering algorithm for multi-view data.", "startOffset": 0, "endOffset": 4}, {"referenceID": 33, "context": "Quadrianto and Lampert [35] studied the metric learning problem in cross-media retrieval tasks with the aim to learn metrics with which the original multi-view higher dimensional features can be projected into a shared feature space, so that the Euclidean distance in this space is meaningful not only within a single view, but also among different views.", "startOffset": 23, "endOffset": 27}, {"referenceID": 1, "context": "We utilised a CRF-based Name Entity Recognition (NER) model of [3] and extending it beyond traffic event extraction, we have proposed a multi-view learning pipeline which fuses the CRF output with the part of speech (POS) tags extracted from the Convolutional Neural Network (CNN) [12] model, for leveraging the city event extraction.", "startOffset": 63, "endOffset": 66}, {"referenceID": 10, "context": "We utilised a CRF-based Name Entity Recognition (NER) model of [3] and extending it beyond traffic event extraction, we have proposed a multi-view learning pipeline which fuses the CRF output with the part of speech (POS) tags extracted from the Convolutional Neural Network (CNN) [12] model, for leveraging the city event extraction.", "startOffset": 281, "endOffset": 285}, {"referenceID": 1, "context": "In terms of CRF training, unlike Anantharam [3] et al.", "startOffset": 44, "endOffset": 47}, {"referenceID": 11, "context": "While various neural network architectures [13,18,40] have been proposed in literature and their performance are investigated for Twitter sentiment classification, to the best of our knowledge, this is the first time that the CNN text analysis is utilised for city even extraction from informal text and its result is integrated with a CRF NER tagger in a deep multi-view learning framework to obtain an enhanced sentence-level inference and event extraction.", "startOffset": 43, "endOffset": 53}, {"referenceID": 16, "context": "While various neural network architectures [13,18,40] have been proposed in literature and their performance are investigated for Twitter sentiment classification, to the best of our knowledge, this is the first time that the CNN text analysis is utilised for city even extraction from informal text and its result is integrated with a CRF NER tagger in a deep multi-view learning framework to obtain an enhanced sentence-level inference and event extraction.", "startOffset": 43, "endOffset": 53}, {"referenceID": 38, "context": "While various neural network architectures [13,18,40] have been proposed in literature and their performance are investigated for Twitter sentiment classification, to the best of our knowledge, this is the first time that the CNN text analysis is utilised for city even extraction from informal text and its result is integrated with a CRF NER tagger in a deep multi-view learning framework to obtain an enhanced sentence-level inference and event extraction.", "startOffset": 43, "endOffset": 53}, {"referenceID": 1, "context": "Although baseline methods such as one proposed by [3] had shown an acceptable performance on time and location dependent annotation tasks, they will not generalise well to annotation task of varying locations and times.", "startOffset": 50, "endOffset": 53}, {"referenceID": 10, "context": "Doing though, we have adopted the CNN graphical model (CNN) proposed in [12] which had been trained on entire English Wikipedia.", "startOffset": 72, "endOffset": 76}, {"referenceID": 34, "context": "org/wiki/Category:Social_events Sport sport dictionaries of [36] Weather http://www.", "startOffset": 60, "endOffset": 64}, {"referenceID": 40, "context": "The event annotation impact score is calculated as the product of event severity and event likelihood scores as in [42].", "startOffset": 115, "endOffset": 119}, {"referenceID": 22, "context": "The CRF is an undirected graphcal model [24] containing nodes that correspond to the set: words(Tweeti) \u22c3 T where words(Tweeti) = xi = {w1, w2, .", "startOffset": 40, "endOffset": 44}, {"referenceID": 18, "context": "To address these challenges, we train the sequence model with the knowledge of locations from Open Street Maps (OSM) [20].", "startOffset": 117, "endOffset": 121}, {"referenceID": 10, "context": "Figure 4: Convolutional Neural Network architecture, source: [12]", "startOffset": 61, "endOffset": 65}, {"referenceID": 10, "context": "For simplicity, we followed [12] suggestion and considered only one look-up table.", "startOffset": 28, "endOffset": 32}, {"referenceID": 10, "context": "Fine details of the adopted CNN architecture are explained in [12].", "startOffset": 62, "endOffset": 66}, {"referenceID": 35, "context": "While combining the two proposed NER tagging approaches can lead in performance enhancement, when term ambiguity and variability are very high, specifically in the case of tweets of short-sentence nature, dictionary-based Named Entity Recognition (NER) may not be an ideal solution even though large-scale terminological resources are available [37].", "startOffset": 345, "endOffset": 349}, {"referenceID": 14, "context": "Since retraining the last supervised fully connected layer of a convolutional neural network for adapting the learning for a new task is a common practice in deep learning, we adopted the Restricted Boltzman Machine (RBM) [16] formulation to perform the multi-view learning with the aim of event classification.", "startOffset": 222, "endOffset": 226}, {"referenceID": 0, "context": "In the Bernoulli RBM, our focus in this work, the visible and hidden variables are assumed to take values (v, h) \u2208 [0, 1].", "startOffset": 115, "endOffset": 121}, {"referenceID": 0, "context": "Perceiving the RBM as an energy model [1,17], the RBM feature learning encodes an input vector v, using a vector of latent variables h = \u03c3(Wv).", "startOffset": 38, "endOffset": 44}, {"referenceID": 15, "context": "Perceiving the RBM as an energy model [1,17], the RBM feature learning encodes an input vector v, using a vector of latent variables h = \u03c3(Wv).", "startOffset": 38, "endOffset": 44}, {"referenceID": 19, "context": "the likelihood of the observations via Gibbs sampling [21] based on a set of training examples and the activity of the hidden unit.", "startOffset": 54, "endOffset": 58}, {"referenceID": 29, "context": "Inspired by Memisevic [31] multi-view image correlation model, we can formulate our view fusion problem via defining a compatibility energy function E : X \u00d7 X \u2032 \u2192 R that encode the relationship between the two views as shown in Fig.", "startOffset": 22, "endOffset": 26}, {"referenceID": 10, "context": "The backpropagation algorithm is a natural choice to efficiently compute gradients of the network architecture as stated in [12].", "startOffset": 124, "endOffset": 128}, {"referenceID": 40, "context": "To capture this, we define the tweet impact factor as the product of event severity and event likelihood scores following [42]: \u02c6 eimpact = scores \u00d7 scorel (10)", "startOffset": 122, "endOffset": 126}, {"referenceID": 1, "context": "where the event severity score, scores, is calculated following the spatio-temporal event grouping approach of [3] referred as Thematic Coherence.", "startOffset": 111, "endOffset": 114}, {"referenceID": 1, "context": "In our evaluations, we have fixed the time \u03b4t to five minutes and unlike [3] who used the tweet\u2019s geo-tag for computing the thematic coherence, upon existence we have utilised the extracted event location (the output of the multi-view tweet annotation described in section 3.", "startOffset": 73, "endOffset": 76}, {"referenceID": 20, "context": "where the Dist(g1, g2) function measures the Vincenty distance [22] between two geolocation coordinates.", "startOffset": 63, "endOffset": 67}, {"referenceID": 1, "context": "Our objective in the following evaluations are three-fold: i) to quantify the extent to which our framework can extract city events from Twitter where we compare our approach with the state-of-the-art baselines [3, 36] on San Francisco data, ii) to evaluate the performance boost of the proposed MV-RBM approach for sentence inference rather than just word tagging by testing the model on locally collected dataset from London; iii) finally to perform similarity analysis and study how well the Twitter extracted events are matching with authority reports.", "startOffset": 211, "endOffset": 218}, {"referenceID": 34, "context": "Our objective in the following evaluations are three-fold: i) to quantify the extent to which our framework can extract city events from Twitter where we compare our approach with the state-of-the-art baselines [3, 36] on San Francisco data, ii) to evaluate the performance boost of the proposed MV-RBM approach for sentence inference rather than just word tagging by testing the model on locally collected dataset from London; iii) finally to perform similarity analysis and study how well the Twitter extracted events are matching with authority reports.", "startOffset": 211, "endOffset": 218}, {"referenceID": 24, "context": "In addition, the API returns all matching tweets up to a volume equal to the streaming cap where the cap is currently set to 1% of the total current volume of tweets published on Twitter [26].", "startOffset": 187, "endOffset": 191}, {"referenceID": 1, "context": "We used the San Francisco Twitter data collected by [3] for a period of four months (Aug 2013 to Nov 2013).", "startOffset": 52, "endOffset": 55}, {"referenceID": 34, "context": "In order to evaluate our CRF name entity recognition model and to assess the efficiency of the proposed classconditioned report catalogues, we compared the performance of our model against two state-of-the-art approaches: B1 [36] and B2 [3].", "startOffset": 225, "endOffset": 229}, {"referenceID": 1, "context": "In order to evaluate our CRF name entity recognition model and to assess the efficiency of the proposed classconditioned report catalogues, we compared the performance of our model against two state-of-the-art approaches: B1 [36] and B2 [3].", "startOffset": 237, "endOffset": 240}, {"referenceID": 1, "context": "Note that while B2 [3] method had been trained on a large corpus of approximately 8 million tweets collected from San Francisco, out CRF model was only trained on generic city-independent report catalogues of Table 1 which means we did not provide domain (city) specific prior knowledge for training our CRF model.", "startOffset": 19, "endOffset": 22}, {"referenceID": 1, "context": "In order to obtain the ground truth NER tags for this confusion matrix, we have used the same tagging schema as of proposed in [3], with the B- and I- prefixes referring to beginning and intermediate tags respectively where exist multiple consecutive tags in an entity phrase 21.", "startOffset": 127, "endOffset": 130}, {"referenceID": 1, "context": "[3], subtle changes in context result in diverse interpretation of Tweet and subtle difference in location and event references and can cause loss of precision.", "startOffset": 0, "endOffset": 3}, {"referenceID": 1, "context": "This Location tagging enhancement is important in our framework since it will enable us to assign more accurate locations to each extracted event rather than assigning the events to their tweeted locations 22 which was reported in previous studies [3].", "startOffset": 248, "endOffset": 251}, {"referenceID": 1, "context": "Unlike the San Francisco test data [3], the London1 data has not been cleaned prior to evaluations.", "startOffset": 35, "endOffset": 38}, {"referenceID": 1, "context": "The main reason is that the San Francisco data which had been used in previous experiments had gone through additional data cleanings (see details in [3]) prior to testing which in turn helped in leveraging the final performance.", "startOffset": 150, "endOffset": 153}, {"referenceID": 1, "context": "As mentioned before, this degradation was expected, as unlike the San Francisco data (the collection and filtering described in [3]), non of the London datasets has been cleaned prior to the system annotation.", "startOffset": 128, "endOffset": 131}, {"referenceID": 41, "context": "[43] proposed to model the intrinsic geometry of tweets through a low-rank, non-linear manifold to visualize the tweets distribution in a two dimensional Euclidean space, in this study we have focused on a visualisation in the real space.", "startOffset": 0, "endOffset": 4}], "year": 2017, "abstractText": "Cities have been a thriving place for citizens over the centuries due to their complex infrastructure. The emergence of the Cyber-Physical-Social Systems (CPSS) and context-aware technologies boost a growing interest in analysing, extracting and eventually understanding city events which subsequently can be utilised to leverage the citizen observations of their cities. In this paper, we investigate the feasibility of using Twitter textual streams for extracting city events. We propose a hierarchical multi-view deep learning approach to contextualise citizen observations of various city systems and services such as traffic, public transport, weather, sociocultural activities and public safety as a source of city events. Our goal has been to build a flexible architecture that can learn representations useful for tasks, thus avoiding excessive task-specific feature engineering. We apply our approach on a real-world dataset consisting of event reports and tweets collected by [3] over four months from San Francisco Bay Area dataset and additional datasets collected from Greater London. The results of our evaluations show that our proposed solution outperforms the existing models and can be used for extracting city related events with an averaged accuracy of 81% over all classes. To further evaluate the impact of our Twitter event extraction model, we have used two sources of authorised reports through collecting road traffic disruptions data from Transport for London API, and parsing the Time Out London website for sociocultural events. The analysis showed that 49.5% of the Twitter traffic comments are reported approximately five hours prior to the authorities official records. Moreover, we discovered that amongst the scheduled sociocultural event topics; tweets reporting transportation, cultural and social events are 31.75% more likely to influence the distribution of the Twitter comments than sport, weather and crime topics.", "creator": "TeX"}}}