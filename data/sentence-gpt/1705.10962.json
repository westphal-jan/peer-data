{"id": "1705.10962", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "31-May-2017", "title": "Analysis of the Effect of Dependency Information on Predicate-Argument Structure Analysis and Zero Anaphora Resolution", "abstract": "This paper investigates and analyzes the effect of dependency information on predicate-argument structure analysis (PASA) and zero anaphora resolution (ZAR) for Japanese, and shows that a straightforward approach of PASA and ZAR works effectively even if dependency information was not available. We constructed an analyzer that directly predicts relationships of predicates and arguments with their semantic roles from a POS-tagged corpus. The features of the system are designed to compensate for the absence of syntactic information by using features used in dependency parsing as a reference to the semantics of the dependency information.", "histories": [["v1", "Wed, 31 May 2017 07:32:29 GMT  (175kb,D)", "http://arxiv.org/abs/1705.10962v1", null]], "reviews": [], "SUBJECTS": "cs.CL", "authors": ["koichiro yoshino", "shinsuke mori", "satoshi nakamura"], "accepted": false, "id": "1705.10962"}, "pdf": {"name": "1705.10962.pdf", "metadata": {"source": "CRF", "title": "Analysis of the Effect of Dependency Information on Predicate-Argument Structure Analysis and Zero Anaphora Resolution", "authors": ["Koichiro Yoshino", "Shinsuke Mori", "Satoshi Nakamura"], "emails": ["s-nakamura@is.naist.jp", "mori.shinsuke.8u@kyoto-u.ac.jp"], "sections": [{"heading": "1 Introduction", "text": "Predicate-argument structure (PAS) including zero anaphora is one of the most fundamental and classical components of natural language processing (NLP). Many NLP applications utilize PAS, such as machine translation (Zhai et al., 2013), question answering (Shen and Lapata, 2007) and dialogue systems (Yoshino et al., 2011).\nConventionally, the PAS analysis (PASA) architecture stands on the pipeline processing of NLP. It is assumed that the analyzer receives the correct results of various preprocessing steps such as word segments (WSs) and part of speech (POS) tags from\na morphological analyzer, and dependency structures from a dependency parser. However, underlying this assumption requires the costly processes of preparing an accurate morphological analyzer and dependency parser for its domain or application. Actually the accuracies of dependency parsers are still not sufficient (around or less than 90%) (Kudo and Matsumoto, 2002; Flannery et al., 2011) to use as input of PASA even if the parser is adapted to the target domain. This is in contrast to morphological analyzers adapted to the target domain (Neubig et al., 2011), which have accuracies of more than 96%. Furthermore, the cost for constructing a dependency parser adapted to the target domain is much higher than the cost of construction of a domain adapted morphological analyzer, in both of data preparation and parser adaptation.\nHowever, this approach still requires a domain adapted dependency parser. In (Yoshino et al., 2013), they proposed a straightforward framework that does not require any syntactic information, and directly predicts the pair of a predicate and an argument that has a relationship of semantic role from an entire document. However, this work did not compare with a PAS analyzer that uses dependency information. This paper follows our previous approach to construct a PAS analyzer that does not assume dependencies as input, compares it with a PAS analyzer that uses dependencies, and investigates the effect of dependency information. This paper also studies influences of parsing errors and the cost of parser construction, which we often encounter in real language processing. The straightforward framework allows us to be free from costly ar X iv :1\n70 5.\n10 96\n2v 1\n[ cs\n.C L\n] 3\n1 M\nay 2\nprocesses of the data preparation and preprocessor construction if the accuracy is enough (Zhou and Xu, 2015)."}, {"heading": "2 Predicate Argument Structure Analysis (PASA)", "text": "The PAS is a relationship between a predicate, a verb or an indeclinable word (noun, adjective, and adjective verbs) that indicates an event, and its arguments. A predicate Pi in a document D has arguments Ai1 , Ai2 , ..., Aij that have semantic roles Si1 , Si2 , ..., Sij . We show an example of a PAS in Figure 1. In the example, predicates P1=fate, P2=bet, P3=concept, P4=fulfill, and P5=address are given, and they have corresponding arguments A11=party,...,A5j=fulfillment with semantic roles S11=ga,...,S5j=ni (gray boxes are predicates). Predicates can take the other predicates as their argument. For example, P5=address takes fulfillment as its ni-case, although the fulfillment is also a predicate. The solid arrows (upper half of the figure) represent dependencies, and the leaves depend on the heads (dependency information does not include labels of edges). Semantic role labels are annotated to the dependency edges (ellipsoidal labels). Language dependent label values of these labels are defined in the shared task of semantic role labeling (SRL) (Hajic\u030c et al., 2009), respectively. The example in the figure is a Japanese sentence. In Japanese, the defined labels are ga (=nominative case), wo (=accusative case) and ni (=dative case). Gray solids lines are dependencies that do not have defined semantic roles. The dotted arrows (lower half of the figure) denote zero anaphora, which occur frequently in Japanese, and express predicate-argument relationships between words which do not have dependency relations. The defined label-set is the same as the SRL label-set. The task of predicting the zero anaphora in particular is called zero anaphora resolution (ZAR) (Iida et al., 2007a; Sasano and Kurohashi, 2009; Iida and Poesio, 2011). The example only shows zero anaphora relations between words in the same sentence, but zero anaphora relations also exist between words in different sentences. ZAR is closely related to the coreference resolution task (Iida. et al., 2003) that predicts identical elements in the real world written in a docu-\nment. If some words are identified as a coreference, each word of a coreferential cluster takes the same role of the same predicate. In the example, the relation between the Socialist party and the party is a coreference, and both words take the ga label of predicates, fate, bet, fulfillment, and address.\nThe task of PASA is that of predicting arguments and their semantic roles for given predicates. Conventional PAS analyzers output only one argument in one semantic role for a predicate and coreference resolution, post-processing, disambiguates the problem of multi arguments of a predicate in the same semantic role (e.g. both of Socialist party and party is ga (nominative case) argument of address) (Matsubayashi et al., 2012). This paper follows this protocol, and defines the PASA task to output one argument in one semantic role for a predicate. In other words, the task of PASA is predicting a part of a coreferential cluster that takes a semantic role for the given predicate. In the example, for P5=address, the analyzer outputs one of Socialist party or party as the semantic role ga (nominative case)."}, {"heading": "3 Pointwise Predicate-Argument Structure Analysis", "text": "Pointwise PASA (PWPASA) is a framework that predicts relations between every word in a document and a given predicate independently from other predicates with a binary classifier (Yoshino et al., 2013). One of the advantages of the pointwise approach is that the classifier does not depend on other tasks of NLP, whose prediction accuracy may not be sufficiently high (Neubig et al., 2011; Mori and Neubig, 2011). The PWPASA does not essentially require global structures such as dependencies, and can be used to create a PASA model that does not refer to dependency information."}, {"heading": "3.1 Model of Prediction", "text": "PWPASA handles the problem of PASA as a binary classification problem for every pair of an argument candidate and a predicate. Labeled pairs of an argument and a predicate are used as positive training examples (P) and unlabeled pairs are used as negative training examples (N). In the example of Figure 2, the upper box shows training examples for the ga-intra classifier. The pair of \u201cfate\u201d and\nOriginal: \u793e\u4f1a\u515a\u306f\u4eca\u5e74\u515a\u306e\u5b58\u4ea1\u3092\u304b\u3051\u305f\u2ea0\u4e3b\u30ea\u30d9\u30e9\u30eb\u69cb\u60f3\u306e\u5b9f\u73fe\u306b\u53d6\u308a\u7d44\u3080 Translation: The Socialist party addresses to fulfill the liberal democratic party concept which they bet the fate of the party in this year.\n\u201cparty\u201d, and the pair of \u201cfate\u201d and \u201cSocialist party\u201d are positive examples, and pairs of \u201cfate\u201d and other candidates are negative. Similarly the bottom box shows some training examples for the wo-intra classifier converted from the example in Figure 1. The system consists of 3\u00d72=6 classifiers in total: ga (nominative case), wo (accusative case) and ni (dative case) for intra-sentence (intra) or inter-sentence (inter) cases. The intra classifiers are trained from all pairs of a predicate and every word in the same sentence, and inter ones are trained from all pairs of predicates and every word in different sentences.\nThe PASA task expects to output one argument for one predicate in one semantic role. However, the PWPASA outputs several argument candidates for a predicate in one semantic role, thus, we used a logistic regression (LR) classifier to select the best candi-\ndate and its prediction probability. As shown in Figure 3, classifiers for the same semantic role output several classification results. Here, ID is word ID and S-ID is sentence ID. The classification results sometimes conflict because the labeling for each pair of an argument candidate and a predicate is independent. (\u201cTokyo\u201d and \u201cpewit gull\u201d are classified into nominatives of the predicate \u201ctangle\u201d in the example of Figure 3). The system outputs one result that has the highest probability of the LR classifiers for one semantic role to a predicate. In the example shown in Figure 3, the results of \u201cTokyo\u201d and \u201cpewit gull\u201d for \u201ctangle\u201d conflict. In this case, the system chooses one of them for the nominative case with the prediction probabilities of LR.\n3.2 Features for PWPASA (PWFeat)\nFeature design is the most important aspect of the PWPASA. The classifier does not use information given by dependencies, but it indirectly refers to the information by using features that reflect dependency relationships. In the subsequent explanations, features indicated by \u2020 are ones generally used in the dependency parsing (Flannery et al., 2011).\n1. \u2020Word n-gram: Uni-grams of words located between -10 \u2013 and +10 positions around the predicate (wp\u221210\u2013wp+10) and the argument candidate (wa\u221210\u2013wa+10), bi-grams and tri-grams of words located -5 \u2013 +5 around the predicate and the argument (wp\u22125wp\u22124, ..., wp+4wp+5, wa\u22125wa\u22124, ..., wa+4wa+5, wp\u22125wp\u22124wp\u22123, ..., wp+3wp+4wp+5 and wa\u22125wa\u22124wa\u22123, ..., wa+3wa+4wa+5). 2. \u2020POS n-gram: Uni-grams, bi-grams and trigrams of POS tags of the surrounding words. 3. \u2020Pairwise word and POS: The pair of the word of the predicate and the argument candidate (wp+0wa+0) and pairs of POS tags of surrounding words located -2 \u2013 +2 (t(wp\u22122)t(wa\u22122), t(wp\u22122)t(wa\u22121), ..., t(wp+2)t(wa+2)). 4. \u2020Word Distance: The number of words between the predicate and the argument candidate. The number as is, and divided and rounded values with 2, 3, 4 and 5. The word distance features take integer values which include negative integers, to make distinction of right and left of the predicate. 5. Predicate Distance: The number of predicates between the predicate and the candidate. 6. Gold case frame: The gold case frame of the target predicate. This information is similar to the results of the word sense disambiguation. An example is shown in Figure 4. If the word sense disambiguation worked perfectly, the system knows that the ga and the wo label is essential for the predicate \u201cfulfill\u201d, and\nthese arguments exist somewhere in the document. On the other hand, system can know that it is not necessary to find an argument that takes the role of ni. This feature is introduced as a binary flag for every semantic role."}, {"heading": "3.3 Features for PWPASA that Depend on", "text": "Language (Lang)\nThe other important viewpoint is language dependence. We list language dependent features of Japanese PASA.\n1. Case Marker Word on the Right Side: Case marker words (ha), (ga), (wo) and (ni) on the right side. 2. Candidate Position: The candidate position in a document is used as a feature. 3. Case Marker Word Distance: Number of case markers words between the predicate and the argument candidate. 4. Pair of Predicate Distance and Case Marker Word Distance: Pairwise features of the predicate distance and the case marker word distance.\n3.4 Features of Dependency Information (Dep) This section describes features referring to dependency information to compare with the pointwise analyzer (PWPASA). PASA with dependency introduces two kinds of dependency features generally used for PASA. We selected features which improve the SRL accuracy significantly in a previous study (Bjo\u0308rkelund et al., 2009).\n1. Dependency Relation between Predicate and Argument Candidate: The dependency relation between the predicate and the argument candidate. We introduced the direct dependency relation feature for distance of up to 3 steps. Figure 5 shows examples of this feature. 2. Head and Leaf Words: Head word of the predicate (wph), the head word of the argument\ncandidate (wah), and the leaf words of the predicate (wpl1 , ...,wpli ) and the leaf words of the argument candidate (wal1 , ...,walj ). For example in Figure 5, the head of \u201cconcept\u201d is \u201cfulfillment\u201d, and leafs of it are \u201cbet\u201d and \u201cliberal democratic party\u201d."}, {"heading": "4 Experimental Evaluation", "text": "We investigated the effect of the dependency information on PASA including ZAR by comparing the proposed analyzer which does not use the dependency information and a more traditional system that uses dependency information. All of experimental conditions except for the dependency information are the same. We constructed two systems that do not use dependency information; PWFeat and PWFeat+Lang, and three systems that use dependency information; oracle dependency (PWFeat+Lang+Dep(oracle)), real parsing results (PWFeat+Lang+Dep(parsed)), and simulated parsing results with 20% errors (PWFeat+Lang+Dep(20% errors)). Used feature type is indicated in names, PWFeat means using features for PWPASA, Lang means using language dependent features, and Dep means using features of dependency information. For parsed, we used a phrase-based dependency parser CaboCha (Kudo and Matsumoto, 2002), which is retrained by the following training set of the PASA. The parsing accuracy was 86.12% (the parsing result includes 13.88% errors)."}, {"heading": "4.1 Experimental Setting", "text": "We used the NAIST Text Corpus (NTC) (Iida et al., 2007b), a corpus which is publicly available1. The documents are annotated with predicate-argument relations and coreferences. The sentences also have lower layer annotations: word boundaries, POS tags, chunks, and phrase-based dependencies. The annotated predicates include not only verbs but also in-\n1https://sites.google.com/site/naisttextcorpus (2015/5/30)\ndeclinable words which indicate events. The NTC contains Japanese newspaper articles and editorials. There are three different types of annotation on pairs of a predicate and its argument in Japanese: ga (nominative case), wo (accusative case) and ni (dative case).\nWe divided the NTC into training and test set. Their specifications are shown in Table 1. The table shows the numbers of documents, sentences, words, predicates and PAS labels annotated on pairs of a predicate and its argument. The PAS label numbers include several labels that indicate the same coreferential cluster from the same predicate in the same semantic role (In the example of Figure 1, there are two arcs with a ga (nominative case) labels from \u201cfulfillment\u201d to \u201cSocialist party\u201d and \u201cparty\u201d, and \u201cSocialist party\u201d and \u201cparty\u201d belong to the same coreferential cluster). As the classifier, we used LIBLINEAR2, a library for large linear classification (Fan et al., 2008), with L2-loss linear logistic regression (LR). We evaluated the system performance by using precision (P), recall (R), and their harmonic mean (F-measure; F)."}, {"heading": "4.2 Effect of Dependency Information", "text": "Table 2 shows a summary in several settings. PWFeat+Lang is the result of the proposed PASA\n2http://www.csie.ntu.edu.tw/ cjlin/liblinear (2015/5/30)\nanalyzer that does not use dependency information. Dependency features (Dep) are additionally used in different settings: oracle (gold dependencies), parsed (real parsing results including errors), and 20% errors (simulated parsing results including 20% errors). Table 3 shows the detailed results of the PWPASA analyzer that does not use the dependency information (PWFeat+Lang), and Table 4 and Table 5 show the results of the analyzers that additionally use the dependency information (PWFeat+Lang+Dep(oracle) and PWFeat+Lang+Dep(parsed)). Role type is the type of PAS labels (ga, wo, ni in Japanese), category is the relation type of the argument and the predicate. \u201cDepend\u201d means an element of the coreferential cluster of the argument have a dependency relation to the predicate. \u201cZero intra\u201d means that one or more elements of the coreferential cluster exist in the same sentence as the predicate, but they do not depend on the predicate. \u201cZero inter\u201d does not include any element that exists in the same sentence of the predicate.\nIn total accuracy (ALL-ALL), the F-measure of PWFeat+Lang was 63.56, 2.70 points lower than PWFeat+Lang+Dep(oracle). The difference is statistically significant (p<0.01), however, it requires the oracle dependency information. If the dependency was a real parsing result including errors (PWFeat+Lang+Dep(parsed)), the difference of F-measure compared to the PWFeat+Lang\nis much smaller, 2.05 points. This indicates that the dependency features is still effective even if some features used in dependency parsing are indirectly used for the PAS analyzer, however, the accuracy of PWFeat+Lang closes in upon PWFeat+Lang+Dep(oracle). These results also indicate that the parsing errors do not fatally influence the PASA accuracy, if the parser is trained in the same domain. On the other hand, the dependency parser requires annotations of 24,283 sentences for the 2.05 points improvement. In our other experiment, annotation speed of dependency was 22.40 sentences (consisting of 24.76 words) per hour (74,865[sent.]/135[hour]), in other words, 509.76 words per hour. Preparing dependency information is an indirect method for domain adaptation of PASA, and the data preparation cost is very high. The annotation of dependencies is very difficult for untrained annotators, and it requires spending a lot of time and energy of the developers.\nIf the parser is not adapted to the target domain, the parsing error rate reaches up to 20% (Flannery et al., 2011). We simulated parsing errors of the test set by randomly replacing a predefined proportion of the edges of the gold data of dependency, and used it on the test set (PWFeat+Lang+Dep(20% errors)). The total accuracy (ALL-ALL) of the PWFeat+Lang model was comparable to the result of the 20% noisy test-set. These results show that the result of a dependency parser achieves this low level of accuracy, because it is not adapted to the domains is not helpful for PASA.\nIn detailed categories, we compared the analyzer that does not use the dependency information (PWFeat+Lang) and the analyzer that uses real parsing results (PWFeat+Lang+Dep(parsed)). The F-measure of the nominative cases that directly depend on predicates (ga (nom.)-Depend) was mainly decreased by the absence of the dependency information (from 76.70 points to 72.21 points). On\nthe other hand, F-measures of the accusative and the dative cases, which depend on predicates (wo (acc.)Depend and ni (dat.)-Depend), PWFeat+Lang performs comparably to the analyzer that uses the dependency information. These results show that the dependency information contributes to predict nominative cases that exist at more distant positions from predicates than accusative cases, especially in SOV languages.\nIn category of Zeros (Zero (intra) and Zero (inter); arguments which do not depend on their predicates, the dependency information negatively influenced all categories. In the Zero intra category (see ALL-Zero (intra) of Table 3, Table 4 and Table 5), the F-measure of the PWFeat+Lang model was 1.74 points (33.26-31.52) better than the F-measure of the PWFeat+Lang+Dep(parsed) model, and 4.42 points (33.26-28.84) better than\nthe F-measure of the PWFeat+Lang+Dep(oracle) with a statistical significance (p<0.01). In Zero inter category (see ALL-Zero (inter) of Table 3, Table 4 and Table 5), the difference was not significant but the F-measure of the PWFeat+Lang model was also better than Fmeasures of the PWFeat+Lang+Dep(oracle) and the PWFeat+Lang+Dep(parsed). This is caused by the fact that the dependency information gives a strong prior to select an argument candidate that depends on the predicate, even if the candidate is not an argument."}, {"heading": "4.3 Effect of language specific features", "text": "We also prepared the analyzer that does not use language specific features of the PWPASA (features described in Section 3.3) to verify the generality of the constructed PWFeat+Lang. By comparing to PWFeat and PWFeat+Lang in Table 2, the total accuracy (ALL-ALL) was decreased by 1.08 points by the lack of the language specific features. It shows that there is a certain level of generality of the PWFeat+Lang model that covers the dependency information with indirect features."}, {"heading": "5 Related Studies", "text": "In the CoNLL shared task 2004 (Carreras and Ma\u0300rquez, 2004; Hacioglu et al., 2004), some systems tackled SRL only with shallow syntax structures; chunks and clauses. In CoNLL shared task 2005 (Carreras and Ma\u0300rquez, 2005; Koomen et al., 2005), more deep syntax structures, dependencies, are provided, and the best system outperformed the best system of CoNLL shared task 2004. However, effects of parsing errors are not deeply analyzed, and these tasks only target labeling semantic roles between elements in the same sentences.\nWhile applications that use PAS demand higher accuracy of PASA in various domains (Imamura et al., 2014), however, it is difficult to improve the accuracy of PASA on a variety of domains because of the lack of annotated corpora in each domain. Constructing new annotated corpora in the new domains is very costly, thus, some previous studies tried to ignore the problem. Semi-supervised and unsupervised approaches (Fu\u0308rstenau and Lapata, 2009; Titov and Klementiev, 2012; Lorenzo and Cerisara,\n2014) tried to improve the accuracy of labeling with unlabeled data, but they did not provide much of an improvement from the unlabeled data. (Ribeyre et al., 2015) also researched the effect of syntax information for English SRL, and reported a 2.80 point improvement of accuracy. Our work focuses on not only SRL but also ZAR.\nHaving training data that are representative of the domain is essential for constructing a robust PAS analyzer (Pradhan et al., 2008). However, data annotation of the higher-layer NLP tasks such as PASA require not only the annotations for the task but also those of lower-layer NLP task, such as dependencies. This property makes it difficult to apply the current supervised approaches to a new domain. Our work tackled this problem by avoiding to analyzing the dependency structure.\nIn the PASA and the ZAR of Japanese, (Imamura et al., 2009) addressed PASA and ZAR with a discriminative model for only verbal predicates. The total accuracy of our work is less than their work, but our system addressed both PASA and ZAR not only for verbal predicates but also for indeclinable predicates which indicate events. Our system also worked better in ZAR of accusative and dative cases. (Sasano and Kurohashi, 2011) proposed a discriminative ZAR model. Our system worked better than their work in the accusative case (wo) and the dative case (ni), but their system worked better in the nominative case (ga)."}, {"heading": "6 Conclusion", "text": "This paper clarified the effect of the dependency information in an PASA by comparing the analyzer that does not use dependency information, an analyzer that uses oracle dependency information, and an analyzer that uses real parsing result including\nparsing errors. The result indicated that dependency information improves PASA. Because analyzers using the dependency information require dependency annotation and parser construction, the cost is very high, which is disproportionate to the improvement in accuracy as shown in Figure 6. The experimental results showed that the indirect features, which compensate for the absence of dependency features, worked well enough. By considering the cost of preparing dependency information, the accuracy is reasonable to use in the realistic situations. We plan to design a framework of rapid data preparation, and adopt the system to a variety of domains in the future."}], "references": [{"title": "Multilingual semantic role labeling", "author": ["Love Hafdell", "Pierre Nugues"], "venue": "In Proceedings of the Thirteenth Conference on Computational Natural Language Learning: Shared Task,", "citeRegEx": "Bj\u00f6rkelund et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Bj\u00f6rkelund et al\\.", "year": 2009}, {"title": "Introduction to the conll-2004 shared task: Semantic role labeling", "author": ["Carreras", "M\u00e0rquez2004] Xavier Carreras", "Llu\u0131\u0301s M\u00e0rquez"], "venue": "In Proceedings of the CoNLL-2004", "citeRegEx": "Carreras et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Carreras et al\\.", "year": 2004}, {"title": "Introduction to the conll-2005 shared task: Semantic role labeling", "author": ["Carreras", "M\u00e0rquez2005] Xavier Carreras", "Llu\u0131\u0301s M\u00e0rquez"], "venue": "In Proceedings of the 9th Conference on Computational Natural Language Learning,", "citeRegEx": "Carreras et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Carreras et al\\.", "year": 2005}, {"title": "Liblinear: A library for large linear classification", "author": ["Fan et al.2008] Rong-En Fan", "Kai-Wei Chang", "Cho-Jui Hsieh", "Xiang-Rui Wang", "Chih-Jen Lin"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Fan et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Fan et al\\.", "year": 2008}, {"title": "Training dependency parsers from partially annotated corpora", "author": ["Yusuke Miyao", "Graham Neubig", "Shinsuke Mori"], "venue": "In Proceedings of the 5th International Joint Conference on Natural Language Processing,", "citeRegEx": "Flannery et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Flannery et al\\.", "year": 2011}, {"title": "Semi-supervised semantic role labeling", "author": ["F\u00fcrstenau", "Lapata2009] Hagen F\u00fcrstenau", "Mirella Lapata"], "venue": "In Proceedings of the 12th Conference of the European Chapter of the Association for Computational Linguistics,", "citeRegEx": "F\u00fcrstenau et al\\.,? \\Q2009\\E", "shortCiteRegEx": "F\u00fcrstenau et al\\.", "year": 2009}, {"title": "Centering a framework for modeling the local coherence of discourse", "author": ["Scott Weinstein", "Aravind K. Joshi"], "venue": null, "citeRegEx": "Grosz et al\\.,? \\Q1995\\E", "shortCiteRegEx": "Grosz et al\\.", "year": 1995}, {"title": "The CoNLL2009 shared task: syntactic and semantic dependencies in multiple languages", "author": ["Haji\u010d et al.2009] Jan Haji\u010d"], "venue": "In Proceedings of CoNLL: Shared Task,", "citeRegEx": "Haji\u010d,? \\Q2009\\E", "shortCiteRegEx": "Haji\u010d", "year": 2009}, {"title": "A cross-lingual ilp solution to zero anaphora resolution", "author": ["Iida", "Poesio2011] Ryu Iida", "Massimo Poesio"], "venue": "In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies,", "citeRegEx": "Iida et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Iida et al\\.", "year": 2011}, {"title": "Incorporating contextual cues in trainable models for coreference resolution", "author": ["Iida. et al.2003] Ryu Iida", "Kentaro Inui", "Hiroya Takamura", "Yuji Matsumoto"], "venue": "In Proceedings of 10th Conference of the European Chapter of the Association", "citeRegEx": "Iida. et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Iida. et al\\.", "year": 2003}, {"title": "Zero-anaphora resolution by learning rich syntactic pattern features", "author": ["Iida et al.2007a] Ryu Iida", "Kentaro Inui", "Yuji Matsumoto"], "venue": "ACM Transactions on Asian Language Information Processing (TALIP),", "citeRegEx": "Iida et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Iida et al\\.", "year": 2007}, {"title": "Annotating a Japanese text corpus with predicate-argument and coreference relations", "author": ["Iida et al.2007b] Ryu Iida", "Mamoru Komachi", "Kentaro Inui", "Yuji Matsumoto"], "venue": "In Proceedings of the Linguistic Annotation Workshop,", "citeRegEx": "Iida et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Iida et al\\.", "year": 2007}, {"title": "Discriminative approach to predicate-argument structure analysis with zeroanaphora resolution", "author": ["Kuniko Saito", "Tomoko Izumi"], "venue": "In Proceedings of the ACLIJCNLP 2009 Conference Short Papers,", "citeRegEx": "Imamura et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Imamura et al\\.", "year": 2009}, {"title": "Predicate argument structure analysis with zero-anaphora resolution for dialogue systems", "author": ["Ryuichiro Higashinaka", "Tomoko Izumi"], "venue": "In Proceedings of the 25th International Conference on Computational", "citeRegEx": "Imamura et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Imamura et al\\.", "year": 2014}, {"title": "Generalized inference with multiple semantic role labeling systems", "author": ["Koomen et al.2005] Peter Koomen", "Vasin Punyakanok", "Dan Roth", "Wen-tau Yih"], "venue": "In Proceedings of the 9th Conference on Computational Natural Language Learning,", "citeRegEx": "Koomen et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Koomen et al\\.", "year": 2005}, {"title": "Japanese dependency analysis using cascaded chunking", "author": ["Kudo", "Matsumoto2002] Taku Kudo", "Yuji Matsumoto"], "venue": "In Proceedings of the 6th Conference on Natural Language Learning - Volume", "citeRegEx": "Kudo et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Kudo et al\\.", "year": 2002}, {"title": "Semi-supervised srl system with bayesian inference", "author": ["Lorenzo", "Cerisara2014] Alejandra Lorenzo", "Christophe Cerisara"], "venue": null, "citeRegEx": "Lorenzo et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Lorenzo et al\\.", "year": 2014}, {"title": "Building japanese predicate-argument structure corpus using lexical conceptual structure", "author": ["Yusuke Miyao", "Akiko Aizawa"], "venue": "In Proceedings of The eighth international conference on Language", "citeRegEx": "Matsubayashi et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Matsubayashi et al\\.", "year": 2012}, {"title": "A pointwise approach to pronunciation estimation for a TTS front-end", "author": ["Mori", "Neubig2011] Shinsuke Mori", "Graham Neubig"], "venue": "In Proceedings of INTERSPEECH,", "citeRegEx": "Mori et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Mori et al\\.", "year": 2011}, {"title": "Pointwise prediction for robust, adaptable Japanese morphological analysis", "author": ["Neubig et al.2011] Graham Neubig", "Yosuke Nakata", "Shinsuke Mori"], "venue": "In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics,", "citeRegEx": "Neubig et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Neubig et al\\.", "year": 2011}, {"title": "Towards robust semantic role labeling", "author": ["Wayne Ward", "James H. Martin"], "venue": "Computational Linguistics,", "citeRegEx": "Pradhan et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Pradhan et al\\.", "year": 2008}, {"title": "Because syntax does matter: Improving predicate-argument structures parsing with syntactic features", "author": ["Eric Villemonte de la Clergerie", "Djam\u00e9 Seddah"], "venue": "In Proceedings of the Ninth Conference on Computational Natu-", "citeRegEx": "Ribeyre et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Ribeyre et al\\.", "year": 2015}, {"title": "A probabilistic model for associative anaphora resolution", "author": ["Sasano", "Kurohashi2009] Ryohei Sasano", "Sadao Kurohashi"], "venue": "In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing,", "citeRegEx": "Sasano et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Sasano et al\\.", "year": 2009}, {"title": "A discriminative approach to Japanese zero anaphora resolution with large-scale case frames", "author": ["Sasano", "Kurohashi2011] Ryohei Sasano", "Sadao Kurohashi"], "venue": "Journal of Information Processing (in Japanese),", "citeRegEx": "Sasano et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Sasano et al\\.", "year": 2011}, {"title": "Using semantic roles to improve question answering", "author": ["Shen", "Lapata2007] Dan Shen", "Mirella Lapata"], "venue": "In Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning,", "citeRegEx": "Shen et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Shen et al\\.", "year": 2007}, {"title": "Semi-supervised semantic role labeling: Approaching from an unsupervised perspective", "author": ["Titov", "Klementiev2012] Ivan Titov", "Alexandre Klementiev"], "venue": "In Proceedings of the 24th International Conference on Computational Linguistics,", "citeRegEx": "Titov et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Titov et al\\.", "year": 2012}, {"title": "A structured model for joint learning of argument roles and predicate senses", "author": ["Masayuki Asahara", "Yuji Matsumoto"], "venue": "In Proceedings of the 48th Annual Meeting of the Association", "citeRegEx": "Watanabe et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Watanabe et al\\.", "year": 2010}, {"title": "Spoken dialogue system based on information extraction using similarity of predicate argument structures", "author": ["Shinsuke Mori", "Tatsuya Kawahara"], "venue": "In Proceedings of the 12th Annual Meeting of the Special Interest Group", "citeRegEx": "Yoshino et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Yoshino et al\\.", "year": 2011}, {"title": "Predicate argument structure analysis using partially annotated corpora", "author": ["Shinsuke Mori", "Tatsuya Kawahara"], "venue": "In Proceedings of the 6th International Joint Conference on Natural Language Processing,", "citeRegEx": "Yoshino et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Yoshino et al\\.", "year": 2013}, {"title": "Handling ambiguities of bilingual predicate-argument structures for statistical machine translation", "author": ["Zhai et al.2013] Feifei Zhai", "Jiajun Zhang", "Yu Zhou", "Chengqing Zong"], "venue": "In Proceedings of the 51st Annual Meeting of the Association", "citeRegEx": "Zhai et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Zhai et al\\.", "year": 2013}, {"title": "End-toend learning of semantic role labeling using recurrent neural networks", "author": ["Zhou", "Xu2015] Jie Zhou", "Wei Xu"], "venue": "In the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language", "citeRegEx": "Zhou et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Zhou et al\\.", "year": 2015}], "referenceMentions": [{"referenceID": 29, "context": "Many NLP applications utilize PAS, such as machine translation (Zhai et al., 2013), question answering (Shen and Lapata, 2007) and dialogue systems (Yoshino et al.", "startOffset": 63, "endOffset": 82}, {"referenceID": 27, "context": ", 2013), question answering (Shen and Lapata, 2007) and dialogue systems (Yoshino et al., 2011).", "startOffset": 73, "endOffset": 95}, {"referenceID": 4, "context": "Actually the accuracies of dependency parsers are still not sufficient (around or less than 90%) (Kudo and Matsumoto, 2002; Flannery et al., 2011) to use as input of PASA even if the parser is adapted to the target domain.", "startOffset": 97, "endOffset": 146}, {"referenceID": 19, "context": "This is in contrast to morphological analyzers adapted to the target domain (Neubig et al., 2011), which have accuracies of more than 96%.", "startOffset": 76, "endOffset": 97}, {"referenceID": 28, "context": "In (Yoshino et al., 2013), they proposed a straightforward framework that does not require any syntactic information, and directly predicts the pair of a predicate and an argument that has a relationship of semantic role from an entire document.", "startOffset": 3, "endOffset": 25}, {"referenceID": 9, "context": "ZAR is closely related to the coreference resolution task (Iida. et al., 2003) that predicts identical elements in the real world written in a document.", "startOffset": 58, "endOffset": 78}, {"referenceID": 17, "context": "both of Socialist party and party is ga (nominative case) argument of address) (Matsubayashi et al., 2012).", "startOffset": 79, "endOffset": 106}, {"referenceID": 28, "context": "Pointwise PASA (PWPASA) is a framework that predicts relations between every word in a document and a given predicate independently from other predicates with a binary classifier (Yoshino et al., 2013).", "startOffset": 179, "endOffset": 201}, {"referenceID": 19, "context": "One of the advantages of the pointwise approach is that the classifier does not depend on other tasks of NLP, whose prediction accuracy may not be sufficiently high (Neubig et al., 2011; Mori and Neubig, 2011).", "startOffset": 165, "endOffset": 209}, {"referenceID": 4, "context": "In the subsequent explanations, features indicated by \u2020 are ones generally used in the dependency parsing (Flannery et al., 2011).", "startOffset": 106, "endOffset": 129}, {"referenceID": 0, "context": "We selected features which improve the SRL accuracy significantly in a previous study (Bj\u00f6rkelund et al., 2009).", "startOffset": 86, "endOffset": 111}, {"referenceID": 3, "context": "As the classifier, we used LIBLINEAR2, a library for large linear classification (Fan et al., 2008), with L2-loss linear logistic regression (LR).", "startOffset": 81, "endOffset": 99}, {"referenceID": 4, "context": "If the parser is not adapted to the target domain, the parsing error rate reaches up to 20% (Flannery et al., 2011).", "startOffset": 92, "endOffset": 115}, {"referenceID": 14, "context": "In CoNLL shared task 2005 (Carreras and M\u00e0rquez, 2005; Koomen et al., 2005), more deep syntax structures, dependencies, are provided, and the best system outperformed the best system of CoNLL shared task 2004.", "startOffset": 26, "endOffset": 75}, {"referenceID": 13, "context": "While applications that use PAS demand higher accuracy of PASA in various domains (Imamura et al., 2014), however, it is difficult to improve the accuracy of PASA on a variety of domains because of the lack of annotated corpora in each domain.", "startOffset": 82, "endOffset": 104}, {"referenceID": 21, "context": "(Ribeyre et al., 2015) also researched the effect of syntax information for English SRL, and reported a 2.", "startOffset": 0, "endOffset": 22}, {"referenceID": 20, "context": "Having training data that are representative of the domain is essential for constructing a robust PAS analyzer (Pradhan et al., 2008).", "startOffset": 111, "endOffset": 133}, {"referenceID": 12, "context": "In the PASA and the ZAR of Japanese, (Imamura et al., 2009) addressed PASA and ZAR with a discriminative model for only verbal predicates.", "startOffset": 37, "endOffset": 59}], "year": 2017, "abstractText": "This paper investigates and analyzes the effect of dependency information on predicateargument structure analysis (PASA) and zero anaphora resolution (ZAR) for Japanese, and shows that a straightforward approach of PASA and ZAR works effectively even if dependency information was not available. We constructed an analyzer that directly predicts relationships of predicates and arguments with their semantic roles from a POS-tagged corpus. The features of the system are designed to compensate for the absence of syntactic information by using features used in dependency parsing as a reference. We also constructed analyzers that use the oracle dependency and the real dependency parsing results, and compared with the system that does not use any syntactic information to verify that the improvement provided by dependencies is not crucial.", "creator": "LaTeX with hyperref package"}}}