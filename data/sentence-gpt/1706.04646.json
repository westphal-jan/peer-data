{"id": "1706.04646", "review": {"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "14-Jun-2017", "title": "Differentially Private Learning of Undirected Graphical Models Using Collective Graphical Models", "abstract": "We investigate the problem of learning discrete, undirected graphical models in a differentially private way. We show that the approach of releasing noisy sufficient statistics using the Laplace mechanism achieves a good trade-off between privacy, utility, and practicality. A naive learning algorithm that uses the noisy sufficient statistics \"as is\" outperforms general-purpose differentially private learning algorithms, but does not perform as well in general-purpose and non-parametric models. As we note in the previous post, we show that the current results have no good statistical power. However, we have tested the Laplace algorithm with non-parametric models of the sample, and found that it performs better in the general-purpose models in a general-purpose model, but does not perform as well in general-purpose and non-parametric models.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "histories": [["v1", "Wed, 14 Jun 2017 19:27:25 GMT  (5623kb,D)", "http://arxiv.org/abs/1706.04646v1", "Accepted to ICML 2017"]], "COMMENTS": "Accepted to ICML 2017", "reviews": [], "SUBJECTS": "cs.LG cs.CR stat.ML", "authors": ["garrett bernstein", "ryan mckenna", "tao sun", "daniel sheldon", "michael hay", "gerome miklau"], "accepted": true, "id": "1706.04646"}, "pdf": {"name": "1706.04646.pdf", "metadata": {"source": "CRF", "title": "Differentially Private Learning of Undirected Graphical Models Using Collective Graphical Models", "authors": ["Garrett Bernstein", "Ryan McKenna", "Tao Sun", "Daniel Sheldon", "Michael Hay", "Gerome Miklau"], "emails": ["<gbernstein@cs.umass.edu>."], "sections": [{"heading": "1. Introduction", "text": "Graphical models are a central tool in probabilistic modeling and machine learning. They pair expressive probability models with algorithms that leverage the graphical structure for efficient inference and learning. However, with data collection and modeling growing in importance in nearly all domains of society, there is increasing demand to apply graphical models in settings where the underlying data is sensitive and must be kept private. For example, consider applying graphical models to analyze electronic health records, with the goal of guiding public health policy. How can we derive these useful population-level outcomes without compromising the privacy of individuals?\n1University of Massachusetts Amherst 2Mount Holyoke College 3Colgate University. Correspondence to: Garrett Bernstein <gbernstein@cs.umass.edu>.\nProceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017. Copyright 2017 by the author(s).\nDifferential privacy is a widely studied formalism for private data analysis (Dwork et al., 2006). It provides a statistical privacy guarantee to individuals: the output of a differentially private algorithm is statistically nearly unchanged even if any single individual\u2019s record is added to or removed from the input data set. The general idea is to carefully randomize the algorithm so that the (random) output does not depend too much on any individual\u2019s data.\nDifferentially private machine learning cleanly addresses the problem of extracting useful population-level models from data sets while protecting the privacy of individuals. Indeed, this is an active and important research area (see Section 1.1), which includes private learning algorithms for a variety of general frameworks and specific machine learning models. This paper addresses the problem of privately learning parameters in a widely used class of probabilistic models: discrete, undirected graphical models. Although our problem can be cast in terms of general private learning frameworks, these do not lead to practical algorithms. Previous work also addresses private learning for directed graphical models (J. Zhang et al., 2014; Z. Zhang et al., 2016). Our problem of learning in undirected models, which are not locally normalized, is more general and substantially harder computationally.\nTo learn accurate models under differential privacy, it is critical to randomize the algorithm \u201cjust enough\u201d to achieve the desired privacy guarantee without diminishing the quality of the learned model too much. This is usually done by modifying a learning algorithm to add noise to some intermediate quantity X , with the noise magnitude calibrated to the sensitivity of X , a measure of how much X can depend on any single individual\u2019s data in the worst case (Dwork et al., 2006). The randomization renders the noisy estimate of X safe for release; all subsequent calculations using the noisy X , but not the original data, are also safe. Where should noise be injected into a machine learning algorithm to achieve the best utility? We highlight two highlevel goals: (1) Noise should be added at an \u201cinformation bottleneck\u201d, so the sensitivity is as small as possible relative to the information being sought,1 (2) noise should be\n1Sensitivity scales with the number of measurements; all else equal, a lower dimensional quantity will have lower sensitivity.\nar X\niv :1\n70 6.\n04 64\n6v 1\n[ cs\n.L G\n] 1\n4 Ju\nn 20\n17\nadded to a quantity for which the sensitivity can be bounded tightly, so the noise magnitude can be kept as small as possible. These two principles are often at odds. For example, adding noise to the final learned parameters \u03b8 (known as output perturbation; Dwork et al., 2006), is appealing from the information bottleneck standpoint, but if the learning algorithm is complex we may not be able to analyze the sensitivity and would have to rely on a coarse bound. Indeed, general private learning frameworks bound the sensitivity using quantities such as Lipschitz, strong-convexity, and smoothness constants (Bassily et al., 2014; Wu et al., 2016) or diameter of the parameter space (Smith, 2008), which may be loose in practice.\nIn this paper we will take the approach of adding noise to the sufficient statistics of a graphical model using the Laplace mechanism, a high-level approach that has also been applied recently for directed models (Zhang et al., 2016; Foulds et al., 2016). This has a number of advantages. First, sufficient statistics, by definition, are an information bottleneck. Second, it is very easy to exactly analyze the sensitivity of sufficient statistics in graphical models, which are contingency tables. Third, adding Laplace noise to contingency tables prior to release is very simple, so it is reasonable to imagine adoption in practice, say, by public agencies.\nHowever, it is not entirely clear how to learn parameters of a graphical model with noisy sufficient statistics. One option, which we will refer to as naive MLE, is to ignore the noise and conduct maximum-likelihood estimation as if we had true sufficient statistics. This works reasonably well in practice, and is competitive with or better than stateof-the-art general-purpose methods. In fact, we will show that naive MLE is consistent and achieves the same asymptotic mean-squared error as non-private MLE. However, at reasonable sample sizes the error due to privacy is significant, and the approach has several pathologies (see also Yang et al., 2012; Karwa et al., 2014; 2016), some of which make it difficult to apply in practice. Therefore, we adopt a more principled approach of performing inference about the true sufficient statistics within an expectationmaximization (EM) learning framework.\nThe remaining problem is how to conduct inference over sufficient statistics of a graphical model given noisy observations thereof. This is exactly the goal of inference in collective graphical models (CGMs; Sheldon & Dietterich, 2011), and we will adapt CGM inference techniques to solve this problem. Put together, our results significantly advance the state-of-the-art for privately learning discrete, undirected graphical models. We clarify the theory and practice of naive MLE. We show that it learns better models than existing state-of-the-art approaches in most scenarios across a broad range of synthetic tasks, and in experiments\nmodeling human mobility from wifi access point data. We then show the more principled approach of conducting inference with CGMs is superior to competing approaches in nearly all scenarios."}, {"heading": "1.1. Related Work", "text": "Differential privacy has been applied to many areas of machine learning, including learning specific models such as logistic regression (Chaudhuri & Monteleoni, 2009), support vector machines (Rubinstein et al., 2009), and deep neural networks (Abadi et al., 2016); privacy in general frameworks such as empirical risk minimization (ERM; Chaudhuri et al., 2011; Kifer et al., 2012; Jain & Thakurta, 2013; Bassily et al., 2014), gradient descent (Wu et al., 2016), and parameter estimation (Smith, 2011); and theoretical analysis of what can be learned privately (e.g., Blum et al., 2005; Kasiviswanathan et al., 2011).\nA key aspect of our work is conducting probabilistic inference over data or model parameters given knowledge of the probabilistic privacy mechanism and its output. Karwa et al. (2014; 2016) take a similar approach but for exponential random graph models, as do Williams & McSherry (2010), but for the factored exponential mechanism. Because sufficient statistics of graphical models are contingency tables, our work connects to the well-studied problem of releasing differentially private contingency tables (Barak et al., 2007; Yang et al., 2012; Hardt et al., 2012); we adopt the Laplace mechanism because it is simple and fits well within our learning framework.\nWe highlight connections between CGMs and differential privacy and adopt existing inference techniques for CGMs. In general, the inference problems we wish to solve are NP-hard (Sheldon et al., 2013), but a number of efficient approximate inference algorithms are available (Liu et al., 2014; Sun et al., 2015; Vilnis et al., 2015). In a paper that was primarily about CGM inference, Sun et al. (2015) conducted a case study using CGMs to privately learn Markov chains; we build on this approach, which was limited in scope and did not address general graph structures.\nOur work connects to an active current line of work on private probabilistic inference, some of which directly addresses learning in directed graphical models, but not the more challenging problem of learning in undirected graphical models. Several closely related approaches, which we refer to as One Posterior Sampling (OPS), show that a single sample drawn from a posterior distribution is differentially private (Dimitrakakis et al., 2014; Wang et al., 2015; Zhang et al., 2016). This can be understood as applying the exponential mechanism to the log-likelihood function, and can provide a point estimate for graphical model parameters (Zhang et al., 2016). To apply OPS, one must sample from the posterior over parameters, p(\u0398|X), which is\nstraightforward for directed graphical models with conjugate priors, but not in undirected models, where posteriors over parameters are usually intractable. Zhang et al. (2016) and Foulds et al. (2016) also developed fully Bayesian methods using Laplace noise-corrupted sufficient statistics to update posterior parameters. Similar considerations apply to this approach, which matches ours in that it uses the same data release mechanism, but, like OPS, requires conjugate priors and thus easily applies only to directed graphical models. Wang et al. (2015) also describe MCMC approaches to draw many private samples from a posterior distribution; this is another general framework that could apply to our problem, but, it relies on loose sensitivity bounds and since we only request point estimates, it would waste privacy budget by drawing many samples."}, {"heading": "2. Background and Problem Statement", "text": "We consider data sets consisting of T discrete attributes associated with each individual. Let xt \u2208 X denote the value of the tth attribute of an individual; we assume for simplicity of notation that all variables take values in the same finite set X . Let x = (x1, . . . , xT ) denote the complete vector of attributes for an individual, and let X = (x(1),x(2), . . . ,x(N)) denote a data set for an entire population of N individuals."}, {"heading": "2.1. Differential Privacy", "text": "Differential privacy offers strong privacy protection by imposing constraints on any algorithm that computes on the private dataset. Informally, it requires that an individual\u2019s data has a bounded effect on the algorithm\u2019s behavior. The formal definition requires reasoning about all pairs of datasets that are otherwise identical except one dataset contains one additional individual\u2019s data vector. Let nbrs(X) denote the set of datasets that differ from X by at most one individual\u2019s vector\u2014i.e., if X\u2032 \u2208 nbrs(X), then X\u2032 = (x(1), . . . ,x(i\u22121),x(i+1), . . . ,x(n)) for some i or X\u2032 = (x(1), . . . ,x(i),x\u2032,x(i+1), . . . ,x(n)) for some i and some x\u2032 \u2208 X T . Definition 1 (Differential Privacy; Dwork et al., 2006). A randomized algorithmA satisfies ( , \u03b4)-differential privacy if for any input X, any X\u2032 \u2208 nbrs(X) and any subset of outputs S \u2286 Range(A),\nPr[A(X) \u2208 S] \u2264 exp( )Pr[A(X\u2032) \u2208 S] + \u03b4.\nWhen \u03b4 = 0, we say that the algorithm satisfies - differential privacy. All of the algorithms we propose satisfy -differential privacy but we compare against some algorithms that satisfy the weaker condition of ( , \u03b4)differential privacy with non-zero \u03b4.\nWe achieve differential privacy by injecting noise into the\nstatistics that are computed on the data. Let f be any function that maps datasets to Rd. The amount of noise depends on the sensitivity of f .\nDefinition 2 (Sensitivity). The sensitivity of a function f is defined as \u2206f = maxX LSf (X) where LSf denotes the local sensitivity of f on input X and is defined as LSf (X) = maxX\u2032\u2208nbrs(X) \u2016f(X)\u2212 f(X\u2032)\u20161.\nWe drop the subscript f when it is clear from context.\nOur approach achieves differential privacy through the application of the Laplace mechanism.\nDefinition 3 (Laplace Mechanism; Dwork et al., 2006). Given function f that maps datasets to Rd, the Laplace mechanism is defined as L(X) = f(X) + z where z = (z1, . . . , zd) and each zi is an i.i.d. random variable from Laplace(\u2206f/ ).\nAn important property of differential privacy is that any additional post-processing on the output cannot weaken the privacy guarantee.\nProposition 1 (Post-processing; Dwork & Roth, 2014). Let A be an ( , \u03b4)-differentially private algorithm that maps datasets to Rd and let g : Rd \u2192 Rd\u2032 be an arbitrary function. Then g \u25e6 A is also ( , \u03b4)-differentially private."}, {"heading": "2.2. Problem Statement", "text": "Our goal is to learn a probabilistic model p(x) from the data set X while protecting the privacy of individuals. We will learn probability distributions p(x) that are undirected discrete graphical models (also called Markov random fields; Koller & Friedman, 2009). These are defined by a set of local potential functions of the form \u03c8C(xC), where C \u2286 {1, . . . , T} is an index set or clique, xC is a subvector of x corresponding to C, and \u03c8C : X |C| \u2192 R+ assigns a potential value to each possible xC . The probability model is p(x) = 1Z \u220f C\u2208C \u03c8C(xC) where C is the\ncollection of cliques that appear in the model, and Z =\u2211 x \u220f C\u2208C \u03c8C(xC) is the normalizing constant or partition function. The graph G with node set V = {1, . . . , T} and edges between any two indices that co-occur in some C \u2208 C is the independence graph of the model; therefore, each index set C is a clique in G.\nFor learning, it is most convenient to express the model in log-linear or exponential family form as:\np(x;\u03b8) = exp {\u2211 C\u2208C \u2211 iC\u2208X |C| I{xC = iC}\u03b8C(iC)\u2212A(\u03b8) } . (1) In this expression: I{\u00b7} is an indicator function; the variable iC \u2208 X |C| denotes a particular setting of the variables xC ; the parameters \u03b8C(iC) = log\u03c8C(iC) are logpotential values; the vector \u03b8 \u2208 Rd is the concatenation of\nall parameters; and A(\u03b8) = logZ(\u03b8) is the log-partition function, with the dependence of Z on the parameters now made explicit. Note that, for any \u03b8 \u2208 Rd, the density is strictly positive: p(x;\u03b8) > 0 for all x. This is true because the potential values \u03c8C(iC) are strictly positive, so the log-potentials are finite.\nThe goal is to learn parameters \u03b8\u0302 from the data X in a way that is -differentially private and such that p(x; \u03b8\u0302) is as accurate as possible. We will measure accuracy as KullbackLeibler divergence from an appropriate reference distribution (Kullback & Leibler, 1951). In synthetic experiments, we will measure the divergence D ( p(\u00b7;\u03b8)\u2016p(\u00b7; \u03b8\u0302) ) , where p(x;\u03b8) is the true density. For real data, we will measure the holdout log-likelihood Eq [ log p(x; \u03b8\u0302) ] where q is the empirical distribution of the holdout data, which is equal to a constant minus D ( q\u2016p(\u00b7; \u03b8\u0302) ) .\nThe problem of privately selecting which cliques to include in the model (i.e., model selection or structure learning) is interesting but not considered in this paper; we assume the cliques C are fixed in advance by the modeler."}, {"heading": "3. Approach", "text": "To develop our approach to privately learn graphical model parameters, we first discuss standard concepts related to maximum-likelihood estimation for graphical models.\nLog-Likelihood, Sufficient Statistics, Marginals. From Eq. (1), the log-likelihood L(\u03b8) = log \u220fN i=1 p ( x(i);\u03b8 ) of the entire data set can be written as\nL(\u03b8) = [\u2211 C\u2208C \u2211 iC\u2208X |C| nC(iC)\u03b8C(iC) ] \u2212NA(\u03b8)\nwhere nC(iC) = \u2211N i=1 I{x (i) C = iC} is a count of how many times the configuration iC for the variables in clique C appears in the population. The collection of counts nC = ( nC(iC) ) for all possible iC is the (population) contingency table on clique C. Let n denote the vector concatenation of the contingency tables for all cliques. Then we can rewrite the log-likelihood more compactly as\nL(\u03b8) = f(n,\u03b8) := \u03b8Tn\u2212NA(\u03b8) (2)\nThe most common approach for parameter learning in graphical models is maximum likelihood estimation: find the parameters \u03b8\u0302 that maximizeL(\u03b8). The resulting parameter vector \u03b8\u0302 is a maximum-likelihood estimator (MLE). It is clear from Eq. (2) that this problem depends on the data only through the contingency tables n. Indeed, the clique contingency tables n are sufficient statistics of the model: they measure all of the information from the data set X that is relevant for estimating the parameter \u03b8 (Fisher, 1922).\nThe algorithmic approach for maximum-likelihood estimation in graphical models is standard (Koller & Friedman, 2009), and we do not repeat the details here. However, there are a few concepts that are important for our development. The marginals of a graphical model are the marginal probabilities \u00b5C(iC) = p(xC = iC ;\u03b8) for all cliques C and configurations iC . Let \u00b5 be the vector concatenation of all marginals, and note that \u00b5 = E\u03b8[n]/N . Similarly, let \u00b5\u0302 = n/N be the data marginals\u2014these are marginal probabilities of the empirical distribution of the data.\nMarginals play a fundamental role in estimation. First, note that we can divide Eq. (2) by N to see that the MLE only depends on the data through the data marginals \u00b5\u0302. However, we leave L(\u03b8) in the current form because it is more convenient for the CGM development in Section 3.2. Second, it is well known that \u2207\u03b8L(\u03b8) = N(\u00b5\u0302 \u2212 \u00b5), so maximum likelihood estimation seeks to adjust \u03b8 so that the data and model marginals match. Third, it can (almost) always succeed in doing so, even if the data marginals do not come from a graphical model. More formally, letM be the marginal polytope: the set of all vectors \u00b5 such that there exists some distribution q(x) with marginal probabilities \u00b5.\nProposition 2 (Wainwright & Jordan, 2008). For any \u00b5 in the interior ofM, there is a unique distribution p(x;\u03b8) with marginals \u00b5, i.e., such that \u00b5 = E\u03b8[n]/N .\nApplying Proposition 2 to the data marginals \u00b5\u0302 shows that if these belong to the interior of M, we may learn a distribution with marginals that match what we observe in the data. Note that, while the distribution p(x;\u03b8) is unique, the parameters \u03b8 are not, because our model is overcomplete. If \u00b5 belongs toM but not the interior ofM, which occurs, for example, when some marginals are zero, the situation is more complex: there is no (finite) \u03b8 \u2208 Rd such that p(x;\u03b8) has marginals \u00b5.2 Similarly, the MLE does not exist, meaning that its maximum is not attained for any finite \u03b8 (Fienberg & Rinaldo, 2012; Haberman, 1973). This issue will end up being significant in our understanding of the naive MLE approach in the following section."}, {"heading": "3.1. Noisy sufficient statistics", "text": "From the development so far, there are two obvious possibilities for randomizing the learning process to achieve privacy:\n1. (Output perturbation) Find the MLE \u03b8\u0302 and add Laplace noise proportional to its sensitivity.\n2. (Sufficient statistics perturbation) Add Laplace noise to the sufficient statistics n, and then conduct maximumlikelihood estimation. 2However, there is a sequence {\u03b8k} where \u03b8k \u2208 Rd and lim k\u2192\u221e E\u03b8k [n]/N = \u00b5.\nThe two approaches are similar from an information bottleneck standpoint\u2014the dimensionality of n and \u03b8\u0302 is the same. However, the sensitivity of \u03b8\u0302 is difficult to analyze, since it requires reasoning about worst-case inputs. It also may be high due to pathological inputs whose local sensitivity is much higher than that of realistic data sets. On the other hand, the sensitivity of n is very easy to analyze and the analysis is tight: the local sensitivity is the same for all data sets.\nProposition 3. Let n(X) be the sufficient statistics of a graphical model with clique set C on data set X. The local sensitivity of n is |C| for all inputs X. Therefore the sensitivity of n is |C|.\n(Proofs can be found in the supplementary material.) So, a simple approach to achieve privacy is to release noisy sufficient statistics y that are obtained after applying the Laplace mechanism:\nyC(iC) = nC(iC) + Laplace ( |C|/ ) (3)\nPositive results. How can we learn with noisy sufficient statistics y? A naive approach is to use y in place of n in maximum-likelihood estimation, i.e., to find \u03b8\u0302 to maximize f(y,\u03b8). The validity of this approach has been debated in the literature (Yang et al., 2012). However, it is relatively easy to show that it behaves well asymptotically.\nProposition 4. Assume x(1), . . . ,x(N) are drawn iid from a probability distribution with marginals \u00b5. The marginal estimate \u00b5\u0304C(iC) = 1N yC(iC) obtained from the noisy sufficient statistics is unbiased and consistent, with mean squared error:\nMSE ( \u00b5\u0304C(iC) ) = \u00b5C(iC)\n( 1\u2212 \u00b5C(iC) ) N + 2|C|2 N2 2 (4)\nNow let \u03b8\u0302 \u2208 argmax\u03b8 f(y,\u03b8) be parameters estimated using the noisy sufficient statistics y. If the true distribution p(x;\u03b8) is a graphical model with cliques C, then the estimated distribution p(x; \u03b8\u0302) converges to p(x;\u03b8).\nPathologies. Asymptotically, the noisy sufficient statistics behave as desired in terms of MSE: the O(1/N) term, which is due to sampling error and not privacy, dominates for large N . However, for practical settings of the O(1/N2) term, which is due to privacy, is dominant until N becomes very large, due to the large constant 2|C|2/ 2. Figure 1(a) illustrates this issue.\nA second pathology is that the noise added for privacy destroys some of the structure expected in the empirical marginals. The true data marginals \u00b5\u0302 = n/N belong to the marginal polytope: in particular, this means that each clique marginal \u00b5\u0302C is nonnegative and sums to one, and\nthat clique marginals agree on common subsets of variables. After adding noise, the pseudo-marginals \u00b5\u0304 = y/N do not belong to the marginal polytope: \u00b5\u0304 may have negative values, and does not satisfy consistency constraints. We find that a partial fix is very helpful empirically: project the pseudo-marginal \u00b5\u0304C for each clique onto the simplex prior to conducting MLE, which can be done via a standard procedure (Duchi et al., 2008). Let \u00b5\u0303 be the projected marginals. We now have that \u00b5\u0303C is a valid marginal for each clique C, but consistency constraints are not satisfied among cliques, and it is still the case that \u00b5\u0303 /\u2208 M. Figure 1(b) illustrates the benefits of projection on the quality of the model learned by Naive MLE.\nA more significant pathology has to do with zeros in the projected marginals \u00b5\u0303, which are more prevalent than in true data marginals \u00b5\u0302. This is because the addition of Laplace noise creates negative values, which are then truncated to zero during projection. As discussed following Proposition 2, zero values in the marginals lead to nonexistence of the MLE (Fienberg & Rinaldo, 2012; Haberman, 1973). If \u00b5\u0303C(iC) = 0, the likelihood increases monotonically as \u03b8C(iC) goes to negative infinity; in other words, the model attempts to drive the learned marginal probability to zero. Numerically, we can address this by regularization, e.g., adding \u03bb\u2016\u03b8\u20162 to the objective function for arbitrarily small \u03bb > 0. However, we may still learn vanishingly small marginal probabilities, which can lead to a very large KL-divergence between the true and learned models. Figure 1(c) illustrates the effect of \u03bb on KL-divergence with both noisy sufficient statistics and true sufficient statistics. At high \u03bb (strong regularization), both methods underfit and yield poor KL divergence. Learning with true sufficient statistics has no tendency to overfit; it achieves good performance for a broad range of \u03bb approaching zero. Naive MLE with noisy sufficient statistics overfits badly (to zeros) for small \u03bb, and must be tuned \u201cjust right\u201d to achieve reasonable performance."}, {"heading": "3.2. Collective Graphical Models", "text": "Since learning with noisy sufficient statistics \u201cas-is\u201d has several pathologies and is less robust than maximumlikelihood estimation in the absence of privacy, we investigate a more principled approach, which matches the data generating process: We treat the true sufficient statistics n as latent variables, and learn \u03b8 to maximize the marginal likelihood p(y;\u03b8) = \u2211 n p(n,y;\u03b8). In this section, we will develop an EM approach to accomplish this.\nIn EM, we need to conduct inference to compute E[n |y;\u03b8] for a fixed value of \u03b8. This is the central problem of collective graphical models (CGMs) (Sheldon & Dietterich, 2011). Consider the joint distribution p(n,y;\u03b8) = p(n;\u03b8)p(y |n), which we use to compute E[n |y;\u03b8]. The\nnoise mechanism p(y |n) arises directly from the Laplace mechanism (see Eq. (3)). The distribution of the sufficient statistics, p(n;\u03b8), is known as the CGM distribution. It can be written in closed form when the model is decomposable, i.e., the cliques C correspond to the nodes of some junction tree T . Although decomposability is a significant restriction, let us assume that such a tree T exists; we will use the exact results derived for this case to develop an approximation for the general case. Let S be the set of separators of T , and let \u03bd(S) be the multiplicity of S \u2208 S , i.e., the number of distinct edges (Ci, Cj) \u2208 T for which S = Ci \u2229Cj . Under these assumptions, the CGM distribution has the form (Liu et al., 2014):\np(n;\u03b8) = h(n) \u00b7 exp ( f(n,\u03b8) ) ,\nh(n) = N ! \u00b7\n\u220f S\u2208S \u220f iS\u2208X |S| ( nS(iS)! )\u03bd(S) \u220f C\u2208C \u220f iC\u2208X |C| nC(iC)! \u00b7 I{n \u2208MZN}\nThe term exp ( f(n,\u03b8) ) is the probability of an ordered data set X with sufficient statistics n, as discussed previously. The term h(n) is a base measure that counts the number of ordered data sets with sufficient statistics equal to n, and enforces constraints on n. The integer-valued marginal polytopeMZN is the set of all vectors n that are sufficient statistics of some data set X of size N .\nExact inference in CGMs is intractable (Sheldon et al., 2013). Therefore, it is typical to relax the integrality constraint and apply Stirling\u2019s approximation: log n! \u2248 n log n \u2212 n. Let MN be the feasible set with the integrality constraint removed, which is now just the standard marginal polytope scaled so that each marginal sums to N instead of one.\nProposition 5 (Sun et al.; Nguyen et al., 2015; 2016). For a decomposable CGM with junction tree T , the following\napproximation of the CGM log-density for any n \u2208MN is obtained by applying Stirling\u2019s approximation:\nlog p(n,y;\u03b8) \u2248 \u03b8Tn\u2212NA(\u03b8)+H(n)+log p(y|n). (5) Here, H(n) = \u2212N \u2211\nx q(x) log q(x) is the entropy of the unique distribution q(x) = p(x;\u03b8) in the graphical model family with marginals equal to n/N .\nProposition 5 is the basis for approximate MAP inference problem in CGMs: find n to maximize Eq. (5) and obtain an approximate mode of p(n |y;\u03b8). Even though our goal is to compute the mean E[n |y;\u03b8], it has been shown that the approximate mode, which is also a real-valued vector, is an excellent approximation to the mean for use within the EM algorithm (Sheldon et al., 2013). Note that for non-decomposable models, we will simply apply the same approximation as in Proposition 5, even though an exact expression for the counting measure h(n), and therefore the correspondence of log h(n) to an entropy H(n), is not known in this case. Then, after dropping the term NA(\u03b8) from Proposition 5, which is constant with respect to n, the approximate MAP problem can be rewritten as:\nn\u2217 \u2208 argmax n\u2208MN \u03b8Tn +H(n) + log p(y |n) (6)\nThis equation reveals a close connection to variational principles for graphical models (Wainwright & Jordan, 2008). It is identical to the variational optimization problem for marginal inference in standard graphical models, except the objective has an additional term log p(y|n), which is nonlinear in n. Several message-passing based algorithms have been developed to efficiently solve the approximate MAP problem. For trees or junction trees, Problem (6) is convex as long as log p(y|n) is concave in n (which is true in most cases of interest, such as Laplace noise) so it can be solved exactly (Sun et al., 2015; Vilnis et al., 2015). For loopy models, both the entropy H(n) and the feasible set MN must be approximated (Nguyen et al., 2016).\nAlgorithm 1 Non-Linear Belief Propagation (NLBP) Input: \u03b8, y, damping parameter \u03b1 > 0\nwhile \u00ac converged do \u03b8\u2032 \u2190 \u03b8 +\u2207n log p(y |n) n\u2032 \u2190 STANDARD-BP ( \u03b8\u2032 ) {Normalized to sum to N}\nn\u2190 (1\u2212 \u03b1)n+ \u03b1n\u2032\nend while\nAlgorithm 2 EM for CGMs Input: Noisy sufficient statistics y\nInitialize \u03b80 arbitrarily while \u00ac converged do nt \u2190 NLBP(\u03b8t,y) \u03b8t+1 \u2190 argmax\u03b8 \u03b8\nTnt \u2212NA(\u03b8) end while\nAlgorithm 1 shows pseudocode non-linear belief propagation (NLBP; Sun et al., 2015), which we select as our primary inference approach due to its simplicity. It is a thin wrapper around standard BP, and can be applied to trees, in which case it exactly solves Problem (6), or it can be applied to loopy graphs by using loopy BP (LBP) as the subroutine, in which case it is approximate.\nOur final EM learning procedure is shown in Algorithm 2. It alternates between inference steps that solve the approximate MAP problem to find nt \u2248 E[n |y; \u03b8t], and optimization steps to re-estimate parameters given the inferred sufficient statistics nt. See also (Sheldon et al., 2013; Liu et al., 2014; Sun et al., 2015)."}, {"heading": "4. Experiments", "text": "We conduct a number of experiments on synthetic and real data to evaluate the quality of models learned by both Naive MLE and CGM.\nMethods. We compare three algorithms: Naive MLE, CGM, and a version of private stochastic gradient descent (PSGD) due to Abadi et al. (2016). PSGD belongs to a class of general-purpose private learning algorithms that can be adapted to our problem, including gradient descent or stochastic gradient descent algorithms for empirical risk minimization (Chaudhuri et al., 2011; Kifer et al., 2012; Jain & Thakurta, 2013; Bassily et al., 2014; Abadi et al., 2016) and the subsample-and-aggregate approach for parameter estimation (Smith, 2011). We chose PSGD because it is a state-of-the-art method and it significantly outperformed other approaches in preliminary experiments. However, note that PSGD satisfies only ( , \u03b4)-differential privacy for \u03b4 > 0, which is a weaker privacy guarantee than -differential privacy. We tune PSGD using a grid search over all relevant parameters to ensure it performs as well as\npossible."}, {"heading": "4.1. Synthetic data", "text": "We evaluate two types of pairwise graphical models: thirdorder chains with edges between two nodes i and j if 1 \u2264 |i \u2212 j| \u2264 3, and (connected) Erdo\u030bs-Re\u0301yni (ER) random graphs. We report results for graphs of 10 nodes, where potentials on each edge are drawn from a Dirichlet distribution with concentration parameter of one; results are similar for smaller and larger models, models with different structures, and for different types of potentials. We vary data size N and privacy parameter . For each setting of model type, N , and , we conduct 25 trials. The trials are nested, with five random populations and five replications per population, i.e.: ni \u223c p(n),yi,j \u223c p(y |ni) for i \u2208 {1, . . . , 5}, j \u2208 {1, . . . , 5}. We measure the quality of learned models using KL divergence from the true distribution, and include for comparison two reference models: a random estimator and a non-private MLE estimator. The random estimator is obtained by randomly generating marginals \u00b5\u0304 and then learning potentials via MLE.\nResults. Figure 2 shows the results for the two models (top: third-order chain, bottom: ER) for different values of N and . CGM improves upon Naive MLE for all models, privacy levels, and population sizes. Recall that PSGD promises only ( , \u03b4)-differential privacy. While \u03b4 is often assumed to be \u201ccryptographically small\u201d, e.g.,O(2\u2212N ), we set \u03b4 to a relatively large value of \u03b4 = 1/N . Increasing \u03b4 weakens the privacy guarantee but enables PGSD to run on a wider range of . However, even with this setting for \u03b4, some of the smaller values of are not attainable by PGSD and are omitted from those plots.\nFigure 3(a) shows a qualitative comparison of edge marginals of a single graph learned by the different methods, compared with the true model marginals; it is evident that CGM learns marginals that are much closer to both the true marginals and those learned by the non-private estimator than Naive MLE is able to learn. Naive MLE is the fastest method; CGM is approximately 4x/8x slower on third-order chains and ER graphs, respectively, and PSGD is approximately 27x/40x slower."}, {"heading": "4.2. Wifi data", "text": "We study human mobility data in the form of connections to wifi access points throughout a highly-trafficked academic building over a twenty-one day period. We treat each (user ID, day) combination as an \u201cindividual\u201d, leading to 124,399 unique individuals; with this data preparation scheme, the unit of protection is one day\u2019s worth of a user\u2019s data. We discretize time by recording the location every 10 minutes, and assign null if the user is not connected to the network. Our probability model p(x) is a\npairwise graphical model over hour-long segments. Therefore, we break each individual\u2019s data into 24 one-hour long segments.\nAn individual now contributes 24 records to each contingency table for the model p(x). Therefore, the sensitivity is now 24 times the number of edges (cliques). However, real data is typically sparse\u2014i.e., an individual is typically observed only a small number of times over the observation period. Therefore, to reduce the sensitivity, the data is normalized prior to calculating sufficient statistics, in a fashion similar to (He et al., 2015). Each user contributes a value of 1/K to each contingency table, where K is the number of edges (xs, xt) for which the user\u2019s values are not both null. With this pre-processing in place, the sensitivity equals the number of edges in the model. A trade-off of\nthis technique is that we bias the model towards individuals with fewer transitions, but we reduce the amount of noise by limiting sensitivity caused by null\u2013null transitions.\nWe reserve data from 25% of the individuals for testing. To compare different approaches, we apply Naive MLE, CGM, and PSGD to privately learn parameters of a graphical model from the training set (75% of the data), with varying privacy levels. We then calculate holdout loglikelihood of the learned parameters on the test set. We again include a non-private method for reference, but in this case, all methods perform better than the random estimator, so we do not show it.\nFigure 3(b) shows the results for fitting a timehomogeneous chain model (edges between adjacent time steps, every potential \u03c8(xt, xt+1) is the same, and the model includes a node potential \u03c6(x1) so it can learn a time-stationary model). As in the synthetic data experiments, CGM improves upon naive MLE across all parameter regimes, and performance improves with population size N and with weakening of privacy (larger ). Both methods outperform PSGD. Naive MLE is the fastest method; CGM is approximately 15x slower, and PSGD is approximately 46x slower."}, {"heading": "Acknowledgments", "text": "This material is based upon work supported by the National Science Foundation under Grant Nos. 1409125, 1409143, 1421325, and 1617533."}, {"heading": "A. Extra Proofs", "text": "Proof of Proposition 3. It is well known that the local sensitivity of any contingency table with respect to our definition of nbrs(X) is one. This is easy to see from the definition of nC following Eq. (2): each individual contributes a count of exactly one to each clique contingency table. Since there are |C| tables, the local sensitivity is exactly |C| for all data sets, and, therefore, the sensitivity is the same. Proof of Proposition 4. Note that nC(iC) is a sum of N iid indicator variables, so nC(iC) \u223c Binomial ( N,\u00b5C(iC) ) , and\nVar ( nc(iC) ) = N\u00b5C(iC) ( 1\u2212 \u00b5C(iC) ) . Now let z \u223c Laplace(|C|/ ) and write:\n\u00b5\u0304C(iC) = 1\nN\n( nC(iC) + z ) Recall that E[z] = 0 and Var(z) = 2|C|2/ 2. We see immediately that E[\u00b5\u0304C(iC)] = E [ nC(iC)/N ] = \u00b5C(iC). Therefore, the estimator is unbiased and its mean-squared error is equal to its variance. Since nC(iC) and z are independent, we have:\nVar ( \u00b5\u0304C(iC) ) =\nVar ( nC(iC) ) N2 + Var(z) N2\n= \u00b5C(iC)\n( 1\u2212 \u00b5C(iC) ) N + 2|C|2 N2 2\nThe fact that p(x; \u03b8\u0302) converges to p(x;\u03b8) follows from Proposition 2 and the consistency of the marginals, as long as the true marginals \u00b5 lie in the interior of the marginal polytopeM. However, this is guaranteed because the true distribution p(x;\u03b8) is strictly positive.\nProof of Proposition 5. After applying Stirling\u2019s approximation to log p(n;\u03b8) we obtain (Nguyen et al., 2016): log h(n) \u2248 H(n) = N logN + \u2211 C\u2208C H\u0302C \u2212 \u2211 S\u2208S \u03bd(S)H\u0302S (7)\nwhere we define H\u0302A = \u2212 \u2211 iA\u2208X |A| nA(iA) log nA(iA) for any A \u2208 C \u222a S. The term H\u0302A is a scaled entropy. We can rewrite it as:\nH\u0302A = \u2212N \u2211 iA nA(iA) N log (nA(iA) N \u00b7N )\n= \u2212N \u2211 iA \u00b5\u0302A(iA) log \u00b5\u0302A(iA)\u2212N \u2211 iA \u00b5\u0302A(iA) logN\n= NHA \u2212N logN\nwhere HA is now the entropy of the empirical marginal distribution \u00b5\u0302A = nA/N . Since the total multiplicity of the separators is one less than the number of cliques, when we substitute back into Eq. (7), all of the N logN terms cancel, and we are left only with\nH(n) = N \u00b7 ( \u2211 C\u2208C(T ) HA \u2212 \u2211 S\u2208S(T ) \u03bd(S)HA ) But, from standard arguments about the decomposition of entropy on junction trees, the term in parentheses is exactly the entropy of distribution q defined as:\nq(x) =\n\u220f C\u2208C \u220f iC\u2208X |C|\n\u00b5\u0302C(xC)\u220f S\u2208S \u220f iS\u2208X |S| \u00b5\u0302S(xS) \u03bd(S) ,\nwhich factors according to C and can be written as p(x;\u03b8) for parameters \u03b8 derived from the marginal probabilities. Although the mapping from parameters to distributions is many-to-one, for any maginals \u00b5\u0302, there is a unique distribution p(x;\u03b8) in the model family that has marginals \u00b5\u0302 (Wainwright & Jordan, 2008), so this uniquely defines q(x) as stated in the Proposition."}], "references": [{"title": "Deep learning with differential privacy", "author": ["Abadi", "Mart\u0131\u0301n", "Chu", "Andy", "Goodfellow", "Ian", "McMahan", "H. Brendan", "Mironov", "Ilya", "Talwar", "Kunal", "Zhang", "Li"], "venue": "In Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security,", "citeRegEx": "Abadi et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Abadi et al\\.", "year": 2016}, {"title": "Private empirical risk minimization: Efficient algorithms and tight error bounds", "author": ["Bassily", "Raef", "Smith", "Adam", "Thakurta", "Abhradeep"], "venue": "In Foundations of Computer Science (FOCS),", "citeRegEx": "Bassily et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Bassily et al\\.", "year": 2014}, {"title": "Practical privacy: the SuLQ framework", "author": ["Blum", "Avrim", "Dwork", "Cynthia", "McSherry", "Frank", "Nissim", "Kobbi"], "venue": "In Proceedings of the Twenty-Fourth ACM SIGMODSIGACT-SIGART Symposium on Principles of Database Systems (PODS),", "citeRegEx": "Blum et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Blum et al\\.", "year": 2005}, {"title": "Privacypreserving logistic regression", "author": ["Chaudhuri", "Kamalika", "Monteleoni", "Claire"], "venue": "In Advances in Neural Information Processing Systems, pp", "citeRegEx": "Chaudhuri et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Chaudhuri et al\\.", "year": 2009}, {"title": "Differentially private empirical risk minimization", "author": ["Chaudhuri", "Kamalika", "Monteleoni", "Claire", "Sarwate", "Anand D"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Chaudhuri et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Chaudhuri et al\\.", "year": 2011}, {"title": "Robust and private Bayesian inference", "author": ["Dimitrakakis", "Christos", "Nelson", "Blaine", "Mitrokotsa", "Aikaterini", "Rubinstein", "Benjamin I.P"], "venue": "In International Conference on Algorithmic Learning Theory,", "citeRegEx": "Dimitrakakis et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Dimitrakakis et al\\.", "year": 2014}, {"title": "Efficient projections onto the l 1-ball for learning in high dimensions", "author": ["Duchi", "John", "Shalev-Shwartz", "Shai", "Singer", "Yoram", "Chandra", "Tushar"], "venue": "In Proceedings of the 25th international conference on Machine learning,", "citeRegEx": "Duchi et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Duchi et al\\.", "year": 2008}, {"title": "The Algorithmic Foundations of Differential Privacy", "author": ["Dwork", "Cynthia", "Roth", "Aaron"], "venue": "Found. and Trends in Theoretical Computer Science,", "citeRegEx": "Dwork et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Dwork et al\\.", "year": 2014}, {"title": "Calibrating noise to sensitivity in private data analysis", "author": ["Dwork", "Cynthia", "McSherry", "Frank", "Nissim", "Kobbi", "Smith", "Adam"], "venue": "In Theory of Cryptography Conference,", "citeRegEx": "Dwork et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Dwork et al\\.", "year": 2006}, {"title": "Maximum likelihood estimation in log-linear models", "author": ["Fienberg", "Stephen E", "Rinaldo", "Alessandro"], "venue": "The Annals of Statistics,", "citeRegEx": "Fienberg et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Fienberg et al\\.", "year": 2012}, {"title": "On the mathematical foundations of theoretical statistics", "author": ["Fisher", "Ronald Aylmer"], "venue": "Philosophical Transactions of the Royal Society of London. Series A, Containing Papers of a Mathematical or Physical Character,", "citeRegEx": "Fisher and Aylmer.,? \\Q1922\\E", "shortCiteRegEx": "Fisher and Aylmer.", "year": 1922}, {"title": "On the theory and practice of privacy-preserving Bayesian data analysis", "author": ["Foulds", "James", "Geumlek", "Joseph", "Welling", "Max", "Chaudhuri", "Kamalika"], "venue": "In Proceedings of the Thirty-Second Conference on Uncertainty in Artificial Intelligence,", "citeRegEx": "Foulds et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Foulds et al\\.", "year": 2016}, {"title": "Log-linear models for frequency data: Sufficient statistics and likelihood equations", "author": ["Haberman", "Shelby J"], "venue": "The Annals of Statistics,", "citeRegEx": "Haberman and J.,? \\Q1973\\E", "shortCiteRegEx": "Haberman and J.", "year": 1973}, {"title": "A simple and practical algorithm for differentially private data release", "author": ["Hardt", "Moritz", "Ligett", "Katrina", "McSherry", "Frank"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Hardt et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Hardt et al\\.", "year": 2012}, {"title": "DPT: differentially private trajectory synthesis using hierarchical reference systems", "author": ["He", "Xi", "Cormode", "Graham", "Machanavajjhala", "Ashwin", "Procopiuc", "Cecilia M", "Srivastava", "Divesh"], "venue": "Proceedings of the VLDB Endowment,", "citeRegEx": "He et al\\.,? \\Q2015\\E", "shortCiteRegEx": "He et al\\.", "year": 2015}, {"title": "Differentially private learning with kernels", "author": ["Jain", "Prateek", "Thakurta", "Abhradeep"], "venue": "ICML (3),", "citeRegEx": "Jain et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Jain et al\\.", "year": 2013}, {"title": "Differentially private exponential random graphs", "author": ["Karwa", "Vishesh", "Slavkovi\u0107", "Aleksandra B", "Krivitsky", "Pavel"], "venue": "In International Conference on Privacy in Statistical Databases,", "citeRegEx": "Karwa et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Karwa et al\\.", "year": 2014}, {"title": "Inference using noisy degrees: Differentially private beta-model and synthetic graphs", "author": ["Karwa", "Vishesh", "Slavkovi\u0107", "Aleksandra"], "venue": "The Annals of Statistics,", "citeRegEx": "Karwa et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Karwa et al\\.", "year": 2016}, {"title": "What can we learn privately", "author": ["Kasiviswanathan", "Shiva Prasad", "Lee", "Homin K", "Nissim", "Kobbi", "Raskhodnikova", "Sofya", "Smith", "Adam"], "venue": "SIAM Journal on Computing,", "citeRegEx": "Kasiviswanathan et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Kasiviswanathan et al\\.", "year": 2011}, {"title": "Private convex empirical risk minimization and highdimensional regression", "author": ["Kifer", "Daniel", "Smith", "Adam", "Thakurta", "Abhradeep"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Kifer et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Kifer et al\\.", "year": 2012}, {"title": "Probabilistic graphical models: principles and techniques", "author": ["Koller", "Daphne", "Friedman", "Nir"], "venue": "MIT press,", "citeRegEx": "Koller et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Koller et al\\.", "year": 2009}, {"title": "On information and sufficiency", "author": ["Kullback", "Solomon", "Leibler", "Richard A"], "venue": "The annals of mathematical statistics,", "citeRegEx": "Kullback et al\\.,? \\Q1951\\E", "shortCiteRegEx": "Kullback et al\\.", "year": 1951}, {"title": "Gaussian approximation of collective graphical models", "author": ["Liu", "Li-Ping", "Sheldon", "Daniel R", "Dietterich", "Thomas G"], "venue": "In Proceedings of the 31st International Conference on Machine Learning (ICML),", "citeRegEx": "Liu et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Liu et al\\.", "year": 2014}, {"title": "Approximate inference using DC programming for collective graphical models", "author": ["Nguyen", "Duc Thien", "Kumar", "Akshat", "Lau", "Hoong Chuin", "Sheldon", "Daniel"], "venue": "In Proceedings of the 19th International Conference on Artificial Intelligence and Statistics,", "citeRegEx": "Nguyen et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Nguyen et al\\.", "year": 2016}, {"title": "Learning in a large function space: Privacy-preserving mechanisms for SVM learning", "author": ["Rubinstein", "Benjamin I.P", "Bartlett", "Peter L", "Huang", "Ling", "Taft", "Nina"], "venue": "arXiv preprint arXiv:0911.5708,", "citeRegEx": "Rubinstein et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Rubinstein et al\\.", "year": 2009}, {"title": "Collective graphical models", "author": ["Sheldon", "Daniel R", "Dietterich", "Thomas G"], "venue": "Neural Information Processing Systems (NIPS),", "citeRegEx": "Sheldon et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Sheldon et al\\.", "year": 2011}, {"title": "Approximate inference in collective graphical models", "author": ["Sheldon", "Daniel R", "Sun", "Tao", "Kumar", "Akshat", "Dietterich", "Thomas G"], "venue": "In Proceedings of the 30th International Conference on Machine Learning (ICML),", "citeRegEx": "Sheldon et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Sheldon et al\\.", "year": 2013}, {"title": "Efficient, differentially private point estimators", "author": ["Smith", "Adam"], "venue": "arXiv preprint arXiv:0809.4794,", "citeRegEx": "Smith and Adam.,? \\Q2008\\E", "shortCiteRegEx": "Smith and Adam.", "year": 2008}, {"title": "Privacy-preserving statistical estimation with optimal convergence rates", "author": ["Smith", "Adam"], "venue": "In Proceedings of the Forty-Third Annual ACM Symposium on Theory of Computing (STOC),", "citeRegEx": "Smith and Adam.,? \\Q2011\\E", "shortCiteRegEx": "Smith and Adam.", "year": 2011}, {"title": "Message passing for collective graphical models", "author": ["Sun", "Tao", "Sheldon", "Daniel R", "Kumar", "Akshat"], "venue": "In Proceedings of the 32nd International Conference on Machine Learning (ICML),", "citeRegEx": "Sun et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Sun et al\\.", "year": 2015}, {"title": "Bethe projections for non-local inference", "author": ["Vilnis", "Luke", "Belanger", "David", "Sheldon", "Daniel", "McCallum", "Andrew"], "venue": "In Proceedings of the Thirty-First Conference on Uncertainty in Artificial Intelligence,", "citeRegEx": "Vilnis et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Vilnis et al\\.", "year": 2015}, {"title": "Graphical models, exponential families, and variational inference", "author": ["Wainwright", "Martin J", "Jordan", "Michael I"], "venue": "Foundations and Trends in Machine Learning,", "citeRegEx": "Wainwright et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Wainwright et al\\.", "year": 2008}, {"title": "Privacy for free: Posterior sampling and stochastic gradient Monte Carlo", "author": ["Wang", "Yu-Xiang", "Fienberg", "Stephen", "Smola", "Alex"], "venue": "In Proceedings of the 32nd International Conference on Machine Learning", "citeRegEx": "Wang et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Wang et al\\.", "year": 2015}, {"title": "Probabilistic inference and differential privacy", "author": ["Williams", "Oliver", "McSherry", "Frank"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Williams et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Williams et al\\.", "year": 2010}, {"title": "Differentially private stochastic gradient descent for in-RDBMS analytics", "author": ["Wu", "Xi", "Kumar", "Arun", "Chaudhuri", "Kamalika", "Jha", "Somesh", "Naughton", "Jeffrey F"], "venue": "CoRR, abs/1606.04722,", "citeRegEx": "Wu et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Wu et al\\.", "year": 2016}, {"title": "Differential privacy for protecting multidimensional contingency table data: Extensions and applications", "author": ["Yang", "Xiaolin", "Fienberg", "Stephen E", "Rinaldo", "Alessandro"], "venue": "Journal of Privacy and Confidentiality,", "citeRegEx": "Yang et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Yang et al\\.", "year": 2012}, {"title": "Privbayes: Private data release via Bayesian networks", "author": ["Zhang", "Jun", "Cormode", "Graham", "Procopiuc", "Cecilia M", "Srivastava", "Divesh", "Xiao", "Xiaokui"], "venue": "In Proceedings of the 2014 ACM SIGMOD International Conference on Management of Data,", "citeRegEx": "Zhang et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Zhang et al\\.", "year": 2014}, {"title": "On the differential privacy of Bayesian inference", "author": ["Zhang", "Zuhe", "Rubinstein", "Benjamin I.P", "Dimitrakakis", "Christos"], "venue": "In Thirtieth AAAI Conference on Artificial Intelligence,", "citeRegEx": "Zhang et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Zhang et al\\.", "year": 2016}], "referenceMentions": [{"referenceID": 8, "context": "Differential privacy is a widely studied formalism for private data analysis (Dwork et al., 2006).", "startOffset": 77, "endOffset": 97}, {"referenceID": 8, "context": "This is usually done by modifying a learning algorithm to add noise to some intermediate quantity X , with the noise magnitude calibrated to the sensitivity of X , a measure of how much X can depend on any single individual\u2019s data in the worst case (Dwork et al., 2006).", "startOffset": 249, "endOffset": 269}, {"referenceID": 8, "context": "For example, adding noise to the final learned parameters \u03b8 (known as output perturbation; Dwork et al., 2006), is appealing from the information bottleneck standpoint, but if the learning algorithm is complex we may not be able to analyze the sensitivity and would have to rely on a coarse bound.", "startOffset": 60, "endOffset": 110}, {"referenceID": 1, "context": "Indeed, general private learning frameworks bound the sensitivity using quantities such as Lipschitz, strong-convexity, and smoothness constants (Bassily et al., 2014; Wu et al., 2016) or diameter of the parameter space (Smith, 2008), which may be loose in practice.", "startOffset": 145, "endOffset": 184}, {"referenceID": 34, "context": "Indeed, general private learning frameworks bound the sensitivity using quantities such as Lipschitz, strong-convexity, and smoothness constants (Bassily et al., 2014; Wu et al., 2016) or diameter of the parameter space (Smith, 2008), which may be loose in practice.", "startOffset": 145, "endOffset": 184}, {"referenceID": 37, "context": "In this paper we will take the approach of adding noise to the sufficient statistics of a graphical model using the Laplace mechanism, a high-level approach that has also been applied recently for directed models (Zhang et al., 2016; Foulds et al., 2016).", "startOffset": 213, "endOffset": 254}, {"referenceID": 11, "context": "In this paper we will take the approach of adding noise to the sufficient statistics of a graphical model using the Laplace mechanism, a high-level approach that has also been applied recently for directed models (Zhang et al., 2016; Foulds et al., 2016).", "startOffset": 213, "endOffset": 254}, {"referenceID": 16, "context": "However, at reasonable sample sizes the error due to privacy is significant, and the approach has several pathologies (see also Yang et al., 2012; Karwa et al., 2014; 2016), some of which make it difficult to apply in practice.", "startOffset": 118, "endOffset": 172}, {"referenceID": 24, "context": "Differential privacy has been applied to many areas of machine learning, including learning specific models such as logistic regression (Chaudhuri & Monteleoni, 2009), support vector machines (Rubinstein et al., 2009), and deep neural networks (Abadi et al.", "startOffset": 192, "endOffset": 217}, {"referenceID": 0, "context": ", 2009), and deep neural networks (Abadi et al., 2016); privacy in general frameworks such as empirical risk minimization (ERM; Chaudhuri et al.", "startOffset": 34, "endOffset": 54}, {"referenceID": 4, "context": ", 2016); privacy in general frameworks such as empirical risk minimization (ERM; Chaudhuri et al., 2011; Kifer et al., 2012; Jain & Thakurta, 2013; Bassily et al., 2014), gradient descent (Wu et al.", "startOffset": 75, "endOffset": 169}, {"referenceID": 19, "context": ", 2016); privacy in general frameworks such as empirical risk minimization (ERM; Chaudhuri et al., 2011; Kifer et al., 2012; Jain & Thakurta, 2013; Bassily et al., 2014), gradient descent (Wu et al.", "startOffset": 75, "endOffset": 169}, {"referenceID": 1, "context": ", 2016); privacy in general frameworks such as empirical risk minimization (ERM; Chaudhuri et al., 2011; Kifer et al., 2012; Jain & Thakurta, 2013; Bassily et al., 2014), gradient descent (Wu et al.", "startOffset": 75, "endOffset": 169}, {"referenceID": 34, "context": ", 2014), gradient descent (Wu et al., 2016), and parameter estimation (Smith, 2011); and theoretical analysis of what can be learned privately (e.", "startOffset": 26, "endOffset": 43}, {"referenceID": 18, "context": ", 2016), and parameter estimation (Smith, 2011); and theoretical analysis of what can be learned privately (e.g., Blum et al., 2005; Kasiviswanathan et al., 2011).", "startOffset": 107, "endOffset": 162}, {"referenceID": 35, "context": "Because sufficient statistics of graphical models are contingency tables, our work connects to the well-studied problem of releasing differentially private contingency tables (Barak et al., 2007; Yang et al., 2012; Hardt et al., 2012); we adopt the Laplace mechanism because it is simple and fits well within our learning framework.", "startOffset": 175, "endOffset": 234}, {"referenceID": 13, "context": "Because sufficient statistics of graphical models are contingency tables, our work connects to the well-studied problem of releasing differentially private contingency tables (Barak et al., 2007; Yang et al., 2012; Hardt et al., 2012); we adopt the Laplace mechanism because it is simple and fits well within our learning framework.", "startOffset": 175, "endOffset": 234}, {"referenceID": 15, "context": "Karwa et al. (2014; 2016) take a similar approach but for exponential random graph models, as do Williams & McSherry (2010), but for the factored exponential mechanism.", "startOffset": 0, "endOffset": 124}, {"referenceID": 26, "context": "In general, the inference problems we wish to solve are NP-hard (Sheldon et al., 2013), but a number of efficient approximate inference algorithms are available (Liu et al.", "startOffset": 64, "endOffset": 86}, {"referenceID": 22, "context": ", 2013), but a number of efficient approximate inference algorithms are available (Liu et al., 2014; Sun et al., 2015; Vilnis et al., 2015).", "startOffset": 82, "endOffset": 139}, {"referenceID": 29, "context": ", 2013), but a number of efficient approximate inference algorithms are available (Liu et al., 2014; Sun et al., 2015; Vilnis et al., 2015).", "startOffset": 82, "endOffset": 139}, {"referenceID": 30, "context": ", 2013), but a number of efficient approximate inference algorithms are available (Liu et al., 2014; Sun et al., 2015; Vilnis et al., 2015).", "startOffset": 82, "endOffset": 139}, {"referenceID": 22, "context": ", 2013), but a number of efficient approximate inference algorithms are available (Liu et al., 2014; Sun et al., 2015; Vilnis et al., 2015). In a paper that was primarily about CGM inference, Sun et al. (2015) conducted a case study using CGMs to privately learn Markov chains; we build on this approach, which was limited in scope and did not address general graph structures.", "startOffset": 83, "endOffset": 210}, {"referenceID": 5, "context": "Several closely related approaches, which we refer to as One Posterior Sampling (OPS), show that a single sample drawn from a posterior distribution is differentially private (Dimitrakakis et al., 2014; Wang et al., 2015; Zhang et al., 2016).", "startOffset": 175, "endOffset": 241}, {"referenceID": 32, "context": "Several closely related approaches, which we refer to as One Posterior Sampling (OPS), show that a single sample drawn from a posterior distribution is differentially private (Dimitrakakis et al., 2014; Wang et al., 2015; Zhang et al., 2016).", "startOffset": 175, "endOffset": 241}, {"referenceID": 37, "context": "Several closely related approaches, which we refer to as One Posterior Sampling (OPS), show that a single sample drawn from a posterior distribution is differentially private (Dimitrakakis et al., 2014; Wang et al., 2015; Zhang et al., 2016).", "startOffset": 175, "endOffset": 241}, {"referenceID": 37, "context": "This can be understood as applying the exponential mechanism to the log-likelihood function, and can provide a point estimate for graphical model parameters (Zhang et al., 2016).", "startOffset": 157, "endOffset": 177}, {"referenceID": 34, "context": "Zhang et al. (2016) and Foulds et al.", "startOffset": 0, "endOffset": 20}, {"referenceID": 11, "context": "(2016) and Foulds et al. (2016) also developed fully Bayesian methods using Laplace noise-corrupted sufficient statistics to update posterior parameters.", "startOffset": 11, "endOffset": 32}, {"referenceID": 11, "context": "(2016) and Foulds et al. (2016) also developed fully Bayesian methods using Laplace noise-corrupted sufficient statistics to update posterior parameters. Similar considerations apply to this approach, which matches ours in that it uses the same data release mechanism, but, like OPS, requires conjugate priors and thus easily applies only to directed graphical models. Wang et al. (2015) also describe MCMC approaches to draw many private samples from a posterior distribution; this is another general framework that could apply to our problem, but, it relies on loose sensitivity bounds and since we only request point estimates, it would waste privacy budget by drawing many samples.", "startOffset": 11, "endOffset": 388}, {"referenceID": 8, "context": "Definition 1 (Differential Privacy; Dwork et al., 2006).", "startOffset": 13, "endOffset": 55}, {"referenceID": 8, "context": "Definition 3 (Laplace Mechanism; Dwork et al., 2006).", "startOffset": 13, "endOffset": 52}, {"referenceID": 35, "context": "The validity of this approach has been debated in the literature (Yang et al., 2012).", "startOffset": 65, "endOffset": 84}, {"referenceID": 6, "context": "We find that a partial fix is very helpful empirically: project the pseudo-marginal \u03bc\u0304C for each clique onto the simplex prior to conducting MLE, which can be done via a standard procedure (Duchi et al., 2008).", "startOffset": 189, "endOffset": 209}, {"referenceID": 22, "context": "Under these assumptions, the CGM distribution has the form (Liu et al., 2014):", "startOffset": 59, "endOffset": 77}, {"referenceID": 26, "context": "Exact inference in CGMs is intractable (Sheldon et al., 2013).", "startOffset": 39, "endOffset": 61}, {"referenceID": 26, "context": "Even though our goal is to compute the mean E[n |y;\u03b8], it has been shown that the approximate mode, which is also a real-valued vector, is an excellent approximation to the mean for use within the EM algorithm (Sheldon et al., 2013).", "startOffset": 210, "endOffset": 232}, {"referenceID": 29, "context": "For trees or junction trees, Problem (6) is convex as long as log p(y|n) is concave in n (which is true in most cases of interest, such as Laplace noise) so it can be solved exactly (Sun et al., 2015; Vilnis et al., 2015).", "startOffset": 182, "endOffset": 221}, {"referenceID": 30, "context": "For trees or junction trees, Problem (6) is convex as long as log p(y|n) is concave in n (which is true in most cases of interest, such as Laplace noise) so it can be solved exactly (Sun et al., 2015; Vilnis et al., 2015).", "startOffset": 182, "endOffset": 221}, {"referenceID": 23, "context": "For loopy models, both the entropy H(n) and the feasible set MN must be approximated (Nguyen et al., 2016).", "startOffset": 85, "endOffset": 106}, {"referenceID": 29, "context": "Algorithm 1 shows pseudocode non-linear belief propagation (NLBP; Sun et al., 2015), which we select as our primary inference approach due to its simplicity.", "startOffset": 59, "endOffset": 83}, {"referenceID": 26, "context": "See also (Sheldon et al., 2013; Liu et al., 2014; Sun et al., 2015).", "startOffset": 9, "endOffset": 67}, {"referenceID": 22, "context": "See also (Sheldon et al., 2013; Liu et al., 2014; Sun et al., 2015).", "startOffset": 9, "endOffset": 67}, {"referenceID": 29, "context": "See also (Sheldon et al., 2013; Liu et al., 2014; Sun et al., 2015).", "startOffset": 9, "endOffset": 67}, {"referenceID": 4, "context": "PSGD belongs to a class of general-purpose private learning algorithms that can be adapted to our problem, including gradient descent or stochastic gradient descent algorithms for empirical risk minimization (Chaudhuri et al., 2011; Kifer et al., 2012; Jain & Thakurta, 2013; Bassily et al., 2014; Abadi et al., 2016) and the subsample-and-aggregate approach for parameter estimation (Smith, 2011).", "startOffset": 208, "endOffset": 317}, {"referenceID": 19, "context": "PSGD belongs to a class of general-purpose private learning algorithms that can be adapted to our problem, including gradient descent or stochastic gradient descent algorithms for empirical risk minimization (Chaudhuri et al., 2011; Kifer et al., 2012; Jain & Thakurta, 2013; Bassily et al., 2014; Abadi et al., 2016) and the subsample-and-aggregate approach for parameter estimation (Smith, 2011).", "startOffset": 208, "endOffset": 317}, {"referenceID": 1, "context": "PSGD belongs to a class of general-purpose private learning algorithms that can be adapted to our problem, including gradient descent or stochastic gradient descent algorithms for empirical risk minimization (Chaudhuri et al., 2011; Kifer et al., 2012; Jain & Thakurta, 2013; Bassily et al., 2014; Abadi et al., 2016) and the subsample-and-aggregate approach for parameter estimation (Smith, 2011).", "startOffset": 208, "endOffset": 317}, {"referenceID": 0, "context": "PSGD belongs to a class of general-purpose private learning algorithms that can be adapted to our problem, including gradient descent or stochastic gradient descent algorithms for empirical risk minimization (Chaudhuri et al., 2011; Kifer et al., 2012; Jain & Thakurta, 2013; Bassily et al., 2014; Abadi et al., 2016) and the subsample-and-aggregate approach for parameter estimation (Smith, 2011).", "startOffset": 208, "endOffset": 317}, {"referenceID": 0, "context": "We compare three algorithms: Naive MLE, CGM, and a version of private stochastic gradient descent (PSGD) due to Abadi et al. (2016). PSGD belongs to a class of general-purpose private learning algorithms that can be adapted to our problem, including gradient descent or stochastic gradient descent algorithms for empirical risk minimization (Chaudhuri et al.", "startOffset": 112, "endOffset": 132}, {"referenceID": 14, "context": "Therefore, to reduce the sensitivity, the data is normalized prior to calculating sufficient statistics, in a fashion similar to (He et al., 2015).", "startOffset": 129, "endOffset": 146}], "year": 2017, "abstractText": "We investigate the problem of learning discrete, undirected graphical models in a differentially private way. We show that the approach of releasing noisy sufficient statistics using the Laplace mechanism achieves a good trade-off between privacy, utility, and practicality. A naive learning algorithm that uses the noisy sufficient statistics \u201cas is\u201d outperforms general-purpose differentially private learning algorithms. However, it has three limitations: it ignores knowledge about the data generating process, rests on uncertain theoretical foundations, and exhibits certain pathologies. We develop a more principled approach that applies the formalism of collective graphical models to perform inference over the true sufficient statistics within an expectationmaximization framework. We show that this learns better models than competing approaches on both synthetic data and on real human mobility data used as a case study.", "creator": "TeX"}}}