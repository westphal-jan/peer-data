{"id": "1706.05198", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "16-Jun-2017", "title": "Structured Best Arm Identification with Fixed Confidence", "abstract": "We study the problem of identifying the best action among a set of possible options when the value of each action is given by a mapping from a number of noisy micro-observables in the so-called fixed confidence setting. Our main motivation is the application to the minimax game search, which has been a major topic of interest in artificial intelligence. In this paper we introduce an abstract setting to clearly describe the essential properties of the problem. While previous work only considered a two-move game tree search problem, our abstract setting can be applied to the general minimax games where the depth can be non-uniform and arbitrary, and transpositions are allowed. We introduce a new algorithm (LUCB-micro) for the abstract setting, and give its lower and upper sample complexity results. Our bounds recover some previous results, which were only available in more limited settings, while they also shed further light on how the structure of minimax problems influence sample complexity.\n\n\n\nThe algorithm is based on a non-zero probability (PS) set (OR) set (OR). The goal is to create a set of possible options when the value of each option is given by a mapping from a number of noisy micro-observables in the so-called fixed confidence setting.\nIn this paper we show that the current low PS is not an optimal option when the value of each option is given by a mapping from a number of noisy micro-observables in the so-called fixed confidence setting. This new approach was developed by a team of two academics in the UK.\nIn this paper we show that the current low PS is not an optimal option when the value of each option is given by a mapping from a number of noisy micro-observables in the so-called fixed confidence setting.\nOur method also introduces an option to the minimax game search. We show that the present low PS is not an optimal option when the value of each option is given by a mapping from a number of noisy micro-observables in the so-called fixed confidence setting. This new approach was developed by a team of two academics in the UK. In this paper we show that the current low PS is not an optimal option when the value of each option is given by a mapping from a number of noisy micro-observables in the so-called fixed confidence setting. This new approach was developed by a team of two academics in the UK. In this paper we show that the present low PS is not an optimal option", "histories": [["v1", "Fri, 16 Jun 2017 09:51:36 GMT  (143kb,D)", "https://arxiv.org/abs/1706.05198v1", null], ["v2", "Mon, 19 Jun 2017 05:47:31 GMT  (143kb,D)", "http://arxiv.org/abs/1706.05198v2", null]], "reviews": [], "SUBJECTS": "cs.LG cs.AI", "authors": ["ruitong huang", "mohammad m ajallooeian", "csaba szepesv\\'ari", "martin m\\\"uller"], "accepted": false, "id": "1706.05198"}, "pdf": {"name": "1706.05198.pdf", "metadata": {"source": "CRF", "title": "Structured Best Arm Identification with Fixed Confidence", "authors": ["Ruitong Huang", "Mohammad M. Ajallooeian", "Csaba Szepesv\u00e1ri", "Martin M\u00fcller"], "emails": ["ruitong@ualberta.ca", "ajallooe@ualberta.ca", "szepesva@ualberta.ca", "mmueller@ualberta.ca"], "sections": [{"heading": "1. Introduction", "text": "Motivated by the problem of finding the optimal move in minimax tree search with noisy leaf evaluations, we introduce best arm identification problems with structured payoffs and micro-observables. In these problems, the learner\u2019s goal is to find the best arm when the payoff of each arm is a fixed and known function of a set of unknown values. In each round, the learner can choose one of the micro-observables to make a noisy measurement (i.e., the learner can obtain a \u201cmicro-observation\u201d). We study these problems in the so-called fixed confidence setting.\nA special case of this problem is the standard best arm identification, which has seen a flurry of activity during the last decade, e.g., (Even-Dar et al., 2006; Audibert and Bubeck, 2010; Gabillon et al., 2012; Kalyanakrishnan et al., 2012; Karnin et al., 2013; Jamieson et al., 2014; Chen and Li, 2015). Recently, Garivier et al. (2016a) considered the motivating problem mentioned above. However, they only considered the simplest (non-trivial) instance when two players alternate for a single round. One of their main observations is that such\nc\u00a9... Ruitong Huang and Mohammad M. Ajallooeian and Csaba Szepesv\u00e1ri and Martin M\u00fcller.\nLicense: CC-BY 4.0, see https://creativecommons.org/licenses/by/4.0/. Attribution requirements are provided at http://jmlr.org/papers/v./ajallooe17a.html.\nar X\niv :1\n70 6.\n05 19\n8v 2\n[ cs\n.L G\n] 1\n9 Ju\ntwo-move problems can be solved more efficiently than if one considers the problem as an instance of a nested best arm identification problem. They proposed two algorithms, one for the fixed confidence setting, the other for the (asymptotic) vanishing confidence setting and provided upper bounds. An implicit (optimization-based) lower bound was also briefly sketched, together with a plan to derive an algorithm that matches it in the vanishing confidence setting.\nOur main interest in this paper is to see whether the ideas of Garivier et al. (2016a) extend to more general settings, such as when the depth can be non-uniform and is in particular not limited to two, or when the move histories can lead to shared states (that is, in the language of adversarial search we allow \u201ctranspositions\u201d). While considering these extensions, we found it cleaner to introduce the abstract setting mentioned below (Section 2). The motivation here is to clearly delineate the crucial properties of the problem that our results use. For the general structured setting, in Section 3 we prove an instance dependent lower bound along the lines of Auer et al. (2002) or Garivier et al. (2016b) (a mild novelty is the way our proof deals with the technical issue that best arm identification algorithms ideally stop and hence their behavior is undefined after the random stopping time). This is then specialized to the minimax game search setting (Section 4), where we show the crucial role of what we call proof sets, which are somewhat reminiscent of the so-called conspiracy sets from adversarial search (McAllester, 1988). Our lower bound matches that of Garivier et al. (2016a) in the case of two-move alternating problems. Considering again the abstract setting, we propose a new algorithm, which we call LUCB-micro (Section 5), and which can be considered as a natural generalization of Maximin-LUCB of Garivier et al. (2016a) (with some minor differences). Under a regularity assumption on the payoff maps, we prove that the algorithm meets the risk-requirement. We also provide a high-probability, instance-dependent upper bound on algorithm\u2019s sample complexity (i.e., on the number of observations the algorithm takes). As we discuss, while this bound meets the general characteristics of existing bounds, it fails to reproduce the corresponding result of Garivier et al. (2016a). To the best of authors\u2019 knowledge, the only comparable algorithm to study best arm identification in a full-length minimax tree search setting (which was the motivating example of our work) is FindTopWinner by Teraoka et al. (2014). This algorithm is a roundbased elimination based algorithm with additional pruning steps that come from the tree structure. When we specialize our framework to the minimax game scenario (and implement other necessary changes to put our work into their ( , \u03b4q-PAC setting), our upper bound is a strict improvement of theirs, e.g., in the number of samples related to the near-optimal micro-observables (leaves of the minimax game tree). Next, we consider the minimax setting (Section 6). First, we show that the regularity assumptions made for the abstract setting are met in this case. We also show how to efficiently compute the choices that LUCB-micro makes using a \u201cmin-max\u201d algorithm. Finally, we strengthen our previous result so that it is able to reproduce the mentioned result of Garivier et al. (2016a)."}, {"heading": "1.1 Notation", "text": "We use N \u201c t1, 2, . . . u to denote the set of positive integers, while we let R denote the set of reals. For a positive integer k P N, we let rks \u201c t1, . . . , ku. For a vector v P Rd, we denote its i-th element by vi; though occasionally we will also use vpiq for the same purpose, i.e., we\nidentify Rd and tf : f : rds \u00d1 Ru in the obvious way. We let |v| denote the vector defined by |v| \u201c p|vi|qiPrds. For two vectors u, v P Rd, we define u \u010f v if and only if ui \u010f vi for all 1 \u010f i \u010f d. Further, we write u \u0103 v when u \u2030 v and u \u010f v. For B \u0102 rds, we write u|B to denote the |B|-dimensional vector obtained from restricting u to components with index in B: u|B \u201c puiqiPB. We use 1d to denote the d dimensional vector whose components are all equal to one. For a nonempty set B, we also use 1B to denote the |B|-dimensional all-one vector. We let Bc \u201c ti P rds : i R Bu to denote the complementer of B (when Bc is used, the base set that the complementer is taken for should be clear from the context). The indicator function will be denoted by I t\u00a8u. We will use a^ b \u201c minpa, bq and a_ b \u201c maxpa, bq. For A \u0102 R, A\u0304 denotes its topological closure, while A\u02dd denotes its interior. Given a real value a P R, a` \u201c a_ 0 and a\u00b4 \u201c \u00b4pa^ 0q. For a sequence pm0, . . . ,miq of some values and some other value m, we define joinph,mq \u201c pm0, . . . ,mi,mq."}, {"heading": "2. Problem setup", "text": "Fix two positive integers, L and K. A problem instance of a structured K-armed best arm identification instance with L micro-observations is defined by a tuple pf, P q, where f : RL \u00d1 RK and P \u201c pP1, . . . , PLq is an L-tuple of distributions over the reals. We let \u00b5i \u201c \u015f\nxdPipxq denote the mean of distribution Pi. We shall denote the component functions of f by f1, . . . , fK : fp\u00b5q \u201c pf1p\u00b5q, . . . , fKp\u00b5qq. The value fip\u00b5q is interpreted as the payoff of arm i and we call f the reward map. The goal of the learner is to identify the arm with the highest payoff. It is assumed that the arm with the highest payoff is unique. The learner knows f , while is unaware of P , and, in particular, unaware of \u00b5. To gain information about \u00b5, the learner can query the distributions in discrete rounds indexed by t \u201c 1, 2, . . . , in a sequential fashion. The learner is also given \u03b4 P p0, 1q, a risk parameter (also known as a confidence parameter). The goal of the learner is to identify the arm with the highest payoff using the least number of observations while keeping the probability of making a mistake below the specified risk level.\nA learner is admissible for a given set S of problem instances if (i) for any instance from S, the probability of the learner misidentifying the optimal arm in the instance is below the given fixed risk factor \u03b4; and (ii) the learner stops with probability one on any instance from S. The interaction of a learner and a problem instance is shown on Fig. 1.\nMinimax games As a motivating example, consider the problem of finding the optimal move for the first player in a finite twoplayer minimax game. The game is finite because the game finishes in finitely many steps (by reaching one of the L possible terminating states). The first player has K\nmoves. The value of each move is a function of the values \u00b5 P RL of the L possible terminating states.\nFormally, such a minimax game is described by G \u201c pM,H, p, \u03c4q, where M is a nonempty finite set of possible moves, H \u0102 Yn\u011b0Mn is a finite set of (feasible) histories of moves, the function p : H \u00d1 t\u00b41,`1u determines, for each feasible history, the identity of the player on turn, and \u03c4 is a surjection that maps a subset Hmax \u0102 H of histories, the set of maximal histories in H, to rLs (in particular, note that \u03c4 may map multiple maximal histories to the same terminating state). An element h of H is maximal in H if it is not the prefix of any other history h1 P H, or, in other words, if it has no continuation in H. The set H has the property that if h P H then every prefix of h with positive length is also is in H. The first player\u2019s moves are given by the histories in H that have a unit length. To minimize clutter, without the loss of generality (WLOG), we identify this set with rKs.\nThe function f \u201c pf1, . . . , fKq underlying G gives the payoffs of the first player. To define f we use the auxiliary function V p\u00a8, \u00b5q : H \u00d1 R that evaluates any particular history given the values \u00b5 assigned to terminal states. Given V , we define fkp\u00b5q \u201c V ppkq, \u00b5q for any k P rKs. It remains to define V : For h P Hmax, V ph, \u00b5q \u201c \u00b5\u03c4phq. For any other feasible history h P H, V ph, \u00b5q \u201c pphqmaxtpphqV ph1, \u00b5q : h1 P Hsuccphqu, where Hsuccphq \u201c tjoinph,mq : m PMuXH is the set of immediate successors of h inH. Thus, when pphq \u201c 1, V ph, \u00b5q is the maximum of the values associated with the immediate successors of h, while when pphq \u201c \u00b41, V ph, \u00b5q is the minimum of these values. We define mph, \u00b5q as the move m defining the optimal immediate successor of h given \u00b5. Note that all many of the defined functions depend on H, but the dependence is suppressed, as we will keep H fixed. One natural problem that fits our setting is a (small) game when the payoffs at the terminating states of a game are themselves randomized (e.g., at the end of a game some random hidden information such as face down cards can decide the value of the final state). As explained by Garivier et al. (2016a), the setting may also shed light on how to design better Monte-Carlo Tree Search (MCTS) algorithms, which is a relatively novel class of search algorithms that proved to be highly successful in recent years (e.g., Gelly et al., 2012; Silver et al., 2016)."}, {"heading": "3. Lower bound: General setting", "text": "In this section we will prove a lower bound for the case of a fixed map f and when the set of instances is the set all normal distributions with unit variance. We denote the corresponding set of instances by Snormf . Our results can be easily extended to the case of other sufficientlyrich family of distributions.\nFor the next result, assume without loss of generality that f1p\u00b5q \u0105 f2p\u00b5q \u011b \u00a8 \u00a8 \u00a8 \u011b fKp\u00b5q. Fix a learner (policy) A, which maps histories to actions. For simplicity, we assume that A is deterministic (the extension to randomized algorithms is standard). Let \u2126 \u201c prLs \u02c6 RqN be the set of (infinite) sequences of observable-index and observation pairs so that for any \u03c9 \u201c pi1, y1, i2, y2, . . . q P \u2126, t \u011b 1, Itp\u03c9q \u201c it and Ytp\u03c9q \u201c yt. We equip \u2126 with the associated Lebesgue \u03c3-algebra F . For an infinite sequence \u03c9 \u201c pi1, y1, i2, y2, . . . q P \u2126, we let T p\u03c9q P N Y t8u be the round index when the algorithm stops (we let T p\u03c9q \u201c 8 if the algorithm never stops on \u03c9). Thus, T : \u2126 \u00d1 N Y t8u. Similarly, define J : \u2126 \u00d1 rK ` 1s to be the choice of the algorithm when it stops, where we define Jp\u03c9q \u201c K ` 1 in case T p\u03c9q \u201c 8.\nThe interaction of a problem instance (uniquely determined by \u00b5) and the learner (uniquely determined by the associated policy A) induces a unique distribution P\u00b5,A over the measurable space p\u2126,Fq, where we agree that in rounds with index t \u201c T ` 1, T ` 2, . . . , we specify that the algorithm chooses arm 1, while the observation distributions are modified so that the observation is deterministically set to zero. We will also use E\u00b5,A to denote the expectation operator corresponding to P\u00b5,A.\nTo appease the prudent reader, let us note that our statements will always be concerned with events that are subsets of the event tT \u0103 8u and as such they are not effected by how we specify the \u201cchoices\u201d of the algorithm and the \u201cresponses\u201d of the environment for t \u0105 T . Take, as an example, the expected number of steps that A takes in an environment \u00b5, E\u00b5,ArT s, which we bound below. Since we bound this only in the case when the algorithm A is admissible, which implies that P\u00b5,ApT \u0103 8q \u201c 1, we have E\u00b5,ArT s \u201c E\u00b5,ArT I tT \u0103 8us. which shows that the behavior of P\u00b5,A outside of P\u00b5,A outside of tT \u0103 8u is immaterial for this statement. The choices we made for t \u0105 T (for the algorithm and the environment) will however be significant in that they simplify a key technical result.\nTo state our result, we need to introduce the set of significant departures, D\u00b5 \u0102 RL, from \u00b5. This set contains all vectors \u2206 such that the best arm under \u00b5 `\u2206 is not arm 1. Formally,\nD\u00b5 \u201c t\u2206 P RL : f1p\u00b5`\u2206q \u010f max i\u01051 fip\u00b5`\u2206qu . (1)\nTheorem 1 (Lower bound) Fix a risk parameter \u03b4 P p0, 1q. Assume that A is admissible over the instance set Snormf at the risk level \u03b4. Define\n\u03c4\u02dap\u00b5q \u201c min # L \u00ff\ni\u201c1 npiq : inf \u2206PD\u00b5\nL \u00ff i\u201c1 npiq\u22062i \u011b 2 logp1{p4\u03b4qq, np1q, . . . , npLq \u011b 0\n+\n. (2)\nThen, E\u00b5,ArT s \u011b \u03c4\u02dap\u00b5q.\nThe proof can be shown to reproduce the result of Garivier and Kaufmann (2016) (see page 6 of their paper) when the setting is best arm identification. The proof uses standard steps (e.g., Auer et al., 2002; Kaufmann et al., 2016) and one of its main merit is its simplicity. In particular, it relies on two information theoretical results; a high-probability Pinsker inequality (Lemma 2.6 from (Tsybakov, 2008)) and a standard decomposition of divergences. The proof is given in Section B (all proofs omitted from the main body can be found in the appendix).\nRemark 2 (Minimal significant departures (Dmin\u00b5 )) From the set of significant departures one can remove all vectors d that are componentwise dominating in absolute value some other significant departure \u2206 P D\u00b5 without effecting the lower bound. To see this, write the lower bound as mint \u0159\ni npiq : n P X\u2206PD\u00b5\u03a6p\u2206qu, where \u03a6p\u2206q \u201c tn P r0,8qL : \u0159 i npiq\u22062i \u011b 2 logp1{p4\u03b4qqu. Then, if d,\u2206 P D\u00b5 are such that |\u2206| \u010f |d| then \u03a6p\u2206q \u0102 \u03a6pdq. Hence, X\u2206PD\u00b5\u03a6p\u2206q \u201c X\u2206PDmin\u00b5 \u03a6p\u2206q where D min \u00b5 \u201c td P D\u00b5 : E\u2206 P D\u00b5 s.t. |\u2206| \u0103 |d|u."}, {"heading": "4. Lower bound for minimax games", "text": "In this section we prove a corollary of the general lower bound of the previous section in the context of minimax games; the question being what role the structure of a game plays in the lower bound. For this section fix a minimax game structure G \u201c pM,H, p, \u03c4q (cf. Section 2). We first need some definitions:\nDefinition 1 (Proof sets) Take a minimax game structure G \u201c pM,H, p, \u03c4q with K first moves and L terminal states. Take j P rKs. A set B \u0102 rLs is said to be sufficient for proving upper bounds on the value of move j if for any \u00b5 P RL and \u03b8 P R, \u00b5|B \u201c \u03b81B implies fjp\u00b5q \u010f \u03b8. Symmetrically, a set B \u0102 rLs is said to be sufficient for proving lower bounds on the value of move j if for any \u00b5 P RL and \u03b8 P R, \u00b5|B \u201c \u03b81B implies fjp\u00b5q \u011b \u03b8.\nWe will call the sets satisfying the above definition upper (resp., lower) proof sets, denoted by B`j (resp., B \u00b4 j ). Proof sets are closely related to conspiracy sets (McAllester, 1988), forming the basis of \u201cproof number of search\u201d (Allis, 1994; Kishimoto et al., 2012). In a minimax game tree, a conspiracy set of a node (say, v) is the set of leaves that must change their evaluation value to cause a change in the minimax value of that node v. Proof sets are also related to cuts in \u03b1\u2013\u03b2 search (Russell and Norvig, 2010).\nOne can obtain minimal upper proof sets that belong to B`j in the following way: Let Hj denote the set of histories that start with move j. Consider a non-empty rH \u0102 Hj that satisfies the following properties: (i) if h P rH and pphq \u201c \u00b41 (minimizing turn) then |Hsuccphq X rH| \u201c 1; (ii) if h P rH and pphq \u201c 1 (maximizing turn) then Hsuccphq \u0102 rH. Call the set of rH that can be obtained this way H`j . From the construction of rH we immediately get the following proposition:\nProposition 3 Take any rH P H`j as above. Then, \u03c4p rH XHmaxq P B ` j .\nA similar construction and statement applies in the case of B\u00b4j , resulting in the set H \u00b4 j . Our next result will imply that the lower bound is achieved by considering departures of a special form, related to proof sets:\nProposition 4 (Minimal significant departures for minimax games) Assume WLOG that f1p\u00b5q \u0105 maxj\u01051 fjp\u00b5q. Let\nS \u201c ! \u2206 P RL : D1 \u0103 j \u010f K , \u03b8 P rfjp\u00b5q, f1p\u00b5qs, B P B`1 , B 1 P B\u00b4j s.t.\n\u2206i \u201c \u00b4p\u00b5i \u00b4 \u03b8q`, @i P BzB1; \u2206i \u201c p\u00b5i \u00b4 \u03b8q\u00b4, @i P B1zB; \u2206i \u201c \u03b8 \u00b4 \u00b5i, @i P B1 XB; \u2206i \u201c 0, @i P pB YB1qc ) .\nThen, Dmin\u00b5 \u0102 S \u0102 D\u00b5.\nNote that the second inclusion shows that replacing D\u00b5 by S in the definition of \u03c4\u02dap\u00b5q would only decrease the value of \u03c4\u02dap\u00b5q, while the first inclusion shows that the value actually does not change. The following lemma, characterizing minimal departures, is essential for our proof of Proposition 4:\nLemma 5 Take any \u00b5 P RL, d P Dmin\u00b5 and assume WLOG that f1p\u00b5q \u0105 maxj\u01051 fjp\u00b5q. Then, there exist B P B`1 , j P t2, . . . ,Ku and B1 P B \u00b4 j such that\n(i) maxtp\u00b5` dqi : i P Bu \u201c f1p\u00b5` dq \u201c fjp\u00b5` dq \u201c mintp\u00b5` dqi : i P B1u;\n(ii) di \u010f 0 if i P BzB1; di \u011b 0 if i P B1zB;\n(iii) @i P B YB1, either p\u00b5` dqi \u201c f1p\u00b5` dq \u201c fjp\u00b5` dq or di \u201c 0.\nProposition 4 implies the following:\nCorollary 6 Let \u00b5 be a valuation and assume WLOG that f1p\u00b5q \u0105 maxj\u01051 fjp\u00b5q. Let Bj \u201c tpB,B1q : B P B`1 , B1 P B \u00b4 j u. Then,\n\u03c4\u02dap\u00b5q \u201c min nPr0,8qL\n!\n\u00ff\ni\nnpiq : min 1\u0103j\u010fK,\u03b8Prfjp\u00b5q,f1p\u00b5qs,pB,B1qPBj\n\u00ff\niPBzB1 npiqp\u00b5i \u00b4 \u03b8q2` `\n\u00ff\niPB1zB npiqp\u00b5i \u00b4 \u03b8q2\u00b4\n` \u00ff\niPBXB1 npiqp\u03b8 \u00b4 \u00b5iq2 \u011b 2 logp 14\u03b4 q\n)\n.\nHence, for any algorithm A admissible over the instance set Snormf at the risk level \u03b4, E\u00b5,ArT s is at least as large than the right-hand side of the above display."}, {"heading": "5. Upper bound", "text": "In this section we propose an algorithm generalizing the LUCB algorithm of Kalyanakrishnan et al. (2012) and prove a theoretical guarantee for the proposed algorithm\u2019s sample complexity under some (mild) assumptions on the structure of the reward mapping f . Our result is inspired and extends the results of Garivier et al. (2016a) (who also started from the LUCB algorithm) to the general setting proposed in this paper. In Section 6 we give a version of the algorithm presented here that is specialized to minimax games and refine the upper bound of this section, highlighting the advantages of the extra structure of minimax games.\nIn this section we shall assume that the distributions pPiqiPrLs are subgaussian with a common parameter, which we take to be one for simplicity:\nAssumption 1 (1-Subgaussian observations) For any i P rLs, X \u201e Pip\u00a8q,\nsup \u03bbPR\nE \u201c expp\u03bbpX \u00b4 EXq \u00b4 \u03bb2{2q \u2030 \u010f 1 .\nWe will need a result for anytime confidence intervals for martingales with subgaussian increments. For stating this result, let pFtqtPN be a filtration over the probability space p\u2126,F ,Pq holding our random variables and introduce Etr\u00a8s \u201c E r\u00a8|Ft\u00b41s. This result appears as (essentially) Theorem 8 in the paper by Kaufmann et al. (2016) who also cite precursors:\nLemma 7 (Anytime subgaussian concentration) Let pXtqtPN be an pFtqtPN-adapted 1- subgaussian, martingale difference sequence (i.e., for any t P N, Xt is Ft-measurable, EtXt \u201c\n0, and sup\u03bb Et \u201c expp\u03bbpXtq \u00b4 \u03bb2{2q \u2030 \u010f 1). For t P N, let Xt \u201c p1{tq \u0159t s\u201c1Xs, while for t P NY t0u and \u03b4 P r0, 1s we let\n\u03b2pt, \u03b4q \u201c logp1{\u03b4q ` 3 log logp1{\u03b4q ` p3{2qplogplogpetqqq` .\nThen, for any \u03b4 P r0, 0.1s,1\nP\n\u02dc\nsup tPN\nXt a\n2\u03b2pt, \u03b4q{t \u0105 1\n\u00b8\n\u010f \u03b4 .\nFor a fixed i P rLs, let Ntpiq \u201c \u0159t s\u201c1 I tIs \u201c iu denote the number of observations taken from Pip\u00a8q up to time t. Define the confidence interval rL\u03b4t piq, U \u03b4t piqs for \u00b5i as follows: We let\np\u00b5tpiq \u201c 1\nNtpiq\nt \u00ff s\u201c1 I tIs \u201c iuYs ,\nthe empirical mean of observations from Pip\u00a8q to be the center of the interval (whenNtpiq \u201c 0, we define p\u00b5tpiq \u201c 0) and\nL\u03b4t piq \u201c max # L\u03b4t\u00b41piq, p\u00b5tpiq \u00b4\nd\n2\u03b2pNtpiq, \u03b4{p2Lqq Ntpiq\n+\n;\nU \u03b4t piq \u201c min # U \u03b4t\u00b41piq, p\u00b5tpiq `\nd\n2\u03b2pNtpiq, \u03b4{p2Lqq Ntpiq\n+\n,\nwhere \u03b2pt, \u03b4q is as in Lemma 7 (note that when Ntpiq \u201c 0, the confidence interval is p\u00b48,`8q). Let T be the index of the round when the algorithm soon to be proposed stops (or T \u201c 8 if it does not stop). Let \u03be \u201c XtPrT s,iPrLst\u00b5i P rL\u03b4t piq, U \u03b4t piqsu be the \u201cgood\u201d event when the proposed respective intervals before the algorithm stops all contain \u00b5i for all i P rLs. One can easily verify that, regardless the choice of the algorithm (i.e., the stopping time T ),\nP p\u03beq \u011b 1\u00b4 \u03b4 , (3) @t P N, L\u03b4t piq \u010f p\u00b5tpiq \u010f U \u03b4t piq. (4)\nFor S \u0102 RL define fpSq \u201c tfpsq : s P Su. With this definition, if we let St \u201c \u015aL i\u201c1rL\u03b4t piq, U \u03b4t piqs then for any j P rKs, fjp\u00b5q P fjpStq holds for any t \u011b 1 on \u03be. Thus, fjpStq is a valid, p1\u00b4 \u03b4qlevel confidence set for fjp\u00b5q. For general f , these sets may have a complicated structure. Hence, we will adapt the following simplifying assumption:\nAssumption 2 (Regular reward maps) The following hold:\n(i) The mapping function f is monotonous with respect to the partial order of vectors: for any u, v P RL, u \u010f v implies fpuq \u010f fpvq;\n1. Note that \u03b2pt, \u03b4q is also defined for t \u201c 0. The value used is arbitrary: It plays no role in the current result. The reason we define \u03b2 for t \u201c 0 is because it simplifies some subsequent definitions.\n(ii) For any u, v P RL, u \u010f v, j P rKs, the set Dpj, u, vq \u201c ti P rLs : rfjpuq, fjpvqs \u0102 rui, vis u is non-empty.\nWe will also let Dtpjq \u201c Dpj, L\u03b4t , U \u03b4t q. Note that the assumption is met when f is the reward map underlying minimax games (see the next section). The second assumption could be replaced by the following weaker assumption without essentially changing our result: with some a \u0105 0, b P R, for any j, u \u010f v, rfjpuq, fjpvqs \u0102 raui ` b, avi ` bs for some i P rLs. The point of this assumption is that by guaranteeing that all intervals on the micro-observables shrink, the interval on the arm-rewards will also shrink at the same rate. We expect that other ways of weakening this assumption are also possible, perhaps at the price of slightly changing the algorithm (e.g., by allowing it to use even more micro-observations per round).\nAlgorithm 1 LUCB-micro for t \u201c 1, 2, . . . do Choose Bt, Ct as in Equation (5) Choose any pIt, Jtq from DtpBtq\u02c6DtpCtq Observe Yt,1 \u201e PItp\u00a8q, Yt,2 \u201e PJtp\u00a8q Update rL\u03b4t pItq, U \u03b4t pItqs, rL\u03b4t pJtq, U \u03b4t pJtqs if Stop() then J \u00d0 Bt, T \u00d0 t return pT, Jq\nAt time t, let\nBt \u201c argmax jPrKs fjpL\u03b4t q ,\nCt \u201c argmax jPrKs,j\u2030Bt\nfjpU \u03b4t q . (5)\n(B stands for candidate \u201cbest\u201d arm, C stands for best \u201ccontender\u201d arm). Based on the above assumption, we can now propose our algorithm, LUCB-micro (cf. Algorithm 1). Following the idea of LUCB, LUCB-micro chooses Bt and Ct in an effort to separate the highest lower bound from the best competing upper bound.2 To decrease the width of the confidence intervals, both for Bt and Ct, a micro-observable is chosen with the help of Assumption 2(ii). This can be seen as a generalization of the choice made in Maximin-LUCB by Garivier et al. (2016a). Here, we found that the specific way Maximin-LUCB\u2019s choice is made considerably obscured the idea behind this choice, which one can perhaps attribute to that the fact that the two-move setting makes it possible to write the choice in a more-or-less direct fashion.\nIt remains to specify the \u2018Stop()\u2019 function used by our algorithm. For this, we propose the standard choice (as in LUCB):\nStop() : fBtpL\u03b4t q \u011b fCtpU \u03b4t q. (6)\nAll statements in this section assume that the assumptions stated so far in this section hold.\nThe following proposition is immediate from the definition of the algorithm.\nProposition 8 (Correctness) On the event \u03be, LUCB-micro returns J correctly: J \u201c j\u02dap\u00b5q.\nLet T denote the round index when LUCB-micro stops3 and define c \u201c f1p\u00b5q`f2p\u00b5q2 and \u2206 \u201c f1p\u00b5q \u00b4 f2p\u00b5q, where we assumed that f1p\u00b5q \u0105 f2p\u00b5q \u011b maxj\u011b2 fjp\u00b5q. The main result\n2. Using a lower bound departs from the choice of LUCB, which would use fjp\u00b5\u0302tq to define Bt. The reason of this departure is that we found it easier to work with a lower bound. We expect the two versions (original, our choice) to behave similarly. 3. The number of observations, or number of rounds as per Fig. 1, taken by LUCB-micro until it stops is 2T .\nof this section is a high-probability bound on T , which we present next. The following lemma is the key to the proof:\nLemma 9 Let t \u0103 T . Then, on \u03be, there exists J P tBt, Ctu such that c P rfJpL\u03b4t q, fJpU \u03b4t qs and fJpU \u03b4t q \u00b4 fJpL\u03b4t q \u011b \u2206{2.\nThe proof follows standard steps (e.g., Garivier et al. 2016a). In particular, the above lemma implies that if T \u0105 t then for J P tBt, Ctu, c P rfJpL\u03b4t q, fJpU \u03b4t qs and fJpU \u03b4t q\u00b4fJpL\u03b4t q \u011b \u2206{2. This in turn implies that for i P tIt, Jtu, Ntpiq cannot be too large.\nTheorem 10 (LUCB-micro upper bound) Let\nHp\u00b5q \u201c \u00ff\niPrLs\n\"\n1 pc\u00b4 \u00b5iq2 \u013e 1 p\u2206{2q2\n*\n, and t\u02dap\u00b5q \u201c mintt P N : 1` 8Hp\u00b5q\u03b2pt, \u03b4{p2Lqq \u010f tu .\nThen, for \u03b4 \u010f 0.1, on the event \u03be, the stopping time T of LUCB-micro satisfies T \u010f t\u02dap\u00b5q.\nNote that \u03b2pt, \u03b4q9 log log t and thus t\u02dap\u00b5q is well-defined. Furthermore, letting c\u03b4 \u201c logp2L{\u03b4q ` 3 log logp2L{\u03b4q, for \u03b4 sufficiently small and Hp\u00b5q sufficiently large, elementary calculations give\nt\u02dap\u00b5q \u010f 16Hp\u00b5qc\u03b4 ` 16Hp\u00b5q log logp8Hp\u00b5qc\u03b4q .\nRemark 11 The constant Hp\u00b5q acts as a hardness measure of the problem. Theorem 10 can be applied to the best arm identification problem in the multi-armed bandits setting, as it is a special case of our problem setup. Compared to state-of-the-art results available for this setting, our bound is looser in several ways: We lose on the constant factor multiplying Hp\u00b5q (Kalyanakrishnan et al., 2012; Jamieson and Nowak, 2014; Jamieson et al., 2014; Kaufmann et al., 2016), we also lose an additive term of Hp\u00b5q log logpLq (Chen and Li, 2015). We also lose logpLq terms on the suboptimal arms (Simchowitz et al., 2017). Comparing with the only result available in the two-move minimax tree setting, due to Garivier et al. (2016a), our bound is looser than their Theorem 1. This motivates the refinement of this result to the minimax setting, which is done in the next section, and where we recover the mentioned result of Garivier et al. (2016a). On the positive side, our result is more generally applicable than any of the mentioned results. It remains an interesting sequence of challenges to prove an upper bound for this or some other algorithm which would match the mentioned state-ofthe-art results, when the general setting is specialized."}, {"heading": "6. Best move identification in minimax games", "text": "In this section we will show upper bounds on the number of observations LUCB-micro takes in the case of minimax game problems. We still assume that the micro-observations are subgaussian (Assumption 1) and the optimal arm is unique. To apply our result, this leaves us with showing that the payoff function in the minimax game satisfies the regularity assumption (Assumption 2).\nFix a minimax game structure G \u201c pM,H, p, \u03c4q. We first show that Property (i) of Assumption 2 holds. This follows easily from the following lemma, which can be proven by induction based on \u201cdistance from the terminating states\u201d.\nLemma 12 For any h P H and u, v P r0, 1sL such that u \u010f v, V ph, uq \u010f V ph, vq.\nFrom this result we immediately get the following corollary:\nCorollary 13 For u, v P r0, 1sL such that u \u010f v, fpuq \u010f fpvq, hence Assumption 2 (i) holds.\nFor j P rKs, u, v P RL, u \u010f v, per Property (ii) of Assumption 2, we need to show that the sets Dpj, u, vq are nonempty. For a history h \u201c pm1,m2, . . . ,m`q P H and 1 \u010f k \u010f `, we denote its length-k prefix pm1, . . . ,mkq by hk. We give an algorithmic demonstration, which also shows how to efficiently pick an element of these sets. The resulting algorithm is called MinMax (cf. Algorithm 2). We define MinMax in a recursive fashion: For each nonmaximal history the algorithm extends the history by adding the move which is optimal for u for minimizing moves, while it extends it by adding the optimal move for v for maximizing moves, and then it calls itself with the new history. The algorithm returns when its input is a maximal history. To show that \u03c4pMinMaxph, u, vqq P Dpj, u, vq we have the following result:\nLemma 14 Fix u, v P RL, u \u010f v, and j P rKs. Let h \u201c MinMaxppjqq and in particular let h \u201c pm1 \u201c j,m2, . . . ,m`q. Then, for all 1 \u010f k \u0103 `,\nrV phk, uq, V phk, vqs \u0102 rV phk`1, uq, V phk`1, vqs ,\nwhere hk is the length-k prefix of h.\nWe immediately get that i \u201c \u03c4phq is an element of Dpj, u, vq:\nCorollary 15 For j, u, v, h as in the previous result, setting i \u201c \u03c4phq, rfjpvq, fjpvqs \u0102 rui, viqs, hence i P Dpj, u, vq \u2030 H.\nWith this, we have shown that all the assumptions needed by Theorem 10 are satisfied, and in particular, we can use It \u201c MinMaxpBt, L\u03b4t , U \u03b4t q and Jt \u201c MinMaxpCt, L\u03b4t , U \u03b4t q. We call the resulting algorithm LUCBMinMax. Then, Theorem 10 gives:\nCorollary 16 Let \u03be, c,\u2206, Hp\u00b5q, t\u02da be as in Section 5. If T is the stopping time of LUCBMinMax running on a minimax game search problem then T \u010f t\u02da.\nAlgorithm 2 MinMax. Inputs: h P H, u, v P RL. if h P Hmax then return h\nelse if pphq \u201c \u00b41 then h\u00d0 joinph,mph, uqq else if pphq \u201c 1 then h\u00d0 joinph,mph, vqq return MinMaxph, u, vq When applied to a minimax game, as defined in Section 2, the upper bound of Corollary 16 is loose and can be further improved as shown in the result below. To state this result we need some further notation. Given a set of reals S, define the \u201cspan\u201d of S as spanpSq \u201c maxu,vPS u \u00b4 v. For a path h P H that connects some move in rKs and some move in rLs: h \u201c pm1, . . . ,m`q with some ` \u011b 0, m1 P rKs and m` P rLs. Finally, for i P rLs such that there is a unique path h P H satisfying \u03c4phq \u201c i, define Vpi, \u00b5q \u201c tV phk, \u00b5q : h \u201c pm1, . . . ,m` \u201c iq, m1 P rKs, 1 \u010f k \u0103 `u. Let Vpi, \u00b5q be an empty set if there is multiple h P H such that \u03c4phq \u201c i.\nTheorem 17 (LUCBMinMax on MinMax Trees) Let\nHp\u00b5q \u201c \u00ff iPrLs mint 1 spanpVpi, \u00b5q Y tc, \u00b5iuq2 , 4 \u22062 u, t\u02dap\u00b5q \u201c mintt P N : 1` 8Hp\u00b5q\u03b2pt, \u03b4{p2Lqq \u010f tu .\nThen, on \u03be, the stopping time T of LUCBMinMax satisfies T \u010f t\u02dap\u00b5q.\nRemark 18 Note that this result recovers Theorem 1 of Garivier et al. (2016a). To see this note that for every leaf pi, jq (as numbered in their paper), \u00b5i,1 P Vppi, jq, \u00b5q. Also note that \u00b5i,1 \u010f \u00b5i,j, thus |c \u00b4 \u00b5i,j | \u010f maxt|c \u00b4 \u00b5i,1|, |\u00b5i,j \u00b4 \u00b5i,1|u. Therefore, spanpt\u00b5i,1, \u00b5i,j , cuq \u201c maxt|\u00b5i,1 \u00b4 c|, |\u00b5i,j \u00b4 \u00b5i,1|u."}, {"heading": "7. Discussion and Conclusions", "text": "The gap between the lower bound and the upper bound There is a substantial gap between the lower and the upper bound. Besides the gaps that already exist in the multiarmed bandit setting and which have been mentioned before, there exists a substantial gap: In particular, it is not hard to show that in regular minimax game trees with a fixed branching factor of \u03ba and depth d, the upper bound scales with Op\u03badq while the lower bound scales with Op\u03bad{2q. One potential is to improve the lower bound so as to consider adversarial perturbations of the values assigned to the leaf nodes: That is, after the algorithm is fixed, an adversary can perturb the values of \u00b5 to maximize the lower bound. Simchowitz et al. (2017) introduces an interesting technique for proving lower bounds of this form and they demonstrate nontrivial improvements in the multi-armed bandit setting.\nDoes the algorithm need to explore all leaves? The hardness measure Hp\u00b5q is rooted in a uniform bound that suggests that all the leaves must potentially be pulled, which may not hold for some particular structure. In particular, the algorithm may be able to benefit from the specific structure of f , saving explorations on some leaves. We present one example when f is a minimax game tree, as in Figure 2. Assume that \u00b51,i \u201c \u00b5\u02da \u0105\u0105 \u00b5\u02da\u02da \u201c \u00b5j,i for 1 \u010f i \u010f K and 2 \u010f j \u010f K. A reasonable algorithm would sample each arm once, then discover that the others arms are much less than the sampled leaf under arm 1. Then the algorithm will continue to explore the other leaves of arm 1, and decide arm 1 to be the best arm. This behavior is also in agreement with our lower bound, where the resulting constraints are:\nN1,ip\u00b5\u02da \u00b4 \u00b5\u02da\u02daq2 \u011b 2 logp1{4\u03b4q; K \u00ff\ni\u201c1 Nj,ip\u00b5\u02da \u00b4 \u00b5\u02da\u02daq2 \u011b 2 logp1{4\u03b4q @j \u2030 1,\nwhich implies N1,i \u011b 1 and \u0159K i\u201c1Nj,i \u011b 1 for j \u2030 1 if \u00b5\u02da\u00b4\u00b5\u02da\u02da is large enough. As we can see from this example, pK\u00b41q2 (out ofK2) leaves need no exploration at all. On the other hand, although we don\u2019t have a tight upper bound, our algorithm in practice manages to explore the remaining K\u00b41 leaves under arm 1 for the next K\u00b41 rounds, and then make the right decision.\nIn general, we would expect that a problem with a feed forward neural network structure is easier than that of a tree structure, as the share of the leaves provides more information and thus save the exploration. This is illustrated on Fig. 3, where an optimal arm can be identified solely based on the network structure, thus the algorithm requires 0 sample for all possible \u00b5. Note that our lower bound does not fail, as we have D\u00b5 \u201c H here.\nAppendices"}, {"heading": "A. The Uniqueness Assumption", "text": "Recall that throughout the paper, by definition, we have the following assumption:\nAssumption 3 The instance is such that j\u02dap\u00b5q \u201c argmaxj fjp\u00b5q is unique.\nWe state this assumption explicitly here, so that we can refer to it easily throughout the appendix."}, {"heading": "B. Proofs for Section 3", "text": "Here we prove Theorem 1, which is restated for the convenience of the reader:\nTheorem 1 (Lower bound) Fix a risk parameter \u03b4 P p0, 1q. Assume that A is admissible over the instance set Snormf at the risk level \u03b4. Define\n\u03c4\u02dap\u00b5q \u201c min # L \u00ff\ni\u201c1 npiq : inf \u2206PD\u00b5\nL \u00ff i\u201c1 npiq\u22062i \u011b 2 logp1{p4\u03b4qq, np1q, . . . , npLq \u011b 0\n+\n. (2)\nThen, E\u00b5,ArT s \u011b \u03c4\u02dap\u00b5q.\nWe start with the two information theoretic results mentioned in the main body of the text. To state these results, let DpP,Qq denote the Kullback\u2013Leibler (KL) divergence of two distributions P and Q. Recall that this is \u015f\nlogpdPdQqdQ when P is absolutely continuous with respect to Q and is infinite otherwise. For the next result, let Npiq \u201c\n\u0159T t\u201c1 I tIt \u201c iu denote\nthe number of times an observation on the micro-observable with index i P rLs before time T .\nLemma 19 (Divergence decomposition) For any \u00b5, \u00b51 P RL it holds that\nDpP\u00b5,A,P\u00b51,Aq \u201c 1\n2\nL \u00ff i\u201c1 E\u00b5,ArNpiqs p\u00b5i \u00b4 \u00b51iq2 . (7)\nNote that 12p\u00b5i \u00b4 \u00b5 1 iq2 on the right-hand side is the KL divergence between the normal distributions with means \u00b5i and \u00b51i and both having a unit variance. The result, naturally, holds for other distributions, as well. This is the result that relies strongly on that we forced the same observations and same observation-choices for t \u0105 T . In particular, this is what makes the left-hand side of (7) finite! The proof is standard and hence is omitted.\nLemma 20 (High probability Pinsker, e.g., Lemma 2.6 from (Tsybakov, 2008)) Let P and Q be probability measures on the same measurable space p\u2126,Fq and let E P F be an arbitrary event. Then,\nP pEq `QpEcq \u011b 1 2 expp\u00b4DpP,Qqq .\nProof [of Theorem 1] WLOG, we may assume that D\u02dd\u00b5 is non-empty. Pick any \u2206 P D\u02dd\u00b5 and let \u00b51 \u201c \u00b5 `\u2206. Let E \u201c tJ \u2030 1u. Since A is admissible, P\u00b5,ApEq \u010f \u03b4. Further, since \u2206 P D\u02dd\u00b5, 1 is not an optimal arm in \u00b51. Hence, again by the admissibility of A, P\u00b51,ApEcq \u010f \u03b4. Therefore, by Lemma 20,\n2\u03b4 \u011b P\u00b5,ApEq ` P\u00b51,ApEcq \u011b 1\n2 expp\u00b4DpP\u00b5,A,P\u00b51,Aqq .\nNow, plugging in (7) of Lemma 19 and reordering we get\nlogp1{p4\u03b4qq \u010f DpP\u00b5,A,P\u00b51,Aq \u201c 1\n2\nL \u00ff i\u201c1 E\u00b5,ArNpiqs p\u00b5i \u00b4 \u00b51iq2 .\nThe result follows by continuity, after noting that T \u201c \u0159L i\u201c1Npiq, that \u2206 P D\u02dd\u00b5 was arbitrary."}, {"heading": "C. Proofs for Section 4", "text": "We start with the following lemma:\nLemma 21 Pick any \u00b5 P RL, j P rKs. Then,\n@B P B`j , fjp\u00b5q \u010f maxt\u00b5i : i P Bu; @B P B \u00b4 j , fjp\u00b5q \u011b mint\u00b5i : i P Bu.\nProof Fix any \u00b5 P RL, j P rKs, B P B`j . Let u \u201c maxt\u00b5i : i P Bu. We want to show that fjp\u00b5q \u010f u. Define \u00b51 \u011b \u00b5 such that \u00b51i \u201c \u00b5i if i R B, and \u00b51i \u201c u otherwise. As noted earlier (cf. Corollary 13), fj is monotonous. Hence, fjp\u00b5q \u010f fjp\u00b51q \u010f u, where the last inequality follows because B P B`j . The proof concerning B \u00b4 j is analogous and is left to the reader.\nLemma 5 Take any \u00b5 P RL, d P Dmin\u00b5 and assume WLOG that f1p\u00b5q \u0105 maxj\u01051 fjp\u00b5q. Then, there exist B P B`1 , j P t2, . . . ,Ku and B1 P B \u00b4 j such that\n(i) maxtp\u00b5` dqi : i P Bu \u201c f1p\u00b5` dq \u201c fjp\u00b5` dq \u201c mintp\u00b5` dqi : i P B1u;\n(ii) di \u010f 0 if i P BzB1; di \u011b 0 if i P B1zB;\n(iii) @i P B YB1, either p\u00b5` dqi \u201c f1p\u00b5` dq \u201c fjp\u00b5` dq or di \u201c 0.\nProof Note that since d P D\u00b5, f1p\u00b5` dq \u010f fjp\u00b5` dq for some j \u2030 1. Fix such an index j. To construct B and B1, we will pick rH1 P H`1 , rHj P H \u00b4 j and set B \u201c \u03c4p rH1 XHmaxq and B1 \u201c \u03c4p rHj XHmaxq. By the construction of H`1 , to pick rH1 it suffices to specify the unique successor h1 in rH1 of any history h P rH1 with pphq \u201c \u00b41. For this, we let h1 P H be the successor for which V ph1, \u00b5`dq \u201c V ph, \u00b5`dq. Similarly, by the construction of H\u00b4j , to pick rHj it suffices to specify the unique successor h1 in rHj of any history h P rHj with pphq \u201c `1. Again, we let h1 P H be the successor for which V ph1, \u00b5 ` dq \u201c V ph, \u00b5 ` dq. Note that by Proposition 3, B P B`1 and B1 P B \u00b4 j .\nLet us now turn to the proof of (i). We start by showing that\nf1p\u00b5` dq \u201c maxtp\u00b5` dqi : i P Bu . (8)\nTo show this, we first prove that\nV ph, \u00b5` dq \u010f f1p\u00b5` dq @h P rH1 . (9)\nThe proof uses induction based on the length of histories in rH1. There is only one history of length 1 (base case): h \u201c p1q. By the definition of f1, V ph, \u00b5`dq \u201c f1p\u00b5`dq. Now, assume that the statement holds for all histories up to length c \u011b 1. Take any h P rH1 of length c` 1. Let h1 P rH1 be the unique immediate predecessor of h: h P Hsuccph1q. This is well-defined thanks to the definition of H and the construction of rH1. If pph1q \u201c \u00b41 then, by the definition of rH1, V ph, \u00b5`dq \u201c V ph1, \u00b5`dq. By the induction hypothesis, V ph1, \u00b5` dq \u010f f1p\u00b5` dq, implying V ph, \u00b5` dq \u010f f1p\u00b5` dq. On the other hand, if pph1q \u201c `1 then f1p\u00b5`dq \u011b V ph1, \u00b5`dq \u201c maxtV ph\u0303, \u00b5`dq, h\u0303 P Hsuccph1qu \u011b V ph, \u00b5`dq, finishing the induction. Hence, we have proven (9).\nNow, we claim that there exists h\u02da P rH1 X Hmax such that V ph\u02da, \u00b5 ` dq \u201c f1p\u00b5 ` dq. This, together with (9) implies (8).\nWe construct h\u02da in a sequential process. For this, we will choose a sequence of moves m1, . . . ,mk such that pm1, . . . ,miq P HmaxX rH1 and V ppm1, . . . ,miq, \u00b5` dq \u201c f1p\u00b5` dq for any 1 \u010f i \u010f k. In a nutshell, this sequence is an \u201coptimal sequence of moves\u201d that starts with move 1, which is also known as a principal variation for the game under move 1. In details, the construction is as follows: To start, we choose m1 \u201c 1. Then V ppm1q, \u00b5`dq \u201c f1p\u00b5`dq, by the definition of f1. Assume that for some i \u011b 1, we already chose pm1, . . . ,miq so that V ppm1, . . . ,miq, \u00b5` dq \u201c f1p\u00b5` dq holds. If h\n.\u201c pm1, . . . ,miq P Hmax, we let k \u201c i and we are done. Otherwise, let mi`1 \u201c mph, \u00b5`dq (this is the \u201coptimal move\u201d at h under valuation \u00b5 ` d). Thus, V pjoinph,mi`1q, \u00b5 ` dq \u201c V ph, \u00b5 ` dq \u201c f1p\u00b5q. Further, by the construction of rH1, joinph,mi`1q P rH1. Since all histories in H are bounded in length, the process ends after some k moves for some finite k, at which point we are done proving our statement.\nTo recap, so far we have proved (8). An entirely analogous proof (left to the reader) shows that also fjp\u00b5` dq \u201c mintp\u00b5` dqi : i P B1u.\nWe now prove that f1p\u00b5`dq \u201c fjp\u00b5`dq, finishing the proof of (i). Assume to the contrary that f1p\u00b5`dq \u0103 fjp\u00b5`dq. Consider the map g : \u03b1 \u00de\u00d1 f1p\u00b5`\u03b1dq\u00b4fjp\u00b5`\u03b1dq on the interval \u03b1 P r0, 1s. Note that g is continuous, gp0q \u0105 0 \u0105 gp1q. Hence, by the intermediate value theorem, there exists \u03b1 P p0, 1q such that gp\u03b1q \u201c 0. Note that f1p\u00b5 ` \u03b1dq \u201c fjp\u00b5 ` \u03b1dq. Hence, \u03b1d P D\u00b5. Since \u03b1|d| \u0103 |d|, d P Dmin\u00b5 cannot hold, a contradiction. Hence, f1p\u00b5`dq \u201c fjp\u00b5` dq.\nLet us now turn to the proof of (ii). We prove that di \u010f 0 holds for all i P BzB1. (The statement concerning elements of B1zB follows similarly, the details are left to the reader.) For the proof, assume to the contrary of the desired statement that there exists some i P BzB1 such that di \u0105 0. Let d1 P RL be such that d1k \u201c dk for j \u2030 i, and d1i \u201c 0. Thus, d1 \u0103 d. By Corollary 13, f1p\u00b5 ` d1q \u010f f1p\u00b5 ` dq \u010f fjp\u00b5 ` dq \u201c mintp\u00b5 ` dqk : k P B1u \u201c mintp\u00b5` d1qk : k P B1u \u010f fjp\u00b5` d1q, where the last equality is due to i R B1 (hence, p\u00b5` dq|B1 \u201c p\u00b5` d1q|B1) while the last inequality follows from Lemma 21. This implies that d1 P D\u00b5. This together with |d1| \u0103 |d| contradicts d P Dmin\u00b5 . Thus, (ii) holds.\nIt remains to prove (iii). For this pick i P B. Since f1p\u00b5 ` dq \u201c fjp\u00b5 ` dq has already been established, it suffices to show that either p\u00b5 ` dqi \u201c f1p\u00b5 ` dq or di \u201c 0. (The case when i P B1 is symmetric and is left to the reader.) If i P B X B1 then by (i), p\u00b5 ` dqi \u010f maxkPBp\u00b5 ` dqk \u201c f1p\u00b5 ` dq \u201c fjp\u00b5 ` dq \u201c minkPB1p\u00b5 ` dqk \u010f p\u00b5 ` dqi, showing that p\u00b5 ` dqi \u201c f1p\u00b5 ` dq \u201c fjp\u00b5 ` dq. Hence, assume that i R B X B1. If di \u201c 0 or p\u00b5 ` dqi \u201c f1p\u00b5 ` dq then we are done. Otherwise, by (ii), di \u0103 0 and by (i), p\u00b5 ` dqi \u0103 maxkPBp\u00b5 ` dqk \u201c f1p\u00b5 ` dq. Let \u201c f1p\u00b5 ` dq \u00b4 p\u00b5 ` dqi. Note that \u0105 0. Define d1 P RL so that d1k \u201c dk if k \u2030 i and let d1i \u201c \u00b4pdi ` q\u00b4. That is, di is shifted up towards zero by a positive amount so that it never crosses zero. Then, |d1| \u0103 |d|. Note also that \u00b5i ` d1i \u201c \u00b5i ` minpdi ` , 0q \u010f \u00b5i ` di ` \u201c f1p\u00b5 ` dq \u201c maxkPBp\u00b5 ` dqk. Hence, maxkPBp\u00b5`d1qk \u201c maxkPBp\u00b5`dqk \u201c f1p\u00b5`dq and thus by Lemma 21, f1p\u00b5`d1q \u010f maxkPBp\u00b5`dq1k \u201c f1p\u00b5`dq. By (i), f1p\u00b5`dq \u201c fjp\u00b5`dq \u201c minkPB1p\u00b5`dqk. By the definition of d1 (thanks to i R B1) and Lemma 21, minkPB1p\u00b5 ` dqk \u201c minkPB1p\u00b5 ` d1qk \u010f fjp\u00b5 ` d1q. Putting together the inequalities, we get f1p\u00b5` d1q \u010f fjp\u00b5` d1q. Hence, d1 P D\u00b5. However, this and |d1| \u0103 |d| contradict d P Dmin\u00b5 , finishing the proof of (iii).\nLemma 22 Given any \u00b5 P RL and any \u03b8 P R, define \u00b51 as follows:\n\u00b51i \u201c # \u03b8, i P I; \u00b5i, otherwise,\nwhere I \u0102 ti : \u00b5i \u011b \u03b8u. Then, fjp\u00b51q \u011b mint \u03b8, fjp\u00b5q u for any j P rKs.\nProof Fix j P rKs. We prove V ph, \u00b51q \u011b mint\u03b8, V ph, \u00b5qu for h P H by induction based on how close a history h is to being a maximal history. Note that this suffices to prove the statement thanks to fjp\u00b51q \u201c V ppjq, \u00b51q \u011b mint\u03b8, V ppjq, \u00b5qu \u201c mint\u03b8, fjp\u00b5qu.\nDefine function c so that cphq \u201c 0 if h P Hmax, and cphq \u201c 1`maxtcph1q : h1 P Hsuccphqu otherwise. Base case: If h P Hmax, then V ph, \u00b51q \u201c \u00b51i P t\u00b5i, \u03b8u \u011b mint\u03b8, \u00b5iu \u201c mint\u03b8, V ph, \u00b5qu for\nsome i P rLs. Induction step: Assume that for any h P H such that cphq \u010f c, V ph, \u00b51q \u011b mint\u03b8, V ph, \u00b5qu. Given h such that cphq \u201c c` 1, if pphq \u201c 1,\nV ph, \u00b51q \u201c maxtV ph1, \u00b51q : h1 P Hsuccphqu \u011b maxtmint\u03b8, V ph1, \u00b5qu : h1 P Hsuccphqu (by induction) (a) \u011b mint\u03b8, V ph1\u02da, \u00b5qu \u201c mint\u03b8, V ph, \u00b5qu,\nwhere in (a), h1\u02da is the optimal h1 such that V ph1\u02da, \u00b5q \u201c V ph, \u00b5q. If pphq \u201c \u00b41,\nV ph, \u00b51q \u201c mintV ph1, \u00b51q : h1 P Hsuccphqu \u011b mintmint\u03b8, V ph1, \u00b5qu : h1 P Hsuccphqu (b) \u011b mint\u03b8, mintV ph1, \u00b5q : h1 P Hsuccphquu \u011b mint\u03b8, V ph, \u00b5qu.\nHere (b) holds because for any h1 P Hsuccphq, V ph1, \u00b5q \u011b mintV ph1, \u00b5q : h1 P Hsuccphqu, thus mint\u03b8 , V ph1, \u00b5qu \u011b mint\u03b8, mintV ph1, \u00b5q : h1 P Hsuccphquu.\nWith this, we are ready to prove Proposition 4, which we repeat here for the reader\u2019s convenience:\nProposition 4 (Minimal significant departures for minimax games) Assume WLOG that f1p\u00b5q \u0105 maxj\u01051 fjp\u00b5q. Let\nS \u201c ! \u2206 P RL : D1 \u0103 j \u010f K , \u03b8 P rfjp\u00b5q, f1p\u00b5qs, B P B`1 , B 1 P B\u00b4j s.t.\n\u2206i \u201c \u00b4p\u00b5i \u00b4 \u03b8q`, @i P BzB1; \u2206i \u201c p\u00b5i \u00b4 \u03b8q\u00b4, @i P B1zB; \u2206i \u201c \u03b8 \u00b4 \u00b5i, @i P B1 XB; \u2206i \u201c 0, @i P pB YB1qc ) .\nThen, Dmin\u00b5 \u0102 S \u0102 D\u00b5.\nProof First we prove Dmin\u00b5 \u0102 S. For this take any d P Dmin\u00b5 . Since d P D\u00b5, by Lemma 5, for some j \u0105 1, f1p\u00b5` dq \u201c fjp\u00b5` dq. WLOG assume j \u201c 2. We will prove that:\nDB P B`1 , B 1 P B\u00b42 s.t. @i P pB YB 1qc, di \u201c 0. (10)\nBy Lemma 5, there exist B P B`1 and B1 P B \u00b4 2 such that\nmaxtp\u00b5` dqi : i P Bu \u201c f1p\u00b5` dq \u201c f2p\u00b5` dq \u201c mintp\u00b5` dqi : i P B1u;\nTake these sets and pick some i P pB YB1qc. If di \u201c 0, we are done. Otherwise, let d1k \u201c dk for all k \u2030 i and let d1i \u201c 0. Then, |d1| \u0103 |d|. By Lemma 21 and Lemma 5 (i),\nf1p\u00b5` d1q \u010f maxtp\u00b5` d1qj : j P Bu \u201c maxtp\u00b5` dqj : j P Bu \u201c f1p\u00b5` dq \u010f f2p\u00b5` dq \u201c mintp\u00b5` dqj , j P B1u \u201c mintp\u00b5` d1qj : j P B1u \u010f f2p\u00b5` d1q.\nThus d1 P D\u00b5, which contradicts that d P Dmin\u00b5 , establishing (10). Also we have f1p\u00b5` dq \u201c f2p\u00b5` dq.\nLet \u03b8 \u201c f1p\u00b5` dq \u201c f2p\u00b5` dq. For i P BzB1, by Lemma 5 (ii) and (iii), di \u201c \u00b4p\u00b5i\u00b4 \u03b8q`. Similarly, di \u201c p\u00b5i \u00b4 \u03b8q\u00b4 for i P B1zB. Note that for i P B XB1,\np\u00b5` dqi \u010f maxtp\u00b5` dqi : i P B XB1u \u010f maxtp\u00b5` dqi : i P Bu \u201c f1p\u00b5` dq \u201c \u03b8 \u201c f2p\u00b5` dq \u201c mintp\u00b5` dqi : i P B1u \u010f mintp\u00b5` dqi : i P B1 XBu \u010f p\u00b5` dqi .\nThus, p\u00b5 ` dqi \u201c \u03b8, and therefore di \u201c \u03b8 \u00b4 \u00b5i. It remains to prove \u03b8 P rf2p\u00b5q, f1p\u00b5qs. We prove this by contradiction. Assume that \u03b8 \u0103 f2p\u00b5q. Define d1 as follows:\nd1i \u201c # \u00b4p\u00b5i \u00b4 f2p\u00b5qq` , if i P B ; 0 , otherwise.\nWe will prove the following claims:\n(i) |d1| \u0103 |d|;\n(ii) f1p\u00b5` d1q \u010f f2p\u00b5q;\n(iii) f2p\u00b5` d1q \u011b f2p\u00b5q.\nAltogether these contradict d P Dmin\u00b5 . To show (i), note that for i P Bc or i P B such that \u00b5i \u010f f2p\u00b5q, |d1i| \u201c 0 \u010f |di|. Assume i P B such that \u00b5i \u0105 f2p\u00b5q \u0105 \u03b8. Then 0 \u0105 d1i \u201c f2p\u00b5q \u00b4 \u00b5i \u0105 \u03b8\u00b4 \u00b5i \u201c \u00b4p\u00b5i \u00b4 \u03b8q` \u201c di, thus |d1i| \u0103 |di|. Therefore |d1| \u0103 |d|, proving (i).\nFor (ii), note that for i P B, \u00b5i` d1i \u201c \u00b5i\u00b4 p\u00b5i\u00b4 f2p\u00b5qq` \u010f f2p\u00b5q, thus maxiPB \u00b5i` d1i \u010f f2p\u00b5q. By Lemma 21, we also have f1p\u00b5 ` d1q \u010f maxPB \u00b5`d1i, which together with the previous inequality implies (ii).\nLastly, for proving (iii) define I \u201c ti P B : \u00b5i \u011b f2p\u00b5qu. Then \u00b51 :\u201c \u00b5 ` d1 can be rewritten as\n\u00b51i \u201c # f2p\u00b5q , if i P I ; \u00b5i , otherwise.\nBy Lemma 22, f2p\u00b5` d1q \u011b f2p\u00b5q, showing (iii) . The inequality \u03b8 \u010f f1p\u00b5q can also be proved using analogous ideas. Therefore, \u03b8 P rf2p\u00b5q, f1p\u00b5qs. Combining all the previous statements leads to the conclusion Dmin\u00b5 \u0102 S. Let us now prove that S \u0102 D\u00b5. Take any element \u2206 P S. Let j P rKs, B P B`1 and B1 P B\u00b4j as in the definition of S. WLOG assume that j \u201c 2. Let \u00b51 \u201c \u00b5 `\u2206. It suffices to show that f1p\u00b51q \u010f \u03b8 and f2p\u00b51q \u011b \u03b8. We show f1p\u00b51q \u010f \u03b8, leaving the proof of the other relationship to the reader (the proof is entirely analogous to the one presented). By\nLemma 21, it suffices to show that maxt\u00b51i : i P Bu \u010f \u03b8. When i P BzB1, \u2206i \u201c \u00b4p\u00b5i \u00b4 \u03b8q`. Thus, \u00b51i \u201c \u00b5i \u00b4 maxp\u00b5i \u00b4 \u03b8, 0q \u201c \u00b5i ` minp\u03b8 \u00b4 \u00b5i, 0q \u010f \u00b5i ` \u03b8 \u00b4 \u00b5i \u010f \u03b8. If i P B X B1, \u00b51i \u201c \u00b5i ` p\u03b8 \u00b4 \u00b5iq \u201c \u03b8, thus finishing the proof."}, {"heading": "D. Proofs for Section 5", "text": "We start with the correctness result:\nProposition 8 (Correctness) On the event \u03be, LUCB-micro returns J correctly: J \u201c j\u02dap\u00b5q.\nProof Assume to the contrary that J \u2030 j\u02dap\u00b5q. WLOG let j\u02dap\u00b5q \u201c 1. By Assumption 2(i) the definition of \u03be and that of J , CT , the stopping rule, fJp\u00b5q \u011b fJpL\u03b4T q \u011b fCT pU \u03b4T q \u011b f1pU \u03b4T q \u011b f1p\u00b5q. This contradicts Assumption 3.\nFor proving the sample complexity bound, we consider the following result:\nLemma 9 Let t \u0103 T . Then, on \u03be, there exists J P tBt, Ctu such that c P rfJpL\u03b4t q, fJpU \u03b4t qs and fJpU \u03b4t q \u00b4 fJpL\u03b4t q \u011b \u2206{2.\nProof We first prove that c P I .\u201c YjPtBt,CturfjpL\u03b4t q, fjpU \u03b4t qs. For this, it suffices to show that it does not hold that c P Ic where Ic \u201c RzI is the complementer of I. Now, c P Ic holds iff at least one of the four conditions hold: (i) fBtpL\u03b4t q \u0105 c and fCtpL\u03b4t q \u0105 c; (ii) fBtpU \u03b4t q \u0103 c and fCtpU \u03b4t q \u0103 c; (iii) fBtpU \u03b4t q \u0103 c and fCtpL\u03b4t q \u0105 c; (iv) fBtpL\u03b4t q \u0105 c and fCtpU \u03b4t q \u0103 c. Consider the following:\nCase (i) implies that fBtp\u00b5q \u011b fBtpL\u03b4t q \u0105 c and similarly fCtp\u00b5q \u0105 c. Thus there are two arms with payoff greater than c, which contradicts Assumption 3.\nCase (ii) implies that no arm has payoff above c, which contradicts the definition of c.\nCase (iii) Then fCtpL\u03b4t q \u0105 c \u0105 fBtpU \u03b4t q \u011b fBtpL\u03b4t q, which contradicts the definition of Bt. Case (iv) If this is true, then by definition the algorithm has stopped, hence t \u0103 T .\nThus, we see that c P Ic cannot hold and hence c P rfJpL\u03b4t q, fJpU \u03b4t qs for either J \u201c Bt or J \u201c Ct, proving the first part. Next, note that for any j P rLs, |c \u00b4 fjp\u00b5q| \u011b \u22062 . Hence, also |c \u00b4 fJp\u00b5q| \u011b \u22062 . Also note that fJp\u00b5q P rfJpL \u03b4 t q, fJpU \u03b4t qs. Thus, fJpU \u03b4t q \u00b4 fJpL\u03b4t q \u011b |c\u00b4 fJp\u00b5q| \u011b \u22062 .\nWe can now prove Theorem 10:\nTheorem 10 (LUCB-micro upper bound) Let\nHp\u00b5q \u201c \u00ff\niPrLs\n\"\n1 pc\u00b4 \u00b5iq2 \u013e 1 p\u2206{2q2\n*\n, and t\u02dap\u00b5q \u201c mintt P N : 1` 8Hp\u00b5q\u03b2pt, \u03b4{p2Lqq \u010f tu .\nThen, for \u03b4 \u010f 0.1, on the event \u03be, the stopping time T of LUCB-micro satisfies T \u010f t\u02dap\u00b5q.\nProof Let \u03c4 be a fixed deterministic integer. Now, on \u03be,\nminpT, \u03c4q \u010f 1` \u03c4 \u00ff\nt\u201c1 I tt \u0103 T u\n(a) \u010f 1`\n\u03c4 \u00ff t\u201c1 I ! DJ P tBt, Ctu s.t. c P rfJpL\u03b4t q, fJpU \u03b4t qs and fJpU \u03b4t q \u00b4 fJpL\u03b4t q \u011b \u2206{2 )\n(b) \u010f 1`\n\u03c4 \u00ff t\u201c1 I ! DI P tIt, Jtu s.t. c P rL\u03b4t pIq, U \u03b4t pIqs and U \u03b4t pIq \u00b4 L\u03b4t pIq \u011b \u2206{2 )\n\u010f 1` \u03c4 \u00ff\nt\u201c1\n\u00ff\niPrLs I ti P tIt, Jtuu I\n! c P rL\u03b4t piq, U \u03b4t piqs and U \u03b4t piq \u00b4 L\u03b4t piq \u011b \u2206{2 )\n(c) \u010f 1`\n\u03c4 \u00ff\nt\u201c1\n\u00ff\niPrLs I ti P tIt, Jtuu I\n\" Ntpiq \u010f 8\u03b2pNtpiq, \u03b4{p2Lqq \u02c6\n1 pc\u00b4 \u00b5iq2 ^ 1p\u2206{2q2\n\u02d9*\n(d) \u010f 1` \u00ff\niPrLs\n\u03c4 \u00ff t\u201c1 I ti P tIt, Jtuu I \" Ntpiq \u010f 8\u03b2p\u03c4, \u03b4{p2Lqq \u02c6\n1 pc\u00b4 \u00b5iq2 ^ 1p\u2206{2q2\n\u02d9*\n\u010f 1` \u00ff\niPrLs 8\u03b2p\u03c4, \u03b4{p2Lqq\n\u02c6\n1 pc\u00b4 \u00b5iq2 ^ 1p\u2206{2q2\n\u02d9\n\u201c 1` 8Hp\u00b5q\u03b2p\u03c4, \u03b4{p2Lqq .\nHere, (a) holds by the first part of Lemma 9, (b) holds by Assumption 2(ii), (c) holds by the definition of \u03b2, (d) holds because \u03b2p\u00a8, \u03b4{p2Lqq is increasing. Picking any \u03c4 such that 8Hp\u00b5q\u03b2p\u03c4, \u03b4{p2Lqq \u010f \u03c4 \u00b4 1, we have minpT, \u03c4q \u010f \u03c4 , showing that T \u010f minpT, \u03c4q \u010f \u03c4 ."}, {"heading": "E. Proofs for Section 6", "text": "Lemma 12 For any h P H and u, v P r0, 1sL such that u \u010f v, V ph, uq \u010f V ph, vq.\nProof We prove the result by induction based on how close a history h is to being a maximal history. As in an earlier proof, for h P H, we let cphq \u201c 0 if h P Hmax and otherwise we let cphq \u201c 1 ` maxtcph1q : h1 P Hsuccphqu, where recall that Hsuccphq denotes the set of immediate successors of h P H in H.\nBase case: If cphq \u201c 0 (i.e., h P Hmax), then V ph, uq \u201c u\u03c4phq \u010f v\u03c4phq \u201c V ph, vq. Induction step: Assuming that for all the h1 P H with cphq \u010f c with some c \u011b 0 it holds that V ph1, uq \u010f V ph1, vq. Take h P H such that cphq \u201c c` 1. WLOG assume that pphq \u201c 1. We have:\nV ph, uq \u201c V pjoinph,mph, uqq, uq \u010f V pjoinph,mph, uqq, vq \u010f V pjoinph,mph, vqq, vq \u201c V ph, vq ,\nwhere the first and the last equalities are by definition, the first inequality is by the induction hypothesis, and the second inequality is due to the definition of mph, vq.\nLemma 14 Fix u, v P RL, u \u010f v, and j P rKs. Let h \u201c MinMaxppjqq and in particular let h \u201c pm1 \u201c j,m2, . . . ,m`q. Then, for all 1 \u010f k \u0103 `,\nrV phk, uq, V phk, vqs \u0102 rV phk`1, uq, V phk`1, vqs ,\nwhere hk is the length-k prefix of h.\nProof Fix 0 \u010f k \u0103 ` and u \u010f v. WLOG assume that ppkq \u201c 1. By the definition of V ph, \u00b5q and mph, \u00b5q,\nV ph, vq \u201c maxtV ph1, vq : h1 P Hsuccphqu \u201c V pjoinph,mph, vqq, vq .\nHence, by the definition of MinMax and the above identity, V phk, vq \u201c V phk`1, vq. Further, V phk, uq \u201c maxtV ph1, uq : h1 P Hsuccphqu \u011b V phk`1, uq. Thus,\nV phk, vq \u010f V phk`1, vq and V phk, uq \u011b V phk`1, uq ,\nfinishing the proof.\nTheorem 17 (LUCBMinMax on MinMax Trees) Let\nHp\u00b5q \u201c \u00ff iPrLs mint 1 spanpVpi, \u00b5q Y tc, \u00b5iuq2 , 4 \u22062 u, t\u02dap\u00b5q \u201c mintt P N : 1` 8Hp\u00b5q\u03b2pt, \u03b4{p2Lqq \u010f tu .\nThen, on \u03be, the stopping time T of LUCBMinMax satisfies T \u010f t\u02dap\u00b5q.\nProof Recall that It \u201c \u03c4pMinMaxpBt, L\u03b4t , U \u03b4t qq and Jt \u201c \u03c4pMinMaxpCt, L\u03b4t , U \u03b4t qqu. Assume that \u03be holds. We prove that VpIt, \u00b5q \u0102 rL\u03b4t pItq, U \u03b4t pItqs and VpJt, \u00b5q \u0102 rL\u03b4t pJtq, U \u03b4t pJtqs hold. The rest of the proof is similar to that of Theorem 10.\nConsider It. The proof for Jt works the same way and is hence omitted. If there is multiple path h P H such that \u03c4phq \u201c It, then VpIt, \u00b5q \u201c H \u0102 rL\u03b4t pItq, U \u03b4t pItqs. Otherwise, let h P H be the unique path. Since It is pulled, h \u201c MinMaxpmq for some m P M . Note that Lemma 14 implies that rV phk, L\u03b4t q, V phk, U \u03b4t qs \u0102 rV phk`1, L\u03b4t q, V phk`1, U \u03b4t qs. Thus it is sufficient to prove that for 1 \u010f k \u0103 `, V phk, \u00b5q P rV phk, L\u03b4t q, V phk, U \u03b4t qs. However, this follows by Lemma 12 and because on the event \u03be, L\u03b4t \u010f \u00b5 \u010f U \u03b4t holds.\nNow let Spiq \u201c Vpi, \u00b5qYtc, \u00b5iu. Fix t \u0103 T . By the above result and by Lemma 9, for one of J \u201c Bt or J \u201c Ct, if I \u201c MinMaxpJ, L\u03b4t , U \u03b4t q then SpIq \u0102 rL\u03b4t pIq, U \u03b4t pIqs, which implies\nthat U \u03b4t pIq \u00b4 L\u03b4t pIq \u011b spanpSpIqq. Therefore,\nminpT, \u03c4q \u010f 1` \u03c4 \u00ff\nt\u201c1 I tt \u0103 T u\n\u010f 1` \u03c4 \u00ff\nt\u201c1 I ! DI P tIt, Jtu s.t. U \u03b4t pIq \u00b4 L\u03b4t pIq \u011b spanpSpIqq )\n\u010f 1` \u03c4 \u00ff\nt\u201c1\n\u00ff\niPrLs I ti P tIt, Jtuu I\n\"\nNtpiq \u010f 8\u03b2pNtpiq, \u03b4{p2Lqq\nspanpSpiqq2\n*\n\u010f 1` \u00ff\niPrLs\n\u03c4 \u00ff t\u201c1 I ti P tIt, Jtuu I \" Ntpiq \u010f 8\u03b2p\u03c4, \u03b4{p2Lqq spanpSpiqq2 *\n\u010f 1` \u00ff\niPrLs\n8\u03b2p\u03c4, \u03b4{p2Lqq spanpSpiqq2 \u201c 1` 8Hp\u00b5q\u03b2p\u03c4, \u03b4{p2Lqq"}], "references": [{"title": "Searching for Solutions in Games and Artificial Intelligence", "author": ["L. Victor Allis"], "venue": "PhD thesis, Maastricht University,", "citeRegEx": "Allis.,? \\Q1994\\E", "shortCiteRegEx": "Allis.", "year": 1994}, {"title": "Best arm identification in multi-armed bandits", "author": ["Jean-Yves Audibert", "S\u00e9bastien Bubeck"], "venue": "In 23rd Annual Conference on Learning Theory, COLT 2010, pages 13\u2013p,", "citeRegEx": "Audibert and Bubeck.,? \\Q2010\\E", "shortCiteRegEx": "Audibert and Bubeck.", "year": 2010}, {"title": "The nonstochastic multiarmed bandit problem", "author": ["Peter Auer", "Nicol\u00f2 Cesa-Bianchi", "Yoav Freund", "Robert E. Schapire"], "venue": "SIAM Journal of Computing,", "citeRegEx": "Auer et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Auer et al\\.", "year": 2002}, {"title": "On the optimal sample complexity for best arm identification", "author": ["Lijie Chen", "Jian Li"], "venue": "arXiv preprint arXiv:1511.03774,", "citeRegEx": "Chen and Li.,? \\Q2015\\E", "shortCiteRegEx": "Chen and Li.", "year": 2015}, {"title": "Action elimination and stopping conditions for the multi-armed bandit and reinforcement learning problems", "author": ["Eyal Even-Dar", "Shie Mannor", "Yishay Mansour"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Even.Dar et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Even.Dar et al\\.", "year": 2006}, {"title": "Best arm identification: A unified approach to fixed budget and fixed confidence", "author": ["Victor Gabillon", "Mohammad Ghavamzadeh", "Alessandro Lazaric"], "venue": "In 26th Annual Conference on Neural Information Processing Systems,", "citeRegEx": "Gabillon et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Gabillon et al\\.", "year": 2016}, {"title": "Optimal best arm identification with fixed confidence", "author": ["Aur\u00e9lien Garivier", "Emilie Kaufmann"], "venue": "In COLT,", "citeRegEx": "Garivier and Kaufmann.,? \\Q2016\\E", "shortCiteRegEx": "Garivier and Kaufmann.", "year": 2016}, {"title": "Maximin action identification: A new bandit framework for games", "author": ["Aur\u00e9lien Garivier", "Emilie Kaufmann", "Wouter M. Koolen"], "venue": "In 29th Annual Conference on Learning Theory, COLT", "citeRegEx": "Garivier et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Garivier et al\\.", "year": 2016}, {"title": "On explore-then-commit strategies", "author": ["Aur\u00e9lien Garivier", "Emilie Kaufmann", "Tor Lattimore"], "venue": "arXiv preprint arXiv:1605.08988,", "citeRegEx": "Garivier et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Garivier et al\\.", "year": 2016}, {"title": "The grand challenge of computer Go: Monte Carlo tree search and extensions", "author": ["Sylvain Gelly", "Levente Kocsis", "Marc Schoenauer", "Mich\u00e8le Sebag", "David Silver", "Csaba Szepesv\u00e1ri", "Olivier Teytaud"], "venue": "Communications of ACM,", "citeRegEx": "Gelly et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Gelly et al\\.", "year": 2012}, {"title": "Best-arm identification algorithms for multi-armed bandits in the fixed confidence setting", "author": ["Kevin Jamieson", "Robert Nowak"], "venue": "In Information Sciences and Systems (CISS),", "citeRegEx": "Jamieson and Nowak.,? \\Q2014\\E", "shortCiteRegEx": "Jamieson and Nowak.", "year": 2014}, {"title": "lil\u2019UCB: An optimal exploration algorithm for multi-armed bandits", "author": ["Kevin G. Jamieson", "Matthew Malloy", "Robert D. Nowak", "S\u00e9bastien Bubeck"], "venue": "In 27th Annual Conference on Learning Theory,", "citeRegEx": "Jamieson et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Jamieson et al\\.", "year": 2014}, {"title": "PAC subset selection in stochastic multi-armed bandits", "author": ["Shivaram Kalyanakrishnan", "Ambuj Tewari", "Peter Auer", "Peter Stone"], "venue": "In Proceedings of the 29th International Conference on Machine Learning,", "citeRegEx": "Kalyanakrishnan et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Kalyanakrishnan et al\\.", "year": 2012}, {"title": "Almost optimal exploration in multiarmed bandits", "author": ["Zohar Shay Karnin", "Tomer Koren", "Oren Somekh"], "venue": "In Proceedings of The 30th International Conference on Machine Learning,", "citeRegEx": "Karnin et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Karnin et al\\.", "year": 2013}, {"title": "On the complexity of best-arm identification in multi-armed bandit models", "author": ["Emilie Kaufmann", "Olivier Capp\u00e9", "Aur\u00e9lien Garivier"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Kaufmann et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Kaufmann et al\\.", "year": 2016}, {"title": "Gametree search using proof numbers: The first twenty years", "author": ["Akihiro Kishimoto", "Mark H.M. Winands", "Martin M\u00fcller", "Jahn-Takeshi Saito"], "venue": "ICGA Journal,", "citeRegEx": "Kishimoto et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Kishimoto et al\\.", "year": 2012}, {"title": "Conspiracy numbers for min-max search", "author": ["David Allen McAllester"], "venue": "Artificial Intelligence,", "citeRegEx": "McAllester.,? \\Q1988\\E", "shortCiteRegEx": "McAllester.", "year": 1988}, {"title": "Artificial Intelligence: A Modern Approach. Pearson Education, Inc", "author": ["Stuart J. Russell", "Peter Norvig"], "venue": "Upper Saddle River, New Jersey,", "citeRegEx": "Russell and Norvig.,? \\Q2010\\E", "shortCiteRegEx": "Russell and Norvig.", "year": 2010}, {"title": "The simulator: Understanding adaptive sampling in the moderate-confidence regime", "author": ["Max Simchowitz", "Kevin G. Jamieson", "Benjamin Recht"], "venue": null, "citeRegEx": "Simchowitz et al\\.,? \\Q2017\\E", "shortCiteRegEx": "Simchowitz et al\\.", "year": 2017}, {"title": "Efficient sampling method for monte carlo tree search problem", "author": ["Kazuki Teraoka", "Kohei Hatano", "Eiji Takimoto"], "venue": "IEICE TRANSACTIONS on Information and Systems,", "citeRegEx": "Teraoka et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Teraoka et al\\.", "year": 2014}], "referenceMentions": [{"referenceID": 4, "context": ", (Even-Dar et al., 2006; Audibert and Bubeck, 2010; Gabillon et al., 2012; Kalyanakrishnan et al., 2012; Karnin et al., 2013; Jamieson et al., 2014; Chen and Li, 2015).", "startOffset": 2, "endOffset": 168}, {"referenceID": 1, "context": ", (Even-Dar et al., 2006; Audibert and Bubeck, 2010; Gabillon et al., 2012; Kalyanakrishnan et al., 2012; Karnin et al., 2013; Jamieson et al., 2014; Chen and Li, 2015).", "startOffset": 2, "endOffset": 168}, {"referenceID": 12, "context": ", (Even-Dar et al., 2006; Audibert and Bubeck, 2010; Gabillon et al., 2012; Kalyanakrishnan et al., 2012; Karnin et al., 2013; Jamieson et al., 2014; Chen and Li, 2015).", "startOffset": 2, "endOffset": 168}, {"referenceID": 13, "context": ", (Even-Dar et al., 2006; Audibert and Bubeck, 2010; Gabillon et al., 2012; Kalyanakrishnan et al., 2012; Karnin et al., 2013; Jamieson et al., 2014; Chen and Li, 2015).", "startOffset": 2, "endOffset": 168}, {"referenceID": 11, "context": ", (Even-Dar et al., 2006; Audibert and Bubeck, 2010; Gabillon et al., 2012; Kalyanakrishnan et al., 2012; Karnin et al., 2013; Jamieson et al., 2014; Chen and Li, 2015).", "startOffset": 2, "endOffset": 168}, {"referenceID": 3, "context": ", (Even-Dar et al., 2006; Audibert and Bubeck, 2010; Gabillon et al., 2012; Kalyanakrishnan et al., 2012; Karnin et al., 2013; Jamieson et al., 2014; Chen and Li, 2015).", "startOffset": 2, "endOffset": 168}, {"referenceID": 1, "context": ", 2006; Audibert and Bubeck, 2010; Gabillon et al., 2012; Kalyanakrishnan et al., 2012; Karnin et al., 2013; Jamieson et al., 2014; Chen and Li, 2015). Recently, Garivier et al. (2016a) considered the motivating problem mentioned above.", "startOffset": 8, "endOffset": 186}, {"referenceID": 16, "context": "This is then specialized to the minimax game search setting (Section 4), where we show the crucial role of what we call proof sets, which are somewhat reminiscent of the so-called conspiracy sets from adversarial search (McAllester, 1988).", "startOffset": 220, "endOffset": 238}, {"referenceID": 6, "context": "Our main interest in this paper is to see whether the ideas of Garivier et al. (2016a) extend to more general settings, such as when the depth can be non-uniform and is in particular not limited to two, or when the move histories can lead to shared states (that is, in the language of adversarial search we allow \u201ctranspositions\u201d).", "startOffset": 63, "endOffset": 87}, {"referenceID": 2, "context": "For the general structured setting, in Section 3 we prove an instance dependent lower bound along the lines of Auer et al. (2002) or Garivier et al.", "startOffset": 111, "endOffset": 130}, {"referenceID": 2, "context": "For the general structured setting, in Section 3 we prove an instance dependent lower bound along the lines of Auer et al. (2002) or Garivier et al. (2016b) (a mild novelty is the way our proof deals with the technical issue that best arm identification algorithms ideally stop and hence their behavior is undefined after the random stopping time).", "startOffset": 111, "endOffset": 157}, {"referenceID": 2, "context": "For the general structured setting, in Section 3 we prove an instance dependent lower bound along the lines of Auer et al. (2002) or Garivier et al. (2016b) (a mild novelty is the way our proof deals with the technical issue that best arm identification algorithms ideally stop and hence their behavior is undefined after the random stopping time). This is then specialized to the minimax game search setting (Section 4), where we show the crucial role of what we call proof sets, which are somewhat reminiscent of the so-called conspiracy sets from adversarial search (McAllester, 1988). Our lower bound matches that of Garivier et al. (2016a) in the case of two-move alternating problems.", "startOffset": 111, "endOffset": 645}, {"referenceID": 2, "context": "For the general structured setting, in Section 3 we prove an instance dependent lower bound along the lines of Auer et al. (2002) or Garivier et al. (2016b) (a mild novelty is the way our proof deals with the technical issue that best arm identification algorithms ideally stop and hence their behavior is undefined after the random stopping time). This is then specialized to the minimax game search setting (Section 4), where we show the crucial role of what we call proof sets, which are somewhat reminiscent of the so-called conspiracy sets from adversarial search (McAllester, 1988). Our lower bound matches that of Garivier et al. (2016a) in the case of two-move alternating problems. Considering again the abstract setting, we propose a new algorithm, which we call LUCB-micro (Section 5), and which can be considered as a natural generalization of Maximin-LUCB of Garivier et al. (2016a) (with some minor differences).", "startOffset": 111, "endOffset": 896}, {"referenceID": 2, "context": "For the general structured setting, in Section 3 we prove an instance dependent lower bound along the lines of Auer et al. (2002) or Garivier et al. (2016b) (a mild novelty is the way our proof deals with the technical issue that best arm identification algorithms ideally stop and hence their behavior is undefined after the random stopping time). This is then specialized to the minimax game search setting (Section 4), where we show the crucial role of what we call proof sets, which are somewhat reminiscent of the so-called conspiracy sets from adversarial search (McAllester, 1988). Our lower bound matches that of Garivier et al. (2016a) in the case of two-move alternating problems. Considering again the abstract setting, we propose a new algorithm, which we call LUCB-micro (Section 5), and which can be considered as a natural generalization of Maximin-LUCB of Garivier et al. (2016a) (with some minor differences). Under a regularity assumption on the payoff maps, we prove that the algorithm meets the risk-requirement. We also provide a high-probability, instance-dependent upper bound on algorithm\u2019s sample complexity (i.e., on the number of observations the algorithm takes). As we discuss, while this bound meets the general characteristics of existing bounds, it fails to reproduce the corresponding result of Garivier et al. (2016a). To the best of authors\u2019 knowledge, the only comparable algorithm to study best arm identification in a full-length minimax tree search setting (which was the motivating example of our work) is FindTopWinner by Teraoka et al.", "startOffset": 111, "endOffset": 1352}, {"referenceID": 2, "context": "For the general structured setting, in Section 3 we prove an instance dependent lower bound along the lines of Auer et al. (2002) or Garivier et al. (2016b) (a mild novelty is the way our proof deals with the technical issue that best arm identification algorithms ideally stop and hence their behavior is undefined after the random stopping time). This is then specialized to the minimax game search setting (Section 4), where we show the crucial role of what we call proof sets, which are somewhat reminiscent of the so-called conspiracy sets from adversarial search (McAllester, 1988). Our lower bound matches that of Garivier et al. (2016a) in the case of two-move alternating problems. Considering again the abstract setting, we propose a new algorithm, which we call LUCB-micro (Section 5), and which can be considered as a natural generalization of Maximin-LUCB of Garivier et al. (2016a) (with some minor differences). Under a regularity assumption on the payoff maps, we prove that the algorithm meets the risk-requirement. We also provide a high-probability, instance-dependent upper bound on algorithm\u2019s sample complexity (i.e., on the number of observations the algorithm takes). As we discuss, while this bound meets the general characteristics of existing bounds, it fails to reproduce the corresponding result of Garivier et al. (2016a). To the best of authors\u2019 knowledge, the only comparable algorithm to study best arm identification in a full-length minimax tree search setting (which was the motivating example of our work) is FindTopWinner by Teraoka et al. (2014). This algorithm is a roundbased elimination based algorithm with additional pruning steps that come from the tree structure.", "startOffset": 111, "endOffset": 1585}, {"referenceID": 2, "context": "For the general structured setting, in Section 3 we prove an instance dependent lower bound along the lines of Auer et al. (2002) or Garivier et al. (2016b) (a mild novelty is the way our proof deals with the technical issue that best arm identification algorithms ideally stop and hence their behavior is undefined after the random stopping time). This is then specialized to the minimax game search setting (Section 4), where we show the crucial role of what we call proof sets, which are somewhat reminiscent of the so-called conspiracy sets from adversarial search (McAllester, 1988). Our lower bound matches that of Garivier et al. (2016a) in the case of two-move alternating problems. Considering again the abstract setting, we propose a new algorithm, which we call LUCB-micro (Section 5), and which can be considered as a natural generalization of Maximin-LUCB of Garivier et al. (2016a) (with some minor differences). Under a regularity assumption on the payoff maps, we prove that the algorithm meets the risk-requirement. We also provide a high-probability, instance-dependent upper bound on algorithm\u2019s sample complexity (i.e., on the number of observations the algorithm takes). As we discuss, while this bound meets the general characteristics of existing bounds, it fails to reproduce the corresponding result of Garivier et al. (2016a). To the best of authors\u2019 knowledge, the only comparable algorithm to study best arm identification in a full-length minimax tree search setting (which was the motivating example of our work) is FindTopWinner by Teraoka et al. (2014). This algorithm is a roundbased elimination based algorithm with additional pruning steps that come from the tree structure. When we specialize our framework to the minimax game scenario (and implement other necessary changes to put our work into their ( , \u03b4q-PAC setting), our upper bound is a strict improvement of theirs, e.g., in the number of samples related to the near-optimal micro-observables (leaves of the minimax game tree). Next, we consider the minimax setting (Section 6). First, we show that the regularity assumptions made for the abstract setting are met in this case. We also show how to efficiently compute the choices that LUCB-micro makes using a \u201cmin-max\u201d algorithm. Finally, we strengthen our previous result so that it is able to reproduce the mentioned result of Garivier et al. (2016a).", "startOffset": 111, "endOffset": 2398}, {"referenceID": 7, "context": "As explained by Garivier et al. (2016a), the setting may also shed light on how to design better Monte-Carlo Tree Search (MCTS) algorithms, which is a relatively novel class of search algorithms that proved to be highly successful in recent years (e.", "startOffset": 16, "endOffset": 40}, {"referenceID": 14, "context": "The proof uses standard steps (e.g., Auer et al., 2002; Kaufmann et al., 2016) and one of its main merit is its simplicity.", "startOffset": 30, "endOffset": 78}, {"referenceID": 5, "context": "The proof can be shown to reproduce the result of Garivier and Kaufmann (2016) (see page 6 of their paper) when the setting is best arm identification.", "startOffset": 50, "endOffset": 79}, {"referenceID": 16, "context": "Proof sets are closely related to conspiracy sets (McAllester, 1988), forming the basis of \u201cproof number of search\u201d (Allis, 1994; Kishimoto et al.", "startOffset": 50, "endOffset": 68}, {"referenceID": 0, "context": "Proof sets are closely related to conspiracy sets (McAllester, 1988), forming the basis of \u201cproof number of search\u201d (Allis, 1994; Kishimoto et al., 2012).", "startOffset": 116, "endOffset": 153}, {"referenceID": 15, "context": "Proof sets are closely related to conspiracy sets (McAllester, 1988), forming the basis of \u201cproof number of search\u201d (Allis, 1994; Kishimoto et al., 2012).", "startOffset": 116, "endOffset": 153}, {"referenceID": 17, "context": "Proof sets are also related to cuts in \u03b1\u2013\u03b2 search (Russell and Norvig, 2010).", "startOffset": 50, "endOffset": 76}, {"referenceID": 10, "context": "Upper bound In this section we propose an algorithm generalizing the LUCB algorithm of Kalyanakrishnan et al. (2012) and prove a theoretical guarantee for the proposed algorithm\u2019s sample complexity under some (mild) assumptions on the structure of the reward mapping f .", "startOffset": 87, "endOffset": 117}, {"referenceID": 7, "context": "Our result is inspired and extends the results of Garivier et al. (2016a) (who also started from the LUCB algorithm) to the general setting proposed in this paper.", "startOffset": 50, "endOffset": 74}, {"referenceID": 14, "context": "This result appears as (essentially) Theorem 8 in the paper by Kaufmann et al. (2016) who also cite precursors: Lemma 7 (Anytime subgaussian concentration) Let pXtqtPN be an pFtqtPN-adapted 1subgaussian, martingale difference sequence (i.", "startOffset": 63, "endOffset": 86}, {"referenceID": 7, "context": "This can be seen as a generalization of the choice made in Maximin-LUCB by Garivier et al. (2016a). Here, we found that the specific way Maximin-LUCB\u2019s choice is made considerably obscured the idea behind this choice, which one can perhaps attribute to that the fact that the two-move setting makes it possible to write the choice in a more-or-less direct fashion.", "startOffset": 75, "endOffset": 99}, {"referenceID": 12, "context": "Compared to state-of-the-art results available for this setting, our bound is looser in several ways: We lose on the constant factor multiplying Hp\u03bcq (Kalyanakrishnan et al., 2012; Jamieson and Nowak, 2014; Jamieson et al., 2014; Kaufmann et al., 2016), we also lose an additive term of Hp\u03bcq log logpLq (Chen and Li, 2015).", "startOffset": 150, "endOffset": 252}, {"referenceID": 10, "context": "Compared to state-of-the-art results available for this setting, our bound is looser in several ways: We lose on the constant factor multiplying Hp\u03bcq (Kalyanakrishnan et al., 2012; Jamieson and Nowak, 2014; Jamieson et al., 2014; Kaufmann et al., 2016), we also lose an additive term of Hp\u03bcq log logpLq (Chen and Li, 2015).", "startOffset": 150, "endOffset": 252}, {"referenceID": 11, "context": "Compared to state-of-the-art results available for this setting, our bound is looser in several ways: We lose on the constant factor multiplying Hp\u03bcq (Kalyanakrishnan et al., 2012; Jamieson and Nowak, 2014; Jamieson et al., 2014; Kaufmann et al., 2016), we also lose an additive term of Hp\u03bcq log logpLq (Chen and Li, 2015).", "startOffset": 150, "endOffset": 252}, {"referenceID": 14, "context": "Compared to state-of-the-art results available for this setting, our bound is looser in several ways: We lose on the constant factor multiplying Hp\u03bcq (Kalyanakrishnan et al., 2012; Jamieson and Nowak, 2014; Jamieson et al., 2014; Kaufmann et al., 2016), we also lose an additive term of Hp\u03bcq log logpLq (Chen and Li, 2015).", "startOffset": 150, "endOffset": 252}, {"referenceID": 3, "context": ", 2016), we also lose an additive term of Hp\u03bcq log logpLq (Chen and Li, 2015).", "startOffset": 58, "endOffset": 77}, {"referenceID": 18, "context": "We also lose logpLq terms on the suboptimal arms (Simchowitz et al., 2017).", "startOffset": 49, "endOffset": 74}, {"referenceID": 3, "context": ", 2016), we also lose an additive term of Hp\u03bcq log logpLq (Chen and Li, 2015). We also lose logpLq terms on the suboptimal arms (Simchowitz et al., 2017). Comparing with the only result available in the two-move minimax tree setting, due to Garivier et al. (2016a), our bound is looser than their Theorem 1.", "startOffset": 59, "endOffset": 265}, {"referenceID": 3, "context": ", 2016), we also lose an additive term of Hp\u03bcq log logpLq (Chen and Li, 2015). We also lose logpLq terms on the suboptimal arms (Simchowitz et al., 2017). Comparing with the only result available in the two-move minimax tree setting, due to Garivier et al. (2016a), our bound is looser than their Theorem 1. This motivates the refinement of this result to the minimax setting, which is done in the next section, and where we recover the mentioned result of Garivier et al. (2016a). On the positive side, our result is more generally applicable than any of the mentioned results.", "startOffset": 59, "endOffset": 481}, {"referenceID": 7, "context": "Remark 18 Note that this result recovers Theorem 1 of Garivier et al. (2016a). To see this note that for every leaf pi, jq (as numbered in their paper), \u03bci,1 P Vppi, jq, \u03bcq.", "startOffset": 54, "endOffset": 78}, {"referenceID": 18, "context": "Simchowitz et al. (2017) introduces an interesting technique for proving lower bounds of this form and they demonstrate nontrivial improvements in the multi-armed bandit setting.", "startOffset": 0, "endOffset": 25}], "year": 2017, "abstractText": "We study the problem of identifying the best action among a set of possible options when the value of each action is given by a mapping from a number of noisy micro-observables in the so-called fixed confidence setting. Our main motivation is the application to the minimax game search, which has been a major topic of interest in artificial intelligence. In this paper we introduce an abstract setting to clearly describe the essential properties of the problem. While previous work only considered a two-move game tree search problem, our abstract setting can be applied to the general minimax games where the depth can be non-uniform and arbitrary, and transpositions are allowed. We introduce a new algorithm (LUCB-micro) for the abstract setting, and give its lower and upper sample complexity results. Our bounds recover some previous results, which were only available in more limited settings, while they also shed further light on how the structure of minimax problems influence sample complexity.", "creator": "LaTeX with hyperref package"}}}