{"id": "1706.08605", "review": {"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "26-Jun-2017", "title": "Developing Bug-Free Machine Learning Systems With Formal Mathematics", "abstract": "Noisy data, non-convex objectives, model misspecification, and numerical instability can all cause undesired behaviors in machine learning systems. As a result, detecting actual implementation errors can be extremely difficult. We demonstrate a methodology in which developers use an interactive proof assistant to both implement their system and to state a formal theorem defining what it means for their system to be correct. The process of proving this theorem interactively in the proof assistant exposes all implementation errors since any error in the program would cause the proof to fail. As a case study, we implement a new system, Certigrad, for optimizing over stochastic computation graphs, and we generate a formal (i.e. machine-checkable) proof that the gradients sampled by the system are unbiased estimates of the true mathematical gradients. We train a variational autoencoder using Certigrad and find the performance comparable to training the same model in TensorFlow. The final result can be inferred as:\n\nThe next step is to train the gradients directly from the implementation of our machine-checkable test suite. The gradient distributions obtained with Certigrad have an accuracy rating of 5.\nOur results demonstrate that even though we're not explicitly verifying the accuracy of the regression, we are trying to verify the accuracy of the regression with a gradient distribution. In this way, we can improve the prediction model by using the gradient distributions as well, such as the gradient distributions as the data above. The results show that even though the gradient distributions are unbiased, the gradients sampled by the system are unbiased estimates of the true mathematical gradients.\nNow, the gradients used in this paper will depend on whether the system's performance improves with the training of the test suite. This is not all. The final result in this paper will be the best approximation, but we can also change the results.\nNext, we evaluate the gradient distributions from the training of the test suite. We test the gradient distributions from the test suite with Gradigrad.\nNow, this paper is based on a real-time gradient distribution. When you check out the Gradigrad code snippet, you will see that the gradients generated from this sample are based on a real-time gradient distribution. If you are able to get this gradient distribution on your machine, you may have seen a gradient distribution in your training routine, which is why the gradient distributions generated by Gradigrad can be tested in many applications.\nThe main difference between this paper and this paper is", "histories": [["v1", "Mon, 26 Jun 2017 21:30:02 GMT  (93kb,D)", "http://arxiv.org/abs/1706.08605v1", "To appear at the Thirty-fourth International Conference on Machine Learning (ICML) 2017"]], "COMMENTS": "To appear at the Thirty-fourth International Conference on Machine Learning (ICML) 2017", "reviews": [], "SUBJECTS": "cs.SE cs.AI", "authors": ["daniel selsam", "percy liang", "david l dill"], "accepted": true, "id": "1706.08605"}, "pdf": {"name": "1706.08605.pdf", "metadata": {"source": "META", "title": "Developing Bug-Free Machine Learning Systems With Formal Mathematics", "authors": ["Daniel Selsam", "Percy Liang", "David L. Dill"], "emails": ["<dselsam@stanford.edu>."], "sections": [{"heading": "1. Introduction", "text": "Machine learning systems are difficult to engineer for many fundamental reasons. First and foremost, implementation errors can be extremely difficult to detect\u2014let alone to localize and address\u2014since there are many other potential causes of undesired behavior in a machine learning system. For example, an implementation error may lead to incorrect gradients and so cause a learning algorithm to stall, but such a symptom may also be caused by noise in the training data, a poor choice of model, an unfavorable optimization landscape, an inadequate search strategy, or numerical instability. These other issues are so common that it is often assumed that any undesired behavior is caused by one of them. As a result, actual implementation errors can persist\n1Stanford University, Stanford, CA. Correspondence to: Daniel Selsam <dselsam@stanford.edu>.\nProceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017. Copyright 2017 by the author(s).\nStandard methodology: test it empirically\nProgram\nDebug\nTest\nOur methodology: verify it mathematically\nindefinitely without detection.1 Errors are even more difficult to detect in stochastic programs, since some errors may only distort the distributions of random variables and may require writing custom statistical tests to detect.\nMachine learning systems are also difficult to engineer because it can require substantial expertise in mathematics (e.g. linear algebra, statistics, multivariate analysis, measure theory, differential geometry, topology) to even understand what a machine learning algorithm is supposed to do and why it is thought to do it correctly. Even simple algorithms such as gradient descent can have intricate justifications, and there can be a large gap between the mechanics of an implementation\u2014especially a highly-optimized one\u2014and its intended mathematical semantics.\n1Theano (Bergstra et al., 2010) has been under development for almost a decade and yet there is a recent GitHub issue (https://github.com/Theano/Theano/issues/4770) reporting a model for which the loss continually diverges in the middle of training. Only after various experiments and comparing the behavior to other systems did the team agree that it is most likely an implementation error. As of this writing, neither the cause of this error nor the set of models it affects have been determined.\nar X\niv :1\n70 6.\n08 60\n5v 1\n[ cs\n.S E\n] 2\n6 Ju\nn 20\n17\nIn this paper, we demonstrate a practical methodology for building machine learning systems that addresses these challenges by enabling developers to find and eliminate implementation errors systematically without recourse to empirical testing. Our approach makes use of a tool called an interactive proof assistant (Gordon, 1979; Gordon & Melham, 1993; Harrison, 1996; Nipkow et al., 2002; Owre et al., 1992; Coq Development Team, 2015-2016; de Moura et al., 2015), which consists of (a) a programming language, (b) a language to state mathematical theorems, and (c) a set of tools for constructing formal proofs of such theorems. Note: we use the term formal proof to mean a proof that is in a formal system and so can be checked by a machine.\nIn our approach, developers use the theorem language (b) to state a formal mathematical theorem that defines what it means for their implementation to be error-free in terms of the underlying mathematics (e.g. multivariate analysis). Upon implementing the system using the programming language (a), developers use the proof tools (c) to construct a formal proof of the theorem stating that their implementation is correct. The first draft of any implementation will often have errors, and the process of interactive proving will expose these errors systematically by yielding impossible proof obligations. Once all implementation errors have been fixed, the developers will be able to complete the formal proof and be certain that the implementation has no errors with respect to its specification. Moreover, the proof assistant can check the formal proof automatically so no human needs to understand why the proof is correct in order to trust that it is. Figure 1 illustrates this process.\nProving correctness of machine learning systems requires building on the tools and insights from two distinct fields: program verification (Leroy, 2009; Klein et al., 2009; Chlipala, 2013; Chen et al., 2015), which has aimed to prove properties of computer programs, and formal mathematics (Rudnicki, 1992; Gonthier, 2008; Gonthier et al., 2013; Hales et al., 2015), which has aimed to formally represent and generate machine-checkable proofs of mathematical theorems. Both of these fields make use of interactive proof assistants, but the tools, libraries and design patterns developed by the two fields focus on different problems and have remained largely incompatible. While the methodology we have outlined will be familiar to the program verification community, and while reasoning formally about the mathematics that underlies machine learning will be familiar to the formal mathematics community, proving such sophisticated mathematical properties of large (stochastic) software systems is a new goal and poses many new challenges.\nTo explore these challenges and to demonstrate the prac-\nticality of our approach, we implemented a new machine learning system, Certigrad, for optimizing over stochastic computation graphs (Schulman et al., 2015). Stochastic computation graphs extend the computation graphs that underly systems like TensorFlow (Abadi et al., 2015) and Theano (Bergstra et al., 2010) by allowing nodes to represent random variables and by defining the loss function for a graph to be the expected value of the sum of the leaf nodes over the stochastic choices. See Figure 2 for an example of a stochastic computation graph. We implement our system in the Lean Theorem Prover (de Moura et al., 2015), a new interactive proof assistant still under active development for which the integration of programming and mathematical reasoning is an ongoing design goal. We formally state and prove functional correctness for the stochastic backpropagation algorithm: that the sampled gradients are indeed unbiased estimates of the gradients of the loss function with respect to the parameters.\nWe note that provable correctness need not come at the expense of computational efficiency: proofs need only be checked once during development and they introduce no runtime overhead. Although the algorithms we verify in this work lack many optimizations, most of the running time when training machine learning systems is spent multiplying matrices, and we are able to achieve competitive performance simply by linking with an optimized library for matrix operations (we used Eigen (Guennebaud et al., 2010)).2 To demonstrate practical feasibility empirically, we trained an Auto-Encoding Variational Bayes (AEVB) model (Kingma & Welling, 2014) on MNIST using ADAM (Kingma & Ba, 2014) and found the performance comparable to training the same model in TensorFlow.\n2Note that the validity of our theorem becomes contingent on Eigen\u2019s matrix operations being functionally equivalent to the versions we formally proved correct.\nWe summarize our contributions:\n1. We present the first application of formal (i.e. machine-checkable) proof techniques to developing machine learning systems.\n2. We describe a methodology that can detect implementation errors systematically in machine learning systems.\n3. We demonstrate that our approach is practical by developing a performant implementation of a sophisticated machine learning system along with a machinecheckable proof of correctness."}, {"heading": "2. Motivation", "text": "When developing machine learning systems, many program optimizations involve extensive algebraic derivations to put mathematical expressions in closed-form . For example, suppose you want to compute the following quantity efficiently:\n\u222b x N (x;\u00b5,Diag(\u03c32)) logN (x; 0, In\u00d7n). (1)\nYou expand the density functions, grind through the algebra by hand and eventually derive the following closed form expression:\n\u22121 2 [ n\u2211 i=1 ( \u03c32i \u2212 \u00b52i ) + n log 2\u03c0 ] (2)\nYou implement a procedure to compute this quantity and include it as part of a larger program, but when you run your first experiment, your plots are not as encouraging as you hoped. After ruling out many other possible explanations, you eventually decide to scrutinize this procedure more closely. You implement a na\u0131\u0308ve Monte Carlo estimator for the quantity above, compare it against your procedure on a few random inputs and find that its estimates are systematically biased. What do you do now? If you re-check your algebra carefully, you might notice that the sign of \u00b52i is wrong, but wouldn\u2019t it be easier if the compiler checked your algebra for you and found the erroneous step? Or better yet, if it did the algebra for you in the first place and could guarantee the result was error-free?"}, {"heading": "3. Background: The Lean Theorem Prover", "text": "To develop software systems with no implementation errors, we need a way to write computer programs, mathematical theorems, and mathematical proofs all in the same\nlanguage. All three capabilities are provided by the new interactive proof assistant Lean (de Moura et al., 2015). Lean is an implementation of a logical system known as the Calculus of Inductive Constructions (Coquand & Huet, 1988), and its design is inspired by the better-known Coq Proof Assistant (Coq Development Team, 2015-2016). Our development makes use of certain features that are unique to Lean, but most of what we present is equally applicable to Coq, and to a lesser extent, other interactive theorem provers such as Isabelle/HOL (Nipkow et al., 2002).\nTo explain and motivate the relevant features of Lean, we will walk through applying our methodology to a toy problem: writing a program to compute the gradient of the softplus function. We can write standard functional programs in Lean, such as softplus: def splus (x : R) : R := log (1 + exp x)\nWe can also represent more abstract operations such as integrals and gradients:\u222b\n(f : R\u2192 R) : R \u2207 (f : R\u2192 R) (\u03b8 : R) : R\nHere the intended meaning of \u222b f is the integral of the function f over all of R, while the intended meaning of \u2207 f \u03b8 is the gradient (i.e. the derivative) of the function f at the point \u03b8. Figure 3 shows how to represent common idioms of informal mathematics in our formal representation; note that whereas some of the informal examples are too ambiguous to interpret without additional information, the Lean representation is always unambiguous.\nWe can represent mathematical theorems in Lean as well. For example, we can use the following predicate to state that a particular function f is differentiable at a point \u03b8: is_diff (f : R\u2192 R) (\u03b8 : R) : Prop\nThe fact that the return type of is_diff is Prop indicates that it is not a computer program to be executed but rather that it represents a mathematical theorem.\nWe can also state and assume basic properties about the gradient, such as linearity: \u2200 (f g : R\u2192 R) (\u03b8 : R), is_diff f \u03b8 \u2227 is_diff g \u03b8\u2192 \u2207 (f + g) \u03b8 =\u2207 f \u03b8 +\u2207 g \u03b8\nReturning to our running example, we can state the theorem that a particular function f computes the gradient of the softplus function:\ndef gsplus_spec (f : R\u2192 R) : Prop := \u2200 x, f x =\u2207 splus x\nSuppose we try to write a program to compute the gradient of the softplus function as follows:\ndef gsplus (x : R) : R := 1 / (1 + exp x)\nThe application gsplus_spec gsplus represents the proposition that our implementation gsplus is correct, i.e. that it indeed computes the gradient of the softplus function for all inputs.\nWe can try to formally prove theorems in Lean interactively:\ntheorem gsplus_correct : gsplus_spec gsplus := lean: ` gsplus_spec gsplus user: expand_def gsplus_spec, lean: ` \u2200 x, gsplus x =\u2207 splus x user: introduce x, lean: x : R ` gsplus x =\u2207 splus x user: expand_defs [gsplus, splus], lean: x : R ` 1 / (1 + exp x) =\u2207 (\u03bb x, log (1 + exp x)) x user: simplify_grad, lean: x : R ` 1 / (1 + exp x) = exp x / (1 + exp x)\nThe lines beginning with lean show the current state of the proof as displayed by Lean, which at any time consists of a collection of goals of the form assumptions ` conclusion. Every line beginning with user invokes a tactic, which is a command that modifies the proof state in some way such that Lean can automatically construct proofs of the original goals given proofs of the new ones. Here the simplify_grad tactic rewrites exhaustively with known gradient rules\u2014in this case it uses the rules for log, exp, addition, constants, and the identity function. The final goal is clearly not provable, which means we have found an implementation error in gsplus. Luckily the goal tells us exactly what gsplus x needs to return: gsplus x = exp x / (1 + exp x). Once we fix the implementation of gsplus, the proof script that failed before now succeeds and generates a machine-checkable proof that the revised gsplus is bug-free. Note that we need not have even attempted to implement gsplus before starting the proof, since the process itself revealed what the program needs to compute. We will revisit this phenomenon in \u00a74.5.\nIn the process of proving the theorem, Lean constructs a formal proof certificate that can be automatically verified by a small stand-alone executable, whose soundness is based on a well-established meta-theoretic argument embedding the core logic of Lean into set theory, and whose implementation has been heavily scrutinized by many developers. Thus no human needs to be able to understand\nwhy a proof is correct in order to trust that it is.3\nAlthough we cannot execute functions such as gsplus directly in the core logic of Lean (since a real number is an infinite object that cannot be stored in a computer), we can execute the floating-point approximation inside Lean\u2019s virtual machine:\nvm_eval gsplus \u03c0 \u2212\u2212 answer: 0.958576"}, {"heading": "4. Case Study: Certified Stochastic Computation Graphs", "text": "Stochastic computation graphs are directed acyclic graphs in which each node represents a specific computational operation that may be deterministic or stochastic (Schulman et al., 2015). The loss function for a graph is defined to be the expected value of the sum of the leaf nodes over the stochastic choices. Figure 2 shows the stochastic computation graph for a simple variational autoencoder.\nUsing our methodology, we developed a system, Certigrad, which allows users to construct arbitrary stochastic computation graphs out of the primitives that we provide. The main purpose of the system is to take a program describing a stochastic computation graph and to run a randomized algorithm (stochastic backpropagation) that, in expectation, provably generates unbiased samples of the gradients of the loss function with respect to the parameters."}, {"heading": "4.1. Overview of Certigrad", "text": "We now briefly describe the components of Certigrad, some of which have no analogues in traditional software systems.4\nMathematics libraries. There is a type that represents tensors of a particular shape, along with basic functions (e.g. exp, log) and operations (e.g. the gradient, the integral). There are assumptions about tensors (e.g. gradient rules for exp and log), and facts that are proved in terms of those assumptions (e.g. the gradient rule for softplus). There is also a type that represents probability distributions over vectors of tensors, that can be reasoned about mathematically and that can also be executed procedurally using a pseudo-random number generator.\nImplementation. There is a data structure that represents stochastic computation graphs, as well as an implementation of stochastic backpropagation. There are also functions that optimize stochastic computation graphs in various ways (e.g. by integrating out parts of the objective\n3This appealing property can be lost when an axiom is assumed that is not true. We discuss this issue further in \u00a74.3.\n4The complete development can be found at www.github.com/ dselsam/certigrad.\nfunction), as well as basic utilities for training models (e.g. stochastic gradient descent).\nSpecification. There is a collection of theorem statements that collectively define what it means for the implementation to be correct. For Certigrad, there is one main theorem that states that the stochastic backpropagation procedure yields unbiased estimates of the true mathematical gradients. There are also other theorems that state that individual graph optimizations are sound.\nProof. There are many helper lemmas to decompose the proofs into more manageable chunks, and there are tactic scripts to generate machine-checkable proofs for each of the lemmas and theorems appearing in the system. There are also tactic programs to automate certain types of reasoning, such as computing gradients or proving that functions are continuous.\nOptimized libraries. While the stochastic backpropagation function is written in Lean and proved correct, we execute the primitive tensor operations with the Eigen library for linear algebra. There is a small amount of C++ code to wrap Eigen operations for use inside Lean\u2019s virtual machine.\nThe rest of this section describes the steps we took to develop Certigrad, which include sketching the high-level architecture, designing the mathematics libraries, stating the main correctness theorem and constructing the formal proof. Though many details are specific to Certigrad, this case study is designed to illustrate our methodology and we expect other projects will follow a similar process. Note: Certigrad supports arbitrarily-shaped tensors, but doing so introduces more notational complexity than conceptual difficulty and so we simplify the presentation that follows by assuming that all values are scalars."}, {"heading": "4.2. Informal specification", "text": "The first step of applying our methodology is to write down informally what the system is required to do. Suppose g is a stochastic computation graph with n nodes and (to simplify the notation) that it only takes a single parameter \u03b8. Then g, \u03b8 together define a distribution over the values at the n nodes (X1, . . . , Xn). Let cost(g,X1:n) be the function that sums the values of the leaf nodes. Our primary goal is to write a (stochastic) backpropagation algorithm bprop such that for any graph g,\nEg,\u03b8 [bprop(g, \u03b8,X1:n)] = \u2207\u03b8 (Eg,\u03b8 [cost(g,X1:n)]) (3)\nWhile this equation may seem sufficient to communicate the specification to a human with a mathematical background, more precision is needed to communicate it to a computer. The next step is to formalize the background\nmathematics, such as real numbers (tensors) and probability distributions, so that we can state a formal analogue of Equation 3 that the computer can understand. Although we believe it will be possible to develop standard libraries of mathematics that future developers can use off-the-shelf, we needed to develop the mathematics libraries for Certigrad from scratch."}, {"heading": "4.3. Designing the mathematics libraries", "text": "Whereas in traditional formal mathematics the goal is to construct mathematics from first principles (Gonthier et al., 2013; Hales et al., 2015), we need not concern ourselves with foundational issues and can simply assume that standard mathematical properties hold. For example, we can assume that there is a type R of real numbers without needing to construct them (e.g. from Cauchy sequences), and likewise can assume there is an integration operator on the reals \u222b (f : R\u2192 R) : R that satisfies the well-known properties without needing to construct it either (e.g. from Riemann sums).\nNote that axioms must be chosen with great care since even a single false axiom (perhaps caused by a single missing precondition) can in principle allow proving any false theorem and so would invalidate the property that all formal proofs can be trusted without inspection.5 However, there are many preconditions that appear in mathematical theorems, such as integrability, that are almost always satisfied in machine learning contexts and which most developers ignore. Using axioms that omit such preconditions will necessarily lead to proving theorems that are themselves missing the corresponding preconditions, but in practice a non-adversarial developer is extremely unlikely to accidentally construct vacuous proofs by exploiting these axioms. For the first draft of our system, we purposely omitted integrability preconditions in our axioms to simplify the development. Only later did we make our axioms sound and propagate the additional preconditions throughout the system so that we could fully trust our formal proofs.\nDespite the convenience of axiomatizing the mathematics, designing the libraries was still challenging for two reasons. First, there were many different ways to formally represent the mathematical objects in question, and we needed to experiment to understand the tradeoffs between the different representations. Second, we needed to extend several traditional mathematical concepts to support reasoning about executable computer programs. The rest of this sub-\n5For example, the seemingly harmless axiom \u2200x, x/x = 1 without the precondition x 6= 0 can be used to prove the absurdity (0 = 0 \u2217 1 = 0 \u2217 (0/0) = (0 \u2217 0)/0 = 0/0 = 1). If a system assumes this axiom, then a formal proof of correctness could not be trusted without inspection since the proof may exploit this contradiction.\nsection illustrates these challenges by considering the problem we faced of designing a representation of probability distributions for Certigrad.\nRepresenting probability distributions. Our challenge is to devise a sufficiently abstract representation of probability distributions that satisfies the following desiderata: we can reason about the probability density functions of continuous random variables, we have a way to reason about arbitrary deterministic functions applied to random variables, we can execute a distribution procedurally using a pseudorandom number generator (RNG), the mathematical and procedural representations of a distribution are guaranteed to correspond, and the mathematics will be recognizable to somebody familiar with the informal math behind stochastic computation graphs.\nWe first define types to represent the mathematical and procedural notions of probability distribution. For mathematics, we define a Func n to be a functional that takes a realvalued function on Rn to a scalar: def Func (n : N) : Type := \u2200 (f : Rn\u2192 R), R\nThe intended semantics is that if p : Func n represents a distribution on Rn, then p f is the expected value of f over p, i.e. Ex\u223cp[f(x)].\nFor sampling, we define an Prog n to be a procedure that takes an RNG and returns a vector in Rn along with an updated RNG:\ndef Prog (n : N) : Type := RNG\u2192 Rn \u00d7 RNG\nWe also assume that there are primitive (continuous) distributions (PrimDist := Func 1 \u00d7 Prog 1) that consist of a probability density function and a corresponding sampling procedure. In principle, we could construct all distributions from uniform variates, but for expediency, we treat other well-understood distributions as primitive, such as the Gaussian (gauss \u00b5 \u03c3 : PrimDist).\nFinally, we define a type of distributions (Dist n) that abstractly represents programs that may mix sampling from primitive distributions with arbitrary deterministic computations. A Dist n can be denoted to a Func n (with the function E) to reason about mathematically, and to an Prog n (with the function run) to execute with an RNG.\nFor readers familiar with functional programming, our construction is similar to a monad. We allow three ways of constructing a Dist n, corresponding to sampling from a primitive distribution (sample), returning a value deterministically (det), and composing two distributions (compose):\nsample ((pdf, prog) : PrimDist) : Dist 1 det (xs : Rn) : Dist n compose (d1 : Dist m) (d2 : Rm\u2192 Dist n) : Dist n"}, {"heading": "E {n : N} (d : Dist n) (f : Rn\u2192 R) : R SCG n : Type", "text": "The mathematical semantics of all three constructors are straightforward:\nE (sample (pdf, prog)) f = \u222b\n(\u03bb x, pdf x * f x) E (det xs) f = f xs E (compose d1 d2) f = E d1 (\u03bb x, (E (d2 x) f))\nas are the procedural semantics:\nrun (sample (pdf, prog)) rng = prog rng run (det xs) rng = (xs, rng) run (compose d1 d2) rng = let (x, rng\u2019) := run d1 rng in run (d2 x) rng\u2019\nWe have defined E and run to correspond; we consider a stochastic program correct if we can prove the relevant theorems about its Func denotation, and we sample from it by passing an RNG to its Prog denotation."}, {"heading": "4.4. Formal specification", "text": "With the background mathematics in place, the next step is to write down the formal specification itself. First, we design types for every other object and function appearing in the informal description. To start, we need a type SCG n to represent stochastic computation graphs on n nodes, and a function SCG.to_dist that takes an SCG n and a scalar parameter \u03b8 to a distribution over n real numbers (Dist n). We also need a function cost that takes a graph and the values at each of its nodes and sums the values at the leaf nodes. Figure 4 provides the full types of all objects that will appear in the specification.\nNow we can write down a type-correct analogue of the informal specification presented in Equation 3:\ndef bprop_spec (bprop : \u2200 {n}, SCG n\u2192 R\u2192 Rn\u2192 R) : Prop := \u2200 (n : N) (g : SCG n) (\u03b8 : R), E (SCG.to_dist g \u03b8) (\u03bb xs, bprop g \u03b8 xs) = \u2207 (\u03bb \u03b8, E (SCG.to_dist g \u03b8) (\u03bb xs, cost g xs)) \u03b8\nGiven the mathematics libraries, implementing the other\nobjects and functions appearing in the specification such as SCG n and SCG.to_dist is straightforward functional programming."}, {"heading": "4.5. Interactive proof", "text": "While conventional wisdom is that one would write their program before trying to prove it correct, the interactive proof process provides so much helpful information about what the system needs to do that we began working on the proof immediately after drafting the specification. We split the proof into two steps. First, we implemented the simplest possible function that satisfied the specification (that only computed the gradient for a single parameter at a time and did not memoize at all) and proved that correct. Second, we implemented a more performant version (that computed the gradient for multiple parameters simultaneously using memoization) and proved it equivalent to the first one.\nFor the first step, we started with a placeholder implementation that immediately returned zero and let the interactive proof process guide the implementation. Whenever the proof seemed to require induction on a particular data structure, we extended the program to recurse on that data structure; whenever the proof showed that a branch of the program needed to return a value with a given expectation, we worked backwards from that to determine what value to return. Proving the first step also exposed errors in our specification in the form of missing preconditions. For the specification to hold, we needed to make additional assumptions about the graph, e.g. that the identifier for each node in the graph is unique, and that each leaf node is a scalar (WellFormed g). We also needed to assume a generalization of the differentiability requirement mentioned in Schulman et al. (2015), that a subset of the nodes determined by the structure of the graph must be differentiable no matter the result of any stochastic choices (GradsExist g \u03b8).\nFor the second step, we wrote the memoizing implementation before starting the proof and used the process of proving to test and debug it. Although the code for memoizing was simple and short, we still managed to make two implementation errors, one conceptual and one syntactic. Luckily the process of proving necessarily exposes all implementation errors, and in this case made it clear how to fix both of them.\nWe completed the main proof of correctness before proving most of the lemmas that the proof depends on, but the lemmas turned out to be true (except for a few missing preconditions) and so proving them did not expose any additional implementation errors. We also completed the main proof while our axioms were still unsound (see \u00a74.3). When we made our axioms sound and propagated the changes we\nfound that our specification required two additional preconditions: that all functions that are integrated over in the theorem statement are indeed integrable (IntegralsExist g \u03b8), and that the many preconditions needed for pushing the gradient over each integral in the expected loss are satisfied (CanDiffUnderInts g \u03b8). However, tracking these additional preconditions did not lead to any changes in our actual implementation. Figure 5 shows the final specification."}, {"heading": "4.6. Optimizations", "text": "We can also use our methodology to verify optimizations that involve mathematical reasoning. When developing machine learning models, one often starts with an easyto-understand model that induces a gradient estimator with unacceptably high variance, and does informal mathematics by hand to derive a new model that has the same objective function but that induces a better gradient estimator. In our approach, the user can write both models and use the process of interactive proving to confirm that they induce the same objective function. Common transformations can be written once and proved correct so that users need only write the first model and the second can be derived and proved equivalent automatically.\nAs part of Certigrad, we wrote a program optimization that integrates out the KL-divergence of the multivariate isotropic Gaussian distribution and we proved once and for all that the optimization is sound. We also verified an optimization that reparameterizes a model so that random variables do not depend on parameters (and so need not be backpropagated through). Specifically, the optimization replaces a node that samples from N (\u00b5,Diag(\u03c32)) with a graph of three nodes that first samples from N (0, In\u00d7n) and then scales and shifts the result according to \u03c3 and \u00b5 respectively. We applied these two transformations in sequence to a na\u0131\u0308ve variational-autoencoder to yield the Auto-Encoding Variational Bayes (AEVB) estimator (Kingma & Welling, 2014)."}, {"heading": "4.7. Verifying backpropagation for specific models", "text": "Even though we proved that bprop satisfies its formal specification (bprop_spec), we cannot be sure that it will compute the correct gradients for a particular model unless we prove that the model satisfies the preconditions of the specification. Although some of the preconditions are technically undecidable, in practice most machine learning models will satisfy them all for simple reasons. We wrote a (heuristic) tactic program to prove that specific models satisfy all the preconditions and used it to verify that bprop computes the correct gradients for the AEVB model derived in \u00a74.6."}, {"heading": "4.8. Running the system", "text": "We have proved that our system is correct in an idealized mathematical context with infinite-precision real numbers. To actually execute the system we need to replace all real numbers in the program with floating-point numbers. Although doing so technically invalidates the specification and can introduce numerical instability in some cases, this class of errors is well understood (Higham, 2002), could be ruled out as well in principle (Harrison, 2006; Boldo et al., 2015; Ramananandro et al., 2016) and is conceptually distinct from the algorithmic and mathematical errors that our methodology is designed to eliminate. To improve performance, we also replace all tensors with an optimized tensor library (Eigen). This approximation could introduce errors into our system if for whatever reason the Eigen methods we use are not functionally equivalent to ones we formally reason about; of course developers could achieve even higher assurance by verifying their optimized tensor code as well."}, {"heading": "4.9. Experiments", "text": "Certigrad is efficient. As an experiment, we trained an AEVB model with a 2-layer encoding network and a 2- layer decoding network on MNIST using the optimization procedure ADAM (Kingma & Ba, 2014), and compared both the expected loss and the running time of our system\nat each epoch against the same model and optimization procedure in TensorFlow, both running on 2 CPU cores. We found that the expected losses decrease at the same rate, and that Certigrad takes only 7% longer per epoch (Figure 6)."}, {"heading": "5. Discussion", "text": "Our primary motivation is to develop bug-free machine learning systems, but our approach may provide significant benefits even when building systems that need not be perfect. Perhaps the greatest burden software developers must bear is needing to fully understand how and why their system works, and we found that by formally specifying the system requirements we were able to relegate much of this burden to the computer. Not only were we able to synthesize some fragments of the system (\u00a74.5), we were able to achieve extremely high confidence that our system was bug-free without needing to think about how all the pieces of the system fit together. In our approach, the computer\u2014 not the human\u2014is responsible for ensuring that all the local properties that the developer establishes imply that the overall system is correct. Although using our methodology to develop Certigrad imposed many new requirements and increased the overall workload substantially, we found that on the whole it made the development process less cognitively demanding.\nThere are many ways that our methodology can be adopted incrementally. For example, specifications need not cover functional correctness, not all theorems need to be proved, unsound axioms can be used that omit certain preconditions, and more traditional code can be wrapped and axiomatized (as we did with Eigen). When developing Certigrad we pursued the ideal of a complete, machinecheckable proof of functional correctness, and achieved an extremely high level of confidence that the system was correct. However, we realized many of the benefits of our methodology\u2014including partial synthesis and reduced cognitive demand\u2014early in the process before proving most of the lemmas. Although we could not be certain that we had found all of the bugs before we made our axioms sound and filled in the gaps in the formal proofs, in hindsight we had eliminated all bugs early in the process as well. While a pure version of our methodology may already be cost-effective for high-assurance applications, we expect that pragmatic use of our methodology could yield many of the benefits for relatively little cost and could be useful for developing a wide range of machine learning systems to varying standards of correctness."}, {"heading": "Acknowledgments", "text": "We thank Jacob Steinhardt, Alexander Ratner, Cristina White, William Hamilton, Nathaniel Thomas, and Vatsal Sharan for providing valuable feedback on early drafts. We also thank Leonardo de Moura, Tatsu Hashimoto, and Joseph Helfer for helpful discussions. This work was supported by Future of Life Institute grant 2016-158712."}], "references": [{"title": "TensorFlow: Large-scale machine learning", "author": ["Fernanda", "Vinyals", "Oriol", "Warden", "Pete", "Wattenberg", "Martin", "Wicke", "Yu", "Yuan", "Zheng", "Xiaoqiang"], "venue": "on heterogeneous systems,", "citeRegEx": "Fernanda et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Fernanda et al\\.", "year": 2015}, {"title": "Theano: a CPU and GPU math expression compiler", "author": ["J. Bergstra", "O. Breuleux", "F. Bastien", "P. Lamblin", "R. Pascanu", "G. Desjardins", "J. Turian", "D. Warde-Farley", "Y. Bengio"], "venue": "In Python for Scientific Computing Conference,", "citeRegEx": "Bergstra et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Bergstra et al\\.", "year": 2010}, {"title": "Verified compilation of floatingpoint computations", "author": ["Boldo", "Sylvie", "Jourdan", "Jacques-Henri", "Leroy", "Xavier", "Melquiond", "Guillaume"], "venue": "Journal of Automated Reasoning,", "citeRegEx": "Boldo et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Boldo et al\\.", "year": 2015}, {"title": "Using crash hoare logic for certifying the fscq file system", "author": ["Chen", "Haogang", "Ziegler", "Daniel", "Chajed", "Tej", "Chlipala", "Adam", "Kaashoek", "M Frans", "Zeldovich", "Nickolai"], "venue": "In Proceedings of the 25th Symposium on Operating Systems Principles,", "citeRegEx": "Chen et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Chen et al\\.", "year": 2015}, {"title": "The bedrock structured programming system: Combining generative metaprogramming and hoare logic in an extensible program verifier", "author": ["Chlipala", "Adam"], "venue": "In ACM SIGPLAN Notices,", "citeRegEx": "Chlipala and Adam.,? \\Q2013\\E", "shortCiteRegEx": "Chlipala and Adam.", "year": 2013}, {"title": "The calculus of constructions", "author": ["Coquand", "Thierry", "Huet", "G\u00e9rard"], "venue": "Information and computation,", "citeRegEx": "Coquand et al\\.,? \\Q1988\\E", "shortCiteRegEx": "Coquand et al\\.", "year": 1988}, {"title": "The Lean theorem prover (system description)", "author": ["de Moura", "Leonardo", "Kong", "Soonho", "Avigad", "Jeremy", "Van Doorn", "Floris", "von Raumer", "Jakob"], "venue": "In Automated Deduction-CADE-25,", "citeRegEx": "Moura et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Moura et al\\.", "year": 2015}, {"title": "Formal proof\u2013the four-color theorem", "author": ["Gonthier", "Georges"], "venue": "Notices of the AMS,", "citeRegEx": "Gonthier and Georges.,? \\Q2008\\E", "shortCiteRegEx": "Gonthier and Georges.", "year": 2008}, {"title": "Edinburgh lcf: a mechanised logic of computation", "author": ["Gordon", "Michael JC"], "venue": null, "citeRegEx": "Gordon and JC.,? \\Q1979\\E", "shortCiteRegEx": "Gordon and JC.", "year": 1979}, {"title": "Introduction to hol a theorem proving environment for higher order logic", "author": ["Gordon", "Michael JC", "Melham", "Tom F"], "venue": null, "citeRegEx": "Gordon et al\\.,? \\Q1993\\E", "shortCiteRegEx": "Gordon et al\\.", "year": 1993}, {"title": "A formal proof of the kepler conjecture", "author": ["Hales", "Thomas", "Adams", "Mark", "Bauer", "Gertrud", "Dang", "Dat Tat", "Harrison", "John", "Hoang", "Truong Le", "Kaliszyk", "Cezary", "Magron", "Victor", "McLaughlin", "Sean", "Nguyen", "Thang Tat"], "venue": "arXiv preprint arXiv:1501.02155,", "citeRegEx": "Hales et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Hales et al\\.", "year": 2015}, {"title": "Hol light: A tutorial introduction", "author": ["Harrison", "John"], "venue": "In International Conference on Formal Methods in ComputerAided Design,", "citeRegEx": "Harrison and John.,? \\Q1996\\E", "shortCiteRegEx": "Harrison and John.", "year": 1996}, {"title": "Floating-point verification using theorem proving", "author": ["Harrison", "John"], "venue": "In International School on Formal Methods for the Design of Computer, Communication and Software Systems,", "citeRegEx": "Harrison and John.,? \\Q2006\\E", "shortCiteRegEx": "Harrison and John.", "year": 2006}, {"title": "Accuracy and stability of numerical algorithms", "author": ["Higham", "Nicholas J"], "venue": null, "citeRegEx": "Higham and J.,? \\Q2002\\E", "shortCiteRegEx": "Higham and J.", "year": 2002}, {"title": "Adam: A method for stochastic optimization", "author": ["Kingma", "Diederik", "Ba", "Jimmy"], "venue": "arXiv preprint arXiv:1412.6980,", "citeRegEx": "Kingma et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Kingma et al\\.", "year": 2014}, {"title": "Formal verification of a realistic compiler", "author": ["Leroy", "Xavier"], "venue": "Communications of the ACM,", "citeRegEx": "Leroy and Xavier.,? \\Q2009\\E", "shortCiteRegEx": "Leroy and Xavier.", "year": 2009}, {"title": "Isabelle/HOL: a proof assistant for higherorder logic, volume 2283", "author": ["Nipkow", "Tobias", "Paulson", "Lawrence C", "Wenzel", "Markus"], "venue": null, "citeRegEx": "Nipkow et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Nipkow et al\\.", "year": 2002}, {"title": "Pvs: A prototype verification system", "author": ["Owre", "Sam", "Rushby", "John M", "Shankar", "Natarajan"], "venue": "In Automated Deduction\u2014CADE-11,", "citeRegEx": "Owre et al\\.,? \\Q1992\\E", "shortCiteRegEx": "Owre et al\\.", "year": 1992}, {"title": "An overview of the mizar project", "author": ["Rudnicki", "Piotr"], "venue": "In Proceedings of the 1992 Workshop on Types for Proofs and Programs,", "citeRegEx": "Rudnicki and Piotr.,? \\Q1992\\E", "shortCiteRegEx": "Rudnicki and Piotr.", "year": 1992}, {"title": "Gradient estimation using stochastic computation graphs", "author": ["Schulman", "John", "Heess", "Nicolas", "Weber", "Theophane", "Abbeel", "Pieter"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Schulman et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Schulman et al\\.", "year": 2015}], "referenceMentions": [{"referenceID": 1, "context": "Theano (Bergstra et al., 2010) has been under development for almost a decade and yet there is a recent GitHub issue (https://github.", "startOffset": 7, "endOffset": 30}, {"referenceID": 16, "context": "Our approach makes use of a tool called an interactive proof assistant (Gordon, 1979; Gordon & Melham, 1993; Harrison, 1996; Nipkow et al., 2002; Owre et al., 1992; Coq Development Team, 2015-2016; de Moura et al., 2015), which consists of (a) a programming language, (b) a language to state mathematical theorems, and (c) a set of tools for constructing formal proofs of such theorems.", "startOffset": 71, "endOffset": 220}, {"referenceID": 17, "context": "Our approach makes use of a tool called an interactive proof assistant (Gordon, 1979; Gordon & Melham, 1993; Harrison, 1996; Nipkow et al., 2002; Owre et al., 1992; Coq Development Team, 2015-2016; de Moura et al., 2015), which consists of (a) a programming language, (b) a language to state mathematical theorems, and (c) a set of tools for constructing formal proofs of such theorems.", "startOffset": 71, "endOffset": 220}, {"referenceID": 3, "context": "Proving correctness of machine learning systems requires building on the tools and insights from two distinct fields: program verification (Leroy, 2009; Klein et al., 2009; Chlipala, 2013; Chen et al., 2015), which has aimed to prove properties of computer programs, and formal mathematics (Rudnicki, 1992; Gonthier, 2008; Gonthier et al.", "startOffset": 139, "endOffset": 207}, {"referenceID": 10, "context": ", 2015), which has aimed to prove properties of computer programs, and formal mathematics (Rudnicki, 1992; Gonthier, 2008; Gonthier et al., 2013; Hales et al., 2015), which has aimed to formally represent and generate machine-checkable proofs of mathematical theorems.", "startOffset": 90, "endOffset": 165}, {"referenceID": 19, "context": "ticality of our approach, we implemented a new machine learning system, Certigrad, for optimizing over stochastic computation graphs (Schulman et al., 2015).", "startOffset": 133, "endOffset": 156}, {"referenceID": 1, "context": ", 2015) and Theano (Bergstra et al., 2010) by allowing nodes to represent random variables and by defining the loss function for a graph to be the expected value of the sum of the leaf nodes over the stochastic choices.", "startOffset": 19, "endOffset": 42}, {"referenceID": 16, "context": "Our development makes use of certain features that are unique to Lean, but most of what we present is equally applicable to Coq, and to a lesser extent, other interactive theorem provers such as Isabelle/HOL (Nipkow et al., 2002).", "startOffset": 208, "endOffset": 229}, {"referenceID": 19, "context": "Stochastic computation graphs are directed acyclic graphs in which each node represents a specific computational operation that may be deterministic or stochastic (Schulman et al., 2015).", "startOffset": 163, "endOffset": 186}, {"referenceID": 10, "context": "Whereas in traditional formal mathematics the goal is to construct mathematics from first principles (Gonthier et al., 2013; Hales et al., 2015), we need not concern ourselves with foundational issues and can simply assume that standard mathematical properties hold.", "startOffset": 101, "endOffset": 144}, {"referenceID": 19, "context": "We also needed to assume a generalization of the differentiability requirement mentioned in Schulman et al. (2015), that a subset of the nodes determined by the structure of the graph must be differentiable no matter the result of any stochastic choices (GradsExist g \u03b8).", "startOffset": 92, "endOffset": 115}, {"referenceID": 2, "context": "Although doing so technically invalidates the specification and can introduce numerical instability in some cases, this class of errors is well understood (Higham, 2002), could be ruled out as well in principle (Harrison, 2006; Boldo et al., 2015; Ramananandro et al., 2016) and is conceptually distinct from the algorithmic and mathematical errors that our methodology is designed to eliminate.", "startOffset": 211, "endOffset": 274}], "year": 2017, "abstractText": "Noisy data, non-convex objectives, model misspecification, and numerical instability can all cause undesired behaviors in machine learning systems. As a result, detecting actual implementation errors can be extremely difficult. We demonstrate a methodology in which developers use an interactive proof assistant to both implement their system and to state a formal theorem defining what it means for their system to be correct. The process of proving this theorem interactively in the proof assistant exposes all implementation errors since any error in the program would cause the proof to fail. As a case study, we implement a new system, Certigrad, for optimizing over stochastic computation graphs, and we generate a formal (i.e. machine-checkable) proof that the gradients sampled by the system are unbiased estimates of the true mathematical gradients. We train a variational autoencoder using Certigrad and find the performance comparable to training the same model in TensorFlow.", "creator": "LaTeX with hyperref package"}}}