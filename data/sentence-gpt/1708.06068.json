{"id": "1708.06068", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "21-Aug-2017", "title": "Vector Space Model as Cognitive Space for Text Classification", "abstract": "In this era of digitization, knowing the user's sociolect aspects have become essential features to build the user specific recommendation systems. These sociolect aspects could be found by mining the user's language sharing in the form of text in social media and reviews. This paper describes about the experiment that was performed in PAN Author Profiling 2017 shared task. The objective of the task is to find the sociolect aspects of the users from their tweets. The sociolect aspects considered in this experiment are user's gender and native language information. Here user's tweets written in a different language from their native language are represented as Document - Term Matrix with document frequency as the constraint. Further classification is done using the Support Vector Machine by taking gender and native language as target classes. This experiment attains the average accuracy of 73.42% in gender prediction and 76.26% in the native language identification task.\n\n\n\nThe experiment was conducted in the following context:\nIn addition to the data presented in the manuscript, the project's main topic is how to improve the ability of the user to find the appropriate topic to evaluate on the basis of the type of topic the user believes is most relevant to the user. To develop this work, the participants had to find the appropriate topic to evaluate on the basis of the type of topic the user believes is most relevant to the user. To do this, the participants had to search the search results of various social media channels for the topic.\nThe task was conducted in the following context:\nUsing the support vector machine by taking gender and native language as target classes. The sample data can be analysed with the help vector. The sample data can be analyzed with the help vector. The sample data can be analysed with the help vector. The sample data can be analysed with the help vector. The sample data can be analysed with the help vector. The sample data can be analysed with the help vector. The sample data can be analyzed with the help vector. The sample data can be analysed with the help vector. The sample data can be analyzed with the help vector. The sample data can be analysed with the help vector. The sample data can be analysed with the help vector. The sample data can be analyzed with the help vector. The sample data can be analysed with the help vector. The sample data can be analyzed with the help vector. The sample data can be analysed with the help vector. The sample data can be analysed with the help vector. The sample data can be analysed with the help vector.\nThe sample data", "histories": [["v1", "Mon, 21 Aug 2017 03:06:07 GMT  (268kb,D)", "http://arxiv.org/abs/1708.06068v1", "6 pages, 6 figures, 3 tables"]], "COMMENTS": "6 pages, 6 figures, 3 tables", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["barathi ganesh hb", "anand kumar m", "soman kp"], "accepted": false, "id": "1708.06068"}, "pdf": {"name": "1708.06068.pdf", "metadata": {"source": "CRF", "title": "Vector Space Model as Cognitive Space for Text Classification", "authors": ["Barathi Ganesh"], "emails": ["barathiganesh.hb@gmail.com,", "anandkumar@cb.amrita.edu,", "soman@amrita.edu"], "sections": [{"heading": "1 Introduction", "text": "The user profiling is an indirect crowd sourcing task, which collect user\u2019s sociolect aspects like age, gender and language variation from their language share (i.e. Tweets, Face book data and Reviews) 1 2. Knowing the user\u2019s sociolect aspects paves way to enrich the performance of recommendation systems, targeted internet advertising, consumer behavior analysis and forensic science. This work is focused on mining of sociolect aspects like gender and language variation (native language) from the user\u2019s (author\u2019s) tweets by having their word usage as an evidence [1][8].\nPAN - 2017 author profiling task is to predict the author\u2019s gender and language variation from their tweets which are 100 in number [1]. This task can be viewed as a text classification problem by having target class as the author\u2019s sociolect aspects and text as their tweets. The primary component in the text classification problem are representation, feature learning and classification. Here we have modelled the Vector Space Model (VSM) as the author\u2019s cognition 3 as cognitive space 4 through the Document - Term Matrix (DTM) representation and feature learning methods. The further prediction of gender and language variation is done through the Support Vector Machine (SVM) based classification.\nMost of the recent researches are focused on representing the context of the text through distributional and distributed text representation methods [2] [3] [4]. This context representation of text\n1http://pan.webis.de/clef17/pan17-web/author-profiling.html 2http://ttg.uni-saarland.de/resources/DSLCC/ 3en.wikipedia.org/wiki/Cognition 4dictionary.sensagent.com/cognitive%20space/en-en/\nar X\niv :1\n70 8.\n06 06\n8v 1\n[ cs\n.C L\n] 2\n1 A\nalone will not contribute much towards the prediction of authors sociolect aspects, since it is also dependent on their source of cognitive knowledge like education, cultural background, age group, working domain etc [5]. In this Author Profiling task \u201dHow\u201d language sharing expressed by an author is having more impact than the \u201dWhat\u201d they actually shared [5]. By observing this, here the Document - Term Matrix (DTM) is used as representation method, in which the fundamental features are words and their frequencies used by the users.\nThe Figure 1 and 2 describes the variation in word frequency with respect to the gender and native language of the users. It can be observed that usage of word and its frequency varies with respect to the user\u2019s sociolect aspects. The frequency of the word used by female is significantly greater than the word used by male. As told above cognitive nature is applicable to native language variation also. We have experimented VSM to model this cognition ability. The words in these Figure 1 and 2 are derived by taking common word across the target classes from the list of words with top 20 highest frequency in the final model. The above shown Figure 1 and 2 has been plotted for English language which is also applicable to the other languages."}, {"heading": "2 Text Representation - Vector Space Model", "text": "Vector Space Model is built from the documents provided. These set of documents are processed to find its equivalent optimized numerical representation in the matrix format.\nD = d1, d2, d3, ..., dn (1)\nHere d represents the sentences or documents (here tweets), D represents its equivalent matrix format (here DTM) and n is the total number of documents.\nThe commonly used methods under VSM are Document - Term Matrix (DTM) and Term Frequency - Inverse Document Frequency Matrix (TF-IDF). These methods are generally referred to as Bag of Word (BOW) method and it follows bag of word hypothesis [6]. In our methodology, TF-IDF is not taken into consideration because, the control over the document frequency and term significance are modeled through minimum document frequency.\nGiven a set of texts as in equation 1, the function f() converts it into the Document Term Matrix (DTM). In this application document refers to the user\u2019s tweet collection, hence the matrix can be viewed as user - term matrix. The function f() measures the event e, where e is the occurrence of terms in the texts. The term may take words, phrases (n-grams) or both. The above can be represented as, D = f(e) if e > k (2) Where D is the DTM with m \u00d7 n size. m is the number of users, k is the minimum document frequency and n is the total number of unique words or phrases (types) present in the document set. The word with frequency < k is not included in the DTM."}, {"heading": "3 Feature Learning", "text": "Feature learning is the abstract level representation of original text content. This enhances the model performance by filtering the unwanted information and reduces the computation time required to build the model. In this work, frequency of the word across the document (document frequency) is taken as the threshold to limit the number of unique words in the vocabulary to build the user - term matrix [6]. The terms in the vocabulary are constrained by the document frequency. Hence the matrix produced through this can be viewed as user - feature matrix. In the produced matrix row refers to the user and column refer to the word used by the user. The following Feature Scaling table gives the comparison between number of words in user - term matrix and user - feature matrix."}, {"heading": "4 Classification", "text": "This experiment does not focus on classification rather than the representation of texts. Therefore the user - feature matrix along with its corresponding target classes are used to train the Support Vector Machine (SVM) classifier with Radial Basis Function (RBF) as the kernal. SVM is a well known non probabilistic classification algorithm which is used most often to perform the VSM based representations [7]. SVM with the default parameter in Scikit Learn library is directly used to build the classifier (i.e. C = 1.0, degree=3, gamma=\u2019auto\u2019, kernel=\u2019rbf\u2019 )."}, {"heading": "5 Experiments and Observations", "text": "This section details the statistics about the given training data set, experimented system and its outcomes. This experiment is conducted with a machine having Intel i7 processor and 16GB of RAM.\nThe data set contains 100 tweets per author and these tweets are written in 4 different languages. Within these different languages, native language of the users also varies. The detailed statistics about the data-set utilized is given in PAN 2017 Author Profiling overview paper [1]. The number of variation in the native language is shown in Data - Set Statistics Table. These 100 tweets per\nauthor is embedded in an xml file and given with the truth file which contains gender and language variation class of the corresponding author. These xml files are passed through xml Python library 5 as a document object model and tweets are extracted out of it. These 100 tweets per author is then concatenated to form a single document per author. By taking white space as the delimiter, tokenization has been performed and Count Vectorizer from SKLEARN python library 6 used to build the DTM. Here document in a row is referred to as the user.\nThe User - Feature Matrix with the class tags are given to the SVM with Radial Basis Function kernal (RBF Kernal) and C = 1 to build the classification models. An independent two classification models are build for the gender prediction and identification of Language variation. To build the classifier SVM from the SKLEARN Python library 7 is utilized. To ensure the performance a 10-fold 10-cross validation is performed and the average accuracy of the 10-validation scores are calculated to find the final accuracy. This can be represented as,\nAccuracy = correctly predicted authors\ntotal authors (3)\nAverage Accuracy =\n\u221110 i=1 Accuracyi\n10 (4)\nThe above said experiment is conducted with minimum document frequency varying between 2 and 25 while representing tweets as User - Feature Matrix. The final classification model is built by selecting the minimum document frequency with highest accuracy across all four languages. Here minimum document frequency acts as a constraint in the selection of words to build a vocabulary. The minimum document frequency is an event of frequency of the word appearing across the documents (i.e. minimum number of users who used the given word). The performance of the model built against the minimum document frequency is given in the Figures 3 and 4. It can be observed that the performance of the models has attained the constant accuracy for the minimum document frequency greater than 4. From this observation in this experiment final model is built with \u201dminimum document frequency = 10\u201d.\n5docs.python.org/2/library/xml.etree.elementtree.html 6scikit-learn.org/stable/modules/generated/sklearn.feature extraction.text.CountVectorizer.html 7scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html\nAs the minimum document frequency increases the size of the User - Feature Matrix gets reduced. This is because the number of words to form the vocabulary is less. This has a significant impact on time to build the classification model. This is shown in the Figure 5 and 6.\nThe User - Feature Matrix of the test data is built against the selected classification model\u2019s vocabulary and thereafter gender, language variations are predicted. The result obtained against the test data are evaluated by the PAN 2017 Author Profiling shared task committee and it is shown in Table 3 8. It can be observed that, the highest performance was attained for Portuguese language and lowest for English language. This is because of the significance of number of native language variation within the language. On the whole, this experimentation attains nearly 70% of accuracy for all the languages in both the tasks.\n8http://pan.webis.de/clef17/pan17-web/author-profiling.html"}, {"heading": "6 Conclusion", "text": "The word usage by the users have been represented in the cognitive space by Document - Term Matrix as Vector Space Model. By considering word usage as features, further classification has been carried out using Support Vector Machine. The observed results have attained nearly an average accuracy of 70 % in both the tasks across different languages. From the assumptions made it has been found that these primary results are satisfactory and that Vector Space Model can be considered as the user\u2019s Cognitive Space.\nThe accuracy of the system can be enriched by representing the tweets using Vector Space Models of Semantics (distributional and distributed representation methods). Our further experimentation will be on deriving the Vector Space Models of Semantics representation methods for modelling the user\u2019s cognitive space from the representation method utilized in this paper."}], "references": [{"title": "Overview of the 5th Author Profiling Task at PAN 2017: Gender and Language Variety Identification in Twitter", "author": ["Rangel", "Francisco", "Paolo Rosso", "Martin Potthast", "Benno Stein"], "venue": "Working Notes Papers of the CLEF", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2017}, {"title": "Distributional Semantic Representation for Text Classification and Information Retrieval", "author": ["HB Barathi Ganesh", "M Anand Kumar", "KP. Soman"], "venue": null, "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2016}, {"title": "Author identification based on word distribution in word space", "author": ["HB Barathi Ganesh", "U Reshma", "M. Anand Kumar"], "venue": "In Advances in Computing, Communications and Informatics (ICACCI),", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2015}, {"title": "Dynamic pooling and unfolding recursive autoencoders for paraphrase detection", "author": ["Socher", "Richard", "Eric H. Huang", "Jeffrey Pennin", "Christopher D. Manning", "Andrew Y. Ng"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2011}, {"title": "Statistical Semantics in Context Space", "author": ["HB Barathi Ganesh", "M Anand Kumar", "KP. Soman"], "venue": null, "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2016}, {"title": "From frequency to meaning: Vector space models of semantics", "author": ["Turney", "Peter D", "Patrick Pantel"], "venue": "Journal of artificial intelligence research", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2010}, {"title": "A practical guide to support vector classification", "author": ["Hsu", "Chih-Wei", "Chih-Chung Chang", "Chih-Jen Lin"], "venue": null, "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2003}, {"title": "Merging Comparable Data Sources for the Discrimination of Similar Languages: The DSL Corpus Collection", "author": ["Tan", "Liling", "Zampieri", "Marcos", "Ljube\u0161ic", "Nikola", "Tiedemann", "J\u00f6rg"], "venue": "Proceedings of the 7th Workshop on Building and Using Comparable Corpora (BUCC)", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2014}], "referenceMentions": [{"referenceID": 0, "context": "This work is focused on mining of sociolect aspects like gender and language variation (native language) from the user\u2019s (author\u2019s) tweets by having their word usage as an evidence [1][8].", "startOffset": 181, "endOffset": 184}, {"referenceID": 7, "context": "This work is focused on mining of sociolect aspects like gender and language variation (native language) from the user\u2019s (author\u2019s) tweets by having their word usage as an evidence [1][8].", "startOffset": 184, "endOffset": 187}, {"referenceID": 0, "context": "PAN - 2017 author profiling task is to predict the author\u2019s gender and language variation from their tweets which are 100 in number [1].", "startOffset": 132, "endOffset": 135}, {"referenceID": 1, "context": "Most of the recent researches are focused on representing the context of the text through distributional and distributed text representation methods [2] [3] [4].", "startOffset": 149, "endOffset": 152}, {"referenceID": 2, "context": "Most of the recent researches are focused on representing the context of the text through distributional and distributed text representation methods [2] [3] [4].", "startOffset": 153, "endOffset": 156}, {"referenceID": 3, "context": "Most of the recent researches are focused on representing the context of the text through distributional and distributed text representation methods [2] [3] [4].", "startOffset": 157, "endOffset": 160}, {"referenceID": 4, "context": "alone will not contribute much towards the prediction of authors sociolect aspects, since it is also dependent on their source of cognitive knowledge like education, cultural background, age group, working domain etc [5].", "startOffset": 217, "endOffset": 220}, {"referenceID": 4, "context": "In this Author Profiling task \u201dHow\u201d language sharing expressed by an author is having more impact than the \u201dWhat\u201d they actually shared [5].", "startOffset": 135, "endOffset": 138}, {"referenceID": 5, "context": "These methods are generally referred to as Bag of Word (BOW) method and it follows bag of word hypothesis [6].", "startOffset": 106, "endOffset": 109}, {"referenceID": 5, "context": "In this work, frequency of the word across the document (document frequency) is taken as the threshold to limit the number of unique words in the vocabulary to build the user term matrix [6].", "startOffset": 187, "endOffset": 190}, {"referenceID": 6, "context": "SVM is a well known non probabilistic classification algorithm which is used most often to perform the VSM based representations [7].", "startOffset": 129, "endOffset": 132}, {"referenceID": 0, "context": "The detailed statistics about the data-set utilized is given in PAN 2017 Author Profiling overview paper [1].", "startOffset": 105, "endOffset": 108}], "year": 2017, "abstractText": "In this era of digitization, knowing the user\u2019s sociolect aspects have become essential features to build the user specific recommendation systems. These sociolect aspects could be found by mining the user\u2019s language sharing in the form of text in social media and reviews. This paper describes about the experiment that was performed in PAN Author Profiling 2017 shared task. The objective of the task is to find the sociolect aspects of the users from their tweets. The sociolect aspects considered in this experiment are user\u2019s gender and native language information. Here user\u2019s tweets written in a different language from their native language are represented as Document Term Matrix with document frequency as the constraint. Further classification is done using the Support Vector Machine by taking gender and native language as target classes. This experiment attains the average accuracy of 73.42% in gender prediction and 76.26% in the native language identification task.", "creator": "LaTeX with hyperref package"}}}