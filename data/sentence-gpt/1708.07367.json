{"id": "1708.07367", "review": {"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "24-Aug-2017", "title": "Mixing Time Estimation in Reversible Markov Chains from a Single Sample Path", "abstract": "The spectral gap $\\gamma$ of a finite, ergodic, and reversible Markov chain is an important parameter measuring the asymptotic rate of convergence. In applications, the transition matrix $P$ may be unknown, yet one sample of the chain up to a fixed time $n$ may be observed. We consider here the problem of estimating $\\gamma$ from this data. Let $\\pi$ be the stationary distribution of $P$, and $\\pi_\\star = \\min_x \\pi(x)$. We show that if $n = \\tilde{O}\\bigl(\\frac{1}{\\gamma \\pi_\\star}\\bigr)$, then $\\gamma$ can be estimated to within multiplicative constants with high probability. When $\\pi$ is uniform on $d$ states, this matches (up to logarithmic correction) a lower bound of $\\tilde{\\Omega}\\bigl(\\frac{d}{\\gamma}\\bigr)$ steps required for precise estimation of $\\gamma$. Moreover, we provide the first procedure for computing a fully data-dependent interval, from a single finite-length trajectory of the chain, that traps the mixing time $t_{\\text{mix}}$ of the chain at a prescribed confidence level. The interval does not require the knowledge of any parameters of the chain. This stands in contrast to previous approaches, which either only provide point estimates, or require a reset mechanism, or additional prior knowledge. The interval is constructed around the relaxation time $t_{\\text{relax}} = 1/\\gamma$, which is strongly related to the mixing time, and the width of the interval converges to zero roughly at a $1/\\sqrt{n}$ rate, where $n$ is the length of the sample path. We show the time $\\Gamma$ should be approximately one week after the sampling period and the phase phase is the minimum for the first step.\n\n\n\nFor a finite and reversible Markov chain, we estimate a finite/linear model of the phase at the boundary $\\pi$, and $\\pi_\\star = \\min_x \\pi(x)$. For the first step, the phase has a very constant interval with zero at a constant value of $N$. We assume that the phase will be a constant at the boundary $n$. Since it has a uniform constant, and the phase is a constant at the boundary $n$. Since its zero", "histories": [["v1", "Thu, 24 Aug 2017 12:05:11 GMT  (43kb)", "http://arxiv.org/abs/1708.07367v1", "34 pages, merges results ofarXiv:1506.02903andarXiv:1612.05330"]], "COMMENTS": "34 pages, merges results ofarXiv:1506.02903andarXiv:1612.05330", "reviews": [], "SUBJECTS": "math.ST cs.LG math.PR stat.ML stat.TH", "authors": ["daniel j hsu", "aryeh kontorovich", "csaba szepesv\u00e1ri"], "accepted": true, "id": "1708.07367"}, "pdf": {"name": "1708.07367.pdf", "metadata": {"source": "CRF", "title": null, "authors": [], "emails": [], "sections": [{"heading": null, "text": "ar X\niv :1\n70 8.\n07 36\n7v 1\n[ m\nat h.\nST ]\n2 4\nA ug\n(\n1 \u03b3\u22c6\u03c0\u22c6\n)\n, then \u03b3 can be estimated to\nwithin multiplicative constants with high probability. When \u03c0 is uniform on d states, this matches (up to logarithmic correction) a lower bound of \u2126\u0303 (\nd \u03b3\u22c6\n)\nsteps required for precise estimation of \u03b3\u22c6. Moreover, we provide the first procedure for computing a fully data-dependent interval, from a single finitelength trajectory of the chain, that traps the mixing time tmix of the chain at a prescribed confidence level. The interval does not require the knowledge of any parameters of the chain. This stands in contrast to previous approaches, which either only provide point estimates, or require a reset mechanism, or additional prior knowledge. The interval is constructed around the relaxation time trelax = 1/\u03b3\u22c6, which is strongly related to the mixing time, and the width of the interval converges to zero roughly at a 1/ \u221a n rate, where n is the length of the sample path."}, {"heading": "1. Introduction", "text": "This work tackles the challenge of constructing confidence intervals for the mixing time of reversible Markov chains based on a single sample path. Let (Xt)t=1,2,... be an irreducible, aperiodic time-homogeneous Markov chain on a finite state space [d] := {1, 2, . . . , d} with transition matrix P . Under this assumption, the chain converges to its unique stationary distribution \u03c0 = (\u03c0i) d i=1 regardless of the initial state distribution q:\nlim t\u2192\u221e Prq (Xt = i) = lim t\u2192\u221e\n(qP t)i = \u03c0i for each i \u2208 [d].\nThe mixing time tmix of the Markov chain is the number of time steps required for the chain to be within a fixed threshold of its stationary distribution:\ntmix := min\n{ t \u2208 N : sup\nq\nmax A\u2282[d]\n|Prq (Xt \u2208 A)\u2212 \u03c0(A)| \u2264 1/4 } .(1) Here, \u03c0(A) = \u2211\ni\u2208A \u03c0i is the probability assigned to set A by \u03c0, and the supremum is over all possible initial distributions q. The problem studied in this work is the construction of a non-trivial confidence interval Cn = Cn(X1, X2, . . . , Xn, \u03b4) \u2282 [0,\u221e], based only on the observed sample path (X1, X2, . . . , Xn) and \u03b4 \u2208 (0, 1), that succeeds with probability 1\u2212 \u03b4 in trapping the value of the mixing time tmix.\nThis problem is motivated by the numerous scientific applications and machine learning tasks in which the quantity of interest is the mean \u03c0(f) = \u2211 i \u03c0if(i) for\n1\nsome function f of the states of a Markov chain. This is the setting of the celebrated Markov Chain Monte Carlo (MCMC) paradigm (J. S. Liu 2001), but the problem also arises in performance prediction involving time-correlated data, as is common in reinforcement learning (Sutton and Barto 1998). Observable, or a posteriori bounds on mixing times are useful in the design and diagnostics of these methods; they yield effective approaches to assessing the estimation quality, even when a priori knowledge of the mixing time or correlation structure is unavailable.\n1.1. Main results. Consider a reversible ergodic Markov chain on d states with absolute spectral gap \u03b3\u22c6 and stationary distribution minorized by \u03c0\u22c6. As is wellknown (see, for example, Levin, Peres, andWilmer (2009, Theorems 12.3 and 12.4)),\n(2) (trelax \u2212 1) ln 2 \u2264 tmix \u2264 trelax ln 4\n\u03c0\u22c6\nwhere trelax := 1/\u03b3\u22c6 is the relaxation time. Hence, it suffices to estimate \u03b3\u22c6 and \u03c0\u22c6. Our main results are summarized as follows.\n(1) In Section 3.1, we show that in some problems n = \u2126((d log d)/\u03b3\u22c6 + 1/\u03c0\u22c6) observations are necessary for any procedure to guarantee constant multiplicative accuracy in estimating \u03b3\u22c6 (Theorems 3.1 and 3.2). Essentially, in some problems every state may need to be visited about log(d)/\u03b3\u22c6 times, on average, before an accurate estimate of the mixing time can be provided, regardless of the actual estimation procedure used. (2) In Section 3.2, we give a point estimator \u03b3\u0302\u22c6 for \u03b3\u22c6, based an a single sample\npath, and prove in Theorem 3.4 that | \u03b3\u0302\u22c6\u03b3\u22c6 \u22121| < \u03b5 with high probability if the path is of length O\u0303(1/(\u03c0\u22c6\u03b3\u22c6\u03b5\n2)). (The O\u0303(\u00b7) notation suppresses logarithmic factors.) We also provide and analyze a point estimator for \u03c0\u22c6. This establishes the feasibility of estimating the mixing time in this setting, and the dependence on \u03c0\u22c6 and \u03b3\u22c6 in the path length matches our lower bound (up to logarithmic factors) in the case where 1/\u03c0\u22c6 = \u2126(d). We note, however, that these results give only a priori confidence intervals that depend on the unknown quantities \u03c0\u22c6 and \u03b3\u22c6. As such, the results do not lead to a universal (chain-independent) stopping rule for stopping the chain when the relative error is below the prescribed accuracy. (3) In Section 4, we propose a procedure for a posteriori constructing confidence intervals for \u03c0\u22c6 and \u03b3\u22c6 that depend only on the observed sample path and not on any unknown parameters. We prove that the intervals shrink at a O\u0303(1/ \u221a n) rate (Theorems 4.1 and 4.2). These confidence intervals trivially\nlead to a universal stopping rule to stop the chain when a prescribed relative error is achieved.\n1.2. Related work. There is a vast statistical literature on estimation in Markov chains. For instance, it is known that under the assumptions on (Xt)t from above, the law of large numbers guarantees that the sample mean \u03c0n(f) := 1 n \u2211n t=1 f(Xt) converges almost surely to \u03c0(f) (Meyn and Tweedie 1993), while the central limit theorem tells us that as n \u2192 \u221e, the distribution of the deviation \u221an(\u03c0n(f)\u2212\u03c0(f)) will be normal with mean zero and asymptotic variance limn\u2192\u221e nVar (\u03c0n(f)) (Kipnis and Varadhan 1986).\nAlthough these asymptotic results help us understand the limiting behavior of the sample mean over a Markov chain, they say little about the finite-time nonasymptotic behavior, which is often needed for the prudent evaluation of a method\nor even its algorithmic design (Kontoyiannis, Lastras-Montan\u0303o, and Meyn 2006; Flegal and Jones 2011; Gyori and Paulin 2014). To address this need, numerous works have developed Chernoff-type bounds on Pr(|\u03c0n(f) \u2212 \u03c0(f)| > \u01eb), thus providing valuable tools for non-asymptotic probabilistic analysis (Gillman 1998; Leo\u0301n and Perron 2004; Kontoyiannis, Lastras-Montan\u0303o, and Meyn 2006; Kontorovich and Weiss 2014; Paulin 2015). These probability bounds are larger than the corresponding bounds for independent and identically distributed (iid) data due to the temporal dependence; intuitively, for the Markov chain to yield a fresh draw Xt\u2032 that behaves as if it was independent of Xt, one must wait \u0398(tmix) time steps. Note that the bounds generally depend on distribution-specific properties of the Markov chain (e.g., P , tmix, \u03b3\u22c6), which are often unknown a priori in practice. Consequently, much effort has been put towards estimating these unknown quantities, especially in the context of MCMC diagnostics, in order to provide data-dependent assessments of estimation accuracy (e.g., Garren and R. L. Smith 2000; Jones and Hobert 2001; Flegal and Jones 2011; Atchade\u0301 2016; Gyori and Paulin 2014). However, these approaches generally only provide asymptotic guarantees, and hence fall short of our goal of empirical bounds that are valid with any finite-length sample path. In particular, they also fail to provide universal stopping rules that allow the estimation of (for example) the mixing time with a fixed relative accuracy.\nLearning with dependent data is another main motivation to our work. Many results from statistical learning and empirical process theory have been extended to sufficiently fast mixing, dependent data (e.g., Yu 1994; Karandikar and Vidyasagar 2002; Gamarnik 2003; Mohri and Rostamizadeh 2008; Steinwart and Christmann 2009; Steinwart, Hush, and Scovel 2009), providing learnability assurances (e.g., generalization error bounds). These results are often given in terms of mixing coefficients, which can be consistently estimated in some cases (McDonald, Shalizi, and Schervish 2011). However, the convergence rates of the estimates from McDonald, Shalizi, and Schervish (2011), which are needed to derive confidence bounds, are given in terms of unknown mixing coefficients. When the data comes from a Markov chain, these mixing coefficients can often be bounded in terms of mixing times, and hence our main results provide a way to make them fully empirical, at least in the limited setting we study.\nIt is possible to eliminate many of the difficulties presented above when allowed more flexible access to the Markov chain. For example, given a sampling oracle that generates independent transitions from any given state (akin to a \u201creset\u201d device), the mixing time becomes an efficiently testable property in the sense studied by Batu, Fortnow, Rubinfeld, W. D. Smith, and White (2000), Batu, Fortnow, Rubinfeld, W. D. Smith, and White (2013), and Bhattacharya and Valiant (2015). Note that in this setting, Bhattacharya and Valiant (2015) asked if one could approximate tmix (up to logarithmic factors) with a number of queries that is linear in both d and tmix; our work answers the question affirmatively (up to logarithmic corrections) in the case when the stationary distribution is near uniform. Finally, when one only has a circuit-based description of the transition probabilities of a Markov chain over an exponentially-large state space, there are complexity-theoretic barriers for many MCMC diagnostic problems (Bhatnagar, Bogdanov, and Mossel 2011).\nThis paper is based on the conference paper of Hsu, Kontorovich, and Szepesva\u0301ri (2015), combined with the results in the unpublished manuscript of Levin and Peres (2016)."}, {"heading": "2. Preliminaries", "text": "2.1. Notations. We denote the set of positive integers by N, and the set of the first d positive integers {1, 2, . . . , d} by [d]. The non-negative part of a real number x is [x]+ := max{0, x}, and \u2308x\u2309+ := max{0, \u2308x\u2309}. We use ln(\u00b7) for natural logarithm, and log(\u00b7) for logarithm with an arbitrary constant base > 1. Boldface symbols are used for vectors and matrices (e.g., v, M), and their entries are referenced by subindexing (e.g., vi, Mi,j). For a vector v, \u2016v\u2016 denotes its Euclidean norm; for a matrix M , \u2016M\u2016 denotes its spectral norm. We use Diag(v) to denote the diagonal matrix whose (i, i)-th entry is vi. The probability simplex is denoted by \u2206d\u22121 = {p \u2208 [0, 1]d : \u2211di=1 pi = 1}, and we regard vectors in \u2206d\u22121 as row vectors.\n2.2. Setting. Let P \u2208 (\u2206d\u22121)d \u2282 [0, 1]d\u00d7d be a d \u00d7 d row-stochastic matrix for an ergodic (i.e., irreducible and aperiodic) Markov chain. This implies there is a unique stationary distribution \u03c0 \u2208 \u2206d\u22121 with \u03c0i > 0 for all i \u2208 [d] (Levin, Peres, and Wilmer 2009, Corollary 1.17). We also assume that P is reversible (with respect to \u03c0):\n\u03c0iPi,j = \u03c0jPj,i, i, j \u2208 [d].(3) The minimum stationary probability is denoted by \u03c0\u22c6 := mini\u2208[d] \u03c0i.\nDefine the matrices\nM := Diag(\u03c0)P and L := Diag(\u03c0)\u22121/2M Diag(\u03c0)\u22121/2 .\nThe (i, j)th entry of the matrix Mi,j contains the doublet probabilities associated with P : Mi,j = \u03c0iPi,j is the probability of seeing state i followed by state j when the chain is started from its stationary distribution. The matrix M is symmetric on account of the reversibility of P , and hence it follows that L is also symmetric. (We will strongly exploit the symmetry in our results.) Further, L = Diag(\u03c0)1/2P Diag(\u03c0)\u22121/2, hence L and P are similar and thus their eigenvalue systems are identical. Ergodicity and reversibility imply that the eigenvalues of L are contained in the interval (\u22121, 1], and that 1 is an eigenvalue of L with multiplicity 1 (Levin, Peres, and Wilmer 2009, Lemmas 12.1 and 12.2). Denote and order the eigenvalues of L as\n1 = \u03bb1 > \u03bb2 \u2265 \u00b7 \u00b7 \u00b7 \u2265 \u03bbd > \u22121. Let \u03bb\u22c6 := max{\u03bb2, |\u03bbd|}, and define the (absolute) spectral gap to be \u03b3\u22c6 := 1\u2212 \u03bb\u22c6, which is strictly positive on account of ergodicity.\nLet (Xt)t\u2208N be a Markov chain whose transition probabilities are governed by P . For each t \u2208 N, let \u03c0(t) \u2208 \u2206d\u22121 denote the marginal distribution of Xt, so\n\u03c0(t+1) = \u03c0(t)P , t \u2208 N. Note that the initial distribution \u03c0(1) is arbitrary, and need not be the stationary distribution \u03c0.\nThe goal is to estimate \u03c0\u22c6 and \u03b3\u22c6 from the length n sample path (Xt)t\u2208[n], and also to construct confidence intervals that \u03c0\u22c6 and \u03b3\u22c6 with high probability; in particular, the construction of the intervals should be fully empirical and not depend on any unobservable quantities, including \u03c0\u22c6 and \u03b3\u22c6 themselves. As mentioned in the introduction, it is well-known that the mixing time of the Markov chain tmix (defined in Eq. (1)) is bounded in terms of \u03c0\u22c6 and \u03b3\u22c6, as shown in Eq. (2). Moreover, convergence rates for empirical processes on Markov chain sequences are also often\ngiven in terms of mixing coefficients that can ultimately be bounded in terms of \u03c0\u22c6 and \u03b3\u22c6 (as we will show in the proof of our first result). Therefore, valid confidence intervals for \u03c0\u22c6 and \u03b3\u22c6 can be used to make these rates fully observable."}, {"heading": "3. Point estimation", "text": "In this section, we present lower and upper bounds on achievable rates for estimating the spectral gap as a function of the length of the sample path n.\n3.1. Lower bounds. The purpose of this section is to show lower bounds on the number of observations necessary to achieve a fixed multiplicative (or even just additive) accuracy in estimating the spectral gap \u03b3\u22c6. By Eq. (2), the multiplicative accuracy lower bound for \u03b3\u22c6 gives the same lower bound for estimating the mixing time. Our first result holds even for two state Markov chains and shows that a sequence length of \u2126(1/\u03c0\u22c6) is necessary to achieve even a constant additive accuracy in estimating \u03b3\u22c6.\nTheorem 3.1. Pick any \u03c0\u0304 \u2208 (0, 1/4). Consider any estimator \u03b3\u0302\u22c6 that takes as input a random sample path of length n \u2264 1/(4\u03c0\u0304) from a Markov chain starting from any desired initial state distribution. There exists a two-state ergodic and reversible Markov chain distribution with spectral gap \u03b3\u22c6 \u2265 1/2 and minimum stationary probability \u03c0\u22c6 \u2265 \u03c0\u0304 such that\nPr [|\u03b3\u0302\u22c6 \u2212 \u03b3\u22c6| \u2265 1/8] \u2265 3/8. Next, considering d state chains, we show that a sequence of length \u2126(d log(d)/\u03b3\u22c6) is required to estimate \u03b3\u22c6 up to a constant multiplicative accuracy. Essentially, the sequence may have to visit all d states at least log(d)/\u03b3\u22c6 times each, on average. This holds even if \u03c0\u22c6 is within a factor of two of the largest possible value of 1/d that it can take, i.e., when \u03c0 is nearly uniform.\nTheorem 3.2. There is an absolute constant c > 0 such that the following holds. Pick any positive integer d \u2265 3 and any \u03b3\u0304\u22c6 \u2208 (0, 1/2). Consider any estimator \u03b3\u0302\u22c6 that takes as input a random sample path of length n < cd log(d)/\u03b3\u0304\u22c6 from a d-state reversible Markov chain starting from any desired initial state distribution. There is an ergodic and reversible Markov chain distribution with spectral gap \u03b3\u22c6 \u2208 [\u03b3\u0304\u22c6, 2\u03b3\u0304\u22c6] and minimum stationary probability \u03c0\u22c6 \u2265 1/(2d) such that\nPr [|\u03b3\u0302\u22c6 \u2212 \u03b3\u22c6| \u2265 \u03b3\u0304\u22c6/2] \u2265 1/4. The proofs of Theorems 3.1 and 3.2 are given in Section 5.\n3.2. A plug-in based point estimator and its accuracy. Let us now consider the problem of estimating \u03b3\u22c6. For this, we construct a natural plug-in estimator. Along the way, we also provide an estimator for the minimum stationary probability, allowing one to use the bounds from Eq. (2) to trap the mixing time.\nDefine the random matrix M\u0302 \u2208 [0, 1]d\u00d7d and random vector \u03c0\u0302 \u2208 \u2206d\u22121 by\nM\u0302i,j := |{t \u2208 [n\u2212 1] : (Xt, Xt+1) = (i, j)}|\nn\u2212 1 , i, j \u2208 [d] ,\n\u03c0\u0302i := |{t \u2208 [n] : Xt = i}|\nn , i \u2208 [d] .\nFurthermore, define\nSym(L\u0302) := 1\n2 (L\u0302+ L\u0302\n\u22a4\n)\nto be the symmetrized version of the (possibly non-symmetric) matrix\nL\u0302 := Diag(\u03c0\u0302)\u22121/2M\u0302 Diag(\u03c0\u0302)\u22121/2.\nLet \u03bb\u03021 \u2265 \u03bb\u03022 \u2265 \u00b7 \u00b7 \u00b7 \u2265 \u03bb\u0302d be the eigenvalues of Sym(L\u0302). Our estimator of the minimum stationary probability \u03c0\u22c6 is \u03c0\u0302\u22c6 := mini\u2208[d] \u03c0\u0302i, and our estimator of the spectral gap \u03b3\u22c6 is \u03b3\u0302\u22c6 := 1 \u2212min{1,max{\u03bb\u03022, |\u03bb\u0302d|}} \u2208 [0, 1]. The astute reader may notice that our estimator is ill-defined when \u03c0\u0302 is not positive valued. In this case, we can simply set \u03b3\u0302\u22c6 = 0.\nThese estimators have the following accuracy guarantees:\nTheorem 3.3. There exists an absolute constant C \u2265 1 such that the following holds. Let (Xt) n t=1 be an ergodic and reversible Markov chain with spectral gap \u03b3\u22c6 and minimum stationary probability \u03c0\u22c6 > 0. Let \u03c0\u0302\u22c6 = \u03c0\u0302\u22c6((Xt) n t=1) and \u03b3\u0302\u22c6 = \u03b3\u0302\u22c6((Xt) n t=1) be the estimators described above. For any \u03b4 \u2208 (0, 1), with probability at least 1\u2212 \u03b4,\n(4) |\u03c0\u0302\u22c6 \u2212 \u03c0\u22c6| \u2264 C\n  \u221a \u03c0\u22c6 log 1 \u03c0\u22c6\u03b4\n\u03b3\u22c6n + log 1\u03c0\u22c6\u03b4 \u03b3\u22c6n\n \nand\n(5) |\u03b3\u0302\u22c6 \u2212 \u03b3\u22c6| \u2264 C\n\u221a log d\u03b4 \u00b7 log n\u03c0\u22c6\u03b4\n\u03c0\u22c6\u03b3\u22c6n .\nTheorem 3.3 implies that the sequence lengths sufficient to estimate \u03c0\u22c6 and \u03b3\u22c6 to within constant multiplicative factors are, respectively,\nO\u0303\n( 1\n\u03c0\u22c6\u03b3\u22c6\n) and O\u0303 ( 1\n\u03c0\u22c6\u03b33\u22c6\n) .\nThe proof of Theorem 3.3 is based on analyzing the convergence of the sample\naverages M\u0302 and \u03c0\u0302 to their expectation, and then using perturbation bounds for eigenvalues to derive a bound on the error of \u03b3\u0302\u22c6. However, since these averages are formed using a single sample path from a (possibly) non-stationary Markov chain, we cannot use standard large deviation bounds; moreover applying Chernoff-\ntype bounds for Markov chains to each entry of M\u0302 would result in a significantly worse sequence length requirement, roughly a factor of d larger. Instead, we adapt probability tail bounds for sums of independent random matrices (Tropp 2015) to our non-iid setting by directly applying a blocking technique of Bernstein (1927) as described in the article of Yu (1994). Due to ergodicity, the convergence rate can be bounded without any dependence on the initial state distribution \u03c0(1). The proof of Theorem 3.3 is given in Section 6.\n3.3. Improving the plug-in estimator. We can bootstrap the plug-in estimator in Eq. (5) to show that in fact, to obtain any prescribed multiplicative accuracy,\nO\u0303(1/(\u03c0\u22c6\u03b3\u22c6)) steps suffice to estimate \u03b3\u22c6. The idea is to apply the estimator \u03b3\u0302\u22c6 from Eq. (5) to the a-skipped chain (Xas) n/a s=1 for some a \u2265 1. This chain has spectral gap \u03b3\u22c6(a) = 1 \u2212 (1 \u2212 \u03b3\u22c6)a. Thus, letting \u03b3\u0302\u22c6(a) be the plug-in estimator for \u03b3\u22c6(a) based on the a-skipped chain, a natural estimator of \u03b3\u22c6 is 1\u2212 (1\u2212 \u03b3\u0302\u22c6(a))1/a.\nWhy may this improve on the original plug-in estimator from Section 3.2? Observe that \u03b3\u22c6(a) = \u2126(\u03b3\u22c6a) for a \u2264 1/\u03b3\u22c6, so the additive accuracy bound from\nEq. (5) for the plug-in estimator on (Xas) n/a s=1 is roughly the same for all a \u2264 1/\u03b3\u22c6. However, when \u03b3\u22c6(a) is bounded away from 0 and 1, a small additive error in estimating \u03b3\u22c6(a) with \u03b3\u0302\u22c6(a) translates to a small multiplicative error in estimating \u03b3\u22c6 using 1\u2212 (1\u2212 \u03b3\u0302\u22c6(a))1/a. So it suffices to use the skipped chain estimator with some a = O(1/\u03b3\u22c6). Since \u03b3\u22c6 is not known (of course), we use a doubling trick to find a suitable value of a.\nThe estimator is defined as follow. For simplicity, assume n is a power of two. Initially, set k := 0. Let a := 2k and \u03b3\u0302\u22c6(a) := \u03b3\u0302\u22c6((Xas) n/a s=1). If \u03b3\u0302\u22c6(a) > 0.31 or a = n, then set A := a and return \u03b3\u0303\u22c6 := 1\u2212 (1\u2212 \u03b3\u0302\u22c6(A))1/A. Otherwise, increment k by one and repeat.\nTheorem 3.4. There exists a polynomial function L of the logarithms of \u03b3\u22121\u22c6 , \u03c0\u22121\u22c6 , \u03b4\u22121, and d such that the following holds. Let (Xt) n t=1 be an ergodic and reversible Markov chain with spectral gap \u03b3\u22c6 and minimum stationary probability \u03c0\u22c6 > 0. Let \u03b3\u0303\u22c6 = \u03b3\u0303\u22c6((Xt) n t=1) be the estimator defined above. For any \u03b5, \u03b4 \u2208 (0, 1), if n \u2265 L/(\u03c0\u22c6\u03b3\u22c6\u03b52), then with probability at least 1\u2212 \u03b4,\u2223\u2223\u2223\u2223 \u03b3\u0303\u22c6 \u03b3\u22c6 \u2212 1 \u2223\u2223\u2223\u2223 \u2264 \u03b5.\nThe definition of L is in Eq. (34). The proof of Theorem 3.4 is given in Section 7. The result shows that to estimate both \u03c0\u22c6 and \u03b3\u22c6 to within constant multiplicative factors, a single sequence of length O\u0303(1/(\u03c0\u22c6\u03b3\u22c6)) suffices."}, {"heading": "4. A posteriori confidence intervals", "text": "In this section, we describe and analyze a procedure for constructing confidence intervals for the stationary probabilities and the spectral gap \u03b3\u22c6.\n4.1. Procedure. We first note that the point estimators from Theorem 3.3 and Theorem 3.4 fall short of being directly suitable for obtaining a fully empirical, a posteriori confidence interval for \u03b3\u22c6 and \u03c0\u22c6. This is because the deviation terms themselves depend inversely both on \u03b3\u22c6 and \u03c0\u22c6, and hence can never rule out 0 (or an arbitrarily small positive value) as a possibility for \u03b3\u22c6 or \u03c0\u22c6.\n1 In effect, the fact that the Markov chain could be slow mixing and the long-term frequency of some states could be small makes it difficult to be confident in the estimates provided by \u03b3\u0302\u22c6 and \u03c0\u0302\u22c6.\nThe main idea behind our procedure, given as Algorithm 1, is to use the Markov property to eliminate the dependence of the confidence intervals on the unknown quantities (including \u03c0\u22c6 and \u03b3\u22c6). Specifically, we estimate the transition probabilities from the sample path using simple state visit counts: as a consequence of the Markov property, for each state, the frequency estimates converge at a rate that depends only on the number of visits to the state, and in particular the rate (given the visit count of the state) is independent of the mixing time of the chain.\nWith confidence intervals for the entries of P in hand, it is possible to form a confidence interval for \u03b3\u22c6 based on the eigenvalues of an estimated transition probability matrix by appealing to the Ostrowski-Elsner theorem (cf. Theorem 1.4 on Page 170 of Stewart and Sun (1990).) However, directly using this perturbation\n1Using Theorem 3.3, it is possible to trap \u03b3\u22c6 in the union of two empirical confidence intervals\u2014 one around \u03b3\u0302\u22c6 and the other around zero, both of which shrink in width as the sequence length increases.\nAlgorithm 1 Confidence intervals\nInput: Sample path (X1, X2, . . . , Xn), confidence parameter \u03b4 \u2208 (0, 1). 1: Compute state visit counts and smoothed transition probability estimates:\nNi := |{t \u2208 [n\u2212 1] : Xt = i}| , i \u2208 [d]; Ni,j := |{t \u2208 [n\u2212 1] : (Xt, Xt+1) = (i, j)}| , (i, j) \u2208 [d]2;\nP\u0302i,j := Ni,j + 1/d\nNi + 1 , (i, j) \u2208 [d]2.\n2: Let A\u0302# be the group inverse of A\u0302 := I \u2212 P\u0302 . 3: Let \u03c0\u0302 \u2208 \u2206d\u22121 be the unique stationary distribution for P\u0302 . 4: Compute eigenvalues \u03bb\u03021\u2265\u03bb\u03022\u2265 \u00b7 \u00b7 \u00b7 \u2265\u03bb\u0302d of Sym(L\u0302), where L\u0302 :=\nDiag(\u03c0\u0302)1/2P\u0302 Diag(\u03c0\u0302)\u22121/2. 5: Spectral gap estimate:\n\u03b3\u0302\u22c6 := 1\u2212max{\u03bb\u03022, |\u03bb\u0302d|}.\n6: Bounds for |P\u0302i,j\u2212Pi,j | for (i, j) \u2208 [d]2: c := 1.1, \u03c4n,\u03b4 := inf{t \u2265 0 : 2d2(1 + \u2308logc 2nt \u2309+)e\u2212t \u2264 \u03b4}, and\nB\u0302i,j :=   \u221a\nc\u03c4n,\u03b4 2Ni + \u221a\u221a\u221a\u221ac\u03c4n,\u03b4 2Ni + \u221a 2cP\u0302i,j(1\u2212 P\u0302i,j)\u03c4n,\u03b4 Ni + 4 3\u03c4n,\u03b4 + |P\u0302i,j \u2212 1d | Ni   2 .\n7: Relative sensitivity of \u03c0:\n\u03ba\u0302 := 1\n2 max\n{ A\u0302#j,j \u2212min { A\u0302#i,j : i \u2208 [d] } : j \u2208 [d] } .\n8: Bounds for maxi\u2208[d] |\u03c0\u0302i \u2212 \u03c0i| and max \u22c3 i\u2208[d]{| \u221a \u03c0i/\u03c0\u0302i \u2212 1|, | \u221a \u03c0\u0302i/\u03c0i \u2212 1|}:\nb\u0302 := \u03ba\u0302max { B\u0302i,j : (i, j) \u2208 [d]2 } , \u03c1\u0302 := 1\n2 max\n\u22c3\ni\u2208[d]\n{ b\u0302\n\u03c0\u0302i ,\nb\u0302\n[\u03c0\u0302i \u2212 b\u0302]+\n} .\n9: Bounds for |\u03b3\u0302\u22c6 \u2212 \u03b3\u22c6|:\nw\u0302 := 2\u03c1\u0302+ \u03c1\u03022 + (1 + 2\u03c1\u0302+ \u03c1\u03022)\n( \u2211\n(i,j)\u2208[d]2\n\u03c0\u0302i \u03c0\u0302j B\u03022i,j\n)1/2 .\nresult leads to very wide intervals, shrinking only at a rate of O(n\u22121/(2d)). We avoid this slow rate by constructing confidence intervals for the symmetric matrix L, so that we can use a stronger perturbation result (namely Weyl\u2019s inequality, as in the proof of Theorem 3.3) available for symmetric matrices.\nTo form an estimate of L based on an estimate of the transition probabilities, one possibility is to estimate \u03c0 using state visit counts as was done in Section 3, and appeal to the relation L = Diag(\u03c0)1/2P Diag(\u03c0)\u22121/2 to form a plug-in estimate of L. However, it is not clear how to construct a confidence interval for the entries of \u03c0 because the accuracy of this estimator depends on the unknown mixing time.\nWe adopt a different strategy for estimating \u03c0. We form the matrix P\u0302 using smoothed frequency estimates of P (Step 1), then compute the group inverse A\u0302# of A\u0302 = I \u2212 P\u0302 (Step 2), followed by finding the unique stationary distribution \u03c0\u0302 of P\u0302 (Step 3), this way decoupling the bound on the accuracy of \u03c0\u0302 from the mixing time. The group inverse A\u0302# of A\u0302 is uniquely defined; and if P\u0302 defines an ergodic chain (which is the case here due to the use of the smoothed estimates), A\u0302# can be computed at the cost of inverting an (d\u22121)\u00d7(d\u22121) matrix (Meyer Jr. 1975, Theorem 5.2).2 Further, given A\u0302#, the unique stationary distribution \u03c0\u0302 of P\u0302 can be read out from the last row of A\u0302# (Meyer Jr. 1975, Theorem 5.3). The\ngroup inverse is also used to determine the relative sensitivity of \u03c0\u0302 to P\u0302 , which is quantified by\n(6) \u03ba\u0302 := 1\n2 max\n{ A\u0302#j,j \u2212min { A\u0302#i,j : i \u2208 [d] } : j \u2208 [d] } .\nWe can regard \u03ba\u0302 as a plug-in estimator for \u03ba, which is defined by substituting the group inverse A# of A in for A\u0302 #\nin Eq. (6). We can now follow the strategy based on estimating L alluded to above. Using\n\u03c0\u0302 and P\u0302 , we construct the plug-in estimate L\u0302 of L, and use the eigenvalues of its symmetrization to form the estimate \u03b3\u0302\u22c6 of the spectral gap (Steps 4 and 5). In the remaining steps, we use matrix perturbation analyses to relate \u03c0\u0302 and \u03c0, viewing P\nas the perturbation of P\u0302 ; and also to relate \u03b3\u0302\u22c6 and \u03b3\u22c6, viewingL as a perturbation of Sym(L\u0302). Both analyses give error bounds entirely in terms of observable quantities (e.g., \u03ba\u0302), tracing back to empirical error bounds for the estimate of P .\nThe most computationally expensive step in Algorithm 1 is the computation of the group inverse A\u0302#, which, as noted earlier, reduces to matrix inversion. Thus, with a standard implementation of matrix inversion, the algorithm\u2019s time complexity is O(n+ d3), while its space complexity is O(d2).\n4.2. Main result. We now state our main theorems. Below, the big-O notation should be interpreted as follows. For a random sequence (Yn)n\u22651 and a (nonrandom) positive sequence (\u03b5\u03b8,n)n\u22651 parameterized by \u03b8, we say \u201cYn = O(\u03b5\u03b8,n) holds almost surely as n \u2192 \u221e\u201d if there is some universal constant C > 0 such that for all \u03b8, lim supn\u2192\u221e Yn/\u03b5\u03b8,n \u2264 C holds almost surely.\nTheorem 4.1. Suppose Algorithm 1 is given as input a sample path of length n from an ergodic and reversible Markov chain and confidence parameter \u03b4 \u2208 (0, 1). Let \u03b3\u22c6 > 0 denote the spectral gap, \u03c0 the unique stationary distribution, and \u03c0\u22c6 > 0 the minimum stationary probability. Then, on an event of probability at least 1\u2212 \u03b4,\n\u03c0i \u2208 [\u03c0\u0302i \u2212 b\u0302, \u03c0\u0302i + b\u0302] for all i \u2208 [d], and \u03b3\u22c6 \u2208 [\u03b3\u0302\u22c6 \u2212 w\u0302, \u03b3\u0302\u22c6 + w\u0302]. Moreover,\nb\u0302 = O ( max\n(i,j)\u2208[d]2 \u03ba\n\u221a Pi,j log logn\n\u03c0in\n) , w\u0302 = O ( \u03ba\n\u03c0\u22c6\n\u221a log log n\n\u03c0\u22c6n +\n\u221a d log logn\n\u03c0\u22c6n\n)\nalmost surely as n \u2192 \u221e.\n2 The group inverse of a square matrix A, a special case of the Drazin inverse, is the unique matrix A# satisfying AA#A = A, A#AA# = A# and A#A = AA#.\nThe proof of Theorem 4.1 is given in Section 8. As mentioned above, the obstacle encountered in Theorem 3.3 is avoided by exploiting the Markov property. We establish fully observable upper and lower bounds on the entries of P that converge at a \u221a (log logn)/n rate using standard martingale tail inequalities; this justifies the validity of the bounds from Step 6. Properties of the group inverse (Meyer Jr. 1975; Cho and Meyer 2001) and eigenvalue perturbation theory (Stewart and Sun 1990) are used to validate the empirical bounds on \u03c0i and \u03b3\u22c6 developed in the remaining steps of the algorithm.\nThe first part of Theorem 4.1 provides valid empirical confidence intervals for each \u03c0i and for \u03b3\u22c6, which are simultaneously valid at confidence level \u03b4. The second part of Theorem 4.1 shows that the width of the intervals decrease as the sequence length increases. The rate at which the widths shrink is given in terms of P , \u03c0, \u03ba, and n. We show in Section 8.5 (Lemma 8.8) that\n\u03ba \u2264 1 \u03b3\u22c6 min{d, 8 + log(4/\u03c0\u22c6)},\nand hence\nb\u0302 = O ( max\n(i,j)\u2208[d]2 min{d, log(1/\u03c0\u22c6)} \u03b3\u22c6\n\u221a Pi,j log logn\n\u03c0in\n) ,\nw\u0302 = O\n( min{d, log(1/\u03c0\u22c6)}\n\u03c0\u22c6\u03b3\u22c6\n\u221a log logn\n\u03c0\u22c6n\n) .\nIt is easy to combine Theorems 3.3 and 4.1 to yield intervals whose widths shrink at least as fast as both the non-empirical intervals from Theorem 3.3 and the empirical intervals from Theorem 4.1. Specifically, determine lower bounds on \u03c0\u22c6 and \u03b3\u22c6 using Algorithm 1, \u03c0\u22c6 \u2265 mini\u2208[d][\u03c0\u0302i \u2212 b\u0302]+ , \u03b3\u22c6 \u2265 [\u03b3\u0302\u22c6 \u2212 w\u0302]+; then plug-in these lower bounds for \u03c0\u22c6 and \u03b3\u22c6 in the deviation bounds in Eq. (5) from Theorem 3.3. This yields a new interval centered around the estimate of \u03b3\u22c6 from Theorem 3.3 and the new interval no longer depends on unknown quantities. The interval is a valid 1 \u2212 2\u03b4 probability confidence interval for \u03b3\u22c6, and for sufficiently large n, the width shrinks at the rate given in Eq. (5). We can similarly construct an empirical confidence interval for \u03c0\u22c6 using Eq. (4), which is valid on the same 1\u2212 2\u03b4 probability event.3 Finally, we can take the intersection of these new intervals with the corresponding intervals from Algorithm 1. This is summarized in the following theorem, which we prove in Section 9.\nTheorem 4.2. The following holds under the same conditions as Theorem 4.1. For any \u03b4 \u2208 (0, 1), the confidence intervals U\u0302 and V\u0302 described above for \u03c0\u22c6 and \u03b3\u22c6, respectively, satisfy \u03c0\u22c6 \u2208 U\u0302 and \u03b3\u22c6 \u2208 V\u0302 with probability at least 1\u22122\u03b4. Furthermore,\n|U\u0302 | = O (\u221a \u03c0\u22c6 log d \u03c0\u22c6\u03b4\n\u03b3\u22c6n\n) and |V\u0302 | = O ( min {\u221a log d \u03b4 \u00b7log(n)\n\u03c0\u22c6\u03b3\u22c6n , w\u0302\n}) almost surely as\nn \u2192 \u221e, where w\u0302 is the width from Algorithm 1. Finally, note that a stopping rule that stops when \u03b3\u22c6 and \u03c0\u22c6 are estimated with a given relative error \u01eb can be obtained as follows. At time n:\n3For the \u03c0\u22c6 interval, we only plug-in lower bounds on \u03c0\u22c6 and \u03b3\u22c6 only where these quantities appear as 1/\u03c0\u22c6 and 1/\u03b3\u22c6 in Eq. (4). It is then possible to \u201csolve\u201d for observable bounds on \u03c0\u22c6. See Section 9 for details.\n1: if n = 2k for an integer k then 2: Run Algorithm 1 (or the improved variant from Theorem 4.2) with inputs (X1, X2, . . . , Xn) and \u03b4/(k(k + 1)) to obtain intervals for \u03c0\u22c6 and \u03b3\u22c6. 3: Stop if, for each interval, the interval width divided by the lower bound on estimated quantity falls below \u01eb. 4: end if It is easy to see then that with probability 1\u2212 \u03b4, the algorithm only stops when the relative accuracy of its estimate is at least \u01eb. Combined with the lower bounds, we conjecture that the expected stopping time of the resulting procedure is optimal up to log factors."}, {"heading": "5. Proofs of Theorems 3.1 and 3.2", "text": "In this section, we prove Theorem 3.1 and Theorem 3.2.\n5.1. Proof of Theorem 3.1. Fix \u03c0\u0304 \u2208 (0, 1/4). Consider two Markov chains given by the following stochastic matrices:\nP (1) := [ 1\u2212 \u03c0\u0304 \u03c0\u0304 1\u2212 \u03c0\u0304 \u03c0\u0304 ] , P (2) := [ 1\u2212 \u03c0\u0304 \u03c0\u0304 1/2 1/2 ] .\nEach Markov chain is ergodic and reversible; their stationary distributions are, respectively, \u03c0(1) = (1 \u2212 \u03c0\u0304, \u03c0\u0304) and \u03c0(2) = (1/(1 + 2\u03c0\u0304), 2\u03c0\u0304/(1 + 2\u03c0\u0304)). We have \u03c0\u22c6 \u2265 \u03c0\u0304 in both cases. For the first Markov chain, \u03bb\u22c6 = 0, and hence the spectral gap is 1; for the second Markov chain, \u03bb\u22c6 = 1/2\u2212 \u03c0\u0304, so the spectral gap is 1/2+ \u03c0\u0304.\nIn order to guarantee |\u03b3\u0302\u22c6 \u2212 \u03b3\u22c6| < 1/8 < |1\u2212 (1/2+ \u03c0\u0304)|/2, it must be possible to distinguish the two Markov chains. Assume that the initial state distribution has mass at least 1/2 on state 1. (If this is not the case, we swap the roles of states 1 and 2 in the constructions above.) With probability at least half, the initial state is 1; and both chains have the same transition probabilities from state 1. The chains are indistinguishable unless the sample path eventually reaches state 2. But with probability at least 3/4, a sample path of length n < 1/(4\u03c0\u0304) starting from state 1 always remains in the same state (this follows from properties of the geometric distribution and the assumption \u03c0\u0304 < 1/4).\n5.2. Proof of Theorem 3.2. We consider d-state Markov chains of the following form:\nPi,j = { 1\u2212 \u03b5i if i = j; \u03b5i\nd\u2212 1 if i 6= j\nfor some \u03b51, \u03b52, . . . , \u03b5d \u2208 (0, 1). Such a chain is ergodic and reversible, and its unique stationary distribution \u03c0 satisfies\n\u03c0i = 1/\u03b5i\u2211d j=1 1/\u03b5j .\nWe fix \u03b5 := d\u22121d/2 \u03b3\u0304 and set \u03b5 \u2032 := d/2\u22121d\u22121 \u03b5 < \u03b5. Consider the following d + 1 different Markov chains of the type described above:\n\u2022 P (0): \u03b51 = \u00b7 \u00b7 \u00b7 = \u03b5d = \u03b5. For this Markov chain, \u03bb2 = \u03bbd = \u03bb\u22c6 = 1\u2212 dd\u22121\u03b5. \u2022 P (i) for i \u2208 [d]: \u03b5j = \u03b5 for j 6= i, and \u03b5i = \u03b5\u2032. For these Markov chains, \u03bb2 = 1\u2212 \u03b5\u2032 \u2212 1d\u22121\u03b5 = 1\u2212 d/2 d\u22121\u03b5, and \u03bbd = 1\u2212 dd\u22121\u03b5. So \u03bb\u22c6 = 1\u2212 d/2 d\u22121\u03b5.\nThe spectral gap in each chain satisfies \u03b3\u22c6 \u2208 [\u03b3\u0304, 2\u03b3\u0304]; in P (i) for i \u2208 [d], it is half of what it is in P (0). Also \u03c0i \u2265 1/(2d) for each i \u2208 [d].\nIn order to guarantee |\u03b3\u0302\u22c6\u2212\u03b3\u22c6| < \u03b3\u0304/2, it must be possible to distinguish P (0) from each P (i), i \u2208 [d]. But P (0) is identical to P (i) except for the transition probabilities from state i. Therefore, regardless of the initial state, the sample path must visit all states in order to distinguish P (0) from each P (i), i \u2208 [d]. For any of the d+ 1 Markov chains above, the earliest time in which a sample path visits all d states stochastically dominates a generalized coupon collection time T = 1 + \u2211d\u22121\ni=1 Ti, where Ti is the number of steps required to see the (i + 1)-th distinct state in the sample path beyond the first i. The random variables T1, T2, . . . , Td\u22121 are independent, and are geometrically distributed, Ti \u223c Geom(\u03b5 \u2212 (i \u2212 1)\u03b5/(d \u2212 1)). We have that\nE[Ti] = d\u2212 1 \u03b5(d\u2212 i) , var(Ti) = 1\u2212 \u03b5 d\u2212id\u22121( \u03b5 d\u2212id\u22121 )2 .\nTherefore\nE[T ] = 1 + d\u2212 1 \u03b5 Hd\u22121, var(T ) \u2264 ( d\u2212 1 \u03b5 )2 \u03c02 6\nwhere Hd\u22121 = 1 + 1/2 + 1/3 + \u00b7 \u00b7 \u00b7+ 1/(d\u2212 1). By the Paley-Zygmund inequality,\nPr ( T > 1\n3 E[T ]\n) \u2265 1\n1 + var(T )(1\u22121/3)2E[T ]2 \u2265 1 1 + ( d\u22121\u03b5 ) 2 \u03c02 6\n(4/9)( d\u22121\u03b5 H2) 2\n\u2265 1 4 .\nSince n < cd log(d)/\u03b3\u0304 \u2264 (1/3)(1 + (d\u2212 1)Hd\u22121/(2\u03b3\u0304)) = E[T ]/3 (for an appropriate absolute constant c), with probability at least 1/4, the sample path does not visit all d states."}, {"heading": "6. Proof of Theorem 3.3", "text": "In this section, we prove Theorem 3.3.\n6.1. Accuracy of \u03c0\u0302\u22c6. We start by proving the deviation bound on \u03c0\u22c6 \u2212 \u03c0\u0302\u22c6, from which we may easily deduce Eq. (4) in Theorem 3.3.\nLemma 6.1. Pick any \u03b4 \u2208 (0, 1), and let (7) \u03b5n := ln ( d \u03b4 \u221a 2 \u03c0\u22c6 )\n\u03b3\u22c6n .\nWith probability at least 1\u2212 \u03b4, the following inequalities hold simultaneously: |\u03c0\u0302i \u2212 \u03c0i| \u2264 \u221a 8\u03c0i(1\u2212 \u03c0i)\u03b5n + 20\u03b5n for all i \u2208 [d];(8) |\u03c0\u0302\u22c6 \u2212 \u03c0\u22c6| \u2264 4 \u221a \u03c0\u22c6\u03b5n + 47\u03b5n.(9)\nProof. We use the following Bernstein-type inequality for Markov chains of Paulin (2015, Theorem 3.3): letting P\u03c0 denote the probability with respect to the stationary chain (where the marginal distribution of each Xt is \u03c0), we have for every \u01eb > 0,\nP \u03c0 (|\u03c0\u0302i \u2212 \u03c0i| > \u01eb) \u2264 2 exp ( \u2212 n\u03b3\u22c6\u01eb 2\n4\u03c0i(1\u2212 \u03c0i) + 10\u01eb\n) , i \u2208 [d].\nTo handle possibly non-stationary chains, as is our case, we combine the above inequality with Paulin (2015, Proposition 3.10), to obtain for any \u01eb > 0,\nP (|\u03c0\u0302i \u2212 \u03c0i| > \u01eb) \u2264 \u221a 1\n\u03c0\u22c6 P\u03c0 (|\u03c0\u0302i \u2212 \u03c0i| > \u01eb) \u2264\n\u221a 2\n\u03c0\u22c6 exp\n( \u2212 n\u03b3\u22c6\u01eb 2\n8\u03c0i(1\u2212 \u03c0i) + 20\u01eb\n) .\nUsing this tail inequality with \u01eb := \u221a 8\u03c0i(1\u2212 \u03c0i)\u03b5n +20\u03b5n and a union bound over all i \u2208 [d] implies that the inequalities in Eq. (8) hold with probability at least 1\u2212\u03b4. Now assume this 1\u2212 \u03b4 probability event holds; it remains to prove that Eq. (9) also holds in this event. Without loss of generality, we assume that \u03c0\u22c6 = \u03c01 \u2264 \u03c02 \u2264 \u00b7 \u00b7 \u00b7 \u2264 \u03c0d. Let j \u2208 [d] be such that \u03c0\u0302\u22c6 = \u03c0\u0302j . By Eq. (8), we have |\u03c0i \u2212 \u03c0\u0302i| \u2264\u221a 8\u03c0i\u03b5n + 20\u03b5n for each i \u2208 {1, j}. Since \u03c0\u0302\u22c6 \u2264 \u03c0\u03021,\n\u03c0\u0302\u22c6 \u2212 \u03c0\u22c6 \u2264 \u03c0\u03021 \u2212 \u03c01 \u2264 \u221a 8\u03c0\u22c6\u03b5n + 20\u03b5n \u2264 \u03c0\u22c6 + 22\u03b5n\nwhere the last inequality follows by the AM/GM inequality. Furthermore, using the fact that a \u2264 b\u221aa+ c \u21d2 a \u2264 b2 + b\u221ac+ c for nonnegative numbers a, b, c \u2265 0 (see, e.g., Bousquet, Boucheron, and Lugosi 2004) with the inequality \u03c0j \u2264 \u221a 8\u03b5n \u221a \u03c0j + (\u03c0\u0302j + 20\u03b5n) gives\n\u03c0j \u2264 \u03c0\u0302j + \u221a 8(\u03c0\u0302j + 20\u03b5n)\u03b5n + 28\u03b5n.\nTherefore \u03c0\u22c6\u2212\u03c0\u0302\u22c6 \u2264 \u03c0j\u2212\u03c0\u0302j \u2264 \u221a 8(\u03c0\u0302\u22c6 + 20\u03b5n)\u03b5n+28\u03b5n \u2264 \u221a 8(2\u03c0\u22c6 + 42\u03b5n)\u03b5n+28\u03b5n \u2264 4 \u221a \u03c0\u22c6\u03b5n+47\u03b5n\nwhere the second-to-last inequality follows from the above bound on \u03c0\u0302\u22c6 \u2212 \u03c0\u22c6, and the last inequality uses \u221a a+ b \u2264 \u221aa+ \u221a b for nonnegative a, b \u2265 0.\n6.2. Accuracy of \u03b3\u0302\u22c6. Let us now turn to proving Eq. (5), i.e., the bound on the error of the spectral gap estimate \u03b3\u0302\u22c6. The accuracy of \u03b3\u0302\u22c6 is based on the accuracy of Sym(L\u0302) in approximating L via Weyl\u2019s inequality:\n|\u03bb\u0302i \u2212 \u03bbi| \u2264 \u2016 Sym(L\u0302)\u2212L\u2016 for all i \u2208 [d].\nMoreover, the triangle inequality implies that symmetrizing L\u0302 can only help:\n\u2016 Sym(L\u0302)\u2212L\u2016 \u2264 \u2016L\u0302\u2212L\u2016.\nTherefore, we can deduce Eq. (5) in Theorem 3.3 from the following lemma.\nLemma 6.2. There exists an absolute constant C > 0 such that the following holds. For any \u03b4 \u2208 (0, 1), if (10) n \u2265 C ( log 1\u03c0\u22c6\u03b4 \u03c0\u22c6\u03b3\u22c6 + logn \u03b3\u22c6 ) ,\nthen with probability at least 1\u2212 \u03b4, the bounds from Lemma 6.1 hold, and\n\u2016L\u0302\u2212L\u2016 \u2264 C (\u221a \u03b5+ \u03b5+ \u03b52 ) ,\nwhere\n\u03b5 :=\n( log d\u03b4 )( log n\u03c0\u22c6\u03b4 )\n\u03c0\u22c6\u03b3\u22c6n .\nWe briefly describe how to obtain the bound on |\u03b3\u0302\u22c6 \u2212 \u03b3\u22c6| that appears in Eq. (5), which is of the form C\u2032 \u221a \u03b5. Observe that if \u03b5 > 1/C\u2032, then, owing to C\u2032 \u2265 1, the bound on |\u03b3\u0302\u22c6 \u2212 \u03b3\u22c6| is trivial. So we may assume that \u03b5 \u2264 1/C\u2032, which implies n/ logn \u2265 C\u2032(log(d/\u03b4))/(\u03c0\u22c6\u03b3\u22c6) (and thus n \u2265 2), and also n \u2265 C\u2032(log(d/\u03b4))(log(1/(\u03c0\u22c6\u03b4)))/(\u03c0\u22c6\u03b3\u22c6). These inequalities imply that n satisfies the condition in Eq. (10), so by Lemma 6.2, we have |\u03b3\u0302\u22c6 \u2212 \u03b3\u22c6| \u2264 \u2016L\u0302 \u2212 L\u2016 \u2264 C( \u221a \u03b5+ \u03b5+ \u03b52) \u2264 C\u2032\u221a\u03b5.\nThe remainder of this section is devoted to proving this lemma. When \u03c0\u0302 is positive valued, the error L\u0302\u2212L may be written as L\u0302\u2212L = EM + E\u03c0L+LE\u03c0 + E\u03c0LE\u03c0 + E\u03c0EM + EME\u03c0 + E\u03c0EME\u03c0 ,\nwhere\nE\u03c0 := Diag(\u03c0\u0302) \u22121/2 Diag(\u03c0)1/2 \u2212 I and\nEM := Diag(\u03c0) \u22121/2 ( M\u0302 \u2212M ) Diag(\u03c0)\u22121/2 .\nTherefore\n\u2016L\u0302\u2212L\u2016 \u2264 \u2016EM\u2016+ (\u2016EM\u2016+ \u2016L\u2016) ( 2\u2016E\u03c0\u2016+ \u2016E\u03c0\u20162 ) .\nIf \u2016E\u03c0\u2016 \u2264 1 also holds, then, thanks to \u2016L\u2016 \u2264 1, \u2016L\u0302\u2212L\u2016 \u2264 \u2016EM\u2016+ \u2016EM\u20162 + 3\u2016E\u03c0\u2016.(11)\n6.3. A bound on \u2016E\u03c0\u2016. Since E\u03c0 is diagonal,\n\u2016E\u03c0\u2016 = max i\u2208[d]\n\u2223\u2223\u2223\u2223 \u221a\n\u03c0i \u03c0\u0302i\n\u2212 1 \u2223\u2223\u2223\u2223 .\nAssume that\n(12) n \u2265 108 ln\n( d \u03b4 \u221a 2 \u03c0\u22c6 )\n\u03c0\u22c6\u03b3\u22c6 ,\nin which case \u221a 8\u03c0i(1\u2212 \u03c0i)\u03b5n + 20\u03b5n \u2264\n\u03c0i 2 ,\nwhere \u03b5n is as defined in Eq. (7). Therefore, on the 1 \u2212 \u03b4 probability event from Lemma 6.1, we have |\u03c0i\u2212 \u03c0\u0302i| \u2264 \u03c0i/2 for each i \u2208 [d], and moreover, 2/3 \u2264 \u03c0i/\u03c0\u0302i \u2264 2 for each i \u2208 [d]. In particular, it also holds that \u03c0\u0302 is positive valued. Further, for this range of \u03c0i/\u03c0\u0302i, we have \u2223\u2223\u2223\u2223 \u221a \u03c0i \u03c0\u0302i \u2212 1 \u2223\u2223\u2223\u2223 \u2264 \u2223\u2223\u2223\u2223 \u03c0\u0302i \u03c0i \u2212 1 \u2223\u2223\u2223\u2223 . We conclude that if n satisfies Eq. (12), then on this 1 \u2212 \u03b4 probability event from Lemma 6.1, \u03c0\u0302 is positive valued and\n(13) \u2016E\u03c0\u2016 \u2264 max i\u2208[d] \u2223\u2223\u2223\u2223 \u03c0\u0302i \u03c0i \u2212 1 \u2223\u2223\u2223\u2223 \u2264 maxi\u2208[d] \u221a 8\u03c0i(1\u2212 \u03c0i)\u03b5n + 20\u03b5n \u03c0i\n\u2264 \u221a\n8\u03b5n \u03c0\u22c6 + 20\u03b5n \u03c0\u22c6 =\n\u221a\u221a\u221a\u221a8 ln ( d \u03b4 \u221a 2 \u03c0\u22c6 )\n\u03c0\u22c6\u03b3\u22c6n +\n20 ln (\nd \u03b4 \u221a 2 \u03c0\u22c6 )\n\u03c0\u22c6\u03b3\u22c6n \u2264 min{C\u2032(\n\u221a \u03b5+ \u03b5), 1}\nfor some suitable constant C\u2032 > 0, where \u03b5 as defined in Lemma 6.2.\n6.4. Accuracy of doublet frequency estimates (bounding \u2016EM\u2016). In this section we prove a bound on \u2016EM\u2016. For this, we decompose EM = Diag(\u03c0)\u22121/2(M\u0302\u2212 M)Diag(\u03c0)\u22121/2 into E (EM ) and EM \u2212 E (EM ), the first measuring the effect of a non-stationary start of the chain, while the second measuring the variation due to randomness.\n6.4.1. Bounding \u2016E (EM ) \u2016: The price of a non-stationary start. Let \u03c0(t) be the distribution of states at time step t. We will make use of the following proposition, which can be derived by following Montenegro and Tetali (2006, Proposition 1.12):\nProposition 6.3. For t \u2265 1, let \u03a5(t) be the vector with \u03a5(t)i = \u03c0 (t) i \u03c0i and let \u2016 \u00b7 \u20162,\u03c0 denote the \u03c0-weighted 2-norm\n\u2016v\u20162,\u03c0 := ( d\u2211\ni=1\n\u03c0iv 2 i\n)1/2 .(14)\nThen,\n(15) \u2016\u03a5(t) \u2212 1\u20162,\u03c0 \u2264 (1 \u2212 \u03b3\u22c6)t\u22121\u221a\n\u03c0\u22c6 .\nAn immediate corollary of this result is that \u2225\u2225\u2225Diag(\u03c0(t))Diag(\u03c0)\u22121 \u2212 I \u2225\u2225\u2225 \u2264 (1\u2212 \u03b3\u22c6) t\u22121\n\u03c0\u22c6 .(16)\nNow note that\nE(M\u0302 ) = 1\nn\u2212 1\nn\u22121\u2211\nt=1\nDiag(\u03c0(t))P\nand thus\nE (EM ) = Diag(\u03c0) \u22121/2 ( E(M\u0302 )\u2212M ) Diag(\u03c0)\u22121/2\n= 1\nn\u2212 1\nn\u22121\u2211\nt=1\nDiag(\u03c0)\u22121/2(Diag(\u03c0(t))\u2212Diag(\u03c0))P Diag(\u03c0)\u22121/2\n= 1\nn\u2212 1\nn\u22121\u2211\nt=1\nDiag(\u03c0)\u22121/2(Diag(\u03c0(t))Diag(\u03c0)\u22121 \u2212 I)M Diag(\u03c0)\u22121/2\n= 1\nn\u2212 1\nn\u22121\u2211\nt=1\n(Diag(\u03c0(t))Diag(\u03c0)\u22121 \u2212 I)L .\nCombining this, \u2016L\u2016 \u2264 1 and Eq. (16), we get\n\u2016E(EM )\u2016 \u2264 1\n(n\u2212 1)\u03c0\u22c6\nn\u22121\u2211\nt=1\n(1\u2212 \u03b3\u22c6)t\u22121 \u2264 1\n(n\u2212 1)\u03b3\u22c6\u03c0\u22c6 .(17)\n6.4.2. Bounding \u2016EM \u2212 E (EM ) \u2016: Application of a matrix tail inequality. In this section we analyze the deviations of EM \u2212 E (EM ). By the definition of EM ,\n\u2016EM \u2212 E (EM ) \u2016 = \u2016Diag(\u03c0)\u22121/2 ( M\u0302 \u2212 EM\u0302 ) Diag(\u03c0)\u22121/2\u2016 .(18)\nThe matrix M\u0302\u2212E ( M\u0302 ) is defined as a sum of dependent centered randommatrices.\nWe will use the blocking technique of Bernstein (1927) to relate the likely deviations of this matrix to that of a sum of independent centered random matrices. The deviations of these will then bounded with the help of a Bernstein-type matrix tail inequality due to Tropp (2015).\nWe divide [n \u2212 1] into contiguous blocks of time steps; each has size a \u2264 n/3 except possibly the first block, which has size between a and 2a\u2212 1. Formally, let a\u2032 := a+ ((n\u2212 1) mod a) \u2264 2a\u2212 1, and define\nF := [a\u2032],\nHs := {t \u2208 [n\u2212 1] : a\u2032 + 2(s\u2212 1)a+ 1 \u2264 t \u2264 a\u2032 + (2s\u2212 1)a}, Ts := {t \u2208 [n\u2212 1] : a\u2032 + (2s\u2212 1)a+ 1 \u2264 t \u2264 a\u2032 + 2sa},\nfor s = 1, 2, . . . . Let \u00b5H (resp., \u00b5T ) be the number of non-empty Hs (resp., Ts) blocks. Let nH := a\u00b5H (resp., nT := a\u00b5T ) be the number of time steps in \u222asHs (resp., \u222asTs). We have\nM\u0302 = 1\nn\u2212 1\nn\u22121\u2211\nt=1\neXte \u22a4\nXt+1\n= a\u2032 n\u2212 1 \u00b7 1 a\u2032\n\u2211\nt\u2208F\neXte \u22a4\nXt+1\n\ufe38 \ufe37\ufe37 \ufe38 M\u0302F\n+ nH n\u2212 1 \u00b7 1\n\u00b5H\n\u00b5H\u2211\ns=1\n( 1\na\n\u2211\nt\u2208Hs\neXte \u22a4\nXt+1\n)\n\ufe38 \ufe37\ufe37 \ufe38 M\u0302H\n+ nT n\u2212 1 \u00b7 1\n\u00b5T\n\u00b5T\u2211\ns=1\n( 1\na\n\u2211\nt\u2208Ts\neXte \u22a4\nXt+1\n)\n\ufe38 \ufe37\ufe37 \ufe38 M\u0302T\n.(19)\nHere, ei is the i-th coordinate basis vector, so eie \u22a4 j \u2208 {0, 1}d\u00d7d is a d\u00d7 d matrix of all zeros except for a 1 in the (i, j)-th position.\nThe contribution of the first block is easily bounded using the triangle inequality:\n(20) a\u2032 n\u2212 1 \u2225\u2225\u2225Diag(\u03c0)\u22121/2 ( M\u0302F \u2212 E(M\u0302F ) ) Diag(\u03c0)\u22121/2 \u2225\u2225\u2225\n\u2264 1 n\u2212 1\n\u2211\nt\u2208F\n{\u2225\u2225\u2225\u2225\u2225 eXte \u22a4 Xt+1\u221a \u03c0Xt\u03c0Xt+1 \u2225\u2225\u2225\u2225\u2225+ \u2225\u2225\u2225\u2225\u2225E ( eXte \u22a4 Xt+1\u221a \u03c0Xt\u03c0Xt+1 )\u2225\u2225\u2225\u2225\u2225 } \u2264 2a \u2032 \u03c0\u22c6(n\u2212 1) .\nIt remains to bound the contributions of the Hs blocks and the Ts blocks. We just focus on the the Hs blocks, since the analysis is identical for the Ts blocks.\nLet\nY s := 1\na\n\u2211\nt\u2208Hs\neXte \u22a4 Xt+1 , s \u2208 [\u00b5H ],\nso\nM\u0302H = 1\n\u00b5H\n\u00b5H\u2211\ns=1\nY s,\nan average of the random matrices Y s. For each s \u2208 [\u00b5H ], the random matrix Y s is a function of\n(Xt : a \u2032 + 2(s\u2212 1)a+ 1 \u2264 t \u2264 a\u2032 + (2s\u2212 1)a+ 1)\n(note the +1 in the upper limit of t), so Y s+1 is a time steps ahead of Y s. When a is sufficiently large, we will be able to effectively treat the random matrices Y s as if they were independent. In the sequel, we shall always assume that the block length a satisfies\n(21) a \u2265 a\u03b4 := 1\n\u03b3\u22c6 ln 2(n\u2212 2) \u03b4\u03c0\u22c6\nfor \u03b4 \u2208 (0, 1). Define\n\u03c0(Hs) := 1\na\n\u2211\nt\u2208Hs\n\u03c0(t), \u03c0(H) := 1\n\u00b5H\n\u00b5H\u2211\ns=1\n\u03c0(Hs).\nObserve that\nE(Y s) = Diag(\u03c0 (Hs))P\nso\nE\n( 1\n\u00b5H\n\u00b5H\u2211\ns=1\nY s\n) = Diag(\u03c0(H))P .\nDefine\nZs := Diag(\u03c0) \u22121/2 (Y s \u2212 E(Y s)) Diag(\u03c0)\u22121/2.\nWe apply a matrix tail inequality to the average of independent copies of the Zs\u2019s. More precisely, we will apply the tail inequality to independent copies Z\u0303s, s \u2208 [\u00b5H ] of the random variables Zs and then relate the average of Z\u0303s to that of Zs. The following probability inequality is from Tropp (2015, Theorem 6.1.1.).\nTheorem 6.4 (Matrix Bernstein inequality). Let Q1,Q2, . . . ,Qm be a sequence of independent, random d1 \u00d7 d2 matrices. Assume that E (Qi) = 0 and \u2016Qi\u2016 \u2264 R for each 1 \u2264 i \u2264 m. Let S = \u2211mi=1 Qi and let\nv = max { \u2016E\u2211i QiQ\u22a4i \u2016, \u2016E \u2211 iQ \u22a4 i Qi\u2016 } .\nThen, for all t \u2265 0,\nP (\u2016S\u2016 \u2265 t) \u2264 2(d1 + d2) exp ( \u2212 t 2/2\nv +Rt/3\n) .\nIn other words, for any \u03b4 \u2208 (0, 1),\nP ( \u2016S\u2016 > \u221a 2v ln 2(d1 + d2)\n\u03b4 +\n2R\n3 ln\n2(d1 + d2)\n\u03b4\n) \u2264 \u03b4 .\nTo apply Theorem 6.4, it suffices to bound the spectral norms of Zs (almost surely), E(ZsZ \u22a4 s ), and E(Z \u22a4 s Zs).\nRange bound. By the triangle inequality,\n\u2016Zs\u2016 \u2264 \u2016Diag(\u03c0)\u22121/2Y s Diag(\u03c0)\u22121/2\u2016+ \u2016Diag(\u03c0)\u22121/2E(Y s)Diag(\u03c0)\u22121/2\u2016 . For the first term, we have\n\u2016Diag(\u03c0)\u22121/2Y s Diag(\u03c0)\u22121/2\u2016 \u2264 1\n\u03c0\u22c6 .(22)\nFor the second term, we use the fact \u2016L\u2016 \u2264 1 to bound\n\u2016Diag(\u03c0)\u22121/2(E(Y s)\u2212M)Diag(\u03c0)\u22121/2\u2016 = \u2016 ( Diag(\u03c0(Hs))Diag(\u03c0)\u22121 \u2212 I ) L\u2016\n\u2264 \u2016Diag(\u03c0(Hs))Diag(\u03c0)\u22121 \u2212 I\u2016 .\nThen, using Eq. (16),\n(23) \u2016Diag(\u03c0(Hs))Diag(\u03c0)\u22121 \u2212 I\u2016 \u2264 (1 \u2212 \u03b3\u22c6) a\u2032+2(s\u22121)a \u03c0\u22c6 \u2264 (1\u2212 \u03b3\u22c6) a \u03c0\u22c6 \u2264 1 ,\nwhere the last inequality follows from the assumption that the block length a satisfies Eq. (21). Combining this with \u2016Diag(\u03c0)\u22121/2M Diag(\u03c0)\u22121/2\u2016 = \u2016L\u2016 \u2264 1, it follows that\n\u2016Diag(\u03c0)\u22121/2E(Y s)Diag(\u03c0)\u22121/2\u2016 \u2264 2(24)\nby the triangle inequality. Therefore, together with Eq. (22), we obtain the range bound\n\u2016Zs\u2016 \u2264 1\n\u03c0\u22c6 + 2.\nVariance bound. We now determine bounds on the spectral norms of E(ZsZ \u22a4 s ) and E(Z\u22a4s Zs). Observe that\nE(ZsZ \u22a4 s )\n= 1\na2\n\u2211\nt\u2208Hs\nE ( Diag(\u03c0)\u22121/2eXte \u22a4 Xt+1 Diag(\u03c0) \u22121eXt+1e \u22a4 Xt Diag(\u03c0) \u22121/2 ) (25)\n+ 1\na2\n\u2211\nt6=t\u2032\nt,t\u2032\u2208Hs\nE ( Diag(\u03c0)\u22121/2eXte \u22a4 Xt+1 Diag(\u03c0) \u22121eXt\u2032+1e \u22a4 Xt\u2032 Diag(\u03c0)\u22121/2 ) (26)\n\u2212Diag(\u03c0)\u22121/2E(Y s)Diag(\u03c0)\u22121E(Y \u22a4s )Diag(\u03c0)\u22121/2.(27)\nThe first sum, Eq. (25), easily simplifies to the diagonal matrix\n1\na2\n\u2211\nt\u2208Hs\nd\u2211\ni=1\nd\u2211\nj=1\nPr(Xt = i,Xt+1 = j) \u00b7 1\n\u03c0i\u03c0j eie\n\u22a4 j eje \u22a4 i\n= 1\na2\n\u2211\nt\u2208Hs\nd\u2211\ni=1\nd\u2211\nj=1\n\u03c0 (t) i Pi,j \u00b7\n1\n\u03c0i\u03c0j eie\n\u22a4 i = 1\na\nd\u2211\ni=1\n\u03c0 (Hs) i\n\u03c0i\n  d\u2211\nj=1\nPi,j \u03c0j\n eie\u22a4i .\nFor the second sum, Eq. (26), a symmetric matrix, consider\nu\u22a4   1\na2\n\u2211\nt6=t\u2032\nt,t\u2032\u2208Hs\nE ( Diag(\u03c0)\u22121/2eXte \u22a4 Xt+1 Diag(\u03c0) \u22121eXt\u2032+1e \u22a4 Xt\u2032 Diag(\u03c0)\u22121/2 )  u\nfor an arbitrary unit vector u. By Cauchy-Schwarz and AM/GM, this is bounded from above by\n1\n2a2\n\u2211\nt6=t\u2032\nt,t\u2032\u2208Hs\n[ E ( u\u22a4 Diag(\u03c0)\u22121/2eXte \u22a4 Xt+1 Diag(\u03c0) \u22121eXt+1e \u22a4 Xt Diag(\u03c0) \u22121/2u )\n+ E ( u\u22a4 Diag(\u03c0)\u22121/2eXt\u2032e \u22a4 Xt\u2032+1 Diag(\u03c0)\u22121eXt\u2032+1e \u22a4 Xt\u2032 Diag(\u03c0)\u22121/2u )] ,\nwhich simplifies to\na\u2212 1 a2 u\u22a4E\n(\u2211\nt\u2208Hs\nDiag(\u03c0)\u22121/2eXte \u22a4 Xt+1 Diag(\u03c0) \u22121eXt+1e \u22a4 Xt Diag(\u03c0) \u22121/2\n) u .\nThe expectation is the same as that for the first term, Eq. (25). Finally, the spectral norm of the third term, Eq. (27), is bounded using Eq. (24):\n\u2016Diag(\u03c0)\u22121/2E(Y s)Diag(\u03c0)\u22121/2\u20162 \u2264 4.\nTherefore, by the triangle inequality, the bound \u03c0 (H) i /\u03c0i \u2264 2 from Eq. (23), and\nsimplifications,\n\u2016E(ZsZ\u22a4s )\u2016 \u2264 max i\u2208[d]\n  d\u2211\nj=1\nPi,j \u03c0j\n  \u03c0 (H) i\n\u03c0i + 4 \u2264 2max i\u2208[d]\n  d\u2211\nj=1\nPi,j \u03c0j\n + 4.\nWe can bound E(Z\u22a4s Zs) in a similar way; the only difference is that the reversibility needs to be used at one place to simplify an expectation:\n1\na2\n\u2211\nt\u2208Hs\nE ( Diag(\u03c0)\u22121/2eXt+1e \u22a4 Xt Diag(\u03c0) \u22121eXte \u22a4 Xt+1 Diag(\u03c0) \u22121/2 )\n= 1\na2\n\u2211\nt\u2208Hs\nd\u2211\ni=1\nd\u2211\nj=1\nPr(Xt = i,Xt+1 = j) \u00b7 1\n\u03c0i\u03c0j eje\n\u22a4 j\n= 1\na2\n\u2211\nt\u2208Hs\nd\u2211\ni=1\nd\u2211\nj=1\n\u03c0 (t) i Pi,j \u00b7\n1\n\u03c0i\u03c0j eje\n\u22a4 j\n= 1\na2\n\u2211\nt\u2208Hs\nd\u2211\nj=1\n( d\u2211\ni=1\n\u03c0 (t) i\n\u03c0i \u00b7 Pj,i \u03c0i\n) eje \u22a4\nj\nwhere the last step uses Eq. (3). As before, we get\n\u2016E(Z\u22a4s Zs)\u2016 \u2264 max i\u2208[d]\n  d\u2211\nj=1\nPi,j \u03c0j\n\u00b7 \u03c0 (H) j\n\u03c0j\n + 4 \u2264 2max\ni\u2208[d]\n  d\u2211\nj=1\nPi,j \u03c0j\n + 4\nagain using the bound \u03c0 (H) i /\u03c0i \u2264 2 from Eq. (23). Independent copies bound. Let Z\u0303s for s \u2208 [\u00b5H ] be independent copies of Zs for s \u2208 [\u00b5H ]. Applying Theorem 6.4 to the average of these random matrices, we have\n(28) P   \u2225\u2225\u2225\u2225\u2225 1\n\u00b5H\n\u00b5H\u2211\ns=1\nZ\u0303s \u2225\u2225\u2225\u2225\u2225 > \u221a 4 (dP + 2) ln 4d \u03b4 \u00b5H + 2 ( 1 \u03c0\u22c6 + 2 ) ln 4d\u03b4 3\u00b5H   \u2264 \u03b4\nwhere\ndP := max i\u2208[d]\nd\u2211\nj=1\nPi,j \u03c0j \u2264 1 \u03c0\u22c6 .\nThe actual bound. To bound the probability that \u2016 \u2211\u00b5H\ns=1 Zs/\u00b5H\u2016 is large, we appeal to the following result (a consequence of Yu 1994, Corollary 2.7). For each s \u2208 [\u00b5H ], let X(Hs) := (Xt : a\u2032 + 2(s \u2212 1)a + 1 \u2264 t \u2264 a\u2032 + (2s \u2212 1)a + 1), which are the random variables determining Zs. Let P denote the joint distribution of (X(Hs) : s \u2208 [\u00b5H ]); let Ps be its marginal over X(Hs), and let P1:s+1 be its marginal over (X(H1), X(H2), . . . , X(Hs+1)). Let P\u0303 be the product distribution formed from the marginals P1,P2, . . . ,P\u00b5H , so P\u0303 governs the joint distribution of (Z\u0303s : s \u2208 [\u00b5H ]). The result from Yu (1994, Corollary 2.7) implies for any event E,\n|P(E)\u2212 P\u0303(E)| \u2264 (\u00b5H \u2212 1)\u03b2(P)\nwhere\n\u03b2(P) := max 1\u2264s\u2264\u00b5H\u22121 E (\u2225\u2225\u2225P1:s+1(\u00b7 |X(H1), X(H2), . . . , X(Hs))\u2212 Ps+1 \u2225\u2225\u2225 tv ) .\nHere, \u2016 \u00b7 \u2016tv denotes the total variation norm. The number \u03b2(P) can be recognized to be the \u03b2-mixing coefficient of the stochastic process {X(Hs)}s\u2208[\u00b5H ]. This result implies that the bound from Eq. (28) for \u2016\u2211\u00b5Hs=1 Z\u0303s/\u00b5H\u2016 also holds for \u2016\u2211\u00b5Hs=1 Zs/\u00b5H\u2016, except the probability bound increases from \u03b4 to \u03b4+(\u00b5H\u22121)\u03b2(P): (29)\nP   \u2225\u2225\u2225\u2225\u2225 1\n\u00b5H\n\u00b5H\u2211\ns=1\nZs \u2225\u2225\u2225\u2225\u2225 > \u221a 4 (dP + 2) ln 4d \u03b4 \u00b5H + 2 ( 1 \u03c0\u22c6 + 2 ) ln 4d\u03b4 3\u00b5H   \u2264 \u03b4 + (\u00b5H \u2212 1)\u03b2(P).\nBy the triangle inequality,\n\u03b2(P) \u2264 max 1\u2264s\u2264\u00b5H\u22121 E (\u2225\u2225\u2225P1:s+1(\u00b7 |X(H1), X(H2), . . . , X(Hs))\u2212 P\u03c0 \u2225\u2225\u2225 tv + \u2016Ps+1 \u2212 P\u03c0\u2016tv )\nwhere P\u03c0 is the marginal distribution of X(H1) under the stationary chain. Using the Markov property and integrating out Xt for t > minHs+1 = a \u2032 + 2sa+ 1, \u2225\u2225\u2225P1:s+1(\u00b7 |X(H1), X(H2), . . . , X(Hs))\u2212 P\u03c0 \u2225\u2225\u2225 tv = \u2225\u2225L(Xa\u2032+2sa+1 |Xa\u2032+(2s\u22121)a+1)\u2212 \u03c0 \u2225\u2225 tv\nwhere L(Y |Z) denotes the conditional distribution of Y given Z. We bound this distance using standard arguments for bounding the mixing time in terms of the relaxation time 1/\u03b3\u22c6 (see, e.g., the proof of Theorem 12.3 of Levin, Peres, and Wilmer 2009): for any i \u2208 [d],\n\u2225\u2225L(Xa\u2032+2sa+1 |Xa\u2032+(2s\u22121)a+1 = i)\u2212 \u03c0 \u2225\u2225 tv = \u2016L(Xa+1 |X1 = i)\u2212 \u03c0\u2016tv \u2264 exp (\u2212a\u03b3\u22c6)\n\u03c0\u22c6 .\nThe distance \u2016Ps+1 \u2212 P\u03c0\u2016tv can be bounded similarly:\n\u2016Ps+1 \u2212 P\u03c0\u2016tv = \u2016L(Xa\u2032+2sa+1)\u2212 \u03c0\u2016tv\n= \u2225\u2225\u2225\u2225\u2225 d\u2211\ni=1 P(X1 = i)L(Xa\u2032+2sa+1 |X1 = i)\u2212 \u03c0 \u2225\u2225\u2225\u2225\u2225 tv\n\u2264 d\u2211\ni=1\nP(X1 = i) \u2016L(Xa\u2032+2sa+1 |X1 = i)\u2212 \u03c0\u2016tv\n\u2264 exp (\u2212(a \u2032 + 2sa)\u03b3\u22c6) \u03c0\u22c6 \u2264 exp (\u2212a\u03b3\u22c6) \u03c0\u22c6 .\nWe conclude\n(\u00b5H \u2212 1)\u03b2(P) \u2264 (\u00b5H \u2212 1) 2 exp(\u2212a\u03b3\u22c6) \u03c0\u22c6 \u2264 2(n\u2212 2) exp(\u2212a\u03b3\u22c6) \u03c0\u22c6 \u2264 \u03b4\nwhere the last step follows from the block length assumption Eq. (21). We return to the decomposition from Eq. (19). We apply Eq. (29) to both the Hs blocks and the Ts blocks, and combine with Eq. (20) to obtain the following probabilistic bound. Pick any \u03b4 \u2208 (0, 1), let the block length be\na := \u2308a\u03b4\u2309 = \u2308 1\n\u03b3\u22c6 ln 2(n\u2212 2) \u03c0\u22c6\u03b4\n\u2309 ,\nso\nmin{\u00b5H , \u00b5T } = \u230a n\u2212 1\u2212 a\u2032\n2a\n\u230b \u2265 n\u2212 1\n2 ( 1 + 1\u03b3\u22c6 ln 2(n\u22122) \u03c0\u22c6\u03b4 ) \u2212 2 =: \u00b5.\nIf\n(30) n \u2265 7 + 6 \u03b3\u22c6 ln 2(n\u2212 2) \u03c0\u22c6\u03b4 \u2265 3a,\nthen with probability at least 1\u2212 4\u03b4, \u2225\u2225\u2225Diag(\u03c0)\u22121/2 ( M\u0302 \u2212 E[M\u0302 ] ) Diag(\u03c0)\u22121/2 \u2225\u2225\u2225\n\u2264 4 \u2308 1 \u03b3\u22c6 ln 2(n\u22122)\u03c0\u22c6\u03b4 \u2309\n\u03c0\u22c6(n\u2212 1) +\n\u221a 4 (dP + 2) ln 4d \u03b4\n\u00b5 +\n2 (\n1 \u03c0\u22c6 + 2 ) ln 4d\u03b4\n3\u00b5 .\n6.4.3. The bound on \u2016EM\u2016. Combining the probabilistic bound from above with the bound on the bias from Eq. (17), we obtain the following. Assuming the condition on n from Eq. (30), with probability at least 1\u2212 4\u03b4,\n(31) \u2016EM\u2016 \u2264 1\n(n\u2212 1)\u03b3\u22c6\u03c0\u22c6 +\n4 \u2308\n1 \u03b3\u22c6 ln 2(n\u22122)\u03c0\u22c6\u03b4\n\u2309\n\u03c0\u22c6(n\u2212 1)\n+\n\u221a 4 (dP + 2) ln 4d \u03b4\n\u00b5 +\n2 (\n1 \u03c0\u22c6 + 2 ) ln 4d\u03b4\n3\u00b5 \u2264 C\u2032\n(\u221a \u03b5+ \u03b5 ) ,\nfor some suitable constant C\u2032 > 0, where \u03b5 as defined in Lemma 6.2.\n6.5. Overall error bound. Observe that the assumption on the sequence length in Eq. (10) implies the conditions in Eq. (12) and Eq. (30) for a suitable choice of C > 0. With this assumption, there is a 1\u2212 5\u03b4 probability event in which Eqs. (8), (9) and (31) hold; in particular, we have the bound on \u2016EM\u2016 from Eq. (31). In this event, the bound on \u2016E\u03c0\u2016 in Eq. (13) also holds, and the claimed bound on \u2016L\u0302\u2212 L\u2016 follows from combining the bound in Eq. (11) with the bounds on \u2016E\u03c0\u2016 and \u2016EM\u2016:\n\u2016L\u0302\u2212L\u2016 \u2264 \u2016EM\u2016+ \u2016EM\u20162 + 3\u2016E\u03c0\u2016 \u2264 4C\u2032 (\u221a \u03b5+ \u03b5 ) + C\u2032 2 (\u221a \u03b5+ \u03b5 )2 \u2264 C (\u221a \u03b5+ \u03b5+ \u03b52 ) ,\nwhere \u03b5 is defined in the statement of Lemma 6.2. The proof of Lemma 6.2 now follows by replacing \u03b4 with \u03b4/5."}, {"heading": "7. Proof of Theorem 3.4", "text": "In this section, we prove Theorem 3.4. We call \u03b3\u0302\u22c6 of Theorem 3.3 the initial estimator. Let C be the constant from\nTheorem 3.3, and define\nn1 = n1(\u03b5; \u03b4, \u03b3\u22c6) := 3C2 \u03b52\u03c0\u22c6\u03b3\u22c6 \u00b7 ( log d \u03b4 ) \u00b7 ( log 3C2 \u03b52\u03c02\u22c6\u03b3\u22c6\u03b4 )\nand\nM(n; \u03b4, \u03b3\u22c6) := C\n\u221a log d\u03b4 \u00b7 log n\u03c0\u22c6\u03b4\n\u03c0\u22c6\u03b3\u22c6n ,\nwhich is the right-hand side of Eq. (5). Observe that\nM(n1; \u03b4, \u03b3\u22c6) \u2264 \u03b5\n\u221a\u221a\u221a\u221a log 3C2 \u03b52\u03c02\u22c6\u03b3\u22c6\u03b4 + log log d\u03b4 + log log 3C2 \u03b52\u03c02\u22c6\u03b3\u22c6\u03b4\n3 log 3C 2\n\u03b52\u03c02\u22c6\u03b3 2 \u22c6\u03b4\n\u2264 \u03b5.\n(Each term in the numerator under the radical is at most a third of the denominator. We have used that \u03c0\u22c6 \u2264 1/d in comparing the second term in the numerator to the denominator.)\nFor a > 0, the spectral gap of the chain with transition matrix P a is denoted by \u03b3\u22c6(a), and the initial estimator of \u03b3\u22c6(a), based on n/a steps of P\na, is denoted by \u03b3\u0302\u22c6(a). Note that\n\u03b3\u22c6(a) = 1\u2212 (1\u2212 \u03b3\u22c6)a . Define K\u03b3\u22c6 := \u230alog2(1/\u03b3\u22c6)\u230b and, for any \u03b4 \u2208 (0, 1), \u03b4\u03b3\u22c6 = \u03b4\u03b3\u22c6(\u03b4) := \u03b4/(K\u03b3\u22c6 + 1).\nProposition 7.1. Fix \u03b5 \u2208 (0, 0.01) and \u03b4 \u2208 (0, 1). Let A be the random variable defined in the estimator of Theorem 3.4 (which depends on (Xt) n t=1). If\nn > n1(\u03b5/ \u221a 2; \u03b4\u03b3\u22c6 , \u03b3\u22c6), then there is an event G(\u03b5) having probability at least 1\u2212 \u03b4, such that on G(\u03b5),\n0.30 < \u03b3\u22c6(A) < 0.54 if \u03b3\u22c6 < 1/2 ,\nA = 1 if \u03b3\u22c6 \u2265 1/2 .\nMoreover, on G(\u03b5), the initial estimator \u03b3\u0302\u22c6(A) applied to the chain (XAs) n/A s=1 satisfies\n|\u03b3\u0302\u22c6(A) \u2212 \u03b3\u22c6(A)| \u2264 \u03b5 .(32)\nThe proof of Proposition 7.1 is based on the following lemma.\nLemma 7.2. Fix n \u2265 n1(\u03b5/ \u221a 2; \u03b4, \u03b3\u22c6). If a\u03b3\u22c6 \u2264 1, then\nPr(|\u03b3\u22c6(a)\u2212 \u03b3\u0302\u22c6(a)| \u2264 \u03b5) > 1\u2212 \u03b4. Proof. Recall the bound M(n; \u03b4, \u03b3\u22c6) on the right-hand side of Eq. (5). If \u03b3\u22c6(a) \u2265 \u03b3\u22c6a/2, then\nM(n/a; \u03b4, \u03b3\u22c6(a)) \u2264 \u221a 2M(n; a\u03b4, \u03b3\u22c6) \u2264 \u221a 2M(n; \u03b4, \u03b3\u22c6) \u2264 \u221a 2 \u00b7 \u03b5\u221a\n2 = \u03b5 ,\nand the lemma follows from applying Theorem 3.3 to the P a-chain. We now show that \u03b3\u22c6(a) \u2265 \u03b3\u22c6a/2. A Taylor expansion of (1 \u2212 \u03b3\u22c6)a implies that there exists \u03be \u2208 [0, \u03b3\u22c6] \u2286 [0, 1/a] such that\n\u03b3\u22c6(a) = 1\u2212 (1\u2212 \u03b3\u22c6)a = \u03b3\u22c6a\u2212 a(a\u2212 1)(1\u2212 \u03be)a\u22122\u03b32\u22c6 2 \u2265 \u03b3\u22c6a 2 .\n(We have used the hypothesis a\u03b3\u22c6 \u2264 1 in the inequality.)\nProof of Proposition 7.1. Define the events G(a; \u03b5) := {|\u03b3\u22c6(a) \u2212 \u03b3\u0302\u22c6(a)| \u2264 \u03b5}, and G = G(\u03b5) := \u22c2K\u03b3\u22c6 k=0 G(2\nk; \u03b5). If k \u2264 K\u03b3\u22c6 , then \u03b3\u22c62k \u2264 \u03b3\u22c62log2(1/\u03b3\u22c6) \u2264 1 and Lemma 7.2 implies that\nPr(Gc) \u2264 K\u03b3\u22c6\u2211\nk=0\nPr(G(2k; \u03b5)c) \u2264 (K\u03b3\u22c6 + 1) \u00b7 \u03b4\nK\u03b3\u22c6 + 1 = \u03b4 .\nOn G, if \u03b3\u22c6 \u2265 1/2, then |\u03b3\u0302\u22c6 \u2212 \u03b3\u22c6| \u2264 0.01, and consequently \u03b3\u0302\u22c6 \u2265 0.49 > 0.31. In this case, A = 1 on G.\nOn the event G, if the algorithm has not terminated by step k \u2212 1, then the following hold:\n(1) If \u03b3\u22c6(2 k) \u2264 0.30, then the algorithm does not terminate at step k. (2) If \u03b3\u22c6(2 k) > 0.32, then the algorithm terminates at step k.\nAlso, assuming \u03b3\u22c6 \u2264 1/2,\n\u03b3\u22c6(2 K\u03b3\u22c6 ) \u2265 1\u2212 (1\u2212 \u03b3\u22c6) 1 2\u03b3\u22c6 \u2265 1\u2212 e\u22121/2 \u2265 0.39 ,\nso the algorithm always terminates before k = K\u03b3\u22c6 on G and thus (32) holds on G. Finally, on G, if A > 1, then \u03b3\u22c6(A/2) \u2264 0.32, whence\n\u03b3\u22c6(A) = 1\u2212 (1\u2212 \u03b3\u22c6(A/2))2 \u2264 1\u2212 (0.68)2 < 0.54 . If \u03b3\u22c6 < 1/2 and A = 1, then \u03b3\u22c6(A) = \u03b3\u22c6 \u2264 1/2.\nWe now prove Theorem 3.4.\nProof of Theorem 3.4. Let (33) n0(\u03b5; \u03b4, \u03b3\u22c6, \u03c0\u22c6) = n0(\u03b5) := L\n\u03c0\u22c6\u03b3\u22c6\u03b52 ,\nwhere (34) L := 3\u00b7(16 \u221a 2)2\u00b7 ( log\nd(\u230alog2(1/\u03b3\u22c6)\u230b+ 1) \u03b4\n) \u00b7 ( log 3 \u00b7 (16 \u221a 2)2 \u00b7 C2(\u230alog2(1/\u03b3\u22c6)\u230b+ 1)\n\u03b52\u03c02\u22c6\u03b3\u22c6\u03b4\n) ,\nand C is the constant in Eq. (5).\nFix n > n0(\u03b5) = n1(\u03b5/(16 \u221a 2); \u03b4\u03b3\u22c6 , \u03b3\u22c6). Let A and G be as defined in Proposi-\ntion 7.1. Assume we are on the event G = G(\u03b5/16) for the rest of this proof. Suppose first that \u03b3\u22c6 < 1/2. We have 0.30 < \u03b3\u22c6(A) < 0.54, and\n|\u03b3\u0302\u22c6(A)\u2212 \u03b3\u22c6(A)| \u2264 \u03b5\n16 < 0.01 ,\nso both \u03b3\u22c6(A) and \u03b3\u0302\u22c6(A) are in [0.29, 0.55], say. Let h(x) = 1\u2212(1\u2212x)1/A, so \u03b3\u22c6 = h(\u03b3\u22c6(A)) and \u03b3\u0303\u22c6 = h(\u03b3\u0302\u22c6(A)). Since (1\u2212x)1/A \u2264 1\u2212 x/A, we have 1\n1\u2212 (1 \u2212 x)1/A \u2264 A x .\nConsequently, on [0.29, 0.55], \u2223\u2223\u2223\u2223 d\ndx log h(x) \u2223\u2223\u2223\u2223 = 1 A (1\u2212 x)1/A\u22121 1\u2212 (1 \u2212 x)1/A \u2264\n1 A(1 \u2212 x) A x =\n1 (1\u2212 x)x \u2264 1 (0.45)(0.29) < 8 .\nThus, | ddx log h(x)| is bounded (by 8) on [0.29, 0.55]. We have | log(h(\u03b3\u0302\u22c6(A))/\u03b3\u22c6)| = | log h(\u03b3\u22c6(A))\u2212 log h(\u03b3\u0302\u22c6(A))| \u2264 8|\u03b3\u22c6(A)\u2212 \u03b3\u0302\u22c6(A)| \u2264 8 \u03b5\n16 \u2264 \u03b5 2 .\nThus, \u03b3\u0303\u22c6 \u03b3\u22c6 = h(\u03b3\u0302\u22c6(A)) \u03b3\u22c6 \u2264 e\u03b5/2 \u2264 1 + \u03b5 . Similarly, \u03b3\u22c6h(\u03b3\u0302\u22c6(A)) \u2264 e \u03b5/2, so\n\u03b3\u0303\u22c6 \u03b3\u22c6 = h(\u03b3\u0302\u22c6(A)) \u03b3\u22c6 \u2265 e\u2212\u03b5/2 \u2265 1\u2212 \u03b5 .\nNow instead suppose that \u03b3\u22c6 \u2265 1/2. Then A = 1 on the event G, and\n|\u03b3\u0303\u22c6 \u2212 \u03b3\u22c6| < \u03b5\n16 ,\nso \u2223\u2223\u2223\u2223 \u03b3\u0303\u22c6 \u03b3\u22c6 \u2212 1 \u2223\u2223\u2223\u2223 < \u03b5 16\u03b3\u22c6 \u2264 \u03b5 ."}, {"heading": "8. Proof of Theorem 4.1", "text": "In this section, we derive Algorithm 1 and prove Theorem 4.1.\n8.1. Estimators for \u03c0 and \u03b3\u22c6. The algorithm forms the estimator P\u0302 of P using Laplace smoothing:\nP\u0302i,j := Ni,j + \u03b1\nNi + d\u03b1\nwhere\nNi,j := |{t \u2208 [n\u2212 1] : (Xt, Xt+1) = (i, j)}| , Ni := |{t \u2208 [n\u2212 1] : Xt = i}| and \u03b1 > 0 is a positive constant, which we set beforehand as \u03b1 := 1/d for simplicity.\nAs a result of the smoothing, all entries of P\u0302 are positive, and hence P\u0302 is a transition probability matrix for an ergodic Markov chain. We let \u03c0\u0302 be the unique\nstationary distribution for P\u0302 . Using \u03c0\u0302, we form an estimator Sym(L\u0302) of L using:\nSym(L\u0302) := 1\n2 (L\u0302+ L\u0302\n\u22a4\n), L\u0302 := Diag(\u03c0\u0302)1/2P\u0302 Diag(\u03c0\u0302)\u22121/2.\nLet \u03bb\u03021 \u2265 \u03bb\u03022 \u2265 \u00b7 \u00b7 \u00b7 \u2265 \u03bb\u0302d be the eigenvalues of Sym(L\u0302) (and in fact, we have 1 = \u03bb\u03021 > \u03bb\u03022 and \u03bb\u0302d > \u22121). The algorithm estimates the spectral gap \u03b3\u22c6 using\n\u03b3\u0302\u22c6 := 1\u2212max{\u03bb\u03022, |\u03bb\u0302d|}.\n8.2. Empirical bounds for P . We make use of a simple corollary of Freedman\u2019s inequality for martingales (Freedman 1975, Theorem 1.6).\nTheorem 8.1 (Freedman\u2019s inequality). Let (Yt)t\u2208N be a bounded martingale difference sequence with respect to the filtration F0 \u2282 F1 \u2282 F2 \u2282 \u00b7 \u00b7 \u00b7 ; assume for some b > 0, |Yt| \u2264 b almost surely for all t \u2208 N. Let Vk := \u2211k t=1 E ( Y 2t |Ft\u22121 ) and Sk := \u2211k t=1 Yt for k \u2208 N. For all s, v > 0, Pr [\u2203k \u2208 N s.t. Sk > s \u2227 Vk \u2264 v] \u2264 ( v/b2\ns/b+ v/b2\n)s/b+v/b2 es/b = exp ( \u2212 v b2 \u00b7 h ( bs v )) ,\nwhere h(u) := (1 + u) ln(1 + u)\u2212 u.\nObserve that in Theorem 8.1, for any x > 0, if s := \u221a 2vx+bx/3 and z := b2x/v,\nthen the probability bound on the right-hand side becomes\nexp ( \u2212x \u00b7 h (\u221a 2z + z/3 )\nz\n) \u2264 e\u2212x\nsince h( \u221a 2z + z/3)/z \u2265 1 for all z > 0 (see, e.g., Audibert, Munos, and Szepesva\u0301ri (2009, proof of Lemma 5)).\nCorollary 8.2. Under the same setting as Theorem 8.1, for any n \u2265 1, x > 0, and c > 1,\nPr [ \u2203k \u2208 [n] s.t. Sk > \u221a 2cVkx+ 4bx/3 ] \u2264 (1 + \u2308logc(2n/x)\u2309+) e\u2212x.\nProof. Define vi := c ib2x/2 for i = 0, 1, 2, . . . , \u2308logc(2n/x)\u2309+, and let v\u22121 := \u2212\u221e. Then, since Vk \u2208 [0, b2n] for all k \u2208 [n], Pr [ \u2203k \u2208 [n] s.t. Sk > \u221a 2max{v0, cVk}x+ bx/3 ]\n=\n\u2308logc(2n/x)\u2309+\u2211\ni=0\nPr [ \u2203k \u2208 [n] s.t. Sk > \u221a 2max{v0, cVk}x+ bx/3 \u2227 vi\u22121 < Vk \u2264 vi ]\n\u2264 \u2308logc(2n/x)\u2309+\u2211\ni=0\nPr [ \u2203k \u2208 [n] s.t. Sk > \u221a 2max{v0, cvi\u22121}x+ bx/3 \u2227 vi\u22121 < Vk \u2264 vi ]\n\u2264 \u2308logc(2n/x)\u2309+\u2211\ni=0\nPr [ \u2203k \u2208 [n] s.t. Sk > \u221a 2vix+ bx/3 \u2227 Vk \u2264 vi ]\n\u2264 (1 + \u2308logc(2n/x)\u2309+) e\u2212x , where the final inequality uses Theorem 8.1. The conclusion now follows because\n\u221a 2cVkx+ 4bx/3 \u2265 \u221a 2max{v0, cVk}x+ bx/3\nfor all k \u2208 [n].\nLemma 8.3. The following holds for any constant c > 1 with probability at least 1\u2212 \u03b4: for all (i, j) \u2208 [d]2, (35) |P\u0302i,j \u2212Pi,j | \u2264 \u221a(\nNi Ni + d\u03b1\n) 2cPi,j(1\u2212 Pi,j)\u03c4n,\u03b4\nNi + d\u03b1 + (4/3)\u03c4n,\u03b4 Ni + d\u03b1 + |\u03b1\u2212 d\u03b1Pi,j | Ni + d\u03b1 ,\nwhere (36)\n\u03c4n,\u03b4 := inf { t \u2265 0 : 2d2 (1 + \u2308logc(2n/t)\u2309+) e\u2212t \u2264 \u03b4 } = O ( log ( d log(n)\n\u03b4\n)) .\nProof. Let Ft be the \u03c3-field generated by X1, X2, . . . , Xt. Fix a pair (i, j) \u2208 [d]2. Let Y1 := 0, and for t \u2265 2, Yt := 1 {Xt\u22121 = i} (1 {Xt = j} \u2212 Pi,j), so that\nn\u2211\nt=1\nYt = Ni,j \u2212NiPi,j .\nThe Markov property implies that the stochastic process (Yt)t\u2208[n] is an (Ft)-adapted martingale difference sequence: Yt is Ft-measurable and E (Yt|Ft\u22121) = 0, for each t. Moreover, for all t \u2208 [n],\nYt \u2208 [\u2212Pi,j , 1\u2212 Pi,j ] , and for t \u2265 2,\nE ( Y 2t |Ft\u22121 ) = 1 {Xt\u22121 = i}Pi,j(1\u2212 Pi,j) .\nTherefore, by Corollary 8.2 and union bounds, we have\n|Ni,j \u2212NiPi,j | \u2264 \u221a 2cNiPi,j(1\u2212 Pi,j)\u03c4n,\u03b4 +\n4\u03c4n,\u03b4 3\nfor all (i, j) \u2208 [d]2. Equation (35) can be viewed as constraints on the possible value that Pi,j may have (with high probability). Since Pi,j is the only unobserved quantity in the bound from Eq. (35), we can numerically maximize |P\u0302i,j \u2212 Pi,j | subject to the constraint in Eq. (35) (viewing Pi,j as the optimization variable). Let B \u2217 i,j be this maximum value, so we have\nPi,j \u2208 [ P\u0302i,j \u2212B\u2217i,j , P\u0302i,j +B\u2217i,j ]\nin the same event where Eq. (35) holds. In the algorithm, we give a simple alternative to computing B\u2217i,j that avoids numerical optimization, derived in the spirit of empirical Bernstein bounds (Audibert, Munos, and Szepesva\u0301ri 2009). Specifically, with c := 1.1 (an arbitrary choice), we compute (37)\nB\u0302i,j :=   \u221a\nc\u03c4n,\u03b4 2Ni + \u221a\u221a\u221a\u221ac\u03c4n,\u03b4 2Ni + \u221a 2cP\u0302i,j(1 \u2212 P\u0302i,j)\u03c4n,\u03b4 Ni + (4/3)\u03c4n,\u03b4 + |\u03b1\u2212 d\u03b1P\u0302i,j | Ni   2\nfor each (i, j) \u2208 [d]2, where \u03c4n,\u03b4 is defined in Eq. (36). We show in Lemma 8.4 that\nPi,j \u2208 [ P\u0302i,j \u2212 B\u0302i,j , P\u0302i,j + B\u0302i,j ]\nagain, in the same event where Eq. (35) holds. The observable bound in Eq. (37) is not too far from the unobservable bound in Eq. (35).\nLemma 8.4. In the same 1 \u2212 \u03b4 event as from Lemma 8.3, we have Pi,j \u2208 [P\u0302i,j \u2212 B\u0302i,j , P\u0302i,j + B\u0302i,j ] for all (i, j) \u2208 [d]2, where B\u0302i,j is defined in Eq. (37). Proof. Recall that in the 1 \u2212 \u03b4 probability event from Lemma 8.3, we have for all (i, j) \u2208 [d]2,\n|P\u0302i,j \u2212 Pi,j | = \u2223\u2223\u2223\u2223 Ni,j \u2212NiPi,j\nNi + d\u03b1 + \u03b1\u2212 d\u03b1Pi,j Ni + d\u03b1\n\u2223\u2223\u2223\u2223\n\u2264 \u221a\n2cNiPi,j(1 \u2212 Pi,j)\u03c4n,\u03b4 (Ni + d\u03b1)2 + (4/3)\u03c4n,\u03b4 Ni + d\u03b1 + |\u03b1\u2212 d\u03b1Pi,j | Ni + d\u03b1 .\nApplying the triangle inequality to the right-hand side, we obtain\n|P\u0302i,j \u2212 Pi,j | \u2264\n\u221a 2cNi(P\u0302i,j(1\u2212 P\u0302i,j) + |P\u0302i,j \u2212 Pi,j |)\u03c4n,\u03b4\n(Ni + d\u03b1)2 + (4/3)\u03c4n,\u03b4 Ni + d\u03b1\n+ |\u03b1\u2212 d\u03b1P\u0302i,j |+ d\u03b1|P\u0302i,j \u2212 Pi,j |\nNi + d\u03b1 .\nSince \u221a A+B \u2264 \u221a A + \u221a B for non-negative A,B, we loosen the above inequality and rearrange it to obtain ( 1\u2212 d\u03b1\nNi + d\u03b1\n) |P\u0302i,j \u2212 Pi,j | \u2264 \u221a |P\u0302i,j \u2212 Pi,j | \u00b7 \u221a 2cNi\u03c4n,\u03b4\n(Ni + d\u03b1)2\n+\n\u221a 2cNiP\u0302i,j(1 \u2212 P\u0302i,j)\u03c4n,\u03b4\n(Ni + d\u03b1)2 + (4/3)\u03c4n,\u03b4 + |\u03b1\u2212 d\u03b1P\u0302i,j | Ni + d\u03b1 .\nWhenever Ni > 0, we can solve a quadratic inequality to conclude |P\u0302i,j \u2212 Pi,j | \u2264 B\u0302i,j .\n8.3. Empirical bounds for \u03c0. Recall that \u03c0\u0302 is obtained as the unique stationary distribution for P\u0302 . Let A\u0302 := I \u2212 P\u0302 , and let A\u0302# be the group inverse of A\u0302\u2014i.e., the unique square matrix satisfying the following equalities:\nA\u0302A\u0302#A\u0302 = A\u0302, A\u0302#A\u0302A\u0302# = A\u0302#, A\u0302#A\u0302 = A\u0302A\u0302#.\nThe matrix A\u0302#, which is well defined no matter what transition probability matrix\nP\u0302 we start with (Meyer Jr. 1975), is a central quantity that captures many prop-\nerties of the ergodic Markov chain with transition matrix P\u0302 (Meyer Jr. 1975). We denote the (i, j)-th entry of A\u0302# by A\u0302#i,j . Define\n\u03ba\u0302 := 1\n2 max\n{ A\u0302\n# j,j \u2212min\n{ A\u0302\n# i,j : i \u2208 [d]\n} : j \u2208 [d] } .\nAnalogously define\nA := I \u2212 P , A# := group inverse of A,\n\u03ba := 1\n2 max\n{ A\n# j,j \u2212min\n{ A\n# i,j : i \u2208 [d]\n} : j \u2208 [d] } .\nWe now use the following perturbation bound from Cho and Meyer (2001, Section 3.3) (derived from Haviv and Van der Heyden (1984) and Kirkland, Neumann, and Shader (1998)).\nLemma 8.5 (Haviv and Van der Heyden 1984; Kirkland, Neumann, and Shader 1998). If |P\u0302i,j \u2212 Pi,j | \u2264 B\u0302i,j for each (i, j) \u2208 [d]2, then\nmax {|\u03c0\u0302i \u2212 \u03c0i| : i \u2208 [d]} \u2264 min{\u03ba, \u03ba\u0302}max{B\u0302i,j : (i, j) \u2208 [d]2} \u2264 \u03ba\u0302max{B\u0302i,j : (i, j) \u2208 [d]2}.\nThis establishes the validity of the confidence intervals for the \u03c0i in the same event from Lemma 8.3.\nWe now establish the validity of the bounds for the ratio quantities \u221a \u03c0\u0302i/\u03c0i and\u221a\n\u03c0i/\u03c0\u0302i.\nLemma 8.6. If max{|\u03c0\u0302i \u2212 \u03c0i| : i \u2208 [d]} \u2264 b\u0302, then\nmax \u22c3\ni\u2208[d]\n{| \u221a \u03c0i/\u03c0\u0302i \u2212 1|, | \u221a \u03c0\u0302i/\u03c0i \u2212 1|} \u2264 1\n2 max\n\u22c3\ni\u2208[d]\n{ b\u0302\n\u03c0\u0302i ,\nb\u0302\n[\u03c0\u0302i \u2212 b\u0302]+\n} .\nProof. By Lemma 8.5, we have for each i \u2208 [d], |\u03c0\u0302i \u2212 \u03c0i|\n\u03c0\u0302i \u2264 b\u0302 \u03c0\u0302i , |\u03c0\u0302i \u2212 \u03c0i| \u03c0i \u2264 b\u0302 \u03c0i \u2264 b\u0302 [\u03c0\u0302i \u2212 b\u0302]+ .\nTherefore, using the fact that for any x > 0,\nmax { | \u221a x\u2212 1|, | \u221a 1/x\u2212 1| } \u2264 1\n2 max {|x\u2212 1|, |1/x\u2212 1|}\nwe have for every i \u2208 [d],\nmax { | \u221a \u03c0i/\u03c0\u0302i \u2212 1|, | \u221a \u03c0\u0302i/\u03c0i \u2212 1| } \u2264 1\n2 max {|\u03c0i/\u03c0\u0302i \u2212 1|, |\u03c0\u0302i/\u03c0i \u2212 1|}\n\u2264 1 2 max\n{ b\u0302\n\u03c0\u0302i ,\nb\u0302\n[\u03c0\u0302i \u2212 b\u0302]+\n} .\n8.4. Empirical bounds for L. By Weyl\u2019s inequality and the triangle inequality,\nmax i\u2208[d]\n|\u03bbi \u2212 \u03bb\u0302i| \u2264 \u2016L\u2212 Sym(L\u0302)\u2016 \u2264 \u2016L\u2212 L\u0302\u2016.\nIt is easy to show that |\u03b3\u0302\u22c6 \u2212 \u03b3\u22c6| is bounded by the same quantity. Therefore, it remains to establish an empirical bound on \u2016L\u2212 L\u0302\u2016.\nLemma 8.7. If |P\u0302i,j \u2212 Pi,j | \u2264 B\u0302i,j for each (i, j) \u2208 [d]2 and max{|\u03c0\u0302i \u2212 \u03c0i| : i \u2208 [d]} \u2264 b\u0302, then\n\u2016L\u0302\u2212L\u2016 \u2264 2\u03c1\u0302+ \u03c1\u03022 + (1 + 2\u03c1\u0302+ \u03c1\u03022) ( \u2211\n(i,j)\u2208[d]2\n\u03c0\u0302i \u03c0\u0302j B\u03022i,j\n)1/2 ,\nwhere\n\u03c1\u0302 := 1\n2 max\n\u22c3\ni\u2208[d]\n{ b\u0302\n\u03c0\u0302i ,\nb\u0302\n[\u03c0\u0302i \u2212 b\u0302]+\n} .\nProof. We use the following decomposition of L\u2212 L\u0302: L\u2212 L\u0302 = EP + E\u03c0,1L\u0302+ L\u0302E\u03c0,2 + E\u03c0,1EP + EPE\u03c0,2 + E\u03c0,1L\u0302E\u03c0,2 + E\u03c0,1EPE\u03c0,2\nwhere\nEP := Diag(\u03c0\u0302) 1/2(P \u2212 P\u0302 )Diag(\u03c0\u0302)\u22121/2,\nE\u03c0,1 := Diag(\u03c0) 1/2 Diag(\u03c0\u0302)\u22121/2 \u2212 I,\nE\u03c0,2 := Diag(\u03c0\u0302) 1/2 Diag(\u03c0)\u22121/2 \u2212 I.\nTherefore\n\u2016L\u2212 L\u0302\u2016 \u2264 \u2016E\u03c0,1\u2016+ \u2016E\u03c0,2\u2016+ \u2016E\u03c0,1\u2016\u2016E\u03c0,2\u2016 + (1 + \u2016E\u03c0,1\u2016+ \u2016E\u03c0,2\u2016+ \u2016E\u03c0,1\u2016\u2016E\u03c0,2\u2016) \u2016EP \u2016.\nObserve that for each (i, j) \u2208 [d]2, the (i, j)-th entry of EP is bounded in absolute value by\n|(EP )i,j | = \u03c0\u03021/2i \u03c0\u0302 \u22121/2 j |Pi,j \u2212 P\u0302i,j | \u2264 \u03c0\u0302 1/2 i \u03c0\u0302 \u22121/2 j B\u0302i,j .\nSince the spectral norm of EP is bounded above by its Frobenius norm,\n\u2016EP \u2016 \u2264 ( \u2211\n(i,j)\u2208[d]2\n(EP ) 2 i,j\n)1/2 \u2264 ( \u2211\n(i,j)\u2208[d]2\n\u03c0i \u03c0j B\u03022i,j\n)1/2 .\nFinally, the spectral norms of E\u03c0,1 and E\u03c0,2 satisfy\nmax {\u2016E\u03c0,1\u2016, \u2016E\u03c0,2\u2016} = max \u22c3\ni\u2208[d]\n{| \u221a \u03c0i/\u03c0\u0302i \u2212 1|, | \u221a \u03c0\u0302i/\u03c0i \u2212 1|},\nwhich can be bounded using Lemma 8.6.\nThis establishes the validity of the confidence interval for \u03b3\u22c6 in the same event from Lemma 8.3.\n8.5. Asymptotic widths of intervals. Let us now turn to the asymptotic behavior of the interval widths (regarding b\u0302, \u03c1\u0302, and w\u0302 all as functions of n). A simple calculation gives that, almost surely, as n \u2192 \u221e,\n\u221a n\nlog logn b\u0302 = O ( max i,j \u03ba \u221a Pi,j \u03c0i ) ,\n\u221a n\nlog logn \u03c1\u0302 = O\n( \u03ba\n\u03c0 3/2 \u22c6\n) .\nHere, we use the fact that \u03ba\u0302 \u2192 \u03ba as n \u2192 \u221e since A\u0302# \u2192 A# as P\u0302 \u2192 P (Li and Wei 2001; Ben\u0301\u0131tez and X. Liu 2012).\nFurther, since\n\u221a n\nlog logn\n(\u2211\ni,j\n\u03c0\u0302i \u03c0\u0302j B\u03022i,j\n)1/2 = O   (\u2211\ni,j\n\u03c0i \u03c0j \u00b7 Pi,j(1\u2212 Pi,j) \u03c0i\n)1/2  = O (\u221a d\n\u03c0\u22c6\n) ,\nwe thus have \u221a\nn\nlog logn w\u0302 = O\n( \u03ba\n\u03c0 3/2 \u22c6\n+\n\u221a d\n\u03c0\u22c6\n) .\nThis completes the proof of Theorem 4.1.\nThe following lemma provides a bound on \u03ba in terms of the number of states and the spectral gap.\nLemma 8.8. \u03ba \u2264 1\u03b3\u22c6 min{d, 8 + ln(4/\u03c0\u22c6)}\nBefore proving this, we prove a lemma of independent interest.\nLemma 8.9. Let \u03c4j be the first positive time that state j is visited by the Markov chain. Then (38) Ei\u03c4j \u2264 2 ( tmix + 8\ntrelax \u03c0j\n) .\nProof. By taking f to be the indicator of state j in Theorem 12.19 of Levin, Peres, and Wilmer (2009), for any i, if t = tmix + 8trelax/\u03c0j , then\nPri(\u03c4j > t) \u2264 1\n2 .\nThus, Pri(\u03c4j > tk) \u2264 2\u2212k, whence Eq. (38) follows.\nProof of Lemma 8.8. It is established by Cho and Meyer (2001) that\n\u03ba \u2264 max i,j |A#i,j | \u2264 sup \u2016v\u20161=1,\u3008v,1\u3009=0 \u2016v\u22a4A#\u20161\n(our \u03ba is the \u03ba4 quantity from Cho and Meyer (2001)), and Seneta (1993) establishes\nsup \u2016v\u20161=1,\u3008v,1\u3009=0\n\u2016v\u22a4A#\u20161 \u2264 d\n\u03b3\u22c6 .\nSince it is shown in Cho and Meyer (2001) that\n\u03ba = 1\n2 max j [ max i6=j Ei(\u03c4j) ] \u03c0j ,\nit follows from Lemma 8.9 that\n\u03ba \u2264 tmix + 8trelax \u2264 trelax(8 + ln(4/\u03c0\u22c6)) ."}, {"heading": "9. Proof of Theorem 4.2", "text": "Let \u03c0\u0302\u22c6,lb and \u03b3\u0302\u22c6,lb be the lower bounds on \u03c0\u22c6 and \u03b3\u22c6, respectively, computed from Algorithm 1. Let \u03c0\u0302\u22c6 and \u03b3\u0302\u22c6 be the estimates of \u03c0\u22c6 and \u03b3\u22c6 computed using the estimators from Theorem 3.3. By a union bound, we have by Theorems 3.3 and 4.1 that with probability at least 1\u2212 2\u03b4,\n(39) |\u03c0\u0302\u22c6 \u2212 \u03c0\u22c6| \u2264 C\n  \u221a \u03c0\u22c6 log d \u03c0\u0302\u22c6,lb\u03b4\n\u03b3\u0302\u22c6,lbn +\nlog d\u03c0\u0302\u22c6,lb\u03b4\n\u03b3\u0302\u22c6,lbn\n \nand\n(40) |\u03b3\u0302\u22c6 \u2212 \u03b3\u22c6| \u2264 C\n  \u221a\nlog d\u03b4 \u00b7 log n\u03c0\u0302\u22c6,lb\u03b4 \u03c0\u0302\u22c6,lb\u03b3\u0302\u22c6,lbn + log d\u03b4 \u00b7 log n\u03c0\u0302\u22c6,lb\u03b4 \u03c0\u0302\u22c6,lb\u03b3\u0302\u22c6,lbn + log 1\u03b3\u0302\u22c6,lb \u03b3\u0302\u22c6,lbn\n  .\nThe bound on |\u03b3\u0302\u22c6\u2212 \u03b3\u22c6| in Eq. (40)\u2014call it w\u0302\u2032\u2014is fully observable and hence yields a confidence interval for \u03b3\u22c6. The bound on |\u03c0\u0302\u22c6\u2212\u03c0\u22c6| in Eq. (39) depends on \u03c0\u22c6, but from it one can derive\n|\u03c0\u0302\u22c6 \u2212 \u03c0\u22c6| \u2264 C\u2032   \u221a \u03c0\u0302\u22c6 log d \u03c0\u0302\u22c6,lb\u03b4\n\u03b3\u0302\u22c6,lbn +\nlog d\u03c0\u0302\u22c6,lb\u03b4\n\u03b3\u0302\u22c6,lbn\n \nusing the approach from the proof of Lemma 8.4. Here, C\u2032 > 0 is an absolute constant that depends only on C. This bound\u2014call it b\u0302\u2032\u2014is now also fully observable. We have established that in the 1\u2212 2\u03b4 probability event from above,\n\u03c0\u22c6 \u2208 U\u0302 := [\u03c0\u0302\u22c6 \u2212 b\u0302\u2032, \u03c0\u0302\u22c6 + b\u0302\u2032], \u03b3\u22c6 \u2208 V\u0302 := [\u03b3\u0302\u22c6 \u2212 w\u0302\u2032, \u03b3\u0302\u22c6 + w\u0302\u2032]. It is easy to see that almost surely (as n \u2192 \u221e),\n\u221a n\nlogn w\u0302\u2032 = O\n(\u221a log(d/\u03b4)\n\u03c0\u22c6\u03b3\u22c6\n)\nand\n\u221a nb\u0302\u2032 = O   \u221a \u03c0\u22c6 log d \u03c0\u22c6\u03b4\n\u03b3\u22c6\n  .\nThis completes the proof of Theorem 4.2.\n10. Discussion\nThe construction used in Theorem 4.2 applies more generally: Given a confidence interval of the form In = In(\u03b3\u22c6, \u03c0\u22c6, \u03b4) for some confidence level \u03b4 and a confidence set En(\u03b4) for (\u03b3\u22c6, \u03c0\u22c6) for the same level, I \u2032 n = En(\u03b4) \u2229 \u222a(\u03b3,\u03c0)\u2208En(\u03b4)In(\u03b3, \u03c0, \u03b4) is a valid 2\u03b4-level confidence interval whose asymptotic width matches that of In up to lower order terms under reasonable assumptions on En and In. In particular, this suggests that future work should focus on closing the gap between the lower and upper bounds on the accuracy of point-estimation. The bootstrap estimator of Theorem 3.4 closes most of the gap when \u03c0 is uniform. Another interesting direction is to reduce the computation cost: the current cubic cost in the number of states can be too high even when the number of states is only moderately large.\nPerhaps more important, however, is to extend our results to large state space Markov chains. In most practical applications the state space is continuous or is exponentially large in some natural parameters. To subvert our lower bounds, we must restrict attention to Markov chains with additional structure. Parametric classes, such as Markov chains with factored transition kernels with a few factors, are promising candidates for such future investigations. The results presented here are a first step in the ambitious research agenda outlined above, and we hope that they will serve as a point of departure for further insights on the topic of fully empirical estimation of Markov chain parameters based on a single sample path."}], "references": [{"title": "Rates of uniform convergence", "author": ["R.L. Karandikar", "M. Vidyasagar"], "venue": null, "citeRegEx": "Karandikar and Vidyasagar,? \\Q2002\\E", "shortCiteRegEx": "Karandikar and Vidyasagar", "year": 2002}, {"title": "An improvement on the perturbation of the group inverse", "author": ["ical Society", "Providence", "X. RI. Li", "Y. Wei"], "venue": null, "citeRegEx": "Society et al\\.,? \\Q2001\\E", "shortCiteRegEx": "Society et al\\.", "year": 2001}, {"title": "The Role of the Group Generalized Inverse in the Theory", "author": ["C.D. Meyer Jr."], "venue": "ficients\u201d. In: AISTATS,", "citeRegEx": "Jr.,? \\Q1975\\E", "shortCiteRegEx": "Jr.", "year": 1975}, {"title": "Stability bounds for non-iid processes", "author": ["M. Springer. Mohri", "A. Rostamizadeh"], "venue": null, "citeRegEx": "Mohri and Rostamizadeh,? \\Q2008\\E", "shortCiteRegEx": "Mohri and Rostamizadeh", "year": 2008}, {"title": "Sensitivity of finite Markov chains under perturbation", "author": ["E. Seneta"], "venue": null, "citeRegEx": "32", "shortCiteRegEx": "32", "year": 1993}, {"title": "Fast Learning from Non-i.i.d", "author": ["I. Steinwart", "A. Christmann"], "venue": "Statistics & Probability Letters", "citeRegEx": "Steinwart and Christmann,? \\Q2009\\E", "shortCiteRegEx": "Steinwart and Christmann", "year": 2009}, {"title": "Reinforcement Learning: An Introduction (Adaptive Computation and Machine Learning)", "author": ["R.S. Sutton", "A.G. Barto"], "venue": "A Bradford Book. isbn:", "citeRegEx": "Sutton and Barto,? \\Q1998\\E", "shortCiteRegEx": "Sutton and Barto", "year": 1998}], "referenceMentions": [{"referenceID": 6, "context": "Liu 2001), but the problem also arises in performance prediction involving time-correlated data, as is common in reinforcement learning (Sutton and Barto 1998).", "startOffset": 136, "endOffset": 159}, {"referenceID": 0, "context": "Many results from statistical learning and empirical process theory have been extended to sufficiently fast mixing, dependent data (e.g., Yu 1994; Karandikar and Vidyasagar 2002; Gamarnik 2003; Mohri and Rostamizadeh 2008; Steinwart and Christmann 2009; Steinwart, Hush, and Scovel 2009), providing learnability assurances (e.", "startOffset": 131, "endOffset": 287}, {"referenceID": 3, "context": "Many results from statistical learning and empirical process theory have been extended to sufficiently fast mixing, dependent data (e.g., Yu 1994; Karandikar and Vidyasagar 2002; Gamarnik 2003; Mohri and Rostamizadeh 2008; Steinwart and Christmann 2009; Steinwart, Hush, and Scovel 2009), providing learnability assurances (e.", "startOffset": 131, "endOffset": 287}, {"referenceID": 5, "context": "Many results from statistical learning and empirical process theory have been extended to sufficiently fast mixing, dependent data (e.g., Yu 1994; Karandikar and Vidyasagar 2002; Gamarnik 2003; Mohri and Rostamizadeh 2008; Steinwart and Christmann 2009; Steinwart, Hush, and Scovel 2009), providing learnability assurances (e.", "startOffset": 131, "endOffset": 287}, {"referenceID": 0, "context": ", Yu 1994; Karandikar and Vidyasagar 2002; Gamarnik 2003; Mohri and Rostamizadeh 2008; Steinwart and Christmann 2009; Steinwart, Hush, and Scovel 2009), providing learnability assurances (e.g., generalization error bounds). These results are often given in terms of mixing coefficients, which can be consistently estimated in some cases (McDonald, Shalizi, and Schervish 2011). However, the convergence rates of the estimates from McDonald, Shalizi, and Schervish (2011), which are needed to derive confidence bounds, are given in terms of unknown mixing coefficients.", "startOffset": 11, "endOffset": 471}, {"referenceID": 0, "context": ", Yu 1994; Karandikar and Vidyasagar 2002; Gamarnik 2003; Mohri and Rostamizadeh 2008; Steinwart and Christmann 2009; Steinwart, Hush, and Scovel 2009), providing learnability assurances (e.g., generalization error bounds). These results are often given in terms of mixing coefficients, which can be consistently estimated in some cases (McDonald, Shalizi, and Schervish 2011). However, the convergence rates of the estimates from McDonald, Shalizi, and Schervish (2011), which are needed to derive confidence bounds, are given in terms of unknown mixing coefficients. When the data comes from a Markov chain, these mixing coefficients can often be bounded in terms of mixing times, and hence our main results provide a way to make them fully empirical, at least in the limited setting we study. It is possible to eliminate many of the difficulties presented above when allowed more flexible access to the Markov chain. For example, given a sampling oracle that generates independent transitions from any given state (akin to a \u201creset\u201d device), the mixing time becomes an efficiently testable property in the sense studied by Batu, Fortnow, Rubinfeld, W. D. Smith, and White (2000), Batu, Fortnow, Rubinfeld, W.", "startOffset": 11, "endOffset": 1182}, {"referenceID": 0, "context": ", Yu 1994; Karandikar and Vidyasagar 2002; Gamarnik 2003; Mohri and Rostamizadeh 2008; Steinwart and Christmann 2009; Steinwart, Hush, and Scovel 2009), providing learnability assurances (e.g., generalization error bounds). These results are often given in terms of mixing coefficients, which can be consistently estimated in some cases (McDonald, Shalizi, and Schervish 2011). However, the convergence rates of the estimates from McDonald, Shalizi, and Schervish (2011), which are needed to derive confidence bounds, are given in terms of unknown mixing coefficients. When the data comes from a Markov chain, these mixing coefficients can often be bounded in terms of mixing times, and hence our main results provide a way to make them fully empirical, at least in the limited setting we study. It is possible to eliminate many of the difficulties presented above when allowed more flexible access to the Markov chain. For example, given a sampling oracle that generates independent transitions from any given state (akin to a \u201creset\u201d device), the mixing time becomes an efficiently testable property in the sense studied by Batu, Fortnow, Rubinfeld, W. D. Smith, and White (2000), Batu, Fortnow, Rubinfeld, W. D. Smith, and White (2013), and Bhattacharya and Valiant (2015).", "startOffset": 11, "endOffset": 1239}, {"referenceID": 0, "context": ", Yu 1994; Karandikar and Vidyasagar 2002; Gamarnik 2003; Mohri and Rostamizadeh 2008; Steinwart and Christmann 2009; Steinwart, Hush, and Scovel 2009), providing learnability assurances (e.g., generalization error bounds). These results are often given in terms of mixing coefficients, which can be consistently estimated in some cases (McDonald, Shalizi, and Schervish 2011). However, the convergence rates of the estimates from McDonald, Shalizi, and Schervish (2011), which are needed to derive confidence bounds, are given in terms of unknown mixing coefficients. When the data comes from a Markov chain, these mixing coefficients can often be bounded in terms of mixing times, and hence our main results provide a way to make them fully empirical, at least in the limited setting we study. It is possible to eliminate many of the difficulties presented above when allowed more flexible access to the Markov chain. For example, given a sampling oracle that generates independent transitions from any given state (akin to a \u201creset\u201d device), the mixing time becomes an efficiently testable property in the sense studied by Batu, Fortnow, Rubinfeld, W. D. Smith, and White (2000), Batu, Fortnow, Rubinfeld, W. D. Smith, and White (2013), and Bhattacharya and Valiant (2015). Note that in this setting, Bhattacharya and Valiant (2015) asked if one could approximate tmix (up to logarithmic factors) with a number of queries that is linear in both d and tmix; our work answers the question affirmatively (up to logarithmic corrections) in the case when the stationary distribution is near uniform.", "startOffset": 11, "endOffset": 1276}, {"referenceID": 0, "context": ", Yu 1994; Karandikar and Vidyasagar 2002; Gamarnik 2003; Mohri and Rostamizadeh 2008; Steinwart and Christmann 2009; Steinwart, Hush, and Scovel 2009), providing learnability assurances (e.g., generalization error bounds). These results are often given in terms of mixing coefficients, which can be consistently estimated in some cases (McDonald, Shalizi, and Schervish 2011). However, the convergence rates of the estimates from McDonald, Shalizi, and Schervish (2011), which are needed to derive confidence bounds, are given in terms of unknown mixing coefficients. When the data comes from a Markov chain, these mixing coefficients can often be bounded in terms of mixing times, and hence our main results provide a way to make them fully empirical, at least in the limited setting we study. It is possible to eliminate many of the difficulties presented above when allowed more flexible access to the Markov chain. For example, given a sampling oracle that generates independent transitions from any given state (akin to a \u201creset\u201d device), the mixing time becomes an efficiently testable property in the sense studied by Batu, Fortnow, Rubinfeld, W. D. Smith, and White (2000), Batu, Fortnow, Rubinfeld, W. D. Smith, and White (2013), and Bhattacharya and Valiant (2015). Note that in this setting, Bhattacharya and Valiant (2015) asked if one could approximate tmix (up to logarithmic factors) with a number of queries that is linear in both d and tmix; our work answers the question affirmatively (up to logarithmic corrections) in the case when the stationary distribution is near uniform.", "startOffset": 11, "endOffset": 1336}, {"referenceID": 0, "context": ", Yu 1994; Karandikar and Vidyasagar 2002; Gamarnik 2003; Mohri and Rostamizadeh 2008; Steinwart and Christmann 2009; Steinwart, Hush, and Scovel 2009), providing learnability assurances (e.g., generalization error bounds). These results are often given in terms of mixing coefficients, which can be consistently estimated in some cases (McDonald, Shalizi, and Schervish 2011). However, the convergence rates of the estimates from McDonald, Shalizi, and Schervish (2011), which are needed to derive confidence bounds, are given in terms of unknown mixing coefficients. When the data comes from a Markov chain, these mixing coefficients can often be bounded in terms of mixing times, and hence our main results provide a way to make them fully empirical, at least in the limited setting we study. It is possible to eliminate many of the difficulties presented above when allowed more flexible access to the Markov chain. For example, given a sampling oracle that generates independent transitions from any given state (akin to a \u201creset\u201d device), the mixing time becomes an efficiently testable property in the sense studied by Batu, Fortnow, Rubinfeld, W. D. Smith, and White (2000), Batu, Fortnow, Rubinfeld, W. D. Smith, and White (2013), and Bhattacharya and Valiant (2015). Note that in this setting, Bhattacharya and Valiant (2015) asked if one could approximate tmix (up to logarithmic factors) with a number of queries that is linear in both d and tmix; our work answers the question affirmatively (up to logarithmic corrections) in the case when the stationary distribution is near uniform. Finally, when one only has a circuit-based description of the transition probabilities of a Markov chain over an exponentially-large state space, there are complexity-theoretic barriers for many MCMC diagnostic problems (Bhatnagar, Bogdanov, and Mossel 2011). This paper is based on the conference paper of Hsu, Kontorovich, and Szepesv\u00e1ri (2015), combined with the results in the unpublished manuscript of Levin and Peres (2016).", "startOffset": 11, "endOffset": 1945}, {"referenceID": 0, "context": ", Yu 1994; Karandikar and Vidyasagar 2002; Gamarnik 2003; Mohri and Rostamizadeh 2008; Steinwart and Christmann 2009; Steinwart, Hush, and Scovel 2009), providing learnability assurances (e.g., generalization error bounds). These results are often given in terms of mixing coefficients, which can be consistently estimated in some cases (McDonald, Shalizi, and Schervish 2011). However, the convergence rates of the estimates from McDonald, Shalizi, and Schervish (2011), which are needed to derive confidence bounds, are given in terms of unknown mixing coefficients. When the data comes from a Markov chain, these mixing coefficients can often be bounded in terms of mixing times, and hence our main results provide a way to make them fully empirical, at least in the limited setting we study. It is possible to eliminate many of the difficulties presented above when allowed more flexible access to the Markov chain. For example, given a sampling oracle that generates independent transitions from any given state (akin to a \u201creset\u201d device), the mixing time becomes an efficiently testable property in the sense studied by Batu, Fortnow, Rubinfeld, W. D. Smith, and White (2000), Batu, Fortnow, Rubinfeld, W. D. Smith, and White (2013), and Bhattacharya and Valiant (2015). Note that in this setting, Bhattacharya and Valiant (2015) asked if one could approximate tmix (up to logarithmic factors) with a number of queries that is linear in both d and tmix; our work answers the question affirmatively (up to logarithmic corrections) in the case when the stationary distribution is near uniform. Finally, when one only has a circuit-based description of the transition probabilities of a Markov chain over an exponentially-large state space, there are complexity-theoretic barriers for many MCMC diagnostic problems (Bhatnagar, Bogdanov, and Mossel 2011). This paper is based on the conference paper of Hsu, Kontorovich, and Szepesv\u00e1ri (2015), combined with the results in the unpublished manuscript of Levin and Peres (2016).", "startOffset": 11, "endOffset": 2028}], "year": 2017, "abstractText": "The spectral gap \u03b3\u22c6 of a finite, ergodic, and reversible Markov chain is an important parameter measuring the asymptotic rate of convergence. In applications, the transition matrix P may be unknown, yet one sample of the chain up to a fixed time n may be observed. We consider here the problem of estimating \u03b3\u22c6 from this data. Let \u03c0 be the stationary distribution of P , and \u03c0\u22c6 = minx \u03c0(x). We show that if n = \u00d5 ( 1 \u03b3\u22c6\u03c0\u22c6 ) , then \u03b3 can be estimated to within multiplicative constants with high probability. When \u03c0 is uniform on d states, this matches (up to logarithmic correction) a lower bound of \u03a9\u0303 ( d \u03b3\u22c6 ) steps required for precise estimation of \u03b3\u22c6. Moreover, we provide the first procedure for computing a fully data-dependent interval, from a single finitelength trajectory of the chain, that traps the mixing time tmix of the chain at a prescribed confidence level. The interval does not require the knowledge of any parameters of the chain. This stands in contrast to previous approaches, which either only provide point estimates, or require a reset mechanism, or additional prior knowledge. The interval is constructed around the relaxation time trelax = 1/\u03b3\u22c6, which is strongly related to the mixing time, and the width of the interval converges to zero roughly at a 1/ \u221a n rate, where n is the length of the sample path.", "creator": "Creator"}}}