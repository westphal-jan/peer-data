{"id": "1709.02169", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "7-Sep-2017", "title": "Bayesian Optimisation for Safe Navigation under Localisation Uncertainty", "abstract": "In outdoor environments, mobile robots are required to navigate through terrain with varying characteristics, some of which might significantly affect the integrity of the platform. Ideally, the robot should be able to identify areas that are safe for navigation based on its own percepts about the environment while avoiding damage to itself. Bayesian optimisation (BO) has been successfully applied to the task of learning a model of terrain traversability while guiding the robot through more traversable areas.\n\n\n\n\n\n\nIn my previous article, I discussed how to use Bayesian optimisation. First I discussed how to implement Bayesian optimisation and applied to the task of learning a model of terrain traversability while guiding the robot through more traversable areas. Later, I described Bayesian optimisation and applied to the task of learning a model of terrain traversability while guiding the robot through more traversable areas. The Bayesian optimisation was able to identify areas where areas are safe and are suitable for navigation based on its own percepts about the environment while avoiding damage to itself.\n\nIn my previous article, I discussed how to use Bayesian optimisation and applied to the task of learning a model of terrain traversability while guiding the robot through more traversable areas. The Bayesian optimisation was able to identify areas where areas are safe and are suitable for navigation based on its own percepts about the environment while avoiding damage to itself.", "histories": [["v1", "Thu, 7 Sep 2017 10:17:52 GMT  (1323kb,D)", "http://arxiv.org/abs/1709.02169v1", "To appear in International Symposium of Robotics Research (ISRR) 2017"]], "COMMENTS": "To appear in International Symposium of Robotics Research (ISRR) 2017", "reviews": [], "SUBJECTS": "cs.RO cs.AI cs.LG", "authors": ["rafael oliveira", "lionel ott", "vitor guizilini", "fabio ramos"], "accepted": false, "id": "1709.02169"}, "pdf": {"name": "1709.02169.pdf", "metadata": {"source": "CRF", "title": "Bayesian Optimisation for Safe Navigation under Localisation Uncertainty", "authors": ["Rafael Oliveira", "Lionel Ott", "Vitor Guizilini", "Fabio Ramos"], "emails": ["rdos6788@uni.sydney.edu.au", "lionel.ott@sydney.edu.au", "vitor.guizilini@sydney.edu.au", "fabio.ramos@sydney.edu.au"], "sections": [{"heading": "1 Introduction", "text": "Mobile robots have been successfully applied to many field applications, such as mining [9], planetary exploration [8], agriculture [24], and environmental monitoring [10], to name a few. In all these applications, robots face environments with physical\nRafael Oliveira The University of Sydney, Australia, e-mail: rdos6788@uni.sydney.edu.au\nLionel Ott The University of Sydney, Australia, e-mail: lionel.ott@sydney.edu.au\nVitor Guizilini The University of Sydney, Australia, e-mail: vitor.guizilini@sydney.edu.au\nFabio Ramos The University of Sydney, Australia, e-mail: fabio.ramos@sydney.edu.au\n1\nar X\niv :1\n70 9.\n02 16\n9v 1\n[ cs\n.R O\n] 7\nS ep\ncharacteristics that are a priori unknown and can heavily affect performance. In the case of ground robots, terrain roughness can affect the ability of a robot to navigate and even cause damage to its on-board hardware due to excessive vibration [22]. To aid in these problems, methods to enable the robot to automatically learn terrain properties from its sensory data have been presented in the literature [8, 18, 22]. However, they usually assume that localisation is accurate enough, without dealing with its inherent uncertainty.\nUncertainty in localisation can mislead learning algorithms with noise-corrupted observations of the location where measurements are taken. In addition, localisation accuracy also affects navigation, since local path execution heavily depends on knowing where the robot is with respect to a given reference path. As a result, localisation inaccuracy can lead a robot into areas that are unsafe for navigation.\nIn this paper, we propose a method that allows a robot to learn a model of its environment while keeping itself safe by considering both model and localisation uncertainty. In particular, we propose:\n\u2022 a framework to account for input uncertainty in Bayesian optimisation [2] for mission planning; and \u2022 an adaptation of the DUCB [10] acquisition function to the context of exploration under uncertain localisation.\nIn our method, we apply an extension of the conventional Gaussian process (GP) [19] regression models to contexts involving input uncertainty [5] as priors for the BO framework. Such GP models allow BO to take into account noise in both the execution of a query and in the observation\u2019s location estimate. We apply the proposed method to the task of learning a model of terrain roughness from experienced vibration data, as in [22].\nThe remainder of this paper is organised as follows. In the next section, we review relevant prior work in the areas of terrain modelling and Bayesian optimisation. Section 3 revises the general GP-based BO framework, which does not consider uncertain inputs. In Section 4 we present our method for Bayesian optimisation under localisation uncertainty. Then, in Section 5, we present experimental results in simulation and on a physical robot to evaluate our approach. Finally, in Section 6, we conclude and propose some directions for future work."}, {"heading": "2 Related Work", "text": "Traversability metrics estimate how hard is it for a vehicle to traverse a certain terrain. In robotics, terrain traversability is usually estimated from either LIDAR range measurements [16] or stereo vision information [6]. Among the different kinds of metrics, terrain roughness can play an important role in planning how a robot should navigate on the terrain [16]. Methods to learn terrain roughness using image data usually rely on learning image classification models [7], which generally do not provide a measure of how uncertain they are about their estimates\nand are computationally intensive. In [12], however, the authors propose using vehicle experience data to learn a Gaussian process (GP) regression model [19] to predict terrain traversability with uncertainty estimates. Though restrictive when compared to 3D range sensing information, as pointed out in [6], proprioceptive sensing can still be a very viable option for traversability estimation with robots that are not equipped with stereo vision or 3D LIDAR sensors, or do not possess the computational resources to process this kind of information on-board online.\nSouza et al. [22] presented a method to learn a GP model for terrain roughness from vehicle experience. The authors applied Bayesian optimisation (BO) [2] in an active perception approach to reduce experienced vibration during navigation while learning the model from IMU measurements online. In the BO framework, the terrain roughness model is learnt online as the algorithm drives the robot around selecting locations to visit balancing a trade-off between exploration and exploitation [2, 22]. Nevertheless, BO usually considers deterministic query locations within its search space, as BO is typically used in problems where a fixed number of parameters have to be optimised, such as in [21, 26].\nRecent work [15] presented a method to apply BO to problems where the execution of a query is uncertain, such as robotic grasping. The authors propose querying BO\u2019s surrogate model using a Gaussian distribution by applying the unscented transform [25]. In this, even with uncertainty in the execution of the query, the algorithm chooses to sample the objective function at locations where interesting values are more likely to be observed, instead of trying to reach a narrow peak. Despite this [15] still assumes that the actual query point can be precisely measured after the sampling, which makes the assumption that the location estimates in the GP observations dataset are deterministic.\nTo deal with uncertain location estimates in observations, besides the usual noisy outputs, BO needs a statistical model that considers partial observations of the inputs when sampling the function being modelled, usually called the objective function in optimisation. In BO the most common approach to modelling the objective function is using Gaussian process (GP) regression [19]. In the case of uncertain input observations, the work in [5] proposed methods to propagate input uncertainty through a GP model, developing analytical approximations to compute covariance function values between inputs represented as Gaussian distributions. Another approach is considered in [13], where the input location estimates are assumed to be corrupted by i.i.d. Gaussian noise, similar to the output observations in standard GP regression. The authors present a method to propagate the input uncertainty to the output of the model using a first-order Taylor approximation. Finally, a more general framework is presented in [4], where the true unobserved inputs of the GP model are considered as latent variables and a variational inference framework is applied to compute the posterior of this GP model under a set of assumptions about the input distributions. None of these methods, however, have been applied to the BO context, where the GP model is built in an online fashion as the algorithm proceeds."}, {"heading": "3 Preliminaries", "text": "In this section, we review the concepts that form the basis of the method we propose. We start with a general introduction to Gaussian process (GP) regression, which is used to model terrain properties. Then we follow with a short review of Bayesian optimisation (BO) using GP priors, which will be our planning technique."}, {"heading": "3.1 Gaussian process regression", "text": "Gaussian process regression [19] is a Bayesian non-parametric framework that places a Gaussian distribution as a prior over the space of functions f , mapping inputs x \u2208 Rd to outputs y \u2208 R. In a similar way to a conventional Gaussian distribution, a GP model needs to specify the mean and the covariance for any given pair of values in its vector space, which for a GP is a reproducing kernel Hilbert space (RKHS) [1, 19]. Considering a mean function \u00b50 : Rd \u2192 R and a positive-definite covariance function k : Rd \u00d7Rd \u2192 R, a GP prior models the distribution of the function values y = [y1, . . . ,yn]T at a given set of input locations X = {xi}ni=1 as:\ny|X\u223cN(\u00b50(X),k(X,X)) , (1)\nwhere \u00b50(X) = [\u00b50(x1), . . . ,\u00b50(xn)]T and [k(X,X)]i j = k(xi,x j). In many practical applications the prior mean \u00b50 is set to zero or a constant that can be learnt from a dataset. For the covariance function there are a few popular choices, one of them is the squared exponential kernel:\nk(x,x\u2032) = \u03c32f exp(\u2212 1 2 (x\u2212x\u2032)TW\u22121(x\u2212x\u2032)) , (2)\nwhere \u03c32f is a signal variance parameter and W is a d\u00d7 d diagonal matrix with [W]ii = \u03bb 2i , and each \u03bbi is a length-scale parameter indicating how much the function can vary along the i-th dimension.\nGiven a set of observations D= {xi,zi}, containing both noise-corrupted outputs zi = f (xi)+ \u03b5i with \u03b5i \u223cN(0,\u03c32n ) and deterministic input locations xi, the values for y\u2217 = f (x\u2217) at a given query location x\u2217 are then distributed according to a Gaussian posterior:\ny\u2217|z,X,x\u223cN(\u00b5(x\u2217),\u03c32(x\u2217)) , (3)\nwhere:\n\u00b5(x\u2217) = \u00b50(x\u2217)+ k(x\u2217,X)K\u22121X (z\u2212\u00b50(X)) (4) \u03c32(x\u2217) = k(x\u2217,x\u2217)\u2212 k(x\u2217,X)K\u22121X k(X,x\u2217) , (5)\nusing KX = k(X,X)+\u03c32n I. Therefore, GP models can be used as priors to model functions that are not directly observable during an optimisation process. Partial\nobservations zt can be collected from the function being optimised to incrementally update the GP model. If the GP prior is appropriately specified, as more observations are collected the variance in the posterior decreases, leading the mean to converge on top of the true f ."}, {"heading": "3.2 Bayesian optimisation", "text": "Consider the problem of searching for the global optimum of a function f : Rd \u2192 R in a certain compact region S\u2282 Rd , i.e.:\nx\u2217 = argmin x\u2208S f (x) . (6)\nAssume that f is unknown to us and we have only access to noisy observations of its output z = f (x)+ \u03b5 with \u03b5 \u223cN(0,\u03c32n ) and that we can only sample the function N times.\nBayesian optimisation [2] assumes that f is a random variable itself and applies a probability distribution over it using a statistical model. Using a Gaussian process (GP) model, BO makes some prior assumptions about f encoded by the mean \u00b50(x) and covariance function k.\nRather than directly searching over f , BO uses an acquisition function h(x) as a guide to sequentially select input locations at which to observe f . The acquisition function uses the information provided by the GP prior and the observations of f to estimate an utility value for sampling f at a given x. So for each observation, BO queries the objective f at the location of highest utility according to the acquisition function, xt , such that:\nxt = argmax x\u2208S h(x) . (7)\nAfter observing f (xt), BO updates the GP\u2019s observations dataset with the new observation {xt ,zt} and proceeds to the next iteration, which improves its belief about f . After the GP update the algorithm proceeds, choosing another xt . The BO loop runs until a stopping criteria is satisfied, which is usually defined by a maximum budget of objective function observations. In the end of this process, BO obtains a model that approximates the objective function f and an estimate of its optimum location x\u2217.\nOne example of acquisition function that can be applied to problems involving robotics navigation is the distance-based upper confidence bound (DUCB) [10]:\nhDUCB(x|Dt\u22121) = \u00b5t\u22121(x)+\u03ba\u03c3t\u22121(x)\u2212 \u03b3d(xt\u22121,x) , (8)\nwhere d(xt\u22121,x) corresponds to the distance between the last sampled location and the candidate x, \u00b5t\u22121 and \u03c3t\u22121 are given by the GP posterior with the observations in Dt\u22121, and \u03ba > 0, \u03b3 > 0 are parameters to be set. In this sense, \u03ba controls the exploration-exploitation trade off, with higher values favouring areas of high uncer-\ntainty, while \u03b3 penalises large jumps, allowing shorter paths between observations. In addition, notice that for minimisation objectives, as in Equation 6, DUCB can be applied by simply flipping the sign of the GP posterior mean to negative instead.\nWhen the hyper-parameters of the GP model are unknown a priori, a few methods can also be applied to adapt them online as BO runs. One of the simplest, but usually effective, of them is to optimise the log-marginal likelihood of the GP [19] after each observation or after collecting a batch of observations. This optimisation can be done by performing a few steps of gradient descent on the hyper-parameters after the GP is updated."}, {"heading": "4 Bayesian optimisation under localisation uncertainty", "text": "In this section we present our framework for Bayesian optimisation under uncertain inputs. By inputs, we refer to points in the objective function f (Equation 6) input space, i.e. any x \u2208Rd . Input noise can affect both the execution of a query to observe the objective function and the location estimates of where these observations are taken, as we further explain in Section 4.2. In this sense, we first need to extend BO\u2019s surrogate model to incorporate uncertainty in the inputs. We propose to use a Gaussian process regression model with uncertain inputs [5] as a prior, which we then incorporate into BO to obtain a framework for optimisation under uncertain inputs. We start by explaining this GP model before going into details about the proposed BO approach."}, {"heading": "4.1 Gaussian process priors with uncertain inputs", "text": "Consider that, due to measurement and execution noise, when evaluating a function f at a desired input x\u2217 \u2208Rd , the actual input location x\u0303\u2217|x\u2217 \u223c P\u2217 where the observation is collected at is not directly observable, but we have access to some estimate of its probability distribution, here indicated by P\u2217. Assuming that f \u223c GP(\u00b50,k), the distribution over y\u0303\u2217 = f (x\u0303\u2217) under input noise is no longer Gaussian due to the non-linear relationship between the distribution of y|x, given by Equation 1, and x. Figure 1 presents an example of what can happen to the output distribution when f is highly non-linear. Therefore, the resulting stochastic process that represents f under random inputs is no longer Gaussian and lacking an analytic formulation [4,5]. However, as demonstrated in [3], based on the work of [5], we can still recover a Gaussian process approximation for f by using the mean and the covariance of the resulting stochastic process under the influence of input noise. In particular, in the case of a constant deterministic mean function \u00b50(x) = m0, the mean and the covariance of this noisy process are:\nEx\u0303\u2217\u223cP\u2217 [ f (x\u0303\u2217)] = m0 (9) CovPi,P j [y\u0303i, y\u0303 j] = EPi,P j [k(x\u0303i, x\u0303 j)] , (10)\nwhere it is assumed that x\u0303i and x\u0303 j are independent. Here E denotes expected value and Cov stands for covariance. Therefore, the expected covariance function is given by:\nEPi,P j [k(x\u0303i, x\u0303 j)] = \u222b\nx\u0303i\u2208Rd \u222b x\u0303 j\u2208Rd k(x\u0303i, x\u0303 j)dPi(x\u0303i)dP j(x\u0303 j) = kp(Pi,P j) . (11)\nDepending on the type of input distributions and the original kernel for deterministic inputs k(x,x\u2032), approximate and analytical solutions for Equation 11 may exist [3, 5, 17]. An example is the squared exponential kernel in Equation 2. If the input distributions are Gaussian, the resulting covariance function, according to [3], is given by:\nkp(N(ui,\u03a3i),N(u j,\u03a3 j)) = \u03c32f exp\n( \u2212 12 (ui\u2212u j) T(W+\u03a3i +\u03a3 j)\u22121(ui\u2212u j) )\n|I +W\u22121(\u03a3i +\u03a3 j)(1\u2212\u03b4i j)|1/2 ,\n(12) where \u03c32f and W are the same hyper-parameters as described for the standard squared exponential kernel in Equation 2.\nThe posterior of the stochastic process representing f \u223c GP(\u00b50,k) under input noise is not Gaussian due to the complicated forms of Equation 4 and Equation 5 with respect to x and X. Yet we can still obtain a suitable approximation [3,5] for the original f in the noisy input setting by doing inference over a GP with mean m0 and covariance function kp, as defined in Equation 11. This approximation is obtained as:\ny\u0303\u2217|D,P\u2217 \u223cN(m(P\u2217),v(P\u2217)) (13)\nwith\nm(P\u2217) = m0 +kT\u2217K\u22121D (z\u2212m0) (14) v(P\u2217) = kp(P\u2217,P\u2217)\u2212kT\u2217K\u22121D k\u2217 , (15)\nwhere m0 is an n-dimensional mean vector with the constant m0 as elements, k\u2217 = [kp(P\u2217,P1), . . . ,kp(P\u2217,Pn)]T, [KD]i j = kp(Pi,P j)+\u03b4i j\u03c32n , and \u03b4i j denotes the Kronecker delta."}, {"heading": "4.2 Bayesian optimisation under localisation uncertainty", "text": "To extend BO to the context of uncertain inputs in robotics, we first have to consider how input noise affects the BO process. In robotics problems involving location estimation, we can split input noise into two categories: localisation noise and execution noise. The first refers to noise affecting the location estimate provided by the robot\u2019s localisation system, usually due to imperfections in motion sensing and in other kinds of sensors, such as GPS devices. The second type, execution noise, is the combined effect of everything affecting the execution of the robot\u2019s path to a given target location, such as localisation noise, uncertain motion dynamics, etc.\nBO sequentially decides where to sample the function being modelled, such as terrain roughness, by using prior information from the observations it has collected in previous steps. In the BO context, execution noise determines the actual location at which an observation will be taken, while localisation noise affects the estimation of that location. Using an uncertain-inputs GP model, as defined in Section 4.1, allows us to take into account both execution and localisation noise in the BO algorithm. For instance, assuming additive zero-mean noise, given a target x, the actual location where the observation will be taken at iteration t is:\nx\u0303\u2217 = x+ \u03b5e , (16)\nwhere \u03b5e \u223c Pe represents execution noise. The query location can then be modelled as a random variable x\u0303\u2217 \u223c Px. In practice, we usually don\u2019t know the execution noise distribution Pe exactly, and consequently don\u2019t know Px. However, we can use an approximate querying distribution P\u0302x \u2248 Px to account for this uncertainty in the query process. Considering that, at each iteration t, the resulting BO loop should select as target location:\nxt = argmax x\u2208S h(P\u0302x) , (17)\nwhich is computed over the uncertain-inputs GP posterior. After observing the objective function, we assume that BO is provided with a distribution of the robot\u2019s location x\u0303t \u223c Pt , such that its mean estimator is:\nx\u0302t = EPt [x\u0303t ] = x\u0303 \u2217 t + \u03b5l,t , (18)\nwhere \u03b5 lt \u223c Pl represents localisation noise. Standard BO would utilise x\u0302t as the input to be added with the corresponding outcome zt into the observations dataset. However, if the localisation noise level is significant or if Pt is multi-modal, x\u0302t might not be a good estimator. Fortunately, the GP model in Section 4.1 allows us to use Pt directly in the observations dataset, mitigating these effects.\nAs Equation 17 requires, the acquisition function needs to be able to handle probability distributions as inputs by using the uncertain-inputs GP model. For some acquisition functions, such as UCB [23], it can be as straight forward as replacing x by Px and using the corresponding GP posterior mean m(Px) (Equation 14) and variance v(Px) (Equation 15). For others, some modifications need to be made. In the case of DUCB, a simple but effective modification to the distance-penalty term is to use the distance between the target location and the mean of the distribution of the last sampled location (EPt\u22121 [x\u0303t\u22121] = x\u0302t\u22121), i.e.:\nhDUCB(P\u0302x) = mt\u22121(P\u0302x)+\u03bav 1/2 t\u22121(P\u0302x)\u2212 \u03b3d(x\u0302t\u22121,x) . (19)"}, {"heading": "5 Experiments", "text": "In this section, we present experimental results obtained with our method for uncertain-inputs Bayesian optimisation (UIBO) in the presence of localisation uncertainty. In all cases, we used the DUCB acquisition function [10] to guide the exploration process. We compare our method against two other approaches. The first is standard BO, which does not consider any uncertainty in the location estimates. The second is unscented Bayesian optimisation (UBO) [15], which considers execution noise by means of the unscented transform [25], but assumes that the location estimate of the observation is accurate."}, {"heading": "5.1 Simulations", "text": "We performed simulations using randomly-generated 2D functions as a model for terrain roughness to be learnt by BO. The task is for the robot to learn a model of the terrain roughness while staying away from areas of high vibration, which can cause damage to the robot. This model should then be more accurate over areas of lower terrain roughness, which are more interesting in practice.\nFor each test, a function is drawn from a Hilbert space [20] with the reproducing kernel defined as the input-noise-free covariance function and combined with a constant mean to keep vibration values positive. In our case, we used the squared exponential (see Equation 2) and its uncertain-inputs equivalent (Equation 12) as covariance functions. To simulate input noise, we sample execution noise from a Gaussian N(0,\u03c32e I) and localisation noise from another Gaussian N(0,\u03c32l I). The querying distribution applied by UIBO is set to also be Gaussian, P\u0302x =N(x,\u03c32x I), and\nis the same distribution as applied by unscented BO (UBO). We set \u03c3e = \u03c3l = 0.07 and \u03c3x = 0.1. Besides input noise, observation noise was set to \u03c3n = 0.1. For DUCB\u2019s parameters, we set \u03ba = 10 and \u03b3 = 2 for the three versions of BO, which were manually tuned. The hyper-parameters for the GP models were fixed and identical for each BO method.\nIn the simulations, we also compared each BO approach using maximum entropy search (ES) as heuristics. These heuristics seek only to reduce the entropy of the corresponding GP posterior, choosing to visit areas of high uncertainty to gain information. ES methods should provide a baseline for comparisons, as they do not consider any estimate of the expected vibration in their search. Following ES guidance, the robot should experience high amounts of vibration and long paths. For fair comparisons, the methods based on deterministic-inputs GP models used the equivalent noise-free version of the uncertain-inputs GP covariance function and the same DUCB parameters, since these do not affect the GP model.\nFigure 2 presents results obtained in simulation. As seen in the test case in Figure 2a, standard BO and UBO using DUCB end up having a much more exploratory behaviour due to noise, which leads the robot to execute long paths over the terrain. UIBO, on the other hand, is able to focus its exploration on areas of lower vibration intensity. Overall, Figure 2b shows that UIBO is able to monotonically improve over iterations, finding areas of low vibration for the robot to navigate through. Both the standard and the unscented versions of BO ended up having an average performance much similar to pure entropy search. As entropy-based methods are purely exploratory, there is no improvement in terms of mean experienced vibration, since the algorithm is not optimising for that. In the case of BO-DUCB and UBO-DUCB, the uncertainty in localisation corrupts the location estimates in the observations dataset, and this effect is not taken into account by the GP model. As a result, both methods are misled into areas close to locations that they previously observed, ending up into this more exploratory behaviour, instead of exploiting previous information.\nTable 1 presents a summary of the final performance in terms of different metrics for each method. The root mean square error (RMSE) and weighted RMSE (WRMSE) [10] values are computed from the corresponding GP posterior mean and the groundtruth values deterministically-queried over a uniform grid covering the entire search space. In our case, the WRMSE emphasises the error in areas of lower vibration, being a better performance indicator for this experiment\u2019s task than the plain RMSE, since we are more interested in finding areas of lower vibration. As seen in Table 1, UIBO is able to outperform the other methods when using DUCB, obtaining a good model of the terrain roughness while travelling the smallest distance and experiencing the least amount of vibration. Entropy search using the uncertain-inputs GP was able to obtain the smallest RMSE and WRMSE values, but required a much longer distance to be travelled under the cost of high vibration. In general, in terms of mean experienced vibration, BO and UBO methods performed worse due to the high amounts of localisation noise, which led them to behave similar to ES. These results indicate that UIBO is able to effectively take into account the uncertainty in localisation, keeping the robot safe while exploring an unknown environment."}, {"heading": "5.2 Experiments with a real robot", "text": "We performed experiments with a physical robot outdoors to test the performance of the proposed uncertain-inputs BO approach against standard BO with DUCB as in [22]. The purpose of this experiment is to highlight the differences in performance and\nin behaviour between both BO approaches when faced with localisation uncertainty in a real-world scenario."}, {"heading": "5.2.1 Experimental setup", "text": "Our test platform was a small four-wheeled skid-steer robot, depicted in Figure 3. The robot is equipped with an on-board computer running ROS 1. The tests were performed in an area with terrain covered by grass and with some portions of harder ground exposed. The goal of the robot is to obtain a model of the terrain roughness based on vibration measurements. As in simulations, the robot should be able to obtain a good model while avoiding rougher areas, which cause high vibration. In this scenario, excessive vibration can cause damage to the robot or affect its ability to perceive the environment.\nOur robot was equipped with an IMU sensor, placed on top of its chassis. With the robot moving, vibration shows up mostly as linear acceleration along the robot\u2019s vertical axis, bouncing the robot up and down to the ground. We considered different methods to measure vibration from a fixed moving window of acceleration measurements. In particular, we considered the mean and the root mean square values. As we want the robot to avoid areas of high vibration, the RMS value demonstrated itself to be a better estimator, since it grows with the amplitude of the vibration, as pictured in Figure 4. The mean, on the other hand, should be always around zero, as each upwards acceleration is immediately compensated by a downwards drop of the robot.\nAs observations for the BO algorithms, the RMS value was measured at a fixed window of 200 measurements when the robot is moving. These observations were combined with location estimates from an extended Kalman filter (EKF) [14], which was configured to fuse wheel odometry, IMU and GPS. As the robot is moving continuously at a bounded maximum speed of 0.5 m/s, instead of at discrete jumps, observations are collected at a rate of 2 Hz in the field experiments, instead of at the\n1 The Robot Operating System: www.ros.org\nend of each BO iteration, as in simulations. All the observations collected between one iteration and the next one are then added to the GP model, before BO selects the next target location to visit.\nWe ran both BO and UIBO for a fixed time budget of 150 seconds. Their search space was set as a rectangular region of 6 by 14 metres. At each iteration, the robot drove autonomously attempting to follow straight paths from its previous goal to the next goal, as given by the BO planner. The iteration was signalled as finished whenever the robot arrived within a given radius from the goal. After that, the GP model updated, the hyper-parameters adapted, and the planner selects a new goal. As the sample rate of observations is relatively low, both BO methods are able to repeatedly execute this process online in close to real time. The DUCB acquisition function was configured with an uncertainty factor \u03ba = 10 and a distance factor \u03b3 = 1. UIBO applied as query distribution an isotropic Gaussian with variance \u03c32x = 2 for each coordinate."}, {"heading": "5.2.2 Performance", "text": "Figure 5 presents the GP model obtained by each BO method. We also collected a set of vibration measurements by manually driving the robot in the area of the experiments. For this validation set, a real time kinematic GPS 2 device was used for high-precision location estimates. These measurements were only used for the purposes of validation, and not passed on to the BO methods, which relied solely on a conventional GPS device fused into an EKF to estimate location, which yielded an uncertainty of a bit less than a metre.\nFor both methods, the robot was placed at an initial position at the top left corner of the search space. As Figure 5a shows, UIBO is able to follow a path that\n2 https://emlid.com/reach/\nquickly spreads itself through the search space and avoids areas of high vibration, thus yielding less model uncertainty in areas of lower vibration (see Figure 5b). On the other hand, standard BO ends up too focused on exploring the top portion of the search space, near where the robot started, following a path that is more concentrated and passes more often by areas that cause higher vibration, which is confirmed by the performance summary in Table 2. In this table, the WRMSE value is computed based on predictions from the final GP models for the observations in the validation set. This set was composed of measurements that concentrate on the top half of the search space, thus the lower standard deviation in the model over that area. Therefore, it should favour standard BO in the WRMSE-based performance comparisons. However, according to Table 2, we can see that, for this experiment, UIBO is able to outperform BO by producing a better model while experiencing less vibration and following a shorter path. Therefore, this fact, which was previously observed in the simulations, is also confirmed in a physical environment."}, {"heading": "6 Conclusion", "text": "In this paper, we presented a new method to Bayesian optimisation for active learning problems in robotics in the cases where uncertainty in the location estimates is significant. The proposed method provides a principled way to consider this uncertainty in the inputs of a Gaussian process model, which is applied as a prior by the BO algorithm. Execution noise is also considered by means of a query distribution when optimising BO\u2019s acquisition function. The method was proved to outperform other BO approaches in simulation and in an experiment with a physical robot. Therefore, the proposed method can be applied to problems where we are interested in mapping the traversability of a terrain, but need to keep the robot safe in the midst of localisation uncertainty.\nSome topics were not addressed by this paper but are worthy of future research work. One of them is the estimation of execution noise, which could be done in an online way by other statistical methods, for example, using maximum likelihood estimates for the parameters of a given distribution. Another topic is the extension of the DUCB-based exploration to continuous path planning, as in [11]. For that, however, a method to propagate execution noise through a candidate path would have to be developed taking into account many hard-to-model factors from both the robot and the environment, such as stochastic motion dynamics and imperfections in sensor noise."}], "references": [{"title": "Theory of Reproducing Kernels", "author": ["N. Aronszajn"], "venue": "Transactions of the American Mathematical Society 68(3), 337\u2013404", "citeRegEx": "1", "shortCiteRegEx": null, "year": 1950}, {"title": "A Tutorial on Bayesian Optimization of Expensive Cost Functions, with Application to Active User Modeling and Hierarchical Reinforcement Learning", "author": ["E. Brochu", "V.M. Cora", "N. de Freitas"], "venue": "Tech. rep., University of British Columbia", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2010}, {"title": "An approximate inference with Gaussian process to latent functions from uncertain data", "author": ["P. Dallaire", "C. Besse", "B. Chaib-Draa"], "venue": "Neurocomputing 74, 1945\u20131955", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2011}, {"title": "Variational Inference for Latent Variables and Uncertain Inputs in Gaussian Processes", "author": ["A.C. Damianou", "M.K. Titsias", "N.D. Lawrence"], "venue": "Journal of Machine Learning Research 17(1), 1\u201362", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2016}, {"title": "Approximate methods for propagation of uncertainty with Gaussian process models", "author": ["A. Girard"], "venue": "Ph. d, University of Glasgow", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2004}, {"title": "Traversability estimation for a planetary rover via experimental kernel learning in a Gaussian process framework", "author": ["K. Ho", "T. Peynot", "S. Sukkarieh"], "venue": "IEEE International Conference on Robotics and Automation (ICRA). pp. 3475\u20133482. IEEE, Karlsruhe, Germany", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2013}, {"title": "Adaptive bayesian filtering for vibration-based terrain classification", "author": ["P. Komma", "C. Weiss", "A. Zell"], "venue": "Proceedings - IEEE International Conference on Robotics and Automation. pp. 3307\u20133313. IEEE, Kobe, Japan", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2009}, {"title": "Adaptive non-stationary kernel regression for terrain modelling", "author": ["T. Lang", "C. Plagemann", "W. Burgard"], "venue": "Burgard, W., Brock, O., Stachniss, C. (eds.) Proc. of the Robotics: Science and Systems Conference (RSS). Atlanta, GA", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2007}, {"title": "Curvature continuous path generation for autonomous vehicle using B-spline curves", "author": ["T. Maekawa", "T. Noda", "S. Tamura", "T. Ozaki", "Machida", "K.i."], "venue": "Computer-Aided Design 42(4), 350\u2013359", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2010}, {"title": "Bayesian Optimisation for Intelligent Environmental Monitoring", "author": ["R. Marchant", "F. Ramos"], "venue": "IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS). IEEE", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2012}, {"title": "Bayesian Optimisation for Informative Continuous Path Planning", "author": ["R. Marchant", "F. Ramos"], "venue": "IEEE International Conference on Robotics and Automation (ICRA). pp. 6136\u20136143", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2014}, {"title": "Building Large Scale Traversability Maps Using Vehicle Experience", "author": ["S. Martin", "L. Murphy", "P. Corke"], "venue": "The 13th International Symposium on Experimental Robotics (ISER). vol. 88, pp. 891\u2013905. Springer", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2013}, {"title": "Gaussian Process Training with Input Noise", "author": ["A. Mchutchon", "C.E. Rasmussen"], "venue": "Advances in Neural Information Processing Systems. pp. 1341\u20131349", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2011}, {"title": "A generalized extended kalman filter implementation for the robot operating system", "author": ["T. Moore", "D. Stouch"], "venue": "Proceedings of the 13th International Conference on Intelligent Autonomous Systems (IAS-13). Springer", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2014}, {"title": "Unscented Bayesian Optimization for Safe Robot Grasping", "author": ["J. Nogueira", "R. Martinez-Cantin", "A. Bernardino", "L. Jamone"], "venue": "IEEE International Conference on Robotics and Automation (ICRA). pp. 1967\u20131972. Daejeon, Korea", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2016}, {"title": "Mobile Robot Traversability Mapping", "author": ["P. Nordin"], "venue": "Licentiate thesis, Link\u00f6ping University", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2012}, {"title": "Gaussian process occupancy maps", "author": ["S.T. O\u2019Callaghan", "F.T. Ramos"], "venue": "The International Journal of Robotics Research (IJRR) 31(1), 42\u201362", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2012}, {"title": "Active Perception for Modelling Energy Consumption in OffRoad Navigation", "author": ["R. Oliveira", "L. Ott", "F. Ramos"], "venue": "Australasian Conference on Robotics and Automation (ACRA). Brisbane, QLD, Australia", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2016}, {"title": "Gaussian Processes for Machine Learning", "author": ["C.E. Rasmussen", "C.K.I. Williams"], "venue": "The MIT Press, Cambridge, MA", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2006}, {"title": "Learning with kernels: support vector machines, regularization, optimization, and beyond", "author": ["B. Sch\u00f6lkopf", "A.J. Smola"], "venue": "MIT press", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2002}, {"title": "Practical bayesian optimization of machine learning algorithms", "author": ["J. Snoek", "H. Larochelle", "R.P. Adams"], "venue": "Pereira, F., Burges, C.J.C., Bottou, L., Weinberger, K.Q. (eds.) Advances in Neural Information Processing Systems 25, pp. 2951\u20132959. Curran Associates, Inc.", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2012}, {"title": "Bayesian Optimisation for Active Perception and Smooth Navigation", "author": ["J.R. Souza", "R. Marchant", "L. Ott", "D.F. Wolf", "F. Ramos"], "venue": "IEEE International Conference on Robotics and Automation (ICRA)", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2014}, {"title": "Information-Theoretic Regret Bounds for Gaussian Process Optimization in the Bandit Setting", "author": ["N. Srinivas", "A. Krause", "S.M. Kakade", "M.W. Seeger"], "venue": "IEEE Transactions on Information Theory 58(5), 1\u201316", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2012}, {"title": "Efficient in-field plant phenomics for row-crops with an autonomous ground vehicle", "author": ["J. Underwood", "A. Wendel", "B. Schofield", "L. McMurray", "R. Kimber"], "venue": "Journal of Field Robotics", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2017}, {"title": "The Unscented Kalman Filter for Nonlinear Estimation", "author": ["E.A. Wan", "R. van der Merwe"], "venue": "Adaptive Systems for Signal Processing, Communications, and Control Symposium (ASSPCC). pp. 153\u2013158", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2000}, {"title": "Using Trajectory Data to Improve Bayesian Optimization for Reinforcement Learning", "author": ["A. Wilson", "A. Fern", "P. Tadepalli"], "venue": "Journal of Machine Learning Research 15, 253\u2013282", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2014}], "referenceMentions": [{"referenceID": 8, "context": "Mobile robots have been successfully applied to many field applications, such as mining [9], planetary exploration [8], agriculture [24], and environmental monitoring [10], to name a few.", "startOffset": 88, "endOffset": 91}, {"referenceID": 7, "context": "Mobile robots have been successfully applied to many field applications, such as mining [9], planetary exploration [8], agriculture [24], and environmental monitoring [10], to name a few.", "startOffset": 115, "endOffset": 118}, {"referenceID": 23, "context": "Mobile robots have been successfully applied to many field applications, such as mining [9], planetary exploration [8], agriculture [24], and environmental monitoring [10], to name a few.", "startOffset": 132, "endOffset": 136}, {"referenceID": 9, "context": "Mobile robots have been successfully applied to many field applications, such as mining [9], planetary exploration [8], agriculture [24], and environmental monitoring [10], to name a few.", "startOffset": 167, "endOffset": 171}, {"referenceID": 21, "context": "In the case of ground robots, terrain roughness can affect the ability of a robot to navigate and even cause damage to its on-board hardware due to excessive vibration [22].", "startOffset": 168, "endOffset": 172}, {"referenceID": 7, "context": "To aid in these problems, methods to enable the robot to automatically learn terrain properties from its sensory data have been presented in the literature [8, 18, 22].", "startOffset": 156, "endOffset": 167}, {"referenceID": 17, "context": "To aid in these problems, methods to enable the robot to automatically learn terrain properties from its sensory data have been presented in the literature [8, 18, 22].", "startOffset": 156, "endOffset": 167}, {"referenceID": 21, "context": "To aid in these problems, methods to enable the robot to automatically learn terrain properties from its sensory data have been presented in the literature [8, 18, 22].", "startOffset": 156, "endOffset": 167}, {"referenceID": 1, "context": "\u2022 a framework to account for input uncertainty in Bayesian optimisation [2] for mission planning; and \u2022 an adaptation of the DUCB [10] acquisition function to the context of exploration under uncertain localisation.", "startOffset": 72, "endOffset": 75}, {"referenceID": 9, "context": "\u2022 a framework to account for input uncertainty in Bayesian optimisation [2] for mission planning; and \u2022 an adaptation of the DUCB [10] acquisition function to the context of exploration under uncertain localisation.", "startOffset": 130, "endOffset": 134}, {"referenceID": 18, "context": "In our method, we apply an extension of the conventional Gaussian process (GP) [19] regression models to contexts involving input uncertainty [5] as priors for the BO framework.", "startOffset": 79, "endOffset": 83}, {"referenceID": 4, "context": "In our method, we apply an extension of the conventional Gaussian process (GP) [19] regression models to contexts involving input uncertainty [5] as priors for the BO framework.", "startOffset": 142, "endOffset": 145}, {"referenceID": 21, "context": "We apply the proposed method to the task of learning a model of terrain roughness from experienced vibration data, as in [22].", "startOffset": 121, "endOffset": 125}, {"referenceID": 15, "context": "In robotics, terrain traversability is usually estimated from either LIDAR range measurements [16] or stereo vision information [6].", "startOffset": 94, "endOffset": 98}, {"referenceID": 5, "context": "In robotics, terrain traversability is usually estimated from either LIDAR range measurements [16] or stereo vision information [6].", "startOffset": 128, "endOffset": 131}, {"referenceID": 15, "context": "Among the different kinds of metrics, terrain roughness can play an important role in planning how a robot should navigate on the terrain [16].", "startOffset": 138, "endOffset": 142}, {"referenceID": 6, "context": "Methods to learn terrain roughness using image data usually rely on learning image classification models [7], which generally do not provide a measure of how uncertain they are about their estimates", "startOffset": 105, "endOffset": 108}, {"referenceID": 11, "context": "In [12], however, the authors propose using vehicle experience data to learn a Gaussian process (GP) regression model [19] to predict terrain traversability with uncertainty estimates.", "startOffset": 3, "endOffset": 7}, {"referenceID": 18, "context": "In [12], however, the authors propose using vehicle experience data to learn a Gaussian process (GP) regression model [19] to predict terrain traversability with uncertainty estimates.", "startOffset": 118, "endOffset": 122}, {"referenceID": 5, "context": "Though restrictive when compared to 3D range sensing information, as pointed out in [6], proprioceptive sensing can still be a very viable option for traversability estimation with robots that are not equipped with stereo vision or 3D LIDAR sensors, or do not possess the computational resources to process this kind of information on-board online.", "startOffset": 84, "endOffset": 87}, {"referenceID": 21, "context": "[22] presented a method to learn a GP model for terrain roughness from vehicle experience.", "startOffset": 0, "endOffset": 4}, {"referenceID": 1, "context": "The authors applied Bayesian optimisation (BO) [2] in an active perception approach to reduce experienced vibration during navigation while learning the model from IMU measurements online.", "startOffset": 47, "endOffset": 50}, {"referenceID": 1, "context": "In the BO framework, the terrain roughness model is learnt online as the algorithm drives the robot around selecting locations to visit balancing a trade-off between exploration and exploitation [2, 22].", "startOffset": 195, "endOffset": 202}, {"referenceID": 21, "context": "In the BO framework, the terrain roughness model is learnt online as the algorithm drives the robot around selecting locations to visit balancing a trade-off between exploration and exploitation [2, 22].", "startOffset": 195, "endOffset": 202}, {"referenceID": 20, "context": "Nevertheless, BO usually considers deterministic query locations within its search space, as BO is typically used in problems where a fixed number of parameters have to be optimised, such as in [21, 26].", "startOffset": 194, "endOffset": 202}, {"referenceID": 25, "context": "Nevertheless, BO usually considers deterministic query locations within its search space, as BO is typically used in problems where a fixed number of parameters have to be optimised, such as in [21, 26].", "startOffset": 194, "endOffset": 202}, {"referenceID": 14, "context": "Recent work [15] presented a method to apply BO to problems where the execution of a query is uncertain, such as robotic grasping.", "startOffset": 12, "endOffset": 16}, {"referenceID": 24, "context": "The authors propose querying BO\u2019s surrogate model using a Gaussian distribution by applying the unscented transform [25].", "startOffset": 116, "endOffset": 120}, {"referenceID": 14, "context": "Despite this [15] still assumes that the actual query point can be precisely measured after the sampling, which makes the assumption that the location estimates in the GP observations dataset are deterministic.", "startOffset": 13, "endOffset": 17}, {"referenceID": 18, "context": "In BO the most common approach to modelling the objective function is using Gaussian process (GP) regression [19].", "startOffset": 109, "endOffset": 113}, {"referenceID": 4, "context": "In the case of uncertain input observations, the work in [5] proposed methods to propagate input uncertainty through a GP model, developing analytical approximations to compute covariance function values between inputs represented as Gaussian distributions.", "startOffset": 57, "endOffset": 60}, {"referenceID": 12, "context": "Another approach is considered in [13], where the input location estimates are assumed to be corrupted by i.", "startOffset": 34, "endOffset": 38}, {"referenceID": 3, "context": "Finally, a more general framework is presented in [4], where the true unobserved inputs of the GP model are considered as latent variables and a variational inference framework is applied to compute the", "startOffset": 50, "endOffset": 53}, {"referenceID": 18, "context": "Gaussian process regression [19] is a Bayesian non-parametric framework that places a Gaussian distribution as a prior over the space of functions f , mapping inputs x \u2208 Rd to outputs y \u2208 R.", "startOffset": 28, "endOffset": 32}, {"referenceID": 0, "context": "In a similar way to a conventional Gaussian distribution, a GP model needs to specify the mean and the covariance for any given pair of values in its vector space, which for a GP is a reproducing kernel Hilbert space (RKHS) [1, 19].", "startOffset": 224, "endOffset": 231}, {"referenceID": 18, "context": "In a similar way to a conventional Gaussian distribution, a GP model needs to specify the mean and the covariance for any given pair of values in its vector space, which for a GP is a reproducing kernel Hilbert space (RKHS) [1, 19].", "startOffset": 224, "endOffset": 231}, {"referenceID": 1, "context": "Bayesian optimisation [2] assumes that f is a random variable itself and applies a probability distribution over it using a statistical model.", "startOffset": 22, "endOffset": 25}, {"referenceID": 9, "context": "One example of acquisition function that can be applied to problems involving robotics navigation is the distance-based upper confidence bound (DUCB) [10]:", "startOffset": 150, "endOffset": 154}, {"referenceID": 18, "context": "One of the simplest, but usually effective, of them is to optimise the log-marginal likelihood of the GP [19] after each observation or after collecting a batch of observations.", "startOffset": 105, "endOffset": 109}, {"referenceID": 4, "context": "We propose to use a Gaussian process regression model with uncertain inputs [5] as a prior, which we then incorporate into BO to obtain a framework for optimisation under uncertain inputs.", "startOffset": 76, "endOffset": 79}, {"referenceID": 3, "context": "Therefore, the resulting stochastic process that represents f under random inputs is no longer Gaussian and lacking an analytic formulation [4,5].", "startOffset": 140, "endOffset": 145}, {"referenceID": 4, "context": "Therefore, the resulting stochastic process that represents f under random inputs is no longer Gaussian and lacking an analytic formulation [4,5].", "startOffset": 140, "endOffset": 145}, {"referenceID": 2, "context": "However, as demonstrated in [3], based on the work of [5], we can still recover a Gaussian process approximation for f by using the mean and the covariance of the resulting stochastic process under the influence of input noise.", "startOffset": 28, "endOffset": 31}, {"referenceID": 4, "context": "However, as demonstrated in [3], based on the work of [5], we can still recover a Gaussian process approximation for f by using the mean and the covariance of the resulting stochastic process under the influence of input noise.", "startOffset": 54, "endOffset": 57}, {"referenceID": 2, "context": "Depending on the type of input distributions and the original kernel for deterministic inputs k(x,x\u2032), approximate and analytical solutions for Equation 11 may exist [3, 5, 17].", "startOffset": 166, "endOffset": 176}, {"referenceID": 4, "context": "Depending on the type of input distributions and the original kernel for deterministic inputs k(x,x\u2032), approximate and analytical solutions for Equation 11 may exist [3, 5, 17].", "startOffset": 166, "endOffset": 176}, {"referenceID": 16, "context": "Depending on the type of input distributions and the original kernel for deterministic inputs k(x,x\u2032), approximate and analytical solutions for Equation 11 may exist [3, 5, 17].", "startOffset": 166, "endOffset": 176}, {"referenceID": 2, "context": "If the input distributions are Gaussian, the resulting covariance function, according to [3], is given by:", "startOffset": 89, "endOffset": 92}, {"referenceID": 2, "context": "Yet we can still obtain a suitable approximation [3,5] for the original f in the noisy input setting by doing inference over a GP with mean m0 and covariance function kp, as defined in Equation 11.", "startOffset": 49, "endOffset": 54}, {"referenceID": 4, "context": "Yet we can still obtain a suitable approximation [3,5] for the original f in the noisy input setting by doing inference over a GP with mean m0 and covariance function kp, as defined in Equation 11.", "startOffset": 49, "endOffset": 54}, {"referenceID": 22, "context": "For some acquisition functions, such as UCB [23], it can be as straight forward as replacing x by Px and using the corresponding GP posterior mean m(Px) (Equation 14) and variance v(Px) (Equation 15).", "startOffset": 44, "endOffset": 48}, {"referenceID": 9, "context": "In all cases, we used the DUCB acquisition function [10] to guide the exploration process.", "startOffset": 52, "endOffset": 56}, {"referenceID": 14, "context": "The second is unscented Bayesian optimisation (UBO) [15], which considers execution noise by means of the unscented transform [25], but assumes that the location estimate of the observation is accurate.", "startOffset": 52, "endOffset": 56}, {"referenceID": 24, "context": "The second is unscented Bayesian optimisation (UBO) [15], which considers execution noise by means of the unscented transform [25], but assumes that the location estimate of the observation is accurate.", "startOffset": 126, "endOffset": 130}, {"referenceID": 19, "context": "For each test, a function is drawn from a Hilbert space [20] with the reproducing kernel defined as the input-noise-free covariance function and combined with a constant mean to keep vibration values positive.", "startOffset": 56, "endOffset": 60}, {"referenceID": 9, "context": "The root mean square error (RMSE) and weighted RMSE (WRMSE) [10] values are computed from the corresponding GP posterior mean and the groundtruth values deterministically-queried over a uniform grid covering the entire search space.", "startOffset": 60, "endOffset": 64}, {"referenceID": 21, "context": "We performed experiments with a physical robot outdoors to test the performance of the proposed uncertain-inputs BO approach against standard BO with DUCB as in [22].", "startOffset": 161, "endOffset": 165}, {"referenceID": 13, "context": "These observations were combined with location estimates from an extended Kalman filter (EKF) [14], which was configured to fuse wheel odometry, IMU and GPS.", "startOffset": 94, "endOffset": 98}, {"referenceID": 10, "context": "Another topic is the extension of the DUCB-based exploration to continuous path planning, as in [11].", "startOffset": 96, "endOffset": 100}], "year": 2017, "abstractText": "In outdoor environments, mobile robots are required to navigate through terrain with varying characteristics, some of which might significantly affect the integrity of the platform. Ideally, the robot should be able to identify areas that are safe for navigation based on its own percepts about the environment while avoiding damage to itself. Bayesian optimisation (BO) has been successfully applied to the task of learning a model of terrain traversability while guiding the robot through more traversable areas. An issue, however, is that localisation uncertainty can end up guiding the robot to unsafe areas and distort the model being learnt. In this paper, we address this problem and present a novel method that allows BO to consider localisation uncertainty by applying a Gaussian process model for uncertain inputs as a prior. We evaluate the proposed method in simulation and in experiments with a real robot navigating over rough terrain and compare it to standard BO methods which assume deterministic inputs.", "creator": "LaTeX with hyperref package"}}}