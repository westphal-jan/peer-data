{"id": "1003.0034", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "26-Feb-2010", "title": "A New Understanding of Prediction Markets Via No-Regret Learning", "abstract": "we explore the striking mathematical connections that exist between futures scoring rules, cost function based prediction markets, providing no - biased learning. we show that any cost function based prediction market can be interpreted as an algorithm for the commonly studied problem of learning from bias advice as reporting trades made in the market weighted losses observed by the learning algorithm. if the loss of the market organizer is bounded, this bound can be used to derive an o ( pr ( t ) ) regret bound for choosing corresponding learning algorithm. we then show that the roles of markets with convex cost functions exactly opposing to the class of follow the regularized leader learning algorithms, with the choice of a cost function toward the field corresponding to the choice beyond a regularizer in the learning problem. still, we show an equivalence separating market scoring rules and prediction markets with convex cost functions. this implies that market scoring rules can also be interpreted naturally and follow the regularized leader algorithms, and may be on positive influence. these connections provide new insight into how it is that commonly studied markets, such as the logarithmic market timing rule, can aggregate opinions into accurate data of the likelihood of future events.", "histories": [["v1", "Fri, 26 Feb 2010 23:27:22 GMT  (40kb,S)", "http://arxiv.org/abs/1003.0034v1", null]], "reviews": [], "SUBJECTS": "cs.AI cs.LG", "authors": ["yiling chen", "jennifer wortman vaughan"], "accepted": false, "id": "1003.0034"}, "pdf": {"name": "1003.0034.pdf", "metadata": {"source": "CRF", "title": "A New Understanding of Prediction Markets Via No-Regret Learning", "authors": ["Yiling Chen", "Jennifer Wortman Vaughan"], "emails": ["yiling@eecs.harvard.edu", "jenn@seas.harvard.edu"], "sections": [{"heading": null, "text": "ar X\niv :1\n00 3.\n00 34\nv1 [\ncs .A\nI] 2\n6 Fe\nb 20\n10\n\u221a T ) regret bound for the corresponding\nlearning algorithm. We then show that the class of markets with convex cost functions exactly corresponds to the class of Follow the Regularized Leader learning algorithms, with the choice of a cost function in the market corresponding to the choice of a regularizer in the learning problem. Finally, we show an equivalence between market scoring rules and prediction markets with convex cost functions. This implies that market scoring rules can also be interpreted naturally as Follow the Regularized Leader algorithms, and may be of independent interest. These connections provide new insight into how it is that commonly studied markets, such as the Logarithmic Market Scoring Rule, can aggregate opinions into accurate estimates of the likelihood of future events."}, {"heading": "1. INTRODUCTION", "text": "Imagine you are interested in learning an accurate estimate of the probability that the United States unemployment rate for a particular month will fall below 10%. You could choose to spend hours digging through news articles, reading financial reports, and weighing various opinions against each other, eventually coming up with a reasonably informed estimate. However, you could potentially save yourself a lot of hassle (and obtain a better estimate!) by appealing to the wisdom of crowds.\nA prediction market is a financial market designed for information aggregation. For example, in a cost function based prediction market [5], the organizer (ormarket maker) trades a set of securities corresponding to each potential outcome of an event. The market maker might offer a security that pays $1 if and only if the United States unemployment rate for January 2010 is above 10%. A risk neutral trader who believes that the true probability that the unemployment rate will be above 10% is p should be willing to buy a share of this security at any price below $p. Similarly, he should be willing to sell a share of this security at any price above $p. For this reason, the current market price of this security can be viewed as the population\u2019s collective estimate of how likely it is that the unemployment rate will\nbe above 10%. These estimates have proved quite accurate in practice in a wide variety of domains. (See Ledyard et al. [27] for an impressive assortment of examples.) The theory of rational expectations equilibria offers some insight into why prediction markets in general should converge to accurate prices, but is plagued by strong assumptions and no-trade theorems [31]. Furthermore, this theory says nothing of why particular prediction market mechanisms, such as Hanson\u2019s increasingly popular Logarithmic Market Scoring Rule (LMSR) [15, 16], might produce more accurate estimates than others in practice. In this work, we aim to provide additional insight into the learning power of particular market mechanisms by highlighting the deep mathematical connections between prediction markets and no-regret learning.\nIt should come as no surprise that there is a connection between prediction markets and learning. The theories of markets and learning are built upon many of the same fundamental concepts, such as proper scoring rules (called proper losses in the learning community) and Bregman divergences. To our knowledge, Chen et al. [6] were the first to formally demonstrate a connection, showing that the standard Randomized Weighted Majority regret bound [9] can be used as a starting point to rederive the well-known bound on the worst-case loss of a LMSR marker maker. (They went on to show that PermELearn, an extension of Weighted Majority to permutation learning [20], can be used to efficiently run LMSR over combinatorial outcome spaces for betting on rankings.) As we show in Section 4, the converse is also true; the Weighted Majority regret bound can be derived directly from the bound on the worst-case loss of a market maker using LMSR. However, the connection goes much deeper.\nIn Section 4, we show how any cost function based prediction market with bounded loss can be interpreted as a no-regret learning algorithm. Furthermore, if the loss of the market maker is bounded, this bound can be used to derive an O( \u221a T ) regret bound for the corresponding learning algorithm. The key ides is to view the trades made in the market as losses observed by the learning algorithm. We can then think of the market maker as learning a probability distribution over outcomes by treating each observed trade as a training instance.\nIn Section 5, we go on to show that the class of convex cost function based markets exactly corresponds to the class of Follow the Regularized Leader learning algorithms [34, 18, 17] in which weights are chosen at each time step to minimize a combination of empirical loss and a convex regularization term. This allows us to interpret the se-\nlection of a cost function for the market as the selection of a regularizer for the learning problem. Furthermore, we prove an equivalence between another common class of prediction markets, market scoring rules, and convex cost function based markets,1 which immediately implies that market scoring rules can be interpreted as Follow the Regularized Leader algorithms too. These connections provide insight into why it is that prediction markets tend to yield such accurate estimates in practice.\nBefore describing our results in more detail, we review the relevant concepts and results from the literature on prediction markets and no-regret learning in Sections 2 and 3."}, {"heading": "2. PREDICTION MARKETS", "text": "In recent years, a variety of compelling prediction market mechanisms have been proposed and studied, including standard call market mechanisms and Pennock\u2019s dynamic parimutuel markets [30]. In this work we focus on two broad classes of mechanisms: Hanson\u2019s market scoring rules [15, 16] and cost function based prediction markets as described in Chen and Pennock [5]. We also briefly discuss the related class of Sequential Convex Parimutuel Mechanisms [1] in Section 5.4."}, {"heading": "2.1 Market Scoring Rules", "text": "Scoring rules have long been used in the evaluation of probabilistic forecasts. In the context of prediction markets and elicitation, scoring rules are used to encourage individuals to make careful assessments and truthfully report their beliefs [33, 11, 26]. In the context of machine learning, scoring rules are used as loss functions to evaluate and compare the performance of different algorithms [3, 32].\nFormally, let {1, \u00b7 \u00b7 \u00b7 , N} be a set of mutually exclusive and exhaustive outcomes of a future event. A scoring rule ~smaps a probability distribution ~p to a score si(~p) for each outcome i, with si(~p) taking values in the extended real line [\u2212\u221e,\u221e]. Intuitively, this score represents the reward of a forecaster might receive for predicting the distribution ~p if the outcome turns out to be i. A scoring rule is said to be regular relative to the probability simplex \u2206N if \u2211N i=1 pisi(~p\n\u2032) \u2208 [\u2212\u221e,\u221e) for all ~p, ~p \u2032 \u2208 \u2206N , with \u2211N i=1 pisi(~p) \u2208 (\u2212\u221e,\u221e). This implies that si(~p) is finite whenever pi > 0. A scoring rule is said to be proper if a risk-neutral forecaster who believes the true distribution over outcomes to be ~p has no incentive to report any alternate distribution ~p \u2032, that is, if \u2211N\ni=1 pisi(~p) \u2265 \u2211N i=1 pisi(~p \u2032) for all distributions ~p \u2032. The rule is strictly proper if this inequality holds with equality only when ~p = ~p \u2032.\nTwo examples of regular, strictly proper scoring rules commonly used in both elicitation and in machine learning are the the quadratic scoring rule [2]:\nsi(~p) = ai + b\n(\n2pi \u2212 N \u2211\ni=1\np2i\n)\n(1)\nand the logarithmic scoring rule [13]:\nsi(~p) = ai + b log(pi) (2)\nwith arbitrary parameters a1, \u00b7 \u00b7 \u00b7 , aN and parameter b > 0. The uses and properties of scoring rules are too extensive 1A similar but weaker correspondence between market scoring rules and cost function based markets was discussed in Chen and Pennock [5] and Agrawal et al. [1].\nto cover in detail here. For a nice survey, see Gneiting and Raftery [12].\nMarket scoring rules were developed by Hanson [15, 16] as a method of using scoring rules to pool opinions from many different forecasters. Market scoring rules are sequentially shared scoring rules. Formally, the market maintains a current probability distribution ~p. At any time, a trader can enter the market and change this distribution to an arbitrary distribution ~p \u2032 of her choice.2 If the outcome turns out to be i, she receives a (possibly negative) payoff of si(~p\n\u2032)\u2212 si(~p). For example, in the popular Logarithmic Market Scoring Rule (LMSR), which is based on the logarithmic scoring rule in Equation 2, a trader who changes the distribution from ~p to ~p \u2032 receives a payoff of b log(p\u2032i/pi).\nSince the trader has no control over ~p, a myopic trader who believes the true distribution to be ~r maximizes her expected payoff by maximizing \u2211\ni risi(~p \u2032). Thus if ~s is a strictly\nproper scoring rule, traders have an incentive to change the market\u2019s distribution to match their true beliefs. The idea is that if traders update their own beliefs over time based on market activity, the market\u2019s distribution should eventually converge to the collective beliefs of the population.\nEach trader in a market scoring rule is essentially responsible for paying the previous trader\u2019s score. Thus the market maker is responsible only for paying the score of the final trader. Let ~p0 be the initial probability distribution of the market. The worst case loss of the market maker is then\nmax i\u2208{1,\u00b7\u00b7\u00b7 ,N} max ~p\u2208\u2206N\n(si(~p)\u2212 si(~p0)) .\nThe worst case loss of the market maker running an LMSR initialized to the uniform distribution is b logN .\nNote that the parameters a1, \u00b7 \u00b7 \u00b7 , aN of the logarithmic scoring rule do not affect either the payoff of traders or the loss of the market maker in the LMSR. For simplicity, in the remainder of this paper when discussing the LMSR we assume that ai = 0 for all i."}, {"heading": "2.2 Cost Function Based Markets", "text": "As before, let {1, \u00b7 \u00b7 \u00b7 , N} be a set of mutually exclusive and exhaustive outcomes of an event. In a cost function based market, a market maker offers a security corresponding to each outcome i. The security associated with outcome i pays off $1 if i happens, and $0 otherwise.3\nDifferent mechanisms can be used to determine how these securities are priced. Each mechanism is specified using a differentiable cost function C : RN \u2192 R. This cost function is simply a potential function describing the amount of money currently wagered in the market as a function of the quantity of shares purchased. If qi is the number of shares of security i currently held by traders, and a trader would like to purchase ri shares of each security (where ri could be zero or even negative, representing the sale of shares), the trader must pay C(~q+~r)\u2212C(~q) to the market maker. The instantaneous price of security i (that is, the price per share of an infinitely small number of shares) is then pi = \u2202C(~q)/\u2202qi.\n2While ~p \u2032 may be arbitrary, in some market scoring rules, such as the LMSR, distributions that place a weight of 0 on any outcome are not allowed because it requires the trader to pay infinite amount of money if the outcome with reported probability 0 actually happens. 3The dynamic parimutuel market falls outside this framework since the winning payoff depends on future trades.\nWe say that a cost function is valid if the associated prices satisfy two simple conditions:\n1. For every i \u2208 {1, \u00b7 \u00b7 \u00b7 , N} and every ~q \u2208 RN , pi(~q) \u2265 0.\n2. For every ~q \u2208 RN , \u2211Ni=1 pi(~q) = 1 . The first condition ensures that the price of a security is never negative. If the current price of the security associated with an outcome i were negative, a trader could purchase shares of this security at a guaranteed profit. The second condition ensures that the prices of all securities sum to 1. If the prices summed to something less than (respectively, greater than) 1, then a trader could purchase (respectively, sell) small equal quantities of each security for a guaranteed profit. Together, these conditions ensure that there are no arbitrage opportunities in the market.\nThese conditions also ensure that the current prices can always be viewed as a valid probability distribution over the outcome space. In fact, these prices represent the market\u2019s current estimate of the probability that outcome i will occur.\nThe following theorem gives sufficient and necessary conditions for the cost function C to be valid. While these properties of cost functions have been discussed elsewhere [5, 1], the fact that they are both sufficient and necessary for any valid cost function C is important for our later analysis. As such, we state the full proof here for completeness.\nTheorem 1. A cost function C is valid if and only if it satisfies the following three properties:\n1. Differentiability: The partial derivatives \u2202C(~q)/\u2202qi exist for all ~q \u2208 RN and i \u2208 {1, . . . , N}.\n2. Increasing Monotonicity: For any ~q and ~q \u2032, if ~q \u2265 ~q \u2032, then C(~q) \u2265 C(~q \u2032).\n3. Positive Translation Invariance: For any ~q and any constant k, C(~q + k~1) = C(~q) + k.\nProof. Differentiability is necessary and sufficient for the price functions to be well-defined at all points. It is easy to see that requiring the cost function to be monotonic is equivalent to requiring that pi(~q) \u2265 0 for all i and ~q. We will show that requiring positive translation invariance is equivalent to requiring that the prices always sum to one.\nFirst, assume that \u2211N\ni=1 pi(~q) = 1 for all ~q. For any fixed\nvalue of ~q, define ~u = ~u(a) = ~q + a~1 and let ui be the ith component of ~u. Then for any k,\nC(~q + k~1)\u2212 C(~q) = \u222b k\n0\ndC(~q + a~1)\nda da\n=\n\u222b k\n0\nN \u2211\ni=1\n\u2202C(~u)\n\u2202ui \u2202ui \u2202a da\n=\n\u222b k\n0\nN \u2211\ni=1\npi(~u)da = k .\nThis is precisely translation invariance. Now assume instead that positive translation invariance holds. Fix any arbitrary ~q \u2032 and k and define ~q = ~q \u2032 + k~1. Notice that by setting ~q \u2032 and k appropriately, we can make ~q take on any arbitrary values. We have,\n\u2202C(~q)\n\u2202k =\nN \u2211\ni=1\n\u2202C(~q)\n\u2202qi \u2202qi \u2202k\n= N \u2211\ni=1\npi(~q).\nBy translation invariance, C(~q \u2032 + k~1) = C(~q \u2032) + k. Thus,\n\u2202C(~q)\n\u2202k =\n\u2202(C(~q \u2032) + k)\n\u2202k = 1.\nCombining the two equations, we have \u2211N\ni=1 pi(~q) = 1.\nOne quantity that is useful for comparing different market mechanisms is the worst-case loss of the market maker,\nmax ~q\u2208RN\n(\nmax i\u2208{1,\u00b7\u00b7\u00b7 ,N}\nqi \u2212 (C(~q)\u2212 C(~0)) ) .\nThis is simply the difference between the maximum amount that the market maker might have to pay the winners and the amount of money collected by the market maker.\nThe Logarithmic Market Scoring Rule described above can be specified as a cost function based prediction market [15, 5]. Then cost function of the LMSR is\nC(~q) = b log\nN \u2211\ni=1\neqi/b ,\nand the corresponding prices are\npi(~q) = \u2202C(~q)\n\u2202qi =\neqi/b \u2211N\nj=1 e qj/b\n.\nThis formulation is equivalent to the market scoring rule formulation in the sense that a trader who changes the market probabilities from ~r to ~r \u2032 in the MSR formulation receives the same payoff for every outcome i as a trader who changes the quantity vectors from any ~q to ~q \u2032 such that p(~q) = ~r and p(~q \u2032) = ~r \u2032 in the cost function formulation."}, {"heading": "3. LEARNING FROM EXPERT ADVICE", "text": "We now briefly review the problem of learning from expert advice. In this framework, an algorithm makes a sequence of predictions based on the advice of a set of N experts and receives a corresponding sequence of losses.4 The goal of the algorithm is to achieve a cumulative loss that is \u201calmost as low\u201d as the cumulative loss of the best performing expert in hindsight. No statistical assumptions are made about these losses. Indeed, algorithms are expected to perform well even if the sequence of losses is chosen by an adversary.\nFormally, at every time step t \u2208 {1, \u00b7 \u00b7 \u00b7 , T}, every expert i \u2208 {1, \u00b7 \u00b7 \u00b7 , N} receives a loss \u2113i,t \u2208 [0, 1]. The cumulative loss of expert i at time T is then defined as Li,T = \u2211T t=1 \u2113i,t. An algorithm A maintains a weight wi,t for each expert i at time t, where\n\u2211n i=1 wi,t = 1. These weights can be\nviewed as a distribution over the experts. The algorithm then receives its own instantaneous loss \u2113A,t = \u2211n i=1 wi,t\u2113i,t, which can be interpreted as the expected loss the algorithm would receive if it always chose an expert to follow according to the current distribution. The cumulative loss of A up to time T is defined in the natural way as LA,T = \u2211T t=1 \u2113A,t = \u2211T t=1 \u2211n i=1 wi,t\u2113i,t.\nIt is unreasonable to expect the algorithm to achieve a small cumulative loss if none of the experts perform well. As such, it is typical to measure the performance of an algorithm in terms of its regret, defined to be the difference\n4This framework could be formalized equally well in terms of gains, but losses are more common in the literature.\nbetween the cumulative loss of the algorithm and the loss of the best performing expert, that is,\nLA,T \u2212 min i\u2208{1,\u00b7\u00b7\u00b7 ,N} Li,T .\nAn algorithm is said to have no regret if the average per time step regret approaches 0 as T approaches infinity.\nThe popular Randomized Weighted Majority (WM) algorithm [28, 9] is an example of a no-regret algorithm. Weighted Majority uses weights\nwi,t = e\u2212\u03b7Li,t\n\u2211n j=1 e\n\u2212\u03b7Lj,t ,\nwhere \u03b7 > 0 is a tunable parameter known as the learning rate. It is well known that the regret of WM after T trials can be bounded as\nLWM(\u03b7),T \u2212 min i\u2208{1,\u00b7\u00b7\u00b7 ,N} Li,T \u2264 \u03b7T + logN \u03b7 .\nWhen T is known in advance, setting \u03b7 = \u221a\nlogN/T yields the standard O( \u221a T logN) regret bound.\nIt has been shown that the weights chosen by Weighted Majority are precisely those that minimize a combination of empirical loss and an entropic regularization term [24, 25, 20]. More specifically, the weights at time t are precisely those that minimize\nN \u2211\ni=1\nwiLi,t\u22121 \u2212 1 \u03b7 H(~w)\namong all ~w \u2208 \u2206N , where H is the entropy. This makes Weighted Majority an example of broader class of algorithms collectively known as Follow the Regularized Leader algorithms [34, 18, 17]. This class of algorithms grew out of the following fundamental insight of Kalai and Vempala [22].\nConsider first the aptly named Follow the Leader algorithm, which chooses weights at time t to minimize \u2211N\ni=1 wi,tLi,t\u22121. This algorithm simply places all of its weight on the single expert (or set of experts) with the best performance on previous examples. As such, this algorithm can be highly unstable, dramatically changing its weights from one time step to the next. It is easy to see that Follow the Leader suffers \u2126(T ) regret in the worst case when the best expert changes frequently. For example, if there are only two experts with losses starting at \u30081/2, 0\u3009 and then alternating \u30080, 1\u3009 , \u30081, 0\u3009 , \u30080, 1\u3009 , \u30081, 0\u3009 , \u00b7 \u00b7 \u00b7 , then FTL places a weight of 1 on the losing expert at every point in time.\nTo overcome this instability, Kalai and Vempala [22] suggested adding a random perturbation to the empirical loss of each expert, and choosing the expert that minimizes this perturbed loss.5 However, in general this perturbation need not be random. Instead of adding a random perturbation, it is possible to gain the necessary stability by adding a regularizer R and choosing weights to minimize\nN \u2211\ni=1\nwi,tLi,t\u22121 + 1\n\u03b7 R(~wt) . (3)\nThis Follow the Regularized Leader (FTRL) approach gets around the instability of FTL and guarantees low regret for a wide variety of regularizers, as evidenced by the following bound of Hazan and Kale [18].\n5A very similar algorithm was originally developed and analyzed by Hannan in the 1950s [14].\nLemma 1 (Hazan and Kale [18]). For any regularizer R, the regret of FTRL can be bounded as LFTRL(R,\u03b7),T \u2212 min\ni\u2208{1,\u00b7\u00b7\u00b7 ,N} Li,T\n\u2264 T \u2211\nt=1\nN \u2211\ni=1\n\u2113i,t(wi,t \u2212wi,t+1) + 1 \u03b7 (R(~wT )\u2212R(~w0)) .\nThis lemma quantifies the trade-off that must be considered when choosing a regularizer. If the range of the regularizer is too small, the weights will change dramatically from one round to the next, and the first term in the bound will be large. On the other hand, if the range of the regularizer is too big, the weights that are chosen will be too far from the true loss minimizers and the second term will blow up.\nIt is generally assumed that the regularizer R is strictly convex. This assumption ensures that Equation 3 has a unique minimizer and that this minimizer can be computed efficiently. Hazan [17] shows that if R is strictly convex then it is possible to achieve a regret of O( \u221a T ). In particular, by optimizing \u03b7 appropriately the regret bound in Lemma 1 can be upper bounded by\n2 \u221a\n2\u03bb max ~w,~w \u2032\u2208\u2206N\n(R(~w)\u2212R(~w \u2032))T (4)\nwhere \u03bb = max\u2113\u2208[0,1]N , ~w\u2208\u2206N \u2113 T [\u22072R(~w)]\u22121\u2113."}, {"heading": "4. INTERPRETING PREDICTION MARKETS AS NO-REGRET LEARNERS", "text": "With this foundation in place, we are ready to describe how any bounded loss market maker can be interpreted as an algorithm for learning from expert advice. The key idea is to equate the trades made in the market with the losses observed by the learning algorithm. We can then view the market maker as essentially learning a probability distribution over outcomes by treating each observed trade as a training instance.\nMore formally, consider any cost function based market maker with instantaneous price functions pi for each outcome i. We convert such a market maker to an algorithm for learning from expert advice by setting the weight of expert i at time t using\nwi,t = pi(\u2212\u01eb~Lt\u22121), (5)\nwhere \u01eb > 0 is a tunable parameter and ~Lt\u22121 = \u3008L1,t\u22121, \u00b7 \u00b7 \u00b7 , LN,t\u22121\u3009 is the vector of cumulative losses at time t\u22121. In other words, the weight on expert i at time t in the learning algorithm is the instantaneous price of security i in the market when \u2212\u01ebLj,t\u22121 shares have been purchased (or \u01ebLj,t\u22121 shares have been sold) of each security j. We discuss the role of the parameter \u01eb in more detail below.\nFirst note that for any valid cost function based prediction market, setting the weights as in Equation 5 entails valid expert learning algorithm. Since the prices of any valid prediction market must be non-negative and sum to one, the weights of the resulting algorithm are guaranteed to satisfy these properties too. Furthermore, the weights are a function of only the past losses of each expert, which the algorithm is permitted to observe.\nBelow we show that applying this conversion to any bounded-loss market maker with slowly changing prices\nyields a learning algorithm with O( \u221a T ) regret. The quality of the regret bound obtained depends on the trade-off between market maker loss and how quickly the prices change. We then show how this bound can be used to rederive the standard regret bound of Weighted Majority, the converse of the result of Chen et al. [6]."}, {"heading": "4.1 A Bound on Regret", "text": "In order to derive a regret bound for the learning algorithm defined in Equation 5, it is necessary to make some restrictions on how quickly the prices in the market change. If market prices change too quickly, the resulting learning algorithm will be unstable and will suffer high worst-case regret, as was the case with the naive Follow The Leader algorithm described in Section 3. To capture this idea, we introduce the notion of \u03c6-stability, defined as follows.\nDefinition 1. We say that a set of price functions ~p is \u03c6-stable for a constant \u03c6 if pi is continuous and piecewise differentiable for all i \u2208 {1, \u00b7 \u00b7 \u00b7 , N} and \u2211N\ni=1 \u2211N j=1\n\u2223 \u2223Di,j(~t) \u2223 \u2223 \u2264 \u03c6 for all ~t, where\nDi,j(~t) =\n\n\n\n\u2202pi(~q) \u2202qj\n\u2223 \u2223 \u2223\n~q=~t if \u2202pi(~q) \u2202qj is defined at ~t,\n0 otherwise.\nDefining \u03c6-stability in terms of the Di,j allows us to quantify how slowly the prices change even when the price functions are not differentiable at all points. We can then derive a regret bound for the resulting learning algorithm using the following simple lemma. This lemma states that when the quantity vector in the market is ~q, if the price functions are \u03c6-stable, then the amount of money that the market maker would collect for the purchase of a small quantity ri of each security i is not too far from the amount that the market maker would have collected had he instead priced the shares according to the fixed price ~p(~q).\nLemma 2. Let C be any valid cost function yielding \u03c6stable prices. For any \u01eb > 0, any ~q \u2208 RN , and any ~r \u2208 RN such that |ri| \u2264 \u01eb for i \u2208 {1, \u00b7 \u00b7 \u00b7 , N},\n\u2223 \u2223 \u2223 \u2223 \u2223 (C(~q + ~r)\u2212C(~q))\u2212 N \u2211\ni=1\npi(~q)ri\n\u2223 \u2223 \u2223 \u2223 \u2223 \u2264 \u01eb 2\u03c6 2 .\nThe proof is in Appendix A. With this lemma in place, we are ready to derive the regret bound. In the following theorem, it is assumed that T is known a priori and therefore can be used to set \u01eb. If T is not known in advance, a standard \u201cdoubling trick\u201d can be applied [4]. The idea behind the doubling trick is to partition time into periods of exponentially increasing length, restarting the algorithm each period. This leads to similar bounds with only an extra factor of log(T ).\nTheorem 2. Let C be any valid cost function yielding \u03c6stable prices. Let B be a bound on the worst-case loss of the market maker mechanism associated with C. Let A be the expert learning algorithm with weights as in Equation 5 with \u01eb = \u221a\n2B/(\u03c6T ). Then for any sequence of expert losses \u2113i,t \u2208 [0, 1] over T time steps,\nLA,T \u2212 min i\u2208{1,\u00b7\u00b7\u00b7 ,N} Li,T \u2264 \u221a 2B\u03c6T .\nProof. By setting the weights as in Equation 5, we are essentially simulating a market over N outcomes. Let ri,t denote the number of shares of outcome i purchased at time step t in this simulated market, and denote by ~rt the vector of these quantities for all i. Note that ri,t is completely in our control since we are simply simulating a market, thus we can choose to set ri,t = \u2212\u01eb\u2113i,t for all i and t. We have that ri,t \u2208 [\u2212\u01eb, 0] for all i and t since \u2113i,t \u2208 [0, 1]. Let qi,t = \u2211t t\u2032=1 ri,t\u2032 be the total number of outstanding shares of security i after time t, with ~qt denoting the vector over all i. The weight assigned to expert i at round t of the learning algorithm corresponds to the instantaneous price of security i in the simulated market immediately before round t, that is, wi,t = pi(\u2212\u01eb~Lt\u22121) = pi(~qt\u22121).\nBy the definition of worst-case market maker loss, maxi qi,t \u2212 (C(~qt) \u2212 C(~0)) \u2264 B. It is easy to see that we can rewrite the left-hand side of this equation to obtain\nmax i\u2208{1,\u00b7\u00b7\u00b7 ,N}\nT \u2211\nt=1\nri,t \u2212 t \u2211\nt=1\n(C(~qt)\u2212 C(~qt\u22121)) \u2264 B .\nFrom Lemma 2, this gives us that\nmax i\u2208{1,\u00b7\u00b7\u00b7 ,N}\nT \u2211\nt=1\nri,t \u2212 t \u2211\nt=1\n(\nN \u2211\ni=1\npi(~qt\u22121)ri,t + \u01eb2\u03c6\n2\n)\n\u2264 B.\nSubstituting pi(~qt\u22121) = wi,t and ri,t = \u2212\u01eb\u2113i,t, we get\nmax i\u2208{1,\u00b7\u00b7\u00b7 ,N}\nT \u2211\nt=1\n(\u2212\u01eb\u2113i,t)\u2212 t \u2211\nt=1\nN \u2211\ni=1\nwi,t (\u2212\u01eb\u2113i,t) \u2264 B + \u01eb 2\u03c6T\n2\nand so\nLA,T \u2212 min i\u2208{1,\u00b7\u00b7\u00b7 ,N} Li,T =\nt \u2211\nt=1\nN \u2211\ni=1\nwi,t\u2113i,t \u2212min i\nT \u2211\nt=1\n\u2113i,t\n\u2264 B \u01eb + \u01eb\u03c6T 2 .\nSetting \u01eb = \u221a 2B/(\u03c6T ) yields the bound."}, {"heading": "4.2 Rederiving the Weighted Majority Bound", "text": "Chen et al. [6] showed that the Weighted Majority regret bound can be used as a starting point to rederive the worst case loss of b logN of an LMSR market maker. Here we show that the converse is also true; by applying Theorem 2, we can rederive theWeighted Majority bound from the bounded market maker loss of LMSR.\nIn order to apply Theorem 2, we must provide a bound on how quickly LMSR prices can change. This is given in the following lemma, the proof of which is in Appendix B.\nLemma 3. Let ~p be the pricing function of a LMSR with parameter b > 0. Then\nN \u2211\ni=1\nN \u2211\nj=1\n\u2223 \u2223 \u2223 \u2223 \u2202pi(~q)\n\u2202qj\n\u2223 \u2223 \u2223 \u2223 \u2264 2 b .\nUsing Equation 5 to transform the LMSR into a learning algorithm, we end up with weights\nwi,t = e\u2212\u01ebLi,t\u22121/b\n\u2211N j=1 e\n\u2212\u01ebLj,t\u22121/b .\nSetting \u01eb = \u221a 2B/(\u03c6T ) = b \u221a\nlogN/T , we see that these weights are equivalent to those used by Weighted Majority with the learning rate \u03b7 = \u01eb/b = \u221a\nlogN/T . As mentioned above, this is the optimal setting of \u03b7. Notice that these weights do not depend on the value of the parameter b in the prediction market.\nWe can now apply Theorem 2 to rederive the standard Weighted Majority regret bound stated in Section 3. In particular, setting B = b logN and \u03c6 = 2/b, we get that when \u03b7 = \u221a log(N)/T ,\nLWM,T \u2212 min i\u2208{1,\u00b7\u00b7\u00b7 ,N} Li,T \u2264 2 \u221a T logN ."}, {"heading": "5. CONNECTIONS BETWEEN MARKET SCORING RULES, COST FUNCTIONS, AND REGULARIZATION", "text": "In this section, we establish the formal connections among market scoring rules, cost function based markets, and the class of Follow the Regularized Leaders algorithms. We start with a representation theorem for cost function based markets, which is crucial in our later analysis."}, {"heading": "5.1 A Representation Theorem for Convex Cost Functions", "text": "In this section we show a representation theorem for convex cost functions. The proof of this theorem relies on the connection between convex cost functions and a class of functions known in the finance literature as convex risk measures, which was first noted by Agrawal et al. [1]. Convex risk measures were originally introduced by Fo\u0308llmer and Schied [8] to model different attitudes towards risk in financial markets. A risk measure \u03c1 can be viewed as a mapping from a vector of returns (corresponding to each possible outcome of an event) to a real number. The interpretation is that a vector of returns ~x is \u201cpreferred to\u201d the vector ~x \u2032 under a risk measure \u03c1 if and only if \u03c1(~x) < \u03c1(~x \u2032).\nFormally, a function \u03c1 is a convex risk measure if it satisfies the following three properties:\n1. Convexity: \u03c1(~x) is a convex function of ~x.\n2. Decreasing Monotonicity: For any ~x and ~x \u2032, if ~x \u2265 ~x \u2032, then \u03c1(~x) \u2264 \u03c1(~x \u2032).\n3. Negative Translation Invariance: For any ~x and value k, \u03c1(~x+ k~1) = \u03c1(~x)\u2212 k.\nThe financial interpretations of these properties are not important in our setting. More interesting for us is that Fo\u0308llmer and Schied [8] provide a representation theorem that states that a function \u03c1 is a convex risk measure if and only if it can be represented as\n\u03c1(~x) = sup ~p\u2208\u2206N\n(\n\u2212 N \u2211\ni=1\npixi \u2212 \u03b1(~p) )\nwhere \u03b1 : \u2206N \u2192 (\u2212\u221e,\u221e] is a convex, lower semicontinuous function referred to as a penalty function. This fact is useful because it allows us to obtain the following result, which was alluded to informally by Agrawal et al. [1]. The full proof is included here for completeness.\nLemma 4. A function C is a valid convex cost function if and only if it is differentiable and can be represented as\nC(~q) = sup ~p\u2208\u2206N\n(\nN \u2211\ni=1\npiqi \u2212 \u03b1(~p) )\n(6)\nfor a convex and lower semi-continuous function \u03b1. Furthermore, for any quantity vector ~q, the price vector ~p(~q) corresponding to C is the distribution ~p maximizing \u2211N\ni=1 piqi \u2212 \u03b1(~p).\nProof. Consider any differentiable function C : RN \u2192 R. Let \u03c1(~q) = C(\u2212~q). Clearly by definition, \u03c1 satisfies decreasing monotonicity if and only if C satisfies increasing monotonicity, and \u03c1 satisfies negative translation invariance if and only if C satisfies positive translation invariance. Furthermore, \u03c1 is convex if and only if C is convex. By Theorem 1, this implies that C is a valid convex cost function if and only if \u03c1 is a convex risk measure. The first half of the lemma then follows immediately from the representation theorem of Fo\u0308llmer and Schied [8].\nNow, because \u03b1(~p) is guaranteed to be convex, \u2211N i=1 piqi\u2212 \u03b1(~p) is a concave function of ~p. The constraints\n\u2211N i=1 pi = 1\nand pi \u2265 0 define a closed convex feasible set. Thus, the problem of maximizing\n\u2211N i=1 piqi \u2212 \u03b1(~p) with respect to\n~p has a global optimal solution and first-order KKT conditions are both necessary and sufficient. Let ~p \u2217(~q) denote an optimal ~p for this optimization problem. Then, C(~q) =\n\u2211N i=1 p \u2217 i (~q)qi \u2212 \u03b1(~p \u2217(~q)). By the envelope theo-\nrem [29], if C(~q) is differentiable, we have that for any i, p\u2217i (~q) = \u2202C(~q)/\u2202qi = pi(~q). Thus the market prices are precisely those which maximize the inner expression of the cost function.\nFurthermore, by a version of the envelope theorem [23], to ensure that C is differentiable, it is sufficient to show that \u03b1 is strictly convex and differentiable.\nCorollary 1. A function C is a valid convex cost function if it can be represented as in Equation 6 for a strictly convex and differentiable function \u03b1. For any ~q, the price vector ~p(~q) is the distribution ~p maximizing\n\u2211N i=1 piqi\u2212\u03b1(~p).\nThe ability to represent any valid cost function in this form allows us to define a bound on the worst-case loss of the market maker in terms of the penalty function of the corresponding convex risk measure.\nLemma 5. The worst-case loss of the market maker defined by the cost function in Equation 6 is no more than\nsup ~p,~p \u2032\u2208\u2206N\n( \u03b1(~p)\u2212 \u03b1(~p \u2032) ) .\nProof. The worst-case loss of the market maker is\nmax ~q\u2208RN\n(\nmax i\u2208{1,\u00b7\u00b7\u00b7 ,N}\nqi \u2212 C(~q) ) +C(~0)\n= max ~q\u2208RN\n(\nmax i\u2208{1,\u00b7\u00b7\u00b7 ,N} qi \u2212 sup ~p\u2208\u2206N\n(\nN \u2211\ni=1\npiqi \u2212 \u03b1(~p) ))\n+ sup ~p \u2032\u2208\u2206N\n( \u2212\u03b1(~p \u2032) )\n\u2264 max ~q\u2208RN\n(\nmax i\u2208{1,\u00b7\u00b7\u00b7 ,N}\nqi \u2212 (\nsup ~p\u2208\u2206N\nN \u2211\ni=1\npiqi \u2212 sup ~p\u2208\u2206N (\u03b1(~p))\n))\n+ sup ~p \u2032\u2208\u2206N\n( \u2212\u03b1(~p \u2032) )\n= max ~q\u2208RN\n(\nmax i\u2208{1,\u00b7\u00b7\u00b7 ,N} qi \u2212 max i\u2208{1,\u00b7\u00b7\u00b7 ,N} qi\n)\n+ sup ~p\u2208\u2206N (\u03b1(~p))\n+ sup ~p \u2032\u2208\u2206N\n( \u2212\u03b1(~p \u2032) )\n= sup ~p,~p \u2032\u2208\u2206N\n( \u03b1(~p)\u2212 \u03b1(~p \u2032) ) .\nThe inequality follows from the fact that for any functions f and g over any domain X , supx\u2208X (f(x) \u2212 g(x)) \u2265 supx\u2208X f(x)\u2212 supx\u2032\u2208X g(x\u2032)."}, {"heading": "5.2 Convex Cost Functions and Market Scoring Rules", "text": "As described in Section 2, the Logarithmic Market Scoring Rule market maker can be defined as either a market scoring rule or a cost function based market. The LMSR is not unique in this regard. As we show in this section, any regular, strictly proper market scoring rule with differentiable scoring functions can be represented as a cost function based market. Likewise, any convex cost function satisfying a few mild conditions corresponds to a market scoring rule. As long as the market probabilities are nonzero, the market scoring rule and corresponding cost function based market are equivalent. More precisely, a trader who changes the market probabilities from ~r to ~r \u2032 in the market scoring rule is guaranteed to receive the same payoff for every outcome i as a trader who changes the quantity vectors from any ~q to ~q \u2032 such that p(~q) = ~r and p(~q \u2032) = ~r \u2032 in the cost function formulation as long as every component of ~r and ~r \u2032 is nonzero. Moreover, any price vector that is achievable in the market scoring rule (that is, any ~p for which si(~p) is finite for all i) is achievable by the cost function based market.\nThe fact that there exists a correspondence between certain market scoring rules and certain cost function based markets was noted by Chen and Pennock [5]. They pointed out that the MSR with scoring function ~s and the cost function based market with cost function C are equivalent if for all ~q and all outcomes i, C(~q) = qi \u2212 si(~p). However, they did not provide any guarantees about the circumstances under which this condition can be satisfied. Agrawal et al. [1] also made use of the equivalence between markets when this strong condition holds. Our result gives very general precise conditions under which an MSR is equivalent to a cost function based market.\nRecall from Lemma 4 that any convex cost function C can\nbe represented as C(~q) = sup~p\u2208\u2206N\n(\n\u2211N i=1 piqi \u2212 \u03b1(~p)\n)\nfor\na convex function \u03b1. Let \u03b1C denote the function \u03b1 corresponding to the cost function C. In the following, we con-\nsider cost functions derived from scoring rules ~s by setting\n\u03b1C(~p) =\nN \u2211\ni=1\npisi(~p) (7)\nand scoring rules derived from convex cost functions with\nsi(~p) = \u03b1C(~p)\u2212 N \u2211\nj=1\n\u2202\u03b1C(~p)\n\u2202pj pj +\n\u2202\u03b1C(~p)\n\u2202pi . (8)\nWe show that there is a mapping between a mildly restricted class of convex cost function based markets and a mildly restricted class of strictly proper market scoring rules such that for every pair in the mapping, Equations 7 and 8 both hold. Furthermore, we show that the markets satisfying these equations are equivalent in the sense described above.\nTheorem 3. There is a one-to-one and onto mapping between the set of convex cost function based markets with strictly convex and differentiable potential functions \u03b1C and the class of strictly proper, regular market scoring rules with differentiable scoring functions ~s such that for each pair in the mapping, Equations 7 and 8 hold.\nFurthermore, each pair of markets in this mapping are equivalent when prices for all outcomes are positive, that is, the profit of a trade is the same in the two markets if the trade starts with the same market prices and results in the same market prices and the prices for all outcomes are positive before and after the trade. Additionally, every price vector ~p achievable in the market scoring rule is achievable in the cost function based market.\nProof. We first show that the function \u03b1C in Equation 7 is strictly convex and differentiable and the scoring rule in Equation 8 is regular, strictly proper and differentiable. We then show that Equations 7 and 8 are equivalent. Finally, we show the equivalence between the two markets.\nConsider the function \u03b1C in Equation 7. Since we have assumed that si is differentiable for all i, \u03b1C is differentiable too. Additionally, it is known that a scoring rule is strictly proper only if its expected value is strictly convex [12], so \u03b1C is strictly convex.\nConsider the scoring rule defined in Equation 8. By Theorem 1 of Gneiting and Raftery [12], a regular scoring rule si(~p) is strictly proper if and only if there exists a strictly convex function G(~p) such that\nsi(~p) = G(~p)\u2212 N \u2211\nj=1\npjG\u0307j(~p) + G\u0307i(~p), (9)\nwhere Gj(~p) is any subderivative of G with respect to pj (if G is differentiable, G\u0307j = \u2202G(~p)/\u2202pj). This immediately implies that the scoring rule defined in Equation 8 is a regular strictly proper scoring rule since \u03b1(~p) is strictly convex. We will see below that si is also differentiable.\nIt is easy to see that Equation 8 implies Equation 7. Suppose Equation 8 holds. Then\nN \u2211\ni=1\npisi(~p) = N \u2211\ni=1\npi\n(\n\u03b1C(~p)\u2212 N \u2211\nj=1\n\u2202\u03b1C(~p)\n\u2202pj pj +\n\u2202\u03b1C(~p)\n\u2202pi\n)\n= \u03b1C(~p) .\nThis also shows that si is differentiable for all i, since the\nderivative of \u03b1C is well-defined at all points and\n\u2202\u03b1C(~p)\n\u2202pi = si(~p) +\nN \u2211\ni=1\n\u2202si(~p)\n\u2202pi .\nTo see that Equation 7 implies Equation 8, suppose that Equation 7 holds. We know that the scoring rule ~s can be expressed as in Equation 9 for some function G. For this particular G,\n\u03b1C(~p) = N \u2211\ni=1\npi\n(\nG(~p)\u2212 N \u2211\nj=1\npjG\u0307j(~p) + G\u0307i(~p)\n)\n= G(~p) .\nSince G(~p) = \u03b1C(~p) and \u03b1C is differentiable (meaning that \u2202\u03b1C/\u2202pi is the only subderivative of \u03b1C with respect to pi), this implies Equation 8.\nWe have established the equivalence between Equations 7 and 8. We now show that a trader gets exactly the same profit for any realized outcome in the two markets if the market prices are positive.\nSuppose in the cost function based market a trader changes the outstanding shares from ~q to ~q \u2032. This trade changes the market price from ~p(~q) to ~p(~q \u2032). If outcome i occurs, the trader\u2019s profit is\n(q\u2032i \u2212 qi)\u2212 ( C(~q \u2032)\u2212 C(~q) )\n= (q\u2032i \u2212 qi)\u2212 ( N \u2211\nj=1\npj(~q \u2032)q\u2032j \u2212 \u03b1C(~p(~q \u2032))\n)\n+\n(\nN \u2211\nj=1\npj(~q)qj \u2212 \u03b1C(~p(~q)) )\n=\n(\nq\u2032i \u2212 N \u2211\nj=1\npj(~q \u2032)q\u2032j + \u03b1C(~p(~q \u2032))\n)\n\u2212 ( qi \u2212 N \u2211\nj=1\npj(~q)qj + \u03b1C(~p(~q))\n)\n. (10)\nFrom Lemma 4, we know that ~p(~q) is the optimal solution\nto the convex optimization max~p\u2208\u2206N\n(\n\u2211N i=1 piqi \u2212 \u03b1C(~p)\n)\n.\nThe Lagrange function of this optimization problem is\nL =\n(\nN \u2211\ni=1\npiqi \u2212 \u03b1C(~p) ) \u2212 \u03bb( N \u2211\ni=1\npi \u2212 1) + N \u2211\ni=1\n\u00b5ipi.\nSince ~p(~q) is optimal, the KKT conditions require that \u2202L/\u2202pi = 0, which implies that for all i,\nqi = \u2202\u03b1C(~p(~q))\n\u2202pi(~q) + \u03bb(~q)\u2212 \u00b5i(~q), (11)\nwhere \u00b5i(~q) \u2265 0 and \u00b5i(~q)pi(~q) = 0. Plugging (11) into (10), we have\n(q\u2032i \u2212 qi)\u2212 ( C(~q \u2032)\u2212 C(~q) )\n=\n(\n\u2202\u03b1C(~p(~q \u2032))\n\u2202pi(~q \u2032) \u2212\nN \u2211\nj=1\npj(~q \u2032) \u2202\u03b1C(~p(~q\n\u2032))\n\u2202pj(~q \u2032) + \u03b1C(~p(~q\n\u2032))\u2212 \u00b5i(~q \u2032) )\n\u2212 ( \u2202\u03b1C(~p(~q))\n\u2202pi(~q) \u2212\nN \u2211\nj=1\npj(~q) \u2202\u03b1C(~p(~q))\n\u2202pj(~q) + \u03b1C(~p(~q))\u2212 \u00b5i(~q)\n)\n= ( si(~p(~q \u2032))\u2212 \u00b5i(~q \u2032) ) \u2212 (si(~p(~q))\u2212 \u00b5i(~q)) . (12)\nWhen pi(~q) > 0 and pi(~q \u2032) > 0, \u00b5i(~q) = \u00b5i(~q \u2032) = 0. In this case, the profit of the trader in the cost function based market is the same as that in the market scoring rule market when he changes the market probability from ~p(~q) to ~p(~q \u2032).\nFinally, observe that using the cost function based market it is possible to achieve any price vector ~r with finite scores si(~r) by setting qi = si(~r) for all i. By Lemma 4, for this setting of ~q, p(~q) is the vector ~p that maximizes \u2211N\ni= pisi(~r)\u2212 \u2211N\ni=1 pisi(~p). Since ~s is strictly proper, this is maximized at ~p = ~r. Since ~s is regular, this implies that it is possible to achieve any prices in the interior of the probability simplex using the cost function based market (and any prices ~p on the exterior as long as si(~p) is finite for all i)."}, {"heading": "5.3 Convex Cost Functions and FTRL", "text": "Consider a prediction market with a convex cost function\nrepresented as C(~q) = sup~p\u2208\u2206N\n(\n\u2211N i=1 piqi \u2212 \u03b1(~p)\n)\nand\nthe corresponding learning algorithm with weights wi,t = pi(\u2212\u01eb~Lt\u22121). (Recall that ~Lt\u22121 = \u3008L1,t\u22121, \u00b7 \u00b7 \u00b7 , LN,t\u22121\u3009 is the vector of cumulative losses at time t \u2212 1.) By Lemma 4, the weights chosen at time t are those that maximize the expression \u2212\u01eb\u2211Ni=1 wiLi,t\u22121 \u2212 \u03b1(~w), or equivalently, those that minimize the expression\nN \u2211\ni=1\nwiLi,t\u22121 + 1\n\u01eb \u03b1(~w) .\nThis expression is of precisely the same form as Equation 3, with \u03b1 playing the role of the regularizer and \u01eb controlling the trade-off between the regularizer and the empirical loss. This implies that every convex cost function based prediction market can be interpreted as a Follow the Regularized Leader algorithm with a convex regularizer! By applying Theorem 2 and Lemma 5, we can easily bound the regret of the resulting algorithm as follows.\nTheorem 4. Let C be any valid convex cost function yielding \u03c6-stable prices, and let \u03b1C be the penalty function associated with C. Let A be the expert learning algorithm with weights as in Equation 5 with \u01eb = \u221a\n2 sup~p,~p \u2032\u2208\u2206N (\u03b1C(~p)\u2212 \u03b1C(~p \u2032))/(\u03c6T ). Then for any sequence of expert losses \u2113i,t \u2208 [0, 1] over T time steps,\nLA,T \u2212 min i\u2208{1,\u00b7\u00b7\u00b7 ,N}\nLi,T \u2264 \u221a\n2T\u03c6 sup ~p,~p \u2032\u2208\u2206N\n(\u03b1C(~p)\u2212 \u03b1C(~p \u2032)) .\nThis bound is very similar to the bound for FTRL given in Equation 4, with \u03c6 playing the role of \u03bb.\nThe connections we established in the previous section imply that every strictly proper market scoring rule can also be interpreted as a FTRL algorithm, now with a strictly convex regularizer. Conversely, any FTRL algorithm with a differentiable and strictly convex regularizer can be viewed as choosing weights at time t to minimize the quantity\nN \u2211\ni=1\nwi (\u01ebLi,t\u22121 + si(~w))\nfor a strictly proper scoring rule ~s. Perhaps it is no surprise that the weight updates of FTRL algorithms can be framed in terms of proper scoring rules given that proper scoring\nrules are commonly used as loss functions in machine learning [3, 32] and FTRL has previously been connected to Bregman divergences [34, 18, 17] which are known to be related to scoring rules [12].\nThis connection hints at why market scoring rules and convex cost function based markets may be able to obtain accurate estimates of probability distributions in practice. Both types of markets are essentially learning the distributions by treating market trades as training data. Beyond that, both markets correspond to well-understood learning algorithms with stable weights and guarantees of no regret."}, {"heading": "5.4 Relation to the SCPM", "text": "Agrawal et al. [1] present another way of describing convex cost function based prediction markets, which they call the Sequential Convex Pari-Mutuel Mechanism (SCPM). The SCPM is defined in terms of limit orders instead of market prices, but the underlying mathematics are essentially the same. In the SCPM, traders specify a maximum quantity of shares that they would like to purchase and a maximum price per share that they are willing to spend. The market then decides how many shares of the trade to accept by solving a convex optimization problem.\nAgrawal et al. [1] show that for every SCPM, there is an equivalent convex cost function based market. For each limit order, the number of shares accepted by the market maker in the SCPM is the minimum of the number of shares requested by the trader and the number of shares that it would take to drive the market price of the shares in the corresponding cost function based market to the limit price of the trader. Thus our results imply that any SCPM mechanism can also be interpreted as a Follow the Regularized Leader algorithm for learning from expert advice.\nWe remark that Agrawal et al. [1] also describe an interpretation of the SCPM in terms of convex risk measures and suggest that the associated penalty function is related to the underlying problem of learning the distribution over outcomes. However, their interpretation is very different from ours. They view the penalty function as characterizing \u201cthe market maker\u2019s commitment to learning the true distribution\u201d since it impacts both the worst case market maker loss and the willingness of the market maker to accept limit orders. On the contrary, we view the penalty function as a regularizer necessary to make the market prices stable."}, {"heading": "6. EXAMPLE: THE QUADRATIC MSR AND ONLINE GRADIENT DESCENT", "text": "In the previous section we described the relationship between market scoring rules, cost function based markets with convex cost functions, and Follow the Regularized Leader algorithms. We discussed how the Logarithmic Market Scoring Rule can be represented equivalently as a cost function based market, and how it corresponds to Weighted Majority in the expert learning setting. In this section, we illustrate the relationship through another example. In particular, we show that the Quadratic Market Scoring Rule can be written equivalently as a cost function based market (namely the Quad-SCPM of Agrawal et al. [1]). We then show that this market corresponds to the well-studied online gradient descent algorithm in the learning setting and give a bound on the regret of this algorithm using Theorem 4.\nThe Quadratic Market Scoring Rule (QMSR) is the mar-\nket scoring rule corresponding to the quadratic scoring function in Equation 1. As was the case in the LMSR, the parameters a1, \u00b7 \u00b7 \u00b7 , aN do not affect the prices or payments of this market. As such, we assume that ai = 0 for all i.\nTheorem 3 implies that we can construct a cost function based market with equivalent payoffs to the QMSR whenever prices are nonzero using the cost function\nC(~q) = sup ~p\u2208\u2206N\n(\nN \u2211\ni=1\npiqi \u2212 N \u2211\ni=1\npib\n(\n2pi \u2212 N \u2211\ni=1\np2i\n))\n= sup ~p\u2208\u2206N\n(\nN \u2211\ni=1\npiqi \u2212 b N \u2211\ni=1\np2i\n)\n.\nThis is precisely the cost function associated with the QuadSCPM market with a uniform prior, which was previously known to be equivalent to the QMSR when prices are nonzero [1]. The worst case loss of the market maker in both markets is b(N \u2212 1)/N .\nFollowing the argument in Section 5.3, this market corresponds to the FTRL algorithm with regularizer \u03b7 = 1/b and R(~w) = \u2211Ni=1 w2i . It has been observed that using FTRL with a regularizer of this form is equivalent to online gradient descent [19, 17]. Thus we can use Theorem 4 to show a regret bound for gradient descent.\nWe first show that the Quad-SCPM prices are \u03c6-stable for \u03c6 = (N2\u22121)/(2b) < N2/(2b). (See Appendix C for details.) We can therefore apply Theorem 4 using \u03c6 = N2/(2b) and sup~p,~p \u2032\u2208\u2206N (\u03b1(~p)\u2212 \u03b1(~p\n\u2032)) = b(N \u2212 1)/N < b to see that for gradient descent,\nLGD,T \u2212 min i\u2208{1,\u00b7\u00b7\u00b7 ,N}\nLi,T \u2264 N \u221a T .\nThis matches the known regret bound for general gradient descent applied to the experts setting [35]."}, {"heading": "7. DISCUSSION", "text": "We have demonstrated the elegant mathematical connection between market scoring rules, cost function based prediction markets, and no-regret learning. This connection is thought-provoking on its own, as it yields to new interpretations of well-known prediction market mechanisms. The interpretation of the penalty function as a regularizer can shed some light on which market scoring rule or cost function based market is best to run under different assumptions about traders.\nAdditionally, this connection has the potential to be of use in the design of new prediction market mechanisms and learning algorithms. In recent years there has been an interest in finding ways to tractably run market scoring rules over combinatorial or infinite outcome spaces [7, 10, 6]. For example, a market maker might wish to accept bets over permutations (\u201chorse A will finish the race ahead of horse B\u201d), Boolean spaces (\u201ceither a Democrat will win the 2010 senate race in Delaware or a Democrat will win in North Dakota\u201d), or real numbers (\u201cGoogle\u2019s revenue in the first quarter of 2010 will be between $x and $y\u201d), in which case simply running a naive implementation of an LMSR (for example) would be infeasible. As mentioned above, by exploiting the connection between Weighted Majority and the LMSR, Chen et al. [6] showed that an extension of the Weighted Majority algorithm to permutation learning [20] could be used to approximate prices in an LMSR over per-\nmutations. Given our new understanding of the connection between markets and learning and the growing literature on no-regret algorithms for large or infinite sets of experts [21], it seems likely that similar learning-based techniques could be developed to calculate market prices for other types of large outcome spaces too."}, {"heading": "A. PROOF OF LEMMA 2", "text": "Fix the vectors ~q and ~r. Let ~u(s) = ~q + s~r. Similarly to how we have defined Di,j(~t), define\nDi(x) =\n{\n\u2202pi(~u(s)) \u2202s\n\u2223 \u2223 \u2223\ns=x if \u2202pi(~u(s)) \u2202s is defined at x,\n0 otherwise.\nUsingDi in place of the derivative allows us to integrate over the derivative even when it is not defined at single points. For any point at which the derivatives are defined, we have\n\u2202C(~u(s))\n\u2202s =\nN \u2211\ni=1\n\u2202C(~u(s))\n\u2202ui(s)\n\u2202ui(s)\n\u2202s =\nN \u2211\ni=1\npi(~u(\u00b7))ri .\nApplying the fundamental theorem of calculus, we have that\nC(~q + ~r)\u2212 C(~q)\n=\n\u222b 1\n0\n\u2202C(~u(s))\n\u2202s\n\u2223 \u2223 \u2223 \u2223\ns=x\ndx =\n\u222b 1\n0\nN \u2211\ni=1\npi(~u(x))ri dx\n=\n\u222b 1\n0\nN \u2211\ni=1\n(\npi(~u(0)) +\n\u222b x\n0\nDi(y)dy\n)\nri dx\n= N \u2211\ni=1\npi(~q)ri +\n\u222b 1\n0\n\u222b x\n0\nN \u2211\ni=1\nriDi(y) dy dx .\nRearranging terms, this gives us that\nC(~q + ~r)\u2212 C(~q)\u2212 N \u2211\ni=1\npi(~q)ri =\n\u222b 1\n0\n\u222b x\n0\nN \u2211\ni=1\nriDi(y) dy dx.\nTo prove the lemma, it is sufficient to bound the absolute value of the expression on the right. This is where the \u03c6stability of the prices comes into play. At any point where the derivatives are defined,\nN \u2211\ni=1\n\u2223 \u2223 \u2223 \u2223 \u2202pi(~u(s))\n\u2202s\n\u2223 \u2223 \u2223 \u2223 = N \u2211\ni=1\n\u2223 \u2223 \u2223 \u2223 \u2223 N \u2211\nj=1\n\u2202pi(~q)\n\u2202qj rj\n\u2223 \u2223 \u2223 \u2223 \u2223 \u2264 \u01eb N \u2211\ni=1\nN \u2211\nj=1\n\u2223 \u2223 \u2223 \u2223 \u2202pi(~q)\n\u2202qj\n\u2223 \u2223 \u2223 \u2223\n\u2264 \u01eb\u03c6 .\nSince we have assumed that the prices are piecewise differentiable this implies that\n\u2223 \u2223 \u2223 \u2223 \u2223 \u222b 1\n0\n\u222b x\n0\nN \u2211\ni=1\nriDi(y) dy dx\n\u2223 \u2223 \u2223 \u2223 \u2223\n\u2264 \u01eb \u222b 1\n0\n\u222b x\n0\nN \u2211\ni=1\n|Di(y)| dy dx\n\u2264 \u01eb \u222b 1\n0\n\u222b x\n0\n\u01eb\u03c6 dy dx = \u01eb2\u03c6\n\u222b 1\n0\nx dx = \u01eb2\u03c6\n2 .\nThis bounds the absolute value of the right hand side of the equation above and proves the lemma.\nB. PROOF OF LEMMA 3\nFor every i and every j 6= i, we have\n\u2202pi(~q)\n\u2202qi =\n\u2202\n\u2202qi\neqi/b \u2211N\nj=1 e qj/b\n= 1\nb\neqi/b \u2211N j=1 e qj/b \u2212\n( eqi/b )2\n(\n\u2211N j=1 e\nqj/b )2\n= 1\nb\n( pi(~q)\u2212 pi(~q)2 ) = 1\nb pi(~q)\n\u2211\nj 6=i\npj(~q)\nand\n\u2202pi(~q)\n\u2202qj =\n\u2202\n\u2202qj\neqi/b \u2211N\nj=1 e qj/b\n= 1\nb\n\u2212eqi/beqj/b (\n\u2211N j=1 e\nqj/b )2\n= \u22121 b pi(~q)pj(~q) .\nThus we have\nN \u2211\ni=1\nN \u2211\nj=1\n\u2223 \u2223 \u2223 \u2223 \u2202pi(~q)\n\u2202qj\n\u2223 \u2223 \u2223 \u2223 = N \u2211\ni=1\n\u2223 \u2223 \u2223 \u2223 \u2202pi(~q)\n\u2202qi\n\u2223 \u2223 \u2223 \u2223 + N \u2211\ni=1\n\u2211\nj 6=i\n\u2223 \u2223 \u2223 \u2223 \u2202pi(~q)\n\u2202qj\n\u2223 \u2223 \u2223 \u2223\n= 2\nb\nN \u2211\ni=1\n\u2211\nj 6=i\npi(~q)pj(~q) .\nWe would like to find the prices that maximize this quantity. Dropping the argument ~q to simply notation, this is equivalent to solving a simple optimization problem:\nmaximize ~p\u2208\u2206N\n2\nb\nN \u2211\ni=1\n\u2211\nj 6=i\npipj .\nIt is straight-forward to show (e.g., using the KKT conditions) that this expression is maximized when the prices are equal across all securities, so pi = 1/N for all i. Then\nN \u2211\ni=1\nN \u2211\nj=1\n\u2223 \u2223 \u2223 \u2223 \u2202pi(~q)\n\u2202qj\n\u2223 \u2223 \u2223 \u2223 \u2264 2 b N(N \u2212 1) N2 \u2264 2 b ."}, {"heading": "C. STABILITY OF QUAD-SCPM PRICES", "text": "The cost function of Quad-SCPM can be written as\nC(~q) = sup ~p\u2208\u2206N\n(\nN \u2211\ni=1\npiqi \u2212 b N \u2211\ni=1\np2i\n)\n.\nBy Lemma 4, the price function of Quad-SCPM is defined by the optimal solution to the optimization problem in this function. The Lagrange function corresponding to the constrained optimization problem is\nL =\n(\nn \u2211\ni=1\npiqi \u2212 b N \u2211\ni=1\np2i\n) \u2212 \u03bb ( N \u2211\ni=1\npi \u2212 1 ) + N \u2211\ni=1\n\u00b5ipi.\nBecause the objective function is strictly concave in ~p, there is a unique optimal solution that satisfies the KKT conditions: \u2202L/\u2202pi = 0 \u2200i, \u2211N i=1 pi = 1, pi \u2265 0 \u2200i, \u00b5i \u2265 0 \u2200i,\nand \u00b5ipi = 0 \u2200i. Thus, the price function is defined by \n  \n  \npi = 1 N + qi+\u00b5i 2b\n\u2212 \u2211N j=1(qj+\u00b5j)\n2bN \u2200i\npi\u00b5i = 0 \u2200i pi \u2265 0 \u2200i \u00b5i \u2265 0 \u2200i.\n(13)\nWhen 1/N + qi/(2b) \u2212 \u2211N\ni=1 qi/(2bN) > 0, \u00b5i = 0 and pi > 0 for all i and the price function is\npi(~q) = 1\nN + qi 2b\n\u2212 \u2211N j=1 qj\n2bN ,\nwhich is the same as that of QMSR. In this case, we have\n\u2202pi \u2202qi = 1 2b \u2212 1 2bN \u2200i and \u2202pi \u2202qj = \u2212 1 2bN \u2200j 6= i .\nConsider the case in which the prices for some outcomes equal 0. Given ~q, let M = {m : pm > 0, \u00b5m = 0} be the set of outcomes that have positive prices. Let K = {k : pk = 0, \u00b5k > 0} be the set of the outcomes that have a positive \u00b5k. Let L = {l : pl = 0, \u00b5l = 0} be the set of outcomes for which both pl and \u00b5l are 0. Denote p\u0303 = minm\u2208M pm and \u00b5\u0303 = mink\u2208K \u00b5k. For 0 < |\u01eb| < min{\u00b5\u0303, 2bp\u0303(N \u2212 |K| \u2212 |L|)}, we consider the following cases:\n\u2022 L = \u2205 and i \u2208 M Consider changing ~q to ~q \u2032, where q\u2032i = qi + \u01eb and q \u2032 j =\nqj \u2200j 6= i. We can verify that the price function for ~q \u2032 is defined by\n\n    \n    \np\u2032i = pi + ( 1 2b \u2212 1 2b(N\u2212|K|) )\u01eb p\u2032j = pj \u2212 \u01eb2b(N\u2212|K|) \u2200j \u2208 M, j 6= i p\u2032k = pk = 0 \u2200k \u2208 K \u00b5\u2032j = \u00b5j = 0 \u2200j \u2208 M \u00b5\u2032k = \u00b5k + \u01eb N\u2212|K| \u2200k \u2208 K\nwhere ~p and ~\u00b5 are the prices and Lagrange multipliers for ~q. Hence, by the definition of derivatives, we have\n\u2202pi \u2202qi = 1 2b \u2212 1 2b(N \u2212 |K|) \u2200i \u2208 M ,\n\u2202pj \u2202qi = \u2212 1 2b(N \u2212 |K|) \u2200i, j \u2208 M, i 6= j ,\n\u2202pk \u2202qi = 0 \u2200k \u2208 K, i \u2208 M .\n\u2022 L 6= \u2205 and i \u2208 M Consider changing ~q to ~q \u2032, where q\u2032i = qi + \u01eb and q \u2032 j =\nqj \u2200j 6= i. The new prices are defined by \n      \n      \np\u2032i = pi + ( 1 2b \u2212 1 2b(N\u2212|K|\u2212|L|) )\u01eb p\u2032j = pj \u2212 \u01eb2b(N\u2212|K|\u2212|L|) \u2200j \u2208 M, j 6= i p\u2032k = pk = 0 \u2200k \u2208 K p\u2032l = pl = 0 \u2200l \u2208 L \u00b5\u2032j = \u00b5j = 0 \u2200j \u2208 M \u00b5\u2032k = \u00b5k + \u01eb N\u2212|K|\u2212|L|\n\u2200k \u2208 K \u00b5\u2032l = \u00b5l + \u01eb N\u2212|K|\u2212|L| \u2200l \u2208 L\nif \u01eb > 0, and \n      \n      \np\u2032i = pi + ( 1 2b \u2212 1 2b(N\u2212|K|) )\u01eb p\u2032j = pj \u2212 \u01eb2b(N\u2212|K|) \u2200j \u2208 M, j 6= i p\u2032k = pk = 0 \u2200k \u2208 K p\u2032l = pl \u2212 \u01eb2b(N\u2212|K|) \u2200l \u2208 L \u00b5\u2032j = \u00b5j = 0 \u2200j \u2208 M \u00b5\u2032k = \u00b5k + \u01eb N\u2212|K|\n\u2200k \u2208 K \u00b5\u2032l = \u00b5l = 0 \u2200l \u2208 L\nif \u01eb < 0.\nFrom the above, we can see that the prices of all outcomes are continuous while we changing qi in its \u01ebneighborhood. However, \u2202pi/\u2202qi, \u2202pj/\u2202qi, and \u2202pl/\u2202qi are not defined at ~q for all i, j \u2208 M , i 6= j, and l \u2208 L, because the left and right derivatives do not equal. We only have \u2202pk/\u2202qi = 0 for all k \u2208 K and i \u2208 M .\n\u2022 L 6= \u2205, l \u2208 L When changing ~q to ~q \u2032, where q\u2032l = ql + \u01eb and q \u2032 j =\nqj \u2200j 6= l, similar to the above case, the new optimal solution is different for \u01eb > 0 and \u01eb < 0. In particular, when \u01eb > 0,\np\u2032l = pl + ( 1 2b \u2212 1 2b(N \u2212 |K|) )\u01eb,\np\u2032j = pj \u2212 \u01eb\n2b(N \u2212 |K|) \u2200j \u2208 M \u222a L such that j 6= l,\nand p\u2032k = pk = 0 \u2200k \u2208 K. When \u01eb < 0, p\u2032j = pj \u2200j, \u00b5\u2032l = \u00b5l \u2212 \u01eb, and \u00b5\u2032j = \u00b5j \u2200j 6= k. We can see that the prices of all outcomes are continuous while we changing ql in its \u01eb-neighborhood. But \u2202pl/\u2202ql and \u2202pj/\u2202ql are not defined at ~q for all j \u2208 M \u222aL, j 6= l, and l \u2208 L, because the left and right derivatives do not equal. \u2202pk/\u2202ql = 0 for all k \u2208 K and l \u2208 L.\n\u2022 k \u2208 K Consider changing ~q to ~q \u2032, where q\u2032k = qk + \u01eb and q \u2032 j =\nqj \u2200j 6= k, the new prices are defined by p\u2032j = pj \u2200j, \u00b5\u2032k = \u00b5k \u2212 \u01eb, and \u00b5\u2032j = \u00b5j \u2200j 6= k. Thus, we have \u2202pk/\u2202qk = 0 \u2200k \u2208 K, \u2202pj/\u2202qk = 0 \u2200k, j \u2208 K, and \u2202pj/\u2202qk = 0 \u2200j \u2208 M, k \u2208 K.\nThe above shows that the price functions are continuous everywhere, but not differentiable everywhere. In particular, when L is not empty (i.e., given ~q there exists some outcome i such that both pi(~q) and \u00b5i(~q) are zero), some of the partial derivatives are not defined at ~q. This corresponds to the second and third cases shown above. We further note that in these two cases, for any i \u2208 M and l \u2208 L, any change in qi or ql will cause the set of L to become empty, because either pl or \u00b5l will become positive for all l \u2208 L. This means that the prices are differentiable almost everywhere, with the only exceptions at finite number of points when L 6= \u2205.\nBecause 0 \u2264 |K| \u2264 N \u2212 1, 0 \u2264 Di,i(t) \u2264 1/(2b)\u2212 1/(2bN) and \u22121/(2b) \u2264 Di,j(t) \u2264 0. We have N \u2211\ni=1\nN \u2211\nj=1\n|Di,j(t)| \u2264 N ( 1 2b \u2212 1 2bN ) +N(N\u22121) 1 2b = N2 \u2212 1 2b ."}], "references": [], "referenceMentions": [], "year": 2010, "abstractText": "We explore the striking mathematical connections that exist between market scoring rules, cost function based prediction markets, and no-regret learning. We show that any cost function based prediction market can be interpreted as an algorithm for the commonly studied problem of learning from expert advice by equating trades made in the market with losses observed by the learning algorithm. If the loss of the market organizer is bounded, this bound can be used to derive an O( \u221a T ) regret bound for the corresponding learning algorithm. We then show that the class of markets with convex cost functions exactly corresponds to the class of Follow the Regularized Leader learning algorithms, with the choice of a cost function in the market corresponding to the choice of a regularizer in the learning problem. Finally, we show an equivalence between market scoring rules and prediction markets with convex cost functions. This implies that market scoring rules can also be interpreted naturally as Follow the Regularized Leader algorithms, and may be of independent interest. These connections provide new insight into how it is that commonly studied markets, such as the Logarithmic Market Scoring Rule, can aggregate opinions into accurate estimates of the likelihood of future events.", "creator": "LaTeX with hyperref package"}}}