{"id": "1106.1821", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "9-Jun-2011", "title": "Collective Intelligence, Data Routing and Braess' Paradox", "abstract": "we consider the problem of determining the autonomous utility functions of the utility - maximizing agents in a multi - agent system structure that all engage synergistically to maximize a global utility. the particular problem domain we explore is the control of network entropy by placing agents on all the routers in the node. multiple approaches to this task have the agents strategically use the ideal shortest path routing algorithm ( ispa ). we demonstrate that in many cases, due to the side - imposed of one agent's actions on local agent's performance, having agents manipulating ispa's output suboptimal as far as finite aggregate cost is concerned, even when they are only trying to detect infinitesimally small amounts processing traffic. the utility rules of the individual agents are not \" aligned \" with the global utility, intuitively speaking. as a particular example involving this we present an instance of braess'paradox in which adding direct links to a network whose agents all choose the item results in a decrease on overall throughput. we also demonstrate that load - balancing, during which the agents'decisions are collectively made to optimize the global cost incurred by all traffic currently being routed, is suboptimal as far as global cost averaged across time is concerned. this is also due to'side - effects ', in this case of current transaction decision on irrelevant components. the mathematics subject collective intelligence ( fae ) largely concerned precisely with the issue of avoiding minimal interference side - effects in multi - agent systems, both over earth and space. we present key concepts from that mathematics : use them to derive an algorithm whose ideal version should have better performance than way of having all agents use the protocol, even in naturally infinitesimal fashion. we present experiments verifying this, and observed showing that a machine - learning - based version that this coin algorithm supporting accounting costs are only imprecisely estimated via empirical means ( a version practically applicable in the real world ) also outperforms the ispa, despite having access to less information than does the ispa. in particular, this coin algorithm almost always avoids braess'paradox.", "histories": [["v1", "Thu, 9 Jun 2011 13:57:43 GMT  (134kb)", "http://arxiv.org/abs/1106.1821v1", null]], "reviews": [], "SUBJECTS": "cs.AI", "authors": ["k tumer", "d h wolpert"], "accepted": false, "id": "1106.1821"}, "pdf": {"name": "1106.1821.pdf", "metadata": {"source": "CRF", "title": null, "authors": ["David H. Wolpert", "dhw ptolemy.ar", "Kagan Tumer"], "emails": [], "sections": [{"heading": "Journal of Arti ial Intelligen e Resear h 16 (2002) 359-387 Submitted 12/01; published 6/02", "text": "Colle tive Intelligen e, Data Routing and Braess' ParadoxDavid H. Wolpert dhw ptolemy.ar .nasa.govNASA Ames Resear h Center, Mailstop 269-2Mo ett Field, CA 94035Kagan Tumer kagan ptolemy.ar .nasa.govNASA Ames Resear h Center, Mailstop 269-3Mo ett Field, CA 94035 Abstra tWe onsider the problem of designing the the utility fun tions of the utility-maximizingagents in a multi-agent system (MAS) so that they work synergisti ally to maximize a globalutility. The parti ular problem domain we explore is the ontrol of network routing bypla ing agents on all the routers in the network. Conventional approa hes to this task havethe agents all use the Ideal Shortest Path routing Algorithm (ISPA). We demonstrate thatin many ases, due to the side-e e ts of one agent's a tions on another agent's performan e,having agents use ISPA's is suboptimal as far as global aggregate ost is on erned, evenwhen they are only used to route in nitesimally small amounts of tra\u00c6 . The utilityfun tions of the individual agents are not \\aligned\" with the global utility, intuitivelyspeaking. As a parti ular example of this we present an instan e of Braess' paradox inwhi h adding new links to a network whose agents all use the ISPA results in a de reasein overall throughput. We also demonstrate that load-balan ing, in whi h the agents'de isions are olle tively made to optimize the global ost in urred by all tra\u00c6 urrentlybeing routed, is suboptimal as far as global ost averaged a ross time is on erned. Thisis also due to \\side-e e ts\", in this ase of urrent routing de ision on future tra\u00c6 . Themathemati s of Colle tive Intelligen e (COIN) is on erned pre isely with the issue ofavoiding su h deleterious side-e e ts in multi-agent systems, both over time and spa e.We present key on epts from that mathemati s and use them to derive an algorithmwhose ideal version should have better performan e than that of having all agents usethe ISPA, even in the in nitesimal limit. We present experiments verifying this, and alsoshowing that a ma hine-learning-based version of this COIN algorithm in whi h osts areonly impre isely estimated via empiri al means (a version potentially appli able in the realworld) also outperforms the ISPA, despite having a ess to less information than does theISPA. In parti ular, this COIN algorithm almost always avoids Braess' paradox.1. Introdu tionThere is a long history of AI resear h on the design of distributed omputational systems,stret hing from Distributed AI (Huhns, 1987) through urrent work on multi-agent systems(MAS's) (Claus & Boutilier, 1998; Hu & Wellman, 1998a; Jennings, Sy ara, & Wooldridge,1998; Sandholm, Larson, Anderson, Shehory, & Tohme, 1998; Sy ara, 1998). When theindividual agents in su h a system ea h have personal utility fun tions they are trying tomaximize and we also have a `world utility' that rates the possible dynami histories ofthe overall system, su h a MAS onstitutes a ` olle tive'. In this paper we are parti ularly on erned with agents that use ma hine learning te hniques (e.g., Reinfor ement Learning 2002 AI A ess Foundation and Morgan Kaufmann Publishers. All rights reserved.\nWolpert & Tumer(RL) Kaelbing, Littman, & Moore, 1996; Sutton & Barto, 1998; Sutton, 1988; Watkins &Dayan, 1992) to try to maximize their utilities.The eld of Colle tive Intelligen e (COIN) is on erned with the entral design problemfor olle tives (Wolpert, Tumer, & Frank, 1999; Wolpert & Tumer, 1999): How, withoutany detailed modeling of the overall system, an one set utility fun tions for the individualagents in a COIN so that the overall dynami s reliably and robustly a hieves large valuesof the provided world utility? In other words, how an we leverage an assumption thatour learners are individually fairly good at what they do, to have the olle tive as a wholeperform well? 1An example of where this question looms very large is the problem of how to optimize the ow of ertain entities (e.g., information pa kets, ars) from sour es to destinations a rossa network of routing nodes. Here we are on erned with the version of the problem inwhi h \\optimization\" onsists of minimizing aggregate ost in urred by the entities owingto their destinations, and where an agent ontrols the routing de isions of ea h node inthe network. This problem underlies the distributed ontrol of a large array of real-worlddomains, in luding internet routing, voi e/video ommuni ation, tra\u00c6 ows, et . Fromthe COIN perspe tive, the problem redu es to the question of what goals one ought toprovide to ea h router's agent so that ea h agent's self-interestedly pursuing its own utilityresults in maximal throughput of the entire system (\\in entive engineering\").In this paper we investigate the appli ation of re ently developed COIN te hniques,to this routing domain. Like all work on erning COINs, these te hniques are designedto be very broadly appli able, and in parti ular are not designed for the routing domain.A ordingly, their performan e in this domain serves as a good preliminary indi ation oftheir more general usefulness.To ground the dis ussion, we will on entrate on the tele ommuni ations data routingproblem where the entities being routed are pa kets. Currently, many real-world algorithmsfor this problem are based on the Shortest Path Algorithm (SPA). In this algorithm ea hrouting node in the network is ontrolled by an agent who maintains a \\routing table\" of the\\shortest paths\" (i.e., sequen es of links having minimal total in urred osts) from its nodeto ea h of the possible destination nodes in the net. Then at ea h moment the agent satis esany routing requests for a parti ular destination node by sending all its pa kets down theasso iated shortest path. Many Ideal SPA (ISPA) algorithms exist for e\u00c6 iently omputingthe shortest path when agent-to-agent path- ost ommuni ation is available and the ostsfor traversing ea h agent's node are unvarying in time, e.g., Dijkstra's Algorithm (Ahuja,Magnanti, & Orlin, 1993; Bertsekas & Gallager, 1992; Deo & Pang, 1984; Dijkstra, 1959).If a non-in nitesimal amount of tra\u00c6 is to be routed to a parti ular destination at somemoment by some agent, then that agent's sending all that tra\u00c6 down a single path willnot result in minimal ost, no matter how that single path is hosen. However if it must hoose a single path for all its tra\u00c6 , and if the routing de isions by all other agents are xed, then tautologi ally by using the ISPA the agent hooses the best su h path, as far asthe tra\u00c6 it is routing is on erned. A ordingly, in the limit of routing an in nitesimally1. The la k of detailed modeling ensures that we do not fa e the problems of \\brittleness\" that sometimesa ompany mismat h between the real world and the assumptions on erning it built into non-adaptive,\\hard-wired\" agents in large MAS's. In turn, this la k of modeling is what auses us to on entrate onadaptive, RL-based agents. 360\nColle tive Intelligen e, Data Routing and Braess' Paradoxsmall amount of tra\u00c6 , with all other agents' strategies being a \\ba kground\", the ISPA isthe optimal (least aggregate in urred ost) routing strategy for the tra\u00c6 of the asso iatedsingle agent onsidered individually.One might hope that more generally, if the agent must allot all of its tra\u00c6 to a singlepath and all other agents' tra\u00c6 de isions are xed, then its hoosing that path via theISPA would be the hoi e that minimizes total in urred ost of all tra\u00c6 a ross the net, atleast in the limit of in nitesimally little tra\u00c6 . This is not the ase though, be ause in usingthe SPA the agent is not on erned with the deleterious side-e e ts of its a tions on the osts to the tra\u00c6 routed by other agents (Korilis, Lazar, & Orda, 1997a; Wolpert et al.,1999). The problem is made all the worse if the other agents are allowed to hange theirde isions in response to our agent's de ision. In the extreme ase, as elaborated below, ifall agents were to try to minimize their personal osts via ISPA's, then the agents woulda tually all re eive higher ost than would be the ase under an alternative set of strategies.This is an instan e of the famous Tragedy Of the Commons (TOC) (Hardin, 1968).Deleterious side-e e ts need not be restri ted to extend over spa e; they an also extendover time. Indeed, onsider the algorithm of having all agents at a given moment makerouting de isions that optimize global ost in urred by the tra\u00c6 urrently being routed,an algorithm often alled \\load-balan ing\" (LB) (Heusse, Snyers, Guerin, & Kuntz, 1998).By de nition, LB avoids the deleterious side-e e ts over spa e that an result in the TOCfor the osts in urred by the tra\u00c6 urrently being routed. However, due to side-e e tsover time, even onventional LB an be suboptimal as far as global ost averaged a rosstime is on erned. Intuitively, one would have to use \\load-balan ing over time\" to ensuretruly optimal performan e. So even if one ould somehow onstru t a distributed proto olgoverning the the agents that aused them to implement LB, still one would not havegotten theme to all a t in a perfe tly oordinated fashion. Su h di\u00c6 ulties make this anappropriate domain in whi h to investigate how well COIN te hniques work in pra ti e.Real-world SPA's (RSPA) work by applying an ISPA to the estimated osts for traversingea h path of every agent. Typi ally those estimates will be in error be ause agent-to-agent ommuni ation is not instantaneous, and therefore routing tables may be based on out ofdate information. More generally though, even if that ommuni ation were instantaneous,the ost to traverse an agent's node may be di erent by the time the pa ket arrives atthat node. A ordingly, in general the performan e of RSPA's is bounded above by thatof the asso iated ISPA. In this paper we do not wish to investigate su h topi s, but ratherto highlight the issue of side-e e ts. A ordingly we \\rig the game\" in our experimental omparisons in favor of the SPA, by using ISPA's rather than RSPA's.In general, even without side-e e ts, determining the optimal solution to a ow problem(e.g., determining what the loads on ea h link need to be to maximize throughput on anon- ooperative data network) an be nontra table (Ahuja et al., 1993; Orda, Rom, & Sidi,1993b). Therefore, we will on ern ourselves with providing good solutions that avoid thedi\u00c6 ulties the ISPA has with side-e e ts. It is not our aim here to present algorithmsthat nd the best possible (perfe tly load-balan ed over time) solution. Previous work onusing ma hine learning to improve routing has sometimes resulted in better performan ethan (non-idealized) SPA's (Littman & Boyan, 1993; Boyan & Littman, 1994; Stone, 2000;Marba h, Mihats h, S hulte, & Tsisiklis, 1998). That work has not grappled with the entral COIN design problem however. 361\nWolpert & TumerIn Se tion 2 we dis uss SPA's de ien ies and in parti ular their manifestations inBraess' paradox. Then, in Se tion 3 we present the theory of olle tive intelligen e, anapproa h that promises to over ome those de ien ies. We then dis uss the routing modelwe will use in our experiments, and show how the theory of COINs an be applied to thatmodel to provide an alternative to shortest path algorithms in Se tion 3. In Se tion 5we present simulation results with that model omparing ISPA to COINs. These resultsdemonstrate that in networks running ISPA, the per pa ket osts an be as mu h as 32% higher than in networks running algorithms based on COIN theory. In parti ular, eventhough it only has a ess to impre ise estimates of osts (a handi ap that does not hold forISPA), the COIN-based algorithm almost always avoids Braess' paradox, in stark ontrastto the ISPA. In that the ost in urred with ISPA's is presumably a lower bound on thatof an SPA not privy to instantaneous ommuni ation, the impli ation is that COINs anoutperform su h real-world SPA's. We on lude that the te hniques of the eld of olle tiveintelligen e an be highly e e tive in designing the utility fun tions of the members of a MASto ensure they work in a oordinated and e\u00c6 ient manner to optimize overall performan e.2. Suboptimality of Shortest Path Routing and Braess ParadoxIn this se tion we rst demonstrate the suboptimality of an SPA when we have multipleagents making simultaneous routing de isions, where no agent knows ahead of time theother's hoi e, and therefore does not know ahead of time exa tly what the osts will be.We then demonstrate that su h suboptimality an hold even when only one agent is makinga de ision, and it knows what de isions the others have previously made. Next we presentBraess' paradox, a parti ularly pointed instan e of these e e ts (for other dis ussion ofBraess' paradox in SPA routing, see Bass, 1992; Cohen & Kelly, 1990; Cohen & Je ries,1997; Hogg, 1995; Glan e & Hogg, 1995; Korilis, Lazar, & Orda, 1999).2.1 Suboptimality of SPAPerhaps the simplest example of how individual greed on the part of all agents an leadto their olle tive detriment o urs when two agents determine that their shortest path isthrough a shared link with a limited apa ity, while both have a se ond option that is slightlyless preferable. In su h a ase, their using the ommon link degrades the performan e ofboth parties, sin e due to limited apa ity the performan e of that link will qui kly fallbelow that of their se ond option.More pre isely, onsider the ase where the shared link has a ost given by x3 whentraversed by x pa kets, and where ea h router has an optional se ond link to the destinationwhere the ost for tra\u00c6 x to traverse su h a se ond link is 2x. A ting alone, with a singlepa ket to send, they would both send that pa ket through the shared link ( ost of 1).However by both doing so, they in ur a larger ost ( ost of 8) than if they had both usedtheir se ond hoi es ( ost of 4). Without knowing what ea h other will do ahead of time(information not onventionally ontained in routing tables), the agents will ne essarilyhave mistaken ost estimates and therefore make in orre t routing de isions. In this, evenin the limit of di erentially small pa kets, use of SPA will lead to a wrong routing de ision.362\nColle tive Intelligen e, Data Routing and Braess' Paradox2.2 Suboptimality of ISPAWe now analyze a situation where the routers may know what the loads are but are ea ha ting to optimize the delays experien ed by their pa kets alone. Consider the networkshown in Figure 1. Two sour e routers X and Y ea h send one pa ket at a time, with Xsending to either intermediate router A or B, and Y sending to either B or C. This typeof network may arise in many di erent topologies as a subnetwork. A ordingly, di\u00c6 ultiesasso iated with this network an also apply to many more omplex topologies. yXJJJJJ JJJ yYJJJJJ JJJ\nyA yB yC Figure 1: Independent de isions at the sour eLet xA, xB, yB , and yC , be the pa ket quantities at a parti ular xed time t, at A, B,or C, and originating from X or Y , as indi ated. At t, ea h sour e has one pa ket to send.So ea h of our variables is binary, with xA + xB = yB + yC = 1. Have Vi(zi) be the ost,per pa ket, at the single instant t, at router i, when the total number of pa kets at thatinstant on that router is zi. So the total ost in urred by all pa kets at the time t, G(~x; ~y),equals xAVA(xA) + (xB + yB)VB(xB + yB) + (yC)VC(yC).In an ISPA, X hooses whi h of xA or xB = 1 so as to minimize the ost in urred byX's pa ket alone, gX(~x) xAVA(xA) + xBVB(xB + yB). In doing this the ISPA ignores theyBVB(xB + yB) term, i.e., it ignores the \\side e e ts\" of X's de ision. Real-world SPA'stypi ally try to approximate this by having X hoose either A or B a ording to whetherVA(0) or VB(yB) is smaller, where those two values an be estimated via pings, for example.The right thing to do from the point of view of minimizing the global ost of ourseis instead to have X minimize G(~x; ~y), or more pre isely, the omponents of G(~x; ~y) thatdepend on X. Writing it out for this ase, X ought to a t to minimize xAVA(xA) + (xB +yB)VB(xB + yB). Due to the onstraint that xA + xB = 1, this means sending down A i VA(1) < (yB + 1)VB(yB + 1) yBVB(yB), whi h di ers from the ISPA result in that X is on erned with the full ost of going through router B, not just the portion of that ostthat its pa ket re eives.In the ontext of this example, thisG-minimizing algorithm onstitutes \\load-balan ing\"(LB). Note that so long as sgn[VA(0) VB(yB) yBV 0B(yB)\u2104 6= sgn[VA(0) VB(yB)\u2104, evenin the limit of in nitesimally small tra\u00c6 (so that xA + xB equals some in nitesimal \u00c6),ISPA and LB still disagree. LB onsiders side-e e ts of urrent routing de isions on othertra\u00c6 urrently being routed. However be ause it does not onsider side-e e ts of routingde isions on future tra\u00c6 , even LB may not optimize global ost averaged a ross all time,363\nWolpert & Tumerdepending on the details of the system. However through the use of \\e e t sets\" COINs an a ount even for su h delayed side-e e ts2.2.3 Braess' ParadoxLet us on lude this se tion with an illustration of Braess' paradox (Bass, 1992; Cohen& Kelly, 1990; Cohen & Je ries, 1997; Glan e & Hogg, 1995; Hogg, 1995; Korilis, Lazar,& Orda, 1997b; Korilis et al., 1999), a phenomenon that dramati ally unders ores theine\u00c6 ien y of the ISPA. This apparent \\paradox\" is perhaps best illustrated through ahighway tra\u00c6 example rst given by Bass (Bass, 1992): There are two highways onne tingtowns S and D. The ost asso iated with traversing either highway (either in terms of tolls,or delays) is V1+V2, as illustrated in Net A of Figure 2. So when x = 1 (a single traveler) foreither path, total a rued ost is 61 units. If on the other hand, six travelers are split equallyamong the two paths, they will ea h in ur a ost of 83 units to get to their destinations. Now,suppose a new highway is built onne ting the two bran hes, as shown in Net B in Figure 2.Further, note that the ost asso iated with taking this highway is not parti ularly high (infa t for any load higher than 1, this highway has a lower ost than any other highway in thesystem). The bene t of this highway is illustrated by the dramati ally redu ed ost in urredby the single traveler: by taking the short- ut, one traveler an traverse the network at a ost of 31 units (2 V1 + V3). Adding a new road has seemingly redu ed the traversal ostdramati ally. ySbbbbb \"\"\"\"\"yV1 yV2 yV2 \"\"\"\"\" yV1bbbbbyD yS\"\"\"\"\"bbbbbyV1 yV2\nyV2 \"\"\"\"\" yV1bbbbbyDyV3 Net A Net BFigure 2: Hex network with V1 = 10x ; V2 = 50 + x ; V3 = 10 + xHowever onsider what happens when six travelers are on the highways in net B. Ifea h agent uses an ISPA, then at equilibrium ea h of the three possible paths ontains twotravelers.3 Due to overlaps in the paths however, this results in ea h traveler in urring a ost of 92 units, whi h is higher than than what they in urred before the new highway wasbuilt. The net e e t of adding a new road is to in rease the ost in urred by every traveler.This phenomenon is known as Braess' paradox.2. A detailed dis ussion and proof of the suboptimality of LB is shown in appendix A. Sin e LB is notused in urrent systems and is hard to imagine ever being used, our experiments do not onsider it; it isdis ussed here for pedagogi al reasons.3. We have in mind here the Nash equilibrium for this problem, where no traveler (or equivalently, norouter) an gain advantage by hanging strategies.364\nColle tive Intelligen e, Data Routing and Braess' Paradox3. Mathemati s of Colle tive Intelligen eOne ommon solution to these types of side-e e t problems is to have parti ular agentsof the network (e.g., a \\network manager\" Korilis, Lazar, & Orda, 1995) di tate ertain hoi es to other agents. This solution an in ur major brittleness and s aling problemshowever. Another kind of approa h, whi h avoids the problems of a entralized manager,is to provide the agents with extra in entives that an indu e them to take a tions that areundesirable to them from a stri t SPA sense. Su h in entive an be in the form of \\taxes\"or \\tolls\" added to the osts asso iated with traversing parti ular links to dis ourage theuse of those links. Su h s hemes in whi h tolls are superimposed on the agents' goals area spe ial ase of the more general approa h of repla ing the goal of ea h agent with a newgoal. These new goals are spe i ally tailored so that if they are olle tively met the systemmaximizes throughput. A priori, a agent's goal need have no parti ular relation with theSPA-type ost in urred by that agent's pa kets. Intuitively, in this approa h, we provideea h agent with a goal that is \\aligned\" with the global obje tive, with no separate on ernfor of that goal's relation to the SPA-type ost in urred by the tra\u00c6 routed by that agent.In this se tion, we summarize the salient aspe ts of a Colle tive Intelligen es (COIN) (Wolpert,Wheeler, & Tumer, 2000; Wolpert & Tumer, 1999). In this paper we onsider systems that onsist of a set of agents, onne ted in a network, evolving a ross a set of dis rete, onse u-tive time steps, t 2 f0; 1; :::g. Without loss of generality, we let all relevant hara teristi s ofa agent at time t | in luding its internal parameters at that time as well as its externallyvisible a tions | be en apsulated by a Eu lidean ve tor ;t with omponents ;t;i. We all this the \\state\" of agent at time t, and let ;t be the state of all agents at time t,while is the state of all agent a ross all time.World utility, G( ), is a fun tion of the state of all agents a ross all time. When is an agent that uses a Ma hine Learning (ML) algorithm to \\try to in rease\" its privateutility, we write that private utility as g ( ), or more generally, to allow that utility tovary in time, g ; ( ).We assume that en ompasses all physi ally relevant variables, so that the dynami sof the system is deterministi (though of ourse impre isely known to anyone trying to ontrol the system). Note that this means that all hara teristi s of an agent at t = 0that a e ts the ensuing dynami s of the system must be in luded in ;0. For ML-basedagents, this in ludes in parti ular the algorithmi spe i ation of its private utility, typi allyin the physi al form of some omputer ode (the mathemati s an be generalized beyondML-based agents, as elaborated in Wolpert & Tumer, 1999).Here we fo us on the ase where our goal, as COIN designers, is to maximize world utilitythrough the proper sele tion of private utility fun tions. Intuitively, the idea is to hooseprivate utilities that are aligned with the world utility, and that also have the propertythat it is relatively easy for us to on gure ea h agent so that the asso iated private utilitya hieves a large value. In this paper, all utilities we onsider are of the form Pt Rt( ;t)for reward fun tions Rt (simply PtRt( ;t) for non-time-varying utilities). From now on,we will only onsider world utilities whose asso iated set of fRtg are all time-translations ofone another. In parti ular, as shown below, overall network throughput is expressible thisway. 365\nWolpert & TumerWe need a formal de nition of the on ept of having private utilities be \\aligned\" withG. Constru ting su h a formalization is a subtle exer ise. For example, onsider systemswhere the world utility is the sum of the private utilities of the individual agents. This mightseem a reasonable andidate for an example of \\aligned\" utilities. However su h systemsare examples of the more general lass of systems that are \\weakly trivial\". It is well-knownthat in weakly trivial systems ea h individual agent greedily trying to maximize its ownutility an lead to the tragedy of the ommons (Hardin, 1968; Crowe, 1969) and a tuallyminimize G. In parti ular, this an be the ase when private utilities are independent oftime and G =P g . Evidently, at a minimum, having G =P g is not su\u00c6 ient to ensurethat we have \\aligned\" utilities; some alternative formalization of the on ept is needed.Note that in the simple network dis ussed in Se tion 2.1, the utilities are weakly trivial,sin e G(~x; ~y) = gX(~x) + gy(~y). This provides another perspe tive on the suboptimality ofISPA in that network.A more areful alternative formalization of the notion of aligned utilities is the on eptof \\fa tored\" systems. A system is fa tored at time when the following holds for ea hagent individually: A hange at time to the state of alone, when propagated a rosstime, will result in an in reased value of g ; ( ) if and only if it results in an in rease forG( ) (Wolpert & Tumer, 1999).For a fa tored system, the side-e e ts of any hange to 's t = state that in reases itsprivate utility annot de rease world utility. There are no restri tions though on the e e tsof that hange on the private utilities of other agents and/or times. In parti ular, we don'tpre lude an agent's algorithm at two di erent times from \\working at ross-purposes\" toea h other, so long as at both moments the agent is working to improve G. In game-theoreti terms, in fa tored systems optimal global behavior orresponds to the agents' always beingat a private utility Nash equilibrium (Fudenberg & Tirole, 1991). In this sense, there anbe no tragedy of the ommons for a fa tored system. As a trivial example, a system isfa tored for g ; = G 8 , a system onventionally alled a `team game'.Furthermore, if our system is fa tored with respe t to private utilities fg ; g, we wantea h agent to be in a state at time that indu es as high a value of the asso iated privateutility as possible (given the initial states of the other agents). Assume is ML-based andable to a hieve fairly large values of most private utilities we are likely to set it for time , i.e., assume that given that private utility g ; , the rest of the omponents of ; areset by 's algorithm in su h a way so as to a hieve a relatively high value of g ; . So ourproblem be omes determining for what fg ; g the agents will best be able to a hieve highg (subje t to ea h other's a tions) while also ausing dynami s that is fa tored for G andthe fg ; g.De ne the e e t set of the agent-time pair ( ; ) at , Ceff( ; )( ), as the set of all agents 0;t whi h under the forward dynami s of the system have non-zero partial derivative withrespe t to the state of agent at t = . Intuitively, ( ; )'s e e t set is the set of the statesof all agents 0;t that would be a e ted by a hange in the state of agent at time .Next, for any set of agents ( 0; t), de ne CL ( ) as the \\virtual\" ve tor formed by lamping the omponents of the ve tor delineated in to an arbitrary xed value, whi h366\nColle tive Intelligen e, Data Routing and Braess' Paradoxin this paper is set to 0. 4 This operation reates a new state ve tor (e.g., worldline) wherethe lamped omponents of that worldline (e.g., one player's a tion at a parti ular timestep) are \\zeroed\" (e.g., removed from the system).The value of the wonderful life utility (WLU for short) for is de ned as:WLU ( ) G( ) G(CL ( )): (1)In parti ular, we are interested in the WLU for the e e t set of agent-time pair ( ; ). ThisWLU is the di eren e between the a tual world utility and the virtual world utility whereall agent-time pairs that are a e ted by ( ; ) have been lamped to a zero state while therest of is left un hanged.Sin e we are lamping to ~0, we an loosely view ( ; )'s e e t set WLU as analogousto the hange in world utility that would have arisen if ( ; ) \\had never existed\", hen ethe name of this utility - f. the Frank Capra movie. Note however, that CL is a purely\\ tional\", ounter-fa tual operator, in that it produ es a new without taking into a ountthe system's dynami s. The sequen e of states the agent-time pairs in are lamped toin onstru ting the WLU need not be onsistent with the dynami al laws of the system.This dynami s-independen e is a ru ial strength of the WLU. It means that to evaluatethe WLU we do not try to infer how the system would have evolved if agent 's state wereset to ~0 at time and the system evolved from there. So long as we know , extending overall time, , and the fun tion G, we know the value of WLU.As mentioned above, regardless of the system dynami s, having g ; = G 8 means thesystem is fa tored at time .Theorem: Regardless of the system dynami s, setting g ; = WLUCeff( ; ) 8 results in afa tored system at time .Proof: The se ond term, G(CLCeff( ; )( )) is, by de nition, independent of ; . Thereforea hange to only the ( ; ) omponent of will only a e t the rst term, G( ). Thereforethe e e t of su h a hange on the value of the world utility is the same as its e e t on thevalue of the wonderful life utility. QED.Sin e fa toredness does not distinguish the team game and wonderful life utilities, weneed some other means of de iding whi h to use as our hoi e of fg ; g. To determinethis, note that sin e ea h agent is operating in a large system, it may experien e di\u00c6 ultydis erning the e e ts of its a tions on G when G sensitively depends on all the agents in thesystem. Therefore ea h may have di\u00c6 ulty learning from past experien e what to do toa hieve high g ; when g ; = G. In parti ular, in routing in large networks, having privaterewards given by the world reward fun tions means that to provide ea h router with itsreward at ea h time step we need to provide it the full throughput of the entire networkat that step. This is usually infeasible in pra ti e. Even if it weren't though, using theseprivate utilities would mean that the routers fa e a very di\u00c6 ult task in trying to dis ern4. The hoi e of the lamping parameter used in an asso iated COIN an a e t its performan e. Howeverwithin wide ranges, it doesn't a e t whether su h a COIN outperforms alternatives like team games.367\nWolpert & Tumerthe e e t of their a tions on their rewards, and therefore would likely be unable to learntheir best routing strategies.This problem an be mitigated by using e e t set WLU as the private utility, sin e thesubtra tion of the lamped term removes mu h of the \\noise\" of the a tivity of other agents,leaving only the underlying \\signal\" of how the agent in question a e ts the utility (thisreasoning is formalized as the on ept of \\learnability\" in Wolpert & Tumer, 1999). A - ordingly, one would expe t that setting private utilities to WLU's ought to result in betterperforman e than having g ; = G 8 ; . This is the primary theoreti al onsideration thatwe leverage in the COIN te hniques investigated in this paper.In pra ti e, we will sometimes only be able to estimate the \\primary\", most prominentportion of the e e t set. Te hni ally, the asso iated WLU is not the e e t set WLU, andtherefore not exa tly fa tored. However assuming that that asso iated WLU is lose enoughto being fa tored, we would expe t the advantage in learnability with su h a WLU to stillresult in better performan e than would using g ; = G 8 ; (see Wolpert et al., 2000;Wolpert & Tumer, 1999). Indeed, for the sake of improving learnability, sometimes we willele t to ex lude ertain agent-time pairs from our estimate of the e e t set of ( ; ), evenif we are sure that that are a e ted by ; . This will be the ase if we expe t that the hanges in G due to varying ; that are \\mediated\" through those agent-time pairs arerelatively insigni ant, and therefore e e tively onstitute noise for the learning pro ess, sothat their e e t on learnability is more important than their e e t on fa toredness.4. Colle tive Intelligen e for Network RoutingIn this se tion, we use the theory summarized in Se tion 3 to derive individual goals forea h router, in the form of private utility fun tions to be maximized by appropriate hoi eof routing de isions. The routers tried to a hieve those maximizations by using algorithmsthat only require limited knowledge of the state of the network (in parti ular knowledgethat is readily available to routers in ommon real data networks). In our simulations ea hrouter used a Memory Based (MB) ma hine learning algorithm (nearest neighbor) to makerouting de isions. More pre isely, for ea h potential routing de ision, the routers look forthe past state that most losely losely mat hes their urrent state (e.g., load). They thenassign an \"estimated\" utility value to ea h potential routing de ision and sele t the a tionwith the highest estimated utility value. We all this algorithm an MB COIN5.4.1 Model Des riptionTo apply the COIN formalism to a network routing model, we must formally des ribethat as a set of deterministi ally evolving ve tors ;t. In the model used in this paper, atany time step all tra\u00c6 at a router is a set of pairs of integer-valued tra\u00c6 amounts andasso iated ultimate destination tags. At ea h su h time step t, ea h router r sums theinteger-valued omponents of its urrent tra\u00c6 at that time step (one omponent for ea h5. Relatively minor details of the algorithm on erning exploration/exploitation issues along with a \\steer-ing\" parameter are dis ussed at the end of this se tion.368\nColle tive Intelligen e, Data Routing and Braess' Paradoxultimate destination) to get its instantaneous load. We write that load as:zr(t) Xd xr;d(t);where the index d runs over ultimate destinations, and xr;d(t) is the total tra\u00c6 at timet going from r towards d. After its instantaneous load at time t is evaluated, the routersends all its tra\u00c6 to the next downstream routers, in a manner governed by the underlyingrouting algorithm. We indi ate su h \\next routers\" by writing:xr;d(t) =Xr0 xr;d;r0(t);where r0 is the next router for tra\u00c6 (r; d), i.e., the rst stop on the path to be followedfrom router r to ultimate destination d. After all su h routed tra\u00c6 goes to those nextdownstream routers, the y le repeats itself, until all tra\u00c6 rea hes its destinations.In our simulations, for simpli ity, tra\u00c6 was only introdu ed into the system (at thesour e routers) at the beginning of su essive disjoint waves of L onse utive time stepsea h6. We use (t) to indi ate either the integer-valued wave number asso iated with timet or the set of all times in that wave, as the ontext indi ates.In a real network, the ost of traversing a router depends on \\after-e e ts\" of re entinstantaneous loads, as well as the urrent instantaneous load. To simulate this e e t, weuse time-averaged values of the load at a router rather than instantaneous load to determinethe ost a pa ket in urs in traversing that router. More formally, we de ne the router'swindowed load, Zr(t), as the running average of that router's load value over a windowof the previous W timesteps (W is always set to an integer multiple of L):Zr(t) 1W tXt0=t W+1 zr(t0) =Xd Xr;d(t);where the value of Xr;d(t) is set byXr;d(t) = 1W tXt0=t W+1xr;d(t0)):Intuitively, for large enough W , using su h a window to determine osts a ross routersmeans that typi ally those osts will only hange substantially over time s ales signi antlylarger than that of the individual routing de isions. Formally, the windowed load is theargument to a load-to- ost fun tion, V ( ), whi h provides the ost a rued at time t byea h pa ket traversing the router at this timestep. That is, at time t, the ost for ea hpa ket to traverse router r is given by V (Zr(t))7. Note that in our model, the osts area rued at the routers, not the links. Also note that for simpli ity we do not physi allyinstantiate the ost as a temporal delay in rossing a router. Di erent routers have di erent6. L was always hosen to be the minimal number ne essary for all tra\u00c6 to rea h its destination beforethe next wave of tra\u00c6 is initiated.7. We also introdu e \\dummy routers\" denoted by V0( ) = 0 whi h help in translating the mathemati sinto the simulations. Omitting them will have no e e t on the simulations.369\nWolpert & TumerV ( ), to re e t the fa t that real networks have di eren es in router software and hardware(response time, queue length, pro essing speed et ). For simpli ity, W is the same for allrouters however. With these de nitions, world utility is given byG( ) = Xt;r zr(t) Vr(Zr(t))= Xt;r;dxr;d(t)Vr(Zr(t))= Xt;r;dxr;d(t)Vr 0 1W tXt0=t W+1Xd0 xr;d0(t0)1A= Xt;r;dxr;d(t)Vr Xd0 Xr;d0(t)! : (2)Our equation for G expli itly demonstrates that, as laimed above, in our representationwe an express G( ) as a sum of rewards,PtRt( ;t), where R( ;t) an be written as fun tionof a pair of (r; d)-indexed ve tors:Rt(xr;d(t);Xr;d(t)) =Xr;d xr;d(t)Vr Xd0 Xr;d0(t)! :Also as laimed, the Rt are temporal translations of one another.Given this model, some of the omponents of ;t must be identi ed with the valuesxr;d;r0(t) 8 r; d; r0 and t, sin e those x's are set by the a tions the agents will take. Sin e allarguments of G must be omponents of , we also in lude the Xr;d(t) 8r; d; t as omponentsof ;t. Formally, for routing based on ML agents, the internal parameters of the ML agentsmust also be in luded in . This is be ause those parameters a e t the routing, and inturn are a e ted by it. So to have evolve deterministi ally, sin e it in ludes the routingvariables, it must also ontain internal parameters of the agents. We won't have any needto expli itly delineate su h variables here however, and will mostly phrase the dis ussion asthough there were no su h internal parameters.Now the values fxr;d;r0(t 1)g 8r; d; r0 spe ify the values fxr;d(t)g 8r; d dire tly. There-fore, in on ert with the fxr;d(t0 < t)g, they also set the fXr;d(t)g dire tly. Moreover in oursimulations the de isions fxr;d;r0(t)g 8r; d; r0 xed by the routing algorithms at all times tare given by a xed fun tion of the fxr;d(t)g and the fZr(t) =Pd0 Xr;d0(t)g. So in point offa t we an map the set of fxr;d;r0(t 1);Xr;d0(t)g 8r; d; r0 to the full set fxr;d;r0(t)g 8r; d; r0,not just to fxr;d(t)g. A ordingly, the xr;d;r0 undergo deterministi evolution. Sin e theirvalues a ross time set all the values of the Xr;d(t) a ross time, we see that the entire set ofthe omponents of ;t undergo deterministi evolution in this representation, as required.For evaluating the wonderful life utility we will need to group the omponents of ;tinto disjoint agents . Here we will have two types of agent, both types being indexed byrouter-destination pairs. For ea h su h agent index (r; d), the rst agent type is the variableXr;d(t), and the se ond agent type is the Eu lidean ve tor with omponents indexed by r0,(xr;d)r0(t). In setting \\a tions\" we are on erned with setting the states of the agents ofthe se ond type. A ordingly, our learners will all be asso iated with agents of this se ond370\nColle tive Intelligen e, Data Routing and Braess' Paradoxtype. Unless expli itly indi ated otherwise, from now on we will impli itly have that se ondtype of agent in mind whenever we refer to a \\agent\" or use the symbol .4.2 ISPA Routing and COIN RoutingBased on the COIN formalism presented in Se tion 3 and the model des ribed above, wenow present the ISPA and COIN-based routing algorithms. At time step t, ISPA has a essto all the windowed loads at time step t 1 (i.e., it has a ess to Zr(t 1) 8r), and assumesthat those values will remain the same at all times t. Note that for large window sizesand times lose to t, this assumption is arbitrarily a urate. Using this assumption, inISPA, ea h router sends pa kets along the path that it al ulates will minimize the ostsa umulated by its pa kets.The COIN-based routing algorithms, in ontrast, do not have su h dire t a ess to theZr. So to evaluate the WLU for a agent (r; d) at any time , su h an algorithm mustestimate the (primary members of the) asso iated e e t set. This means determining what omponents of ; will, under the dynami s of the system, be hanged by altering any of the omponents of the ve tor xr;d( ).As a rst approximation, we will ignore e e ts on tra\u00c6 that hanging xr;d;r0( ) mayhave that are \\mediated\" by the learning algorithms running in the system. That is, weignore hanges that arise due to the the e e ts that hanging xr;d;r0( ) has on rewards, hanges whi h indu e hanges in future training sets, whi h then in turn get mapped to hanges in the fxr;d;r0(t)g (and therefore the fXr;d(t)g) via the learning algorithms runningon the agents.As another approximation, we will ignore e e ts mediated by the routing algorithms'observations of the state of the network. That is, we ignore hanges in the fxr00;d0;r000(t)g thatvarying xr;d( ) may ause due to asso iated hanges in the state of the network per eived by(r00; d0)'s routing algorithm, hanges that in turn ause that algorithm to modify its routingde isions a ordingly. We only onsider the behavior of those routing algorithms that are(potentially) dire tly a e ted by xr;d( ) in that they (potentially) have to route pa ketsthat, at time , passed through r on the way to d. So in parti ular we ignore e e ts ofxr;d( ) on the fxr00;d0 6=d;r000(t)g.Sin e all pa kets routed in a wave arrive at their destinations by the end of the wave,these approximations mean that the only xr00;d00;r000(t) that are in our estimate for xr;d( )'se e t set have t in the same wave as . These are the only ones that are, potentially, dire tlya e ted by the fxr;d;r0(t)g by \\ haining together\" the sequen e of xr00;d00;r000(t) that get thepa kets in xr;d(t) to their ultimate destination. Due to the wave nature of our simulationsthough, the only xr00;d00;r000(t) within 's wave that are a e ted by xr;d( ) all have d00 = d.For reasons of oding simpli ity, we do not on ern ourselves with whether t < within agiven wave and then ex lude some xr00;d00;r000(t) a ordingly. In other words, all t within 'swave are treated equally.So one set of members of xr;d( )'s e e t set is fxr00;d;r000(t) 8r00; d; r000; t 2 ( )g. Notethat some of these members will be relatively una e ted by xr;d( ) (e.g., those with r00 farin the net away from r). Again for simpli ity, we do not try to determine these and ex ludethem. As with keeping the xr00;d;r000(t < ), this in lusion of extra agents in our estimate ofthe e e t set should hurt learnability, but in general should not hurt fa toredness. Therefore371\nWolpert & Tumerit should delay how qui kly the learners determine their optimal poli ies, but it won't a e tthe quality (for G) of those poli ies nally arrived at. Note also that trying to determinewhether some parti ular xr00;d;r000(t 2 ( )) should be in luded in xr;d( )'s e e t set wouldmean, in part, determining whether pa kets routed from (r; d) would have rea hed r00 if(r; d) had made some routing de ision di erent from the one it a tually made. This wouldbe a non-trivial exer ise, in general.In ontrast to the ase with the xr00;d0;r000(t), there are Xr00;d0(t) with t in the future of 'swave that both are a e ted by xr;d(t) and also are not ex luded by any of our approximationsso far. In parti ular, the Xr00;d(t) with either r00 = r or r00 one hop away from r will bedire tly a e ted by xr;d(t), for t 2 [W 1i=0 ( + iL)) ( f. the de nition of the X variables).For simpli ity, we restri t onsideration of su hXr00;d variables to those with the same routeras r, r00 = r.This nal estimate for the e e t set is learly rather poor | presumably results betterthan those presented below would a rue to use of a more a urate e e t set. However it'sworth bearing in mind that there is a \\self-stabilizing\" nature to the hoi e of e e t sets,when used in onjun tion with e e t set WLU's. This nature is mediated by the learningalgorithms. If one assigns the same utility fun tion to two agents, then the reward oneagent gets will be determined in part by what the other one does. So as it modi es itsbehavior to try to in rease its reward, that rst agent will be modifying its behavior in away dependent on what the other agent does. In other words, if two agents are given thesame WLU be ause they are estimated to be in ea h other's e e t set, then ipso fa to theywill be in ea h other's e e t set.Using our estimate for the e e t set, the WLU for ( ; ) is given by the di eren ebetween the total ost a rued in 's wave by all agents in the network and the ost a ruedby agents when all agents sharing 's destination are \\erased.\" More pre isely, any agent that has a destination d will have the following e e t set WLU's, g ; :g ; ( )= G( ) G(CLCeff( ; )( ))= Xt;r0;d0 xr0;d0(t) Vr0 Xd0 Xr0;d0(t)! Xt;r0;d0 xr0;d0(t)(1 I(t 2 ( ))I(d0 = d)) Vr0 Xd00 [ Xr0;d00(t) (1 I(t 2 [W 1i=0 ( + iL))I(d00 = d)) \u2104!= Xt2 ( )Xr0 0 Xd0 xr0;d0(t) Vr0(Xd00 Xr0;d00(t)) Xd0 6=d xr0;d0(t) Vr0(Xd00 6=dXr0;d00(t))1A+ Xt2[W 1i=1 ( +iL)Xr0 0 Xd0 xr0;d0(t) [Vr0(Xd00 Xr0;d00(t)) Vr0(Xd00 6=dXr0;d00(t))\u21041A (3)where I(:) is the indi ator fun tion that equals 1 if its argument is true, 0 otherwise.To allow the learner to re eive feedba k on erning its a tions in a wave immediatelyfollowing that wave rather than wait for WL time steps, we will approximate the se ondsum in that last equality, the one over times following 's wave, as zero. There is anotherway we an view the resultant expression, rather than as an approximation to the e e t372\nColle tive Intelligen e, Data Routing and Braess' Paradoxset WLU. That is to view it as the exa t WLU of an approximation to the e e t set, anapproximation whi h ignores e e ts on future windowed loads of lamping a urrent tra\u00c6 level. Regardless of what view we adopt, presumably better performan e ould be a hievedif we did not implement this approximation.Given this approximation, our WLU be omes a wave-indexed time-translation-invariantWL \\reward fun tion\" (WLR):g ; ( ;t2 ( )) = Xt2 ( );r0 Xd0 xr0;d0(t) Vr0(Xd00 Xr0;d00(t)) Xd0 6=d xr0;d0(t) Vr0(Xd00 6=dXr0;d00(t))1A : (4)Noti e that tra\u00c6 going from a router r0 6= r to a destination d0 6= d a e ts the value ofthe WLR for agent (r; d). This re e ts the fa t that WLR takes into a ount side-e e tsof (r; d)'s a tions on other agents. Note also that ea h r0-indexed term ontributing to theWLR an be omputed by the asso iated router r0 separately, from information availableto that router. Subsequently those terms an be propagated through the network to , inmu h the same way as routing tables updates are propagated.Given this hoi e of private utility, we must next spe ify how the COIN-based routingalgorithm olle ts the initial data that (in onjun tion with this utility) is to be used toguide the initial routing de isions that every agent with more than one routing option mustmake. In our experiments that data was olle ted during a preliminary running of an ISPA.In this preliminary stage, the routing de isions are made using the ISPA, but the resultinga tions are \\s ored\" using the WLR given by Equation 3. We use the ISPA to generate therouting de isions in the initial data sin e it is likely in pra ti e that some kind of SPA willbe the routing algorithm running prior to \\turning on\" the COIN algorithm. Alternatelyone an generate the initial data's routing de isions by having the routers make randomde isions, or by having them implement a sequen e of de isions that \\sweeps\" a ross a gridthrough the possible set of a tions. The data olle ted in this stage provides us with initialinput-output training sets to be used by the ma hine learning algorithm on ea h agent: forea h router-destination agent, inputs are identi ed with windowed loads on outgoing links,and the asso iated WLR values for the destination in question are the outputs.After su\u00c6 ient initial data is olle ted using the ISPA, the system swit hes to usingthe COIN algorithm to make subsequent routing de isions. In this stage, ea h agent routespa kets along the link that it estimates (based on the training set) would provide the bestWLR. To perform the estimation, the MB COIN makes use of a single-nearest-neighboralgorithm as its learner. This algorithm simply guesses that the output that would ensuefrom any andidate input is the same as the output of the element of the training setthat is the nearest neighbor (in input spa e) of that andidate input.8 In other words, thelearner nds the training set input-output pair whose input value (loads on outgoing links)8. This is a very simple learning algorithm, and we use it here only to demonstrate the potential pra ti alfeasibility of a COIN-based routing algorithm. The performan e an presumably be improved if moresophisti ated learning algorithms (e.g., Q-learning Sutton & Barto, 1998; Watkins & Dayan, 1992) areused. 373\nWolpert & Tumeris losest to that whi h would result from ea h potential routing de ision. Then the learnerassigns the WLR asso iated with that training data pair as the estimate for what WLRwould result from said routing de ision. These WLR values are then used to hoose amongthose potential routing de isions. The input-output data generated under this algorithm isadding to the training set as it is generated.In this routing algorithm, the routers only estimate how their routing de isions (asre e ted in their loads at individual time steps) will a e t their WLR values (based onmany agents' loads). It is also possible to al ulate exa tly how the routing de isions a e tthe routers' WLR's if, unlike the MB COIN, we had full knowledge of the loads of allagents in the system. In a way similar to ISPA, for ea h router we an evaluate the exa tWLR value that would ensue from ea h of its andidate a tions, under the assumptionthat windowed loads on all other routers are the same one wave into the future as they arenow. We all this algorithm for dire tly maximizing WLR (an algorithm we all the fullknowledge COIN, or FK COIN).Note that under the assumption behind the FK COIN, the a tion hooses in wave ( )that maximizes WLR will also maximize the world reward. In other words, WL reward isperfe tly fa tored with respe t to (wave-indexed) world reward, even though the asso iatedutilities are not related that way (due to ina ura y in our estimate of the e e t set). Dueto this fa toredness, the FK COIN is equivalent to load balan ing on world rewards. Sin eLB in general results in inferior performan e ompared to LB over time, and sin e the FKCOIN is equivalent to LB, one might expe t that its performan e is suboptimal. Intuitively,this suboptimality re e ts the fa t that one should not hoose the a tion only with regardto its e e t on urrent reward, but also with on ern for the reward of future waves. In thelanguage of the COIN framework, this suboptimality an be viewed as a restatement of thefa t that for our inexa tly estimated e e t set, the system will not be perfe tly fa tored.The learning algorithm of the MB COIN as des ribed is extraordinarily rude. In addi-tion, the asso iated s heme for hoosing an a tion is purely exploitative, with no explorationwhatsoever. Rather than hoose some parti ular more sophisti ated s heme and tune it to t our simulations, we emulated using more sophisti ated algorithms in general. We didthis by modifying the MB COIN algorithm to o asionally have the FK COIN determinea router's a tion rather than the purely greedy learner outlined above. The steering pa-rameter dis ussed in Se tion 5.5 determines how often the routing de ision is based on theMB COIN as opposed to the FK COIN.5. Simulation ResultsIn pra ti e, it is very di\u00c6 ult to implement either FK COIN or LB. In this se tion we useexperiments to investigate behavior of algorithms that an on eivably be used in pra ti e.More pre isely, based on the model and routing algorithms dis ussed above, we have per-formed simulations to ompare the performan e of ISPA and MB COIN a ross a variety ofnetworks, varying in size from ve to eighteen routers. In all ases tra\u00c6 was inserted intothe network in a regular, non-sto hasti manner at the sour es. The results we report areaveraged over 20 runs. We do not report error bars as they are all lower than 0:05.In Se tions 5.1 - 5.4 we analyze tra\u00c6 patterns over four networks where ISPA su ersfrom the Braess' paradox. In ontrast, the MB COIN almost never falls prey to the paradox374\nColle tive Intelligen e, Data Routing and Braess' Paradoxfor those networks (or for no networks we have investigated is the MB COIN signi antlysus eptible to Braess' paradox). Then in Se tion 5.5 we dis uss the e e t on the MBCOIN's performan e of the \\steering\" parameter whi h determines the intelligen e of theMB COIN.95.1 Bootes NetworkThe rst network type we investigate is shown in Figure 3. It is in many senses a trivialnetwork, as in Net A, the sour es do not even have any hoi es to make. The loads intro-du ed at the sour es do not hange in time and are listed in Tables 1 and 2, along with theperforman es of our algorithms. yS1 yV1 yV2\nyD yS2AAAAAyV0 yV0 yS1 yV3yV1 yV2 yD yS2 AAAAAyV0 yV0Net A Net BFigure 3: Bootes NetworkLoads at (S1; S2) Net ISPA MB COIN1,1 A 6.35 6.35B 8.35 5.932,1 A 8.07 8.07B 10.40 7.882,2 A 9.55 9.55B 10.88 9.714,2 A 10.41 10.41B 11.55 10.41Table 1: Average Per Pa ket Cost for BOOTES2 networks for V1 = 10 + log(1 + x) ; V2 =4x2 ; V3 = log(1 + x) .The MB COIN results are identi al to the ISPA results in the absen e of the additionallink (Network A). However, Braess' paradox arises with ISPA, in that the addition of thenew link in network B degrades the performan e of the ISPA in six of the eight tra\u00c6 regimes and load-to- ost fun tions investigated. The MB COIN on the other hand is only9. In Se tions 5.1 - 5.4, the steering parameter is set at 0.5.375\nWolpert & TumerLoads at (S1; S2) Net ISPA MB COIN1,1 A 30.35 30.35B 20.35 20.352,2 A 35.55 35.55B 40.55 34.994,2 A 41.07 41.07B 50.47 44.136,3 A 44.63 44.63B 51.40 44.63Table 2: Average Per Pa ket Cost for BOOTES4 network for V1 = 50 + log(1 + x) ; V2 =10x ; V3 = log(1 + x) .hurt by the addition of the new link on e, and manages to gainfully exploit it seven times.When their behavior is analyzed in nitesimally, the MB COIN either uses the additionallink e\u00c6 iently or hooses to ignore it in those seven ases. Moreover, the MB COIN'sperforman e with the additional link is always better than the ISPA's. For example, addingthe new link auses a degradation of the performan e by as mu h as 30 % (loads = f2; 1g)for the ISPA, whereas for the same load ve tor MB COIN performan e improves by 7 %.5.2 Hex NetworkIn this se tion we revisit the network rst dis ussed in Se tion 2.1 (redrawn in Figure 4 toin lude the dummy agents). In Table 3 we give full results for the load-to-delay fun tionsdis ussed in that se tion. We then use load-to- ost fun tions whi h are qualitatively similarto those dis ussed in Se tion 2.1, but whi h in orporate non-linearities that better representreal router hara teristi s. That load-to- ost fun tion and asso iated results are reportedin Table 4. ySbbbbb \"\"\"\"\"yV1 yV2 yV2 \"\"\"\"\" yV1bbbbbyDyV0 yV0 yS\"\"\"\"\"bbbbbyV1 yV2 yV2 \"\"\"\"\" yV1bbbbbyDyV3 yV0 yV0 Net A Net BFigure 4: Hex networkThis network demonstrates that while the addition of a new link may be bene ial inlow tra\u00c6 ases, it leads to bottlene ks in higher tra\u00c6 regimes. For ISPA although the376\nColle tive Intelligen e, Data Routing and Braess' Paradoxper pa ket ost for loads of 1 and 2 drop drasti ally when the new link is added, the perpa ket ost in reases for higher loads. The MB COIN on the other hand uses the newlink e\u00c6 iently. Noti e that the MB COIN's performan e is slightly worse than that of theISPA in the absen e of the additional link. This is aused by the MB COIN having to usea learner to estimate the WLU values for potential a tions whereas the ISPA simply hasdire t a ess to all the information it needs ( osts at ea h link).Load Net ISPA MB COIN1 A 55.50 55.56B 31.00 31.002 A 61.00 61.10B 52.00 51.693 A 66.50 66.65B 73.00 64.454 A 72.00 72.25B 87.37 73.41Table 3: Average Per Pa ket Cost for HEX network for V1 = 50+x ; V2 = 10x ; V3 = 10+x. Load Net ISPA MB COIN1 A 55.41 55.44B 20.69 20.692 A 60.69 60.80B 41.10 41.103 A 65.92 66.10B 61.39 59.194 A 71.10 71.41B 81.61 69.88Table 4: Average Per Pa ket Cost for HEX network for V1 = 50 + log(1 + x) ; V2 =10x ; V3 = log(1 + x) .5.3 Butter y NetworkThe next network we investigate is shown in Figure 5. It is an extension to the simplenetwork dis ussed in Se tion 5.1. We now have doubled the size of the network and havethree sour es that have to route their pa kets to two destinations (pa kets originating atS1 go to D1, and pa kets originating at S2 or S3 go to D2). Initially the two halves of thenetwork have minimal onta t, but with the addition of the extra link two sour es from thetwo two halves of the network share a ommon router on their potential shortest path.377\nWolpert & Tumer\nyS1 TTTTTyV1 yV2 TTTTT yD1 yS2 TTTTT yD2 yV3TTTTT yV1 yS3 yV0 yV0 yS1 TTTTT yV3 yV1 yV2 TTTTT yD1 yS2 TTTTT yD2 yV3TTTTT yV1 yS3 yV0 yV0Net A Net BFigure 5: Butter y NetworkTable 5 presents two sets of results: rst we present results for uniform tra\u00c6 throughall three sour es, and then results for asymmetri tra\u00c6 . For the rst ase, the Braess'paradox is apparent in the ISPA: adding the new link is bene ial for the network at lowload levels where the average per pa ket ost is redu ed by nearly 20%, but deleterious athigher levels. The MB COIN, on the other hand, provides the bene ts of the added linkfor the low tra\u00c6 levels, without su ering from deleterious e e ts at higher load levels.Loads (S1; S2; S3) Net ISPA MB COIN1,1,1 A 112.1 112.7B 92.1 92.32,2,2 A 123.3 124.0B 133.3 122.54,4,4 A 144.8 142.6B 156.5 142.33,2,1 A 81.8 82.5B 99.5 81.06,4,2 A 96.0 94.1B 105.3 94.09,6,3 A 105.5 98.2B 106.7 98.8Table 5: Average Per Pa ket Cost for BUTTERFLY network for V1 = 50+log(1+x) ; V2 =10x ; V3 = log(1 + x).For the asymmetri tra\u00c6 patterns, the added link auses a drop in performan e for theISPA, espe ially for low overall tra\u00c6 levels. This is not true for the MB COIN. Noti e alsothat in the high, asymmetri tra\u00c6 regime, the ISPA performs signi antly worse than theMB COIN even without the added link, showing that a bottlene k o urs on the right sideof network alone (similar to the Braess' paradox observed in Se tion 5.1).378\nColle tive Intelligen e, Data Routing and Braess' Paradox5.4 Ray NetworkIn all the networks and tra\u00c6 regimes dis ussed so far the sour es are the only routers withmore than one routing option. The nal network we investigate is a larger network wherethe number of routers with multiply options is signi antly higher than in the previousnetworks. Figure 6 shows the initial network (Net A) and the \\augmented\" network (NetB), where new links have been added. The original network has relatively few hoi es forthe routers, as pa kets are dire ted toward their destinations along \\ onduits.\" The newlinks are added in the augmented networks to provide new hoi es ( rossing patterns) that ould be bene ial if ertain of the original onduits experien e large osts.\nyS1eeee yS2%%%%yV3 JJJ J yV3JJJJ yV1 yV2 yV2 yV1 yV0 yV0 yV0 yV0yV2 \"\"\"\"\"yV1 \"\"\"\"\"yV1bbbbb yV2bbbbbyD1 yD2 yS1eeee yS2%%%%yV3 JJJ J yV3##### yV3JJJJ yV3 yV1 yV2 yV2#####yV1yV3 yV3yV0 yV0 yV0 yV0yV2 \"\"\" \"\"yV1 \"\"\"\"\"yV1bbbbb yV2bbbbbyD1 yD2\nNet A Net BFigure 6: Ray networkTable 6 shows the simulation results for these networks (S1 and S2 send pa kets to D1and D2 respe tively). At low load levels both the ISPA and the MB COIN use the new linkse e tively, although the MB COIN performs slightly worse. This is mainly aused by thedi\u00c6 ulty en ountered by the simple learner (single nearest neighbor algorithm) in qui klylearning the tra\u00c6 patterns in this large network. Unlike the ISPA however, the MB COINavoids the Braess' paradox in all ases ex ept the very high tra\u00c6 regime. Moreover, eventhere, the e e t is signi antly milder than that en ountered by the ISPA.5.5 Steering the MB COINThe nal aspe t of COIN-based routing we investigate is the impa t of the hoi e for thevalue of the steering parameter. This parameter both ontrols the amount of explorationthe algorithm performs and determines the \\intelligen e\" of the MB COIN at estimatingthe surfa e dire tly al ulated by the FK COIN. In Figures 7 - 8, the FK COIN results orrespond to setting the steering parameter of the MB COIN to 1:0. This provides anupper bound on the performan e that an be a hieved though MB COIN.For the HEX network (Figure 7), the performan e at the worst setting for the MB COIN,whi h orresponds to no steering, is omparable to ISPA. In ontrast, with moderate steering379\nWolpert & TumerLoads at S1andS2) Net ISPA MB COIN2,2 A 143.6 143.7B 124.4 126.93,3 A 154.6 154.9B 165.5 151.04,4 A 165.4 166.0B 197.7 165.66,6 A 186.7 187.4B 205.1 191.6Table 6: Average Per Pa ket Cost for RAY network for V1 = 50 + log(1 + x) ; V2 =10x ; V3 = 10 + log(1 + x).\n65\n70\n75\n80\n85\n0 0.1 0.2 0.3 0.4 0.5\nP e r\nP a ck\ne t D\ne la\ny\nSteering Parameter\nISPA FK COIN MB COIN\n140\n150\n160\n170\n180\n0 0.1 0.2 0.3 0.4 0.5\nP e r\nP a ck\ne t D\ne la\ny\nSteering Parameter\nISPA FK COIN MB COIN\nFigure 7: Impa t of steering on Hex4 (left) and Ray4 (right) networks.(0.5) the results are similar to that of the FK COIN, as the learner has more informationto work with (arising from the extra parts of the input spa e represented in the trainingset due to the o asional use of the FK COIN), it bridges the gap between a suboptimalalgorithm sus eptible to Braess' paradox and one whi h e\u00c6 iently avoids that paradox.For the RAY network (Figure 7), the value of the steering parameter is more riti al.With no steering at all, the MB COIN performs poorly in this network | even worse thanISPA. This is not surprising in that be ause there are many routing hoi es that a e tthe performan e, the simple memory-based learner needs proper \\seeding\" to be able toperform well. Even with minimal steering though, the MB COIN qui kly outperforms theISPA.Finally, for both the Butter y and Bootes networks (Figure 8) the MB COIN needsvery little steering to perform well. Although for the Butter y network the performan e ofMB COIN improves slightly with more information, it is signi antly better than the ISPAa ross the board. 380\nColle tive Intelligen e, Data Routing and Braess' Paradox\n90\n95\n100\n105\n0 0.1 0.2 0.3 0.4 0.5\nP e r\nP a ck\ne t D\ne la\ny\nSteering Parameter\nISPA FK COIN MB COIN\n35\n40\n0 0.1 0.2 0.3 0.4 0.5\nP e r\nP a ck\ne t D\ne la\ny\nSteering Parameter\nISPA FK COIN MB COIN\nFigure 8: Impa t of steering on Butter y4 (left) and Bootes4 (right) networks.6. Con lusionE e tive routing in a network is a fundamental problem in many elds, in luding data ommuni ations and transportation. Using a shortest path algorithm (SPA) on ea h of therouters to determine that router's de isions is a popular approa h to this problem. Howeverunder ertain ir umstan es it su ers from a number of undesirable e e ts. One su h e e t isBraess' paradox, where for the same pattern of introdu ed tra\u00c6 into a network, in reasingthe apa ity of that network results in lower overall throughput, due to the harmful side-e e ts of the de isions made by ea h router on the tra\u00c6 in the rest of the system. Eventhe theoreti al load-balan ing algorithm, whi h addresses some of these e e ts to produ ede isions that are optimal for any single moment of time, an still su er from side-e e tsthat result in sub-optimal performan e. This is be ause su h e e ts extend a ross time(i.e., what you do now a e ts performan e later) as well as spa e.The Colle tive Intelligen e approa h is a novel way of ontrolling distributed systems soas to avoid deleterious side-e e ts of routing de isions. The entral idea is to have learningalgorithms ontrol the autonomous agents that onstitute the overall distributed system.In su h a Colle tive Intelligen e (COIN), the entral issue is to determine the personalobje tives to be assigned to ea h of those autonomous agents. One wants to hoose thosegoals so that the greedy pursuit of those goals by the asso iated learning algorithms leads todesirable behavior of the overall system. In this paper we have summarized the mathemati sof designing su h goals and derived a routing algorithm based on that mathemati s.We ran omputer simulations to ompare a COIN-based algorithm with an ideal SPA(whose performan e upper-bounds all real-world SPA's) for routing. The COIN-based algo-rithm was severely handi apped. The estimation of the \\e e t sets\" used by that algorithmwas ex eedingly rude. In addition, the learning algorithms of the agents were parti ularlyunsophisti ated, and therefore were not able to e e tively maximize their individual perfor-man es. In ontrast, the ideal SPA had a ess to more information on erning the state ofthe system than the (real-world-implementable) COIN did, information that no real-worldSPA ould a ess. 381\nWolpert & TumerDespite these biases in favor of the ideal SPA, in our experiments the ideal SPA indu edaverage osts as mu h as 32 % higher than the COIN-based algorithm. Furthermore theCOIN-based algorithm almost always avoided the Braess' paradox that seriously diminishedthe performan e of the SPA.These te hniques have also been very su essfully employed in many other, non-routingdomains, su h as oordination of autonomous rovers (Tumer, Agogino, & Wolpert, 2002), ombinatorial optimization, \\ ongestion games\" (Wolpert & Tumer, 2001), and ontrol ofdata-upload from a planet (Wolpert, Sill, & Tumer, 2001). We on lude from these resultsthat the te hniques of the eld of olle tive intelligen e an be highly e e tive in designingthe utility fun tions of the members of a MAS to ensure they work in a oordinated ande\u00c6 ient manner to optimize overall performan e. We are urrently investigating extensionsof our COIN algorithm that involve novel goals for the agents, goals that are more \\learn-able\" for the learning algorithms. We are also expanding the simulations to larger networksusing a ommer ial event driven simulator. Future work will fo us on not making the ap-proximation that urrent tra\u00c6 levels do not a e t future windowed loads (Equation 3).It will also involve investigating better estimates of e e t sets, in parti ular not in ludingall agents with the same destination in one's e e t set, and more generally using a more\\ ne-grained\" representation of the agents, for example in luding ea h pa ket's originatingsour e, to allow a more ne-grained e e t set (and resultant WLU).A knowledgmentsThe authors thank Joe Sill and the reviewers for their helpful omments.Appendix A. Suboptimality of Load-Balan ingIn this appendix we we present an existen e proof of the suboptimality of Load-Balan ing(LB) by expli itly onstru ting a situation where onventional LB is suboptimal.Consider a system with dis rete time, in whi h the sour e agent X under onsiderationmust route one pa ket to the ( xed) destination at ea h time step. Presume further thatno tra\u00c6 from any sour e agent other than X enters any of the agents X sends to, so thattra\u00c6 oming from X is the sole sour e of any osts asso iated withX's outbound links. LetS(t) be the number of times our agent sent a pa ket down some link A in the W time stepspre eding t, and take s(t) = A;B to mean that the router uses link A or B, respe tively, attime t. Model queue ba kups and the like by having the ost to send a pa ket down linkA at time t be CA(S(t)=W ), and have the ost for our router to instead send the pa ketdown link B be CB(1 S(t)=W ), For simpli ity we assume that both CA(:) and CB(:) aremonotoni ally in reasing fun tions of their arguments.Restri t attention to agents that work by having s(t) = A i S(t) k for some real-valued threshold k. The LB algorithm will hoose s(t) = A i CA(S(t)=W ) CB(1 S(t)=W ). So the LB algorithm's behavior is indistinguishable from this kind of thresholdalgorithm, with k set so that CA(k=W ) = CB(1 k=W ). (We impli itly assume that CA(:)and CB(:) are hosen so that su h a solution exists for 1 < k < W 1.) The question is382\nColle tive Intelligen e, Data Routing and Braess' Paradoxwhat k should be to optimize total averaged ost a ross time, and in parti ular if that k isthe same as kLB , the k that LB uses.Now as we go from one time step to the next, the routing de ision made W time stepsago drops out of the omputation of S(t), while the routing de ision just made is newlyin luded. In general, S(t+1) = S(t)+ 1 if the router just used A at time t and used link Bat the time W time steps into the past. On the other hand, S(t+1) = S(t) 1 if the routerjust used B and used A W time steps ago, while S(t+1) = S(t) if the routing de ision justmade is the same as the routing de ision W time steps ago. So in general, S(t) an only hange by -1, 0, or +1 as we go from one time step to the next.Consider ases where 1 < k < W 1, so that eventually the router must hoose an A,and at some subsequent time t the router swit hes from A to B. At that time s(t 1) = Aand s(t ) = B. This implies that S(t 1) k; S(t ) > k. De ne the value S(t 1) as k .Note that S(t ) = k + 1, and k 1 < k k.Now for any time t0, if S(t0) = k + 1, s(t0 + 1) = B, and the only possible next valuesare S(t0 + 1) = k or S(t0 + 1) = k + 1, depending on the old de ision s(t W ) that getsdropped out of the window. Similarly, if S(t0) = k , s(t0 + 1) = A, and the only possiblenext values are S(t0 + 1) = k or S(t0 + 1) = k + 1, again depending on the old de isionbeing dropped. So we see that on e S(t0) 2 fk ; k + 1g, it stays there forever.This means that be ause of the relationship between k and k , in any interval of W onse utive time steps subsequent to t , the number of pa kets sent along A by router Xmust be 2 (k 1; k+1\u2104. (Note that it is possible to send k+1 pa kets along A, but not k 1pa kets. Therefore the number sent along B must be 2 [W (k + 1);W (k 1)). Ea htime that a pa ket is sent along A the ost in urred is the ost of link A with average tra\u00c6 level S(t)=W , CA(S(t)=W ). Similarly, ea h time the link B is hosen, the ost in urred isCB(1 S(t)=W ). Sin e S(t) 2 fk ; k + 1g, and both CA(:) and CB(:) are monotoni allyin reasing, the ost for sending the pa ket down link A 2 (CA((k 1)=W ); CA((k+ 1)=W \u2104,and that for sending it down link B is ontained in [CB(1 (k+1)=W ); CB(1 (k 1)=W )).Now we know that the hoi e of A must have average frequen y (a ross all time) betweenk =W and (k +1)=W . Similarly, B will have average frequen y between (1 (k +1)=W )and 1 k =W . A ordingly, the average ost is bounded above byk + 1W CA k + 1W + 1 k W CB 1 k 1W ; (5)where the rst term provides the maximum possible average ost for using link A, whilethe se ond term independently provides the maximum possible average ost for using linkB. Note that the a tual ost will be lower sin e the two frequen ies in this bound, one forA and one for B, annot both have the values indi ated. Be ause k 1 < k k and sin e1 k 1W = 1 + 2W k+1W , our upper bound is itself bounded above byk + 1W CA k + 1W + 1 + 2W k + 1W CB 1 + 2W k + 1W : (6)The optimal k will result in an average ost lower than the minimum over all k of theupper bound on average ost, given in Equation 6. So the average ost for the optimalk is bounded above by the minimum over k of this upper bound. Lable this argmin ofEquation 6 k'. 383\nWolpert & TumerSin e other values of k besides kLB result in behavior equivalent to LB, it does notsu\u00c6 e to simply test if k' = kLB . Instead let us evaluate some lower bounds in a similarfashion to how we evaluated upper bounds. Using the average frequen ies dis ussed above,the average ost is bounded below by:k WCA k 1W + 1 1W k W CB 1 k + 1W ; (7)where the rst term provides the minimum possible average ost for using link A, while these ond term provides the minimum possible average ost for using link B. Again, be ausek 1 < k k, the term is Equation 7 is further bounded below byk 1W CA k 1W + 1 2W k 1W CB 1 2W k 1W : (8)In parti ular this bound holds for the average ost of the LB algorithm:kLB 1W CA kLB 1W + 1 2W kLB 1W CB 1 2W kLB 1W ; (9)where as before kLB satis es CA(kLB=W ) = CB(1 kLB=W ).By appropriate hoi e of CA(:) and CB(:), we an ensure that the lower bound on the ost with the LB algorithm (Equation 9 evaluated with k = kLB) is higher than the upperbound on the average ost in urred by the optimal algorithm (the minimum over k of Equa-tion 6). That is, the best possible average ost a hieved by load balan ing will be worsethan the worst average ost that ould arise through the optimal routing strategy. Thisestablishes that LB does not engage in optimal routing.Example: Let CA(x) = x2 and CB(x) = x. Balan ing the loads on A and B | settingCA(S(t)=W ) = CB(1 S(t)=W ) | results in (S(t)=W )2 = 1 S(t)=W , leading to kLB=W =p5 12 = :618. For W = 1000, the asso iated lower bound on average ost (Equation 9) is(:618)3 + (:998 :618)2 = :380. On the other hand, with CA and CB given as above, Eq 6is (k+1W )3 + (1 + 2W k+1W )2. Di erentiating with respe t to k and setting the result tozero leads to k0W = 13 1W + p28+48=W6 . For a window size of W = 1000, this yieldsk0=W = :548, a di erent result than kLB . Plugging into Equation 6, the upper bound onthe ost with k0 is (:549)3 + (1:002 :549)2 = :371, whi h is less than :380.Referen esAhuja, R. K., Magnanti, T. L., & Orlin, J. B. (1993). Network Flows. Prenti e Hall, NewJersey.Bass, T. (1992). Road to ruin. Dis over, 13 (5), 56{61.Bertsekas, D., & Gallager, R. (1992). Data Networks. Prenti e Hall, Englewood Cli s, NJ.Bonabeau, E., Henaux, F., Guerin, S., Snyders, D., Kuntz, P., & Theraulaz, G. (1999a).Routing in tele ommuni ations networks with \\smart\" and-like agents. (pre-print).Bonabeau, E., Sobkowski, A., Theraulaz, G., & Deneubourg, J.-L. (1999b). Adaptive taskallo ation inspired by a model of division of labor of so ial inse ts. (pre-print).384\nColle tive Intelligen e, Data Routing and Braess' ParadoxBoyan, J. A., & Littman, M. (1994). Pa ket routing in dynami ally hanging networks:A reinfor ement learning approa h. In Advan es in Neural Information Pro essingSystems - 6, pp. 671{678. Morgan Kaufman.Choi, S. P. M., & Yeung., D. Y. (1996). Predi tive Q-routing: A memory based reinfor ementlearning approa h to adaptive tra\u00c6 ontrol. In Touretzky, D. S., Mozer, M. C., &Hasselmo, M. E. (Eds.), Advan es in Neural Information Pro essing Systems - 8, pp.945{951. MIT Press.Claus, C., & Boutilier, C. (1998). The dynami s of reinfor ement learning ooperativemultiagent systems. In Pro eedings of the Fifteenth National Conferen e on Arti ialIntelligen e, pp. 746{752, Madison, WI.Cohen, J. E., & Je ries, C. (1997). Congestion resulting from in reased apa ity in single-server queueing networks. IEEE/ACM Transa tions on Networking, 5 (2), 305{310.Cohen, J. E., & Kelly, F. P. (1990). A paradox of ongestion in a queuing network. Journalof Applied Probability, 27, 730{734.Crowe, B. L. (1969). The tragedy of the ommons revisited. S ien e, 166, 1103{1107.Deo, N., & Pang, C. (1984). Shortest path algorithms: Taxonomy and annotation. Networks,14, 275{323.Dijkstra, E. (1959). A note on two problems in onne tion with graphs. Numeri he Math-emati s, 1 (269-171).Fudenberg, D., & Tirole, J. (1991). Game Theory. MIT Press, Cambridge, MA.Glan e, N. S. (1993). Dynami s with Expe tations. Ph.D. thesis, Stanford University.Glan e, N. S., & Hogg, T. (1995). Dilemmas in omputational so ieties. In Lesser, V.(Ed.), Pro . of the 1st International Conferen e on Multi-Agent Systems (ICMAS95),pp. 117{124, Menlo Park, CA. AAAI Press.Hardin, G. (1968). The tragedy of the ommons. S ien e, 162, 1243{1248.Heusse, M., Snyers, D., Guerin, S., & Kuntz, P. (1998). Adaptive agent-driven routingand load balan ing in ommuni ation networks. Advan es in Complex Systems, 1,237{254.Hogg, T. (1995). So ial dilemmas in omputational e osystems. In Pro eedings of theFourteenth International Joint Conferen e on Arti ial Intelligen e, pp. 711{716, SanMateo, CA. Morgan Kaufmann.Hu, J., & Wellman, M. P. (1998a). Multiagent reinfor ement learning: Theoreti al frame-work and an algorithm. In Pro eedings of the Fifteenth International Conferen e onMa hine Learning, pp. 242{250.Hu, J., & Wellman, M. P. (1998b). Online learning about other agents in a dynami multi-agent system. In Pro eedings of the Se ond International Conferen e on AutonomousAgents, pp. 239{246.Huberman, B. A., & Hogg, T. (1988). The behavior of omputational e ologies. In TheE ology of Computation, pp. 77{115. North-Holland.385\nWolpert & TumerHuberman, B. A., & Lukose, R. M. (1997). So ial dilemmas and internet ongestion. S ien e,277 (5325), 535{537.Huberman, B. A., & Hogg, T. (1993). The emergen e of omputational e ologies. In Nadel,L., & Stein, D. (Eds.), 1992 Le tures in Complex Systems, Vol. V of SFI Studies inthe S ien es of Complexity, pp. 185{205. Addison-Wesley, Reading, MA.Huhns, M. E. (Ed.). (1987). Distributed Arti ial Intelligen e. Pittman, London.Jennings, N. R., Sy ara, K., & Wooldridge, M. (1998). A roadmap of agent resear h anddevelopment. Autonomous Agents and Multi-Agent Systems, 1, 7{38.Kaelbing, L. P., Littman, M. L., & Moore, A. W. (1996). Reinfor ement learning: A survey.Journal of Arti ial Intelligen e Resear h, 4, 237{285.Kelly, F. P. (1996). Modeling ommuni ation networks, present and future. Philosophi alTrends Royal So iety of London A, 354, 437{463.Korilis, Y. A., Lazar, A. A., & Orda, A. (1995). Ar hite ting non ooperative networks.IEEE Journal on Sele ted Areas in Communi ations, 13 (8), 1241{1251.Korilis, Y. A., Lazar, A. A., & Orda, A. (1997a). A hieving network optima using Sta kel-berg routing strategies. IEEE/ACM Transa tions on Networking, 5 (1), 161{173.Korilis, Y. A., Lazar, A. A., & Orda, A. (1997b). Capa ity allo ation under non ooperativerouting. IEEE Transa tions on Automati Control, 42 (3), 309{325.Korilis, Y. A., Lazar, A. A., & Orda, A. (1999). Avoiding the Braess paradox in non oop-erative networks. Journal of Applied Probability, 36, 211{222.Kumar, S., & Miikkulainen, R. (1997). Dual reinfor ement Q-routing: An on-line adaptiverouting algorithm. In Arti ial Neural Networks in Engineering, Vol. 7, pp. 231{238.ASME Press.Littman, M. L., & Boyan, J. (1993). A distributed reinfor ement learning s heme for networkrouting. In Pro eedings of the 1993 International Workshop on Appli ations of NeuralNetworks to Tele ommuni ations, pp. 45{51.Marba h, P., Mihats h, O., S hulte, M., & Tsisiklis, J. (1998). Reinfor ement learning for all admission ontrol and routing in integrated servi e networks. In Advan es inNeural Information Pro essing Systems - 10, pp. 922{928. MIT Press.Orda, A., Rom, R., & Shimkin, N. (1993a). Competitive routing in multiuse ommuni ationnetworks. IEEE/ACM Transa tions on Networking, 1 (5), 510{521.Orda, A., Rom, R., & Sidi, M. (1993b). Minimum delay routing in sto hasti networks.IEEE/ACM Transa tions on Networking, 1 (2), 187{198.Sandholm, T., Larson, K., Anderson, M., Shehory, O., & Tohme, F. (1998). Anytime oali-tion stru ture generation with worst ase guarantees. In Pro eedings of the FifteenthNational Conferen e on Arti ial Intelligen e, pp. 46{53.Sandholm, T., & Lesser, V. R. (1995). Issues in automated negotiations and ele troni om-mer e: extending the ontra t net proto ol. In Pro eedings of the Se ond InternationalConferen e on Multi-Agent Systems, pp. 328{335. AAAI Press.386\nColle tive Intelligen e, Data Routing and Braess' ParadoxS haerf, A., Shoham, Y., & Tennenholtz, M. (1995). Adaptive load balan ing: A study inmulti-agent learning. Journal of Arti ial Intelligen e Resear h, 162, 475{500.Shenker, S. J. (1995). Making greed work in networks: A game-theoreti analysis of swit hservi e dis iplines. IEEE Transa tions on Networking, 3 (6), 819{831.Stone, P. (2000). TPOT-RL applied to network routing. In Pro eedings of the SeventeenthInternational Ma hine Learning Conferen e, pp. 935{942. Morgan Kau man.Subramanian, D., Drus hel, P., & Chen, J. (1997). Ants and reinfor ement learning: A asestudy in routing in dynami networks. In Pro eedings of the Fifteenth InternationalConferen e on Arti ial Intelligen e, pp. 832{838.Sutton, R. S. (1988). Learning to predi t by the methods of temporal di eren es. Ma hineLearning, 3, 9{44.Sutton, R. S., & Barto, A. G. (1998). Reinfor ement Learning: An Introdu tion. MIT Press,Cambridge, MA.Sy ara, K. (1998). Multiagent systems. AI Magazine, 19 (2), 79{92.Tumer, K., Agogino, A., & Wolpert, D. (2002). Learning sequen es of a tions in olle tivesof autonomous agents. In Pro eedings of the First International Joint Conferen e onAutonomous Agents and Multi-Agent Systems, Bologna, Italy.Tumer, K., & Wolpert, D. H. (2000). Colle tive intelligen e and Braess' paradox. InPro eedings of the Seventeenth National Conferen e on Arti ial Intelligen e, pp. 104{109, Austin, TX.Watkins, C., & Dayan, P. (1992). Q-learning. Ma hine Learning, 8 (3/4), 279{292.Wolpert, D. H., Kirshner, S., Merz, C. J., & Tumer, K. (2000). Adaptivity in agent-basedrouting for data networks. In Pro eedings of the fourth International Conferen e ofAutonomous Agents, pp. 396{403.Wolpert, D. H., Sill, J., & Tumer, K. (2001). Reinfor ement learning in distributed domains:Beyond team games. In Pro eedings of the Seventeenth International Joint Conferen eon Arti ial Intelligen e, pp. 819{824, Seattle, WA.Wolpert, D. H., & Tumer, K. (1999). An Introdu tion to Colle tive Intelligen e. Te h.rep. NASA-ARC-IC-99-63, NASA Ames Resear h Center. URL:http://i .ar .na-sa.gov/i /proje ts/ oin pubs.html. To appear in Handbook of Agent Te hnology,Ed. J. M. Bradshaw, AAAI/MIT Press.Wolpert, D. H., & Tumer, K. (2001). Optimal payo fun tions for members of olle tives.Advan es in Complex Systems, 4 (2/3), 265{279.Wolpert, D. H., Tumer, K., & Frank, J. (1999). Using olle tive intelligen e to route internettra\u00c6 . In Advan es in Neural Information Pro essing Systems - 11, pp. 952{958. MITPress.Wolpert, D. H., Wheeler, K., & Tumer, K. (2000). Colle tive intelligen e for ontrol ofdistributed dynami al systems. Europhysi s Letters, 49 (6). 387"}], "references": [], "referenceMentions": [], "year": 2011, "abstractText": null, "creator": "dvips(k) 5.86 Copyright 1999 Radical Eye Software"}}}