{"id": "1202.5597", "review": {"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "25-Feb-2012", "title": "Hybrid Batch Bayesian Optimization", "abstract": "bayesian optimization goals at optimizing an unknown non - convex / concave function that is costly to evaluate. we more interested in application scenarios where concurrent function evaluations are possible. preparing such a prediction, bo could choose to either sequentially evaluate the function, one input at a time and wait for the output of the function before making the reward selection, or evaluate the function at a batch of multiple inputs at once. these two different settings are commonly referred to as the sequential and batch settings of bayesian optimization. in general, the sequential setting leads to better optimization performance as each function evaluation is selected with more information, whereas the continuation setting has an advantage in terms off the standard experimental time ( excess number of arguments ). in latter work, our goal is to combine evolutionary strength of both settings. combined, we systematically analyze bayesian optimization using gaussian process as the posterior estimator and provide a hybrid matrix that, based on the current state, dynamically switches between typical conditional policy and a batch policy with decreasing batch sizes. we provide theoretical justification for our algorithm and present experimental results on specific crop related problems. the results show that our method demonstrates actual speedup ( up to % 78 ) orthogonal to a batch sequential policy, without suffering any significant performance loss.", "histories": [["v1", "Sat, 25 Feb 2012 02:00:51 GMT  (210kb,D)", "https://arxiv.org/abs/1202.5597v1", null], ["v2", "Wed, 29 Feb 2012 01:55:33 GMT  (211kb,D)", "http://arxiv.org/abs/1202.5597v2", null], ["v3", "Tue, 1 May 2012 03:08:22 GMT  (214kb,D)", "http://arxiv.org/abs/1202.5597v3", null]], "reviews": [], "SUBJECTS": "cs.AI cs.LG", "authors": ["javad azimi", "ali jalali", "xiaoli zhang fern"], "accepted": true, "id": "1202.5597"}, "pdf": {"name": "1202.5597.pdf", "metadata": {"source": "CRF", "title": "Hybrid Batch Bayesian Optimization", "authors": ["Javad Azimi", "Ali Jalali", "Xiaoli Fern"], "emails": ["azimi@eecs.oregonstate.edu", "alij@utexas.edu", "xfern@eecs.oregonstate.edu"], "sections": [{"heading": "1 Introduction", "text": "Bayesian optimization tries to optimize an unknown function f(\u00b7) by requesting a set of experiments when f(\u00b7) is costly to evaluate [8, 4]. In this work, we are interested in finding a point x\u2217 \u2208 X d such that:\nx\u2217 = argmax x\u2208Xd f(x), (1)\nwhere X d is our d-dimensional compact input space and f(\u00b7) is the non-concave underlying function which has multiple local optima. The function f(\u00b7) might be the performance of a black box device characterized by input x. For example, in our motivating application we try to optimize the power output of nano-enhanced Microbial Fuel Cells (MFCs). MFCs [3] use micro-organisms to generate electricity. It has been shown that efficiency of generated electricity power significantly depends on the surface properties of the anode [12]. Our problem involves optimizing the surface properties of the anodes in order to maximize the output power. The goal is to develop an efficient BO algorithm for this application since running an experiment is very expensive and time consuming.\nFocusing on the task of function maximization, each run of BO consists of two main steps: estimating the values of the unknown function f(\u00b7) via a probabilistic model such as GP, and selecting the best next experiment(s) according to the probabilistic model via some selection criterion. The results of the experiment(s) are then be added to update the probabilistic model and this cycle is repeated until we meet a stopping criterion.\nMost of the proposed selection criteria in BO are sequential, where only one experiment is selected at each iteration [11, 8, 14, 9]. Sequential policies usually perform very well in practice, since they optimize the experiment selection at each iteration by using the maximum available information for each experiment. However, they are not time efficient in many applications where running an experiment takes a long time, and we have the capability to run multiple experiments in parallel. This motivates the batch algorithms in which more than one experiment is selected at each iteration.\nRecently, Azimi et al. [2] introduced a batch BO approach that selects a batch of k experiments at each iteration that approximates the behavior of a given sequential heuristic. Ginsbourger et al. [7] introduced a constant liar heuristic algorithm to select a batch of experiments based on the Expected Improvement (EI) [9] policy. Specifically, after\nar X\niv :1\n20 2.\n55 97\nv3 [\ncs .A\nI] 1\nM ay\nselecting an experiment by EI, the output of the selected point is set to a constant value. This experiment is then added to the prior and the procedure is repeated until k experiments are selected. Although these two batch algorithms [2, 7] can speedup the experiment selection by a factor of k, their results show that batch selection in general performs worse than the sequential EI policy, especially when the total number of experiments is small. This observation motivates us to introduce a Hybrid BO approach that dynamically alternates between sequential and batch selection to achieve improved time efficiency over sequential without degrading the optimization performance.\nIn this paper, we focus on a class of batch policies that is based on simulating a sequential policy and provide a systematic approach to analyze such batch BO policies. We analytically connect the mismatch between the BO\u2019s probabilistic model and the underlying true function to the performance of the batch policy. We provide full characterization of simulated-based batch policies when the batch size is 2. For the purpose of illustration, consider a batch policy that selects 2 experiments. The first experiment matches the sequential policy. The choice of the second experiment, however, will depend on what is the simulated outcome of the first experiment. We show that the distance between the second experiment picked by a simulation-based batch policy (without the knowledge of the output of the first experiment) and the one picked by the sequential policy (with the knowledge of the output of the first experiment) is upper-bounded by a quantity that is proportional to the square root of the estimation error (of the outcome of the first experiment).\nThis analysis naturally gives rise to our hybrid batch/sequential algorithm. Our algorithm works as follows: At each step, given any sequential policy (EI in this paper), find the best next single experiment and estimate its possible outcome via BO\u2019s probabilistic model (GP in this paper). Then, update the prior with that point and choose the next best single experiment and so on. We analytically show that this process can be continued until a certain stopping criterion is met. This stopping criterion measures how much a simulated experiment is going to bias our probabilistic model (mainly because of inaccuracy in estimation of the outcomes of the first experiment). If the bias is small, we continue to add more examples to our batch; and if it is large, we stop.\nThe proposed algorithm has the appealing property that it behaves more like a sequential policy in early stages when the number of observed experiments is small, and naturally transits to batch mode in later stages when more experiments are available. This is because the stopping criterion tends to be more stringent in early stages because the bias of the prior can be potentially large, forcing the algorithm to act sequentially. The beauty of this algorithm is that it evolves from a sequential algorithm to a batch algorithm in an optimal manner characterized by our theoretical results.\nExperimental results show that the proposed algorithm can achieve up to 78% speedup over the sequential policy without degrading the performance even with a very small number of experiments. We also show that, by increasing the number of experiments, the speedup rate is increased significantly which is consistent with the theoretical results presented in the paper.\nThe paper is organized as follows. We introduce the Gaussian Process which is used as our model in Section 2. The proposed dynamic batch algorithm is described in Section 3. Section 4 presents the experimental results and the paper is concluded in Section 5"}, {"heading": "2 Gaussian Process", "text": "A BO algorithm has two main ingredients: a probabilistic model for the unknown function, and, a selection criterion for choosing next best experiment(s) based on the model. We select GP [13] as our probabilistic model and EI [9] as our selection criterion. We study the properties of GP in this section and postpone the analysis of EI to the next section.\nWe use GP to build the posterior over the outcome values given our observation set O = (xO,yO), where, xO = {x1, x2, . . . , xn} is the set of inputs and yO = {y1, y2, . . . , yn} is the set of outcomes (of the experiment) such that yj = f(xj) and f(\u00b7) is the underlying unknown function.\nFor a new input point xi, GP models the unknown output yi = f(xi) as a normal random variable yi \u223c N (\u00b5xi|O, \u03c32xi|O), with \u00b5xi|O = k(xi,xO)k(xO,xO) \u22121yO and \u03c3 2 xi|O = k(xi, xi)\u2212 k(xi,xO)k(xO,xO)\n\u22121k(xO, xi), where, k(\u00b7, \u00b7) is any arbitrary kernel function.\nDefinition 1. Let x = {x1, x2, . . . , xm} \u2208 X \\ xO be any unobserved set of points. Let y\u0302 = {y\u03021, y\u03022, . . . , y\u0302m} be our estimate of their outputs based on GP considering yi|O \u223c N (\u00b5xi|O, \u03c32xi|O). For any new point z \u2208 X \\ {xO \u222a x}, let yz|O \u223c N (\u00b5z|O, \u03c32z|O) and yz|O, (x, y\u0302) \u223c N (\u00b5\u0302z|O,x, \u03c3\u0302 2 z|O,x).\nUnder the GP model, the variance of a point z depends only on the location of the observed points and is independent of their outputs, i.e., \u03c3\u03022z|O,x = \u03c3 2 z|O,x. Therefore, we can update the variance of any point z after finalizing\nour new query set x without the knowledge of their true outputs y = f(x). The following theorem characterizes the change in the variance of z if we query x.\nTheorem 1. Assuming \u2206(\u03c3z) := \u03c32z|O \u2212 \u03c3 2 z|O,x, we have\n\u2206(\u03c3z) = ( CA\u22121BT\u2212 k(z,x) ) D ( CA\u22121BT\u2212 k(z,x) )T , (2)\nwhere, B = k(x,xO), A = k(xO,xO), C = k(z,xO) and D = (k(x,x)\u2212BA\u22121BT )\u22121.\nFrom a practical point of view, this theorem enables us to update the variance of z via computing the difference \u2206(\u03c3z) and add it to the previous value. This scheme is much faster than recalculating the variance of z directly. The computational bottleneck of this update is only the matrix inversion in D with complexity O(m3), considering the fact that k(xO,xO)\u22121 has been computed before, while the complexity of the direct variance computation is O ( (n+m)3 ) .\nThe actual expected value \u00b5z|O,x heavily depends on the true outputs y = f(x), which are not available. Without the knowledge of the true outputs, we make an estimation \u00b5\u0302z|O,x based on the GP-suggested output values y\u0302. We bound this estimation error in the next theorem. Theorem 2. Let \u03b3z = \u2225\u2225(k(z,x)\u2212 CA\u22121BT )D\u2225\u2225\n2 . Then,\u2223\u2223\u00b5z|O,x \u2212 \u00b5\u0302z|O,x\u2223\u2223 \u2264 \u03b3z \u2225\u2225y \u2212 y\u0302\u2225\u22252\u2223\u2223\u00b5z|O,x \u2212 \u00b5z|O\u2223\u2223 \u2264 \u03b3z\u2225\u2225y \u2212 \u00b5x|O\u2225\u22252.\nHere, \u2016 \u00b7 \u20162 is vector 2-norm. This theorem tells us that our estimation error at point z is proportional to the parameter \u03b3z , which is known to us without the knowledge of y. Intuitively, if \u03b3z is small, we would think that our estimation \u00b5\u0302z|O,x is accurate and hence, we can make our decision about the point z without knowing y, i.e., before the result of experiment on x returns. This observation tells us that it is possible to do batch BO without a big loss in performance.\nRemark: If we want to minimize our estimation error of \u00b5\u0302z|O,x in expectation, we should set y\u0302 = \u00b5x|O. This is in some sense trivial and even counter intuitive. One might claim that if the unknown function is upper-bounded by M , then the best choice for y\u0302 is M since it increases the expected value around the optimal point in the GP model. However, this theorem shows that this choice is overly optimistic.\nThe previous theorem provides a performance bound based on our estimation error on y\u0302, however, from a practical point of view, that bound cannot be computed since we do not know the exact values of y. As a practical measure, we would like to focus on the expected value of the estimation error as opposed to the error itself. Next corollary provides an upper-bound on the expected error, by simply taking expectation from the result of theorem 2. Corollary 1. Let \u03b8x := \u221a\u2211m\ni=1 \u03c3 2 xi|O, then\nEy [ |\u00b5z|O,x \u2212 \u00b5z|O| ] \u2264 \u03b3z\u03b8x.\nMoreover, Ey [ |\u00b5z|O,x \u2212 \u00b5\u0302z|O,x| ] \u2264 \u03b3z ( \u03b8x + \u2016y\u0302 \u2212 \u00b5x|O\u20162 ) .\nRemark 1: We focus on the second bound in this corollary, which has two terms. The first term (\u03b3z\u03b8x) measures \u201chow close\u201d the point z is to x. The second term captures the bias of our estimator y\u0302. According to this corollary, the best choice for y\u0302 is the mean \u00b5x|O.\nRemark 2: This corollary entails that if for some small value of , we have \u03b3z ( \u03b8x + \u2016y\u0302 \u2212 \u00b5x|O\u20162 ) \u2264 , (3)\nthen, we are guaranteed that Ey [ |\u00b5z|O,x \u2212 \u00b5\u0302z|O,x| ] \u2264 .\nSince \u03b3z and \u03b8x are both computable without the knowledge of y, this observation motivates us to use this as a stopping criterion for our algorithm to determine if the current estimation bias is too large to continue selecting more examples in the batch. In the nutshell, when we want to query a batch of samples, if this criterion is met, we are sure that our estimation of y is accurate and hence, we do not need to wait for the label of the selected examples before making the next selection."}, {"heading": "3 Hybrid Batch Bayesian Optimization", "text": "In a sequential approach, we query for only one experiment at a time using a selection criterion (policy), mainly because the selection criterion requires the output of the previous query to find the next best one. Suppose we have the capability of running nb experiments in parallel, and we are limited by the total number of possible experiments nl. At each iteration, the question is whether or not we can query more than one sample to speed up the experimental procedure without losing performance comparing to the sequential approach.\nWe use Expected Improvement (EI) as our base sequential selection criterion. Below we provide the formal definition for EI.\nDefinition 2. EI[9] at point x with associated GP prediction y|O \u223c N (\u00b5x|O, \u03c32x|O) is defined to be\nEI(x|O) = ( \u2212 u\u03a6(\u2212u) + \u03c6(u) ) \u03c3x|O, (4)\nwhere, u = (ymax \u2212 \u00b5x|O)/\u03c3x|O and ymax = max yi\u2208yO yi. Also, \u03a6(\u00b7) and \u03c6(\u00b7) represent standard Gaussian distribution and density functions respectively.\nOur proposed algorithm selects a batch (possibly one) of samples at each iteration based on the EI policy, where the batch size is dynamically determined at each step. In particular, the algorithm will continue to select more experiments if the condition in (3) is satisfied for the select point z.\nTo explain the algorithm, suppose we are at the beginning of the first round of the algorithm. Thus far, we have observed yO = f(xO) at some randomly chosen sample points xO. To form our batch query, we start from an empty set of samples and gradually add the next best sample one at a time. The first sample we pick (x1) is identical to the first sample that sequential EI picks (x\u22171), simply because both maximize the same objective, i.e., x1 = x \u2217 1. To pick our second sample, we estimate y\u22171 = f(x \u2217 1) by some value y\u03021. This estimation, changes the EI function of all unobserved points to some E\u0302I function formulated as\nE\u0302I(z|O, x\u22171) = ( \u2212 u\u0302\u03a6(\u2212u\u0302) + \u03c6(u\u0302) ) \u03c3z|O,x\u22171 ,\nwhere, u\u0302 = max(ymax,y\u03021)\u2212\u00b5\u0302z|O,x\u22171\n\u03c3z|O,x\u22171 . This is different from the true EI function:\nEI(z|O, x\u22171) = ( \u2212 u\u03a6(\u2212u) + \u03c6(u) ) \u03c3z|O,x\u22171 ,\nwhere, u = max(ymax,y\n\u2217 1 )\u2212\u00b5z|O,x\u22171\n\u03c3z|O,x\u22171 . Obviously, optimizing E\u0302I might not lead to the optimum of the true EI . However,\nthe next lemma shows that these two functions are close to each other for a good estimation y\u03021.\nLemma 1. At any point z, we have\u2223\u2223\u2223EI(z|O, x\u22171)\u2212 E\u0302I(z|O, x\u22171)\u2223\u2223\u2223 \u2264 1 2 ( 1 + \u03c3z|O \u03c3x\u22171 |O )\u2223\u2223\u2223y\u03021 \u2212 y\u22171 \u2223\u2223\u2223. (5) In the light of this lemma, there is hope that x2 = arg max E\u0302I (a potential batch sample from our algorithm) is close to x\u22172 = arg max EI (the optimal sample picked by sequential policy). The next theorem bounds the error of our algorithm in terms of the second selected point in comparison to the sequential EI.\nTheorem 3. Let \u03a3min be the minimum singular value of the Hessian matrix d 2E\u0302I dx2 (x) on the line intersecting x2 and x\u22172. Then, \u2225\u2225\u2225x\u22172 \u2212 x2\u2225\u2225\u22252 2 \u2264 2 \u03a3min ( 1 + max(\u03c3x2|O, \u03c3x\u22172 |O)\n\u03c3x\u22171 |O ) \u2223\u2223\u2223y\u03021 \u2212 y\u22171 \u2223\u2223\u2223. (6) Here x2 is the second point selected by our simulation based batch method without knowing the outcome of x1, whereas x\u22172 is the second point selected by the sequential EI method after knowing the outcome of x1. Remark 1: The parameter \u03a3min captures the curvature of the E\u0302I function around its optimal point x2. This curvature cannot be zero unless x\u22172 is very far from x2, which is very unlikely due to the closeness of their expected values (see Corollary 1).\nRemark 2: This theorem shows that the sample estimation error is proportional to the square root of the estimation error of y\u22171 . This means that the sample estimation is more sensitive to the output estimation error for functions taking value in [0, 1].\nThis line of analysis can be extended to next samples. These results show that an algorithm based on the estimation can be successful. In practice, after we optimized E\u0302I for x2, then, we check the condition (3) (i.e., \u03b3x2(\u03b8x\u22171 + \u2016y\u03021 \u2212 \u00b5y|O\u20162) \u2264 ) and if this condition is satisfied, we add x2 to our batch query and move on to x3 and so on. Algorithm 1 summarizes our proposed method for hybrid batch Bayesian optimization.\nAlgorithm 1 Hybrid Batch Expected Improvement Input: Total budget of experiments (nl), maximum batch size (nb), the predictor (y\u0302), current observation O = (xO ,yO) and stopping threshold .\nwhile nl > 0 do x\u22171 \u2190 arg max\nx\u2208X EI(x|O).\nA \u2190 (x\u22171, y\u03021), nl \u2190 nl \u2212 1.\nz \u2190 arg max x\u2208X E\u0302I(x|O \u222a A). while ( \u03b3z(\u03b8xA + \u2016y\u0302A \u2212 \u00b5xA|O\u20162) \u2264 ) and (nl > 0) and (|A| < nb) do\nA \u2190 A\u222a (z, y\u0302z), nl \u2190 nl \u2212 1. z \u2190 arg max\nx\u2208X E\u0302I(x|O \u222a A).\nend while yA \u2190 RunExperiment(xA) O \u2190 O \u222a (xA,yA)\nend while return max(yO)\nIn early stages, this algorithm behaves more like a sequential policy since the criterion for building up a batch is very hard to satisfy, mainly because \u03b8x is large when we have only a few samples in O. After collecting enough samples, the term \u03b8x starts decreasing and as it gets closer and closer to zero, we can select larger and larger batch sizes. Thus, the algorithm gradually transits into a batch policy while maintaining a close match to the performance to the pure sequential policy.\n4 Experimental Results\nBenchmarks. We consider 6 well-known synthetic benchmark functions: Cosines and Rosenbrock [1, 5] over [0, 1]2, Hartman(3)[6] over [0, 1]3, Hartman(6)[6] over [0, 1]6, Shekel[6] over [3, 6]4 and Michalewicz [10] over [0, \u03c0]5. The analytic expression for these functions are shown in Table 1.\nThe other two real benchmarks are Fuel Cell and Hydrogen. In Fuel Cell, the goal is to maximize the generated electricity from microbial fuel cells with by changing the nano structure properties of the anodes. We fit a regression model on the data to build our function f(\u00b7) for evaluation. In Hydrogen benchmark, the data has been collected as part of a study on Hydrogen production from a particular bacteria where the goal is to maximize the amount of Hydrogen production by optimizing the PH and Nitrogen levels of growth medium. Both Fuel cell and Hydrogen data are in [0, 1]2. Their contour plots are shown in Figure 1.\nSetting. We use a GP using a zero-mean prior and Gaussian kernel function k(x, y) = exp(\u2212 1l \u2016 x\u2212 y \u2016 2), with kernel width l = 0.01\u03a3di=1li, where, li is the length of the i th dimension [2]. For this kernel function, we can directly\ndrive the next two corollaries from theorems 1, 2.\nCorollary 2. For all points z \u2208 X \\ {O, x\u22171}, and kernel function k(x, y) = e\u2212 \u2016x\u2212y\u20162 l , we have \u2206(\u03c3z) \u2265 if\n\u2016 z \u2212 x\u22171 \u20162\u2264 \u2212l ln (\u221a n \u2016 A\u22121BT \u20162 +\u03c3x\u22171 |O \u221a ) .\nThis corollary entails that after selecting the first experiment x\u22171, the set of points z such that \u2206(\u03c3z) \u2265 are located inside a hyper sphere centered at x\u22171. In other words, those inside the hyper sphere are those whose variance is affected significantly (more than ) when x\u22171 is selected.\nCorollary 3. Under the assumption of Corollary 2, we have E[|\u00b5z|O,x \u2212 \u00b5\u0302z|O,x|] \u2265 if \u2016 z \u2212 x\u22171 \u20162\u2264 \u2212l ln \u221a \u03c0 2\n2\u03c36x\u22171 |O \u2212 n \u2016 A\u22121BT \u201622.\nSimilar to corollary 2, the corollary 3 represents a hyper sphere centered at x\u22171 and the points which are inside the hyper sphere are those whose expected values are affected more than when x\u22171 is selected.\nWe run our algorithm on each benchmark for 100 independent times and the average simple regret is reported as the result. The simple regret is the difference between the maximum value of f(\u00b7), denoted by M , and ymax after finishing the experimental procedure. In each run, the algorithm starts with 2 initial random points for 2, 3-dimensional benchmarks and 5 initial random points for higher dimensional benchmarks. The total number of experiments nl is set to 15 for 2, 3-dimensional and 30 for the higher dimensional benchmarks. The maximum batch size at each iteration, nb, is set to 5. The parameter is set to 0.02 for 2, 3-dimensional and 0.2 for higher dimensional benchmarks. Note that, our experimental setup is designed to match typical scenarios encountered in real applications, where we typically start with a very small number of random experiments, and are restricted with a total budget.\nResults. Our algorithm requires us to select a specific estimation for y\u0302. Recall that our theoretical analysis from Theorem 2 suggests that to minimize the estimation error of \u00b5\u0302z|O,x in expectation, we should use y\u0302 = \u00b5x|O. Here we hope to confirm this by comparing different possible estimations for y\u0302. In particular, we consider 6 different estimations of y\u0302 including: 1) y\u0302 = M , which means we expect to observe the best possible output for each experiment selected by\nEI; 2) y\u0302 = ymax, where ymax = maxyi\u2208yO yi is our current best observation; 3) y\u0302 = (1 + \u03b6)ymax, which means each step of EI algorithm is expected to improve the best current observation by margin \u03b6, we set the value of \u03b6 to 0.1 in our experiment; 4) y\u0302 = \u00b5\u0302x|O, which means we set the value of y\u0302 to be the expected output at that point; 5) y\u0302 = ymin, where ymin = minyi\u2208yO yi is the current minimum observed output; and 6) y\u0302 = random, which set y\u0302 to a uniform random value drawn in [ymin, ymax].\nTo demonstrate the effectiveness of our algorithm, we consider two state-of-the-art batch BO algorithms in the literature: 1) simulation matching (Matching) [2] and 2) the constant liar approach in which the output of the selected samples in the batch is set to their mean in order to select the next experiment (CL(\u00b5\u0302)) [7]. For both methods, we set the batch size to k = 5. We have also reported the performance of the sequential EI and pure random selection policies.\nThe speedup of our proposed approach is calculated as the percentage of the samples in the whole experiment that are selected in batch mode. More specifically, if we finish nl samples in T steps, the speedup is calculated as 1 \u2212 Tnl . Clearly, the maximum speedup in our setting is %80, that can be only achieved if we select 5 experiments at each time steps. For example, the speedup of proposed baseline batch approaches, Matching and CL(\u00b5\u0302), are %80. Table 2 shows the result.\nInterestingly, all of the 6 considered estimators achieved similar performance (comparable to EI) in terms of their regrets. The key difference between the different estimators is the level of speedup they achieve. In particular, we observe that the most speedup is achieved by y\u0302 = \u00b5\u0302x|O, for which we are able to produce over 70% speedup (very close to fully batch) for the three high dimensional functions Michalewicz, Shekel and Hartman 6.\nFurther inspection of the speedup rates reveal that setting y\u0302 to a large value, for exampleM , ymax, and (1+\u03b6)ymax, generally leads to less speedup than the other choices. This can be explained by noting that a large value of y\u0302 will lead to higher chance of violating the condition required for making the next experiment selection in Algorithm 1, which is stated in Equation 3. In particular, for a large y\u0302, the next point selected by EI will most likely be very close to x, since the mean of the points close to x are high. This will lead to a large \u03b3z . Further, the quantity \u2016y\u0302 \u2212 \u00b5x|O\u20162 is likely very large. Consequently, it is easy to violate this condition thus stop the selection process early on. In contrast, if y\u0302 = ymin, although \u2016y\u0302 \u2212 \u00b5x|O\u20162 is large, we expect \u03b3z to be small because the next point z selected by EI will likely to be far away from x since the mean and variance of the points close to x are very small. Considering the two terms jointly, we expect to achieve a higher speedup by setting y\u0302 = ymin comparing to setting y\u0302 to a large value, which is exactly what we observe in our experiments. Finally, by setting y\u0302 to \u00b5x|O, we have \u2016y\u0302\u2212 \u00b5x|O\u20162 = 0 and the stopping criterion only depends on \u03b3z\u03b8x. Thus we expect to achieve the maximum speedup among the different choices we consider for y\u0302.\nOur experimental investigation shows that the size of the batch generally increases as the experiment goes forward. This is consistent with our theoretical results in which the value of \u03b3z ( \u03b8x + \u2016y\u0302 \u2212 \u00b5x|O\u20162 ) decreases as the variances decreases. Note that, sampling at any arbitrary point when the number of observations is small would change the\nvariance of the input space significantly comparing to the case where there are a lot of observation points. Therefore, the stopping criteria of Algorithm 1 is less likely to be met in the early stages of the experimental procedure where there are a few observation points.\nThe \u00b5-Constant Batch Approach. This part of the experiments is motivated by our theoretical analysis and the goal is to shed some lights on a batch method recently proposed by Ginsbourger et al. [7], which selects a batch of experiments that jointly maximize the EI objective. They show that finding such a batch of experiments is practically intractable. Therefore, they introduced a heuristic approach called Constant liar to select a batch of k experiments. After selecting the first experiment, Constant liar sets the output of the selected experiment as a constant value c. That experiment is then added to the set of observations and the next experiment is selected. This procedure is repeated until k experiments are selected. They introduced several possible ways for setting c, including c = M , c = \u00b5\u0302 and c = ymin. They empirically demonstrated that setting c = M provided them a good result for their particular test functions. However, there is no theoretical justification or guidance toward what is the best c.\nOur theoretical analysis, in particular Corollary 1, indicates that by setting c (y\u0302 in this paper) to \u00b5\u0302x|O, the condition for continued experiment selection can be easily met comparing to other settings, i.e., \u03b3z\u03b8x \u2264 . Thus, a batch of k \u2265 1 experiments are requested at most iterations without degrading the performance. This theoretical result also justifies the choice of setting c = \u00b5\u0302x|O in the constant liar approach. We call this approach \u00b5-Constant Batch. We run this algorithm on proposed 8 benchmarks for different batch sizes 5 and 10. Figures 2 and 3 show the performance of \u00b5-Constant along with 5 competitive approaches: 1) Sequential EI; 2) Constant liar with y\u0302 = M ; 3) Constant liar with y\u0302 = ymax; 4) Constant liar with y\u0302 = ymin; and 5) Matching, which is a recently proposed approach by Azimi et al. [2]. For this set of experiments, we use the same experimental setup as used in Table 2.\nThe results show that the \u00b5-constant batch approach performs very competitively compared to the Matching approach, which is one of the best existing batch Bayesian optimization approach in the literature. In addition, it is more practical than the Matching approach for high dimensional applications since its computational complexity is significantly less than the Matching algorithm. Note that the performance of \u00b5-Constant is also shown in Table 2 as CL(\u00b5\u0302). It is worth emphasizing that while \u00b5-Constant achieves highly competitive batch performance, it is consistently worse than sequential EI and the proposed Hybrid Batch EI algorithm. This result suggests that the stopping criterion used in Algorithm 1 is in fact effective toward identifying the condition under which we must stop increasing the batch size to avoid significant performance degradation compared to the sequential EI."}, {"heading": "5 Conclusion", "text": "In the Bayesian optimization framework, we investigated the problem of batch query selection with the goal of maintaining the performance of a sequential policy which using fewer iterations. Although our results are for general BO problems, for the sake of clarity, we focused on the task of maximizing an unknown non-convex/concave function.\nThere are two main contributions in this paper. Firstly, we introduce a systematic way to analyze the performance and limits of simulation-based batch BO methods by a) proving universal bounds on the bias caused by the simulation (estimation-of-outcome) error; and b) analyzing the selection of the second experiment when we have an estimate of the outcome of the first experiment. In all cases, we provide theoretical bounds on the error, relating the simulation error to the prediction error of the next best experiment.\nSecondly, based on the analysis above, we proposed an algorithm that behaves optimally in expectation. This algorithm at each step decides whether or not to pick another query to add to the current batch, and as such dynamically determines the appropriate batch size at each step. In early iterations, our algorithm behaves more similar to the sequential policy and gradually moves toward a batch policy with variable batch sizes.\nThe empirical evaluation over both synthetic and real data shows substantial speedup (up to 78% ) compared to the corresponding sequential policy, with little to nothing loss in the optimization performance. Our theoretical results also shed some interesting light on the Constant-liar approach, a recently proposed batch selection method based on the EI objective."}, {"heading": "A Proof of Theorem 1", "text": "Recalling the notation introduced in the Theorem statement, we have\n\u2206(\u03c3z) = CA \u22121CT \u2212 [C k(z,x)]\n[ A BT\nB k(x,x)\n]\u22121 [ CT\nk(z,x) ] = CA\u22121CT \u2212 [C k(z,x)] [ A\u22121 +A\u22121BTDBA\u22121 \u2212A\u22121BTD\n\u2212DBA\u22121 D\n] [ CT\nk(z,x) ] = ( CA\u22121BT \u2212 k(z,x) ) D ( BA\u22121CT \u2212 k(z,x) )T .\nThis concludes the proof of the theorem."}, {"heading": "B Proof of Theorem 2", "text": "By definition and block matrix inversion lemma, we have\n\u00b5z|O,x \u2212 \u00b5\u0302z|O,x = k(z, {xO,x})k({xO,x}, {xO,x})\u22121 [ 0\ny \u2212 y\u0302 ] = (k(z,x)\u2212 CA\u22121BT )D(y \u2212 y\u0302).\nFor the second part, we have\n\u00b5z|O \u2212 \u00b5z|O,x = CA\u22121yO \u2212 [C k(z,x)] [ A BT\nB k(x,x) ]\u22121 [ yO y ] = CA\u22121yO \u2212 [C k(z,x)] [ A\u22121 +A\u22121BTDBA\u22121 \u2212A\u22121BTD\n\u2212DBA\u22121 D\n] [ yO y\u2217 ] = ( CA\u22121BT \u2212 k(z,x) ) D ( BA\u22121yO \u2212 y\n) = ( CA\u22121BT \u2212 k(z,x) ) D ( \u00b5x|O \u2212 y ) .\nThis concludes the proof of the theorem."}, {"heading": "C Proof of Lemma 1", "text": "Let \u2206z = max(ymax, y\u22171)\u2212 \u00b5z|O,x\u22171 . Using Theorem 2, we have\n\u2206\u0302z := max(ymax, y\u03021)\u2212 \u00b5\u0302z|O,x\u22171 = max(ymax, y \u2217 1)\u2212 \u00b5z|O,x\u22171 + max(ymax, y\u03021)\u2212max(ymax, y \u2217 1)\n\u2212 1 \u03c32x\u22171 |O\n( k(z, x\u22171)\u2212 k(z,xO)k(xO,xO)\u22121k(xO, x\u22171) )( y\u03021 \u2212 y\u22171 ) = \u2206z + max(ymax, y\u03021)\u2212max(ymax, y\u22171)\u2212 \u03c1z,x\u22171 \u03c3z|O\n\u03c3x\u22171 |O\n( y\u03021 \u2212 y\u22171 ) \ufe38 \ufe37\ufe37 \ufe38\n\u03b4z\n= \u2206z + \u03b4z.\nHere, \u03c1z,x\u22171 represents the correlation coefficient between x and x1. Thus, we have\n|\u03b4z| \u2264 ( 1 + \u03c3z|O\n\u03c3x\u22171 |O\n) |y\u03021 \u2212 y\u22171 | .\nBy mean-value theorem, there exists \u03b1 \u2208 [0, 1], such that\n\u2212\u2206\u0302z\u03a6 ( \u2212 \u2206\u0302z \u03c3z|O,x\u22171 ) + \u03c3z|O,x\u22171\u03c6 ( \u2206\u0302x \u03c3z|O,x\u22171 ) \ufe38 \ufe37\ufe37 \ufe38\nE\u0302I(z)\n= \u2212\u2206x\u03a6 ( \u2212 \u2206x \u03c3z|O,x\u22171 ) + \u03c3z|O,x\u22171\u03c6 ( \u2206x \u03c3z|O,x\u22171 ) \ufe38 \ufe37\ufe37 \ufe38\nEI(z)\n\u2212\u03a6 ( \u2212\u2206z + \u03b1\u03b4z\n\u03c3z|O,x\u22171\n) \u03b4z\nThus, \u2223\u2223\u2223EI(z)\u2212 E\u0302I(z)\u2223\u2223\u2223 = \u03a6(\u2212\u2206z + \u03b1\u03b4z \u03c3z|O,x\u22171 )\u2223\u2223\u2223\u03b4z\u2223\u2223\u2223 \u2264 1\n2 \u2223\u2223\u2223\u03b4z\u2223\u2223\u2223 \u2264 1 2 ( 1 + \u03c3z|O\n\u03c3x\u22171 |O )\u2223\u2223\u2223y\u03021 \u2212 y\u22171\u2223\u2223\u2223. This concludes the Proof of Lemma."}, {"heading": "D Proof of Theorem 3", "text": "By optimality of x2 and x\u22172, we have\nEI(x2)\u2212 E\u0302I(x2) \u2264 EI(x\u22172)\u2212 E\u0302I(x2) \u2264 EI(x\u22172)\u2212 E\u0302I(x\u22172).\nUsing Lemma 1, we get \u2223\u2223\u2223EI(x\u22172)\u2212 E\u0302I(x2)\u2223\u2223\u2223 \u2264 12 ( 1 + max(\u03c3x2|O, \u03c3x\u22172 |O)\n\u03c3x\u22171 |O )\u2223\u2223\u2223y\u03021 \u2212 y\u22171\u2223\u2223\u2223. We can continue\nE\u0302I(x2)\u2212 E\u0302I(x\u22172) \u2264 \u2223\u2223\u2223E\u0302I(x2)\u2212 EI(x\u22172)\u2223\u2223\u2223+ \u2223\u2223\u2223EI(x\u22172)\u2212 E\u0302I(x\u22172)\u2223\u2223\u2223\n\u2264 ( 1 + max(\u03c3x2|O, \u03c3x\u22172 |O)\n\u03c3x\u22171 |O )\u2223\u2223\u2223y\u03021 \u2212 y\u22171\u2223\u2223\u2223 By optimality of x\u22172, the derivative of EI is zero at x \u2217 2 and Taylor series expansion yields that for some \u03b1 \u2208 [0, 1],\nwe have\nE\u0302I(x\u22172)\u2212 E\u0302I(x2) = 1\n2 (x\u22172 \u2212 x2)T\nd2E\u0302I\ndx2\n( (1\u2212 \u03b1)x\u22172 + \u03b1x2 ) (x\u22172 \u2212 x2).\nFinally, we get \u2225\u2225\u2225x\u22172 \u2212 x2\u2225\u2225\u22252 2 \u2264\n2 \u2223\u2223\u2223E\u0302I(x\u22172)\u2212 E\u0302I(x2)\u2223\u2223\u2223\n\u03a3min ( d2E\u0302I dx2 ((1\u2212 \u03b1)x \u2217 2 + \u03b1x2) ) \u2264 2\n\u03a3min\n( 1 + max(\u03c3x2|O, \u03c3x\u22172 |O)\n\u03c3x\u22171 |O\n)\u2223\u2223\u2223y\u03021 \u2212 y\u22171\u2223\u2223\u2223. (7)"}, {"heading": "E Proof of Corollary 2", "text": "From theorem 1, there is an interesting finding which shows that the difference of variance of any point z in the input space after adding the point x\u2217 to our observation set is exactly D ( k(z, x\u22171)\u2212BA\u22121CT )2 if we consider x\u22171 as a single point. Since \u03b42z \u2212 \u03b42\u2217z > 0, therefore m \u2265 0. In addition, when |x\u2217| = 1, it can be shown that m\u22121 = \u03c3\u22172. Thus, we are interested in the points where \u03b42z \u2212 \u03b4\u22172 \u2265 \u2265 0. Therefore we have:\n\u03b42z \u2212 \u03b42\u2217z \u2212 \u2265 0 Dk(x\u22171, z) 2 \u2212 ( 2DCA\u22121BT ) k(x\u22171, z) + ( D(CA\u22121BT )2 ) \u2212 \u2265 0\n(8)\nthis is a quadratic function of k(x\u22171, z) with 2 real roots as follow:\nk(x\u22171, z) =\n{ r1 = CA \u22121BT + \u221a\nD\nr2 = CA \u22121BT \u2212 \u221a D\n(9)\nSo we are interested in the region where k(x\u22171, z) \u2265 r1 or k(x\u22171, z) \u2264 r2. For large value of the r2 < 0 and since k(x\u22171, z) > 0, we are only interested in where k(x \u2217 1, z) \u2265 r1. Therefore we have\n1 \u2265 k(x\u22171, z) = e \u2212\u2016z\u2212x\u22171\u2016 2 l \u2265 CA\u22121BT + \u221a\nD \u2265 0 (10)\nWe are trying to introduce an upper bound for r1 which is free from Pz . Clearly CA\u22121BT \u2264 |CA\u22121BT |. Then we have,\n|CA\u22121BT | =\u2016 CA\u22121BT \u20162 \u2264\u2016 C \u20162 \u2016 A\u22121BT \u20162 Cauchy-Shwrz inequality \u2264 \u221a n \u2016 C \u2016\u221e \u2016 A\u22121BT \u20162\n\u2264 \u221a n \u2016 A\u22121BT \u20162 sinec 0 \u2264\u2016 C \u2016\u221e\u2264 1\n(11)\nTherefore we are certain about the point satisfying the following equation\nk(x\u22171, z) \u2265 \u221a n \u2016 A\u22121BT \u20162 +\n\u221a\nD \u2016 z \u2212 x\u2217 \u20162 \u2264 \u2212l ln (\u221a n \u2016 A\u22121BT \u20162 + \u221a\nD ) \u2016 z \u2212 x\u2217 \u20162 \u2264 \u2212l ln (\u221a n \u2016 A\u22121BT \u20162 +\u03c3\u2217 \u221a )\n(12)"}, {"heading": "F Proof of Corollary 3", "text": "\u2225\u2225(CA\u22121BT \u2212 k(x\u22171, z))D\u2225\u2225\u221e \u221a 2\n\u03c0 \u2016\u03c3x\u22171|O\u20161 \u2265 \u2223\u2223(CA\u22121BT \u2212 k(x\u22171, z))\u2223\u2223 \u2265 \u221a\n2 \u03c0 |\u03c3x\u22171|O|D\n|(CA\u22121BT \u2212 k(x\u22171, z))|2 \u2265  \u221a 2 \u03c0 |\u03c3x\u22171|O|D 2\n(CA\u22121BT )2 + k(x\u22171, z) 2 \u2265 \u03c0\n2\n2\u03c32x\u22171 |O D2\nk(x\u22171, z) 2 \u2265 \u03c0\n2\n2\u03c36x\u22171 |O \u2212 n \u2016 A\u22121BT \u201622\n\u2016 z \u2212 x\u2217 \u20162 \u2264 \u2212l ln \u221a \u03c0 2\n2\u03c36x\u22171 |O \u2212 n \u2016 A\u22121BT \u201622\n(13)\nNote that |a\u2212 b|2 \u2264 2 \u2217 (a2 + b2). Therefore E[|\u00b5z|O,x \u2212 \u00b5\u0302z|O,x|] \u2265 if we have\n\u2016 z \u2212 x\u2217 \u20162\u2264 \u2212l ln \u221a \u03c0 2\n2\u03c36x\u22171 |O \u2212 n \u2016 A\u22121BT \u201622 (14)"}], "references": [{"title": "A nonparametric approach to noisy and costly optimization", "author": ["B.S. Anderson", "A. Moore", "D. Cohn"], "venue": null, "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2000}, {"title": "Batch bayesian optimization via simulation matching", "author": ["J. Azimi", "A. Fern", "X. Fern"], "venue": null, "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2010}, {"title": "Electricity production by geobacter sulfurreducens attached to electrodes", "author": ["D. Bond", "D. Lovley"], "venue": "Applications of Environmental Microbiology,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2003}, {"title": "A tutorial on Bayesian optimization of expensive cost functions, with application to active user modeling and hierarchical reinforcement learning", "author": ["E. Brochu", "V.M. Cora", "N. de Freitas"], "venue": "Technical Report TR-2009-23,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2009}, {"title": "A memory-based rash optimizer", "author": ["M. Brunato", "R. Battiti", "S. Pasupuleti"], "venue": "Workshop on Heuristic Search, Memory Based Heuristics and Their applications", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2006}, {"title": "The Global Optimization Problem: An Introduction Toward Global Optimization", "author": ["L. Dixon", "G. Szeg"], "venue": null, "citeRegEx": "6", "shortCiteRegEx": "6", "year": 1978}, {"title": "Kriging is well-suited to parallelize optimization", "author": ["D. Ginsbourger", "R.L. Riche", "L. Carraro"], "venue": "Computational Intelligence In Expensive Optimization Problems,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2010}, {"title": "A taxonomy of global optimization methods based on response surfaces", "author": ["D. Jones"], "venue": "Journal of Global Optimization,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2001}, {"title": "Bayesian algorithms for one-dimensional globaloptimization", "author": ["M. Locatelli"], "venue": "J. of Global Optimization,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 1997}, {"title": "Genetic algorithms + data structures = evolution programs (2nd, extended ed.)", "author": ["Z. Michalewicz"], "venue": null, "citeRegEx": "10", "shortCiteRegEx": "10", "year": 1994}, {"title": "Memory-based stochastic optimization", "author": ["A. Moore", "J. Schneider"], "venue": "In NIPS", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 1995}, {"title": "Improved fuel cell and electrode designs for producing electricity from microbial", "author": ["D. Park", "J. Zeikus"], "venue": "degradation. Biotechnol.Bioeng.,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2003}, {"title": "Gaussian Processes for Machine Learning", "author": ["C.E. Rasmussen", "C.K.I. Williams"], "venue": null, "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2006}], "referenceMentions": [{"referenceID": 7, "context": "Bayesian optimization tries to optimize an unknown function f(\u00b7) by requesting a set of experiments when f(\u00b7) is costly to evaluate [8, 4].", "startOffset": 132, "endOffset": 138}, {"referenceID": 3, "context": "Bayesian optimization tries to optimize an unknown function f(\u00b7) by requesting a set of experiments when f(\u00b7) is costly to evaluate [8, 4].", "startOffset": 132, "endOffset": 138}, {"referenceID": 2, "context": "MFCs [3] use micro-organisms to generate electricity.", "startOffset": 5, "endOffset": 8}, {"referenceID": 11, "context": "It has been shown that efficiency of generated electricity power significantly depends on the surface properties of the anode [12].", "startOffset": 126, "endOffset": 130}, {"referenceID": 10, "context": "Most of the proposed selection criteria in BO are sequential, where only one experiment is selected at each iteration [11, 8, 14, 9].", "startOffset": 118, "endOffset": 132}, {"referenceID": 7, "context": "Most of the proposed selection criteria in BO are sequential, where only one experiment is selected at each iteration [11, 8, 14, 9].", "startOffset": 118, "endOffset": 132}, {"referenceID": 8, "context": "Most of the proposed selection criteria in BO are sequential, where only one experiment is selected at each iteration [11, 8, 14, 9].", "startOffset": 118, "endOffset": 132}, {"referenceID": 1, "context": "[2] introduced a batch BO approach that selects a batch of k experiments at each iteration that approximates the behavior of a given sequential heuristic.", "startOffset": 0, "endOffset": 3}, {"referenceID": 6, "context": "[7] introduced a constant liar heuristic algorithm to select a batch of experiments based on the Expected Improvement (EI) [9] policy.", "startOffset": 0, "endOffset": 3}, {"referenceID": 8, "context": "[7] introduced a constant liar heuristic algorithm to select a batch of experiments based on the Expected Improvement (EI) [9] policy.", "startOffset": 123, "endOffset": 126}, {"referenceID": 1, "context": "Although these two batch algorithms [2, 7] can speedup the experiment selection by a factor of k, their results show that batch selection in general performs worse than the sequential EI policy, especially when the total number of experiments is small.", "startOffset": 36, "endOffset": 42}, {"referenceID": 6, "context": "Although these two batch algorithms [2, 7] can speedup the experiment selection by a factor of k, their results show that batch selection in general performs worse than the sequential EI policy, especially when the total number of experiments is small.", "startOffset": 36, "endOffset": 42}, {"referenceID": 12, "context": "We select GP [13] as our probabilistic model and EI [9] as our selection criterion.", "startOffset": 13, "endOffset": 17}, {"referenceID": 8, "context": "We select GP [13] as our probabilistic model and EI [9] as our selection criterion.", "startOffset": 52, "endOffset": 55}, {"referenceID": 8, "context": "EI[9] at point x with associated GP prediction y|O \u223c N (\u03bcx|O, \u03c3 x|O) is defined to be", "startOffset": 2, "endOffset": 5}, {"referenceID": 0, "context": "This means that the sample estimation is more sensitive to the output estimation error for functions taking value in [0, 1].", "startOffset": 117, "endOffset": 123}, {"referenceID": 0, "context": "We consider 6 well-known synthetic benchmark functions: Cosines and Rosenbrock [1, 5] over [0, 1], Hartman(3)[6] over [0, 1], Hartman(6)[6] over [0, 1], Shekel[6] over [3, 6] and Michalewicz [10] over [0, \u03c0].", "startOffset": 79, "endOffset": 85}, {"referenceID": 4, "context": "We consider 6 well-known synthetic benchmark functions: Cosines and Rosenbrock [1, 5] over [0, 1], Hartman(3)[6] over [0, 1], Hartman(6)[6] over [0, 1], Shekel[6] over [3, 6] and Michalewicz [10] over [0, \u03c0].", "startOffset": 79, "endOffset": 85}, {"referenceID": 0, "context": "We consider 6 well-known synthetic benchmark functions: Cosines and Rosenbrock [1, 5] over [0, 1], Hartman(3)[6] over [0, 1], Hartman(6)[6] over [0, 1], Shekel[6] over [3, 6] and Michalewicz [10] over [0, \u03c0].", "startOffset": 91, "endOffset": 97}, {"referenceID": 5, "context": "We consider 6 well-known synthetic benchmark functions: Cosines and Rosenbrock [1, 5] over [0, 1], Hartman(3)[6] over [0, 1], Hartman(6)[6] over [0, 1], Shekel[6] over [3, 6] and Michalewicz [10] over [0, \u03c0].", "startOffset": 109, "endOffset": 112}, {"referenceID": 0, "context": "We consider 6 well-known synthetic benchmark functions: Cosines and Rosenbrock [1, 5] over [0, 1], Hartman(3)[6] over [0, 1], Hartman(6)[6] over [0, 1], Shekel[6] over [3, 6] and Michalewicz [10] over [0, \u03c0].", "startOffset": 118, "endOffset": 124}, {"referenceID": 5, "context": "We consider 6 well-known synthetic benchmark functions: Cosines and Rosenbrock [1, 5] over [0, 1], Hartman(3)[6] over [0, 1], Hartman(6)[6] over [0, 1], Shekel[6] over [3, 6] and Michalewicz [10] over [0, \u03c0].", "startOffset": 136, "endOffset": 139}, {"referenceID": 0, "context": "We consider 6 well-known synthetic benchmark functions: Cosines and Rosenbrock [1, 5] over [0, 1], Hartman(3)[6] over [0, 1], Hartman(6)[6] over [0, 1], Shekel[6] over [3, 6] and Michalewicz [10] over [0, \u03c0].", "startOffset": 145, "endOffset": 151}, {"referenceID": 5, "context": "We consider 6 well-known synthetic benchmark functions: Cosines and Rosenbrock [1, 5] over [0, 1], Hartman(3)[6] over [0, 1], Hartman(6)[6] over [0, 1], Shekel[6] over [3, 6] and Michalewicz [10] over [0, \u03c0].", "startOffset": 159, "endOffset": 162}, {"referenceID": 2, "context": "We consider 6 well-known synthetic benchmark functions: Cosines and Rosenbrock [1, 5] over [0, 1], Hartman(3)[6] over [0, 1], Hartman(6)[6] over [0, 1], Shekel[6] over [3, 6] and Michalewicz [10] over [0, \u03c0].", "startOffset": 168, "endOffset": 174}, {"referenceID": 5, "context": "We consider 6 well-known synthetic benchmark functions: Cosines and Rosenbrock [1, 5] over [0, 1], Hartman(3)[6] over [0, 1], Hartman(6)[6] over [0, 1], Shekel[6] over [3, 6] and Michalewicz [10] over [0, \u03c0].", "startOffset": 168, "endOffset": 174}, {"referenceID": 9, "context": "We consider 6 well-known synthetic benchmark functions: Cosines and Rosenbrock [1, 5] over [0, 1], Hartman(3)[6] over [0, 1], Hartman(6)[6] over [0, 1], Shekel[6] over [3, 6] and Michalewicz [10] over [0, \u03c0].", "startOffset": 191, "endOffset": 195}, {"referenceID": 0, "context": "Both Fuel cell and Hydrogen data are in [0, 1].", "startOffset": 40, "endOffset": 46}, {"referenceID": 1, "context": "01\u03a3i=1li, where, li is the length of the i th dimension [2].", "startOffset": 56, "endOffset": 59}, {"referenceID": 1, "context": "To demonstrate the effectiveness of our algorithm, we consider two state-of-the-art batch BO algorithms in the literature: 1) simulation matching (Matching) [2] and 2) the constant liar approach in which the output of the selected samples in the batch is set to their mean in order to select the next experiment (CL(\u03bc\u0302)) [7].", "startOffset": 157, "endOffset": 160}, {"referenceID": 6, "context": "To demonstrate the effectiveness of our algorithm, we consider two state-of-the-art batch BO algorithms in the literature: 1) simulation matching (Matching) [2] and 2) the constant liar approach in which the output of the selected samples in the batch is set to their mean in order to select the next experiment (CL(\u03bc\u0302)) [7].", "startOffset": 321, "endOffset": 324}, {"referenceID": 6, "context": "[7], which selects a batch of experiments that jointly maximize the EI objective.", "startOffset": 0, "endOffset": 3}, {"referenceID": 1, "context": "[2].", "startOffset": 0, "endOffset": 3}], "year": 2012, "abstractText": "Bayesian Optimization (BO) aims at optimizing an unknown function that is costly to evaluate. We focus on applications where concurrent function evaluations are possible. In such cases, BO could choose to either sequentially evaluate the function (sequential mode) or evaluate the function at a batch of multiple inputs at once (batch mode). The sequential mode generally leads to better optimization performance as each function evaluation is selected with more information, whereas the batch mode is more time efficient (smaller number of iterations). Our goal is to combine the strength of both settings. We systematically analyze BO using a Gaussian Process as the posterior estimator and provide a hybrid algorithm that dynamically switches between sequential and batch with variable batch sizes. We theoretically justify our algorithm and present experimental results on eight benchmark BO problems. The results show that our method achieves substantial speedup (up to 78%) compared to sequential, without suffering any significant performance loss.", "creator": "LaTeX with hyperref package"}}}