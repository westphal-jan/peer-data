{"id": "1205.2613", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "9-May-2012", "title": "Measuring Inconsistency in Probabilistic Knowledge Bases", "abstract": "this paper develops an inconsistency measure on conditional network knowledge bases. the measure is based on fundamental principles termed inconsistency measures and thus gives perfectly solid theoretical framework for the treatment across inconsistencies in probabilistic autonomous systems. we illustrate its usefulness and immediate limitations on several examples and present some formal results. building on this technique we use numerical shapley technology - a well - known solution for coalition games - to define a sophisticated indicator that is not only able to measure inconsistencies but appropriately reveal the causes of inconsistencies in the knowledge environment. altogether these tools guide the knowledge then change his aim to restore consistency and therefore enable him to build a solid and usable knowledge metric that can be employed in probabilistic expert systems.", "histories": [["v1", "Wed, 9 May 2012 18:31:58 GMT  (177kb)", "http://arxiv.org/abs/1205.2613v1", "Appears in Proceedings of the Twenty-Fifth Conference on Uncertainty in Artificial Intelligence (UAI2009)"]], "COMMENTS": "Appears in Proceedings of the Twenty-Fifth Conference on Uncertainty in Artificial Intelligence (UAI2009)", "reviews": [], "SUBJECTS": "cs.AI", "authors": ["matthias thimm"], "accepted": false, "id": "1205.2613"}, "pdf": {"name": "1205.2613.pdf", "metadata": {"source": "CRF", "title": "Measuring Inconsistency in Probabilistic Knowledge Bases", "authors": ["Matthias Thimm"], "emails": [], "sections": [{"heading": null, "text": "This paper develops an inconsistency measure on conditional probabilistic knowledge bases. The measure is based on fundamental principles for inconsistency measures and thus provides a solid theoretical framework for the treatment of inconsistencies in probabilistic expert systems. We illustrate its usefulness and immediate application on several examples and present some formal results. Building on this measure we use the Shapley value\u2014a well-known solution for coalition games\u2014to define a sophisticated indicator that is not only able to measure inconsistencies but to reveal the causes of inconsistencies in the knowledge base. Altogether these tools guide the knowledge engineer in his aim to restore consistency and therefore enable him to build a consistent and usable knowledge base that can be employed in probabilistic expert systems."}, {"heading": "1 Introduction", "text": "Inconsistencies arise easily when experts share their knowledge in order to build a common knowledge base. Although these inconsistencies often affect only a little portion of the knowledge base or emerge from only little differences in the experts knowledge, they cause severe damage. Especially in knowledge bases that use classical logic as a means for knowledge representation, inconsistencies render the whole knowledge base useless, due to the well-known principle ex falso quodlibet. Therefore reasoning under inconsistency is an important field in AI and there are many proposals to deal with inconsistency in classical logic, e. g. (Rescher and Manor, 1970; Konieczny et al., 2005), or in other logical frameworks, e. g. paraconsistent logics (Bziau et al., 2007), default logics (Reiter, 1980),\ndefeasible logics (Billington, 2008), and argumentation theory (Bench-Capon and Dunne, 2007). Furthermore there are several approaches to analyze and measure inconsistency in qualitative frameworks, e. g. (Lozinskii, 1994; Benferhat et al., 1997; Knight, 2001; Hunter and Konieczny, 2004), and some in quantitative frameworks (mainly possibilistic frameworks), e. g. (Dubois et al., 1992).\nHere, we aim at analyzing inconsistencies in a probabilistic framework and in particular measuring inconsistency in conditional probabilistic knowledge bases (Nute and Cross, 2002; Kern-Isberner, 2001; Benferhat et al., 1999; Ro\u0308dder and Meyer, 1996). In these, knowledge is captured using conditionals (A |B) that describe rules of the form \u201cIf B then A\u201d and are interpreted using conditional probabilities. In contrast to probabilistic networks like Bayesian Networks (Pearl, 1998) conditional probabilistic knowledge bases do not demand the complete specification of every conditional probability of every probabilistic dependence and thus do not define a unique probability distribution as the underlying model. Nonetheless, using maximum entropy methods (Grove et al., 1994) one can determine a single probability distribution that describes the specified knowledge in an unbiased way. However, due to the unstructured approach of conditional probabilistic knowledge bases inconsistencies easily occur whereas Bayesian Networks forbid cyclic dependencies and so inconsistencies cannot arise by definition.\nThere is very little work on the treatment of inconsistencies in a conditional probabilistic framework (Ro\u0308dder and Xu, 2001; Finthammer et al., 2007). The method described in (Finthammer et al., 2007) consists of a set of heuristics that are used to restore consistency in a knowledge base. Although this method is not based on a theoretical elaboration it works well in real-world examples and has been applied successfully to improve fraud detection in management. Other related work (Hansen and Jaumard, 1996; Andersen and Pretolani, 2001) investigates inconsistencies in classi-\ncal theories enriched with probabilistic semantics but without treatment of conditional probabilities as we do here. Furthermore the authors of (Hansen and Jaumard, 1996; Andersen and Pretolani, 2001) are mainly interested in efficient algorithms for determining whether a knowledge base is inconsistent and not to what degree.\nThe main contribution of this paper consists of the development of an inconsistency measure on conditional probabilistic knowledge bases that is based on fundamental principles that are desired from inconsistency measures in general. Furthermore we apply the approach taken in (Hunter and Konieczny, 2006) on our framework and use the Shapley value (Shapley, 1953) to define a more sophisticated inconsistency measure based on the basic inconsistency measure developed before. Using this Shapley inconsistency measure we are able to determine not only the degree of inconsistency but also the contributors to it, i. e. the conditionals that are responsible for the inconsistency.\nThis paper is organized as follows. In Section 2 we start with some necessary preliminaries and a description of the basic framework. Afterwards in Section 3 we discuss the basic problem of determining consistency in the basic framework. In Section 4 we go on by stating some desirable properties of an inconsistency measure on probabilistic knowledge bases in general and propose a measure that fulfills these properties. In order to be able to determine the causes of inconsistency we continue in Section 5 by introducing a more sophisticated measure based on the Shapley value and the basic inconsistency measure introduced before. In Section 6 we conclude."}, {"heading": "2 Preliminaries", "text": "We are working with a propositional framework of random variables. Let V = {V1, . . . , Vn} be a set of propositional variables with finite domains Dom(V1), . . . ,Dom(Vn). The set V is assumed to be given for all upcoming definitions. An expression of the form Vi = vi is called a literal if vi is in the domain of Vi, i. e. vi \u2208 Dom(Vi). The language LV is generated using the connectives \u00ac, \u2227, and \u2228 on the literals in V in the usual way. We abbreviate conjunctions A\u2227B by AB and negation \u00acA by overlining A. If V is a binary variable, i. e., it is Dom(V ) = {true, false}, we abbreviate V = true by just V and V = false by V . We write > for tautological formulas, e. g. A \u2228 A = >. A complete conjunction or interpretation is a conjunction of literals where every Vi \u2208 V appears exactly once. If \u03c9 is a complete conjunction, then \u03c9 |= (Vi = vi) if and only of Vi = vi appears in \u03c9. For an arbitrary formula B the expression \u03c9 |= B evaluates in the usual way.\nLet \u2126 be the set of all complete conjunctions of V, i. e., the set of all interpretations of the propositional language induced by V.\nProbabilistic knowledge bases are build using probabilistic constraints, that impose certain restrictions on the conditional probabilities of the models of the knowledge base. A probabilistic constraint r is an expression of the form (A |B)[d] with formulas A,B and d \u2208 [0, 1]. If B = > we write (A)[d] instead of (A | >)[d]. A set of probabilistic constraints R = {r1, . . . , rm} is called a knowledge base. Let R denote the set of all knowledge bases. The models of a knowledge base R are the probability distributions PR : \u2126\u2192 [0, 1] that fulfill all restrictions on the conditional probabilities imposed by the probabilistic constraints in R. More specific, a probability distribution PR : \u2126 \u2192 [0, 1] is a model for a knowledge base R, written PR |= R, if and only if PR |= r for every r \u2208 R. That is\nPR |= (A |B)[d] :\u21d4 PR(A |B) = d \u21d4 PR(AB) = d \u00b7 P (B)\nwith PR(A) = \u2211 \u03c9\u2208\u2126,\u03c9|=A PR(\u03c9) .\nObserve, that we used the notation PR(AB) = d\u00b7P (B) to express that the conditional probability of PR(A |B) is d in order to avoid a case differentiation for PR(B) = 0. For the rest of this paper, we assume that all probabilistic constraints are self-consistent, i. e., for every singleton set {r} with r being a probabilistic constraint we assume that {r} has a model. For example, we forbid constraints of the form (A |A)[d] with d > 0 and the like.\nA knowledge base R made of probabilistic constraints describes incomplete knowledge. Usually, one is interested in performing inductive representation techniques and thus in computing a single probability distribution that describes R best and thus gives a complete description of the problem area at hand. This can be done using methods based on maximum entropy, which feature several nice properties (Paris, 1994; Grove et al., 1994; Kern-Isberner, 2001; Ro\u0308dder and Meyer, 1996). Although these methods are not the topic of the present paper, consistency is a necessary requirement for their application."}, {"heading": "3 Determining Consistency", "text": "It must not always be the case, that a probability distribution PR with PR |= R for a knowledge base R exists, e. g., for the knowledge base R = {(A |B)[0.5], (B | >)[0.5], (A | >)[0.1]} with literals A,B there is no distribution PR with PR |= R.\nHence, we are interested in determining for a specific knowledge base R, whether R is consistent (if there is at least on distribution PR with PR |= R) or inconsistent (if there is no such PR).\nIn the following, we reduce this problem to a constraint satisfaction problem similar to the approaches in (Hansen and Jaumard, 1996; Andersen and Pretolani, 2001), which consider purely propositional knowledge bases without conditional constraints. Let R be a knowledge base. For a probability distribution PR : \u2126 \u2192 [0, 1] to be a model of R, every probabilistic constraint (A |B)[d] \u2208 R imposes PR(A |B) = d to hold. Let Mod(A) = {\u03c9 \u2208 \u2126 |\u03c9 |= A} be the set of all models of the formula A. For every complete conjunction \u03c9 \u2208 \u2126 we introduce a variable \u03b1\u03c9 that determines the unknown value of PR(\u03c9). Then (A |B)[d] translates to\u2211\n\u03c9\u2208Mod(AB)\n\u03b1\u03c9 = d \u00b7 \u2211\n\u03c9\u2208Mod(B)\n\u03b1\u03c9 . (1)\nIn order to ensure that PR is indeed a probability distribution we need the following normalization constraints \u2211\n\u03c9\u2208\u2126 \u03b1\u03c9 = 1 (2)\n\u2200\u03c9 \u2208 \u2126 : \u03b1\u03c9 \u2265 0 . (3)\nTaken together for all probabilistic constraints r \u2208 R the corresponding equation (1) and the equations (2) and (3), this yields a constraint satisfaction problem CSR on the variables {\u03b1\u03c9 |\u03c9 \u2208 \u2126}. Proposition 1. Let R be a knowledge base. R is consistent if and only if CSR has a solution.\nThe proof of Proposition 1 is straightforward as every assignment of values to the variables \u03b1\u03c9, that is legal with respect to the constraint satisfaction problem CSR, directly corresponds to a probability distribution PR with PR(\u03c9) = \u03b1\u03c9. Hence, if there is an assignment for all \u03b1\u03c9 the corresponding probability distribution PR is a model for all probabilistic constraints r \u2208 R and therefore a model for R."}, {"heading": "4 Measuring Inconsistency", "text": "The simple piece of information that a knowledge base R is inconsistent is not always sufficient for knowledge engineering and analyzing. In order to fix the knowledge base more detailed information on the inconsistency is necessary. There is much work on analyzing inconsistency in qualitative frameworks, see e. g. (Knight, 2001; Wong and Besnard, 2001; Hunter and\nKonieczny, 2006), but there is very less work on analyzing inconsistency in quantitative frameworks, especially in probabilistic frameworks as the one discussed here (Finthammer et al., 2007). While (Finthammer et al., 2007) is mainly concerned with resolving inconsistencies using heuristics, here we take a more formal approach in the analysis of inconsistency by formalizing and developing an inconsistency measure on probabilistic knowledge bases.\nWe go on by stating some desirable properties of an inconsistency measure on knowledge bases. Afterwards we propose a simple inconsistency measure that is based on the constraint satisfaction problem CSR and also fulfills the desirable properties."}, {"heading": "4.1 Desirable Properties", "text": "Let Inc be a function Inc : R \u2192 [0,\u221e] that maps a knowledge base R \u2208 R onto a positive real. We desire several properties of Inc in order of Inc describing an inconsistency measure. Some of the following properties are adapted from (Hunter and Konieczny, 2006) and rewritten to fit a probabilistic framework. Intuitively we want Inc to be a function on knowledge bases that is monotonically increasing with the inconsistency in the knowledge base. If the knowledge base is consistent, Inc shall be minimal. For the upcoming definitions let R be an arbitrary knowledge base and r, r\u2032 be probabilistic constraints.\n(Consistency) If R is consistent, then Inc(R) = 0.\n(Inconsistency) If R is inconsistent, then Inc(R) > 0.\nThe above properties ensure that Inc is indeed an inconsistency measure and not an information measure (Cover, 2001) as it should not distinguish between different consistent knowledge bases but measure inconsistent ones.\n(Monotonicity) It is Inc(R) \u2264 Inc(R \u222a {r}).\n(Super-Additivity) If R\u2229R\u2032 = \u2205, it is Inc(R\u222aR\u2032) \u2265 Inc(R) + Inc(R\u2032).\nThe measure of inconsistency can only increase when new pieces of information are added to the knowledge base. Thus inconsistencies cannot be resolved with new information. (Super-Additivity) is the stronger property, as it can be easily seen that (SuperAdditivity) implies (Monotonicity).\n(Weak Independence) If no literal in r is mentioned in R, then it is Inc(R) = Inc(R \u222a {r}).\nAs we assume that all probabilistic constraints are selfconsistent, the addition of a constraint not involving any parts of the language mentioned yet shall not lead to an increase in the inconsistency.\nWe say that r is a free constraint iff for every set R\u2032 \u2286 R such that R\u2032 is inconsistent and minimal with this property, it is r /\u2208 R\u2032. Then we can strengthen the above property as follows.\n(Independence) If r is a free constraint in R \u222a {r}, then it is Inc(R) = Inc(R \u222a {r}).\nThis property ensures that not only constraints that do not use literals previously mentioned cannot increase inconsistency, but also constraints that do not take part in any inconsistency of the knowledge base do so. It is easy to see that satisfaction of the second property implies satisfaction of the first property.\nProposition 2. If Inc satisfies (Independence), then Inc satisfies (Weak Independence).\nThe previous two properties describe cases where the inconsistency of a knowledge base should remain constant despite the addition of new information. Conversely, the next property describes a case when the inconsistency should increase.\n(Penalty) If r is not a free constraint in R\u222a{r}, then it is Inc(R) < Inc(R \u222a {r}).\nSimilar to the motivation for (Independence) we state that if a probabilistic constraint r contributes to a minimal inconsistent subset of the knowledge base, then the inconsistency must be strictly greater than in the knowledge base without r.\nSo far we have not taken into account that we are working in a probabilistic framework. It is hard to grasp in what way the probabilities of the conditionals influence the inconsistency of the whole knowledge base. Consider a knowledge base R and a probabilistic constraint (A |B)[d] \u2208 R. How should the inconsistency measure Inc behave when increasing (or decreasing) the value d? There is no definite answer to this question as, on the one hand, the inconsistency may vanish because the constraint may become consistent with the rest of the knowledge base, or, on the other hand, the inconsistency may rise because the constraint may remove itself from a \u201cconsistent state\u201d. But one demand can be made: The change in the measure of inconsistency should be continuous in d. If one does only slightly change a given knowledge base, the resulting inconsistency measure should have only changed slightly as well. We formalize this intuition as follows.\nDefinition 1 (Characteristic function). Let R = {(A1 |B1)[d1], . . . , (An |Bn)[dn]} be a knowledge base. The function \u039bR : [0, 1]n \u2192 R with\n\u039bR(x1, . . . , xn) = {(A1 |B1)[x1], . . . , (An |Bn)[xn]}\nis called the characteristic function of R.\nDefinition 2 (Characteristic Inconsistency function). Let R be a knowledge base with |R| = n. The function \u03b8Inc,R : [0, 1]n \u2192 [0,\u221e] with \u03b8Inc,R = Inc \u25e6 \u039bR is called the characteristic inconsistency function of Inc and R.\nThe above definitions allow us to state our last property in a concise way as follows.\n(Continuity) The characteristic inconsistency function \u03b8Inc,R is continuous in all arguments."}, {"heading": "4.2 An Inconsistency Measure", "text": "In this subsection we develop an inconsistency measure on probabilistic knowledge bases that fulfills the basic properties described above. For this reason, we extend the consistency test from the previous section by including variables that measure the deviation of the values of the probabilistic constraints from consistent ones in a minimal way. But first, consider the following remark.\nRemark 1. For every set R\u2032 = {(A1 |B1), . . . , (An |Bn)} of qualitative conditionals (neglecting the probabilistic values) there are reals d1, . . . , dn \u2208 [0, 1], such that R = {(A1 |B1)[d1], . . . , (An |Bn)[dn]} is consistent.\nThis is easy to see, because one can consider any probability distribution P and assign di := P (Ai |Bi). As we only consider self-consistent constraints, every value is computable. Bearing this observation in mind, let R = {(A1 |B1)[d1], . . . , (An |Bn)[dn]} be a knowledge base. For every i = 1, . . . , n we introduce variables \u03b7i, \u03c4i \u2208 [0, 1] that measure the positive and negative minimal deviations of the value of the probabilistic constraint (Ai |Bi)[di]. In the following, we define an optimization problem, that minimizes the deviation of R to a consistent knowledge base. To this end, we have to modify the probabilistic constraints in R in a minimal way, such that the knowledge base R\u2032 with the modified constraints is consistent, i. e., there is a probability distribution PR\u2032 that is a model for R\u2032. As before let \u03b1\u03c9 denote the probability of a complete conjunction \u03c9 \u2208 \u2126. For every constraint (Ai |Bi)[di], i = 1, . . . , n we write\u2211\n\u03c9\u2208Mod(AiBi)\n\u03b1\u03c9 = (di + \u03b7i \u2212 \u03c4i) \u00b7 \u2211\n\u03c9\u2208Mod(Bi)\n\u03b1\u03c9 (4)\nto comprehend for the fact that the modified probabilistic constraint (Ai |Bi)[di + \u03b7i \u2212 \u03c4i] imposes PR\u2032(Ai |Bi) = di + \u03b7i \u2212 \u03c4i1. To ensure well-formed constraints we also have to consider the following normalization constraints\n0 \u2264 d1 + \u03b71 \u2212 \u03c41 \u2264 1, . . . , 0 \u2264 dn + \u03b7n \u2212 \u03c4n \u2264 1 (5)\nand as before \u2211 \u03c9\u2208\u2126 \u03b1\u03c9 = 1 (6)\n\u2200\u03c9 \u2208 \u2126 : \u03b1\u03c9 \u2265 0 . (7)\nWe denote with OPTR the set of constraints (4), (5), (6), and (7) for a knowledge base R. In order to determine the minimal necessary deviation of R from a consistent knowledge base, we formulate an optimization problem by minimizing the function\nf(\u03b71, . . . , \u03b7n, \u03c41, . . . , \u03c4n) = \u03b71 + . . .+ \u03b7n + \u03c41 + . . .+ \u03c4n\ngiven OPTR. Let Inc\u2217(R) denote the solution for f in this optimization problem and let \u03b7\u22171 , . . . , \u03b7 \u2217 n, \u03c4 \u2217 1 , . . . , \u03c4 \u2217 n be the parameters for a minimal value. Considering again Remark 1, there is always a solution for the optimization problem defined above.\nProposition 3. For every knowledge base R, the value Inc\u2217(R) is well-defined.\nAs not all constraints in this optimization problem are strictly convex, the values of \u03b7\u22171 , . . . , \u03b7 \u2217 n, \u03c4 \u2217 1 , . . . , \u03c4 \u2217 n do not have to be unique in general (Boyd and Vandenberghe, 2004). But some straightforward observations can be made on the value of Inc\u2217.\nProposition 4. If \u03b7\u2217i > 0 then \u03c4 \u2217 i = 0 and if \u03c4 \u2217 i > 0 then \u03b7\u2217i = 0. Proposition 5. Let R = {(A1 |B1)[d1], . . . , (An |Bn)[dn]} be a knowledge base, then it is\n0 \u2264 Inc\u2217(R) \u2264 \u2211\n1\u2264i\u2264n\nmax(di, 1\u2212 di) \u2264 n .\nFor any specific knowledge base R Proposition 5 states that the value of Inc\u2217(R) is bounded above by the number of conditionals in R. By exploiting this observation one can define a normalized inconsistency measure by\nInc\u22170(R) =def { 0 if R = \u2205 Inc\u2217(R) |R | otherwise\n1We explicitly distinguish between positive (\u03b7i) and negative (\u03c4i) deviations to avoid determining absolute values when summing the deviations (see below).\nwith values between zero and one for any knowledge base R. However, we will go on by investigating the properties of the unnormalized inconsistency measure Inc\u2217, which naturally apply to the normalized inconsistency measure Inc\u22170 as well. Example 1. Consider the knowledge base R1 = {r1, r2, r3, r4} with r1 = (A |B)[0.8], r2 = (A |B)[0.6], r3 = (B)[0.5], and r4 = (A)[0.2]. Here, it is Inc\u2217(R1) = 0.5 with \u03b7\u22171 = \u03c4 \u2217 1 = \u03b7 \u2217 2 = \u03c4 \u2217 2 = \u03b7 \u2217 3 = \u03c4 \u2217 3 = \u03c4 \u2217 4 = 0 and \u03b7\u22174 = 0.5. Therefore, the fourth constraint (A)[0.2] has to be adjusted to (A)[0.7] in order to restore consistency (this is just one possible adjustment). Example 2. Consider the knowledge base R2 = {r1, r2, r3} with r1 = (A |B)[1], r2 = (B)[1], and r3 = (A)[0]. Here, it is Inc\u2217(R2) = 1 with \u03b7\u22171 = \u03b7 \u2217 2 = \u03c4\u22172 = \u03b7 \u2217 3 = \u03c4 \u2217 3 = 0 and \u03c4 \u2217 1 = 1.\nAs the next example shows, it must not always be a single probabilistic constraint, that has to be modified in order to restore consistency. Example 3. Consider the knowledge base R3 = {r1, r2, r3, r4, r5} with r1 = (A |C)[0.7], r2 = (B |C)[0.8], r3 = (A)[0.2], r4 = (B)[0.3], and r5 = (C)[0.5]. Here, it is Inc\u2217(R2) = 0.25 with \u03b7\u22171 = \u03c4 \u2217 1 = \u03b7\u22172 = \u03c4 \u2217 2 = \u03c4 \u2217 3 = \u03c4 \u2217 4 = 0 and \u03b7 \u2217 3 = 0.15 and \u03b7 \u2217 4 = 0.1.\nWe show now that Inc\u2217 is indeed an appropriate inconsistency measure for probabilistic knowledge bases as it satisfies the desired properties described in the previous section. Proposition 6. The function Inc\u2217 satisfies (Consistency), (Inconsistency), (Monotonicity), (SuperAdditivity), (Weak Independence), (Independence), (Penalty), and (Continuity).\nAs mentioned before Proposition 6 also applies to the normalized inconsistency measure Inc\u22170. This is especially true for the property (Continuity) as for R = \u2205 the function \u03b8Inc\u22170 ,R trivializes to the constant (and therefore continuous) function \u03b8Inc\u22170 ,R = 0."}, {"heading": "5 Determining the Causes of Inconsistency", "text": "In Example 2 it has been shown, that the first constraint (A |B)[1] had to be modified in order to restore consistency of the knowledge base R2. This might tempt to make the assumption that this constraint is alone responsible for the inconsistency in R2. But if one looks at R2 in more depth, one can see that the situation is symmetrical in all three constraints. The optimization problem has more than one solution, as for example \u03b7\u22172 = 1 also solves the inconsistency (with all other values being zero) with the same inconsistency measure of one. In fact, most inconsistent knowledge\nbases feature this behavior, as for the optimization problem it is best to alter as less values of the probabilistic constraints as possible. Usually, one is not only interested in determining a simple value of inconsistency, but to determine the causes of the inconsistency and ultimately to restore consistency. In Example 2 all three constraints are equally responsible for producing the inconsistency in R2. In order to achieve a more in-depth analysis of the inconsistency in probabilistic knowledge bases in general, we apply the same technique as in (Hunter and Konieczny, 2006), where the Shapley value (Shapley, 1953) is used to determine the causes of inconsistency in propositional knowledge bases.\nWe go one by giving a short overview over coalition game theory and the role of the Shapley value in it, followed by the definition of the Shapley inconsistency measure on probabilistic knowledge bases."}, {"heading": "5.1 Coalition Game Theory", "text": "Coalition game theory is concerned with games, where players can form coalitions in order to maximize their own payoff of the game. Let P denote the power set. Definition 3 (Coalition Game). A coalition game (N, v) is composed of a set of players N \u2286 N and a function v : P(N)\u2192 R with v(\u2205) = 0 and v(S \u222a T ) \u2265 v(S) + v(T ) for S, T \u2286 N with S \u2229 T = \u2205.\nFor every possible coalition C \u2286 N of players in the game, the value v(C) determines the payoff this coalition gets. As this payoff must be distributed on the members of C, every player has to evaluate for his own, which coalition to form in order to maximize his own expected payoff. Not every player has to expect the same payoff for himself, as players may be more or less important for the forming of coalitions. Example 4 (taken from (Hunter and Konieczny, 2006)). LetN = {1, 2, 3} and the function v : P(N)\u2192 R be defined as\nv({1}) = 1 v({2}) = 0 v({3}) = 1 v({1, 2}) = 10 v({2, 3}) = 11 v({1, 3}) = 4\nv({1, 2, 3}) = 12\nIn this game, not every player should expect the same payoff, as for instance it is more advantageous for player 1 to form a coalition with player 2 rather than with player 3 alone.\nA solution to a coalition game (N, v) consists of an assignment Si(v) of payoffs to each player i \u2208 N , that is fair in the sense that every player gets as much payoff as his contribution in the grand coalition N weighs. Some formal desirable properties of a solution are as follows.\n(Efficiency) \u2211\ni\u2208N Si(v) = v(N)\n(Symmetry) For all i, j \u2208 N , if v(C \u222a {i}) = v(C \u222a {j}) for all C \u2286 N \\ {i, j} then Si(v) = Sj(v)\n(Dummy) If for i \u2208 N it is v(C) = v(C \u222a {i}) for all C \u2286 N then it is Si(v) = 0\n(Additivity) Si(v + w) = Si(v) + Si(w)\nA solution should comprehend for the fact, that the value to be distributed among the players is the maximal value that can be achieved (Efficiency). If two players are indistinguishable by their contributions to the coalitions, they deserve the same payoff (Symmetry); if a player does not contribute to any coalition at all, his payoff should be zero (Dummy). (Additivity) describes the desired behavior of a solution if two coalition games are combined.\nIt can be shown (Shapley, 1953), that the Shapley value defined as follows is the only solution for a coalition game that satisfies (Efficiency), (Symmetry), (Dummy), and (Additivity).\nDefinition 4 (Shapley Value). Let (N, v) be a coalition game. The Shapley Value Si(v) for a player i \u2208 N is defined as Si(v) = \u2211\nC\u2286N\n(|C| \u2212 1)!(|N | \u2212 |C|)! |N |! (v(C)\u2212 v(C \\ {r})\nExample 5 ((Hunter and Konieczny, 2006)). The Shapley values for the players 1, 2, 3 from Example 4 are\nS1(v) \u2248 2.83 S2(v) \u2248 5.83 S3(v) \u2248 3.3"}, {"heading": "5.2 Shapley Inconsistency Measure", "text": "We now define in accordance to (Hunter and Konieczny, 2006) a Shapley function using an inconsistency measure Inc, thus being enabled to further investigate the causes of inconsistency.\nDefinition 5 (Probabilistic Shapley Inconsistency Measure). Let K be a knowledge base, r \u2208 K a probabilistic constraint, and Inc an inconsistency measure. We define the probabilistic Shapley inconsisteny measure SKInc(r) of r in K as SKInc(r) = \u2211\nC\u2286K\n(|C| \u2212 1)!(n\u2212 |C|)! n! (Inc(C)\u2212Inc(C\\{r}))\nUsing the probabilistic Shapley inconsistency value we can obtain more specific information about how the\ninconsistency is distributed on the probabilistic constraints of a knowledge base. In the following we use the inconsistency measure Inc\u2217 developed in the previous section for the application of the Shapley inconsistency measure. Example 6. Consider again the knowledge base R1 = {r1, r2, r3, r4} with r1 = (A |B)[0.8], r2 = (A |B)[0.6], r3 = (B)[0.5], and r4 = (A)[0.2] from Example 1 with Inc\u2217(R1) = 0.5. There it is SR1Inc\u2217(r1) \u2248 0.15, SR1Inc\u2217(r2) \u2248 0.117, S R1 Inc\u2217(r3) \u2248 0.05, and S R1 Inc\u2217(r4) \u2248 0.183. The distribution of the Shapley values indicates that the constraint r4 = (A)[0.2] is mostly responsible for the inconsistency in R1 and r3 = (B)[0.5] is less responsible. This can be justified as both rules r1 and r2 describe an influence of B on A and \u2013 assuming that the knowledge base describes causal rather that diagnostic information \u2013 thus state that B is more entrenched or more basic than A. Thus, rule r4 that gives a probability of A not conditioned on anything else, is most dangerous for consistency. Example 7. Consider again the knowledge base R2 = {r1, r2, r3} with r1 = (A |B)[1], r2 = (B)[1], and r3 = (A)[0] from Example 2 with Inc\u2217(R2) = 1. There it is SR2Inc\u2217(r1) \u2248 0.33, S R2 Inc\u2217(r2) \u2248 0.33, and SR2Inc\u2217(r3) \u2248 0.33. Here it is clear, that all three probabilistic constraints are equally responsible for the inconsistency in R2. This reflects the intuition described above. Example 8. Consider again the knowledge base R3 = {r1, r2, r3, r4, r5} with r1 = (A |C)[0.7], r2 = (B |C)[0.8], r3 = (A)[0.2], r4 = (B)[0.3], and r5 = (C)[0.5] from Example 3 with Inc\u2217(R3) = 0.25. There it is SR3Inc\u2217(r1) \u2248 0.062, S R3 Inc\u2217(r2) \u2248 0.045, S R3 Inc\u2217(r3) \u2248 0.062, SR3Inc\u2217(r4) \u2248 0.045, and S R3 Inc\u2217(r5) \u2248 0.036.\nThe probabilistic Shapley inconsistency measure satisfies the same properties as the Shapley value due to its direct application on an inconsistency measure. Proposition 7. If Inc is an inconsistency measure that satisfies (Consistency) and (Super-Additivity), then the probabilistic Shapley inconsistency measure SInc satisfies\n(Efficiency) \u2211\nr\u2208R S R Inc(r) = Inc(R)\n(Symmetry) For all r, r\u2032 \u2208 R, if Inc(R\u2032 \u222a {r}) = Inc(R\u2032\u222a{r\u2032}) for all R\u2032 \u2286 R\\{r, r\u2032} then SRInc(r) = SInc(r\u2032)\n(Dummy) If for r \u2208 R it is Inc(R\u2032) = Inc(R\u2032 \u222a {r}) for all R\u2032 \u2286 R then it is SRInc(r) = 0\nThe property (Additivity) was neglected as it does not make sense for our application, cf. (Hunter and Konieczny, 2006). From Proposition 7 it follows directly\nCorollary 1. The probabilistic Shapley inconsistency measure SInc\u2217 satisfies (Efficiency), (Symmetry), and (Dummy).\nUsing the inconsistency measure Inc\u2217 and the Shapley inconsistency measure SRInc\u2217 the knowledge engineer can support his efforts to restore consistency in a probabilistic knowledge base R. The solutions of the optimization problem OPTR describe the minimal adjustments to be made in order to restore consistency. By considering the Shapley inconsistency measures SRInc\u2217 for the constraints in R one can select the most appropriate solution and modify the knowledge base accordingly. We will formalize this approach of restoring consistency using inconsistency measures in an upcoming paper."}, {"heading": "6 Summary and Discussion", "text": "We developed an inconsistency measure on conditional probabilistic knowledge bases and showed that this measure satisfies several desirable properties. We went on by using this measure and the well-known Shapley value to define a more sophisticated measure that gives the knowledge engineer the means to restore consistency of a knowledge base by identifying the causes for the inconsistency. Due to its heritage from the Shapley value the Shapley inconsistency measure satisfies several nice properties.\nThe examples in this paper were computed by a prototypical implementation of the function Inc\u2217 and SRInc\u2217 in Java which uses the free optimization software OpenOpt2 to solve the optimization problems of type OPTR.\nThe inconsistency measure described here and inconsistency measures in general are useful when dealing with data from heterogenous sources as in information fusion or belief revision (Bloch and Hunter, 2001; Alchourro\u0301n et al., 1985; Kern-Isberner and Ro\u0308dder, 2003). They can point at discrepancies in the data representation and give hints on possible fixes within the model. Many expert systems in highly-crucial application areas like medical diagnosis or fraud detection demand to draw consistent conclusions but need to use distorted and ambiguous information at the same time. Actually, we are currently investigating the possibilities of applying information engineering techniques as the described inconsistency measure and information fusion in the field of fraud detection in the annual audit relating to commercial law. For future work we also plan to extend and apply the work reported here on relational probabilistic knowledge bases.\n2http://openopt.org/\nAcknowledgments. The research reported here was partially supported by the Deutsche Forschungsgemeinschaft under grant KE 1413/2-1."}], "references": [{"title": "On the logic of theory change: Partial meet contraction and revision functions", "author": ["C.E. Alchourr\u00f3n", "P. G\u00e4rdenfors", "D. Makinson"], "venue": "Journal of Symbolic Logic,", "citeRegEx": "Alchourr\u00f3n et al\\.,? \\Q1985\\E", "shortCiteRegEx": "Alchourr\u00f3n et al\\.", "year": 1985}, {"title": "Easy cases of probabilistic satisfiability", "author": ["K.A. Andersen", "D. Pretolani"], "venue": "Annals of Mathematics and Artificial Intelligence,", "citeRegEx": "Andersen and Pretolani.,? \\Q2001\\E", "shortCiteRegEx": "Andersen and Pretolani.", "year": 2001}, {"title": "Argumentation in artificial intelligence", "author": ["T.J.M. Bench-Capon", "P.E. Dunne"], "venue": "Artificial Intelligence,", "citeRegEx": "Bench.Capon and Dunne.,? \\Q2007\\E", "shortCiteRegEx": "Bench.Capon and Dunne.", "year": 2007}, {"title": "Some Syntactic Approaches to the Handling of Inconsistent Knowledge Bases: A Comparative Study \u2013 Part 1: The Flat Case", "author": ["S. Benferhat", "D. Dubois", "H. Prade"], "venue": "Studia Logica,", "citeRegEx": "Benferhat et al\\.,? \\Q1997\\E", "shortCiteRegEx": "Benferhat et al\\.", "year": 1997}, {"title": "Possibilistic and Standard Probabilistic Semantics of Conditional Knowledge Bases", "author": ["S. Benferhat", "D. Dubois", "H. Prade"], "venue": "Journal of Logic and Computation,", "citeRegEx": "Benferhat et al\\.,? \\Q1999\\E", "shortCiteRegEx": "Benferhat et al\\.", "year": 1999}, {"title": "Propositional clausal defeasible logic", "author": ["D. Billington"], "venue": "Proceedings of JELIA 2008,", "citeRegEx": "Billington.,? \\Q2008\\E", "shortCiteRegEx": "Billington.", "year": 2008}, {"title": "Fusion: General Concepts and Characteristics", "author": ["I. Bloch", "A. Hunter"], "venue": "International Journal of Intelligent Systems,", "citeRegEx": "Bloch and Hunter.,? \\Q2001\\E", "shortCiteRegEx": "Bloch and Hunter.", "year": 2001}, {"title": "Convex Optimization", "author": ["S.P. Boyd", "L. Vandenberghe"], "venue": null, "citeRegEx": "Boyd and Vandenberghe.,? \\Q2004\\E", "shortCiteRegEx": "Boyd and Vandenberghe.", "year": 2004}, {"title": "Elements of Information Theory. WileyInterscience", "author": ["T.M. Cover"], "venue": "New York, second edition,", "citeRegEx": "Cover.,? \\Q2001\\E", "shortCiteRegEx": "Cover.", "year": 2001}, {"title": "Inconsistency in Possibilistic Knowledge Bases: To live with it or not live with it", "author": ["D. Dubois", "J. Lang", "H. Prade"], "venue": "Fuzzy Logic for the Management of Uncertainty ,", "citeRegEx": "Dubois et al\\.,? \\Q1992\\E", "shortCiteRegEx": "Dubois et al\\.", "year": 1992}, {"title": "Resolving inconsistencies in probabilistic knowledge bases", "author": ["M. Finthammer", "G. Kern-Isberner", "M. Ritterskamp"], "venue": "KI", "citeRegEx": "Finthammer et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Finthammer et al\\.", "year": 2007}, {"title": "Random worlds and maximum entropy", "author": ["A.J. Grove", "J.Y. Halpern", "D. Koller"], "venue": "Journal of Artificial Intelligence Research (JAIR),", "citeRegEx": "Grove et al\\.,? \\Q1994\\E", "shortCiteRegEx": "Grove et al\\.", "year": 1994}, {"title": "Approaches to measuring inconsistent information", "author": ["A. Hunter", "S. Konieczny"], "venue": "In Inconsistency Tolerance,", "citeRegEx": "Hunter and Konieczny.,? \\Q2004\\E", "shortCiteRegEx": "Hunter and Konieczny.", "year": 2004}, {"title": "Shapley inconsistency values", "author": ["A. Hunter", "S. Konieczny"], "venue": "In Proceedings of the 10th International Conference on Knowledge Representation", "citeRegEx": "Hunter and Konieczny.,? \\Q2006\\E", "shortCiteRegEx": "Hunter and Konieczny.", "year": 2006}, {"title": "Belief revision and information fusion in a probabilistic environment", "author": ["G. Kern-Isberner", "W. R\u00f6dder"], "venue": "In Proceedings of FLAIRS\u201903,", "citeRegEx": "Kern.Isberner and R\u00f6dder.,? \\Q2003\\E", "shortCiteRegEx": "Kern.Isberner and R\u00f6dder.", "year": 2003}, {"title": "Conditionals in Nonmonotonic Reasoning and Belief Revision", "author": ["G. Kern-Isberner"], "venue": "Number 2087 in Lecture Notes in Computer Science. Springer,", "citeRegEx": "Kern.Isberner.,? \\Q2001\\E", "shortCiteRegEx": "Kern.Isberner.", "year": 2001}, {"title": "Measuring inconsistency", "author": ["K.M. Knight"], "venue": "Journal of Philosophical Logic,", "citeRegEx": "Knight.,? \\Q2001\\E", "shortCiteRegEx": "Knight.", "year": 2001}, {"title": "Reasoning under inconsistency: The forgotten connective", "author": ["S. Konieczny", "J. Lang", "P. Marquis"], "venue": "In Proceedings of IJCAI-2005,", "citeRegEx": "Konieczny et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Konieczny et al\\.", "year": 2005}, {"title": "Resolving contradictions: A plausible semantics for inconsistent systems", "author": ["E.L. Lozinskii"], "venue": "Journal of Automated Reasoning,", "citeRegEx": "Lozinskii.,? \\Q1994\\E", "shortCiteRegEx": "Lozinskii.", "year": 1994}, {"title": "The Uncertain Reasoner\u2019s Companion: A Mathematical Perspective", "author": ["J. Paris"], "venue": null, "citeRegEx": "Paris.,? \\Q1994\\E", "shortCiteRegEx": "Paris.", "year": 1994}, {"title": "Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference", "author": ["J. Pearl"], "venue": null, "citeRegEx": "Pearl.,? \\Q1998\\E", "shortCiteRegEx": "Pearl.", "year": 1998}, {"title": "A logic for default reasoning", "author": ["R. Reiter"], "venue": "Artificial Intelligence,", "citeRegEx": "Reiter.,? \\Q1980\\E", "shortCiteRegEx": "Reiter.", "year": 1980}, {"title": "On inference from inconsistent premises", "author": ["N. Rescher", "R. Manor"], "venue": "Theory and Decision,", "citeRegEx": "Rescher and Manor.,? \\Q1970\\E", "shortCiteRegEx": "Rescher and Manor.", "year": 1970}, {"title": "Coherent Knowledge Processing at Maximum Entropy by SPIRIT", "author": ["W. R\u00f6dder", "C.-H. Meyer"], "venue": "In Proc. of the Twelfth Conf. on Uncertainty in Artificial Intelligence,", "citeRegEx": "R\u00f6dder and Meyer.,? \\Q1996\\E", "shortCiteRegEx": "R\u00f6dder and Meyer.", "year": 1996}, {"title": "Elimination of inconsistent knowledge in the probabilistic expertsystem-shell spirit (in german)", "author": ["W. R\u00f6dder", "L. Xu"], "venue": "In Proc. Symposium Operations Research", "citeRegEx": "R\u00f6dder and Xu.,? \\Q2000\\E", "shortCiteRegEx": "R\u00f6dder and Xu.", "year": 2000}, {"title": "A value for n-person games", "author": ["L.S. Shapley"], "venue": "Contributions to the Theory of Games II,", "citeRegEx": "Shapley.,? \\Q1953\\E", "shortCiteRegEx": "Shapley.", "year": 1953}, {"title": "Paraconsistent reasoning as an analytic tool", "author": ["P. Wong", "P. Besnard"], "venue": "Journal of the Interest Group in Propositional Logic,", "citeRegEx": "Wong and Besnard.,? \\Q2001\\E", "shortCiteRegEx": "Wong and Besnard.", "year": 2001}], "referenceMentions": [{"referenceID": 22, "context": "(Rescher and Manor, 1970; Konieczny et al., 2005), or in other logical frameworks, e.", "startOffset": 0, "endOffset": 49}, {"referenceID": 17, "context": "(Rescher and Manor, 1970; Konieczny et al., 2005), or in other logical frameworks, e.", "startOffset": 0, "endOffset": 49}, {"referenceID": 21, "context": ", 2007), default logics (Reiter, 1980), defeasible logics (Billington, 2008), and argumentation theory (Bench-Capon and Dunne, 2007).", "startOffset": 24, "endOffset": 38}, {"referenceID": 5, "context": ", 2007), default logics (Reiter, 1980), defeasible logics (Billington, 2008), and argumentation theory (Bench-Capon and Dunne, 2007).", "startOffset": 58, "endOffset": 76}, {"referenceID": 2, "context": ", 2007), default logics (Reiter, 1980), defeasible logics (Billington, 2008), and argumentation theory (Bench-Capon and Dunne, 2007).", "startOffset": 103, "endOffset": 132}, {"referenceID": 18, "context": "(Lozinskii, 1994; Benferhat et al., 1997; Knight, 2001; Hunter and Konieczny, 2004), and some in quantitative frameworks (mainly possibilistic frameworks), e.", "startOffset": 0, "endOffset": 83}, {"referenceID": 3, "context": "(Lozinskii, 1994; Benferhat et al., 1997; Knight, 2001; Hunter and Konieczny, 2004), and some in quantitative frameworks (mainly possibilistic frameworks), e.", "startOffset": 0, "endOffset": 83}, {"referenceID": 16, "context": "(Lozinskii, 1994; Benferhat et al., 1997; Knight, 2001; Hunter and Konieczny, 2004), and some in quantitative frameworks (mainly possibilistic frameworks), e.", "startOffset": 0, "endOffset": 83}, {"referenceID": 12, "context": "(Lozinskii, 1994; Benferhat et al., 1997; Knight, 2001; Hunter and Konieczny, 2004), and some in quantitative frameworks (mainly possibilistic frameworks), e.", "startOffset": 0, "endOffset": 83}, {"referenceID": 9, "context": "(Dubois et al., 1992).", "startOffset": 0, "endOffset": 21}, {"referenceID": 15, "context": "Here, we aim at analyzing inconsistencies in a probabilistic framework and in particular measuring inconsistency in conditional probabilistic knowledge bases (Nute and Cross, 2002; Kern-Isberner, 2001; Benferhat et al., 1999; R\u00f6dder and Meyer, 1996).", "startOffset": 158, "endOffset": 249}, {"referenceID": 4, "context": "Here, we aim at analyzing inconsistencies in a probabilistic framework and in particular measuring inconsistency in conditional probabilistic knowledge bases (Nute and Cross, 2002; Kern-Isberner, 2001; Benferhat et al., 1999; R\u00f6dder and Meyer, 1996).", "startOffset": 158, "endOffset": 249}, {"referenceID": 23, "context": "Here, we aim at analyzing inconsistencies in a probabilistic framework and in particular measuring inconsistency in conditional probabilistic knowledge bases (Nute and Cross, 2002; Kern-Isberner, 2001; Benferhat et al., 1999; R\u00f6dder and Meyer, 1996).", "startOffset": 158, "endOffset": 249}, {"referenceID": 20, "context": "In contrast to probabilistic networks like Bayesian Networks (Pearl, 1998) conditional probabilistic knowledge bases do not demand the complete specification of every conditional probability of every probabilistic dependence and thus do not define a unique probability distribution as the underlying model.", "startOffset": 61, "endOffset": 74}, {"referenceID": 11, "context": "Nonetheless, using maximum entropy methods (Grove et al., 1994) one can determine a single probability distribution that describes the specified knowledge in an unbiased way.", "startOffset": 43, "endOffset": 63}, {"referenceID": 10, "context": "There is very little work on the treatment of inconsistencies in a conditional probabilistic framework (R\u00f6dder and Xu, 2001; Finthammer et al., 2007).", "startOffset": 103, "endOffset": 149}, {"referenceID": 10, "context": "The method described in (Finthammer et al., 2007) consists of a set of heuristics that are used to restore consistency in a knowledge base.", "startOffset": 24, "endOffset": 49}, {"referenceID": 1, "context": "Other related work (Hansen and Jaumard, 1996; Andersen and Pretolani, 2001) investigates inconsistencies in classiTHIMM 530 UAI 2009", "startOffset": 19, "endOffset": 75}, {"referenceID": 1, "context": "Furthermore the authors of (Hansen and Jaumard, 1996; Andersen and Pretolani, 2001) are mainly interested in efficient algorithms for determining whether a knowledge base is inconsistent and not to what degree.", "startOffset": 27, "endOffset": 83}, {"referenceID": 13, "context": "Furthermore we apply the approach taken in (Hunter and Konieczny, 2006) on our framework and use the Shapley value (Shapley, 1953) to define a more sophisticated inconsistency measure based on the basic inconsistency measure developed before.", "startOffset": 43, "endOffset": 71}, {"referenceID": 25, "context": "Furthermore we apply the approach taken in (Hunter and Konieczny, 2006) on our framework and use the Shapley value (Shapley, 1953) to define a more sophisticated inconsistency measure based on the basic inconsistency measure developed before.", "startOffset": 115, "endOffset": 130}, {"referenceID": 19, "context": "This can be done using methods based on maximum entropy, which feature several nice properties (Paris, 1994; Grove et al., 1994; Kern-Isberner, 2001; R\u00f6dder and Meyer, 1996).", "startOffset": 95, "endOffset": 173}, {"referenceID": 11, "context": "This can be done using methods based on maximum entropy, which feature several nice properties (Paris, 1994; Grove et al., 1994; Kern-Isberner, 2001; R\u00f6dder and Meyer, 1996).", "startOffset": 95, "endOffset": 173}, {"referenceID": 15, "context": "This can be done using methods based on maximum entropy, which feature several nice properties (Paris, 1994; Grove et al., 1994; Kern-Isberner, 2001; R\u00f6dder and Meyer, 1996).", "startOffset": 95, "endOffset": 173}, {"referenceID": 23, "context": "This can be done using methods based on maximum entropy, which feature several nice properties (Paris, 1994; Grove et al., 1994; Kern-Isberner, 2001; R\u00f6dder and Meyer, 1996).", "startOffset": 95, "endOffset": 173}, {"referenceID": 1, "context": "In the following, we reduce this problem to a constraint satisfaction problem similar to the approaches in (Hansen and Jaumard, 1996; Andersen and Pretolani, 2001), which consider purely propositional knowledge bases without conditional constraints.", "startOffset": 107, "endOffset": 163}, {"referenceID": 16, "context": "(Knight, 2001; Wong and Besnard, 2001; Hunter and Konieczny, 2006), but there is very less work on analyzing inconsistency in quantitative frameworks, especially in probabilistic frameworks as the one discussed here (Finthammer et al.", "startOffset": 0, "endOffset": 66}, {"referenceID": 26, "context": "(Knight, 2001; Wong and Besnard, 2001; Hunter and Konieczny, 2006), but there is very less work on analyzing inconsistency in quantitative frameworks, especially in probabilistic frameworks as the one discussed here (Finthammer et al.", "startOffset": 0, "endOffset": 66}, {"referenceID": 13, "context": "(Knight, 2001; Wong and Besnard, 2001; Hunter and Konieczny, 2006), but there is very less work on analyzing inconsistency in quantitative frameworks, especially in probabilistic frameworks as the one discussed here (Finthammer et al.", "startOffset": 0, "endOffset": 66}, {"referenceID": 10, "context": "(Knight, 2001; Wong and Besnard, 2001; Hunter and Konieczny, 2006), but there is very less work on analyzing inconsistency in quantitative frameworks, especially in probabilistic frameworks as the one discussed here (Finthammer et al., 2007).", "startOffset": 216, "endOffset": 241}, {"referenceID": 10, "context": "While (Finthammer et al., 2007) is mainly concerned with resolving inconsistencies using heuristics, here we take a more formal approach in the analysis of inconsistency by formalizing and developing an inconsistency measure on probabilistic knowledge bases.", "startOffset": 6, "endOffset": 31}, {"referenceID": 13, "context": "Some of the following properties are adapted from (Hunter and Konieczny, 2006) and rewritten to fit a probabilistic framework.", "startOffset": 50, "endOffset": 78}, {"referenceID": 8, "context": "The above properties ensure that Inc is indeed an inconsistency measure and not an information measure (Cover, 2001) as it should not distinguish between different consistent knowledge bases but measure inconsistent ones.", "startOffset": 103, "endOffset": 116}, {"referenceID": 7, "context": ", \u03c4 \u2217 n do not have to be unique in general (Boyd and Vandenberghe, 2004).", "startOffset": 44, "endOffset": 73}, {"referenceID": 13, "context": "In order to achieve a more in-depth analysis of the inconsistency in probabilistic knowledge bases in general, we apply the same technique as in (Hunter and Konieczny, 2006), where the Shapley value (Shapley, 1953) is used to determine the causes of inconsistency in propositional knowledge bases.", "startOffset": 145, "endOffset": 173}, {"referenceID": 25, "context": "In order to achieve a more in-depth analysis of the inconsistency in probabilistic knowledge bases in general, we apply the same technique as in (Hunter and Konieczny, 2006), where the Shapley value (Shapley, 1953) is used to determine the causes of inconsistency in propositional knowledge bases.", "startOffset": 199, "endOffset": 214}, {"referenceID": 13, "context": "Example 4 (taken from (Hunter and Konieczny, 2006)).", "startOffset": 22, "endOffset": 50}, {"referenceID": 25, "context": "It can be shown (Shapley, 1953), that the Shapley value defined as follows is the only solution for a coalition game that satisfies (Efficiency), (Symmetry), (Dummy), and (Additivity).", "startOffset": 16, "endOffset": 31}, {"referenceID": 13, "context": "Example 5 ((Hunter and Konieczny, 2006)).", "startOffset": 11, "endOffset": 39}, {"referenceID": 13, "context": "We now define in accordance to (Hunter and Konieczny, 2006) a Shapley function using an inconsistency measure Inc, thus being enabled to further investigate the causes of inconsistency.", "startOffset": 31, "endOffset": 59}, {"referenceID": 13, "context": "(Hunter and Konieczny, 2006).", "startOffset": 0, "endOffset": 28}, {"referenceID": 6, "context": "The inconsistency measure described here and inconsistency measures in general are useful when dealing with data from heterogenous sources as in information fusion or belief revision (Bloch and Hunter, 2001; Alchourr\u00f3n et al., 1985; Kern-Isberner and R\u00f6dder, 2003).", "startOffset": 183, "endOffset": 264}, {"referenceID": 0, "context": "The inconsistency measure described here and inconsistency measures in general are useful when dealing with data from heterogenous sources as in information fusion or belief revision (Bloch and Hunter, 2001; Alchourr\u00f3n et al., 1985; Kern-Isberner and R\u00f6dder, 2003).", "startOffset": 183, "endOffset": 264}, {"referenceID": 14, "context": "The inconsistency measure described here and inconsistency measures in general are useful when dealing with data from heterogenous sources as in information fusion or belief revision (Bloch and Hunter, 2001; Alchourr\u00f3n et al., 1985; Kern-Isberner and R\u00f6dder, 2003).", "startOffset": 183, "endOffset": 264}], "year": 2009, "abstractText": "This paper develops an inconsistency measure on conditional probabilistic knowledge bases. The measure is based on fundamental principles for inconsistency measures and thus provides a solid theoretical framework for the treatment of inconsistencies in probabilistic expert systems. We illustrate its usefulness and immediate application on several examples and present some formal results. Building on this measure we use the Shapley value\u2014a well-known solution for coalition games\u2014to define a sophisticated indicator that is not only able to measure inconsistencies but to reveal the causes of inconsistencies in the knowledge base. Altogether these tools guide the knowledge engineer in his aim to restore consistency and therefore enable him to build a consistent and usable knowledge base that can be employed in probabilistic expert systems.", "creator": "TeX"}}}